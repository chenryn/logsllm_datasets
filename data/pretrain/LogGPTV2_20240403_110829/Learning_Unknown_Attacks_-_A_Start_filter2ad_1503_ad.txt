In  principal,  similarity  is  rule  based  and  consists  of  two  steps:  classification  and
generalization. Classification categorizes bad requests into meaningful types such as
buffer  overflow  or  remote  command  execution  and,  as  required,  further  into  sub-
types.  Generalization  develops  a  set  of  rules  for  determining  similarity  between  an
observed  bad  request  and  a  new  request  based  on  the  classification  results.  These
rules  can  be  implemented  either  as  an  active  checking  process  or  as  comparison
templates for use by another program.
For the proof-of-concept on web server buffer overflow attacks via http requests,
we  implemented  one  rule  that  acts  as  both  a  classifier  and  a  generalizer.  It  is  the
following:
-  If (1) the query length of the bad request is greater than (256+X) [this part of the
rule classifies  the  request  as  a  buffer  overflow  type1]  and  (2)  the  methods  of  the
new request and the bad request are the same and (3) the file extensions of the new
and bad requests are the same and (4) the query length of the new request is greater
than or equal to the query length of the bad request, then return false (i.e., block the
request).
Even with X=0 in this rule, many variants of Code Red I and II are blocked. The
initial or padding characters in the query are irrelevant to how Code Red works; the
length is critical; so whether "XXX..." or "NNN..." or "XNXN..." are in the query of
the  attack,  the  attack  is  blocked.  In  addition,  the  name  of  the  file  (minus  the
extension) is also irrelevant to how Code Red works, because it is the file extension
that identifies the resource (Index Server) that is vulnerable to a buffer overflow, and
it is the query that causes the buffer overflow, not the entire URI. (The URI contains
the path identifying the resource and, optionally, the query.)
The  reason  for  the  first  condition  in  the  rule  is  to  differentiate  in  a  trivial  way
between bad requests that are buffer overflow attacks and bad requests that are some
other type of attack, like remote command execution. Unfortunately, it introduces the
possibility of false negatives, that is, a bad request that was a buffer overflow attack,
but with the overflow occurring after less than 256 characters, would be ignored as an
example to be generalized.
This  rule  has  been  constructed  from  extensive  analysis  of  buffer  overflows  in
general, buffer overflows in IIS and Apache web servers, and Code Red, in particular.
Note that it only generalizes "learned" behavior. That is, if the HACQIT cluster has
never been attacked by Code Red, it will not stop the first Code Red  attack.  It  will
1 X starts out equal to zero. Its role will be discussed later.
172
J.E. Just et al.
also  not  stop  the  first  case  of  a  variant  of  Code  Red  that  uses  the  .IDQ  extension2.
This variant would first have to be "experienced", learned as a bad request, and then
generalized by the above rule. Most importantly, the  rule does  not  prevent  use  of  a
resource  like  Index  Server;  it  prevents  a  wider  variety  of  attacks  that  exploit  an
identified vulnerability in it from reducing availability of the web server.
Although  this  rule  appears  Microsoft-oriented,  as  the  concept  of  file  extensions
does not exist under Unix, it would work against attacks exploiting vulnerabilities in
other software, such as php and perl, because these resources also use file extensions.
It might be possible to generalize this to file types under Unix. The key distinction to
be made is, does the path in the URI identify a document to be returned to the client
or does it identify an executing resource such as a search engine, a DBMS, etc.?
Finding the minimum length of padding characters for a buffer overflow attack is
not  difficult.  We  have  implemented  an  enhanced  version  of  the  forensics  and
generalization  modules  that  iteratively  tests  attack  variants  in  the  Sandbox  with
different  padding  character  lengths.  Specifically  it  successively  tests  padding
character  lengths  between  256  and  (Y-256)  where  Y  is  the  length  of  the  observed
buffer overflow padding size. From this testing, it determines the value of X (which
appears  in  the  first  condition  of  the  generalization  rule  above)  and  passes  it  to  the
ContentFilterBridge  for  inclusion  in  the  revised  generalization  rule.  The  observed
padding size is currently determined by the number of characters before the first non-
printing character (i.e., not ACSII character coder 32 through 126) in the query. While
this  is  only  an  approximation  that  depends  on  certain  assumptions  being  true,  it
proved  to  be  a  very  useful  approach  for  the  proof-of-concept  implementation.  Our
investigation with Code Red II shows the padding in the query that causes the buffer
overflow is no more than one byte over the minimum required; that is, if you remove
two characters from the query, a buffer overflow will not occur, and IIS will respond
to the request correctly and continue to function according to specification.
It is worth comparing this automatic generalization with Snort's hand-coded rules
for  preventing  Code  Red  attacks.  Snort  is  widely  used,  open  source,  lightweight
Intrusion Detection System. Immediately after the flurry of initial Code Red attacks,
Snort aficionados began crafting rules to block these attacks. It took at least two days
before rules  were  posted on  the  Snort  site.  These  were  not  generalized  and  did  not
work against trivial variants. Some three months later, the rules block on ".ida" and
".idq"  in  the  URI  and  "payload  size"  greater  than  239  [13].  The  use  of  the  file
extensions  shows  some  generalization  but  the  use  of  239  as  a  limit  on  legitimate
requests intended for Index Server in fact cause false positives because  the  payload
can be much greater than 239 (at least 373) without causing the web server to fail. 
Other improvements to generalization would use analysis based on HTTP headers
and  body  content.  These  and  other  improvements  are  the  central  focus  of  the  next
phase of research.
One  additional  aspect  of  the design  of  the  ContentFilterBridge  software  is  worth
discussing. It first calls AllowRequest with the bad request received from the MAC. If
AllowRequest returns true, that means the bad request is not on the bad request list, so
2  Index  Server  uses  file  types  indicated  by  the  extensions,  “.IDA”  and  “.IDQ”.  These  two
extensions are used by IIS to identify the Index Server resource, which is then passed either
the whole URI or the query component of the URI. The “path” component of the URI does
not affect the behavior of the Index Server, except for the file extension identifying it as the
resource target. Any file name other than “default” in “default.ida” works as well.
Learning Unknown Attacks – A Start
173
it is added. If AllowRequest returns false, this means it is on the bad request list, so it
is not added to the list. This prevents duplication.
With the addition of generalization, not only will duplicates be prevented, but also
trivial variants will not extend the bad request list to a performance-crippling length.
As there are over 21792 (or more than the number of atoms in the universe) variants of
Code Red, this is an important and effective aspect of the design.
6   Next Steps
6.1   Software Improvements
In its initial implementation, the Forensics module truncates bad requests to the first
two  components  of  the  HTTP  request,  namely,  the  method  and  URI.  This  makes
sense in the case of the buffer overflows on web servers but it needs to be enhanced
so there is a more robust way to identify the initiating event of an attack. In addition,
there is much work to do to enhance the Forensics module’s process for finding initial
attack sequences efficiently, especially for multi-request attacks. 
Similarly,  the  initial  generalization  rule  base  will  be  moved  into  a  separate
Generalization  module  that  reflects  the  architecture.  This  module  will  attempt  to
generalize  all  requests  or  patterns  returned  by  the  forensics  module  to  the  content
filter and insert specific new rules into the content filter. More broadly, we want the
Generalizer  to  be  able  to  task  the  Forensics  Module  to  run  Sandbox  tests  on  any
proposed set of filter rules and generalization parameters to what works, e.g., which
contain  the  essential  initiating  event.  In  this  way,  we  can  refine  the  generalization
while providing continued protection at the Content Filter level.
There is a great deal of work to be done in developing rules for generalizing attack
patterns  so  that  simple  attack  variants  won’t  work.  We  would  like  to  do  this  by
focusing  on  meaningful  attack  classes.  The  literature  contains  many  works  on
classifying  various  aspects  of  computer  security  including  fault  tolerance,  replay
attacks in cryptographic protocols, inference detection approaches, COTS equipment
security risks, and computer attacks. Essentially all of these authors have emphasized
that the utility of a taxonomy depends upon how well it accomplishes its purpose and
that there is no such thing as a universal taxonomy. 
Another  module  that  we  will  likely  need  is  one  that  allows  us  to  simulate
vulnerabilities in applications and generate resulting sensor reading. It is difficult to
rely on real world attacks on our specific applications. There are simply not enough of
them in circulation to give us the breadth of attack types that we need for the research.
6.2   Theory Improvements
As  Krsul  [14]  states,  “Making  sense  of  apparent  chaos  by  finding  regularities  is  an
essential characteristic of human beings.” He laid out the essential characteristics of
successful  taxonomies:  (1)  They  should  have  explanatory  and  predictive  value.  (2)
Computer  vulnerability  taxonomies  should  classify  the  features  or  attributes  of  the
vulnerabilities,  not  the  vulnerabilities  themselves.  (3)  Their  classes  should  be
mutually exclusive and collectively exhaustive. (4) Each level or division should have
a  fundamentum  divisionis  or  basis  for  distinction  so  that  an  entity  can  be
174
J.E. Just et al.
unequivocally  placed 
the  other.  (5)  The  classification
characteristics should be objective, deterministic, repeatable, and  specific.  Note  that
item (3) above is very difficult to achieve in practice outside the realm of mathematics
and should be probably be replaced by extensibility as a goal. 
in  one  category  or 
Krsul developed a very extensive list of classes particularly focused on erroneous
environmental assumptions. Unfortunately, his and most of the previous efforts (see
review  by  Lough  [15])  on  developing  taxonomies  have  focused  on  identifying  and
characterizing vulnerabilities in source code so that programmers could identify and
eliminate  them  before  the  software  was  deployed.  At  one  level  this  are  fine  in  that
they can give us insights into types of vulnerabilities. For example, the classic study
by  Landwehr  et  al.  [16] 
inadvertent  software
vulnerabilities:
·  Validation error (incomplete/inconsistent)
·  Domain  error  (including  object  re-use,  residuals,  and  exposed  representation
the  following 
lists 
type  of 
errors)
·  Serialization/aliasing (including TOCTTOU errors)
·  Identification/authentication errors
·  Boundary  condition  violation  (including  resource  exhaustion  and  violable
constraint errors)
·  Other exploitable logic errors
While these are important efforts and give us insights, we really need a taxonomy
of remote access attacks, particularly one that characterizes the initiating events that
can be exploited via network-based attacks on COTS or GOTS software.
Since our focus is on unknown network-based attacks, recent work by Richardson
[17]  is  of  interest.  He  developed  a  taxonomy  for  DoS  attacks  that  identifies  the
following attack mechanisms:
1. Buffer overflows
2. IP fragmentation attacks
3. Other incorrect data attacks
4. Overwhelm with service requests
5. Overwhelm with data
6. Poor authentication or access control 
·  Poor authentication scheme
·  IP spoofing
·  Data poisoning
·  Other miscellaneous protection shortcomings)
These  categories  will  be  informed  by  other  studies  of  taxonomies  [e.g.,  18,  19].
The  results  will  form  the  initial  basis  for  our  categorization  of  initiating  events  of
unknown attacks. Priorities will be given to those attacks that are known not to have
adequate protection measures built into the cluster currently and for which there are
not easy fixes to the design that would prevent them. For example, IP fragmentation
attacks against the primary can be prevented with a proxy on the firewall or gateway
and IP spoofing is prevented by the VPN.
Learning Unknown Attacks – A Start
175
7   Conclusions and Recommendations
Our design for an intrusion tolerant server cluster uses a behavior specification-based
approach to identify errors and failover to the hot spare. It then uses fault diagnosis to
recognize the attack that caused failover  (or violated  QoS)  and block  it  so  repeated
attacks won't defeat us again. We learn exact attacks by testing entries from complete
log files in a “Sandbox” until we duplicate the observed failure. Single stage attacks
can be recognized in seconds, automatically. 
We have demonstrated that it is possible to generalize web server buffer overflow
attack signatures after the initial identified attack so that simple variants that exploit
the same vulnerability will be blocked also. We do this using a similarity measure for
the class of attack. We have implemented rules that generalize a large subset of buffer
overflow  attacks  aimed  at  web  servers  and  have  tested  it  using  the  Internet
Information Server (IIS) by Microsoft, and believe that it will also work for Apache
and other web servers also. For buffer overflow attacks, which have become the most
common  type  of  attack,  we  can  also  learn  the  minimum  length  of  the  request  that
causes the buffer overflow. This is important to minimize the probability of blocking
legitimate transactions, i.e., the false positive rate.
We believe this knowledge-based learning is broadly applicable to many classes of
remote access attacks and has significant uses outside of intrusion tolerance. We also
believe that the generalization approach can be significantly extended to other classes
of attack. The key, we believe, is generalizing an attack pattern to protect against all
variants that exploit the same vulnerability rather than trying to generalize a specific
attack  to  protect  against  all  such  attacks  in  the  class.  The  ease  of  generalizing  an
attack pattern should be proportional to the ease of creating simple attack variants that
work against the same vulnerability.
In  summary,  we  have  developed  an  approach  to  dynamic  learning  of  unknown
attacks that shows great promise. We have also implemented a proof of concept for
generalization that works for a significant class of buffer overflow attacks against web
servers  on  Microsoft  NT/2000.  Our  results  so  far  indicate  that  the  generalization
algorithms will be specific to particular types of attacks (such as buffer overflow), to
particular protocols (such as http) and to particular application classes. More work is
needed to determine whether they must be specific to particular applications but that
is a likely outcome if the application class is not dominated by standard protocols. 
We recommend that other researchers examine this knowledge-based approach to
identifying unknown attacks. We hope they find it useful enough to apply it to other
areas.
References
1. Schneier, B: Secrets and Lies: Digital Security in a Networked World. John Wiley & Sons,
Inc., 2000 206, 210
2. Gray, J., Reuter, A.: Transaction Processing: Concepts and Techniques. Morgan Kaufmann
Publishers, San Francisco, CA, 1993 107
3. Lampson, B.: Computer Security in the Real World. Invited essay at 16th Annual Computer
Security  Applications  Conference,  11–15  December,  New  Orleans,  LA,  available  at
http://www.acsac.org/2000/papers/lampson.pdf
176
J.E. Just et al.
4.
Just, J.E., et al.: Intelligent Control for Intrusion Tolerance of Critical Application Services.
Supplement of the 2001 International Conference on Dependable Systems and Networks,
1–4 July 2001, Gothenburg, SW
5. Reynolds, J., et al.: Intrusion Tolerance for Mission-Critical Services. Proceedings of the
2001 IEEE Symposium on Security and Privacy, May 13–16, 2001, Oakland, CA
6. Reynolds,  J.,  et  al.:  The  Design  and  Implementation  of  an  Intrusion  Tolerant  System.
Proceedings of the 2002 International Conference on Dependable Systems and Networks,
23–26 June 2002, Washington, DC, pending
7. Ko,  Calvin:  Logic  Induction  of  Valid  Behavior  Specifications  for  Intrusion  Detection.
IEEE Symposium on Security and Privacy 2000: 142–153
8. Ko, Calvin, Brutch, Paul, et al.: System Health and Intrusion Monitoring Using a Hierarchy
of Constraints. Recent Advances in Intrusion Detection 2001: 190–204
9. Balzer,  R.,  and  Goldman,  N.:  Mediating  Connectors.  Proceedings  of  the  19th  IEEE
International Conference on Distributed Computing Systems, Austin, Texas, May 31-June
4, 1999, IEEE Computer Society Press 73-77
10. Strunk,  J.D.,  et  al.:  Self-securing  storage:  Protecting  data  in  compromised  system.
Operating  Systems  Design  and  Implementation,  San  Diego,  CA,  23–25  October  2000,
USENIX Association, 2000 165–180
11. Ganger,  G.R.,  et  al.:  Survivable  Storage  Systems.  DARPA  Information  Survivability
Conference and Exposition (Anaheim, CA, 12-14 June 2001), pages 184–195 vol 2. IEEE,
2001
12. Russell,  S.,  Norvig,  P,:  Artificial  Intelligence:  A  Modern  Approach.  Prentice  Hall,  New
York, 1995 
13. Roesch,  M.:  Snort  Users  Manual,  Snort  Release:  1.8.3.  November  6,  2001,  available  at
http://www.snort.org/docs/writing_rules/
14.  Krsul,  I.V.:  Software  Vulnerability  Analysis.  PhD  thesis,  Purdue  University,  West
Lafayette, IN, May, 1998, p. 17, available at
https://www.cerias.purdue.edu/techreports-ssl/public/97-05.pdf 
15. Lough, D.L.: A Taxonomy of Computer Attacks with Applications to Wireless Networks.
PhD  Thesis,  Virginia  Polytechnic  and  State  University,  Blackburg,  VA,  available  at
http://scholar.lib.vt.edu/theses/available/etd-04252001-234145/
16. Landwehr, C. E., Bull, A. R., McDermott, J. P., Choi, W. S.: A Taxonomy of Computer
Program  Security  Flaws.  ACM  Computing  Surveys,  Volume  26,  Number  3,  September
1994
17. Richardson,  T.W.:  The  Development  of  a  Database  Taxonomy  of  Vulnerabilities  to
Support the Study of Denial of Service Attacks. PhD thesis, Iowa State University, 2001
18.  Aslam, T.: A Taxonomy of Security Faults in the Unix Operating System. Master's Thesis,
Purdue University, Department of Computer Sciences, August 1995.
http://citeseer.nj.nec.com/aslam95taxonomy.html
19. Du, W. and Mathur, A.: Categorization of Software Error that Led to Security Breaches.
Technical Report 97-09, Purdue University, Department of Computer Science, 1997