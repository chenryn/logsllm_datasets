### Principles of Similarity in Attack Detection

In principle, similarity-based detection is a rule-driven process that involves two primary steps: classification and generalization. Classification categorizes malicious requests into meaningful types, such as buffer overflow or remote command execution, and, if necessary, further subdivides them into subtypes. Generalization, on the other hand, develops a set of rules to determine the similarity between an observed malicious request and a new incoming request based on the classification results. These rules can be implemented either as an active checking process or as comparison templates for use by another program.

### Proof-of-Concept for Web Server Buffer Overflow Attacks

For our proof-of-concept, we focused on web server buffer overflow attacks via HTTP requests. We implemented a single rule that serves both as a classifier and a generalizer. The rule is as follows:

- **If**:
  1. The query length of the bad request exceeds (256 + X) characters (this classifies the request as a buffer overflow type).
  2. The methods of the new request and the bad request are the same.
  3. The file extensions of the new and bad requests are the same.
  4. The query length of the new request is greater than or equal to the query length of the bad request,
- **Then**: Return `false` (i.e., block the request).

Even with \( X = 0 \), this rule effectively blocks many variants of Code Red I and II. The initial or padding characters in the query are irrelevant to how Code Red operates; the critical factor is the query length. Whether the query contains "XXX..." or "NNN..." or "XNXN...", the attack is blocked. Additionally, the name of the file (excluding the extension) is also irrelevant because it is the file extension that identifies the vulnerable resource (Index Server), and the query is what causes the buffer overflow, not the entire URI.

### Rationale for the Rule

The first condition in the rule differentiates between buffer overflow attacks and other types of attacks, such as remote command execution. However, this introduces the possibility of false negatives. A bad request that is a buffer overflow attack but occurs after fewer than 256 characters would be ignored.

This rule was developed through extensive analysis of buffer overflows in general, specific vulnerabilities in IIS and Apache web servers, and detailed examination of Code Red. It generalizes "learned" behavior, meaning that if the HACQIT cluster has never been attacked by Code Red, it will not stop the first Code Red attack. Similarly, it will not stop the first case of a variant of Code Red using the `.IDQ` extension. This variant would first need to be "experienced," learned as a bad request, and then generalized by the rule. Importantly, the rule does not prevent the use of resources like Index Server; it prevents a wider variety of attacks that exploit identified vulnerabilities from reducing the availability of the web server.

### Generalization and Snort Comparison

Although this rule appears Microsoft-oriented due to the concept of file extensions, it can be adapted to work against attacks exploiting vulnerabilities in other software, such as PHP and Perl, which also use file extensions. The key distinction is whether the path in the URI identifies a document to be returned to the client or an executing resource like a search engine or DBMS.

Finding the minimum length of padding characters for a buffer overflow attack is straightforward. We have implemented an enhanced version of the forensics and generalization modules that iteratively test attack variants in a sandbox with different padding character lengths. Specifically, it tests padding character lengths between 256 and (Y - 256), where Y is the length of the observed buffer overflow padding size. This testing determines the value of X, which is used in the generalization rule.

### Automatic Generalization vs. Snort

It is worth comparing this automatic generalization with Snort's hand-coded rules for preventing Code Red attacks. Snort, a widely used, open-source, lightweight Intrusion Detection System, required at least two days to post rules after the initial Code Red attacks. These rules were not generalized and did not work against trivial variants. Three months later, the rules blocked URIs containing ".ida" and ".idq" with a payload size greater than 239. While the use of file extensions shows some generalization, the limit of 239 caused false positives because the payload can be much larger (at least 373) without causing the web server to fail. Future improvements will include analysis based on HTTP headers and body content.

### Design of the ContentFilterBridge

The ContentFilterBridge software first calls `AllowRequest` with the bad request received from the MAC. If `AllowRequest` returns `true`, the bad request is added to the list. If it returns `false`, the request is already on the bad request list and is not added again, preventing duplication. With generalization, duplicates and trivial variants will not extend the bad request list to a performance-crippling length, which is crucial given the vast number of Code Red variants.

### Next Steps

#### Software Improvements

- **Forensics Module**: Enhance the module to more robustly identify the initiating event of an attack, especially for multi-request attacks.
- **Generalization Module**: Move the initial generalization rule base into a separate module that can generalize all requests or patterns returned by the forensics module and insert specific new rules into the content filter.
- **Simulation Module**: Develop a module to simulate vulnerabilities in applications and generate sensor readings, as real-world attacks may not provide the breadth of attack types needed for research.

#### Theory Improvements

- **Taxonomy Development**: Develop a taxonomy of remote access attacks, particularly one that characterizes the initiating events that can be exploited via network-based attacks on COTS or GOTS software.
- **Prioritization**: Prioritize attacks that currently lack adequate protection measures and for which there are no easy fixes to the design.

### Conclusions and Recommendations

Our design for an intrusion-tolerant server cluster uses a behavior specification-based approach to identify errors and failover to a hot spare. It then uses fault diagnosis to recognize the attack that caused the failover and block it to prevent repeated attacks. We have demonstrated the feasibility of generalizing web server buffer overflow attack signatures so that simple variants exploiting the same vulnerability are also blocked. This knowledge-based learning approach is broadly applicable to many classes of remote access attacks and has significant uses beyond intrusion tolerance.

We recommend that other researchers examine this knowledge-based approach to identifying unknown attacks and apply it to other areas.