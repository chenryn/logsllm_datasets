Ensure also that the channel has values specified for the retry attributes: SHORTRTY and LONGRTY.
In the event of transient failures such as network errors, the channel will then attempt to restart
automatically.
b)Issue the following command to start the channel again manually:
START CHANNEL(QM1.TO.QM2)
On IBM MQ for z/OS, you can detect when a user stops a channel by using command
event messages.
306 Monitoring and Performance for IBM MQ
6.Optional: If the value of the STATUS field is RETRY, perform the following steps:
a)Check the error logs to identify the error, then correct the problem.
b)Issue the following command to start the channel again manually:
START CHANNEL(QM1.TO.QM2)
or wait for the channel to connect successfully on its next retry.
7.Optional: If the value of the STATUS field is BINDING or REQUESTING, the channel has not yet
successfully connected to the partner. Perform the following steps:
a)Issue the following command, at both ends of the channel, to determine the substate of the
channel:
DIS CHSTATUS(QM1.TO.QM2) ALL
Note:
i)In some cases there might be a substate at one end of the channel only.
ii)Many substates are transitory, so issue the command a few times to detect whether a channel is
stuck in a particular substate.
b)Check Table 31 on page 307 to determine what action to take:
Table 31. Substates seen with status binding or requesting
Initiating MCA Responding MCA
Notes
substate 1 substate 2
NAMESERVER The initiating MCA is waiting for a name server request
to complete. Ensure that the correct host name has been
specified in the channel attribute, CONNAME, and that your
name servers are set up correctly.
SCYEXIT SCYEXIT The MCAs are currently in conversation through a security
exit. For more information, see “Determining whether the
channel can process messages fast enough” on page 310.
CHADEXIT The channel autodefinition exit is currently executing. For
more information, see “Determining whether the channel can
process messages fast enough” on page 310.
RCVEXIT RCVEXIT Exits are called at channel startup for MQXR_INIT. Review
SENDEXIT SENDEXIT the processing in this part of your exit if this takes a long time.
MSGEXIT MSGEXIT For more information, see “Determining whether the channel
MREXIT MREXIT can process messages fast enough” on page 310.
SERIALIZE SERIALIZE This substate only applies to channels with a disposition of
SHARED.
NETCONNECT This substate is shown if there is a delay in connecting due to
incorrect network configuration.
SSLHANDSHAKE SSLHANDSHAKE A TLS handshake consists of a number of sends and receives.
If network times are slow, or connection to lookup CRLs are
slow, this affects the time taken to do the handshake.
On IBM MQ for z/OS this substate can also be
indicative of not having enough SSLTASKS.
Notes:
IBM MQ Monitoring and performance 307
i)The initiating MCA is the end of the channel which started the conversation. This can be senders,
cluster-senders, fully-qualified servers and requesters. In a server-requester pair, it is the end
from which you started the channel.
ii)The responding MCA is the end of the channel which responded to the request to start the
conversation. This can be receivers, cluster-receivers, requesters (when the server or sender is
started), servers (when the requester is started) and senders (in a requester-sender call-back
pair of channels).
Checking that the channel is moving messages
If you have a problem with a transmission queue, check that the channel is moving messages
Before you begin
Issue the command DIS CHSTATUS(QM1.TO.QM2) ALL. If the value of the STATUS field is RUNNING,
the channel has successfully connected to the partner system.
Check that there are no uncommitted messages on the transmission queue, as described in “Checking
that messages on the queue are available” on page 304.
About this task
If there are messages available for the channel to get and send, perform the following checks:
Procedure
1.In the output from the display channel status command, DIS CHSTATUS(QM1.TO.QM2) ALL, look at
the following fields:
MSGS
Number of messages sent or received (or, for server-connection channels, the number of MQI calls
handled) during this session (since the channel was started).
BUFSSENT
Number of transmission buffers sent. This includes transmissions to send control information only.
BYTSSENT
Number of bytes sent during this session (since the channel was started). This includes control
information sent by the message channel agent.
LSTMSGDA
Date when the last message was sent or MQI call was handled, see LSTMSGTI.
LSTMSGTI
Time when the last message was sent or MQI call was handled. For a sender or server, this is the
time the last message (the last part of it if it was split) was sent. For a requester or receiver, it is the
time the last message was put to its target queue. For a server-connection channel, it is the time
when the last MQI call completed.
CURMSGS
For a sending channel, this is the number of messages that have been sent in the current batch.
For a receiving channel, it is the number of messages that have been received in the current batch.
The value is reset to zero, for both sending and receiving channels, when the batch is committed.
STATUS
The status of the channel, which can be Starting, Binding, Initializing, Running,
Stopping, Retrying, Paused, Stopped, or Requesting.
SUBSTATE
The action that the channel is currently performing.
INDOUBT
Whether the channel is currently in doubt. This is only YES while the sending Message Channel
Agent is waiting for an acknowledgment that a batch of messages that it has sent has been
successfully received. It is NO at all other times, including the period during which messages are
308 Monitoring and Performance for IBM MQ
being sent, but before an acknowledgment has been requested. For a receiving channel, the value
is always NO.
2.Determine whether the channel has sent any messages since it started. If any have been sent,
determine when the last message was sent.
3.The channel might have started a batch that has not yet completed, as indicated by a non-zero value in
CURMSGS. If INDOUBT is YES, the channel is waiting to receive acknowledgment that the other end of
the channel received the batch. Look at the SUBSTATE field in the output and refer to Table 32 on page
309:
Table 32. Sender and receiver MCA substates
Sender SUBSTATE Receiver SUBSTATE Notes
MQGET RECEIVE Normal states of a channel at rest.
SEND RECEIVE SEND is usually a transitory state. If SEND is seen it indicates
that the communication protocol buffers have filled. This can
indicate a network problem.
RECEIVE If the sender is seen in RECEIVE substate for any length of
time, it is waiting on a response, either to a batch completion
or a heartbeat. You might want to check why a batch takes a
long time to complete.
Note: You might also want to determine whether the channel can process messages fast enough,
especially if the channel has a substate associated with exit processing.
Checking why a batch takes a long time to complete
Reasons why a batch can take a long time to complete include a slow network or a channel is using
message retry processing.
About this task
When a sender channel has sent a batch of messages it waits for confirmation of that batch from the
receiver, unless the channel is pipelined. The factors described in this task can affect how long the sender
channel waits.
Procedure
• Check whether the network is slow.
The NETTIME value is the amount of time, displayed in microseconds, taken to send an end of batch
request to the remote end of the channel and receive a response minus the time to process the end of
batch request. This value can be large for either of the following reasons:
– The network is slow. A slow network can affect the time it takes to complete a batch. The
measurements that result in the indicators for the NETTIME field are measured at the end of a
batch. However, the first batch affected by a slowdown in the network is not indicated with a change
in the NETTIME value because it is measured at the end of the batch.
– Requests are queued at the remote end, for example a channel can be retrying a put, or a put
request may be slow due to page set I/O. Once any queued requests have completed, the duration
of the end of batch request is measured. So if you get a large NETTIME value, check for unusual
processing at the remote end.
• Check whether the channel is using message retry.
If the receiver channel fails to put a message to a target queue, it might use message retry processing,
rather than put the message to a dead-letter queue immediately. Retry processing can cause the batch
to slow down. In between MQPUT attempts, the channel will have STATUS(PAUSED), indicating that it
is waiting for the message retry interval to pass.
IBM MQ Monitoring and performance 309
Determining whether the channel can process messages fast enough
If there messages are building up on the transmission queue, but you have found no processing problems,
determine whether the channel can process messages fast enough.
Before you begin
Issue the following command repeatedly over a period of time to gather performance data about the
channel:
DIS CHSTATUS(QM1.TO.QM2) ALL
About this task
Confirm that there are no uncommitted messages on the transmission queue, as described in “Checking
that messages on the queue are available” on page 304, then check the XQTIME field in the output from
the display channel status command. When the values of the XQTIME indicators are consistently high,
or increase over the measurement period, the indication is that the channel is not keeping pace with the
putting applications.
Perform the following tests:
Procedure
1.Check whether exits are processing.
If exits are used on the channel that is delivering these messages, they might add to the time spent
processing messages. To identify if this is the case, do the following checks:
a)In the output of the command DIS CHSTATUS(QM1.TO.QM2) ALL, check the EXITTIME field.
If the time spent in exits is higher than expected, review the processing in your exits for any
unnecessary loops or extra processing, especially in message, send, and receive exits. Such
processing affects all messages moved across the channel.
b)In the output of the command DIS CHSTATUS(QM1.TO.QM2) ALL, check the SUBSTATE field.
If the channel has of one of the following substates for a significant time, review the processing in
your exits:
• SCYEXIT
• RCVEXIT
• SENDEXIT
• MSGEXIT
• MREXIT
For more information on channel substates, see the table Table 32 on page 309.
2.Check whether the network is slow.
If messages are not moving fast enough across a channel, it might be because the network is slow. To
identify if this is the case, do the following checks:
a)In the output of the command DIS CHSTATUS(QM1.TO.QM2) ALL, check the NETTIME field.
These indicators are measured when the sending channel asks its partner for a response. This
happens at the end of each batch and, when a channel is idle during heartbeating.
b)If this indicator shows that round trips are taking longer than expected, use other network
monitoring tools to investigate the performance of your network.
3.Check whether the channel is using compression.
If the channel is using compression, this adds to the time spent processing messages. If the channel is
using only one compression algorithm, do the following checks:
a)In the output of the command DIS CHSTATUS(QM1.TO.QM2) ALL, check the COMPTIME field.
These indicators show the time spent during compression or decompression.
310 Monitoring and Performance for IBM MQ
b)If the chosen compression is not reducing the amount of data to send by the expected amount,
change the compression algorithm.
4.If the channel is using multiple compression algorithms, do the following checks:
a)In the output of the command DIS CHSTATUS(QM1.TO.QM2) ALL, check the COMPTIME,
COMPHDR, and COMPMSG fields.
b)Change the compression algorithms specified on the channel definition, or consider writing a
message exit to override the channel's choice of compression algorithm for particular messages
if the rate of compression, or choice of algorithm, is not providing the required compression or
performance.
Solving problems with cluster channels
If you have a build up of messages on the SYSTEM.CLUSTER.TRANSMIT.QUEUE queue, the first step
in diagnosing the problem is discovering which channel, or channels, are having a problem delivering
messages.
About this task
To discover which channel, or channels, using the SYSTEM.CLUSTER.TRANSMIT.QUEUE are having a
problem delivering messages. Perform the following checks:
Procedure
1.Issue the following command:
DIS CHSTATUS(*) WHERE(XQMSGSA GT 1)
Note: If you have a busy cluster that has many messages moving, consider issuing this command with
a higher number to eliminate the channels that have only a few messages available to deliver.
2.Look through the output for the channel, or channels, that have large values in the field XQMSGSA.
Determine why the channel is not moving messages, or is not moving them fast enough. Use the tasks
outlined in “Monitoring channels” on page 305 to diagnose the problems with the channels found to
be causing the build up.
The Windows performance monitor
In IBM WebSphere MQ 7.0 and earlier versions, it was possible to monitor the performance of local
queues on Windows systems by using the Windows performance monitor. As of IBM WebSphere MQ 7.1,
this method of performance monitoring is no longer available.
You can monitor queues on all supported platforms by using methods described in “Real-time
monitoring” on page 299.
Monitoring clusters
Within a cluster you can monitor application messages, control messages, and logs. There are special
monitoring considerations when the cluster load balances between two or more instances of a queue.
Monitoring application messages in the cluster
Typically, all cluster messages that leave the queue manager pass through the
SYSTEM.CLUSTER.TRANSMIT.QUEUE, irrespective of which cluster sender channel is being used to
transmit the message. Each channel is draining messages targeted for that channel in parallel with all
other cluster sender channels. A growing build-up of messages on this queue can indicate a problem with
one or more channels and must be investigated:
• The depth of the queue must be monitored appropriately for the cluster design.
• The following command returns all channels that have more than one message that is waiting on the
transmit queue:
IBM MQ Monitoring and performance 311
DIS CHSTATUS(*) WHERE(XQMSGSA GT 1)
With all cluster messages on a single queue, it is not always easy to see which channel has problems
when it begins to fill up. Using this command is an easy way to see which channel is responsible.
You can configure a cluster queue manager to have multiple transmission queues. If you change the
queue manager attribute DEFCLXQ to CHANNEL, every cluster-sender channel is associated with a
different cluster transmit queue. Alternatively you can configure separate transmission queues manually.
To display all the cluster transmit queues that are associated with cluster-sender channels, run the
command:
DISPLAY CLUSQMGR (qmgrName) XMITQ
Define cluster transmission queues so that they follow the pattern of having the fixed stem of the queue
name on the left. You can then query the depth of all the cluster transmission queues returned by the
DISPLAY CLUSMGR command, by using a generic queue name:
DISPLAY QUEUE (qname *) CURDEPTH
Monitoring control messages in the cluster
The SYSTEM.CLUSTER.COMMAND.QUEUE queue is used for processing all cluster control messages for
a queue manager, either generated by the local queue manager or sent to this queue manager from
other queue managers in the cluster. When a queue manager is correctly maintaining its cluster state,
this queue tends toward zero. There are situations where the depth of messages on this queue can
temporarily grow however:
• Having lots of messages on the queue indicates churn in the cluster state.
• When making significant changes, allow the queue to settle in between those changes. For example,
when moving repositories, allow the queue to reach zero before moving the second repository.
While a backlog of messages exists on this queue, updates to the cluster state or cluster-related
commands are not processed. If messages are not being removed from this queue for a long time, further
investigation is required, initially through inspection of the queue manager error logs (or CHINIT logs on
z/OS ) which might explain the process that is causing this situation.
The SYSTEM.CLUSTER.REPOSITORY.QUEUE holds the cluster repository cache information as a number
of messages. It is usual for messages to always exist on this queue, and more for larger clusters.
Therefore, the depth of messages on this queue is not an issue for concern.
Monitoring logs
Problems that occur in the cluster might not show external symptoms to applications for many days (and
even months) after the problem originally occurs due to the caching of information and the distributed
nature of clustering. However, the original problem is often reported in the IBM MQ error logs (and
CHINIT logs on z/OS). For this reason, it is vital to actively monitor these logs for any messages written
that relate to clustering. These messages must be read and understood, with any action taken where
necessary.
For example: A break in communications with a queue manager in a cluster can result in knowledge
of certain cluster resources that are being deleted due to the way that clusters regularly revalidate the
cluster resources by republishing the information. A warning of such an event potentially occurring is
reported by the message AMQ9465 or CSQX465I on z/OS systems. This message indicates that the
problem needs to be investigated.
312 Monitoring and Performance for IBM MQ
Special considerations for load balancing
When the cluster load balances between two or more instances of a queue, consuming applications
must be processing messages on each of the instances. If one or more of those consuming applications
terminates or stops processing messages, it is possible that clustering might continue to send messages
to those instances of the queue. In this situation, those messages are not processed until the applications
are functioning correctly again. For this reason the monitoring of the applications is an important part of
the solution and action must be taken to reroute messages in that situation. An example of a mechanism
to automate such monitoring can be found in this sample: The Cluster Queue Monitoring sample program
(AMQSCLM).
Related concepts
“Tuning distributed publish/subscribe networks” on page 373
Use the tuning tips in this section to help improve the performance of your IBM MQ distributed publish/
subscribe clusters and hierarchies.
“Balancing producers and consumers in publish/subscribe networks” on page 379
An important concept in asynchronous messaging performance is balance. Unless message consumers
are balanced with message producers, there is the danger that a backlog of unconsumed messages might
build up and seriously affect the performance of multiple applications.
Monitoring transmission queue switching
It is important that you monitor the process of cluster-sender channels switching transmission queues so
that the impact on your enterprise is minimized. For example, you should not attempt this process when
the workload is high or by switching many channels simultaneously.
The process of switching channels
The process used to switch channels is:
1.The channel opens the new transmission queue for input and starts getting messages from it (using
get by correlation ID)
2.A background process is initiated by the queue manager to move any messages queued for the
channel from its old transmission queue to its new transmission queue. While messages are being
moved any new messages for the channel are queued to the old transmission queue to preserve
sequencing. This process might take a while to complete if there are a large number of messages for
the channel on its old transmission queue, or new messages are rapidly arriving.
3.When no committed or uncommitted messages remain queued for the channel on its old transmission
queue then the switch is completed. New messages are now put directly to the new transmission
queue.
To avoid the eventuality of numerous channels switching simultaneously IBM MQ provides the ability to
switch the transmission queue of one or more channels that are not running. On:
• IBM MQ for Multiplatforms the command is called runswchl
• IBM MQ for z/OS the CSQUTIL utility can be used to process a SWITCH CHANNEL command instead
Monitoring the status of switch operations
To understand the status of switch operations administrators can perform the following actions:
• Monitor the queue manager error log (AMQERR01.LOG) where messages are output to indicate the
following stages during the operation:
– The switch operation has started
– The moving of messages has started
– Periodic updates on how many messages are left to move (if the switch operation does not complete
quickly)
– The moving of messages has completed
IBM MQ Monitoring and performance 313
– The switch operation has completed
On z/OS, these messages are output to the queue manager job log, not the channel initiator job log,
although a single message is output by a channel to the channel initiator job log if it initiates a switch
when starting.
• Use the DISPLAY CLUSQMGR command to query the transmission queue that each cluster-sender
channel is currently using.
• Run the runswchl command (or CSQUTIL on z/OS) in query mode to ascertain the switching status of
one or more channels. The output of this command identifies the following for each channel:
– Whether the channel has a switch operation pending
– Which transmission queue the channel is switching from and to
– How many messages remain on the old transmission queue
Each command is really useful, because in one invocation you can determine the status of every
channel, the impact a configuration change has had and whether all switch operations have completed.
Potential issues that might occur
See Potential issues when switching transmission queues for a list of some issues that might be
encountered when switching transmission queue, their causes, and most likely solutions.
Related concepts
“Tuning distributed publish/subscribe networks” on page 373
Use the tuning tips in this section to help improve the performance of your IBM MQ distributed publish/
subscribe clusters and hierarchies.
“Balancing producers and consumers in publish/subscribe networks” on page 379
An important concept in asynchronous messaging performance is balance. Unless message consumers
are balanced with message producers, there is the danger that a backlog of unconsumed messages might
build up and seriously affect the performance of multiple applications.
Monitoring application balancing
You can use the DISPLAY APSTATUS command to monitor the state of application balancing across a
uniform cluster, and to investigate why the application is not balanced if that is unexpected.
Monitoring the current state of applications across queue managers in a cluster
From any queue manager in a uniform cluster you can get an overview of the current state of applications
across all the queue managers of a cluster by running the DIS APSTATUS command.
From IBM MQ 9.2.0 the TYPE field is also displayed in the output.
For example, after a queue manager has just started you might see output like the following:
1 : DIS APSTATUS(*) type(APPL)
AMQ8932I: Display application status details.
APPLNAME(MYAPP) CLUSTER(UNIDEMO)