B+B.size. Given the fact that B.size has been lowered
(because of the overflow), the allocator will fail in updating
the value of C.prev size. The update will instead happen
in a memory area located before C.prev size.
5. Allocate a small chunk B2.
B2 will be allocated where B was and after B1.
6. Free the chunks B1 and C.
When C is freed,
the allocator uses the value of
C.prev size to determine the location of the chunk before
C. Since C.prev size has not been updated correctly, the
allocator will mistakenly think that the only chunk present
before C is B1. Given the fact that B1 has been freed and
that C is being freed, the allocator will consolidate B1 and
C (i.e., it will merge the two free chunks to create a single,
bigger free chunk). After this step, the allocator will think
that a single free chunk exists after A.
7. Allocate a large chunk D.
D will end up being allocated in such a way as to overlap B2.
This happens because the allocator lost track of the existence
of the chunk B2, as explained in the previous steps.
8. Write inside D to change the content of B2
At this point D and B2 overlap, and, therefore, the attacker
has reached the Overlapping Allocation exploitation prim-
itive. We will provide more details about this exploitation
primitive, and how it can be used, in Section 5.2.
In 2017, a patch was proposed and accepted [18] for
glibc (we will refer to this patch as Chris Evans’ patch,
after its author), introducing a comparison between the size
and the previous size of two adjacent chunks, when they
are consolidated together. In particular, the patch checks if,
during a consolidating operation, the following condition
is true: next chunk(X).prev size == X.size, where
X is an arbitrary freed chunk and next chunk is a func-
tion returning the next chunk of a given chunk by computing
next chunk = X + X.size.
Interestingly, similar to other security checks present in
glibc, Chris Evans’ patch was added with some degree of
uncertainty about its effectiveness, stated by the author him-
self in his blog post: “Did we finally nail off-by-one NULL
byte overwrites in the glibc heap? Only time will tell!” [19].
This check is effective in detecting the exploitation of a 1-
byte NULL overflow with the technique explained above (the
2 In ptmalloc, given a chunk X proceeded by a free chunk, the field
X.prev size is conventionally located in the memory word before the
start of X.
memory corruption will be detected during Step 4). However,
it was subsequently discovered that the check could be easily
bypassed using a slight modification of the attack [44]. In
particular, an attacker can, during Step 1, set the content of B,
so that a “fake” value of next chunk(B).prev size is
present at the end of the chunk B, as shown on the bottom of
Figure 1. Given the premise that an attacker can utilize the
1-byte NULL overflow to perform this technique, the same
primitive could be used to set the memory contents at the
end of a chunk, hence, this constraint does not pose a new
restriction to the attack. This value will remain untouched by
the subsequent steps in the exploit, and will pass the check
during consolidation (Step 4).
This chain of events shows three important points:
1. Even seemingly minor memory corruption bugs can be
exploited to achieve arbitrary code execution.
2. Exploiting memory corruption in the heap is complex
and intertwined with the internals of the specific libc
implementation.
3. Modern libc implementations contain checks to de-
tect and mitigate memory corruption bugs. However,
their effectiveness is, in general, limited and, most im-
portantly, not systematically tested.
Our work aims exactly at targeting this third point, by creat-
ing HEAPHOPPER, a tool to perform bounded model check-
ing of libc implementations to detect if and how memory
corruption bugs can be exploited.
As an example, in Section 7.7, we will show how our tool
was able to automatically understand that the aforementioned
glibc patch was bypassable. On the contrary, a better patch,
which we have since submitted to glibc project, cannot be
bypassed [15].
3 HEAPHOPPER: Design Overview
HEAPHOPPER’s goal is to evaluate the exploitability of an al-
locator in the presence of memory corruption vulnerabilities
in the application using the allocator. Specifically, it detects
if and how different heap-metadata corruption flaws can be
exploited in a given heap implementation to grant an attacker
exploitation primitives. HEAPHOPPER works by analyzing
the compiled library implementing the heap allocation and
deallocation functions (i.e., malloc and free).
Our choice of focusing on compiled binary code instead of
source code was motivated by three main reasons. First of all,
using binary code allows us to analyze heap implementations
for which the source code is not available. Secondly, the anal-
ysis of the source code may not be sufficient to realistically
model the way in which memory is handled, since different
compilers and compilation options may result in different
memory layouts, influencing the exact way in which a bug
corrupts memory. Additionally, for the problem we want
to solve, the loss of semantic information induced by code
102    27th USENIX Security Symposium
USENIX Association
Figure 2: HEAPHOPPER overview
compilation is not significant, since the only semantic infor-
mation that our analysis needs is the location of the malloc
and free functions.
The input of HEAPHOPPER is a compiled binary library
(in the format of a shared object file) implementing a heap
and a configuration file specifying:
List of transactions: A list of operations that an attacker
is allowed to perform, such as malloc, free, buffer over-
flows, use-after-free, etc. For some of the transactions, fur-
ther details can be specified, as we will explain in Section 4.1.
Bound: The maximum number of transactions that an
attacker can perform.
List of security properties: A list of invalid states in
which the attacker has reached the ability to perform specific
exploitation primitives.
HEAPHOPPER works by automatically finding sequences of
transactions that make the model of the analyzed heap im-
plementation reach states where specific security properties
are violated.
As output, HEAPHOPPER produces proof-of-concept
(PoC) source code C files, exemplifying how different opera-
tions can be used to achieve different exploitation primitives.
Figure 2 provides an overview of HEAPHOPPER. Inter-
nally, HEAPHOPPER first generates lists of transactions by
enumerating permutations of the transactions provided in the
configuration file (see Section 4.2 for details). For each of
these lists of transactions, a corresponding C file is generated
and compiled.
Then, each compiled C file is symbolically executed up to
the point when a state providing to the attacker an exploita-
tion primitive is reached (see Section 5.2 for details). To
detect such a state, HEAPHOPPER checks, for any reached
state, if any provided security property is violated. Using
symbolic execution HEAPHOPPER can, at the same time,
verify such properties and determine the content that attacker-
controllable data (e.g., the content of legitimately malloced
buffers or the value of overflowing data) should have to
achieve a detected security property violation.
The use of symbolic execution obviously requires
HEAPHOPPER to have access to the compiled binary code
of the analyzed library. However, HEAPHOPPER does not
require access to the library source code nor to any knowl-
edge about its data structures or internal functions. The only
pieces of information needed by HEAPHOPPER to analyze a
libc implementation are its compiled code and the location
of the functions malloc and free.
Two problems typically affect symbolic execution: path
explosion and constraint complexity. We minimize path ex-
plosion by splitting our symbolic exploration into separate
exploitation attempts. Each exploitation attempt only ex-
plores a single list of transactions. As a consequence, the
only branches encountered by our execution are those within
the heap implementation.
At the same time, we lower the complexity of the gen-
erated constraints by minimizing the amount of symbolic
data and using specific symbolic memory handlers when an
access to symbolic memory is encountered (see Section 5.3
and Section 5.4).
As a last step, symbolic execution traces, alongside with
their associated constraints, are used to generate PoC source
code, exemplifying how to achieve the desired exploitation
primitive.
4 Generating Heap Interaction Models
The first step toward bounded model checking is to create
a model. In case of HEAPHOPPER, the base of our model
is the heap, which is represented as a state. We add a set of
USENIX Association
27th USENIX Security Symposium    103
Configuration-Transactions-Bounds-Exploitation PrimitivesHeap (libc)Implementation(shared object file)Path GenerationSymbolic ExecutionPoC GenerationPoC ExploitsSource Code HeapHopperMFUAF...Lists of TransactionsMFUAF...MFUAF...MFUAF...Exploitation Attempts Source CodeMFUAF...c1=malloc(s1)free(c1)read(0,c1,s2)...Compiled ExploitationAttemptsangr(symbolic execution engine)Heap Functions HookingSecurity Properties Violation DetectorSymbolic Memory HandlersSymbolicValuesConcretizationSymbolicPointersConcretizationPoC Generatorc1=malloc(0x100)free(c1)read(0,c,0x20)...c1=malloc(0x100)free(c1)read(0,c,0x20)...Symbolic Execution Traces with Constraintsc1=malloc(0x100)free(c1)read(0,c1,0x20)...interactions that transition the heap into a new state. These
interactions represent an application’s usage or misusage of
the heap. To make our analysis feasible, we need to limit the
number of interactions that we consider, thereby bounding
the state space of the heap as well. In order to check our
model, we then combine single interactions into sequences
up to the specific bound, creating a sequence of transitions
that allows us to verify the reachable states.
4.1 Heap Transactions
Initially, HEAPHOPPER needs a set of operations that modify
the heap. These include both direct and indirect interactions.
Direct interactions refer to allocator functionality, specifically
malloc and free. Indirect interactions are modifications
of the allocated memory, such as buffer overflows, presum-
ably caused by flaws in the program using the allocator.
We define a transaction as an operation that modifies
the heap’s state directly or indirectly. Each transaction is
represented as a code stub modeling the desired behavior.
The combination of these code stubs then creates valid source
code that represents a specific sequence of transactions on
the state of the heap. In the following, we describe each of
our transactions in detail, with a short explanation of why
they are relevant in our interaction model.
malloc (M). The malloc transaction is used to allocate
memory.
It gets the size of the requested memory as a
parameter, and returns a memory block of the requested size.
HEAPHOPPER models the size by passing a symbolic value
to the heap. However, a completely unconstrained value
would result in an unacceptable overhead both in terms of
number of paths (since different sizes exercise different code
paths in the allocators) and constraint complexity. Instead,
we bound the size to a concrete range of values that must be
specified in advance. For this reason, the symbolic execution
unit will use symbolic-but-constrained values for the size
parameter of malloc.
To choose the range of that constrain values, we rely on
the fact that most of the allocator implementations execute
different code paths for certain ranges of sizes, typically
called bins [35]. In particular, we implemented a separate
tool that uses the execution traces of libc executions to
determine size ranges that lead to different execution paths.
The boundary values of the identified ranges can afterward
be plugged into the configuration file, to specify how to
constrain the value of malloc’s size parameter.
free (F). free is the API call to deallocate memory. This
transaction represents a legitimate free invocation, and its
argument will be any of the previously malloced chunks.
If multiple malloc transactions have been previously per-
formed, we will generate a different sequence for each one
as the argument to the free transaction.
overflow (O). Fundamentally, an overflow is an out-of-
bounds write into a buffer. In a heap scenario, the buffer is
represented by an allocated chunk, and the overflow happens
into the memory right after the chunk. In most cases, the
memory overwritten is another chunk adjacent in memory.
For allocators that make use of inline metadata, this can
have severe consequences regarding the integrity of internal
data, which often leads directly to exploitation primitives and
further memory corruptions.
There are two common paths that lead to a heap overflow.
First, the simple case of a missing bounds check, similar to
an overflow in any other memory region. Second, a bug in
the determination of the allocation size, ending up with a
chunk that is smaller than intended. Most often, this is the
result of an integer overflow when calculating the allocation
size.
In our model, an overflow represents an indirect interac-
tion with the heap. We implement it by inserting symbolic
memory right at the end of an allocated chunk returned by
malloc. Similar to the free transaction, we create a dif-
ferent sequence for each prior allocated chunk being the
target to the overflow. Since an overflow could be arbitrarily
long, we have to bound its length. Similarly to the alloca-
tion sizes, this is handled by making the overflow lengths
symbolic-but-constrained. Furthermore, HEAPHOPPER sup-
ports constraining the actual input values to certain bytes or
byte ranges, which allows adjusting the model to specific sce-
narios. For instance, the poisoned NULL byte we described
in Section 2.3 can be simulated restricting the overflow size
to 1 and the possible values of the overflowing data to just
NULL (0x00).
use-after-free (UAF).
In general, a use-after-free transac-
tion means an access to memory that has been freed. If a
UAF happens as a read access, it can be used by an attacker
as an information leak. The action becomes even more pow-
erful if the reference to the freed chunk is used for a write
access, because it lets an attacker manipulate data stored
inside the freed chunk, and this modified data might be
used later by the vulnerable program.
We model a UAF transaction by writing symbolic memory
into any freed chunk. Similar to the previous transactions,
this requires the creation of different sequences for each
previously freed chunk, and a bound on the number of
bytes written into memory.
double-free (DF). A double-free happens when a memory
chunk is freed twice, without being reallocated in between.
Typically, this occurs when a reference to a freed chunk is not
removed, but wrongly used again, similar to a use-after-free.
However, in a double-free scenario, instead of a read or write
access, the freed chunk’s reference is only passed to free
again. Nevertheless, in case of a successful double-free, the
chunk is stored inside the allocator’s internal structures for
freed chunks twice, which can lead to further corruption of
104    27th USENIX Security Symposium
USENIX Association
the heap structure.
The double-free is modeled as a call to free with any
formerly freed chunk, which entails a different sequence
for each of them.
fake-free (FF). A fake-free happens when an attacker con-
trols the parameter passed to free, and decides to make it
point to a controlled region, where a fake allocated chunk
has been placed. Allocators typically check that the pointer
passed to free points to a valid memory chunk, but it may
still be possible to create a fake chunk passing those checks.
If not rejected by the allocator, the fake chunk will be added
to the allocator’s structure for freed chunks. This could po-
tentially lead to future allocations returning the maliciously
fake chunk.
We model the fake-free action by adding a free invoca-
tion pointing to a fully symbolic memory region. The size of
this region has to be bounded to a specific value in advance.
The symbolic execution unit will automatically determine, if
possible, the values that this symbolic area must contain in