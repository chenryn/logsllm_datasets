graph topology of our login data, and how different network
conﬁgurations might affect our detection algorithms.
3.2 Data Cleaning
The vast majority of our data’s login events do not reﬂect
meaningful remote access events (i.e., did not enable a user
to remotely execute commands or access sensitive data on
the destination machine). Hopper applies four ﬁltering rules
described below to remove these logins from our data set. Ex-
cluding these spurious logins, our data set contains 3,527,844
successful logins, with a median of 4,098 logins per day.
Filtering Windows logins: As noted in prior work [27],
many “logins” between internal machines in Windows en-
terprise environments do not represent a meaningful remote
access event. Rather, these logins often correspond to uninter-
esting artifacts and special API calls that result from Windows
enterprise logging, and do not provide a user with the ability
to access data or alter the destination machine. Removing
these logins from our data results in a 40× reduction, which
comes primarily from removing three types of logins: printing
jobs, authentications into update and logging servers, and non-
administrator logins to Windows Domain Controllers. Most
non-administrator logins to Domain Controllers correspond
to artifacts of Kerberos authentication, where Domain Con-
trollers serve the role of a Kerberos Key Distribution Center
(KDC) and requests for a Kerberos ticket generate a record
of a “login” into the Domain Controller. After removing this
collection of spurious logins, our data set contains roughly
19.5 million login events.
Filtering automation logins: We further winnow our data set
by removing internal logins that result from low-risk automa-
tion. Hopper analyzes a historical set of logins and identiﬁes a
set of login edges that correspond to automation. Speciﬁcally,
each automation edge consists of a triplet (source, destination,
and username), that (1) occurs frequently across our data,2
(2) occurs on at least 50% of the historical days, and (3) has a
target username that does not match any employee’s account
(i.e., a non-human username). Hopper then outputs a list of
these edges as candidates for automation related logins. After
a review by the organization’s security team, Hopper removes
2In our work, we deﬁne a frequently occurring edge as one that occurs
greater than N = 24× D times, where D equals the number of days in the
historical data set (i.e., in total, the edge occurs at least as often as a process
that runs once every hour on each day in the historical data set).
any login whose (source, destination, and target user) matches
an edge listed in the approved automation set.
In our data, Hopper identiﬁes a set of approximately 30 au-
tomation edges that account for over 16 million login events.
Manually inspecting these automation logins reveals that they
correspond to mundane operations with minimally privileged
service accounts via a restricted set of remote-API calls (e.g.,
speciﬁc remctl calls [1] exposed by the destination machines).
For example, many of these logins resulted from ﬁle synchro-
nization operations between a central “leader” node and geo-
graphic replicas (e.g., a central software repository machine
syncing its content with replicated, regional servers). Another
common category of these automation logins corresponds to
version control and bug tracking software performing git op-
erations to synchronize state among each other; these internal
logins occurred under a restricted “git” user account that has
access to a limited API of git operations.
3.3 Ethics
This work involved a collaboration between academia and in-
dustry. Our research used an existing, historical data set of em-
ployee logins between internal machines at Dropbox, which
enterprises commonly collect to secure their environment.
Only authorized security employees at Dropbox accessed this
data; no sensitive data or personally identifying information
was shared outside of Dropbox. Additionally, the machines
that store and operate directly on data from Dropbox’s cus-
tomers reside on separate infrastructure; our study did not
involve that infrastructure or access any customer-related data.
This project underwent internal review and received approval
by the legal, privacy, and security teams at Dropbox.
4 Modeling Lateral Movement
Our Approach: Hopper, our system, constructs a graph of
user logins between internal machines and then detects lateral
movement by identifying suspicious paths in this graph. A
suspicious path corresponds to a sequence of logins made
by a single actor with two properties: (1) the path has at
least one login where the actor uses a set of credentials that
does not match their own, (2) the path accesses at least one
machine that the actor does not have access to under their
own credentials.
Motivating Intuition: This approach leverages a simple yet
powerful observation: in many real-world enterprise attacks,
adversaries conduct lateral movement to acquire additional
credentials and access new machines that their initial foothold
did not have access to [9,20,31,34,36,39,45]. For example, at
many organizations, access to sensitive data and/or powerful
internal capabilities requires a special set of privileges, which
most enterprise users lack. Thus, attacker lateral movement
will produce paths that use a new (elevated) set of credentials
3096    30th USENIX Security Symposium
USENIX Association
Figure 2: Hopper analyzes login events between internal machines
within an enterprise and generates alerts for paths of logins that
correspond to suspicious lateral movement activity. Hopper has two
key components: (1) a causality engine that infers a set of causal
paths that a login might belong to (§ 5), and (2) detection and scoring
algorithms that decide whether to alert on a path of logins (§ 6).
(Property 1) and access sensitive machines that their initial
victim could not access (Property 2). By searching for these
two key properties, Hopper also illustrates how login data not
only provides visibility into attacker lateral movement, but
also contains latent signals that reveal the completion of other
core stages of an attack’s lifecycle. For example, Property 1
captures the fact that attackers frequently acquire privileged
credentials (the “privilege escalation” and “credential access”
stages from the MITRE ATT&CK Framework [46]) to access
additional machines within an organization.
Moreover, the combination of these two attack path prop-
erties corresponds to characteristics that we do not expect in
benign paths: users should access machines under their own
credentials and they should only login to machines that they
have legitimate privileges to access.
4.1 Challenge: Anomalies at Scale
Prior work detects lateral movement by identifying logins that
traverse rare graph edges, under the assumption that attacker
movement will occur between users and machines that rarely
interact with each other [2, 30, 44]. While intuitive, these ap-
proaches generate too many false positives, due to the volume
of rare-but-benign behavior that occurs in large enterprises.
Even after applying Hopper’s data cleaning steps (§ 3.1),
tens of thousands of logins create “rare” graph edges in our
data set. If we alerted on logins whose edges have never
occurred in recent history, such a detector would produce
over 24,000 alerts across our data (over 1,600 alerts / month).
These rare-but-benign logins stem from a diverse set of causes,
such as users performing maintenance on machines they rarely
access (e.g., a user serving on their team’s on-call rotation),
new users or employees returning from a long vacation, and
users simply accessing rare-for-their-role services. Although
prior work introduces techniques to reﬁne this anomaly de-
tection approach, they still produce too many false positives
(§ 7.4). By re-framing the deﬁnition of an attack path from
simply anomalous paths, to paths that contain the key proper-
ties we highlight, Hopper can detect a range of lateral move-
ment attacks with signiﬁcantly fewer false positives.
Figure 3: An example of a simple login graph. Solid black edges
(L1 and L2) correspond to benign login events. Dashed red edges
(L3 and L4) correspond to a lateral movement attack path.
4.2 Hopper: System Overview
Hopper consists of two stages, shown in Figure 2. The ﬁrst
stage of Hopper (§ 5) runs a “causality engine” that aggregates
a set of logins into a graph of user movement and identiﬁes
broader paths of movement formed by groups of logically-
related logins. The second stage of Hopper (§ 6) takes a set
of login paths and decides whether to generate an alert by
identifying which login paths contain the two key attack prop-
erties described above. During this ﬁnal stage, Hopper prunes
common benign movement paths, extracts a set of features for
each path, and uses a combination of detection rules and a new
anomaly scoring algorithm to compute the “suspiciousness”
of each login path.
The Login Graph: Given a set of logins, Hopper constructs
a directed multi-graph that captures the interactions among
users and internal machines. Figure 3 shows a simple ex-
ample of a login graph constructed by Hopper. Each login
creates a directed edge in the graph, where the edge’s source
and destination nodes correspond to the machine initiating
and receiving the login. Edges represent unique, timestamped
logins from the source to the destination machine; multiple lo-
gins between the same two machines generate multiple edges.
Each edge is annotated with a target username: the account
that was logged into on the destination machine (the username
and permissions that the new session operates under).
Login Paths and Causal Users: A path of logins corre-
sponds to a series of connected edges, where each edge is
“caused” by the same actor. We use the term causal user to
refer to the actor whose machine initiated a path of logins,
which might not be the same as the target user recorded in
each login. The causal user is the original actor responsible
for making these logins (taken from the ﬁrst edge in each
path), while each login’s target user reﬂects the credentials
that the login’s destination machine received.
For example, in Figure 3, an attacker compromises Alice’s
machine (A) and makes a series of internal logins that forms
a two-hop lateral movement path from Machine A to Z. The
attacker ﬁrst uses Alice’s credentials in a login to Machine
Y , shown as L3. Then the attacker compromises Bob’s cre-
USENIX Association
30th USENIX Security Symposium    3097
Alerts: SuspiciousPathsDomain ContextScenario Matcher(2) Alert GeneratorFeatureExtractionScoring &DetectionPathsAlert BudgetLogins(1) CausalityEngineMachine A (Client)Owner = AliceMachine B (Client)Owner = BobMachine Y (Server)Owner = NoneMachine Z (Server)Owner = NoneL3 : ( t3 , Alice )L4 :  ( t4 , Bob )L1:  ( t1 , Alice )L2:  ( t2 , Bob )dentials on Y and uses them to login to Bob’s account on Z,
labeled L4. For each of the logins in this path, Alice is the
causal user, since all of the logins were made (caused) by a
user starting from Alice’s machine. Alice and Bob are the tar-
get users of L3 and L4 respectively, since each login presented
those usernames and credentials during authentication.
Path Types: One of the key attack properties that Hopper
looks for is whether a path’s causal user ever authenticates into
a machine with a new set of credentials. As described later in
Section 5, the information provided in standard authentication
logs does not always enable Hopper to precisely infer whether
a path exhibits this property. Accordingly, Hopper makes a
distinction between three types of paths: a BENIGN path, a
path with a CLEAR credential switch, or an UNCLEAR path.
Hopper labels a path as BENIGN if every login in the path
uses the causal user’s credentials (e.g., no switch in creden-
tials occurred). A path has a CLEAR credential switch if at
least one login in the path must have switched to a new set
of credentials. For example, in Figure 3, assume that login
L2 did not occur at all, then the paths (L1, L4) and (L3, L4)
correspond to paths with a CLEAR switch, because all paths
leading to L4 previously used a different set of credentials. On
the other hand, if all of L1, L2, L3 occurred and Hopper cannot
clearly determine which of them caused L4, then Hopper will
treat both the paths (L1, L4) and (L3, L4) as UNCLEAR paths.
An UNCLEAR path corresponds to a situation where Hopper
cannot cleanly infer a causal path for a given login, but rather
infers multiple potential paths, where some of the paths in-
volve a switch in credentials (e.g., L3 to L4), but others do not
(e.g., L2 to L4). As discussed in Section 6, because of these
different levels of certainty, Hopper uses two sets of detection
algorithms to classify a path as malicious. For paths with a
CLEAR credential switch, Hopper applies a simple rule-set
(§ 6.1). However, when limitations in real-world logs create
uncertainty about the paths that Hopper’s causality engine in-
fers (i.e., UNCLEAR paths), Hopper uses an anomaly scoring
algorithm to determine when to alert on a path (§ 6.2).
5 Inferring Causal Login Paths
Standard authentication logs describe point-wise activity that
lacks broader context about each login, such as from whom
and where the login originated. For example, in Figure 3,
given login L4 in isolation, a detector does not know whether
Bob accurately reﬂects the user responsible for making the
login, or whether another user such as Alice has stolen Bob’s
credentials and used them in a malicious login. Thus, for
each login (Li) that occurs, the ﬁrst stage of Hopper runs
a “causality engine” that coarsely infers the broader path
of movement that a login belongs to and the causal user
responsible for initiating the movement path. To do so, Hopper
uses a time-based heuristic to infer a set of “causal paths”
for Li, where each path corresponds to a unique sequence of
Path Component
Login List
Causal User
Description
List of logins in the path
Username of the employee whose
machine initiated the path
Changepoint Logins A list of logins where the username
Path Type
differs from the path’s preceding login
BENIGN, CLEAR, or UNCLEAR: whether
the path switches to new credentials
Table 2: Information in each path generated by Hopper’s causality
engine (§ 5). Given a new login, Hopper infers a set of these causal
paths, each of which reﬂects a sequence of logins that an actor could
have made up to and including the new login.
connected logins that could have led to Li and occurred within
the maximum time limit for a remote login session.
Identifying Causally-Related Logins: Hopper produces a
set of causal paths by running a backwards-tracing search
from Li to identify a sequence of causally-related logins that
include Li. Two logins are causally related if they (1) form
a connected set of edges in the login graph and (2) occur
within T hours of each other. Concretely, we say that Lk is a
causal, inbound login for Li if the destination of Lk equals the
source machine of Li, and Lk occurred within 24 hours prior
to the time of Li. We choose a threshold of 24 hours based
on the maximum duration of a login session at Dropbox; for
sessions that exceed this duration, the company requires the
source machine to re-authenticate, which produces a fresh
login event in our data. For example, in Figure 3, L1, L2, and
L3 are all causal logins for L4 if they occurred within 24 hours
prior to t4. Using this causal rule, Hopper infers a set of login
paths by identifying all of the causal logins for Li, and then
recursively repeats this search on each of those causal logins.
This process is similar to provenance and taint-tracking
methods that trace the ﬂow of information from a sink (Li’s
destination machine) back to its source (the root node of Li’s
login path) [18, 24, 25]. As with these ﬂow-tracking meth-
ods, naive backwards-tracing risks a “dependency explosion”,
where each backwards step can exponentially increase the
number of paths that Hopper infers, but only one of these
paths represents Li’s true causal path. We ﬁnd that four opti-
mizations and environmental factors mitigate this risk.
First, Hopper can use an optimized implementation that
requires only a single-step of backwards-tracing per login.
At a high-level, based on our key attack properties, Hopper
only needs to analyze paths that involve a switch in creden-
tials (Property 1). As a result, Hopper can incrementally build
a set of “watchlist” paths that contain a potential switch in
credentials. For each new login, Hopper only needs to per-
form one step of backwards-tracing to determine if the new
login involves a switch in credentials, or if it extends one of
these watchlist paths; Appendix A in our extended techni-
cal report [22] describes this implementation in more detail.
3098    30th USENIX Security Symposium
USENIX Association
Second, we observe that enterprise networks tend to have a
relatively ﬂat topology, since most users prefer to directly
access their target server; this behavior limits dependency
explosion, which we discuss more in Section 8.2. Third, due
to the natural workﬂows of users and a standard implementa-
tion of least privileges, most machines only get accessed by a
handful of users for speciﬁc job duties. This clustering limits
the number of inbound logins per machine, which reduces the
potential for path explosion (§ 8.2). Finally, to mitigate path
explosion that can occur from users or scripts making many
repeated logins to/from a machine, Hopper deduplicates paths
to one unique path per day (i.e., one unique set of daily login
edges, where a daily edge is a four-tuple of a login’s source,
destination, target username, and timestamp rounded to the
date it occurred).
Path Components and Types: Every causal path inferred
by Hopper contains the information in Table 2. Each path
includes a list of “changepoint” logins: logins that used a
different username than the preceding login in the path. For
logins that occurred from a client source machine, if the target
username does not match the source machine’s owner, Hopper