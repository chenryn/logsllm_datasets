Slack, it’s all of those.” –A participant
Shared accounts.
People on campaigns usually main-
tained multiple shared email accounts (e.g., for the candidate,
press, general information, donations, etc.) and social media
accounts (e.g., Facebook, Twitter, Instagram, YouTube, etc.),
to enable multiple staffers and consultants to communicate
with voters, donors, and more. In some contexts, participants
mentioned using email aliases like “press@” or “info@” to
protect the privacy of workers who managed the alias, while
providing an authoritative point of contact. Participants esti-
mated that shared accounts might be accessed by 2 to 20 peo-
ple. The shared nature of these accounts introduced security
vulnerabilities: participants described them as often having
passwords that were simple, credentials that were shared in
potentially vulnerable ways (e.g., on a whiteboard, a note
taped to a laptop, or via SMS or email), and 2FA not enabled,
in part due to a lack of support for multi-tenant accounts.
“Not all services have a coherent model for shared ac-
counts. . . Some like , have no model. So there’s
no choice on . . . around having a single set of ac-
count credentials that are shared by a large group of people.
And that large group probably includes the candidate, ran-
dom volunteers who walked in the door, and outside consult-
ing ﬁrms. And so it’s not shocking at all that these passwords
are simplistic, and that these accounts get taken over with
some regularity.” –A participant
Personal account use.
Participants emphasized that cam-
paign workers pervasively used personal (i.e., non-managed,
consumer) accounts, for several reasons. First, they were in-
credibly busy, which led to ad hoc decision-making regarding
what account to use in any given context. For example, if a
staffer was on the go with only their personal device, they
might use the personal accounts already set up on it. Relat-
edly, campaigns rarely had enough money to buy devices for
staff or consultants, so personal device use was common. This
meant that personal and work accounts were housed together
on individual personal devices, and cross-over between the
two was more likely in the busy and chaotic campaign work
environment. Another barrier to managed account use was
that sometimes providers charged money per account or for
certain administrator features. Furthermore, in an effort to
control who may be viewed as “speaking on behalf” of the
campaign, some campaigns were hesitant to give consultants
and volunteers campaign-domain email accounts or other
managed accounts. Finally, participants explained that some
consultants used consumer accounts (e.g., Gmail, Yahoo, Hot-
mail, or AOL) for campaign work. Even when participants
described efforts to separate work and personal accounts, they
still considered personal communications at risk. Personal
accounts were a major vulnerability for campaigns, because
they housed data that attackers were after, and campaigns had
no visibility or control over their security conﬁgurations.
“What ends up happening is that work product ends up in
their personal accounts. So  go after the personal
accounts, where they have data on polling, on digital trends,
plans, what emails we’re going to send out. . . that sort of stuff.
All of this is being shared in  to their per-
sonal account that IT staff can’t secure.” –A participant
Transient account ownership.
Incumbents are frequent
campaigners, and many elected positions in the U.S. have no
term limits. For example, in the U.S. Congress, people in the
House of Representatives campaign every 2 years for their
seat; Senators campaign every 6 years; some states’ Gover-
nors and representatives campaign every 2 or 4 years. Cam-
paigns that recurred tended to have new staff who reused ex-
isting accounts. Thus, a host of accounts needed to be passed
from one owner (who may no longer be on the campaign)
to the next, after each cycle. The need to pass on account
ownership, frequently paired with a lack of knowledge of how
to do this safely and efﬁciently, created a barrier to adoption
for account security features, like strong passwords and 2FA.
Participants also described cases where former staffers or
consultants retained access to sensitive accounts.
“ usually give people 30 to 60
days to wind down, and then you’ll keep 1 or 2 accounts
around. . . Depending on whether the campaign is dead, or
if it might come back in a couple of years. . . Then every-
thing pretty much lies dormant. There’s no real hygiene of
going through and changing all the passwords. People leave
me on  from campaigns for a long
time. . .  they decide to run and reactivate their old
1190    30th USENIX Security Symposium
USENIX Association
website, their social media, that kind of thing, they may clean
up who was on it, or they may not. . . What happens most fre-
quently is,  ‘Hey do you remember the pass-
word to this one? I can’t remember it, or I can’t ﬁnd it, or I
don’t have the recovery email.’ I’ve dealt with that with every
campaign I’ve ever worked on.” –A participant
Under-utilization of strong 2FA. Given their experiences
with campaigns, participants believed that most people in-
volved with campaigns had likely heard of 2FA, used some
form of it on at least one account, and associated it with be-
ing an important part of account security. However, 2FA was
described as under-utilized across campaign workers’ many
accounts. Personal accounts were commonly described as not
protected by 2FA, even though they often contained campaign-
relevant information or communications.
[Do you have 2FA on most accounts?] “Not all of them,
but some of them.” [How do you decide which accounts?]
“Mostly, what I’m prompted for, what is called to my atten-
tion.” –A participant
People involved with campaigns were described as often
using weaker second factors (SMS codes were commonly
used). All but two participants told us what second factors they
used—either at present, or in the past. Many used multiple
types—including SMS codes, app-generated codes, codes
from an email or phone call, security keys, hardware token
codes, and/or prompts—but SMS codes were by far the most
commonly used. All the security key users had some sort
of background or training in computer security. Participants
who had successfully helped colleagues adopt 2FA described
needing to start them on more familiar phone-based factors
and ease them into stronger second factors (which were widely
perceived as harder to use).
“ I’ve considered going to the
super-advanced, key chain thing. . . ” [Why did you decide
not to use a hardware security key?] “It seemed like it was
a little more than I was bargaining for, from an ease-of-
use standpoint. . . I felt like my level of security was sufﬁ-
cient. . .  another device.” –A
participant
Our interview protocol included a set of questions to eval-
uate participants’ understanding of 2FA and various second
factors. Based on their responses, we inferred from partici-
pants that many of them and their campaign colleagues did
understand that 2FA is for account security and has to do with
signing in, but did not understand how 2FA improves their
security, that different types of second factors offer meaning-
fully different levels of protection, and that they should use
2FA to protect most of their accounts.
[What attacks might the code via phone call be vulnerable
to?] “I don’t know. . . I have no idea.” [How about the app?]
“It just seems really complicated to set up. But hacking I
guess? I don’t know.” –A participant
Participants cited several pain points with 2FA that con-
tributed to this low adoption or understanding. Most com-
monly cited was that 2FA required extra time and effort. This
mattered to some busy participants, who described prioritiz-
ing their effort by only setting up 2FA on accounts perceived
to be at risk (which left some personal accounts unprotected).
Second, quick access to their accounts was described as criti-
cal, and some participants worried that 2FA might keep them
out of accounts. For example, some traveled often and had
trouble accessing second factors on airplanes, when they did
not have cell service or WiFi, or when their phone’s battery
was dead. Others avoided using a security key because they
worried about losing it or not having it when needed. Some
cited the need to buy a physical thing as a barrier, either for
cost or convenience reasons. Further, because most campaigns
did not have full time IT staff, they did not have access to tech
support for help with 2FA setup or account lockouts.
“This is important: inconveniencing candidates is one of the
third rails of working on a campaign. And so, if you introduce
any sort of wrinkle that might prevent the candidate from ac-
cessing their  account, or being able to receive
their email because they don’t have their two-factor device
there. . . that’s a recipe for a bad day. Because they’re going
to get very upset. . . none of them thinks they’re going to be
targeted for cybersecurity attacks.” –A participant
Account lockout is a real risk with 2FA [28]. However, it
seemed that the population overestimated the likelihood or
frequency of this happening, and underestimated the impor-
tance of using stronger account security protections given the
threats they face.
Finally, participants who were more familiar with security
technologies noted that 2FA suffered from usability issues,
caused in part by a lack of standardization across providers
on terminology, requirements, available second factor options,
and where settings were found.
“The reality is the industry has done a terrible job of making
it easy to be secure by default. Even very basic things, like
if people hear about two-factor and actually want to do it,
good luck ﬁnding the settings. Good luck understanding why
every service has different requirements. . . Everyone calls it
something different. . . ” –A participant
Weak password practices.
Participants who had worked
on party committees or more permanent organizations or con-
sultancies, which were not transient like campaigns, typically
described password practices that followed best practices,
including common use of password managers, within their
organizations. However, they observed that campaigns typi-
cally did not have such policies and relied more heavily on
personal accounts. Thus, campaigns depended on individual
workers choosing to use strong, unique passwords on their
own personal accounts. And as noted above, passwords were
often simplistic and sometimes shared insecurely for shared
USENIX Association
30th USENIX Security Symposium    1191
accounts, and were sometimes known by people no longer on
the campaign for transiently owned accounts.
Password managers were not commonly used on cam-
paigns, according to participants. Several participants with
security expertise used password managers and had tried to
help others on campaigns adopt them. They described these
efforts as challenging: password managers incorrectly saved
credentials often enough that confused and busy users aban-
doned them.
“ should probably use a password man-
ager. But. . . password managers are just way too awkward
and complicated for people to bother with. And even when
people really care, the reality is that the integration with the
apps and the browsers is ﬂaky enough that even when. . . you
think you saved the password, but you really saved a differ-
ent password, or you didn’t actually save your password, and
you never wrote it down or anything. So the next time you
come to the site, whatever is in the password manager doesn’t
work. That happens often enough for me, and I’m committed
to them. For people who aren’t committed to them, that sort
of thing happens once, they get confused once, and they’re
done.” –A participant
4.3 Campaign threat models
The practices and vulnerabilities described above are mean-
ingful in the context of the speciﬁc threats people involved
with campaigns believe they face. While prior work has de-
tailed threats to campaigns [20,31,47], here we focus on what
participants perceived the main threats to be.
Attackers.
Participants were most concerned about nation-
state attackers. According to participants, these attackers are
sophisticated, well-funded, relentless, and had not yet experi-
enced repercussions from the widely publicized attacks during
the 2016 election cycle. Nearly all participants raised those
attacks as evidence that some people involved with campaigns
were targeted by nation-states (though not all believed they
speciﬁcally were likely targets). A few participants described
evidence that they and their colleagues had been targeted,
including that they had received specialized state-sponsored
attack warnings, or general security alerts on their accounts.
“It seems narcissistic in some ways to think that you’re going
to be the target of it, but I got over that because as recently
as last month I received the warning that ‘a nation-state has
attempted to access your account’. . . And I’ve gotten account
recovery attempts, you know, ‘Someone is attempting to re-
cover your account. Is this you?’ And I’m like ‘no.”’ –A par-
ticipant
Some participants reported concerns about thieves, citizens,
or special interest groups as potential attackers. Most (but not
all) participants were less concerned with the other party,
members of the same party, or the press as attackers—but
there was nearly universal concern about those entities getting
leaked sensitive information as a result of an attack.
Attacks & targeting.
The attacks that participants had ex-
perienced, or heard about others in politics experiencing from
colleagues or the media, were top of mind. Collectively, their
top concern was phishing—they noted that it was cheap, easy,
can lead to considerable damage, and worked in the 2016
election cycle. Our more security-knowledgeable participants
noted that personal accounts, especially for communications
and social media, were a focus of attackers since they housed
data of interest to attackers and were less likely protected by
an IT team, security expert, or security policies (e.g., that en-
forces 2FA). Multiple participants reported receiving phishing
emails, though a few did not believe their role with campaigns
increased their risk of receiving phishing messages.
“The  that I’m the most nervous about are phishing
attempts that are getting more and more sophisticated. . . I’ve
seen a lot of them. . . In this last 6 months or so. . . I’ve
seen some really effective phishing attempts. . . The domain
is spoofed really effectively. . . Those make me nervous be-
cause there are people on political campaigns who. . . it’s not
that they’re careless, it’s just that they don’t know any bet-
ter. . . They will click on things and have no idea what they
might be opening up.” –A participant
Attackers were described as motivated to identify people
afﬁliated with a campaign. Participants talked about how
attackers might use FEC ﬁlings (which are publicly avail-
able, and list anyone paid by a campaign) and social media
(staffers often update their employment status, listing the cam-
paign). As evidence of this occurring, a participant recounted
how people afﬁliated with a campaign—even across organi-
zations—received the same phishing emails.
“Political organizations have to report to the FEC where they
spend money, and who they pay, including staff and consul-
tants. So we tell people: ‘You work  now.
Your name will be on an FEC report. You will be targeted.
. . . Don’t put it on  right away. You’re making
yourself a target.”’ –A participant
Though less salient than phishing, participants discussed
other attacks. From sophisticated attackers, participants talked
about ransomware, malware, and DDoS. From domestic at-
tackers, participants talked about people stealing devices or
information from campaign ofﬁces, constantly following and
recording candidates or campaign staff in person (to cap-
ture something damaging), harassing candidates or others
involved with campaigns on social media, and threatening
physical harm—all of which were experienced across our
set of participants. From a variety of attackers, participants
discussed scams aimed to steal money or efforts to spread
mis/disinformation and fake news.
Harms.
For campaigns, the main harm participants wor-
ried about was losing an election due to leaked or stolen infor-
mation, or monetary theft. Leaked information could cause
1192    30th USENIX Security Symposium
USENIX Association
embarrassment, loss of voters, or the loss of a strategic ad-
vantage. For democracy, the harm was that election outcomes
could be changed, weakening the institution of elections.
“As somebody who experienced it ﬁrsthand working on the
2016 race, I think that played a huge role in the outcome,
based on the events that happened afterwards. If campaigns
aren’t secure, elections may not be free, and that’s not what
we stand for. If somebody can have a hand in what gets said
based on using material that was hacked, I think that’s very
dangerous.” –A participant
5 Recommendations for safer campaigns
Political campaigns have recently realized the impact that dig-
ital security can have on candidates, staff members, political