### Energy Overhead of Scrubbing

Scrubbing, the process of checking and correcting memory errors, is more energy-intensive than refreshing, as it involves streaming data over the memory bus. However, scrubbing is performed much less frequently than refreshing, which means its overall contribution to system energy consumption is relatively small. For example, the total energy required to refresh an 8GB DIMM once is approximately 1.1mJ, while the energy for a single scrub operation is about 161mJ (150 times more). However, scrubbing occurs four orders of magnitude less frequently (every 15 minutes compared to every 64ms for refreshing). Table I illustrates the total energy consumed by scrubbing versus refreshing, with scrub intervals varying from four minutes to one hour. When scrubbing is performed every 15 minutes, as assumed in our evaluations, it results in only a 1% increase in energy consumption compared to refreshing.

### Performance and Energy Analysis

We used a detailed memory system simulator, USIMM [8], to model a quad-core system operating at 3.2GHz, connected to a DDR3-1600 (800MHz) memory system. As refresh overheads increase with technology scaling, we analyzed DRAM chips with densities ranging from 8Gb to 64Gb. The memory system consists of four DIMMs, so the total memory size ranges from 32GB (for 8Gb chips) to 256GB (for 64Gb chips). The baseline system uses the JEDEC-specified 64ms refresh interval, and we linearly increased the refresh cycle time with density (TRF C varies from 350ns to 2800ns).

We evaluated all workloads provided by USIMM for the Memory Scheduling Championship [2]. These workloads are memory-intensive and involve a large number of transactions between the memory system and the core [35]. The 18 workloads come from various suites, including SPEC (2), PARSEC (9), BioBench (2), and Commercial (5). We report the average performance across all 18 workloads.

To assess the effectiveness of AVATAR in reducing refresh operations, we evaluated three designs: AVATAR-1, AVATAR-120, and AVATAR-360, representing one day, 120 days, and 360 days after a retention time test, respectively. We also included a theoretical scheme that does not perform any refreshes.

#### A. Speedup

Figure 16 shows the speedup for AVATAR-1, AVATAR-120, AVATAR-360, and No Refresh compared to the JEDEC-specified refresh scheme. The performance benefit of eliminating refreshes increases with chip density, ranging from 4% at the 8Gb node to 54% at the 64Gb node (as denoted by the No Refresh bars). AVATAR provides approximately two-thirds of the performance benefit of No Refresh. Even after a year of continuous operation, AVATAR maintains most of the performance benefits close to those observed on the first day after retention testing. For instance, AVATAR improves performance by 35% even a year after retention time testing.

![Speedup from refresh savings. The performance of AVATAR improves with technology node.](fig16.png)

#### B. Energy-Delay Product

Refresh operations not only impact performance but also consume significant energy. Figure 17 compares the Energy Delay Product (EDP) of AVATAR-1, AVATAR-120, AVATAR-360, and No Refresh to the JEDEC-specified refresh scheme. The energy benefits of eliminating refreshes also increase with higher chip density. No Refresh potentially reduces the EDP by 68% at the 64Gb node. AVATAR-1 reduces EDP by 8%, 16%, 31%, and 55% for the 8Gb, 16Gb, 32Gb, and 64Gb nodes, respectively. AVATAR-360 has EDP savings similar to those of AVATAR-1.

![Energy Delay Product. The savings in Energy Delay Product increases with technology node.](fig17.png)

Overall, our analysis demonstrates that AVATAR not only significantly improves reliability but also achieves most of the performance and energy benefits of an otherwise-unreliable multirate refresh scheme.

### Related Work

To the best of our knowledge, this is the first comprehensive study and modeling of the effect of VRT cells on multirate refresh mechanisms. We provide a new analytical model showing that relying solely on ECC to correct VRT failures can result in an unacceptable rate of data loss. Our VRT-aware multirate refresh mechanism can ensure reliable operations in the presence of VRT failures. In this section, we discuss prior works that have proposed different mechanisms to mitigate the negative effects of DRAM refresh operations and profile VRT failures.

#### A. Lowering Refresh Rate

Prior works on minimizing refresh overhead by extending the refresh interval can be categorized into three classes:

- **Profiling-Based:** These schemes exploit the non-uniformity in retention times of DRAM cells to reduce refresh operations (e.g., [4, 21, 28, 36, 38, 41, 44]). They group rows into different bins based on initial retention time profiling and apply a higher refresh rate only to rows in the lower retention time bin. These mechanisms assume that the retention time profile of DRAM cells does not change at runtime, which is not always true due to VRT failures [29].

- **ECC-Based:** Prior work proposed to minimize refresh overhead by extending the refresh interval and using stronger ECC (5EC6ED) to correct retention failures [42]. However, this approach incurs significant bandwidth and performance overheads as it reads the entire 1KB chunk of data at every access to verify or update ECC.

- **Software Hint-Based:** These mechanisms rely on software/OS hints to lower the refresh rate or reliability for non-critical or invalid regions [11, 30, 31]. They cannot fully exploit the non-uniformity of retention times across the chip.

#### B. Refresh Scheduling

Previous works have proposed flexible scheduling of refresh operations to reduce their interference with program accesses [6, 12, 35, 40]. Our work complements these efforts by proposing a mechanism that reduces refresh overhead by extending the refresh interval for most memory rows.

#### C. Profiling for VRT

Although the VRT phenomenon has been widely studied [7, 10, 13, 20, 32, 33, 37, 43, 45], recent works have discussed issues in retention time profiling in the presence of VRT cells [19, 29]. Khan et al. [19] studied the effectiveness of multi-round testing, guard-banding, and different-strength ECC codes at tolerating VRT failures. Another prior work [3] uses profiling to detect retention failures when the module enters self-refresh mode, but it cannot guarantee data integrity as VRT failures can occur after testing.

### Conclusions

Multirate refresh schemes exploit the non-uniformity in retention times of DRAM cells to reduce refresh operations. While these schemes are effective, they face challenges due to the Variable Retention Time (VRT) phenomenon, which causes data errors even with ECC DIMMs. This paper introduces AVATAR, the first practical, effective, and reliable multirate refresh scheme. Our contributions include:

1. Characterizing the behavior of VRT cells and developing an architecture-level model to analyze multirate refresh in the presence of VRT.
2. Demonstrating that a VRT-agnostic approach relying on ECC DIMMs to correct VRT failures leads to an unacceptable rate of data loss.
3. Proposing AVATAR, a VRT-aware multirate refresh mechanism that adaptively changes the refresh rate to handle VRT failures at runtime, improving reliability to tens of years while maintaining most of the refresh savings and performance and energy benefits of multirate refresh.

AVATAR reduces refresh operations by 62%-72% for a DRAM system without additional hardware changes. This reduction leads to approximately 35% performance improvement and 55% energy-delay product reduction with 64Gb DRAM chips. We conclude that AVATAR is a highly effective and simple multirate refresh mechanism that ensures correct DRAM operation even in the presence of VRT failures.

### Acknowledgments

Chris Wilkerson contributed substantially to this work. We thank him for his insightful feedback and discussions. We also thank the anonymous reviewers for their valuable feedback. This work was supported in part by NSF grants 1319587, 1212962, 0953246, 1320531, 1065112, the Intel Science and Technology Center on Cloud Computing, and the Center for Future Architecture Research (C-FAR), one of the six SRC STARnet Centers, sponsored by MARCO and DARPA.

### References

[References listed as in the original text]

---

This optimized version aims to improve clarity, coherence, and professionalism while maintaining the technical details and structure of the original text.