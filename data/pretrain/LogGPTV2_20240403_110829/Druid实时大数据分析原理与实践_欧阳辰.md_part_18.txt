"fieldName":"new_visitor_count"
"type":"hyperUniqueCardinality"
"new_visitor_rate"
"arithmetic",
135
---
## Page 160
thirty_minute, hour, day, week, month, quarter, year .
aggregations和 postAggregations指定聚合方式。
136
context
descending
postAggregations
aggregations
filter
granularity
intervals
dataSource
queryType
字段名
·其他的，
·none，不被推荐使用。
·all，汇总为1条输出。
Timeseries 输出每个时间粒度内指定条件的统计信息，
Timeseries查询包含如下部分。
"intervals":[
“2016-08-07T00:00:00+08:00/2016-09-05T23:59:59+08:00
，则输出相应粒度的统计信息。
指定一些查询参数，如结果是否进缓存等
是否降序
后聚合器
聚合器
过滤器
查询结果进行聚合的时间粒度
查询时间区间范围，ISO-8601格式
要查询数据集dataSource名字
对于Timeseries查询，该字段的值必须是Timeseries
描述
，通过filter指定过滤条件，通过
Druid实时大数据分析原理与实践
否
否
否
是
否
是
是
是
是否必需
---
## Page 161
例子如下：
01-01到2012-01-03的数据，但是如果2012-01-02没有数据，会收到如下结果：
第6章数据查询
"dataSource":"sample_datasource",
"queryType": "timeseries",
"result":{"sample_namel": 0}
"timestamp":"2012-01-02T00:00:00.0007"
如果不希望Druid 自动补o，可以在请求的 context 中指定 skipEmptyBuckets的值为 true，
"result":{"sample_name1":
"timestamp":"2012-01-03T00:00:00.000Z",
"result":["sample_name1":
"timestamp":"2012-01-01T00:00:0.000Z",
Timeseries查询默认会给没有数据的buckets 填0，例如granularity设置为day，查询2012-
输出可能如下：
"result":{
"timestamp":
"click_rate": 1, 
"new_visitor_rate":0,
"click_visitor_count": 5.006113467958146,
"new_visitor_count":0,
"visit_count": 5.006113467958146,
"pv":30.000000061295435,
"2016-08-27116:00:00.000Z"
Y
137
---
## Page 162
按钮比率、ad_campaign与ad_media的组合个数，查询示例如下：
以及每个ad_source对应的访问次数、访客数、新访客数、点击按钮数、新访客比率、点击
定host=www.mejia.wang，以及来自PC或手机访问，希望获取访客数最高的3个ad_source，
返回前N条记录，并支持指定Metric为排序依据。例如，对指定广告主id=2852199100和指
6.5
Buckets为true，Druid也不会补0。
138
"context":{
00000:00:00100-10-2002/00000:00:0010-10-2107100100.
"aggregations":[
"granularity”:"day"，
TopN是非常常见的查询类型，返回指定维度和排序字段的有序 top-n序列。TopN支持
但是需要注意的是，如果2012-01-02对应的Segiment不存在，即使不设置 skipEmpty-
"skipEmptyBuckets":"true"
{"type": "longSum", "name": "sample_name1", 
metric":
"threshold":3
"dimension":"ad_source"
"granularity":"all",
"dataSource":
"queryType":"topN",
filter":[
TopN
"fields":[
"type": "and",
"metric":"pv"
"type":"numeric",
"value"; "www.mejia.wang"
"dimension":"host"
"type":"selector"
"visitor_statistics",
,"fieldName":"sample_fieldName1"}
Druid实时大数据分析原理与实践
---
## Page 163
第6章
"aggregations":
数据查询
"fieldName":"new_visit_count"
"name":“new_visitor_count",
"type":
"fieldName":"visit_count"
"name":"visitor_count"
"type":
"fieldName":"count"
"type": "LongSum"
"fields":
"type":"or",
"value":"2852199100"
"dimension":"corpuin",
"type":"selector",
"hyperUnique"
"hyperUnique"
"value":"2"
"dimension":"device_type",
"type":"selector",
"value":
"type":"selector",
一
139
---
## Page 164
140
'postAggregations":
"fields":[
"fn":“/",
"fn":"/",
"type":
"byRow":true
"type":"cardinality"
"fieldName":"click_visit_count"
"name"：
"type":
'fields":
'name":
'fieldNames":[
'name":"sub_count",
"name":"click_visitor_count",
"type":“hyperUnique"
"ad_media"
"ad_campaign"
"click_rate",
"arithmetic"
"fieldName":"visitor_count"
"type":"hyperUniqueCardinality",
"fieldName":"new_visitor_count"
"type”:“"hyperUniqueCardinality”,
"new_visitor_rate",
"arithmetic",
Druid实时大数据分析原理与实践
---
## Page 165
第6章
context
metric
threshold
dimension
postAggregations
aggregations
filter
granularity
intervals
dataSource
queryType
字段名
TopN查询包含如下部分。
"intervals":[
数据查询
"2016-08-30T00:00:00+08:00/2016-09-05T23:59:59+08:00"
指定一些查询参数，如结果是否进缓存等
进行统计并排序的Metric，如PV
TopN的N取值
如URL
进行TopN查询的维度，一个 TopN查询指定且只能指定一个维度，
后聚合器
聚合器
过滤器
查询结果进行聚合的时间粒度
查询时间区间范围，ISO-8601格式
要查询数据集dataSource名字
对于TopN查询，该字段的值必须是topN
描述
"fieldName":"visitor_count"
"type”:"hyperUniqueCardinality",
"fieldName":"click_visitor_count"
"type":"hyperUniqueCardinality"
是
是
否
是
否
是
是
是
是
是否必需
否
是
141
---
## Page 166
"metric":{
"metric":{
"metric":{
"metric":{
"metric"："”//默认方式，升序排列
142
查询结果如下：
"previousStop":""
"type"："alphaNumeric",//指定数字排序
"previousStop"："”//如"b"，按照字典序，排到“b”开头的为止
"type"："lexicographic"，//指定按照字典序排序
"metric":
"type"："inverted",//指定按照numeric升序排列
"metric":""
"type":
·metric：TopN专属，指定排序依据。它有如下使用方式：
·aggregations：聚合器。用到的聚合函数和字段需要在metricsSpec中定义。HyperUnique
·filter：过滤指定的条件。支持“and”，“or”，“not”，“in”，
上述查询JSON基本上包含了TopN查询中能用到的所有特性。
能比HyperUnique差。
nality用来计算指定维度的基数，它与HyperUnique不同的是支持多个维度，但是性
采用 HyperLogLog近似对指定字段求基数，这里用来算出各种行为的访客数。cardi-
"timestamp":"2016-08-29T16:00:00.000Z",
："numeric",
//指定按照numeric降序排列
，支持加、减、乘、除等运算。
Druid实时大数据分析原理与实践
---
## Page 167
最后的结果，如果dimension的基数在1000 以内，则是准确的，超过1000就是近似值了。
第6章数据查询
需要注意的是，topN是一个近似算法，每一个 Segment返回前1000条进行合并再得到
"result";
"click_visitor_count":
nobosaunospe
"visitor_count": 4.003911343725148,
"sub_count":1.0002442201269182,
"click_rate":0,
"new_visitor_rate":
"pv":3，
"click_visitor_count":0
"ad_source":"google",
"new_visitor_count":4.003911343725148,
"sub_count":1.0002442201269182,
"click_rate":0,
"new_visitor_rate":1,
"pv":4,
new_visitor_count":4.003911343725148,
visitor_count":4.003911343725148,
"click_visitor_count":0
'ad_source":"baidu",
"visitor_count": 7.011990219885757,
sub_count":1.0002442201269182,
"click_rate":0,
new_visitor_count": 7.011990219885757,
"new_visitor_rate":
"pv":5,
143
---
## Page 168
击按钮数、新访客比率和点击按钮比率，查询示例如下：
在limitSpec中按照指定Metric排序，不过不支持offset。
中，对GroupBy有一个优化，可以通过在Context中指定使用新的算法。GroupBy支持limit，
进行groupby，则应尽量使用TopN。这两者的性能比GroupBy要好很多，在Druid0.9.2版本
统计数据，类似于groupbyhour之类的操作，通常应该使用Timeseries。
指定更多的维度，但性能比TopN要差很多。
的维度进行排序，并输出 limit行数。同时，支持having操作。GroupBy与TopN 相比，可以
6.6
144
例如，希望查询每组ad_source、ad_campaign和ad_media对应的访客数、新访客数、点
"filter":{
"granularity":
"dataSource":
"queryType"：“
GroupBy类似于 SQL中的group by操作，能对指定的多个维度进行分组，也支持对指定
'limitSpec":[
dimensions":[
GroupBy
"fields":[
"type":"and",
"columns":[
"limit":1000,
"type":"default"
"ad_media"
"ad_campaign"
"ad_source"
"dimension":"host"
"type":"selector"
"direction":“descending"
"dimension":"visitor_count",
"visitor_statistics",
"all",
"groupBy"
。如果是对时间范围进行聚合，输出各个时间的
Druid实时大数据分析原理与实践
，如果是对单个维度
---
## Page 169
第
6章
"aggregations":
数据查询
"name": "new_visitor_count",
"type":