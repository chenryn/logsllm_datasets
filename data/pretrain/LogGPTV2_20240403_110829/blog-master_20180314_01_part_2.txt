```  
6、HASH 或 group agg  
```  
postgres=# explain (analyze,verbose,timing,costs,buffers) select count(*) from t group by (random()*10)::int;  
                                                           QUERY PLAN                                                             
--------------------------------------------------------------------------------------------------------------------------------  
 GroupAggregate  (cost=401830.06..464809.48 rows=2519177 width=12) (actual time=1907.227..2622.407 rows=11 loops=1)  
   Output: count(*), (((random() * '10'::double precision))::integer)  
   Group Key: (((random() * '10'::double precision))::integer)  
   Buffers: shared hit=11171, temp read=24908 written=27447  
   ->  Sort  (cost=401830.06..408128.00 rows=2519177 width=4) (actual time=1869.656..2249.684 rows=2519177 loops=1)  
         Output: (((random() * '10'::double precision))::integer)  
         Sort Key: (((random() * '10'::double precision))::integer)  
         Sort Method: external merge  Disk: 34544kB  
         Buffers: shared hit=11171, temp read=24908 written=27447  
         ->  Seq Scan on public.t  (cost=0.00..55256.60 rows=2519177 width=4) (actual time=0.014..399.124 rows=2519177 loops=1)  
               Output: ((random() * '10'::double precision))::integer  
               Buffers: shared hit=11171  
 Planning time: 0.104 ms  
 Execution time: 2629.891 ms  
(14 rows)  
```  
```  
2018-03-14 10:33:14.781 CST,"postgres","postgres",49481,"[local]",5aa885b7.c149,17,"EXPLAIN",2018-03-14 10:15:19 CST,3/5018620,0,LOG,00000,"temporary file: path ""base/pgsql_tmp/pgsql_tmp49481.7"", size 35373056",,,,,,"explain (analyze,verbose,timing,costs,buffers) select count(*) from t group by (random()*10)::int;",,"FileClose, fd.c:1564","psql"  
```  
7、distinct  
```  
postgres=# explain (analyze,verbose,timing,costs,buffers) select count(distinct uid1) from t;  
                                                        QUERY PLAN                                                          
--------------------------------------------------------------------------------------------------------------------------  
 Aggregate  (cost=42660.71..42660.72 rows=1 width=8) (actual time=1961.611..1961.612 rows=1 loops=1)  
   Output: count(DISTINCT uid1)  
   Buffers: shared hit=11171, temp read=18053 written=18971  
   ->  Seq Scan on public.t  (cost=0.00..36362.77 rows=2519177 width=4) (actual time=0.009..279.037 rows=2519177 loops=1)  
         Output: uid1, uid2  
         Buffers: shared hit=11171  
 Planning time: 0.081 ms  
 Execution time: 1961.654 ms  
(8 rows)  
```  
```  
2018-03-14 10:32:14.004 CST,"postgres","postgres",49481,"[local]",5aa885b7.c149,16,"EXPLAIN",2018-03-14 10:15:19 CST,3/5018618,0,LOG,00000,"temporary file: path ""base/pgsql_tmp/pgsql_tmp49481.6"", size 30318592",,,,,,"explain (analyze,verbose,timing,costs,buffers) select count(distinct uid1) from t;",,"FileClose, fd.c:1564","psql"  
```  
8、递归查询  
特别是死循环  
```  
postgres=# WITH RECURSIVE t(n) AS (  
    SELECT 1  
  UNION ALL  
    SELECT n+1 FROM t  
)  
SELECT n FROM t LIMIT 10000;  
```  
```  
2018-03-14 11:03:58.574 CST,"postgres","postgres",49481,"[local]",5aa885b7.c149,8238,"SELECT",2018-03-14 10:15:19 CST,3/5018664,0,LOG,00000,"temporary file: path ""base/pgsql_tmp/pgsql_tmp49481.8219"", size 140000",,,,,,"WITH RECURSIVE t(n) AS (  
    SELECT 1  
  UNION ALL  
    SELECT n+1 FROM t  
)  
SELECT n FROM t LIMIT 10000;",,"FileClose, fd.c:1564","psql"  
```  
[《PostgreSQL 递归死循环案例及解法》](../201607/20160723_01.md)  
普通的CTE 会用到临时文件吗？  
取决于内部执行的QUERY，以及执行计划是否有必要使用临时文件，同样使用临时文件的阈值还是work_mem。一条QUERY可以使用多个work_mem，还是看执行计划，你可以简单理解为执行树中，每一个NODE都有机会用到work_mem的大小的内存。  
9、在当前会话中跟踪temp file的使用   
```
postgres=# set log_temp_files =0;
SET
postgres=# set client_min_messages =log;
SET
postgres=# create table t_j(id int , info text);
LOG:  statement: create table t_j(id int , info text);
CREATE TABLE
postgres=# insert into t_j select generate_series(1,1000000);
INSERT 0 1000000
postgres=# set work_mem ='4MB';
SET
postgres=# explain (analyze,verbose,timing,costs,buffers) select count(*) from t_j t1 join t_j t2 using (id);
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2056", size 1498584
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2071", size 1498584
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2058", size 1497192
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2073", size 1497192
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2053", size 1495632
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2068", size 1495632
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2050", size 1506096
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2065", size 1506096
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2055", size 1503504
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2070", size 1503504
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2052", size 1505064
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2067", size 1505064
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2051", size 1495416
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2066", size 1495416
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2060", size 1498392
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2075", size 1498392
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2046", size 1495440
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2061", size 1495440
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2049", size 1501536
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2064", size 1501536
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2057", size 1498752
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2072", size 1498752
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2054", size 1498032
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2069", size 1498032
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2059", size 1513032
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2074", size 1513032
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2048", size 1500360
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2063", size 1500360
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2047", size 1489584
LOG:  temporary file: path "base/pgsql_tmp/pgsql_tmp27966.2062", size 1489584
                                                                QUERY PLAN                                                                 
-------------------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=73228.00..73228.01 rows=1 width=8) (actual time=1167.670..1167.671 rows=1 loops=1)
   Output: count(*)
   Buffers: shared hit=8850, temp read=5532 written=5502
   ->  Hash Join  (cost=30832.00..70728.00 rows=1000000 width=0) (actual time=375.622..1053.586 rows=1000000 loops=1)
         Hash Cond: (t1.id = t2.id)
         Buffers: shared hit=8850, temp read=5532 written=5502
         ->  Seq Scan on public.t_j t1  (cost=0.00..14425.00 rows=1000000 width=4) (actual time=0.012..155.899 rows=1000000 loops=1)
               Output: t1.id
               Buffers: shared hit=4425
         ->  Hash  (cost=14425.00..14425.00 rows=1000000 width=4) (actual time=375.207..375.207 rows=1000000 loops=1)
               Output: t2.id
               Buckets: 131072  Batches: 16  Memory Usage: 3227kB
               Buffers: shared hit=4425, temp written=2736
               ->  Seq Scan on public.t_j t2  (cost=0.00..14425.00 rows=1000000 width=4) (actual time=0.005..157.634 rows=1000000 loops=1)
                     Output: t2.id
                     Buffers: shared hit=4425
 Planning time: 0.115 ms
 Execution time: 1167.726 ms
(18 rows)
```
## 小结  
当一些Query的操作，使用的内存量大于work_mem指定阈值时，就会触发使用临时文件。包括排序，IDSTINCT，MERGE JOIN，HASH JOIN，哈希聚合，分组聚合，SRF，递归查询 等操作。  
通过设置 log_temp_files ，当会话使用临时文件大小超过了设置大小，就可以跟踪到临时文件的使用。  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")