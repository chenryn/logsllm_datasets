## 沉浸式学习PostgreSQL|PolarDB 22: 用KMeans 数据聚集算法进行无监督学习和数据分类分析    
### 作者    
digoal    
### 日期    
2023-10-27    
### 标签    
PostgreSQL , PolarDB , 数据库 , 教学    
----    
## 背景      
欢迎数据库应用开发者参与贡献场景, 在此[issue](https://github.com/digoal/blog/issues/121)回复即可, 共同建设《沉浸式数据库学习教学素材库》, 帮助开发者用好数据库, 提升开发者职业竞争力, 同时为企业降本提效.    
- 系列课程的核心目标是教大家怎么用好数据库, 而不是怎么运维管理数据库、怎么开发数据库内核. 所以面向的对象是数据库的用户、应用开发者、应用架构师、数据库厂商的产品经理、售前售后专家等角色.    
本文的实验可以使用永久免费的阿里云[云起实验室](https://developer.aliyun.com/adc/scenario/f55dbfac77c0467a9d3cd95ff6697a31)来完成.    
如果你本地有docker环境也可以把镜像拉到本地来做实验:    
x86_64机器使用以下docker image:    
- [《amd64 image》](../202307/20230710_03.md)    
ARM机器使用以下docker image:    
- [《arm64 image》](../202308/20230814_02.md)    
## 业务场景1 介绍: 用KMeans 数据聚集算法进行无监督学习和数据分类分析    
每家公司都有机会通过使用机器学习以最小的努力改进其决策流程。然而，缺点是对于大多数 DBMS，您需要在数据库之外执行机器学习过程。PostgreSQL|PolarDB 中并非如此。  
由于 PostgreSQL|PolarDB 包含对其他语言的多个扩展。您无需离开 PostgreSQL|PolarDB 即可训练和使用机器学习算法。  
让我们看一下如何使用 PLPython 直接在 PostgreSQL|PolarDB 中执行 Kmeans（最流行的无监督学习算法之一）。  
### 实现和对照      
传统数据库无法实现库内kmeans聚集.  
#### 传统方法 设计和实验     
无.  
#### PolarDB|PG新方法1 设计和实验  
1、安装依赖包  
```  
# 进入容器
docker exec -ti pg bash  
# 进入postgres用户
su - postgres  
# 换国内源
pip3 config set global.index-url https://mirrors.aliyun.com/pypi/simple/
# 安装依赖库
pip3 install pandas  
pip3 install scikit-learn  
```  
2、导入测试数据, 采用公开可用的 iris 数据集。  
https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data  
```  
CREATE TABLE iris(  
  sepal_length REAL,  
  sepal_width REAL,  
  petal_length REAL,  
  petal_width REAL,  
  species varchar(20)  
);  
copy iris from stdin with (format csv);  
--  拷贝以上网页内容 
\.  
```  
现在我们已经有了要使用的数据，让我们跳转到 kmean 的核心函数。  
3、安装plpython3u  
```  
psql  
create language plpython3u;  
```  
4、使用 PL/Python 编写的函数可以像任何其他 SQL 函数一样调用。由于 Python 拥有无数的机器学习库，因此集成非常简单。此外，除了完全支持Python之外，PL/Python还提供了一组方便的函数来运行任何参数化查询。因此，执行机器学习算法可能只需要几行代码。让我们来看看  
参数说明:  
- input_table: 数据集表名, 用于聚集训练  
- columns: 列名  
- clus_num: 产生多少个聚集点  
```  
CREATE OR replace FUNCTION kmeans(input_table text, columns text[], clus_num int) RETURNS bytea AS  
$$  
from pandas import DataFrame  
from sklearn.cluster import KMeans  
from _pickle import dumps  
import pandas as pd  
all_columns = ",".join(columns)  
if all_columns == "":  
    all_columns = "*"  
rv = plpy.execute('SELECT %s FROM %s;' % (all_columns, plpy.quote_ident(input_table)))  
frame = []  
for i in rv:  
    frame.append(i)  
df = DataFrame(frame).convert_dtypes(convert_floating =True)  
kmeans = KMeans(n_clusters=clus_num, random_state=0).fit(df._get_numeric_data())  
return dumps(kmeans)  
$$ LANGUAGE plpython3u;  
```  
正如您所看到的，该脚本非常简单。首先，我们导入所需的函数，然后从传递的列中生成一个字符串，或者如果传递的是空数组，则将其替换为 `*`，最后我们使用 PL/Python 的执行函数构建查询。尽管这超出了本文的范围，但我强烈建议您阅读有关如何使用 PL/Python 参数化查询的内容。  
构建并执行查询后，我们需要将其转换为数据帧并将数值变量转换为数值类型（默认情况下它们可能会被解释为其他类型）。然后，我们调用 kmeans，其中传递的输入组数量作为参数传递，作为您想要获取的簇的数量。最后，我们将其转储到 cPickle 中并返回存储在 Pickle 中的对象。Pickling 对于稍后恢复模型是必要的，否则 Python 将无法直接从来自 PostgreSQL 的字节数组恢复 kmeans 对象。  
最后一行指定扩展语言：在本例中，我们使用 python3，使用名为 plpython3u 的扩展语言  
5、存储模型  
创建一个模型而不用它做任何事情是没有多大意义的。因此，我们需要存储它。  
为此，我们首先创建一个模型表：  
```  
CREATE TABLE models (  
  id SERIAL PRIMARY KEY,  
  model BYTEA NOT NULL  
);  
```  
在这种情况下，我们的表只有一个主键和一个字节数组字段，这是序列化的实际模型。请注意，它与我们定义的 kmeans 返回的数据类型相同。  
一旦我们有了表，我们就可以轻松地使用模型插入新记录：  
```  
INSERT INTO models(model) SELECT kmeans('iris', array[]::text[], 3);     
```  
在本例中，我们将 columns 参数作为空数组传递，以对表中的所有数值变量执行聚类。请考虑这只是一个例子。例如，在生产案例中，您可能需要添加一些额外的字段，以便更轻松地识别不同的模型。  
6、显示模型信息  
到目前为止，我们能够创建一个模型并存储它，但是直接从数据库获取它并不是很有用。您可以通过运行来检查它  
从型号中选择`*`；  
因此，我们需要返回 Python 来显示有关模型的有用信息。这是我们将要使用的函数：  
参数说明:  
- model_table: 模型表名称   
- model_column: 模型列二进制值   
- model_id: 模型ID    
```  
CREATE OR replace FUNCTION get_kmeans_centroids(model_table text, model_column text, model_id int) RETURNS real[] AS  