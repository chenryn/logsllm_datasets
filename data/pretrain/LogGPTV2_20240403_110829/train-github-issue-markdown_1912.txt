### System Information
- **Custom Code**: N/A
- **OS Platform and Distribution**: macOS High Sierra, Version 10.13.4 (17E202)
- **TensorFlow Installation Source**: Source
- **TensorFlow Version**: Attempting to compile at `e365dea` with minimal local changes (see below)
- **Python Version**: 2.7.15
- **Bazel Version**: 0.13.1 (Homebrew)
- **GCC/Compiler Version**: Apple LLVM version 8.1.0 (clang-802.0.42)
- **CUDA/cuDNN Version**: CUDA 9.2.64 for Mac, cuDNN 7.1
- **GPU Model and Memory**: NVIDIA GeForce GT 750M with 2 GB device memory, CUDA Compute Capability 3.0
- **Exact Command to Reproduce**:
  ```sh
  ./configure
  bazel build --config=opt --config=cuda --save_temps --explain=explain.txt --verbose_explanations --verbose_failures --linkopt=-Wl,-rpath,/usr/local/cuda/lib //tensorflow/tools/pip_package:build_pip_package
  ```

### Problem Description
This issue is a reoccurrence of #9072, but the previously suggested solutions (not using clang as the CUDA compiler and using CommandLineTools) do not resolve the problem.

#### Configuration Details
- Bazel version: 0.13.1 (Homebrew)
- Python location: `/usr/local/opt/python@2/bin/python2.7`
- Python library path: `/usr/local/Cellar/python@2/2.7.15/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages`
- Enabled support: Google Cloud Platform, Hadoop File System, Amazon S3 File System, Apache Kafka Platform
- Disabled support: XLA JIT, GDR, VERBS, OpenCL SYCL, MPI
- CUDA support enabled with CUDA 9.2 and cuDNN 7.1.4
- CUDA compute capability: 3.0
- CUDA compiler: nvcc
- Host compiler: `/usr/bin/gcc`

#### Build Command
```sh
bazel build --config=opt --config=cuda --save_temps --explain=explain.txt --verbose_explanations --verbose_failures --linkopt=-Wl,-rpath,/usr/local/cuda/lib //tensorflow/tools/pip_package:build_pip_package
```

#### Error Message
```sh
Starting local Bazel server and connecting to it...
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
ERROR: Inconsistent crosstool configuration; no toolchain corresponding to 'local_darwin' found for cpu 'darwin'
INFO: Elapsed time: 0.903s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (2 packages loaded)
```

#### Additional Information
- `xcode-select -p` output: `/Library/Developer/CommandLineTools`
- `/usr/bin/gcc --version` output:
  ```
  Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
  Apple LLVM version 8.1.0 (clang-802.0.42)
  Target: x86_64-apple-darwin17.5.0
  Thread model: posix
  InstalledDir: /Library/Developer/CommandLineTools/usr/bin
  ```
- The `deviceQuery` CUDA SDK sample builds and runs without issues.

### Local Changes
The only local changes from `e365dea` are:
- Adjusted shared memory alignment in several GPU kernels:
  - `concat_lib_gpu_impl.cu.cc`
  - `depthwise_conv_op_gpu.cu.cc`
  - `split_lib_gpu.cu.cc`
- Commented out `-lgomp` in `third_party/gpus/cuda/BUILD.tpl` and `third_party/toolchains/gpus/cuda/BUILD`

### Source Code / Logs
#### Diff for `concat_lib_gpu_impl.cu.cc`
```diff
diff --git a/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc b/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc
index a561d918bd..46c91b4511 100644
--- a/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc
+++ b/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc
@@ -69,7 +69,7 @@
   IntType num_inputs = input_ptr_data.size;
   // verbose declaration needed due to template
-  extern __shared__ __align__(sizeof(T)) unsigned char smem[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char smem[];
   IntType* smem_col_scan = reinterpret_cast(smem);
   if (useSmem) {
```

#### Diff for `depthwise_conv_op_gpu.cu.cc`
```diff
diff --git a/tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc b/tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc
index 5390222b3a..fcbd733614 100644
--- a/tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc
+++ b/tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc
@@ -172,7 +172,7 @@
   const DepthwiseArgs args, const T* input, const T* filter, T* output) {
   assert(CanLaunchDepthwiseConv2dGPUSmall(args));
   // Holds block plus halo and filter data for blockDim.x depths.
-  extern __shared__ __align__(sizeof(T)) unsigned char shared_memory[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char shared_memory[];
   T* const shared_data = reinterpret_cast(shared_memory);
   const int num_batches = args.batch;
@@ -452,7 +452,7 @@
   const DepthwiseArgs args, const T* input, const T* filter, T* output) {
   assert(CanLaunchDepthwiseConv2dGPUSmall(args));
   // Holds block plus halo and filter data for blockDim.z depths.
-  extern __shared__ __align__(sizeof(T)) unsigned char shared_memory[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char shared_memory[];
   T* const shared_data = reinterpret_cast(shared_memory);
   const int num_batches = args.batch;
@@ -1118,7 +1118,7 @@
   const DepthwiseArgs args, const T* output, const T* input, T* filter) {
   assert(CanLaunchDepthwiseConv2dBackpropFilterGPUSmall(args, blockDim.z));
   // Holds block plus halo and filter data for blockDim.x depths.
-  extern __shared__ __align__(sizeof(T)) unsigned char shared_memory[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char shared_memory[];
   T* const shared_data = reinterpret_cast(shared_memory);
   const int num_batches = args.batch;
@@ -1388,7 +1388,7 @@
   const DepthwiseArgs args, const T* output, const T* input, T* filter) {
   assert(CanLaunchDepthwiseConv2dBackpropFilterGPUSmall(args, blockDim.x));
   // Holds block plus halo and filter data for blockDim.z depths.
-  extern __shared__ __align__(sizeof(T)) unsigned char shared_memory[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char shared_memory[];
   T* const shared_data = reinterpret_cast(shared_memory);
   const int num_batches = args.batch;
```

#### Diff for `split_lib_gpu.cu.cc`
```diff
diff --git a/tensorflow/core/kernels/split_lib_gpu.cu.cc b/tensorflow/core/kernels/split_lib_gpu.cu.cc
index 393818730b..58a1294005 100644
--- a/tensorflow/core/kernels/split_lib_gpu.cu.cc
+++ b/tensorflow/core/kernels/split_lib_gpu.cu.cc
@@ -121,7 +121,7 @@
   int num_outputs = output_ptr_data.size;
   // verbose declaration needed due to template
-  extern __shared__ __align__(sizeof(T)) unsigned char smem[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char smem[];
   IntType* smem_col_scan = reinterpret_cast(smem);
   if (useSmem) {
```

#### Diff for `third_party/gpus/cuda/BUILD.tpl`
```diff
diff --git a/third_party/gpus/cuda/BUILD.tpl b/third_party/gpus/cuda/BUILD.tpl
index 2a37c65bc7..43446dd99b 100644
--- a/third_party/gpus/cuda/BUILD.tpl
+++ b/third_party/gpus/cuda/BUILD.tpl
@@ -110,7 +110,7 @@
     ],
     linkopts = ["-lgomp"],
-    linkstatic = 1,
+    #linkstatic = 1,
     visibility = ["//visibility:public"],
 )
```

#### Diff for `third_party/toolchains/gpus/cuda/BUILD`
```diff
diff --git a/third_party/toolchains/gpus/cuda/BUILD b/third_party/toolchains/gpus/cuda/BUILD
index 4cb8380938..d025c4f3aa 100644
--- a/third_party/toolchains/gpus/cuda/BUILD
+++ b/third_party/toolchains/gpus/cuda/BUILD
@@ -115,7 +115,7 @@
     ],
     linkopts = ["-lgomp"],
-    linkstatic = 1,
+    #linkstatic = 1,
     visibility = ["//visibility:public"],
 )
```