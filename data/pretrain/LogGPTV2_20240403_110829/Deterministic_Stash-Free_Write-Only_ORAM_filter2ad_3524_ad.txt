into a ceiling based on the fact that, for any two integers x, y,
⌈x/y⌉ = ⌊(x + y − 1)/y⌋.
The height of the Trie is then equal to the height of a b-ary tree
with Np + 1 nodes, which is O(logb N). This is the number of Trie
nodes that need to be written to the holding area of the position
WoORAM on each update (including a potential dummy node).
b−1
Each write to the data WoORAM requires rewriting h ∈ O(logb N)
nodes in the Trie (for a single path). Each of those writes to the
holding area of the position WoORAM needs, on average, Np/Mp
number of refreshes to the main area, where Np is the size of the
position WoORAM’s main area and Mp is the size of the position
WoORAM’s holding area.
Looking up a position in the Trie requires reading O(logb N)
blocks in the position WoORAM, each of which results in up to two
physical reads due to having to check for fresher data. A refresh
operation in the position WoORAM also requires a read of the
Trie to determine if fresher data for that node exists in the holding
area. If the sizes of the main area Np and holding area Mp for the
position WoORAM are not set appropriately, this could lead to
O(log2
N) reads to perform an update. However, consider that we
can control the ratio Np/Mp. If we set Mp ≫ Np logb N then we
need to perform only O(1) refreshes per position map update, thus
requiring O(log Np) reads per update.
If N is a power of b, then the number of leaf nodes in the Trie
N/b is also a power of b, and the Trie is a complete b-ary tree of
height logb(N/b). If N is not a power of b, then the last level of
the Trie is incomplete, and leaf node heights may differ by one. In
order to preserve write obliviousness, in cases of rewriting a path
with smaller height, we add one additional dummy node write.
Finally, observe that the branching factor b can play a role in
the performance. With b = 2, the size of a Trie path is minimized,
but the height and number of nodes Np are maximal. Increasing
b will reduce the height of the Trie and the number of Trie nodes,
while increasing the total size of a single path. As we will show
next, adjusting the packing of position map by setting the branching
factor b can be done carefully to achieve write communication cost
of exactly 2B in a fully sequential write pattern.
3.4 Fully Sequential Physical Write Pattern
In this section, we describe how to achieve fully sequential writing
of physical storage and how to minimize the communication cost.
This requires interleaving the various storage elements of DetWo-
ORAM such that all the writing, regardless of which part of the
construction is being written, occurs sequentially.
To understand the challenge at hand, first consider a simple
implementation which aligns the data WoORAM (main and holding
areas) adjacent to the position WoORAM (main and holding area)
forming a single storage data array broken into size-B blocks. A
write to the data WoORAM will result in a write to the holding
area plus M/N average writes to the main area. The position map
is also updated, requiring O(logb N) nodes in the Trie to be written
to the holding area and O(1) refreshes of the position WoORAM’s
main area, provided Mp ∈ Ω(Np logb N). While all these writes
occur sequentially within their respective data/position WoORAM
main/holding areas, do not occur sequentially on the underlying
storage device as each of the various WoORAM areas are separated.
Furthermore, the writes to the position map are wasteful in that
they may update only a few nodes, constituting just a small fraction
of the block, but in the uniform access model this in fact requires
updating the entire block.
We can improve on this storage layout and achieve a minimum
in write performance requiring exactly 2 blocks to be written to
Figure 4: Interleaving of WoORAMs into a Storage Array
with 2B size sequential writes.
physical storage for each block write, where one block is the new
data, a half block worth of main area refresh, and a half block worth
of position map updates. Further, we can interleave the various
WoORAM portions such that those 2 blocks are written sequentially
on the physical device.
Data WoORAM Block Interleaving. Every logical block write to
the data WoORAM results in exactly one block write to the holding
area of data WoORAM. Recall that there are two parameters for
setting up DetWoORAM: N , the size of the main area, and M, the
size of the holding area. These two values need not be the same,
and in fact, to achieve sequential writing, we will set M = 2N . In
this case, on average M
2 block is refreshed to the main area for
N
each logical write.
With adjacent main and holding areas, this could be achieved by
performing one full block refresh on every other logical write. To
make the writing sequential, we will instead refresh half of a block
on every logical write, resulting in the following storage layout:
= 1
h0,
m
m
1
j
1
m
0
□ , h2,
0
m
1
□ , h3,
0
m
0
□ , h1,
0
j
1
m
1
□ , . . . , hM−2,
is the first half of the block mj, m
0
N−1
□ , hM−1,
where m
is the back half of mj,
and □ represents empty space. (This empty space will be used to
store nodes for the position WoORAM, as we will show next.)
1
N−1
□
There is a slight complication to reading now, as a single main
area block is actually divided between two physical memory lo-
cations, resulting in an additional (constant) overhead for reading
operations. The benefit is that the writing is fully sequential now:
each logical write requires writing sequentially the data being up-
dated (to the holding area), and the next half block of data being
refreshed (to the main area), plus another half-block containing
position map information as we will detail next. Also observe that,
under this configuration with M = 2N , the total physical memory
requirement will be 4N blocks.
Position WoORAM Block Interleaving. As suggested above,
the remaining half-block of data □ in the above construction will be
used to store position map information. A diagram storage achiev-
ing 2 sequential physical block writes per logical write is shown in
Figure 4.
Specifically, these B2 bits will store the Trie nodes written to
position WoORAM holding and main areas during a single logical
write operation. This is (potentially) possible because the Trie nodes
in the position WoORAM are much smaller than the blocks in the
data WoORAM. Fully sequential writing will be achieved if and
only if all of the Trie nodes written during a single step can always
fit into B/2 bits.
There are many settings of parameters M, b, and Mp that may
make sequential writing possible, depending on logical and physical
memory requirements and the physical block size B. We will choose
some parameters here and demonstrate that they would work for
any conceivable value of N .
For this purpose, set the branching factor b = 2, and then recall
from (3.1) that the number of Trie nodes and the Trie height will
be Np = N − 2 and h = ⌈lg(N − 2)⌉, respectively.
area to be
Next, set the number of nodes in the position WoORAM holding
Mp = Np · h.
(3.2)
This ensures that only (at most) one Trie node needs to be refreshed
to the position WoORAM main area when writing an entire path of
h Trie nodes during a single logical write operation. (The number of
Trie nodes written to the holding area for each operation is always
h.) Based on these formulae, we need to have enough space in the
B/2 bits of a half block to fit h + 1 Trie nodes.
What remains is to estimate the size of each Trie node. Each
node stores b = 2 DetWoORAM pointers, each of which contains
⌈lg M⌉ bits for the holding area position, ⌈lg B⌉ bits for the block
offset, and 1 bit for the bit diff value. The condition that h + 1 Trie
nodes fit into B/2 bits then becomes
(h + 1) · (⌈lg M⌉ + ⌈lg B⌉ + 1) ≤ B
2
(3.3)
Combining this inequality with all of the previous settings for
b, M, and Mp, and assuming a block size of 4096 bytes (so B =
4096 · 8 = 215) as is the default in modern Linux kernels, we have
(⌈lg(N − 2)⌉ + 1) · (⌈lg N⌉ + 17) ≤ 214
.
That inequality is satisfied for values of N up to 6.6× 1035, which is
much more than any conceivable storage size. Further tuning of the
b and M parameters could be dome to achieve an even tighter pack-
ing and/or better read performance while maintaining 2 physical
block writes per logical write.
3.5 Encryption Modes
The deterministic and sequential access pattern fits nicely with
encryption of each block using counter mode. In particular, We
encrypt each DetWoORAM block using AES encryption based on
the number i∥064 as a counter. Recall that the client maintains
the global counter i (64-bit long). Assuming the block size B is
reasonable (shorter than 264 · 16 bytes), there will be no collision
of IVs, and the security of encryption is guaranteed. We stress
that we do not need space for storing IVs due to this optimization
which cannot be applied to previous schemes. For example, the
randomized procedures in schemes like HiVE-WoORAM, IVs must
be stored separately on the server, adding to the communication
cost overhead.
However, the physical blocks that store the position map Trie
are encrypted with AES in CBC mode. When we pack multiple Trie
nodes together, such as during interleaving or packing as described
previously, we can encrypt a group of Trie nodes together in one
shot using a single IV. Since Trie nodes are much smaller than B,
we can place that IV for that group of nodes at the beginning of the
block itself, thus avoiding an extra memory access on read or write.
We note that after packing the Trie nodes into blocks, the number
of blocks in the main DetWoORAM is significantly larger than that
in the Position-DetWoORAM, so that most of the data is encrypted
using counter mode.
4 ANALYSIS OF DETWOORAM
We formally state the security (obliviousness), and communica-
tion complexity of DetWoORAM. Fortunately, the simplicity of
the construction makes the proofs relatively straightforward in all
cases.
Security proof. First we state the security in terms of the defini-
tions in Section 2.1.
WoORAM that contain the same number of write operations.
Theorem 4.1. DetWoORAM provides write-only obliviousness.
Proof. Let (cid:174)x and (cid:174)y denote two sequences of operations in Det-
The sequence of locations of physical writes is deterministic and
does not in any way depend on the actual locations being written,
and the contents of physical writes are encrypted using an IND-CPA
symmetric cipher. Therefore ii it holds that
WOnly(PhysicalAccΠ((cid:174)x)) ≈c WOnly(PhysicalAccΠ((cid:174)y)),
because the locations in these two access patterns are identical,
and the contents in the access patterns are indistinguishable from
■
random.
Communication complexity. For the complexity analysis, as-
sume that:
trie nodes, and
• the size ratio M/N is a constant,
• the branching factor b is a constant,
• the block size B is large enough to contain a single path of
• the position map holding area is at least O(log N) times larger
N). From a practical
Asymptotically this means that B ∈ Ω(log2
standpoint, even in the extreme case of storing a yottabyte of data
(280 bytes), with holding area size M = N , branching factor b = 2,
and 4KB blocks (i.e., B = 4096), an entire path of trie nodes is still
well below the block size at 1496 bytes.
than the position map’s main area.
Theorem 4.2. Under the assumptions above, the number of physi-
cal block writes per logical block write in DetWoORAM is O(1). Fur-
thermore, the number of physical block reads per logical read or write
operation is O(log N).
Proof. Let h ∈ O(logb N) for the height of the trie that stores
the position map. A single read to DetWoORAM requires at most
two block reads and one position map lookup, which requires fetch-
ing all h nodes in the Trie path to that position. Fetching a Trie
node in the position WoORAM requires accessing the parent node
as well, requiring at most 2h nodes need to be fetched. In the worst
case every node might be packed in a different block, so this is
O(1 + h) physical block reads per logical read, which is O(logb N).
A single write to DetWoORAM requires at most 1+⌈M/N⌉ block
writes to holding and main areas and one update to the position
map Trie. Each main area refresh requires an additional block read
and position map lookup. Because M/N is a constant, this is O(1)
block writes, O(logb N) reads, and one trie update.
Updating a single node in the Trie involves first fetching the
path to that node in O(logb N) physical reads, then writing each
node on that path, updating the pointers in the parent nodes from
leaf back up to root. This requires h writes to the position map
WoORAM, which from the assumptions will require h writes to
the holding area plus O(1) refreshes in position map WoORAM’s
main area. These O(1) refreshes each require looking up O(logb N)
nodes in the position map WoORAM, for an additional reading cost
of up to O(log N) physical blocks.
All together we get O(logb N) physical reads per logical write,
and O(1) physical writes per logical write.
■
5 IMPLEMENTATION
We have implemented our DetWoORAM system, using the Trie-
based position map, in an open source C++ library available at
https://github.com/detworam/detworam. As we will show in this
section, comparison benchmarks validate our theoretical results on
the efficiency of DetWoORAM, showing it to be many times faster
than the previous scheme of HiVE-WoORAM, and only a few times
slower than a non-oblivious baseline.
Our library. The library relies on BUSE (Block device in USErspace,
https://github.com/acozzette/BUSE) to allow mounting a normal
filesystem as with any other device. We also use the mbed TLS
library (https://tls.mbed.org/) for encryption utilities. We also made
extensive use of C++ templates in our implementation, which al-
lows for considerable flexibility in choosing the parameters for the
DetWoORAM and automatically tuning the performance at compile-
time. For example, based on the size and number of backend storage
blocks, the exact byte sizes needed to store pointers, relative pro-
portion of data WoORAM to position map WoORAM, trie height,
and relative main/holding area sizes will all be seamlessly chosen
at compile time.
The implementation is exactly as described in the previous sec-
tion, with a default Trie branching factor of b = 64 unless otherwise
noted. The only exception is that we did not implement the full
interleaving, but rather the packing solution within the position
map WoORAM to pack trie nodes into single blocks. Two blocks
at a time (from the position map holding and position map main
areas) are held in memory while they are being filled sequentially,
and then are written back to disk once filled. In total, the result
is that rather than having a fully sequential access pattern as we