ulator, so we did not compare our results with VC3’s. We compared
Spark-Uranus and Opaque’s encryption mode [77], which provides
the same security guarantee as Spark-Uranus. Therefore, the com-
parison between Spark-Uranus and Opaque’s encryption mode
is apple-to-apple. Opaque uses the code-rewrite approach, among
existing SGX-based big-data systems [11, 54, 59, 77], Opaque’s en-
cryption mode [77] is the most efficient system in terms of dataset
sizes and performance overhead. Opaque also has an oblivious
mode to handle CPU architectural access pattern attacks, out of
the scope of this paper (§3.1). For SGX-Spark [11], we compiled
its code and found that it is undergoing development. We were
unable to compile SGX-Spark in our cluster due to missing code
Figure 6: Spark-Uranus performance overhead compared with native Spark and Opaque. “1” (red line) means no overhead.
Program
Total
JECALL
/JOCALL
Encryption
/Decryption
Program
Total
ECALL
/OCALL
Encryption
/Decryption
Time (s)
Filter
AdvRevenue
RevenueAggr
TreatmentJoin
PatientsQuery
GeneQuery
PageRank
LinearRegre
Table 2: Breakdown of Spark-Uranus (Opaque’s dataset).
4.28
6.02
51.1
7.57
5.32
9.87
59.8
4.13
Time (s)
0.307
0.776
4.382
0.074
0.033
0.085
2.021
0.093
Time (s)
0.01164
0.00194
0.10954
0.0037
0.00334
0.0085
0.07774
0.00194
Count
582
97
5.5k
185
167
425
3.89k
97
Time (s)
Time (s)
Time (s)
Filter
AdvRevenue
RevenueAggr
TreatmentJoin
PatientsQuery
GeneQuery
PageRank
LinearRegr
5.37
22.92
29.20
6.87
3.49
7.00
75.59
6.15
Table 3: Breakdown of Opaque (Opaque’s dataset).
3.88
12.40
16.38
3.83
2.10
4.18
42.36
3.60
23.4
58.6
85.0
73.8
39.2
176.9
185.0
33.7
Count
1.2M
4.16M
5.46M
1.27M
0.70M
1.39M
14.1M
1.2M
components (e.g., shm). Therefore, we did a qualitative analysis
between Spark-Uranus and SGX-Spark in §6.3.
For Spark-Uranus, the evaluated 7 dataset is taken from Opaque,
including 3 medical dataset and 4 big-data dataset. For all 8 queries,
Spark-Uranus was evaluated with typical sizes of dataset as in
Spark [76], two to three orders of magnitude larger than the dataset
sizes evaluated in Opaque (Table 1). For ZooKeeper-Uranus, we
used a popular benchmark ZK-Smoketest [14]. We used concurrent
connections to make the servers reach peak throughput. All data
points were the median of 11 executions. We focused on these
questions:
§6.3 What is the performance of Spark-Uranus compared to
Opaque and Spark?
§6.4 What is the performance of ZooKeeper-Uranus compared
with SecureKeeper and ZooKeeper?
§6.5 How does Uranus defend against attacks?
§6.6 What are Uranus’s limitations?
6.3 Spark-Uranus v.s. Opaque
Figure 6a shows the performance overhead of Spark-Uranus and
Opaque on Opaque’s dataset. Spark-Uranus’s performance is nor-
malized to native Spark, and Opaque’s performance is normalized
to native SparkSQL because Opaque is built on SparkSQL. Opaque’s
implementation can run a maximum 10 million records for all the
eight queries (Table 1). We looked into Opaque’s code and found
that its code restricted dataset size using assertions, and we were
unable to make Opaque work with larger dataset even the asser-
tions were removed. With the dataset size Opaque can support,
Spark-Uranus is on-average 3.7X faster than Opaque.
To analyze why Spark-Uranus is faster than Opaque, we col-
lected Uranus’s and Opaque’s runtime micro events in Table 2 and
Table 3. By comparing the number of (J)ECalls, Opaque’s ECall fre-
quency is much higher. The reason is that Opaque does ECalls for
each SparkSQL operator [77]; Spark-Uranus’s JECall wraps UDF
(e.g., map), and the call frequency of these functions is proportional
to the total number of executed Spark tasks [76]. The number of
these tasks is much small than the number of SparkSQL operators
in practice. The encryption/decryption time of these queries was
negligible except for the first three queries in Table 2, because these
queries did fewer computations than the other queries. For example,
Filter checks only if each record meets a condition provided in
UDF. Spark queries are all functional, objects did not escape across
threads in an enclave, so Uranus’s region-based GC took the fast
path (§4.4) and did not incur observable performance overhead. We
will evaluate our region-based GC in Figure 7.
Overall, Uranus enables a simple trusted and untrusted code
partition for Spark: each UDF is called by a wrapper function anno-
tated with JECall (§6.1). Opaque integrates SGX in the SparkSQL
layer (i.e., each SQL operator does one ECall), because this can
avoid rewriting the readily mature Java UDF (Spark queries) or
SparkSQL queries using C/C++. Opaque’s design choice makes its
ECall frequency much higher than Spark-Uranus’s (Table 2).
Because SGX-Spark’s code cannot compile in our cluster, we
did a qualitative study between Spark-Uranus and SGX-Spark
on both performance and security guarantees. To the best of our
knowledge, Carlos et al. [19] is the only paper that reports SGX-
Spark’s performance. This paper runs SGX-Spark Streaming on up
to 32MB medical dataset and reports a performance overhead of
FilteringAverageRevenueRevenueAggrTreatJoinPatientQueryGeneQueryPageRankLR(a) small dataset (100MB)012345678Normalized Execution TimeOpaqueSpark-UranusFilteringAverageRevenueRevenueAggrTreatJoinPatientQueryGeneQueryPageRankLR(b) large dataset01020304050Normalized Execution TimeSpark-UranusSpark-intSpark-Uranus-intFigure 7: Spark-Uranus’s sensitivity on the number of threads per-
enclave and input partition size per-thread (LinearRegr).
4X ∼ 5X over vanilla Spark. On the similar dataset size (around
100 MB), Figure 6a shows that Spark-Uranus incurs an overhead
of 1.7% ∼ 80.2%, so Spark-Uranus is much faster than SGX-Spark.
Because SGX-Spark runs an unmodified JVM in an enclave, it lacks
a protocol to verify the integrity of loaded UDF. Uranus’s new
bytecode attestation protocol (§4.1) can be integrated in SGX-Spark
to achieve the verification task. Uranus’s efficient GC (§4.4) can
also be integrated in SGX-Spark.
To compare Uranus’s interpreter and JIT compiler performance
(§4.2), we wrote a simple PI calculation program in Java and ran it in
an enclave with the perf command in Linux. Uranus’s interpreter
took 9.9s to finish, while its compiler took only 1.7s. We found that
the interpreter incurred 59M missed predicted branch instructions
in 3 billion branch instructions, while the compiler incurred 1.6M
missed predicted branches in 152M branches. Compared to the
interpreter, Uranus’s JIT is more efficient, as it greatly reduces
missed branches.
Figure 6b shows Spark-Uranus’s performance overhead on large
dataset. Spark-Uranus incurred 1.2X to 7.6X overhead compared
to native Spark on typical large dataset. Spark-Uranus incurred
the smallest overhead in RevenueAggr, as it is shuffle-intensive and
shuffle code runs outside enclaves.
Comparing Figure 6a and 6b, Spark-Uranus incurred higher
overhead when dataset was larger. A possible reason is that native
Spark’s Hotspot JIT compiler generated more optimized code when
execution time was longer, while Uranus’s JIT (§4.2) contains no IR
optimizations to maintain a small TCB. To validate this reason, we
ran Spark-Uranus completely with interpreters both within and
outside enclaves (Spark-Uranus-int), and native Spark completely
in interpreter (Spark-int), shown in Figure 6b. Spark-Uranus-int
has similar performance to Spark-int. This implies that Uranus’s
JIT is the main reason of Spark-Uranus’s performance overhead
due to the removal of IR optimizations. Spark-Uranus-int is faster
than Spark-int on some queries due to Uranus’s efficient region-
based GC (§4.4).
Figure 7a investigates the effectiveness of Uranus’s GC on
multi-threading. We ran Spark-Uranus and Spark-Uranus with
Uranus’s region-based mechanism disabled (all threads share a
global enclave heap). In native Spark, when each machine ran only
one thread to process data, Spark’s execution time was 80.0s. When
each machine ran four threads to process data concurrently, the
execution time was 49.1s, a 38% improvement. For Spark-Uranus,
when the number of thread increased from one to four, Spark-
Uranus’s execution time decreased from 628.2s to 193.0s, a 69.2%
improvement. When we disabled Spark-Uranus’s region-based
memory management in each enclave, and when the number of
Figure 8: Performance of coordination services.
threads in each enclave increased from one to four, Spark-Uranus’s
execution time decreased from 777.1s to 600.2s, a merely 22.7% im-
provement. This 22.7% improvement is worse than native Spark’s,
because enclave memory is merely about 100MB, and frequent
GCs were invoked on the enclave heap. Surprisingly, Uranus’s
region-based GC is more scalable than native Spark’s, indicating
that Uranus’s region-based memory management is suitable for
data-handling applications. Actually, Yak [55] has also confirmed a
similar scalability benefit when a GC adopts a per-thread memory
management for Spark.
Figure 7b evaluates the sensitivity of input data size for each
thread (task). This figure suggests that a 2MB partition size for
input data is suitable for running big-data queries with SGX. While
increasing this size, Uranus consumes more enclave memory, and
Uranus’s GC starts to invoke MarkSweepCompact when the en-
clave page pool has no available page (§4.4). The time taken in
Uranus’s GC grew when the size of each partition increased. Note
that enclave memory consumption includes both the partition and
its intermediate results. If EPC capacity increases in the future [56],
Spark-Uranus’s performance overhead would be further reduced.
To analyze the performance overhead of Uranus’s runtime
checks for enforcing enclave boundary (§4.3) and GC STW (§4.4),
we disabled both their checks in all Spark-Uranus queries using the
typical dataset sizes (Spark-Uranus queries do not share objects
among threads, so disabling GC STW will not affect the executions);
Uranus’s performance improved by merely at most 1.2% among
all queries. For enforcing the enclave boundary, only the trusted
bytecode accessing heap objects (e.g., putfield) requires injecting
runtime checks on the constant enclave memory bounds (§4.3), and
the trusted bytecode accessing stack variables (e.g.,aload) does not
require these checks. Uranus’s GC STW injects only checks to func-
tion entry points and back-edge of basic blocks, and these checks
observe only needGC without doing an atomic operation (§4.4).
needGC remains zero most of the time for real-world applications.
To stress test the overhead of these runtime checks, we wrote a
simple Java program, which does only getfield and putfield in
a busy loop within enclaves. This query incurred a 8.9% performance
degradation when Uranus’s runtime checks were re-enabled. In
real-world applications, the percentage of heap-access and back-
edge instructions among all trusted bytecode instructions is much
lower than the percentage in this simple query, so Uranus’s runtime
checks incur little performance overhead in real-world applications.
6.4 ZooKeeper-Uranus v.s. SecureKeeper
We ran Zk-Smoketest for ZooKeeper, ZooKeeper-Uranus and Se-
cureKeeper with a typical workload of 30% SET and 70% GET, and
make all these systems reach peak throughput. This workload is
1234Number of Thread02004006008001000Runtime (s)SparkSpark-Uranus-disable-regionSpark-Uranus50011001400180025004400Size of one Partition (KB)050100150200250300Runtime (s)Execution TimeGC Time50100150200250300350Number of client connections0123456Latency (ms)ZooKeeperZooKeeper-UranusSecurekeeper100200300Number of client connections020000400006000080000100000Throughput (req/s)ZooKeeperZooKeeper-UranusSecurekeeperevaluated in SecureKeeper’s paper. Figure 8 shows the latency and
throughput of three systems. ZooKeeper-Uranus had only 19%
performance overhead compared with ZooKeeper, which is reason-
able considering ZooKeeper-Uranus’s security guarantees. Secure-
Keeper’s performance is close to ZooKeeper-Uranus’s, because
SecureKeeper’s code is highly customized and uses little memory
in enclaves. SecureKeeper adds around 3.4k LoC C/C++ code to
ZooKeeper’s Java code base, making ZooKeeper hard to maintain.
In contrast, ZooKeeper-Uranus adds only a few JECall annota-
tions to ZooKeeper and has the same security guarantee compared
to SecureKeeper. Our evaluation (Appendix F) shows that Uranus’s
GC is efficient even when slow paths exists in an application.
6.5 Attack Analysis.
OS root privileged attacks. An attacker may try to see sensitive
data or to tamper with application logic. Uranus tackles these at-
tacks: for data confidentiality, all objects created in Uranus enclave
are stored in enclave memory; for integrity, the Uranus runtime
(§4) does not take unverified data or code from outside enclaves.
Uranus ensures the execution integrity of each JECall and its
invocation sequence.
Code and data rollbacks. An attacker may try to replace applica-
tion code with a stall, buggy version to compromise data privacy.
Uranus ensures the integrity of each code version, because clients
can verify the hash of all dependent classes and manifest (§4.1). An