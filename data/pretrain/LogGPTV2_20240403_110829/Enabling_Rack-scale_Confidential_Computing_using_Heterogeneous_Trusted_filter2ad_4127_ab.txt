a secure self-destructing chassis that is armed with a micro-
controller (MCU) system and a set of sensors (e.g., pressure,
vibration and temperature etc) for access control management
and intrusion detection/response [30]–[34], [104], [105]. As
such, the hardware adversary cannot mount a snooping attacks
on the PCIe fabric within the HETEE box. We exclude
electromagnetic and power analysis and leave them to the
future work. Like TrustZone, our approach is not completely
immune to a cold boot attack, but does provide a certain level
of protection: the cold boot attack [98]–[100] cannot succeed
when the time taken to open the sealed box illegally is longer
than that for retaining memory content after the power is
removed. Also if necessary, the HETEE chassis could include
more expensive self-destructive protection [101], [102].
Others. We use standard cryptographic techniques, and attacks
against cryptographic algorithms are out of our scope. The
ciphertext communicated between HETEE and remote users
needs to be forwarded by non-secure hosts, so denial of service
attacks are also not considered in this paper. We also trust the
FPGA synthesis tool and the mCPU ﬁrmware. We assume
that the ﬁrmware of GPU does not include malicious code
and its integrity is protected, and our design has to trust the
hardware vendor for the correctness of the ﬁrmware updates
(see Section VII).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:57:53 UTC from IEEE Xplore.  Restrictions apply. 
1452
III. HETEE ARCHITECTURE
A. Design Overview
HETEE APIs
(cid:7)(cid:131)(cid:150)(cid:131)(cid:481)(cid:3)(cid:6)(cid:145)(cid:134)(cid:135)(cid:3)(cid:481)(cid:3)(cid:16)(cid:145)(cid:134)(cid:135)(cid:142)
(cid:3)(cid:428)(cid:3)(cid:21)(cid:135)(cid:143)(cid:145)(cid:150)(cid:135)(cid:3)(cid:4)(cid:150)(cid:150)(cid:135)(cid:149)(cid:150)(cid:131)(cid:150)(cid:139)(cid:145)(cid:144)
(cid:21)(cid:135)(cid:149)(cid:151)(cid:142)(cid:150)(cid:149)
Remote Users
HETEE Box
Security 
Controller 
PCIe Fabric
Proxy
Proxy
Node 0
Node 0
Proxy
Node n
P
C
I
e
R
e
s
o
u
r
c
e
S
h
a
r
i
n
g
F
a
b
r
i
c
(cid:6)(cid:142)(cid:145)(cid:151)(cid:134)(cid:3)
(cid:137)(cid:131)(cid:150)(cid:135)(cid:153)(cid:131)(cid:155)(cid:149)
Secure 
World
Accelerators 
Data Center Network (ETH/IB)
(cid:21)(cid:131)(cid:133)(cid:141)(cid:3)(cid:882)(cid:21)(cid:131)(cid:133)(cid:141)(cid:3)(cid:883)
TOR Switch
HETEE Box
Node 1 
Node 2 
Node 3
Node 4
P
C
I
e
R
e
s
o
u
r
c
e
S
h
a
r
i
n
g
F
a
b
r
i
c
Fig. 1. HETEE Overview.
Idea and architecture. HETEE is designed to provide an
efﬁcient, practical and ﬂexible trusted execution environment
for rack-scale heterogeneous computing in clouds and data
centers, with the focus on protecting Platform as a Service
(PaaS) (Machine Learning Platform as a service (MLPaaS) [6],
[7], [109] in particular) against information leaks (to other
platform users and the platform provider). Through HETEE,
the cloud service provider can create an enclave for a user on
a proxy node, running OS and other public platform software
(e.g, Tensorﬂow), while the enclave user uploads her code
and data into the enclave to run her task on the platform (e.g.,
training a ML model). The result will only go back to the user.
This service model has been used by today’s TEE service
providers such as Microsoft Conﬁdential Computing [109].
Compared with prior work [15] [16], our approach is unique in
that it leverages existing data center technologies and resources
to achieve scalable protection, requires no chip-level change,
and strives to minimize the side-channel attack surface.
Fig. 1 illustrates the architecture of a typical data center
running HETEE. Our approach uses PCIe ExpressFabric as
a high-speed,
low-latency resource sharing network inside
the rack, connecting local computing server nodes to a pool
of heterogeneous computing units (GPUs, FPGA-based ac-
celerators, etc.). In particular, the HETEE box provides the
rack-scale resource sharing fabric built on PCIe Expressfabric
chips. While other commercial computing nodes may only
integrate traditional PCIe transparent switch chip rather than
the PCIe Expressfabric chips for I/O extensions, they can
connect to the resource sharing fabric via PCIe extension
adaptor and PCIe cable. Inside each rack, the HETEE box
manages heterogeneous units, dynamically allocating them to
computing tasks and isolating them from each other through
several modules, including Security Controller (SC), proxy
nodes, and accelerator resources with PCIe interfaces.
User support. HETEE provides a set of APIs and a library
for remote users to utilize the TEE service. Through these
toolkits, the user ﬁrstly establishes a trust relation with an
HETEE enclave (through its SC) and negotiates with it a
shared secret through a remote attestation. The subsequent
messages between the user and the box are then encrypted
and integrity-protected.
For this purpose, the APIs we provide include the typical
functions send_message and receive_message that
deliver the following three messages based on a classic re-
quest/acknowledge protocol:
• Conﬁguration messages: The remote user sends the conﬁg-
uration message to the SC to create a new HETEE enclave,
as well as the speciﬁed type and number of accelerators. The
SC will assign a unique ID to each enclave.
• Code messages: These messages are used to transfer pro-
grams to be executed to the HETEE enclave, which could be
AI models in the ONNX format [35], or CUDA code etc.
• Data messages: The messages used to deliver sensitive data.
Design challenges. Behind the support for the remote user
are a set of techniques developed to securely and dynamically
share computing resources for both secure and non-secure
computing tasks. These techniques are meant to address the
following technical challenges: (a) how to share computing
resources while providing strong isolation for HETEE enclaves
(Sec. III-B); (b) how to minimize the TCB (Sec. III-C).
For (a), HETEE utilizes the PCIe ExpressFabric to dynam-
ically and physically isolate an enclave from other enclaves
and from the untrusted OS. For (b), we adopt a unique two-
level isolation strategy in which the SC is the only trusted
node and runs a small set of ﬁrmware with integrated security
and management code, while the proxy node operates the
heavy software stack for controlling accelerators and executing
the AI runtime. This approach,
together with our use of
hardware to replace software control, helps simplify the TCB.
In the rest of the section, we present the detailed designs
of these techniques, together with the mechanism to establish
trust between the HETEE and the user.
B. Elastic Resources Allocation and Isolation
Elastic resources allocation. The PCIe ExpressFabric Switch
chip has a dedicated management port for conﬁguration, which
is used by the SC for computing unit allocation and computing
isolation. Through the chip’s driver, the SC can implement a
PCIe network conﬁguration using its APIs and/or Command
Line Instructions (CLIs). This allows deﬁnition of different
connection topologies on-demand, so as to dynamically assign
accelerators to the hosts on the same rack and separate
different computing tasks from each other. More speciﬁcally,
such elasticity in resource allocation and isolation offers the
following supports:
• Elastic allocation of pooled secure accelerators. Pooled
accelerators in the secure state can be dynamically allocated
as security resources:
the SC can assign multiple
accelerators to a dedicated proxy node that runs an enclave
by conﬁguring the PCIe fabric chip. As shown in Fig. 2 (a),
to handle a secure computing task, a server node forwards
encrypted requests and data from the user to the SC ﬁrst, which
then decrypts the messages and delivers the content to the
proxy node that controls secure accelerators. Through the
that
is,
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:57:53 UTC from IEEE Xplore.  Restrictions apply. 
1453
(cid:54)(cid:72)(cid:70)(cid:88)(cid:85)(cid:76)(cid:87)(cid:92)(cid:3)(cid:38)(cid:82)(cid:81)(cid:87)(cid:85)(cid:82)(cid:79)(cid:79)(cid:72)(cid:85)(cid:3)
(cid:11)(cid:54)(cid:38)(cid:12)
(cid:346)
(cid:536) Secure Boot
(cid:536)(cid:3)Remote Attestation
(cid:536)(cid:3)Resource Assignment & Isolation
(cid:536)(cid:3)Task De/Encryption and Scheduling
(cid:54)(cid:72)(cid:85)(cid:89)(cid:72)(cid:85)(cid:3)
(cid:49)(cid:82)(cid:71)(cid:72)
(cid:36)(cid:70)(cid:70)(cid:72)(cid:79)(cid:72)(cid:85)(cid:68)(cid:87)(cid:82)(cid:85)(cid:86)(cid:3)
(cid:54)(cid:72)(cid:70)(cid:88)(cid:85)(cid:72)(cid:18)(cid:44)(cid:81)(cid:86)(cid:72)(cid:70)(cid:88)(cid:85)(cid:72)
(cid:348)
(cid:536)(cid:3)User Code
(cid:536) Tensorflow
w
(cid:536)(cid:3)Runtime
(cid:536)(cid:3)Driver
(cid:347)
(cid:347)
(cid:51)(cid:85)(cid:82)(cid:91)(cid:92)(cid:3)
(cid:49)(cid:82)(cid:71)(cid:72)(cid:3)(cid:3)(cid:19)(cid:3)(cid:3)
(cid:51)(cid:85)(cid:82)(cid:91)(cid:92)
(cid:49)(cid:82)(cid:71)(cid:72)(cid:3)(cid:3)(cid:20)(cid:3)(cid:3)
(cid:346)(cid:3)(cid:38)(cid:76)(cid:83)(cid:75)(cid:72)(cid:85)(cid:87)(cid:72)(cid:91)(cid:87)
(cid:347)(cid:3)(cid:3)(cid:51)(cid:79)(cid:68)(cid:76)(cid:81)(cid:87)(cid:72)(cid:91)(cid:87)
(cid:348)(cid:3)(cid:3)(cid:51)(cid:79)(cid:68)(cid:76)(cid:81)(cid:87)(cid:72)(cid:91)(cid:87)
(a) Use accelerators in secure mode.
(cid:536)(cid:3)User Code 
(cid:536)(cid:3)Tensorflow
(cid:536)(cid:3)Runtime
(cid:536)(cid:3)Driver
(cid:54)(cid:72)(cid:85)(cid:89)(cid:72)(cid:85)(cid:3)
(cid:49)(cid:82)(cid:71)(cid:72)
(cid:54)(cid:72)(cid:70)(cid:88)(cid:85)(cid:76)(cid:87)(cid:92)(cid:3)(cid:38)(cid:82)(cid:81)(cid:87)(cid:85)(cid:82)(cid:79)(cid:79)(cid:72)(cid:85)(cid:3)
(cid:11)(cid:54)(cid:38)(cid:12)
(cid:536) Secure Boot
(cid:536)(cid:3)Remote Attestation
(cid:536)(cid:3)Resource Assignment & Isolation
(cid:536)(cid:3)Task De/Encryption and Scheduling
(cid:36)(cid:70)(cid:70)(cid:72)(cid:79)(cid:72)(cid:85)(cid:68)(cid:87)(cid:82)(cid:85)(cid:86)(cid:3)
(cid:54)(cid:72)(cid:70)(cid:88)(cid:85)(cid:72)(cid:18)(cid:44)(cid:81)(cid:86)(cid:72)(cid:70)(cid:88)(cid:85)(cid:72)
(cid:349)
(cid:349)(cid:3)(cid:51)(cid:79)(cid:68)(cid:76)(cid:81)(cid:87)(cid:72)(cid:91)(cid:87)
(cid:51)(cid:85)(cid:82)(cid:91)(cid:92)(cid:3)
(cid:49)(cid:82)(cid:71)(cid:72)(cid:3)(cid:3)(cid:19)(cid:3)(cid:3)
(cid:51)(cid:85)(cid:82)(cid:91)(cid:92)
(cid:49)(cid:82)(cid:71)(cid:72)(cid:3)(cid:3)(cid:20)(cid:3)(cid:3)
(b) Use accelerators in insecure mode.
Fig. 2. Elastic allocation of resources.
dynamic network conﬁguration, we can allocate accelerators
in the resource pool according to computing requirements,
achieving better resource utilization and efﬁciency. The remote
users can request accelerators for their tasks. An AI framework
can also automatically assess its workload and ask for an
appropriate amount of the accelerator resource.
• Secure mode switch across secure/insecure worlds for ac-
celerators. HETEE is also designed to support the dynamic
switch of the accelerator between secure and insecure worlds,
to share the expensive computing unit across different servers
when they work on non-sensitive computing tasks. Under the
HETEE architecture, computing units for the servers on the
same rack are all managed by the HETEE box. They are
dynamically allocated to the nodes outside the box through re-
conﬁguring the PCIe switch network, so the nodes can directly
manage and use the accelerator shown in Fig. 2 (b). When this
happens, however, the accelerator moves from a secure state
to an insecure one. So when the unit comes back to the pool
for a sensitive task, it needs to be restored to a secure state.
the mode switch of accelerators, we have
designed a priority-based preemptive accelerator scheduling
mechanism. A secure switching service needs to run on the
SC. In the meantime, local nodes (i.e., the servers on the same
rack) can ask the controller to release some of the accelera-
tor resources from the secure world through a conﬁguration
message or an out-of-band request. The switching service can
also send high-priority requests to local nodes, halting the
tasks performed by the accelerator in the insecure world and
bringing them back to the secure world.
Efﬁcient secure cleanup. When an enclave is destroyed, both
the proxy node and related computing units need to be
cleaned up to remove data and restored to the “secure” state
To support
before the establishment of a new enclave. For this purpose,
the SC initiates a cold, secure reboot on the proxy node,
which clears the context including all the data inside mem-
ory and architectural registers. Meanwhile, all accelerators
assigned to the proxy node are also powered off and reset
to get back to their original, secure states, assuming that their
ﬁrmware has not been compromised. Our experiments show
that such cold reboots can effectively remove the memory and
accessible registers’ content on the state-of-the-art GPUs like
NVIDIA TITAN X and NVIDIA Tesla M40.
The secure reboot process ensures that the proxy node
can only load the OS and accelerator software from signed
images on the SC. This has been done by modifying the
microserver’s PCB board. Speciﬁcally, we removed the Boot
ROM chip on the proxy node board and connected the SPI
interface circuit line for boot-loading to the dedicated IO pin of
the FPGA chip on the SC board. As a result, the function of the
Boot ROM chip is replaced by the module on the FPGA chip,
which veriﬁes and loads the OS and other code to the proxy
node. Also, taken over by the SC board is the Intelligent
Platform Management Interface (IPMI) physical interface on