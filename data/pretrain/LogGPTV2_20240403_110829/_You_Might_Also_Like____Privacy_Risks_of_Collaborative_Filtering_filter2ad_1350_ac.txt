function responsePairStats to collect all pairwise co-
variances between possible answers to questions on his list.
Next, he directs the target user to speciﬁc questions from his
list via links of the form http://hunch.com/people/(cid:104)username(cid:105)
/edit-answer/?qid=(cid:104)qid(cid:105) where (cid:104)username(cid:105) is replaced by the
target user’s username and (cid:104)qid(cid:105) is replaced with the ques-
tion id. The attacker must know the username, but the site
provides a social networking feature with proﬁle pages where
usernames can be linked to real names, interests, and other
personal information. We assume that the user responds to
all questions at the same time and that his responses to most
AUX questions match the attacker’s auxiliary information (our
inference algorithms are robust to some mistakes in AUX).
Our goal is to show that individual responses can be inferred
from the public outputs of recommender systems, not
to
conduct an actual attack. Therefore, we omit discussion of
mechanisms for convincing a Hunch user to respond to a set
of THAY questions. Similarly, it is a matter of opinion which
questions and answers constitute sensitive information about
an individual. For our purposes, it is sufﬁcient to show that
the attacker can infer the values of the user’s secret responses
to questions chosen by the attacker.
Data collection. Hunch does not update the covariance matrix
immediately after the user responds to the attacker-supplied
questions. At the time of our experiment, Hunch had approx-
imately 5,000 possible answers to THAY questions and thus
had to keep statistics on 12.5 million answer pairs. The update
cycle of pairwise statistics varies, but seems to be on the order
of 2-3 weeks. Each day during this period, for each known
AUX response ai, the attacker uses responsePairStats
to collect the covariances between (1) ai and all possible
answers to TARGET questions, and (2) ai and aj, where i (cid:54)= j
(i.e., cross-covariances between all AUX responses).
Algorithm 3: HUNCHINFERENCE
Input: Set Q of non-overlapping sets Rq containing all
possible answers to each TARGET question q, set of
known responses to AUX questions A,
PROPAGATEDAUX returns a subset of A,
implementation-speciﬁc parameters
thresholdsupport,score
Output: Inferred responses to TARGET questions q
inferredResponses = {}
foreach answer set Rq in Q do
maxScore = thresholdscore
maxSupport = thresholdsupport
foreach observation time τ do
propagatedτ = PROPAGATEDAUX(A, τ )
∆ = observation period beginning at τ
N∆ = delta matrix containing changes in covariances
between items in Rq ∪ A
foreach TARGET answer r in Rq do
scoreSetr = subset of a ∈ A such that
N∆[r][a] > 0
supportr = |scoreSetr ∩ propagatedτ|
scorer =
if scorer ≥ thresholdscore then
|propagatedτ |
|supportr|
if supportr > maxSupport then
inf erredResponses[q] = {r}
maxSupport = supportr
maxScore = scorer
else if supportr = maxSupport then
if scorer > maxScore then
maxScore = scorer
inf erredResponses[q] = {r}
else if scorer == maxScore then
inf erredResponses[q] =
inf erredResponses[q] ∪ {r}
return inferredResponses
The above covariances are not updated simultaneously,
which greatly complicates the attacker’s task. Hunch appears
to split THAY questions into chunks and update pairwise
answer statistics one chunk at a time. For instance, covariances
between possible answers to question 1 and question 2 may
update on Tuesday and Friday, while covariances between
answers to question 1 and question 3 update on Thursday.
The attacker must be able to detect when the covariances he
is interested in have “propagated” (see Section IV-B).
Inferring secret responses. Algorithm 3 shows the inference
procedure. Intuitively, the algorithm looks for a subset of AUX
answers whose cross-covariances have increased (indicating
that they propagated into the covariance matrix), and then
for a single answer to each of the TARGET questions whose
covariances with most of the AUX responses in the propagated
subset have increased simultaneously.
For the algorithm to work, it is essential that large chunks
of AUX responses propagate into the covariance matrix at
the same time (as is the case for Hunch). The attacker can
expect to see large positive shifts in covariance between the
user’s (known) responses to AUX questions and (unknown)
responses to TARGET questions soon after both AUX and
TARGET have propagated. The larger the number of AUX
Fig. 1. Hunch: Accuracy vs. yield for real users. Each point represents a
particular tuning of the algorithm, thresholdscore ranges from 45% to 78%,
thresholdsupport ranges between 32% and 57% of AUX size.
Fig. 2.
Hunch: Accuracy vs. yield for simulated users: average of 8
users, 4 users assigned low-activity questions, 4 users assigned high-activity
questions, thresholdscore ranges from 40% to 75%, thresholdsupport
ranges between 28% and 55% of AUX size.
questions for which this pattern is observed, the higher the
attacker’s conﬁdence that
the TARGET answer for which
covariances have increased is the user’s true response.
Results. For the experiment with real users, we used 5
volunteers and chose THAY questions with at least 4 possible
answers. Questions were ordered by sample size, and each user
was assigned 20 questions in a round-robin fashion; 15 were
randomly designated as AUX and 5 as TARGET. We requested
that users respond honestly to all questions and collected
their responses to serve as the “ground-truth oracle.” After
all responses were entered into Hunch, we collected pairwise
answer statistics via the API as described above and applied
Algorithm 3 to infer the responses to TARGET questions.
Results are shown in Fig. 1 in the form of a yield-accuracy
curve, with each point corresponding to a particular setting
of the algorithm’s parameters. We constructed a linear rela-
tion between thresholdscore and thresholdsupport parameters
which produced good results across all experiments. We use
this relation for all Hunch graphs. Parameter ranges are listed
in captions. Here yield is the fraction of unknown responses
for which the algorithm produces candidate inferences and
accuracy is the fraction of candidate inferences that are correct.
For the experiment on simulated users, we used all 375
Hunch THAY questions with at least 4 possible answers. We
monitored the number of users responding to each question
(calculated as change in sample size) for 1 week prior to
the experiment and ranked questions by activity level. The
40 questions with the lowest activity were assigned to user A,
the next 40 to user B, etc., for a total of 9 users. Due to a data
collection error, the data for one user had to be discarded.
For each user, 30 questions were randomly assigned as AUX
and 10 as TARGET. The simulated users “selected” answers
Fig. 3. Hunch: Yield vs. size of AUX for simulated users. thresholdscore
is 70%, thresholdsupport is 51.25% of AUX size.
following the actual distribution obtained from Hunch, e.g.,
if 42% of real users respond “North America” to some
question, then the simulated user selects this answer with 0.42
probability. Results are in Fig. 2. As expected, the inference
algorithm performs better on less active questions. Overall,
our algorithm achieves 78% accuracy with 100% yield.
Fig. 3 shows, for a particular setting of parameters, how
yield and accuracy vary with the size of auxiliary information.
As expected, larger AUX reduces the number of incorrect
020406080100020406080100% Yield (total inferences made)% Accuracy020406080100020406080100% Yield (total inferences made)% AccuracyllllllllllllllAllLow ActivityHigh Activity1015202530020406080100AUX Size% YieldllllllllllllllllllllllllCorrect InferencesTotal InferencesAlgorithm 4: LIBRARYTHINGINFERENCE
Input: set of “common” delta matrices NC, set of “obscure”
delta matrices NO, scoring function: R|A| → P(A), set
of AUX items A, lookup table of popularities P ,
thresholdpop for popularity of AUX books,
thresholdscore for score, window time interval in
which we expect changes to propagate
Inferred books from the target user’s library
Output:
inferences = {}
scoreSets = dict{}
foreach observation time τ do
foreach delta matrix N∆ in NC ,NO within window of τ
do
foreach target item t in N∆ do
if t /∈ scoreSets then
scoreSets[t] = {}
scoreSets[t] = scoreSets[t] ∪
SCOREFUNCTION(N∆[t],A, P, thresholdpop)
foreach target item t in keys of scoreSets do
if |scoreSets[t]| ≥ thresholdscore and t /∈ A then
inf erences = inf erences ∪ {t}
return inf erences
Algorithm 5: LTSCOREFUNCTION
Input: Delta-matrix row Tt corresponding to book t,
implemented as a dictionary keyed on AUX books and
containing the relative change in list position, set of
AUX books A, lookup table of popularities P ,
threshold for popularity of AUX book
Output: Subset of AUX books with which t increased in
correlation
scoreSet = {}
foreach a ∈ A do
if popularity P [a] ≤ threshold then
scoreSet = scoreSet ∪ {a}
if Tt[a] > 0 then
return scoreSet
When parameters are tuned for higher yield, related-items
inference produces many false positives for LibraryThing.
The reason is that many public libraries have accounts on
LibraryThing with thousands of books. Even if some book
rises in K lists related to the target user’s library, K is
rarely more than 20, and 20 books may not be enough to
identify a single user. False positives often mean that another
LibraryThing user, whose library is a superset of the target
user’s library, has added the inferred book to their collection.
C. Last.fm
Last.fm is an online music service with over 30 million
monthly users, as of March 2009 [18]. Last.fm offers cus-
tomized radio stations and also records every track that a user
listens to via the site or a local media player with a Last.fm
plugin. A user’s listening history is used to recommend music
and is public by default. Users may choose not to reveal
real-time listening data, but Last.fm automatically reveals the
number of times they listened to individual artists and tracks.
Public individual listening histories provide a “ground-truth
oracle” for this experiment, but the implications extend to
Fig. 4.
Inference vs. Bayesian prediction on simulated Hunch users.
thresholdscore is 55%, thresholdsupport is 40% of AUX size. We used
low thresholds to ensure that our algorithm reached 100% yield.
inferences, resulting in higher accuracy.
Inference vs. prediction. To illustrate the difference between
inference and prediction, we compared the performance of
our algorithm to a Bayesian predictor. Let Xi be a possible
answer to a TARGET question and Yj be the known response
to the jth AUX question. The predictor selects Xi to max-
imize P (Xi|Y1)P (Xi|Y2)··· P (Xi|Yn), where P (Xi|Yj) =
P (XiYj )
P (Yj ) = covar(Xi,Yj )+P (Xi)P (Yj )
. Individual probabilities
and covariances are available from the Hunch API. As Fig. 4
shows, our algorithm greatly outperforms the Bayesian predic-
tor, averaging 73.75% accuracy vs. 33.75% accuracy for the
predictor. This is not surprising, because our algorithm is not
making educated guesses based on what similar users have
done, it is observing the effects of actual transactions!
P (Yj )
B. LibraryThing
LibraryThing is an online recommender system for books
with over 1 million members and 55 million books in their
online “libraries” [19]. For each book, LibraryThing provides
a “People with this book also have... (more common)” list
and a “People with this book also have... (more obscure)” list.
These lists have 10 to 30 items and are updated daily.
Algorithm 4 shows our inference procedure. Here delta
matrices contain changes in “related books (common)” and
“related books (obscure)” lists. Because these lists are updated
frequently, the algorithm takes a window parameter. When
a book is added to the user’s library, we expect that, within
window, it will rise in the lists associated with the “auxiliary”
books. Algorithm 5 counts the number of such lists, provided
they are associated with less popular auxiliary books.
We used the site’s public statistics to select 3 users who
had consistently high activity, with 30-40 books added to
their collections per month. 200 random books from each
user’s collection were selected as auxiliary information. The
experiment ran for 4 months. Results are shown in Fig. 5.
0
1
2
3
4
5
6
7
8
9
10
A
B
C
D
E
G
H
I
Average
Number Correct
User
Bayesian Predictor
Inference Algorithm
ATTRIBUTES OF CANDIDATE INFERENCES. COMPUTED SEPARATELY FOR
AUX ITEMS FOR WHICH TARGET ROSE AND THOSE FOR WHICH IT FELL.
TABLE I
Attribute
numSupports
avgInitP os
avgChange
avgListeners
avgP lays
avgArtistScore
avgSimScore
avgT agScore
Deﬁnition
Number of AUX similarity lists in which
TARGET rose/fell
Average initial position of TARGET item in
supporting AUX item similarity list
Average change of TARGET item in sup-
porting AUX item similarity lists
Average number of listeners for AUX items
supporting TARGET
Average number of plays for AUX items
supporting TARGET
Average number of other AUX supports by
same artist as any given AUX support
Average sum of match scores for all other
AUX supports appearing in any given AUX
support’s updated similarity list
Average sum of cosine similarity between
normalized tag weight vectors of any given
AUX support and every other AUX support
Fig. 5. LibraryThing: Accuracy vs. yield: for all users (averaged) and for
the strongest user.
cases where individual records are private.
Aggregated data available through the Last.fm site and API
include user-to-user recommendations (“neighbors”) and item-
to-item recommendations for both artists and tracks. We focus
on track-to-track recommendations. Given a track, the API
provides an ordered list of up to 250 most similar tracks
along with “match scores,” a measure of correlation which
is normalized to yield a maximum of one in each list.
Our Last.fm experiment
is similar to our LibraryThing
experiment. Using changes in the similarity lists for a set of
known auxiliary (AUX) tracks, we infer some of the TARGET
tracks listened to by the user during a given period of time.
Unlike other tested systems, Last.fm updates all similarity
lists simultaneously on a relatively long cycle (typically, every
month). Unfortunately, our experiment coincided with changes
to Last.fm’s recommender system.4 Thus during our six-month
experiment, we observed a single update after approximately
four months. Batched updates over long periods make infer-
ence more difﬁcult, since changes caused by a single user are
dominated by those made by millions of other users.
Several features of Last.fm further complicate adversarial
inference. Last.fm tends not to publish similarity lists for
unpopular tracks, which are exactly the lists on which a single
user’s behavior would have the most impact. The number of
tracks by any given artist in a similarity list is limited to
two. Finally, similarity scores are normalized, hampering the
algorithm’s ability to compare them directly.
Setup. We chose nine Last.fm users with long histories and
public real-time listening information (to help us verify our
inferences). As auxiliary information, we used the 500 tracks
that each user had listened to most often, since this or similar
information is most likely to be available to an attacker.
Inferring tracks. After each update, we make inferences using
4Private communication with Last.fm engineer, July 2010.
the generic algorithm for related-items lists (Algorithm 1) with
one minor change: we assume that each value in N∆ also