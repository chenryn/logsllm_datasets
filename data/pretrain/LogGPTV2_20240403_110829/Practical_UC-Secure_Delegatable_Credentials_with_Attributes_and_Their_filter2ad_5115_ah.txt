281–300.
[17] Melissa Chase, Markulf Kohlweiss, Anna Lysyanskaya, and Sarah Meiklejohn.
2013. Malleable Signatures: Complex Unary Transformations and Delegatable
Anonymous Credentials. Cryptology ePrint Archive, Report 2013/179. (2013).
http://eprint.iacr.org/2013/179.
[18] Melissa Chase, Markulf Kohlweiss, Anna Lysyanskaya, and Sarah Meiklejohn.
2013. Succinct Malleable NIZKs and an Application to Compact Shuffles. In
TCC 2013 (LNCS), Amit Sahai (Ed.), Vol. 7785. Springer, Heidelberg, 100–119.
https://doi.org/10.1007/978-3-642-36594-2_6
[19] Melissa Chase, Markulf Kohlweiss, Anna Lysyanskaya, and Sarah Meikle-
john. 2014. Malleable Signatures: New Definitions and Delegatable Anony-
mous Credentials. In IEEE 27th Computer Security Foundations Symposium,
CSF 2014, Vienna, Austria, 19-22 July, 2014. IEEE Computer Society, 199–213.
https://doi.org/10.1109/CSF.2014.22
[20] Melissa Chase and Anna Lysyanskaya. 2006. On Signatures of Knowledge. In
CRYPTO 2006 (LNCS), Cynthia Dwork (Ed.), Vol. 4117. Springer, Heidelberg,
78–96.
[21] David Chaum. 1982. Blind Signatures for Untraceable Payments. In CRYPTO’82,
David Chaum, Ronald L. Rivest, and Alan T. Sherman (Eds.). Plenum Press, New
York, USA, 199–203.
[22] David Chaum, Claude Crépeau, and Ivan Damgård. 1988. Multiparty Uncondi-
tionally Secure Protocols (Extended Abstract). In 20th ACM STOC. ACM Press,
11–19.
[23] Augusto Jun Devegili, Michael Scott, and Ricardo Dahab. 2007. Implementing
Cryptographic Pairings over Barreto-Naehrig Curves (Invited Talk). In PAIRING
2007 (LNCS), Tsuyoshi Takagi, Tatsuaki Okamoto, Eiji Okamoto, and Takeshi
Okamoto (Eds.), Vol. 4575. Springer, Heidelberg, 197–207.
[24] Uriel Feige, Amos Fiat, and Adi Shamir. 1988. Zero-Knowledge Proofs of Identity.
Journal of Cryptology 1, 2 (1988), 77–94.
[25] Amos Fiat and Adi Shamir. 1987. How to Prove Yourself: Practical Solutions to
Identification and Signature Problems. In CRYPTO’86 (LNCS), Andrew M. Odlyzko
(Ed.), Vol. 263. Springer, Heidelberg, 186–194.
[26] Georg Fuchsbauer. 2011. Commuting Signatures and Verifiable Encryption.
In EUROCRYPT 2011 (LNCS), Kenneth G. Paterson (Ed.), Vol. 6632. Springer,
Heidelberg, 224–245.
[27] Georg Fuchsbauer and David Pointcheval. 2009. Formal to Practical Security.
Springer-Verlag, Berlin, Heidelberg, Chapter Anonymous Consecutive Delegation
of Signing Rights: Unifying Group and Proxy Signatures, 95–115. https://doi.
org/10.1007/978-3-642-02002-5_6
[28] Shafi Goldwasser, Silvio Micali, and Charles Rackoff. 1985. The Knowledge
Complexity of Interactive Proof-Systems (Extended Abstract). In 17th ACM STOC.
ACM Press, 291–304.
[29] Jens Groth. 2015. Efficient Fully Structure-Preserving Signatures for Large
Messages. In ASIACRYPT 2015, Part I (LNCS), Tetsu Iwata and Jung Hee
Cheon (Eds.), Vol. 9452. Springer, Heidelberg, 239–259. https://doi.org/10.1007/
978-3-662-48797-6_11
[30] Dennis Hofheinz and Victor Shoup. 2015. GNUC: A New Universal Composability
Framework. Journal of Cryptology 28, 3 (July 2015), 423–508. https://doi.org/10.
1007/s00145-013-9160-y
[31] Ralf Kuesters and Max Tuengerthal. 2013. The IITM Model: a Simple and Ex-
pressive Model for Universal Composability. Cryptology ePrint Archive, Report
2013/025. (2013). http://eprint.iacr.org/2013/025.
[32] Satoshi Nakamoto. 2008. Bitcoin: A peer-to-peer electronic cash system. (2008).
[33] Birgit Pfitzmann and Michael Waidner. 2000. Composition and Integrity Preser-
vation of Secure Reactive Systems. In ACM CCS 00, S. Jajodia and P. Samarati
(Eds.). ACM Press, 245–254.
[34] Claus-Peter Schnorr. 1990. Efficient Identification and Signatures for Smart
Cards. In CRYPTO’89 (LNCS), Gilles Brassard (Ed.), Vol. 435. Springer, Heidelberg,
239–252.
[35] Mårten Trolin and Douglas Wikström. 2005. Hierarchical Group Signatures. In
ICALP 2005 (LNCS), Luís Caires, Giuseppe F. Italiano, Luís Monteiro, Catuscia
Palamidessi, and Moti Yung (Eds.), Vol. 3580. Springer, Heidelberg, 446–458.
.
ℱ,𝒮,ℰ
≈ IDEAL
A SECURITY PROOF
We now prove Theorem 4.1. We have to prove that our scheme
realizes ℱdac, which means proving that for every adversary 𝒜,
there exists a simulator 𝒮 such that for every environment ℰ we
have EXECΠ,𝒜,ℰ
To show that no environment ℰ can distinguish the real world,
in which it is working with Πdac and adversary 𝒜, from the ideal
world, in which it uses ℱdac with simulator 𝒮, we use a sequence of
games. We start with the real world protocol execution. In the next
game we construct one entity 𝒞 that runs the real world protocol for
all honest parties. Then we split 𝒞 into two pieces, a functionality ℱ
and a simulator 𝒮, where ℱ receives all inputs from honest parties
and sends the outputs to honest parties. We start with a dummy
functionality, and gradually change ℱ and update 𝒮 accordingly,
to end up with the full ℱdac and a satisfying simulator. First we
define all intermediate functionalities and simulators, and then we
prove that they are all indistinguishable from each other.
Game 1: This is the real world.
Game 2: We let the simulator 𝒮 receive all inputs and generate all
outputs by simulating the honest parties honestly. It also simulates
the hybrid functionalities honestly. Clearly, this is equal to the real
world.
Game 3: We now start creating a functionality ℱ that receives
inputs from honest parties and generates the outputs for honest
parties. It works together with a simulator 𝒮. In this game, we
simply let ℱ forward all inputs to 𝒮, who acts as before. When
𝒮 would generate an output, it first forwards it to ℱ, who then
outputs it. This game hop simply restructures Game 2, we have
Game 3 = Game 2.
Game 4: ℱ now handles the setup queries, and lets 𝒮 enter algo-
rithms that ℱ will store. ℱ checks the structure of sid, and aborts
if it does not have the expected structure. This does not change the
view of ℰ, as ℐ in the protocol performs the same check, giving
Game 4 = Game 3.
Session C5:  Using BlockchainsCCS’17, October 30-November 3, 2017, Dallas, TX, USA697If the unforgeability check for level L credentials triggers with
non-negligible probability, there must be an attribute token at that
was valid before but is rejected by the unforgeability check of ℱ.
This means that one of the two statements must hold with non-
negligible probability:
• at proves knowledge either of a public key cpkL that belongs
to an honest user with the correct attributes, but this user
never signed m (as otherwise the unforgeability check would
not trigger)
• at proves knowledge of a public key cpkL that does not
belong to an honest user.
In the first case, we can reduce to the unforgeability-2 property
of Sib: There can only be polynomially many delegations of a level
L credential to an honest user. Pick a random one and simulate
the receiving party with the public key vk as received from the
unforgeability game of Sib. When the user delegates this credential,
use the Sign1 oracle, and when presenting the credential, use the
Sign2 oracle. Finally, when ℱ sees an attribute token at that it
considers a forgery, the soundness of NIZK allows us to extract
from the zero-knowledge proof. With non-negligible probability,
cpkL = vk, and then tag is a Sib forgery.
In the second case, we can reduce to the unforgeability-1 property
of Sib: If L = 1, simulate the issuer with ipk ← vk, where vk is
taken from the Sib unforgeability game. As isk us not known to
the simulator, we simulate πisk, and define the Present algorithm
to simulate the proof such that the issuer secret key is not needed.
ℐ uses the Sign1 oracle to delegate. If a delegation was chosen,
simulate the receiver using cpki ← vk. If L > 1, there can only be
polynomially many delegations that give an honest user a credential
of level L − 1. Pick a random one and simulate the receiving party
with cpkL−1 ← vk. Use the Sign1 oracle to delegate this credential,
and the Sign2 oracle to present this credential. Finally, when ℱ sees
an attribute token at that it considers a forgery, extract from the
zero-knowledge proof. With non-negligible probability, cpkL−1 =
vk, and then σL is a Sib forgery on message cpkL.
We provide the detailed description of the simulator on Fig. 6. ℱ
of Game 8 of equal to ℱdac, conclusing our sequence of games. (cid:3)
Game 5: ℱ now handles the verification queries using the algo-
rithm that 𝒮 defined in Game 4. In Game 4, 𝒮 defined the Ver
algorithm as the real world verification algorithm so we have Game
5 = Game 4.
Game 6: ℱ now also handles the delegation queries. If both the del-
egator and the delegatee are honest, 𝒮 does not learn the attribute
values and must simulate the real world protocol with dummy val-
ues. As all communication is over a secure channel, this difference
is not noticable by the adversary.
If the delegatee is corrupt, 𝒮 learns the attribute values 𝒮 can
simulate the real world protocol with the correct input. If the dele-
gator is corrupt and the delegatee honest, 𝒮 has to take more care:
The corrupt delegator may have received delegated credentials from
other corrupt users, without 𝒮 and ℱ knowing. If 𝒮 would make a
delegation query with ℱ on the delegator’s behalf, ℱ would reject
as it does not possess the required attributes for this delegation,
invalidating the simulation. In this case, 𝒮 first informs ℱ of the
missing delegations, such that ℱ’s records accept the delegation,
and only then calls ℱ on the delegator’s behalf for this delegation.
As 𝒮 only lacks information to simulate when both parties are
honest, but this change is not noticable due to the use of a secure
channel, Game 6 ≈ Game 5.
Game 7: ℱ now generates the attribute tokens for honest parties,
using the Present algorithm that 𝒮 defined in Game 4. First, ℱ
checks whether the party is eligible to create such an attribute
token, and aborts otherwise. This does not change ℰ’s view, as the
real world protocol performs an equivalent check. Second, ℱ tests
whether attribute token at generated with Present is valid w.r.t. Ver
before outputting at. 𝒮 defined Present to sign a valid witness for
the NIZK that at is, and Ver will verify the NIZK. By completeness
of all the sibling signature schemes Sib and completeness of NIZK,
at will be accepted by Ver. This shows that ℱ outputs an attribute
token if and only if the real world party would output an attribute
token.
Next, we must show that the generated attribute token is indis-
tinguishable between the real and ideal world. Both the real world
protocol and the Present algorithm compute
at ← NIZK(cid:8)(σ1, . . . , σL, cpk1, . . . , cpkL, ⟨a
L
1 = Sibi−1.Verify1(cpki−1, σi , cpki , a
i =1
′
i, j⟩i(cid:60)D , tag) :
′
′
i,1, . . . , a
i,ni
∧ 1 = Sib.Verify2(cpkL, tag, m)(cid:9)
)
but in the real world, a party uses his own credential every time
he proves this statement, and ℱ creates a fresh credential for every
signature. Note that the credential only concerns the witness of the
zero-knowledge proof. By the witness indistinguishability of the
zero-knowledge proofs, this change is not noticable and we have
Game 7 ≈ Game 6.
Game 8: ℱ now guarantees unforgeability of attribute tokens. We
make this change gradually, where in the first intermediate game
we guarantee unforgeability of level 1 attribute tokens, then of level
2, and so forth, and we prove that each game is indistinguishable
from the previous.
Session C5:  Using BlockchainsCCS’17, October 30-November 3, 2017, Dallas, TX, USA698i
=
Setup
Honest ℐ
• On input (SETUP, sid, ⟨ni ⟩i) from ℱ.
– Parse sid as (ℐ, sid′) and give “ℐ” input (SETUP, sid, ⟨ni ⟩i).
– When “ℐ” outputs (SETUPDONE, sid), 𝒮 takes its public key ipk and se-
cret key isk and defines Present and Ver, and the attribute spaces ⟨Ai ⟩i .
∗ Define Present(m, (cid:174)a1, . . . , (cid:174)aL) as follows: Run (cpki, cski) ←
Sigi .Gen(1κ)
←
Sig0 .Sign(isk; cpk1, (cid:174)a1) and σi ← Sigi−1 .Sign(cski−1, cpki, (cid:174)ai) for
i = 2, . . . , L. Next, compute at as in the real world protocol and
return at.
∗ Define Ver(at, m, (cid:174)a1, . . . , (cid:174)aL) as the real world verification algorithm
that verifies with respect to ipk.
∗ Define Ai as G1 for odd i and as G2 for even i.
𝒮 sends (SETUP, sid, Present, Ver, ⟨Ai ⟩i) to ℱ.
1, . . . , L. Compute σ1
for
Corrupt ℐ
• 𝒮 notices this setup as it notices ℐ registering a public key with “ℱca” with
sid = (ℐ, sid′).
– If the registered key is of the form (ipk, πisk) and πisk is valid, 𝒮 extracts
isk from πisk.
– 𝒮 defines Present, Ver and ⟨Ai ⟩ as when ℐ is honest, but now depending
on the extracted key.
– 𝒮 sends (SETUP, sid) to ℱ on behalf of ℐ.
• On input (SETUP, sid) from ℱ.
– 𝒮 sends (SETUP, sid, Present, Ver, ⟨Ai ⟩i) to ℱ.
• On input (SETUPDONE, sid) from ℱ
– 𝒮 continues simulating “ℐ”.
Delegate
Honest 𝒫, 𝒫′
• 𝒮 notices this delegation as it receives (ALLOWDEL, sid, ssid, 𝒫, 𝒫′, L)
from ℱ.
– 𝒮 picks dummy attribute values (cid:174)a1, . . . , (cid:174)aL and gives “𝒫” input
– When “𝒫′” outputs (DELEGATE, sid, ssid, (cid:174)a1, . . . , (cid:174)aL, 𝒫), output
(DELEGATE, sid, ssid, (cid:174)a1, . . . , (cid:174)aL, 𝒫′).
(ALLOWDEL, sid, ssid) to ℱ.
Honest 𝒫, corrupt 𝒫′
• 𝒮 notices this delegation as it receives (ALLOWDEL, sid, ssid, 𝒫, 𝒫′, L)
from ℱ.
– Output (ALLOWDEL, sid, ssid) to ℱ.
• 𝒮 receives (DELEGATE, sid, ssid, (cid:174)a1, . . . , (cid:174)aL, 𝒫) as 𝒫′ is corrupt.
– 𝒮 gives “𝒫” input (DELEGATE, sid, ssid, (cid:174)a1, . . . , (cid:174)aL, 𝒫′).
Honest 𝒫′, corrupt 𝒫
• 𝒮 notices this delegation as “𝒫” outputs(DELEGATE, sid, ssid, (cid:174)a1, . . . , (cid:174)aL,
𝒫).
– If L > 1 and 𝒮 has not simulated delegating attributes (cid:174)a1, . . . ,
(cid:174)aL−1
to 𝒫, and there is a corrupt party 𝒫′′ that has attributes (cid:174)a1, . . . , (cid:174)ai for
0 < i < L − 1 (note that if the root delegator ℐ is corrupt, i = 0), 𝒫′′
may have delegated (cid:174)ai, . . . , (cid:174)aL−1 to 𝒫′ without 𝒮 noticing. Therefore,
𝒮 needs to delegate attributes (cid:174)ai, . . . , (cid:174)aL−1 in the ideal world, which is
possible as 𝒫′′ is corrupt: 𝒮 sends (DELEGATE, sid, ssid, (cid:174)a1, . . . , (cid:174)ai, 𝒫′)
on 𝒫′′’s behalf to ℱ and allows the delegation, and for j = i +1, . . . , L−1,
sends (DELEGATE, sid, ssid, (cid:174)a1, . . . , (cid:174)aj, 𝒫′) on 𝒫′’s behalf to ℱ, allow-
ing every delegation. Note that 𝒫′ now possesses attributes (cid:174)a1, . . . ,
(cid:174)aL−1
in ℱ’s records.
– Send (DELEGATE, sid, ssid, (cid:174)a1, . . . , (cid:174)aL, 𝒫′) on 𝒫’s behalf to ℱ.
• On input (ALLOWDEL, sid, ssid, 𝒫, 𝒫′, L) from ℱ.
– Output (ALLOWDEL, sid, ssid) to ℱ.
Corrupt 𝒫, 𝒫’
Nothing to simulate.
Present
Nothing to simulate.
Verify
Nothing to simulate.
Figure 6: Description of the Simulator
Session C5:  Using BlockchainsCCS’17, October 30-November 3, 2017, Dallas, TX, USA699