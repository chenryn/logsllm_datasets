### References

1. Melissa Chase, Markulf Kohlweiss, Anna Lysyanskaya, and Sarah Meiklejohn. 2013. Malleable Signatures: Complex Unary Transformations and Delegatable Anonymous Credentials. *Cryptology ePrint Archive*, Report 2013/179. [Link](http://eprint.iacr.org/2013/179).

2. Melissa Chase, Markulf Kohlweiss, Anna Lysyanskaya, and Sarah Meiklejohn. 2013. Succinct Malleable NIZKs and an Application to Compact Shuffles. In *TCC 2013* (LNCS), Vol. 7785, edited by Amit Sahai. Springer, Heidelberg, pp. 100–119. [DOI](https://doi.org/10.1007/978-3-642-36594-2_6).

3. Melissa Chase, Markulf Kohlweiss, Anna Lysyanskaya, and Sarah Meiklejohn. 2014. Malleable Signatures: New Definitions and Delegatable Anonymous Credentials. In *IEEE 27th Computer Security Foundations Symposium (CSF 2014)*, Vienna, Austria, July 19-22, 2014. IEEE Computer Society, pp. 199–213. [DOI](https://doi.org/10.1109/CSF.2014.22).

4. Melissa Chase and Anna Lysyanskaya. 2006. On Signatures of Knowledge. In *CRYPTO 2006* (LNCS), Vol. 4117, edited by Cynthia Dwork. Springer, Heidelberg, pp. 78–96.

5. David Chaum. 1982. Blind Signatures for Untraceable Payments. In *CRYPTO'82*, edited by David Chaum, Ronald L. Rivest, and Alan T. Sherman. Plenum Press, New York, USA, pp. 199–203.

6. David Chaum, Claude Crépeau, and Ivan Damgård. 1988. Multiparty Unconditionally Secure Protocols (Extended Abstract). In *20th ACM STOC*. ACM Press, pp. 11–19.

7. Augusto Jun Devegili, Michael Scott, and Ricardo Dahab. 2007. Implementing Cryptographic Pairings over Barreto-Naehrig Curves (Invited Talk). In *PAIRING 2007* (LNCS), Vol. 4575, edited by Tsuyoshi Takagi, Tatsuaki Okamoto, Eiji Okamoto, and Takeshi Okamoto. Springer, Heidelberg, pp. 197–207.

8. Uriel Feige, Amos Fiat, and Adi Shamir. 1988. Zero-Knowledge Proofs of Identity. *Journal of Cryptology* 1(2), pp. 77–94.

9. Amos Fiat and Adi Shamir. 1987. How to Prove Yourself: Practical Solutions to Identification and Signature Problems. In *CRYPTO'86* (LNCS), Vol. 263, edited by Andrew M. Odlyzko. Springer, Heidelberg, pp. 186–194.

10. Georg Fuchsbauer. 2011. Commuting Signatures and Verifiable Encryption. In *EUROCRYPT 2011* (LNCS), Vol. 6632, edited by Kenneth G. Paterson. Springer, Heidelberg, pp. 224–245.

11. Georg Fuchsbauer and David Pointcheval. 2009. Formal to Practical Security. In *Springer-Verlag, Berlin, Heidelberg*, Chapter: Anonymous Consecutive Delegation of Signing Rights: Unifying Group and Proxy Signatures, pp. 95–115. [DOI](https://doi.org/10.1007/978-3-642-02002-5_6).

12. Shafi Goldwasser, Silvio Micali, and Charles Rackoff. 1985. The Knowledge Complexity of Interactive Proof-Systems (Extended Abstract). In *17th ACM STOC*. ACM Press, pp. 291–304.

13. Jens Groth. 2015. Efficient Fully Structure-Preserving Signatures for Large Messages. In *ASIACRYPT 2015, Part I* (LNCS), Vol. 9452, edited by Tetsu Iwata and Jung Hee Cheon. Springer, Heidelberg, pp. 239–259. [DOI](https://doi.org/10.1007/978-3-662-48797-6_11).

14. Dennis Hofheinz and Victor Shoup. 2015. GNUC: A New Universal Composability Framework. *Journal of Cryptology* 28(3), pp. 423–508. [DOI](https://doi.org/10.1007/s00145-013-9160-y).

15. Ralf Kuesters and Max Tuengerthal. 2013. The IITM Model: A Simple and Expressive Model for Universal Composability. *Cryptology ePrint Archive*, Report 2013/025. [Link](http://eprint.iacr.org/2013/025).

16. Satoshi Nakamoto. 2008. Bitcoin: A Peer-to-Peer Electronic Cash System. [Link](http://www.bitcoin.org/bitcoin.pdf).

17. Birgit Pfitzmann and Michael Waidner. 2000. Composition and Integrity Preservation of Secure Reactive Systems. In *ACM CCS 2000*, edited by S. Jajodia and P. Samarati. ACM Press, pp. 245–254.

18. Claus-Peter Schnorr. 1990. Efficient Identification and Signatures for Smart Cards. In *CRYPTO'89* (LNCS), Vol. 435, edited by Gilles Brassard. Springer, Heidelberg, pp. 239–252.

19. Mårten Trolin and Douglas Wikström. 2005. Hierarchical Group Signatures. In *ICALP 2005* (LNCS), Vol. 3580, edited by Luís Caires, Giuseppe F. Italiano, Luís Monteiro, Catuscia Palamidessi, and Moti Yung. Springer, Heidelberg, pp. 446–458.

### Security Proof

We now prove Theorem 4.1, which states that our scheme realizes the ideal functionality \(\mathcal{F}_{\text{dac}}\). Specifically, we need to show that for every adversary \(\mathcal{A}\), there exists a simulator \(\mathcal{S}\) such that for every environment \(\mathcal{E}\), the following holds:

\[
\text{EXEC}_{\Pi, \mathcal{A}, \mathcal{E}} \approx \text{IDEAL}_{\mathcal{F}_{\text{dac}}, \mathcal{S}, \mathcal{E}}
\]

To demonstrate this, we use a sequence of games. We start with the real-world protocol execution and gradually transform it into the ideal world, ensuring that each step is indistinguishable from the previous one.

**Game 1: Real World**
- This is the real-world protocol execution.

**Game 2: Simulator Receives Inputs and Generates Outputs**
- The simulator \(\mathcal{S}\) receives all inputs and generates all outputs by simulating the honest parties and hybrid functionalities honestly. This game is equivalent to the real world.

**Game 3: Functionality \(\mathcal{F}\) and Simulator \(\mathcal{S}\)**
- We introduce a functionality \(\mathcal{F}\) that receives inputs from honest parties and generates outputs for them. \(\mathcal{F}\) works together with \(\mathcal{S}\). In this game, \(\mathcal{F}\) simply forwards all inputs to \(\mathcal{S}\), who acts as before. When \(\mathcal{S}\) generates an output, it first forwards it to \(\mathcal{F}\), who then outputs it. This game is structurally identical to Game 2.

**Game 4: Handling Setup Queries**
- \(\mathcal{F}\) now handles setup queries and lets \(\mathcal{S}\) enter algorithms that \(\mathcal{F}\) will store. \(\mathcal{F}\) checks the structure of \(\text{sid}\) and aborts if it does not have the expected structure. This does not change the view of \(\mathcal{E}\), as the protocol performs the same check. Thus, Game 4 is equivalent to Game 3.

**Game 5: Verification Queries**
- \(\mathcal{F}\) now handles verification queries using the algorithm defined by \(\mathcal{S}\) in Game 4. Since \(\mathcal{S}\) defined the verification algorithm as the real-world verification algorithm, Game 5 is equivalent to Game 4.

**Game 6: Delegation Queries**
- \(\mathcal{F}\) now also handles delegation queries. If both the delegator and delegatee are honest, \(\mathcal{S}\) simulates the real-world protocol with dummy values. If the delegatee is corrupt, \(\mathcal{S}\) can simulate with the correct input. If the delegator is corrupt and the delegatee is honest, \(\mathcal{S}\) informs \(\mathcal{F}\) of missing delegations to ensure \(\mathcal{F}\) accepts the delegation. This change is not noticeable due to the secure channel, so Game 6 is indistinguishable from Game 5.

**Game 7: Generating Attribute Tokens**
- \(\mathcal{F}\) now generates attribute tokens for honest parties using the Present algorithm defined by \(\mathcal{S}\) in Game 4. \(\mathcal{F}\) checks whether the party is eligible to create the attribute token and aborts otherwise. It also tests whether the generated attribute token is valid. By the completeness of the sibling signature schemes and NIZK, \(\mathcal{F}\) outputs an attribute token if and only if the real-world party would. The generated attribute token is indistinguishable between the real and ideal worlds due to the witness indistinguishability of the zero-knowledge proofs. Thus, Game 7 is indistinguishable from Game 6.

**Game 8: Unforgeability of Attribute Tokens**
- \(\mathcal{F}\) now guarantees unforgeability of attribute tokens. We make this change gradually, starting with level 1 attribute tokens and then higher levels, proving that each game is indistinguishable from the previous one. Finally, \(\mathcal{F}\) in Game 8 is equal to \(\mathcal{F}_{\text{dac}}\).

### Detailed Description of the Simulator

The detailed description of the simulator \(\mathcal{S}\) is provided in Figure 6. The steps include handling setup, delegation, and present operations, ensuring that the simulation is indistinguishable from the real-world protocol.

**Setup:**
- **Honest \(\mathcal{I}\):** On receiving a setup request, \(\mathcal{S}\) parses \(\text{sid}\) and gives the input to \(\mathcal{I}\). \(\mathcal{S}\) takes the public key \(\text{ipk}\) and secret key \(\text{isk}\) and defines the Present and Ver algorithms and attribute spaces.
- **Corrupt \(\mathcal{I}\):** \(\mathcal{S}\) notices the setup and extracts \(\text{isk}\) from \(\pi_{\text{isk}}\) if valid. \(\mathcal{S}\) then defines Present, Ver, and attribute spaces based on the extracted key.

**Delegate:**
- **Honest \(\mathcal{P}\) and \(\mathcal{P}'\):** \(\mathcal{S}\) picks dummy attribute values and simulates the delegation.
- **Honest \(\mathcal{P}\) and corrupt \(\mathcal{P}'\):** \(\mathcal{S}\) simulates the delegation with the correct input.
- **Honest \(\mathcal{P}'\) and corrupt \(\mathcal{P}\):** \(\mathcal{S}\) ensures that \(\mathcal{F}\) accepts the delegation by informing \(\mathcal{F}\) of missing delegations.
- **Corrupt \(\mathcal{P}\) and \(\mathcal{P}'\):** No simulation is needed.

**Present and Verify:**
- No specific simulation is required for these operations.

This completes the proof that our scheme realizes \(\mathcal{F}_{\text{dac}}\).