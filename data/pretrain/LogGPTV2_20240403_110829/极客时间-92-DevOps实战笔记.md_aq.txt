# 10 \| 配置管理：最容易被忽视的DevOps工程实践基础你好，我是石雪峰。从今天开始，专栏正式进入了工程实践的部分。在 DevOps的体系中，工程实践所占的比重非常大，而且和我们的日常工作息息相关。正因为如此，DevOps包含了大量的工程实践，很多我们都耳熟能详，比如持续集成、自动化测试、自动化部署等等，这些基本上是实践DevOps 的必选项。可是，还有一些实践常常被人们所忽视，但这并不代表它们已经被淘汰或者是不那么重要了。恰恰相反，它们同样是DevOps 能够发挥价值的根基，配置管理（ConfigurationManagement）就是其中之一。它的理念在软件开发过程中无处不在，可以说是整个DevOps工程实践的基础。所以今天我们就来聊一聊配置管理。说了这么多，那软件配置管理到底是个啥呢？熟悉运维的同学可能会说，不就是类似 Ansible、Saltstack的环境配置管理工具吗？还有人会说，CMDB配置管理数据库也是配置管理吧？这些说法都没错。配置管理这个概念在软件开发领域应用得非常普遍，几乎可以说无处不在，但是刚刚提到的这些概念，都是细分领域内的局部定义。我今天要讲到的配置管理，是一个宏观的概念，是站在软件交付全生命周期的视角，对整个开发过程进行规范管理，控制变更过程，让协作更加顺畅，确保整个交付过程的完整、一致和可追溯。看到这里，我估计你可能已经晕掉了。的确，配置管理的理论体系非常庞大。但是没关系，你只需要把四个核心理念记在心中就足够了。这四个理念分别是：**版本变更标准化，将一切纳入版本控制，全流程可追溯和单一可信数据源**。1. 版本变更标准化**版本控制是配置管理中的一个非常核心的概念，而对于软件来说，最核心的资产就是源代码**。现在很多公司都在使用类似 Git、SVN之类的工具管理源代码，这些工具其实都是版本控制系统。版本描述了软件交付产物的状态，可以说，从第一行软件代码写下开始，版本就已经存在了。现代软件开发越来越复杂，往往需要多人协作，所以，如何管理每个开发者的版本，并把它们有效地集成到一起，就成了一个难题。实际上，版本控制系统就是为了解决这个问题的。试想一下，如果没有这么一套系统的话，所有代码都在本地，不要说其他人了，就连自己都会搞不清楚哪个是最新代码。那么，当所有人的代码集成到一起的时候，那该是多么混乱啊！不仅如此，如果线上发生了严重问题，也找不到对应的历史版本，只能直接把最新的代码发布上去，简直就是灾难。**配置管理中的另一个核心概念是变更**。我们对软件做的任何改变都可以称之为一次变更，比如一个需求，一行代码，甚至是一个环境配置。**版本来源于变更**。对于变更而言，核心就是要记录：**谁，在什么时间，做了什么改动，具体改了哪些内容，又是谁批准的**。这样看来，好像也没什么复杂的，因为现代版本控制系统基本都具备记录变更的功能。那么，是不是只要使用了版本控制系统，就做到变更管理了呢？的确，版本控制系统的出现，大大简化了管理变更的成本，至少是不用人工记录了。但是，从另一方面来看，用好版本控制系统也需要有一套规则和行为规范。比如，版本控制系统需要打通公司的统一认证系统，也就是任何人想要访问版本控制系统，都需要经过公司统一登录的认证。同时，在使用Git的时候，你需要正确配置本地信息，尤其是用户名和邮箱信息，这样才能在提交时生成完整的用户信息。另外，系统本身也需要增加相关的校验机制，避免由于员工配置错误导致无效信息被提交入库。改动说明一般就是版本控制系统的提交记录，一个完整的提交记录应该至少包括以下几个方面的内容：1.  **提交概要信息**        ：简明扼要地用一句话说明这个改动实现了哪些功能，修复了哪些问题；        2.  **提交详细信息**        ：详细说明改动的细节和改动方式，是否有潜在的风险和遗留问题等；        3.  **提交关联需求**        ：是哪次变更导致的这次提交修改，还需要添加上游系统编号以关联提交和原始变更。        这些改动应该遵循一种标准化的格式，并且有相关的格式说明和书写方式，比如有哪些关键字，每一行的长度，变更编号的区隔是使用逗号、空格还是分号等等。如果按照这个标准来书写每次的变更记录，其实成本还是很高的，更不要说使用英文来书写的话，英文的表达方式和内容展现形式又是一个难题。我跟你分享一个极品的提交注释，你可以参考一下。>  > switch to Flask-XML-RPC> dependency> > >>>  > CR: PBX-2222> > >>>  > The Flask-XML-RPC-Re fork has Python 3 support, but it has a> couple> >>>  > other problems.> > >>>  > 1.   >>>>     test suite does not>     pass>     >>> 2.   >>>>     latest code is not>     tagged>     >     >>> 3.   >>>>     uncompiled source code is not distributed via>     PyPI>     >>>>  > The Flask-XML-RPC module is essentially dead upstream, but it> is> >>>  > packaged in EPEL 7 and Fedora. This module will get us far enough> to> >>>  > the> >>>  > point that we can complete phase one for this> project.> >>>  > When we care about Python 3, we can drop XML-RPC entirely and get> the> >>>  > service consumers to switch to a REST API> instead.> >>>  > (Note, with this change, the Travis CI tests will fail for Python> 3.> >>>  > The> >>>  > solution is to drop XML-RPC> support.)> >这时，肯定有人会问，花这么大力气做这个事情，会不会有点得不偿失呢？从局部来看，的确如此。但是，换个角度想，当其他人看到你的改动，或者是评审你的代码的时候，如果通过提交记录就能清晰地了解你的意图，而不是一脸蒙地把你叫过来，让你再讲一遍，这样节约的时间比当时你书写提交记录的时间要多得多。**所以你看，一套标准化的规则和行为习惯，可以降低协作过程中的沟通成本，一次性把事情做对，这也是标准和规范的重要意义**。当然，如果标准化流程要完全依靠人的自觉性来保障，那就太不靠谱了。毕竟，人总是容易犯错的，会影响到标准的执行效果。所以，当团队内部经过不断磨合，逐步形成一套规范之后，最好还是用自动化的手段保障流程的标准化。这样做的好处有两点：一方面，可以降低人为因素的影响，如果你不按标准来，就会寸步难行，也减少了人为钻空子的可能性。比如，有时候因为懒，每次提交都写同样一个需求变更号，这样的确满足了标准化的要求，但是却产生了大量无效数据。这时候，你就可以适当增加一些校验机制，比如只允许添加你名下的变更，或者是只允许开放状态的变更号等等。另一方面，在标准化之后，很多重复性的工作就可以自动化完成，标准化的信息也方便计算机分析提取，这样就可以提升流程的流转效率。**可以说，标准化是自动化的前提，自动化又是 DevOps最核心的实践**。这样看来，说配置管理是 DevOps工程实践的基础就一点不为过了吧。2. 将一切纳入版本控制如果说，今天这一讲的内容，你只需要记住一句话，那就是将一切纳入版本控制，这是配置管理的金科玉律。你可能会问，需要将什么样的内容纳入版本控制呢？我会毫不犹豫地回答你："一切都需要！"比如软件源代码、配置文件、测试编译脚本、流水线配置、环境配置、数据库变更等等，你能想到的一切，皆有版本，皆要被纳入管控。这是因为，软件本身就是一个复杂的集合体，任何变更都可能带来问题，所以，全程版本控制赋予了我们全流程追溯的能力，并且可以快速回退到某个时间点的版本状态，这对于定位和修复问题是非常重要的。之前，我就遇到过一个问题。一个 iOS应用发灰度版本的时候一切正常，但是正式版本就遇到了无法下载的情况。当时因为临近上线，为了查这个问题，可以说是全员上阵，团队甚至开始互相抱怨，研发说代码没有变化，所以是运维的问题；运维说环境没动过，所以是研发的问题。结果到最后才发现，这是由于一个工具版本升级，某个参数的默认值从"关闭"变成了"打开"导致的。所以你看，如果对所有内容都纳入版本控制，快速对比两个版本，列出差异点，那么，解决这种问题也就是分分钟的事情，大不了就把所有改动都还原回去。纳入版本控制的价值不止如此。实际上，很多 DevOps实践都是基于版本控制来实现的，比如，环境管理方面推荐采用基础设施即代码的方式管理环境，也就是说把用代码化的方式描述复杂的环境配置，同时把它纳入版本控制系统中。这样一来，任何环境变更都可以像提交代码一样来完成，不仅变更的内容一目了然，还可以很轻松地实现自动化。**把原本复杂的事情简单化，每一个人都可以完成环境变更**。这样一来，开发和运维之间的鸿沟就被逐渐抹平了，DevOps的真谛也是如此。所以，现在行业内流行的"什么什么即代码"，其背后的核心都是版本控制。不过，这里我需要澄清一下，纳入版本控制并不等同于把所有内容都放到 Git中管理。有些时候，我们很容易把能力和工具混为一谈。Git只是一种流行的版本控制系统而已，而这里强调的其实是一种能力，工具只是能力的载体。比如，Git本身不擅长管理大文件，那么可以把这些大文件放到 Artifactory或者其他自建平台上进行管理。对自建系统来说，实现版本控制的方式有很多种，比如，可以针对每次变更，插入一组新的数据，或者直接复用Git这种比较成熟的工具作为后台。唯一不变的要求就是，无论使用什么样的系统和工具，都需要把版本控制的能力考虑进去。另外，在实践将一切纳入版本控制的时候，你可以参考一条小原则。如果你不确定是否需要纳入版本控制，有一个简单的判断方法就是：**如果这个产物可以通过其他产物来重现，那么就可以作为制品管理，而无需纳入版本控制**。举个例子，软件包可以通过源代码和工具重新打包生成，那么，代码、工具和打包环境就需要纳入管控，而生成的软件包可以作为制品；软件的测试报告如果可以通过测试管理平台重新自动化生成，那么同样可以将其视为制品，但前提是，测试管理平台可以针对每一个版本重新生成测试报告。3. 全流程可追溯对传统行业来说，全流程可追溯的能力从来不是可选项，而是必选项。像航空航天、企业制造、金融行业等，对变更的管控都是非常严谨的，一旦出现问题，就要追溯当时的全部数据，像软件源代码、测试报告、运行环境等等。如果由于缺乏管理，难以提供证据证明基于当时的客观情况已经做了充分的验证，就会面临巨额的罚款和赔偿，这可不是闹着玩的事情。像最近流行的区块链技术，除了发币以外，最典型的场景也是全流程可追溯。所以说，**技术可以日新月异，但很多理念都是长久不变的**。**对于配置管理来说，除了追溯能力以外，还有一个重要的价值，就是记录关联和依赖关系**。怎么理解这句话呢？我先提个问题，在你的公司里面，针对任意一个需求，你们是否能够快速识别出它所关联的代码、版本、测试案例、上线记录、缺陷信息、用户反馈信息和上线监控数据呢？对于任意一个应用，是否可以识别出它所依赖的环境，中间件，上下游存在调用关系的系统、服务和数据呢？如果你的回答是"yes"，那么恭喜你，你们公司做得非常好。不过，绝大多数公司都是无法做到这一点的。因为这不仅需要系统与系统之间的关联打通、数据联动，也涉及到一整套完整的管理机制。DevOps非常强调价值导向，强调团队内部共享目标，这个目标其实就是业务目标。但实际情况是，业务所关注的维度，和开发、测试、运维所关注的维度都各不相同。业务关心的是提出的需求有没有上线，而开发关心的是这个需求的代码有没有集成，运维关心的是包含这个代码的版本是否上线。所以，如果不能把这些信息串联打通，就没有真正做到全流程可追溯。关于这个问题，我给你的建议是**把握源头，建立主线**。所谓源头，对于软件开发而言，最原始的就是需求，**所有的变更都来源于需求**。所以，首先要统一管理需求，无论是开发需求、测试需求还是运维需求。接下来，要以需求作为抓手，去关联下游环节，打通数据，这需要系统能力的支持，也需要规则的支持。比如，每次变更都要强制关联需求编号，针对不同的需求等级定义差异化流程，这样既可以减少无意义的审批环节，给予团队一定的灵活性，也达到了全流程管控的目标。这是一个比较漫长的过程，但不积跬步，无以至千里，DevOps也需要一步一个脚印地建设才行。4. 单一可信数据源最后，我想单独谈谈单一可信数据源。很多人不理解这是什么东西，我举个例子你就明白了。有一个网络热词叫作"官宣"，也就是官方宣布的意思。一般情况下，官宣的信息都是板上钉钉的，可信度非常高。可问题是，如果有多个官宣的渠道，信息还都不一样，你怎么知道要相信哪一个呢？这就是单一可信数据源的意义。试想一下，我们花了很大力气来建设版本控制的能力，但如果数据源本身不可靠，缺乏统一管控，那岂不是白忙一场吗？所以，对于软件开发来说，必须要有统一的管控：1.  对于代码来说，要有统一的版本控制系统，不能代码满天飞；        2.  对于版本来说，要有统一的渠道，不能让人随便本地打个包就传到线上去了；        3.  对于开发依赖的组件来说，要有统一的源头，不能让来路不明的组件直接集成到系统中。这不仅对于安全管控来说至关重要，对于企业内部的信息一致性也是不可或缺的。        **同时，单一可信数据源也要能覆盖企业内部元数据的管控**。比如，企业内部经常出现这种情况，同样是应用，在 A部门的系统中叫作 123，在 B 部门的系统中叫作ABC，在打通两边平台的时候，这就相当于"鸡同鸭讲"，完全对不上。再比如，信息安全团队维护了一套应用列表，但实际上，在业务系统中，很多应用都已经下线且不再维护了，这样一来，不仅会造成资源浪费，还伴随着非常大的安全风险。很多时候，类似的这些问题都是因为缺乏统一的顶层规划和设计导致的，这一点，在建立配置管理能力的时候请你格外关注一下。总结今天我给你介绍了 DevOps工程实践的基础配置管理，以及配置管理的四大理念，分别是版本变更标准化、将一切纳入版本控制、全流程可追溯和单一可信数据源，希望能帮你掌握配置管理的全局概念。虽然配置管理看起来并不起眼，但是就像那句经典的话一样："岁月静好，是因为有人替你负重前行。"对于任何一家企业来说，信息过载都是常态，而**配置管理的最大价值正是将信息序列化**，对信息进行有效的整理、归类、记录和关联。而软件开发标准和有序，也是协同效率提升的源头，所以，配置管理的重要性再怎么强调都不为过。思考题你在企业中遇到过哪些配置管理方面的难题呢？你们的配置管理体系又是如何建立的呢？你遇到过因为缺乏单一可信数据源而导致"鸡同鸭讲"的有趣故事吗？欢迎在留言区写下你的思考和答案，我们一起讨论，共同学习进步。如果你觉得这篇文章对你有所帮助，欢迎你把文章分享给你的朋友。![](Images/94ddfb3c31810c68bfd0097449ef5eeb.png)savepage-src="https://static001.geekbang.org/resource/image/7c/33/7c26a9b917677371cf3aac78d949ae33.jpg"}
# 11 \| 分支策略：让研发高效协作的关键要素你好，我是石雪峰。今天我们来聊聊分支策略。 在上一讲中，我反复强调过一个理念，那就是将一切纳入版本控制。其实，现代版本控制系统不仅可以记录版本和变更记录，还有一个非常重要的功能，那就是**分支管理**。 现代软件开发讲究效率和质量，大多依赖于多团队间的协作来实现。对于一些大型软件来说，即便是百人团队规模的协作也没什么奇怪的。如果软件架构没有良好的拆分，很有可能出现几百人在一个代码仓库里面工作的情况。这时，分支管理就成了不可或缺的功能。 一方面，分支可以隔离不同开发人员的改动，给他们提供一个相对独立的空间，让他们能够完成自己的开发任务。另一方面，整个团队也需要根据软件的发布节奏来完成代码提交、审核、集成、测试等工作。 所以，如果说多人软件协作项目中有一个灵魂的话，我认为，这个灵魂就是分支策略。可以说，**分支策略就是软件协作模式和发布模式的风向标**。选择一种符合 DevOps 开发模式的分支策略，对于 DevOps的实践落地也会大有帮助。 今天，我会给你拆解一些常见的分支策略，帮你了解这些策略的核心流程、优缺点，以及适用的场景和案例。 主干开发，分支发布![](Images/ac085331398cc8c648cf7f661824ae34.png)savepage-src="https://static001.geekbang.org/resource/image/71/85/717a85f005b8da0b593d6376db679685.png"}>  > [图片来源：> > > >>>  > [https://paulhammant.com/2013/12/04/what_is_your_branching_model/> > > >在这种分支策略下，开发团队共享一条主干分支，所有的代码都直接提交到主干分支上，主干分支就相当于是一个代码的全量合集。**在软件版本发布之前，会基于主干拉出一条以发布为目的的短分支**。 你需要注意一下这句话里的两个关键词： 1.       **以发布为目的**        。这条分支存在的意义不是开发新功能，而是对现有功能进行验收，并在达到一定的质量标准后对外发布。一般来说，新功能不会基于这条分支提交，只有一些    Bugfix    会集成进来。所以，对于这种发布分支会有比较严格的权限管控。毕竟，谁都不想让那些乱七八糟、未经验证的功能跑到发布分支上来。        2.       **短分支**        。这条发布分支一般不会存在太长时间，只要经过回归验证，满足发布标准后，就可以直接对外发布，这时，这条分支的历史使命也就结束了。除非上线之后发现一些紧急问题需要修复，才会继续在这条分支上修改验证，并将改动同步回主干分支。所以，只要在主干分支和发布分支并行存在的时间段内，所有发布分支上的改动都需要同步回主分支，这也是我们不希望这条分支存在时间过长的原因，因为这会导致重复工作量的线性累计。        对于以版本节奏驱动的软件项目来说，这种分支策略非常常见，比如客户端产品，或者是那种需要在客户终端升级的智能硬件产品，像智能手机、智能电视等。 早在很多年前，乐视刚刚推出超级电视的时候，喊过一个口号叫"周周更新"。要知道，当时智能电视产品的更新频率普遍是几个月一次。 其实，如果你了解分支策略的话，你就会发现，"周周更新"的背后也没什么特别的。当时，我所在的团队恰好负责智能电视产品线的分支策略，采用的就是主干开发、分支发布的模式。其中基于主干的发布分支提前两周拉出，然后在发布分支上进行回归验证，并在第一周发出体验版本给喜欢尝鲜的用户试用。然后，根据用户反馈和后台收集的问题进行进一步修正，并最终发布一个稳定版本。我把当时的分支策略图分享给你，你可以参考一下。 ![](Images/b0c7717c78ec7127967eeb86d678920e.png)savepage-src="https://static001.geekbang.org/resource/image/e0/46/e05c3b28341b3c99cceb3b916f5e7046.jpg"}这种模式的优势有三个： 1.       对于研发团队来说，只有一条主线分支，不需要在多条分支间切换。        2.       在发布分支拉出之后，主干分支依然处于可集成状态，研发节奏可以保持在一个相对平稳的状态。        3.       发布分支一般以版本号命名，清晰易懂，线上哪个版本出了问题，就在哪个分支上修复。        不过，这种模式也存在着缺点和挑战： 1.       **它对主线分支的质量要求很高**        。如果主线分支出了问题，就会 block    所有开发团队的工作。对于一个百人团队、每日千次的提交规模来说，如果不对提交加以约束，这种情况的发生频率就会非常高。        2.       **它对团队协作的节奏要求很高**        。如果主线分支上的功能没有及时合入，但是业务方又坚持要在指定版本上线这个功能，这就会导致发布分支"难产"。甚至有些时候，会被迫允许部分未开发完成的功能在发布分支上继续开发，这会给发布分支的质量和稳定性造成很大的挑战。        3.       **在主线和发布分支并存期间，有可能会导致两边提交不同步的情况**        。比如，发布分支修复了一个线上问题，但是由于没有同步回主线，导致同样的问题在下一个版本中复现。测试出来的问题越多，这种情况出现的概率就越大，更不要说多版本并存的情况了。        这些问题的解决方法包括以下几点： 1.       建立提交的准入门禁，不允许不符合质量标准的代码合入主线。        2.       采用版本火车的方式，加快版本的迭代速度，功能"持票上车"，如果跟不上这个版本就随下个版本上线。另外，可以采用功能开关、热修复等手段，打破版本发布的固定节奏，以一种更加灵活的方式对外发布。        3.       通过自动化手段扫描主线和发布分支的差异，建立一种规则。比如 Hotfix    必须主线和发布分支同时提交，或者发布分支上线后，由专人反向同步等。        分支开发，主干发布![](Images/c45aed24e9fa37e4e8a8455cc5f60e00.png)savepage-src="https://static001.geekbang.org/resource/image/b9/69/b956a9dc626cad58976b55c5cb773169.png"}>  > [图片来源：> > > [https://paulhammant.com/2013/12/04/what_is_your_branching_model/> > > >当开发接到一个任务后，会基于主干拉出一条特性开发分支，在特性分支上完成功能开发验证之后，通过Merge request 或者 Pull request的方式发起合并请求，在评审通过后合入主干，并在主干完成功能的回归测试。开源社区流行的GitHub 模式其实就是属于这种。 根据特性和团队的实际情况，还可以进一步细分为两种情况： 1.  每条特性分支以特性编号或需求编号命名，在这条分支上，只完成一个功能的开发；        2.  以开发模块为单位，拉出一条长线的特性分支，并在这条分支上进行开发协作。        **两者的区别就在于特性分支存活的周期，拉出时间越长，跟主干分支的差异就越大，分支合并回去的冲突也就越大**。所以，对于长线模式来说，要么是模块拆分得比较清晰，不会有其他人动这块功能，要么就是保持同主干的频繁同步。**随着需求拆分粒度的变小，短分支的方式其实更合适**。 这种模式下的优势也有两点： 1.       **分支开发相对比较独立，不会因为并行导致互相干扰**        。同时，特性只有在开发完成并验收通过后才会合入主干，对主干分支的质量起到了保护作用；        2.       随着特性分支的流行，在这种模式下，分支成了特性天然的载体。一个特性所关联的所有代码可以保存在一条特性分支上，这为以特性为粒度进行发布的模式来说提供了一种新的可能性。也就是说，如果你想要发布哪个特性，就可以直接将特性分支合并到发布分支上，这就让某一个特性变得"可上可下"，而不是混在一大堆代码当中，想拆也拆不出来。        关于这种特性分支发布的方法，我给你提供一份参考资料slate-object="inline"，你可以了解一下。不过，我想提醒你的是，特性发布虽然看起来很好，但是有三个前置条件：第一个是**特性拆分得足够小**，第二是**有强大的测试环境作支撑**，可以满足灵活的特性组合验证需求，第三是**要有一套自动化的特性管理工具**。 当然，分支开发、主干发布的模式也有缺点和挑战： 1.       非常考验团队特性拆分的能力。如果一个特性过大，会导致大量并行开发的分支存在，分支的集成周期拉长，潜在的冲突也会增多。另外，分支长期存在也会造成跟主线差异过大的问题。所以，        **特性的粒度和分支存活的周期是关键要素。根据经验来看，分支存活的周期一般不要超过一周**        。        2.       对特性分支的命名规范要求很高。由于大量特性分支的拉出，整个代码仓库会显得非常乱。面对一大堆分支，谁也说不清到底哪个还活着，哪个已经没用了。所以，如果能够跟变更管理系统打通，自动化创建分支就最好了。        3.       特性分支的原子性和完整性，保证一个特性的关联改动需要提交到一条分支上，而不是到处都是。同时，特性分支上的提交也需要尽量清晰，典型的就是原子性提交。        我之前所在的一个团队就是采用的这种分支策略。有一次，我为了分支策略的执行细节跟研发负责人争得面红耳赤，争论的核心点就是：当特性分支合并回主干的时候，到底要不要对特性分支上的代码进行整理？ 只要做过开发，你就会知道，很少有人能只用一次提交就把代码写对的，因为总是会有这样那样的问题，导致特性分支上的提交乱七八糟。 在合入主干的时候，为了保证代码的原子性，其实是有机会对代码提交进行重新编排的，Git在这方面可以说非常强大。如果你熟练掌握 git rebase命令，就可以快速合并分拆提交，将每一个提交整理为有意义的原子性的提交，再合入主干，或者干脆把特性分支上的改动压合成一个提交。当然，这样做的代价就是不断重写特性分支的历史，给研发团队带来额外的工作量。我跟你分享一些常见的命令。 >  > 比如：当前特性分支 feature1，主分支> master，那么，你可以执行以下命令整理提交历史：> > >>  > git checkout feature1 && git fetch origin && git rebase -i> origin/master> > >>  > ![](Images/b841333dc897f6ae59c9777e57696930.png)> savepage-src="https://static001.geekbang.org/resource/image/b7/1b/b709ba3701064f950534eb93d822731b.png"}>>  > 最常见的操作包括：> > >>>  > p：选择提交；> > >>>  > r：更新提交的注释信息；> > >>>  > e：编辑提交，可以将一个提交拆分成多个；> > >>>  > s：压合提交，将多个提交合并成一个；> > >>>  > f：类似压合提交，但是放弃这个提交的注释信息，直接使用合并提交的注释信息；> > >>>  > 当然，在 git rebase> 的交互界面中，你也可以调整提交的顺序，比如将特性功能和关联的 Bugfix> 整合在一起。> > >**需要提醒你的是，分支策略代表了研发团队的行为准则，每个团队都需要磨合出一套适合自己的模式来**。 主干开发，主干发布![](Images/d91e32698ab0bcc8e12550585a892e1d.png)savepage-src="https://static001.geekbang.org/resource/image/8f/b0/8f1b96d9847430effaba8d5ee45d8bb0.png"}>  > [图片来源：> > > [https://paulhammant.com/2013/12/04/what_is_your_branching_model/> > > >今天给你介绍的第三种分支策略是主干开发、主干发布。武学高手修炼到一定境界之后，往往会发现大道至简，分支策略也是如此。所以，第三种分支策略可以简单理解为没有策略。**团队只有一条分支，开发人员的代码改动都直接集成到这条主干分支上，同时，软件的发布也基于这条主干分支进行**。 对于持续交付而言，最理想的情况就是，每一次提交都能经历一系列的自动化环境并部署到生产环境上面，而这种模式距离这个目标就更近了一点。 可想而知，如果想要做到主干分支在任何时间都处于可发布状态，那么，这就对每一次提交的代码质量要求非常高。 在一些追求工程卓越的公司里，你要提交一行代码，就必须经历"九九八十一难"，因为有一系列的自动化验收手段，还有极为严格的代码评审机制来保证你的提交不会把主干分支搞挂掉。当然，即便如此，问题也是难以避免的，那我们该怎么做呢？这里我就要给你介绍下Facebook 的分支策略演进案例了。 Facebook最早采用的也是主干开发、分支发布的策略，每天固定发布两次。但是，随着业务发展的压力增大，团队对于发布频率有了更高的要求，这种分支策略已经无法满足每天多次发布的需求了。于是，他们开始着手改变分支策略，从主干开发、分支发布的模式，演变成了主干开发、主干发布的模式。 为了保证主干分支的质量，自动化验收手段是必不可少的，因此，每一次代码提交都会触发完整的编译构建、单元测试、代码扫描、自动化测试等过程。在代码合入主干后，会进行按需发布，先是发布到内部环境，也就是只有Facebook的员工才能看到这个版本，如果发现问题就立刻修复，如果没有问题，再进一步开放发布给2%的线上生产用户，同时自动化检测线上的反馈数据。直到确认一切正常，才会对所有用户开放。 最后，通过分支策略和发布策略的整合，注入自动化质量验收和线上数据反馈能力，最终将发布频率从固定的每天2 次，提升到每天多次，甚至实现了按需发布的模式。Facebook最新的分支策略如图所示： ![](Images/b205f1dc76322e74920f9f6104840d3a.png)savepage-src="https://static001.geekbang.org/resource/image/b2/64/b2a7a2d841e5b95d1fbf83d286d42364.jpg"}>  > [ 图片来源：> > > [https://engineering.fb.com/web/rapid-release-at-massive-scale/> > > >看到这里，你可能会问："在这三种典型策略中，哪种策略是最好的？我应该如何选择呢？"其实，这个问题也困扰着很多公司。 的确，不同类型、规模、行业的软件项目采用的分支策略可能都不尽相同，同时，发布频率、软件架构、基础设施能力、人员能力水平等因素也在制约着分支策略的应用效果。 所以，很难说有一种通用的分支策略可以满足所有场景的需求。但是，有些分支策略的原则更加适合于快速迭代发布的场景，也就更加适合DevOps的发展趋势。所以，我个人比较推荐的是**主干开发结合特性分支的模式**，也就是团队共享一条开发主干，特性开发基于主干拉出特性分支，快速开发验收并回归主干，同时，在特性分支和主干分别建立不同的质量门禁和自动化验收能力。 这样做的好处在于，**可以加快代码集成频率，特性相对独立清晰**，并且主干分支又可以保持一定的质量水平。不过，在执行的过程中，你需要遵守以下原则： 1.       团队共享一条主干分支；        2.       特性分支的存活周期要尽量短，最好不要超过 3    天；    3.       每天向主干合并一次代码，如果特性分支存在超过 1    天，那么每天都要同步主干代码；        4.       谨慎使用功能开关等技术手段，保持代码干净和历史清晰；        5.       并行分支越少越好，如果可能的话，尽量采用主干发布。        关于最后一条，你需要注意的是，**是否需要发布分支，主要取决于项目的发布模式**。对于按照版本方式发布的项目来说，比如App、智能硬件系统，以及依赖大量外部系统联调的核心系统，可以按照发布固定的节奏拉出发布分支；对于发布节奏较快、系统架构拆分后相对独立的应用来说，可以直接采用主干发布的模式，并结合安全发布策略把控整体的发布质量。 这种分支发布的策略图如下所示： ![](Images/db0a34435125985bd0bf9613b41a0ee7.png)savepage-src="https://static001.geekbang.org/resource/image/16/5e/165381a31f212516ee92fd295040465e.jpg"}总结今天，我给你介绍了三种分支策略，建议你对照我给你分享的分支策略图，好好理解一下。另外，我还介绍了适合 DevOps模式的分支策略以及一些使用原则。还记得我最开始说的吗？分支策略就是研发协作和发布模式的风向标，分支策略的变化对整个研发团队的习惯和节奏都是一个非常大的调整，找到适合当前团队的分支策略，才是最重要的。 思考题你目前所在的团队采用的是哪种分支策略？你觉得当前的分支策略有哪些问题或改进空间吗？你是否经历过分支策略的调整呢？如果有的话，你在这个过程中踩过什么"坑"吗？有没有什么心得呢？ 欢迎在留言区写下你的思考和答案，我们一起讨论，共同学习进步。如果你觉得这篇文章对你有所帮助，欢迎你把文章分享给你的朋友。 ![](Images/94ddfb3c31810c68bfd0097449ef5eeb.png)savepage-src="https://static001.geekbang.org/resource/image/7c/33/7c26a9b917677371cf3aac78d949ae33.jpg"}