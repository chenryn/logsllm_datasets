Lookup To look up the latency of a packet, PBF checks
whether the packet is present in any of the BFs; the delay
represented by the BF that returns a match is the estimated
latency of the queried packet. Clearly, the complexity of the
lookup operation is O(k) since k BFs need to be consulted.
Limitations A big problem with PBF is that, PBF needs
to allocate storage for each of the k groups diﬀerently since
the frequency counts for each group could be diﬀerent. Of
course, PBF could use the estimated frequency counts, but
since our centers are calculated based on packets two epochs
back, these estimates may not be accurate. Thus, the only
options are to allocate higher amounts of storage per BF
than necessary, or once the capacity of a BF is reached, it
stops adding packets, leading to false negatives.
3.3.2 Prior approach: COMB
The second option we explore is using a recent generic
data structure called combinatorial Bloom ﬁlters (COMB)
designed for supporting multiset membership testing [20].
While PBF strictly partitions all BFs, COMB uses a single
BF, but represents diﬀerent groups using diﬀerent subsets of
hash functions. COMB contains three parameters, an f -bit
vector in which θ bits are set to 1 to indicate the code for
a group, and h diﬀerent hash functions for each bit-position
(in total h · f hash functions).
Insert For given center ci, it ﬁrst looks up the code C(ci)
corresponding to the group; for each bit position that is set
(θ bits will be set in each code), it picks the corresponding
set of hash functions to index into the BF, and sets the
105(a) PBF, O(1) insert, O(k) lookup
(b) COMB, O(1) insert, O(f ) lookup
(c) SVBF, O(1) insert, O(1) lookup
Figure 3: Diﬀerent variants of Bloom ﬁlters with diﬀerent insert and lookup and O(f ) lookup where f is
the size of bit vector. SVBF has O(1) insert and O(1) lookup assuming reading the k vector takes 1 memory
access.
appropriate bits to 1 (just like a regular BF insert). Thus,
for each packet, it requires setting up to h· θ bits in the BF.
Lookup For each packet, it tests the positions indexed
by hashing the packet with h · f hash functions. The f -
bit code is formed by setting a bit position to 1, only if all
bits indexed by the hash functions associated with the bit
position indicate a 1 in the BF. The code then indicates the
center.
Limitations The biggest advantage of COMB is that, un-
like PBF, it does not need to know the number of packets
in each group. However, storage requirement increases as
θ increases, which decreases storage eﬃciency (as we shall
compare shortly). Another limitation is that lookup com-
plexity is high since all the h · f hash functions need to be
queried, and all these bits are randomly located.
3.3.3 Our new data structure: SVBF
In the philosophy of maintaining one BF for all the groups,
we could consider another, perhaps simpler alternative. Here,
instead of storing packet s directly, we can store its concate-
nation with the group id, ci, i.e., s(cid:48) = s ⊕ ci, where ⊕ is a
concatenation operator. Inserts are fast, but lookups (that
involve querying a packet with all concatenations of group
ids, i.e. k queries) are quite slow. Further, these cannot be
parallelized since all the bits are scattered all across the BF.
To address this problem, we propose a new data structure
called SVBF that essentially preserves the simplicity of a
single BF, but reduces the lookup complexity signiﬁcantly.
Speciﬁcally, we store the bits corresponding to diﬀerent de-
lay values for the same packet close-by so that during queries
we can read all the bits in a burst instead of reading them
sequentially from various bit positions.
Insert The insert operation is quite similar to a regular BF,
except for a small modiﬁcation. In regular BF, each packet
is hashed using multiple hash functions, and bits at those
indices are set to 1. In SVBF, we use the center’s index of
the packet as an oﬀset into a vector of delay values. Thus,
we set the bit corresponding to (hj(s) + i) mod m, where j
is the hash function index, i ∈ [0, k − 1] is the center index
of the packet, and m is the size of SVBF. We do this for all
hash functions. This is shown in Figure 3(c) where a packet
that matches the second center c1 (center index 1) is added
into the BF using hash functions H1 and H2. The oﬀset at
which the bit is set is 1 for this second center.
Lookup Given packet s, we ﬁrst hash the packet to ob-
tain various hash indices hj(s) mod m. From each of these
bases, we read the next set of k bits, i.e., hj(s) mod m to
(hj(s) + k − 1) mod m, to obtain bitmap Bj. We compute
Data structure #Hash Capacity (m/n)
Insert
Lookup
hashtable
PBF
COMB(50, 1)
COMB(11, 2)
COMB(8, 3)
SVBF
1
9
9
7
6
9
147 bits/pkt
12.8 bits/pkt
12.8 bits/pkt
18.5 bits/pkt
24.2 bits/pkt
12.8 bits/pkt
1
9
9
14
18
9
1
450
450
77
48
27
Table 1: Example of complexity of storage data
structures for single port memory. 32 bit word is
assumed for lookup in SVBF. Classiﬁcation failure
rate pcf = 0.1 and k = 50. hashtable is tuned for
pfc = 0.02. The unit for insertion and lookup is the
number of memory accesses.
the bit-wise AND across all these bitmaps, B = B1&B2& . . ..
In the ﬁnal bitmap (B), the oﬀset where a bit is set to 1 is
the center index.
While SVBF looks like a simple BF, there are two ma-
jor diﬀerences. First, a BF only supports a membership
check of a single sort, but SVBF supports multiset member-
ship check. Second, the biggest advantage of this scheme is
that, it relies on ‘burst reads’ which are simpler than ran-
dom reads that COMB and BF suﬀer from. Thus, instead
of k memory accesses, we need at most (cid:100)k/w(cid:101) + 1 memory
accesses for each hash index as shown in Table 2. For ex-
ample, for k = 50, we can obtain the bit maps in a total
of 3 × h memory accesses assuming a 32-bit machine word,
and h is the number of hash functions. In Table 1, we show
an example that outlines the storage complexity, lookup and
insert times of SVBF compared to other data structures.
3.3.4 Classiﬁcation failures
BFs are known to suﬀer from false positives occasionally,
in which case a given element is not in the BF, but the BF
returns with a positive answer. In PBF, this translates to a
classiﬁcation failure problem, since two (or more) BFs, one
legitimate and one (or more) false positive may both (all)
indicate a hit—the question is which one to trust. Similarly,
COMB too may suﬀer from classiﬁcation failures where more
than θ bits in the bit vector are set to one. Even SVBF
may suﬀer from classiﬁcation failure, since the bitmap B
described above may have more than one position set to 1
occasionally. We formally analyze this in §3.4.
Tie-breaking heuristic One option when classiﬁcation
fails due to the false positives, is to just not return an an-
swer; this may be an acceptable choice given the system in-
herently trades oﬀ some amount of accuracy in order to scale
c0c1c48c49Closest centermatch in parallelPacketlatency110100101111001110111101Different Bloom filters for different centersc0c1c48c491101001011Closest centermatch in parallelSingle Bloom filter, Different sets of hash functionsPacketlatency10101001111001010Group CodeH1H2H3H4H5H6H7H80101c0c1c48c491101001011Closest centermatch in parallelSingle Bloom filter, Same hash functionsPacketlatency1Offset is the number of the matched centerH1H2106Data structure
PBF
COMB
SVBF
#Hash functions
hPBF = − log2(1 − (1 − pcf)1/(k−1))
hCOMB = − log2(1 − (1 − pcf)1/(f−θ))
hSVBF = − log2(1 − (1 − pcf)1/(k−1))
Capacity (m/n)
≥ hPBF/ log 2
θ × hCOMB/ log 2
Insert
hPBF
θ × hCOMB
Lookup
k × hPBF
f × hCOMB
hSVBF/ log 2
hSVBF
((cid:100)k/w(cid:101) + 1) × hSVBF
Note
lookup can be parallelized
random access for lookup
serial burst read in the
unit of word
Table 2: Complexity of storage data structures for single port memory. w is the size of memory word. log is
natural log.
better. We can also choose to resolve such conﬂicts using the
following tie-breaking heuristic. When a packet can poten-
tially match many groups, we report the latency value of the
group with the largest number of packets among all conﬂict-
ing groups. For identifying this, we assume we can store run-
ning packet counts for each group in an extra counter. This
approach now can introduce false classiﬁcation because the
decisions can be wrong. But, we observed that this heuris-
tic works well when the distribution of the cardinalities of
BFs is skewed (e.g., long tailed, heavy tailed), and can im-
prove accuracy in many cases. However, as we mention in
§4, the result of a query will be explicitly tagged so that the
application which uses this data can be informed about the
‘guess’ing nature of the answer.
3.4 Analysis of PLS
Now we discuss why simple hash table cannot scale in
terms of space requirement while achieving O(1) insert and
lookup, and analyze the dependence of collision performance
of the proposed data structures on storage dimensioning.
3.4.1 Hash table
While hash tables are typically simple, at a minimum they
require the packet hash (32 bits) and group id (6 bits for 50
centers), thus requiring at least 38 bits per packet. Colli-
sion avoidance schemes present a further challenge for scal-
ing. Thus, in order to perform a comparison with a BF,
we consider a simpler hash table with no collision avoid-
ance scheme, in which the packet digest is used to address
a memory location in which the group id is stored (col-
lisions will override the group id). For our analysis we
consider n packets whose digest values are distributed in-
dependently and uniformly across m locations. Following
§3.3.4, the false classiﬁcation probability pfc is proportion
of packets allocated to already occupied locations: pfc =
n (1−(1−1/m)n); see e.g. Section 3.3.2 of [25]. Although
1− m
the required capacity m is not given as an explicit function of
a target pfc, we have the approximation pfc ≈ n/(2m) when
n (cid:28) m. For example, when pfc = 0.02 (a median false clas-
siﬁcation rate that SVBF achieves in §5.3) then m = 24.6n.
Considering k = 50, each bucket is 6 bits. Then, m/n = 147
bits/packet, even higher than the regular hash tables. Thus,
this simple variant does not scale.
3.4.2 Collision analysis & storage dimensions
We now analyze the frequencies of classiﬁcation failures
due to storage collisions for queries on the PBF, COMB
and SVBF data structures. First, it is convenient to iden-
tify a generic collision analysis that applies to each storage
method. Following the terminology of §3.3, the false pos-
itive probability pfp denotes a probability that a given set
of storage locations pertaining to a single delay group are
occupied. Then, classiﬁcation failure for a packet in delay
cf = 1 −(cid:81)
group i occurs if it has a false positive in any other delay
group j: p(i)
j(cid:54)=i(1 − p(j)
fp ).
Consider now speciﬁcally a BF with m locations and h
hash functions. We assume an independent hash digest dis-
tribution over all packets. For simplicity, we assume that the
query packet is mapped by the hash functions to h distinct
locations1. As is well known, the false positive probability
that a set of h bits are all set after the insertion of n back-
ground objects is pfp = p(m, n, h) = (1 − (1 − 1/m)nh)h.
Collisions in PBF Each delay group i has capacity mi
i mi = m) and ni background packets allocated to it
i ni = n). Given a classiﬁcation failure probability for a
packet in a delay group i, by averaging over all n packets in
their respective delay groups, we have
((cid:80)
((cid:80)
(1 − p(mi, ni, h))
(1)
pcf = 1 −(cid:88)
nj
n
j
(cid:89)
i(cid:54)=j
Since the operational allocations mi and ni are not known in
advance, for design purposes one would assume uniformity,
in which case (1) reduces to (3) below.
Collisions in COMB All delay group locations for the
query ﬂow may be set by any of the background ﬂows. Since
COMB uses θ bits to denote a group id in a code, it is