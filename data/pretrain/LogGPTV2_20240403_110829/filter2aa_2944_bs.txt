346
CHAPTER 10
Microservice APIs in Kubernetes
(https://kubernetes.io/docs/home/) for the correct apiVersion when writ-
ing a new configuration file.
To create the namespace, run the following command in your terminal in the root
folder of the natter-api project:
kubectl apply -f kubernetes/natter-namespace.yaml
The kubectl apply command instructs Kubernetes to make changes to the cluster to
match the desired state specified in the configuration file. You’ll use the same com-
mand to create all the Kubernetes objects in this chapter. To check that the name-
space is created, use the kubectl get namespaces command:
$ kubectl get namespaces
Your output will look similar to the following:
NAME              STATUS   AGE
default           Active   2d6h
kube-node-lease   Active   2d6h
kube-public       Active   2d6h
kube-system       Active   2d6h
natter-api        Active   6s
You can now create the pod to run the H2 database container you built in the last sec-
tion. Rather than creating the pod directly, you’ll instead create a deployment, which
describes which pods to run, how many copies of the pod to run, and the security attri-
butes to apply to those pods. Listing 10.3 shows a deployment configuration for the
H2 database with a basic set of security annotations to restrict the permissions of the
pod in case it ever gets compromised. First you define the name and namespace to
run the deployment in, making sure to use the namespace that you defined earlier. A
deployment specifies the pods to run by using a selector that defines a set of labels that
matching pods will have. In listing 10.3, you define the pod in the template section of
the same file, so make sure the labels are the same in both parts. 
NOTE
Because you are using an image that you built directly to the Minikube
Docker daemon, you need to specify imagePullPolicy: Never in the con-
tainer specification to prevent Kubernetes trying to pull the image from a
repository. In a real deployment, you would have a repository, so you’d
remove this setting.
You can also specify a set of standard security attributes in the securityContext section
for both the pod and for individual containers, as shown in the listing. In this case, the
definition ensures that all containers in the pod run as a non-root user, and that it is not
possible to bypass the default permissions by setting the following properties:
runAsNonRoot: true ensures that the container is not accidentally run as the
root user. The root user inside a container is the root user on the host OS and
can sometimes escape from the container.
347
Deploying Natter on Kubernetes
allowPrivilegeEscalation: false ensures that no process run inside the con-
tainer can have more privileges than the initial user. This prevents the con-
tainer executing files marked with set-UID attributes that run as a different
user, such as root.
readOnlyRootFileSystem: true makes the entire filesystem inside the container
read-only, preventing an attacker from altering any system files. If your container
needs to write files, you can mount a separate persistent storage volume.
capabilities: drop: - all removes all Linux capabilities assigned to the container.
This ensures that if an attacker does gain root access, they are severely limited in
what they can do. Linux capabilities are subsets of full root privileges and are
unrelated to the capabilities you used in chapter 9.
LEARN ABOUT IT
For more information on configuring the security context of a
pod, refer to http://mng.bz/mN12. In addition to the basic attributes specified
here, you can enable more advanced sandboxing features such as AppArmor,
SELinux, or seccomp. These features are beyond the scope of this book. A start-
ing point to learn more is the Kubernetes Security Best Practices talk given by Ian Lewis
at Container Camp 2018 (https://www.youtube.com/watch?v=v6a37uzFrCw). 
Create a file named natter-database-deployment.yaml in the kubernetes folder with
the contents of listing 10.3 and save the file.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: natter-database-deployment     
  namespace: natter-api                
spec:
  selector:                   
    matchLabels:              
      app: natter-database    
  replicas: 1    
  template:
    metadata:
      labels:                 
        app: natter-database  
    spec:
      securityContext:          
        runAsNonRoot: true      
      containers:
        - name: natter-database                          
          image: apisecurityinaction/h2database:latest   
          imagePullPolicy: Never   
          securityContext:                     
            allowPrivilegeEscalation: false    
            readOnlyRootFilesystem: true       
            capabilities:                      
              drop:                            
                - all                          
Listing 10.3
The database deployment
Give the deployment a 
name and ensure it 
runs in the natter-api 
namespace.
Select which 
pods are in the 
deployment.
Specify
how many
copies of
the pod to
run on the
cluster.
Specify a security
context to limit
permissions inside
the containers.
Tell Kubernetes the 
name of the Docker 
image to run.
Ensure that 
Kubernetes uses the 
local image rather 
than trying to pull one 
from a repository.
348
CHAPTER 10
Microservice APIs in Kubernetes
          ports:                     
            - containerPort: 9092    
Run kubectl apply -f kubernetes/natter-database-deployment.yaml in the natter-
api root folder to deploy the application.
 To check that your pod is now running, you can run the following command:
$ kubectl get deployments --namespace=natter-api
This will result in output like the following:
NAME                         READY   UP-TO-DATE   AVAILABLE   AGE
natter-database-deployment   1/1     1            1           10s
You can then check on individual pods in the deployment by running the following
command
$ kubectl get pods --namespace=natter-api
which outputs a status report like this one, although the pod name will be different
because Kubernetes generates these randomly:
NAME                                       READY   STATUS    RESTARTS   AGE
natter-database-deployment-8649d65665-d58wb   1/1     Running   0       16s
Although the database is now running in a pod, pods are designed to be ephemeral
and can come and go over the lifetime of the cluster. To provide a stable reference for
other pods to connect to, you need to also define a Kubernetes service. A service pro-
vides a stable internal IP address and DNS name that other pods can use to connect to
the service. Kubernetes will route these requests to an available pod that implements
the service. Listing 10.4 shows the service definition for the database. 
 First you need to give the service a name and ensure that it runs in the natter-api
namespace. You define which pods are used to implement the service by defining a
selector that matches the label of the pods defined in the deployment. In this case,
you used the label app: natter-database when you defined the deployment, so use
the same label here to make sure the pods are found. Finally, you tell Kubernetes
which ports to expose for the service. In this case, you can expose port 9092. When a
pod tries to connect to the service on port 9092, Kubernetes will forward the request
to the same port on one of the pods that implements the service. If you want to use a
different port, you can use the targetPort attribute to create a mapping between the
service port and the port exposed by the pods. Create a new file named natter-data-
base-service.yaml in the kubernetes folder with the contents of listing 10.4. 
apiVersion: v1
kind: Service
Listing 10.4
The database service
Expose the database 
server port to other pods.
349
Deploying Natter on Kubernetes
metadata:
  name: natter-database-service       
  namespace: natter-api               
spec:
  selector:                    
    app: natter-database       
  ports:
    - protocol: TCP    
      port: 9092       
Run
kubectl apply -f kubernetes/natter-database-service.yaml
to configure the service.
10.2.3 Building the Natter API as a Docker container
For building the Natter API container, you can avoid writing a Dockerfile manually
and make use of one of the many Maven plugins that will do this for you automatically.
In this chapter, you’ll use the Jib plugin from Google (https://github.com/Google-
ContainerTools/jib), which requires a minimal amount of configuration to build a
container image.
 Listing 10.5 shows how to configure the maven-jib-plugin to build a Docker con-
tainer image for the Natter API. Open the pom.xml file in your editor and add the
whole build section from listing 10.5 to the bottom of the file just before the closing
 tag. The configuration instructs Maven to include the Jib plugin in the
build process and sets several configuration options:
 Set the name of the output Docker image to build to “apisecurityinaction/
natter-api.”
 Set the name of the base image to use. In this case, you can use the distroless Java
11 image provided by Google, just as you did for the H2 Docker image. 
Pop quiz 
3
Which of the following are best practices for securing containers in Kubernetes?
Select all answers that apply.
a
Running as a non-root user
b
Disallowing privilege escalation
c
Dropping all unused Linux capabilities
d
Marking the root filesystem as read-only
e
Using base images with the most downloads on Docker Hub
f
Applying sandboxing features such as AppArmor or seccomp
The answer is at the end of the chapter.
Give the service a name in 
the natter-api namespace.
Select the pods that implement 
the service using labels.
Expose the 
database port.
350
CHAPTER 10
Microservice APIs in Kubernetes
 Set the name of the main class to run when the container is launched. If there is
only one main method in your project, then you can leave this out.
 Configure any additional JVM settings to use when starting the process. The
default settings are fine, but as discussed in chapter 5, it is worth telling Java to
prefer to use the /dev/urandom device for seeding SecureRandom instances to
avoid potential performance issues. You can do this by setting the java.security
.egd system property.
 Configure the container to expose port 4567, which is the default port that our
API server will listen to for HTTP connections.
 Finally, configure the container to run processes as a non-root user and group.
In this case you can use a user with UID (user ID) and GID (group ID) of 1000.
      com.google.cloud.tools     
      jib-maven-plugin     
      2.4.0                      
          apisecurityinaction/natter-api     
          gcr.io/distroless/java:11     
          ${exec.mainClass}     
            -Djava.security.egd=file:/dev/urandom    
            4567      
          1000:1000      
Before you build the Docker image, you should first disable TLS because this avoids
configuration issues that will need to be resolved to get TLS working in the cluster.
You will learn how to re-enable TLS between microservices in section 10.3. Open
Main.java in your editor and find the call to the secure() method. Comment out (or
delete) the method call as follows:
//secure("localhost.p12", "changeit", null, null);     
Listing 10.5
Enabling the Jib Maven plugin
Use the latest version of 
the jib-maven-plugin.
Provide a name
for the generated
Docker image.
Use a minimal base 
image to reduce the 
size and attack surface.
Specify the main 
class to run.
Add any
custom JVM
settings.
Expose the port that the 
API server listens to so that 
clients can connect.
Specify a non-root 
user and group to 
run the process.
Comment out the secure() 
method to disable TLS.
351
Deploying Natter on Kubernetes
The API will still need access to the keystore for any HMAC or AES encryption keys. To
ensure that the keystore is copied into the Docker image, navigate to the src/main
folder in the project and create a new folder named “jib.” Copy the keystore.p12 file
from the root of the project to the src/main/jib folder you just created. The jib-maven-
plugin will automatically copy files in this folder into the Docker image it creates. 
WARNING
Copying the keystore and keys directly into the Docker image is
poor security because anyone who downloads the image can access your
secret keys. In chapter 11, you’ll see how to avoid including the keystore in
this way and ensure that you use unique keys for each environment that your
API runs in.
You also need to change the JDBC URL that the API uses to connect to the database.
Rather than creating a local in-memory database, you can instruct the API to connect
to the H2 database service you just deployed. To avoid having to create a disk volume
to store data files, in this example you’ll continue using an in-memory database run-
ning on the database pod. This is as simple as replacing the current JDBC database
URL with the following one, using the DNS name of the database service you cre-
ated earlier:
jdbc:h2:tcp://natter-database-service:9092/mem:natter
Open the Main.java file and replace the existing JDBC URL with the new one in the
code that creates the database connection pool. The new code should look as shown
in listing 10.6.
var jdbcUrl =                                                  
    "jdbc:h2:tcp://natter-database-service:9092/mem:natter";   
var datasource = JdbcConnectionPool.create(
    jdbcUrl, "natter", "password");              
createTables(datasource.getConnection());
datasource = JdbcConnectionPool.create(
    jdbcUrl, "natter_api_user", "password");     
var database = Database.forDataSource(datasource);
To build the Docker image for the Natter API with Jib, you can then simply run the fol-
lowing Maven command in the same shell in the root folder of the natter-api project:
mvn clean compile jib:dockerBuild
You can now create a deployment to run the API in the cluster. Listing 10.7 shows the
deployment configuration, which is almost identical to the H2 database deployment
you created in the last section. Apart from specifying a different Docker image to run,
you should also make sure you attach a different label to the pods that form this
deployment. Otherwise, the new pods will be included in the database deployment.
Listing 10.6
Connecting to the remote H2 database
Use the DNS name 
of the remote 
database service.
Use the same JDBC URL when 
creating the schema and when 
switching to the Natter API user.
352
CHAPTER 10
Microservice APIs in Kubernetes
Create a new file named natter-api-deployment.yaml in the kubernetes folder with the
contents of the listing.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: natter-api-deployment     
  namespace: natter-api
spec:
  selector:
    matchLabels:
      app: natter-api       
  replicas: 1
  template:
    metadata:
      labels:
        app: natter-api     
    spec:
      securityContext:
        runAsNonRoot: true
      containers:
        - name: natter-api
          image: apisecurityinaction/natter-api:latest     
          imagePullPolicy: Never
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities:
              drop:
                - all
          ports:
            - containerPort: 4567    
Run the following command to deploy the code:
kubectl apply -f kubernetes/natter-api-deployment.yaml
The API server will start and connect to the database service.
 The last step is to also expose the API as a service within Kubernetes so that you
can connect to it. For the database service, you didn’t specify a service type so Kuber-
netes deployed it using the default ClusterIP type. Such services are only accessible
within the cluster, but you want the API to be accessible from external clients, so you
need to pick a different service type. The simplest alternative is the NodePort service
type, which exposes the service on a port on each node in the cluster. You can then
connect to the service using the external IP address of any node in the cluster. 
 Use the nodePort attribute to specify which port the service is exposed on, or leave
it blank to let the cluster pick a free port. The exposed port must be in the range
30000–32767. In section 10.4, you’ll deploy an ingress controller for a more controlled
Listing 10.7
The Natter API deployment
Give the API deployment a 
unique name.
Ensure the labels for 
the pods are different 
from the database 