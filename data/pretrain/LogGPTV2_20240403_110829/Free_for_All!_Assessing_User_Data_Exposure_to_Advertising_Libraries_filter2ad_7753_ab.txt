app’s runtime generated local ﬁles, an ad library might learn
whether its user suffers from headaches, whether she is currently
pregnant, and, if so, the current trimester of her pregnancy. All
these are targeted data which advertisers can monetize [42],
making them a valuable addition to ad libraries.
Moreover, an aggressive ad library could utilize its vantage
position to peak on user input. In particular, such a library
could locate all the UI elements that correspond to targeted data
related to user input [34], [23] and monitor them to capture
the data as they become available. For example, by monitoring
the user’s input on Text Me! Free Texting & Call,
a communication app with 10,000,000–50,000,000 downloads,
an ad library would be able to capture the user’s gender,
age and zip code. Note that these data constitute the quasi
identiﬁers [44] proven to be enough to uniquely identify a large
percentage of registered voters in the US.
Nonetheless, an ad library can exploit both the inherited
privileges of its host app and the position on a user’s device.
Irrespective of the host app, the ad libraries, can make use
of public APIs to learn more about the user. Such APIs are
considered harmless by the Android Open Source Project
(AOSP) designers and are left unprotected. This means that the
apps can use those APIs without the need to request permissions
from either the system or the user. In this work, we found that by
merely acquiring the list of installed applications through such
APIs, one can learn targeted data such as a user’s marital
status, age, and gender among others.
To model these attack channels, we further categorize them
them into two classes, namely the in-app and out-app
exploitation class. The in-app class contains attack channels
that are dependent on the ad library’s host app. The protected
API’s, app local ﬁles and user input, are examples of such
channels. The out-app class contains attack channels that
are independent of the host app. The public API’s are an
example of this. Through the rest of this work, we assume
that an ad library can gain access to targeted data through
permission-protected APIs, runtime-generated app local ﬁles,
user input, and unprotected APIs.
IV. DATA EXPOSURE THROUGH IN-APP CHANNELS
Ad libraries can leverage their position within their host
apps to access exposed targeted data. Some targeted data are
dependent on what the host apps themselves collect from the
users. An ad library can access such data by parsing the ﬁles
its host app created at runtime to store such information locally,
that is in its own UID-protected storage. Furthermore, it can
inherit the permissions granted to its host app and leverage that
privilege to collect targeted data through permission-protected
APIs. Finally, it can peek on what the host app user inputs
to the app. In this section, we explore what an ad library can
learn through these in-app attack channels. We elaborate on our
methodology and provide insights from real world examples.
To gain insight on what an ad library can learn, we perform
manual inspection of some real-world free apps. This way
we can validate our assumptions about data exposure through
in-app attack channels and further create ground truth for test
data that we can use to do evaluations of our framework in
subsequent sections.
We ﬁrst cherry-pick a few free apps we selected for purposes
of illustration. We downloaded the target apps from Google
Play and used Apktool to decompile them. We located the
packages corresponding to the Google AdMob advertising
network library and located an entry point that is called every
time an ad is about to be loaded. We injected our attack logic
there to demonstrate how the ad library can examine local ﬁles.
In particular, our logic dumps the database and xml ﬁles that
the app has created at runtime. We then compiled the app and
ran it on a physical device by manually providing it with some
input. Here are some examples of what such an aggressive
ad library could learn in this position (or what AdMob is, in
principle, able to learn now).
I’m Pregnant helps women track their pregnancy
progress and experience. It has 1,000,000–5,000,000 instal-
lations and is ranked with 4.4 stars 2 on Google Play. Our
code was able to read and extract the local ﬁles created by
the host app. After manually reviewing the retrieved ﬁles, we
found that the host app is storing the weight of the user, the
height, current pregnancy month and day, symptoms such as
headaches, backache and constipation. It also recorded events
such as dates of intercourse (to establish the date of conception)
and outcomes like miscarriage or date of birth.
Diabetes Journal helps users better manage their
diabetes. It has 100,000–500,000 installations and ranked with
4.5 stars on Google Play. Our code was able to extract the local
ﬁles generated by the app. Manually reviewing these ﬁles, we
found that it exposes the user’s birth date, gender, ﬁrst-name
and last name, weight and height, blood glucose levels, and
workout activities.
TalkLife targets users that suffer from depression, self-
harm, or suicidal thoughts. It has 10,000–50,000 installations
on Google Play and ranked with 4.3 stars. In contrast with the
other two apps above, TalkLife stores the user information in
a user object which it serializes and then stores in a local ﬁle.
In this case, some knowledge of the host app allows our code
to deserialize the user object and get her email, date of birth,
and ﬁrst name. Deserializing the user object also provided our
library the user password in plain text.
Thus, if an opportunistic advertising library is included in
apps like these, then a careful manual review of the apps will
reveal some pathways to targeted data. At this point it helps to
have a little more terminology. Let us say that a data point is
a category of targeted data point values. For example, gender
is a data point, whereas knowing that Bob is a male is a data
point value. What we would like to do, is examine a collection
of apps to see what data points they expose to ad libraries.
To explore these ideas and their reﬁnement we develop
three datasets listed in the ﬁrst three rows of Table I. For the
ﬁrst, we make a list of the 100 most popular free apps in each
of the 27 categories on Google Play to get 2700 apps. After
removing duplicate apps, we were left with 2535 unique apps.
We call this the Full Dataset, FD. From these we randomly
selected 300 apps for manual review. From these apps we
removed the ones that crashed on our emulator or required the
use of Google Play Services. We will refer to this as the Level
2Applications on Google Play are being ranked by users. A 5-star application
is an application of the highest quality.
4
TABLE I: Datasets
Name
Full Dataset (FD)
Number
2535
Level One Dataset
(L1)
Level Two Dataset
(L2)
App Bundle Dataset
(ABD)
262
35
243
Description
Unique apps collected from the 27
Google Play categories.
Apps randomly selected from FD.
Apps purposively selected from
L1.
App bundles collected through sur-
vey.
One Dataset (L1). On this dataset, we searched for data point
exposure by two means. First, we inspected the manifest to see
if the permissions themselves would suggest that certain types
of data points would be present. For example, we predicted
that the address attribute could be derived by the library if the
host app is granted the ACCESS_COARSE_LOCATION or the
ACCESS_FINE_LOCATION permission, the email attribute
from the GET_ACCOUNTS permissions, the phone attribute
from the READ_PHONE_STATE permission and the online
search from the READ_HISTORY_BOOKMARKS permission.
Second, we launched the app, looked to see what local ﬁles it
produced, and looked into these ﬁles to see if they expose any
particular data points.
The data points we consider must include user data that
the ad libraries are likely interested in harvesting. To this end,
we extract data points mostly based on a calculator provided
by the Financial Times (FT) [42]. This calculator provides
illustrative information sought by data brokers together with an
estimate of its ﬁnancial value in the U.S. based on analysis of
industry pricing data at the time the calculator was created. For
example, according to the FT calculator, basic demographic
information like age and gender are worth about $.007. If
an opportunistic advertising network can learn that a user is
(probably) an accountant, then the cumulative information is
worth $.079 (according to the calculator); if they also know
that this accountant is engaged to be married, this increases
the value to $.179. Engaged individuals are valuable because
they face a major life change, are likely to both spend more
money and change their buying habits. An especially noteworthy
data point is a pregnancy. This is well illustrated by events
surrounding Target’s successful program to use the habits of
registered expecting shoppers to derive clues about unregistered
ones in order to target them with advertising about baby
care products [13]. The FT calculator provides us with a
realistic way of exploring the relative value of an information
gathering strategy. The precise ﬁgures are not important, and
have probably changed signiﬁcantly since the introduction of
the calculator, but they give some ballpark idea of value and
the system provides a benchmark for what a more accurate
and detailed database of its kind might use.
We abstracted the questionnaire-like attributes from the
FT calculator into keywords and used these as a guide to
data points to ﬁnd in the apps reviewed. For example, we
transformed the question “Are you a ﬁtness and exercise buff”
into “workout”. We refer to the overall attack technique that
examines local ﬁles and uses protected APIs, as a level one
inspection (L1-I). We found 29 categories of data points in L1
by this means, including ‘gender’, ‘age’, ‘phone number’, ‘email
address’, ‘home address’, ‘vehicle’, ‘online searches’, interests
like ‘workout’ and others. Table II depicts some popular apps
and the data points they expose to ad libraries performing a
level one inspection.
"
s
n
o
)
a
c
i
l
p
p
A
#
"
25"
20"
15"
10"
5"
0"
3"
5"
10"
vehicle"
workout" online"search"
12"
age"
18"
115"
gender"
address"
118"
email"
136"
phone"
Data"Points"
(a)
"
s
n
o
)
a
c
i
l
p
p
A
#
"
25"
20"
15"
10"
5"
0"
3"
3"
4"
6"
6"
8"
8"
9"
13"
20"
22"
22"
weight" vehicle"
stock"
workout"
online"
search"
ﬁrst"
last"
name"
name"
Data"Points"
age"
gender" email"
phone" address"
(b)
Fig. 1: Number of apps with data points inferred by (a) level
one inspection of L1, (b) level two inspection of L2.
However, an ad library could also utilize the fact that it
can eavesdrop on user inputs in its host app. This can be done
on Android by exploring the resource ﬁles of packages. Once
an interesting layout ﬁle is found, an offensive library can
inﬂate the layout from the library package and read from its UI
elements. With this strategy, the ad library can ﬁnd targeted data
that are input by the user but not necessarily kept in local ﬁles.
Let us call the attack strategy that utilizes not only local ﬁles
and protected APIs, but also user input eavesdropping, a level
two inspection (L2-I). To better understand what data points
are exposed to an ad library performing a level two inspection,
we selected 35 of the apps in the L1 dataset and reviewed them
manually to ﬁnd data points that level two inspection could
reveal. We call this the L2 dataset. The 35 apps in question
are ones that exposed one or more data points other than ones
derived from the manifest. We made this restriction to assure
that there was no straight-forward strategy for ﬁnding data
points in these apps so we could better test the automated
inference techniques we introduce later. Table II depicts some
popular apps and the data points they expose to ad libraries
performing a level two inspection. We observe that apps expose
not only demographic information but also more sensitive data
such as user health information. The complete list of apps and
the data points they expose is omitted due to space limitations.
Figure 1a displays the number of apks in the level one
inspection that were found to expose the basic data points we
listed earlier. Figure 1b portrays a similar graph for the level
two inspection. Here, we pruned all data points with frequency
less than three. We observe that data points that can be derived
by exploiting the host app’s permissions are more prevalent
than other ones. This is because the permissions are coarse-
5
TABLE II: Data exposure from popular apps to ad libraries performing level-one (L1-I) and level-two (L2-I) inspection.
Attack
Strategy
L1-I
L1-I
L2-I
L2-I
Category
MEDICAL
EDUCATION
HEALTH & FITNESS
Application Name
Menstrual Calendar
myHomework Student Planner
Run with Map My Run
LIFESTYLE
BeNaughty - Online Dating App & Call
Num. of installations
1 ⇥ 106   5 ⇥ 106
1 ⇥ 106   5 ⇥ 106
5 ⇥ 106   10 ⇥ 106
5 ⇥ 106   10 ⇥ 106
Exposed data points
pregnancy, trimester, headache
gender, age, address
phone, email, ﬁrst name, last name, age, gender, address, workout
phone, email, age, gender, address, marital status, parent
grained and app developers are likely to use them for a number
of reasons, whereas other data points would be present only if
the host app is explicitly collecting that information. Overall,
it is clear that targeted data is exposed by apps through in-app
attack channels to ad libraries. Next we examine exposure
through out-app channels.
V. DATA EXPOSURE THROUGH OUT-APP CHANNELS
Ad libraries can surreptitiously access targeted data not
only through in-app attack channels but also from host-app-
independent channels such as public APIs. Such APIs are
considered to be harmless and thus made available to all
applications on the platform without
the need of special
permissions. In particular, Android provides a pair of publicly
available functions, which we will abbreviate as getIA and
getIP, that return app bundles, the list of installed apps on a