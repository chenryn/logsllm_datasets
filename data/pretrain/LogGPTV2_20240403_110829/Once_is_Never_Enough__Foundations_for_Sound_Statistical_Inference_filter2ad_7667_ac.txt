Because Shadow is a user-space, single process application,
it can easily run on laptops, desktops, and servers with mini-
mal conﬁguration (resource requirements depend on the size
of the experiment model). As a simulator, Shadow has com-
plete control over simulated time; experiments may run faster
or slower than real time depending on: (i) the simulation load
relative to the processing resources available on the host ma-
chine, and (ii) the inherent parallelizability of the experiment
model. This control over time decouples the ﬁdelity of the
experiment from the processing time required to execute it,
and allows Shadow to scale independently of the processing
capabilities of the host machine; Shadow is usually limited
by the RAM requirements of its loaded plugins.
Shadow has numerous features that allow it to achieve
its goals, including dynamic loading of independent names-
paces for plugins [70], support for multi-threaded plugins via
a non-preemptive concurrent thread scheduling library (GNU
Portable Threads11) [52], function interposition, and an event
scheduler based on work stealing [9]. The combination of its
features makes Shadow a powerful tool for Tor experimenta-
tion, and has led it to become the most popular and standard
tool for conducting Tor performance research [63].
4.2 Shadow Improvements
After investigation of the results from some early exper-
iments, we made several improvements to Shadow that we
believe cause it to produce signiﬁcantly more accurate results
when running our Tor network models from §3.2. Our im-
provements include run-time optimizations, ﬁxes to ensure de-
terministic execution, faster Tor network bootstrapping, more
realistic TCP connection limits, and several network stack
improvements (see the extended version of this paper for
more details [40, Appendix C]). Our improvements have been
incorporated into Shadow v1.13.2.
4.3 Evaluation
We have thus far made two types of foundational contribu-
tions: those that result in more representative Tor networks,
and those that allow us to run more scalable simulations
faster than was previously possible. We demonstrate these
contributions through Tor network simulations in Shadow.
Representative Networks: We produce more representa-
tive networks by considering the state of the network over
time rather than modeling a single snapshot as did previous
work [32, 38]. We consider relay churn to demonstrate how
the true Tor network changes over time. Figure 1 shows the
rate of relay churn over all 744 consensus ﬁles (1 per hour) in
Tor during January 2019. After 2 weeks, fewer than 75% of re-
lays that were part of the network on 2019-01-01 still remain
11https://www.gnu.org/software/pth
3420    30th USENIX Security Symposium
USENIX Association
Figure 1: The rate of Tor relay churn over all 744 consensuses from
January 2019. Shown are the number of Tor relays that existed on
2019-01-01 that remain and the number of relays that did not exist
on 2019-01-01 that joined (and possibly left again) over time.
while more than 3,000 new relays joined the network. After
3 weeks, more new relays had joined the network than had
remained since 2019-01-01. Our models account for churn by
sampling from all such relays as described in §3.2.
In addition to producing more representative models, our
Shadow network stack enhancements further improve network
accuracy. To demonstrate these contributions, we simulate
ten Tor network models that were generated following the
methods in §3.2 (using Tor network state from 2019-01). We
model Tor at the same s = 0.31 scale that was used in previous
work [38] (i.e., ≈2k relays and ≈250k users) using a process
scale factor of p = 0.01 (i.e., each TGen process simulated
1/0.01 = 100 Tor users). We compare our simulation results
to those produced by state-of-the-art methods [38] (which
used Tor network state from 2018-01) and to reproducible
Tor metrics [67, 68] from the corresponding modeling years
(2019 for our work, 2018 for the CCS 2018 work).12
The results in Figure 2 generally show that previous work
is noticeably less accurate when compared to Tor 2018 than
our work is compared to Tor 2019. We notice that previous
work exhibited a high client download error rate in Figure 2c
and signiﬁcantly longer download times in Figures 2e–2g
despite the network being appropriately loaded as shown in
Figure 2h. We attribute these errors to the connection limit and
network stack limitations that were present in the CCS 2018
version of Shadow (the errors are not present in this work due
to our Shadow improvements from §4.2). Also, we remark
that the relay goodput in Figure 2h exhibits more variance in
Tor than in Shadow because the Tor data is being aggregated
over a longer time period (1 year for Tor vs. less than 1 hour
for Shadow) during which the Tor network composition is
signiﬁcantly changing (see Figure 1).
Scalable Simulations: Our new models and Shadow en-
hancements enable researchers to run larger networks faster
than was previously possible. We demonstrate our improve-
ments to scalability in two ways. First, we compare in the
top part of Table 2 the resources required for the 31% experi-
ments described above. We distinguish total run time from the
(a) Circuit Build (b) Circuit RTT (c) DL Error Rate (d) DL Goodput
(e) TTLB 50 KiB (f) TTLB 1 MiB (g) TTLB 5 MiB (h) Relay Goodput
Figure 2: Results from 10 simulations at network scale s = 0.31
(modeled using Tor network state from 2019-01) and 1 simulation
using state-of-the-art methods from CCS 2018 [38] (modeled us-
ing Tor network state from 2018-01) compared to reproducible Tor
metrics [68] during the respective years. Shown are benchmark
client metrics for: (a) circuit build times; (b) round trip times (time
from data request to ﬁrst byte of response); (c) download error rate;
(d) download goodput (i.e., transfer rate for range [0.5 MiB, 1 MiB]
over 1 MiB and 5 MiB transfers), and (e)–(g) download times for
transfers of size 50 KiB, 1 MiB, and 5 MiB. Relay goodput in (h) is,
for each second, the sum over all relays of application bytes written
(extrapolated by a 1/0.31 factor to account for scale). (Note that
circuit times in (a) are unavailable in the CCS 2018 model [38].)
The shaded areas represent 95% conﬁdence intervals (CIs) that were
computed following our method from §5.
time required to bootstrap all Tor relays and clients, initialize
all trafﬁc generators, and reach steady state. We reduced the
time required to execute the bootstrapping process by 2 days,
18 hours, or 80%, while we reduced the total time required to
run the bootstrapping process plus 25 simulated minutes of
steady state by 33 days, 12 hours, or 94%. The ratio of real
time units required to execute each simulated time unit dur-
ing steady state (i.e., after bootstrapping has completed) was
reduced by 96%, further highlighting our achieved speedup.
When compared to models of the same s = 31% scale from
previous work, we observed that our improvements reduced
the maximum RAM required to run bootstrapping plus 25 sim-
ulated minutes of steady state from 2.6 TiB down to 932 GiB
(a total reduction of 1.7 TiB, or 64%).
Second, we demonstrate how our improvements enable
us to run signiﬁcantly larger models by running three Tor
models at scale s = 1.0, i.e., at 100% of the size of the true
Tor network. We are the ﬁrst to simulate Tor test networks of
this scale.13 The bottom part of Table 2 shows that each of
12Although the models used Tor data spanning one month, we consider it
reasonable to reﬂect the general state of Tor throughout the respective year.
13We attempted to run a 100% scale Tor network using the CCS 2018
model [38], but it did not complete the bootstrapping phase within 30 days.
USENIX Association
30th USENIX Security Symposium    3421
2019-01-012019-01-052019-01-092019-01-132019-01-172019-01-212019-01-252019-01-292019-02-010200040006000RelayCountRemainingfrom2019-01-01NewlyJoinedsince2019-01-01Tor2019ThisWork(s=0.31)Tor2018CCS2018(s=0.31)CDF0510Time(sec)0.000.250.500.751.000612Time(sec)0.000.250.500.751.00100101102ErrorRate(%)0.000.250.500.751.0002040Goodput(Mbit/s).0.000.250.500.751.00CDF0816Time(sec)0.000.250.500.751.0002550Time(sec)0.000.250.500.751.0004080Time(sec)0.000.250.500.751.00120160200Goodput(Gbit/s)0.000.250.500.751.00(a) Circuit Build (b) Circuit RTT (c) DL Error Rate (d) DL Goodput
(e) TTLB 50 KiB (f) TTLB 1 MiB (g) TTLB 5 MiB (h) Relay Goodput
Figure 3: Results from 3 simulations at network scale s = 1.0 (mod-
eled using Tor network state from 2019-01) compared to repro-
ducible Tor metrics [68]. The metrics are as were deﬁned in the
Fig. 2 caption. The shaded areas represent 95% conﬁdence intervals
(CIs) that were computed following our method from §5.
17 hrs.
2 days, 2 hrs.
Scale s(cid:63) RAM Bootstrap Time Total Time
Table 2: Scalability improvements over the state of the art
Model
Ω◦
CCS’18 [38]† 31% 2.6 TiB 3 days, 11 hrs. 35 days, 14 hrs. 1850
This work†
79
This work‡
31% 932 GiB
8 days, 6 hrs.
100% 3.9 TiB 2 days, 21 hrs.
310
(cid:63) 31%: ≈2k relays and ≈250k users; 100%: 6,489 relays and 792k users
◦ Ω: ratio of real time / simulated time in steady state (after bootstrapping)
† Using 8×10-core Intel Xeon E7-8891v2 CPUs each running @3.2 GHz.
‡ Using 8×18-core Intel Xeon E7-8860v4 CPUs each running @2.2 GHz.
our 100% Tor networks consumed at most 3.9 TiB of RAM,
completed bootstrapping in 2 days, 21 hours, and ran the
entire simulation (bootstrapping plus 25 simulated minutes
of steady state) in 8 days, 6 hours. We show in Figure 3
that our 100% networks also achieve similar performance
compared to the metrics published by Tor [68]. Our results
are plotted with 95% conﬁdence intervals to better understand
how well our sampling methods are capable of reproducing
the performance characteristics of the true Tor network. We
describe how to conduct such a statistical inference in §5 next.
5 On the Statistical Signiﬁcance of Results
Recall that our modeling methodology from §3.2 produces
sampled Tor networks at scales of 0  0 Tor networks according
to §3.2. The ith resulting Tor network is associated with a
work and the relays that were chosen when generating it. To
probability distribution (cid:98)Pi(X) which is speciﬁc to the ith net-
estimate (cid:98)Pi(X), we run mi > 0 simulations in the ith Tor net-
3422    30th USENIX Security Symposium
USENIX Association
Tor2019ThisWork(s=1.0)with95%CICDF0510Time(sec)0.000.250.500.751.000.01.53.0Time(sec)0.000.250.500.751.00100101102ErrorRate(%)0.000.250.500.751.0002550Goodput(Mbit/s).0.000.250.500.751.00CDF048Time(sec)0.000.250.500.751.0002040Time(sec)0.000.250.500.751.0004080Time(sec)0.000.250.500.751.00150175200Goodput(Gbit/s)0.000.250.500.751.00true probability distribution of random variable X
Table 3: Symbols used to describe our statistical methodology.
Symbol Description
P(X)
FX (x) cumulative distribution function of X at x such that P(X ≤ x)
F−1
X (y) inverse distribution function of X at y such that y = FX (F−1
µ(y)
ε(y)
n
estimate of inverse distribution function at quantile y
error on inverse distribution estimate at quantile y
number of independently sampled Tor networks
X (y))
mi
νi j
Xi and F−1
X
Xi (y) at quantile y by taking the
Xi (y) inverse distribution function of X in network i at quantile y
Xi j (y) inverse distribution function of X from sim j in net i at quantile y
mean over the mi empirical distributions from network i:
work. During the jth simulation in the ith network, we sample
number of simulations in sampled Tor network i
number of samples of X collected from sim j in net i
estimate of inverse distribution function in network i at quantile y
error on inverse distribution estimate in network i at quantile y
byte measurements from the simulation). These νi j samples
i=1 mi
(cid:98)Pi(X) probability distribution over X in network i
(cid:98)FXi(x) cumulative distribution function of X at x such that(cid:98)Pi(X ≤ x)
(cid:98)F−1
(cid:98)µi(y)
(cid:98)εi(y)
(cid:101)Ei j(X) empirical distribution over νi j samples of X from sim j in net i
(cid:101)FXi j(x) cumulative distribution function of X at x such that(cid:102)Ei j(X ≤ x)
(cid:101)F−1
νi j values of X from (cid:98)Pi(X) (i.e., we collect νi j time to last
form the empirical distribution (cid:101)Ei j(X), and we have ∑n
then estimate the inverse distributions (cid:98)F−1
tions (cid:98)Pi(X) and P(X), respectively.
First, we estimate each (cid:98)F−1
j=1(cid:101)F−1
(cid:98)F−1
Xi (y) =(cid:98)µi(y) = 1
We refer to (cid:98)µi as an estimator of (cid:98)F−1
distribution (cid:98)FXi(x) =(cid:98)Pi(X ≤ x).
F−1
X (y) ≈ µ(y) = 1
such distributions in total (one for each simulation).
Estimating Distributions: Once we have completed the sim-
ulations and collected the ∑n
i=1 mi empirical distributions, we
associ-
ated with the sampled network and true probability distribu-
Xi ; when taken over a
range of quantiles, it allows us to estimate the cumulative
n ∑n
We refer to µ as an estimator of F−1