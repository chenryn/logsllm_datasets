title:Heavy Hitter Estimation over Set-Valued Data with Local Differential
Privacy
author:Zhan Qin and
Yin Yang and
Ting Yu and
Issa Khalil and
Xiaokui Xiao and
Kui Ren
Heavy Hitter Estimation over Set-Valued Data with Local
Differential Privacy
Zhan Qin1,3∗
PI:EMAIL
Issa Khalil1
PI:EMAIL
Yin Yang2
PI:EMAIL
Xiaokui Xiao4
PI:EMAIL
Ting Yu1
PI:EMAIL
Kui Ren3
PI:EMAIL
1Qatar Computing Research Institute, Hamad Bin Khalifa University, Qatar
2College of Science and Engineering, Hamad Bin Khalifa University, Qatar
3Department of Computer Science Engineering, State University of New York at Buffalo, USA
4School of Computer Science and Engineering, Nanyang Technological University, Singapore
ABSTRACT
In local diﬀerential privacy (LDP), each user perturbs her
data locally before sending the noisy data to a data collector.
The latter then analyzes the data to obtain useful statistics.
Unlike the setting of centralized diﬀerential privacy, in LDP
the data collector never gains access to the exact values of
sensitive data, which protects not only the privacy of data
contributors but also the collector itself against the risk of
potential data leakage. Existing LDP solutions in the liter-
ature are mostly limited to the case that each user possesses
a tuple of numeric or categorical values, and the data collec-
tor computes basic statistics such as counts or mean values.
To the best of our knowledge, no existing work tackles more
complex data mining tasks such as heavy hitter discovery
over set-valued data.
In this paper, we present a systematic study of heavy hit-
ter mining under LDP. We ﬁrst review existing solutions,
extend them to the heavy hitter estimation, and explain why
their eﬀectiveness is limited. We then propose LDPMiner,
a two-phase mechanism for obtaining accurate heavy hitters
with LDP. The main idea is to ﬁrst gather a candidate set
of heavy hitters using a portion of the privacy budget, and
focus the remaining budget on reﬁning the candidate set in a
second phase, which is much more eﬃcient budget-wise than
obtaining the heavy hitters directly from the whole dataset.
We provide both in-depth theoretical analysis and extensive
experiments to compare LDPMiner against adaptations of
previous solutions. The results show that LDPMiner signif-
icantly improves over existing methods. More importantly,
∗This work was conducted while the ﬁrst author was doing
internship at Qatar Computing Research Institute.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’16, October 24-28, 2016, Vienna, Austria
c(cid:13) 2016 ACM. ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978409
LDPMiner successfully identiﬁes the majority true heavy
hitters in practical settings.
Keywords
Local Diﬀerential Privacy; Heavy Hitter
1.
INTRODUCTION
Nowadays, with the advance of big data analytics, orga-
nizations have become increasingly interested in collecting
and analyzing user data. For example, web browsers and
mobile apps often collect system logs and usage patterns as
a means to guide the development of future versions; crowd-
sourcing platforms, such as Mechanical Turk1, also provide
a convenient way to collect information from contributors.
However, the collection of user data could incur signiﬁcant
privacy risks, as demonstrated in several past incidences,
e.g., [15, 32], where accidental leakage of sensitive data led to
public outrage, reputation damage, and legal actions against
the data collector.
Local diﬀerential privacy (LDP) is the state-of-the-art ap-
proach to addressing the privacy concerns in data collection,
which has been implemented in the Google Chrome browser
[12]. Its main idea is to ensure that the data collector (i)
never collects or possesses the exact values of any personal
data, and yet (ii) would still be able to derive general statis-
tics about the users. In particular, in LDP, each user locally
perturbs her data under diﬀerential privacy [10], which is a
strong and rigorous notion of privacy that provides plausi-
ble deniability; then, the user sends the perturbed data to
the collector. As such, LDP protects both the users (against
privacy risks) and the data collector itself (against damages
caused by potential privacy breaches).
However, since LDP is a relatively new concept, existing
solutions are mostly limited to obtaining statistics over a
single numeric or categorical attribute, such as select-count
[12], marginals [13] and histograms [3]. Similarly, multi-
dimensional data analysis under LDP is also limited to sim-
ple numeric or categorical attributes, or the most basic types
of aggregates, e.g., mean of each attribute [8]. As a conse-
quence, existing solutions for LDP are inadequate for more
1https://www.mturk.com
complex types of data mining tasks. In particular, consider
the problem of identifying heavy hitters over set-valued data,
where (i) each user has a set of up to l items (e.g., web pages
browsed, movies watched, locations visited, books purchased
from an online store), and (ii) we aim to identify the top-k
most frequent items among all users. Heavy hitter discov-
ery is a well studied problem in data mining with numerous
important applications, such as marketing analysis, cyber-
attack detection and trend monitoring. As we show in Sec-
tion 3, if we extend existing solutions to the heavy hitter
problem, they would incur both prohibitively high commu-
nications overhead and low utility of result. One main rea-
son for their ineﬃciency and ineﬀectiveness is that each user
reports to the data collector much information that is not rel-
evant to the ﬁnal result, i.e., items not in the ﬁnal top-k list.
This incurs large communication costs, as well as a waste
of the privacy budget, which is a key concept in diﬀerential
privacy whose usage is negatively correlated with the utility
of results.
To address the deﬁciency of the existing solutions, we pro-
pose LDPMiner, a novel algorithm for mining heavy hitters
under local diﬀerential privacy. The main idea of LDPMiner
is to employ a two-phase framework: the ﬁrst phase iden-
tiﬁes a candidate set for the top-k frequent items, and the
second phase focuses the remaining privacy budget on reﬁn-
ing the candidates, rather than spread it over all items in
the universe. Both phases are non-trivial because (i) they
operate on set-valued data, (ii) they involve only constant
communication cost, and (iii) they achieve an error rate that
is both empirically small and asymptotically optimal. In ad-
dition, there is synergy between the two phases: a user that
reports the same items in both phases can do so with a re-
duced amount of perturbations, while still satisfying diﬀer-
ential privacy. In-depth theoretical analysis and extensive
experiments using real data conﬁrm the eﬀectiveness, eﬃ-
ciency, and practical value of LDPMiner.
The remainder of this paper is organized as follows. Sec-
tion 2 provides the background on LDP and the existing
LDP solutions for heavy hitter estimation. Section 3 formu-
lates the problem and describes naive solutions. Section 4
presents the general framework of LDPMiner and elaborates
on the algorithms used in the two phases of LDPMiner. Sec-
tion 5 presents a thorough experimental evaluation. Section
6 surveys related work. Section 7 concludes the paper with
directions for future work.
2. BACKGROUND
2.1 Local Differential Privacy
Local diﬀerential privacy (LDP) [22, 14] is a data collec-
tion framework based on -diﬀerential privacy [10]. Under
this framework, each data contributor (e.g., a user of a web-
site) locally perturbs her own data using a randomized mech-
anism that satisﬁes -diﬀerential privacy, before sending the
noisy version of her data to a data collector. Speciﬁcally, a
randomized mechanism M satisﬁes -diﬀerential privacy, if
and only if for any two neighbor databases D and D(cid:48) (ex-
plained shortly) that diﬀer in exactly one record, and any
possible output s of M, we have the following inequality:
P r[M(D) = s]
P r[M(D(cid:48)) = s]
≤ e
(1)
Intuitively, given an output s of mechanism M, an ad-
versary cannot infer with high conﬁdence (controlled by )
whether the input database is D or its neighbor D(cid:48), which
provides plausible deniability for individuals involved in the
sensitive database. Here,  is a system parameter called the
privacy budget that controls the strength of privacy protec-
tion. A smaller  signiﬁes stronger privacy protection, since
the adversary has lower conﬁdence when it tries to distin-
guish between D and D(cid:48).
The concept of diﬀerential privacy was originally proposed
for the setting where a trusted data curator, who possesses
a database containing the exact data records from multiple
individuals, publishes perturbed statistics derived from the
database using a randomized mechanism. Hence, the deﬁni-
tion of diﬀerential privacy involves the notion of “neighbor
databases”. In contrast, in LDP, there is no trusted data cu-
rator; instead, each individual perturbs her own data record
under -diﬀerential privacy. In this situation, D and D(cid:48) are
two singleton databases, each containing exactly one record.
Since two neighbor databases diﬀer by exactly one record,
essentially D and D(cid:48) represent two arbitrary records. In the
problem studied in this paper (described in Section 3), ev-
ery record is a set of items, and each of D and D(cid:48) represents
such an item set.
An important property of diﬀerential privacy is sequential
composability, which is elaborated by McSherry in [26]:
Theorem 2.1. Given t random mechanisms Mi (1 ≤ i ≤
t), each of which satisﬁes i-diﬀerential privacy. Then, the
sequence of Mi(D) satisﬁes(cid:0)(cid:80)t
(cid:1)-diﬀerential privacy.
i=1 i
As pointed out in [26], sequential composition applies even
when the t mechanisms are not independent, i.e., subsequent
mechanisms can incorporate the outcomes of the preceding
mechanisms. In other words, these mechanisms can be arbi-
trary functions of the input database and preceding outputs.
Since record perturbation mechanisms in LDP satisfy diﬀer-
ential privacy, they can also be sequentially composed. Ac-
cordingly, given a privacy budget , each user can partition 
into multiple portions and use each portion to release certain
randomized information under diﬀerential privacy. This is
the foundation of the proposed two-phase framework, elab-
orated in Section 4.
2.2 Existing LDP Solutions
An LDP solution includes both (i) a user-side data per-
turbation mechanism and (ii) an algorithm executed by the
data collector for computing statistical information from the
noisy data received from the users. The former one’s main
requirement is to satisfy diﬀerential privacy. Theoretically,
every diﬀerentially private mechanism can be potentially ap-
plied to the LDP setting to be run at each user. In reality,
however, most mechanisms for enforcing diﬀerential privacy
are designed to run at a central data curator who has access
to the exact records of all users, with the goal of publish-
ing perturbed statistics based on these records.
In LDP,
neither assumptions holds, since the privacy protection al-
gorithm is run by individual users who do not have access to
other user’s data, and that the information to be released is
the perturbed data, not analysis results. Consequently, al-
though the fundamental mechanisms for diﬀerential privacy
such as the Laplace mechanism [10] and the geometric mech-
anism [16] can be applied to LDP, more sophisticated ones,
e.g., for the frequent itemset mining [25], cannot be applied
to LDP as they require global knowledge of all users’ data.
Further, perturbing the data at the user side is only part
of the solution; traditional diﬀerentially private mechanisms
do not address the other important problem in LDP, i.e.,
computing statistics at the data collector based on individ-
uals’ noisy data. Hence, conventional solutions for enforcing
diﬀerential privacy are largely inadequate for the LDP set-
ting.
In the following, we overview LDP solutions, which
have attracted signiﬁcant attention fairly recently.
Randomized Response.
It has been pointed out (e.g.,
in [12]) that a classic randomized response (RR) technique
commonly used in statistics can be adapted to LDP. Specif-
ically, RR asks each user a sensitive question whose answer
can be either yes or no, e.g., “Are you HIV positive?” The
goals are (i) that each user answers the question with plausi-
ble deniability, and (ii) that the data collector can compute
an unbiased estimate of the percentage of users whose an-
swer is “yes” (resp. “no”). To do so, each user ﬂips a coin
before answering the question. If the coin turns head, the
user provides her true answer (let’s say it is “yes”); other-
wise, she reports the opposite of her true answer (i.e., “no”).
To adapt RR to satisfy LDP, we make the coin biased, with
a probability p (resp. 1 − p) to turn head (resp. tail). It
has been proven (e.g., in [12]) that RR satisﬁes -diﬀerential
privacy with the following value of p:
p =
e
1 + e
(2)
Next we clarify how the data collector in RR estimates
the percentage of users with an “yes” answer.
If the data
collector simply outputs the percentage of “yes” among the
noisy answers (denoted by c), the results would be biased,
due to the random perturbations performed at the users. To
correct this, the data collector reports the following adjusted
estimate:
(cid:48)
c
= c × c, where c =
1
1 − 2p
(3)
RR is limited to the case where each user answers a binary
question. Nevertheless, it is a fundamental building block
for more sophisticated LDP solutions, explained below.
RAPPOR. RAPPOR [12, 13] extends RR to more com-
plex data types at the user as well as more sophisticated
statistics at the data collector. The most relevant problem
addressed by RAPPOR is frequency estimation over cate-