current status quo is reportedly missing many issues, accu-
rately assessing few of them, and only sometimes properly
mitigating them [19]. To make progress, we must develop re-
search protocols that respect client well-being, are cognizant
of safety risks, weigh the relative beneﬁts of research to those
risks, and, overall, minimize the potential for harm.
We therefore put into place a multifaceted strategy for
performing this research responsibly. We partnered with the
New York City Mayor’s Ofﬁce to End Domestic and Gender-
Based Violence (ENDGBV) [16], which runs Family Justice
USENIX Association
28th USENIX Security Symposium    107
Centers (FJCs) [17] in each borough of New York City (NYC).
The FJCs provide a diverse array of resources for IPV victims,
including police, legal, mental health, housing assistance, and
more. All research protocols were approved not only by our
institutional IRB but also by the ENDGBV leadership.
Our consultation protocols went through a thorough, it-
erative design process that: (1) started with initial designs
grounded in ﬁndings from prior work [19, 20, 27]; (2) a two-
month process of iterative and incremental reﬁnements driven
by focus groups with relevant IPV professionals; (3) a re-
view and approval process with the ENDGBV leadership of
our reﬁned protocols and instruments for client consultations;
and (4) an ongoing reﬁnement process that was responsive to
needs that arose during client consultations.
This process maximized the amount of meaningful research
we could do before interacting with clients. In step (2) we
conducted 14 rounds of iterative design with a total of 56
IPV professionals. Each round involved a 60–90 minute fo-
cus group held at one of the FJCs, in which we summarized
the current consultation design, demonstrated our methods,
and gave participants copies of our questionnaires and ma-
terials. They were encouraged to edit, rewrite, and redesign
them. We took detailed notes. Data analysis was performed
immediately after each focus group, consisting of a detailed
assessment of our notes with a speciﬁc focus on suggestions
for improvements or changes. In subsequent sections, we
give examples of quotes emanating from focus groups that
help explain, or led to changes in, our consultation protocol.
These quotes are illustrative and not intended to represent a
comprehensive thematic analysis of the focus groups.
After nine rounds of changes based on participant feedback,
we had several consecutive focus groups that did not elicit any
new suggestions. We therefore determined our procedure and
methods were ready for a review and approval process with
the ENDGBV. This involved presentations to, and discussions
with, ENDGBV leadership about our protocol. Ultimately,
we and the ENDGBV concluded that it was ready for use with
clients due to (i) the sufﬁciency of safety procedures we put
in place to minimize potential harm to clients, and (ii) the
fact that the ENDGBV leadership concluded that our research
would beneﬁt their clients. We discuss our safety procedures
for consultations in detail in Section 6.
Finally, we note that safety issues extend also to the well-
being of the participating researchers. In addition to the po-
tential for vicarious trauma or other emotional strain, spyware
could in theory leak recordings of consultations to abusers.
We discuss self-care and researcher safety in Section 6.
4 A Consultation Protocol for IPV Victims
We created and reﬁned a ﬁrst-of-its-kind protocol for con-
ducting a tech consultation in which a trained volunteer with
expertise in technology meets face-to-face with an IPV victim.
We refer to the volunteer as the tech consultant, or simply
Figure 1: Summary of how a client participates in a tech con-
sultation, beginning with a referral from an IPV professional.
consultant, and the victim as the client. A diagrammatic
overview of our consultation procedure appears in Figure 1.
We give a high level walk-through, and provide more details
about various aspects of the procedure starting in Section 4.1.
Throughout we give examples of how the iterative design
process with stakeholders impacted our design.
We use a referral model that ensures safe integration of our
consultations into NYC’s existing survivor support services.
Upon setting an appointment and meeting with a client, we
use a procedure that we refer to as understand-investigate-
advise (UIA). This emphasizes three important aspects of the
consultation: understanding tech risks in the client’s digital
footprint, investigating their root causes, and providing advice
about how they might improve their digital security.
To maximize the efﬁcacy of the UIA procedure, we devel-
oped a number of non-technical and technical instruments
to aid consultants, including: a technology assessment ques-
tionnaire, a diagrammatic approach called a technograph for
mapping a client’s digital footprint, guides for reminding con-
sultants how to check security settings for common services
and devices, and a software tool called ISDi (IPV Spyware
Discovery) that can safely detect the kinds of spyware re-
ported as used in IPV settings by prior work [8]. We also
developed a number of training materials, checklists, and as-
sociated protocols to help prepare consultants for meeting
with clients. These instruments were reﬁned via focus groups
with professionals as well as in an ongoing manner as we
gained experience working with clients.
Integration into Client Support Services
4.1
One of the ﬁrst questions we faced is how to make tech con-
sultations ﬁt into the broader landscape of victim support
services, such as legal, ﬁnancial, and social services. Al-
though consultants will be qualiﬁed to provide assistance
with technology security and privacy, they will not necessar-
ily be qualiﬁed to help with overall safety planning, legal
advice, mental health, or other aspects of a client’s case. It
is therefore essential that other IPV professionals are able to
assist the client before, during, and after a consultation.
To ensure all clients have appropriate support from an IPV
professional, we use a referral model in which consultants
only see clients that are referred to them by other IPV profes-
sionals for potential tech problems. Using a referral model
108    28th USENIX Security Symposium
USENIX Association
has signiﬁcant safety and procedural beneﬁts over alternative
models. In particular, the referring professional will know the
client’s background and abuse history and be qualiﬁed to help
them safety plan around the results of the consultation (e.g.,
if it is safe to change their privacy settings, remove apps, etc.).
If possible, and if the client is comfortable, we encourage the
referring professional (or client case manager) to be present
during the consultation so that they can also discuss their
questions or concerns with the consultant.
Referral models have other beneﬁts as well. They allow
us to balance client anonymity with continuity of care, since
the professional can serve as a safe communication channel
between the consultant and client. This speciﬁcally enables
consultants to perform followups for issues that cannot be
fully investigated during a consultation. For example, we
saw clients asking about esoteric or non-English apps, hav-
ing browser extensions that are not on the extension market,
and describing seemingly inexplicable tech situations.
In
such cases, we perform further research on the topic after the
consultation, and communicate any discoveries back via the
referring professional. If appropriate, the client may elect to
participate in a second consultation, which happened a couple
times so far in our work.
Regardless of followup requirements, when a consulta-
tion is complete (and with client permission) the consultant
performs a hand-off procedure that communicates relevant
ﬁndings to the referring professional. If the professional is
in the room, this may happen at the end of the consultation.
Otherwise, it happens via email or phone call. This hand-off
is vitally important. First because it facilitates proper safety
planning, as we discuss later in the section. In addition, it
provides some reassurance to clients potentially frightened by
a consultation’s discoveries. As one professional described,
our hand-off procedure:
“...might help the client feel a little bit more com-
fortable. ‘Oh my gosh, I’m being tracked. At least
I know there’s an ofﬁcer that can help me with this
situation.’ You’re also aware of what’s going on as
a screener, as well as a case manager. I have three
different backups. I think it was very well done.”
(P36, Case Manager)
4.2 Understand-Investigate-Advise Procedure
When the client arrives for a consultation, we follow stan-
dard IPV advocacy practices and take a client-centered ap-
proach [31], which assumes the client knows best regarding
their own situation and will be the one to make decisions.
One professional described client-centered practice as:
“having a conversation with the client and ... let-
ting the client formulate their decisions, their an-
swers. [Professionals] cannot provide them with
[answers] because they’re the only ones who know
what risks are being posed.” (P36, Case Manager)
Therefore, taking a client-centered approach, the consultant
begins by asking the client what their main concerns are
and/or what caused them to seek out a consultation. We refer
to these as their chief concerns3 and a primary goal of the
consultant is to try to accurately identify them. For example,
we heard clients express fear that spyware was installed on
their devices, that their “phones were tapped”, or that their
abuser had access to information they should not have (e.g.,
a client’s photos). In some cases the chief concerns are not
very clear and take some gentle questioning to ascertain.
From this starting point, the tech consultant will utilize
a wide range of instruments and tools that we have created
to (1) understand the client’s digital footprint and entangle-
ments to identify potential avenues for harm; (2) investigate
their devices, apps, and services to look for, and assess the
root cause(s) of, their tech problems; and (3) advise clients
on how they might move forward. See Figure 1.
Understanding footprint and entanglements. Prior work
on tech and IPV [14, 19, 27, 34, 43] indicates that there are no
best practices or standard procedures for asking about tech
risks or understanding the root cause(s) of client concerns.
The lack of standardized procedures may contribute to serious,
on-going tech abuse being overlooked. We therefore created
several instruments that help systematize the discovery and
assessment of tech problems in IPV.
To systematize problem discovery, we created and reﬁned
a Technology Assessment Questionnaire, or TAQ (Figure 5
in the Appendix). We started with questions that aimed to
uncover common problems surfaced in prior work [20], such
as risk of device/account compromise if the abuser knows or
can guess the client’s passwords (e.g., their password is their
child’s birthday), or ownership-based risks, when the abuser is
the legal owner of the client’s devices or accounts. Feedback
from focus groups helped us reﬁne question wording, and
include additional questions that professionals thought would
be helpful. As one example, we received many suggestions
on the importance of asking about children’s devices. As one
professional told us,
“[For parents] with younger kids, I think another
question that might be important is asking if your
children go on visits and if they take their electron-
ics with them on visits.” (P40, Social Worker)
We added ﬁve questions about risks with children’s devices.
This feedback was particularly helpful, as we saw several
cases in our ﬁeld study of children’s devices being the likely
avenue by which the abuser had access to client data.
To support a client-centered approach, the TAQ is designed
to be used as a reference to ensure consultants cover important
3In medicine, this would be called a chief complaint, but we feel that
‘concern’ is more client-centered.
USENIX Association
28th USENIX Security Symposium    109
topics, rather than as a prescribed interview format. The
consultant lets the client lead the conversation and discuss
topics they ﬁnd important, which often touches on a subset
of the TAQ. The consultant uses the TAQ to remember to
raise remaining topics that the client may not have thought
about. We arrived at this approach after early feedback from
professionals that it is more empowering to let clients drive
conversations, rather than peppering them with questions.
A challenge that came up in early consultations is building
a mental map of the client’s digital footprint and entangle-
ments. Carol’s example in Section 2 illustrates the potential
complexity of client technology use. In the ﬁeld, clients often
came with half a dozen devices, many accounts, an involved
abuse timeline, and various pieces of (often circumstantial)
evidence of account or device compromise (e.g., the abuser
keeps tracking or calling them despite changing phones). It is
easy for consultants to lose track of relevant details.
We therefore created the technograph, a visual map
loosely inspired by genograms, a technique used by clinicians
in medicine and behavioral health to map family relationships
and histories [22]. The technograph uses shapes and symbols
to visually document relationships between (1) devices, (2) ac-
counts, and (3) people (usually the client’s family). Drawing
connections between entities gives the consultant a clearer
picture of potential sources of compromise. An example that
may have been created discussing Carol’s situation appears
in the full version of this paper.
The technograph is particularly helpful to identify when
abusers may have indirect access to a client’s digital assets.
For example, two-factor authentication for iCloud accounts
can be bypassed if a child’s device is a contact for the ac-
count. Another example is when family plans synchronize
data across devices and accounts. The technograph allows
tracing these potential indirect access routes more easily.
Investigating devices, accounts, and services. After using
the TAQ and technograph to construct a clearer picture of
the client’s situation, the next phase of the consultation is
to thoroughly investigate devices, accounts, or services that
may be compromised by the abuser. We created tools that
investigate in two ways: (1) by scanning the client’s mobile
devices for spyware or other unwanted surveillance apps using
a new IPV Spyware Discovery (ISDi) tool that we built, and
(2) by manually checking the privacy conﬁgurations of the
client’s devices, apps, and accounts. We discuss each in turn.
As we detail later, most clients have hundreds of apps on
their devices. In addition to the threat of spyware-capable
apps being installed surreptitiously, many otherwise legiti-
mate apps may be conﬁgured by the abuser to act as spyware.
For example, Google maps can be conﬁgured to update an
abuser about the client’s location, and while it provides vari-
ous notiﬁcations that tracking is ongoing, their effectiveness is
uncertain. We therefore have a dichotomy between unwanted
and wanted apps, with the mere presence of the former being
sufﬁcient for a safety discussion whereas the latter require
investigation into their conﬁguration.
Detecting unwanted apps manually via the user interface
(UI) will not work: many IPV spyware apps can effectively
hide their presence from the UI [8]. Indeed, current state-of-
the-art practice by non-technologist professionals is to use
circumstantial evidence to conclude spyware is installed, e.g.,
if a phone acts “glitchy” it most likely has spyware and should
be reset if not discarded [20]. We therefore constructed an
IPV Spyware Discovery (ISDi) tool for detecting unwanted
apps on a client’s iOS or Android devices. It also checks if the
device has been jailbroken (for iOS) or rooted (for Android),
which may indicate that dangerous spyware is installed. With
the client’s permission, the consultant uses ISDi to program-
matically obtain via USB connection the apps installed on
their devices, highlighting ones that are known to be risky in
IPV. Should the device be detected as rooted/jailbroken or
any risky apps found, the consultant can discuss whether the
client rooted the phone, recognizes the app, etc.
Our focus groups with professionals helped us iterate on
the user ﬂow and understand how best to integrate the tool into
client consultations. We learned that clients and professionals
want to view and understand the steps required to use the tool
as well as visually examine the scan results. Professionals
expressed concern about communicating to clients appropri-
ately about privacy issues. One professional suggested that,
during a consultation, we say that:
“We will see and go through every application on
your phone, we will not see any information in your
social media, texts, photos. We will only see the