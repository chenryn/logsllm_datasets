# References

1. A. Ailamaki, D. J. DeWitt, M. D. Hill, and M. Skounakis. Weaving relations for cache performance. In VLDB, 2001.
2. Apache. Centralized cache management in HDFS. Available at: https://hadoop.apache.org/docs/r2.3.0/hadoop-project-dist/hadoop-hdfs/CentralizedCacheManagement.html
3. Apache. HDFS short-circuit local reads. Available at: http://hadoop.apache.org/docs/r2.5.1/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html
4. Apache. Sentry. Available at: http://sentry.incubator.apache.org/
5. P. Flajolet, E. Fusy, O. Gandouet, and F. Meunier. HyperLogLog: The analysis of a near-optimal cardinality estimation algorithm. In AOFA, 2007.
6. A. Floratou, U. F. Minhas, and F. Ozcan. SQL-on-Hadoop: Full circle back to shared-nothing database architectures. PVLDB, 2014.
7. G. Graefe. Encapsulation of parallelism in the Volcano query processing system. In SIGMOD, 1990.
8. C. Lattner and V. Adve. LLVM: A compilation framework for lifelong program analysis & transformation. In CGO, 2004.
9. S. Melnik, A. Gubarev, J. J. Long, G. Romer, S. Shivakumar, M. Tolton, and T. Vassilakis. Dremel: Interactive analysis of web-scale datasets. PVLDB, 2010.
10. S. Padmanabhan, T. Malkemus, R. C. Agarwal, and A. Jhingran. Block-oriented processing of relational database operations in modern computer architectures. In ICDE, 2001.
11. V. Raman, G. Attaluri, R. Barber, N. Chainani, D. Kalmuk, V. KulandaiSamy, J. Leenstra, S. Lightstone, S. Liu, G. M. Lohman, T. Malkemus, R. Mueller, I. Pandis, B. Schiefer, D. Sharpe, R. Sidle, A. Storm, and L. Zhang. DB2 with BLU Acceleration: So much more than just a column store. PVLDB, 6, 2013.
12. V. K. Vavilapalli, A. C. Murthy, C. Douglas, S. Agarwal, M. Konar, R. Evans, T. Graves, J. Lowe, H. Shah, S. Seth, B. Saha, C. Curino, O. Oâ€™Malley, S. Radia, B. Reed, and E. Baldeschwieler. Apache Hadoop YARN: Yet another resource negotiator. In SOCC, 2013.
13. T. Willhalm, N. Popovici, Y. Boshmaf, H. Plattner, A. Zeier, and J. Schaffner. SIMD-scan: Ultra fast in-memory table scan using on-chip vector processing units. PVLDB, 2, 2009.

## 8.5 Resource Management

Resource management in an open multi-tenancy environment, where Impala shares cluster resources with other processing frameworks such as MapReduce and Spark, remains an unsolved problem. The existing integration with YARN does not cover all use cases, and YARN's focus on a single reservation registry with synchronous resource reservation makes it difficult to accommodate low-latency, high-throughput workloads. We are actively investigating new solutions to address this issue.

## 8.6 Support for Remote Data Storage

Impala currently relies on the colocation of storage and computation to achieve high performance. However, cloud data storage services like Amazon S3 are becoming increasingly popular. Additionally, legacy storage infrastructure based on SANs necessitates the separation of computation and storage. We are actively working on extending Impala to access Amazon S3 (slated for version 2.2) and SAN-based systems. Beyond simply replacing local with remote storage, we are also planning to investigate automated caching strategies that allow for local processing without imposing additional operational burdens.

## 9. Conclusion

In this paper, we presented Cloudera Impala, an open-source SQL engine designed to bring parallel DBMS technology to the Hadoop environment. Our performance results showed that, despite Hadoop's origin as a batch processing environment, it is possible to build an analytic DBMS on top of it that performs as well as or better than current commercial solutions, while retaining the flexibility and cost-effectiveness of Hadoop.

In its current state, Impala can already replace traditional, monolithic analytic RDBMSs for many workloads. We predict that the gap in SQL functionality will diminish over time, allowing Impala to handle an increasing fraction of pre-existing data warehouse workloads. However, we believe that the modular nature of the Hadoop environment, where Impala leverages several standard components shared across the platform, confers advantages that cannot be replicated in a traditional, monolithic RDBMS. Specifically, the ability to mix file formats and processing frameworks means that a broader spectrum of computational tasks can be handled by a single system without the need for data movement, which is often one of the biggest impediments in data processing.