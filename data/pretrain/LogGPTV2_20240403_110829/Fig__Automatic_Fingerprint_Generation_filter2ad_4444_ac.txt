use a greedy algorithm to create such a ﬁngerprint that adds
queries until all the implementation classes can be classi-
ﬁed. This algorithm is guaranteed to ﬁnd a small set of
queries, since the problem is equivalent to the Set-Cover
problem [28].
Testing the ﬁngerprint Once the ﬁnal classiﬁcation func-
tion has been generated for each usable query, we test it
using a larger set of testing hosts whose implementation
classes are known, examining for each ﬁngerprint if it clas-
siﬁes all the hosts correctly. We then discard any ﬁngerprint
that does not classify the hosts correctly. This may hap-
pen if the training hosts are not representative of the imple-
mentation classes; however, in our experiments, this did not
happen.
4.4. Approximate Fingerprint Matching
Once shipped in a ﬁngerprint tool, the ﬁngerprints are
used to classify new hosts. Sometimes, however, no ﬁn-
gerprint may match a new host and then one simple ap-
proach might be to classify the host as unknown. However,
it could happen that the host truly belongs to one of the
known classes but has slight differences in its responses,
e.g. some network conﬁguration parameter has been man-
ually changed from the default. A more elaborate option
would be to try to ﬁnd an approximate match by calculating
the distance to all known classes and selecting the nearest
class [13, 19]. In this case, only if the new host is far from
all of the existing classes would the host be classiﬁed as
unknown.
Some current ﬁngerprinting tools such as Nmap1 have an
option to do approximate matching, where the tool will print
that no perfect match was found, but it was able to ﬁnd a
match with some percentage overlap. However, we need
to validate when such a match is meaningful: an approx-
imate matching is only meaningful when the behavior of
each implementation class is well-separated from the oth-
ers. So, we want to answer the following question: given a
feature-space, how can we tell when we can do approximate
matching, and how can we do approximate matching?
We answer this in the following manner: (a) ﬁrst we
use a clustering algorithm to cluster the responses from the
training hosts, (b) then, we examine the implementation
classes of the resulting clusters to check if the clusters truly
represent the implementation classes, that is, if each clus-
ter consists of a single implementation class and is well-
separated from the other clusters.
If the implementation
classes form well-separated clusters, the training hosts are
representative of their respective implementation classes,
and any un-represented implementation class is also well-
separated from these classes in this feature space, then we
can use approximate matching with this feature space to
classify new hosts that have no exact ﬁngerprint match.
There might be classes that spread over two or more clus-
ters, for example because hosts in the same class exhibit
one of two distinct behaviors. We deﬁne a z-gap property
that takes this into account, and needs to hold for a well-
separated clustering: the distance between any two hosts in
different implementation classes needs to be at least z times
the distance between any two hosts in the same cluster, be-
longing to the same implementation class.
To do the clustering, we examine two natural feature
spaces derived from the set of input candidate queries. In
the ﬁrst case, for each training host, we generate the set of
all distinct position-substrings for each ﬁeld in the response
1using equivalent options –osscan-guess or –fuzzy
to a single query, as described in Section 4.1. We then
remove all dynamic ﬁelds and use the remaining position-
substrings as features. In the second case, for each training
host, we generate the set of all distinct position-substrings
of length one byte in the response to a single query, and use
those as the features. This second case is independent of the
ﬁeld structure of the protocol and we use it to analyze the
impact of dynamic ﬁelds contained in the responses. In both
cases, the ﬁnal feature space is the cross product of the fea-
ture spaces that we have deﬁned for each query. Once the
ﬁnal feature space is deﬁned, the responses from each host
to different queries are then turned into a {0, 1}n vector in
these feature spaces. The distance metric we use for each
feature space is the squared Euclidean distance; so, the dis-
tance between two hosts is their squared Euclidean distance
when represented in the feature space.
With the z-gap property and a feature space, we can ap-
ply any clustering algorithm to test if there is a good cluster-
ing of the hosts. Here, we use X-means [24], an extension
of the standard k-means algorithm to the case where k is
unknown. We choose X-means over k-means because we
do not know k, and over hierarchical clustering because we
do not need to deﬁne a stopping criterion. In Section 5.4,
we see that this algorithm performs well when the imple-
mentation classes are well-separated.
Given a new host that needs an approximate match, we
do the following: we compute the distance from the host to
each of the clusters. If the host is within a distance d/z from
the nearest cluster, where d is the smallest distance between
any two clusters, we classify it into the nearest cluster. If
the host is farther away, we classify it as unknown. When
the z-gap property holds, this rule will give us the correct
matches. In Section 5.4, we show the results of using this
rule for classifying new hosts for OS and DNS ﬁngerprint-
ing.
5. Evaluation
We evaluate our results using 128 hosts from 3 differ-
ent implementation classes for the OS experiments, and 54
hosts from 5 different implementation classes for the DNS
experiments. Tables 1 and 2 show the number of hosts in
each implementation class for the OS and DNS experiments
respectively.
For the OS experiment we send queries to
open TCP ports, i.e. port 139 on Windows or port 22 on
Linux and Solaris.
5.1. Candidate Queries
For OS ﬁngerprinting several protocols such as TCP,
UDP or ICMP can be used. In this paper we focus on TCP,
Class ID Hosts OS class
Class 1
Class 2
Class 3
Windows XP SP2
Linux 2.6.11
Solaris 9
77
29
22
Table 1. Hosts used in TCP/IP evaluation.
Class ID Hosts DNS class
Class 4
Class 5
Class 6
Class 7
Class 8
BIND 8.3.0-RC1 – 8.4.4
BIND 9.2.3rc1 – 9.4.0a0
Windows Server 2003
MyDNS
TinyDNS 1.05
10
12
11
10
11
Table 2. Hosts used in DNS evaluation.
due to its rich semantics. As explained in Section 3, the
candidate query exploration phase uses domain knowledge
to select some ﬁelds to be explored exhaustively and others
to be explored only with selected values.
Table 3 shows the 305 TCP/IP candidate queries that
were explored in the candidate query exploration phase. We
emphasize that this exploration can be easily expanded and
is by no means complete, these candidate queries were se-
lected as examples to test the validity of the ﬁngerprint gen-
eration process. Three ﬁelds in the TCP header were ex-
plored using exhaustive search: the TCP ﬂags byte (Byte
12), and Byte 13 which comprises the Data Offset and the
Reserved ﬁelds [25]. For reference the TCP & DNS headers
are reproduced in Appendix B. The reason we performed
an exhaustive search on these ﬁelds is because they have
rich semantics, and because new functionality, such as the
ﬂags for Explicit Congestion Notiﬁcation [26], has not been
thoroughly explored. For the other ﬁelds, only a few cor-
ner cases that could potentially hold interesting information
were selected.
For DNS ﬁngerprinting, bytes 2 & 3 of the DNS
header were exhaustively searched. These bytes contain the
Opcode, Rcode and F lags ﬁelds. Also the Qtype ﬁeld in
the Question record [21] was exhaustively searched. Like
the selected TCP ﬁelds, these ﬁelds were chosen because
they have rich semantics and support numerous options.
5.2. Conjunction and Decision List Fingerprints
As explained in Section 4.2, for each candidate query,
the learning algorithm takes two steps in order to ﬁnd the
ﬁnal ﬁngerprint. First, it generates binary-ﬁngerprints for
each implementation class, which determine whether a host
belongs to this class or not. Then, the set of all binary-
ﬁngerprints for the same query forms the ﬁnal ﬁngerprint.
In our results, we show the number of binary and ﬁnal
ﬁngerprints found for the cases of OS and DNS ﬁngerprint
generation. For the OS experiments the features are ex-
tracted from the TCP/IP headers in the response, while for
the DNS experiments only the DNS header in the response
is used. We run the learning algorithms on the responses of
70% of the hosts in each class and test the resulting ﬁnger-
prints using the remaining 30% hosts. Any other split of the
host set is valid as long as there are sufﬁcient hosts in the
training set.
5.2.1 Binary and Final Fingerprints
Table 4 shows the number of binary and ﬁnal ﬁngerprints
identiﬁed in both steps of the algorithm for the OS and DNS
experiments.
For each experiment, a series of columns show the num-
ber of binary-ﬁngerprints for the corresponding implemen-
tation classes, while the rightmost column shows the num-
ber of ﬁnal ﬁngerprints. Each binary-ﬁngerprint for an im-
plementation class can decide whether or not a host belongs
to that class. The ﬁnal ﬁngerprint can classify the host into
any of the known classes, or state that the class is unknown.
As expected, the decision list algorithm outputs a decision
list ﬁngerprint in many cases where the conjunction algo-
rithm cannot output a conjunction ﬁngerprint – this happens
when the hosts that belong the class under consideration ex-
hibit multiple types of behavior.
The Final columns in Table 4 show that there is no ﬁ-
nal conjunction ﬁngerprint that can separate all the classes
in both the OS and DNS experiments. On the other hand,
there are 66 decision list ﬁngerprints in the OS experiment
that can classify hosts of all 3 classes, and 19 in the DNS
experiment that can classify hosts of all 5 classes.
Intuitively, as the number of known classes increases,
we expect to ﬁnd fewer queries that can classify hosts of
all known classes simultaneously. For example, when we
run the conjunction algorithm using only the Windows and
Linux classes, we ﬁnd 130 ﬁnal ﬁngerprints that can sep-
arate Windows and Linux hosts, but when we add Solaris,
we ﬁnd no ﬁnal ﬁngerprints that can classify hosts of all of
the three classes simultaneously. Note that as the number of
classes grows, we can apply the learning algorithms on sets
of queries, rather than on a single query. This will generate
ﬁngerprints that contain multiple queries, each individually
covering some subset of known classes and the whole ﬁn-
gerprint covering all classes.
Testing We evaluate the 66 OS and 19 DNS ﬁnal decision
list ﬁngerprints produced during the learning phase by send-
ing the corresponding queries, in the ﬁnal ﬁngerprint, to the
remaining 30% hosts in each implementation class. Each
of the ﬁnal ﬁngerprints properly classiﬁes all hosts in the
testing set into their true OS or DNS class.
Field
tcp sport
tcp offset
tcp reserved
tcp ﬂags
tcp window
tcp checksum
tcp urgentPtr
Size
16
4
4
8
16
16
16
Type
guided
exhaustive
exhaustive
exhaustive
guided
guided
guided
# Queries
9
16
16
256
2
2
4
Tested values
0,8,255,1023-4,49151-2,55000,65535
all
all
all
0, 65535
good, bad
invalid value with URG ﬂag set, value with URG ﬂag not set
Table 3. Candidate queries for OS ﬁngerprinting. A total 305 queries were tested. The ﬁeld size is
given in bits.
Fingerprint type
Conjunction ﬁngerprints
Decision list ﬁngerprints
Linux
Solaris Windows
Final
Bind8
Bind9 Microsoft MyDNS
TinyDNS
Final
42
130
53
98
53
98
0
66
0
33
0
28
22
32
2
29
9
41
0
19
OS
DNS
Table 4. Number of binary and ﬁnal ﬁngerprints output by the learning phase.
5.2.2 Fingerprint Examples
In this section, we show an example of the conjunction and
decision list ﬁngerprints for a speciﬁc TCP/IP query. First,
we show the conjunction binary-ﬁngerprint that separates
the Linux class from the other classes (we refer to this case
as Linux/NotLinux):
Query: tcp_flags=S+P;
if (Response: ip_id=0x0000,tcp_window=0x16d0)
then Linux
else NotLinux
As shown in the ﬁrst
line of the conjunction binary-
ﬁngerprint, this query explores the tcp ﬂags ﬁeld and has
the SYN+PUSH ﬂags set. This conjunction ﬁngerprint says
that if in the response, the IP identiﬁcation ﬁeld has a value
of zero and the TCP window has a value of 5,840 then the
host is Linux, otherwise it is NotLinux. The values of the
other ﬁelds in the response do not matter.
The conjunction binary-ﬁngerprint for this query exists
for the cases of Linux/NotLinux and Solaris/NotSolaris but
not for the case Windows/NotWindows. Next, we show
the corresponding decision list binary-ﬁngerprint for the
Linux/NotLinux case. Note that the decision list algorithm
is able to extract more than one rule for the NotLinux case.
Query: tcp_flags=S+P;
if (Response: tcp_window=0xffff)
then NotLinux
else if (Response: tcp_window=0x16d0)
then Linux
else if (Response: ip_verHdrLen=0x45,
ip_tos=0x00, ip_len=0x002c,
ip_flags&offset=0x4000, ip_protocol=0x06,
tcp_offsetReserved=0x60, tcp_flags=0x12,
tcp_urgentPtr=0x0000)
then NotLinux
Now, decision list binary-ﬁngerprints exist for all three
cases (Linux/NotLinux, Windows/NotWindows, and So-
laris/NotSolaris) and the system can generate the following
decision list ﬁnal ﬁngerprint that can classify a host into one
of all three classes simultaneously.
Query: tcp_flags=S+P;
if (Response: tcp_window=0xffff)
then Windows
else if (Response: tcp_window=0x16d0)
then Linux
else if (Response: tcp_window=0xc0a0)
then Solaris
else if (Response: ip_verHdrLen=0x45,
ip_tos=0x00, ip_len=0x002c,
ip_flags&offset=0x4000, ip_protocol=0x06,
tcp_offsetReserved=0x60, tcp_flags=0x12,
tcp_window=0x40e8, tcp_urgentPtr=0x0000)
then Windows
else Unknown
This ﬁnal ﬁngerprint shows that all Solaris hosts set the
tcp window to 49,312 and all Linux hosts set the value to
5,840 but the Windows hosts use two different values for
that ﬁeld: 65,535 or 16,616.
5.3. Interesting Queries
The ﬁnal ﬁngerprints generated in our experiments con-
tain some especially interesting queries because we are
not aware of any ﬁngerprinting tool that currently uses
them. Here, we give some selected examples of these novel
queries.
First, we ﬁnd that the hosts in the Windows and Solaris
classes respond to queries with an invalid value in the Data
Offset ﬁeld of the TCP header. This ﬁeld represents the
number of 32-bit words in the TCP header. The candidate
query should have a value of 5 (20 bytes) in this ﬁeld but
we deliberately send queries with this ﬁeld set to smaller
and larger values. Both Windows and Solaris hosts reply
with a SYN+ACK if the value in the ﬁeld is less than ﬁve,
while the Linux hosts do not reply to these incorrect values.
No host in any class replies to values larger than ﬁve. This
reveals that both Windows and Solaris fail to check the TCP
header for this simple case.
Second, we see that Windows and Linux hosts ignore the
values of the ECN or CWR bits in the queries but certain
combinations trigger a different response for Solaris hosts.
For example, a query with the SYN+PUSH+ECN+CWR
ﬂags all set, gets a SYN+ACK response from both Windows
and Linux but a SYN+ACK+ECN response from Solaris.
Finally, we ﬁnd that Linux and Solaris hosts set the TCP
Acknowledgment Number in a RST packet to zero but Win-
dows hosts set it to the value that was sent in the TCP Ac-
knowledgement Number ﬁeld of the query. This is interest-
ing because a single packet with the ACK ﬂag set, that is
sent to a closed port, can distinguish Windows hosts from
both the Linux and Solaris hosts. This type of query is very
inconspicuous and might be difﬁcult to ﬂag as a ﬁngerprint-
ing attempt.
Among the DNS queries we also ﬁnd interesting behav-
ior. For example, DNS servers should copy the value of the