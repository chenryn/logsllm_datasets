title:Side Effects Are Not Sufficient to Authenticate Software
author:Umesh Shankar and
Monica Chew and
J. D. Tygar
USENIX Association
Proceedings of the
13th USENIX Security Symposium
San Diego, CA, USA
August 9–13, 2004
© 2004 by The USENIX Association
Phone: 1 510 528 8649
All Rights Reserved
FAX: 1 510 548 5738
Rights to individual papers remain with the author or the author's employer.
Email: PI:EMAIL
For more information about the USENIX Association:
WWW: http://www.usenix.org
 Permission is granted for noncommercial reproduction of the work for educational or research purposes.
This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein.
Side effects are not sufﬁcient to authenticate software
Umesh Shankar(cid:3)
UC Berkeley
Monica Chew
UC Berkeley
J. D. Tygar
UC Berkeley
PI:EMAIL
PI:EMAIL
PI:EMAIL
Abstract
Kennell and Jamieson [KJ03] recently introduced the
Genuinity system for authenticating trusted software on
a remote machine without using trusted hardware. Gen-
uinity relies on machine-speciﬁc computations, incorpo-
rating side effects that cannot be simulated quickly. The
system is vulnerable to a novel attack, which we call a
substitution attack. We implement a successful attack on
Genuinity, and further argue this class of schemes are not
only impractical but unlikely to succeed without trusted
hardware.
1 Introduction
A long-standing problem in computer security is remote
software authentication. The goal of this authentica-
tion is to ensure that the machine is running the correct
version of uncorrupted software. In 2003, Kennell and
Jamieson [KJ03] claimed to have found a software-only
solution that depended on sending a challenge problem
to a machine. Their approach requires the machine to
compute a checksum based on memory and system val-
ues and to send back the checksum quickly. Kennell and
Jamieson claimed that this approach would work well in
practice, and they have written software called Genuin-
ity that implements their ideas. Despite multiple requests
Kennell and Jamieson declined to allow their software to
be evaluated by us.
In this paper, we argue that
(cid:15) Kennell and Jamieson fail to make their case be-
cause they do not properly consider powerful at-
tacks that can be performed by unauthorized “im-
poster” software;
(cid:15) Genuinity and Genuinity-like software is vulner-
able to speciﬁc attacks (which we have imple-
mented, simulated, and made public);
(cid:15) Genuinity cannot easily be repaired and any
software-only solution to software authentication
faces numerous challenges, making success un-
likely;
(cid:15) proposed applications of Genuinity for Sun Net-
work File System authentication and AOL Instant
Messenger client authentication will not work; and
(cid:3)This work was supported in part by DARPA, NSF, the US Postal
Service, and Intel Corp. The opinions here are those of the authors and
do not necessarily reﬂect the opinions of the funding sponsors.
(cid:15) even in best-case special purpose applications (such
as networked “game boxes” like the Playstation 2
or the Xbox) the Genuinity approach fails.
To appreciate the impact of Kennell and Jamieson’s
claims,
it is useful to remember the variety of ap-
proaches used in the past to authenticate trusted soft-
ware. The idea dates back at least to the 1970s and
led in one direction to the Orange Book model [DoD85]
(and ultimately the Common Criteria Evaluation and
Validation Scheme [NIS04]).
In this approach, ma-
chines often run in physically secure environments to
ensure an uncorrupted trusted computing base.
In
other contemporary directions, security engineers are
exploring trusted hardware such as a secure copro-
cessor [SPWA99, YT95].
The Trusted Computing
Group (formerly the Trusted Computing Platform Al-
liance) [Gro01] and Microsoft’s “Palladium” Next Gen-
eration Security Computing Base [Mic] are now consid-
ering trusted hardware for commercial deployment. The
idea is that trusted code runs on a secure processor that
protects critical cryptographic keys and isolates security-
critical operations. One motivating application is digital
rights management systems. Such systems would allow
an end user’s computer to play digital content but not to
copy it, for example. These efforts have attracted wide
attention and controversy within the computer security
community; whether or not they can work is debatable.
Both Common Criteria and trusted hardware efforts re-
quire elaborate systems and physical protection of hard-
ware. A common thread is that they are expensive and
there is not yet a consensus in the computer security
community that they can effectively ensure security.
If the claims of Kennell and Jamieson were true, this
picture would radically change. The designers of Gen-
uinity claim that an authority could verify that a partic-
ular trusted operating system kernel is running on a par-
ticular hardware architecture, without the use of trusted
hardware or even any prior contact with the client. In
their nomenclature, their system veriﬁes the genuinity of
a remote machine. They have implemented their ideas
in a software package called Genuinity. In Kennell and
Jamieson’s model, a service provider, the authority, can
establish the genuinity of a remote machine, the entity,
and then the authority can safely provide services to
that machine. Genuinity uses hardware speciﬁc side ef-
fects to calculate the checksum. The entity computes
a checksum over the trusted kernel, combining the data
values of the code with architecture-speciﬁc side effects
of the computation itself, such as the TLB miss count,
cache tags, and performance counter values. Kennell
and Jamieson restrict themselves to considering only
uniprocessors with ﬁxed, predetermined hardware char-
acteristics, and further assume that users can not change
hardware conﬁgurations. Unfortunately, as this paper
demonstrates, even with Kennell and Jamieson’s as-
sumptions of ﬁxed-conﬁguration, single-processor ma-
chines, Genuinity is vulnerable to a relatively easily im-
plemented attack.
To demonstrate our points, our paper present two
classes of attacks—one class on the Genuinity imple-
mentation as presented in the original paper [KJ03], and
more general attacks on the entire class of primitives
proposed by Kennell and Jamieson. We wanted to illus-
trate these attacks against a working version of Genuin-
ity, but Kennell and Jamieson declined to provide us with
access to their source code, despite repeated queries. We
therefore have attempted to simulate the main features of
Genuinity as best we can based on the description in the
original paper.
NFS: Sun’s Network File System NFS is
The designers of Genuinity consider two applications:
a well
known distributed ﬁle system allowing entities
(clients) to mount remote ﬁlesystems from an
authority (an NFS ﬁle server). Unfortunately,
NFSv3,
the most widely deployed version, has
no real user authentication protocol, allowing
malicious users to impersonate other users. As a
result, NFS ultimately depends on entities to run
trusted software that authenticates the identities of
the end users. Genuinity’s designers propose using
Genuinity as a system for allowing the authority to
ensure that appropriate client software is running
on each entity. The Genuinity test veriﬁes a trusted
kernel. However, a trusted kernel is not sufﬁcient
to prevent adversaries from attacking NFS: the
weakness is in the protocol, not any particular
implementation. We describe the NFS problem in
more depth in Section 6.5.1.
AIM: AOL Instant Messenger AIM is a text messag-
ing system that allows two entities (AIM clients)
to communicate after authenticating to an author-
ity (an AIM central server). AIM has faced chal-
lenges because engineers have reverse engineered
AIM’s protocol and have built unauthorized entities
which the authority cannot distinguish from autho-
rized entities. Kennell and Jamieson propose the
use of Genuinity to authenticate that only approved
client software is running on entities, thus prevent-
ing communication from unauthorized rogue AIM
client software. As we discuss in Section 6.5.2 be-
low, Genuinity will not work in these applications
either.
In addition to these two applications, we consider a third
application not discussed by Kennell and Jamieson:
Game box authentication Popular set-top game boxes
such as Sony’s Playstation 2 or Microsoft’s Xbox
are actually computers that support network-
ing. They allow different users to play against
each other. However, a widespread community
of users attempts to subvert game box security
(e.g., [Hua03]), potentially allowing cheating in on-
line gaming. One might consider treating the game
boxes as entities and the central servers as authori-
ties and allowing Genuinity to authenticate the soft-
ware running on the game boxes. This is arguably
a best-case scenario for Genuinity: vendors man-
ufacture game boxes in a very limited number of
conﬁgurations and attempt to control all software
conﬁgurations, giving a homogeneous set of con-
ﬁgurations. However, even in this case, Genuinity
fails, as we discuss in Section 7.2 below.
In short, we argue below that Genuinity fails to provide
security guarantees, has unrealistic requirements, and
high maintenance costs. More generally, our criticisms
go to the heart of a wide spectrum of potential software-
only approaches for providing authentication of trusted
software in distributed systems. These criticisms have
important consequences not only for Genuinity, but for
a wide variety of applications from digital rights man-
agement to trusted operating system deployment.
Below, Section 2 summarizes the structure of Genuin-
ity based on Kennell and Jamieson’s original paper. Sec-
tion 3 outlines speciﬁc attacks on Genuinity. Section 4
describes a speciﬁc substitution attack that can be used
to successfully attack Genuinity and a speciﬁc imple-
mentation of that attack that we have executed. Section 5
details denial of service attacks against the current im-
plementation of Genuinity. Section 6 describes a number
of detailed problems with the Genuinity system and its
proposed applications. Finally, Section 7 concludes by
broadening our discussion to present general problems
with software-only authentication of remote software.
2 A description of Genuinity
The Genuinity scheme has two parts: a checksum primi-
tive, and a network key agreement protocol. The check-
sum primitive is designed so that no machine running
a different kernel or different hardware than stated can
compute a checksum as quickly as a legitimate entity
can. The network protocol leverages the primitive into a
key agreement that resists man-in-the-middle attacks.
Genuinity’s security goal is that no machine can com-
pute the same checksum as the entity in the allotted time
without using the same software and hardware. If we
substitute our data for the trusted data while computing
the same checksum in the allowed time, we break the
scheme.
As the authors of the original paper note, the check-
sum value can in principle be computed on any hard-
ware platform by simulating the target hardware and
software. The security of the scheme consequently rests
on how fast the simulation can be performed: if there
is a sufﬁcient gap between the speed of the legitimate
computation and a simulated one, then we can distin-
guish one from the other. Kennell and Jamieson incor-
porate side effects of the checksum computation itself
into the checksum, including effects on the memory hi-
erarchy. They claim that such effects are difﬁcult to sim-
ulate efﬁciently. In Section 3, however, we present an
attack that computes the correct checksum using mali-
cious code quickly enough to fool the authority. A key
trick is not to emulate all the hardware itself, but simply
to emulate the effects of slightly different software.
Genuinity makes the following assumptions:
1. The entity is a single-processor machine. A
multi-processor machine with a malicious proces-
sor could snoop the key after the key agreement
protocol ﬁnishes.
2. The authority knows the hardware and software
conﬁguration of the entity. Since the checksum
depends on the conﬁguration, the authority must
know the conﬁguration to verify that the checksum
is correct.
3. There is a lower bound on the processor speed that
the authority can verify. For extremely slow pro-
cessors, the claim that no simulator is fast enough
is untrue.
4. The Genuinity test runs at boot time so the authority
can specify the initial memory map to compute the
checksum, and so the dynamic state of the kernel is
entirely known.
Genuinity also makes the implicit assumption that all
instructions used in computing the checksum are simu-
latable; otherwise, the authority could not simulate the
test to verify that the checksum result is correct. As we
discuss in Section 4.1.1, the precise-simulation require-
ment is quite stringent on newer processors.
In rest of this section we detail the Genuinity primi-
tive, a checksum computation that the authority uses to
verify the code and the hardware of the entity simul-
taneously. Following that, we review the higher level
network key agreement protocol that uses the checksum
primitive to verify an entity remotely.
2.1 The Genuinity checksum primitive
The checksum computation is the foundation of the Gen-
uinity scheme. The goal of this primitive is that no
machine with an untrusted kernel or different hardware
than claimed will be able to produce a correct checksum
quickly enough.
The details of the test are speciﬁed in the paper [KJ03]
for a Pentium machine. First, the entity maps the ker-
nel image into virtual memory using a mapping supplied
by the authority, where each page of physical memory
is mapped into multiple pages of virtual memory. This
makes precomputation more difﬁcult. Next, the author-
ity sends a pseudorandom sequence of addresses in the
form of a linear-feedback shift register. The entity then
constructs the checksum by adding the one-byte data
values at these virtual addresses. The original paper does
not indicate how many iterations are performed during
the course of the test. Between additions, the entity in-
corporates one of the following values into the checksum
(the original paper under-speciﬁes algorithmic details;
see Table 2 for assumptions):
1. Whether a particular Instruction or Data TLB en-
try exists, and if so, its mapping. The original pa-
per does not make clear which potential entries are
queried (in addition, according to the Intel refer-
ence page [Int03], using the special test registers
needed to access the TLB and cache data can lead
to unpredictable results afterwards);
2. Instruction or data cache tags (again, the original
paper does not indicate which cache entries to ac-
cess);
3. A performance counter which measures the number
of branch instructions encountered;
4. A performance counter which measures the number
of instructions executed.
These processor-speciﬁc data sources are summarized in
Table 1.
The authority must also compute the checksum. Since
Kennell and Jamieson assume there is no fast simula-