Specifically, HT(·) denotes the fraction of normal users whose top-
K recommendations include the target items after the attack on
the surrogate model. Denote Sim(Ii , I k
t ) as the cosine similarity
between any item Ii and its k-th target item before the attack. A
successful attack lifts the t-th target item before any other item
Ij in Ii’s recommendation, say Sim∆(Ii , I k
t ) > Sim∆(Ii , Ij). An at-
tacker aims to promote target items to as many users as possible
and promote as many target items as possible for each user. The
target attack is modeled as:
HT ( ˜Y) =
σ(∆i, j,tk(Sim∆(Ii , I k
t ) − Sim∆(Ii , Ij))) ,
|M|
|M|
K
i =1
j=1
k =1
where Ij can be any item not in the target items set T , and ∆i, j,tk =
Sim(Ii , I k
t ) − Sim(Ii , Ij). By maximizing HT ( ˜Y), we maximize the
successful score of the target attack. To constrain the range of item
space shifting, the target attack problem OPT-T is formulated as:
(8)
HT ( ˜Y) + κ∥ ˜WWW −WWW ∥2 .
OPT-T: max
˜WWW
After solving Eqn. (7) (for OPT-A) or Eqn. (8) (for OPT-T), we get
the poisoned item distributional representations ˜WWW , which include
a set of reference item vectors, i.e., ˜vvvi ∈ ˜WWW . An attacker needs to
operate the items to achieve the attack objective, which lets each
distributional vector move towards the reference item vector, e.g.,
vvvi → ˜vvvi. Here, the challenge is how to “move” the item distribu-
tional vector toward the reference item vector. We next construct a
reference matrix which can help the attacker to achieve this goal.
5.2 Reference Matrix
Reference matrix is an |M| × |M| matrix, with each entry Rij
representing the relationship between item Ii and item Ij.
Generating First-Order Reference Matrix RRR1. First-Order Ref-
erence MatrixRRR1 captures the first-order proximity features among
items from the surrogate model. It illustrates how close two items
are related to each other, e.g. item Ii and item Ij are bought at the
same time, or they both get high ratings from the same user. In our
surrogate model, the first-order proximities of item I1 are shown
j=1
Sim(Ii , Ij)· Sim(Ij , Ik)/K
Ij with probability p(Ij|Ii) = Sim(Ii , Ij)/K
in Figure 4(b) with green arrows. To generate RRR1, we start from an
arbitrary item Ii as the key item. Then we sample the next key item
k =1 Sim(Ii , Ik). Note that
the key item is sampled from Ii’s K most similar items for acceler-
ating the sampling speed. For each sampled item pair (Ii , Ij), we
add 1 to the corresponding entry Rij in RRR1. Next, we use the item
Ij as the new key item to continue reference sampling, which stops
upon reaching a relatively large number, e.g., 1, 000, 000. Each entry
Rij in RRR1 can be considered as the number of co-occurring times
for items Ii and Ij under first-order proximity.
Generating Second-Order Reference Matrix RRR2. This Refer-
ence MatrixRRR2 captures the second-order proximity feature among
items from the surrogate model, e.g., item Ii and item Ik are usually
bought together with item Ij, respectively. As shown in Figure 4(b),
items I7, I8, and I9 have the second-order proximity with item I1.
K
To generate RRR2, we start from an arbitrary item Ii as the key item.
Then, we sample the next key item Ik with probability p(Ik|Ii , Ij) =
k =1(Sim(Ii , Ij)· Sim(Ij , Ik)). For each
sampled item pair (Ii , Ik), we add 1 to the corresponding entry Rij
in RRR2. The steps above repeat until exhausting all item pairs. The
entry Rij in RRR2 represents the number of co-occurring times for
items Ii and Ij under the second-order proximity.
Our Attack Reference MatrixRRR1,2. Since different recommender
systems have different capabilities to learn the first-order proximity
and the second-order proximity, we define the reference matrix
RRR1,2 considering both proximities: RRR1,2 ≜ 1/2RRR1 + 1/2RRR2.
Relationship Between Surrogate Model and Reference Ma-
trix. Considering the surrogate model expressed by Eqn. (3), its
first part loдσ(Sim(Ii , Ij) − Sim(Ii , Ik) is the well-known pointwise
mutual information (PMI) of item Ii and item Ij [50]. It captures
the feature of co-occurring times Ci, j for items Ii and Ij in the sam-
pling dataset. Reference Matrix estimates the co-occurring times
with respect to the item vectors, which is learned by the surrogate
model. The second part can be considered as a regularization term
that constrains item vectors into a specification space. Thus, for
Type-I recommendation, the reference matrix’s values signify the
co-occurring count Ci, j of item pairs. For Type-II recommendation,
the values in the reference matrix reflect the weighted co-occurring
count ˆriCi, j of item pairs, with ˆri = ri − (rmin + (rmax − rmin)/2).
5.3 Complete Attack Solutions
Now, we can summarize our attack solution to poison the item
distributional representations by using the reference matrix.
Phase I: Reproducing items’ proximities. We use the sampling data
to train the surrogate model as shown in Section 4.2 and apply this
trained model to calculate the similarities Sim(Ii , Ij) between any
two items Ii and Ij.
Phase II: Optimizing OPT-A or OPT-T. For availability attack, we
find the original top-K similar items for each item Ii before perform-
ing the attack. Notably, the original top-K similar items for each
item Ii do not change during algorithm execution. Since Sim(Ii , I k
i )
for k = 1, . . . , K are constant, we use the gradient method to min-
imize Eqn. (7). Then we derive the reference item vectors ˜WWW by
using Stochastic Gradient Descent (SGD)[7] method. Specifically,
in each iteration of the SGD algorithm, three items Ii, I k
i , and Ij are
selected, where I k
is item Ii’s k-th similar item. The optimization
i
Session 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea57stops when ˜WWW becomes stable. For target attack, we first randomly
t from the target item set T . Then items Ii and Ij
select an item I k
are randomly selected. Since Sim(Ii , Ij) is a constant derived from
surrogate model, Stochastic Gradient Ascent (SGA) method is used
to maximize Eqn. (8) to derive the reference item vectors.
Phase III: Generating reference matrix. We generate the reference
matrix RRR1,2 before attack with respect to WWW . Then we generate
reference matrix ˜RRR1,2 after optimizing OPT-A or OPT-T by using the
item reference vector ˜WWW . Since reference matrix estimates the item
co-occurrence count, we derive the count differences as ∆RRRI
1,2 =
max{ ˜RRR1,2 − RRR1,2, 0} for attacking Type-I websites and ∆RRRI I
1,2 =
˜RRR1,2 − RRR1,2 for attacking Type-II websites.
Phase IV: Crafting fake user strategy. We craft fake users’ behaviors
according to ∆RRRI
1,2. Fake user crafting strategies are differ-
ent on Type-I and Type-II websites. For Type-I social websites, fake
users can only click and purchase items. The strategy for crafting
fake users are to find item pairs matching the count change matrix
∆RRR1,2. However, finding a perfect match is an NP-hard problem.
We use a greedy method to generate fake users. Specifically, we
first sample the item pairs from the count changing matrix with
the likelihood according to the values. Assuming item pair (Ii , Ij)
is sampled, we subtract 1 from the matrix and add the item pair to
the attack area of fake user ˆu1’s operation list, i.e.,
1,2 or ∆RRRI I
(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)
˜u : {(item item
attack area
(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)
) + (item item item
filler area
(cid:124)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:123)(cid:122)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:125)
) + · · · + (item item
attack area
)}
Then, we randomly sample several popular items and fill them
in the filler area until meeting the maximum requirement. In our
attack, we set the total length of each user operation list to 50,
which is divided into ten segments. Each segment contains one
sampled item pair and 3 filler items. Thus, there are a total of 10
item pairs and 30 filler items in each fake user’s operation list.
For Type-II websites, fake users can rate items. To simplify the
attack strategy, the first step is to sample the item pair (Ii , Ij) ac-
cording to the absolute value as the likelihood in ∆RRRI I
1,2. We set a
default rating value for item Ij as the maximum rating rmax . The
rating of Ii depends on the sign of ∆RRRI I
1,2(Ii , Ij). The maximum
rating rmax is assigned to Ii if ∆RRRI I
1,2(Ii , Ij) > 0; otherwise, the
minimum rating rmin is assigned to Ii. Next, we subtract ˆri from
the corresponding entry in ∆RRRI I
1,2. For item Ik sampled for a filler
area, its rating is assigned as the average rating of Ik on the web-
site. After calculating one fake user’s operation list, we continue to
calculate other fake users’ operation lists until reaching the attack
budget,U
i =1 | ˜ui| ≤ ∆max .
Phase V: Injecting fake users. Finally, we inject fake users on the
websites and operate on items according to the strategy derived in
Phase IV.
6 EXPERIMENT
We implement our proposed black-box attack and conduct extensive
experiments for performance evaluation. Our main goal is twofold.
First, we evaluate the capability of our constructed surrogate model
in reproducing original recommendations. Second, we perform our
crafted availability attack and target attack solutions on a set of CF-
based recommender systems to quantify our attack performance.
6.1 Experimental Setup
6.1.1 Dataset. Our experiments are conducted on two types of
data, one is collected by us from online websites and the other is
from existing real-world datasets, described sequentially as follows.
1) Sampling Data Collection from Online Websites. We em-
ploy the Random Walk Collection method (in Section 4.1) to collect
sampling trails from three real-world websites, i.e., Airbnb, Ama-
zon, and NetEase Music, and apply the Random Injection Collection
method (in Section 4.1) to gather the data from MovieLens. The
underlying recommender algorithms of the three websites are all
unknown to us. For each sampling trail, the key item is randomly
selected. Specifically, in Amazon, we collect 50, 000 unique items
from the entire website (AmazonR) and another 50, 000 unique
items from Books category (AmazonB). In NetEase Music, 10, 000
unique songs are collected. For Airbnb, we collect data from three
locations in different scales, i.e., Manhattan (AirbnbMA), New York
City(AirbnbN Y ), and United States (AirbnbU S ), collecting 5, 000,
10, 000, and 50, 000 unique items, respectively. In MovieLens, 2, 000
and 5, 000 unique movies are collected, denoted respectively as
MoiveLens2k and MoiveLens5k. In this procedure, we strictly follow
the rules (regulated by Airbnb [1], Amazon [3], and MovieLens[61])
to gather the data. Since NetEase Music does not provide robot
rules for data crawling, we follow similar rules to select songs
in each website and record those recommended songs from the
“similar songs” section. We set a threshold of 4 requests/min, far
below servers’ limits in all four platforms. For collecting data in
MovieLens, we repeatedly rate different items and collect the results
returned from the recommending area. For data privacy considera-
tion, each gathered item is directly hashed to a unique string as its
index, without exposing its name or other information.
2) Real-world Datasets. We consider several real-world datasets
widely adopted by the literature, as stated below.
• MovieLens [34] (ml-100k, ml-1m, and ml-20m). MovieLens dataset
collected users’ ratings from MovieLens website [59], containing
user ID, item ID, ratings and timestamp. Each user has rated at
least 20 movies. We randomly sample three different dataset sizes:
100K ratings (ml-100k), 1M ratings (ml-1m), and 20M ratings (ml-
20m), for experiments.
• Netflix [62] (n f ). This is a Netflix Prize Open Competition dataset
which contains movies and their rating information from users.
The dataset n f is sampled from the users, each of which has rated
at least 20 movies.
• Amazon [35] (am-b and am-d). Amazon dataset contains reviews
from Amazon [2] spanning May 1996 - July 2014, with each record
containing user ID, item ID, ratings and timestamp. The dataset
am-b and am-d are sampled from the categories of Books and
Digital Music, respectively, with each user rating at least 5 items
and each item having at least 5 reviews.
• Twitter [47] (tr). This dataset includes the entire follower-
following topology of Twitter [76] network, collected in 2009.
We sample the dataset tr by selecting users with more than 20
friends or followers.
• Google+ [49] (д+). д+ is sampled over the users on Google+ with
• AMiner Citation Network [4] (ac). This is a citation dataset ex-
tracted from DBLP, ACM, MAG (Microsoft Academic Graph),
more than 20 friends or followers.
Session 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea58and other sources by AMiner. ac is sampled over articles with at
least 5 citations.
The numbers of users and items included in each dataset are
listed in Table 10 in Appendix A.2. For each of these real-world
datasets, we collect 100, 000 sampling trails for training our surro-
gate model.
6.1.2 CF Recommender Algorithms. Each of four categories of CF
recommender algorithms takes 1 to 4 algorithms listed below for
experiments:
• (1) Item-based CF: IBCF [54];
• (2) Matrix Factorization-based CF: Singular vector decomposition
(SV D)[64], Alternating least squares (ALS)[40], and Bayesian
personalized ranking (BPR)[65];
• (3) Neural Network-based CF: Neural collaborative filtering
(NCF)[37], Collaborative metric learning (CML)[38], Deep col-
laborative filtering (DCF)[52], and EmbeddingDotBias model in
the fast.ai library (FAST )[25];
• (4) Graph-based CF: Knowledge graph convolution networks
(KGCN )[79].
6.1.3 Counterpart Methods. For availability attack, since there is
no existing work for comparison, we consider a baseline attack
counterpart, i.e., RandomA: an attacker randomly selects the items
to perform operations. If ratings are needed, the attacker generates
random ratings centering around the averaged rating in dataset.
For target attack, we consider the following five attack counter-
parts from the literature. (1) RandomT [48]: An attacker randomly
selects some filler items along with the targeted items to perform
operations. If ratings are needed, the attacker generates the high-
est ratings for target items and random ratings for filler items. (2)
Averaдe [48]: An attacker performs operations on the target items
and a set of filler items sampled based on the item degrees. (3)
Bandwaдon [10]: An attacker operates on both the targeted items
and a set of popular items. (4) PGAT [51]: An attacker carefully
selects a set of items to operate upon for boosting a subset of items.
(5) SGLDT [51]: An attacker carefully selects a set of items and
mimics normal user behaviors to perform attacks. All compared
counterparts belong to the white-box attacks with full or partial
knowledge. Those requiring the least knowledge for attacking will
be presented in Section 6.3. In addition, it should be noted that
the counterparts of PGAT and SGLDT are designed specifically for
attacking MF-based CF with the full knowledge of underlying algo-
rithms, dataset, and item relationship information. In contrast, our
attack belongs to the black-box attack, without knowledge about
prior information.
6.1.4 Metrics and Settings. We define a precision metric PRES @K
to measure the performance of our surrogate model in reproducing
original recommender systems’ outcomes. The metric is defined
as the fraction of the top-K recommended items falling into the
recommended ones of the original recommender system. That is,
s (i)|
/|M|, where |M| is the total number
of items, and F K(i) and LK
s (i) indicate the top-K recommended
items for item i from the target recommender system and from the
surrogate model, respectively. On the other hand, we define two
other metrics, precision PRE@K and hit ratio HR@K, to measure
PRES @K =
|F K(i)∩LK
K
i
Table 2: Performance of the surrogate model on online data
Type
PRES @K(%)
Type-I
AirbnbU S
AirbnbN Y
AirbnbMA
AmazonR
AmazonB
N etEase Music
Type-II MoiveLens2k
MoiveLens5k
3
85.12
86.60
95.21
65.30
72.15
83.26
70.08
71.26
5
83.34
92.76
97.33
75.46
78.02
81.30
71.13
73.42
K
10
81.25
93.54
97.42
73.81
80.11
-
74.56
78.96
15
78.61
93.20
97.25
66.53
77.26
-
77.67
80.01
20
65.76
88.46
96.14
50.21
75.43
-
79.34
82.22
i
the performance of our availability attack and target attack, respec-
tively, when attacking the original recommender systems. Specifi-
cally, PRE@K represents the fraction of items demoted from users’
/|M|,
where ˜F K(i) denotes the top-K recommended items after the attack.
HR@K indicates the fraction of target items promoted to user’s
top-K recommender list, i.e., PRE@K = 
top-K recommender list, i.e., HR@K =
|F K(i)− ˜F K(i)|
| ˜F K(i)∩T|
/|M|.
In our surrogate model, the vector size for item representation is
set to 128. The hyper-parameters for all the targeted recommender
systems are taken from original papers or in default settings from
the library. All experiments are implemented by one lab computer,
with AMD Ryzen 5 5600X CPU and 64 GB DRAM, equipped with
one Nvidia GeForce RTX 3080 GPU.
K
K
i
6.2 Performance of Surrogate Model
6.2.1 Recommendation on Online Social Data. We train our sur-
rogate model based on data collected from different online web-
sites. To test its reproductive capability, we randomly select 5, 000
unique items in each dataset collected from Airbnb, Amazon, and
MoiveLens, and 2, 000 unique songs from NetEase Music. For each
selected item, we use the trained surrogate model to find its top-K
similar items, with K being 3, 5, 10, 15, and 20, respectively. No-
tably, NetEase Music only supports the top-5 recommendation, so
we consider its K to be 3 and 5. We compare the surrogate model’s
top-K similar items to the top-K recommendations from the original
online websites. Table 2 shows the results of PRES @K.
From this table, we can see our surrogate model performs best
on the AirbnbMA with PRES @K values always higher than 95%