a
m
r
o
f
r
e
P
a
m
r
o
N
1.1
1.05
1
0.95
0.9
0.85
0.8
DECC latency
DECC IPC
Figure 15: Performance overhead
D. Power and Energy
According to our device simulations (Section IV), a trans-
verse read consumes 1.67× more energy than a normal read.
As seen in Section V, to compute DECC, two transverse reads
and a normal read are required when arriving at the expected
destination. Furthermore, to check if an error occurred, all the
STT-MRAM cells must be read. DECC with 64/72 column
ECC for LCL = 512 and n = 32 requires 832 cells and for
n = 16 requires 704 cells. In comparison, p-ECC-O shifts
only by one domain at a time to guarantee the integrity of
the system. However, this characteristic has a huge impact on
the power consumption and performance because the extra-
heads are repeatedly used. P-ECC uses the extra heads to
check the auxiliary information less frequently than p-ECC-O;
however, the energy needed to shift the additional domains for
the auxiliary information penalizes the scheme from a power
perspective.
Figure 16 compares the energy consumed by our scheme
with p-ECC and p-ECC-O. Note, the static power, determined
using a modiﬁed version of NVSIM [32–34], between the
various schemes was not signiﬁcantly different, (e.g., within
1%), making the biggest difference in energy due to dynamic
power. On average, the energy for the entire reading process
consumed by DECC with 64/72 column ECC for n = 32 and
LCL = 512 is 52% smaller than the energy consumed by
p-ECC and 75% smaller than p-ECC-O.
Thus, the DECC approach provides signiﬁcant savings in
area/density and energy, while maintaining a similar perfor-
y
g
r
e
n
E
d
e
z
i
l
a
m
r
o
N
0.55
0.45
0.35
0.25
0.15
DEC64/p-ECC-S adaptive
DEC64/p-ECC-O
Figure 16: Energy consumption: DECC with 64/72 column ECC vs
p-ECC, DECC with 64/72 column ECC vs p-ECC-O
385
mance to the leading fault-tolerance approach for shift faults
in DWM.
VII. RELATED WORK
DWM has been proposed for use in a variety of computer
architecture components due to its near SRAM access speeds,
low static power, and high density. DWM has been studied for
use in main memory [38] and at various cache levels [8–10]
in general purpose processor architectures. A full implemen-
tation of a DWM stack-based CPU was constructed based on
DWM [39]. DWM has also been proposed for use in GPU
register ﬁles [40–42] and cache hierarchies [43, 44]. It has
also been proposed for buffers used in on-chip networks [45]
and to construct a content addressable memory [46]. Most
architectural studies of DWM have focused on enhancing the
performance and reducing dynamic energy of DWM through
new shifting policies and data placement policies by utilizing
knowledge of data access frequency [47–49].
Several different solutions have been proposed to increase
the feasibility of DWM by increasing their resiliency against
pinning and shifting faults. Vahid et al. proposed to use
Varshamov-Tenegolts which is an algorithm mainly used to
detect packet loss on internet transmissions to resolve the
pinning issue [50]. Additionally, [51, 52] proposed to read
the same data several times through different heads, separated
by a speciﬁc interval, in order to detect a disruption in the case
of over- or under-shift. However, in these previous studies, to
verify the memory state many consecutive shifts and reads
must be performed, during which data cannot be written.
These solutions were strictly worse in their performance versus
the HIFI [11] solutions, which is why we used HIFI as our
comparison in this work.
VIII. CONCLUSION
Domain wall memory prototypes exhibit a signiﬁcant prob-
ability of positional shift faults. These faults can discourage
DWM’s potential usage despite its area and energy advantages
compared to other traditional and even emerging memory
technologies. To overcome this reliability limitation and allow
the intrinsic beneﬁts of domain-wall memory to shine, we
developed DECC, an efﬁcient correction methodology, which
is original in its design concept, considering its capability to
correct potential errors in the primary data due to shifting
faults by only protecting a smaller derived set of data (the
signature) extracted from the original data. In order to cal-
culate this derived information, our novel access technique,
transverse reading, is used to calculate the number of ones in
the nanowire.
Using these concepts we reach a DUE MTTF of 15 years,
fulﬁlling the requirement of 10 years set by [37]. In addition,
while keeping similar performance and static power of the
state-of-the-art HIFI technique [11], our scheme decreases the
area overhead by 3.7× and the dynamic energy by 52% on
average for a nanowire length of 32 data bits in a memory
sub-array consisting of 512 nanowires.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:37:28 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] Y. Huai, “Spin-transfer torque MRAM (STT-MRAM): Challenges and
prospects,” AAPPS bulletin, Vol. 18, No. 6, No. 6, pp. 33–40, 2008.
[2] T. Coughlin,
“MRAM Developer Day,” Forbes, August 2018.
[available online] https://www.forbes.com/sites/tomcoughlin/2018/08/
10/mram-developer-day/.
[3] S. S. P. Parkin, M. Hayashi, and L. Thomas, “Magnetic Domain-Wall
Racetrack Memory,” Science, Vol. 320, No. 5874, pp. 190–194, Apr.
2008.
[4] W. Z. F. M. H. L. C. Zhang, G. Sun and W. Zhao, “Quantitative modeling
of racetrack memory, a tradeoff among area, performance, and power,”
Design Automation Conference, 2015.
[5] C. Augustine, A. Raychowdhury, B. Behin-Aein, S. Srinivasan,
J. Tschanz, V. K. De, and K. Roy, “Numerical analysis of domain
wall propagation for dense memory arrays,” Electron Devices Meeting
(IEDM), 2011 IEEE International, pp. 17–6, IEEE, 2011.
[6] A. J. Annunziata, M. Gaidis, L. Thomas, C. W. Chien, C. C. Hung,
P. Chevalier, E. O’Sullivan, J. P. Hummel, E. Joseph, Y. Zhu, T. Topuria,
and E. Delenia, “Racetrack memory cell array with integrated magnetic
tunnel junction readout,” Electron Devices Meeting, 1988. IEDM ’88.
Technical Digest., International, 12 2011.
[7] Y. Zhang, W. Zhao, J.-O. Klein, D. Ravelsona, and C. Chappert,
“Ultra-High Density Content Addressable Memory Based on Current
Induced Domain Wall Motion in Magnetic Track,” IEEE Transactions
on Magnetics (TMAG), Vol. 48, No. 11, pp. 3219 –3222, nov. 2012.
[8] R. Venkatesan, V. Kozhikkottu, C. Augustine, A. Raychowdhury, K. Roy,
and A. Raghunathan, “TapeCache: a High Density, Energy Efﬁcient
Cache based on Domain Wall Memory,” Proc. of ISLPED), pp. 185–190,
2012.
[9] R. Venkatesan, M. Sharad, K. Roy, and A. Raghunathan, “DWM-
TAPESTRI-an energy efﬁcient all-spin cache using domain wall shift
based writes,” Proc. of DATE, pp. 1825–1830, 2013.
[10] H. Xu, Y. Alkabani, R. Melhem, and A. K. Jones, “FusedCache: A
naturally inclusive, racetrack memory, dual-level private cache,” IEEE
Transactions on Multi-Scale Computing Systems, Vol. 2, No. 2, No. 2,
pp. 69–82, 2016.
[11] C. Zhang, G. Sun, X. Zhang, W. Zhang, W. Zhao, T. Wang, Y. Liang,
Y. Liu, Y. Wang, and J. Shu, “Hi-ﬁ playback: Tolerating position errors
in shift operations of racetrack memory,” ACM SIGARCH Computer
Architecture News, Vol. 43, pp. 694–706, ACM, 2015.
[12] Y. Zhang, W. Zhao, D. Ravelosona, J.-O. Klein, J.-V. Kim, and C. Chap-
pert, “Perpendicular-magnetic-anisotropy CoFeB racetrack memory,”
Journal of Applied Physics, Vol. 111, No. 9, No. 9, p. 093925, 2012.
[13] Z. Sun, W. Wu, and H. Li, “Cross-layer racetrack memory design for
ultra high density and low power consumption,” Design Automation
Conference (DAC), 2013 50th ACM/EDAC/IEEE, pp. 1–6, IEEE, 2013.
[14] D. Kline, H. Xu, R. Melhem, and A. K. Jones, “Racetrack Queues for
Extremely Low-Energy FIFOs,” IEEE Transactions on Very Large Scale
Integration (VLSI) Systems, No. 99, No. 99, pp. 1–14, 2018.
[15] M. Moeng, H. Xu, R. Melhem, and A. K. Jones, “ContextPreRF:
Enhancing The Performance and Energy of GPUs with Non-Uniform
Register Access (NURA),” IEEE Transactions on VLSI, 2014.
[16] R. Venkatesan, S. G. Ramasubramanian, S. Venkataramani, K. Roy, and
A. Raghunathan, “Stag: Spintronic-tape architecture for gpgpu cache
hierarchies,” ACM SIGARCH Computer Architecture News, Vol. 42,
No. 3, No. 3, pp. 253–264, 2014.
[17] Q. Hu, G. Sun, J. Shu, and C. Zhang, “Exploring main memory design
based on racetrack memory technology,” Proceedings of the 26th edition
on Great Lakes Symposium on VLSI, pp. 397–402, ACM, 2016.
[18] G. Panagopoulos, C. Augustine, X. Fong, and K. Roy, “Exploring
variability and reliability of multi-level STT-MRAM cells,” Device
Research Conference (DRC), 2012 70th Annual, pp. 139–140, IEEE,
2012.
[19] M. Aoki, H. Noshiro, K. Tsunoda, Y. Iba, A. Hatada, M. Nakabayashi,
A. Takahashi, C. Yoshida, Y. Yamazaki, T. Takenaga, et al., “Novel
highly scalable multi-level cell for STT-MRAM with stacked perpendic-
ular MTJs,” VLSI Technology (VLSIT), 2013 Symposium on, pp. T134–
T135, IEEE, 2013.
[20] R. Y. Ranjan and P. Keshtbod, “Multi-state spin-torque transfer magnetic
random access memory,” Dec. 23 2014. US Patent 8,917,543.
[21] R. Bell, J. Hu, and R. H. Victora, “Dual referenced composite free layer
design optimization for improving switching efﬁciency of spin-transfer
torque RAM,” AIP Advances, Vol. 7, No. 5, No. 5, p. 055929, 2017.
[22] K. Tsunoda, H. Noshiro, C. Yoshida, Y. Yamazaki, A. Takahashi, Y. Iba,
A. Hatada, M. Nakabayashi, T. Takenaga, M. Aoki, et al., “A novel MTJ
for STT-MRAM with a dummy free layer and dual tunnel junctions,”
2012 International Electron Devices Meeting, pp. 29–1, IEEE, 2012.
[23] G. Cabrera and L. Falicov, “Theory of the residual resistivity of Bloch
walls I. Paramagnetic effects,” physica status solidi (b), Vol. 61, No. 2,
No. 2, pp. 539–549, 1974.
[24] L. Berger, “Prediction of a domain-drag effect
in uniaxial, non-
compensated, ferromagnetic metals,” Journal of Physics and Chemistry
of Solids, Vol. 35, No. 8, No. 8, pp. 947–956, 1974.
[25] S. Fukami, T. Suzuki, N. Ohshima, K. Nagahara, and N. Ishiwata,
“Micromagnetic analysis of current driven domain wall motion in
nanostrips with perpendicular magnetic anisotropy,” Journal of Applied
Physics, Vol. 103, No. 7, No. 7, p. 07E718, 2008.
[26] M. Scheinfein and E. Price, “LLG Micromagnetics Simulator, software
for micromagnetic simulations,” see http://llgmicro. home. mindspring.
com. Google Scholar, 1997.
[27] W. Zhao, Y. Zhang, H. Trinh, J. Klein, C. Chappert, R. Mantovan,
A. Lamperti, R. Cowburn, T. Trypiniotis, M. Klaui, et al., “Magnetic
domain-wall racetrack memory for high density and fast data storage,”
Solid-State and Integrated Circuit Technology (ICSICT), 2012 IEEE 11th
International Conference on, pp. 1–4, IEEE, 2012.
[28] K. A. Roxy and S. Bhanja, “Reading Nanomagnetic Energy Minimiz-
ing Coprocessor,” IEEE TRANSACTIONS ON NANOTECHNOLOGY,
March 2018.
[29] Y. Zhang, L. Zhang, W. Wen, G. Sun, and Y. Chen, “Multi-level
cell STT-RAM: Is it realistic or just a dream?,” 2012 IEEE/ACM
International Conference on Computer-Aided Design (ICCAD), pp. 526–
532, IEEE, 2012.
[30] Y. Zhang, Y. Li, Z. Sun, H. Li, Y. Chen, and A. K. Jones, “Read per-
formance: The newest barrier in scaled STT-RAM,” IEEE Transactions
on Very Large Scale Integration (VLSI) Systems, Vol. 23, No. 6, No. 6,
pp. 1170–1174, 2015.
[31] S. M. Seyedzadeh, R. Maddah, A. Jones, and R. Melhem, “Leveraging
ecc to mitigate read disturbance, false reads and write faults in stt-ram,”
2016 46th Annual IEEE/IFIP International Conference on Dependable
Systems and Networks (DSN), pp. 215–226, IEEE, 2016.
[32] C. Zhang, G. Sun, W. Zhang, F. Mi, H. Li, and W. Zhao, “Quantitative
modeling of racetrack memory, a tradeoff among area, performance, and
power,” Design Automation Conference (ASP-DAC), 2015 20th Asia and
South Paciﬁc, pp. 100–105, IEEE, 2015.
[33] X. Dong, C. Xu, Y. Xie, and N. P. Jouppi, “Nvsim: A circuit-level
performance, energy, and area model for emerging nonvolatile memory,”
IEEE Transactions on Computer-Aided Design of Integrated Circuits
and Systems, Vol. 31, No. 7, No. 7, pp. 994–1007, 2012.
[34] S. J. Wilton and N. P. Jouppi, “CACTI: An enhanced cache access and
cycle time model,” IEEE Journal of Solid-State Circuits, Vol. 31, No. 5,
No. 5, pp. 677–688, 1996.
[35] T. E. Carlson, W. Heirman, S. Eyerman, I. Hur, and L. Eeckhout, “An
Evaluation of High-Level Mechanistic Core Models,” ACM Transactions
on Architecture and Code Optimization (TACO), 2014.
[36] J. L. Henning, “SPEC CPU2006 benchmark descriptions,” ACM
SIGARCH Computer Architecture News, Vol. 34, pp. 1–17, 2006.
[37] S. S. Mukherjee, J. Emer, and S. K. Reinhardt, “The soft error problem:
An architectural perspective,” 11th International Symposium on High-
Performance Computer Architecture, pp. 243–247, IEEE, 2005.
[38] Y. Wang and H. Yu, “An ultralow-power memory-based big-data com-
puting platform by nonvolatile domain-wall nanowire devices,” Proceed-
ings of the 2013 International Symposium on Low Power Electronics and
Design, pp. 329–334, IEEE Press, 2013.
[39] H. A. Khouzani and C. Yang, “A DWM-Based Stack Architecture
Implementation for Energy Harvesting Systems,” ACM Trans. Embed.
Comput. Syst., Vol. 16, No. 5s, pp. 155:1–155:18, Sept. 2017.
[40] M. Moeng, H. Xu, R. Melhem, and A. K. Jones, “ContextPreRF:
Enhancing the performance and energy of GPUs with nonuniform
register access,” IEEE Transactions on Very Large Scale Integration
(VLSI) Systems, Vol. 24, No. 1, No. 1, pp. 343–347, 2016.
[41] E. Atooﬁan, “Reducing shift penalty in Domain Wall Memory through
register locality,” 2015 International Conference on Compilers, Archi-
tecture and Synthesis for Embedded Systems (CASES), pp. 177–186, Oct
2015.
[42] M. Mao, W. Wen, Y. Zhang, Y. Chen, and H. Li, “Exploration of GPGPU
register ﬁle architecture using domain-wall-shift-write based racetrack
386
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:37:28 UTC from IEEE Xplore.  Restrictions apply. 
memory,” 2014 51st ACM/EDAC/IEEE Design Automation Conference
(DAC), pp. 1–6, June 2014.
[43] R. Venkatesan, S. G. Ramasubramanian, S. Venkataramani, K. Roy,
and A. Raghunathan, “STAG: Spintronic-tape Architecture for GPGPU
Cache Hierarchies,” Proceeding of the 41st Annual International Sym-
posium on Computer Architecuture, ISCA ’14, (Piscataway, NJ, USA),
pp. 253–264, IEEE Press, 2014.
[44] E. Atooﬁan and A. Saghir, “Shift-aware racetrack memory,” 2015 33rd
IEEE International Conference on Computer Design (ICCD), pp. 427–
430, Oct 2015.
[45] D. Kline, H. Xu, R. Melhem, and A. K. Jones, “Domain-wall memory
buffer for low-energy NoCs,” 2015 52nd ACM/EDAC/IEEE Design
Automation Conference (DAC), pp. 1–6, IEEE, 2015.
[46] Y. Zhang, W. Zhao, J. Klein, D. Ravelsona, and C. Chappert, “Ultra-
High Density Content Addressable Memory Based on Current Induced
Domain Wall Motion in Magnetic Track,” IEEE Transactions on Mag-
netics, Vol. 48, No. 11, pp. 3219–3222, Nov 2012.
[47] H. Mao, C. Zhang, G. Sun, and J. Shu, “Exploring data placement in
racetrack memory based scratchpad memory,” 2015 IEEE Non-Volatile
Memory System and Applications Symposium (NVMSA), pp. 1–5, IEEE,
2015.
[48] X. Chen, E. H.-M. Sha, Q. Zhuge, C. J. Xue, W. Jiang, and Y. Wang,
“Efﬁcient data placement for improving data access performance on
domain-wall memory,” IEEE Transactions on Very Large Scale Integra-
tion (VLSI) Systems, Vol. 24, No. 10, No. 10, pp. 3094–3104, 2016.
[49] S. Mittal, “A Survey of Techniques for Architecting Processor Compo-
nents Using Domain-Wall Memory,” J. Emerg. Technol. Comput. Syst.,
Vol. 13, No. 2, pp. 29:1–29:25, Nov. 2016.
[50] A. Vahid, G. Mappouras, D. J. Sorin, and R. Calderbank, “Correcting
Two Deletions and Insertions in Racetrack Memory,” arXiv preprint
arXiv:1701.06478, 2017.
[51] Y. M. Chee, H. M. Kiah, A. Vardy, E. Yaakobi, et al., “Codes correcting
position errors in racetrack memories,” Information Theory Workshop
(ITW), 2017 IEEE, pp. 161–165, IEEE, 2017.
[52] Y. M. Chee, H. M. Kiah, A. Vardy, K. Van Vu, and E. Yaakobi, “Codes
Correcting Limited-Shift Errors in Racetrack Memories,” 2018 IEEE
International Symposium on Information Theory (ISIT), pp. 96–100,
IEEE, 2018.
387
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:37:28 UTC from IEEE Xplore.  Restrictions apply.