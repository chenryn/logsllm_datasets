(Πinsy,A, λ) = 1]| = 0.
(Πinsy,A, λ) = 1] − Pr[Expano-Earn
Lemma 27. If Πuacs has simulation anonymity (Deﬁnition 5), then for all ppt algorithms A it holds
that | Pr[Expano-Earn
Proof. We have to show that we can simulate the experiment and especially the challenge phase
independent of b. Since Πuacs satisﬁes simulation anonymity (Deﬁnition 5), there are ppt algorithms
SSetup, SReceive, SShowPrv, SUpdRcv. Therefore, we can perfectly simulate the setup by running SSetup.
Next, observe that we can honestly execute the oracles as in the experiment, since we know all
inputs of the users. In the challenge phase the experiment executes Earn ↔ A, where Earn is an
execution of UpdRcvuacs ↔ A. We can perfectly simulate Earn in the challenge phase independent
of b by running SUpdRcv ↔ A.
b
b
b
usr + dsid∗
b
b
In the Spend case of experiment Expano-Spend
prvdr, where the user commits to a dsid∗
Remember that the adversary A in Expano-Spend
(Πinsy,A, λ) we have to look at the Spend ↔ Deduct
protocol of Πinsy (Construction 23), since the setup and challenge phase of Expano-Spend
executes
Spend(ub, k) ↔ A. In the challenge phase the adversary A is asked to guess which of the users u0, u1
that he picked before executed the Spend protocol.
Let us ﬁrst state where Πcmt and Πenc are used. During Spend ↔ Deduct the provider (in
Expano-Spend
the adversary) gets commitments (generated with Πcmt) from the users during the
usr ← Zp
combined generation of a fresh dsid∗ = dsid∗
prvdr ∈ Zp.
and the provider provides his dsid∗
Also during Spend ↔ Deduct, the user encrypts dsid∗ under his user public key upkenc as
ctrace ← Encryptenc(pp, upkenc, dsid∗). Here the adversary could break anonymity by distinguishing
which user public key was used to encrypt or the breaks CPA security.
(Πinsy,A, λ) can query the spend oracle Spend(u,
k) for user u and spend value k in the setup and challenge phase. In each of the oracle executions he
learns the dsid of the token that the user spends. This means that Spend executions in the setup
phase and the execution in the challenge phase are implicitly linked. In detail, A chooses users u0, u1
in the challenge phase. Then in the challenge phase Spend, A learns the dsid∗
b to a commitment C∗
and encryption ctraceb he received during the last Spend execution in the setup phase with either u0
or u1. If he could link the information, he would break anonymity. Let us quickly deal with the easy
case where A never triggered a spend operation during the setup phase, then the dsid∗ that he gets
during the challenge Spend is a fresh random value from Zp w.h.p..
For the rest of the proof we will change the challenge phase. In detail, we change in the challenge
b the adversary A gets (index i in the following) and how the encryption
Spend execution which dsid∗
ctrace that A receives is generated (index j in the following). Therefore, we deﬁne experiments Hi,j
where i, j ∈ {0, 1}.
(Πinsy,A, λ). In H0,0 the adversary
0
gets in the challenge phase one execution of Spend with user u0 where A receives dsid∗
0 (j = 0).
Therefore, the only important Spend execution of the setup phase is the last execution with user
u0 (i = 0) where A gets the commitment C∗
usr) and encryption
ctrace0 = Encryptenc(pp, upkenc,0, dsid∗
prvdr. H1,1 is analogous. To
show |[Pr[H0,0 = 1] − Pr[H1,1 = 1]]| ≤ negl we also deﬁne an intermediate experiment H0,1 and
prove that | Pr[H0,0 = 1]− Pr[H0,1 = 1]| ≤ negl and | Pr[H0,1 = 1]− Pr[H1,1 = 1]| ≤ negl. In H0,1 we
output dsid∗
0 was determined and used in the previous
Spend execution (part of the setup phase) with user u0. The change is that we no longer also output
an encryption of dsid∗
0 under upkenc,0. Instead, we output ctrace0 = Encryptenc(pp, upkenc,1, dsid∗
1),
where dsid∗
1 was determined and used in the previous Spend execution (part of the setup phase)
with user u1. The public key upkenc,1 is also the one of user u1.
Lemma 28. If Πuacs has simulation anonymity and Πenc is key-ind. CPA secure, then for all ppt A,
|(Pr[H0,0(A) = 1] − Pr[H0,1(A) = 1])| = negl(λ) for all λ ∈ N.
0 in the challenge Spend execution, where dsid∗
(Πinsy,A, λ) and H1,1 = Expano-Spend
0), where dsid∗
0 = dsid∗
usr + dsid∗
0 = Commitcmt(pp, pkcmt, dsid∗
Let H0,0 = Expano-Spend
1
34
b
Proof. Assume that adversary A distinguishes H0,0, H0,1 with non-negligible probability. We give a
reduction B using A to key-indistinguishable CPA security (Deﬁnition 19) of Πenc. In the reduction
(Πenc,A, λ) (b ∈ {0, 1}) two public keys that B injects as two user public
B we get from Expkey-ind
keys upkenc,0 and upkenc,1 by guessing one pair of the users that A can choose in the challenge phase
of H0,b. Since Πuacs guarantees simulation anonymity (Deﬁnition 5) and c = usk · γ + dsrnd is
perfectly hiding, the reduction B can simulate the setup of the incentive system and the oracles
Keygen, Join, Earn, Spend of H0,b for two users u0, u1 that we choose before. For all other users
B executes the oracles honestly as in the experiment. If A outputs two users that are not our guess
u0, u1, then B aborts. This happens with probability 1 − 1
poly(λ)2 . Otherwise, in the challenge phase
with A, Spend is changed in B as described above. In detail, B gives the Expkey-ind
challenger dsid∗
0
and dsid∗
1 (both from the latest token of the users u0, u1 from the setup phase) and outputs the answer
of the challenger as the encryption for A. Eventually, A outputs his guess ˆb which B outputs to the
Expkey-ind
(Πenc, B, λ) =
1]| =
1
challenger. Consequently, | Pr[Expkey-ind
poly(λ)2 · |(Pr[H0,0(A) = 1] − Pr[H0,1(A) = 1])|.
(Πenc, B, λ) = 1] − Pr[Expkey-ind
0
b
b
1
Next, we look at | Pr[H0,1 = 1] − Pr[H1,1 = 1]|. From H0,1 to H1,1 we change which dsid∗
b the
0 that is part of the latest token
1 from the latest token of user u1. As described above the adversary receives
b corresponding to the latest token of the users. Remember,
(Πinsy,A, λ).
adversary receives during the challenge Spend execution. Either dsid∗
of the user u0 or dsid∗
commitments and encryptions for dsid∗
H1,1 = Expano-Spend
Lemma 29. If Πuacs guarantees simulation anonymity, Πenc is key-indistinguishable CPA secure,
Πcmt is computational hiding, then for all ppt adversaries A it holds that |(Pr[H0,1(A) = 1] −
Pr[H1,1(A) = 1])| = negl
1
Lemma 29 follows from the following lemmas. First, we deﬁne a helper experiment Gb
for u, v, x, y ∈ {0, 1} that we will use in the following lemmas.
u,v,x,y(D, λ)
Gb
u,v,x,y(D, λ) :
• pp ← G(1λ)
• pkcmt ← KeyGencmt(pp)
• sk0, sk1 ← KeyGenenc() and pk0, pk1 ← ComputePKenc(pp)
• Hand D pp, pkcmt, pk0, and pk1
• Choose two messages m0, m1 ← Mpp
Phase 1:
• Hand D the commitment Cu where Commitcmt(pp, pkcmt, mu) → (Cu, Open)
• Receive share ∈ Mpp from D
• Hand D the encryption Sv ← Encryptenc(pp, pk v, mv + share)
Phase 2:
• Hand D the commitment Cx where Commitcmt(pp, pkcmt, mx) → (Cx, Open)
• Receive share0 ∈ Mpp from D
• Hand D the encryption Sy ← Encryptenc(pp, pk y, my + share0)
Challenge:
• Hand D message mb
• Receive ˆb from D
• Output 1 iﬀ ˆb = b
Lemma 30. If Πuacs guarantees simulation anonymity, Πenc is key-indistinguishable CPA secure,
Πcmt is computational hiding, then there is an ppt reduction D such that for all ppt adversaries A it
35
0,0,1,1(D, λ).
0,0,1,1(D, λ) and G1
0,0,1,1(D, λ) = 1]| = 1
0,0,1,1(D, λ) = 1] − Pr[G1
polyλ · | Pr[H0,1(A) = 1] − Pr[H1,1(A) =
holds that | Pr[G0
1]|.
Proof. Assume that an adversary A distinguishes H0,1 and H1,1, then we can give an reduction D
that distinguishes G0
In the following we deﬁne D against Gb0,0,1,1(D, λ) using A. To shorten the proof, in D the guessing
of two users u0, u1 to inject the public keys given by Gb0,0,1,1(D, λ) and the handling of the oracle
queries is analogous to B. The last Spend query by A for user u0 is answered with the help of
Phase 1 in Gb0,0,1,1(D, λ) and the rest of Spend simulated. From Phase 1 D uses the commitment
Cu instead of generating a commitment to a fresh dsidusr. In Spend, A hands D (acting as the
user) a dsidprvdr that D hands itself to Gb0,0,1,1(D, λ) (Phase 1) as share. The encryption that D
gets from Phase 1 is used as the encryption ctrace in Spend. For the last Spend query by A for
user u1 reduction D acts analogous with the diﬀerence that D uses Phase 2. Eventually A enters
the challenge phase and outputs two user handles. If the handles are not the one that D guessed,
then abort. Otherwise, D simulates a Spend with A where D is supposed to send A the dsid of
the latest token of the challenged user. Hence, D sends the message mb that D received in the
challenge phase of Gb0,0,1,1(D, λ) instead. If A outputs ˆb, D also outputs ˆb to Gb0,0,1,1(D, λ). Overall,
| Pr[G0
0,0,1,1(D, λ) = 1] − Pr[G1
0,0,1,1(D, λ) = 1]| = 1
polyλ · | Pr[H0,1(A) = 1] − Pr[H1,1(A) = 1]|.
0,0,1,1(E, λ) = 1] − Pr[G1
1,1,0,0 = G1
0,0,1,1.
It is left to show that for all ppt algorithms E it holds that | Pr[G0
0,0,1,1(E,
λ) = 1]| ≤ negl. Remember, in Gb
u,v,x,y(D, λ) the bits (u, v) determine Phase 1, (x, y) Phase 2, and
b determines the output message mb at the end of the experiment. In detail, the bits u and x
determine the messages for the commitments; the bits v and y determine the messages and public
keys for the encryption. In Figure 7 we show an overview of the following proof steps, where Phase 1
and Phase 2 points to the point where we introduce a change to the previous game and “key-ind.
CPA” respectively “comp. hiding” is the security guarantee that we use in the reduction.
Lemma 31. It holds that G0
Proof. This is the last step presented in Figure 7. The lemma follows from the following observation.
Since the experiment Gu,v,x,y chooses the challenge messages itself, the order of the Phases can be
switched without changing the game while also changing the challenge message from m0 to m1.
Changing order of the Phases is the same as replacing mu, mv, mx, and my by m1−u, m1−v, m1−x,
and m1−y.
Lemma 32. If Πenc is key-indistinguishable CPA secure, then for all ppt adversaries E it holds that
| Pr[G0
Proof. We show that if there is an adversary E s.t. | Pr[G0
is non-negligible, than we can give an reduction RPhase 1
ki-cpa