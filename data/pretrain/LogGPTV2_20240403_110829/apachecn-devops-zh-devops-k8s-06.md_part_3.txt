  annotations: 
    prometheus.io/scrape: 'true' 
    prometheus.io/path: '/prom' 
... 
spec: 
  ports: 
 - port: 9100 
```
我们的示例存储库下的模板`prom-config-k8s.yml`包含为普罗米修斯发现 Kubernetes 资源的配置。将其应用于:
```
$ kubectl apply -f prometheus/config/prom-config-k8s.yml  
```
因为它是一个配置映射，所以需要几秒钟才能保持一致。然后，通过向进程发送`SIGHUP`来重新装载普罗米修斯:
```
$ kubectl exec -n monitoring ${PROM_POD_NAME} -- kill -1 1
```
提供的模板基于普罗米修斯官方存储库的这个例子；您可以在这里找到更多用法:
[https://github . com/Prometheus/Prometheus/blob/master/documentation/examples/Prometheus-kublets . yml](https://github.com/prometheus/prometheus/blob/master/documentation/examples/prometheus-kubernetes.yml)
此外，文档页面详细描述了普罗米修斯配置的工作原理:
[https://prometheus.io/docs/operating/configuration/](https://prometheus.io/docs/operating/configuration/)
# 从 Kubernetes 收集数据
实现前面在 Prometheus 中讨论的五个监控层的步骤现在已经非常清楚了:安装导出器，用适当的标签注释它们，然后在自动发现的端点上收集它们。
普罗米修斯中的主机层监控由节点导出器([https://github.com/prometheus/node_exporter](https://github.com/prometheus/node_exporter))完成。它的 Kubernetes 清单可以在本章的示例下找到，它包含一个带有刮擦注释的 DaemonSet。安装时请使用:
```
$ kubectl apply -f exporters/prom-node-exporter.yml
```
它的相应配置将由 pod 发现角色创建。
容器层收集器应该是 cAdvisor，它已经安装在 kubelet 中。因此，用节点模式发现它是我们唯一需要做的事情。
Kubernetes 的监控是由 kube-state-metrics 完成的，这也是之前介绍过的。更好的一点是，它带有普罗米修斯注释，这意味着我们不需要做任何额外的事情来配置它。
到目前为止，我们已经建立了一个基于普罗米修斯的强大监控栈。关于应用和外部资源监控，普罗米修斯生态系统中有大量的导出器来支持监控我们系统中的各种组件。例如，如果我们需要我们的 MySQL 数据库的统计数据，我们可以只安装 MySQL 服务器导出器([https://github.com/prometheus/mysqld_exporter](https://github.com/prometheus/mysqld_exporter)，它提供了全面和有用的指标。
除了已经描述的这些度量标准，Kubernetes 组件中还有一些其他有用的度量标准，它们在许多方面发挥着重要作用:
*   **Kubernetes API 服务器**:API 服务器在`/metrics`暴露状态，默认启用此目标。
*   **kube-controller-manager** :这个组件公开了端口`10252`上的指标，但是在一些托管的 Kubernetes 服务上是不可见的，比如**谷歌容器引擎** ( **GKE** )。如果您在自托管集群上，应用“`kubernetes/self/kube-controller-manager-metrics-svc.yml`”会为普罗米修斯创建端点。
*   **kube-scheduler** :它使用端口`10251`，在 GKE 的集群上也看不到。“`kubernetes/self/kube-scheduler-metrics-svc.yml`”是为普罗米修斯创建目标的模板。
*   **kube-DNS**:kube-DNS pod 中有两个容器，`dnsmasq`和`sky-dns`，它们的度量端口分别是`10054`和`10055`。对应的模板是`kubernetes/self/ kube-dns-metrics-svc.yml`。
*   **etcd**:etcd 集群在端口`4001`上还有一个普罗米修斯度量端点。如果您的 etcd 集群是由 Kubernetes 自托管和管理的，您可以将“`kubernetes/self/etcd-server.yml`”作为参考。
*   **Nginx 入口控制器**:Nginx 控制器在端口`10254`发布度量。但是这些指标只包含有限的信息。要按主机或路径获取连接计数等数据，您需要激活控制器中的`vts`模块来增强收集的指标。
# 与格拉夫纳一起查看指标
表达式浏览器有一个内置的图形面板，使我们能够看到可视化的指标，但它不是为日常工作设计的可视化仪表板。格拉夫纳是普罗米修斯的最佳选择。我们已经在[第 4 章](04.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e)、*中讨论了如何设置 Grafana 使用存储和资源*，我们也在知识库中提供了本章的模板；两个选项都可以。
要在 Grafana 中看到普罗米修斯度量，我们必须先添加一个数据源。连接到我们的普罗米修斯服务器需要以下配置:
*   类型:“普罗米修斯”
*   Url: `http://prometheus-svc.monitoring:9090`
*   访问:代理
一旦连接上，我们就可以导入一个仪表板来查看正在运行的东西。在 Grafana 的分享页面([https://grafana.com/dashboards?dataSource=prometheus](https://grafana.com/dashboards?dataSource=prometheus))上有丰富的现成仪表盘。以下截图来自仪表盘`#1621`:
![](img/00102.jpeg)
因为图表是由普罗米修斯公司的数据绘制的，所以只要我们掌握了 PromQL，我们就有能力绘制我们关心的任何数据。
# 记录事件
利用系统状态的定量时间序列进行监控，使我们能够迅速找出系统中哪些组件发生了故障，但这仍然不足以诊断综合征下的根本原因。因此，通过将事件与检测到的异常相关联，收集、保存和搜索日志的日志记录系统无疑有助于揭示出现问题的原因。
通常，日志记录系统中有两个主要组件:日志记录代理和日志记录后端。前者是程序的抽象层。它收集、转换日志并将日志分派到日志后端。日志后端存储收到的所有日志。与监控一样，为 Kubernetes 构建日志系统最具挑战性的部分是确定如何将日志从容器收集到集中的日志后端。通常，向程序发送日志有三种方式:
*   将所有东西倾倒至`stdout` / `stderr`
*   书写`log`文件
*   将日志发送到日志记录代理或直接记录后端；Kubernetes 中的程序也能够以同样的方式发出日志，只要我们了解日志流在 Kubernetes 中是如何流动的
# 聚合日志的模式
对于直接登录到日志代理或后端的程序来说，它们是否在 Kubernetes 内部总体上并不重要，因为它们在技术上并不通过 Kubernetes 输出日志。至于其他情况，我们将使用以下两种模式来集中日志。
# 使用每个节点的日志记录代理收集日志
我们知道我们通过`kubectl logs`检索到的消息是从容器的`stdout` / `stderr`重定向的流，但是用`kubectl logs`收集日志显然不是一个好主意。实际上，`kubectl logs`从 kubelet 获取日志，kubelet 从下面的容器引擎将日志聚合到主机路径`/var/log/containers/`。
因此，在每个节点上设置日志代理，并配置它们来跟踪和转发路径下的`log`文件，正是我们汇聚运行容器的标准流所需要的，如下图所示:
![](img/00103.jpeg)
实际上，我们还会配置一个日志代理来跟踪来自系统和 Kubernetes 的日志，它们是主节点和节点上`/var/log`下的组件，例如:
*   `kube-proxy.log`
*   `kube-apiserver.log`
*   `kube-scheduler.log`
*   `kube-controller-manager.log`
*   `etcd.log`
除了`stdout` / `stderr`之外，如果应用的日志作为文件存储在容器中并通过`hostPath`卷持久化，节点日志记录代理同样能够将它们传递给节点。然而，对于每个导出的`log`文件，我们必须在日志代理中定制它们相应的配置，以便它们能够被正确调度。此外，我们还需要正确命名`log`文件，以防止任何冲突，并自行处理日志旋转，这使其成为不可扩展和不可管理的日志机制。
# 运行边车容器来转发日志
有时只是很难修改我们的应用来将日志写入标准流而不是`log`文件，我们也不想面对登录`hostPath`卷带来的麻烦。在这种情况下，我们可以运行一个 Sidecar 容器来处理一个 pod 内的日志记录。换句话说，每个应用容器都有两个共享相同`emptyDir`体积的容器，这样 Sidecar 容器就可以跟踪来自应用容器的日志，并将它们发送到它们的容器之外，如下图所示:
![](img/00104.jpeg)
虽然我们不再需要担心`log`文件的管理，但是像为每个 pod 配置日志代理和将 Kubernetes 的元数据附加到日志条目这样的杂务仍然需要额外的努力。另一种选择是利用 Sidecar 容器将日志输出到标准流，而不是像下面的 pod 一样运行一个专用的日志代理；应用容器坚持不懈地向`/var/log/myapp.log`写入消息，而 Sidecar 在共享卷中尾随`myapp.log`。
```