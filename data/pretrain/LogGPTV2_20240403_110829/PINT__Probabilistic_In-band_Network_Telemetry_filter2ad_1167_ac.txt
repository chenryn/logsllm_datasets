e.g., the median latency of a (flow, switch) pair. We formulate
the general problem as follows: Fix some flow x. Let p1, . . . , pz
denote the packets of x and s1, . . . , sk denote its path. For each
switch si , we need to collect enough information about the sequence
Si,x = ‚ü®v(p1, si), v(p2, si), . . . v(pz , si)‚ü© while meeting the query‚Äôs
bit-budget. For simplicity of presentation, we assume that packets
can store a single value.7
value from(cid:8)v(pj , s1), . . . , v(pj , sk)(cid:9) with probability 1/k. This way,
PINT‚Äôs Encoding Module runs a distributed sampling process.
The goal is to have each packet carry the value of a uniformly
chosen hop on the path. That is, each packet pj should carry each
with probability 1 ‚àí e‚àí‚Ñ¶(z/k), each hop will get z/k ¬∑ (1 ¬± o(1))
samples, i.e., almost an equal number.
To get a uniform sample, we use a combination of global hashing
and the Reservoir Sampling algorithm [82]. Specifically, when the
i‚Äôth hop on the path (denoted si ) sees a packet pj , it overwrites its
digest with v(pj , si) if –¥(pj , i) ‚â§ ri . Therefore, the packet will end
up carrying the value v(pj , si) only if (i) –¥(pj , i) ‚â§ ri , and (ii) ‚àÄ»∑ ‚àà
{i + 1, . . . , k} : –¥(pj , »∑) > r »∑ . To get uniform sampling, we follow
the Reservoir Sampling algorithm and set ri ‚âú 1/i. Indeed, for each
hop (i) and (ii) are simultaneously satisfied with probability 1/k.
Intuitively, while later hops have a lower chance of overriding the
digest, they are also less likely to be replaced by the remaining
switches along the path.
Intuitively, we can then use existing algorithms for constructing
statistics from subsampled streams. That is, for each switch si , the
collected data is a uniformly subsampled stream of Si,x . One can
then apply different aggregation functions. For instance, we can esti-
mate quantiles and find frequently occurring values. As an example,
we can estimate the median and tail latency of the (flow, switch) pair
by finding the relevant quantile of the subsampled stream.
On the negative side, aggregation functions like the number
of distinct values or the value-frequency distribution entropy are
poorly approximable from subsampled streams [49].
PINT aims to minimize the decoding time and amount of per-flow
storage. To that end, our Recording Module does not need to store
all the incoming digests. Instead, we can use a sketching algorithm
that suits the target aggregation (e.g., a quantile sketch [39]). That is,
for each switch si through which flow x is routed, we apply a sketch-
ing algorithm to the sampled substream of Si,x . If given a per-flow
space budget (see ¬ß3.3) we split it between the k sketches evenly.
This allows us to record a smaller amount of per-flow information
and process queries faster. Further, we can use a sliding-window
sketch (e.g., [5, 11, 13]) to reflect only the most recent measure-
ments. Finally, the Inference Module uses the sketch to provide
estimates on the required flows.
7If the global bit-budget does not allow encoding a value, we compress it at the cost
of an additional error as discussed in Section 4.3. If the budget allows storing multiple
values, we can run the algorithm independently multiple times and thereby collect more
information to improve the accuracy.
5
Figure 4: Multiple encoders send a distributed message.
The accuracy of PINT for dynamic aggregation depends on the ag-
gregation function, the number of packets (z), the length of the path
(k), and the per-flow space stored by the Recording Module (which
sits off-switch in remote storage). We state results for two typical
aggregation functions. The analysis is deferred to Appendix A.1.
THEOREM 1. Fix an error target Œµ ‚àà (0, 1) and a target quantile
œï ‚àà (0, 1) (e.g., œï = 0.5 is the median). After seeing O(kŒµ‚àí2) packets
from a flow x, using O(kŒµ‚àí1) space, PINT produces a (œï¬±Œµ)-quantile
of Sx,i for each hop i.
THEOREM 2. Fix an error target Œµ ‚àà (0, 1) and a target threshold
Œ∏ ‚àà (0, 1). After seeing O(kŒµ‚àí2) packets from a flow x, using O(kŒµ‚àí1)
space, PINT produces all values that appear in at least a Œ∏-fraction
of Sx,i , and no value that appears less than a (Œ∏ ‚àí Œµ)-fraction, for
each hop i.
4.2 Distributed Coding Schemes
When the values are static for a given flow (i.e., do not change
between packets), we can improve upon the dynamic aggregation
approach using distributed encoding. Intuitively, in such a scenario,
we can spread each value v(x, si) over multiple packets. The chal-
lenge is that the information collected by PINT is not known to
any single entity but is rather distributed between switches. This
makes it challenging to use existing encoding schemes as we wish to
avoid adding extra overhead for communication between switches.
Further, we need a simple encoding scheme to adhere to the switch
limitations, and we desire one that allows efficient decoding.
Traditional coding schemes assume that a single encoder owns
all the data that needs encoding. However, in PINT, the data we
wish to collect can be distributed among the network switches.
That is, the message we need to transfer is partitioned between
the different switches along the flow‚Äôs path.
We present an encoding scheme that is fully distributed without
any communication between encoders. Specifically, we define our
scheme as follows: a sequence of k encoders hold a k-block message
M1, . . . , Mk such that encoder ei has Mi for all i ‚àà {1, . . . , k}. The
setting is illustrated in Fig. 4. Each packet carries a digest which
has a number of bits that equals the block size and has a unique
identifier which distinguishes it from other packets. Additionally,
each encoder is aware of its hop number (e.g., by computing it from
the TTL field in the packet header). The packet starts with a digest
of 0 (a zero bitstring) and passes through e1, . . . , ek . Each encoder
can modify the packet‚Äôs digest before passing it to the next encoder.
After the packet visits ek , it is passed to the Receiver, which tries to
decode the message. We assume that the encoders are stateless to
model the switches‚Äô inability to keep a per-flow state in networks.
Our main result is a distributed encoding scheme that needs k ¬∑
log log‚àó k ¬∑ (1 + o(1)) packets for decoding the message with near-
linear decoding time. We note that Network Coding [32] can also be
6
(a) Algorithm Progress
(b) Probability of Decoding
Figure 5: The XOR scheme (with prob. 1/d) decodes fewer hops at first
but is able to infer the entire path using a similar number of packets to
Baseline. By interleaving both schemes (Hybrid), we get a better result
as the first hops are mainly decoded by Baseline packets and the last
hops by XOR packets that have XOR probability log log d/log d and
are more likely to hit the missing hops. Plotted for d = k = 25 hops.
adapted to this setting. However, we have found it rather inefficient,
as we explain later on.
Baseline Encoding Scheme. A simple and intuitive idea for a dis-
tributed encoding scheme is to carry a uniformly sampled block on
each packet. That is, the encoders can run the Reservoir Sampling
algorithm using a global hash function to determine whether to write
their block onto the packet. Similarly to our Dynamic Aggregation al-
gorithm, the Receiver can determine the hop number of the sampling
switch, by evaluating the hash function, and report the message.
The number of packets needed for decoding the message using
this scheme follows the Coupon Collector Process (e.g., see [24]),
where each block is a coupon and each packet carries a random sam-
ple. It is well-known that for k coupons, we would need k ln k(1 +
o(1)) samples on average to collect them all. For example, for
k = 25, Coupon Collector has a median (i.e., probability of 50%
to decode) of 89 packets and a 99‚Äôth percentile of 189 packets,
as shown in Fig. 5.
The problem with the Baseline scheme is that while the first
blocks are encoded swiftly, later ones require a higher number of
packets. The reason is that after seeing most blocks, every consec-
utive packet is unlikely to carry a new block. This is because the
encoders are unaware of which blocks were collected and the proba-
bility of carrying a new block is proportional to number of missing
blocks. As a result, the Baseline scheme has a long ‚Äútail‚Äù, meaning
that completing the decoding requires many packets.
Distributed XOR Encoding. An alternative to the Baseline scheme
is to use bitwise-xor while encoding. We avoid assuming that the
encoders know k, but assume that they know a typical length d, such
that d = Œò(k). Such an assumption is justified in most cases; for
example, in data center topologies we often know a tight bound on
the number of hops [72]. Alternatively, the median hop count in the
Internet is estimated to be 12 [80], while only a few paths have more
than 30 hops [15, 77]. The XOR encoding scheme has a parameter
p, and each encoder on the path bitwise-xors its message onto the
packet‚Äôs digest with probability p = 1/d, according to the global hash
function. That is, the i‚Äôth encoder changes the digest if –¥(pj , i) < p.
We note that this probability is uniform and that the decision of
whether to xor is independent for each encoder, allowing a distributed
implementation without communication between the encoders.
‚Ä¶ùëí1ùëí2ùëí3ùëíùëòMessage Blocks010000000101111111010011010110101111010110101001EncodersùëÄ1ùëÄ2ùëÄ3ùëÄùëòPackets‚Äô pathReceiverArriving PacketsùëÄ1,‚Ä¶,ùëÄùëòDecode010000000000010000110000010011110000010110101111050100150200Number of Packets0510152025E[Missing Hops]XORHybridBaseline050100150200Number of Packets0.00.20.40.60.81.0Decode ProbabilityXORHybridBaselineWhen a packet reaches the Receiver, the digest is a bitwise-xor
of multiple blocks Mi1 ‚äï . . . ‚äï MiK , where K is a binomial random
variable K ‚àº Bin(k, p). The Receiver computes –¥(pj , 1), . . . , –¥(pj , k)
to determine the values i1, . . . , iK . If this set contains exactly one
unknown message block, we can discover it by bitwise-xoring
the other blocks. For example, if we have learned the values of
M1, M3, M4, M6 and the current digest is pj .dig = M1 ‚äï M5 ‚äï M6,
we can derive M5 since M5 = pj .dig ‚äï M1 ‚äï M6.
On its own, the XOR encoding does not asymptotically improve
over the Baseline. Its performance is optimized when p = 1/d =
Œò(1/k), where it requires O(k log k) packets to decode, i.e., within a
constant factor from the Baseline‚Äôs performance. Interestingly, we
show that the combination of the two approaches gives better results.
Interleaving the Encoding Schemes.
Intuitively, the XOR and
Baseline schemes behave differently. In the Baseline, the chance of
learning the value of a message block with each additional packet
decreases as we receive more blocks. In contrast, to recover data
from an XOR packet, we need to know all xor-ed blocks but one.
When p is much larger than 1/k, many packet digests are modified
by multiple encoders, which means that the probability to learn a
message block value increases as we decode more blocks.
As an example for how the interleaved scheme helps, consider
the case of k = 2 encoders. The Baseline scheme requires three
packets to decode the message in expectation; the first packet always
carries an unknown block, but each additional packet carries the
missing block with probability only 1/2. In contrast, suppose each
packet chooses the Baseline scheme and the XOR scheme each with
probability 1/2, using p = 1. For the interleaved scheme to complete,
we need either two Baseline packets that carry different blocks or
one XOR packet and one Baseline packet. A simple calculation
shows that this requires just 8/3 packets in expectation.
For combining the schemes, we first choose whether to run the
Baseline with probability œÑ , or the XOR otherwise. Once again,
switches make the decision based on a global hash function applied
to the packet identifier to achieve implicit agreement on the packet
type. Intuitively, the Baseline scheme should reduce the number
of undecoded blocks from k to k‚Ä≤, and the XOR will decode the
rest. To minimize the number of packets, we can set œÑ = 3/4 and the
XOR probability8 to log log d/log d to reduce the required number of
packets to O(k log log k/log log log k). In such setting, the Baseline
decodes most hops, leaving k‚Ä≤ ‚âà k/log k for the XOR layer. For
example, when k = 25, we get a median of 41 packets and a 99‚Äôth
percentile of 68 packets to decode the message. That is, not only
does it improve the average case, the interleaving has sharper tail
bounds. This improvement is illustrated in Fig. 5.
Multi-layer Encoding. So far, we used a single probability for
xor-ing each packet, which was chosen inversely proportional to k‚Ä≤
(the number of hops that were not decoded by the Baseline scheme).
This way, we maximized the probability that a packet is xor-ed
by exactly one of these k‚Ä≤ blocks, and we xor any block from the
k ‚àí k‚Ä≤ that are known already to remove them from the decoding.
However, when most of the k‚Ä≤ blocks left for XOR are decoded,
it also ‚Äúslows down‚Äù and requires more packets for decoding each
additional block. Therefore, we propose to use multiple XOR lay-
ers that vary in their sampling probabilities. We call the Baseline
8If d ‚â§ 15 then log log d < 1; in this case we set the probability to 1/log d.
7
scheme layer 0, and the XOR layers 1, . . . , L. Each XOR layer
‚Ñì ‚àà {1, . . . , L} starts with k‚Ñì undecoded blocks, xors with probabil-
ity p‚Ñì, and ends when k‚Ñì+1 blocks are undecoded.
Our analysis, given in Appendix A.2, shows that by optimizing
‚Ñì=1 and {p‚Ñì}L
the algorithm parameters œÑ , L, {k‚Ñì}L
‚Ñì=1, we obtain the
following result. The value of L is a function of d, and we have
that L = 1 if d ‚â§ ‚åäee‚åã = 15 and L = 2 if 16 ‚â§ d ‚â§ ee e ; i.e.,
in practice we need only one or two XOR layers.
THEOREM 3. After seeing k log log‚àó k(1+o(1)) packets, the Multi-
layer scheme can decode the message.
We note that the o(1) term hides an O(k) packets additive term,
where the constant depends on how well d approximates k. Namely,
when d = k, our analysis indicates that k(log log‚àó k +2+o(1)) packets
are enough. Finally, we note that if d is not representative of k at all,
we still get that k ln k(1 + o(1)) packets are enough, the same as in
the Baseline scheme (up to lower order terms). The reason is that
our choice of œÑ is close to 1, i.e., only a small fraction of the packets
are used in the XOR layers.
Comparison with Linear Network Coding. Several algorithms
can be adapted to work in the distributed encoding setting. For
example, Linear Network Coding (LNC) [32] allows one to decode a
message in a near-optimal number of packets by taking random linear
combinations over the message blocks. That is, on every packet, each
block is xor-ed into its digest with probability 1/2. Using global hash
functions to select which blocks to xor, one can determine the blocks
that were xor-ed onto each digest. LNC requires just ‚âà k + log2 k
packets to decode the message. However, in some cases, LNC may
be suboptimal and PINT can use alternative solutions. First, the LNC
decoding algorithm requires matrix inversion which generally takes
O(k3) time in practice (although theoretically faster algorithms are
possible). If the number of blocks is large, we may opt for approaches
with faster decoding. Second, LNC does not seem to work when
using hashing to reduce the overhead. As a result, in such a setting,
LNC could use fragmentation, but may require a larger number of
packets than the XOR-based scheme using hashing.
Example #2: Static Per-flow Aggregation. We now discuss how
to adapt our distributed encoding scheme for PINT‚Äôs static aggrega-
tion. Specifically, we present solutions that allow us to reduce the
overhead on packets to meet the bit-budget in case a single value
cannot be written on a packet. For example, for determining a flow‚Äôs
path, the values may be 32-bit switch IDs, while the bit-budget can
be smaller (even a single bit per packet). We also present an imple-
mentation variant that allows to decode the collection of packets
in near-linear time. This improves the quadratic time required for
computing(cid:8)–¥(pj , i)(cid:9) for all packets pj and hops i.
Reducing the Bit-overhead using Fragmentation. Consider a sce-
nario where each value has q bits while we are allowed to have
smaller b-bits digests on packets. In such a case, we can break each
value into F ‚âú ‚åàq/b‚åâ fragments where each has ‚â§ b bits. Using an
additional global hash function, each packet pj is associated with a
fragment number in {1, . . . , F}. We can then apply our distributed
encoding scheme separately on each fragment number. While frag-
mentation reduces the bit overhead, it also increases the number of
packets required for the aggregation, and the decode complexity, as
if there were k ¬∑ F hops.
Reducing the Bit-overhead using Hashing. The increase in the
required number of packets and decoding time when using fragmen-
tation may be prohibitive in some applications. We now propose
an alternative that allows decoding with fewer packets, if the value-
set is restricted. Suppose that we know in advance a small set of
possible block values V, such that any Mi is in V. For example,
when determining a flow‚Äôs path, V can be the set of switch IDs
in the network. Intuitively, the gain comes from the fact that the
keys may be longer than log2 |V| bits (e.g., switch IDs are often