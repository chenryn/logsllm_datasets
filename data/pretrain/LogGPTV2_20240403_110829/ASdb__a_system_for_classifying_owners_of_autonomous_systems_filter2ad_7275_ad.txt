# Evaluation of ASdb Stages

## Stage, Matched by ASN, and Classifier
- **0 Sources Matched**
- **1 Source Matched**
- **≥2 Sources Matched — ≥ 2 Agree**
- **≥2 Sources Matched — None Agree**

## Overall Layer 1 and Layer 2 Classification
- **Layer 1 - Tech**
- **Layer 1 - Not Tech**
- **Overall Layer 2**
- **Uniform Gold Standard**

### Coverage and Accuracy
| Category | Coverage | Accuracy |
|----------|----------|----------|
| 0 Sources Matched | 14% | 97% |
| 1 Source Matched | 29% | 95% |
| ≥2 Sources Matched — ≥ 2 Agree | 3% | 89% |
| ≥2 Sources Matched — None Agree | 18% | 93% |
| Layer 1 - Tech | 30% | 100% |
| Layer 1 - Not Tech | 5% | 97% |
| Overall Layer 2 | 97% | 98% |
| Uniform Gold Standard | 60% | 92% |

**Table 8: Evaluation of ASdb Stages**  
ASdb provides a layer 1 and layer 2 classification for at least 93% of all ASes across all three data sets and achieves a 93% Layer 1 accuracy on the test set. Note that NAICSlite layer 2 coverage can exceed NAICSlite layer 1 coverage, as only the ASes with a labeler-assigned NAICSlite layer 2 category (142, 141, and 189 for the three data sets, respectively) are evaluated in NAICSlite layer 2 metrics. The sample size is 150 ASes for the Gold Standard and test set, and 320 for the Uniform Gold Standard set.

## Performance Breakdown
ASdb provides a layer 1 and layer 2 classification for at least 93% of ASes across all three data sets, which is at least 25% better coverage than any individual data source. ASdb also achieves accuracy on par with or better than external data sources:
- **Layer 1 Accuracy**: 93%, 97%, and 89% for the test, Gold Standard, and Uniform Gold Standard sets, respectively.
- **Layer 2 Accuracy**: 75%, 87%, and 82% for the test, Gold Standard, and Uniform Gold Standard sets, respectively.

The weakest points in the ASdb pipeline correspond to cases where there is no multi-source agreement (60% accuracy on the test set where ≥2 sources matched but none agree, 80% accuracy where only 1 source matched). Without additional manual review, ASdb cannot classify the 4% of test-set ASes where no data sources match.

## Layer 1 Precision and Coverage
To assess ASdb’s coverage and accuracy across the long tail of NAICSlite layer-1 categories, we perform a per-category analysis using the Uniform Gold Standard dataset. ASdb’s coverage and accuracy depend on external data sources’ coverage and accuracy. ASdb consistently achieves nearly identical coverage compared to the data source with the best coverage in the same NAICSlite layer 1 category, while achieving equivalent or better accuracy across 9/16 of categories. The lower precision ASdb achieves in certain categories, as compared to the most accurate data source, is due in all but one case to the most accurate data source—Crunchbase—exhibiting coverage up to 5 times worse.

## Number of Applied NAICSlite Categories
We confirm that ASdb does not achieve its measured accuracy by inflating the number of categories it assigns to each AS:
- **Layer 2**: 84 (59%) ASes are assigned only 1 category, 16 (11%) are assigned 2 categories, and the maximum number of assigned categories is 10.
- **Layer 1**: 104 (73%) ASes are assigned 1 category, 20 (14%) are assigned 2 categories, and the maximum number of layer-1 categories is 4.

For both layer-1 and layer-2, the long tail is even sparser for the Gold Standard than it is for the test set.

## Comparison with Prior Works
ASdb offers at least 89 additional categories compared to popular AS classification databases like IPinfo (4 categories) and PeeringDB (6 categories). To compare ASdb’s performance with IPinfo, we map IPinfo and NAICSlite’s hosting, ISP, and education categories to each other, and map all other 92 NAICSlite categories to IPinfo’s “business.” For PeeringDB, we map its content, enterprise, non-profit, education, and remaining categories to IPinfo’s hosting, business, education, and ISP categories, respectively.

ASdb categorizes 3 times and 7 times more ASes than IPinfo and PeeringDB, respectively. The F1 metric shows that ASdb always performs better. However, ASdb achieves an F1-score of 65% for hosting providers in the test set (still 2.7 times more accurate than IPinfo). Upon further investigation, 17% of all hosting providers do not have domains, 9% have no data source matches, and another 9% were marked as non-hosting by at least two data sources, even when our classifier classified the AS as hosting.

Overall, ASdb is:
- 2.5–6 times more accurate for hosting providers
- 1.3–2.5 times more accurate for ISPs
- 1.1–5 times more accurate for education entities
- 1.3–12 times more accurate for business entities

## Maintaining ASdb
Between October 2020 and February 2021, an average of 21 ASes were registered daily, belonging to an average of 19 new organizations. Additionally, 4% of all registered ASes changed their ownership metadata at least once during this period. It is crucial that ASdb is easily updated, as we estimate an average of 140 ASes will need to be updated every week.

ASdb will be primarily maintained by automatically querying data sources available to our research group. We have also integrated a simple way for the research community to submit AS classification corrections, which will be verified by a human before integration. For all system components requiring human intervention, we plan to devise a community program that requests users of ASdb to periodically complete a human-maintenance task (e.g., review corrections, fetch Zvelo data).

## Conclusion
In this paper, we introduced ASdb, a system that classifies 96% of ASes with 93% and 75% accuracy on 17 industry categories and 95 sub-categories, respectively. ASdb allows the research community to understand the largely overlooked long-tail of industry sectors that run the Internet. For example, joining ASdb’s dataset with an Internet Telnet scan (using a 1% IPv4 LZR scan conducted in March 2021 across 65,535 ports) reveals that critical-infrastructure organizations like electric utility companies, government organizations, and financial institutions are more likely to host Telnet than technology companies.

The process of building ASdb offers insights for the Internet measurement community. We show that business-oriented databases can be applied to networking-specific problems. However, data sources not tailored towards the technology community (e.g., business databases) should not be solely relied upon, as they consistently provide worse coverage and accuracy for data pertaining to technology entities. We learn that crowdwork is not the most promising solution; machine learning and simple heuristics perform with nearly the same accuracy at a fraction of the cost. Aggregating existing data sources and different classification solutions helps build the best-performing classification system.

We designed ASdb to be extendable and maintainable, and we plan to release it and the resulting dataset at asdb.stanford.edu.

## Acknowledgements
We thank Natasha Sharp, Julie Plummer, and Casey Mullins for support with project logistics and data labeling. We thank David Adrian, Fengchen Gong, Catherine Han, Hans Hanley, Tatyana Izhikevich, Deepak Kumar, and Gerry Wan for providing feedback on the paper, and members of the Stanford Empirical Security Research Group for valuable discussions. We thank the anonymous reviewers and shepherd Romain Fontugne for their helpful comments. This work was supported in part by the National Science Foundation under award CNS-1823192, two NSF Graduate Fellowships DGE-1656518, a Stanford Graduate Fellowship, and gifts from Google, Inc., Cisco Systems, Inc., and Comcast Corporation.

## References
[References listed here as provided in the original text]