### Data Partitioning and Assumptions

We partition the dataset into 361 sets, each containing 100 objects. Each set roughly corresponds to a day in this one-year dataset. Since Digg does not support negative votes, we assume all objects are good for simplicity. (Additionally, most of these objects have already received at least one vote from a guide.) We construct one round for each set, with each round containing all 100 good objects.

### Validation of Small Dimensions

Based on the thesis that small dimensions can be validated through specific conditions, we will validate the following sufficient (but not necessary) conditions:

1. The vote distribution follows a Pareto distribution.
2. A Pareto vote distribution typically implies a small dimension.

We will use the four datasets listed in Table 3 to validate the first condition and use simulation/analysis to validate the second. Even if the representativeness of our datasets is questioned, as long as the heavy-tail distribution (which is universal and fundamental) applies, the dimension is likely to be small. Furthermore, since we are only concerned with the "heavy-tailness" of the vote distribution from honest identities, we do not expect votes from Sybil identities to affect this property.

### Vote Distribution Analysis

Figures 5(b) through 5(e) show the fit of the four datasets to a Pareto distribution, with \( b \) values ranging from 1.08 to 1.73. The flat components at the tails are due to the finite number of users in the datasets. We ignore these flat parts when fitting to the Pareto distribution, which makes the tails "lighter" (i.e., \( b \) larger) and results in more pessimistic estimates. The figures indicate that all datasets, except Netflix, have a good fit. Although Pareto does not fit Netflix well initially, the dimension is mainly determined by the tail portion, so the initial part is not critical.

### Synthetic Dataset Construction

To determine if a Pareto distribution implies a small dimension, we construct synthetic datasets with synthetic voting patterns for the guides based on given Pareto distributions. We then use these datasets to determine the dimension.

### DSybil's Performance Under Attack

We evaluate DSybil's performance under a worst-case attack scenario, where the attack starts after some initial attack-free rounds. Our DSybil toolkit processes the dataset for a number of attack-free rounds and outputs the total loss so far, along with the trust values of all identities. These values, combined with the dimension of the remaining rounds, allow us to use Equations 6 and 8 to bound the loss under the worst-case attack.

To demonstrate the robustness of the results against different voting patterns of non-guides, we perturb their votes in Digg in various ways. The results shown in Figure 7 are based on the perturbation yielding the largest loss.

Figure 7 illustrates Alice’s per-round loss when the attack starts after she has used DSybil for a given number of days (each day corresponds to 20 rounds). The results show that DSybil’s growing defense is significant. Even if Alice has used DSybil for only one day before the attack starts, her per-round loss drops from around 12% to 6% (under \( M = 10^{10} \)). If Alice has used DSybil for a month, her per-round loss further drops to around 4%. Assuming an average honest user’s lifespan using DSybil is one year, 99.7% of users will have used DSybil for at least one day when the attack starts.

### Conclusion

This paper presents DSybil, a novel defense mechanism for mitigating the influence of Sybil identities in recommendation systems. DSybil provides provable guarantees that are optimal. Our evaluation shows that DSybil’s loss remains small even under a potential Sybil attack launched from a million-node botnet.

### Acknowledgments

We thank Avrim Blum, Wee Sun Lee, Siddhartha Srinivasa, and Nathan Ratliff for valuable discussions on related issues in the machine learning context. We also thank Brad Karp for useful discussions about attacks on Digg and Wikipedia, and Avrim Blum and the anonymous reviewers for their helpful comments on this paper.

### References

[References are provided in the original text and remain unchanged.]

---

This revised version aims to make the text more coherent, clear, and professional, while maintaining the technical details and structure of the original content.