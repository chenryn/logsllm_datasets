##### 7. 分布式应用程序协调管理 {#分布式应用程序协调管理 .list-paragraph}
分布式处理模块均向协调管理模块注册，注册之后会在zookeeper中建立临时节点，当模块出现故障由zookeeper感知临时节点退出重新选举选出leader，由zookeeper统一协调管理模块并通过zookeeper协调各模块之间等通信，交换，通过ZooKeeper承载.涉及到消息队列，流处理，搜索引擎等分布式处理模块
![{A940A8B0-0346-BFD3-D9AE-AB50C6D04B72}](media/image10.jpeg){width="6.7131944444444445in"
height="4.148611111111111in"}
##### 8.日志配置规则解析 {#日志配置规则解析 .list-paragraph}
####### 8.1流处理平台内置了常用的日志解析规则，能够识别、解析常见的日志格式。 {#流处理平台内置了常用的日志解析规则能够识别解析常见的日志格式 .list-paragraph}
配置格式：
\[
{ \"grok\" : { \"rule\" : \[ { \"pattern\" :
\[\[\"%{ApacheAccess1}\"\]\] } \] } },
{\"split\" : { \"rule\": \[ {\"source\": \"x_forward\",
\"split_string\": \", \"} \] }},
{\"date\" : { \"rule\" : \[\"dd/MMM/yyyy:HH:mm:ss Z\"\] }},
{\"geo\" : { \"rule\" : \[ { \"source\": \"clientip\",
\"target\":\"geo\", \"field\": \[ \"all\" \] } \] }}
\]
ApacheAccess1正则格式:
%{ApcClientIP}%{SPACE}
%{ApcIdent}%{SPACE}
%{ApcUser}%{SPACE}
%{ApcTimestamp}%{SPACE}
%{ApcRequest}%{SPACE}
%{ApcStatus}%{SPACE}
%{ApcRespLen}
(?:%{SPACE}%{ApcReferer}%{SPACE}%{ApcUa}(?:%{SPACE}%{ApcXForward})?)?
%{GREEDYDATA}
时间戳格式为
%{MONTHDAY}/%{MONTH}/%{YEAR}:(?!\=200
  [append](\l)        将子管道的结果附加在主管道的结果之后                        append \[\[ \* \| stats max(status) by
                                                                                  appname \]\]
  [autoregress](\l)   拷贝一个或者多个当前事件之前的事件中的字段值到当前事件      autoregress clientip p=1-2
  [eval](\l)          计算表达式，并将表达式的值放入字段中，请参阅                eval username = case(user_name, user)
                      **搜索命令函数**                                            
  [bucket](\l)        将连续的值放入离散集中                                      bucket timestamp span=1h as ts
  [fields](\l)        删除结果中的字段                                            fields status, clientip
  [join](\l)          类似sql的连接，将来自主管道的结果和子管道的结果连接在一起   join type=left clientip \[\[ \* \| stats
                                                                                  avg(resp_len) by clientip \]\]
  [jpath](\l)         类似xpath抽取json中的字段值                                 jpath output=prices
                                                                                  path=\"store.book\[\*\].price\"
  [lookup](\l)        显示调用字段值查找                                          lookup email  on
                                                                                  id=userId
  [limit](\l)         返回前n个结果                                               limit 10
  [movingavg](\l)     计算移动平均值                                              movingavg sum_len,10 as smooth_sum_len
  [mvexpand](\l)      拆分多值字段                                                mvexpand iplist limit=100
  [mvcombine](\l)     合并指定字段                                                mvcombine sep=\",\" ip
  [parse](\l)         搜索时抽取字段                                              parse
                                                                                  \"(?\\\d+\\.\\d+\\.\\d+\\.\\d+)\"
  [rollingstd](\l)    计算移动的标准差                                            rollingstd sum_resp_len, 10 as
                                                                                  resp_len_rolling_std
  [rename](\l)        重新命名指定字段                                            rename apache.status as http_code
  [stats](\l)         提供统计信息，可以选择按照字段分组                          stats count() by apache.method
  [sort](\l)          按照指定的字段对结果进行排序                                sort by apache.status
  [where](\l)         使用表达式对结果进行过滤                                    where apache.status \400
  [save](\l)          将搜索结果为外部文件                                        
  [top](\l)           返回指定字段top的值集合                                     top 3 apache.clientip by apache.method
  [transaction](\l)   将结果分组成交易                                            
  [table](\l)         将查询结果以表格形式展示，并对字段进行筛选                  table apache.status, apache.method
  [transpose](\l)     将查询的表格结果进行行列转换                                transpose row=apache.method
                                                                                  column=apache.status valuefield=cnt
  [esma](\l)          对某一个字段的未来值进行预测                                esma latency timefield=ts period=7
                                                                                  futurecount=30
  [dedup](\l)         对搜索结果中指定字段值的重复情况进行去重和过滤              dedup 3 apache.status, apache.geo.city
  [map](\l)           将前一个查询的结果用于下一个查询                            map {apache.status:\$apache.status\$ \| stats
                                                                                  count()}
  [timechart](\l)     对时间分桶进行统计查询                                      timechart limit=5 bins=10 minspan=1m span=10m
                                                                                  max(x) as ma count() as cnt by
                                                                                  apache.geo.city
  ------------------- ----------------------------------------------------------- ---------------------------------------------
###### 10. 数据字典动态更新 {#数据字典动态更新 .list-paragraph}
通过日志分析软件数据处理系统的关联字典功能，提取出数据间的有关联的字段值，并根据新接入的数据进行实时更新。通过动态字典，能够使得不同来源的有关联的数据实现关联。支持根据新增的日志，自动更新已提取的字典信息，可加载新字典到服务中
对于终端数据，有如下定义的字典；
dicts = \[
{
key_field = uiddevrecordid
field_names = \[strdevip\]
dict_name = id_ip.csv
domain = ops
schedule_interval_in_sec = 60
scan_period = 60 d
es_fetch_size = 100000
query = \"{ \\\"wildcard\\\": { \\\"tag\\\": { \\\"value\\\":
\\\"\*devbaseinfo\\\" } } }\"
},
{
key_field = dimensions.IP
field_names = \[dimensions.cookie_Login_Cookie\]
dict_name = ip_cookie.csv
domain = ops
schedule_interval_in_sec = 60
scan_period = 30 d
es_fetch_size = 100000
query = \"{ \\\"term\\\": { \\\"appname\\\": { \\\"value\\\":
\\\"userinfo\\\" } } }\"
}
\]
static_dicts = \[
{
key_field = cookie_Login_Cookie
field_names = \[depart_id, area_id\]
dict_name = cookie_office.csv
domain = ops
schedule_interval_in_sec = 60
scan_period = 30 d
es_fetch_size = 100000
}
\]
即从id_ip, ip_cookie,
cookie_office三个动态字典中提取出的有用字段，依序关联完成从终端的id到营业厅的关联关系。
###### 11. OPENAPI支持 {#openapi支持 .list-paragraph}
针对海量大数据存储，具备API实时数据获取的调用能力，接口使用HTTP，通过HTTPBasicAuth进行权限校验。当前提供如下接口：
•SplSearch:搜索类接口是使用日志易的SearchPorcessLanguage(SPL)进行日志搜索对应的接口，除了基本搜索之外还有通过搜索执行的下载、LogTail、DrillDown、上下文查询功能。
•Agent:Agent类接口对日志易数据接入代理进行配置，除了基本的增删查改，在日志易Web界面中Agent管理菜单下的小部分功能可通过API进行配置。
•ParserRule:提取规则接口对日志易数据接入历程中日志解析规则进行配置，除了基本的增删查改，在日志易Web界面中数十类提取规则均可通过API进行配置。
•Alert:告警类接口对日志易告警功能进行配置，除了基本的增删查改，在日志易Web界面可进行的告警发送方式（即告警插件）、高级配置下的扩展搜索、
•SourceGroup:日志来源类接口对日志来源进行增删查改管理。可通过日志易Web界面了解，另外可参看售后人员提供的使用手册中的管理设置-日志管理-日志来源章节。
•Account:当前用户接口只支持简单的用户增删查改管理。
•AccountGroup:用户分组接口除了用户分组的增删查改管理外，还包括设置用户组成员、指定用户分组与角色关系。
•ResourceGroup:日志易中的告警、定时任务、提取规则等各类数据都被抽象为资源，通过资源分组完成各自的权限管理。资源分组接口除了资源分组本身的增删查改管理外，还包括对资源组成员的操作。
•AlertMonitor:日志易的告警监控提供了对告结果的状态、操作处理和统计分析。