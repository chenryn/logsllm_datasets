OWASP MASVS to determine the security requirements of mobile applications on the basis of the risk
assessment phase. Iteratively reviewing requirements when features and data classes are added is common,
especially with Agile projects.
Threat Modeling, which is basically the identification, enumeration, prioritization, and initial handling of threats, is
a foundational artifact that must be performed as architecture development and design progress. Security
Architecture, a Threat Model factor, can be refined (for both software and hardware aspects) after the Threat
Modeling phase. Secure Coding rules are established and the list of Security tools that will be used is created.
The strategy for Security testing is clarified.
All security requirements and design considerations should be stored in the Application Life Cycle Management
(ALM) system (also known as the issue tracker) that the development/ops team uses to ensure tight integration of
security requirements into the development workflow. The security requirements should contain relevant source
code snippets so that developers can quickly reference the snippets. Creating a dedicated repository that's under
version control and contains only these code snippets is a secure coding strategy that's more beneficial than the
traditional approach (storing the guidelines in word documents or PDFs).
Securely develop the software. To increase code security, you must complete activities such as Security Code
Reviews, Static Application Security Testing, and Security Unit Testing. Although quality analogues of these
security activities exist, the same logic must be applied to security, e.g., reviewing, analyzing, and testing code for
security defects (for example, missing input validation, failing to free all resources, etc.).
Next comes the long-awaited release candidate testing: both manual and automated Penetration Testing
28
Mobile App Security Testing
("Pentests"). Dynamic Application Security Testing is usually performed during this phase as well.
After the software has been Accredited during Acceptance by all stakeholders, it can be safely transitioned to
Operation teams and put in Production.
The last phase, too often neglected, is the safe Decommissioning of software after its end of use.
The picture below illustrates all the phases and artifacts:
Based on the project's general risk profile, you may simplify (or even skip) some artifacts, and you may add others
(formal intermediary approvals, formal documentation of certain points, etc.). Always remember two things: an
SDLC is meant to reduce risks associated with software development, and it is a framework that helps you set
up controls to that end. This this is a generic description of SDLC; always tailor this framework to your projects.
Defining a Test Strategy
Test strategies specify the tests that will be performed during the SDLC as well as testing frequency. Test strategies
are used to make sure that the final software product meets security objectives, which are generally determined by
clients' legal/marketing/corporate teams. The test strategy is usually created during the Secure Design phase, after
risks have been clarified (during the Initiation phase) and before code development (the Secure Implementation
phase) begins. The strategy requires input from activities such as Risk Management, previous Threat Modeling, and
Security Engineering.
A Test Strategy needn't be formally written: it may be described through Stories (in Agile projects), quickly
enumerated in checklists, or specified as test cases for a given tool. However, the strategy must definitely be shared
because it must be implemented by a team other than the team who defined it. Moreover, all technical teams must
agree to it to ensure that it doesn't place unacceptable burdens on any of them.
Test Strategies address topics such as the following:
objectives and risk descriptions
plans for meeting objectives, risk reduction, which tests will be mandatory, who will perform them, how and when
they will be performed
acceptance criteria
To track the testing strategy's progress and effectiveness, metrics should be defined, continually updated during the
project, and periodically communicated. An entire book could be written about choosing relevant metrics; the most we
can say here is that they depend on risk profiles, projects, and organizations. Examples of metrics include the
following:
the number of stories related to security controls that have been successfully implemented
code coverage for unit tests of security controls and sensitive features
29
Mobile App Security Testing
the number of security bugs found for each build via static analysis tools
trends in security bug backlogs (which may be sorted by urgency)
These are only suggestions; other metrics may be more relevant to your project. Metrics are powerful tools for getting
a project under control, provided they give project managers a clear and synthetic perspective on what is happening
and what needs to be improved.
Distinguishing between tests performed by an internal team and tests performed by an independent third party is
important. Internal tests are usually useful for improving daily operations, while third-party tests are more beneficial to
the whole organization. Internal tests can be performed quite often, but third-party testing happens at most once or
twice a year; also, the former are less expensive than the latter. Both are necessary, and many regulations mandate
tests from an independent third party because such tests can be more trustworthy.
Security Testing in Waterfall
What Waterfall Is and How Testing Activities Are Arranged
Basically, SDLC doesn't mandate the use of any development life cycle: it is safe to say that security can (and must!)
be addressed in any situation.
Waterfall methodologies were popular before the 21st century. The most famous application is called the "V model", in
which phases are performed in sequence and you can backtrack only a single step. The testing activities of this model
occur in sequence and are performed as a whole, mostly at the point in the life cycle when most of the app
development is complete. This activity sequence means that changing the architecture and other factors that were set
up at the beginning of the project is hardly possible even though code may be changed after defects have been
identified.
Security Testing for Agile/DevOps and DevSecOps
DevOps refers to practices that focus on a close collaboration between all stakeholders involved in software
development (generally called Devs) and operations (generally called Ops). DevOps is not about merging Devs and
Ops. Development and operations teams originally worked in silos, when pushing developed software to production
could take a significant amount of time. When development teams made moving more deliveries to production
necessary by working with Agile, operation teams had to speed up to match the pace. DevOps is the necessary
evolution of the solution to that challenge in that it allows software to be released to users more quickly. This is largely
accomplished via extensive build automation, the process of testing and releasing software, and infrastructure
changes (in addition to the collaboration aspect of DevOps). This automation is embodied in the deployment pipeline
with the concepts of Continuous Integration and Continuous Delivery (CI/CD).
People may assume that the term "DevOps" represents collaboration between development and operations teams
only, however, as DevOps thought leader Gene Kim puts it: "At first blush, it seems as though the problems are just
between Devs and Ops, but test is in there, and you have information security objectives, and the need to protect
systems and data. These are top-level concerns of management, and they have become part of the DevOps picture."
In other words, DevOps collaboration includes quality teams, security teams, and many other teams related to the
project. When you hear "DevOps" today, you should probably be thinking of something like DevOpsQATestInfoSec.
Indeed, DevOps values pertain to increasing not only speed but also quality, security, reliability, stability, and
resilience.
Security is just as critical to business success as the overall quality, performance, and usability of an application. As
development cycles are shortened and delivery frequencies increased, making sure that quality and security are built
in from the very beginning becomes essential. DevSecOps is all about adding security to DevOps processes. Most
defects are identified during production. DevOps specifies best practices for identifying as many defects as possible
early in the life cycle and for minimizing the number of defects in the released application.
30
Mobile App Security Testing
However, DevSecOps is not just a linear process oriented towards delivering the best possible software to operations;
it is also a mandate that operations closely monitor software that's in production to identify issues and fix them by
forming a quick and efficient feedback loop with development. DevSecOps is a process through which Continuous
Improvement is heavily emphasized.
The human aspect of this emphasis is reflected in the creation of cross-functional teams that work together to achieve
business outcomes. This section is focused on necessary interactions and integrating security into the development
life cycle (which starts with project inception and ends with the delivery of value to users).
What Agile and DevSecOps Are and How Testing Activities Are Arranged
Overview
Automation is a key DevSecOps practice: as stated earlier, the frequency of deliveries from development to operation
increases when compared to the traditional approach, and activities that usually require time need to keep up, e.g.
deliver the same added value while taking more time. Unproductive activities must consequently be abandoned, and
essential tasks must be fastened. These changes impact infrastructure changes, deployment, and security:
infrastructure is being implemented as Infrastructure as Code
deployment is becoming more scripted, translated through the concepts of Continuous Integration and
Continuous Delivery
security activities are being automated as much as possible and taking place throughout the life cycle
The following sections provide more details about these three points.
Infrastructure as Code
Instead of manually provisioning computing resources (physical servers, virtual machines, etc.) and modifying
configuration files, Infrastructure as Code is based on the use of tools and automation to fasten the provisioning
process and make it more reliable and repeatable. Corresponding scripts are often stored under version control to
facilitate sharing and issue resolution.
Infrastructure as Code practices facilitate collaboration between development and operations teams, with the following
results:
Devs better understand infrastructure from a familiar point of view and can prepare resources that the running
31
Mobile App Security Testing
application will require.
Ops operate an environment that better suits the application, and they share a language with Devs.
Infrastructure as Code also facilitates the construction of the environments required by classical software creation
projects, for development ("DEV"), integration ("INT"), testing ("PPR" for Pre-Production. Some tests are usually
performed in earlier environments, and PPR tests mostly pertain to non-regression and performance with data that's
similar to data used in production), and production ("PRD"). The value of infrastructure as code lies in the possible
similarity between environments (they should be the same).
Infrastructure as Code is commonly used for projects that have Cloud-based resources because many vendors
provide APIs that can be used for provisioning items (such as virtual machines, storage spaces, etc.) and working on
configurations (e.g., modifying memory sizes or the number of CPUs used by virtual machines). These APIs provide
alternatives to administrators' performing these activities from monitoring consoles.
The main tools in this domain are Puppet, Terraform, Packer, Chef and Ansible.
Deployment
The deployment pipeline's sophistication depends on the maturity of the project organization or development team. In
its simplest form, the deployment pipeline consists of a commit phase. The commit phase usually involves running
simple compiler checks and the unit test suite as well as creating a deployable artifact of the application. A release
candidate is the latest version that has been checked into the trunk of the version control system. Release candidates
are evaluated by the deployment pipeline for conformity to standards they must fulfill for deployment to production.
The commit phase is designed to provide instant feedback to developers and is therefore run on every commit to the
trunk. Time constraints exist because of this frequency. The commit phase should usually be complete within five
minutes, and it shouldn't take longer than ten. Adhering to this time constraint is quite challenging when it comes to
security because many security tools can't be run quickly enough (#paul, #mcgraw).
CI/CD means "Continuous Integration/Continuous Delivery" in some contexts and "Continuous Integration/Continuous
Deployment" in others. Actually, the logic is:
Continuous Integration build actions (either triggered by a commit or performed regularly) use all source code to
build a candidate release. Tests can then be performed and the release's compliance with security, quality, etc.,
rules can be checked. If case compliance is confirmed, the process can continue; otherwise, the development
team must remediate the issue(s) and propose changes.
Continuous Delivery candidate releases can proceed to the pre-production environment. If the release can then
be validated (either manually or automatically), deployment can continue. If not, the project team will be notified
and proper action(s) must be taken.
Continuous Deployment releases are directly transitioned from integration to production, e.g., they become
accessible to the user. However, no release should go to production if significant defects have been identified
during previous activities.
The delivery and deployment of applications with low or medium sensitivity may be merged into a single step, and
validation may be performed after delivery. However, keeping these two actions separate and using strong validation
are strongly advised for sensitive applications.
Security
At this point, the big question is: now that other activities required for delivering code are completed significantly faster
and more effectively, how can security keep up? How can we maintain an appropriate level of security? Delivering
value to users more often with decreased security would definitely not be good!
Once again, the answer is automation and tooling: by implementing these two concepts throughout the project life
cycle, you can maintain and improve security. The higher the expected level of security, the more controls,
checkpoints, and emphasis will take place. The following are examples:
32
Mobile App Security Testing
Static Application Security Testing can take place during the development phase, and it can be integrated into the
Continuous Integration process with more or less emphasis on scan results. You can establish more or less
demanding Secure Coding Rules and use SAST tools to check the effectiveness of their implementation.
Dynamic Application Security Testing may be automatically performed after the application has been built (e.g.,
after Continuous Integration has taken place) and before delivery, again, with more or less emphasis on results.
You can add manual validation checkpoints between consecutive phases, for example, between delivery and
deployment.
The security of an application developed with DevOps must be considered during operations. The following are
examples:
Scanning should take place regularly (at both the infrastructure and application level).
Pentesting may take place regularly. (The version of the application used in production is the version that should
be pentested, and the testing should take place in a dedicated environment and include data that's similar to the
production version data. See the section on Penetration Testing for more details.)
Active monitoring should be performed to identify issues and remediate them as soon as possible via the
feedback loop.
References
[paul] - M. Paul. Official (ISC)2 Guide to the CSSLP CBK, Second Edition ((ISC)2 Press), 2014
[mcgraw] - G McGraw. Software Security: Building Security In, 2006
OWASP MASVS
V1.1: "All app components are identified and known to be needed."
V1.3: "A high-level architecture for the mobile app and all connected remote services has been defined and
security has been addressed in that architecture."
V1.4: "Data considered sensitive in the context of the mobile app is clearly identified."
V1.5: "All app components are defined in terms of the business functions and/or security functions they provide."
V1.6: "A threat model for the mobile app and the associated remote services has been produced that identifies
potential threats and countermeasures."
33
Mobile App Security Testing
V1.7: "All security controls have a centralized implementation."
V1.10: "Security is addressed within all parts of the software development lifecycle."
34
Mobile App Authentication Architectures
Mobile App Authentication Architectures
Authentication and authorization problems are prevalent security vulnerabilities. In fact, they consistently rank second
highest in the OWASP Top 10.
Most mobile apps implement some kind of user authentication. Even though part of the authentication and state
management logic is performed by the back end service, authentication is such an integral part of most mobile app
architectures that understanding its common implementations is important.
Since the basic concepts are identical on iOS and Android, we'll discuss prevalent authentication and authorization
architectures and pitfalls in this generic guide. OS-specific authentication issues, such as local and biometric
authentication, will be discussed in the respective OS-specific chapters.
General Guidelines on Testing Authentication
There's no one-size-fits-all approach to authentication. When reviewing the authentication architecture of an app, you
should first consider whether the authentication method(s) used are appropriate in the given context. Authentication
can be based on one or more of the following:
Something the user knows (password, PIN, pattern, etc.)
Something the user has (SIM card, one-time password generator, or hardware token)
A biometric property of the user (fingerprint, retina, voice)
The number of authentication procedures implemented by mobile apps depends on the sensitivity of the functions or
accessed resources. Refer to industry best practices when reviewing authentication functions. Username/password
authentication (combined with a reasonable password policy) is generally considered sufficient for apps that have a
user login and aren't very sensitive. This form of authentication is used by most social media apps.
For sensitive apps, adding a second authentication factor is usually appropriate. This includes apps that provide
access to very sensitive information (such as credit card numbers) or allow users to transfer funds. In some industries,
these apps must also comply with certain standards. For example, financial apps have to ensure compliance with the
Payment Card Industry Data Security Standard (PCI DSS), the Gramm Leach Bliley Act, and the Sarbanes-Oxley Act
(SOX). Compliance considerations for the US health care sector include the Health Insurance Portability and
Accountability Act (HIPAA) and the Patient Safety Rule.
You can also use the OWASP Mobile AppSec Verification Standard as a guideline. For non-critical apps ("Level 1"),
the MASVS lists the following authentication requirements:
If the app provides users with access to a remote service, an acceptable form of authentication such as
username/password authentication is performed at the remote endpoint.
A password policy exists and is enforced at the remote endpoint.
The remote endpoint implements an exponential back-off, or temporarily locks the user account, when incorrect
authentication credentials are submitted an excessive number of times.
For sensitive apps ("Level 2"), the MASVS adds the following:
A second factor of authentication exists at the remote endpoint and the 2FA requirement is consistently enforced.
Step-up authentication is required to enable actions that deal with sensitive data or transactions.
The app informs the user of the recent activities with their account when they log in.
You can find details on how to test for the requirements above in the following sections.
35
Mobile App Authentication Architectures
Stateful vs. Stateless Authentication
You'll usually find that the mobile app uses HTTP as the transport layer. The HTTP protocol itself is stateless, so there
must be a way to associate a user's subsequent HTTP requests with that userâ€”otherwise, the user's log in
credentials would have to be sent with every request. Also, both the server and client need to keep track of user data
(e.g., the user's privileges or role). This can be done in two different ways:
With stateful authentication, a unique session id is generated when the user logs in. In subsequent requests, this
session ID serves as a reference to the user details stored on the server. The session ID is opaque; it doesn't
contain any user data.
With stateless authentication, all user-identifying information is stored in a client-side token. The token can be
passed to any server or micro service, eliminating the need to maintain session state on the server. Stateless
authentication is often factored out to an authorization server, which produces, signs, and optionally encrypts the
token upon user login.
Web applications commonly use stateful authentication with a random session ID that is stored in a client-side cookie.
Although mobile apps sometimes use stateful sessions in a similar fashion, stateless token-based approaches are
becoming popular for a variety of reasons:
They improve scalability and performance by eliminating the need to store session state on the server.
Tokens enable developers to decouple authentication from the app. Tokens can be generated by an
authentication server, and the authentication scheme can be changed seamlessly.
As a mobile security tester, you should be familiar with both types of authentication.
Supplementary Authentication
Authentication schemes are sometimes supplemented by passive contextual authentication, which can incorporate:
Geolocation
IP address
Time of day
The device being used
Ideally, in such a system the user's context is compared to previously recorded data to identify anomalies that might
indicate account abuse or potential fraud. This process is transparent to the user, but can become a powerful
deterrent to attackers.
Verifying that Appropriate Authentication is in Place (MSTG-ARCH-2 and
MSTG-AUTH-1)
Perform the following steps when testing authentication and authorization:
Identify the additional authentication factors the app uses.
Locate all endpoints that provide critical functionality.
Verify that the additional factors are strictly enforced on all server-side endpoints.
Authentication bypass vulnerabilities exist when authentication state is not consistently enforced on the server and
when the client can tamper with the state. While the backend service is processing requests from the mobile client, it
must consistently enforce authorization checks: verifying that the user is logged in and authorized every time a
resource is requested.
Consider the following example from the OWASP Web Testing Guide. In the example, a web resource is accessed
through a URL, and the authentication state is passed through a GET parameter:
36