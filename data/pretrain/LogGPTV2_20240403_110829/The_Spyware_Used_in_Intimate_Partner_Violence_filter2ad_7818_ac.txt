### Average AUC Across All Folds

We utilized Python's Scikit-Learn library [50] for training and evaluating our machine learning models. Our analysis revealed that logistic regression (LR) with an L2 penalty and an inverse of the regularization strength (C) set to 0.02094 (determined via grid search) performed the best, achieving an AUC value of 0.94 (with 1.0 being the optimal value). This configuration resulted in a false positive rate (FPR) of 4% and a false negative rate (FNR) of 4%.

We also tested other algorithms, including decision trees, random forests, K-means, and SVM, but none outperformed the LR model.

### Evaluation

To evaluate the performance of our machine learning model, we used 200 apps from two different time periods. Half of these apps (denoted as TS1) were sampled from the first week’s 6,361 apps (excluding the first day’s results, which were used to select the 1,000 training apps), and the other half (denoted as TS2) were sampled from the fourth (last) week’s 7,581 apps. We manually labeled these 200 apps as either benign or IPS-relevant. TS1 contained 28 IPS-relevant apps, while TS2 had 22.

In Figure 4 (first group of rows, with a cutoff of 0.5), we present the accuracy, FPR, and FNR of the logistic regression model on the training data (TR) and the two test sets (TS1 and TS2). The results indicate that the LR classifier generalizes well, as the test accuracy is close to that of the training dataset. Additionally, the model handles concept drift effectively: apps from a month later are classified with similar accuracy to those from the same time period. When averaging across the entire test set (TS1+2), the classifier achieves 93% accuracy with a 6% false negative rate.

### Minimizing False Negative Rates

Given the critical nature of minimizing false negatives—erroneously classifying an app usable for IPS as benign—we experimented with different classification thresholds. Specifically, we explored how confident the LR model needs to be before classifying an app as IPS-relevant. We found that a threshold of 0.3 (as opposed to the standard 0.5; the positive class is IPS apps) achieves a false negative rate below 1% and a false positive rate of 19%, with 34% of all apps marked as relevant. These figures are averages over 10 random folds of the training data. The performance at this threshold on the test data is shown in Figure 4.

### Reducing False Positive Rates

The false positive rate can be reduced through manual inspection of the ML-pruned apps. For example, in subsequent sections, we only investigate apps that we manually verified to be IPS-relevant. To scale manual inspection, we explored using Amazon Mechanical Turk, as detailed in Appendix C.

### Limitations of Our App Discovery Approach

Our app discovery approach has several limitations. First, we focused solely on English-language search queries and apps with descriptions in English, potentially missing spyware used in non-English-speaking communities. However, our methods can be localized to other languages.

Additionally, our initial seed queries were manually selected, and the snowball sampling did not cover an exhaustive set of search terms that an abuser might use. As a result, some IPS apps may have been missed.

Our machine learning and manual labeling approaches primarily relied on Google Play store descriptions, which can be cursory, vague, or incomplete. Some apps have capabilities not listed in their descriptions, while others promise features they do not deliver. Future work could leverage more comprehensive specifications from separate websites or natural language processing techniques to improve accuracy.

Another potential improvement is to augment our techniques with direct analysis of app binaries, using advanced malware analysis methods [14, 24, 32, 44, 59].

Finally, determining what should be considered IPS-relevant is not always clear, even for expert human analysts. Our ground truth labels may contain some errors, and we tended to conservatively mark apps as IPS-relevant, prioritizing a low false negative rate. This approach seems appropriate given the many online resources suggesting the use of well-intentioned apps (such as folder synchronization tools) for IPS.

### IPS-Relevant App UX and Capabilities

In Section III, we discussed the discovery of IPS tools through manual and automated crawling. Here, we delve into the types of apps found, grouping them into high-level categories and analyzing both their user experience (from the perspective of both abusers and victims) and their capabilities.

#### App Selection

We manually investigated 70 apps: 61 from Google Play (on-store) and 9 from the open web (off-store). The apps were selected by ordering on-store apps by download count and choosing at least three from each category, capping the maximum number to 15 per category. Of the 23 off-store apps, 18 were free, and 5 required purchase. We randomly selected 6 free apps and 3 that required purchase.

For each app, a researcher reviewed the description, installed it on a simulated victim phone, and recorded the capabilities provided. We found that 12 of the 70 apps were buggy or did not work as described and excluded them from further discussion.

#### Categories of Apps

Most apps fell into three categories based on their intended usage:

- **Personal Tracking**: Apps intended for use solely by the owner of a phone, such as text message forwarding services and anti-theft (Find-my-phone) apps.
- **Mutual Tracking**: Apps allowing a group of people to track each other’s locations, such as Find-my-family apps or couple trackers.
- **Subordinate Tracking**: Apps designed to enable one party to track another, such as child or employee monitoring apps. Most off-store IPS spyware falls into this category.

Figure 5 summarizes these categories with examples.

#### (Ab)user Experience

Assuming physical access to a victim’s unlocked device, installation and configuration of most apps are straightforward. Prior research [40, 58] indicates that abusers often have access to victims’ phones and can obtain the necessary credentials.

Most apps, both on and off the Play Store, use a subscription payment model with tiered pricing. Popular dual-use apps on the Play Store cost between $5 for a lifetime upgrade (Wheres My Droid) and $10 USD per month (TrackView). Off-store apps range from $20 to $50 USD per month (for up to five phones).

On-store apps can be installed via the Play Store app, while off-store apps require configuring the device to allow installation from "unknown sources" and disabling Google Play Protect. Installation and configuration usually take only a few minutes of access to the victim’s phone.

Remote installation of dual-use apps is possible from the Google Play web interface if the abuser knows the credentials of the device’s primary Google account. However, Android requires that no third-party apps run until they are first opened on the device, and permissions must be granted. Thus, an abuser needs physical access to the device at least once for activation.

Once installed, the abuser links the victim device to their credentials for remote access. Credentials may be a username and password or a license number. Most off-store spyware can hide the app icon, and two on-store apps (Cerberus and TrackView) also offer this feature.

Depending on the type of IPS app, the abuser can access gathered data in different ways. Personal-use apps forward data to an email or phone number, mutual trackers require installation on two phones, and subordinate tracking apps often provide web portals for accessing information. We discovered that several portals have severe vulnerabilities, allowing arbitrary users to access sensitive information. Despite repeated attempts, we received no response from the vendors.

No app required rooting the victim’s phone, although many off-store spyware apps offer additional functionality if the device is rooted, such as reading contents of messaging apps like WhatsApp. Some companies (e.g., FlexiSpy) sell pre-rooted phones, providing a streamlined abuser experience with invasive monitoring abilities.

In summary, installation and use of IPS apps are easy for abusers, giving them dangerous surveillance capabilities.

#### App Capabilities

Both on-store and off-store apps provide a wide range of capabilities, from simple location tracking to near-complete remote control over a phone. We discuss these capabilities in three dimensions: monitoring abilities, covertness, and control.

**Monitoring Abilities**: IPS apps typically gather location, communication logs (SMS and call logs), communication data (SMS content or call recordings), media content (photos, videos, or files), and phone usage (app usage or web history). Many apps can also take photos or record ambient sounds in real-time.

**Covertness**: Most basic dual-use apps are GPS tracking apps that record the location and sync it with a remote server. Some, like family locator apps, allow sharing location data. Many third-party find-my-phone apps, such as Find My Android, respond via SMS with the device’s location when triggered by a code-word.

**Control**: Some apps offer full control, including remote locking and wiping, recording calls, syncing data, and controlling the phone remotely. Subordinate tracking apps often provide web portals for accessing information, and some can hide the app icon.

In conclusion, the ease of installation and the extensive capabilities of IPS apps pose significant risks, making it crucial to develop robust detection and prevention methods.