extending the untrusted attacker-provided code with runtime
checks. However, the attacks in Table 8 demonstrate that such
JIT checks can be transiently circumvented to leak memory
contents outside of the sandbox. Furthermore, in the case of
Spectre-BTB/RSB, even non-JIT compiled real-world code
has been shown to be exploitable when the attacker controls
sufﬁcient inputs to the victim application. Kocher et al. [50]
constructed a minimalist proof-of-concept that reads attacker-
controlled inputs into registers before calling a function. Next,
they rely on BTB poisoning to redirect transient control ﬂow
to a gadget they identiﬁed in the Windows ntdll library that
allows leaking arbitrary memory from the victim process.
Likewise, Chen et al. [13] analyzed various trusted enclave
runtimes for Intel SGX and found several instances of vul-
nerable branches with attacker-controlled input registers, plus
numerous exploitable gadgets to which transient control ﬂow
may be directed to leak unauthorized enclave memory. Bhat-
tacharyya et al. [9] analyzed common software libraries that
are likely to be linked against a victim program for gadgets.
They were able to ﬁnd numerous gadgets and were able to
exploit one in OpenSSL to leak information.
Case Study: Linux Kernel. To further assess the prevalence
of Spectre gadgets in real-world software, we selected the
Linux kernel (Version 5.0) as a relevant case study of a major
open-source project that underwent numerous Spectre-related
USENIX Association
28th USENIX Security Symposium    259
Table 8: Spectre-type attacks on real-world software.
Attack
Spectre-PHT [50]
Spectre-BTB [50]
Spectre-BTB [13]
Spectre-BTB [9]
Spectre-RSB [59]
Spectre-STL [29]
Gadgets
2
2
336
690
1
1
JIT Description

/




Chrome Javascript, Linux eBPF
Linux eBPF, Windows ntdll
SGX SDK Intel/Graphene/Rust
OpenSSL, glibc, pthread, ...
Firefox WebAssembly
Partial PoC on Linux eBPF
Figure 4: Evolution of Spectre-PHT patches in the Linux
kernel over time (2018-2019).
security patches over the last year. We opted for an in-depth
analysis of one speciﬁc piece of software instead of a breadth-
ﬁrst approach where we do a shallow analysis of multiple
pieces of software. This allowed us to analyse historical data
(i.e., code locations the kernel developers deemed necessary
to protect) that led to the second tier classiﬁcation discussed
in Section 5.1.
There are a couple of reasons that make analysis difﬁ-
cult. The ﬁrst is that Linux supports many different platforms.
Therefore, particular gadgets are only available in a speciﬁc
conﬁguration. The second point is that the number of instruc-
tions that can be transiently executed depends on the size of
the ROB [89]. As we analyze high-level code, we can only
estimate how far ahead the processor can transiently execute.
Table 7 shows the number of occurrences of each gadget
type from our second tier classiﬁcation. While Figure 4 shows
around 120 occurrences of array_index_nospec, the num-
ber of gadgets in our analysis is higher. The reason behind
that is that multiple arrays are indexed with the same masked
index and that there are multiple branches on a value that was
loaded with a potential malicious index. Our analysis also
shows that more dangerous gadgets that either allow more
than 1-bit leakage or even arbitrary code execution are not
frequently occurring. Even if one is found, it might still be
hard to exploit. During our analysis, we also discovered that
the patch had been reverted in 13 locations, indicating that
there is also some confusion among the kernel developers
what needs to be ﬁxed.
6 Defenses
In this section, we discuss proposed defenses in software and
hardware for Spectre and Meltdown variants. We propose a
classiﬁcation scheme for defenses based on their attempt to
stop leakage, similar to Miller [62]. Our work differs from
Miller in three points. First, ours extends to newer transient
execution attacks. Second, we consider Meltdown and Spec-
tre as two problems with different root causes, leading to a
Table 9: Categorization of Spectre defenses and systematic
overview of their microarchitectural target.
Defense InvisiSpec
SafeSpec
DAW
Reduction
Tracking
Stufﬁng
Retpoline
G
Timer
Taint
RSB
SLH
Serialization
Sloth
Masking
Isolation
Value
SSBD/SSBB
Poison
Index
Site
YSNB
IBRS
STIBP
IBPB
l
a
r
u
t
c
e
t
i
t Cache
n
e
TLB
m
e
BTB
l
E
BHB
PHT
RSB
AVX
FPU
Ports
h
c
r
a
o
r
c
i
M
C1
C2
C3
A defense considers the microarchitectural element (
it or same technique possible for it (
) or does not consider it at all (
).
), partially considers
different classiﬁcation. Third, it helped uncover problems that
were not clear with the previous classiﬁcation.
We categorize Spectre-type defenses into three categories:
C1: Mitigating or reducing the accuracy of covert channels
used to extract the secret data.
C2: Mitigating or aborting speculation if data is potentially
accessible during transient execution.
C3: Ensuring that secret data cannot be reached.
Table 9 lists proposed defenses against Spectre-type attacks
and assigns them to the category they belong.
We categorize Meltdown-type defenses into two categories:
D1: Ensuring that architecturally inaccessible data remains
inaccessible on the microarchitectural level.
D2: Preventing the occurrence of faults.
6.1 Defenses for Spectre
C1: Mitigating or reducing accuracy of covert channels.
Transient execution attacks use a covert channel to transfer
a microarchitectural state change induced by the transient
instruction sequence to the architectural level. One approach
in mitigating Spectre-type attacks is reducing the accuracy of
covert channels or preventing them.
Hardware. One enabler of transient execution attacks is that
the transient execution sequence introduces a microarchitec-
tural state change the receiving end of the covert channel
observes. To secure CPUs, SafeSpec [45] introduces shadow
hardware structures used during transient execution. Thereby,
any microarchitectural state change can be squashed if the
prediction of the CPU was incorrect. While their prototype
implementation protects only caches (and the TLB), other
channels, e.g., DRAM buffers [69], or execution unit conges-
tion [1, 9, 56], remain open.
Yan et al. [91] proposed InvisiSpec, a method to make
transient loads invisible in the cache hierarchy. By using a
speculative buffer, all transiently executed loads are stored in
this buffer instead of the cache. Similar to SafeSpec, the buffer
is invalidated if the prediction was incorrect. However, if the
260    28th USENIX Security Symposium
USENIX Association
04080OccurrencesJanFebMarAprMayJunJulAugSepOctNovDecJanFebMarAprarray_index_nospecarray_index_mask_nospecprediction was correct, the content of the buffer is loaded into
the cache. For data coherency, InvisiSpec compares the loaded
value during this process with the most recent, up-to-date
value from the cache. If a mismatch occurs, the transient load
and all successive instructions are reverted. Since InvisSpec
only protects the caching hierarchy of the CPU, an attacker
can still exploit other covert channels.
Kiriansky et al. [47] securely partition the cache across its
ways. With protection domains that isolate on a cache hit,
cache miss and metadata level, cache-based covert channels
are mitigated. This does not only require changes to the cache
and adaptions to the coherence protocol but also enforces the
correct management of these domains in software.
Kocher et al. [50] proposed to limit data from entering
covert channels through a variation of taint tracking. The idea
is that the CPU tracks data loaded during transient execution
and prevents their use in subsequent operations.
Software. Many covert channels require an accurate timer
to distinguish microarchitectural states, e.g., measuring the
memory access latency to distinguish between a cache hit and
cache miss. With reduced timer accuracy an attacker cannot
distinguish between microarchitectural states any longer, the
receiver of the covert channel cannot deduce the sent informa-
tion. To mitigate browser-based attacks, many web browsers
reduced the accuracy of timers in JavaScript by adding jit-
ter [61,70,80,88]. However, Schwarz et al. [73] demonstrated
that timers can be constructed in many different ways and,
thus, further mitigations are required [71]. While Chrome
initially disabled SharedArrayBuffers in response to Melt-
down and Spectre [80], this timer source has been re-enabled
with the introduction of site-isolation [77].
NetSpectre requires different strategies due to its remote
nature. Schwarz et al. [74] propose to detect the attack using
DDoS detection mechanisms or adding noise to the network
latency. By adding noise, an attacker needs to record more
traces. Adding enough noise makes the attack infeasible in
practice as the amount of traces as well as the time required
for averaging it out becomes too large [87].
C2: Mitigating or aborting speculation if data is poten-
tially accessible during transient execution.
Since Spectre-type attacks exploit different prediction
mechanisms used for speculative execution, an effective
approach would be to disable speculative execution en-
tirely [50, 79]. As the loss of performance for commodity
computers and servers would be too drastic, another proposal
is to disable speculation only while processing secret data.
Hardware. A building blocks for some variants of Spectre
is branch poisoning (an attacker mistrains a prediction mech-
anism, cf. Section 3). To deal with mistraining, both Intel
and AMD extended the instruction set architecture (ISA) with
a mechanism for controlling indirect branches [4, 40]. The
proposed addition to the ISA consists of three controls:
• Indirect Branch Restricted Speculation (IBRS) prevents
indirect branches executed in privileged code from being
inﬂuenced by those in less privileged code. To enforce
this, the CPU enters the IBRS mode which cannot be
inﬂuenced by any operations outside of it.
• Single Thread Indirect Branch Prediction (STIBP) re-
stricts sharing of branch prediction mechanisms among
code executing across hyperthreads.
• The Indirect Branch Predictor Barrier (IBPB) prevents
code that executes before it from affecting the prediction
of code following it by ﬂushing the BTB.
For existing ARM implementations, there are no generic
mitigation techniques available. However, some CPUs im-
plement speciﬁc controls that allow invalidating the branch
predictor which should be used during context switches [6].
On Linux, those mechanisms are enabled by default [46].
With the ARMv8.5-A instruction set [7], ARM introduces
a new barrier (sb) to limit speculative execution on follow-
ing instructions. Furthermore, new system registers allow to
restrict speculative execution and new prediction control in-
structions prevent control ﬂow predictions (cfp), data value
prediction (dvp) or cache prefetch prediction (cpp) [7].
To mitigate Spectre-STL, ARM introduced a new barrier
called SSBB that prevents a load following the barrier from by-
passing a store using the same virtual address before it [6]. For
upcoming CPUs, ARM introduced Speculative Store Bypass
Safe (SSBS); a conﬁguration control register to prevent the
re-ordering of loads and stores [6]. Likewise, Intel [40] and
AMD [3] provide Speculative Store Bypass Disable (SSBD)
microcode updates that mitigate Spectre-STL.
As an academic contribution, plausible hardware mitiga-
tions have furthermore been proposed [48] to prevent transient
computations on out-of-bounds writes (Spectre-PHT).
Software. Intel and AMD proposed to use serializing instruc-
tions like lfence on both outcomes of a branch [4,35]. ARM
introduced a full data synchronization barrier (DSB SY) and
an instruction synchronization barrier (ISB) that can be used
to prevent speculation [6]. Unfortunately, serializing every
branch would amount to completely disabling branch predic-
tion, severely reducing performance [35]. Hence, Intel further
proposed to use static analysis [35] to minimize the number of
serializing instructions introduced. Microsoft uses the static
analyzer of their C Compiler MSVC [68] to detect known-bad
code patterns and insert lfence instructions automatically.
Open Source Security Inc. [66] use a similar approach using
static analysis. Kocher [49] showed that this approach misses
many gadgets that can be exploited.
Serializing instructions can also reduce the effect of in-
direct branch poisoning. By inserting it before the branch,
the pipeline prior to it is cleared, and the branch is resolved
quickly [4]. This, in turn, reduces the size of the speculation
window in case that misspeculation occurs.
While lfence instructions stop speculative execution,
Schwarz et al. [74] showed they do not stop microarchitec-
tural behaviors happening before execution. This, for instance,
USENIX Association
28th USENIX Security Symposium    261
includes powering up the AVX functional units, instruction
cache ﬁlls, and iTLB ﬁlls which still leak data.
Evtyushkin et al. [18] propose a similar method to seri-
alizing instructions, where a developer annotates potentially
leaking branches. When indicated, the CPU should not predict
the outcome of these branches and thus stop speculation.
Additionally to the serializing instructions, ARM also in-
troduced a new barrier (CSDB) that in combination with con-
ditional selects or moves controls speculative execution [6].
Speculative Load Hardening (SLH) is an approach used by
LLVM and was proposed by Carruth [12]. Using this idea,
loads are checked using branchless code to ensure that they
are executing along a valid control ﬂow path. To do this,
they transform the code at the compiler level and introduce
a data dependency on the condition. In the case of misspec-
ulation, the pointer is zeroed out, preventing it from leaking
data through speculative execution. One prerequisite for this
approach is hardware that allows the implementation of a
branchless and unpredicted conditional update of a register’s
value. As of now, the feature is only available in LLVM for
x86 as the patch for ARM is still under review. GCC adopted
the idea of SLH for their implementation, supporting both
x86 and ARM. They provide a builtin function to either emit
a speculation barrier or return a safe value if it determines
that the instruction is transient [17].
Oleksenko et al. [65] propose an approach similar to Car-
ruth [12]. They exploit that CPUs have a mechanism to detect
data dependencies between instructions and introduce such a
dependency on the comparison arguments. This ensures that
the load only starts when the comparison is either in regis-
ters or the L1 cache, reducing the speculation window to a