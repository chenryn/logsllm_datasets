title:Examining Failures and Repairs on Supercomputers with Multi-GPU Compute
Nodes
author:Amir Taherin and
Tirthak Patel and
Giorgis Georgakoudis and
Ignacio Laguna and
Devesh Tiwari
2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)
3
4
0
0
0
.
1
2
0
2
.
7
8
9
8
4
N
S
D
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
1
2
0
2
©
0
0
.
1
3
$
/
1
2
/
7
-
2
7
5
3
-
4
5
6
6
-
1
-
8
7
9
|
)
N
S
D
(
s
k
r
o
w
t
e
N
d
n
a
s
m
e
t
s
y
S
e
l
b
a
d
n
e
p
e
D
n
o
e
c
n
e
r
e
f
n
o
C
l
a
n
o
i
t
a
n
r
e
t
n
I
P
I
F
I
/
E
E
E
I
l
a
u
n
n
A
t
s
1
5
1
2
0
2
Examining Failures and Repairs on Supercomputers
, Devesh Tiwari(cid:2)
with Multi-GPU Compute Nodes
†
, Ignacio Laguna
(cid:2)Northeastern University
Amir Taherin(cid:2), Tirthak Patel(cid:2), Giorgis Georgakoudis
Lawrence Livermore National Laboratory
†
†
Abstract—Understanding the reliability characteristics of su-
percomputers has been a key focus of the HPC and dependability
communities. However, there is no current study that analyzes
both the failure and recovery characteristics over multiple gener-
ations of a GPU-based supercomputer with multiple GPUs on the
same node. This paper bridges that gap and reveals surprising
insights based on monitoring and analyzing the failures and
repairs on the Tsubame-2 and Tsubame-3 supercomputers.
I. INTRODUCTION
HPC system reliability has been a major area of research
for multiple decades. The primary driving factor has been
the need to provide sustained reliability for long-running
applications executing on multiple nodes. This line of re-
search has resulted in making CPUs more reliable over time,
and now GPUs too [1]–[6] – as they have become main-
stream for supercomputing. While there have been multiple
ﬁeld studies about GPU and CPU errors [7]–[11], they are
largely focused on a single production-scale supercomputer.
There is no existing study that shares the experience and
lessons learned from GPU-accelerated supercomputers over
multiple generations. Furthermore, previous studies on GPU-
accelerated supercomputers have included only one GPU per
node and are limited to NVIDIA K80 or older GPUs [8]–
[11]. In this study, we study two generations of Tsubame
supercomputers (employing NVIDIA K20X and P100 GPUs);
and importantly, each node has multiple GPU cards, which
results in previously unobserved failure characteristics and
creates opportunities for further innovation [8]–[14].
Additionally, this study also highlights the need for opti-
mizing the time to recovery from failure – an aspect that has
not received sufﬁcient discussion and attention from previous
ﬁeld-studies. But, we show that the time to recovery is now
becoming an important concern and ﬁgure of metric for
system operations. Innovative solutions are needed to reduce
the time to recovery, and in turn minimize the impact of
failures on system operations. Overall, our major ﬁndings and
implications include:
• As expected, GPUs are one of
the most critical
components in these GPU-accelerated supercomputers
from the reliability point of view. Contrary to other GPU
deployments [10], [11], [15], we ﬁnd that the hardware
reliability of NVIDIA GPUs has improved remarkably
over the generations (up to 4× improvement in overall
system MTBF). But, GPU-related software and ﬁrmware
failures (e.g., GPU driver issues) are still a concern
from further
research investment
and could beneﬁt
the GPU vendor/chip manufacturer.
from outside
We also introduce a new term “performance-error-
proportionality” to encourage systems community to
jointly capture the effects of raw computing power and
failure rate for benchmarking: “useful work done per
failure-free period” (e.g., total FLOP per MTBF).
failure
• We found that software failures are becoming the
dominant
supercomputers.
Alarmingly, the cause or type of a large fraction of these
software failures is not known and are difﬁcult to be
reproduced.
these
type
on
• As we move
toward multi-accelerator-per-node
supercomputers, our
system
operators need to be wary of multiple GPUs failing
simultaneously, and the failure distribution within a node
being non-uniform and temporally correlated.
analysis
reveals
that
• While the mean time between two failures has improved
drastically over the generations, we ﬁnd that the mean
time to recovery remains largely similar, i.e., the time to
quickly heal from a failure is not improving at all. Each
failure disrupts the system for roughly the same amount
of time. Our failure type and seasonal analysis shows
that the time to recovery trends vary across failure types
and are not necessarily strongly correlated by the failure
density in a particular time frame.
Our analysis tool and failure logs are available open-source
at: http://doi.org/10.5281/zenodo.4606221.
II. TSUBAME SUPERCOMPUTER BACKGROUND AND
ANALYSIS METHODOLOGY
Tsubame is a supercomputer-class series of large-scale
computing facilities housed at
the Global Scientiﬁc Infor-
mation and Computing Center (GSIC) at Tokyo Institute of
Technology. Tsubame-1 was announced in 2006 as the then
most powerful supercomputer in Japan. Tsubame-1 leveraged
speciﬁc accelerators from ClearSpeed. Tsubame-2 was intro-
duced in 2010 with 1408 nodes reaching theoretical peak
(Rpeak) of 2.3 PFlop/s and power consumption of 1.4 MWatts.
In 2017, Tsubame-3 was announced for Artiﬁcial Intelligence
applications. It reached a theoretical peak (Rpeak) of 12.1
PFlop/s with power consumption of 792 kW. In terms of
978-1-6654-3572-7/21/$31.00 ©2021 IEEE