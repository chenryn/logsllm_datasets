Assume we are trying to learn a sequence to sequence map. For this we can use
Recurrent and TimeDistributedDense layers. Now assume that the sequences have
different lengths. We should pad both input and desired sequences with zeros,
right? But how will the objective function handle the padded values? There is
no choice to pass a mask to the objective function. Won't this bias the cost
function?