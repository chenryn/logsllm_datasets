title:Quantitative Evaluation of Dynamic Platform Techniques as a Defensive
Mechanism
author:Hamed Okhravi and
James Riordan and
Kevin M. Carter
Quantitative Evaluation of Dynamic Platform
Techniques as a Defensive Mechanism(cid:2)
Hamed Okhravi, James Riordan, and Kevin Carter
{hamed.okhravi,james.riordan,kevin.carter}@ll.mit.edu
MIT Lincoln Laboratory
Abstract. Cyber defenses based on dynamic platform techniques have been pro-
posed as a way to make systems more resilient to attacks. These defenses change
the properties of the platforms in order to make attacks more complicated. Un-
fortunately, little work has been done on measuring the effectiveness of these
defenses. In this work, we ﬁrst measure the protection provided by a dynamic
platform technique on a testbed. The counter-intuitive results obtained from the
testbed guide us in identifying and quantifying the major effects contributing to
the protection in such a system. Based on the abstract effects, we develop a gen-
eralized model of dynamic platform techniques which can be used to quantify
their effectiveness. To verify and validate our results, we simulate the general-
ized model and show that the testbed measurements and the simulations match
with small amount of error. Finally, we enumerate a number of lessons learned
in our work which can be applied to quantitative evaluation of other defensive
techniques.
Keywords: Dynamic platforms, platform diversity, quantitative evaluation, met-
rics, intrusion tolerance, moving target.
1 Introduction
Developing secure systems is difﬁcult and costly. The high cost of effectively mitigating
all vulnerabilities and the far lesser cost of exploiting a single one creates an environ-
ment which advantages cyber attackers. New active cyber defense paradigms have been
proposed to re-balance the landscape and create uncertainty for the attackers [1]. One
such paradigm is active defenses based on dynamic platform techniques.
Dynamic platform techniques (or simply, dynamic platforms) dynamically change
the properties of a computing platform in order to complicate attacks. Platform prop-
erties refer to hardware and operating system (OS) attributes such as instruction set
architecture (ISA), stack direction, calling convention, kernel version, OS distribution,
and machine instance. Various dynamic platform techniques have been proposed in the
literature. Emulation-based techniques change the calling sequence and instruction set
presented to an application [2]; multivariant execution techniques change properties
such as stack direction or machine description using compiler generated diversity and
(cid:2) This work is sponsored by the Department of Defense under Air Force Contract #FA8721-05-
C-0002. Opinions, interpretations, conclusions and recommendations are those of the author
and are not necessarily endorsed by the United States Government.
A. Stavrou et al. (Eds.): RAID 2014, LNCS 8688, pp. 405–425, 2014.
c(cid:2) Springer International Publishing Switzerland 2014
406
H. Okhravi, J. Riordan, and K. Carter
virtualization [3–6]; migration-based techniques change the hardware and operating
system of an application using containers and compiler-based checkpointing [7]; server
diversiﬁcation techniques rotate a server across multiple platforms and software stacks
using network proxies [8]; self cleansing techniques change the machine instance by
continuously rotating across many virtual machines and re-imaging the inactive ones
[9–11].
Unfortunately, little work has been done on understanding and quantifying the im-
pact of dynamic platforms on the security of a system. The impact of such techniques
is often assumed to be intuitive and straight forward. Moreover, one cannot compare
different features provided by different dynamic platforms in a quantitative way. For
example, is it more effective to support multiple platforms that are running simultane-
ously and voting on the result (a.k.a. multi-instance), or to have one active platform, but
support cleansing of the inactive ones (a.k.a. cleanup)?
In this work, we ﬁrst identify the four major features proposed by different dynamic
platforms in the literature. We then perform a set of experiments on a testbed with one
such technique that is augmented to support these features in order to quantify its pro-
tection. The results from our testbed experiments are, in fact, counter-intuitive and com-
plex. The complexity of the results suggest that various underlying effects contribute to
such a system.
Based on our observations and the mathematical principles involved, we enumerate
and analyze the various underlying effects in an abstract analysis of a dynamic platform
system. To evaluate the completeness of our enumerated list of abstract effects, we
develop a generalized model of dynamic platforms based on these effects and verify
and validate the model by simulating the same experiments as the ones we performed
on the testbed. The matching results and the small amounts of error validate our model
and verify that we have at least correctly captured the main effects contributing to the
protection provided by a dynamic platform. Finally, we enumerate a number of lessons
learned that can be applied to the quantitative evaluation of other defensive techniques.
Our contributions are as follows:
– To the best of our knowledge, we perform the ﬁrst quantitative evaluation of dy-
namic platforms as a defensive mechanism and illustrate the complexities and the
counter-intuitive effects contributing to such a system. Moreover, we enumerate the
major effects and their impacts.
– We develop a generalized model of dynamic platforms and simulate the results. We
verify and validate the model by comparing the simulated results with the testbed
experiments and show that they match closely.
– We demonstrate how testbed experiments, abstract analysis, and modeling and sim-
ulation can be used together to quantify the impact of defensive techniques. In our
work, testbed experiments are used to uncover the complexities, abstract analysis is
used to enumerate and describe such complexities, and modeling and simulation is
used to check the completeness of the abstract analysis and to validate the results.
We enumerate a number of lessons learned which can guide future evaluations of
the defenses.
The rest of the paper is organized as follows. Section 2 provides a brief overview
of dynamic platform techniques. Section 3 describes the threat model used throughout
Quantitative Evaluation of Dynamic Platform Techniques
407
the paper. Section 4 discusses our testbed experiments and measurements performed
on a real system. Section 5 discusses our abstract analysis approach and its results.
Section 6 describes our generalized model of dynamic platforms. Section 7 presents
the simulation results from the generalized model. Section 8 enumerates a number of
lessons learned and discusses our ﬁndings. We discuss the related work in Section 9
before concluding the paper in Section 10.
2 Dynamic Platform Background
We brieﬂy describe the defensive techniques based on dynamic platforms. We provide
enough background for understanding the rest of the paper. More details about each
technique can be found in its original publication.
Dynamic platform techniques change platform properties in order to make attacks
more complicated [12]. They often rely on temporal changes (e.g. VM rotation), di-
versity (e.g. multivariant execution), or both (e.g. migration-based techniques) to pro-
tect a system. These techniques are often implemented using machine-level or operat-
ing system-level virtualization, compiler-based code diversiﬁcation, emulation layers,
checkpoint/restore techniques, or a combination thereof. Emulation-based techniques
such as Genesis [2] often use an application-level virtual machines such as Strata [13] or
Valgrind [14] to implement instruction set diversity. In some cases, multiple instances
are executed and a monitor compares their results. Multivariant execution techniques
such as Reverse stack [15] (also called N-variant systems [16]) use compiler-based
techniques to create diverse application code by replacing sets of instructions with se-
mantically equivalent ones. Migration-based techniques such as Talent [7] use operating
system-level virtualization (containers) to move an application across diverse architec-
tures and operating systems. A dynamic platform can also be achieved at a higher ab-
straction level by switching between different implementations of servers [8]. These
techniques either do not preserve the state (e.g. a web server) or they preserve it using
high level conﬁguration ﬁles (e.g. DNS server). Finally, self-cleansing techniques such
as SCIT [9] only change the current instance of the platform without diversifying it.
The main goal, in this case, is bringing the platform to its pristine state and removing
persistence of attacks.
We have identiﬁed four features that determine the protection provided by dynamic
platform techniques. Later in our analysis, we show that these features can result in very
different defensive beneﬁts for each technique. The four features are:
Diversity. A dynamic platform technique provides diversity if it changes the properties
of the platform used for running the application. For example, the Reversed Stack
[15] technique provides diversity because it changes the direction of stack growth
whereas SCIT [9] does not because it rotates the service among homogeneous vir-
tual machines.
Multi-Instance. A technique is multi-instance if more that one platform instance is
used to serve a transaction simultaneously. For example, multivariant execution [3]
is a multi-instance technique because it runs a transaction on multiple different in-
stances of the platform and compares the results, whereas Talent [7] is not, because
it uses one instance at a time.
408
H. Okhravi, J. Riordan, and K. Carter
Table 1. Features of some of the dynamic platform techniques
Diversity Multi-Instance Limited Duration Cleanup
Technique
SCIT [9]
GA-Based Conﬁguration [17]
MAS [18]
Multivariant Execution [3]
Reversed Stack [15]
Talent [17]
Machine desc. diversity [6]
N-Variant System [16]
Intrusion Tolerance for MCS [19]
Intrusion Tolerant WS [8]
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
Limited Duration. A technique has limited duration if the instance of the platform can
change while processing a single transaction. Otherwise, we call it extended dura-
tion which means that the technique must ﬁnish processing a transaction before it
can change the instance of the platform. For example, using genetic algorithms to
change platform conﬁgurations [17] has limited duration because the the conﬁgura-
tion can change while processing a transaction whereas moving attack surfaces [18]
completes each transaction on the same instance on which it started (i.e. extended
duration).
Cleanup. A technique supports cleanup if each instance is wiped and imaged into
a pristine state before it is used again. For example, SCIT [9] supports cleanup
whereas multivariant execution does not.
Table 1 shows a list of representative dynamic platform techniques and their features.
We use one of the above techniques, Talent, to quantitatively analyze the effective-
ness of dynamic platforms. Although Talent does not natively support multi-instance
and cleanup, we augment it with these features to understand their impact. The main
reason for using Talent was its code availability, but we show that our analysis can be
generalized based on the features of the techniques.
In this work, our goal is not to provide arguments for merits or demerits of any of
the proposed dynamic platform techniques. Rather, we strive to quantitatively evaluate
dynamic platforms as a cyber defense mechanism and study various features that can
signiﬁcantly change their impact.
2.1 Talent
Talent [7] is a technique that allows live migration of applications across diverse plat-
forms. It uses operating-system-level virtualization (OpenVZ [20]) to sandbox an ap-
plication and migrate the environment. For internal process state migration, Talent uses
a portable checkpoint compiler (CPPC [21]) to insert checkpointing instructions into
a code. At the time of migration, it pauses a process, checkpoints its state, moves the
Quantitative Evaluation of Dynamic Platform Techniques
409
state to the next platform, and resumes the execution. Some portions of the code are
re-executed in order to construct the entire state.
Since it allows an application to run on different operating systems and architecture,
Talent provides diversity. Also, it is a limited duration technique, because it can pause a
process and resume it on a different platform. However, it does not natively support multi-
instance since one platform is active at a time; it does not implement cleanup either.
Talent has been implemented on Intel Xeon 32-bit, Intel Core 2 Quad 64-bit, and
AMD Opteron 64-bit processors. It has also been tested with Gentoo, Fedora (9, 10, 11,
12, and 17), CentOS (4, 5, and 6.3), Debian (4, 5, and 6), Ubuntu (8 and 9), SUSE (10
and 11), and FreeBSD 9 operating systems.
3 Threat Model
We discuss multiple threat models in this paper but analysis shows that they share com-
mon features. To make the analysis more precise, we explicitly describe the core threat
model in this section. Variations upon the core threat model are described in the other
sections as appropriate.
In our model, the defender has a number of different platforms to run a critical ap-
plication. The attacker has a set of exploits (attacks) that are applicable against some of
these platforms, but not the others. We call the platforms for which the attacker has an
exploit “vulnerable” and the others “invulnerable.” In a strict systems security terminol-
ogy, vulnerable does not imply exploitable; without loss of generality, we only consider
exploitable vulnerabilities. An alternative interpretation of this threat model is that the
vulnerabilities are exploitable on some platforms, but not on the other ones.
The defender does not know which platforms are vulnerable and which are invulner-
able, nor does she have detection capabilities for the deployed exploits. This scenario,
for example, describes the use of zero-day exploits by attackers, for which no detection
mechanism exists by deﬁnition.
Since there is little attempt to isolate the inactive platforms in dynamic platform
systems, we assume that all platforms are accessible by the attacker, and the attacker
attempts to exploit each one.
The attacker’s goal is what creates the variations in our threat model. For example,
one success criteria may be for the attacker to compromise the system for a given pe-
riod of time to cause irreversible damage (e.g. crash a satellite), while a different success
criteria gives the attacker gradual gain the longer the system is compromised (e.g. ex-
ﬁltration of information). Different techniques with different features provide varying
protections against these goals which we study in the subsequent sections.
4 Experiments
4.1 Experiment Setup
To understand the protection provided by dynamic platforms, we start by performing
simple experiments with Talent and two real-world exploits. We observe that contrary
410
H. Okhravi, J. Riordan, and K. Carter
to the naïve view, even these simple experiments result in very complex results which
highlight a number of subtleties about dynamic platforms.
To perform the experiments, a notional application with C back-end and GUI front-
end has been ported to Talent. The application’s back-end performs attestation of ma-
chines within a local network and its front-end displays the result. However, the details
of the application are unimportant for the evaluations done in this work, so for the sake
of brevity we do not discuss them here.
On the testbed, we have a pool of ﬁve different platforms: Fedora on x86, Gentoo on
x86, Debian on x86_64, FreeBSD on x86, and CentOS on x86. The application runs for
a random amount of time on a platform before migrating to a different one (i.e. platform
duration).
The attacker’s goal in the experiments is to control the active platform for some time
T . Since in a real scenario the vulnerability of the platform is unknown, we may con-
secutively migrate to multiple vulnerable platforms, in which case the attacker wins.
To implement this scenario on the testbed, we launch two real exploits against Talent.
The ﬁrst is the TCP MAXSEG exploit which triggers a divide by zero vulnerability in
net/ ipv4/tcp.c (CVE-2010-4165) to perform a DoS attack on the platform. Only
the Gentoo platform is vulnerable to this attack. The second attack is the Socket Pairs
exploit which triggers a garbage collection vulnerability in net/unix/
garbage.c (CVE-2010-4249) to saturates the CPU usage and ﬁle descriptors. The Fe-
dora and CentOS platforms are vulnerable to this attack. Our Debian and FreeBSD
platforms are not vulnerable to these exploits.
In each conﬁguration, we select N ∈ (1, 5) platforms. For each trial, the application
randomly migrates across those N platforms without immediate repeat. In the case
of N = 1 (baseline), the application remains on the same platform during the entire
trial. Without loss of generality, the duration on each platform (d) is chosen randomly
and uniformly from 40 − 60 seconds. Although we have no reason to believe that these
are the appropriate values for a real-world application, we will show later that the actual
values of the duration (d) and attacker’s goal (T ) are inconsequential to our experiments
and can be parametrized.
One or both exploits become available to the attacker at random times during each
trial. As a result, zero to three platforms can be compromised (zero when the exploit is
not effective against the set of platforms and three when both exploits are available and
Fedora, CentOS, and Gentoo are in the pool of platforms). When the exploit is launched,
its payload reaches all of the platforms in the selected set at once (not one after another).
This approach tries to model the behavior of network-based exploits that propagate to all
machines within a network very rapidly. Each trial runs for 15 minutes. We collect 300
trials for each conﬁguration. We also collect a central log which includes a timestamp,
the status of each platform (up or down), and the active platform and a local log (for
veriﬁcation purposes) which also includes ﬁner-grained CPU load for each platform.
Fig. 1 illustrates one trial with 3 platforms. The red arrows show when exploits are
launched. In this case, platforms 2 and 5 are vulnerable to exploits 1 and 2 respectively.
A shaded rectangle shows a compromised platform while a white rectangle shows an
uncompromised one (vulnerable or invulnerable).
Quantitative Evaluation of Dynamic Platform Techniques
411
Exploit 1 
Exploit 2 
P2 
P5 
P2 
P1 
time 
P2 
P5 
P1 
Fig. 1. A 3-platform trial
Uncompromised 
Compromised 
4.2 Experiment Results
We calculate the value of the metric, which is the percentage of time that the attacker is
in control for longer than T and present these results in Fig. 2.
The results are completely perplexing. In fact, the results are so counter-intuitive that
we initially thought that some mistakes have been made in collecting them. We can at
least observe the following peculiarities in the results.
– The 1-platform result is very different than the others and seems to estimate a
straight line for T > 100 sec.
– More platforms does not always result in lower chance of attacker success. Speciﬁ-
cally for 60  120, more platforms result in lower chance of attacker success and that
remains the case for larger values of T .
The complexity of the results suggest that various effects should be in play which we
explain one by one in the next section.
s
d
e
e
c
c
u
S
r
e
k
c
a
t
t
i
A
e
h
t
e
m
T
f
o
n
o
i
t
r
o
P
0.35 
0.3 
0.25 
0.2 
0.15 
0.1 
0.05 
0 
0 
1 Platform 
2 Platforms 
3 Platforms 