 45
 55
 60
Fig. 5: Throughput robustness during crash-stop failures. We
plot
throughput when a replica crashes in the consensus-based
system (either the leader or a random replica) and Astro I.
represent optimistic upper-bounds. In BFT-SMaRt we omit
the cross-shard coordination step, which typically consists
of a 2PC protocol posing signiﬁcant overhead, thus a fully
working sharded solution would necessarily sustain less than
4K pps [48], [80].
D. Performance Robustness
We now investigate how our Astro and the baseline react
to two problems that can arise in practice, namely failure
(e.g., crash) and asynchrony (network delays) at a replica.
We consider the impact of these issues when they affect a
random replica in each system, as well as the case when the
leader is affected in the consensus-based system.
Astro I and Astro II have similar robustness characteris-
tics: they are completely decentralized (there is no leader)
and making a payment only requires broadcasting a message.
To maximize fairness of comparison, we experiment with
Astro I, as its message pattern and cryptographic primitives
(MAC-based channel authentication) are the most similar to
BFT SMaRt.
We study the evolution of throughput within a window of
execution of 40s, ignoring a warm-up period of 20s. For
all these experiments, we introduce asynchrony or failure
after 30s elapse. To induce asynchrony, we again use the
trafﬁc control utility tc with the network emulator queuing
discipline. We always use a delay of 100ms. For instance, to
introduce such a delay on all packets outgoing from interface
eth0 at a replica, we use the following command:
tc qdisc change dev eth0 root netem delay 100ms.
We use 10 clients, each running a single thread. The goal
is to evaluate these systems below saturation point. If we
introduce failures at saturation, this can lead BFT-SMaRt to
halt or enter a livelock where the system is unable to do view-
change (i.e. leader election). Moreover, at saturation point
Astro can sustain the same throughput independently of how
many replicas accept client operations; this is because no
single replica in our broadcast-based system is a bottleneck.
In other words, stopping a replica at saturation point in Astro
would not impact throughput, giving an advantage to our
system over the consensus-based solution. We ﬁrst report
results for a system size N = 49. We run these experiments
with larger and smaller systems, but similar observations
emerge as the ones we describe below. For completeness, we
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:24:09 UTC from IEEE Xplore.  Restrictions apply. 
34
 400
 300
 200
 100
t
u
p
h
g
u
o
r
h
T
)
c
e
s
/
s
t
n
e
m
y
a
p
(
 200
 100
t
u
p
h
g
u
o
r
h
T
)
c
e
s
/
s
t
n
e
m
y
a
p
(
Consensus-Leader-A
Consensus-Leader-B
Consensus-Random
Broadcast-Random
Consensus-Fail
Consensus-Async
Broadcast-Fail
Broadcast-Async
Asynchrony
Crash-stop failure or asynchrony
 0
 20
 25
 35
 50
 30
Execution history (seconds)
 40
 45
 55
 60
 0
 20
 25
 35
 30
 50
Execution history (seconds)
 40
 45
 55
 60
Fig. 6: Throughput robustness during asynchrony. We show, for
N=49, how throughput evolves in the consensus- and broadcast-
based systems during asynchrony (100ms delay for each outgoing
packet) at one replica, either the leader or random.
also discuss a set of interesting results with a larger system
size of N = 100.
In Figure 5 we show how the throughput evolves when
we introduce a crash-stop failure at a replica (N = 49). For
consensus, this failure has a severe impact on throughput if
the leader is affected (the Consensus-Leader curve), because
the view-change protocol has to execute. The throughput
drops to 0 while this protocol runs, typically a few seconds.
For larger system sizes, this protocol can take longer to
execute, as we will show later. When a random replica fails
in the consensus-based system (Consensus-Random), there is
a brief decrease in throughput when all clients and replicas
get disconnected from the affected replica, but thereafter
performance recovers. In Astro I we stop a random replica
(Broadcast-Random), and thereafter throughput drops from
270 pps to 250 pps, which accounts for the failed replica
which was handling roughly 20 pps from one of the clients.
This decrease is barely visible in the plots.
Figure 6 shows how asynchrony impacts the performance
in the two systems (N = 49). We depict
two separate
executions for the case of consensus when the leader is
affected, because there are two possible outcomes. First, it
may happen that throughput decreases and remains that way;
this is the Consensus-Leader-A timeline. Second, the system
can go through a view-change (Consensus-Leader-B) because
the leader is too slow or its buffers can overﬂow and packets
get dropped (inﬂating the replica-to-replica delay). Clearly,
initiating a view-change is preferable in this case, because the
throughput penalty is smaller. There is a well-known tradeoff,
however, in choosing the view-change timeout [26], [60]:
initiating view-change too aggressively can lead to frequent
leader changes even in good conditions, which can erode
performance on the long-run.
When a random replica is affected with asynchrony in
the consensus-based system (Consensus-Random execution
in Figure 6), performance drops brieﬂy because there is a
quorum switch, i.e., the affected replica is replaced by a
different one in the active quorum [9]. For the broadcast-
based system (the Broadcast-Random timeline), asynchrony
affects performance in the same manner in which a failure
does. Concretely, the affected replica no longer sustains the
same amount of client operations, so the overall throughput
reduces correspondingly.
Fig. 7: Throughput robustness. We show how throughput evolves
for N = 100 when a crash-stop failure or asynchrony affects the
consensus-based system or the broadcast-based system.
We also show results for the case of a larger system size
(N = 100) in Figure 7. There are four timelines in this
execution, as follows. For the consensus-based solution, we
show what happens when there is either a crash-stop failure
or asynchrony at the leader. In the former case (Consensus-
Fail), the view-change protocol kicks off and lasts for roughly
20 seconds, while throughput stays at zero; this is similar
to the Consensus-Leader execution in Figure 5. In the latter
case (Consensus-Async), performance degrades and stays that
way for as long as the affected replica remains the leader;
this is similar to the Consensus-Leader-A in Figure 6. For
the broadcast-based solution we consider the same two issues
affecting a random replica. When either of these issues arises
(Broadcast-Fail or Broadcast-Async) throughput is affected
correspondingly with the number of operations that the failed
replica is handling (and which is unable to continue). Note
that Astro relies on fate-sharing [25] between a client and its
representative: when a replica stops, all the associated xlogs
naturally stop as well.
We conclude with two general observations. First, Astro
does not suffer from overall (i.e., global) throughput degra-
dation that can happen in leader-based protocols such as
most consensus algorithms. Second, our system does not rely
on timeouts for liveness. Simply put, Astro progresses at
the speed of the network. These two advantages are closely
linked, and they both follow from the asynchronous nature
of the broadcast protocol we rely on.
VII. RELATED WORK
Since Nakamoto’s original Bitcoin paper [62], follow-up
payment systems seek to prevent double-spending by estab-
lishing a total order of transactions, i.e., solving consensus.
Consequently, a lot of effort has been devoted to improving
the consensus layer.
Dealing with the Consensus Bottleneck. Research on
consensus algorithms has shown signiﬁcant breakthroughs
and modern protocols quote impressive performance num-
bers [79], [80]. To push performance even further, several
interesting systems address the consensus bottleneck with
sharding [4], [48], [53], [80], [76]. Approving a cross-shard
payment, however, requires special coordination [48], [76],
[80]. Off-chain payment networks such as Lightning [64] and
Raiden [63] strive to minimize the impact of consensus pro-
tocols. They allow parties to move funds from a blockchain
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:24:09 UTC from IEEE Xplore.  Restrictions apply. 
35
into high-performance payment channels, for which the ﬁnal
balance is settled back on the blockchain after use. Recent
advances in this ﬁeld rely on trusted hardware to provide an
asynchronous protocol for all interactions [51]. These results
bring noticeable improvements over Bitcoin, enabling good
scalability and very fast payments. Nevertheless, the under-
lying problem of consensus is only reduced, not overcome.
In Astro we take a different approach: We provide robust
performance by avoiding consensus protocols altogether.
Performance Instability of Consensus. Recent work empha-
sizes the problem that performance of consensus algorithms
hangs on a fragile thread, namely their view-change sub-
protocol [17], [38], [78]. HotStuff, for instance, proposes
to absorb view-change in the common-case consensus algo-
rithm; this sidesteps performance instability but comes with
the cost of a higher common-case latency [78].
Another line of research circumvents the view-change
issue with randomized consensus protocols, such as Hon-
eyBadgerBFT [60] or BEAT [32]. Both are based on work
by Ben-Or et al. [11] combining reliable broadcast (BRB)
with binary Byzantine agreement (ABA). In a nutshell, these
protocols comprise a broadcast phase (where replicas form
encrypted batches of payments which they disseminate using
BRB), an agreement phase (involving N instances of the
ABA protocol to agree on a common set of batches), and
a decryption phase (requiring each replica to obtain f + 1
decryption shares). These protocols push the performance of
consensus by carefully choosing modern cryptographic tools
and system parameters.
Various leaderless consensus protocols have been pro-
posed, for both crash and Byzantine models [14], [28], [29],
[49], [61]. These protocols, however, either make use of some
form of coordinator in corner-cases, or rely on additional
synchrony assumptions, or provide probabilistic guarantees.
For example, a thorough study of the appendix of [61] reveals
that EPaxos only ensures probabilistic liveness and, as shown
recently [71], has correctness issues.
Astro is deterministic and fully asynchronous. It does not
solve the general consensus problem, but instead focuses on
payments. Since our system relies exclusively on BRB and no
BA primitive is necessary, Astro is simpler and more efﬁcient
than modern leaderless randomized consensus protocols.
Avoiding Consensus Protocols. Recent
re-
theoretical
sults [42], [43] show that consensus is unnecessary for
implementing a payment system, contrary to popular belief.
For instance,
[42] showed that the basic double-spending
problem, as deﬁned by Nakamoto [62], can be cast as a
sequential object
it has consensus number
1 in Herlihy’s hierarchy [45]. Whilst the observation that
consensus is unnecessary to prevent double-spending in a
theoretical context has been made, we apply this insight for
the ﬁrst time to obtain Astro: a full system solution (design,
implementation, evaluation), that is also efﬁcient.
type and that
The exclusive logs in Astro resemble conﬂict-free repli-
cated data types (CRDTs) [68]. Similar to a CRDT, different
xlogs support concurrent updates while preserving consis-
tency. Since each log has a unique owner, we rule out
the possibility of conﬂicting operations on each log. Note,
however, that appending a payment to the history of a client’s
xlog A is not commutative, i.e., any two payments within the
same history need to be ordered with respect to one another.
This is a departure from classic CRDTs, but it ensures in
our case that the state at correct nodes always converges to
a consistent version.
Our xlog abstraction in Astro resembles the acyclic graph