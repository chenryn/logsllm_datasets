Payman Mohassel and Peter Rindal. “ABY3: A Mixed Protocol Framework for Machine Learn-
ing.” In: ACM CCS 18. Ed. by David Lie et al. Toronto, ON, Canada: ACM Press, Oct. 2018,
pp. 35–52. doi: 10.1145/3243734.3243760.
Tobias Nipkow and Gerwin Klein. Concrete Semantics: With Isabelle/HOL. Springer Interna-
tional Publishing, Inc., 2014. isbn: 3319105418 9783319105413.
Flemming Nielson, Hanne R. Nielson, and Chris Hankin. Principles of Program Analysis.
Springer Publishing Company, Incorporated, 2010. isbn: 3642084745, 9783642084744.
Erman Pattuk et al. “CheapSMC: A Framework to Minimize SMC Cost in Cloud.” In: CoRR
abs/1605.00300 (2016). arXiv: 1605.00300. url: http://arxiv.org/abs/1605.00300.
Alexander Schrijver. Combinatorial Optimization: Polyhedra and Eﬃciency. 1st. Springer-Verlag
Berlin Heidlberg, 2003. isbn: 978-3-540-44389-6, 0937-5511.
Michael L. Scott. Programming Language Pragmatics (2Nd Edition). Morgan Kaufmann, 2015.
isbn: 0124104096.
Axel Schr¨opfer and Florian Kerschbaum. “Forecasting Run-Times of Secure Two-Party Com-
putation.” In: Eighth International Conference on Quantitative Evaluation of Systems, QEST
2011, Aachen, Germany, 5-8 September, 2011. 2011, pp. 181–190. doi: 10.1109/QEST.2011.33.
url: https://doi.org/10.1109/QEST.2011.33.
[SR18]
[SKM11] Axel Schr¨opfer, Florian Kerschbaum, and G¨unter M¨uller. “L1 - An Intermediate Language for
Mixed-Protocol Secure Computation.” In: COMPSAC. IEEE Computer Society, 2011, pp. 298–
307. isbn: 978-0-7695-4439-7. url: http : / / dblp . uni - trier . de / db / conf / compsac /
compsac2011.html#SchropferKM11.
Nigel Smart and Dragos Rotaru. SCALE-MAMBA. 2018. url: https : / / github . com /
KULeuven-COSIC/SCALE-MAMBA (visited on 11/22/2018).
Raja Vall´ee-Rai et al. “Soot - a Java Bytecode Optimization Framework.” In: Proceedings of the
1999 Conference of the Centre for Advanced Studies on Collaborative Research. CASCON ’99.
Mississauga, Ontario, Canada: IBM Press, 1999, pp. 13–. url: http://dl.acm.org/citation.
cfm?id=781995.782008.
[Val+99]
[Wil+94] Robert P. Wilson et al. “SUIF: An Infrastructure for Research on Parallelizing and Optimizing
Compilers.” In: SIGPLAN Notices 29.12 (1994), pp. 31–37. doi: 10.1145/193209.193217. url:
https://doi.org/10.1145/193209.193217.
Andrew Chi-Chih Yao. “Protocols for Secure Computations (Extended Abstract).” In: 23rd
FOCS. Chicago, Illinois: IEEE Computer Society Press, Nov. 1982, pp. 160–164. doi: 10.1109/
SFCS.1982.38.
[Yao82]
A Notation
In this appendix we cover notation and terminology that is used through out the paper.
A.1 General Terminology
– (IMP-)source code: This is the starting point of our compiler. It is standard programming language code
for an imperative language such as IMP. We denote it by S. All loops have a known upper bound on
their iterations.
– MPC-source code: The output of our compiler on some source code S. We denote the compiler by CMPC(·).
The compiler removes if-statements and φ-nodes, and adds MUX-statements in their place. MPC-source
contains for-loops with known bounds.
– Block B of MPC-source: Sequence of assignment statements or blocks (in case of for-loop nesting) enclosed
in a for-loop.
27
an intermediate representation between (IMP-)source and MPC-source.
– (IMP-)SSA-code: this is the output of SSA on some source-code S. We will denote it as CSSA(S). This is
– Linearized-code : Linear(S): This is the linearization of some MPC-source CMPC(·). It contains no loops,
only straight-line code of assignment statments. The corresponding CFG of this would be simply a
straight line.
– We refer to statement in Linear(S) as simple statements and denote them as st. Since the corresponding
CFG is a line we often refer to simple statements as nodes in (the CFG of ) Linear(S).
A.2 Costs Model
Simple Model
– St = {st1, . . . , st(cid:96)} denotes the ordered set of statements in Linear(S)
– Π = {π1, . . . , πm} denotes (a set of) multi-party protocols and Σ = {σ1, . . . , σq} denotes (a set) of secret
– For each (i, j) ∈ [(cid:96)] × [m], the triple (sti, πj, cπj
sti corresponds to
– For each (i, j) ∈ Σ2: the triple (σi, σj, cσi2σj ) ∈ Σ × Σ × Z≥0, where intuitively, cσi2σj is the cost of
sharing schemes (in typical scenarios such as [DSZ15; MR18; Cha+17; B¨us+18] q = m.)
sti) ∈ B × Π × Z≥0, where intuitively, cπj
the cost of emulating in a ﬂow statement sti with protocol πj.
securely converting a sharing according to scheme σi into a sharing according to σj.
– Whenever the sequence St, and set Π are clear from the context we use cπj
sti’s and cσi2σj instead of the
setup of triples. Furthermore, in all existing works on protocol mixing—including ours—each protocol
πi is associated with a single sharing scheme σi; in such cases, in slight abuse of notation, we denote the
conversion cost from σi to σj as cπi2πj (instead of cσi2σj ). In fact, to further simplify our notation and
consistently with the ABY notation, for the three ABY protocols πA, πB, and πY, and for X, Z ∈ {A, B, Y}
we use cX2Z to denote the conversion cost cπX 2πZ
from the sharing corresponding to πX (which we refer
to as Sharing X) to the sharing corresponding πZ (which we refer to as Sharing Z).
Amortized Model
(·)), where fc
πj
sti
πj
sti
πj
sti
– The triplet (sti, πj, fc
: N → Z≥0 denotes the amortized execution cost function, which
on input (cid:96) ∈ N outputs the amortized cost fc
((cid:96)) of computing (cid:96) parallel copies of sti with protocol πj.
– The triplet (σi, σj, fcσi2σj (·)), where fcσi2σj : N → Z≥0 denotes the amortized conversion cost function,
which on input (cid:96) ∈ N outputs the amortized cost fcσi2σj ((cid:96)) of converting (cid:96) sharings according to σi into
sharings according to σj.
– For brevity, for X, Z ∈ {A, B, Y} we use fcX2Z to denote the function fcπX 2πZ from the sharing correspond-
ing to πX to the sharing corresponding πZ. The costs of the simple model corresponds to the output of
the above functions on input (cid:96) = 1.
OPA for Linearized MPC
– PA is a sequence of pairs of the type (st1, π1), . . . , (st|St|, π|St|) where (sti, πj) ∈ PA means that state-
ment sti is assigned protocol πj.
A.3 Solving The Linearized OPA
n is the cost to run node n ∈ CMPC(S)
n is the cost to run node n using πY.
– cA
– cY
– cA2Y is the cost to run A2Y conversion.
– cY 2A is the cost to run Y2A conversion.
28
Variables and Constraints
– (d, u) ⊇ (d, u(cid:48)) denotes that (d, u) subsumes (d, u(cid:48)) i.e. all paths from d to u(cid:48) go through min cut(d, u).
From IP Linear(S) to IP CMPC(S)
– α : Linear(S) → CMPC(S) denotes the “abstraction” function i.e. provides mapping from Linear(S) to
– γ : (CMPC(S) × CMPC(S)) → 2Linear(S) denotes the “concretization” function i.e. provides mapping from
CMPC(S).
CMPC(S) to Linear(S).
B Preliminaries
B.1 Program Analysis
We next discuss concepts that are standard building blocks of static analysis and are necessary background for
our results. We assume minimal familiarity with program analysis, and refer an interested reader to [Aho+06].
Basic Block (BB) A basic block (BB) is a straight-line sequence of instructions, deﬁned by the compiler.
The set of basic blocks that may execute before a given basic block are called its predecessors. Similarly, the
set of blocks that may execute after a given block are called its successors.
Control Flow Graph (CFG) A control ﬂow graph (CFG) is a directed graph that represents all possible
control ﬂow paths in a program. The nodes in the CFG are basic blocks, and the edges model ﬂow of control
between basic blocks. There is an edge from a basic block to each of its successors. It is also common to
consider each statement in a basic block as a separate node with an outgoing edge to the statement/node
immediately following within the basic block.
Reaching Deﬁnitions (RDs) Reaching deﬁnitions is a classical data-ﬂow analysis technique [Aho+06;
NNH10]. It computes def-use chains (d, u), where d is a deﬁnition of a variable x: e.g., x = y + z, and
u is a use of x: e.g., z = x ∗ y, or x > y. In the classical sense, reaching deﬁnitions is deﬁned over a CFG,
where d and u are statements/nodes in the graph. A def-use chain (d, u) entails that there is a path from d
to u in the CFG that is free of a deﬁnition of x, or in other words, the deﬁnition of x at d may reach the use
of x at u.
Reasoning about dependencies like def-use chains can be greatly simpliﬁed by an appropriate intermediate
representation (IR). Now, we describe an intermediate representation (IR) called Static Single Assignment
(SSA) form. This is a standard IR in compilers and beneﬁts static analysis by immediately exposing def-use
dependencies. The standard algorithm to translate a program into SSA form is due to Cytron et al. [Cyt+91].
Static Single Assignment (SSA) form SSA form entails that each variable in the program is assigned exactly
once. If the source code has multiple deﬁnitions of the same variable, the variable is split into multiple versions
for each deﬁnition. Consider, for instance, the code fragment in Figure 5(a). Without SSA, a compiler needs
to construct def-use chains to reason that the ﬁrst deﬁnition of x is not used and is, therefore, dead code.
Now consider the same code fragment in SSA form in Figure 5(b). It is immediately obvious that variable x1
has no uses. Moreover, it is also obvious—because all variables are assigned only once—that y is only a copy
of x2. Therefore, in any uses of y, y can be replaced with x2 without changing the input program behavior.
Furthermore, x2 is a constant with value 2, and consequently z is a constant too, with value 200. The ﬁnal
SSA-program will just use the constant value 200 and will eliminate the variables in the original program in
Figure 5(a).
A natural question is, if SSA form allows variable assignment only once, how does it determine which
variable to use when multiple control ﬂow paths merge into a single node e.g. the if-else in ﬁgure 6(a). This
is taken care of in SSA by so-called phi (φ) nodes.
29
1 x = 1;
2 x = 2;
3 y = x;
4 z = y * 100;
1 x1 = 1;
2 x2 = 2;
3 y = x2;
4 z = y * 100;
(a)
(b)
Figure 5. A simple source program and its SSA form. x 1 = 1 is dead code and also, y is just a copy of x 2. y is a
constant, and z is a constant with value of 200.
1 if (flag) {
x1 = 1;
2
3 }
4 else {
1 if (flag) {
x1 = 1;
2
3 }
4 else {
x2 = 2;
5
6 }
7 x3 = x?; // Is x3 x1 or x2?
(b)
(a)
x2 = 2;
5
6 }
7 x3 = φ(x1, x2);
Figure 6. A program and its SSA form. We assume that the ﬁrst argument of a φ node (x1 in our case) carries the
value along the then-arm of the if-statement, and the second argument (x2 in our case) carries the value along the
else-arm.
Phi (φ) Nodes φ-nodes follow immediately after control-ﬂow from two or more paths joins (merges) into a
single node. They have the form x3 = φ(x1, x2), where x3, is a new version of the variable, and φ(x1, x2),
contains the versions of the variable along the diﬀerent paths. The φ-node entails that x’s value at this point
comes from either the then-arm (x1) or the else-arm (x2) depending on what path control ﬂow took to arrive
at the merge node. Figure 6(b) shows the SSA form (including a φ-node) corresponding to code in Figure
6(a).
IMP Imperative Language Recall that one of our goals in this work is to deﬁne MPC-source, the input IR
for MPC compilers/optimizers. Towards this goal, we start from a standard representation of program syn-
tax. The standard representation in the functional programming languages literature uses lambda calculus.
However, MPC programs live in the imperative world. Therefore, we choose a standard minimal representa-
tion of an imperative language, IMP. IMP (cf. [NK14, ch. 7]) is a simple programming language in which a
statement can either be an 1) assignment to an expression where expression can be a constant, a variable or
an operation between two variables, 2) an if-then-else conditional or 3) a while loop.
C Program Analysis of MPC Source
C.1 Program Syntax
1 int x = a;
2 int y = b;
3 while (y != 0) {
1 // Computes val%mod
2 int rem = val;
3 while (rem ≥ mod)
4 rem = rem - mod;
5 return rem;
(a) Remainder
4
5
r = rem(x,y);
x = y;
y = r;
6
7 }
8 return x;
(b) GCD
Figure 7. Standard algorithms for Remainder and GCD
30
We assume an IMP-like source syntax [NK14]. The IMP syntax models an imperative language, such as
FORTRAN, C, or Java, and our results apply to any of these languages. We impose the following standard
restrictions necessary to accommodate MPC: there is no recursion, and all loop-bounds are statically known.
The IMP source is translated into Static Single Assignment (SSA) using standard techniques [Cyt+91]. Fig. 8
abstracts the SSA syntax corresponding to IMP-like sourecode. Note that this is standard SSA, however, to