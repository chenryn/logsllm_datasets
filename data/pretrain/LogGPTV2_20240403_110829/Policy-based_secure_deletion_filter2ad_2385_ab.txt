attributes to delete can be speciﬁed independently of each other in
arbitrary order.
Example 1. The policy graph of Figure 1 has six attributes (resp.,
source nodes) named Alice, Bob, Project_X, Exp_2014, Exp_2015,
and Audit and six protection classes (resp., interior nodes) named
p1, . . . , p6. The latter are threshold nodes that implement binary
AND and OR gates. The attributes model users that own ﬁles with
different protection needs, a project category, expiration dates for
stored data, and a special audit need for deleting stored data.
For example, protection class p3 is governed by a policy Alice
OR Exp_2015; thus data in p3 becomes inaccessible as soon as a
Figure 1: A sample policy graph.
delete operation for protection classes owned by Alice is executed
or a delete operation for the ﬁles with expiration Exp_2015 takes
place.
Protection class p1 has policy (Alice OR Exp_2014) AND Audit.
Data protected under this class only disappears after the attribute
Alice or the attribute Exp_2014 has been deleted, and, furthermore,
after a secure deletion operation for Audit has been executed. This
might apply when data protected under p1 is more important for
retention than data under p2, as data in class p1 can be destroyed
only after an auditor has given consent to its erasure.
User Bob owns the data protected under p4, p5, and p6. The
policy dictates that classes p5 and p6 become inaccessible after se-
curely deleting the attributes Exp_2014 or Exp_2015, respectively,
or when data owned by Bob and data labeled by Project_X is se-
curely deleted. For instance, Bob might be a temporary user work-
ing on project X, and regardless of whether Bob leaves the organiza-
tion, his data must be retained until the end of the project, i.e., until
it is erased explicitly by specifying Project_X for secure deletion.
Consider the initial state and suppose a secure deletion operation
with attribute Exp_2014 is invoked. Then p2 and p5 become inac-
cessible, but p1 remains present as Audit has not been speciﬁed for
deletion. If data protected with owner Alice securely deleted later,
then p3 becomes inaccessible but p1 can still be retrieved.
2.4 System model
In a practical system supporting policy-based secure deletion,
there are two distinct kinds of storage space: erasable and perma-
nent memory. A small erasable memory forms the root of trust and
must be under close control of the system operators. It is provided,
for instance, by key-management systems, hardware-security mod-
ules (HSM), or local ﬁlesystems which support physical secure
deletion. Content that has been deleted from the erasable mem-
ory is impossible to retrieve for both legitimate and malicious par-
ties. On the other hand, permanent memory is readily available
with large capacity, but its content can neither be erased nor hidden
from an adversary. Many forms of storage encountered in practice
fall in this category, ranging from the complex storage hierarchies
of a data center to the mobile end-user devices attached to storage
back-ends in the cloud.
In this work, we consider a user with access to erasable mem-
ory and permanent memory. Her goal is to store a potentially large
number of ﬁles and to selectively delete ﬁles according to a dele-
tion policy. Information to be stored is protected, resulting in ci-
phertext being written to permanent memory. The ciphertext is
available later for accessing non-deleted ﬁles. Secure deletion op-
erations make it impossible for an adversary to retrieve the deleted
ﬁles, even if the adversary uses coercion and obtains all keys in
the erasable memory. The constructions exploit the capability to
261remove data from erasable memory. (In other words, we assume a
“bounded peek-a-boo adversary” according to Reardon et al. [23].)
We assume the adversary is passive and cannot modify data sto-
red on either type of memory. In practice, one can ensure this easily
through orthogonal data-authentication methods.
2.5 Secure deletion schemes
We now introduce the formal notion of a policy-based secure
deletion scheme. The model is cryptographic and formulated as a
secret-key scheme for simplicity.
We deﬁne a predicate deleted(G, D, p) for a deletion policy
with attributes A, policy graph G, and protection classes P that
denotes whether deleting all attributes in a set D ⊆ A implies that
the protection class p ∈ P should become inaccessible. In terms of
the Boolean circuit interpretation of G, suppose those source nodes
of G corresponding to the attributes in D are set to TRUE; then
deleted(G, D, p) denotes the value of node p in G. The notation
[a, b] for two integers a and b denotes the set of integers {a, . . . , b};
the expression [a] is short for [1, a].
Deﬁnition 1. A policy-based deletion scheme E is a tuple (Init,
Protect, Access, Delete), consisting of four probabilistic polyno-
mial-time algorithms (in terms of a security parameter κ) with the
following properties:
• Init(κ, G) → (M0, S0)
The initialization algorithm takes as inputs the security pa-
rameter κ and a policy graph G. It outputs an initial master
key M0 and initial auxiliary state S0.
• Delete(Mt, St, At) → (Mt+1, St+1)
The secure deletion algorithm takes as inputs a master key Mt,
auxiliary state St, and a set of attributes At ⊆ A, and outputs
a new master key/auxiliary state pair reﬂecting the deletion
of the supplied attributes.
Throughout the operation of the scheme, a set D ⊆ A that
contains the union of all attributes deleted so far is implicitly
maintained. That is, after t + 1 calls to Delete, it holds D =
∪t
i=0Ai.
• Protect(Mt, St, p, f ) → c
The protect algorithm takes as inputs a master key Mt, aux-
iliary state St, a protection class p ∈ P, and a ﬁle f which
is a binary string of any length, and outputs a ciphertext c.
If deleted(G, D, p) = TRUE, i.e., the protection class has
already been deleted, then c = ⊥. Otherwise, the protection
class is still accessible and c ∈ {0, 1}∗ is a protected version
of the ﬁle f .
• Access(Mt, St, p, c) → f
The access algorithm takes as inputs a master key Mt, aux-
iliary state St, a protection class p, and a ciphertext c, and
outputs a string f ∈ {0, 1}∗ or ⊥.
Whenever a master key/auxiliary state tuple (Mt, St) appears
here, we assume that Mt and St are well-formed and result from
a call to Init and a number of subsequent repeated calls to Delete.
In other words, for some Init(κ, G) = (M0, S0) and a sequence
A0, A1, . . . , At−1 of subsets of A, it holds Delete(Mi, Si, Ai) =
(Mi+1, Si+1), for i ∈ [t − 1]. Note that this assumption incurs no
loss of generality in the adversarial model considered here.
All four algorithms except for Access are usually probabilis-
tic; they output a random variable induced by their internal random
choices. In statements about particular output values of an algo-
rithm, such as in the preceding paragraphs, it is implied that these
outputs may occur with non-zero probability.
Next, we discuss the completeness and security properties of a
policy-based deletion scheme E .
Deﬁnition 2. A policy-based deletion scheme deﬁned as above is
said to be complete if any protected ﬁle can be accessed at a later
time unless it has been deleted. That is, for any t and j ≤ t, for all
p ∈ P, for all f ∈ {0, 1}∗, for all {Ai}t−1
i=0 , where Ai ⊆ A, and
all key/state tuples (Mi, Si), for i ∈ [t − 1], such that Init(κ, G) =
(M0, S0) and Delete(Mi, Si, Ai) = (Mi+1, Si+1), it holds that
Access(cid:0)Mt, St, p, Protect(Mj , Sj, p, f )(cid:1) = f.
i=0 Ai, p) = FALSE.
conditioned on deleted(G, ∪t−1
The security of a policy-based deletion scheme is deﬁned using
the following experiment for an adversary A and a security param-
eter κ.
Secure deletion experiment SecdelA,E (κ) :
1. The adversary A is given κ and outputs a policy graph G
with corresponding sets A and P for the attributes and the
protection classes, respectively. Also, the adversary outputs
a set D ⊆ A of all attributes to be deleted at the end.
Then, algorithm Init(κ, G) → (M0, S0) is executed and S0
is given to A.
2. A is given oracle access to protection and deletion operations.
In particular, the set D of deleted attributes, the index t, and
the current master key/auxiliary state pair (Mt, St) are main-
tained; A may choose inputs (p, f ) for protection and re-
ceives the output of Protect(Mt, St, p, f ); A may also spec-
ify At ⊆ D, which causes algorithm Delete(Mt, St, At) →
(Mt+1, St+1) to be invoked, then A receives St+1.
3. The adversary A outputs some p∗ ∈ P such that deleted(G,
D, p∗) = FALSE and two strings f0, f1 ∈ {0, 1}∗ of the
same length.
4. After a random bit b ← {0, 1} is chosen, a ciphertext c∗ ←
Protect(Mt, St, p∗, fb) is computed and given to A.
5. The adversary is given further oracle access to protection
and deletion operations, continued from step 2, until A stops
under the condition that deleted(G, D, p∗) = TRUE and
D = D, i.e., p∗ is inaccessible for the current set D of
deleted attributes and that set is the same as the one deﬁned
in step 1.
6. A receives the current value of Mt and outputs a bit ˆb. The
experiment returns 1 if ˆb = b and 0 otherwise.
Deﬁnition 3. A policy-based deletion scheme E is called secure
when for all probabilistic polynomial-time adversaries A, there ex-
ists a negligible function ε such that
PrhSecdelA,E (κ) = 1i ≤
1
2
+ ε(κ).
Remark. A secure deletion scheme maintains the secrecy of the
protected and deleted content. According to the security deﬁnition,
in the last step of Secdel, the adversary receives the master key. At
this point, the ﬁles protected under all classes that have not yet been
deleted are obviously exposed to A. However, any protected ﬁle
that has already been deleted is guaranteed to remain conﬁdential,
even after the master key has been leaked.
Note that the security model requires the adversary to declare
the attributes to delete upfront, before it can observe any output
produced by the scheme and adaptively choose in what order to
delete these attributes. Our security notion is similar to “selective
security” for attribute-based encryption [24, 14].
The security notion may readily be extended to cover adver-
sarial modiﬁcations to permanent memory, analogous to chosen-
ciphertext attacks against encryption schemes. As storage systems
typically protect data integrity through different means (that addi-
tionally prevent replay attacks), we omit this extension for clarity.
2622.6 Measuring efﬁciency
We will characterize implementations of secure deletion schemes
in terms of the cost incurred for executing their operations. We de-
ﬁne the deletion cost, protection cost, and access cost as the com-
plexities of running the deletion, protection, and access algorithms,
respectively. Complexities are expressed in terms of computation
steps or, more usually, through the number of calls to an encryption
primitive made by the algorithm.
We consider deletion schemes with constant deletion cost, inde-
pendent of the number of protected ﬁles, to be the most interesting.
For the constructions considered in this work, protection and access
cost do not differ, hence we are mainly interested in access cost.
Furthermore, the size of the erasable memory for storing the
master key and the permanent memory for storing the auxiliary
state are important parameters. We quantify them as the master-
key size and auxiliary-state size, respectively. Note the protected
ﬁles must be maintained outside the secure deletion scheme.
3. CONSTRUCTIONS
3.1 Prerequisites
In the constructions described below, we assume for simplicity
that master keys and auxiliary state values Mt and St, returned
by Init and Delete operations, are associative arrays indexed by
nodes and edges of G. Thus, the values St[v] and St[e] denote the
auxiliary data, if any, associated to v ∈ V and e ∈ E, respectively.
The notation St|V ′,E ′
denotes only the collection of entries of St
restricted to v ∈ V ′ ⊆ V and e ∈ E′ ⊆ E; of course, we require
E′ ⊆ V ′ × V ′ for such restrictions.
Secret-key encryption schemes. A secret-key encryption sche-
me S consists of three algorithms Keygen, Encrypt, and Decrypt.
The probabilistic key generation algorithm Keygen(κ) outputs a
key K; algorithm Encrypt(K, m) takes a key K and a plaintext m
as inputs and returns a ciphertext c; algorithm Decrypt(K, c) takes
a key K and a ciphertext c as inputs and returns a plaintext m.
We assume S is complete and IND-CPA secure according to the
standard notions.
Secret-sharing schemes. A (m + 1)-out-of-n secret-sharing
scheme denotes a method to split a secret s into n shares s1, . . . , sn
such that m + 1 or more shares are sufﬁcient to recover s, but m or
fewer shares give away no statistical information about s. The oper-
ation of sharing s is expressed by (s1, . . . , sn) ← Sharen
m+1(s),
and the algorithm to recover s from shares ¯s1, . . . , ¯sm+1 is written
as s ← Recover(¯s1, . . . , ¯sm+1). We use, for instance, the well-
known implementation based on polynomial interpolation [25].
3.2 Direct secure deletion schemes
We now introduce a class of secure deletion schemes with a par-
ticularly simple implementation of the deletion operation. We call
them direct because their deletion operation merely erases parts of
the master key that corresponds directly to the deleted attributes.
More precisely, a direct secure deletion scheme always generates
a master key Mt in the form of a tuple with exactly one component
for every attribute in A. The deletion operation for a set of at-
tributes At ⊆ A erases those components of Mt that correspond
to At. In other words, every master key Mt is an associative array
indexed by a ∈ A, where Mt[a] denotes the component corre-
sponding to a. The deletion operation for At computes Mt+1 as
Figure 2: Basic secure deletion scheme, implemented from en-
cryption and secret sharing.
Stronger security for direct schemes. Recall from Deﬁnition 3
that in the last step of its experiment, the adversary is given the
current value of the master key. Given that D is supplied by A,
the set of all attributes to be deleted eventually, in the ﬁrst step,
it is clear that the master key given to the adversary at the end is
M0|ArD . As a consequence, A can receive it in the ﬁrst rather
than last step, hence providing the adversary with more information
earlier in the experiment. We use this stronger security deﬁnition
when showing the security of direct policy-based deletion schemes.
3.3 Basic scheme
A secure deletion scheme with a very basic policy can be im-
plemented directly from a secret-key encryption scheme S and a
secret-sharing scheme.
Let G = (V, E) be a policy graph with n ≥ 1 source nodes,
connected to a single interior node that is also the only protection
class. In other words, as shown in Figure 2, the nodes V = A ∪ P
are given by a set of attributes A = {a1, . . . , an} and a set P =
{p} composed of a single protection class, and the edges are E =
{e1, . . . , en}, where ei = (ai, p) for i ∈ [n]. The interior node p
has a threshold parameter m.
We construct E = (Init, Protect, Access, Delete) as follows:
• Init(κ, G)
– For each attribute ai ∈ A select a random key Ki ←
S.Keygen(κ) and set M0[ai] ← Ki;
– Select a random key Kp ← S.Keygen(κ) and con-
struct a (n−m+1)-out-of-n secret sharing for the key,
i.e., (s1, . . . , sn) ← Sharen
n−m+1(Kp); then, com-
pute xi ← S.Encrypt(Ki, si) for i ∈ [n] and set the
initial auxiliary state to be S0[p] ← (x1, . . . , xn);
– Output (M0, S0).
• Delete(Mt, St, At)
As this is a direct secure deletion scheme, proceed as deﬁned
in Section 3.2.
• Protect(Mt, St, p, f )
If deleted(G, D, p) = TRUE, set c ← ⊥. Otherwise, let
(x1, . . . , xn) ← St[p]; for each i ∈ [n] such that ai 6∈ D