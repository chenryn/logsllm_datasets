### Optimized Text

For instance, an analyst can choose to use only the best matches if the goal is to highlight perfect similarity (e.g., code reused as-is) between two binaries. Alternatively, a combination of best and partial matches can be used to capture more generic dependencies, including minor variations and "evolutions" of the code.

Another challenge with the similarity graph is that it often contains a large number of edges, with many samples being variations or simple recompilations of the same family. To make the output more readable and better emphasize the evolutionary lines, we visualize the Minimum Spanning Tree (MST) \( G' \) of \( G \), which shows the path of minimum binary difference among all samples. This approach to clustering binaries is inspired by methods in the clustering literature that are based on the MST of the pairwise distance matrix between elements [4, 11].

Furthermore, we observed that MSTs, which are generally used as an intermediate representation of the clustering structure, faithfully convey information about the relationships between items in our dataset. This information is not always preserved when converting the MST to a set of clusters. For this reason, we base our analysis on minimum spanning trees.

The tree can be further colored according to AV labels (to get an overview of the relationships among different families and spot erroneous labels assigned by AV engines) or to the closest source file we downloaded using symbol names (thus leading to a clearer picture of the genealogy of a single malware family). In the following sections, we will explore these two views and present several examples of our main findings.

### 4. Results

We used the workflow for code-based clustering presented in the previous section to plot phylogenetic trees for the six top architectures in our dataset. We found that the current IoT malware landscape is primarily dominated by three closely connected families: Gafgyt, Mirai, and Tsunami. These families contain hundreds of variants grouped under the same AV label and have the longest persistence on VirusTotal. Over time, they have started to exhibit fused traits and continue to be detected on VirusTotal. On the other hand, more specialized IoT malware targets specific CPU architectures and has a much shorter lifespan. Although IoT malware code is not as complex as that found in Windows malware, AVs may still struggle with identifying widely reused functions and packed samples.

As described in Section 3.5, the distance function we used for the HNSW algorithm is based on the number of functions with binary similarity ≥ 0.5 (as suggested by Diaphora). The analyst can adjust this threshold when plotting the graphs to either display even uncertain similarities among families (at 0.5 threshold) or highlight only the perfect matches of exact code reuse (at 1.0 threshold).

#### 4.1. Code Reuse

Figure 3 shows the lineage graph for MIPS samples plotted at a similarity ≥ 0.9, with nodes colored according to their AVClass labels.

Overall, MIPS samples include 39 different labels. However, the graph is dominated by a few large families: Gafgyt, Tsunami, and Mirai. These three families cover 87% of the MIPS samples and have served as inspiration for different groups of malware developers, likely due to the availability of their source code online. It is interesting to note how this tangled dependency is reflected in the fact that most Tsunami variants are located on the left side of the graph, close to Gafgyt, but some also appear on the right side due to an increased number of routines borrowed from Mirai.

Besides these three main players, the graph also shows samples without any label or belonging to minor families. For example, the zoom region [A] contains a small connected component of 283 Dnsamp samples with a tail of 4 samples: 1 labeled Ganiw and 3 labeled Kluh. All together, they are linked to ChinaZ, a group known for developing DDoS ELF malware. The very high similarity between Ganiw and Kluh is particularly interesting, as Kluh could be seen as an evolution of Ganiw (and appeared 3 months later on VirusTotal), yet AVs assign them different labels.

Table 3 reports the number of shared functions (at 0.9 similarity) across the top 10 families in our dataset and takes into account the full picture of the six main architectures. The code sharing for Mirai, Gafgyt, and Tsunami is once again confirmed to play a fundamental role in IoT malware, with hundreds of functions shared across the three. However, we can see their influence in minor families like Dnsamp, which borrows functions for random number generation and checksum computations, or Lightaidra, which reuses 18 functions from Gafgyt. Less widespread families such as Dnsamp and Ddostf also show high similarity, with a total of 65 shared functions. Targeted campaigns like VPNFilter do not overlap with the main components of the famous families.

#### 4.2. Outliers and AV Errors

One of the analyses we can perform on the phylogenetic trees is the detection of anomalous labels by looking for outlier nodes. We define an outlier as a (set of) node(s) of one color that is part of a cluster containing only nodes of a different color. Outliers can correspond to samples misclassified by the majority of AV scanners or to variants of a given family that share a considerable amount of code with another family (making it difficult to decide which label is more appropriate). Outliers can also be used to assign a label, based on its neighbors, to samples for which AVClass did not return one.

Although the number of mislabeled samples is not significant in our dataset, our automated pipeline can promptly detect suspicious cases in newly collected data. The outliers discussed in this section also show that a very high ratio of code similarity can often confuse several AV signatures.

Based on a manual inspection of each group of outliers, Table 4 reports a lower bound estimation of the mislabeling cases broken down by architecture. Overall, we found 118 cases, with 62 samples believed to have a wrong AVClass label and 56 for which AVClass was unable to agree on the AV labels. ARM and MIPS (which cover 66% of our dataset) are responsible for over 80% of the errors, with MIPS samples being the most problematic to classify. The pattern is reversed for less popular architectures, like Hitachi SH and Motorola 68000 (13.3% of the dataset), which account for fewer errors.

Table 5 provides the number of variants recognized for the top 10 families in our dataset. Malware families marked with a "-" contained only stripped samples, which prevented accurate variant identification.

| Family         | Total Samples | Candidate Variants (Source Code) | Validated Variants |
|----------------|---------------|----------------------------------|--------------------|
| Gafgyt         | 1428          | 386                              | 210                |
| Mirai          | 2091          | 1                                | 1                  |
| Tsunami        | 48            | 1                                | 1                  |
| Dnsamp         | 1             | 1                                | 1                  |
| Hajime         | 11            | 1                                | 1                  |
| Ddostf         | 7             | 1                                | 1                  |
| Lightaidra     | 1             | 1                                | 1                  |
| Pnscan         | 1             | 1                                | 1                  |
| Skeeyah        | -             | -                                | -                  |
| VPNFilter      | -             | -                                | -                  |

This table highlights the number of samples, candidate variants identified through source code, and validated variants for each family.