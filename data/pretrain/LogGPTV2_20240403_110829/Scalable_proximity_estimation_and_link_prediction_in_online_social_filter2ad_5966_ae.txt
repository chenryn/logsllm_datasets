n
a
i
r
a
V
f
o
n
o
i
t
c
a
r
F
 1
 1
 0.8
 0.8
 0.6
 0.6
 0.4
 0.4
 0.2
 0.2
 0
 0
# Dimensions
(c) LiveJournal
Katz, beta=0.05
Katz, beta=0.005
Rooted PageRank
 10
 10
 20
 20
 30
 30
 40
 40
 50
 50
 60
 60
 10
 10
 20
 20
 30
 30
 40
 40
 50
 50
 60
 60
 10
 10
 20
 20
 30
 30
 40
 40
 50
 50
 60
 60
# Dimensions
(d) MySpace
# Dimensions
(e) YouTube
# Dimensions
(f) Wikipedia
Figure 6: Fraction of total variance captured by the best rank-k approximation to inter-landmark proximity matrices Katz[L, L]
and RPR[L, L].
that proximity sketch generally performs better than proximity em-
bedding for large values (i.e., greater than 1% of row sums), and
performs worse for small values (i.e., greater than 0.1% and 0 of
row sums). This is consistent with our expectation, since prox-
imity sketch is designed to approximate large elements. This also
suggests that the two algorithms are complimentary and we can po-
tentially have a hybrid algorithm that chooses the results among the
two algorithms based on the magnitude of the estimated values.
Estimating large Rooted PageRank values. Table 5(b) shows
the NMAE of proximity sketch in estimating RPR. As for Katz,
proximity sketch yields lower error than proximity embedding for
large elements (i.e., larger than 1%, and 0.1% of row sums) and
higher error for small elements (i.e., larger than 0). This conﬁrms
that proximity sketch is effective in estimating large elements.
4.2.3 Incremental Proximity Update
Next, we evaluate the accuracy of our incremental proximity up-
date algorithm. We use two checkpoints of crawl data that differ
by one day: May 17–18, 2007 for Flickr, July 22–23, 2007 for
YouTube, and April 5–6, 2007 for Wikipedia. The one-day gap
between two checkpoints yields 0.3%, 0.5%, and 0.05% difference
between M and M ′ for Flickr, YouTube, and Wikipedia, respec-
tively. We do not use LiveJournal, MySpace, and Digg, since we
have no checkpoints that are one day apart for these sites.
Figure 7 plots the CDF of normalized absolute errors and relative
errors for the Katz measure using the incremental update algorithm
in conjunction with proximity embedding (denoted as “Embed +
inc. updates”). For comparison, we also plot the errors of using
proximity embedding alone (denoted as “Prox. embedding only”).
As we can see, the curves corresponding to incremental update are
very close to those of proximity embedding. This indicates that
we can use the incremental algorithm to efﬁciently and accurately
update the proximity matrix as M changes dynamically and only
re-compute the proximity matrix periodically over multiple days.
4.2.4 Scalability
Table 6 shows the computation time for proximity embedding,
proximity sketch, incremental proximity embedding, common neigh-
bor, and shortest path computation. The measurements are taken on
an Intel Core 2 Duo 2.33GHz machine with 4GB memory running
Ubuntu Linux kernel v2.6.24. We explicitly distinguish the query
time for positive and negative samples – A node pair hA, Bi is con-
sidered a positive sample if there is a friendship link from A to B;
otherwise it is considered a negative sample.
330 
F
D
C
F
D
C
 1
 1
 0.99
 0.99
 0.98
 0.98
 0.97
 0.97
 0.96
 0.96
 0.95
 0.95
 0.94
 0.94
 0.93
 0.93
 0.92
 0.92
 0.91
 0.91
 0.9
 0.9
Embed. + Inc. update (NMAE=0.01)
Prox. embedding only (NMAE=0.00)
F
D
C
 1
 1
 0.98
 0.98
 0.96
 0.96
 0.94
 0.94
 0.92
 0.92
 0.9
 0.9
 0.88
 0.88
 0.86
 0.86
 0.84
 0.84
 0.82
 0.82
 0.8
 0.8
F
D
C
 1
 1
 0.99
 0.99
 0.98
 0.98
 0.97
 0.97
 0.96
 0.96
 0.95
 0.95
 0.94
 0.94
 0.93
 0.93
 0.92
 0.92
 0.91
 0.91
 0.9
 0.9
Embed. + Inc. update
Prox. embedding only
Embed. + Inc. update (NMAE=0.04)
Prox. embedding only (NMAE=0.02)
 0
 0
 0.02
 0.02
 0.04
 0.04
 0.06
 0.06
 0.08
 0.08
 0.1
 0.1
 0
 0
 0.1
 0.1
 0.2
 0.2
 0.3
 0.3
 0.4
 0.4
 0.5
 0.5
 0
 0
 0.02
 0.02
 0.04
 0.04
 0.06
 0.06
 0.08
 0.08
 0.1
 0.1
(a) Flickr, normalized absolute errors
(b) Flickr, relative errors, top 10%
(c) YouTube, normalized absolute errors
Normalized Absolute Errors
Relative Errors
Normalized Absolute Errors
 1
 1
 0.98
 0.98
 0.96
 0.96
 0.94
 0.94
 0.92
 0.92
 0.9
 0.9
 0.88
 0.88
 0.86
 0.86
 0.84
 0.84
 0.82
 0.82
 0.8
 0.8
F
D
C
 1
 1
 0.99
 0.99
 0.98
 0.98
 0.97
 0.97
 0.96
 0.96
 0.95
 0.95
 0.94
 0.94
 0.93
 0.93
 0.92
 0.92
 0.91
 0.91
 0.9
 0.9
Embed. + Inc. update
Prox. embedding only
Embed. + Inc. update (NMAE=0.00)
Prox. embedding only (NMAE=0.00)
F
D
C
 1
 1
 0.98
 0.98
 0.96
 0.96
 0.94
 0.94
 0.92
 0.92
 0.9
 0.9
 0.88
 0.88
 0.86
 0.86
 0.84
 0.84
 0.82
 0.82
 0.8
 0.8
Embed. + Inc. update
Prox. embedding only
 0
 0
 0.1
 0.1
 0.2
 0.2
 0.3
 0.3
 0.4
 0.4
 0.5
 0.5
 0
 0
 0.02
 0.02
 0.04
 0.04
 0.06
 0.06
 0.08
 0.08
 0.1
 0.1
 0
 0
 0.1
 0.1
 0.2
 0.2
 0.3
 0.3
 0.4
 0.4
 0.5
 0.5
(d) YouTube, relative errors, top 10%
(e) Wikipedia, normalized absolute error
(f) Wikipedia, relative errors, top 10%
Relative Errors
Normalized Absolute Errors
Relative Errors
Figure 7: Normalized absolute errors and relative errors of incremental update algorithm, Katz measure.
We make several observations. First, the query time for both
proximity embedding and proximity sketch is small, even smaller
than common neighbor and shortest path computation, which are
traditionally considered much cheaper operations than computing
Katz measure. Second, the preprocessing time of proximity sketch
and proximity embedding increases linearly with the number of
links in the dataset. As preprocessing can be done in parallel, we
use the Condor system [17] for datasets with a large number of
links. Running preprocessing step simultaneously from 150 ma-
chines, we observe that the total preprocessing time goes down to
less than 30 minutes, even for large networks such as MySpace
and LiveJournal. Furthermore, the pre-processing only needs to
be done periodically (e.g., once every few days). For symmet-
ric networks, such as MySpace and YouTube, proximity embed-
ding only needs to compute either P [L, ∗] or P [∗, L], reducing the
preparation time to half of that of proximity sketch. Finally, the in-
cremental proximity update algorithm eliminates pre-computation
time at the cost of increased query time. However, even the in-
creased query time is much smaller than shortest path computation.
These results demonstrate the scalability of our approaches.
4.2.5 Summary
To summarize, our evaluation shows that proximity embedding
and proximity sketch are complementary: the former is more accu-
rate in estimating random samples, whereas the latter is more effec-
tive in estimating large elements. Comparing Katz and RPR, prox-
imity embedding yields much more accurate estimation for Katz
than for RPR due to the low-rank property in the Katz matrix. In
particular, proximity embedding yields highly accurate Katz esti-
mation for random samples (achieving NMAE of within 0.02).
Note that for the purpose of link prediction, it is insufﬁcient to
only estimate few large Katz values because (i) more than 15% of
node pairs having Katz measure greater than 0.1% of row sums
already have friendship (i.e., links) and (ii) for the remaining 85%
node pairs, which are not already friends, the probability of node-
pairs with the large Katz values becoming friends is only 0.21%,
whereas the average probability of random node-pairs becoming
friends is 10.57%. So we use proximity embedding for estimating
Katz for link prediction in Section 4.3.
4.3 Link Prediction Evaluation
4.3.1 Evaluation Methodology
In the friendship link prediction problem, we construct the pos-
itive set as the set of user pairs that were not friends in the ﬁrst
snapshot, but become friends in the second snapshot. The negative
set consists of user pairs that are friends in neither snapshots.
Metrics. We measure link prediction accuracy in terms of false
negative rate (FN), and false positive rate (FP):
F N =
F P =
#of missed friend links
#of new-friend links
#of incorrectly predicted friend links
#of non-friend links
We also observe that not all proximity measures are applicable to
all node pairs. For example, common neighbor is applicable only
when nodes are two hops away. Thus we introduce another metric,
called applicable ratio (AR), which quantiﬁes the fraction of node
pairs for which a given proximity measure is non-zero.
Training and testing datasets. As shown earlier, we create three
snapshots of friendship networks (S1, S2, and S3) for each net-
work in Table 2. We train link predictors by analyzing the differ-
ences in link relations of between S1 and S2, and predict who will
likely make friendship relations in S3. Therefore, the training set is
based on the period from S1 to S2, and the testing set is based on
the period from S2 to S3. Note that we only consider the common
users of the two snapshots when we count the new friendship links.
Since friendship relations in our datasets are very sparse, we sam-
ple about 50,000 positives and 200,000 negatives for both training
and testing purposes.
Link predictors. We evaluate basic link predictors based on the
following three classes of proximity measures.
• Distance based predictor: graph distance (GD).
• Node neighborhood based predictors: common neighbors (CN),
Adamic/Adar (AA), preferential attachment (PA), and PageR-
ank product (PRP).
• Path-ensemble based predictor: Katz (Katz).
331Dataset
Job type
Sample type
Digg
Flickr
LiveJournal
MySpace
YouTube
Wikipedia
proximity embedding
Query
Preprocess
proximity sketch
Incremental update
Common neighbor
Shortest path distance
Preprocess
Query
Query
Query
Query
Pos
0.1µs
Neg