1.04
1.22
6.96
3.93
8.16
10.07
11.07
5.00
13.89
9.55
16.43
7.50
22.74
15.10
36.43
22.32
31.77
31.60
92.69
76.96
60.07
56.42
138.21
128.93
77.08
77.60
Speech
Music
Iter.
500
1000
500
1000
None
10.11
10.80
4.92
5.03
50 dB
40 dB
30 dB
20 dB
10 dB
6.67
7.42
3.92
3.91
6.53
7.54
3.56
3.68
5.88
6.85
3.53
3.40
5.49
6.46
3.39
3.49
4.70
5.72
2.98
3.20
0 dB
3.05
3.61
2.02
2.30
Speech
Music
1) Evaluation of Hearing Thresholds: In Table I, the results
for speech and music samples are shown for 500 and for 1000
iterations of backpropagation, respectively. The value in the
ﬁrst row shows the setting of λ. For comparison, the case
without the use of hearing thresholds is shown in the column
‘None.’ We applied all combinations of settings on a test set of
speech containing 72 samples and a test set of music containing
70 samples. The test set of speech was the same as for the
previous evaluations and the target text was the same for all
audio samples.
The results in Table I show the dependence on the number
of iterations and on λ. The higher the number of iterations and
the higher λ, the lower the WER becomes. The experiments
with music show some exceptions to this rule, as a higher
number of iterations slightly increases the WER in some cases.
However, this is only true where no thresholds were employed
or for λ = 50.
As is to be expected, the best WER results were achieved
when the hearing thresholds were not applied. However, the
results with applied thresholds show that it is indeed feasible
to ﬁnd a valid adversarial example very reliably even when
minimizing human perceptibility. Even for the last column,
where the WER increases to more than 100 %, it was still
possible to create valid adversarial examples, as we will show
in the following evaluations.
In Table II, the corresponding values for the mean per-
ceptibility φ are shown. In contrast to the WER, the value
φ decreases with λ, which shows the general success of the
thresholds, as smaller values indicate a smaller perceptibility.
Especially when no thresholds are used, φ is signiﬁcantly
higher than in all other cases. The evaluation of music samples
shows smaller values of φ in all cases, which indicates that it
is much easier to conceal adversarial examples in music. This
was also conﬁrmed by the listening tests (cf. Section V).
text
2) Phone Rate Evaluation: For the attack, timing changes
are not relevant as long as the target
is recognized
correctly. Therefore, we have tested different combinations of
audio input and target text, measuring the number of phones
that we could hide per second of audio, to ﬁnd an optimum
phone rate for our ASR system. For this purpose, different
target utterances were used to create adversarial examples from
audio samples of different lengths. The results are plotted in
Figure 7. For the evaluations, 500 iterations and λ = 20 were
used. Each point of the graph was computed based on 200
adversarial examples with changing targets and different audio
samples, all of them speech.
Figure 7 shows that the WER increases clearly with an
increasing phone rate. We observe a minimum for 4 phones
per second, which does not change signiﬁcantly at a smaller
rate. As the time to calculate an adversarial sample increases
Fig. 7: Accuracy for different phone rates. To create the
examples, 500 iterations of backpropagation and λ = 20 are
used. The vertical lines represent the variances.
with the length of the audio sample, 4 phones per second is a
reasonable choice.
3) Number of Required Repetitions: We also analyzed the
number of iterations needed to obtain a successful adversarial
example for a randomly chosen audio input and target text.
The results are shown in Figure 8. We tested our approach
for speech and music, setting λ = 0, λ = 20, and λ = 40,
respectively. For the experiments, we randomly chose speech
ﬁles from 150 samples and music ﬁles from 72 samples. For
each sample, a target text was chosen randomly from 120
predeﬁned texts. The only constraint was that we used only
audio-text-pairs with a phone rate of 6 phones per second or
less, based on the previous phone rate evaluation. In the case of
a higher phone rate, we chose a new audio ﬁle. We repeated the
experiment 100 times for speech and for music and used these
sets for each value of λ. For each round, we ran 100 iterations
and checked the transcription. If the target transcription was
not recognized successfully, we started the next 100 iterations
and re-checked, repeating until either the maximum number
of 5000 iterations was reached or the target transcription was
successfully recognized. An adversarial example was only
counted as a success if it had a WER of 0 %. There were
also cases were no success was achieved after 5000 iterations.
This varied from only 2 cases for speech audio samples with
λ = 40 up to 9 cases for music audio samples with λ = 0.
In general, we can not recommend using very small values
of λ with too many iterations, as some noise is added during
each iteration step and the algorithm becomes slower. Even
though the results in Figure 8 show that it is indeed possible
to successfully create adversarial samples with λ set to zero,
but 500 or 1000 iterations may be required. Instead, to achieve
a higher success rate, it is more promising to switch to a higher
value of λ, which often leads to fewer distortions overall than
using λ = 0 for more iterations. This will also be conﬁrmed by
the results of the user study, which are presented in Section V.
The algorithm is easy to parallelize and for a ten-second
audio ﬁle, it takes less than two minutes to calculate the
9
5101520Phones per second20406080100WER in %TABLE III: Comparison of SNR with CommanderSong [59],
best result shown in bold print.
None
15.88
40 dB
17.93
20 dB
21.76
0 dB
19.38
SNR
CommanderSong [59]
15.32
voice command hidden in an audio sample. The MUSHRA
test provides an estimate of the perceived audio quality of
adversarial examples, where we tested different parameter
setups of the hiding process.
A. Transcription Test
While the original text of a speech audio sample should
still be understandable by human listeners, we aim for a result
where the hidden command cannot be transcribed or even
identiﬁed as speech. Therefore, we performed the transcription
test,
listeners were asked to transcribe the
utterances of original and adversarial audio samples.
in which test
1) Study Setup: Each test listener was asked to transcribe
21 audio samples. The utterances were the same for everyone,
but with randomly chosen conditions: 9 original utterances,
3 adversarial examples with λ = 0, λ = 20, and λ = 40
respectively and 3 difference signals of the original and
the adversarial example, one for each value of λ. For the
adversarial utterances, we made sure that all samples were
valid, such that the target text was successfully hidden within
the original utterance. We only included adversarial examples
which required ≤ 500 iterations.
We conducted the tests in a soundproofed chamber and
asked the participants to listen to the samples via headphones.
The task was to type all words of the audio sample into
a blank text ﬁeld without any provision of auto-completion,
grammar, or spell checking. Participants were allowed to repeat
each audio sample as often as needed and enter whatever
they understood. In a post-processing phase, we performed
manual corrections on minor errors in the documented answers
to address typos, misspelled proper nouns, and numbers.
After revising the answers in the post-processing step, we
calculated the WER using the same algorithms as introduced
in Section IV-B1.
2) Results: For the evaluation, we have collected data from
22 listeners during an internal study at our university. None
of the listeners were native speakers, but all had sufﬁcient
English skills to understand and transcribe English utterances.
As we wanted to compare the WER of the original utterances
with the adversarial ones, the average WER of 12.52 % overall
test listeners was sufﬁcient. This number seems high, but the
texts of the WSJ are quite challenging. For the evaluation, we
ignored all cases where only the difference of the original and
adversarial sample was played. For all of these cases, none of
the test listeners was able to recognize any kind of speech and
therefore no text was transcribed.
For the original utterances and the adversarial utterances,
an average WER of 12.59 % and 12.61 % was calculated. The
marginal difference shows that the difference in the audio does
not inﬂuence the intelligibility of the utterances. Additionally,
we have tested the distributions of the original utterances and
(a) Speech
(b) Music
Fig. 8: Success rate as a function of the number of iterations.
The upper plot shows the result for speech audio samples and
the bottom plot the results for music audio samples. Both sets
were tested for different settings of λ.
adversarial perturbations with 500 backpropagation steps on
a 6-core (12 threads) Intel Core i7-4960X processor.
E. Comparison
We compare the amount of noise with Commander-
Song [59], as their approach is also able to create targeted
attacks using Kaldi and therefore the same DNN-HMM-based
ASR system. Additionally, is the only recent approach, which
reported she signal-to-noise-ratio (SNR) of their results.
The SNR measures the amount of noise σ, added to the
original signal x, computed via
SNR(dB) = 10 · log10
Px
Pσ
,
where Px and Pσ are the energies of the original signal and
the noise. This means, the higher the SNR, the less noise was
added.
Table III shows the SNR for successful adversarial sam-
ples, where no hearing thresholds are used (None) and for
different values of λ (40 dB, 20 dB, and 0 dB) in comparison
to CommanderSong. Note, that the SNR does not measure the
perceptible noise and therefore, the resulting values are not
always consistent with the previously reported φ. Nevertheless,
the results show, that in all cases, even if no hearing thresholds
are used, we achieve higher SNRs, meaning, less noise was
added to create a successful adversarial example.
V. USER STUDY
We have evaluated the human perception of our audio
manipulations through a two-part user study. In the transcrip-
tion test, we veriﬁed that it is impossible to understand the
10
050010002000300040005000Iterations0  20 40 60 80 100Success Rate in % = 0 = 20 = 40050010002000300040005000Iterations0  20 40 60 80 100Success Rate in % = 0 = 20 = 40Fig. 9: WER for all 21 utterances over all test listeners of the
original utterances and the adversarial utterances.
the adversarial utterances with a two-sided t-test to verify
whether both distributions have the same mean and variance.
The test with a signiﬁcance level of 1 % shows no difference
for the distributions of original and adversarial utterances.
In the second step, we have also compared the text from the
test listeners with the text which was hidden in the adversarial
examples. For this, we have measured a WER far above 100 %,
which shows that the hidden text is not intelligible. Also, there
are only correct words which were in the original text, too, and
in all cases these were frequent, short words like is, in, or the.
B. MUSHRA Test
In the second part of the study, we have conducted a Mul-
tiple Stimuli with Hidden Reference and Anchor (MUSHRA)
test, which is commonly used to rate the quality of audio
signals [44].
1) Study Setup: The participants were asked to rate the
quality of a set of audio signals with respect to the original
signal. The set contains different versions of the original audio
signal under varying conditions. As the acronym shows, the
set includes a hidden reference and an anchor. The former
is the sample with the best and the latter the one with the