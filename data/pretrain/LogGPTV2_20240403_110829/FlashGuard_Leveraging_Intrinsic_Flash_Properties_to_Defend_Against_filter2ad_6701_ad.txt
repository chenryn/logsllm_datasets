online transaction processing
OLTP of a brokerage firm
IO Pattern
R:22.3%, W:77.7%
R:18.0%, W:82.0%
R:0.9%, W:99.1%
R:8.6%, W:91.4%
R:0.001%,
W:99.999%
R:10.0%, W:90.0%
R:35.5%, W:64.5%
R:11.9%, W:88.1%
R:10.8%, W:89.2%
R:3.1%, W:96.9%
R:9.3%, W:90.7%
R:56.4%, W:43.6%
R:15.2%, W:84.8%
R:17.6%, W:82.4%
R:40.4%, W:59.6%
R:20.1%, W:79.9%
R:29.9%, W:70.1%
R:83.2%, W:16.8%
R:0.0%, W:100.0%
R:75.1%, W:24.9%
R:91.8%, W:8.2%
Figure 7: The total size of the data encrypted by each ran-
somware familiy.
FIU for twenty days [49]; (3) the database workload traces of run-
ning TPC-C benchmark and TPC-E benchmark for eight days [48];
(4) the storage traces of running IOZone benchmark [18] for ten
days; (5) the storage traces of running the Postmark benchmark [29]
for ten days. For each experiment, we first run 50 million mixed
read and write operations to warm up the system and then replay
each trace to collect the performance results.
6.2 Efficiency on Data Recovery
FlashGuard performs the procedure of data recovery following
the approaches discussed in § 5.4. Once the recovery procedure is
finished, we manually verify the pages that have been read from
flash device. All the original versions of the encrypted data can be
found in the flash pages recovered by FlashGuard. Figure 7 displays
the average size of the data recovered from infection by different
families, which ranges from 0.2 GB to 4.1 GB.
Figure 8: The time of restoring the data that have been en-
crypted by ransomware.
The execution time of restoring the encrypted data ranges from
4.2 seconds to 49.6 seconds as shown in Figure 8. FlashGuard lever-
ages the internal parallelism in flash device to access the retained
invalid pages in parallels. It is noted that the recovery time is not
proportional to the victim data size, as the retained invalid pages are
not evenly distributed across the parallel elements (i.e., chip-level
packages) in flash device. However, the current recovery approach
used in FlashGuard is much faster than the naive approach that
scans the whole flash device (which takes 707.7 seconds).
As most of the ransomware samples do not read and overwrite
user data many times, it takes little time for FlashGuard to recon-
struct the original files. Although encryption ransomware would
attack user data with the knowledge of SSD properties, such as
keeping reading and overwriting user data to an SSD (more cases
will be discussed in § 7), FlashGuard can still restore the encrypted
data since it retains all their older versions.
6.3 Impact on Storage Performance
To understand the impact of FlashGuard on storage performance,
we begin with the default over-provisioning (15% of the SSD’s full
capacity), and run the acknowledged storage traces collected from
real-world applications (see Table 3). We assume all the writes are
encrypted, which means all the invalid pages that have been read
will be retained in SSD. The time of holding these invalid pages
ranges from 2 days to 20 days, the storage latency and throughput
are reported in Figure 9 and Figure 10.
For most of the workloads, the average latency of running them
on FlashGuard is almost the same as that of running them on the
unmodified SSD as shown in Figure 9. For I/O-intensive workloads
including Postmark, TPCC and TPCE, FlashGuard increases the av-
erage latency by up to 6.1%. As the time of holding retained invalid
pages is increased, the average latency is slightly increased. In terms
of I/O throughput, FlashGuard has trivial impact as shown in Fig-
ure 10. For I/O-intensive workloads, the average throughput drops
by up to 0.6%. FlashGuard does not introduce much performance
overhead for several reasons:
First, according to our statistical study on a variety of real-world
storage traces collected over six to twenty days (see Figure 11),
only a small portion (4.1% on average) of the storage operations
have the similar I/O patterns (i.e., read-overwrite operations) as
encryption ransomware. Therefore, FlashGuard retains only a small
amount of invalid pages for regular applications. Second, the RFTL
in FlashGuard delays the GC execution on the flash blocks with
CTB-LockerJigSawMaktub7ev3nHydraCryptTeslaCryptCerberStampadoMobefCryptoFortressCryptoWallLockyPetya01.02.03.04.05.0Victim Data Size (GB)CTB-LockerJigSawMaktub7ev3nHydraCryptTeslaCryptCerberStampadoMobefCryptoFortressCryptoWallLockyPetya015304560Recovery Time (secs)(a) Server Storage in Enterprise
(b) Server Storage in University
(c) Misc I/O Workloads
Figure 9: The average latency of running real-world workloads with FlashGuard vs. Unmodified SSD. The time of holding
retained invalid pages in FlashGuard ranges from 2 days to 20 days. FlashGuard’s average latency is almost the same as that
of the unmodified SSD for a variety of workloads.
(a) Server Storage in Enterprise
(b) Server Storage in University
(c) Misc I/O Workloads
Figure 10: The average throughput of running real-world workloads with FlashGuard vs. Unmodified SSD. FlashGuard has
negligible impact on the I/O throughput for most of these workloads.
To further understand the performance overhead of FlashGuard,
we profile the GC events and collect statistics on the number of addi-
tional page movements. As shown in Table 4, all the FIU workloads
incur no additional page movements, although the time of holding
the retained invalid pages is set to be 20 days. For the workloads
running in enterprise servers, up to 0.8% of the page movements
are contributed by retaining invalid pages. For those I/O intensive
workloads such as Postmark, TPCC and TPCE, more page move-
ments are introduced. Since the IOZone traces are write-only, no
pages are required to be retained in FlashGuard.
We also investigate how the over-provisioning (i.e., reserve more
free blocks in SSD) affects FlashGuard’s performance. We increase
the over-provisioning ratio from 15% (default setting) to 20% and
30% respectively, and do the performance comparison with the
unmodified SSD. As demonstrated in Figure 12, the average I/O
latency of running a variety of real-world workloads on FlashGuard
is almost the same as that of running these workloads on unmodified
SSD, indicating that FlashGuard has negligible negative impact
on regular storage operations. As we increase the ratio of over-
provisioning, the average latency is slightly decreased for both
unmodified SSD and FlashGuard because the storage capacity is
traded for performance. In terms of the storage throughput with
different over-provisioning ratio (not shown in the paper), we reach
the similar conclusion that FlashGuard introduces trivial overhead.
Figure 11: The analytics on the I/O patterns of the real-world
application workloads.
retained invalid pages by counting them as valid pages, which
reduces the chances of moving retained invalid pages. Third, the GC
is executed in background, which allows FTLs schedule GC during
the idle time of flash controller, further reducing the performance
interference caused by GC. Finally, the existing I/O schedulers and
FTLs provide decent GC efficiency (i.e., the valid page movements
during GC procedure) for many workloads. When all the pages
on a flash block are invalid, the flash block will be erased without
incurring any page movement. In FlashGuard, no additional page
movement is required for a flash block whose pages are all retained
invalid pages.
ms-hmms-mdsms-prnms-prxyms-rsrchms-srcms-stgms-tsms-usrms-wdevms-web020040060080010001200MicrosecondsUnmodified SSDFlashGuard (2 days)FlashGuard (4 days)FlashGuard (8 days)FlashGuard (16 days)FlashGuard (20 days)coursewebmailhomemailserverresearchwebusers050100150200250300350MicrosecondsPostmarkIOZoneTPCCTPCE100101102103104105Microsecondsms-hmms-mdsms-prnms-prxyms-rsrchms-srcms-stgms-tsms-usrms-wdevms-web0102030405060IOPS (x1000)Unmodified SSDFlashGuard (2 days)FlashGuard (4 days)FlashGuard (8 days)FlashGuard (16 days)FlashGuard (20 days)coursewebmailhomemailserverresearchwebusers05101520253035IOPS (x1000)PostmarkIOZoneTPCCTPCE0102030405060IOPS (x1000)ms-hmms-mdsms-prnms-prxyms-rsrchms-srcms-stgms-tsms-usrms-wdevms-webcoursewebmailhomemailserverresearchwebusersPostmarkIOZoneTPCCTPCE020406080100Percentage (%)ReadWriteRead-OverwriteTable 4: The additional page movements (%) for retaining invalid pages in FlashGuard over the time period from 2 to 10 days.
Server Storage in Enterprise
Server Storage in University
Misc I/O Workloads
s
y
a
d
2
4
8
16
20
m
h
0.0
0.0
0.5
0.5
0.5
s
d
m
0.0
0.0
0.0
0.0
0.0
n
r
p
0.0
0.0
0.0
0.0
0.0
y
x
r
p
0.0
0.0
0.0
0.0
0.0
h
c
r
s
r
0.0
0.0
0.0
0.0
0.0
c
r
s
0.0
0.0
0.0
0.0
0.0
g
t
s
0.0
0.0
0.0
0.0
0.0
t
r
s
s u
0.0
0.0
0.1
0.0
0.0
0.1
0.3
0.0
0.0
0.3
v
e
d
w
0.0
0.0
0.0
0.0
0.0
b
e
w
0.1
0.1
0.4
0.6
0.8
e
s
r
u
o
c
0.0
0.0
0.0
0.0
0.0
l
i
a
m
b
e
w
0.0
0.0
0.0
0.0
0.0
e
m
o
h
0.0
0.0
0.0
0.0
0.0
r
e
v
r
e
s
l
i
a
m
0.0
0.0
0.0
0.0
0.0
h
c
r
a
e
s
e
r
0.0
0.0
0.0
0.0
0.0
s
r
e
s
u
b
e
w
0.0
0.0
0.0
0.0
0.0
k
r
a
m
t
s
o
P
8.5
9.1
9.7
9.7
9.7
I
e
n
o
Z
O
0.0
0.0
0.0
0.0
0.0
C
C
P
T
8.1
8.3
8.8
8.8
8.8
E
C
P
T
5.3
5.5
5.7