non-exploitable size. They already note that their approach is
highly dependent on the ordering of instructions as the CPU
might perform the load before the comparison. In that case,
the attack would still be possible.
Google proposes a method called retpoline [83], a code se-
quence that replaces indirect branches with return instructions,
to prevent branch poisoning. This method ensures that return
instructions always speculate into an endless loop through the
RSB. The actual target destination is pushed on the stack and
returned to using the ret instruction. For retpoline, Intel [39]
notes that in future CPUs that have Control-ﬂow Enforcement
Technology (CET) capabilities to defend against ROP attacks,
retpoline might trigger false positives in the CET defenses.
To mitigate this possibility, future CPUs also implement hard-
ware defenses for Spectre-BTB called enhanced IBRS [39].
On Skylake and newer architectures, Intel [39] proposes
RSB stufﬁng to prevent an RSB underﬁll and the ensuing
fallback to the BTB. Hence, on every context switch into the
kernel, the RSB is ﬁlled with the address of a benign gadget.
This behavior is similar to retpoline. For Broadwell and older
architectures, Intel [39] provided a microcode update to make
the ret instruction predictable, enabling retpoline to be a ro-
bust defense against Spectre-BTB. Windows has also enabled
retpoline on their systems [14].
C3: Ensuring that secret data cannot be reached. Differ-
ent projects use different techniques to mitigate the problem
of Spectre. WebKit employs two such techniques to limit the
access to secret data [70]. WebKit ﬁrst replaces array bound
checks with index masking. By applying a bit mask, WebKit
cannot ensure that the access is always in bounds, but intro-
duces a maximum range for the out-of-bounds violation. In
the second strategy, WebKit uses a pseudo-random poison
value to protect pointers from misuse. Using this approach,
an attacker would ﬁrst have to learn the poison value before
he can use it. The more signiﬁcant impact of this approach
is that mispredictions on the branch instruction used for type
checks results in the wrong type being used for the pointer.
Google proposes another defense called site isolation [81],
which is now enabled in Chrome by default. Site isolation
executes each site in its own process and therefore limits the
amount of data that is exposed to side-channel attacks. Even
in the case where the attacker has arbitrary memory reads, he
can only read data from its own process.
Kiriansky and Waldspurger [48] propose to restrict access
to sensitive data by using protection keys like Intel Memory
Protection Key (MPK) technology [31]. They note that by
using Spectre-PHT an attacker can ﬁrst disable the protection
before reading the data. To prevent this, they propose to in-
clude an lfence instruction in wrpkru, an instruction used
to modify protection keys.
6.2 Defenses for Meltdown
D1: Ensuring that architecturally inaccessible data re-
mains inaccessible on the microarchitectural level.
The fundamental problem of Meltdown-type attacks is that
the CPU allows the transient instruction stream to compute on
architecturally inaccessible values, and hence, leak them. By
assuring that execution does not continue with unauthorized
data after a fault, such attacks can be mitigated directly in
silicon. This design is enforced in AMD processors [4], and
more recently also in Intel processors from Whiskey Lake
onwards that enumerate RDCL_NO support [40]. However,
mitigations for existing microarchitectures are necessary, ei-
ther through microcode updates, or operating-system-level
software workarounds. These approaches aim to keep archi-
tecturally inaccessible data also inaccessible at the microar-
chitectural level.
Gruss et al. originally proposed KAISER [22, 23] to miti-
gate side-channel attacks defeating KASLR. However, it also
defends against Meltdown-US attacks by preventing kernel
secrets from being mapped in user space. Besides its perfor-
mance impact, KAISER has one practical limitation [22, 56].
For x86, some privileged memory locations must always be
mapped in user space. KAISER is implemented in Linux as
kernel page-table isolation (KPTI) [58] and has also been
262    28th USENIX Security Symposium
USENIX Association
backported to older versions. Microsoft provides a similar
patch as of Windows 10 Build 17035 [42] and Mac OS X and
iOS have similar patches [41].
For Meltdown-GP, where the attacker leaks the contents of
system registers that are architecturally not accessible in its
current privilege level, Intel released microcode updates [35].
While AMD is not susceptible [5], ARM incorporated miti-
gations in future CPU designs and suggests to substitute the
register values with dummy values on context switches for
CPUs where mitigations are not available [6].
Preventing the access-control race condition exploited by
Foreshadow and Meltdown may not be feasible with mi-
crocode updates [85]. Thus, Intel proposes a multi-stage ap-
proach to mitigate Foreshadow (L1TF) attacks on current
CPUs [34, 90]. First, to maintain process isolation, the op-
erating system has to sanitize the physical address ﬁeld of
unmapped page-table entries. The kernel either clears the
physical address ﬁeld, or sets it to non-existent physical mem-
ory. In the case of the former, Intel suggests placing 4 KB of
dummy data at the start of the physical address space, and
clearing the PS bit in page tables to prevent attackers from
exploiting huge pages.
For SGX enclaves or hypervisors, which cannot trust the
address translation performed by an untrusted OS, Intel pro-
poses to either store secrets in uncacheable memory (as spec-
iﬁed in the PAT or the MTRRs), or ﬂush the L1 data cache
when switching protection domains. With recent microcode
updates, L1 is automatically ﬂushed upon enclave exit, and
hypervisors can additionally ﬂush L1 before handing over
control to an untrusted virtual machine. Flushing the cache is
also done upon exiting System Management Mode (SMM) to
mitigate Foreshadow-NG attacks on SMM.
To mitigate attacks across logical cores, Intel supplied a
microcode update to ensure that different SGX attestation
keys are derived when hyperthreading is enabled or disabled.
To ensure that no non-SMM software runs while data belong-
ing to SMM are in the L1 data cache, SMM software must
rendezvous all logical cores upon entry and exit. According
to Intel, this is expected to be the default behavior for most
SMM software [34]. To protect against Foreshadow-NG at-
tacks when hyperthreading is enabled, the hypervisor must
ensure that no hypervisor thread runs on a sibling core with
an untrusted VM.
D2: Preventing the occurrence of faults. Since Meltdown-
type attacks exploit delayed exception handling in the CPU,
another mitigation approach is to prevent the occurrence of a
fault in the ﬁrst place. Thus, accesses which would normally
fault, become (both architecturally and microarchitecturally)
valid accesses but do not leak secret data.
One example of such behavior are SGX’s abort page se-
mantics, where accessing enclave memory from the outside
returns -1 instead of faulting. Thus, SGX has inadvertent pro-
tection against Meltdown-US. However, the Foreshadow [85]
attack showed that it is possible to actively provoke another
fault by unmapping the enclave page, making SGX enclaves
susceptible to the Meltdown-P variant.
Preventing the fault is also the countermeasure for
Meltdown-NM [78] that is deployed since Linux 4.6 [57].
By replacing lazy switching with eager switching, the FPU is
always available, and access to the FPU can never fault. Here,
the countermeasure is effective, as there is no other way to
provoke a fault when accessing the FPU.
6.3 Evaluation of Defenses
Spectre Defenses. We evaluate defenses based on their ca-
pabilities of mitigating Spectre attacks. Defenses that require
hardware modiﬁcations are only evaluated theoretically. In
addition, we discuss which vendors have CPUs vulnerable to
what type of Spectre- and Meltdown-type attack. The results
of our evaluation are shown in Table 10.
Several defenses only consider a speciﬁc covert channel
(see Table 9), i.e., they only try to prevent an attacker from
recovering the data using a speciﬁc covert channel instead of
targeting the root cause of the vulnerability. Therefore, they
can be subverted by using a different one. As such, they can
not be considered a reliable defense. Other defenses only limit
the amount of data that can be leaked [70,81] or simply require
more repetitions on the attacker side [74, 87]. Therefore, they
are only partial solutions. RSB stufﬁng only protects a cross-
process attack but does not mitigate a same-process attack.
Many of the defenses are not enabled by default or depend
on the underlying hardware and operating system [3, 4, 6, 40].
With serializing instructions [4, 6, 35] after a bounds check,
we were still able to leak data on Intel and ARM (only with
DSB SY+ISH instruction) through a single memory access and
the TLB. On ARM, we observed no leakage following a CSDB
barrier in combination with conditional selects or moves. We
also observed no leakage with SLH, although the possibility
remains that our experiment failed to bypass the mitigation.
Taint tracking theoretically mitigates all forms of Spectre-
type attacks as data that has been tainted cannot be used in a
transient execution. Therefore, the data does not enter a covert
channel and can subsequently not be leaked.
Meltdown Defenses. We veriﬁed whether we can still exe-
cute Meltdown-type attacks on a fully-patched system. On
a Ryzen Threadripper 1920X, we were still able to execute
Meltdown-BND. On an i5-6200U (Skylake), an i7-8700K
(Coffee Lake), and an i7-8565U (Whiskey Lake), we were
able to successfully run a Meltdown-MPX, Meltdown-BND,
and Meltdown-RW attack. Additionally to those, we were
also able to run a Meltdown-PK attack on an Amazon EC2
C5 instance (Skylake-SP). Our results indicate that current
mitigations only prevent Meltdown-type attacks that cross the
current privilege level. We also tested whether we can still
successfully execute a Meltdown-US attack on a recent Intel
Whiskey Lake CPU without KPTI enabled, as Intel claims
these processors are no longer vulnerable. In our experiments,
USENIX Association
28th USENIX Security Symposium    263
Table 10: Spectre defenses and which attacks they mitigate.
g
c
e
p
S
i
s
i
v
n
I
c
e
p
S
e
f
a
S
G
W
A
D
n
e
e
g
n
askin
Isolatio
Valu
Stufﬁ
olin
M
ex
Poiso
etp
Site
d
In
R
H
L
S
n
B
S
R
n
n
ctio
g
n
i
k
c
u
a
d
r
e
T
R
h
t
er
t
n
Tim
o
i
l
a
S
T
erializatio
S
B
B
S
D/S
B
S
S
S
B
R
N
S
IB
Y
P
B
TIB
P
IB
S
Defense
Attack
Intel
ARM
AMD
Spectre-PHT
Spectre-BTB
Spectre-RSB
Spectre-STL
Spectre-PHT
Spectre-BTB
Spectre-RSB
Spectre-STL
Spectre-PHT
Spectre-BTB
Spectre-RSB
Spectre-STL
), theoretically mitigated (
Symbols show if an attack is mitigated (
gated (
retically impeded (
ready, while typeset defenses are academic proposals.
), partially mitigated (
), theoretically impeded (
), not miti-
), not theo-
). Defenses in italics are production-
), or out of scope (
we were indeed not able to leak any data on such CPUs but
encourage other researchers to further investigate newer pro-
cessor generations.
6.4 Performance Impact of Countermeasures
There have been several reports on performance impacts of
selected countermeasures. Some report the performance im-
pact based on real-world scenarios (top of Table 11) while
others use a speciﬁc benchmark that might not resemble real-
world usage (lower part of Table 11). Based on the different
testing scenarios, the results are hard to compare. To further
complicate matters, some countermeasures require hardware
modiﬁcations that are not available, and it is therefore hard to
verify the performance loss.
One countermeasure that stands out with a huge decrease in
performance is serialization and highlights the importance of
speculative execution to improve CPU performance. Another
interesting countermeasure is KPTI. While it was initially
reported to have a huge impact on performance, recent work
shows that the decrease is almost negligible on systems that
support PCID [20]. To mitigate Spectre and Meltdown, cur-
rent systems rely on a combination of countermeasures. To
show the overall decrease on a Linux 4.19 kernel with the
default mitigations enabled, Larabel [54] performed multiple
benchmarks to determine the impact. On Intel, the slowdown
was 7-16% compared to a non-mitigated kernel, on AMD it
was 3-4%.
Naturally, the question arises which countermeasures to
enable. For most users, the risk of exploitation is low, and
default software mitigations as provided by Linux, Microsoft,