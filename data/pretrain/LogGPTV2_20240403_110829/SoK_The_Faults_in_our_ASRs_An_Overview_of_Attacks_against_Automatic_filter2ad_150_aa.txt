title:SoK: The Faults in our ASRs: An Overview of Attacks against Automatic
Speech Recognition and Speaker Identification Systems
author:Hadi Abdullah and
Kevin Warren and
Vincent Bindschaedler and
Nicolas Papernot and
Patrick Traynor
4
1
0
0
0
.
1
2
0
2
.
1
0
0
0
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
1
2
0
2
©
0
0
.
1
3
$
/
1
2
/
5
-
4
3
9
8
-
1
8
2
7
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
1
2
0
2
2021 IEEE Symposium on Security and Privacy (SP)
SoK: The Faults in our ASRs: An Overview of
Attacks against Automatic Speech Recognition and
Speaker Identiﬁcation Systems
Hadi Abdullah1, Kevin Warren1, Vincent Bindschaedler1, Nicolas Papernot2, and Patrick Traynor1
1University of Florida
2University of Toronto
Abstract—Speech and speaker recognition systems are em-
ployed in a variety of applications, from personal assistants to
telephony surveillance and biometric authentication. The wide
deployment of these systems has been made possible by the
improved accuracy in neural networks. Like other systems based
on neural networks, recent research has demonstrated that
speech and speaker recognition systems are vulnerable to attacks
using manipulated inputs. However, as we demonstrate in this
paper, the end-to-end architecture of speech and speaker systems
and the nature of their inputs make attacks and defenses against
them substantially different than those in the image space. We
demonstrate this ﬁrst by systematizing existing research in this
space and providing a taxonomy through which the community
can evaluate future work. We then demonstrate experimentally
that attacks against these models almost universally fail to
transfer. In so doing, we argue that substantial additional work
is required to provide adequate mitigations in this space.
I. INTRODUCTION
Voice Processing Systems (VPSes) are a critical
inter-
face for both classical and emerging systems. While by no
means conceptually new, the last decade has seen a dramatic
improvement in both Automatic Speech Recognition (ASR)
and Speaker Identiﬁcation (SI) VPSes. Such interfaces are
not merely for convenience; rather, they drastically improve
usablity for groups such as the elderly and the visually im-
pared [1], [2], make devices without screens such as headless
IoT systems accessible [3], and make user authentication
nearly invisible [4], [5].
Advances in neural networks have helped make VPSes
practical. Although different architectures have been used in
the past (e.g., Hidden Markov models), systems built atop
neural networks now dominate the space. While neural net-
works have enabled signiﬁcant improvements in transcription
and identiﬁcation accuracy, substantial literature in the ﬁeld
of adversarial machine learning shows that
they are also
vulnerable to a wide array of attacks. In particular, the research
community has put forth signiﬁcant effort
to demonstrate
that image classiﬁcation and, only recently, VPSes built on
neural networks are vulnerable to exploitation using small
perturbations to their inputs.
While it may be tempting to view VPSes as simply an-
other application of neural networks and to therefore assume
that previous work on adversarial machine learning applies
directly to this new application, this paper shows that this is
demonstrably untrue. We make the following contributions:
• Taxonomization of VPS Threat Models: Attacks on
VPSes are conducted using a number of widely differ-
ing (sometimes implicit) assumptions about adversarial
behavior and ability. We provide the ﬁrst framework for
reasoning more broadly about work in this space.
• Categorization of Existing Work: We take the body of
work on attacks and defenses for VPSes and categorize
them based on the above taxonomy. We show that while
many papers have already been published, signiﬁcant
work remains to be done.
• Experimental Testing of Transferability: We demon-
strate that transferability, or the ability to exploit multiple
models using an adversarial input is not currently achiev-
able against VPSes via attacks that rely on gradient-based
optimization [6]. Through extensive experimentation, we
show that transferability is currently extremely unlikely
even when considering two instances of the same VPSes
trained separately on the same train-test splits, hyper-
parameters, initial random seeds and architecture. The
methodology and results for the experiments can be found
in the Appendix.
The remainder of this paper is organized as follows: Sec-
tion II provides background information on VPSes; Section III
discusses the special considerations that must be understood
when attacking VPSes; Sections VI and IV details our threat
model taxonomy; Section V then identiﬁes the novel con-
tributions of published work through this taxonomy; Sec-
tion VII explores currently proposed defense and detection
mechanisms; Section XI-A explores transferability and why
optimization attacks currently fail to provide this property
for VPSes; Section VIII discusses open issues; Section IX
provides concluding remarks and the Appendix details the
methodology and results for the transferability experiments.
II. BACKGROUND
A. Psychoacoustics
Modern speech recognition systems are designed to approx-
imate the functioning of the human auditory system [7]. Re-
search in psychoacoustics has revealed the complex ways with
which the human brain processes audio. For example, there
© 2021, Hadi Abdullah. Under license to IEEE.
DOI 10.1109/SP40001.2021.00014
730
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:09:49 UTC from IEEE Xplore.  Restrictions apply. 
Figure 1: The steps that form the Automatic Speech Recognition pipeline. (a) The audio is recorded using a microphone. (b) It
is prepossessed to remove any rudimentary noise or high frequencies using a low pass ﬁlter. (c) The audio is passed through a
feature extraction function (in this case the MFCC function) that extracts the most important features of the audio sample. (d)
The features are passed on to the model for inference, which outputs a non-human-readable string. (e) The string is decoded
to produce a human-readable transcription.
is a difference between the actual intensity and the brain’s
perceived intensity of an audio tone. Therefore, the perception
of loudness is non-linear with respect to intensity [8]. In order
to double the brain’s perceived intensity, one must increase
the actual intensity by a factor of eight. Similarly, the limit of
human hearing ranges from 20Hz to 20kHz. Any frequency
outside this range (e.g., ultrasound (20kHz to 10 MHz)),
can not be heard. The brain employs complex processes to
understand speech in noisy environments or during cross-talk.
These include visual cues, pitch separation, intensity, binural
unmasking, context, and memory [8].
time domain signal into the frequency domain representa-
tion [20]:
)k] − i · sin[
N−1(cid:88)
(cid:18)
(cid:19)
Fk =
(n +
(n +
)k]
sn
cos[
π
N
π
N
1
2
1
2
n=0
(cid:18)
(cid:19)
|Fk|
700
mk = 2595 log10
1 +
B. Voice Processing Systems (VPSes)
Researchers have developed VPSes to capture functionality
of the human auditory system, albeit coarsely. VPSes are
of two types: ASR systems and SI systems. ASR systems
convert speech to text. SI systems attempt to identify a person
by their speech samples. There are a wide variety of ASR
and SI systems in use today, including personal assistants
(e.g., Google Home [9], Amazon Alexa [10], Siri [11]),
telephony surveillance systems [12], [13], [14], [15], [16], and
conferencing transcription services [17].
The modern ASR system pipeline consists of the steps
shown in Figure1. Due to the similarity of the SI and ASR
pipelines, in this subsection we deﬁne the pipeline in the
context of ASR. The steps include the following:
1) Preprocessing: The audio sample is ﬁrst passed through
a preprocessing phase (Figure 1(b)). Here, segments of audio
containing human speech are identiﬁed using voice-activity
detection algorithms, such as G.729 [18]. Next, these selected
segments are passed through a low-pass ﬁlter to remove high
frequencies. This helps to improve ASR accuracy by removing
the unnecessary noise from the samples.
2) Feature Extraction: The ﬁltered audio is divided into
overlapping frames, usually 20 ms in length [19], to capture
the transitions in the signal. Each frame is then passed to
the feature extraction step (Figure 1(c)). To approximate the
human auditory system, the most commonly used algorithm
is the Mel Frequency Cepstral Coefﬁcient (MFCC) [19],
which extracts the features that the human ear considers most
important. The MFCC is comprised of four steps (Figure 1(c)):
a) Discrete Fourier Transform (DFT): The DFT of the
audio sample is computed ﬁrst (Figure 1(c.i)). It converts a
where the real and imaginary parts are used to infer the phase
of the signal and intensity of a frequency. F = (F1, ..., FN )
is a vector of complex numbers, N is the total number of
samples, n is the sample number, k is the frequency number,
and sn is the n-th sample of the input. The magnitude of
Fk corresponds to the intensity of the k-th frequency in s.
The DFT output, called the spectrum, provides a ﬁne-grained
understanding of an audio sample’s frequency composition.
b) Mel Filtering: As previously mentioned, the human
auditory system treats frequencies in a non-linear manner. To
recreate this effect, the Mel ﬁlter scales the intensities of the
frequencies accordingly (Figure 1(c.ii)), using the following:
where mk is the resulting Mel scaled frequency intensity. The
scale assigns a higher weight to frequencies that exist between
100Hz and 8kHz [21]. This is done to amplify the frequencies
that constitute human speech.
c) Log Scaling: The output of the Mel-ﬁlter is scaled by
the log function (Figure 1(c.iii)). This reproduces logarithmic
perception exhibited by the human auditory system.
d) Discrete Cosine Transform (DCT): The DCT (Fig-
ure 1(c.iv)) [21] decomposes an input into a series of co-
sine components. The components that represent most of the
information about the input are retained, while the rest are
discarded. This is done using the following equation:
N−1(cid:88)
n=0
(cid:18) (2n + 1)kπ
(cid:19)
2N
Fk =
sn cos
where Fk is the intensity of the kth component in s.
3) Inference: The extracted features are ﬁnally passed to
a probabilistic model for inference (Figure 1(d)). There are a
variety of models available for VPSes. However, we focus on
neural networks as they are the dominant choice in this space.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:09:49 UTC from IEEE Xplore.  Restrictions apply. 
731
dimensional (character × total time) matrix of probabilities
(Figure 2(d)). In the image domain, one typically picks the la-
bel corresponding to the largest probability as the ﬁnal output.
In contrast, doing so in an ASR will not necessarily produce
a correct transcription. As a result, there are multiple possible
transcriptions for a single audio ﬁle [23]. For example, as seen
in Figure 2(d), for the audio sample with the word “lock”,
a model may produce multiple strings such as “llo-ockk” or
“ll-ok-kk”. The output strings are not reader friendly, since
they reﬂect speaker characteristics like speed and accent. To
overcome this problem, the decoding stage of the ASR system
converts the model output string into words (Figure 2(e)). One
of the most commonly used decoding algorithms is Beam
Search [24]. It is charged with selecting a sequence of tokens
based on a distribution of probabilities over dictionary words,
which the model predicts for each token. This heuristic is
commonly employed to explore multiple sequences without
being too sensitive to the model’s prediction at each step of the
sequence. This is a heuristic that always outputs the most likely
word for a given label string, thus the output transcription is
not guaranteed to be optimal.
5) Alternative Conﬁgurations: There are many possible
conﬁgurations for an ASR pipeline. These can use different
types of voice-activity detection algorithms for preprocessing
(Figure 1(b)) or any variety of feature extraction algorithms
(Figure 1(c)), which include DFTs, MFCCs, or Convolutional
Blocks. Similarly, an ASR system can use any number of
model types for inference, including DNN-HMM [25], DNN-
RNN [26], [5] and HMM-GMM [27], [28]. ASRs with
different conﬁgurations are frequently introduced. Given the
popularity of neural networks, we expect non-neural network
VPS conﬁgurations to eventually be phased out. As a result,
the focus of our paper is adversarial ML in the space of neural
network based VPSes. This allows us to apply our ﬁndings to
a larger population of VPSes.
C. Speaker Identiﬁcation (SI)
1) Types: SI systems can be broadly classiﬁed into two
types:
identiﬁcation and veriﬁcation. Identiﬁcation systems
determine the identity of the speaker of a given voice sample.
In contrast, veriﬁcation system ascertains whether the claimed
identity of a speaker matches the given voice sample. For
simplicity of exposition, we refer to both as SI.
2) ASR vs SI: The modern ASR and SI pipelines are very
similar to each other [29]. Both of them use the overall
structure illustrated in Figure 2. Both systems employ pre-
processing, feature extraction, and inference. However, they
differ at the last stage of the pipeline. While ASRs have a
decoding stage (Figure 2(e)), SIs do not. Instead, an SI directly
outputs the probability distribution across all
the speakers
effectively stopping at Figure 2(d).
D. Adversarial Machine Learning in VPSes
The term adversarial machine learning refers to the study of
attacks and defenses for ML systems [30]. Attacks may target