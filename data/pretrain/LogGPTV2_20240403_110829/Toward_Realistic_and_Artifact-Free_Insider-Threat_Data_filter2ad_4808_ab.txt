We assembled a “library” of realistic insider attacks,
scripted the attacks, and launched the scripts against partic-
ipating users’ accounts. Whereas other researchers injected
one user’s commands into another user’s data as a simu-
lated attack, our scripts perform a real-world attack against
the user’s account (and then recover from the attack). The
scripts were designed to impersonate an attacker who gains
unauthorized access to an account (e.g., by using the vic-
tim’s workstation while he or she is away).
In another departure from other researchers’ methods,
users in the present study sanitized their own data. We felt
that the users themselves were in the best position to iden-
tify sensitive information, and that their input would help re-
searchers understand what sort of data users are reluctant to
share. An application called the Sanitizer was built to allow
users to view and to search their own data, to mark records
as sensitive, and to export sanitized copies of the data. Data
could be exported using any of the three sanitization strate-
gies (Redact-Only, Token-Only, and Word-Token), which
are described in detail in Section 5.3. By having users san-
itize their own data, researchers avoided having to employ
unnecessarily broad, draconian sanitization techniques.
To replicate Maxion’s experiment, we converted the
users’ sanitized data into Truncated and Enriched evaluation
data sets, and the performance of the naive-Bayes detector
was tested on each one. The miss rate, false alarm rate, and
cost of error were calculated as in the earlier experiment. To
compare the results to those using raw, unsanitized data, we
deployed the naive-Bayes detector on users’ workstations,
and we walked the users through the process of running it
on their own raw data and reporting the results. In this way,
we were able to compare the results of the experiment on
raw data to the results with each of the three types of sani-
tization, yet the users’ sensitive raw data were never shared
with the researchers.
5. Apparatus
We wrote three software programs to enable this in-
vestigation: (1) a reliable data-collection package called
Monolog; (2) an insider-script library to automate the in-
jection of realistic insider attacks; and (3) a Sanitizer ap-
plication to enable the review and sanitization of collected
data.
8989
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:38:02 UTC from IEEE Xplore.  Restrictions apply. 
5.1. Monolog data collector
Monolog (as in “monitor and logger”) was designed to
reliably record user behavior within a command shell on
the Linux operating system. We instrumented the com-
mand shell bash to collect data commonly used for user
proﬁling at the command line. Lane and Brodley [5] col-
lected the command lines typed by their users. Greenberg
[2] collected not only the command lines, but also the cur-
rent working directory and the exit status of each command.
Schonlau et al. [11] collected the names of the programs ex-
ecuted (which may differ from the commands typed by the
user because of shell aliases or scripting). Monolog records
each of these types of data used in earlier studies.
Previous researchers found that instrumenting a shell
was problematic because of the complexity of the code [2].
We avoid much of the complexity because the shells sim-
ply send command-line data to a dedicated logging facil-
ity as soon as it becomes available. By keeping little state
in the instrumented shells, we avoid data loss if the shell
crashes or is unexpectedly terminated. The logging process,
called the Monolog daemon, writes data from the shells
to restricted-access ﬁles, one per monitoring shell process.
Access restrictions prevent users from snooping into each
others’ logs, and also prevents users from corrupting their
own logs. The design of the daemon is simple compared to
that of a shell. It is under 3K lines of code, and its correct-
ness can be tested independently of the instrumented shells.
5.2. Insider-script library
While Monolog ensures that user commands are reliably
collected, another mechanism is needed to inject realistic
insider commands. Previous researchers borrowed com-
mands from one benign user to use as insider data for an-
other user [5, 7, 11], but as we have noted, this is unrealistic.
We developed a library of scripts designed to impersonate a
human attacker who gains access to another user’s account.
Our scripts were designed to execute the commands of an
attack in a shell monitored by Monolog, so we conduct a
real attack against a participating user’s account. Conduct-
ing the attack allows us to verify its realism, whereas adding
the commands of the attack to data already collected does
not.
Four attack-injection scripts were developed. The at-
tacks were chosen to be consistent with actual insider in-
cidents reported to our research group or documented by
Keeney et al. [4]. The commands executed to accomplish
the attack were chosen by a researcher with some prior
penetration-testing experience.
1. Backdoor. The script downloads the nc network-
connection utility, compiles it, and installs it in the partic-
ipating user’s home directory. The nc program enables a
user to set up a listening socket which will execute a pro-
gram if a remote host connects to it. The nc program is
conﬁgured to listen on a randomly chosen port and, when a
remote host connects, to run /bin/sh. Consequently, the
script sets up a backdoor into the user’s account that any-
one can use just by connecting to the right port. After per-
forming the injection, the script veriﬁes that the backdoor is
running by connecting to it. It recovers from the attack by
removing the backdoor and the nc program.
2. Portscan. The nmap port-scanning program is down-
loaded, compiled, and installed from the command line. It
is used to perform reconnaissance on three other computers
(intended to represent future targets for the attacker). After
performing the injection, the script veriﬁes the output of the
port-scanner. It recovers from the attack by removing the
nmap program.
3. Exposure. The permissions on key ﬁles containing the
user’s personal data are changed to allow anyone on the
system to view them. All “history” ﬁles in the user’s home
directory are changed so that anyone has read permission.
This change allows a spy to reconnoiter the ﬁles the user
accesses. After performing the injection, the script veriﬁes
that the permissions on these ﬁles have changed. It recovers
from the attack by restoring the original permissions.
4. Snoop. The history command is run to determine the
last several commands typed by the user. Potential ﬁle-
names are identiﬁed and extracted from the list. The find
command is used to ﬁnd paths to a selection of those ﬁles,
and those ﬁles which are found are examined with the head
command. This script examines the ﬁrst few lines of up to
10 ﬁles recently accessed by the user, simulating an attempt
to gather information about the user’s recent activities. Af-
ter performing the injection, the script veriﬁes the output of
the commands. No recovery from the attack is necessary
beyond exiting the shell used for the injection.
We designed each script by ﬁrst conducting the attack
manually under controlled conditions. The attack was
recorded by Monolog, and the commands typed by the at-
tacker were extracted, along with the time intervals between
them. Then, we wrote a script (using Perl and the Expect
package) to replay the commands of the attack, scheduling
the timing of each command to match the timing from the
recording. Then, we wrote veriﬁcation functions to parse
the output of each command and to ensure that the expected
output is printed (e.g., no “ﬁle not found” error messages).
We parse and verify the output of each command because
we would not want to conduct an attack that fails in prac-
tice. Further, attack scripts can incorporate the output of
one command as arguments to later commands (e.g., the
Snoop attack uses the ﬁle names printed by history as
arguments in subsequent calls to find). We end the script
9090
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:38:02 UTC from IEEE Xplore.  Restrictions apply. 
with a ﬁnal veriﬁcation and recovery function that restores
the system to its pre-attack state.
The attack scripts are run from a shell that is not mon-
itored by the data collector, so that the name of the script
itself does not appear in the logs as an artifact. For the same
reason, the functions to verify the success of the attack and
recover from it do not themselves execute shell commands.
5.3. Sanitizer application
The data collector and injection library described above
ensure that realistic user behavior is collected, and that re-
alistic attacks are injected. The Sanitizer ensures that users
can look through the collected data to ﬁnd and sanitize in-
formation that users judge to be sensitive.
It provides a
graphical interface with which to review the data collected
by the Monolog data collector.
The Sanitizer contains three panels, shown in Figure 1.
The large panel on the right contains a marked-up copy of
a Monolog session log. Text that may be potentially sensi-
tive is shown on a gray background, and text that has been
marked as sensitive is shown on a black background. A
user can mark text as sensitive by selecting it and pushing a
button. The top-left panel contains a list of all the sessions
not yet sanitized (i.e., a “to-do” list). The lower-left panel
contains a list of sessions that have been sanitized already.
When marking text as sensitive, users choose between
two marking options, called Redact and Tokenize. They
represent different sanitization preferences, and are in-
tended to solicit the user’s judgment about how sensitive
the text is.
1. Tokenize: A user selects Tokenize if he or she prefers
that the selected text be replaced with tokens in the sani-
tized copy of the data. If the same span of text has been
marked for tokenization in two separate places, the same
token will be used to cover it up. This might be a prob-
lem if, for instance, a user’s password is “God” and he to-
kenizes it. Suppose the password is covered up with the
string  and elsewhere in the sanitized data
appears the phrase “In  we trust.” Someone
looking at the sanitized data could infer the user’s password.
2. Redact: The fact that a token will be reused leaks some
information about what was sanitized. The Redact button
can be used in situations where this leakage is problematic.
A user selects redaction if he or she prefers that the selected
text is completely blacked out (as is done to cover up classi-
ﬁed information in declassiﬁed documents). Substituting
the ﬁxed-length redaction string  makes it im-
possible to tell whether one redacted string is the same as
another, making it appropriate for extremely sensitive data
such as passwords.
It is important to note that these marks register a preference.
Whether the data are either tokenized or redacted depends
on the sanitization strategy selected when a sanitized copy
of the data is actually exported.
After sanitizing all the sessions that he or she wishes to
export, the user is given a choice between three sanitiza-
tion strategies called Redact-Only, Token-Only, and Word-
Token. The strategies differ in how they cover up data
marked as sensitive.
Intuitively, they represent different
balance points in the trade-off between a user concerned
with maintaining as much privacy as possible and a re-
searcher trying to preserve useful information. Of the three,
Redact-Only favors privacy the most, Word-Token favors
the preservation of useful information, and Token-Only is
in the middle..
1. Redact-Only. All spans of text marked for sanitization
(either redaction or tokenization) are redacted. All sensi-
tive spans of text are replaced by a string of ﬁve X’s (i.e.,
).
2. Token-Only. All spans of text marked for either redac-
tion or tokenization are replaced by numbered token strings
(e.g.,  or ). If the exact same
span of text appears in two different locations, both will be
replaced by a token with the same number.
3. Word-Token. Spans of text marked for redaction or for
tokenization are ﬁrst divided into words (with whitespace-
delimited boundaries). Then, each word is tokenized indi-
vidually. Whenever a word is tokenized, a search is per-
formed, and every instance of that word is replaced with the
same token without regard for whether it was marked for
sanitization or not (e.g., if the username mary is tokenized
as , then every whitespace-delimited occur-
rence of mary will be replaced with ).
The Redact-Only and Token-Only strategies mimic strate-
gies that others have used in practice [2, 9]. The Word-
Token strategy was designed speciﬁcally to avoid intro-
ducing artifacts into experimental evaluations of anomaly-
based insider-threat detectors. In essence, Word-Token san-
itization makes a list of every distinct word that appears in
any span of text marked sensitive, associates a distinct to-
ken with each word, and replaces every instance of the word
with the corresponding token.
Anomaly-based detection systems (e.g., naive Bayes [8],
Lane and Brodley’s detector [5], and Schonlau et al.’s detec-
tors [11]) are built to recognize patterns between the words
on a command line (e.g., relative frequencies or common
repeating sequences), and to detect violations of these pat-
terns. We theorize that Word-Token sanitization will not
introduce artifacts because the performance of an anomaly-
based detector should not change if every instance of a word
in a data set is replaced with a new word. This study ex-
plores whether our theory holds true.
9191
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:38:02 UTC from IEEE Xplore.  Restrictions apply. 
Figure 1. The Sanitizer application’s graphical user interface shows a list of logs to be sanitized
(top-left panel), a list of logs already sanitized (bottom-left panel), and the contents of a log ﬁle cur-