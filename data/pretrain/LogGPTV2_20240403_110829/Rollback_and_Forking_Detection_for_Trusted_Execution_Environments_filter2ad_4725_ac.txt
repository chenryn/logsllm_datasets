with some P (cid:2)= LCM this veriﬁcation will reveal it. Note
that the remote attestation protocol also convinces the admin
that T is actually executed on the TEE and protected against
a malicious server.
Finally, the admin generates two secret keys, kC for securing
the communication and kP for storing the protocol state, and
injects them into T through the secure channel provided by
the TEE. After T has received the keys, it initializes the
protocol and service states, and retrieves a sealing key kS =
get-keyT,LCM from the TEE. Recall that kP is used to encrypt
the state, and that kP and kC together are stored encrypted kS.
Since kS is generated in a deterministic way in the trusted
hardware of the TEE, T can recover its state from an earlier
epoch using the stable storage of S after a crash. And because
every T running on a different physical TEE obtains a different
sealing key, this binds the state of T to the hardware. The
admin also distributes the communication key to the clients
using a secure channel to each of them.
D. System reboot and recovery
The server S controls starting and stopping T . As argued be-
fore, the TEE is stateless and, therefore, T cannot distinguish
a reboot after a crash from an attack by S. In order to tolerate
server crashes and reboots without administrative intervention,
162
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:47 UTC from IEEE Xplore.  Restrictions apply. 
but also to facilitate planned restarts, the application state is
stored on stable storage.
When the server reboots after a crash, it recreates the trusted
execution context T that runs LCM. T then enters init, which
ﬁrst tries to load a previous state and resumes from there when
it exists. As T obtains kS = get-keyT,LCM from the TEE, it
can decrypt and authenticate kP and the state with kS; the
state also contains kS for communicating with the clients.
T recovers V form the state and can easily derive (t, h)
from V by looking up the client which executed the last
operation in V . Formally, V is an array of (ta, t, h) triples,
and argmax(V ) returns the index of the triples with the highest
sequence number t.
T has now entered a new epoch and is ready to continue
request processing without remote attestation. The clients trust
that T runs LCM from the initial veriﬁcation step during
bootstrapping and from the binding of the sealing key (kS)
that T
to the TEE through the secure hardware. Recall
recovers the communication key kC via the sealing key. Once
a client can engage in encrypted and properly authenticated
communication, protected through kC, to some TEE, the trust
of the client from the initial attestation extends to the current
holder of kC.
E. Stability
For determining the stability of operations, T maintains
the map V with two sequence numbers for every client.
One sequence number of the last acknowledged operation,
and another sequence number of the last operation. The
function majority-stable(V ) returns the sequence number of
the operation that is stable among a majority, that is, the largest
acknowledged sequence number in V that is less than or equal
to more than n/2 sequence numbers in V . Stability indicates
to the clients when their operations have been observed by
others and helps detecting forking attacks. When the server is
correct and all clients periodically invoke operations, then all
operations become stable eventually. In the case of a forking
attack, where one or more clients are separated, the operations
of the forked clients will cease to become stable.
The client protocol returns the sequence number t and the
majority-stable sequence number q together with the operation
result. This enables the client to track the progress of the
operation history. Depending on the application, a client might
want to verify that some critical operation has become stable
or wait until it does before invoking new operations. Note that
the client protocol as described in Alg. 1 only receives stability
updates when it invokes new operations. If the client needs to
be informed earlier about the stability of past operations, it can
simply invoke dummy operations periodically, as introduced
by FAUST [10]. Alternatively, Alg. 1 could be extended to
support a callback mechanism, where clients can register for
a notiﬁcations of stability updates, as also used in Venus [35].
F. Extensions
1) Tolerating server crashes: As the server might crash,
to allow T to recover and
we now extend the protocol
continue processing. In the simple case where T crashes
while it is idling, the correct server restarts it and continues
with the protocol as described before. On the other hand,
when T crashes during the processing of a client request,
we differentiate between two cases: either it crashes before
the store operation returns and has saved the application and
protocol state or afterwards.
Therefore, we equip the client with a retry mechanism:
When the client has not received a reply until a timer expires,
it sends the message again, but marks it as a retry attempt. In
the ﬁrst case (T crashes before successfully stores), the server
will restart T and it eventually receives the retry message.
The veriﬁcation of the sequence number tc and the hash chain
value hc ensures that the lost message has not already been
processed. T simply continues processing and returns the reply
to the client. In the second case (when T crashes after stores),
the veriﬁcation of tc and hc fails since ti stored in V [i] is
bigger than the value received from Ci. The retry marker
instructs T to not consider this as a rollback attack. Therefore,
we extend the protocol state V to store the last operation
result r as well. Then T can retrieve the result from V and
(re)send the REPLY message.
2) Server migration: Since location transparency is a major
advantage in cloud computing, we also include a migration
mechanisms that allows to move a trusted execution context T
to a different host system. There are two trusted execution
context instances involved, on the origin system to be moved
and on the target system to which the protocol migrates.
Migration requires cooperation between the two machines and
that the server’s stable storage can be accessed from the origin
and the target system, for instance by using shared remote
storage.
The migration works as follows. The (correct) origin server
signals the target server to start a trusted execution context T (cid:2)
and to prepare it for migration. Normally, T (cid:2) would try to
retrieve a state encryption key kP from stable storage but
since it was encrypted with the sealing key of T on the origin
system, T (cid:2) cannot obtain that. For this reason, T takes over the
role of the admin and bootstraps T (cid:2) according to the earlier
description. After successful remote attestation, T injects the
state encryption key kP via a secure channel. At this point, T
stops processing requests and provides its current state to T (cid:2);
then T (cid:2) restores the application and protocol state, resumes
executing requests, and is still able to uphold the guarantees
of LCM against rollback and forking attacks.
This migration mechanism does not require a trusted party
and works completely transparently for clients. However,
when the origin system crashes without any possibility to
recover, e.g., when the TEE hardware malfunctions, then an
intervention by a trusted admin is required. In contrast to
the solutions based on a TMC mentioned in Sec. III-A, this
migration mechanism is more robust to server failures. In
particular, the migration of a TMC always requires an admin to
read the last TMC value from the origin system and to update
the TMC on the target system with the correct counter value.
Clearly, this fails if the origin system becomes inaccessible.
163
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:47 UTC from IEEE Xplore.  Restrictions apply. 
LCM still allows migration because the TEE is stateless and
because the state is stored on remote storage. Our proposed
migration scheme is similar to [37].
3) Group membership: In a practical system, the group of
clients will dynamically change, as clients may be removed
from the collaboration group and new clients may join. Al-
though the protocol formulation uses a static client group, it
is easy to extend LCM for handling dynamic changes. When
a new client joins the group, the admin sends the shared
secret kC for secure communication with the trusted execution
context to the new client and instructs T to include the client in
the protocol state. For removing a client, the admin generates
a new fresh communication key k(cid:2)
C and distributes it to all
remaining clients. Then the admin sends a removal request
with k(cid:2)
C to T , which uses the fresh key afterwards.
V. IMPLEMENTATION
The LCM protocol relies on our assumptions as described
in Sec. II and can be implemented with any TEE technolgy
such as Intel SGX.
A. Intel SGX
Intel’s Software Guard Extensions (SGX) [31] adds hard-
ware enforced security to the Intel CPU architecture. SGX
enables applications to execute certain code in a trusted exe-
cution context, also called enclave. Enclaves are isolated and
a hardware enforced mechanism guarantees the conﬁdentiality
and the integrity of an enclave even if the entire system is
compromised. Moreover, the SGX platform checks that an
application has not been tampered with when loading code and
data at initialization into an enclave. SGX offers an attestation
mechanism [1] for enclaves that allows to prove to a remote
third party that an enclave runs a given application on an
actual SGX platform. For utilizing the system’s persistent
storage and at the same time preserving data conﬁdentiality
and integrity, SGX supports data sealing. It permits to decrypt
sealed data only by the origin enclave or another enclave
by the same enclave developer. In the SGX programming
model, applications in an enclave are considered to be trusted
whereas all other applications (even the operating system)
are untrusted. Typically, those enclave applications are small,
hence, it is less likely to expose vulnerabilities. Using the SGX
Software Development Kit (SDK) [23], [22] enables devel-
opers to divide their applications into a trusted component
(enclave) and untrusted component. The trusted component
is signed by the developer. For bridging the trust border
between enclaves and untrusted components, SGX provides
the Enclave Deﬁnition Language (EDL) that is used by enclave
developers to specify an interface and generate “gateway” code
comprising Enclave calls (ecall) and Outside calls (ocall).
1) Enclave protection: SGX features two properties that
are essential to execute code securely in an enclave. First,
SGX veriﬁes that an enclave is instantiated with the correct
application. The enclave code contains an Enclave Signature
(SIGSTRUCT) produced by the enclave developer that allows
the SGX platform to detect whether the code of the enclave
has been tampered with. In particular, SIGSTRUCT comprises
an enclave measurement, a cryptographic hash that identiﬁes
the code and data, and the enclave developer’s public key,
that serves as the identity of the enclave developer. When the
enclave is loaded, the CPU calculates the enclave measurement
and compares it to the measurement in SIGSTRUCT; if they
match the enclave completes its instantiation successfully.
Second, SGX protects against any access and modiﬁcation
from untrusted components. To this end, the enclave resides in
an isolated memory area called enclave page cache (EPC) that
can not be accessed from outside an enclave. This is enforced
through a memory access control mechanism. The EPC size is
limited to 128 MB, thus, when enclave reaches that limit or a
context switch occurs, pages are moved to DRAM. A memory
encryption engine [19] protects pages when swapping between
EPC and DRAM in terms of conﬁdentially, integrity, as wells
provides replay attack prevention. Those two mechanisms
prevent any untrusted component from accessing or modifying
the enclave memory. Note that this mechanism only protects
the in-memory state but not persistent state of an enclave.
When an enclave is terminated, all in-memory state is lost.
2) Enclave attestation: SGX supports remote attestation [1]
that demonstrates to a remote client that an enclave runs a
given application inside an SGX platform and therefore can be
considered to be trustworthy. This is vital for establishing trust
in an enclave application and is required prior provisioning
any secrets or protected data. The remote attestation brieﬂy
works as follows: A remote client sends an challenge to the
enclave including a nonce. The enclave produces a report that
comprises some metadata including a short hash value of the
application code, the enclave developer identity, and additional
user data. The user data contains the nonce. Note that enclave
developers may also include custom values in the user data,
for instance, some information about the current enclave state.
Additionally, the report comprises a MAC that is produced
using a report key provided by the SGX platform. A special
enclave, so called Quoting enclave, receives the report and
validates it by using the same report key. The SGX platform
enforces that only enclaves are able to retrieve this report
key, thus, are able to create and verify report structures. If
the veriﬁcation succeeds, the Quoting enclave signs the report
with a platform speciﬁc key and replaces the MAC with the
signature. SGX leverages a group signature scheme (EPID [9])
that does not reveal the identity of the platform. In other words,
the signature states that some SGX platform has produces that
signature. The signed report (Quote) is sent to the remote client
which then validates signature (using a EPID infrastructure),
veriﬁes integrity of the attest, and ﬁnally checks that that the
Quote matches the challenge using the nonce.
3) Data sealing: Application code and data are secured
while residing within an enclave. However, when an enclave
is terminated the data is lost and can not be recovered when
the enclave restarts again. Therefore, SGX features a sealing
mechanism [23], [22] based on AES-GCM-128 that allows to
encrypt and authenticate data before it leaves an enclave by
using a special sealing key provided by the SGX platform.
164
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:47 UTC from IEEE Xplore.  Restrictions apply. 
In particular, SGX provides two types of sealing: An enclave
identity based sealing that only allows enclaves running the
same application to decrypt
the sealed data; and enclave
developer based sealing where all enclaves can decrypt sealed
data which are developed (signed) by the same developer.
B. LCM framework
We implemented LCM as a framework in Java and C++
consisting of a client-side and a server-side library that can
be integrated with SGX-enabled applications which require
rollback and fork detection for persistent state. We designed
the LCM framework in a modular and generic way that allows
us to reuse the protocol for various applications The LCM
client-library is implemented in Java and follows the descrip-
tion as presented in Alg. 1. It uses AES-GCM with 128-bit
keys provided by the Java Cryptography Extension to protect
the conﬁdentiality and integrity of all protocol messages. The
LCM client library uses a simple network interface including
methods for sending and receiving protocol message. This
allows to reuse an existing application network stack instead
of handling the communication with the server by our library.
The LCM server-side library is implemented in C++ using
the Intel SGX SDK (Version 1.6) [23]. It only utilizes trusted
libraries provided by the SGX SDK, such as libsgx_tcrypto
for cryptographic hashing and encryption. In particular, we
use SHA-256 for constructing the hash chain and AES-GCM
with 128-bit keys for encrypting the protocol messages, as well
as the protocol and application state. For persistently storing
the state encryption key we use the SGX sealing function.
We deﬁned two interfaces that must be implemented by the
enclave application. First, an operation processor, that receives
a client operation and returns the operation result; and second,
serialization interface that returns the application state as a
byte sequence. The implementation does not strictly follow the
Alg. 2 as presented in Sec. IV. That is, we optimized the code
in order to eliminate the ocall when storing the application
and protocol state at server’s persistent storage. Instead, we
piggyback the encrypted data together with the reply message.
Furthermore, we implemented operation batching mechanism
where the LCM protocol receives multiple invoke messages
with a single ecall. In contrast to Alg. 2, the application and
protocol state is stored once per batch. Our current proof of
concept does not make use of remote attestation. However, for
a deployment this can be extended using the mechanisms as
provided by the SGX SDK.
C. Building applications with LCM
In order to demonstrate our LCM framework we integrated
LCM with a simple persistent key-value store (KVS) running
in an enclave on a remote server. The prototype architecture is
shown in Fig. 3. Clients and the remote server communicating
via TCP socket connections. A KVS stores data objects
in a ﬂat namespace, where each object is identiﬁed by a
unique name or key. The KVS is implemented using trusted
libraries provided by the SGX SDK. In particular, we use
std::map for storing key-values pairs as strings of arbitrary
1
LCM client
KVS client
LCM client
KVS client
LCM client
KVS client
Request 
batching
Reply
2
5
k
r
o
w
e
N
t
Server application
Trusted execution context
3
LCM 
protocol
Key-value 
Store
4
6
Stable storage
Fig. 3.
protected with LCM.
The prototype architecture of an enclave based key-value store
length. The current version of the SGX SDK does not support
std::unordered_map which would be our ﬁrst choice due to
its constant access time.
Clients invoke GET, PUT and DEL operations through the
KVS client which instantiates the LCM client-library. A server