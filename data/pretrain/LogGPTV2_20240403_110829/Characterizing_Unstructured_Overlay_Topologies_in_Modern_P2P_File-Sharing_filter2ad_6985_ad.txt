surprising 60% of all paths having a length of 4. (ii) the
results from our snapshots are nearly identical; whereas
in [23], there is considerable variance from one crawl to an-
other. In summary, the path lengths have become shorter,
more homogeneous, and more stable.
Effect of Two-Tier Topology: To examine the effect of the
two-tier overlay topology on path length, we also plot the
path length between all peers (including leaves) in 7(b). If
each leaf had only one ultrapeer, the distribution of path
length between leaves would look just like the top-level
path lengths (Figure 7(a)), but right-shifted by two. How-
ever, since each leaf peer has multiple parents, the path
length distribution between leaves (and thus for all peers)
has a more subtle relationship with Figure 7(a). Comparing
Figures 7(a) and 7(b) shows us the cost introduced by using
a two-tier overlay. In the top-level, most paths are of length
4. Among leaves, we see that around 50% of paths are of
length 5 and the other 50% are of length 6. Thus, getting
to and from the top-level overlay introduces an increase of
1 to 2 overlay hops.
Eccentricity: The longest observed path in these four
snapshots was 12 hops, however the vast majority (99.5%)
of paths have a length of 5 hops or less. To further ex-
plore the longest paths in the topology, we examined the
distribution of eccentricity in the top-level overlay. The ec-
centricity of a peer is the distance from that peer to the
most distant other peer. More formally, given the func-
tion P (i, j) that returns the shortest path distance between
nodes i and j, the eccentricity, Ei of node i is deﬁned as
follows: Ei = max(P (i, j), ∀j). Figure 7(c) shows the
distribution of eccentricity in four topology snapshots. This
ﬁgure shows that the distribution of eccentricity is rather
homogeneous and low which is an indication that the over-
lay graph is a relatively balanced and well-connected mesh,
rather than a chain of multiple groups of peers.
4.3 Small World
Recent studies have shown that many biological and man-
made graphs (e.g., collaborations among actors, the electri-
cal grid, and the WWW graph) exhibit “small world” prop-
erties. In these graphs, the mean pairwise distance between
nodes is small and nodes are highly clustered compared to
random graphs with the same number of vertices and edges.
A study by Jovanovic et al. [12] in November–December
2000 concluded that the Gnutella network exhibits small
world properties as well. Our goal is to verify to what
extent recent top-level topologies of the Gnutella network
still exhibit small world properties despite growth in over-
Graph
New Gnutella
Old Gnutella
Movie Actors
Power Grid
C. Elegans
Lactual
4.17–4.23
3.30–4.42
3.65
18.7
2.65
Lrandom Cactual
3.75
3.66
2.99
12.4
2.25
0.018
0.02
0.79
0.08
0.28
Crandom
0.00038
0.002
0.00027
0.005
0.05
Table 3: Small World Characteristics
lay population, an increase in node degree, and changes
in overlay structure. The clustering coefﬁcient of a graph,
Cactual, represents how frequently each node’s neighbors
are also neighbors, and is deﬁned as follows [35]:
C(i) =
D(i)
Dmax(i)
, Cactual = Pi C(i)
|V |
D(i), Dmax(i) and |V | denote the number of edges be-
tween neighbors of node i, the maximum possible edges
between neighbors of node i, and the number of vertices in
the graph, respectively. For example, if node A has 3 neigh-
bors, they could have at most 3 edges between them, so
Dmax(A) = 3. If only two of them are connected together,
that’s one edge and we have D(A) = 1 and C(A) = 1
3 .
C(i) is not deﬁned for nodes with fewer than 2 neighbors.
Thus, we simply exclude these nodes from the computa-
tion of Cactual. Table 3 presents ranges for the clustering
coefﬁcient (Cactual) and mean path length (Lactual) for the
Gnutella snapshots from Table 1 as well as the mean values
from four random graphs with the same number of vertices
and edges (i.e., Crandom and Lrandom). Because comput-
ing the true mean path lengths (Lrandom) is computation-
ally expensive for large graphs, we used the mean of 500
sample paths selected uniformly at random. We also in-
clude the information presented by Jovanovic et al. [12]
and three classic small world graphs [35].
A graph is loosely identiﬁed as a small world when its
mean path length is close to random graphs with the same
number of edge and vertices, but its clustering coefﬁcient is
orders of magnitude larger than the corresponding random
graph (i.e., Lactual and Lrandom are close, but Cactual is
orders of magnitude larger than Crandom). All three classic
small world graphs in the table exhibit variants of these
conditions. Snapshots of modern Gnutella clearly satisfy
these conditions which means that modern Gnutella still
exhibits small world properties.
Comparing the clustering coefﬁcient between modern
Gnutella and old Gnutella shows that modern Gnutella has
less clustering. A plausible explanation is the increased
size, which provides the opportunity for more diverse con-
nectivity to other peers. A high clustering coefﬁcient im-
plies a larger fraction of redundant messages in ﬂood-based
querying. The observed clustering could be a result of fac-
tors like peer bootstrapping, the peer discovery mechanism,
and overlay dynamics. Further analysis is needed to better
USENIX Association
Internet Measurement Conference 2005  
57
t
s
e
g
r
a
l
n
i
s
e
d
o
n
)
%
(
t
n
e
n
o
p
m
o
c
g
n
i
n
i
a
m
e
R
d
e
t
c
e
n
n
o
c
100
90
80
70
60
50
40
30
20
10
0
0 10 20 30 40 50 60 70 80 90 100
Precentage of nodes removed
Figure 8: Fraction of remaining nodes in the largest con-
nected component as a function of the percentage of orig-
inal nodes removed for the 9/27, 10/11, and 10/18 snap-
shots. The top (overlapped) lines and the bottom three lines
present random and pathological node removal scenarios,
respectively.
understand the underlying causes. Section 5 shows how
peer churn is one factor that contributes to clustering.
4.4 Resilience
We also examine the resilience in different snapshots of the
Gnutella overlay topology using two different types of node
removal: (i) random removal, and (ii) pathologically re-
moving the highest-degree nodes ﬁrst. An early study [24]
conducted the same analysis on Gnutella based on a par-
tial topology snapshot, ﬁnding that the overlay is resilient
to random departures, but under pathological node removal
quickly becomes very fragmented (after removing just 4%
of nodes).
Figure 8 depicts the fraction of remaining nodes in the
topology which remain still connected in both the random
and pathological node removal. This ﬁgure clearly shows
the Gnutella overlay is not only extremely robust to random
peer removals, but it also exhibits high resilience to patho-
logical node removal. Even after removing 85% of peers
randomly, 90% of the remaining nodes are still connected.
For the pathological case, after removing the 50% of peers
with the highest-degree, 75% of the remaining nodes re-
main connected. There are two possible factors contribut-
ing to this difference with earlier results [24]: (i) the higher
median node degree of most nodes in modern Gnutella, and
(ii) a non-negligible number of missing nodes and edges in
the partial snapshot of the earlier study. Our result implies
that complex overlay construction algorithms (e.g., [36])
are not always a necessary prerequisite for ensuring re-
silience in unstructured overlays.
5 Overlay Dynamics
In Section 4, we characterized the graph-related properties
of individual snapshots of the overlay topology. However,
in practice the overlay topology is inherently dynamic since
connections (i.e., edges) are constantly changing. These
dynamics can signiﬁcantly affect the main functionality of
the overlay which is to provide connectivity and efﬁciently
route the messages (e.g., queries, responses) among par-
ticipating peers. Characterizing overlay dynamics enables
us to examine their impact on performance of P2P appli-
cations. For example, a query or response message can be
routed differently or even dropped as a result of changes in
the edges of the overlay. To our knowledge, aggregate dy-
namics of unstructured P2P overlay have not been studied.
There are two basic causes for observed dynamics in the
overlay topology as follows:
• Dynamics of Peer Participation: When a peer joins (or
departs) the network, it establishes (or tears down) its
connections to other participating peers in the overlay.
Therefore, these changes in overlay edges are user-
driven8.
• Dynamics of Neighbor Selection: Two existing peers
in the overlay may establish a new (or tear down an
existing) connection between them. Such a change in
edges is not triggered by users and thus considered
protocol-driven.
Note that the user-driven dynamics of peer participation
are likely to exhibit similar heavy-tailed distributions in dif-
ferent P2P applications [31, 28]. Therefore, characteriza-
tion of user-driven dynamics in the overlay provides a use-
ful insight for design of other Gnutella-like unstructured
P2P overlays.
In this section, we characterize the dynamics of the Gnu-
tella network. More speciﬁcally, we want to investigate (i)
whether a subset of participating peers form a relatively
stable core for the overlay, (ii) what properties (such as
size, diameter, degree of connectivity or clustering) this sta-
ble core exhibits, and (iii) what underlying factors con-
tribute to the formation and properties of such a stable
core.
Methodology: Our main goal is to determine whether ob-
served dynamics (i.e., the rate of change in the edges of
the overlay) are different at various regions of the overlay.
We primarily focus on the top-level overlay in our analysis,
because leaf nodes do not forward trafﬁc and therefore do
not provide meaningful connectivity between peers. One
key issue is to deﬁne a core region for the “spaghetti-like”
overlay. We use the following methodology to identify and
characterize any potentially stable core for the overlay. In-
tuitively, if the overlay has a stable core, it must contain the
long-lived peers of the overlay. Therefore, to identify the
stable core of the overlay at any point of time, we select
the subset of participating peers who have been part of the
overlay for at least τ minutes, i.e., all peers whose uptime
is longer than a threshold τ. We call this subset of peers
58
Internet Measurement Conference 2005
USENIX Association
h
t
i
w
s
r
e
e
p
)
%
(
x
t
s
a
e
l
l
e
v
e
l
-
p
o
T
t
a
e
m
i
t
p
u
10/16/04
10/22/04
11/26/04
12/23/04
12/29/04
100
80
60
40
20
0
h
t
i
w
s
r
e
e
p
)
%
(
x
t
s
a
e
l
l
e
v
e
l
-
p
o
T
t
a
e
m
i
t
p
u
100
80
60
40
20
0
10/16/04
10/22/04
11/26/04
12/23/04
12/29/04
)
%
(
g
n
i
r
e
t
s
u
l
C
d
e
s
a
e
r
c
n
I
10/16/04
10/22/04
11/26/04
12/23/04
12/29/04
100
80
60
40
20
0
0 5 10 15 20 25 30 35 40 45 50
0
20
40
60
80 100 120
(a) Percentage of top-level peers with uptime
Uptime (hours)
(b) Percentage of top-level peers with uptime
Uptime (minutes)
at least x
at least x (zoomed in)
0 5 10 15 20 25 30 35 40 45
Time in top level threshold (hours)
(c) Percentage of increased clustering among
stable nodes, relative to a randomized
topology for 5 different snapshots
Figure 9: Number of stable peers and their external connectivity for different τ
)
%
(
t
n
e
n
o
p
m
o
C
t
s
e
g
r
a
L
100
98
96
94
92
90
88
86
10/16/04
12/23/04
12/29/04
)
s
p
o
h
(
e
c
n
a
t
s
i
D
25
20
15
10
5