matching candidates than actual matches are possible. Since
all matched nodes in the output T1 and T2 of our tree diﬀer-
ence algorithm are colored blue, we can simply set the value
of this feature to 1 if the node is blue and 0 if it is not.
The motivation for this measure is that many web sites, for
example blogs, use templates when publishing a new article
or when showing a new comment, classiﬁed, or advertisement.
Detecting that a template is repeated allows us to model the
degree to which a web site has drifted away from expected
changes, e.g., in terms of character count distributions for a
blog with articles written in English.
4.2 Shannon Entropy
Second, we leverage the Shannon entropy as a feature of infor-
mation in a tag or an attribute’s value. Two diﬀerent features
are derived from the Shannon entropy: (a) the absolute Shan-
non entropy, which is dependent on the length of the string, (b)
the normalized Shannon entropy, i.e., the absolute Shannon
113
1 
2
3
4
5
6
7 
[...] foo [...]
Listing 1: Base version, source code.
1 
2
3
4
5
6
7
8 
Listing 2: Current version, source code.
[...] bar [...]
Figure 2: Comparison between a general tree diﬀerence algorithm and the fuzzy tree diﬀerence algorithm (section 3). Nodes
with a green diagonal stripes pattern denote nodes that were detected as inserted, while nodes with a red chessboard pattern
were detected as being removed.
entropy divided by the ideal Shannon entropy of a string of the
same length (i.e., it is normalized to the interval from 0 to 1).
Our intuition behind the Shannon entropy is to measure
the distance on how far the tag or attribute is away from a
random source. For instance, to model that the URL in a “src”
attribute of a  tag was generated by a random source.
4.3 Character Count
In the third set of features we employ a character count.
The ﬁrst feature in this set simply measures how often a single
character occurs in the tag or the attribute’s value and discrim-
inates between upper- and lower-case characters. The second
feature also measures how often a single character occurs,
however, it ignores capitalization and counts an “A” as an “a”.
The third feature follows in simplicity and is the count of each
digit. A fourth, ﬁfth and sixth feature are taking advantage of
the same method, but are performed on the fuzzy hash value
(ssdeep in our implementation) of the tag or attribute instead.
Beyond these six features, we are also computing relative
features for both of those two sets, as we did already in case of
the Shannon entropy. Alike to the Shannon entropy features,
the motivation behind these features is to model the character
and digit distribution in a string.
4.4 Kolmogorov Complexity
The third set of measures we introduce is based on an ap-
proximation of the upper-bound on the Kolmogorov complex-
ity [22]. Kolmogorov complexity denotes a complexity measure
specifying the lower-bound of text necessary to describe an-
other piece of text in an algorithmic way. One of the most
important properties of the complexity is its incomputability.
An upper-bound on the other hand is easy to compute by
taking the length of the text compressed by any lossless com-
pression algorithm. Since these features are based on a second
information theoretical measure, next to the Shannon entropy,
it is necessary to emphasize that they are complementary in
our scenario: on the one hand, Kolmogorov complexity is
conceptually diﬀerent from the Shannon entropy, and on the
other hand, we approximate the Kolmogorov complexity up
to (at best) an additive constant.
These measures exploit the upper-bound and the fact that
compressing already packed data results in nearly no beneﬁt, in
order to measure a change that introduces packed or encrypted
data, such as malicious data trying to evade detection.
We introduce, again, two diﬀerent features based on com-
puting an upper-bound of the Kolmogorov complexity. First,
the absolute upper-bound on the tag extracted by our tree
diﬀerence algorithm; second, the ratio of the upper-bound over
the length of the string. In case of very short strings, the upper-
bound might even take up more space than the actual string.
4.5 Script Inclusion
Scripts included in web sites are the most prominent way to
infect a user with malware, but they are also used legitimately.
Diﬀerences exist between how malicious scripts and legitimate
ones are used and included. For instance, malicious scripts
are rarely including local ﬁles; instead, they usually include
from an external source or provide the source code directly.
The following two binary features model these diﬀerences.
4.5.1 Absolute Source URL
The enduring rise of content-delivery networks, which are
often heavily relying on load-balancing based on the domain
name system (DNS), lead to scripts being included much more
often with an absolute and external source address in legiti-
mate cases than it was the case prior to the predominance of
these networks (due to potential compatibility issues if scripts
are included diﬀerently). It is important to understand if a
web site is hosted on a content-delivery network since it bears
the reasoning that these web sites are generally much more
optimized than personal web sites, to save on bandwidth on
account of the smaller size. This then has an impact on the
Base versionCurrent versionFuzzy TreeDifference(section 3)Standard Tree Differencevs.Tree Differencehtmlscriptheadpbodyhtmlpbodyhtmlscriptheadhtmlscriptheadpbodyp114importance of other features. This feature is also binary; it
is 1 for an absolute non-external source URL and 0 otherwise.
The many legitimate use cases of including scripts from
an absolute URL suggest that this feature will not have a
discriminatory impact on its own; rather, it supports other
features by modeling the inclusion-style in a web site. The
notion of a single inclusion-style roots in previous work by
Nikiforakis et al. [23], which suggests that web sites follow the
same inclusion patterns, i.e., the distribution of how scripts are
included is biased toward either relative or absolute inclusions,
and only rarely uniform.
4.5.2 External Source URL
While the last feature is a bias function to judge the use of
scripts with an absolute source, the next feature is a bias func-
tion for the concept of external source URLs. It is important
to mention that, if an external script is included, assuming
the external domain is maintained by a third party, then the
web site operator has to trust that the third party providing
the external script will not insert any malicious code.
4.6 Inline Frames
Similar to the features to model the use of script tags, the
following three binary features try to model the inclusion of
malicious inline frames, by looking into properties that are
uncommon for benign inclusions.
4.6.1 Absolute and External Source URL
Likewise to the nature of the source URL features for scripts,
these features give an intuition on the use of inline frames.
Both features are identical to their script sibling, but they
examine  tags instead of  tags.
Their motivation follows closely the motivation for the script
features: i.e., the feature for absolute source URLs is support-
ing other inline frame measures as a bias function. In the
past, inline frames with an external source address were often
used to include either advertisements or third party widgets.
Recently, those moved to inline JavaScript or embedding plu-
gins directly. Adversaries, on the other hand, still use these
frames because they allow for easier ﬁngerprinting and sup-
port delivering diﬀerent infection vectors per user, for example
depending on the browser’s patch-level, installed plugins, or
by obfuscating each reply diﬀerently. This ﬁne-grained con-
trol helps the adversary to maximize the attack eﬃcacy while
reducing the likelihood of detection.
4.6.2 Hidden Frame
Beyond absolute and external frames, another indicator
for malicious content being included exists: hidden frames.
Legitimate frames are generally made visible to the user. Ad-
versaries on the other hand prefer that the included web site
is invisible, which is why they often resort to setting width
and height of the frame to a low value, so that the frame is
visually hard to spot for a human. We investigated a random
sample of 10,000 inline frame tags that we extracted from our
dataset and found that legitimate inline frames are often set
to a width and height of larger than 100 and rarely hidden
(the style attribute “display: none” is rarely used). We model
this phenomenon, assuming that a majority of malicious inline
frames uses a much smaller area of screen space, by restricting
width and height of our feature to a maximum of 15 pixels.
The feature is simply 1 for hidden frames and 0 otherwise.
5 EVALUATION
Generally, the problem we are trying to solve is an instance
of knowledge discovery in databases [24, 25]. More precisely,
when searching actively for infection campaigns next to a
web crawler, we are interested in detecting outliers, i.e., novel
changes, and the appearance of clusters, i.e., when a new
trend is observed, for instance an infection campaign. While
various clustering algorithms can be employed, the design of
our system encourages the use of an algorithm that detects
local outliers. Additionally, the distribution of a cluster can
diﬀer from the distribution of any other cluster, particularly
for clusters with a low member count, i.e., it is not reasonable
to assume that all changes follow a very similar distribution
in the feature space. Since we are primarily interested in the
formation of new clusters, when it is even less likely that this
assumption will hold, centroid- or distribution-based clustering
algorithms such as k-means (which will give spherically shaped
clusters) or expectation-maximization (e.g., Gaussian mixture
models) are unlikely to provide any valuable insight on new
infection campaigns early enough. To counter this issue, we
adopt a variant of the density-based clustering algorithm OP-
TICS (Ordering Points To Identify the Clustering Structure,
by Ankerst et al. [26]), namely OPTICS-OF (OPTICS with
Outlier Factors) by Breunig et al. [27].
5.1 OPTICS-OF
The OPTICS-OF algorithm takes two parameters: the max-
imum distance for a cluster and the minimal number of vectors
necessary to form a cluster. In the scenario of trend analy-
sis, the maximum distance corresponds to the similarity of
a change, while the minimal number of vectors necessary de-
scribes the number of instances of a change we want to observe
before we consider it a trend, i.e., before we want to verify
that we found a previously-unknown infection campaign.
The algorithm works, in essence, as follows: if two vectors in
the feature space are closer than the maximum distance, then
they are directly density-reachable. If at least the minimal
number of vectors are directly density-reachable from a vector,
then this vector is a core object and forms a cluster. A cluster
does not only contain directly density-reachable vectors from
this core object, but is deﬁned transitively, i.e., it contains
all vectors that are directly and transitively density-reachable
from the core objects. Therefore, an outlier is either not
density-reachable to any other vector at all, or only density-
reachable to a number of vectors, where none of the vectors is
a core object, i.e., none of the vectors forms a cluster. In our
experiments, we require 10 similarity vectors that are directly
density-reachable to form a cluster.
5.2 Dataset
First, in this section, we describe in detail what constraints
we imposed on our dataset, why these constraints were im-
posed, and how we obtained our dataset. In general, it is a
challenging problem to obtain a representative sample of diﬀer-
ent and distinct malicious web sites. Invernizzi et al. [28] have
shown that this is even the case when only mediocre toxicity3
is required, i.e., it is even diﬃcult for a dataset with a small but
non-negligible percentage of malicious web sites. This poses a
problem for collecting our dataset because we desire moderate
toxicity and diversity among malicious infection vectors to
verify that we can correctly, and without bias, identify similar
trends, and by this, similar infection campaigns. Moreover, to
discard trivial cases, the requirements on the web sites in our
dataset are even more restrictive:
• Web sites must have been set-up for a legitimate reason,
i.e., we are interested in landing pages and not interested
3Toxicity measures the maliciousness of dataset and simply
corresponds to the fraction of malicious samples in a dataset
over all the samples of the dataset.
115Figure 3: Overview of the diﬀerence in time between base
and current version of a pair in the ﬁnal dataset.
in exploit pages. Exploit pages denote web sites that are
set up by an adversary to exclusively deliver malicious code,
while landing pages denote the infected legitimate page. We
enforce this restriction because recent work establishes that
legitimate web sites are nowadays the primary target and
because other approaches by Provos et al. [11, 14], Ratana-
worabhan et al. [29], Curtsinger et al. [30] or Seifert et
al. [31] are already able to detect purely malicious web sites
with outstanding accuracy.
• Two distinct versions of a web site are required, i.e., a web
sites must have been modiﬁed (legitimately or maliciously)
to constitute a realistic sample.
We obtained our dataset by crawling the web from January
2013 to May 2013 via a 10-node cluster of custom crawlers run-
ning an adaptive fetch schedule with a recrawl delay of at least
15 minutes and an exponential back-oﬀ delay (multiplied by a
constant factor of 10 if no change was observed in a recrawl and
with a strict maximum of one week). The hourly seed of URLs
for our crawler contained web sites that were already present in
our dataset and also Yandex’s search engines results for Twit-
ter’s trending topics. Additionally, to counter the problem of
low toxicity and prevent a bias toward benign web sites, we in-
jected a total of 2,979,942 URLs of web sites into our crawl seed
that the Wepawet online analyzer [12] had analyzed previously,
starting with samples observed in the beginning of January
2013 and ending with samples observed at the end of April
2013. In total, after removing exact duplicates and restricting
the number of pairs per unique URL to a maximum of 10, our
dataset spans a size of 700GiB and 26,459,103 distinct web site
pairs from 12,464,920 unique URLs. A distinct pair denotes
a pair where both versions are diﬀerent from each other in re-
spect to the SHA256 checksum of their normalized DOM tree.
The time diﬀerence, before a change between base and cur-
rent version of a web site was observed, is shown in Figure 3.
The average time diﬀerence of our pairs is 4 weeks, with 80%
of all pairs being 2 hours or more apart, 70% being 12 hours or
more apart, 60% being 7 days or more apart, and 50% being
20 days or more apart (median). Since not all web sites have
been recrawled after exactly 15 minutes, we can only observe
that a change happens in at least 16% of the web sites in a
15 minute interval after a visit.
5.3 Case Studies: Identiﬁed Trends/Clusters
In our experiments, we identiﬁed a total of 67,038 diﬀerent
clusters, with the majority of clusters having 30 or less elements.
Figure 4: Overview of the number of diﬀerent elements that
are in each cluster.
Figure 4 depicts the ﬁnal distribution of cluster sizes we ob-
served in our experiments. Evidently, the observed distribution
follows closely the power law function: y = 2014 · (x − 10)−1.8.