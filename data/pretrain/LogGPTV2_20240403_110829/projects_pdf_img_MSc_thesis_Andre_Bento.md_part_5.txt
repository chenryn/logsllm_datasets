### 2.2.3 Graph Database Tools

Graph databases (GDBs) have gained significant interest in recent years, driven by the increasing use of artificial intelligence and machine learning. However, the current state of GDBs is not entirely satisfactory, as evidenced by the limited offerings in the field.

The interest in graph databases has surged in recent years due to the rise of artificial intelligence and machine learning. Consequently, the available tools in this domain are still relatively limited. In the past, when social networks became popular, the development of graph databases accelerated, with many powerful technologies being developed in closed-source environments. For example, Facebook's TAO database, as shown in Table 2.3, was designed to support the entire social network. It stores users as nodes and their relationships as edges, providing very low latency. However, detailed information about this tool is scarce, with only a few scientific papers available [42], [43].

Among the available tools, ArangoDB stands out for its multi-data-type support, which allows for a wide range of data structures to be stored in nodes and edges. Additionally, it supports scalability through cluster deployment, although this feature is only available in the paid version. ArangoSmartGraphs storage improves the writing of graphs in distributed systems [44]. The main drawback of ArangoDB is the steep learning curve associated with AQL (Arango Query Language). This can be mitigated by using provided API clients, though at the cost of reduced control.

Neo4J is the most widely accepted GDB in the open-source community. Its popularity has grown in recent years due to its simplicity and ease of use [45]. However, Neo4J lacks support for scalability, meaning it can only run on a single machine. Some users have reported success in implementing horizontal scaling, but these claims are unverified [46].

Choosing a graph database can be challenging due to the rapid evolution of features and tooling support. The decision often hinges on the need for ease of use and horizontal scalability. ArangoDB is more suitable for large projects where the size of the graphs may exceed the capacity of a single machine. Conversely, Neo4J is better suited for simpler projects, such as functionality testing and prototyping, where graph storage is a secondary concern.

### 2.2.4 Time-Series Database Tools

This subsection covers tools for storing time-indexed series of values, which are essential for this research due to the close relationship between distributed tracing and time, as discussed in Subsections 2.1.3 and 2.1.5. Service dependency graphs, which represent the system at a given time, can also provide valuable monitoring information for microservice systems. For this purpose, Time Series Databases (TSDBs) are used to store time-series-based values.

A TSDB is defined as "a database optimized for time-stamped or time-series data like arrays of numbers indexed by time (a date-time or a date-time range)" [47]. These databases are natively implemented with specialized time-series algorithms to enhance performance and efficiency. They treat time as a discrete quantity rather than a continuous dimension, allowing for operations such as creating, enumerating, updating, organizing, and destroying various time-series entries in short access times.

The usage and popularity of TSDBs have grown due to the Internet of Things (IoT) trend. Discussions in this area have increased over the past few years and are expected to continue, driven by ubiquitous computing. TSDBs are particularly useful for storing and analyzing data from geographically spread sensors that gather information at specific points in time [48].

Table 2.4 compares two TSDBs: InfluxDB and OpenTSDB.

| **InfluxDB** [49] | **OpenTSDB** [50] |
|------------------|--------------------|
| **Description**  | An open-source time-series database written in Go, optimized for fast, high-availability storage and retrieval of time-series data in fields such as operations monitoring, application metrics, IoT sensor data, and real-time analytics. | A distributed and scalable TSDB written on top of HBase, designed to store, index, and serve metrics collected from computer systems (network gear, operating systems, and applications) at a large scale, making this data easily accessible and displayed. |
| **License**      | MIT                | GPL               |
| **Supported Languages** | Erlang, Go, Java, JavaScript, Lisp, Python, R, Scala | Erlang, Go, Java, Python, R, Ruby |
| **Pros**         | Scalable in the enterprise version; outstanding high performance; accepts data from HTTP, TCP, and UDP protocols; SQL-like query language; allows real-time analytics. | Massively scalable; excellent for large amounts of time-based events or logs; accepts data from HTTP and TCP protocols; good platform for future analytical research into particular aggregations on event/log data; completely free. |
| **Cons**         | High price tag for the enterprise version; clustering support only available in the enterprise version. | Hard to set up; not a good choice for general-purpose application data. |

Both InfluxDB and OpenTSDB are capable of scaling and accept HTTP and TCP transfer protocols. InfluxDB has an enterprise version with advanced features like clustering support, high availability, and scalability [51], while OpenTSDB offers these features for free. In terms of performance, InfluxDB generally outperforms OpenTSDB in benchmarks [52]. However, OpenTSDB is completely free and easier to set up, though it is more challenging to develop for.

Ultimately, the choice between these TSDBs depends on the required performance. If high performance and low-latency responses are needed, InfluxDB is the better option. If performance is less critical and cost is a concern, OpenTSDB is the preferred choice.

### 2.3 Related Work

This section presents related work in the field of distributed tracing data handling and analysis. It is divided into three subsections:

#### 2.3.1 Mastering AIOps

Distributed tracing has recently gained widespread acceptance in the industry, driven by new architectural and software engineering practices such as cloud-native, fine-grained systems, and agile methodologies. The complexity of web-scale distributed applications is a recent phenomenon, and as a result, there has been limited research in this field.

One recent trend is AIOps, the application of Artificial Intelligence to IT Operations, introduced in 2016 [54]. This trend aims to automate and enhance IT operations using AI. The key drivers of this revolution include:

- The difficulty of manually managing distributed infrastructures and system states.
- The increasing amount of data that needs to be retained, creating numerous challenges for operators.
- The growing distribution of infrastructure across geography and organizations, as seen in trends like cloud-first development and fog computing.
- The overwhelming number of new technologies and frameworks, making it difficult for operators to keep up.

Huawei's work, "Mastering AIOps with Deep Learning, Time-Series Analysis, and Distributed Tracing" [55], uses distributed tracing data and deep learning to detect anomalous traces. The method encodes traces and trains a neural network to identify significant differences. While this approach is effective, it is limited to classifying traces as normal or abnormal, lacking detailed interpretability.

#### 2.3.2 Anomaly Detection using Zipkin Tracing Data

Tooling in this field is not yet fully mature. Although distributed tracing tools are being used in production environments, they do not fully meet the needs of operators, leading to increased effort in monitoring large, complex architectures like microservices.

Salesforce conducted research using Zipkin to detect anomalies in a microservice-based system [56]. Zipkin is used for distributed tracing, collecting traces and providing performance insights. However, the current open-source version of Zipkin lacks in-depth performance analysis of span data.

The approach involved using Python AI packages to extract service dependency graph values, specifically the number of connections from each service. This allowed them to identify high-traffic areas in the network and potential bottlenecks. The findings were valuable for service networking architects, as services with many connections could become choking points if they fail.

The research concluded that Zipkin tracing data can identify network congestion, bottlenecks, and heat maps. However, the tool does not provide this level of analysis. Future work could include adding features like daily metrics, correlation between microservices load and latency, and alerts for identified bottlenecks or heat maps.

#### 2.3.3 Analysing Distributed Trace Data

Pinterest focused on researching latency problems in their microservices solution. With tens of services and hundreds of network calls per trace, the volume of trace data is overwhelming. Pinterest developed a closed-source tool called "Pintrace Trace Analyser" [57] to process trace data from Zipkin and detect latency issues.

The tool analyzes thousands of traces over extended periods, providing a holistic view of performance. The conclusions highlighted the need for better tooling to ease the life of operators, including automatic report generation and alerts for latency and call thresholds.

#### 2.3.4 Research Possible Directions

The related work indicates that there is limited research in this area, but the trend is expected to grow. Key research directions include:

- Focusing on the most important traces to reduce the volume of tracing.
- Developing new methods that leverage existing distributed tracing tools.
- Automating the detection of anomalies in distributed systems.

### Chapter 3: Research Objectives and Approach

This chapter details the problem, objectives, and approach of the research. Section 3.1 presents the research objectives, and Section 3.2 compiles and evaluates the research questions.

#### 3.1 Research Objectives

Modern distributed services are large, complex, and increasingly built upon other complex distributed services. Debugging such systems is challenging, involving the collection, interpretation, and display of information about interactions among concurrently executing processes. Distributed tracing data helps maintain a history of system activities.

End-to-end tracing captures causally-related activity within and among the components of a distributed system. As systems grow in scale and complexity, tracing becomes a critical tool for management tasks like diagnosis and resource accounting. However, the growth of tracing data poses new challenges, as it is used by system operators to manage and monitor the system.