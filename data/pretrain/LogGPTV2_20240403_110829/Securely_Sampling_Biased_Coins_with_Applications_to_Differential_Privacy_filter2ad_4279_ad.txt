is 1 diminishes at a doubly exponential rate, meaning κ will stay nearly constant as the number
of samples and privacy requirements grow. We note that sampling in this way implicitly makes
the noise an integer, meaning we are actually sampling from the geometric distribution. This is
ideal since geometric noise satisﬁes our diﬀerential privacy needs while avoiding the expensive
computation of the natural logarithm.
3.3 Converting One-Sided Noise to Two-Sided noise
In order to convert our one-sided geometric sample into a discrete Laplace sample we can use
the following procedure:
1: Let Geo(2/ε) be our one sided geometric distribution
2: procedure DiscreteLaplace(2/ε)
3:
(cid:46) ﬂip fair bit
(cid:46) positive noise if heads, negative if tails
(cid:46) if −0 is sampled, retry
x ← Geo(2/ε)
b ←next(1, coins)
s ← (2b − 1)x
if x = 0 ∧ b = 0 then
DiscreteLaplace(2/ε)
else
return s
4:
5:
6:
7:
8:
9:
end if
10:
11: end procedure
Note that no privacy is lost by leaking how many failures occur before a successful sample is
made since this the number of failures is independent of the noise sample. However, since stopping
early does not mesh with an MPC, one must now generate enough one-sided samples such that
the probability of not getting enough successes is negligible. When ε ≤ 1, the probability of failure
for a given one-sided sample (P [x = 0]/2) is less than 0.25, which means generating d two-sided
samples will need less than 1.5d one-sided samples for reasonable security and suﬃciently large d
(i.e. d = 220, 2−80 chance of failing to get d successes). While using two-sided noise does yield
higher accuracy on noisy counts, the need to release noisy counts at the end of report noisy max
is application dependent. Thus, we omit this procedure from our implementation.
3.4
Implementing Report-Noisy-Max
Using bitwise sampling from §3.2 and make-batch from §2, we can construct a secure
implementation of noisy max. We present the pseudocode below:
15
1: Let λ be the security parameter, ε be the DP parameter, and κ restrict our noise domain
to [0, 2κ)
2: Let p0, p1, . . . be the binary expansions (out to f bits, derived from ε) for the biased
coins needed to compute k bit noise, where k ≤ κ is derived from κ to optimize run time
3: Let cstack be the push-only stack of size g used for making batches of g coins, where g is
picked along with a small constant c to optimize run time
4: procedure MNMλ,ε,κ(u1, . . . , ud)
5:
for i = k to 0 do
(cid:46) ui = u(x, yi)
for j = 1 to d/g do
make-batch(c, g, pi)
s1, . . . , sg ←purge(cstack)
zg(j−1)+1, . . . , zgj ← zg(j−1)+1|s1, . . . , zgj|sg
end for
(cid:46) output coins
(cid:46) concat noise
(cid:46) sample zi corresponds to ui
6:
7:
8:
9:
10:
11:
end for
return max-idx(u1 + z1, . . . , ud + zd)
12:
13: end procedure
We note that the pseudocode for ODOλ,ε,κ, the algorithm that uses comparator circuits to
ﬂip all biased coins, follows directly from the bitwise sampling in §3.2 and the deﬁnition of noisy
max, so we do not provide it.
3.5 Complexity Theorems
We now present the following theorems which follow very simply from the make-batch
theorems:
Theorem 3.3. Let ε ∈ [0.001, 10] and the number of bits for all ui (potentially padded) be
constants, λ be as above, d be the number of choices, and κ = O(log(λ + log d)). Then the circuit
complexity of MNMλ,ε,κ with make-batch from §2.2 is O(d log2(λ + log d)).
Proof. Going forward, cost, complexity, and circuit complexity will all refer to the number of
non-XOR gates. First note that since each ui is the same ﬁxed number of bits, the addition and
max operations yield total complexity O(d) which will be dominated by the cost of sampling.
The only diﬀerence between sampling d times from Geo(2/ε) and producing d coins is that we
make d coins of the same bias k times instead of once. This does change the length of the bias
needed to maintain λ security, so we will address the eﬀect this has. We want the statistical
diﬀerence for κn biased coins to be less than 2−λ overall. This gives the following inequality for
f (bias length):
(1 − 2−f )κd ≥ 1 − 2−f κd = 1 − 2−f +log κ+log d ≥ 1 − 2−λ,
so f ≥ λ + log κ + log d =⇒ f = O(λ + log d). Part of the proof in §2.2 lets us conclude that the
cost per coin is thus O(log f ). We pick k such that the bias for the kth bit is the last non-zero
bias for f bits of precision. Choosing k this way makes it so full comparisons are only done for
the coins that are not all 0s in their expansions to f bits. From [DKM+06] we know that the
chance of bit j being 1 is 1/(1 + exp(2j−1ε)). Thus, k will be κ or the lowest integer such that
1/(1 + exp(2kε))  w, which is then used as the size of the ﬁnal
group.
5 Evaluation
The main contribution of this paper is the design of a new circuit family for sampling biased
coins that is suitable for use in secure computation protocols. To illustrate the beneﬁts of this
new design, we have implemented our new sampling schemes, the ODO sampling scheme, and
the report-noisy-max mechanism. The focus of the paper is not on secure computation, and
therefore we consider the simpler two-party honest-but curious model; our techniques, however,
apply equally to multi-party computation protocols that handle a variety of adversarial models.
Implementation Details. Our code can be found at https://www.gitlab.com/neucrypt/secure
ly sampling. We implemented and benchmarked both ODO and MNM, using Obliv-C [ZE15],
an extension of C that compiles and executes Yao’s Garbled Circuits protocols with many
protocol-level optimizations.
18
Benchmarks were performed using Ubuntu 18.04 with Linux kernel 4.18.0-1009-gcp 64-bit,
running on pairs of identical Google Cloud Instance n1-highcpu-4 instances. Code was compiled
using gcc version 8.2.0 (Ubuntu 8.2.0-7ubuntu1), with the -O3 -march=native ﬂags.
We evaluated performance in two network settings. In the ﬁrst network setting that mimics
a LAN setup, all instances ran in the same us-east1-b datacenter. Using iperf, we measured
the bandwidth between the pairs of instances to be 7.5 gigabits per second and the ping times to
be 0.4ms. The second network setting reﬂects a typical WAN in which one machine was in the
us-east1 datacenter while the others were in the us-west1 datacenter. Again using iperf, we
measured the bandwidth between the two instances to be 330 megabits per second. These two
network settings highlight the diﬀerence in network communication requirements between the
various algorithms.
Selection of parameters. Using our MNM sampler requires choosing the following parameters:
1. u: This parameter represents the number of pushes (cg as described above) needed to
produce g coins with a desired chance of failure. In our experiments for ε = 2−3 ln 2, δ = 2−60,
this parameter ranged from 1941 to 6947.
2. g: The primary batch size used to make all groups except for the remainder group (which
in some cases is still size g). In our experiments for ε = 2−3 ln 2, δ = 2−60, this parameter
ranged from 765 to 3069.
3. (cid:96): The length of the bias for a desired 2−λ statistical diﬀerence overall (f in the MNM
pseudocode). In our experiments for ε = 2−3 ln 2, δ = 2−60, this parameter ranged from 78
to 85.
4. v: This represents the number of pushes needed to produce q coins with the same desired
chance of failure as each of the batches of g. In our experiments for ε = 2−3 ln 2, δ = 2−60,
this parameter ranged from 1066 to 6947.
5. q: The remainder batch size, used as an optimization (to make as few extra coins as
possible). In our experiments for ε = 2−3 ln 2, δ = 2−60, this parameter ranged from 381 to
3069.
In choosing these parameters, we picked κ as in our diﬀerential privacy discussion thus letting
us solve for k as described in Theorem 3.3. Then we iterated over the choices for g, which are
3(2i) for i = 0, 1, 2, . . . , 15 (for i > 15, the cost per operation is too high compared to the minor
reduction of c). For each g, we found the minimum number of pushes needed to make
P[cg pushes yield < g coins] ≤ 2−(f−log g),
with f ≥ λ + log κ + log d. By taking d (mod g) we could easily deduce what the remainder
group would be, and the number of pushes needed for that to satisfy our desired overall chance
of failure. With this done, we calculated what the total concrete gate count would be for noisy
max based on our benchmarks of data structure operations and the cost of evaluating a log f bit
predicate using multiple eﬃcient 6-bit predicates. When doing this we ﬁrst compared whether
the pop-only stack or the predicate would be faster and chose the appropriate one. Finally, we
took the parameters that yielded the lowest estimated concrete gate count for noisy max.
19
5.1 Microbenchmarks of datastructures
In this section we present the gate complexity of our cpush, pop, and creset operations, as
well as the complexity of our predicate implementations for diﬀerent biases. To compute these,
we modiﬁed our Obliv-C implementation to report speciﬁc gate counts.
Complexity of push. Here we empirically measure the gate complexity of our cpush imple-
mentation. We consider stacks of size n = 3·2t bits and then apply n conditional cpush operations
while measuring the number of gates required for each operation. Figure 2 graphs the number of
gates for the ﬁrst 6141 operations as well the average number of gates for the ﬁrst i operations.
4,000
3,000
2,000