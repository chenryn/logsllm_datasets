Since TaintPipe’s data communication is lightweight,
TaintPipe can achieve nearly constant delay given
enough number of worker threads. The upper limit num-
ber of worker threads is also bounded, which equals
roughly the ratio of the taint analysis execution time over
the application thread execution time for each segment.
Due to TaintPipe’s pipelining design, it is possible that
TaintPipe may detect an attack some time after the real
68  24th USENIX Security Symposium 
USENIX Association
attack has happened. However, this trade-off does not
prevent TaintPipe from practically supporting a broad va-
riety of security applications, such as attack forensic in-
vestigation and post-fact intrusion detection, which do
not require strict runtime security enforcement.
It is
worth noting that different from ShadowReplica, Taint-
Pipe does not depend on extensive static analysis to re-
duce data communication. Therefore, TaintPipe has a
wider range of applications in speeding up analyzing ob-
fuscated binaries, as static analysis of obfuscated bina-
ries is of great challenge.
3 Design
3.1 Architecture
Figure 3 illustrates the architecture of TaintPipe. We
have built the pipelining framework on top of a dynamic
binary instrumentation tool, enabling TaintPipe to work
with unmodiﬁed program binaries. The steps followed
by TaintPipe for pipelining taint analysis are:
1. TaintPipe takes in a binary along with the taint seeds
as input. The instrumented application thread starts
execution with lightweight online logging for con-
trol ﬂow and other information (Section 4.1.1).
2. Then the instrumented program is executed together
with a multithreaded logging tool to efﬁciently de-
liver the logged data to memory (Section 4.1.2).
3. When the proﬁle buffer becomes full, a taint analy-
sis engine will be invoked for online pipelined taint
analysis (Section 4.2.1).
4. The generated log data are then used to construct
straight-line code, which helps to solve many pre-
cision loss problems in static taint analysis.
In
this stage, we generate a segment of executed code
blocks for each logged data buffer. The memory
addresses that are accessed through indirect jump
targets are also resolved (Section 4.2.2).
5. The taint analysis engine will further translate
straight-line code to taint operations, which avoid
precision loss and support both multi-tag and bit-
level taint analysis (Section 4.2.3).
6. With the constructed taint operations, TaintPipe per-
forms pipelined symbolic taint analysis. When a
thread ﬁnishes taint analysis with an explicit taint
state, it synchronizes with its following thread to re-
solve the symbolic taint state (Section 4.2.4).
3.2 Segmented Symbolic Taint Analysis
In this section, we analyze symbolic taint analysis from
a theoretical point of view to justify the correctness of
our pipelining scheme. In order to formalize segmented
symbolic taint analysis, we use the following notations:
1. Let σ denote a taint state, which maps variables to
their taint tags.
2. Let A (σ ,S) denote a symbolic taint analysis A on
a straight-line code segment S, with an initial taint
state σ. We use Aσ (S) for convenience.
Note that the straight-line code segment S has no con-
trol transfer statement. Conceptually, S only contains one
type of statements, namely assignment statements. Of
course, from the implementation point of view, there may
be other types of statements, but they can all be regarded
as assignment statements. For example, as we will show
in Section 4.2.3, our taint operations contain assignment
operations, laundering operations, and arithmetic opera-
tions. The latter two operations can be derived from taint
assignment operations.
Based on the semantics of assignment statements, we
deﬁne symbolic taint analysis for an assignment state-
ment as follows:
Aσ (x := e) =σ [x (cid:31)→ et ]
(1)
where et denotes the taint tag of e, and [·] is the taint state
update operator.
If x is a new variable, the taint state
σ is extended with a new mapping from x to its taint.
If x occurs in the taint state σ, for the variables in the
domain of σ whose symbolic taint expressions depend
on x, their symbolic taint expressions will be updated or
recomputed with the new taint value of x.
Assume σ1 = Aσ (i1) for a statement i, then the sym-
bolic taint analysis for two sequential statements i1;i2 is:
Aσ (i1;i2) =A σ1 (i2)
(2)
Assume straight-line code segment S1 = (i1;S(cid:28)1). We
can then deduce the symbolic taint analysis on two se-
quential segments S1;S2 as follows:
Aσ (S1;S2)
=Aσ ((i1;S(cid:28)1);S2)
=Aσ (i1; (S(cid:28)1;S2))
=···
=AAσ (S1)(S2)
(3)
That is, given Aσ (S1) =σ 1 and Aε (S2) =σ 2, where ε is
an empty taint state, Eq. 3 leads to:
Aσ (S1;S2) =σ 2[σ1]
(4)
USENIX Association  
24th USENIX Security Symposium  69
Instrumented 
Program 
Execution
Multithreaded 
Logging Tool
Logged 
Control Flow
Figure 3: Architecture.
Straight-line 
Code 
Construciton
Pipelined  
Symbolic Taint 
Analysis
Here, we misuse the taint state update operator [·] and
apply it to a taint state map, instead of a single taint vari-
able update. With Eq. 4, we can perform segmented taint
analysis in parallel or in a pipeline style. For two seg-
ments S1;S2, assume the starting taint state is σ0. We
start two threads, one compute Aσ0(S1) and the other
computes Aε (S2), where ε is an empty taint state. As-
sume the result of the ﬁrst thread analysis is σ1 and the
result of the second is σ2. The symbolic taint analysis of
S1;S2 is σ2[σ1], that is, the right hand side of Eq. 4. Eq. 4
forms the foundation of our segmented taint analysis in a
pipeline style.
4
Implementation
To demonstrate the efﬁcacy of TaintPipe, we have devel-
oped a prototype on top of the dynamic binary instru-
mentation framework Pin [23] (version 2.12) and the bi-
nary analysis platform BAP [5] (version 0.8). The on-
line logging and pipelining framework are implemented
as Pin tools, using about 3,100 lines of C/C++ code. The
taint operation constructors are built on BAP IL (inter-
mediate language). TaintPipe’s taint analysis engine is
based on BAP’s symbolic execution module, using about
4,400 lines of Ocaml and running concurrently with Pin
tools. We utilize Ocaml’s functor polymorphism so that
taint states can be instantiated in either concrete or sym-
bolic style. All of the functionality implemented in taint
analysis engine are wrapped as function calls. To sup-
port communication between Pin tools and taint analysis
engine, we develop a lightweight RPC interface so that
each worker thread can directly call Ocaml code. The
saving and loading of the taint cache lookup table is im-
plemented using the Ocaml Marshal API, which encodes
IL expressions as sequences of compact bytes and then
stores them in a disk ﬁle.
Dynamic binary instrumentation tools tend to inline
compact and branch-less code to the ﬁnal translated
code. For the code with conditional branches, DBI emits
a function call instead, which introduces additional over-
head. Therefore, we carefully design our instrumenta-
tion code to favor DBI’s code inlining. To fully reduce
online logging overhead, we also utilize Pin-speciﬁc
optimizations. We leverage Pin’s fast buffering APIs
for efﬁcient data buffering. For example, the inlined
INS InsertFillBuffer() writes the control ﬂow pro-
ﬁle directly to the given buffer; the callback function
registered in PIN DefineTraceBuffer() processes the
buffer when it becomes full or thread exits. Besides,
we force Pin to use the fastcall x86 calling convention
to avoid emitting stack-based parameter loading instruc-
tions (i.e., push and pop). Currently Pin-tools do not sup-
port the Pthreads library. Thus we employ Pin Thread
API to spawn multiple worker threads. We also im-
plement a counting semaphore based on Pin’s locking
primitives to assist thread synchronization. Addition-
ally, TaintPipe can be extended to support multithreaded
applications with no difﬁculty by assigning one taint
pipeline for each application thread.
4.1 Logging
TaintPipe’s pipeline stages consist of multiple threads.
The thread of instrumented application (producer) serves
as the source of pipeline, and a number of Pin inter-
nal threads act as worker threads to perform symbolic
taint analysis on the data collected from the applica-
tion thread. Note that unlike application threads, worker
threads are not JITed and therefore execute natively. One
of the major drawbacks of previous dynamic taint anal-
ysis decoupling approaches is the large amount of in-
formation collected in the application thread and the
high overhead of communication between the applica-
tion thread and analysis thread. To address these chal-
lenges, TaintPipe performs lightweight online logging to
record information required for pipelined taint analysis.
The logged data comprise control ﬂow proﬁle and the
concrete execution state when taint seeds are ﬁrst intro-
duced, which is the starting point of our pipelined taint
analysis. The initial execution state, consisting of con-
crete context of registers and memory, (e.g., CR0∼CR4,
EFLAGS and addresses of initial taint seeds), is used to
reduce the number of fresh symbolic taint variables.
We take major two steps to reduce the application
thread slowdown: First, we adopt a compact proﬁle
structure so that the proﬁle buffer contains logged data
as much as possible, and it is quite simple to recover
the entry address of each basic block as well. Second,
we apply the “one producer, multiple consumers” model
and N-way buffering scheme to process full buffers asyn-
chronously, which allows application to continue execu-
tion while pipelined taint analysis works in parallel. We
will discuss each step in the following sub-sections.
70  24th USENIX Security Symposium 
USENIX Association
4.1.1 Lightweight Online Logging
Besides the initial execution state when the taint seeds
are introduced, TaintPipe collects control ﬂow informa-
tion, which is represented as a sequence of basic blocks
executed. Conceptually, we can use a single bit to record
the direction of conditional jump [29], which leads to
a much more compact proﬁle. However, reconstruction
straight-line code from 1 bit proﬁle is more complicated
to make it ﬁt for ofﬂine analysis. Zhao et al. [47] pro-
posed Detailed Execution Proﬁle (DEP), a 2-byte proﬁle
structure to represent 4-byte basic block address on x86-
32 machine.
In DEP, a 4-byte address is divided into
two parts: H-tag for the 2 high bytes and L-tag for 2
low bytes. If two successive basic blocks have the same
H-tag, only L-tag of each basic block enters the proﬁle
buffer; otherwise a special tag 0x0000 followed by the
new H-tag will be logged into the buffer.
We extend DEP’s scheme to support REP-preﬁx in-
structions. A number of x86 instructions related to string
operations (e.g., MOVS, LODS) with REP-preﬁx are exe-
cuted repeatedly until the counter register (ecx) counts
down to 0. Dynamic binary instrumentation tools [23, 4]
normally treat a REP-preﬁxed instruction as an implicit
loop and generate a single instruction basic block in each
iteration. In our evaluation, there are several cases that
unrolling such REP-preﬁx instructions would be a perfor-
mance bottleneck. We address this problem by adding
additional escape tags to represent such implicit loops.
Figure 4 presents an example of the control ﬂow proﬁle
we adopted. The left part shows a segment of straight-
line code containing 1028 basic blocks, and 1024 out
of them are due to REP-preﬁxed instruction repetitions.
Our proﬁle (the right side of Figure 4) encodes such case
with two consecutive escape tags (0xffff), followed by
the number of iterations (0x0400).
We note that it is usually unnecessary to turn on the
logging all the time. For example, when application
starts executing, many functions are only used during
loading. At that time, no sensitive taint seed is intro-
duced. Therefore we perform on-demand logging to
record control ﬂow proﬁle when necessary. As applica-
tion starts running, we only instrument limited functions
to inspect the various input channels that taint could be
introduced into the application (taint seeds). Such taint
seeds include standard input, ﬁles and network I/O. Be-
sides, users can customize other values as taint seeds,
such as function return values or parameters. When the
pre-deﬁned taint seeds are triggered, we turn on the con-
trol ﬂow proﬁle logging. At the same time, we save the
current execution state to be used in the pipelined taint
analysis. Many well-known library functions have ex-
plicit semantics, which facilitates us to selectively turn
off logging inside these functions and propagate taint
0x804fff0
BB_1
0x804fffa
BB_2
0x8050004
BB_3
0x8050016
BB_4
rep movsd 
0x8050028
rep movsd 
... 
rep movsd 
0x8050030
BB_1028
4-byte tag 
profile
0xfff0
0xfffa
0x0000
0x0805
0x0004
0x0016
0xffff
0xffff
0x0400
0x0030
2-byte tag 
profile
Repetition 
Count: 1024
Figure 4: An example of 2-byte tag proﬁle.
correspondingly at function level. We will discuss this
issue further in Section 4.2.3.
4.1.2 N-way Buffering Scheme
Since TaintPipe’s online logging is lightweight, appli-
cation (producer) thread’s execution speed is typically
faster than the processing speed of worker threads.
To mitigate this bottleneck, we employed “one pro-
ducer, multiple consumers” model and N-way buffering
scheme [46]. At the center of our design is a thread pool,
which is subdivided into n linked buffers, and the pro-
ducer thread and multiple worker threads work on differ-
ent buffers simultaneously. More speciﬁcally, when the
instrumented application thread starts running, we ﬁrst
allocate n linked empty buffers (n > 1). At the same time,
n Pin internal threads (worker threads) are spawned.
Each worker thread is bound to one buffer and communi-
cates with the application thread via semaphores. When
a buffer becomes full, the application thread will release
the full buffer to its corresponding worker thread and
then continue to ﬁll in the next available empty buffer.
Given a full proﬁle buffers, a worker thread will send it to
a taint analysis engine to perform concrete/symbolic taint
analysis in parallel. After that, the worker thread will re-
lease the proﬁle buffer back to the application thread and
wait for processing the next full buffer.
It is apparent that the availability of unused worker
USENIX Association  
24th USENIX Security Symposium  71
threads and the size of proﬁle buffer will affect over-
all performance of TaintPipe (both application execution
time and pipelined taint analysis) signiﬁcantly. In Sec-
tion 5.1, we will conduct a series of experiments to ﬁnd
the optimal values for these two factors.
4.2 Symbolic Taint Analysis
4.2.1 Taint Analysis Engine
When the application thread releases a full proﬁle buffer,
a worker thread is waked up to capture the proﬁle buffer
and then communicates with a taint analysis engine for
pipelined taint analysis. The taint analysis engine will
ﬁrst convert the control ﬂow proﬁle to a segment of
straight-line intermediate language (IL) code and then
translates the IL code to even simpler taint logic oper-
ations. The translations are cached for efﬁciency at taint
basic block level. The key components of taint analysis
engine are illustrated in Figure 5.
The core of TaintPipe’s taint analysis engine is an ab-
stract taint analysis processor, which simulates a segment
of taint operations and updates the taint states accord-
ingly. The taint state structure contains two contexts: vir-
tual registers keeping track of symbolic taint tags for reg-
ister, and taint symbolic memory for symbolic taint tags
in memory. The taint symbolic memory design is like the
two-level page table structure and each page of memory
consists of symbolic taint formulas rather than concrete
values. After the initialization of the symbolic taint in-
puts, the engines perform taint analysis either concretely
or symbolically in a pipeline style.
4.2.2 Straight-line Code Construction
Given the control ﬂow proﬁles, recovering each basic
block’s H-tag and L-tag is quite straightforward. A basic
block’s entry address is the concatenation of its corre-
sponding H-tag and L-tag [47]. The taint analysis engine
should only execute the instructions required for taint
propagation. Otherwise, the work thread may run much
slower than the application thread. On the other side, due
to the cumbersome x86 ISA, precisely propagating taint
for the complex x86 instructions is an arduous work, es-
pecially for some instructions with side effect of condi-
tional taint (e.g., CMOV). To achieve these two goals, we
ﬁrst extract the x86 instructions sequence from the ap-
plication binary and then lift them to BIL [5], a RISC-
like intermediate language. Since we know exactly the
execution sequence, the sequence is a straight-line code.
We have removed all the direct and indirect control trans-
fer instructions and substituted them with control transfer
target assertion statements.
After resolving an indirect control transfer, we go one
step further to determine all the memory operation ad-
Figure 6: A path predicate constrains symbolic memory
access within the boundary of 7 < i < 10.
dresses which depend on this indirect control transfer tar-
get. For example, after we know the target of jmp eax,
we continue to trace the use-def chain of eax for each
memory load or store operation whose address is calcu-
lated through this eax. With the initial execution state
(containing addresses of taint seeds) and indirect control
transfer target resolving, we are able to decide most of
the memory operation addresses.
For some applications such as word processing, a sym-
bolic taint input may be used as a memory lookup index.
Without any constraint, a symbolic memory index could
point to any memory cell. Inspired by the index-based
memory model proposed by Cha et al. [8], we attempt to
narrow down the symbolic memory accesses to a small
range with symbolic taint states and path predicates. We
ﬁrst leverage value set analysis [2] to limit the range of
a symbolic memory access and then reﬁne the range by
querying a constraint solver. The path predicate along
the straight-line code usually limits the scope of sym-
bolic memory access. Figure 6 shows such an example