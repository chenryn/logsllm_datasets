title:Privacy and Integrity Preserving Computations with CRISP
author:Sylvain Chatel and
Apostolos Pyrgelis and
Juan Ram&apos;on Troncoso-Pastoriza and
Jean-Pierre Hubaux
Privacy and Integrity Preserving Computations 
with CRISP
Sylvain Chatel, Apostolos Pyrgelis, Juan Ramón Troncoso-Pastoriza, and 
Jean-Pierre Hubaux, EPFL
https://www.usenix.org/conference/usenixsecurity21/presentation/chatel
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.Privacy and Integrity Preserving Computations with CRISP
Sylvain Chatel
EPFL
Apostolos Pyrgelis
EPFL
Juan Ramón Troncoso-Pastoriza
EPFL
Jean-Pierre Hubaux
EPFL
Abstract
In the digital era, users share their personal data with service
providers to obtain some utility, e.g., access to high-quality
services. Yet, the induced information ﬂows raise privacy and
integrity concerns. Consequently, cautious users may want
to protect their privacy by minimizing the amount of infor-
mation they disclose to curious service providers. Service
providers are interested in verifying the integrity of the users’
data to improve their services and obtain useful knowledge
for their business. In this work, we present a generic solu-
tion to the trade-off between privacy, integrity, and utility,
by achieving authenticity veriﬁcation of data that has been
encrypted for ofﬂoading to service providers. Based on lattice-
based homomorphic encryption and commitments, as well
as zero-knowledge proofs, our construction enables a service
provider to process and reuse third-party signed data in a
privacy-friendly manner with integrity guarantees. We evalu-
ate our solution on different use cases such as smart-metering,
disease susceptibility, and location-based activity tracking,
thus showing its versatility. Our solution achieves broad gen-
erality, quantum-resistance, and relaxes some assumptions of
state-of-the-art solutions without affecting performance.
1 Introduction
In our inter-connected world, people share personal informa-
tion collected from various entities, networks, and ubiquitous
devices (i.e., data sources) with a variety of service providers,
in order to obtain access to services and applications. Such
data ﬂows, which typically involve a user, a data source, and
a service provider (as depicted in Figure 1), are common for
a wide range of use cases, e.g., smart metering, personalized
health, location-based activity tracking, dynamic road tolling,
business auditing, loyalty programs, and pay-as-you-drive in-
surance. However, due to conﬂicting interests of the involved
parties, such data interactions inherently introduce a trade-off
between privacy, integrity, and utility.
Some users seek to protect their privacy by minimizing the
amount of personal information that they disclose to curious
third-parties. Service providers are interested in maintaining
the value obtained from the users’ data. To this end, service
providers are concerned about verifying the integrity of the
data shared by their users, i.e., ensure that the user’s data has
been certiﬁed by a trusted, external, data source. Both parties
want to obtain some utility from these data ﬂows: Service
providers want to use the data for various computations that
yield useful knowledge for their business or services, and
users share part of their data to obtain services and applica-
tions. As users might not know upfront the number and details
of the computations, they wish to ofﬂoad their data once to
the service provider and be contacted only to authorize the
revelation of the result. Thus, in this work we present a solu-
tion that enables ﬂexible computations on third-party signed
data ofﬂoaded to a service provider in a privacy and integrity
preserving manner.
To illustrate the inherent trade-off between privacy, in-
tegrity, and utility, we detail some of the use cases:
Smart Metering. Smart meters (i.e., data sources) measure
the consumption of a user’s household. The data is shared with
a service provider (e.g., a different legal entity) for billing and
load-balancing analysis. A user’s privacy can be jeopardized
as energy consumption patterns can reveal her habits [27, 68].
The service provider wants guarantees on the data integrity to
provide reliable services [10]. Malicious users might cheat to
reduce their bills or disrupt the service provider’s analysis.
Disease Susceptibility. Medical centers and direct-to-
consumer services [3, 92], provide a user with her DNA se-
quence to improve her health and to customize her treatments.
Genomic data can be used for disease-susceptibility tests of-
fered by service providers, e.g., research institutions that seek
to form the appropriate cohorts for their studies. The user
wants to protect her data as DNA is considered a very sen-
sitive and immutable piece of information for her and her
relatives [45]. Correspondingly, service providers are keen
on collecting users’ data and verifying its integrity so that
they can use it for disease-risk estimation or other types of
analyses, e.g., drug-effect prediction or health certiﬁcates. Ma-
licious users might tamper with the genomic data they share
to disrupt this process and pass a medical examination.
USENIX Association
30th USENIX Security Symposium    2111
Location-Based Activity Tracking. A user’s wearable de-
vice monitors her location by querying location providers.
The user then shares this information with service providers,
e.g., online ﬁtness social networks [63] or insurance compa-
nies [2] to obtain activity certiﬁcates or discount coupons.
As location data can reveal sensitive information, e.g., her
home/work places or habits [61, 93], the user is concerned
about her privacy. Service providers want legitimate data to
issue activity certiﬁcates, provide discounts for performance
achievements, and build realistic user proﬁles. Malicious users
might be tempted to modify their data, aiming to claim fake
accomplishments and obtain beneﬁts they are not entitled to.
Figure 1: Three-party model and their interaction phases.
is
the private information authenticated with . The user pro-
. The service provider computes ψ(·) on the
tects it via
protected data and obtains an output which is revealed as m.
The above use cases fall under the three-party model of
Figure 1, with (i) malicious users, and (ii) honest-but-curious
service providers and data sources; as such, they exhibit the
trade-off between privacy, integrity, and utility. To support
integrity protection regarding users’ data, service providers
require a data source to certify it, e.g., by means of a digital
signature. This certiﬁcation should require minimal to no
changes to the data source: using only deployed hardware
and software infrastructure. Another common denominator is
that service providers want to collect users’ data and perform
various computations. Consequently, users should be able to
ofﬂoad their protected data to service providers (i.e., transfer
a copy of the data only once) in such a way that their privacy
is preserved, the data integrity can be veriﬁed, and various
ﬂexible computations are feasible.
A simple solution is to establish a direct communication
channel between the data source and the service provider. This
way, the data source could compute the operations queried by
the service provider on the user’s data. However, this would
prevent the user from remaining in control of her data and
require the data source to bear computations that are outside
of its interests. Another approach is to let the data source
certify the user’s data by using specialized digital signature
schemes such as homomorphic signatures [19, 24–26, 56] or
homomorphic authenticators [5, 48, 54, 87]. Thus, the user
could locally compute the queried operation and provide the
service provider with the result and a homomorphic signature
attesting its correct computation on her data. However, this
would require software modiﬁcations at the data source, which
would come at a prohibitive cost for existing services, and
introduce signiﬁcant overhead at the user.
In the existing literature, several works specialize in the
challenges imposed by the above use cases but provide only
partial solutions by either addressing privacy [12, 32, 40, 41,
71, 73], or integrity [20, 37, 83, 86]. The handful of works
addressing both challenges require signiﬁcant modiﬁcations
to existing hardware or software infrastructures. For instance,
SecureRun [85], which achieves privacy-preserving and cheat-
proof activity summaries, requires heavy modiﬁcations to the
network infrastructure. Similarly, smart metering solutions
using secure aggregation, e.g., [4, 74, 76], rely on specialized
signature schemes that are not yet widely supported by current
smart meters. These approaches are tailored to their use case
and cannot be easily adapted to others, hence there is the need
for a generic solution to the trade-off between privacy and
integrity, without signiﬁcantly degrading utility.
ADSNARK [13] is a generic construction that could be
employed to address the trade-off between privacy, integrity,
and utility. In particular, it enables users to locally compute on
data certiﬁed by data sources and to provide proof of correct
computation to service providers. However, ADSNARK does
not support the feature of data ofﬂoading that enables service
providers to reuse the collected data and to perform various
computations. Indeed, ADSNARK and other zero-knowledge
solutions [17,49,50], require the user to compute a new proof
every time the service provider needs the result of a new com-
putation. Furthermore, it requires a trusted setup, and is not
secure in the presence of quantum adversaries [66]. The latter
should be taken into account considering recent advances in
quantum computing [9] and the long term sensitivity of some
data.
In this work we propose CRISP (privaCy and integRIty pre-
Serving comPutations), a novel solution that achieves utility,
privacy, and integrity; it is generic, supports data ofﬂoading
with minimal modiﬁcation to existing infrastructures, relaxes
the need for a trusted setup, and is quantum-resistant. Mo-
tivated by the need to protect users’ privacy and by the of-
ﬂoading requirement to support multiple computations on
their data, CRISP relies on quantum-resistant lattice-based
approximate homomorphic encryption (HE) primitives [35]
that support ﬂexible polynomial computations on encrypted
data without degrading utility. To ensure data integrity, we
employ lattice-based commitments [15] and zero-knowledge
proofs [29] based on the multi-party-computation-in-the-head
(or MPC-in-the-head) paradigm [64], which enable users to
simultaneously convince service providers about the correct-
ness of the encrypted data, as well as the authenticity of the
underlying plaintext data, using the deployed certiﬁcation
mechanism.
We evaluate our solution on three use cases covering a wide
range of applications and computations: smart metering, dis-
ease susceptibility, and location-based activity-tracking. Our
2112    30th USENIX Security Symposium
USENIX Association
Service ProviderUserData SourceHonest-but-curiousHonest-but-curiousMalicious but rationalmmmCOMPUTATIONCOLLECTIONTRANSFERVERIFICATIONDATA RELEASEΨ(       )=mexperimental results show that our construction introduces ac-
ceptable computation overhead for users to privately ofﬂoad
their data and for service providers to both verify its authentic-
ity and to perform the desired computations. The magnitude
of the communication overhead ﬂuctuates between tens and
hundreds of mega bytes per proof and is highly dependent
on the use case and its security requirements. To this end, in
Section 6, we also present different optimizations that can
reduce the proof size, thus making our construction practi-
cal for real-life scenarios. Additionally, we demonstrate that
CRISP achieves high accuracy in the computations required
by the use cases, yielding an average absolute accuracy of
more than 99.99% over the respective datasets. Compared to
the state of the art [13], we reach comparable performance
and achieve post-quantum security guarantees with more ﬂex-
ibility in the computations.
Our contributions are the following:
• A generic, quantum-resistant solution that enables pri-
vacy and integrity preserving computations in the three-
party model of Figure 1, with minimal modiﬁcations of
the existing infrastructure;
• the necessary primitives to achieve authenticity veriﬁca-
tion of homomorphically encrypted data in the quantum
random oracle model;
• an implementation of CRISP [72] and its performance
evaluation on various representative use cases that
rely on different types of computations and real-world
datasets.
To the best of our knowledge, it is the ﬁrst time such a solution
is proposed.
This paper is organized as follows: In Section 2, we discuss
the system and threat model on which our construction oper-
ates. In Section 3, we introduce useful cryptographic prim-
itives. Then, we present CRISP’s architecture in Section 4
and in Section 5 we perform its privacy and security analysis.
In Section 6, we evaluate CRISP on various use cases and
in Section 7 we discuss some of its aspects. We review the
related work in Section 8 and conclude in Section 9.
2 Model
We describe the model, assumptions, and objectives of CRISP.
2.1 System Model
We consider three entities: a user, a service provider, and a
data source, as depicted in Figure 1. The user obtains from the
data source certiﬁed data about herself and/or her activities,
she subsequently shares it with the service provider to obtain
some service. The user is interested in sharing (i.e., ofﬂoad-
ing) her data while protecting her privacy, i.e., she wants to
have full control over it but still obtain utility from the service
provider. The service provider is interested in (i) verifying
the authenticity of the user’s data, and (ii) performing on it
multiple computations that are required to provide the service
and/or improve its quality. The data source can tolerate only
minimal changes to its operational process and cannot cope
with any heavy modiﬁcation to the underlying infrastructure
and dependencies of the hardware and software. Finally, we
assume the existence of a public key infrastructure that ver-
iﬁes the identities of the involved parties as well as secure
communication channels between the user and the data source,
and between the user and the service provider.
2.2 Threat Model
We present the assumed adversarial behavior for the three en-
tities of our model with computationally bounded adversaries.
Data Source. The data source is considered honest and is
trusted to generate valid authenticated data about the users’
attributes or activities.
Service Provider. The service provider is considered honest-
but-curious, i.e., it abides by the protocol and does not engage
in denial-of-service attacks. However, it might try to infer
as much information as possible from the user’s data and
perform computations on it without the user’s consent.
User. We consider a malicious but rational user. In other
words, she engages in the protocol and will try to cheat only
if she believes that she will not get caught – and hence be
identiﬁed and banned – by the service provider. This type of
adversary is also referred to as covert in the literature [11].
The user is malicious in that she might try to modify her data,
on input or output of the data exchange, in order to inﬂuence
the outcome of the service provider’s computations to her
advantage. Nonetheless, the user is rational, as she desires to
obtain utility from the service provider and thus engages in
the protocol.
2.3 Objectives
Overall, the main objective of our construction is to provide
the necessary building blocks for secure and ﬂexible com-
putations in the considered three-party model. To this end,
user’s privacy should be protected by keeping her in control