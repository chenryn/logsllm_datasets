title:The power of procrastination: detection and mitigation of execution-stalling
malicious code
author:Clemens Kolbitsch and
Engin Kirda and
Christopher Kruegel
The Power of Procrastination: Detection and
Mitigation of Execution-Stalling Malicious Code
Clemens Kolbitsch
Vienna University of
Technology
Vienna, Austria
PI:EMAIL
Engin Kirda
Northeastern University
Boston, MA, USA
PI:EMAIL
Christopher Kruegel
UC Santa Barbara
Santa Barbara, CA, USA
PI:EMAIL
Abstract
Malware continues to remain one of the most important security
problems on the Internet today. Whenever an anti-malware solu-
tion becomes popular, malware authors typically react promptly
and modify their programs to evade defense mechanisms. For ex-
ample, recently, malware authors have increasingly started to create
malicious code that can evade dynamic analysis.
One recent form of evasion against dynamic analysis systems is
stalling code. Stalling code is typically executed before any mali-
cious behavior. The attacker’s aim is to delay the execution of the
malicious activity long enough so that an automated dynamic anal-
ysis system fails to extract the interesting malicious behavior. This
paper presents the ﬁrst approach to detect and mitigate malicious
stalling code, and to ensure forward progress within the amount of
time allocated for the analysis of a sample. Experimental results
show that our system, called HASTEN, works well in practice, and
that it is able to detect additional malicious behavior in real-world
malware samples.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection
General Terms
Security
Keywords
Malware Analysis, Evasion, Emulation
1.
INTRODUCTION
Malicious software (malware) is the driving force behind many
security problems on the web. For example, a large fraction of the
world’s email spam is sent by botnets [16], Trojan programs steal
account credentials for online banking sites [27], and malware pro-
grams participate in click fraud campaigns and distributed denial of
service attacks [15].
Malware research is an arms race. As new anti-malware solu-
tions are introduced, attackers are updating their malicious code to
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’11, October 17–21, 2011, Chicago, Illinois, USA.
Copyright 2011 ACM 978-1-4503-0948-6/11/10 ...$10.00.
evade analysis and detection. For example, when signature-based
anti-virus scanners became widely adopted, attackers started to use
code obfuscation and encryption to thwart detection. As a conse-
quence, researchers and security vendors shifted to techniques that
focus on the runtime (dynamic) behavior of malware.
An important enabler for behavior-based malware detection are
dynamic analysis systems (such as ANUBIS [2], CW-SANDBOX [3],
NORMAN SANDBOX [4], and TEMU [25]). These systems exe-
cute a captured malware program in a controlled environment and
record its actions (such as system calls, API calls, and network
trafﬁc). Based on the collected information, one can decide on
the malicious nature of a program, prioritize manual analysis ef-
forts [8], and automatically derive models that capture malware
behaviors [14, 19]. Such models can then be deployed to protect
end-users’ machines.
As dynamic analysis systems have become more popular, mal-
ware authors have responded by devising techniques to ensure that
their programs do not reveal any malicious activity when executed
in such an automated analysis environment. Clearly, when malware
does not show any unwanted activity during analysis, no detection
models can be extracted. For anti-malware researchers, these eva-
sion attempts pose a signiﬁcant problem in practice.
A common approach to thwart dynamic analysis is to identify the
environment in which samples are executed. To this end, a malware
program uses checks (so-called red pills) to determine whether it is
being executed in a virtual machine [13, 24] or a system emulator
such as Qemu [20, 22, 23]. Whenever a malware program is able to
detect that it is running inside such an environment, it can simply
exit.
Reacting to the evasive checks (red pills), researchers have pro-
posed more transparent analysis environments [11, 12]. Another
approach has focused on the detection of differences between the
execution of a program in a virtual platform and on real hard-
ware [6, 17]. When such a discrepancy is identiﬁed, the checks
responsible for the difference can be removed. Finally, systems that
perform multi-path exploration [9, 21] or that identify “malicious
triggers” [10] can detect and bypass checks that guard malicious
activity.
In the next step of the arms race, malware authors have begun to
introduce stalling code into their malicious programs. This stalling
code is executed before any malicious behavior – regardless of the
execution environment. The purpose of such evasive code is to
delay the execution of malicious activity long enough so that auto-
mated analysis systems give up on a sample, incorrectly assuming
that the program is non-functional, or does not execute any action
of interest. It is important to observe that the problem of stalling
code affects all analysis systems, even those that are fully transpar-
ent. Moreover, stalling code does not have to perform any checks.
285Thus, systems that aim to detect malware triggers or that explore
multiple execution paths do not reveal any additional behaviors.
With stalling code, attackers exploit two common properties of
automated malware analysis systems: First, the time that a sys-
tem can spend to execute a single sample is limited. Typically, an
automated malware analysis system will terminate the analysis of
a sample after several minutes. This is because the system has to
make a trade-off between the information that can be obtained from
a single sample, and the total number of samples that can be ana-
lyzed every day. Second, malware authors can craft their code so
that the execution takes much longer inside the analysis environ-
ment than on an actual victim host. Thus, even though a sample
might stall and not execute any malicious activity in an analysis
environment for a long time (many minutes), the delay perceived
on the victim host is only a few seconds. This is important because
malware authors consider delays on a victim’s machine as risky.
The reason is that the malicious process is more likely to be de-
tected or terminated by anti-virus software, an attentive user, or a
system reboot.
In this paper, we present the ﬁrst approach to detect and evade
malicious stalling code, and to ensure forward progress within the
amount of time allocated for the analysis of a sample. To this end,
we introduce techniques to detect when a malware sample is not
making sufﬁcient progress during analysis. When such a situation
is encountered, our system automatically examines the sample to
identify the code regions that are likely responsible for stalling the
execution. For these code regions (and these regions only), costly
logging is disabled. When this is not sufﬁcient, we force the ex-
ecution to take a path that skips (exits) the previously-identiﬁed
stalling code.
We implemented our approach in HASTEN, an extension for ANU-
BIS, our dynamic analysis system. Our experimental evaluation
shows that HASTEN is effective in practice and can reveal addi-
tional behavior in real-world malware.
This paper makes the following contributions:
• We present the ﬁrst approach to detect and deal with mali-
cious stalling code in real-world malware, and to ensure for-
ward progress within the amount of time allocated for the
analysis of a malware sample.
• We propose HASTEN, a dynamic analysis system extension
to detect and passively mitigate the impact of stalling code.
To this end, we identify stalling code regions and execute
them with reduced logging.
• We introduce an active extension to HASTEN that forces the
execution of the malware to take a path that skips the previously-
identiﬁed stalling code. This helps in cases where reduced
logging is not sufﬁcient.
2. PROBLEM DESCRIPTION
In this section, we discuss the problem of stalling code in more
detail, and we show a real-world code example that implements
such a mechanism.
2.1 Deﬁnition
We deﬁne a stalling code region as a sequence of instructions
that fulﬁlls two properties: First, the sequence of instructions runs
considerably slower inside the analysis environment than on a real
(native) host.
In this context, “considerably slower” means that
the slowdown is large compared to the average slowdown that the
sandbox incurs for normal, benign programs. Examples of slow
1 unsigned count, t;
2
3 void helper() {
4
5
6
7
8 }
t = GetTickCount();
t++;
t++;
t = GetTickCount();
count=0x1;
do {
9 void delay() {
10
11
12
13
14
15
16 }
helper();
count++;
} while
(count!=0xe4e1c1);
Figure 1: Stalling code in W32.DelfInj
operations are system call invocations (because of additional log-
ging overhead) and machine instructions that are particularly costly
to emulate (e.g., ﬂoating point operations or MMX code).
The second property of stalling code is that its entire execution
must take a non-negligible amount of time. Here, non-negligible
has to be put into relation with the total time allocated for the auto-
mated analysis of a program. For example, for a dynamic analysis
system, this could be in the order of a few minutes. Thus, we expect
the stalling code to run for at least several seconds. Otherwise, the
analysis results would not be signiﬁcantly affected. That is, when
an instruction sequence ﬁnishes within a few milliseconds instead
of microseconds, we do not consider this as stalling code.
Clearly, an attacker could create stalling code that stalls execu-
tion on the real host in the same way it does in the analysis environ-
ment. For example, the attacker could use sleep calls, or create high
amounts of activity to delay execution. However, in practice, exe-
cution delays using sleep-like functions can be easily skipped, and
delaying execution (for example, by raising the volume of activ-
ity) increases chances of being detected and terminated on a victim
host.
Intuitively, our deﬁnitions imply that stalling code contains “slow”
operations (to satisfy the ﬁrst property), and that these operations
are repeated many times (to satisfy the second property). As a re-
sult, attackers typically implement stalling code as loops that con-
tain slow operations (and we will sometimes refer to stalling code
as stalling loops in this paper).
2.2 Example of Stalling Code
Figure 1 shows a stalling loop implemented by real-world mal-
ware. This code was taken from a sample that was ﬁrst submitted
to the Anubis analysis system in February 2010. As the sample was
only available in binary format, we reverse engineered the malware
program and manually produced equivalent C code. Since the ex-
ecutable did not contain symbol information, we introduced names
for variables and functions to make the code more readable. To
determine the malware family that this sample belongs to, we sub-
mitted it to the popular VirusTotal service. VirusTotal uses around
40 anti-virus (AV) tools to scan each uploaded sample. All 40 AV
scanners considered the ﬁle to be malicious, and most tools labeled
our sample as Trojan Win32.DelfInj.
As can be seen in Figure 1, the code contains a number of un-
necessary calculations involving the return value of the Windows
GetTickCount function. According to documentation provided
by Microsoft [5], GetTickCount “retrieves the number of mil-
liseconds that have elapsed since the system was started, up to 49.7
days.” It is typically used to measure the time that elapses between
two events. In this scenario, however, the repeated invocations are
not useful. In fact, the value of the variable tick is simply over-
written by subsequent calls to GetTickCount. Moreover, this
loop is executed 15 million times. This strongly supports the intu-
ition that the purpose of this code is to stall execution.
When the code shown in Figure 1 is run natively on a real pro-
cessor, the loop executes and terminates in a matter of milliseconds.
2861 // H4X0r: make sure delay loop was not interrupted
2 void check() {
3
4 }
if (count!=0xe4e1c1) exit();
Figure 3: Malware code to check that the delay loop has not
been interrupted.
many times. Thus, as a ﬁrst step, HASTEN attempts to identify
the code region that is repeatedly executed. To this end, our sys-
tem starts to dynamically record information about the addresses
of instructions (code blocks) that are executed. Using these ad-
dresses, we build a (partial) control ﬂow graph (CFG) of the non-
progressing thread. This CFG is then searched for loops.
Intuitively, the code that is identiﬁed by this process represents
the stalling loop(s). For example, in the code snippet in Figure 1,
our tool would identify the do-while loop in the delay function
(Line 11-15). The stalling code region would also include the
helper function (L. 3-8), since it is invoked inside the body of
the loop (L. 12). Note that our system uses inter-procedural con-
trol ﬂow analysis for loop detection. This allows us to handle cases
in which a loop is not part of a single function, but the result of
recursive function calls.
Once the stalling loop is identiﬁed, HASTEN adapts its analysis
for this code region. More precisely, we ﬁrst whitelist the code
that is part of the stalling region. Note that this whitelist covers
only those instructions (basic blocks) that have been executed pre-
viously by the malware. Thus, parts of a stalling loop that have
not been executed before are not whitelisted. In the next step, the
system limits (or turns off) detailed malware introspection for the
whitelisted code regions. This approach signiﬁcantly reduces (or
removes) the overhead that is introduced by the analysis environ-
ment.
The passive mode is called “passive” because we do not interfere
with the malware execution; we only modify the analysis environ-
ment to accelerate stalling loops.
Active mode. When HASTEN operates in active mode, it actively
interferes with the execution of the binary. In particular, the tool at-
tempts to force a stalling loop to exit (or, more precisely, to follow
a code path that exits the whitelisted region that the previous analy-
sis has identiﬁed; this might force execution into parts of a stalling
loop that have not yet been executed). To this end, our system uses
the previously-constructed CFG and identiﬁes all nodes associated
with conditional jumps that are (i) part of the stalling loop and that
(ii) have one successor node that is not part of the whitelisted code
region. That is, we identify all nodes through which there exists a
path that exits the stalling code. At the next loop iteration, when
such a conditional jump is encountered, HASTEN ﬂips the check
that this instruction implements (e.g., a less-than would be con-
verted into a greater-or-equal). Hence, the thread is forced to con-
tinue execution along a path outside the stalling region.
Altering the ﬂow of execution of a program (such as prema-
turely preempting a loop or following an “unexplored” path within
the loop) can leave this program in an inconsistent state. Refer-
ring back to our example in Figure 1, one can see that the variable
count will not have the expected value (0xe4e1c1) when HAS-
TEN forces the loop to exit. This might be irrelevant, but at the
same time, there is a possibility that it could also lead to program
crashes. Malware authors could leverage these inconsistencies to
expose the analysis system. For example, consider an attacker that
calls check, shown in Figure 3, after the delay function (from
Figure 1). If our system would preempt the loop, this comparison