## 论文的核心方法 {#143.html#-}了解了这篇论文的大体思路以后，我们现在来看看论文的第一个核心部件：**如何利用深度神经网络来提取图片的美感信息？**``{=html}首先，这篇论文提出的模型假设对于每一个商品，我们都有一个**综合的美感标签**，并且还有一个**细节标签**来表达这个商品图案的"**图像风格**"（Style）。美感的综合标签是一个1\~10的打分，而图像风格则是文字的图像特征，比如"高曝光"、"对比色"等。那么，我们需要一个神经网络模型，来同时对美感标签和细节的图像风格进行建模。具体来说，文章提出的模型分为了两个层次。第一个层次是用来解释细节的图像风格。在本文采用的数据中，一共有14 种图像风格，作者们就用了 14 个**子网络**（SubNetwork）来针对这些风格。每个风格都对应一个独立的**子神经网络**。每一个子神经网络都是标准的"**卷积网络**"（CNN）。他们的目标是尽可能地学习到特性来表示每个细节的图像风格。当我们有了第一层的 14个子网络之后，再把这些子网络学习到的特性都整合起来，形成**中间特性层**，然后再经过一个卷积网络，从而学习到一个对商品的整体美感评分进行解释的神经网络。在文章中，作者们提到这两个层次的神经网络并不是分类进行训练的，而是**在一个整体中进行训练**。意思就是说，我们同时训练底层的针对图像风格的14 个子网络的参数，以及高层次的针对美感评分的网络的参数。当我们得到了图片的美感信息之后，下一步，就来看一下**如何利用张量分解来进行商品推荐**。相比于传统的张量分解，在这篇文章中，作者们提出了一种新颖的，针对商品推荐的张量表达模式，叫作"动态协同过滤"（DynamicCollaborative Filtering），或简称 **DCF**。DCF认为，每一个用户对于某个商品的购买取决于两个方面的因素。第一，用户是否对这个商品有喜好。第二，这个商品是不是符合时间维度上面的"流行度"。作者们认为，只有当这两个条件同时满足的时候，也就是用户喜欢某个当季的商品时才会做出购买的决定。因此，作者们使用了**两个矩阵分解**来分别代表这两个假设。第一个矩阵分解是针对用户和商品这个矩阵，这里我们会学习到用户对商品的**喜好度**。第二个矩阵分解是针对时间和商品这个矩阵，这里我们会学习到时间和商品的**流行度**。然后，作者把这两个矩阵分解（或者说是把两个矩阵）相乘，这就得到了一个张量，来表达**用户在时间维度上对商品的喜好**。那么，如何把刚才学习到的图片美感信息给融入到这个新的张量学习框架下呢？作者们是这么做的，针对我们刚才所说的两个矩阵分解进行"扩展"。刚才我们说，这个张量分解是基于一个假设，那就是用户在时间维度上的购买决定取决于，用户是否对这个商品有喜好，以及这个商品是不是符合时间维度上面的"流行度"。我们用了两个矩阵分解来表达这两个假设。每一个矩阵分解都是把一个大的矩阵分解成两个向量，比如用户和商品的矩阵就被分解为用户特性和商品特性。基于此，作者们就在这个用户和商品的矩阵后面，再加上一个商品和图片美感信息矩阵，用来混合这两种信息。也就是说，我们刚才的第一个假设，用户对商品的好感，就被扩展成了**两个矩阵的加和**，用户和商品矩阵以及商品和图片信息矩阵，这两个矩阵的加和依然是一个矩阵。同理，时间和商品的流行度，被扩展成了时间和商品矩阵以及商品和图片信息矩阵的加和。也就是说，新的模型是两个矩阵的乘积组成的张量分解，而这里的每个矩阵分别又是两个矩阵的加和。这就是作者们最终提出的模型。
## 方法的实验效果 {#143.html#-}作者们在亚马逊的衣服数据集上做了实验来验证模型的有效性。这个亚马逊的数据集由将近四万的用户、两万多的商品和超过二十七万的购买信息构成。除了这篇文章提出的模型以外，作者们还比较了一些其他算法，例如完全随机的算法、只推荐最流行的商品、传统的矩阵分解模型以及只有基本图像信息但没有美感信息的算法。文章汇报了排序的精度NDCG 以及"召回"（Recall）等指标。从实验效果来看，这篇文章提出的模型要明显好于矩阵分解以及只有基本图像信息的算法，表明针对产品的图像美感进行建模是有价值的。并且，作者们提出的新的张量分解方法也被证明是切实有效的。
## 小结 {#143.html#-}今天我为你讲了今年万维网大会的一篇优秀论文。文章介绍了如何对商品的图片美感进行建模，以及如何把提取到的信息融入到一个基于张量分解的推荐系统中。一起来回顾下要点：第一，我们详细介绍了这篇文章要解决的问题以及贡献；第二，我们简要地介绍了文章提出方法的核心内容；第三，我们简单分享了一下模型的实验成果。最后，给你留一个思考题，有没有在没有标签情况下对图片的美感进行建模的呢？欢迎你给我留言，和我一起讨论。![](Images/5f1a3d2ca933c759573c72ee2ba198b7.png){savepage-src="https://static001.geekbang.org/resource/image/ef/b2/efd991ee74e55356bb2776f3d8d375b2.jpg"}
# 102 \| The Web 2018论文精读：如何改进经典的推荐算法BPR？今天，我们来看万维网大会上的一篇优秀短论文。在万维网大会上，主要发表两类论文。一类是10 页的长论文，一类是 2页的短论文或称作展板论文。短论文主要是发表短小的成果或者是还在研究过程中的重要成果。每一届的万维网大会，都会评选出一篇最佳短论文奖。今天我和你分享的论文，题目是《利用查看数据，贝叶斯个性化排序的一种改进的取样器》（[AnImproved Sampler for Bayesian Personalized Ranking by Leveraging ViewData](https://www.comp.nus.edu.sg/~xiangnan/papers/www18-improvedBPR.pdf)）。这篇论文也有六位作者，和我们介绍的上一篇论文一样，都来自清华大学和新加坡国立大学。
## 贝叶斯个性化排序 {#144.html#-}要想理解这篇论文的内容，我们必须要讲一下什么是"**贝叶斯个性化排序**"（BayesianPersonalized Ranking），或者简称是**BPR**。有关 BPR的详细介绍，可以阅读参考文献 \[1\]。我们在这里仅对 BPR进行一个高维度的总结。简单来说，**BPR是推荐系统中的一个配对排序（Pairwise）学习算法**。在我们前面介绍搜索算法的时候，曾经提到了各种配对排序学习算法。配对排序学习不是针对每一个数据实例来学习其标签或者响应变量，而是学习一个相对的顺序，希望能够把所有的正例都排列到负例之前。也就是说，对于配对排序来说，每一个数据实例的预测值本身并不重要，排序算法在意的是对于一正一负的一个配对来说，是否能够把正例给准确地排列到负例之上。这其实就要求BPR 在数值上对正例的预测值能够比负例的预测值高。BPR主要是解决了在推荐系统中长期以来只对单个数据点进行预测，比如需要对用户物品的喜好矩阵建模的时候，之前的大多数算法都无法有效地对没有观测到的数据进行建模。而BPR是配对算法，因此我们只需要关注观测的数据以及他们之间的关系，从而能够对用户的喜好，特别是有"**隐反馈**"（ImplicitFeedback）数据的时候，取得更加明显的效果。这里的隐反馈指的并不是用户告诉系统其对每一个物品的喜好程度，而是用户在和系统的交互过程中通过一些行为表达出的喜好。这些用户的行为往往并不全面，因此需要算法和模型能够对这些行为进行有效建模。
## 论文的主要贡献和核心方法 {#144.html#-}了解了 BPR大概是怎么回事以后，我们来看一看这篇论文的主要贡献和核心方法。``{=html}首先我们刚才讲到 BPR的核心是学习一个配对的排序问题。那么在训练的时候，我们需要对一个正例和一个负例的配对进行学习，更新参数。然而在一个自然的用户隐反馈数据集里，正例相对来说往往是少数，负例则是绝大多数。因此，一个传统的方法就是在组成一个配对的时候，相对于一个正例来说，我们都"均匀地"（Uniformly）选取负样本来组成配对，这个过程有时候也叫"采样"（Sampling）。这篇论文有两个主要贡献。第一个贡献是，作者们发现，如果在全局均匀地采样负样本，第一没有必要，第二可能反而会影响最后学习的效果。第二个贡献是，针对电子商务的应用，作者们发明了一种负样本采样的方法，使得学习算法可以利用到更多的用户"浏览"（View）信息，从而能够对算法的整体训练效果有大幅度的提升。
## 方法的实验效果 {#144.html#-}这篇论文的数据集分别使用了母婴产品"贝贝网"和天猫的数据。其中，贝贝网有约16 万用户、12 万商品、260 万次购买和 4600 万次浏览；天猫的数据则有 3万用户、3 万多商品、46 万次购买和 150 多万次浏览。两个数据集都呈现了大于99% 的"稀疏度"（Sparsity）。首先，作者们实验了不从全局中选取负样本而仅仅采样一部分，而且是相比于原来的空间非常小的样本，比如仅仅几百个负样本而不是几万个的情况。实验效果在贝贝网上不仅没有影响算法的精确度，算法的精确度反而还有提升。而在天猫的数据集上，算法效果没有提升，而有一些小幅度的下降，但是作者们认为这样的代价还是值得的，因为数据集的减少，算法的训练时间会大幅度降低。从这个实验中，作者们得出了不需要从全局进行采样的结论。紧接着，作者们提出了一个新的概念，那就是，对用户的数据集合进行划分，把用户的行为分为"购买集"（C1）、"浏览但没有购买集"（C2）、"剩下的数据"（C3）这三个集合。作者们提出，BPR要想能够达到最好的效果，需要对这三种数据集进行采样。也就是说，我们需要组成C1 和 C2、C1 和 C3 以及 C2 和 C3 的配对来学习。具体来说，用户在贝贝网和天猫的数据中尝试了不同的比例来对这三种集合进行采样。总体的经验都是C3 中采样的数据要大于 C2 中的，然后要大于 C1中的。这其实就是说训练算法要更好地学习到用户不喜欢某件东西的偏好。采用这样的采样方式，作者们展示了模型的效果比传统的BPR 或仅仅使用"最流行的物品"作为推荐结果要好 60% 左右。