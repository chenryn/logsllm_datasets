### Throughput of Our Scheme

The server's disk I/O cost is approximately O(log n), meaning it needs to read roughly O(log n) blocks for each write operation. Our experiments show that, if the server's disk I/O were fully utilized, the Proof of Retrievability (POR) write throughput achievable under our setup would be around 20 MB/s. In this experiment, we cached the smallest 10 levels of the hierarchical log structure H in memory.

In practice, however, the client-server bandwidth is more likely to be the bottleneck, and the actual POR throughput will be limited by the available client-server bandwidth.

### Disk I/O and Seek Operations

Although the server needs to read O(log n) blocks for each write, the number of seeks is very small. As mentioned earlier in Section 6.1, the hierarchical log structure H is mostly written in a sequential manner. By choosing a large chunk size (approximately 50 MB) and caching chunks in memory, each write operation requires only 0.03 to 0.06 seeks on average. We also cache the Merkle hash tree for U in memory during our experiments.

### Audit Cost

For these experiments, we set λ = 128, meaning each audit samples 128 blocks from each level H(cid:96) and buffer C. Figure 8 shows the time spent by the server for each audit operation, including the time for reading the disk and performing computations, but excluding the network transfer time between the client and server (which is characterized separately in Figure 10). The majority of this time is spent on disk I/O, dominated by disk seeks. There are roughly O(λ log n) seeks per audit operation, parallelized across 7 disks, with each seek taking about 12 ms.

Figure 9 illustrates the disk I/O cost for an audit. As discussed in Section 6.1, we optimize for writes at a slightly higher audit cost, resulting in an audit disk I/O cost of O(λβ log² n). This is why the line in the figure curves slightly and is not linear.

### Computational Overhead for Hierarchical Erasure Coding

As shown in Figure 11, the hierarchical coding scheme can be computed at extremely fast speeds, exceeding 1600 MB/s per level on a modern processor. To characterize the computational cost, we cached about 4 GB of data in memory and avoided performing disk fetches during the experiment.

### Client-Server Bandwidth for Audits

Figure 10 shows the client-server bandwidth consumed for an audit. As mentioned in Section 6.1, unlike our theoretical construction, our implementation chooses to speed up writes at a slightly higher client-server bandwidth for audits, specifically β log n + O(λ log n).

### References

[1] https://en.wikipedia.org/wiki/Hash_tree.
[2] Fast Fourier Transform. http://math.berkeley.edu/~berlek/classes/CLASS.110/LECTURES/FFT.
[3] Fast Fourier Transform. http://en.wikipedia.org/wiki/Fast_Fourier_transform.
[4] SLOCCount. http://www.dwheeler.com/sloccount/.
[5] G. Ateniese, R. Burns, R. Curtmola, J. Herring, L. Kissner, Z. Peterson, and D. Song. Provable Data Possession at Untrusted Stores. In CCS, 2007.
[32] Q. Zheng and S. Xu. Fair and Dynamic Proofs of Retrievability. In CODASPY, 2011.
[6] S. Benabbas, R. Gennaro, and Y. Vahlis. Verifiable Delegation of Computation over Large Datasets. In CRYPTO, pages 111–131, 2011.
[7] K. D. Bowers, A. Juels, and A. Oprea. Proofs of Retrievability: Theory and Implementation. In CCSW, pages 43–54, 2009.
[8] D. Cash, A. Kupcu, and D. Wichs. Dynamic Proofs of Retrievability via Oblivious RAM. In Eurocrypt, 2013.
[9] Y. Dodis, S. P. Vadhan, and D. Wichs. Proofs of Retrievability via Hardness Amplification. In TCC, pages 109–127, 2009.
[10] C. Erway, A. Kupcu, C. Papamanthou, and R. Tamassia. Dynamic Provable Data Possession. In CCS, 2009.
[11] O. Goldreich and R. Ostrovsky. Software Protection and Simulation on Oblivious RAMs. J. ACM, 1996.
[12] M. T. Goodrich and M. Mitzenmacher. Privacy-Preserving Access of Outsourced Data via Oblivious RAM Simulation. In ICALP, 2011.
[13] M. T. Goodrich, M. Mitzenmacher, O. Ohrimenko, and R. Tamassia. Privacy-Preserving Group Data Access via Stateless Oblivious RAM Simulation. In SODA, 2012.
[14] A. Juels and B. S. K. Jr. PORS: Proofs of Retrievability for Large Files. In ACM Conference on Computer and Communications Security, pages 584–597, 2007.
[15] E. Kushilevitz, S. Lu, and R. Ostrovsky. On the (In)security of Hash-Based Oblivious RAM and a New Balancing Scheme. In SODA, 2012.
[16] R. C. Merkle. A Certified Digital Signature. In Proceedings on Advances in Cryptology, CRYPTO '89, 1989.

### Appendix

#### Achieving Public Verifiability

Although our basic construction in Section 4 provides public verifiability, the more efficient scheme described in Section 5 does not, as the homomorphic checksum requires the client to keep secret state. In this section, we show how to make the efficient scheme of Section 5 publicly verifiable. In a publicly verifiable setting, only a trusted data source can write data, but anyone can perform verifiable reads and POR audits.

Ensuring public verifiability for reads is straightforward, as a Merkle hash tree is maintained over the buffer U. The trusted source can sign and publish the up-to-date root digest of this Merkle-hash tree, making it available for public verification of read operations.

We now focus on achieving public auditability, enabling anyone to challenge the server to prove it possesses all data (owned by the source) while maintaining low write operation bandwidth.

##### Public Auditability with Low Write Cost

To achieve public auditability, we build a separate Merkle hash tree over the blocks of each level H(cid:96) and one for C. The up-to-date root digests of all O(log n) hash trees will be publicized. During a public audit, a user with the root digests requests O(λ) blocks at random for each level H(cid:96) and buffer C, and checks them with the root digests.

One question remains: how does the trusted source keep track of these root digests without transferring original blocks during the rebuilding of the hierarchical levels? To address this, we sketch our idea below, with full details and proofs in the full online version [22].

Our idea is to have the server compute the new Merkle trees for a level (or the buffer C) when it is being rebuilt. However, we need to protect against a malicious server that can potentially cheat and output the wrong digests. We apply a probabilistic checking idea here.

When rebuilding a level H(cid:96) (or buffer C), the following happens:
- As in the secretly-verifiable scheme (Section 5), the trusted source downloads the encrypted/authenticated homomorphic checksums and "simulates" the rebuilding over these (cid:101)σ(B)'s.
- The server performs the rebuilding, computes the new digest h of H(cid:96), and commits h to the source.
- The source challenges O(λ) random blocks in H(cid:96). For each challenged block B: the source downloads the block itself B, its (cid:101)σ(B), and the path in the Merkle tree necessary to verify block B. The client then checks that (cid:101)σ(B) verifies for B, and that the already committed root digest h verifies for B as well.

Proof intuition: This idea works because if the server can pass the probabilistic check (of the committed root digest h), then at least a constant fraction of the rebuilt level H(cid:96) (or buffer C) is correctly incorporated into the claimed digest h. Due to PoR's inherent erasure coding, this suffices to prove the retrievability of the publicly verifiable PoR scheme. The full proof is deferred to the full online version [22].

Write cost: Suppose the trusted source caches locally the smallest log λ + log(2/ε) levels, consisting of about 2λ/ε number of blocks, for an arbitrarily small 0 < ε < 1. These are the levels accessed more frequently during write operations. We can then show that the source-server bandwidth for each write operation is β(1 + ε) + O(λ log n). The details of this analysis are elementary and deferred to the full online version [22]. This analysis assumes that exactly λ blocks are probabilistically checked for each Merkle tree hash tree of the remaining (uncached) levels.

##### Reducing Public Audit Cost

The publicly verifiable approach described above requires O(λ log n(β + log n)) overhead for public auditing. Particularly, for each of the O(log n) levels H(cid:96) as well as C, O(λ) blocks need to be checked; and to check a block involves downloading the block itself and log n hashes of the Merkle hash tree. With some additional tricks, we can further improve the public audit overhead to O(λβ log n). We defer these details to the Appendix. The basic idea is as follows:

- Instead of building a separate Merkle tree per level H(cid:96), build a single Merkle tree over the entire hierarchical log structure H, and another one for C. The Merkle tree will be aligned on top of the hierarchical structure H. Since H has exponentially growing levels, we can view H as a tree, where internal nodes are assigned values—in our case, the blocks are the values of internal nodes of the Merkle tree. The hash of each internal node in the Merkle tree is computed as H(hleft, hright, B), where hleft is the hash of the left child, hright is the hash of the right child, and B is the block associated with that node. The client publishes the hash of the Merkle tree for H and the one for C.
- During public audits, random checks for C are still done as before. To check H, instead of randomly sampling O(λ) blocks from each level H(cid:96), the client randomly samples O(λ) paths from the root to O(λ) randomly selected leaf nodes, and samples the blocks on these paths. As a result, O(λ) blocks from each level get sampled, and only O(λ log n) hashes need to be transmitted to verify all the paths sampled—namely, hashes of all sibling nodes to the sampled paths need to be transmitted. This reduces the public audit overhead to O(λβ log n), assuming β = O(λ).
- When a non-top level H(cid:96) gets rebuilt, the server rebuilds the Merkle hash tree, and the client performs the following probabilistic checking protocol. The client first retrieves all hashes at level H(cid:96)+1, ensuring they are consistent with the old digest. The client then randomly samples O(λ) blocks at level H(cid:96), to ensure these blocks are correctly incorporated into the new root digest as claimed by the server.
- When the top level is rebuilt, the client simply checks O(λ) random blocks in the top level, ensuring they are correctly incorporated into the root digest.

**Theorem 4:** The dynamic PoR scheme with public verifiability satisfies both authenticity (Definition 1) and retrievability (Definition 2). The proof is in the full online version [22].

##### Resizing the Storage

Our scheme can easily be modified to support insertions and deletions of blocks. Insertions can be supported by adding a level to the hierarchical log structure H whenever the number of blocks doubles. Deletions can be supported by updating the deleted block with ⊥. Further, whenever the number of deleted elements exceeds roughly half the size of the dataset, the client can rebuild and consolidate the hierarchical log by suppressing deleted items. More details will be provided in the full online version [22].

### Acknowledgments

This work is partially supported by NSF grant CNS-1314857, a Google Research Award, the NSF Graduate Research Fellowship under Grant No. DGE-0946797, by a DoD National Defense Science and Engineering Graduate Fellowship, by Intel award through the ISTC for Secure Computing, and a grant from Amazon Web Services. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the funding agencies. We would like to thank Hubert Chan, Jonathan Katz, and Hongsheng Zhou for helpful discussions, and the anonymous reviewers for their insightful feedback.