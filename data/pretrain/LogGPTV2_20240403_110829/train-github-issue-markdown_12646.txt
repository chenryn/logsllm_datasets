    from collections import OrderedDict
    import random
    import pandas as pd
    pd.__version__
    '0.20.3'
    df = pd.DataFrame.from_dict(OrderedDict(
        [
            ((lv1, lv2, lv3), {'KG': random.randint(0, 100)})
            for lv1 in ['A', 'B']
            for lv2 in ['M', 'N', 'O']
            for lv3 in ['X', 'Y', 'Z']
        ]
    ))
    df     
| A | B  
---|---|---  
| M | N | O | M | N | O  
| X | Y | Z | X | Y | Z | X | Y | Z | X | Y | Z | X | Y | Z | X | Y | Z  
KG | 16 | 71 | 27 | 8 | 83 | 0 | 100 | 72 | 100 | 42 | 26 | 21 | 91 | 5 | 36 |
98 | 96 | 52  
    df.loc[:, idx[:, :, 'X']]
| A | B  
---|---|---  
| M | N | O | M | N | O  
| X | X | X | X | X | X  
KG | 44 | 83 | -28 | 5 | -31 | 44  
    df.xs('Y', level=2, axis=1) - df.xs('Z', level=2, axis=1)
| A | B  
---|---|---  
| M | N | O | M | N | O  
KG | 44 | 83 | -28 | 5 | -31 | 44  
    idx = pd.IndexSlice
    df.loc[:, idx[:, :, 'X']] = (df.xs('Y', level=2, axis=1) - df.xs('Z', level=2, axis=1))
    df
| A | B  
---|---|---  
| M | N | O | M | N | O  
| X | Y | Z | X | Y | Z | X | Y | Z | X | Y | Z | X | Y | Z | X | Y | Z  
KG | NaN | 71 | 27 | NaN | 83 | 0 | NaN | 72 | 100 | NaN | 26 | 21 | NaN | 5 |
36 | NaN | 96 | 52  
This was unexpected. I realize that the indexes do not match, and hence this
behavior, but I expect Pandas to throw an Exception, rather than silently do
this
    idx = pd.IndexSlice
    df.loc[:, idx[:, :, 'X']] = (df.xs('Y', level=2, axis=1) - df.xs('Z', level=2, axis=1)).values
    df
| A | B  
---|---|---  
| M | N | O | M | N | O  
| X | Y | Z | X | Y | Z | X | Y | Z | X | Y | Z | X | Y | Z | X | Y | Z  
KG | 44 | 71 | 27 | 83 | 83 | 0 | -28 | 72 | 100 | 5 | 26 | 21 | -31 | 5 | 36
| 44 | 96 | 52  
This was, of course, the behavior I was expecting