pointers, are captured by the control-ﬂow part of OEI attes-
tation. OAT relies on programmers to annotate semantically
critical variables because labeling such variables is subjective
and speciﬁc to program semantics.
The control-dependent variables (automatically detected)
and the semantically critical variables (annotated by program-
mers) form the initial set of critical variables. Our compiler
then automatically expands this set to include the direct and
indirect pointers to these variables and their dependencies.
Pointers to a critical variable allow indirect deﬁne or use
of the variable. Therefore, we treat such data pointers as
special critical variables, referred to as critical pointers. Our
compiler iteratively identiﬁes them from a global points-to
map produced by the standard Anderson pointer analysis.
Dependencies of a critical variable V are the variables that
may inﬂuence the value of V. Verifying the integrity of V
implies verifying the integrity of both V and its dependencies.
Given a set of critical variables, our compiler ﬁnds all their
dependencies by ﬁrst constructing the program dependence
graph and then performing a backward traversal for each
variable along the data dependence edges. Newly discovered
variables during the traversal are added to the critical variable
set. The iterative search for dependencies stops when the set
reaches a ﬁxpoint. This automatic dependency discovery also
simpliﬁes critical variable annotation: programmers only need
to annotate one, not all, variable for each piece of critical data.
Value-based Deﬁne-Use Check: OAT compiler instruments
all deﬁne- and use-sites for each variable in the expanded
critical variable set. During runtime, the instrumentation at
each deﬁne-site captures the identity of the critical variable
(i.e., a compiler-generated label) and the value to be assigned
to the variable. It sends the information to the measurement
engine in the Secure World via the trampolines. Similarly,
the use-site instrumentation captures the variable identity and
the current value of the variable and sends them to the
measurement engine.
For an array-typed critical variable, each array element ac-
cess is instrumented by OAT compiler. OAT compiler identiﬁes
8
and instruments every memory access whose target address
is calculated as an offset relative to a critical variable. This
critical variable can be an array name or a pointer that points to
a buffer. This design also uniformly covers multi-dimensional
arrays and nested arrays because in both cases an array element
access is based on a memory address that is calculated from the
array’s name or base address. From the measurement engine’s
perspective, it only sees critical variables or critical array
elements identiﬁed by their addresses, rather than entire array
objects. The integrity of each element is checked indepen-
dently during runtime.
The measurement engine maintains a hashmap which stores
pairs of . V ariableID is the ad-
dress of a variable or an array element. The measurement
engine updates the hashmap at each instrumented deﬁne-site
and checks the value at each instrumented use-site. Regardless
whether a variable is on the stack (local) or the heap (global),
its def-use sites should always have matching values. A
value mismatch indicates a corrupted critical variable. The
measurement engine ﬁnally sends the CVI checking result
along with the control-ﬂow measurements in a signed blob
to the remote veriﬁer.
Pointer-based Access to Critical Variables: Consider an
example: *(P+n) = x, where P is the base address of a
critical array A; n is the dynamic index. This is a legitimate
critical variable deﬁne-site. Assuming that, due to a program
bug, the dereference *(P+n) could go out of the bounds
of A and reach another critical variable B, the measurement
engine would then mistakenly update the value of B to x in
its hashmap when this out-of-bounds write happens.
We solve this issue by enforcing dynamic bounds checking
on critical pointers. When a critical pointer is dereferenced, the
measurement engine checks if the pointer dereference breaches
the bounds of the current pointee. This check relies on
the dynamic bounds information (similar to SoftBound [46])
collected by the measurement engine for each critical pointer.
If a bounds breach is found, the measurement engine performs
CVI check only on the overlapping bytes between the accessed
memory region and the initially pointed variable (i.e., it only
updates or checks the value of the expected pointee). This de-
sign ensures CVI check correctness while allowing intentional
out-of-bounds pointer dereferences in normal programs.
VI. IMPLEMENTATION
Our OAT prototype implementation includes 6,017 lines of
C++ code for the compiler (an LLVM module), 440 lines of
C and assembly code for the trampoline library, 476 lines of
C code for the measurement engine, and 782 lines of Python
code for the veriﬁcation engine.
Hardware & Software Choices: We selected a widely used
IoT development board,
the HiKey board (ARM Cortex-
A53), as our reference device for prototyping. We made this
choice due to the board’s unlocked/programmable TrustZone,
its full compatibility with open-source TEE OS, and its reliable
debugging tools. We do realize that the board has a relatively
9
powerful processor compared to some low-end embedded
devices. However, no development board currently available
comes with a low-end ARM processor and an unlocked
TrustZone at the same time. Nevertheless, OAT’s design and
implementation are neither speciﬁc to this board nor dependent
on powerful processors. The only hardware requirement OAT
has is the TrustZone extension, which is available on many
commercial embedded ARM SoCs.
We used OP-TEE [45] as our TEE OS (the OS for the
Secure World). Although OAT is designed for bare-metal em-
bedded devices (i.e., no stand-alone OS in the Normal World),
we used the vendor-customized Linux as the Normal World
OS solely for the purpose of easily booting and debugging the
board. OAT itself does not assume the presence of a Normal
World OS. Even though OAT’s performance can be negatively
affected by the unnecessary OS, our evaluation (§VIII) shows
the overhead under this disadvantaged conﬁguration is still
acceptable.
in Appendix §A.
The implementation details of the OAT system is attached
VII. DISCUSSION
Multithreading: Our current prototype only supports single-
thread programs, which constitute the majority of today’s
embedded programs. To attest multi-thread programs, we need
to augment the OAT compiler to instrument threading-related
events and have the measurement engine collect measurements
and perform checks on a per-thread basis. We consider multi-
threading support out-of-scope for this paper because it does
not need any change to the design of OEI attestation but
requires signiﬁcant engineering efforts to implement.
Interrupt Handling: Interrupt handling poses a challenge to
the control ﬂow veriﬁcation due to its asynchronous nature.
When an interrupt happens in the middle of an attested
operation, we do not know in advance where the interrupted
location is. If the measurement engine cannot recognize and
process interrupts, they may introduce out-of-context control
ﬂow events that can fail or confuse the veriﬁcation.
OAT overcomes this challenge by treating each interrupt
handler invoked during an operation as an execution of a
sub-program. It instruments the handler both at the entry and
the exit points. The instrumentation notiﬁes the measurement
engine of the beginning and the end of such a sub-program.
Thus the control ﬂow events of the handler are recorded in a
separate trace and hash and veriﬁed independently. OAT also
checks if an invoked interrupt handler matches the interrupt
that triggered the handler.
Annotation: OAT allows programmers to optionally annotate
semantically critical variables for CVI attestation. However,
this annotation is not required for detecting data-oriented pro-
gramming [33], control-ﬂow bending [10], or similar data-only
attacks, whose target data (i.e., control-dependent variables)
are automatically detected by OAT compiler and included in
CVI veriﬁcation. On the other hand, the annotation process
TABLE II: Runtime Overhead Breakdown
Overhead Sources
Attestation Init (Oat init)
Trampoline Func(Otramp)
Attestation Exit (Oat exit)
Time(CPU Cycles)
5.1*107
5.5*104
2.6*107
Time(ms)
42.879
0.045
21.351
for semantically critical variables is simple and facilitated by
the compiler’s automatic dependency analysis.
VIII. EVALUATION AND ANALYSIS
We conducted: (i) micro performance tests to measure the
overhead of each step in OEI attestation; (ii) macro perfor-
mance tests on 5 real embedded programs of different kinds
to examine OAT’s overall overhead; (iii) tests against possible
attacks; (iv) analysis on how OAT defends against evasions.
A. Micro Performance Tests
The runtime overhead of OEI attestation can be broken
down into three parts, as shown in the ﬁrst column in Table II:
(i) attestation initialization (Oat init), taking place at the entry
of an attestation scope (i.e., an operation); (ii) trampoline
invocation (Otramp), including a direct smc call to initiate
the world switch and a return from the Secure World (i.e.,
the roundtrip world-switch overhead); (iii) attestation exit
(Oat exit), happening at the end of an attestation scope.
We created a test program that incurs each type of overhead
exactly once. We ran this program for 1,024 times and obtained
the average overhead in terms of CPU cycles as well as
time used, as shown in Table II. Oat init and Oat exit are
orders of magnitudes larger than Otramp. This is because
they involve establishing or terminating the attestation session
and the communication between the Normal and the Secure
worlds. Since the initialization and exit happen only once for
each attestation, their overhead tends to blend in the (much
longer) operation execution time and is unnoticeable.
B. Tests on Real Embedded Programs
We selected 5 open-source embedded programs to evaluate
the end-to-end overhead of OAT. We could not test more
programs because of the non-trivial manual effort required
for porting each program to our development board. This
requirement is due to embedded programs’ device-speciﬁc
nature. It
is not posed by our system. We picked these
programs because they represent a reasonable level of variety.
Some of them may seem toy-like, which is not intentional but
reﬂects the fact that most embedded programs are simple by
design. We note that these programs are by no means standard
benchmarks. In fact, there are no standard benchmarks for
bare-metal embedded devices available at the time of writing.
It is also rare for embedded device vendors to publicly release
their ﬁrmware in source code form. The 5 selected embedded
programs are:
• Syringe Pump (SP) is a remotely controlled liquid-
injection device, often used in healthcare and food
Fig. 3: Compile-time overhead
processing settings. We apply OEI attestation to the
“injection-upon-command” operation.
• House Alarm System (HA) [25] is an IoT device that,
when user-speciﬁed conditions are met, takes a picture
and triggers an alarm. We apply OEI attestation to its
“check-then-alarm” operation.
• Remote Movement Controller (RM) [27] is an embedded
device that allows the physical movement of its host
to be controlled remotely, similar to the example given
in
the “receive-execute-command”
operation.
§III-A. We attest
• Rover Controller (RC) [28] controls the motor on a rover.
We attest the “receive-execute-command” operation.
• Light Controller (LC) [26] is a smart lighting controller.
We attest the “turn-on/off-upon-command” operation.
Compile-time Overhead: We instrumented OAT compiler to
measure its own performance in terms of binary size increase
and compilation delay. Figure 3 shows the results for each
program. The absolute increase in code size ranges from 1 to
3 KB, which is acceptable even for embedded devices, despite
the seemingly large percentage (13%). We ﬁnd that the size
increase is not proportional to the original code size and is
dominated by the trampoline library, which has a ﬁxed size.
The compilation delay caused by the attestation-related code
analysis and instrumentation may seem high, averaging 62%.
But in absolute terms, the delay is less than 1 second for
the tested programs. We believe this is acceptable given that
(i) the overhead is on par with similar code analysis and
instrumentation techniques; (ii) the compilation is ofﬂine and
happens only once for each program version.
Operation Execution Time & Instrumentation Statistics:
For each test program, we measured the execution times with
and without OEI attestation enabled for the selected operation.
The results are shown in the column named “Operation Exec.
Time” in Table III. The sub-column “Overhead” shows the
relative delay caused by OAT to operation executions, averag-
ing 2.7%. We observed that the delays are unnoticeable and
blend in the much longer end-to-end execution time of the
10
Syringe PumpHouse Alarm SystemMovement ControllerRover ControllerLight Controller051015202530Code Size(KB)12.0030.0022.008.7013.00Original Code SizeCode Size IncreaseOriginal Compile TimeCompile Time Increase0.00.51.01.52.02.5Compile Time(s)1.462.621.490.910.83TABLE III: Runtime overhead measured on 5 real embedded programs
Operation Exec. Time
OAT Instrumentation Statistics
w/o OEI (s) w/ OEI (s) Overhead (%) B.Cond Def-Use
Icall/Ijmp Critical Var.
Prog.
SP
HA
RM
RC
LC
Avg.
10.19
5.28
10.01
2.55
5.33
N/A
10.38
5.36
10.13
2.66
5.56
N/A
1.9%
1.6%
1.3%
4.5%
4.4%
2.7%
488
147
901
14
931
496
2
91
100
33
2420
529
Ret