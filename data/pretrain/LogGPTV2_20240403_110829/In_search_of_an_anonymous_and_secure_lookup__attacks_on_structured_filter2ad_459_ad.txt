4Note that even if Bud(A) is not honest, the attacker can
still learn that A is honest. The attacker can obtain the ID
of A through Bud(A), since A requests Bud(A) to perform
the lookup.
5Values of l are selected according to the Torsk paper [16]:
⌉, where we use typical values κ = 3, ǫ = 0.01.
l = ⌈
nκ
ǫ
2 log2
3
1
0.9
0.8
0.7
0.6
0.5
)
)
W
R
(
r
P
l
(
k
a
w
m
o
d
n
a
r
a
g
n
i
t
p
u
r
r
e
t
n
i
f
o
y
t
i
l
i
0.4
b
a
b
o
r
P
0.3
0.2
0
0.02
0.04
0.06
l=13 (n=1000)
l=14 (n=5000)
l=15 (n=10000)
0.14
0.16
0.18
0.2
0.08
Fraction of malicious nodes (f)
0.1
0.12
Figure 9: P r(RW ) – Probability that the attacker
can block a honest node from performing a random
walk to select a buddy.
5.3 Analysis
Now we analyze the anonymity of Torsk under buddy ex-
haustion attack. We let RW denote the event that the at-
tacker can interrupt a random walk. Then, P r(RW ) equals
the chance that there is at least one malicious node picked
in the random walk. Therefore,
(1 − p)i−1p(1 − f )i!
p(1 − f )l+1
1 − (1 − f )(1 − p)
P r(RW ) = (1 − f )l 1 −
+(cid:16)1 − (1 − f )l(cid:17) = 1 −
∞
Xi=1
where p = 1
l , representing the probability that the random
walk stops at a particular hop of the tail. Figure 9 shows
that when f = 0.2, the attacker can successfully interrupt
about 99% random walks.
A node under buddy exhaustion attack could try to re-
peatedly perform random walks in parallel, in hopes of ﬁnd-
ing new buddies before the client gives up the circuit con-
struction. However, the number π of concurrent random
walks a querier can perform is limited by its computational
capacity. During the random walk, the querier needs to
perform 2d certiﬁcate-verifying operations at each hop (the
Torsk authors [16] suggest d is 8 or 16). We let ϕ denote
the average latency between two hops in a random walk
(according to the experimental results in [16], ϕ ≈ 0.2sec).
Suppose that the time needed to verify a public-key signa-
ture is τ (e.g., τ = 0.5ms). Then, π is bounded by ϕ
2dτ ,
which is equal to 25 with d = 8, ϕ = 0.2sec, and τ = 0.5ms.
Apart from π, the maximum number of random walks the
querier can perform in parallel before the client’s timeout
is also determined by the time σ needed to perform an in-
terrupted random walk. σ is determined by the number of
hops that a random walk travels before meeting the ﬁrst
malicious node. Hence, the expected value of σ, E(σ), is
calculated as:
ϕ  ∞
Xj=1
(j + l)(1 − p)j−1p(1 − f )l+j−1f +
i(1 − f )i−1f!
l
Xi=1
We assume the attacker ﬂoods B with ν + µ lookup re-
quests, where µ is the number of buddies maintained by each
node. We let EX denote the event that the attacker can
successfully prevent B from extending the circuit, and let Φ
315)
)
X
E
(
r
P
i
(
d
e
d
n
e
t
x
e
g
n
e
b
m
o
r
f
t
i
u
c
r
i
c
a
g
n
i
t
n
e
v
e
r
p
f
o
y
t
i
l
i
b
a
b
o
r
P
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
f=0.2, l=15 (n=10000)
f=0.15, l=15 (n=10000)
f=0.1, l=15 (n=10000)
f=0.2, l=14 (n=5000)
f=0.15, l=14 (n=5000)
f=0.1, l=14 (n=5000)
100
200
300
400
v
500
600
700
800
)
)
|
R
R
B
(
r
P
(
y
t
i
l
i
b
a
i
l
i
e
r
/
e
s
m
o
r
p
m
o
C
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
f=0.2, l=15 (n=10000)
f=0.16, l=15 (n=10000)
f=0.1, l=15 (n=10000)
f=0.2, l=14 (n=5000)
f=0.16, l=14 (n=5000)
f=0.1, l=14 (n=5000)
100
200
300
400
v
500
600
700
800
Figure 10: P r(EX) – Probability that the attacker
can prevent a honest node from extending a circuit.
Φ = 5min, and π = 25.
denote the client’s maximum waiting time before giving up
the circuit construction (e.g., Φ = 5min). Then,
P r(EX) =
ν
Xi=0
bino(cid:18)i,
πΦ
E(σ)
, 1 − P r(RW )(cid:19)
Figure 10 shows that when ν is larger than a threshold
value (e.g., 200 when f = 0.15, n = 10 000), the attacker
can prevent a particular relay from extending the circuit
with success probability nearly 1. We note that it is reason-
able to consider fairly large ν, in that the attacker may ask
her controlled malicious nodes to ﬂood a particular node in
collaboration. For instance, in a network with n = 10 000
nodes and 20% malicious nodes, there would be 2000 ﬂood-
ing requests if each malicious node contributes one.
Now we analyze the anonymity of Torsk under buddy ex-
haustion attack. We let R denote the event that a circuit
is reliable (either when both the entry and exit nodes are
compromised, or when the attacker fails to launch buddy
exhaustion attack). R is equivalent to:
(MA ∧ MC ) ∨ ¬MA ∧ ¬MB ∧ ¬MC ∧ ¬(LK ∧ EX)
We let LK denote the event that a lookup is observed by the
attacker, and let BR represent that a circuit is compromised.
Then, the fraction of compromised circuits out of reliable
circuits, P r(BR|R), is calculated as:
P r(BR ∧ R)
P r(R)
=
f 2
f 2 + (1 − f )3(1 − P r(LK)P r(EX))
Figures 11, and 12 present the analysis results for P r(BR|R)
with diﬀerent impact factors. We simulate the buddy ex-
haustion attack on Torsk. We generate 20 random topolo-
gies, and for each topology we perform 1000 circuit con-
structions. Figure 13 shows the simulation results, with
ν = 500, Φ = 5min, and π = 25. We can see that with
buddy exhaustion attack, the attacker can break over 80%
of all constructed circuits.
5.4 Improvements to Torsk
The authors [16] suggested that the random walk process
for buddy selection needs to start over whenever a queried
malicious node returns an invalid certiﬁcate. This allows
the attacker to block honest nodes from ﬁnding new bud-
dies. Nevertheless, we think restarting the random walk
Figure 11: Eﬀect on varying the number of ﬂooding
lookup requests. Φ = 5min, and π = 25.
)
)
|
R
R
B
(
r
P
(
y
t
i
l
i
b
a
i
l
i
e
r
/
e
s