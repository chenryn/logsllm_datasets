UB
UB
?
n
n
n
n
?
ub
ub
ub
?
n
n
n
n
n
n
n
?
ub
?
n
n
?
?
?
n
n
?
Classification of Exploits Inferred from Real-world Attacks. “setup” means that vulnerability is exposed during channel setup (and possibly usage as well)
whereas “use” means it is exposed only during channel use; “idm” means that it is exposed during identiﬁer distribution. “OB” means overblocking; “UB”,
underblocking; “ub”, underblocking that a censor can easily recover from by retransmitting its own probe; and “n”, neither under- nor overblocking.
TABLE V
We lack empirical evidence as to whether such mimicry
approaches would enjoy a period of success long enough to
warrant their deployment.
Research Gap 6. We do not understand the speed with which
censors block new approaches. Thus, we lack the ability to
gauge the value of deploying low-overhead approaches with
known weaknesses.
We do have some information on this question. On March 8,
2013, Iran blocked most VPNs, forcing users to switch to
more sophisticated circumvention tools [123]. The Iranian
government adapted suﬃciently to these new tools for users to
complain of them no longer working within two months (by
May 5 [123]).
Another illustration involves two Tor incidents: Iran 2011/09
and Iran 2013/03. In the ﬁrst incident, Iran learned to ﬁnger-
print an abnormal TLS certiﬁcate lifetime used by Tor. It took
Iran about 1.5 years to ﬁngerprint the less odd but still static
and easily identiﬁable lifetime Tor used next.
Finally, while the research papers we examined lacked IDM
exploits, we note that this reﬂects an artifact of aforementioned
split of research into papers looking IDM and those looking
at channels proper, for which we only selected papers in the
second category for this detailed analysis.
B. Nature of Exploit Detection Activity
Houmansadr et al. distinguish between passive, reactive, and
proactive exploits [1].3 An exploit can passively monitor traﬃc
passing through the censor’s border (say), or interact with
clients and servers reactively to modify traﬃc or proactively by
producing traﬃc. For example, suppose that a circumvention
approach attempting to look like a normal web server reacts
diﬀerently to a request for a non-existent webpage [1]. The
censor could passively wait until a real user makes such a
request and the deviation naturally arises to detect it. Alter-
nately, the censor could reactively modify a request to point
to a non-existent page, which converts what might be a low
probability vulnerability into a high one. Another alternative
is to proactively probe the circumvention approach by sending
it such a request at the censor’s convenience.
3They call exploits “attacks” and reactive exploits “active attacks”.
925925
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
Description and where seen
Detect a feature of a packet that diﬀers from the cover protocol
Diﬀerent packet sizes for packets with ﬁxed length from Skype [1]
Absence of start-of-message ﬁelds of Skype UDP packets [1]
Diﬀerent ciphersuite for TLS handshake than Chrome on Linux [35]
Detect a feature of content that diﬀers from the cover protocol
Diﬀerent HTTP response length than Firefox downloading Amazon.com [29]
Check for discrepancies in the ﬁle-format semantics of PDF xrefs [1]
Detect packets produced by a probe that diﬀer from the cover protocol’s
Manipulating the tag ﬁeld in SIP OK to close a connection that normally would be kept open [1]
Verify standard supernode behavior by ﬂushing supernode cache [1]
Check for the correct response to HTTP GET request for an existing page [1]
Wrong response to HTTP GET request for non-existing page or wrong protocol [1]
Detect the presence of packets that the cover protocol would not produce
Detect the presence of packets from a TCP close or delay that Skype would not produce [1]
Detect the absence of packets that the cover protocol would produce
Absence of standard Skype control traﬃc [1]
Absence of standard Skype user traﬃc [1]
Absence of normal server replies to client [35]
Absence of expected Skype setup packets in response to network inferference [1]
Absence of expected SIP setup packets in response to malformed requests [1]
Absence of call termination after dropping SIP RTP packets [1]
Absence of response to odd HTTP requests [1]
Detect making connections in a way that the cover protocol does not
Connecting to a tainted IP during setup even if the channel does not [76]
Many long-lived connections to one bridge node vs. few short-lived [76]
Check for abnormal number of concurrent connections while downloading [29]
Has an abnormally large number of outgoing connections per session [27]
Many HTTP/Skype connections to a single server [1]
Diﬀerent number of TCP connections per session than Firefox downloading Amazon.com [29]
Having a non-standard connection duration [26, 48, 49]
Detect abnormal traﬃc feature (e.g., timing or size) distributions
Check for dependencies between supposedly separate connections [1]
Non-random-looking TLS handshake client nonce [15]
Non-random packet length distribution [24]
Diﬀerent number of HTTP request-response pairs per connection when downloading Amazon.com [29]
Diﬀerent distribution of packet lengths from normal traﬃc [18, 19, 22, 23, 48, 49]
Diﬀerent distribution of ﬂow sizes from normal TCP [19]
Diﬀerent distribution of connection times from normal TCP [19]
Diﬀerent distribution of interpacket arrival times or rate from normal traﬃc [1, 18, 22, 23, 30, 48, 49]
Diﬀerent average packet size than Skype [30]
Diﬀerent average diﬀerence in packet length over time from Skype voice [76]
Diﬀerent standard deviation of distribution of packet lengths from Skype voice [76]
Fits the pattern of pre-recorded traﬃc [1]
Diﬀerent n-grams distribution over packet lengths than normal traﬃc [34, 49]
Phase
Nature
Network loss
setup
setup
setup
use
use
passive
passive
passive
passive
passive
setup
subsidiary
subsidiary
subsidiary
reactive
proactive
proactive
proactive
setup
reactive
setup
use
setup
setup
setup
use
subsidiary
passive
passive
proactive
reactive
reactive
reactive
proactive
UB
n
n
OB&UB
UB
UB
OB
OB
n
n
OB
OB
OB
OB
OB
OB
OB
setup
use
use
use
setup
use
use
setup
setup
use
use
use
use
use
use
use
use
use
use
use
passive
passive
passive
passive
passive
passive
passive
passive/reactive
passive
passive
passive
passive
passive
passive
passive
passive
passive
passive
passive
passive
UB
n / UB
n / OB&UB
UB
UB
n / OB&UB
n / OB&UB
OB&UB
n
OB&UB
OB&UB
OB&UB
OB&UB
n / OB&UB
OB&UB
OB&UB
OB&UB
OB&UB
OB&UB
OB&UB
Classification of Exploits Inferred from Vulnerabilities Found in Papers. The notation is the same as in Table V. “Subsidiary” means that it is an active
exploit on how the approach behaves when not acting as a channel, such as in response to port scanning. The results of measurement loss may be inferred
from those of network loss: cases where neither would be blocked (“n”) become underblocking (“UB”). When there is not enough information to make a
deﬁnitive classiﬁcation, we separate the possibilities with “/”. We put exploits discussed in only the traﬃc analysis papers [1, 76] in grey.
TABLE VI
Proactive exploits can operate indiscriminately by scanning
the Internet looking for circumvention servers. However, given
the Internet’s size, we observe that such exploits tend to be
triggered by some other event. For example, a passive exploit
may identify suspicious traﬃc coming from a server, which
might then trigger a proactive probe to conﬁrm with higher
conﬁdence that the server is running a circumvention tool. The
conﬁrmation may then trigger the blacklisting of the server’s
IP address (as seen in China [70]). This overall attack starts
with a cheap, low-conﬁdence passive exploit, moves onto a
more expensive high-conﬁdence one, and ends with a high-
conﬁdence simple exploit that ﬁnally blocks traﬃc.
Table V shows real-world censors using passive and proac-
tive exploits, but not reactive ones.
We conjuncture that censors avoid reactive attacks since
such exploits must operate not just at line speed, like passive
ones, but also manipulate traﬃc at that speed. Thus, censors
may prefer to use proactive exploits of a vulnerability even
when a reactive exploit for it also exists.
Recommendation 4. Today’s landscape indicates that circum-
926926
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
ventors should concern themselves more with low-cost passive
and proactive exploits than reactive ones.
Table VI shows 5 reactive exploits (all from [1]) out of 37
exploits found in the papers examined, even after we discarded
reactive versions of proactive exploits.
C. Packet Loss
Lastly, we look at the robustness of vulnerabilities to lost
packets. A censor’s monitor can fail to observe a particular
packet for a ﬂow (whether benign or circumventing) due to
several reasons: the measurement apparatus cannot keep up
with the traﬃc stream and fails to capture the packet; a routing
change, or multipath routing, causes the packets to take a
route that does not transit the monitored link; or the packet is
genuinely lost by the network, such as due to congestion.
In the ﬁrst two instances, the loss is only from the per-
spective of the monitor, not from the client or server. For
either, suppose that allowed traﬃc normally includes a packet
absent from the circumventing traﬃc, a type of vulnerability
ﬂagged many times in Table VI. In this case, the apparent loss
will make allowed traﬃc look disallowed, and simple exploits
of the vulnerability will overblock. Exploits could attempt
to avoid such overblocking by not acting immediately and
checking for the presence of exculpatory packets over period
of time long enough to produce multiples instances of it, or, in
the case of proactive exploits, probing again. However, such
complexity adds storage costs, slows blocking, and could still
overblock in the face of multiple lost packets.
If instead the circumventing traﬃc has a packet not found in
allowed traﬃc, such missing packets will cause simple exploits
to underblock, which, per the empirical evidence presented
previously, censors tend to prefer to overblocking. More com-
plex vulnerabilities involving the distribution of some feature
over time may cause both over- and under-blocking over time.
On the other hand, genuine packet loss in some cases will
not particularly aﬀect the exploit. Such packets will register
as dropped to the end-points, often causing retransmission,
providing the exploit another detection opportunity.
Table V shows that real censors tend to use vulnerabilities
that produce underblocking but not overblocking for lost
packets. Table VI, on the other hand, shows papers focusing on
vulnerabilities that may produce overblocking for lost packets.
Recommendation 5. Censors use exploits for which packet
loss results in underblocking instead of overblocking. Circum-
ventors should protect against such exploits.
VIII. Research Agenda
Our empirical investigations of censors and circumventors
above has identiﬁed 6 research gaps and 5 recommendations.
We now consider future directions for research in more detail.
A. Guiding Abstractions
Researchers often beneﬁt from abstractions to guide their
work. We already discussed a few that provide perspectives
on the space of circumvention approaches: steganography vs.
polymorphism, setup vs. usage of channels, and the nature of
the exploit’s detection activity.
We now consider abstractions designed to guide the re-
searcher’s thinking when selecting how to evaluate an ap-
proach. We view these through the lens of the central question
for circumvention evaluation: How do we deﬁne success?
Since environments and use cases vary, we do not seek to
provide a ﬁxed list of criteria that approaches must consider.
Rather, we aim to illuminate the tradeoﬀs involved in adopting
various evaluation criteria by considering notions of success
concrete enough to serve as common guides, but ﬂexible
enough to adapt to diﬀerent environments and use cases.
For example, we might consider the volume of goodput that
a tool enables, where goodput refers to productive evading
traﬃc. If we view our overarching goal as resisting the
impediments to free communication that censorship imposes,
then we might well deem deployed approach A as doing better
in this regard than deployment B if, at the end of the day—
and for whatever reasons—A will allow users to successfully
conduct more overall circumventing traﬃc than B will.
We can reﬁne this abstraction based on the premise that
censors and evaders engage in an ongoing arms race with
an ebb and ﬂow largely determined by economic concerns.
That perspective leads us to consider an abstract metric
of success based on costs: the amount of goodput that an
approach provides at a given cost to the advocates who must
select among proposed approaches. This metric highlights that
circumvention approaches are tools for converting resources
(costs) into products (goodput).
We consider such metrics as abstract for two reasons. First,
while intuitive and recognizable enough to help us organize
the problem space, they are parametric in how we calculate
goodput and cost. In this framework, just what constitutes
goodput is by design a value judgement: a dissident com-
municating a single picture from a demonstration might have
much more productive value than thousands of users accessing
banned YouTube videos. Similarly, diﬀerent advocates may
assign diﬀerent prices to goodput for the same approach if
they value resources diﬀerently.
Second, we do not expect evaluations to actually compute
these values, since they require information often unknown.
But these abstract metrics provide fruitful touchstones: they
underscore how for assessing utility of an approach many
considerations can come into play beyond purely technical
concerns such as worst-case blocking vulnerabilities. From
this perspective, we can rate the concrete evaluation criteria
such as those identiﬁed in our survey based on how well in
isolation and in combination, they predict abstract metrics such
as goodput-per-cost. We might then look to approach-speciﬁc
evaluations to provide evidence that an approach could in
practice drive up a censor’s costs.
Our perspective challenges the narrower views of some prior
evaluations. By examining total cost, we remind the evaluator
that every aspect of the traﬃc produced by the evasion
approach matters, not simply those considered by its designer.
We seek with such a universal view to encourage designers to
widen their focus and identify often simple countermeasures
that have undermined past approaches.
927927
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
While as stated we pose the cost-of-goodput metric solely in
terms of an advocate’s costs, it naturally extends to the costs of
censors and users. An approach inexpensively blocked by the
censor will produce no goodput for the advocate’s investment;
an approach whose high cost to users drives them away will
likewise make for a poor investment.
This relationship also highlights possibilities for cost shift-
ing. Users could promote approaches they value by paying
advocates to maintain them (such as reﬂected by the common
practice of many paid VPN services).
Research Gap 7. Little research exists in informing censor-
ship circumvention approaches with cost shifting. Approaches
aiming to also provide anonymity may pose additional re-
search questions in this direction given the challenges of
anonymous billing.
B. Understanding Censors and Their Technical Measures
Since practical evaluation criteria will depend in part upon
the nature of the relevant censors, we need good methods of
understanding censors to determine the most eﬀective ways to
evaluate circumvention tools. As noted above (Gap 1), little
research examines how censors operate.
To this end, the circumvention community would beneﬁt
from tools that systematically experiment on censors to de-
termine how they block traﬃc from a given circumvention
technology. Such tools will not only speed up the response
to censorship events, but also complement in situ and retro-
spective measurement studies. The improved models learned
from the responses of censors will enable developers to design
evasion approaches that better anticipate future censorship
countermeasures.
Furthermore, such tools would allow circumventors to
respond more quickly to new censorship attacks. When a
censor blocks a tool, circumvention developers respond by
determining the features that the censor has started using to
distinguish evading traﬃc from allowed traﬃc. For example,
currently the Tor project mostly relies on end-users under a
censorship regime reporting blocking events, and then ﬁnding
a ﬁx by tweaking evading traﬃc until it gets past the censor,
making adjustments in an ad hoc fashion. This unsystematic
process proves time-consuming and provides only narrow
illumination of the censor’s behavior. A survey we conducted
of Tor’s issues tracker [148] found that it can take from a
couple of hours (e.g., Iran’s DPI exploit based on certiﬁcate
lifetime) to a couple of months (e.g., China’s active probing of
bridges) to identify the censorship mechanism. It also requires
signiﬁcant time and burdens the developer community. Thus,
a debugging-like tool to identify how a censor blocks a given
evasion tool would have signiﬁcant utility.
C. Understanding the Arms Race
As noted above (Gap 6), we know little about how long it
takes for a censor to deploy new technology in response to
a new circumvention approach. Thus, it is diﬃcult to know
whether easy-come-easy-go approaches proposed by others
would be worth the eﬀort of deployment [58, 59, 149]. The
circumvention community would beneﬁt from automated sys-
tems for detecting new censorship actions, which would enable
early detection of censorship events, detailed measurements as
these events unfold, and comprehensive analyses to understand
the speed of the arms race.
The community would also beneﬁt from a better understand-
ing of the internal dynamics of the organizations that imple-
ment the censor’s policies. Understanding their organizational
structure could lead to approaches that cut across it, leading
to a diﬀusion of responsibility and perhaps delayed responses.
the responses
of censors appear as driven by political developments as
technical. Much as they ratchet up censorship by deploying
new attacks around politically sensitive times, circumventors
could hold back new approaches for release during those times,
helping channels to operate when they are needed most.
Furthermore, as observed in Section IV,
D. Evaluation Engines
Moving forward, researchers could develop evaluation en-
gines that implement recommendations such as those we frame
in this work. In particular, researchers could create automated
evaluation systems that identify the types of vulnerabilities
exploited by real censors. As discussed before Recommen-
dation 5, academic work has largely examined complex but
well-known features, such as packet size distributions and
entropy (e.g., [18, 19, 22–24, 26, 34, 41, 48, 49, 52]). The
community would beneﬁt from engines that identify subtle
but simple vulnerabilities, such as using telltale cipher suites.
In particular, the employment of machine learning with an
emphasis on using it to illuminate feature selection could
provide a useful starting point for such engines.
IX. Conclusion
We have focused in this work on comparing theory to
practice in order to stimulate research addressing the circum-
vention problems of today. We do not mean to suggest that
forward-looking research serves no purpose; clearly, censors
continually evolve toward increasingly sophisticated blocking,
and thus the future will require increasingly sophisticated
approaches to circumvention. However, our examination high-
lights signiﬁcant gaps in the research literature. Among these,
we note that the ﬁeld lacks methods of evaluating approaches
against vulnerabilities that are diﬃcult to ﬁnd, but easy for the
censor to exploit once found, like those used in practice. Given
the limited resources available for research, our survey points
up signiﬁcant concerns that the current focus on sophisticated
attacks that could arise in the future may come at the expense
of more eﬀectively addressing the realistic attacks of today.
Acknowledgements. We thank the numerous tool authors
who responded to our questions about their evaluations and
the anonymous reviewers of our submission. We gratefully
acknowledge funding support from the Freedom 2 Connect
Foundation, Intel, the National Science Foundation (grants
0424422, 1237265, 1223717, and 1518918), the Open Tech-
nology Fund, the US Department of State Bureau of Democ-
racy, Human Rights, and Labor. The opinions in this paper are
those of the authors and do not necessarily reﬂect the opinions
of any funding sponsor or the United States Government.
928928
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:11:18 UTC from IEEE Xplore.  Restrictions apply. 
References
[1] A. Houmansadr, C. Brubaker, and V. Shmatikov, “The parrot is dead:
Observing unobservable network communications,” in 2013 IEEE
Symp. on Security and Privacy, ser. SP ’13.
IEEE Computer Society,
2013, pp. 65–79.
[2] “BridgeDB,” https://bridges.torproject.org/.
[3] P. Lincoln, I. Mason, P. Porras, V. Yegneswaran, Z. Weinberg, J. Mas-
sar, W. Simpson, P. Vixie, and D. Boneh, “Bootstrapping communica-
tions into an anti-censorship system,” in Free and Open Communica-
tions on the Internet. USENIX, 2012.
[4] N. Feamster, M. Balazinska, G. Harfst, H. Balakrishnan, and D. R.
Karger, “Infranet: Circumventing web censorship and surveillance,” in
USENIX Security Symp., 2002, pp. 247–262.
[5] T. Ruﬃng, J. Schneider, and A. Kate, “Identity-based steganography
and its applications to censorship resistance,” in Hot Topics in Privacy
Enhancing Technologies. Springer, 2013.
[6] L. Invernizzi, C. Kruegel, and G. Vigna, “Message In A Bottle: Sailing
past censorship,” in Annual Computer Security Applications Conf.
ACM, 2013.
[7] C. Connolly, P. Lincoln, I. Mason, and V. Yegneswaran, “TRIST:
Circumventing censorship with transcoding-resistant image steganog-
raphy,” in Free and Open Communications on the Internet. USENIX,
2014.
[8] Ludde, uau, The 8472, Parg, and Nolar, “Message stream encryption,”
https://wiki.vuze.com/w/Message Stream Encryption, Feb. 2006, ac-
cessed Aug. 10, 2015.
[9] S. Ho, “Feed Over Email,” https://code.google.com/p/foe-project/.
[10] “Mailmyweb,” https://www.mailmyweb.com/index.php/en/.
[11] S. Cao, L. He, Z. Li, and Y. Yang, “SkyF2F: Censorship resistant via
skype overlay network,” in Intl. Conf. on Information Engineering.
IEEE, 2009, pp. 350–354.
[12] S. Burnett, N. Feamster, and S. Vempala, “Chipping away at censorship
ﬁrewalls with user-generated content,” in USENIX Security Symp.
USENIX, 2010.
[13] A. Houmansadr, G. T. K. Nguyen, M. Caesar, and N. Borisov,
“Cirripede: Circumvention infrastructure using router redirection with
plausible deniability,” in Computer and Communications Security.
ACM, 2011, pp. 187–200.
[14] J. Karlin, D. Ellard, A. W. Jackson, C. E. Jones, G. Lauer, D. P.
Mankins, and W. T. Strayer, “Decoy routing: Toward unblockable
Internet communication,” in Free and Open Communications on the
Internet. USENIX, 2011.
[15] E. Wustrow, S. Wolchok, I. Goldberg, and J. A. Halderman, “Telex:
Anticensorship in the network infrastructure.” in USENIX Security
Symp., 2011.
[16] Q. Wang, X. Gong, G. T. K. Nguyen, A. Houmansadr, and N. Borisov,
“CensorSpoofer: Asymmetric communication using IP spooﬁng for
censorship-resistant web browsing,” in Computer and Communications
Security. ACM, 2012.
[17] D. Fiﬁeld, N. Hardison, J. Ellithorpe, E. Stark, D. Boneh, R. Dingle-
dine, and P. Porras, “Evading censorship with browser-based proxies,”
in 12th Intl. Conf. on Privacy Enhancing Technologies, ser. PETS’12.
Springer-Verlag, 2012, pp. 239–258.
[18] H. Mohajeri Moghaddam, B. Li, M. Derakhshani, and I. Goldberg,
“SkypeMorph: Protocol obfuscation for Tor bridges,” in 2012 ACM
conf. on Computer and communications security, 2012, pp. 97–108.
[19] Z. Weinberg, J. Wang, V. Yegneswaran, L. Briesemeister, S. Cheung,
F. Wang, and D. Boneh, “StegoTorus: A camouﬂage proxy for the Tor
anonymity system,” in 2012 ACM conf. on Computer and communica-
tions security. ACM, 2012, pp. 109–120.
[20] G. Kadianakis and N. Mathewson, “obfs2 (the twobfuscator),”
Jan. 2011, https://gitweb.torproject.org/pluggable-transports/obfsproxy.
git/tree/doc/obfs2/obfs2-protocol-spec.txt.
[21] ——, “obfs3 (the threebfuscator),” Jan. 2013, https://gitweb.torproject.
org/pluggable-transports/obfsproxy.git/tree/doc/obfs3/obfs3-protocol-
spec.txt.
[22] Y. Angel and P. Winter, “obfs4 (the obfourscator),” May 2014,
https://gitweb.torproject.org/pluggable-transports/obfs4.git/tree/doc/
obfs4-spec.txt.
[23] P. Winter, T. Pulls, and J. Fuss, “ScrambleSuit: A polymorphic net-
work protocol to circumvent censorship,” in Wksp. on Privacy in the
Electronic Society. ACM, 2013, uRL: http://www.cs.kau.se/philwint/
pdf/wpes2013.pdf.
[24] B. Wiley, “Dust: A blocking-resistant Internet
transport protocol,”
Available at http://blanu.net/Dust.pdf, 2011.
[25] “GoAgent,” https://github.com/goagent/goagent.
[26] D. Fiﬁeld, C. Lan, R. Hynes, P. Wegmann, and V. Paxson, “Blocking-
resistant communication through domain fronting,” Privacy Enhancing
Technologies, vol. 1, no. 2, 2015.
[27] D. Fiﬁeld, G. Nakibly, and D. Boneh, “OSS: Using online scanning
services for censorship circumvention,” in Privacy Enhancing Tech-
nologies Symp. Springer, 2013.
[28] K. P. Dyer, S. E. Coull, T. Ristenpart, and T. Shrimpton, “Protocol
misidentiﬁcation made easy with format-transforming encryption,” in
Computer and Communications Security. ACM, 2013.
[29] K. P. Dyer, S. E. Coull, and T. Shrimpton, “Marionette: A pro-
grammable network traﬃc obfuscation system,” in 24th USENIX Se-
curity Symposium (USENIX Security 15), Aug. 2015.
[30] A. Houmansadr, T. J. Riedl, N. Borisov, and A. C. Singer, “I want my
voice to be heard: IP over Voice-over-IP for unobservable censorship
circumvention.” in NDSS, 2013.
[31] W. Zhou, A. Houmansadr, M. Caesar, and N. Borisov, “SWEET:
Serving the web by exploiting email tunnels,” in Hot Topics in Privacy
Enhancing Technologies. Springer, 2013.
[32] D. Nobori and Y. Shinjo, “VPN Gate: A volunteer-organized public
VPN relay system with blocking resistance for bypassing government
censorship ﬁrewalls,” in Networked Systems Design and Implementa-
tion. USENIX, 2014.
[33] B. Jones, S. Burnett, N. Feamster, S. Donovan, S. Grover, S. Gu-
nasekaran, and K. Habak, “Facade: High-throughput, deniable censor-
ship circumvention using web search,” in Free and Open Communica-
tions on the Internet. USENIX, 2014.
[34] S. Li, M. Schliep, and N. Hopper, “Facet: Streaming over videocon-
ferencing for censorship circumvention,” in WPES, 2014.
[35] E. Wustrow, C. M. Swanson, and J. A. Halderman, “TapDance: End-
to-middle anticensorship without ﬂow blocking,” in USENIX Security
Symp. USENIX, 2014.
[36] C. Brubaker, A. Houmansadr, and V. Shmatikov, “CloudTransport:
Using cloud storage for censorship-resistant networking,” in Privacy
Enhancing Technologies Symp. Springer, 2014.
[37] “uProxy,” https://www.uproxy.org/.
[38] J. Marshall, “CGIProxy,” http://www.jmarshall.com/tools/cgiproxy/.
[39] Ultrareach Internet Corporation, “Ultrasurf,” http://ultrasurf.us/.
[40] Dynamic Internet Technology,
Inc., “Freegate,” http://dit-inc.us/
freegate.html.
[41] “Psiphon 3 circumvention system README,” https://bitbucket.org/
[44] “GTunnel,” http://www.internetfreedom.org/GTunnel.html.
[45] AnchorFree, “Hotspot Shield,” http://www.hotspotshield.com/.
[46] “JAP,” https://anon.inf.tu-dresden.de/index en.html.
[47] “Your Freedom,” https://www.your-freedom.net/.
[48] B. Hahn, R. Nithyanand, P. Gill, and R. Johnson, “Games without
frontiers: Investigating video games as a covert channel,” in IEEE
European Symp. on Security and Privacy (Euro S&P), 2016, to appear.
ArXiv report available: http://arxiv.org/abs/1503.05904.
[49] P. Vines and T. Kohno, “Rook: Using video games as a low-bandwidth
censorship resistant communication platform,” 2015.
[50] J. Holowczak and A. Houmansadr, “CacheBrowser: Bypassing Chinese
censorship without proxies using cached content,” in Computer and
Communications Security. ACM, 2015.
[51] Simurgh Proxy, Inc., “Green Simurgh,” http://simurghesabz.net/.
[52] Y. Wang, P. Ji, B. Ye, P. Wang, R. Luo, and H. Yang, “GoHop:
Personal VPN to defend from censorship,” in Intl. Conf. on Advanced
Communication Technology.