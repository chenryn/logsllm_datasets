to be converted into an MPC-compatible input. To do so, we
formulate a gadget that converts ciphertext to arithmetic shares.
The general idea behind the protocol is inspired by arithmetic
sharing protocols [23, 27].
Gadget 3. For m parties, each party having the public
key PK and a share of the secret key SK, given public
ciphertext EncPK(a), convert a into m shares ai ∈ Zp
such that a ≡ (cid:2)
ai mod p. Each party Pi receives secret
share ai and does not learn the original secret value a.
Each party uses this gadget
Gadget usage.
to convert
EncPK(wi) and EncPK(ui) into input shares and compute
the soft threshold function using MPC (in our case, SPDZ).
We denote p as the public modulus used by SPDZ.
Protocol. The protocol proceeds as follows:
1) Each party Pi generates a random value ri ∈ [0, 2
|p|+κ]
and encrypts it, where κ is a statistical security parameter.
Each party should also generate an interval plaintext proof
of knowledge of ri, then publish EncPK(ri) along with the
proofs.
2) Each party Pi takes as input the published {EncPK(rj)}m
j=1
and compute the product with EncPK(a). The result is
c = EncPK(a +
j=1 rj).
(cid:2)m
3) All parties jointly decrypt c to get plaintext b.
4) Party 0 sets a0 = b − r0 mod p. Every other party sets
ai ≡ −ri mod p.
5) Each party publishes EncPK(ai) as well as an interval proof
of plaintext knowledge.
(cid:24)(cid:20)(cid:18)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
and uk
2) Coordination: The ADMM coordination step takes in
wk+1
i , and outputs zk+1. The z update requires
i
computing the soft-threshold function (a non-linear function),
so we express it in MPC. Additionally, since we are doing
ﬁxed point integer arithmetic as well as using a relatively small
prime modulus for MPC (256 bits in our implementation), we
need to reduce the scaling factors accumulated on wk+1
during
plaintext-ciphertext matrix multiplication. We currently perform
this operation inside MPC as well.
i
3) Conversion from MPC: After the MPC computation, each
party receives shares of z and its MAC shares, as well as shares
of wi and its MAC shares. It is easy to convert these shares
back into encrypted form simply by encrypting the shares,
publishing them, and summing up the encrypted shares. We
can also calculate uk+1
this way. Each party also publishes
interval proofs of knowledge for each published encrypted
cipher. Finally, in order to verify that they are indeed valid
SPDZ shares (the speciﬁc protocol is explained in the next
section), each party also publishes encryptions and interval
proofs of all the MACs.
i
E. Model release
1) MPC conversion veriﬁcation: Since we are combining
two protocols (homomorphic encryption and MPC), an attacker
can attempt to alter the inputs to either protocol by using
different or inconsistent attacker-chosen inputs. Therefore,
before releasing the model, the parties must prove that they
correctly executed the ciphertext to MPC conversion (and vice
versa). We use another gadget to achieve this.
Gadget 4. Given public parameters: encrypted value
EncPK(a), encrypted SPDZ input shares EncPK(bi), en-
crypted SPDZ MACs EncPK(ci), and interval proofs of
plaintext knowledge, verify that
i bi mod p, and
2) bi are valid SPDZ shares and ci’s are valid MACs on
1) a ≡ (cid:2)
bi.
i
i
Gadget usage. We apply Gadget 4 to all data that needs to
be converted from encrypted ciphers to SPDZ or vice versa.
More speciﬁcally, we need to prove that (1) the SPDZ input
shares are consistent with EncPK(wk+1
) that is published
from each party, and (2) the SPDZ shares for wk+1
and zk
are authenticated by the MACs.
Protocol. The gadget construction proceeds as follows:
1) Each party veriﬁes
that EncPK(a), EncPK(bi) and
EncPK(ci) pass the interval proofs of knowledge. For
example, bi and ci need to be within [0, p].
well as Ed = EncPK(a − (cid:2)
2) Each party homomorphically computes EncPK(
3) Each party randomly chooses ri ∈ [0, 2
|a|+|κ|
], where
κ is again a statistical security parameter, and publishes
EncPK(ri) as well as an interval proof of plaintext knowl-
edge.
i bi), as
i bi).
(cid:2)
(cid:10)
4) Each party calculates Ef = Ed
EncPK((a − (cid:2)
log |m| + |p| + |a| + |κ| < |n|.
i bi) +
(cid:2)
i EncPK(ri)p =
i(ri · p)). Here we assume that
5) All parties participate in a joint decryption protocol to
decrypt Ef obtaining ef .
6) Every party individually checks to see that ef is a multiple
of p. If this is not the case, abort the protocol.
7) The parties release the SPDZ global MAC key α.
8) Each
calculates EncPK(α(
(cid:2)
EncPK(
(cid:2)
party
ci).
δ) ≡ (cid:2)
ci mod p.
9) Use the same method in steps 2 – 6 to prove that α(
bi + δ))
(cid:2)
and
bi +
The above protocol is a way for parties to verify two
things. First, that the SPDZ shares indeed match with a
previously published encrypted value (i.e., Gadget 3 was
executed correctly). Second, that the shares are valid SPDZ
shares. The second step is simply verifying the original SPDZ
relation among value share, MAC shares, and the global key.
Note that we cannot verify these relations by simply releasing
the plaintext data shares and their MACs since the data shares
correspond to the intermediate weights. Furthermore, the shares
need to be equivalent in modulo p, which is different from the
Paillier parameter N. Therefore, we use an alternative protocol
to test modulo equality between two ciphertexts, which is the
procedure described above in steps 2 to 6.
Since the encrypted ciphers come with interval proofs of
plaintext knowledge, we can assume that a ∈ [0, l]. If two
ciphertexts encrypt plaintexts that are equivalent to each other,
they must satisfy that a ≡ b mod p or a = b + ηp. Thus, if
we take the difference of the two ciphertexts, this difference
must be ηp. We could then run the decryption protocol to test
that the difference is indeed a multiple of p.
i bi mod p, simply releasing the difference could
still reveal extra information about the value of a. Therefore, all
parties must each add a random mask to a. In step 3, ri’s are
generated independently by all parties, which means that there
must be at least one honest party who is indeed generating a
random number within the range. The resulting plaintext thus
i bi with the statistical
i bi mod p, then the protocol reveals
i bi mod p. This is safe because
i bi mod p is when an adversary
misbehaves and alters its inputs, and the result is independent
from the honest party’s behavior.
statistically hides the true value of a−(cid:2)
parameter κ. If a (cid:10)≡ (cid:2)
the difference between a−(cid:2)
the only way to reveal a−(cid:2)
2) Weight vector decryption: Once all SPDZ values are
veriﬁed, all parties jointly decrypt z and the ﬁnal weights are
released to everyone.
If a ≡ (cid:2)
VII. EXTENSIONS TO OTHER MODELS
Though we used LASSO as a running example, our tech-
niques can be applied to other linear models like ordinary
least-squares linear regression, ridge regression, and elastic net.
Here we show the update rules for ridge regression, and leave
its derivation to the readers.
Ridge regression solves a similar problem as LASSO, except
with L2 regularization. Given a dataset (X, y) where X
(cid:24)(cid:20)(cid:19)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
is the feature matrix and y is the prediction vector, ridge
2 + λ(cid:5)w(cid:5)2. The
regression optimizes arg minw
update equations for ridge regression are:
(cid:5)Xw − y(cid:5)2
1
2
wk+1
i = (XT
i Xi + ρI)
i yi + ρ(zk − uk
−1(XT
i ))
+ (ρ/2)(cid:5)wi − zk + uk
i (cid:5)2
2λ/m + ρ ( ¯wk+1 + ¯uk)
i + xk+1
i − zk+1
ρ
2
zk+1 =
uk+1
i = uk
The local update is similar to LASSO, while the coordination
update is a linear operation instead of the soft threshold function.
Elastic net, which combines L1 and L2 regularization, can
therefore be implemented by combining the regularization
terms from LASSO and ridge regression.
VIII. EVALUATION
We implemented Helen in C++. We utilize the SPDZ
library [1], a mature library for maliciously secure multi-
party computation, for both the baseline and Helen. In our
implementation, we apply the Fiat-Shamir heuristic to our zero-
knowledge proofs [32]. This technique is commonly used in
implementations because it makes the protocols non-interactive
and thus more efﬁcient, but assumes the random oracle model.
We compare Helen’s performance to a maliciously secure
baseline that trains using stochastic gradient descent, similar to
SecureML [54]. Since SecureML only supports two parties in
the semihonest setting, we implemented a similar baseline using
SPDZ [27]. SecureML had a number of optimizations, but they
were designed for the two-party setting. We did not extend
those optimizations to the multi-party setting. We will refer
to SGD implemented in SPDZ as the “secure baseline” (we
explain more about the SGD training process in Section VIII-A).
Finally, we do not benchmark Helen’s Paillier key setup phase.
This can be computed using SPDZ itself, and it is ran only
once (as long as the party conﬁguration does not change).
A. Experiment setup
We ran our experiments on EC2 using r4.8xlarge instances.
Each machine has 32 cores and 244 GiB of memory. In order to
simulate a wide area network setting, we created EC2 instances
in Oregon and Northern Virginia. The instances are equally
split across these two regions. To evaluate Helen’s scalability,
we used synthetic datasets that are constructed by drawing
samples from a noisy normal distribution. For these datasets,
we varied both the dimension and the number of parties. To
evaluate Helen’s performance against the secure baseline, we
benchmarked both systems on two real world datasets from
UCI [29].
Training assumptions. We do not tackle hyperparameter
tuning in our work, and also assume that the data has been nor-
malized before training. We also use a ﬁxed number of rounds
(10) for ADMM training, which we found experimentally using
the real world datasets. We found that 10 rounds is often enough
for the training process to converge to a reasonable error rate.
Recall that ADMM converges in a small number of rounds
because it iterates on a summary of the entire dataset. In
contrast, SGD iteratively scans data from all parties at least
once in order to get an accurate representation of the underlying
distributions. This is especially important when certain features
occur rarely in a dataset. Since the dataset is very large, even
one pass already results in many rounds.
MPC conﬁguration. As mentioned earlier, SPDZ has two
phases of computation: an ofﬂine phase and an online phase.
The ofﬂine phase can run independently of the secure function,
but the precomputed values cannot be reused across multiple
online phases. The SPDZ library provides several ways of
benchmarking different ofﬂine phases, including MASCOT [46]
and Overdrive [47]. We tested both schemes and found
Overdrive to perform better over the wide area network. Since
these are for benchmarking purposes only, we decided to
estimate the SPDZ ofﬂine phase by dividing the number of
triplets needed for a circuit by the benchmarked throughput. The
rest of the evaluation section will use the estimated numbers
for all SPDZ ofﬂine computation. Since Helen uses parallelism,
we also utilized parallelism in the SPDZ ofﬂine generation
by matching the number of threads on each machine to the
number of cores available.
On the other hand, the SPDZ online implementation is not
parallelized because the API was insufﬁcient to effectively
express parallelism. We note two points. First, while paralleliz-
ing the SPDZ library will result in a faster baseline, Helen
also utilizes SPDZ, so any improvement to SPDZ also carries
over to Helen. Second, as shown below, our evaluation shows
that Helen still achieves signiﬁcant performance gains over
the baseline even if the online phase in the secure baseline is
inﬁnitely fast.
Finally, the parameters we use for Helen are: 128 bits for
the secure baseline’s SPDZ conﬁguration, 256 bits for the
Helen SPDZ conﬁguration, and 4096 bits for Helen’s Paillier
ciphertext.
B. Theoretic performance
Baseline
Helen
Secure SGD
SVD decomposition
SVD proofs
MPC ofﬂine
Model compute
C · m2 · n · d
c1 · n · d2
c1 · m2 · d
c1 · m · d2 + c2 · d3
c1 · m2 · d + c2 · d2 + c3 · m · d
TABLE I: Theoretical scaling (complexity analysis) for SGD
baseline and Helen. m is the number of parties, n is the number
of samples per party, d is the dimension.
Table I shows the theoretic scaling behavior for SGD and
Helen, where m is the number of parties, n is the number
of samples per party, d is the dimension, and C and ci are
constants. Note that ci’s are not necessarily the same across the
different rows in the table. We split Helen’s input preparation
phase into three sub-components: SVD (calculated in plaintext),
SVD proofs, and MPC ofﬂine (since Helen uses SPDZ during
the model compute phase, we also need to run the SPDZ ofﬂine
phase).
(cid:24)(cid:20)(cid:20)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
number of parties m. The MPC ofﬂine phase scales quadratic
in m, but its effects are not very visible for a small number of
parties. The model compute phase is dominated by the linear
scaling in m because the quadratic scaling factor isn’t very
visible for a small number of parties.
Finally, we also ran a microbenchmark to understand Helen’s
network and compute costs. The experiment used 4 servers and
a synthetic dataset with 50 features and 100K samples per party.
We found that the network costs account for approximately