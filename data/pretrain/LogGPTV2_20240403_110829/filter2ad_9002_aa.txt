**作者：时钟@RainSec  
本文为作者投稿，Seebug Paper 期待你的分享，凡经采用即有礼品相送！ 投稿邮箱：PI:EMAIL**
## go-fuzz
> Go-fuzz的原理很多都是基于AFL，这里只分析了一些它独特的地方，收获很多，也希望可以和大家交流，如有分析错误还望交流指正。
go-fuzz是google开源的一款go语言fuzz框架，它和AFL很大的一个不同是在于，AFL通常通过对未修改的文件的输入进行操作，而go-fuzz需要你编写一个Fuzz函数，go-fuzz通过不断的调用该函数来进行fuzz，前者通常会为每一个输入创建一个新的进程，后者则是不断的调用Fuzz函数因此不需要经常启动或者重启进程。
## 什么是覆盖引导型Fuzz
覆盖引导型Fuzz通过代码覆盖率信息来决定一个突变是否有效，如果代码覆盖率增长就保存该输入并对其进行持续变异，否则就丢弃该变异：
## 源码解析
### go-fuzz-build模块
该模块的主要作用在于将需要测试的包信息和测试用例信息打包方便进行测试。
  1. 利用PProf进行性能分析
  2. 加载选中的go语言包和github.com/dvyukov/go-fuzz/go-fuzz-dep这个fuzz材料包
  3. 遍历加载的go语言包里面所有的函数名查找所有的名为Fuzz的函数，同时进行签名认证，但是Fuzz函数的个数应该大于0同时小于等于255
  4. 获取环境变量，大多是和go有关的环境变量.
  5. 加载go语言标准库
  6. 忽略一些标准库中的包和github.com/dvyukov/go-fuzz/go-fuzz-dep这个包，因为没有理由进行fuzz测试，为了避免陷入循环（具体为啥我也不是很清楚）
  7. 在/tmp下创建临时文件夹保存需要使用的tools和包
  8. 接下来就是很高阶的语法树等的建立过程，这个过程中会使用gatherLiterals获取到你提供的初始材料
  9. 获取到需要fuzz的包的具体信息，进而可以生成go-fuzz的元数据
  10. 将存储信息的cover.exe和sonar.exe已经metadata打包生成zip文件夹
### 语法树插桩实现
go语言不同于C语言可以as等汇编工具来较为方便的实现编译时插桩（具体可以参考AFL的插桩方式），为了实现go语言的编译时插桩，我们首先要了解go语言整体的编译流程：
  1. 词法与语法分析
  2. 类型检查
  3. 中间代码生成
  4. 机器码生成
那么其实大致就可以看出比较理想的地方就是词法与语法分析的时候对抽象语法书进行插桩了，同时go标准库也提供了scanner，ast和token等相关库来帮助很好的扫描，解析和创建相关抽象语法树，在整个插桩的过程中其实是把go的包一个个遍历插桩的，然后因为go-fuzz不允许导入main包，其实是因为它在插桩完成之后会自己加入相关的main函数。
在go-fuzz-build中实现了结构体File和结构体Sonar，这两个结构体都实现了自己的Visit()函数用来遍历相关的语法树：
    type File struct {
        fset     *token.FileSet
        pkg      string
        fullName string
        astFile  *ast.File
        blocks   *[]CoverBlock
        info     *types.Info
    }
    type Sonar struct {
        fset     *token.FileSet
        fullName string
        pkg      string
        blocks   *[]CoverBlock
        info     *types.Info
    }
在整个的build的过程中也会生成coverBin和sonarBin两个文件分别对应上述两个结构体的语法树遍历函数执行结果。
#### File遍历
在生成coverBin的时候使用的是File结构体对应的Visit遍历函数，不过在开始遍历之前会通过自身实现的addImport来实现go-fuzz-dep包相关内容的导入：
> file.addImport("go-fuzz-dep", fuzzdepPkg, "CoverTab")
    func (f *File) addImport(path, name, anyIdent string) {
        newImport := &ast.ImportSpec{
            Name: ast.NewIdent(name),
            Path: &ast.BasicLit{
                Kind:  token.STRING,
                Value: fmt.Sprintf("%q", path),
            },
        }
        impDecl := &ast.GenDecl{
            Lparen: f.astFile.Name.End(),
            Tok:    token.IMPORT,
            Specs: []ast.Spec{
                newImport,
            },
            Rparen: f.astFile.Name.End(),
        }
        // Make the new import the first Decl in the file.
        astFile := f.astFile
        astFile.Decls = append(astFile.Decls, nil)
        copy(astFile.Decls[1:], astFile.Decls[0:])
        astFile.Decls[0] = impDecl
        astFile.Imports = append(astFile.Imports, newImport)
        // Now refer to the package, just in case it ends up unused.
        // That is, append to the end of the file the declaration
        //  var _ = _cover_atomic_.AddUint32
        reference := &ast.GenDecl{
            Tok: token.VAR,
            Specs: []ast.Spec{
                &ast.ValueSpec{
                    Names: []*ast.Ident{
                        ast.NewIdent("_"),
                    },
                    Values: []ast.Expr{
                        &ast.SelectorExpr{
                            X:   ast.NewIdent(name),
                            Sel: ast.NewIdent(anyIdent),
                        },
                    },
                },
            },
        }
        astFile.Decls = append(astFile.Decls, reference)
    }
观察源码其实逻辑也很简单，首先创建了一个基本声明信息节点来将相关的包导入原本的语法树中，同时为了避免导入包但是未使用，所以导入简单的声明语句。导入完成之后使用ast.Walk()来遍历语法树，该函数会调用File结构体对应的Visit函数。
    // 源码太长，只贴部分
    func (f *File) Visit(node ast.Node) ast.Visitor {
        switch n := node.(type) {
        case *ast.FuncDecl:
            if n.Name.String() == "init" {
                // Don't instrument init functions.
                // They run regardless of what we do, so it is just noise.
                return nil
            }
        case *ast.GenDecl:
            if n.Tok != token.VAR {
                return nil // constants and types are not interesting
            }
        case *ast.BlockStmt: // {}中间的语句
            // If it's a switch or select, the body is a list of case clauses; don't tag the block itself.
            if len(n.List) > 0 {
                switch n.List[0].(type) {
                case *ast.CaseClause: // switch
                    for _, n := range n.List {
                        clause := n.(*ast.CaseClause)
                        clause.Body = f.addCounters(clause.Pos(), clause.End(), clause.Body, false)
                    }
                    return f
                case *ast.CommClause: // select
                    for _, n := range n.List {
                        clause := n.(*ast.CommClause)
                        clause.Body = f.addCounters(clause.Pos(), clause.End(), clause.Body, false)
                    }
                    return f
                }
            }
            n.List = f.addCounters(n.Lbrace, n.Rbrace+1, n.List, true) // +1 to step past closing brace.
    ......
    }
可以看出在遍历语法树的过程中对节点的类型进行了判断，然后对{}中间的内容进行一个判断和插桩，具体的插桩函数如下：
    func (f *File) addCounters(pos, blockEnd token.Pos, list []ast.Stmt, extendToClosingBrace bool) []ast.Stmt {
        // Special case: make sure we add a counter to an empty block. Can't do this below
        // or we will add a counter to an empty statement list after, say, a return statement.
        if len(list) == 0 {
            return []ast.Stmt{f.newCounter(pos, blockEnd, 0)}
        }
        // We have a block (statement list), but it may have several basic blocks due to the
        // appearance of statements that affect the flow of control.
        var newList []ast.Stmt
        for {
            // Find first statement that affects flow of control (break, continue, if, etc.).
            // It will be the last statement of this basic block.
            var last int
            end := blockEnd
            for last = 0; last  Counter是作者自定义的一种插桩计数器，这种计数器主要包括两个部分:
>
>   1.
> 对于每个包的File的结构体都维护了一个*[]CoverBlock，每次增加Counter都会在这个数组里面增加一个CoverBlock里面记录了插桩语法树的位置以及内部是否还包含多少其他声明。
>   2. 一个是ast.IncDecStmt节点，这个是newCounter()函数的返回值
>
如果body不为空就找到所有影响控制流的声明，比如if，switch, break
,goto等都会开启或者中断一个新的控制流，找到边界声明之后判断其是否属于刚才的类型：
    func (f *File) endsBasicSourceBlock(s ast.Stmt) bool {
        switch s := s.(type) {
        case *ast.BlockStmt:
            // Treat blocks like basic blocks to avoid overlapping counters.
            return true
        case *ast.BranchStmt:
            return true
        case *ast.ForStmt:
            return true
        case *ast.IfStmt:
            return true
        case *ast.LabeledStmt:
            return f.endsBasicSourceBlock(s.Stmt)
        case *ast.RangeStmt:
            return true
        case *ast.SwitchStmt:
            return true
        case *ast.SelectStmt:
            return true
        case *ast.TypeSwitchStmt:
            return true
        case *ast.ExprStmt:
            // Calls to panic change the flow.
            // We really should verify that "panic" is the predefined function,
            // but without type checking we can't and the likelihood of it being
            // an actual problem is vanishingly small.
            if call, ok := s.X.(*ast.CallExpr); ok {
                if ident, ok := call.Fun.(*ast.Ident); ok && ident.Name == "panic" && len(call.Args) == 1 {
                    return true
                }
            }
        }
        found, _ := hasFuncLiteral(s)
        return found
    }
其实就是大量的switch语句，如果是的话，就可以将直接边界作为end进行插桩，这一步的意义其实就是在于把{}里面的body不断的分割成一个个可以影响控制流的小块进行分别插桩。其实到这里我们就可以洞悉go-fuzz整个的插桩思想：在语法分析的时候就通过go-fuzz本身所包含的一个包的内容插桩到各个可以影响控制流的语句块中，那么接下来对应的工作就应该是如何对这些进行插桩语句块进行感知，这其实就是Sonar结构体的作用，这是go-fuzz发明的声呐系统。
#### Sonar遍历
Sonar结构体同样实现了Visit方法来用于遍历语法树，部分源码如下：
    func (s *Sonar) Visit(n ast.Node) ast.Visitor {
    switch nn := n.(type) {
        case *ast.BinaryExpr:
            break