creates on Di’s receiver. Di and Dj conﬂict if either has a
SINR below the threshold of its required data rate. Thus,
the conﬂict degree of Di is the number of link requests that
conﬂict with Di when considered in this way.
To determine if a candidate radio link Li can be admitted
given the presence of scheduled links L on the same channel,
the scheduler calculates SINRk,L′ for each Lk ∈ L′ = L ∪
{Li} as the following:
SIN Rk,L′ =
,
(3)
Sk
N + Pj:Lj ∈L′\{Lk} Ijk
where the notation is identical to those in Eq. (2). If each
SINRk,L′ satisﬁes the corresponding data rate requirement,
then Li can be scheduled on this channel. This accounts for
the interference accumulated by multiple links, and ensures
that scheduled links can be active simultaneously without
conﬂict.
Conﬂict-Degree based Greedy Scheduling. With
the goal of minimizing the job completion time, the schedul-
ing problem can be mapped to a traditional graph coloring
problem that aims to use the minimal number of colors to
color all nodes. In our case, the colors map to 60 GHz fre-
quency channels and time slots. We employ techniques from
the graph coloring literature [19] in a greedy fashion, where
we schedule rack-level requests in an order based on their
conﬂict degrees. The conﬂict degree di of an unscheduled
request Di is deﬁned as the number of other unscheduled
requests denoted by set DC , such that if Di and any request
in DC are on the same channel, at least one cannot achieve
the required data rate.
There is an issue of link preemption in the scheduler.
Given long-lived links that provide less than ideal link us-
age, should the scheduler preempt them, i.e. pause them,
in order to schedule competing links? In a non-preemptive
model, the scheduler keeps the unﬁnished links untouched,
and checks which new ones can be added. This policy en-
sures that scheduled links will not be disturbed until they
complete, thus minimizing the antenna rotation delay and
control overhead by interrupting an ongoing link transmis-
sion. In a preemptive model, the scheduler pauses ongoing
links, treats them as new requests with the remaining un-
sent traﬃc, and schedules them together with new link re-
quests. Since previous link requests must compete with new
requests, this policy could lead to interruptions to ongoing
active links. The beneﬁt, however, is that such a policy could
increase the number of concurrent, active links. While we
evaluate both policies in Section 5, our default scheduler is
non-preemptive.
We note that more complex policies can be added to our
scheduler, such as alternative ranking metrics that prioritize
job by their deadlines in deadline-driven data centers [43]. In
such priority-based scheduling policies, care must be taken
to avoid link starvation by gradually increasing the priority
of jobs as their waiting time increases. We leave the design
of those metric-based schedulers as future work.
450Assigning Radios to Links. To minimize the antenna
rotation overhead, the scheduler assigns scheduled links to
unassigned radios during scheduling.
It applies a simple
policy. First, if an idle radio on the rack is already pointing
to the desired destination rack, the scheduler assigns the
link to this radio. Second, if multiple candidate/idle radios
exist, the scheduler checks the existing orientations of these
antennas and selects the one that is closest in angle to the
desired angle for the new link’s destination rack.
5. ADDRESSING TRAFFIC HOTSPOTS
In this section, we use network simulations to quantify
3D beamforming’s ability to deliver additional bandwidth
to data center environments, and its advantages over its 2D
counterpart. We consider the case of using wireless links to
cover traﬃc hotspots on top of an existing wired network
in data centers. Speciﬁcally, we seek to answer three key
questions:
1) Does adding 3D beamforming links to existing wired net-
works signiﬁcantly increase available bandwidth for hotspots?
2) How signiﬁcant are the beneﬁts of 3D beamforming over
2D beamforming, and where are they most visible?
3) Will antenna rotation delay of today’s rotators be a per-
formance bottleneck for 3D beamforming?
While we answer these questions using results from syn-
thetic traﬃc traces, we hope trends identiﬁed by our study
will serve as useful guidelines for practical deployment of 3D
beamforming systems.
5.1 Simulation Setup
For our traﬃc hotspot simulations, we use the data center
and radio conﬁgurations described in Section 3.2. It consists
of 250 racks and a total of 5000 servers. The distance be-
tween the antenna and the ceiling (h) is 2m. We use 60GHz
radios with 10dBm transmit power and 10◦ horn antennas.
There are three channels of width 2.16GHz, and each radio
can operate on one channel at a time. We derive data rates
following the speciﬁcations of the IEEE 802.11ad standard.
For this data center size, every possible pair of racks is able
to form a 1-hop link at 5+Gbps using 3D beamforming.
There are 8 radios positioned at the top of each rack. To
account for the rotation delay, we assume each antenna uses
a rotator from FLIR [4]. The pan speed is 300◦/second
and the tilt speed is 60◦/second. We also examine the case
where the rotation is instantaneous, which represents the
best possible (ideal) performance for 3D beamforming links.
Traﬃc Generation.
Existing traces [15, 16, 23, 25] do
not map data sources to rack locations. Hence, we used
synthetic traﬃc generated based on popular workloads [18]
to produce hotspots. We simulate a simple scenario, where
400 of the 5000 total servers in the data center each sends
a ﬁxed data payload to 200 other servers. The 400 servers
are chosen randomly from any rack in the data center. Each
data payload is 128MBytes, and each of the 400 transmitters
chooses a set of 200 servers to receive its data. We refer to a
complete cycle where each server sends a single payload to
each of its 200 destinations as a single round.
To produce controlled traﬃc hotspots, we introduce a
slight bias in server selection. This might emulate a slight
preference for certain machines based on their properties
such as compute power, uptime, memory size, or network
proximity to storage servers. We identify 50 random servers
in the data center as “preferred” servers. In each round, each
of the 400 transmitters chooses 200 receivers to receive their
data, randomly, but with a small bias. As we choose each
of the 200, there is a 10% chance that the receiver server
is one of the 50 preferred servers. Once we have chosen
200 unique receivers for each of the 400 transmitters, we ag-
gregate these server-pair traﬃc loads based on their server
locations to produce traﬃc demands at the rack level. We
repeat the above procedure to generate 10 rounds of rack-
level workloads.
We assume an underlying wired network oﬀering 1Gbps
network bisection bandwidth. We also explore larger values
ranging from 2 to 6Gbps, which are typical given the over-
subscription of today’s data centers [14]. Since our goal is to
understand how 3D beamforming addresses traﬃc hotspots,
one issue that arises is how traﬃc demands are split across
wired and wireless network links. Without advocating any
particular allocation policy, we assume that the traﬃc is split
between the two networks by setting a ﬁxed “deadline” for
wired links to ﬁnish their portion of the transmission. This
allows us to deﬁne the portion of traﬃc sent over the wired
network a priori, thus deriving the amount of “overﬂow”
traﬃc allocated to the 60 GHz network. To compute job
completion time, we assume that wired and wireless links
send data in parallel.
5.2 Impact of Adding 2D/3D Beamforming
Coverage of 2D Links. One of the primary limitations
with 2D beamforming is potential blockage issues that result
in lower signal strength and loss in data throughput. Prior
proposals limited 2D beamforming links to connecting neigh-
boring racks that have no potential blockage issues. Our ﬁrst
experiment looks considers portion of the total overﬂow traf-
ﬁc can be sent over 2D links, where overﬂow traﬃc is the
traﬃc that cannot be sent by the wired network by the spec-
iﬁed deadline. Figure 8(a) plots this as a ratio of total traﬃc
across neighboring links, i.e. traﬃc that can be sent across
2D links, over total overﬂow traﬃc. In all of our graphs, we
plot error bars covering the 90% conﬁdence interval.
Less than 3% of overﬂow traﬃc can be addressed using 2D
links, regardless of how much traﬃc is sent across the wired
network. We note that this ﬁgure might increase, depend-
ing on how well the data center managers scheduled jobs
to increase rack aﬃnity and limit hotspots to neighboring
racks, but this would introduce an additional constraint in
job scheduling. Note that we do not plot similar values for
3D links, because 3D links can connect all possible rack pairs
in our scenario with a single hop, thus coverage is 100%.
Impact of Antenna Rotation Delay. Next, we look at
3D performance, and try to understand the impact on end-
to-end latency by antenna rotation delays. In Figure 8(b),
we plot the wireless completion time, i.e. time required to
send overﬂow traﬃc over the 3D links, against the wired
completion deadline. A longer wired deadline means more
traﬃc will go over the wired network and less overﬂow traﬃc
will be left for wireless links. We also draw the line “y = x”
to show the minimum time to complete transmissions if we
used the ideal traﬃc allocation between wired and wireless.
By plotting 3D links with and without rotational delay, we
see that all transmissions are completed in 9 seconds in a
realistic system, but can be improved to 8 seconds if we
451D
2
y
b
d
e
r
e
v
o
c
c
i
f
f
a
r
t
f
o
n
o
i
t
c
a
r
F
 0.1
 0.08
 0.06
 0.04
 0.02
 0
2D/Overflow
)
s
(
e
m
l
i
t
n
o
i
t
e
p
m
o
c
s
s
e
e
r
i
l
 4
 5
 6
 7
 8
 9
 10  11
W
w/ rotation delay
w/o rotation delay
 40
 30
 20
 10
 0
x = y
)
s
(
e
m
l
i
t
n
o
i
t
e
p
m
o
c
l
a
t
o
T
Wired only
Wired+2D
Wired+3D
 35
 30
 25
 20
 15
 10
 5
 0
 4
 5
 6
 7
 8
 9
 10
 11
 14  16  18  20  22  24  26  28  30  32
Wired completion deadline (s)
Wired completion deadline (s)
Max flow size (Gb)
(a) Portion of Traﬃc Covered by 2D
Links
(b) Impact of Antenna Rotation Delay
on 3D Performance
(c) Total Completion Time
Figure 8: Performance of 2D and 3D beamforming links in conjunction with a wired network with 1Gbps
bisection bandwidth. (a) Less than 3% of overﬂow traﬃc can be addressed using 2D links, while 3D links
can cover 100%. (b) The time required for 3D to send all the overﬂow traﬃc vs. the wired completion
deadline, using today’s rotators or ideal rotators with zero delay. (c) Adding 3D beamforming cuts the total
job completion time by half.
completely eliminate antenna rotation delays. This is the
eﬀective upper bound on how well we can perform given
perfect radio assignment, and shows that antenna rotation
delay is only a small component in end-to-end performance.
Total Completion Time. Next, in Figure 8(c), we plot
the eﬀective completion time (if both wired and wireless net-
works transmitted simultaneously with optimal traﬃc split)
for diﬀerent rounds of our simulation, assuming a 1Gbps bi-
section on the wired network. Regardless of the size of the
biggest ﬂow, 3D wireless is generally able to reduce total
transmission time by half. Since 2D links can only address
a small portion of the overﬂow traﬃc, its impact on comple-
tion time is limited.
Next, we ask the question, “will 3D beamforming links
become less useful for wired networks with higher bisection
bandwidth?” We vary the underlying bisection bandwidth
of the wired network between 1 Gbps and 6 Gbps, and in
each case, compute the minimal completion time if we per-
formed the ideal traﬃc split between the wired and wire-
less networks. Figure 9 shows that even as the wired net-
work grows in bisection bandwidth, adding 3D beamforming
can still reduce total transmission time signiﬁcantly (rang-
ing from more than 50% to slightly less than 40% as wired
bandwidth ranges from 1 Gbps to 6 Gbps). This is not sur-
prising. Since the demand in our hotspot scenario is ﬁxed,
a wired network with larger bisection bandwidth consumes
more traﬃc, leaving less overﬂow traﬃc for the 60 GHz links.
5.3 Impact of Scheduler Policies
We now evaluate the net impact of diﬀerent design choices
in our link scheduler.
Preemption vs. No Preemption We discussed the is-
sue of preempting existing links in Section 4. To understand
which policy is more preferable, we compare the job com-
pletion time when applying these two policies with the same
workload as above. Non-preemptive is the default policy
used in prior experiments, where once a link is scheduled,
it utilizes the radio until it ﬁnishes. The preemptive policy
considers all radios on a rack when scheduling requests, and
where deemed appropriate by the scheduler, will pause an
existing link to give its radio to a higher priority link request.
We plot the completion time of the wireless traﬃc load
in Figure 10(a). The results match our expectations. A
non-preemptive policy reduces the completion time by up
Wired completion time (s)
Rotator usage reduction via
intelligent radio assignment
4
6
7
8
27% 22% 22% 21%
Table 1: Intelligent radio assignment leads to mod-
erate reduction in rotator usage.
to 25% compared to the preemptive policy. This is be-
cause rescheduling the paused link introduces signiﬁcant ad-
ditional overhead (and more antenna rotation), thus reduc-
ing overall eﬃciency.
Intelligent Radio Assignment.
Finally, we evaluate
the impact of using intelligent radio assignment during link
scheduling. Figure 10(b) plots the completion time for the
wireless traﬃc load for our default scheduler (including in-
telligent radio assignment) and a basic scheduler, which uses
random choice to choose between available radios. Neither
scheduler uses link preemption.
The results are varied, depending on the traﬃc load on
the wireless network. When the large majority of traﬃc is
sent through the wired network, only the strongest of the
hotspots remain for the wireless network. In this case, there
will be high contention for radios at a small number of racks,
and very little choice in terms of radio assignment. Thus the
optimization shows small beneﬁt. When a larger portion of