title:Take This Personally: Pollution Attacks on Personalized Services
author:Xinyu Xing and
Wei Meng and
Dan Doozan and
Alex C. Snoeren and
Nick Feamster and
Wenke Lee
Take This Personally: Pollution Attacks  
on Personalized Services
Xinyu Xing, Wei Meng, and Dan Doozan, Georgia Institute of Technology;  
Alex C. Snoeren, University of California, San Diego;  
Nick Feamster and Wenke Lee, Georgia Institute of Technology
Open access to the Proceedings of the 22nd USENIX Security Symposium is sponsored by USENIXThis paper is included in the Proceedings of the 22nd USENIX Security Symposium.August 14–16, 2013 • Washington, D.C., USAISBN 978-1-931971-03-4Take This Personally: Pollution Attacks on Personalized Services
Xinyu Xing, Wei Meng, Dan Doozan, Alex C. Snoeren†, Nick Feamster, and Wenke Lee
Georgia Institute of Technology and †UC San Diego
Abstract
Modern Web services routinely personalize content
to appeal to the speciﬁc interests, viewpoints, and con-
texts of individual users. Ideally, personalization allows
sites to highlight information uniquely relevant to each
of their users, thereby increasing user satisfaction—and,
eventually, the service’s bottom line. Unfortunately, as
we demonstrate in this paper, the personalization mech-
anisms currently employed by popular services have not
been hardened against attack. We show that third parties
can manipulate them to increase the visibility of arbi-
trary content—whether it be a new YouTube video, an
unpopular product on Amazon, or a low-ranking website
in Google search returns. In particular, we demonstrate
that attackers can inject information into users’ proﬁles
on these services, thereby perturbing the results of the
services’ personalization algorithms. While the details of
our exploits are tailored to each service, the general ap-
proach is likely to apply quite broadly. By demonstrating
the attack against three popular Web services, we high-
light a new class of vulnerability that allows an attacker
to affect a user’s experience with a service, unbeknownst
to the user or the service provider.
1
Introduction
The economics of the Web ecosystem are all about clicks
and eyeballs. The business model of many Web services
depends on advertisement: they charge for prime screen
real estate, and focus a great deal of effort on develop-
ing mechanisms that make sure that the information dis-
played most prominently is likely to create revenue for
the service, either through a direct ad purchase, com-
mission, or at the very least improving the user’s ex-
perience. Not surprisingly, malfeasants and upstanding
business operators alike have long sought to reverse engi-
neer and exploit these mechanisms to cheaply and effec-
tively place their own content—whether it be items for
sale, malicious content, or afﬁliate marketing schemes.
Search engine optimization (SEO), which seeks to im-
pact the placement of individual Web pages in the results
provided by search engines, is perhaps the most widely
understood example of this practice.
Modern Web services are increasingly relying upon
personalization to improve the quality of their customers’
experience. For example, popular websites tailor their
front pages based on a user’s previous browsing history
at the site; video-sharing websites such as YouTube rec-
ommend related videos based upon a user’s watch his-
tory; shopping portals like Amazon make suggestions
based on a user’s previous purchases; and search engines
such as Google return customized results based upon a
wide variety of user-speciﬁc factors. As the Web be-
comes increasingly personal, the effectiveness of broad-
brush techniques like SEO will wane. In its place will
rise a new class of schemes and outright attacks that ex-
ploit the mechanisms and algorithms underlying this per-
sonalization. In other words, personalization represents
a new attack surface for all those seeking to steer user
eyeballs, regardless of their intents.
In this paper, we demonstrate that contemporary per-
sonalization mechanisms are vulnerable to exploit.
In
particular, we show that YouTube, Amazon, and Google
are all vulnerable to the same class of cross-site scripting
attack, which we call a pollution attack, that allows third
parties to alter the customized content the services return
to users who have visited a page containing the exploit.
Although the attack is quite effective, we do not claim
that it is the most powerful, broadly applicable, or hard
to defeat. Rather, we present it as a ﬁrst example of a
class of attacks that we believe will soon—if they are not
already—be launched against the relatively unprotected
underbelly of personalization services.
Our attack exploits the fact that a service employing
personalization incorporates a user’s past history (includ-
ing, for example, browsing, searching and purchasing ac-
tivities) to customize the content that it presents to the
USENIX Association  
22nd USENIX Security Symposium  671
1
user. Importantly, many services with personalized con-
tent log their users’ Web activities whenever they are
logged in regardless of the site they are currently visiting;
other services track user activities on the site even if the
user is logged out (e.g., through a session cookie). We
use both mechanisms to pollute users’ service proﬁles,
thereby impacting the customized content returned to the
users in predictable ways. Given the increasing portfolio
of services provided by major players like Google and
Amazon, it seems reasonable to expect that a large frac-
tion of users will either be directly using the service or at
least logged in while browsing elsewhere on the Web.
We show that pollution attacks can be extremely effec-
tive on three popular platforms: YouTube, Google, and
Amazon. A distinguishing feature of our attack is that
it does not exploit any vulnerability in the user’s Web
browser. Rather, it leverages these services’ own person-
alization mechanisms to alter user’s experiences. While
our implementation employs cross-site request forgery
(XSRF) [13], other mechanisms are possible as well.
The ability to trivially launch such an attack is es-
pecially worrisome because it indicates the current ap-
proach to Web security is ill-equipped to address the
vulnerabilities likely to exist in personalization mecha-
nisms. In particular, today’s Web browsers prevent ex-
ploits like cross-site scripting and request forging by en-
forcing boundaries between domains though “same ori-
gin” policies. The limitations of these approaches are
well known, but our attack represents a class of exploits
that cannot be stopped by client-side enforcement: in an
attempt to increase the footprint of its personalization en-
gine (e.g., Google recording search queries that a user
enters on a third-party page), a service with personalized
services is providing the cross-site vector itself. Hence,
only the service can defend itself from such attacks on its
personalization. Moreover, enforcing isolation between
independent Web sessions seems antithetical to the goal
of personalization, which seeks to increase the amount of
information upon which to base customization attempts.
This paper makes the following contributions:
• We describe pollution attacks
three
platforms—YouTube, Google, and Amazon—that
allow a third party to alter the personalized content
these services present
to users who previously
visited a Web page containing the exploit.
against
• We study the effectiveness of our attack on each of
these platforms and demonstrate that it (1) can in-
crease the visibility of almost any YouTube chan-
nel; (2) dramatically increase the ranking of most
websites in the short term, and even have lasting im-
pacts on the personalized rankings of a smaller set
of sites, and (3) cause Amazon to recommend rea-
sonably popular products of the attacker’s choosing.
2
• Our attack and its effectiveness illustrates the im-
portance of securing personalization mechanisms in
general. We discuss a number of implications of our
study and ways for websites to mitigate similar vul-
nerabilities in the future.
The rest of the paper is organized as follows. Section 2
provides a general overview of pollution attacks on per-
sonalized services. Sections 3, 4, and 5 introduce speciﬁc
attacks that can be launched against YouTube, Google,
and Amazon, respectively, and report on our success. We
survey related work in Section 6 and discuss limitations
of our work and possible defenses in Section 7 before
concluding in Section 8.
2 Overview and Attack Model
In this section, we present a brief overview of personal-
ization as it is used by popular Web services. We then
present a model of pollution attacks, which we apply
to three different scenarios later in the paper: YouTube,
Amazon, and Google.
2.1 Personalization
Online services are increasingly using personalization to
deliver information to users that is tailored to their inter-
ests and preferences. Personalization potentially creates
a situation where both the service provider and the user
beneﬁt: the user sees content that more closely matches
preferences, and the service provider presents products
that the user is more likely to purchase (or links that the
user is more likely to click on), thus potentially resulting
in higher revenues for the service provider.
The main instrument that a service provider can use to
affect the content that a user sees is modifying the choice
set, the set of results that a user sees on a particular screen
in response to a particular query. The size of a choice
set differs for different services. For example, YouTube
shows the user anywhere from 12–40 videos; Amazon
may show the user up to ﬁve sets of recommended prod-
ucts; Google’s initial search results page shows the top
ten results. Figure 1 shows several examples of choice
sets on different sites.
When a user issues a query, a service’s personaliza-
tion algorithm affects the user’s choice set for that query.
The choice set that a personalization algorithm produces
depends on a user query, as well as a number of auxil-
iary factors, including the universe of all possible con-
tent and the user’s browsing history. Previous work has
claimed that many factors, ranging from geography to
time of day, may affect the choice set that a user sees.
For the purposes of the attacks in this paper, we focus on
how changes to a user’s history can affect the choice set,
672  22nd USENIX Security Symposium 
USENIX Association
USENIX Association  
22nd USENIX Security Symposium  673
(a)CustomizedYouTube.(b)CustomizedAmazon.(c)CustomizedGoogle.Figure1:websiteswithpersonalizedservices(personalizedservicestailorthedataintheredrectangles).Figure2:Overviewofhowhistorypollutioncanulti-matelyaffecttheuser’schoiceset.holdingotherfactorsﬁxed.Inparticular,westudyhowanattackercanpollutetheuser’shistorybygeneratingfalseclicksthroughcross-siterequestforgery(XSRF).Wedescribetheseattacksinthenextsection.2.2PollutionAttacksTheobjectiveofapollutionattackistoaffectauser’schoiceset,givenaparticularinput.Insomecases,auser’schoicesetappearsbeforetheuserentersanyin-put(e.g.,uponaninitialvisittothepage).Inthiscase,theattacker’sgoalmaybetoaffectadefaultchoiceset.Figure2showsanoverviewoftheattacker’sgoal:theattackeraimstoaffecttheresultingchoicesetbyalter-ingtheuser’shistorywithfalseclicks,usingcross-siterequestforgeryastheattackvector.Thisattackrequiresthreesteps:1.Modeltheservice’spersonalizationalgorithm.Weassumethattheattackerhassomeabilitytomodelthepersonalizationalgorithmthatthesiteusestoaf-fecttheuser’schoiceset.Inparticular,theattackermusthavesomeideaofhowtheuser’spasthistoryaffectstheuser’schoiceset.Thisinformationisof-tenavailableinpublishedwhitepapers,butinsomecasesitmayrequireexperimentation.2.Createa“seed”topollutetheuser’shistory.Givensomeknowledgeofthepersonalizationalgorithmandagoalforhowtoaffectthechoiceset,theat-tackermustdesigntheseedthatisusedtoaffecttheuser’schoiceset.Dependingontheservice,theseedmaybequeries,clicks,purchases,oranyotheractivitythatmightgointotheuser’shistory.Agoodseedcanaffecttheuser’schoicesetwithaminimalnumberof“falseclicks”,aswedescribenext.3.Injecttheseedwithavectoroffalseclicks.Topol-luteauser’shistory,inmostcaseswerequirethattheuserbesignedintothesite.(Forsomeservices,pollutioncantakeplaceevenwhentheuserisnotsignedin.)Then,theattackercanuseamechanismtomakeitappearasthoughtheuseristakingactionontheWebsiteforaparticularservice(e.g.,click-ingonlinks)usingaparticularattackvector.Inthefollowingsections,weexplorehowanattackercanapplythissameproceduretoattackthepersonalizationalgorithmsofthreedifferentservices:YouTube,Ama-zon,andGooglesearch.3PollutionAttacksonYouTubeInthissection,wedemonstrateourattackonYouTube1.FollowingtheattackstepswedescribedinSection2,weﬁrstmodelhowYouTubeusesthewatchhistoryofaYouTubeuseraccounttorecommendvideosbyreview-ingtheliterature[5].Second,wediscusshowtoprepareseeddata(i.e.,seedvideos)topromotetargetdata(i.e.,targetvideosbelongingtoaspeciﬁcchannel).Third,weintroducehowtoinjecttheseedvideostoaYouTubeuseraccount.Finally,wedesignexperimentsandquantifytheeffectivenessofourattack.3.1YouTubePersonalizationYouTubeconstructsapersonalizedlistofrecommendedvideosbaseduponthevideosauserhaspreviouslyviewed[5].YouTubeattemptstoidentifythesubsetofpreviouslyviewedvideosthattheuserenjoyedbycon-sideringonlythosevideosthattheuserwatchedforalongperiodoftime.Typically,YouTuberecommendsvideosthatotheruserswithsimilarviewinghistories1Ademovideoisavailableathttp://www.youtube.com/watch?v=8hij52ws98A.3have also enjoyed. YouTube tracks the co-visitation re-
lationship between pairs of videos, which reﬂects how
likely a user who watched a substantial portion of video
X will also watch and enjoy video Y . In general, there
may be more videos with co-visitation relationships than
there is display area, so YouTube prioritizes videos with
high rankings. YouTube will not recommend a video the
user has already watched.
YouTube displays recommended videos in the sugges-
tion list placed alongside with a playing video (e.g., Fig-
ure 5) and in the main portion of the screen at the end of
a video (Figure 1(a)). A suggestion list appearing next to
a video typically contains 20–40 suggested videos, two
of which are recommended based upon personalization.
At the end of a video, YouTube shows an more concise
version of the suggestion list that contains only twelve of
the videos from the full list; these videos may or may not
contain personal recommendations.
3.2 Preparing Seed Videos
YouTube organizes videos into channels, where each
channel corresponds to the set of uploads from a particu-
lar user. In our attack, we seek to promote a set of target
videos, ΩT , all belonging to the same YouTube channel,
C. To do so, we will use an additional set of seed videos,
ΩS, that have a co-visitation relationship with the target
videos. By polluting a user’s watch history with videos in
ΩS, we can cause YouTube to recommend videos in ΩT .
There are two ways to obtain ΩS: we can identify videos
with pre-existing co-visitation relationships to the target
videos, or we can create the relationships ourselves.
Existing Relationships.
In the simplest version of the
attack, the attacker identiﬁes existing videos to use as
the seed set. For example, given a target video set
ΩT belonging to channel C,
the attacker could con-
sider all of the other videos in the channel, C − ΩT ,
as candidate seeds. For every candidate video, the at-
tacker checks which videos YouTube recommends when
a fresh YouTube account (i.e., a YouTube account with
no history) watches it. YouTube allows its users to view
their recommended videos at http://www.youtube.
com/feed/recommended.
If the candidate video trig-
gers YouTube to recommend a video in ΩT , then the at-
tacker adds the injected video to seed video set ΩS.
In general, this process allows the attacker to identify
seed videos for every target video in ΩT . The attacker
cannot yet launch the attack, though, because a YouTube
video in ΩS may trigger YouTube to also recommend
videos not in ΩT . To address this issue, the attacker can
simply add these unwanted videos to the seed video set
ΩS because YouTube does not recommend videos that
the user has already watched. As we will show later, the
attacker can convince YouTube that the user watched, but
did not enjoy, these unwanted videos, so their inclusion
in ΩS will not lead to additional recommendations.
Fabricating Relationships. For some videos, it may
be difﬁcult to identify a seed set ΩS that recommends all
of the elements of ΩT due to lack of co-visitation rela-
tionships for some of the target elements. Instead, attack-
ers who upload their own content to use as the seed set
can create co-visitation relationships between this con-
tent and the target set. In particular, an attacker uploads
a set of videos, Ω0, and establishes co-visitation relation-
ships between Ω0 and ΩT through crowd-sourcing (e.g.,
Mechanical Turk or a botnet): YouTube visitors need
only watch a video in Ω0 followed by a video in ΩT .
After a sufﬁcient number of viewing pairs, the attacker
can use videos in Ω0 as the seed set. As we will show in
Section 3.4.1, a relatively small number of viewing pairs
sufﬁces.
3.3
Injecting Seed Videos
To launch the attack and inject seed videos into a
victim’s YouTube watch history, an attacker can harness
XSRF to forge the following two HTTP requests for each
video in the seed set: (1) http://www.youtube.com/
user_watch?plid=&video_id=,
and (2) http://www.youtube.com/set_awesome?
plid=&video_id=, where
plid
and video id correspond to the values found in the
source code of the seed video’s YouTube page. The
ﬁrst HTTP request spoofs a request from the victim to
start watching the seed video, and the second convinces
YouTube that the victim watched the video for a long
period of time. Both HTTP requests are required for
videos in ΩS to trigger the recommendation of videos in
ΩT , but only the ﬁrst HTTP request is needed to prevent
the recommendation of unwanted videos.
3.4 Experimental Design
We evaluated the effectiveness of our attack both in con-
trolled environments and against real YouTube users. We
ﬁrst validated the the attack in the simplest scenario,
where the attack promoted existing YouTube channels
through existing co-visitation relationships. We then
considered the scenario where an attack seemed to up-
load and promote content from a channel that the attacker
created. Finally, we conducted a small-scale experiment
to demonstrate the effectiveness of the attack against a
volunteer set of real YouTube users.
674  22nd USENIX Security Symposium 
USENIX Association
4
3.4.1 New Accounts
We ﬁrst promoted existing YouTube channels by launch-
ing our attack against victims with fresh YouTube user
accounts. This experiment conﬁrms the effectiveness of
our approach in the absence of other, potentially counter-
vailing inﬂuences, such as recommendations based on a
user’s existing history.
We began by selecting 100 existing YouTube channels
at random from the list of the top 2,000 most-subscribed
channels published by VidStatsX [19]. For each of the
selected YouTube channels, we randomly selected 25
videos from the channel as the target video set, used the
method described in the previous section to identify a
seed video set, and injected the seed videos to a fresh
YouTube account.
We then considered promoting new content by creat-
ing our own YouTube channel and similarly attacking
fresh YouTube accounts. Our YouTube channel contains
two 3-minute videos. We selected one of the videos as
a one-element target video set and used the other as the
seed set. We created a co-visitation relationship by em-
bedding both videos on a web page and recruiting volun-
teers to watch both videos sequentially. We obtained 65
and 68 views for our seed and target video respectively.
3.4.2 Existing Accounts
We studied the effectiveness of our pollution attack using
real YouTube user accounts. We recruited 22 volunteers
with extensive pre-existing YouTube watch histories. To
limit the inconvenience to our volunteers, we limited our
study to attempting to promote one moderately popular
YouTube channel based upon existing co-visitation rela-
tionships. We selected a moderately popular account be-
cause a popular channel may be recommended anyway
(regardless of out attack); conversely, an entirely new
channel requires a certain amount of effort to establish
the co-visitation relationships as described above and we
have limited volunteer resources.
Based on these parameters, we arbitrarily selected the
channel OnlyyouHappycamp. We believe this selection
is a reasonable candidate to be promoted using our attack
for several reasons. First, compared to popular chan-
nels, most videos in OnlyyouHappycamp have low view
counts (about 2,000 view counts per video on average)
and the number of subscribers to the channel is a simi-
larly modest 3,552. Both of these are easily achievable
by an attacker at fairly low cost2. Second, most videos in
OnlyyouHappycamp are 22 minutes long, which makes
them suitable for promotion. As we will explain in Sec-
tion 3.5.1, the length of a target video affects its likeli-
2According to the prices in underground markets such as
freelancer.com and fiverr.com, 40,000 view counts and 10,000
subscribers cost $15 and $30 US dollars, respectively.
e
t
a
r
n
o
i
t
o
m
o
r
P
3
.
0
2
.
0
1
.
0
0
.
0
1
3
5
7
14
9 11
17
Target video ID
20
23
Figure 3: The promotion rate for each of the 25 target
videos in channel lady16makeup. Two videos were rec-
ommended in each of the 114 trials.
hood for being recommended as a result of a co-visitation
relationship with another video.
Similar to the experiments with new accounts, we ran-
domly selected 15 target videos from channel Onlyy-
ouHappycamp, identiﬁed a seed set, and injected the
seed videos into the volunteers’ YouTube accounts. Af-
ter pollution, the volunteers were asked to use their ac-
counts to watch three videos of their choice and report
the suggestion list displaying alongside each of their
three videos.
3.5 Evaluation
We evaluated the effectiveness of our pollution attacks
by logging in as the victim user and viewing 114 repre-
sentative videos3. We measured the effectiveness of our
attack in terms of promotion rate: the fraction of the 114
viewings when at least one of the target videos was con-
tained within the video suggestion list. Recall that the
list contains at most two personalized recommendations
(see Section 3.1); we deem the attack successful if one
or both of these videos are videos that were promoted as
a result of a pollution attack.
3.5.1 New Accounts
Pollution attacks successfully promoted target videos
from each of the 100 selected existing channels: Each
time we injected seed videos for a particular channel, we
observed the target videos in the suggestion list for each
of the 114 videos. Since these are fresh accounts, there
is no other history, so our targeted videos always occupy
both of the personalized recommendation slots.
In addition, we observed the particular target videos
shown in the suggestion video list varied, even when
3We attempted to view 150 videos random from a trace of YouTube
usage at our institution over the course of several months. Unfortu-