title:Path ORAM: an extremely simple oblivious RAM protocol
author:Emil Stefanov and
Marten van Dijk and
Elaine Shi and
Christopher W. Fletcher and
Ling Ren and
Xiangyao Yu and
Srinivas Devadas
An Extremely Simple Oblivious RAM Protocol
Path ORAM:
Emil Stefanov†, Marten van Dijk‡, Elaine Shi∗, Christopher Fletcher◦,
Ling Ren◦, Xiangyao Yu◦, Srinivas Devadas◦
† UC Berkeley
‡ UConn
∗ UMD
◦ MIT CSAIL
ABSTRACT
We present Path ORAM, an extremely simple Oblivious
RAM protocol with a small amount of client storage. Partly
due to its simplicity, Path ORAM is the most practical
ORAM scheme for small client storage known to date. We
formally prove that Path ORAM requires O(log2 N/ log χ)
bandwidth overhead for block size B = χ log N . For block
sizes bigger than ω(log2 N ), Path ORAM is asymptotically
better than the best known ORAM scheme with small client
storage. Due to its practicality, Path ORAM has been
adopted in the design of secure processors since its proposal.
Categories and Subject Descriptors
K.6.5 [Management of Computing and Information
Systems]: Security and Protection
General Terms
Algorithms, Security
Keywords
Oblivious RAM; ORAM; Path ORAM; access pattern
1.
INTRODUCTION
It is well-known that data encryption alone is often not
enough to protect users’ privacy in outsourced storage appli-
cations. The sequence of storage locations accessed by the
client (i.e., access pattern) can leak a signiﬁcant amount of
sensitive information about the unencrypted data through
statistical inference. For example, Islam et. al. demon-
strated that by observing accesses to an encrypted email
repository, an adversary can infer as much as 80% of the
search queries [21].
Oblivious RAM (ORAM) algorithms, ﬁrst proposed by Gol-
dreich and Ostrovsky [13], allow a client to conceal its access
pattern to the remote storage by continuously shuﬄing and
re-encrypting data as they are accessed. An adversary can ob-
serve the physical storage locations accessed, but the ORAM
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516660.
algorithm ensures that the adversary has negligible probabil-
ity of learning anything about the true (logical) access pat-
tern. Since its proposal, the research community has strived
to ﬁnd an ORAM scheme that is not only theoretically inter-
esting, also practical [4, 7, 12, 14–17, 22, 23, 25–27, 30, 33–38].
In this paper, we propose a novel ORAM algorithm called
Path ORAM 1. This is to date the most practical ORAM
construction under small client storage. We prove theoret-
ical bounds on its performance and also present matching
experimental results.
Path ORAM makes the following contributions:
Simplicity and practical eﬃciency. In comparison to
other ORAM algorithms, our construction is arguably much
simpler. Although we have no formal way of measuring its
simplicity, the core of the Path ORAM algorithm can be
described in just 16 lines of pseudocode (see Figure 1) and
our construction does not require performing sophisticated
deamortized oblivious sorting and oblivious cuckoo hash
table construction like many existing ORAM algorithms [4,
7, 12–17, 22, 25–27, 35–37]. Instead, each ORAM access can
be expressed as simply fetching and storing a single path
in a tree stored remotely on the server. Path ORAM’s
simplicity makes it more practical than any existing ORAM
construction with small (i.e., constant or poly-logarithmic)
local storage.
Asymptotic eﬃciency. We prove that for a reasonably
large block size B = χ·log N bits where N is the total number
of blocks, Path ORAM with recursion (where recursion is
proposed in Shi et al. [30]; see Section 3.7) achieves an
asymptotic bandwidth cost of O(log2 N/ log χ) blocks, and
consumes O(log2 N/ log χ)ω(1) block client-side storage2. In
other words, to access a single block, the client needs to
in reality access O(log2 N/ log χ) physical blocks to hide its
access patterns from the storage server. The above result
achieves a failure probability of N−ω(1), negligible in N .
As pointed out later in Section 1.1, our result outperforms
the best known ORAM for small client storage [22], both in
terms of asymptotics and practicality, for reasonably large
block sizes, i.e., block sizes typically encountered in practical
applications.
Practical and theoretic impact of Path ORAM. Since
we ﬁrst proposed Path ORAM [32] in February 2012, it
1Our construction is called Path ORAM because data on
the server is always accessed in the form of tree paths.
2Throughout this paper, when we write the notation g(n) =
O(f (n)) · ω(1), we mean that for any function h(n) = ω(1),
it holds that g(n) = O(f (n)h(n)).
299ORAM Scheme
Kushilevitz et al. [22]
Gentry et al. [11] (B = χ log N )
Client Storage
(# blocks)
O(1)
Read & Write Bandwidth
(# blocks)
O(log2 N/ log log N )
O(log2 N ) · ω(1)
O(log3 N/(log log N log χ)) · ω(1)
Recursive Path ORAM (B = χ · log N ) O(log2 N/ log χ) · ω(1)
O(log2 N/ log χ)
(store stash on client)
Recursive Path ORAM (B = χ · log N )
(store stash on server)
O(log N ) · ω(1)
O(log2 N/ log χ) · ω(1)
Table 1: Comparison to other ORAM schemes: Asymptotic bandwidth cost. B is the block size (in terms of #
bits), N is the total number of blocks. The Path ORAM Stash is deﬁned in Section 3. The failure probability is set to N−ω(1)
in this table, i.e., negligible in N .
has made both a practical and a theoretic impact in the
community.
On the practical side, Path ORAM is the most suitable
known algorithm for hardware ORAM implementations due
to its conceptual simplicity, small client storage, and practical
eﬃciency. Ren et al. built a simulator for an ORAM-enabled
secure processor based on the Path ORAM algorithm [29] and
the Ascend processor architecture [9, 10] uses Path ORAM
as a primitive. Maas et al. [24] implemented Path ORAM on
a secure processor using FPGAs and the Convey platform.
On the theoretic side, subsequent to the proposal of Path
ORAM, several theoretic works adopted the same idea of
path eviction in their ORAM constructions — notably the
works by Gentry et al. [11] and Chung et al. [6]. These two
works also try to improve ORAM bounds based on the binary
tree construction by Shi et al. [30]; however, as pointed out
in Section 1.1 our bound is asymptotically better than those
by Gentry et al. [11] and Chung et al. [6]. Gentry’s Path
ORAM variant construction has also been applied to secure
multiparty computation [11].
Novel proof techniques. Although our construction is
simple, the proof for upper bounding the client storage is
quite intricate and interesting. Our proof relies on the cre-
ation of a second ORAM construction and a reduction from
Path ORAM to the second ORAM construction. We provide
concrete bounds showing that for M load/store operations
on N data blocks, recursive Path ORAM with client storage
≤ R log N/ log χ blocks, server storage 28N blocks and band-
width 14(log N )2/ log χ blocks per load/store operation, fails
during one of the M load/store operations with probability
≤ 14 · 0.625−RM log N/ log χ. Our empirical results in Sec-
tion 5 indicate that the constants in practice are even lower
than our theoretic bounds.
1.1 Related Work
Oblivious RAM was ﬁrst investigated by Goldreich and
Ostrovsky [12, 13, 25] in the context of protecting software
from piracy, and eﬃcient simulation of programs on oblivious
RAMs. Since then, there has been much subsequent work
[4,6,7,11–15,17,22,25–27,35,37] devoted to improving ORAM
constructions. Path ORAM is based upon the binary-tree
ORAM framework proposed by Shi et al. [30].
Optimality of Path ORAM. Under small (i.e., constant or
poly-logarithmic) client storage, the best known ORAM was
proposed by Kushilevitz et al., and has O(log2 N/ log log N )
blocks bandwidth cost [22].
Our Path ORAM algorithm with recursion as in Shi et
al. [30] is competitive with Kushilevitz et al. [22] in terms of
bandwidth cost, when the block size is at least Ω(log2 N ) bits;
and can asymptotically outperform Kushilevitz et al. [22]
for larger block sizes. For example, for block size B =
Ω(log2 N ) bits, our bandwidth cost is O(log2 N/ log log N )
blocks, matching the best known bound of Kushilevitz et
al. [22], under small client storage.
Of particular interest is the case when block size is at least
Ω(λ) bits, where λ is the security parameter (e.g., λ = 128
or λ = 256) and N = poly(λ) — since this is what one
typically encounters in practical applications. In this case,
recursive Path ORAM’s bandwidth cost is only O(log N )
blocks; moreover it has O(1) round-trips since the depth
of recursion would be constant. Goldreich and Ostrovsky
show that under O(1) client storage, any ORAM algorithm
must have bandwidth overhead Ω(log N ) (regardless of the
block size). Since then, a long-standing open question is
whether it is possible to have an ORAM construction that has
O(1) or poly log(N ) client-side storage and O(log N ) blocks
bandwidth cost [13, 14, 22]. Our bound partially addresses
this open question for reasonably large block sizes.
Comparison with Gentry et al. and Chung et al..
Gentry et al. [11] improve on the binary tree ORAM scheme
proposed by Shi et al. [30]. To achieve 2−λ failure probabil-
ity, their scheme achieves O(λ(log N )2/(log λ log χ)) blocks
bandwidth cost, for block size B = χ · log N bits. Assuming
that N = poly(λ), their bandwidth cost is O(λ log N/ log χ)
blocks.
In comparison, recursive Path ORAM achieves
O(log2 N/ log χ) blocks bandwidth cost. Note that typi-
cally λ (cid:29) log N since N = poly(λ). Therefore, recursive
Path ORAM is much more eﬃcient than the scheme by
Gentry et al.. Table 1 presents this comparison, assuming
a failure probability of N−ω(1), i.e., negligible in N . Since
N = poly(λ), the failure probability can also equivalently be
written as λ−ω(1). We choose to use N−ω(1) to simplify the
notation in the asymptotic bounds.
Chung and Pass [6] proved a similar (in fact slightly worse)
bound as Gentry et al. [11]. As mentioned earlier, our bound
is asymptotically better than Gentry et al. [11] or Chung
and Pass [6].
Very recently, Chung et al. proposed another statisti-
cally secure binary-tree ORAM algorithm [5] based on Path
ORAM. Their theoretical bandwidth bound is log log n factor
worse than ours. Their simulation results suggest an empiri-
cal bucket size of 4 [1] — which means that their practical
bandwidth cost is a constant factor worse than Path ORAM,
300since they require operating on 3 paths in expectation for
each data access, while Path ORAM requires reading and
writing only 1 path.
Statistical security. We note that Path ORAM is also sta-
tistically secure (not counting the encryption). Statistically
secure ORAMs have been studied in several prior works [2,8].
All known binary-tree based ORAM schemes and variants
are also statistically secure [6, 11, 30] (assuming each bucket
is a trivial ORAM).
2. PROBLEM DEFINITION
We consider a client that wishes to store data at a remote
untrusted server while preserving its privacy. While tradi-
tional encryption schemes can provide conﬁdentiality, they
do not hide the data access pattern which can reveal very
sensitive information to the untrusted server. In other words,
the blocks accessed on the server and the order in which
they were accessed is revealed. We assume that the server
is untrusted, and the client is trusted, including the client’s
processor, memory, and disk.
The goal of ORAM is to completely hide the data access
pattern (which blocks were read/written) from the server.
From the server’s perspective, read/write operations are
indistinguishable from random requests.
Notations. We assume that the client fetches/stores data
on the server in atomic units, referred to as blocks, of size
B bits each. For example, a typical value for B for cloud
storage is 64 − 256 KB while for secure processors smaller
blocks (128 B to 4 KB) are preferable. Throughout the paper,
let N be the working set, i.e., the number of distinct data
blocks that are stored in ORAM.
Like all other related work, our ORAM constructions do
not consider information leakage through the timing channel,
such as when or how frequently the client makes data requests.
Achieving integrity against a potentially malicious server is
discussed in Section 3.8. We do not focus on integrity in our
main presentation.
3. THE PATH ORAM PROTOCOL
We ﬁrst describe the Path ORAM protocol with N/χ +
O(log N ) · ω(1) blocks of client storage, and then later in
Section 3.7 we explain how the client storage can be reduced
to O(log2 N/ log χ) · ω(1) blocks via recursion.
3.1 Overview
We now give an informal overview of the Path ORAM
protocol. The client stores a small amount of local data in
a stash. The server-side storage is treated as a binary tree
where each node is a bucket that can hold up to a ﬁxed
number of blocks.
Main invariant. We maintain the invariant that at any
time, each block is mapped to a uniformly random leaf bucket
in the tree, and unstashed blocks are always placed in some
bucket along the path to the mapped leaf.
Whenever a block is read from the server, the entire path
to the mapped leaf is read into the stash, the requested block
is remapped to another leaf, and then the path that was just
read is written back to the server. When the path is written
back to the server, additional blocks in the stash may be
evicted into the path as long as the invariant is preserved
and there is remaining space in the buckets.
3.2 Server Storage
Simplicity. We aim to provide an extremely simple ORAM
construction in contrast with previous work. Our scheme
consists of only 16 lines of pseudo-code as shown in Figure 1.
Data on the server is stored in a tree consisting of buckets
as nodes. The tree does not have to necessarily be a binary
tree, but we use a binary tree in our description for simplicity.
Security deﬁnitions. We adopt the standard security def-
inition for ORAMs from [34]. Intuitively, the security deﬁni-
tion requires that the server learns nothing about the access
pattern. In other words, no information should be leaked
about: 1) which data is being accessed; 2) how old it is
(when it was last accessed); 3) whether the same data is
being accessed (linkability); 4) access pattern (sequential,
random, etc); or 5) whether the access is a read or a write.
Definition 1
(Security definition). Let
(cid:126)y := ((opM , aM , dataM ), . . . , (op1, a1, data1))
denote a data request sequence of length M , where each opi
denotes a read(ai) or a write(ai, data) operation. Speciﬁcally,
ai denotes the identiﬁer of the block being read or written,
and datai denotes the data being written. In our notation,
index 1 corresponds to the most recent load/store and index