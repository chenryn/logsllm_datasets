# Path ORAM: An Extremely Simple Oblivious RAM Protocol

**Authors:**
- Emil Stefanov†
- Marten van Dijk‡
- Elaine Shi∗
- Christopher W. Fletcher◦
- Ling Ren◦
- Xiangyao Yu◦
- Srinivas Devadas◦

**Affiliations:**
- † UC Berkeley
- ‡ UConn
- ∗ UMD
- ◦ MIT CSAIL

## Abstract
We introduce Path ORAM, an extremely simple and efficient Oblivious RAM (ORAM) protocol that requires minimal client storage. Due to its simplicity, Path ORAM is the most practical ORAM scheme for small client storage known to date. We formally prove that Path ORAM achieves a bandwidth overhead of \(O(\log^2 N / \log \chi)\) for block size \(B = \chi \log N\). For block sizes larger than \(\omega(\log^2 N)\), Path ORAM outperforms the best-known ORAM schemes with small client storage. Its practicality has led to its adoption in the design of secure processors.

## Categories and Subject Descriptors
K.6.5 [Management of Computing and Information Systems]: Security and Protection

## General Terms
Algorithms, Security

## Keywords
Oblivious RAM, ORAM, Path ORAM, Access Pattern

## 1. Introduction
Data encryption alone is often insufficient to protect users' privacy in outsourced storage applications. The access pattern, or the sequence of storage locations accessed by the client, can leak significant information about the unencrypted data through statistical inference. For example, Islam et al. demonstrated that observing accesses to an encrypted email repository can reveal up to 80% of the search queries [21].

Oblivious RAM (ORAM) algorithms, first proposed by Goldreich and Ostrovsky [13], allow a client to conceal its access pattern to remote storage by continuously shuffling and re-encrypting data as it is accessed. While an adversary can observe the physical storage locations, the ORAM algorithm ensures that the adversary has a negligible probability of learning anything about the true (logical) access pattern. Since its proposal, the research community has strived to find an ORAM scheme that is both theoretically interesting and practical [4, 7, 12, 14–17, 22, 23, 25–27, 30, 33–38].

In this paper, we propose Path ORAM, a novel ORAM algorithm that is the most practical construction under small client storage. We provide theoretical bounds on its performance and present matching experimental results.

### Contributions of Path ORAM
1. **Simplicity and Practical Efficiency**: Compared to other ORAM algorithms, Path ORAM is significantly simpler. The core of the Path ORAM algorithm can be described in just 16 lines of pseudocode (see Figure 1). Unlike many existing ORAM algorithms, Path ORAM does not require sophisticated deamortized oblivious sorting or cuckoo hash table construction. Each ORAM access involves fetching and storing a single path in a tree stored remotely on the server.
   
2. **Asymptotic Efficiency**: For a reasonably large block size \(B = \chi \log N\) bits, where \(N\) is the total number of blocks, Path ORAM with recursion (as proposed in [30]) achieves an asymptotic bandwidth cost of \(O(\log^2 N / \log \chi)\) blocks. This result outperforms the best-known ORAM for small client storage [22] for block sizes typically encountered in practical applications.

3. **Practical and Theoretical Impact**: Since its introduction in February 2012, Path ORAM has made both practical and theoretical impacts. On the practical side, Path ORAM is the most suitable algorithm for hardware ORAM implementations due to its conceptual simplicity, small client storage, and practical efficiency. It has been adopted in the design of secure processors such as the Ascend processor architecture [9, 10]. On the theoretical side, subsequent works have adopted the idea of path eviction in their ORAM constructions, notably by Gentry et al. [11] and Chung et al. [6].

4. **Novel Proof Techniques**: Despite its simplicity, the proof for upper bounding the client storage is intricate and interesting. Our proof relies on creating a second ORAM construction and reducing Path ORAM to it. We provide concrete bounds showing that for \(M\) load/store operations on \(N\) data blocks, recursive Path ORAM with client storage \(\leq R \log N / \log \chi\) blocks, server storage \(28N\) blocks, and bandwidth \(14 (\log N)^2 / \log \chi\) blocks per load/store operation, fails with a probability \(\leq 14 \cdot 0.625^{-RM \log N / \log \chi}\). Empirical results indicate that the constants in practice are even lower than our theoretical bounds.

### 1.1 Related Work
Oblivious RAM was first investigated by Goldreich and Ostrovsky [12, 13, 25] in the context of protecting software from piracy and efficiently simulating programs on oblivious RAMs. Subsequent work has focused on improving ORAM constructions [4, 6, 7, 11–15, 17, 22, 25–27, 35, 37]. Path ORAM is based on the binary-tree ORAM framework proposed by Shi et al. [30].

#### Optimality of Path ORAM
Under small (i.e., constant or poly-logarithmic) client storage, the best-known ORAM was proposed by Kushilevitz et al. [22], with a bandwidth cost of \(O(\log^2 N / \log \log N)\) blocks. Path ORAM is competitive with Kushilevitz et al. [22] when the block size is at least \(\Omega(\log^2 N)\) bits and can outperform it for larger block sizes. For block size \(B = \Omega(\log^2 N)\) bits, Path ORAM's bandwidth cost matches the best-known bound of \(O(\log^2 N / \log \log N)\) blocks. For block sizes at least \(\Omega(\lambda)\) bits, where \(\lambda\) is the security parameter (e.g., \(\lambda = 128\) or \(\lambda = 256\)), Path ORAM's bandwidth cost is only \(O(\log N)\) blocks, with \(O(1)\) round-trips.

#### Comparison with Gentry et al. and Chung et al.
Gentry et al. [11] improve on the binary tree ORAM scheme proposed by Shi et al. [30], achieving a bandwidth cost of \(O(\lambda (\log N)^2 / (\log \lambda \log \chi))\) blocks for block size \(B = \chi \log N\) bits. Assuming \(N = \text{poly}(\lambda)\), their bandwidth cost is \(O(\lambda \log N / \log \chi)\) blocks. In comparison, recursive Path ORAM achieves \(O(\log^2 N / \log \chi)\) blocks, making it more efficient for typical values of \(\lambda \ll \log N\).

Chung and Pass [6] proved a similar (slightly worse) bound. Recently, Chung et al. [5] proposed a statistically secure binary-tree ORAM algorithm based on Path ORAM, with a theoretical bandwidth bound that is \(\log \log n\) factor worse than ours. Their simulation results suggest a practical bandwidth cost that is a constant factor worse than Path ORAM, as they require operating on 3 paths in expectation for each data access, while Path ORAM requires reading and writing only 1 path.

#### Statistical Security
Path ORAM is also statistically secure (not counting the encryption). Statistically secure ORAMs have been studied in several prior works [2, 8]. All known binary-tree-based ORAM schemes and variants are also statistically secure [6, 11, 30], assuming each bucket is a trivial ORAM.

## 2. Problem Definition
We consider a client that wishes to store data at a remote untrusted server while preserving its privacy. Traditional encryption schemes provide confidentiality but do not hide the data access pattern, which can reveal sensitive information to the untrusted server. We assume the server is untrusted, and the client, including its processor, memory, and disk, is trusted.

The goal of ORAM is to completely hide the data access pattern (which blocks were read/written) from the server. From the server’s perspective, read/write operations should be indistinguishable from random requests.

### Notations
- The client fetches/stores data on the server in atomic units called blocks, each of size \(B\) bits.
- \(N\) is the working set, i.e., the number of distinct data blocks stored in ORAM.
- Typical values for \(B\) in cloud storage are 64–256 KB, while for secure processors, smaller blocks (128 B to 4 KB) are preferable.

Our ORAM constructions do not consider information leakage through the timing channel, such as when or how frequently the client makes data requests. Achieving integrity against a potentially malicious server is discussed in Section 3.8.

## 3. The Path ORAM Protocol
We first describe the Path ORAM protocol with \(N/\chi + O(\log N) \cdot \omega(1)\) blocks of client storage, and then explain how the client storage can be reduced to \(O(\log^2 N / \log \chi) \cdot \omega(1)\) blocks via recursion.

### 3.1 Overview
Path ORAM maintains the invariant that each block is mapped to a uniformly random leaf bucket in a binary tree, and unstashed blocks are always placed in some bucket along the path to the mapped leaf. When a block is read, the entire path to the mapped leaf is read into the stash, the requested block is remapped, and the path is written back to the server. Additional blocks in the stash may be evicted into the path as long as the invariant is preserved and there is remaining space in the buckets.

### 3.2 Server Storage
Path ORAM aims to provide an extremely simple ORAM construction. Data on the server is stored in a binary tree consisting of buckets as nodes. We adopt the standard security definition for ORAMs from [34], which requires that the server learns nothing about the access pattern.

**Definition 1 (Security Definition):** Let \(\mathbf{y} := ((\text{op}_M, a_M, \text{data}_M), \ldots, (\text{op}_1, a_1, \text{data}_1))\) denote a data request sequence of length \(M\), where each \(\text{op}_i\) denotes a \(\text{read}(a_i)\) or \(\text{write}(a_i, \text{data})\) operation. Specifically, \(a_i\) denotes the identifier of the block being read or written, and \(\text{data}_i\) denotes the data being written. In our notation, index 1 corresponds to the most recent load/store and index \(M\) to the oldest.