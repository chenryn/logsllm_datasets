title:On Measuring the Similarity of Network Hosts: Pitfalls, New Metrics,
and Empirical Analyses
author:Scott E. Coull and
Fabian Monrose and
Michael Bailey
On Measuring the Similarity of Network Hosts:
Pitfalls, New Metrics, and Empirical Analyses
University of North Carolina
University of Michigan
Fabian Monrose
Chapel Hill, NC
PI:EMAIL
Michael Bailey
Ann Arbor, MI
PI:EMAIL
Scott E. Coull
RedJack, LLC.
Silver Spring, MD
PI:EMAIL
Abstract
As the scope and scale of network data grows, se-
curity practitioners and network operators are increas-
ingly turning to automated data analysis methods to ex-
tract meaningful information. Underpinning these meth-
ods are distance metrics that represent the similarity be-
tween two values or objects.
In this paper, we argue
that many of the obvious distance metrics used to mea-
sure behavioral similarity among network hosts fail to
capture the semantic meaning imbued by network pro-
tocols. Furthermore, they also tend to ignore long-term
temporal structure of the objects being measured. To ex-
plore the role of these semantic and temporal character-
istics, we develop a new behavioral distance metric for
network hosts and compare its performance to a met-
ric that ignores such information. Speciﬁcally, we pro-
pose semantically meaningful metrics for common data
types found within network data, show how these met-
rics can be combined to treat network data as a uniﬁed
metric space, and describe a temporal sequencing algo-
rithm that captures long-term causal relationships. In
doing so, we bring to light several challenges inherent
in deﬁning behavioral metrics for network data, and put
forth a new way of approaching network data analysis
problems. Our proposed metric is empirically evaluated
on a dataset of over 30 million network ﬂows, with re-
sults that underscore the utility of a holistic approach to
network data analysis.
1
Introduction
Network operators face a bewildering array of secu-
rity and operational challenges that require signiﬁcant
instrumentation and measurement of their networks, in-
cluding denial of service attacks, supporting quality of
service, and capacity planning. Unfortunately, the com-
plexity of modern networks often make manual exami-
nation of the data provided by such instrumentation im-
practical. As a result, operators and security practition-
ers turn to automated analysis methods to pinpoint in-
teresting or anomalous network activities. Underlying
each of these methods and their associated applications
is a fundamental question: to what extent are two sets of
network activities similar?
As straightforward as this may seem, the techniques
for determining this similarity are as varied as the num-
ber of domains they have been applied to. These range
from identifying duplicates and minor variations using
cryptographic hashes and edit distance of payloads, to
the use of distributions of features and their related
statistics (e.g., entropy). While each has been shown to
provide value in solving speciﬁc problems, the diversity
of approaches clearly indicates that there is no generally
accepted method for reasoning about the similarity of
network activities.
With this in mind, the goal of this paper is to make
progress in developing a uniﬁed approach to measur-
ing the similarity of network activities. In doing so, we
hope to encourage a more rigorous method for describ-
ing network behaviors, which will hopefully lead to new
applications that would be difﬁcult to achieve otherwise.
While a complete framework for rigorously deﬁning dis-
tance is beyond the scope of any one paper, we address
two key aspects of network similarity that we believe
must be considered in any such a framework. That is,
the spatial and temporal characteristics of the network
data.
Here, spatial characteristics refer to the unique se-
mantic relationships between the values in two identi-
cal or related ﬁelds. For example, if we wish to cluster
tuples of data that included IP addresses and port num-
bers, we would have two obvious ways of accomplish-
ing the task: (1) treat the IPs and ports as numeric val-
ues (i.e., integers) and use subtraction to calculate their
distance, or (2) treat them as discrete values with no re-
lationship to one another (e.g., in a probability distribu-
tion). Clearly, neither of these two options is exactly cor-
rect, since the network protocols that deﬁne these data
types also deﬁne unique semantic relationships.
Temporal characteristics, on the other hand, describe
the causal relationships among the network activities
over time. One way to capture temporal information is
to examine short n-grams or k-tuples of network activ-
ities. However, this too may ignore important aspects
of network data. As an example, changes in trafﬁc vol-
ume may alter the temporal locality captured by these
short windows of activity. Moreover, network data has
no restriction on this temporal locality, which means that
activities can have long-term causal relationships with
each other, extending to minutes, hours, or even days.
Successfully building robust notions of similarity that
address these temporal characteristics mean addressing
similarity over large time scales.
Contributions.
In this paper, we explore these spatial
and temporal properties in an effort to learn what im-
pact they may have on the performance of automated
network analysis methods. To focus our study, we ex-
amine the problem of classifying host behaviors, which
requires both strong notions of semantically-meaningful
behavior and causal relationships among these behav-
iors to provide a meaningful classiﬁcation. Furthermore,
we develop an example uniﬁed metric space for network
data that encodes the unique spatial and temporal prop-
erties of host behavior, and evaluate our proposed met-
ric by comparing it to one that ignores those properties.
We note that it is not our intention to state that current
analysis methodologies are “wrong,” nor that we present
the best metric for computing similarity. Instead, we ex-
plore whether general metrics for network activities can
be created, how such metrics might lead to improved
analysis, and examine the potential for new directions
of research.
More concretely, we begin by deﬁning metric spaces
for a subset of data types commonly found within net-
work data. We design these metric spaces to encode
the underlying semantic relationship among the values
for the given data type, including non-numeric types
like IP addresses and port numbers. Then, we show
how to combine these heterogeneous metric spaces into
a uniﬁed metric space that treats network data records
(e.g., packets, network ﬂows) as points in a multi-
dimensional space. Finally, we describe host behaviors
as a time series of these points, and provide a dynamic
time warping algorithm that efﬁciently measures behav-
ioral distance between hosts, even when those time se-
ries contain millions of points.
In doing so, we de-
velop a geometric interpretation of host behavior that is
grounded in semantically-meaningful measures of be-
havior, and the long-term temporal characteristics of
those behaviors. Wherever possible, we bring to light
several challenges that arise in the development of gen-
eral metrics for network data.
To evaluate our proposed metric, we use a dataset
containing over 30 million ﬂows collected at the Uni-
versity of Michigan. Our experiments compare the per-
formance of our metric to that of the L1 (i.e., Manhattan
distance) metric, which ignores semantics and temporal
information, in a variety of cluster analysis tasks. The
results of these experiments indicate that semantic and
temporal information play an important role in captur-
ing a realistic and intuitive notion of network behaviors.
Furthermore, these results imply that it may be possible
to treat network data in a more rigorous way, similar to
traditional forms of numeric data. To underscore this po-
tential, we show how our metric may be used to measure
the privacy provided by anonymized network data in the
context of well-established privacy deﬁnitions for real-
valued, numeric data; namely, Chawla et al. ’s (c, t)-
isolation deﬁnition [6].
2 Related Work
There is a long, rich body of work related to de-
veloping automated methods of network data analy-
sis. These include, but are not limited to, supervised
[18, 8, 2, 30, 9, 31] and unsupervised [17, 15, 29, 14,
10, 32, 3] trafﬁc classiﬁcation, anomaly and intrusion
detection [11, 28, 27, 24, 13], and data privacy appli-
cations [7, 25, 16, 4]. Rather than attempt to enumer-
ate the various approaches to automated data analysis,
we instead point the interested reader to recent surveys
of trafﬁc classiﬁcation [22] and anomaly detection tech-
niques [5]. Also, we reiterate that the purpose of this
paper is to explore the role of semantics and temporal
information in developing a framework for deﬁning sim-
ilarity among network activities – a task that, to the best
of our knowledge, has not been thoroughly examined in
the literature thus far.
Of the network data analysis approaches proposed
thus far, the work of Eskin et al.
[11] is most closely
related to our own. Eskin et al. address the problem of
unsupervised anomaly detection by framing it as a form
of outlier detection in a geometric space. Their approach
uses kernel functions to map arbitrary input spaces to
a high-dimensional feature space that encodes the dis-
tances among the input values. They show how to use
these kernel functions to encode short windows of k sys-
tem calls for host-based anomaly detection, and ﬁelds
found within network data for network-based detection.
Clearly, Eskin et al. share our goal of describing a
uniﬁed metric (i.e., feature) space for measuring the sim-
ilarity of network data. However, there are two very im-
portant distinctions. First, while Eskin et al. show how to
map non-numeric types (e.g., IP addresses) to a common
feature space, they do so in such a way that all semantic
relationships among the values is removed. In particu-
lar, their kernel function treats each value as a discrete
value with a binary distance measure: either the value is
the same or it is different. Second, their approach for en-
coding sequences of activities (i.e., system calls in their
case) is limited to relatively short windows due to the ex-
ponential growth in dimensions of the feature space and
the sparsity of that space (i.e., the “curse of dimension-
ality”). By contrast, we seek to explore the semantic and
temporal information that is missing from their metrics
by developing semantically-meaningful spatial metrics
and long-term temporal metrics based on dynamic time
warping of time series data.
3 Preliminaries
For ease of exposition, we ﬁrst provide deﬁnitions
and notation that describe the network data we analyze
in a format-independent manner. We also deﬁne the
concepts of metric spaces and product metrics, which
we use to create a foundation for measuring similarity
among network hosts.
Network Data Data describing computer network ac-
tivities may come in many different forms, including
packet traces, ﬂow logs, and web proxy logs. Rather
than describe each of the possible formats individually,
we instead deﬁne network data as a whole in more ab-
stract terms. Speciﬁcally, we consider all network data
to be a database of m rows and n columns, which we
represent as an m × n matrix. The rows represent indi-
vidual records, such as packets or ﬂows, with n ﬁelds,
which may include source and destination IP addresses,
port numbers, and time stamps. We denote the ith row
as the n-dimensional vector (cid:126)vi =,
and the database as V =T . For our pur-
poses, we assume a total ordering on the rows (cid:126)vi ≤ (cid:126)vi+1
based on when the record was added to the database by
the network sensor. Furthermore, we associate each col-
umn in the matrix (i.e., ﬁeld) with an atomic data type
that deﬁnes the semantic relationship among its values.
More formally, we deﬁne a set of types T = {t1, . . . , t(cid:96)}
and an injective function F : [1, n] → T that maps a col-
umn to its associated data type.
Metric Spaces To capture a notion of similarity
among values in each column, we deﬁne a metric space
for each data type in the set T . A metric space is sim-
ply a tuple (X, d), where X is a non-empty set of val-
ues being measured and d : X × X → R+ is a non-
negative distance metric. The metric function must sat-
isfy three properties: (1) d(x, y) = 0 iff x = y; (2)
d(x, y) = d(y, x); and (3) d(x, y) + d(y, z) ≥ d(x, z).
We denote the metric for the type tj as (Xtj , dtj ).
Given the metric spaces associated with each of the
columns via the data type mapping described above,
(XF (1), dF (n)), . . . , (XF (n), dF (n)), we can deﬁne a p-
product metric to combine the heterogeneous metric
spaces into a single metric space that measures simi-
larity among records as if they were points in an n-
dimensional space. Speciﬁcally,
the p-product met-
ric is deﬁned as (XF (1) × . . . × XF (n), dp), where
XF (1) × ··· × XF (n) denotes the Cartesian product of
the sets and dp is the p-norm:
dp((cid:126)x, (cid:126)y) = (dF (1)(x1, y1)p + ··· + dF (n)(xn, yn)p) 1
We note that metrics we propose are straightforward
generalizations of well-known metrics [19]; hence, the
proofs are omitted for brevity.
p
4 Metric Spaces for Network Data
To provide a foundation for measuring similarity
among network hosts, we deﬁne a metric space that cap-
tures both the spatial and temporal characteristics of the
host’s behaviors as follows. We begin by deﬁning met-
rics spaces that capture semantically rich relationships
among the values for each data type found in the net-
work data. For the purposes of this initial study, we re-
strict ourselves to providing example metrics for four
prevalent data types: IP addresses, port numbers, time
ﬁelds, and size ﬁelds. Next, we show how to combine
these heterogeneous metric spaces into a single, uniﬁed
metric space using a p-product metric and a novel nor-
malization procedure that retains the semantic relation-
ships of the constituent metric spaces. This allows us
to treat each network data record as a point and cap-
ture the spatial characteristics of the host’s behavior in
a meaningful way. Finally, we model a host’s temporal
behavior as a time series of points made up of records
associated with the host (e.g., ﬂows sent or received by
the host), and show how dynamic time warping may be
used to efﬁciently measure distance between the behav-
ior of two hosts.
4.1 Data Types and Metric Spaces
Network data may contain a wide variety of data
types, each with its own unique semantics and range of
possible values. That said, without loss of generality,
we can classify these types as being numeric (e.g., times-
tamps, TTL values, sizes) or categorical (e.g., TCP ﬂags,
IPs, ports) in nature. The primary distinction between
these two categories of types is that numeric types have
distance metrics that naturally follow from the integer or
real number values used to represent them, while cate-
gorical types often do not maintain obvious linear rela-
tionships among the values. Here, we describe example
metric spaces for two data types in each category: time
and size as numeric types, and IP and port as categorical.
Numeric Types. The time and size data types contain
values syntactically encoded as 16 or 32 bit integers, and
(a) Distance hierarchy for port type.
(b) Distance hierarchy for IP type.
Figure 1. Distance metrics for categorical types of port and IP. Distances listed to the left
indicate the distance when values diverge at that level of the hierarchy.
have semantics that mirror those of the integers them-
selves. That is, a distance of ten in the integers is se-
mantically the same as ten bytes or ten seconds1. Both
types can be represented by metric spaces of the form
(X = {0, . . . , M}, d(x, y) = |x− y|), where M is sim-