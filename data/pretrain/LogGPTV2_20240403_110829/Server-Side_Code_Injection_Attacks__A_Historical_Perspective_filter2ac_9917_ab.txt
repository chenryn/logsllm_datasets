a minimalistic environment which allows (emulated) execution of system calls.
Both approaches allow the generation of understanding on the payload behav-
ior: nemu is able to identify the plaintext payload generated by the decryption
loop [51]; libemu instead fully executes the shellcode, including the payload,
and allows the identiﬁcation of the executed system calls. An alternative high-
performance implementation is adopted by ShellOS [52], which uses a separate
virtual machine to monitor and analyze the memory buﬀers of a virtual machine.
3 Dataset
Our analysis is based on an extensive data set of server-side attacks collected
by the SGNET distributed honeypot deployment [5,25] over a period ranging
from the 12th of September 2007 until the 12th of September 2012, i.e., exactly
5 years.
6
3.1 Raw data
SGNET is an initiative open to any institution willing to access the collected
data, where partners interested in participating are required to contribute by
hosting a honeypot at the premises of their network.
SGNET is a hybrid system that combines high interaction techniques (Ar-
gos [17]) with protocol learning techniques [53,54], allowing SGNET sensors to
gradually learn to autonomously handle well-known activities. Thanks to this
learning process, SGNET honeypots are capable of carrying on rich interactions
with attackers without requiring a-priori knowledge of the type of exploits they
will be subjected to. The implementation of the sensors has changed over the
years, and their logging capabilities have changed as well. This leads to limita-
tions in our ability to compare insights provided by the SGNET internal com-
ponents, whose implementation and characteristics have changed. For instance,
SGNET leveraged diﬀerent versions of argos [17], a costly but very reliable tech-
nique for the identiﬁcation of code injection attack by means of memory tainting.
Only certain releases of SGNET stored the Argos output, and the information
is thus available only on a small portion of the dataset. Despite the inability
to leverage this type of information, the SGNET maintainers have decided to
collect since the beginning of the project full packet traces of all the interactions
observed by the active honeypots, which now amount to more than 100GB of raw
data that are made available to all partners. Despite the diﬀerent capabilities of
the sensors in handling code injection attacks, this raw data can be used as a
benchmarking platform for the analysis of the performance of diﬀerent analysis
and detection tools.
The SGNET project has enforced on all participants a number of rules to
ensure the stability and the comparability of the observations. All sensors run
a well-deﬁned and controlled software conﬁguration, and each sensor is always
associated to 3 public IP addresses and to a well deﬁned emulation proﬁle.
The proﬁle of the honeypots has changed only once throughout the observation
period, in February 2011, when the original emulation proﬁle (a Microsoft Win-
dows 2000 SP0 OS running IIS services) was upgraded to Windows XP SP0. It
is clear that, as a side-eﬀect of the partnership schema enforced by the project,
the dataset at our disposal is sparse: the honeypot addresses do not belong to
a single network block but to a variety of organizations (ISPs, academic institu-
tions, but also industry) spread all over the world. This is a very important and
rather unique property that allows us to have visibility on a variety of diﬀerent
segments of the IP space, and also considerably reduces the concerns associated
to the detectability of the honeypots, and the representativeness of the data it
collected. Each sensor is associated to only three, often non-contiguous, IP ad-
dresses in a monitored network. Diﬀerently from larger honeynets, creating a list
of the addresses monitored by SGNET is an extremely costly action that to the
best of our knowledge was never carried out so far. The sparsity of the obser-
vations also introduces important challenges in the analysis. SGNET honeypots
are in fact deployed on a voluntary basis, and this causes signiﬁcant ﬂuctuations
in the number of active honeypots throughout the deployment lifetime. Over
7
Detector name
snort
snort-shellcode
snort-et
Description
Flags ﬂows as attacks whenever any exploit-speciﬁc alert is raised
by Snort.
Flags ﬂows as attacks whenever any generic shellcode-detection
alert is raised by Snort.
Flags ﬂows as attacks whenever any exploit-speciﬁc alert is raised
by Snort using the Emerging Threats (ETPro) ruleset.
snort-et-shellcode Flags ﬂows as attacks whenever any generic shellcode detection
alert is rasied by Snort using the Emerging Threats (ETPro)
ruleset.
Static heuristics for the detection of common packers and pay-
loads used in the Amun honeypot.
Used in this paper to ﬂag ﬂows as attacks by means of a set of
getPC heuristics.
Flags ﬂows as attacks when a polymorphic shellcode is detected,
or a plaintext payload matching certain heuristics.
libemu
amun
nemu
Table 1. Summary of the detection methods considered in the paper.
these ﬁve years, the deployment varies from a total of 10 active sensors to a
maximum of 71, achieved in 2010. In general, as we will see in Figure 3, the
achieved coverage of the IP space varies signiﬁcantly. This variability needs to
be taken carefully into account throughout the analysis.
3.2
Identifying exploits
Among the diﬀerent exploit detection techniques proposed in the literature, we
have chosen to focus on three classes of approaches that are used in operational
environments and that are suitable to oﬄine analysis of captured traces. The
three classes are associated with a diﬀerent level of sophistication and reliance
on a-priori knowledge, as summarized in Table 1.
Signature-based approaches. We include in our study the two most commonly
used rule sets for the Snort IDS [9]:
– The oﬃcial Snort ruleset, generated by the SourceFire Vulnerability Research
Team (VRT). We have used the rules version 2931 (9 October 2012).
– The ruleset provided by Emerging Threats, that is now maintained in the
context of a commercial oﬀering. While an open version of the ruleset is still
available, we have been granted access to the more complete ETPro ruleset
(May 2013) that was used for the experiments.
For both rulesets we have identiﬁed two classes of signatures. Some attempt to
detect speciﬁc network threats, and thus incorporate detailed information on the
activity being detected (e.g., a particular vulnerability being exploited through
a speciﬁc service). Other signatures are instead more generic, and attempt to
identify byte sequences that are inherent in the transmission of a shellcode in-
dependently from the involved protocol or vulnerability. For each ruleset, we
have deﬁned two separate detectors: a detector ﬂagging any ﬂow triggering one
8
of the generic shellcode detection signatures (with suﬃx -shellcode) and another
ﬂagging any ﬂow triggering any of the attack-speciﬁc signatures.
Shellcode emulation heuristics. Widely used honeypot techniques such as Ne-
penthes [20] and its python counterpart Amun [21] use a set of heuristics to iden-
tify unencrypted payloads, as well as common decryptors. While not designed
speciﬁcally for the purpose of attack identiﬁcation, the shellcode identiﬁcation
component of these honeypots is particularly critical to their ability to collect
malware: while simple exploit emulation techniques are often suﬃcient to collect
payloads, the inability of the honeypot to correctly emulate a shellcode will ren-
der it completely blind to the associated malware variant. This is particularly
relevant considering the prominent role these technologies still have nowadays
in contributing fresh samples to common malware repositories.
CPU emulators. Finally, we have included in the study two widely known
CPU emulation approaches for the detection of shellcode, namely libemu [23]
(used in the Dionaea [22] honeypot) and nemu [49]. We have used libemu in its
most common conﬁguration, which uses heuristics for the identiﬁcation of getPC
code to detect the presence of a valid shellcode. The approach followed by nemu is
instead more sophisticated and applies runtime execution heuristics that match
certain instructions, memory accesses, and other machine-level operations. Nemu
has been extended to also detect plain, non-self-decrypting shellcode using a set
of heuristics that match inherent operations of diﬀerent plain shellcode types,
such as the process of resolving the base address of a DLL through the Process
Environment Block (PEB) or the Thread Information Block (TIB) [51].
For each detected shellcode, Nemu generates a detailed trace of all executed
instructions and accessed memory locations. For self-decrypting shellcodes, we
extracted the decryption routine from the execution trace by identifying the
seeding instruction of the GetPC code (usually a call or fstenv instruction),
which stores the program counter in a memory location. Nemu also identiﬁes
the execution of loops, so we consider the branch instruction of the loop that
iterates through the encrypted payload as the ﬁnal instruction of the decryptor.
To account for variations in the operand values of the decryptor’s instructions,
e.g., due to diﬀerent encryption keys, shellcode lengths, and memory locations,
we categorize each decryptor implementation by considering its sequence of in-
struction opcodes, without their operands [55].
We have chosen to exclude from the analysis the identiﬁcation of ROP pay-
loads [56] and ShellOS [52]. ROP attack detection requires detailed assumptions
on the conﬁguration and runtime memory of the targeted application. Similarly,
ShellOS is not particularly suitable for oﬄine analysis as it requires replaying
the collected traﬃc against an instrumented virtualization environment.
4 A historical perspective
The ﬁve years of data at our disposal allow us to step back, and critically look at
the evolution of the threat landscape and the impact of its changes on the tools
at our disposal. How is the threat landscape structured across the IP space, and
9
Fig. 1. Attacks per day, per honeypot,
detected by diﬀerent tools.
Fig. 2. Attacks per day, per honeypot,
for diﬀerent targeted ports.
how has it evolved over the years? What is the impact of this evolution on the
diﬀerent intrusion detection practices?
Figure 1 graphically represents the information at our disposal. Each of the
tools introduced in the previous section has ﬂagged a certain amount of ﬂows as
“attacks.” In order to take into account the varying number of sensors, we have
normalized the number of observed events with the total number of honeypot
sensors known to be active in a speciﬁc day. For better readability of the graph,
we have sampled the daily observations into monthly averages. The snort-et
detector is particularly noisy due to its inherent characteristics: intrusion detec-
tion systems go beyond the detection of code injection attacks and focus also on
other threats. For instance, the spike observable in July 2011 is associated to a
large amount of SSH scan activities generated by a misconﬁgured sensor. But
even factoring these diﬀerences, we can see a signiﬁcant variance in the number
of ﬂows identiﬁed by the various detectors, and only libemu and nemu almost
perfectly overlap in the number of detected attacks.
Figure 2 shows the distribution across time of the ports receiving the highest
attack volume. Not surprisingly, the three ports with the highest volume are the
typical Windows ports (445, 139, 135). However, their distribution over time has
changed signiﬁcantly. Back in 2008, most of the observed attacks were against the
DCE/RPC locator service. While this type of exploits has only slightly dimin-
ished over the years, it has been overtaken in 2009 by a much higher attack load
on the Microsoft-DS port (445). Exploits against port 2967 (only 53 sessions)
have been observed only for a few weeks in 2008, but have never been observed
since then. We have no reason to believe that these trends can be associated
to any kind of change in the level of attack sophistication; rather, these trends
directly reﬂect the evolution of the vulnerability surface for the diﬀerent services
over the years. Attacks leveraging vulnerabilities that were left unpatched by
the largest group of users are those who became more successful.
This ﬁrst high level picture underlines important trends in terms of attack
volume. The attack volume per installed honeypot increases steadily with a
major peak at the end of 2009 (which as we will see coincides with the initial
20082009201020112012time050100150200# attacks per honeypot address per dayamunlibemunemusnortsnort_shellcodesnort_etsnort_et_shellcode20082009201020112012time0102030405060# attacks per honeypot address per dayport 139port 135port 445port 296710
Fig. 3. Evolution of attacks observed in diﬀerent \8 networks.
spread of the Conﬁcker worm). The second half of 2011 coincides instead with an
overall decrease of attack activity. A full understanding of this trend is possible
only by going more in depth in the dataset and understanding the distribution
of the attacks across the IP space.
4.1 Characterizing the IP space
The fact that the scanning activity across the IP space is not uniformly spread
is well known, and was documented by diﬀerent research groups already in
2004 [3,4]. However, due to the intrinsic diﬃculty associated to dispersing mon-
itoring sensors across the Internet, previous work had leveraged low-interaction
honeypots and had limited the analysis to the identiﬁcation of diﬀerent packet
rates [4] across diﬀerent networks or the identiﬁcation of diﬀerent high level
attack proﬁles [3]. The information at our disposal in this paper is diﬀerent:
we have visibility on the complete exploitation phase on a variety of identical
honeypots dispersed across the Internet.
Attack volumes. This unique perspective is shown in Figure 3, in which we
have looked at the way the observed events are distributed over the diﬀerent net-
works the SGNET deployment was monitoring. Every y-coordinate is associated
to a speciﬁc \8 network monitored by one or more SGNET sensors. The size of