title:A Guided Approach to Behavioral Authentication
author:Yeeun Ku and
Leo Hyun Park and
Sooyeon Shin and
Taekyoung Kwon
POSTER: A Guided Approach to Behavioral Authentication
Yeeun Ku, Leo Hyun Park, Sooyeon Shin, and Taekyoung Kwon∗
Yonsei University, Seoul, 03722, Korea
{koo_secure,dofi,shinsy80,taekyoung}@yonsei.ac.kr
ABSTRACT
User’s behavioral biometrics are promising as authentication factors
in particular if accuracy is sufficiently guaranteed. They can be
used to augment security in combination with other authentication
factors. A gesture-based pattern lock system is a good example
of such multi-factor authentication, using touch dynamics in a
smartphone. However, touch dynamics can be significantly affected
by a shape of gestures with regard to the performance and accuracy,
and our concern is that user-chosen patterns are likely far from
producing such a good shape of gestures. In this poster, we raise this
problem and show our experimental study conducted in this regard.
We investigate if there is a reproducible correlation between shape
and accuracy and if we can derive effective attribute values for user
guidance, based on the gesture-based pattern lock system. In more
general, we discuss a guided approach to behavioral authentication.
CCS CONCEPTS
• Security and privacy → Usability in security and privacy;
KEYWORDS
authentication; smartphone; pattern lock; behavior;
ACM Reference Format:
Yeeun Ku, Leo Hyun Park, Sooyeon Shin, and Taekyoung Kwon. 2018.
POSTER: A Guided Approach to Behavioral Authentication. In 2018 ACM
SIGSAC Conference on Computer and Communications Security (CCS ’18),
October 15–19, 2018, Toronto, ON, Canada. ACM, New York, NY, USA, 3 pages.
https://doi.org/10.1145/3243734.3278488
1 INTRODUCTION
Behavioral authentication (or behavior-based authentication) is a
prospective approach to user authentication – user’s behavioral
biometrics are measured by various sensing (and monitoring) mech-
anisms and leveraged for authentication. In particular the security
of user authentication can be dramatically augmented if behav-
ioral authentication is combined with traditional authentication
methods in the vein of multi-factor authentication. For example, it
would be a promising two-factor combination to mix a pattern lock
system with gesture-based recognition on a smartphone having
already plenty of sensing mechanisms [2]. Even if an adversary
peeps at a secret pattern drawn by a user, e.g., through shoulder-
surfing attacks [10] or smudge attacks [1], or occasionally guesses
∗Corresponding author
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5693-0/18/10.
https://doi.org/10.1145/3243734.3278488
Figure 1: Concept of guided approach. When a user selects
a pattern, the system guides it for a good shape of gestures.
The policy is set from attribute definition and measurement.
the poorly-chosen pattern in a few attempts [11], it is unlikely that
she can mimic the user’s drawing gestures to fool various sensing
mechanisms of smartphone at authentication [4]. However, prob-
lems remain: First, behavioral authentication demands a number of
sensors and extractable features for accuracy in authentication [8].
Second, the accuracy heavily depends on the shapes of gestures –
not all gestures perform fairly for authentication [4]. Thus, our
study is strongly motivated by these problems, particularly for the
combination of pattern lock and gesture recognition.
The pattern lock system is a graphical password mechanism pop-
ularly deployed in Android devices, and it stems from earlier recall-
based systems such as Draw-A-Secret (DAS) [3] and Pass–Go [7].
Even in case that the pattern lock system is combined with ges-
ture recognition using touch dynamics, e.g., [2], a user may choose
a simple secret pattern at convenience [9], or a poorer (saying,
simpler) pattern by presuming stronger security coming from two-
factor authentication. Indeed, from the perspectives of behavioral
authentication, our concern is that user-chosen patterns can be
usually so simple not to assure a shape of gestures required for
good accuracy in authentication. On the other hand, too complex
patterns could also deteriorate the accuracy in authentication if
a complex drawing pattern and its longer drawing time increase
the degree of freedom. That is, our concern is about the shape of
gestures and its quality, caused by user-chosen patterns.
In this poster, we raise the aforementioned problems and present
our experimental study performed in this regard – we study if there
is a correlation between shape and accuracy, which is reproducible
to guide users. Saying, our ultimate proposal is that a system guides
a user to select a secret pattern having a good shape and quality
for accuracy in behavioral authentication without losing security.
In more general, we propose a guided approach to behavioral au-
thentication. Accordingly, our study is focused on the pattern lock
system combined with gesture recognition using touch dynamics
in a smartphone, but can be extended for further combinations.
2 OUR APPROACH
Figure 1 illustrates the basic concept of our guided approach. We
assume that the dependency of accuracy is closely related to the
four attributes (i.e., the number of segments in a straight-line, an
angle, a direction, and the number of turns) of a pattern. Segment
Password Generationcaption. Overview and process of behavioral authentication with policy for various shapes of gestures (e.g., pattern, rotate, drawing, sliding, zoom-in, zoom-out, and etc.).User AuthenticationUser EnrollmentFeatureExtractionAuthenticationSuccess or FailDataCollectionModelTrainingStorageClassiﬁcationDecisionMakingUser AuthenticationUser EnrollmentFeatureExtractionAuthenticationSuccess or FailDataCollectionModelTrainingStorageClassiﬁcationDecisionMakingUser AuthenticationUser EnrollmentFeatureExtractionAuthenticationSuccess or FailDataCollectionModelTrainingStorageClassiﬁcationDecisionMakingUser AuthenticationPhaseUser EnrollmentPhaseAuthenticationSuccess or FailDecisionMakingPolicyGestures+MeasurementAttributesAngleSegmentTurnDirectionStatistical TestFriedmanWilcoxonMachine LearningDTSVMkNNGNBRFLRRecommendationPolicyEnforcement How about these patterns?InteractiveGuidancePoster PresentationCCS’18, October 15-19, 2018, Toronto, ON, Canada2237(cid:113)
y + s2
s2
x + s2
z where sx , sy, and sz are the readings of each
SM =
sensor along the X, Y and Z directions. Tables 1 and 2 list 16 and 90
features extracted from touch events and sensors, respectively.
3 EVALUATION
Study Design. We developed a customized pattern lock applica-
tion on Samsung Galaxy S8 to collect touch dynamics. While a
user draws a pattern, the application records the touch dynamics
acquired from touchscreen and sensors. We then recruited 20 par-
ticipants (two females, 18 males) who experienced pattern lock by
word of mouth and fliers on bulletin boards in a university. They
were students, general office workers and university staffs, and on
average 27.7 years old (SD = 5.7). We gave a phone to each par-
ticipant and asked them to draw the 29 patterns. Each participant
drew each pattern for at least 25 times.
Based on 25 touch dynamics samples for each pattern, we mea-
sured the accuracy of 106 individual features using five-fold cross
validation and compared the results in the same attribute each other.
We then evaluated the impact of values for each attribute group
or subgroup. We employed the six classification algorithms, which
are known to be very effective for behavioral authentication [8]:
namely, Decision Tree (DT), Support Vector Machine (SVM), K-
Nearest Neighbor (kNN), Gaussian Naive Bayes (GNB), Random
Forest (RF), and Logistic Regression (LR). This study was approved
by the Institutional Review Board (IRB) of the local university.
Results. We performed the statistical tests to ascertain whether
there exists the accuracy differences between patterns for different
attribute values. We compared the accuracies of 106 individual
features of patterns for different attribute values. A significance
level α was set at 5%. The null hypothesis was that there exist no
significant differences among patterns for different attribute values
in terms of the accuracy to classify a participant. The Friedman
test was adopted to determine the overall significant differences
among three or more patterns and the Wilcoxon signed-rank test
was conducted to establish the significant differences between two
patterns. If there was a difference in the results of the Friedman
Table 2: Features from sensors (a total of 90).
Accelero
meter
Magneto
meter
Gyro
scope
Description
avgAX
avgAY
avgAZ
avgAM
numPAX
numPAY
numPAZ
numNAX
numNAY
numNAZ
stdAX
stdAY
stdAZ
stdAM
maxAX
maxAY
maxAZ
maxAM
minAX
minAY
minAZ
minAM
skewAX
skewAY
skewAZ
skewAM
kurAX
kurAY
kurAZ
kurAM
avgOX
avgOY
avgOZ
avgOM
numPOX
numPOY
numPOZ
numNOX
numNOY
numNOZ
stdOX
stdOY
stdOZ
stdOM
maxOX
maxOY
maxOZ
maxOM
minOX
minOY
minOZ
minOM
skewOX
skewOY
skewOZ
skewOM
kurOX
kurOY
kurOZ
kurOM
avgGX
avgGY
avgGZ
avgGM
numPGX
numPGY
numPGZ
numNGX
numNGY
numNGZ
stdGX
stdGY
stdGZ
stdGM
maxGX
maxGY
maxGZ
maxGM
minGX
minGY
minGZ
minGM
skewGX
skewGY
skewGZ
skewGM
kurGX
kurGY
kurGZ
kurGM
Average x-axis value of each sensor
Average y-axis value of each sensor
Average z-axis value of each sensor
Average magnitude value of each sensor
Number of positive x-axis values of each sensor
Number of positive y-axis values of each sensor
Number of positive z-axis values of each sensor
Number of negative x-axis values of each sensor
Number of negative y-axis values of each sensor
Number of negative z-axis values of each sensor
Standard deviation of x-axis value of each sensor
Standard deviation of y-axis value of each sensor
Standard deviation of z-axis value of each sensor
Standard deviation of magnitude value of each sensor
Maximum x-axis value of each sensor
Maximum y-axis value of each sensor
Maximum z-axis value of each sensor
Maximum magnitude value of each sensor
Minimum x-axis value of each sensor
Minimum y-axis value of each sensor
Minimum z-axis value of each sensor
Minimum magnitude value of each sensor
Skewness of x-axis of each sensor
Skewness of y-axis of each sensor
Skewness of z-axis of each sensor
Skewness of magnitude of each sensor
Kurtosis of x-axis of each sensor
Kurtosis of y-axis of each sensor
Kurtosis of z-axis of each sensor
Kurtosis of magnitude of each sensor
Figure 2: Component patterns with different values for each
attribute considered for guidance.
is a straight-line, that connects dot-to-dot on the 3×3 grid [6]. For
example, in Figure 2, the pattern S1 and S2 have one segment and
two segments, respectively. We define possible values for each
attribute and measure the accuracy of patterns for each value then
perform statistical tests. Therefore, we set a policy about effective
attribute values so that users who use a gesture-based pattern lock
system can refer the policy as a guide then generate the effective
and secure patterns. For example, the policy can be suggested as a
recommendation on a screen when a user generates a secret pattern.
If the shape of the pattern is not effective to classify a user, the
authentication performance may decrease. To design the pattern
which meet the high accuracy, we defined 29 component patterns
for different attributes and values, as presented in Figure 2. As each
attribute is independent, the patterns, except segment, have the
same number of segments but their values are different. For the
direction attribute, patterns are grouped into subgroups by angle.
Touch dynamics which captures how a user touches the touch-
screen finely vary depending on the habit of user’s smartphone
usage. We expect that the pattern-drawing behavior of users can be
used to classify them, and acquire touch dynamics data when a user
draws a pattern on the 3×3 grid and extract the useful features, from
the acquired data, on a segment basis. The features extracted from
the touch events are intimately related to interactions between
a touchscreen and the pattern-drawing of user [8]; Meanwhile,
the pattern-drawing behavior of users typically causes condition
changes of the smartphone. These condition changes can be profiled
with three-dimensional sensors: accelerometer, gyroscope, and mag-
netometer. We extract the features with x, y, and z-axis values from
sensors and also the magnitude of each sensor [5]. It is computed as
Table 1: Features from touch events (a total of 16).
Touch event Feature
Description
numTE
avgTP
stdTP
maxTP
minTP
avgTS
stdTS
maxTS
minTS
avgSS
stdSS
maxSS
minSS
SS
SA
TD
Number of touch events of each segment
Average of touch pressure of each segment
Standard deviation of touch pressure of each segment
Maximum of touch pressure of each segment
Minimum of touch pressure of each segment
Average of touch size of each segment
Standard deviation of touch size of each segment
Maximum of touch size of each segment
Minimum of touch size of each segment
Average of slide speed of each segment
Standard deviation of slide speed of each segment
Maximum of slide speed of each segment
Minimum of slide speed of each segment
Slide speed when moving from one point to the next
Slide angle when moving from one point to the next
Time duration of each segment
SegmentS1A5A4A3A2A6A1A7A8T1T2T3D1D2D3D4D5D6D7D8D9D10D11D12DirectionD13D14D15D16TurnS2AnglePoster PresentationCCS’18, October 15-19, 2018, Toronto, ON, Canada2238Table 3: Policy regarding the values of each attribute.
← More effective
S2 (Two)
A6 (75°)
A7 (120°)
A8 (135°)
D9 (lower right, 60°)
D11 (upper right, 60°)
T3 (Three)
Segment
Angle
Direction
Turn
Moderate
S1 (One)
A1 (90°)
A2 (60°)
A3 (45°)
Poorer →
A4 (30°)
A5 (15°)
Other Direction Values
T2 (Two)
T1 (One)
test, the Wilcoxon signed-rank test was performed as a post-hoc
analysis by selecting two patterns among all patterns used in the
Friedman test. Table 4 provides the statistical results including p-
values for the Friedman and Wilcoxon signed-rank tests. Based on
the general statistical results, we set a policy about values of each
attribute of a pattern as described in Table 3.
4 SUMMARY AND FUTURE DIRECTION
Our study is underway to realize the guided approach concept il-
lustrated in Figure 1. Our proposal is to guide a user, for example,
so as to select a pattern producing a good shape of gestures in the
hybrid gesture-based pattern lock system, without losing security.
Since we have found that there is a correlation between shape and
accuracy, and derived effective attribute values for patterns, it is
desirable to construct the gesture-based pattern lock system, which
guides a user interactively for a pattern selection. However, our
experiments are still limited in feature engineering, and in investi-