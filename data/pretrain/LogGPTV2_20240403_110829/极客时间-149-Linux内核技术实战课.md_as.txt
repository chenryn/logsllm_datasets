# 首先设置要追踪的函数    $ echo ksys_pread64 > /sys/kernel/debug/tracing/set_graph_function    
# 其次设置要追踪的线程的pid，如果有多个线程，那需要将每个线程都逐个写入    $ echo 6577 > /sys/kernel/debug/tracing/set_ftrace_pid    $ echo 6589 >> /sys/kernel/debug/tracing/set_ftrace_pid    
# 将function_graph设置为当前的tracer，来追踪函数调用情况    $ echo function_graph > /sys/kernel/debug/tracing/current_trace然后我们就可以通过 /sys/kernel/debug/tracing/trace_pipe来查看它的输出了，下面就是我追踪到的耗时情况：![](Images/1b93a8d9258dee77777e5001e5efe8ce.png)savepage-src="https://static001.geekbang.org/resource/image/68/fc/689eacfa3ef10c236221f1b2051ab5fc.png"}我们可以发现 pread(2) 有 102ms 是阻塞在 io_schedule()这个函数里的，io_schedule() 的意思是，该线程因 I/O阻塞而被调度走，线程需要等待 I/O 完成才能继续执行。在 function_graph里，我们同样也能看到 **pread**\*\*(**2**)\*\* 是如何一步步执行到 io_schedule的，由于整个流程比较长，我在这里只把关键的调用逻辑贴出来：     21)               |            __lock_page_killable() {     21)   0.073 us    |              page_waitqueue();     21)               |              __wait_on_bit_lock() {     21)               |                prepare_to_wait_exclusive() {     21)   0.186 us    |                  _raw_spin_lock_irqsave();     21)   0.051 us    |                  _raw_spin_unlock_irqrestore();     21)   1.339 us    |                }     21)               |                bit_wait_io() {     21)               |                  io_schedule() {我们可以看到，**pread（2）**是从 \_\_lock_page_killable 这个函数调用下来的。当pread(2) 从磁盘中读文件到内存页（page）时，会先 lock 该 page，读完后再unlock。如果该 page 已经被别的线程 lock 了，比如在 I/O 过程中被lock，那么 pread(2) 就需要等待。等该 page 被 I/O 线程 unlock后，pread(2) 才能继续把文件内容读到这个 page中。我们当时遇到的情况是：在 pread(2) 从磁盘中读取文件内容到一个 page中的时候，该 page 已经被 lock 了，于是调用 pread(2)的线程就在这里等待。这其实是合理的内核逻辑，没有什么问题。接下来，我们就需要看看为什么该page 会被 lock 了这么久。因为线程是阻塞在磁盘 I/O 里的，所以我们需要查看一下系统的磁盘 I/O情况，我们可以使用 iostat来观察： >  > \$ iostat -dxm 1> > >追踪信息如下：![](Images/02fd6f729f799d80adca81cc809b97a2.png)savepage-src="https://static001.geekbang.org/resource/image/ca/04/ca94121ff716f75c171e2a3380d14d04.png"}其中，sdb 是业务 pread(2)读取的磁盘所在的文件，通常情况下它的读写量很小，但是我们从上图中可以看到，磁盘利用率（%util）会随机出现比较高的情况，接近100%。而且 avgrq-sz 很大，也就是说出现了很多 I/O 排队的情况。另外，w/s比平时也要高很多。我们还可以看到，由于此时存在大量的 I/O 写操作，磁盘I/O 排队严重，磁盘 I/O 利用率也很高。根据这些信息我们可以判断，之所以pread(2)读磁盘文件耗时较长，很可能是因为被写操作饿死导致的。因此，我们接下来需要排查到底是谁在进行写I/O 操作。 通过 iotop 观察 I/O 行为，我们发现并没有用户线程在进行 I/O写操作，写操作几乎都是内核线程 kworker来执行的，也就是说用户线程把内容写在了 Page Cache 里，然后 kwoker 将这些Page Cache中的内容再同步到磁盘中。这就涉及到了我们这门课程第一个模块的内容了：如何观测Page Cache 的行为。自己写分析工具如果你现在还不清楚该如何来观测 Page Cache的行为，那我建议你再从头仔细看一遍我们这门课程的第一个模块，我在这里就不细说了。不过，我要提一下在Page Cache模块中未曾提到的一些方法，这些方法用于判断内存中都有哪些文件以及这些文件的大小。常规方式是用 fincore 和mincore，不过它们都比较低效。这里有一个更加高效的方式：通过写一个内核模块遍历inode 来查看 Page Cache的组成。该模块的代码较多，我只说一下核心的思想，伪代码大致如下：    iterate_supers // 遍历super block      iterate_pagecache_sb // 遍历superblock里的inode          list_for_each_entry(inode, &sb->s_inodes, i_sb_list)            // 记录该inode的pagecache大小             nrpages = inode->i_mapping->nrpages;             /* 获取该inode对应的dentry，然后根据该dentry来查找文件路径；             * 请注意inode可能没有对应的dentry，因为dentry可能被回收掉了，             * 此时就无法查看该inode对应的文件名了。             */            dentry = dentry_from_inode(inode);             dentry_path_raw(dentry, filename, PATH_MAX);使用这种方式不仅可以查看进程正在打开的文件，也能查看文件已经被进程关闭，但文件内容还在内存中的情况。所以这种方式分析起来会更全面。通过查看 Page Cache的文件内容，我们发现某些特定的文件占用的内存特别大，但是这些文件都是一些离线业务的文件，也就是不重要业务的文件。因为离线业务占用了大量的Page Cache，导致该在线业务的 workingset 大大减小，所以 pread(2)在读文件内容时经常命中不了 PageCache，进而需要从磁盘来读文件，也就是说该在线业务存在大量的 pagein 和pageout。 至此，问题的解决方案也就有了：我们可以通过限制离线业务的 Page Cache大小，来保障在线业务的 workingset，防止它出现较多的refault。经过这样调整后，业务再也没有出现这种性能抖动了。你是不是对我上面提到的这些名字感到困惑呢？也不清楚 inode 和 PageCache 是什么关系？如果是的话，那就说明你没有好好学习我们这门课程的 PageCache模块，我建议你从头再仔细学习一遍。好了，我们这节课就讲到这里。课堂总结我们这节课的内容，对于应用开发者和运维人员而言是有些难度的。我之所以讲这些有难度的内容，就是希望你可以拓展分析问题的边界。这节课的内容对内核开发者而言基本都是基础知识，如果你看不太明白，说明你对内核的理解还不够，你需要花更多的时间好好学习它。我研究内核已经有很多年了，尽管如此，我还是觉得自己对它的理解仍然不够深刻，需要持续不断地学习和研究，而我也一直在这么做。我们现在回顾一下这节课的重点：1.  strace    工具是应用和内核的边界，如果你是一名应用开发者，并且想去拓展分析问题的边界，那你就需要去了解    strace 的原理，还需要了解如何去分析 strace    发现的问题；        2.  ftrace    是分析内核问题的利器，你需要去了解它；        3.  你需要根据自己的问题来实现特定的问题分析工具，要想更好地实现这些分析工具，你必须掌握很多内核细节。        课后作业关于我们这节课的"自己写分析工具"这部分，我给你留一个作业，这也是我没有精力和时间去做的一件事：请你在sysrq 里实现一个功能，让它可以显示出系统中所有 R 和 D状态的任务，以此来帮助开发者分析系统 load飙高的问题。我在我们的内核里已经实现了该功能，不过在推给 Linux 内核时，maintainer希望我可以用另一种方式来实现。由于那个时候我在忙其他事情，这件事便被搁置了下来。如果你实现得比较好，你可以把它提交给Linux 内核，提交的时候你也可以 cc一下我（PI:EMAIL）。对了，你在实现时，也可以参考我之前的提交记录：scheduler: enhancement to show_state_filter andSysRq  slate-object="inline"。欢迎你在留言区与我讨论。最后，感谢你的阅读，如果你认为这节课的内容有收获，也欢迎把它分享给你的朋友。