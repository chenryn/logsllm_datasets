### 函数追踪与性能分析

#### 1. 设置要追踪的函数
首先，设置需要追踪的函数。例如，追踪 `ksys_pread64` 函数：
```sh
echo ksys_pread64 > /sys/kernel/debug/tracing/set_graph_function
```

#### 2. 设置要追踪的线程 PID
其次，设置要追踪的线程 PID。如果有多个线程，需要逐个写入：
```sh
echo 6577 > /sys/kernel/debug/tracing/set_ftrace_pid
echo 6589 >> /sys/kernel/debug/tracing/set_ftrace_pid
```

#### 3. 设置 function_graph 为当前 tracer
将 `function_graph` 设置为当前的 tracer，以追踪函数调用情况：
```sh
echo function_graph > /sys/kernel/debug/tracing/current_tracer
```

然后，可以通过 `/sys/kernel/debug/tracing/trace_pipe` 查看输出。以下是我们追踪到的耗时情况：

![](https://static001.geekbang.org/resource/image/68/fc/689eacfa3ef10c236221f1b2051ab5fc.png)

从上图可以看出，`pread(2)` 在 `io_schedule()` 函数中阻塞了 102ms。`io_schedule()` 的作用是当线程因 I/O 操作被阻塞时，将其调度走，直到 I/O 操作完成才能继续执行。

在 `function_graph` 中，我们可以看到 `pread(2)` 如何一步步执行到 `io_schedule()`。以下是关键的调用逻辑：
```plaintext
21)               |            __lock_page_killable() {
21)   0.073 us    |              page_waitqueue();
21)               |              __wait_on_bit_lock() {
21)               |                prepare_to_wait_exclusive() {
21)   0.186 us    |                  _raw_spin_lock_irqsave();
21)   0.051 us    |                  _raw_spin_unlock_irqrestore();
21)   1.339 us    |                }
21)               |                bit_wait_io() {
21)               |                  io_schedule() {
```

#### 4. 分析 `pread(2)` 调用路径
`pread(2)` 从 `__lock_page_killable` 函数调用下来。当 `pread(2)` 从磁盘读取文件内容到内存页（page）时，会先锁定该页，读完后再解锁。如果该页已经被其他线程锁定（如在 I/O 过程中），`pread(2)` 就需要等待。等该页被解锁后，`pread(2)` 才能继续读取文件内容到该页中。

我们遇到的情况是：`pread(2)` 从磁盘读取文件内容到一个已被锁定的页时，线程在这里等待。这是合理的内核逻辑，没有问题。接下来，我们需要查看为什么该页会被锁定这么久。

#### 5. 检查磁盘 I/O 情况
使用 `iostat` 观察系统的磁盘 I/O 情况：
```sh
iostat -dxm 1
```

追踪信息如下：

![](https://static001.geekbang.org/resource/image/ca/04/ca94121ff716f75c171e2a3380d14d04.png)

从上图可以看到，磁盘 `sdb` 的利用率（%util）随机出现较高情况，接近 100%，且 `avgrq-sz` 很大，表明存在大量 I/O 排队。此外，`w/s` 也比平时高很多。这说明有大量的 I/O 写操作导致磁盘 I/O 排队严重，磁盘 I/O 利用率很高。

因此，`pread(2)` 读取磁盘文件耗时较长，可能是由于被写操作饿死导致的。我们需要排查是谁在进行写 I/O 操作。

#### 6. 使用 `iotop` 观察 I/O 行为
通过 `iotop` 观察 I/O 行为，发现写操作几乎都是由内核线程 `kworker` 执行的。这意味着用户线程将内容写入 Page Cache，然后 `kworker` 将这些内容同步到磁盘。

#### 7. 观测 Page Cache 行为
为了更全面地分析 Page Cache 的行为，可以编写一个内核模块遍历 inode 来查看 Page Cache 的组成。核心思想如下：
```c
iterate_supers // 遍历 super block
  iterate_pagecache_sb // 遍历 superblock 里的 inode
    list_for_each_entry(inode, &sb->s_inodes, i_sb_list)
      // 记录该 inode 的 pagecache 大小
      nrpages = inode->i_mapping->nrpages;
      // 获取该 inode 对应的 dentry，然后根据 dentry 查找文件路径
      dentry = dentry_from_inode(inode);
      dentry_path_raw(dentry, filename, PATH_MAX);
```

通过这种方式，不仅可以查看进程正在打开的文件，还能查看文件已被关闭但内容仍在内存中的情况。

#### 8. 发现问题并调整
通过查看 Page Cache 的文件内容，发现某些特定的离线业务文件占用了大量内存。这导致在线业务的工作集大大减小，`pread(2)` 读取文件内容时经常无法命中 Page Cache，需要从磁盘读取文件，从而产生大量的 pagein 和 pageout。

解决方案是限制离线业务的 Page Cache 大小，保障在线业务的工作集，防止其出现较多的 refault。经过调整后，业务再也没有出现这种性能抖动。

#### 课堂总结
- **strace** 是应用和内核的边界工具，应用开发者需要了解其原理及如何分析问题。
- **ftrace** 是分析内核问题的利器，需要掌握其使用方法。
- 根据具体问题实现特定的分析工具，需要掌握许多内核细节。

#### 课后作业
请在 `sysrq` 中实现一个功能，显示系统中所有 R 和 D 状态的任务，帮助开发者分析系统负载飙高的问题。如果你实现得比较好，可以提交给 Linux 内核，并 cc 给我（PI:EMAIL）。参考之前的提交记录：scheduler: enhancement to show_state_filter and SysRq。

欢迎在留言区与我讨论。感谢你的阅读，如果你认为这节课的内容有收获，也欢迎把它分享给你的朋友。