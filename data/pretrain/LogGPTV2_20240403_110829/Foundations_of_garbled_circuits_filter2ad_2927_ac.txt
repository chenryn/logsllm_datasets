(φ) = m(f )
when φ = Φ(f ). We also require that |f| be easily deter-
mined from Φ(f ).
(φ) = n(f ) and f.m = m(cid:3)
Speciﬁc side-information functions are useful for circuit
garbling. Side-information function Φsize reveals the num-
ber of inputs, outputs, and gates of a circuit f ; formally,
Φsize(f ) = (n, m, q) for a circuit f = (n, m, q, A, B, G). Side-
information function Φtopo reveals the topological circuit but
not the functionality of each gate: Φtopo(f ) = (n, m, q, A, B),
with notation and conventions as above. Side-information
function Φcirc reveals the entire circuit: Φcirc(f ) = f .
Privacy. Let G = (Gb, En, De, Ev, ev) be a garbling scheme,
k ∈ N a security parameter, and Φ a side-information func-
tion. We deﬁne an indistinguishability-based notion of pri-
vacy via game PrvIndG,Φ (top-left of Fig. 4) and a simulation-
based notion of privacy via game PrvSimG,Φ,S (top-right of
Fig. 4, where S is a simulator). Executing either game with
an adversary requires one to specify the garbling scheme, ad-
versary, security parameter, and side-information function.
Executing game PrvSim additionally requires one to specify
the algorithm S.
Refer ﬁrst to game PrvIndG,Φ. Adversary A gets input 1k
and must make exactly one Garble query. That query is an-
swered as speciﬁed in the game, the security parameter used
here being the same as the one provided to the adversary.
The adversary must eventually halt, outputting a bit b
, and
the game’s Finalize procedure determines if the adversary
has won on this run, namely, if b = b
. The corresponding
(cid:3)
(cid:3)
advantage is deﬁned via
Adv
prv.ind, Φ
G
(A, k) = 2 Pr[PrvInd
G,Φ(k)] − 1,
A
the probability, normalized to [0, 1], that the adversary cor-
rectly predicts b. Protocol G is prv.ind secure over Φ if for
every PT adversary A the function Adv
(A,·) is neg-
ligible.
prv.ind, Φ
G
Explaining the deﬁnition, the adversary chooses (f0, x0)
and (f1, x1) such that Φ(f0) = Φ(f1) and, also, ev(f0, x0) =
ev(f1, x1). The game picks challenge bit b and garbles fb to
(F, e, d). It encodes xb as the garbled input X = Ene(xb).
The adversary is handed (F, X, d), which determines y =
De(d, Ev(F, En(e, xb))) = ev(fb, xb). The adversary must
guess b. In a scheme we deem secure, it should be unable to
ascertain which of (f0, x0), (f1, x1) got garbled.
Next we deﬁne prv.sim security via game PrvSimG,Φ,S as-
sociated to garbling scheme G, information function Φ and
an algorithm S called a simulator. The adversary B is run
on input 1k and must make exactly one Garble query. The
query is answered as speciﬁed in Fig. 4, with k being the
same as the input to the adversary. The adversary must
eventually output a bit, and the game’s Finalize procedure
indicates if the adversary has won—again, if the adversary
correctly predicted b. The adversary’s advantage is
prv.sim, Φ,S
G
(B, k) = 2 Pr[PrvSim
G,Φ,S (k)] − 1 ,
B
Adv
prv.sim, Φ,S
G
the probability, normalized to [0, 1], that the adversary wins.
Protocol G is prv.sim secure over Φ if for every PT adversary
B there is a PT algorithm S such that Adv
(B, k)
is negligible.
Let us again explain. For the prv.sim notion we let the
adversary choose (f, x). Either we garble it to (F, e, d) ←
Gb(1k, f ) and X ← En(e, x), handing the adversary (F, X, d),
or else we ask the simulator to devise a “fake” (F, X, d) based
solely on k, φ = Φ(f ), and y = ev(f, x). From this limited
information the simulator must produce an (F, X, d) indis-
tinguishable, to the adversary, from the ones produced using
the actual garbling scheme.
The indistinguishability deﬁnition for garbling schemes is
simpler due to the absence of the simulator, but we con-
sider this notion “wrong” when the side-information func-
tion is such that indistinguishability is inequivalent to the
simulation-based deﬁnition. See Section 4.
Obliviousness.
Informally, a garbling scheme achieves
obliviousness if possession of a garbled function F and gar-
bled input X lets one compute the garbled output Y , yet
(F, X) leaks nothing about f or x beyond Φ(f ). Contrast-
ing this with privacy, there the agent evaluating the garbled
function does learn the output; here, she learns not even
that, as a needed piece of information, d, is withheld. Pri-
vacy and obliviousness are both secrecy notions, and cut
from the same cloth. Yet they will prove incomparable: a
private scheme could divulge the output even without d; an
oblivious scheme could reveal too much once d is shown.
As with privacy, we formalize two notions, obv.ind and
obv.sim, via the games of Fig. 4. The formalizations consider
games ObvIndG,Φ and ObvSimG,Φ,S , run with adversaries
A and B, respectively. As usual the adversary gets input
1k and the security parameter used in the game is also k.
The adversary makes a single call to the game’s Garble
procedure and outputs a bit b
(cid:3)
Adv
obv.ind, Φ
G
obv.sim, Φ, S
G
Adv
. We deﬁne
(A, k) = 2 Pr[ObvInd
G,Φ(k))] − 1
A
(B, k) = 2 Pr[ObvSim
G,Φ,S (k)] − 1
B
and
788Game PrvIndG,Φ
proc Garble(f0, f1, x0, x1)
if Φ(f0) (cid:6)= Φ(f1) then return ⊥
if {x0, x1} (cid:6)⊆ {0, 1}f0.n then return ⊥
if ev(f0, x0) (cid:6)= ev(f1, x1) then return ⊥
b (cid:2){0, 1}; (F, e, d) ← Gb(1k, fb); X ← En(e, xb)
return (F, X, d)
proc Garble(f0, f1, x0, x1)
if Φ(f0) (cid:6)= Φ(f1) then return ⊥
if {x0, x1} (cid:6)⊆ {0, 1}f0.n then return ⊥
b (cid:2){0, 1};
return (F, X)
(F, e, d) ← Gb(1k, fb); X ← En(e, xb)
Game ObvIndG,Φ
proc Garble(f, x)
b (cid:2){0, 1}
if x (cid:6)∈ {0, 1}f.n then return ⊥
if b = 1 then (F, e, d) ← Gb(1k, f ); X ← En(e, x)
Game PrvSimG,Φ,S
else y ← ev(f, x); (F, X, d) ← S(1k, y,Φ( f ))
return (F, X, d)
proc Garble(f, x)
b (cid:2){0, 1}
if x (cid:6)∈ {0, 1}f.n then return ⊥
if b = 1 then (F, e, d) ← Gb(1k, f ); X ← En(e, x)
Game ObvSimG,Φ,S
else (F, X) ← S(1k, Φ(f ))
proc Garble(f, x)
(F, e, d) ← Gb(1k, f ); X ← En(e, x)
return (F, X)
return (F, X)
proc Finalize(Y )
return (De(d, Y ) (cid:6)= ⊥ and Y (cid:6)= Ev(F, X))
Game AutG
Figure 4: Games for deﬁning the prv.ind, prv.sim, obv.ind, obv.sim, and aut security of a garbling scheme
G = (Gb, En, De, Ev, ev). Here S is a simulator, Φ is an information function and k is the security parameter input
to the adversary. Procedure Finalize(b
) of the ﬁrst four games returns (b = b
).
(cid:3)
(cid:3)
as the probability, normalized to [0, 1], that adversary’s out-
put is a correct guess of the underlying bit b. Protocol G
is obv.ind secure over Φ if for every PT adversary A, we
(A, k) is negligible. It is obv.sim se-
have that Adv
cure over Φ if for every PT adversary B there exists a PT
simulator S such that Adv
(B,·) is negligible.
obv.sim, Φ, S
G
obv.ind, Φ
G
Let us explain the diﬀerence between prv.ind and obv.ind.
First, we no longer demand that ev(f, x0) = ev(f, x1): the
adversary may now name any (f0, x0) and (f1, x1) as long
as the functions have the same side information. Second,
the decoding function d is no longer provided to the adver-
sary. The adversary must guess if (F, X) stems from garbling
(f0, x0) or (f1, x1).
Similarly, the diﬀerence between prv.sim and obv.sim is
two-fold. First, in the obliviousness notion the simulator
is denied y = ev(f, x); it must create a convincing (F, X)
without that. Second, the simulator no longer returns to the
adversary the (simulated) decoding function d; the return
value is (F, X) and not (F, X, d).
Authenticity.
So far we have dealt exclusively with se-
crecy notions. One can formalize an authenticity property
as well [17], which we do via game AutG of Fig. 4. Au-
thenticity captures an adversary’s inability to create from a
garbled function F and its garbled input X a garbled out-
put Y (cid:6)= F (X) that will be deemed authentic.
Fix a garbling scheme G = (Gb, En, De, Ev, ev), adversary
A, and security parameter k ∈ N. Run adversary A on
input 1k, allowing it a single call to the Garble procedure
of the game. The adversary outputs a string Y , and, when
it does, the game’s Finalize procedure is called to decide
if the adversary has won. The adversary’s aut-advantage is
deﬁned as AdvautG (A, k) = Pr[Aut
G (k)]. Protocol G is aut-
A
secure if for all PT adversaries A, AdvautG (A,·) is negligible.
Sets of garbling schemes. To compactly and precisely
express relations between notions we will write them as con-
tainments and non-containments between sets of garbling
schemes. To this end, for xxx ∈ {prv.ind, prv.sim, obv.ind,
obv.sim} we let GS(xxx, Φ) be the set of all garbling schemes
that are xxx-secure over Φ. Similarly, we let GS(aut) be the
set of all garbling schemes that are aut-secure.
We also let GS(ev) be the set of all garbling schemes G =
(Gb, En, De, Ev, ev) whose evaluation function is ev. This
captures garbling schemes for a particular class of functions.
As per our previous notation, GS(evcirc) now denotes the set
of all circuit-garbling schemes.
4. RELATIONS
We show that prv.sim always implies prv.ind, and prv.ind
implies prv.sim under certain added conditions on the side-
information function. We show that the same holds for
obv.ind and obv.sim, under a weaker assumption on the side-
information function. The conditions on the side-information
function are relatively mild. We will also justify the non-
implications for the security notions compactly summarized
in Fig. 2. As part of this we will show that prv.ind does not
always imply prv.sim and obv.ind does not always imply
obv.sim.
Invertibility of side-information functions.
Let Φ
be a side-information function. An algorithm M is called
a Φ-inverter if on input φ in the range of Φ it returns a
preimage under Φ of that point, meaning a string f such
that Φ(f ) = φ. Such an inverter always exists, but it might
not be eﬃcient. We say that Φ is eﬃciently invertible if there
is a polynomial-time Φ-inverter. Similarly, an algorithm M
(cid:3)
is called a (Φ, ev)-inverter if on input (φ, y), where φ = Φ(f
)
and y = ev(f
.n, returns an
(f, x) satisfying Φ(f ) = φ and ev(f, x) = y. We say that
(Φ, ev) is eﬃciently invertible if there is a polynomial-time
(Φ, ev)-inverter.
and x ∈ {0, 1}f
) for some f
, x
(cid:3)
(cid:3)
(cid:3)
(cid:2)
The following theorem summarizes the invertibility at-
tributes of the circuit-related size-information functions we
deﬁned earlier. It shows that all side-information functions
Φcirc, Φtopo, and Φsize are eﬃciently invertible, and that,
(Φsize, evcirc) and (Φtopo, evcirc) are eﬃciently invertible.
789Proposition 1. For Φ ∈ {Φsize, Φtopo, Φcirc}, there is a
linear-time inverter. For Φ ∈ {Φsize, Φtopo} there is a linear-
time (Φ, evcirc)-inverter.
In contrast, there is no eﬃcient (Φcirc, evcirc)-inverter (under
a computational assumption); consider the case where f is
drawn from a family implementing a one-way function.
Equivalence of prv.ind and prv.sim.
The following
says that prv.sim implies prv.ind security, and conversely
if (Φ, ev) is eﬃciently invertible. The proof is in the full
paper [11].
Proposition 2. For any PT Φ:
(1) GS(prv.sim, Φ) ⊆
GS(prv.ind, Φ) and (2) If (Φ, ev) is eﬃciently invertible then
GS(prv.ind, Φ) ∩ GS(ev) ⊆ GS(prv.sim, Φ) ∩ GS(ev).
The ﬁrst part says that if garbling scheme G is prv.sim se-
cure over Φ then G is prv.ind secure over Φ. The second
part says that if garbling scheme G = (Gb, En, De, Ev, ev)
is prv.ind secure over Φ and (Φ, ev) is eﬃciently invertible
then G is prv.sim secure over Φ. In the full version [11], we
show that eﬃcient invertibility of (Φ, ev) is required to prove
that prv.ind implies prv.sim, so the notions are not always
equivalent.
A corollary of Propositions 1 and 2 is that prv.sim and
prv.ind are equivalent for circuit-garbling schemes over Φtopo
and Φsize, which we summarize as:
Corollary 1. For Φ ∈ {Φtopo, Φsize}, GS(prv.ind, Φ) ∩
GS(evcirc) = GS(prv.sim, Φ) ∩ GS(evcirc).
Equivalence of obv.ind and obv.sim.
The following
says that obv.sim implies obv.ind security, and conversely
if Φ is eﬃciently invertible. The invertibility condition is
thus weaker than in the privacy case.
Proposition 3. For any PT Φ: (1) GS(obv.sim, Φ) ⊆
GS(obv.ind, Φ) and (2) If Φ) is eﬃciently invertible then
GS(obv.ind, Φ) ⊆ GS(obv.sim, Φ).
In the full version of this paper [11], we show that Φ being
eﬃciently invertible is required to prove that obv.ind implies
obv.sim. But the side-information function Φ we use is arti-
ﬁcial; for any “reasonable” one we know, obv.ind and obv.sim
will be equivalent.
Again a corollary of Propositions 1 and 3 is that obv.sim
and obv.ind are equivalent for circuit-garbling schemes over
side-information functions Φcirc, Φtopo and Φsize:
Corollary 2. GS(obv.ind, Φ) = GS(obv.sim, Φ), for any
Φ ∈ {Φtopo, Φsize, Φcirc}.
5. ACHIEVING PRIVACY
We provide a simple, privacy-achieving circuit-garbling
scheme, Garble1. It is described in terms of a new primitive,
a dual-key cipher (DKC). We will prove security of Garble1
assuming the security of its DKC. We will then show how
to instantiate a DKC using a PRF. Instantiating this PRF
via AES leads to an eﬃcient garbling scheme. Diﬀerently in-
stantiating the DKC directly with AES can give even better
eﬃciency.
Dual key ciphers. Before describing Garble1 we will need
to specify the syntax of a DKC. These objects formalize a
two-key lockbox—one where you need both keys to open the
box. This has long been used as a metaphor to explain how
garbling schemes work (e.g., [35] (pp. 163–164)), but Lindell
and Pinkas also give a notion of double-encryption security