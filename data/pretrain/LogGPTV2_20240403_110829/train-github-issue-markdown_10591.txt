# Checklist
  * I have verified that the issue exists against the `master` branch of Celery.
  * This has already been asked to the discussions forum first.
  * I have read the relevant section in the  
contribution guide  
on reporting bugs.
  * I have checked the issues list  
for similar or identical bug reports.
  * I have checked the pull requests list  
for existing proposed fixes.
  * I have checked the commit log  
to find out if the bug was already fixed in the master branch.
  * I have included all related issues and possible duplicate issues  
in this issue (If there are none, check this box anyway).
## Mandatory Debugging Information
  * I have included the output of `celery -A proj report` in the issue.  
(if you are not able to do this, then at least specify the Celery  
version affected).
  * I have verified that the issue exists against the `master` branch of Celery.
  * I have included the contents of `pip freeze` in the issue.
  * I have included all the versions of all the external dependencies required  
to reproduce this bug.
## Optional Debugging Information
  * I have tried reproducing the issue on more than one Python version  
and/or implementation.
  * I have tried reproducing the issue on more than one message broker and/or  
result backend.
  * I have tried reproducing the issue on more than one version of the message  
broker and/or result backend.
  * I have tried reproducing the issue on more than one operating system.
  * I have tried reproducing the issue on more than one workers pool.
  * I have tried reproducing the issue with autoscaling, retries,  
ETA/Countdown & rate limits disabled.
  * I have tried reproducing the issue after downgrading  
and/or upgrading Celery and its dependencies.
## Related Issues and Possible Duplicates
#### Related Issues
  * None
#### Possible Duplicates
  * None
## Environment & Settings
**Celery version** :
**`celery report` Output:**
    #celery report
    software -> celery:3.1.26.post2 (Cipater) kombu:3.0.37 py:3.6.4
                billiard:3.3.0.23 py-amqp:1.4.9
    platform -> system:Linux arch:64bit, ELF imp:CPython
    loader   -> celery.loaders.default.Loader
    settings -> transport:amqp results:disabled
# Steps to Reproduce
## Required Dependencies
  * **Minimal Python Version** : 3.6.4
  * **Minimal Celery Version** : 3.1.26.post2
  * **Minimal Kombu Version** : 3.0.37
  * **Minimal Broker Version** : redis5
  * **Minimal Result Backend Version** :
  * **Minimal OS and/or Kernel Version** : centos7
  * **Minimal Broker Client Version** : N/A or Unknown
  * **Minimal Result Backend Client Version** : N/A or Unknown
### version info
celery 3.1.26.post2  
celery-once 3.0.1  
django-celery 3.3.0
### Python Packages
Output: ```shelll #python3 -m pip list Package Version
\---------------------------------- ------------ aenum 2.2.3 amqp 1.4.9
anyjson 0.3.3 APScheduler 3.5.3 asn1crypto 0.24.0 Babel 2.7.0 backcall 0.2.0
backports.lzma 0.0.14 bcrypt 3.1.7 billiard 3.3.0.23 bitarray 1.5.3 cassandra-
driver 3.19.0 celery 3.1.26.post2 celery-once 3.0.1 certifi 2021.5.30 cffi
1.14.6 chardet 3.0.4 charset-normalizer 2.0.3 clickhouse-driver 0.2.1 coreapi
2.3.3 coreschema 0.0.4 crcmod 1.7 cryptography 3.4.7 cycler 0.10.0 dateparser
1.0.0 decorator 5.0.9 Django 2.0.1 django-cas-ng 3.6.0 django-celery 3.3.0
django-cors-headers 2.1.0 django-extensions 3.1.0 django-redis 4.10.0 django-
werkzeug-debugger-runserver 0.3.1 djangorestframework 3.7.7
djangorestframework-jwt 1.11.0 docopt 0.6.2 drf-yasg 1.16.0 elasticsearch
7.13.4 enum34 1.1.6 et-xmlfile 1.1.0 flower 0.9.3 future 0.17.1 gevent 1.3.4
greenlet 1.1.0 gremlinpython 3.4.4 gunicorn 19.8.1 happybase 1.2.0 idna 3.2
importlib-metadata 4.6.1 impyla 0.16.2 inflection 0.5.1 ipython 7.16.1
ipython-genutils 0.2.0 isodate 0.6.0 itypes 1.2.0 jdcal 1.4 jedi 0.17.2 Jinja2
3.0.1 jmespath 0.10.0 joblib 0.16.0 kiwisolver 1.2.0 kombu 3.0.37 ldap3 2.4.1
lxml 4.2.5 MarkupSafe 2.0.1 matplotlib 3.2.1 mybatis-mapper2sql 0.1.8 Naked
0.1.31 numpy 1.19.5 odps 3.5.1 openpyxl 3.0.7 oss2 2.5.0 pandas 1.1.5 paramiko
2.7.2 parso 0.7.1 pexpect 4.8.0 phoenixdb 0.7 pickleshare 0.7.5 Pillow 7.2.0
pip 20.2.3 ply 3.11 prettytable 0.7.2 prompt-toolkit 3.0.19 protobuf 3.17.3
psutil 5.8.0 ptyprocess 0.7.0 pyasn1 0.4.8 pycparser 2.20 pycryptodome 3.10.4
Pygments 2.9.0 PyJWT 1.6.4 pymongo 3.7.2 PyMySQL 0.9.2 PyNaCl 1.4.0 pyodps
0.10.7 pyOpenSSL 19.1.0 pyparsing 2.4.7 pypinyin 0.42.0 python-cas 1.4.0
python-dateutil 2.8.2 python-docx 0.8.6 pytz 2021.1 PyYAML 5.4.1 redis 2.10.6
regex 2021.7.6 requests 2.26.0 ruamel.yaml 0.17.21 ruamel.yaml.clib 0.2.6
scikit-learn 0.23.1 scipy 1.5.1 setuptools 28.8.0 shellescape 3.8.1 simplejson
3.15.0 six 1.16.0 sklearn 0.0 SQLAlchemy 1.4.20 sqlparse 0.2.4 sshtunnel 0.4.0
tablestore 5.1.0 threadpoolctl 2.1.0 thrift 0.13.0 thriftpy2 0.4.5 tornado
4.5.3 traitlets 4.3.3 typing-extensions 3.10.0.0 tzlocal 2.1 uritemplate 4.1.1
urllib3 1.26.6 wcwidth 0.2.5 Werkzeug 1.0.1 xlrd 2.0.1 XlsxWriter 1.2.7 xlwt
1.3.0 xpinyin 0.7.6 zipp 3.5.0 ```
### Other Dependencies
Redis5.0
## Minimally Reproducible Test Case
### my celery task like below ```python from celery import task
def execuet_job():  
result = execute_celery.apply_async(params)
@task(base=QueueOnce, once={'graceful': True})  
def execute_celery(params):  
do_some_job()
    start celery with the following command
    ```shell
    celery multi start proj -A settings worker -l info --statedb=/data/celery/working1.state  --logfile=/data/celery/worker.log --pidfile=/data/celery/worker1.pid -n worker1.%h -Q worker1_queue
### my celery config ```python import os from celery import Celery
app = Celery('src')
app.config_from_object('django.conf:settings')
app.conf.ONCE = {  
'backend': 'celery_once.backends.Redis',  
'settings': {  
'url': 'redis://:%s@%s:%s/3' % (  
redis_password, redis_address, redis_port),  
'default_timeout': 172800  
}  
}
    ### my django project settings like below
    ```python
    import os
    import datetime
    from libs import util
    import djcelery
    from kombu import Exchange, Queue
    import sys
    CACHES = {
        'default': {
            'BACKEND': 'django_redis.cache.RedisCache',
            'LOCATION': 'redis://' + redis_conf.redis_address + ':' + redis_conf.redis_port,
            "OPTIONS": {
                "CLIENT_CLASS": "django_redis.client.DefaultClient",
                "CONNECTION_POOL_KWARGS": {"max_connections": 100}, 
                "PASSWORD": redis_conf.redis_password,
            },
        },
    }
    REST_FRAMEWORK = {
        'DEFAULT_PERMISSION_CLASSES': (
            'rest_framework.permissions.IsAuthenticated',
        ),
        'DEFAULT_AUTHENTICATION_CLASSES': (
            'rest_framework_jwt.authentication.JSONWebTokenAuthentication',
        ),
    }
    JWT_AUTH = {
        'JWT_RESPONSE_PAYLOAD_HANDLER':
            'rest_framework_jwt.utils.jwt_response_payload_handler',
        'JWT_EXPIRATION_DELTA': datetime.timedelta(seconds=3000000),
    }
    djcelery.setup_loader()
    CELERYD_FORCE_EXECV = True
    CELERYD_CONCURRENCY = 4
    CELERY_ACKS_LATE = False
    CELERYD_MAX_TASKS_PER_CHILD = 200
    CELERYD_TASK_TIME_LIMIT = 172800
    BROKER_TRANSPORT_OPTIONS = {'visibility_timeout': 31536000}
    CELERY_DISABLE_RATE_LIMITS = True
    CELERY_IMPORTS = (
        'proj.tasks',
        'proj.archiver'
    )
    CELERY_TIMEZONE = 'Asia/Shanghai'
    BROKER_BACKEND = 'redis'
    BROKER_URL = 'redis://:%s@%s:%s/1' % (
        redis_conf.redis_password, redis_conf.redis_address, redis_conf.redis_port)
    CELERY_RESULT_BACKEND = 'redis://:%s@%s:%s/2' % (
        redis_conf.redis_password, redis_conf.redis_address, redis_conf.redis_port)
    CELERY_QUEUES = (
        Queue("default", Exchange("default"), routing_key="default"),
        Queue("worker1_queue", Exchange("worker1_queue"), routing_key="worker1_router"),
        Queue("worker2_queue", Exchange("worker2_queue"), routing_key="worker2_router"),
        Queue("worker3_queue", Exchange("worker3_queue"), routing_key="worker3_router"),
        Queue("worker4_queue", Exchange("worker4_queue"), routing_key="worker4_router"),
        Queue("worker5_queue", Exchange("worker5_queue"), routing_key="worker5_router")
    )
    CELERY_ROUTES = {
        'proj.tasks.mytask_execute_celery1': {"queue": "worker1_queue", "routing_key": "worker1_router"},
        'proj.tasks.mytask_execute_celery2': {"queue": "worker2_queue", "routing_key": "worker2_router"},
        'proj.tasks.mytask_execute_celery3': {"queue": "worker3_queue", "routing_key": "worker3_router"},
        'proj.tasks.mytask_execute_celery4': {"queue": "worker4_queue", "routing_key": "worker4_router"},
        'proj.tasks.work_execute_celery': {"queue": "worker5_queue", "routing_key": "worker5_router"},
        'proj.archiver.newwork_execute_celery': {"queue": "worker5_queue", "routing_key": "worker5_router"},
        'proj.tasks.binlog_analyse_celery': {"queue": "worker5_queue", "routing_key": "worker5_router"}
    }
# Expected Behavior
except work execute succes
# Actual Behavior
I submit task to celery,I saw the celery log,task was received
     Received task: tasks.execute_celery[b664cb23-5c80-46c7-9705-28295cd4431f]
however,the task was not execute,with celery state `RECEIVED`, what's the
problem with celery?