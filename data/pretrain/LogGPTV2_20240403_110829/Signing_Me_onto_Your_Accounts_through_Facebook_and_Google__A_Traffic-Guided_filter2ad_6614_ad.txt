   } & … & … & … (other 13 elements ) 
BRM2:src=!IdP   dst=http://!IdP/xd_proxy.php↓ 
Arguments: origin[BLOB] ↓ & transport[WORD] ↓ & 
           result[SEC] ↑ & … & … (other 4 elements )
BRM3:src=!IdP↓  dst=http://Bob/login.php  
Arguments: origin[BLOB] ↓ & transport[WORD] ↓ & 
           result[SEC] ↑ & … & … (other 3 elements ) 
to 
Figure 10: the Facebook+NYTimes trace in scenario (B) 
Flaw and exploit. Again, we had to verify whether the 
above  identified  opportunity  was  indeed  exploitable.  This 
time,  things  turned  out  to  be  more  complicated  than  they 
appeared to be. Specifically, we tested the exploit by setting 
all  arguments  of  BRM1 
those  on  a  normal 
Facebook+NYTimes  SSO  trace.  We  found  that  although 
Facebook indeed responded as if it was communicating with 
NYTimes (i.e., all the arguments, including result, were 
carried  in  BRM2),  the  browser  failed  to  deliver  these 
arguments to http://Bob.com/login.php in BRM3, 
and thus thwarted our exploit. This test clearly indicates that 
Facebook’s  web contents protect the secret token  result 
within the user’s browser.  
Our  manual  analysis  of  the  web  contents  reveals  that 
such protection comes from the same-origin policy enforced 
by the browser, which Facebook leverages to ensure that the 
browser  only  transfers  the  secret  token  from  Facebook’s 
domain  to  the  domains  of  authorized  parties  such  as 
NYTimes, but not Bob.com. The browser mechanisms that 
Facebook  utilizes  for  this  goal  include  “postMessage”, 
“Adobe  Flash”  and  “fragment”.  A  relying  website,  e.g., 
NYTimes.com  or  Bob.com,  is  allowed  to  choose  one  of 
them using  the  transport element in BRM1. Figure 11 
shows how the protection works when Adobe Flash is used.  
(3) Flash B to 
HTML DOM  
(4) HTTP 
request to 
NYTimes
http://NYTimes.com  
http://fbcdn.net  
(2) Flash A 
to flash B 
B  
A
(1) HTTP 
response from 
Facebook 
Figure 11: The complete view of a benign BRM3 
The browser takes four steps to transfer the secret (i.e., 
result element) from Facebook to NYTimes. The cross-
domain  communication  happens  during  Steps  (2)  and  (3) 
between  two  windows,  one  rendering  the  content  for 
NYTimes  and  the  other  for  fbcdn.net,  which  is  affiliated 
with Facebook. Each of them hosts a Flash object, denoted 
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:30 UTC from IEEE Xplore.  Restrictions apply. 
by  A  and  B  respectively.  Both  objects  are  supposed  to  be 
downloaded  from  fbcdn.net  during  the  SSO.  This  allows 
Flash A to pass the secret to Flash B because they are of the 
same origins (fbcdn.net). Flash B further sends the secret to 
the  HTML  DOM  of  its  hosting  page  only  if  the  page’s 
domain  is  indeed  NYTimes.  Our  exploit  mentioned  above 
was  defeated  by  this  defense  mechanism,  which  seems 
logically secure: Flash’s same-origin policy ensures that the 
secret  will  be  passed  only  when  Flash  B  is  loaded  from 
fbcdn.net,  which  implies  that  Flash  B  will  only  hand  over 
the secret to NYTimes, not to other domains.   
• 
Let’s  look  at  our  adversarial  scenario,  in  which  the 
domain of the hosting page is actually Bob.com, although it 
declares  to  be  NYTimes.com  in  BRM1.  To  bypass  the 
defense and obtain the secret token in Alice’s browser, Bob 
must find a way to either let Flash A pass the secret token to 
a Flash downloaded from Bob.com website or convince the 
trusted  Flash  B  (from  fbcdn.net)  to  send  the  token  even 
when Flash B’s hosting page is Bob.com, not NYTimes.com. 
In  other  words,  the  problem  of  attacking  this  SSO  can  be 
reduced to one of the following questions: 
• 
Is it possible to let Flash B (from fbcdn.net) deliver 
the secret to the web page from Bob.com? 
Is Flash A (from fbcdn.net) allowed to communicate 
with a Flash object from Bob.com? 
For the first question, we analyzed the ActionScript of 
Flash B from fbcdn.net and did not find any way to make it 
send  the  secret  to  a  non-NYTimes  page.  For  the  second 
question, we found that the answer is positive, because of a 
unique  cross-domain  mode  of  Adobe  Flash  called 
unpredictable  domain  communication  [23]:  by  naming  a 
Flash object from Bob.com with an underscore prefix, such 
as “_foo”, Flash A can communicate with it despite the fact 
that the Flash comes from a different domain. Note that this 
logic flaw was found thanks to the domain knowledge about 
how  Flash  communicates,  which  serves  as  the  last  link  on 
the chain of our exploit. We made an exploit demo [33] to 
show  how  this  exploit  works:  once  Alice  visits  Bob.com 
while she has signed onto Facebook, Bob.com uses its Flash 
to acquire the secret token from Flash A, which allows Bob 
to  log  into  NYTimes  as  Alice  and  also  impersonate 
NYTimes  to  access  Alice’s  Facebook  data,  such  as  her 
personal information (e.g., birthdate), status updates, etc.  
Our  communication  with  Facebook.  Because  the 
problem  was  on  Facebook’s  side,  all  RP  websites  were 
subject  to  the  same  exploit  that  worked  on  NYTimes.  We 
reported the finding to Facebook, and suggested a way to fix 
the  issue.  After  9  days,  Facebook  confirmed  our  finding 
through  email,  and  applied  our  suggested  fix  on  the  same 
day. Facebook acknowledged us on its public webpage for 
security researchers [12] (before Facebook implemented the 
“bug bounty”  monetary reward program). The finding  was 
also  reported  in  several  news  stories,  including  those  on 
Computer World, The Register, eWeek, etc [33]. 
4.3.  JanRain 
JanRain  is  a  prominent  provider  of  social  login  and 
social  sharing  solutions  for  commercial  businesses  and 
websites. It claimed to have over 350,000 websites using its 
web  SSO  services.  Its  customers  include  leading  websites 
such  as  sears.com,  nasdaq.com,  savings.com,  etc.  Its 
flagship  product,  Janrain  Engage,  wraps  individual  web 
SSO  services  from 
including  Google, 
Facebook, Twitter,  etc,  into  a  single  web  SSO  service.  By 
using  the  service,  its  customers  adopt  these  SSO  schemes 
altogether and thus avoid integrating them one by one. This 
service is interesting not only because of its popularity but 
also because of the unique role it plays in web SSO: it is a 
wrapper  IdP  service  that  relies  on  the  wrapped  IdPs  for 
authentication.  This  potentially  makes 
the  already 
complicated web SSO systems even more complex.  
leading  IdPs, 
Analysis result. Figure 12 shows the trace produced by 
the  BRM  analyzer  when  our  test  server  did  an  SSO  using 
Google  ID  through  JanRain.  Before  we  can  come  to  the 
details  of  this  analysis,  a  few  issues  need  to  be  explained. 
First,  in  our  adversarial  scenarios,  IdPs  are  the  parties  not 
under  Bob’s  control,  so  we  simply  treat  both  JanRain  and 
Google  as  a  single  IdP  party  for  the  convenience  of  the 
analysis.  Second,  to  integrate  JanRain’s  service,  an  RP 
needs  to  register  with  JanRain  a  unique  application  name 
(AppName)  for  the  RP’s  web  application,  e.g.,  “RP-App”. 
JanRain then creates a  subdomain RP-App.rpxnow.com for 
this  application  (rpxnow.com  is  a  domain  owned  by 
JanRain).  This  subdomain  will  be  used  by  the  RP  to 
communicate  with  JanRain  a  set  of  settings  for  the  SSO 
process.  JanRain  server  stores  these  settings  and  refers  to 
them through a handle, denoted as settingsHandle2 in 
our  analysis.  Also  note  that  in  this  analysis,  we  treat 
AppName as an argument, although it is a subdomain. For 
example,  http://AppName.rpxnow.com/a.php?foo&bar 
is 
shown as: 
    src=xxx  dst=http://IdP/a.php  
  Arguments: AppName & foo & bar 
Figure  12  describes  7  BRMs  during  this  complicated 
SSO (login using Google ID through JanRain). When a user 
wants to sign onto an RP, the RP generates BRM1 to inform 
the IdP (i.e., JanRain) about its AppName, together with the 
settings for this SSO. Such settings include: openid_url, 
a  URL  for  activating  the  Google  ID  authentication,  and 
xdReceiver  and  token_url,  which  are  the  dst 
elements for BRM5 and BRM7 respectively. In the figure, 
BRM2  –  BRM4  (enclosed  in  the  dashed  bracket)  describe 
the traffic of Google ID authentication, as shown previously 
in Figure 8. By the end of BRM4, JanRain gets the user’s 
Google profile data. BRM5 – BRM7 pass a secret token to 
the RP for retrieving the profile data from JanRain. 
the  actual 
2  In 
is  called 
implementations, 
“discovery_token”  in  JanRain’s  wrapping  of  Yahoo  and  Google, 
and “_accelerator_session_id” in its wrapping of Facebook. 
this  handle 
372
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:30 UTC from IEEE Xplore.  Restrictions apply. 
BRM1: src=RP dst=http://!IdP/openid/start  
Arguments: AppName &  
  openid_url{http://IdP/account/o8/ud} &  
  xdReceiver{http://IdP/xdcomm?AppName}& 
  token_url{http://RP/finish-login} & 
  … & …  (other 2 elements ) 
BRM2:src=!IdP dst= http://IdP/account/o8/ud
Arguments: all Google ID’s arguments as shown in BRM1 
in Figure 8, in which openid.return_to is set to http: 
//IdP/openid/finish?AppName&settingsHandle
BRM3: Google ID’s traffic, similar to BRM2 in Figure 8. 
BRM4:src=!IdP dst=http://!IdP/openid/finish
Arguments: AppName & settingsHandle[SEC] & 
AllOpenIDData (a pseudo element that we introduce for 
the sake of presentation simplicity. It represents all data 
returned from Google ID as in BRM3 in Figure 8)
BRM5: src=!IdP   dst=http://IdP/xdcomm 
Arguments: AppName &  redirectUrl {   
   http://IdP/redirect?AppName&loc[SEC]}
BRM6: src=IdP   dst=http://!IdP/redirect 
Arguments: AppName & loc[SEC] 
BRM7: src=!IdP dst= http://RP/finish-login 
Arguments: token[SEC] 
Figure 12: benign traffic of our website integrating JanRain that 
wraps Google ID 
We  further  analyzed  the  BRMs  under  the  three 
adversarial  scenarios.  Figure  13  shows  the  result  for 
Scenario (B), where Bob impersonates the RP to the IdP.  
BRM1: src=Bob dst=http://!IdP/openid/start  
Arguments: AppName↓ & openid_url↓ &  
           xdReceiver ↓  & token_url ↓ & … & … 
BRM2 – BRM4: (details omitted, see Figure 12)
BRM5: src=!IdP   dst=http://IdP/xdcomm↓ 
Arguments: AppName↓ &  redirectUrl {   
   http://IdP/redirect?AppName&loc[SEC]↑}
BRM6: src=IdP   dst=http://!IdP/redirect 
Arguments: AppName↓ & loc[SEC]↑ 
BRM7:src=!IdP  dst=http://Bob/finish-login↓ 
Arguments: token[SEC]↑ 
Figure 13: adversarial scenario (B) 
An opportunity that we can easily identify is BRM1, in 
which  Bob  could  set  AppName↓  to  that  of  the  target  RP 
while  pointing  token_url↓  to  his  own  domain.  This 
would  trick  JanRain  into  collecting  the  user’s  profile  data 
from  Google 
the  secret 
token[SEC]↑ to Bob, as token_url serves as the dst 
element for BRM7. 
the  RP  and  sending 
for 
Flaw  and  exploit.  To  understand  whether 
this 
opportunity  indeed  works,  we  set  up  a  server  as  a  mock 
target RP of the attack. The test revealed that like Facebook, 
JanRain  also  puts  in  place  some  protection  measures. 
JanRain requires every registered app to supply a  whitelist 
for identifying the app’s associated domains. For example, 
the  whitelist  for  RP-App  includes  “RP-App.rpxnow.com” 
and “*.RP.com”. The token_url of BRM1 needs to be on 
the  whitelist.  In  our  test,  the  arguments  of  BRM1  were 
AppName=“RP-App”  &  token_url=“http:// 
Bob.com/finish-login”, which JanRain found to be 
inconsistent with the whitelist (Bob.com not on the whitelist 
of  RP-App)  and  thus  stopped  the  SSO.  Furthermore,  we 
found  that  even  if  we  temporarily  added  Bob.com  to  the 
mock RP’s whitelist to let BRM1 succeed (and removed it 
from  the  whitelist  after  BRM1),  the  secret  token  obtained 
from  BRM7  is  still  useless.  This  is  due  to  another  check 
against  the  whitelist:  when  a  website  uses  the  token  to 
retrieve  Alice’s  Google  ID  profile  from  JanRain,  JanRain 
finds  something  wrong:  the  token  was  previously  sent  to 
Bob.com  according  to  the  token_URL;  thus  Bob.com  is 
supposed to be on the RP’s whitelist, but it is not.  
 Given  the  protection  of  whitelisting,  it  is  clear  that 
token_url in BRM1 must be in a domain on RP-App’s 
whitelist (e.g., http://RP.com/finish-login). The trouble now 
is  that  dst  on  BRM7  is  exactly  token_url.  In  other 
words, once token_url is set according to the target RP’s 
whitelist, there is no way that Bob can have BRM7 sent to 
him. This forced us to look back at the result of our analysis 
and  try  another  opportunity.  Actually,  dst in  BRM5  is 
propagated  from  the  xdReceiver  in  BRM1,  which  Bob 
appears to be able to write. If he could change this element 
(e.g., 
to  http://Bob.com/xdcomm)  without  being 
caught,  he could  have JanRain send him BRM5. BRM5 is 
also important, as it contains  loc, another piece of secret. 
Stealing  loc  is  as  damaging  as  stealing  token.  If  Bob 
obtains  loc,  his  exploit  will  succeed,  as  loc  is  the  only 
secret  Bob  needs  in  order  to  use  his  own  browser  to  go 
through  BRM6  and  BRM7,  which  will  get  Alice’s  session 
into  the  browser.  Therefore,  we  saw  that  stealing  loc 
through BRM5 was a plausible idea.  
Our  test  showed  both  encouraging  and  challenging 
sides  of  the  idea.  On  the  challenging  side,  we  found  that 
JanRain  also  checked  xdReceiver  in  BRM1  against  the 