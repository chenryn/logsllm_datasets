√
√
√
×
×
×
−
−
−
−
−
−
Considering Location
Context
√
×
×
×
×
×
×
−
−
−
−
−
−
external information, which are not available in our scenario.
Thus,
their approaches cannot be applied to solving our
problem. On the other hand, algorithms designed for proﬁle
datasets [15], [16], [26] (e.g., age, gender, language) are not
applicable to location trajectories, and thus omitted for brevity.
Privacy Protection Mechanisms.
Researchers have in-
vestigated different ways to anonymize user data to preserve
privacy. The most common privacy models are k-anonymity
[36], l-diversity [24] and t-closeness [21]. Related to these
three models, a number of speciﬁc techniques have been pro-
posed to anonymize location trajectory data. Osman et al. [2]
proposed a technique to protect privacy by shifting trajectory
points in space that are close to each other in time. Marco
et al. [18] proposed an algorithm named GLOVE to grant k-
anonymity of trajectories through specialized spatio-temporal
generalization. Another work from Osman [1] developed a
time-tolerant method. Simon et al. [30] provided two metrics,
conditional entropy and worst-case quality loss, to evaluate the
privacy protection mechanisms.
Recently, researchers also explore to apply differential
privacy to location trajectory datasets [3], [5], [12]. For ex-
ample, Andr´es et al. [5] introduced geo-indistinguishability,
which used criteria of differential privacy to make sure the
user’s exact location is unknown while keeping enough utility
for certain desired service. Gergely et al. [3] studied an
anonymization scheme to release spatio-temporal density data
based on differential privacy. In our work, the deﬁnition of
privacy is based on the uniqueness of user trajectories, whose
privacy model is based on k-anonymity.
III. THREAT MODEL
In this work, we seek to examine how much of individuals’
privacy will be leaked if the ISP shares their anonymized tra-
jectory datasets. We investigate this problem by implementing
and testing a wide range of de-anonymization attack schemes
against real-world trajectory datasets. To better describe the
de-anonymization problem, we ﬁrst formally deﬁne the threat
model in this section. Our threat model mainly consists of two
components, i.e., the ISP that is the data owner to publish
anonymized trajectory traces, and the adversary which seeks
to re-identify users in the published dataset. For the ease of
reading, we summarize the key notations in Table II.
A. Location Data Publishing by ISP
TABLE II.
A LIST OF COMMONLY USED NOTATIONS.
Notat.
U
V
T
R
L
S
Lv
Su
Lv(t)
Su(t)
σ
D
R(u, D)
Φ(S, D)
T v
i,j
I(·)
Description
The set of true identities of all users.
The set of pseudonyms of all users.
The set of all time slots.
The set of all regions.
The set of anonymized ISP traces.
The set of traces as external information (adversary knowledge).
ISP trajectory of user with pseudonym v.
External trajectory of user u.
Location in the ISP trajectory of user with pseudonym v at time
slot t.
Location in the external trajectory of user u at time slot t.
Anonymization function mapping U to V .
Similarity score function between trajectories.
The rank of the true matched trajectory of u based on similarity
function D.
Transition matrix of user u.
Performance metric of de-anonymization attack.
Indicator function of logical expressions with I(true) = 1 and
I(false) = 0.
σ to anonymize it, i.e., replace the user identity u with
the pseudonym σ(u). We further deﬁne V as the set of
pseudonyms of all users.
After anonymization, a spatio-temporal
record in the
dataset is deﬁned as a 3-tuple (v, t, r), where v ∈ V is the
pseudonym of the user, and r, t are the observed location and
timestamp, respectively.
We deﬁne the mobility trace of the user with pseudonym
v ∈ V published by ISP as a T -size vector Lv =
(Lv(1), Lv(2), ..., Lv(T )) where Lv(t) represents the location
observed at time slot t, and T is the total number of time
slots. For time slots with a location record, Lv(t) is the
corresponding geographic coordinate. For time slots without
a location record, Lv(t) is ∅. We further deﬁne L as the set of
all mobility traces in the ISP dataset, as L = {Lv|v ∈ V }. In
this work, we mainly focus on the effectiveness of the de-
anonymization attacks. We assume the ISP does not apply
additional obfuscations to the data other than the common
steps such as reducing the spatio-temporal resolution of the
records [33]. This beneﬁts assessing the upper-bound perfor-
mance of the existing attacking methods against real-world
datasets.
B. Adversary
In the de-anonymization attack, an adversary seeks to re-
identify users using external information. An adversary is de-
scribed by two components, i.e., utilized knowledge (external
information), and attack method.
Let U represent
the set of the identities of all users.
Before the dataset is published, the ISP uses a map function
Adversary Knowledge.
Adversary can use different types
of external knowledge for de-anonymization. In this paper,
3
we mainly focus on two categories of adversaries. The ﬁrst
category is the company-level attacker, e.g., application and
service providers who have users’ sub-trajectory information
uploaded by the application software installed on the users’
mobile devices. The second category is the individual-level
attacker, who can obtain external
information by crawling
the publicly available location information (online check-ins)
shared by users.
For an arbitrary adversary, regardless of its category, we
use a uniform T -size vector Su = (Su(1), Su(2), ..., Su(T ))
to represent its external information, with Su(t) representing
the location (geographic coordinate) observed at time slot t
for user u ∈ U, In addition, we set S(t) = ∅ in time slot t
without locations. We further deﬁne S = {Su|u ∈ U} as the
set of all traces in the external information.
Attack Method.
Attack method of the adversary is de-
scribed by the similarity score function D deﬁned between
trajectories in ISP dataset and external information, i.e., D :
L × S → R, where R is the set of real numbers. Based on
this similarity function, for each user u with external trajectory
Su, adversary rank of all its candidate trajectories in the ISP
dataset. The goal of the adversary is to rank the ISP trajectory
belonging to u, i.e., Lσ(u) as high as possible.
More speciﬁcally, we use R(u, D) to denote the rank of
Lσ(u) based on similarity function D. Further, denote function
h as the metric of the ranking R(u, D). For higher R(u, D),
h(R(u, D)) is larger. Then, the performance of the attack
method can be expressed as follows,
Φ(S, D) =
1
|U|
h(R(u, D)).
(cid:88)
Su∈S
For any adversary, given external information S, the target can
be expressed as follows,
Φ(S, D).
arg max
D
In terms of the ranking, a well-established and widely-
used evaluation metric is the hit-precision of top-k candidates,
which is deﬁned as follows,
(cid:40) k−(x−1)
h(x) =
k
0,
,
if k ≥ x ≥ 1,
if x > k.
For example, if the true matched trajectory Lσ(u) has the
largest similarity, i.e., D(Su, Lσ(u)) ≥ D(Su, Lv) for any
v ∈ V , then, R(u, D) = 1 and h(R(u, D)) = 1. If Lσ(u)
ranks 3 in all candidate trajectories in L, R(u, D) = 3 and
h(R(u, D)) = k−2
k .
IV. GROUND-TRUTH TRAJECTORY DATASETS
To empirically assess the effectiveness of de-anonymization
algorithms against large-scale trajectories from ISP, we collect
real-world ground-truth datasets. The data are obtained from
a major ISP, a large online social network and a check-
in/review service for an overlapped user population. We also
have the ground-truth mapping between users across these
three datasets. The datasets are obtained through our research
collaborations and a summary of the datasets is shown in
Table III. Below, we describe the datasets in detail and perform
a preliminary analysis.
A. ISP Dataset
The main dataset contains 2,161,500 ISP trajectories from
a major cellular service provider in China from April 19
to April 26 in 2016 covering whole metropolitan area of
Shanghai. Each trajectory is constructed based on the user’s
connection records to the base stations (cellular towers). Each
spatial-temporal data point in the trace is characterized by an
anonymized user ID, base station (BS) ID and a timestamp.
This dataset will serve as the target dataset for evaluating the
de-anonymization attack.
B. Social Network Dataset
As the external information for de-anonymizing users, we
also collect datasets from Weibo, a large online social network
in China with over 340 million users. The challenge is to
obtain the ground-truth mapping between users in the ISP
dataset and the Weibo users. This is doable from the ISP side
because Weibo’s mobile app uses HTTP to communicate with
its servers and the Weibo ID is visible in the URL. Given
the sensitivity of the data, we approached Weibo’s Data and
Engineering team to ask for the permission to collect the
Weibo IDs from the ISP end for this research. After setting
up a series of privacy and data protection plans, Weibo gave
us the approval to use the data only for research purposes
(more detailed data protection and ethical guidelines are in
Section IV-E).
App-level GPS Data. With the permission of Weibo, our
collaborators in the ISP marked the Weibo sessions for users
that appear in the ISP traces, within the same time window
April 19 to April 26 in 2016. In this way, we construct
an external GPS dataset of 56,683 matched users. In this
dataset, each location trajectory is characterized by a user’s
Weibo ID, and a series of GPS coordinates that show up in
HTTP sessions between the mobile app and Weibo server.
This dataset represents location traces that users report to the
Weibo server. Using this dataset as external information, we
can evaluate how much Weibo service can de-anonymize a
shared ISP dataset, i.e., company level attacks. Note that the
Weibo ID is only visible to the ISP collaborator. The ID has
been replaced with an encrypted bitstream before the data
is handled to us. A mapping between the bitstream to the
anonymized ISP user ID is provided to us.
User Location Check-ins.
Based on the matched Weibo
IDs, our collaborator at the ISP also helped to collected a
check-in dataset using Weibo’s open APIs2. This dataset covers
the same time window of previous datasets (Synchronized),
as well as all the historical check-ins of the matched users
(Historical). Since check-in data is publicly available to any
third-parties, we use it to evaluate how much any attackers
can de-anonymize a shared ISP dataset, i.e., individual level
attacks. Similarly, we only access the anonymized ID, instead
of the actual Weibo ID.
C. Review Service Dataset
To make sure our analysis is not biased towards a single
dataset, we collected a secondary dataset to validate our obser-
vations. The secondary dataset was collected from Dianping,
2http://open.weibo.com
4
TABLE III.
STATISTICS OF COLLECTED DATASETS.
Dataset
ISP
Weibo App-level
Weibo Check-in (Historical)
Weibo Check-in (Synchronized)
Dianping App-level
Total#
Users
2,161,500
56,683
10,750
503
45,790
Total#
Records
134,033,750
239,289
141,131
873
107,543
#Recd.