experiments using the GPS coordinates exploration strategies (see
Subsection 3.2).
Experiment Design and Results. Using our MITM proxy setup,
we reverse engineer the API of the service and identified an API
call used to add a speed detector and a second API which allows
searching for speed detectors. The second is useful for observing
the success or failure of the injection. We successfully spoofed the
service’s mobile app’s network requests using our framework. We
found that values outside the expected longitude and latitude range
(CE-O) are rejected. However, for the latitude and longitude experi-
ments (CE-Long and CE-Lat), 48/180 (26.6%) and 55/360 (15.3%) of
the injections succeeded respectively. Consecutive injections are
blocked after a fixed number of requests (see red points on Figure 4),
which led us to hypothesize that the points were not rejected based
on semantic validation but instead were rejected due to a rate limit
on the number of points a registered user can submit. To overcome
this, we generate a pool of fake user fingerprints which we rotate
through when performing the injections. We noticed that the user-
id for a participant depends on the Android-id of her phone and
relaunching the app after changing the Android-id of the emulator
phone creates two requests with two different but corresponding
ids for registration and retrieval of PoIs on the map. So, we wrote
two scripts to automate this process, one of them employed adb
to keep relaunching the app and the other script interacted with
our MITM proxy to scan the requests and responses and extract
the (registration-id, user-id) pairs out of them so that we can use
them later for our experiments. We follow this setup to generate a
pool of 86 fake users and conduct the CE-2D experiment where we
do injections for the whole 2D range of latitudes and longitudes.
Furthermore, we add a delay of 10 seconds between successive
injections and repeat the whole sequence of requests that happen
on launching the app for each injection, instead of just calling the
injection API call. With this setup, we were able to perform suc-
cessful injections for the entire 2D range of points as described in
CE-2D (see Figure 4 (green points)). The only exceptions where the
injection failed was when either the longitude or latitude was 0 or
when the value of latitude was exactly on the boundaries -90 or 90.
For CE-Prec, we saw that POIs can be inserted with a precision of
up to 5 decimal places but no two POIs can be closer than 0.002 on
either longitude or the latitude scale, which happens to be equiva-
lent to around 222 meters in distance. To prevent any harm to the
service or its users we identified another API request which we
employ with an input value of 0 in the request body, to remove the
added PoIs after each successful injection.
8 SAFETY SERVICES
A number of MCSs allow users to share safety-related information.
One such service is Neighbors by Ring [16] (NbR), whose Android
app has been downloaded over 1,000,000 times. This service allows
its users to share four kinds of posts: crimes, safety-related events,
lost pets, and unexpected activities. These can include text, images,
Figure 3: Transit: Faking Buses with Supersonic Speeds.
• Supersonic Speeds. In this experiment, we aim to find whether
supersonic speeds (greater than the speed of sound—1235km/h) are
possible. To explore this we use a variation of the numeric value
exploration strategy. However, when a failure is encountered dur-
ing geometric growth, before reverting back to the last successful
value, we linearly (s = 10) try the next 4 values, and only if all 4
fail we finish exploring higher values. This is needed to deal with
uncertainties at high speeds where we found the behavior of the
service can be unpredictable. Specifically, our algorithm proceeds as
follows: to find the highest acceptable speed Sh, the attack emulator
starts at the speed 10 km/h and keeps doubling this value until the
first failed attack speed Si is observed on the victim phone. The
failed attack is further confirmed with 4 more adversarial speeds
: Si + 10, Si + 20, Si + 30, Si + 40. If more than 4 attacks fail out
of 5 experiments, we regard Si as the first failed attack speed and
Si−1 as the last successful attack speed. Therefore, Sh is within the
range [Si−1, Si]. Given Sj = Si−1+Si
, range [Si−1, Si] is divided into
two ranges: [Si−1, Sj] and [Sj , Si]. If Sj is able to attack the victim
phone, Sh is within [Sj , Si], otherwise, [Si−1, Sj]. By keeping on
dividing the range, Sh is finally confirmed. As shown in Figure 3,
we managed to succeed with supersonic speeds of up to 2350 km/h.
We repeated the attack at this speed 10 times. We found that 3/10
(30%) of the times the injection at 2350 km/h influences the victim.
Other transportation services. For our analysis we also selected
GoogleMaps (Section 3). Even though its susceptibility to general
data poisoning attacks was established manually [45], we could
not apply our framework to scale up the analysis. In particular, we
could not decrypt its APIs calls due to the usage of not only server
but also client certificates which our framework cannot currently
bypass. However, our framework can be expanded with a farm of
real phones and emulators to support the analysis of such cases.
2
7 LOCATION-BASED SERVICES
Services such as Police Detector and ToiFi (Toilet Finder), crowd-
source points of interests (PoIs). An adversary targeting such ser-
vices might create or remove PoIs to their own benefit. For example,
a fake police radar can deceive an individual into using another
route; a fake toilet might be used to lure potential victims to de-
serted locales. Using spoofed networked requests we were able to
verify and analyze IIV vulnerabilities for both ToiFi and Police De-
tector. Due to space limitations, we present our analysis on ToiFi
(Toilet) in Appendix A.
Police Detector Overview. Police detector (Speed Camera Radar)
[17] uses crowdsourcing to help users make intelligent decisions
while driving. Its Android app was installed more than 5,000,000
951Characterizing Improper Input Validation Vulnerabilities of Mobile Crowdsourcing Services
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Table 3: NbR: Fake Injection Success Rates.
Strategy
Image
Crime
Safety
Lost Pet
RSG
SGP
SGA
SGP
SGA
SGP
SGA
n/a
n/a
n/a
Irrelevant
Irrelevant
Relevant
Relevant
n/a
9/25
22/25
9/25
22/25
9/25
23/25
n/a
6/25
19/25
6/25
20/25
6/25
20/25
n/a
10/25
16/25
10/25
16/25
16/25
25/25
Unexpected Ac-
tivity
n/a
1/25
9/25
1/25
9/25
2/25
12/25
Total
0/100
23/100
66/100
23/100
67/100
33/100
80/100
Figure 4: Police Detector: CE-Long & CE-Lat Successful In-
jections (•), CE-2D Successful Injections (•).
even video streams from security cameras, and share the reporting
device’s location. Fake reports can be used to spread chaos or de-
fame a location or neighborhood. In a more sophisticated scenario,
enemy states or organizations with political affiliations can deploy
elaborate propaganda schemes.
Manual Attack. We submitted manually–constructed sample tex-
tual posts controlling for both the location and the semantics of
the text. We found that NbR does not verify the location but does
verify the semantics of the textual report. For example, our attempt
to inject “dangerous cat spotted” was rejected, but our attempt to
inject “dangerous dog spotted” was successful. Additionally, posts
that were too vague about the safety issue were rejected as well. We
suspect that NbR uses a machine learning algorithm to determine
whether posts are legitimate or not in order to tackle fake posts.
Experiment Design. To further explore the service’s semantic
validation, we submit posts generated using our post generation
strategies: random sentence generation (RSG), sentence genera-
tion with pre-trained GPT-2 (SGP), and sentence generation with
adapted GPT-2 (SGA), and report the posts’ acceptance rate. To
configure the strategies’ parameters, we first use our DEM module
to execute the app, interact with it, and extract already present but
unseen posts. We collected a dataset of 1080 genuine posts which
follow the format: . Using the genuine posts descriptions we determine
the average sentence length (= 30) words for the RSG strategy. We
also identify the three most common words present in the first
sentence of each post’s description, by category. These are used as
the keywords and titles of the fake posts in the SGP strategy. For
the adaptive approach (SGA), we fine-tuned the text generation
model. The model was trained for 1000 epochs and with a learning
rate of 10−4 and a temperature of 0.7 for the generation.
To test the generated posts, we set up three Android devices
and submit them via the UI of the target service’s Android app,
using our DEM module. Since the app requires a unique email
address to create an account, we create temporary emails for each
device. We set the devices’ location in Death Valley, California at
different spots such to minimize exposure to real users. Once a post
is submitted, our script updates the page for up to 8 minutes until
the post appears in the user’s submissions. We noticed that the
time to get the decision varies between 1 to 7 minutes. If the post
appears, it is marked as accepted and the script deletes the post.
If the post is not accepted, the respective email address receives a
rejection email and the post never appears in the submissions. We
also found that the service blocks accounts that post too often and
set a limit of 8 rejected posts a day. Once a user is blocked, their
submissions are ignored without any notification. To overcome this
problem, we submit at most 3 posts an hour and set random delays
in the range of 20 to 35 minutes between posts. We also monitor
the emails manually to check that the posts are not ignored.
Results. Table 3 shows the number of accepted posts per category
out of the total number of submitted fake posts for each of the
generation strategies. Examples of successful injections are shown
in Appendix B, Table 5. The results show that the app does not
accept just any input text, as none of the random posts went through.
Furthermore, some text-only posts generated with the SGP strategy
are rejected even if they are of topics similar to the ones accepted by
the service. Those posts were possibly too vague about safety issues
and without a clearly defined structure. However, 23 out of 100 fake
posts were indeed approved. Fake posts generated using the SGA
strategy were more likely to get accepted as 66% of posts were able
to replicate the format and or the necessary information required
by the app. Moreover, the model generated crime related posts
with almost 90% success rate. The “Unexpected Activity” category
seems to be the hardest to imitate as it has the lowest acceptance
for both strategies. When comparing fake and genuine posts, we
found that “Unexpected Activity” posts often also include video
footage captured with the Ring security camera.
Enriching posts with irrelevant images did not help except for
one post that mentions a troop of policemen. We hypothesize that
the blue color of the image could be mistakenly taken as their
usually blue uniform. Nevertheless, this experiment show that there
is semantic validation using the images. Indeed, posting the fake
reports with relevant images improved the success rate for both the
SGP and the SGA strategies and particularly for the category “Lost
Pet”. The rates also improve slightly for the other categories.
These results show that Neighbors by Ring does check for seman-
tic soundness and also relevance to their categories. The app is also
more lenient for “Lost Pet” posts, especially if given an image. How-
ever, for posts of type “Crime”, “Safety” and “Unexpected Activity”,
the emphasis seems to be on the input text and the information it
provides. Nevertheless, we show that using our fake post generation
strategies, an adversary can generate multiple posts fulfilling these
conditions and effectively perform successful injection attacks.
9 DISCUSSION ON COUNTERMEASURES
Majority voting, origin attestation, and reputation schemes can
help alleviate improper input injections. However, majority voting
depends on the availability of multiple sources of information at
any given point in time which is not always true in services with
real-time requirements. Origin validation approaches can limit an
adversary’s ability to scale up the attacks, but they are not effective
952ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Khan, et al.
Table 4: Example countermeasures and the ensuing reduction in the affected attack surface. e1 = 0.2 ∗ 350 and e2 = 0.2 ∗ 70.
App Domain
Strava
Map My Run
Fitbit
Transit
Basket Savings
Police Detector
NbR
Example Countermeasure
Restrict running distance (d) to be at most the world record
Restrict running distance (d) to be at most the world record
Restrict running distance (d) to be at most the world record
App Type
Fitness
Fitness
Fitness
Transportation Enforce bus speed (v) according to highway code—70mph in UK Motorways
Pricing
Location
Safety