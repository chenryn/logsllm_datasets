and compared their responses. A divergence was de-
tected when the HTTP status code differed, hence di-
vergences that caused the servers to modify external
state differently or produce different output pages
would not be detected. The system described by Totel,
Majorczyk, and Mé extended this idea to compare the
actual web page responses of the two servers [62].
Since different servers do not produce exactly the same
output on all non-attack requests because of nondeter-
minism, design differences in the servers, and host-
specific properties, they developed an algorithm that
compares a set of server responses to determine which
divergences are likely to correspond to attacks and
which are benign. The system proposed by Gao, Reiter,
and Song [28] deployed multiple servers in a similar
way, but monitored their behavior using a distance met-
ric that examined the sequence of system calls each
server made to determine when the server behaviors
diverged beyond a threshold amount.
All of these systems use multiple available implementa-
tions of the same service running on isolated machines
and compare the output or aspects of the behavior to
notice when the servers diverged. They differ in their
system architectures and in how divergences are recog-
nized. The primary advantage of our work over these
approaches is the level of assurance automated diversity
and monitoring can provide over design diversity. Be-
cause our system takes advantage of knowing exactly
how the variants differ, we can make security claims
about large attack classes. With design diversity, secu-
rity claims depend on the implementations being suffi-
ciently different to diverge noticeably on the attack (and
functionality claims depend on the behaviors being suf-
ficiently similar not exceed the divergence threshold on
non-attack inputs). In addition, these approaches can be
used only when diverse implementations of the same
service are available. For HTTP servers, this is the case,
but for custom servers the costs of producing a diverse
implementation are prohibitive in most cases. Further,
even though many HTTP servers exist, most advanced
websites take advantages of server-specific functionality
(such as server-side includes provided by Apache), so
would not work on an alternate server. Design diversity
approaches offer the advantage that they may be able to
detect attacks that are at the level of application seman-
tics rather than low-level memory corruption or code
injection attacks that are better detected by artificial
diversity. In Section 6, we consider possible extensions
to our work that would combine both approaches to
provide defenses against both types of attacks.
108
Security ’06: 15th USENIX Security Symposium
USENIX Association
3. Model
Our goal is to show that for all attacks in a particular
attack class, if one variant is compromised by a given
attack, another variant must exhibit divergent behavior
that is detected by the monitor. To show this, we de-
velop a model of execution for an N-variant system and
define two properties the variant processes must main-
tain to provide a detection guarantee.
We can view an execution as a possibly infinite se-
quence of states: [S0, S1, …]. In an N-variant system, the
state of the system can be represented using a tuple of
the states of the variants (for simplicity, this argument
assumes the polygrapher and monitor are stateless; in
our implementation, they do maintain some state but we
ignore that in this presentation). Hence, an execution of
an N-variant system is a sequence of state-tuples where
St,v represents the state of variant v at step t: [, , … ].
Because of the artificial variation, the concrete state of
each variant differs. Each variant has a canonicalization
function, Cv, that maps its state to a canonical state that
matches the corresponding state for the original process.
For example, if the variation alters memory addresses,
the mapping function would need to map the variant’s
altered addresses to canonical addresses. Under normal
execution, at every execution step the canonicalized
states of all variants are identical to the original pro-
gram state:
≥
∀
t
≤
<
≤
<
v
0, 0
N:
Cv (St, v) = Cw (St, w) = St.
N, 0
w
Each variant has a transition function, Tv, that takes a
state and an input and produces the next state. The
original program, P, also has a transition function, T.
The set of possible transitions can be partitioned into
consistent transitions and aberrant transitions. Consis-
tent transitions take the system from one normal state to
another normal state; aberrant transitions take the sys-
tem from a normal state to a compromised state. An
attack is successful if it produces an aberrant transition
without detection. Our goal is to detect all aberrant tran-
sitions.
We partition possible variant states into three sets: nor-
mal, compromised, and alarm. A variant in a normal
state is behaving as intended. A variant in a compro-
mised state has been successfully compromised by a
malicious attack. A variant in an alarm state is anoma-
lous in a way that is detectable by the monitor. We aim
to guarantee that the N-variant system never enters a
state-tuple that contains one or more variants in com-
prised states without any variants in alarm states. To
establish this we need two properties: normal equiva-
lence and detection.
Normal equivalence. The normal equivalence property
is satisfied if the N-variant system synchronizes the
states of all variants. That is, whenever all variants are
in normal states, they must be in states that correspond
to the same canonical state. For security, it is sufficient
to show the variants remain in equivalent states. For
correctness, we would also like to know the canonical
state of each of the variants is equivalent to the state of
the original process.
We can prove the normal equivalence property stati-
cally using induction:
1. Show that initially all variants are in the same ca-
nonical state:
∀
≤
<
0
v
N: Ci (S0, v) = S0.
2. Show that every normal transition preserves the
equivalence when the system is initially in a normal
state:
∀
∈
≤
<
S
v
Normal, 0
N, Sv
where Cv (Sv) = S, p
Cv (Tv (Sv, p)) = T (S, p).
∈
Inputs:
Alternatively, we can establish it dynamically by exam-
ining the states of the variants and using the canonicali-
zation function to check the variants are in equivalent
states after every step. In practice, neither a full static
proof nor a complete dynamic comparison is likely to
be feasible for real systems. Instead, we argue that our
implementation provides a limited form of normal
equivalence using a combination of static argument and
limited dynamic comparison, as we discuss in Section 5.
Detection. The detection property guarantees that all
attacks in a certain class will be detected by the
N-variant system as long as the normal equivalence
property is satisfied. To establish the detection property,
we need to know that any input that causes one variant
to enter a compromised state must also cause some
other variant to enter an alarm state. Because of the
normal equivalence property, we can assume the vari-
ants all are in equivalent states before processing this
input. Thus, we need to show:
∀
∈
≤
<
v
N, Sv where Cv (Sv) = S,
∀
S
p
∈
Normal, 0
Inputs:
Tv (Sv, p)
∈
∃
Compromised
w such that Tw (Sw, p)
∈
Alarm and Cw (Sw) = S
If the detection property is established, we know that
whenever one of the variants enters a compromised
USENIX Association
Security ’06: 15th USENIX Security Symposium
109
state, one of the variants must enter an alarm state. An
ideal monitor would instantly detect the alarm state and
prevent all
the other variants from continuing. This
would guarantee that the system never operates in a
state in which any variant is compromised.
In practice, building such a monitor is impossible since
we cannot keep the variants perfectly synchronized or
detect alarm states instantly. However, we can approxi-
mate this behavior by delaying any external effects (in-
cluding responses to the client) until all variants have
passed a critical point. This keeps the variants loosely
synchronized, and approximates the behavior of in-
stantly terminating all other variants when one variant
encounters an alarm state. It leaves open the possibility
that a compromised variant could corrupt the state of
other parts of the system (including the monitor and
other variants) before the alarm state is detected. An
implementation must use isolation mechanisms to limit
this possibility.
4. Variations
Our framework works with any diversification tech-
nique that produces variants different enough to provide
detection of a class of attack but similar enough to es-
tablish a normal equivalence property. The variation
used to diversify the variants determines the attack class
the N-variant system can detect. The detection property
is defined by the class of attack we detect, so we will
consider attack classes, such as attacks that involve exe-
cuting injected instructions, rather than vulnerability
classes such as buffer overflow vulnerabilities.
Next, we describe two variations we have implemented:
address space partitioning and instruction set tagging.
We argue (informally) that they satisfy both the normal
equivalence property and the detection condition for
important classes of attacks. The framework is general
enough to support many other possible variations,
which we plan to explore in future work. Other possible
variations that could provide useful security properties
include varying memory organization,
file naming,
scheduling, system calls, calling conventions, configura-
tion properties, and the root user id.
4.1 Address Space Partitioning  
The Introduction described an example variation where
the address space is partitioned between two variants to
disrupt attacks that rely on absolute addresses. This
simple variation does not prevent all memory corruption
attacks since some attacks depend only on relative ad-
dressing, but it does prevent all memory corruption at-
involve direct references to absolute ad-
tacks that
dresses. Several common vulnerabilities including for-
mat string [56, 54], integer overflow, and double-free
[24] may allow an attacker to overwrite an absolute
location in the target’s address space. This opportunity
can be exploited to give an attacker control of a process,
for example, by modifying the Global Offset Table [24]
or the .dtors segment of an ELF executable [48]. Re-
gardless of the vulnerability exploited and the targeted
data structure, if the attack depends on loading or stor-
ing to an absolute address it will be detected by our
partitioning variants. Since the variation alters absolute
addresses, it is necessary that the original program does
not depend on actual memory addresses (for example,
using the value of a pointer directly in a decision). Al-
though it is easy to construct programs that do not sat-
isfy this property, most sensible programs should not
depend on actual memory addresses.
Detection. Suppose P0 only uses addresses whose high
bit is 0 and P1 only uses addresses whose high bit is 1.
We can map the normal state of P0 and P1 to equivalent
states using the identity function for C0 and a function
that flips the high bit of all memory addresses for C1 (to
map onto the actual addresses used by P, more complex
mapping functions may be needed). The transition func-
tions, T0 and T1 are identical; the generated code is what
makes things different since a different address will be
referenced in the generated code for any absolute ad-
dress reference. If an attack involves referencing an
absolute address, the attacker must choose an address
whose high bit is either a 0 or 1. If it is a 0, then P0 may
transition to a compromised state, but P1 will transition
to an alarm state when it attempts to access a memory
address outside P1’s address space. In Unix systems,
this alarm state is detected by the operating system as a
segmentation fault. Conversely, if the attacker chooses
an address whose high bit is 1, P1 may be compromised
but P0 must enter an alarm state. In either case, the
monitor detects the compromise and prevents any ex-
ternal state modifications including output transmission
to the client.
Our detection argument relies on the assumption that
the attacker must construct the entire address directly.
For most scenarios, this assumption is likely to be valid.
For certain vulnerabilities on platforms that are not
byte-aligned, however, it may not be. If the attacker is
able to overwrite an existing address in the program
without overwriting the high bit, the attacker may be
able to construct an address that is valid in both vari-
ants. Similarly, if an attacker can corrupt a value that is
subsequently used with a transformed absolute address
in an address calculation, the detection property is vio-
110
Security ’06: 15th USENIX Security Symposium
USENIX Association
lated. As with relative attacks, this indirect memory
attacks would not be detected by this variation.
Normal equivalence. We have two options for estab-
lishing the normal equivalence property: we can check
it dynamically using the monitor, or we can prove it
statically by analyzing the variants. A pure dynamic
approach is attractive for security assurance because of
its simplicity but impractical for performance-critical
servers. The monitor would need to implement C0 and
C1 and compute the canonical states of each variant at
the end of each instruction execution. If the states
match, normal equivalence is satisfied. In practice,
however, this approach is likely to be prohibitively ex-
pensive. We can optimize the check by limiting the
comparison to the subset of the execution state that may
have changed and only checking the state after particu-
lar instructions, but the overhead of checking the states
of the variants after every step will still be unacceptable
for most services.
transitions result
The static approach requires proving that for every pos-
sible normal state, all normal
in
equivalent states on the two variants. This property re-
quires that no instruction in P can distinguish between
the two variants. For example, if there were a condi-
tional jump in P that depended on the high bit of the
address of some variable, P0 and P1 would end up in
different states after executing that instruction. An at-
tacker could take advantage of such an opportunity to
get the variants in different states such that an input that
transitions P0 to a compromised state does not cause P1
to reach an alarm state. For example, if the divergence
is used to put P0 in a state where the next client input
will be passed to a vulnerable string format call, but the
next client input to P1 is processed harmlessly by some
other code, an attacker may be able to successfully
compromise the N-variant system. A divergence could
also occur if some part of the system is nondeterminis-
tic, and the operating environment does not eliminate
this nondeterminism (see Section 5). Finally, if P is
vulnerable to some other class of attack, such as code
injection, an attacker may be able to alter the transition
functions T0 and T1 in a way that allows the memory
corruption attack to be exploited differently on the two
variants to avoid detection (of course, an attacker who
can inject code can already compromise the system in
arbitrary ways).
In practice, it will not usually be possible to completely