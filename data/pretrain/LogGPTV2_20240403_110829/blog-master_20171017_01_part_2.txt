增加这个功能可以用来控制更细粒度的权限。      
例如禁止超级用户从远程登录。(现有的方法，把所有超级用户列一遍，但是当用户权限变更（例如从超级用户变成了普通用户）后，PG_HBA.CONF并不会变更。)      
#### 14. 释放CACHE      
syscache    
relcache    
buffer    
#### 15. 脏读功能      
read uncommitted 隔离级别  
#### 16. 解读数据文件的命令行工具或UDF  
从数据文件直接读取数据文件的内容。类似灾难恢复  
#### 17. 负载策略，客户端就近选择节点      
[思路]      
一种负载策略。      
读负载均衡、或多master的场景，客户端(最终客户端或proxy)选择就近节点。      
例如多机房的场景，通过IP地址判断先从哪个节点读。      
或者根据配置的节点顺序进行，直到取到正常节点为止(pg-jdbc目前是这种方式)。      
#### 18. redo, log日志分离      
目前PG所有日志都打印在一起，不利于日志分析。      
建议将审计日志、错误日志、慢SQL日志(包括auto_explain的)、其他日志分开成4个文件打印。      
#### 19. 并行恢复、未达到一致性点之前，恢复过程允许只读操作，自动过滤不一致数据块，或自动使用旧快照。   快速打开库允许只读。    
#### 20. 在log_min_duration和 auto_explain记录的SQL中记录锁等待的时长      
#### 21. 使用copy导入数据时，跳过异常的行。      
#### 22. walsender支持restore_command取文件传送给walreceiver      
#### 23. 自动校准成本因子, 维度支持      
自动校准cost因子，让实例得到最准确的执行计划      
#### 24. 支持多种数据块规格      
支持不同业务形态的表，采用不同的块大小。  
#### 25. 支持设置EXTEND BLOCK大小  
默认每次EXTEND 1个BLOCK，批量导入时性能有提升空间。  
[《PostgreSQL 单表并行bulkload的extend file lock 冲突问题解决》](../201805/20180515_03.md)    
#### 26. 批量数据提交   
PG如果能将插入这块的消息协议改进一下也许性能能提高比较多，将目前的 ESES..ES 改为 EEE...S 就好了。这样就可以实现类似于批量插入了。      
#### 27. pg_basebackup 过滤 hash index & unlogged table      
#### 28. 自动预热缓存      
#### 29. 资源隔离 : 会话级、用户级、语句级、库级 内存、CPU单位时间、IOPS  限制      
#### 30. 截断聚合      
截断头尾百分比后输出聚合值。类似的应用场景有排除噪点、干扰数据后的聚合。      
例如统计tps的平均值，方差，标准差。但是由于一些干扰因素可能导致测试TPS时造成了一些干扰，使用这种方法可以过滤掉一些干扰数据。      
http://api.pgxn.org/src/trimmed_aggregates/      
#### 31. 语法层面支持count采用输出  
允许用户选择需要精确count还是评估COUNT    
结合pg_class.reltuples    
结合sample语法，输出采样    
#### 32. libpq协议层压缩支持      
#### 33. 基于hash聚合的count distinct支持      
#### 34. plan hint 支持      
#### 35. 改进垃圾回收进程，只保留需要的tuple版本，而不是最早事务之前的所有版本。      
#### 36. 便捷的各种数据类产品打通，同步。      
数据同步模块    
#### 37. postgresql, pg_stat_all_tables, 建议添加autovacuum, auto analyze, analyze, vacuum等存储为数组，记录最近N次的操作统计信息，包括每次扫描了多少BLOCK，产生了多少DIRTY PAGE等等。      
便于突发的IO或CPU的排错。 目前只记录最后一次，而且统计信息只能到LOG里面翻看，不够便捷。       
```      
-[ RECORD 57 ]------+---------------------------------------      
relid               | 16794      
schemaname          | public      
relname             | xxx      
seq_scan            | 0      
seq_tup_read        | 0      
idx_scan            | 7878      
idx_tup_fetch       | 29897      
n_tup_ins           | 48337      
n_tup_upd           | 0      
n_tup_del           | 0      
n_tup_hot_upd       | 0      
n_live_tup          | 765193      
n_dead_tup          | 0      
n_mod_since_analyze | 13404      
last_vacuum         |       
last_autovacuum     | 2018-01-16 17:42:57.694793+08      
last_analyze        |       
last_autoanalyze    | 2018-01-13 09:13:02.457322+08      
vacuum_count        | 0      
autovacuum_count    | 1      
analyze_count       | 0      
autoanalyze_count   | 1      
```      
#### 38. Greenplum, postgresql , 加入roaringbitmap，同时支持 多阶段并行聚合函数。      
#### 39. PostgreSQL, GPDB , jsonbd 一种内置压缩能力的JSON类型，实际上数据库内核也可以在数组、全文检索等其他多值类型上增加类似的压缩功能（相当于内置的数据字典能力），将字典化这个工作转嫁给数据库来实现。         
https://github.com/postgrespro/jsonbd        
```      
CREATE EXTENSION jsonbd;      
CREATE TABLE t(a JSONB COMPRESSION jsonbd);      
```      
#### 40. online split, merge 分区表.      
#### 41. postgresql, gpdb 支持动态执行计划，执行过程中根据实际的NODE扫描并返回的数据的统计信息，动态调整执行计划。      
#### 42. timescale , postgresql, 提供数据自动老化能力（自动有损压缩）。      
#### 43. postgresql, 支持具备阶段性可靠性的UNLOGGED TABLE，加速导入。      
#### 44. postgresql , skip locked , 返回未获得锁的行。以便再次处理。      
#### 45. 支持冻结从库的receiver进程，不接受主库的wal。目前仅支持replay的冻结。       
用途，在多副本的情况下，HA切换时，保证不出现脑裂。      
```      
 pg_catalog | pg_wal_replay_pause           | void                     |                     | normal      
 pg_catalog | pg_wal_replay_resume          | void                     |                     | normal      
```      
#### 47. 支持普通用户设置synchronous_commit  
citus, 元数据 2PC，同时要求每个节点的SLAVE，必须同步接收到DDL。  
保证元数据的全局一致性。   
#### 48. 多实例的监控管理  
当是企业中有多个数据库时，需要一个可以管理多个实例的软件。  
例如将问题优先暴露。  
#### 49. update|delete skip locked, nowait语法支持      
目前PG支持select xxx for update skip locked , nowait.      
但是不支持dml直接使用skip locked或者nowait      
不利于低延迟的同类需求，需要发多次QUERY，开启事务来支持。      
考虑添加直接的 update | delete skip locked, nowait 支持。      
#### 50. 支持基于index的sample scan
例如采用索引扫描返回很多条记录假设100万，用户需要在这100万随机挑选10000条，排序输出TOP -K。   
常用于大量数据搜索，例如推荐引擎。   
#### 51. pg_stat_statements 支持细粒度配置，比如只收集超过N秒的SQL，只收集某些表相关的SQL等。  
#### 52. PG支持类似ORACLE的表空间管理，而非每个对象对应相关的数据文件
[《PostgreSQL 单库对象过多，触发Linux系统限制 (ext4_dx_add_entry: Directory index full!) (could not create file "xx/xx/xxxxxx": No space left on device)》](../201804/20180410_04.md)  
[《PostgreSQL DaaS设计注意 - schema与database的抉择》](../201610/20161012_01.md)  
[《PostgreSQL 备库apply延迟(delay)原理分析与诊断》](../201703/20170301_01.md)  
#### 53. PostgreSQL支持DIO
避免多重BUFFER   
#### 54. PostgreSQL 支持更多的资源共享（session目前的relcache, syscache, work_mem都是独立的，期待共享），向Oracle PGA, SGA的设计看齐。
#### 55. PostgreSQL 支持脑裂函数，目前脑裂的话，只能在LOG中查看
主备异常切换时，老主库可能有未同步到备库的WAL，出现时间线分歧。但是在未来可能被demote为备库，实际上已经不能接上备库，如果1 MIN内再次发生HA，会导致切换到不该切换的库。  
加一个函数，防止脑裂(主备由于时间线错乱不可相互复制状态)，在备库的角色执行，判断当前主备是否处于脑裂状态。  
脑裂时，不能主动切换到脑裂的备库。（人为介入，如果主库不可恢复，可能需要人为修复）  
目前需要从LOG中判断  
```
2018-05-04 11:29:55.524 CST,,,28551,,5aebd38b.6f87,20,,2018-05-04 11:29:15 CST,,0,LOG,00000,"restarted WAL streaming at 118/EA000000 on timeline 5",,,,,,,,"WalReceiverMain, walreceiver.c:400",""
2018-05-04 11:29:55.534 CST,,,28551,,5aebd38b.6f87,21,,2018-05-04 11:29:15 CST,,0,LOG,00000,"replication terminated by primary server","End of WAL reached on timeline 5 at 118/EABAA6D0.",,,,,,,"WalReceiverMain, walreceiver.c:467",""
2018-05-04 11:29:55.535 CST,,,28547,,5aebd38b.6f83,14,,2018-05-04 11:29:15 CST,1/0,0,LOG,00000,"new timeline 6 forked off current database system timeline 5 before current recovery point 118/EABCA368",,,,,,,,"rescanLatestTimeLine, xlog.c:4347",""
```
以下为已有的判断依据，接收到的WAL小于REPLAY的WAL位置。说明本地库在作为主库角色时，有WAL没有同步给上游，所以出现接收到的WAL小于REPLAY的WAL位置。  
```
postgres=# select pg_last_wal_replay_lsn();
 pg_last_wal_replay_lsn 
------------------------
 118/EABCA368
(1 row)
postgres=# select pg_last_wal_receive_lsn();
 pg_last_wal_receive_lsn 
-------------------------
 118/EA000000
(1 row)
```
pg_last_wal_receive_lsn小于pg_last_wal_replay_lsn，或pg_last_wal_receive_lsn 为 NULL，都可以判断为脑裂。  
#### 56. PG 目前临时表不支持并行，可以考虑支持。  
#### 57. cluster增强
支持cluster ， 数据INSERT时动态聚集.  
数据按 segment组织，SEGMENT 内 尽量的保持按cluster id值聚集。   
prefetch 效果好 ，范围扫描，效率提升  
DB2, fsm，列表结构，并发写存问题    
fsm 打散，多个，随机挑选，降低写入冲突      
#### 58. failover slot
[《PostgreSQL slot failover》](../201805/20180516_01.md)  
#### 59. 改进slot
目前SLOT会导致主库不清理备库需要的垃圾版本，导致膨胀，CPU飙升等问题。  
改良，把这块的功能去掉，这块的功能还是需要feed back开关来控制。  
[《PostgreSQL slot failover》](../201805/20180516_01.md)  
#### 60. 改进目录结构
目前PG的一个DB在一个TBS中对应一个目录，如果这个DB在表空间下很多对象，可能打爆文件系统的INODE INDEX上限。  
建议，加一层目录，改进pg_filemap，比如按TABLE OID HASH一层。这样可以减少文件系统的INODE INDEX打爆。   
[《如何在CentOS 6.x x64系统中创建超过16TB的ext4文件系统》](../201609/20160918_01.md)  
#### 61. 分析能力增强
1、读写磁盘吞吐快照区间统计，区分索引，表，垃圾回收，FREEZE，AUTOANALYZE。分类统计。
2、锁等待时长快照区间统计，区分锁粒度，下钻到对象。
#### 62. range[]索引
例如一个范围类型的数组，不需要展开数据，即可对齐进行索引的包含检索。   
类似于range的倒排+GIST索引。   
#### 63. gis类型支持更完备的统计信息
GIS类型的统计信息不多，评估不准确。  
```
postgres=# select * from pg_stats where tablename='test' and attname='pos';
 schemaname | tablename | attname | inherited | null_frac | avg_width | n_distinct | most_common_vals | most_common_freqs | histogram_bounds | correlation | most_common_elems | most_common_elem_freqs | elem_count_histogram 
------------+-----------+---------+-----------+-----------+-----------+------------+------------------+-------------------+------------------+-------------+-------------------+------------------------+----------------------
 public     | test      | pos     | f         |         0 |        32 |         -1 |                  |                   |                  |             |                   |                        | 
(1 row)
postgres=# explain analyze select * from test where st_contains(st_setsrid(st_makebox2d(st_makepoint(119,60), st_makepoint(122,71)), 4326) , pos);
                                                                                                                                                                                                                                   QUERY PLAN
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Gather  (cost=0.00..2815576.91 rows=10033 width=553) (actual time=1.028..11177.961 rows=30100000 loops=1)
   Workers Planned: 12
   Workers Launched: 12
   ->  Parallel Seq Scan on test  (cost=0.00..2815576.91 rows=836 width=553) (actual time=0.048..2786.635 rows=2315385 loops=13)
         Filter: (('0103000020E610000001000000050000000000000000C05D400000000000004E400000000000C05D400000000000C051400000000000805E400000000000C051400000000000805E400000000000004E400000000000C05D400000000000004E40'::geometry ~ pos) AND 
_st_contains('0103000020E610000001000000050000000000000000C05D400000000000004E400000000000C05D400000000000C051400000000000805E400000000000C051400000000000805E400000000000004E400000000000C05D400000000000004E40'::geometry, pos))
 Planning time: 0.189 ms
 Execution time: 13554.917 ms
(7 rows)
```
[《PostgreSQL 空间类型统计信息不准确导致SQL执行计划不准(包含、相交查询)的优化实践》](../201807/20180711_02.md)    
#### 64. 重启实例性能改进
重启实例时，会堵塞所有新建连接，然后开始执行SHUTDOWN CHECKPOINT，如果此时数据库SHARED BUFFER里面的DIRTY PAGE很多，会导致shutdown时间很长，影响业务的时间也比较长。  
改进建议：  
1、先执行checkpoint，此时不影响业务。   
2、执行完CKPT后，进入原有的SHUTDOWN流程，堵塞所有新建连接，然后开始执行SHUTDOWN CHECKPOINT。   
3、由于第一步已经执行了CKPT，所以基本上SHARED BUFFER里面的DIRTY PAGE已经很少了，第二步执行shutdown checkpoint时，会很快，影响业务（堵塞连接）的时间很短。   
#### 65. 根据client的application_name，控制连接数限制，资源队列等。   多租户，共享连接，限流等场景。   
#### 66
当数据库异常停库，再次启动时。又或者由于进程CRASH后自动重启时。需要进入恢复模式，恢复完成后，数据库才能正常交互。  
在启动过程中，正在恢复时，如果此时连接数据库，会报错如下：  
```  
the database system is starting up  
```  
用户只看这个信息，并不知道数据库还要启动多久，现在已经恢复到什么状态了？  
内核层面可以稍作改进，报错时，同时输出正在恢复的WAL位点，以及距离最后一个文件的WAL位点差多少MB没有恢复。这样用户大概就还知道还需要多久。  
[《PostgreSQL 恢复模式错误日志增强 - 提供正在恢复的WAL（XLOG）文件位置》](../201808/20180810_02.md)   
#### 67
1、慢SQL记录到表里面。（或者单独的文件存储方便查询）