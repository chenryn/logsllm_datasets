0
INTER-KEYSTROKE TIMINGS IN MILLISECONDS: KEYLOGGER VS.
S C H E D S T A T MEASUREMENTS (LINUX).
Table III
Timings
bash
ssh
www.google.com
www.google.de
1000
2000
3000
4000
5000
6000
7000
8000
9000
Time (in milliseconds)
1
2
3
4
5
True Measured True Measured
127
191
88
159
111
128
191
87
161
112
159
111
184
199
119
160
111
184
198
119
Figure 23.
google.com and google.de (US-based browser).
Evolution of the Firefox memory footprint when loading
s
e
g
a
p
l
e
b
a
h
s
i
u
g
n
i
t
s
i
d
f
o
%
100
80
60
40
20
0
DRS only
DRS+Shared
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
% of recognizable visits
Figure 24. Chrome: Recognition rate when considering shared memory in
addition to DRS (100 pages, 1,000-page ambiguity set). No false positives.
which has three ﬁelds: time spent on the CPU, time spent
waiting, and timeslices run on the CPU. It turns out that
the timeslice counter leaks precise information about the
keystrokes the process is taking as input.
In programs like bash and ssh, user input is much slower
than the program itself. Therefore, they get off the run queue
whenever they wait for a keystroke and only get back once
the user presses a key. Every time the user presses a key,
bash and ssh execute for 1 and 2 timeslices, respectively,
before going back to wait for the next keystroke.
The attacker can thus continuously monitor schedstat
to ﬁnd out when keys are pressed and calculate precise inter-
keystroke timings. Table III compares these measurements
with an actual keylogger as the ﬁrst author is typing his
name. These timings can be used to reconstruct the user’s
input using an appropriate natural language model [20], but
we leave this as a topic for future research.
Android. In Android, /proc//schedstat is not
the number of voluntary and involuntary
available, but
context switches made by a process can be read from
/proc//status. While the process waits for a
call to retrieve the user’s keystroke, the kernel removes it
from the run queue. This results in a context switch and
enables the attacker to measure inter-keystroke timings.
We experimented with two Android applications: an MMS
app for sending text and multimedia messages and a bash
shell. For bash, we monitored the shell process’s context-
switch counts in /proc//status. Every time the
user presses a key, the count increases by 1. Unlike bash,
the MMS app has an input loop, so the context-switch count
is increasing even while it is waiting for keystrokes. This
is typical of many GUI applications because in Android
devices, a keystroke is usually processed by an input method
editor (IME) before it is passed to the application. In our
case, LIME IME is handling the key-press events, thus the
attack process monitors the number of context switches in
a LIME process named net.toload.main. For every
key press, the LIME process typically makes 3 − 5 context
switches, but as Fig. 25 shows, the intermediate context-
switch delays are very small compared to the delay caused
by waiting for keystroke inputs because user input is much
slower than computation. Table IV shows that this enables
the attacker to precisely measure inter-keystroke timings.
This attack is not speciﬁc to the MMS app. All keystrokes
handled by the LIME process are potentially vulnerable.
INTER-KEYSTROKE TIMINGS IN MILLISECONDS: KEYLOGGER VS.
S T A T U S MEASUREMENTS (ANDROID).
Table IV
Timings
MMS app
bash
True Measured True Measured
445
399
176
236
175
449
399
176
240
173
256
320
165
393
255
256
320
175
391
256
1
2
3
4
5
Combining side channels. We now show how keystroke
information inferred from the CPU scheduling statistics can
enhance our basic attack based on memory usage dynamics.
155
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:37 UTC from IEEE Xplore.  Restrictions apply. 
)
s
d
n
o
c
e
s
i
l
l
i
m
n
i
(
l
y
a
e
D
400
350
300
250
200
150
100
50
0
0
inter-keystroke
interval
5
10
15
20
25
30
35
40
Voluntary context switches
Figure 25. Context-switch delays (LIME in Android).
Consider two sites whose front pages have relatively
similar memprints: rediff.com (an Indian Web portal)
and plentyoffish.com (a popular dating site). Their
URLs require a different number of keystrokes (Table V),
enabling the attack process to disambiguate them if the user
types the URL directly into the Android browser.
INTER-KEYSTROKE TIMINGS IN MILLISECONDS: KEYLOGGER VS.
S T A T U S MEASUREMENTS (ANDROID BROWSER).
Table V
Timings
1
2
3
4
5
6
7
8
9
10
11
rediff
393
400
327
313
331
plentyoffish
True Measured True Measured
400
386
689
405
325
768
943
315
803
329
220
294
519
89
927
201
400
690
768
943
803
220
298
518
88
927
199
IX. DEFENSES
Changing the OS. Attacks described in this paper are not
speciﬁc to proc. Most operating systems reveal ﬁne-grained
accounting statistics about program execution. As long as
temporal changes in these statistics are correlated with the
program’s secrets, they can be used to infer the latter.
Even the blunt solution of removing the proc ﬁlesys-
tem entirely may not eliminate this class of attacks. For
example, proc is deprecated in FreeBSD, but memory
usage information is still available via utilities like ps
and top. An unprivileged attack process can run them
directly or use the same mechanism they use (e.g., call
156
kvm_getprocs) to measure memory usage of other users’
processes. For example, the attacker can execute ps -l -p
, which returns virtual set size (VSZ), equal to DRS
+ shared + code size. Code size is typically constant, thus
this immediately leaks the information needed for the attack.
Furthermore, changes to the proc ﬁlesystem may break
existing applications. Out of 30 applications from the An-
droid standard installation, 24 do not access proc, while
6 use /proc/self/cmdline to obtain their command-
line parameters. Therefore, removing memory usage in-
formation from proc on Android is unlikely to affect
existing applications. If OS designers cooperate, this may be
feasible defense—at the cost of breaking existing utilities.
Information about the program’s memory usage will still be
available through indirect channels, such as the size of swap
ﬁles, but these channels are more coarse-grained and likely
to reduce the efﬁcacy of the attack.
Some kernel-hardening patches7 remove the ability to
view processes outside of chroot even if /proc is
mounted, remove addresses from /proc/pid/stat (this
prevents the attack from [20]), or even restrict proc to show
only the user’s own processes (this breaks existing utilities).
Even if the attack process cannot view information about
other processes via proc, it can still exploit side channels
like the loading time of shared libraries and pid ordering,
as well as aggregate, system-wide information such as total
free memory, total context switches, etc. These channels are
signiﬁcantly coarser and noisier, but may still be correlated
with the secrets of the target application.
Changing the application. Without changes to the OS, an
application cannot prevent a concurrent attacker from mea-
suring its memory footprint and must modify its behavior
so that its memory usage is not correlated with its secrets.
Network-level defenses, such as browsing through proxies,
Tor, or SSL/TLS, do not provide much protection, nor does
browsing in “private” or “incognito” mode.
To reduce the correlation between the application’s be-
havior and OS-visible changes in its footprint, the allocator
should manage the application’s memory internally, without
exposing allocations and de-allocations to the OS. Imple-
menting programs in managed languages largely solves the
problem. We have not been able to stage our attack against
the Lobo browser implemented in Java.
Modern browser architectures such as Chrome and OP
create a new process for each tab or site instance, allowing
the attacker to easily match his footprint measurements
against the database of pre-computed signatures. As ex-
plained in Section V, mobile operating systems frequently
restart the browser process, which again beneﬁts the attacker.
In contrast, monolithic desktop browsers such as Firefox
reuse the same process for multiple sites. Matching a page
visited in a fresh Firefox is the same as for Chrome, but
7http://grsecurity.net/features.php
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:37 UTC from IEEE Xplore.  Restrictions apply. 
matching subsequently visited pages requires a different
matching algorithm that only looks at footprint deltas (i.e.,
how much it increased or decreased) and ignores the absolute
size. Recognition remains feasible, but its accuracy drops off
because pure-delta sequences are signiﬁcantly noisier.
In Section VI, we described a variation of the matching
algorithm that considers reductions in the footprint caused
by the browser de-allocating large images after rendering
them and returning the memory to the OS via unmap. This
variation works well even if the Firefox process is “dirty,”
regardless of the previously rendered pages.
Therefore, even returning to monolithic browser architec-
tures where the same rendering process is used for all pages
may not completely foil the attack.
X. CONCLUSION
Many modern systems leverage OS user and process
abstractions for security purposes—for example, to prevent
Android applications from snooping on each other. This has
unintended consequences because the OS reveals certain
accounting information about every process, including the
size of its memory footprint and CPU scheduling statistics.
It has been observed in other contexts [4] that even when a
single piece of information is harmless, how it changes over
time can leak secrets. In this paper, we demonstrated that
the pattern of changes in the browser’s memory footprint
uniquely identiﬁes thousands of webpages, allowing the
attacker (e.g., a malicious Android application or another
user on a shared workstation) to infer which pages the
victim is browsing, her relationship with websites, and
other private information. CPU scheduling statistics can be
used for keystroke snifﬁng and to improve accuracy of the
memory-footprint attack.
These attacks are a symptom of a bigger problem. Privacy
risks of system isolation mechanisms are poorly understood
and a worthy topic of further research.
Acknowledgments. We are grateful to Arvind Narayanan
for insightful comments on a draft of this paper, to Chad
Brubaker for pointing out that the attack is foiled by browser
add-ons that block ads and/or scripts, and to our shepherd
Simha Sethumadhavan for helping us improve and clarify
the presentation. The research described in this paper was
partially supported by the NSF grants CNS-0746888 and
CNS-0905602, Google research award, and the MURI pro-
gram under AFOSR Grant No. FA9550-08-1-0352.
REFERENCES
[1] D. Asonov and R. Agrawal. Keyboard acoustic ema-
nations. In S&P, 2004.
[2] M. Backes, M. D¨urmuth, and D. Unruh. Compromising
reﬂections - or - how to read LCD monitors around the
corner. In S&P, 2008.
[3] L. Cai and H. Chen. TouchLogger: Inferring keystrokes
on touch screen from smartphone motion. In HotSec,
2011.
[4] J. Calandrino, A. Kilzer, A. Narayanan, E. Felten, and
V. Shmatikov. ”You might also like:” Privacy risks of
collaborative ﬁltering. In S&P, 2011.
[5] S. Chen, R. Wang, X. Wang, and K. Zhang. Side-
channel leaks in Web applications: A reality today, a
challenge tomorrow. In S&P, 2010.
[6] G. Danezis. Trafﬁc analysis of the HTTP protocol over
http://research.microsoft.com/en-us/um/people/
TLS.
gdane/papers/TLSanon.pdf, 2010.
[7] J. Friedman. Tempest: A signal problem. NSA Cryp-
tologic Spectrum, 1972.
[8] C. Grier, S. Tang, and S. King. Secure Web browsing
with the OP Web browser. In S&P, 2008.
[9] M. Hogye, C. Hughes, J. Sarfaty, and J. Wolf. Analysis
of the feasibility of keystroke timing attacks over SSH
connections. Technical Report CS588, University of
Virginia, December 2001.
[10] A. Narayanan and V. Shmatikov.
Robust de-
anonymization of large sparse datasets. In S&P, 2008.
[11] M. Padlipsky, D. Snow, and D. Karger. Limitations
of end-to-end encryption in secure computer networks.
Technical Report ESD-TR-78-158, MITRE Corpora-
tion, August 1978.
[12] G. Peluso. Design your application to manage perfor-
mance data logs using the PDH library. http://www.
microsoft.com/msj/1299/pdh/pdh.aspx, 1999.
[13] S. Saponas, J. Lester, C. Hartung, S. Agarwal, and
T. Kohno. Devices that tell on you: Privacy trends in
consumer ubiquitous computing. In USENIX Security,
2007.
[14] R. Schlegel, K. Zhang, X. Zhou, M. Intwala, A. Ka-
padia, and X.Wang. Soundcomber: A stealthy and
context-aware sound trojan for smartphones. In NDSS,
2011.
[15] D. Song, D. Wagner, and X. Tian. Timing analysis
of keystrokes and timing attacks on SSH. In USENIX
Security, 2001.
[16] Q. Sun, D. Simon, Y-M. Wang, W. Russell, V. Pad-
manabhan, and L. Qiu. Statistical identiﬁcation of
encrypted Web browsing trafﬁc. In S&P, 2002.
[17] D. Tsafrir, Y. Etsion, and D. Feitelson.
Secretly
monopolizing the CPU without superuser privileges.
In USENIX Security, 2007.
[18] M. Vuagnoux and S. Pasini. Compromising electro-
magnetic emanations of wired and wireless keyboards.
In USENIX Security, 2009.
[19] C. Wright, L. Ballard, S. Coull, F. Monrose, and
G. Masson. Spot me if you can: Uncovering spoken
phrases in encrypted VOIP conversations.
In S&P,
2008.
[20] K. Zhang and X. Wang. Peeping Tom in the neighbor-
hood: Keystroke eavesdropping on multi-user systems.
In USENIX Security, 2009.
157
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:37 UTC from IEEE Xplore.  Restrictions apply.