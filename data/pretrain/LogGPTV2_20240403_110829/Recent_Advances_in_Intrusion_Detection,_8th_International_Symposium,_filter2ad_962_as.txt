The biggest obstacle for a hybrid system is the source of the feedback informa-
tion. Ideally, it should be automated and transparent to users. For example, the
feedback to email spam classiﬁers may be a user hitting a button in their email
client that notiﬁes the mail server to reconsider an inappropriately classiﬁed
email as spam. This feedback loop is an example of supervised online learning
and distributes the burden of supervision to users of the system. The feedback
mechanism in our system facilitates unsupervised online learning. The source
of information is based on an x86 emulator, STEM [29], that is augmented to
protect processes with Instruction Set Randomization.
1.2 Instruction Set Randomization
ISR is the process of creating a unique execution environment to eﬀectively
negate the success of code-injection attacks. This unique environment is created
by performing some reversible transformation on the instruction set; the trans-
formation is driven by a random key for each executable. The binary is then
decoded during runtime with the appropriate key.
84
M.E. Locasto et al.
Since an attacker crafts an exploit to match some expected execution environ-
ment (e.g. x86 machine instructions) and the attacker cannot easily reproduce
the transformation for his exploit code, the injected exploit code will most likely
be invalid for the specialized execution environment. The mismatch between the
language of the exploit code and the language of the execution environment
causes the exploit to fail. Without knowledge of the key, otherwise valid (from
the attacker’s point of view) machine instructions resolve to invalid opcodes or
eventually crash the program by accessing illegal memory addresses. Previous
approaches to ISR [3] [12] have proved successful in defeating code injection at-
tacks. Such techniques are typically combined with address-space obfuscation [4]
to prevent “jump into libc” attacks.
Randomizing an instruction set requires that the execution environment pos-
sess the ability to de-randomize or decode the binary instruction stream during
runtime. For machine code, this requirement means that either the processor
hardware must contain the decoding logic or that the processor be emulated in
software. STEM minimizes the cost of executing in software by selectively em-
ulating parts of an application. During the application’s runtime, control can
freely switch between the real and the virtual processors. By carefully selecting
the pieces of the application that are emulated, it is possible to minimize the
runtime overhead of the emulation.
This practical form of ISR allows us to capture injected code and correlate it
with input that has been classiﬁed as anomalous. Barrantes et al. [3] show that
code injection attacks against protected binaries fail within a few bytes (two or
three instructions) of control ﬂow switching to the injected code. Therefore, the
code pointed to by the instruction pointer at the time the program halts is (with
a high probability) malicious code. We can extract this code and send it to our
ﬁlter to create a new signature and update our classiﬁer’s model.
1.3 Contributions
The main contribution of this paper is a complete system that uses information
conﬁrming an attack to assist a classiﬁer and update a signature-based ﬁlter.
Filtering strategies are rarely based solely on anomaly detection; anomaly-based
classiﬁers usually have a high false positive rate. However, when combined with
feedback information conﬁrming an attack, the initial classiﬁcation provided by
the anomaly detector can assist in creating a signature. This signature can then
be deployed to the ﬁlter to block further malicious input. It is important to
note that our protection mechanism catches the exploit code itself. Having the
exploit code allows very precise signature creation and tuning of the classiﬁer.
Furthermore, this signature can be exchanged with other instances of this system
via a centralized trusted third party or a peer-to-peer network. Such information
exchange [7], [14] can potentially inoculate the network against a zero-day worm
attack [1], [13], [18], [35].
We present the design of FLIPS, a host-based application-level ﬁrewall that
adapts to new malicious input. Our prototype implementation adjusts its
FLIPS: Hybrid Adaptive Intrusion Prevention
85
ﬁltering capability based on feedback from two sources: (a) an anomaly-based
classiﬁer [38] that is specialized to the content ﬂows for a speciﬁc host and (b) a
binary supervision framework [29] that prevents code-injection attacks via ISR
and captures injected code. The details of our design are presented in Section 3,
and we describe the prototype implementation of the system for an HTTP server
in Section 4. We discuss related work in Section 2, our experimental validation
of FLIPS in Section 5, directions for future research in Section 6, and conclude
the paper in Section 7.
2 Related Work
Augmenting detection systems with an adaptive response mechanism is an emerg-
ing area of research. Intrusion prevention, the design and selection of mechanisms
to automatically respond to network attacks, has recently received an amount
of attention that rivals its equally diﬃcult sibling intrusion detection. Response
systems vary from the low–tech (manually shut down misbehaving machines)
to the highly ambitious (on the ﬂy “vaccination”, validation, and replacement
of infected software). In the middle lies a wide variety of practical techniques,
promising technology, and nascent research.
The system proposed by Anagnostakis et al. [2] has many of the same goals
as FLIPS. However, there are a number of diﬀerences in architecture and imple-
mentation. Most importantly, our use of ISR allows FLIPS to detect and stop all
instances of code injection attacks, not just stack-based buﬀer overﬂows. Also,
FLIPS is meant to protect a single host without the need for a “shadow.”
Two other closely related systems are the network worm vaccine architecture
[28] and the HACQIT system [25]. More recently, researchers have investigated
transparently detecting malicious email attachments [27] with techniques similar
to ours and [28]. HACQIT employs a pair of servers in which the outputs of the
primary and secondary server are compared. If the outputs are diﬀerent, then a
failure has occurred. The HACQIT system then attempts to classify the input
that caused this error and generalize a rule for blocking it. The network and
email worm vaccine architectures propose the use of honeypot and auxiliary
servers, respectively, to provide supervised environments where malware can
infect instrumented instances of an application. The system can then construct
a ﬁx based on the observed infection vector and deploy the ﬁx to the production
server. In the case of the email worm vaccine, the email can be silently dropped,
stripped of the attachment, or rejected.
In contrast, FLIPS is meant to protect a single host without the need for
additional infrastructure. Since the system is modular, it is an implementation
choice whether or not to distribute the components across multiple machines.
FLIPS also precisely identiﬁes attack code by employing ISR. It does not need to
correlate input strings against other services or try to deduce where attack code
is placed inside a particular input request. In addition, our anomaly detection
component can construct models of both good and “bad” inputs to detect and
block slight variants of malicious input.
86
M.E. Locasto et al.
2.1 Code Injection and ISR
One of the major contributions of this work is the use of a practical form of ISR.
The basic premise of ISR [3] [12] is to prevent code injection attacks [23] from
succeeding by creating unique execution environments for individual processes.
Code injection is not limited to overﬂowing stack buﬀers or format strings. Other
injection vectors include web forms that allow arbitrary SQL expressions (a
solution to this problem using SQL randomization is proposed in [5]), CGI scripts
that invoke shell programs based on user input, and log ﬁles containing character
sequences capable of corrupting the terminal display.
Our x86 emulator STEM can selectively derandomize portions of an instruc-
tion stream, eﬀectively supporting two diﬀerent instruction sets at the same time.
Various processors support the ability to emulate or execute other instruction
sets. These abilities could conceivably be leveraged to provide hardware support
for ISR. For example, the Transmeta Crusoe chip1 employs a software layer for
interpreting code into its native instruction format. The PowerPC chip employs
“Mixed-Mode” execution2 for supporting the Motorola 68k instruction set. Like-
wise, the ARM chip can switch freely between executing its regular instruction
set and executing the Thumb instruction set. A processor that supports ISR
could use a similar capability to switch between executing regular machine in-
structions and randomized machine instructions. In fact, this is almost exactly
what STEM does in software. Having hardware support for ISR would obviate
the need for (along with the performance impact of) software-level ISR.
2.2 Anomaly Detection and Remediation
Anomaly-based classiﬁcation is a powerful method of detecting inputs that are
probably malicious. This conclusion is based on the assumption that malicious
inputs are rare in the normal operation of the system. However, since a sys-
tem can evolve over time, it is also likely that new non-malicious inputs will
be seen [9] [32]. Indeed, some work [16] has shown that it is possible to evade
anomaly-based classiﬁers. Therefore, anomaly-based detectors [38] [17] require
an additional source of information that can conﬁrm or reject the initial classiﬁ-
cation. Pietraszek [22] presents a method that uses supervised machine learning
to tune an alert classiﬁcation system based on observations of a human expert.
Sommer and Paxon [33] explore a related problem: how to augment signature-
based NIDS to make use of context when applying signatures.
FLIPS receives feedback from an emulator that monitors the execution of a
vulnerable application. If the emulator tries to execute injected code, it catches
the fault and notiﬁes the classiﬁer and ﬁlter. It can then terminate and restart
the process, or simulate an error return from the current function. While our
prototype system employs ISR, there are many other types of program super-
vision that can provide useful information. Each could be employed in parallel to
1
2
http://www.transmeta.com/crusoe/codemorphing.html
http://developer.apple.com/documentation/mac/runtimehtml/RTArch-75.html
FLIPS: Hybrid Adaptive Intrusion Prevention
87
gather as much information as possible. These approaches include input taint
tracking [36] [20], program shepherding [15], (a similar technique is proposed
in [24]) and compiler-inserted checks [31]. One advantage of FLIPS’s feedback
mechanism is that it can identify with high conﬁdence the binary code of the
attack. In an interesting approach to detection, Toth and Kruegel [37] and Stig
et al. [34]) consider the problem of ﬁnding x86 code in network packets.
Eﬀective remediation strategies remain a challenge. The typical response of
protection mechanisms has traditionally been to terminate the attacked pro-
cess. This approach is unappealing for a variety of reasons; to wit, the loss of
accumlated state is an overarching concern. Several other approaches are pos-
sible, including failure oblivious computing [26], STEM’s error virtualization
[29], DIRA’s rollback of memory updates [31], crash-only software [6], and data
structure repair [8]. Remediation strategies sometimes include the deployment
of ﬁrewall rules that block malicious input. The most common form of this strat-
egy is based on dropping packets from “malicious” hosts. Even with whitelists
to counter spooﬁng, this strategy is too coarse a mechanism. Our system allows
for the generation of very precise signatures because the actual exploit code can
be caught “in the act.”
Automatically creating reliable signatures of zero-day exploits is the focus of
intense research eﬀorts [13]. Signatures of viruses and other malware are cur-
rently produced by manual inspection of the malware source code. Involving
humans in the response loop dramatically lengthens response time and does
nothing to stop the initial infection. In addition, deployed signatures and IDS
rules do nothing to guard against new threats. Singh et al. describe the Early-
bird system for automatically generating worm signatures and provide a good
overview of the shortcomings of current approaches to signature generation [30].
3 FLIPS – A Learning Application Filter
While we describe our implementation of FLIPS in Section 4, this section pro-
vides an overview of the design space for a host-based intrusion prevention sys-
tem. The system is composed of a number of modules that provide ﬁltering,
classiﬁcation, supervision, and remediation services. We can use the metrics pro-
posed by Smirnov and Chiueh [31] to classify FLIPS: it detects attacks, identiﬁes
the attack vector, and provides an automatic repair mechanism.
The goal of the system is to provide a modular and compact application-
level ﬁrewall with the ability to automatically learn and drop conﬁrmed zero-
day attacks. In addition, the system should be able to generate zero-day worm
and attack signatures, even for slightly metamorphic attack input. We tune
the anomaly detection by catching code injection attacks with our supervision
component. Only attacks that actually inject and execute code are conﬁrmed
as malicious and fed back to the anomaly detector and ﬁlter. As a result, only
conﬁrmed attacks are dropped in the future.
88
M.E. Locasto et al.
3.1 FLIPS Design
The design of FLIPS is based on two major components: a ﬁltering proxy and an
application supervision framework. A major goal of the design is to keep the sys-
tem modular and deployable on a single host. Figure 1 shows a high-level view of
this design. The protected application can be either a server waiting for requests
or a client program receiving input. Input to a client program or requests to a
server are passed through the ﬁltering proxy and dropped if deemed malicious.
If the supervision framework detects something wrong with the protected appli-
cation, it signals the ﬁlter to update its signatures and models. Although server
replies and outgoing client traﬃc can also be modeled and ﬁltered, our current
implementation does not perform this extra step. Outgoing ﬁltering is useful in
protecting a client application by stopping information leaks or the spread of
self-propagating malware.
The function of the proxy is to grade or score the input and optionally drop
it. The proxy is a hybrid of the two major classiﬁcation schemes, and its subcom-
ponents reﬂect this dichotomy. A chain of signature-based ﬁlters can score and
drop a request if it matches known malicious data, and a chain of anomaly-based
classiﬁers can score and drop the input if it is outside the normal model. Either
chain can allow the request to pass even if it is anomalous or matches previous
malicious input. The default policy for our prototype implementation is to only
drop requests that match a signature ﬁlter. Requests that the anomaly classiﬁer
deems suspicious are copied to a cache and forwarded on to the application.
We adopt this stance to avoid dropping requests that the anomaly component
mislabels (false positives). The current implementation only drops requests that
Input
source
Proxy
Signature
filter
&
classifier
chain
Anomaly
&
filter
classifier
chain
firewall
Protected
Application
Supervision
framework &
feedback source
Fig. 1. General Architecture of FLIPS. Requests are passed through a ﬁltering proxy
and dropped if deemed malicious. The application should be protected by a packet
ﬁltering ﬁrewall that only allows the local proxy instance to contact the application.
The application processes the requests and sends the response back through the proxy.
If the input causes a code injection attack, the supervision framework contacts the
proxy with the injected code and the proxy updates its models and signatures.
FLIPS: Hybrid Adaptive Intrusion Prevention
89
have been conﬁrmed to be malicious to the protected application and requests
that are closely related to such inputs.
The function of the application supervision framework is to provide a way
to stop an exploit, automatically repair the exploited vulnerability, and report
information about an exploit back to the ﬁlters and classiﬁers. Similar to the
ﬁltering and classiﬁcation chains, the supervision framework could include a
number of host-based monitors to provide a wide array of complementary feed-
back information to the proxy. Our prototype implementation is based on one
type of monitor (ISR) and will only provide feedback information related to
code-injection attacks. Many other types of attacks are possible, and whether
something is an attack or not often depends on context. FLIPS’s design allows for
an array of more complicated monitors. STEM allows the application to recover
from a code injection attack by simulating an error return from the emulated
function after notifying the proxy about the injected code.
3.2 Threat Model
In this work, we assume a threat model that closely matches that of previous
ISR eﬀorts. Speciﬁcally, we assume that an attacker does not have access to the
randomized binary or the key used to eﬀect achieve this randomization. These
objects are usually stored on a system’s disk or in system memory; we assume the
attacker does not have local access to these resources. In addition, the attacker’s
intent is to inject code into a running process and thereby gain control over the
process by virtue of the injected instructions. ISR is especially eﬀective against
these types of threats because it interferes with an attacker’s ability to automate
the attack. The entire target population executes binaries encoded under keys
unique to each instance. A successful breach on one machine does not weaken
the security of other target hosts.
3.3 Caveats and Limitations
While the design of FLIPS is quite ﬂexible, the nature of host-based protec-
tion and our choices for a prototype implementation impose several limitations.
First, host-based protection mechanisms are thought to be diﬃcult to manage
because of the potential scale of large deployments. Outside the enterprise en-
vironment, home users are unlikely to have the technical skill to monitor and
patch a complicated system. We purposefully designed FLIPS to require little
management beyond installation and initial training. PayL can perform unsu-
pervised training. One task that should be performed during system installation
is the addition of a ﬁrewall rule that redirects traﬃc aimed at the protected
application to the proxy and only allows the proxy to contact the protected
application.
Second, the performance of such a system is an important consideration in
deployment. We show in Section 5 that the beneﬁt of automatic protection and
repair (as well as generation of zero-day signatures) is worth the performance
impact of the system. If the cost is deemed too high, the system can still be
90
M.E. Locasto et al.
deployed as a honeypot or a “twin system” that receives a copy of input meant
for another host. Third, the proxy should be as simple as possible to promote
conﬁdence in its codebase that it is not susceptible to the same exploits as the
protected application. We implement our proxy in Java, a type-safe language
that is not vulnerable to the same set of binary code injection attacks as a C
program. Our current implementation only considers HTTP request lines. Specif-
ically, it does not train or detect on headers or HTTP entity bodies. Therefore,
it only protects against binary code injection attacks contained in the request
line. However, nothing prevents the scope of training and detecting from being
expanded, and other types of attacks can be detected at the host.
4 Implementation
This section deals with the construction of our prototype implementation. The
proxy was written in Java and includes PayL (400 lines of code) and a simple
HTTP proxy that incorporates the signature matching ﬁlter (about 5000 lines
of code). The supervision framework is provided by STEM (about 19000 lines
of C code). One advantage of writing the proxy in Java is that it provides an
implicit level of diversity for the system. The small codebase of PayL and the
proxy allows for easy auditing.