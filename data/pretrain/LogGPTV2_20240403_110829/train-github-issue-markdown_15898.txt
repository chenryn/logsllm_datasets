 **Is this a request for help?** (If yes, you should use our troubleshooting
guide and community support channels, see
http://kubernetes.io/docs/troubleshooting/.):
No
**What keywords did you search in Kubernetes issues before filing this one?**
(If you have found any duplicates, you should instead reply there.):
controller key, duplicate certificates, controller rekey
* * *
**Is this a BUG REPORT or FEATURE REQUEST?** (choose one):
bug report
**Kubernetes version** (use `kubectl version`):
Client Version: version.Info{Major:"1", Minor:"4", GitVersion:"v1.4.3",
GitCommit:"4957b090e9a4f6a68b4a40375408fdc74a212260", GitTreeState:"clean",
BuildDate:"2016-10-16T06:36:33Z", GoVersion:"go1.6.3", Compiler:"gc",
Platform:"linux/amd64"}  
Server Version: version.Info{Major:"1", Minor:"4", GitVersion:"v1.4.3",
GitCommit:"4957b090e9a4f6a68b4a40375408fdc74a212260", GitTreeState:"clean",
BuildDate:"2016-10-16T06:20:04Z", GoVersion:"go1.6.3", Compiler:"gc",
Platform:"linux/amd64"}
**Environment** :
  * **Cloud provider or hardware configuration** : self-hosted VM
  * **OS** (e.g. from /etc/os-release): Ubuntu 14.04.05
  * **Kernel** (e.g. `uname -a`): 4.4.0-45
  * **Install tools** : Manual installation
  * **Others** :
**What happened** :
I generated an independent cert+key for each of my two controllers. Pods
(especially kube-dns) had a high failure rate in talking to the apiserver.
This showed up as 401 status in the apiserver log, and "the server requested
the client to provide authenticate" in the pod kubedns log.
**What you expected to happen** :
I expected it to work. :)
**How to reproduce it** (as minimally and precisely as possible):
  1. Generate a different certificate and key for each controller machine (apiserver, controller manager, scheduler).
  2. Load kube-dns.
**Anything else do we need to know** :
In many places, standard practice is to issue an independent certificate for
each server. If Kubernetes doesn't support that configuration, it should be
documented.