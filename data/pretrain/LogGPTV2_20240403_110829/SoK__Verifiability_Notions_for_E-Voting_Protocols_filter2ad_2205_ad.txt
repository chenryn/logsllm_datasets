metric).
Vi /∈Vcast
nated)
(iii-b). ⊥ ← Extr(τ ,{αi}Vi∈Vcast
)
Fig. 1: E2E-veriﬁability by Kiayias et al.
follow the protocol honestly. For these voters and those in
Vcast the extractor could not determine their votes, and hence,
it would be very likely that the adversary wins the game in
Figure 1: if the extractor outputs votes, then it would be very
likely that Condition (iii-a) is satisﬁed, and otherwise Condition
(iii-b) would be satisﬁed.
This problem can be ﬁxed by providing the extractor with
the votes of the voters in Vcast, not only with their receipts.
In this case, the extractor could simply compute Result(τ )
Vi /∈Vcast such that d1(Result(τ ), ρ(c1, . . . , cn)) is
and choose (ci)
minimal. This would be the best extractor, i.e., the one that
makes it the hardest for the adversary to win the game. Note
that this extractor does not have to actually extract votes from
τ, or even look closely at τ, except for computing Result(τ ).
Conditions (iii-a) and (iii-b) could therefore be replaced by
the following one:
(iii)* For any combination of choices (ci)
Vi /∈Vcast :
d1(Result(τ ), ρ(c1, . . . , cn)) ≥ k.
This is then similar to Deﬁnition 2 where votes of dishonest
voters are quantiﬁed existentially. (Note that (iii)* talks about
when veriﬁability is broken, while Deﬁnition 2 talks about the
goal, i.e., what veriﬁability should achieve, hence the switch
from existential quantiﬁcation in Deﬁnition 2 to universal
quantiﬁcation in (iii)*). As explained in Section IV,
the
existential quantiﬁcation is very reasonable because, for several
reasons, it is often not possible to extract votes of dishonest
voters.
785785
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:36 UTC from IEEE Xplore.  Restrictions apply. 
Our second observation is that the deﬁnition (even the
version with the ﬁx above) is too weak in the following sense.
Consider runs where honest voters cast their votes successfully,
and hence, obtain a receipt, but do not verify their receipt, and
where the veriﬁcation would even fail. Because of Condition
(ii), the adversary would right away loose the game in these
runs. However, these runs are realistic threats (since often voters
do not verify), and hence, guarantees should be given even for
such runs. The game in Figure 1 simply discards such runs.
Therefore, instead of Condition (ii) one should simply require
that the judge (looking at τ and waiting for complaints from
voters, if any) accepts the run. Note that if the judge does not
accept the run, then the election is invalid.
D. Casting in the KTV Framework
Protocol PKZZ. The set of agents Σ consists of the voters,
the bulletin board B, the voting authority EA, the judge J, the
tellers T1, . . . , Tm and the remaining participants.
When a voter V runs her honest program πV in the casting
phase, she expects a choice c, a credential and the public
parameters of the election (if her input is empty, she stops).
Then, she runs Cast in interaction with B, and expects a receipt
α (if she does not receive a receipt, she stops). When the voter
is triggered by the judge in the veriﬁcation phase, the voter
reads the election transcript τ from the bulletin board B (if she
does not receive τ, she outputs ”reject”) and runs Verify(τ , α).
If Verify(τ , α) evaluates to ”false” or ”true”, respectively, she
sends ”reject” or ”accept” to the judge J. The deﬁnition of
Kiayias et al. is not explicit about whether voters always verify
when triggered or not. So here one could also model that
they decide whether they verify according to some probability
distribution.
When a teller T runs its honest program πT in the setup
phase, it interacts with the remaining tellers, the EA and B.
It expects as output its secret state st (otherwise, it stops). In
the tally phase, on input st and the contents of B (if any input
is empty, it stops), it runs Tally in interaction with B and EA,
and outputs a partial tally ta that is sent to EA.
When the election authority EA runs its honest program
πEA, it expects a security parameter 1(cid:5) in the setup phase (if the
input is empty, it stops). Then, it runs Setup in interaction with
B and the tellers, and outputs the election parameters, which are
published in B, and the voters’ credentials (cred1, . . . , credn),
which are sent to the corresponding voters (V1, . . . , Vn). In the
tally phase, EA runs Tally in interaction with B and the tellers,
and publishes the partial tally data ta1, . . . ,tam produced by
each teller at the end of the interaction.
When the judge J runs its honest program πJ and is triggered
in the veriﬁcation phase, it reads the election transcript τ. It
performs whatever check prescribed by the protocol. If one of
these checks fails, J outputs “reject”. Otherwise, J iteratively
triggers all voters and asks about their veriﬁcation results
(if any). If one of the voters rejects, J outputs “reject”, and
otherwise, “accept”.
E2E veriﬁability. We deﬁne the goal γθ,k,Extr, which is
parameterized by θ, k, and Extr as in Figure 1, to be the
set of runs of PKZZ (with some adversary A) such that at least
one of the Conditions (i), (ii), (iii-a) or (iii-b) in Figure 1 is
not satisﬁed. With this, Deﬁnition 4, corresponds to the notion
of (γθ,k,Extr, δ)-veriﬁability according to Deﬁnition 1 when the
same extractors are used and one quantiﬁes over the same set
of adversaries.
As already discussed above, this deﬁnition on the one hand
is too speciﬁc (due to the use of the extractor) and on the other
hand too weak (due to Condition (ii)). Therefore, as mentioned,
the deﬁnition would be improved if Conditions (iii-a) and (iii-b)
were replaced by (iii)* and Condition (ii) was replaced by the
condition that the judge accepts the run. If one set θ = 0 in
addition, then Deﬁnition 4 would closely resemble γk from
Deﬁnition 2.
VII. COMPUTATIONAL ELECTION VERIFIABILITY BY
CORTIER ET AL.
In this section, we study the deﬁnition of veriﬁability by
Cortier et al. [19], which can be seen as an extension of a
previous veriﬁability deﬁnition by Catalano et al. [32], whereby
the bulletin board may act maliciously, and thus it could
potentially perform ballot stufﬁng (i.e. stuff itself with self-
made ballots on behalf of voters who did not vote) or erase
ballots previously cast by voters.
A. Model
Cortier et al. [19] model an e-voting scheme Π as a
tuple (Setup, Credential, Vote, VerifyVote, Valid, Board, Tally,
Verify) of ppt algorithms where VerifyVote and Verify are
non-interactive. The entities are the registrar Reg, the bulletin
board B, the teller T and the voters. The algorithm Setup((cid:5))
is run by the teller T, and outputs the public parameters of the
election prmpub and the secret tallying key sk. The procedure
Credential is run by Reg with the identity idi of voter Vi,
and outputs a public/secret credential pair (upki, uski). The
algorithms discussed next implicitly take prmpub as input. The
algorithm Vote is run interactively between B and a voter Vi, on
inputs prmpub, a choice ci and her credentials (upki, uski). Upon
successful termination, a ballot bi is appended to the public
transcript τ of the election. The procedure Valid(b) outputs 1
or 0 depending on whether b is well-formed. Board denotes the
algorithm that B must run to update τ. The algorithm Tally is
run at the end of the election by T, given the content of B and
the secret key sk as input, and outputs tallying proofs P and
the ﬁnal election result Result. VerifyVote(τ , upki, uski, b) is an
algorithm run by voter Vi that checks whether ballot b appears
in τ. The algorithm Verify(τ , Result, P) denotes the veriﬁcation
of the result of the election, while VerifyVote(τ , upki, bi)
denotes the veriﬁcation that ballot bi from voter Vi was included
in the ﬁnal transcript of the election as published by B.
B. Veriﬁability Against Malicious Bulletin Board
In the e-voting system Helios [6], a dishonest bulletin board
B may add ballots, since it is the sole entity checking the
eligibility of voters. If B is corrupted, then it might stuff the
ballot box with ballots on behalf of voters that in fact did
not vote. This problem, as already mentioned in Section IV-B,
is called ballot stufﬁng. The work in [19] gives a deﬁnition
of veriﬁability in the computational model to account for a
malicious bulletin board. To defend voters against a dishonest
B, a registration authority Reg is required. Depending on
whether both B and Reg are required to be honest, [19] deﬁnes
weak veriﬁability (both are honest) or strong veriﬁability (not
simultaneously dishonest).
In Figure 2 we give a snapshot of the cryptographic game
used in [19] to deﬁne veriﬁability in case B is dishonest. The
adversary has oracles to register voters, corrupt voters, and
786786
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:36 UTC from IEEE Xplore.  Restrictions apply. 
Experiment Expverb
A,Π
creates voters’
Adversary A has access to the following oracles:
• Oreg(id):
credentials via
(upkid, uskid)←Credential(id), stores them as
U = U ∪{(id, upkid, uskid)}, and returns upkid
to the attacker.
• Ocorrupt(id): ﬁrstly, checks if an entry (i,∗,∗)
appears in U ;
if not, stops. Else, gives
(upkid, uskid) to A, updates a list of corrupted
voters C U = C U ∪{(i, upkid)} and updates the
list of honest cast ballots HVote by removing
any occurrence (id,∗,∗).
• Ovote(id, c): if (i,∗,∗) /∈ U , or (i,∗) ∈ C U ,
aborts; else returns b = Vote(i, upkid, uskid, c)
and replaces any previous entry (id,∗,∗) in
HVote with (i, c,b). The latter list is used to
record the voter’s intention.
Let Checked ⊆ HVote contain those id’s who checked
that their ballot appears in τ at the end of the election.
The experiment outputs a bit as follows, with 1
meaning that the attacker was successful:
(1) (τ , Result, P)←AOreg,Ocorrupt,Ovote
(2) if Verify(τ , Result, P) = 0 return 0
(3) if Result =⊥ return 0
(4) if ∃ (iA
,∗), . . . , (iA
, cA
nA
1
1
∈ C s.t. 0 ≤ nB ≤ |C U | s.t.
∃ cB
, . . . , cB
(cid:5)
(cid:4){cE
nB
(cid:12)R ρ
Result = ρ
,∗) ∈ HVote\Checked
(cid:4){cB
(cid:4){cA
, cA
nA
(cid:12)R ρ
(cid:5)
1
}nA
i=1
i
i
i
}nE
i=1
return 0 else return 1
, cE
1
1
(cid:5)
}nB
i=1
where Checked = {(iE
Fig. 2: Veriﬁability against bulletin board by Cortier et al. [19]
), . . . , (iE
nE
,bE
nE
, cE
nE
,bE
1
)}
A,Π) = Pr[Expverb
let honest voters vote. The condition for winning the game
is explained below. Note that Cortier et al. assume that the
result function admits partial counting, namely ρ(S1 ∪ S2) =
ρ(S1) (cid:12)R ρ(S2) for any two lists S1,S2 containing sequences of
elements c ∈ C and where (cid:12)R : R× R → R is a commutative
operation. For example, the standard result function that counts
the number of votes per candidate admits partial counting.
Deﬁnition 5 (Veriﬁability against malicious bulletin board).
An election scheme achieves veriﬁability against the bulletin
board if the success rate Succ(Expverb
A,Π((cid:5)) = 1] of
any ppt adversary A is negligible as a function of (cid:5), where
Expverb
A,Π is deﬁned as in Figure 2.
Roughly speaking, this deﬁnition declares a protocol veriﬁ-
able if, in the presence of a malicious bulletin board (which
can erase previous cast ballots and/or cast ballots on behalf
of absentee voters), voters who check that their ballot has not
been removed are guaranteed that their choice has been counted
in the ﬁnal result. Also some of the votes of honest voters
who did not check might also be contained in the ﬁnal result.
However, their votes may as well have been dropped (but not
altered to other votes). Voters under adversarial control can
only vote once, with choices belonging to the choice space.
The bulletin board cannot stuff itself with additional ballots
without getting caught.
Experiment Expverg
A,Π
Adversary A has access to the oracle Ovote, Ocorrupt
as before, and additionally Ocast, that allows A to
cast ballots to B on behalf of corrupted voters, as
follows:
• Ocast(id, b): run Board(τ , b).
Let HVote and Checked be the lists deﬁned before.
that HVote contains entries of the form
Recall
(id, c, b), that stand for honest voters’ choices. The
experiment outputs a bit as follows:
(1) (Result, P)←AOcast,Ocorrupt,Ovote
(2) if Verify(τ , Result, P) = 0 return 0