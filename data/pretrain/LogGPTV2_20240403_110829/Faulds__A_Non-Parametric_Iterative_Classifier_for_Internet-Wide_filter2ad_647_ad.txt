i
π t
iv (u (cid:3)
jv ),
β t
i j := p(ωi |u(cid:3)
j , θt
u , α t ) =
v =1
pt
i jn
i =1
.
pt
i j
(20)
(21)
Table 7: User Features of Database D3
OS
Linux
Windows
Novell
Win
5, 792
16,384
6, 144
OPT
TTL DF
1
0 MNWNNTNNS
1
64
128
128
MNWSNN
MSTNW
MSS
1, 460
1, 380
1, 460
The next result follows from substitution of (20)-(21) into (3)
and (19), as well as earlier proofs of Theorems 3.1 and 4.1.
Theorem 5.1. Under user distortion, estimators (3) and (19) can
be written as
α t +1
i
=
π t +1
iv (y) =
m
1
m
j =1
m
j =1
β t
i j ,
jv =y
β t
i j 1u (cid:3)
mα t +1
i
(22)
(23)
.
Furthermore, this is the EM algorithm for (θu , α ).
5.3 Discussion
To evaluate the result of Theorem 5.1, we construct a new database
D3, shown in Table 7, by switching from RTOs to user features.
Note that this Linux signature ties Novell in DF and MSS, while
Windows does the same in TTL. For simplicity of presentation, we
use simulation scenarios with ϕiv = ϕv for all i, where ϕv is the
probability with which feature v stays at the default value. This re-
places matrix ϕiv with a vector ϕv , which is easier to follow across
the different tables.
The initial PMFs π 0
iv of EM are set up to include 90% of the
mass on the default value and split the remainder uniformly across
the viable alternatives. Since it is believed [42] that the order of
non-NOP options cannot be changed without rewriting the TCP/IP
stack of the OS, we initialize π 0
i 4 to allow only candidates compat-
ible with the original ui 4. For example, MST is feasible for Linux,
but not the other two signatures in Table 7. Note that any single
option (M, S, W) and the empty set are valid for all three OSes.
We use two models for generating noisy observations. The first
one, which we call RAND, picks uniformly from the space of pos-
sible values observed in our Internet scan, except OPT is limited
to compatible subsets/supersets of the original. We have 5,695 can-
didates for Win, four for TTL, two for DF, 266 for OPT, and 1,082
for MSS. Decisions are made independently for each feature v and
each observation j, which models users “tweaking" their OS with-
out coordinating with each other or sharing a common objective.
Even though RAND can generate 13.1 billion unique combinations
u(cid:3)
j , only a small subset is encountered by the classifier in our sim-
ulations below.
The second model, which we call PATCH, selects an alternative
vector of features u(cid:3)(cid:3)
i for each OS ωi and switches the default value
uiv to u (cid:3)(cid:3)
iv with probability 1 − ϕv , again independently for each v.
This represents deployment of software patches that change one of
the features to an updated value. The probability for a host to use
multiple patches is the product of corresponding (1 − ϕv )’s. For
example, modification to both Win and OPT affects (1 − ϕ1)(1 −
ϕ4) fraction of hosts. Vectors u(cid:3)(cid:3)
i are non-adversarial and do not
attempt to confuse the classifier. We construct them by flipping
Session D5:  Network SecurityCCS’17, October 30-November 3, 2017, Dallas, TX, USA977Table 8: Patched User Features
Table 11: Handling of RST Packets
Vector Win
5, 793
16, 386
6, 147
u(cid:3)(cid:3)
1
u(cid:3)(cid:3)
2
u(cid:3)(cid:3)
3
TTL DF OPT MSS
1, 461
128
1, 382
32
1, 463
64
M
M
M
0
1
0
Table 9: Parameters of Scenario S3
Feature stay prob ϕv
Case Model
S31
(0.3, 0.2, 0.5, 0.4, 0.4)
RAND
S32
(0.0, 0.0, 0.1, 0.2, 0.0)
RAND
S33
PATCH (0.2, 0.2, 0.2, 0.2, 0.2)
Popularity α
(0.90, 0.05, 0.05)
(0.90, 0.05, 0.05)
(0.7, 0.2, 0.1)
Table 10: Classification Results in D3
Case Hershel+
ρ 1
0.76
0.29
0.31
S31
S32
S33
ρ 1
0.79
0.32
0.50
ρ ∞
0.96
0.91
1
EM
ϕ ∞
v
(0.30, 0.20, 0.50, 0.40, 0.40)
(0.00, 0.00, 0.10, 0.20, 0.00)
(0.20, 0.20, 0.20, 0.20, 0.20)
n
the DF flag, setting OPT to M, and adding i to all remaining fields
(modulo the max field value). The result is given in Table 8.
To estimate vector ϕt
v =
i =1
v in the classifier, we use a weighted aver-
age of feature non-modification across all OSes, i.e., ϕt
α t
i
ϕt
iv . Our next scenario S3 is detailed in Table 9 and the correspond-
ing outcome is given by Table 10. We omit vector α ∞
since it matches
ground-truth α very accurately. Due to the new treatment of non-
default features in (18), the first iteration of EM in Table 10 is su-
perior to Hershel+. However, both are much worse than the last
iteration. It should be noted that the second case S32 modifies Win,
TTL, and MSS in 100% of the samples. Identifiability in such con-
ditions is helped by the fact that OPT is constrained to a subset
of the original string, which makes a certain fraction of randomly
generated values feasible for only one OS. This allows EM to learn
to ignore (Win, TTL, MSS) and focus decisions on (DF, OPT). Fur-
thermore, when guessing is involved, EM uses its knowledge of α
to correctly pick the most-likely OS. It is also interesting that S33
is classified with 100% accuracy once EM gets a grasp on the new
values in Table 8 and their probability of occurrence.
6 COMPLETE SYSTEM
6.1 Reset Packets
Because loss of RST packets causes the corresponding user features
(i.e., ACK/RST flags, ACK sequence number, window size [42]) to
be wiped out, there is dependency between distortion applied by
the network and the user. As a result, this case should be handled
separately. The first modification needed is to increase the length
of network vectors di and d(cid:3)
j to accommodate the RST timestamp.
The second change is to add RST values into user features. Since
it is currently believed that RST fields are unmodifiable indepen-
dently of each other [42], they can be combined into a single inte-
ger and appended to user vectors ui and u(cid:3)
j in position b + 1.
There are four possible scenarios for handling RST packets. They
i j that must
are shown in Table 11, each with a certain probability ζ t
RST present
di
yes
no
yes
no
d(cid:3)
j
yes
yes
no
no
Action
Multiplier ζ t
i j
–
ignore RST in d(cid:3)
j
π t
π t
(u(cid:3)
(u(cid:3)
i ,b +1
j ,b +1
i ,b +1
j ,b +1
)
)
–
–
1
1
be factored into the formulas developed earlier. When both the ob-
servation and candidate signature contain a RST, the only multi-
plier needed is the probability that the received feature was pro-
duced by that OS. If the sampled OS has a RST, but the signature
does not, this indicates a possible interference from an interme-
diate device (e.g., IDS after expiring connection state, scrubbers).
In this case, it is likely meaningless to use the temporal character-
istics of the RST, which is why we omit it from d(cid:3)
j before com-
puting the loss and delay probabilities. However, multiplication
by π t
) is still warranted since we must assign a proper
weight to this mismatch. The third row of the table corresponds
to packet loss, which is handled automatically in pt
i (γ ), i.e., no ad-
ditional actions or multipliers are needed. Finally, the last row is
identical to the setup assumed in preceding sections.
(uj,b +1
i,b +1
6.2 Final Model
We now combine the developed network, user, and RST models
into a single framework. Redefining (12) as
pt
i jτ γ = α t
i ζ t
i j
π t
iv (u (cid:3)
jv )
(cid:7) b
v =1
(cid:8)
f t
T (τ )pt
i (γ )
|d(cid:3)
j |
r =1
f t
Δ
(δi jτ γ r )
(24)
allows us to compute β t
However, (23) requires an update to
i jτ γ still via (13), as well as reuse (14)-(17).
m
1u jv =y
j =1

τ γ β t
i jτ γ
π t +1
iv (y) =
,
(25)
mα t +1
i

where v = 1, 2, . . . , b + 1. The final classifier, which we call Faulds1,
is applied after EM has converged and is given by
p(ωi |x(cid:3)
j , θ ∞, α ∞) =
β ∞
i jτ γ .
(26)
τ γ
It is easy to generalize our earlier results to cover the complete
model, as given in the next theorem without proof.
Theorem 6.1. Under both network and user distortion, estimator
(13)-(17), (24)-(25) is the EM algorithm for (θ, α ).
6.3 Scaling the Database
Due to the large number of features it combines, Faulds is not chal-
lenged by the previous toy databases. We therefore switch to a
more realistic set of signatures created by Plata in [41]. We call
this database D4 and note that it contains 420 stacks, among which
some have the same exact RTO vector and others overlap in all
1Henry Faulds was a Scottish scientist who extended the ideas of William Herschel
and proposed the first usable forensic fingerprint-identification method in 1880.
Session D5:  Network SecurityCCS’17, October 30-November 3, 2017, Dallas, TX, USA978l
s
e
p
m
a
s
f
o
n
o
i
t
c
a
r
f
100
10-1
10-2
10-3
10-4
100
actual
estimated
101
rank of OS
102
(a) Faulds α
l
s
e
p
m
a
s
f
o
n
o
i
t
c
a
r
f