title:Identifying Dormant Functionality in Malware Programs
author:Paolo Milani Comparetti and
Guido Salvaneschi and
Engin Kirda and
Clemens Kolbitsch and
Christopher Kruegel and
Stefano Zanero
2010 IEEE Symposium on Security and Privacy
Identifying Dormant Functionality in Malware Programs
Paolo Milani Comparetti∗, Guido Salvaneschi†, Engin Kirda‡,
Clemens Kolbitsch∗, Christopher Kruegel§ and Stefano Zanero†
∗Technical University of Vienna
{pmilani,kolbitsch}@seclab.tuwien.ac.at
{salvaneschi,zanero}@elet.polimi.it
†Politecnico di Milano
§University of California, Santa Barbara
‡Institut Eurecom
PI:EMAIL
PI:EMAIL
Abstract—To handle the growing ﬂood of malware, security
vendors and analysts rely on tools that automatically identify
and analyze malicious code. Current systems for automated
malware analysis typically follow a dynamic approach, ex-
ecuting an unknown program in a controlled environment
(sandbox) and recording its runtime behavior. Since dynamic
analysis platforms directly run malicious code, they are resilient
to popular malware defense techniques such as packing and
code obfuscation. Unfortunately, in many cases, only a small
subset of all possible malicious behaviors is observed within the
short time frame that a malware sample is executed. To mitigate
this issue, previous work introduced techniques such as multi-
path or forced execution to increase the coverage of dynamic
malware analysis. Unfortunately, using these techniques is
potentially expensive, as the number of paths that require
analysis can grow exponentially.
In this paper, we propose REANIMATOR, a novel solution to
determine the capabilities (malicious functionality) of malware
programs. Our solution is based on the insight that we can
leverage behavior observed while dynamically executing a
speciﬁc malware sample to identify similar functionality in
other programs. More precisely, when we observe malicious
actions during dynamic analysis, we automatically extract and
model the parts of the malware binary that are responsible
for this behavior. We then leverage these models to check
whether similar code is present in other samples. This allows
us to statically identify dormant functionality (functionality
that is not observed during dynamic analysis) in malicious
programs. We evaluate our approach on thousands of real-
world malware samples, and we show that our system is
successful in identifying additional, malicious functionality. As
a result, our approach can signiﬁcantly improve the coverage
of malware analysis results.
I. INTRODUCTION
Malware is a signiﬁcant problem and the root cause for
many security threats on the Internet. For each new malware
binary that is discovered, it is important to understand its
malicious capabilities, its propagation vectors, and its impact
on the local system. This is necessary to determine the type
and severity of the threat that the malware poses. Also, this
information is valuable to create detection signatures and
removal procedures. Of course, given the sheer volume of
1081-6011/10 $26.00 © 2010 IEEE
DOI 10.1109/SP.2010.12
61
new samples that appear every day, obtaining a preliminary
understanding of the capabilities of a malware binary re-
quires the use of automated analysis systems.
Currently, dynamic analysis tools (such as Norman Sand-
box, Anubis [1], and CWSandbox [2]) are the most popular
choice when performing automated malware analysis. These
tools run the binary under inspection in a controlled environ-
ment (a sandbox) and monitor its runtime behavior, typically
by recording the Windows API library and the operating
system calls, including arguments, that the program invokes.
The advantage of dynamic analysis techniques is that the ac-
tions of a malware sample can be observed directly, without
complications due to runtime packing or code obfuscation.
Although useful in practice, dynamic techniques are not
without
issue is that a
dynamic analysis run is unlikely to reveal the entire range of
capabilities of a given binary. The reason is that the analysis
can only observe behaviors for which the corresponding
code is actually executed. In contrast, many malware pro-
grams include triggers that ensure that certain functions are
invoked only when particular environmental or temporal
conditions are satisﬁed. Common examples are bot programs
that wait for external input from their command and control
servers, or malware programs that execute their malicious
payload only before (or after) a certain date.
limitations. The most signiﬁcant
Previous research [3]–[5] has recognized the problem that
dynamic techniques suffer from limited coverage. The pro-
posed solutions mainly revolve around the idea of increasing
the number of paths that are dynamically explored. To this
end, analysis systems execute a binary multiple times. For
each run, such systems either provide different inputs that
invert the outcomes of certain conditional branches (possible
triggers) [3], [4], or simply force the execution along a
different path [5]. In both cases, additional code can be
reached, potentially revealing previously-unseen behavior.
Unfortunately, systems that explore multiple execution
paths have to deal with the path explosion problem. Path
explosion occurs because, for each interesting branch in the
program, the analysis has to follow two successor paths.
This leads to an exponential growth in the overall number
of paths that need to be explored. Various heuristics are
used to ﬁrst select more promising continuations. However,
these heuristics rarely achieve full code coverage. Thus,
even though multi-path analysis can increase the number of
behaviors that are observed during a dynamic analysis run, it
is unlikely that the entire code is executed. Moreover, multi-
path analysis is costly, which is a signiﬁcant limitation when
considering the tens of thousands of samples that need to be
analyzed daily.
In this paper, we propose REANIMATOR, a novel approach
to identify dormant behaviors (behaviors that are not ob-
served during dynamic analysis) in malware binaries. Our
approach exploits the fact that many malware samples share
the same code base, or at least, parts of their code. This is
due to the fact that many samples are just re-packaged, poly-
morphic variants of the same malware program. Moreover,
as previous studies have shown [6], copying and pasting is
a common practice in software development, and, certainly,
malware programmers are no exception.
The basic approach of REANIMATOR is the following:
for every malware sample that is examined by a dynamic
malware analysis system, we check its runtime actions for
the presence of certain interesting, high-level behaviors.
These behaviors are expressed in the context of system calls
and Windows API functions, and they represent actions such
as packet snifﬁng, or terminating anti-virus processes. For
each behavior that is observed, we automatically locate the
code of the binary that is responsible for this behavior. It is
important that the located code is accurate; that is, the iden-
tiﬁed code should be directly responsible for the observed
behavior, and not contain unrelated helper functions, such
as library routines. Based on the identiﬁed code regions, we
create a model that captures structural information of this
code. Using these models, we can then check other binaries
for the presence of similar code. This is done by statically
examining the unpacked body of a malware binary. When
a model matches, we assume that the malware program
contains functionality that
implements the corresponding
behavior.
We performed empirical experiments to demonstrate the
accuracy of our system by comparing it with the results of
a source-code-level plagiarism detection tool. Furthermore,
we tested our system on large, real-world malware datasets.
Our results show that REANIMATOR can successfully detect
dormant functionality and signiﬁcantly increase the coverage
of dynamic analysis techniques.
The main contributions of this paper are the following:
• We introduce a novel technique to automatically iden-
tify and model code regions in binaries that are directly
responsible for speciﬁc runtime behaviors.
• We present a system that leverages models to stat-
ically check unknown programs for the presence of
previously-seen, malicious functionality.
• Our experimental evaluation demonstrates that our sys-
tem successfully ﬁnds dormant behaviors in malware
samples that are not discovered by a dynamic malware
analysis tool.
II. SYSTEM GOALS AND APPROACH
The goal of REANIMATOR is to improve the quality of
the results delivered by automated malware analysis sys-
tems. In particular, we address a key limitation of dynamic
malware analysis platforms, which can only examine code
paths that are actually executed. To do this, we statically
search a malware binary for code that was not run during
dynamic analysis but that implements speciﬁc functionality
that is of interest to a malware analyst. Clearly, the concept
of statically searching a program for code fragments that
indicate malicious behaviors is not novel per se. However,
our approach offers a combination of two salient properties
that improve signiﬁcantly over previous work. More pre-
cisely, our techniques enable us to automatically generate
functionality-aware models of binary code.
Automated model generation. The ability to automatically
extract models is important, because it removes the need for
tedious and time consuming manual analysis, and scales to
the large volume of malware samples that are discovered
on a daily basis. Previous work on automated signature (or,
more generally, model) generation resulted in a number of
systems that extract byte strings [7], token sequences [8],
or control ﬂow graphs [9] to identify malware binaries.
Fundamentally, all these systems share the same underlying
mechanism: They search for bytes, instructions, or subgraphs
that frequently appear in a set of malicious programs (or
execution traces) while, at the same time, they do not appear
in legitimate programs (or traces). This basic approach is
often successful in automatically extracting models that are
able to (statically) classify an unknown program as malicious
or benign. However, such models carry little additional
semantic information. In particular, it is typically unclear
whether a generated model captures some core malware
behavior or simply represents a program artifact or auxiliary
functionality. This is a serious limitation when such models
are deployed in an automated malware analysis system.
The reason is that it is often clear that a program under
examination is malicious (e.g., because it was collected by
a honeypot as the payload of an exploit), but it is not clear
which set of functionalities this program implements.
Functionality-aware models. To identify speciﬁc malware
behaviors, one requires models that are functionality-aware.
That is, these models need to be equipped with semantic
information that indicates the presence of speciﬁc, malicious
functionality (e.g.,
that a malware sends spam,
monitors keystrokes, or starts a web server to provide
the fact
62
backdoor access to a compromised host). So far, efforts
to build functionality-aware models relied on human ana-
lysts. For instance, previous work has proposed semantics-
aware code templates [10] and malware blueprints [11].
Such models can precisely characterize code snippets that
implement suspicious functionality, such as unpacking or
sending spam mails. However, while code templates and
malware blueprints are robust to minor code changes and
obfuscation, they are nonetheless speciﬁc to one concrete
way in which a high-level behavior is implemented. We call
a piece of code that implements a malicious behavior in one
speciﬁc way an instantiation of this behavior. Of course, it is
common that members of a certain malware family share the
same instantiation of a particular behavior. Moreover, code
sharing makes it likely that the same instantiation can be
found across several different malware families. However, it
is necessary to manually develop a different code template
or blueprint for each new behavior instantiation that
is
identiﬁed. Clearly, this is undesirable, given the massive
volume of novel malware that is encountered in the wild.
The ability of REANIMATOR to generate functionality-
aware models enables us to statically explore malware bina-
ries for instantiations of speciﬁc behaviors. This allows us
to accurately recognize malicious program capabilities, even
when the corresponding code was not executed, addressing
an important limitation of dynamic analysis systems. The
ability to extract models automatically allows us to cope
with the large number of malware samples that need to be
analyzed. In addition, it is faster for our system to automat-
ically generate a model for a newly-identiﬁed instantiation
of a behavior than for a malware author to manually modify
the code to create this instantiation. This is an important
advantage in the arms race between defenders and malware
authors.
Rationale of approach. As mentioned previously, the goal
of our system is to recognize the purpose of code that is not
executed during dynamic analysis (dormant functionality).
To this end, we exploit the fact that a dynamic malware
analysis platform receives, executes, and observes thousands
of malware programs every day. The basic insight is that,
when analyzing a malware sample, we can take advantage
of the wealth of information obtained from previous analysis
runs. More precisely, we can statically search a program for
the presence of a code fragment that is sufﬁciently similar
to code that (i) was executed during a previous, unrelated
analysis run and (ii) was found to be an instantiation of a
certain malware behavior. In this case, we know that the
program under examination contains functionality that can
produce this observed behavior.
It is important to note that the behaviors that can be ob-
served in a dynamic analysis environment vary signiﬁcantly,
even for instances of the same malware family. For example,
depending on the availability of the command and control
B1
B2
B3
.
.
.
Bn
γ1
γ2
γ3
γn
O'
Malware
sample
A. Dynamic Behavior
B. Extracting
Identiﬁcation
Genotypes Models
C. Finding
Dormant Functionality
Behaviors
Genotype models
New malware
samples
Figure 1. An overview of the REANIMATOR workﬂow.
(C&C) server or the currently-advertised command, a bot
will invoke different payload routines (e.g., the bot might
scan, start a proxy server, send spam, or do nothing). Thus,
frequently, a single dynamic analysis run only reveals a small
portion of the entire set of behaviors that a malware program
could exhibit. With REANIMATOR, we can automatically
generate a model that captures the code that is responsible
for the observed behavior. As a result, each execution of
a binary contributes a piece to a global knowledge base
that stores different instantiations for different behaviors.
This knowledge base can then be used to discover dormant
functionality in other malware samples.
III. SYSTEM OVERVIEW
REANIMATOR works in three phases, as shown in Fig-
ure 1. The ﬁrst two phases are responsible for generating
functionality-aware models for different behaviors. The last
phase uses previously constructed models to check for
dormant behaviors. The following paragraphs outline the
three phases in more detail.
A. Dynamic Behavior Identiﬁcation
In the ﬁrst phase, a malware binary is executed in an
instrumented, dynamic analysis environment. For this, we
obtained access to Anubis [1], a sandbox that is built on
top of the whole-system emulator Qemu. Anubis records
the invocations of a large set of security-relevant system
calls and Windows API functions. In addition, the system
uses taint analysis to track data ﬂow dependencies between
system and function call arguments.
Based on the output of Anubis, we use a set of speciﬁ-
cations to identify different types of interesting, security-
relevant behaviors that a malware binary has exhibited
during the dynamic analysis. We call such externally-visible,
security-relevant behaviors that are observed during dynamic
analysis malware phenotypes. Examples of phenotypes in-
clude sending spam, launching attacks, installing a key-
board logger, and performing password snifﬁng. To write
behavioral speciﬁcations for different phenotypes, we build
upon previous work that has introduced languages to express
speciﬁc malware behavior with the help of graphs [12] or
63
automata [13], [14]. Both approaches use as input a trace of
system calls observed during dynamic analysis, information
that is readily available in the Anubis output.
For our work, we use rules that describe a malware
phenotype in terms of the required system or API calls, their
arguments, and the data ﬂows between these arguments. This
is very similar to malspecs [12]. For instance, we detect
that a malware program is sending spam by looking for
outgoing mail trafﬁc on TCP port 25. Such activity is, by