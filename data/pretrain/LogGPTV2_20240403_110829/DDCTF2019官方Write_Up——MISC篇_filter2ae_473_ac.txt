    for i, pair in enumerate(pairs3):
        x, y = pair
        top = 1
        bottom = 1
        for j, pair in enumerate(pairs3):
            if j == i:
                continue
            xj, yj = pair
            top = (top * (-xj)) % p
            bottom = (bottom * (x - xj)) % p
        res3 += (y * top * gmpy2.invert(bottom, p)) % p
        res3 %= p
    print res3
    print repr(long_to_bytes(res3))
    # 'DDCTF{nYrpbcscdNgqX63IdtnkLrq9FQvwfa2f}'
    flag:DDCTF{nYrpbcscdNgqX63IdtnkLrq9FQvwfa2f}
## 0x07：伪-声纹锁
分析给的voice_lock文件，首先在限定的采样频率范围内进行傅里叶变换(首先采样频率范围小，在采样频率范围之内只有150个频率采样点，采样率低，导致还原的信号失真，混叠)。根据滑动窗口大小，进行傅里叶逆变换，得到较为失真的音频(虽然满足了calc_diff<3,但是仍然听不出flag)
分析过程：
还原音频程序：
    import cmath
    import librosa  # v0.6.2, maybe ffmpeg is needed as backend
    import numpy as np  # v1.15.4
    from scipy.fftpack import fft, ifft
    import sys
    from PIL import Image  # Pillow v5.4.1
    import matplotlib.pyplot as plt
    window_size = 2048
    step_size = 100
    max_lim = 0.15
    f_ubound = 2000
    f_bins = 150
    sr = 15000
    def transform_x(x, f_ubound=f_ubound, f_bins=f_bins):
        freqs = np.logspace(np.log10(20), np.log10(f_ubound), f_bins)
        seqs = []
        for f in freqs:
            seq = []
            d = cmath.exp(-2j * cmath.pi * f / sr)
            coeff = 1
            for t in range(0, len(x)):
                seq.append(x[t] * coeff)
                coeff *= d
            seqs.append(seq)
        sums = []
        for seq in seqs:
            X = [sum(seq[:window_size])/window_size]
            for t in range(step_size, len(x), step_size):
                X.append(X[-1]-sum(seq[t-step_size:t])/window_size)
                if t+window_size-step_size < len(x):
                    X[-1] += sum(seq[t+window_size-step_size:t +
                                     window_size])/window_size
            sums.append(X)
        return np.array(sums)
    def calc_diff(x, spec):
        x = transform_x(x)
        print(x.shape)
        diff = 0
        for i in range(0, x.shape[0]):
            xx = np.abs(x[i])
            xx = np.round(linear_map(xx, np.min(
                xx), np.max(xx), 0, 255)).astype(np.uint8)
            sp = np.abs(spec[i])
            sp = np.round(linear_map(sp, np.min(
                sp), np.max(sp), 0, 255)).astype(np.uint8)
            diff += np.linalg.norm(xx-sp)
        return diff/x.shape[0]/x.shape[1]
    freqs = np.logspace(np.log10(20), np.log10(f_ubound), f_bins)
    N = 95000
    def linear_map(v, old_dbound, old_ubound, new_dbound, new_ubound):
        return (v-old_dbound)*1.0/(old_ubound-old_dbound)*(new_ubound-new_dbound) + new_dbound
    def image_to_array(img):
        img_arr = linear_map(np.array(img.getdata(), np.uint8).reshape(
            img.size[1], img.size[0], 3), 0, 255, -max_lim, max_lim)
        return img_arr[:, :, 1] + img_arr[:, :, 2] * 1j
    C_fingerprint = image_to_array(Image.open('fingerprint.png'))
    dataRecovered = [0 for i in range(N)]
    dataRecoveredWriteCount = [0 for i in range(N)]
    for windowStart in range(0, 93000, step_size):
        print('loop(', windowStart, '/', 93000, ')')
        xLen = 100
        F = []
        for i in range(len(freqs)):
            F.append((C_fingerprint[i][int(windowStart/100)]) *
                     cmath.exp(2j * cmath.pi * freqs[i] / sr * (100*int(windowStart/100))))
        xRecovered = []
        for n in range(100):
            result = 0
            for ad in range(len(freqs)):
                f = freqs[ad]
                fw = F[ad]
                result += fw * cmath.exp(2j * cmath.pi * f / sr * n)
            xRecovered.append(result)
        xRecovered = np.array(xRecovered)
        for ad in range(xLen):
            xr = xRecovered[ad]
            adAllocate = windowStart + ad
            dataRecovered[adAllocate] = (
                dataRecovered[adAllocate] * dataRecoveredWriteCount[adAllocate] + xr) / (dataRecoveredWriteCount[adAllocate] + 1)
            dataRecoveredWriteCount[adAllocate] += 1
    dataRecovered = np.real(dataRecovered)
    out = []
    librosa.output.write_wav("recovered.wav", dataRecovered, sr)
    for i in range(0, 150):
        out.append([C_fingerprint[i][j] for j in range(0, 950)])
    out = np.array(out)
    print(calc_diff(dataRecovered, out))
    print('done!')
得到音频文件，跟官方人员沟通提交脚本和还原的音频后，得到flag:DDCTF{VOICE_ENCODED_TEST}
想了解更多 题目出题人视角解析，请关注：滴滴安全应急响应中心（DSRC）公众号查看：