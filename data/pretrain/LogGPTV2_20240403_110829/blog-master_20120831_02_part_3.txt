     |     0  
(1 row)  
remote :   
remote=> select sum(hashtext(t.*::text)),count(*) from rmt_test t;  
     sum      | count   
--------------+-------  
     |     0  
(1 row)  
```  
2\. 在remote库测试DML以及truncate  
```  
remote=> insert into rmt_test select generate_series(1,10000),'digoal'||random(),'test'||random(),now(),clock_timestamp();  
INSERT 0 10000  
```  
比对两库有无差异  
```  
local :   
local=> select sum(hashtext(t.*::text)),count(*) from loc_test t;  
     sum      | count   
--------------+-------  
 -25035561749 | 10000  
(1 row)  
remote :   
remote=> select sum(hashtext(t.*::text)),count(*) from rmt_test t;  
     sum      | count   
--------------+-------  
 -25035561749 | 10000  
(1 row)  
```  
UPDATE, DELETE, TRUNCATE得到的结果local, remote库都一致, 这里不再列出.  
3\. 测试异常, 把remote的login权限去除, 然后在local库插入10000条记录, 可以看到记录被写入了loc_test同时也写入了sync_err_rec表.  
```  
remote=# alter role remote nologin;  
ALTER ROLE  
```  
注意要把所有连接remote的用户全部踢掉, 否则local还连在remote上, 测试将得不到要的结果.  
```  
remote=# select pg_terminate_backend(pid) from pg_stat_activity where usename='remote';  
 pg_terminate_backend   
----------------------  
 t  
```  
在local库插入10000条记录  
```  
\c local local  
local=> insert into loc_test select generate_series(1,10000),'digoal'||random(),'test'||random(),now(),clock_timestamp();  
```  
将报出10000条如下NOTICE  
```  
NOTICE:  v_conn_status:, v_exec_status:.  
INSERT 0 10000  
```  
查看loc_test 以及 sync_err_rec.  
```  
local=> select count(*) from loc_test ;  
 count   
-------  
 10000  
(1 row)  
local=> select count(*) from sync_err_rec;  
 count   
-------  
 10000  
(1 row)  
```  
4\. 处理异常记录, 先把remote用户的login权限加上, 然后到local库调用deal_sync_err_rec函数.  
```  
local=> \c remote postgres  
You are now connected to database "remote" as user "postgres".  
remote=# alter role remote login;  
ALTER ROLE  
```  
处理1000条错误同步记录.  
```  
remote=# \c local local  
You are now connected to database "local" as user "local".  
local=> select * from deal_sync_err_rec(1000);  
 deal_sync_err_rec   
-------------------  
 t  
(1 row)  
```  
看到sync_err_rec减少了1000条记录.  
```  
local=> select count(*) from sync_err_rec;  
 count   
-------  
  9000  
(1 row)  
```  
远程库将多出1000条记录.  
```  
local=> \c remote remote  
You are now connected to database "remote" as user "remote".  
remote=> select count(*) from rmt_test ;  
 count   
-------  
  1000  
(1 row)  
```  
继续将所有的错误记录都修复.  
```  
local=> select * from deal_sync_err_rec(10000);  
 deal_sync_err_rec   
-------------------  
 t  
(1 row)  
```  
现在sync_err_rec中将没有记录.  
```  
local=> select count(*) from sync_err_rec;  
 count   
-------  
     0  
(1 row)  
```  
比对两库有无差异   
```  
local :   
select sum(hashtext(t.*::text)),count(*) from loc_test t;  
local=> select sum(hashtext(t.*::text)),count(*) from loc_test t;  
     sum      | count   
--------------+-------  
 -29845555432 | 10000  
(1 row)  
remote :   
remote=> select sum(hashtext(t.*::text)),count(*) from rmt_test t;  
     sum      | count   
--------------+-------  
 -29845555432 | 10000  
(1 row)  
```  
初步测试完全正常.  
## 小结  
1\. multi - master复制需要解决冲突的问题.  
  本例没有实现冲突解决, 只将同步错误记录到sync_err_rec表.  
  在设计多主复制时, 应该尽可能避免两边更新同一条记录, 可以考虑两边使用不同的主键取值范围.  
    例如A库的主键是mod(id,2)=0;  
    B库的主键是mod(id,2)=1;  
    这样可以避免两边去操作同一条记录.  
2\. 认真看的朋友一定会发现, 这里的复制存在一个比较大的漏洞, 当异常发生后, 记录写入sync_err_rec表, 但是当恢复正常后, 如果又发生了DML操作, 远程数据库执行SQL的顺序将发生颠倒, 也就是说sync_err_rec里面记录的SQL还未执行, 由触发器触发的SQL已经开始执行了.   
打个比方,   
2\.1\. sync_err_rec中有一条(UPDATE) DELETE from remote.rmt_test where pk1=1 and pk2='digoal';INSERT into remote.rmt_test values(1, 'digoal', 'test',...);  
2\.2\. 恢复正常后. 又对loc_test进行了2个DML操作.   
```  
DELETE from local.loc_test where pk1=1 and pk2='digoal';   
INSERT INTO local.loc_test values(1, 'digoal', 'DDDDDDDDD',....);  
```  
此时在remote库, 应该是remote.rmt_test values(1, 'digoal', 'DDDDDDDDD',....)的记录存在.  
3\. 修复sync_err_rec的记录. 那么会抹去 remote.rmt_test values(1, 'digoal', 'DDDDDDDDD',....);这条记录, 变成老的记录remote.rmt_test values(1, 'digoal', 'test',...) .  
怎么修复这个问题呢?  
3\.1\. 在loc_test的触发器中调用deal_sync_err_rec可行吗?   
如果可行, 必须一次性处理掉所有dst_server在sync_err_rec中的所有记录. 也是个麻烦事. (如果异常记录太多的话).  
确保sync_err_rec中的记录只允许在远程执行一次,  如果是并发的触发deal_sync_err_rec会不会有问题 ?   
我们来看看deal_sync_err_rec这个函数 :   
```  
begin  
  -- 取出最早的记录的dst_server, 接下来将处理这个dst_server发生的错误.  
  -- 如果是并发执行, sync_err_rec中的同样的记录可能会被多个会话取到.   
  select dst_server into v_dst_server from sync_err_rec order by create_time limit 1;  
  -- 空表示没有记录直接返回  
  if (v_dst_server is NULL) then  
    return true;  
  end if;  
  -- 将v_dst_server的值赋予给连接名  
  v_conn_name := v_dst_server;  
  -- 取出一批记录  
  -- 如果是并发执行, sync_err_rec中的同样的记录可能会被多个会话取到.   
  select array_agg(id), string_agg(dst_query, ';') into v_id, v_dst_query from   
    (select id,dst_query from sync_err_rec where dst_server=v_dst_server order by create_time limit i_limit) t;  
  -- 删除sync_err_rec中对应的记录.  
  -- 当某个会话先获得了这些记录的行锁, 那么delete执行后删除掉的行总数应该等于select unnest(v_id)的记录数.  
  -- 而等待中的会话删除的行数应该是0. 但是不会报错, 只是要等别人释放这些行锁. 这里就是并行执行deal_sync_err_rec的问题所在.  
  -- 修复并行执行deal_sync_err_rec的问题, 这里要加一个判断, 如果删除行数不等于select unnest(v_id)的记录数. 返回异常.  
  -- 那么loc_test的触发器函数在接收到这个异常后, 将会记录这次触发DML或者TRUNCATE的SQL到sync_err_rec表,   
  -- 也不会去调用dblink_exec(v_conn_name, v_dst_query, true);远程执行.   
  -- 但是问题又来了, 在(1.成功执行deal_sync_err_rec的会话后) 和 (2.记录这次触发DML或者TRUNCATE的SQL到sync_err_rec表前) 之间,   
  -- sync_err_rec这个表里面的数据对其他会话来说是无记录的, 也就是说其他会话的DML将复制到远程, 又发生SQL执行顺序的问题了.  
  delete from sync_err_rec where id in (select unnest(v_id));  
  if ( dblink_get_connections() @> ('{'||v_conn_name||'}')::text[] ) then   
  else  
    select * into v_conn_status from dblink_connect(v_conn_name, v_dst_server);  
  end if;  
  -- 这里使用的是true, 所以远程异常, 本地也异常. 确保到这一步还可以回退, 只要这一步执行成功, 那本地删除的sync_err_rec和远程都执行成功.  
  select * into v_exec_status from dblink_exec(v_conn_name, v_dst_query, true);  
  -- raise notice 'v_conn_status:%, v_exec_status:%.', v_conn_status, v_exec_status;  
  return true;  
END;  
```  
结论, 在loc_test的触发器中调用deal_sync_err_rec不可行.  
那么更好的办法是, 如果发现sync_err_rec有对应的dst_server的记录,那就直接往sync_err_rec里面写, 而不要复制到远程. (或者sync_err_rec没有记录, 并且sync_err_rec被其他会话加了RowExclusiveLock锁, 此时可能正在处理sync_err_rec中的记录或者其他会话在写入,  那也要直接往sync_err_rec里面写, 而不要复制到远程. 最终都是为了保证SQL的执行顺序), 让deal_sync_err_rec来处理异常. 所以需要修改被复制表的触发器函数.  
修改后的函数如下 :   
3\.2\. deal_sync_err_rec函数增加显锁  
```  
  select dst_server into v_dst_server from sync_err_rec order by create_time limit 1 for update;  
```  
完全函数 :   
```  
create or replace function deal_sync_err_rec (i_limit int) returns boolean as $$  
declare  
  v_conn_name text;  -- 连接名  
  v_conn_status text;  -- 存储dblink_connect(v_conn_name, v_dst_server)的返回值  
  v_exec_status text;  -- 存储dblink_exec(v_conn_name, v_dst_query, true|false)的返回值.  
  v_dst_server text;  -- foreign server, 一次取一个. 根据这个dst_server再抽取错误的同步记录, 进行处理.  
  v_dst_query text;  -- sync_err_rec中记录的SQL语句  
  v_id int8[];  -- sync_err_rec的主键, 用于记录一批记录, BATCH删除.  
begin  
  -- 取出最早的记录的dst_server, 加上RowExclusiveLock锁, 接下来将处理这个dst_server发生的错误.  
  select dst_server into v_dst_server from sync_err_rec order by create_time limit 1 for update;  
  -- 空表示没有记录直接返回  
  if (v_dst_server is NULL) then  
    return true;  
  end if;  
  -- 将v_dst_server的值赋予给连接名  
  v_conn_name := v_dst_server;  
  -- 取出一批记录  
  select array_agg(id), string_agg(dst_query, ';') into v_id, v_dst_query from   
    (select id,dst_query from sync_err_rec where dst_server=v_dst_server order by create_time limit i_limit) t;  