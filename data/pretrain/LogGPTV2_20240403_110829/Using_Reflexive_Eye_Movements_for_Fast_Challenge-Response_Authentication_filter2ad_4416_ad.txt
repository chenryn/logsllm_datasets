ticate users over the course of a normal work day (without
re-calibration), we require each enrolled user to take part
in a minimum of three (up to four) sessions. The ﬁrst two
sessions are ﬁve minutes apart and mimic a legitimate user
leaving his desk to take a break or use the restroom. All
subsequent sessions are at least 6 hours apart. Participants
acting as external attackers are only invited to one session
where they are asked to impersonate a legitimate user, i.e.,
the system uses the calibration proﬁle and biometric tem-
plate of the chosen legitimate user. Every external attacker
tries to authenticate as 5 diﬀerent legitimate users, at least
3 times per user. In their last session, legitimate users were
asked to act as internal attackers and each performed a min-
imum of 15 attempts of impersonating other users, analo-
gously to external attackers.
Test Population. Experimental data was acquired from
a total of 30 participants aged 21 to 58 who were recruited
from the general public through public advertisements, email
lists, and social media. The only requirement was a mini-
mum age of 18. The test population consists of 7 women and
23 men. Out of the 30 recruited participants, 22 participants
were enrolled as legitimate users and 8 participants repre-
sented external attackers whose gaze characteristics were not
known to the system. The acquired data set consists of a
total of 1602 gaze-responses: 1021 authentication attempts
by legitimate users and 581 simulated attack attempts by
either internal or external attackers.
Participants were told that their eye movements will be
recorded for the purpose of evaluating the feasibility of dis-
tinguishing individuals based on their behavioral gaze-based
biometrics. They then signed a written consent form in
accordance with the experiment ethics review approved by
the University’s research ethics committee, reference number
SSD/CUREC1A/14-226. Names have been replaced with
pseudonyms.
Participants who do not have normal vision wore contact
lenses or were asked to remove their glasses. This was done
to remove the possibility that classiﬁcation relies on poten-
tial speciﬁc characteristics of recorded gaze when glasses are
worn. For the same reason, lighting conditions were not
changed during all experiment sessions.
Figure 7: Measured authentication time and EER as a func-
tion of gaze-challenge complexity N . As N increases from 8
to 24, the EER reduces from above 12% to under 6%, while
at the same time, the median time to authenticate grows lin-
early from 2 seconds to about 9 seconds. The vertical line
depicts a scenario where 15 positions are used in a challenge:
the median authentication time is around 5 seconds, while
the EER is close to 7%.
7. SYSTEM EVALUATION
We now experimentally evaluate the proposed system with
respect to the design goals stated in Section 3.
7.1 Varying the Challenge Complexity N
One of the deﬁning parameters of the proposed system
is N , the number of stimulus positions in a single gaze-
challenge. We ﬁrst analyze the eﬀect that varying N has
on authentication time and overall user classiﬁcation perfor-
mance. Incrementing N directly increases the complexity of
gaze-challenge, thus requiring more time to respond to the
visual stimulus. At the same time, larger N should allow
the system to extract more stable features and thus achieve
stronger classiﬁcation results. On the other hand, as N de-
creases, both the authentication time, and the classiﬁcation
performance are likely to decline.
Setup. Since all user experiments were run with gaze-
challenges that had N = 25 stimulus dot positions, we can
evaluate the classiﬁer performance in a scenario where gaze-
challenges consist of K < N positions by simulating that the
stimulus presentation and gaze recording stopped after the
K-th position was gazed. Such an adapted dataset is con-
structed by only considering gaze measurements that were
recorded before the (K + 1)-th stimulus position is shown.
The classiﬁcation performance for each K and for each
user is estimated by computing an Equal Error Rate (EER)
while performing a ﬁve-fold cross-validation of the individual
classiﬁers as follows. In each of ﬁve repetitions, four out of
ﬁve folds of the legitimate user’s authentication attempts
are provided as enrolment data for user enrolment that was
performed as described in Section 5. The remaining fold was
used to evaluate classiﬁer performance against other users’
authentication attempts as negative samples. The resulting
EER for any K is computed as an average across all ﬁve
folds of all individual users’ classiﬁers for that K.
Results. We show the eﬀect of varying N on authentication
time and classiﬁcation performance in Figure 7. The median
time for a single authentication attempt grows linearly from
Figure 8: Empirical cumulative distribution function for du-
ration of all measured authentication attempts when N = 15.
Close to 50% of the attempts took less than 5 seconds, while
more than 80% of the attempts lasted less than 7.5 seconds.
2 seconds for 8 stimulus positions, to about 9 seconds for 24
stimulus positions. At the same time, the overall EER of
the classiﬁcation falls from around 12% when only 8 stim-
ulus positions are used, to a level of 6% when 24 stimulus
positions are used in a challenge.
Since N = 15 shows a balanced trade-oﬀ between classiﬁ-
cation performance and median authentication time, we use
this value to report results in the remainder of the analysis.
In order to provide a more comprehensive estimate of the
time required for the majority of users to authenticate than
just median, in Figure 8 we show a cumulative density func-
tion of the authentication times for all users when N = 15.
The ﬁgure shows that half of the users authenticate in 5
seconds or less, while the authentication for more than 80%
of the users takes less than 7.5 seconds. As we discuss in
Section 9, these times are favorable to previous related work
in gaze-based authentication, as well as reported password
authentication times.
7.2
Impersonation Attacks
Setup. Recall that, in an impersonation attack, the at-
tacker targets a speciﬁc user with the goal of responding to
the gaze-challenge posed by the system, and successfully im-
personating the legitimate user in order to gain access. The
attacker is permitted to use the gaze-based authentication
system in any way he wishes, such as purposely moving or
altering the angle of his head to try to increase the chance
of gaining access.
As described in Section 6.2, we purposely design the user
experiments to simulate this type of attack as closely as pos-
sible: all participants were asked to perform multiple “attack
attempts”, in which they falsely claimed some other user’s
identity and tried to authenticate with the gaze calibration
proﬁle of the legitimate user loaded by the system.
For each user, we perform a ﬁve-fold cross-validation to
estimate the performance of the system under such attacks.
We enrol the user as described in Section 5, using four out
of ﬁve folds of legitimate user’s samples, and then evaluate
the performance of the whole authentication system on the
remaining one ﬁfth of the legitimate user’s gaze-responses
that were not used for enrollment. During evaluation, legit-
imate user’s samples are labeled as positive, while all attack
attempts that other users made while pretending to be the
legitimate user are labeled as negative. We consider an au-
thentication attempt accepted by the system only if it passes
both the identity veriﬁcation and the freshness veriﬁcation.
For freshness veriﬁcation, we use a threshold T = 50%.
EER [%]Median time to authenticate [s]Number of dot positions per authentication (N)9912675321015201015200.000.250.500.751.002.55.07.510.0Authentication Time [s]Empirical CDFFigure 9: The ROC curves that show authentication perfor-
mance under impersonation attacks. Red and green curves
represent only internal and external attackers, while blue
curve shows the overall combined performance. The EER
for internal attackers equals to 6.2%, while for external at-
tackers it is expectedly slightly higher, and amounts to 7.3%.
The overall EER for all attackers is 6.3%.
Besides overall performance, we also separately evaluate
two disjunct subsets of the attack attempts: those originat-
ing from external attackers, who are unknown to the sys-
tem, and those originating from internal attackers, whose
previous authentication attempts might have been used as
negative samples during enrollment.
Results. We show the system performance against imper-
sonation attacks as an ROC curve in Figure 9. Since individ-
ual user classiﬁers output a probability that a given sample
belongs to the respective legitimate user, we can achieve
diﬀerent classiﬁcation performance by varying the thresh-
old above which a sample is considered legitimate. As this
threshold increases, so does the likelihood of falsely rejecting
a legitimate user (FRR) increase, but at the same time, the
likelihood of falsely accepting an attacker (FAR) decreases.
Diﬀerent combinations of FAR and FRR values for three
attack scenarios (internal, external, and all attackers) are
shown in Figure 9. For all three scenarios, it is possible
to achieve low FAR values (under 5%) if FRR is increased
closer to 10% and vice-versa.
An Equal Error Rate (EER) is deﬁned as the rate at which
FRR and FAR are equal, and is usually used to compare dif-
ferent classiﬁers. As expected, in terms of EER, the system
achieves slightly stronger performance against internal at-
tackers (6.2% EER) than external attackers (7.3% EER).
Overall, the system achieves an EER of 6.3% for imperson-
ation attacks; as we discuss in Section 8, this result is prefer-
able to any previously reported performance of gaze-based
authentication systems.
7.3 Replay Attacks
Setup. Recall from Section 4.3 that in order to prevent
reuse of biometric data, the system veriﬁes that the received
gaze-response corresponds to the presented gaze-challenge,
i.e., that the user successfully gazed at no less than a cho-
sen percentage T of the stimulus positions presented during
authentication.
The result of verifying freshness of a received response
Figure 10: Performance of the freshness veriﬁcation proce-
dure depending on the chosen threshold T . As we change
the required percentage of successfully gazed stimuli to clas-
sify a gaze sample as “fresh“ from 0% to 50%, the ratio of
successfully detected replay attempts rises from 0 to close to
1. At the same time, the ratio of successfully classiﬁed fresh
attempts starts declining as the required threshold increases
over 60%, showing almost perfect results for the thresholds
between 40% and 60%.
does not depend on the claimed identity during authenti-
cation, but only on the positions of the dot in the visual
stimulus. Therefore, in order to provide a more comprehen-
sive estimate of the distinctiveness of a challenge-response
pair, we report the results for a scenario in which identity
veriﬁcation always returns a positive answer.
In order to evaluate the probability of success of a replay
attack, for each gaze-challenge ci, we simulate a “replay” of
all other gaze-responses gj to the VerifyFreshness function of
the system. We calculate the success rate of replaying gj to
ci as the percentage of stimulus positions from ci that would
be considered successfully gazed if a user’s response was gj.
Since our dataset consists of 1021 legitimate authentica-
tion attempts, each recorded with a unique gaze-challenge,
we are able to simulate more than 106 potential replay at-
tempts in order to estimate the true reject rate. Further-
more, in order to estimate the true accept rates, we use
the same procedure to simulate a total of 1021 legitimate
authentication attempts, in which the gaze-response was in-
deed generated as the user was presented the matching gaze-
challenge.
Results. Figure 10 shows achieved performance of the
challenge-response veriﬁcation for diﬀerent values of T , which
we vary from 0% to 100%. As T , the ratio of replay attempts
that are correctly rejected (TRR) increases, while the ra-
tio of legitimate, fresh attempts that are correctly accepted
(TAR) decreases.
A desired threshold is the one that detects all replay at-
tempts, while accepting all legitimate authentication attempts
as fresh. Figure 10 shows a wide range of potential threshold
values that lie between 40% and 60% and almost perfectly
separate the fresh and the replayed gaze-responses. Such a
broad range of thresholds that achieve strong classiﬁcation is
a desirable property for any classiﬁcation system as it gives
strong conﬁdence in reported results.
Since we use T = 50% to evaluate impersonation attacks,
we report speciﬁc numeric details for this threshold. The