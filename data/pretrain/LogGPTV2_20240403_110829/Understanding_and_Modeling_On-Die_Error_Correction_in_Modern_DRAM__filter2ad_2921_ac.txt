n
Ideally, all of the parameters that comprise θ are known at test-
ing time. Unfortunately, experiments are often imperfect, and
internal device characteristics are difficult to obtain without
proprietary knowledge or laborious reverse-engineering. If
such parameters are unknown, we can infer them alongside
the unknown ECC scheme.7
In this work, we model data-retention errors as uniform-
random, independent events among cells programmed to the
“charged” state with a fixed probability determined by testing
conditions. θ then encapsulates i) the single-bit error proba-
bility, called the raw bit error rate (RBER), ii) the programmed
data pattern, and iii) the spatial layout of true-/anti-cells.
Unfortunately, evaluating Equation 4 analytically is difficult
even for data-retention errors due to the complexity of the
interactions between the ECC scheme and the parameters en-
compassed by θ. Instead, we numerically estimate the solution
to Equation 4 using Monte-Carlo simulation as described in Sec-
7While we could lump the unknown ECC scheme into θ as an unknown
microarchitectural characteristic, we keep it logically separate since θ repre-
sents what we already understand about DRAM devices, and the unknown
ECC scheme represents what we do not.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:57:59 UTC from IEEE Xplore.  Restrictions apply. 
tion 5. This approach allows our analysis to flexibly take into
account arbitrarily complex model parameters (e.g., detailed
microarchitectural characteristics, nontrivial error models).
4.4. Inferring the Model Parameters
mum a posteriori (MAP) estimation problem over a set F of
We now formulate the reverse-engineering task as a maxi-
hand-selected ECC schemes that are either directly mentioned
in context with on-die ECC (HSC(71, 64, 3) [41, 43, 93] and
HSC(136, 128, 3) [17, 48, 67, 68, 86]) or are used as demonstra-
tive examples of applying our methodology to devices with
stronger and/or more complicated codes (e.g., BCH(n, k, d),
HSC(n, k, d), REP(3, 1, 3)). Note that we also take into ac-
count implementation details of each of these schemes (e.g.,
systematic vs. non-systematic encodings) using our simulation
infrastructure as we describe in Section 5.3.
To reverse-engineer the unknown ECC scheme funknown, we
start by expressing it as the most likely ECC scheme out of all
possible schemes fi ∈ F given a set of observations O:
funknown = argmax
fi
(P[fi | O])
Unfortunately, we cannot directly evaluate Equation 5 since
our observations O are measured from a device with a fixed
ECC scheme. Instead, we use the Bayes theorem to express
Equation 5 in terms of the probability of obtaining measure-
ments O given an arbitrary ECC scheme fi, which we can
calculate using the relationship in Equation 3. This yields:
(cid:4)
(cid:3)
P[O | fi]P[fi]
(P[O | fi]P[fi])
P[O]
funknown = argmax
fi
= argmax
fi
(5)
(6)
Note that we ignore the denominator (i.e., the marginal likeli-
hood) in Equation 6 because it is a fixed scale factor indepen-
dent of fi and does not affect the maximization result.
We assume a uniformly-distributed prior (i.e., P[fi]) given
that we cannot guarantee anything about the on-die ECC im-
plementation. By restricting our analysis to only the afore-
mentioned ECC schemes, we already exclude any schemes that
we consider to be unrealistic. In principle, we could assign
greater or lower probability mass to schemes that have been
mentioned in prior work or that are exceedingly expensive,
respectively, but we choose not to do so because i) we cannot
guarantee that the devices we test are similar to those men-
tioned in prior work, and ii) we want to demonstrate the power
of our methodology without biasing the results towards any
particular ECC schemes.
The likelihood function (i.e., P[O | fi]) incorporates the ex-
perimental data we obtain from real devices. As we show in
Section 4.2, our measurements provide us with the probability
of observing an n-bit error in each of j independent DRAM
bursts. Defining N as a random variable representing the num-
ber of erroneous bits observed in a single burst and assuming
observations are independent events (validated in Section 4.3),
we rewrite the likelihood function as:
P[O | fi] = Pfi,θ
⎡
⎣jmax(cid:7)
⎤
⎦ =
jmax(cid:10)
N = nj
j=0
j=0
Pfi,θ[N = nj]
(7)
18
This is essentially a multinomial probability mass function
(PMF) evaluated at O, where each probability mass is computed
using Equation 4. Unfortunately, as described in Section 4.3, the
model parameter θ encapsulates the pre-correction error rate,
which we do not know and cannot measure post-correction.
Therefore, for each ECC scheme fi, we first maximize the like-
lihood distribution over θ:
P[O | fi] = max
⎛
⎝jmax(cid:10)
⎞
⎠
Pfi,θ[N = nj]
(8)
θ
j=0
Inserting the result of Equation 8 into our original optimiza-
tion objective (Equation 6), we obtain the final objective func-
tion to optimize in order to reverse-engineer the ECC scheme
funknown used in our devices:
⎞
⎠ P[fi]
⎞
⎠ (9)
⎛
⎝max
θ
⎛
⎝jmax(cid:10)
j=0
⎞
⎠
⎛
⎝jmax(cid:10)
j=0
funknown = argmax
fi
Pfi,θ[N = nj]
where the inner product term is calculated using Equation 4.
After the ECC scheme is reverse-engineered, we can repeat-
edly apply Equation 8 to solve for θ across many different ex-
periments (i.e., observations). Since θ represents all parameters
necessary to describe the pre-correction error distribution (de-
scribed in Section 4.3), this is equivalent to reverse-engineering
the pre-correction error rate. With the ECC scheme known as
fknown, Equation 8 simplifies to:
θ
unknown = argmax
θ
Pfknown,θ[N = nj]
(10)
With Equations 9 and 10, we can reverse-engineer both i) the
ECC scheme and ii) the pre-correction error rates from ob-
served post-correction errors for any DRAM device whose
error distributions are obscured by ECC. In Section 7.3, we
experimentally demonstrate how to apply Equation 9 to real
devices with on-die ECC.
5. Simulation Methodology
To apply EIN to data from real devices, we develop and publicly
release EINSim [1], a flexible open-source C++-based simulator
that models the life of a dataword through the entire ECC en-
coding/decoding process. EINSim accounts for different ECC
implementations and pre-correction error characteristics to
ensure that EIN is applicable to a wide variety of DRAM de-
vices and standards. This section describes EINSim’s extensible
design and explains how EINSim can be used to solve the opti-
mization problems formulated in Section 4.
5.1. EINSim High-Level Architecture
Figure 4 shows a high-level diagram of the logical flow of data
through EINSim’s different components. To model a DRAM
experiment, we simulate many individual burst-length accesses
that each access a different group of cells. Each burst simu-
lates an experimental measurement, yielding a distribution of
measured values across all simulated bursts. We describe the
function of each simulator component.
1 Word generator constructs a bitvector using commonly
tested data patterns (e.g., 0xFF, 0xAA, RANDOM) [3, 51, 52, 72,
79, 98, 128], simulating the data written to DRAM.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:57:59 UTC from IEEE Xplore.  Restrictions apply. 
Input Configuration
ECC schemes
1
      Word Generator
word
4
    Error Checker
‘corrected’ word
2
     ECC Model
     ECC Model
ECC Model
ECC Model
ECC Model
ECC Model
Encoder
Encoder
Encoder
Encoder
Encoder
Encoder
Decoder
Decoder
Decoder
Decoder
Decoder
Decoder
codeword(s)
3
      Error Injector
erroneous codeword(s)
observable
Output Distribution
Figure 4: High-level block diagram showing the logical flow of
data through the different components in our simulator.
2 ECC model encompasses an ECC implementation, includ-
ing the encoding/decoding algorithms and implementation de-
tails such as systematic vs. non-systematic encodings. Because
a single word from the word generator may comprise multiple
ECC datawords, EINSim provides a configurable mapping for
decomposing the word into ECC datawords.
3 Error injector injects errors into a given codeword ac-
cording to a configurable error distribution. We implement
support for data-retention errors as described in Section 4.3.
We provide configurable parameters for the spatial distribution
of true-/anti-cells (e.g., alternating per row) and the single-bit
probability of failure (i.e., RBER). Errors are injected uniform-
randomly across each bit that can fail (i.e., each “charged” cell
per the chosen true-/anti-cell layout and data pattern) using a
Bernoulli distribution with p equal to the desired RBER nor-
malized by the ratio of all cells that can fail, which ensures that
the simulated error rate meets the target RBER on average.
4 Error checker takes the pre- and post-correction words
as inputs and calculates a user-defined measurement (e.g., to-
tal number of bit-flips). This corresponds to an experimental
observable as explained in Section 4.2.
5.2. EINSim Validation
We validate EINSim using a combination of manual and
automatic unit tests. For the ECC model, we 1) provide
tests for detecting/correcting the right amount of errors
(exhaustively/sample-based for short/long codes); 2) hand-
verify the inputs/outputs of encoders/decoders where reason-
able; 3) hand-validate the generator/parity-check matrices
and/or code generator polynomials against tables of known
values (e.g., [18]); and 4) validate the minimum distance and
weight distributions of codewords. Due to the simplicity of
how we model the true-/anti-cell layout and data-retention er-
rors, we validate the error-injection correctness by 1) manual
inspection and 2) using summary statistics (e.g., distribution
of errors across many simulated bursts).
5.3. Applying EINSim to Experimental Data
To analyze data taken from a real experiment, we configure the
simulation parameters to match the experiment and simulate
enough read accesses (e.g., >105) to allow the distribution
of simulated measurements to numerically estimate the real
experimental measurements. This approach effectively solves
Equation 4 through Monte-Carlo simulation for any model
parameters {fi, θ} that can be simulated using EINSim.
Equation 4 across a wide range of model parameters {fi, θ}
Figure 1 in Section 1 provides several examples of evaluating
using a 256-bit input word programmed with a RANDOM data
pattern. The X-axis shows the pre-correction bit error rate
(BER), i.e., the RBER component of θ, and the Y-axis shows
the observed BER, which is computed by taking an expectation
value over the distribution resulting from solving Equation 4.
Curves represent different ECC schemes fi, and each data point
represents one simulation of 106 words, subdividing each word
into multiple ECC datawords as necessary.
We see that each ECC scheme transforms the pre-correction
For example, stronger codes (e.g.,
error rate differently.
REP(768, 256, 3), BCH(78, 64, 5)) dramatically decrease the
observed BER, whereas weaker codes (e.g., HSC(265, 256, 3))
have a relatively small effect. Interestingly, we see that many
of the codes actually exacerbate the error rate at high enough
pre-correction error rates because, on average, the decoder
mistakenly “corrects” bits without errors more often than not.
These examples demonstrate that different ECC schemes have
different effects on the pre-correction error distribution, and
Equation 9 exploits these differences to disambiguate schemes.
5.4. Inferring the Model Parameters
To infer the model parameters f and θ, which represent the ECC
scheme and pre-correction error distribution characteristics,
respectively, we need to perform the optimization given by
Equation 9. We do this using a grid search across f and θ,
simulating 104 uniformly-spaced error rates for each of several
different ECC schemes, data patterns and true-/anti-cell layouts.
While a denser grid may improve precision, this configuration
sufficiently differentiates the models we analyze (Section 7.3).
The solutions to Equation 9 are the inferred ECC scheme
and pre-correction error distribution characteristics that best
explain the experimental observations. From there, we can use
Equation 10 evaluated with the known ECC scheme in order to
determine θ for any additional experiments that we run (e.g.,
different error rates).
5.5. Inference Accuracy
MAP estimation rigorously selects between known models and
inherently can neither confirm nor deny whether the MAP esti-
mate is the “real” answer. We identify this as a limitation of EIN
in Section 5.8. However, in the event that a device uses a scheme
that is not considered in the MAP estimation, it would be ev-
ident when testing across different experimental conditions
and error rates since it is unlikely that any of the chosen ECC
schemes would be the single maximum-a-posteriori scheme
(i.e., best explaining the observed data) across all experiments.
We can also use confidence intervals to gauge the error in
each MAP estimate. This requires repeating the MAP estima-
tion over N bootstrap samples [25] taken from the observed
data O. The min/max or 5th/95th percentiles are typically taken
to be the confidence bounds.
5.6. Applying EIN to Other Systems
EIN can be extended to any ECC-protected communication
channel provided that we can induce uncorrectable errors
whose pre-correction spatial distribution follows some known
property (e.g., uniform-randomness). Examples include, but
are not limited to, DRAM rank-level (i.e., DRAM-controller-
19
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:57:59 UTC from IEEE Xplore.  Restrictions apply. 
level) ECC and other memory technologies (e.g., SRAM, Flash,
Phase-Change Memory).
5.7. Applying EIN to Data from Prior Studies
EIN is applicable to data presented in a prior study if the study
supplies enough information to solve Equation 10. This re-
quires that the study provides both: 1) the pre-correction error
characteristics, either directly as statistical distributions or im-
plicitly through the experimental methodology (e.g., device
model number, tested data patterns) and 2) the distribution
of errors amongst post-correction words as discussed in Sec-
tion 4.2. If these are known, EIN can infer both the ECC scheme
and the pre-correction error rates from the given data.
5.8. Limitations of EIN
EIN has three main limitations. However, in practice, these
limitations do not hurt its usability since both DRAM and ECC
design are mature and well-studied topics. We discuss each
limitation individually:
1) Cannot guarantee success or failure. As described in Sec-
tion 5.5, MAP estimation cannot guarantee whether the
correct solution has (not) been found. However, Section 5.5
describes how testing across different operating conditions
and using confidence intervals helps mitigate this limitation.
2) Requires knowledge and control of errors. Using EIN requires
i) knowing statistical properties of the spatial distribution
of pre-correction errors, and ii) the ability to induce uncor-
rectable errors. Fortunately, EIN can use any one of the many
well-studied, easily-manipulated error mechanisms that
are fundamental to DRAM technology (e.g., data retention,
RowHammer, reduced-latency access; see Section 4.3). Such
mechanisms are unlikely to change dramatically for future
devices (e.g., retention errors are modeled similarly across
decades of DRAM technologies [16, 29, 30, 35, 64, 77, 87, 127]),
which means that EIN will likely continue to be applicable.
3) Cannot identify bit-exact error locations. While EIN infers
pre-correction error rates, it cannot determine the bit-exact
locations of pre-correction errors. Unfortunately, since multi-
ple erroneous codewords may map to each visible dataword,
we are not aware of a way to infer error locations without
insight into the exact ECC implementation (e.g., algorithms,