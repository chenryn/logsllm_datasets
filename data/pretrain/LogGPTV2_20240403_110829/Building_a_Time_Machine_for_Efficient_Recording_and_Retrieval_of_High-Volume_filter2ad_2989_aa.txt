title:Building a Time Machine for Efficient Recording and Retrieval of High-Volume
Network Traffic
author:Stefan Kornexl and
Vern Paxson and
Holger Dreger and
Anja Feldmann and
Robin Sommer
for Efﬁcient Recording and Retrieval of High-Volume Network Trafﬁc
Building a Time Machine
Stefan Kornexl Vern Paxson Holger Dreger Anja Feldmann Robin Sommer
TU M¨unchen
TU M¨unchen
TU M¨unchen
ICSI / LBNL
TU M¨unchen
Abstract
There are times when it would be extraordinarily convenient to
record the entire contents of a high-volume network trafﬁc stream,
in order to later “travel back in time” and inspect activity that has
only become interesting in retrospect. Two examples are secu-
rity forensics—determining just how an attacker compromised a
given machine—and network trouble-shooting, such as inspect-
ing the precursors to a fault after the fault. We describe the design
and implementation of a Time Machine to efﬁciently support such
recording and retrieval. The efﬁciency of our approach comes
from leveraging the heavy-tailed nature of network trafﬁc: be-
cause the bulk of the trafﬁc in high-volume streams comes from
just a few connections, by constructing a ﬁlter that records only
the ﬁrst N bytes of each connection we can greatly winnow down
the recorded volume while still retaining both small connections
in full, and the beginnings of large connections (which often suf-
ﬁces).
The system is designed for operation in Gbps environments,
running on commodity hardware. It can hold a few minutes of a
high volume stream in RAM, and many hours to days on disk; the
user can ﬂexibly conﬁgure its operation to suit the site’s nature.
We present simulation and operational results from three distinct
Gbps production environments exploring the feasibility and efﬁ-
ciency of a Time Machine implementation. The system has al-
ready proved useful in enabling analysis of a break-in at one of
the sites.
1 Introduction
Network packet traces—particularly those with not only
headers but full contents—can prove invaluable both for
trouble-shooting network problems and for investigating
security incidents. Yet in many operational environments
the sheer volume of the trafﬁc makes it infeasible to capture
the entire stream or retain even signiﬁcant subsets for ex-
tended amounts of time. Of course, for both troubleshoot-
ing and security forensics, only a very small proportion of
the trafﬁc actually turns out to be pertinent. The problem
is that one has to decide beforehand, when conﬁguring a
trafﬁc monitor, what context will turn out to be relevant
retrospectively to investigate incidents.
Only in low volume environments can one rou-
tinely bulk-record all network trafﬁc using tools such as
tcpdump [2]. Rising volumes inevitably require ﬁltering.
For example, at the Lawrence Berkeley National Labora-
tory (LBNL), a medium-size Gbps environment, the net-
work trafﬁc averages 1.5 TB/day, right at the edge of what
can be recorded using commodity hardware. The site has
found it vital to record trafﬁc for analyzing possible secu-
rity events, but cannot retain the full volume. Instead, the
operators resort to a tcpdump ﬁlter with 85 terms describ-
ing the trafﬁc to skip—omitting any recording of key ser-
vices such as HTTP, FTP data, X11 and NFS, as well as
skipping a number of speciﬁc high-volume hosts, and all
non-TCP trafﬁc. This ﬁlter reduces the volume of recorded
trafﬁc to about 4% of the total.
At higher trafﬁc rates, even such ﬁltering becomes tech-
nically problematic. For example, the Munich Scientiﬁc
Research Network (M¨unchner Wissenschaftsnetz, MWN),
a heavily-loaded Gbps university environment, averages
more than 2 TB external trafﬁc each day, with busy-hour
loads of 350 Mbps. At that level, it is very difﬁcult to reli-
ably capture the full trafﬁc stream using a simple commod-
ity deployment.
A ﬁnal issue concerns using the captured data. In cases
of possible security compromise, it can be of great impor-
tance to track down the attacker and assess the damage as
quickly as possible. Yet, manually sifting through an im-
mense archive of packet traces to extract a “needle in a
haystack” is time-consuming and cumbersome.
In this work we develop a system that uses dynamic
packet ﬁltering and buffering to enable effective bulk-
recording of large trafﬁc streams. As this system allows us
to conveniently “travel back in time”, we term it a Time Ma-
chine. Our Time Machine buffers network streams ﬁrst in
memory and then on disk, providing several days of nearly-
complete (from a forensics and trouble-shooting perspec-
tive) historic data and supporting timely access to locate
the haystack needles. Our initial application of the Time
Machine is as a forensic tool, to extract detailed past in-
formation about unusual activities once they are detected.
Already the Time Machine has proved operationally useful,
enabling diagnosis of a break-in that had gone overlooked
at LBNL, whose standard bulk-recorder’s static ﬁlter had
missed capturing the relevant data.
Naturally, the Time Machine cannot buffer an entire
high-volume stream. Rather, we exploit the “heavy-tailed”
nature of network trafﬁc to partition the stream more effec-
tively (than a static ﬁlter can) into a small subset of high
interest versus a large remainder of low interest. We then
record the small subset and discard the rest. The key in-
sight that makes this work is that most network connections
are quite short, with only a small number of large connec-
tions (the heavy tail) accounting for the bulk of the total
volume [6]. However, very often for forensics and trouble-
shooting applications the beginning of a large connection
contains the most signiﬁcant information. Put another way,
given a choice between recording some connections in their
USENIX Association
Internet Measurement Conference 2005  
267
entirety, at the cost of missing others in their entirety; ver-
sus recording the beginnings of all connections and the en-
tire contents of most connections, we generally will prefer
the latter.
The Time Machine does so using a cutoff limit, N: for
every connection, it buffers up to the ﬁrst N bytes of trafﬁc.
This greatly reduces the trafﬁc we must buffer while retain-
ing full context for small connections and the beginning for
large connections. This simple mechanism is highly efﬁ-
cient: for example, at LBNL, with a cutoff of N = 20 KB
and a disk storage budget of 90 GB, we can retain 3–5 days
of all of the site’s TCP connections, and, using another
30 GB, 4–6 days for all of its UDP ﬂows (which tend to
be less heavy-tailed).
We are not aware of any comparable system for trafﬁc
capture. While commercial bulk recorders are available
(e.g, McAfee Security Forensics [3]), they appear to use
brute-force bulk-recording, requiring huge amounts of disk
space. Moreover, due to their black-box nature, evaluat-
ing their performance in a systematic fashion is difﬁcult.
Another approach, used by many network intrusion detec-
tion/prevention systems, is to record those packets that trig-
ger alerts. Some of these systems buffer the start of every
connection for a short time (seconds) and store them per-
manently if the session triggers an alert. Such systems do
not provide long-term buffers or arbitrary access, so they do
not support retrospective analysis of a problematic host’s
earlier activity. The Bro NIDS [5] can either record all an-
alyzed packets, or future trafﬁc once an incident has been
detected. Finally, the Packet Vault system was designed to
bulk record entire trafﬁc streams [1]. It targets lower data
rates and does not employ any ﬁltering.
We organize the remainder of the paper as follows. In
§ 2, we brieﬂy summarize the Time Machine’s design
goals. In § 3, we use trace-driven simulation to explore the
feasibility of our approach for data-reduction in three high-
volume environments. We discuss the Time Machine’s ar-
chitecture in § 4 and present an evaluation of its perfor-
mance in two of the environments in § 5. § 6 summarizes
our work.
2 Design Goals
We identiﬁed six major design goals for a Time Machine:
Provide raw packet data. The Time Machine should
enable recording and retrieval of full packets, including
payload, rather than condensed versions (e.g., summaries,
or just byte streams without headers), in order to prevent
losing crucial information.
Buffer trafﬁc comprehensively. The Time Machine
should manage its stored trafﬁc for time-frames of multi-
ple days, rather than seconds or minutes. It should not re-
strict capture to individual hosts or subnetworks, but keep
as widespread data as possible.
Prioritize trafﬁc. Inevitably, in high-volume environ-
ments we must discard some trafﬁc quickly. Thus, the Time
Machine needs to provide means by which the user can ex-
press different classes of trafﬁc and the resources associ-
ated with each class.
Automated resource management. From experience,
we know that having to manually manage the disk space as-
sociated with high-volume packet tracing becomes tedious
and error-prone over time. The Time Machine needs to en-
able the user to express the resources available to it in high-
level terms and then manage these resources automatically.
Efﬁcient and ﬂexible retrieval. The Time Machine
must support timely queries for different subsets of the
buffered data in a ﬂexible and efﬁcient manner. However,
its packet capture operation needs to have priority over
query processing.
Suitable for high-volume environments using com-
modity hardware. Even though we target large networks
with heavily loaded Gbps networks, there is great beneﬁt
in a design that enables the Time Machine to run on off-
the-shelf hardware, e.g., PCs with 2 GB RAM and 500 GB
disk space.
3 Feasibility Study
In this section we explore the feasibility of achieving the
design goals outlined above by leveraging the heavy-tailed
nature of trafﬁc to exclude most of the data in the high-
volume streams.
Methodology: To evaluate the memory requirements of a
Time Machine, we approximate it using a packet-buffer
model. We base our evaluation on connection-level logs
from the three environments described below. These logs
capture the nature of their environment but with a relatively
low volume compared to full packet-level data. Previous
work [7] has shown that we can use ﬂow data to approxi-
mate the data rate contributed by a ﬂow, so we can assume
that a connection spreads its total trafﬁc across its duration
evenly, which seems reasonable for most connections, es-
pecially large ones.
We evaluate the packet-buffer model in discrete time
steps, enabling us to capture at any point the volume of
packet data currently stored in the buffer and the growth-
rate at which that volume is currently increasing. In our
simplest simulation, the arrival of a new connection in-
creases the growth-rate by the connection’s overall rate
(bytes transferred divided by duration); it is decreased by
the same amount when it ﬁnishes. We then add the notion
of keeping data for an extended period of time by intro-
, which deﬁnes how
ducing an eviction time parameter, Te
long the buffer stores each connection’s data. In accordance
with our goals, we aim for a value of Te
on the order of days
rather than minutes.
268
Internet Measurement Conference 2005
USENIX Association
)
S
>
e
z
s
n
o
i
i
t
c
e
n
n
o
c
(
P
1
1
0
.
1
0
0
0
.
5
0
−
e
1
7
0
−
e
1
NERSC
LBL
MWN
Te = 3h, no cut−off
Te = 4d, 20kB cut−off
Te = 4d, 10KB cut−off
]
B
G
[
e
m
u