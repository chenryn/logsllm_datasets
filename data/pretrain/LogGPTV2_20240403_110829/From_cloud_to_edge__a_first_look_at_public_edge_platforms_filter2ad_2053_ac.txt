Enterprises
public
Old. Not publicaly available. Small scale.
/
Table 2: A comparison of cloud/edge workloads traces that are publicly available. We also explain why we choose Azure as the
cloud-side counterpart for head-to-head comparison in this work.
nearest edge
3rd-nearest edge
nearest cloud
all clouds
Nearest edge site
Nearest cloud site
)
s
m
(
T
T
R
80
70
60
50
40
30
20
10
0
WiFi
LTE
5G
(a) Median RTT across users.
1st-2nd-3rd hop
44.2%-10.3%-15.1%
10.2%-70.1%-9.4%
97.9% in total
Rest
52.5%
WiFi
25.2%
LTE
17.8%
5G
Table 3: Hop-level breakdown of network delay
Rest
30.2%
10.3%
2.1%
1st-2nd-3rd hop
30.1%-5.0%-11.5%
10.1%-51.6%-13.1%
82.2% in total
be more significant when 5G infrastructures become more widely
deployed and accessible to more end users.
We also analyze the average RTT and physical distance to the
nearest edge/cloud site across users based on their locations, i.e.,
whether they are co-located with an edge/cloud site in the same
city. The results are summarized in Table 4. In our experiments,
most users (69%) are not co-located with any edge/cloud site. In
such a circumstance, the average RTT is reduced from 34.97ms (to
the nearest cloud) to 22.37ms (to the nearest edge) with NEP, and
the geographical distance is reduced from 351km to 130km. The
reduction is much more significant when the users are co-located
with a NEP site but not a cloud site (18%), i.e., 47.06ms to 18.45ms.
For cases where users are co-located with both edge/cloud sites, we
find NEP edge can still improve the RTT. The reason is that NEP
deploys multiple sites in a few cities, e.g., Beijing, so that the users
in those cities can access nearer resources. In summary, while NEP
delivers lower network delay to end users through resources in
proximity, the benefits vary across different locations of endpoints.
Network jitter Many network-sensitive tasks like live stream-
ing are required to deliver consistent, predictable user experience.
To quantify the network jitter, we measure the RTT coefficient
of variation (CV for short, measured as stddev/mean) during our
repetitive tests (30 times) for each experiment. As illustrated in
Figure 2(b), edge platform has significantly lower RTT CV (i.e.,
higher stability) compared to cloud platform. Under WiFi/LTE/5G,
the median RTT CV is only 1.1%/2.3%/0.7% for the nearest edge
and 1.5%/3.2%/1.7% for the 3rd nearest edge. Taking the nearest
edge as baseline, the nearest cloud site has 5.8×/3.9×/5.7× higher
median RTT CV, and the average numbers across all sites can be up
to 30×. Such a low network jitter is critical to provide service-level
agreement (SLA) to edge customers.
Per-hop latency breakdown Table 3 illustrates the hop-level
breakdown of the end-to-end RTT. We highlight the latency of
the first 3 hops and combine the rest. For WiFi, the first wireless
hop contributes to 44.2%/30.2% of the end-to-end latency to the
nearest edge/cloud. For LTE, the second hop contributes the most
latency, e.g., 70.1% to the nearest edge. This is because the 2nd hop
contains the network delay accumulated from multiple physical
hops in the GTP-U tunnel, where data packets are encapsulated in
GTP Protocol Data Units and the hop count is not changed during
(b) RTT coefficient of variation (CV) across users.
Figure 2: The network delay (median RTT) and jitter (RTT
CV) from end users to edge/cloud sites.
Overall RTT Figure 2(a) illustrates the median RTTs across
users under different network types. Under WiFi, the median RTT
for the nearest edge site is 10.5ms, which is 1.89× (19.8ms) faster
than the nearest cloud site, and 3.4× (35.7ms) faster than all clouds
on average. The 3rd nearest edge site also provides smaller network
latency (15.5ms) than the nearest cloud. Under LTE, the overall
improvement decreases: the median latency for the nearest edge is
34.2ms, which is only 1.42×/1.93× faster than the nearest/all cloud
sites. The decreased latency reduction comes from that the first 2
hops of LTE network incur much higher latency than WiFi (47.8ms
vs. 9.0ms on average). We will give more details of hop-level latency
breakdown later in this section.
For 5G4, the median RTT of the nearest edge is only 10.4ms. Its
significant improvement over LTE mainly attributes to the flatten
architecture of 5G and the improved fiber fronthaul/backhaul [6,
97]. The improvement over all clouds is also tremendous (2.64×).
However, the improvement is much smaller (1.35×) compared to
the nearest cloud. We dig into our trace and find out that almost
all our 5G testing results are from Beijing due to very limited 5G
coverage in other regions in China. Since AliCloud also deploys
a site in Beijing, the difference in accessing NEP and AliCloud is
trivial. We expect the network improvement brought by NEP to
4In China, 5G network operates at 3.5 GHz frequency. Note that comparing 5G to LTE
is not the focus of this study, for which we refer readers to [73, 97].
41
IMC ’21, November 2–4, 2021, Virtual Event, USA
Mengwei Xu et al.
U/E/C
Locations
RTT (ms)
Nearest-E
RTT (ms)
Nearest-C
Dist (KM)
Nearest-E
Dist (KM)
Nearest-C
Figure 3: Hop numbers
Figure 4: Inter-site RTTs
the transmission [24]. Therefore, the “hop” latency is longer. Such
an observation is consistent with a recent measurement study [97].
For 5G, our collected trace doesn’t contain the latency of the first 2
hops, possibly because the ICMP service is disabled by the operator.
Instead, we report the latency of the first 3 hops in total, and find
they dominate the end-to-end latency, i.e., 98% for the nearest edge.
Note that, compared to cloud platforms, the current deployment
of NEP mainly reduces the inter-city transmission delay (i.e., the
backbone network). The traffic still needs to travel through the core
network within a city to reach the edges.
Hop number Figure 3 illustrates the number of hops between
end devices and edge/cloud servers, averaged across all network
types. It shows that the hop number to the nearest edge (5–12)
is much fewer than the clouds (10–16). The reduced hop number
leads to lower network latency and jitter. To further reduce the
hop distance, NEP needs to increase the site density and sink the
resources into the core network by collaborating with operators as
aforementioned.
Inter-site RTT We also measure the network latency between
NEP’s sites. We obtain the RTT between every site pair every 5
minutes in a day of June 2020, and average the results. Figure 4
illustrates the geographical distances (x-aixs) and network latency
(y-axis) between edge sites. Overall, the RTTs increase with the
inter-site distances, and reach 100ms when two sites are 3000km
away. More importantly, it shows there are many nearby edge
sites that have very low RTT, thanks to the deployment density
of NEP. For each site, there are 1/3/11 nearby sites that are within
5ms/10ms/20ms RTTs on average. It promises fine-grained resource
and user request scheduling between edge sites.
Implications NEP delivers noticeably lower and more stable
network delay for end users compared to AliCloud. Despite that, NEP
hasn’t fully reached the envisioned prospects of edge computing (even
with current 5G), e.g., sub-10ms delay and 1–2 hops distance to access
edge resources [51]. The last-mile hops (1st for WiFi and 2nd for LTE)
become the bottleneck of network delay. To step forward, NEP needs
to deploy denser sites and collaborate with operators to sink the edge
resources into ISP’s core networks or even cellular base stations, i.e.,
Mobile Edge Computing [12, 51].
3.2 End-to-end Network Throughput
Between a cloud/edge VM and a client, the network throughput
is bounded by the poorest link among them, e.g., the first hop for
wireless access as commonly believed. Based on the data collected
through crowdsourcing (§2.1.1), this section dives into the ques-
tion: how does the geographic distance (or hop number) affect the
10.96
18.45
22.37
15.64
47.06
34.97
0
0
130
U/E & U/C co-located (13%)
U/E co-located (18%)
None co-located (69%)
0
973
351
Table 4: Average RTT and physical distance to the near-
est edge/cloud server across different locations of users.
“U/E/C”: user, edge site, cloud site. “co-located” means the
user is in a city where at least one edge/cloud site is deployed.
When calculating the distance, we look at the geographic dis-
tance at city level. Numbers averaged across WiFi/4G/5G.
(a) Downlink throughput
(b) Uplink throughput
Figure 5: The TCP-based network throughput against ge-
ographical distance. Each point represents a 15-sec iPerf-
tested result. “corr” is the Pearson correlation coefficient (-1
to 1) between distance and throughput.
network throughput between end users and data centers. By an-
swering this question, we can learn whether or how edge platforms
like NEP can improve the network throughput compared to remote
clouds.
Figure 5 illustrates the overall results of our throughput testing.
The key observation is that, when throughput is low e.g., ≤100Mbps
for LTE and WiFi, the correlation between the distance and through-
put is negligible, as indicated by Pearson correlation coefficient
lower than 0.2 [28]. Noting that the 5G uplink bandwidth (mean:
52Mbps) is strictly capped by asymmetric time slot ratio in the ISP’s
configuration following Rel-15 TS 38.306 [24], thus its correlation
with distance is also negligible. Only when the throughput reaches
high, e.g., for 5G downlink (mean: 497Mbps) and wired access (mean:
480Mbps), the correlation becomes significant (corr>0.7). In such
cases, the throughput degrades observably as physical distance
increases. The reason is that, with LTE/WiFi access, the network
throughput is usually bounded by the bandwidth capacity at wire-
less hop, therefore has little correlation with the distance. When
the capacity is high, e.g., for 5G downlink, the bottleneck resides
at the Internet link which directly correlates with the distance (or
RTT [66]). It is also confirmed by our observations of the TCP con-
gestion window size and the packet loss rate during experiments.
Note that, to have perceivable benefits from the geographically
closer edge resources, two more factors need to be satisfied besides
the high bandwidth capacity: (1) Applications that can generate
high-volume traffic at more than 200Mbps. We find that few to-
day’s applications can do that: for example, streaming video at 4K
42
From Cloud to Edge: A First Look at Public Edge Platforms
IMC ’21, November 2–4, 2021, Virtual Event, USA
Edge
11.4ms
22.2ms
18.1ms
WiFi
LTE
5G
Cloud-1 Cloud-2 Cloud-3
16.6ms
25.6ms
22.8ms
55.1ms
63.2ms
60.8ms
40.9ms
54.6ms
49.5ms
Table 5: The RTTs of edge/cloud VMs used for QoE experi-
ments in §3.3, averaged across different locations.
resolution and 60FPS consumes only less than 100Mbps [27]. (2)
Equally-high or even higher bandwidth needs to be allocated to
the edge VMs so that the DC gateway doesn’t become the bottle-
neck. Such high bandwidth usage, however, can be prohibitively
expensive to developers.
Implications Bringing resources closer to users improves net-
work throughput on NEP only with high bandwidth capacity at the
last mile, e.g., for 5G downlink and wired access. Such an advan-
tage over cloud computing, however, is weakened by the absence
of ultra-bandwidth-hungry applications and the cost considerations
from developers’ perspectives. Given that, we conclude that improving
network throughput is not a primary incentive of current edge appli-
cations on NEP. In the future, however, we believe that the throughput
improvement will benefit more emerging, bandwidth-hungry edge
applications.
3.3 Application Performance (QoE)
This section presents the experiment results of application-level
QoE. Recall that (§2.1.1) we use one nearest edge VM and 3 cloud
VMs with different distances from the area where the experiments
are carried out. For reference, Table 5 shows the average RTTs to
those VMs in this experiment. For simplicity, we term the tests
as “Cloud-1/2/3” from the nearest to the farthest. Note that the
locations and resource characteristics of the servers are described
in §2.1.1.
3.3.1 Cloud Gaming. By hosting game execution and rendering on
backend servers, cloud gaming promises mobile devices the ability
to play games at a lower cost [58]. Cloud gaming systems have
stringent response delay requirements, as gamers may demand
less than 100ms response delay [36]. With cloud servers as the
backend, it is difficult for players to attain real-time interactivity in
the face of wide-area network latency. With much lower latency,
edge computing is expected to significantly improve the game
experience [21]. We now validate our cloud gaming systems built
with edge/cloud backend.
Metrics We follow prior work [53] to measure the end-to-end
performance as the interval between a player issuing a command