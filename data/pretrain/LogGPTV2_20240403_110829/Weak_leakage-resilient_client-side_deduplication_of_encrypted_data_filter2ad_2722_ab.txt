Table 1. Comparison of various cloud storage services.
Encryption
Server side enc
Client side enc
Convergent enc
Name
Dropbox
SpiderOak
Cross-User
No (See footnote 1)
No [35]
Yes
Deduplication
Yes
Yes
Yes
Wuala
1.2 Our results and contribution
1.2.1 Overview of proposed scheme
We brieﬂy describe the proposed client-side deduplication
scheme over encrypted ﬁles as below.
First Upload of File F . Suppose Alice is the ﬁrst user who
uploads a sensitive ﬁle F to the cloud storage. She will
independently choose a random AES key τ, and produces
two ciphertexts as below (See Figure 1): The ﬁrst ciphertext
CF is generated by encrypting ﬁle F with encryption key
τ using AES method, and the size of CF is almost equal
to the size of F ; the second ciphertext Cτ is generated by
encrypting the short AES key τ with ﬁle F as the encryption
key using some custom encryption method, and the size of
Cτ is in O(|τ|) which is very small.
Figure 1. The generation of large ciphertext CF and short
ciphertext Cτ .
Finally, Alice will send a hash value hash(F ) and two
ciphertexts (CF , Cτ ) to the cloud storage server. The cloud
storage server will compute the hash value hash(CF ), insert
a short entry (key = hash(F ); value = (hash(CF ), Cτ ))
into its lookup database, and store the potentially large ci-
phertext CF separately.
6 https://spideroak.com/
LongUserFileFShortSecretKeyτCiphertextCF=Encτ(F)CiphertextCτ=dEncF(τ)PlaintextPlaintextEncryptionKeyEncryptionKeySubsequent Upload of File F . Suppose another user Carol
tries to upload the same ﬁle F into the cloud, after Alice
has already uploaded F . Carol sends hash value hash(F )
to the cloud storage server, and the cloud storage server
ﬁnds a matched entry in its lookup database: (key =
hash(F ); value = (hash(CF ), Cτ )). Next, the cloud stor-
age server will send the short ciphertext Cτ to Carol. Carol
can decrypt Cτ using ﬁle F as decryption key and obtain the
secret AES key τ. Carol can encrypt her ﬁle F with AES key
τ to generate CF and send the newly computed hash value
hash(CF ) to the cloud storage server. The cloud will com-
pare Carol’s version of hash value hash(CF ) with the one
computed by itself. If the two hash values are equal, then
Carol is allowed to download CF from the cloud storage
from now on. If the two hash values are different, then with
overwhelming high probability7, either Alice has launched
a poison attack w.r.t. ﬁle F , or Carol is cheating, or both. If
Alice is honest, she can recover ﬁle F from the cloud, and
present ﬁle F as a proof; if Carol is honest, she can present
her local copy of F as a proof.
After this, assuming that both Alice and Carol are honest,
Carol may remove the local copy of ﬁle F if she likes and
keeps the AES key τ safely in local storage. Carol can
always recover ﬁle F by downloading the ciphertext CF
from the cloud and decrypting it with key τ.
1.2.2 Our Contributions
In this paper, we focus on cross-user client-side deduplica-
tion over users’ sensitive data ﬁles, and protect data privacy
from both outside adversaries and the honest-but-curious
cloud storage server. Our contributions in this paper can be
summarized as below:
• In Section 3, we propose a formulation for client-side
deduplication of encrypted ﬁles. Our formulation pro-
tects conﬁdentiality of users’ sensitive ﬁles against both
malicious outside adversaries and honest-but-curious in-
side adversaries. Furthermore, our formulation also pro-
tects an important type of partial information (particu-
larly, any physical bit F [i] at position i of ﬁle F ) of users’
sensitive ﬁles, although the nature of deduplication im-
plies that semantic-security is unachievable. In contrast,
the recent work by Ng et al. [28] does not protect partial
information and suffers from divide and conquer attack.
• In Section 4, we propose the ﬁrst secure (Deﬁnition 2)
client-side deduplication scheme of encrypted ﬁles in the
bounded leakage setting. We prove its security against
malicious outside adversaries and honest-but-curious in-
side adversaries and with respect to any distribution of
user ﬁle in Theorem 1. In contrast, the PoW schemes by
Halevi et al. [20] only deals with outside adversaries, and
their most practical construction is only proved secure
7 Except the negligibly rare case that a collision of the hash function is
found.
against a particular type of distribution of user ﬁle and
their proof (in random oracle) relies on an untypical as-
sumption (More details are given later in Section 2).
Our scheme can be applied for deduplication of sensitive
ﬁles that have very low min-entropy due to a one-time leak-
age. It is worth pointing out our leakage setting is weaker
than Halevi et al. [20], so that our scheme achieves a weaker
goal in this aspect and allows exposure of the whole ﬁle by
leaking a short string (rather than account id/password) in
the strong leakage setting of Halevi et al. This weakness has
been resolved in our full paper [42].
The next Section 2 briefs the background and discusses
related works. Experiment result is reported in Section 5.
Section 6 concludes this paper.
2. Related works
2.1 Pairwise-Independent Hash Family
A hash family {Hk : M → {0, 1}L} is pairwise-independent
(or say universal hash [8, 38]), if for any two distinct inputs
x1, x2 ∈ M, Prk[Hk(x1) = Hk(x2)] = 2−L.
2.2 Works on Secure Deduplication before PoW
Deduplication of encrypted ﬁles have been studied since the
design of convergent encryption by Douceur et al. [14]. To
the best of our knowledge, all existing works (e.g. [3, 14, 24,
36]) before Halevi et al. [20] do not consider leakage setting
and most of them focus on server-side deduplication.
2.3 Proofs of Ownership
To prevent private data leakage to outside adversary, Halevi et
al. [20] proposed a notion of “proofs of ownership” (PoW).
In a PoW scheme, any owner of a ﬁle F , without necessar-
ily knowing other owners of F , can efﬁciently prove to the
cloud storage server that he/she owns the ﬁle F ; any out-
side adversary cannot prove that he/she has the ﬁle F with
probability larger than a predeﬁned threshold, even if a cer-
tain amount of efﬁciently-extractable information of ﬁle F
is leaked to the adversary. Such leakage may occur at any
time except during the course of interactive proof between
the cloud storage server and the cloud user.
Halevi et al. [20] proposed three constructions. The
ﬁrst construction encodes a ﬁle using some error erasure
code, and then applies the standard Merkle Hash Tree proof
method over the encoded ﬁle. The second construction is
a generic framework. Let Hk : {0, 1}M → {0, 1}L be
any pairwise independent hash family. Given a ﬁle F of
M bits long, the second construction computes the hash
value Hk(F ) with a public randomness k as hash key
and applies the standard Merkle Hash Tree proof method
over the L bits value Hk(F ). The third construction is
the most practical one. It designs an efﬁcient hash family
k : {0, 1}M → {0, 1}L and applies the standard Merkle
H
(cid:48)
Hash Tree proof method over H
k(F ). However, their con-
(cid:48)
k is not pairwise-independent (even if in the
struction of H
(cid:48)
random oracle model). Consequently, the generic framework
in the second construction cannot apply and a new secu-
rity proof is required. As the authors explicitly mentioned,
Halevi et al. [20]’s security proof for their third construc-
tion has some limitations: (1) the proof assumes that the
ﬁle F is sampled from a particular type of distribution (a
generalization of “block-ﬁxing distribution”); (2) the proof
is given “under the unproven assumption that their scheme
will generate a good code” (See text around Theorem 3 in
their paper [20] ); (3) the proof is given in random oracle
model, where SHA256 is treated as a random function.
2.4 Extremely Efﬁcient but Less Secure “PoW”
Very recently, Pietro and Sorniotti [32] proposed an efﬁcient
“PoW” scheme: They use the projection of the ﬁle F onto
K 8 randomly selected bit-position i1, . . . , iK as the “proof”
of ownership of the ﬁle F , that is, the knowledge of bit-string
F [i1](cid:107) . . .(cid:107)F [iK] is a “proof” of ownership of ﬁle F .
This scheme is extremely efﬁcient. However, this work [32]
has at least these limitations: (1) it does not protect privacy
against honest-but-curious cloud storage server; (2) it is se-
cure only if the min-entropy of ﬁle F to the view of adver-
saries is close to the bit-length of ﬁle F , after the leakage
occurs.
2.5 Existing Plausible Attempt for Privacy-Preserving
PoW
Recently, Ng et al. [28] made an attempt to support PoW
over encrypted ﬁles. Their method encrypted ﬁles on client
side and shared the encryption key among a group of
users who know each other. Their method applies exist-
ing scheme [12] to do key management within the group,
and focus on formulating and devising proofs of ownership
scheme in a privacy preserving manner.
Here we brief their PoW scheme as below: A ﬁle is di-
vided into many blocks xi’s, and a commitment ci is com-
puted from each xi under a secret key. Then the standard
Merkle Hash Tree method applies over the commitments
(c1, c2, . . .). After the completion of Merkle Hash Tree proof
protocol, the veriﬁer knows some commitment value ci, and
the prover has to show that he/she has the knowledge of
some secret value xi whose commitment is ci, without re-
vealing information on xi to the veriﬁer.
We observe that their proof of knowledge of xi against ci
is similar to the generalized Okamoto-Identiﬁcation scheme
[30], given by Alwen et al. [1]. This proof of identiﬁcation
scheme allows the veriﬁer to efﬁciently decide whether the
secret value xi is equal to any given candidate value x, thus
allows brute-force search of x.
In summary, Ng et al. [28]’s PoW scheme has the follow-
ing limitations: (1) it is very slow in computation: in every
execution of the proof protocol, to generate all commitment
8 K is a system parameter. In their experiment [32], K takes values in the
range [100, 2000].
values ci’s, |F|/1024 number of exponentiations9 in a mod-
ulo group of size ≈ 21024 are required where |F| denotes the
bit-length of ﬁle F ; (2) the encryption key is shared among
a group of “friends”, which is not suitable for client-side
deduplication over encrypted ﬁles, since in current typical
client-side duplication setting, owners of the same ﬁle will
be anonymous to each other; (3) it suffers from “divide and
conquer attack” mentioned previously in Section 1.1.3, al-
though (i) it is provably privacy-preserving under their for-
mulation [28] and (ii) it is applied in ﬁle-level instead of
block-level.
In an extreme example, a large ﬁle F with L(≥ λ)
bits min-entropy to the view of the curious cloud server
is divided into L blocks xi’s where each xi has exactly 1
bit min-entropy to the view of the curious cloud server. If
Ng et al. [28]’s method is applied over such a ﬁle F , then
the honest-but-curious cloud server could learn everything
of the ﬁle efﬁciently in time O(L) instead of O(2L) during
the proof process, by brute-force searching of the value of
each xi independently. In contrast, if the proposed scheme in
this paper applies over the same ﬁle F , any efﬁcient curious
cloud server or outside adversary cannot recover the ﬁle and
cannot obtain the bit value F [i] at any bit-position i in ﬁle
F , assuming F [i] was unknown to adversaries before the
execution of the proof protocol.
Another recent work [43] combines proofs of storage (i.e
POR [9, 23, 33, 41] and PDP [4]) with proofs of owner-
ship. However, this work [43] fails to fulﬁll the efﬁciency
requirement on server side given by Halevi et al. [20], not to
mention privacy protection of user data against the curious
server.
It is worth noting that, after our work (the full version [42]
of this paper), a very recent independent work by Bellare et
al. [7] contains a scheme called “Randomized Convergent
Encryption” (RCE), which has encryption part essentially
identical to the encryption part of our scheme. However,
Bellare et al. does not consider any leakage setting.
3. Security Model
In this section, we propose a security formulation for client-
side deduplication of encrypted ﬁles.
3.1 System Model and Trust Model
3.1.1 Cloud Storage Server
Cloud Storage Server (Cloud Server or Cloud for short) is
the entity who provides cloud storage service to various
users. Cloud Storage Server has a small and fast primary
storage and a large but slow secondary storage. Although the
computation power (CPU, I/O, network bandwidth, etc) of
Cloud Storage Server is much stronger than a single average
9 One such group exponentiation requires more than 3 milliseconds in a
model PC, which means that it requires more than 3000 seconds to generate
all commitments for a ﬁle of size 1 giga-bits. Such expensive operation will
be executed every time when a user tries to upload the same ﬁle to the cloud.
user, the average computation power per each online user
is usually very limited. We assume that the small and fast
primary storage is well-protected from outside adversaries,
and the large but slow secondary storage could be visible to
outside adversaries.
An example of cloud storage server is Dropbox. Users’
ﬁles uploaded to Dropbox are actually stored in Amazon’s
S3 data center (i.e. Dropbox’s secondary storage) and Drop-
box only runs relatively small server to manage meta data
(i.e. Dropbox’s primary storage). Another cloud storage ser-
vice provider Wuala stored users’ ﬁles in P2P network (the