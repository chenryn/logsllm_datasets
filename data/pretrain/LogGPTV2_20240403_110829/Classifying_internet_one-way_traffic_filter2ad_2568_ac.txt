bogon. We use the sign retry to address the situation
where a host re-uses the same 5-tuple for a connection
retry by canceling the TCP TIME WAIT state through
non-standard conﬁguration of the socket interface.
4.2 Classiﬁer
A class is associated with one or more rules. We
deﬁne the following classes:
• Service Unreachable: access attempt to tempo-
rary unavailable services.
• Malicious Scanning: probing for the exploita-
tion of vulnerabilities in end systems.
• Benign P2P: P2P applications trying to access
peers in their local host cache that are not anymore
available.
• Backscatter: replies to DoS attack traﬃc that
uses randomly chosen source IP addresses to hide
the real identity of an attacker.
• Suspected Benign: one-way ﬂows may exist as
part of benign applications using data and control
connections in parallel and employing one of them
for acknowledgment only. Another cause may be
temporary failures within an otherwise productive
communication.
• Bogon: one-way ﬂows originating from bogon IP
space.
• Other: one-way ﬂows that do not match any of
the above classes.
We carefully design our classiﬁcation rules with a sys-
tematic process shown in Figure 3. We start with an
initial set of rules and in each iteration we classify ﬂows,
compute a conﬂict report of the resulting classiﬁcation
and update the rules. The conﬂict report describes ﬂows
classiﬁed in multiple classes. Speciﬁcally, it reports: 1)
the classes that intersect; 2) the size of the intersec-
tions; 3) a list of sign combinations in the intersections
ordered by their popularity; and 4) the number of re-
maining unclassiﬁed ﬂows. Based on the conﬂict report
6
Figure 3: Rule reﬁnement stages
and in particular the sign combinations, we then man-
ually update the rules to resolve conﬂicts and to reduce
the number of unclassiﬁed ﬂows. Each ﬂow is checked
against 18 diﬀerent signs, which in theory yields a max-
imum of 262,144 possible sign combinations. However,
most combinations do not occur in practice.
In our
data, we observe a total of 1,035 diﬀerent sign combi-
nations. Moreover, one could ignore sign combinations
that are only observed in a small number of ﬂows re-
sulting in a sharp reduction on the number of interest-
ing combinations. We iteratively repeat this procedure
until we resolve all conﬂicts and cannot further signif-
icantly reduce the number of unclassiﬁed ﬂows. Based
on the described procedure we derived a ﬁrst version of
our classiﬁcation rules after eight iterations. Then, we
further reﬁne our rules based on our validation. The
ﬁnal classiﬁer includes 17 classiﬁcation rules shown in
Table 3.
The classes “Malicious Scanning” and “Suspected Be-
nign” employ multiple rules with diﬀerent contribution
to the overall class results. Based on our data, we
see two rules that contribute most to the class “Ma-
licious Scanning”. In particular, rules 3 and 4 match
73.5% and 10.2% of the ﬂows in this class, respectively.
The high value of rule 4 is surprising as this rule con-
tains two seemingly conﬂicting signs (TRWnom and
HCscan). This indicates that the TRW algorithm rates
some sources too optimistic as being nominal. The re-
maining rules account for 9: 5.8%, 7: 5.4%, 6: 2.0%, 8:
1.6%, 2: 0.9%, 5: 0.5% and 1: 0.3%. In the class “Sus-
pected Benign” the major contributor is rule 15 with
56.9%, followed by rule 13 with 24.0%, rule 16 with
16.7% and rule 14 with 2.4%. We discuss the accuracy
of our ruleset in Section 5.
Our classiﬁer processes input ﬂows in three passes. In
a ﬁrst pass it initializes local services, local P2P hosts
and inactive local IP addresses. In a second pass match-
ing signs are assigned to ﬂows and in a ﬁnal pass rules
are applied to account each ﬂow to a unique class. We
have implemented our classiﬁer in C++ and run it on
a dedicated Linux cluster with a fast RAID disk sub-
system. We collect logs of the overhead of the three
passes combined for all 16 runs. In general, the over-
Initial, revised RulesClassificationIntersection Empty?Rule RefinementConflict  reportNoValidationSatisfied?Final RulesRule Refinementalpha/beta RulesNoYesYesClass Name
Rule # Flow Membership Rules
Malicious
Scanning
Backscatter
Service
Unreachable
Benign P2P
Scanning
Suspected
Benign
Bogon
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
{T RW scan, HCscan, P otOk} ⇒ Scanner
{HCscan, T RW scan, T RW nom, P otOk} ⇒ Scanner
{T RW scan, HCscan, P otOk} ⇒ Scanner
{T RW nom, HCscan} ⇒ Scanner
{GreyIP, Onepkt, T RW scan, HCscan, Backsc, ICM P , U DP , bogon} ⇒ Scanner
{GreyIP, T RW scan, HCscan, Onepkt, ICM P , Backsc, bogon} ⇒ Scanner
{Onepkt, GreyIP , ICM P , T RW scan, HCscan, T RW nom, bogon, P 2P , U nreach, P otOk, Backsc, Large} ⇒ Scanner
{GreyIP, Onepkt, T RW scan, HCscan, Backsc, ICM P , T CP , bogon} ⇒ Scanner
{ICM P, T RW scan, T RW nom, HCscan, InOut, bogon, P otOk} ⇒ Scanner
{Backsc, T RW scan, HCscan, P 2P , InOut, P otOk} ⇒ Backscatter
{U nreach, T RW scan, HCscan, bogon, P 2P} ⇒ U nreachable
{P 2P, T RW scan, HCscan, bogon} ⇒ P 2P
{P otOk, U nreach, P 2P , T RW nom, bogon} ⇒ Benign
{Large, GreyIP , T RW scan, HCscan, P 2P , U nreach, P otOk, ICM P , Backsc, bogon, T RW nom} ⇒ Benign
{T RW nom, GreyIP , HCscan, P 2P , U nreach, bogon, Backsc} ⇒ Benign
{ICM P, InOut, T RW scan, HCscan, T RW nom, bogon, P otOk} ⇒ Benign
{bogon, T RW scan, HCscan, Backsc} ⇒ Bogon
Table 3: Rules used to classify one-way ﬂows. Each rule speciﬁes which signs have to be present or
absent (sign names with overbars). An overview of deﬁned signs can be found in Table 2.
head scales with the size of the dataset, but also de-
pends on dataset characteristics. On average a run
processed 28.6 gigaﬂows in 23.1 hours (with a maxi-
mum of 37.4 hours) and required 3.4 GB of memory
(with a peak of 6.1 GB). Considering the monitoring
period length of 400 hours these ﬁgures are well within
real-time bounds. Note that we exclude the overhead
for preprocessing (time binning, ﬂow defragmentation,
biﬂow-pairing) as it largely depends on the available
input data (e.g. NetFlow export or YAF-created ﬂow
records). On our NetFlow records the preprocessing re-
quired the most resources while still safely remaining
within real-time bounds.
Our classiﬁcation scheme has one parameter that needs
conﬁguration: the time window size used for P2P and
services identiﬁcation and for scanner detection. We set
it by default to 30 minutes, but on a smaller network
the window size should be increased (see also Section 5).
5. VALIDATION
In this section we evaluate the accuracy of our clas-
siﬁer and optimize its rule set. Validating an one-way
traﬃc classiﬁcation scheme is very challenging. A major
challenge is the scarcity of information available from
one-way traﬃc consisting of very short ﬂows carrying
few packets and frequently no payload. We address this
challenge, ﬁrst, by building more accurate host proﬁles
based on ﬂows over long time windows, second, by care-
fully examining one-way packets for violation of relevant
protocol state machines, and third, by exploiting DPI
and application identiﬁcation techniques.
We ﬁrst use a traﬃc summarization technique [5]
based on frequent item-set mining (FIM) to summarize
ﬂows of diﬀerent classes into frequent item-sets, which
can be then easily inspected by an analyst. We ap-
ply this approach in each class and measurement pe-
riod between 2004 and 2011. In summary, we ﬁnd that
for diﬀerent classes and periods up to 75% of the ﬂows
were correctly classiﬁed. However, with this approach
we cannot assess the remaining ﬂows and the number
of false negatives.
Realizing a thorough evaluation solely with ﬂow data
is challenging, as we miss information like TCP ﬂag and
ICMP types/codes. A validation of one-way traﬃc clas-
siﬁcation solely based on ﬂow data provides insuﬃcient
evidence. For this reason, we built a dedicated valida-
tion setup in a smaller network to obtain more detailed
data.
5.1 Validation Setup
We built a monitoring setup and collected packet
traces at the Internet gateway of the swiss university
Hochschule f¨ur Technik Rapperswil (HSR) occupying a
/16 IP range. The campus network is sparsely pop-
ulated with a total of 3,949 active IP addresses seen
during our experiment. We use a dedicated host that is
tapping traﬃc between the border router and the ﬁre-
wall. On the ﬁrewall no ﬁltering is activated, enabling
us to see all traﬃc routed to this IP range. To reliably
collect packet data, we use an Endace DAG card that
provides exact packet timestamps. Mandated by the
IT security policy, we anonymize all IP addresses using
a preﬁx-preserving scheme. Note that anonymization
does not allow us to use active probing for our valida-
tion as proved to be useful in [24].
We collected packet traces for 19 consecutive days
and extracted ﬂows using the YAF ﬂow meter [13] con-
ﬁgured for bidirectional ﬂow export. We then split
ﬂows into 10-minute intervals and defragmented ﬂows
within each interval resulting in a total of 322.7 mio
ﬂows, which include 219.6 mio (68.1%) incoming one-
way ﬂows, 8.06 mio outgoing one-way ﬂows (2.5%) and
95.1 mio two-way ﬂows (29.5%). The small fraction of
two-way ﬂows can be explained by the scarce popula-
7
tion of the monitored network. We retain packet data
for a sub-period of three randomly chosen days.
To obtain application labels we conﬁgured YAF with
its optional DPI application identiﬁcation feature that
assigns application labels to ﬂows it recognizes. How-
ever, the coverage achieved by YAF is limited. Thus,
we used an additional DPI application identiﬁer to add
a second set of application labels for almost all ﬂows.
This additional DPI application identiﬁer originally was
developed to evaluate the BLINC classiﬁer [18] and in
an improved version to evaluate several competing ap-
proaches to application identiﬁcation [19].
To learn more on the occurrence of one-way ﬂows
using bogus source IP addresses we periodically down-
loaded the full bogon list provided by [8] throughout
the data collection process. This list not only contains
the oﬃcial IANA-reserved address ranges, but includes
all IP ranges assigned to regional registrars that have
not yet been handed out to costumers.
5.2 Validation Criterias
To determine class memberships we build a DPI clas-
siﬁer that uses an extensive set of 34 rules that make
heavy use of details available only from packet-level
data. In the following paragraphs, we summarize the
key additional information we extract from the packet-
level data and how we exploit it. Then, we provide more
details on detecting the diﬀerent classes.
Extended Host Proﬁles: For each host, we main-
tain an extended host proﬁle over a full observation pe-
riod of 457 hours (19 days) that tracks successful and
failed connections. We use extended host proﬁles in the
TRW algorithm and, in combination with application
identiﬁcation, for identifying P2P hosts and local ser-
vices. This is feasible in a /16 network, i.e., it required
12 GBytes of memory for 10.2 mio extended host pro-
ﬁles, but does not scale reasonably for larger networks.
ICMP types and codes: For ICMP ﬂows, we ana-
lyze if type and code information and the communica-
tion situation of the involved host pair ﬁt a class. For
example, we deem a ﬂow as backscatter if it is an echo
reply and the receiver never sent a request to the sender.
In addition, we check if the source of an ICMP ﬂow is
not already identiﬁed as a scanner, which interestingly
is true for more than 92.1% of all incoming one-way
ICMP ﬂows.
Protocol State Machine: As an additional way to
identify malicious scan traﬃc, we analyze how well in-
dividual ﬂows follow the transport layer protocol state
machine. Malformed packets are frequently used to ex-
ploit weaknesses of protocol stacks or to penetrate non-
stateful ﬁrewalls. For TCP ﬂows, we test if the ﬂags
of consecutive packets ﬁt into acceptable state changes
in the TCP protocol machine and run sanity checks on
the sequence numbers of segments.
Application Identiﬁcation: We apply application
identiﬁcation techniques [13, 18, 19] on two-way ﬂows
to discover local services and to detect hosts running
P2P applications.
Precise Timestamps: We rely on packets times-
tamps to identify the initiator of a connection, which
is not possible using NetFlow timestamps. Initiator de-
tection is useful in combination with DPI and extended
host proﬁles for mapping local services.
The rules used for validation and the corresponding
DPI-based signs are described in Tables 4 and 5, re-
spectively.
In the next few paragraphs, we provide a
summary of the rules of each class.
5.2.1 Class ‘Malicious Scanning’
For a scanner detection, we rely on the TRW algo-
rithm which we conﬁgure for an upper bound on false
positives of 0.5% and a IP population degree of 20
We counted a total of 10.2 mio unique IP addresses
outside of our network during the 457 hours: 8.50 mio
are pure sources of one-way ﬂows, 1.22 mio are involved
in two-way ﬂows only, and 0.446 mio external hosts have
both one- and two-way ﬂows. Dissecting the group hav-
ing one-way ﬂows only we get 7.62 mio external hosts
involved in inﬂows, 0.628 mio involved in outﬂows and
a remaining group of 0.254 mio hosts involved in both
types of one-way ﬂows. Finally, we observe an almost
linear growth of the number of unique external IP ad-
dresses over time, showing only a small decrease of the
growth rate after two-third of the observation period.
This indicates that scanner frequently change their IP
address and/or use a high count of randomly chosen
spoofed IP addresses for a decoy scanning that hides
the real source behind faked source addresses.
As an additional way to identify malicious scan traﬃc
we analyze how well individual ﬂows follow the trans-
port layer protocol state machine by inspecting arriv-
ing packets. This criterion is based on the fact that
malformed packets frequently are used to exploit weak-
nesses of protocol stacks or to penetrate non-stateful
ﬁrewalls. For TCP ﬂows we test if the ﬂags of consec-
utive packets ﬁt into acceptable state changes in the
TCP protocol machine and run sanity checks on the
sequence numbers of segments. For UDP ﬂows we can-
not gain much insight from the protocol state mache.
Thus, we just test if a packet has no payload to detect
simple UDP scans. In the case of ICMP traﬃc, we in-
spect the ICMP type and code information picked from
the packet header. Depending on the type information,
we can distinguish between ICMP query and error mes-
sages. But, it is hard to draw conclusions from this in-
formation as almost any kind of ICMP messages is pop-
ular for scanning including ICMP destination port un-
reachable messages [10]. We classify unanswered ICMP
requests as scan ﬂows without further checks. For other
one-way ICMP ﬂows, we evaluate for each ﬂow the com-
munication situation of the host pair involved (e.g., is
this ICMP ﬂow an answer to a UDP ﬂow?) and also
check if the ﬂow source is not already identiﬁed as a
scanner, which is true for more than 92.1% of all in-
coming one-way ICMP ﬂows. Otherwise, if we see that
there are solely inﬂows exchanged between a host pair,
then we classify an ICMP ﬂow as backscatter.