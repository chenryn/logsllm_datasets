are diﬃcult to generate with random walks over grammar
459space, thus a brute force approach is ineﬃcient. Therefore,
code templates (see Section 2.5.2) are used to reconstruct
the source code just one step before compilation.
Valid context Source ﬁles with proper structure and
grammar still contain undeﬁned variables, functions, class-
es, etc., and are thus still uncompilable. This is addressed
by mutating the source code during the mutation phase (see
Section 2.5) with real classes, API functions and predeﬁned
variables that are extracted from runtime libraries of the
AVM.
2.3.2 Generation of nearly-valid code snippets
One possible approach for fuzzing AVMs based on gram-
mar involves randomly generating source code that follow
the grammar structure. However, na¨ıve random walks over
grammar rules are not guaranteed to terminate. Referring
to the idea of LangFuzz [19], we bring an end to the ran-
dom walk code generation process using instances of gram-
mar rules learnt from known test suites. This is a good
start, but in contrast to LangFuzz, it is not the ﬁnal step be-
fore code execution. Furthermore, we enhance LangFuzz ’s
idea by incorporating both depth-ﬁrst and breadth-ﬁrst al-
gorithms into ScriptGene, as described in algorithm 1. The
Algorithm 1 ActionScript code generation
Input:
A decision of sub-rule selection, seednum;
Output:
Nearly-valid code snippets, codearray;
1: Initialize codearray as [startrulenode];
2: Initialize the sub-rule selection based on seednum using
a deterministic-random algorithm;
3: while (Number of active nodes and number of genera-
4:
5:
6:
7:
8:
tion cycles are still low) do
for each node in codearray do
if node is not an active node then
Remain node unchanged;
else
Replace node with expanded nodes using
breadth-ﬁrst/depth-ﬁrst algorithms of sub-rule s-
elections;
end if
9:
10:
end for
11: end while
12: for each node in codearray do
13:
14: end for
15: return codearray;
Replace node with rule instances of its type;
AS code is generated on a per-cycle basis. Each cycle of gen-
eration expands the nodes inside the codearray. Iteration is
used instead of recursion, since determination of possible
code length and number of nodes are more convenient with
iteration. These important parameters control the termina-
tion of the code generation phase.
Each level of expansion is done on active nodes. The type
of the node determines if a node is active or not. In ﬁgures
2, 4 and 3, each circle represents a node, while the char-
acter inside states the content. A given node is a NULL
atom if the node is blank (previous level of expansion has
randomly chosen zero for the quantiﬁers or optional). The
quantiﬁers (‘*’,‘+’) and optional (‘?’) are stored without
any simpliﬁcations and will be replaced by a random num-
ber in its valid range during code generation. This is also
diﬀerent from LangFuzz [19]. Before a level of expansion,
the nodes in the codearray are scanned and a hierarchy is
established for each cycle: rule->block->atom. During each
cycle, only the highest hierarchy item is set active. This
ordered expansion is more eﬀective and intuitive when we
need to examine the generation process. Both ordered and
non-ordered expansion processes are illustrated in ﬁgures 2
and 4 for comparison. In a non-ordered expansion process,
such as illustrated in ﬁgure 2, diﬀerent structures will in-
evitably begin to embed each other (a block inside a block,
an atom inside a block embedded further inside a rule, ex-
tended from an atom. . . ). Additionally, expansion cycles
may be wasted on extending structures that will eventual-
ly become NULL (the left branch of ﬁgure 2, for example).
Therefore, the ordered process as depicted in ﬁgure 4 is our
node expansion approach. Although ﬁgure 4 appears to
Figure 2: Node expansions in random order.
Figure 3: Left branch represents a depth-ﬁrst sub-
rule selection. Right branch represents a breadth-
ﬁrst sub-rule selection.
depict a breadth-ﬁrst algorithm, it is not. Breadth-ﬁrst or
depth-ﬁrst algorithms apply to the selection of sub-rules.
Rules consist of sub-rules, separated by “j” in ANTLR such
as “Rule S: a j b j c”. Rule “S” can be selected as “a”, “b”
(cid:53)(cid:88)(cid:79)(cid:72)(cid:36)(cid:87)(cid:82)(cid:80)(cid:37)(cid:79)(cid:82)(cid:70)(cid:78)S: (a b)? (c d)*a: (cid:254)-(cid:255)    b: (c a)+c: (cid:254).(cid:255)d: c? | a?(cid:54)(cid:11)(cid:68)(cid:3)(cid:69)(cid:12)(cid:34)(cid:11)(cid:70)(cid:3)(cid:71)(cid:12)(cid:13)(cid:11)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:12)(cid:13)(cid:70)(cid:11)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:12)(cid:13)(cid:68)(cid:34)(cid:11)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:12)(cid:34)(cid:11)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:12)(cid:34)(cid:16)(cid:68)(cid:11)(cid:70)(cid:3)(cid:68)(cid:12)(cid:14)(cid:70)(cid:68)(cid:70)(cid:71)(cid:70)(cid:68)(cid:34)(cid:70)(cid:68)(cid:34)(cid:17)(cid:17)(cid:68)(cid:17)(cid:17)(cid:16)(cid:53)(cid:88)(cid:79)(cid:72)(cid:36)(cid:87)(cid:82)(cid:80)S: a | b | c(cid:54)(cid:68)(cid:54)(cid:68)(cid:54)(cid:68)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:54)(cid:68)(cid:54)(cid:69)(cid:54)(cid:70)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)(cid:17)460or “c”. Our breadth-ﬁrst method is a random selection a-
mong sub-rules, whereas our depth-ﬁrst method holds on to
the initial selection at the beginning of the code generation
phase (see line 2 of algorithm 1). Figure 3 demonstrates the
diﬀerence between breadth-ﬁrst and depth-ﬁrst algorithm-
s. Our breadth-ﬁrst method is similar to that used by [19].
Depth-ﬁrst algorithm was added, based on results of our
previous testings of the regular expression interpreter [31].
This addition enables us to test AVMs with nested grammar
structures. The idea is akin to sending a “((((((expr))))))”,
to test the expression interpreter. Nested structures appear
to be validated with less caution and return more bugs. In-
tuitively, to cover more grammar rules, breadth-ﬁrst algo-
rithms need longer code lengths, while depth-ﬁrst algorithms
need more generation cycles with diﬀerent sub-rule initial-
izations. To terminate the code generation process as in line
Figure 4: Node expansions following the rule, block,
atom order.
13 of algorithm 1, we study code fragments (which are es-
sentially examples for non-terminals in grammar rules and
in our case, are instances of rules) from the AVM test suite
in Tamarin [12], which is an open-source AVM project under
Mozilla. The AS source code is taken from their acceptance
test cases and dissected into pieces then categorized based
on their rule types. A sample code fragment pool is built
after parsing the test suite with the help of G1, in which
there are several instances for each rule. The G1 grammar
ﬁle originally belongs to a plug-in for Eclipse, intended to be
part of a syntax highlighter function. It is imperfect when
handling large assortments of code fragments. Since some
parsed results may contain faults, the pool requires manual
ﬁxes. In addition, G2 is a modiﬁed version of G1, not all of
the rules ﬁnd their instances from this test suite. Thus, the
missing ones are added manually.
2.4 Extraction of runtime information
After creating nearly-valid AS code snippets, all the iden-
tiﬁers pointing to labels, functions, variables and types are
marked with the AS lexier. Some of these will be replaced
with runtime classes, properties and API functions of the
AVM, while others need modiﬁcations to suit the current
context. A knowledge base is built for this purpose, con-
taining the relevant runtime class information of the AVM.
Runtime class information can be obtained from mainly t-
wo sources. The ﬁrst is the ActionsPanel 3.xml, found in the
sub-directory of the SWF Integrated Development Environ-
ment (IDE), Adobe Flash Professional CS6 [4]. It contain-
s suﬃcient information for the construction of expressions
that declare variables to be instances of classes, call their
member functions and modify their properties. However, it
does not contain newly published APIs and classes.
The second one is the ﬁle playerglobal.swc, which accom-
panies newly released versions of Adobe Flash. This ﬁle
contains the newly introduced APIs and runtime classes,
and constitutes suﬃcient information for a compiler to de-
termine if a class or function exists. By unpacking the play-
erglobal.swc ﬁle yields the ﬁles catalog.xml and library.swf.
Inside catalog.xml are names of runtime classes, especial-
ly some undocumented API functions. Demonstrations of
functions and properties are missing compared to Action-
sPanel 3.xml. It is possible that they reside in library.swf in
binary format. Instead of dealing with library.swf, the dy-
namic reﬂection mechanism of Flash is used to extract the
missing information. Thus, describeType [1] is employed to
restore the structure of the class using only its name.
After runtime information has been collected, veriﬁcation
is required for runtime class mutations, to ensure that they
are compatible with our compilation environment. Our com-
piler asc.jar comes from Flex SDK [2], an open-source SD-
K designed to build Flash. Asc.jar performs compilation-
checks by utilizing the information in playerglobal.abc. How-
ever, playerglobal.abc is not as up-to-date as playerglob-
al.swc. Therefore, the compilation and execution status of
each class collected in the current AVM of interest is manu-
ally veriﬁed, to minimize the amount of non-executable test
cases produced by the mutation phase.
To verify the compilation status of these runtime classes,
an AS source ﬁle is built by importing all the classes collect-
ed, then called upon with describeType inside a “try-catch”
clause. The classes that are not recognized (cause excep-
tions) by asc.jar and the target AVM are excluded, then the
valid description output by describeType are recorded. For
this purpose, a Python module is created that parses all the
XML outputs of both describeType and ActionsPanel 3.xml,
to build a runtime class pool in memory. This pool contains:
(cid:15) name of runtime classes and their parent classes,
(cid:15) name of member functions and the type of each pa-
(cid:15) name of dynamic and static properties of each class.
rameter,
2.5 Runtime class mutation
Step 1, mark identiﬁers
This phase is a critical part of ScriptGene. Outputs of this
phase are valid AS code that will be compiled into SWF ﬁles.
The guiding idea of runtime class mutation is to bring more
interactions between diﬀerent classes and give a valid con-
text to the code simultaneously. This is done in the following
two steps.
2.5.1
We mark the identiﬁers pointing to names and types of
functions, classes, catch variables, break variables, continue
variables, labels and function-calls via lexical analysis. The
lexier is based on G1, which recognizes all the identiﬁers.
The identiﬁers are distinguished according to the characters
of the former and latter tokens in the lexical sequence. For
example, if a “while” clause is generated in code generation
phase, then identiﬁers such as “DateCase” are neither API
functions nor static classes and are not yet acceptable to
the compiler. Subsequently, the nearly-valid AS source code
(cid:53)(cid:88)(cid:79)(cid:72)(cid:36)(cid:87)(cid:82)(cid:80)(cid:37)(cid:79)(cid:82)(cid:70)(cid:78)S: (a b)? (c d)*a: (cid:254)-(cid:255)    b: (c a)+c: (cid:254).(cid:255)d: c? | a?(cid:54)(cid:11)(cid:68)(cid:3)(cid:69)(cid:12)(cid:34)(cid:11)(cid:70)(cid:3)(cid:71)(cid:12)(cid:13)(cid:70)(cid:70)(cid:71)(cid:70)(cid:71)(cid:71)(cid:70)(cid:71)(cid:17)(cid:68)(cid:34)(cid:17)(cid:70)(cid:34)(cid:68)(cid:17)(cid:17)(cid:17)(cid:17)(cid:16)461will become a marked ﬁle with all the identiﬁers replaced by
markers, for example:
1: while(new Object+=a,
DateCase.setMilliseconds(newms)||c,
i++||f||2);
2: while(new _varname_+=_varname_,
_varname_._funcall_(_varname_)||_varname_,
_varname_++||_varname_||2);
2.5.2 Step 2, replace markers
The input of this step is the output of the previous step,
an AS source code ﬁle full of markers. Our goal is to mu-
tate these markers with real classes, build a context for each
variable that will be used and to correct lexical issues to
compensate for G1. For example, marked AS code will re-
place “ userdeﬁne ” in the following prebuilt template:
package{
import flash.display.*;
_import_
_globalvardeclaration_
_userdefine_
public class Main extends MovieClip{
public function Main():void{
_functioncall_
}
}
}
When the mutation begins, the input will be a template
ﬁle full of markers. All the classes, API functions, global
variables and member properties will be enumerated from
the runtime class information pool as built in Section 2.4.
Every mutation cycle will commence by picking several class-
es from the runtime class information pool. Presently, we
have adopted a limit of two classes per cycle. During this
process, all markers in the template ﬁle will be replaced with
meaningful code.
“ import ” will be replaced with “import” clause to include
the class of our choice. ” globalvardeclaration ” will be re-
placed with declarations of class objects with “new” clauses.
References are made to the runtime class information pool
to check the existence of constructors. If so, a “new” clause is
built for this class with appropriate parameters. Otherwise,
the chosen class is a static class. Properties and member
functions of such a class can be used directly without decla-
ration.
Next, a variable pool and a function pool are initialized.
The variable pool and the function pool stores the variable
names and methods of runtime class objects of our choice
respectively, including all of their properties and their par-
ents’. These two pools will be referred to, when markers
referencing variables and function-calls are encountered. In
addition, there is one more global pool to record the classes
that ScriptGene generates and their variables, functions and
labels.
When ScriptGene scans the marked template ﬁle, it will
encounter several kinds of markers. Markers referring to
variables will be replaced as listed below.
(cid:15) A variable pointing to the instance of a picked class.
(cid:15) A property of the chosen class and its parent.
(cid:15) A member function of the chosen class and its paren-
t. Member functions can be seen as variables in AS
under speciﬁc circumstances. Thus, they can be incor-
porated into grammar structures, such as assignment
expressions.
(cid:15) A property or member function of the chosen class in
prototype form. This is added, since prototype is a
way to inherit for this object-oriented program. We
expect that it will lead to more interactions between
diﬀerent classes.
Under special circumstances, only pure variables are permit-
ted (variables that are instances of classes), such as “ var-
name ++”, “-- varname ”. These situations are identiﬁed
and replaced with only predeﬁned instances of the chosen
classes.
The function-call mutation is similar to the variable mu-
tation. All the markers pointing to function-calls with mem-
ber functions of chosen classes and their parents are replaced
appropriately.
Other than the runtime class mutations, grammar struc-
tures in the marked template ﬁle also needs manual ﬁxes.
Some are ﬁxed by altering G2 in Section 2.2, such as “con-
tinue” clauses. To accomplish this, we maintain a label pool
to record recently declared labels. Once “continue” clauses
are encountered that request for labels, the labels are substi-
tuted and appended. Although this process is not foolproof,
it is necessary to enable a substantial portion of the code to
compile. Other ﬁxes on grammar structures are too trivial
to be listed here and can be found on our website [11].
When all the variables and function-calls used in the code
snippets have been declared, the instruction ﬂow is altered
to be logical and grammar errors are ﬁxed. The “ func-
tioncall ” markers are replaced by calls to member functions
that ScriptGene has generated and mutated. Then, all the
classes from the global pool are initialized and every func-
tion is called to enable our generated code to run in the
target AVM. This completes the generation of compilable
AS source code.
3. EVALUATION
Two experiments were conducted with ScriptGene. The
ﬁrst evaluates diﬀerent generation and mutation strategies:
breadth-ﬁrst or depth-ﬁrst during code generation phase and
multiple or single templates during runtime class mutation
phase.
The second compares our code coverage with the origi-
nal Tamarin test suite. The results show that ScriptGene
achieves a much better code coverage than Tamarin in all
three versions of AVMs tested. A brief analysis of typical
bugs found during the second experiment and details about
how they were found will be given.
3.1 Testing conditions
The testing process consists of three parts: a generation
phase, a runtime class mutation phase and an execution
phase. The ﬁrst part typically requires about half a day