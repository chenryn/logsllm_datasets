fore determining the cross-correlation value, the two signals were
aligned and a bandpass filter was applied to isolate frequencies be-
tween 150-1000 Hz (what appear to be the frequencies most related
to the original speech).
Because the signals are aligned, we should find a peak at lag=0 in
the cross-correlation graphs if the two signals are highly correlated.
Figure 4 shows the cross-correlation graphs generated from samples
of the speaker FAC saying the digit “One” in each of the speech SPL
settings. Looking at the absolute amplitude in the cross-correlation
graph, we find the normalized cross-correlation values for the 60,
65, and 70 dB samples are 0.63, 0.69, and 0.81 respectively. These
values confirm a decent level of correlation between the signals
(e.g., a significant amount of the original signal was recovered).
420ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Payton Walker and Nitesh Saxena
(a) 60 dB Speech (Noisy)
(b) 65 dB Speech (Noisy)
(c) 70 dB Speech (Noisy)
(d) 70 dB Speech (Clean)
Figure 5: Frequency spectrum graphs generated from post-processed, Alexa recorded samples (noisy) of speaker FAC saying the digit “One”,
for each speech SPL tested (60, 65, 70 dB); as well as a graph generated from a clean sample (no injected noise) with 70 dB speech. While normal
speech related frequencies are present, we can see noise cancellation becomes more successful as the speech volume increases.
Table 1: Averaged results from PESQ and SNR analysis for each individual speaker.
Alexa Recovered Audio
60 dB
65 dB
70 dB
Speaker
ID
FAC
FBH
FCA
FDC
FEA
MAE
MBD
MCB
MDL
MEH
PESQ
1.2
1.2
1.2
1.2
1.2
1.2
1.2
1.3
1.3
1.2
SNR
8.8 dB
9.8 dB
10.2 dB
7.1 dB
8.6 dB
8.2 dB
8.8 dB
8.0 dB
8.7 dB
9.3 dB
PESQ
1.3
1.3
1.2
1.2
1.3
1.2
1.3
1.3
1.1
1.1
SNR
8.6 dB
10.6 dB
9.8 dB
7.5 dB
9.0 dB
8.0 dB
9.0 dB
8.2 dB
9.6 dB
10.1 dB
PESQ
1.7
1.3
1.3
1.2
1.5
1.5
1.4
1.3
1.5
1.4
SNR
7.7 dB
10.2 dB
9.2 dB
6.7 dB
9.3 dB
6.5 dB
7.1 dB
7.5 dB
7.9 dB
6.6 dB
Baseline
PESQ
1.8
1.6
1.4
1.5
1.6
1.6
1.7
1.7
1.8
1.7
SNR
15.7 dB
14.9 dB
20.7 dB
24.0 dB
16.8 dB
23.5 dB
22.1 dB
17.9 dB
16.2 dB
16.2 dB
Table 2: Averaged results from PESQ and SNR analysis for both speaker genders.
Speaker
Gender
Male
Female
Alexa Recovered Audio
60 dB
65 dB
70 dB
Baseline
PESQ SNR PESQ SNR PESQ SNR PESQ
1.6
1.2
1.2
1.7
8.8 dB
8.6 dB
7.9 dB
7.1 dB
SNR
18.4 dB
19.2 dB
1.3
1.2
9.0 dB
9.0 dB
1.4
1.4
6.3 SNR & PESQ
Another way that we evaluated our recovered samples was using
metrics that describe speech presence and quality in noisy audio.
Specifically, we look at Signal-to-Noise Ratio (SNR) and Percep-
tual Evaluation of Speech Quality (PESQ) scores. SNR shows us
how successful the post-processing was at reducing the noise and
enhancing the speech frequencies. Further, the PESQ score rates
the quality of the speech in terms of how perceptible it is to hu-
man listening. We believe these two standard metrics are useful for
demonstrating the potential vulnerability of these audio samples
to eavesdropping attacks. To highlight the greatest potential for
speech to be recovered from noisy samples, we filtered our dataset
for the SNR and PESQ analysis to include the samples from each
experimental scenario that displayed the greatest speech leakage.
For each speaker, digit, and speech SPL that we tested, we collected
5 different samples to build our 1500 sample dataset. Therefore,
choosing the best sample out of 5 for each scenario resulted in a
filtered dataset of 300 samples that we used to generate average
SNR and PESQ scores for each speaker and gender. Table 1 and
Table 2 show these average scores summarized per speaker and
gender, respectively.
Signal-to-Noise Ratio: We calculated the SNR values of each in-
dividual audio sample using the equation:
SN R = 20 ∗ loд10(std(siдnal)
std(noise) )
The variable signal refers to the recovered signal from each sce-
nario, and the variable noise is the raw noise signal that was injected
during the scenarios. The values produced by this equation were
verified using the snr() function built into Matlab. We found the
average SNR values for all speakers, in each experimental scenario,
was positive. This was also seen when the values were averaged per
421Evaluating the Effectiveness of PJDs in Mitigating Smart Speaker Eavesdropping Attacks Using GWN
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Table 3: Summarized classification results (using Random Forest) observed for the different speech tasks, feature sets, and speech SPLs
considered in our experiments. Bold accuracies indicate the highest values observed for each speech task and feature set.
Classification Task
# Classes
# Features
Speech
(Digit)
Recognition
10 (digits,
0-9)
Random
Guess: 10%
144 (ALL)
17 (filtered)
Speaker
Identification
10 (speakers)
Random
Guess: 10%
144 (ALL)
17 (filtered)
Gender
Identification
2 (Male,
Female)
Random
Guess: 50%
144 (ALL)
17 (filtered)
Speech SPL
(dB)
60
65
70
60
65
70
60
65
70
60
65
70
60
65
70
60
65
70
Classification Accuracy (%)
80:20
10-Fold CV
30
40
36
24
34
35
30
51
39
32
49
37
76
80
66
77
76
71
90:10
22
34
36
22
46
42
40
50
38
36
50
42
69
80
76
71
78
74
29.8
37.2
39.6
28.4
36.6
36
38.4
46.2
39.4
40.2
43.4
40.6
75.6
76.8
70
76.9
74.8
69.2
gender. Although the SNR scores do not reveal any particular pat-
tern or trend across the different SPL settings (i.e., similar amount
of noise can be removed at all speech levels), it is important to
recognize that all recovered and processed samples produced posi-
tive SNR values, with most scenarios averaging an SNR of 8 dB or
higher. These positive values indicate the recovered speech signal is
greater than the noise remaining in the sample post-processing. We
also collected baseline samples of the normal speech audio (without
any injected noise) which produced the highest SNR values. The
decrease in SNR of our recovered samples, compared to the baseline,
reflects noise that still remains even after signal processing.
Perceptual Evaluation of Speech Quality: PESQ is the metric
that is most related to human perceived intelligibility of the recov-
ered samples [29]. The results from our PESQ analysis support our
previous observations of speech leakage. To calculate PESQ scores
for individual audio samples, we used a python PESQ wrapper [35].
The provided function takes the recovered audio sample and the
original raw audio sample as input and compares them to deter-
mine the quality of speech contained in the sample. After averaging
the scores for both genders and for each speaker, we find positive
scores above 1.0 for all scenarios. Additionally, we observed a con-
sistent and expected pattern among the averaged values where the
PESQ scores increase (albeit slightly) as the original speech SPL
increases. Further, we also find that the PESQ scores calculated are
comparable to the scores of the baseline samples. This means that
the speech content we were able to recover has a similar intelli-
gibility, in terms of human perception, to the raw recordings we