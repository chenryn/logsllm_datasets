1.62
(b) Varying PAL input parameter size.
Parameter marshaling
4K
92
16K
279
8K
152
32K
536
0K
25
Table 2: PAL setup overhead microbenchmarks (in µs). Avg.
of 100 runs with negligible variance.
head. However, there are two benchmarks with over 10%,
and two more with 29% and 37% overhead. We attribute this
high overhead to paging operations performed with the cur-
rent hardware’s NPT support, and expect that performance
will improve as NPT hardware matures. For I/O application
benchmarks, sequential access to very large ﬁles incurs the
highest overhead – over 20%. We also expect this overhead to
diminish with newer NPT hardware. All of the other bench-
marks show less than 7% overhead.
6.3 Performance of PALs
We present micro- and macro-benchmarks to evaluate sources
of PAL overhead and application-level impact, respectively.
6.3.1 PAL Microbenchmarks
We evaluate the overhead when TrustVisor receives control
in 5 cases (Tables 2 and 3): (a) when an application regis-
ters a PAL, (b) when any function inside the PAL is called,
(c) when a function inside the PAL ﬁnishes execution and re-
turns to the application, (d) when an application unregisters a
PAL, and (e) when a PAL calls any µTPM function. We use
microbenchmarks to measure the overhead of the TrustVisor
framework in cases (a) – (d), and the overhead of µTPM op-
erations provided by TrustVisor in case (e). We also evaluate
the performance of real applications to illustrate the overall
performance in a practical environment.
TrustVisor Framework Overhead. TrustVisor’s overhead
has four causes. (1) Each time TrustVisor is invoked, the CPU
must switch from guest mode to host mode, which includes
saving the current guest environment into the VMCB, and
loading the host environment from the VMCB. After Trust-
Visor ﬁnishes its task, the CPU will switch back to the guest
by performing the reverse environment saving and loading.
Thus, there will be a noticeable performance impact from
both cache and TLB activity. (2) When TrustVisor sets NPT
protections for PALs or switches between guest legacy mode
and guest secure mode, it will walk the page tables in the
guest, change permissions in the NPTs, and perform some
TLB operations. The bigger the PAL, the more overhead is
incurred. (3) Integrity measurement during registration uses
SHA-1 to hash the PAL pages containing executable code.
(4) Parameter marshaling will incur memory copy overhead
between the untrusted application and PAL.
TrustVisor
0.98
0.96
0.98
0.94
0.97
1.00
0.85
0.73
0.66
socket
reread
bcopy
page fault
mmap
ctxsw
exec
fork
null
0.5
Performance (Normalized to native Linux, higher is better)
0.8
0.9
0.6
0.7
1
1.1
s
k
r
a
m
h
c
n
e
B
xalancbmk
astar
omnetpp
h264ref
sjeng
libquantum
hmmer
gobmk
mcf
gcc
bzip2
perlbench
0.8
TrustVisor
1.37
1.15
1.12
1.29
1.01
1.03
1.03
1.00
1.01
1.05
1.03
1.03
0.9
1
1.1
1.2
1.3
Runtime (Normalized to native Linux, lower is better)
Apache Server
UDP
TCP
Postmark
frandom
fwrite
fread
Kernel Build
0.6
TrustVisor
0.96
1.00
1.00
0.97
1.00
0.93
0.78
0.75
0.7
0.8
0.9
1
1.1
Performance (Normalized to native Linux, higher is better)
(a) Lmbench microbenchmarks.
(b) SPECint 2006 runtime.
(c) I/O benchmarks.
Figure 6: Performance impact of TrustVisor compared to native Linux.
Native Linux
TrustVisor
Extend
24066
533
Seal
358102
11.7
UnSeal
1008654
12.6
Quote
815654
21000
Table 3: TPM vs. µTPM microbenchmarks (in µs). Avg. of
100 runs with negligible variance.
HMAC
Sign
Avg
0.059
62.644
Stdev
0.003
0.181
Avg
5.071
67.461
Stdev
0.018
0.008
TrustVisor
Flicker
Table 4: HMAC and sign PAL overhead performed using
TrustVisor vs. using Flicker (in ms). Avg. of 100 runs.
Table 2(a) summarizes the overhead of PAL registration,
and Table 2(b) summarizes the overhead of marshaling pa-
rameters during PAL execution. We compare these results
to the same operations performed on native Linux, where
appropriate. We choose four PAL sizes for registration and
unregistration. For PAL execution, we choose ﬁve different
parameter sizes. Our results for the one-time cost of regis-
tration show that the performance penalty for a 4 KB PAL
is about 31 µs. With a larger PAL, the overhead increases
by 27 µs per 4 KB page. This is expected because, during
registration, the integrity measurement overhead (cause (3))
outweighs other overheads (causes (1) and (2)). The unreg-
istration overhead is reasonable – less than 1.5 µs, and along
with increasing PAL size, the elapsed time of unregistration
only slightly increases. For PAL execution, the overhead of
switching between guest legacy mode and guest secure mode
is about 25 µs without parameters, and increases by about
65 µs with each 4 KB page of parameters. The switching
overhead increases proportionally to the size of the marshaled
parameters because causes (4) and (2) are more signiﬁcant
than cause (1). Note that there is no additional performance
penalty when PAL functions run in secure guest mode unless
they invoke µTPM operations.
µTPM Overhead. µTPM functions can only be used by hy-
percalls when the PAL is running in secure guest mode. The
overhead of µTPM functions comes from two places: (1) the
hypercall to switch between the guest and the host, and (2)
the performance of the µTPM function itself. For fair com-
parison with other systems, we distinguish between these two
overheads in our results.
Table 3 summarizes the results for µTPM operations. We
compare all the results to the corresponding operations on na-
tive Linux with Flicker [22], which both depend on the hard-
ware TPM.
6.3.2 PAL Macrobenchmarks
HMAC and Sign. Two simple tasks that require a secret
key are computing message authentication codes (MACs) and
digital signatures. We implemented a routine to compute
a HMAC-SHA-1 over a 1000 byte payload using a 512-bit
key as both a PAL run using TrustVisor and a PAL run us-
ing Flicker. Likewise, we implemented a routine to perform
a digital signature using a 1024-bit RSA key over a 20-byte
hash value as both a PAL run using TrustVisor and a PAL run
using Flicker. Our results are shown in Table 4. TrustVisor
outperforms Flicker by several orders of magnitude for the
HMAC operations, and by more than one order of magnitude
for the sign operations.
OpenSSH. Here we evaluate the overhead induced by
TrustVisor on OpenSSH 4.3p2 as modiﬁed for use with
Flicker [22]. We ported the security-sensitive portions to run
in a PAL using µTPM operations. We compare native SSH
performance with Flicker- and TrustVisor-induced overheads,
executing all versions on our Dell PowerEdge T105.
We modiﬁed the Flicker-protected code to use the hard-
ware TPM’s Non-Volatile RAM facility for protecting the
sensitive state, instead of the hardware TPM’s Sealed Stor-
age facility. This considerably improves Flicker’s perfor-
mance, as TPM Unseal averages nearly 1 second, whereas
TPM NV Read on our machine executes in 15 ms on average
with negligible variance. However, NV-RAM does impose
scalability issues for Flicker, as there are only a few KB of
NV-RAM available in today’s TPMs [33]. Thus, the perfor-
mance results for our Flicker-based runs should be considered
a best-case for Flicker.
We deﬁne Connect-to-Prompt to be the time elapsed be-
tween establishment of the TCP connection and prompting
Connect-to-Prompt
Prompt-to-Shell
Native
110
0
Flicker
1316
131
TV
1260
11
Table 5: SSH server-side password processing overhead.
Note that both the Flicker and TrustVisor Connect-to-prompt
ﬁgures include the time to generate a hardware TPM Quote.
Avg. of 100 runs.
Test
Scenarios
Single
Prefork
Concurrent
Transactions
1
5
5
50
100
200
Perf (txns/second)
Vanilla
26.60
37.91
53.71
57.84
58.05
58.04
TV
24.06
37.13
53.53
57.31
58.03
58.07
Full
22.96
34.57
48.49
51.35
51.29
51.08
(a) Connect-to-Prompt
(b) Prompt-to-Shell
Operation
DRTM
Key Gen
Seal
TPM sharing
Time (ms)
TV
Fli
0
14
199
196
0
15
64
-
Operation
DRTM
Unseal
Decrypt
TPM sharing
Time (ms)
TV
Fli
0
14
0