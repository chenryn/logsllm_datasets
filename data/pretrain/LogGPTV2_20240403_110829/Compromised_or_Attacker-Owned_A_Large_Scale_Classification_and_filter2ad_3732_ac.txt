we are of the label, with 100 being the most conﬁdent and
50 being undecided. To improve the quality of labeling, two
domain experts performed the labeling for all the domains
and we excluded the domains with conﬂicting labels.
During manual veriﬁcation, we ﬁrst check the content of the
apex domain. Most of the time the content itself reveals if it is
a public apex domain providing web hosting, sharing, forums
or other collaborative platforms. For the remaining apexes,
whose functionalities are not clear from the content, we utilize
our PDNS based subdomain enumeration tool, and get the
subdomains belonging to each apex domain. We then cross
compare the content of these subdomains as well as their
names to label the apex as public or private. For example,
for public domains, different subdomains tend to have very
different contents whereas for a private domain, their content
follows a certain theme. With this process, we collect two
ground truth sets PP-GT1 (PP stands for Public Private) and
PP-GT2 from DS1 and DS2 respectively, as summarized in
Table 3.
5.1.2 Feature Engineering
We extract the features in Table 4 from the VT NOD system
to train a classiﬁer. The meanings of most of the features are
1The code is available at https://github.com/qcri/compromised
Table 3: Public/Private Ground Truth
Ground truth
PP-GT1
PP-GT2
Public
410
528
Private
1370
1408
Figure 7: ROC Curves for RF Public Classiﬁers where Class
1 is Public
straightforward. Compared to private apex domains, public
domains tend to host more subdomains and are scanned more
frequently in VT. #subdomains and #scans capture these ob-
servations. Since subdomains are not under the control of the
public apex domain owner, in practice, some of the subdo-
mains are malicious and others are benign, whereas subdo-
mains under private apexes tend to be mostly either benign
or malicious. #Mal_Scans and Mal_Scan_Ratio capture the
volume and this difference. Most public apexes, especially
CDNs and proxy services, utilize FQDNs of the domains they
serve (e.g. www.superwhys.com.akamai.com) whereas pri-
vate apexes uses mostly descriptive popular keywords in the
subdomain part such as www, mail, ns and m (for mobile). By
proﬁling all domains seen in PDNS during the study period,
we identify the top 100 subdomains as the popular keywords.
We capture these differences using the #Pop_Keywords, Ra-
tio_Pop_Keywords and #Avg_Depth features. We observe
that there are more variations between subdomain names
under public apex domains than those under private ones.
Avg_Sub_Entropy measures the average entropy across all
subdomains to capture this observation. While not directly
related, #Subdomains and #Avg_Depth are inspired from
public key sharing in CDNs [63], and #Pop_Keywords and
#Avg_Sub_Entropy features are inspired from the diversity
features described in [42].
5.1.3 Model Training and Classiﬁcation Accuracy
We train 8 classiﬁers (Support Vector Classiﬁcation (SV),
Random Forest (RF), Extra Tree (ET), Logistic Regression
(LR), Decision Tree (DT), Gradient Boosting (GB), Ada
Boosting (AB) and K-Neighbors (KN) Classiﬁcation) using
the features in Table 4. Out of all of the classiﬁers, RF per-
forms the best.
USENIX Association
30th USENIX Security Symposium    3727
Table 4: Public Apex Classiﬁer Features
Feature Name
VT Duration
#Scans
#Mal_Scans
Mal_Scan_Ratio
#subdomains
#Pop_Keywords
Ratio_Pop_Keywords
#Avg_Depth
Avg_Sub_Entropy
Description
The time between the apex domain ﬁrst and last seen in VT
No. of unique scans performed for the apex and its subdomains
No. of unique scans that VT marks apex or its subdomains as malicious
The ratio of scans with malicious results and the total number of scans for apex and its subdomains
The number of FQDNs (Fully Qualiﬁed Domain Names) observed in VT URL feed for the apex domain
The number of popular keywords used in the subdomain part of the FQDNs of the apex domain
The ratio of popular keywords used and the total number of FQDNs observed for the apex domain
The average number of subdomain levels used in the FQDNs belonging to the apex domain
The average entropy of the subdomain parts of the FQDNs belonging to the apex domain.
Novel




[63]
[42]

[63]
[42]
Our model on both ground truth sets performs really well,
showing the generalizability of our model across different
datasets. With 10-fold cross validation on a balanced dataset,
the RF classiﬁer on PP-GT1 labels public apex domains with
92% accuracy, 97.4% precision and 87.5% recall. The RF
classiﬁer on PP-GT2 labels public apex domains with 97.2%
accuracy, 97.7% precision and 95.6% recall. As shown in
Figure 7, AUCs of the two ROC curves are 96% and 99%
for GT1 and GT2 respectively, demonstrating high degrees of
separability of the two classes. One reason for the better per-
formance in GT2 is that the two classes in GT2’s ground truth
data have a better separation, resulting in a better decision
boundaries.
5.1.4 Observations
We applied the above trained model to all the URLs in DS1
and DS2, and identiﬁed 6,675 malicious public apex domains
and 725,325 malicious private apex domains in total. It is
interesting to see that among all the apex domains hosting
malicious URLs, only 1% are public apexes. However, these
public apexes host a large portion of malicious URLs: 46.5%
of malicious URLs are from public apexes. This observation
is not surprising, given that attackers can utilize public apexes
to deploy a large number of malicious URLs with almost no
cost. Meanwhile, note that most existing work on malicious
domain detection either focuses on apex domains or treats
all URLs the same without distinction. Our ﬁnding suggests
that malicious URLs from public apexes form a unique and
signiﬁcant set of Internet entities with their own distinguishing
characteristics. Therefore, it would be more effective to design
detection mechanisms speciﬁcally targeting such malicious
URLs. Our classiﬁer would help researchers to quickly zoom
into such URLs.
Figure 8 shows the average Alexa ranking distribution for
public and private apex domains. For unranked domains, we
assign the insigniﬁcant rank of 1 million for better visualiza-
tion. We see that public apexes have a higher average Alexa
ranking than private apexes as public apex domains along
with their vast number of subdomains are accessed more fre-
quently by users. Yet it is also interesting to see that half
of public domains are not popular (unranked), showing that
attackers also utilize less popular public domains to launch
attacks. As public apex domains could also host many benign
subdomains, current registration and domain reputation based
systems [29,42] and inference based systems [37,64] that rely
on Alexa ranking (or domain popularity) may inadvertently
blacklist public apex domains, disrupting benign sites.
Figure 8: Average Alexa Ranking for Public and Private Apex
Domains during the Study Period
5.2 Attacker-Owned/Compromised
Apex Classiﬁer
Private
5.2.1 Ground Truth Collection
We manually create two ground truth sets of compromised
and attacker-owned apex domains AC-GT1 (AC stands for
Attacker-Owned/Compromised) and AC-GT2 from the pri-
vate domains identiﬁed from DS1 and DS2 respectively using
our public/private classiﬁer.
We ﬁrst select a random sample of 2500 domains from
each of DS1 and DS2. We perform manual inspection of each
sample and provide a conﬁdence score to indicate how con-
ﬁdent the domain experts are about the label. The following
information and sources are manually inspected to decide if a
malicious apex is compromised or attacker-owned. In addi-
tion to checking the website, we check auxiliary information
such as registration information including historical WHOIS
records, hosting information, and PDNS information. We also
check the detailed reports from two threat intelligence plat-
forms, riskiq.com and otx.alienvault.com. Further, we
3728    30th USENIX Security Symposium
USENIX Association
inspect detailed reports from two reputation services, GSB
and SA. To identify compromised domains, we rely on the
deviations of the visual and auxiliary information in the apex
domain and the domain under consideration. We observe that
shadow domains, one type of compromised domains, have
very different contents compared to the main website and
the auxiliary information such as hosting IPs are different
for the main website (reputed hosting provider) and the do-
main under consideration (bullet proof hosting) [42, 50]. On
the other hand, attacker-owned domains have relatively new
registration information [35], are likely to utilize fast ﬂux
networks [54], are short-lived (likely to be NX domain) [33],
and blacklisted [39, 60]. After manual veriﬁcation, we select
the ones with 90% or above conﬁdence scores assigned by
the domain experts. A summary of the ground truth datasets
are shown in Table 5.
Table 5: Compromised/Attacker-Owned Private Apex Ground
Truth
Ground truth
AC-GT1
AC-GT2
Compromised Attacker-Owned
704
685
1004
885
5.2.2 Feature Engineering
We identify ﬁve groups of features: lexical, VT report, VT
proﬁle, PDNS (hosting), and Alexa features. Table 6 sum-
marizes these features. Lexical features capture the lexical
properties of the URL under consideration. VT report features
include those attributes that are directly available from VT
reports. VT proﬁle features are extracted from our VT NOD
system. PDNS features are extracted from the Farsight Passive
DNS DB system. Most of the lexical, Alexa and PDNS fea-
tures either have been proposed in or adapted from previous re-
search on detecting malicious URLs [25,26,34,40,43,61,66].
Past research utilizes these features to distinguish attacker-
owned domains from benign domains that usually appear
consistently in domain reputation lists such as Alexa Top
1M [58, 71]. In our case, these features are useful as many
apexes of compromised domains are likely to have properties
similar to such benign domains. We improve our classiﬁer
with additional features that collectively amplify the deviation
of malicious websites hosted on benign apexes.
Next, we describe those features that either improve ex-
isting ones or are newly introduced in our work. VT Report
Features are directly extracted from the VT reports. We ob-
serve that the VT_Duration feature for compromised domains
tends to be higher than that for attacker-owned domains. One
reason is that compromised domains are in general harder to
detect by existing systems [35, 37] as attackers are exploiting
the reputation of legitimate domains. Due to the same reason,
we observe that the number of scanners that mark a compro-
mised site as malicious is less than that for attacker-owned
sites. Positive_count captures this observation. Compared to
attacker-owned domains, we observe that attackers more of-
ten use compromised domains as a redirection site in order to
evade detection, which is captured by Is_URL_Redirected.
VT proﬁle features capture the intuition that almost all
subdomains and scans of attacker-owned domains are ma-
licious whereas only some of the subdomains and scans of
compromised domains are malicious.
From the PDNS features, the number of authoritative name
servers and the number of SOA domains capture the ob-
servation that attacker-owned domains change their hosting
providers more often than benign domains to evade detec-
tion or takedown. Additionally, as Lever et al. [41] point
out, attackers drop catch or re-register domains to exploit the
residual trust in them, which also results in domain being
associated with multiple name servers. Comparison of apex
domains with name server domains and SOA features cap-
ture the observation that benign domains are more likely to
be hosted in their own servers compared to attacker-owned
ones. We improve several lexical features present in previous
work [34,43,61]. Speciﬁcally, we observe that attacker-owned
domains more often use these squatting methods to imperson-
ate brands compared to compromised domains. We proﬁle
Alexa Top 1M domains over 1 year to identify Alexa top 1000
brands to detect combosquatting [38], levelsquatting [31] and
target embedding [57] domains which are shown to be much
more prevalent than traditional squatting types [27, 49]. Fea-
tures Brand, Similar, and Pop_Keywords capture new squat-
ting tactics used by attackers. The presence of these features
in the apex part of domains makes a domain more likely to
be an attacker-owned one. On the other hand, the presence of
such lexical features in the path is likely to identify compro-
mised ones.
5.2.3 Model Training and Classiﬁcation Accuracy
We train the same 8 classiﬁers (SV, RF, ET, LR, DT, GB,
AB and KN) as in Section 5.1.3, out of which, RF and ET
performed the best.
Figure 9 shows the ROC curves for RF for both AC-GT1
and AC-GT2, with 10-fold cross validation (the ROC curves
for ET are similar). Our classiﬁer achieves 90.6% accuracy
with 94.7% precision and 86.1% recall for AC-GT1, and
96.8% accuracy with 99.1% precision and 93.4% recall for
AC-GT2. The fact that our model achieves high accuracy
for datasets collected on different time periods shows the
robustness of our approach and that it could be generalized
to different ground truth datasets. Feature importance charts
show that no single feature is dominant in deciding the class
label which makes it difﬁcult for adversarial manipulations.
USENIX Association
30th USENIX Security Symposium    3729
Feature Name
VT_Duration
Response_Code
Rlength
Is_URL_Redirected
Positive_Count
Domain_Malicious
#Total_Scans
#Benign_Scans
#Subdomain_Mal
PDNS_Duration
Name_Servers
Query_Count
SOA_Domains_Nos
SOA_Domain
#Subdomains
Minus