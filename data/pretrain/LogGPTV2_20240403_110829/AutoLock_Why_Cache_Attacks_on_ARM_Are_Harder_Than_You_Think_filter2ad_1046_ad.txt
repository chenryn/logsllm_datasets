fected by AutoLock, because cache maintenance opera-
tions such as cache ﬂushing seem to override AutoLock.
Eviction-based Attacks. The second group of attacks
relies on cache eviction, i.e., the removal of cache con-
tents by ﬁlling the corresponding parts of the cache with
dummy or unrelated content. Osvik et al. [42] intro-
duced two eviction based attacks, called Evict+Time
and Prime+Probe, which both target software imple-
mentations of AES. As the underlying attack strategies
are more generic, Acıiçmez [1] and Percival [44] uti-
lized Prime+Probe to steal an RSA key while Neve and
Seifert used it to perform an efﬁcient last round attack
on AES [40]. Ristenpart et al. [46] used the same tech-
nique to recover keystrokes from co-resident virtual ma-
chines (VMs) in the Amazon EC2 cloud. This work
was later expanded by Zhang et al. [57], proving the ef-
fectiveness of Prime+Probe to recover El Gamal keys
across VMs. Liu et al. [39] and Irazoqui et al. [27]
showed the feasibility of Prime+Probe via the last-level
cache. Both studies opened a range of scenarios in which
cache attacks could be applied. For instance, Oren et
al. [41] executed Prime+Probe in JavaScript and Inci
et al. [26] demonstrated the applicability of the tech-
nique in commercial IaaS clouds. As a cross-over to
the ﬂush based attacks, Gruss et al. [24] proposed the
Evict+Reload attack, which removes cache contents
through evictions but other than that remains identical to
the Flush+Reload technique. All of the eviction based
attacks are inherently affected by AutoLock, if they are
executed in a cross-core scenario. While this might not
hold for the same-core attacks proposed in early litera-
ture, it very much applies to the most recent attacks that
pose greater threats in practice.
Cache Internals. Besides the generic structure and
behavior of caches, literature has also exploited more
implementation speciﬁc aspects.
Irazoqui et al. [28]
demonstrated the applicability of cache attacks across
CPUs through the cache coherency protocol, which al-
lows the execution of Flush+Reload style attacks by
forwarding cache ﬂush and data request messages be-
tween two CPU clusters. Yarom et al. [52] showed that
cache bank contentions introduce timing variations of ac-
cesses to different words on a single cache line. This un-
dermines the general assumption in other work that dif-
ferent words on one cache line have the same timing be-
havior. Gruss et al. [21] introduced prefetching instruc-
tions as a way to load memory into cache without explic-
itly accessing it. This can be used to circumvent supervi-
sor mode access prevention and address space layout ran-
domization. As the exact impact of AutoLock on these
attacks is unclear, we leave a more detailed assessment
of AutoLock’s intricacies in these cases to future work.
Countermeasures. The threat posed by cache attacks
has been addressed from both hardware and software
side in the form of countermeasures. Hardware based
approaches often leverage programmable lockdown, i.e.,
the ability to actively lock cache lines. Cache contents
belonging to sensitive applications are then locked and
therefore protected from eviction by other, e.g., ma-
licious applications.
In literature, this programmable
lockdown is for instance used by Wang and Lee [49]
and by Liu et al. [38] to counter cache attacks. Al-
though AutoLock also prevents cache lines from being
evicted and therefore behaves in a similar way, there are
two main differences compared to the proposed coun-
termeasures. First, there is no means of controlling
AutoLock, as it can neither be conﬁgured nor disabled.
Second, AutoLock only protects lines in the LLC under
certain conditions, i.e., if they are kept in core-private
cache levels. Once these lines are removed from core-
private levels, the protection immediately stops. As such,
AutoLock cannot provide any guarantee to impede cache
attacks.
It is rather an additional layer of complexity
that an adversary has to overcome during a cache attack.
Software based countermeasures often try to separate the
cache footprints of applications, such that each applica-
tion gets a separate portion of the cache, which prevents
interferences at the cache level. In literature, this strategy
has for instance been applied by Kim et al. [33] and Zhou
et al. [59]. Ultimately, applications that handle sensitive
data should be designed such that both execution ﬂow
and memory accesses are independent of any sensitive
input that is processed. As this is not a trivial task, several
tools have been proposed that help to detect cache leaks
and ﬁx vulnerable code [4, 18, 53]. If applications cannot
be ﬁxed, other approaches try to detect and stop cache
attacks in real-time, before any harm is caused [55]. For
these system- and application-level countermeasures, we
do not expect any particular impact from AutoLock.
Most of the previous cache attack literature is dedicated
to the x86 architecture. Recent works [37, 54, 56] have
1084    26th USENIX Security Symposium
USENIX Association
Table 4: Utility of known cache attacks in different
scenarios on ARM Cortex-A processors with inclusive
caches implementing AutoLock. ‘’ indicates the attack
is unaffected by AutoLock, while ‘’ denotes obstruc-
tion by AutoLock. Flush+Reload and Flush+Flush
are uninhibited by AutoLock but only apply to a limited
number of ARMv8-A SoCs and are thus listed as ‘*’.
Attack
Same-core Cross-core Cross-CPU
Evict + Time [42]
Prime + Probe [42]
Flush + Reload [51]
Evict + Reload [24]
Flush + Flush [23]


*

*


*

*


*

*
made several contributions to overcome the challenges
of applying known userspace cache attacks from x86 to
ARM processors. AutoLock is not recognized or men-
tioned in any of them. The following section is dedicated
to discuss how AutoLock relates to these publications
and why it might have stayed undetected.
5.1 AutoLock in Previous Work
Lipp et al. [37] were the ﬁrst to demonstrate the feasibil-
ity of Prime+Probe, Flush+Reload, Evict+Reload,
and Flush+Flush attacks on ARM devices. Despite
their extensive experiments, the authors did not mention
any encounter of a feature similar to AutoLock. We be-
lieve this can mainly be explained with their selection of
test devices: the OnePlus One, the Alcatel One Touch
Pop 2, and the Samsung Galaxy S6. Respectively, these
mobile phones feature the Krait 400, the Cortex-A53,
and a big.LITTLE conﬁguration of the Cortex-A53 and
Cortex-A57. We assume that the Krait 400, like the Krait
450 we experimented on, does not feature AutoLock.
The Samsung Galaxy S6 features a full-hierarchy ﬂush
instruction that is available from userspace by default.
Thus, the authors bypassed AutoLock on this device by
ﬂushing cache lines instead of evicting them. In contrast,
the Alcatel One Touch Pop 2 features a Cortex-A53 that
would potentially be affected by AutoLock according to
our results. Yet, Lipp et al. successfully demonstrate
a covert channel based on cross-core evictions on this
chip. A possible explanation could be that the SoC man-
ufacturers are different. While Lipp et al. experiment
on a Qualcomm Snapdragon 410, we perform our tests
on an ARM built Juno SoC. This could mean that the
existence of AutoLock is yet more fragmented than our
results might indicate. If this should be true, testing for
AutoLock on a speciﬁc device is more important than
ever. Another explanation is that the authors relied on
evictions caused by background activity or by the mea-
surement program itself (self-evictions).
Zhang et al. [56] implemented a variant of the
Flush+Reload attack in a zero-permission Android ap-
plication. The authors also experimented on processors
we expect to feature AutoLock, but they did not mention
any encounter with it either. In fact, they used the same
processors analyzed in this work, namely, the Cortex-A7,
A15, A53, A57, and the Krait 450. Since their work
was focused solely on Flush+Reload, one of the two
cache attacks unaffected by AutoLock, we assume they
never encountered it during their experiments. One of
the main contributions of their work was to implement
an instruction-side Reload in a return-oriented manner,
i.e., by executing small blocks of instructions. This con-
tribution stemmed from using the cacheflush syscall
in the Flush step, as it only invalidates the instruction
side. As a prerequisite for their ﬁnal target device se-
lection, the authors experimentally determined the inclu-
siveness property of the last-level caches on all devices.
Surprisingly, they concluded that all of the L2 caches in
the aforementioned processors are inclusive with respect
to the L1 data and instruction caches. This contradicts
our experiments, which found the Cortex-A7 and A53 to
only be inclusive on the instruction side, and the Cortex-
A15 and A57 to only be inclusive on the data side. Fur-
ther, the ofﬁcial ARM documentation of the Cortex-A7,
for example, explains that “Data is only allocated to the
L2 cache when evicted from the L1 memory system, not
when ﬁrst fetched from the system." [6]. We understand
this to mean that the L2 cache of the Cortex-A7 is not in-
clusive with respect to the L1 data caches. This complies
with our observations.
In other previous work, Zhang et al. [54] implemented
a Prime+Probe attack in an unprivileged Android appli-
cation on an ARM Cortex-A8. Since we did not con-
duct experiments on this processor model, it is unclear
whether AutoLock is implemented on it. However, the
test system used by Zhang et al. comprised only a sin-
gle Cortex-A8 processor core. As AutoLock does not
affect same-core attacks, the experiments of the authors
would not have been affected, even if the Cortex-A8 im-
plemented AutoLock.
6
Implications of AutoLock
Automatic Lockdown prevents the eviction of cache
lines from inclusive cache levels, if copies of that line
are contained in any of the caches said level is inclu-
sive to. Yet, the ability to evict data and instructions
from a target’s cache is a key requirement for practi-
cal cross-core cache attacks. Table 4 illustrates the im-
pact of AutoLock on state of the art cache attacks im-
plemented on ARM Cortex-A processors. Each row
shows one attack technique and the corresponding ef-
fect of AutoLock in three different scenarios: same-
USENIX Association
26th USENIX Security Symposium    1085
Table 5: Selection of recent smartphones from manu-
facturers with high global market share [16]. For each
listed device, the SoC, the contained processing cores,
and their assumed exposure to AutoLock are given. A
‘’ indicates that AutoLock is currently expected to be
present, while a ‘-’ states unknown exposure.
Smartphone
SoC
AutoLock
Assumed
Core(s)
Typhoon
Twister
A72, A53
A73, A53
A53
A53
A53
Kryo
Kryo
A53
A53
Mediatek MT6750T
- (A72), (A53)
Hurricane, Zephyr
- (A72), (A53)
- (A73), (A53)
Snapdragon 435
Snapdragon 425
Snapdragon 820
Snapdragon 821
Apple A8
Apple A9
Apple A10
Kirin 955
Kirin 960
Kirin 658
Apple iPhone 6
Apple iPhone 6s (Plus)
Apple iPhone 7 (Plus)
Huawei P9
Huawei P10 (Plus)
Huawei P10 Lite
Huawei Y7
LG Harmony
LG V20
LG G6
Oppo A77
Oppo R9s
Oppo R9s Plus
Oppo R11 (Plus)
Samsung Galaxy S6 (Edge)
Samsung Galaxy S7
Samsung Galaxy S8b
Samsung Galaxy S7 Edgea
Samsung Galaxy S8+b
vivo V5
vivo V5 Plus
vivo Y55s
Xiaomi Mi Max 2
Xiaomi Mi6
Xiaomi Mi 5c
a . . . An alternative edition of the S7 Edge features an Exynos 8890.
b . . . The S8(+) can both feature either an Exynos 8895 or a Snapdragon 835.
Snapdragon 820
Snapdragon 835
Mediatek MT6750
Snapdragon 625
Snapdragon 425
Snapdragon 625
Snapdragon 835
(A57), (A53)
- (M1), (A53)
- (M2), (A53)
A72, A53
Kryo
A57, A53
M1, A53
M2, A53
Snapdragon 625
Snapdragon 653
Snapdragon 660
Kryo
Kryo
A53
A53
A53
A53
Kryo
A53
Exynos 7420
Exynos 8890
Exynos 8895
-
-
-



-
-

