FLIS aggregator pages Tech support scams
Features (image)
Features (HTML)
Features (linguistic)
Features (sequence)
Source of landing-page collection
Type of SE attacks to collect
Srinivasan et al. [29] TrueClick [13] WebWitness [24, 25]
Active
(cid:35)
(cid:35)
(cid:35)
(cid:35)
(cid:32)
(cid:35)
Tech support scams Trick banners
Active
(cid:35)
(cid:35)
(cid:32)
(cid:35)
(cid:35)
(cid:35)
File sharing site Depending on users
Passive
(cid:35)
(cid:35)
(cid:35)
(cid:35)
(cid:35)
(cid:71)(cid:35) (network level)
SE downloads
Table 2: Results of web crawling starting from landing page collected with each method.
# Landing pages
# Landing pages lead to SE attacks
# Unique visited URLs
# Unique URLs of visited SE pages
# Unique visited domains
# Unique domains of visited SE pages
# Unique downloaded Malware samples
Search Engine (StraySheep)
5,000
1,060 (21.2%)
50,587
4,716 (9.3%)
4,984
446 (8.9%)
160
Social Media (StraySheep) Alexa Top Sites (Baseline) Trend Words (Baseline) Core Keywords (Baseline)
5,000
46 (0.9%)
30,133
628 (2.1%)
4,507
95 (2.1%)
41
5,000
808 (16.2%)
25,722
1,633 (6.3%)
3,619
151 (4.2%)
186
5,000
65 (1.3%)
16,240
105 (0.6%)
3,537
27 (0.6%)
3
5,000
33 (0.7%)
27,818
80 (0.3%)
8,046
42 (0.5%)
50
depth increased. Therefore, we set the maximum depth to four in
the following experiments.
To determine keywords for selecting lure elements, we followed
the statistical method described in Section 3.2.1. First, we manually
browsed landing pages (e.g., game download, movie streaming,
and torrent sites) and clicked on various HTML elements. We also
browsed intermediate pages navigated from them such as fake
virus alerts, file downloading, and advertising pages served by URL
shorteners. We then gathered 1,447 lure elements from 978 web
pages, which we confirmed finally led to SE attacks. To determine if
the reached web pages contained SE attacks, we used URL/domain
blacklists (Google Safe Browsing, Symantec DeepSight [31], and
hpHosts [4]) to match visited web pages and checked the MD5 hash
values of the downloaded binaries with VirusTotal. We defined an
SE page, which matched the blacklist whose label was associated
with SE attacks (e.g., phishing, tech support scam, and survey scam)
or started downloading malware or potentially unwanted programs
(PUPs) [18, 34]. We used the same method of checking SE pages in
the following experiments. We randomly selected 5,000 non lure
elements that did not redirect to any SE pages from the landing
and intermediate pages. We created lure and non lure elements’
documents containing words extracted from attributes and text
content to calculate tf-idf. Finally, we chose 31 keywords specific to
the lure elements by excluding proper nouns (e.g., game and movie
titles) and words with zero tf-idf values.
4.3 Effectiveness of URL Collection
To show the effectiveness of StraySheep’s landing-page-collection
module, we validated landing pages collected by this module; thus,
we used the web-crawling module to recursively crawl the landing
pages and identified whether visited web pages caused SE attacks.
We compared the number of collected landing pages that led to SE
attacks across the five methods, i.e., the landing-page-collection
module’s two methods (search engine and social media) and three
baseline methods (Alexa top sites, trend words, and core keywords).
We collected 5k landing pages for each method.
Search Engine (StraySheep’s Method) This method collected
a total of 3k core keywords from EC/database sites, such as ama-
zon.com, steampowered.com, billboard.com, and imdb.com, which
we chose from Alexa top 500 sites. These core keywords were di-
vided into five categories: software (game and applications), video
(movie, animation, and TV series), music, eBook, and comic. This
method generated 90k search queries by concatenating the core
keywords with an average of 30 predefined qualifiers for each cat-
egory. It searched the queries using Microsoft Bing Web Search
API [5] (Bing API) and collected about 1M unique URLs. In that
web search, it gathered URLs from up to 30 search results for each
search query. Note that the search queries containing the same core
keywords with different qualifiers sometimes returned duplicate
search results, and some search queries returned less than 30 search
results. Finally, we randomly sampled 5k URLs from the collected
1M URLs to crawl for the crawling experiment.
Social Media (StraySheep’s Method) This method also searched
seven social-media platforms (Facebook, Twitter, Youtube, Dailymo-
tion, Vimeo, Flickr, and GoogleMap) using the same search queries
as the above search-engine experiment. This method extracted
links from posting messages (from Facebook, Twitter, and Flickr),
descriptions of uploaded video (from Youtube, Dailymotion, and
Vimeo), and descriptions of GoogleMap’s My Maps. It used search
forms on Youtube, Dailymotion, and Facebook because they have
flexible search mechanisms and searched Bing API for the other
social-media platforms to gather up to 30 social media postings
for each search query. It searched for 10k search queries (sampled
from 90k search queries) for each social-media platform and found
a total of 130k unique social-media postings. These search queries
often returned less than 30 search queries. This method then gath-
ered 45k unique links by scraping these 130k social-media postings.
Some social-media postings did not include any links or included
multiple links. Finally, we randomly sampled 5k URLs from the 45k
links for the crawling experiment.
Alexa Top Sites (Baseline Method) We gathered the top 5k do-
main names from Alexa top sites and converted them to 5k URLs
by adding “http://” to the domain names.
Trend Words (Baseline Method) We searched the top 1k trend
words collected from Google Trends using Bing API and randomly
selected 5k URLs from the 30k search results (retrieved 30 results
per query).
Core Keywords (Baseline Method) We simply searched 3k core
keywords collected with the above search-engine method in Bing
Session 8: Web Security ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan400Table 3: Results for each web-crawling module.
StraySheep
SE pages
Total
9,374 (5.4%) 173,060 13,559 (2.4%) 562,708 19,241 (3.6%) 540,822
6,283 (8.5%)
5,445 (3.0%) 180,920
513 (6.7%)
9,734
335 (3.4%)
# Total pages
# Unique visited pages
# Unique visited domains
API and randomly sampled 5k URLs from the 90k search results
(retrieved 30 results per query).
5,998 (3.1%) 191,901
437 (3.2%)
13,545
ElementCrawler
SE pages
LinkCrawler
SE pages
Total
Total
73,906
7,660
Table 2 lists the results of web crawling for each method. The
landing pages that led to SE attacks and collected with the search-
engine and social-media methods accounted for 21.2 and 16.2% for
each 5k landing pages. While, those of the three baseline meth-
ods (Alexa top sites, trend words, and core keywords) were much
smaller, 0.7, 1.3, and 0.9%, respectively. From the results of the
search-engine and social-media methods, the numbers of unique
visited URLs and domain names were larger than those of the three
baseline methods. The number of malware samples reached from
the URLs collected with the search-engine and social-media meth-
ods was also larger than that of the other three methods.
4.4 Efficiency of Web Crawling
To evaluate the efficiency of StraySheep’s web-crawling module,
especially, the function to follow lure elements selected by the
selecting component, we compared the ratio of SE pages in visited
web pages and the time to reach SE attacks among three web-
crawling modules: that of StraySheep’s web-crawling module and
two baseline web-crawling modules. Then, we compared crawling
performance of StraySheep with that of TrueClick [13].
Comparison of crawling performance with baseline web-crawling
modules and StraySheep We implemented the two baseline
modules: ElementCrawler, which extracts all visible elements on the
web pages and simply clicks them, and LinkCrawler, which purely
selects all the link elements (HTML a tag with href attribute) and
clicks them. Note that elements selected by ElementCrawler contain
all those selected by LinkCrawler. ElementCrawler and LinkCrawler
are alternative implementations of StraySheep’s web-crawling
module, which are implemented by replacing the selecting compo-
nent (see Section 3.2.1) with the function of selecting all elements or
all links from an HTML source code. The landing pages we input to
the three modules were the same 10k URLs as those collected by the
landing-page-collection module, as mentioned in Section 4.3, which
are the 5k URLs collected from a search engine and another 5k
URLs collected from social media. We newly crawled the 10k land-
ing pages using ElementCrawler and LinkCrawler under the same
condition mentioned in Section 4.3. We compared these crawling
results with those of the above experiment in which StraySheep’s
web-crawling module crawled the 10k landing pages. In the same
manner as the above experiment, we identified SE pages using
blacklists and VirusTotal.
Table 3 shows the number of total pages, unique visited pages,
and domain names for each web-crawling module. The numbers
of unique visited pages and domain names of SE pages visited
with StraySheep’s web-crawling module were 6,283 pages and
513 domain names, which were larger than those of the baseline
modules, and the percentages of pages and domain names of SE
pages were also larger than those of the baseline modules (8.5
and 6.7%, respectively). Although the numbers of total pages of
ElementCrawler and LinkCrawler were three times larger than
Figure 5: CDF of time taken to complete web crawling for
each landing page within 1-hour timeout. Horizontal lines
mean percentage of web crawling completed before timeout.
Table 4: Crawling efficiency of each web-crawling module.
# Unique domains of visited SE pages
Total crawling time [sec]
Crawling efficiency [/sec]
StraySheep ElementCrawler
437
29,698,118
1.5 · 10−5
513
8,429,288
6.1 · 10−5
LinkCrawler
335
28,421,460
1.2 · 10−5
that with StraySheep’s web-crawling module, StraySheep’s web-
crawling module had the best percentage (5.4%) for all SE pages.
This is because StraySheep’s web-crawling module selected lure
elements from thousands of elements to crawl web pages likely to
cause SE attacks, while ElementCrawler and LinkCrawler simply
took turns to click elements and reached many benign web pages.
Next, we analyzed the efficiency of each web-crawling module by
comparing the time taken to complete visiting web pages branching
from the landing page. Figure 5 is a cumulative distribution function
(CDF) of the time for each web-crawling module, which shows the
percentage of web crawling finished at a certain time out of all
web crawling starting from 10k landing pages. We found that 88.5%
of StraySheep’s web crawling module finished within one-hour
timeout. In contrast, ElementCrawler finished only 22.8% of web
crawling within the timeout and LinkCrawler finished 29.9%. The
average time to complete web crawling for each landing page was
14 minutes for StraySheep’s web-crawling module, 49 minutes for
ElementCrawler, and 47 minutes for LinkCrawler.
To measure the web-crawling modules’ ability to reach SE attacks
per total crawling time, we calculated crawling efficiency.
Crawling efficiency indicates the ability to reach the unique domain
names of SE pages per unit of time. Higher crawling efficiency
implies that the module can efficiently reach new SE pages.
We show the crawling efficiency for each web-crawling module
in Table 4. Total crawling time in Table 4 represents the sum of
the times to complete crawling 10k landing pages. The crawling
efficiency of StraySheep’s web-crawling module was 4.1 times
higher than that of ElementCrawler and 5.1 times higher than that
of LinkCrawler, making it the most efficient module to reach SE
attacks. As described in Section 3.2.1, since StraySheep’s web-
crawling module detected lure elements that led to SE pages by
using the selecting component, it visited more SE pages in less time
than the two baseline modules. We also examined the ability to
Crawling Efficiency [/sec] =
# Unique domains of visited SE pages
Total crawling time [sec]
.
00:00:0000:10:0000:20:0000:30:0000:40:0000:50:0001:00:00Time0%20%40%60%80%100%StraySheep:88.5%ElementCrawler:22.8%LinkCrawler:29.9%StraySheepElementCrawlerLinkCrawlerSession 8: Web Security ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan401Table 5: Results of web crawling using StraySheep and
TrueClick.
Unique visited pages
(domain names)
Unique visited SE pages
(domain names)
StraySheep
TrueClick
48,524 (5,809)
7,917 (2,978)
Unique malware samples
266
1
3,897 (219)
523 (78)
Table 6: Unique SE pages observed at each depth by using
StraySheep and TrueClick.
depth
1
2
3
4
Unique SE pages
SE pages crawled using StraySheep
(domain names)
SE pages crawled by TrueClick
(domain names)
97 (44)
845 (86)
1068 (104)
2302 (106)
3,897 (219)
97 (44)
356 (35)
48 (12)
25 (12)
523 (78)
Figure 6: Overlap of SE pages’ domain names observed using
StraySheep and TrueClick.
visit SE attacks that can be reached via multiple web pages. The
details of this examination are given in Appendix A.
Comparison of crawling performance with TrueClick and
StraySheep We also conducted an additional experiment compar-
ing the crawling performance of StraySheep with that of TrueClick
in terms of the ability to reach SE pages and collect malware exe-
cutables. TrueClick is a tool that distinguishes fake advertisement
banners (trick banners) from genuine download links. TrueClick