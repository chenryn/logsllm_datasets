as a court order, while organizations could also request a
takedown through a ‘takedown notice’ [42].
• No action: for a domain registered by a seemingly benign
actor (including domains sinkholed by other security orga-
nizations), no action is taken by law enforcement and the
domain remains with its original owner.
The aim of the Avalanche takedown is to prevent the botnet
owners from interacting with infected machines by blocking
access to the required domains that the DGAs will generate
in the year following the takedown. However, as these DGAs
may generate labels that collide with benign sites, performing
a blanket takedown of all generated domains would harm
legitimate websites. For Avalanche, public prosecutors therefore
ﬁrst had to manually classify domains into benign and malicious:
as shown in Table II, they had to determine an appropriate
action for a few thousand registered DGA domains each year.
For registered domains, an incorrect decision may have
unintended adverse effects [23], [42]. In case of the seizure of
a benign domain, its legitimate owner can no longer provide its
service to end users. Owners may experience lengthy downtime,
as challenging an illegitimate seizure and regaining the domain
can be an opaque and difﬁcult process [42], [49]; it appears
that this also holds for Avalanche domains [21], [66].
Conversely, not preemptively seizing a malicious domain
allows the botnet
to respawn and continue its malicious
operation: as the takedown does not remove the malware from
infected machines, these will continue to establish contact
with DGA domains. Once the botnet owners can obtain such
a domain, the attackers can launch new attacks or spread
malware to additional hosts. The takedown efforts, intended to
permanently stop the malware, are then effectively spoiled.
Manually classifying all DGA domains is a resource- and
time-consuming process, where due to ‘decision fatigue’ [28],
[90], the mental effort in making repetitive decisions could
lead to biases. Given the severe consequences of incorrect
classiﬁcations, our goal is to develop an automated approach
to the classiﬁcation of DGA domains that performs with high
accuracy, in order to relieve human investigators from manual
effort as much as possible. At the same time, this does not
preclude a manual review of those domains that are the hardest
to classify or that could have the most signiﬁcant effects. In
the analysis of our approach in Section V, we quantify how
such a union of automated and manual classiﬁcation can still
lead to a signiﬁcant reduction in required effort. Through such
a reduction in manual effort and time, we can ensure the
correctness of takedown decisions, thereby minimizing negative
effects on website owners as well as end users.
B. Constraints for distinguishing malicious and benign domains
While our base goal is to distinguish malicious and benign
domains, we cannot use previously proposed solutions as they
rely on certain indicators that would not work for the Avalanche
3
TABLE III.
OVERVIEW OF GOALS AND STRATEGIES FOR THE
DIFFERENTIATION OF BENIGN AND MALWARE/DGA DOMAINS.
Context/Detection goal
Active malware domains
within regular trafﬁc
Likely DGA domains
within regular trafﬁc
Future malicious domains
at registration
Benign domains within
known malware domains
Benign domains within
future DGA domains
Individual
patterns
Proactive
analysis
No active
connections Related work















[15], [16], [19]
[26], [78], [96]
[33], [38], [86]
[47]
Our work
use case. Concretely,
these indicators no longer hold for
malicious domains (e.g. bulk registration), cannot be observed
by us (e.g. detecting malware activity), or are counterproductive
(e.g. alerting the attacker). Table III summarizes how the
different contexts, goals and strategies of previous works do
not fully satisfy our requirements.
The reason is that the assumptions made in previous work
no longer hold due to a different balance between malicious
and benign domains: instead of detecting domains with clear
malicious behavior among a (large) set of regular trafﬁc, we
assume that domains are malicious (they would be contacted
by malware) and need to detect benign domains (i.e. accidental
collisions). While in previous approaches, domains that do
not exhibit strong indicators of maliciousness (offered by the
former) are benign, the absence of such indicators in our use
case means that we may not make such an assumption, and
makes those previous approaches ineffective for Avalanche.
We translate these unique characteristics of the Avalanche
takedown into three constraints. First, we need to take the
characteristics of benign domains into account as well, by de-
veloping appropriate features that capture individual differences
in registration and conﬁguration. Second, as we cannot leverage
ongoing malware activity itself, we need to develop features
that allow for a proactive analysis. Third, attackers may not
evade or detect data collection, so we may not make any active
connections to domains in order to remain stealthy. In this
section, we elaborate on these challenges and differences that
make previous approaches ineffective for our use case.
a) Individual registration and conﬁguration patterns:
Previous work often assumes that speciﬁc (bulk) patterns in
the setup of domains indicates maliciousness.
For example, PREDATOR [38] relies on the observation
that in order to evade blacklisting, malicious spam domains
are registered in bulk (over 50% in groups of ten or more at
one registrar in ﬁve minute intervals), causing these temporal
clusters to be similar in infrastructure, lexical composition and
life-cycle stage. In a similar spirit, Premadoma [86] relies on
similarities in registrant data and the prevalence of malicious
domains at speciﬁc facilitators (such as registrars) to detect
sustained large-scale malicious campaigns. However, these
patterns are no longer usable for our set of domains. Attackers
only need to register one of the domains that the DGA outputs
at a given time, so they no longer need to register domains
in bulk, as is necessary for spam domains, also reducing the
likelihood that they share e.g. registrars. Figure 1 conﬁrms this:
93.5% of malicious domains in the 2017 and 2018 iterations
of the Avalanche takedown are registered in clusters of fewer
Fig. 1. Cumulative distribution of registration counts for a given day and
registrar, for malicious domains from the 2017 and 2018 iterations.
than 10 domains at their given registrar in one day (as opposed
to the ﬁve minute interval in PREDATOR [38]). Moreover, the
accidentally colliding benign sites do not have any relationship
and will therefore not share any properties either.
Systems such as DeepDGA [96] and FANCI [78] detect
DGA domains from linguistic patterns in their label. However,
we know that all domains are either generated by a DGA or
hard coded in malware, so it would be incorrect to use such
patterns to categorize them as malicious.
In summary, because of the characteristics of our domain
set (singular malicious and unrelated benign domains, all output
by a DGA), many of the assumptions that the above approaches
make on patterns that determine maliciousness are no longer
valid. We must therefore resort to capturing more generic,
common registration and conﬁguration patterns for individual
domains. These patterns should not only capture ‘obvious’
maliciousness, but also properties that indicate benignness.
b) Proactive analysis: Previous work relies on observing
ongoing malicious behavior: e.g. Exposure [19] leverages
irregular DNS conﬁgurations and access patterns to detect ‘do-
main ﬂux’ [41]; Pleiades [16] captures patterns in NXDOMAIN
responses to DNS queries by active malware. These systems
rely on ongoing malware activity that generates the analyzed
trafﬁc. Similarly, systems that use only the label to detect
DGA candidates based on their appearance [26], [78], [96]
need ongoing malware activity, otherwise infected hosts are not
contacting malicious domains that are then visible in trafﬁc.
Crucially, because malicious domains have to be taken
down before they can cause any harm, we have to classify
them proactively, i.e. before infected machines would actively
query the malicious domain. This distinguishes our work from
the above works, as we cannot analyze and rely on patterns
within any (ongoing) malware activity. While we can and do
use features similar to those from previous systems, we are
restricted to detecting patterns in registration, conﬁguration,
and regular trafﬁc. Moreover, we already know that a DGA
generated the domains that we have to classify, meaning that
we start with an assumption that the domains are malicious.
c) No active connections to domains: Internet measure-
ments can be classiﬁed into two groups: passive collection,
where already ongoing trafﬁc is observed, and active collection,
where new trafﬁc is injected into the network. Notos [15] and
Exposure [19] are examples of systems that analyze patterns
in passively collected DNS queries. In contrast, Mentor [47]
relies in part on website content features to measure positive
domain reputation, requiring active and targeted data collection
through crawling the domains.
4
051015202530Number of registrations for a given day, registrar020406080100Percentage of domainsMaliciousWhile we have a similar goal to Mentor of detecting
benign domains within presumably malicious domains, we
avoid including features that require us to actively connect
to domains. Malicious actors are namely known to detect
active scanning and respond differently to appear more benign
(‘cloaking’) [46], and could thus mislead our classiﬁcation.
More broadly, such probes could alert them of efforts to
investigate and disrupt malicious infrastructures, allowing
attackers to shift their approach or hide any traces to avoid
repercussions [3]. A stealthier analysis without targeted active
data collection therefore avoids endangering the effectiveness
of ongoing investigations [19], [102].
C. Ground truth data
The advantage of our collaboration with law enforcement
is that we can use their manual classiﬁcation of benign and
malicious domains from the takedown as a trustworthy source of
ground truth. Previous studies mostly rely on publicly available
blacklists and whitelists as the labeled ground truth [89], but
malware blacklists have been found to contain benign parked or
sinkholed domains and are ineffective at fully covering domains
of several malware families [54], while lists of popular domains
commonly used as whitelists can easily be manipulated by
malware providers [56].
However, the real-world context of the Avalanche takedown
affects the composition of our ground truth data. Concretely,
our data set is relatively small, as seen in Table II. Plohmann
et al. [71] have seen a similarly small proportion of registered
domains among DGA domains. We can expect this number to
be small: malicious actors only need to register few domains,
as the malware will try all DGA-generated domains; conversely,
benign actors are less likely to be interested in using the often
random-looking domains generated by the DGAs. Previous
studies are able to evaluate their approach on much larger data
sets, albeit self-constructed and arbitrarily selected. Nonetheless,
training on a small data set is a challenge that prosecutors would
also face, and our analysis is therefore valuable for informing
them on the feasibility, constraints and beneﬁts of an automated
approach for such a practical use case.
D. Ethical considerations
We use the data set of the Avalanche takedown shared with
us by our law enforcement partner. We augment this data with
third-party data, avoiding unnecessary active probes of both
benign and malicious domains. However, given the sensitivity
of the former and commercial agreements for the latter, we
cannot share this data with external parties. We release the data
processing scripts and resulting models at https://github.com/
DistriNet/avalanche-ndss2020 to support reproducibility.
We assisted law enforcement agencies by applying our
approach to the 2019 Avalanche iteration. While the use of
machine learning for law enforcement purposes may be con-
tested [69], human investigators may similarly make involuntary
errors, e.g. due to ‘decision fatigue’ [28], [90].
IV. DATA SET ANALYSIS AND FEATURE EXTRACTION
To determine a suitable takedown action for algorithmically
generated domains (AGDs), we search for relevant features
providing a full view of their properties over time. We
then create a classiﬁer that detects whether patterns in these
properties are more likely to correspond to a benign or malicious
domain without having to rely on ongoing malware activity.
In this section, we ﬁrst analyze how different data sources
can track different stages of the domain life cycle and we discuss
the insights on how features capture contrasting properties of
benign and malicious domains. Then, we select the ﬁnal set of
features and discuss the reasons for omitting certain features.
A. Life cycle of a domain
To correctly identify the intent of a domain registration,
we need to observe patterns in the domain life cycle, as they
indicate who obtained the domain, how they use it, and how
they value it. For each identiﬁed step, we determine which
relevant features capture the actions of the domain owner and
list sources that track this information. Through our analysis,
we can then ensure that our selection of features and data sets
appropriately covers each step.
L1. Choice of the domain name: The prospective owners
of a domain (the registrants) must ﬁrst choose the domain name
that they want to purchase. Usually, the name is chosen to be
easily memorized, sufﬁciently short, and representative of the
service provided by the domain, but as malicious actors will
need to produce domains in bulk, they will generate them
automatically. The resulting names have a random or patterned
appearance that we can capture in lexical features on the label
itself in order to automatically detect DGAs [77], [78], [96].
L2. Registration of the domain: A registrant registers a
domain through a registrar, typically paying a registration fee for
at least 1 year [44] (although free and shorter offers exist [35]
that tend to attract abuse [50]). The registrant identity, the
registrar used, and the timestamps of the registration start and
end are then made publicly available in the WHOIS database.
We can then extract the registration patterns to distinguish
benign and malicious sites [60]. Due to privacy concerns
and regulations (e.g., the European General Data Protection
Regulation), the publicly available identity of the registrant
may be obfuscated: the real identity is then only available to
the registrar and the top-level domain (TLD) registry. This
data may be leveraged in collaborations with registries, e.g. for
detecting malicious domains at registration time [86], [93].
L3. DNS conﬁguration: Once a domain has been
registered, its entry in the Domain Name System (DNS) must be
conﬁgured to allow discovery of its services using the domain
name. The nameserver is passed onto the TLD registry and will
appear in its zone ﬁles. The domain resource records conﬁgured
in the nameserver zone ﬁle then become available for querying.
Active DNS data sets (collected by e.g., OpenINTEL [91])
rely on scanning zone ﬁles or popular domains to obtain these
records, while passive DNS data sets (collected by e.g., Farsight
Security [32]) extract them from monitored DNS responses.
Both types of data sets have been used to detect malicious
domain registrations and activity [19], [52], [84].
L4. Setup of
the service infrastructure: The main
purpose of a domain name is usually to provide a service
for which an infrastructure needs to be set up. The records
stored in DNS may reveal the hosting infrastructure or third-
party service providers (e.g., cloud providers) from which
5
actors that enable malicious activity can be derived [72], [101].
A scan of open ports accompanied by “banner grabs” may
reveal provided services and the content available through the
service may reveal its purpose. Such an operation requires
active probing of the domain, which either can be executed
ad hoc or is already performed regularly by e.g. Censys [30]
and Project Sonar [73], whose scale enables analyses of botnet
devices [14]. Furthermore, certiﬁcates obtained by the domain
owner for their service may also be tracked in Certiﬁcate
Transparency logs [55].
L5. Service activity: Once the service is set up, end
users can start interacting with it. Trafﬁc to the service may
be logged either at the server, the client, or in any network in-
between. These logs can then be analyzed for multiple purposes.
Malicious behavior can be detected and publicly shared in