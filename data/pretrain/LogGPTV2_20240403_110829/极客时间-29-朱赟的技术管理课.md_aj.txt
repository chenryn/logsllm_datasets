# 15 \| 每个工程师都应该了解的：系统拆分四年前，我加入了风头正劲的 Square 公司。两年前，我又加入了涨势甚猛的Airbnb公司。在我加入的时候，这两个公司都有上百名的工程师，网站和主要产品的核心功能也已齐备。两家创业公司从 0 到 1的创业过程我并没有亲身经历，但是两次都恰好经历了公司从 1 到 N的扩张过程和业务拆分的过程。今天我就和你聊聊，公司从 1 到 N 发展过程中的系统拆分问题。
## 创业初期的代码现状在 Square 刚刚起步的时侯，整个产品都是基于 Ruby on Rails构建的，所有的产品和功能代码几乎都在一个代码库里。等到我进入 Square 的时候，有一些服务已经从 Ruby代码中分离出来了，形成了单独的 Java 或者 Ruby服务，然而大部分功能还是在一大块 Ruby 代码里。当时，几乎所有的工程师每天都在这一份基准代码（CodeBase）里写程序。虽然有严格的代码审核过程和规范的开发流程，但是，不同功能的代码模块会产生交叉影响，不同工程师改动的模块会有重合或牵连，所以，系统还是会时不时出现问题。那时候， Square 的做法是：在周五对本周所有的代码进行代码审查（CodeReview），通过审查之后，把修改合并到主分支，然后再发布到生产环境。这种做法虽然可以避免产生人为错误，但是非常不灵活，比如，每周只有周五有一次机会将改进的代码部署到线上。可以想象一下，一百多名工程师，就算只有三分之一的人在这个代码池子里改代码，一周累积下来，已经有不少的改动了。于是，当时 Square有个系统管理员组（Sysops），专门负责每周五的部署。我也是工作近半年的时侯，因为表现不错才被荣幸地"选拔" 进了这个 "特别行动小组"，承担部署的重任。那么说，每次的部署是一幅什么样的场景呢？部署开始的时候，一正一副两位工程师正襟危坐，多个显示器同时打开，进行各种指标监控。工程师先将在测试环境中测试无误的代码部署到若干生产机器上，进行灰度发布，这就意味着有一部分用户的访问量会调用新代码。如果监控没有发现异常的话，再进行全量发布，这周修改的代码就会被部署到几百台机器上。一旦出现异常，监控系统就开始各种红色告警，工程师们会立刻扔下手中的可乐或者咖啡，进入备战状态，停止系统，进行数据回滚、排查问题、修复，从头开始把流程再来一遍，直到代码安全地部署到线上并能够正常运行为止。随后的两年，我们进行了细致的业务拆分，等到我离开 Square的时候，大部分可以独立出来的服务都已经拆分出来，很多系统可以分别部署和上线，也就再没有了那种激动人心的周五上线日。Airbnb的情况也差不多，我刚加入的时候，代码状态甚至更原始一些。不同的是，Airbnb没有一周只能部署一次代码的规矩，所有的工程师只要准备好了就可以做部署上线。这样做的优点是可以快速迭代，每次部署的代码改动也很小，缺点是几乎任何时候都有人在部署代码。时时的部署也就意味着，红色告警随时可能在身边响起。``{=html}
## 为什么系统需要进行业务拆分为什么会出现这种情况呢？我在文稿中给大家放了一张图，图例很好地阐述了效率和复杂度的关系。![](Images/2aeef13e45e1c59e1a51f1891ef6c946.png){savepage-src="https://static001.geekbang.org/resource/image/07/46/073b59403af00ce2a3f14dfd40d29146.png"}图的 X 轴代表了基本复杂度（Base Complexity），Y轴代表了生产效率。我们可以看出，当一个公司规模很小的时候，基本复杂度相对较小，所以单一代码库（Monolith）的效率就会高。然而，随着公司业务的扩展，访问量的增加，其基本复杂度就会逐步升高，达到某一个临界点后，微服务（Microservice）的效率就远远高于单一代码库。关于微服务，这里就不做详述了，极客时间会发布专门的微服务知识产品。为了解决效率和复杂度的问题，无论是在 Square 还是Airbnb，我都有一大部分时间花在了业务拆分上。下面，我就和你聊聊这几年做业务拆分的一些心得和踩过的坑。
## 业务拆分并不像看起来那么简单我们从一个例子谈起，比如你有一个功能模块，大概可以分成四部分。其中模块 A连接一个外部模块 D，A 输出的结果，会被模块 B 和 模块 C 分别调用。![](Images/e5a3f3a3dae5443809fea872c50b83d8.png){savepage-src="https://static001.geekbang.org/resource/image/0d/41/0d025d3dbf4fced55f898f95c717fd41.jpeg"}针对这样的模块，我们可以做一个集成测试（IntegrationTest），在模拟（mock）D 的情况下，测试 A、B、C 是不是可以正确运行。如果有人修改了模块 A 的返回值，但忘了修改模块 B 和 C的接口，测试就会立刻失败，不会存在因为忘了修改接口而测试通过的可能。一旦通过了集成测试，所有的改动会在一次部署中同时展现（Rollout）或者回滚（Rollback），非常容易控制。![](Images/cc6dc593243af996dd9ab070d9ce6610.png){savepage-src="https://static001.geekbang.org/resource/image/49/71/497117af9fcdf178319ed60f357e4271.jpeg"}随着业务的发展，A、B、C三个功能被拆分成三个独立的服务（Service），各自保存在不同的代码库，或者是同一个代码库不同的服务容器（ServiceContainer）里。这样的话，测试用例就不能综合测试这三部分的功能了，只能模拟相互的请求（Request）或响应（Response），如果在开发环境下联调测试，则需要本地建立这三个服务。根据每个公司开发环境的成熟度，这一步可能很简单，也可能耗掉你几个小时，才能让不同服务在本地正常运行，并且需要通过RPC 相互调用。RPC就是远程过程调用的意思。有远程调用，就会用到本地桩和过程调用，这涉及了本地多服务的配置，过程繁复，不小心就会引入错误，测试成本也会随之增加。如果程序员在改动的时候并没有按照正常流程进行测试，尤其是一些 "很小的"或者 "不相干的" 改动，一旦部署上线，系统就可能出现各种各样的问题。就算一切顺利，有一天，A 修改了自己的接口，RPC调用中请求的一个字段（Field）从 integer 变成 string 类型。如果 A、B、C还在一起的时候，我们在代码库里把三者的相应类型都改了就好；但是，现在A、B、C 都是独立的服务，可以独立地部署，这事就有点麻烦了，我们很难保证A、B、C 的部署总是完全同步。有经验的读者知道，我们为接口做个向后兼容（BackwardCompatibility）就好了，只要：1.  先改 A 的接口，让它接受 integer 也接受 string，如果请求是    integer，先做一下转换，然后发布这个改动；2.  修改 B 和 C 的接口，响应从 integer 变成 string 类型，发布这个改动；3.  等到 A、B、C 的新代码都稳定了，再修改 A 的接口，只接受 string    类型的参数，发布这个变化，我们就完成了所有接口的改动。这样就没问题了么？并没有这么简单。因为 A 还有其他代码，所以在上面的第二步之后，你有可能发现 A的代码有一个问题，需要将线上的代码回滚到之前的某个版本。这时候 B 和 C的接口已经是 string 类型了，而 A 只接受integer，然后，线上就是频繁请求报错。当然，这里举的是一个简单的例子，我们可以通过延长第一步的兼容时间来避免出现类似问题，但是，实际工作中的改动不会是这么简单的依赖关系，或者没有约束关系，所以，服务之间无缝修改接口，是一个需要非常小心的问题。
## 业务拆分时的注意事项系统拆分后的痛远远不止于此。就我自己的经历，大概有下面的这些感受。
### 测试会变得异常复杂因为模块被独立出来之后，并没有办法很方便地写出集成测试用例。一个做法是模拟出所有接口的请求和响应，但实际上大部分时候根本没法测试跨服务的改动，这种做法多少有点自欺欺人的味道。另一个方法就是在本地配置好所有的服务，用真实的服务响应来测试。但是撇开本地设置多服务的复杂度，保证本地服务一直是最新代码，同样也是一件麻烦的事。尤其是同步开发的工程师变多以后，可能你正在测的服务没有问题，但是在你做测试的同时，已经有同事对你刚刚测试的服务做改动推送到了主分支上。测试的复杂度，几乎是软件工程中的万恶之源。当每个小改动都让测试变得耗时耗力时，就难保没有偷工减料的员工，大家揣着"我的改动应该没问题"的侥幸心理，不去做完整测试，就把自己的代码合并进主分支。尤其是大部分这么做的改动都没有问题，时间一长，侥幸心理一再滋长，人们直接合并代码的胆子也越来越大，终于有一天会把生产系统彻底搞挂。针对这个问题，我和在 Google 工作的朋友交流过。Google 或者 Facebook这样的大公司里，整个系统做得相当成熟，测试环境做得非常完美。每个服务都对应设置了在线的测试服务，写集成测试极其方便，或者把服务做成开箱即用，工程师可以一次性地建立所有的本地服务进行联调和测试，但是，对于大部分创业公司来说，很难达到这个水准。