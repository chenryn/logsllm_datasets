title:A Logic of Secure Systems and its Application to Trusted Computing
author:Anupam Datta and
Jason Franklin and
Deepak Garg and
Dilsun Kirli Kaynar
A Logic of Secure Systems and its Application to Trusted Computing
Anupam Datta
PI:EMAIL
Jason Franklin
PI:EMAIL
Deepak Garg
PI:EMAIL
Dilsun Kaynar
PI:EMAIL
Abstract
We present a logic for reasoning about properties of
secure systems. The logic is built around a concurrent
programming language with constructs for modeling ma-
chines with shared memory, a simple form of access
control on memory, machine resets, cryptographic oper-
ations, network communication, and dynamically loading
and executing unknown (and potentially untrusted) code.
The adversary’s capabilities are constrained by the system
interface as deﬁned in the programming model (leading
to the name CSI-ADVERSARY). We develop a sound proof
system for reasoning about programs without explicitly
reasoning about adversary actions. We use the logic
to characterize trusted computing primitives and prove
code integrity and execution integrity properties of two
remote attestation protocols. The proofs make precise
assumptions needed for the security of these protocols and
reveal an insecure interaction between the two protocols.
1. Introduction
Contemporary secure systems are complex and de-
signed to provide subtle security properties in the face
of attack. Examples of such systems include hypervi-
sors, virtual machine monitors, security kernels, operating
systems, web browsers, and secure co-processor-based
systems such as those utilizing the Trusted Computing
Group’s Trusted Platform Module (TPM) [1]. In this paper
we initiate a program to formally model abstractions
of such systems and specify and analyze their security
properties in the presence of a general class of adver-
saries. Speciﬁcally, we introduce the Logic of Secure
Systems (LS2) and use it to carry out a detailed analysis
of Trusted Computing systems. The logic is built around
a programming language for modeling systems and is
inspired by a logic for network protocol analysis, Protocol
Composition Logic (PCL) [2]–[5].
Programming Model. The programming language is
designed to be expressive enough to model practical
secure systems while still maintaining a sufﬁciently high
level of abstraction to enable simple reasoning. Following
PCL,
the language includes process calculi and func-
tional constructs for modeling cryptographic operations,
straightline code, and network communication. We in-
troduce constructs for modeling machines and shared
memory, a simple form of access control on memory,
machine resets, and dynamically loading and executing
unknown (and potentially untrusted) code. The primitives
for reading and writing to memory are inspired by the
treatment of memory cells in impure functional languages
like Standard ML [6]. We model memory protection, a
fundamental building block for secure systems [7], by
allowing programs to acquire exclusive-write locks on
memory locations. The treatment of dynamically loading
and executing unknown code is novel to this work.
While these constructs are the common denominator
for many secure systems, including the trusted comput-
ing systems examined in this paper,
they are by no
means sufﬁcient to model all systems of interest. The
language, however, is extensible in a modular fashion, as
we illustrate by extending the core language (presented
in Section 2) with a trusted computing subsystem (in
Section 3). At a high level, each system component can be
viewed as exposing an interface. For example, the inter-
face for memory includes read, write, and reset operations.
Adding a new component to the system involves adding
operations in the programming language corresponding
to the interface exposed by it. Platform Conﬁguration
Registers (PCR) in the TPM are an example since they
can be modeled as a special form of memory that may be
accessed via read, reset, and a new extend operation. Some
extensions can have a more global effect on the language
semantics. For instance, adding the reset operation to the
language affects both how state of local memory and TPM
PCRs may be updated.
Interfaces to system components also provide a useful
conceptual view of the adversary. Since the capabilities
of the adversary are constrained by the system interface,
we refer to her as a CSI-ADVERSARY. For example, the
adversary can write to unprotected memory locations, but
can only update PCRs through the extend operation in
its interface. Formally, the adversary may execute any
program expressible in our programming model, i.e. the
adversary can perform symbolic cryptographic operations,
intercept messages on the network, inject messages that it
can create, read and write memory locations that are not
explicitly locked by another thread, and reset machines.
Because of these capabilities, the adversary can launch
a broad range of attacks on the network and the local
machines including replay attacks, modifying and inject-
ing malicious code on local machines, and exploiting race
conditions to compromise systems.
Logic. Security properties of programs are expressed
in LS2 using modal formulas of the form [P]tb,te
A,
which means that formula A holds whenever thread I
executes exactly the program P in the time interval (tb,te],
irrespective of the actions executed concurrently by other
threads including the adversary. The thread I identiﬁes the
principal executing the program, the machine on which the
program is being executed, and includes a unique identi-
ﬁer. The formula A expresses security properties, such as
conﬁdentiality, integrity, authentication, as well as code
and execution integrity. The logic includes predicates that
reﬂect the programming language constructs for shared
memory, memory protection, machine resets and a form
of unconditional jump to model branching to dynamically
loaded code.
I
Security properties are established using a proof system
for LS2. A central design goal that LS2 achieves (following
PCL) is that the proof system does not mention adversary
actions. Instead,
the semantics and soundness of the
proof system guarantee that if [P]tb,te
I A is provable, then
A holds in all
traces in which I completes execution
of program P, including those that contain adversarial
threads. This implicit treatment of adversaries simpliﬁes
proofs signiﬁcantly. Designing a sound proof system that
supports this local style of reasoning,
in spite of the
global nature of shared memory changes and execution
of dynamically loaded unknown code, turned out to be a
signiﬁcant technical challenge.
We formalize local reasoning principles about shared
invariance of
memory with axioms that reason about
values in memory based on local actions of threads that
hold locks (see Section 2). This approach is technically
similar to concurrent separation logic, whose regions
resemble LS2’s locks [8], but distinct from formal systems
which support global reasoning about concurrent shared
memory programs [9]. Our initial idea to reason about
execution of dynamically loaded code was to treat the
code being branched to as a continuation of the code
calling it. However, this approach does not work for the
case where the code being branched to is either read from
memory or received over the network, because nothing
can be determined about the called code by looking at
the caller’s program. As a result, traditional methods for
proving program invariants such as those based on Hoare
logic and its extensions
[10]–[12] do not apply to this
setting. Yet this is exactly what we needed to reason in
the face of adversaries who can modify or inject code
into the system. Our ﬁnal technical approach for reasoning
about execution of dynamically loaded code is based on
a program invariance rule, which we elaborate on in
Section 2 and illustrate in Section 4.1.
Trusted Computing. We model and analyze two trusted
computing protocols that rely on TPMs to provide in-
tegrity properties:
load-time attestation using a Static
Root of Trust for Measurement (SRTM) [13] and late-
launch-based attestation using a Dynamic Root of Trust
for Measurement (DRTM) [14]–[16]. In doing so, we
make the following contributions. First, we formalize,
using axioms,
the behavior of core trusted computing
primitives including the TCG’s widely-deployed secure
co-processor,
the Trusted Platform Module (TPM), as
well as recently introduced hardware to support the late
launch of a security kernel
in a protected execution
environment. Hardware implementations of late launch are
publicly available in both AMD’s Secure Virtual Machine
Architecture (SVM) [15] and Intel’s Trusted eXecution
Technology (TXT) [16]. These axioms provide a succinct
speciﬁcation of the primitives, which serve as building
blocks in the proofs of the protocols (see Section 3).
Second, we formally deﬁne and prove code integrity and
execution integrity properties of the attestation protocols
(Section 4; Theorems 2–4). To the best of our knowledge,
these are the ﬁrst logical security proofs of these protocols.
Finally, the formal proofs yield insights about the secu-
rity of these protocols. The invariants used in the proofs
make precise the properties that the Trusted Computing
Base (TCB) must satisfy. In Section 4, we describe these
invariants and manually check that an invariant holds on
a security kernel implementation used in an attestation
protocol. We demonstrate that newly introduced hardware
support for late launch actually adversely affects the
security of previous generation attestation protocols. We
describe an attack that utilizes hardware support for late
launch to exploit load-time attestation protocols that mea-
sure software starting at system boot. The attack enables
an adversary to report false system integrity measurements
that are not tied to the actual state of the platform. This
attack could be used to exploit Digital Rights Management
(DRM) protocols that rely on load-time attestation.
2. Logic of Secure Systems
We introduce the syntax of the Logic of Secure Systems
(LS2) in this section. The next section introduces features
of LS2 that are speciﬁc to trusted computing. Due to lack
of space, we restrict technical descriptions to the extent
necessary to explain the main concepts and application,
and refer the reader to a technical report for details [17].
Expressions/Values
e
Machine
Location
Action
m
l
a
ˆX, ˆY
K
K−1
x
(e,e(cid:48))
SIGK{|e|}
ENCK{|e|}
SY MENCK{|e|}
H(e)
P
::= n
|
|
|
|
|
|
|
|
|
|
::= m.RAM.k | m.disk.k | m.pcr.k | m.d pcr.k
::= read l
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
::= (cid:104) ˆX,η,m(cid:105)
write l,e
extend l,e
lock l
unlock l
send e
receive
sign e,K
verify e,K
enc e,K
dec e,K
symenc e,K
symdec e,K
hash e
eval f ,e
proj1 e
proj2 e
match e,e(cid:48)
new
Number
Agent
Key
Inverse of key K
Variable
Pair
Value e signed by private key K
Value e encrypted by public key K
Value e encrypted by symmetric key K
Hash of e
Program reiﬁed as data
Read location l
Write e to location l
Extend PCR l with e
Obtain write lock on location l
Release write lock on location l
Send e as a message
Receive a message
Sign e with private key K