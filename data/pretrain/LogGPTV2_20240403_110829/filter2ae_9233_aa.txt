**1、背景**  
去年听学长说2018秋招的AI岗位竞争挺激烈的，今年又听学长说2019秋招的AI岗位很激烈，原因无非是做AI方向的同学越来越多，而且很多都是跨专业的。大环境越来越激烈，但是一些公司表示还是招不到满意的人。那么未来几年内，哪个方向的机器学习人才最紧缺呢？我觉得有两个方向，第一个方向是机器学习+垂直领域，第二个方向是机器学习落地。早几年AI行业的招聘是走粗放模式的，只要你是调包侠调参怪，学历不错，都有好的offer，如今AI领域的岗位正在朝精细化发展，特定领域的机器学习专家最紧缺，这就是机器学习应用于垂直领域，所有的跨领域应用最终都是为了机器学习落地产生商业价值，这就需要全栈式机器学习人才，从需求、模型、算法、高效工程实现、部署和优化一把梭做好的机器学习人才。  
本篇文章从机器学习在垂直领域的应用出发，具体阐述机器学习在网络空间安全领域的应用。
**2、机器学习在网络空间安全垂直领域的应用**  
我国于2015年正式批准设立“网络空间安全”国家一级学科，目前网络空间安全的研究主要涉及五个研究方向，即网络空间安全基础、密码学及应用、系统安全、网络安全、应用安全。  
目前机器学习在网络空间安全基础、密码学及应用两个方向的研究较少涉及，而在系统安全、网络安全、应用安全三个方向中有大量的研究。其中，系统安全以芯片、系统硬件物理环境及系统软件为演技对象，网络安全主要以网络基础设施、网络安全监测为研究重点，应用层面则关注应用软件安全、社会网络安全。  
个人比较关注网络安全和应用安全，而第三届阿里云安全算法挑战赛的主题是恶意软件分类，属于应用安全，所以我尝试以本次比赛为例分析机器学习在安全垂直领域的应用。
**3、第三届阿里云安全算法挑战赛**  
第三届阿里云安全算法挑战赛基本介绍：使用来自windows可执行程序经过沙箱程序模拟运行后得到的API指令序列数据集，区分五类恶意软件。竞赛背景、数据说明等详细介绍参考天池第三届阿里云安全算法挑战赛。  
我注意到此次比赛组队规则中有一句：鼓励算法背景选手和安全背景选手跨界组合。这或许正验证着机器学习和垂直领域跨领域结合的深度问题。仅有算法背景的同学和有跨领域背景的同学同时去做垂直领域，或许结合的深度有所不同，而产生意想不到的结果。所以我分别从算法工程师的算法角度和安全算法工程师的安全算法两个角度去分析此次比赛。  
**3.1 第一层面：算法**  
仅从算法工程师（无安全领域背景）的层面分析待解决安全问题，浅层次结合机器学习和垂直领域。  
3.1.1 探索性数据分析  
在建模之前，我们都会对原始数据进行一些可视化探索，以便更快地熟悉数据，更有效进行之后的特征工程和建模  
打开训练集，取前5行观测，
我们可以看到给定的数据中包含数值型和文本型的特征。  
看一下训练集有多少数据，
训练集有409631049个样例，  
我们先看看目标变量label，
绘成柱状图，
感染型病毒文件在五类恶意软件中数量最多，有3397个，其次是挖矿程序文件，有744个，DDOS木马文件有598个，勒
索病毒文件有287个，蠕虫病毒文件最少，只有53个。  
再看看api的数量分布，
可以看到排名靠前的api主要功能是注册表读写、文件读写、获取系统信息，  
再看看不同label的api数量分布，  
看第一类勒索病毒api数量分布，
看一下top10 api，  
3.1.2 赛题理解  
预分析完数据后，再结合整体比赛介绍，我们来还原一下比赛的数据集是如何产生的：假设某个文件有以下的api调用顺
序，采集精度是10ms，这里忽略api的return value，  
那么将生成如下数据文件，  
3.1.3 抽象问题  
每个文件有多个api调用，api之间可能存在一定的序列关系，同时api可以看成是一个个单词，这样文件的api调用就是一个个文本，所以要解决的分类问题可以看成是NLP领域中含单词顺序的文本分类问题。
3.1.4 解决问题  
解决问题的方式大概有三种：
  1. 就用NLP领域的文本词带模型来建模  
2.用统计机器学习中的传统统计特征来建模分析  
3.从深度学习领域处理时间序列的序列建模角度进行训练模型  
现在来解决问题：  
1) 仅使用NLP领域的文本词带模型训练模型  
特征提取和算法分别使用n-gram tfidf和xgboost，其中n-gram可分为unigram、bigram ……9-gram
、10-gram。做了四 组实验，如表1所示：  
表1（注：表中mlogloss是原始的logloss，loss是官方定义的loss）
可以看到单纯的文本向量已经拥有不错的效果，bigram效果最好，unigram到bigram，loss有较明显的下降，优化比较明显，再往下到trigram优化效果反而不好，结合三种gram，较trigram效果略有提升。分析下原因：可能是由于文件的api之间存在一定的时间序列关系，所以当使用含有一定的序列建模能力的bigram时，效果会得到提升，但是可能api之间的序列关系太长了，可能分布几百到几十万不等，使用n-gram tfidf很难对长序列建模，序列关系不确定可能导致trigram效果不好。
2) 仅使用统计机器学习领域的统计特征训练模型  
学习了排行榜第55名、第7名和第1名的队伍的统计学特征提取方式，发现提取的统计特征越全面、越多，模型效果一般越好，这里比较下三个队伍在统计学领域对本次比赛中安全数据的处理方式。  
55 th的队伍提取了一些全局特征和局部特征，如表2；7
th的队伍提取的统计特征为全局特征和api特征，全局特征相比55th并没有大的改变，关键在于新增的api特征：每个文件中的api在总api中出现的次数和比率。总api去重后有300个左右，按照这种特征处理方式提取特征，增加了600多个api特征；1
st的队伍提取的统计特征非常全面，主要分为四大类：全局特征、局部组合特征、高阶局部特征、2-gram局部特征展开。和之前两只队伍比，全局特征和局部组合特征基本不变（全局特征相比55th增加了quantile分位数），主要加入了高阶局部特征和2-gram局部特征，如表3，
测试了三组实验，如下表：
分析实验结果：可以看到统计特征越全面越多效果一般越好，全面的统计特征效果好于tfidf效果。存在的问题是较难全面地提取统计特征，包括但不限于全局特征、局部特征、高级局部特征等等，并且有些特征可能会过拟合，操作起来有点麻烦。
3) 结合NLP特征和统计学特征训练单模型  
合并第55th队伍的统计学特征和NLP下的特征训练单模型，
对比表1，观察train loss 下降了，valid
loss不但没有下降，反而提升了一点，原因应该是tfidf的文本向量的效果已经不错，加入传统简单统计特征会过拟合（这里有疑惑，7
th队伍就没有过拟合），但是由于特征的可解释性问题，具体无法解释。目前只用lgb实验了合并两个领域的特征向量训练单模型，会过拟合。未实验模型融合的方法，即分别使用两个领域的特征训练两个单模型再模型融合，猜想效果会好些，应该不会过拟合。  
合并7th队伍的统计学特征和NLP下的特征训练单模型，
对比上表，观察加入55th的统计特征，valid
loss有一定的回升，说明7th加入的api特征起到了作用，加入好的统计特征对效果不错的tfidf有一定的促进作用，加入差的统计特征反而效果不好。到这里为止的模型都无法对api进行长序列建模，但是还是可以通过api的数量和占比等传统统计特征来提升检测效果，现在欠缺的就是长序列建模。  
没有测试1st的统计学特征和NLP下特征合并训练单模型，猜测模型效果较以上会得到明显提升。个人感觉使用tfidf复杂度较低，同时模型效果还不错，可以作为baseline，然后再尝试统计学统计特征训练模型对比效果。