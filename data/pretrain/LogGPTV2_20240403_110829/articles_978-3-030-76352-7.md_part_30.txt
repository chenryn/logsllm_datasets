per class then the memory leak is found [2]. Nick Mitchell and Gary Sevitsky
proposed “LeakBot”, which looks for heap size growth patterns in the heap
graphs of Java applications to find memory leaks [7]. “LEAKPOINT” proposed
byClauseetal.usesdynamictaintingtotrackheapmemorypointersandfurther
analyze it to detect memory leaks [3].
Most of the online detection algorithms that are proposed focus either on
the programming language of the running application or on garbage collection
strategies or the internals of the application based on the object’s allocation,
references, and deallocation. To the best of our knowledge, there is no previous
workthatsolelyfocusesonthedetectionofmemoryleaksusingjustthesystem’s
memory utilization data on which application is deployed. The work in this
paper, therefore, focuses on the detection of a memory leak pattern irrespective
oftheprogramminglanguageoftheapplicationortheknowledgeofapplication’s
source code or the low-level details such as allocation times of objects, object
staleness, or the object references.
Online Memory Leak Detection in the Cloud-Based Infrastructures 191
Table 1. Symbols and definitions.
Symbol Interpretation
t A timestamp
x t The percentage utilization of a resource (for example
memory or disk usage) of a virtual machine at time t
N Number of data points
x={x 1,x 2,...,x N} A VM’s memory utilization observations from the Cloud
T Time series window length
x t−T:t A sequence of observations {x t−T,x t−T+1,...,x t} from
time t−T to t
U Percentage memory utilization threshold equal to 100
C Critical time
3 Methodology for Memory Leak Detection
In this section, we present the problem statement of memory leak detection and
describes our proposed algorithm’s workflow for solving it.
3.1 Problem Statement
Table1 shows the symbols used in this paper.
Wearegivenx={x 1,x 2,...,x N},anN×1datasetrepresentingthememory
utilization observations of the VM and an observation x t ∈R is the percentage
memory utilization of a virtual machine at time t. The objective of this work
is to determine whether or not there is a memory leak on a VM such that an
observation x t at time t reaches the threshold U memory utilization following a
trend in the defined critical time C. Formally:
Problem 1 (Memory Leak Detection)
– Given:aunivariatedatasetofN timeticks,x={x 1,x 2,...,x N},representing
the memory utilization observations of the VM.
– Output:ananomalouswindowforaVMconsistingofasequenceofobserva-
tions x t−T:t such that these observations after following a certain trend will
reach the threshold U memory utilization at time t+M where M ≤C.
Definition 1 (Critical Time). It is the maximum time considered relevant for
reporting a memory leak in which if the trend line of memory utilization of VM
is projected, it will reach the threshold U.
3.2 Illustrative Example
Figure1 shows the example memory utilization of a memory leaking VM with
the marked anomalous window between t k and t n. It shows that the memory
192 A. Jindal et al.
utilization of the VM will reach the defined threshold (U = 100%) within the
defined critical time C by following a linearly increasing trend (shown by the
trend line) from the observations in the anomalous window. Therefore, this VM
is regarded as a memory leaking VM.
Fig.1.ExamplememoryutilizationofamemoryleakingVMwiththemarkedanoma-
lous window.
Our developed approach can be applied for multiple VMs as well. We also
have conducted an experiment to understand the memory usage patterns of
memory leak applications. We found that, if an application has a memory leak,
usuallythememoryusageoftheVMonwhichitisrunningincreasessteadily.It
continuestodosountilalltheavailablememoryofthesystemisexhausted.This
usually causes the application attempting to allocate the memory to terminate
itself. Thus, usually a memory leak behaviour exhibits a linearly increasing or
“sawtooth” memory utilization pattern.
3.3 Memory Leak Detection Algorithm: Precog
The Precog algorithm consists of two phases: offline training and online detec-
tion. Figure2 shows the overall workflow of the Precog algorithm.
Offline Training: The procedure starts by collecting the memory utilization
dataofaVMandpassingittoDataPre-processing module,wherethedatasetis
firsttransformedbyresamplingthenumberofobservationstooneeverydefined
resampling time resolution and then the time series data is median smoothed
over the specified smoothing window. In Trend Lines Fitting module, firstly, on
the whole dataset, the change points P ={P 1,P 2,...,P k}, where k ≤n−1, are
detected. By default, two change points one at the beginning and other at the
end of time series data are added. If the change points are not detected, then
the algorithm will have to go though each data point and it will be compute
intensive, therefore these points allows the algorithm to directly jump from one
change point to another and selecting all the points in between the two change
points. Trend Lines Fitting module selects a sequence of observations x t−L:t
Online Memory Leak Detection in the Cloud-Based Infrastructures 193
Fig.2. Overall workflow of Precog algorithm.
between the two change points: one fixed P 1 and other variable P r where r ≤k
andalineisfittedonthemusingthelinearregression.TheR-squaredscore,size
of the window called as duration, time to reach threshold called exit time and
slope of line are calculated. This procedure is repeated with keeping the fixed
change point the same and varying the other for all other change points. Out of
all the fitted lines, the best-fitted line based on the largest duration and highest
slopeisselectedforthefixedchangepoint.Ifthisbest-fittedlines’timetoreach
threshold falls below the critical time then its slope and duration are saved as
historic trends.
This above procedure is again repeated by changing the fixed change point
to all the other change points. At the end of this whole procedure, we get for
each change point, a best-fitted trend if it exists. Amongst the captured trends,
maximumdurationandthemaximumslopeofthetrendsarealsocalculatedand
saved. This training procedure can be conducted routinely, e.g., once per day or
week. The method’s pseudocode is shown in the Algorithm’s 1 Train function.
Online Detection:IntheOnlineDetectionphase,foranewsetofobservations
{x k,x k+1,x k+2,...,x k+t−1x k+t}fromtimektotwheret−k ≥P minbelonging
toaVMafterpre-processingisfedintotheTrendLinesFitting module.InTrend
LinesFitting module,thechangepointsaredetected.Asequenceofobservations
x t−L:t between the last two change points starting from the end of the time
series are selected and a line is fitted on them using the linear regression. The
R-squared score, slope, duration and exit time to reach threshold of the fitted
line is calculated. If its slope and duration are greater than the saved maximum
counter parts then that window is marked anomalous. Otherwise, the values
are compared against all the found training trends and if fitted-line’s slope and
duration are found to be greater than any of the saved trend then, again that
window will be marked as anomalous. This procedure is further repeated by
analyzing the observations between the last change point P k and the previous
next change point until all the change points are used. This is done for the
194 A. Jindal et al.
cases where the new data has a similar trend as the historic data but now with
a higher slope and longer duration. The algorithm’s pseudo code showing the
training and test method are shown in the Algorithm 1.
Definition 2 (Change Points). A set of time ticks which deviate highly from
the normal pattern of the data. This is calculated by first taking the first-order
difference of the input timeseries. Then, taking their absolute values and cal-
culating their Z-scores. The indexes of observations whose Z-scores are greater
than the defined threshold (3 times the standard deviation) represents the change
points. The method’s pseudocode is shown in the Algorithm’s 1 CPD function.
4 Evaluation
We design experiments to answer the questions:
– Q1. Memory Leak Detection Accuracy: how accurate is Precog in the
detection of memory leaks?
– Q2. Scalability:How does the algorithm scale with the increasein the data
points?
– Q3. Parameter Sensitivity: How sensitive is the algorithm when the
parameters values are changed?
We have used F1-Score (denoted as F1) to evaluate the performance of the
algorithms. Evaluation tests have been executed on a machine with 4 physical
cores(3.6GHzIntelCorei7-4790CPU)withhyperthreadingenabledand16GB
of RAM. These conditions are similar to a typical cloud VM. It is to be noted
thatthealgorithmdetectsthecaseswherethereisanongoingmemoryleakand
assumesthatpreviouslytherewasnomemoryleak.Forourexperiments,hyper-
parameters are set as follows. The maximum threshold U is set to 100 and the
defined critical time C is set to 7 days. The smoothing window size is 1h and
re-sampling time resolution was set to 5min. Lastly, the minimum R-squared
score R2min for a line to be recognized as a good fit is set to 0.75. 65% of data
wasusedfortrainingandtherestfortesting.However,wealsoshowexperiments
on parameter sensitivity in this section.
4.1 Q1. Memory Leak Detection Accuracy
To demonstrate the effectiveness of the developed algorithm, we initially syn-
thetically generated the timeseries. Table2 shows the F1 score corresponding to
each memory leak pattern and also the overall F1 score. Table2 shows that
Precog is able to reach an overall accuracy of 90%.
In addition, to demonstrate the effectiveness of the developed algorithm on
therealcloudworkloads,weevaluatedPrecogontherealClouddatasetprovided
byHuaweiMunichwhichconsistsofmanuallylabeledmemoryleakdatafrom60
VMs spanned over 5 days and each time series consists of an observation every
Online Memory Leak Detection in the Cloud-Based Infrastructures 195
Algorithm 1: Precog Algorithm
Input: input Train Ts,R2 score min, input Test Ts, critical time
Output: anomalous list a
1 Function CPD(x=input Ts,threshold=3):
2 absDiffTs=first order absolute difference of x
3 zScores=calculate z-scores of absDiffTs
4 cpdIndexes=indexes of (zScores>threshold)
5 return cpdIndexes // return the change-points indexes
6 Function TRAINING(x=input Train Ts, R2 score min,C =critical time):
// Train on input Train Ts
7 P = CPD(x) // get Change-points
8 p1 = 0
9 while p1 <= length(P) do
10 p2 = p1
11 D b,S b,T b =0 // best local trend’s duration, slope, exit time
12 while p2 <= length(P) do
13 exit time,r2,dur,slope←LinearRegression(ts) // fitted
line’s exit time, R2 score, duration, slope
14 if r2≥R2 score min and dur≥D b and slope≥S b then
15 Update(D b,S b,T b) // update best local values
16 p2=p2+1
17 if T b ≤C then
18 if D b ≥D max and S b ≥S max then
19 Update(D max,S max) // update global trend values
20 saveTrend(D b,S b), save(D max,S max) // save values
21 p1=p1+1
22 Function TEST(x=input Test Ts,C =critical time):
// Test on the new data to find anomalous memory leak window
23 a=[0] // anomalous empty array of size input Test Ts
24 P = CPD(x) // get Change-points
25 len=length(P) // length of change point indexes
26 while i≤len do
27 ts=x[P[len−i]:P[len]] // i is a loop variable
28 exit time,r2,dur,slope=LinearRegression(ts)
29 D max,S max,Trends=get saved values
30 if exit time,≤C and r2≥R min then
31 if slope≥S max and dur≥D max then
32 a[P[len−i]:P[len]]=1 // current trend greater than
global saved so mark anomalous
33 else
34 For Each t in Trends if slope≥S t and dur≥D t then
35 a[P[len−i]:P[len]]=1 // current trend greater than
one of the saved trend so mark anomalous
36 i=i+1
37 return a // list with 0s and anomalous indexes represented by 1
196 A. Jindal et al.
Table2.Syntheticallygeneratedtimeseriescorrespondingtoeachmemoryleakpattern
and their accuracy score.
Memory leak pattern +ve cases −ve cases F1 score Recall Precision
Linearly increasing 30 30 0.933 0.933 0.933
Linearly increasing (with noise) 30 30 0.895 1.0 0.810
Sawtooth 30 30 0.830 0.73 0.956
Overall 90 90 0.9 0.9 0.91
minute. Outofthese60VMs,20VMshadamemoryleak. Suchhighnumberof
VMshavingmemoryleaksisduetothefactthatapplicationswithmemoryleak
weredeliberatelyrunontheinfrastructure.ThealgorithmachievedtheF1-Score
of 0.857, recall equals to 0.75 and precision as 1.0. Average prediction time
per test data containing approximately 500 points is 0.32s.
Furthermore,wepresentthedetailedresultsofthealgorithmontheselected4
casesshownintheFig.3:simplelinearlyincreasingmemoryutilization,sawtooth
linearly increasing pattern, linearly increasing pattern with no trends detected
intrainingdata,andlinearlyincreasingwithsimilartrendastrainingdata.The
figurealsoshowsthechangepoints,trainingtrendsandthedetectedanomalous
memory leak window for each of the cases.
ForthefirstcaseshowninFig.3a,memoryutilizationisbeingusednormally
until it suddenly starts to increase linearly. The algorithm detected one training
trend and reported the complete test set as anomalous. The test set trend is
having similar slope as training trend but with a longer duration and higher
memory usage hence it is reported as anomalous.
In the second case (Fig.3b), the trend represents commonly memory leak
sawtooth pattern where the memory utilization increases upto a certain point
and then decreases (but not completely zero) and then again it start to increase
inthesimilarmanner.Thealgorithmdetectedthreetrainingtrendsandreported
mostofthetestsetasanomalous.Thetestsetfollowsasimilartrendascaptured
duringthetrainingbutwiththehighermemoryutilization,henceitisreported.
In the third case (Fig.3c), no appropriate training trend was detected in the
completetrainingdatabut,thealgorithmisabletodetectanincreasingmemory
utilization trend in the test dataset.
In Fig.3d, the VM does not have a memory leak but its memory utilization
was steadily increasing which if observed without the historic data seems to be
a memory leak pattern. However, in the historic data, the same trend is already
observed and therefore it is a normal memory utilization pattern. Precog using
thehistoricdatafordetectingthetrainingtrendsandthencomparingthemwith
the test data correctly reports that trend as normal and hence does not flag the
window as anomalous. It is also to be noted that, if the new data’s maximum
goes beyond the maximum in the training data with the similar trend then it
will be regarded as a memory leak.
Online Memory Leak Detection in the Cloud-Based Infrastructures 197
(a) Linearly increasing (b) Sawtooth linearly increasing
(d)Linearlyincreasingwithsimilartrend
(c) Linearly increasing without trends
as training data and correctly not
detected in training data
detected
Fig.3. Algorithm result on 3 difficult cases having memory leak (a–c) and one case
not having a memory leak (d).
4.2 Q2. Scalability
Next, we verify that our prediction method scale linearly. We repeatedly dupli-
cateourdatasetintimeticks,addGaussiannoise.Figure4bshowsthatPrecog’
predict method scale linearly in time ticks. Precog does provide the prediction
results under 1s for the data with 100,000 time ticks. However, the training
method shown in Fig.4a is quadratic in nature but training needs to conducted