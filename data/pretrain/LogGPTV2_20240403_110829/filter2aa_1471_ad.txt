address of the KPCR, and at segment 38h (KGDT_R3_TEB), the
base address of the current thread’s TEB. There are no MSRs used
for segmentation on these systems.
Lazy segment loading
Based on the description and values of the segments described earlier, it may
be surprising to investigate the values of DS and ES on an x86 and/or x64
system and find that they do not necessarily match the defined values for
their respective ring levels. For example, an x86 user-mode thread would
have the following segments:
CS = 1Bh (18h | 3)
ES, DS = 23 (20h | 3)
FS = 3Bh (38h | 3)
Yet, during a system call in Ring 0, the following segments would be
found:
CS = 08h (08h | 0)
ES, DS = 23 (20h | 3)
FS = 30h (30h | 0)
Similarly, an x64 thread executing in kernel mode would also have its ES
and DS segments set to 2Bh (28h | 3). This discrepancy is due to a feature
known as lazy segment loading and reflects the meaninglessness of the
Descriptor Privilege Level (DPL) of a data segment when the current Code
Privilege Level (CPL) is 0 combined with a system operating under a flat
memory model. Since a higher CPL can always access data of a lower DPL
—but not the contrary—setting DS and/or ES to their “proper” values upon
entering the kernel would also require restoring them when returning to user
mode.
Although the MOV DS, 10h instruction seems trivial, the processor’s
microcode needs to perform a number of selector correctness checks when
encountering it, which would add significant processing costs to system call
and interrupt handling. As such, Windows always uses the Ring 3 data
segment values, avoiding these associated costs.
Task state segments
Other than the code and data segment registers, there is an additional special
register on both x86 and x64 architectures: the Task Register (TR), which is
also another 16-bit selector that acts as an offset in the GDT. In this case,
however, the segment entry is not associated with code or data, but rather
with a task. This represents, to the processor’s internal state, the current
executing piece of code, which is called the Task State—in the case of
Windows, the current thread. These task states, represented by segments
(Task State Segment, or TSS), are used in modern x86 operating systems to
construct a variety of tasks that can be associated with critical processor traps
(which we’ll see in the upcoming section). At minimum, a TSS represents a
page directory (through the CR3 register), such as a PML4 on x64 systems
(see Part 1, Chapter 5, “Memory management,” for more information on
paging), a Code Segment, a Stack Segment, an Instruction Pointer, and up to
four Stack Pointers (one for each ring level). Such TSSs are used in the
following scenarios:
■    To represent the current execution state when there is no specific trap
occurring. This is then used by the processor to correctly handle
interrupts and exceptions by loading the Ring 0 stack from the TSS if
the processor was currently running in Ring 3.
■    To work around an architectural race condition when dealing with
Debug Faults (#DB), which requires a dedicated TSS with a custom
debug fault handler and kernel stack.
■    To represent the execution state that should be loaded when a Double
Fault (#DF) trap occurs. This is used to switch to the Double Fault
handler on a safe (backup) kernel stack instead of the current thread’s
kernel stack, which may be the reason why a fault has happened.
■    To represent the execution state that should be loaded when a Non
Maskable Interrupt (#NMI) occurs. Similarly, this is used to load the
NMI handler on a safe kernel stack.
■    Finally, to a similar task that is also used during Machine Check
Exceptions (#MCE), which, for the same reasons, can run on a
dedicated, safe, kernel stack.
On x86 systems, you’ll find the main (current) TSS at selector 028h in the
GDT, which explains why the TR register will be 028h during normal
Windows execution. Additionally, the #DF TSS is at 58h, the NMI TSS is at
50h, and the #MCE TSS is at 0A0h. Finally, the #DB TSS is at 0A8h.
On x64 systems, the ability to have multiple TSSs was removed because the
functionality had been relegated to mostly this one need of executing trap
handlers that run on a dedicated kernel stack. As such, only a single TSS is
now used (in the case of Windows, at 040h), which now has an array of eight
possible stack pointers, called the Interrupt Stack Table (IST). Each of the
preceding traps is now associated with an IST Index instead of a custom TSS.
In the next section, as we dump a few IDT entries, you will see the difference
between x86 and x64 systems and their handling of these traps.
EXPERIMENT: Viewing the TSSs on an x86 system
On an x86 system, we can look at the system-wide TSS at 28h by
using the same dg command utilized earlier:
Click here to view code image
kd> dg 28 28
                                  P Si Gr Pr Lo
Sel    Base     Limit     Type    l ze an es ng Flags
---- -------- -------- ---------- - -- -- -- -- --------
0028 8116e400 000020ab TSS32 Busy 0 Nb By P  Nl 0000008b
This returns the virtual address of the KTSS data structure,
which can then be dumped with the dx or dt commands:
Click here to view code image
kd> dx (nt!_KTSS*)0x8116e400
(nt!_KTSS*)0x8116e400                 : 0x8116e400 [Type: 
_KTSS *]
    [+0x000] Backlink         : 0x0 [Type: unsigned short]
    [+0x002] Reserved0        : 0x0 [Type: unsigned short]
    [+0x004] Esp0             : 0x81174000 [Type: unsigned 
long]
    [+0x008] Ss0              : 0x10 [Type: unsigned short]
Note that the only fields that are set in the structure are the Esp0
and Ss0 fields because Windows never uses hardware-based task
switching outside of the trap conditions described earlier. As such,
the only use for this particular TSS is to load the appropriate kernel
stack during a hardware interrupt.
As you’ll see in the “Trap dispatching” section, on systems that
do not suffer from the “Meltdown” architectural processor
vulnerability, this stack pointer will be the kernel stack pointer of
the current thread (based on the KTHREAD structure seen in Part
1, Chapter 5), whereas on systems that are vulnerable, this will
point to the transition stack inside of the Processor Descriptor
Area. Meanwhile, the Stack Segment is always set to 10h, or
KGDT_R0_DATA.
Another TSS is used for Machine Check Exceptions (#MC) as
described above. We can use dg to look at it:
Click here to view code image
kd> dg a0 a0
                                  P Si Gr Pr Lo
Sel    Base     Limit     Type    l ze an es ng Flags
---- -------- -------- ---------- - -- -- -- -- --------
00A0 81170590 00000067 TSS32 Avl  0 Nb By P  Nl 00000089
This time, however, we’ll use the .tss command instead of dx,
which will format the various fields in the KTSS structure and
display the task as if it were the currently executing thread. In this
case, the input parameter is the task selector (A0h).
Click here to view code image
kd> .tss a0
eax=00000000 ebx=00000000 ecx=00000000 edx=00000000 
esi=00000000 edi=00000000
eip=81e1a718 esp=820f5470 ebp=00000000 iopl=0         nv up 
di pl nz na po nc
cs=0008  ss=0010  ds=0023  es=0023  fs=0030  gs=0000             
efl=00000000
hal!HalpMcaExceptionHandlerWrapper:
81e1a718 fa              cli
Note how the segment registers are set up as described in the
“Lazy segment loading” section earlier, and how the program
counter (EIP) is pointing to the handler for #MC. Additionally, the
stack is configured to point to a safe stack in the kernel binary that
should be free from memory corruption. Finally, although not
visible in the .tss output, CR3 is configured to the System Page
Directory. In the “Trap dispatching” section, we revisit this TSS
when using the !idt command.
EXPERIMENT: Viewing the TSS and the IST on an
x64 system
On an x64 system, the dg command unfortunately has a bug that
does not correctly show 64-bit segment base addresses, so
obtaining the TSS segment (40h) base address requires dumping
what appear to be two segments, and combining the high, middle,
and low base address bytes:
Click here to view code image
0: kd> dg 40 48
                                                    P Si Gr 
Pr Lo
Sel        Base              Limit          Type    l ze an 
es ng Flags
---- ----------------- ----------------- ---------- - -- -- 
-- -- --------
0040 00000000`7074d000 00000000`00000067 TSS32 Busy 0 Nb By 
P  Nl 0000008b
0048 00000000`0000ffff 00000000`0000f802  0 Nb By 
Np Nl 00000000
In this example, the KTSS64 is therefore at
0xFFFFF8027074D000. To showcase yet another way of
obtaining it, note that the KPCR of each processor has a field
called TssBase, which contains a pointer to the KTSS64 as well:
Click here to view code image
0: kd> dx @$pcr->TssBase
@$pcr->TssBase                : 0xfffff8027074d000 [Type: 
_KTSS64 *]
    [+0x000] Reserved0        : 0x0 [Type: unsigned long]
    [+0x004] Rsp0             : 0xfffff80270757c90 [Type: 
unsigned __int64]
Note how the virtual address is the same as the one visible in the
GDT. Next, you’ll also notice how all the fields are zero except for
RSP0, which, similarly to x86, contains the address of the kernel
stack for the current thread (on systems without the “Meltdown”
hardware vulnerability) or the address of the transition stack in the
Processor Descriptor Area.
On the system on which this experiment was done, a 10th
Generation Intel processor was used; therefore, RSP0 is the current
kernel stack:
Click here to view code image
0: kd> dx @$thread->Tcb.InitialStack
@$thread->Tcb.InitialStack : 0xfffff80270757c90 [Type: void 
*]
Finally, by looking at the Interrupt Stack Table, we can see the
various stacks that are associated with the #DF, #MC, #DB, and
NMI traps, and in the Trap Dispatching section, we’ll see how the
Interrupt Dispatch Table (IDT) references these stacks:
Click here to view code image
0: kd> dx @$pcr->TssBase->Ist
@$pcr->TssBase->Ist     [Type: unsigned __int64 [8]]
    [0]              : 0x0 [Type: unsigned __int64]
    [1]              : 0xfffff80270768000 [Type: unsigned 
__int64]
    [2]              : 0xfffff8027076c000 [Type: unsigned 
__int64]
    [3]              : 0xfffff8027076a000 [Type: unsigned 
__int64]
    [4]              : 0xfffff8027076e000 [Type: unsigned 
__int64]
Now that the relationship between ring level, code execution, and some of
the key segments in the GDT has been clarified, we’ll take a look at the
actual transitions that can occur between different code segments (and their
ring level) in the upcoming section on trap dispatching. Before discussing
trap dispatching, however, let’s analyze how the TSS configuration changes
in systems that are vulnerable to the Meltdown hardware side-channels
attack.
Hardware side-channel vulnerabilities
Modern CPUs can compute and move data between their internal registers
very quickly (in the order of pico-seconds). A processor’s registers are a
scarce resource. So, the OS and applications’ code always instruct the CPU to
move data from the CPU registers into the main memory and vice versa.
There are different kinds of memory that are accessible from the main CPU.
Memory located inside the CPU package and accessible directly from the
CPU execution engine is called cache and has the characteristic of being fast
and expensive. Memory that is accessible from the CPU through an external
bus is usually the RAM (Random Access Memory) and has the characteristic
of being slower, cheaper, and big in size. The locality of the memory in
respect to the CPU defines a so-called memory hierarchy based on memories
of different speeds and sizes (the more memory is closer to the CPU, the
more memory is faster and smaller in size). As shown in Figure 8-2, CPUs of
modern computers usually include three different levels of fast cache
memory, which is directly accessible by the execution engine of each
physical core: L1, L2, and L3 cache. L1 and L2 caches are the closest to a
CPU’s core and are private per each core. L3 cache is the farthest one and is
always shared between all CPU’s cores (note that on embedded processors,
the L3 cache usually does not exist).
Figure 8-2 Caches and storage memory of modern CPUs and their average
size and access time.
One of main characteristics of cache is its access time, which is
comparable to CPU’s registers (even though it is still slower). Access time to
the main memory is instead a hundred times slower. This means that in case
the CPU executes all the instructions in order, many times there would be
huge slowdowns due to instructions accessing data located in the main
memory. To overcome this problem, modern CPUs implement various
strategies. Historically, those strategies have led to the discovery of side-
channel attacks (also known as speculative attacks), which have been proven
to be very effective against the overall security of the end-user systems.
To correctly describe side-channel hardware attacks and how Windows
mitigates them, we should discuss some basic concepts regarding how the
CPU works internally.
Out-of-order execution
A modern microprocessor executes machine instructions thanks to its
pipeline. The pipeline contains many stages, including instruction fetch,
decoding, register allocation and renaming, instructions reordering,
execution, and retirement. A common strategy used by the CPUs to bypass
the memory slowdown problem is the capability of their execution engine to
execute instructions out of order as soon as the required resources are
available. This means that the CPU does not execute the instructions in a
strictly sequential order, maximizing the utilization of all the execution units
of the CPU core as exhaustive as possible. A modern processor can execute
hundreds of instructions speculatively before it is certain that those
instructions will be needed and committed (retired).
One problem of the described out-of-order execution regards branch
instructions. A conditional branch instruction defines two possible paths in
the machine code. The correct path to be taken depends on the previously
executed instructions. When calculating the condition depends on previous
instructions that access slow RAM memory, there can be slowdowns. In that
case, the execution engine waits for the retirement of the instructions
defining the conditions (which means waiting for the memory bus to
complete the memory access) before being able to continue in the out-of-
order execution of the following instructions belonging to the correct path. A
similar problem happens in the case of indirect branches. In this case, the
execution engine of the CPU does not know the target of a branch (usually a
jump or a call) because the address must be fetched from the main memory.
In this context, the term speculative execution means that the CPU’s pipeline
decodes and executes multiple instructions in parallel or in an out-of-order
way, but the results are not retired into permanent registers, and memory
writes remain pending until the branch instruction is finally resolved.
The CPU branch predictor
How does the CPU know which branch (path) should be executed before the
branch condition has been completely evaluated? (The issue is similar with
indirect branches, where the target address is not known). The answer lies in
two components located in the CPU package: the branch predictor and the
branch target predictor.
The branch predictor is a complex digital circuit of a CPU that tries to
guess which path a branch will go before it is known definitively. In a similar
way, the branch target predictor is the part of the CPU that tries to predict the
target of indirect branches before it is known. While the actual hardware
implementation heavily depends on the CPU manufacturer, the two
components both use an internal cache called Branch Target Buffer (BTB),
which records the target address of branches (or information about what the
conditional branch has previously done in the past) using an address tag
generated through an indexing function, similar to how the cache generates
the tag, as explained in the next section. The target address is stored in the
BTB the first time a branch instruction is executed. Usually, at the first time,
the execution pipeline is stalled, forcing the CPU to wait for the condition or
target address to be fetched from the main memory. The second time the
same branch is executed, the target address in the BTB is used for fetching
the predicted target into the pipeline. Figure 8-3 shows a simple scheme of an
example branch target predictor.
Figure 8-3 The scheme of a sample CPU branch predictor.
In case the prediction was wrong, and the wrong path was executed
speculatively, then the instruction pipeline is flushed, and the results of the
speculative execution are discarded. The other path is fed into the CPU
pipeline and the execution restarts from the correct branch. This case is
called branch misprediction. The total number of wasted CPU cycles is not
worse than an in-order execution waiting for the result of a branch condition
or indirect address evaluation. However, different side effects of the
speculative execution can still happen in the CPU, like the pollution of the
CPU cache lines. Unfortunately, some of these side effects can be measured
and exploited by attackers, compromising the overall security of the system.
The CPU cache(s)
As introduced in the previous section, the CPU cache is a fast memory that
reduces the time needed for data or instructions fetch and store. Data is
transferred between memory and cache in blocks of fixed sizes (usually 64 or
128 bytes) called lines or cache blocks. When a cache line is copied from
memory into the cache, a cache entry is created. The cache entry will include
the copied data as well as a tag identifying the requested memory location.
Unlike the branch target predictor, the cache is always indexed through
physical addresses (otherwise, it would be complex to deal with multiple
mappings and changes of address spaces). From the cache perspective, a
physical address is split in different parts. Whereas the higher bits usually
represent the tag, the lower bits represent the cache line and the offset into the
line. A tag is used to uniquely identify which memory address the cache
block belongs to, as shown in Figure 8-4.
Figure 8-4 A sample 48-bit one-way CPU cache.
When the CPU reads or writes a location in memory, it first checks for a
corresponding entry in the cache (in any cache lines that might contain data
from that address. Some caches have different ways indeed, as explained
later in this section). If the processor finds that the memory content from that
location is in the cache, a cache hit has occurred, and the processor
immediately reads or writes the data from/in the cache line. Otherwise, a
cache miss has occurred. In this case, the CPU allocates a new entry in the
cache and copies data from main memory before accessing it.
In Figure 8-4, a one-way CPU cache is shown, and it’s capable of
addressing a maximum 48-bits of virtual address space. In the sample, the
CPU is reading 48 bytes of data located at virtual address 0x19F566030. The
memory content is initially read from the main memory into the cache block
0x60. The block is entirely filled, but the requested data is located at offset
0x30. The sample cache has just 256 blocks of 256 bytes, so multiple
physical addresses can fill block number 0x60. The tag (0x19F56) uniquely
identifies the physical address where data is stored in the main memory.
In a similar way, when the CPU is instructed to write some new content to
a memory address, it first updates the cache line(s) that the memory address
belongs to. At some point, the CPU writes the data back to the physical RAM
as well, depending on the caching type (write-back, write-through, uncached,
and so on) applied to the memory page. (Note that this has an important
implication in multiprocessor systems: A cache coherency protocol must be
designed to prevent situations in which another CPU will operate on stale
data after the main CPU has updated a cache block. (Multiple CPU cache
coherency algorithms exist and are not covered in this book.)
To make room for new entries on cache misses, the CPU sometime should
evict one of the existing cache blocks. The algorithm the cache uses to
choose which entry to evict (which means which block will host the new
data) is called the placement policy. If the placement policy can replace only
one block for a particular virtual address, the cache is called direct mapped
(the cache in Figure 8-4 has only one way and is direct mapped). Otherwise,
if the cache is free to choose any entry (with the same block number) to hold
the new data, the cache is called fully associative. Many caches implement a
compromise in which each entry in main memory can go to any one of N
places in the cache and are described as N-ways set associative. A way is
thus a subdivision of a cache, with each way being of equal size and indexed
in the same fashion. Figure 8-5 shows a four-way set associative cache. The
cache in the figure can store data belonging to four different physical
addresses indexing the same cache block (with different tags) in four
different cache sets.
Figure 8-5 A four-way set associative cache.
Side-channel attacks
As discussed in the previous sections, the execution engine of modern CPUs
does not write the result of the computation until the instructions are actually
retired. This means that, although multiple instructions are executed out of
order and do not have any visible architectural effects on CPU registers and
memory, they have microarchitectural side effects, especially on the CPU