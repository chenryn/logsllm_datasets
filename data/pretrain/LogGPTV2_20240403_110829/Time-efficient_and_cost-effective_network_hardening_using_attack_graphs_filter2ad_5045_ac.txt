ct is reachable from any dummy exploit ei, all such exploits
need to be prevented, and the only way to achieve this is by
disabling the corresponding preconditions, that is hardening
the network with respect to all target conditions in Ct.
Additionally, we assume that, given a target condition ct,
the attack graph is a tree rooted at ct and having initial
conditions as leaf nodes. In Section IV, we showed an
example of how this can be achieved using the mechanism
to break cycle adopted by the algorithm in [2]. If the attack
graph is not a tree, it can be converted to this form by
using such mechanism. Looking at the attack graph from the
point of view of a given target condition has the additional
advantage of ignoring exploits and conditions that do not
contribute to reaching that target condition.
On Line 1, the algorithm performs a topological sort of the
nodes in the attack graph (exploits and security conditions),
and pushes them into a queue, with initial conditions at the
front of the queue. While the queue is not empty, an element
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:08 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 2 F orwardSearch(G, k)
Input: Attack graph G = (E ∪ C, Rr ∪ Ri), and optimization parameter k.
S, and mapping minCost : C ∪ E → R+.
Output: Mapping σ : C ∪ E → 2
1: Q ← T opologicalSort(C ∪ E)
2: while Q (cid:15)= ∅ do
q ← Q.pop()
if q ∈ Ci then
else if q ∈ E then
else if q ∈ C \ Ci then
c∈C | (c,q)∈Ri σ(q)
σ(q) ← {{A} | q ∈ A}
σ(q) ← (cid:2)
{e1, . . . , em} ← {e ∈ E | (e, q) ∈ Ri}
σ(q) ← {S1 ∪ . . . ∪ Sm | Si ∈ σ(ei)}
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13: minCost(q) = minS∈σ(q) cost(S)
14: end while
end if
σ(q) ← topK(σ(q), k)
c1 
e1 
cn 
en 
ct 
Figure 5. Example of multiple target conditions and dummy target
q is popped from the queue. If q is an initial condition, then
q is associated with a set of strategies σ(q) such that each
strategy simply contains one of the allowable actions in A
disabling q (Line 5). If q is an exploit, then q is associated
with a set of strategies σ(q) that is the union of the sets of
strategies for each condition c required by q (Line 7). In fact,
an exploit can be prevented by disabling any of its required
conditions. Finally, if q is an intermediate condition, then
q is associated with a set of strategies σ(q) such that each
strategy is the union of a strategy for each of the exploits
that imply q (Lines 9-10). In fact, in order to disable an
intermediate condition, all the exploits that imply it must be
prevented. When suboptimal solutions are acceptable, then
only the best k intermediate solutions are maintained at each
step of the algorithm (Line 12), and the minimal hardening
cost for the current node is computed accordingly (Line 13).
Example 1: Consider the attack graph of Figure 3. The
only three allowable actions on the corresponding network
are stop f tp(2) = {f tp(1, 2), f tp(0, 2)}, block host(0) =
{f tp(0, 1), sshd(0, 1), f tp(0, 2)}, and stop sshd(1) =
{sshd(0, 1)}. Assume that cost({stop f tp(2)}) = 20,
cost({block host(0)}) = 10, and cost({stop sshd(1)}) =
15. It is clear that the optimal strategy to harden the network
to root(2) is S = {block host(0)}, with
with respect
a cost of 10. Let us now examine the behavior of the
algorithm for k = 1. All nodes are added to the queue
in topological order, and initial conditions are examined
ﬁrst. After all the initial conditions have been examined,
we obtain σ(f tp(1, 2)) = {{stop f tp(2)}}, σ(f tp(0, 1)) =
{{block host(0)}}, σ(sshd(0, 1)) = {{block host(0)}},
and σ(f tp(0, 2)) = {{block host(0)}}. Once the algorithm
examines exploit rsh(1, 2), on Line 7, before pruning, we
obtain σ(rsh(1, 2)) = {{stop f tp(2)},{block host(0)}}.
After pruning (Line 12), we obtain σ(rsh(1, 2)) =
{{block host(0)}}, as {block host(0)} is the strategy
with the lowest cost. Finally, we obtain σ(root(2)) =
{{block host(0)}}, that is the algorithm, in this case, re-
turns the optimal solutions.
From the example above, it is clear that in our approach
administrators only have to assign the cost of performing
allowable actions (which are meaningful aggregates of initial
conditions), whereas in previous approaches they had to
assign cost values to each individual initial condition.
Now, let us consider a different example showing how
the value of k may have an impact on the optimality of the
solution. Intuitively, the higher the value of k, the closer the
computed solution is to the optimal one.
Example 2: Consider the attack graph of Figure 6, and
assume that cost({A1}) = 10, cost({A2}) = 18, and
cost({A3}) = 10. Also assume that cost is additive. It is
clear that the optimal strategy to harden the network with
respect to c5 is S = {A2}, with a cost of 18. Let us now
examine the behavior of the algorithm for k = 1. On Line 1
we obtain Q = (cid:17)c1, c2, c3, c4, e1, e2, c5(cid:18). Thus, c1 is the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:08 UTC from IEEE Xplore.  Restrictions apply. 
ﬁrst node to be examined. After the ﬁrst 4 elements of the
queue have been examined, we obtain σ(c1) = {{A1}},
σ(c2) = {{A2}}, σ(c3) = {{A2}}, and σ(c4) = {{A3}}.
Then e1 is considered. The full set of possible strategies for
e1 is σ(e1) = {{A1},{A2}}, but, since k = 1, only the
best one is maintained and propagated to following steps.
A similar consideration applies to e2. In conclusion we
obtain σ(e1) = {{A1}} σ(e2) = {{A3}}. Finally, we obtain
σ(c5) = {{A1, A3}}, and minCost(c5) = 20, which is
slightly above the optimal cost. Similarly, it can be shown
that, for k = 2, the algorithm returns minCost(c5) = 18,
i.e., the optimal solution. This conﬁrms that larger values of
k make solutions closer to the optimal one.
A1
c1
A2
c2
c3
A3
c4
e1
e2
c5
Figure 6. Example of attack graph with d = 2 and n = 2
We now show that, in the worst case – when k = 1 –
the approximation ratio is upper-bounded by nd/2. However,
experimental results indicate that, in practice, the approx-
imation ratio is much smaller than its theoretical bound.
First, let us consider the type of scenario in which solutions
may not be optimal. To this aim, consider again the attack
graph conﬁguration of Figure 6. When computing solutions
for e1 and e2 respectively, we make local decisions without
considering the whole graph, i.e., we independently compute
the optimal solution for e1 and the optimal solution for e2,
given hardening strategies for their preconditions. However,
at a later stage, we need to merge solutions for both e1 and
e2 in order to obtain solutions for c5. At this point, since
there exists an allowable action (i.e., A2) that would have
disabled preconditions of both e1 and e2, with a cost lower
than the combined cost of their locally optimal solutions,
but the strategy including A2 has been discarded for k = 1,
the solution is not optimal. This suggests that both k and the
maximum in-degree n of nodes in the graph play a role in
determining the optimality of the solution. Additionally, as
the algorithm traverses the graph towards target conditions,
there may be a multiplicative effect in the approximation
error. In fact, the depth d of the tree also plays a role
in determining the outcome of the approximation, but this
effect can be compensated by increasing the value of k. We
can prove the following theorem.
Theorem 1: Given an attack graph G with depth d and
maximum in-degree n, the upper bound of the approxima-
d−l
2
tion ratio of algorithm F orwardSearch for k = 1 is n
d
2 .
Proof: We prove the result by induction, assuming
that the cost function is additive. We use the term level
l to denote nodes that are at a distance l from the target
condition. We need to prove that for each l ∈ [1, d − 2],
the cost of hardening conditions at level l is n
times
the optimal cost. The worst case – depicted in Figure 7 –
∗ (with
is the one in which (i) a single allowable action A
∗}) = x) disables one precondition for each of the
cost({A
2 exploits ed−1,i at level d − 1 (i.e., exploits depending on
m
initial conditions), where m = nd is the number of initial
conditions; (ii) for each exploit ed−1,i, all the preconditions
∗ are disabled by an action Ai such that
not disabled by A
cost({Ai}) = x− ε, where ε is an arbitrarily small positive
real number; and (iii) actions Ai are pairwise disjoint.
Base case. When choosing a strategy for ed−1,i, the algo-
rithm picks the one with the lowest cost, that is strategy {Ai}
with cost x − ε. Then, when choosing a strategy for cd−2,i,
the algorithm combines strategies for its n predecessors,
which all cost x − ε. Since such strategies are disjoint and
cost is additive, the cost to harden any condition at level
d − 2 of the attack tree is n · (x − ε).
Inductive step. If hardening strategies for conditions at
level d−j of the attack tree cost nj/2·(x−ε), then hardening
strategies for exploits at level d−j−1 of the attack tree also
cost nj/2 · (x− ε). When choosing a strategy for conditions
at level d − j − 2, the algorithm combines strategies for its
n predecessors, which all cost nj/2 · (x − ε). Since such
strategies are disjoint and cost is additive, the cost to harden
any condition at level d− j − 2 of the attack tree is n· nj/2 ·
(x − ε) = n
· (x − ε).
j+2
2
Although this result indicates that the bound may increase
exponentially with the depth of the attack tree, the bound
is in practice – as conﬁrmed by experimental results –
much lower than the theoretical bound. In fact, the worst
case scenario depicted in Figure 7 is quite unrealistic.
Additionally, the bound can be reduced by increasing the
value of k. For instance, by setting k = n, the bound
d−2
becomes n
2 , that is the bound for a graph with depth
d − 2 and in-degree n.
Example 3: Consider the attack graph conﬁguration of
Figure 6 (with n = 2 and d = 2), and assume that
cost({A2}) = x, cost({A1}) = x − ε, and cost({A3}) =
x − ε. For k = 1, if the cost function is additive, we obtain
minCost(c5) = 2 · (x − ε) ≈ 2 · x, which means that in the
worst case the cost is twice the optimal cost.
VII. EXPERIMENTAL RESULTS
In this section, we report the experiments we conducted to
validate our approach. Speciﬁcally, our objective is to evalu-
ate the performance of algorithm F orwardSearch in terms
of processing time and approximation ratio for different
values of the depth d of the attack graph and the maximum
in-degree n of nodes in the graph. In order to obtain graphs
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:49:08 UTC from IEEE Xplore.  Restrictions apply. 
A1
A*
A2
Am/2
cd,1
cd,2
cd,3
cd,4
cd,m-1
cd,m
ed-1,1
ed-1,2
ed-1,m/2
cd-2,1
e1,1
e1,2
ct
Figure 7. Worst case scenario
with speciﬁc values of d and n, we started from realistic
graphs, like the one of Figure 3, and augmented them with
additional synthetic conditions and exploits. Although the
large attack graphs we generated through this process are
mostly synthetic, we made considerable efforts to make such
graphs consistent with real attack graphs. Additionally, for
each such graph, we randomly generated different groupings
of initial conditions into allowable actions,
in order to
account for variability in what administrators can control.
All the results reported in this section are averaged over
multiple graphs with the same values of d and n, but
different conﬁgurations of allowable actions.
2.0
1.5
1.0
0.5
)
s
(
e
m
i
t
g
n
i
s
s
e
c
o
r
P
0.0
2
Exact solution
k = 1
k = 2
k = 5
k = 10
d = 4 
3
4
5
n 
Figure 8. Processing time vs. n for d = 4 and different values of k
First, we show that, as expected, computing the optimal
solution is feasible only for very small graphs. Figure 8
shows how processing time increases when n increases and
for d = 4, and compares processing times of the exact algo-
rithm with processing times of algorithm F orwardSearch
for different values of k. It is clear that the time to compute
the exact solution starts to diverge at n = 4, whereas
processing time of algorithm F orwardSearch is still well
under 0.5 seconds for k = 10 and n = 5. Similarly,
Figure 9 shows how processing time increases when d
increases and for n = 2, and compares processing times
of the exact algorithm with processing times of algorithm
F orwardSearch for different values of k. The time to
compute the exact solution starts to diverge at d = 5,
whereas processing time of algorithm F orwardSearch is
still under 20 milliseconds for k = 10 and d = 10.
Exact solution
k = 1
k = 2
k = 5
k = 10
n = 2 
)
s
m
(
e
m
i
t
g
n
i
s
s
e
c
o
r
P
30
25
20
15
10
5
0
0
1
2
3
4
5
6
7
8
9
10
11
d 