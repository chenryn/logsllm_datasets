tain neighborhood. The latter is useful when, for instance, Z is a
university and the adversary may infer the lack of education.
AdaTrace follows an iterative perturbation strategy to implement
Defense 1. Let DZ denote the subset of trajectories that visit zone Z.
We perturb the features concerning DZ in the private synopsis, e.g.,
Π(DZ), R(DZ), L(DZ). In the most relaxed setting of ϑ = +∞ no
perturbation is necessary; whereas in the strictest setting ϑ = 0, the
features must be maximally perturbed so that they exactly equal
population averages. For any ϑ in between, we perturb the features
iteratively, converging to population averages in each iteration,
until Defense 1 is satisfied. After the defense is satisfied, we plug
the perturbed features back to the private synopsis.
Partial Sniffing. Armed with user u’s subtrajectory from the sniff
region, the adversary aims to link u with a synthetic trajectory
Ts ∈ Dsyn. Since the user’s actual trajectory Tu is not in Dsyn the
linkage is not genuine, however the threat stems from two cases:
(i) Ts sufficiently resembles Tu, thus the adversary can still make
correct inferences using Ts. (ii) Ts contains visits to a sensitive zone
Z – although u may or may not have visited Z in reality, such an
inference can have discriminating or harmful impact on u, and
therefore should be prohibited.
Defense 2 (φ, ϱ). Let SR denote the sniff region, Tsnif f ed denote
the sniffed subtrajectory, Z denote a sensitive zone, and visit(T , Z)
denote the number of times trajectory T visits zone Z.
(1) Find the matching synthetic trajectory:
Ts = argmin
T ∈Dsyn
DTW((T ∩ SR),Tsnif f ed)
(2) If |intersection(Ts ,Tu)| > φ, mark as susceptible.
(3) If visit(Ts , Z) > ϱ, mark as susceptible.
(4) If no susceptibility is found in the above steps, mark as attack-
resilient.
AdaTrace enforces the above defense to thwart the partial sniff-
ing threat. Its first step is to identify Ts using Dynamic Time Warp-
ing (DTW) as the geographical distance metric, which is a promi-
nent method for measuring trajectory distance [30, 50, 52]. Then,
in step 2, we prohibit correct location disclosures. Since exactly
matching GPS coordinates and trajectories are rare, we allow for
inexact intersections within a small error margin. φ is a threshold
controlling the maximum amount of intersection allowed between
Ts and Tu. It can be defined using absolute length (e.g., 100 me-
ters, 1 kilometer) or using percentage of relative trajectory length
(e.g., 10% of Ts). In step 3, we prohibit sensitive location disclosures.
To prohibit any sensitive disclosure, we set ϱ = 0, which is suit-
able when trajectories are short, e.g., corresponding to taxi trips
or home-work commutes. If trajectories are collected over long
periods of time such as one month, it is advisable to set higher ϱ.
Outlier Leakage. In the outlier leakage attack, the threat stems
from an adversary’s ability to make sensitive inferences from atypi-
cal, outlier trajectories. To combat this threat, we must first identify
and detect outliers. We adapt the most popular distance-based out-
lier definition [40, 44]: Outliers are those trajectories that have
highest distance to their respective k’th nearest neighbor. It re-
mains to define an appropriate distance function d so that distances
between trajectories can be measured, and the nearest neighbors
of each trajectory (according to d) can be identified. AdaTrace con-
siders three distance functions, each of which corresponds to a
different type of outlier:
(1) Trip outlier: Trajectories with non-traditional trip start and
end locations. In this case, d is set as the geographical distance
between trajectories’ trip start and end locations.
(2) Length/duration outlier: Trajectories with unusually long or
short lengths. In this case, d is set to measure the difference between
two trajectories’ route lengths.
(3) Mobility outlier: Trajectories with unusual mobility patterns,
in which case d is set to measure the Jensen-Shannon Divergence
(JSD) between the mobility models of two trajectories: d(T1,T2) =
JSD(Π(T1), Π(T2)).
The distance functions above allow us to compute distances
between pairs of trajectories and detect whether a trajectory is a
certain type of outlier based on distance to its k’th nearest neighbor.
After detecting outliers, AdaTrace enforces Defense 3.
Defense 3 (β, κ). Let Tout ∈ Dsyn be a distance-based outlier,
and d be the distance function used in detecting Tout .
respect to d: Takin = argminT ∈Dr eal d(Tout ,T)
d(Tout ,Tsim) − d(Tout ,Takin) ≤ β
(1) Find the trajectory in Dr eal that is most similar to Tout with
(2) Let y be the number of trajectories Tsim ∈ Dr eal that satisfy:
(3) If y ≥ κ, mark as attack-resilient, otherwise susceptible.
The intuition behind this defense is as follows. We first identify
Takin, the real trajectory most similar to Tout . We then check how
many real trajectories exist which have distance similar to Takin’s
distance to Tout , and denote this quantity by y. This effectively
searches for a crowd of y trajectories with maximum distance β
to the candidate outlier. Note that we always have y ≥ 1 due to
Tsim = Takin in step 2. Finally, if y ≥ κ, where κ is the privacy
parameter enforcing a minimum crowd size, we conclude that Tout
plausibly blends in a crowd of actual trajectories. Hence, the trajec-
tory is similar to a group of actual users’ trajectories, it cannot be
conclusively linked to a particular user, and outlier leakage is not a
concern. However, if y  pop(Dr eal , Lj)) ∧ (pop(Dsyn, Li) > pop(Dsyn, Lj))
(pop(Dr eal , Li) < pop(Dr eal , Lj)) ∧ (pop(Dsyn, Li) < pop(Dsyn, Lj))
That is, their popularity ranks (in sorted order) agree. They are said
to be discordant if their ranks disagree. The Kendall-tau coefficient
can then be applied as:
(# of concordant pairs) − (# of discordant pairs)
KT =
n(n − 1)/2
In our experiment, we determine the locations L1, ..., Ln using a
fine-grained grid and use n = 400 locations.
Frequent travel pattern metrics. Mining popular travel patterns
has also received significant attention from the geodata analysis
community, for understanding traffic flows and road network per-
formance, and providing better navigation services. The following
two metrics measure resemblance with respect to frequent patterns
(FPs). For both metrics, we project trajectories on a uniform grid U,
thus obtaining the sequence of cells they pass through. We define a
pattern P as an ordered sequence of cells, e.g., P : C2 → C4 → C3.
We define the support of a pattern, supp(D, P), as the number of
occurrences of P in database D. We mine the top-k patterns in D,
i.e., the k patterns with highest support, denoted by F kU(D).
Our first metric measures difference in patterns’ support. We cal-
culate the relative difference between supp(Dr eal , P) and supp(Dsyn, P)
for each frequent pattern P ∈ F . Formally, the FP average relative
error is:
P ∈FkU(Dr eal)
|supp(Dr eal ,P)−supp(Dsyn,P)|
supp(Dr eal ,P)
F P AvRE =
k
Our second metric measures the set similarity between the top-k
patterns in Dr eal and the top-k patterns in Dsyn. Following the
F1-measure, i.e., harmonic mean of precision and recall, we define
the FP similarity metric as:
F P Similarity = F1(F kU(Dr eal), F kU(Dsyn))
FP similarity score is between 0 and 1, where higher score implies
better set preservation, and is therefore more desired. For the AvRE
metric, lower error values are more desired. In our experiments we
use k = 100, as higher k returned patterns with insignificant sup-
port. Also, we assume a 6x6 uniform grid for U and only consider
patterns that are at least 3 cells long.
Spatio-temporal travel metrics. Since many trajectory databases
consist of taxi/Uber rides or daily commutes, analysis of spatio-
temporal features of these trips becomes critical. We employ 3
evaluation metrics for trip and travel analysis.
Our first metric, called trip error, measures how well the cor-
relations between trips’ start and end regions are preserved. We
make use of the empirical trip distribution R defined in Section 4.3.
Given the grid U, we compute the trip distributions of the real and
synthetic databases, denoted R(Dr eal) and R(Dsyn) respectively.
The trip error is defined as: JSD(R(Dr eal),R(Dsyn)) where JSD is
the Jensen-Shannon divergence.
Our second metric, called length error, measures the error in
trip lengths (i.e., distances travelled in each trip). We calculate
the total distance travelled in a trip by adding up the distance be-
tween each consecutive GPS reading. Upon learning the maximum
length from Dr eal , we quantize trip lengths into 20 equi-width
buckets: {[0, x),[x, 2x), ..., [19x, 20x]}, where 20x is the longest
length present in Dr eal . For each bucket we determine how many
trips’ length fall into that bucket, thereby obtaining a histogram of
lengths. Let N(Dr eal) and N(Dsyn) denote this empirical, bucke-
tized histogram of real and synthetic databases respectively. The
length error is calculated as: JSD(N(Dr eal),N(Dsyn)).
Our final metric, called diameter error, is adopted from [26]. The
diameter of a trajectory T is defined as the maximum distance
between any pair of its GPS readings (not necessarily consecu-
tive). Similar to length error, we learn the maximum diameter from
Dr eal , perform equi-width bucketing and histogram extraction. Let
E(Dr eal) and E(Dsyn) denote the diameter distributions of the real
and synthetic database respectively. The diameter error is calculated
as: JSD(E(Dr eal), E(Dsyn)).
6.3 Comparison with Existing Generators
In this section we compare AdaTrace with ngram, DPT and SGLT.
Since all generators except SGLT have ε (differential privacy budget)
as a parameter, we perform our comparison by varying ε. Results
are summarized in Table 2. We make two general observations. First,
AdaTrace provides superior utility when subjected to the same level
of privacy: Out of 63 total comparison settings, AdaTrace outper-
forms its competitors in 53 cases. In certain settings, AdaTrace’s
utility improvement is significant (2-3 fold or more). In addition
to a utility advantage, AdaTrace also has a privacy advantage over
its competitors due to its attack resilience property. Second, we
observe that errors decrease and utility increases when higher ε is
used. As such, we can conclude that data quality is responsive to
changes in the privacy parameters, making AdaTrace flexible.
Table 2: Comparing AdaTrace with its competitors. Best result in each category is shown in bold. For FP F1 Similarity and
location Kendall-tau, higher values are better. For remaining metrics, lower values are better.
Geolife
Brinkhoff
Trip Error
Length Error
ε=0.5
Query AvRE ε=1.0
ε=2.0
ε=0.5
FP AvRE ε=1.0
ε=2.0
ε=0.5
ε=1.0
ε=2.0
ε=0.5
ε=1.0