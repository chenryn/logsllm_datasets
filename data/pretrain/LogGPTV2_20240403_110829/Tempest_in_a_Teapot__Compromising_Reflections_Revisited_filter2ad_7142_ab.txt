gain of approximately 20%.
2.2. Out-of-focus Blur and Motion Blur
In any image captured with a large enough aperture,
objects that are either closer or farther away than the selected
focus distance will be blurred. This out-of-focus blur is often
quite moderate for medium aperture SLR cameras – and
sometimes even desirable in photography as a visual effect.
In our application, as a large aperture telescope is applied for
improved light efﬁciency, the blurring can be rather drastic
(e.g., see Figure 1), posing a signiﬁcant obstacle when
capturing a high-resolution image of an object at unknown
or varying distance such as the slightly moving eye.
The range of distances in which objects appear “sufﬁ-
ciently sharp” for a ﬁxed focus setting is called the depth
of ﬁeld (DOF). The notion of “sufﬁciently sharp” in image
processing applications is related to the circle of confusion,
the area covered by a single object point projected onto the
image sensor given the current focus settings. If the circle of
confusion is signiﬁcantly larger than one camera pixel the
object will appear blurred. For an optical system consisting
of a single lens with focal length f and aperture D, at a
given distance s and for a pixel size v, the DOF is given by
2HFD s2
HFD 2−s2
∞
for s  0. Combined with Fast Fourier
Transformation, this is a fast and simple linear ﬁltering
procedure that can be proven to be optimal in terms of mean
squared error when the noise n is Gaussian. However, as a
linear method it is bound to produce the visually unpleasant
“ringing” artifacts [5]. Moreover, its performance decreases
in the presence of non-Gaussian noise, and it is not robust
to small imprecisions in PSF estimates, or small violations
of spatial invariance.
A widespread alternative is Richardson-Lucy deconvolu-
tion (RL) [25], [18]. Though computationally more costly
than the Wiener ﬁlter, RL is still fairly fast. It is a simple
nonlinear iteration, one step of which reads
· uk
uk+1 =
(cid:4)(cid:4)
(cid:3)
∗ ∗
h
(cid:3)
(2)
f
uk ∗ h
∗
where h
denotes the adjoint of the point-spread function,
∗(x, y) = h(−x,−y). This algorithm is better adapted to
h
Poisson noise in the data; in particular, the positivity of
grayvalues is a built-in constraint. In absence of noise, the
sharp image g would be a ﬁxed point of (2). However, due to
the ill-posedness of deconvolution, even small perturbations
are ampliﬁed over time such that after a while noise begins
to dominate the ﬁltered image. As a result, the deconvolution
process needs to be regularized by the number of iterations,
with fewer iterations meaning less sharpness, but also less
noise. For deblurring the reﬂections captured in the eye we
use Richardson-Lucy deconvolution.
2.4. Ofﬂine-Measurement of the PSF
Out-of-focus blur can be quite accurately removed from
an image, provided that the PSF could be measured accu-
rately. This is the case when the exact location of both the
focus plane and the object are known. (This is demonstrated
319
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:15:26 UTC from IEEE Xplore.  Restrictions apply. 
Figure 7. A sequence of measured PSFs, after stacking and post-processing. Their circular shape coined the notion
of “circles of confusion” in astronomic imaging.
Figure 8. Example of an unsharp image with unknown PSF (ﬁrst image), and the results from deconvolution using
the series of PSFs from Figure 7. The fourth PSF yields the best result.
Figure 9. Removing out-of-focus blur with deconvolution: Blurred image (left), the measured PSF (middle), and the
result of deconvolution (right). These images were taken from a stationary object, the correct PSF was measured.
in Figure 9, where the reﬂection is taken from a static object,
so the PSF can be measured accurately.)
For a moving target, however, the exact locations are
typically not known. In this section we will show that good
results can be achieved by measuring a series of PSFs for
varying distances and trying to deconvolve the blurred image
with each of them, followed by manually selecting the best
image. The main advantage of measuring the PSFs ofﬂine
is that we can use very long exposure times when capturing
the PSF, as this is done under lab conditions. Thus we
obtain an accurate PSF with low noise, which is crucial for
deconvolution algorithms to work well.
More sophisticated methods for determining the PSF
exist [35], [10]. However, our experiments show that these
have problems when faced with the signiﬁcant amount of
noise that is present in our measurements. Our method has
the advantage that it is more robust and tolerates some errors
in the measurement. Even dim images can be enhanced
signiﬁcantly.
For the a priori calibration, we use a bright source of
light (a white LED) with a circular mask and capture its
reﬂection in a small sphere. Taking its reﬂection in a sphere
greatly decreases the light’s apparent size so that it closely
resembles a true point light source. We capture several such
320
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:15:26 UTC from IEEE Xplore.  Restrictions apply. 
images under identical conditions and average over them
to further decrease the noise level, which is a standard
technique in astronomical imaging. A sequence of such
measured PSFs for different levels of out-of-focus blur is
displayed in Figure 7. The circular shape of the measured
PSFs is slightly irregular due to slight imperfections of the
telescope.
Once we obtain a sufﬁciently large sequence of measured
PSFs, given an unsharp image, we run the deconvolution
algorithm with each of these measured PSFs as input.
Finally, we select the output image that gives the sharpest
results by visual inspection.
2.5. Online-Measurement of the PSF
In this section we describe an alternative method that
allows us to determine the precise PSF that was effective in
a particular measurement. In addition to accurately dealing
with out-of focus blur, this technique also measures any
motion blur that occurs while capturing the image.
Basically, the technique relies on having a single bright
point with a dark surrounding area close to the monitor; the
image of this single point on the sensor then constitutes
the PSF. The key part for this approach is the selection
of the light source: if the source is not bright enough, the
measurement will be too noisy; if the source is too large
(such as electric bulbs), the measurement will be inaccurate.
Suitable light sources turned out to be either a laser or a
bright LED.
For a realistic attack, invisible light, e.g. infrared light, is
preferable as it has the advantage that it facilitates the task of
separating the PSF from background light, and it additionally
does not capture the attention and hence the suspicion of
the observed user. The light source can be mounted at any
position that ensures that the reﬂection of the light source
in the eye of the user is captured by the telescope. At
the telescope, the captured image passes a selective mirror
that reﬂects visible light while letting infrared light pass.
After additional ﬁltering, both light paths can be captured as
usual. (Some care has to be taken to remove potential effects
from different chromatic aberrations caused by the different
wavelengths, and possibly different sensor characteristics.)
Measuring the PSF in this way should yield very accurate
results. However, the use of bright invisible light sources is
prohibitively dangerous for academic purposes. We hence
did not implement it and used the same technique with
visible light instead; the overall approach did not change.
We believe that both approaches should give comparable
results.
2.6. Discussion of Results
Results with the PSF measured ofﬂine are shown in Fig-
ure 8. We obtained a sufﬁciently large number of measured
PSFs and ran the deconvolution algorithm with each of these
measured PSFs. Finally, we select the output image that
gives the best results.
This approach works very well if there is no motion blur
present in the captured image, thus it is very useful when
spying on stationary objects. The advantage of this method
is that the PSF can be accurately measured ofﬂine, since
one can use long exposures times to reduce the noise level
and to increase the image quality. However, if there is some
amount of motion blur present in the captured image, this
approach performs rather poorly.
When spying on the human eye, measuring the PSF
online as described in Section 2.5 performs much better.