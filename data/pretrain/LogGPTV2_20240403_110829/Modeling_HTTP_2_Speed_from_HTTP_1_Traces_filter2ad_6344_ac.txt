tor, the ΔP LT results are, to a large extent, impacted by page structure and its
interplay with TCP window growth and RTT.
5.2 Evaluation
Basic HTTP/2, Aggregate Dataset. Figure 4 plots the distribution of
ΔP LT s across the aggregate dataset. Recall that this contains nearly 280K water-
falls. Of these, almost 60 % beneﬁt from HTTP/2 (negative ΔP LT ). For another
28 % of the samples, the performance of the two protocols is identical, and
HTTP/2 actually hurts performance for the rest. We discuss the possible rea-
sons for some of these below, but these results paint a nuanced picture: HTTP/2
does improve performance for a majority of waterfalls, but despite better pro-
tocol design, web page PLTs can largely be determined by page structure and
dependencies.
Basic HTTP/2, Per-Website Dataset. The aggregate dataset provides
a macroscopic view of HTTP/2 performance, but looking at the per-website
dataset provides more interesting insights. Figure 5 shows the fraction of times
each website experienced a negative (green), positive (red), or zero (blue) ΔP LT .
Fig. 4. Overall impact of HTTP/2 on PLTs over 280K input waterfalls at zero loss.
Modeling HTTP/2 Speed from HTTP/1 Traces
243
For a given website, each waterfall represents a page view by a client. This ﬁgure
shows that diﬀerent downloads of the same page may be impacted diﬀerently by
HTTP/2. Several factors contribute to this: the RTT of a client, the variability
of user agents, devices and processing times, and the impact of customizations
and dynamic content mean that no two waterfalls are likely to be the same.
However, Fig. 5 hides the magnitude of the ΔP LT s on each website, so we
resort to a diﬀerent view of this result. Figure 6 plots some ﬁrst order statistics
of the ΔP LT s, for each website. The bottom and top whiskers indicate the 10th
and 90th percentile respectively, the bottom and top of a bar indicates the 25th
and 75th percentile, and the dark dot shows the median.
For all websites except 2, HTTP/2 improves PLT at the 75th percentile. In
other words, for these websites, at least 75 % of the downloads would see a beneﬁt
by using HTTP/2. For nearly two-thirds of the websites, the 90th percentile of
clients would see a beneﬁt. For nearly half the websites (28 out of 55), the 10th
percentile of clients see a ΔP LT of 10 % or more. Taken together, these results
present an interesting view of HTTP/2 performance: under no-loss conditions,
the structure of most websites is such that multiplexing provides beneﬁts.
But why is it that, for a third of the websites, the upper quartile of waterfalls
are negatively impacted by HTTP/2? One hypothesis was that the clients of
these websites had a qualitatively diﬀerent RTT distribution than those of other
websites (HTTP/2 is known to degrade with RTT [4]). However, plotting the
distribution of RTTs (omitted for space) showed no obvious correlation between
the distribution of ﬁrst-order statistics of the RTTs and those of the ΔP LT s.
Other potential reasons for performance diﬀerences across websites could
be diﬀerences in macroscopic Web page characteristics such as total payload of
resources in the waterfall, number, total payload and number of resources served
from the origin domain (which get multiplexed), number of cached resources,
number of 3PC resources, critical path length, number of 3PC resources on
critical path, number of js/css/html ﬁles served from the origin (and thus get
)
%
(
)
T
L
P
(
Δ
 20
 15
 10
 5
 0
-5
-10
-15
-20
 0
 10
 20
 30
 40
 50
Web Page #
Fig. 5. Fraction of times a website
experienced bad(red) / zero(blue) /
good(green) PLT change (Color ﬁgure
online)
Fig. 6. ΔP LT distributions for each
website at zero loss. Each candlestick
shows 10/25/50/75/90th %ile.
244
K. Zariﬁs et al.
Fig. 7. Impact of Prioritization on the (i) ΔP LT distribution across all samples of all
pages (left) and (ii) 90th percentile of the ΔP LT of each page (right).
prioritized in that channel) and device type. None of these seemed to directly
correlate with the observed ΔP LT s.
So, we resorted to a methodology that explores the impact of optimizations
like prioritization and push, based on observed patterns in manually examined
waterfalls, focusing on those that stood out in terms of HTTP/2 impact. Each
optimization focuses on one aspect of page structure, and we wanted to see if
negative HTTP/2 impact could be explained by some of these.
Prioritization, Per-Website Data. Figure 7 shows the results of the priori-
tization what-if scenario. Recall that this scenario was motivated by the obser-
vation that some pages download many critical objects (e.g. Javascripts), which
in turn trigger many other downloads. Basic HTTP/2 does not prioritize these,
so can delay the download of a resource that is on the critical path.
After applying prioritization, only 2 websites still see a negative impact from
HTTP/2 at the 90 %th percentile (at most 10 % of the time). Figure 7 (right)
shows the increase or decrease in the 90th percentile: for the third of the websites
for which basic HTTP/2 can perform badly in the upper quartile, prioritization
provides signiﬁcant gains, improving the 90th percentile ΔP LT s by up to 4 %.
We notice that prioritization does not aﬀect the 90th percentile of the websites
in the middle of the ﬁgure, for which the impact of HTTP/2 was already almost
always positive. Figure 7 (left) shows that across all waterfalls, prioritization
slightly improves the ΔP LT distribution but also removes the tail of negative
impacts.
Push, Per-Website Data. Another reason why HTTP/2 performs worse than
HTTP/1.1 is a structural one. We have found examples where HTTP/2 multi-
plexes 6 or fewer objects. In such cases, using parallel connections can be better,
since each of those (up to 6 for most browsers) starts with an initial window of 10,
whereas HTTP/2 uses a single TCP channel with the same congestion window.
We have seen a similar eﬀect with domain sharding. When a website is sharded
across 3 domains and HTTP/2 multiplexes 18 objects or fewer, HTTP/1.1 wins.
This indicates that these websites may have been optimized for HTTP/1.1.
Figure 8 shows performance using ideal push. As with prioritization, ideal
push provides beneﬁts at the 90th percentile except for 3 websites. However,
relative to prioritization, it improves the median performance of each website
signiﬁcantly and only 7 out of 55 websites do not see more than 10 % gain for
Modeling HTTP/2 Speed from HTTP/1 Traces
245
the top 10th percentile of samples. This more pervasive improvement is visible
in the change in the aggregate CDF (Fig. 8 (left)), where now only 3–4% of
waterfalls see a negative performance impact from HTTP/2.
Fig. 8. Impact of Push on the (i) ΔP LT distribution across all samples of all pages
(left) and (ii) 90th percentile of the ΔP LT of each page (right).
Putting it all Together. Figure 9 plots the overall impact of the optimizations
on the aggregate dataset. This results in gains with HTTP/2 for nearly 70 % of
the waterfalls, equal performance for most of the rest, and only about 1 % of
the waterfalls seeing worse performance. The fraction of waterfalls with high
performance gains is much higher, thanks in large part to push.
In summary, our results suggest that HTTP/2’s features provide good per-
formance gains for most of the websites. For about a third, the top quartile’s
PLT performance worsens with HTTP/2, but this can be ﬁxed with a combina-
tion of prioritization and push. Prioritization addresses structural issues in the
waterfall that cause this worse performance, and push does that too, but also
increases the gains for HTTP/2 across the board by utilizing idle network time.
6 Related Work
Several prior studies have assessed the performance of SPDY [4–6], the precursor
to HTTP/2. The approach of recording and replaying a website, used in many
of those, misses out on unreplayable parts of a download, and does not expose
the variability across many downloads of the same page due to personalization,
Fig. 9. Impact of HTTP/2 with optimizations on PLTs
246
K. Zariﬁs et al.
localization and dynamic content [11,14]. Our work uses traces from real page
views, so contains actual processing and rendering delays, and realistic client
distributions. Furthermore, by using a model, we are able to explore several
what-if scenarios on a very large dataset at fairly fast speed.
Prior work [3,7] has also focused on impact of SPDY speciﬁcally on cellular
networks. The results are ambiguous, with some showing PLT decrease by 23 %
and others highlighting that the single channel suﬀers more often from spuri-
ous retransmissions. Our work is complementary, and we have left the focus on
mobile devices for future work.
Our work would beneﬁt from the help of a tool that calculates object rela-
tionships, like the browser plug-in wProf [13]. Unfortunately wProf calculates
dependencies in real-time, which can not be used at the scale of traces that we
are dealing with. A similar tool could be used to share structures and critical
paths of targeted websites, which can inform optimal prioritization.
7 Conclusion
While HTTP/2 standardization is complete, the conditions under which
HTTP/2 improves over the existing standard are not yet completely under-
stood. Our work adds to this understanding by analyzing a large dataset of
instrumented HTTP/1.1 page views using a model called rt-h2 that estimates
ΔP LT from this dataset. We ﬁnd that HTTP/2’s basic features can improve the
90th percentile ΔP LT for nearly two thirds of the websites. Push and priori-
tization extend this further to cover all websites. Our work reveals aspects of
page structure in our dataset that determine the eﬃcacy of push and prioriti-
zation. Much work remains, however, including potentially enriching our model,
exploring to what extent our estimated ΔP LT s manifest themselves in CDNs,
and ﬁnding methods to achieve the forms of prioritization and push we consider
in this paper.
Acknowledgments. We thank our shepherd, Srikanth Sundaresan, and the reviewers
for their helpful comments. Kyriakos Zariﬁs performed this work while employed tem-
porarily at Akamai. This work was funded in part by the National Science Foundation
(NSF) under grant number CNS-1413978.
References
1. HTTP Pipelining Not So Fast (Nor Slow!). http://www.guypo.com/http-pipe
lining-not-so-fast-nor-slow/
2. Resource Timing Speciﬁcation. http://www.w3.org/TR/resource-timing/
3. SPDY Performance on Mobile Networks. https://developers.google.com/speed/
articles/spdy-for-mobile
4. SPDY whitepaper. https://www.chromium.org/spdy/spdy-whitepaper
5. Cherif, W., Fablet, Y., Nassor, E., Taquet, J., Fujimori, Y.: Dash fast start using
HTTP/2. In: NOSSDAV (2015)
Modeling HTTP/2 Speed from HTTP/1 Traces
247
6. El-Khatib, Y., Tyson, G., Welzl, M.: Can SPDY really make the web faster? In:
IFIP Networking Conference (2014)
7. Erman, J., Gopalakrishnan, V., Jana, R., Ramakrishnan, K.K.: Towards a
SPDY’ier mobile web? In: CoNEXT (2013)
8. Flach, T., Dukkipati, N., Terzis, A., Raghavan, B., Cardwell, N., Cheng, Y., Jain,
A., Hao, S., Katz-Bassett, E., Govindan, R.: Reducing web latency: the virtue of
gentle aggression. In: SIGCOMM (2013)
9. Ha, S., Rhee, I., Xu, L.: CUBIC: a new tcp-friendly high-speed TCP variant.
Operating Syst. Rev. 42, 64–74 (2008)
10. Meenan, P.: How fast is your web site? Commun. ACM 56, 49–55 (2013)
11. Padhye, J., Nielsen, H.F.: A comparison of SPDY and HTTP performance. Tech-
nical report, July 2012
12. Varvello, M., Schomp, K., Naylor, D., Blackburn, J., Finamore, A., Papagiannaki,
K.: To HTTP/2, or not to HTTP/2, that is the question. In: PAM (2016)
13. Wang, X.S., Balasubramanian, A., Krishnamurthy, A., Wetherall, D.: Demystifying
page load performance with wprof. In: NSDI (2013)
14. Wang, X.S., Balasubramanian, A., Krishnamurthy, A., Wetherall, D.: How speedy
is SPDY? In: NSDI (2014)