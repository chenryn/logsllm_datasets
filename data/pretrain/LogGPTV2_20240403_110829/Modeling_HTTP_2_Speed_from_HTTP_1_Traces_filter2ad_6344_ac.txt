### 5.2 Evaluation

#### Basic HTTP/2, Aggregate Dataset
Figure 4 illustrates the distribution of ΔP LT (Page Load Time) changes across an aggregate dataset containing nearly 280,000 waterfalls. Approximately 60% of these samples show improved performance with HTTP/2 (negative ΔP LT). Another 28% of the samples exhibit identical performance for both protocols, while the remaining samples indicate that HTTP/2 actually degrades performance. These results highlight a nuanced picture: although HTTP/2 generally improves performance for the majority of waterfalls, the overall PLT is still significantly influenced by page structure and dependencies.

#### Basic HTTP/2, Per-Website Dataset
The aggregate dataset provides a broad overview of HTTP/2 performance, but a more detailed analysis can be gained from the per-website dataset. Figure 5 shows the frequency of negative (green), positive (red), and zero (blue) ΔP LT values for each website. Each waterfall in this context represents a page view by a client. This figure demonstrates that different downloads of the same page can be affected differently by HTTP/2 due to factors such as RTT (Round-Trip Time), variability in user agents, devices, processing times, and the impact of customizations and dynamic content.

However, Figure 5 does not provide information on the magnitude of the ΔP LT changes. To address this, Figure 6 presents first-order statistics of the ΔP LT for each website. The bottom and top whiskers represent the 10th and 90th percentiles, respectively, while the bottom and top of the bar indicate the 25th and 75th percentiles. The dark dot marks the median.

For all but two websites, HTTP/2 improves PLT at the 75th percentile, meaning that at least 75% of the downloads would benefit from using HTTP/2. For approximately two-thirds of the websites, the 90th percentile of clients would also see a benefit. Additionally, for nearly half the websites (28 out of 55), the 10th percentile of clients experience a ΔP LT improvement of 10% or more. These results suggest that under no-loss conditions, the multiplexing feature of HTTP/2 provides benefits for most websites.

#### Investigating Negative Impacts
Despite these benefits, for about a third of the websites, the upper quartile of waterfalls is negatively impacted by HTTP/2. One hypothesis was that these websites had a qualitatively different RTT distribution compared to others. However, plotting the RTT distributions (omitted for space) showed no clear correlation between RTT and ΔP LT.

Other potential reasons for performance differences could include variations in macroscopic web page characteristics, such as the total payload of resources, the number and size of resources served from the origin domain, the number of cached resources, the number of third-party (3PC) resources, critical path length, and the number of JavaScript, CSS, and HTML files served from the origin. None of these factors directly correlated with the observed ΔP LT changes.

#### Optimization Scenarios

##### Prioritization, Per-Website Data
Figure 7 presents the results of a prioritization what-if scenario. This scenario was motivated by the observation that some pages download many critical objects (e.g., JavaScripts), which in turn trigger additional downloads. Basic HTTP/2 does not prioritize these, potentially delaying the download of resources on the critical path.

After applying prioritization, only two websites still experienced a negative impact from HTTP/2 at the 90th percentile. Figure 7 (right) shows the changes in the 90th percentile: for the third of the websites where basic HTTP/2 performed poorly in the upper quartile, prioritization provided significant gains, improving the 90th percentile ΔP LT by up to 4%. Prioritization did not affect the 90th percentile of websites in the middle of the figure, where the impact of HTTP/2 was already mostly positive. Figure 7 (left) indicates that across all waterfalls, prioritization slightly improves the ΔP LT distribution and eliminates the tail of negative impacts.

##### Push, Per-Website Data
Another reason for HTTP/2's poorer performance compared to HTTP/1.1 is structural. We found examples where HTTP/2 multiplexes six or fewer objects. In such cases, using parallel connections can be more effective, as each connection (up to six for most browsers) starts with an initial window of 10, whereas HTTP/2 uses a single TCP channel with the same congestion window. Domain sharding can also affect performance; when a website is sharded across three domains and HTTP/2 multiplexes 18 or fewer objects, HTTP/1.1 may perform better, indicating that these websites may have been optimized for HTTP/1.1.

Figure 8 shows the performance using ideal push. Similar to prioritization, ideal push provides benefits at the 90th percentile for all but three websites. However, it significantly improves the median performance of each website, and only seven out of 55 websites do not see more than a 10% gain for the top 10th percentile of samples. This widespread improvement is evident in the change in the aggregate CDF (Figure 8 (left)), where only 3-4% of waterfalls now experience a negative performance impact from HTTP/2.

#### Putting it All Together
Figure 9 summarizes the overall impact of the optimizations on the aggregate dataset. With these optimizations, nearly 70% of the waterfalls see improvements with HTTP/2, most of the rest experience equal performance, and only about 1% see worse performance. The fraction of waterfalls with high performance gains is much higher, largely due to the use of push.

In summary, our results suggest that HTTP/2's features provide good performance gains for most websites. For about a third of the websites, the top quartile's PLT performance worsens with HTTP/2, but this can be mitigated with a combination of prioritization and push. Prioritization addresses structural issues in the waterfall that cause poor performance, while push not only resolves these issues but also increases the overall gains by utilizing idle network time.

### 6 Related Work
Several prior studies have assessed the performance of SPDY, the precursor to HTTP/2. Many of these studies used the approach of recording and replaying a website, which misses unreplayable parts of a download and does not capture the variability across multiple downloads of the same page due to personalization, localization, and dynamic content. Our work uses traces from real page views, capturing actual processing and rendering delays and realistic client distributions. By using a model, we can explore various what-if scenarios on a large dataset at a fast speed.

Previous research has also focused on the impact of SPDY on cellular networks, with mixed results. Some studies show a 23% decrease in PLT, while others highlight that the single channel suffers more often from spurious retransmissions. Our work complements these studies, and we plan to focus on mobile devices in future work.

Our work would benefit from a tool like wProf, which calculates object relationships in real-time. Unfortunately, wProf cannot handle the scale of traces we are dealing with. A similar tool could help share structures and critical paths of targeted websites, informing optimal prioritization.

### 7 Conclusion
While HTTP/2 standardization is complete, the conditions under which HTTP/2 improves over the existing standard are not yet fully understood. Our work contributes to this understanding by analyzing a large dataset of instrumented HTTP/1.1 page views using a model called rt-h2, which estimates ΔP LT. We find that HTTP/2's basic features can improve the 90th percentile ΔP LT for nearly two-thirds of the websites. Push and prioritization extend this further to cover all websites. Our work reveals aspects of page structure that determine the efficacy of push and prioritization. Future work includes enriching our model, exploring how our estimated ΔP LTs manifest in CDNs, and finding methods to achieve the forms of prioritization and push considered in this paper.

### Acknowledgments
We thank our shepherd, Srikanth Sundaresan, and the reviewers for their helpful comments. Kyriakos Zariﬁs performed this work while employed temporarily at Akamai. This work was funded in part by the National Science Foundation (NSF) under grant number CNS-1413978.

### References
1. HTTP Pipelining Not So Fast (Nor Slow!). http://www.guypo.com/http-pipelining-not-so-fast-nor-slow/
2. Resource Timing Specification. http://www.w3.org/TR/resource-timing/
3. SPDY Performance on Mobile Networks. https://developers.google.com/speed/articles/spdy-for-mobile
4. SPDY whitepaper. https://www.chromium.org/spdy/spdy-whitepaper
5. Cherif, W., Fablet, Y., Nassor, E., Taquet, J., Fujimori, Y.: DASH fast start using HTTP/2. In: NOSSDAV (2015)
6. El-Khatib, Y., Tyson, G., Welzl, M.: Can SPDY really make the web faster? In: IFIP Networking Conference (2014)
7. Erman, J., Gopalakrishnan, V., Jana, R., Ramakrishnan, K.K.: Towards a SPDY’ier mobile web? In: CoNEXT (2013)
8. Flach, T., Dukkipati, N., Terzis, A., Raghavan, B., Cardwell, N., Cheng, Y., Jain, A., Hao, S., Katz-Bassett, E., Govindan, R.: Reducing web latency: the virtue of gentle aggression. In: SIGCOMM (2013)
9. Ha, S., Rhee, I., Xu, L.: CUBIC: a new TCP-friendly high-speed TCP variant. Operating Syst. Rev. 42, 64–74 (2008)
10. Meenan, P.: How fast is your web site? Commun. ACM 56, 49–55 (2013)
11. Padhye, J., Nielsen, H.F.: A comparison of SPDY and HTTP performance. Technical report, July 2012
12. Varvello, M., Schomp, K., Naylor, D., Blackburn, J., Finamore, A., Papagiannaki, K.: To HTTP/2, or not to HTTP/2, that is the question. In: PAM (2016)
13. Wang, X.S., Balasubramanian, A., Krishnamurthy, A., Wetherall, D.: Demystifying page load performance with wprof. In: NSDI (2013)
14. Wang, X.S., Balasubramanian, A., Krishnamurthy, A., Wetherall, D.: How speedy is SPDY? In: NSDI (2014)