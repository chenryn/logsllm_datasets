Figure 7: Number of movements per edge creation event
for Facebook
coeﬃcient of variation (COV) of masters is 0.0019. Thus,
our online heuristic is successful in balancing masters across
servers. To test against workload imbalances, we examine
write patterns. The COV of writes per server is 0.37, which
indicates that they are fairly balanced across all servers and
no single server is the source of a high proportion of writes.
We expect reads to be even more balanced across users: sys-
tems such as Twitter handle reads automatically through
API calls via periodic polling (90% of Twitter traﬃc is gen-
erated via its API). Further, there is a very low correlation
between heavy-writers and the number of their slave repli-
cas. So, they do not present a big problem for the system.
We have therefore shown that SPAR handles both writes
and reads well in terms of balancing them across servers as
per requirements.
5.3.2 Moving Nodes Around
Next, we turn our attention to the footprint of SPAR in
terms of user’s data movements (migrations). In Fig. 6, we
show a stacked bin time-series of action taken by SPAR on-
381 
2
Client Requests
1
0.8
0.6
0.4
0.2
s
t
n
e
v
e
"
n
o
i
t
c
a
o
n
"
f
o
o
i
t
a
r
Orkut
Facebook
Twitter
Orkut
Facebook
Twitter
s
t
n
e
v
e
/
d
e
v
o
m
s
e
d
o
n
#
1.5
1
0.5
0
4
8
16 32
number of servers
64 128 256 512
0
4
8
16 32
number of servers
64 128 256 512
Figure 8: Movement costs for various datasets.
line upon each edge arrival event for the Facebook dataset
with K = 2 and 16 servers. We see that following a transient
phase during which the network builds up, SPAR online en-
ters a steady-state phase in which 60% of edge arrivals do
not create any movements.
In the remaining 40% of the
cases, data gets moved.
In Fig. 7, we plot the number of transmissions per edge
arrival, with its CDF as an inset. We see that whenever
a movement occurs, in an overwhelming majority (90%) of
cases, it involves the data of only two users or less. The
largest movement involves moving data of 130 users (nodes).
Fig. 8 summarizes the movement costs on the system for
Facebook, Orkut and Twitter from 4 servers to 512. The
left plot in Fig. 8 depicts the average fraction of do nothing
actions that involve no movement of nodes (users’ data), dis-
counted the transient phase. The right plot in Fig. 8 depicts
the total of number of movements divided by the number of
edges. These ﬁgures show that the footprint remains low for
all conﬁgurations of datasets and number of servers.
5.3.3 Adding/Removing Servers
Adding servers: When a server is added, we can use one
of two policies: (1) wait for new arrivals to ﬁll up the server,
or (2) re-distribute existing masters from other servers into
the new server. We will study the overhead of such policies
in terms of replication costs.
We start with the ﬁrst case, where we go from 16 to 32
servers by adding one server every 150K new users. This
strategy yields a marginal increase of ro (2.78), compared to
the ro (2.74) that we would have obtained if the system was
dimensioned for 32 servers from the beginning. This shows
that SPAR is able to achieve an eﬃcient state independently
of how servers are added. Although it does not do an ex-
plicit re-distribution, the COV of the number of masters per
server remains very low at the end on the trace (0.004). This
shows that we can gracefully add new servers without extra
overhead.
In the second experiment, we tested the eﬀect of an exten-
sive upgrade of the infrastructure. We double the number of
servers at once and force re-distribution of the masters. This
reduces the number of masters per server by half while being
load-balanced. We tested the addition of 16 servers in two
cases, ﬁrst after 50% of the edge creation trace is replayed,
and second after 100%. Doubling the number of servers leads
to the expected transmission of half the masters. SPAR,
however, needs to move additional slaves to maintain lo-
cal semantics. Adding a server also causes an increase in
the ﬁnal replication overhead. For instance, doubling the
initial 16 servers at 50% of the trace produces a transient
increase in the replication overhead by 10% . This overhead
......................
FrontEnds
(State-less)
Application Logic
......................
Middleware (Library)
......................
................
PM
DS
................
w
LDS
RMDS
x
LDS
RMDS
Data Store 
Servers
u
LDS
RMDS
v
LDS
RMDS
Figure 9: Sketch of SPAR’s architecture
is progressively reduced as new edges are added, reaching
2.82, only a 2% higher than if we started with 32 servers.
With proactive reshuﬄing of edges (replay old edges as if
new), described in Sec. 4, the additional overhead caused
by addition of servers on-the-ﬂy becomes almost insigniﬁ-
cant, although the number of movements is higher due to
the proactive reshuﬄing.
Removing servers: Next, we test what happens when a
server is removed. The average number of movements is
485K, with a marginal increase in ro from 2.74 to 2.87. We
can further reduce ro to 2.77, at the cost of additional 180K
transmissions, if we replay the edges of the nodes aﬀected
by the server removal. One might argue that server removal
seldom happens as systems usually do not scaled down. The
case of server removals due to failures is discussed in Sec. 6.2.
Overall, we have demonstrated that SPAR is able to dis-
tribute load eﬃciently, and cope with both social network
graph dynamics as well as physical (or virtual) machine dy-
namics with low overhead. Next, we describe the SPAR
system architecture.
6. SPAR SYSTEM ARCHITECTURE
We now describe the basic architecture and operations
of SPAR. Fig. 9 depicts how SPAR integrates into a typ-
ical three-tier web architecture. The only interaction be-
tween the application and SPAR is through the Middle-ware
(M W ). The M W needs to be called by the application to
know the address of the back-end server that contains the
user’s data to be read or written. Once the application has
obtained the address, it uses the common interface of any
data-store e.g. a MySQL driver, Cassandra’s API, etc. The
application logic can be written as if centralized since it is
agnostic to the number of back-end servers, how to operate
them and how to scale out. Making those operations scalable
and transparent is the task of the remaining components of
SPAR: the Directory Service DS, the Local Directory Ser-
vice LDS, the Partition Manager P M and the Replication
Manager RM .
6.1 System Operations
Data Distribution: The data distribution is handled
by the DS, which returns the server that hosts the master
382replica of a user through a key table look-up: Hm(key) →
u. Additionally, the DS also resolves the list of all servers
where the user has replicas in: Hs(i) → {u, v, ..., w}. The
Directory Service is implemented as a DHT with consistent
caching and is distributed across all servers in the data back
end. The Local Directory Service (LDS) contains a partial
of the look-up table Hm
view of the DS. Speciﬁcally,
and N
M of look-up table Hs. The LDS only acts as cache
of the DS for performance reasons and is invalidated by the
DS whenever the location of a replica changes.
N (1+ro)
M
Data Partitioning: The P M runs the SPAR algorithm
described in Sec. 4 and performs the following functions: (i)
map the user’s key to its replicas, whether master or slaves,
(ii) schedule the movement of replicas, and (iii) re-distribute
replicas in the event of server addition or removal. SPAR
algorithm would allow the P M to be distributed. However,
for simplicity, we implemented a centralized version of P M
and run multiple mirrors that act on the failure of the main
P M to avoid single point of failure2. P M is the only com-
ponent that can update the DS. Note that this simpliﬁes
the requirements to guarantee global consistency on the DS
because only the main P M can write to it.
Data Movements: Data movements (migrations of repli-
cas) takes place when a replica needs to be moved (migrated)
from one server to another. After a movement, all replicas
undergo reconciliation to avoid inconsistencies that could
have arisen during the movement, i.e. the user writing data
while its master changes its location. The same applies when
a replica is scheduled to be removed. We do not propose a
new mechanism to handle such reconciliation events, but in-
stead rely on the semantic reconciliation based on versioning
proposed in other distributed systems (e.g. Dynamo [13]).
Data Replication and Consistency: The Replication
Manager RM runs on each server of the data back-end. The
main responsibility of RM is to propagate the writes that
take place on a user’s master to all her slaves using an even-
tual consistency model, which guarantees that all the repli-
cas will – with time – be in sync. Note that since SPAR relies
on a single master and multiple slaves conﬁguration. This
avoids the inconsistencies arising from maintaining multi-
ple masters. A single master has the additional beneﬁt that
inconsistencies can only arise due to failures or due to move-
ments produced by edge, node or server arrivals and not as
part of the regular operations of read and writes. Note that
the RM is not replacing the data-store, but diﬀerent data-
stores need diﬀerent implementations of the RM to adapt to
its interface. In this ﬁrst iteration of SPAR we provide the
implementation of RM for MySQL and Cassandra although
other data-stores could be equally supported (i.e. Postgres,
Memcached, MongoDB etc.).
Adding and Removing Servers: The P M also con-
trols the addition and/or removal of servers into the back-
end cluster on demand. This process is described in Sec. 4
and evaluated in 5.
Handling Failures: Failure on the servers running the
data back-end are bond to happen, either because of server
speciﬁc failures, e.g. disk, PSU failure, etc. or because of
failures at the data-center level, e.g. power outages, network
issues, etc.
SPAR relies on a heartbeat-like system to monitor the
2The current centralized version of P M can handle 52 edge
creations per second in a commodity server.
health of the data back-end servers. When a failure is de-
tected the P M decides the course of action based on the
failure management policy set by the administrator. We
consider two types of policies, one that reacts to transient
failures and another one to permanent failures.
A permanent failure is treated as a server removal.
In
this case, slave replicas of the master that went down are
promoted to masters and all their neighbors are recreated.
For more details see Section 4 and 5.
For transient failure events (short lived), one potential
option is to promote one of the slave replicas whose master
went down without triggering the recreation of her neigh-
bors. Consequently, the local data semantics is temporally
sacriﬁced. In this case, the system would only suﬀer a grace-
ful degradation since we can leverage a nice property of
SPAR. This property entails that the server hosting a slave
replica of one of the failed masters will also contain a large
portion of the neighbors of such master. Therefore, while
the promotion of a slave does not guarantee local data se-
mantics, it does still provide access to most of the user’s
neighborhood. To better illustrate this point let us take the
example of the Twitter dataset for 16 partitions.
In this
case, 65% of users have more than 90% of their direct neigh-
bors present in the server that hosts the best possible slave
replica, which is the candidate to be promoted in the case of
failure. This solution should only be applied for extremely
short lived outages. Otherwise, the user experience of the
OSN would suﬀer and the system administrator would be
better oﬀ implementing the permanent failure scenario.
Current SPAR replication is not meant for high-availability
but for redundancy and to guarantee local data semantics.
However, high-availability in SPAR could be obtained in two
ways: one is to modify the formulation of the problem so
that there are at least K(cid:2)
master replicas where the local data
semantics is maintained while minimizing MIN REPLICA.
This approach, however, is left for future work. The other
option is a simple brute force approach that mirrors the
SPAR system under K = 0 as many times as desired.3
6.2
Implementation Details
The RM sits on top of a data-store and controls and mod-
iﬁes its operations. The read events (e.g. selects) are for-
warded directly to the data-store without delay. However,
the write events (e.g.updates, inserts, deletes) need to be
analyzed and can be altered both for replication and perfor-
mance reasons.
Let us illustrate the inner workings of the RM with an
example of a write operation in MySQL. A user i wants
to create a new event w, which generates the following com-
mand to be inserted in MySQL: insert into event(iid,wid,w) ,
where iid and wid are the pointers to the user and the event’s
content. The RM will react to this command by obtaining
the target table event. The RM knows, through simple
conﬁguration rules, that the event table is partitioned, and
thus the insert needs to be replayed in all servers hosting
the slave replicas of user iid. The RM queries its LDS to
obtain the list of servers to propagate the insert, and issue
the same insert command to the local MySQL. Addition-
3For instance, in the case of Twitter for 128 server, we could
obtain via mirroring three master replicas (with full local
semantics) with a replication overhead ro of 6.63. The one
master plus two slave replicas conﬁguration (K = 2) would
result in a ro of 3.20.
383ally, this event will be broadcast to all the neighbors of the
user. For each contact j of i the application will generate
a insert into event-inbox(iid,jid,wid) and the RMmysql will
replay the same command to all the appropriate servers.
7. SPAR IN THE WILD: EVALUATION
In this section, we study the performance of SPAR on two
data-stores: MySQL (a traditional RDBMS) and Cassan-
dra (a Key-Value used in production). More speciﬁcally, we
compare SPAR against random partitioning (for Cassandra)
and full replication (for MySQL).
As the reference OSN application to be scaled we use an
open-source Twitter-clone called Statusnet [5], which relies
on centralized architecture (PHP and MySQL/Postgres).
Our testbed consists of a cluster of 16 low-end commodity
servers: the so-called “little engine(s)”. These servers are
interconnected by a Gigabit-Ethernet switch. Each server
has a Pentium Duo CPU at 2.33GHz with 2GB of RAM
and a single hard drive. The data of what Twitter was as of
end of 2008 (Sec. 5.1.2) is loaded in the data-stores.
7.1 Evaluation with Cassandra
Statusnet is designed to run on top of MySQL or Post-
gres. Therefore, to evaluate SPAR with Cassandra we need
to reproduce the functionality on Statusnet for the data
model speciﬁc of Cassandra (version 0.5.0). We deﬁne a
data scheme that contains information about users, updates
(tweets) and the list of update streams that the users sub-
scribe to. We implement the data scheme using diﬀerent
columns and super columns.
To implement SPAR on top of Cassandra, ﬁrst, we disable
the default random partitioner of Cassandra by creating iso-
lated independent instances of Cassandra. The Cassandra
nodes in our system do not communicate with each other.