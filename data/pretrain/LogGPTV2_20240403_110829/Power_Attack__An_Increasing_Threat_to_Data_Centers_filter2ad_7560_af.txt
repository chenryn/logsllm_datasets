(with a control period of 2 minutes), for power to return after
a power spike. Clearly, a power attacker can launch multiple
attacks within such a long interval.
In summary, although power capping can mitigate power
attack to some extent, it cannot completely prevent power
3 No attack at valley is successful.
attack due to the three reasons discussed above. More im-
portantly, power capping is mainly designed to allow more
aggressive power oversubscription in data centers [12], which
can actually lead to a greater risk of power attack.
B. Server consolidation and energy proportionality
Servers are well known to consume too much power even
when they are idling. Some recent studies show that current
servers still draw about 60% of their peak power at idle [23].
This fact is far away from the ideal case where a server’s
energy consumption can be proportional to its workload, which
is called energy proportionality. An energy-proportional server
would consume little energy at idle and its energy consumption
would increase proportionally to its workload intensity. Since
the average server utilization in typical data centers is only
20-30% [23], energy-proportional servers would lead to a
signiﬁcant amount of energy savings. While today’s servers
are still not yet energy-proportional by themselves, a recently
proposed power management strategy, called server consolida-
tion, can help make a data center more energy-proportional by
dynamically migrating and consolidating the workloads onto
a small number of servers and shutting down other servers for
energy savings. For example, some recent studies [33], [8],
[32], [34] have proposed VM placement solutions that rely on
live VM migration for server consolidation.
While these server consolidation solutions can indeed re-
duce the overall energy consumption of a data center, they may
actually also increase the risk of having power attacks. The key
idea of server consolidation is to consolidate workload, so that
only a smaller number of servers are used with high utilization,
which generally comes with high power consumption for each
server. In addition, most server consolidation solutions try
to put consolidated workload on servers in the same rack
or connected to the same PDU for easier management. This
strategy could also lead to less cooling costs, because only
those Computer Room Air Conditioning (CRAC) units that are
near this rack/PDU needs to be running, while other CRACs
near those shutdown racks/PDUs can be turned off as well
for energy savings [4]. Therefore, server consolidation clearly
would increase the power consumption of the rack or PDU
that is selected to run the consolidated workload. This thus
would push them further to the edge of having a power outage,
providing an attacker a better opportunity to launch power
attacks.
Whereas future server hardware will certainly become
more energy proportional to their workloads, energy propor-
tionality may also provide more opportunities for a power
attacker. The key reason is that energy proportionality can
allow more aggressive power oversubscription, which in turn
increases the likelihood of having power outages. For instance,
for a today’s server that is not energy proportional, suppose its
peak power is 200 W and it consumes 80% of the peak power,
i.e., 160 W, when it works at a 20% utilization. Therefore, for
a rack equipped with a CB that has a 2000 W of rated power
limit, the rack is likely to host 12 such servers with power
oversubscription based on the power values at 20% utilization.
Now, let us suppose that we have energy-proportional servers
that consume only 40 W (20% of peak) of power at a 20%
utilization. With aggressive power oversubscription, now the
rack can host up to 50 servers. In such a case, an attacker
can more easily increase the power consumption of the rack
to about 4000 W, simply by increasing the server utilization
to only 40%, resulting in signiﬁcant overload and immediate
trip of the CB and thus the shutdown of the rack.
IX. MITIGATION METHODS
The difﬁculty of defending against a power attack roots
in three aspects. First, although power oversubscription is the
major vulnerability exposed to power attacks, it is also one
of the key techniques to reduce the operational cost of a data
center. As data centers continue to scale up in a fast speed
and it is extremely expensive to upgrade data center power
infrastructures, power oversubscription has become the trend
and will be more aggressive to accommodate more servers
in a data center. Second, it is challenging to monitor power
consumption of each server accurately in a large scale data
center. Since deploying power meters for every server in a
data center is too costly [9], [24], current power management
solutions tend to approximate the power consumption of each
server via utilization-based modeling. However, our work
demonstrates that system utilization cannot precisely reﬂect
power consumption. Without accurate and timely measurement
of power consumption of servers, it will be difﬁcult to detect
and prevent power attacks. Third, with the pervasion and
easy access of cloud services, an attacker can consume the
computing resources of a data center like a normal user.
Although the intention of attackers is very different from that
of normal users, it is very difﬁculty to distinguish attackers
from normal users and deny their service requests at
the
beginning.
In spite of these difﬁculties, there exist feasible approaches
to mitigating the consequence of a power attack. Tracking
down the power consumption of individual incoming requests
and taking corresponding reaction can be a promising way
to defend against a power attack at the server level. Shen
et al. [31] built models estimating the power consumption
of requests throughout their execution life in a very ﬁne-
grained fashion. Such an approach can effectively throttle
high-consumption request rate and thus suppress power spikes,
which will mitigate power attacks to some extent. It also has
minor impact on the service performance.
At the cluster and data center levels, we propose a new load
balancing strategy, called power balancing, that uses the esti-
mated power consumption as an important factor (along with
CPU utilization or throughput) to distribute incoming service
requests. Different from traditional load balancing algorithms
that are based on system utilization and amount of workload,
power balancing captures service requests that consume a
large amount of power and evenly distributes them to servers
connected to different branch circuits in a data center. As
a result, the chance of tripping a branch circuit breaker is
minimized. We leave the detailed design, implementation, and
evaluation of the power balancing mechanism as our future
work.
The deployment of per-server UPS is an alternative way
to defend against power attacks. When each server contains
a mini-UPS, a short period of power outage will not bring
13
down the server. Besides, per-server UPS is also promising to
improve energy efﬁciency [6]. However, replacing data-center-
level UPS with tens of thousands of mini-UPSes is not an
easy task. Different UPS deployment mechanisms will bring
in great impact on data centers, and hence it will take time to
have per-server UPSes be widely deployed in data centers.
X. RELATED WORK
While we are the ﬁrst to propose the concept of power
attack, there are numerous research works studying power
management in different computing environments.
A number of studies focus on improving power man-
agement in data centers. Some works seek to save energy
by adjusting workload distribution algorithms in a data cen-
ter [39], [20], while some other works aim at reducing power
consumption of individual servers [7], [37]. However, even
with these solutions, data centers are still under high power
provisioning pressure and rely on power oversubscription to
handle this pressure.
A research conducted by Fu et al. [13] demonstrates how
much power consumption and how long such consumption
lasts will trip a CB in a data center. Their study shows that the
time to trip a CB has functional relationship with the amount
of power that exceeds the rated power of the CB. The more
power consumption exceeds the rated power of CB, the less
time it takes to trip the CB. Their study provides the theoretical
support for more aggressive power oversubscription.
A study on power consumption of high performance
computation benchmarks is conducted by Kamil et al. [16].
They analyzed the power consumption patterns of different
HPC benchmarks including NAS [2], STREAM [3], and
High Performance Linpack (HPL). Their work supports our
argument that different computation workloads will lead to
considerably different power consumption patterns. Their study
also demonstrates that HPL is the benchmark whose power
consumption is the closest to that of real world computation-
intensive scientiﬁc workload.
Although many server consolidation solutions only take
resource consumption into account [19], [8], there exist pre-
vious works studying the power and energy savings brought
by server consolidation [25], [32]. While these studies focus
on the power consumption before and after VM migration,
we demonstrate that the additional power consumption during
migration can be exploited by a malicious attacker. The work
of Liu et al. [21] models the power consumption during VM
migration. They demonstrated that different VM migration
mechanisms and conﬁgurations will lead to different migration
power consumptions. Their work implies that an attacker can
impose additional workload to the to-be-migrated VMs to
increase power consumption during migration.
Some of the previous studies on web services demon-
strate that there are different ways to increase resource/power
consumption with specially crafted web requests. The work
of Wu et al. [38] observes that cache misses generate more
power consumption at a web server. A research conducted
by Crosby et al. [10] introduces the computational attack
against web servers. By sending requests with certain data
14
sequence, an attacker can force some data structure operations
to suffer the worst case algorithm complexity, therefore costing
extra computing resources and thus resulting in more power
consumption.
Wu et al. [38] introduced a concept called energy attack.
While energy attack also attempts to increase power consump-
tion of a target, it is a different concept from power attack.
The goal of energy attack is to enlarge the operational cost
of a victim (usually a web service provider) by increasing
overall energy consumption, but our power attack can trip CBs
in a data center, which can lead to more disastrous damage.
Normally an energy attack increases the power consumption of
victim moderately for a long period, which has high demand
of stealthiness. In contrast, a power attack needs to generate
signiﬁcant power spikes in a relatively short period.
XI. CONCLUSION
In this paper, we investigate the vulnerability of power
oversubscription in data centers and introduce the concept of
power attack. We explore different attack vectors in PaaS, IaaS
and SaaS environments, respectively. In PaaS, we demonstrate
that an attacker can manipulate running workloads to signif-
icantly increase power consumption. In IaaS, we propose the
concept of parasite attack and further show that VM migration
can be exploited for helping to mount a power attack. In SaaS,
we craft high power consumption requests that can trigger
cache misses and intensive ﬂoating point operations to launch
a power attack. Our experimental results show that a power
attack can easily increase power consumption of a target by
over 30% in different environments and our power attack trips
the CB of our server room. We further conduct a data center
level simulation based on real world traces. The simulation
results indicate that a power attack can bring down a PDU or
even an entire data center. Moreover, we discuss the impact of
various power management schemes upon power security of
data centers and propose effective defenses to mitigate power
attacks.
As the future work, on one hand, we will further explore
more efﬁcient and stealthy power attack vectors in different
data center environments; on the other hand, we will sys-
tematically study defense techniques, develop prototypes, and
conduct experiments to evaluate their effectiveness against
power attacks in real scenarios.
XII. ACKNOWLEDGEMENT
We would like to thank the anonymous reviewers for their
insightful feedback. This work was partially supported by ONR
grant N00014-13-1-0088 and NSF grant CNS-1143607.
REFERENCES
[1]
[2]
parallel
http://www.nas.nasa.gov/Resources/
“China national grid,” http://en.wikipedia.org/wiki/CNGrid.
“Nas
Software/npb.html,2007.
“stream,” http://www.cs.virginia.edu/stream/.
benchmarks,”
[3]
[4] F. Ahmad and T. N. Vijaykumar, “Joint optimization of idle and cooling
power in data centers while maintaining response time,” in Proceedings
of ASPLOS, 2010.
[28] P. Ranganathan, P. Leech, D. Irwin, and J. S. Chase, “Ensemble-level
power management for dense blade servers.” in Proceedings of IEEE
ISCA’06.
[29] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage, “Hey, you, get
off of my cloud: exploring information leakage in third-party compute
clouds,” in Proceedings of the ACM CCS’09, pp. 199–212.
[30] R. Shea and J. Liu, “Understanding the impact of denial of service
attacks on virtual machines,” in Proceedings of the 2012 IEEE 20th
International Workshop on Quality of Service.
[31] K. Shen, A. Shriraman, S. Dwarkadas, and X. Zhang, “Power and
energy containers for multicore servers,” in Proceedings of ACM
SIGMETRICS’12, pp. 403–404.
[32] H. Shirayanagi, “Honeyguide: A vm migration-aware network topology
for saving energy consumption in data center networks,” in Proceedings
of the 2012 IEEE Symposium on Computers and Communications, pp.
460–467.
[33] A. Verma, P. Ahuja, and A. Neogi, “pmapper: Power and migration cost
aware application placement in virtualized systems,” Middleware 2008,
pp. 243–264.
[34] A. Verma, G. Dasgupta, T. Kumar, N. Pradipta, and D. R. Kothari,
“Server workload analysis for power minimization using consolidation,”
in Proceedings of the 2009 conference on USENIX Annual technical
conference.
[35] X. Wang and M. Chen, “Cluster-level feedback power control for per-
formance optimization,” in Proceedings of the 14th IEEE International
Symposium on High-Performance Computer Architecture, 2008.
[36] X. Wang, M. Chen, C. Lefurgy, and T. W. Keller, “Ship: Scalable
hierarchical power control for large-scale data centers,” in Proceedings
of IEEE PACT’09, pp. 91–100.
[37] Y. Wang, X. Wang, M. Chen, and X. Zhu, “Power-efﬁcient response
time guarantees for virtualized enterprise servers,” in Proceedings of
IEEE RTSS’08, pp. 303–312.
[38] Z. Wu, M. Xie, and H. Wang, “Energy attack on server systems,” in
Proceedings of USENIX WOOT’11.
[39] Y. Yao, L. Huang, A. Sharma, L. Golubchik, and M. Neely, “Data
centers power reduction: A two time scale approach for delay tolerant
workloads,” in Proceedings of IEEE INFOCOM’12, pp. 1431–1439.
APPENDIX
In Amazon EC2, the physical location of a VM can be
associated with the its type, “zone”, and IP address. An
attacker can customize the VMs by specifying in which zone
the VM will be instantiated and what is the instance type so
that the VM will be located in a certain physical area. After
the VM is booted, the attacker can further infer the “location”
of the booted VMs as well as their host physical machines via
IP address and packet round time information [29]. Since the
VM will change its IP address, i.e., its physical location every
time it is rebooted, the attacker can place a VM to a target
machine or rack by keeping rebooting the VM until it reaches
the desired location. In this way, the attacker can deploy many
VMs on those physical machines that are within the same rack.
[5] S. Bapat, “The future of data centers,” http://citris-uc.org/ﬁles/
Bapatallocated/The Future Of Data Centers-1.pdf.
[6] L. Barroso and U. H¨olzle, “The datacenter as a computer: An introduc-
tion to the design of warehouse-scale machines,” Synthesis Lectures on
Computer Architecture, vol. 4, no. 1, pp. 1–108, 2009.
[7] M. Chen, X. Wang, and X. Li, “Coordinating processor and main
memory for efﬁcient server power control,” in Proceedings of the ACM
2011 international conference on Supercomputing, pp. 130–140.
[8] H. W. Choi, H. Kwak, A. Sohn, and K. Chung, “Autonomous learning
for efﬁcient resource utilization of dynamic vm migration,” in Proceed-
ings of ACM ICS ’08, pp. 185–194.
[9] G. Contreras and M. Martonosi, “Power prediction for intel xscale
processors using performance monitoring unit events,” in Proceedings
of ACM ISLPED ’05, pp. 221–226.
[10] S. A. Crosby and D. S. Wallach, “Denial of service via algorithmic
the 12th USENIX Security
complexity attacks,” in Proceedings of
Symposium, 2003, pp. 29–44.
J. Dean, “Designs, lessons and advice from building large distributed
systems,” http://goo.gl/nc9K.
[11]
[12] X. Fan, W.-D. Weber, and L. A. Barroso, “Power provisioning for a
warehouse-sized computer,” in Proceedings of ACM ISCA’ 07, pp. 13–
23.
[13] X. Fu, X. Wang, and C. Lefurgy, “How much power oversubscription
is safe and allowed in data centers,” in Proceedings of ACM ICAC ’11,
pp. 21–30.
[14] S. Gorman, “Power supply still a vexation for the nsa,” The Baltimore
Sun, 2007.
[15] A. Greenberg, J. Hamilton, D. A. Maltz, and P. Patel, “The cost of a
cloud: research problems in data center networks,” ACM SIGCOMM
Computer Communication Review, vol. 39, no. 1, pp. 68–73, 2008.
[16] S. Kamil, J. Shalf, and E. Strohmaier, “Performance and energy mod-
eling for live migration of virtual machines,” http://crd.lbl.gov/assets/
pubs presos/CDS/ATG/powereffreportxt4.pdf.
[17] C. Lefurgy, X. Wang, and M. Ware, “Server-level power control,” in
Proceedings of the IEEE ICAC’ 07.
[18] ——, “Power capping: a prelude to power
shifting,” Cluster
Computing, vol. 11, no. 2, pp. 183–195, Jun. 2008. [Online]. Available:
http://dx.doi.org/10.1007/s10586-007-0045-4
[19] X. Li, Q. He, J. Chen, K. Ye, and T. Yin, “Informed live migration
strategies of virtual machines for cluster load balancing,” in Proceedings
of
the 8th IFIP international conference on Network and parallel
computing, 2011, pp. 111–122.
[20] M. Lin, A. Wierman, L. L. Andrew, and E. Thereska, “Dynamic right-
sizing for power-proportional data centers,” in Proceedings of IEEE
INFOCOM’11, pp. 1098–1106.
[21] H. Liu, C.-Z. Xu, H. Jin, J. Gong, and X. Liao, “Performance and
energy modeling for live migration of virtual machines,” in Proceed-
ings of ACM the 20th international symposium on High performance
distributed computing 2011, pp. 171–182.
J. Markoff,
power
expected,”
data-centers-using-less-power-than-forecast-report-says.html.
than was
http://www.nytimes.com/2011/08/01/technology/
centers’
“Data
[22]
use
less
[23] D. Meisner, B. T. Gold, and T. F. Wenisch, “Powernap: eliminating
server idle power,” in ACM Sigplan Notices, vol. 44, no. 3, 2009, pp.
205–216.
[24] D. Meisner and T. F. Wenisch, “Peak power modeling for data cen-
ter servers with switched-mode power supplies,” in Proceedings of
ACM/IEEE ISLPED ’10, pp. 319–324.
[25] ——, “Dreamweaver: architectural support for deep sleep,” SIGARCH
Comput. Archit. News, vol. 40, no. 1, pp. 313–324, Mar. 2012.
[Online]. Available: http://doi.acm.org/10.1145/2189750.2151009
[26] N. Mi, G. Casale, L. Cherkasova, and E. Smirni, “Burstiness in multi-
tier applications: Symptoms, causes, and new models,” in Springer
Middleware 2008, pp. 265–286.
[27] R. Raghavendra, P. Ranganathan, V. Talwar, Z. Wang, and X. Zhu, “No
power struggles: Coordinated multi-level power management for the
data center,” in Proceedings of ACM ASPLOS 2008.
15