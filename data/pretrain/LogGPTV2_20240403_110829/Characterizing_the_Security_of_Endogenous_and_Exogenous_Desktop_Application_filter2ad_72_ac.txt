common traﬃc for a speciﬁc application would be useful.
3.5 What Is the Attack Surface that Applications Expose Through
Open Ports?
In this experiment,
instead of using the application-labelled ﬂow data, we
use conﬁguration information generated through OSQuery. The query-pack for
“listening-ports” provides information about all listening ports assigned to a
process. This is a better way of identifying listening ports than using the ﬂow
data since we have an authoritative snapshot of the ports used, and can avoid
using heuristics to determine traﬃc direction. We ﬁnd on average an application
exposes 11.1 listening ports per host, with a median of 1. A few outliers cause
this skew, these applications are listening on many diﬀerent ports: Docker (254
unique ports), dnscrypt-proxy (67), mDNSResponder (28) CiscoSparkHelper
(28), Safari (16), vmware-natd (14), Microsoft Teams Helper (11), Spotify (9)
zoom.us (4) and Dropbox (3). Docker is, by far, the application that exposes the
542
M. R. McNiece et al.
most listening ports, which in retrospect is logical. Developers can run contain-
ers on their laptop using Docker, and can conﬁgure the ports that the container
listens to on the host OS. Interestingly there are also applications that are expos-
ing more ports than the median that we did not expect to have such a network
presence, such as: BetterTouchTool (2), HP Device Monitor (3), [VisualStudio]
Code Helper (Renderer) (4). We were unable to conﬁdently attribute these con-
nections back to the domains where they originated because a lack of consistent
identiﬁers between OsQuery and NVM.
Takeaway: Applications that expose listening ports add exposed attack surface
that deserves further investigation. There have been cases of applications run-
ning webservers that they use to communicate with their web-clients that lead to
vulnerabilities [13–15]. We leave determining what applications are doing with
these listening ports for future work.
3.6 How Is Endogenous Traﬃc Represented in Browsers?
As mentioned in Subsect. 3.1, our approach for determining what traﬃc is
endogenous for an application struggles to narrow down traﬃc observed from
browsers. We suspect that this is because browsers are entirely user-triggered
applications and there are likely large similarities in browsing destinations
between users. In our dataset, we observed traﬃc for three browsers: Google
Chrome, Mozilla Firefox, and Apple Safari. Browsing behavior for users between
browsers is fairly similar as common tasks (email, social media, news) are not
functions exclusive to any one browser. Across all three browsers, there are 2,671
unique connections (domain at 2LD, port), 1,720 (64%) of those are common
across at least two browsers, and 1,335 (50%) are common across all three. Look-
ing at endogenous connections exclusive to a single browser, Chrome has 593
unique connections, Firefox has 187 connections, and Safari has 171. This mim-
ics the rough pattern of popularity of each of these browsers within our device
population, so we do not make any conclusions about one of these browsers
having a smaller set of endogenous behavior. Takeaway: Browsers have fun-
damentally diﬀerent types of traﬃc from other desktop applications, but their
traﬃc is similar to each other.
4 Related Work
Host-based anomaly detection has been a staple of security research since the
early 2000s [26] and numerous works have explored addressing anomalous activ-
ity on a host [22,40,41]. Anomaly detection has been well explored at the network
level with tools like Snort [36] and NetFlow based techniques [29,43]. Identifying
applications and operating systems through observing network traﬃc and recon-
naissance has also been well explored [25,34,42], including single packet ﬁnger-
prints of operating systems [37,38]. There are also enterprise software oﬀerings
that can identify the application generating network traﬃc and measure aspects
of ﬂows [16,20,21,31]. Researchers have also used TLS ﬁngerprints as a method
Characterizing the Security of Endogenous and Exogenous Desktop
543
of identifying software [17], provided techniques to impersonate common soft-
ware to circumvent censorship [27], and shown how parrot-based circumvention
can fail [30]. By contrast, we act as an omniscient passive observer of traﬃc and
study the connections made by applications focusing on the common connections
rather than the anomalous.
Internet-scale measurement has been conducted to look at HTTPS and TLS
implementation and weakness [24,39], building features to measure DNS [19,32],
or scraping the internet to measure the use of cryptographic libraries [35]. With
regard to work in desktop application security, in 2006 Bellissimo et al. studied
the updated mechanisms of popular desktop applications [18]. In 2012, Georgiev
et al. found that the implementation of SSL certiﬁcation validation was funda-
mentally broken in many widely used libraries [28]. In contrast, our work does
not examine TLS implementation but instead measures apparent TLS usage.
In 2017 Dormann published a blog about the consequences of insecure software
updates [23], and a year later, Microsoft was still distributing software over
HTTP [33]. To the best of our knowledge, there has not been a prior large-scale,
extensive study of the security posture of desktop applications communication
channels.
A Data Ethics
While working on this project, we followed all institutional procedures from all
aﬃliated institutions. Our IRB reviewed our proposal and datasets and deter-
mined that this was not human subjects research. All human and machine iden-
tiﬁers in our dataset have been removed and replaced with encrypted versions
that are encrypted with a key that the research team does not have access to.
All telemetry was collected through existing monitoring infrastructure that has
strict ACLs. Furthermore, all telemetry was collected from corporate managed
and owned devices where users are made aware that the devices are monitored
for security and compliance. Throughout our analysis we focus on the network
behavior of applications not individual users. Any individual user’s data could be
excluded from our dataset without impact to our ﬁndings. We made no attempt
to ﬁnd evidence of sensitive actions or non-work-related activity (video games,
streaming video, social media, etc.) The focus of our research is on the network
behavior of applications, not of the individuals using the applications.
B RFC 1918
RFC 1918 [10] describes and reserves 3 IP ranges for private use only, we used
this to label each source IP and destination IP as “private” or “public”. If an IP
is “private” then it is not on the Internet, and is instead on some internal/private
network. After labeling each ﬂow, there are four possible combinations:
– Private Source to Private Destination (Internal) - Neither end is an Internet
facing IP, communication to internal services
544
M. R. McNiece et al.
– Private Source to Public Destination (Outbound) - Destination is an Internet
facing IP, likely an outbound connection
– Public Source to Private Destination (Inbound) - Destination is not an Inter-
net facing IP, so is either a connection from a NAT device to an internal
service, or an inbound connection from a public service to a device
– Public Source to Private Destination (NAT) - Both ends have an Internet
facing IP, but one must be local device with a NAT IP though we can’t tell
which.
References
1. https://transparencyreport.google.com/https/overview
2. https://spark.apache.org/
3. https://www.cisco.com/c/en/us/td/docs/security/vpn client/anyconnect/anycon-
nect47/administration/guide/b AnyConnect Administrator Guide 4-7/nvm.html
4. https://osquery.io/
5. https://parquet.apache.org/
6. https://snort.org/downloads/ip-block-list
7. https://umbrella.cisco.com/blog/cisco-umbrella-1-million
8. https://docs.umbrella.com/investigate-api/docs/security-information-for-a-dom-
ain-1
9. https://github.com/osquery/osquery/blob/master/packs/incident-response.
conf#L211
10. https://tools.ietf.org/html/rfc1918
11. https://github.com/georg-un/kneebow
12. https://blog.jacopo.io/en/post/apple-ocsp/
13. https://nvd.nist.gov/vuln/detail/CVE-2019-13450
14. https://nvd.nist.gov/vuln/detail/CVE-2019-13449
15. https://nvd.nist.gov/vuln/detail/CVE-2019-15006
16. Anderson, B., McGrew, D.: Identifying encrypted malware traﬃc with contextual
ﬂow data. In: Proceedings of the 2016 ACM Workshop on Artiﬁcial Intelligence
and Security, AISec 2016, pp. 35–46. ACM, New York (2016)
17. Anderson, B., McGrew, D.: TLS beyond the browser: combining end host and
network data to understand application behavior. In: Proceedings of the Inter-
net Measurement Conference, IMC 2019, pp. 379–392. Association for Computing
Machinery, New York (2019)
18. Bellissimo, A., Burgess, J., Fu, K.: Secure Software Updates: Disappointments and
New Challenges. HotSec, pp. 37–43 (2006)
19. Chen, Y., Antonakakis, M., Perdisci, R., Nadji, Y., Dagon, D., Lee, W.: DNS
Noise: Measuring the pervasiveness of disposable domains in modern DNS traﬃc.
In: Proceedings - 44th Annual IEEE/IFIP International Conference on Dependable
Systems and Networks, DSN 2014, pp. 598–609 (2014)
20. Cisco Systems Inc: Cisco Security Analytics White Paper (2018). https://www.
cisco.com/c/dam/en/us/products/collateral/security/stealthwatch/white-paper-
c11-740605.pdf
21. Cisco Systems Inc: Cisco Encrypted Traﬃc Analytics - White Paper (2019).
https://www.cisco.com/c/dam/en/us/solutions/collateral/enterprise-networks/
enterprise-network-security/nb-09-encrytd-traf-anlytcs-wp-cte-en.pdf
Characterizing the Security of Endogenous and Exogenous Desktop
545
22. Denning, D.E.: An intrusion-detection model. In: 1986 IEEE Symposium on Secu-
rity and Privacy, pp. 118–118 (1986)
23. Dormann, W.: The Consequences of Insecure Software Updates (2017). https://
insights.sei.cmu.edu/cert/2017/06/the-consequences-of-insecure-software-
updates.html
24. Durumeric, Z., et al.: The Security Impact of HTTPS Interception (2017)
25. Durumeric, Z., Wustrow, E., Halderman, J.A.: ZMap: fast internet-wide scanning
and its security applications. In: 22nd USENIX Security Symposium (USENIX
Security 2013), pp. 605–620. USENIX Association, Washington, D.C., August 2013
26. Forrest, S., Hofmeyr, S., Somayaji, A., Longstaﬀ, T.: A sense of self for Unix
processes, pp. 120–128. Institute of Electrical and Electronics Engineers (IEEE),
December 2002
27. Frolov, S., Wustrow, E.: The use of TLS in censorship circumvention. In: Proceed-
ings of The Network and Distributed System Security Symposium (2019)
28. Georgiev, M., Iyengar, S., Jana, S., Anubhai, R., Boneh, D., Shmatikov, V.: The
most dangerous code in the world: validating SSL certiﬁcates in non-browser soft-
ware. In: ACM Conference on Computer and Communications Security, pp. 38–49
(2012)
29. Hofstede, R., Bartoˇs, V., Sperotto, A., Pras, A.: Towards real-time intrusion detec-
tion for NetFlow and IPFIX. In: 2013 9th International Conference on Network
and Service Management, pp. 227–234 (2013)
30. Houmansadr, A., Brubaker, C., Shmatikov, V.: The parrot is dead: observing unob-
servable network communications. In: Proceedings - IEEE Symposium on Security
and Privacy, pp. 65–79 (2013)
31. Kleopa, C., Judge, C.: Snort - OpenAppID (2015) https://www.snort.org/
documents/openappid-detection-webinar
32. Kountouras, A., et al.: Enabling network security through active DNS datasets.
In: Monrose, F., Dacier, M., Blanc, G., Garcia-Alfaro, J. (eds.) RAID 2016. LNCS,
vol. 9854, pp. 188–208. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-
45719-2 9
33. Leonhard, W.: Microsoft is distributing security patches through insecure
HTTP links — Computerworld (2018). https://www.computerworld.com/article/
3256304/microsoft-is-distributing-security-patches-through-insecure-http-links.
html
34. Lyon, G.F.: Nmap Network Scanning: The Oﬃcial Nmap Project Guide to Network
Discovery and Security Scanning. Insecure, USA (2009)
35. Nemec, M., Klinec, D., Svenda, P., Sekan, P., Matyas, V.: Measuring popularity of
cryptographic libraries in internet-wide scans, pp. 162–175 (2017)
36. Roesch, M.: Snort - lightweight intrusion detection for networks. In: Proceedings of
the 13th USENIX Conference on System Administration, LISA 1999, pp. 229–238.
USENIX Association, USA (1999)
37. Shamsi, Z., Cline, D.B.H., Loguinov, D.: Faulds: a non-parametric iterative clas-
siﬁer for internet-wide OS ﬁngerprinting. In: ACM Conference on Computer and
Communications Security, pp. 971–982 (2017)
38. Shamsi, Z., Nandwani, A., Leonard, D., Loguinov, D.: Hershel: single-Packet OS
Fingerprinting. IEEE/ACM Trans. Netw. 24(4), 2196–2209 (2016)
39. Springall, D., Durumeric, Z., Halderman, J.A.: Measuring the Security Harm of
TLS Crypto Shortcuts, pp. 33–47 (2016)
40. Wagner, D., Soto, P.: Mimicry attacks on host-based intrusion detection systems.
In: Proceedings of the 9th ACM Conference on Computer and Communications
546
M. R. McNiece et al.
Security, CCS 2002, pp. 255–264. Association for Computing Machinery, New York
(2002)
41. Yeung, D.Y., Ding, Y.: Host-based intrusion detection using dynamic and static
behavioral models. Pattern Recogn. 36(1), 229–243 (2003)
42. Zalewski, M.: P0F V3: Passive Fingerprinter (2012). http://lcamtuf.coredump.cx/
p0f3/README
43. Zhenqi, W., Xinyu, W.: NetFlow based intrusion detection system. In: Proceed-
ings - 2008 International Conference on MultiMedia and Information Technology,
MMIT 2008, pp. 825–828 (2008)