OSNs, we apply divide-and-conquer. We slice the computation of
user comparison into smaller jobs along the time dimension and use
parallelism to scale (§ 4.5). We then aggregate the results of multi-
ple smaller computations to obtain period-long user similarity.
Accuracy: The diversity of normal user behavior and the stealthi-
ness of malicious activity hinder high accurate detection. Anomaly
detection schemes inevitably incur false positives and negatives. As
a result, the goal of an automated detection system is often to re-
duce both the false positive and negative rates. In order to achieve
high accuracy, we design SynchroTrap based on our understanding
of an attacker’s economic constraints. Moreover, as the false posi-
tive and false negative rates are usually inversely related, Synchro-
Trap provides a set of tunable parameters in its design and enables
operators to tune these parameters (§ 4.6) for a desired trade-off.
Adaptability to new applications: Attack campaigns can target
distinct OSN applications. Because the properties of a user’s ac-
tions, such as the association between the user and other OSN ob-
jects, can vary in different applications, a detection scheme opti-
mized for one application may not be applicable to others. There-
fore, it is challenging to develop a generic solution that can adapt
to new applications. For example, CopyCatch [16] detects fraudu-
lent page likes (once-only actions), but cannot be used to uncover
repeated spam-photo uploads from the same IP addresses. Unlike
CopyCatch, in our design we decouple the similarity metrics (§ 4.3)
from the clustering algorithm (§ 4.4), which enables us to handle
both once-only and other generic actions. Furthermore, we rep-
resent an action with a tuple abstraction (§ 4.2), including a times-
tamp dimension and an attacker constraint dimension. This abstrac-
tion makes the system design independent of the OSN applications
that SynchroTrap protects.
4. SYSTEM DESIGN
In this section, we describe the design of our system in detail. We
categorize user actions according to OSN applications (§ 4.1) and
perform detection on a per-application basis. We deﬁne a generic
matching metric for time-stamped user actions (§ 4.2) and quan-
tify the similarity of a user pair using the fraction of their matched
actions (§ 4.3). We use a single-linkage hierarchical clustering al-
gorithm to group users based on the pairwise user similarity (§ 4.4).
In § 4.5, we parallelize the computation of user-pair comparison to
address the large-data challenge.
4.1 Partitioning activity data by applications
OSNs usually provide many features and functions in the form
of OSN applications, such as photo uploading, page like, messag-
ing, etc. Malicious accounts are not necessarily coordinated across
all types of actions allowed by the platforms. To reduce operational
cost, an attacker can focus his missions and target only partial di-
mensions of the user action space, e.g., uploading spam photos,
promoting rogue apps, etc. As a result, a scheme using holistic
comparison of user activities may miss malicious users that target
only particular OSN functions. This problem is reminiscent of the
“curse of dimensionality” in clustering high-dimensional data [29].
To mitigate the impact of irrelevant actions, we categorize a user’s
actions into subsets according to the applications they belong to,
which we call application contexts. We then detect malicious ac-
counts within each application context. For example, we separate
the photo upload and page like applications to suppress spam pho-
tos and fraudulent page likes, respectively. Next, we describe how
we cluster user actions for an OSN application.
4.2 Comparing user actions
In SynchroTrap, we abstract time-stamped user actions as tu-
ples, each of which has an explicit constraint ﬁeld that can express
both resource and mission constraints. We require exact match on
the constraint ﬁeld to capture an attacker’s constraints. From the
point of view of an OSN provider, each user action has a number
of attributes. Table 1 summarizes the main attributes used in this
paper and their deﬁnitions. An AppID can include an identiﬁer of
an application-layer network protocol (e.g., HTTP) to indicate a
ﬁne-grained application category. An AssocID can be the identi-
ﬁer of an associated OSN object (e.g., photos, pages, users, etc).
We denote our tuple abstraction of a time-stamped user action as
hU, T, Ci, where U , T , and C represent user ID, action timestamp,
and a constraint object, respectively. A constraint object can be a
combination of certain action attributes, such as a concatenation of
AssocID, source IP address, etc.
User ID
Attribute Meaning
UID
Timestamp Timestamp of the user action
AppID
AssocID
IP address
Application identiﬁer, e.g., posting and messaging
Object ID with which a user action is associated
IP address of the user client
Table 1: Attributes of a user action and their meanings.
Our tuple abstraction of user actions is expressive.
It enables
SynchroTrap to quickly adapt to a speciﬁc attack in an application,
provided that the constraint ﬁeld is properly designated. For exam-
ple, one can choose the followee identiﬁer (a type of AssocID) as
the constraint ﬁeld to defeat abusive user following on Instagram.
Based on the tuple abstraction, we deﬁne action match, denoted
by "≈". Two actions of different users match if they pertain to the
same constraint object and their timestamps fall into the same time
window of a pre-deﬁned length Tsim (e.g., 1 hour). That is, a
match of two user actions is possible only if they occur within a
matching window of Tsim.
hUi, Ti, Cii ≈ hUj , Tj, Cj i
if Ci = Cj and |Ti − Tj| ≤ Tsim
4.3 Pairwise user similarity metrics
We quantify the similarity of two users by computing the frac-
tion of their matched actions during a time period Tp (e.g., a week).
We use the Jaccard similarity, a widely-used metric that measures
the similarity of two sets [24], as the similarity metric. The Jaccard
similarity metric ranges from 0 to 1. A value close to 1 indicates
high similarity.
Per-constraint similarity. We introduce the per-constraint simi-
larity to measure the fraction of matched actions on a single con-
straint object (e.g., a single source IP address). Let Ai be the set of
actions performed by user Ui, i.e. Ai = {hU, T, Ci|U =Ui}. As we
require exact match on the constraint ﬁeld of user actions, we fur-
ther break down Ai into disjoint subsets according to the value of
the constraint ﬁeld, i.e., where Ak
i = {hU, T, Ci|U =Ui, C=Ck}.
We derive user similarity on a single constraint object using Jac-
card similarity, as shown below. When we compute the Jaccard
similarity, we apply the action matching operator "≈" (§ 4.2) to
obtain the set intersection and the set union.
Sim(Ui, Uj , Ck) =
|Ak
|Ak
i ∩ Ak
j |
i ∪ Ak
j |
Overall similarity.
In certain OSN applications, the association
of a user to a constraint object does not appear more than once.
For example, in Facebook app installation, a user can install an app
only once. In such cases, the Jaccard similarity of a user pair on
a single constraint object (i.e., an app ID) can only be either 0 or
1. To better characterize the similarity among users, we use the
overall Jaccard similarity, which accounts for user actions across
all constraint objects.
Sim(Ui, Uj) =
|Ai ∩ Aj|
|Ai ∪ Aj|
=
Pk |Ak
Pk |Ak
i ∩ Ak
j |
i ∪ Ak
j |
4.4 Scalable user clustering
We choose the single-linkage hierarchical clustering algorithm [26]
to cluster users due to its effectiveness and potential scalability. We
Edge similarity threshold
1
2
Figure 3: Transforming the single-linkage hierarchical cluster-
ing algorithm to the algorithm of connected components in two
steps. Edges represent similarity between users. A user pair
connected by a thicker edge has a higher similarity.
do not use other off-the-shelf clustering schemes because they ei-
ther rely on a special distance metric (e.g., Euclidean distance in
k-means), or are not scalable. We refer readers to [26] for a com-
plete review of the clustering techniques. In addition, we do not
seek to use graph partitioning algorithms for clustering users, be-
cause even widely-used graph partitioning tools like METIS [28]
take many hours to process a graph with only multiple millions
of nodes [40]. Instead, our objective is to transform our detection
scheme to a clustering algorithm that can scale up to large OSNs.
Single-linkage hierarchical clustering. The single-linkage hier-
archical clustering algorithm uses an agglomerative approach that
begins with each user as a different cluster, and iteratively merges
clusters with high similarity and produces larger clusters. This al-
gorithm generates a cluster-merging dendrogram that shows the
merging hierarchy of clusters and the degree of similarity on each
level. By breaking the dendrogram at a desired level, one obtains
a set of clusters in which intra-cluster user similarity exceeds a
certain threshold. A detailed description of the algorithm is doc-
umented in [26]. Because this algorithm relies on a sequential pro-
cess to construct the entire dendrogram in a bottom-up fashion, a
straightforward implementation is difﬁcult to scale.
Making the algorithm suitable for parallel implementation. The
key property of single-linkage hierarchical clustering is that the
similarity of two clusters is determined by the maximum similar-
ity among all pairs of users drawn from each different cluster. The
cluster-similarity metric merges a group of close clusters in each
iteration into a larger connected component in a user similarity
graph, where nodes are users and an undirected edge exists be-
tween a pair of users if their similarity is above a certain threshold.
Using this property we adapt the single-linkage hierarchical clus-
tering algorithm to a parallel version. Our idea is that if we set the
similarity threshold ﬁrst and ﬁlter out user pairs below that, the
desired user clusters are exactly the connected components in the
pruned user similarity graph. Therefore, we can employ an efﬁcient
graph algorithm [27] to search for connected components. Figure 3
illustrates our two-step adaptation of the single-linkage clustering
algorithm. We choose to adapt to the connected components al-
gorithm because it is highly scalable on massive graphs due to its
inherent parallelism [27].
User-pair ﬁltering function. We use a ﬁltering function to select
user pairs with action similarity above a certain degree. We intro-
duce two criteria to choose a user pair according to their similarity
at different granularities (§ 4.3).
• F1: There exists at least one constraint object, for which users
have a per-constraint similarity above a certain threshold.
• F2: Their overall similarity is above a certain threshold.
The ﬁrst ﬁltering criterion uncovers malicious user pairs that
manifest loosely synchronized behavior on a set of single constraint
User activities Daily user
comparison
Aggregation
& Clustering
t
t+1
t+2
t+3
t+4
t+5
Figure 4: SynchroTrap’s processing pipeline at Facebook. A
new aggregation job (dashed) does not incur re-execution of
daily jobs. Arrows indicate the data ﬂow.
objects (e.g., IP addresses). In some cases, malicious accounts may
even spread their actions over a number of constraint objects. We
use criterion F2 to compare user similarity for applications where a
user can carry out a certain action only once per constraint object.
4.5 Parallelizing user-pair comparison
To process continuous user-activity data stream at scale, we use
incremental processing. In particular, we divide the large compu-
tation of user-pair comparison on a bulk data set into a series of
smaller ones in the time dimension. We store the intermediate re-
sults and aggregate them over a certain time period. This process-
ing pipeline greatly reduces the size of a single job and thus its
hardware consumption, making SynchroTrap a more scalable and
manageable solution in practice.
4.5.1 Daily comparison
Figure 4 shows the data ﬂow of SynchroTrap’s processing pipeline
at Facebook. We slice the computation of user comparison and des-
ignate daily jobs to generate similar user pairs based on the user-
activity log. Because SynchroTrap detects consistently loosely syn-
chronized activities over a sustained period of time, we aggregate
daily similarity metrics and perform user clustering periodically
(e.g., weekly). As shown in Figure 4, because aggregation jobs
can reuse the results of daily jobs, a new aggregation job does not
incur re-execution of daily jobs.
We design an aggregatable data interface between daily jobs and
aggregation jobs by decomposing the period-long user similarity
(§ 4.3) over days, as shown below. Let Ak
i,t denote the set of ac-
tions on constraint object Ck that user Ui performs on day t, i.e.
Ak
i,t = {hU, T, Ci|U =Ui, C=Ck, T is within day t}. For a user
pair (Ui, Uj ) and a constraint object Ck, we generate and store the
number of their daily action matches, |Ak
j,t|, and the number
of daily total actions that each of them has carried out, i.e., |Ak
i,t|
and |Ak
i,t ∩ Ak
j,t|.
Sim(Ui, Uj, Ck) =
|Ak
|Ak
i ∩ Ak
j |
i ∪ Ak
j |
=
|Ak
i ∩ Ak
j |
j | − |Ak
j,t|
|Ak
i | + |Ak
i,t ∩ Ak
j,t| − Pt |Ak
=
Pt |Ak
i,t| + Pt |Ak
Pt |Ak
i ∩ Ak
j |
i,t ∩ Ak
j,t|
By aggregating the daily results, we derive user similarity over a
course of time. The last equality holds because user-action matches
across days are rare, as the size of a matching window we choose
is on the order of minutes or a few hours.
s
e
s
s
e
r
d
d
a
P
I
f
o
n
o
i
t
c
a
r
F
0
10
−2
10
−4
10
−6
10
−8
10
0
10
1
10
2
10
Active user population
3
10
4
10
SWi+1
SWi
2Tsim
Tsim
5
10
6
10
U1
U2
Time
Figure 5: Distribution of user population over IP addresses at
Facebook login. We depict the fraction of IP addresses with
respect to the number of active users per IP address.
4.5.2 Hourly comparison with sliding windows
Stragglers in daily jobs. A straightforward MapReduce imple-
mentation of the daily user comparison yields jobs whose comple-
tion time could be prolonged by straggler reducers. This strag-
gler issue is caused by the highly skewed distribution of user ac-
tions over constraint objects. Even on a daily basis, there exist hot
objects that are associated with an extremely large number of ac-
tions/users. Figure 5 shows the distribution of the number of login
users over IP addresses on one day at Facebook. As we can see,
while most of IP addresses are not used by many users (less than
100), the user population distribution per IP is heavy-tailed. These
few popular IP addresses used by more than 100K daily active
users can lead to straggler reducers that might run for days.
f (f > 1), the execution time can be reduced by 1
Mitigation with overlapping sliding windows. We mitigate this
issue by further partitioning users with their actions on large con-
straint objects. If the number of users in a partition is reduced by a
factor of 1
f 2 , as we