title:Shredding Your Garbage: Reducing Data Lifetime Through Secure Deallocation
author:Jim Chow and
Ben Pfaff and
Tal Garfinkel and
Mendel Rosenblum
Shredding Your Garbage: Reducing Data Lifetime
Through Secure Deallocation
Jim Chow, Ben Pfaff, Tal Garﬁnkel, Mendel Rosenblum
{jchow,blp,talg,mendel}@cs.stanford.edu
Stanford University Department of Computer Science
Abstract
Today’s operating systems, word processors, web
browsers, and other common software take no measures
to promptly remove data from memory. Consequently,
sensitive data, such as passwords, social security num-
bers, and conﬁdential documents, often remains in mem-
ory indeﬁnitely, signiﬁcantly increasing the risk of expo-
sure.
We present a strategy for reducing the lifetime of data
in memory called secure deallocation. With secure deal-
location we zero data either at deallocation or within a
short, predictable period afterward in general system al-
locators (e.g. user heap, user stack, kernel heap). This
substantially reduces data lifetime with minimal imple-
mentation effort, negligible overhead, and without mod-
ifying existing applications.
We demonstrate that secure deallocation generally
clears data immediately after its last use, and that with-
out such measures, data can remain in memory for days
or weeks, even persisting across reboots. We further
show that secure deallocation promptly eliminates sen-
sitive data in a variety of important real world applica-
tions.
1 Introduction
Clearing sensitive data, such as cryptographic keys,
promptly after use is a widely accepted practice for de-
veloping secure software [23, 22]. Unfortunately, this
practice is largely unknown in commodity applications
such as word processors, web browsers, and web servers
that handle most of the world’s sensitive data, e.g. pass-
words, conﬁdential documents.
Consequently, sensitive data is often scattered widely
through user and kernel memory and left there for indef-
inite periods [5]. This makes systems needlessly fragile,
increasing the risk of exposing sensitive data when a sys-
tem is compromised, or of data being accidentally leaked
due to programmer error [1] or unexpected feature inter-
actions (e.g. core dumps [15, 16, 14, 13], logging [5]).
We advocate a solution to this based on the observation
that data’s last use is usually soon before its deallocation.
Thus, we can use deallocation as a heuristic for when to
automatically zero data.
By zeroing data either at deallocation or within a short
predictable period afterward in system allocators (heap,
stack, kernel allocators, etc.), we can provide signiﬁ-
cantly shorter and more predictable data lifetime seman-
tics, without modifying existing applications. We refer
to this automatic approach to zeroing as secure dealloca-
tion.
We deﬁne the concept of a data life cycle to provide a
conceptual framework for understanding secure deallo-
cation. Using this framework, we characterize the effec-
tiveness of secure deallocation in a variety of workloads.
We evaluated secure deallocation by modifying all ma-
jor allocation systems of a Linux system, from compiler
stack, to malloc-controlled heap, to dynamic allocation
in the kernel, to support secure deallocation. We then
measured the effectiveness and performance overheads
of this approach through the use of whole-system sim-
ulation, application-level dynamic instrumentation, and
benchmarks.
Studying data lifetime across a range of server and in-
teractive workloads (e.g. Mozilla, Thunderbird, Apache
and sshd), we found that with careful design and imple-
mentation, secure deallocation can be accomplished with
minimal overhead (roughly 1% for most workloads).
We further show that secure deallocation typically re-
duces data lifetime to within 1.35 times the minimum
possible data lifetime (usually less than a second).
In
contrast, waiting for data to be overwritten commonly
produces a data lifetime 10 to 100 times the minimum
and can even stretch to days or weeks. We also provide
an in-depth analysis demonstrating the effectiveness of
this approach for removing sensitive data across the en-
tire software stack for Apache and Emacs.
USENIX Association
14th USENIX Security Symposium
331
We argue that these results provide a compelling case
for secure deallocation, demonstrating that it can provide
a measurable improvement in system security with neg-
ligible overhead, without requiring program source code
to be modiﬁed or even recompiled.
Our discussion proceeds as follows. In the next sec-
tion we present the motivation for this work. In section 3
we present our data lifetime metric and empirical results
on how long data can persist. In section 4 we present the
design principles behind secure deallocation while sec-
tions 5, 6, and 7 present our analysis of effectiveness and
performance overheads of secure deallocation.
In sec-
tions 8 and 9 we discuss future and related work. Sec-
tion 10 offers our conclusions.
2 Motivation
In this section we discuss how sensitive data gets ex-
posed, how today’s systems fail to take measures to re-
duce the presence of long-lived sensitive data, and why
secure deallocation provides an attractive approach to re-
ducing the amount of long-lived data in memory.
2.1 The Threat Of Data Exposure
The simplest way to gain access to sensitive data is by
directly compromising a system. A remote attacker may
scan through memory, the ﬁle system or swap parti-
tion, etc. to recover sensitive data. An attacker with
physical access may similarly exploit normal software
interfaces [7], or if sufﬁciently determined, may resort
to dedicated hardware devices that can recover data di-
rectly from device memory. In the case of magnetic stor-
age, data may even be recoverable long after it has been
deleted from the operating system’s perspective [9, 11].
Software bugs that directly leak the contents of mem-
ory are common. One recent study of security bugs in
Linux and OpenBSD discovered 35 bugs that can be used
by unprivileged applications to read sensitive data from
kernel memory [6]. Recent JavaScript bugs in Mozilla
and Firefox can leak an arbitrary amount of heap data to a
malicious website [21]. Many similar bugs undoubtedly
exist, but they are discovered and eradicated slowly be-
cause they are viewed as less pressing than other classes
of bugs (e.g. buffer overﬂows).
Data can be accidentally leaked through unintended
feature interactions. For example, core dumps can leak
sensitive data to a lower privilege level and in some
cases even to a remote attacker. In Solaris, ftpd would
dump core ﬁles to a directory accessible via anonymous
FTP, leaking passwords left in memory [15]. Simi-
lar problems have been reported in other FTP and mail
servers [16, 14, 13]. Systems such as “Dr. Watson” in
Windows may even ship sensitive application data in
core ﬁles to a remote vendor. Logs, session histories,
and suspend/resume and checkpointing mechanisms ex-
hibit similar problems [7].
Leaks can also be caused by accidental data reuse.
Uncleared pages might be reused in a different protec-
tion domain, leaking data between processes or virtual
machines [12]. At one time, multiple platforms leaked
data from uncleared buffers into network packets [1].
The Linux kernel implementation of the ext2 ﬁle system,
through versions 2.4.29 and 2.6.11.5, leaked up to ap-
proximately 4 kB of arbitrary kernel data to disk every
time a new directory was created [2].
If data leaks to disk, by paging or one of the mech-
anisms mentioned above, it can remain there for long
periods of time, greatly increasing the risk of exposure.
Even data that has been overwritten can be recovered [9].
Leaks to network attached storage run the risk of inad-
vertently transmitting sensitive data over an unencrypted
channel.
As our discussion illustrates, data can be exposed
through many avenues. Clearly, reducing these avenues
e.g. by ﬁxing leaks and hardening systems, is an im-
portant goal. However, we must assume in practice that
systems will have leaks, and will be compromised. Thus,
it behooves us to reduce or eliminate the amount of sen-
sitive data exposure that occurs when this happens by
minimizing the amount of sensitive data in a system at
any given time.
2.2 What’s Wrong with Current Systems
Unfortunately, most applications take no steps to mini-
mize the amount of sensitive data in memory.
Common applications that handle most sensitive data
were never designed with sensitive data in mind. Ex-
amples abound, from personal data in web clients and
servers, to medical and ﬁnancial data in word proces-
sors and databases. Often even programs handling data
known to be sensitive take no measures to limit the life-
time of this data, e.g. password handling in the Windows
login program [5].
Applications are not the only culprits here. Operat-
ing systems, libraries and language runtimes are equally
culpable. For example, in recent work we traced a pass-
word typed into a web form on its journey through a sys-
tem. We discovered copies in a variety of kernel, window
manager, and application buffers, and literally dozens of
copies in the user heap. Many of these copies were long
lived and erased only as memory was incidentally reused
much later [5].
Consequently, even when programmers make a best-
effort attempt to minimize data lifetime, their efforts are
often ﬂawed or incomplete as the fate of memory is of-
ten out of their control. A process has no control over
332
14th USENIX Security Symposium
USENIX Association
malloc
write
read
First allocation
write
read
free
Second allocation
malloc
write
time
ideal
secure deallocation
natural
Figure 1: A time line showing the relationship of different memory events for a particular memory location. The span from ﬁrst
write to last read is the ideal lifetime. The data must exist in the system at least this long. The span from ﬁrst write to deallocation
is the secure deallocation lifetime. The span from ﬁrst write to the ﬁrst write of the next allocation is the natural lifetime. Because
programs often rely on reallocation and overwrite to eliminate sensitive data, the natural lifetime is the expected data lifetime in
systems without secure deallocation.
kernel buffers, window manager buffers, and even over
application memory in the event that a program crashes.
time
3 Characterizing Data Lifetime
We begin this section with a conceptual framework for
understanding secure deallocation and its role in mini-
mizing data lifetime. We then present an experimental
results quantifying how long data persists in real systems.
3.1 Data Life Cycle
The data life cycle (Figure 1) is a time line of interesting
events pertaining to a single location in memory:
Ideal Lifetime is the period of time that data is in use,
from the ﬁrst write after allocation to the last read
before deallocation. Prior to the ﬁrst write, the
data’s content is indeterminate, and after the last
read the data is “dead,” in the sense that subsequent
writes cannot affect program execution (at least for
normal process memory). Thus, we cannot reduce
data lifetime below the ideal lifetime without re-
structuring the code that uses it.
Natural Lifetime is the window of time where attack-
ers can retrieve useful information from an alloca-
tion, even after it has been freed (assuming no se-
cure deallocation). The natural lifetime spans from
the ﬁrst write after allocation to the ﬁrst write of a
later allocation, i.e. the ﬁrst overwrite. This is the
baseline data lifetime seen in today’s systems.
Secure Deallocation Lifetime attempts to improve on
the natural lifetime by zeroing at time of dealloca-
tion. The secure deallocation lifetime spans from
the ﬁrst write after allocation until its deallocation
(and zeroing). The secure deallocation lifetime falls
between the natural and ideal lifetimes.
1
2
3
Writes to Allocation 1
Writes to Allocation 3
Writes to Allocation 2
Figure 2: Incomplete overwrites, or holes, lead to the accumu-
lation of data from previous allocations in current ones. This
time line shows how a given block of memory gradually accu-
mulates data from three different allocations.
Deﬁning data lifetime in this manner provides a frame-
work for reasoning about the effectiveness of zeroing
policies. The degree to which the secure deallocation
lifetime matches the ideal lifetime gives us a metric
for understanding how well secure deallocation approxi-
mates an optimal policy.
Reallocation and Holes When memory is reallocated
and used for a different purpose, it is not uncommon for
the previous contents of the memory to be incompletely
overwritten, allowing some data from the previous allo-
cation to survive. We refer to the sections of surviving
data as holes. Holes may arise from unused variables
or ﬁelds, compiler-added padding for stack frame align-
ment or in structs, or unused portions of large buffers.
For example, it is common for user-level ﬁle name
handling code to allocate PATH MAX (at least 256) byte
buffers even though they aren’t completely used in most
situations, and Linux kernel code often allocates an en-
USENIX Association
14th USENIX Security Symposium
333
tire 4,096-byte page for a ﬁle name. The unused portion
of the buffer is a hole. This is important for data lifetime
because any data from a previous allocation that is in the
hole is not overwritten. Figure 2 illustrates the accumu-
lation of data that can result from these holes.
It might seem that secure deallocation is a superﬂuous
overhead since the job of overwriting sensitive data can
simply be handled when the memory is reused. However,
in some programs, holes account for the vast majority of
all allocated data. Thus, simply waiting for reallocation
and overwrite is an unreliable and generally poor way to
ensure limited data lifetime. The next section shows an
example of this.
)
B
M
(
g
n
i
n
i
a
m
e
R
s
p
m
a
t
S
4
3
2
1
0
Linux Desktop
Windows Desktop
Linux Server
0
7
Time (Days)
14
3.2 Long-Term Data Lifetime
On today’s systems, we cannot predict how long data will
persist. Most data is erased quickly, but our experiments
described here show that a signiﬁcant amount of data
may remain in a system for weeks with common work-
loads. Thus, we cannot depend on normal system activi-
ties to place any upper bound on the lifetime of sensitive
data. Furthermore, we found that rebooting a computer,
even by powering it off and back on, does not necessarily
clear its memory.
We wrote Windows and Linux versions of software de-
signed to measure long-term data lifetime and installed
it on several systems we and our colleagues use for ev-
eryday work. At installation time, the Linux version
allocates 64 MB of memory and ﬁlls it with 20-byte
“stamps,” each of which contains a magic number, a se-
rial number, and a checksum. Then, it returns the mem-
ory to the system and terminates. A similar program un-
der Windows was ineffective because Windows zeroes
freed process pages during idle time. Instead, the Win-
dows version opens a TCP socket on the localhost inter-
face and sends a single 4 MB buffer ﬁlled with stamps
from one process to another. Windows then copies the
buffer into dynamically allocated kernel memory that is
not zeroed at a predictable time. Both versions scan all
of physical memory once a day and count the remaining
valid stamps.
Figure 3 displays results for three machines actively
used by us and our colleagues. The machines were
Linux and Windows desktops with 1 GB RAM each and
a Linux server with 256 MB RAM. Immediately after
the ﬁll program terminated, 2 to 4 MB of stamps could
be found in physical memory. After 14 days, between
23 KB and 3 MB of the stamps could still be found. If
these stamps were instead sensitive data, this could pose
a serious information leak.
In the best case, the Linux server, only 23 KB of
stamps remained after 14 days. We expected that these
remaining stamps would disappear quickly, but in fact,
Figure 3: Lifetime of 20-byte “stamps” written to memory by
a test program run on several machines used daily. This shows
that data can often persist in memory for days or weeks under
common workloads. Despite appearances, the Linux server did
not drop quickly to 0 KB: at 14 days, it retained about 23 KB;
at 28 days, about 7 KB.
after an additional 14 days, about 7 KB of stamps were
still left. A closer look found most data retained over the
long term to lie in holes in pages owned by the Linux
slab allocator, which divides pages into smaller blocks
of equal size for piecemeal use. Most block sizes do
not ﬁt evenly into the page size, so leftover space (up
to hundreds of bytes worth) follows the ﬁnal block in a
slab, and some blocks also contain data members that are