country of residence. 
Definitions: In the questions, ‚Äòrecent‚Äô was defined as the pre-
vious two years, and ‚Äòsecurity champion‚Äô to be a non-expert 
who takes a particular interest in security [8]. We asked de-
velopers with more than one app to provide answers for the 
most frequently updated one. 
Secure Development Practices: The questions about secure de-
velopment practices asked specifically about five of the most 
frequently-used assurance techniques [45,51], as follows: 
Threat  
Working as a team to identify actors and po-
Assessment 
tential threats; following this up with risk as-
sessment and mitigation decisions. 
Keeping  components  up-to-date  using  com-
ponent  security  analysis  tools  to  the  tool-
chain. 
Using code analysis tools to identify certain 
categories of security vulnerability. 
Configura-
tion Review 
Automated 
Static  
Analysis 
Code  
Review 
Penetration  
Testing 
Having  other  programmers  or  security  ex-
perts review code for security problems. 
Having  external  specialist  security  testers 
identify flaws. 
Question Wording: All the questions about security processes 
were worded as questions of fact, rather than of future inten-
tions as in some security surveys [16], to reduce the impact 
of desirability biases. 
Omissions: We considered asking about code analysis tools, 
since these are of particular interest to researchers. However, 
static analysis is only one of the five assurance techniques 
considered, and investigating all the techniques would have 
made the questionnaire unacceptably long without contrib-
uting to answers for the research questions.  
3.2. Survey Pre-Testing 
After developing an initial questionnaire, we conducted a set 
of  pre-tests  to  glean  insights  into  how  survey  respondents 
might  interpret  and  answer  questions,  and  how  long  they 
might take to complete the survey, as follows. 
Expert Review: After developing and revising a first version 
of the survey questionnaire, we asked an experienced usable 
security and privacy researcher with survey expertise, who is 
not part of the research team, to review our survey question-
naire and evaluate question wording, ordering, and bias. Ex-
pert reviewing is a method that supports identifying questions 
that require clarification and uncovering problems with ques-
tion ordering or potential biases [36]. Following the expert 
review, we improved the wording of several questions, and 
changed the survey software configuration to randomize the 
order of answers and questions wherever this was possible. 
Face-to-face Testing: To test our survey questions under real-
istic conditions, we then identified four local Android devel-
opers who were not previously involved in the research pro-
ject, and asked each to complete the survey while discussing 
it with a researcher. As a result, we modified the wording of 
two questions and added one. We also noted that responses 
from those who had produced only simple apps were not in-
teresting from a security viewpoint, and accordingly modi-
fied our criteria for invitations to only invite developers of 
‚Äòsuccessful‚Äô and ‚Äòmaintained‚Äô apps: ones that had received 
more than 100 downloads and at least one update. 
Pilot Survey: To further test the questionnaire, we ran a set of 
pilot surveys with Android developers drawn from the same 
invitation list as the main survey (Section 3.4), inviting 5000 
and  gaining  30  completed  entries.  Participants  of  the  pilot 
were excluded from the full survey. 
We used the results to check that the number of drop-outs 
during the survey was acceptable; it was, since of those who 
completed the first page of questions, only 21% dropped out 
later in the survey. In the pilot questionnaire we used a text 
field for developers to answer what changes they had made 
as a result of GDPR; we coded the pilot responses, and pro-
vided the most frequent answers as ‚Äòtick boxes‚Äô in the final 
survey. 
292    29th USENIX Security Symposium
USENIX Association
The  results  also  helped  focus  and  plan  our  analysis  of  the 
data.  
Specifically, we identified the following additional research 
questions to help scope the problem of supporting develop-
ers: 
RQ3 What proportion of Android developers have access to 
security experts, and  
RQ4 To what extent do Android developers actually use as-
surance techniques? 
3.3. Calculation of Required Sample Size 
We  used  Fowler‚Äôs  guidance  [21],  identifying  the  smallest 
subgroups for which we wanted data, using the pilot data to 
estimate the proportion of these, and making the sample size 
large enough to get significant data from these groups. The 
key subgroups were those developers working with security 
professionals, and those using assurance techniques; and we 
chose to get between 50 and 100 in each group to give typical 
sampling errors on data for each subgroup of between 4% and 
15%. Based on the pilot data, therefore, we calculated a target 
sample size of 310, requiring us to send 55,000 invitations. 
3.4. Recruitment 
We  invited  only  registered  Google  Play  developers.  From 
January to February 2019 we crawled the details‚Äô pages of 
3,608,673 (2,087,829 free and 1,520,844 paid) Android ap-
plications from those published in Google Play. For all apps, 
we stored their last update time, name, developer data and 
download counts. 
Overall, we identified 312,369 developer accounts that match 
the 100+ downloads and update requirements in Google Play. 
The number of apps published by a single developer account 
in that sample ranges from 1 to 3,302 with a median of 2. 
From these 312,369 developer accounts, we selected a ran-
dom sample of 55,000, and sent a single invitation email to 
each to ask them kindly to support our research. Of the in-
vited 55,000 participants, 605 started and 345 completed the 
survey. Ten of the invited developers reached out to us via 
email. None complained about being contacted; three asked 
to be removed from the mailing list; the remainder provided 
various reasons for not completing the survey, including two 
who noted the security questions and stated that their apps 
had  no  security  aspects.  240  took  the  opportunity  to  leave 
their email address in the survey questionnaire for us to send 
them the results of this work. 
3.5. Filtering Invalid Results 
In  psychological  surveys,  a  common  stratagem  is  to  ask  a 
question twice, once negated. One can then filter out mean-
ingless  responses  (or  use  them  to  calculate  a  ‚Äúself-con-
sistency‚Äù score for the survey). Since our survey was asking 
facts rather than personality, we concluded that this would be 
contrived and irritating to the respondents. Instead we looked 
Expert, Champion 
in Team?
0 no, 1 champion, 2 
0 none, 1 champion, 
expert, 3 both
2 expert, 3 both
Expertise Support 
Score
Importance of 
Security & Privacy
Coded: 0 not at all, 
to 4 extremely 
0
Developer 
Security 
Knowledgeability
+
Requirements Score
Coded: 0 not at all, 
to 4 extremely 
Developer 
Knowledge Score
Each Assurance 
Technique use
Coded: 0 none ‚Ä¶ 
to 4 every build
Reported App 
Update Frequency
Reported %age 
Security Updates
+
Assurance Technique 
Score
Log (updateFreq * 
proportionSecurity)
Security Update 
Frequency Score
Figure 2: Survey Security Scores 
at response times, experimented to find a minimum time that 
a participant might be expected to take to complete the sur-
vey, and filtered out the few (10) surveys that had taken less 
than that minimum time to complete.  
3.6. Survey Statistical Analysis Plan 
This paper uses four forms of statistical analysis: 
1.  Population analysis, to explore how well our sample cor-
responds to the larger population; 
2.  Graphical analysis, to show the nature of the data; 
3.  Confidence limits for proportions in the wider population 
based on proportions in the sample; and 
4.  Correlation  analysis,  to  identify  relationships  between 
different data items.  
We defined the statistics scores and outline analysis methods 
before  collecting  the  main  survey  data,  as  required  for  re-
search  best  practice  [11,12].  For  analysis,  we  used  Python 
statistical packages, including Pandas, Statsmodels, and Sea-
born, in Jupyter Notebooks [25]. 
Linear Analysis for RQ1: To address RQ1, we defined scores 
based on each respondent‚Äôs survey answers: some scores cap-
tured the ‚Äúneed for security and privacy‚Äù (the independent, 
‚Äòinput‚Äô, variables); others the ‚Äúsecurity-enhancing activities 
and interactions in the development team‚Äù (the dependent, 
‚Äòoutput‚Äô, variables).  
Figure 2 shows the processing we did to create these scores. 
The aim in each case was to create an ordinal score that ap-
proximated to linear across the range of raw data, so a higher 
score corresponds to more security (or more drivers towards 
security) and each increment represents a similar semantic in-
crease.  As shown, the Requirements Score reflects the secu-
rity need as the arithmetic sum of the three Likert-style re-
sponses encoded as integers; similarly, to explore the why, 
there  are  Developer  Knowledge  and  Expertise  Support 
USENIX Association
29th USENIX Security Symposium    293
scores.  We  estimated  a  Security  Update  Frequency  as  the 
product of the answers to two questions; this had an exponen-
tial (Poisson) distribution, so to make it linear [3] we used a 
transformation: log(ùë•&+1)  to  create  the  Security  Update 
Frequency Score. Appendix C provides more details. 
The calculation of the Expertise Support Score is based on an 
assumption that direct expert involvement is more effective 
than ‚Äòsecurity champions‚Äô; the Requirements Score assumes 
that, for example, occasionally using two techniques is as ef-
fective as regularly using one; and the Assurance Technique 
Score assumes that, say, considering four techniques is as ef-
fective as consistently using one. Though reasonable as an 
approach, none of these scores are linear or even provably 
ordinal [44]; we anticipated that inconsistencies in the scor-
ing would add to the statistical variance but not obscure over-
all trends. See Section 5.5 for a post-hoc justification. 
In statistics, the usual relationship to look for is a linear one. 
In line with previous research in the field [16] we used the 
Pearson  Correlation  Coefficient  (‚ÄòPearson  R‚Äô)  calculation 
[14] to establish whether pairs of values had a significant lin-
ear relationship; this test is acceptable for Likert-style data 
[24,31].  
Given that the scores were not provably linear, we also inves-
tigated  a  more  sophisticated  modelling  technique,  creating 
Decision Tree models [41] for pairs of scores and using F-
Tests [13] to compare each with the simpler Pearson R model. 
In  this  analysis  we  treated  the  Security  Update  Frequency 
score as a dependent variable (output); and the Requirements, 
Expertise Support, and Developer Knowledge scores as inde-
pendent variables (inputs)4. The use of Assurance Techniques 
is likely to be affected by the latter three variables but may 
itself in turn affect the Security Update Frequency and other 
security outcomes; in the analysis, therefore, we treated the 
Assurance Technique score both as an independent and as a 
dependent variable.  
Since the analysis constituted multiple tests on the same data, 
we  applied  the  Bonferroni  correction  [40],  reducing  the 
threshold  for  ‚Äòsignificance‚Äô  accordingly  to (5%)/5=1%. 
To validate the preconditions for the Pearson Correlation Co-
efficient test [14], we then constructed x-y plots of all the 
pairs of variables that showed significant correlation. 
4. Application Analysis Methodology 
In the second phase of the project, we downloaded and ana-
lyzed  the  apps  corresponding  to  the  survey  responses.  For 
analysis, we used a selection of state-of-the-art of vulnerabil-
ity scanners. Each one focuses on a different problem cate-
gory and produces a relatively low number of false positives. 
We chose mature tools that are openly accessible to Android 
developers.  
4.1. Description of Analysis Tools 
The  tools  covered  three  key  areas:  SSL  Security,  Crypto-
graphic API Misuse, and Privacy Leaks. We selected these 
areas based on previous work and because these cover a rep-
resentative range from the possible security and privacy vul-
nerabilities faced by application developers [34].  
SSL Security: A key concern in the secure treatment of infor-
mation  is  the  correct  use  of  secure  transport  mechanisms 
(SSL, TLS) when connecting to remote systems. To capture 
this  aspect,  we  used  two  techniques.  First,  we  used  Mal-
loDroid [20] to inspect the correct use of certificate validation 
in the apps code. Second, we extracted any HTTPS URLs 
from the constant pools of the classes contained in the app 
using the OPAL framework [17] and checked the correspond-
ing  server  configurations  and  certificates  using  the  com-
mand-line tools curl and openssl.  
Cryptographic  API  Misuse:  Many  apps  use  cryptographic 
measures  to  improve  data  security  and  privacy,  and  a  key 
concern in the secure treatment of information is the handling 
of  cryptographic  primitives  (e.g.,  for  persistence).  We  run 
CogniCrypt [26]  to  capture  this  aspect.  CogniCrypt  uses 
static inter-procedural static program analysis to detect mis-
uses of the Java Cryptography API. The detected problems 
range from improper configuration of algorithms (e.g., use of 
AES with ECB) to incorrect order of calls to the API. As it is 
formulated as a static program analysis, CogniCrypt makes 
conservative assumptions (over-approximations) on the con-
trol flow of the program, which may produce false positive 
reports. 
Privacy Leaks: To find possibly harmful data flow that can 
lead to privacy leaks, we used FlowDroid [4]. This tool is de-
signed to find information flow in Android apps between de-
fined information sources and information sinks. For exam-
ple, the location APIs are considered as sources of private in-
formation,  and  the  text  message  sending  APIs  as  sinks. 
FlowDroid uses static inter-procedural data flow analysis to 
find  evidence  of  directed  information  flow  between  these 
methods. We configured the tool with the default sources and 
sink for Android provided by the authors, which had been 
constructed by manual inspection of common vulnerabilities 
in Android apps. FlowDroid is not able to determine if the 
found information flow is to be considered an actual leak as 
it might also be intended to use the information in the partic-
ular context (e.g. for location-based services). 
Practical Approach: We downloaded the application binaries 
for at least one application by each of the survey respondents, 
4Pearson‚Äôs R does not distinguish dependent and independent variables, so this 
affects only our choice of scores to correlate with each other. 
294    29th USENIX Security Symposium
USENIX Association
CogniCrypt Issue 
Count
FlowDroid Issue 
Count
MalloDroid Issue 
Count
Server SSL Issue 
Count
- Log (count + 1)
Cryptographic API 
Misuse Score
- Log (count + 1)
Privacy Leak Score
+
- Log (total + 1)
SSL Security Score
Figure 3: App Analysis Security Scores 
wherever possible; we ran the full set of scanning tools on 
each, and counted the issues (reports of possible vulnerabili-
ties) generated. Appendix A lists the versions of the tools we 
used. 