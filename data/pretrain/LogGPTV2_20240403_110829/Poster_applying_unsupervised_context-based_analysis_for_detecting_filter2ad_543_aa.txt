title:Poster: applying unsupervised context-based analysis for detecting
unauthorized data disclosure
author:Ma'ayan Gafny and
Asaf Shabtai and
Lior Rokach and
Yuval Elovici
POSTER: Applying Unsupervised Context-Based Analysis 
for Detecting Unauthorized Data Disclosure 
Ma'ayan Gafny 
Asaf Shabtai 
Department of Information Systems Engineering and, 
Deutsche Telekom Laboratories at Ben-Gurion University 
Ben-Gurion University, Beer-Sheva, Israel 
Lior Rokach 
Yuval Elovici
{gafnym, shabtaia, rokach, elovici}@bgu.ac.il 
a 
encapsulates 
tree-like  model 
ABSTRACT 
In  this  paper,  we  propose  a  new  unsupervised  approach  for 
identifying  suspicious  access  to  sensitive  relational  data.  In  the 
proposed  method, 
the 
characteristics  of  the  result-set  (i.e.,  data)  that  the user normally 
access within each possible context. During the detection phase, 
result-sets  are  examined  against  the  induced  model  and  a 
similarity score is derived. 
Categories and Subject Descriptors 
[Computer-Communication  Networks]:  General  – 
C.2.0 
security and protection; H 2.0 [Database Management]: General 
– Security, integrity, and protection. 
General Terms 
Security. 
Keywords 
Data  Leakage,  Data  misuse,  Information  leakage,  Insider  threat, 
Unsupervised learning, One class decision tree. 
1.  INTRODUCTION 
Protecting  sensitive  data  (e.g.,  customer  records)  from 
unauthorized disclosure is a major concern of every organization. 
Since the organization's employees and its business partners need 
access to sensitive data in order to perform their daily work, the 
obstinacy of preventing data misuse is intensified. Therefore, the 
goal of this research is to identify suspicious access to database by 
insiders. 
this  paper,  we  propose  a  new  method  for  detecting 
In 
unauthorized data disclosure by an insider. Our assumption is that 
users interact with a system using a client application (e.g., Web 
browser)  and  can  submit  requests  (for  data)  in  order  to perform 
various tasks. Requests are submitted to an application server that 
interacts with a database in order to retrieve the required data and 
to send the result-sets to the user. Each user accesses the system 
within  a  specific  role  (e.g.,  a  manager)  and  is  assigned  a  set  of 
permissions  to  allow  him/her  to  perform  tasks.  This,  however, 
creates  a  problem  since  a  user  may  exploit  his/her  legitimate 
access rights in order to leak data or to take actions that are not in 
line  with  the  organization’s  goals.  Therefore,  the  goal  is  to 
identify  insiders'  access  to  database  records  that  may  eventually 
lead to data leakage or data misuse.  
Copyright is held by the author/owner(s). 
CCS'11, October 17-21, 2011, Chicago, Illinois, USA. 
ACM 978-1-4503-0948-6/11/10.  
Previous work addressed this problem mainly by profiling normal 
user behavior and alerting whenever a user's action deviates from 
these  profiles.  A  user  profile  can  be  generated  according  to  a 
syntax-centric  approach  (based  on  the  structure  of  the  SQL 
queries  submitted  by  the  users  [1])  or  data-centric  approach 
(based  on  the  data  that  is  retrieved  following  the  user's  request 
[2]).  In  this  research,  we  propose  a  new  unsupervised  approach 
for  identifying  suspicious  access  to  sensitive  tabular  data.  The 
proposed method uses a tree-like detection model in which each 
leaf holds a set of rules. The rules, that define what data may be 
viewed within the context the leaf is associated with, are extracted 
using frequent item-sets. The training set, used for generating the 
detection  model,  is  composed  of  result  sets  and  the  context  in 
which they were retrieved. The requests in the training set do not 
need  to  be  labeled  (we  assume  that  most  of  the  log  records  are 
legitimate), and therefore the learning is unsupervised. During the 
detection phase, the appropriate set of rules is obtained according 
to  the  context  of  the  request.  A  record  in  the  result  set  that 
matches at least one of the rules is considered to be normal. The 
result set's score is the proportion of records that were marked as 
normal. If the result-set achieves a similarity score of more than a 
predefined threshold, the action is considered to be legitimate. By 
analyzing both the context of the request as well as the data that 
the  user  is  exposed  to  (i.e.,  the  result-set),  the  method  enhances 
the  accuracy  of  the  detection  and  better  distinguishes  between a 
normal  and  abnormal  request.  This  is  important  since  the  same 
request  may  be  legitimate  if  performed  within  one  context  but 
abnormal within another. 
2.  INDUCING THE DETECTION MODEL 
The  detection  model  is  a  one-class  clustering  tree  in which 
each  leaf  in  the  tree  represents  a  cluster  of  records  that  can  be 
accessed  legitimately  within  the  specific  context (Figure 1). The 
characteristics of the cluster are represented by a set of rules (e.g., 
frequent item-sets). Therefore, inducing the detection model is a 
two-step  process:  (1)  Constructing  the  detection  model;  (2) 
Generating the leaf rule sets. 
2.1  Defining the Splitting Criterion 
The construction of the decision tree is an iterative process. 
In each step, a context attribute is selected to be the next splitting 
attribute  and  the  node  dataset  is  split  into  smaller  datasets 
according  to  the  values  of  the  splitting  attribute.  Similarly  to 
existing measures (e.g., entropy), we define a measure that ranks 
the  context  attributes  according  to  their  ability  to  distinguish 
between the subsets of each of the possible values of the attribute. 
In  order  to  choose  the  next  attribute  for  split,  we  calculate  the 
Jaccard  similarity  coefficient  [3]  for  each  possible  split  (i.e., 
765intersection between complete records, divided by the union size). 
If the examined attribute has more than two possible values, each 
possible value is examined against the union of all other subsets. 
The  final  score  for  the  attribute  is  calculated  by  the  weighted 
average of all the calculated outcomes. The weight of each score 
is determined by the proportion between the size of the subset and 
the size of the record-set before the current split. We offer doing 
this  as  opposed  to  examining  each  possible  pair  of  subsets 
because we expect that the second will yield very low similarity 
scores and therefore will be less accurate. 
The  process  is  recurred  until  one  of  two  possible  stopping 
conditions  is  met:  (1)  no  more  rules  can  be  generated  with  the 
minimal support required; or (2) the current dataset size is smaller 
than  a  predefined  threshold  t.  This  threshold  is  defined  by  a 
proportion  of  the  original  dataset  size,  and  is  designated  for 
avoiding over-fitting. The output of this process is a set of rules 
that best represent the data set matching the specific leaf. 
Figure. 1. The proposed one class detection model. 
2.2  Representing the Result-Set as a Logical 
Expression 
Once the tree model is induced, each leaf contains a subset of 
records that are normally retrieved within the specific context that 
is defined by the path that starts from the root node and ends are 
the leaf node. At this stage, each subset of records is represented 
as a set of rules by finding frequent item-sets [4] that best describe 
the leaf dataset. We will refer to these frequent item-sets as rules. 
The  rules  are  derived  from  the  sensitive  attributes  and  context 
attributes that were not chosen as a splitting attribute during the 
construction  of  the  tree.  In  the  detection  phase,  a  record  in  the 
result  set  that  matches  at  least  one  of  the  rules  is  considered 
normal.  Otherwise,  it  is  marked  as  abnormal.  For  example, 
according to the  highlighted leaf in Figure 1, transactions which 
are performed at Berlin in the evening, usually retrieve private or 
business customer records from Berlin. 
A  frequent  item-set  is  a  set  of  items  that  appears  in  the  dataset 
more  than  a  predefined  number  of  times.  In  order  to  derive  the 