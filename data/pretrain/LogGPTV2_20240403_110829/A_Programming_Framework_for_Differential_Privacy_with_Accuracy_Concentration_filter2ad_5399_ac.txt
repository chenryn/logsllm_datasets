we will obtain datasets that will still differ in s rows—thus,
the accumulated stability remains the same. The primitive
dpGroupBy returns a dataset where rows with the same
key are grouped together. The functional argument (of type
r → k) maps rows to keys of type k. The rows in the return
dataset (Data (2*s) (k, [r])) consist of key-rows pairs of type
(k, [r])—syntax [r] denotes the type of lists of elements of
type r. What appears on the left-hand side of the symbol ⇒
are type constraints. They can be seen as static demands for the
types appearing on the right-hand side of ⇒. Type constraint
Eq k demands type k, denoting keys, to support equality;
otherwise grouping rows with the same keys is not possible.
The accumulated stability of the new dataset is multiplied by
2 in accordance with stability calculations for transformations
[2, 34]—observe that 2*s is a type-level multiplication done
by a type-level function (or type family [37]) *. Our API also
considers transformations similar to those found in SQL like
intersection (dpIntersect), union (dpUnion), and selection
(dpSelect) of datasets, where the accumulated stability is
updated accordingly. Providing a general join transformation
is known to be challenging [2, 38, 39, 40]. The output of a join
may contain duplicates of sensitive rows, which makes difﬁcult
to bound the accumulated stability of datasets. However, and
similar to PINQ, DPella supports a limited form of joins, where
a limit gets imposed on the number of output records mapped
under each key in order to obtain stability. For brevity, we skip
its presentation and assume that all the considered information
is contained by the rows of given datasets.
2) Partition: Primitive dpPart deserves special attention.
This primitive is a mixture of a transformation and aggregations
since it partitions the data (transformation) to subsequently
apply aggregations on each of them. More speciﬁcally, it splits
the given dataset (Data s r) based on a row-to-key mapping
(r → k). Then, it takes each partition for a given key k
and applies it to the corresponding function Data s r →
Query (Value a), which is given as an element of a key-
4A separation that can be enforced via Haskell modules [36]
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
416
query mapping (Map k ((Data s r) → Query (Value a))).
Subsequently, it returns the values produced at every partition
as a key-value mapping (Query (Map k (Value a))). The
primitive dpPartRepeat, used by the examples in Section II,
is implemented as a special case of dpPart and thus we do
not discuss it further.
Partition is one of the most important operators to save
privacy budget. It allows to run the same query on a dataset’s
partitions but only paying for one of them—recall Theorem II.3.
The essential assumption that makes this possible is that
every query runs on disjoint datasets. Unfortunately, data
analysts could ignore this assumption when writing queries—
see Appendix A for an example. To catch such possible coding
errors, DPella deploys an static information-ﬂow control (IFC)
analysis similar to that provided by MAC [41]. IFC ensures
that queries run by dpPart do not perform queries on shared
datasets by attaching provenance labels to datasets Data s r
indicating to which part of the query they are associated with
and propagates that information accordingly. The implemented
IFC mechanism is transparent to data analysts and curators,
i.e., they do not need to understand how it works. Analysts and
curators only need to know that, when the IFC analysis raises
an alarm, is due to a possibly access to non-disjoint datasets
when using dpPart.
3) Aggregations: DPella presents primitives to count
(dpCount), sum (dpSum), and average (dpAvg) rows in datasets.
These primitives take an argument eps :: , a dataset, and
build a Laplace mechanism which is eps-differentially private
from which a noisy result gets return as a term of type
Value Double. The purpose of data type Value a is two
fold: to encapsulate noisy values of type a originating from
aggregations of data, and to store information about
its
accuracy—intuitively, how “noisy” the value is (explained
in Section IV). The injected noise of these queries gets
adjusted depending on three parameters: the value of type ,
the accumulated stability of the dataset s, and the sensitivity of
the query (recall Deﬁnition II.2). More speciﬁcally, the Laplace
mechanism used by DPella uses accumulated stability s to scale
the noise, i.e., it consider b from Theorem II.1 as b = s · ΔQ
 .
The sensitivity of DPella’s aggregations are hard-coded into the
implementation—similar to what PINQ does. The sensitivities
of dpSum and dpAvg are set to 1 and 2, respectively, by
applying a clipping function (r → Double). This function
maps the values under scrutiny into the interval [−1, 1] before
executing the query. The sensitivity of dpCount and dpMax
is set to 1. To implement the Laplace mechanism, the type
constrain Stb s in dpCount, dpSum, and dpAvg demands the
accumulated stability parameter s to be a type-level natural
number in order to obtain a term-level representation when
injecting noise. Finally, primitive dpMax implements report-
noisy-max [20]. This query takes a list of possible responses
(Responses a is a type synonym for [a]) and a function of
type r → a to be applied to every row. The implementation
of dpMax adds uniform noise to every score—in this case, the
amount of rows voting for a response—and returns the response
with the highest noisy score. This primitive becomes relevant
to obtain the winner option in elections without singling out
any voter. However, it requires that the accumulated stability of
the dataset to be 1 in order to be sound [22]. DPella guarantees
such requirement by typing: the type of the given dataset as
argument is Data 1 r.
4) Privacy budget and execution of queries: The primitive
budget statically computes how much privacy budget
is
required to run a query. It is worth notice that DPella returns
an upper bound of the required privacy budget rather than the
exact one—an expected consequence of using a type-system
to compute it and provide early feedback to data analysts.
Finally, the primitive dpEval is used by data curators to run
queries (Query a) under given privacy budgets (), where
datasets are just lists of rows ([r]). It assumes that the initial
accumulated stability as 1 (Data 1 r) since the dataset has
not yet gone through any transformation, and DPella will
automatically calculate the accumulated stability for datasets
affected by subsequent transformations via the Haskell’s type
system. This primitive returns a computation of type IO a,
which in Haskell are computations responsible to perform side-
effects—in this case, obtaining randomness from the system
in order to implement the Laplace mechanism.
5) Implementation: DPella is implemented as a deep em-
bedded domain-speciﬁc language (EDSL) in Haskell. Due to
such design choice, data analysts can piggyback on Haskell’s
infrastructure to build queries in a creative way. For instance, it
is possible to leverage on any of Haskell’s pure functions. The
following one-liner (of type Query [Value Double]) shows
how to write a query that generates possibly non-disjoint
datasets from ds :: Data s r based on different criteria for
then performing a counting.
mapM (flip dpSelect ds>=>dpCount eps) fs
Variable eps is the epsilon to spend in each counting while
fs :: [r → Bool] is the criteria list. The high-order functions
flip, mapM, and (>=>) are standard in Haskell and represent
a function who switches arguments, the monadic versions of
map, and the Kleisli arrow, respectively. Despite DPella being a
ﬁrst-order interface, data analysts can use Haskell’s high-order
functions to compactly describe queries.
IV. ACCURACY
DPella uses the data type Value a responsible to store a
result of type a as well as information about its accuracy.
For instance, a term of type Value Double stores a noisy
number (e.g., coming from executing dpCount) together with
its accuracy in terms of a bound on the noise introduced to
protect privacy.
DPella provides an static analysis capable to compute the
accuracy of queries via the following function
accuracy :: Query (Value a) → β → α
which takes as an argument a query and returns a function,
called inverse Cumulative Distribution Function (iCDF), captur-
ing the theoretical error α for a given conﬁdence 1-β. Function
accuracy does not execute queries but rather symbolically
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
417
-- Accuracy analysis (data analyst)
-- Norms (data analyst)
accuracy :: Query (Value a) → β → α
norm∞ :: [Value Double] → Value [Double]
:: [Value Double] → Value [Double]
:: [Value Double] → Value [Double]
:: [Value Double] → Value [Double]
-- Accuracy combinators (data analyst)
:: [Value Double] → Value Double
:: Value Double → Value Double
norm2
norm1
rmsd
add
neg
Fig. 4: DPella API: Part II
interpret all of its components in order to compute the accuracy
of the result based on the sub-queries and how data gets
aggregated. DPella follows the principle of improving accuracy
calculations by detecting statistical independence. For that, it
implements taint analysis [24] in order to track if values were
drawn from statistically independent distributions.
A. Accuracy calculations
DPella starts by generating iCDFs at the time of running
aggregations based on the following known result of the Laplace
mechanism:
Deﬁnition IV.1 (Accuracy for the Laplace mechanism). Given
a randomized query ˜Q(·) : db → R implemented with the
Laplace mechanism as in Theorem II.1, we have that
(cid:3) β
| ˜Q(D) − Q(D)| > log(1/β) · ΔQ

(3)
Pr
(cid:2)
(cid:3)
Recall that the Laplace mechanism used by DPella utilizes
accumulated stability s to scale the noise, i.e., it consider
b from Theorem II.1 as b = s · ΔQ
 . Consequently, DPella
stores the iCDF λβ → log(1/β) · s · ΔQ
for the values of
type Value Double returned by aggregation primitives like
dpCount, dpSum, and dpAvg. However, queries are often more
complex than just calling aggregation primitives—as shown by
CDF2 in Figure 1b. In this light, DPella provides combinators
responsible to aggregate noisy values, while computing its
iCDFs based on the iCDFs of the arguments. Figure 4 shows
DPella API when dealing with accuracy.

1) Norms: DPella exposes primitives to aggregate the
magnitudes of several errors predictions into a single measure—
a useful tool when dealing with vectors. Primitives norm∞,
norm2, and norm1 take a list of values of type Value Double,
where each of them carries accuracy information, and produces
a single value (or vector) that contains a list of elements
(Value [Double]) whose accuracy is set to be the well-
known (cid:7)∞-, (cid:7)2-, (cid:7)1-norms, respectively. Finally, primitive rmsd
implements root-mean-square deviation among the elements
given as arguments. In our examples, we focus on using norm∞,
but other norms are available for the taste, and preference, of
data analysts.
2) Adding values: The primitive add aggregates values and,
in order to compute accuracy of the addition, it tries to apply the
Chernoff bound if all the values are statistically independent;
otherwise, it applies the union bound. More precisely, for the
next deﬁnitions we assume that primitive add receives n terms
Union
Chernoff
α
2,000
1,000
0
0
20
40
60
Sub-queries
80
Fig. 5: Union vs. Chernoff bounds
2303
155
100
v1::Value Double, v2::Value Double, ... , vn::Value Double.
Importantly, since we are calculating the theoretical error, we
should consider random variables rather than speciﬁc numbers.
The next deﬁnition speciﬁes how add behaves when applying
union bound.
Deﬁnition IV.2 (add using union bound). Given n (cid:4) 2 random
variables Vj with their respective iCDF j, where j ∈ 1 . . . n,
and αj = iCDFj( β
j=1 Vj has
the following accuracy:
n ), then the addition Z =
(cid:4)n
(cid:4)n
Pr[|Z| >
j=1 αj] (cid:3) β
(4)
Observe that to compute the iCDF of Z, the formula uses
the iCDFs from the operands applied to β
n. Union bound
makes no assumption about the distribution of the random
variables Vj.
In contrast, the Chernoff bound often provides a tighter
error estimation than the commonly used union bound when
adding several statistically independent queries sampled from
a Laplace distribution. To illustrate this point, Figure 5 shows
that difference for the cdf2 function we presented in Section II
with  = 0.5 (for each DP sub-query) and β = 0.1. Clearly, the
Chernoff bound is asymptotically much better when estimating
accuracy, while the union bound works best with a reduced
number of sub-queries—observe how lines get crossed in Figure
5. In this light, and when possible, DPella computes both
union bound and Chernoff bound and selects the tighter error
estimation. However, to apply Chernoff bound, DPella needs
to be certain that the events are independent. Before explaining
how DPella detects that, we give an speciﬁcation of the formula
we use for Chernoff.
Deﬁnition IV.3 (add using Chernoff bound [42]). Given
n (cid:4) 2 independent random variables Vj ∼ Lap(0, bj),
where j ∈ 1 . . . n, bM = max {bj}j=1...n, and ν >
max{
ln 2
j=1 Vj
has the following accuracy:
Pr[|Z| > ν ·
β}, then the addition Z =
(cid:5)(cid:4)n
j=1 b2
(cid:4)n
8 ln 2
j , bM
(cid:5)
(cid:5)
(5)
DPella uses the value ν = max{
β} +
0.00001 to satisfy the conditions of the deﬁnition above when
applying the Chernoff bound—any other positive increment to
j=1 b2
j , bM
ln 2
β ] (cid:3) β
(cid:5)(cid:4)n
(cid:5)
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
418
the computed maximum works as well5.
Lastly, to support subtraction, DPella provides primitive
neg responsible to change the sign of a given value. We next
explain how DPella checks that values come from statistically
independent sampled variables.
3) Detecting statistical independence: To detect statistical
independence, we apply taint analysis when considering terms
of type Value a. Speciﬁcally, every time a result of type
Value Double gets generated by an aggregation query in
DPella’s API (i.e., dpCount, dpSum, etc.), it gets assigned
a label indicating that it is untainted and thus statistically
independent. The label also carries information about the scale
of the Laplace distribution from which it was sampled—a
useful information when applying Deﬁnition IV.3. When the
primitive add receives all untainted values as arguments, the
accuracy of the aggregation is determined by the best estimation
provided by either the union bound (Deﬁnition IV.2) or the
Chernoff bound (Deﬁnition IV.3). Importantly, values produced
by add are considered tainted since they depend on other
results. When add receives any tainted argument, it proceeds
to estimate the error of the addition by just using union bound—
we refer readers to Appendix B for a piece of DPella code
which intituively illustrates how our taint analysis works. In
the next Section, we proceed to formally deﬁne our accuracy
analysis.
B. Implementation
The accuracy analysis consists on symbolically interpreting
a given query, calculating the accuracy of individual parts,
and then combining them using our taint analysis. We in-
troduce two polymorphic symbolic values: D :: Data s r