which relies on iterated Bernoulli trials, leaks the values ∥Sc∥2 and
⟨z, Sc⟩. If we ignore the compression of the signature element z2,
exploiting the leakage of the scalar product to recover the secret key
is a simple matter of linear algebra; however, real implementations
do include compression, which seems to thwart that attack.
However, the leakage of the norm ∥Sc∥2 does suffice to recover
the secret key using our variant of the Howgrave-Graham–Szydlo
algorithm provided that the algebraic norm of s1 (or s2) is easy
to factor, which happens in a noticeable fraction of all cases (over
3% for the 128-bit secure parameter sets BLISS-I and BLISS-II, for
example, according to Table 2). And it seems difficult to protect
against this attack.
Hard-to-factor algebraic norms. A first possible countermeasure
could be to try and ensure that the algebraic norms of s1 and s2 are
hard to factor, but it isn’t clear how that could be done in practice:
just generating these values using the existing key generation al-
gorithm and eliminating “easy to factor” values seems hopeless, as
there is no such thing as an efficient test for “hard to factor” com-
posites. Alternatively, one could try to construct these values as
products of two small, sparse elements with large prime norms (so
as to obtain RSA-like cyclotomic integers), but this would require a
significant increase in all parameters (worsening the efficiency of
BLISS to a considerable extent). Moreover, relying on the hardness
of factoring in a scheme whose main selling point is postquantum
security is quite unsatisfactory.
11
Constant-time implementation. A much easier possible counter-
measure could be to try and implement the iterated Bernoulli rejec-
tion sampling algorithm in constant time. Our simple power analysis
(or rather, SEMA) attack is made particularly easy in the case of
the implementation of Pöppelmann et al. [46] by the fact that al-
gorithm SampleBernExp(x ) as described in Figure 2 carries out
the samplings Bci
only for indices i such that the corresponding
bits xi of x are 1. This produces a trace very similar to the 1990s
SPA attacks on RSA [37, §3.1]: one can simply read the bits of x on
the trace directly (where, in our case, x = K − ∥Sc∥2). The same
observation applies of course to strongSwan with respect to branch
tracing. One can make things more difficult for the side-channel
attacker by rewriting the algorithm in such a way that the Bci
samplings are carried out all the time regardless of the value xi. We
can also eliminate data-dependent branches completely. A possible
such algorithm is described in Figure 11.
That countermeasure is probably sufficient at least in the case of
strongSwan, provided that on takes good care to precompute the
bits xi before starting the loop, and to check that the compiler does
not introduce spurious branching instructions in that computation.
Strictly speaking, however, the countermeasure does not eliminate
all leakage related to the xi’s. For example, it involves a multipli-
cation a · xi whose operands are just bits, so one can reasonably
expect to be able to distinguish the cases xi = 0 and xi = 1 on
a power or EM trace, according to the Hamming weight leakage
model.
Rejection sampling using transcendental functions. As mentioned
in §2, one could also avoid iterated Bernoulli sampling entirely, and
carry out the rejection sampling in a single step by computing the
rejection probability every time with sufficient precision and com-
paring it to uniformly sampled randomness in a suitable interval.
However, this involves computing the transcendental functions exp
and cosh to a high precision if one doesn’t want to lose too much
accuracy at the tails of the distribution (which could in principle
jeopardize the security of the scheme via statistical attacks of the
form considered by Ducas and Nguyen against NTRUSign [17]).
Such a computation, however, would be really inefficient, especially
on constrained devices like the 8-bit AVR microcontroller targeted
in our experiments. Moreover, it is also highly non-linear and has
a high circuit complexity, making it particularly inconvenient if
one wants to introduce more theoretically sound countermeasures
against SPA and DPA, like masking.
One could also conceivably precompute all possible values for
the probabilities involved in rejection sampling and tabulate them,
in an approach similar to CDT-based techniques for Gaussian sam-
pling. The rejection sampling step would then be fast and easy to
implement in constant time. The obvious drawback, however, is
that the storage requirement is very large: tens of thousands of high-
precision values for each parameter set, amounting to megabytes
of storage overall. This is again unsuitable on constrained devices.
It may be acceptable on desktop computers, however, but in that
setting, cache attacks become a source of concern.
Using a scheme with a simpler rejection sampling? A different
approach could be to use an alternate scheme with a simpler rejec-
tion sampling algorithm. An obvious candidate is the “ancestor” of
BLISS: the lattice-based signature scheme described by Güneysu,
Lyubashevsky and Pöppelmann (GLP) in [28], which targets a uni-
form distribution in a suitable interval for the coefficients of the
signature elements z1, z2, instead of the bimodal Gaussian distribu-
tion of BLISS. Due to that difference, the GLP scheme has slightly
less compact signatures: BLISS signatures at the 128-bit security
level are about 5000-bit long, while GLP signatures are about 9000-
bit long (and the bit security claim is also a bit weaker).
However, the rejection sampling step also becomes considerably
simpler: it simply involves checking whether the coefficients of z1
and z2 fall in the expected interval. In other words, it boils down to
a collection of simple integer comparisons, which are typically fast,
constant-time operations even on the most modest platforms. More-
over, this simple rejection sampling can be easily combined with
arithmetic masking: although it is not a linear operation, masking
it amounts to masking a shallow Boolean circuit with single-bit
output, which can be done efficiently (it can be seen as a simpler
variant of the arithmetic-to-Boolean masking conversion of Coron
et al. [10]).
6.2 Attack on the Gaussian sampling
We also showed in §4 that the variable-time algorithm for dis-
crete Gaussian sampling proposed by Ducas et al. [14] and used
in strongSwan is also a potential source of side-channel leakage.
Mounting a concrete key recovery attack only seems practical when
given access to a mostly “noise-free” attack vector like branch trac-
ing, but in that case, the attack is very powerful: it recovers the
entire secret key with high probability from the branch trace of a
single signature, and works for all keys.
Gaussian sampling in constant time. As we have seen above, the
function SampleBernExp can be implemented in constant time
relatively painlessly and with a moderate performance penalty. The
same cannot be said of SamplePosGaussian however: that function
carries out an a priori unbounded number of iterations, and even
though it is feasible to fix a large bound instead, the performance
penalty incurred if one were to execute the entire for loop instead
of returning early would be tremendous. Therefore, converting
this overall Gaussian sampling algorithm to constant time seems
impractical.
One could observe that implementing SampleBernExp alone in
constant time would make the attack significantly more difficult.
This is true, but even though the attacker would no longer be able
to recover the entire output of SampleGaussian, he would still be
able to compute x, and hence would get the value of z up to the
small error y located in the least significant bits. In other words,
the attacker would be able to replace the large Gaussian masks yi
by much smaller noise values, which clearly affects the security of
the scheme.
Therefore, in any setting where resorting to a side-channel at-
tack vector similar to branch tracing is plausible, it seems prefer-
able to avoid the Gaussian sampling algorithm of Ducas et al. alto-
gether.Other algorithms for discrete Gaussian sampling are much
more practical to implement in constant time. This includes the
approach proposed by Dwarakanath and Galbraith [18] combining
Knuth–Yao with cumulative distribution tables; it suffers from a
large storage requirements, however. The most convenient option
so far seems to be the algorithm of Micciancio and Walter [40],
which can be implemented entirely in constant time with only
integer arithmetic, and relies on an amount of storage than can
be tailored to specific applications: the algorithm runs faster with
more storage, but can use less storage on more constrained devices.
Alternatively, switching to a simpler signature scheme such as
GLP [28] solves the problem for this source of leakage as well: the
masks in GLP are sampled with uniform coefficients in short inter-
vals, and this is again straightforward to implement in a constant-
time and branch-free manner.
6.3 Attack on the multiplication by c
As seen in §5, we can also recover the secret key from power anal-
ysis/EMA traces of the computation of the products s1 · c, s2 · c of
the secret key elements with the varying hash element c computed
during signature generation (which is a sparse polynomial with
coefficients in {0, 1}).
We have described this key recovery in the context of the Pöppel-
mann et al. implementation [46], in which c is simply represented
as the list of the positions of its non-zero coefficients, and the prod-
ucts s1 · c, s2 · c are computed as simple sums of signed shifts of s1
and s2 respectively.
We note that even if c is instead represented as a ring element
and the products si · c are computed as generic products in the ring
(using the number-theoretic transform in Zq[x]/(xn + 1)), a DPA
attack will still easily recover the si’s. This is because the NTT-based
product operation is a simple component-wise product of vectors
in Zn
q, where the vectors corresponding to s1 and s2 are constant,
whereas the other operands of the multiplication vary with each
signature generation. Since the size of the integers involved is quite
small (q is about 14-bit long), the key recovery is feasible with
a reasonable number of traces on an arbitrary platform, and is of
course even easier on an 8-bit microcontroller, where multiplication
is carried out on 8-bit operands.
Again, protecting against such a DPA attack seems tricky. We
can suggest the following two possible approaches, but both of
them have drawbacks.
A heuristic countermeasure. What makes the DPA approach so
effective against this multiplication is the fact that it combines the
secret key with a variable operand c which is known to the adversary
since it is part of the signature. One possible approach make the
leakage harder to exploit is thus to avoid multiplying the secret
by a known value. This can be done by computing the element
zi = yi + (−1)b si · c as:
zi = c · wi where wi = c−1 · yi + (−1)b si .
With that formula, the known value c−1 is multiplied by a secret
value yi, but since that secret value changes with each signature
generation, it is much more difficult to exploit the corresponding
leakage with DPA (although a single-trace template attack may still
apply when the adversary has access to an identical device). As for
the product of c with wi, the corresponding leakage should not be
an issue since wi can be recovered from the available signature
elements anyway (in case the iteration corresponds to a signature
that is actually output; for values eliminated in rejection sampling,
the argument does not hold, but c is not known in that case either).
12
This provides a heuristic countermeasure which may help against
DPA attacks (although a quantitative evaluation of the effectiveness
of that countermeasure is left for future work). It can be seen as an
alternative to Saarinen’s countermeasure [49], which does thwart
the stronger attacks of §5. It does have a number of limitations
however. As we have noted, it may still be defeated by template
attacks. Moreover, it involves the computation of the inversion
c−1, which would typically be carried out in the Fourier domain
(so it amounts to a series of inversions in Zq). This is a somewhat
costly operation on constrained devices, and has the additional
drawback of requiring c to be invertible (which happens with prob-
ability (1 − 1/q)n ≈ 0.96, which is high but still less than 1). And
since c−1 has full size coefficients modulo q, one cannot use a naive
multiplication taking advantage of the sparsity of c: relying on a
full-blown number-theoretic transform seems necessary to achieve
satisfactory performance.
Arithmetic masking. It is also possible to achieve provable secu-
rity against DPA (at least in the so-called t-probing model, which
is known to capture realistic leakage scenarios [48]) using arith-
metic masking (with the caveat that, again, template attacks still
apply [43]). The linearity of the multiplication by c makes it partic-
ularly easy to mask. However, the entire signing algorithm needs to
be masked for the security argument to be valid. In particular, one
also needs to mask the generation of the random Gaussian values
y1, y2, which seems difficult, and the rejection sampling, which we
have already noted sounds even harder. These highly non-linear op-
erations constitute a major stumbling block for applying a masking
countermeasure.
Thus, one may again want to consider an alternate scheme involv-
ing simpler operations, like the GLP scheme mentioned earlier [28].
In that scheme, y1 and y2 are sampled from uniform distributions
in suitable intervals, so that a masked sampling is reasonably easy
to implement. The generation of u, z1, z2 remains linear, and as
noted above the rejection sampling can be masked easily as well.
This may make the larger signature size an acceptable trade-off to
achieve good security against physical attacks.
6.4 Related schemes
BLISS–B. In [13], Ducas proposed an optimized variant of BLISS
called BLISS–B, which features significantly faster key generation
and signing algorithms while maintaining the same security level.
This variant is also implemented in strongSwan [51].
The main functional difference between BLISS and BLISS–B is the
way the “challenge element” c is used in the signature generation
algorithm. In BLISS–B, c is computed in a similar way as in BLISS (as
the output of a hash function mapping to sparse polynomials with
0/1 coefficents), but instead of computing the signature elements zi
directly with c as zi = yi + (−1)b si c, the algorithm first obtains an
intermediate ring element c′ by flipping the signs of the coefficients
of c, and uses c′ instead of c in the computation of the zi’s. The sign
flips are deterministic, and are chosen in such a way as to make the
norm ∥Sc′∥2 = ∥s1c′∥2 +∥s2c′∥2 smaller, which reduces the chance
that a candidate signature is thrown out in rejection sampling, and
hence improves the overall signing speed. The change does not
affect signature verification, since it only depends on the value of
c′ modulo 2, which is equal to the original c.
In terms of side-channel security, the change introduced by
BLISS–B looks rather dangerous, as the sign flips are typically
implemented in terms of secret-dependent branches (this is in par-
ticular the case in strongSwan). We have not mounted a specific
attack against this modification, but at least in a strong attack model
like branch tracing, it seems relatively easy to exploit. BLISS–B is
also vulnerable to the attack of §4 (since the Gaussian sampling is
exactly the same as in BLISS) and the attack of §5 adapts relatively
easily as well (since the multiplication si c′ is still carried out as a
sequence of shifted additions and subtractions, and the values of the
shifts are known). On the other hand, the attack of §3 seems difficult
to adapt, because the leakage reveals the norm ∥Sc′∥2 whereas the
attacker only knows c. Since the attack requires many signatures,
simply guessing the sign flips is not feasible either. Generalizing
this attack to BLISS–B is an interesting open problem.
GPV-style hash-and-sign signatures. Besides Fiat–Shamir style
signatures, the other major type of lattice-based signature scheme in
the random oracle model consists of hash-and-sign signatures based
on GPV lattice trapdoors and Gaussian sampling in lattices [23].
Such schemes are considered less efficient than their Fiat–Shamir
counterparts, but offer some advantages, like clearer security guar-
antees in the quantum random oracle model.
Not many implementations of GPV-style lattice signatures have
been published, but a few efficient variants have publicly available
code, including the NTRU-based scheme of Ducas, Lyubashevsky
and Prest [16]. A complete side-channel evaluation of these imple-
mentations is beyond the scope of this paper, but generally speak-
ing, a major issue with all of these schemes from a side-channel
standpoint is the fact that the main operation in signature gener-
ation, namely Gaussian sampling in a lattice, is hard to carry out
in constant-time and without secret-dependent branches (this is in
contrast with a scheme like BLISS, which only require Gaussian
sampling over Z). In fact, to the best of our knowledge, this is still
an open problem at the time of this writing, and until this prob-
lem is solved, even an SPA-resistant implementation of GPV-style
signatures appears difficult to achieve.
7 ACKNOWLEDGMENTS
We would like to thank the anonymous reviewers for their insightful
comments. This work has been supported in part by the European
Union’s H2020 Programme under grant agreement number 669891.
REFERENCES
[1] Onur Aciiçmez, Shay Gueron, and Jean-Pierre Seifert. 2007. New Branch Predic-
tion Vulnerabilities in OpenSSL and Necessary Software Countermeasures. In
IMACC (LNCS), Steven D. Galbraith (Ed.), Vol. 4887. Springer, 185–203.
[2] Onur Aciiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert. 2007. On the Power
of Simple Branch Prediction Analysis. In ASIACCS, Feng Bao and Steven Miller
(Eds.). ACM, 312–320.
[3] Onur Aciiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert. 2007. Predicting Secret
Keys Via Branch Prediction. In CT-RSA (LNCS), Masayuki Abe (Ed.), Vol. 4377.
Springer, 225–242.
[4] Sedat Akleylek, Nina Bindel, Johannes A. Buchmann, Juliane Krämer, and Gior-
gia Azzurra Marson. 2016. An Efficient Lattice-Based Signature Scheme with
Provably Secure Instantiation. In AFRICACRYPT (LNCS), David Pointcheval, Ab-
derrahmane Nitaj, and Tajjeeddine Rachidi (Eds.), Vol. 9646. Springer, 44–60.
[5] Ian Beer. 2016. Linux: perf_event_open() can race with execve(). Google
Project Zero bug report. (2016). https://bugs.chromium.org/p/project-zero/issues/
detail?id=807.
13
[6] Nina Bindel, Johannes A. Buchmann, and Juliane Krämer. 2016. Lattice-Based
Signature Schemes and Their Sensitivity to Fault Attacks. In FDTC, Philippe
Maurine and Michael Tunstall (Eds.). IEEE Computer Society, 63–77.
[7] Yuval Bistritz and Alexander Lifshitz. 2010. Bounds for resultants of univariate
and bivariate polynomials. Linear Algebra Appl. 432, 8 (2010), 1995–2005. Special
issue devoted to the 15th ILAS Conference.
Experimenting with Post-Quantum Cryptogra-
phy. (2016). https://security.googleblog.com/2016/07/experimenting-with-post-
quantum.html
[8] Matt Braithwaite. 2016.
138 in Graduate Texts in Mathematics. Springer.
[9] Henri Cohen. 1993. A Course in Computational Algebraic Number Theory. Number
[10] Jean-Sébastien Coron, Johann Großschädl, Mehdi Tibouchi, and Praveen Kumar
Vadnala. 2015. Conversion from Arithmetic to Boolean Masking with Logarithmic
Complexity. In FSE (LNCS), Gregor Leander (Ed.), Vol. 9054. Springer, 130–149.
[11] Özgür Dagdelen, Rachid El Bansarkhani, Florian Göpfert, Tim Güneysu, Tobias
Oder, Thomas Pöppelmann, Ana Helena Sánchez, and Peter Schwabe. 2014.
High-Speed Signatures from Standard Lattices. In LATINCRYPT (LNCS), Diego F.
Aranha and Alfred Menezes (Eds.), Vol. 8895. Springer, 84–103.
[12] Richard Dedekind. 1878. Uber den Zusammenhang zwischen der Theorie der
Ideale und der Theorie der hoheren Kongruenzen. Abhandlungen der Koniglichen
Gesellschaft der Wissenschaften zu Gottingen 23 (1878), 1–23.
[13] Léo Ducas. 2014. Accelerating BLISS: the geometry of ternary polynomials. IACR
Cryptology ePrint Archive 2014 (2014), 874. http://eprint.iacr.org/2014/874
[14] Léo Ducas, Alain Durmus, Tancrède Lepoint, and Vadim Lyubashevsky. 2013.
Lattice Signatures and Bimodal Gaussians. In CRYPTO (LNCS), Ran Canetti and