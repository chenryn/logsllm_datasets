title:Synthesizing Plausible Privacy-Preserving Location Traces
author:Vincent Bindschaedler and
Reza Shokri
2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy
Synthesizing Plausible Privacy-Preserving Location Traces
Vincent Bindschaedler
UIUC
PI:EMAIL
Reza Shokri
Cornell Tech
PI:EMAIL
Abstract— Camouﬂaging user’s actual location with fakes is a
prevalent obfuscation technique for protecting location privacy.
We show that the protection mechanisms based on the existing
(ad hoc) techniques for generating fake locations are easily
broken by inference attacks. They are also detrimental to many
utility functions, as they fail to credibly imitate the mobility
of living people. This paper introduces a systematic approach
to synthesizing plausible location traces. We propose metrics
that capture both geographic and semantic features of real
location traces. Based on these statistical metrics, we design a
privacy-preserving generative model to synthesize location traces
which are plausible to be trajectories of some individuals with
consistent lifestyles and meaningful mobilities. Using a state-
of-the-art quantitative framework, we show that our synthetic
traces can signiﬁcantly paralyze location inference attacks. We
also show that these fake traces have many useful statistical
features in common with real traces, thus can be used in
many geo-data analysis tasks. We guarantee that the process
of generating synthetic traces itself is privacy preserving and
ensures plausible deniability. Thus, although the crafted traces
statistically resemble human mobility, they do not leak signiﬁcant
information about any particular individual whose data is used
in the synthesis process.
I. INTRODUCTION
It is preferable not to travel with a dead man.
Henri Michaux
A popular method to protect the privacy of a mobile user,
who queries a location-based service (LBS), is to hide her
true query among fake queries. Users keep the obtained
information to their real queries and discard the responses
to all their fake queries. The existing techniques to generate
fake locations [10], [23], [24], [26], [45], [49], [56], are based
on very simple heuristics such as i.i.d. location sampling and
sampling locations from a random walk on a grid or on the
road network or between points of interest. The generated
location traces using these types of techniques fail to capture
the essential semantic and even some basic geographic features
of the mobility of a living human who has a consistent lifestyle
and meaningful mobility. Thus, as we quantitatively show, they
poorly protect users’ privacy against location inference attacks
that can easily ﬁlter out the trajectories of the jumping dead.
In order to be plausible, synthetic traces need to statistically
resemble real traces, thus themselves should be generated in a
privacy-preserving manner. Consider the most naive protection
scheme where location samples from the trajectory of Alice
(a real person who perhaps is not even using the LBS) are
used to mask locations of Bob (a LBS user). Clearly this is
too intrusive with respect to the privacy of Alice, although it
confuses the attacker about Bob’s truly visited locations. The
obfuscation techniques that compose an area of fake locations
around the user’s true location, e.g., [30], [39], [52], are
inappropriate for similar reasons: they have a strong statistical
correlation with the user’s true trace and do not introduce
much error to location inference attacks. Thus, they are less
privacy preserving than even, for example, i.i.d generated fake
locations [45].
In this paper, we present and evaluate the ﬁrst formal
and systematic methodology to generate fake yet semantically
real privacy-preserving location traces. In this approach, we
propose two mobility metrics that capture how realistic a
synthetic location trace is with respect to the geographic and
semantic dimensions of human mobility. We then construct
a probabilistic generative model that produces synthetic yet
plausible traces according to these metrics. We build our gen-
erative model upon a dataset of real location traces as seeds.
Thus, the model itself needs to be privacy-preserving. To this
end, we design privacy tests to control and limit information
leakage about the seed dataset. We then use state-of-the-art
location inference attacks to evaluate the effectiveness of our
fake traces in preserving the privacy of LBS users. On a set
of real location traces, we show that the attacker’s probability
of error [46] in estimating the true location of users over
time is 0.9972 when using our method, i.e., we achieve close
to maximum privacy. By comparison, the attacker’s error is
0.2958, 0.3066, 0.3802, and 0.7486 when using existing i.i.d.
sampling and random walk methods.
Our scheme is based on the fact that mobility patterns of
different individuals are semantically similar, regardless of
which geographic locations they visit. These common features
of human mobility stem from their similar lifestyles, e.g.,
traversing between home, workplace, friends’ place, favorite
shops and recreational places, and occasional new locations.
These mobility patterns share a similar structure that reﬂect
the general behavior of a population (at a high level [48]).
We model the mobility of each individual in two dimensions:
geographic and semantic. In addition to the common mobility
patterns (i.e., how people move in a city), the geographic
features are mostly speciﬁc to each individual (e.g., what
everyone refers to as her “home” is located in a geographically
distinct place), whereas the semantic features are mostly
generic and representative of overall human mobility behavior
(e.g., most people have a “home” where they stay overnight).
Thus, the semantic representations of human mobilities are
very similar, especially within a culture group with similar life
2375-1207/16 $31.00 © 2016 IEEE
© 2016, Vincent Bindschaedler. Under license to IEEE.
DOI 10.1109/SP.2016.39
DOI 10.1109/SP.2016.39
546
546
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:44 UTC from IEEE Xplore.  Restrictions apply. 
styles. We extract these common semantic features as well as
the aggregate geographic features from real mobility datasets,
as seed. Using this, we probabilistically generate synthetic
traces which are geographically probable and semantically
similar to real
traces. This results in a set of traces for
nonexistent individuals with meaningful lives and consistent
mobility patterns as any real individual in the seed dataset.
We preserve the privacy of seed traces. Our ﬁrst step is
a random and independent sampling of the seeds, which
is shown to be very effective in boosting the privacy of
individuals in a database [16]. We generate synthetic traces
from sampled seed traces. We then accept a synthetic trace
only if (1) it is geographically dissimilar to seeds and (2) the
same synthetic trace could have been generated from k ≥ 1
non-sampled alternatives. This ensures plausible deniability.
This is intrinsically similar to the notions of crowd blending
privacy [16], zero knowledge privacy [17], and outlier privacy
[31]. Our privacy guarantees protect the privacy of seed traces
against the following threats: inference attacks (to learn which
locations the seed contributors have visited), and membership
inclusion attack (to learn if a particular individual with certain
semantic habits has been in the seed dataset).
The application of our generated synthetic traces goes be-
yond protecting the privacy of mobile users in location-based
services. Our generated traces can also be used for a variety of
geo-data analysis tasks such as modeling human mobility [28],
map inference [29], points of interest extraction [59], semantic
annotation of locations [55], and location optimization for
opening new shops [22]. We list six features of traces that
contribute to these applications and show that our synthetic
traces exhibit a similar performance to what is achieved from
real traces on these tasks. For example, out of 400 locations,
the accuracy of synthetic traces in extracting the top-35 points
of interest is 96.7% compared to real traces. This is 88.5% and
100% respectively for the top-30 and top-40 points of interest.
Novelty. We design, implement as a tool, and evaluate with
real data the ﬁrst formal privacy-preserving generative model
to synthesize plausible location traces. Our privacy guarantees
ensure plausible deniability for individuals whose trace is
used by our algorithm. In a LBS scenario, we show that our
fake traces can bring near maximum location privacy (against
state-of-the-art inference attacks) for the users with minimum
overhead (i.e., the number of fake locations needed to be sent
to the LBS server along with the true location). We also show
that these traces do not perturb the semantic proﬁle of the user
in location-based recommender systems. In the dataset release
scenario, where only synthetic traces are released for analysis,
we show that useful features are preserved for multiple geo-
data analysis tasks. We design privacy tests to ensure that the
synthetic traces do not leak more information about the real
traces from which they are generated than alternative traces.
II. RELATED WORK
Synthetic (also called fake or dummy) information can
protect privacy and security in many different systems such as
web search [18], [20], anonymous communications [5], [12],
547547
authentication systems [21], and statistical analysis [33], [42].
In all these scenarios, the main challenge and the still open
problem is to generate context-dependent fake information that
resembles genuine user-produced data and also provides an
acceptable level of utility while enhancing privacy of users.
In location-based services, location obfuscation is a preva-
lent non-cryptographic technique to protect location privacy. It
does not require changing the infrastructure, as it can also be
done entirely on the user’s side either by altering (perturbing)
the location coordinates to be reported or by sending fake
location reports interleaved or along with the true locations.
Many location perturbation techniques are based on adding
some noise to the user’s location coordinates or reducing its
granularity, e.g., [3], [4], [19], [47]. The downside of these
techniques is that they reduce the users’ experienced LBS
service quality. This is because the server provides contextual
information related to the queried location and not the true
location of the user. So, users have to trade service quality
for privacy. Optimal solutions for location perturbation are
proposed [7], [47] which show the high cost of this technique.
Hiding the user’s true location among fake locations is a
promising yet not systematically-approached method to pro-
tecting location privacy. There are few simple techniques pro-
posed so far: adding independently selected locations drawn
from the population’s location distribution [45], generating
dummy locations from a random walk on a grid [24], [56],
constructing fake driving trips by building the path between
two random locations on the map given the more probable
paths traveled by drivers [26], adding noise to the paths
generated by road trip planner algorithms [10], or generating
the path between points of interests [49] and pausing at
those points [23]. All these solutions lack a formal model for
human mobility and do not consider the semantics associated
with location traces. Thus, the generated traces can be easily
distinguished from real trajectories, as we show in this paper.
To address potential misunderstandings, we contrast our
work with anonymization, and releasing aggregate statistics.
(1) Anonymization consists in removing identiﬁers of individ-
uals in the data, and publishing only the resulting (sanitized)
dataset. While this preserves utility, it does not provide much
privacy protection. Indeed, many researchers have shown that
anonymous traces are easily re-identiﬁable [32], [50], [58].
(2) Releasing privacy-preserving aggregate statistics has been
proposed in many contexts. In particular, there has been a lot of
recent work on releasing differentially-private histograms for
various types of data [1], [2], [54]. These are totally unsuitable
to be used in the LBS scenario and, in general, in applications
which require full location traces. For example, to obtain a
full location trace from a private histogram, one way is to
repeatedly and independently sample locations from it. This
results in an unlikely trace which include “jumps” between lo-
cations regardless of their distance and mobility constraints. In
particular, [1] considers the problem of releasing differentially-
private location histograms at various time intervals. Also,
[9] releases variable length n-grams with differential privacy
guarantee, which cannot produce full location traces.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:44 UTC from IEEE Xplore.  Restrictions apply. 
In summary, the existing approaches do not evaluate how
plausible and privacy-preserving their synthesized traces are.
They are only based on simple heuristics about human mobil-
ity. Hence, they do not properly preserve geographic features
of it, and completely ignore its semantic features. As a result,
their produced traces are not suitable in many scenarios.
They also lack privacy guarantees (and fail) against inference
attacks. This paper ﬁxes these shortcomings and enables us to
reason about and generate plausible synthetic location traces.
There are also several notable related works which appear
similar to this work but have subtle and important differences.
An example is DP-WHERE [36] which uses Call Detail
Records (CDRs) databases to produce differentially-private
synthetic databases with a distribution close to real CDRs.
However, CDRs are not equivalent to full location trajectories
because the location is only known at the time when a call
is made. Another example, is wPINQ [40] which achieves
differential privacy by calibrating down the weight of some
data records. wPINQ further proposes a way of generating
synthetic datasets using Markov chain Monte Carlo methods.
The techniques used, scenarios, and utility evaluation prohibit
a direct comparison with our work: wPINQ focuses on graphs
given noisy measurements about
the number of triangles,
whereas we consider the problem of generating plausible full
location trajectories.
Finally, Dwork et al. [15] introduce a class of mechanisms
called Propose-Test-Release (PTR) which ﬁrst picks a bound
on the sensitivity (of a statistic of interest) and then (privately)
tests whether noise calibrated to this candidate bound is
sufﬁcient to ensure differential privacy. If so, then a noised
output is released, otherwise no output is produced. There are
two major differences between PTR and our work. First, we
aim to generate synthetic location traces, whereas [15] seeks
privacy-preserving ways to estimate robust statistics such as
discovering the median of a dataset without prior knowledge
of the scale of the data. Second, the PTR framework performs
a test of the sensitivity of a statistic before deciding to release
a noised output, whereas our privacy tests are there to test the
synthetic traces generated themselves before deciding whether
to release them.
III. OUR SCHEME
In this section, we present a sketch of, and describe the
main intuition behind our scheme for generating fake traces.
We assume that time and space are discrete, so a location
trace is represented as a sequence of visited locations over
time. In our scheme, we synthesize a trace through a multiple
step process. We transform a (geographic) seed trace into the
semantic space and probabilistically transform it back to the
geographic space. Thus, the sampled trace is geographically
and semantically plausible. Figure 1 illustrates our scheme.
A. Subsampling the Seeds
We generate synthetic location traces by using a set of real
traces, from which we randomly subsample a set which we
refer to as the seed dataset. We refer to the set of traces
1
4
5
Sampled Seeds
Real Location Traces
A trace is a sequence of locations 
visited over time
Semantic Seed
Proposed Fake Trace
Transform each seed trace into 
the semantic domain by 
replacing each location with all 
equivalent locations in its cluster
     Generate a fake trace that can 
be mapped back to the same 
semantic seed and follows the 
aggregate mobility model
2
3
6
   From the similarity between 
mobility traces, infer the semantic 
similarity between locations, build 
a similarity graph and cluster it
Compute mobility model for 
each trace and also their 
aggregate mobility (as e.g., 
the probabilistic model for 
average mobility)
Mobility Models per 
Location Trace
Aggregate Mobility 
Model
Location Semantic 
Graph with Classes
Privacy Test
Fake Location Traces
Reject the fake traces if their 
geographic similarity with the 
seed exceeds a threshold or do 
not satisfy plausible deniability 
Fig. 1: Sketch of the proposed scheme.
that are not sampled as the alternative dataset. The reason for
subsampling becomes more clear when we explain our privacy
guarantees. Put simply, to guarantee plausible deniability, we
ensure that
there are k alternative traces that could have
produced a similar synthetic trace generated from a seed.
B. Computing the Semantic Similarity
Our goal here is to compute the semantic similarity between
locations. To this end, we start with modeling mobility of seed
locations. For each trace (i.e., sequence of locations visited
in the trace) in the seed dataset, we compute a probabilis-
tic mobility model that represents the visiting probability to
each location and transition probability among the locations
(see Section IV-A). The mobility model encompasses the
spatiotemporal behavior of each individual across different
locations. Time, duration, and probability of visiting a location,
as well as the probable previous and subsequent locations are
computable from the mobility model.
We analyze and discover the semantic relation between
different locations in a consistent manner by considering all
locations together. To this end, we propose a semantic similar-
ity metric (see Section IV-D). Intuitively, we assign a higher
similarity value to a pair of locations if multiple individuals
have similar spatiotemporal activities in them. We ﬁnd the
optimal way to map the visited locations in a pair of traces
such that
the mapping maximizes the statistical similarity
between their mobility models. The semantic similarity metric
is therefore the statistical similarity between mobility models
under the optimal semantic mapping between locations. This
means that if we were to translate the locations visited by two
individuals according to the discovered best mapping, they
would follow the same mobility model when their semantic
similarity is high (i.e., have similar life styles). For example,
consider Alice and Bob spending all day at their respective
work locations wA and wB, and all night at their respective
home locations hA and hB. Obviously, their mobility models
are semantically very similar, although it might be the case that
hA (cid:3)= hB and wA (cid:3)= wB. In this example, the best semantic
mapping between locations will be wA ↔ wB and hA ↔ hB.
548548
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:09:44 UTC from IEEE Xplore.  Restrictions apply. 
That said, the semantic similarity metric we propose goes
beyond simply ﬁnding the best mapping for home and work.
Indeed, the best mapping is over all locations, so it may be
that Alice’s favorite bar is mapped to Bob’s favorite nightclub,
if Alice and Bob visit those places in a similar way.
For each pair of mobility models of traces in the seed
dataset, we compute their semantic similarity as well as
the best semantic mapping between their locations. Note
that the semantic similarity is quantifying the similarity of
two mobility models, not that of two location traces. This
incorporates the similarity between statistical information in
the traces rather than their exact sequence of locations. We
then aggregate all the location matchings across all seed trace
pairs, with weights based on the semantic similarity between
mobility models, and construct a location semantic graph,