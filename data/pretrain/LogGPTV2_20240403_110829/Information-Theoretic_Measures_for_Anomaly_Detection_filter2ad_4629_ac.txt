S
I
I
I
I
12 
14 
16 
16 
8 
sequence lenglh 
10 
(a) Conditional  entropy of in-bound and out-bound email. 
-e- *-me0 + s-m20 
t so-in80 
6 
8 
10 
sequame length 
20 
(b) Misclassification  rate of in-bound email 
14 
16 
12 
I8 
0.02 - 
). 
- 
E 0.015 - 
- 
DO1 - 
0.005 L 
12 
' 
14 
' 
16 
' 
18 
0 
2 
4 
6 
' 
6 
6 
sequellce length 
' 
10 
(c) Misclassification  rate of out-bound email. 
IO 
8 
sequence length 
12 
14 
16 
18 
(d) Relative conditional entropy. 
~
'
'
'
'
>
'
'
sequence lenglh 
(e) Accuracy/cost trade-off. 
2 
4 
10 
8 
sequence lengfh 
6 
18 
(f) Estimated accuracylcost  trade-off. 
14 
16 
12 
Figure 2. Results on MIT Lincoln Lab sendmail  BSM data. 
137 
O L  
2 
' 
4 
x  10-3 
0 6 -  
2 0.6 - 
P 
0 4 -  
0 2 -  
I 
3.3  MIT Lincoln Lab Network Data 
A major challenge in  anomaly detection is to determine 
the granularity of the subject. For example in modeling user 
behavior, we need to decide whether to build separate pro- 
files  for weekdays and  weekends,  and  for  the  weekdays, 
whether  finer  time  segments,  e.g., mornings,  afternoons, 
and evenings, are necessary  [ 171.  Likewise  for a network, 
we need to decide whether we should build models for each 
host,  service,  or some combinations  of  the  two.  Without 
proper guidelines and tools, this remains an ad hoc process. 
Here we studied whether we can measure the regularity of 
network data and use it to guide data partitioning, which is 
equivalent to  subject refinement,  and to  help  feature con- 
struction (and hence model building). 
We used the tcpdump data developed and distributed by 
MIT Lincoln  Lab  for the  1998 DARPA  evaluation  in  our 
experiments.  The data contains traffics in  a simulated mil- 
itary network that consists of  hundreds of  hosts.  We  pro- 
cessed four days’ tcpdump data using a modified version of 
Bro [24], a programmable IDS with  a robust packet  filter- 
ing and re-assembly  engine.  Each record describes a con- 
nection  using  the  following features:  timestamp, duration, 
source port, source host, service (i.e., destination port plus 
protocol type), destination host, source bytes (i.e., number 
of bytes from source to destination), destination bytes, and 
flag  (summarizing the hand-shake behavior).  We  used the 
connection  data  of  each day  as  a  separate  set for experi- 
ments.  We  also separated out  the  intrusions  to  create  the 
pure normal datasets. 
We computed entropy, i.e., irregularity, for each (normal) 
dataset. Here, each data point is simply a connection record 
with the timestamp removed.  In  order to achieve high de- 
tection  performance with  low  false  alarm  rate,  the  dataset 
needs to be as regular as possible, i.e., its entropy as small 
as possible (see discussion  in  Section 2.1).  If  the entropy 
is large, then  we should try to further partition the data set 
into more regular subsets. Table  1 shows the entropy of the 
original (unpartitioned) datasets  and the subsets.  Here the 
entropy after partitioning is the average of the entropy val- 
ues of all the subsets.  We can see the entropy values of the 
original datasets are very large. This implies that if we build 
a model using dataset that contains all hosts and all services, 
the data may  be  too irregular  for the  model to work well. 
We  tried  all  features  to  select the  one that  results in  sub- 
sets with the smallest entropy values.  Destination host was 
then used for partitioning the data into per-host subsets. We 
see that the entropy is significantly decreased, which means 
that each subset is much more regular.  If we further parti- 
tion the data into per-service subsets, the entropy continues 
to decrease but not as dramatically. Note that this data par- 
titioning process is equivalent to classification process (see 
Section 2.4) since both use reduction  in entropy, i.e., infor- 
Table 1. Entropy of  network connection data. 
Date  1)  Original  1  per-Host  I  (further) Der-Service  I 
2.60068 
2.69049 
3.3 1312 
2.69542 
I 
, 
mation gain, as the guiding principle. 
In previous work, we showed that introducing some per- 
host and per-service  temporal  and statistical  features, e.g., 
“the count of connections to the same host as the current one 
in  the  past  2  seconds”,  to the  connection  data can  signifi- 
cantly improve the detection performance of network mod- 
els  [ 171.  However,  we  did  not develop  a means to deter- 
mine the proper time window, e.g., 2 seconds, for comput- 
ing the features.  In the case study here,  we explored if we 
can use conditional entropy to determine  the time window. 
We created sequences of service, destination host, flag, and 
the combination  of  the  three,  from the  connection data as 
follows:  using  a sliding  time  window  of  n seconds  and a 
step of one connection, scan the connection records that fall 
within  the  past  n seconds  with  regard  to  the  current con- 
nection  and put all the services (or destination hosts, flags, 
etc.)  into a short sequence.  Given a set of such sequences, 
we then  compute the conditional entropy of  sequence z of 
length Ic  given its subsequence (prefix) y of length Ic-  1, i.e., 
the uncertainty of determining the next service (or host, flag, 
etc.) given the past services (or hosts, flags, etc.) Since the 
sequences can have different lengths (i.e., for each n. there 
can  be different  ICs) due to  the  fact  that  the  traffic  volumc 
per time window  is not constant, we first computed the en- 
tropy  for each subset of  Ic-length sequences, then  used  the 
weighted  sum of these entropy values as the entropy of en- 
tire  set.  We  used  different time  windows,  with  an  incre- 
ment  of  2  seconds,  e.g., 2, 4, 6, 8,  10, etc.  to  create the 
sequences and compute the conditional entropy. From Fig- 
ures 3(a), 3(b), 3(c), and 3(d), we can see that, in general, 
conditional entropy decrease  as  window  size grows.  Intu- 
itively, this is because the more information is included, the 
smaller the uncertainty. We can also see that the conditional 
entropy on flag sequences is very low, indicating that, in the 
normal dataset, connections within a time window are likely 
to have  similar behavior with regard to network protocols, 
i.e., they  all have the normal  flags or error flags (e.g., con- 
nection failures due to network congestion). 
As in previous work [ 171, for each time window, we con- 
structed a set of temporal and statistical features to (approx- 
imately) capture the per-host and per-service sequential de- 
pendencies, e.g., “for the connections in the past 2 seconds, 
the  percentage  that  have the  same destination  host  as the 
current one”, “the percentage  of different hosts”, and “the 
percentage of error flags”, etc.  We  added these features to 
138 
1 -  
$ 0 6 -  
5 0.6 - 
0.4. 
0.2 - 
'
I
8 
"
6 
Ome mndw $me 
L
20 
4 
(a)  Conditional entropy: destination only. 
10 
12 
18 
14 
16 
'
'
'
0 
0 
I
2 
0.2: 
02 
: O R f  - 
n 
0.1 
0.05 
0 
2 
4 
8 
6 
IO 
lime window w e  
18 
(c) Conditional entropy: flag only. 
14 
12 
16 
O L   " '  " '  " ' 
0 
12 
16 
18 
14 
4 
2 
6 
10 
Itme wndow $88 
8 
(b) Conditional entropy: service only. 
t B 
+ Wednesday 
1 4 -  
1.2- 
% p  1 -  
- 
- 
$ 0.8 
D 
0 6 -  
- 
0.4 
- 
0.2 
01  " " "  " 
0 
10 
18 
12 
14 
18 
6 
8 
4 
2 
11-  window 5118 
(d) Conditional entropy: service, destination, and Bag. 
1 
0 
2 
4 
6 
8 
lime wndow scze 
10 
12 
14 
16 
18 
(e) Misclassification  rate: normal and intrusion data 
Figure 3. Results on MIT Lincoln Lab tcpdump data. 
139 
the connection records and applied RIPPER to build classi- 
fiers  as anomaly detection models.  Our goals were to study 
how the data partitioning scheme based on entropy and the 
feature construction  process  based  on  conditional entropy 
affect the performance of detection  models.  We used 80% 
of  normal data for training  and the remaining 20% of nor- 
mal data as well as the intrusion  data for testing,  Two fac- 
tors determine how  a  dataset used  in  the experiments was 
derived  from the  original  dataset:  partitioning  -  none,  by 
host, or (by host  first and further) by  service;  and  tempo- 
ral and statistical features - none, or using a particular time 
window to compute and add the features.  For the datasets 
without partitioning, we used the destination host of a con- 
nection as its class label, for the per-host datasets, we used 
service, and for the per-service datasets, we used flag. 
Figure 3(e) shows the misclassification rates of anomaly 
detection  models constructed  from these  datasets.  A  win- 
dow size 0 means that no temporal  and statistical features 
are added. The misclassification rates of all per-host models 
(and likewise all per-service models) of the same time win- 