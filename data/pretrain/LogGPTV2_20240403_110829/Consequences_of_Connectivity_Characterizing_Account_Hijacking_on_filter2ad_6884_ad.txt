F
D
C
100%
75%
50%
25%
0%
0 30
100
200
Days since last tweet
300
compromise
random
Figure 6: User retention of victims post-compromise com-
pared to a random sample of Twitter users. We ﬁnd 40%
of compromised accounts were not active in the last month
compared to 17% of random accounts.
Our results, shown in Figure 7, indicate that 57% of com-
promised users lose followers post-compromise compared to
only 18% of random users. Again, we cannot conclusively
determine whether this is a direct result of compromise. One
alternative explanation is that compromised victims were
participants in a fake follower scheme [25], after which other
victims cleaned up their social connections upon becoming
uninfected (or voluntarily leaving the program), thus reduc-
ing the follower counts of all parties involved. Whichever
the conclusion, it is clear that compromised users have a
higher likelihood of becoming more isolated from the rest of
Twitter, stymieing their future engagement.
4.3 Controlling Hijacked Accounts
Criminals author spam tweets from hijacked accounts in
one of two ways: directly with control of a victim’s username
and password, browser, or cookie, or alternatively via an ap-
plication with a valid OAuth token (approved by either the
victim or the criminal; we cannot distinguish which). We
observe that 30% of spam tweets sent via a victim’s account
originate from the web and mobile sites where criminals re-
quire direct access. Miscreants generate the remaining 70%
of tweets through long tail of over 9,900 applications. We ex-
plore some of the most popular applications used to control
compromised accounts further in Section 6.
495●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
F
D
C
100%
75%
50%
25%
0%
−200 −100
0
Change in followers
100
200
compromise
random
Figure 7: Change in follower counts of victims post-
compromise compared to a random sample of Twitter users.
We ﬁnd 57% of compromised accounts lose relationships
compared to only 18% of random users.
In contrast, spammers operating fraudulent accounts es-
chew any requirement of installing an application, authoring
94% of spam tweets via the web and mobile sites. Users post
legitimate content on the other hand—measured in terms
of both memes as well as a random sample of tweets se-
lected uniformly throughout our collection period—65% of
the time via clients owned and operated by Twitter (e.g.,
Twitter for Android, Twitter for iOS, TweetDeck) and other
sanctioned cross-posting platforms such as Tumblr and Face-
book.
Our ﬁndings indicate that platform abuse via the API
contributes substantially to the control of compromised ac-
counts. Assuming these applications are unwittingly in-
stalled by victims (as opposed to criminals controlling their
credentials),
improved API safeguards such as detecting
anomalous ﬂuxes in application installs as well as near-
duplicate content being posted by an application can reduce
the spread of compromise.
5. SOCIAL NATURE OF COMPROMISE
A critical question in relation to account hijacking is how
criminals obtain access to a victim’s account. We ﬁnd evi-
dence that infections are dominated by social contagions—
phishing and malware campaigns that propagate along the
social graph, abusing the trust that users place in their
friends. We examine how this trust inﬂuences the rapid
spread of compromise and how criminals bootstrap conta-
gions that fan out to millions of users.
5.1 Social Contagions
We measure the connectivity of
infected users and
meme participants to understand whether compromise, like
memes, spreads along the social graph. Given our crawl of
the Twitter graph G(V, E), we denote a victim as a single-
ton if no edge exists between the victim and another user
infected by the same contagion (e.g., another user in the
same cluster).
We ﬁnd that 88% of contagions exhibit connectivity be-
tween victims, where an average of 56% of compromised
users have at least one neighbor that is also compromised.
These contagions account for 95% of all spam tweets sent by
compromised accounts. As we discussed in Section 3.6, our
down-sampled dataset may result in users (and thus their
Figure 8: Example of calculating the number of incom-
ing edges through which an infection could propagate for a
synthetic graph.
relationships) being omitted, leading to a higher estimate of
singleton infections. To understand this bias, we compare
the connectivity of retweeted memes, where we ﬁnd 76% of
participants share an edge with a participating friend. As-
suming all retweets spread via the social graph and abide
the same sample rate as contagions, this would indicate an
average of 0.56/0.76, or 74% of compromised users share at
least one relation with another victim.
The remaining 12% of compromised clusters are composed
entirely of singleton infections. These compromises may
be tied to password guessing, database dumps, or exter-
nal contagions, as discussed in Section 2. We caution that
it may be possible for external contagions, such as those
spread through email social graphs, to reﬂect as though
they spread along the Twitter social graph. Similarly, nat-
ural homophily [19] in friends using the same web services
may result in database dumps exhibiting social connectivity.
As such, we cannot deﬁnitively say whether the majority of
compromise spreads within Twitter, but there is a strong
tendency for victims to be connected.
5.2
Inﬂuence of Compromised Neighbors
Neighbors connected to a user—either in real life or in
an online social network—inﬂuence that user’s decision-
making. This inﬂuence manifests in information cascades
including the adoption of online memes [1, 2, 5, 23], health
and lifestyles choices [6], and the spread of biological in-
fections [21]. We observe that compromise in online social
networks abides by the same process, where users with in-
fected friends appear more likely to fall prey to malware and
phishing scams as a result of the trust they place in their
social connections.
To gauge the inﬂuence of compromised neighbors, we mea-
sure the probability p(i|k) that a user becomes infected given
they have k previously infected neighbors. Figure 8 shows
a sketch of our approach—adopted from social science tech-
niques for measuring the virulence of memes [2,7]. To start,
we label all of the vertices V in our graph crawl G(V, E) as
either infected (grey in our example) or uninfected (white).
We treat each cascade independently, running this process
once per each cluster in our dataset. Next, we mark each
node with its infection time ti—the timestamp of the ﬁrst
spam tweet a victim posts belonging to the contagion in
question—or ∞ if the node is not infected. Given a di-
rected edge E(s, d) between a source s and destination d,
we consider the source to be aninﬂuencing neighbor if s is
infected and t(i,s) < t(i,d). This metric captures whether
a neighboring infection could spread to the destination or
whether that destination was already infected. Finally, we
count the total number of inﬂuencing neighbors k for each
496●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
F
D
C
100%
75%
50%
25%
0%
Delay between onset and participation (hours)
100
1,000
1
10
Figure 9: Likelihood of a user joining a cascade given k-
neighbors already participate in the cascade. Both compro-
mise and memes spread via a social process where friends
inﬂuence a user’s decisions.
user in V and calculate p(i|k) for all possible k. In our ex-
ample, p(i|k = 1) = 0.5, while p(i|k = 2) = 1. To analyze
all contagions at once, we calculate the average p(i|k) across
contagions, weighting each contagion equally independent of
size. To serve as a comparison, we repeat this same process
for all of the memes in our dataset.
Our results, shown in Figure 9, demonstrate that com-
promise is more eﬀective at spreading as more of a user’s
neighbors fall victim to attacks. We ﬁnd that the probabil-
ity of a victim becoming compromised increases from 0.1%
with only one neighboring infection to 1% when a user has 20
neighboring infections. This behavior is nearly identical to
memes in the early stages, indicating that compromised vic-
tims, like meme participants, are inﬂuenced by their peers.
In both cases, the inﬂuence of friends eventually tapers oﬀ
to a constant likelihood—a phenomenon previously observed
by social scientists [2, 23]—but we ﬁnd that compromised
peers have stronger lasting power.
Our results highlight that compromise occurs as a social
process where users in social networks are vulnerable to the
bad decision-making of their neighbors. In contrast, if large-
scale compromise was more frequently related to database
breaches eﬀecting millions of users or password guessing,
we would expect the likelihood of a victim’s compromise
to be independent of their number of compromised peers.
Consequently, we argue that early outbreak detection in so-
cial networks is critical as it both prevents neighbors from
spreading their infection as well as restricts infections to
their nascent stage before they become 10–100 times more
eﬀective at spreading.
5.3 Seeding Compromise Diffusions
If compromise is a social contagion, there remains a ques-
tion as to how criminals bootstrap the initial cascade eﬀect.
We ﬁnd that 35% of compromise campaigns rely on more
than 100 fake accounts to start the infection process. Of
these accounts, 25% tweet within 24 hours of the onset of
the compromise campaign. (The remaining accounts join at
a later date, presumably to re-seed new infection chains.)
Our dataset cannot elucidate how the attacker started the
remaining 65% of compromise campaigns. One hypothesis
is that criminals obtain a small number of compromised ac-
counts via targeted attacks or by directly purchasing them
from the underground, in turn compromising the victim’s
friends to start a cascade.
compromise
fraudulent