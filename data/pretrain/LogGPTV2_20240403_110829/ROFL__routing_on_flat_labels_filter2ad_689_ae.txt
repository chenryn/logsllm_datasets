head for peering can be reduced to that of multihoming with the
bloom ﬁlter optimization discussed in Section 4.2, at the expense
of larger per-router state requirements. Surprisingly however, the
cost of a multi-homed join is not signiﬁcantly larger than that of a
single-homed join. This happens because although there are typi-
cally 75-100 ASes in an AS’s up-hierarchy, and the multi-homed
join must discover a successor through each, there are typically a
much smaller number of unique successors. We leveraged this ob-
servation to optimize the multi-homed join, by eliminating redun-
dant lookups that resolve to the same successor. Next, we roughly
extrapolated these results to an Internet-scale system with 600 mil-
lion IDs, and estimate that the ephemeral join requires around 14
messages, the single-homed join requires around 80 messages, and
the multi-homed join requires around 100 messages. Moreover, it
should be noted that these control messages are more lightweight
than traditional routing protocols, since intermediate routers do not
need to process these messages in their slow-paths. However, we
found that using the bloom ﬁlter optimization reduced the overhead
of the peering join to be equal to the overhead of the recursively
multihomed join. Finally, the state at hosting routers increases with
the number of hosts and the number of ﬁngers hosts maintain. We
found that with 600 million IDs each maintaining 256 ﬁngers, we
required on average 184 Mbits per AS to store hosting state.
Stretch: Figure 8b shows a CDF of data packet stretch for single-
homed joins. Stretch decreases with the number of proximity-based
]
s
t
e
k
c
a
p
[
d
a
e
h
r
e
v
o
i
n
o
J
 350
 300
 250
 200
 150
 100
 50
 0
Ephemeral
Single-homed
Rec. multi-homed
Peering
 1
 10
 100  1000  10000
IDs
(a)
n
o
i
t
c
a
r
f
e
v
i
t
l
a
u
m
u
C
 1
 0.8
 0.6
 0.4
 0.2
 0
ROFL 60 fingers
ROFL 160 fingers
ROFL 280 fingers
BGP-policy
 1  2  3  4  5  6  7  8  9  10
Stretch
(b)
 2.5
 2
 1.5
 1
 0.5
h
c
t
e
r
t
S
 0
 0.1  1
 10  100 1000 10000 100000
average finger cache size [Mbits per AS]
(c)
Figure 8: Interdomain routing: (a) Comparison of joining strategies (b) Stretch (c) Effect of pointer caching
ﬁngers: with 60 ﬁngers, ROFL’s average stretch is 2.8, while stretch
is 2.3 for 160 ﬁngers. If hosts perform a join across peering links
as well, the stretch increases to 2.8 for 160 ﬁngers. We found that
stretch decreased slightly (not shown here) as the number of IDs
in the system increased. This decrease happens because there is a
highly uneven distribution of hosts across ASes in the Internet, and
hence as we scale up the number of IDs the chances that the source
and destination are in the same AS increases. We roughly extrapo-
lated these results to an Internet-scale graph with 600 million IDs,
and estimated 128 ﬁngers (peering join overhead of 200) gives a
stretch of around 2.9, and 340 ﬁngers (peering join overhead of
445) gives a stretch of around 2.5. However, increasing the num-
ber of ﬁngers also increases the size of the join messages that carry
proximity-ﬁngers. For example, with 256 ﬁngers the message size
increases to 1638 bytes. If we assume an MTU of 1500 bytes, a
256-ﬁnger single-homed join requires 258 IP packets.
Although a stretch of 2-3 seems high, it need only be suffered by
the ﬁrst packet: stretch for remaining packets can be reduced to one
by exchanging the list of ASes above the destination in the hierar-
chy (Section 5.1), or by caching the destination’s AS. As a compar-
ison point we plot the stretch incurred today by BGP policies, mea-
sured using Routeviews traces (shown as BGP-policy in Figure 8b).
In addition, we found that the isolation property contributes signif-
icantly to reducing stretch (through consistency checks in our sim-
ulator, we veriﬁed there were no cases in any of our experiments
when the isolation property was broken). Next, Figure 8c shows
pointer caching (Section 4.1) reduces stretch further. In these ex-
periments, we model each AS with a pointer cache as a single node,
and make the size of this cache proportional to the number of hosts
in that AS. The x-axis shows the average amount of pointer caching
state per AS, extrapolated to an Internet-scale topology with 600
million hosts. An average pointer cache size of 20M entries per AS
reduces stretch from 2 to 1.33 (note that routers today can support
millions of entries). Finally, we found that using bloom ﬁlters for
peering as described in Section 4.2 results in a stretch of 3.29 with
size 18 Mbits/AS, though this stretch can be reduced to 2.5 with
more ﬁngers or larger 74 Mbit bloom ﬁlters.
Failures: Stub ASes (ASes near the network edge) are believed
to be signiﬁcantly more unstable than ISPs near the core [14]. In
this experiment we fail randomly selected stub ASes and measure
two metrics. First, we measure the number of paths affected by the
failure. We found on average 99.998% of Internet paths were un-
affected by the failure, indicating that the effects of failures were
well contained. Next, we found that ROFL required on average
4950 messages to repair successors after a stub AS failure, which
roughly corresponds to the number of identiﬁers hosted in the failed
stub AS.
6.4 Summary of results
Intradomain: Based on Rocketfuel traces, we simulated ROFL
over four ISPs, ranging in size from 201 to 604 internal routers.
ROFL is able to provide a routing stretch of 1.2 to 2 with 9Mbits of
pointer cache, with reasonable load balance across routers. Hosts
typically complete joining in less than 40ms, with less than 45
control messages generated per host. ROFL correctly heals from
partitions, host failures, and host mobility with control overhead
roughly that of rejoining the affected hosts.
Interdomain: We extrapolated our simulation results over the AS
graph to the Internet scale system with 600 million hosts, and esti-
mated that a ROFL host can join across all providers and peers and
acquire 340 ﬁngers with ∼445 control messages. This overhead can
be reduced for unstable hosts by performing a single-homed join
(∼75 messages), or an ephemeral join (∼14 messages). The host
can route packets in a manner that respects several inter-AS poli-
cies, with an average stretch of 2.5. This stretch may be reduced
to 2.1 by roughly doubling the number of ﬁngers. By maintaining
pointer caches at border routers, this stretch may be reduced fur-
ther (to 1.33 with on average 20 million entries of caching space
per AS). Finally, ASes may reduce join overhead by leveraging
bloom ﬁlters to eliminate joins across peering links. This reduces
join overhead to ∼100 messages, but requires 74 Mbits of bloom
ﬁlter state per AS.
7. RELATED WORK AND DISCUSSION
While we’ve drawn general insights from many sources, our de-
tailed mechanism owes much to two particular sources: VRR [7],
which was the basis for our intradomain design, and Canon [17],
which was the basis for our interdomain design. Given that
VRR was designed for a very different context, ad-hoc routing,
we build upon VRR by introducing a simpliﬁed path construc-
tion/maintenance protocol, a protocol to ensure correctness in the
presence of network partitions, and several approaches to improve
scalability and resilience to churn. We similarly extend Canon, by
modifying the design to support several Internet policies, and lever-
aging proximity-based ﬁngers to reduce stretch.
The project that seems to have the most in common with our
design objectives is TRIAD [10], and its content routing design
in [18]. TRIAD routes on URLs by mapping URLs to next-hops.
In theory, every network router could do this but, because of load
concerns, TRIAD only performs content routing at gateways (ﬁre-
walls/NATs) between realms and BGP-level routers between ASes.
Forwarding state is built up in intermediate content routers as pack-
ets are routed, and name sufﬁx reachability is distributed among
address realms just like BGP distributes address preﬁxes among
ASes. It thus relies on aggregation to scale, and will fail if object
locations do not follow the DNS hierarchy closely. If, to counteract
this, name-level redirection mechanisms are used to handle hosts
whose names do not match network topology, then this becomes
essentially a resolution mechanism. This last comment also applies
to IPNL, which also does some routing on FQDNs.
These previous forays into the name-routing arena suggest not
only its difﬁculty but also its worth. Routing on names brings with
it several architectural beneﬁts, as we alluded to in the Introduction,
but most of all it breaks out of a long-standing architectural mind-
set. The art of architecture is gracefully maneuvering within the
boundaries of the possible. Our goal here is to investigate whether
those boundaries can be expanded, not to seek grace.
Our design has a reasonable set of features; multiple delivery
models, a fair amount of policy control, and some, but not much,
trafﬁc control. The remaining question, then, is about performance.
On that score, we view this work as the beginning, not the end. The
results are close enough to tempt, but not enough to satisfy.
8. REFERENCES
[1] I. Abraham, A. Badola, D. Bickson, D. Malkhi, S. Maloo, S. Ron,
“Practical locality-awareness for large scale information sharing,”
IPTPS, February 2005.
[2] T. Anderson, T. Roscoe, D. Wetherall, “Preventing Internet
denial-of-service with capabilities,” SIGCOMM Comput. Commun.
Rev., 34(1):39–44, 2004.
[3] H. Balakrishnan, K. Lakshminarayanan, S. Ratnasamy, S. Shenker, I.
Stoica, M. Walﬁsh, “A layered naming architecture for the Internet,”
ACM SIGCOMM, August 2004.
[4] H. Ballani, Y. Chawathe, S. Ratnasamy, T. Roscoe, and S. Shenker,
“‘Off by Default!,” HotNets, 2005.
[5] H. Ballani, P. Francis. ”Towards a Global IP Anycast Service,” ACM
SIGCOMM, Aug 2005
[6] B. Bloom, “Space/time trade-offs in hash coding with allowable
errors,” Commun. ACM, vol. 13, no. 7, pp. 422-426, July 1970.
[7] M. Caesar, M. Castro, E. Nightingale, G. O’Shea, A. Rowstron,
“Virtual ring routing: network routing inspired by DHTs,” ACM
SIGCOMM, September 2006.
[8] M. Castro, P. Drushel, A. Ganesh, A. Rowstron, and D. Wallach,
“Secure routing for structured peer-to-peer overlay networks” OSDI,
December 2002.
[9] M. Castro, P. Druschel, Y. Charlie Hu, A. Rowstron, “Exploiting
network proximity in peer-to-peer overlay networks,” Microsoft
Research technical report MSR-TR-2002-82, 2002.
[10] D. Cheriton, M. Gritter, “TRIAD: a scalable deployable NAT-based
Internet architecture,” Technical report, January 2000.
[11] D. Clark, R. Braden, A. Falk, V. Pingali, “FARA: reorganizing the
addressing architecture,” SIGCOMM FDNA Workshop, August 2003.
[12] S. Deering, D. Cheriton. ”Multicast Routing in Datagram
Internetworks and Extended LANs,” ACM TOCS, 1990.
[13] J. Douceur, “The Sybil Attack” IPTPS, March 2002.
[14] A. Feldmann, O. Maennel, Z. Mao, A. Berger, B. Maggs, “Locating
Internet routing instabilities,” ACM SIGCOMM, August 2004.
[15] B. Ford, “Unmanaged internet protocol: taming the edge network
management crisis,” HotNets, Cambridge, MA, Nov. 2003.
[16] P. Francis, R. Gummadi, “IPNL: a NAT-extended Internet
architecture,” ACM SIGCOMM, August 2002.
[17] P. Ganesan, K. Gummadi, H. Garcia-Molina, “Canon in G major:
designing DHTs with hierarchical structure,” ICDCS, March 2004.
[18] M. Gritter and D. Cheriton, “An Architecture for Content Routing
Support in the Internet,” In the USENIX Symposium on Internet
Technologies and Systems, March 2001.
[19] M. Handley and A. Greenhalgh, “Steps towards a DoS-resistant
internet architecture,” FDNA, 2004.
[20] J. Jannotti, “Network layer support for overlay networks,” PhD
thesis, MIT, August 2002.
[21] J. Jannotti, D. K. Gifford, K. L. Johnson, M. F. Kaashoek, J. W.
O’Toole Jr, ”Overcast: Reliable Multicasting with an Overlay
Network,” OSDI, October 2000.
[22] P. Jokela, P. Nikander, J. Melen, J. Ylitalo, J. Wall, “Host identity
protocol - extended abstract,” in Wireless World Research Forum,
February 2004.
[23] A. Jonsson, M. Folke, B. Ahlgren, “The split naming/forwarding
network architecture,” Proc. Swedish National Computer
Networking Workshop (SNCNW), September 2003.
[24] D. Krioukov, kc claffy, “Toward compact interdomain routing,”
Unpublished draft,
http://www.krioukov.net/∼dima/pub/cir.pdf
[25] D. Krioukov, K. Fall, X. Yang, “Compact routing on Internet-like
graphs,” IEEE Infocom , March 2004.
[26] D. Mazieres, “Self-certifying ﬁle system,” PhD thesis, MIT, May
2000.
[27] A. Myers, E. Ng, H. Zhang, “Rethinking the service model: scaling
ethernet to a million nodes,” HotNets, November 2004.
[28] M. O’Dell, “GSE - an alternate addressing architecture for IPv6,”
ftp://ds.internic.net/internet-drafts/draftietf-ipngwg-gseaddr-00.txt,
1997.
[29] L. Peterson, S. Shenker, J. Turner, “Overcoming the Internet impasse
through virtualization,” HotNets, November 2004.
[30] A. Rowstron, P. Druschel, “Pastry: scalable, distributed object
location and routing for large-scale peer-to-peer systems,”
IFIP/ACM Middleware, November 2001.
[31] J. Saltzer, “On the naming and binding of network destinations,”
RFC 1498, August 1993.
[32] N. Spring, R. Mahajan, D. Wetherall, “Measuring ISP topologies
with Rocketfuel,” ACM SIGCOMM, August 2002.
[33] I. Stoica, D. Adkins, S. Zhuang, S. Shenker, S. Surana, “Internet
indirection infrastructure,” ACM SIGCOMM, August 2002.
[34] I. Stoica, R. Morris, D. Lieben-Nowell, D. Karger, M. Kaashoek, F.
Dabek, H. Balakrishnan, “Chord: a scalable peer-to-peer lookup
protocol for Internet applications,” IEEE Transactions on Networks,
11(1) 17-32, 2003.
[35] L. Subramanian, S. Agarwal, J. Rexford, R. Katz,“Characterizing the
Internet Hierarchy from Multiple Vantage Points,” in IEEE Infocom
2002, June 2002.
[36] L. Subramanian, M. Caesar, C. Ee, M. Handley, M. Mao, S. Shenker,
I. Stoica, “HLP: a next-generation interdomain routing protocol,”
ACM SIGCOMM, August 2005.
[37] M. Walﬁsh, H. Balakrishnan, S. Shenker, “Untangling the web from
DNS,” NSDI March 2004.
[38] M. Walﬁsh, J. Stribling, M. Krohn, H. Balakrishnan, R. Morris, S.
Shenker, “Middleboxes no longer considered harmful,” OSDI,
December 2004.
[39] F. Wang, L. Gao, “Inferring and characterizing Internet routing
policies,” Proc. Internet Measurement Conference, October 2003.
[40] Abraham Yaar, Adrian Perrig, Dawn Song, “Pi: A Path Identiﬁcation
Mechanism to Defend against DDoS Attacks,” IEEE Symposium on
Security and Privacy, 2003.
[41] X. Yang, “NIRA: a new Internet routing architecture,” SIGCOMM
Workshop on Future Directions in Network Architecture (FDNA),
August 2003.
[42] X. Yang, D. Wetherall, and T. Anderson, “A DoS-limiting Network
Architecture,” ACM SIGCOMM 2005, August 2005.
[43] CAIDA, “Skitter,” http:
//www.caida.org/tools/measurement/skitter.
[44] “FIND: future Internet network design,”
http://find.isi.edu, December 2005.
[45] “GENI: global environment for network innovations,”
http://www.geni.net
[46] Internet Systems Consortium, “Domain survey host count,”
http://www.isc.org/index.pl?/ops/ds/, July 2005.
[47] ‘NewArch project: future-generation Internet architecture,‘’
http://www.isi.edu/newarch/
[48] “Route Views Project,” http://www.routeviews.org.