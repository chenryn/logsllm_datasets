devices of the same class (e.g., enterprise hard drives) on
both local and remote storage (if any).
4. PROOFS OF DATA RESIDENCY
4.1 Setup and Audit Phases
A PoDR scheme is to be carried out in two phases, Setup
and Audit:
• Setup: In the setup phase, V as a data owner gener-
ates a secret key sk based on the security parameter λ.
Next, V encodes the ﬁle F into (cid:101)F using the secret key
sk. Finally, V sends the encoded ﬁle (cid:101)F to P, discards
both F and (cid:101)F , only keeps the secret key sk and some
metadata needed for conducting the audit.
• Audit: In the audit phase, V conducts a data res-
idency checking by challenging P to prove that the
original ﬁle F can be reconstructed from data main-
tained in its local drives. This phase comprises two
stages, challenge-response and veriﬁcation.
– Challenge-response: The veriﬁer ﬁrst obtains an
environment proﬁle E based on which she could
assess the response latencies.
The veriﬁer V sends v challenges to the prover,
and P replies with the corresponding responses.
The challenges are sent one-by-one. Upon receipt
of a response or a special symbol ⊥, the veriﬁer
V proceeds by carrying out the following:
1. Generate and send the next challenge to P.
V can choose not to send any challenge.
2. Generate and send to itself the special symbol
⊥ which will arrive at a time speciﬁed by V.
V can choose not to send the symbol ⊥1.
(cid:104)q1, . . . , qv(cid:105) be
Let
sent,
(cid:104)f1, . . . , fv(cid:105) the corresponding responses, and
(cid:104)t1, . . . , tv(cid:105) their latency. We call v the audit size.
– Veriﬁcation. Based on the challenges, the corre-
sponding responses and latencies (cid:104)t1, . . . , tv(cid:105), to-
gether with the environment proﬁle E, V decides
whether to accept P as passing the audit.
the v
challenges
Overall, the algorithms in a PoDR scheme consist of:
(1) the key generation and ﬁle encoding algorithms used
during the setup, together with (2) the challenge generation
algorithms, and (3) the veriﬁcation algorithm used in the
audit. Implicitly, the scheme also requires an algorithm for
the prover to generate the responses.
4.2 Security and Adversarial Model
We now formalise the capabilities and constraints of
the adversary. First, let us deﬁne by T net, T loc and T rmt
three positive random variables, each follows a predeﬁned
distribution. The random variable T net corresponds to the
challenge-response transmission time, T loc corresponds to
fetching time of an honest prover in producing the response,
and T rmt corresponds to the fetching time when the data
are loaded from the remote storage. The environment
proﬁle E is a description of the distributions of T net, T loc
and T rmt. The prover also has access to, but cannot
inﬂuence, the environment proﬁle E.
Storage preparation during setup. During the setup phase,
the prover applies a transformation on the received encoded
ﬁle (cid:101)F , obtaining (cid:104)D, (cid:101)D(cid:105). The portion D is to be kept in the
local drives, whereas (cid:101)D is to be kept in the remote storage
((cid:101)D could be empty). The prover initialises a cache C of
ﬁnite size.
Response generation during audit. For each challenge qi,
the prover can choose to compute the response from one of
the three probabilistic algorithms R, (cid:101)R or ˆR. All of these
access to D and (cid:101)D: R only reads from the local drives, (cid:101)R
algorithms have access to the cache C, but diﬀer in their
reads from both local and remote storages, and ˆR does not
read from any storage.
1Recall the next challenge can only be sent upon receipt of
the response of the previous one or the special symbol ⊥,
this allows V to send the next challenge without waiting for
the response.
4
i
, tloc
Given a challenge qi, the prover independently draws three
samples (tnet
) from the distributions T net, T loc,
T rmt respectively to obtain actual values of these three tim-
ings. Next, the prover decides to take one of the following
actions:
, trmt
i
i
1. Send R(qi, D, C) as response and set
2. Send (cid:101)R(qi,(cid:104)D, (cid:101)D(cid:105), C) as response and set
i + δi;
ti = tnet
i + tloc
i +(cid:101)δi;
ti = tnet
i + trmt
3. Send ˆR(qi, C) as response and set
where δi,(cid:101)δi and ˆδi are positive values chosen by the prover.
ti = tnet
i + ˆδi.
By the above deﬁnition, the prover can foresee all the
timing measurements and can inﬂuence the value of ti by
adding delays and choosing which algorithm it would use
in preparing the response. Nevertheless, it cannot speed-up
the timings further than what dictated by E. The cache C
is updated after every the response.
Remarks. The above formulation implies a strong adver-
sary that (1) has the knowledge of the actual time taken
to read and transmit the data; (2) is able to produce the
response as fast as an atomic loading operation2; and (3)
is able to arbitrarily delay the response. As discussed in
the threat model, it is necessary to consider such strong
adversary since the adversary would have full control of
both the local and remote servers.
4.3 Security deﬁnitions
Given the proﬁle E, we say that a PoDR scheme is (E,
ψ)-secure if, for any prover who passes the audit with prob-
ability at least ψ, there is a polynomial time algorithm to
reconstruct the original ﬁle F from D – a portion of data
that the prover stores locally (except with negligible proba-
bility of failure). The randomness is taken over the random
decisions made by the probabilistic algorithms, and the sam-
pling of the timings.
For a PoDR scheme and a proﬁle E, we call the smallest
upper bound on ψ(cid:48) such that the scheme is (E, ψ(cid:48))-secure the
false acceptance rate (denoted by ψ). We call the probability
that the honest prover, who keeps entire (cid:101)F in its local drives,
fails the audit the false rejection rate (denoted by γ).
5. POTENTIAL ATTACKS
In this section, we consider two data residency checking
protocols that incorporate latency measurements with well-
known PoR schemes [36, 26] in a straightforward manner,
and brieﬂy discuss how a dishonest prover who has relocated
signiﬁcant portion of the data to remote storages, to an ex-
tent that the original ﬁle cannot be reconstructed from its
local drives, can evade detection. We report detailed attacks
in Appendix C.
2We stress that the prover’s algorithms are still polynomial
time.
5
5.1 SW-PoR based data residency checking
The ﬁrst protocol is constructed on top of the PoR scheme
by Shacham and Waters (SW-PoR) [36]. The audit asks for
v data blocks and their associated homomorphic authenti-
cation tags. The prover passes the audit if the response is
valid (with respect to the SW-PoR scheme) and the response
latency is within an expected threshold.
The protocol’s logic is based on a premise that should the
dishonest prover have located signiﬁcant portion of the data
to remote storages, the extra time taken to retrieve the re-
quested data would make the overall latency exceed the ex-
pected threshold. Nevertheless, such a premise fails to con-
sider a possibility that the dishonest prover can still evade
the expected threshold by speeding up the time taken to
compute the response (i.e., aggregating the requested data
blocks). In particular, it can over-clock its processor or have
the remote servers concurrently compute the intermediate
values and then aggregate the intermediate values into the
ﬁnal response. We conduct experimental studies to illus-
trate feasibility of these attacks, and report the results in
Appendix C.1.
5.2
JK-PoR based residency checking
One possible mitigation for the previous attack is to elim-
inate computation time from the response latency, adopting
the authenticator-based PoR [26, 28]. In this scheme, the
data owner encodes her ﬁle using a redundant encoding and
authenticate all the blocks of the encoded data. During the
residency checking, the veriﬁer issues a single request that
asks for v randomly chosen data blocks (v is a security pa-
rameter) and measures the latency incurred by the storage
provider in delivering all those requested blocks.
Although the computation time is eliminated from the
response latency, an adversary can still reduce the latency
by distributing the fetching of the requested blocks. With
suﬃcient number of remote storage servers, the reduction
of fetching time can oﬀset the additional latency incurred
by accessing the remote storage. We empirically study the
eﬀectiveness of such evasion strategy and report the results
in Appendix C.2.
6. PROPOSED CONSTRUCTION
In this section, we present our construction for PoDR.
Our construction is built on top of the authenticator-based
PoR by Juels et al.
[26]. We ﬁrst give an overview of the
setup and audit phases. Next, we propose two implementa-
tion variants for the residency checking, a network-based im-
plementation N-ResCheck, and a trusted computing-based
implementation E-ResCheck. E-ResCheck illustrates an
interesting use-case of trusted computing, wherein having
the veriﬁer of a cryptographic protocol co-locating with the
prover enhances the security. Finally, we analyse the secu-
rity of our construction.
6.1 Setup
The original ﬁle F is divided into n blocks where the size
of each block is a parameter to be determined. The data
owner applies standard error-erasure code (such as the Reed-
consists of m = (1 + c)× n encoded data blocks (c > 0) such
that knowledge of any n blocks is suﬃcient to reconstruct
Solomon code [33]) on F , generating (cid:101)F . The encoded ﬁle (cid:101)F
F . We refer to the ratio n/m as code rate. (cid:101)F is identi-
indexed by a particular integer i ∈ [1..m]. The data owner
ﬁed by an unique ﬁle handle (cid:101)FID and each block in (cid:101)F is
appends to every encoded data block (cid:101)fi in (cid:101)F a b-bit MAC
obtaining fi ← (cid:101)fi||HM AC(sk,(cid:101)fi||(cid:101)FID||i), where HM AC()
of its content, ﬁle handle and index under her secret key sk,
is a keyed-hash function that returns b-bit output and ||
means concatenation. After entrusting the data to the stor-
age provider, the data owner can delete all local copies, keep-
ing only the secret key sk and some metadata for veriﬁcation
and reconstructing F from the outsourced blocks.
whereby V issues the challenge qi (qi ← (cid:101)FID||i), receives fi
ti. V extracts ˜fi from fi and computes HM AC(sk,(cid:101)fi||qi),
function Request(qi) is an interaction between V and P
from P, and at the same time measures the response latency
obtaining a b-bit MAC of ˜fi||qi under sk. V then compares
it against fi’s authentication tag (i.e., IsValid(sk, qi, fi)),
rejecting the audit if they are inconsistent4. On the other
hand, if all of the responses are valid, the veriﬁer will rely on
the number of late responses (w.r.t the latency threshold d)
to call the decision. If such number exceeds the late delivery
threshold l, V rejects the audit.
if ti > d then
late ← late + 1;
Q ← InitiateQuery(v)
late ← 0; f orged ← f alse;
for each qi ∈ Q do
ti, fi ← Request(qi);
if IsValid(sk, qi, fi) then
Algorithm 1 Residency Checking
1: procedure ResidencyChecking(v, d, l)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19: end procedure
end for
if f orged or (late > l) then
end if
f orged ← true;
Reject;
else
Accept;
end if
else
end if
6.2 Audit
To begin the residency checking, V ﬁrst obtains an en-
vironment proﬁle E (i.e. description of the distributions of
T net, T loc and T rmt) and decides on three parameters:
• v: The audit size, which is the number of blocks that
she would like to challenge P.
• d: The latency threshold, which is an expected latency
that a valid response should meet.
• l: The late delivery threshold, which is the number
of late responses (whose latency exceeds d) that V is
willing to tolerate.
We investigate how these parameters are to be chosen in
Section 7.
Next, V executes the residency checking procedure de-
tailed in Algorithm 1. The algorithm utilises three functions.
InitiateQuery(v) chooses v block indices at random3, each
is a challenge asking the prover for the corresponding data
block. The challenges are to be sent one-by-one. The
3This is not inconsistent with the description of the Audit
phase in Section 4. Since the block indices are chosen at
random and independent of one another, choosing them all
at once or at diﬀerent times would not aﬀect the randomness.
In addition, note that there is no sending and receiving of
the special symbol ⊥, in this residency checking procedure,
the next challenge can only be sent after response for the
previous challenge is received.
6
The parameters are chosen to meet the security and per-
formance requirements, in particular the false acceptance
rate (ψ), false rejection rate (γ) and total ﬁle expansion
factor (h). The three parameters b, c and s are to be de-
cided during the setup phase. The audit size v and the two
thresholds d, l can be determined during the audit phase,
or predetermined so that they are the same for all audit
sessions. The parameter setting also depends on the envi-
ronment proﬁle E. In practice, V can obtain information on
E using various mechanisms, depends on the implementation
details. We shall discuss two variants in the following.
6.3 N-ResCheck Implementation
The ﬁrst implementation variant, N-ResCheck, assumes
that the veriﬁer V and the prover P communicate over the
network. In this variant, the environment proﬁle E contains
information on network status. This information can be
obtained using various tools and techniques [10, 25]. The
latency observed by V accounts for the data fetching time
and challenge-response transmission time.
Guaranteeing the delivery of challenges and responses is
necessary, for P has to respond to every challenge. Our im-
plementation employs the reliable TCP [32] for transmission
of challenges and responses, despite its higher latency vari-
ance compared to other protocols such as UDP [31], which
suﬀers from packet loss. Although it is possible to design
a residency checking protocol which supports packet loss of
known rate, such variant would introduce diﬃculties in dif-
ferentiating dishonest prover who relocates the data from
the one who discards some of the blocks.
For a residency checking of size v on (cid:101)F which consists
The communication cost of N-ResCheck is reasonable.
of m s-byte blocks, the overall communication cost is
(8s + log m)× v bits. As we shall show later in Section 7, an
optimal choice of block size is 64 bytes and that of challenge
size v ranges from 250 to 400. With these parameters, the
overall communication cost for verifying the residency of a
1GB ﬁle is only a few KBs.
Limitations. The assumption that N-ResCheck makes on
the ability of V to obtain information regarding the network
status at audit time may not always be feasible. In addition,
the measured latency inevitably includes the transmission
time of the challenges and responses, adding noise to the
measurement and thus having a certain impact on the secu-
rity of the residency checking. To mitigate these limitations,
4Should the authentication tag be computed solely from (cid:101)fi,
P will be able to rightfully replace one block with another
that has the same tag and destroy the former. Since the
authentication tag in our protocol also covers the block ID,
which is chosen at random during the audit, such incident
will be detected with high probability.
we discuss in the next section another implementation vari-
ant that relies on a trusted unit co-locating with the drives
on the storage server. Such trusted unit can be provisioned
by various implementation mechanisms, for example by uti-
lizing the recently released Intel SGX processors [9].
6.4 E-ResCheck Implementation
The second implementation – E-ResCheck – entrusts a
trusted unit on the prover’s storage server (i.e. the trusted
unit and the drives are both installed on the same server)
to carry out the residency checking. Such unit is responsi-
ble for provisioning a protected execution environment (aka
enclave), which we shall refer to as Verifying Enclave (VE).
P can neither tamper with VE operations, nor change the
code and data loaded to it without being detected by V.
However, it can supply inputs for VE.
In E-ResCheck, the environment proﬁle E contains in-
formation on housekeeping operations at the OS level on
P(cid:48)s server, which arguably can be accurately estimated. VE,
representing the veriﬁer, conducts a residency checking as
speciﬁed in Algorithm 1. Unlike the previous variant, the
latency measured by VE accounts only for the fetching time
of the prover, excluding altogether the network time re-
quired for transmission. Without the potentially noisy fac-
tor, E-ResCheck oﬀers more reliable measurements, and
thus is more secure.
While we treat the trusted unit as an abstraction so that
it can be realised by various mechanisms, our implementa-
tion provisions VE using Intel Skylake processors with SGX
Enabled BIOS support [9]. Unlike special trusted unit hard-
ware such as IBM secure processor [5], these SGX-enabled
processors are now widely available in commodity systems.
The code running inside VE – the veriﬁcation code – can
be written by V, or by any other party and vetted by V to
ensure its correctness. Further, remote attestation mecha-
nism [12] allows V to check if the correct code is loaded into
VE. This mechanism also allows the veriﬁer and VE to estab-
lish shared secrets, which enables secure channel for their
for V to send the secret key to VE or
communication (e.g.
for VE to send the residency checking result to V).
The Intel SGX speciﬁcations are well aligned with our
protocol and threat model. In speciﬁc, enclaves cannot di-
rectly access OS-provided services (which are not trusted in
the thread models of SGX). They need to make OCall to an
interface routine to ask the untrusted application to handle
those services. In our context, the fetching of the requested
block is performed by the prover, who is also untrusted. The
VE issues a query for a requested block by making an OCall
to the prover’s untrusted application, which then retrieves
the block and makes an ECall to pass it as input parameter
to VE. Since this ECall is invoked by the untrusted party,
the veriﬁcation code needs to be written with care so that
no attack window is exposed. We refer readers to Intel SGX
programming reference for further details on coding guide-
line for programming enclave code [7].
While getting a trusted source for absolute time in SGX
is challenging, it is possible to measure relative time with
respect to a reference point [40]. We note that absolute
time is not necessary in our setting, for the response latency
measured by VE is an elapsed duration between an OCall
and the corresponding ECall passing the requested block
into VE, to which relative time with respect to the same
stable reference point is suﬃcient.
Eﬀect of block size on security. We highlight the eﬀect of
the block size on the overall security. Rotational drives, in