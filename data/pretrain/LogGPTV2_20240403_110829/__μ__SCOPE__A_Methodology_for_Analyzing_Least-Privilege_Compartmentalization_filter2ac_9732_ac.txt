(Type(sd, od, op) = Unmediated)(cid:17)
∃sd, od
(1)
Privilege RepresentationInstrumentation, Observation, and Trace OutputInputS’Compartmentalization and AnalysisSeparation HypothesesPrivilege and Performance AnalysisCode StructurePer LineFunctionFileDirectoryClusteringTrace of Priv OpsSubjectOpObjects1   Alloc  o2s3   Write  o2s1   Read   o2s1   Alloc  o3…    …      …s5   Call   s6s7   Ret    s5s4   Free   o2InstrumentS?AllocFreeReadWriteCallRetCAPMAP Privilege Operationso2o3c1c3c4c6c5c7o2o3c1c3c4c6c5c7o2o3s1s3s4s6s5s7.cmap ﬁlesParseManualCompartmentalize1. Determine Subject Domain Groups2. Determine Object Domain Groups3. Determine Access Mediation Policy      {Unmediated, Mediated, Not}o2o3s1s3s4s6s5s7s3s6s7s1s4s5UnmediatedRead, Write,FreeUnmediatedCall, ReturnMediatedCall, ReturnMediatedWriteMediatedCall, ReturnUnmediatedCall, ReturnMetrics300RAID ’21, October 6–8, 2021, San Sebastian, Spain
Roessler and Dautenhahn, et al.
all objects in od. As a result, if any instruction i ∈ sd and object
o ∈ od have an operation privilege defined in the CAPMAP, every
instruction and object in the (sd, od) compartment is granted that
operation privilege. Note that our compartmentalization model is
more general than conventional models that typically (1) require
objects to exist within at most one compartment (have unmediated
edges from a single subject) and (2) assign object ownership based
on the allocating subject.
5.3 Metrics
µSCOPE treats compartmentalization as an optimization problem
over the privilege-performance space. To do so, it uses metrics that
can be computed on a CAPMAP augmented with dynamic privilege
counts to capture tradeoffs in privilege and separation costs.
5.3.1 Privilege. To quantify the privilege that exists in the sys-
tem under various compartmentalizations, we use the size of the
privilege set, |PS| (see Sec. 2). To make the numbers generally mean-
ingful for comparison, the Privilege Set Ratio (PSR) is defined as a
ratio of the |PS| under a particular compartmentalization and the
|PS| of the monolithic case, i.e., when the whole task is a single
compartment. We break down five different operations (read, write,
call, return, and free) and provide a separate PSR for each.3
Simply put, we add one unit of privilege to the |PS| for each
particular instruction that is allowed to perform the specified oper-
ation on a particular object. For memory reads and writes case, the
unit object is a byte of memory, and we group together all the bytes
allocated by a particular static instruction as a single object class.
For calls and returns, the unit is a single function entry or return
point. The total privilege then is the weighted sum of all instruc-
tions and the objects they are allowed to operate upon. Specifically,
for each operation type op, we can compute |PS(op)| for any priv(·)
definition as a weighted sum over the privileges that exist:
cpriv(i, o, op) × w(o, op)
(2)
|PS(op)| =

i∈I
o∈O
Here cpriv simply has a 1 when priv(i, o, op) is true, and 0 when
it is false. w(o, op) is a weighting function that potentially depends
on the operation, the size of the object, and the security importance
of the object. In the simplest case, it could be the size of the object
in bytes.
The reference count for the monolithic case, |PSmono(op)|, is
simply the case where all feasible privileges exist. So, we evaluate
Eq. 2 with priv = privmono:
privmono(i, o, op) =
if i performs op
(cid:40)
(3)
true,
f alse, otherwise
Conversely, for the least-privilege compartmentalization PSmin(op),
every instruction is its own sd and every object is its own od. We can
compute |PSmin(op)| as Eq. 2 with priv(i, o, op) = capmap(i, o, op).
With this in mind, the lower bound of PSR is given as:
PSRmin(op) = |PSmin(op)|/|PSmono(op)|
(4)
For the compartmentalization case where edges are typed as Not,
Mediated, or Unmediated, we compute Eq. 2 using priv(i, o, op) =
3Other types of operations, such as jumps or memory allocation, can be represented
in the same way.
privcompar t(i, o, op) from Eq. 1. A concrete example to illustrate
these metrics is shown in App. A.
5.3.2 Performance Model. To reason about the overhead of a candi-
date compartmentalization, we build a model to estimate the impact
of these external operations, assigning a fixed cost to each mediated,
unmediated, and internal operation:
Tsep = Tunsep + 
+ 
+ 
op∈OPS
op∈OPS
Nmed(op) × Tmed(op)
op∈OPS
Nunmed(op) × Tunmed(op)
Nint(op) × Tint(op)
(5)
Here Tsep is the estimated execution time for the separated design
while Tunsep is the original, unseparated execution time. Tmed(op)
is the additional time for a mediated external operation op, and
Nmed(op), Nunmed(op), and Nint(op) are the total number of me-
diated, unmediated, and internal operations of type op. Tunmed is
the additional time for an unmediated external operation. Tint(op)
is the the additional time for an internal operation, a call or re-
turn inside the SD, when separated for modeling cases, like SFI
[26] (Sec. C), where each of these operations adds some overhead.
We can calculate the number of mediated external accesses for a
particular compartmentalization as:
tops(i, o, op) is the number of times i performs op on o. d(i, o, op)
is a similar calculation to Eq. 1 that identifies all edges in the fine-
grained privilege map that are associated with an unmediated edge
in the coarse-grained compartmentalization graph. We calculate un-
mediated and internal operations similarly with different conditions
on d(i, o, op). This model does not explicitly account for temporal
or blocking effects; as such, the numbers are best interpreted as
averages. We treat memcpy as a single mediated operation.
5.4 Separability Analysis
Once we have a CAPMAP to represent necessary privileges (Sec. 5.1),
a dynamic performance trace to represent relative frequency of use,
a compartmentalization model that defines the space of legal com-
partments (Sec. 5.2), and metrics for privilege and performance
(Sec. 5.3), it becomes possible to systematically analyze the space
of compartmentalizations. We could generate all such compartmen-
talizations, evaluate their privilege and performance metrics, and
report the full continuum of privilege-performance points obtain-
able for the system. Unfortunately, the full set of compartments
is too large to practically enumerate for all but the most trivial
systems.
The CAPMAP with dynamic frequency counts on edges gives us
a graph to which we can apply standard single- and multi-objective
graph clustering and partitioning algorithms to gain access to the

Nmed(op) =
1,
d(i, o, op) =
0, otherwise
d(i, o, op) × tops(i, o, op)
(6)
o∈KO
i∈I
if ¬(∃sd, od ((o ∈ or) ∧ (i ∈ sc)
∧ Type(sd, od, op) = Unmediated))
301µSCOPE: A Methodology for Analyzing Least-Privilege Compartmentalization in Large Software Artifacts
RAID ’21, October 6–8, 2021, San Sebastian, Spain
interesting points in the continuum. This allows us, for example, to
formulate compartmentalization as constrained graph clustering
optimization problems by placing constraints on properties of the
compartments (e.g., subject size, object size, maximum number of
edges on subject or object) and the privilege metric (Eq. 2) or perfor-
mance (Eq. 5) and identifying objective functions to minimize, such
as excess privilege (|PS(op)| − |PSmin(op)|), performance overhead
((Tsep − Tunsep)/Tsep) or the ratio of privilege and performance
(|PS(op)|/Tsep). Using a sequence of optimization queries, we can
establish bounds on feasible performance and privilege points in
the space. Furthermore, since the models themselves are paramet-
ric (e.g., relative weighting of operations and objects), analyses
can be tuned for different needs (e.g., privacy vs. integrity) and
mechanisms (Sec. 6.6), and adjusted for perceived importance (e.g.,
object weighting, Sec. 8.8). We provide concrete examples of this
parameterization and heuristic clustering algorithms in Secs. 6.2
through 6.6.
6 MAPPING LINUX AND C TO µSCOPE
In this section we apply the generic µSCOPE methodology to the
Linux kernel. We present a concrete instance of the approach that
makes selections for: (1) language bindings to generate meaning-
ful identifiers for subjects and objects, (2) specific algorithms for
choosing subject groups, object groups, and access mediation, (3)
specific privilege metric weights for our analysis, and (4) a spe-
cific set of mechanism costs to estimate the performance overhead
of separation, given a range of possible enforcement mechanisms.
These decisions represent initial design choices and offer many
parameterizations.
6.1 Mapping C for Fine-Grained Identification
Each machine instruction in the vmlinux must be mapped to a SD,
and each static and dynamically allocated C object must be mapped
to an OD. Objects includes global and per-CPU variables, as well
as objects from Linux’s dynamic allocators (Sec. 7.1). For simplicity
of analysis, we statically compile all required kernel modules.
6.2 Subject Domains
The data in the weighted CAPMAP provides us with rich, low-
level information about the control-flow flow and data-accessing
patterns of code, from which we can intelligently produce subject
domains. Because clustering is known to be NP-hard [7], we use a
lightweight, greedy clustering algorithm that assigns instructions
into clusters. More heavyweight clustering would only increase the
high separability we are able to identify. We begin the algorithm
by placing each function into its own cluster; we then proceed to
perform repeated cluster-merge operations until an assignment
of code into Subject Domains is produced. To determine which
clusters to merge at each step, we consider all possible pairs and
compute the ratio of a utility function to that of a cost function
for that pair; we then take the pair with the highest ratio, perform
the merge, and repeat. The utility function we use is the expected
performance savings of combining the two clusters: by combining
frequently interacting pieces of code, we save on the costs of cross-
compartment calls between those clusters. The cost function we
use is the net increase in |PS| incurred by the merge—that is, after
merging two clusters, the code and data of each can be exposed to
the code of the other (in the case of Unmediation), and |PS| captures
this quantification. The algorithm stops when there are no merges
left with a ratio above a specified minimum threshold α (that is,
no merges are favorable in terms of performance savings to |PS|).
Intuitively, α specifies the acceptable tradeoff level of performance
cost per unit of |PS|.
By varying values of α, we can produce a range of Subject Do-
mains at various points in the privilege-performance continuum.
We refer to subject domains constructed from this clustering algo-
rithm from their values of α. We include a web-based compartment
explorer for compartments generated with this algorithm: µSCOPE
compartment explorer.4
6.3 Object Domains
After assigning instructions into Subject Domains, we then assign
the objects from the CAPMAP into ODs. At the most fine-grained
level, each object would be mapped into its own Object Domain
(e.g., the data allocated from each allocation site, or each global
variable, would be its own OD). For some enforcement mechanisms,
such as Virtual Memory using an MMU, there may be significant
performance implications for subjects that are allowed access to
many ODs (e.g., TLB pressure). For these enforcement mechanisms,
we run an object clustering algorithm that combines object classes
together into coarser ODs, so that no SD has access edges to more
than a specific object limit number of ODs. For some of the enforce-
ment mechanisms we model (capability hardware, direct hardware
support) no object clustering is applied.
To cluster objects, we use a greedy clustering algorithm similar to
the one we use for creating subject domains. We begin by assigning
each object class into its own OD. We then iteratively consider each
SD that has access edges to more than the object limit number of
ODs. For each such SD, we consider all pairs of ODs accessed by the
SD as candidates for a merge. We select the pair that has the lowest
value of a cost function, merge those ODs into a single OD, then
move on to the next SD that is over the limit until all SDs satisfy
the object limit constraint. The cost function we use to evaluate
merges is the net total increase of |PS| that would result from the
merge—since merging object classes will open up more PS (due
to each OD being possibly mapped unmediated in multiple SDs).
We set the object limit to 64 to match the number of entries in the
DTLB on modern CPUs [17].
6.4 Access Mediation
For each Subject Domain, Object Domain and operation type triple
(sd, od, op) we must choose a mediation type (Sec. 5.2). If our CAPMAP
tells us that the SD does not perform the specified operation on
the OD, the type is Not and that operation is disallowed. For opera-
tions that are allowed, we type the mediation as either Mediated or
Unmediated.
We begin our algorithm with all edges typed as Mediated. We
then pick the edge that yields the largest performance savings per
unit increase of |PS| to unmediate. We set its type as Unmediated,
record the properties of the compartmentalization, then repeat the
same process until all edges are typed as Unmediated. Note that
4https://uscope-linux.github.io/compartment_explorer/
302RAID ’21, October 6–8, 2021, San Sebastian, Spain
Roessler and Dautenhahn, et al.
Table 1: Performance profile modeling parameters.
Tmed(op)
r, w, call,
free
ret
0 6000 6000 6000
0 450 1500 650
50
150