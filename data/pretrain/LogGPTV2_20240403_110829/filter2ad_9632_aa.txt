# HBC隐私攻击
|
##### 译文声明
本文是翻译文章
译文仅供参考，具体内容表达以及含义原文为准。
## 前言
一般的机器学习系统应用于分类任务时，就是给定一个测试样本，然后返回一个标签，或者说是属性。比如对于MNIST来说，就是给一张手写体数字图像，分类器返回0~9中的一个数字。但是对于其他的一些数据集，情况就没有这么简单了，比如对于一个可以分析人类表情的机器学习系统，输入的是一张人脸，它会返回高兴或者难过，但是除此之外，人脸数据实际上还包含一些其他属性，比如性别、年龄、种族等。如果涉及到一些敏感属性的话，那可能就会带来严重的隐私风险。
那么作为攻击者，是否可以训练出这么一种分类器：它的输出不仅可以用于推断目标属性，而且还会秘密携带有关用户数据的敏感属性的信息。
如下图所示
假设存在一个服务器，该服务器为其用户提供对针对已知目标属性
训练的分类器的访问权限。设用户的数据x(比如人脸)包括目标属性y(如年纪)和敏感属性s(如种族).由服务器提供的分类器会估计y，用户会得到分类器返回的y^.但是，作为攻击者，不仅可以训练模型使其给出关于y的准确估计，同时当其输入给攻击G的时候，G可以推断出敏感属性s。图中的(1)(2)表示的是两种不同的场景，即不论分类器给出的是原始的输出还是软输出。
本文要分析的工作来自CCS 2021，名为Honest-but-Curious Nets: Sensitive Attributes of Private
Inputs Can Be Secretly Coded into the Classifiers’ Outputs，它告诉我们这类攻击都是可以实现的。
这里顺带说一下，Honest-but-Curious简称HBC是来自密码学领域的一个半可信模型下的概念，原先是指，在两方计算中不偏离其指定协议但试图从接收到的数据中推断出尽可能多的敏感信息的合法方被称为诚实但好奇（HBC）方，这里研究人员用其指代可以实现类似目的的分类器，这种分类器的输出不仅可用于推断目标属性，而且还可以秘密携带有关用户数据的敏感属性的信息。
## 形式化
在给出具体定义之前，需要声明一下，这个工作用了很多信息论的公式，所以先来看看信息论相关的
设随机变量
随机变量a的熵表示为：
随机变量b于a的交叉熵：
a和c的互信息为：
我们假设用户数据x采样自一个未知的数据分布D，设x可以提供关于至少两个潜在分类变量(属性)的信息，比如y为目标属性，s为敏感属性。分类器F以x为输入并输出y^,其可以表示为
其中的yi^^是Pr(y=i|x)。
设y-是从y^得到的关于y的预测值(比如在二分类中基于阈值，在多分类中基于argmax函数)
我们假设x，以及F的所有中间的计算都是隐藏的，用户只知道y^.
对于仅服务器知道的敏感属性s的攻击可以记做
设s-是从s^得到的关于s的预测值.
这里的马尔科夫链为：
接下来我们定义诚实方，给定测试数据Dtest，如果满足下式我们就说分类器F是诚实的，即-h
其中 ∈ [0, 1]，表示的是分类器的测试准确率
当其预测目标属性时，我们称其为F的诚实方
然后定义好奇方，给定测试数据Dtest和攻击者G，如果满足下式则称之为好奇
其中 s ∈ [0, 1]，表示的是攻击者在测试集上的攻击成功率
当其预测敏感属性时，我们称其为F的好奇方
当分类器F在相同的数据Dtest上同时表现出诚实和好奇时，我们称之为Honest-but-Curious,HBC
而当分类器训练的目的仅是为了达到最佳的诚实，而没有任何额外的好奇，我们称其为标准分类器。
此外我们还有区分黑盒和白盒环境，我们这里以用户在推理时面对分类器的视角进行区分，在黑盒下，用户只能拿到分类器的输出而不知道其架构、参数等，在白盒下，用户知道分类器的架构、输出以及计算时的所有中间过程。
作为攻击者，我们的目的就是要训练一个HBC。
接下来我们分黑盒和白盒两种情况介绍如何实现HBC。
## 黑盒
这里先以一个比较简单的逻辑回归分类器为例进行说明。数据分布如下图所示
其中每个样本x有两个属性∈{0,1}和∈{0,1}
如果与
相关，那么分类器的任何输出总是会暴露一些敏感信息，所以s和y的相关性越小，构建HBC分类器的难度就越大。而在上图中可以看到，y和s是独立的，并且对于每个属性而言，都有一个最优的线性分类器
很明显，对于这个数据集我们可以找到一个最优的逻辑回归分类器
模拟y的决策边界。这样的分类器是-h， = 1，同时它也是–， = 0.5；这意味着分类器是诚实的，不会泄露任何敏感信息。而任何使 > 0.5
的线性分类器的都需要通过强制 < 1 来实现，而这会降低分类器的诚实性。这也是实现HBC的难点所在。
我们可以尝试着分别在两个属性上分别训练一个分类器，并将其合并起来得到最终的y^
此时的y^就是对于目标属性y和敏感数学s的预测值的混合后的结果。大概的示意图如下
这里的混合其实有两种方式，用公式可以分别表示如下
[]符号表示的意思是取整
由于这两个分类器对于各自的属性而言都是最优的，所以实际上对于第二种混合而言，y^实际上只有四种值。如下
只要 ≠ 0.5,，给定y^，我们就可以精确的估计y和s，从而实现HBC分类器的构建
当然了，此时的分类器不再是线性的了。
而对于第一种混合方式而言，其难点在于y^的可能取值是在[0,1]范围的，所以我们可以做的就是定义一个阈值‘，并以此对[0,1]进行区间划分，划分如下所示
不过这种方案得到HBC分类器不如后一种混合方式的，一个简单的例子示意图如下
这里 = 0.8 and = 0.2，使用第二种混合方式，可以实现 = 1和 = 1；使用第一种混合方式，可以实现当′ = .1时， = .99 和 =
.95
总之，在黑盒情况下，服务器可以训练两个单独的分类器，每个分类器都具有足够高的准确度，并且可以使用两个输出的混合来构建HBC。
## 白盒
理论上来讲，分类器的输出y^，是一个可以携带无限量信息的向量。
所以在没有任何特定约束的情况下，通过处理y^是可以泄露隐私信息的，甚至可以用于重构数据x。但是实际上有各种各样的限制，比如数据的复杂性、对soft
output的要求等。这里我们引入信息论的知识来分析分类器的好奇方和输出的熵之间的关系。
我们知道，随机变量x的熵是其信息内容的期望值，也叫做自信息，即：
但我们在数据中寻找目标信息时，数据中存在的潜在的不相关的信息可能会让提取目标信息更加艰难。原则上来说，这种不相关的信息对于我们的目标任务而言，其实是一种噪声。比如说当我们在寻找目标属性时，对于一个DNN分类器而言其输入x输出概率分布，输出相比于输入而言具有更低的熵。尽管从熵的角度来看，y^带有的信息比x更少，但是相对于目标y而言，
y^的信息还是过多了。
同时，在分类器输出的熵和好奇方之间存在一定的关系。对于较大的H(y^）
说明y^此时带有更多的信息，所以更有可能被提取出于目标任务不相关的信息
举个例子，比如Y=4,y=1,y独立于s。在一个极端的情况下，当分类器的输出为y^=[0,1,0,0]
（此时H(y^)=0）
那么y^就没有携带关于s的信息，如果要附加关于s的信息的话就会增加熵
在监督学习中，通常使用的损失函数是交叉熵，如下所示
在训练过程中会最小化Hy(y^)
然而，由于数据通常是有噪声的，所以我们不能在推理时对Hy(y^)设置上界。在实践中，将 H(y^) 与 H (y^) 一起最小化可能有助于在推理时保持
H(y^) 较低，但是不能保证分类器在推理时总是会产生最小或有界的熵输出。
根据这一事实， 我们可以将分类器输入x的私有属性编码到分类器的输出中。
###  正则化攻击
第一种实现的攻击方案是通过将正则化F上的损失函数来强制分类器将s显式编码到y^的熵中
一般来说，y^有两个属性可以用于创建HBC分类器，分别是：
Argmax：使用 y^ 中最大元素的索引来预测