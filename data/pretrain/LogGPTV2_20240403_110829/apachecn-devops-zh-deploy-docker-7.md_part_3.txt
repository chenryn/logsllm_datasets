If you really wanted to, you actually can change the `ulimit` settings of an already-running process with `prlimit` from the `util-linux` package, but this method of adjusting the values is discouraged because the settings do not persist during process restarts and are thus pretty useless for that purpose. With that said, if you want to find out whether your `ulimit` settings have been applied to a service that is already running, this CLI tool is invaluable, so don't be afraid to use it in those cases.
要更改此设置，您需要根据您的分发进行选项组合:
*   创建安全限制配置文件。你可以通过在类似`/etc/security/limits.d/90-ulimit-open-files-increase.conf`的东西上加几行来完成。以下示例将打开文件软限制设置在`root`上，然后将所有其他帐户(`*`不适用于`root`帐户)设置为`65536`。你应该提前找出你的系统合适的数值:
    ```
    root soft nofile 65536
    root hard nofile 65536
    * soft nofile 65536
    * hard nofile 65536
    ```
*   将`pam_limits`模块添加到**可插拔认证模块** ( **PAM** )。这将反过来影响所有具有以前 ulimit 更改设置的用户会话，因为某些发行版不包含它，否则您的更改可能不会持续。在`/etc/pam.d/common-session`中增加以下内容:
    ```
    session required pam_limits.so
    ```
*   或者，在某些发行版上，您可以在覆盖文件
    ```
    LimitNOFILE=65536
    ```
    中的`systemd`中将设置直接添加到受影响的服务定义中
Overriding `systemd` services is a somewhat lengthy and distracting topic for this section, but it is a very common strategy for tweaking third-party services running on cluster deployments with that init system, so it is a very valuable skill to have. If you would like to know more about this topic, you can find a condensed version of the process at [https://askubuntu.com/a/659268](https://askubuntu.com/a/659268), and if you want the detailed version the upstream documentation can be found at [https://www.freedesktop.org/software/systemd/man/systemd.service.html](https://www.freedesktop.org/software/systemd/man/systemd.service.html). CAUTION! In the first example, we used the `*` wildcard, which affects all accounts on the machine. Generally, you want to isolate this setting to only the affected service accounts, if possible, for security reasons. We also used `root` because root values are specifically set by name in some distributions, which overrides the `*` wildcard setting due to the higher specificity. If you want to learn more about limits, you can find more information on these settings at [https://linux.die.net/man/5/limits.conf](https://linux.die.net/man/5/limits.conf).
# 最大文件描述符
就像我们对会话和进程有最大打开文件限制一样，内核本身对整个系统的最大打开文件描述符也有限制。如果达到此限制，将无法打开任何其他文件，因此这需要在可能同时打开大量文件的机器上进行调整。
该值是内核参数的一部分，因此可以通过`sysctl`看到:
```
$ sysctl fs.file-max
fs.file-max = 757778
```
虽然在这台机器上，这个值似乎是合理的，但我见过一些旧的发行版，其值低得惊人，如果您在系统上运行大量容器，很容易出错。
Most kernel configuration settings we discuss here and later in this chapter can be temporarily changed with `sysctl -w =""`. However, since those values are reset back to defaults on each reboot, they usually are of no long-term use for us and are not going to be covered here, but keep in mind that you can use such techniques if you need to debug a live system or apply a temporary time-sensitive fix.
要将其更改为在重新启动后仍然有效的值，我们需要将以下内容添加到`/etc/sysctl.d`文件夹(即`/etc/sysctl.d/10-file-descriptors-increase.conf`):
```
fs.file-max = 1000000
```
进行此更改后，重新启动，您现在应该能够在机器上打开多达 100 万个文件句柄！
# 套接字缓冲区
为了提高性能，增加套接字缓冲区的大小通常是非常有利的，因为它们不再执行单台机器的工作，而是在常规机器连接的基础上运行尽可能多的 Docker 容器的工作。为此，您可能应该设置一些设置，以确保套接字缓冲区不会难以跟上通过它们的所有流量。在写这本书的时候，大多数这些默认缓冲区设置在机器启动时通常都很小(我检查过的几台机器中有 200 KB)，它们应该是动态缩放的，但是你可以从一开始就强制它们变得更大。
在 Ubuntu LTS 16.04 安装中，以下是缓冲区设置的默认设置(尽管您的设置可能会有所不同):
```
net.core.optmem_max = 20480
net.core.rmem_default = 212992
net.core.rmem_max = 212992
net.core.wmem_default = 212992
net.core.wmem_max = 212992
net.ipv4.tcp_rmem = 4096 87380 6291456
net.ipv4.tcp_wmem = 4096 16384 4194304
```
我们将通过向`/etc/sysctl.d/10-socket-buffers.conf`添加以下内容来将这些值调高到一些合理的默认值，但请确保使用在您的环境中合理的值:
```
net.core.optmem_max = 40960
net.core.rmem_default = 16777216
net.core.rmem_max = 16777216
net.core.wmem_default = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 87380 16777216
```
通过增加这些值，我们的缓冲区开始变大，并且应该能够以更好的吞吐量处理相当多的流量，这是我们在集群环境中想要的。
# 短暂的港口
如果您不熟悉临时端口，它们是所有出站连接在连接上没有明确指定始发端口时分配的端口号，这是绝大多数端口。例如，如果您对几乎每个客户端库执行任何类型的出站 HTTP 请求，您很可能会将这些短暂端口中的一个指定为连接的返回通信端口。
要查看机器上临时端口使用的一些示例，您可以使用`netstat`:
```
$ netstat -an | grep ESTABLISHED
tcp        0      0 192.168.56.101:46496     :443      ESTABLISHED
tcp        0      0 192.168.56.101:45512     :443      ESTABLISHED
tcp        0      0 192.168.56.101:42014     :443      ESTABLISHED
tcp        0      0 192.168.56.101:45984     :443      ESTABLISHED
tcp        0      0 192.168.56.101:56528     :443      ESTABLISHED
```
当您开发具有多个服务和大量出站连接的系统时(在使用 Docker 服务时，这实际上是强制性的)，您可能会注意到您被允许使用的端口数量是有限制的，并且可能会发现这些端口可能会与您的一些内部 Docker 服务正在使用的范围重叠，从而导致间歇性且经常令人讨厌的连接问题。为了解决这些问题，需要对临时端口范围进行更改。
由于这些也是内核设置，我们可以看到`sysctl`的当前范围，就像我们在前面几个例子中所做的那样:
```
$ sysctl net.ipv4.ip_local_port_range
net.ipv4.ip_local_port_range = 32768    60999
```
您可以看到，我们的范围在端口分配的上半部分，但是任何可能在该范围内开始侦听的服务都可能有问题。我们还可能需要超过 28，000 个端口。
You may be curious how you get or set the `ipv6` settings for this parameter, but luckily (at least for now) this same setting key is used for both `ipv4` and `ipv6` ephemeral port ranges. At some point, this setting name may change, but I think we are at least a couple of years away from that.
要更改该值，我们可以使用`sysctl -w`进行临时更改，或者使用`sysctl.d`进行永久更改:
```
$ # First the temporary change to get us up to 40000
$ # ports. For our services, we separately have to
$ # ensure none listen on any ports above 24999.
$ sudo sysctl -w net.ipv4.ip_local_port_range="25000 65000"
net.ipv4.ip_local_port_range = 25000 65000
$ # Sanity check
$ sysctl net.ipv4.ip_local_port_range
net.ipv4.ip_local_port_range = 25000    65000
$ # Now for the permanent change (requires restart)
$ echo "net.ipv4.ip_local_port_range = 25000 65000" | sudo tee /etc/sysctl.d/10-ephemeral-ports.conf
```
通过这一更改，我们有效地将可支持的出站连接数增加了 30%以上，但我们也可以轻松地使用相同的设置来确保临时端口不会与其他正在运行的服务发生冲突。
# 网络过滤器调整
可悲的是，到目前为止，我们看到的设置并不是唯一需要随着与服务器的网络连接的增加而调整的东西。随着服务器负载的增加，您也可能开始在`dmesg`和/或内核日志中看到`nf_conntrack: table full`错误。对于那些不熟悉`netfilter`的人来说，它是一个内核模块，在哈希表中跟踪所有**网络地址转换** ( **NAT** )会话，向其中添加任何新的连接，并在它们关闭并达到预定义的超时后清除它们，因此当您增加从一台机器到另一台机器的连接量时，您很可能会发现这些相关设置中的大多数都是相当保守的默认值，需要调整(尽管您的分布可能会有所不同-请确保验证您的设置！):
```
$ sysctl -a | grep nf_conntrack
net.netfilter.nf_conntrack_buckets = 65536
net.netfilter.nf_conntrack_generic_timeout = 600
net.netfilter.nf_conntrack_max = 262144
net.netfilter.nf_conntrack_tcp_timeout_close = 10
net.netfilter.nf_conntrack_tcp_timeout_close_wait = 60
net.netfilter.nf_conntrack_tcp_timeout_established = 432000
net.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120
net.netfilter.nf_conntrack_tcp_timeout_last_ack = 30
net.netfilter.nf_conntrack_tcp_timeout_max_retrans = 300
net.netfilter.nf_conntrack_tcp_timeout_syn_recv = 60
net.netfilter.nf_conntrack_tcp_timeout_syn_sent = 120
net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120
net.netfilter.nf_conntrack_tcp_timeout_unacknowledged = 300
```
其中有相当多是可以更改的，但是需要调整的错误的常见疑点如下:
*   `net.netfilter.nf_conntrack_buckets`:控制连接哈希表的大小。增加这个值是明智的，尽管它可以用更激进的超时来代替。请注意，这不能用常规`sysctl.d`设置来设置，而是需要用内核模块参数来设置。
*   `net.netfilter.nf_conntrack_max`:要保存的条目数。默认情况下，这是前一个条目值的四倍。
*   `net.netfilter.nf_conntrack_tcp_timeout_established`:这将保持开放连接的映射长达五天(！).为了不溢出您的连接跟踪表，这通常几乎是强制减少的，但是不要忘记它需要高于 TCP `keepalive`超时，否则您将会得到意外的连接中断。
要应用最后两个设置，您需要将以下内容添加到`/etc/sysctl.d/10-conntrack.conf`中，并为您自己的基础架构配置调整值:
```
net.netfilter.nf_conntrack_tcp_timeout_established = 43200
net.netfilter.nf_conntrack_max = 524288
```