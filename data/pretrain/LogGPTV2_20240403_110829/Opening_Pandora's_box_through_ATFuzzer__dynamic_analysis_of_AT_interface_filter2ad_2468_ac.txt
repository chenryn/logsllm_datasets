of individual grammar grows rapidly. This behavior is character-
ized as structural bloating. Referring to the AT grammar in Figure 3,
multiple cmds (production rules) can contribute to generating the
final commands that are sent to the AT command injector for eval-
uation. These commands can grow indefinitely, but do not induce
any structural changes, and thus cause structural bloating. These
input commands, therefore, hardly contribute to the effectiveness
of the fuzzer. To limit this behavior, we restrict the grammar to
have at most three cmds at each round to generate the input AT
commands for testing.
Figure 5: Examples of one-point and two-point grammar cossover
mechanisms.
4.1.3 Grammar crossover. In the grammar crossover stage, ATFuzzer
strives to induce changes in the grammar aiming to systematically
break the correlation and structure of the grammar. For this, we
take inspiration from traditional genetic programming and apply
our custom two-point crossover technique to the grammars.
Two-point crossover. ATFuzzer picks up two random production
rules from the given parent grammars and generates two random
numbers c1 and c2 within ℓ where ℓ is the minimum length between
the two production rules. ATFuzzer then swaps the fields of the two
production rules that are between points c1 and c2.
Figure 5 shows how ATFuzzer performs the two-point crossover
operation on production rules +CTFN = and +CTFR = (a subset
of the AT grammar in Figure 3) used for controlling the cellular
functionalities and for urgent call forwarding, respectively. By ap-
plying two-point crossover on +CFUN = CFUNarg1, CFUNarg2
and +CTFR = number, type, subaddr, satype, ATFuzzer gener-
ates +CFUN = number, CFUNarg2 and +CTFR = CFUNarg1, t-
ype, subaaddr, satype which in turn contribute in generating ver-
satile inputs.
Algorithm 2: Two-Point Grammar Crossover
Data: ParentGrammar Pa, ParentGrammar Pb
Result: Pa,Pb
1 Randomly pick production rule Ra from Pa and Rb from Pb
2 Ra ← Ra1 , Ra2 , ..., Ral
3 Rb ← Rb1 , Rb2 , ..., Rbm
4 c1 ← random integer chosen from 1 to min(l, m)
5 c2 ← random integer chosen from 1 to min(l, m)
6 if c > d then
7
8 end
9 for i from c to d − 1 do
10
11 end
swap grammar rules of Rai , Rbi
swap c1 and c2
Figure 6: Example of three grammar mutation strategies.
4.1.4 Grammar mutation. During crossover operation, ATFuzzer
constructs grammars that may have diverse structures which are,
however, not enough to test the constraints and correlations as-
sociated with a command and its arguments. This is due to the
fact that AT commands have constraints not only on the fields
but also on the commands itself. Therefore, generating versatile
grammars that can generate such test inputs is an important as-
pect of ATFuzzer design. To deal with this pattern, we propose
three mutation strategies— addition, trimming, and negation. We
use AT+CTFR=number,type,subaddr,satype (one of the exam-
ple grammars presented in Figure 3) to illustrate these mutation
strategies with examples shown in Figure 6.
Addition. With our first strategy we randomly insert/add a field
chosen from the production rule of the given grammar at a random
location. For instance, applying this mutation strategy (shown in
Figure 6) to one of the grammars +CTFR = number,type,subaddr,
satype yields +CTFR = number,type,satype,subaddr,satype con-
taining an additional argument added after the second argument
of the actual grammar. The mutation also has changed the type
(string) of third argument (subaddr) of the actual grammar to inte-
ger (satype) in the new grammar. ATFuzzer, thereby, tests the type
correctness along with the structure of the grammar.
Trimming. Our second mutation strategy is to randomly trim an
argument from a production rule for the given grammar. Referring
to Figure 6, applying this to our example grammar for +CTFR, we
+CFUN	=	CFUNarg1				,	CFUNarg2																																							+CTFR	=		number,									type	,subaddr,	satype	c1c2+CFUN	=	number									,	CFUNarg2																																							+CTFR	=		CFUNarg1,			type	,subaddr,	satype	c1c2Negating	a	production	ruleAdding	a	production	rulesatype,	+CTFRtype,	subaddr,satype+CTFR	=	number,type,subaddr,satype+CTFR=	number,	type,	subaddr,	satypeTrimming	a	production	rule+CTFR	=	number,subaddr,satype=	number	535obtain a production rule AT + CTFR = number,subaddr,satype
which also deviates from the original grammar with respect to both
the structure and type.
Negation. Our last mutation strategy focuses on the constraints
associated with the arguments of a command. Referring to the AT
grammar in Figure 3, we encode the constraints with additional
conditions (denoted with {. . . }) in the grammar production rules.
With the negation strategy, we randomly pick a production rule of
the grammar and choose a random argument that has a condition
associated with it. We negate the condition which we use to replace
the original one at its original place in the production rule. Figure 6
demonstrates how we negate the production rule associated with
number used to represent a phone number. The number is a string
type with a constraint on its length. We negate this condition with
the following three heuristics: (i) Generating strings that are longer
than the specified length; (ii) Generating strings that contain not
only alphanumeric characters but also special characters; and (iii)
Generating an empty string.
Algorithm 3: Grammar Mutation
Data: Grammar Ga, Tunable parameters : Pα , Pβ , Pγ
Result: Mutated Ga
1 Randomly pick production rule Ra from Ga
2 Ra ← Ra1 , Ra2 , ..., Ral
3 c ← random integer chosen from 1 to l
4 P ← Generate random probability from (0, 1)
5 if Pα ≥ P then
6
7 end
8 if Pβ ≥ P then
9
10 end
11 if Pγ ≥ P then
12
13
14 end
d ← random integer chosen from 1 to l
add argument Pac at position l in production rule Ra
replace Pc {ϕ} with Pc {¬ϕ}in production rule Ra
trim argument Rac from production rule Ra
4.2 Evaluation Module
The primary task of the evaluation module is to generate a number
of test inputs (i.e., concrete AT command instances) for the grammar
received from the evolution module. It then evaluates the test inputs
with the AT command injector, and finally evaluate the grammar
itself based on the scores of the generated test inputs. To what
follows, we explain how the evaluation module calculates the fitness
score of a grammar.
Fitness evaluation. At the core of ATFuzzer is the fitness
4.2.1
function that guides the fuzzing and acts as a liaison for the coverage
information. We devise our fitness function based on the timing
information and baseband related information of the smartphone.
Our fitness function comprises of two parts: (1) Fitness score of
the test inputs generated from a grammar; (2) Fitness score of the
grammar in the population.
Fitness score of the test inputs of a grammar. The fitness eval-
uator of ATFuzzer generates N inputs from each grammar and
calculates the score for each input. We define this fitness function
for an input AT command instance x as:
fitness(x) = α × timingscore + (1 − α) × disruptionscore
where α is a tunable-parameter that controls the impact of
timingscore and disruptionscore. Let tx be the time required for
executing an AT command x (0 ≤ x < N) on the smartphone
t1 + t2 + .... + tN
.
under test. Execution time of an AT command is defined as the time
between when the AT command is sent and when the output is
received by the AT command injector. Note that, we normalize the
execution time by the input length.
Let t1, t2, ..., tN be the time for executing N AT commands, we
define the timing score for instance x in a population of size N as
follows: timingscore =
ti
Note that while running AT commands over Bluetooth, the com-
mands and their responses are transmitted in over-the-air (OTA)
Bluetooth packets. To compute the precise execution time of the
AT command on the smartphone, we take off the transmission and
reception times from the total running time. Also, to make sure
Bluetooth signal strength change does not interfere with the timing
information, our system keeps track of the RSSI (Received Signal
Strength Indication) value and carries out the fuzzing at a constant
RSSI value.
We define disruptionscore based on the following four types of
disruption events: (i) Complete shutdown of SIM card connectiv-
ity; (ii) Complete shutdown of cellular Internet connectivity; (iii)
Partial disruption in cellular Internet connectivity; (iv) Partial dis-
ruption of SIM card connectivity with the phone. For cases (i) and
(ii), complete shutdown causes denial of cellular/SIM functionality,
recovery from which requires rebooting the device. ATFuzzer uses
adb reboot command which takes ∼ 15 − 20 seconds to restart the
device without entailing any manual intervention. On the contrary,
partial shutdown for the cases (iii) and (iv) induce denial of cellu-
lar/SIM functionality for ∼ 3 − 5 seconds and thus does not call for
rebooting the device to recuperate back to its normal state. These
events are detected and monitored using the open-source tools
available to us from Android, e.g., logcat, dumpsys, and tombstone.
When injecting the AT commands we use these tools to detect the
events at run time. We take into account if there is a crash in the
baseband or the RIL daemon. We assign a score between 0 − 1 to a
disruption event in which 0 denotes no disruption at all (i.e., the de-
vice is completely functional) with no adverse effects and 1 denotes
complete disruption of the cellular or SIM card connectivities.
Fitness score of a grammar. After computing the fitness scores
for all the concrete input instances, we calculate the grammar’s
score by taking the average over all instance scores.
5 EVALUATION
Our primary goal in this section is to evaluate the effectiveness
of ATFuzzer by following the best possible practices [26, 55] and
guidelines [34]. We, therefore, first discuss the experiment setup
and evaluation criteria, and then evaluate the efficacy of our proto-
type against the widely used AFL [59] fuzzer— customized for our
context.
5.1 Experiment Setup
ATFuzzer setup. We implemented ATFuzzer with ∼4000 lines of
Python code. We encoded the grammars (with JSON) for a corpus
of 90 baseband-related AT commands following the specification in
the 3GPP [11] documentation and extracting some of the vendor-
specific AT commands following the work of Tian et al. [53]. During
its initialization, ATFuzzer receives the name of the AT command
536as input, retrieves the corresponding grammar that will be used
as the seed (GAT in algorithm 1) from the file, generates the initial
grammar population, and realizes the proposed crossover and muta-
tion strategies. Hence, our approach is general and easily adaptable
to other structured inputs, since it is not bound to any specific
grammar structure. Since testing a concrete AT command instance
requires 15-20 seconds on average (because of checking the cellu-
lar and SIM card connectivity after executing a command and for
rebooting the device in case of AT interface’s unresponsiveness for
blacklisting), we set Psize to 10 which we found through empiri-
cal study to be the most suitable in terms of ATFuzzer’s stopping
condition. Following the same procedure, we test 10 concrete AT
commands in each round for a given grammar. We set the proba-
bility Ppop to 0.5 to ensure uniform distribution in the grammar
varying ratio.
Conceptually, one can argue for testing at a “batch” mode to chop
the average time for fuzzing an AT grammar. For instance, injecting
10 AT commands together and then checking the cellular and SIM
connectivity at once. Although this design philosophy is intuitive,
it fails to serve our purpose due to the following fact. This approach
may be able to detect permanent disruptions but it is unable to
detect temporary disruptions to cellular or SIM connectivity. For
instance, even if the second AT command in the batch induces a
temporary disruption, there will be no trace of disruptions at all by
the time when the tenth (i.e., the last) AT command is executed.
Target devices. We tested 10 different devices (listed in Table 1)
from 6 different vendors running 6 different android versions to
diversify our analysis. For Bluetooth, we do not require any config-
uration on the phone. For running AT commands over USB some
phones, however, require additional configuration. For additional
details, see Appendix A.1.
Device
USB Config
Baseband
Interface
OS
Android
Version
4.3
4.3
6.0
6.0.1
5.1.1
Build
Number
JSS15J.
I9300XU
GND5
JSS15J.
I9300XX
UGND5
MRA58K
1.00.600.1
8.0_g
CL800193
release-
keys
LMY48I
Samsung
Note2
Samsung
Galaxy
S3
LG G3
HTC
Desire 10
lifestyle
LG
Nexus 5
Motorola
Nexus 6
Baseband
Vendor
Samsung
Exynos
4412
Samsung
Exynos
4412
Qualcomm
Snap-
dragon
801
Qualcomm
Snap-
dragon
400
Qualcomm
Snap-
dragon
800
Qualcomm
Snap-
dragon
805
Qualcomm
Snap-
dragon
810
Qualcomm
Snap-
dragon
835
HiSilicon
Kirin
620
(28 nm)
Qualcomm
MSM8998
Snap-
dragon
835
N7100DD
UFND1
I9300XX
UGNA8
MPSS.DI.2.0.1.
c1.13-00114
-M8974AA
AAANPZM-
1.43646.2
3.0.U205591
@60906G_01.
00.U0000. 00_F
M8974A-
2.0.50.2.26
MDM9625_
104662.22.