Rule Pattern
What to Delay?1
Issue Exploited
Consequence
T1 = T2, C1 ⊥ C2, A1 = ¬A2
A1 ⇒ T2, A2 ⇒ T1, C1 ⊥ C2
A1 ⇒ T2, C1 ⊥ C2
A1 ⇒ T2, T1 ⊥ C2
C1 → R2 (C2 → R1)
C1 → R2 (C2 → R1)
C1 → R2
T1 → R2
T1  ∆Tinterval; note
that we have ignored the difference between the transmission
time for sending the two trigger events, as it
is usually
negligible when there are no attacks), Rule 12 will be triggered
earlier than Rule 8 (i.e., the execution order is reversed),
leading to a successful attack. Otherwise, the attack fails.
While user behaviors change time by time, there usually
exists a pattern and the pattern can be learned from his-
torical events and commands, which can be inferred using
side channel attacks [27], [30], [31] (see Section II-B). If
the attacker finds that
the user never goes to the living
room within ∆Tallowed after she opens the front door (i.e.,
∆Tallowed < ∆Tinterval), he chooses not to perform an action
disordering attack on Rules 8 and 12 since it will never
succeed. If ∆Tinterval is smaller than ∆Tallowed with a high
probability, then the attack success rate is also high. Note that
failed DAI attack attempts remain stealthy since the delay does
not trigger alarms at any layers of the IoT protocol stack.
V. EVALUATION
In Section V-A, we describe the deployment details of two
real-world smart home testbeds used for evaluating DAI. In
Section V-B, we validate DAI attacks in the two testbeds. In
Section V-C, we evaluate the attack opportunities and success
rates of DAI attacks on a daily life basis.
A. Smart Home Testbeds and Attack Implementation
There are no public datasets of smart homes (including
devices, rule sets, and configuration). Thus, like previous work
on IoT security research [8], [26], [47], we set up smart home
testbeds, denoted as T1 and T2, which are in two real homes
to evaluate the DAI attacks. We received the IRB approval
(see Appendix D for details). There are two persons (a male
graduate student and a female graduate student in their 30s
and 29s, respectively) living in testbed T1, and one person in
T2 (a 27-year-old male graduate student). None of the testbed
members are the authors. The smart home layouts and the
IoT devices in each smart home are given in Fig. 11 and
Table II, respectively. In total, 36 automation rules are installed
on 4 automation platforms to interact with 55 IoT devices. The
automation rules, which are listed in Table III, are chosen from
the official app stores [48] or open-source datasets [49], and
the final configurations are based on the discussion between
the researchers and the residents living in the testbeds. Each
testbed has a WiFi router, providing a WiFi access point and
a few Ethernet ports for the deployed IoT devices.
A Raspberry Pi 4 Model B with a 2GB RAM and a
32GB MicroSD card is placed in each testbed to simulate
a device compromised by the attacker. It is worth noting
that
if the attacker and the victim share a WiFi (e.g., at
a factory, company, hospital, or university), or the attacker
has stolen the WiFi password, the attacker can launch the
attacks directly from his device. Plus, an attacker who has
compromised the smart home router or has physical contact
with the cable can also launch attacks without relying on ARP
spoofing. Note ARP spoofing is decades-old mature attacks
for hijacking traffic. A famous tool, IoT Inspector [50], has
demonstrated that ARP spoofing can hijack a large amount
of IoT traffic without causing network instability. We use the
ARP spoofing-based technique to turn the Raspberry Pi into a
relay node that can examine and delay the traffic between IoT
devices/hubs and the WiFi router, or between IoT devices and
hubs. By configuring the firewall rules through iptables,
all traffic forwarded by the Raspberry Pi is under the control
of our attack script. The attack script uses the approach
in [29] to recognize events/commands from encrypted traffic.
The approach [29] constructs packet-level signatures of IoT
events and commands based on source & destination IPs and
payload lengths in an offline phase, and then detects events
and commands with the signatures in runtime with an accuracy
over 97%. The attack script utilizes a DFA matching approach
[26] to infer automation rules from the event and command
logs of a couple of days (one week in our experiment),