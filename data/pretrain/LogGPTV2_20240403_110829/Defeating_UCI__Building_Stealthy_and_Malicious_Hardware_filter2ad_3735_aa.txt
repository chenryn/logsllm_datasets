title:Defeating UCI: Building Stealthy and Malicious Hardware
author:Cynthia Sturton and
Matthew Hicks and
David A. Wagner and
Samuel T. King
2011 IEEE Symposium on Security and Privacy
Defeating UCI: Building Stealthy and Malicious Hardware
Cynthia Sturton
Matthew Hicks
David Wagner
Samuel T. King
University of California,
Berkeley
University of Illinois,
Urbana-Champaign
University of California,
Berkeley
University of Illinois,
Urbana-Champaign
Abstract—In previous work Hicks et al. proposed a method
called Unused Circuit Identiﬁcation (UCI) for detecting ma-
licious backdoors hidden in circuits at design time. The UCI
algorithm essentially looks for portions of the circuit that go
unused during design-time testing and ﬂags them as potentially
malicious. In this paper we construct circuits that have ma-
licious behavior, but that would evade detection by the UCI
algorithm and still pass design-time test cases. To enable our
search for such circuits, we deﬁne one class of malicious circuits
and perform a bounded exhaustive enumeration of all circuits
in that class. Our approach is simple and straight forward,
yet it proves to be effective at ﬁnding circuits that can thwart
UCI. We use the results of our search to construct a practical
attack on an open-source processor. Our malicious backdoor
allows any user-level program running on the processor to enter
supervisor mode through the use of a secret “knock.” We close
with a discussion on what we see as a major challenge facing
any future design-time malicious hardware detection scheme:
identifying a sufﬁcient class of malicious circuits to defend
against.
Keywords-hardware; security; attack
I. INTRODUCTION
A computer’s hardware layer is often trusted implicitly.
As a result, a machine that contains untrustworthy hardware
may be open to attack, regardless of its operating system
or software stack. If the hardware contains a backdoor, an
attacker may be able to gain total control of the machine,
bypassing any security protections provided by the software.
This is true even if the OS and application layers are free of
bugs and vulnerabilities. Recent research has demonstrated
how just such an attack could work [1], [2], and the media
have started to report on the United States government’s
concern about the possibility of these attacks occurring in
the real world [3], [4].
There has been a variety of research on the problem
of detecting malicious hardware (see Section VII for an
overview). In this paper we focus on the Hicks et al.
paper [2] which tackles the problem of detecting malicious
hardware inserted at design time. The authors of that work
propose an algorithm, Unused Circuit Identiﬁcation (UCI),
for identifying portions of a circuit that go unused during
design-time testing. The idea is that an attacker inserting
malicious code into an existing hardware design will work to
ensure the malicious behavior is not activated during design-
time testing. The assumption is that any circuitry inserted by
1081-6011/11 $26.00 © 2011 IEEE
DOI 10.1109/SP.2011.32
64
The UCI Algorithm. Suppose s carries the same value as t
Figure 1.
for every test case executed during design-time testing. This means that
the intervening logic could have been replaced by a single wire, without
invalidating any of the tests. In this case, the UCI algorithm ﬂags the
circuitry between s and t as potentially malicious.
the attacker will remain inactive during the entirety of the
design-time testing process.
The UCI algorithm works by creating a dataﬂow graph
corresponding to the source code under test and then looking
for any pair of signals (s, t), such that t is dependent on
s and the intervening logic between s and t could have
been replaced by a wire without affecting any of the outputs
computed during design-time testing. If such a pair is found,
that pair identiﬁes a portion of the circuit that does not
appear to have been activated during design-time testing and
thus might be malicious. Figure 1 illustrates the idea behind
UCI.
In this work, we identify circuits that have hidden (i.e.,
malicious) behavior, yet can evade detection by the UCI
algorithm. In particular, these circuits have the following
property: for all dependent signal pairs (s, t), there exists
at least one conﬁguration of inputs that would result in
s 6= t and would not cause the circuit to exhibit the hidden
behavior. This conﬁguration of inputs, if present in the suite
of test cases used during design-time testing, ensures the
UCI algorithm will not ﬂag the circuitry between s and t as
potentially malicious. In other words, in our circuits there
is no pair of dependent signals that are always equal during
design-time testing.
To produce these attack circuits, we developed a search
algorithm for ﬁnding circuits that are malicious (have hidden
behavior), admissible (would pass design-time testing), and
stealthy (would evade UCI). The algorithm is straightfor-
ward, a bounded exhaustive enumeration of possible combi-
national logic circuits from a given set of gates, yet it proves
powerful in ﬁnding hardware that defeats UCI.
Using one of the circuits returned by our search, we imple-
ment a practical attack against an open-source processor. We
insert a backdoor into an open-source processor and show
that the backdoor is not detected by the UCI algorithm.
Our backdoor allows a user-level program that knows the
secret handshake to enter supervisor mode and thus take
control of the system. The behavior of our attack is identical
to one described in earlier work on malicious backdoors
in hardware [2], but unlike prior work, our backdoor is
constructed in a way that evades detection by UCI. Our
attack targets the Leon3 processor,1 an implementation of the
SPARCv8 architecture.2 We synthesize a Leon3 processor
with our backdoor added and show that a user-level program
running on Linux on the processor can exploit the attack
and cause the processor to transition into supervisor mode
by executing a special sequence of instructions.
After describing our practical attack, we look at ways
UCI might be strengthened against the type of attacks we
built. Our work suggests there is no easy ﬁx to UCI,
and indeed, any UCI-like algorithm that depends solely
on test cases (which are necessarily non-exhaustive) for
the speciﬁcation of correct behavior will always run into
difﬁculty. We identify what we see as a major challenge for
any future UCI-like algorithm: identifying an adequate class
of malicious circuits to defend against. We discuss these
topics further in Section VI.
A. Contributions
This research contributes to the ﬁeld of malicious hard-
ware detection in the following ways:
• We show that UCI, the malicious hardware detection
scheme proposed by Hicks et al. [2], is ﬂawed. We
design and implement an attack on the Leon3 processor
that can be exploited to launch a software-level attack.
The malicious hardware evades detection by UCI, while
still allowing the processor to pass design-time testing.
• We present an approach for ﬁnding malicious circuits
that can be easily tailored and replicated for evaluating
future research in the area of malicious hardware detec-
tion. We use this approach to ﬁnd simple circuits that
contain malicious behavior, but that UCI would not be
able to detect.
• We present what we feel is a major challenge facing
any future design-time malicious hardware detection
scheme:
identifying an adequate class of malicious
circuits to defend against.
1http://www.gaisler.com
2http://www.sparc.org
B. Threat Model and Assumptions
We follow the same threat model and assumptions in-
troduced by Hicks et al. [2]. Namely, we assume a rogue
designer can insert malicious hardware into the circuit de-
sign, but the attack needs to remain hidden during traditional
design-time testing. The rogue designer cannot control the
suite of tests used for design-time testing of the hardware,
but can learn arbitrary information about the test cases (e.g.,
which instructions will appear in a test case).
II. BACKGROUND: UCI
Before describing our approach to ﬁnding attacks on
UCI, we ﬁrst explain how the UCI algorithm works. The
following description is intended only to give a high level
understanding of how the algorithm works. The technical
details can be found in the original paper [2].
UCI operates on the design of some circuit, given in
some hardware description language (HDL).3 The algorithm
proceeds in four phases: static analysis,
instrumentation,
veriﬁcation, and classiﬁcation. In the ﬁrst phase, a dataﬂow
graph is constructed from the source code (which may or
may not contain hidden malicious logic). In the graph, each
edge represents a signal (wire) and each node represents a
gate. The dataﬂow graph is used to ﬁnd the set of all dataﬂow
pairs: the set of pairs of signals (s, t) where there is some
path from s to t in the dataﬂow graph. Such a path indicates
that data can ﬂow from signal s to signal t. Another way to
think about it is that signal t is dependent on signal s.
Once the set of dataﬂow pairs has been identiﬁed, the
original source code is modiﬁed to include tracking hard-
ware: signals that note whenever any dataﬂow pair becomes
unequal, i.e., whenever s 6= t.
The third phase of the algorithm is veriﬁcation. The
newly instrumented code is simulated and run through a
battery of tests. At the end of the veriﬁcation phase, the
tracking signals show which, if any, dataﬂow pairs were
equal throughout all test cases. These dataﬂow pairs indicate
places where malicious circuitry may lie. If there is a
dataﬂow pair (s, t) for which the property s = t holds
throughout all test cases, then it follows that the circuitry
between s and t could be replaced with a single wire
(i.e., short-circuited) without affecting the result of any test
case. This intermediate circuitry is highlighted as potentially
malicious, as this logic seems to serve no purpose in any of
the test cases.
III. CONSTRUCTING ATTACKS: METHODOLOGY
In this section, we deﬁne a class of circuits that can
evade detection by UCI and that can be used for malicious
3Hicks et al. [2] state that their approach would work equally well on a
netlist describing the circuit. However, their exposition assumes the HDL
is provided and therefore, in our description, we do as well. This issue has
no bearing on the ability of UCI to detect our attacks.
65
purposes. Then, we conduct a systematic search for circuits
in this class, with the following approach:
1) We ﬁx an upper bound on the number of input signals
to the circuit and on the size of the circuit (total
number of gates). Also, we ﬁx the type of gates that
may be used in the circuit.
2) We enumerate all circuits of the class which fall within
the bounds.
3) We analyze each circuit generated and keep those that
evade UCI, meet our deﬁnition of malicious, and could
still pass design-time testing.
Size:
2) Suppose C1 = (f1, S1) and C2 = (f2, S2)
are circuits, and suppose the circuit C is
formed by combining the outputs of circuits
C1 and C2 with a 2-input gate g from the
basis of gates, i.e., C = g(C1, C2). Then the
resulting circuit can be expressed as
C = (g(f1, f2), S1 ∪ S2 ∪ {f1, f2}).
A similar pattern applies to gates with more
or less than 2 inputs.
All circuits produced by this search defeat UCI and
could be used by an attacker to insert a stealthy, malicious
backdoor into a target hardware design. We deﬁne search
criteria that are sufﬁcient for a circuit to evade detection
by UCI, but the criteria are by no means necessary: there
may be other ways to construct circuits that defeat UCI. The
search criteria are designed to keep the search practical. As
shown in Section IV, the class of circuits the search produces
is rich enough to defeat UCI and produce a malicious circuit
that can be used in a practical attack.
A. Deﬁnitions
Before deﬁning the class of circuits targeted by our search,
we deﬁne the following terms:
Basis of Gates:
The basis of gates is a set G = {g0, g1, . . . , gn}
of logic gates available for use in building circuits.
Circuits generated by our search will use only these
gates.
Circuit:
For our purposes, a circuit C is some combina-
tional logic built using gates from the basis. C(x)
denotes the output of C on input x. We focus on
circuits that produce a single bit of output, so a
circuit C deﬁnes an output function f from n-
bit inputs to 1-bit outputs: namely, the function
f : {0, 1}n → {0, 1} given by f (x) = C(x). The
output function f speciﬁes only the input-output
behavior of the circuit, whereas the circuit C itself
also records the internal structure of the circuit.
Each internal wire w of C computes some function
fw. In our search algorithm, for each circuit C we
store only its output function f and the set S =
{fw : w is an internal wire of C} of functions for
each internal wire of C. For conciseness, we often
identify the circuit C with this information: C =
(f, S). Given an arbitrarily complex circuit design,
we can compute f, S recursively, as follows:
1) If C is a single wire connecting an input
x to the output, it computes the projection
function f (x) = x and has no internal wires:
C = (f, ∅).
The size of the circuit is the total number of gates
used to construct the circuit.
Trigger Condition:
We deﬁne two types of inputs to every circuit con-
structed: trigger and non-trigger. The non-trigger
inputs are the normal inputs, which are used in the
normal functionality of the circuit, while the trigger
inputs are used only to deﬁne a rare condition
under which the hidden malicious behavior will be
activated. In particular, the hidden behavior should
appear if and only if the set of trigger inputs
are driven with a single, speciﬁc, predetermined,
value (the trigger value). The trigger condition is
the condition that
the trigger inputs are driven
with that speciﬁc value. Thus, under the trigger
condition, a malicious circuit exhibits its special
hidden behavior.
The input x to the circuit
is decomposed into
x = (i, t), where i = (i0, . . . , iℓ) denotes the non-
trigger inputs and t = (t0, . . . , tm) denotes the
trigger inputs.
Non-Trigger Condition: