来做发现。我们服务采用Nginx来做负载均衡，开源社区的方案例
如Consul Template，都需要进行reload操作，而reload过程中
会造成大量的失败请求。我们现在基于Consul实现了一个nginx-
upsync-module。
高可用架构 50
Nginx仅需在upstream配置中声明Consul集群即可完成后端服
务的动态发现。
upstream test {
# fake server otherwise ngx_http_upstream will report error when startup
server 127.0.0.1:11111;
# all backend server will pull from consul when startup and will delete fake
server
consul 127.0.0.1:8500/v1/kv/upstreams/test update_timeout=6m update_
interval=500ms strong_dependency=off;
upstream_conf_path /usr/local/nginx/conf/upstreams/upstream_test.conf;
}
这个模块是用C语言实现的，效率已经经过线上验证，目前验证在
20W QPS压力没有问题。而且这个模块代码已经开源在Github上，
也欢迎大家提Issue：https://github.com/weibocom/nginx-
upsync-module。
高可用架构 51
下图是我们做的几种方案的性能对比：
当然我们的RPC框架motan也会支持Consul，实现机制同样也
是利用Consul的long polling机制，等待直到监听的X-Consul-
Index位置发生变化，这个功能已经在我们内网验证通过，不过由
于依赖整个motan框架，所以目前还没有开源。
Consul的监控
由于Consul处于系统核心位置，一旦出现问题会导致整体所有
集群失联，所以我们对Consul做了一系列保障措施，其中所有
Consul Server节点监控指标如下：
高可用架构 52
高可用架构 53
Leader节点监控指标如下图：
高可用架构 54
Consul的坑
除了使用不当导致的问题之外，Consul Server节点通信通道
UDP协议，偶发会出现server不停被摘除的现象，这个问题官方
已在跟进，计划会增加TCP的通道保证消息的可靠性。
高可用架构 55
容器调度
容器调度基于Swarm实现，依赖Consul来做节点发现（话说
Swarm才刚刚宣布Production Ready）。容器调度分为三级，应用-
应用池-应用实例，一个应用下有多个应用池，应用池可以按机房
和用途等来划分。一个应用池下有多个Docker容器形式的应用实例。
我们利用Swarm的Filter机制，实现了适应业务的调度算法。整
个调度过程分为两步：主机过滤：指定机房、内存、CPU、端口等
条件，筛选出符合条件的主机集合；策略选择：对符合条件的主机
集合进行打分，选择出最合适的主机，在其上创建容器以部署应用。
调度子系统Roam实现了批量的容器调度与编排。
高可用架构 56
业务调度
容器调度是于业务无关，具体串联起资源管理，容器调度，发现等
系统，完成业务容器最终跨云部署的是我们的JPool系统。JPool
除了完成日常的业务容器上线发布之外，最重要的是完成动态扩缩
容功能，使业务实现一键扩容、一键缩容，降低快速扩容成本。一
次扩容操示意图如下：
围绕这调度和发现，需要很多工具的支撑。例如为了使业务接入更
加方便，我们提供了自动打包工具，它包括代码打包、镜像打包的
解决方案，支持svn、gitlab等代码仓库，业务仅需要在工程中定
义pom.xml和Dockerfile即可实现一键打包代码，一键打包镜像，
过程可控，接入简单。
高可用架构 57
我们还对Docker的Registry，我们进行了一些优化，主要是针对
混合云跨机房场景，提供跨机房加速功能，整个服务架构如下：
混合云监控体系
微博体系在经历了多年的IT建设过程后，已经初步建立了一套完整
的信息化管理流程，极大地提升了微博业务能力。同时微博开展了
大量的IT基础设施建设(包括网络、机房、服务器、存储设置、数据库、
中间件及各业务应用系统等)。
高可用架构 58
针对于混合云体系，我们提供了一套完整的监控告警解决方案，实
现对于云上IT基础架构的整体监控与预警机制，最大程度地保证了
微博体系能够稳定地运行在混合云体系上，不间断地为用户提供优
质的服务。监控告警解决方案实现了四个级别上的监控与预警：
 系统级监控
 业务级监控
 资源级监控
 专线网络监控
系统级监控
混合云体系支持的系统级监控（与新浪sinawatch系统的对接）包
括：CPU，磁盘，网卡，IOPS，Load，内存。
高可用架构 59
业务监控
混合云体系集成了目前微博业务监控平台Graphite，自动提供了
业务级别(SLA)的实时监控与告警。所有的配置与操作都是系统自
动完成的，不需要用户进行额外的配置操作。
业务级别的监控包括：
 J VM监控: 实时监控堆、栈使用信息、统计gc收集时间、检查
JVM瓶颈等。
 吞吐量监控： 实时监控业务系统吞吐量(QPS或TPS)。
 平均耗时监控: 实时监控业务系统接口的平均耗时时间。
 单机性能监控: 实时监控单台服务器的各种业务指标。
 Slow监控: 监控服务器集群，实时显示当前业务系统中最慢的
性能瓶颈。
高可用架构 60
资源监控
混合云体系集成了目前微博资源监控平台sinadsp，自动提供了对
各种底层资源的实时监控与告警。所有的配置与操作都是系统自动
完成的，不需要用户进行额外的配置操作。
具体的监控指标包括：命中率，QPS/TPS，连接数，上行/下行带宽，
CPU，内存。
高可用架构 61
前进路上遇到的那些坑
需要注意的坑，实际在各部分中都有提及。今天分享的主要内容就
是这些了，当然业务上云，除了上面这些工作之外，还存在很多技
术挑战要解决。比如跨云的消息总线，缓存数据同步，容量评估，
流量调度，RPC框架，微服务化等。■
Q&A
Q1：为什么选Consul？看中有对比Zookeeper、etcd，
尤其是etcd？
我们有对比etcd和consul，主要还是看重了consul基于K-V
之外额外功能，比如支持DNS，支持ACL。另外etcd不对get
request做超时处理，Consul对blocking query有超时机制。
Q2：上面提到的方案主要是Java体系， 对于其他语言
（php, nodejs, golang）体系系统的是否有很好的支持（开
发、测试、发布部署、监控等）？
已经在开始php的支持。其实容器化之后，所有语言都是适用的。
Q3：Docker registry底层存储用的是什么，怎么保障高
可用的？
底层使用的Ceph，前端无状态，通过DNS做跨云智能解析，加速
下载。
高可用架构 62
Q4：Consul temple reload nginx时为什么会造成大量
请求失败呢，不是graceful的吗？
是graceful的，在QPS压力较大的情况下，由于需要进行大量重连，
过程中会产生较多失败请求。
Q5：Ceph IO情况怎么？高IO的是不是不太适合用Ceph？
针对Registry场景Ceph IO是可以胜任的。不过Ceph暂时还没
有宣布Production Ready，所以对于极端业务场景，请谨慎。
高可用架构 63
Docker 实战
使 用 开 源 Calico 构 建 Docker
多租户网络
作者/ 高永超(flex) PaaS 平台的网络需求
宜信大数据创新中心云平
台运维专家。目前专注于 在使用 Docker 构建 PaaS 平台的过程中，我们首先遇到的问题
DevOps 和 PaaS 平台开发
是需要选择一个满足需求的网络模型：
（基础设施方向）。曾在豆瓣
担任过 SA Team Leader。
 让每个容器拥有自己的网络栈，特别是独立的 IP 地址。
《Pro Puppet》第一版中文
 能够进行跨服务器的容器间通讯，同时不依赖特定的网络设备。
译者。
 有访问控制机制，不同应用之间互相隔离，有调用关系的能够通讯。
调研了几个主流的网络模型：
 Docker 原生的 Bridge 模型：NAT 机制导致无法使用容器 IP
进行跨服务器通讯（后来发现自定义网桥可以解决通讯问题，但
是觉得方案比较复杂）。
 Docker 原生的 Host 模型：大家都使用和服务器相同的 IP，端
口冲突问题很麻烦。
高可用架构 64
 Weave OVS 等基于隧道的模型：由于是基于隧道的技术，在
用户态进行封包解包，性能折损比较大，同时出现问题时网络抓
包调试会很蛋疼。
 在对上述模型都不怎么满意的情况下，发现了一个还不怎么被大
家关注的新项目：Project Calico。
Project Calico 是 纯 三 层 的 SDN 实 现，它 基 于 BPG 协 议 和
Linux 自己的路由转发机制，不依赖特殊硬件，没有使用 NAT
或 Tunnel 等技术。能够方便的部署在物理服务器，虚拟机（如
OpenStack）或者容器环境下。同时它自带的基于 Iptables 的
ACL 管理组件非常灵活，能够满足比较复杂的安全隔离需求。
高可用架构 65
使用 Calico 来实现 Docker 的跨服务器
通讯
环境准备
 两个 Linux 环境 node1|2（物理机，VM 均可），假定 IP 为：
192.168.78.21|22。
 为 了 简 单，请 将 node1|2 上 的 Iptables INPUT 策 略 设 为
ACCEPT，同时安装 Docker。
 一个可访问的 Etcd 集群（192.168.78.21:2379），Calico 使
用其进行数据存放和节点发现
启动 Calico
在 node1|2 上面下载控制脚本：
# wget https://github.com/projectcalico/calico-docker/releases/download/