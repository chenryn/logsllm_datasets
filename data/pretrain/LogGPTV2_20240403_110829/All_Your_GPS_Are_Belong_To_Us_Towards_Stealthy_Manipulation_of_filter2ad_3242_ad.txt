can signiﬁcantly increase the hit rate (blue lines) com-
paring to those of the basic algorithm (red lines). In ad-
dition, Figure 5e shows that iterative algorithm also sig-
niﬁcantly increases the total number of bypassed grids by
all the victim routes, i.e. the number of potential target
destinations for the attacker.
Endangering Attack Result.
If the attacker aims
to endanger the victim, then we focus on the wrong-way
rate. Given a taxi trip, we aim to ﬁnd at least one victim
route that contains a wrong way segment. The basic al-
gorithm identiﬁed a wrong-way victim route for 599 out
of the 600 taxi trips (99.8%). Notably, 90.4% of trips
have the victim routes that contain a highway type of
wrong way segment, which incurs real danger.
Boston vs. Manhattan.
Boston has denser road net-
works and irregular road shapes. Manhattan has a sparser
and grid-like road network. The road network features
affect the attack performance. As shown in Figure 5b and
Figure 5c, the smaller grid size helps Boston to reduce
the hit rate deﬁcit against Manhattan, since the dense
road segments in Boston allow us to divert the victim
to more precise destinations. In addition, since Boston
has more irregular roads, it is more difﬁcult to search
for a long victim route that matches the ghost route. On
the contrary, Manhattan’s grid-like road structure yields
a better match for long victim routes as shown in Fig-
ure 5a. Our attack works for small cities, but will yield
fewer options for attackers (validated in our real-world
driving test).
Original Destination Estimation.
Recall that to run
the attack algorithm, the attacker needs some knowledge
about D, the original destination of the victim. Here,
we evaluate the impact of the inaccurate estimation of
D. More speciﬁcally, given a true D, we randomly set
an estimated D(cid:48) that is within 200m, 500m or 1000m.
Using D(cid:48), we generate the estimated route, and then cal-
culate the overlapped portion with the original route. As
shown in Figure 5f, even if the estimated destination is
not accurate, there are enough overlapped segments (in
the beginning) that can help to generate the victim routes.
For example, even with 1000m error, the attacker can di-
USENIX Association
27th USENIX Security Symposium    1535
(cid:48)(cid:53)(cid:48)(cid:48)(cid:49)(cid:48)(cid:48)(cid:48)(cid:49)(cid:53)(cid:48)(cid:48)(cid:65)(cid:118)(cid:101)(cid:114)(cid:97)(cid:103)(cid:101)(cid:32)(cid:100)(cid:105)(cid:118)(cid:101)(cid:114)(cid:116)(cid:101)(cid:100)(cid:32)(cid:100)(cid:105)(cid:115)(cid:116)(cid:97)(cid:110)(cid:99)(cid:101)(cid:32)(cid:40)(cid:109)(cid:41)(cid:48)(cid:48)(cid:46)(cid:50)(cid:48)(cid:46)(cid:52)(cid:48)(cid:46)(cid:54)(cid:48)(cid:46)(cid:56)(cid:49)(cid:67)(cid:68)(cid:70)(cid:66)(cid:79)(cid:83)(cid:45)(cid:66)(cid:77)(cid:65)(cid:78)(cid:45)(cid:66)(cid:77)(cid:65)(cid:78)(cid:45)(cid:73)(cid:66)(cid:79)(cid:83)(cid:45)(cid:73)(cid:48)(cid:48)(cid:46)(cid:50)(cid:48)(cid:46)(cid:52)(cid:48)(cid:46)(cid:54)(cid:48)(cid:46)(cid:56)(cid:49)(cid:72)(cid:105)(cid:116)(cid:32)(cid:114)(cid:97)(cid:116)(cid:101)(cid:32)(cid:40)(cid:103)(cid:114)(cid:105)(cid:100)(cid:32)(cid:115)(cid:105)(cid:122)(cid:101)(cid:32)(cid:61)(cid:32)(cid:53)(cid:48)(cid:48)(cid:109)(cid:41)(cid:48)(cid:48)(cid:46)(cid:50)(cid:48)(cid:46)(cid:52)(cid:48)(cid:46)(cid:54)(cid:48)(cid:46)(cid:56)(cid:49)(cid:67)(cid:68)(cid:70)(cid:66)(cid:50)(cid:48)(cid:48)(cid:48)(cid:77)(cid:50)(cid:48)(cid:48)(cid:48)(cid:66)(cid:49)(cid:48)(cid:48)(cid:48)(cid:77)(cid:49)(cid:48)(cid:48)(cid:48)(cid:66)(cid:53)(cid:48)(cid:48)(cid:77)(cid:53)(cid:48)(cid:48)(cid:48)(cid:48)(cid:46)(cid:50)(cid:48)(cid:46)(cid:52)(cid:48)(cid:46)(cid:54)(cid:48)(cid:46)(cid:56)(cid:49)(cid:72)(cid:105)(cid:116)(cid:32)(cid:114)(cid:97)(cid:116)(cid:101)(cid:32)(cid:40)(cid:103)(cid:114)(cid:105)(cid:100)(cid:32)(cid:115)(cid:105)(cid:122)(cid:101)(cid:32)(cid:61)(cid:32)(cid:50)(cid:48)(cid:48)(cid:109)(cid:41)(cid:48)(cid:48)(cid:46)(cid:50)(cid:48)(cid:46)(cid:52)(cid:48)(cid:46)(cid:54)(cid:48)(cid:46)(cid:56)(cid:49)(cid:67)(cid:68)(cid:70)(cid:66)(cid:50)(cid:48)(cid:48)(cid:48)(cid:77)(cid:50)(cid:48)(cid:48)(cid:48)(cid:66)(cid:49)(cid:48)(cid:48)(cid:48)(cid:77)(cid:49)(cid:48)(cid:48)(cid:48)(cid:77)(cid:53)(cid:48)(cid:48)(cid:66)(cid:53)(cid:48)(cid:48)(cid:48)(cid:48)(cid:46)(cid:50)(cid:48)(cid:46)(cid:52)(cid:48)(cid:46)(cid:54)(cid:48)(cid:46)(cid:56)(cid:49)(cid:72)(cid:105)(cid:116)(cid:32)(cid:114)(cid:97)(cid:116)(cid:101)(cid:32)(cid:40)(cid:103)(cid:114)(cid:105)(cid:100)(cid:32)(cid:115)(cid:105)(cid:122)(cid:101)(cid:32)(cid:61)(cid:32)(cid:50)(cid:48)(cid:48)(cid:109)(cid:41)(cid:48)(cid:48)(cid:46)(cid:50)(cid:48)(cid:46)(cid:52)(cid:48)(cid:46)(cid:54)(cid:48)(cid:46)(cid:56)(cid:49)(cid:67)(cid:68)(cid:70)(cid:77)(cid:50)(cid:48)(cid:48)(cid:48)(cid:45)(cid:66)(cid:77)(cid:49)(cid:48)(cid:48)(cid:48)(cid:45)(cid:66)(cid:77)(cid:50)(cid:48)(cid:48)(cid:48)(cid:45)(cid:73)(cid:77)(cid:53)(cid:48)(cid:48)(cid:45)(cid:66)(cid:77)(cid:49)(cid:48)(cid:48)(cid:48)(cid:45)(cid:73)(cid:77)(cid:53)(cid:48)(cid:48)(cid:45)(cid:73)(cid:48)(cid:53)(cid:48)(cid:48)(cid:49)(cid:48)(cid:48)(cid:48)(cid:49)(cid:53)(cid:48)(cid:48)(cid:35)(cid:32)(cid:111)(cid:102)(cid:32)(cid:116)(cid:97)(cid:114)(cid:103)(cid:101)(cid:116)(cid:101)(cid:100)(cid:32)(cid:100)(cid:101)(cid:115)(cid:116)(cid:105)(cid:110)(cid:97)(cid:116)(cid:105)(cid:111)(cid:110)(cid:115)(cid:48)(cid:48)(cid:46)(cid:50)(cid:48)(cid:46)(cid:52)(cid:48)(cid:46)(cid:54)(cid:48)(cid:46)(cid:56)(cid:49)(cid:67)(cid:68)(cid:70)(cid:77)(cid:65)(cid:78)(cid:45)(cid:66)(cid:66)(cid:79)(cid:83)(cid:45)(cid:66)(cid:77)(cid:65)(cid:78)(cid:45)(cid:73)(cid:66)(cid:79)(cid:83)(cid:45)(cid:73)(cid:48)(cid:48)(cid:46)(cid:50)(cid:48)(cid:46)(cid:52)(cid:48)(cid:46)(cid:54)(cid:48)(cid:46)(cid:56)(cid:49)(cid:65)(cid:118)(cid:101)(cid:114)(cid:97)(cid:103)(cid:101)(cid:32)(cid:111)(cid:118)(cid:101)(cid:114)(cid:108)(cid:97)(cid:112)(cid:32)(cid:114)(cid:97)(cid:116)(cid:101)(cid:32)(cid:112)(cid:101)(cid:114)(cid:32)(cid:114)(cid:111)(cid:117)(cid:116)(cid:101)(cid:48)(cid:48)(cid:46)(cid:50)(cid:48)(cid:46)(cid:52)(cid:48)(cid:46)(cid:54)(cid:48)(cid:46)(cid:56)(cid:49)(cid:67)(cid:68)(cid:70)(cid:66)(cid:49)(cid:48)(cid:48)(cid:48)(cid:77)(cid:49)(cid:48)(cid:48)(cid:48)(cid:66)(cid:53)(cid:48)(cid:48)(cid:77)(cid:53)(cid:48)(cid:48)(cid:66)(cid:50)(cid:48)(cid:48)(cid:77)(cid:50)(cid:48)(cid:48)tion, there is another -42.41 dB free space propagation
loss at a two-meter distance. This means, beyond two
meters away from the car, the signal strength is already
very weak (about -127.41 dBm), which cannot take the
lock of any GPS devices.
In total, we tested on two different routes as shown
in Figure 6. In both screenshots, lines A → D represent
original routes. Blue lines stand for ghost routes, while
black lines stand for victim routes. A is the user’s ac-
tual location and B is the corresponding ghost location.
C is the user’s diverted destination, D is the original des-
tination. In the ﬁrst case (Figure 6a), the attacker set the
ghost location to another location on the original route.
Our test showed that this indeed can avoid triggering the
“re-calculating” voice prompt. The route took nine min-
utes and the driver was successfully diverted to the pre-
deﬁned location 2.1 kilometers away from the original
destination. In the second case (Figure 6b), the attacker
set the ghost location off the original route, which trig-
gered a “re-calculating” voice prompt. This time, the
driver drove ﬁve minutes and was diverted 2.5 kilometers
away. In both cases, the smartphone was locked to the
spoofed signal without dropping once. The sequences
of fake locations were fed to the phone smoothly with
a 10Hz update frequency. Despite the potential cross-
checks of heading and ﬁlters embedded in Google Maps,
the navigation instructions were triggered in time.
7 Attacks with Human in the Loop
Next, we examine how stealthy the attack can be to hu-
man drivers (victims) through a user study. As previously
stated, the attack focuses on people who drive in the un-
familiar locations because they would be more likely to
rely on the GPS navigation (instead of their own knowl-
edge of the roads). We will also check the validity of
this assumption in the user study. Our study cannot in-
volve attacking human subjects when they drive real cars
Instead, we conduct a de-
due to safety implications.
ceptive user study in a simulated environment using a
customized driving simulator. Our study received the ap-
proval of our local IRB (#17-936).
7.1 User Study Methodology
Our user study examines three high-level research ques-
tions. R1: how do users use GPS navigation systems in
practice? R2: under what conditions is the GPS spoof-
ing attack more likely to deceive users successfully? R3:
what are the user perceptions towards the GPS spooﬁng
attack? We explore the answers with three key steps: pre-
study survey, driving tests, and post-study interview. To
avoid alerting the participants, we frame the study with a
non-security purpose, stating that the study is to test the
(a) On-Route Attack
(b) Off-Route Attack
Figure 6: The original routes and victim routes in the
real-world driving tests.
vert the victim using the ﬁrst half of the ghost navigation
route (medium 0.5 overlap rate).
Computation Time Delay.
The ghost route search-
ing can be completed within milliseconds for the basic
attack. The average searching time for one ghost lo-
cation candidate is 0.2ms in Manhattan and 0.3ms in
Boston. The iterative attack takes a longer but accept-
able time: 0.13s in Manhattan and 0.32s in Boston. Note
that attacker can always pre-compute the route (within a
minute) before the victim arrives the attack location.
6.3 Real-world Driving Tests
We implemented the full attack algorithm and validated
the feasibility through real-world driving tests. Two au-
thors performed the same-car attack using our own car.
One author acted as the driver (victim) who strictly fol-
lowed the navigation instructions from the Google Maps
(v9.72.2) running on the phone (XIAOMI MIX2 with
Android 8.0 and HUAWEI P8 with Android 6.0). The
other author sat on the backseat to operate the spoofer
and ran the attack algorithm on a laptop. As previously
stated, the spoofer can tell apart the fake GPS signals
with the real ones, and thus the attacker knows the true
location of the victim. The goal of the real-world driving
tests is to examine if the spoofer can trigger the fake nav-
igation instruction in real-time right before users need to
make a navigation decision.
Similar as early measurements, we obtained a legal
permission from the local radio regulation authority, and
conducted the experiments exclusively in China. In addi-
tion, we have taken active steps to make sure the spoof-
ing signals did not affect innocent users or cars. More
speciﬁcally, we performed our measurements in a sub-
urb area after midnight when there were almost no other
cars on the road. To minimize the impact of the spoof-
ing signals, we reduce the transmit power of the spoofer
to the minimum (-40 dBm) and then use attenuators (30
dB) to reduce the signal strength after locking in. The
metal structure of the car also acts as a shield to contain
the spooﬁng signals (about 15 dB attenuation). In addi-
1536    27th USENIX Security Symposium
USENIX Association
(a) Experiment Setups
(b) ETS II Game View
(c) Google Street View
Figure 7: User study setups; The ETS II Game View is comparable to the Google Street View at the same location.
usability of our simulation software. We debrief users
after the driving test to obtain the informed consent. The
study takes about 50 minutes and we compensate each
participant $10.
Pre-study Survey.
The survey asks two questions:
(1) how often do you use GPS navigation services when
driving in familiar locations (e.g., home and work) and
unfamiliar locations (e.g., visiting a new city). (2) what
information provided by the navigation service do you
primarily rely on during driving?
Driving Tests.
To simulate a realistic driving sce-
nario, we build a simulator by modifying a popular driv-
ing simulation game “Euro Truck Simulator II” (ETS
II) [2]. We use ETS II for three reasons. First, the game
presents the ﬁrst-person view with realistic vehicle inte-
rior and dashboard. In addition to the front view, the par-
ticipant can easily move the view-angle (to see through
the passenger window and the backseat) by moving the
cursor. This provides a wide view range to the partic-
ipant. Second, the simulator can load real-world maps
where the 3D street view mimics the reality. Figure 7b
and Figure 7c show the side-by-side companion of the
game view (of a 3:1 map) and the actual street view (from
Google Street View) at the same location. Because the
street view is rendered in a high-resolution, the street
signs and road names are clearly displayed. Third, the
simulator SDK allows us to control the day-and-night
settings and special weather conditions. We provide a
demo video under this link2.
For the driving test, we simulate attacking a victim
who drives in a new city. We display the driver’s view
on a 22 inch LED display (1920 x 1200) and load a 3:1
map of Budapest in Hungary [3], which is considered an
unfamiliar city for our participants. At the same time, we
run Google Maps on an Android smartphone as the nav-
igation app. The app provides turn-by-turn navigation,
and the voice prompt reads the street names. The smart-
phone is placed in front of the LED display (near the
“dashboard” area) as shown in Figure 7a. For ethical and
2Demo:
https://www.dropbox.com/sh/h9zq8dpw6y0w12o/
AABZiKCUOhe44Bu1CtHZzHLta
(a) Original Route
(b) Victim Route
Figure 8: The original and victim route for the user study.
legal reasons, we cannot directly spoof the GPS signal
of the smartphone. Instead, the smartphone runs a dedi-
cated app (developed by us) to fetch GPS sequences from
a server. The server reads the GPS information from the
driving simulator in real time and generates fake loca-
tions for the smartphone. In this way, we can directly
manipulate the GPS read of the smartphone for the user
study.
To examine user reactions to the attack, we assign
each participant driving tasks. The participants will drive
to deliver packages to a given destination following the
navigation of Google Maps. Figure 8 shows the driving
routes used in our user study. Figure 8a shows the orig-
inal route that the participant is supposed to take. Fig-
ure 8b shows the route to which the attacker aims to de-
tour the participants. This route is chosen because it con-
tains a high-way in the victim route, and only local-ways
in the original route. These are the clear discrepancies for
the victim to recognize. We tune two parameters: driving
time (day or night) and weather (rainy or clear). The par-
ticipant will deliver the package four times (on the same
route) in this order: “rainy night”, “clear night”, “rainy
day”, and “clear day”. This order makes it easier to rec-
ognize the attack in the end than at the beginning. The
experiment stops whenever the participant recognizes the
attack. Note that the attack covers the takeover phase
when the phone loses the GPS signal for a while and then
jumps to a new location.
To help the participants to get familiar with the driving
simulator, we spend about 5–10 minutes to let the partic-
USENIX Association
27th USENIX Security Symposium    1537
ipants play with the simulator before the real tests. We
also use the time to train the participants to “think-aloud”
— expressing their thoughts and actions verbally. Dur-
ing the real test, we encourage the participants to think-
aloud and record the audio.
Post-study Interview.
In the interview, we ﬁrst de-
brief the participants about the real purpose of the study.
Second, we ask about their perceptions towards GPS
spooﬁng attacks. Third, we let the participants comment
on the key differences between using the driving simu-
lator and their real-world driving. The participants can
withdraw their data at any time and can still receive the
full compensation.
Recruiting Participants.
We performed the user
study in both the U.S. and China. The user study ma-
terials have been translated into the respective languages
of the participants. Given that the study requires the par-
ticipants to physically come to the lab (and stay for about
one hour), we cannot perform the study on a massive
scale. With a limited scale, our goal is to recruit a diverse
sample of users. We distribute our study information on
social media, user study websites, and student mailing
lists. We recruited 40 participants (20 in the U.S. and 20
in China). Among the 40 participants, there are 30 male
and 10 female. 17 people are 26–35 years old, and 20
people are 18–25, and 3 people are 36–50. Regarding
the driving experience, 22 people drive for <3 years, 16
people drive for 3–10 years, and 2 people drive for 10–20
years. Our participants are slightly biased towards tech-
savvy users: 20 users (50%) have a Computer Science
background.
7.2 User Study Results
Driving and Navigation Habits.
Users are more
likely to use GPS navigation systems when traveling in
unfamiliar areas. We ask users to rate how often they
use GPS in “familiar”, “not-too-familiar” and “unfamil-
iar” areas with a scale of 10 (1=never; 10=almost every
time). The U.S. participants’ the average score for un-
familiar places is much higher (7.85) than familiar loca-
tions (4.55). The results from China are consistent (10.0
vs. 3.93). This means, our attack may not be applicable
to familiar area since people don’t rely on GPS.
Users are more likely to rely on the voice prompt
and visual instructions than the textual information. We
present a Google Maps screen and ask which informa-
tion the participant typically rely on to make driving de-
cisions (a multi-choice question). In the U.S., 13 users
(68.4%) choose voice prompt, 11 users (57.9%) rely on
visual elements such as road shapes and arrows, and only
6 users (31.6%) choose textual information such as street
names. The results from China are consistent. These re-
sults are in favor of our attack, which is designed to ma-
nipulate the voice and the visual elements.
User Reactions to GPS Spooﬁng Attacks.
Our at-
tack has achieved a high successful rate (95%). Out of 40
people, only one U.S. participant and one Chinese partic-
ipant recognized the attack. The rest 38 participants all
ﬁnished the four rounds of driving tasks and followed the
navigation to reach the wrong destinations.
Both participants recognized the attack because they
detected certain inconsistency between the navigation in-
formation and the surrounding environment on the road.
The U.S. participant (user#38, m, 18-25, driving <3
years) recognized the attack during the second round
(clear night). He was driving on a high way with a gas
station on his right when he realized that the Google
Maps showed that he was on a local way without a gas
station nearby. He also checked the street signs and rec-
ognized the inconsistent road names. The Chinese par-