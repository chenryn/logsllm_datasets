high reputation scores) using bad PIPs. However, this as-
sumption might not be true because a normal user’s com-
puter can be hacked and turned into a bad PIP so this nor-
0.6%
0.3%
1.0% 32.1% 66.2% 0.1%
0.5% 21.6% 77.5% 0.1%
# Users % % Inter- % % De- % Un-
in 1,000 Good mediate Bad lected known
Case
A ∩ B
551.9
A ∪ B 1,154.2
Table 10: The user reputation in July 2011, for users who
had positive reputation back in August, 2010. We consider
two criteria: (A) user name is within the top 3 naming pat-
terns; (B) user registration date is in the top 1 registration
month. First row: Both criteria are true. Second row: Ei-
ther criteria is true.
mal user’s activities are mixed with bad users. To increase
conﬁdence, we correlated events from diﬀerent bad PIPs to-
gether and identify users that login from multiple bad PIPs.
To further distinguish bad users from good ones, we conser-
vatively use the following two criteria:
Top Registration Month: This is similar to the valida-
tion method we use in Section §4.3. For each PIP, we place
accounts into bins according to their registration month. As
a bad PIP is dominantly used by malicious users, an account
has a high chance of being malicious if it falls into the top
bin that has the most number of accounts.
Top 3 Naming Patterns: The Hotmail group extracts
the naming pattern (how the user name is structured, e.g.,
words plus 2 digits) of each user account, and we place ac-
counts into into bins according to their naming patterns.
Accounts that fall into the top 3 bins on a bad PIP are also
very suspicious.
For users with good reputation scores as of August, 2010,
but login from at least 2 bad PIPs in that month, we exam-
ine the above two criteria. We consider two cases here: (i)
Both criteria are true, and (ii) either criterion is true. Sim-
ilar to the previous sections, we check the reputation scores
according to the reputation system in July 2011. Table 10
shows that only less than 0.6% of the users remain good 11
months later for both cases.
In the “both true” case, we
observed that more than 66% of the accounts are deleted,
and more than 32% of the accounts are eventually classiﬁed
as bad. This suggests that our PIP list can eﬀectively de-
tect malicious users months before the Hotmail reputation
system does.
6. CONCLUSION
The ability to distinguish bad or abused populated IP ad-
dresses from good ones is critical to online service providers.
As a ﬁrst step towards this direction, we propose PIPMiner,
a fully automated method to classify PIPs with a high ac-
curacy. We demonstrate that the labeled PIP list can help
identify attacks months before other detection methods. Al-
though PIP lists are derived from service logs and thus may
be application-speciﬁc, we show that they can be applied
across datasets to detect new attacks. An interesting future
direction is to study the overlaps and correlations among
PIPs derived from diﬀerent services, and to merge these
PIPs for detecting attacks that would be hard to identify
by a single service provider alone.
338Acknowledgements
We thank Martin Abadi and Qifa Ke for their valuable ad-
vice and thank Mihai Budiu and Jon Currey their help on
DryadLINQ. We are also grateful to Linda McColm, Keiji
Oenoki, Krish Vitaldevara, Vasanth Vemula from the Hot-
mail team, and Jeﬀ Carnahan, Harry Katz, Ivan Osipkov,
Robert Sim from the Windows Live Safety Platform team
for providing us with data and valuable comments.
References
[1] GML AdaBoost Matlab Toolbox.
http://goo.gl/vh0R9.
[2] Networks enterprise data acquisition and IP rotation
services. http://x5.net.
[3] Quova. http://www.quova.com/.
[4] ToR network status.
http://torstatus.blutmagie.de/.
[5] J. D. Brutlag. Aberrant behavior detection in time
series for network monitoring. In USENIX Conference
on System Administration, 2000.
[6] X. Cai and J. Heidemann. Understanding block-level
address usage in the visible Internet. In SIGCOMM,
2010.
[7] M. Casado and M. J. Freedman. Peering through the
shroud: The eﬀect of edge opacity on IP-based client
identiﬁcation. In NSDI, 2007.
[8] C.-C. Chang and C.-J. Lin. LIBSVM: A library for
support vector machines. ACM Transactions on
Intelligent Systems and Technology, 2011.
[9] R. Dingledine, N. Mathewson, and P. Syverson. ToR:
The second-generation onion router. In USENIX
Security Symposium, 2004.
[10] H. Eidnes, G. de Groot, and P. Vixie. Classless
IN-ADDR.ARPA delegation. RFC 2317, 1998.
[11] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang,
and C.-J. Lin. LIBLINEAR: A library for large linear
classiﬁcation. Journal of Machine Learning Research,
2008.
[12] S. Hao, N. A. Syed, N. Feamster, A. G. Gray, and
S. Krasser. Detecting spammers with SNARE:
Spatio-temporal network-level automatic reputation
engine. In USENIX Security Symposium, 2009.
[13] M. Isard, M. Budiu, Y. Yu, A. Birrell, and D. Fetterly.
Dryad: Distributed data-parallel programs from
sequential building blocks. In EuroSys, 2007.
[14] J. P. John, F. Yu, Y. Xie, M. Abadi, and
A. Krishnamurthy. Searching the searchers with
searchaudit. In USENIX Security, 2010.
[15] J. Jung and E. Sit. An empirical study of spam traﬃc
and the use of DNS black lists. In IMC, 2004.
[16] E. Katz-Bassett, J. P. John, A. Krishnamurthy,
D. Wetherall, T. Anderson, and Y. Chawathe.
Towards IP geolocation using delay and topology
measurements. In IMC, 2006.
[17] H.-T. Lin, C.-J. Lin, and R. C. Weng. A note on
Platt’s probabilistic outputs for support vector
machines. Mach. Learn., 2007.
[18] A. Metwally and M. Paduano. Estimating the number
of users behind IP addresses for combating abusive
traﬃc. In KDD, 2011.
[19] S. Nagaraja, P. Mittal, C.-Y. Hong, M. Caesar, and
N. Borisov. BotGrep: detecting P2P botnets using
structured graph analysis. In USENIX Security
Symposium, 2010.
[20] J. C. Platt. Probabilistic outputs for support vector
machines and comparisons to regularized likelihood
methods. In Advances in Large Margin Classiﬁers,
1999.
[21] J. R. Quinlan. C4.5: programs for machine learning.
Morgan Kaufmann Publishers Inc., 1993.
[22] A. Ramachandran, N. Feamster, and D. Dagon.
Revealing botnet membership using DNSBL
counter-intelligence. In Usenix Workshop on Steps to
Reducing Unwanted Traﬃc on the Internet (SRUTI),
2006.
[23] A. Ramachandran, N. Feamster, and S. Vempala.
Filtering spam with behavioral blacklisting. In CCS,
2007.
[24] G. Stringhini, T. Holz, B. Stone-Gross, C. Kruegel,
and G. Vigna. Botmagniﬁer: Locating spambots on
the Internet. In USENIX Security Symposium, 2011.
[25] L. Wang, K. S. Park, R. Pang, V. Pai, and
L. Peterson. Reliability and security in the codeen
content distribution network. In USENIX ATC, 2004.
[26] Y. Xie, V. Sekar, D. A. Maltz, M. K. Reiter, and
H. Zhang. Worm origin identiﬁcation using random
moonwalks. In IEEE Symposium on Security and
Privacy, 2005.
[27] Y. Xie, F. Yu, and M. Abadi. De-anonymizing the
internet using unreliable ids. In SIGCOMM, 2009.
[28] Y. Xie, F. Yu, K. Achan, E. Gillum, M. Goldszmidt,
and T. Wobber. How dynamic are IP addresses? In
SIGCOMM, 2007.
[29] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten,
and I. Osipkov. Spamming botnets: Signatures and
characteristics. In SIGCOMM, 2008.
[30] Y. Yu, M. Isard, D. Fetterly, M. Budiu, U. Erlingsson,
P. K. Gunda, and J. Currey. DryadLINQ: A system
for general-purpose distributed data-parallel
computing using a high-level language. In OSDI, 2008.
[31] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and
E. Gillum. BotGraph: Large scale spamming botnet
detection. In NSDI, 2009.
APPENDIX
A.
IMPLEMENTATION
Our implementation consists of two stages.
In the ﬁrst
stage, we parse the data sets and extract PIPs with their
features and labels. We implement this stage in a parallel
fashion by harnessing a cluster of 240 machines. The sec-
ond stage is the training and testing stage. Fortunately, the
input to this stage is small enough (e.g., less than 200 MBs
for 1.7 million PIP addresses), allowing us to implement it
on a single machine.
Data Parsing and Feature Extraction: The ﬁrst stage
is implemented on top of Dryad, an execution engine allow-
ing distributed data-parallel computation [13]. Our primary
input data is a large collection of user login records. The
records are hash partitioned to a set of processing machines
according to the user login IP address, and then each ma-
chine independently computes per-IP account counts and
339per-IP request counts to derive PIP list and blocks. We
eﬃciently merge the remaining data sets such as the user
account data by performing distributed join operations. We
then partition the records that are associated with a PIP
address based on its block ID, ensuring that the records in
the same PIP blocks are processed by the same comput-
ing node. This is a critical phase to minimize the system
overhead, allowing computing nodes to derive PIP features
independently.
We further optimize the system performance using three
methods. First, we conﬁgure DryadLINQ to use dynamic
partitioning range keys, which are determined at run time
by sampling the input datasets. This helps balance the data
load on each machine, especially for our second partition
phase where the input key distribution is hard to estimate
in advance. Second, we minimize the cross-node communi-
cation cost by compressing the intermediate results. This re-
duces the communication overhead by ∼68%. Finally, some
PIP blocks consist of a very large number of IP addresses
(e.g., mobile gateways), each of which can potentially be as-
sociated with a disproportionate amount of records. This
can lead to an increased computation load on certain com-
puting nodes, making them the bottleneck of the operations,
especially for large data sets. To sidestep this, we randomly
sample requests of only the top 20 PIPs, which originally
carry the largest number of user requests. The per-PIP
sampling rate is automatically chosen such that the top 20
PIPs will ﬁnally have a similar number of user requests of
the 21st largest PIP. This scheme does not signiﬁcantly bias
the classiﬁcation results because PIPMiner requires only a
small number of requests per PIP to achieve high classiﬁca-
tion accuracy. This scheme, however, can reduce the overall
computation time for feature extraction by 35% − 55%.
Training and Testing: For training and testing, we ran
our experiments on a single machine with Quad Core CPU
and 8 GB memory. We use the LIBSVM [8] and LIBLIN-
EAR [11] toolkits in our implementation. To compare with
other classiﬁcation algorithms, we use GML AdaBoost [1]
and Quinlan’s C4.5 [21] decision tree. We also tested the
Matlab built-in classiﬁcation algorithms,
including Naive
Bayes, bagged decision trees and linear discriminant anal-
ysis (LDA), for performance comparison.
B. COMPARISON TO QUOVA PROXY LIST
We have shown that our PIP list can help ﬂag malicious
sign-ups right on the day of the sign-ups. This section
attempts to answer the question: Does our labeled PIP
list have wider applicability compared to commercial proxy
lists? To answer this question, we extract proxy IP addresses
in Quova’s GeoPoint data using the IP Routing Type ﬁeld
and apply the Quova proxy list to the Windows Live ID
sign-up abuse problem. We ﬁnd that >99.9% of the Quova
proxy IPs are not associated with any sign-up activities, and
99.8% of the PIPs that have good sign-ups are not included
by Quova’s list. For Quova proxy IPs that do have activities,
to ensure fair comparison, we only look at those that are as-
sociated with greater than 20 sign-up requests per month.
These proxies are categorized into diﬀerent types by Quova,
including mobile gateways, AOL proxies, regional proxies,
and international proxies. For each type of Quova prox-
ies, Figure 8 shows the fraction of good and bad sign-ups.
Figure 8: Given a certain type of IP addresses, the percent-
age of good and bad accounts. We use the Hotmail user
reputation trace in July, 2011 to classify users into good,
bad, intermediate, and unknown.
Case
|P|: Intl. Proxies (Quova)
|G|: Our good PIPs
|P ∩ G|: # Covered
|P ∩ G|/|P|: % Coverage
IP
Good
Address Sign-ups
1,164
3,951
203,087
397,539
939
80.6%
3,467
87.7%
Table 11: The number of good sign-ups that are originated
from our good PIPs and from Quova’s international proxies.
Clearly, mobile gateways, AOL proxies and regional proxies
all have mixed sign-up behaviors (20% of the sign-ups are
good and 40% of the sign-ups are bad), letting through a lot
of malicious sign-ups. Although Quova’s international prox-
ies are associated with a large percentage of good sign-ups,
our good PIP list already covers most of them: 80.6% of the
IPs and 87.7% of the good sign-ups as shown in Table 11.
C. TIME FORECASTING FEATURES
We apply forecasting models on data time series to ﬁnd
out abnormal periods, which might be the abuse periods of
good PIPs. As we observed strong periodicities from many
good PIPs, we adopt the additive Holt-Winters’ seasonal
forecasting model [5], which decouples a time series T [t] into
three factors: level L[t], trend B[t] and seasonal S[t]:
L[t] = α(T [t] − S[t − υ]) + (1 − α)(L[t − 1] + B[t − 1])
B[t] = β(L[t] − L[t − 1]) + (1 − β)(B[t − 1])
S[t] = γ(T [t] − L[t]) + (1 − γ)(S[t − υ])
The season length is denoted by υ, and the update rate pa-
rameters are α, β, and γ. Then the forecast F [t] simply adds
up these three factors, i.e., F [t] = L[t−1]+B[t−1]+S[t−υ].
To quantify whether the time series can be accurately pre-
dicted by the forecasting model, we call it an anomaly when
the forecast error is relatively large (i.e., the diﬀerence and
the ratio between the forecast value F [t] and the actual
value T [t] is larger than some thresholds). A grid search
is automatically performed to ﬁnd the best parameters and
thresholds that maximizing the cross-validation accuracy on
the sampled training data. For the anomaly threshold, we
search in diﬀerent multiples of the standard deviation of the
time series. Our features include the number and the density
of the low-volume anomalies (T [t] (cid:28) F [t]) and high-volume
anomalies (T [t] (cid:29) F [t]).
0%20%40%60%80%100%Quova Proxy Lists Our PIP List Good sign-ups: Bad sign-ups: Percentage of good/bad sign-up accounts Type of IP addresses 340