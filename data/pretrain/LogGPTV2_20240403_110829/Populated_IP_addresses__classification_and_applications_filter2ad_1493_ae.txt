### High Reputation Scores and Bad PIPs

It is often assumed that users with high reputation scores are unlikely to use bad PIPs (Potentially Infected or Malicious IP addresses). However, this assumption may not hold true, as a normal user's computer can be compromised and turned into a bad PIP. Consequently, the activities of such a compromised user can be mixed with those of bad users.

To increase confidence in our analysis, we correlated events from different bad PIPs and identified users who logged in from multiple bad PIPs. To further distinguish between bad and good users, we conservatively applied the following two criteria:

1. **Top Registration Month:**
   - This method is similar to the validation approach used in Section 4.3. For each PIP, we categorize accounts based on their registration month. Since a bad PIP is predominantly used by malicious users, an account registered in the month with the highest number of registrations has a higher likelihood of being malicious.

2. **Top 3 Naming Patterns:**
   - The Hotmail group extracts the naming pattern (e.g., words plus 2 digits) of each user account and categorizes them accordingly. Accounts that fall into the top 3 most common naming patterns on a bad PIP are considered highly suspicious.

For users with good reputation scores as of August 2010 but who logged in from at least two bad PIPs during that month, we examined the above two criteria. We considered two cases:
- **Both Criteria True:** Both the top registration month and top 3 naming patterns criteria are met.
- **Either Criterion True:** At least one of the criteria is met.

We then checked the reputation scores of these users according to the Hotmail reputation system in July 2011. Table 10 shows that less than 0.6% of the users remained good 11 months later in both cases.

In the "both true" case, more than 66% of the accounts were deleted, and more than 32% were eventually classified as bad. This suggests that our PIP list can effectively detect malicious users months before the Hotmail reputation system does.

### Conclusion

The ability to distinguish bad or abused PIPs from good ones is critical for online service providers. As a first step, we propose PIPMiner, a fully automated method to classify PIPs with high accuracy. Our labeled PIP list can help identify attacks months before other detection methods. Although PIP lists are derived from service logs and may be application-specific, they can be applied across datasets to detect new attacks. Future work could explore the overlaps and correlations among PIPs derived from different services, and merge these PIPs to detect attacks that would be hard to identify by a single service provider alone.

### Acknowledgements

We thank Martin Abadi and Qifa Ke for their valuable advice, and Mihai Budiu and Jon Currey for their help with DryadLINQ. We are also grateful to Linda McColm, Keiji Oenoki, Krish Vitaldevara, Vasanth Vemula from the Hotmail team, and Jeff Carnahan, Harry Katz, Ivan Osipkov, Robert Sim from the Windows Live Safety Platform team for providing data and valuable comments.

### References

[1] GML AdaBoost Matlab Toolbox. http://goo.gl/vh0R9
[2] Networks enterprise data acquisition and IP rotation services. http://x5.net
[3] Quova. http://www.quova.com/
[4] ToR network status. http://torstatus.blutmagie.de/
[5] J. D. Brutlag. Aberrant behavior detection in time series for network monitoring. In USENIX Conference on System Administration, 2000.
[6] X. Cai and J. Heidemann. Understanding block-level address usage in the visible Internet. In SIGCOMM, 2010.
[7] M. Casado and M. J. Freedman. Peering through the shroud: The effect of edge opacity on IP-based client identification. In NSDI, 2007.
[8] C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2011.
[9] R. Dingledine, N. Mathewson, and P. Syverson. ToR: The second-generation onion router. In USENIX Security Symposium, 2004.
[10] H. Eidnes, G. de Groot, and P. Vixie. Classless IN-ADDR.ARPA delegation. RFC 2317, 1998.
[11] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 2008.
[12] S. Hao, N. A. Syed, N. Feamster, A. G. Gray, and S. Krasser. Detecting spammers with SNARE: Spatio-temporal network-level automatic reputation engine. In USENIX Security Symposium, 2009.
[13] M. Isard, M. Budiu, Y. Yu, A. Birrell, and D. Fetterly. Dryad: Distributed data-parallel programs from sequential building blocks. In EuroSys, 2007.
[14] J. P. John, F. Yu, Y. Xie, M. Abadi, and A. Krishnamurthy. Searching the searchers with SearchAudit. In USENIX Security, 2010.
[15] J. Jung and E. Sit. An empirical study of spam traffic and the use of DNS black lists. In IMC, 2004.
[16] E. Katz-Bassett, J. P. John, A. Krishnamurthy, D. Wetherall, T. Anderson, and Y. Chawathe. Towards IP geolocation using delay and topology measurements. In IMC, 2006.
[17] H.-T. Lin, C.-J. Lin, and R. C. Weng. A note on Platt’s probabilistic outputs for support vector machines. Mach. Learn., 2007.
[18] A. Metwally and M. Paduano. Estimating the number of users behind IP addresses for combating abusive traffic. In KDD, 2011.
[19] S. Nagaraja, P. Mittal, C.-Y. Hong, M. Caesar, and N. Borisov. BotGrep: detecting P2P botnets using structured graph analysis. In USENIX Security Symposium, 2010.
[20] J. C. Platt. Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. In Advances in Large Margin Classifiers, 1999.
[21] J. R. Quinlan. C4.5: programs for machine learning. Morgan Kaufmann Publishers Inc., 1993.
[22] A. Ramachandran, N. Feamster, and D. Dagon. Revealing botnet membership using DNSBL counter-intelligence. In Usenix Workshop on Steps to Reducing Unwanted Traffic on the Internet (SRUTI), 2006.
[23] A. Ramachandran, N. Feamster, and S. Vempala. Filtering spam with behavioral blacklisting. In CCS, 2007.
[24] G. Stringhini, T. Holz, B. Stone-Gross, C. Kruegel, and G. Vigna. BotMagnifier: Locating spambots on the Internet. In USENIX Security Symposium, 2011.
[25] L. Wang, K. S. Park, R. Pang, V. Pai, and L. Peterson. Reliability and security in the Codeen content distribution network. In USENIX ATC, 2004.
[26] Y. Xie, V. Sekar, D. A. Maltz, M. K. Reiter, and H. Zhang. Worm origin identification using random moonwalks. In IEEE Symposium on Security and Privacy, 2005.
[27] Y. Xie, F. Yu, and M. Abadi. De-anonymizing the internet using unreliable IDs. In SIGCOMM, 2009.
[28] Y. Xie, F. Yu, K. Achan, E. Gillum, M. Goldszmidt, and T. Wobber. How dynamic are IP addresses? In SIGCOMM, 2007.
[29] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and I. Osipkov. Spamming botnets: Signatures and characteristics. In SIGCOMM, 2008.
[30] Y. Yu, M. Isard, D. Fetterly, M. Budiu, U. Erlingsson, P. K. Gunda, and J. Currey. DryadLINQ: A system for general-purpose distributed data-parallel computing using a high-level language. In OSDI, 2008.
[31] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and E. Gillum. BotGraph: Large scale spamming botnet detection. In NSDI, 2009.

### Appendix

#### A. Implementation

Our implementation consists of two stages:

1. **Data Parsing and Feature Extraction:**
   - In the first stage, we parse the datasets and extract PIPs along with their features and labels. This stage is implemented in a parallel fashion using a cluster of 240 machines.
   - The primary input data is a large collection of user login records. These records are hash-partitioned to a set of processing machines based on the user login IP address. Each machine independently computes per-IP account counts and request counts to derive the PIP list and blocks.
   - We efficiently merge the remaining datasets, such as user account data, by performing distributed join operations. Records associated with a PIP address are partitioned based on their block ID, ensuring that records within the same PIP block are processed by the same computing node. This minimizes system overhead and allows nodes to derive PIP features independently.
   - We further optimize system performance using three methods:
     - **Dynamic Partitioning Range Keys:** We configure DryadLINQ to use dynamic partitioning range keys, determined at runtime by sampling the input datasets. This balances the data load on each machine, especially in the second partition phase where the input key distribution is hard to estimate in advance.
     - **Compression of Intermediate Results:** We compress intermediate results to reduce cross-node communication costs by approximately 68%.
     - **Sampling Requests:** Some PIP blocks contain a very large number of IP addresses, leading to increased computation load on certain nodes. To mitigate this, we randomly sample requests from the top 20 PIPs, which carry the largest number of user requests. The per-PIP sampling rate is chosen such that the top 20 PIPs have a similar number of user requests as the 21st largest PIP. This reduces the overall computation time for feature extraction by 35-55%.

2. **Training and Testing:**
   - For training and testing, we ran experiments on a single machine with a Quad Core CPU and 8 GB memory. We used the LIBSVM [8] and LIBLINEAR [11] toolkits.
   - To compare with other classification algorithms, we used GML AdaBoost [1] and Quinlan’s C4.5 [21] decision tree. We also tested MATLAB built-in classification algorithms, including Naive Bayes, bagged decision trees, and linear discriminant analysis (LDA).

#### B. Comparison to Quova Proxy List

We demonstrated that our PIP list can flag malicious sign-ups on the day of sign-up. This section explores whether our labeled PIP list has broader applicability compared to commercial proxy lists like Quova's. We extracted proxy IP addresses from Quova’s GeoPoint data using the IP Routing Type field and applied the Quova proxy list to the Windows Live ID sign-up abuse problem. We found that over 99.9% of Quova proxy IPs were not associated with any sign-up activities, and 99.8% of the PIPs with good sign-ups were not included in Quova’s list. For Quova proxy IPs with activities, we only considered those with more than 20 sign-up requests per month. These proxies were categorized into different types, including mobile gateways, AOL proxies, regional proxies, and international proxies. Figure 8 shows the fraction of good and bad sign-ups for each type of Quova proxy.

**Table 11: Good Sign-Ups from Our Good PIPs and Quova’s International Proxies**

| Case | Intl. Proxies (Quova) | Our Good PIPs | # Covered | % Coverage |
|------|-----------------------|---------------|-----------|------------|
| | 1,164 | 3,951 | 203,087 | 397,539 |
| | 939 | 80.6% | 3,467 | 87.7% |

Clearly, mobile gateways, AOL proxies, and regional proxies all have mixed sign-up behaviors, letting through many malicious sign-ups. Although Quova’s international proxies are associated with a large percentage of good sign-ups, our good PIP list already covers 80.6% of the IPs and 87.7% of the good sign-ups.

#### C. Time Forecasting Features

We applied forecasting models to time series data to identify abnormal periods, which might indicate abuse periods of good PIPs. Given the strong periodicities observed in many good PIPs, we used the additive Holt-Winters’ seasonal forecasting model [5]. This model decomposes a time series \( T[t] \) into three factors: level \( L[t] \), trend \( B[t] \), and seasonal \( S[t] \):

\[
L[t] = \alpha (T[t] - S[t - \upsilon]) + (1 - \alpha)(L[t - 1] + B[t - 1])
\]
\[
B[t] = \beta (L[t] - L[t - 1]) + (1 - \beta)(B[t - 1])
\]
\[
S[t] = \gamma (T[t] - L[t]) + (1 - \gamma)(S[t - \upsilon])
\]

The season length is denoted by \( \upsilon \), and the update rate parameters are \( \alpha \), \( \beta \), and \( \gamma \). The forecast \( F[t] \) is then given by:

\[
F[t] = L[t - 1] + B[t - 1] + S[t - \upsilon]
\]

To quantify whether the time series can be accurately predicted by the forecasting model, we define an anomaly when the forecast error is relatively large (i.e., the difference and ratio between the forecast value \( F[t] \) and the actual value \( T[t] \) exceed certain thresholds). A grid search is performed to find the best parameters and thresholds that maximize the cross-validation accuracy on the sampled training data. For the anomaly threshold, we search in different multiples of the standard deviation of the time series. Our features include the number and density of low-volume anomalies (\( T[t] \ll F[t] \)) and high-volume anomalies (\( T[t] \gg F[t] \)).