I have installed Nginx, uWSGI, and Django on a VDS with 3 CPU cores. uWSGI is currently configured to use 6 processes, each with 5 threads. My goal is to configure uWSGI so that it uses processes for load balancing until all processes are busy, and then resorts to threads if necessary. However, it seems that uWSGI prefers using threads, and I haven't found a configuration option to change this behavior. Currently, the first process is utilizing 100% of the CPU time, the second process is using around 20%, and the remaining processes are mostly idle.

Our website typically receives 40 requests per second (r/s). Normally, 3 processes without any threads would be sufficient to handle the request load. However, request processing occasionally hangs due to various issues, such as locked shared resources. In these situations, one or more processes become unresponsive, leading to a backlog of requests. Users, growing impatient, repeatedly click the link, which further exacerbates the problem, causing all processes to hang and leaving all users waiting.

To improve the server's robustness, I considered increasing the number of threads. However, the Python Global Interpreter Lock (GIL) limits the effectiveness of multithreading in Python, as threads cannot fully utilize all CPU cores. Therefore, multiple processes are generally more effective for load balancing. Threads, on the other hand, can be beneficial in scenarios where there are locked shared resources or I/O wait delays, as a process can continue working while one of its threads is blocked.

I do not want to decrease the time limits unless absolutely necessary, as this could lead to showing error messages to users or making them wait for every request. Theoretically, the problem could be solved with threads, and I prefer to avoid these negative user experiences if possible.

**Proposed Solution:**

1. **Upgrade uWSGI to the latest stable version**: This ensures that you have access to the most recent features and bug fixes.
2. **Use the `--thunder-lock` option**: This option can help in distributing requests more evenly across processes.

After implementing these changes, I am now running with 50 threads per process, and all requests are being distributed more evenly among the processes.