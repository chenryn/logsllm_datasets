check
Object
Object
object
update
check
2
Object
Object
object
update
n
o
i
t
c
e
l
l
o
c
m
u
s
k
c
e
h
c
add
add
CROSSCHECK
check
Object
Object
object
update
check
Object
Object
object
update
n
o
i
t
c
e
l
l
o
c
m
u
s
k
c
e
h
c
add
add
Fig. 1. CROSSCHECK approach
As depicted in Figure 1, each time we update the checksum
during the execution of a request, this checksum Ci is added
to a checksum collection (CC) together with a unique object
id, i ∈ I = {1 . . . n} that is equal across all replicas for the
corresponding object. This id ﬁts two purposes: First, we can
efﬁciently compare objects across replica boundaries. Second, it
enables us to detect control-ﬂow changes as divergent execution
ﬂows result in a different sequence of checksums or divergent
checksum collections. We also add a reference to the state
object exhibiting the checksum and store it in the CC. In case
of recovery this enables the identiﬁcation of corrupted state
objects (see Section III-C).
After executing the request, all replicas perform a state
validation as shown in Figure 2. Initially all replicas broadcast
their checksum collection CC, together with a potential client
reply message RM and its checksum RC as  to the other replicas. As state object references are
s t a t e V a l i d a t i o n ( ){
b r o a d c a s t ();
while ( quorum );
) {
/ / compare t o o t h e r s :
f o r e a c h ( msgSet . e l e m e n t s ( )
)
i f ( vrfyMsgSet ({ chk . CC, chk . RC})
e l s e
quorum ++;
o r d e r e d B r o a d c a s t ();
)
}
msgSet . add ( chk ) ;
}
i f ( i s C l i e n t C o n n e c t e d == true )
e x t e r n a l i z e ();
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
}
Fig. 2. CROSSCHECK state validation algorithm
only valid at the origin, these are excluded from the 
message.
On each receipt of a  message, a replica calls
vrfyLocal() to verify its checksums (all Ci in CC and RC)
and the modiﬁed state object ids by comparison with the
received data from the remote replica (Line 6). Additionally, all
received messages are compared to each other by vrfyMsgSet()
(Line 12). Whenever an error is detected (Line 9 and 15), a
 request is send via the ordering stage. This
is required for recovery and causes all replicas eventually to
enter a quiescent state by ﬁnishing all running executions.
Meanwhile, error detection proceeds until a quorum of f+1
matching checksums is gathered.
At this point we are able to distinguish the corrupted from the
correct-working replicas and the affected state objects which
are added to a list for later recovery. Since the reply messages
RM are also exchanged, the replica responsible for the client
connection may externalize a correct reply to the client even
in the presence of a fault. As additional faults may occur
during reply to the client, the  may
contain RMu and RCv from any validated replica u and v.
This procedure is also described in [11] and enables client-side
error detection (if supported).
C. Recovering from faults
As outlined in our system model (see Section II), we consider
state corruptions of one or multiple state objects in f replicas.
This leaves a pool of f +1 fault-free replicas which can be used
for recovery. State corruptions are either detected ahead of state
object access (see Section III-A), or as part of crosschecking
the execution (see Section III-B). In the latter case, control-
ﬂow errors are also detected beside plain state corruptions. In
the most simple case, recovery from state corruptions that are
detected ahead of access can be handled by the generic object
protection, if object state duplication has been applied.
650
In the absence of a local object-state copy, the affected
state object has to be requested from any fault-free replica.
However, since the remaining fault-free replicas might already
have successfully passed and modiﬁed their fault-free copy
of the affected state object, there is no state object version
available that enables the direct replacement and continuation
of the effected request execution at the faulty replica. The same
problems arise if both state corruptions and control-ﬂow errors
are detected during the crosscheck phase.
Therefore, we use a synchronization model where the
remaining fault-free replicas ﬁnish the execution of ongoing
requests to provide updates for the faulty replica. In a naive
implementation we would simply compare all state object
checksums and replace faulty ones, however, this would be
time consuming. To minimize the overhead, we focus on the
deltas between the co-executing replicas that are determined
by their recent execution history.
If a state corruption is detected, we proceed as follows: First,
all replicas need to reach a quiescent state. Therefore, once a
fault is detected, a  request is distributed via
the ordering stage to all replicas ensuring that running request
executions are ﬁnished and no new executions are started.
More speciﬁcally, all requests that have been distributed via the
ordering stage before the  request are ﬁnished
by the fault-free replicas. After this point, all of them are in a
consistent state. The faulty replica ﬁnishes all already executing
requests and aborts request execution in case of detecting a
corrupted object. The latter prevents control-ﬂow errors and
contains the state corruption. Next, the faulty replica transmits a
list of all state-object checksums that have been changed during
or after the detection of the state corruption. This explicitly
includes requests that were executed concurrently to the fault-
detecting or faulty request. Once the fault-free replicas receive
the list of checksums, they build their own list and compile
a state delta. This state delta consists of state objects with
diverging checksums, state objects that are locally changed
due to request execution but not at the faulty replica, and state
objects that changed at the faulty replica but not locally. The
latter group is caused by control-ﬂow errors. The state delta
is then transmitted to the faulty replica, which in turn uses
the ﬁrst complete incoming data set to update its local state.
All requests that are not ﬁnished before recovery need to be
discarded by the faulty replica, since the state (delta) update
already covers those requests. However, if the faulty replica
is responsible for any client connection, it must externalize
the reply to the client. Therefore, the state-delta transfer also
includes the reply messages.
After ﬁnishing recovery, the repaired replica broadcasts a
 message via the ordering stage. Once received
by any replica, normal operation can be safely continued.
IV. IMPLEMENTATION
As a case study, we implemented our approach in an actively
replicated key-value store based on MEMCACHED++ (Figure 3),
a C++ version of memcached. In case of MEMCACHED++, all
relevant components of memcached are represented by classes
Client
Connect
Ordering
Dispatch
E
x
e
c
u
t
i
o
n
first
last
Dispatch
CROSSCHECK
Externalize
Replica R0
00
p
SPREAD
STATE
STATE
Replica Ri
Ordering
Dispatch
first
last
E
x
e
c
u
t
i
o
n
Dispatch
CROSSCHECK
Fig. 3. Prototype implementation
that can be individually hardened by applying GOP. These
components include a central hash table that manages all key-
value pairs, the individual key-value pairs, and a number of
management classes.
Such a replicated key-value store can be used to provide
a highly available source for data exchange (e.g., conﬁgu-
ration information) in distributed applications and could be
extended to offer coordination support similar to Chubby [1]
and Zookeeper [21]. MEMCACHED++ offers an object-oriented
design and features the same API and threading model as the
original version of memcached.
As described by the system model, we need to enforce an
ordered execution of requests. We achieve this by the integration
of ordering support into MEMCACHED++: On receipt of a client
request, a replica parses the request and broadcasts a client
request  to all replicas
(including itself) via the Spread Toolkit [18]. Spread provides a
reliable group communication channel and brings all requests
in one deﬁned order. After receiving , each replica
registers the new request to Storyboard [14], which creates
a lock-order prediction and ensures deterministic execution.
Afterwards, all replicas execute the request in a multi-threaded
– but controlled – way.
Before externalizing the reply, we perform the crosscheck
by exchanging  between the replicas and validating
its content (see Section III-B). While waiting for 
messages to arrive, we continue execution by processing further