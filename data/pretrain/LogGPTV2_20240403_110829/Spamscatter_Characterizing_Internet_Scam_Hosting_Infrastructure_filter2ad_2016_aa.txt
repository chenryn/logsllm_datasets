title:Spamscatter: Characterizing Internet Scam Hosting Infrastructure
author:David S. Anderson and
Chris Fleizach and
Stefan Savage and
Geoffrey M. Voelker
Spamscatter: Characterizing Internet Scam Hosting Infrastructure
David S. Anderson
Chris Fleizach
Collaborative Center for Internet Epidemiology and Defenses
Stefan Savage
Geoffrey M. Voelker
Department of Computer Science and Engineering
University of California, San Diego
Abstract
Unsolicited bulk e-mail, or SPAM, is a means to an end.
For virtually all such messages, the intent is to attract the
recipient into entering a commercial transaction — typi-
cally via a linked Web site. While the prodigious infras-
tructure used to pump out billions of such solicitations is
essential, the engine driving this process is ultimately the
“point-of-sale” — the various money-making “scams”
that extract value from Internet users.
In the hopes of
better understanding the business pressures exerted on
spammers, this paper focuses squarely on the Internet in-
frastructure used to host and support such scams. We
describe an opportunistic measurement technique called
spamscatter that mines emails in real-time, follows the
embedded link structure, and automatically clusters the
destination Web sites using image shingling to capture
graphical similarity between rendered sites. We have
implemented this approach on a large real-time spam
feed (over 1M messages per week) and have identiﬁed
and analyzed over 2,000 distinct scams on 7,000 distinct
servers.
1 Introduction
Few Internet security issues have attained the universal
public recognition or contempt of unsolicited bulk email
— SPAM. In 2006, industry estimates suggest that such
messages comprise over 80% over all Internet email with
a total volume up to 85 billion per day [15,17]. The scale
of these numbers underscores the prodigious delivery in-
frastructures developed by “spammers” and in turn mo-
tivates the more than $1B spent annually on anti-spam
technology. However, the engine that drives this arms
race is not spam itself — which is simply a means to an
end — but the various money-making “scams” (legal or
illegal) that extract value from Internet users.
In this paper, we focus on the Internet infrastructure
used to host and support such scams. In particular, we
analyze spam-advertised Web servers that offer merchan-
dise and services (e.g., pharmaceuticals, luxury watches,
mortgages) or use malicious means to defraud users (e.g.,
phishing, spyware, trojans). Unlike mail-relays or bots,
scam infrastructure is directly implicated in the spam
proﬁt cycle and thus considerably rarer and more valu-
able. For example, a given spam campaign may use
thousands of mail relay agents to deliver its millions of
messages, but only use a single server to handle requests
from recipients who respond. Consequently, the avail-
ability of scam infrastructure is critical to spam prof-
itability — a single takedown of a scam server or a spam-
mer redirect can curtail the earning potential of an entire
spam campaign.
The goal of this paper is to characterize scam infras-
tructure and use this data to better understand the dy-
namics and business pressures exerted on spammers. To
identify scam infrastructure, we employ an opportunis-
tic technique called spamscatter. The underlying prin-
ciple is that each scam is, by necessity, identiﬁed in the
link structure of associated spams. To this end, we have
built a system that mines email, identiﬁes URLs in real
time and follows such links to their eventual destina-
tion server (including any redirection mechanisms put in
place). We further identify individual scams by cluster-
ing scam servers whose rendered Web pages are graph-
ically similar using a technique called image shingling.
Finally, we actively probe the scam servers on an ongo-
ing basis to characterize dynamic behaviors like avail-
ability and lifetime. Using the spamscatter technique on
a large real-time spam feed (roughly 150,000 per day) we
have identiﬁed over 2,000 distinct scams hosted across
more than 7,000 distinct servers. Further, we character-
ize the availability of infrastructure implicated in these
scams and the relationship with business-related factors
such as scam “type”, location and blacklist inclusion.
The remainder of this paper is structured as follows.
Section 2 reviews related measurement studies similar in
topic or technique.
In Section 3 we outline the struc-
USENIX Association
16th USENIX Security Symposium
135
ture and lifecycle of Internet scams, and describe in de-
tail one of the more extensive scams from our trace as
a concrete example. Section 4 describes our measure-
ment methodology, including our probing system, image
shingling algorithm, and spam feed.
In Section 5, we
analyze a wide range of characteristics of Internet scam
infrastructure based upon the scams we identify in our
spam feed. Finally, Section 6 summarizes our ﬁndings
and concludes.
2 Related work
Spamscatter is an opportunistic network measurement
technique [5], taking advantage of spurious trafﬁc —
in this case spam — to gain insight into “hidden” as-
pects of the Internet — in this case scam hosting infras-
tructure. As with other opportunistic measurement tech-
niques, such as backscatter to measure Internet denial-
of-service activity [20], network telescopes and Internet
sinks [32] to measure Internet worm outbreaks [19, 21],
and spam to measure spam relays [27], spamscatter pro-
vides a mechanism for studying global Internet behavior
from a single or small number of vantage points.
We are certainly not the ﬁrst to use spam for oppor-
tunistic measurement. Perhaps the work most closely
related to ours is Ramachandran and Feamster’s recent
study using spam to characterize the network behavior of
the spam relays that sent it [27]. Using extensive spam
feeds, they categorized the network and geographic loca-
tion, lifetime, platform, and network evasion techniques
of spam relay infrastructure. They also evaluated the ef-
fectiveness of using network-level properties of spam re-
lays, such as IP blacklists and suspect BGP announce-
ments, to ﬁlter spam. When appropriate in our analyses,
we compare and contrast characteristics of spam relays
and scam hosts; some scam hosts also serve as spam re-
lays, for example. In general, however, due to the differ-
ent requirements of the two underground services, they
exhibit different characteristics; scam hosts, for exam-
ple, have longer lifetimes and are more concentrated in
the U.S.
The Webb Spam Corpus effort harvests URLs from
spam to create a repository of Web spam pages, Web
pages created to inﬂuence Web search engine results or
deceive users [31]. Although both their effort and our
own harvest URLs from spam, the two projects differ
in their use of the harvested URLs. The Webb Spam
Corpus downloads and stores HTML content to create
an ofﬂine data set for training classiﬁers of Web spam
pages. Spamscatter probes sites and downloads content
over time, renders browser screenshots to identify URLs
referencing the same scam, and analyzes various charac-
teristics of the infrastructure hosting scams.
Both community and commercial services consume
URLs extracted from spam. Various community services
mine spam to speciﬁcally identify and track phishing
sites, either by examining spam from their own feeds or
collecting spam email and URLs submitted by the com-
munity [1, 6, 22, 25]. Commercial Web security and ﬁl-
tering services, such as Websense and Brightcloud, track
and analyze Web sites to categorize and ﬁlter content,
and to identify phishing sites and sites hosting other po-
tentially malicious content such as spyware and keylog-
gers. Sites advertised in spam provide an important data
source for such services. While we use similar data in our
work, our goal is infrastructure characterization rather
than operational ﬁltering.
Botnets can play a role in the scam host infrastructure,
either by hosting the spam relays generating the spam
we see or by hosting the scam servers. A number of
recent efforts have developed techniques for measuring
botnet structure, behavior, and prevalence. Cook et al. [9]
tested the feasibility of using honeypots to capture bots,
and proposed a combination of passive host and network
monitoring to detect botnets. B¨acher et al. [23] used hon-
eynets to capture bots, inﬁltrate their command and con-
trol channel, and monitor botnet activity. Rajab et al. [26]
combined a number of measurement techniques, includ-
ing malware collection, IRC command and control track-
ing, and DNS cache probing. The last two approaches
have provided substantial insight into botnet activity by
tracking hundreds of botnets over periods of months. Ra-
machandran and Feamster [27] provided strong evidence
that botnets are commonly used as platforms for spam
relays; our results suggest botnets are not as common for
scam hosting.
We developed an image shingling algorithm to deter-
mine the equivalance of screenshots of rendered Web
pages. Previous efforts have developed techniques to de-
termine the equivalence of transformed images as well.
For instance, the SpoofGuard anti-phishing Web browser
plugin compares images on Web pages with a database of
corporate logos [7] to identify Web site spooﬁng. Spoof-
Guard compares images using robust image hashing, an
approach employing signal processing techniques to cre-
ate a compressed representation of an image [30]. Robust
image hashing works well against a number of different
image transformations, such as cropping, scaling, and ﬁl-
tering. However, unlike image shingling, image hashing
is not intended to compare images where substantial re-
gions have completely different content; reﬁnements to
image hashing improve robustness (e.g., [18,28]), but do
not fundamentally extend the original set of transforms.
3 The life and times of an Internet scam
In this section we outline the structure and life cycle
of Internet scams, and describe in detail one of the
136
16th USENIX Security Symposium
USENIX Association
Figure 1: Components of a typical Internet scam.
more extensive scams from our trace as a concrete ex-
ample. This particular scam advertises “Downloadable
Software,” such as ofﬁce productivity tools (Microsoft,
Adobe, etc.) and popular games, although in general
the scams we observed were diverse in what they offered
(Section 5.1).
Figure 1 depicts the life of a spam-driven Internet
scam. First, a spam campaign launches a vast number
of unsolicited spam messages to email addresses around
the world; a large spam campaign can exceed 1 billion
emails [12]. In turn the content in these messages fre-
quently advertises a scam — unsolicited merchandise
and services available through the Web — by embed-
ding URLs to scam Web servers in the spam; in our data,
roughly 30% of spam contains such URLs (Section 5.1).
An example of spam that does not contain links would
be “pump-and-dump” stock spam intended to manipu-
late penny stock prices [3]; the recent growth of image-
based stock spam has substantially reduced the fraction
of spam using embedded URLs, shrinking from 85% in
2005 to 55% in 2006 [12]. These spam campaigns can
be comparatively brief, with more than half lasting less
than 12 hours in our data (Section 5.4). For our exam-
ple software scam, over 5,000 spam emails were used to
advertise it over a weeklong period.
Knowing or unsuspecting users click on URLs in
spam to access content from the Web servers hosting the
scams. While sometimes the embedded URL directly
speciﬁes the scam server, more commonly it indicates
an intermediate Web server that subsequently redirects
trafﬁc (using HTTP or Javascript) on towards the scam
server. Redirection serves multiple purposes. When
spammer and scammer are distinct, it provides a sim-
ple means for tagging requests with the spammer’s afﬁl-
iate identiﬁer (used by third-party merchants to compen-
sate independent “advertisers”) and laundering the spam-
based origin before the request reaches the merchant (this
laundering provides plausible deniability for the mer-
Figure 2: Screenshots, hostnames, and IP addresses of
different hosts for the “Downloadable Software” scam.
The highlighted regions show portions of the page that
change on each access due to product rotation. Image
shingling is resilient to such changes and identiﬁes these
screenshots as equivalent pages.
chant and protects the spammer from potential conﬂicts
over the merchant’s advertising policy). If spammer and
scammer are the same, a layer of redirection is still use-
ful for avoiding URL-based blacklists and providing de-
ployment ﬂexibility for scam servers. In our traces, most
scams use at least one level of redirection (Section 4).
On the back end, scams may use multiple servers to
host scams, both in terms of multiple virtual hosts (e.g.,
different domain names served by the same Web server)
and multiple physical hosts identiﬁed by IP address (Sec-
tion 5.2). However, for the scams in our spam feed, the
use of multiple virtual hosts is infrequent (16% of scams)
and multiple physical hosts is rare (6%); our example
software scam is one of the more extensive scams, using
at least 99 virtual hosts on three physical hosts.
Finally, different Web servers (physical or virtual), and
even different accesses to a scam using the same URL,
can result in slightly different downloaded content for the
same scam. Intentional randomness for evasion, rotating
advertisements, featured product rotation, etc., add an-
other form of aliasing. Figure 2 shows example screen-
shots among different hosts for the software scam. To
overcome these aliasing issues, we use screenshots of
Web pages as a basis for identifying all hosts participat-
ing in a given scam (Section 4.2).
A machine hosting one scam may be shared with other
scams, as when scammers run multiple scams at once or
the hosts are third-party infrastructure used by multiple
scammers. Sharing is common, with 38% of scams be-
USENIX Association
16th USENIX Security Symposium
137
ing hosted on a machine with at least one other scam
(Section 5.3). One of the machines hosting the soft-
ware scam, for example, also hosted a pharmaceutical
scam called “Toronto Pharmacy” (which happened to be
hosted on a server in Guangzhou, China).
The lifetimes of scams are much longer than spam
campaigns, with 50% of scams active for at least a week
(Section 5.4). Furthermore, scam hosts have high avail-
ability during their lifetime (most above 99%) and ap-
pear to have good network connectivity (Section 5.5); the
lifetime of our software scam ran for the entire measure-
ment period and was available 97% of the time. Finally,
scam hosts tend to be geographically concentrated in the
United States; over 57% of scam hosts from our data
mapped to the U.S. (Section 5.6.2). Such geographic
concentration contrasts sharply with the location of spam
relay hosts; for comparison, only 14% of spam relays
used to send the spam to our feed are located in the U.S.
Figure 3 shows the geographic locations of the spam re-
lays and scam hosts for the software scam. The three
scam hosts were located in China and Russia, whereas
the 85 spam relays were located around the world in 30
countries.
The lifetimes, high availability, and good network con-
nectivity, as well as the geographic diversity of spam
relays compared with scam hosts, all reﬂect the funda-
mentally different requirements and circumstances be-
tween the two underground services. Spam relays re-
quire no interaction with users, need only be available to
send mail, but must be great enough in number to mit-
igate the effects of per-host blacklists. Consequently,
spam relays are well suited to “commodity” botnet in-
frastructure [27]; one recent industry estimate suggests
that over 80% of spam is in fact relayed by bots [13]. By
contrast, scam hosts are naturally more centralized (due
to hosting a payment infrastructure), require interactive
response time to their target customers, and may — in
fact — be hosting legal commerce. Thus, scam hosts are
much more likely to have high-quality hosting infrastruc-
ture that is stable over long periods.
4 Methodology
This section describes our measurement methodology.
We ﬁrst explain our data collection framework for prob-
ing scam hosts and spam relays, and then detail our im-
age shingling algorithm for identifying equivalent scams.
Finally, we describe the spam feed we use as our data
source and discuss the inherent limitations of using a sin-
gle viewpoint.
4.1 Data collection framework
We built a data collection tool, called the spamscatter
prober, that takes as input a feed of spam emails, ex-
tracts the sender and URLs from the spam messages, and
probes those hosts to collect various kinds of information
(Figure 1). For spam senders, the prober performs a ping,
traceroute, and DNS-based blacklist lookup (DNSBL)
once upon receipt of each spam email. The prober per-
forms more extensive operations for the scam hosts. As
with spam senders, it ﬁrst performs a ping, traceroute,
and DNSBL lookup on scam hosts. In addition, it down-
loads and stores the full HTML source of the Web page
speciﬁed by valid URLs extracted from the spam (we do
not attempt to de-obfuscate URLs).
It also renders an
image of the downloaded page in a canonical browser
conﬁguration using the KHTML layout engine [14], and
stores a screenshot of the browser window. For scam
hosts, the prober repeats these operations periodically for
a ﬁxed length of time. For the trace in this paper, we
probed each host and captured a screenshot while vis-
iting each URL every three hours. Starting from when
the ﬁrst spam email introduces a new URL into the data
set, we probe the scam host serving that URL for a week
independently of whether the probes fail or succeed.
As we mentioned earlier, many spam URLs simply
point to sites that forward the request onto another server.
There are many possible reasons for the forwarding be-
havior, such as tracking users, redirecting users through
third-party afﬁliates or tracking systems, or consolidat-
ing the many URLs used in spam (ostensibly to avoid
spam ﬁlters) to just one. Occasionally, we also noticed
forwarding that does not end, either indicating a miscon-
ﬁguration, programming error, or a deliberate attempt to
avoid spidering.
The prober accommodates a variety of link forwarding
practices. While some links direct the client immediately
to the appropriate Web server, others execute a series of
forwarding requests, including HTTP 302 server redi-
rects and JavaScript-based redirects. To follow these, the
prober processes received page content to extract simple
META refresh tags and JavaScript redirect statements.
It then tracks every intermediate page between the initial
link and the ﬁnal content page, and marks whether a page
is the end of the line for each link. Properly handling for-
warding is necessary for accurate scam monitoring. Over
68% of scams used some kind of forwarding, with an av-
erage of 1.2 forwards per URL.
4.2 Image shingling
Many of our analyses compare content downloaded from
scam servers to determine if the scams are equivalent.
For example, scam hosts may serve multiple indepen-
138
16th USENIX Security Symposium
USENIX Association
Figure 3: Geographic locations of the spam relays and scam server hosts for the “Downloadable Software” scam. The
three scam servers are located in China and Russia and shown with dark grey points. The 85 spam relays are located
around the world in more than 30 different countries, and are shown in white.
dent scams simultaneously, and we cannot assume that
URLs that lead to the same host are part of the same
scam. Similarly, scams are hosted on multiple virtual
servers as well as distributed across multiple machines.
As a result, we need to be able to compare content from
scam servers on different hosts to determine whether