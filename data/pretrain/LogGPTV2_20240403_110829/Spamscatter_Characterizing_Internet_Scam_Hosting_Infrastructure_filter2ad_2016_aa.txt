# Title: Spamscatter: Characterizing Internet Scam Hosting Infrastructure

## Authors:
- David S. Anderson
- Chris Fleizach
- Stefan Savage
- Geoffrey M. Voelker

### Affiliations:
- Collaborative Center for Internet Epidemiology and Defenses
- Department of Computer Science and Engineering, University:// California, San Diego

## Abstract
Unsolicited bulk email, or SPAM, is a means to an end. For virtually all such messages, the intent is to attract the recipient into entering a commercial transaction, typically via a linked website. While the extensive infrastructure used to send billions of these solicitations is essential, the driving force behind this process is the "point-of-sale" — the various money-making "scams" that extract value from Internet users.

In this paper, we focus on the Internet infrastructure used to host and support such scams. We describe an opportunistic measurement technique called "spamscatter," which mines emails in real-time, follows the embedded link structure, and automatically clusters destination websites using image shingling to capture graphical similarity between rendered sites. We have implemented this approach on a large real-time spam feed (over 1M messages per week) and have identified and analyzed over 2,000 distinct scams hosted on 7,000 distinct servers.

## 1. Introduction
Few Internet security issues have attained the universal public recognition or contempt of unsolicited bulk email — SPAM. In 2006, industry estimates suggest that such messages comprise over 80% of all Internet email, with a total volume up to 85 billion per day [15, 17]. The scale of these numbers underscores the extensive delivery infrastructures developed by spammers, motivating the more than $1B spent annually on anti-spam technology. However, the engine driving this arms race is not spam itself, but the various money-making "scams" (legal or illegal) that extract value from Internet users.

In this paper, we focus on the Internet infrastructure used to host and support such scams. Specifically, we analyze spam-advertised web servers that offer merchandise and services (e.g., pharmaceuticals, luxury watches, mortgages) or use malicious means to defraud users (e.g., phishing, spyware, trojans). Unlike mail-relays or bots, scam infrastructure is directly implicated in the spam profit cycle and is thus considerably rarer and more valuable. For example, a given spam campaign may use thousands of mail relay agents to deliver its millions of messages but only a single server to handle requests from recipients who respond. Consequently, the availability of scam infrastructure is critical to spam profitability; a single takedown of a scam server or a spammer redirect can curtail the earning potential of an entire spam campaign.

The goal of this paper is to characterize scam infrastructure and use this data to better understand the dynamics and business pressures exerted on spammers. To identify scam infrastructure, we employ an opportunistic technique called "spamscatter." The underlying principle is that each scam is, by necessity, identified in the link structure of associated spams. We have built a system that mines email, identifies URLs in real time, and follows such links to their eventual destination server (including any redirection mechanisms put in place). We further identify individual scams by clustering scam servers whose rendered web pages are graphically similar using a technique called image shingling. Finally, we actively probe the scam servers on an ongoing basis to characterize dynamic behaviors like availability and lifetime. Using the spamscatter technique on a large real-time spam feed (roughly 150,000 per day), we have identified over 2,000 distinct scams hosted across more than 7,000 distinct servers. Further, we characterize the availability of infrastructure implicated in these scams and the relationship with business-related factors such as scam "type," location, and blacklist inclusion.

The remainder of this paper is structured as follows. Section 2 reviews related measurement studies similar in topic or technique. Section 3 outlines the structure and lifecycle of Internet scams, and describes in detail one of the more extensive scams from our trace as a concrete example. Section 4 describes our measurement methodology, including our probing system, image shingling algorithm, and spam feed. In Section 5, we analyze a wide range of characteristics of Internet scam infrastructure based upon the scams we identify in our spam feed. Finally, Section 6 summarizes our findings and concludes.

## 2. Related Work
Spamscatter is an opportunistic network measurement technique [5], taking advantage of spurious traffic — in this case, spam — to gain insight into "hidden" aspects of the Internet, such as scam hosting infrastructure. As with other opportunistic measurement techniques, such as backscatter to measure Internet denial-of-service activity [20], network telescopes and Internet sinks [32] to measure Internet worm outbreaks [19, 21], and spam to measure spam relays [27], spamscatter provides a mechanism for studying global Internet behavior from a single or small number of vantage points.

We are not the first to use spam for opportunistic measurement. Perhaps the work most closely related to ours is Ramachandran and Feamster’s recent study using spam to characterize the network behavior of the spam relays that sent it [27]. Using extensive spam feeds, they categorized the network and geographic location, lifetime, platform, and network evasion techniques of spam relay infrastructure. They also evaluated the effectiveness of using network-level properties of spam relays, such as IP blacklists and suspect BGP announcements, to filter spam. When appropriate in our analyses, we compare and contrast characteristics of spam relays and scam hosts; some scam hosts also serve as spam relays, for example. In general, however, due to the different requirements of the two underground services, they exhibit different characteristics; scam hosts, for example, have longer lifetimes and are more concentrated in the U.S.

The Webb Spam Corpus effort harvests URLs from spam to create a repository of web spam pages, web pages created to influence web search engine results or deceive users [31]. Although both their effort and our own harvest URLs from spam, the two projects differ in their use of the harvested URLs. The Webb Spam Corpus downloads and stores HTML content to create an offline data set for training classifiers of web spam pages. Spamscatter probes sites and downloads content over time, renders browser screenshots to identify URLs referencing the same scam, and analyzes various characteristics of the infrastructure hosting scams.

Both community and commercial services consume URLs extracted from spam. Various community services mine spam to specifically identify and track phishing sites, either by examining spam from their own feeds or collecting spam email and URLs submitted by the community [1, 6, 22, 25]. Commercial web security and filtering services, such as Websense and Brightcloud, track and analyze websites to categorize and filter content and to identify phishing sites and sites hosting other potentially malicious content such as spyware and keyloggers. Sites advertised in spam provide an important data source for such services. While we use similar data in our work, our goal is infrastructure characterization rather than operational filtering.

Botnets can play a role in the scam host infrastructure, either by hosting the spam relays generating the spam we see or by hosting the scam servers. A number of recent efforts have developed techniques for measuring botnet structure, behavior, and prevalence. Cook et al. [9] tested the feasibility of using honeypots to capture bots and proposed a combination of passive host and network monitoring to detect botnets. Bächer et al. [23] used honey nets to capture bots, infiltrate their command and control channel, and monitor botnet activity. Rajab et al. [26] combined a number of measurement techniques, including malware collection, IRC command and control tracking, and DNS cache probing. The last two approaches have provided substantial insight into botnet activity by tracking hundreds of botnets over periods of months. Ramachandran and Feamster [27] provided strong evidence that botnets are commonly used as platforms for spam relays; our results suggest botnets are not as common for scam hosting.

We developed an image shingling algorithm to determine the equivalence of screenshots of rendered web pages. Previous efforts have developed techniques to determine the equivalence of transformed images as well. For instance, the SpoofGuard anti-phishing web browser plugin compares images on web pages with a database of corporate logos [7] to identify website spoofing. SpoofGuard compares images using robust image hashing, an approach employing signal processing techniques to create a compressed representation of an image [30]. Robust image hashing works well against a number of different image transformations, such as cropping, scaling, and filtering. However, unlike image shingling, image hashing is not intended to compare images where substantial regions have completely different content; refinements to image hashing improve robustness (e.g., [18, 28]), but do not fundamentally extend the original set of transforms.

## 3. The Life and Times of an Internet Scam
In this section, we outline the structure and lifecycle of Internet scams and describe in detail one of the more extensive scams from our trace as a concrete example. This particular scam advertises "Downloadable Software," such as office productivity tools (Microsoft, Adobe, etc.) and popular games, although in general, the scams we observed were diverse in what they offered (Section 5.1).

Figure 1 depicts the life of a spam-driven Internet scam. First, a spam campaign launches a vast number of unsolicited spam messages to email addresses around the world; a large spam campaign can exceed 1 billion emails [12]. In turn, the content in these messages frequently advertises a scam — unsolicited merchandise and services available through the web — by embedding URLs to scam web servers in the spam; in our data, roughly 30% of spam contains such URLs (Section 5.1). An example of spam that does not contain links would be "pump-and-dump" stock spam intended to manipulate penny stock prices [3]; the recent growth of image-based stock spam has substantially reduced the fraction of spam using embedded URLs, shrinking from 85% in 2005 to 55% in 2006 [12]. These spam campaigns can be comparatively brief, with more than half lasting less than 12 hours in our data (Section 5.4). For our example software scam, over 5,000 spam emails were used to advertise it over a weeklong period.

Knowing or unsuspecting users click on URLs in spam to access content from the web servers hosting the scams. While sometimes the embedded URL directly specifies the scam server, more commonly it indicates an intermediate web server that subsequently redirects traffic (using HTTP or JavaScript) towards the scam server. Redirection serves multiple purposes. When spammer and scammer are distinct, it provides a simple means for tagging requests with the spammer's affiliate identifier (used by third-party merchants to compensate independent "advertisers") and laundering the spam-based origin before the request reaches the merchant (this laundering provides plausible deniability for the merchant and protects the spammer from potential conflicts over the merchant’s advertising policy). If spammer and scammer are the same, a layer of redirection is still useful for avoiding URL-based blacklists and providing deployment flexibility for scam servers. In our traces, most scams use at least one level of redirection (Section 4).

On the back end, scams may use multiple servers to host scams, both in terms of multiple virtual hosts (e.g., different domain names served by the same web server) and multiple physical hosts identified by IP address (Section 5.2). However, for the scams in our spam feed, the use of multiple virtual hosts is infrequent (16% of scams) and multiple physical hosts is rare (6%); our example software scam is one of the more extensive scams, using at least 99 virtual hosts on three physical hosts.

Finally, different web servers (physical or virtual), and even different accesses to a scam using the same URL, can result in slightly different downloaded content for the same scam. Intentional randomness for evasion, rotating advertisements, featured product rotation, etc., add another form of aliasing. Figure 2 shows example screenshots among different hosts for the software scam. To overcome these aliasing issues, we use screenshots of web pages as a basis for identifying all hosts participating in a given scam (Section 4.2).

A machine hosting one scam may be shared with other scams, as when scammers run multiple scams at once or the hosts are third-party infrastructure used by multiple scammers. Sharing is common, with 38% of scams being hosted on a machine with at least one other scam (Section 5.3). One of the machines hosting the software scam, for example, also hosted a pharmaceutical scam called "Toronto Pharmacy" (which happened to be hosted on a server in Guangzhou, China).

The lifetimes of scams are much longer than spam campaigns, with 50% of scams active for at least a week (Section 5.4). Furthermore, scam hosts have high availability during their lifetime (most above 99%) and appear to have good network connectivity (Section 5.5); the lifetime of our software scam ran for the entire measurement period and was available 97% of the time. Finally, scam hosts tend to be geographically concentrated in the United States; over 57% of scam hosts from our data mapped to the U.S. (Section 5.6.2). Such geographic concentration contrasts sharply with the location of spam relay hosts; for comparison, only 14% of spam relays used to send the spam to our feed are located in the U.S. Figure 3 shows the geographic locations of the spam relays and scam hosts for the software scam. The three scam hosts were located in China and Russia, whereas the 85 spam relays were located around the world in 30 countries.

The lifetimes, high availability, and good network connectivity, as well as the geographic diversity of spam relays compared with scam hosts, all reflect the fundamentally different requirements and circumstances between the two underground services. Spam relays require no interaction with users, need only be available to send mail, but must be great enough in number to mitigate the effects of per-host blacklists. Consequently, spam relays are well suited to "commodity" botnet infrastructure [27]; one recent industry estimate suggests that over 80% of spam is, in fact, relayed by bots [13]. By contrast, scam hosts are naturally more centralized (due to hosting a payment infrastructure), require interactive response time to their target customers, and may, in fact, be hosting legal commerce. Thus, scam hosts are much more likely to have high-quality hosting infrastructure that is stable over long periods.

## 4. Methodology
This section describes our measurement methodology. We first explain our data collection framework for probing scam hosts and spam relays, and then detail our image shingling algorithm for identifying equivalent scams. Finally, we describe the spam feed we use as our data source and discuss the inherent limitations of using a single viewpoint.

### 4.1 Data Collection Framework
We built a data collection tool, called the "spamscatter prober," that takes as input a feed of spam emails, extracts the sender and URLs from the spam messages, and probes those hosts to collect various kinds of information (Figure 1). For spam senders, the prober performs a ping, traceroute, and DNS-based blacklist lookup (DNSBL) once upon receipt of each spam email. The prober performs more extensive operations for the scam hosts. As with spam senders, it first performs a ping, traceroute, and DNSBL lookup on scam hosts. In addition, it downloads and stores the full HTML source of the web page specified by valid URLs extracted from the spam (we do not attempt to de-obfuscate URLs). It also renders an image of the downloaded page in a canonical browser configuration using the KHTML layout engine [14] and stores a screenshot of the browser window. For scam hosts, the prober repeats these operations periodically for a fixed length of time. For the trace in this paper, we probed each host and captured a screenshot while visiting each URL every three hours. Starting from when the first spam email introduces a new URL into the dataset, we probe the scam host serving that URL for a week independently of whether the probes fail or succeed.

As mentioned earlier, many spam URLs simply point to sites that forward the request onto another server. There are many possible reasons for the forwarding behavior, such as tracking users, redirecting users through third-party affiliates or tracking systems, or consolidating the many URLs used in spam (ostensibly to avoid spam filters) to just one. Occasionally, we also noticed forwarding that does not end, either indicating a misconfiguration, programming error, or a deliberate attempt to avoid spidering.

The prober accommodates a variety of link forwarding practices. While some links direct the client immediately to the appropriate web server, others execute a series of forwarding requests, including HTTP 302 server redirects and JavaScript-based redirects. To follow these, the prober processes received page content to extract simple META refresh tags and JavaScript redirect statements. It then tracks every intermediate page between the initial link and the final content page and marks whether a page is the end of the line for each link. Properly handling forwarding is necessary for accurate scam monitoring. Over 68% of scams used some kind of forwarding, with an average of 1.2 forwards per URL.

### 4.2 Image Shingling
Many of our analyses compare content downloaded from scam servers to determine if the scams are equivalent. For example, scam hosts may serve multiple independent scams simultaneously, and we cannot assume that URLs that lead to the same host are part of the same scam. Similarly, scams are hosted on multiple virtual servers as well as distributed across multiple machines. As a result, we need to be able to compare content from scam servers on different hosts to determine whether they are part of the same scam.