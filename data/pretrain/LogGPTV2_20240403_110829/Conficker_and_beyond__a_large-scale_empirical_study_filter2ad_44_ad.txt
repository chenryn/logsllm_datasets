are already on some blacklists and we believe that the dis-
parity is caused by the diﬀerence of distribution of infected
hosts. As we mentioned in Section 4.1 and 4.2, the distri-
Insight from Result 6. (Unfortunately, blacklists
can not help us all the time) Only less than 20% of vic-
tims are on DNS blacklists, which means that we need better
ways to detect future emerging malware.
5.2 Dshield and FIRE
Some other reputation-based detection systems are also
provided to complement DNS blacklists, and we need to in-
vestigate their performance of detection. Since most DNS
blacklists are mainly to detect hosts or ASes sending spam,
they may not detect other malicious behaviors (potentially)
performed by (emerging) infected hosts. There are several
studies that try to detect network scanning attacks or web-
based attacks and Dshield [6] and FIRE [7] are good exam-
ples of them. Dshield provides information to detect hosts or
ASes sending suspicious network scanning/attacking pack-
ets, and FIRE [7] lists malicious ASes which frequently host
rogue networks by measuring their reputation. We plan to
inspect how many Conﬁcker victims are notiﬁed by Dshield
and FIRE.
Result 7. (Dshield) Only 0.33% of victims of Conﬁcker
are found on the list of malicious IP addresses reported by
DShield, and most of the top ASes infected by Conﬁcker are
not on the malicious AS list of Dshield.
Checking Conﬁcker victims against the list provided by
Dshield [4], we found that only a small portion of hosts
and ASes are on the list. We investigated 588,797 IP ad-
dresses presented by Dshield, and they denoted world-wide
attackers/scanners that were detected by all kinds of IDSs
and reported to DShield. Since one of the infection vectors
in Conﬁcker is random IP scanning [17], we expect a large
portion of Conﬁcker victims to show up in Dshield. How-
ever, we only ﬁnd 82,856 hosts from the list. This shows
that these Conﬁcker victim hosts are probably easy targets
of many previous malware. However, DShield is still not
good at catching major portions of new emerging malware
such as Conﬁcker. Similarly, we examined the malicious AS
list provided by Dshield and we only observed 83 Conﬁcker
infected ASes out of 10,584 ASes given by Dshield. Only
one of them (AS4812) is a serious contributor of Conﬁcker
(ranked 12th among infected ASes) but the rest are not as
critical as AS4812. Most of them cover less than 0.02% of
Conﬁcker victims.
Result 8. (FIRE) Most highly infected ASes by Con-
ﬁcker are not reported by FIRE.
We compared our infection list of ASes with the results
provided by FIRE as well and we want to know whether
FIRE is helpful in detecting Conﬁcker victims. Although
FIRE denotes AS4134 as the 8th most malicious AS in its
list, most of other heavily infected ASes by Conﬁcker are
not shown in the top 500 malicious ASes of FIRE. Some of
the main contributing ASes to Conﬁcker have never shown
up on FIRE’s list.
Insight from Result 7 and 8.
(New and com-
plementary detection approaches are needed) DNS
blacklists, Dshield and FIRE detect only a small portion of
Conﬁcker victims. This means that these reputation-based
approaches are not the perfect solution. We need to im-
prove them signiﬁcantly and complement them with other
approaches.
When we tested Dshield and FIRE, we expected that
they could complement DNS blacklists, but the result is not
very positive. This implies that these reputation-based sys-
tems alone are far from enough to protect the Internet from
emerging threats. We believe that new detection systems
based on anomalous behaviors of malware could be a good
complementary approach to them.
fecting nearby hosts. Conﬁcker has a function of scanning
randomly selected IP addresses. Although this will help
Conﬁcker to spread globally, it is not probably very eﬃ-
cient these days because most networks are protected by ﬁre-
walls or Network Intrusion Detection/Prevention Systems.
To propagate more eﬃciently, Conﬁcker adopts several in-
teresting techniques to infect hosts nearby; (1) an ability to
infect other hosts in the same subnet, (2) an ability to in-
fect hosts in the nearby subnets, and (3) an ability to infect
portable storage devices.
The diverse infection techniques of Conﬁcker lead us to
ask this question: “Which vector is more eﬀective to in-
fect hosts?”. Some previous studies suggested that second
approach - (ii) infecting nearby hosts - is probably more
dominant in the Conﬁcker case [17, 12]. We think that this
seems reasonable, because even though most networks are
protected well from outside threats, they are still open to in-
ternal attacks. However, they do not show concrete evidence
to support it.
To determine whether this hypothesis is correct, we con-
structed a test. Prior to explaining our test, we declare that
we will use /24 subnet as a basic unit in our test. And we
make the following deﬁnition to simplify the test. We deﬁne
two terms: (i) “camp” is the group of /24 subnets whose /16
subnet is the same and locations are close together, and (ii)
each /24 subnet is a “neighbor” of nearby /24 subnets in the
same camp. Sometimes, even if two /24 subnets are in the
same /16 subnet, their physical locations could be far from
each other. However, since our concept of “camp” is each /24
subnet with both nearby IP address and physical location,
we should consider its location as well. Based on the above
deﬁnition, we establish a hypothesis as follows. Of the two
infection vectors of Conﬁcker, suppose the second infection
vector plays a dominant role, the infection pattern4 of a /24
subnet will be similar to that of its “neighbors” in the same
“camp”. In other words, the hosts in nearby networks of in-
fected host are more likely to be selected as future victims
than randomly chosen hosts.
To evaluate this hypothesis, we have tested the following
scenarios. First, we divide hosts into /24 subnets and as-
sign each /24 subnet into a “camp” based on our deﬁnition.
Second, we investigate the infection pattern of each /24 sub-
net to see whether the infection pattern of each /24 subnet
is similar to its “neighbors”. We use Variance-Mean Ratio
(VMR) [9] for a numerical expression. In this test, we mea-
sure the mean and variance value of the numbers of infected
hosts of each /24 subnet in each “camp”, and calculate VMR
for each “camp”. If the value of VMR is less than one, dis-
tribution of the data set shows under-dispersion with mean
value in the center, which means that infection patterns of
/24 subnets in the “camp” are very similar to each other.
Result 9.
(Neighborhood) Most /24 subnets show
similar infection patterns (numbers of infected hosts) with
their “neighbors”. The closer they are located with each other,
the more similar in their infection patterns.
6. CAN NEIGHBORHOOD WATCH HELP?
Conﬁcker still uses network scanning to infect other hosts
on the Internet as previous worms and bots did, and it also
adopts several advanced skills to infect hosts eﬃciently. The
spreading techniques of Conﬁcker can be classiﬁed into two
categories [3, 17]; (i) infecting random hosts and (ii) in-
We measured the VMR value of each “camp” and we found
that more than 70% of “camps” denoted that their /24 sub-
net members are similar to each other. From this result, we
reasonably infer that the dominant infection vector of Con-
4We use the number of infected hosts of /24 subnet as a
feature to represent an infection pattern.
Within Distance # of all “camps” # of “camps” whose /24 subnet members are similar to each other
≈ 100km
≈ 200km
≈ 300km
85,246
65,748
54,415
62,121 (72.87%)
44,633 (67.88%)
36,495 (67.06%)
Table 7: The number of all “camps” and “camps” whose members are similar to each other.
ﬁcker is to infect nearby hosts. The test result is shown
in Table 7. When we did this test, we got three types
of “camps” based on its geographical information. For in-
stance, if we set the distance metric for the “camp” as 100km
which means that all /24 subnets in the “camp” have the
same /16 subnet and they are within 100km of each other,
we found 85,246 “camps” from our data and we discovered
62,121 “camps” whose /24 subnet members are similar to
each other. We observed that more than 67% of “camps”
showed that their /24 subnet members are similar to each
other. The closer their locations are, the clearer this pattern
is shown. This result tells us that Conﬁcker is more likely
to select nearby hosts than randomly chosen hosts and this
means Conﬁcker victims are mainly infected by neighbor
networks/hosts. We deduce from this result that infection
from the inside could be more harmful than the threats from
the outside. Usually, most enterprise networks and ISPs pro-
tect their internal hosts using ﬁrewalls and IPS/IDS from
external attacks, but there are very few approaches to pro-
tect hosts from internal threats.
Result 9.1 (Detection based on neighborhood in-
formation) We could detect unknown victims by sharing
and correlating neighbor alert information, even if we only
know small sets of families and its neighbors.
Based on previous results, we propose an approach of de-
tecting (or early warning) emerging (unknown) infected /24
subnets using neighborhood information and we show that
the approach can detect unknown infected /24 subnets with
more than 90% of accuracy. From the above test, we ﬁnd
that Conﬁcker victims share their infection patterns with
their neighbors, and this ﬁnding gives us an intuition that
collecting and sharing neighborhood information would be
helpful to detect unknown malware or provide early warn-
ings. To validate this intuition, we have tested the simple
scenario of “We only have small portions of information of
benign and malicious hosts, but we can gather neighborhood
information. Then, how many unknown malicious hosts can
we detect (or predict) based on neighborhood information?”.
As a method of considering neighborhood information, we
use the K-Nearest Neighbor (KNN) classiﬁcation algorithm,
because it is a very popular approach that classiﬁes unknown
examples using the most similar “neighbors” in the known
examples. When we apply the KNN algorithm to our data,
we need the following preparations.
• deﬁne classes:
in this test, we deﬁne two classes;
benign (normal /24 subnet) and malicious (/24 subnet
which has Conﬁcker victims)
• collect data: we use our Conﬁcker data for malicious
data, and we collected the same number of benign /24
subnets as malicious /24 subnets.5
5As a result, we have 1,300,000 malicious /24 subnets (in-
• divide data: we randomly select 20% of data from
both data sets for training samples and other 80% of
data is used for testing.
After all preparation was completed, we used the KNN
algorithm (we use 3 for K and use IP address to calculate
the distance) to our data and found that it can detect un-
known infected /24 subnets with a high accuracy. As shown
in Table 8, we ﬁnd that even if we only know a small part
of Conﬁcker data (20%), we can still predict other infected
/24 subnets within more than 90% accuracy with reasonable
True Positive (TP) and False Positive (FP)6 rates. This de-
tection result implies that if we share neighbor information,
we could detect unknown victims or provide early warnings
more eﬃciently.
Detection Accuracy TP rate FP rate
91.59%
91.65%
8.5%
Table 8: Accuracy, TP and FP rate of the Detection
Approach based on Neighborhood Information.
Insight from Result 9 and 9.1.
(Neighborhood
watch) We observe that a large portion of victims could
be infected by nearby victims and ﬁnd that it is very impor-
tant to share threat information with neighborhood networks.
And this insight implies that further research is needed for
developing new detection/defending approaches based on co-
operated/shared (alert) information (and probably in an ef-
ﬁcient privacy-preserving way).
7. CONCLUSION
In this paper, we have studied a large-scale Conﬁcker in-
fection data to discover (i) their distribution over networks,
ASes and etc, (ii) diﬀerence from previous bots/worms (iii)
the eﬀectiveness of current reputation-based malware detec-
tion/warning systems, and (iv) some insight to help detect
future malware.
Our analysis of Conﬁcker victims and cross-comparison
results allowed us to obtain profound insights of Conﬁcker
victims. They also guide us to understand the trends of
malware infections and to ﬁnd interesting ideas that can
aid the design of future malware detecting systems. We re-
vealed that current reputation-based malware detecting sys-
tems depending on previously known information are not
enough to detect most Conﬁcker victims. This result sug-
gests that diﬀerent kinds of (complementary) detection sys-
tems such as an anomaly-based detection system are needed.
fected by Conﬁcker), and 1,300,000 benign /24 subnets
(NOT infected by Conﬁcker or other malware).
6TP denotes the rates that the detector classiﬁes real mali-
cious networks correctly, and FP denotes the rates that the
detector classiﬁes benign networks as malicious.
We provide a basis that proves the hypothesis of “A Con-
ﬁcker bot is more likely to infect nearby hosts than ran-
domly chosen hosts” and we believe that it calls for more
research of detection systems which are based on watch-
ing/sharing/correlating neighborhood information.
Acknowledgments
We greatly thank Chris Lee and ShadowServer.org for pro-
viding the data used in this paper. We also would like to
thank our shepherd, Sven Dietrich, and anonymous review-
ers for their insightful comments and feedback to improve
the paper. This material is based upon work supported
in part by the Oﬃce of Naval Research under Grant no.
N00014-09-1-0776, the National Science Foundation under
Grant CNS-0954096, and the Texas Higher Education Co-
ordinating Board under NHARP Grant no. 01909. Any
opinions, ﬁndings, and conclusions or recommendations ex-
pressed in this material are those of the author(s) and do not
necessarily reﬂect the views of the Oﬃce of Naval Research,
the National Science Foundation, and the Texas Higher Ed-
ucation Coordinating Board.
8. REFERENCES
[1] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and
N. Feamster. Building a Dynamic Reputation System
for DNS. In Proceedings of USENIX Security of
Symposium, Aug. 2010.
[2] CAIDA. Conﬁcker/Conﬂicker/Downadup as seen from
the UCSD Network Telescope. http://www.caida.
org/research/security/ms08-067/conficker.xml.
[3] E. Chien. Downadup: Attempts at Smart Network
Scanning. http://www.symantec.com/connect/blogs/
downadup-attempts-smart-network-scanning.
[4] DHIELD. All suspicious Source IPs in DSHIELD.
http://www.dshield.org/feeds/daily_sources.
[5] DNSBL. invaluement DNSBL (an anti-spam
blacklist). http://dnsbl.invaluement.com/.
[6] DSHIELD. Cooperative Network Security
Community. http://www.dshield.org/.
[7] FIRE. Finding Rogue Networks.
http://maliciousnetworks.org/.
[8] Fortune. Fortune 100 companies.
http://money.cnn.com/magazines/fortune/.
[9] U. G. and C. I. Oxford Dictionary of Statistics (2nd
edition). Oxford University Press, 2006.
[10] T. Holz, C. Gorecki, and F. Freiling. Detection and
Mitigation of Fast-Flux Service Networks. In
Proceedings of NDSS Symposium, Feb. 2008.
[11] N. Ianelli and A. Hackworth. Botnets as a Vehicle for
Online Crime. 2005.
[12] S. Krishnan and Y. Kim. Passive identiﬁcation of
Conﬁcker nodes on the Internet. In University of
Minnesota - Technical Document, 2009.
[13] J. Kristoﬀ. Experiences with Conﬁcker C Sinkhole
Operation and Analysis. In Proceedings of Australian
Computer Emergency Response Team Conference,
May 2009.
[14] D. Moore, V. Paxson, S. Savage, C. Shannon,
S. Staniford, and N. Weaver. Inside the Slammer
Worm. In Proceedings of IEEE Security and Privacy,
May 2003.
[15] D. Moore, C. Shannon, and K. Calﬀy. Code-red: a
case study on the spread and victims of an internet
worm. In Proceedings of ACM SIGCOMM Workshop
on Internet Measurement, Nov. 2002.
[16] B. N. Online. Clock ticking on worm code. http:
//news.bbc.co.uk/2/hi/technology/7832652.stm.
[17] P. Porras, H. Saidi, and V. Yegneswaran. A Foray into
Conﬁcker’s Logic and Rendezvous Points. In
Proceedings of USENIX LEET, Apr. 2009.
[18] A. Ramachandran and N. Feamster. Understanding
the Network-Level Behavior of Spammers. In
Proceedings of ACM SIGCOMM, Sep. 2006.
[19] C. Shannon and D. Moore. The Spread of the Witty
Worm. In Proceedings of IEEE Security and Privacy,
May 2004.
[20] SORBS. Fighting spam by ﬁnding and listing
Exploitable Servers. http://www.au.sorbs.net/.
[21] SPAMHAUS. Spamcop.net.
http://www.spamcop.net/.
[22] SPAMHAUS. The SPAMHAUS Project.
http://www.spamhaus.org/.
[23] SRI-International. An analysis of Conﬁcker C.
http://mtc.sri.com/Conficker/addendumC/.
[24] B. Stock, M. E. Jan Goebel, F. C. Freiling, and
T. Holz. Walowdac Analysis of a Peer-to-Peer Botnet.
In Proceedings of European Conference on Computer
Network Defense (EC2ND), Nov. 2009.
[25] B. Stone-Gross, M. Cova, L. Cavallaro, B. Gilbert,
M. Szydlowski, R. Kemmerer, C. Kruegel, and
G. Vigna. Your Botnet is My Botnet: Analysis of a
Botnet Takeover. In Proceedings of ACM CCS, Nov.
2009.
[26] M. S. Techcenter. Conﬁcker worm. http://technet.
microsoft.com/en-us/security/dd452420.aspx.
[27] Tmetric. Bandwidth Measurement Tool. http:
//mbacarella.blogspot.com/projects/tmetric/.
[28] UPI. Virus strikes 15 million PCs.
http://www.upi.com/Top_News/2009/01/26/
Virus-strikes-15-million-PCs/
UPI-19421232924206/.
[29] Verisign. The Domain Name Industry Brief.
http://www.verisign.com/domain-name-services/
domain-information-center/
domain-name-resources/
domain-name-report-sept09.pdf.
[30] D. Watson. Know Your Enemy: Containing Conﬁcker.
http://www.honeynet.org/papers/conficker.
[31] Y. Xie, F. Yu, K. Achan, E. Gillum, M. Goldzmidt,
and T. Wobber. How Dynamic are IP Addresses? In
Proceedings of ACM SIGCOMM, Aug. 2007.
[32] Y. Xie, F. Yu, K. Achan, R. Panigraphy, G. Hulte,
and I. Osipkov. Spamming Botnets: Signatures and
Characteristics. In Proceedings of ACM SIGCOMM,
Aug. 2008.