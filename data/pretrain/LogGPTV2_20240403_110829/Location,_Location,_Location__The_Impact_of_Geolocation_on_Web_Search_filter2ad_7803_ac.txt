dramatically by query. The number of search results that
change is between 5 and 17, where 17 is essentially all search
results on the page. We also notice that (similar to our
observations about noise) general terms such as “school”
or “post oﬃce” exhibit higher personalization than brand
names.
The analogous plots for politicians and controversial
queries show similar trends as Figure 6, but with much lower
overall personalization. However, there are a few exceptional
Figure 6: Personalization of each search term for local queries.
Figure 7: Amount of personalization caused by diﬀerent types
of search results.
search terms. In the case of politicians, these exceptions are
common names such as “Bill Johnson” or “Tim Ryan”, so
it is likely that the diﬀerences stem from ambiguity. In the
case of controversial terms, the most personalized queries
are “health”, “republican party”, and “politics”.
Search Result Types.
It is not terribly surprising
that Google personalizes Maps and News results based on
location. However, we ﬁnd that personalization of Maps and
News results only explains a small portion of the diﬀerences
we observe.
Figure 7 breaks down the overall edit distance values into
components corresponding to News, Maps, and all other
search results, for each granularity and query type. For
controversial queries, 6-18% of the edit distance can be at-
tributed to News results, and interestingly, this fraction in-
creases from county to nation granularity. A diﬀerent com-
position is seen for local queries: 18-27% of diﬀerences are
caused by Maps results. The takeaway is that, surprisingly,
the vast majority of changes due to location-based person-
alization impact “typical” results.
Consistency Over Time.
Thus far, all of our plots
have presented values averaged over 5 days. To determine
whether personalization is consistent over time, we plot Fig-
ure 8. In this ﬁgure, we choose one location in each granu-
larity to serve as the baseline. The red line plots the average
edit distance when comparing the baseline to its control (i.e.,
the red line shows the noise ﬂoor); each black line is a com-
parison between the baseline and another location at that
granularity. We focus on local queries since they are most
heavily personalized.
Figure 8 shows that the amount of personalization is sta-
ble over time. Politicians and controversial terms show the
 0 4 8 12 16 20Wendy’sStarbucksDairy QueenChipotleSubwayBurger KingKFCMcdonaldsPost OfficeFootballPolling PlaceRailChick-fil-aBankTrainSushiRestaurantBurgerParkUniversityCoffeeFast FoodFire StationStationBusAirportPolice StationHigh SchoolSchoolElementary SchoolHospitalCollegeMiddle SchoolAvg. Edit DistanceCounty (Cuyahoga)State (Ohio) National* (USA) 0 2 4 6 8 10 12NSCNSCNSCAvg. Edit DistanceMapsNewsOtherPoliticiansControversialLocal(a) County (Cuyahoga)
(b) State (Ohio)
(c) National (USA)
Figure 8: Personalization of 25 locations, each compared to a baseline location, for local queries. The red line compares two treatments
at the baseline location (i.e., the experimental control), and thus shows the noise ﬂoor.
same trend but with lower personalization overall (ﬁndings
not shown). As expected, we see a wide gulf between the
baseline and other locations at state and nation granularity,
since search results are extremely diﬀerent at these long dis-
tances. However, interestingly, we see that some locations
“cluster” at the county-level, indicating that some locations
receive similar search results to the baseline.
Demographics.
To investigate why certain locations
cluster at the county-level, we examined many potential cor-
relations between all pairs of county-level locations. This
included correlations based on distance (i.e., do closer loca-
tions tend to cluster), as well as 25 demographic features like
population density, poverty, educational attainment, ethnic
composition, English ﬂuency, income, etc. Unfortunately,
we were unable to identify any correlations that explain the
clustering of locations. Based on this analysis, it appears
that Google Search does not use demographic features to
implement location-based personalization.
4. RELATED WORK
Search Personalization.
Many researchers have in-
vestigated strategies for personalizing search engines in or-
der to increase the quality of results [8, 17, 18]. Dou et al.
and Micarelli et al. survey several diﬀerent personalization
techniques [4,14] to determine what features improve search
results the most. Several studies have speciﬁcally focused on
the importance of location in search personalization: [3, 26]
use linguistic tools to infer geo-intention from search queries,
while [25, 26] focuses on location relevance of webpage con-
tent to the given search query.
In contrast to studies that
Auditing Algorithms.
aim to develop new personalization algorithms, a recent line
of work measures deployed personalization systems to un-
derstand their impact on users. Latanya Sweeney examined
Google Adsense and uncovered that the system serves ads in
a racially biased manner [22]. Our prior work [11] as well as
Bobble [24] examine how Google Search personalizes search
results, and ﬁnd that geolocation is one of the features used
by the algorithm. However, these studies only examine the
impact of IP address geolocation, and only at course-grained
locations (e.g., diﬀerent states and countries). Other studies
have examined the eﬀects of algorithmic personalization on
the Facebook News Feed [5, 6], e-commerce [10, 15, 16], and
online ads [7, 13].
5. CONCLUDING DISCUSSION
In this paper, we present a detailed analysis of location-
based personalization on Google Search. We develop a novel
methodology that allows us to query Google from any loca-
tion around the world. Using this technique we sent 3,600
distinct queries to Google Search over a span of 30 days from
59 locations across the US.
Our ﬁndings show that location does indeed have a large
impact on search results, and that the diﬀerences increase as
physical distance grows. However, we observe many nuances
to Google’s implementation of location-based personaliza-
tion. First, not all types of queries trigger the algorithm to
the same degree: politicians are essentially unaﬀected by ge-
ography; controversial terms see small changes due to News;
and local terms see large diﬀerences due to changes in Maps
and normal results. Second, not all queries expected to trig-
ger location-personalization do: for example, search results
for brand names like “Starbucks” do not include Maps.
Finally, and most surprisingly, we also discover that
Google Search returns search results that are very noisy, es-
pecially for local queries. This non-determinism is puzzling,
since Google knows the precise location of the user (during
our experiments), and thus should be able to quickly calcu-
late the closest set of relevent locations.
Much work remains to be done. Our methodology can eas-
ily be extended to other countries and search engines. We
also plan on further investigating the correlations between
demographic features and search results. Additional con-
tent analysis on the search results may help us uncover the
speciﬁc instances where personalization algorithms reinforce
demographic biases.
The full list of query terms, as well as our source code and
data, are all open-source and available at our website:
http://personalization.ccs.neu.edu
Acknowledgements
We thank the anonymous reviewers and our shepherd,
Matthew Luckie, for their helpful comments. We also thank
Arash Molavi Kakhki for developing the JavaScript reim-
plementation of the Geolocation API used in this project.
This research was supported in part by NSF grants CNS-
1054233, CNS-1319019, and CHS-1408345. Any opinions,
ﬁndings, and conclusions or recommendations expressed in
this material are those of the authors and do not necessarily
reﬂect the views of the NSF.
 0 2 4 6 8 10 1212345Avg. Edit DistanceDay 0 2 4 6 8 10 1212345Avg. Edit DistanceDay 0 2 4 6 8 10 1212345Avg. Edit DistanceDay6. REFERENCES
[1] Alexa Top 500 Global Sites.
http://www.alexa.com/topsites.
[2] J. Burn-Murdoch. US web statistics released for May 2012:
which sites dominate, and where do we go for online news?
The Guardian, 2012.
[3] P. N. Bennett, F. Radlinski, R. W. White, and E. Yilmaz.
Inferring and Using Location Metadata to Personalize Web
Search. SIGIR, 2011.
[4] Z. Dou, R. Song, and J.-R. Wen. A Large-scale Evaluation
and Analysis of Personalized Search Strategies. WWW,
2007.
[5] M. Eslami, A. Aleyasen, K. Karahalios, K. Hamilton, and
C. Sandvig. FeedVis: A Path for Exploring News Feed
Curation Algorithms. CSCW, 2015.
[6] M. Eslami, A. Rickman, K. Vaccaro, A. Aleyasen, A.
Vuong, K. Karahalios, K. Hamilton, and C. Sandvig. “I
always assumed that I wasn’t really that close to [her]”:
Reasoning about invisible algorithms in the news feed.
CHI, 2015.
[7] S. Guha, B. Cheng, and P. Francis. Challenges in
Measuring Online Advertising Systems. IMC, 2010.
[8] S. Gauch, J. Chaﬀee, and A. Pretschner. Ontology-based
personalized search and browsing. Web Intelligence and
Agent Systems, 1, 2003.
[9] Google. Personalized Search Graduates from Google Labs.
News From Google Blog, 2005.
http://googlepress.blogspot.com/2005/11/
personalized-search-graduates-from_10.html.
[10] A. Hannak, G. Soeller, D. Lazer, A. Mislove, and C.
Wilson. Measuring Price Discrimination and Steering on
E-commerce Web Sites. IMC, 2014.
[11] A. Hannak, P. Sapiezy´nski, A. M. Kakhki, B.
Krishnamurthy, D. Lazer, A. Mislove, and C. Wilson.
Measuring Personalization of Web Search. WWW, 2013.
[12] HTML5 Geolocation API.
http://dev.w3.org/geo/api/spec-source.html.
[13] M. Lecuyer, G. Ducoﬀe, F. Lan, A. Papancea, T. Petsios,
R. Spahn, A. Chaintreau, and R. Geambasu. XRay:
Enhancing the Web’s Transparency with Diﬀerential
Correlation. USENIX Security, 2014.
[14] A. Micarelli, F. Gasparetti, F. Sciarrone, and S. Gauch.
Personalized Search on the World Wide Web. The Adaptive
Web, Peter Brusilovsky, Alfred Kobsa, and Wolfgang Nejdl,
eds., Springer-Verlag, 2007.
[15] J. Mikians, L. Gyarmati, V. Erramilli, and N. Laoutaris.
Detecting Price and Search Discrimination on the Internet.
HotNets, 2012.
[16] J. Mikians, L. Gyarmati, V. Erramilli, and N. Laoutaris.
Crowd-assisted Search for Price Discrimination in
E-Commerce: First results. CoNEXT, 2013.
[17] M. G. Noll and C. Meinel. Web Search Personalization via
Social Bookmarking and Tagging. Proc. of The Semantic
Web and 2nd Asian Conference on Asian Semantic Web
Conference, 2007.
[18] A. Pretschner and S. Gauch. Ontology based personalized
search. ICTAI, 1999.
[19] E. Pariser. The Filter Bubble: What the Internet is Hiding
from You. Penguin Press, 2011.
[20] PhantomJS. 2015. http://phantomjs.org.
[21] Right to be Forgotten ruling.
http://ec.europa.eu/justice/data-protection/files/
factsheets/factsheet_data_protection_en.pdf.
[22] L. Sweeney. Discrimination in Online Ad Delivery. SSRN,
2013.
[23] D. Y. Wang, M. Der, M. Karmai, L. Saul, D. McCoy, S.
Savage, and G. M. Voelker. Search + Seizure: The
Eﬀectiveness of Interventions on SEO Campaigns. IMC,
2014.
[24] X. Xing, W. Meng, D. Doozan, N. Feamster, W. Lee, and
A. C. Snoeren. Exposing Inconsistent Web Search Results
with Bobble. PAM, 2014.
[25] B. Yu and G. Cai. A query-aware document ranking
method for geographic information retrieval. GIR, 2007.
[26] X. Yi, H. Raghavan, and C. Leggetter. Discovering Users’
Speciﬁc Geo Intention in Web Search. WWW, 2009.