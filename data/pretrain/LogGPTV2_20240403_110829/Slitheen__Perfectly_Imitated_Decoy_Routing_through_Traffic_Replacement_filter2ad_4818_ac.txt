the server’s TCP options, or IP TLS values as these are supplied by
the overt site itself. We give a more complete security analysis of
Slitheen and a comparison to existing systems in Section 4.
3.2 Content Replacement Details
While the replacement of the X-Slitheen headers and leaf content
types is straightforward in theory, it is difﬁcult to achieve in prac-
tice while also minimizing the latency introduced by the station.
HTTP responses may be spread across multiple TLS records, and
each record may contain multiple responses. Additionally, a record
may be spread across multiple packets, leaving the station unable
to decrypt a record to replace its contents or determine the content
type of the responses it contains until the rest of the record has been
received. Furthermore, packets may be delayed or dropped and ar-
rive at the relay station out of order. Waiting for the receipt of an
entire record before sending the observed packet to the client intro-
duces an identiﬁable amount of latency, which may be used by the
censor to detect the usage of Slitheen.
A simple solution to receiving a record fragment is to forward the
record unchanged and forego any possibly replaceable responses it
contains. However, as record sizes for large image ﬁles are fre-
quently large themselves, this results in a signiﬁcant drop in the
bandwidth available for delivering censored content. To address
this trade-off, we analyzed all possible states that may occur at the
relay station upon the receipt of a packet from the overt site and
determined a replacement procedure that maximizes the amount of
downstream data that can be replaced without delaying packets that
contain partial records.
Record state. When a packet is received by the relay station, the
TLS record state of the ﬂow determines whether the packet’s con-
tents begin with a new record, contain the contents of a previously
processed record, or contain the remnants of a previous record and
the beginning of a new record. The record’s length, speciﬁed in
the record header, determines how many full or partial records are
contained in the current packet and how many bytes of subsequent
packets contain the contents of the record. Although the relay sta-
tion may not be able to decrypt a record if it is spread across mul-
tiple packets, it is still able to maintain a view of the record state.
Depending on the HTTP state of the ﬂow, these records may be
safely replaced without being decrypted by the station.
A ﬂow can have an unknown record state if packets arrive at the
station out of order.
If the delayed packet does not contain any
new record headers, the station is able to maintain the record state
and processes the received packet in the usual manner, assuming
the eventual receipt of the missing packet. However, if the delayed
packet contained the beginning of a new record, the station has lost
the record state and can only regain it after the missing packet ar-
rives. While the record state is unknown, the station is unable to
encrypt modiﬁed records for the client, as it does not know the
lengths or contents of the record(s) in a received packet.
HTTP state. The station also maintains information about the
HTTP state of each ﬂow, indicating whether the next record will
contain all or part of a response header, or response body. We give
the state machine for HTTP responses in Figure 3. The end of a
header is determined, as speciﬁed in RFC 2616 [9], by the receipt
of two consecutive carriage return and line feed characters (CRLF):
one to signify the end of the last header ﬁeld, and one to signify
that there are no more header ﬁelds in the message. The length
of the response is determined by the status code of the response,
and the transfer encoding (in which case the length is updated with
each subsequent “chunk”) or the content length. The Content-Type
header indicates to the station whether the subsequent response
should be replaced.
The HTTP state of the ﬂow is updated upon the receipt of a new
record header. Depending on the HTTP state, a record does not
need to be decrypted in order to be replaced. When the station
receives a new record, it checks the record header to determine
whether the record is contained in the TCP segment and may be
decrypted, or whether the record is spread across multiple packets.
It then determines, based on the HTTP state, whether the record
may be replaced. If the HTTP state and the record’s length indi-
cates that it contains only a replaceable HTTP response body, the
station will then construct a new record of the same length and ﬁll
it with downstream data from the client’s queue. After encrypting
the modiﬁed record, it sends the ﬁrst part, matching the length of
the record fragment in the received TCP segment, and stores the
remainder of the modiﬁed record to replace the data in subsequent
packets. After the entire record has been sent, the next TCP seg-
ment data will contain the header of a new TLS record.
If, however, the station is unable to decrypt a record that contains
information about the response length or content type, the HTTP
state of the ﬂow will be unknown until the station receives the rest
of the record and decrypts it. In this case, the contents of the record
will be forwarded immediately to the client, without modiﬁcation
and a copy saved by the station to decrypted when the entire record
arrives. Upon its receipt, the station can re-evaluate the HTTP state
of the ﬂow. Similarly, when the record state of the ﬂow is unknown
due to a delayed or dropped packet, the HTTP state of the ﬂow will
remain unknown until the station receives the missing packet. At
this point, the station will determine the updated state and continue
processing records.
3.3 Future Changes to HTTP
We have designed our system for use with HTTP/1.1, in which
a user issues a sequence of HTTP GET requests to retrieve the
resources on a page. However, the recently proposed HTTP/2.0
speciﬁcation suggests several changes that increase the efﬁciency
of page loads by reducing header sizes and allowing concurrently
loaded HTTP responses. Our system requires minor changes to
function with the new speciﬁcation.
Header reduction in HTTP/2.0 is achieved through compression.
The header ﬁelds of an HTTP request or response are compressed
before transmission to their destination. We can still add our own
headers to the list before compression, but special care must be
taken to ensure that the total compressed size of the headers with
our extra data does not vary signiﬁcantly from the size of a typical
HTTP header to the site. When the headers are received by the
relay station, the station must uncompress the headers to analyze or
modify them, and then re-compress the headers before forwarding
the trafﬁc. If modiﬁcations are made, the station must ensure that
the size of the re-compressed HTTP message stays consistent.
To allow for multiple concurrently loaded resources, HTTP/2.0
encapsulates requests and responses in HTTP frames. Each request
and corresponding response is identiﬁed by a unique stream ID.
These stream IDs are later used by the client to demultiplex the se-
quence of frames into separate resources. The multiplexing of re-
sources complicates our calculation of the HTTP state at the relay
station as an incoming encrypted record may contain data from sev-
eral streams. The station will need to keep track of the HTTP state
of each stream, but without the ability to decrypt the record and
determine which stream(s) it contains, the station will be unable
to determine the next HTTP state of each stream and will not be
Figure 3: A ﬂow may be in one of several TLS (blue) and HTTP (red, green, and black) states. When a new packet arrives that allows the
relay station to ﬁnd the beginning of a new TLS record, the station uses the record’s length, its (possibly) decrypted data, and the length of
the packet to determine the next HTTP state. States in the shaded red circle must be decrypted to decide the next state. If the ﬂow is in a
red, shaded state when the relay receives a partial TLS record it cannot decrypt due to missing data, the ﬂow will enter into the UNKNOWN
state until the remainder of the record is received and decrypted. This is represented by the dashed red arrow. States in green dashed boxes
indicate states where data may be replaced. If the HTTP header showed a leaf content type, the relay station will construct a new record to
replace the one(s) it receives. A ﬂow with an HTTP state of UNKNOWN may recover its state by reconstructing partial or missing records
and analyzing the decrypted data, along with the previous known state.
able to replace the record contents with proxied downstream data.
Without testing to determine how often the station will lose track
of the HTTP state of a tagged ﬂow, we are unable to guess at how
difﬁcult it will be to maintain a steady bandwidth for downstream
proxy data. We leave this analysis for future work.
4. SECURITY ANALYSIS
We have analyzed the security of our system by examining the
effectiveness of previously proposed decoy routing attacks [18, 25,
26]. These attacks consider three different types of adversaries: a
passive adversary capable of only monitoring trafﬁc, an active ad-
versary capable of both monitoring and modifying trafﬁc by drop-
ping, injecting, or changing packets inside their area of inﬂuence,
and ﬁnally a routing-capable adversary who is able to not only
change trafﬁc, but also make routing decisions on trafﬁc that leaves
their network.
The goal of the adversary is ultimately to identify a decoy rout-
ing session. An adversary may also try to identify the censored
content that the client is accessing through the decoy routing ses-
sion. We do not consider attacks that allow the adversarial censor
to perform unrealistic computations or utilize unrealistic amounts
of resources; For example, we assume that the adversary is unable
to distinguish a tagged ClientHello message from a truly random
nonce, as doing so would violate a cryptographic assumption. Sim-
ilarly, we assume that the adversary may not compromise the TLS
session between the client and the overt site by brute-forcing the
overt site’s private key, or performing a TLS downgrade attack.
Furthermore, deployed relay stations and overt sites are assumed
to be geographically outside the censor’s sphere of inﬂuence.
4.1 Latency and Fingerprinting Attacks
Added latency in decoy routing systems stems from two sources:
(1) the additional time it takes for the relay station proxy to com-
municate with a possibly distant censored server, and (2) from the
mechanisms of the proxy itself in processing and verifying the TLS
handshake, and manipulating data that ﬂows through it. In their
experiments, Schuchard et al. found that there was a signiﬁcant
amount of latency from both sources independently, enough to iden-
tify the usage of previous decoy routing systems.
Slitheen defends perfectly against the ﬁrst type of latency. The
relay station does not wait to communicate with the covert desti-
nation, but forwards packets from the overt site immediately after
possibly replacing their contents with queued downstream proxy
data. Similarly, the station forwards upstream data immediately af-
ter processing the record’s contents to extract the Slitheen ID of the
ﬂow and upstream data for the proxy.
The second type of latency, from the Slitheen proxy itself, is
more difﬁcult to prevent. Schuchard et al. show that Telex exhib-
ited enough latency to detect its usage even by choosing a covert
destination on the same server as the overt destination (effectively
reducing the ﬁrst type of latency to zero). Although Schuchard et
al. were unable to determine the cause of the latency, their ﬁndings
suggest some amount of overhead imposed by the relay proxy and
TLS handshake protocol. While the tagging procedure of Slitheen
matches that of Telex, our proxying protocol behaves very differ-
ently.
If there is overhead introduced by the proxy on the relay
station, it will not affect the rate at which incoming packets to the
relay station are processed, replaced, and forwarded to their desti-
nation. We performed a latency analysis of our system by accessing
an overt destination as both an overt site for tagged ﬂows and as a
regular, untagged access. Our results, given in Section 6.2, show
that we do not introduce enough latency to identify the use of our
decoy routing system by timing page loads.
In addition to identifying the use of decoy routing, Schuchard
et al. show that latency can be used to ﬁngerprint packet sequences
and determine which censored webpage a client has accessed. Slith-
een defends against both this and other traditional website ﬁnger-
printing attacks by eliminating not only the latency from accessing
distant covert destinations, but also by forcing the packet timings,
sizes, and directionality to exactly follow that of a regular access
to the overt site. The latency ﬁngerprinting method relies on dif-
ferences between the latency distributions of visits to different cen-
sored sites. With Slitheen, accesses to different censored sites will
all produce the same latency distribution, as the latency source is
only in the decryption and re-encryption of records passing through
the relay station.
This, coupled with the fact that the observed packet sequences
of a regular access and a decoy access to any overt destination will
be identical in terms of packet sizes, relative timing, and direction
drastically reduces the censor’s ability to distinguish between the
two types of trafﬁc.
4.2 Passive Attacks
In addition to timing and latency attacks, there are a number of
other attacks an adversary may employ to detect the use of Slitheen.
Protocol Fingerprinting. Previous decoy routing schemes are sus-
ceptible to protocol ﬁngerprinting attacks, in which the adversary
leverages the possible differences in the TCP/IP implementations
of the overt destination and the proxy. Mimicry is an inherently dif-
ﬁcult problem, as any difference in options, parameters, or variable
values can alert the censor to a suspicious change in the connection.
The defense proposed by Wustrow et al. [25] requires each station
to build a proﬁle of each overt site that accounts for all possible
variations in TCP options and IP header values. This solution is
costly in terms of storage and also slow to update; a change in the
TCP options or headers requires an immediate change at the station
to evade censor scrutiny.
Slitheen eliminates risk of protocol ﬁngerprinting by reusing the
TCP and IP headers sent by the overt site. The only differences in
the data sent by the overt site and the Slitheen proxy are the en-
crypted payload and the TCP checksum. Neither of these values
provides the censor with any information that suggests the replace-
ment of the requested resource with proxy data.
Website Fingerprinting. An adversary capable of observing traf-
ﬁc may attempt to ﬁngerprint the website by analyzing packet sizes,
timings, and directionality. Our system eliminates the usage of
packet sizes and directionality features completely, as these will
be identical to those exhibited in a regular access of the overt page.
The relay station merely replaces the contents of overt packets and
does not modify their size or destinations. Furthermore, timings
will remain consistent as we are not holding packets at the relay
station, but rather forwarding them immediately after possibly re-
placing their contents. In Section 6, we will show that these opera-
tions add no discernible latency to loading an overt page.
Station Malfunction. In the event that the relay station fails to rec-
ognize a tagged ﬂow, a Slitheen client’s OUS will interact with the
overt site in the normal manner, avoiding suspicion. Telex and Tap-
Dance clients assume that the station is present and able to block
or monitor upstream ﬂows to the overt destination. If the station is
absent in Telex or Tapdance, the connection to the overt site termi-
nates early or results in an HTTP error message that may indicate
their use to a passively monitoring censor.
4.3 Active Attacks
An active adversary is capable of modifying, injecting, or drop-
ping trafﬁc in addition to passive monitoring. The following attacks
are known active attacks against previous decoy routing systems.
Tag Replay Attack. Our system inherits protection against a tag or
handshake replay attack from the Telex handshake procedure. If an
adversary attempts to replay a tag, they will not be able to success-
fully construct the TLS Finished message without knowledge of the
shared secret, resulting in a connection terminated by the client and
overt destination.
State-Controlled Root Certiﬁcates. In deployments where cen-
sors are actively performing man-in-the-middle attacks on TLS traf-
ﬁc by mandating the installation of a state-controlled root certiﬁ-
cate, the resultant ﬂows will not properly proceed through the tag-
ging procedure and will pass through the station unaltered. While
this performs a denial of service attack on Slitheen, it does not re-
veal a client’s usage of the system unless they include X-Slitheen
headers in their upstream requests. To alert the client of the fact
that their decoy routing session has not been safely established, we
propose a slight modiﬁcation to the TLS handshake in which the
Slitheen station adds an additional input, seeded from the client’s
tag, to the TLS Finished hash sent to the client, after the station has
veriﬁed that the Finished messages are correct. When the client re-
ceives the Finished message, they will verify it using the additional