title:Learning scheduling algorithms for data processing clusters
author:Hongzi Mao and
Malte Schwarzkopf and
Shaileshh Bojja Venkatakrishnan and
Zili Meng and
Mohammad Alizadeh
Learning Scheduling Algorithms for Data Processing Clusters
Hongzi Mao, Malte Schwarzkopf, Shaileshh Bojja Venkatakrishnan, Zili Meng⋆, Mohammad Alizadeh
MIT Computer Science and Artificial Intelligence Laboratory ⋆Tsinghua University
{hongzi,malte,bjjvnkt,alizadeh}@csail.mit.edu,PI:EMAIL
Abstract
Efficiently scheduling data processing jobs on distributed compute
clusters requires complex algorithms. Current systems use simple,
generalized heuristics and ignore workload characteristics, since
developing and tuning a scheduling policy for each workload is infea-
sible. In this paper, we show that modern machine learning techniques
can generate highly-efficient policies automatically.
Decima uses reinforcement learning (RL) and neural networks to
learn workload-specific scheduling algorithms without any human
instruction beyond a high-level objective, such as minimizing average
job completion time. However, off-the-shelf RL techniques cannot
handle the complexity and scale of the scheduling problem. To build
Decima, we had to develop new representations for jobs’ dependency
graphs, design scalable RL models, and invent RL training methods
for dealing with continuous stochastic job arrivals.
Our prototype integration with Spark on a 25-node cluster shows
that Decima improves average job completion time by at least 21%
over hand-tuned scheduling heuristics, achieving up to 2× improve-
ment during periods of high cluster load.
CCS Concepts: Software and its engineering → Scheduling; Networks →
Network resources allocation; Computing methodologies → Reinforcement
learning
Keywords: resource management, job scheduling, reinforcement learning
ACM Reference Format:
Hongzi Mao, Malte Schwarzkopf, Shaileshh Bojja Venkatakrishnan, Zili Meng
and Mohammad Alizadeh. 2019. Learning Scheduling Algorithms for Data
Processing Clusters. In SIGCOMM ’19, August 19-23, 2019, Beijing, China.
ACM, Beijing, China, 19 pages. https://doi.org/10.1145/3341302.3342080
Introduction
1
Efficient utilization of expensive compute clusters matters for enter-
prises: even small improvements in utilization can save millions of
dollars at scale [11, §1.2]. Cluster schedulers are key to realizing these
savings. A good scheduling policy packs work tightly to reduce frag-
mentation [34, 36, 76], prioritizes jobs according to high-level metrics
such as user-perceived latency [77], and avoids inefficient configura-
tions [28]. Current cluster schedulers rely on heuristics that prioritize
generality, ease of understanding, and straightforward implementa-
tion over achieving the ideal performance on a specific workload. By
using general heuristics like fair scheduling [8, 31], shortest-job-first,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGCOMM ’19, August 19-23, 2019, Beijing, China
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-5956-6/19/08. . . $15.00
https://doi.org/10.1145/3341302.3342080
and simple packing strategies [34], current systems forego potential
performance optimizations. For example, widely-used schedulers
ignore readily available information about job structure (i.e., internal
dependencies) and efficient parallelism for jobs’ input sizes. Unfortu-
nately, workload-specific scheduling policies that use this information
require expert knowledge and significant effort to devise, implement,
and validate. For many organizations, these skills are either unavail-
able, or uneconomic as the labor cost exceeds potential savings.
In this paper, we show that modern machine-learning techniques
can help side-step this trade-off by automatically learning highly
efficient, workload-specific scheduling policies. We present Decima1,
a general-purpose scheduling service for data processing jobs with
dependent stages. Many systems encode job stages and their depen-
dencies as directed acyclic graphs (DAGs) [10, 19, 42, 80]. Efficiently
scheduling DAGs leads to hard algorithmic problems whose optimal
solutions are intractable [36]. Given only a high-level goal (e.g., mini-
mize average job completion time), Decima uses existing monitoring
information and past workload logs to automatically learn sophisti-
cated scheduling policies. For example, instead of a rigid fair sharing
policy, Decima learns to give jobs different shares of resources to
optimize overall performance, and it learns job-specific parallelism
levels that avoid wasting resources on diminishing returns for jobs
with little inherent parallelism. The right algorithms and thresholds
for these policies are workload-dependent, and achieving them today
requires painstaking manual scheduler customization.
Decima learns scheduling policies through experience using mod-
ern reinforcement learning (RL) techniques. RL is well-suited to
learning scheduling policies because it allows learning from actual
workload and operating conditions without relying on inaccurate as-
sumptions. Decima encodes its scheduling policy in a neural network
trained via a large number of simulated experiments, during which it
schedules a workload, observes the outcome, and gradually improves
its policy. However, Decima’s contribution goes beyond merely apply-
ing off-the-shelf RL algorithms to scheduling: to successfully learn
high-quality scheduling policies, we had to develop novel data and
scheduling action representations, and new RL training techniques.
First, cluster schedulers must scale to hundreds of jobs and thou-
sands of machines, and must decide among potentially hundreds of
configurations per job (e.g., different levels of parallelism). This leads
to much larger problem sizes compared to conventional RL applica-
tions (e.g., game-playing [61, 70], robotics control [51, 67]), both
in the amount of information available to the scheduler (the state
space), and the number of possible choices it must consider (the ac-
tion space).2 We designed a scalable neural network architecture that
combines a graph neural network [12, 23, 24, 46] to process job and
cluster information without manual feature engineering, and a policy
1In Roman mythology, Decima measures threads of life and decides their destinies.
2For example, the state of the game of Go [71] can be represented by 19 × 19 = 361
numbers, which also bound the number of legal moves per turn.
270
SIGCOMM ’19, August 19-23, 2019, Beijing, China
H. Mao et al.
network that makes scheduling decisions. Our neural networks reuse
a small set of building block operations to process job DAGs, irre-
spective of their sizes and shapes, and to make scheduling decisions,
irrespective of the number of jobs or machines. These operations are
parameterized functions learned during training, and designed for the
scheduling domain — e.g., ensuring that the graph neural network
can express properties such as a DAG’s critical path. Our neural net-
work design substantially reduces model complexity compared to
naive encodings of the scheduling problem, which is key to efficient
learning, fast training, and low-latency scheduling decisions.
Second, conventional RL algorithms cannot train models with con-
tinuous streaming job arrivals. The randomness of job arrivals can
make it impossible for RL algorithms to tell whether the observed
outcome of two decisions differs due to disparate job arrival patterns,
or due to the quality the policy’s decisions. Further, RL policies nec-
essarily make poor decisions in early stages of training. Hence, with
an unbounded stream of incoming jobs, the policy inevitably accu-
mulates a backlog of jobs from which it can never recover. Spending
significant training time exploring actions in such situations fails to
improve the policy. To deal with the latter problem, we terminate train-
ing “episodes” early in the beginning, and gradually grow their length.
This allows the policy to learn to handle simple, short job sequences
first, and to then graduate to more challenging arrival sequences. To
cope with the randomness of job arrivals, we condition training feed-
back on the actual sequence of job arrivals experienced, using a recent
technique for RL in environments with stochastic inputs [55]. This
isolates the contribution of the scheduling policy in the feedback and
makes it feasible to learn policies that handle stochastic job arrivals.
We integrated Decima with Spark and evaluated it in both an exper-
imental testbed and on a workload trace from Alibaba’s production
clusters [6, 52].3 Our evaluation shows that Decima outperforms ex-
isting heuristics on a 25-node Spark cluster, reducing average job
completion time of TPC-H query mixes by at least 21%. Decima’s
policies are particularly effective during periods of high cluster load,
where it improves the job completion time by up to 2× over exist-
ing heuristics. Decima also extends to multi-resource scheduling of
CPU and memory, where it improves average job completion time by
32-43% over prior schemes such as Graphene [36].
In summary, we make the following key contributions:
(1) A scalable neural network design that can process DAGs of ar-
bitrary shapes and sizes, schedule DAG stages, and set efficient
parallelism levels for each job (§5.1–§5.2).
(2) A set of RL training techniques that for the first time enable
training a scheduler to handle unbounded stochastic job arrival
sequences (§5.3).
(3) Decima, the first RL-based scheduler that schedules complex data
processing jobs and learns workload-specific scheduling policies
without human input, and a prototype implementation of it (§6).
(4) An evaluation of Decima in simulation and in a real Spark cluster,
and a comparison with state-of-the-art scheduling heuristics (§7).
2 Motivation
Data processing systems and query compilers such as Hive, Pig, Spark-
SQL, and DryadLINQ create DAG-structured jobs, which consist of
processing stages connected by input/output dependencies (Figure 1).
3We used an earlier version of Alibaba’s public cluster-trace-v2018 trace.
Figure 1: Data-parallel jobs have complex data-flow graphs like the ones
shown (TPC-H queries in Spark), with each node having a distinct number
of tasks, task durations, and input/output sizes.
For recurring jobs, which are common in production clusters [4],
reasonable estimates of runtimes and intermediate data sizes may be
available. Most cluster schedulers, however, ignore this job structure
in their decisions and rely on e.g., coarse-grained fair sharing [8, 16,
31, 32], rigid priority levels [77], and manual specification of each
job’s parallelism [68, §5]. Existing schedulers choose to largely ignore
this rich, easily-available job structure information because it is diffi-
cult to design scheduling algorithms that make use of it. We illustrate
the challenges of using job-specific information in scheduling deci-
sions with two concrete examples: (i) dependency-aware scheduling,
and (ii) automatically choosing the right number of parallel tasks.
2.1 Dependency-aware task scheduling
Many job DAGs in practice have tens or hundreds of stages with
different durations and numbers of parallel tasks in a complex depen-
dency structure. An ideal schedule ensures that independent stages
run in parallel as much as possible, and that no stage ever blocks on
a dependency if there are available resources. Ensuring this requires
the scheduler to understand the dependency structure and plan ahead.
This “DAG scheduling problem” is algorithmically hard: see, e.g.,
the illustrative example by Grandl et al. [36, §2.2] and the one we
describe in detail in Appendix A. Theoretical research [18, 20, 48, 69]
has focused mostly on simple instances of the problem that do not cap-
ture the complexity of real data processing clusters (e.g., online job
arrivals, multiple DAGs, multiple tasks per stage, jobs with different
inherent parallelism, overheads for moving jobs between machines,
etc.). For example, in a recent paper, Agrawal et al. [5] showed that
two simple DAG scheduling policies (shortest-job-first and latest-
arrival-processor-sharing) have constant competitive ratio in a basic
model with one task per job stage. As our results show (§2.3, §7),
these policies are far from optimal in a real Spark cluster.
Hence, designing an algorithm to generate optimal schedules for
all possible DAG combinations is intractable [36, 57]. Existing sched-
ulers ignore this challenge: they enqueue tasks from a stage as soon
as it becomes available, or run stages in an arbitrary order.
2.2 Setting the right level of parallelism
In addition to understanding dependencies, an ideal scheduler must
also understand how to best split limited resources among jobs. Jobs
vary in the amount of data that they process, and in the amount of
parallel work available. A job with large input or large intermediate
data can efficiently harness additional parallelism; by contrast, a job
running on small input data, or one with less efficiently parallelizable
operations, sees diminishing returns beyond modest parallelism.
271
          150100151020150100200Number of tasksDuration (sec)Data shuffle (MB)150100200151020150100Query 21                                                                                                                                        Query 20                                                       Query 17                     Query 8                                                                                                                                                                                                                                                                                                                                      Query 2Learning Scheduling Algorithms for Data Processing Clusters
SIGCOMM ’19, August 19-23, 2019, Beijing, China
the total time to complete all jobs by 30% compared to SJF. Further,
unlike fair scheduling, Decima partitions task slots non-uniformly
across jobs, improving average JCT by 19%.
Designing general-purpose heuristics to achieve these benefits is
difficult, as each additional dimension (DAG structure, parallelism,
job sizes, etc.) increases complexity and introduces new edge cases.
Decima opens up a new option: using data-driven techniques, it auto-
matically learns workload-specific policies that can reap these gains.
Decima does so without requiring human guidance beyond a high-
level goal (e.g., minimal average JCT), and without explicitly mod-
eling the system or the workload.
3 The DAG Scheduling Problem in Spark
Decima is a general framework for learning scheduling algorithms
for DAG-structured jobs. For concreteness, we describe its design in
the context of the Spark system.
A Spark job consists of a DAG whose nodes are the execution
stages of the job. Each stage represents an operation that the system
runs in parallel over many shards of the stage’s input data. The inputs
are the outputs of one or more parent stages, and each shard is pro-
cessed by a single task. A stage’s tasks become runnable as soon as
all parent stages have completed. How many tasks can run in parallel
depends on the number of executors that the job holds. Usually, a stage
has more tasks than there are executors, and the tasks therefore run in
several “waves”. Executors are assigned by the Spark master based on
user requests, and by default stick to jobs until they finish. However,
Spark also supports dynamic allocation of executors based on the wait
time of pending tasks [9], although moving executors between jobs
incurs some overhead (e.g., to tear down and launch JVMs).
Spark must therefore handle three kinds of scheduling decisions: (i)
deciding how many executors to give to each job; (ii) deciding which
stages’ tasks to run next for each job, and (iii) deciding which task to
run next when an executor becomes idle. When a stage completes, its
job’s DAG scheduler handles the activation of dependent child stages
and enqueues their tasks with a lower-level task scheduler. The task
scheduler maintains task queues from which it assigns a task every
time an executor becomes idle.
We allow the scheduler to move executors between job DAGs as it
sees fit (dynamic allocation). Decima focuses on DAG scheduling (i.e.,
which stage to run next) and executor allocation (i.e., each job’s degree
of parallelism). Since tasks in a stage run identical code and request