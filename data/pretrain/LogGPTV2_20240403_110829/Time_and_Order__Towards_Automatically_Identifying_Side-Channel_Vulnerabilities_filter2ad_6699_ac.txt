foreach ns ∈ n.successor() do
pgnext ← ns.StartAddr() / 4096
if pgnum (cid:54)= pgnext then
p.E ← G i
G i
w(pgnum, pgnext) ← w(pgnum, pgnext) + 1
p.E ∪ {}
end
end
Ntmp ← Ntmp \ {n}
Ntmp ← Ntmp ∪ {n.successor()}
until Ntmp (cid:54)= /0;
return G i
p
end
we just ﬁrst get all of the page numbers for all of the
executed basic blocks by traversing G i, and then we
traverse G i again to add the edges between the pages.
The weights are updated accordingly when there is a
cross-page control ﬂow transfer.
• Generating the order and timing. Once we have gen-
erated the nodes and edges for G i
p, we then generate
the order and timing information. The algorithm works
similar to algorithm 1 with the differences that we need
to record the new page order information, based on the
original order recorded in G i while traversing G i. Also,
for timing information, we will accumulate the recorded
timing information of the basic blocks that belong to the
same page based on the execution order. We will discard
our lower and upper bound timing estimation for each
basic block that was captured by the TNT packet if they
all belong to the same page.
4.3 Vulnerability Identiﬁcation
ANABLEPS detects both order-based and time-based side-
channel vulnerabilities by cross comparing the corresponding
ED-CFGs. More speciﬁcally, comparing Gps reveals vulner-
abilities at the page-level, which can be exploited by an ad-
versary that monitors the enclave program’s page accesses
(through page faults or page table entry updates). Comparing
Gcs reveal vulnerabilities at the cache-level, which can be ex-
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 449p = G j
p and G 2
ploited by an adversary that monitors the enclave program’s
cache accesses. Directly comparing Gs reveal vulnerabilities
at the basic-block level, which can be exploited by monitoring
the branch prediction units [20]. In the following, we use Gp
as examples to illustrate the process of vulnerability detection.
Order-based Vulnerability Detection. We compare every
G i
p with each other, the program is not vulnerable to page level
attack if the order information of every edge been accessed
in all G i
ps are the same. Otherwise, the attacker can infer
the secret based on the differences. The algorithm for graph
comparison is straightforward: G i
p if and only if the
sets of node and edges are identical, including the Order
list in each node, and the execution counts in the edges. In
Figure 1(d)(e)(f), with different input, the execution order of
the nodes are different. For instance, by comparing nodes
n1 in G 1
p, the length of their Order lists is different,
which can clearly differentiate the two graphs.
Time-based Vulnerability Detection. When any two graphs
p, ∀Ii,Ij ∈ I , are not vulnerable to order-based side
p and G j
G i
channels. ANABLEPS needs to further investigate time-based
vulnerabilities, by comparing the Time lists of the correspond-
ing nodes. The comparison of the Time lists is as follows:
The kth element of nl.Time in node nl in graph G i
p is com-
pared with the kth element of nl.Time in graph G j
p. However,
unlike comparison of the Order lists, where any difference
can directly conclude the comparison, comparing the Time
lists is more subtle. The execution time of a program can
be inﬂuenced by many reasons, such as on-demand paging,
caching, interrupts, etc.. In practice, each nl.Time[k] is a 2-
tuple (tmean,tstd), rather than a single value. The ﬁrst element
of the 2-tuple is the mean execution time to reach the succes-
sor node from multiple runs and the second element is the
one standard deviation. With enough number of samples, the
impact from side effects can be reduced.
To generate (tmean,tstd) for the list Time of each node, the
program is executed with the same input Ii ∈ I L times; so
each nl.Time[k] (the kth element of nl) is also executed L
times. The mean and standard deviation are calculated using
these L execution time between node nl and its kth successor.
In our implementation, L = 10.
Determining the Input Space for G i. Since the edge in G i
p
(and G i
c) can correspond to the jumps in different locations
in the program, we can only use the one-to-one mapping
relationship between G i and Ii to determine the input space for
G i. In particular, for each concrete input Isyntactic ∈ {Ifuzz ∪
Iconcolic}, we run the concolic execution with this seed input
again, but we also track the corresponding path constraints for
this seed input. Once we have collected the path constraints,
we then use a constraint solver to solve the constraints. If no
other input satisﬁes (or the execution time of the solver takes
too much time to solve.2), it means the input is unique (Ii is
2We currently set up this time to be 90 minutes.
completely leakable). Otherwise, we have to use application-
speciﬁc knowledge to determine the leakage.
5 Evaluation
We have implemented ANABLEPS to detect the side-channel
vulnerabilities for x86 and x86-64 ELF binaries by integrating
and extending a number of open source tools. In particular,
we extend Driller [30], which is built atop of AFL [1] and
concolic execution, for Input Generation, and we use perf
to conﬁgure Intel PT and dynamically collect the runtime
information of each input. We built the PT packets decoder
based on the open source library, libipt [3]. The ED-CFG
construction and cross-comparison tool is built using python
scripts by analyzing the PT packets, and matching the de-
coded address to the binary code with pyelftools library [5].
To quantify the input space for a given trace, we extended
angr [36], an easily extensible python-based symbolic execu-
tion tool, to negate the constraints of the input we provide and
calculate the input space. The prototype of ANABLEPS will
be public available at github.com/OSUSecLab/ANABLEPS.
In this section, we present our evaluation results. We ﬁrst
describe how we set up the experiment in §5.1, and then de-
scribe the experimental results in §5.2. All of our evaluations
are performed in Ubuntu Desktop 16.04LTS, running atop
Intel i7-7700 CPU, with 32G physical memory.
5.1 Experiment Setup
Benchmark Selection. Ideally we would like to use the SGX
programs for the test. However, there are not that many SGX
programs available, and therefore we run the legacy applica-
tions with library OS (e.g., Grephane-SGX [2]) support for
the evaluation. In particular, we selected 8 programs from a
variety of applications such as data analytics and machine
learning, image processing, and text processing. The name of
these programs is presented in the ﬁrst column of Table 1.
Functionality Under Test. Each of the tested benchmark pro-
gram contains quite sophisticated functionalities. Certainly,
we cannot test all of their functionalities; we only tested the
functionality of our interest (shown in the 2nd column of
Table 1), based on our best understanding with the bench-
marks. For instance, when testing Genometools, we know
the genomic related program usually takes two types of input:
bed format and gff3 format. Converting between these two
formats is a widely used operation in genomes. Therefore, we
test the genome library libgenometools.so by converting
bed format to gff3 format.
Input Generation. To launch each of the testing program
with Driller [30], we provide the seed inputs based on our best
understanding of the program. Even with both AFL and con-
colic execution, we still cannot explore all the program paths.
We therefore conﬁgure Driller [30] to run 48 hours for each
450          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Associationof the testing program. The number of syntactic inputs even-
tually generated are presented in the 3rd column of Table 1.
Trace Collection. With the input generated above, we run the
tested program traced by Intel PT. The tested program is run
outside of SGX in a debug mode. The execution time would
be similar to that of executing inside enclaves, because instruc-
tions executed in the enclave-mode and non-enclave-mode
have the same timing constraints (the main timing difference
happens at ECalls/OCalls). Each input generated a separate
trace ﬁle. The total size of the decoded PT trace ﬁle for each
program is presented in the 4th column of Table 1. Depending
on the size and input to the program, this size varies from a
few Gigabytes to several hundreds of Gigabytes.
5.2 Experimental Results
Next, we present how ANABLEPS detects the branch level,
page level, and cache level side-channel vulnerabilities based
on each individual trace and their corresponding input. As
we have described, from each input (and its corresponding
execution trace), we ﬁrst built their ED-CFGs, namely G is,
which are used to detect the branch level side channels. The
total number of such ED-CFGs is presented in the 5th column
of Table 1. Compared to the 3rd column of Table 1, we can
notice that except for three benchmarks (namely Freetype,
QRcodegen, and Genometools), the total number of unique
G is are all smaller than the total number of the syntactic inputs
generated by ANABLEPS.
Detecting Order-based Side Channels. To detect order-
based side channels, we ﬁrst cross-compare all of the G is
(G i
cs) to detect whether there is any unique Ii that maps
to a particular G i (G i
c). As we are detecting order-based
side channels, only Order of the G is (G i
cs) are used in
the comparison. Many inputs have such a one-to-one mapping
G i ↔ Ii (G i
c ↔ Ii), which suggests that no other
input I j maps to the same G i. The branch-level, page-level
and cache-level statistics for this mapping is reported in the
6th column of Table 1, the 3rd column of Table 2, and the
8th column of Table 2, respectively. From the table, we can
notice that compared to the branch-level vulnerabilities, less
one-to-one mappings are detected in page-level and cache-
level. For instance, while all inputs of dA in deep learning
can be recovered by branch-level side channel, they cannot
be recovered by page-level side channels.
p ↔ Ii or G i
ps or G i
ps or G i
p or G i
ps or G i
As the traces are dynamically collected, the node or edge
which can differ any two G is (G i
cs) must leak some
secret of interest. It is possible that many nodes or edges only
leak a partial secret. However, for some program, a set of
vulnerable nodes can be used together to leak the entire secret
(e.g., the Deep Learning case uses two nodes to leak the entire
secret). Moreover, it is also possible that part of leaked secret
can be used to infer the entire secret (e.g., the padding oracle
p → Iis or G i
attack for crypto algorithms only need to know if the padding
is correct or not).
Detecting Time-based Side Channels. For those that have
multiple inputs corresponding to the same trace, i.e., one-to-N
mappings (G i → Iis, G i
c → Iis), their statistics
are reported in the 8th column of Table 1, the 4th column of
Table 2, and the 9th column of Table 2, respectively. Next,
we use the timing information to further differentiate G i (G i
p
and G i
c) and see whether there is still one-to-one mapping
(i.e., G i ↔ Ii) after considering the timing differences. That
is, we hope to determine whether there are time-based side-
channel vulnerabilities when the program is not vulnerable to
order-based side channels. In practice, only large enough time
differences can be used to differentiate two traces. Therefore,
thresholds are deﬁned from empirical results. We report under
three different threshold settings (i.e., with t1 = 2ns, t2 = 10ns,
and t3 = 20ns), the number of such one-to-one mappings, and
these results are reported in the last three columns of Table 1,
the columns 5 to 7 and columns 10 to 12 of Table 2. We notice
that it is relative hard to differentiate inputs based on timing
information at branch level. However, many inputs can be
further differentiated after applying time information at page
or cache level.
Determining Input Spaces. Previous experiments are based
on generated inputs Iis. However, not all inputs in the whole
inputs set are generated. Therefore, we would like to know
whether there is only one input Ii in the whole inputs set that
can map to a particular G i, that is, if |{Ij|E(p,Ij) = G i,∀ j ∈
I}| = 1, which can be determined by using concolic execution.
If so, then the input Ii can be differentiated by order-based
vulnerabilities. The total number of symbolic execution de-
termined input Ideterminstic is reported in the 7th column of
Table 1. We can see that for some applications, such as QR-
codegen and Deep learning, Ideterminstic is non-zero, mean-
ing at branch-level some inputs of these programs can be
uniquely identiﬁed by execution traces. For some applica-
tions, Ideterminstic is zero, indicating by the constraint solver
that there are other inputs that all have the same execution
traces with generated inputs, e.g., function Sort in gsl, al-
though |G i ↔ Ii| is non-zero (120 for gsl).
However, the concolic execution cannot ﬁnish for ﬁve
programs (marked with × in the Table), including Hunspell,
PNG, and Freetype, because of the limitation in either
computation power or physical memory space. For these
programs, ANABLEPS cannot answer if these execution
traces will completely leak the information of the input.
5.2.1 Performance Overhead
We also measured the performance of ANABLEPS, though
it is an ofﬂine analysis tool. We report the execution time
for each of the key component of ANABLEPS in Table 3.
More speciﬁcally, during the Input Generation (IG) phase,
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 451Benchmark
Program
Functionality
under Test
|Isyntactic|
Deep Learning
gsl
Hunspell
PNG
Freetype
Bio-rainbow
QRcodegen
Genometools
dA
SdA
DBN
RBM
Sort
LogisticRegression
Permutation
Spell Checking
Image Render
Character Render
Bioinfo Clustering
Generate QR Code
bed to gff3 convertion
214
176
152
187
198
220
200
231
294
206
128
204
201
Trace Size
(GB)
76.8
384.2
139.0
225.9
25.1
2.8
3.0
307.2
82.3
352.6
51.3
17.9
382.4
|G i|
214
176
152
55
41
154
135
168
135
206
119
204
25
|G i ↔ Ii|
214
176
152
16
18
120
100
157
120
206
118
204
12
Detecting Branch Side Channel
|Ideteministic|
|G i → Iis|
214
176
152
0
0