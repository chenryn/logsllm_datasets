### Text Extraction Attack and Website Classification

Currently, text extraction attacks require a known background and a large 175pt font. Our website classification experiments assume a simple scenario where a user is statically viewing a webpage. We leave the task of achieving website classification in the presence of user interaction (such as active scrolling) for future work.

### Granularity

Our attacks detected information at a coarser resolution than individual pixels. The required bandwidth for detecting individual pixels far exceeds the acoustic transmission properties of air. Modern screens render pixels at over 100 MHz, whereas sound propagation in the air above a few hundred kHz has a very short range due to attenuation and distortion effects. This affects the type of screen content that can be distinguished. For example, our text extraction (Section V) works on large fonts. Similarly, on-screen keyboard snooping (Section IV-B) is more accurate in portrait orientation, where coarse pixel line granularity suffices.

### Attacker Sample Rate

In Sections IV-B through VI-A, we exploit a carrier signal at 32 kHz. To carry out these attacks, the attacker’s sample rate must be at least 64 kHz (due to the Nyquist limit, and assuming that aliasing is eliminated by hardware filters). While modern commodity hardware often samples at 96 kHz (as demonstrated in Sections III-B, IV-B, and VI-A using a mobile phone), low-end attackers recording at lower rates might be limited to the remote attacks demonstrated in Section VI-B.

### Accuracy Depends on Microphone Distance and Screen Model

The quality and extractability of the leakage signal vary significantly with the microphones' proximity to the screen (see Figure III.2) and the screen's make and model (see Figure II.3). However, even relatively noisy signals acquired at a distance (Section VI-A) or signals passed through a lossy codec (Section VI-B) can be used to mount an attack. The deterioration of the underlying signal with distance is analyzed in Appendix D.

### Mitigations

#### Elimination
An obvious remedy to such leakage is for computer screen manufacturers to more carefully evaluate their designs to minimize "coil whine" and similar electronic component vibrations within screen circuitry. The ubiquity of leakage across manufacturers and models (Figures II.3, III.2, and III.3 demonstrate leakage in Dell, Soyo, Apple, Philips, HQ, BenQ, and Samsung; attacks were simulated on various Dell and Soyo screens in Sections IV through VII) suggests that this may be difficult or costly.

#### Masking
Acoustic noise generators can be used to mask the signal, but this comes at a cost in design, manufacturing, and ergonomic disruption (some of the exploitable signal lies within the human-audible frequency range). The masking should have adequate energy and spectrum coverage to reduce the signal-to-noise ratio by orders of magnitude because the leakage signal is retransmitted 60 times per second, offering high redundancy.

#### Shielding
Acoustic shielding of screens may reduce the leakage amplitude but is difficult to achieve while maintaining adequate air circulation for cooling. For microphones built into screens, a sound-absorbing barrier may reduce microphone pickup of internally-generated sounds (but would not affect external microphones). In cases where there is an electromagnetic contribution to the leakage (see Section II-B), corresponding shielding would also be desirable, though typically expensive.

#### Software Mitigations
A more promising approach to mitigating the attacks presented in this paper is software countermeasures. Variations on software mitigations to the EM Tempest attack, which change on-screen content to mask the leakage, such as font filtering [34], can be considered. Additionally, because our extraction attacks use mainly the aggregate horizontal intensity of pixel lines, while mostly losing the information inside individual lines, fonts can be changed such that all letters project the same horizontal intensity. Finally, our attacks heavily rely on neural network classifiers, which are vulnerable to inputs specifically crafted to mislead them [23], [46].

### Conclusion

We report a new physical side-channel leak: acoustic leakage of screen content. We suggest powerful attacks that extract highly precise information, such as on-screen text and on-screen keyboard presses. This leakage is uniquely dangerous because even weak attackers, who only receive encoded audio traces from legitimate communication channels, and attackers with no access to the victim’s physical screen, can exploit it. We demonstrate this by successfully simulating highly precise content extraction and identification attacks across an array of setups, as well as a simple but well-motivated attack scenario: exploiting an open Hangouts connection to deduce what on-screen activity a party to the call is involved in. This is the first demonstrated attack using codec-encoded acoustic emanations from non-mechanical peripherals, for which users do not have a reason to suspect acoustic leakage would even exist.

### Acknowledgments

Roei Schuster and Eran Tromer are members of the Check Point Institute for Information Security. This work was supported by the Blavatnik Interdisciplinary Cyber Research Center (ICRC); by the Check Point Institute for Information Security; by the Defense Advanced Research Project Agency (DARPA) and Army Research Office (ARO) under Contract #W911NF-15-C-0236; by the Israeli Ministry of Science and Technology; by the Leona M. & Harry B. Helmsley Charitable Trust; by NSF awards #CNS-1445424 and #CCF-1423306; by the 2017-2018 Rothschild Postdoctoral Fellowship; and a gift from Intel. Any opinions, findings, and conclusions or recommendations expressed are those of the authors and do not necessarily reflect the views of ARO, DARPA, NSF, the U.S. Government, or other sponsors.

### References

[References list remains unchanged]

### Appendix

#### A. Our Trace Chunking Algorithm

1. **Algorithm in Detail:**
   - The algorithm initiates an empty collection of chunks.
   - It searches for the first two consecutive chunks whose sizes are in G and whose correlation is higher than the threshold.
   - One of these chunks is set as the first, master chunk, and added to the collection.
   - Starting from the position after the added chunk, it searches for the next chunk size in G such that the correlation with the master chunk is higher than the threshold, and adds it to the collection.