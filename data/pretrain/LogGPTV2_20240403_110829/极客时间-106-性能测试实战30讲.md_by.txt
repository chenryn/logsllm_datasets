#   36 0x3B44178A8B9CE1C3     20.1134  0.0%    16  1.2571  0.04 INSERT    
#   39 0x370753250D9FB9EF     14.5224  0.0%    11  1.3202  0.04 INSERT    
# MISC 0xMISC               2152.2442  0.8%   151 14.2533   0.0 你可以看到确实有四个 SQL消耗了更多的时间，并且时间还不短。这是明显的性能问题，但是我把这 SQL拿出来执行过呀，并不慢。怎么回事呢？我让做数据库运维的人把 DB proxy 层的所有 SQL日志拿出来分析一遍。为什么我要 DB proxy层的数据呢？因为这一段会把所有执行的 SQL 都记录下来，而慢日志记录的是 1s以上的（取决于 DB 中的配置）。首先是把 time cost 大于 200ms 的 SQL都拉出来，结果发现，真的在 TPS 下降的那个时间段，出现了 SQL执行超长的情况，并且和我执行的，还是同样的业务SQL。 怎么办？既然到这个层面了，这些执行的 SQL只有一点区别，那就是查询条件。慢的 SQL的查询条件，我拿回来试了，果然是慢，查出来的数据也是完全不一样的，居然能查出几万条数据来。前面说了，这个语句是根据客户ID 查出记录数的，那么就根据客户 ID，做一次 groupby，看下数据量为啥有这么多大差别。于是得到了如下的结果：    客户ID, 数量    '这一列只是客户id，无它', '91307'    '这一列只是客户id，无它', '69865'    '这一列只是客户id，无它', '55075'    '这一列只是客户id，无它', '54990'    '这一列只是客户id，无它', '54975'    '这一列只是客户id，无它', '54962'    '这一列只是客户id，无它', '54899'    '这一列只是客户id，无它', '54898'    '这一列只是客户id，无它', '54874'    '这一列只是客户id，无它', '54862'    ....................    '这一列只是客户id，无它', '161'    '这一列只是客户id，无它', '161'    '这一列只是客户id，无它', '161'    '这一列只是客户id，无它', '161'    '这一列只是客户id，无它', '161'    '这一列只是客户id，无它', '161'    '这一列只是客户id，无它', '160'    '这一列只是客户id，无它', '160'从这个结果可以看到，不同客户 ID的记录条数差别太大了。这是谁干的好事？！我们一开始就强调数据需要造均衡，要符合生产真实用户的数据分布。到这里，问题基本上就明确了，查一下参数化的数据，里面有 10万条数据，而取到记录数在五六万左右的客户 ID的时候，才出现了响应时间长的问题。而我之前的执行的SQL，恰好试了多次都是数据量少的。下面怎么办呢？先做个最规矩的实验，把 5万条往后的数据全都删掉！场景再执行一遍。于是就得到了如下的结果：![](Images/cd25c2158872236352883c1d62ec7adb.png)savepage-src="https://static001.geekbang.org/resource/image/cb/3b/cbf4620fd4fb76e9a1862226da33253b.png"}问题完美解决。可是问题怎么出现的呢？经过询问负责产生基础数据的人，最后得知，一开始数据库里的基础数据不够。由于我在项目中要求基础数据量和参数化数据量要达到生产级别。于是把这个工作安排给了一个同事，就是造出每个客户都和生产环境中差不多量级的记录。当时是用压力脚本做客户ID的参数化，然后用执行压力的方式造的数据。本来这个事情在做的时候，应该是把每个客户 ID都加到差不多的记录的。但是这个人在做的时候，觉得一个个循环加下去实在是太消耗时间了，终于等不急了，于是在干了几个小时之后，觉得每个客户ID 上都有了一些数据量之后，自己做了个决定，把客户 ID减少到只有几百个，这样很快就干完了！哭笑不得的感觉有没有？！总结很多性能问题，在出现的时候，都会觉得无从下手，而当分析到根本原因的时候，就觉得啼笑皆非。但很多时候，在真实的场景中，很多性能问题连原因都没有分析出来，连啼笑皆非的机会都没有，就开始寻找规避的手段了，这就像用一个坑去埋另一个坑，于是大坑套小坑、小坑套水洼。还有，在做性能分析的时候，有经验固然是好事，但是经验也并不是在所有的场景中都能有效地帮你解决问题，相反，它们有时也会成为累赘，成为判断出现偏差的原因。所以我现在都会诚心地告诫一些性能测试从业人员：一定要全局监控、定向监控一层层数据查，不要觉得查了某个点就判断这个组件没问题了。像我这样的老鸟也照样得从全局查起，不然也是掉坑里。而这个"全局 -定向"的思路，也照样适用一些新手，可以形成排查手册。在我带过的项目中，我经常会讲这样的思路，制作排查手册（因为每个项目用的东西都会有些区别），而这些思路和排查手册，现在就变成了你一篇篇看过的文章。所以我希望看专栏的人都能知道真正的分析性能瓶颈的过程是什么样子。不要在意自己现在会什么，要多在意以后会什么。问题讲完了今天的内容，你能说一下为什么通过抓包可以判断出响应时间的拆分吗？以及，数据分布不均衡还会带来哪些性能问题？欢迎你在评论区写下你的思考，也欢迎把这篇文章分享给你的朋友或者同事，一起交流一下。