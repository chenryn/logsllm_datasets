### Apache Airflow version
2.3.0 (latest released)
### What happened
The unique ID of the task is seemingly not calculated correctly in base.py and
it can cause in a duplicate key error, my guess is that this bit from
/decorators/base.py:115:
    if tg_task_id not in dag.task_ids:
        return task_id
doesn't make any sense and the actual return should be:
    if tg_task_id not in dag.task_ids:
        return tg_task_id
But I didn't write it so there is maybe a reason down the line for `return
task_id`. Someone that does know his way around TaskFlow's codebase should
pitch in.
### What you think should happen instead
task.expand should not lead to a airflow.exceptions.DuplicateTaskIdFound
inside task groups.
### How to reproduce
Pick example_task_group_decorator.py, change it so that task_1 returns a list,
and call task_2 with `.expand(value=task_1)`.
A modification as simple as this will already kill the DAG:
    #
    # Licensed to the Apache Software Foundation (ASF) under one
    # or more contributor license agreements.  See the NOTICE file
    # distributed with this work for additional information
    # regarding copyright ownership.  The ASF licenses this file
    # to you under the Apache License, Version 2.0 (the
    # "License"); you may not use this file except in compliance
    # with the License.  You may obtain a copy of the License at
    #
    #   http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing,
    # software distributed under the License is distributed on an
    # "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
    # KIND, either express or implied.  See the License for the
    # specific language governing permissions and limitations
    # under the License.
    """Example DAG demonstrating the usage of the @taskgroup decorator."""
    import pendulum
    from airflow.decorators import task, task_group
    from airflow.models.dag import DAG
    # [START howto_task_group_decorator]
    # Creating Tasks
    @task
    def task_start():
        """Empty Task which is First Task of Dag"""
        return '[Task_start]'
    @task
    def task_1(value: int) -> list[str]:
        """Empty Task1"""
        return [f'[ Task1 {value} ]', f'[ Task1 {value+1} ]']
    @task
    def task_2(value: list[str]) -> str:
        """Empty Task2"""
        return f'[ Task2 {value} ]'
    @task
    def task_3(value: str) -> None:
        """Empty Task3"""
        print(f'[ Task3 {value} ]')
    @task
    def task_end() -> None:
        """Empty Task which is Last Task of Dag"""
        print('[ Task_End  ]')
    # Creating TaskGroups
    @task_group
    def task_group_function(value: int) -> None:
        """TaskGroup for grouping related Tasks"""
        task_3(task_2.expand(value=task_1(value)))
    # Executing Tasks and TaskGroups
    with DAG(
        dag_id="example_task_group_decorator",
        start_date=pendulum.datetime(2021, 1, 1, tz="UTC"),
        catchup=False,
        tags=["example"],
    ) as dag:
        start_task = task_start()
        end_task = task_end()
        for i in range(5):
            current_task_group = task_group_function(i)
            start_task >> current_task_group >> end_task
    # [END howto_task_group_decorator]
### Operating System
Manjaro Linux
### Versions of Apache Airflow Providers
_No response_
### Deployment
Virtualenv installation
### Deployment details
_No response_
### Anything else
_No response_
### Are you willing to submit PR?
  * Yes I am willing to submit a PR!
### Code of Conduct
  * I agree to follow this project's Code of Conduct