利用整个行业范围内需要更易于消费的社交数据提供集体输入和知
识，Gmip作为"漏斗”，接收的是很多不同的协议和格式，而输出的
是一致、异构的数据，并提供了对数据更便捷的访问方式。
数据的商业价值
关于开源软件是好是坏的争论基本结束。企业何时对其软件或者是
部分软件进行并源，何时不能并源，有很清晰的界限。总体来说，
如果你的软件享有“独一无二”的知识产权，把你和外界的其他方面
分离开，你应该考虑不把它开源。否则，它就可以作为开源，这样
开源社区可以在代码中涵盖其经验和专业知识，为全世界作出责
献。遗憾的是，软件开源而言的数据相对决策框架还不够成熟。
API的爆炸使得数据发布商措手不及，因此，他们对数据价值的理
解变得糊涂得一文不值。
一些传统的内容发布商已经强化了其数据的价值。提供免费的周刊
来提供内容，包含广告商支持内容（评论）和产品（杂志）的生
成。一些贸易杂志收取订阅金，不加入广告模式。Internet上的传统
的媒体/内容发布商主要采取广告模式来支持他们的数据（内容）的
分布。然而，通过API访问社交数据没有成熟的模型。提供商是否
需要为数据本身的访问收费，还是一切都免费？除非你是一个
“freegan”（反消费者），否则以上问题没有一个有明确的答案。除
非谈及的数据存在内在价值，否则对其评价变得非常困难和曲折。
如果你作为数据使用者，为了购买微博客消息，是否应该花费0.01
美元？这个消息是否应该获得许可，或者访问方式是否应该被租
用？数据项的价值和对它在转换处理之间的区别并始变得很明显。
用户在发布商的服务上真正去生成内容，是否应该获得其中收益的
一部分？从刚开始，谁是真正的数据拥有者？正如你所见的，这里
充斥着很多这样的问题，它们没有明显的答案。
1468
---
## Page 1470
当出现了社交数据，在该行业中，一些发布商会声称他们的数据是
无价的，而另一些则认为数据是免费的。数据使用者已经潜意识地
相信绝大多数的数据是免费的。因此，如果真的对社交数据进行标
价，他们便会发展成价值链切实的一部分。
公共的与私有的
有些数据被认为是公共的，而其他数据则被认为是私有的。公共和
私有这二者之间的区别是通过提供数据的服务来定义的，而且通常
是通过给定服务的《服务条款》来概括的。虽然对这二者的社会理
解及其本身是很有意思的话题，但是我在这部分将考虑访问这二者
的技术上的一些隐式问题。
让我们从两个当中更简单的公共数据说起。访问公共数据相对来说
比较简单。今天绝大多数的数据API是通过未授权的REST接口来访
问的。这意味着在网络上它们和其他的URL并没有什么区别，它们
可以很容易被任意用户和应用程序利用。访问这些API终端需要很
少的身份验证形式，如果有的话，而且对API用户的授权通常是通
过不透明的方式在幕后实现处理的。两种更丰富的验证方式是使用
HTTPBasic-Auth和嵌入在URL中的"API关键字”。这两种方式都允
许API服务基于身份验证证书来控制对数据和API功能的访问。令人
惊讶的是，这两种方式和HTTP都能工作很好。不考虑对公共数据
的API访问是否需要任何身份验证，底层的社交数据在绝大多数情
况下仍然是“公共的”。
私有数据带来了很多麻烦。由于越来越多的应用并始利用通常被认
为“私有”的其他应用的数据，这需要控制终端用户的访问。数据提
供商还使用各种技术，在访问权限控制中叠加上自已的观点意见。
这些技术都使得私有数据的聚集访问方式变得异常复杂。
保证终端用户数据在存储角度是受到保护的，这仅仅是挑战的一部
分。存储余和加密技术允许应用“蓬勃发展”，通常不需要考虑用
户数据的去失和折中方案。实际上，用户对应用程序很放心，为了
允许更深层的AP集成，他们免费提交用户名和密码到第三方应用
程序。这种做法实际上非常不安全，但是它说明了用户为了获得他
们期望的功能，甘愿牺牲其隐私信息。有两种有效可选的方案用于
分享私人登录证书：OAuth和BlindURL。
1469
---
## Page 1471
OAuth(http：//oauth.net/）提供了简单的解决方案来允许各种服务之
间进行交互，所有这些交互都给终端用户在他们的信息上提供了最
终的权限控制权，而不需要和第三方透露他们的用户名和密码。交
互程序把用户交给其期望的集成点，询问用户是否允许集成服务所
请求的访问权限控制。如果终端用户赞成该交互，两个服务之间就
共享一个令牌（Tken)，而且用户也可以选择撤销服务的访问权限许
可。
BlindURL是在服务和用户之间共享信息的更简单的方式，但是它们
在技术上还不够“安全”，因此它们通常都没有什么可信度。Flickr的
“GuestPass"共享功能能够巧妙地利用盲目的URL来允许用户和那些
没有Flickr账号的用户分享“私有”的照片，因此，这些用户不属于
Flickr用户的“朋友"或者“家族”。BlindURL为了使用服务来获取URL
的使用许可，它不需要用户做出任何额外的工作，但是它们从技术
上能够猜测出来，这会带来私有信息泄露的隐患。
Gnip当前只处理公共的数据。对于公共的和私有的边界访问控制必
须提供给终端用户，而且当讨论中间基础设施时，它并非总是很清
晰的。例如，你不知道也不关心公司采用什么样的通信路由服务信
用卡来保证金融交易，而对于谁能够访问你的假期照片的访问权限
的控制却是至关重要的。Gmip正在努力在公共数据和私有数据之间
画线，以及它最终如何为私有数据提供如公有数据一样的服务支
持。
结束语：通过Gmip思考
每天“涵涌”的数据“浪潮"把更多的异构API"拍上海岸”，而在这些
API中，必须保证数据的一致性。作为面向消息的中间件服务，
Gnip公司承诺使用中间数据代理的方式来“传送Web数据”。这意味
着该数据发布商期望通过很多内部的传输协议来分享这些数据，
Gnip从发布商获取规范化的数据，并实时地传送给Gnip用户（从消
息接收到重播时间延迟低于60秒）。不考虑内部的数据格式不一
致，Gmip把数据“清洗"并“规范化"成标准的格式作为服务提供给
Gnip用户。其结果是只使用Gnip的单点集成，就可以为其他应用提
供一致的、格式化的数据。
你可以通过Gnip一个接口来访问很多的社交数据API，且都是“实
时"地。Gmip的框架主要采用之前所述的事件模型，为了促进网络
和应用之间总体上更高效的数据流。然而，它也支持轮询方式。把
1470
---
## Page 1472
基于轮询的应用切换到基于事件的模式来最大化利用Gmip提供的规
范化的数据的优点，而通过手工处理将很麻烦。如果不是同步，那
么完全采取尚待完善的发布/订阅框架和格式一致性标准，采取中间
代理是很有必要的。
当前的基础设施在推进事情进展方面已经做了很多工作，而且网上
贸易已经蓬勃发展。然而，不断改变用例和终端用户需求使得和当
前框架保持一致会使我们受到一些局限。实时社交数据的需求要求
在构建我们的应用的底层控制流上做出修改。我很期望看到基于事
件的架构可以扩展到整个Web。
第9章探寻DeepWeb
AlonHalevy和IJayantMadhaven
什么是DeepWeb
“DeepWeb”（深网）指的是隐藏在HTML表单后的Web内容。为了
获取这些内容，用户必须提交包含有效值的表单。例如图9-1的商店
定位表单，搜索邮编为94043的商店，可以得到一个包含了商店列
表的Web页面。该结果页面即为DeepWeb的Web页面的一个例子。
tore Jocato
图9-1：Borders商店定位表单和提交特定表单得到的DeepWeb结
果页（见彩图21）
DeepWeb被公认为是搜索引擎在覆盖率上存在的一个很大空白。这
是因为搜索引擎通过Web爬虫(cawler)来发现页面，并在索引中包含
这些页面，从传统意义上来说，这些Web爬虫仅仅依赖于Web页面
的超链接来发现新的Web内容。它们缺乏自动提交表单的能力，因
此在表单后的Web页面无法被搜索引擎索引。包含表单的页面通常
对表单后的页面内容包含很少；因此，对于普通的用户，只有当他
1471
---
## Page 1473
们已经知道相应的HTML表单或者搜索引擎以某种方式将他们引导
至该表单，这些用户才能够发现这些DeepWeb内容。事实上，Deep
Web（也称"不可见网络"（IvisibleWeb)或者“暗网"（HddenWeb)）的
名字正是基于以下观察一Web用户无法通过搜索引擎简单地访问
这些内容。
很多文章认为DeepWeb拥有的数据比现在可搜索的WWW要多得多
(Brgman2001，He2007，Raghavan 2001）。我们最近的研究
(Mdhavan2007）估计，存在儿十万包含潜在有用的deep-web内容的
HTML表单，而且DeepWeb涵盖的范围跨越了每个可以想象的领
域。这些流行的领域包括二手车销售、房地产清单、公寓租赁、求
职、产品和食品食谱。有很多表单可以访问政府或者公共部门信
息，比如法律法规、法院裁决、环境报告等。还有些表单可以让用
户搜索更加深层的内容，如绿荫树、去公园的打车费、马雕像等。
当考虑DeepWeb时，我们必须记住HTML表单适用于Web中的各种
任务，但不是所有表单都可以访问deep-web内容。例如，要求输入
用户名和密码的登录表单、提交用户输入到论坛和博客的反馈表
单、执行购买的购物车等，这些表单需要获取用户的私有信息或者
导致后台状态改变，因此不属于DeepWeb的一部分。相反，我们主
要考虑那些允许用户匿名搜索信息的表单。
由于deep-web内容的本质特征和数量规模，很自然地，搜索引擎会
希望在它们的Web索引中包含这些内容。这样，搜索引擎才可以向
用户展现这些新的内容，反之亦然。因此，无论在学术领域还是工
业领域，人们对如何提供访问deep-web内容的问题都很感兴趣。但
是，很大一部分的研究和技术将重点放在了如何在某些狭窄的领域
来解决这个问题。这种做法最显著代表是垂直搜索引擎，每个都是
专注于某个狭窄领域的内容。例如，二手车搜索和求职搜索网站允
许用户从单一门户网站搜索很多底层的站点。这种策略虽然可以访
问一部分DeepWeb内容，但是其可达的范围非常有限，并且忽略了
大量不适合于这些狭义领域的基于表单的网站。
我们的目标是为通用搜索引擎用户提供DeepWeb访问方式。从搜索
引擎的角度，我们希望包含很大规模的DeepWeb内容，即能够访问
尽可能多的上千万的HTML表单。因此，我们需要一个解决方案可
以在所有可能的语言和领域工作，而且不需要人工监督，即一个完
全自动化的策略。从deep-web站点主机(hst)角度考虑，该策略不应
1472
---
## Page 1474
该过度使用站点宿主的资源；换句话说，该策略只应该驱动那些真
正相关的用户流量到该网站。
在这一章，我们将概述一个满足上述标准的解决方案。该方案名称
是探寻(srfacing)，对于每个HTML表单，预计算一组查询，这组查
询可能能够从深层站点中返回有用的内容。从每个预计算的查询中
汇集URL，再把这些URL插入到搜索引擎的索引。从高层上看，我
们的方法解决了两个挑战：一是在向一个表单提交查询时，决定需
要填写哪些表单输入框；二是找到合适的值来填写这些输入框。在
核心上，该方法依赖于通过智能选择的样本查询来探测HTML表
单，然后分析检索到的Web页面的区别。该策略虽然简单优雅，却
是非常高效的，而且可以有效地为Web搜索用户提供很大一部分
DeepWeb内容。我们的搜寻策略可以应用于Web中任何使用get方法
（在本章后面会概述）的HTML表单。这主要是为了排除一些我们
不希望爬虫去抓取的表单，比如需要用户信息的表单或者是产品购
实结果表单，这些表单通常使用post方法，
我们的deep-web探寻系统已经部署到G公司的搜索引擎上。该系统
成功地抓取了儿百个领域下的数百万个站点。目前，在G公司的网
站上，每秒有超过1000个的查询，在首页结果中能够看到一条来自
DeepWeb的搜寻结果。总体来说，搜索引擎用户发现这些结果和普
通的搜索结果一样有用。关于该解决方案更详细的探讨和实验分析
请参考(Mdhavan2008）和(Mdhavan2009）。
在本章的剩余部分，我们首先探讨访问deep-web站点的其他可选方