max
We can bound the above if we replace natural numbers with
real numbers, resulting in
SSσ,b(ˆxλp) 
20κ(− ln δ)1.5 exp(−1)G−1
−2pmax ln pmax
ns (1 − β)
.
Fig. 7.
Inﬂuence of global parameters on the improvement factor.
B. Private Choice of Parameters
The parameters required as input in Mechanism 1 are 1,
2, δ, m and r. For reasons of privacy, the choice of these
parameters cannot be based on optimization on a particular
input dataset. We therefore discuss some heuristic choices
for these parameters based on our experiments above. The
parameters  = 1 + 2 and δ can be chosen in the standard
way. For instance,  = 1 and δ = n−2. From Tables I and II,
a value in the range 0.8 to 0.9 is a reasonable choice for 1.
Note that 2 is readily determined by  and 1. From the same
tables, we see that an r between 1 and 2 sufﬁces. We therefore
discuss heuristics for choosing m.
Heuristics for Selecting the Time Lag m: We specify two
criteria that should be satisﬁed by the time lag. By assigning
reasonably conservative (with respect to utility guarantees)
values to the free parameters in the two criteria, we obtain a
value of m that is expected to provide good utility in practice.
With β = 0.02, δ = 2−20,  = 1 and pmax = 0.005, we
ﬁnd that m should be at least 20,000 in order to satisfy the ﬁrst
criterion. The second criterion imposes m > 80, 000 for good
utility. From Tables I and II we see that with m > 80, 000 we
indeed obtain good utility. Of course, the higher the time lag
m, the better the utility gain, with the trade-off that there is a
longer time lag before we output the sum.
VII. EXPERIMENTAL EVALUATION
A. Accumulated Error on the Sum
We now show the improvement factor in computing the
moving average (sum) through our mechanism. Since the error
is maximized at step n, i.e., the last observation of the stream,
we compare the value of ˆc(σ, n) through our mechanism
against its counterpart via the BT algorithm. For both datasets,
we run the two mechanisms a total of 20,000 times and display
the empirical probability density function (PDF) of error.
11If the time lag is small, the observations will be sparsely distributed
implying a large scale of smooth sensitivity.
10
1) Train Trips Dataset: We ﬁxed  = 1, δ = 2−20, β =
0.02, m = 50, 000 and n = 25, 000, 000, and obtained the
values of the local parameters after optimization, shown in
Table I. We set B = 1440 minutes, which is the maximum
possible commute time in a 24 hour period. Figure 8 shows
the PDF of the resulting error (normalized by the maximum
value B) of our mechanism and the BT algorithm. We see that
the error in our case is more tightly concentrated around 0. On
average, we obtain an improvement factor of 3.5.
better than the BT algorithm, with an improvement factor of
9 on average.
Fig. 10. PDF of the error on the supermarket dataset through our mechanism
and the BT algorithm.
For this dataset as well we are interested in knowing
whether the estimated error due to outliers is well below the
actual error. Figure 11 shows that the dataset does indeed have
a light-tailed distribution with the actual error being almost
always below the estimated value.
Fig. 11. Distribution of the outlier error ratio: (real error)/(estimated error)
on the supermarket dataset. Once again our estimated outlier error is close to
the real outlier error.
B. Does the Distribution Remain Light-Tailed across Time?
Recall that our mechanism promises improved utility based
on the premise that data distribution is light-tailed. Since
the input stream is time dependent, the estimated threshold
(using the λp-quantile) through m observations with a given
time period may be drastically different from its estimate
via a different time period. To ensure that this is not the
case, we analyzed the distribution of the train trips dataset
across different hours and different days of the week. The
distributions are shown in Figures 12 and 13, respectively.
While the beginning of the distributions show variation based
on the time period, the tails are similar and light-tailed. Thus,
our estimated threshold is likely to improve utility independent
of the time period in real datasets.
VIII. RELATED WORK
As previously noted, the privacy-preserving algorithms for
continual release of statistics from binary streams proposed
Fig. 8.
and the BT algorithm.
PDF of the error on the train trips dataset through our mechanism
We are also interested in knowing whether our estimation
of the outlier error (i.e., the second summand in Eq. 16), is
close to the actual outlier error. This will validate whether our
assumption that the distribution of the dataset is light-tailed.
To verify this we re-ran our mechanism 20,000 times on the
estimated error with the same
same dataset and obtained the ratio
parameters as above. Figure 9 shows that we have erred on the
precautionary side with our estimation of outlier error being
well within the actual error.
real error
Fig. 9. Distribution of the outlier error ratio: (real error)/(estimated error)
on the train trips dataset. Our estimated outlier error is well below the real
outlier error.
2) Supermarket Dataset: For the supermarket dataset, we
use the same set of parameters except that we have n =
150, 000 (due to less data points) and B = 3, 000 dollars (a
conservative guess on the amount spent). Figure 10 shows the
PDF of the error from our mechanism and the BT algorithm.
Once again the error through our mechanism is more tightly
concentrated around 0. For this dataset, we perform much
11
As argued before, privacy-preserving continual release of
the sum is only one example of functions that can be released
with improved utility through our mechanism. As long as the
target function remains a function of the stream, has reduced
sensitivity based on tighter concentration of input data, and
the error due to outliers can be bounded and related to the
p-quantile, we can adapt all the steps of our method to the
given function. This allows us to estimate the threshold from
the data, thus ﬁnding the optimum balance between the error
due to symmetric noise and the error due to outliers. Examples
of such functions include the sliding window average or the
decaying sum where either past observations are completely
discarded or are given progressively less weights [7]. Another
example is continually releasing histogram of the input stream
where we would like to completely discard bins above the
main concentration of the data.
Our work on estimating the threshold using the p-quantile
can be thought of as an exercise in ﬁnding “robust” statis-
tics [16] with differential privacy, a line of work that was
discussed in [17] and [18]. These works estimate the scale
of the input data with the help of the interquartile range using
the Propose-Test-Release approach [17]. Brieﬂy, this approach
checks whether a given analysis uses a function that is robust
or stable [9] on a given dataset or not. If the answer is no,
the analysis is abandoned. In other words, the interquartile
range may not even be released if it is not stable for the
given dataset. Our approach is different as we use the p-
quantile as the estimate of the scale of the input dataset,
and use smooth sensitivity to release it. Unlike the Propose-
Test-Release approach which may not release the p-quantile
depending on input data, we have the advantage that we
always obtain an estimate. This allows us to optimize utility
by bounding errors introduced by the estimation of the scale of
the dataset. We note that the problem of ﬁnding differentially
private quantiles is also tackled in [19], but the main ingredient
there is the exponential mechanism [20], and the context is
static datasets rather than continual release of data.
The main idea of our work is to reduce the sensitivity of
the query (in our case, the moving sum), by relying on some
initial knowledge of the input data. If we succeed in reducing
sensitivity, we signiﬁcantly reduce the scale of noise added
to the query, thus improving accuracy of the query answer. A
similar approach has also been used in some other works for
other query types or applications. In [21], the authors use prior
knowledge of the dataset to release time-series data with better
accuracy. The aforementioned approach is also used in [8]
where the aim is to display a differentially private histogram
by altering the size of the bins in order to artiﬁcially reduce
sensitivity.
IX. DISCUSSION
An interesting question to ponder is what kind of data
distributions are likely to have a light-tailed distribution. Look-
ing at the two datasets evaluated in this paper, we see that
one common characteristic is that they emerge from short-
lived, time-constrained events. Thus, more generally, streaming
data with short-lived events is likely to exhibit light-tailed
distributions. In addition to the two datasets used in this paper,
other examples of data exhibiting a light-tailed distribution
include smart meter-based energy readings data (e.g. electricity
Fig. 12.
Again all are light-tailed.
Train commute time distribution from different hours of the day.
Fig. 13. Train commute time distribution from different days of the week.
All are light-tailed.
in [4], [5] can be generalized to the scenario addressed in
this paper,
i.e., release of statistics from a stream whose
values are from the real interval [0, B]. Indeed, we have used
the algorithm from [5] as one of the components of our
method. However, the focus of the two works in [4] and [5]
is on improving the error for binary strings which do not
have the added factor of B. The two algorithms are based
on event-level privacy. As such, if the aim of privacy is to
protect all events from an individual (e.g., all trips made by
an individual over the course of the whole year), then the
privacy provided by these algorithms is insufﬁcient. The work
from [14] attempts to improve this by offering privacy for up
to w successive events. Noting that any w successive events
might not contain multiple events originating from a single
individual, the authors from [15] introduce l-trajectory privacy,
where any successive l events from a user are targeted for
privacy. These works essentially propose privacy mechanisms
for variants of the deﬁnition of differential privacy where
neighbouring streams are deﬁned differently from the standard
deﬁnition of Hamming distance. We note that our method can
be easily used in conjunction with these algorithms, as we only
use the BT algorithm from [5] in a modular way. However, to
ﬁnd a utility maximizing threshold in a differentially private
manner for any variation in the deﬁnition of neighbouring
streams requires tweaking our mechanism. Likewise, these
algorithms also target inﬁnite streams as opposed to bounded
streams (as is done in our paper). Application of our approach
to these settings is an interesting area for future work.
12
0255075100125150Time(minutes)0.000.010.020.03PDF0-4H4-8H8-12H12-16H16-20H20-24H[6] C. Dwork and G. J. Pappas, “Privacy in information-rich intelligent
[7]
[8]
infrastructure,” arXiv preprint arXiv:1706.01985, 2017.
J. Bolot, N. Fawaz, S. Muthukrishnan, A. Nikolov, and N. Taft,
“Private decayed predicate sums on streams,” in Proceedings of the
16th International Conference on Database Theory. ACM, 2013, pp.
284–295.
J. Xu, Z. Zhang, X. Xiao, Y. Yang, G. Yu, and M. Winslett, “Differen-
tially private histogram publication,” The VLDB Journal, vol. 22, no. 6,
pp. 797–822, 2013.
[9] S. Vadhan, “The complexity of differential privacy,” in Tutorials on the
Foundations of Cryptography. Springer, 2017, pp. 347–450.
[10] K. Nissim, S. Raskhodnikova, and A. Smith, “Smooth sensitivity and
sampling in private data analysis,” in Proceedings of the thirty-ninth
annual ACM symposium on Theory of computing. ACM, 2007, pp.
75–84.
[11] F. D. McSherry, “Privacy integrated queries: an extensible platform
for privacy-preserving data analysis,” in Proceedings of the 2009 ACM
SIGMOD International Conference on Management of data. ACM,
2009, pp. 19–30.
[12] S. G. Nash, “A survey of truncated-newton methods,” in Numerical
Analysis: Historical Developments in the 20th Century. Elsevier, 2001,
pp. 265–279.
[13] M. Gaboardi, J. Honaker, G. King, J. Murtagh, K. Nissim, J. Ullman,
and S. Vadhan, “Psi ({\Psi}): a private data sharing interface,” arXiv
preprint arXiv:1609.04340, 2016.
[14] G. Kellaris, S. Papadopoulos, X. Xiao, and D. Papadias, “Differentially
private event sequences over inﬁnite streams,” Proceedings of the VLDB
Endowment, vol. 7, no. 12, pp. 1155–1166, 2014.
[15] Y. Cao and M. Yoshikawa, “Differentially private real-time data release
over inﬁnite trajectory streams,” in Mobile Data Management (MDM),
2015 16th IEEE International Conference on, vol. 2.
IEEE, 2015, pp.
68–73.
[16] F. R. Hampel, E. M. Ronchetti, P. J. Rousseeuw, and W. A. Stahel,
John
Robust statistics: the approach based on inﬂuence functions.
Wiley & Sons, 2011, vol. 196.
[17] C. Dwork and J. Lei, “Differential privacy and robust statistics,” in
Proceedings of the forty-ﬁrst annual ACM symposium on Theory of
computing. ACM, 2009, pp. 371–380.
[18] C. Dwork and A. Smith, “Differential privacy for statistics: What we
know and what we want to learn,” Journal of Privacy and Conﬁden-
tiality, vol. 1, no. 2, p. 2, 2010.
[19] A. Smith, “Privacy-preserving statistical estimation with optimal con-
vergence rates,” in Proceedings of the forty-third annual ACM sympo-
sium on Theory of computing. ACM, 2011, pp. 813–822.
[20] F. McSherry and K. Talwar, “Mechanism design via differential pri-
vacy,” in Foundations of Computer Science, 2007. FOCS’07. 48th
Annual IEEE Symposium on.
IEEE, 2007, pp. 94–103.
[21] L. Fan, L. Xiong, and V. Sunderam, “Differentially private multi-
dimensional time series release for trafﬁc monitoring,” in IFIP Annual
Conference on Data and Applications Security and Privacy. Springer,
2013, pp. 33–48.
usage), phone call durations data, length of posts/comments on
online social networks (e.g., on the website Reddit), average
time spent on a given location, or daily average inter-arrivals
of check-in times (location-based networks). Consequently, the
resulting readings are bounded, even though the bound B
might be unknown in advance or only loosely known. These
are in contrast to heavy-tailed distributions where (underlying)
events are not short-lived or time-constrained, e.g., income
distribution, ﬁle sizes in computer systems, and network trafﬁc
over a long period of time.
We would like to stress that in case the input distribution
is not light-tailed, our estimated threshold τ would be closer
to the global bound B. Thus, in the worst case we would
be able to provide utility similar to the BT algorithm (with
the disadvantage that we add a time lag m). An example of
this is a uniform distribution over [0, B], where the threshold
τ would be close to B (estimated via the ﬁrst m readings).
Similar argument applies to other heavy-tailed distributions.
Also,
importantly, our privacy deﬁnition is not dependent
on the light-tailed distribution assumption. Thus, the privacy
guarantee remains the same regardless of the nature of the
input distribution.
X. CONCLUSION
We have presented a privacy-preserving mechanism to
continually display the moving average of a stream of ob-
servations where the bound on each observation is either too
conservative or not known a priori. We have relied on justiﬁed
assumptions on real-world datasets to obtain a better bound
on observations of the stream. Moreover, we have shown how
to obtain this bound in a differentially private manner while
optimizing utility. Our mechanism can be applied to many real-
world applications where continuous monitoring and reporting
of statistics is required, e.g., smart meter data and commute
times. Our techniques can be improved in several ways. We
have relied on the quantile to estimate the bound on the
streaming data based on smooth sensitivity. There may be other
ways to display the quantile using other robust statistics. Our
mechanism can be adapted to compute functions other than
the moving average. Likewise, our method can be used in
conjunction with algorithms that provide privacy for multiple
events instead of single events as is done in this paper. Overall,
we see our work as an instance of applying differential privacy
in practice.
REFERENCES
[1] A. Molina-Markham, P. Shenoy, K. Fu, E. Cecchet, and D. Irwin,
“Private memoirs of a smart meter,” in Proceedings of the 2nd ACM
workshop on embedded sensing systems for energy-efﬁciency in build-
ing. ACM, 2010, pp. 61–66.
[2] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise
Springer,
to sensitivity in private data analysis,” in TCC, vol. 3876.
2006, pp. 265–284.
[3] C. Dwork, A. Roth et al., “The algorithmic foundations of differential
privacy,” Foundations and Trends R(cid:13) in Theoretical Computer Science,
vol. 9, no. 3–4, pp. 211–407, 2014.
[4] C. Dwork, M. Naor, T. Pitassi, and G. N. Rothblum, “Differential
privacy under continual observation,” in Proceedings of the forty-second
ACM symposium on Theory of computing. ACM, 2010, pp. 715–724.
[5] T.-H. H. Chan, E. Shi, and D. Song, “Private and continual release
of statistics,” ACM Transactions on Information and System Security
(TISSEC), vol. 14, no. 3, p. 26, 2011.
13