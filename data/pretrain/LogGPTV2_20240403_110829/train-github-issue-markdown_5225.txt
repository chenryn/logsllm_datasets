## üêõ Bug
I noticed that my generated JIT was creating two variables with the exact same
parameters.
Also: Simply deleting the duplicated lines makes everything faster.
## To Reproduce
Python:
    for (x, l, c) in zip(sources, self.loc, self.conf):
            conf.append(c(x).permute(0, 2, 3, 1).contiguous().view(c(x).size(0), -1, self.num_classes))
            loc.append(l(x).permute(0, 2, 3, 1).contiguous().view(l(x).size(0), -1, 4))
JIT:
      _78 = torch._convolution(input64, weight56, _66, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _79 = torch._convolution(input64, weight56, _66, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _80 = ops.prim.NumToTensor(torch.size(_79, 0))
      _81 = torch.contiguous(torch.permute(_78, [0, 2, 3, 1]))
      _82 = torch.view(_81, [int(_80), -1, 2])
      _83 = torch._convolution(input64, weight53, _59, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _84 = torch._convolution(input64, weight53, _59, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _85 = ops.prim.NumToTensor(torch.size(_84, 0))
      _86 = torch.contiguous(torch.permute(_83, [0, 2, 3, 1]))
      _87 = torch.view(_86, [int(_85), -1, 4])
      _88 = torch._convolution(input70, weight57, _68, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _89 = torch._convolution(input70, weight57, _68, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _90 = ops.prim.NumToTensor(torch.size(_89, 0))
      _91 = torch.contiguous(torch.permute(_88, [0, 2, 3, 1]))
      _92 = torch.view(_91, [int(_90), -1, 2])
      _93 = torch._convolution(input70, weight54, _61, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _94 = torch._convolution(input70, weight54, _61, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _95 = ops.prim.NumToTensor(torch.size(_94, 0))
      _96 = torch.contiguous(torch.permute(_93, [0, 2, 3, 1]))
      _97 = torch.view(_96, [int(_95), -1, 4])
      _98 = torch._convolution(input76, weight58, _70, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _99 = torch._convolution(input76, weight58, _70, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _100 = ops.prim.NumToTensor(torch.size(_99, 0))
      _101 = torch.contiguous(torch.permute(_98, [0, 2, 3, 1]))
      _102 = torch.view(_101, [int(_100), -1, 2])
      _103 = torch._convolution(input76, weight55, _63, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _104 = torch._convolution(input76, weight55, _63, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _105 = ops.prim.NumToTensor(torch.size(_104, 0))
      _106 = torch.contiguous(torch.permute(_103, [0, 2, 3, 1]))
      _107 = [_87, _97, torch.view(_106, [int(_105), -1, 4])]
See _78, _79 and _83,_84 for example.
Simplified code:
      _78 = torch._convolution(input64, weight56, _66, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _batch = int(ops.prim.NumToTensor(torch.size(_78, 0)))
      _81 = torch.contiguous(torch.permute(_78, [0, 2, 3, 1]))
      _82 = torch.view(_81, [_batch, -1, 2])
      _83 = torch._convolution(input64, weight53, _59, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _86 = torch.contiguous(torch.permute(_83, [0, 2, 3, 1]))
      _87 = torch.view(_86, [_batch, -1, 4])
      _88 = torch._convolution(input70, weight57, _68, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _91 = torch.contiguous(torch.permute(_88, [0, 2, 3, 1]))
      _92 = torch.view(_91, [_batch, -1, 2])
      _93 = torch._convolution(input70, weight54, _61, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _96 = torch.contiguous(torch.permute(_93, [0, 2, 3, 1]))
      _97 = torch.view(_96, [_batch, -1, 4])
      _98 = torch._convolution(input76, weight58, _70, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _101 = torch.contiguous(torch.permute(_98, [0, 2, 3, 1]))
      _102 = torch.view(_101, [_batch, -1, 2])
      _103 = torch._convolution(input76, weight55, _63, [1, 1], [1, 1], [1, 1], False, [0, 0], 1, True, False, True)
      _106 = torch.contiguous(torch.permute(_103, [0, 2, 3, 1]))
      _107 = [_87, _97, torch.view(_106, [_batch, -1, 4])]
## Expected behavior
Only a single convolution
## Environment
Please copy and paste the output from our  
environment collection script  
(or fill out the checklist below manually).
You can get the script and run it with:
    wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py
    # For security purposes, please check the contents of collect_env.py before running it.
    python collect_env.py
  * PyTorch Version (e.g., 1.0): 1.2.0
  * OS (e.g., Linux): Linux
  * How you installed PyTorch (`conda`, `pip`, source): pip
  * Build command you used (if compiling from source): N/A
  * Python version: 3.6
  * CUDA/cuDNN version: 10.0/7.5
  * GPU models and configuration: Titan V
  * Any other relevant information: