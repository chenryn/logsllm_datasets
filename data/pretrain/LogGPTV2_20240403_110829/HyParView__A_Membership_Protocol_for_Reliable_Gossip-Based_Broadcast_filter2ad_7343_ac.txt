### 5.2. Effect of Failures

We first evaluate the impact of massive failures on the reliability of gossip protocols when different membership protocols are used. In each experiment, all nodes join the overlay and execute 50 cycles of the membership protocol to ensure stabilization. After this stabilization period, we randomly induce failures in a specified percentage of nodes, ranging from 10% to 95%. We then measure the reliability of the protocol by sending 1,000 messages from random correct nodes before the next cycle of the membership protocol. Although Scamp does not require this stabilization time, as it stabilizes immediately after the join period, the membership protocols still perform all reactive steps, including excluding failed nodes from their partial views.

**Figure 2: Reliability for 1,000 Messages**

The average reliability for these runs of 1,000 messages is shown in Figure 2. As can be seen, HyParView maintains high reliability even with up to 90% node failures. Even at 95% failure rates, HyParView delivers messages to approximately 90% of the active processes. Scamp and Cyclon exhibit constant reliability for failure percentages as low as 10%, but their performance significantly degrades above 50% (with reliabilities below 50%). CyclonAcked, however, offers competitive performance, maintaining high reliability for failure rates up to 70%. This highlights the importance of fast failure detection in gossip protocols. HyParView's superior reliability, even at lower failure rates, is due to its deterministic selection of nodes for forwarding gossip messages, combined with a symmetric view, ensuring 100% reliability in a stable environment as long as the overlay remains connected.

**Figures 3a-3f: Reliability Evolution After Failures**

Figures 3a-3f show the evolution of reliability with each message sent after the failures, for different failure percentages. In all figures, HyParView typically recovers faster and closer to 100% reliability. CyclonAcked, Cyclon, and Scamp follow in that order. Above 80% failures, the reliability of all protocols drops close to 0%.

From the figures, it is clear that HyParView recovers almost immediately from failures because all members of the active views are tested in a single broadcast. Basic Cyclon and Scamp, lacking a failure detector, do not recover until the membership protocol is executed again. To maintain reliability under high failure rates, they would need very high fanouts, which is inefficient in steady state. Adding acknowledgments to Cyclon (CyclonAcked) allows it to recover high reliability after a small number of message exchanges (approximately 25). However, for 80% or higher failure rates, CyclonAcked cannot match HyParView's reliability. This is due to the asymmetric nature of the Cyclon overlay, where some nodes may have outgoing links but no incoming ones, leading to nodes that can broadcast but not receive messages. In contrast, HyParView's symmetric active membership ensures that if a node can reach another correct node, it is also reachable by messages from other nodes, contributing to its high resilience.

### 5.3. Healing Time

**Figure 4: Healing Time**

Figure 4 shows the number of membership cycles required to achieve the same reliability in message dissemination after a massive node failure for different failure percentages. In each simulation, after the stabilization period, failures are induced, followed by multiple membership protocol cycles. In each cycle, 10 random nodes are selected to execute a broadcast. The average reliability of these messages is calculated, and the cycles required for each protocol to regain its pre-failure reliability are counted.

As expected, HyParView recovers in just 1 or 2 rounds for all failure percentages below 80%. Cyclon requires a significant number of membership cycles, increasing almost linearly with the percentage of failed nodes. Scamp's recovery time depends on the Lease Time, which is typically high to preserve stability in the membership.

### 5.4. Graph Properties

**Table 1: Graph Properties After Stabilization**

| Protocol | Average Clustering Coefficient | Average Shortest Path |
|----------|--------------------------------|------------------------|
| HyParView | 0.00092 | 2.60426 |
| Cyclon | 0.022476 | 3.35398 |
| Scamp | 0.006836 | 6.38542 |

As noted in Section 2.3, the overlays produced by the membership protocol must exhibit good properties such as a low clustering coefficient, small average shortest path, and balanced in-degree distribution. Table 1 shows these values after 50 membership cycles. HyParView achieves a significantly lower clustering coefficient than Scamp or Cyclon, which is expected given its smaller active view. This contributes to its high resilience to node failures.

In terms of average shortest path, HyParView has a longer path than Scamp and Cyclon. This is not surprising, as HyParView maintains a smaller active view, limiting the number of distinct paths. However, this does not affect the latency of the gossip protocol. The low global clustering and use of all existing paths between nodes allow HyParView to deliver gossip within fewer hops than the other protocols.

**Figure 5: In-Degree Distribution**

Figure 5 shows the in-degree distribution of all nodes in the overlay after the stabilization period. Cyclon and Scamp have a wide range of in-degrees, indicating that some nodes are extremely popular while others are almost unknown. This distribution leads to some nodes receiving redundant messages and others rarely seeing messages. In Scamp, some nodes are known only by one other node. HyParView's symmetric active view ensures that almost all nodes are known by the maximum number of nodes possible (the active view length of 5), resulting in a more uniform distribution and high probability of each node receiving messages the same number of times.

### 5.5. Discussion

From our results, several key lessons can be drawn. First, the speed of failure detection is crucial for maintaining high reliability in the presence of massive faults. A gossip strategy that uses a reliable transport (also serving as a failure detector) over a fixed overlay (built using a probabilistic membership protocol) offers the best performance. Using all the links of the overlay aims for 100% reliability as long as the overlay remains connected, allowing for smaller fanouts compared to protocols that rely on redundancy to mask failures. The use of a passive view, with candidates to replace failed nodes in the active view, enhances resilience to massive failures. Therefore, a hybrid approach with a small active view and a larger, low-cost passive view, maintained by different strategies, provides better resilience and resource usage than a single large view with a higher fanout.

The use of TCP could cause blockages in the overlay if slow nodes do not consume messages from their reception buffers. However, this effect is mitigated by considering slow nodes as failed and expelling them from all active views, as described in [12].

### 6. Conclusions and Future Work

Gossip protocols are attractive due to their low maintenance cost, making them suitable for applications requiring high resilience to massive node failures. This paper is the first to study the effect of gossip reliability under such conditions, using different approaches to maintain partial membership information. We propose a gossip strategy that floods the overlay topology created by a probabilistic membership protocol, supported by a novel hybrid membership protocol. Our protocol maintains a small active view and a larger passive view for fault tolerance, preserving high reliability with a small fanout even when up to 80% of nodes fail.

Future work includes experimenting to define the relationship between the passive view size and the resilience level, testing HyParView on the PlanetLab platform to measure packet overhead, and exploring adaptive fanouts to maximize resource use based on node heterogeneity. This approach, while maintaining deterministic gossip target selection, could lead to optimized emergent overlays.

### References

[1] K. Birman, M. Hayden, O. Ozkasap, Z. Xiao, M. Budiu, and Y. Minsky. Bimodal multicast. ACM TOCS, 17(2), May 1999.

[2] M. Deshpande, B. Xing, I. Lazardis, B. Hore, N. Venkatasubramanian, and S. Mehrotra. CREW: A gossip-based flash-dissemination system. In Proc. of the 26th ICDCS, Washington, DC, USA, 2006.

[3] P. T. Eugster, R. Guerraoui, S. B. Handurukande, P. Kouznetsov, and A.-M. Kermarrec. Lightweight probabilistic broadcast. ACM TOCS, 21(4):341–374, 2003.

[4] P. T. Eugster, R. Guerraoui, A.-M. Kermarrec, and L. Massoulie. From Epidemics to Distributed Computing. IEEE Computer, 37(5):60–67, 2004.

[5] A. Ganesh, A. Kermarrec, and L. Massoulie. Peer-to-peer membership management for gossip-based protocols, 2003.

[6] A. J. Ganesh, A.-M. Kermarrec, and L. Massoulie. SCAMP: Peer-to-peer lightweight membership service for large-scale group communication. In Networked Group Communication, pages 44–55, 2001.

[7] M. Hayden and K. Birman. Probabilistic broadcast. Technical report, Ithaca, NY, USA, 1996.

[8] M. Jelasity, R. Guerraoui, A.-M. Kermarrec, and M. van Steen. The peer sampling service: experimental evaluation of unstructured gossip-based implementations. In Proc. of Middleware '04, pages 79–98, 2004.

[9] A. Kermarrec, L. Massoulie, and A. Ganesh. Probabilistic reliable dissemination in large-scale systems, 2001.

[10] J. Leitão. Gossip-based broadcast protocols. Master’s thesis, University of Lisbon, 2007.

[11] Peersim p2p simulator. http://peersim.sourceforge.net/.

[12] J. Pereira, L. Rodrigues, M. J. Monteiro, R. Oliveira, and A.-M. Kermarrec. NEEM: Network-friendly epidemic multicast. In Proc. of the 22nd SRDS, pages 15–24, Florence, Italy, Oct. 2003.

[13] J. Pereira, L. Rodrigues, A. Pinto, and R. Oliveira. Low-latency probabilistic broadcast in wide area networks. In Proc. of the 23rd SRDS, pages 299–308, Florianopolis, Brazil, Oct. 2004.

[14] PlanetLab: Home. http://planet-lab.org/.

[15] S. Staniford, V. Paxson, and N. Weaver. How to own the internet in your spare time. In Proceedings of the 11th USENIX Security Symposium, pages 149–167, Berkeley, CA, USA, 2002. USENIX Association.

[16] A. Stavrou, D. Rubenstein, and S. Sahu. A lightweight, robust p2p system to handle flash crowds. Technical Report EE020321-1, Columbia University, New York, NY, Feb. 2002.

[17] S. Voulgaris, D. Gavidia, and M. Steen. Cyclon: Inexpensive membership management for unstructured p2p overlays. Journal of Network and Systems Management, 13(2):197–217, June 2005.