                h, w = original_shape[0], original_shape[1]
                # see https://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders for formulae
                old_l, old_s = tf.cond(h > w, lambda: [h, w], lambda: [w, h])
                old_l, old_s = tf.cast(old_l, tf.float32), tf.cast(old_s, tf.float32)
                new_l = (old_l * tf.cos(rotation) - old_s * tf.sin(rotation)) / tf.cos(2 * rotation)
                new_s = (old_s - tf.sin(rotation) * new_l) / tf.cos(rotation)
                new_h, new_w = tf.cond(h > w, lambda: [new_l, new_s], lambda: [new_s, new_l])
                new_h, new_w = tf.cast(new_h, tf.int32), tf.cast(new_w, tf.int32)
                bb_begin = tf.cast(tf.ceil((h - new_h) / 2), tf.int32), tf.cast(tf.ceil((w - new_w) / 2), tf.int32)
                rotated_image_crop = rotated_image[bb_begin[0]:h - bb_begin[0], bb_begin[1]:w - bb_begin[1], :]
                # If crop removes the entire image, keep the original image
                rotated_image = tf.cond(tf.equal(tf.size(rotated_image_crop), 0),
                                        true_fn=lambda: img,
                                        false_fn=lambda: rotated_image_crop)
            return rotated_image
    def random_padding(image: tf.Tensor, max_pad_w: int = 5, max_pad_h: int = 10) -> tf.Tensor:
        w_pad = list(np.random.randint(0, max_pad_w, size=[2]))
        h_pad = list(np.random.randint(0, max_pad_h, size=[2]))
        paddings = [h_pad, w_pad, [0, 0]]
        return tf.pad(image, paddings, mode='REFLECT', name='random_padding')
    def augment_data(image: tf.Tensor) -> tf.Tensor:
        with tf.name_scope('DataAugmentation'):
            # Random padding
            image = random_padding(image)
            image = tf.image.random_brightness(image, max_delta=0.1)
            image = tf.image.random_contrast(image, 0.5, 1.5)
            image = random_rotation(image, 0.05, crop=True)
            if image.shape[-1] >= 3:
                image = tf.image.random_hue(image, 0.2)
                image = tf.image.random_saturation(image, 0.5, 1.5)
            return image
    def padding_inputs_width(image: tf.Tensor, target_shape: Tuple[int, int], increment: int) -> Tuple[
        tf.Tensor, tf.Tensor]:
        target_ratio = target_shape[1] / target_shape[0]
        # Compute ratio to keep the same ratio in new image and get the size of padding
        # necessary to have the final desired shape
        shape = tf.shape(image)
        # 计算宽高比
        ratio = tf.divide(shape[1], shape[0], name='ratio')
        new_h = target_shape[0]
        new_w = tf.cast(tf.round((ratio * new_h) / increment) * increment, tf.int32)
        f1 = lambda: (new_w, ratio)
        f2 = lambda: (new_h, tf.constant(1.0, dtype=tf.float64))
        new_w, ratio = tf.case({tf.greater(new_w, 0): f1,
                                tf.less_equal(new_w, 0): f2},
                               default=f1, exclusive=True)
        target_w = target_shape[1]
        # Definitions for cases
        def pad_fn():
            with tf.name_scope('mirror_padding'):
                pad = tf.subtract(target_w, new_w)
                img_resized = tf.image.resize_images(image, [new_h, new_w])
                # Padding to have the desired width
                paddings = [[0, 0], [0, pad], [0, 0]]
                pad_image = tf.pad(img_resized, paddings, mode='SYMMETRIC', name=None)
                # Set manually the shape
                pad_image.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])
                return pad_image, (new_h, new_w)
        def replicate_fn():
            with tf.name_scope('replication_padding'):
                img_resized = tf.image.resize_images(image, [new_h, new_w])
                # If one symmetry is not enough to have a full width
                # Count number of replications needed
                n_replication = tf.cast(tf.ceil(target_shape[1] / new_w), tf.int32)
                img_replicated = tf.tile(img_resized, tf.stack([1, n_replication, 1]))
                pad_image = tf.image.crop_to_bounding_box(image=img_replicated, offset_height=0, offset_width=0,
                                                          target_height=target_shape[0], target_width=target_shape[1])
                # Set manually the shape
                pad_image.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])
                return pad_image, (new_h, new_w)
        def simple_resize():
            with tf.name_scope('simple_resize'):
                img_resized = tf.image.resize_images(image, target_shape)
                img_resized.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])
                return img_resized, target_shape
        # 3 cases
        pad_image, (new_h, new_w) = tf.case(
            {  # case 1 : new_w >= target_w
                tf.logical_and(tf.greater_equal(ratio, target_ratio),
                               tf.greater_equal(new_w, target_w)): simple_resize,
                # case 2 : new_w >= target_w/2 & new_w , '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
    INFO:tensorflow:Starting evaluation at 2017-11-28-12:21:42
    INFO:tensorflow:Restoring parameters from model_test\model.ckpt-54692
    2017-11-28 20:22:04.720980: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.236689657]
    INFO:tensorflow:Evaluation [1/3]
    2017-11-28 20:28:32.360331: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.238805175]
    INFO:tensorflow:Evaluation [2/3]
    2017-11-28 20:35:41.020994: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.237995088]
    INFO:tensorflow:Evaluation [3/3]
    INFO:tensorflow:Finished evaluation at 2017-11-28-12:43:21
    INFO:tensorflow:Saving dict for global step 54692: eval/CER = 0.0108218, eval/accuracy = 0.929688, global_step = 54692, loss = 0.23783
    time:1306.1133954524994
    model: model_test\model.ckpt-54692 Evaluation results: {'eval/CER': 0.01082176, 'eval/accuracy': 0.9296875, 'loss': 0.23782997, 'global_step': 54692}
tensorflow 1.3
    INFO:tensorflow:Using config: {'_model_dir': 'models_vgg_100K_no_eval', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': gpu_options {
      per_process_gpu_memory_fraction: 0.6
    }
    , '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}
    INFO:tensorflow:Starting evaluation at 2017-11-28-12:49:50
    INFO:tensorflow:Restoring parameters from model_test\model.ckpt-54692
    2017-11-28 20:50:12.841210: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.17519826]
    INFO:tensorflow:Evaluation [1/3]
    2017-11-28 20:51:03.366275: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.2987892]
    INFO:tensorflow:Evaluation [2/3]
    2017-11-28 20:51:49.843030: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.20660429]
    INFO:tensorflow:Evaluation [3/3]
    INFO:tensorflow:Finished evaluation at 2017-11-28-12:52:19
    INFO:tensorflow:Saving dict for global step 54692: eval/CER = 0.01188, eval/accuracy = 0.924479, global_step = 54692, loss = 0.226864
    time:157.26274514198303
    model: model_test\model.ckpt-54692 Evaluation results: {'eval/CER': 0.011879961, 'eval/accuracy': 0.92447919, 'loss': 0.22686392, 'global_step': 54692}