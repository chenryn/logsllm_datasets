V. IMPLEMENTATION
K-Scheduler consists of two components. First, to build
the edge horizon graph, we construct the target program’s
inter-procedural CFG. We initially compile the program with
wllvm [5] and use the LLVM’s (version 11.0.1) opt tool to
extract each function’s intra-procedural CFG. In Python 3.7,
we then merge each intra-procedural CFG together based on
caller-callee relations to produce the inter-procedural CFG.
We also implement all pieces from Algorithm 1 such as loop
removal in Python. To classify CFG nodes as visited, we re-
use a fuzzer’s edge coverage information to identify visited
basic blocks. Second, to compute Katz centrality, we use the
power method provided by networkit [4], a large-scale graph
computing library.
We now describe how we integrate K-Scheduler into
LibFuzzer [3] and AFL [62] to show our technique is generic
and widely applicable. We run K-Scheduler as a standalone
process that communicates with a fuzzer to set the fuzzer’s
seed ranking based on centrality and identify the mapping
between a seed node and its corresponding horizon nodes.
We measure how much overhead K-Scheduler adds to the
fuzzing process in Section VI.
Libfuzzer Integration. Libfuzzer [3] computes an energy for
each seed in the form of a probability and ﬂips a coin with bias
corresponding to the seed’s energy to determine whether a seed
should be selected for mutation. Higher energy probabilities
indicate a seed will be chosen more frequently. To integrate
into Libfuzzer, we follow the same integration as Entropic,
a state-of-the-art seed scheduler for Libfuzzer, and set each
seed’s energy to its Katz centrality score normalized by the
total centrality scores for all seeds.
AFL Integration. Unlike Libfuzzer’s probabilistic seed selec-
tion, AFL generally selects every seed for mutation. A seed’s
energy also determines its corresponding mutation budget. To
integrate into AFL, we set each seed’s energy directly to its
Katz centrality score.
VI. EVALUATION
Our evaluation aims to answer the following questions.
1) Comparison against
seed schedulers: How does
K-Scheduler compare against other seed scheduling
strategies?
2) Bug Finding: Does K-Scheduler improve a fuzzer’s
3) Runtime Overhead: What is the performance overhead
ability to ﬁnd bugs?
of K-Scheduler?
4) Impact of Design Choices: How do K-Scheduler’s
various design choices contribute to its performance?
5) Non-evolutionary
Does
K-Scheduler show promise for seed scheduling in
non-evolutionary fuzzing settings?
settings:
fuzzing
A. Experimental Setup
the academic community. These strategies are generally in-
tegrated into AFL or Libfuzzer. Directly comparing a seed
scheduling strategy that uses AFL with another seed schedul-
ing strategy that uses Libfuzzer can be misleading since the
underlying fuzzers may cause the performance difference in-
stead of the underlying seed scheduling strategy. Therefore, to
be fair, we integrate K-Scheduler into both Libfuzzer and
AFL separately and make comparisons about seed scheduling
strategies when the underlying fuzzer is the same. Note this
integration also demonstrates that K-Scheduler is generic
and widely applicable.
For K-Scheduler’s comparison against Libfuzzer-based
seed schedulers, we compare K-Scheduler against En-
tropic, a state-of-the-art seed scheduler in Libfuzzer [9]. To
ensure a fair comparsion, we follow the same integration with
Libfuzzer as Entropic. We also compare against Libfuzzer’s
default seed scheduler as a baseline and refer to it as Default.
We use Libfuzzer and Entropic from LLVM 11.0.1 in our
comparison. For K-Scheduler’s comparison against AFL-
based seed schedulers, we compare against strategies that
prioritize seeds if they take paths rarely observed (RarePath),
reach rarely observed edges (RareEdge) or discover new
paths (NewPath). We also compare against a strategy that
prioritizes seeds based on security-sensitive coverage (Sec-
Cov). To compare against RarePath, RareEdge, NewPath, and
SecCov we use AFLFast [7], FairFuzz [32], EcoFuzz [60],
and TortoiseFuzz [55] respectively. Since these fuzzers all
modify AFL, we integrate K-Scheduler into AFL using
their same modiﬁcations for a fair comparison. Moreover, we
set each fuzzer to use the same mutation strategy to a enable
a fair comparison. Hence, we disabled FairFuzz’s custom
mutation strategy. We also compare against AFL’s default seed
scheduling strategy as a baseline and refer to it as Default.
2) Benchmark Programs: In our seed scheduler compari-
son, we use the Google FuzzBench benchmark, a commonly
used dataset to evaluate fuzzing performance on real-world
programs. At the time of this writing, the benchmark consists
of 40+ programs, so we decide to evaluate over a subset
of them. We pick 12 diverse real-world programs from the
benchmark that includes cryptographic and database programs
as well as parsers as shown in Table III. We plan to evaluate
against
the entire benchmark in the future. We also use
the default seed corpus and conﬁguration provided by the
benchmark to enable a fair comparison. Note that Google
FuzzBench conﬁgures all AFL-based fuzzers to use havoc
mode by default [1], since AFL havoc mode has been shown
to signiﬁcantly outperform AFL deterministic mode [58].
For our bug-ﬁnding experiments, we select 12 real-world
parsing programs commonly used to evaluate fuzzer’s bug
ﬁnding performance [7, 32, 60]. The 12 programs cover 8 ﬁle
formats: ELF, ZIP, PNG, JPEG, TIFF, TAR, TEXT
and XML. The list of programs and their details can be found
in Table VI. Since these programs do not come with a default
seed corpus, we make a corpus with small valid ﬁles.
1) Baseline Seed Scheduling Strategies: We compare
against popular seed scheduling strategies from industry and
3) Environmental Setup: We run all our evaluations on 4
64-bit machines running Ubuntu 20.04 with Intel Xeon E5-
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:01:25 UTC from IEEE Xplore.  Restrictions apply. 
72200
2623 CPUs (96 cores in total). We follow standard operating
procedure in fuzzing evaluations [7, 9, 32] and bound each
fuzzer to 1 CPU core. Because our current implementation
runs K-Scheduler in a separate process, we assign fuzzers
using K-Scheduler 2 cores, one for the fuzzer and one for
the K-Scheduler.
B. RQ1: Seed scheduling comparison
For K-Scheduler’s comparison against Libfuzzer-based
seed schedulers, we follow the original evaluation of En-
tropic [9] and use the same two metrics for comparison: edge
coverage and feature coverage. Edge coverage measures how
many branches were reached along an input’s execution path,
whereas feature coverage includes this information as well
as branch hit count. For example, edge coverage would not
distinguish coverage between two inputs that visit the same
branch a different number of times, but feature coverage would
distinguish them.
We run K-Scheduler, Default (i.e., Libfuzzer’s default
seed scheduler), and Entropic on the 12 Google FuzzBench
programs for 24 hours. We repeat each 24 hour run ten
times for statistical power. In arithmetic mean over these
10 runs, Table
II and Table III summarize the edge and
feature coverage results for 1 hour and 24 hours, respectively.
Appendix Table XV and Table XVI show the corresponding
result from applying the Mann Whitney U test between
K-Scheduler and the tested seed schedulers in terms of
edge and feature coverage. Within 1 hour, K-Scheduler
improves upon next-best seed scheduling strategy Entropic by
20.11% in median and 31.75% in arithmetic mean over the
12 FuzzBench programs in feature coverage. For the 24 hour
runs, K-Scheduler achieves 20.66% in median and 25.89%
in arithmetic mean more feature coverage than Entropic. We
attribute the increased improvement of K-Scheduler over
Entropic within the ﬁrst hour to K-Scheduler’s scheduling
of promising seeds more frequently given a limited fuzzing
budget (i.e., fuzzer only schedules a limited number of seeds).
However, as the fuzzing budget increases to 24 hours, Entropic
will eventually also schedule those promising seeds more
frequently, which narrows the performance difference between
K-Scheduler. Moreover, with a signiﬁcance level of 0.05,
our feature coverage over Entropic results are statistically
signiﬁcant for all programs for 24 hour runs and all programs
except zlib for the 1 hour runs. Our results show that using
the CFG structure for seed scheduling can improve fuzzing
performance.
For K-Scheduler’s comparison against AFL-based seed
schedulers, we only use edge coverage as a metric for com-
parison because AFL does not report feature coverage. We run
K-Scheduler, Default (i.e., AFL’s default seed scheduler),
RarePath, RareEdge, NewPath, and SecurityCov on the same
12 Google FuzzBench programs for 24 hours, repeated ten
times. In arithmetic mean over these 10 runs, Table
IV
and Table V summarize the edge coverage results for 1
hour and 24 hours respectively. Appendix Table XVII and
Table XVIII show the Mann-Whitney U test results. Similar
TABLE II: Arithmetic mean feature and edge coverage of
Libfuzzer-based seed schedulers on 12 FuzzBench programs for
1 hour over 10 runs. We mark the highest number in bold.
K-Scheduler
Entropic
Default
Programs
freetype
libxml2
lcms
harfbuzz
libjpeg
libpng
openssl
openthread
re2
sqlite
vorbis
zlib
feature
51,184
39,240
2,886
35,017
10,974
5,001
14,520
6,525
31,292
73,532
9,106
2,711
edge
edge feature
edge feature
10,886 46,698 10,691 40,040
9,446
7,661 24,167
6,296
6,128 25,914
1,497
874
1,004
1,392
1,707
9,112 23,349
7,588
7,551 23,455
2,553
2,208
7,510
2,193
7,424
1,501
1,476
1,469
4,604
4,525
4,622 12,830
4,327
4,294 13,029
3,318
2,947
3,044
5,150
5,397
6,275 28,877
6,207
6,147 29,941
13,299 44,198 12,189 52,060 12,735
2,136
1,823
790
782
7,632
2,572
2,010
784
5,710
2,408
Arithmetic mean coverage gain 31.75% 12.51% 37.37% 15.72%
20.11% 8.32% 34.54% 13.91%
Median coverage gain
TABLE III: Arithmetic mean feature and edge coverage of
Libfuzzer-based seed schedulers on 12 FuzzBench programs for
24 hours over 10 runs. We mark the highest number in bold.
Programs
K-Scheduler
feature
71,717
freetype
54,081
libxml2
6,345
lcms
48,105
harfbuzz
15,861
libjpeg
5,312
libpng
16,644
openssl
openthread 11,405
33,797
re2
92,493
sqlite
10,417
vorbis
3,215
zlib
Entropic
Default
edge feature
edge feature
edge
13,754 75,370 14,120 67,510 12,870
9,869 36,958
7,310
2,541
1,784
4,425
10,358 32,799
8,912
3,033 11,755
2,574
1,535
1,501
5,002
4,971 15,137
4,738
4,965
3,196
6,435
6,482 32,401
6,367
15,540 75,723 14,351 83,228 14,710
2,247
2,115
801
787
7,038 39,247
2,082
3,413
8,808 33,499
2,646 11,220
1,501
4,992
4,731 15,173
3,276
6,123
6,347 32,725
9,906
2,698
2,208
790
8,873
2,510
Arithmetic mean coverage gain 25.89% 13.69% 31.43% 16.34%
20.66% 6.68% 22.75% 6.54%
Median coverage gain
to the comparison against Libfuzzer-based seed schedulers,
we observe a higher improvement of K-Scheduler over
the other seed scheduling strategies within the ﬁrst hour.
K-Scheduler outperforms the next best seed scheduling
strategy (RarePath) by 7.95% in arithmetic mean and 3.62%
in median over the 12 FuzzBench programs. For the 24 hour
runs, K-Scheduler achieves 4.21% in arithmetic mean and
1.91% in median more coverage than RarePath. We note that
the improvement of K-Scheduler against AFL-based seed
schedulers is not as signiﬁcant as K-Scheduler’s com-
parison against Libfuzzer-based seed schedulers. We believe
K-Scheduler’s diminished performance difference occurs
because the underlying fuzzer, AFL, iterates over the seed
queue multiple times during the 24 hours fuzzing campaign
and therefore will schedule nearly all seeds frequently, reduc-
ing the effect of seed selection.
The coverage plots over time also highlight the promise of
K-Scheduler. Figure 5 and 6 show that K-Scheduler
generally maintains its performance advantage during the
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:01:25 UTC from IEEE Xplore.  Restrictions apply. 
82201
TABLE IV: Arithmetic mean edge coverage of AFL-based seed
schedulers on 12 FuzzBench programs for 1 hour over 10 runs.
K-Sched Default RarePath RareEdge NewPath
SecCov
AFL
AFL AﬂFast FairFuzz EcoFuzz TortoiseFuzz
Fuzzer
freetype
libxml2
lcms
harfbuzz
libjpeg
libpng
openssl
openthread
re2
sqlite
vorbis
zlib
12,077 11,001
8,120
5,793
1,989
1,882
9,169
8,864
2,391
2,354
1,488
1,470
4,560
4,485
5,245
5,063
5,792
5,612
9,865 10,038
2,048
2,006
761
758
Arithmetic mean gain 4.80%
1.87%
Median gain
10,707
5,836
1,540