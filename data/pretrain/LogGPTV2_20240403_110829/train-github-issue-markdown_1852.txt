**_(See the comments below for a simpler repro case.)_**
A model with shared inputs, LSTM, and Lambda layers fails to deserialize. A
minimal repro case is here.
    from keras.engine import Input, Model
    from keras.layers import Lambda, concatenate, Dense, LSTM
    from keras.models import save_model, load_model
    input_shape = (20, 300)
    input_1 = Input(input_shape)
    input_2 = Input(input_shape)
    lstm = LSTM(32)
    e1 = lstm(input_1)
    e2 = lstm(input_2)
    negative_e1 = Lambda(lambda x: -x)(e1)
    hidden = concatenate([e1, e2, negative_e1])
    logistic_regression = Dense(1, activation="sigmoid")(hidden)
    model = Model(inputs=[input_1, input_2], outputs=logistic_regression)
    model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
    print("Original model %s" % model)
    name = "model.hd5"
    save_model(model, name)
    restored_model = load_model(name)
    print("Restored model %s" % restored_model)
(This model is a simplification of a strategy used for textual semantic
equivalence detection. The actual strategy takes the square of `e2 - e1` which
exhibits the same problem.)
The `restore_model` fails with the exception `ValueError: Missing layer:
input_2`.
This is as simple as I have been able to make the repro case.  
Changing the model in the following ways makes the bug go away:
  * Not using multiple inputs
  * Not putting the inputs through a shared LSTM. (It works if you either omit the LSTM or use a separate LSTM for each input.)
  * Not using a Lambda layer. (It works if you omit the Lambda layer, or replace it with a non-lambda function, e.g. `keras.layers.add([e1, e2])`)
This looks similar to #4160, but doesn't have the nested layers that issue
has, so I'm not sure if it's the same bug.
This is the full stack trace.
    Traceback (most recent call last):
      File "/Users/billmcn/src/keras_serialization_bug/keras_serialization_bug.py", line 28, in 
        restored_model = load_model(name)
      File "/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/models.py", line 232, in load_model
        model = model_from_config(model_config, custom_objects=custom_objects)
      File "/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/models.py", line 293, in model_from_config
        return layer_module.deserialize(config, custom_objects=custom_objects)
      File "/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/layers/__init__.py", line 46, in deserialize
        printable_module_name='layer')
      File "/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/utils/generic_utils.py", line 140, in deserialize_keras_object
        list(custom_objects.items())))
      File "/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/engine/topology.py", line 2374, in from_config
        process_layer(layer_data)
      File "/Users/billmcn/anaconda/envs/keras-serialization-bug/lib/python3.5/site-packages/keras/engine/topology.py", line 2361, in process_layer
        raise ValueError('Missing layer: ' + inbound_layer_name)
    ValueError: Missing layer: input_2
_Keras version 2.0.4 with TensorFlow backend, Python 3.5.3_
## Checklist
  * Check that you are up-to-date with the master branch of Keras. You can update with:  
pip install git+git://github.com/fchollet/keras.git --upgrade --no-deps
  * If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found here.
  * If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:  
pip install git+git://github.com/Theano/Theano.git --upgrade --no-deps
  * Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).