### 6.3 Analyzing IT Services

#### 6.3.1 Existing Software Solutions for ITIL Service Management

Today, numerous software solutions are available to support and manage ITIL (Information Technology Infrastructure Library) services. Examples include ServiceNow, Zendesk, Kayako, UserVoice, and Freshdesk. These solutions offer a wide range of features, such as SLA (Service Level Agreement) and escalation management, integration with social media platforms, automated ticket routing, and graphical form design. The choice of solution depends on the specific requirements of the organization.

#### 6.3.2 ITIL Incident Management Service Blueprint

During service provisioning, incidents are managed using an activity record system. Activities are assigned to appropriate team members who handle the tasks accordingly. These systems generate events, which are recorded in a log to provide an audit trail. This trail can be used to understand how services were provisioned. For example, each time an activity in the service illustrated in Figure 6.3 is executed, an event is generated and stored in a log. Event records typically contain information such as a timestamp, the name of the activity executed, the owner and priority of the incident case, the status of the service, and a description of the incident. Once an incident has been properly handled, it is closed.

**Figure 6.3: ITIL Incident Management Service Blueprint (adapted from [19], p.48)**

| Physical Evidence | Information | Web | Phone | Email |
|-------------------|-------------|-----|-------|-------|
| System Page       | Connection  | Address |
| Customer Actions  | Event Mgmt. | Interface | Phone Call | Email |
| Onstage Contact   | Incident    | Identification | Logging | Categorization |
| Backstage Contact | Service Request | Fulfillment |
| Major Incident Procedure | Initial Diagnosis | Escalation | Investigation & Diagnosis | Resolution & Recovery |
| Support Processes | Incident Prioritization | Closure |

**Figure 6.4: Example of a Software Application to Support ITIL Incident Management**

This process includes the detection of errors and inconsistencies to improve data quality, the integration of schema, and the consolidation of instances. Afterward, service analytics are applied to the dataset to extract valuable insights and knowledge about service provisioning patterns.

#### 6.3.3 Dataset Description

A real-life dataset from the automotive industry is used to illustrate how service analytics can be operationalized. The dataset contains event records from operational business processes and was generated by an incident management system called VINST. The dataset has the following characteristics:

- Available from the Business Process Intelligence (BPI) Challenge 2013 website.
- Contains event records from a three-week period from May 1, 2012, to May 23, 2012.
- Includes 65,533 events pertaining to 7,554 incident records.
- Not preprocessed or filtered, other than being anonymized.

**Table 6.2: Attributes of the Dataset**

| Attribute         | Count | Description                                           |
|-------------------|-------|-------------------------------------------------------|
| SR Number         | 7,554 | Unique ticket number for each incident reported.      |
| Change Date+Time  | Many  | Timestamp indicating when the status of an incident changed. |
| Status            | 4     | Status of the incident management service: queued, accepted, completed, closed. |
| Substatus         | 13    | Substatus of an incident case: assigned, awaiting assignment, cancelled, closed, in progress, wait, unmatched. |
| Involved ST       | 24    | IT organization providing the service, divided into functions (mostly technology-wise). |
| Involved Org      | 25    | Business area of the user reporting the incident to the service desk. |
| Involved Team     | 649   | Team responsible for resolving the incident.           |
| SR Latest Impact  | 4     | Impact of an incident for the customer: major, high, medium, low. |
| Product           | 704   | Identification of the product that originated the incident. |
| Country           | 23    | Country of the support team that takes ownership of the incident record. |
| Owner Country     | 32    | Country of the owner.                                  |
| Owner First Name  | 1,440 | Person of the support team who is the owner of the reported incident. |

**Table 6.3: Extract of the Dataset**

| Instances                                                                                      |
|-------------------------------------------------------------------------------------------------|
| 1-364285768; 2010-03-31T15:59:42+01:00; Accepted; In Progress; A2_4; Org line A2; V30; Medium; PROD582; fr; France; Frederic |
| 1-364285768; 2010-03-31T16:00:56+01:00; Accepted; In Progress; A2_4; Org line A2; V30; Medium; PROD582; fr; France; Frederic |
| 1-364285768; 2010-03-31T16:45:48+01:00; Queued; Awaiting Assignment; A2_5; Org line A2; V5 3rd; Medium; PROD582; fr; France; Frederic |
| 1-364285768; 2010-04-06T15:44:07+01:00; Accepted; In Progress; A2_5; Org line A2; V5 3rd; Medium; PROD582; fr; France; Anne Claire |
| 1-364285768; 2010-04-06T15:44:38+01:00; Queued; Awaiting Assignment; A2_4; Org line A2; V30; Medium; PROD582; fr; France; Anne Claire |
| 1-364285768; 2010-04-06T15:44:47+01:00; Accepted; In Progress; A2_5; Org line A2; V13 2nd 3rd; Medium; PROD582; fr; France; Anne Claire |
| 1-364285768; 2010-04-06T15:44:51+01:00; Completed; Resolved; A2_5; Org line A2; V13 2nd 3rd; Medium; PROD582; fr; France; Anne Claire |

#### 6.3.4 Preprocessing and Cleaning

Preprocessing the dataset was necessary before conducting the analysis. Microsoft Excel was used as the basic tool for data munging. Its features for importing CSV files and filtering/sorting capabilities made it easy to identify missing data and estimate attribute counts. Python was used to manually convert the dataset from its original format to a more convenient format for analysis. The objective was to better understand support tiers, owner names, and handle missing values.

**Support Tiers**

The `Involved ST` attribute combined the support team name and the support tier. For example, `S2 2nd` indicated the support team `S2` and the support tier `2nd`. A new attribute, `Support line`, was created to solely indicate the support tier. The values for `Support line` were `1st`, `2nd`, `3rd`, and `2nd-3rd`.

**Owner Names**

The `Owner first name` attribute had 1,440 unique values (e.g., Frederic and Anne Claire). These names did not map uniquely to the `Owner country` attribute, likely because several people with the same name were located in different countries. To address this, the `Owner country` was concatenated with `Owner first name` to create a new attribute, resulting in 1,688 distinct entities.

**Missing Values**

Several values of the `Status` and `Substatus` attributes were not specified in the dataset. Instances without these values were removed. The format of timestamps was also modified to enable processing by various tools.

#### 6.3.5 Predicting Incident Closure

The goal of this section is to construct a predictive model to understand the factors that influence whether an incident will be closed or not. Specifically, the objective is to understand the impact of the number of functional divisions, support teams, and organizations involved in the resolution of an incident on the closure of incidents.

**Classification and Prediction**

Classification and prediction are forms of data analysis used to build models that capture important data patterns or predict future data trends. The question to be answered is: How can we predict whether an IT service incident report submitted will be resolved or not? The prediction is based on attributes that describe an incident, such as support teams involved, country owning the incident, and functional departments involved. Organizations can use classification techniques to answer this question.

**Training Set**

| ID  | SR Number  | _Status | Involved ST | ... | Closed |
|-----|------------|---------|-------------|-----|--------|
| 1   | 1-364285768| 3       | S42         | ... | Yes    |
| 2   | 1-467153946| 1       | V30         | ... | No     |
| 3   | 1-504538555| 5       | D2          | ... | Yes    |
| 4   | 1-506071646| 4       | D2          | ... | No     |
| 5   | 1-512795200| 7       | D5          | ... | No     |
| 6   | 1-516553982| 4       | A1          | ... | No     |
| 7   | 1-529096847| 3       | N38         | ... | Yes    |
| ... | ...        | ...     | ...         | ... | ...    |

**Testing Set**

| ID  | SR Number  | _Status | Involved ST | ... | Closed |
|-----|------------|---------|-------------|-----|--------|
| 81  | 1-364285768| 2       | S42         | ... | Yes    |

By evaluating the accuracy of the model, organizations can gain insights into the factors that influence incident resolution and improve their service management processes.