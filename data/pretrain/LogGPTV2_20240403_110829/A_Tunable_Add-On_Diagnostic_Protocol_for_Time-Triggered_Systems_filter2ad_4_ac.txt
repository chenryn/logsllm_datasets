network are ﬁltered using the p/r algorithm. We remark that
in our extended fault model these properties hold for obedi-
ent nodes, i.e., both correct nodes and nodes encountering
omission faults, whereas for classical diagnostic protocols
they only hold for correct nodes. These properties imply
that an obedient node is able to diagnose itself.
We ﬁrst prove that the diagnostic matrix used for the hy-
brid voting consists of validity bits of messages sent in the
same round. Next we study the conditions under which the
hybrid voting is able to calculate a consistent health vector
that provides for the three properties deﬁned above.
Lemma 1 All local syndromes al dmj correctly received
and aggregated by the diagnostic jobs executed at round k
contain the value of the validity bits of the messages sent
in the same previous diagnosed round, which can be either
k − 3 or k − 2 depending on the schedule of nodes and on
the global communication schedule.
Proof Diagnostic messages are updated at every round.
Therefore, each diagnostic job at round k can read values
sent either in round k or k − 1. The read alignment done
in the aggregation phase ensures that all local syndromes
al dmj were sent in round k − 1. Such local syndromes
were formed either in the same round as they were sent or in
the previous, i.e., either in round k−1 or k−2. This depends
on the local schedule of diagnostic jobs with respect to the
global communication schedule, i.e., on the send alignment.
The local detection phase also uses read alignment to con-
sistently form local syndromes of validity bits referring to
messages sent in the previous round, i.e., either round k − 3
or k − 2. This round is therefore the diagnosed round. (cid:3)
The aligned local syndromes formed at round k consti-
tute the diagnostic matrix for the diagnosed round k − 3 or
k − 2. Due to malicious faults during the dissemination,
local syndromes can contain incorrect information, and dif-
ferent diagnostic matrices can be formed at different nodes.
In the following, we prove that the hybrid voting function
H-maj(V ) calculates a consistent health vector satisfying
correctness, completeness and consistency; a, s and b will
represent the number of asymmetric, symmetric malicious
and benign faulty nodes over one execution of the protocol.
Lemma 2 The consistent health vector calculated by each
obedient node at round k guarantees consistency, com-
pleteness and correctness for faults occurred at round k − 3
or k − 2 as long as N > 2a + 2s + b + 1 and a ≤ 1.
is
executed
over
the
referring to the
Proof As proved in Lemma 1,
the hybrid voting
H-maj(V )
local
syndromes
of validity bits
same diagnosed
round. Let us consider the N-1 tuple of values V =
hal dm1[i], . . . , al dmi−1[i], al dmi+1[i], . . . , al dmN [i]i
used by an obedient node to diagnose i. Among these val-
ues, up to b are erroneous (ε), the actual number depending
on the amount of benign faulty nodes failing during the
dissemination phase. The other N − b − 1 values are either
correct (and therefore symmetric) or malicious/asymmetric.
If the diagnosed sender was correct or benign faulty, all
correct votes will carry the same opinion to all obedient
nodes. As N −b−1 > 2(a+s), malicious and/or asymmet-
ric votes are a minority and are outvoted by correct values in
each obedient node. Thus, a consistent decision is reached
that ensures correctness and completeness.
If the diagnosed sender is not correct nor benign faulty
in the diagnosed round, the only property required is con-
sistency. If the sender had been symmetric malicious, it was
not detected as faulty by any node. Similar to the previous
case, there is a consistent majority of correct votes at each
obedient node saying that the sender was not faulty, and
therefore consistency is guaranteed.
If the diagnosed sender was asymmetric faulty, its vote
does not contribute to the diagnosis on its health, since the
opinion of a node on itself is ignored and excluded from the
vector V . As there can be at most one asymmetric sender
over one execution of the protocol, each obedient node re-
ceives the same set of votes and reaches a consistent diag-
nosis, which can assume any value.
(cid:3)
The condition N > 2a + 2s + b + 1 requires that, even
if there are no malicious faults, b  2a + 2s + b + 1 and a ≤ 1; or there are only benign
faults, N − 1 ≤ b ≤ N . In the latter case, local collision
(cid:3)
detection is necessary for self-diagnosis.
7. The membership protocol
A common approach to keep consistency in fault-tolerant
distributed systems is to use a group membership service.
When an asymmetric fault occurs, nodes are partitioned into
two sets, also called cliques, such that the members of one
clique received the message whereas the other did not. In
such case a membership service outputs a new view consist-
ing of the larger of these cliques. As all the members of a
clique have received the same set of messages, they have a
consistent state. The properties required for a group mem-
bership service are the following:
- Membership liveness: A new unique view is formed
whenever an obedient node receives a locally de-
tectable faulty message m;
- View synchrony: As a new view is formed, all obe-
dient nodes remaining across consecutive views have
received the same set of messages prior to, and includ-
ing, m.
If there is a benign fault, all receivers form a unique
clique and Alg. 1 detects sender faulty nodes correctly. In
case of asymmetric faults, however, two different cliques of
receivers are formed and the diagnostic protocol of Alg. 1
cannot detect them.
A modiﬁed diagnostic protocol can detect the presence
of disjoint cliques and allow the determination of views
according to the properties above. In Alg. 1, the analysis
phase must be executed before the dissemination phase; af-
ter the consistent health vector is calculated, the modiﬁed
algorithm accuses (as member of the minority clique) the
nodes that send local syndromes disagreeing with it. Such
accusations, called minority accusations, are added in the
current aligned local syndrome al ls and subsequently dis-
seminated. The protocol satisﬁes the desired properties as
shown in Theorem 2:
Theorem 2 If an obedient correct node receives a locally
incorrect message m and N > 2a+2s+b+1, a ≤ 1, a new
view is generated after two complete executions of the mod-
iﬁed diagnostic protocol (membership liveness) containing
all nodes never deemed as faulty. Such a view satisﬁes view
synchrony for all messages prior to and including m.
Proof A locally detectable message can be received due to
either a benign or an asymmetric fault.
If a benign fault
occurs, it is detected by the diagnostic protocol as shown in
Theorem 1. The sender is the only node which received the
message and will be excluded from the view.
If an asymmetric fault occurs during the broadcast of
message m, two cliques of obedient nodes are formed. The-
orem 1 guarantees that all obedient nodes calculate a con-
sistent health vector, which contains a consistent decision
(faulty/non faulty) on message m. During the dissemina-
tion phase of the diagnostic protocol, however, obedient
nodes of the minority cliques try to send local syndromes
disagreeing with the consistent decision. As a ≤ 1, such
nodes can either correctly broadcast it, and be accused by
all other obedient nodes (minority accusation), or be benign
faulty senders, and thus be accused by the local detection
mechanisms of all the other obedient nodes. In both cases
they will be consistently accused and diagnosed as faulty in
the next execution of the diagnostic protocol.
(cid:3)
8. Validation of the protocols
In this section we present the results of the experimental
validation of the diagnostic and membership protocols. We
used physical fault injection to validate the properties of the
protocol under different scenarios. We emphasize that all
parameters used in the validation (and tuning, see Sec. 9)
arise from actual automotive and aerospace applications.
Prototype setup. The validation setup consists of a set
of four nodes consisting of a host computer (Inﬁneon Tri-
core 1796) and a communication controller (Xilinx Vertex
4 FPGA), which are interconnected via a redundant TT net-
work (layered TTP). Each host computer runs a TT operat-
ing system. A diagnostic job runs on each node as an add-on
application-level module sending one diagnostic message
per round. No constraint was imposed on the internal node
scheduling besides executing diagnostic jobs once every
round. The static node scheduling deﬁned the constant in-
tegers l{1,..,N } and the predicates send curr round{1,..,N }
used by the protocol for the read and the send alignment op-
erations. Interface variables are automatically updated and
the validity bits of a message m can be read using the API
call tt Receiver Status. The bandwidth required for
each diagnostic message is N = 4 bits.
We also used an additional disturbance node, which is
able to emulate hardware faults in the communication net-
work. As the protocol does not discriminate between node
and link faults, a fault in a node can be emulated by corrupt-
ing or dropping a message it sends.
Injection cases. We selectively injected different classes
of physical faults on the bus (electrical spikes, random
noise, periods of silence) to simulate faults in a determin-
istic and reproducible manner. As we know which faults
are injected, we can experimentally evaluate whether the
diagnostic protocol is able to detect them. Each experiment
class was repeated 100 times for consistency. A total of
1500 fault injection experiments was conducted.
We injected bursty faults of increasing length: one slot,
two slots and two TDMA rounds. The ﬁrst two cases fall
in the hypothesis of Lemma 2, the third in the hypothe-
sis of Lemma 3.
In the latter case, all slots of a whole
TDMA round are lost, reproducing a communication black-
out where no nodes are able to send any messages (and
therefore no local syndromes are sent).
In each of these
three cases, bursts can start in any of the 4 sending slots,
thus we considered 12 experiment classes.
Another experiment class aimed at validating the abil-
ity of the protocol to correctly update penalty and reward
counters for a given node. A fault is injected in the sending
slots of the node every second TDMA round for 20 TDMA
rounds. Hence, either the penalty or the reward counter
should be increased at every round.
The effect of one malicious node sending random local
syndromes was also considered.
Its presence is not sup-
posed to induce the other nodes to diagnose correct nodes
as faulty. As any of the four nodes can be malicious, we
considered 4 experiment classes.
To validate the clique detection capabilities of the mem-
bership protocol, we placed the disturbance node between
Node 1 and the rest of the cluster and disconnected the bus
during the sending slot of at least another node to produce
(and detect) a minority clique formed by Node 1.
9. Practical tuning of the p/r algorithm
In order to correctly discriminate between healthy and
unhealthy nodes, the penalty and reward thresholds have to
be tuned together with the criticality levels for each node.
We now describe experiences on the tuning of our proto-
type for realistic automotive and aerospace settings. Table 2
summarizes the results of our tuning.
Characterizing intermittent faults. The ﬁrst difﬁculty
faced during the practical tuning of the protocol is how to
characterize unhealthy nodes. The p/r algorithm resets the
penalty and reward counters for a node if it does not fail
for R consecutive rounds, where R is the reward thresh-
If a fault appears before R is reached, it is consid-
old.
ered correlated with the previous fault. Therefore, R should
be large enough to correlate intermittent faults. The time
to reappearance of intermittent faults, however, depends on
the speciﬁc frequency of fault activation for each node (i.e.,
which hardware components of the node are damaged and
how often they are stimulated by the software) and is un-
known in most practical systems.
While setting R, designers must make a probabilistic
tradeoff between the capability of correlating intermittent
faults with a large time to reappearance and the avoidance
of incorrect correlation of independent and external tran-
sient faults. In Figure 3 we show such a tradeoff for our
automotive and aerospace settings, where the length of the
TDMA round is set to T = 2.5ms. Our practical choice
was to set R = 106 to correlate faults whose interarrival
time is within R × T ∼= 42min, which can be pragmati-
cally considered a reasonable value. After detecting a tran-
sient fault, the resulting probability of correlating a second
transient fault is less than 1% considering the rates of Fig. 3.
It must be noticed that a healthy node will be isolated only if
P subsequent transient faults are correlated, where P is the
penalty threshold [7]. In all our prototypes the probability
of isolation of a healthy node is thus negligible.
Tuning the diagnostic latency. To increase availabil-
ity and accumulate diagnostic data, the p/r algorithm delays
node isolation and increases the diagnostic latency. An ap-
plication can be prevented from correctly exchanging mes-
sages if some of its jobs are hosted on a faulty node that is
kept operative by the p/r algorithm. In such case the ap-
plication might experience an outage. Applications with
different criticality classes have different requirements on
s
t
l
u
a
f
t
n
e
i
s
n
a
r
t
f
o
n
o
i
t
a
e
r
r
o
c
l
.
b
o
r
P
 0.1
 0.01
 0.001
 0.0001
 1e-005
 1e-006
 1e-007
 1e-008
 1e-009
 1e-010