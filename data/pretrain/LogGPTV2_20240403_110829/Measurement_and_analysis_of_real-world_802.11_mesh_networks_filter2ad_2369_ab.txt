125We refer to the set of bit rates present in probe set P as Prates. Each
bit rate b in Prates is associated with a loss rate, bloss.
We use the loss rates and SNRs of these probes to measure the
accuracy of SNR-based bit rate adaptation algorithms in Section 4,
to measure the potential improvements from opportunistic routing
in Section 5, and to determine the frequency of hidden terminals
in Section 6. Before delving into these problems, we discuss two
properties of our data set in more detail.
3.1.1 SNR
Each received probe has an SNR value associated with it, re-
ported by the Atheros chip and logged on the Meraki device. The
MadWiFi driver reports an “RSSI” quantity on each packet recep-
tion. The 802.11 standard does not specify how this information
should be calculated, so different chipsets and drivers behave dif-
ferently. The behavior of MadWiFi on the Atheros chipset is well-
documented on the MadWiFi web site2 and has been veriﬁed by
various researchers (including us in the past). The MadWiFi docu-
mentation describes the RSSI it reports as follows:
“In MadWiFi, the reported RSSI for each packet is ac-
tually equivalent to the Signal-to-Noise Ratio (SNR)
and hence we can use the terms interchangeably. This
does not necessarily hold for other drivers though.
This is because the RSSI reported by the MadWiFi
HAL is a value in dB that speciﬁes the difference be-
tween the signal level and noise level for each packet.
Hence the driver calculates a packet’s absolute signal
level by adding the RSSI to the absolute noise level.”
In this paper, we use the term SNR rather than RSSI because the
former is a precise term while the latter varies between vendors.
The SNR for a given probe set is not always the same because
wireless channel properties vary with time. As mentioned, each
probe set contains data from about 20 probes per each bit rate,
which are averaged to produce tuples of the form
(cid:2)Sender, Bit rate, Mean loss rate, Most recent SNR(cid:3)
There is one such entry for each probed bit rate from each sender
AP, and the means are calculated using the number of probes re-
ceived at each bit rate from the neighbor. The transmissions at the
different bit rates are interspersed, and the SNR at each bit rate may
be different for each bit rate because of channel variations. We use
the median of these SNRs as the “SNR of the probe set”. We ﬁnd
that this way of estimating the receiver SNR over the duration of
these probes is robust, as the SNR values within a probe set do not
value signiﬁcantly; see Figure 2, explained below.
Figure 2 presents a CDF of the standard deviations of SNRs
within each probe set as well as over each link. The standard devi-
ation within each probe set is small (less than 5 dB approximately
97.5% of the time). The bulk of the observed SNRs in our data set
lie between 0 and 70 dB. We also present the standard deviations
of the SNRs on each link and within each network over time, to
illustrate the diverse range of SNRs present in each network. Not
pictured is the standard deviation of the k most recent SNR values
on a link, which we found to be comparable to the standard devia-
tion within a probe set for small values of k; i.e., the SNR on a link
does not vary signiﬁcantly on short time scales.
3.1.2 Throughput
A word on the deﬁnition of throughput is in order. What really
matters in practice is the performance observed by applications that
2http://madwifi-project.org/wiki/UserDocs/RSSI
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Probe Sets
Links
Networks
 5
 10
 15
 20
 25
 30
Standard Deviation in SNR (dB)
Figure 2: CDF of the standard deviation of SNR values within a
probe set, for individual links, and for the network at large. The
standard deviation of the SNR within a probe set is less than 5
dB over 97.5% of the time. The standard deviations taken over
all the links of each network are quite a bit larger, indicating
each network has links with a diverse range of SNRs.
run over transport protocols like TCP. Unfortunately, using link-
layer measurements to predict the application-perceived throughput
and latency of data transfers is difﬁcult, if not impossible, with the
data set we have (for instance, we don’t have information about
the burst loss patterns or over short time scales). We do know,
however, that with a good link-layer error recovery scheme and a
good transport protocol, the throughput should track the product of
the bit rate and the packet success rate. In this paper, we use the
product of the bit rate and packet success rate as the deﬁnition of
throughput. This metric is what some bit rate adaptation schemes
like RRAA [38] seek to optimize.
4. SNR-BASED BIT RATE ADAPTATION
We begin by using our inter-AP probe data to determine how ac-
curate an indicator the SNR is of the optimal bit rate. By “optimal”
bit rate, we mean the bit rate that results in the highest throughput
between two nodes. There are two reasons for investigating this
question:
1. Dynamically selecting a suitable bit rate is a signiﬁcant factor
in achieving high throughput in wireless network.
2. For bit rate adaptation schemes that use frame-level informa-
tion, such as [4] and [38], it takes a non-negligible amount of
probe trafﬁc and time to pick the best rate. As networks move
from 802.11b/g to 802.11n, there are many more bit rate con-
ﬁgurations to pick from. It is possible that the SNR can be
used as a hint to narrow down the set of bit rates to consider,
especially in relatively static settings involving ﬁxed mesh
APs, saving much of the current overhead of probes.
Our main ﬁnding in this section is that the SNR is not an accurate
indicator when trained over an entire network (i.e., when one SNR-
to-bit-rate look-up table is used for an entire network), but as the
speciﬁcity of the training environment increases (from per-network
to per-link), the SNR begins to work quite well. For a given link,
it is possible to train the nodes to develop a simple look-up method
keyed by SNR to pick the optimal bit rate almost all the time. This
result implies that one could not use the SNR to select the opti-
mal bit rate between two APs without knowing anything about the
condition of the link between them. However, with knowledge of
126a link’s condition, a simple bit rate selection algorithm using the
SNR would likely work very well. The caveat is that this result
holds in our data set for inter-AP communication. It is probable
that it would hold for static clients, but not as likely to hold for
mobile ones (see Section 4.6).
4.1 Bit Rate Selection Using SNR
Recall that the SNR is a measure of how much a signal has been
corrupted by noise. Intuitively, a higher SNR indicates a “better”
link, and one would expect to be able to send more information, i.e.,
use a higher bit rate on that link. Similarly, a low SNR indicates a
poor link, and one would expect to need a lower bit rate. It is this
intuition that motivates SNR-based bit rate adaptation. Indeed, the
throughput and optimal bit rate clearly depend on the SNR accord-
ing to Shannon’s theorem, but the question is whether our relatively
coarsely-sampled SNR can be used as an accurate hint for deter-
mining the correct bit rate. Our bit rate adaptation algorithm works
as follows: To select the bit rate for a link between AP1 and AP2,
measure the SNR s on this link. Then, using a look-up table that
maps SNR values to bit rates, look up s and use the corresponding
bit rate.
The key question in this method is how to create the look-up
table from SNR to bit rate. For a probe set between AP1 and AP2,
we deﬁne Popt as the bit rate that maximized the throughput for a
particular probe set, i.e.,
Popt = max{b× (1− bloss) : b ∈ Prates}
Given the SNR and Popt values from every probe set P in our data
set, we consider three options for creating the look-up table:
1. Network: For each network n and each SNR s represented
in our data for n, assign bit rate b to s, where b is the most
frequent value of Popt for SNR s (i.e., the bit rate that was
most frequently the optimal bit rate for the probe sets with
SNR s). For links in network n, select the bit rates by using
n’s look-up table.
2. AP: Instead of creating one look-up table per network, create
one per AP. For a particular link, the source will use its own
look-up table to select the bit rate, but this table will not vary
with the destination.
3. Link: Instead of creating one look-up table per AP, create
one per link. Use a link’s own table to select its bit rates.
This approach differs from the AP approach in that each AP
now has one table per neighbor.
As listed, each of these methods uses a more speciﬁc environ-
ment than the last. As a result, each would have a different start-up
cost. With the ﬁrst, training needs to be done on the network as a
whole, but not per-link. If one were to add a link to the network, the
same look-up table could still be used (though it may be beneﬁcial
to re-train if the network changed drastically). With the second,
training would need to occur when a new node was added, but only
at that node. With the third, training would need to occur every
time a new link was added, at both the source and destination of
the link; this is discussed more in Section 4.5.
Note that we could also make a global look-up table, where the
same look-up table was used for every link in every network. This
strategy would have virtually no start-up cost. However, it would
also only work well if Popt never changed (i.e., if it were the case
that, for a particular SNR value, the optimal bit rate was always the
same regardless of the network or link that we were using). Figure 3
shows the unique values of Popt for each SNR in our 802.11b/g
)
s
/
t
i
b
M
(
e
t
a
R
t
i
B
48
36
24
12
11
6
1
 0
 10
 20
 30
 40
 50
SNR (dB)
 60
 70
 80
 90
Figure 3: Optimal bit rates for an SNR at a particular time,
over our entire data set. Many SNRs see different optimal bit
rates at different times, which motivates the need for a better
method than a global SNR look-up table.
networks (a similar result holds for 802.11n, which we do not show
separately here). Note that each probe set contains data for each bit
rate, so on any link all bit rates have a chance of being optimal.
We ﬁnd that one bit rate is not always optimal for a particular
SNR in most cases, indicated by the fact that many SNRs have
points at multiple bit rates. Occasionally there is a clear winner:
for SNRs above 80 dB, the optimal bit rate is 48 Mbit/s in our
data set (we don’t evaluate the performance of 54 Mbit/s because
Meraki does not probe that rate as frequently [5]). However, for the
majority of SNRs, at least two bit rates, and in some cases as many
as six, could be the best. Thus, for most of this section, we do not
present results for the global look-up table, as Figure 3 indicates
that it is not a viable bit rate-selection strategy (and indeed, we
have veriﬁed that it is not with our own analysis).
As an aside, note that in Figure 3, 1Mbit/s is never the optimal
bit rate; each link always performed better with a higher bit rate.
This result leads us to believe that ACKs, which are sent at 1Mbit/s
in 802.11b/g, could possibly be sent at a higher bit rate, at least for
static nodes. This is the approach taken in 802.11a.
4.2 Distribution of Optimal Bit Rate with
SNR
Though Figure 3 shows that one SNR can have multiple optimal
bit rates over time, it does not give us any information about the
frequency with which each bit rate is optimal. It may be the case
that, for each SNR, one bit rate is the best 99% of the time over all
networks, in which case even a global look-up table would work
99% of the time.
To understand this notion better, we consider the following:
Given a particular percentile p, what is the smallest number of
unique bit rates needed to select the optimal bit rate p% of the
time? For example, if one bit rate was the best 67% of the time
for a given SNR and another was the best 30% of the time, then it
would take two bit rates to select the optimal bit rate 95% of the
time, but only one to select it 50% of the time.
Figure 4 shows this result for varying percentiles in each of our
three cases (per-network, per-AP, and per-link), for 802.11b/g net-
works. We can see from Figure 4(a) that a network-centric ap-
proach can still require more than three unique bit rates before it
is able to predict the optimal one with 95% accuracy. This implies
that a network-based look-up table would not be able to be at least
95% accurate in all cases. However, as we move to the per-AP
127d
e
d
e
e
N
s
e
t
a
R
t
i
B
f
o
r
e
b
m
u
N
 4
 3
 2
 1
 0
50%
80%
95%
 0
 10
 20
 30
 40
 50
SNR (dB)
 60
 70
 80
 90
d
e
d
e
e
N
s
e
t
a
R
t
i
B
f
o
r
e
b
m
u
N
 4
 3
 2
 1
 0
50%
80%