# 二、自动缩放 Kubernetes 集群的节点
May I say that I have not thoroughly enjoyed serving with humans? I find their illogic and foolish emotions a constant irritant.
- *史巴克*
**horizontalpodoautoscaler**(**HPA**)的使用是构建弹性、容错和高可用性系统的最关键方面之一。但是，如果没有具有可用资源的节点，这是没有用的。当 Kubernetes 因为没有足够的可用内存或中央处理器而无法调度新的 Pods 时，新的 Pods 将是不可调度的，并且处于挂起状态。如果我们不增加集群的容量，挂起的 Pods 可能会无限期地保持这种状态。为了让事情变得更复杂，Kubernetes 可能会开始移除其他 Pods，为那些处于挂起状态的 Pods 腾出空间。正如您可能已经猜到的那样，这可能会导致比我们的应用没有足够的副本来满足需求的问题更糟糕的问题。
Kubernetes 通过 Cluster Autoscaler 解决了节点伸缩的问题。
Cluster Autoscaler has a single purpose to adjust the size of the cluster by adding or removing worker nodes. It adds new nodes when Pods cannot be scheduled due to insufficient resources. Similarly, it eliminates nodes when they are underutilized for a period of time and when Pods running on one such node can be rescheduled somewhere else.
集群自动缩放器背后的逻辑很容易理解。我们还没有看到它是否也容易使用。
让我们创建一个集群(除非您已经有一个集群)，并为自动缩放做准备。
# 创建集群
我们将继续使用来自`vfarcic/k8s-specs`([https://github.com/vfarcic/k8s-specs](https://github.com/vfarcic/k8s-specs))存储库的定义。为了安全起见，我们先拉最新版本。
All the commands from this chapter are available in the `02-ca.sh` ([https://gist.github.com/vfarcic/a6b2a5132aad6ca05b8ff5033c61a88f](https://gist.github.com/vfarcic/a6b2a5132aad6ca05b8ff5033c61a88f)) Gist.
```
 1  cd k8s-specs
 2
 3  git pull
```
接下来，我们需要一个集群。请使用下面的 Gists 作为创建新集群或验证您已经满足所有要求的灵感。
A note to AKS users
At the time of this writing (October 2018), Cluster Autoscaler does not (always) work in **Azure Kubernetes Service** (**AKS**). Please jump to *Setting up Cluster Autoscaler in AKS* section for more info and the link to instructions how to set it up.
*   `gke-scale.sh` : **GKE** 带 3 个 n1-standard-1 工作节点，带 **tiller** ，带`--enable-autoscaling`参数([https://gist . github . com/vfarcic/9c 777487 F7 ebee 6c 09027 d3a 1 df 8663 c](https://gist.github.com/vfarcic/9c777487f7ebee6c09027d3a1df8663c))。
*   `eks-ca.sh` : **EKS** 带 3 个 T2 .小工人节点，带**分蘖**，带**度量服务器**([https://gist . github . com/vfarcic/3d fc71 DC 687 de 3 ed 98 E8 f 804 D7 abbob](https://gist.github.com/vfarcic/3dfc71dc687de3ed98e8f804d7abba0b))。
*   `aks-scale.sh` : **带有 3 个 Standard_B2s 工作节点的 AKS** 和带有**分蘖**([https://gist . github . com/vfarcic/f1b 05d 33 cc 8 a 98 e 4c eab 3d 3770 C2 feb](https://gist.github.com/vfarcic/f1b05d33cc8a98e4ceab3d3770c2fe0b))。
检查 Gists 时，您会注意到一些事情。首先，Docker for Desktop 和 minikube 不在那里。两者都是无法扩展的单节点集群。我们需要在可以按需添加和删除节点的地方运行集群。我们将不得不使用云供应商之一(例如，AWS、Azure、GCP)。这并不意味着我们不能扩展内部集群。
我们可以，但这取决于我们使用的供应商。有些人确实有解决办法，而有些人没有。为了简单起见，我们将坚持三大之一。请在**谷歌 Kuberentes 引擎** ( **GKE** )、亚马逊**Kubernetes 弹性容器服务**(**EKS**)或 **Azure Kubernetes 服务** ( **AKS** )之间进行选择。如果你不确定选择哪一个，我建议选择 GKE，因为它是最稳定和功能最丰富的托管 Kubernetes 集群。
您还会注意到，GKE 和 AKS Gists 与上一章相同，而 EKS 发生了变化。正如您已经知道的，前者已经有了度量服务器。EKS 没有，所以我复制了我们以前使用的 Gist，并添加了安装 Metrics Server 的说明。我们可能在本章中不需要它，但我们将在以后大量使用它，我希望您能习惯一直使用它。
如果您更喜欢在本地运行这些示例，您可能会对本章中我们将不使用本地集群的消息感到震惊。不要绝望。成本将保持在最低水平(总共可能只有几美元)，下一章我们将回到本地集群(除非您选择留在云中)。
现在我们在 GKE、EKS 或 AKS 有了一个集群，我们的下一步是启用集群自动扩展。
# 设置集群自动缩放
在开始使用集群自动缩放器之前，我们可能需要安装它。我说我们*可能*，而不是说我们*必须*，因为一些 Kubernetes 风味确实带有集群自动色卡，而其他的没有。我们将逐一介绍“三大”管理的 Kubernetes 集群。你可以选择探索这三个，或者跳到你更喜欢的一个。作为一种学习体验，我相信在所有三个提供商中体验运行 Kubernetes 是有益的。然而，这可能不是你的观点，你可能更喜欢只使用一个。选择权在你。
# 在 GKE 设置集群自动缩放器
这将是有史以来最短的部分。如果在创建集群时指定了`--enable-autoscaling`参数，那么在 GKE 就没什么可做的了。它已经带有预先配置好的集群自动缩放器。
# 在 EKS 设置集群自动缩放器
与 GKE 不同，EKS 没有集群自动缩放器。我们必须自己配置。我们需要向工作节点专用的自动缩放组添加一些标签，为我们正在使用的角色添加额外的权限，并安装集群自动缩放器。
我们走吧。
我们将向工作节点专用的自动缩放组添加一些标签。要做到这一点，我们需要发现该组的名称。由于我们使用 **eksctl** 创建了集群，因此名称遵循一种模式，我们可以使用该模式来过滤结果。另一方面，如果您在没有 eksctl 的情况下创建了 EKS 集群，那么逻辑应该仍然与下面的逻辑相同，尽管命令可能略有不同。
首先，我们将检索 AWS 自动缩放组的列表，并用`jq`过滤结果，以便只返回匹配组的名称。
```
 1  export NAME=devops25
 2
 3  ASG_NAME=$(aws autoscaling \
 4      describe-auto-scaling-groups \
 5      | jq -r ".AutoScalingGroups[] \
 6      | select(.AutoScalingGroupName \
 7      | startswith(\"eksctl-$NAME-nodegroup\")) \
 8      .AutoScalingGroupName")
 9
10 echo $ASG_NAME
```
后一个命令的输出应该类似于下面的命令。
```
eksctl-devops25-nodegroup-0-NodeGroup-1KWSL5SEH9L1Y
```
我们将集群的名称存储在环境变量`NAME`中。接下来，我们检索所有组的列表，并用`jq`过滤输出，以便只返回那些名称以`eksctl-$NAME-nodegroup`开头的组。最后，同一个`jq`命令检索了`AutoScalingGroupName`字段，并将其存储在环境变量`ASG_NAME`中。最后一个命令输出组名，以便我们可以(直观地)确认它看起来是正确的。
接下来，我们将向组中添加一些标签。Kubernetes 集群自动缩放器将与具有`k8s.io/cluster-autoscaler/enabled`和`kubernetes.io/cluster/[NAME_OF_THE_CLUSTER]`标签的集群一起工作。所以，我们所要做的就是添加这些标签，让 Kubernetes 知道使用哪个组。
```
 1  aws autoscaling \
 2      create-or-update-tags \
 3      --tags \
 4      ResourceId=$ASG_NAME,ResourceType=auto-scaling-group,Key=k8s.io/
    clusterautoscaler/enabled,Value=true,PropagateAtLaunch=true \
 5      ResourceId=$ASG_NAME,ResourceType=auto-scaling-
    group,Key=kubernetes.io/cluster/$NAME,Value=true,PropagateAtLaunch=true
```
我们在 AWS 中要做的最后一项更改是向通过 eksctl 创建的角色添加一些额外的权限。就像自动缩放组一样，我们不知道角色的名称，但是我们知道用来创建它的模式。因此，在向角色添加新策略之前，我们将检索角色的名称。
```
 1  IAM_ROLE=$(aws iam list-roles \
 2      | jq -r ".Roles[] \
 3      | select(.RoleName \
 4      | startswith(\"eksctl-$NAME-nodegroup-0-NodeInstanceRole\")) \
 5      .RoleName")
 6  
 7  echo $IAM_ROLE
```
后一个命令的输出应该类似于下面的命令。
```
eksctl-devops25-nodegroup-0-NodeInstanceRole-UU6CKXYESUES
```
我们列出了所有的角色，并使用`jq`过滤输出，以便只返回名称以`eksctl-$NAME-nodegroup-0-NodeInstanceRole`开头的角色。过滤角色后，我们检索`RoleName`并将其存储在环境变量`IAM_ROLE`中。
接下来，我们需要描述新策略的 JSON。我已经准备了一个，让我们快速看一下。
```
 1  cat scaling/eks-autoscaling-policy.json
```
输出如下。
```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "autoscaling:DescribeAutoScalingGroups",
        "autoscaling:DescribeAutoScalingInstances",
        "autoscaling:DescribeLaunchConfigurations",
        "autoscaling:DescribeTags",
        "autoscaling:SetDesiredCapacity",
        "autoscaling:TerminateInstanceInAutoScalingGroup"
      ],
      "Resource": "*"
    }
  ]
}
```
如果你熟悉 AWS(我希望你熟悉)，那么这个策略应该很简单。它允许一些与`autoscaling`相关的附加动作。
最后，我们可以`put`把新策略交给角色。
```
 1  aws iam put-role-policy \
 2      --role-name $IAM_ROLE \
 3      --policy-name $NAME-AutoScaling \
 4      --policy-document file://scaling/eks-autoscaling-policy.json
```
现在，我们向自动缩放组添加了所需的标签，并创建了允许 Kubernetes 与该组交互的附加权限，我们可以安装集群自动缩放掌舵图。
```
 1  helm install stable/cluster-autoscaler \
 2      --name aws-cluster-autoscaler \
 3      --namespace kube-system \
 4      --set autoDiscovery.clusterName=$NAME \
 5      --set awsRegion=$AWS_DEFAULT_REGION \