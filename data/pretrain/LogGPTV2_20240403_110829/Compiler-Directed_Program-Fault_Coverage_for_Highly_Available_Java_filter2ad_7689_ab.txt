observing a fault activation. For example, at the operat-
ing system level, the timeout and retry of a TCP socket
can easily mask transient hardware link errors, and thus no
application-level SocketException is ever thrown. Like-
wise, a mirrored ﬁle system can hide many types of SCSI
disk errors from the JVM. This effect must be considered in
the construction of our mapping of fault-operation pairs to
exceptions, and our coverage metric (deﬁned in Section 2.3)
accounts for this kind of lower-level fault handling.
Additionally, layering may cause latent errors. For ex-
ample, input buffering can allow numerous disk reads to
succeed after a fault, until all buffered data have been con-
sumed; at that point, if the fault is still active, a later read
may throw an exception. Likewise, the JVM may not ob-
serve socket exceptions for minutes, even in the face of total
link failure, because TCP attempts numerous retries in the
face of lost packets. In this case, data that was written dur-
2Java also has unchecked exceptions such as NullPointerException
that do not need explicit handling. These generally do not correspond to
the class of faults we are studying.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:06:14 UTC from IEEE Xplore.  Restrictions apply. 
ing the time of the fault may be lost, without causing any
exception (there may not be any more I/O operations by the
time TCP gives up). The potential for latent errors inﬂu-
ences the interpretation of our run-time collection of cover-
age data, in that we cannot assume that exceptions caused
by a fault that occurs during the execution of a given try
block will necessarily appear in the expected catch of that
particular try.
2.3 Fault-Catch Coverage
Given the complex relationship between faults and ex-
ceptions, we envision that any given testing effort would
begin by deﬁning an explicit universe of faults to be stud-
ied, which we call F . Each catch block in the program can
potentially be triggered by some subset3 of F that we call
f. On a given test run, some subset of f, which we call e,
will actually trigger this catch.
The program-fault coverage metric we have chosen for
our work is somewhat analogous to the all-defs metric, but
with faults playing the role of potentially deﬁning error
states, and catch blocks “using” the error states to perform
a recovery action.
Deﬁnition (Fault-catch Coverage Metric): Given a single
catch block c that can potentially be triggered by a subset
f of the fault universe F , and a set of test runs t in which
fault set e ⊆ f trigger exceptions that reach c, the Fault-
catch Coverage of c by t is
|e|
|f| .
We chose this deﬁnition over several other possibilities
for a variety of reasons – see [14] for details.
Our knowledge of which exceptions can possibly be han-
dled by which catch blocks is derived from a static rep-
resentation of the Java source or bytecodes, rather than
data from the executing program. Therefore, we are mak-
ing the usual assumption of compile-time program analysis,
namely, that every static path in the program representation
is actually executable. This may not be the case, so that if
we use a def-use type coverage metric from exception oc-
currence site to catch block, then we may include some in-
feasible def-use relations, which can never be covered. This
is a common problem in software testing as well; it is ad-
dressed by using as precise as possible program analysis to
eliminate infeasible paths where possible and by human ex-
amination.
There are several ways to produce aggregate information
about code that contains many catch blocks, such as an
entire application, a library, or a new unit of code that is
being added to a working application. Consider code with
n catch blocks c1...cn, in which ci can be triggered by
3This subset will exclude any faults that are not related to the opera-
tions in the associated try (i.e. the subset for a catch corresponding
to a try with no I/O operations would not include IOException).
Furthermore, we also exclude faults that will be handled by lower layers of
software (or hardware). The tester may also choose to exclude faults that
are not relevant due to program usage.
fault set fi, and a test t in which faults in set ei have each
produced an exception that reaches ci.
Deﬁnition (Average Fault-catch Coverage:): The average
of all the ratios
Deﬁnition (Overall Fault-catch Coverage:): The ratio of
the total numbers of tested and possible faults,
|ei|
|fi| .
(cid:1)n
|ei|(cid:1)n
|fi|
i=1
i=1
Deﬁnition (Fraction of Covered Catches): The fraction of
the catches for which | ei |=| fi |.
We leave as an open question under what circumstances
different aggregate measures are best, because we strongly
suspect that no single aggregate will capture all user needs.
We therefore envision the use of a language-aware soft-
ware tool (such as the Eclipse IDE [1]) that could maintain
the raw data about vulnerable operations, faults injected,
thrown exceptions and covered catches. This tool could
then present whatever metric is chosen by the tester, or even
help the tester identify inadequately tested catch blocks or
faults for which little testing has been done.
2.4 Measuring Fault-catch Coverage
The set of faults that may be associated with each catch
does not vary from test to test, and can thus be computed
statically. Unfortunately, an analysis based on the type
of exception declared in the catch could produce a dra-
matic overestimate of fi for many catches, since the de-
clared type may be a supertype that subsumes many ex-
ceptions that cannot actually be thrown. This same effect
applies to the exception types declared by methods called
in the try block. Thus, to overestimate as little as possi-
ble, we perform an interprocedural analysis of the code in
the try block. Intuitively, using the calling structure of the
program, we ﬁnd a primitive operation that actually throws
an exception and then propagate it backwards on the calling
structure to ﬁnd its list of callers, stopping at the “nearest”
try block. Details of this analysis are left for Section 3.
Information about the faults that actually trigger each
catch must be collected separately for each run. We
do this by instrumenting each catch block to record its
identiﬁer, the class of exception that reached it, and the
fault associated with the exception. We do not currently
record the source (e.g., throw) of the exception, but we
could in principle do so using the JDK method Throw-
able.printStackTrace().
Note that our current experimental system simply
records the fault that is currently being injected. This re-
quires communication with the fault-injection engine (see
Section 3.2), and is most easily accomplished if there is
never more than one (simultaneous) fault injected (as in the
experiment in Section 4). Furthermore, our current system
cannot actually guarantee that the injected fault caused the
exception. For example, if we inject a disk fault in one
block, but for some other reason an IOException occurs,
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:06:14 UTC from IEEE Xplore.  Restrictions apply. 
we will record that the injected fault reached the catch
block. We do not expect this effect to be signiﬁcant (we
have never observed it in our tests), but if it proves to be a
problem, we will explore systems for tracking information
about injected faults across the program/system boundary.
3
Injecting Faults to Improve Coverage
We now consider how the compiler can instrument appli-
cation code to communicate with a fault-injection engine at
run-time, in order to direct the fault-injection process to ob-
tain high program-fault coverage as measured by our met-
ric. Speciﬁcally, we use Mendosus as our fault-injection in-
frastructure, but our approach could, in principle, be applied
using any fault-injection system that can inject the faults we
study.
For this work, we have extended Mendosus with an API
for dynamic external direction as to when speciﬁc faults
should be injected. Previously, Mendosus injected faults
according to a pre-determined script comprised of traces
and/or random distributions. Our basic approach currently
is to identify a statement inside a try block, where the soft-
ware has committed to the execution of some vulnerable
operation (such as a read from a ﬁle), but before the op-
eration itself is performed. At this program point, we in-
sert instrumentation to select an appropriate fault and to di-
rect Mendosus to inject this fault, using the API described
in Section 3.2. Once execution reaches the corresponding
catch block, or the end of the try block, we direct Men-
dosus to cancel the injected fault.
We currently inject only one fault per run of the program,
using multiple single-fault runs to obtain high coverage.
Our techniques could be used to inject multiple faults per
run, but we have no way of measuring the interactions be-
tween faults, and thus have not explored this approach. Our
choice of the “single-fault-per-run” approach could poten-
tially prevent us from covering a catch clause in code that
can only be reached after the recovery from a prior fault, but
we do not expect this to be a problem in practice.
We could, in principle, trigger a catch block by sim-
ply replacing a vulnerable operation with a throw of an
appropriate exception. However, this approach would pro-
duce results that differ from a true fault in several important
ways: it would only affect one thread on a multi-threaded
or multi-node application, subsequent accesses to the hard-
ware that is supposed to have failed would (inappropriately)
work, and the effects of lower-level recovery strategies (in
the operating system, libraries, etc.) would be lost.
In general, Mendosus may require advanced warning of
the fault to be injected, in case it impacts multiple nodes in a
distributed application. For this reason, we move the instru-
mentation backward in the code as far as we can, possibly
all the way to the beginning of the try block, although no
farther because we want to plant the fault only when it has a
chance of exercising the speciﬁc catch block of interest to
obtain coverage. In the future, we may investigate the use
of proﬁling techniques to provide an estimate, for speciﬁc
program points, of the amount of time until the vulnerable
operation will be triggered; it is not clear that accurate tim-
ing information will be needed.
3.1 Compiler Analyses
Two dataﬂow analyses allow us to accomplish both the
communication with Mendosus and the recording of the
fault-catch coverage achieved. Both are performed on Java
bytecodes, so we can apply them whether or not source code
is available. The ﬁrst analysis, exception handler analysis,
essentially traces backwards from an excepting operation
(or call) in the Java code to its handler which will be on the
call stack when the exception occurs. The second analysis,
resource points-to analysis, ﬁnds all objects reachable from
the (ﬁelds of) actual arguments in a method call; this analy-
sis is necessary to give access to objects such as ﬁle descrip-
tors, which may result in excepting computations during the
lifetime of this method call.
Exception handler analysis uses a compile-time repre-
sentation of the program call tree [29] to guide the back-
wards search from an exception occurrence point to a han-
dler. The call tree records the sequence of method calls that
may occur during execution in a tree structure. Its nodes
are methods and its edges connect the calling method with
the called method (annotated by the call site). The call tree
can be approximated by compile-time class analysis [33, 6,
12, 15] or reference points-to analysis [27, 22, 24]. The
exception occurrence point may be either a Java library call
whose JNI routines generate the exception or a speciﬁc Java
method call which throws the exception (and does not han-
dle it). By searching backwards on the call tree, we can ﬁnd
the closest exception handler for the exception, according to
Java exception semantics[4]. The backwards search on the
call tree requires us to examine each method call to ascer-
tain whether or not it is included in a try block that handles
the exception type whose handler we seek.
Once we ﬁnd the handler, the associated method call in
the try block becomes the focus of our placement of com-
munication with Mendosus; the type of fault requested de-
pends on the operation(s) at the exception occurrence. In the
actual implementation of our prototype, we will use an ap-
proximation of the call tree, a potentially exponential-sized
structure; possible choices to be investigated include a call-
ing context tree [5] or a call graph with annotations about
call site locations within its nodes (i.e., methods). We plan
to experiment with these different program representations
in order to balance analysis cost with accuracy.
Resource points-to analysis allows us to ﬁnd the spe-
ciﬁc object on which the excepting computation occurs;
this is necessary to determine the set of possible faults to
be injected. Points-to analysis enables approximation at
compile-time of the set of objects to which some reference
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:06:14 UTC from IEEE Xplore.  Restrictions apply. 
variable can point at run-time. When the solutions at dis-
tinct method call sites are differentiated by the analysis so
that different points-to information can be associated with
them, then the analysis is termed context-sensitive. We will
use a context-sensitive reference points-to analysis to ascer-
tain those objects necessary for the vulnerable operation,
even if references to them are stored in ﬁelds of other ob-
jects. We need the type of the object to select appropriate
faults to inject; however, it may not be possible to deter-
mine the appropriate set of faults to inject until run-time,
because they are determined by the run-time type of an ob-
ject. For example, an open InputStream may correspond
to a FileInputStream, in which case disk faults are ap-
propriate, or it may correspond to an input stream from a
socket, in which case network faults are appropriate. We
will use the reﬂection library in the JDK to determine these
types at run-time. This library allows run-time examination
of object properties such as type and value. We need values
for some of the object’s ﬁelds to provide to Mendosus (e.g.,
the ﬁle descriptor for an input stream).
These two analyses, described above, pinpoint the con-
structs in the application that we must instrument. The ﬁrst
identiﬁes both the try blocks into which we insert fault-
injection and cancellation code and the associated catch
blocks that we instrument to measure coverage. The second
analysis provides information about the objects involved,
which is needed to select appropriate fault types and pa-
rameters for communicating with Mendosus, as well as in-
formation that is needed to analyze method calls in order to
construct the call tree.
3.2
Instrumentation-Driven Fault Injection API
In the instrumented application code, we need to inform
Mendosus to inject a fault or to cancel a previously injected
fault. The kind of fault determines the appropriate parame-
ters needed. To facilitate the communication with Mendo-
sus, we implemented a user-level client Java library export-
ing the following methods:
public static boolean inject(int fault-
Type, int interval, SomeList parameters)
This method requests an injection of a fault of type fault-
Type, which will expire after interval number of
seconds. The faultType is determined using the run-time
type of the object (e.g., ﬁle descriptor or a communication
socket), as a key into a list of fault types provided by
Mendosus.
The parameter list parameters contains
additional information to guide Mendosus in the injection
of the fault,4 such as the ﬁle descriptor. The boolean return