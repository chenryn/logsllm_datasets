### Observing Fault Activation

At the operating system level, mechanisms such as TCP socket timeouts and retries can mask transient hardware link errors, preventing the application from throwing a `SocketException`. Similarly, a mirrored file system can hide many types of SCSI disk errors from the JVM. This masking effect must be considered when mapping fault-operation pairs to exceptions and in defining our coverage metric (detailed in Section 2.3), which accounts for lower-level fault handling.

Additionally, layering can cause latent errors. For example, input buffering may allow numerous disk reads to succeed after a fault, until all buffered data is consumed. At that point, if the fault persists, a subsequent read may throw an exception. Similarly, the JVM may not observe socket exceptions for minutes, even in the case of total link failure, because TCP attempts multiple retries in the face of lost packets. In this scenario, data written during the fault may be lost without causing any exception, especially if there are no further I/O operations by the time TCP gives up. The potential for latent errors influences the interpretation of our runtime coverage data, as we cannot assume that exceptions caused by a fault during a given `try` block will necessarily appear in the corresponding `catch` block.

### 2.3 Fault-Catch Coverage

Given the complex relationship between faults and exceptions, we propose that any testing effort should begin by defining an explicit set of faults to be studied, denoted as \( F \). Each `catch` block in the program can potentially be triggered by a subset of \( F \), which we call \( f \). During a test run, a subset of \( f \), denoted as \( e \), will actually trigger the `catch` block.

**Definition (Fault-catch Coverage Metric):** Given a single `catch` block \( c \) that can potentially be triggered by a subset \( f \) of the fault universe \( F \), and a set of test runs \( t \) in which fault set \( e \subseteq f \) triggers exceptions that reach \( c \), the Fault-catch Coverage of \( c \) by \( t \) is defined as:

\[
\text{Fault-catch Coverage} = \frac{|e|}{|f|}
\]

We chose this definition over other possibilities for various reasons, detailed in [14].

Our knowledge of which exceptions can be handled by which `catch` blocks is derived from a static representation of the Java source or bytecodes, rather than from runtime data. Therefore, we assume that every static path in the program representation is executable, though this may not always be the case. Using a def-use type coverage metric from the exception occurrence site to the `catch` block may include infeasible def-use relations, which can never be covered. This common problem in software testing is addressed by using precise program analysis to eliminate infeasible paths where possible and by human examination.

To produce aggregate information about code with many `catch` blocks, such as an entire application, library, or new unit of code, consider code with \( n \) `catch` blocks \( c_1, c_2, \ldots, c_n \), where each \( c_i \) can be triggered by fault set \( f_i \), and a test \( t \) in which faults in set \( e_i \) have each produced an exception that reaches \( c_i \).

**Definition (Average Fault-catch Coverage):** The average of all the ratios:

\[
\text{Average Fault-catch Coverage} = \frac{1}{n} \sum_{i=1}^{n} \frac{|e_i|}{|f_i|}
\]

**Definition (Overall Fault-catch Coverage):** The ratio of the total numbers of tested and possible faults:

\[
\text{Overall Fault-catch Coverage} = \frac{\sum_{i=1}^{n} |e_i|}{\sum_{i=1}^{n} |f_i|}
\]

**Definition (Fraction of Covered Catches):** The fraction of the catches for which \( |e_i| = |f_i| \):

\[
\text{Fraction of Covered Catches} = \frac{|\{c_i \mid |e_i| = |f_i|\}|}{n}
\]

We leave open the question of which aggregate measures are best under different circumstances, as no single aggregate is likely to capture all user needs. We envision the use of a language-aware software tool (such as the Eclipse IDE [1]) that could maintain raw data about vulnerable operations, injected faults, thrown exceptions, and covered `catch` blocks. This tool could present the chosen metric and help identify inadequately tested `catch` blocks or faults with insufficient testing.

### 2.4 Measuring Fault-catch Coverage

The set of faults that may be associated with each `catch` does not vary from test to test and can be computed statically. However, an analysis based on the type of exception declared in the `catch` could overestimate \( f_i \) for many `catch` blocks, as the declared type may be a supertype that subsumes many exceptions that cannot actually be thrown. To minimize overestimation, we perform an interprocedural analysis of the code in the `try` block. Intuitively, using the calling structure of the program, we find a primitive operation that actually throws an exception and propagate it backward on the calling structure to find its list of callers, stopping at the "nearest" `try` block. Details of this analysis are provided in Section 3.

Information about the faults that actually trigger each `catch` must be collected separately for each run. We instrument each `catch` block to record its identifier, the class of the exception that reached it, and the fault associated with the exception. Currently, we do not record the source (e.g., `throw`) of the exception, but this could be done using the JDK method `Throwable.printStackTrace()`.

Note that our current experimental system simply records the fault currently being injected, requiring communication with the fault-injection engine (see Section 3.2). This is most easily accomplished if there is never more than one simultaneous fault injected, as in the experiment in Section 4. Our current system cannot guarantee that the injected fault caused the exception. For example, if we inject a disk fault in one block, but an `IOException` occurs for another reason, we will still record that the injected fault reached the `catch` block. This effect is not expected to be significant, but if it proves problematic, we will explore systems for tracking injected faults across the program/system boundary.

### 3 Injecting Faults to Improve Coverage

We now consider how the compiler can instrument application code to communicate with a fault-injection engine at runtime to direct the fault-injection process and achieve high program-fault coverage as measured by our metric. Specifically, we use Mendosus as our fault-injection infrastructure, but our approach could, in principle, be applied using any fault-injection system that can inject the faults we study.

For this work, we have extended Mendosus with an API for dynamic external direction as to when specific faults should be injected. Previously, Mendosus injected faults according to a predetermined script comprised of traces and/or random distributions. Our basic approach is to identify a statement inside a `try` block where the software has committed to executing a vulnerable operation (such as a file read), but before the operation itself is performed. At this program point, we insert instrumentation to select an appropriate fault and direct Mendosus to inject this fault using the API described in Section 3.2. Once execution reaches the corresponding `catch` block or the end of the `try` block, we direct Mendosus to cancel the injected fault.

We currently inject only one fault per run of the program, using multiple single-fault runs to achieve high coverage. Our techniques could be used to inject multiple faults per run, but we have no way of measuring the interactions between faults and thus have not explored this approach. Our "single-fault-per-run" approach could potentially prevent us from covering a `catch` clause that can only be reached after recovery from a prior fault, but we do not expect this to be a problem in practice.

We could, in principle, trigger a `catch` block by simply replacing a vulnerable operation with a `throw` of an appropriate exception. However, this approach would differ from a true fault in several important ways: it would only affect one thread in a multi-threaded or multi-node application, subsequent accesses to the failed hardware would (inappropriately) work, and the effects of lower-level recovery strategies (in the operating system, libraries, etc.) would be lost.

In general, Mendosus may require advanced warning of the fault to be injected, especially if it impacts multiple nodes in a distributed application. For this reason, we move the instrumentation as far back in the code as possible, possibly all the way to the beginning of the `try` block, but no farther, to ensure the fault has a chance of exercising the specific `catch` block of interest to obtain coverage. In the future, we may investigate the use of profiling techniques to estimate the amount of time until the vulnerable operation is triggered, though it is not clear that accurate timing information will be needed.

### 3.1 Compiler Analyses

Two dataflow analyses enable us to accomplish both the communication with Mendosus and the recording of fault-catch coverage achieved. Both are performed on Java bytecodes, so they can be applied whether or not source code is available.

1. **Exception Handler Analysis:** This analysis traces backward from an excepting operation (or call) in the Java code to its handler, which will be on the call stack when the exception occurs.
2. **Resource Points-to Analysis:** This analysis finds all objects reachable from the fields of actual arguments in a method call, necessary to give access to objects such as file descriptors, which may result in excepting computations during the lifetime of the method call.

**Exception Handler Analysis:** Uses a compile-time representation of the program call tree [29] to guide the backward search from an exception occurrence point to a handler. The call tree records the sequence of method calls that may occur during execution in a tree structure. Its nodes are methods, and its edges connect the calling method with the called method (annotated by the call site). The call tree can be approximated by compile-time class analysis [33, 6, 12, 15] or reference points-to analysis [27, 22, 24]. The exception occurrence point may be either a Java library call whose JNI routines generate the exception or a specific Java method call that throws the exception (and does not handle it). By searching backward on the call tree, we can find the closest exception handler for the exception, according to Java exception semantics [4]. The backward search on the call tree requires examining each method call to determine whether it is included in a `try` block that handles the exception type sought.

Once we find the handler, the associated method call in the `try` block becomes the focus of our placement of communication with Mendosus; the type of fault requested depends on the operation(s) at the exception occurrence. In the actual implementation of our prototype, we will use an approximation of the call tree, a potentially exponential-sized structure. Possible choices to be investigated include a calling context tree [5] or a call graph with annotations about call site locations within its nodes (i.e., methods). We plan to experiment with these different program representations to balance analysis cost with accuracy.

**Resource Points-to Analysis:** Allows us to find the specific object on which the excepting computation occurs, necessary to determine the set of possible faults to be injected. Points-to analysis enables approximation at compile-time of the set of objects to which some reference variable can point at runtime. When the solutions at distinct method call sites are differentiated by the analysis so that different points-to information can be associated with them, the analysis is termed context-sensitive. We will use a context-sensitive reference points-to analysis to ascertain those objects necessary for the vulnerable operation, even if references to them are stored in fields of other objects. We need the type of the object to select appropriate faults to inject; however, it may not be possible to determine the appropriate set of faults to inject until runtime, as they are determined by the runtime type of an object. For example, an open `InputStream` may correspond to a `FileInputStream`, in which case disk faults are appropriate, or it may correspond to an input stream from a socket, in which case network faults are appropriate. We will use the reflection library in the JDK to determine these types at runtime. This library allows runtime examination of object properties such as type and value. We need values for some of the object's fields to provide to Mendosus (e.g., the file descriptor for an input stream).

These two analyses pinpoint the constructs in the application that we must instrument. The first identifies both the `try` blocks into which we insert fault-injection and cancellation code and the associated `catch` blocks that we instrument to measure coverage. The second analysis provides information about the objects involved, which is needed to select appropriate fault types and parameters for communicating with Mendosus, as well as information needed to analyze method calls to construct the call tree.

### 3.2 Instrumentation-Driven Fault Injection API

In the instrumented application code, we need to inform Mendosus to inject a fault or to cancel a previously injected fault. The kind of fault determines the appropriate parameters needed. To facilitate communication with Mendosus, we implemented a user-level client Java library exporting the following methods:

```java
public static boolean inject(int faultType, int interval, SomeList parameters)
```

This method requests the injection of a fault of type `faultType`, which will expire after `interval` number of seconds. The `faultType` is determined using the runtime type of the object (e.g., file descriptor or communication socket) as a key into a list of fault types provided by Mendosus. The parameter list `parameters` contains additional information to guide Mendosus in the injection of the fault, such as the file descriptor. The boolean return value indicates whether the injection was successful.