settings when roaming
TABLE I
FELT ET AL. PROPOSED GRANTING A SELECT SET OF 12 PERMISSIONS AT
RUNTIME SO THAT USERS HAVE CONTEXTUAL INFORMATION TO INFER
WHY THE DATA MIGHT BE NEEDED [15]. OUR INSTRUMENTATION OMITS
THE LAST TWO PERMISSION TYPES (INTERNET & WRITE_SYNC_SETTINGS)
AND RECORDS INFORMATION ABOUT THE OTHER 10.
responses to permission prompts. They also observed that
privacy decisions were highly nuanced, demonstrating that a
one-size-ﬁts-all model is unlikely to be sufﬁcient; a given
information ﬂow may be deemed appropriate by one user but
not by another user. They recommended applying machine
learning in order to infer individual users’ privacy preferences.
To achieve this, research is needed to determine what factors
affect user privacy decisions and how to use those factors to
make privacy decisions on the user’s behalf. While we cannot
automatically capture everything involved in Nissenbaum’s
notion of context, we can try to detect when context has
likely changed (insofar as to decide whether a different privacy
decision should be made for the same application and data
type), by seeing whether the circumstances surrounding a data
request are similar to previous requests.
III. METHODOLOGY
We collected data from 131 participants to understand what
factors could be used to infer whether a permission request is
likely to be deemed appropriate by the user.
Previous work by Felt et al. made the argument that certain
permissions are appropriate for runtime prompts, because they
protect sensitive resources and because viewing the prompt
at runtime imparts additional contextual information about
why an application might need the permission [15]. Similarly,
Thompson et al. showed that other permission requests could
be replaced with audit mechanisms, because they represent
either reversible changes or are sufﬁciently low risk to not
warrant habituating the user to prompts [41]. We collected
information about 10 of the 12 permissions Felt et al. suggest
are best-suited for runtime prompts. We omitted INTERNET
and WRITE_SYNC_SETTINGS, because those permissions only
warrant runtime prompts if the user is roaming and we did not
expect any participant to be roaming during the study period,
and focused on the remaining 10 permission types (Table I).
While there are many other sensitive permissions beyond this
1079
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:17 UTC from IEEE Xplore.  Restrictions apply. 
Type
Behavioral
Instrumentation
Runtime
Information
Permission
Requests
Event Recorded
Changing developer options
Opening/Closing security settings
Changing security settings
Enabling/Disabling NFC
Changing location mode
Opening/Closing location settings
Changing screen-lock type
Use of two factor authentication
Log initial settings information
User locks the screen
Screen times out
App locks the screen
Audio mode changed
Enabling/Disabling speakerphone
Connecting/Disconnecting headphones
Muting the phone
Taking an audio call
Taking a picture (front- vs. rear-facing)
Visiting an HTTPS link in Chrome
Responding to a notiﬁcation
Unlocking the phone
An application changing the visibility
Platform switches to a new activity
An app requests a sensitive permission
ESM prompt for a selected permission
Fig. 1. A screenshot of an ESM prompt.
INSTRUMENTED EVENTS THAT FORM OUR FEATURE SET
TABLE II
set, Felt et al. concluded that the others are best handled by
other mechanisms (e.g., install-time prompts, ACGs, etc.).
We used the Experience Sampling Method (ESM) to collect
ground truth data about users’ privacy preferences [20]. ESM
involves repeatedly questioning participants in situ about a
recently observed event; in this case, we probabilistically asked
them about an application’s recent access to data on their
phone, and whether they would have permitted it if given the
choice. We treated participants’ responses to these ESM probes
as our main dependent variable (Figure 1).
We also instrumented participants’ smartphones to obtain
data about their privacy-related behaviors and the frequency
with which applications accessed protected resources. The
instrumentation required a set of modiﬁcations to the Android
operating system and ﬂashing a custom Android version onto
participants’ devices. To facilitate such experiments, the Uni-
versity of Buffalo offers non-afﬁliated academic researchers
access to the PhoneLab panel [33], which consists of more
than 200 participants. All of these participants had LG Nexus
5 phones running Android 5.1.1 and the phones were periodi-
cally updated over-the-air (OTA) with custom modiﬁcations to
the Android operating system. Participants can decide when to
install the OTA update, which marks their entry into new ex-
periments. During our experiment period, different participants
installed the OTA update with our instrumentation at different
times, thus we have neither data on all PhoneLab participants
nor data for the entire period. Our OTA update was available to
participants for a period of six weeks, between February 2016
and March 2016. At the end of the study period, we emailed
participants a link to an exit survey to collect demographic
information. Our study received institutional review board
(IRB) approval.1
A. Instrumentation
The goal of our instrumentation was to collect as much
runtime and behavioral data as could be observed from the An-
droid platform, with minimal performance cost. We collected
three categories of data: behavioral information, runtime infor-
mation, and user decisions. We made no modiﬁcations to any
third-party application code; our dynamic analysis techniques
could be used on any third-party Android application.
Table II contains the complete list of behavioral and runtime
events our instrumentation recorded. The behavioral data fell
under several categories, all chosen based on several hypothe-
ses that we had about the types of behaviors that might cor-
relate with privacy preferences: web-browsing habits, screen
locking behavior, third-party application usage behavior, audio
preferences, call habits, camera usage patterns, and behavior
related to security settings. For example, we hypothesized that
someone who manually locks their device screen are more
privacy-conscious than someone who lets it time out.
We also collected runtime information about the context of
each permission request, including the visibility of the request-
ing application at the time of request, what the user was doing
when the request was made (i.e., the name of the foreground
application), and the exact Android API function invoked by
the application to determine what information was requested..
The visibility of an application reﬂects the extent to which the
1Approved by the UC Berkeley IRB under protocol #2013-02-4992
1080
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:17 UTC from IEEE Xplore.  Restrictions apply. 
user was likely aware that the application was running; if the
application was in the foreground, the user had cues that the
application was running, but if it was in the background, then
the user was likely not aware that the application was running
and therefore might ﬁnd the permission request unexpected—
some background services can still be visible to the user due to
on-screen notiﬁcation or other cues that could be perceptible.
We monitored processes’ memory priority levels to determine
the visibility of all Android processes. We also collected
information about which Android Activity was active in
the application.2
Once per day we probabilistically selected one of these
permission requests and prompted the user about them at
runtime (Figure 1). We used weighted reservoir sampling to
select a permission request to prompt about. We weight the
combination of application, permission, visibility based on
their frequency of occurrence seen by the instrumentation; the
most-frequent combination has a higher probability of being
shown to participants using ESM. We prompted participants
a maximum of three times for each unique combination. We
tuned the wording of the prompt to make it clear that the
request had just occurred and their response would not affect
the system (a deny response would not actually deny data).
These responses serve as the ground truth for all the analysis
mentioned in the remainder of the paper.
The intuition behind using weighted reservoir sampling is
to focus more on the frequently occurring permission requests
over rare ones. Common permission requests contribute most
to user habituation due to their high frequency. Thus, it is
more important to learn about user privacy decisions on highly
frequent permission requests over the rare ones, which might
not risk user habituation or annoyance (and the context of rare
requests may be less likely to change).
B. Exit Survey
At the end of our data collection period, PhoneLab staff
emailed participants a link to our online exit survey, which
they were incentivized to complete with a rafﬂe for two $100
Amazon gift cards. The survey gathered demographic informa-
tion and qualitative information on their privacy preferences.
Of the 203 participants in our experiment, 53 fully completed
the survey, and another 14 partially completed it. Of the 53
participants to fully complete the survey, 21 were male, 31
were female, and 1 undisclosed. Participants ranged from
20 to 72 years of age (μ = 40.83, σ = 14.32). Participants
identiﬁed themselves as 39.3% staff, 32.1% students, 19.6%
faculty, and 9% other. Only 21% of the survey respondents
had an academic qualiﬁcation in STEM, which suggests that
the sample is unlikely to be biased towards tech-savvy users.
C. Summary
We collected data from February 5 to March 17, 2016.
PhoneLab allows any participant to opt-out of an experiment
at any time. Thus, of the 203 participants who installed our
2An Android Activity represents the application screen and UI elements
currently exposed to the user.
custom Android build, there were 131 who used it for more
than 20 days. During the study period, we collected 176M
events across all participants (31K events per participant/day).
Our dataset consists of 1,686 unique applications and 13K
unique activities. Participants also responded to 4,636 prompts
during the study period. We logged 96M sensitive permission
requests, which translates to roughly one sensitive permission
request every 6 seconds per participant. For the remainder of
the paper, we only consider the data from the 131 participants
who used the system for at least 20 days, which corresponds
to 4,224 ESM prompts.
Of the 4,224 prompts, 55.3% were in response to AC-
CESS_WIFI_STATE, when trying to access WiFi SSID informa-
tion that could be used to infer the location of the smartphone;
21.0%, 17.3%, 5.08%, 0.78%, and 0.54% were from accessing
location directly, reading SMS, sending SMS, reading call
logs, and accessing browser history, respectively. A total of
137 unique applications triggered prompts during the study
period. Of the 4,224 prompts, participants wanted to deny
60.01% of them, and 57.65% of the prompts were shown when
the requesting application was running in the foreground or
the user had visual cues that the application was running (e.g.,
notiﬁcations). A Wilcoxon signed rank test with continuity
correction revealed a statistically signiﬁcant difference in par-
ticipants’ desire to allow or deny a permission request based
on the visibility of the requesting application (p < 0.0152,
r = 0.221), which corroborates previous ﬁndings [43].
IV. TYPES OF USERS
We hypothesized that there may be different types of users
based on how they want to disclose their private information
to third parties. It is imperative to identify these different
sub-populations since different permission models affect users
differently based on their privacy preferences; performance
numbers averaged across a user population could be mislead-
ing since different sub-populations might react differently to
the same permission model.
While our study size was too small to effectively apply
clustering techniques to generate classes of users, we did
ﬁnd a meaningful distinction using the denial rate (i.e., the
percentage of prompts to which users wanted to deny access).
We aggregated users by their denial rate in 10% increments
and examined how these different participants considered the
surrounding contextual circumstances in their decisions.
We discovered that application visibility was a signiﬁcant
factor for users with a denial rate of 10–90%, but not for
users with a denial rate of 0–10% or 90–100%. We call
the former group Contextuals, as they seem to care about
the surrounding context (i.e., they make nuanced decisions,
allowing or denying a permission request based on whether
they had contextual cues that indicated that the requesting
application was running), and the latter group Defaulters,
because they seem to simply always allow or always deny
requests, regardless of contextual cues.
Defaulters accounted for 53% of 131 participants and Con-
textuals accounted for 47%. A Wilcoxon signed-rank test with
1081
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:17 UTC from IEEE Xplore.  Restrictions apply. 
i
s
t
n
a
p
c
i
t
r
a
P
f
o
r
e
b
m
u
N
15
10
5
0
Category
Contextuals
Defaulters
0
25
50
Denial Rate
75
100
Fig. 2. Histogram of users based on their denial rate. Defaulters tended to
allow or deny almost all requests without regard for contextual cues, whereas
Contextuals considered the visibility of the requesting application.
Policy
AOI
AOFU-AP
AOFU-APV
AOFU-AF PV
AOFU-VP
AOFU-VA
AOFU-A
AOFU-P
AOFU-V
Contextuals Defaulters Overall
6.00% 25.00%
93.33% 84.61%
92.85% 83.33%
98.95% 84.61%
94.44% 78.04%
93.75% 84.21%
93.54% 83.33%