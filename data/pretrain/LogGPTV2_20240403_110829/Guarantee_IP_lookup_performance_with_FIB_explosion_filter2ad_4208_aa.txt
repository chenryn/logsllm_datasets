title:Guarantee IP lookup performance with FIB explosion
author:Tong Yang and
Gaogang Xie and
Yanbiao Li and
Qiaobin Fu and
Alex X. Liu and
Qi Li and
Laurent Mathy
Guarantee IP Lookup Performance with FIB Explosion
Tong Yang,Gaogang Xie*
PI:EMAIL,
ICT, CAS, China.
*PI:EMAIL
YanBiao Li
Hunan University, China
PI:EMAIL
Alex X. Liu
Department of Computer
Science and Engineering,
Michigan State University
PI:EMAIL
Qi Li
ICT, CAS, China
PI:EMAIL
Qiaobin Fu
ICT, CAS, China
PI:EMAIL
Laurent Mathy
University of Liege, Belgium
PI:EMAIL
ABSTRACT
The Forwarding Information Base (FIB) of backbone routers
has been rapidly growing in size. An ideal IP lookup algo-
rithm should achieve constant, yet small, IP lookup time
and on-chip memory usage. However, no prior IP lookup
algorithm achieves both requirements at the same time. In
this paper, we ﬁrst propose SAIL, a Splitting Approach to IP
Lookup. One splitting is along the dimension of the lookup
process, namely ﬁnding the preﬁx length and ﬁnding the
next hop, and another splitting is along the dimension of
preﬁx length, namely IP lookup on preﬁxes of length less
than or equal to 24 and IP lookup on preﬁxes of length
longer than 24. Second, we propose a suite of algorithms
for IP lookup based on our SAIL framework. Third, we im-
plemented our algorithms on four platforms: CPU, FPGA,
GPU, and many-core. We conducted extensive experiments
to evaluate our algorithms using real FIBs and real traﬃc
from a major ISP in China. Experimental results show that
our SAIL algorithms are several times or even two orders of
magnitude faster than well known IP lookup algorithms.
Categories and Subject Descriptors
C.2.6 [Internetworking]: Routers; C.2.1 [Computer-
Communication Networks]: Network Architecture and
Design—Store and forward networks
Keywords
IP Lookup; SAIL; Virtual Router Multi-FIB Lookup; LPM
INTRODUCTION
1.
1.1 Background and Motivation
The growth of FIB sizes on backbone routers has been
accelerating. According to the RIPE Network Coordina-
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
SIGCOMM’14, August 17–22, 2014, Chicago, IL, USA.
Copyright 2014 ACM 978-1-4503-2836-4/14/08 ...$15.00.
http://dx.doi.org/10.1145/2619239.2626297.
tion Centre, FIB sizes have become about half a million
entries [3]. At the same time, cloud computing and network
applications have driven the expectation on router through-
put to the scale of 200 Gbps. The fast growth of FIB sizes
and throughput demands bring signiﬁcant challenges to IP
lookup (i.e., FIB lookup). An ideal IP lookup algorithm
should satisfy the following two harsh requirements. First,
IP lookup time should meet wire speed yet remain constant as
FIB sizes grow. IP lookup time is per packet cost and should
be optimized to the extreme to meet wire speed. Second,
on-chip memory usage should meet capacity constraints yet
remain constant as FIB sizes grow. On-chip memory (such
as CPU cache and FPGA block RAM) is about 10 times
faster than oﬀ-chip DRAM [9], but is limited in size (in the
scale of a few MB) and much more expensive than DRAM;
furthermore, as on-chip memory technologies advance, its
sizes do not grow much as compared to DRAM. Without
satisfying these two requirements, router performance will
degrade as FIB grows, and router hardware will have to be
upgraded periodically.
1.2 Summary and Limitations of Prior Art
IP lookup has long been a core networking issue and var-
ious schemes have been proposed. However, none of them
satisﬁes the two requirements of both constant lookup time
and constant on-chip memory usage. Some algorithms can
achieve constant IP lookup time, such as TCAM based
schemes [11,19] and FPGA based schemes [14, 16], but their
on-chip memory usage will grow quickly as FIB sizes grow.
Some algorithms, such as full-expansion [31] and DIR-24-
8 [13], can achieve constant memory usage by simply push-
ing all preﬁxes to levels 24 and 32, but even the lookup table
for level 24 alone is too large to be stored in on-chip memory.
1.3 Proposed SAIL Approach
In this paper, we propose SAIL, a Splitting Approach to
IP Lookup. We split the IP lookup problem along two di-
mensions as illustrated in Figure 1. First, we split the IP
lookup problem into two sub-problems along the dimension
of the lookup process: ﬁnding the preﬁx length (i.e., ﬁnd-
ing the length of the longest preﬁx that matches the given
IP address) and ﬁnding the next hop (i.e., ﬁnding the nex-
t hop of this longest matched preﬁx). This splitting gives
us the opportunity of solving the preﬁx length problem in
on-chip memory and the next hop problem in oﬀ-chip mem-
ory. Furthermore, since on-chip and oﬀ-chip memory are
39two entities, this splitting allows us to potentially pipeline
the processes of ﬁnding the preﬁx length and the next hop.
Finding prefix length
Finding next hop
Prefix length  0~24
On-Chip
Off-chip
Prefix length 25~32
Off-chip
Off-chip
Figure 1: Two-dimensional splitting of IP lookup.
Second, we split the IP lookup problem into two sub-
problems along the dimension of preﬁx length: length ≤ 24
and length ≥ 25. This splitting is based on our key obser-
vation that on backbone routers, for almost all traﬃc, the
longest matching preﬁx has a length ≤ 24. This intuitive-
ly makes sense because typically backbone routers do not
directly connect to small subnets whose preﬁxes are longer
than 24. Our observation may not hold for edge routers;
however, the FIBs for edge routers are signiﬁcantly smaller
that those for backbone routers. The scope of this paper
is on backbone routers. The key beneﬁt of this splitting is
that we can focus on optimizing the IP lookup performance
for traﬃc whose longest matching preﬁx length is ≤ 24.
There is some prior work that performed splitting along
the dimension of the lookup process or the dimension of
preﬁx length; however, no existing work performed splitting
along both dimensions. Dharmapurikar et al. proposed to
split the IP lookup process into two sub-problems: ﬁnding
the preﬁx length using Bloom ﬁlters and ﬁnding the next
hop using hash tables [36]. Pierluigi et al. and Gupta et
al. proposed to split IP preﬁxes into 24 and 32 based on the
observation that 99.93% of the preﬁxes in a backbone router
FIB has a length of less than or equal to 24 [13, 31]. Note
that our IP preﬁx splitting criteria is diﬀerent because our
splitting is based on traﬃc distribution and their splitting
is based on preﬁx distribution.
1.4 Technical Challenges and Solutions
The ﬁrst technical challenge is to achieve constant, yet
small, on-chip memory usage for any FIB size. To address
this challenge, in this paper, we propose to ﬁnd the longest
matching preﬁx length for a given IP address using bit maps.
Given a set of preﬁxes in a FIB, for each preﬁx length i (0 ≤
i ≤ 32), we ﬁrst build a bit map Bi[0..2i − 1] whose initial
values are all 0s. Then, for each preﬁx p, we letB i[|p|] = 1
where |p| denotes the binary value of the ﬁrst i bits of p.
Thus, for all preﬁxes of lengths 0∼24 in any FIB, the total
i=0 2i = 4MB, which is
memory size for all bit maps is
small enough to be stored in on-chip memory.
(cid:2)24
The second technical challenge is to achieve constant, yet
small, IP lookup time for any FIB size. To address this chal-
lenge, in this paper, we classify the preﬁxes in the given FIB
into two categories: those with length ≤ 24 and those with
length ≥ 25. (1) For preﬁxes of length ≤ 24, for each preﬁx
length i (0 ≤ i ≤ 24), we build a next hop array Ni[0..2i − 1]
in oﬀ-chip memory so that for each preﬁx p whose next hop
is n(p), we let Ni[|p|] = n(p). Thus, given an IP address a,
we ﬁrst ﬁnd its preﬁx length using bit maps in on-chip mem-
ory and ﬁnd the next hop using one array lookup in oﬀ-chip
memory. To ﬁnd the preﬁx length using bit maps, for i from
24 to 0, we test whether Bi[a >>(32 − i)] = 1; once we ﬁnd
the ﬁrst i so that Bi[a >> (32− i)] = 1 holds, we know that
the longest matching preﬁx length is i. Here a >>(32 − i)
means right shifting a by 32 − i bits. In this step, the maxi-
mum number of on-chip memory accesses is 25. To ﬁnd the
next hop, suppose the longest matching preﬁx length for a
is i, we can ﬁnd its next hop Ni[a >>(32 − i)] by one oﬀ-
chip memory access. (2) For preﬁxes of length ≥ 25, many
IP lookup schemes can be plugged into our SAIL framework.
Possible schemes include TCAM (Ternary Content Address-
able Memory), hash tables, and next-hop arrays. Choosing
which scheme to deal with preﬁxes of length ≥ 25 depend-
s on design priorities, but have little impact on the overall
IP lookup performance because most traﬃc hits preﬁxes of
length ≤ 24. For example, to bound the worst case lookup
speed, we can use TCAM or next hop arrays. For next hop
arrays, we can expand all preﬁxes of length between 25 and
31 to be 32, and then build a chunk ID (i.e., oﬀsets) array
and a next hop array. Thus, the worst case lookup speed is
two oﬀ-chip memory accesses.
The third technical challenge is to handle multiple FIBs
for virtual routers with two even harsher requirements: (1)
Multi-FIB lookup time should meet wire speed yet remain
constant as FIB sizes and FIB numbers grow. (2) On-chip
memory usage should meet capacity constraints yet remain
constant as FIB sizes and FIB numbers grow. To address
this challenge, we overlay all FIB tries together so that all
FIBs have the same bit maps; furthermore, we overlay all
next hop arrays together so that by the next hop index and
the FIB index, we can uniquely locate the ﬁnal next hop.
The remaining of the paper proceeds as follows. We ﬁrst
review related work in Section 2. In Section 3 and 4, we
introduce our basic SAIL algorithm and optimization tech-
niques, respectively. We then present our implementation
details and experimental results in Section 5 and 6, respec-
tively. We discuss the application of our SAIL framework
to IPv6 lookup in Section 7. Finally, we give concluding re-
marks in Section 8.
2. RELATED WORK
As IP lookup is a core networking issue, much work has
been done to improve its performance. We can categorize
prior work into trie-based algorithms, Bloom ﬁlter based al-
gorithms, range-based algorithms, TCAM-based algorithms,
FPGA-based algorithms, GPU-based algorithms, and multi-
FIB lookup algorithms.
Trie-based Algorithms: Trie-based algorithms use the
trie structure directly as the lookup data structure or indi-
rectly as an auxiliary data structure to facilitate IP lookup
or FIB update. Example algorithms include binary trie [27],
path-compressed trie [20], k-stride multibit trie [39], full ex-
pansion/compression [31], LC-trie [38], Tree Bitmap [40],
priority trie [17], Lulea [28], DIR-24-8 [13], ﬂashtrie [26],
shapeGraph [15], and trie-folding [12]. A comprehensive sur-
vey of trie-based algorithms is in [27].
Bloom Filter based Algorithms: Dharmapurikar et al.
proposed the PBF algorithm where they use Bloom ﬁlters
to ﬁrst ﬁnd the longest matching preﬁx length in on-chip
memory and then use hash tables in oﬀ-chip memory to ﬁnd
the next hop [36]. Lim et al. proposed to use one bloom ﬁlter
to ﬁnd the longest matching preﬁx length [22]. These Bloom
ﬁlter based IP lookup algorithms cannot achieve constant
lookup time because of false positives and hash collisions.
Furthermore, to keep the same false positive rate, their on-
40chip memory sizes grow linearly with the increase of FIB
size.
Range-based Algorithms: Range-based algorithms are
based on the observation that each preﬁx can be mapped
into a range in level 32 of the trie. Example such algorithms
are binary search on preﬁx lengths [24], binary range search
[27], multiway range trees [32], and range search using many
cores [25].
TCAM-based Algorithms: TCAM can compare an in-
coming IP address with all stored preﬁxes in parallel in hard-
ware using one cycle, and thus can achieve constant lookup
time. However, TCAM has very limited size (typically a few
Mbs like on-chip memory sizes), consumes a huge amount
of power due to the parallel search capability, generates a
lot of heat, is very expensive, and diﬃcult to update. Some
schemes have been proposed to reduce power consumption
by enabling only a few TCAM banks to participate in each
lookup [11]. Some schemes use multiple TCAM chips to im-
prove lookup speed [19, 29, 34]. Devavrat et al. proposed to
reduce the movement of preﬁxes for fast updating [8].
FPGA-based Algorithms: There are two main issues
to address for FPGA-based IP lookup algorithms: (1) how to
store the whole FIB in on-chip memory, and (2) how to con-
struct pipeline stages. Some early FPGA-based algorithms
proposed to construct compact data structures in on-chip
memory [23, 33]; however, these compact data structures
make the lookup process complex and therefore increase the
complexity of FPGA logics. For FPGA in general, the more
complex the logics are, the lower the clock frequency will
be. To improve lookup speed, Hamid et al. proposed to only
store a part of data structure in on-chip memory using hash-
ing [14]. To balance stage sizes, some schemes have been pro-
posed to adjust the trie structure by rotating some branches
or exchanging some bits of the preﬁxes [7, 10, 16].
GPU-based Algorithms: Leveraging the massive par-
allel processing capability of GPU, some schemes have been
proposed to use GPU to accelerate IP lookup [35, 42].
Multi-FIB Lookup Algorithms: The virtual router ca-
pability has been widely supported by commercial routers. A
key issue in virtual routers is to perform IP lookup with mul-
tiple FIBs using limited on-chip memory. Several schemes
have been proposed to compress multiple FIBs [18, 21, 37].
3. SAIL BASICS
In this section, we present the basic version of our SAIL
algorithms. In the next section, we will present some opti-
mization techniques. Table 1 lists the symbols used through-
out this paper.
3.1 Splitting Lookup Process
We now describe how we split the lookup process for a
given IP address into the two steps of ﬁnding its longest
matching preﬁx length and ﬁnding the next hop. Given a
FIB table, we ﬁrst construct a trie. An example trie is in
Figure 2(b). Based on whether a node represents a preﬁx in
the FIB, there are two types of nodes: solid nodes and empty
nodes. A node is solid if and only if the preﬁx represented
by the node is in the FIB. That is, a node is solid if and only
if it has the next hop. A node is an empty node if and only
if it has no next hop. Each solid node has a label denoting
the next hop of the preﬁx represented by the node. For any
node, its distance to the root is called its level. The level of
a node locates a node vertically. Any trie constructed from
Table 1: Symbols used in the paper
Symbol Description
Bi
Ni
Ci
BNi
BCNi
a
v
p
|p|
p(v)
n(v)
l
bit map array for level i
next hop array for level i
chunk ID array for level i
combined array of Bi and Ni
combined array of Bi, Ci and Ni
IP address
trie node
preﬁx
value of the binary string in preﬁx p
preﬁx represented by node v
next hop of solid node v