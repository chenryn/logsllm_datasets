CPU cycle – e.g., the probability for ﬂipping bit #3 exactly in
the time frame between cycle 4 and 5 in Figure 1a – is extremely
low. Recent large-scale studies on DRAM (DDR-2 and DDR-3)
memory technology report soft-error rates of 0.061 FIT 3 per
Mbit [9], 0.066 FIT /Mbit [10] and 0.044 FIT /Mbit [11].
Even though different DRAM vendors were tested, the resulting
soft-error rates are quite similar. Using the mean of these three
error rates, for a single bit, the soft-error rate per nanosecond
(assuming a clock rate of 1 GHz, or one cycle per ns, for our
simplistic CPU from Section II-C) is:
g = 0.057
=
0.057
FIT
Mbit
109h · 106bit
109 · 3600 · 109ns · 106bit
=
0.057
≈ 1.6 · 10−29
1
ns · bit
The probability of one benchmark run being hit by k = 0,
1, 2, or more independent faults can be calculated using the
binomial distribution. Nevertheless, for such an extremely low
fault probability, it can be well approximated using the Poisson
distribution (assuming the occurrence of faults is a Poisson
process) [26]:
Pλ(k) = λk
k! e
−λ
(1)
The Poisson parameter λ = gw is calculated using the
aforementioned soft-error rate g, and the fault-space size w =
Δt · Δm characterizing the benchmark by its runtime in CPU
cycles Δt, and the amount of main memory in bits Δm it
uses. Using concrete values for the benchmark runtime and
memory usage, e.g., Δt = 1s (corresponding to 109 cycles in
our simplistic CPU model) and Δm = 1 MiB = 223bit, yields
the probabilities for k faults hitting one benchmark run listed
in Table I.
Unsurprisingly, for the magnitude of the parameter values,
the probability that a benchmark run is not hit at all is extremely
high. This zero-fault case naturally does not require any FI
2Note that time is quantized in granules of CPU cycles (cf. Section II-C).
3The FIT (Failures In Time) rate measures the number of failures to be
expected per 109 hours of operation.
321321
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:50:36 UTC from IEEE Xplore.  Restrictions apply. 
(cid:9)
(cid:16)
(cid:15)
(cid:14)
(cid:4)
(cid:5)
(cid:13)
(cid:12)
(cid:11)
(cid:8)
(cid:10)
(cid:25)
(cid:24)
(cid:23)
(cid:22)
(cid:21)
(cid:20)
(cid:19)
(cid:18)
(cid:17)
(cid:17)
(cid:18)
(cid:19)
(cid:20)
(cid:27)(cid:28)(cid:8)(cid:4)(cid:14)(cid:5)(cid:16)(cid:8)
(cid:31)(cid:32)(cid:33)(cid:15)(cid:34)(cid:29)(cid:7)(cid:8)(cid:28)(cid:6)(cid:8)
(cid:27)(cid:28)(cid:8)(cid:4)(cid:14)(cid:5)(cid:16)(cid:8)
(cid:1)(cid:13)(cid:15)(cid:16)(cid:8)
(cid:1)(cid:7)(cid:29)(cid:9)(cid:9)(cid:8)(cid:9)
(cid:2)(cid:8)(cid:29)(cid:30)
(cid:9)
(cid:16)
(cid:15)
(cid:14)
(cid:4)
(cid:5)
(cid:13)
(cid:12)
(cid:11)
(cid:8)
(cid:10)
(cid:25)
(cid:24)
(cid:23)
(cid:22)
(cid:21)
(cid:20)
(cid:19)
(cid:18)
(cid:17)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:25) (cid:17)(cid:26)
(cid:17)(cid:17)
(cid:17)(cid:18)
(cid:17)
(cid:18)
(cid:19)
(cid:20)
(cid:21)
(cid:22)
(cid:23)
(cid:24)
(cid:25) (cid:17)(cid:26)
(cid:17)(cid:17)
(cid:17)(cid:18)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:1)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)
(cid:23)
(cid:22)
(cid:21)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:1)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)
(cid:24)
(a) Single-bit ﬂip fault space for a run-to-completion benchmark. Each
dot represents a possible FI space/time coordinate. The benchmark
proceeds until and stops at a speciﬁc point in time, the corresponding
memory bit is ﬂipped, and the benchmarks resumes.
(b) Single-bit ﬂip fault space and def/use equivalence classes extracted
from a program trace, reducing the FI experiments (dots) that need to
be conducted. Fault injections at white coordinates (non-ﬁlled circles)
can be omitted, as a fault there is overwritten or never read (dormant
faults). A black dot represents a class of equivalent faults (light-gray
coordinates) between the write and subsequent read instruction.
Fig. 1. The fault space spanned by CPU Cycles × Memory Bits. Every discrete (cycle, bit) coordinate denotes an event where a memory bit can ﬂip during the
depicted twelve CPU cycles.
TABLE I.
POISSON PROBABILITIES FOR k = 0, 1, 2, OR MORE
INDEPENDENT FAULTS HITTING ONE BENCHMARK RUN.
k
0
1
2
Pλ(k Faults)
1.328 · 10−13
8.821 · 10−27
Pλ(k Faults)
3.905 · 10−40
1.297 · 10−53
0.999999999999867
k
3
4
. . .
. . .
experiments. But, even more noteworthy, the probability for
two or more hits is so much lower than for one fault hitting
the benchmark’s used memory Δm that these cases can be
considered negligible.4 Hence, at current (and tomorrow’s) fault
rates, and for short benchmark runtimes, it sufﬁces to inject
one fault per benchmark run.
Nevertheless, applying the numbers from our hypothetical
benchmark example to the fault-space diagram in Figure 1a
(the CPU cycles axis now spans from 0 to Δt = 109 cycles,
the memory bits axis from bit #0 to #223) clariﬁes that, for a
full fault-space scan, even with only one fault per run w =
Δt·Δm ≈ 8.4·1015 FI experiments would have to be conducted.
Even assuming we can simulate our simple CPU in real-time,
this procedure would take about 266 million CPU years.
B. Reducing Experiment Efforts: Fault Sampling
One widespread solution to this fault-space explosion
problem is fault sampling [12], [27], [28]. Since the distribution
of faults in the fault space is assumed uniform (Section II-C), FI
experiments are picked uniformly from this space (Figure 1a).
Consequently, the results can be used to estimate the fault
coverage factor (or short, fault coverage) [29], “deﬁned as the
probability of system recovery given that a fault exists” [27].
4Even at a hypothetical fault rate of g = 10−20, nine orders of
magnitude higher than in the example, the distance between Pλ(1 Fault)
and Pλ(2 Faults) is still more than 104.
322322
The fault coverage c, or – formalizing the citation from
[27] – P (No Eﬀect|1 Fault) or 1-P (Failure|1 Fault), can be
calculated after randomly picking N (time, space) coordinates
from the fault space, and running an FI experiment for each
of them. In each experiment, the benchmark program is run
from the beginning until the CPU cycle for the FI (the time
component of the randomly picked coordinate from Figure 1a)
has been reached. The machine is then paused, the fault gets
injected by ﬂipping the bit in memory corresponding to the
space component of the coordinate, and the machine is resumed.
As described in Section II-D, then the experiment outcome is
observed, turning out either as “No Effect”, or as “Failure”.
In the latter case, the failure counter F is incremented. (“No
Effect” results are implicitly counted as N − F ).
The fault coverage c can subsequently be calculated as
c = 1 − P (Failure|1 Fault) = 1 − F
N
.
(2)
We will see in Section IV and V that the fault coverage metric,
originally only devised for the assessment of hardware systems
[29], is ﬂawed for comparing software programs. The sampling
process itself is unproblematic, as long as a sufﬁciently large
number of samples is taken for statistically authoritative results.
This topic is outside the scope of this paper, and we, thus, refer
to the literature covering this matter [12], [27], [28].
C. Reducing Experiment Efforts: Def/use Pruning
Recent FI techniques proceed with more sophistication than
randomly sampling locations in the fault space, and are based
on instruction and memory-access traces. These traces are
created during a so-called “golden run”, which exercises the
target software without injecting faults (and, thus, serves as a
reference for the expected program behavior).
Figure 1b exemplarily shows the memory-access informa-
tion recorded during the golden run. The dynamic instruction
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:50:36 UTC from IEEE Xplore.  Restrictions apply. 
starting in CPU cycle 4, a store, writes (“W”) eight bits to
main memory, and the data is read (“R”) back into the CPU
in cycle 11, executing a load instruction.
Based on this kind of memory-access trace information,
Smith et al. [30] and Güthoff and Sieh [31] are among the
ﬁrst concisely describing the classical def/use analysis for
experiment reduction (termed “operational-proﬁle-based fault
injection” in the latter paper). It is so fundamental that it
was subsequently reinvented several times, e.g., by Benso et
al. [32], [15], Berrojo et al. [33] (“Workload Dependent Fault
Collapsing”), Barbosa et al. [34] (“inject-on-read”), and recently
by Grinschgl et al. [35] and Hari et al. [19].
The basic insight is that all fault locations between a def
(a write or store, “W” in Figure 1b) or use (a read or load, “R”
in the ﬁgure) of data in memory, and a subsequent use, are
equivalent: regardless of when exactly in this time frame a fault
is injected there, the earliest point where it will be activated
is when the corrupted data is read. Instead of conducting one
experiment for every point within this time frame, it sufﬁces to
conduct a single experiment (for example at the latest possible
time directly before the load, black dot in Figure 1b), and
assume the same outcome for all remaining coordinates within
that def/use equivalence class (light-gray frames in Figure 1b).
Similarly, all points in time between a load or store and
a subsequent store without a load in between (light-gray dots
in the remaining fault-space coordinates left, right and above
the marked equivalence classes in Figure 1b) are known to
result in “No Effect” without having to run experiments at all:
injected faults will be overwritten by the next store in all cases.
The result of the def/use pruning process is a partitioning of
the fault space into equivalence classes, some of which a single
experiment needs to be conducted for (those ending with a
load, “R”), and some with a priori known experiment outcome.
From the 12 · 9 = 108 experiments in the illustrative example
of Figure 1a, only 8 remain after def/use pruning in Figure 1b.
In real-world examples, def/use pruning (especially when
applied to faults in memory) is extremely effective. For example,
the baseline variant of the SYNC2 benchmark (cf. Section II-D)
is reduced from a raw fault-space size of w ≈ 1.5 · 108 to
merely 19,553 experiments. Thus, a full fault-space scan is
feasible even on a single machine within a reasonable time
frame, and without any loss of precision regarding the result
information on any point in the fault space.
D. Def/use Pruning and the Weighting Pitfall
Since its inception, def/use pruning was meant as an effort-
reducing, conservative optimization for the theoretical full
fault-space scanning model [34]. If, assuming the experiment
numbers from Figure 1b, four of the eight (black-dotted)
actually conducted experiments turned out as “Failure” (and,
inversely, the remaining four as “No Effect”), this number must
not be used in Equation 2 for fault-coverage calculation without
any post-processing, yielding a wrongly calculated coverage of
c = 1− 4
8 = 50%. Instead, the previously collapsed equivalence
classes must be expanded to their original size again, weighting
each FI-obtained result with the corresponding equivalence-
class size. Güthoff et al. also state this explicitly: “Each result
obtained by [. . . ] fault injection experiments must be weighted
with the corresponding relative data life-cycle length.” [31]
bin_sem2
sync2
bin_sem2
sync2
e
g
a
r
e
v
o
c
t
l
u
a
F
100%
75%
50%
25%
0%