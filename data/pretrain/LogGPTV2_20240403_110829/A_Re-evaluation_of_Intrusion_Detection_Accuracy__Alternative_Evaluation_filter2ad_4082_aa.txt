title:A Re-evaluation of Intrusion Detection Accuracy: Alternative Evaluation
Strategy
author:Said Al-Riyami and
Frans Coenen and
Alexei Lisitsa
POSTER: A Re-evaluation of Intrusion Detection Accuracy: an
Alternative Evaluation Strategy
Said Al-Riyami
Liverpool University
Liverpool, UK
PI:EMAIL
Frans Coenen
Liverpool University
Liverpool, UK
PI:EMAIL
Alexei Lisitsa
Liverpool University
Liverpool, UK
PI:EMAIL
ABSTRACT
This work tries to evaluate the existing approaches used to bench-
mark the performance of machine learning models applied to network-
based intrusion detection systems (NIDS). First, we demonstrate
that we can reach a very high accuracy with most of the traditional
machine learning and deep learning models by using the existing
performance evaluation strategy. It just requires the right hyper-
parameter tuning to outperform the existing reported accuracy
results in deep learning models. We further question the value of
the existing evaluation methods in which the same datasets are
used for training and testing the models. We are proposing the
use of an alternative strategy that aims to evaluate the practicality
and the performance of the models and datasets as well. In this
approach, different datasets with compatible sets of features are
used for training and testing. When we evaluate the models that
we created with the proposed strategy, we demonstrate that the
performance is very bad. Thus, models have no practical usage, and
it performs based on a pure randomness. This research is important
for security-based machine learning applications to re-think about
the datasets and the model’s quality.
KEYWORDS
Intrusion detection system, Network Security, Security and Privacy,
Domain Adaptation, Machine Learning, Deep Learning
1 INTRODUCTION
In recent years, the number of malware and intrusion attacks has
escalated dramatically. Symantec claims that it detected more than
357 millions new variants of malware in 2016 [12]. Kaspersky report
that it detected 360,000 new malicious files a day in 2017 [2]. The
McAfee Labs Threats Report of 2017 state that it detected 57.6
million new malware or about 157,808 per day [3].
One of the most commonly used intrusion detection methods
is signature-based detection, which uses knowledge of attacks in
the form of signatures, which can be easily checked against moni-
tored traffic. The major issue with this method is the availability
of signatures in the context of the constantly growing number of
attacks; the set of signatures has to be constantly updated and this
requires expert knowledge. This issue can be alleviated in part by
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5693-0/18/10.
https://doi.org/10.1145/3243734.3278490
the automation of the detection procedures and the use of machine
learning methods, in particular, supervised machine learning.
For years, traditional machine learning algorithms have been
used for the network intrusion detection system (NIDS). For ex-
ample, Decision tree learning, Random forest, Logistic regression,
Naive Bayes, k-nearest neighbours algorithm (k-NN) and other. But
recently, the use of Deep Learning models has become popular in
areas of cybersecurity. There are several architectures that can be
for deep learning includes Article Neural Network (ANN), Autoen-
coders (AE), Convolution Neural Networks (CNN) and Recurrent
Neural Networks (RNN) with different cells, like Long Short-Term
Memory (LSTM) and Gated Recurrent Unit (GRU).
There are several labelled datasets used for the purpose of evalu-
ating network intrusion detection system. For example, NSL-KDD
which is a refined version of the popular KDD Cup 1999 datasets.
The dataset can be used in term of binary classification (normal,
attack), or multi-class classification (5 attack categories, or the name
of the exact attack) [13]. Most of the research on NIDS has focused
on creating machine learning models that perform better than pre-
viously reported in term of accuracy. Other measures are also used
as the F1 score. The evaluation strategy used is by train and test in
the same dataset. The results based on this method of evaluating
are very high. You can get 97% and more accurate detection rate
with most of the datasets available to NIDS. We argue that this
way of evaluation is far from the main goal of creating an intrusion
detection system. The model should build a real understanding of
the attack behaviour. But the results we are getting is more towards
overfitting on the dataset itself that have been created in a par-
ticular computer network setting with a particle methodology to
introduce intrusion’s ground truth.
Section 2 focus on the current strategy of evaluation. We will
demonstrate that we can get very high accuracy in the different
datasets by using traditional machine learning algorithms, as well
as deep learning models after a good hyperparameters tuning. Our
result shows that we can match the reported result or exceed them
in some cases. Section 3 we propose training and testing are done
in two different datasets. By doing so, we show that the models
perform poorly. This result is very important to re-think the models
and datasets available in this area.
2 GETTING ACCURACY HIGH
Most of the time when we use traditional machine learning algo-
rithms for NIDS, we are getting a higher result comparing with
deep learning algorithms. In this section, we want to demonstrate
that we can use most of the deep learning models and try to reach to
the same performance of classical machine learning or even more.
The aim of this part is to show that getting a high-performance
Poster PresentationCCS’18, October 15-19, 2018, Toronto, ON, Canada2195Table 1: Evaluation with the current strategy - F1 Score
Algorithm Kyoto+ NSL-KDD gureKDD NSL-KDD (multi)
DT
RF
logit
k-NN
ANN
LSTM
GRU
99.46%
99.56%
93.69%
99.15%
99.24%
99.21%
99.17%
99.92%
99.94%
97.34%
99.92%
99.46%
99.42%
99.31%
99.36%
99.30%
95.27%
98.07%
98.25%
98.45%
98.40%
97.64%
98.19%
93.57%
97.16%
98.13%
97.91%
98.03%
model is not hard based on the strategy method of evaluating the
models.
2.1 Methodology
We will use three different datasets: Kyoto2006+, NSL-KDD, and
gureKDD. First, we will check the accuracy that has been reported
in those datasets. Then, we will run different traditional machine
learning algorithms and report the result. Finally, we will try differ-
ent deep learning algorithms. Even though we getting low accuracy
at the beginning, comparing with traditional machine learning, but
we will show with the right hyperparameters tunning we can match
or bypass the result of the traditional machine learning.
The training and testing are done within the same dataset. The
split is around 80% for training and 20% for testing. Then, we will
calculate the performance only based on the result of the testing
part. The performance can be measured by the ratio of the total
number of correct predictions by the total number of predictions.
But to avoid any Accuracy Paradox that might be there because of
the distribution imbalance of the data, we use the F1 score calculated
using Equation 1. The F1 will balance between Precision and Recall.
The models that we used are: Decision Tree (DT), Random forest
(RF), Logistic Regression (logit), K-NN, Artificial Neural Network
(ANN), and Recurrent Neural Network (RNN) with Long Short-Term
Memory (LSTM) and with Gated Recurrent Unit (GRU).
F1 = 2 Precision × Recall
Precision + Recall
=
2T P
2T P + F P + F N
(1)
2.2 Kyoto+2006 Dataset Experiments
Kyoto 2006+ is a dataset that has been generated for the purpose of
NIDS [10][11]. They used honeypot traffic as a source of ground
truth about the malicious activities. The dataset contains 22 features.
There are 3 class of labels for this dataset: normal, known attack,
unknown attack. We will convert the problem to be binary where 0
means normal traffic and 1 means malicious traffic. For comparison
reason, we will follow the same split and preprocessing of this
dataset to the one reported in [1]. The best accuracy results in
that paper are ≈84.15%. And after we calculated their F1 score we
got ≈87.56%. Another reported work with the same datasets can
be found here [9]. They used a stack of Artificial Neural Network
(ANN) layers. Their best result shows when they used 1000 hidden