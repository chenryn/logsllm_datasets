**Title: A Re-evaluation of Intrusion Detection Accuracy: An Alternative Evaluation Strategy**

**Authors:**
- Said Al-Riyami, Liverpool University, Liverpool, UK
- Frans Coenen, Liverpool University, Liverpool, UK
- Alexei Lisitsa, Liverpool University, Liverpool, UK

**Abstract:**
This study re-evaluates the existing approaches used to benchmark the performance of machine learning models in network-based intrusion detection systems (NIDS). We demonstrate that high accuracy can be achieved with both traditional and deep learning models using current evaluation strategies, often through careful hyperparameter tuning. However, we question the validity of these methods, which typically use the same datasets for training and testing. We propose an alternative strategy that evaluates the practicality and performance of models by using different datasets for training and testing. Our results show that when this approach is applied, the performance of the models significantly degrades, indicating that they may not generalize well to new data. This research highlights the need to reconsider the quality and diversity of datasets and models in security-based machine learning applications.

**Keywords:**
Intrusion detection system, Network Security, Security and Privacy, Domain Adaptation, Machine Learning, Deep Learning

**1. Introduction**
In recent years, the number of malware and intrusion attacks has dramatically increased. For instance, Symantec detected over 357 million new malware variants in 2016 [12], while Kaspersky reported 360,000 new malicious files per day in 2017 [2]. The McAfee Labs Threats Report from 2017 indicated the detection of 57.6 million new malware instances, or approximately 157,808 per day [3].

One of the most common intrusion detection methods is signature-based detection, which relies on known attack signatures. However, the rapid growth in the number of attacks necessitates frequent updates to the signature set, requiring expert knowledge. This challenge can be partially addressed through the automation of detection procedures and the use of machine learning, particularly supervised learning.

Traditional machine learning algorithms, such as decision trees, random forests, logistic regression, Naive Bayes, and k-nearest neighbors (k-NN), have been widely used in NIDS. Recently, deep learning models, including artificial neural networks (ANNs), autoencoders (AEs), convolutional neural networks (CNNs), and recurrent neural networks (RNNs) with Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) cells, have gained popularity in cybersecurity.

Several labeled datasets, such as NSL-KDD (a refined version of the KDD Cup 1999 dataset), are commonly used for evaluating NIDS. These datasets can be used for binary classification (normal vs. attack) or multi-class classification (different types of attacks) [13]. Most research focuses on improving the accuracy of NIDS models, often achieving over 97% accuracy. However, we argue that this high accuracy may result from overfitting to the specific characteristics of the training dataset, rather than a true understanding of attack behavior.

**2. Current Evaluation Strategies**
The current evaluation strategy involves training and testing models on the same dataset, typically with an 80/20 split. This method often yields very high accuracy, but it may not reflect the model's ability to generalize to new, unseen data. In this section, we demonstrate that high accuracy can be achieved with both traditional and deep learning models after appropriate hyperparameter tuning.

**2.1 Methodology**
We evaluate three datasets: Kyoto2006+, NSL-KDD, and gureKDD. We first compare our results with previously reported accuracies, then run various traditional and deep learning algorithms. The training and testing are performed within the same dataset, with an 80/20 split. Performance is measured using the F1 score, which balances precision and recall, to avoid the accuracy paradox caused by class imbalance.

**2.2 Experiments with the Kyoto+2006 Dataset**
The Kyoto 2006+ dataset is generated for NIDS and includes 22 features, with labels for normal, known, and unknown attacks. We convert this into a binary classification problem (0 for normal, 1 for malicious). Previous work [1] reported an accuracy of approximately 84.15%, with an F1 score of about 87.56%. Another study [9] used a stack of ANNs and achieved their best results with 1000 hidden units.

**Table 1: Evaluation with the Current Strategy - F1 Score**

| Algorithm | Kyoto+ | NSL-KDD | gureKDD | NSL-KDD (multi) |
|-----------|--------|---------|---------|------------------|
| DT        | 99.46% | 99.92%  | 99.36%  | 98.07%           |
| RF        | 99.56% | 99.94%  | 98.45%  | 97.16%           |
| logit     | 93.69% | 97.34%  | 95.27%  | 98.13%           |
| k-NN      | 99.15% | 99.92%  | 98.40%  | 97.91%           |
| ANN       | 99.24% | 99.46%  | 97.64%  | 98.03%           |
| LSTM      | 99.21% | 99.42%  | 98.19%  |                  |
| GRU       | 99.17% | 99.31%  | 93.57%  |                  |

These results show that high performance can be achieved with the current evaluation strategy. However, the next section will explore the limitations of this approach and propose an alternative.

**3. Alternative Evaluation Strategy**
To better assess the practicality and generalization of NIDS models, we propose using different datasets for training and testing. This approach aims to evaluate how well the models perform on data that they have not seen during training. Our experiments with this alternative strategy reveal that the performance of the models significantly degrades, suggesting that they may not be as effective in real-world scenarios as previously thought.

**Conclusion**
This research highlights the importance of rethinking the evaluation methods for NIDS models. While high accuracy can be achieved with current strategies, the models may not generalize well to new data. Future work should focus on developing more robust and practical evaluation methods to ensure the effectiveness of NIDS in real-world applications.

**References:**
[1] Reference 1
[2] Reference 2
[3] Reference 3
[9] Reference 9
[10] Reference 10
[11] Reference 11
[12] Reference 12
[13] Reference 13