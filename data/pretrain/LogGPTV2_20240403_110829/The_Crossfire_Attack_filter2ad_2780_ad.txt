of attack packets reach the target links and ﬂood them. Note
that additional attack routes to target links can always be
found before the attack and used only if necessary.
In addition to the dynamic assignment of attack ﬂows,
the adversary can instruct bots to estimate the available
bandwidth towards the target links using a priori bandwidth
estimation tools (e.g., Pathneck [40]) and predict early
congestion before assigning attack ﬂows. In this way, the
adversary can provision the bots so that early congestion
would not happen.
D. Execution Time of Target Selection Algorithm
The greedy algorithm of selecting a set of T target links
runs as follows:
Let R, L and T be the set of all bot-to-target area routes,
the set of candidate links for the target area, and the set of
target links, respectively. Let li be a link on a route.
(1) Add all distinct links (l(cid:2)
(2) Take out the highest ﬂow density link, lmax
is) of R to L.
, from L and
i
(3) Recompute the ﬂow density for all li’s in L.
(4) Repeat (2) and (3) until T target links are selected, i.e.,
add it to T .
until |T | = T .
The above algorithm ﬁnds the T best target links that
disconnect the target area in terms of the degradation ratio,
134
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:31 UTC from IEEE Xplore.  Restrictions apply. 
Target area
Univ1
Pennsylvania
East Coast
T = 10
T = 20
T = 30
T = 40
T = 50
0.94
3.10
13.44
1.87
5.46
24.93
2.79
7.38
35.13
3.72
8.99
43.96
4.65
10.38
52.05
Table IV: Execution time (in seconds) to select T target links
for different target sizes.
i
in T iterations of steps (2) - (3). Step (3) re-evaluates ﬂow
densities after removing all routes of R that include lmax
and as a consequence, the step ensures that the adversary
selects the target link that maximally disconnects the target
area at each iteration. Table IV shows the execution times
taken by our experiments. As expected, the execution time is
proportional to the number of target links (T ) for all target
areas, and grows signiﬁcantly for a large target area (e.g., 52
seconds in selecting 50 target links for the East Coast of the
US), since more unique links can be found in large target
areas. However, the number of unique links is bounded by
a limited number of routes. This number is limited because
bot-decoy pairs in the same source and destination subnets
produce a single unique route. Hence, the execution time of
the algorithm is short enough (e.g., at most a couple minutes)
for an adversary to adapt to all potential route changes even
for a large target area, in practice.
E. The Cost of the Crossﬁre Attack
To launch a Crossﬁre attack, an adversary needs bots. To
get them, she can either infect user machines and install
her own bots or buy the bots from Pay-Per Install (PPI)
botnet markets [41]. For cost estimation, we assume that
the adversary buys the bots from the markets. Our cost
estimates are based on a recent analysis of PPI botnet
markets [41]. A possible option would be to rent cloud
services for bot operation from many, say one hundred,
providers around the world. Given the low computation and
communication requirements of Crossﬁre bots and the high-
bandwidth connectivity of data centers to the Internet, the
bots’ behavior during an attack would not trigger providers’
alarms.
PPI botnet markets have region-speciﬁc pricing plans.
Generally, bots in the US or the UK are most expensive
and cost $100-$180 per thousand bots. Bots in continental
Europe cost $20-$60 whereas bots in the rest of the world
cost less than $10 per thousand bots. The mix of bots used
in our experiments (presented in Section III-B) has 49%
of bots in the US or UK, 37% in continental Europe, and
14% in the rest of the world. If we assume the size of
a bot cluster (β) is 500, the total cost of the Crossﬁre
attack is roughly $46K. Our experiments also show (viz.,
Section V-D) that the minimum number of required bots
that can ﬂood 10 target links can be as low as 107,200 bots,
and hence the attack cost can be as low as $9K. This implies
that a single organization or even an individual can launch a
massive Crossﬁre attack. If the attack is state- or corporate-
sponsored, many more bots can be purchased and a much
larger number of links can be targeted. In this case, the
Crossﬁre attack could easily disconnect almost 100% of the
Internet connections to a large target area.
V. EXPERIMENT SETUP AND RESULTS
In this section, we demonstrate the feasibility of the
Crossﬁre attack and its effects on various target areas using
real Internet data. In particular, we show how one sets up the
bots, decoy servers, and target area for a Crossﬁre attack.
A. Bots
Instead of using real bots to perform our experiments,
which would raise ethical [42, 43] and/or legal concerns
[44], we use PlanetLab nodes [45] and Looking Glass (LG)
servers as attack sources. PlanetLab is a global research
testbed that supports more than one thousand nodes at
549 sites. An LG server is a publicly available router that
provides a Web-interface for running a set of commands,
including traceroute [46]. They have been used as vantage
points for discovering Internet topology [47, 48, 49].
The PlanetLab and LG server networks provide a faithful
approximation of a globally distributed bot network. As seen
in Fig. 5, the 620 PlanetLab nodes and 452 LG servers are
located 309 cities in 56 countries. In Section III-B, we will
show that different bot distributions created using PlanetLab
nodes and LG servers, result in practically the same attack
effectiveness. Hence, the Crossﬁre attack using real bots
(e.g., leased from botnet markets) would experience similar
attack effects as in our experiments. A single PlanetLab
node or LG server represents several hundred bots, given
(1) the high degree of clustering observed in real-bot distri-
butions [50, 51], and (2) the fact that bot-originated trafﬁc
from the same AS domain would converge at a router and
then follow the same route, due to the BGP’s single best
route selection policy. Hence, the routes we trace from the
PlanetLab nodes or LG servers to the public servers in the
target area, allows us to build the actual Internet link map
of the target area. We call the group of bots represented by
the same PlanetLab node or LG server a bot cluster, and
experiment with cluster sizes of 100, 200, and 500 bots.
B. Decoy servers
Decoy servers, which are the destinations for attack trafﬁc,
can be any public server whose physical location is nearby
a target area. Among various possible ways an adversary
could select decoy servers, one way is to ﬁnd servers of
public institutions (e.g., universities and colleges) physically
located surrounding the target area. For example, the servers
of a university or college are typically located on their
135
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:31 UTC from IEEE Xplore.  Restrictions apply. 
Target area
Univ1
Univ2
New York
Pennsylvania
Massachusetts
Virginia
East Coast (US)
West Coast (US)
Number of
public servers
in target area
1,000
1,000
86,000
82,000
54,000
34,000
351,000
201,000
Number of
decoy servers
350,000
350,000
265,000
269,000
297,000
317,000
351,000
201,000

Figure 5: A map of geographic locations of the 620 Planet-
Lab nodes (red pins) and 452 LG servers (blue pins) used
in our experiments.
Table V: The extrapolated numbers of public servers in target
areas and decoy servers used for attacking each target area
in our experiments
campus11.
We found 552 institutions (i.e., universities and colleges)
on both the East Coast (10 states) and West Coast (7 states)
of the US, which can provide large numbers of decoy
servers. The list of institutions in a speciﬁc US state is easily
found on the Web12. An adversary can ﬁnd a minimum of
1,000 public servers within an institution. For example, we
found 2,737 and 7,411 public web servers within Univ1 in
Pennsylvania and Univ2 in Massachusetts, respectively, via
port-scanning. Had we used real bots, port scanning duties
would be distributed to each bot and would be performed
over a period of time, to avoid triggering IDSs or ﬁrewall
alarms at those institutions. Similarly, an adversary could
use 351,000 public servers located in 351 institutions on the
East Coast of the US, and 201,000 public servers in 201
institutions on the West Coast.
C. Target area
A target area is the geographic location where an ad-
versary wants to block Internet trafﬁc. To establish that
the Crossﬁre attack works for various target-area sizes,
we used three different conﬁgurations: small, medium, and
large. For the small area size, we set a single organization
as the target area. Speciﬁcally, we set Univ1 and Univ2
as examples of small-sized target areas. As examples of
medium-sized areas, we picked four US states, namely New
York, Pennsylvania, Massachusetts, and Virginia. Finally,
we picked ten states on the East Coast and seven on the
West Coast as two examples for large target areas. Note that
the large target areas’ sizes could conceivably represent a
medium-size country. For a small or medium target area,
we chose decoy servers outside the target area for the
undetectability of attack ﬂows. However, for a large target
area, we chose decoy servers inside the target area since
11The adversary might use a public search engine, such as SHODAN
(http://www.shodanhq.com), to gather a large number of publicly accessible
IPs at a geographical location. However, use of SHODAN would require
cross-validation of the IP addresses in a geolocation due to possible search
inaccuracies. Cross-validation would be a fairly simple matter of comparing
results of multiple IP geolocation services for a certain target area
12http://www.4icu.org/
the wide array of decoy servers within the area would not
diminish the Crossﬁre’s undetectability.
Table V illustrates the extrapolated numbers of public
servers in the target areas and decoy servers used for
attacking those areas. Note that the extrapolation is based
on that an adversary can ﬁnd 1,000 public servers within an
institution.
D. Results
We performed Internet-scale experiments to verify the
feasibility and the impact of the Crossﬁre attack based on
the steps described in Section II. For each attack target area
illustrated in Table V, we construct a link map (Step 1,
viz., Section II-A) and select the target links (Step 2, viz.,
Section II-B), using the PlanetLab nodes and LG servers, and
public servers in the target area. Bot-coordination (Step 3,
viz., Section II-C) is performed via simulations, for obvious
ethical and legal reasons. However, the simulations use the
real link map and data obtained from the ﬁrst two attack
steps illustrated in Fig. 2. In this section, we summarize the
results of our experiments.
Link map. We gather traceroute data from all the Planet-
Lab nodes and LG servers (i.e., sources) to all the institutions
in the target areas (i.e., destinations) and construct
the
link maps centered on the target areas of the East and
West Coasts of the US. For each source-destination pair,
we run a traceroute six times to diagnose link persistence.
Since multiple traceroute packets (i.e., ICMP packets) to
the same destination are independently load-balanced at a
load-balancing router [26], running six traceroutes is enough
to determine whether a link on the route is persistent or
transient. We classify a link as persistent if the link appears
in all six traceroute results. The false positive probability,
namely the probability that we falsely determine a transient
link as persistent, is at most 0.016 ((cid:2) 2−6). This is the
case because the highest false positive probability is reported
when a router, which has two load-balancing links to the next
hop router, happens to select the same link in forwarding
six traceroute packets originated from the same source. If
136
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:31 UTC from IEEE Xplore.  Restrictions apply. 
Target area
Univ1
Univ2
New York
Pennsylvania
Massachusetts
Virginia
East Coast (US)
West Coast (US)
Percentage of persistent links
79.99 %
70.37 %
69.70 %
75.68 %
74.11 %
70.32 %
71.78 %
72.37 %
Table VI: Percentage of persistent links per target area
the router has more load-balancing links, the false positive
probability becomes lower.
We summarize the percentages of persistent links found
by traceroutes in Table VI. Regardless of the size of a target
area, the majority of the discovered links are persistent and
hence can be used for the Crossﬁre attack. This result shows
that even though trafﬁc load-balancing through multiple
links is widely implemented by ISPs in the current Internet,
a large portion of Internet links are persistent. This enables
the adversary to easily ﬁnd (persistent) target links. In the
following subsection, we discuss how the adversary ﬁnds the
target links whose congestion would effectively disconnect
a target area.
Link Coverage. Although one could not demonstrate that
all links leading to a target area can be found by traceroute,
one could show that all critical links can be found for a
target area. To show this we selected different uniformly-
distributed subsets of the 1,072 bots used (i.e., PlanetLab
nodes and LG servers); e.g., subsets of 10%, 20%,..., 90%
of all bots. We computed their degradation ratios for three
target areas and plotted those against the baseline degra-
dation ratio produced by all 1,072 bots. Figure 6 shows
that, for each target area, beyond a certain bot-subset size,
the differences in deviations from the baseline degradation
ratios taper off, indicating that additional critical links which
would increase degradation ratios can no longer be found;
i.e., that size is approximately 10% of all bots for Univ1,
20% for Pennsylvania, and 50% for the East Coast. In similar
experiments, if we vary server-subset sizes beyond a certain
target-area related threshold, additional critical links that
would increase the degradation ratios could not be found
any longer. These two experiments suggest that the critical
links we ﬁnd adequately cover the ﬂows toward a target area.
Flow density. To compute ﬂow densities of all persistent
links of the link map, we count the number bot-to-target area
routes on those links. As expected, the distribution of ﬂow
densities is highly non-uniform, namely it follows a power-
law distribution; i.e., a few links have unusually high ﬂow
densities while most of the other links have much lower ﬂow