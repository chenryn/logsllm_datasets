sizes for two PWB and fence combinations: CLFLUSH+ NOP (left)
and CLFLUSHOPT + SFENCE (right).
// deﬁned in [11]
By using both servers, we highlight the performance im-
plications of both real SGX and real PM. All experimental
comparisons are executed separately for each server, as they
have completely different characteristics. We indicate where
necessary on which node an experiment is carried out. All
SCONE containers are based on Alpine Linux [25].
All models used in our evaluations are convolutional neural
networks (CNNs). The convolutional layers use leaky rectiﬁed
linear unit (LReLU) [15] as activation, and all output layers are
softmax [29] layers. The model optimization algorithm used is
stochastic gradient descent (SGD), and the learning rate used is
0.1. Except stated otherwise, all training iterations use a batch
size of 128. Concerning the dataset, we use MNIST [2], a very
popular dataset in the deep learning community. It consists of
70’000 grayscale images of handwritten digits (60’000 training
samples and 10’000 test samples).
Why SGX-Romulus makes sense. We begin by comparing
SGX-ROMULUS with the unmodiﬁed Romulus library running
in a SCONE container, with the goal of understanding how
a manually ported library using the Intel SGX SDK and the
unmodiﬁed version in SCONE stand against each other.
We measure how many swaps per second (SPS) they achieve,
a metric commonly used [11] to compare PM libraries. SPS
stores an array of integers in PM and evaluates the overhead
of randomly swapping array values within a transaction, for
different persistence fences and transaction sizes. This experi-
ment uses the sgx-emlPM node, as real SGX is the main factor
that dictates the performance differences. For each transaction
size we run SPS for 20 s. Figure 6 shows the throughput of
swap operations on a 10 MB persistent array with different
transaction sizes for different systems with a single threaded
application. We include results for two choices of PWB
implemented by Romulus and SGX-ROMULUS: clflush +
NOP and clflushopt + sfence. Our servers do not have
support for clwb.
the persistence fences
take approximately 1.6× to 3.7× longer to complete in
SGX-ROMULUS when compared to native (no SGX) systems
for transaction sizes between 2 and 2048 swaps operations
per transaction. When compared to Romulus in SCONE,
transactions for both fence implementations in SGX-ROMULUS
are approximately 1.5× to 2.5× slower for transaction sizes
between 2 to 64 swap operations per transaction. Beyond 64
swap operations per transaction, there is a pronounced drop
in throughput for Romulus in SCONE, and SGX-ROMULUS
We observe that
in both cases,
 0 10 20 30 40 500500100015002000CLFLUSH + NOPSwaps/µsSwaps/TXNativeSgx−romulusScone−romulus 0 10 20 30 40 500500100015002000CLFLUSHOPT + SFENCESwaps/TXcontributes more (66.4%) to the overall mirroring latency on
average for model sizes beneath 78 MB. This jumps to 92.3%
once the EPC limit is crossed. This overhead is due to expensive
page swapping between the EPC and regular DRAM by the
SGX kernel driver. For restores, reads contribute on average
75% and 91.2% for values beneath and beyond the EPC limit
respectively. Similarly, we have a high overhead beyond the
EPC limit due to the SGX driver’s page swaps. Our results
show in-enclave decryption is relatively cheaper.
For the emlSGX-PM server, without real SGX hardware
(hence no expensive page swaps), the main bottleneck is real
PM. We observe (Table Ib) that for server sgx-emlPM, writes
to PM are on average 7.9× and 9.6× faster when compared to
writes to SSD for enclave sizes beneath and beyond the EPC
limit respectively. SSD writes are generally more expensive due
the expensive ocalls and serialization operations to secondary
storage. Saves are overall 3.5× and 1.7× faster for enclave sizes
beneath and beyond the EPC limit respectively. Similarly, for
restores, reads from PM into enclave memory are on average
3× and 1.8× faster for enclave sizes beneath and beyond
the EPC limit respectively, when compared to the SSD-based
counterpart. Restores are overall 2.5× and 1.7× faster for
enclave sizes beneath and beyond the EPC limit. A similar
breakdown is done for the emlSGX-PM node.
Training larger models. Our results suggest PLINIUS is best
suited for models with sizes beneath the EPC limit. Models
larger than the EPC limit can be trained with PLINIUS but
this leads to a signiﬁcant drop in training performance due to
the extensive page swaps by the SGX kernel driver. Figure 7
shows our mirroring mechanism still peforms better than SSD-
based checkpointing for model sizes beyond the EPC limit.
A possible strategy to overcome the EPC limitation could be
to distribute the training job over multiple secure CPUs. We
will explore this idea in the future. Also, a recent processor
release by Intel expands the EPC to 256 MB [4]. This paves
the way for applications that leverage PLINIUS to train much
larger models more efﬁciently.
Mirroring frequency. By default PLINIUS does mirroring
after every iteration. The mirroring frequency can be easily
increased or decreased. All things being equal, a training
environment with a small or high frequency of failures will
require respectively, small or high mirroring frequencies to
achieve good fault tolerance guarantees.
Overhead of data batch decryptions. For efﬁciency rea-
sons, ML algorithms (e.g., SGD) manipulate training data
(a) Breakdown of mirroring steps
(%)
(b) PLINIUS speed-ups
SGX-emlPM emlSGX-PM
Save
Encrypt
Write
Restore
Read
Decrypt
SGX-emlPM emlSGX-PM
66.4%
92.3%
33.6%
7.7%
A
75%
91.2%
25%
8.8%
30.3%
69.7%
B
17.8%
82.2%
Save
Write
Total
Restore
Read
Total
7.9×
9.6×
3.5×
1.7×
A
3×
1.8×
2.5×
1.7×
4.5×
3.2×
B
16.8×
3.7×
TABLE I: Shaded cells: values beyond the EPC size.
8
Fig. 7: PM mirroring vs. checkpointing on SSD for sgx-emlPM
(top) and emlSGX-PM (bottom).
transactions are 1.6× to 6.9× faster. We justify this behaviour
as a result of limited space available for Romulus’ volatile
redo log in the SCONE container. These results suggest SGX-
ROMULUS is a preferable choice for our ML system, where
multiple operations are carried out on persistent models within
transactions of relatively larger sizes.
PM mirroring vs. SSD-based checkpointing. Next, we
compare the mirroring mechanism in PLINIUS to traditional
checkpointing on a SSD using SGX-DARKNET. For SSD
checkpointing, we use ocalls to fread and fwrite libC
routines to read/write from/to SSD. After each call to fwrite,
we ﬂush the libC buffers and issue an fsync, to ensure
data is actually written to secondary storage. We vary model
sizes by increasing the total number of convolutional layers.
We measure the times to save/mirror-out (encrypt in the
enclave and write to PM) and restore/mirror-in (read from
PM into enclave and decrypt), and compare these to SSD-based
checkpoint saves (encrypt and write to SSD) and SSD-based
checkpoint restores (read from SSD into enclave and decrypt),
which are the state-of-the-art methods for fault tolerance. All
data points are an average of 5 runs.
Figure 7 represents the results obtained on our two servers.
As a general observation, in PLINIUS, in-enclave data encryp-
tion contributes more to the save-latency (i.e., mirror-out) when
compared to writes to PM. For restores in PLINIUS, reads from
PM into enclave memory contribute more to the overall latency.
When compared to traditional saves and restores on SSD, our
mirroring mechanism gives less overhead.
Table Ia shows a performance breakdown of each mirroring
steps for saves and restores in PLINIUS, while Table Ib
shows the average performance improvements of our mirroring
mechanism when compared to SSD-based checkpointing. To
reduce the effect of outliers, we evaluate results beneath and
beyond the EPC limit separately. The usable EPC size is
93.5 MB, reached for model size 78 MB, due to the presence
of other data structures in enclave memory (e.g., temporary
buffers used for encryption) as well as enclave code. We observe
(Table Ia) that for saves in a real SGX environment, encryption
 0 200 400 600 8001022334456677889100sgx−emlPM − Mirroring Step: SaveLatency (ms)Model Size (MB)Encrypt (SSD)Write (SSD)Encrypt (PM)Write (PM) 0 200 400 600 8001022334456677889100sgx−emlPM − Mirroring Step: RestoreModel Size (MB)Read (SSD)Decrypt (SSD)Read (PM)Decrypt (PM) 0 200 4001022334456677889100emlSGX−PM − Mirroring Step: SaveLatency (ms)Model Size (MB)Encrypt (SSD)Write (SSD)Encrypt (PM)Write (PM) 0 200 4001022334456677889100emlSGX−PM − Mirroring Step: RestoreModel Size (MB)Read (SSD)Decrypt (SSD)Read (PM)Decrypt (PM)Fig. 8: Variation of iteration times with different batch sizes for
encrypted and unencrypted MNIST data.
Fig. 9: Crash/resumes are done by randomly killing and restarting
the training process every 10 to 15 minutes during model training.
in batches for each training iteration. In this experiment we
study the performance impact on total iteration time of batch
decryptions of training data into enclave memory. We proceed
by comparing the iteration times with different batch sizes for
a model being trained via the PLINIUS mechanism, to a model
trained with batches of unencrypted data on PM. We recall
that in PLINIUS, batches of encrypted training data are read
from PM and decrypted in enclave memory for each iteration.
All models have 5 LReLU-convolutional layers.
Figure 8 shows the results obtained on both systems. We
observe that iterations with batch decryption of data into
enclave memory are 1.2× slower on average for both systems.
We consider this a relatively small price to pay for data
conﬁdentiality during training.
Crash resilience. The main purpose of our experiments here
is to demonstrate that PLINIUS’s mirroring mechanism is crash
resilient (or failure transparent), as well as demonstrate the
performance impact on the training process of a non-crash-
resilient system. We deﬁne a crash-resilient system as one
capable of recovering its state (i.e., learned parameters) prior
to a system crash.The experiments consider models with 5
LReLU-convolutional layers, trained with the MNIST dataset
for 500 iterations. We study the variation of the loss while
doing random crashes during model training.
Figure 9 presents the results obtained on the emlSGX-PM
server, but similar results are obtained on sgx-emlPM. We
proceed by training a model using PLINIUS with 9 random
crashes (and resumptions) during the training process. We
compare the loss curve obtained here to one obtained without
any crashes (baseline). Figure 9(a) shows that despite the
crashes, the loss curve follows closely (no breaks at crash and
resume points) the one obtained without crashes. This indicates
the model parameters are saved and restored correctly using the
mirroring mechanism in PLINIUS. In comparison, Figure 9(b)
9
Fig. 10: Model training with AWS EC2 spot instance traces.
shows the loss curve obtained when the system cannot recover
its learned parameters following random crashes. For this
experiment we run our system while disabling model’s weights
saving via our mirroring mechanism. At every resumption
point,
the model begins the learning process with initial
randomized weights, and thus still requires 500 iterations to
be fully trained, hence increasing the total iterations (from
when training ﬁrst began) required to train the model to over
1000 in this experiment. This shows the beneﬁt of crash-
resilience in an ML system. In the next section, we use a
more realistic crash/resume pattern (spot instance trace) to
show crash resilience in PLINIUS.
PLINIUS on AWS EC2 Spot instances. A practical use
case for PLINIUS framework would be model training on spot
instances, such as those offered by Amazon EC2 and Microsoft
Azure. Spot instances are liable to many interruptions during
their lifetimes, and model training in such a scenario requires
efﬁcient fault tolerance guarantees (such as those provided by
PLINIUS) to reduce cost and increase efﬁciency of the training
process. We use Amazon EC2 spot instance traces from [38]
to simulate a realistic model training scenario with PLINIUS
on a spot instance. The spot traces contain market prices of
spot instances at different timestamps (5 minutes intervals). To
simulate spot model training, we set a maximum bid price in
our simulator script, and our simulation algorithm periodically
(every 5 minutes) compares the market price at each timestamp
in the spot trace to our bid price. If max_bid > market_price,
our training process is launched (or continues if it was already
running). Otherwise, the training process is killed. We train a
model with 12 LReLU-convolutional layers for 500 iterations
on server emlSGX-PM.
Figure 10(a) shows the loss curve obtained after 500
iterations. As explained in the previous section, this shows
PLINIUS is crash resilient as training resumes where it left
off prior to the training process being stopped. Figure 10(b)
shows a “state curve” of the training process (or spot instance)
throughout the training process. The process state is 1 when it
is running and 0 otherwise. We observe only 2 interruptions