in achieving security systems and greatly improves the
practicality of security property checking and veriﬁca-
tion tools.
388 
17th USENIX Security Symposium 
USENIX Association
# of rules
# of True Violations
Software
Linux
Xen
Total
Table 3: Overall results of AutoISES. Numbers in parentheses are true violations in warning reports.
False Positives in Errors
# Inspected Uninspected
265
0
265
1/6
1/2
2/8
51
33
84
28 (2)
25 (2)
3
7
1
8
# of Warnings
linux/fs/sys_splic.c:
static long do_splice_from(…, struct file *out,...)
{
Security check
linux/fs/sys_splic.c:
static long do_splice_to(struct file *in, ...)
{
Security check
linux/net/decnet/netfilter/dn_rtmsg.c:
static inline void dnrmg_receive_user_skb(..)
{
Security check
…
security_file_permission()
is missing here before
splice_write.
…
security_file_permission()
is missing here before
splice_read.
...
security_netlink_recv() should be
used instead of cap_raised() for
consistency.
return out->f_op->splice_write(...);
}
return in->f_op->splice_read(...);
}
if (!cap_raised(...))
RCV_SKB_FAIL(-EPERM); ...
}
(a)
(b)
(c)
Figure 6: True violations AutoISES automatically detected in the latest versions of Linux kernel. All of these violations have
already been conﬁrmed by the Linux developers.
5.1 Detected Violations
We manually examined every error report and only the
top warning reports (due to time constraints) to deter-
mine if a report is a true violation or a false positive.
5.1.1 True Violations
There are two types of true violations, exploitable viola-
tions and consistency violations.
Exploitable Violations Among the 8 true violations,
5 are exploitable violations. Figure 6 (a) and (b) show
two exploitable violations.
In Linux 2.6.21.5, secu-
rity check security file permission() was miss-
ing before the ﬁle splice read and ﬁle splice write op-
eration. Without the check, an unauthorized user could
splice data from pipe to ﬁle and vice versa, which could
cause permanent data loss, information leak, etc. This
violation has already been conﬁrmed by the Linux de-
velopers.
Consistency Violations We term the 3 remaining true
violations Consistency Violations, meaning that although
they may not be exploitable, they violate the consistency
of using security check functions. Such inconsistencies
can confuse developers and make the software difﬁcult
to maintain, both of which can contribute to more errors
in the future. Therefore, it is important for developers to
ﬁx consistency violations.
Figure 6 (c) shows an example of a consistency vio-
lation. A security check security netlink recv(),
before
checks
permission
processing
which
the
received netlink message, was missing in
dnrmg receive user skb(), which receives and
processes netlink messages. This error could cause
to receive messages from unauthorized
the kernel
users.
However,
dnrmg receive user skb()
did call
function cap raised(), which is what
security netlink recv() calls eventually. In other
words, it bypasses the security check interface functions,
and calls the backend security policy functions, which is
a bad practice and should be avoided.
At the time of writing, 2 out of the 3 consistency vi-
olations, including the example shown above, have been
conﬁrmed and ﬁxed by the corresponding developers.
5.1.2 False Positives
The false positive rate in error reports is 2 out of 8. There
are more false positives in the warning reports because
no untrusted-space exposability analysis is performed on
the warning reports. Developers can choose to focus on
the error reports to save time, or also examine the warn-
ings if desired.
Several factors can contribute to false positives. First,
as we use conservative function pointer alias analysis, we
can mistakenly consider accesses not related to an oper-
ation as part of the operation, and generate an imprecise
rule. These extra accesses do not need to be protected by
the security check, but our tool may still report such false
violations. A static analysis tool with more advanced
function pointer alias analysis could reduce such false
positives.
USENIX Association  
17th USENIX Security Symposium 
389
sys_io_getevents()
read_events()
(1)
aio_run_all_iocbs()
__aio_run_iocbs()
aio_run_iocb()
sys_io_submit()
io_submit_one()
(2)
aio_setup_iocb()
aio_run_iocb()
security_file_permission()
Figure 7: A false positive detected by AutoISES in Linux
kernel 2.6.21.5. Only related functions are shown.
check
Additionally, certain semantics of the target code
make some of
the detected errors not exploitable.
Figure 7 shows such an example where an im-
plicit
temporal constraint on certain system calls
allows the coverage of a security check to span
AutoISES reported that a
multiple system calls.
security
security file permission()
should be called before aio run iocb(), but
in
the call chain in Figure 7(1) starting from a sys-
tem call function sys io getevents(),
the check
security file permission() was missing. How-
ever, this is not an exploitable violation, because system
call sys io getevents() cannot be called without
system call sys io submit() being invoked ﬁrst,
which consults the proper security check in its callee
function aio setup iocb() in call chain (2). Because
AutoISES did not know this restriction in using the
system calls,
if
the ﬁle permission is changed after the setup system
call sys io submit() and before the invocation of
sys io getevents(), then unauthorized accesses can
occur. Linux developers conﬁrmed the potential of such
violations, but are unlikely to ﬁx it because the current
Linux implementation does not enforce protection
against this type of violations.
it reports the violation. However,
There are at least two ways to reduce or eliminate false
positives. First, we can employ more accurate static anal-
ysis techniques. Additionally, as increasing granular-
ity could reduce false positives (discussed later in Sec-
tion 5.3), we can experiment with even ﬁner granularity,
such as distinguishing increment, decrement, and zero-
ing operations, to further reduce false positives.
5.2 Parameter Sensitivity and Time Over-
head
default,
we
set
the
By
of
accessV iolationCount to be 50% of the rule size,
which is the total number of data structure accesses in
a rule. We found that for Linux, the detection results
are not very sensitive to this parameter, meaning that
threshold
most true violations perform all or almost all of the data
structure accesses, and false violations often perform
none or only a few of the data structure accesses.
These results show that the generated rules capture the
implicit security rules well, and these rules are effective
in helping detecting violations to them. For Xen, the
results are more sensitive to the threshold. A possible
explanation is that, in general Xen security checks are
called fewer times compared to Linux kernel, therefore,
there are fewer instances for AutoISES to learn precise
rules. As a result, the inferred Xen rules contain more
noisy accesses that do not need to be protected by the
check functions. In this case, we set the threshold to be
higher, 90%, to minimize the impact of noisy accesses.
AutoISES spent 86 minutes on inferring 51 rules from
the entire Linux kernel, and 116 minutes on using these
rules to check for violations in the entire Linux kernel.
As the code size of Xen is much smaller, the time spent
on Xen rule generation is 25 seconds, and 39 minutes for
detection. This shows that our tool is efﬁcient enough to
be used in practice for large real world software.
the implicit
security rules.
5.3 Impact of Rule Granularity
In many cases,
a coarse-grained rule is overly
generalized and thus does not precisely repre-
sent
For example,
two different checks, security file link() and
security file unlink() are designed to protect two
different inode operations. However, as shown in Fig-
ure 8(a), the inferred operations of Granularity(F −, A+)
are the same. Using ﬁner granularity, Granularity(F +,
A+), AutoISES is able to automatically infer two differ-
ent operations (Figure 8(b)-(c)). For example, the unlink
operation
access READ inode->i size,
which is not part of the link operation.
contains
Fine-grained rules cause less false positives during
the detection stage.
For 5 randomly selected secu-
rity checks, compared with the most coarse-grained
rules (Granularity(F −,A−)) our most ﬁne-grained rules
(Granularity(F +,A+)) on average cause 33% fewer
false positives (in both error reports and warning re-
ports). Granularity(F +, A−) cause 20% fewer false pos-
itives, and Granularity(F −, A+) 13.3% fewer. The re-
sults show that using ﬁner granularity can greatly reduce
the number of false positives, and adjusting the rule gran-
ularity could be considered as an important tuning pa-
rameter for other rule inference and violation detection
tools [9, 11, 20, 22, 30].
Although coarse-grained rules produce a higher
false positive rate, they can provide very useful infor-
mation that ﬁne-grained rules may fail to unveil.
In
the example above, the operation of Granularity(F −,
A+) is shared by almost all
inode related security
390 
17th USENIX Security Symposium 
USENIX Association
Rule of Granularity(F-, A+):
Security Check:
security_inode_link/security_inode_unlink
Protected operation:
1. READ dentry
2. READ inode
3. WRITE inode
4. READ nameidata
5. WRITE vfsmount
6. READ (Global) names_cachep
(a) rule for security_inode_link
and security_inode_unlink
Rule of Granularity(F+, A+):
Security Check:
security_inode_link
Protected operation:
1. READ inode->i_ino
2. READ inode->i_nlink
3. WRITE inode->i_nlink
4. READ inode->i_sb
...
Rule of Granularity(F+, A+):
Security Check:
security_inode_unlink
Protected operation:
1. READ inode->i_size
2. READ inode->i_ino
3. READ inode->i_nlink
4. WRITE inode->i_nlink
5. READ inode->i_sb
...
(b) rule for security_inode_link
(c) rule for security_inode_unlink
Figure 8: For two security checks, security file link() and security file unlink(), the inferred operations of
Granularity(F −, A+) are the same. If we use Granularity(F +, A+), the learned operations are different, e.g., the unlink operation
contains an extra access, READ inode->i size.
check functions,
including security inode rename(),
security inode rmdir(),
security inode mkdir(),
security file link(),
security file unlink(),
security inode symlink(), etc. Therefore, the rule
represent the common accesses of inode operations in
general. A more ﬁne-grained rule may fail to reveal the
common behavior among all inode and ﬁle operations.
In addition, a ﬁne-grained rule can be overly speciﬁc,
and cause false negatives. We did not observe such cases
for our most ﬁne-grained rules in this study, i.e., our most
ﬁne-grained rules were able to detect all of the true viola-
tions. The result indicates that the default granularity we
use is the best among the 4 levels of granularity in terms
of detection accuracy, as they produce the least number
of false positives, and the same number of false nega-
tives as the coarse-grained rules. In the future, we plan
to experiment with even ﬁner granularity and its impact
on both false positives and false negatives.
Results from different levels of granularity can be used
as a metric for violation ranking. For example, a viola-
tion that is reported at all levels of granularity is probably
more likely to be a true violation than one that is reported
only at some levels. In our future work, we will explore
using the number of granularity levels a violation occurs
at to rank violations.
6 Discussions and Limitations
6.1 Key Techniques that Make AutoISES
Work
Automatically generating security speciﬁcations poses
several key challenges that make previous static analy-
sis tools not directly applicable. We designed ﬁve im-
portant techniques (ﬁrst four are new) to address these
challenges as summarized below (Sec. column lists cor-
responding sections that describe the techniques):
Challenge
How to represent a sensitive
operation at the code level
High false positive rates as
many sensitive operations
can not be exposed to the
untrusted space
Root functions for analysis:
Cannot simply start analysis
from direct callers of a secu-
rity check function
Insufﬁcient
stances of
functions
invocation
in-
security check
Data structure accesses are
spread in different functions.
Our Solution
Use Data structure accesses
based on our key observation
Simple untrusted space ex-
posability study to greatly re-
duce false positives
Automatic root function dis-
covery: Automatically dis-
cover functions that actually
use security check functions
for authorization check
different
Leverage
im-
plementations
(e.g.,
from
different ﬁle systems) of the