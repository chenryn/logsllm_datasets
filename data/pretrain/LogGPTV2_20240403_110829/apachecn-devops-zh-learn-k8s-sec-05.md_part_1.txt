# 五、配置 Kubernetes 安全边界
安全边界分隔安全域，其中一组实体共享相同的安全关注点和访问级别，而信任边界是程序执行和数据改变信任级别的分界线。安全边界中的控件确保在没有适当验证的情况下，在边界之间移动的执行不会提升信任级别。当数据或执行在没有适当控制的情况下在安全边界之间移动时，安全漏洞就会出现。
在本章中，我们将讨论安全和信任边界的重要性。我们将首先关注介绍，以澄清安全和信任边界之间的任何混淆。然后，我们将遍历 Kubernetes 生态系统中的安全域和安全边界。最后，我们将了解一些 Kubernetes 特性，这些特性增强了部署在 Kubernetes 中的应用的安全边界。
您应该理解安全域和安全边界的概念，也应该理解基于底层容器技术围绕 Kubernetes 构建的安全边界，以及内置的安全功能，如 PodSecurityPolicy 和 NetworkPolicy。
我们将在本章中讨论以下主题:
*   安全边界介绍
*   安全边界与信任边界
*   Kubernetes 安全域
*   作为安全边界的 Kubernetes 实体
*   系统层的安全边界
*   网络层的安全边界
# 安全边界介绍
安全边界存在于数据层、网络层和系统层。安全界限取决于信息技术部门或基础设施团队使用的技术。例如，公司使用虚拟机来管理其应用—虚拟机管理程序是虚拟机的安全边界。虚拟机管理程序确保虚拟机中运行的代码不会从虚拟机中逸出或影响物理节点。当公司开始采用微服务并使用编排器来管理他们的应用时，容器就是安全边界之一。但是，与虚拟机管理程序相比，容器并不提供强有力的安全边界，也不是为了。容器在应用层实施限制，但不能阻止攻击者从内核层绕过这些限制。
在网络层，传统上，防火墙为应用提供强大的安全边界。在微服务架构中，Kubernetes 中的 Pods 可以与其他人进行通信。网络策略用于限制 Pods 和服务之间的通信。
数据层的安全边界是众所周知的。内核将对系统或 bin 目录的写访问权限限制为仅根用户或系统用户，这是数据层安全边界的一个简单示例。在容器化的环境中，chroot 防止容器篡改其他容器的文件系统。Kubernetes 以一种可以在网络层和系统层强制实施强安全边界的方式来重构应用部署。
# 安全边界与信任边界
安全边界和信任边界经常被用作同义词。虽然相似，但这两个术语之间存在着的细微差别。一个**信任边界**是系统改变其信任级别的地方。执行信任边界是指令需要不同权限才能运行的地方。例如，在`/bin`中执行代码的数据库服务器就是一个跨越信任边界的执行示例。类似地，数据信任边界是数据在具有不同信任级别的实体之间移动的地方。终端用户插入到可信数据库中的数据是数据跨越信任边界的一个例子。
**安全边界**是不同安全域之间的分界点，而安全域是同一访问级别内的一组实体。例如，在传统的 web 架构中，面向用户的应用是安全域的一部分，而内部网络是不同安全域的一部分。安全边界有与之相关的访问控制。把信任边界想象成一堵墙，把安全边界想象成围绕着墙的栅栏。
确定生态系统中的安全和信任边界非常重要。它有助于确保在越过边界之前对指令和数据进行适当的验证。在 Kubernetes 中，组件和对象跨越不同的安全边界。当攻击者越过安全边界时，理解这些边界以制定风险缓解计划是很重要的。CVE-2018-1002105 是因跨越信任边界的验证缺失而导致的攻击的主要例子；API 服务器中的代理请求处理允许未经身份验证的用户获得群集的管理员权限。同样，CVE-2018-18264 允许用户跳过仪表板上的身份验证过程，以允许未经身份验证的用户访问敏感的群集信息。
现在我们来看看不同的 Kubernetes 安全域名 ins。
# Kubernetes 安全域
Kubernetes 集群可以大致分为三个安全域:
*   **Kubernetes 主组件**:Kubernetes 主组件定义了 Kubernetes 生态系统的控制平面。主组件负责集群平稳运行所需的决策，如调度。主组件包括`kube-apiserver`、`etcd`、`kube-controller`管理器、DNS 服务器和`kube-scheduler`。Kubernetes 主组件中的漏洞会危及整个 Kubernetes 集群。
*   **Kubernetes 工作组件** : Kubernetes 工作组件部署在每个工作节点上，确保 Pods 和容器运行良好。Kubernetes 工作组件使用授权和 TLS 隧道与主组件通信。集群可以在工作组件受损的情况下运行。它类似于环境中的流氓节点，一旦被识别，就可以从集群中删除。
*   **Kubernetes 对象** : Kubernetes 对象是表示集群状态的持久实体:部署的应用、卷和命名空间。Kubernetes 对象包括 Pods、服务、卷和名称空间。这些由开发人员或 DevOps 部署。对象规范为对象定义了额外的安全边界:定义一个带有安全上下文的 Pod、与其他 Pod 通信的网络规则等等。
高级安全域部门应该帮助您专注于关键资产。记住这一点，我们将开始研究 Kubernetes 实体和为它们建立的安全边界。
# 作为安全边界的 Kubernetes 实体
在 Kubernetes 集群中，您与之交互的 Kubernetes 实体(对象和组件)有自己的内置安全边界。安全边界源自实体的设计或实现。理解构建在它们内部或周围的安全界限非常重要:
*   **容器**:容器是 Kubernetes 集群中的基本组件。容器使用 cgroups、Linux 名称空间、AppArmor 配置文件和运行在容器内的应用的 seccomp 配置文件为应用提供最小隔离。
*   **PODS**:PODS 是一个或多个容器的集合。与容器相比，Pods 隔离了更多的资源，例如网络和 IPC。安全上下文、网络策略和 PodSecurityPolicy 等功能在 pod 级别工作，以确保更高级别的隔离。
*   **节点**:Kubernetes 的节点也是安全边界。可以使用`nodeSelectors`指定 Pods 在特定节点上运行。内核和虚拟机管理程序对节点上运行的 Pod 实施安全控制。像 AppArmor 和 SELinux 这样的特性以及其他主机强化机制可以帮助提高安全性。
*   **集群**:集群是主节点和工作节点上的荚、容器和组件的集合。一个集群提供了强大的安全边界。在一个集群内运行的 Pods 和容器在网络和系统层与其他集群隔离。
*   **命名空间**:命名空间是隔离 pods 和服务的虚拟集群。LimitRanger 准入控制器在名称空间级别应用来控制资源利用和拒绝服务攻击。网络策略可以应用于命名空间级别。
*   **Kubernetes API 服务器**:Kubernetes API 服务器与所有 Kubernetes 组件交互，包括`etcd`、`controller-manager`和`kubelet`，这是集群管理员用来配置集群的。它调解与主组件的通信，因此集群管理员不必直接与集群组件交互。
我们在 [*第 3 章*](03.html#_idTextAnchor091)*威胁建模*中讨论了三种不同的威胁参与者:权限攻击者、内部攻击者和最终用户。这些威胁行为者也可能与前面的 Kubernetes 实体进行交互。我们将看到攻击者面临这些实体的安全边界:
*   **终端用户**:终端用户或者与入口交互，或者直接与节点上的开放端口交互。对于最终用户来说，节点、Pods、`kube-apiserver`和外部防火墙保护集群组件不受损害。
*   **内部攻击者**:内部攻击者可以访问 Pods 和容器。由`kube-apiserver`实施的名称空间和访问控制防止这些攻击者升级权限或危害集群。网络政策和 RBAC 控制可以防止横向移动。
*   **权限攻击者** : `kube-apiserver`是保护主组件免受权限攻击者危害的唯一安全边界。如果权限攻击者妥协`kube-apiserver`，游戏就结束了。
在本节中，我们从用户的角度来看安全边界，并向您展示了安全边界是如何在 Kubernetes 生态系统中构建的。接下来，让我们从微服务的角度来看系统层的安全边界。
# 系统层的安全边界
微服务在 Pods 内部运行，Pods 计划在集群中的工作节点上运行。在前面的章节中，我们已经强调了容器是一个被分配了专用 Linux 名称空间的进程。容器或 Pod 消耗了工作节点提供的所有必要资源。因此，从系统的角度理解安全边界以及如何加强它是很重要的。在本节中，我们将一起讨论基于 Linux 名称空间和 Linux 功能构建的微服务的安全边界。
## Linux 命名空间作为安全边界
Linux 命名空间是 Linux 内核的一个特性，用于出于隔离目的对资源进行分区。通过分配名称空间，一组进程可以看到一组资源，而另一组进程可以看到另一组资源。我们已经在 [*第 2 章*](02.html#_idTextAnchor049)*Kubernetes Networking*中介绍了 Linux 名称空间。默认情况下，每个 Pod 都有自己的网络命名空间和 IPC 命名空间。同一 pod 中的每个容器都有自己的 PID 名称空间，因此一个容器不知道同一 Pod 中运行的其他容器。同样，一个 Pod 不知道同一工作节点中存在其他 Pod。
总的来说，从安全角度来看，默认设置为微服务提供了相当好的隔离。但是，允许在 Kubernetes 工作负载中配置主机命名空间设置，更具体地说，在 Pod 规范中。启用这些设置后，微服务使用主机级命名空间:
*   **主机网络**:Pod 使用主机的网络命名空间。
*   **主机 IPC**:Pod 使用主机的 IPC 命名空间。
*   **主机 PID**:Pod 使用主机的 PID 命名空间。
*   **共享进程名称空间**:同一个 Pod 中的容器将共享一个 PID 名称空间。
当您尝试将工作负载配置为使用主机名称空间时，一定要问自己一个问题:为什么必须这样做？当使用主机名称空间时，pods 完全了解同一个工作节点中其他 pods 的活动，但这也取决于分配给容器的 Linux 功能。总的来说，事实是，您解除了其他微服务的安全界限。让我举一个简单的例子。这是容器内可见的进程列表:
```
root@nginx-2:/# ps aux
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root           1  0.1  0.0  32648  5256 ?        Ss   23:47   0:00 nginx: master process nginx -g daemon off;
nginx          6  0.0  0.0  33104  2348 ?        S    23:47   0:00 nginx: worker process
root           7  0.0  0.0  18192  3248 pts/0    Ss   23:48   0:00 bash
root          13  0.0  0.0  36636  2816 pts/0    R+   23:48   0:00 ps aux
```
如您所见，在`nginx`容器内，从容器中只能看到`nginx`流程和`bash`流程。这个`nginx` pod 不使用主机 PID 命名空间。让我们看看如果 pod 使用主机 PID 命名空间会发生什么:
```
root@gke-demo-cluster-default-pool-c9e3510c-tfgh:/# ps axu
USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND