void GetData(
void Sink(
OperatorResultType Execute(
DataChunk &chunk,
GlobalSinkState &gstate,
DataChunk &input,
GlobalSourceState &gstate,
LocalSinkState &lstate,
LocalSourceState &lstate); DataChunk &chunk,
DataChunk &input);
OperatorState &state);
void Combine(
GlobalSinkState &gstate,
LocalSinkState &lstate);
void Finalize(
GlobalSinkState &gstate);
DuckDB - Pipelines
GROUP BY cid
FIRST(name), SUM(rev+tax)
HASH JOIN
cust.cid=sale.cid
Pipeline 2 (HT Probe + Aggregate)
Scan Scan
cust sale
Sink
GROUP BY cid
FIRST(name), SUM(rev+tax)
Pipeline 1 (HT Build)
Operator
Sink
HASH JOIN
HASH JOIN
cust.cid=sale.cid
cust.cid=sale.cid
Source
Source
Scan
Scan
sale
cust
DuckDB - Push-Based Execution
• Pull-based: the control flow lives insides the operator
• Very flexible!
• Built on recursive calls - the call stack holds all state
Volcano
void Projection::GetChunk(DataChunk &result) {
// get the next chunk from the child
child->GetChunk(child_chunk);
HashAggregate::GetChunk(DataChunk &result)
if (child_chunk.size() == 0) {
HashJoin::GetChunk(DataChunk &result)
return;
Projection::GetChunk(DataChunk &result)
}
Table::GetChunk(DataChunk &result)
// execute expressions
executor.Execute(child_chunk, result);
}
DuckDB - Push-Based Execution
• Push-based: control flow happens in a central location
• This has a number of advantages
Push-Based
void Projection::Execute(DataChunk &input, DataChunk &result) {
executor.Execute(input, result);
}
class PipelineState {
public:
//! Intermediate chunks for the operators
vector> intermediate_chunks;
}
DuckDB - Push-Based Execution
• Handling control flow in a central location enables optimizations
Vector Cache Scan Sharing
Add small caches between operators We can push results of one scan
into multiple sinks
GROUP BY item
SUM(rev+tax) Scan AGGREGATE
sale SUM(rev)
FILTER
sale >= 90% GROUP BY item
SUM(rev+tax)
Scan
sale
DuckDB - Push-Based Execution
• Storing state in a central location allows us to pause execution
Backpressure
Async I/O
Pause pipeline when buffer is full
Pause pipeline while HTTP request is in progress
Resume when buffer is empty
Resume when data is available
HASH JOIN
BUFFER
cust.cid=sale.cid
10MB
HTTP Scan
HASH JOIN
sale
cust.cid=sale.cid
Scan
cust
Storage
DuckDB - Table Storage
• DuckDB uses a single-file block-based storage format
• WAL is stored as a separate file
• Support for ACID using headers
BLOCK_SIZE = 256KB
4K
4K 4K BLOCK_SIZE
INFO HEADER_ONE HEADER_TWO BLOCK BLOCK
block id 0 block id 1
DuckDB - Table Storage
• Tables are partitioned into row groups
• Each row group has 120K~ rows
• Row groups are the parallelism and checkpoint unit
taxi.db
Row Group 1 Row Group 2
pickup_at dropoff_at pickup_at dropoff_at
Rows 0-120K Rows 120K-240K
DuckDB - Table Storage
• Compression works very well with columnar storage
• Speeds up I/O
• Can speed up execution (see vectors!)
• Compression can make data smaller and queries faster
DuckDB - Table Storage
• General-purpose, heavy-weight compression
• gzip, zstd, snappy, lz4
• Finds patterns in bits
• Special purpose, lightweight compression
• RLE, bitpacking, dictionary, FOR, delta, …
• Finds specific patterns in data
DuckDB - Table Storage
• General-purpose compression is simple to apply
• Works great for space saving!
• However…
• Higher (de)compression speed slows down execution
• Need to decompress in bulk - no random seeks or compressed
execution!
DuckDB - Table Storage
• Lightweight compression detects specific patterns
• Very fast!
• Patterns can be exploited during execution
• Downside: No effect if the patterns are not there!
• We need to implement/use multiple different algorithms
DuckDB - Table Storage
Row Group 1
• Compression works per-column per row-group
pickup_at dropoff_at
• Two phases:
• Analyze
• Figure out which compression method is best
• Compress
• Use the best compression method to compress the column
DuckDB - Table Storage
duckdb.org/2022/10/28/lightweight-compression.html
Lightning Round
DuckDB - Buffer Manager
• Custom lock-free buffer manager
• Inspired by lean-store
• Granularity: 256KB blocks
• Traditional buffer manager functionality:
• Set memory limit
• Pin blocks to fix them in memory
• Unpin blocks to tell the system it is alright to release them
DuckDB - Out-Of-Core
• DuckDB supports larger-than-memory execution
Out-Of-Core Hash Join
• Streaming engine
• Special join, sort & window algorithms
• Goal: Gracefully degrade performance
• Avoid performance cliff!
DuckDB - Transactions
• DuckDB supports ACID transactions
• Based on HyPer MVCC model
• Optimized for vectorized processing
• DuckDB supports snapshot isolation
MVCC
Latest V1 V2
• Optimistic concurrency control
• Changes to the same rows → transaction abort
DuckDB - External Formats
• DuckDB supports querying directly over many formats
• Parquet, CSV, JSON, Arrow, Pandas, SQLite, Postgres, …
$ duckdb
D FROM lineitem.parquet;
┌────────────┬───────────┬───────────┬───┬───────────────────┬────────────┬──────────────────────┐
│ l_orderkey │ l_partkey │ l_suppkey │ … │ l_shipinstruct │ l_shipmode │ l_comment │
│ int32 │ int32 │ int32 │ │ varchar │ varchar │ varchar │
├────────────┼───────────┼───────────┼───┼───────────────────┼────────────┼──────────────────────┤
│ 1 │ 155190 │ 7706 │ … │ DELIVER IN PERSON │ TRUCK │ to beans x-ray car… │
│ 1 │ 67310 │ 7311 │ … │ TAKE BACK RETURN │ MAIL │ according to the … │
│ 1 │ 63700 │ 3701 │ … │ TAKE BACK RETURN │ REG AIR │ ourts cajole above… │
│ 1 │ 2132 │ 4633 │ … │ NONE │ AIR │ s cajole busily ab… │
│ 1 │ 24027 │ 1534 │ … │ NONE │ FOB │ the regular, regu… │
│ · │ · │ · │ · │ · │ · │ · │
│ · │ · │ · │ · │ · │ · │ · │
│ · │ · │ · │ · │ · │ · │ · │
│ 5999975 │ 7272 │ 2273 │ … │ COLLECT COD │ REG AIR │ ld deposits aga │
│ 5999975 │ 6452 │ 1453 │ … │ DELIVER IN PERSON │ SHIP │ ffily along the sly │
│ 5999975 │ 37131 │ 2138 │ … │ DELIVER IN PERSON │ FOB │ counts cajole even… │
│ 6000000 │ 32255 │ 2256 │ … │ TAKE BACK RETURN │ MAIL │ riously pe │
│ 6000000 │ 96127 │ 6128 │ … │ NONE │ AIR │ pecial excuses nag… │
├────────────┴───────────┴───────────┴───┴───────────────────┴────────────┴──────────────────────┤
│ 6001215 rows (10 shown) 16 columns (6 shown) │
└────────────────────────────────────────────────────────────────────────────────────────────────┘
DuckDB - Pluggable Catalog
• DuckDB supports attaching multiple databases and has a fully
pluggable catalog
$ duckdb
D ATTACH 'sqlite.db' (TYPE sqlite);
D SELECT database_name, path, type FROM duckdb_databases();
┌───────────────┬───────────┬─────────┐
│ database_name │ path │ type │
│ varchar │ varchar │ varchar │
├───────────────┼───────────┼─────────┤
│ sqlite │ sqlite.db │ sqlite │
│ memory │ NULL │ duckdb │
└───────────────┴───────────┴─────────┘
D USE sqlite;
D CREATE TABLE lineitem AS FROM ‘lineitem.parquet';
D CREATE VIEW lineitem_subset AS
SELECT l_orderkey, l_partkey, l_suppkey, l_comment FROM lineitem;
$ sqlite3 sqlite.db
sqlite> SELECT * FROM lineitem_subset LIMIT 3;
┌────────────┬───────────┬───────────┬─────────────────────────────────────┐
│ l_orderkey │ l_partkey │ l_suppkey │ l_comment │
├────────────┼───────────┼───────────┼─────────────────────────────────────┤
│ 1 │ 155190 │ 7706 │ to beans x-ray carefull │
│ 1 │ 67310 │ 7311 │ according to the final foxes. qui │
│ 1 │ 63700 │ 3701 │ ourts cajole above the furiou │
└────────────┴───────────┴───────────┴─────────────────────────────────────┘
DuckDB - Pluggable File System + HTTP/Object Store Reads
• DuckDB has a pluggable file system
• Used for querying over HTTP/S3/object stores
$ duckdb
D LOAD httpfs;
D FROM 'https://github.com/duckdb/duckdb-data/releases/download/v1.0/yellowcab.parquet';
┌──────────┬──────────────────────┬──────────────────────┬───┬──────────────┬──────────────────────┬──────────────┐
│ VendorID │ tpep_pickup_datetime │ tpep_dropoff_datet… │ … │ tolls_amount │ improvement_surcha… │ total_amount │
│ int32 │ varchar │ varchar │ │ varchar │ varchar │ varchar │
├──────────┼──────────────────────┼──────────────────────┼───┼──────────────┼──────────────────────┼──────────────┤
│ 2 │ 2016-01-01 00:00:00 │ 2016-01-01 00:00:00 │ … │ 0 │ 0.3 │ 8.8 │
│ 2 │ 2016-01-01 00:00:00 │ 2016-01-01 00:00:00 │ … │ 0 │ 0.3 │ 19.3 │
│ 2 │ 2016-01-01 00:00:00 │ 2016-01-01 00:00:00 │ … │ 0 │ 0.3 │ 34.3 │
│ 2 │ 2016-01-01 00:00:00 │ 2016-01-01 00:00:00 │ … │ 0 │ 0.3 │ 17.3 │
│ 2 │ 2016-01-01 00:00:00 │ 2016-01-01 00:00:00 │ … │ 0 │ 0.3 │ 8.8 │
│ · │ · │ · │ · │ · │ · │ · │
│ · │ · │ · │ · │ · │ · │ · │
│ · │ · │ · │ · │ · │ · │ · │
│ 1 │ 2016-01-01 13:03:57 │ 2016-01-01 13:10:39 │ … │ 0 │ 0.3 │ 7.8 │
│ 2 │ 2016-01-01 13:03:57 │ 2016-01-01 13:15:13 │ … │ 0 │ 0.3 │ 13.33 │
│ 1 │ 2016-01-01 13:03:58 │ 2016-01-01 13:39:53 │ … │ 10.5 │ 0.3 │ 98.8 │
│ 2 │ 2016-01-01 13:03:58 │ 2016-01-01 13:07:47 │ … │ 0 │ 0.3 │ 6.36 │
│ 2 │ 2016-01-01 13:03:58 │ 2016-01-01 13:21:01 │ … │ NULL │ NULL │ NULL │
├──────────┴──────────────────────┴──────────────────────┴───┴──────────────┴──────────────────────┴──────────────┤
│ 234118 rows (10 shown) 19 columns (6 shown) │
└─────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘
DuckDB - Extensions
• DuckDB offers support for extensions
• Distributed through INSTALL and LOAD commands
• Can be loaded as a shared library
• Many of our core features are implemented as extensions
┌──────────────────┬────────┬───────────┬──────────────┬──────────────────────────────────────────────────────────────────────┐
│ extension_name │ loaded │ installed │ install_path │ description │
├──────────────────┼────────┼───────────┼──────────────┼──────────────────────────────────────────────────────────────────────┤
│ fts │ false │ false │ │ Adds support for Full-Text Search Indexes │
│ httpfs │ false │ false │ │ Adds support for reading and writing files over a HTTP(S) connection │
│ icu │ true │ true │ (BUILT-IN) │ Adds support for time zones and collations using the ICU library │
│ json │ false │ false │ │ Adds support for JSON operations │
│ parquet │ true │ true │ (BUILT-IN) │ Adds support for reading and writing parquet files │
│ postgres_scanner │ false │ false │ │ Adds support for reading from a Postgres database │
│ sqlite_scanner │ false │ false │ │ Adds support for reading SQLite database files │
│ substrait │ false │ false │ │ Adds support for the Substrait integration │
│ tpcds │ false │ false │ │ Adds TPC-DS data generation and query support │
│ tpch │ true │ true │ (BUILT-IN) │ Adds TPC-H data generation and query support │
└──────────────────┴────────┴───────────┴──────────────┴──────────────────────────────────────────────────────────────────────┘
DuckDB - WASM
• DuckDB has a WASM build
• Runs inside the browser
• And it is actually fast!
DuckDB - Conclusion
• DuckDB is free and open source
• Contributions are welcome!
• We have a website - https://duckdb.org/
• Source code - https://github.com/duckdb/duckdb
Thanks for having me!
Any questions?
@duckdb duckdb.org
discord.gg/tcvwpjfnZx