# Title: Hands-Off the Wheel in Autonomous Vehicles? A Systems Perspective on Over a Million Miles of Field Data

**Authors:**
- Subho S. Banerjee
- Saurabh Jha
- James Cyriac
- Zbigniew T. Kalbarczyk
- Ravishankar K. Iyer

**Affiliations:**
- §Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL 61801, USA.
- †Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL 61801, USA.

**Abstract:**
Autonomous vehicle (AV) technology is rapidly becoming a reality on U.S. roads, promising improvements in traffic management, safety, and the comfort and efficiency of vehicular travel. According to the California Department of Motor Vehicles (DMV), between 2014 and 2017, manufacturers tested 144 AVs, driving a cumulative 1,116,605 autonomous miles, with 5,328 disengagements and 42 accidents reported. This paper investigates the causes, dynamics, and impacts of these AV failures by analyzing disengagement and accident reports from public DMV databases. Our findings include that AVs are 15 to 4,000 times more likely to be involved in accidents per mile driven compared to human-driven vehicles. Additionally, drivers of AVs need to remain as alert as those of non-AVs, and machine-learning-based systems for perception and decision-making are the primary cause of 64% of all disengagements.

**Index Terms:**
- Autonomous Vehicles
- Reliability
- Fault Characterization
- Disengagement
- Accident

## I. Introduction
Autonomous vehicle (AV) technologies are heralded as transformative, with the potential to improve traffic congestion, safety, productivity, and comfort [1]. Several U.S. states, including California, Texas, Nevada, Pennsylvania, and Florida, have begun testing AVs on public roads. Previous research has focused on the design of automation technology [2]–[7], its adoption [8], the impact of AVs on congestion [9], and legal and regulatory barriers [10]–[15]. As semi- and fully-automated vehicles become more prevalent, safety and reliability are critical for public acceptance and adoption. This paper evaluates the reliability of AVs by analyzing the causes, dynamics, and impacts of failures across various manufacturers using publicly available field data from tests on California public roads, including urban streets, freeways, and highways.

### Dataset
The California Department of Motor Vehicles (CA DMV) requires all manufacturers testing AVs on public roads to file annual reports detailing disengagements (failures that cause control to switch from the software to the human driver) and accidents (actual collisions with other vehicles, pedestrians, or property) [16]. Our focus is on semi-autonomous vehicles that require a human driver as a fallback in case of failure. We analyze field data collected over a 26-month period from September 2014 to November 2016, covering 12 AV manufacturers, 144 vehicles, and 1,116,605 autonomous miles. Across all manufacturers, we observed 5,328 disengagements, 42 of which led to accidents.

### Results
This paper presents:
1. An end-to-end workflow for analyzing AV failure data.
2. Insights into failure modes in AVs, including:
   - Drivers of AVs need to remain as alert as drivers of non-AVs.
   - For the same number of miles driven, human-driven non-AVs were 15 to 4,000 times less likely to be involved in an accident.
   - 64% of disengagements were due to problems in, or untimely decisions made by, the machine learning system.
   - In terms of reliability per mission, AVs are 4.22 times worse than airplanes but 2.5 times better than surgical robots.

These findings suggest that while individual components of AV technology (e.g., vision and control systems) may have matured, entire AV systems are still in a "burn-in" phase. Our analysis shows a distinct improvement in AV performance over time, but also highlights the need for continued improvement in dependability.

### Organization
Figure 1 illustrates the end-to-end pipeline for processing failure data from autonomous vehicles. Section II describes two real examples of AV-related accidents on California roads. Section III details the AVs and the data collection methodology (Stage I of the pipeline). Section IV covers the preprocessing, filtering, and natural language processing (NLP) steps required to convert the data into a format suitable for analysis (Stages II & III of the pipeline). Section V presents the statistical analysis of the failure data and summarizes the insights derived (Stage IV of the pipeline). Finally, Sections VI to VIII discuss threats to validity, related work, and conclusions, respectively.

## II. Case Studies
In this section, we present two representative case studies based on real events that occurred in Mountain View, CA. These case studies illustrate how issues in the perception, learning, and control systems of an AV can lead to accidents.

### A. Case Study I: Real-Time Decisions
Example 1 in Figure 2 shows a scenario where the human driver of the AV proactively took control from the autonomous agent to prevent an accident but was unable to rectify the situation in time. The disengagement report logs the error as either “Disengage for a recklessly behaving road user” or “incorrect behavior prediction.” Specifically, a Waymo prototype vehicle was in autonomous mode at a street intersection when a pedestrian started to cross. The AV decided to yield but did not stop. The test driver took control as a precaution. In this complex scenario, the driver had limited options and braked, resulting in a rear collision.

### B. Case Study II: Anticipating AV Behavior
Example 2 in Figure 2 shows a scenario where a Waymo prototype vehicle was hit by a manual vehicle from the rear at a street intersection. The disengagement report logs the cause as “Disengage for a recklessly behaving road user.” The AV had signaled a right turn and decelerated, then came to a complete stop before moving again to gauge traffic. The rear vehicle driver misinterpreted the AV's movements and collided with it.

### C. Summary
By law, both accidents were caused by the drivers in the non-AVs; however, close inspection of the accident reports shows that the AVs had a significant share of the responsibility. These examples highlight the poor decision-making of AVs leading to accidents.

1. **Complex Scenarios:** Street intersections represent complex scenarios where AVs must analyze multiple traffic flows and make decisions in a constrained environment. Failures are attributed to the learning-based perception system, which did not infer the evolving environment dynamics in time, leading to inadequate decisions.
2. **Driver Reaction Time:** In both cases, drivers either voluntarily took or were forced to take control in complex and dynamic traffic scenarios, often with very little time to react and undo the AV's actions.
3. **Anticipation by Other Drivers:** Drivers in non-AVs often cannot anticipate decisions made by AVs, leading to accidents.

Using the limited publicly available information about the design of AV systems, we draw our conclusions by analyzing human-entered textual logs containing information about accidents and disengagements. Our method localizes failures to the learning, perception, and decision-and-control subsystems of an AV to understand the causes of disengagements and accidents.

## III. AV System Description and Data Collection

### A. Preliminaries
1. **Autonomous Vehicles (AVs):** An AV uses an autonomous driving system (ADS) capable of supporting and assisting a human driver in controlling the main functions of steering and acceleration, and monitoring the surrounding environment (e.g., other vehicles/pedestrians, traffic signals, and road markings) [21].
2. **SAE Levels of Autonomy:** The Society of Automotive Engineers (SAE) defines six levels of autonomy, from 0 (no automation) to 5 (full, unrestricted automation). Levels 0–2 (e.g., anti-lock braking, cruise control) require a human driver to monitor the environment, while Levels 3–5 involve truly automated driving systems where the AV monitors the environment and controls the vehicle. This paper focuses on Level 3 vehicles.
3. **Disengagements:** Level 3 requires the presence of a human driver to serve as a fallback when the autonomous system fails. A transfer of control from the autonomous system to the human driver in case of a failure is called a disengagement. Disengagements can be initiated manually by the driver or autonomously by the car.
4. **Accidents:** An accident is an actual collision with other vehicles, pedestrians, or property. Not all disengagements lead to collisions; most are handled safely by human operators, with only a small fraction leading to accidents.

### B. AV Hierarchical Control Structure
Manufacturers have not disclosed the architectures of their autonomous vehicles. To identify multidimensional causes of AV disengagements/accidents, we built a hierarchical control structure for AVs using the systems-theoretic hazard modeling and analysis abstraction STPA (Systems-Theoretic Process Analysis) [23]. Figure 3 shows an AV hierarchical control structure derived from technical documentation [22], [24]–[27]. This system, referred to as the "Autonomous Driving System" (ADS), includes major components such as sensors (e.g., GPS, RADAR, LIDAR, and cameras) responsible for gathering environmental data.

**Figure 1.** The end-to-end data collection, processing, and analysis pipeline that forms the basis of this study.

**Figure 2.** Accident scenarios.

**Figure 3.** AV hierarchical control structure.