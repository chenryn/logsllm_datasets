title:Hands Off the Wheel in Autonomous Vehicles?: A Systems Perspective
on over a Million Miles of Field Data
author:Subho S. Banerjee and
Saurabh Jha and
James Cyriac and
Zbigniew T. Kalbarczyk and
Ravishankar K. Iyer
2018 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Hands Off the Wheel in Autonomous Vehicles?
A Systems Perspective on over a Million Miles of Field Data
Subho S. Banerjee§, Saurabh Jha§, James Cyriac†, Zbigniew T. Kalbarczyk† and Ravishankar K. Iyer†§
§Department of Computer Science, †Department of Electrical and Computer Engineering,
University of Illinois at Urbana-Champaign, Urbana IL - 61801, USA.
Abstract—Autonomous vehicle (AV) technology is rapidly be-
coming a reality on U.S. roads, offering the promise of im-
provements in trafﬁc management, safety, and the comfort and
efﬁciency of vehicular travel. The California Department of
Motor Vehicles (DMV) reports that between 2014 and 2017,
manufacturers tested 144 AVs, driving a cumulative 1,116,605
autonomous miles, and reported 5,328 disengagements and 42
accidents involving AVs on public roads. This paper investigates
the causes, dynamics, and impacts of such AV failures by ana-
lyzing disengagement and accident reports obtained from public
DMV databases. We draw several conclusions. For example, we
ﬁnd that autonomous vehicles are 15 – 4000× worse than human
drivers for accidents per cumulative mile driven; that drivers of
AVs need to be as alert as drivers of non-AVs; and that the AVs’
machine-learning-based systems for perception and decision-and-
control are the primary cause of 64% of all disengagements.
Index Terms—Autonomous Vehicles, Reliability, Fault Charac-
terization, Disengagement, Accident.
I. INTRODUCTION
Autonomous vehicle (AV) technologies are advertised to be
transformative, with a potential to improve trafﬁc congestion,
safety, productivity, and comfort [1]. Several states in the U.S.
(e.g., California, Texas, Nevada, Pennsylvania, and Florida)
have already started testing AVs on public roads. Prior
research into AVs has focused predominantly on the design of
automation technology [2]–[7], its adoption [8], the impact of
AVs on congestion [9], and the legal [10], [11] and regulatory
barriers [12]–[15] for AV implementation. With the increasing
popularity and ubiquitous deployment of semi- and fully-
automated vehicles on public roads, safety and reliability have
increasingly become critical requirements for public acceptance
and adoption. This paper assesses, in broad terms, the reliability
of AVs by evaluating the cause, dynamics, and impact of
failures across a wide range of AV manufacturers utilizing
publicly available ﬁeld data from tests on California public
roads, including urban streets, freeways, and highways.
Dataset. The California Department of Motor Vehicles (CA
DMV) mandates that all manufacturers testing AVs on public
roads ﬁle annual reports detailing disengagements (a failure that
causes the control of the vehicle to switch from the software
to the human driver) and accidents (an actual collision with
other vehicles, pedestrians, or property) [16]. The focus of
the testing program, and of this paper, is on semi-autonomous
vehicles that require a human driver to serve as a fall-back
in the case of failure. In particular, we are interested in
studying failures that pertain to sensing (e.g., cameras, LIDAR)
and computing systems (e.g., hardware and software systems
that enable environment perception and vehicle control) that
enable the “self-driving” features of the vehicles. We analyze
ﬁeld data collected over a 26-month period from September
2014 to November 2016 (part of the DMV’s 2016 and 2017
data releases), containing data from 12 AV manufacturers for
144 vehicles that drove a cumulative 1, 116, 605 autonomous
miles. Across all manufacturers, we observe a total of 5, 328
disengagements, 42 of which led to accidents.
Results. This paper presents 1) an end-to-end workﬂow
for analyzing AV failure data, and 2) several insights about
failure modes in AVs (across a single manufacturer’s ﬂeet,
across different manufacturers, and in time) by executing the
proposed workﬂow on the available data. Our study shows:
1) Drivers of AVs need to be as alert as drivers of non-AV
vehicles. Further, the small size of the overall action window
(detection time + reaction time) would make reaction-time-
based accidents a frequent failure mode with the widespread
deployment of AVs.
2) For the same number of miles driven, for the manufacturers
that reported accidents, human-driven non-AVs were 15 −
4000× less likely than AV’s to have an accident.
3) 64% of disengagements were the result of problems in, or
untimely decisions made by, the machine learning system.
4) In terms of reliability per mission, AVs are 4.22× worse
than airplanes, and 2.5× better than surgical robots.
These ﬁndings demonstrate that while individual components
of AV technology (e.g., vision systems, control systems) may
have matured, entire AV systems are still in a “burn-in” phase.
The analysis presented in this paper shows a distinct
improvement in the performance of AVs over time. However,
it also demonstrates the need for continued improvement in the
dependability of this technology. It is conceivable (moreover,
expected) that AV manufacturers are performing a similar
analysis of data coming from their testing ﬂeets, but to the
best of our knowledge, information on such analysis is not
available publicly. Our goal is to support resilience research
by characterizing failures of autonomous vehicles, rather than
to further the operational perspective of the manufacturer. Our
results can better inform the design of future AVs.
Organization. Fig. 1 shows the end-to-end pipeline for
processing failure data from autonomous vehicles. Section II
describes two real examples of AV-related accidents on Califor-
nia roads. Section III describes the AVs and the data collection
methodology (Stage I of the pipeline). Section IV describes
the preprocessing, ﬁltering, and natural language processing
(NLP) steps required to convert the data to a format suitable for
analysis (Stages II & III of the pipeline). Section V describes
the statistical analysis of the failure data and summarizes the
insights derived from the analysis (Stage IV of the pipeline).
Finally, Sections VI to VIII describe the threats to validity,
related work and conclusions, respectively.
2158-3927/18/$31.00 Â©2018 IEEE
DOI 10.1109/DSN.2018.00066
586
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:23:35 UTC from IEEE Xplore.  Restrictions apply. 
Stage I: Data Collection
Disengagement 
database
1,116,605 autonomous 
miles driven
5,328 disengagements
1
42 accidents
2
Accident database
Accident 
Reports
Each accident is 
reported separately
OCR 
Parse + 
Filter 
Data from 2016 
and 2017 reports
Disengagement 
Reports
Stage II: Parsing and Filtering
OCR 
Parse + 
Filter 
Normalize 
NLP
Failure 
Dictionary
4
Stage IV: Statistical 
Analysis of Failures
3
NLP
Stage III: Natural 
Language Processing
Consolidated 
failure data
Further 
statistical 
analysis 
(presented in 
Section IV)
Figure 1. The end-to-end data collection, processing, and analysis pipeline that forms the basis of this study.
II. CASE STUDIES
In this section, we present two representative case studies
based on real events that occurred in the streets of Mountain
View, CA. These case studies illustrate how problems in the
perception, learning, and control systems of an AV can manifest
as an accident.
A. Case Study I: Real-Time Decisions
Example 1 in Fig. 2 shows a case in which the human driver
of the AV proactively took over the control of the vehicle from
the autonomous agent (to prevent an accident) but was unable to
rectify decisions made by the autonomous agent in time to pre-
vent an accident. The disengagement report (i.e., error logs from
the AV combined with post-mortem analysis performed by the
manufacturer) logs the error as either “Disengage for a
recklessly behaving road user” or “incorrect
behavior prediction.” Speciﬁcally, a Waymo prototype
vehicle was in autonomous mode at a street intersection when a
pedestrian started to cross the street. From the accident report,
we ﬁnd that the AV decided to yield to the pedestrian but did
not stop. The test driver proactively took control of the car
as a precaution. At the same time, there was a car in front of
the AV that was also yielding to the pedestrian, and another
vehicle to the rear in the adjacent lane that was making a lane
change. In this complex scenario, the driver did not have many
options other than to brake, and the rear vehicle collided with
the back of the AV.
B. Case Study II: Anticipating AV Behavior
Example 2
in Fig. 2 shows a case in which a Waymo
prototype vehicle was running in autonomous mode and was
El Camino 
Real
2
1 mph
4 mph
C
l
a
r
k
A
v
1
5
m
p
h
10 mph
South Shoreline Blvd
W
a
y
H
i
g
h
s
c
h
o
o
l
Before Collision:
During Collision:
Autonomous Vehicle
Manual Vehicle
Collision
Autonomous Vehicle
Manual Vehicle
Figure 2. Accident scenarios.
587
hit by a manual vehicle from the rear at a street intersection. The
disengagement report logs the cause as “Disengage for a
recklessly behaving road user.” In this case, the
AV had signaled a right turn and had started to decelerate for
the turn. It came to a complete stop before it started moving
again towards the intersection to gauge the trafﬁc coming from
the other side in order to make a safe turn. The movement
towards the intersection was required to allow the recognition
system to analyze the scene and produce a movement plan
for the car. The driver of the rear vehicle was confused and
interpreted this movement to mean that the AV was conitinuing
on its path (i.e., making the turn). The driver ﬁrst stopped (as
the AV stopped) and then started moving (as the AV started
to move again). This resulted in a rear collision on the AV, as
the driver could not anticipate the actions of the AV.
C. Summary
By law, both of those accidents were caused by the drivers in
the non-AV; however, close inspection of the accident reports
shows that the AV had a signiﬁcant share of the responsibility.
The above examples showcase the poor AV decision-making
that eventually leads to accidents.
1) The street intersections represent complex scenarios in
which the AV needs to analyze multiple trafﬁc ﬂows and
make decisions in a constrained environment. Based on
our analysis we attribute the failures to the learning-based
perception system, which did not infer in time the evolving
environment dynamics from the onboard sensor systems
(e.g., RADAR, LIDAR), leading the learning-based control
system to make inadequate decisions.
2) In both cases, drivers either voluntarily took or were forced
to take control from the autonomous system in complex and
dynamic trafﬁc scenarios that frequently gives them very
little time to react and undo the AV’s actions. The perception
and reaction time is crucial in accident avoidance.
3) Drivers in other non-AVs often cannot anticipate decisions
made by AVs, which frequently also leads to accidents.
Using the limited publicly available information about the
design of the AV systems (e.g.,
[17]–[20]), we draw our
conclusions by analyzing human-entered textual logs that
contain information about accidents and disengagements. Our
method localizes failures to the learning, perception, and
decision-and-control subsystems of an AV to understand the
causes of disengagements and accidents.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:23:35 UTC from IEEE Xplore.  Restrictions apply. 
III. AV SYSTEM DESCRIPTION AND DATA COLLECTION
A. Preliminaries
1) Autonomous Vehicles
An AV is any vehicle that uses an autonomous driving system
(ADS) technology capable of supporting and assisting a human
driver in the tasks of 1) controlling1 the main functions of
steering and acceleration, and 2) monitoring the surrounding
environment (e.g., other vehicles/pedestrians, trafﬁc signals,
and road markings) [21].
The Society of Automotive Engineers (SAE) deﬁnes six
levels of autonomy that are based on the extent to which the
technology is capable of supporting and assisting the driving
tasks [21]. The levels of autonomy go from 0 (no automation)
to 5 (full, unrestricted automation). Levels 0–2 (e.g., anti-lock
braking, cruise control) require a human driver to be responsible
for monitoring the environment of the vehicle, with different
levels of automation available to support vehicle control tasks.
Levels 3–5 are thought of as truly automated driving systems
where the AV both monitors the environment and controls the
vehicle. The subject of this paper is the Level 3 vehicles.
2) Disengagements
Level 3 requires the presence (and attention) of a human
driver to serve as a fall-back when the autonomous system
fails. A transfer of control from the autonomous system to the
human driver in the case of a failure is called a disengagement.
Disengagements can be initiated either manually by the driver
or autonomously by the car. Manual disengagements initiated
by the driver are cautionary (e.g., if one feels uncomfortable,
or wants to adopt a proactive approach to prevent a potential
accident). Automated disengagements are indicative of a design
limitation of the AV.
3) Accidents
An accident
is an actual collision with other vehicles,
pedestrians, or property. Note that not all disengagements
lead to collisions. As we show later in this paper, most
disengagements are handled safely by the human operators,
with only a small fraction leading to accidents. For example,
in some reported collisions, the test driver initiated a manual
disengagement before the collision (an artifact of the training
program that all test drivers acting as AV safety-pilots have to
undergo before they are allowed on public roads [16]).
B. AV Hierarchical Control Structure
Manufacturers have not disclosed the architectures of their
autonomous vehicles. However, to identify multidimensional
causes of AV disengagements/accidents, we built a hierarchical
control structure for AVs by using the systems-theoretic hazard
modeling and analysis abstraction STPA (Systems-Theoretic
Process Analysis) [23]. Fig. 3 shows an AV hierarchical control
structure derived based on technical documentation [22], [24]–
[27]. We assert that these information sources are representative
and provide a conceptual view of AV systems that is sufﬁciently
detailed to enable creation of an STPA model. We refer to
this system as the “Autonomous Driving System” (ADS).
The major components of the ADS are 1) “sensors” (e.g.,
GPS, RADAR, LIDAR, and cameras) that are responsible for
1Here, “control” incorporates both decision and control.
Human Drivers
Insufﬁcient Time to
React to Disengagement
Driver
D
Unexpected Driver Action,
n,