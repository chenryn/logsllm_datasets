In  the  first phase, the sensor data is protected as soon 
as  it  is  read  by  an  Input  Protect  module  that  adds  a 
signature (a simple checksum in our case) to it. The same 
is  true  for  the  desired  set-point  data,  in  the  case  it  is 
produced  outside  the  controller.  Then,  an  Input  Assert 
module  tests  all  the  data that  will  be  used  in  the  control 
algorithm,  namely  the  inputs,  state  variables  and  the 
constant parameters of the control algorithm.  The tests are 
performed twice.  The assertions  performed  over the input 
values  consist  on  reasonableness  tests,  based  on  the 
expected process behavior.  The constants are checked by 
means  of  the  signature  calculated  during  the  system 
set-up phase.  The state variables  are also tested  by  means 
of  their  signature, produced  at the Output Protect module 
in  the  previous  iteration.  The “magic  number” produced 
in  the  previous  iteration  is  also  tested,  and  different 
numbers  are  added  to  the  current  “magic number”  after 
the successful execution of each set of tests. 
In  the  Output  Protect  module,  the  values  for  the 
control  action  and  the  new  state  variables that  have just 
been calculated  are protected  again by a signature. 
The  Output  Assert  module  verifies  the  values  calcu- 
lated by the controller, i.e., the new state variables and the 
control action, by  means of reasonableness tests, limiting 
possible erroneous values to  an upper  bound. Finally, the 
values  used  as input  for  the  control  code are tested  once 
more for corruption detection. 
All  the  tests  executed  by  the  Input and  Output Assert 
modules  are  executed  twice  and,  after  each  successful 
execution,  the  “magic  number”  is  updated.  The  outputs 
from the  Controller consist  on  the  control  actions  to  the 
Process  actuators, along  with  the  signature that  authenti- 
cates the data, and the “magic number”. 
The Output Test module  is  a small module  (may be a 
trivial  piece  of  hardware)  that  is  close  to  the  controlled 
process.  It  is  responsible  for  testing  the  validity  of  the 
“magic  number”  and  signature  associated  with 
the 
controller  outputs.  If  any  test  fails,  those  outputs  don’t 
reach the  Process actuators.  The key  requirement  for this 
Output Test module  is that  it should be fault-independent 
from  the  controlling  computer  - a  fault  in  the  latter 
should  not  affect  the  Output  Test  module.  This external 
module  could  even  use  replication  due  to  its  extreme 
simplicity (a few gates). 
3.  Experimental setup 
We  followed  an  experimental  validation  methodology 
fault-injection  of  a  comprehensive  set  of 
through 
hardware transients  in  the  controller’s  CPU and  memory. 
3 16 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply. 
We  have  adapted  the  controller  of  the  COTS  “PS600 
[ 131 
Laboratory  Experiment 
Inverted  Pendulum” 
manufactured  by  a  German  firm  (Amira  Cmbh) 
(sec 
Figure 2)  to  meet  our  needs,  and  used  it  to  control  the 
physical process. No simulations were used. 
Figure 2 - Inverted Pendulum (picture taken 
from Amira web site - http://www.amira.de) 
3.1.  The physical process 
The  Inverted  Pendulum  Controller  is  one  of  the 
best-known  and  most  demanding control  benchmarks.  Its 
goal is  to  keep the  inverted pendulum’s weight balanced, 
while  the  cart  follows  a  reference  path,  preventing  the 
pendulum  from  falling  down,  even  in  the  presence  of 
small external disturbances. Our study was  not  concerned 
with  the  control  algorithm  itself,  since  that  is  a  con- 
trol-enginecring  problem. We  have  simply  used  one  that 
was available. 
The structure  of Inverted  Pendulum  setup can be  seen 
in  Figure 3. It is composed by  a cart (6) that moves along 
a  metal  guiding  bar  (5).  An  aluminum  rod  (9)  with  a 
cylindrical  weight  (7) is fixed to  the cart by  an axis. The 
cart  is  connected  by  a  transmission  belt  (4)  to  a  drive 
wheel  (3). 
% 
Figure 3 - The Inverted Pendulum Process 
3 
Control engineers consider this  a hard process  because 
317 
it  always operates  on  its stability  limit. This process  has 
thus  stringent  time  constraints,  and  is  one  of  the  most 
difficult  standard  processes  to  control. It  has  typically  a 
control  loop period  of  30 msec.  and  a latency of  control 
information,  i.e.,  the  time  interval  between  the  sampling 
moment and the actuation moment, of less than  10 msec. 
The  control  computers  are  standard  90MHz  Intel 
Pentium based PC’s with  8M of RAM. They use no disks, 
because  the  real-time  constraints of  the  application  make 
them useless. 
The process has an ISA interface card that connects the 
PC to the process control box, which  is responsible for all 
the  digital/analog  conversion  and  other  necessary 
operations.  This  control  box  collects  periodically  the 
information from the pendulum sensors (cart position  and 
pendulum  rod  angle),  and  puts  these  values  at  the  ISA 
card  I/O  ports.  This  card  then  generates  an  interrupt  so 
that  the  software  collects  this  data  from  the  1/0 ports, 
calculates  the  control  action  (consisting  on  the  force  to 
actuate  at  the  drive  wheel)  and  writes  it  back  in  the  I/O 
ports of the same card. 
3.2.  The control application 
The  control  application  is  running  on  top  of  SMX’ 
(Simple  Multitasking Executive)  [ 141, a  COTS  real-time 
kernel  from  Micro  Digital  Inc,  USA,  working  in  16-bit 
protected mode. 
We  have  isolated  the  Controller  under  fault  injection 
from  the  Process.  Another  computer,  that  we  call  the 
Process Interface,  contains the process interface ISA card 
and  communicates with  the control computer by means of 
a  serial  connection.  The  Process  Interface  computer 
controls  the  pendulum  whenever  the  main  controller  is 
unavailable.  We  have  made  this  decision  because,  when 
we are executing the  fault-injection experiments, we must 
reset  the  target computer after the  injection of each  fault, 
so  that  some  error  does  not  stay  latent  and  affect  the 
following  injection  run,  and  this  frequent  reset  could 
damage  the  process  setup.  Additionally,  since  we  use 
standard  PCs,  the  power-on  sequence  is  quite  long 
(around  20  seconds  in  our  system),  during  which  the 
pendulum  setup  would  not  be  controlled  (the  same 
happens when  the  main  Controller crashes because  of an 
injected  fault)  and  could be damaged.  Since the  Inverted 
Pendulum  does not  stay  in  the  upright  position  when  the 
controller  stays  silent  for  more  than  100  msec,  the 
pendulum  would  certainly  fall  down.  Before  the  next 
experiment could begin it would be  necessary to raise the 
pendulum,  a  task  the  controller  is  not  always  able  of 
performing  alone,  needing  occasional  human  interven- 
long 
tion,  which  would  make 
sequences  of  unattended  fault-injections.  Note  that  it  is 
easy  to  decide  when  the  Process  Interface  should  take 
over - a  simple  timeout  is  used,  that  detects  when  the 
it  difficult 
to  have 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply. 
control  outputs  are  not  produced  at  the  specified  I O  ms 
latency of control  information. 
In  order  to  prevent  the  pendulum  from  falling  down 
when  the  controller  is  clearly  misbehaving,  we  also 
defined  a "crash" rod  angle (20 degree deviation  from the 
vertical  position)  and  a  "crash"  cart  position  (15  cm 
deviation  from  the  desired  position).  If  those  limits  are 
crossed  by  the  cart  or  pendulum,  the  Process  Interface 
controller  takes  over,  the  experiment  is  classified  as  a 
crash, and  hopefully the  Process Controller still manages 
to  prevent  the  pendulum  from  falling,  which  it  does  in 
most cases. 
To  minimize 
the  modifications  on  the  Controller 
software due to.the fact that  it is not directly connected to 
the  pendulum  setup, we  have just  changed  the  addresses 
where the reads and writes are done - instead of being in 
the  ISA card  I/O  ports,  they  are done  at  the  registers  of 
the  serial  interface  controllers.  The  data  format  is  the 
same.  The Process Interface computer just  has to  bypass 
the  information  from  the  serial  ports  to  the  process  card 
ports and vice-versa. 
In  order to evaluate the  three  failure  models, we  have 
built  only two different versions  of  the  control  system.  In 
the  first  version,  the  main  Controller  has  no  special 
fault-tolerance  built-in.  A  copy  of  the  control  software 
runs  in  the  Process  Interface  computer.  This  computer 
implements also a voter, comparing the outputs it receives 
from  the  main  controller  with  the  outcome  of  its  own 
calculations.  Since  no  fault-injection  is  executed  in  this 
Process Interface, we  may  have confidence on its results. 
This  setup  was  used  to  test  the  Fail-Silent  model,  by 
voting  the  outputs  produced  by  both  versions  of  the 
control  software  and 
thus  detecting  any  fail-silence 
violation.  The  Fail-Arbitrary  model  was  also  tested  with 
this  version  of  the  control  system,  since  the  Controller 
computer that is subjected  to fault-injection  has no special 
fault-tolerance  built-in.  This  is  done  because,  when  the 
voter  detects  some difference, we  just  log  that  event - 
the outputs of the main Controller are still delivered to the 
to  see 
Inverted  Pendulum  system,  enabling  us 
the 
behavior of the system under the Fail-Arbitrary  model. 
The  second  version  of  our  system  has  a  Controller 
implemented  with  robust  assertions  and  an  Output  Test 
module 
the  Process  Interface  computer.  This 
version was used to test the Fail-Bounded model. 
inside 
3.3.  The fault model 
The  disturbances  internal  to  the  Controller  are  pro- 
duced using RT-Xception [4], the real-time  version  of the 
[ 2 ] .  This  version  adds  to  the  original 
Xception  tool 
Xception  the  benefit  of  not  having  almost  any  "probe 
effect",  i.e.  it  induces  a  negligible  time  overhead on  the 
target application. 
The  faults  injected  in  both  versions  of  the  software 
were  transient  bit  flips,  affecting  only  one  machine 
instruction  and  one  processor  functional  unit  at  a  time 
(Registers, Integer  ALU,  Floating-point ALU,  Data  bus, 
Address  Bus,  and  Memory  Management  Unit).  Faults 
were  also  injected  in  main  mcmory.  The  number  of  bits 
affectcd  depended  on  the  size of  the  injected  data - we 
choose  to  affect  25%  of  the  bits.  For  a  byte,  this  means 
changing  two  bits;  for  an  SO-bit  extended  precision 
number 20 bits  were affected. Most of  the  injected  faults 
wcre time triggered  so that they  occurred randomly  at any 
point  during  the  exccution  of  the  program.  In  order  to 
speed-up  the  experiments, the  probability  to  inject  faults 
while  running  the  idle  task  has  been  reduced  by  using  a 
spatial  trigger  located  at  the  beginning  of  the  iteration 
to  start  the  time  trigger  after  a  random 
programmed 
number  of  times.  Then,  the 
trigger  starts  the 
fault-injection  after  a  random  time,  set  to  fall  inside  the 
execution of the controller code. 
time 
We  have  also  injected  faults  directed  to  specific data 
structures.  In  these  cases,  we  have  instructed  the  fault 
injector to  trigger  when  the  targeted  variables were being 
updatcd,  and  to  corrupt  the  data  bus  during  the  corre- 
sponding memory store. 
4.  Experimental results and discussion 
In  this  section,  we  shall  analyze  the  behavior  of  the 
pendulum  controller under  a series of  faults to understand 
what  kind  of  failure  model  is  more  cost-effective for the 
described class of systems. 
4.1.  Fail-Arbitrary and Fail-Silent models 
As  already  explained,  these  two  failure  models  were 
tested  using  thc same setup ofthe system and  fault set. To 
do so. the voter was instructed  to log any disagreement on 
the  results  from  the  two  versions  of  the  controller,  and 
always  output  the  result  from  the  Controller  into  the 
process  I/O  ports.  This  voter  is  also  useful  to  check  (for 
testing purposes only) if  the output  from the Controller in 
the Fail-Arbitrary  model  was correct. 
4.1.1.  Injection of random transient faults 
The results  obtained  after  the  injection  of  a  series  of 
999  random  faults,  targeting 
the  different  processor 
functional  units  and  uniformly  distributed  along  the 
controller execution time, are summarized in Table 1. 
Since  the  Fail-Silent  version  (FS) is  based  on  repli- 
cated  controllers  of  the  Fail-Arbitrary  version  (FA), the 
figures for c r u h  and  correct outpiif  are the  same in  both 
versions.  If the system crashes, no approach can output its 
results.  Thus, the  systems became  silent  for  about half  of 
all  fault  injection  runs, a number that  also includes faults 
that lead  to unrecoverable errors detected by the processor 
or  the  kernel  (e.g.  memory  protection  violations),  which 
318 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply. 
Controller behavior 
Detected error 
Crash 
Correct output 
Fail-Arbitrary 
(FA) 
Fail-Silent 
IFS) 
47.5% 
50.8% 
475 
507 
1.7% 
47.5% 
50.8% 
17 
475 
507 
1.7% 
Undet. wrong output 
0 
Table  1.  Behavior of  the  Fail-Arbitrary and 
Fail-Silent  controllers  under  uniformly 
distributed faults (% and no. of cases) 
0% 
17 
A  large  number  of  faults  (50.8%) do not  produce any 
observable error. While this figure may seem surprising at 
first, it is consistent  with  other fault injection  experiments 
we  have  been  performing  along  the  years  with  very 
different  processors  (280, 68000, T800,  PowerPC,  etc) 
and  with  different  fault  injection  techniques  (pin-level, 
SWIFI, etc). A more detailed observation reveals why this 
is  so:  there  is  an  intrinsic  redundancy  in  every  system. 