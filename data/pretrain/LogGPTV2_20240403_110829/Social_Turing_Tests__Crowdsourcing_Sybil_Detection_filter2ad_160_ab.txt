Facebook
IN
32
50
50
50
Test Group
CN Expert
CN Turker
US Expert
US Turker
US Social
IN Expert
IN Turker
# of
Proﬁles
Testers per Tester
24
418
40
299
198
20
342
100
10
50
12
25
100
12
Table 1. Datasets, test groups, and proﬁles
per tester.
Dataset
Category
Renren
Facebook
US
Facebook
IN
Legit.
Sybil
Legit.
Sybil
Legit.
Sybil
News-
Feed
165
30
55.62
60.15
55
31.6
Photos
302
22
184.78
10.22
53.37
10.28
Proﬁle
Images
Censored
Images
10
1.5
32.86
4.03
7.27
4.44
0
0.06
0
1.81
0
0.08
Table 2. Ground-truth data statistics (average
number per proﬁle).
legitimate proﬁles on Renren directly from Renren Inc. The
security team at Renren gave us complete information on
1082 banned Sybil proﬁles, from which we randomly se-
lected 100 for our user study. Details on how Renren bans
Sybil accounts can be found in [31]. We collected legitimate
Renren proﬁles using the same methodology as for Face-
book. We seeded a crawler with 4 trustworthy proﬁles from
people in the lab, crawled 100K friends-of-friends, and then
sampled 100 public proﬁles. We forwarded these proﬁles to
Renren’s security team and they veriﬁed that the proﬁles
belonged to real users.
Summary and Data Sanitization.
Table 1 lists the ﬁnal
statistics for our three datasets. Since the Renren data was
provided directly by Renren Inc., all proﬁles are conﬁrmed
as either Sybils or legitimate users. For Facebook US and
India, proﬁles that were banned by Facebook are conﬁrmed
Sybils, and the remaining unconﬁrmed suspicious proﬁles
are not listed.
During our manual inspection of proﬁles, we noticed that
some include images of pornography or graphic violence.
We determined that it was not appropriate for us to use
these images as part of our user study. Thus, we manually
replaced objectionable images with a grey image contain-
ing the words “Pornographic or violent image removed.”
This change protects our test subjects from viewing objec-
tionable images, while still allowing them to get a sense of
the original content that was included in the proﬁle. Out
of 45,096 total images in our dataset, 58 are ﬁltered from
Facebook US, 4 from Facebook India, and 6 from Renren.
All objectionable images are found on Sybil proﬁles; none
are found on legitimate proﬁles.
Finally, we show the basic statistics of ground-truth pro-
ﬁles in Table 2. Legitimate users have more photo albums
and proﬁle photos, while Sybils have more censored pho-
tos. The “News-Feed” column shows the average number of
items in the ﬁrst 5 chronological pages of each user’s news-
feed. On Facebook, the news-feed includes many types of
items, including wall posts, status updates, photo tags, etc.
On Renren, the feed only includes wall posts from friends.
3.2 Experiment Design
Using the datasets in Table 1, our goal is to assess the
ability of humans to discriminate between Sybil and legiti-
mate user proﬁles. To test this, we perform a simple, con-
trolled study: we show a human test subject (or simply a
tester) a proﬁle from our dataset, and ask them to classify
it as real or fake. The tester is allowed to view the proﬁle’s
basic information, wall, photo albums, and individual pho-
tos before making their judgment. If the tester classiﬁes the
proﬁle as fake, they are asked what proﬁle elements (basic
information, wall, or photos) led them to this determination.
Each tester in our study is asked to evaluate several pro-
ﬁles from our dataset, one at a time. Each tester is given
roughly equal number of Sybil proﬁles and legitimate pro-
ﬁles. The proﬁles from each group are randomized for each
tester, and the order the proﬁles are shown in is also ran-
domized.
Implementation. We implement our study as a website.
When a tester begins the study, they are presented with a
webpage that includes a consent form and details about our
study. After the tester agrees, they are directed to the ﬁrst
proﬁle for them to evaluate. Figure 2 shows a screenshot of
our evaluation page. At the top are links to the all of the
proﬁles the tester will evaluate. Testers may use these links
to go back and change their earlier answers if they wish.
Below the numbered links is a box where testers can
record their evaluation for the given proﬁle: real or fake,
and if fake, what proﬁle elements are suspicious (proﬁle,
wall, and/or photos)? When the tester is done evaluating the
given proﬁle, they click the “Save Changes” button, which
automatically directs their browser to the next proﬁle, or the
end of the survey if all proﬁles have been evaluated.
Below the evaluation box are three buttons that allow the
tester to view the given proﬁle’s basic information (shown
by default), wall, and photo albums. The basic information
and wall are presented as JPEG images, in order to preserve
the exact look of Facebook/Renren, while also preventing
the tester from clicking any (potentially malicious) embed-
ded links. Testers may click on each photo album to view
the individual photos contained within.
and each proﬁle was evaluated by multiple testers from each
group. This allows us to examine the overall detection ac-
curacy of the group (e.g. the crowd), versus the accuracy
of each individual tester. We now introduce the three test
groups, and explain how we administered our study to them.
Experts.
The ﬁrst group of test subjects are experts.
This group contains Computer Science professors and grad-
uate students that were carefully selected by us. The expert
group represents the practical upper-bound on achievable
Sybil detection accuracy.
The expert group is subdivided into three regional
groups: US, Indian, and Chinese experts. Each expert group
was evaluated on the corresponding regional dataset. We
approached experts in person, via email, or via social me-
dia and directed them to our study website to take the test.
Table 1 lists the number of expert testers in each regional
group. Expert tests were conducted in February, 2012.
As shown in Table 1, each Chinese and Indian expert
evaluated 100 proﬁles from our dataset, while US experts
evaluated 50 proﬁles. This is signiﬁcantly more proﬁles per
tester than we gave to any other test group. However, since
experts are dedicated professionals, we assume that their ac-
curacy will not be impacted by survey fatigue. We evaluate
this assumption in Section 5.
Turkers.
The second group of test subjects are turkers
recruited from crowdsourcing websites. Unlike the expert
group, the background and education level of turkers cannot
be experimentally controlled. Thus, the detection accuracy
of the turker group provides a lower-bound on the efﬁcacy
of a crowdsourced Sybil detection system.
Like the expert group, the turker group is subdivided into
three regional groups. US and Indian turkers were recruited
from MTurk. HITs on MTurk may have qualiﬁcations as-
sociated with them. We used this feature to ensure that only
US based turkers took the Facebook US test, and Indian
turkers took the Facebook India test. We also required that
turkers have ≥90% approval rate for their HITs, to ﬁlter
out unreliable workers. We recruited Chinese turkers from
Zhubajie, the largest crowdsourcing site in China. Table 1
lists the number of turkers who completed our study in each
region. Turker tests were conducted in February, 2012.
Unlike the expert groups, turkers have an incentive to
sacriﬁce accuracy in favor of ﬁnishing tasks quickly. Be-
cause turkers work for pay, the faster they complete HITs,
the more HITs they can do. Thus, of all our test groups, we
gave turkers the fewest number of proﬁles to evaluate, since
turkers are most likely to be effected by survey fatigue. As
shown in Table 1, Chinese turkers each evaluated 10 pro-
ﬁles, while US and Indian turkers evaluated 12.
We priced each Zhubajie HIT at $0.15 ($0.015 per pro-
ﬁle), and each MTurk HIT at $0.10 ($0.0083 per proﬁle).
These prices are in line with the prevailing rates on crowd-
Figure 2. Screenshot of the English version
of our user study website.
At the end of the survey, the tester is asked to answer a
short questionnaire of demographic information. Questions
include age, gender, country of residence, education level,
and years of OSN experience. There is also a free-form
comment box where tester can leave feedback.
On the server-side, we record all of the classiﬁcations
and questionnaire answers made by each tester. We also
collect additional information such as the time spent by the
tester on each page, and total session time per tester.
Because our datasets are in two different languages, we
construct two versions of our study website. Figure 2 shows
the English version of our site, which is used to evaluate
Facebook proﬁles. We also constructed a Chinese version
of our site to evaluate Renren proﬁles.
Limitations.
The methodology of our user study has
two minor limitations. First, we give testers full proﬁles to
evaluate, including basic info, wall, and photos. It is not
clear how accurate testers would be if given different infor-
mation, or a restricted subset of this information. Second,
we assume that there are no malicious testers participating
in our user study. Although attackers might want to inﬁl-
trate and disrupt a real crowdsourced Sybil detector, there
is little for them to gain by disrupting our study. Related
work on detecting crowdsourcing abuse may be helpful in
mitigating this problem in the future [7].
3.3 Test Subjects
In order to thoroughly investigate how accurate different
types of users are at detecting Sybils, we ran user studies
on three different groups of test subjects. Each individual
tester was asked to evaluate ≥10 proﬁles from our dataset,
CN
IN
US
s
r
e
t
s
e
T
f
o
%
 100
 80
 60
 40
 20
 0
Graduate
Bachelors
High
Primary
s
r
e
t
s
e
T
f
o
%
 100
 80
 60
 40
 20
 0
CN
IN
US
5-10 Years
2-5 Years
0-2 Years
Never
s
r
e
t
s
e
T
f
o
%
 100
 80
 60
 40
 20
 0
CN
IN
US
Female
Male
E
T
E
T
E
T
S
E
T
E
T
E
T
S
E
T
E
T
E
T
S
x
u
x
u
x
u
o
p
e
r
k
p
e
r
k
p
e
rt
e
r
rt
e
r
rt
r
k
ci
r
a
l
e
x
u
x
u
x
u
o
p
e
r
k
p
r
k
p
r
k
e
e
rt
e
r
rt
e
r
rt
ci
r
a
l
e
x
u
x
u
x
u
o