First CE Matters: On the Importance of Long Term
Properties on Memory Failure Prediction
Jasmin Bogatinovski, Odej Kao Qiao Yu, Jorge Cardoso
Technical University Berlin, Berlin, Germany Huawei Munich Research, Munich, Germany
{jasmin.bogatinovski, odej.kao}@tu-berlin.de University of Coimbra, CISUC, DEI, Coimbra, Portugal
PI:EMAIL
Abstract—Dynamic random access memory failures are a reliable DIMM behaviour. To reduce the effect of the DIMM
threat to the reliability of data centres as they lead to data failures alternative strategies are needed. 2202
loss and system crashes. Timely predictions of memory failures
ApossiblestrategytoamortizetheeffectofDIMMfailures
allow for taking preventive measures such as server migration
istopredictwhenthememorywillfail.Byasufficientlylarge
and memory replacement. Thereby, memory failure prediction
prevents failures from externalizing, and it is a vital task to predictioninterval,thecorrectpredictionenablesthetriggering
improvesystemreliability.Inthispaper,werevisitedtheproblem of preventive measures (e.g., server migration). Therefore, the voN
ofmemoryfailureprediction.Weanalyzedthecorrectableerrors failure will not be externalised. This makes memory failure
(CEs) from hardware logs as indicators for a degraded memory
prediction an important task for system reliability. The key
state. As memories do not always work with full occupancy,
requirement for memory prediction is the availability of data 12
access to faulty memory parts is time distributed. Following this
intuition, we observed that important properties for memory that encapsulates the properties of a degraded DIMM. Two
failure prediction are distributed through long time intervals. In common data sources are used, i.e., 1) hardware error logs
]CD.sc[
contrast, related studies, to fit practical constraints, frequently and 2) system-level metrics [4]. Hardware error logs record
only analyze the CEs from the last fixed-size time interval
thecorrectableerrorsgeneratedfromtheDIMM’sECCchips.
while ignoring the predating information. Motivated by the ob-
These errors are referred to as correctable errors. Different
served discrepancy, we study the impact of including the overall
(long-range) CE evolution and propose novel features that are studies show that the accumulated repetition of CE on nearby
calculated incrementally to preserve long-range properties. By memory locations is correlated with memory failures [4],
coupling the extracted features with machine learning methods, [5]. Therefore, DIMM characterization through CEs is useful
welearnapredictivemodeltoanticipateupcomingfailuresthree 1v14401.2122:viXra
to model DIMM degradation. In contrast, memory-related
hours in advance while improving the average relative precision
system-level metrics are time series points showing the mem-
and recall for 21% and 19% accordingly. We evaluated our
methodologyonreal-worldmemoryfailuresfromtheserverfleet ory utilization (e.g., byte read/write). Although system-level
of a large cloud provider, justifying its validity and practicality. metrics are reported as useful [6], [7], the CEs are generally
Index Terms—memory failure prediction, data science, relia- recognized to better capture the memory degradation and are
bility, AIOps, log data
more frequently used for failure prediction [4].
In this paper, we revisit the problem of memory failure
I. INTRODUCTION
prediction by using CEs. Owning to practical requirements
Dynamic random access memory errors are omnipresent
(e.g., unavailable infrastructure for long-term storage of the
failure types in data centres. A memory error is an event
overall CE log history), existing approaches introduce an
which results in the wrong reading of the logical state of one
observation window with a fixed time duration as part of the
or multiple bits from how they were last written. An error
algorithmdesign.Studiestypicallyconsiderafixedwindowof,
in a single bit corrupts the stored information and affects the
e.g.,oneortwoweeks[6],[8],[9].However,astheutilization
ongoing computation, sometimes leading to system crashes.
of the servers has a stochastic component, it is often the case
The root causes of DIMM errors are diverse, ranging from
thattheserverswillbeaccessedtimeapartatdistantintervals.
hardware corruption of the memory arrays, up to bit-flips due
Furthermore, as memories on a single server do not always
to electromagnetic influence (e.g., cosmic ray strikes) [1]. As
work with full occupancy, the access of the faulty memory
a preventive strategy for DIMM reliability, the manufacturers
parts (and CE generation thereof) is time-distributed as well.
integrate different error correcting codes (ECC) onto the
Therefore, by using fixed observation windows, one may
chip for single (e.g., parity checking) [2] or multi-bit error
expect that important details from CE history may be missed.
correction(e.g.,ChipKill[3]).Whileusefulinalimitedsetof
Basedonthisintuition,weexaminetheimpactofconsidering
circumstances(e.g.,SECcorrectsasinglebit),oncetheerrors
theoverallCEsDIMMhistoryinsteadofusinganobservation
exceedtheassumptionsontheECCalgorithms(e.g.,theerror
window of fixed size. We used our observations to propose
occurs in multiple bits), the memory failure externalises and
a set of novel features that can be incrementally calculated
frequentlyresultsinasystemcrash.Therefore,relyingonerror
while preserving the long-term temporal CEs dependencies of
correction codes as a preventive strategy is insufficient for
adegradedDIMMnotneedingtostoreallthedata.Bypairing
IEEEBigData978-1-6654-8045-1/22/$31.00©2022IEEE the calculated features with machine learning methods, we
Overall CE reporting history for the DIMM Single Correctable Error Model Learning
Raw (RF, XGBoost)
Failure
Hardware Data Filtering Feature Extraction Learned Model
time t -w t t +m CE Logs Inference Predicted DIMMs
(A) Observat0 i on Window Curren0 t Time0 (B) Phase with Failures
Fig. 1: (A) The Memory Failure Prediction Problem; (B) Model learning pipeline;
learn a predictive model that can anticipate memory failures be accessed at different time intervals. Furthermore, different
three hours in advance, outperforming operational practices. address locations of the DIMMs on the same server will be
Our evaluation is performed on real-world memory failure accessed at different time intervals. If certain cells are faulty,
data collected from the server fleet of a large cloud provider, the sparsity in memory address accesses will lead to non-
justifying the validity and practicality of our approach. uniformtemporalCEsdistribution.Byusingfixedobservation
windows(t −w :t ),onemayexpecttomissdetailsrelevant
0 0
II. BACKGROUND
for predicting memory failures. We found that there exist
A. System Memory Organization propertiesoffailuresthatpropagatethroughtimethroughCEs
that often surpass the observation window (t −w :t ) (e.g.,
The memory system of a server has a hierarchical orga- 0 0
the number of unique banks that generate CEs). Thereby,
nization. A single DIMM (dual in-line memory module) is
we consider structuring the CE reporting history into two
a computer working memory type. The DIMM stores each
disjoint time intervals, i.e., 1) (−inf :t −w) (Figure 1a (A)
data bit in a separate memory cell and is used by the CPU for 0
highlighted in grey) and 2) (t −w :t ) (the white rectangle).
differentoperations(e.g.,add,write).TheDIMMisconnected 0 0
By proposing novel incrementally calculable features that
with the integrated memory controller (IMC) within the CPU
among others characterize the difference between the disjoint
via a memory channel. To increase the DIMM performance,
intervals(e.g.,thenumberofnewbanksgeneratingcorrectable
a DIMM is usually composed of multiple integrated chips
errors), we can preserve important information for upcoming
that are organized in ranks (set of connected chips). Each
failures. Motivated by our intuition, the focal point of this
chipisfurthercomposedfromarraysoftransistorsidentifiable
paper is to investigate the potential strengths of this view of
by rows and columns. The intersection between a row and
the memory failure prediction problem.
column is called cell. Each cell stores one bit. The DIMM
has also additional circuitry that enables effective memory
III. PREDICTINGMEMORYFAILURESWITHCES
operations, and potentially ECC mechanisms for CE event
generation.TheCEeventscanbereadoutfromdedicatedCPU In this section, we describe the procedure we implemented
registersetgroups(e.g.,theMachineCheckException(MCE) to learn a memory failure prediction model. It is a standard
register set for Intel x86) generating the CE logs. Opposed to machine learning pipeline composed of data preprocessing,
the properties of the software logs, like semantics [10], or feature extraction and model learning. Once the model is
sequences [11], the CE logs contain information about the learned it is used for online prediction. Figure 1b (B) shows
place in the memory where the CE occurred (e.g., specific the pipeline. The input data comes in form of CE logs. They
cell, bank, row, etc). contain information for the DIMM name the CE appeared in,
the timestamp, and the CE information (e.g., row, columns,
B. Problem Formulation banks,andsimilar).Theloginformationproceedstowardsthe
Let D is a DIMM that reported a CE log, denoted by datapreprocessingwhereCEswithincompleteloginformation
i
l(t ) at a certain point in time t , and let w and m denote are filtered. The filtered CEs proceed toward the feature
j j
an observation window length and a prediction time length extraction part. The latter implements a set of functions that
interval, accordingly. The goal of memory failure prediction characterize the degradation state of the DIMM. Once the
is to map F : φ(l ) (cid:55)→ B , where t is the current features are extracted the CE represented with the feature
(t0−w:t0) m 0
observationmomentandφ(l )isarepresentationfunc- vectorisgivenasinputforthemachinelearningmodel.Inthe
(t0−w:t0)
tion φ : L (cid:55)→ Rd that maps the set of observed correctable following, we discuss each of the three parts in more detail.
i
errors L for DIMM D from thetime period (t −w, t ) into
i i 0 0
a certain representation space Rd, where d is representation A. CEs Preprocessing and Feature Extraction
size. The set B ∈{0,1} denotes if the DIMM i will fail in The recorded CEs contain noise. For example, not all CE
m
m time units (1) or not (0). logs have information for the columns, rows or banks. Addi-
Motivation. In previous works [6], [8], [9], the observation tionally,certaintypesofcorrectableerrors,suchas”uce.read”
window w used for feature extraction is usually fixed, e.g., logs appear rarely. Therefore, the CEs preprocessing removes
twoweeks.Figure1a(A)illustratesthiswiththetimeinterval CEs of this kind (e.g., that are of type ”uce.read”, or have in-
(t −w :t ). Intuitively, as the utilization of the servers has a sufficientCEinformation).ThefilteredCEsproceededtoward
0 0
stochastic component, it is often the case that the servers will the feature extraction part.
Memory Failure Feature
Note: For Column, Row and Cell level
Taxonomy the same categories of features exist.
1. General Count 2. Bank Level 3. Column Level 4. Row Level 5. Cell Level
4.1 Row
4.2 Repeating Rows 4.3 Bank Row
Neighbourhood
1.1 Total Count 2.1 # Banks
1.2 Count Read 2.2 # New Banks 4.2.1 # Repeating
1.3 Count SCRUB 2.3 # New Banks in 4.1.1 # Errors in Row Error Rows 4.3.1 # Errors
1.4 Count UCE Last Time Interval 4.1.2 # New Rows 4.2.2 # New 4.3.2 # New