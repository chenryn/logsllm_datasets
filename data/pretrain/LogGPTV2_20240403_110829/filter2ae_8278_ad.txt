举个栗子：  
[使用LOF（Local Outlier Factor）异常检测算法检测异常访问者](https://jeary.org/post-80.html)  
[使用K-means对网站访问者进行聚类](https://jeary.org/post-81.html)  
以上只是两次浅层次的尝试，虽然还无法替代传统的方式进行安全分析，但至少我们通过非传统、无规则的方式找到的异常的IP与异常的请求，虽然准确率与召回率还有待进一步实践确认，但至少我们的思路已经打开了。
另外不知道大家是否记得在上篇文章中在没有使用ELK这样的技术体系之前，我们是对数据进行统计分析的，如果有印象的朋友可能就知道，是采用了类似计算的方式，将日志解析到Mysql以后，采用规则过一遍日志，然后将命中结果存入到Mysql现成”统计结果表“，最后采用SQL语句进行分组查询统计，然后利用Excel进行可视化。这个”统计结果表“所说的结果，便是我们这的计算结果，我们根据分析需求，从不同的维度，对数据进行计算，这个维度可以是针对一个IP、一个路径、甚至某一个Referer或Ua,如图为针对IP进行不同维度指标的统计计算结果：
整个计算过程是在日志的处理过程中实现的，根据需求，计算顺序可以进行自定义，不过通常都是在解析及增量解析完成后进行，因为增量解析完以后，信息更丰富，能进行计算的维度更丰富。
## 七、数据分析方法
### 1、经验转化
    所谓的经验转化，便是将专家对数据的理解以及分析经验、分析逻辑等进行转化，形成可工程化应用的一个过程。基于攻击特征的规则统计便是对此一个最浅显的一个应用案例。首先我们来简单讲讲什么是专家经验，我还是以上篇中撰造的日志为例：
    eg:
00:01 GET  9.9.9.9 200 [正常请求]  
00:02 GET ' 9.9.9.9 500 [疑似攻击]  
00:05 GET ' and 1=user() or ''=' 9.9.9.9 500
[确认攻击]  
00:07 GET ' and 1=(select top 1 name from
userinfo) or ''=' 9.9.9.9 500 [确认攻击]  
00:09 GET ' and 1=(select top 1 pass from
userinfo) or ''=' 9.9.9.9 500 [确认攻击]  
00:10 GET  9.9.9.9 404 [疑似攻击]  
00:12 GET  9.9.9.9 404 [疑似攻击]  
00:13 GET  9.9.9.9 404 [疑似攻击]  
00:14 GET  9.9.9.9 404 [疑似攻击]  
00:15 GET  9.9.9.9 404 [疑似攻击]  
00:15 GET  9.9.9.9 200 [疑似攻击]  
00:18 POST  9.9.9.9 200 [疑似攻击]  
00:20 GET  9.9.9.9 200 [疑似攻击]  
00:20 POST  9.9.9.9 200 [疑似攻击]  
00:23 POST  9.9.9.9 200 [确认攻击]  
00:25 POST  9.9.9.9 200 [确认攻击]  
00:26 POST  9.9.9.9 200 [确认攻击]
具有安全经验的人应该不难看出，我们的经验主要可总结为以下：  
1.Web攻击特征  
可通过请求判断是否属于攻击请求且可判断出所属何种攻击以及攻击可造成的危害或者成功后达到的目的  
2.攻击手法  
从攻击行为上进行逻辑分析，判断是否构成某种行为链
那么我们如何对此经验进行转化呢？我们先来说说Web攻击特征，可以看到通过这个经验，我们能具体得到以下信息：  
请求属性：确认攻击、疑似攻击、正常请求  
技术攻击类型：SQL注入、文件下载、敏感、XSS跨站、命令执行、XXE..  
攻击行为类型：利用SQL注入获取用户信息、利用命令执行写入webshell、利用文件下载漏洞下载配置文件..  
判定原因：命中XX正则、满足XX条件、符合XX逻辑  
风险等级：根据攻击行为类型、技术攻击类型等结果进行综合风险评定  
..
为什么我们看到Web请求的时候能得到这么丰富的信息呢，原因是因为我们丰富的安全攻防经验，我们对Web应用的深度理解，我们对开发语言的理解，对HTTP的理解，对容器的理解，对业务逻辑的理解，然而想要把这些经验完全的工程化是非常复杂的事情，想要完全做到几乎不可能，而业内传统的做法是，使用简单的规则匹配进行转化，我们在数据治理的数据增量解析过程中加入我们的”安全经验“,在日志流处理过程中，首先进行格式解析，随后便调用安全专家编写的攻击规则进行增量解析。对此的实践工程参见：
~~PS：此插件非本人所写，本人不懂Ruby也不太喜欢脚本类语言（乃是团队内懂七种语言的[Ver007](http://www.ver007.org/?p=714)所写，）~~  
那么攻击手法又该如何进行经验转化呢？我们都知道，攻击手法是一个逻辑上的东西，不像文本类的攻击特征只需要进行关键字、正则匹配即可，而攻击手法属于行为类攻击特征，简单说就是文本类通过正则进行匹配，匹配成功则认为是XXX攻击，而行为类的特征是具有逻辑性的，比如上面的例子，我们看到了大量的后台地址404了，会联想到这是一次后台爆破行为，后台地址是文本类经验，而
**大量后台地址404**
则属于行为类经验，又比如我们看到攻击者注入用户信息后开始了扫描后台，那么很有可能攻击者已经得到了管理员账户密码，但是还没有找到登录入口，这种具有逻辑性的行为，那么这样的逻辑性经验我们又该如何转换呢？开始尝试的做法是：设计简单的攻击行为链的模型，通过攻击类型、攻击行为等信息进行规则化关联。  
渗透步骤：  
攻击分类：
攻击行为分类：
攻击行为链
~~似乎看到了Attack Models、 Attack Trees、 Kill Chain的影子~~  
引用一张图来描述这个过程：(此图来源于碳基体)
通过对行为发生的逻辑顺序进行搜寻，我们找到了所有在日志中出现的符合行为逻辑的的行为链  
首先通过对渗透步骤、攻击类型、攻击行为类型等进行定义，并将攻击逻辑直接简化为攻击行为步骤，实际上mode1中的[1,2,5,6,10]对应便是攻击行为分类中的各个行为，组成起来便是”探测注入“、”利用SQL注入获取数据“、”后台扫描“、”上传文件“、”恶意webshell小马“，但是实际工程化的时候并非这么简单，会遇到诸多的问题，首先面临的便是日志分析七大难题，规则不够精细化，误报漏报问题，其次就是可信度问题，还有就是需要判定攻击成功的可能性问题，这种具有逻辑性的经验转化是我当初想要实现的Web自动化溯源流程中最为关键的环节.
**虽然实现后问题诸多，但从提出想法，到目前实现，也算是迈出了一大步。而后续，这种转化还会持续下去。  
对于经验转化，这些只是冰山一角，将领域知识应用到实际的工程化中，其实在目前的大部分安全产品中随处可见。**
### 2、统计分析
    其实”统计分析“和数据分析一样也具有一个广义的含义，学术中的统计分析包含了调查、收集、分析、预测等，涉及课程包括数学分析、解析几何、高等代数、微分方程、复变函数、实变函数与泛函分析、近世代数。这里仅指传统的统计分析，如有统计学大佬、高等数据大佬、概率论大佬或者学SPSS\SAS的大佬请轻喷。
    先说说如何来理解传统的统计分析吧，我们先来看看统计局的一个[报表](http://www.stats.gov.cn/tjsj/tjgb/rdpcgb/qgkjjftrtjgb/201810/t20181012_1627451.html)：
可以看到并非不复杂，一眼看去基本是普通公众可以理解的统计数据。嗯，这就是我们要说的统计分析。  