Hadoop Eclipse插件有很多版本，比如Hadoop官方下载包中的版本、IBM的版本等。下面将以Hadoop官方下载包中的插件为例介绍安装和使用方法。安装插件之前先要安装Hadoop和Eclipse（这部分内容略去，直接介绍插件的安装）。需要注意的是，在Hadoop1.0版本中，并没有像0.20版本那样，在HADOOP_HOME/contrib./eclipse-plugin有现成的Eclipse插件包，而是在HADOOP_HOME/src/contrib/eclipse-plugin目录下放置了Eclipse插件的源码。下面将详细介绍如何编译此源码生成适用于Hadoop1.0的Eclipse插件。
1.安装环境
操作系统：Ubuntu 11.10
软件：
Eclipse 3. 7
Java 1. 6.0_22
Hadoop 1. 0.1
2.编译步骤
1）首先需要下载ant和ivy安装包。将下载的两个安装包解压到待安装的目录下，然后将ivy包中ivy-2.2.0.jar包ant安装目录的lib目录下，然后配置/etc/profile中ant的安装目录。在文件的最末尾添加下面内容（请以自己的安装路径替换下面配置内容的路径部分）：
export ANT_HOME=/home/ubuntu/apache-ant-1.8.3
export PATH="$ANT_HOME/bin：$PATH"
2）将终端路径定位到Hadoop安装目录下，执行ant compile。这一命令需要执行的时间稍长。
3）再将终端的路径定位到HADOOP_HOME/src/contrib/eclipse-plugin。然后执行下面的命令，注意-D后紧跟Eclipse安装路径和Hadoop版本，并没有空格。
ant-Declipse.home=/home/ubuntu/eclipse-Dversion=1.0.1 jar
4）命令执行完之后，就可以在HADOOP_HOME/build/contrib/hadoop-eclipse路径下找到自己生成的Eclipse插件了。下面就可以安装配置Eclipse插件。
3.安装步骤
1）将Hadoop Eclipse plugin移动到Eclipse的插件文件夹（即Eclipse\plugins）中。重启Eclipse。
2）在Eclipse中打开Hadoop视图。依次选择：Eclipse→Window→perspective→Other，然后选择Map/Reduced并点击OK。Eclipse会出现Hadoop视图。左边Project Explorer会出现DFS Locations，下方选项卡中会出现Map/Reduce Locations选项卡。
3）在下方选项卡中选中Map/Reduce Locations，然后在出现的空白处右键点击选择New Hadoop location……，这时会弹出配置Hadoop location的窗口。按照下面的提示正确配置Hadoop。
Location Name-hadoop
Map/Reduce Master：
Host-localhost
Port-9001
DFS Master：
Host-localhost
Port-9000
User name-系统用户名
配置完成之后点击finish, Map/Reduce Locations下就会出现新配置的Map/Reduce location。Eclipse界面左边的DFS location下面也出现新配置的DFS，点击“+”可以查看其结构。
到此，Hadoop Eclipse插件已经安装完成，可以辅助大家开发MapReduce程序和管理HDFS集群。由于对于HDFS的管理比较简单，下面仅举例介绍如何使用此插件来简化大家MapReduce程序的编写。
18.2.3 Hadoop Eclipse的使用举例
首先打开Hadoop视图（图略），然后右键点击Project Explorer空白处选择New→Project。在创建工程向导中选择创建Map/Reduce工程，然后输入工程名，点击finish，此时Project Explore中会出现新创建的工程。接下来就是编写具体的MapReduce代码了，有两种做法。一种是右键点击新建工程然后新建一个class，并输入自己完整的MapReduce的代码以新建class代码区。注意，代码中的类名要和创建类时输入的类名相同，代码编写完之后直接选择Run on Hadoop即可。另外一种方法是分别建立MapReduce Driver、Mapper、Reducer，再在Hadoop上运行MapReduce Driver。下面详细介绍这两种方法。
1.方法一
方法一是在MapReduce工程下创建符合MapReduce程序框架的普通class文件，然后在Hadoop运行。这种办法直接明了，灵活性比较高。具体步骤如下：
首先在刚才新创建的Hadoop工程上右键点击依次选择New→class，然后点击Next，输入类名TestMapReduce之后点击finish。然后在class文件中输入自己的MapReduce框架函数（本书第6章的程序都可以）。
然后选中TestMapReduce之后选择Run on Hadoop。在输出窗口就可以看到程序在Hadoop上执行的实时信息。
需要注意的是，如果选择Run as Java Application，程序会在类似于单机模式的Hadoop上运行，这时程序的输入和输出都是本地的目录，而不是HDFS上的目录。
2.方法二
方法二是在创建三个MapReduce框架的类时，会自动添加上继承的类和实现的接口以及接口中需要覆盖的函数，这样大家只需要修改类中的函数即可，非常方便。具体步骤如下：
首先在刚才新创建的Hadoop工程上右键点击依次选择New→Other→Map/Reduce→Mapper，然后点击Next，输入类名TestMapper之后点击finish。在自动生成的Map函数中输入自己的处理函数。需要注意的是，Mapper抽象类中Map方法的参数类型和自动生成的不匹配，只需要按照提示修改自动生成Map函数的参数类型就可以了。
接下来在刚才新创建的Hadoop工程上右键点击依次选择New→Other→Map/Reduce→Reducer，然后点击Next，输入类名TestReducer之后点击finish。在自动生成的Reduce函数中输入自己的处理函数。同样需要按照提示修改自动生成Map函数的参数类型，使其和Reducer抽象类中Reduce方法的类型匹配。
最后在刚才新创建的Hadoop工程上右键点击依次选择New→Other→Map/Reduce→MapReduceDriver，然后点击Next，输入类名TestDriver之后点击finish。如果生成的代码中有下面两行内容：
conf.setInputPath（new Path（"src"））；
conf.setOutputPath（new Path（"out"））；
这两个内容是配置MapReduce Job在集群上的输入和输出路径，使用的API和Hadoop中的API不匹配。因此需要将这两段代码改成：
conf.setInputFormat（TextInputFormat.class）；
conf.setOutputFormat（TextOutputFormat.class）；
FileInputFormat.setInputPaths（conf, new Path（"In"））；
FileOutputFormat.setOutputPath（conf, new Path（"Out"））；
同时还需要确认Map/Reduce工程下已经创建了输入文件夹In且没有输出文件夹Out。在自动生成的代码中还有下面的两行：
conf.setMapperClass（org.apache.hadoop.mapred.lib.IdentityMapper.class）；
conf.setReducerClass（org.apache.hadoop.mapred.lib.IdentityReducer.class）；
它们的作用是配置MapReduce Job中Map过程的执行类和Reduce过程的执行类，也就是前两个步骤编写的两个Class。所以将这两行修改成下面的内容：
conf.setMapperClass（TestMapper.class）；
conf.setReducerClass（TestReducer.class）；
最后在TestDriver类名上点击右键依次选择Run As→Run on Hadoop，并选择之前已经配置的Hadoop server，点击finish，接下来就可以看到Eclipse开始运行TestDriver了。这里需要注意的问题有两个：
1）如果任务执行失败，出错提示为Java space heap。这主要是因为Eclipse执行任务时内存不够，导致任务失败，解决的办法是选中工程并点击Run→Run Configuretions，点击出现窗口中间的Arguments选项卡，在VM arguments中写入：-Xms512m-Xmx512m，然后点击Apply，接下来就可以正常执行程序了。这句话的主要作用是配置这个工程可以使用的内存最小值与最大值都是512MB。
2）如何调试MapReduce程序。安装有Hadoop Eclipse插件的Eclipse可以调试MapReduce程序，调试的办法就是正常Java程序在Eclipse中的调试办法，即设置断点，启动Debug，按步调试。
18.3 Hadoop Streaming的介绍和使用
 18.3.1 Hadoop Streaming的介绍
Hadoop Streaming是Hadoop的一个工具，它帮助用户创建和运行一类特殊的MapReduce作业，这些特殊的MapReduce作业是由一些可执行文件或脚本文件充当Mapper或Reducer。也就是说Hadoop Streaming允许用户用非Java的编程语言编写MapReduce程序，然后Streaming用STDIN（标准输入）和STDOUT（标准输出）来和我们编写的Map和Reduce进行数据交换，并提交给Hadoop。命令格式如下：
$HADOOP_HOME/bin/hadoop jar$HADOOP_HOME/hadoop-streaming.jar\
-input myInputDirs\
-output myOutputDir\
-mapper/bin/cat\
-reducer/bin/wc
1.Streaming的工作原理
在上面的命令里，Mapper和Reducer都是可执行文件，它们从标准输入按行读入数据，并把计算结果发送给标准输出。Streaming工具会创建一个MapReduce作业，并把它发送给合适的集群，同时监视这个作业的整个执行过程。
如果一个可执行文件被用于Mapper，则在其初始化时，每一个Mapper任务会把这个可执行文件作为一个单独的进程启动。Mapper任务运行时，它把输入切分成行，并把结果提供给可执行文件对应进程的标准输入。同时，它会收集可执行文件进程标准输出的内容，并把收到的每一行内容转化成key/value对，作为输出。默认情况下，一行中第一个tab之前的部分被当做key，之后的（不包括tab）被当做value。如果没有tab，则整行内容被当做key值，value值为null。具体的转化策略会在下面讨论。
如果一个可执行文件被用于Reducer，每个Reducer任务同样会把这个可执行文件作为一个单独的进程启动。Reducer任务运行时，它把输入切分成行，并把结果提供给可执行文件对应进程的标准输入。同时，它会收集可执行文件进程标准输出的内容，并把每一行内容转化成key/value对，作为输出。默认情况下，一行中第一个tab之前的部分被当作key，之后的（不包括tab）被当做value。
用户也可以使用Java类作为Mapper或Reducer。本节最初给出的命令与这里的命令等价：
$HADOOP_HOME/bin/Hadoop jar$HADOOP_HOME/Hadoop-streaming.jar\
-input myInputDirs\
-output myOutputDir\
-mapper org.apache.hadoop.mapred.lib.IdentityMapper\
-reducer/bin/wc
用户可以设定stream.non.zero.exit.is.failure的值为true或false，从而表明streaming task的返回值非零时是Failure还是Success。默认情况下，streaming task返回非零时表示失败。
2.将文件打包到提交的作业中
利用Streaming用户可以将任何可执行文件指定为Mapper/Reducer。这些可执行文件可以事先存放在集群上，也可以用-file选项让可执行文件成为作业的一部分，并且会一起打包提交。例如：
$HADOOP_HOME/bin/hadoop jar$HADOOP_HOME/hadoop-streaming.jar\
-input myInputDirs\
-output myOutputDir\
-mapper myPythonScript.py\
-reducer/bin/wc\
-file myPythonScript.py
上面的例子描述了一个用户把可执行Python文件指定为Mapper。其中的选项“-file myPythonScirpt.py”使可执行Python文件作为作业的一部分被上传到集群的机器上。
除了可执行文件外，其他Mapper或Reducer需要用到的辅助文件（比如字典、配置文件等）也可以用这种方式打包上传。例如：
$HADOOP_HOME/bin/hadoop jar$HADOOP_HOME/hadoop-streaming.jar\
-input myInputDirs\
-output myOutputDir\
-mapper myPythonScript.py\
-reducer/bin/wc\
-file myPythonScript.py\
-file myDictionary.txt
3.Streaming选项与用法
（1）只使用Mapper的作业
有时候只需要使用Map函数处理输入数据。这时只须把mapred.reduce.tasks设置为零，Mapreduce框架就不会创建Reducer任务，Mapper任务的输出就是整个作业的最终输出。
为了做到向下兼容，Hadoop Streaming也支持“-reduce None”选项，它与“-jobconf mapred.reduce.tasks=0”等价。
（2）为作业指定其他属性
和其他普通的MapReduce作业一样，用户可以为Streaming作业指定数据格式，命令如下：
-inputformat JavaClassName
-outputformat JavaClassName
-partitioner JavaClassName
-combiner JavaClassName
如果不指定输入格式，程序会默认使用TextInputFormat。因为TextInputFormat得到的key值是LongWritable类型的（key值并不是输入文件中的内容，而是value偏移量），所以key会被丢弃，只会把value用管道方式发给Mapper。
另外，用户提供的定义输出格式的类需要能够处理Text类型的key/value对。如果不指定输出格式，则默认会使用TextOutputFormat类。
（3）Hadoop Streaming中的大文件和档案
任务依据-File和-Archive选项在集群中分发文件和档案，选项的参数是用户已上传至HDFS的文件或档案的URI。这些文件和档案在不同的作业间缓存。用户可以通过fs.default.name配置参数的值得到文件所在的host和fs_port。
下面是使用-cacheFile选项的例子：
-File hdfs：//host：fs_port/user/testfile.txt#testlink
在上面的例子里，URL中#后面的内容是建立在任务当前工作目录下的符号链接的名字。这个任务的当前工作目录下有一个“testlink”符号链接，它指向testfile.txt文件在本地的复制位置。如果有多个文件，选项可以写成：
-File hdfs：//host：fs_port/user/testfile1.txt#testlink1
-File hdfs：//host：fs_port/user/testfile2.txt#testlink2
-Archive选项用于把JAR文件复制到任务当前工作目录，并自动把JAR文件解压缩。例如：
-Archive hdfs：//host：fs_port/user/testfile.jar#testlink3
在上面的例子中，testlink3是当前工作目录下的符号链接，它指向testfile.jar解压后的目录。
下面是使用-Archive选项的另一个例子。其中，input.txt文件有两行内容，分别是两个文件的名字：testlink/cache.txt和testlink/cache2.txt。“testlink”是指向档案目录（JAR文件解压后的目录）的符号链接，这个目录下有“cache.txt”和“cache2.txt”两个文件。代码如下所示：
$HADOOP_HOME/bin/Hadoop jar$HADOOP_HOME/Hadoop-streaming.jar\
-input"/user/me/samples/cachefile/input.txt"\
-mapper"xargs cat"\
-reducer"cat"\
-output"/user/me/samples/cachefile/out"\
-Archive'hdfs：//Hadoop-nn1.example.com/user/me/samples/
cachefile/cchedir.jar#testlink'\
-D mapred.map.tasks=1\
-D mapred.reduce.tasks=1\
-D mapred.job.name="Experiment"
$ls test_jar/
cache.txt cache2.txt
$jar cvf cachedir.jar-C test_jar/.
added manifest
adding：cache.txt（in=30）（out=29）（deflated 3%）
adding：cache2.txt（in=37）（out=35）（deflated 5%）
$Hadoop dfs-put cachedir.jar samples/cachefile
$Hadoop dfs-cat/user/me/samples/cachefile/input.txt
testlink/cache.txt
testlink/cache2.txt
$cat test_jar/cache.txt
This is just the cache string
$cat test_jar/cache2.txt
This is just the second cache string
$Hadoop dfs-ls/user/me/samples/cachefile/out
Found 1 items
/user/me/samples/cachefile/out/part-00000＜r 3＞69
$Hadoop dfs-cat/user/me/samples/cachefile/out/part-00000