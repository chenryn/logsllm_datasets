title:How to keep a secret: leakage deterring public-key cryptosystems
author:Aggelos Kiayias and
Qiang Tang
How to Keep a Secret:
Leakage Deterring Public-key Cryptosystems
Aggelos Kiayias
National and Kapodistrian University of Athens
Dept. of Informatics and Telecommunications
PI:EMAIL
National and Kapodistrian University of Athens
Qiang Tang
& University of Connecticut
PI:EMAIL
ABSTRACT
How is it possible to prevent the sharing of cryptographic
functions? This question appears to be fundamentally hard
to address since in this setting the owner of the key is the
adversary: she wishes to share a program or device that (po-
tentially only partly) implements her main cryptographic
functionality. Given that she possesses the cryptographic
key, it is impossible for her to be prevented from writing
code or building a device that uses that key. She may
though be deterred from doing so. We introduce leakage-
deterring public-key cryptosystems to address this problem.
Such primitives have the feature of enabling the embedding
of owner-speciﬁc private data into the owner’s public-key so
that given access to any (even partially functional) imple-
mentation of the primitive, the recovery of the data can be
facilitated. We formalize the notion of leakage-deterring in
the context of encryption, signature, and identiﬁcation and
we provide eﬃcient generic constructions that facilitate the
recoverability of the hidden data while retaining privacy as
long as no sharing takes place.
Categories and Subject Descriptors
K.6 [Management of Computing and Information Sys-
tems]: Security and Protection; E.3 [Data Encryption]:
Public key Cryptosystems
Keywords
Public-key Cryptography, Self-enforcement, Key Manage-
ment, Leakage-deterring
1.
INTRODUCTION
Consider any organization that maintains a PKI support-
ing various cryptographic functions including public-key en-
cryption, signatures and identiﬁcation. How is it possible to
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516691 .
prevent individuals from sharing their cryptographic func-
tions? Certiﬁed PKI members, out of convenience or even
malice, can delegate their private keys to each other (or
even to outsiders), thus violating accountability and organi-
zational policy. Even worse, delegation can be partial: for
instance, a public-key encryption user can share (or, in fact,
even sell) an implementation that only decrypts messages
of a certain form (e.g., only e-mails from a speciﬁc source).
Seemingly, very little can be done to prevent this as the ad-
versary in this case is the owner of the cryptographic key:
inevitably practice has shown that no matter how much one
protects a cryptographic implementation, a determined at-
tacker can always reverse engineer it.
The above scenario puts forth the central problem our
work aims to solve: how is it possible to prevent the sharing
of cryptographic functions? The main challenge here is that
the owner of the key is adversarial: she wishes to share a pro-
gram or hardware device that (potentially only partly) im-
plements her main cryptographic functionality. Given that
she possesses the cryptographic key (either in software or
hardware), it is impossible for her to be prevented from del-
egating it. However, as we highlight, there can be ways
for her to be deterred from doing so. A straightforward de-
terrence mechanism would be to identify and penalize the
sharing behavior. However, the enforcement of a penalty
mechanism is contingent to detecting the act of sharing —
something that limits the eﬀectiveness of penalties: a cau-
tious adversary can keep itself “below the radar” and thus
remain penalty-free. To address this we put forth and ex-
plore a more proactive approach.
A cryptographic scheme will be called leakage-deterring if
the release of any implementation of the cryptographic func-
tion (e.g, decryption, signing), leads to the recovery of some
private information (that the owner prefers to keep hidden)
by anyone that possesses the implementation. Leakage de-
terrence is thus achieved in the sense that sharing the cryp-
tographic function in any form incurs the penalty of reveal-
ing the private information (while non-sharing maintains its
privacy).
Note that a leakage-deterring primitive should retain its
original functionality (e.g., encryption, signing, identiﬁca-
tion) but it will also oﬀer two additional operations: ﬁrst,
it is possible to embed private data into the public-key of
the primitive in a way that they are (at least) semantically
secure. The embedding operation is facilitated through an
interaction with an authority that vouches for the integrity
of the private data and is akin to a PKI certiﬁcation of the
owner’s public-key. In this fashion, the primitive’s public-
943key becomes “enhanced” and is a carrier of private infor-
mation itself (i.e., a ciphertext) — otherwise the intended
functionality of the primitive should remain unchanged. The
second operation that is oﬀered by a leakage-deterring prim-
itive comes into play when the owner of the secret key pro-
duces an implementation of the main operation in the form
of a “box” and shares it with other entities (in software or
hardware). Given such a box, any entity that receives it can
utilize a public recovering algorithm that will interact with
the box and produce the private data that are embedded
into the owner’s enhanced public-key.
In a nutshell, designing a leakage-deterring scheme re-
quires the transformation of the public-key of the primitive
into a (one-time) ciphertext that can be decrypted by any
working implementation of the cryptographic functionality.
The main challenge comes precisely from this latter require-
ment: any working implementation of the cryptographic
functionality should be usable as a decryption key that un-
locks the private data embedded into the public-key, even if
the adversarial implementor takes into account the recover-
ability algorithm and the enhanced public-key that carries
the private data when implementing the functionality.
To appreciate the complexity of the problem, consider a
naive attempt to produce a leakage-deterring public-key en-
cryption (PKE): the authority certiﬁes as the enhanced pub-
lic key the pair (pk, ψ) where ψ = Enc(pk, s) and s is the
private data related to the owner. Recoverability can be at-
tempted by feeding ψ into a decryption box. It is apparent
that this construction can be defeated by an adversarial im-
plementation of decryption that given input c, it decrypts
it only in the case c (cid:54)= ψ (or even Dec(c) (cid:54)= s). The con-
structions we seek should facilitate recoverability even if the
adversarial box implementor releases implementations that
work for arbitrary input distributions of her choice.
The applications of leakage-deterring cryptographic prim-
itives are in any context where the intentional leakage of a
cryptographic functionality should be deterred or restricted
in some fashion or in a context where the leakage of an im-
plementation should enable the computation of a value that
is otherwise hidden.
In the most simple scenario, the en-
hanced public-key contains some piece of information that
the owner prefers to keep secret (e.g., her credit-card num-
ber or similar piece of private information as suggested by
Dwork, Lotspiech and Naor [9] that introduced the concept
of self-enforcement – in a related but diﬀerent context – see
below). It follows that the system setup “self-enforces” the
owner to keep the cryptographic functionality to herself. De-
pending on the deployment environment, diﬀerent types of
secret-information can be used. We describe more applica-
tion scenarios of leakage deterring cryptographic primitives
in section 5.
Our Contributions. We introduce, formalize and imple-
ment leakage-deterring cryptographic primitives for public-
key encryption, digital signatures, and identiﬁcation schemes.
The main technical contributions we provide are three dif-
ferent techniques for constructing leakage-deterring crypto-
graphic primitives. Our techniques enable the secure em-
bedding of private information into the public key of the
primitive in a way that is recoverable given any (even par-
tially) working implementation. Our ﬁrst method, applies
to encryption that is partially homomorphic; given a box
that works only for some adversarially chosen distributions
we show how to exploit the homomorphic property to appro-
priately manipulate a target ciphertext and make it decrypt-
able by the adversarial decryption box. Our second method,
which can rely on any encryption scheme, hides the key that
unlocks the private information into an exponentially large
key space that is encoded in the public-keys. By using ap-
propriate redundancy in the public key space we enable the
tracing of the vector of keys that identify the private infor-
mation, out of any (even partially working) implementation.
Achieving recoverability while maintaining small ciphertext
size in this setting requires an involved recoverability algo-
rithm which is one of the highlights of our contributions.
Finally, our third method applies to signature and identiﬁ-
cation schemes. It uses the fact that working implementa-
tions of suitably chosen such primitives can be used to build
“knowledge extractors.” These are algorithms that reveal in-
formation about the secret-key of the underlying primitives
which we use to hide the private information.
Our ﬁrst construction for public-key encryption requires a
standard homomorphic property and achieves constant size
ciphertexts while oﬀering recoverability for any (non-trivial)
adversarial distribution. The second construction is generic
and the size of ciphertexts is a parameter that increases
as the min-entropy of the allowed adversarial distributions
becomes smaller. We analyze our constructions in the IND-
CPA setting and then present a generic transformation to
obtain IND-CCA2 security.1
It is evident that there is a
trade-oﬀ between privacy and recoverability. For encryp-
tion schemes, we aim at maximizing the recoverability while
privacy can only be achieved if no decryption query is al-
lowed. For the case of signatures, we present a construc-
tion that maintains the privacy of the embedded informa-
tion even if the adversary has arbitrary access to the signing
functionality (which is most desirable since digital signatures
are typically publicly available). We still manage to enable
recoverability by exploiting the random oracle model and
non-black-box access to the implementation. Security prop-
erties of our identiﬁcation schemes are shown in the standard
model. To attain privacy in the standard model we utilize
strong extractors for random variables with high conditional
unpredictability.
Related work. The most relevant work to ours is [9] that
introduced self-enforcement as a way of avoiding illegal con-
tent redistribution in a multi-user setting. Self-enforcement
was argued in that paper by ensuring (under certain as-
sumptions) that an owner has only two options when im-
plementing a decoder: either using her private key (that
includes private personal information), or encoding a de-
rived key that is of size proportional to the data to be de-
crypted. In our terminology, this means that the schemes
of [9] exhibit a leakage-deterrence/program-length tradeoﬀ
and hence are not leakage-deterring per se. Furthermore,
recoverability in [9] is only “white-box” as opposed to the
1It may come as a surprise that recoverability and IND-
CCA2 can actually coexist. Attaining IND-CCA2 intu-
itively means that a decryption oracle basically leaks no use-
ful information about manipulated ciphertexts. Thus, the
recovering algorithm can seemingly do nothing useful with
access to a decryption implementation beyond decrypting
valid ciphertexts, which if related to the enhanced public-
key can be rejected. Still, the paradox can be resolved, if
one observes that the decryption oracle should be useless
only with respect to breaking the security of regular cipher-
texts and not the security of the data that are somehow
embedded into the enhanced public-key.
944black-box nature that our constructions achieve. In another
related line of work [5, 27, 4, 21] it was discussed how to
deter a user from transferring her credentials (or the secret
key directly) to others in the context of identiﬁcation sys-
tems. The techniques from these works – by nature – were
restricted to only identiﬁcation schemes and digital signa-
tures. The primitive of circular encryption introduced in
[4] might look promising at ﬁrst sight to achieve leakage-
deterrence in the public-key encryption setting as well, how-
ever, no recovery algorithm which works for all partial im-
plementations is immediately apparent. Indeed, recall that
the technically most challenging aspect of leakage-deterring
cryptosystems is in the design of black-box recoverability
and for this, techniques other than circular encryption are
needed.
Interestingly, our embedding techniques eventu-
ally obviate the need for circular encryption altogether as
they can hide the owner private data in an information-
theoretic sense and hence the secret-key can be safely em-
bedded into the public-key without jeopardizing the security
of the scheme. Furthermore, for the case of identiﬁcation
and signature schemes, the idea of taking advantage of the
knowledge extractor for preventing the transfer of identiﬁca-
tion tokens has been utilized before [5, 27, 4, 21] (in the sense
that sharing a token implies sharing the key). In our con-
struction we go beyond this, by showing that the secret key
can be of suﬃcient (pseudo)entropy so that it can hide ar-
bitrary information (and not merely itself). In fact we show
that no additional intractability assumptions are necessary
for achieving leakage-deterring signature and identiﬁcation
schemes. Other forms of leakage deterring techniques were
considered in various settings, e.g., limited delegation [13],
data collection [14], e-payments [31] or designated veriﬁer
signatures in [26, 32] in the form of non-delegatability (which
is a weaker notion than our leakage-deterring concept).
Another related notion, introduced in [28], dealt with the
problem copyrighting a public-key decryption function: a
single public-key decryption functionality should be imple-
mented in many distinct ways so that if an implementation
is derived from some of them, then it is possible to dis-
cover the index of at least one of the implementations that
was used. This notion was further investigated in [23] and
was related to traitor tracing schemes [6]. In the context of
public-key encryption, the objective of copyrighting a func-
tion or of a traitor tracing scheme is orthogonal to ours.
While in both cases we deal with adversarial implementa-
tions of cryptographic functionalities (hence the similarities
in terminology), the adversarial goal is diﬀerent: in the case
of traitor tracing, the adversary has many diﬀerent imple-
mentations of the same functionality and tries to produce a
new one that is hard to trace back to the ones she is given.
In an attack against a leakage-deterring scheme on the other
hand the adversary possesses an implementation of a cryp-
tographic functionality and tries to modify it in a way that
it cannot be used to extract some information that is hidden
in the primitive’s public-key. Combining the two function-
alities in one is an interesting question and we leave it as
open problem (a step towards this general direction but in
a much weaker model than ours was suggested in the work
of [24] but the leakage-deterring aspect (in our terminology)
was found to be insecure in [22]).
Accountable authority identity based encryption (AIBE) [15,
16, 25, 30] considers the problem of judging whether an im-
plementation of decryption belongs to the owner or the PKG
(in the context of IBE). In this setting, both the owner and
the PKG may be the potential adversary who try to impli-
cate the other. Hence, some property similar to our recover-
ability is needed. In any case, the single bit decisional output
required by AIBE is much weaker than our recoverability re-
quirement in leakage-deterring public-key encryption (even
in the IBE setting) where by interacting with a decryption
box, one should recover the whole private data embedded in
the enhanced public-key.
Finally we should point out that the notion of leakage de-
terrence is diﬀerent from the notion of leakage-resilience (see
e.g., [20, 10]). Our notion aims at constructing schemes with
the property that intensional leakage of the cryptographic
functionality implies the revelation of some private owner
information (hence they are “leakage-deterring”), while the
leakage-resilience notion aims at ensuring that the uninten-
tional leakage (as in the case of side channel attacks) pro-
vides no useful information to an adversary.
2. DEFINITIONS AND SECURITY MODEL
2.1 Leakage-deterring Cryptosystems
A leakage-deterring cryptographic primitive includes two