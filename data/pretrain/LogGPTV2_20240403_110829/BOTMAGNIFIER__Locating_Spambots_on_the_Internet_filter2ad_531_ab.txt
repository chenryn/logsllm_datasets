of the observation period, there is a delay introduced be-
fore BOTMAGNIFIER can identify new spam hosts. This
is not desirable when the output is used for improving
spam defenses. In practice, we found that an observation
period of one day allows us to generate sufﬁciently large
seed pools from the available spam feed. To evaluate
the impact that the choice of the analysis period might
have on our analysis system, we looked at the length of
100 spam campaigns, detected over a period of one day.
The average length of these campaigns is 9 hours, with a
standard deviation of 6 hours. Of the campaigns we ana-
lyzed, 25 lasted less than four hours. However, only two
of these campaigns did not generate large enough seed
pools to be considered by BOTMAGNIFIER. On the other
hand, 8 campaigns that lasted more than 18 hours would
not have generated large enough seed pools if we used
a shorter observation period. Also, by manual investi-
gation, we found that campaigns that last more than one
day typically reach the threshold of 1,000 IP addresses
for their seed pool within the ﬁrst day. Therefore, we be-
lieve that the choice of an observation period of one day
works well, given the characteristics of the transaction
log we used. Of course, if the volume of either the seed
pools or the transaction log increased, the observation
period could be reduced accordingly, making the system
more effective for real-time spam blacklisting.
Note that it is not a problem when a spam campaign
spans multiple observation periods.
In this case, the
bots that participate in this spam campaign and are ac-
tive during multiple periods are simply included in mul-
tiple seed pools (one for each observation period for this
campaign).
2.2 Transaction Log
The transaction log is a record of email transactions car-
ried out on the Internet during the same time period
used for the generation of the seed pools. For the cur-
rent version of BOTMAGNIFIER and the majority of our
experiments, we obtained the transaction log by ana-
lyzing the queries to a mirror of Spamhaus, a widely-
used DNS-based blacklisting service (DNSBL). When
an email server S is contacted by a client C that wants
to send an email message, server S contacts one of the
Spamhaus mirrors and asks whether the IP address of the
client C is a known spam host. If C is a known spam-
mer, the connection is rejected or the email is marked as
spam.
Each query to Spamhaus contains the IP address of
It is possible that S may not query Spamhaus di-
C.
rectly. In some cases, S is conﬁgured to use a local DNS
server that forwards the query. In such cases, we would
mistakenly consider the IP address of the DNS server
as the mail server. However, the actual value of the IP
address of S is not important for the subsequent analy-
sis. It is only important to recognize when two different
clients send email to the same server S. Thus, as long
as emails sent to server S yield Spamhaus queries that
always come from the same IP address, our technique is
not affected.
Each query generates an entry in the transaction log.
More precisely, the entry contains a timestamp, the IP
address of the sender of the message, and the IP address
of the server issuing the query. Of course, by monitoring
a single Spamhaus mirror (out of 60 deployed throughout
the Internet), we can observe only a small fraction of the
global email transactions. Our mirror observes roughly
one hundred million email transactions a day, compared
to estimates that put the number of emails sent daily at
hundreds of billions [13].
Note that even though Spamhaus is a blacklisting ser-
vice, we do not use the information it provides about the
blacklisted hosts to perform our analysis.
Instead, we
use the Spamhaus mirror only to collect the transaction
logs, regardless of the fact that a sender may be a known
spammer. In fact, other sources of information can be
used to either populate the seed pools or to collect the
transaction log. To demonstrate this, we also ran BOT-
MAGNIFIER on transaction logs extracted from netﬂow
data collected from a number of backbone routers of a
large ISP. The results show that our general approach is
still valid (see Section 6.4 for details).
3 Characterizing Bot Behavior
Given the two input datasets described in the previous
section, the ﬁrst step of our approach is to extract the be-
havior of known spambots. To this end, the transaction
log is consulted. More precisely, for each seed pool, we
query the transaction log to ﬁnd all events that are associ-
ated with all of the IP addresses in that seed pool (recall
that the IP addresses in a seed pool correspond to known
spambots). Here, an event is an entry in the transaction
log where the known spambot is the sender of an email.
Essentially, we extract all the instances in the transaction
log where a known bot has sent an email.
Once the transaction log entries associated with a seed
pool are extracted, we analyze the destinations of the
spam messages to characterize the bots’ behavior. That
is, the behavior of the bots in a seed pool is characterized
by the set of destination IP addresses that received spam
messages. We call the set of server IP addresses targeted
by the bots in a seed pool this pool’s target set.
The reason for extracting a seed pool’s target set is the
insight that bots belonging to the same botnet receive the
same list of email addresses to spam, or, at least, a subset
of addresses belonging to the same list. Therefore, dur-
ing their spamming activity, bots belonging to botnet A
will target the addresses contained in list LA, while bots
belonging to botnet B will target destinations belonging
to list LB. That is, the targets of a spam campaign char-
acterize the activity of a botnet.
Unfortunately, the target sets of two botnets often have
substantial overlap. The reason is that there are many
popular destinations (server addresses) that are targeted
by most botnets (e.g., the email servers of Google, Ya-
hoo, large ISPs with many users, etc.) Therefore, we
want to derive, for each spam campaign (seed pool), the
most characterizing set of destination IP addresses. To
this end, we remove from each pool’s target set all server
IP addresses that appear in any target set belonging to
another another seed pool.
More precisely, consider
the seed pools P =
p1, p2, . . . , pn. Each pool pi stores the IP addresses
of known bots that participated in a certain campaign:
i1, i2, . . . , im. In addition, consider that the transaction
log L contains entries in the form (cid:104)t, is, id(cid:105), where t is a
time stamp, is is the IP address of the sender of an email
and id is the IP address of the destination server of an
email. For each seed pool pi, we build this seed pool’s
target set T (pi) as follows:
T (pi) := {id|(cid:104)t, is, id(cid:105) ∈ L ∧ is ∈ pi}.
(1)
Then, we compute the characterizing set C(pi) of a
seed pool pi as follows:
C(pi) := {id|id ∈ T (pi) ∧ id /∈ T (pj), j (cid:54)= i}.
As a result, C(pi) contains only the target addresses
that are unique (characteristic) for the destinations of
bots in seed pool pi. The characterizing set C(pi) of
each pool is the input to the next step of our approach.
(2)
4 Bot Magniﬁcation
The goal of the bot magniﬁcation step is to ﬁnd the IP ad-
dresses of additional, previously-unknown bots that have
participated in a known spam campaign. More precisely,
the goal of this step is to search the transaction log for IP
addresses that behave similarly to the bots in a seed pool
pi. If such matches can be found, the corresponding IP
addresses are added to the magniﬁcation set associated
with pi. This means that a magniﬁcation set stores the IP
addresses of additional, previously-unknown bots.
BOTMAGNIFIER considers an IP address xi that ap-
pears in the transaction log L as matching the behavior
of a certain seed pool pi (and, thus, belonging to that
spam campaign) if the following three conditions hold:
(i) host xi sent emails to at least N destinations in the
seed pool’s target set T (pi); (ii) the host never sent an
email to a destination that does not belong to that target
set; (iii) host xi has contacted at least one destination that
is unique for seed pool pi (i.e., an address in C(pi)). If
all three conditions are met, then IP address xi is added
to the magniﬁcation set M(pi) of seed pool pi.
More formally, if we deﬁne D(xi) as the set of desti-
nations targeted by an IP address xi, we have:
xi ∈ M(pi) ⇐⇒ |D(xi) ∩ T (pi)| ≥ N ∧
D(xi) ⊆ T (pi) ∧
D(xi) ∩ C(pi) (cid:54)= ∅.
(3)
The intuition behind this approach is the following:
when a host h sends a reasonably large number of emails
to the same destinations that were targeted by a spam
campaign and not to any other targets, there is a strong
indication that the email activity of this host is similar to
the bots involved in the campaign. Moreover, to assign
a host h to at most one campaign (the one that it is most
similar), we require that h targets at least one unique des-
tination of this campaign.
Threshold computation. The main challenge in this
step is to determine an appropriate value for the thresh-
old N, which captures the minimum number of destina-
tion IP addresses in T (pi) that a host must send emails to
in order to be added to the magniﬁcation set M(pi). Set-
ting N to a value that is too low will generate too many
bot candidates, including legitimate email servers, and
the tool would generate many false positives. Setting N
to a value that is too high might discard many bots that
should have been included in the magniﬁcation set (that
is, the approach generates many false negatives). This
trade-off between false positives and false negatives is a
problem that appears in many security contexts, for ex-
ample, when building models for intrusion detection.
An additional, important consideration for the proper
choice of N is the size of the target set |T (pi)|. Intu-
P and recall R values for each threshold setting. Since
we want to express the quality of the magniﬁcation pro-
cess as a function of k, independently of the size of a
campaign, we use Equation 4 to get k = N|T (pi)|.
The precision value P (k) represents what fraction of
the IP addresses that we obtain as candidates for the mag-
niﬁcation set for a given k are actually among the ground
truth IP addresses. The recall value R(k), on the other
hand, tells us what fraction of the total bot set B is identi-
ﬁed. Intuitively, a low value of k will produce high R(k),
but low P (k). When we increase k, P (k) will increase,
but R(k) will decrease. Optimally, both precision and
recall are high. Thus, for our analysis, we use the prod-
uct P R(k) = P (k) · R(k) to characterize the quality
of the magniﬁcation step. Figure 1 shows how P R(k)
varies for different values of k. As shown for each cam-
paign, P R(k) ﬁrst increases, then stays relatively level,
and then starts to decrease.
The results indicate that k is not a constant, but varies
with the size of |T (pi)|. In particular, small campaigns
have a higher optimal value for k compared to larger
campaigns: as |T (pi)| increases, the value of k slowly
decreases. To reﬂect this observation, we use the follow-
ing, simple way to compute k:
k = kb + α
|T (pi)| ,
(5)
where kb is a constant value, α is a parameter, and
|T (pi)| is the number of destinations that a campaign
targeted. The parameters kb and α are determined so
that the quality of the magniﬁcation step P R is maxi-
mized for a given ground truth dataset. Using the Cut-
wail campaigns as the dataset, this yields kb = 8 · 10−4
and α = 10.
Our experimental results show that these parameter
settings yield good results for a wide range of campaigns,
carried out by several different botnets. This is because
the magniﬁcation process is robust and not dependent
on an optimal threshold selection. We found that non-
optimal thresholds typically tend to decrease recall. That
is, the magniﬁcation process does not ﬁnd all bots that it
could possibly detect, but false positives are limited. In
Section 6.4, we show how the equation of k, with the val-
ues we determined for parameters kb and α, yields good
results for any campaign magniﬁed from our Spamhaus
dataset. We also show that the computation of k can be
performed in the same way for different types of trans-
action logs. To this end, we study how BOTMAGNIFIER
can be used to analyze netﬂow records.
5 Spam Attribution
Once the magniﬁcation process has completed, we merge
the IP addresses from the seed pool and the magniﬁca-
Figure 1: Quality of magniﬁcation for varying k using
ten Cutwail campaigns of different sizes.
itively, we expect that N should be larger when the size
of the target set increases. This is because a larger target
set increases the chance that a random, legitimate email
sender hits a sufﬁcient number of targets by accident, and
hence, will be incorrectly included into the magniﬁcation
set. In contrast, bots carrying out a spam campaign that
targets only a small number of destinations are easier to
detect. The reason is that as soon as a legitimate email
sender sends an email to a server that is not in the set tar-
geted by the campaign, it will be immediately discarded
by our magniﬁcation algorithm. Therefore, we represent
the relationship between the threshold N and the size of
the target set |T (pi)| as:
N = k · |T (pi)|, 0 < k ≤ 1,
(4)
where k is a parameter. Ideally, the relation between N
and |T (pi)| would be linear, and k will have a constant
value. However, as will be clear from the discussion be-
low, k also varies with the size of |T (pi)|.
To determine a good value for k and, as a consequence,
select a proper threshold N, we performed an analysis
based on ground truth about the actual IP addresses in-
volved in several spam campaigns. This information was
collected from the takedown of more than a dozen C&C
servers used by the Cutwail spam botnet. More speciﬁ-
cally, each server stored comprehensive records (e.g., tar-
get email lists, bot IP addresses, etc.) about spam activi-
ties for a number of different campaigns [35]
In particular, we applied BOTMAGNIFIER to ten Cut-
wail campaigns, extracted from two different C&C
servers. We used these ten campaigns since we had a
precise view of the IP addresses of the bots that sent the
emails. For the experiment, we varied the value for N in
the magniﬁcation process from 0 to 300. This analysis
yielded different magniﬁcation sets for each campaign.
Then, using our knowledge about the actual bots B that
were part of each campaign, we computed the precision
 0 0.2 0.4 0.6 0.8 1 0 0.0005 0.001 0.0015 0.002 0.0025 0.003 0.0035PR(k)kcampaign with 75,681 dest.campaign with 63,491 dest.campaign with 56,113 dest.campaign with 42,498 dest.campaign with 36,400 dest.campaign with 27,531 dest.campaign with 26,112 dest.campaign with 17,044 dest.campaign with 9,342 dest.campaign with 7,776 dest.tion set to obtain a campaign set. We then apply several
heuristics to reduce false positives and to assign the dif-
ferent campaign sets to speciﬁc botnets. Note that the
labeling of the campaign sets does not affect the results
of the bot magniﬁcation process. BOTMAGNIFIER could
be used in the wild for bot detection without these at-
tribution functionalities. It is relevant only for tracking
the populations of known botnets, as we discuss in Sec-
tion 6.2.
5.1 Spambot Analysis Environment
The goal of this phase is to understand the behavior of
current spamming botnets. That is, we want to determine
the types of spam messages sent by a speciﬁc botnet at
a certain point in time. To this end, we have built an
environment that enables us to execute bot binaries in a
controlled setup similarly to previous studies [11, 39].
Our spambot analysis environment is composed of one
physical system hosting several virtual machines (VMs),
each of which executes one bot binary. The VMs have
full network access so that the bots can connect to the
C&C server and receive spam-related conﬁguration data,
such as spam templates or batches of email addresses to
which spam should be sent. However, we make sure that
no actual spam emails are sent out by sinkholing spam
trafﬁc, i.e., we redirect outgoing emails to a mail server
under our control. This server is conﬁgured to record
the messages, without relaying them to the actual des-
tination. We also prevent other kinds of malicious traf-
ﬁc (e.g., scanning or exploitation attempts) through vari-
ous ﬁrewall rules. Some botnets (e.g., MegaD) use TCP
port 25 for C&C trafﬁc, and, therefore, we need to make
sure that such bots can still access the C&C server. This
is implemented by ﬁrewall rules that allow C&C trafﬁc
through, but prevent outgoing spam. Furthermore, bot-
nets such as Rustock detect the presence of a virtual en-
vironment and refuse to run. Such samples are executed
on a physical machine conﬁgured with the same network
restrictions. To study whether bots located in different
countries show a unique behavior, we run each sample