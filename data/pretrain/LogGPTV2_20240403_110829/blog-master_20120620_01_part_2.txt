                     Merge Cond: (t.app_id = at.app_id)  
                     Join Filter: ((t.ismax IS TRUE) AND (t.deleted = 0::numeric))  
                     ->  Index Scan using idx_test1_2 on test1 t  (cost=0.00..18847.95 rows=110646 width=531) (actual time=0.011..15  
9.184 rows=110646 loops=1)  
                     ->  Materialize  (cost=0.00..15.58 rows=476 width=7) (actual time=0.015..0.642 rows=900 loops=1)  
                           ->  Index Scan using idx_test2_1 on test2 at  (cost=0.00..14.39 rows=476 width=7) (actual time=0.013..0.3  
47 rows=476 loops=1)  
 Total runtime: 584.740 ms  
(12 rows)  
```  
## 优化2   
通过优化1, 查询性能基本上有1倍左右的提升.   
但是从总时长来看, 越到后面, 每一次翻页都需要消耗几百毫秒. 每页显示的数量越少, 全部翻完所消耗的时间就越长.  
我们来用一个函数测试一下使用大小不一样的分页, 看看时间分别是多少.  
```  
create or replace function f_test1(i_limit int) returns int as $$  
declare  
v_work int;  
v_count int;  
v_offset int;  
i int;  
begin  
v_work := 0;  
v_count := 0;  
v_offset := 0;  
i := 1;  
raise notice 'start time:%',clock_timestamp();  
loop  
  select count(*) into v_work from   
    (select 1 from   
      test1 t  
      left outer join test2 at   
      on (t.APP_ID=at.APP_ID and t.DELETED=0 and t.ismax is true)  
      left outer join   
      test3 h   
      on (t.APP_ID=h.APP_ID)  
      limit i_limit offset v_offset  
    )t;  
  if v_work=0 then  
    exit;  
  end if;  
  v_offset := i * i_limit;  
  v_count := v_count + v_work;  
  i := i+1;  
end loop;  
raise notice 'end time:%',clock_timestamp();  
return v_count;  
end;  
$$ language plpgsql;  
-- 测试每页10000条  
digoal=> select * from f_test1(10000);  
NOTICE:  start time:2012-06-21 10:44:34.148575+08  
NOTICE:  end time:2012-06-21 10:44:36.095619+08  
 f_test1   
---------  
  110646  
(1 row)  
耗时2秒.  
-- 测试每页100条  
digoal=> select * from f_test1(100);  
NOTICE:  start time:2012-06-21 10:44:45.448933+08  
NOTICE:  end time:2012-06-21 10:46:53.070959+08  
 f_test1   
---------  
  110646  
(1 row)  
耗时128秒.  
```  
所以第二种优化手段是, 提高每页获取的数量, 增加应用层缓存, 也就是说每次取的页数多一点, 不用每一页都来数据库取. 当然如果应用能够一次把数据全取过去就最好了.  
最后一点, 本例的分页SQL都没有ORDER BY, 算是个业务层的BUG, 这种分页是不可取的, 因为无法保证返回的顺序.  
参考修改如下 :   
```  
select t.APP_ID, t.APP_VER, t.CN_NAME, t.PACKAGE, t.APK_SIZE, t.APP_SHOW_VER, t.DESCRIPTION,t.CONTENT_PROVIDER,at.APP_TAG,h.SCORE       
from   
test1 t  
left outer join test2 at   
on (t.APP_ID=at.APP_ID and t.DELETED=0 and t.ismax is true)  
left outer join   
test3 h   
on (t.APP_ID=h.APP_ID)  
order by t.app_id  
limit 24 offset 0;  
```  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")