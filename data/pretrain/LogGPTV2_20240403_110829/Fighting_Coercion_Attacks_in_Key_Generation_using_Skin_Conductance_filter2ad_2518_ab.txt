total bits in a feature descriptor of SC
feature key using SC
Mel-frequency Cepstral Coefﬁcients (MFCCs) instead of
linear cepstrum [24]. MFCC has advantages over linear
cepstrum that the frequency bands are equally spaced on
the mel scale, which approximates the human auditory
system’s response more closely than the linearly-spaced
frequency bands used in the linear cepstrum [13].
Associating centroids to the acoustic model We con-
vert the raw speech signal into a sequence of acoustic
feature vectors in terms of the Mel-frequency Cepstral
Coefﬁcients (MFCCs) [10].
In the next paragraph we
provide a short description on the extraction of MFCC
(see Figure 4).
Figure 4: Block diagram of extracting MFCC
The voice signal is ﬁrst divided into blocks of 20 to 30
msec (see Figure 3(a)), and Discrete Fourier Transform
(DFT) is performed to obtain the frequency representa-
tion of each block. The neighboring frequencies in each
block are grouped into bins of overlapping triangular
bands of equal bandwidth. These bins are equally spaced
on a Mel-scale instead of a normal scale as the lower fre-
quencies are perceptually more important than the higher
frequencies. The content of each band is now summed
and the logarithmic of each sum is computed. To see this
effect in time domain, Discrete Cosine Transform is ap-
plied to yield a “spectrum like” representation ψ(t) that
collectively make up an MFC, and ψ(1), . . . ψ(12) are
called MFCC, where higher order coefﬁcients are dis-
carded. This vector is called a frame (fV ).
We run a sliding window of 30 msec over an utterance
to obtain blocks 10 msec apart from one another, and ex-
tract the MFCC, hψ(1), . . . ψ(12)i, for each block (see
Figure 3(b)). n frames are obtained from utterance of the
password (see Figure 3(c)). An acoustic model of vec-
6
tors from a speaker-independent and text-independent
database of voice signals is obtained, from which vector
quantization is used to partition the acoustic model into
clusters (see Figure 3(d)). A multivariate normal distri-
bution for each cluster is generated, where each cluster
is parameterized by the vector c of a component-wise
means (called a centroid) and the covariance matrix Σ
for the vectors in the cluster. The density function for
this distribution is
P (c | x) =
1
(2π)δ/2pdet(Σ)
e−(x−c)T Σ−1(x−c)/2
where δ is the dimension of the vectors. We denote the
set of centroids as C.
Segmentation of frames After getting the centroids
from a speaker-independent database of voice signals,
we try to obtain the transcription, i.e., the starts and ends,
of the phonemes of an individual user’s utterance.
To do this, we perform segmentation on the spo-
ken password. Let fV (1), . . . fV (n) be the sequence
of frames from the utterance, and F (R1), . . . F (Rs) be
the sequence of s segments (s is a constant and same
for all users), where F (Ri) is the ith segment contain-
ing the sequence of frames fV (j), . . . fV (j′) such that,
1 ≤ j ≤ j′ ≤ n. Intuitively, each F (Ri) corresponds to
one “component sound” of the user’s utterance.
We did this with an iterative approach (see algo-
rithm 1). Ranges R1, . . . , Rs are ﬁrst initialized to be
equally long. We then calculate the matching centroid c
for a segment F(R), i.e., the one for which the likelihood
of F(R) w.r.t. c is maximum. Dynamic programming is
then used to determine a new segmentation for that frame
sequence. This process is repeated until an optimal seg-
mentation is obtained, which is mapped to the feature
descriptor (see Figure 3(e,f)).
Feature descriptor Having derived a segmentation for
a spoken password, we next deﬁne the feature descriptor
(φV ) of this segmentation that is typically the same when
the same user speaks out the same utterance. To do this,
Algorithm 1 Spoken password segmentation
Segmentation (fV (1), . . . , fV (n), s)
1: Score
2: for i = 1 to s do
←− 0
′
3: Ri ←− „j (i − 1) × n
s
s k«
k,j i × n
L(F (Ri)|c) ←− Yj ∈ Ri
(fV (j)|c)
end while
c(Ri) ←− arg max
c ∈ C
{L(F (R)|c)}
4: end for
5: repeat
6:
7:
8:
9:
′
Score ←− Score
for i = 1 to s do
while ∀c ∈ C do
10:
11:
12:
13:
14:
end for
let[s
′
Score
i=1
′
R
i ←− [1, n]
s
←−
Yi = 1
′
15: Ri ←− R
i
- Score  tV
⊥, otherwise
0, if µφSC (i) + kσφSC (i)  tSC
⊥, otherwise
∀ 1 ≤ i ≤ mV
∀ 1 ≤ i ≤ mSC
BV (i) =8>:
BSC (i) =8>:
for some threshold tV and tSC respectively (see Fig-
ure 3(j)). This phase is the training phase in our model.
Here k is a parameter to acquire a tradeoff between se-
curity and usability. With the increase in value of k, the
user has better chance to generate the key successfully,
but will hamper the security of the scheme. More pre-
cisely, the increase in the value of k will increase the
false-positive rate and decrease the false-negative rate (as
shown in our results in the evaluation Section 6).
The idea of deﬁning the partial feature descriptor
in this way is illustrated in Figure 5 (where the set
{B, µ, σ, t} is replaced by {BV , µφV , σφV , tV } and
{BSC, µφSC , σφSC , tSC} for voice and skin conductance
respectively). If the ith feature descriptor is consistently
same i.e. µ(i) + kσ(i) .
The key generation
template therefore comprises of key K encrypted
with Z = |KHi| derived keys and the lookup tables
.
the template = ,
>,
Thus,
4.3.2 Cryptographic key reconstruction
When a user tries to reconstruct the cryptographic key,
he/she ﬁrst presents his/her spoken password and the skin
conductance. The model collect this information, ex-
tracts the features and generates the feature descriptors
for both voice and the SC. Corresponding shares from the
lookup tables are chosen based on the feature descriptors.
8
bV (i) = (0
bSC (i) = (0
1
1
if φV (i) < tV
otherwise
if φSC (i) < tSC
otherwise
∀ 1 ≤ i ≤ mV
∀ 1 ≤ i ≤ mSC
For example, if the feature descriptor φSC (i) is less than
the threshold tSC , then bSC(i) = 0 and TSC (i, 0) is cho-
sen from TSC as a key share; otherwise bSC(i) = 1 and
TSC(i, 1) is chosen (see Figure 3(i)). bV and bSC are the
feature keys and are obtained from voice and SC respec-
tively.
A key K ′ is derived by concatenating the key shares
(see Figure 3(k)). This derived key is then used to de-
crypt the |KHi| encrypted keys stored in the template. If
the decryption succeeds (by matching the released B and
the stored B), then the key K is released.
KD =(DK ′ (EKHi
Random,
(K|B)),
if K ′ = KHi
if K ′ 6= KHi
where, DK ′ (msg) is a publicly known decryption algo-
rithm.
4.4 Discussions
While we try to use the consistency of voice and skin
conductance to generate the correct key only when it is
the genuine user in the normal emotional state, the incon-
sistency of voice and skin conductance poses challenges,
too. Voice produced and skin conductance measured of
the genuine user in a non-stressed emotional status might
change due to tiredness, illness, noise, and etc.
We used an error correction technique, in particu-
lar, hamming distance, to improve the usability of the
scheme. mCd different keys are derived from any freshly
generated key K ′ obtained from the feature descriptors
and T (similar to the one derived in section 4.3.2), which
are d distance away from the derived key K ′. All of these
mCd keys are then used to decrypt the encrypted keys be-
fore giving any negative answer to the user. If the decryp-
tion succeeds then the key K is released. For example, if
d = 2 and length of the key is m, then mC2 different
keys are derived. Thus, |KHi | ×m C2 decryptions are
performed in attempting to recover K.
Another issue concerns the privacy of the biometric
data used. Ballard et al. propose using randomized bio-
metric templates protected with low-entropy passwords
to provide strong biometric privacy [4]. One can use this
in conjunction with our model to provide both coercion
resistance and biometric privacy. However, it is unclear
whether the use of low-entropy passwords may have a
negative impact on coercion resistance since, intuitively,
an attacker may blame the user for providing the wrong
low-entropy password in a coercion (similar problem dis-
cussed in section 3.2). We leave this as future work to
develop a solution that satisﬁes both requirements.
5 Experimental Setup
We presented our design in generating a cryptographic
key using voice and skin conductance in Section 4. It is
important to test it out with real human beings to evalu-
ate its performance. However, this is difﬁcult as we need
to ﬁnd a way to make the participants feel stressed or
nervous. It is clear that we cannot actually coerce them
to do something by, e.g., putting a gun over their heads.
Nevertheless, we performed case studies to induce stress
on the participants and measure their voice and skin con-
ductance. (IRB approval was obtained from our univer-
sity before the user study.) We present the experimental
setup in this section and the evaluation results and dis-
cussion in the next section.
5.1 Demographics
Since we were going to induce stress on the participants,
we decided to concentrate on the younger generation (un-
dergraduate and graduate students in the age from 18 to
30). We had altogether 43 participants, from which 4
participants detached the sensors from their ﬁngers when
they were nervous during the experiment. Therefore, we
successfully performed our experiments on 39 partici-
pants, out of which 22 were male and 17 were female.
5.2 Experimental settings
Participants were asked to sit in a small ofﬁce where the
overhead ﬂuorescent lights were turned off and a dim red
incandescent lamp was turned on to reduce the possible
electrical interference with the monitoring equipments.
The room was air conditioned to approximately 72◦F and
humidity level was generally dry. This is done in accor-
dance to the variation of skin conductance in different
environmental conditions [36].
Skin conductance sensors1 were attached to the three
middle ﬁngers of the participant to record SC (shown in
Figure 2). The participant was also asked to keep her left
hand (with sensors attached) as still as possible to avoid
interference from the sensors. Fake heart rate tags were
tied to the wrist, which gave an illusion of monitoring the
heart rate.
Initially, there was an incomplete disclosure regarding
the purpose and the steps of the study in order to ensure
that the participant’s responses will not be affected by her
knowledge of the research.
5.3 Procedure
We ran two experiments (e1 and e2). Each experiment
consisted of two parts, where the ﬁrst parts (e1n and e2n)
were conducted when the participants were in a normal
(calm) condition, and the second parts (e1s and e2s) were
conducted when the participants were stressed.
We ran experiment e1n by
• showing nice (geographical) pictures one after an-
other and short phrases (the spoken password em-
bedded) which are related to the pictures, and ask-
ing the participant to read them out;
• showing fake visual heartbeats at a normal rate at
the bottom of the screen and correspondingly play-
ing heartbeats sound.
In order to capture the emotional responses in the
stress scenario in e1s,
• a frightening horror movie was played, replacing
the nice pictures;
• the rate of the heartbeats were gradually increased
to induce more stress on the participant;
• the participant was asked to read out some short
phrases at the end of each horror scene (rather than
along with the video) to avoid distraction.
Similar studies have been performed previously to
measure the stress level in users [26, 19].
In e2, we went a bit further to induce more stress on
the participant. Figure 6 shows the change in skin con-
ductance in response to different events in e2. During e2,
the participant was asked to type a few sentences (e.g.,
“Work is much more fun than fun”) shown to her in a
ﬁxed period of time. She was also warned (prior to the
experiment) not to press the “ALT” key on the keyboard,
as it would cause the computer program to crash and all
data would be lost (event A). We then left the partici-
pant alone in the room to continue typing (event B). We
conﬁgured the computer to restart after 3 minutes irre-
spective of whether the participant actually touched the
“ALT” key or not. The computer would then boot from
a USB drive into MS-DOS and display some error mes-
sages (event C). This completes the ﬁrst part of e2, i.e.,
e2n.
Stress started to develop at this point in time as the