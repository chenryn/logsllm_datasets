(k)
Eθ[Z
i
] = (1 − γk)Eθ[B
] = (1 − γk)Eθ[Y
] = (1 − γk)Eθ[Z
(k−1)
i
(k−1)
(k−1)
i
i
] +γ k
] +γ k
]+
tkD d)i
πi(e
πetkD d ,
tkD0 )idi
(πe
πetkD d ,
(πe
τD )i(e
(tk−τ )D d)idτ
,
(k)
ij ] = (1 − γk)Eθ[N
πetkD d
(k−1)
ij
]+
Eθ[N
γk
tk(cid:2)
0
tk(cid:2)
(tk−τ )D d)j dτ
τD )i(e
0
(πe
γk
(0)
i
πetkD d
], Eθ[Z
] and Eθ[N
(i (cid:5)= j)
(18)
for i, j ∈ S \ {0} and appropriate initial values Eθ[B
(0)
],
i
(0)
ij ]. The integrals can be com-
Eθ[Y
i
puted using uniformization [2], [14]. However, it should be
noted that the numerical computations involved in (18) require
signiﬁcantly more effort than the computations in (9) with
the densities for hyperexponential, hyper-Erlang or APHDs in
canonical form. From the expectations, the parameters of the
new distribution can be computed as follows.
(0)
π(k)
i
D(k)
i,j =
= Eθ[B
Eθ[N
Eθ[Z
(k)
i
(k)
ij ]
(k)
i
i
], d(k)
] , D(k)
(k)
= Eθ[Y
i
(k)
Eθ[Z
i
i,i = −d(k)
i
]
] ,
−(cid:10)
i(cid:4)=j
D(k)
i,j .
(19)
104
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:54:41 UTC from IEEE Xplore.  Restrictions apply. 
i(cid:15)
j=i−δ
i(cid:15)
j=i−δ
V. AN ADAPTIVE ONLINE-ALGORITHM
The online EM-algorithm in [7] assumes independent iden-
(cid:10)∞
(cid:10)∞
tically distributed data. Under some regularity conditions it
is shown that the algorithm converges for 0  δ. Averaging is a
common approach to accelerate the convergence of stochastic
approximation algorithms.
If the online EM-algorithm is applied to a potentially inﬁnite
sequence of observations, then it will converge to a stationary
point and further observations will not modify the parameters
any more because the weights γi converge to 0. This also
means that the algorithm will not or very slowly react on
changes in the observed sample, if they occur late enough.
Another aspect is that a large number of observations might
be necessary to reach the stationary point. In a real setting
one would like to have an approach which computes a ﬁrst
PHD after a moderate number of samples, improves this model
using further observations and detects changes in the observed
sequence quickly by computing a new PHD.
To develop such an algorithm several PHDs have to be
generated and compared online. The ﬁrst PHD is estimated
using the online EM-algorithm on T:i0. The stopping value i0
may be chosen adaptively if the following condition holds for
some small  > 0.
(cid:7)π(i0) − π(i0−1)(cid:7),
(cid:7)D(i0) − D(i0−1)(cid:7)
(cid:7)D(i0−1)(cid:7)
max
 br.
(23)
Convergence of the approach towards a ﬁxed distribution can
only be assured under some regularity conditions [26]. In
particular this implies that all parameters of the distribution
can be identiﬁed which means that
the representation is
unique. This is the case for the canonical representation of
APHDs but not for hyperexponential, Hyper-Erlang or other
mixture distributions. In the latter situation, the algorithm may
in the worst case alternate between different representations of
the same distribution. This has the effect that the distribution is
changed unnecessarily but usually does not affect the quality
of the stochastic model.
) changes in every step,
The direct use of (23) is limited to samples of a moderate
size. Since (π(i), D(i)
the whole
likelihood value has to be recomputed starting with t1. Con-
sequently, the effort of the approach grows quadratically with
the length of the sample. This is too much for larger samples.
For a more efﬁcient approach we deﬁne for i >0
(cid:13)
+ Λi−1 and Λ
0
= 0,
f(π(i)
Λi = log
,D(i))(ti)
(24)
+ Ξi−1. If a new PHD
and Ξi = log
(πcurr, Dcurr) is deﬁned from the current PHD (π(i), D(i)
),
then we set Ξi = Λi.
, D(i)
), (πcurr, Dcurr)
= Λi − Ξi
,Dcurr)(ti)
f(πcurr
(π(i)
(cid:16)
(cid:19)
lrT:i
(25)
(cid:16)
(cid:12)
(cid:19)
is an approximation of lr(.) which can be used in (23). The
approach describes a one-sample update which has shown to
be nearly optimal, i.e. reaches the optimal sample size required
for (23) up to a factor of the order log log(1/α) where α
lr requires
an effort which is only linear in the size of T .
describes the type I-error [27]. The computation of  
The presented approach computes a sequence of PHDs
with an increasing ﬁtting quality measured in terms of the
likelihood. If the distribution of the observed values changes,
then this will only be detected after a long time and it
will take even longer until the computed PHD captures the
new distribution because the online EM-algorithm keeps the
information of past samples which had a larger weight than
current samples due to the decreasing weight function. The
detection of changes in the incoming values is denoted as
change point detection in statistics and quality control. A large
number of different approaches exists in the literature to detect
change points, for overviews see [25], [34], [35].
For our purpose an online algorithm is required which
is usually window based. Formally, we have the following
problem
lcTi−w:i (π0, D0
) = max
1≤k≤w
log(f(π,D)(tj)) − log(f(π0,D0)(tj))
(cid:30)
(cid:30)
i(cid:10)
i(cid:10)
max
(π,D)∈Θ
= arg max
1≤k≤w
j=i−k
max
(π,D)∈Θ
j=i−k
log(f(π,D)(tj)) − log(f(π0,D0)(tj))
(26)
(cid:31)
(cid:31)
∗
k
105
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:54:41 UTC from IEEE Xplore.  Restrictions apply. 
where Θ is the set of PHDs of the respective type and w is
the window size. lcTi−w:i (πcurr, Dcurr) is the measure of the
difference between the best estimate for a sub-sample of length
≤ w and the current estimate for the distribution and k
∗ is an
estimate for the time point when the distribution changes. If
(cid:19)
(cid:16)
, D∗
lcTi−w:i (πcurr, Dcurr) > bc,
(27)
then the estimated PHD changes at i−k
∗ from (πcurr, Dcurr)
to (π∗
) which is the optimal PHD estimated in (26). As
before, the evaluation of (26) requires a huge effort because
for each k ∈ [i − w, i] a new set of parameters has to be
estimated for the PHD and the corresponding likelihood value
has to be computed. In our case this means to evaluate several
iterations of the EM algorithm on Ti−k:i. Thus, we propose
an approximation approach similar to one presented above
to approximate lrT:i (.) which is based on the change point
detection approach from [27].
Let Ξi:k = Ξi − Ξk for i > kand 0 else. Then deﬁne
(ˆπi, ˆDi
) as a sequence of PHDs that are computed using
the online EM algorithm with constant weights γ. The use
of constant weights is recommended in [20] for time varying
data and enables the EM algorithm to detect changes in the
data. Then deﬁne the one sample update as
+ Ψi−1 and Ψ
0
(28)
Ψi = log
(cid:12)
= 0.
f(ˆπ(i), ˆD(i))(ti)
(cid:13)
With Ψi:k = Ψi − Ψk for i > k and 0 else, we can deﬁne
(cid:13)
lcTi−w:i(πcurr, Dcurr) = max
,
1≤k≤w
Ψi:i−k − Ξi:i−k
∗
The use of  
ˆk
(29)
lcTi−w:i () instead of lcTi−w:i () in (27) results in
an efﬁcient algorithm with a linear effort in the length of the
sample.
(cid:12)
Ψi:i−k − Ξi:i−k
= arg max
1≤k≤w
.
Algorithm 1 summarizes the whole adaptive online algo-
rithm for PHDs. In the online EM-update steps the E- and
M-step are performed for one of the PHD types presented in
the previous section. The algorithm requires some parameters.
First,
it has to be started with some initial guess of the
PHD parameters resulting from available information of the
observed process or available data. Usually one uses pre-
sampling with the online EM-algorithm until (21) holds or
a PHD is determined from several iterations of an ofﬂine
EM-algorithm for APHDs [2], [13], [14] using data sampled
before the online algorithm starts. Whenever a change point is
detected by the algorithm, the log-likelihood values are reset
and weights are initialized again. The variable ˆi stores the
index when the change point has been detected. The estimated
change point is then ˆi − ˆk
∗. For the weights γi of the online
EM-algorithm we use γ0 = 1 and α ∈ (0.5, 1) which assures
convergence for identically and independently distributed data.
For the ﬁxed weight γ we choose values between 0.01 and
0.1 as for the online algorithm in [20]. Crucial is the choice
of the thresholds bc and br. Even with the exact values for
lrT:i (.) and lcTi−w:i (.) the distribution of the test statistics
of the likelihood ratio, which is the basis for our decisions,
0
, ˆD
) = (ˆπ0
function ONLINE PHD(initial guess (πcurr, Dcurr))
) = (πcurr, Dcurr) ;
initialize (π0, D0
initialize Λ0 = Ξ0 = Ψ0 = 0, ˆi = 0 ;
for i = 1, 2, . . . do
grep new value ti ;
γi = γ0(i − ˆi)
−α ;
online EM-update to compute (πi, Di) with γi;
online EM-update to compute (ˆπi, ˆDi
) with γ;
update Λi, Ξi, Ψi ;
if i ≥ w and  
lcTi−w:i (πcurr, Dcurr) > bc then
) ;
(πcurr, Dcurr) = (ˆπi, ˆDi
(πi, Di) = (ˆπi, ˆDi
Λi = Ξi = Ψi = 0 ;
update change point at i − ˆk
ˆi = i ;
) ;
∗ ;
else
if  
lrT:i ((πi, Di), (πcurr, Dcurr) > br then
(πcurr, Dcurr) = (πi, Di) ;
Λi = Ξi ;
update new estimate at i ;
end if
end if
end for
end function
Fig. 1: Adaptive Online EM-Algorithm for PHDs
lrT:i (.) and  
one-sample approximations  
is unknown for most distributions. Since we work with the
lcTi−w:i(.), we cannot
expect to ﬁnd the exact relation between the threshold and
the type I-error, i.e., the error to choose (πi, Di) or (ˆπi, ˆDi
)
if the data is drawn from (πcurr, Dcurr). [24] suggests for
the likelihood ratio values between 20 and 100 which means
for the log-likelihood, that we use, threshold values between
log(20) and log(100) are appropriate. The value for bc should
be signiﬁcantly larger than br because otherwise the change
point detection becomes too sensitive. However, an optimal
choice of the parameters is application dependent and cannot
be done without knowing the application and the data.
VI. EXPERIMENTAL RESULTS
To evaluate the online EM algorithm experimentally, we
apply the algorithm to generate PHDs for different traces.
In particular, we use three synthetical traces that have been
generated from PHDs and provide different challenges for the
ﬁtting algorithms, i.e. no change points, change points due to
a varying mean and change points due to a varying variance.
Additionally, we test our algorithms with real-world data from
the failure trace archive (FTA) [36], [37].
The general experiment setup is identical for all traces.
We apply the online EM algorithm from Fig. 1 to ﬁt a
hyperexponential, a hyper-Erlang, an acyclic PHD in canonical
form and an acyclic PHD as described in Sects. IV-B - IV-E
to the traces. For comparison we also use classical ofﬂine EM
approaches with the same subclasses of PHDs. The steps for
acyclic PHDs are given in Sect. III, while the approach from
[13] is used for ofﬂine hyper-Erlang and hyperexponential
parameter estimation. Note, that we also restrict the algorithms
described in Sects. III and IV-E to acyclic PHDs for our
106
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:54:41 UTC from IEEE Xplore.  Restrictions apply. 
experiments even though they could work with arbitrary PHDs.
This is commonly done for PHD ﬁtting, since it has little effect
on the ﬁtting quality but signiﬁcantly reduces the complexity
of the optimization problem.
A. Synthetical Trace Without Change Points
The ﬁrst synthetical trace is generated from a APHD in
canonical form with π = (0.2, 0.3, 0.4, 0.1) and λ1 = 1, λ2 =
4, λ3 = 8, λ4 = 15. It contains k = 100000 elements and
has no change points. As mentioned above, we estimate the
parameters of seven different PHDs according to the trace.
The hyperexponential, hyper-Erlang and APHD resulting from
ofﬂine EM algorithms are denoted as HExp ofﬂine EM, HErD
ofﬂine EM and APHD ofﬂine EM, respectively, in the follow-
ing. Similarly, we use HExp online EM and HErD online EM
for hyperexponential and, hyper-Erlang distributions from the
algorithms described in Sects. IV-B and IV-C. To distinguish
the two APHDs resulting from the online approach described