title:Symbolic Execution of Obfuscated Code
author:Babak Yadegari and
Saumya Debray
Symbolic Execution of Obfuscated Code
Babak Yadegari, Saumya Debray
Department of Computer Science
University of Arizona
Tucson, AZ 85721
{babaky, debray}@cs.arizona.edu
ABSTRACT
Symbolic and concolic execution ﬁnd important applications
in a number of security-related program analyses, including
analysis of malicious code. However, malicious code tend to
very often be obfuscated, and current concolic analysis tech-
niques have trouble dealing with some of these obfuscations,
leading to imprecision and/or excessive resource usage. This
paper discusses three such obfuscations: two of these are al-
ready found in obfuscation tools used by malware, while the
third is a simple variation on an existing obfuscation tech-
nique. We show empirically that existing symbolic analyses
are not robust against such obfuscations, and propose ways
in which the problems can be mitigated using a combination
of ﬁne-grained bit-level taint analysis and architecture-aware
constraint generations. Experimental results indicate that
our approach is eﬀective in allowing symbolic and concolic
execution to handle such obfuscations.
Categories and Subject Descriptors
D.2.4 [Software Engineering]: [Software/Program Veriﬁ-
cation]
Keywords
Symbolic Execution; Obfuscation; Reverse Engineering; Taint
Analysis
1.
INTRODUCTION
Symbolic and concolic execution play important roles in
a variety of security and software testing applications, e.g.,
test case and exploit generation [4, 5, 9, 17, 34], vulnerability
detection [5, 6, 10], and code coverage improvement in dy-
namic analysis of malware code [2, 3, 26]. The general idea
behind symbolic/concolic execution is to represent computa-
tions along a particular execution path using logical formu-
las and apply constraint solving techniques to identify inputs
that would cause the program to take alternative execution
paths. Analyses based on symbolic execution are especially
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813663.
important for dealing with programs that are diﬃcult to an-
alyze using conventional techniques. This makes the preci-
sion of such analyses an important consideration in security
applications: on the one hand, identifying too many candi-
date execution paths, with corresponding inputs, can over-
whelm the analysis and slow down processing; on the other
hand, missing some execution paths can cause the analysis
to fail to explore important parts of the input program.
Given the importance of symbolic analysis for code cov-
erage improvement in dynamic analysis of potentially mali-
cious code, it is important to identify and understand any
potential weaknesses of this approach. Previous studies have
discussed attacks on symbolic execution systems using cryp-
tographic hash functions [36] or unsolved mathematical con-
jectures [43] to construct computations that are diﬃcult to
invert. These are sophisticated attacks and help deﬁne the-
oretical boundaries for symbolic analyses, however they do
not speak to potential problems in symbolic analysis arising
out of code obfuscation techniques used by existing malware.
It turns out that several existing code obfuscation tech-
niques used by malware (or simple variations on them) can
signiﬁcantly aﬀect the precision of current concolic analyses.
For example, some obfuscations, such as those used in the
software protection tool EXECryptor [38], can cause large
amounts of overtainting and lead to a path explosion in the
symbolic analysis; others, such as those used by the obfus-
cation tool VMProtect [41], transform conditional branch
instructions into indirect jumps that symbolic analyses ﬁnd
diﬃcult to analyze; and ﬁnally, a form of runtime code self-
modiﬁcation, variations of which we have seen in existing
malware, can conceal conditional jumps on symbolic values
such that they are not detected by concolic analysis. This
situation is problematic because a signiﬁcant motivation be-
hind using symbolic/concolic execution in malware analysis
is to get around code obfuscations. This makes it especially
important to devise ways to mitigate such loss of precision
when performing symbolic analysis of obfuscated code. This
paper takes a ﬁrst step in this direction.
This paper makes two contributions. First, it identiﬁes
shortcomings in existing concolic analysis algorithms by de-
scribing three diﬀerent anti-analysis obfuscations that cause
problems for symbolic execution. These obfuscations were
selected because (1) they, or simple variants of them, are
currently already used in malware, e.g., through tools like
VMProtect and EXECryptor; and (2) the problems they
cause for symbolic execution are not discussed in the re-
search literature. Second, we describe a general approach,
based on a combination of ﬁne-grained taint analysis and
732architecture-aware constraint generation, that can be used
to mitigate the eﬀects of these obfuscations. For the sake of
concreteness, the discussion is in many places formulated in
terms of the widely used x86 architecture; however, the con-
cepts are general and apply to other architectures as well.
Our experiments indicate that the approach we describe can
signiﬁcantly improve the results of symbolic execution on
obfuscated programs.
The rest of the paper is organized as follows: Section 2
discusses background on concolic execution and introduces
problems that arise in concolic analysis of obfuscated code.
Section 3 discusses these challenges in greater detail. Section
4 describes our approach for dealing with these challenges.
Section 5 presents experimental results from evaluation of a
prototype implementation of our approach. Section 6 dis-
cusses related work, and Section 7 concludes.
2. BACKGROUND
2.1 Concolic Execution and Input Generation
Concolic (concrete+symbolic) execution uses a combina-
tion of concrete and symbolic execution to analyze how input
values ﬂow through a program as it executes, and uses this
analysis to identify other inputs that can result in alterna-
tive execution behaviors [17, 34]. The process begins with
certain variables/locations—typically, those associated with
(possibly a subset of) the program’s inputs—being marked
as “symbolic.” The instructions of the program are then
processed as follows: if any of the operands of the instruc-
tion are marked symbolic, then the instruction is “executed”
symbolically:
the output operands of the instruction are
marked as symbolic, and the relationship between the in-
put and output operands of the instruction is represented
as a constraint between the corresponding symbolic vari-
ables; otherwise, the instruction is executed normally and
the program’s state is updated. If a location or variable x
becomes marked as symbolic, we say that x “becomes sym-
bolic.” The constraints collected along an execution path
characterize the computation along that path in terms of
the original symbolic variables, and can be used to reason
about what inputs to the program can cause which branches
in the program to be taken or not. Symbolic analysis can
identify input classes to the program if there are control
transfers in the program aﬀected by the input values [22] by
which program takes diﬀerent execution paths.
2.2 Concolic Execution of Obfuscated Code
Figure 1 shows the problem with concolic analysis of ob-
fuscated code. Our test program, shown in Figure 1(a),
consists essentially of a single symbolic variable and two if
statements, nested one inside the other, that give rise to a to-
tal of three distinct execution paths. Our goal is to use con-
colic execution to identify diﬀerent inputs that will, between
them, cover all three execution paths. Symbolic execution of
this simple program is almost trivial: the concolic execution
engine S2E [10] ﬁnds just two states and makes just seven
queries, and the analysis takes less than 20 seconds over-
all. If we run this simple program through the obfuscation
tool VMProtect [41], however, the results are dramatically
diﬀerent: a depth-ﬁrst search strategy times out after more
than 12 hours, having encountered close to 15,000 states and
generated over 14,000 queries, but failing to generate any al-
ternative inputs. A random search strategy does somewhat
int main(int argc, char **argv){
int n = atoi(argv[1]); /* n is symbolic */
int retVal;
int r = n+6;
if(r  12 hrs)
Random
original
2
7
17
obfuscated
25,800
25,094
14,160
(b) Analysis statistics (S2E)
Figure 1: Eﬀects of code obfuscation on concolic
analysis performance (Obfuscator: VMProtect [41];
concolic engine: S2E [10])
better in that it does not time out, but it takes nearly 800
times as long to generate alternative inputs compared to
the unobfuscated version. This strategy encounters 25,800
states and generates more than 25,000 queries—an increase
of four orders of magnitude. That such a trivial program
should pose such a formidable challenge to symbolic execu-
tion when it has been obfuscated is sobering in its implica-
tions for more complex code: VMProtect and other similar
obfuscators have been used for protecting malware against
analysis for a decade or more (e.g., the Ilomo/Clampi bot-
net, which used VMProtect to protect its executables, was
encountered in 2005 [14]). The problem is not speciﬁc to
S2E: for example, when invoked on the obfuscated version
of the program shown above, Vine [37] exits with an error
message. The remainder of this paper examines the reasons
underlying the problems described above and some possible
ways by which the problems may be mitigated or remedied.
3. ANTI-CONCOLIC OBFUSCATIONS
While there has been a great deal of work on constructing
and defeating diﬀerent kinds of obfuscations, for the pur-
poses of this paper we are concerned primarily with obfus-
cations that aﬀect concolic analysis, focusing in particular
on concolic analysis to improve code coverage in obfuscated
and malicious code.1 Such analyses use constraints on exe-
1The obfuscation tools we used to evaluate our techniques,
discussed in Section 5, incorporate many additional obfus-
cations, but in our experience these other obfuscations did
not have much of an eﬀect on symbolic execution.
733Flag
Bit position
NT
14
IOPL
13-12
15
OF
11
DF
10
IF
9
TF
8
Overﬂow
Sign
SF
7
Zero
ZF
6
Parity
Carry
AF
4
3
5
PF
2
CF
0
1
Figure 2: x86 FLAGS register [20]
cution paths leading up to conditional jumps to determine
alternative inputs that can cause a diﬀerent execution path
to be taken. There are basically two broad ways in which
this approach can be attacked:
1. The conditional jump can be manipulated in ways that
make it diﬃcult to identify a relationship with the orig-
inal inputs:
(a) The conditional jump can be transformed into an
indirect jump whose target depends on the pred-
icate of the original conditional jump.
(b) The conditional jump can be transformed into
a diﬀerent conditional jump whose predicate de-
pends on, but is diﬀerent from, that of the original
conditional jump.
2. The conditional jump, or its relationship with the in-
put, can be concealed:
(a) The conditional jump can be injected into the in-
struction stream at runtime, in the form of a di-
rect unconditional jump, using conditional code
modiﬁcation (“symbolic code”).
(b) Implicit information ﬂows can be used to conceal
a conditional jump’s dependence on inputs.
Of the possibilities listed above, this paper focuses on ap-
proaches 1(a), 1(b), and 2(a). The use of implicit ﬂows
(item 2(b) above) has been discussed elsewhere by Caval-
laro et al. [8]. Sharif et al. discuss using cryptographic hash
functions to realize an extreme form of approach 2(b) [36];
the discussion here considers simpler (and stealthier) forms
of this approach that can nevertheless pose problems for
concolic analysis. We have observed these obfuscations, or
simple variants of them, in existing malware.
3.1 Conditional Jump to Indirect Jump
Transformation
In the x86 architecture, conditional logic of the form
if e then S
is usually realized as follows: ﬁrst, the expression e is eval-
uated and the condition code ﬂags set; then, depending on
the predicate involved in e, the appropriate combination of
ﬂags is used in a conditional branch instruction:
FLAGS := evaluate e
jcc AS
where cc represents the particular combination of ﬂags cor-
responding to the predicate in e, and AS is the address of
the code for S. The architecture of FLAGS register on x86
processors is shown in Figure 2. However, this same eﬀect
can be realized by using the condition code ﬂags resulting
from the evaluation of e to compute the target address:
FLAGS := evaluate e
r := f (FLAGS)
jmp r
/* compute target address */
In this case, the function f uses the condition code ﬂag val-
ues to compute the target address; in particular, when the
ﬂag values indicate that the predicate e is true, the address
computed by f (FLAGS) is AS. A key diﬀerence between these
two approaches is that in the ﬁrst case, the use of a con-
ditional branch instruction makes explicit the two possible
control ﬂow targets that are possible. This is not the case,
however, for the indirect jump in the second case. As a
result, the indirect jump is harder to analyze symbolically
than the ﬁrst: Schwartz et al. refer to this as the symbolic
jump problem [33].
Obfuscators sometimes exploit this situation by trans-
forming conditional branches to indirect jumps. This is il-
lusrated by the following example.
Example 3.1. Consider the following code fragment:
/* x86: test */
/* x86: pushf */
1
2
3
4
5
6
7
8
r0 := input();
FLAGS := test(r0)
push(FLAGS)
r1 := pop()
r2 := and r1, 0x40
r3 := 0x500000
r4 := or r3, r2
jmp r4
Instructions 2–4 above check the input value and move the
condition code ﬂags into register r1. After some bit manip-
ulation (instruction 5), it is bitwise or’d with the value in
register r3 (instruction 7). The resulting value is then used
as the target of an indirect jump (instruction 8).
What is actually going on here is that instruction 5 ex-
tracts the bit corresponding to the Zero Flag (ZF), in bit
position 6, from r1 into r2. The result of the bitwise or
operation (instruction 7) is therefore either 0x500040 (if ZF
had the value 1 after instruction 2) or 500000 (if ZF was 0).
The indirect jump at instruction 8 is therefore really a con-
ditional jump to one of these two addresses depending on
the value of ZF from instruction 2.
While this example is couched in terms of the widely-used
x86 architecture, the ideas are not x86-speciﬁc: e.g., the
ARM architecture allows similar direct manipulation of con-
dition code bits with its MSR/MRS instructions. Such obfusca-
tions are particularly an issue with virtualization-based ob-
fuscation, where the program being obfuscated is translated
into a byte-code like representation of the instruction set of a
custom virtual machine (VM) and interpreted using a cus-
tom interpreter for that VM. Several commercial software
protection tools are based on this approach [30, 31, 38, 41];
these tools are also used sometimes to protect malware code
[16, 39]. While the details of the interpreters diﬀer from
one obfuscation tool to another, their high-level structure is
typically that of a conventional fetch-dispatch-execute loop.
The VM has its own virtual instruction pointer (VIP), which
it uses to access the byte-code instructions it interprets. The
VIP is initialized to the program’s entry point in the byte-
code, and its subsequent values are controlled by the logic
of the byte-code program as it executes.
734There are several diﬀerent ways in which such an inter-
preter can implement conditional statements in the input
program, which all amount to setting the VIP to one of two
alternatives depending on the value of some predicate. VM-
Protect [41] uses arithmetic on the condition code ﬂags to
determine the address of the appropriate VIP value. Since
the ﬂags are in general symbolic, this causes the interpreter’s
VIP to become symbolic as well.
Symbolic execution of virtualized programs becomes chal-
lenging if the interpreter’s VIP becomes symbolic. The prob-
lem is that the constraint solving process used to identify
such inputs has no way of distinguishing between alterna-
tive execution paths arising due to the interpreter running
on a diﬀerent byte code program, and those arising from a
diﬀerent input to the original byte code program. In eﬀect,
symbolic execution turns the interpreter into a generator of
inputs it can interpret or accept [5], except that in this case
the byte-code is not dependent on the input and so is not
itself symbolic—it suﬃces to make the VIP symbolic.
If
the VIP becomes symbolic, the number of possible alterna-
tives for the symbolic execution engine to consider at the