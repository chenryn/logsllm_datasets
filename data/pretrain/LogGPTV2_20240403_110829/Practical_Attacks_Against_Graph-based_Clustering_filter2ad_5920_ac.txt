In addition to being eective, the attacks do not substantially
raise the anomaly prole of infected hosts: before and after the tar-
geted noise injection attacks the hosts occupy a similar percentile
for the number of NXDOMAINs queried. Small community attack
results show that the traditional way of choosing hyperparameters
for generating graph embeddings is insucient when we analyze
the system in an adversarial setting, because it creates a large area
for possible small community attack instances. While following the
accepted methodology for selecting the rank for SVD and hyper-
parameters for node2vec, all DGA clusters can be hidden in noisy
clusters by subdividing the infected hosts into smaller groups to
sacrice some agility, even while using hundreds of DGA domains.
Even in the minimal knowledge case where the small community
attack cannot be tested, attackers can sometimes still hide.
5.1 Choosing Hyperparamters
First, we carefully choose hyperparameters for the graph clustering
methods in Pleiades to ensure high quality clusters are generated.
Figure 11 shows the results used to determine the appropriate
hyperparameters.
5.1.1
Spectral Clustering. We use the scree plot shown in Fig-
ure 4 to choose the rank of SVD. We x the rank of the SVD to be
35, where the scree plot plateaus. While dierent than the 15 used
in the original Pleiades implementation [9], the underlying datasets
are dierent so it is not unreasonable to nd dierent ranks.
Session E4:  Adversarial Social NetworkingCCS’17, October 30-November 3, 2017, Dallas, TX, USA11311.00
0.75
l
e
u
a
V
0.50
0.25
●
●
●
●
20
40
●
●
●
●
●
●
●
●
●
●
80
60
Walk Length
100 120
150
●
●
●
●
●
2
● Adjusted Rand Index
Completeness
Fowlkes−Mallows Index
Homogeneity
NMI
V−Meausure
Figure 5: Using cluster validity metrics to choose walk
length.
5.1.2 Community Discovery. We use the best partition method
from the NetworkX community discovery library [61] which im-
plements the Louvain algorithm [14]. The Louvain algorithm ef-
ciently extracts good communities on the graph by optimizing
the modularity metric, which measures the density of links within
communities in comparison to outside them. It rst sets each node
to be its own community, and iteratively merges them to maximize
modularity. The algorithm stops when a local maxima is reached.
This community detection algorithm scales to large network with
hundreds of millions of nodes.
5.1.3 node2vec. We use traditional cluster validity metrics to
compare dierent hyperparameters of node2vec. Twelve DGA mal-
ware families, including both known and newly detected ones, were
used as reference clusters. We use validity metrics including Adjusted
Rand Index, Completeness, Fowlkes-Mallows index, Homogene-
ity, Normalized Mutual Information (NMI), purity, and V-Measure
score. We rst choose context size six, which has the rst highest
validity scores. Several larger context sizes generate equal validity
scores, but they produce noisier clusters. This is because that larger
context sizes in DNS graphs tend to include more noisy nodes, such
as popular benign NXDOMAINs, or popular hosts that are likely
proxies.
Then we choose the walk length according to Figure 5. Multiple
walk length values produce high validity scores, but we choose
walk length 20, which corresponds to the second highest peak.
Because using walk length 20 generates cleaner Murofet clusters
than a walk length smaller than 10, due to the fact that longer walk
length provides more samples of neighborhoods and the model is
learned better. The number of walks per node, dimensions, and
SGD epoch does not show much dierence. We decide on 15 walks,
60 dimensions, and one learning epoch after manual inspection.
Lastly, we use a uniform random probability to choose the next
node in the random walk process.
5.2 Targeted Noise Injection
We run our version of Pleiades to generate all attacker graphs.
Four DGA families were identied: Pykspa, Suppobox, Murofet,
and Gimemo. For each we extract the attacker graphs (G) and the
target domains (V ). These domains are labeled using the classier
from Section 4.1.1. Before and after the attack, there can be multiple
clusters formed within G and G0, depending on the graph clustering
technique. We use the classier model to test how likely it is that
each cluster belongs to the true DGA malware family, both before
and after the attack. We present the overall distribution of the
predicted class probabilities to show the impact of the attacks.
We use dierent types of noisy domains at dierent knowledge
levels. For a DGA, these nodes are new NXDOMAINs (V 0) that
will be classied as benign, also queried by the infected hosts (U ).
In the minimal knowledge case, we create a DGA algorithm that
is classied as benign. It is a dictionary DGA that uses the most
popular English words from movie subtitles [23], popular web terms,
and the top one million Alexa domains. We randomly add numbers
and dashes, and randomly select a top-level domain from four
choices. In addition, we generate some punycode domains that
start with the character sequence “xn–”, and some domains with
a “www” subdomain. We generate 59,730 veried NXDOMAINs.
In the perfect and moderate knowledge cases, the adversary uses
existing, unpopular NXDOMAINs from G and the surrogate dataset,
respectively.
5.2.1
Spectral Clustering. Figure 6a shows the classier’s pre-
dicted true class probabilities from before the attack is mounted,
and after the minimal, moderate, and perfect knowledge targeted
noise injection attacks are performed. For each knowledge level,
we inject two dierent levels of noise as described in Section 5.2
and re-run the clustering and subsequent classication to assess
the damage from the targeted noise injection. Recall that we try
two attack variants, attack variant 1 and 2, where we inject one
or two mirrored sets of vertices and edges, respectively. This is to
both i) understand how much noise is needed to yield successful
evasion, and ii) determine the cost incurred by adding noise.
Spectral clustering generates 267 DGA clusters from the four mal-
ware families across 12 days. Before the attack, only 0.4% clusters
(1 out of 267) are predicted with the wrong labels. In comparison,
after the attacks, all clusters are predicted with the wrong labels.
Next, we will examine the predicted class probabilities change in
the true class label.
Figure 6a uses the violin plots to show the distribution of pre-
dicted class probabilities for the true DGA families, before and after
the attacks. The circle is the median value, the thick line within
the violin indicates interquartile range, and the thin line depicts
a 95% condence interval. The shape of the violin shows the dis-
tribution of the probability values. For example, the rst violin in
Figure 6a has a median of 100% predicted class probabilities, and all
data points in the interquartile range have 100% probability value.
Specically, before the attacks, 238 clusters are predicted with 100%
class probability that they belong to the true class, and only 28
clusters have a probability between 60% and 100%. For example,
the Pykspa cluster had a class probability of only 10% because it
contained only two domain names that had very dierent feature
distributions from the majority of Pykspa clusters. The two variants
Session E4:  Adversarial Social NetworkingCCS’17, October 30-November 3, 2017, Dallas, TX, USA1132of the attack introduced at least 50% and 66% noise to the DGA
clusters.
Minimal Knowledge. After the attacks, we classify each new
adversarial cluster containing target domains and plot the target
class probability distributions in the Figure 6a. Attack variant 1
(“Minimal Benign DGA 1”) generated new clusters with  80%
predicted class probability, with a median of 0%. The predicted
class probabilities of 84% of the new clusters drop to zero. Attack
variant 2 further decreases the classier prediction condence, as
shown by “Minimal Benign DGA 2” in Figure 6a. After injecting two
benign DGA domains, the predicted class probabilities of 87% of the
new clusters plummet to 0%. The overall distribution of prediction
condences also shifts downward compared to “Minimal Benign
DGA 1”.
Perfect Knowledge. The median of predicted class probabilities for
DGA malware families drops to 10%. As depicted by “Perfect Long
Tail 1” in Figure 6a, 86% of adversarial clusters were assigned the
probabilities of belonging to the true DGA class that are at most 10%
. The distribution of class probability values has a smaller variance
compared to those in the “Minimal Benign DGA 1”. “Perfect Long
Tail 2” in Figure 6a shows that the maximum prediction condence
is 30%, slightly lower than the maximum 40% condence from the
targeted noise injection attack of “Minimal Benign DGA 2”.
Moderate Knowledge. We see similar results for the two targeted
noise injection attack variants in the moderate knowledge case as in
the other cases: a strong drop in predicted class probabilities, with
a smaller, more compact distribution of values for attack variant
2. After attack variant 1, 98.3% of new clusters were assigned less
than 20% condence; after attack variant 2, 98.8% of new clusters
have less than 20% condence.
Spectral clustering can be largely defeated at all knowledge levels
using the targeted noise injection attacks.
Since previous experiments show that minimal knowledge at-
tackers can carry out targeted noise injection as eectively as more
powerful attackers, we will simply demonstrate that the same tar-
geted noise injection attack variant 1 in minimal knowledge also
works with community discovery and node2vec.
5.2.2 Community Discovery. We use the same set of DGA do-
mains labeled in Spectral Clustering for evaluation. Before the
attack, 80% clusters can be predicted with the correct label, which
dropped to 2% after the attack. Figure 6b shows the predicted class
probabilities for communities containing all target domains before
and after the attack. Before the attack, the median of predicted
probabilities is 90%, and the interquartile range is from 50% to 100%.
Specically, 71 communities contain target domains, among which
ten communities only contain one target domain, and seven commu-
nities have between 40% to 70% target domains. These noisy com-
munities formed the lower part of the distribution, with  50% pre-
dicted class probabilities in “Community Before Attack”, as shown
in Figure 6b. After the attack, the median class probability craters
to 0%. Overall 98% of new communities were predicted with lower
than 50% probability of belonging to the true class, and 86% of
communities have lower than 10% class probabilities.
This demonstrates that the targeted noise injection attack is also
eective against the community discovery algorithm.
Before Attack
Average Increase
Attack Variant 1
Attack Variant 2
Before Attack
Average Increase
Attack Variant 1
Attack Variant 2
= 95th Percentile, 90.88% of hosts
To Percentile
From Percentile
99.85%
99.74%
99.74%
99.88%
Table 2: Anomaly cost as percentile of the distinct number of
NXDOMAINs queried by hosts, before and after the attack.
Only 9.12% of infected hosts become more suspicious, while
the rest remain the same.
5.2.3
node2vec. Using the same set of DGA domains labeled in
Spectral Clustering, before the attack, 89% clusters can be predicted
with the correct label, which dropped to 0.8% after the attack. Fig-
ure 6b shows that, before the attack on node2vec, the median of
predicted probabilities is 100%, and the interquartile range is from
90% to 100%. A total of 85% of clusters were predicted with at least
70% class probability. After the attack, 92% clusters have at most
10% predicted class probabilities.
Targeted noise injection attack also evades node2vec embeddings.
5.2.4 Targeted Noise Injection Costs. It is simple for malware to
query additional domains, however, infected hosts engaging in such
queries may become more suspicious and easier to detect due to
the extra network signal they produce. This may cause the anomaly
cost of the targeted noise injection attack to be high enough to
render it useless.
We analyze the anomaly cost by measuring the infected host
percentile of the NXDOMAIN distribution both before and after the
attacks for the two variants of the targeted noise injection attacks,
summarized in Table 2. Before any attack, only 9.12% of infected
hosts ranked lower than 95th percentile, and the remaining 90.88%
of them ranked higher than 95th percentile. This means that, with-
out any attack, infected hosts were already querying more unique
NXDOMAINs than most hosts in the network. However, doing tar-
geted noise injection attacks further increases the percentile ranks
of the infected hosts, but not substantially.
We separated the results based on whether infected hosts were
querying fewer domains than 95% of all hosts in the local network.
Table 2 shows that among the 9.12% infected hosts ranked lower
than 95th percentile before the attack, they increased from an aver-
age percentile of 69.86% to 88.73% after the targeted noise injection
attack variant 1. Furthermore, they increased to 93.98% after attack
variant 2. However, 90.88% of infected hosts did not become more
anomalous. They were ranked higher than the 95th percentile be-
fore the attack. Their average percentile increased by 0.11% after
attack variant 1, and by 0.14% after attack variant 2. Because they
were querying more domains than other hosts before the attack,
injecting noise does not change their percentile substantially.
The majority of hosts had little change in “suspiciousness”, whereas
a small percentage of hosts increased their suspiciousness after the
targeted noise injection attacks.
Session E4:  Adversarial Social NetworkingCCS’17, October 30-November 3, 2017, Dallas, TX, USA1133●
●
●
●
●
●
●
8
.
0
4
.
0
y
t
i
l
i
l
b
a
b
o
r
P
s
s
a
C
d
e
t
c
d
e
r
P
i
0
.
0
●
●
●
n   D G A   2
n   D G A   1
k
a t e   1
c
e   A tt a
n i g
r
e
a l:  M i n i m a l  B e
a l:  M i n i m a l  B e
r
a l:  M o
a l:  M o
c t r
c t r
e
c t r
S p
S p
c t r
e
S p
e
S p
n i g
d
e
a l:  B e f o
c t r
c t r
e
S p
e
S p
●
●
●
a t e   2
n
o
r
e
c t  L
d
r f e
a l:  P e
a l:  P e
c t r
e
S p
g   T a il  1
c t  L
r f e
n
o
g   T a il  2
(a) Spectral Clustering: Predicted class probabilities.
8
.
0
4
.
0
y
t
i
l
i
l
b
a
b
o