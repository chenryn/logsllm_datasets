t
i
l
i
b
a
b
o
r
P
8
6
4
2
0
base load
using top−k
using scan
0.1
0.2
0.3
0.4
CPU utilization
0.5
0.6
SumStat
a: Addr. Scan
b: Apps
c: SQLi Attackers
d: SQLi Victims
e: SSH badclient BF
f: SSH Bruteforce
g: Mime metrics
h: Port Scan
i: Traceroute
1e+07
h
i
s
e
t
u
n
m
5
1
r
e
p
s
e
g
a
s
s
e
M
1e+05
1e+03
a
i
g
f
d
c
b
e
12:00
18:00
00:00
06:00
12:00
Fig. 6. Single node CPU load comparison
Fig. 7. Exchanged messages per sumstat
Figure 6 shows a corresponding probability density for the three conﬁgura-
tions.7 We see that while using the summary statistics framework imposes over-
head, it remains small for scan detection (0.4 percentage points more). The
diﬀerence with the top-k script (1.6 percentage points more) is more noticeable
due to the increased cost per observation that the more expensive maintenance
of the probabilistic data structure entails. In either case, we deem the overhead
low, relative to the input volume.
5.3 Memory Overhead
We next analyze the memory overhead introduced by the summary statistics
framework. For this we follow the same approach as for CPU, measuring memory
usage while running Bro repeatedly on the same input trace with the same
three conﬁgurations. In all cases, we ﬁnd the memory overhead imposed by the
summary statistics framework reasonable. Even there the mean overhead is only
about 6.7% (max. 179MB) in comparison to the baseline of a standard Bro setup.
5.4 Communication Overhead
Finally, we examine the communication overhead the summary statistics frame-
work incurs in cluster operation. We add a script to the Bro manager node that logs
all incoming and outgoing messages triggered by the summary statistics frame-
work. For each message we output its timestamp and further meta-information
for identifying its origin (e.g., the name of the reducer and the exact type of the
message). We ran this measurement live for 24 hours on a 57-node Bro cluster of a
7 The measurement was done in a single-system Bro setup. However, we repeated it
in cluster setup with a separate manager process, with similar results.
●
●
●
●
Count Me In: Viable Distributed Summary Statistics
337
medium-sized research organization that we have access to. The cluster monitors
uplink traﬃc averaging at about 1 Gb/s during day-time hours. The setup used the
full set of standard summary statistic scripts that come with a standard Bro in-
stallation, including detecting scans, traceroutes, SQL injection attacks, and SSH
bruteforcing; as well as using two custom scripts to measure MIME statistics and
traﬃc volume to several large sites (Google, Facebook, etc.).
Figure 7 shows a breakdown of the diﬀerent summary statistics and the mes-
sage overhead each caused. We ﬁnd the scan detector responsible for most of
the exchanged messages, due to the large number of incoming connections that
it needs to classify. In total, the nodes exchanged 1,930,564,662 messages, with
about half of them going from the manager to the worker nodes. This is due to
the manager always initiating the exchange of values (i.e., even after a worker’s
notiﬁcation, it is the manager that then polls for updates). This means that
each node sends about 399.03 messages per second each way. Messages relat-
ing to the intermediary updates constitute 0.40% of the overall communication.
69,810 times a worker node notiﬁes the manager that it should request updates.
In 27,704, or 39.68%, of these cases, the manager chooses to ignore that re-
quest (an optimization that our implementation applies to limit simultaneously
outstanding key updates for the case where a set of keys triggers many notiﬁca-
tions in short succession; by default, the framework limits the number of simul-
taneously running updates to 10 per summary statistic). In 15.98% of the cases
that the request is accepted by the manager, the target threshold has indeed
been crossed, and hence the manager alarms after aggregating the individual
values.
Overall, we deem the level of communication realistic for such large-scale,
high-volume settings; and clearly within what Bro’s communication system is
able to handle [23]. This conclusion is supported by the Indiana University setup,
which is running the scan detector in operations (§4.1). We note that scan de-
tection represents pretty much the worst case for a distributed monitoring setup
as one needs to continuously correlate activity about many addresses across all
nodes in a timely manner. While we have not yet performed a more system-
atic sensitivity analysis, we expect that we could further reduce the messages
exchanged by tuning the speciﬁcs of the update mechanism.
6 Related Work
Our design and implementation represent a generic framework that supports a
wide spectrum of network-based summary statistics. We are not aware of any
system that provides similar ﬂexibility with an easy-to-use interface, suitable for
real-time processing in distributed deployments.
Summary statistics are widely used throughout the networking and security
communities, both in research and operations. To give just a few examples of re-
search eﬀorts presenting applications and/or corresponding data structures, the
literature includes work on ﬁnding port scanners in backbones [24], eﬃciently
counting the number of network ﬂows in high-speed environments [16,9], de-
tecting attacks against routers [1], computing real-time traﬃc summaries [15],
338
J. Amann, S. Hall, and R. Sommer
or identifying elephant ﬂows [8]. However, all of these eﬀorts remain speciﬁc to
their particular target application, while our work provides a framework on top
of which one can implement such analyses.
In operations, appliances from companies like SonicWall and Palo Alto Net-
works compute traﬃc summaries and break-downs, however they hardwire the
analysis performed. Several open-source utilities can apply statistical computa-
tions to network traﬃc, in particular NetFlow-based toolsets like SILK [22] and
ﬂow-tools [11]. However, they remain restricted to the abstractions their input
format provides, are intended mainly for oﬄine/batch usage, and do not pro-
vide the ﬂexibility of performing arbitrary computations. Splunk can compute
top-k-style statistics ﬂexibly on diﬀerent features, yet its input remains limited
to externally produced log ﬁles.
For intrusion detection, Denning pioneered statistical monitoring in her semi-
nal work on the host-based IDES system [7]. Today, scan detectors come with vir-
tually any IDS, including open-source systems such as Snort [21]. Older versions
of Bro [19] used to come with four fully separate scan detector implementations,
all targeting diﬀerent traﬃc features and/or threshold schemes. Our summary
statistics framework supports all four directly within its uniﬁed API. We refer
to, e.g.,
[18,12] for a broader overview of statistical anomaly detection (as well
as other approaches). We note that while we limit our summary statistics frame-
work implementation to threshold-based schemes for now, conceptually it could
support further statistical approaches as well.
Cohen et al. [4] present an abstract framework for weighted sampling in dis-
tributed settings. It is similar in intent to our work, however, it only considers
the case of sampling, and evaluates optimal algorithms for this setting. Peng et
al. [20] uses a cumulative sum algorithm to collect statistics at nodes and share
information using a machine learning algorithm. In contrast to our work, their
usage scenario is limited to cumulative sums and their evaluation focuses on
optimizing detection delays and bandwidth, not on providing a generally usable
framework for distributed summary statistics.
We use a set of probabilistic data structures to eﬃciently compute statistics
that traditionally would be very resource intensive to maintain on large inputs.
We choose data structures that satisfy our constraints (see §2.4), yet note that
there are further candidates. For example, there are extensions available for the
HyperLogLog algorithm that we use [10]: Kane et al. [14] propose an algorithm
with an even lower memory overhead; it however remains complex and seems
impractical to implement [13]. Heule et al. likewise propose a series of improve-
ments to HyperLogLog [13]. As our main contributions concerns the framework
itself—not individual computations—we do not further explore such alternatives,
though may do so in the future if the current implementation ever turned out
to represent a bottleneck.
7 Conclusion
In this work, we present the design and implementation of a novel summary statis-
tics framework for network monitoring. As one of its key features, the framework
Count Me In: Viable Distributed Summary Statistics
339
supports computing statistics on arbitrary keys, such as IP addresses, DNS labels,
or HTTP server names. Furthermore, our design speciﬁcally targets distributed
deployment, and can thus be used in environments where sensors are either scat-
tered over independent tapping points, or jointly process a high-volume link in a
load-balancing setup. We assess the feasibility of our approach by implementing
the summary statistics framework on top of the open-source Bro network monitor,
and showcase a set of example applications in realistic large-scale settings.
Overall, we consider the summary statistics framework an extensible platform
that enables research and operators to measure and quantify characteristics of
their network traﬃc, with much less eﬀort than they would traditionally require
in particular in the distributed setup. Using the summary statistics framework,
users can implement powerful statistical measurements in just a handful lines of
code, and immediately deploy them for real-time processing.
Acknowledgments. We would like to thank for their collaboration Keith
Lehigh and Indiana University; Aashish Sharma and the Lawrence Berkeley Na-
tional Laboratory; Justin Azoﬀ and the National Center for Supercomputing Ap-
plications at the University of Illinois; as well as further unnamed organisations
that have operated early versions of the framework. This work was supported
by the US National Science Foundation under grants OCI-1032889 and ACI-
1348077; by the U.S. Army Research Laboratory and the U.S. Army Research
Oﬃce under MURI grant No. W911NF-09-1-0553; and by a fellowship within
the Postdoc-Programme of the German Academic Exchange Service (DAAD).
Any opinions, ﬁndings, and conclusions or recommendations expressed in this
material are those of the authors or originators, and do not necessarily reﬂect
the views of the NSF, the ARL/ARO, or the DAAD, respectively.
References
1. Barman, D., Satapathy, P., Ciardo, G.: Detecting Attacks in Routers using
Sketches. In: Workshop on High Performance Switching and Routing, HPSR (2007)
2. Bro SumStat Scripts & Repos, http://www.icir.org/johanna/sumstats
3. Bro Network Security Monitor Web Site, http://www.bro.org
4. Cohen, E., Duﬃeld, N., Kaplan, H., Lund, C., Thorup, M.: Composable, Scalable,
and Accurate Weight Summarization of Unaggregated Data Sets. Proc. VLDB
Endow. 2(1) (August 2009)
5. Das, S., Antony, S., Agrawal, D., El Abbadi, A.: Thread Cooperation in Multicore
Architectures for Frequency Counting over Multiple Data Streams. Proc. VLDB
Endow. 2(1) (August 2009)
6. Dean, J., Ghemawat, S.: MapReduce: Simpliﬁed Data Processing on Large Clus-
ters. Commun. ACM 51(1) (January 2008)
7. Denning, D.E.: An Intrusion-Detection Model. IEEE TSE 13(2) (February 1987)
8. Estan, C., Varghese, G.: New Directions in Traﬃc Measurement and Accounting:
Focusing on the Elephants, ignoring the Mice. ACM Trans. Comput. Syst. 21(3)
(August 2003)
9. Estan, C., Varghese, G., Fisk, M.: Bitmap Algorithms for Counting Active Flows
on High-Speed Links. IEEE/ACM Trans. Netw. 14(5) (October 2006)
340
J. Amann, S. Hall, and R. Sommer
10. Flajolet, P., Fusy, É., Gandouet, O., et al.: Hyperloglog: The Analysis of a Near-
Optimal Cardinality Estimation Algorithm. In: Proc. of the International Confer-
ence of Analysis of Algorithms, AFOA (2007)
11. Flow-tools information, http://www.splintered.net/sw/flow-tools
12. Garcia-Teodoro, P., Díaz-Verdejo, J.E., Maciá-Fernández, G., Vzquez, E.:
Anomaly-Based Network Intrusion Detection: Techniques, Systems and Challenges.
Computers & Security 28(1-2) (2009)
13. Heule, S., Nunkesser, M., Hall, A.: HyperLogLog in Practice: Algorithmic Engi-
neering of a State of The Art Cardinality Estimation Algorithm. In: Proc. EDBT
(2013)
14. Kane, D.M., Nelson, J., Woodruﬀ, D.P.: An Optimal Algorithm for the Distinct
Elements Problem. In: Proceedings ACM PODS (2010)
15. Keys, K., Moore, D., Estan, C.: A Robust System for Accurate Real-Time Sum-
maries of Internet Traﬃc. In: Proc. SIGMETRICS (2005)
16. Kim, H.A., O’Hallaron, D.R.: Counting Network Flows in Real Time. In: Proc.
IEEE Global Telecommunications Conference, vol. 7 (2003)
17. Metwally, A., Agrawal, D., El Abbadi, A.: Eﬃcient Computation of Frequent and
Top-k Elements in Data Streams. In: Proc. ICDT (2005)
18. Patcha, A., Park, J.M.: An Overview of Anomaly Detection Techniques: Existing
Solutions and Latest Technological Trends. Computer Networks 51(12) (2007)
19. Paxson, V.: Bro: A System for Detecting Network Intruders in Real-Time. Com-
puter Networks 31(23-24) (1999)
20. Peng, T., Leckie, C., Ramamohanarao, K.: Information Sharing for Distributed
Intrusion Detection Systems. Journal of Network and Computer Applications 30(3)
(August 2007)
21. Roesch, M.: Snort: Lightweight Intrusion Detection for Networks. In: LISA (1999)
22. SILK
Knowledge,
Internet-Level
System
for
–
http://tools.netsa.cert.org/silk/
23. Sommer, R., Paxson, V.: Exploiting Independent State For Network Intrusion De-
tection. In: ACSAC (2005)
24. Sridharan, A., Ye, T.: Tracking Port Scanners on the IP Backbone. In: Proc. Work-
shop on Large Scale Attack Defense, LSAD (2007)
25. Vallentin, M., Sommer, R., Lee, J., Leres, C., Paxson, V., Tierney, B.: The NIDS
Cluster: Scalable, Stateful Network Intrusion Detection on Commodity Hardware.
In: Kruegel, C., Lippmann, R., Clark, A. (eds.) RAID 2007. LNCS, vol. 4637, pp.
107–126. Springer, Heidelberg (2007)
26. Vitter, J.S.: Random Sampling with a Reservoir. ACM TOMS 11(1) (March 1985)