d
o
n
d
e
s
s
e
c
c
a
f
o
#
.
g
v
A
0
0.0
0.2
0.1
0.5
(a) sl = 2l + 3, p = 0.9, f = 0.3, and
w = 1.
0.3
0.4
γ
Client
Group
 of Servers
lock request to a quorum
return version within T or T 
2
1
Write
Operation
write to a whole or
a part of the quorum 
Read
Operation
read latest data 
from a node
with
TFTP
unlock request to a quorum
Figure 10. Overview of ﬁle transfer protocol designed.
 # of nodes ( h=2, f=0.5 )
# of nodes ( h=8, f=0.3 )
5.1 Experimental Setup
14
12
10
8
6
4
2
s
e
d
o
n
d
e
s
s
e
c
c
a
f
o
#
.
g
v
A
0
0.0
0.2
0.1
0.5
(b) sl = 2l + 3, p = 0.99, f = 0.3, and
w = 1.
0.3
0.4
γ
Figure 8. Average number of nodes accessed for proba-
bilistic TP, as a function of parameter γ.
tic QS, however, LV read availability was 0.7421. This
means that the probabilistic QS could not obtain the latest
data with a probability of about 25%.
5 Experiments of Data Replication Proto-
cols
In this section, we describe the design and implemen-
tation of the data replication protocol. We also report
the measured results of throughput for the QS, grid pro-
tocol, and TP on our experimental system. We evalu-
ated throughput under conditions where node availability
p was set to 1.0 or 0.0.
We implemented ﬁle transfer protocols based on the
QS, grid protocol, and TP in C++. The source codes
were about 2500 lines. We set up 17 Linux computers
(Celeron 2-GHz, 256-MB RAM) for the measurements.
Both the client and server for ﬁle transfer were running on
16 computers. These were remotely controlled through a
controller. As we can see from Fig. 9, the computers
and controller were connected to one another via 1-Gb/s
switching hubs.
5.2 Speciﬁcations of File Transfer Protocol
We implemented the ﬁle transfer protocol by expand-
ing a simple protocol, TFTP [13]. TFTP assumes that a
client will connect to one server node. In this study we
designed a version management mechanism for data by
adding version information to the data written to servers.
We also implemented read and write lock operations for
the target data to avoid concurrent execution of conﬂict-
ing operations.
Figure 10 is a conceptual diagram of the ﬁle transfer
protocol implemented in this study. Before transmission,
the client sent the lock requests to target servers. Each
server maintained a queue to store lock requests, and ex-
ecuted lock operations in order of arrival when this was
possible. Then, the servers sent back lock acknowledge-
ments with version information on the data stored. If the
client received lock acknowledgements from all servers
to which lock requirements had been sent within the time-
out interval, T1, or if it received acknowledgements from
the minimum number of required servers within the time-
out interval, T2, it started ﬁle transmission based on the
received version information. However, if the client failed
to receive acknowledgements from the minimum number
of required servers within T2 seconds, write operation ter-
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
8
Client / Server
Controller
1-Gb/s Switching Hub
1-Gb/s Switching Hub
1-Gb/s Switching Hub
17 Linux Computers
Figure 9. Experimental setup for data replication protocols.
minated unsuccessfully. The client tried to request the
next level for read operation. After the ﬁle had been trans-
mitted, the client sent unlock requests, and the operation
was completed. Note that ﬁle transmissions for multiple
servers were performed sequentially.
5.3 Experimental Results and Remarks
Here, we report on the measured results of through-
put in terms of processed requests/s, which was obtained
by implementing ﬁle transfer protocol. Through all the
experiments, request frequency λ for the operations on
each client was set to 0.5 ≤ λ ≤ 2.5 [the number of re-
quests/s]. The rate read operations occurred to write op-
erations was set to 1. The time to measure each result was
1,000 seconds. Time-out intervals were set to T1 = 0.1 [s]
and T2 = 1.0 [s]. We also used a text ﬁle of 10 KB for the
transmitted data.
Figure 11 plots the measured throughputs for TP with
γ = 0.0, grid protocol, and quorum system. We applied
the same node arrangements as in Fig. 2 to the TP with
γ = 0.0, where sl = 2l + 3, h = 2, N = 15, f =
0.5, w = 1, and γ = 0.0. We applied the same 4 × 4
arrangement as in Fig. 1 to the grid protocol. We set the
parameters to N = 15, |W Q| = 8, and |RQ| = 8 for
the quorum system. The throughputs for every protocol
decreased as the request frequency λ increased. TP had
the highest throughput. This can be attributed to the fact
that the size of quorums for the TP was smaller than for
the other protocols.
Figure 12 plots the measured throughput for TP using
sl = 2l + 3 and h = 2 similar to Fig. 2, under differ-
ent γ conditions, i.e., 0.0 and 0.2. In all ranges of λ, TP
with γ = 0.2 had higher throughput, although the differ-
ences were not signiﬁcantly large. They were considered
to have been caused when time-outs occurred while the
request was kept in the queue.
Table 3 lists the measured throughput for grid proto-
col and the TP with λ = 2.0 [requests/s]. We applied
14
12
10
8
6
4
2
]
s
/
s
t
s
e
u
q
e
r
f
o
#
[
t
u
p
h
g
u
o
r
h
T
Trapezoid Protocol ( γ =0.0 )
Grid Protocol
Quorum System
0.5
2.5
Request Frequency, λ [# of requests/s]
1.5
1.0
2.0
Figure 11. Average throughput on data replication proto-
cols ( N ≈ 15 and p = 1.0 ), TP: sl = 2l + 3, h = 2,
N = 15, f = 0.5, w = 1, γ = 0.0 and grid protocol:
4 × 4, quorum system: N = 15, |RQ| = 8, |W Q| = 8.
the same node arrangements as in Fig. 2 to the TP where
sl = 2l + 3, h = 2, N = 15, f = 0.5, w = 1, and γ
= 0.0 or 0.2. Here, we measured throughput under con-
ditions where at most one node was always unavailable,
i.e., p = 0.0. The unavailable node was selected as A1,2
for the grid protocol, and B1,2 for the TP. For case A,
where all nodes were available, the difference between
the grid protocol and the TP, with γ = 0.0, was about
15%, while TPs, with γ = 0.0 and γ = 0.2, had smaller
differences. For case B, where one node was unavailable,
the grid protocol had the lowest throughput. However, the
probabilistic TP with γ = 0.2 had a moderate decrease in
throughput compared with the other protocols or condi-
tions.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
9
IEEE Micro, Vol. 23, No. 2, pp. 22-28, Mar. - Apr. 2003.
[2] M. J. Carey and M. Livny, ”Conﬂict Detection Tradeoffs
for Replicated Data,” ACM Trans. on Database System,
Vol. 16, No. 4, pp. 703-746, Dec. 1991.
[3] M. Naor and A. Wool, ”The Load, Capacity and Avail-
ability of Quorum Systems,” SIAM Journal on Comput-
ing, Vol. 27, No. 2, pp. 423-447, Apr. 1998.
[4] D. K. Gifford, ”Weighted Voting for Replicated Data,”
Proc. of 7th ACM Symposium on Operating System Prin-
ciples, pp. 150-162, Dec. 1979.
[5] S. Y. Cheung, M. Ammar, and M. Ahamad, ”The Grid
Protocol: A High Performance Scheme for Maintaining
Replicated Data,” IEEE Trans. on Knowledge and Data
Engineering, Vol. 4, No. 6, pp. 582-592, Dec. 1992.
[6] D. Agrawal and A. E. Abbadi, ”The Tree Quorum Pro-
tocol: An Efﬁcient Approach for Managing Replicated
Data,” Proc. of 16th Very Large Database Conference, pp.
243-254, Aug. 1990.
[7] D. Agrawal and A. E. Abbadi, ”The Generalized Tree
Quorum Protocol: An Efﬁcient Approach for Managing
Replicated Data,” ACM Trans. on Database System, Vol.
17, No. 4, pp. 689-717, Dec. 1992.
[8] H. Y. Youn, D. Lee, B. Lee, J. S. Choi, H. G. Kim, C.
W. Park, and L. H. Su, ”An Efﬁcient Hybrid Replication
Protocol for Highly Available Distributed System,” Proc.
of IASTED International Conference. on Communications
& Computer Networks, pp. 508-513, Nov. 2002.
[9] M. Arai, T. Suzuki, M. Ohara, S. Fukumoto, K. Iwasaki,
and H. Y. Youn, ”Analysis of Read and Write Availability
for Generalized Hybrid Data Replication Protocol,” Proc.
of IEEE Paciﬁc Rim International Symposium on Depend-
able Computing, pp. 143-150, Mar. 2004.
[10] D. Malkhi, M. K. Reiter, and A. Wool, ”Probabilistic Quo-
rum Systems,” Information and Computation, Vol. 170,
No. 2, pp. 184-206, 2001.
[11] J. Luo, J. P. Hubaux, and P. T. Eugster, ”PAN: Providing
Reliable Storage in Mobile Ad Hoc Networks with Prob-
abilistic Quorum Systems,” Proc. of ACM International
Symposium on Mobile Ad Hoc Networking & Comput-
ing, pp. 1-12, 2003.
[12] J. Luo, P. T. Eugster, and J. P. Hubaux, ”Route Driven
Gossip: Probabilistic Reliable Multicast in Ad Hoc Net-
works,” Proc. of INFOCOM’03, 2003.
[13] K. Sollins, ”The TFTP Protocol (Revision 2),” RFC 1350,
Jul. 1992.
14
12
10
8
6
4
2
]
s
/
s
t
s
e
u
q
e
r
f
o
#
[
t
u
p
h
g
u
o
r
h
T
Trapezoid Protocol ( γ =0.0 )
Trapezoid Protocol ( γ =0.2 )
0.5
2.5
Request Frequency, λ [# of requests/s]
2.0
1.0
1.5
Figure 12. Average throughput for probabilistic TP using
sl = 2l + 3, h = 2, N = 15, p = 1.0, f = 0.5, and
w = 1
Table 3. Average throughput [the number of requests/s]
on data replication protocols( N ≈ 15, λ = 2.0 [re-
quests/s] ), TP: sl = 2l + 3, h = 2, f = 0.5, w = 1,
grid protocol: 4 × 4.
# of unavailable nodes
Grid Protocol
TP (γ = 0.0)
probabilistic TP (γ = 0.3)
case A case B
0
10.01
11.42
11.68
1
0.2707
0.4751
1.757
6 Conclusion
We proposed a probabilistic TP that combined a TP
with the concept of probabilistic QS. The proposed tech-
nique was able to provide a higher read availability than
that with TP alone. We theoretically analyzed the read
availability, latest version read availability (LV read avail-
ability), and the expected number of nodes to be accessed.
Our numerical evaluations substantiated the probabilistic
TP improved data availability. As we can see from Fig.
4, read availability is dramatically improved. Figures 8
indicates that when N is more than 100, the average num-
ber of nodes accessed can be decreased. Furthermore, the
probabilistic TP achieves much greater LV read availabil-
ity than the probabilistic QS, which consists of almost the
same size quorum. We implemented various replication
protocols on a system consisting of 17 personal comput-
ers and found the probabilistic TP had better fault toler-
ance in terms of the availability of data.
References
[1] L. A. Barroso, J. Dean, U. Holzle, and Google, ”Web
Search for a Planet: The Google Cluster Architecture,”
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
10