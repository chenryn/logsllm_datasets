from X. We say that two datasets D = {𝑑1, . . . , 𝑑𝑛} and D′ =
1, . . . , 𝑑′
𝑛} are neighboring (and denoted by D ∼ D′) if they dif-
{𝑑′
fer in one data point, i.e., there exists an 𝑖 ∈ [𝑛] such that 𝑑𝑖 ≠ 𝑑′
and for every 𝑗 ∈ [𝑛], 𝑗 ≠ 𝑖, we have 𝑑 𝑗 = 𝑑′
𝑗.
𝑖
Definition 2 (Central Differential Privacy - DP [16, 17]). For 𝜖, 𝛿 ≥
0, a randomized mechanism M : X𝑛 → Y is said to be (𝜖, 𝛿)-
differentially private (in short, (𝜖, 𝛿)-DP), if for all neighboring
datasets D ∼ D′ ∈ X𝑛 and every subset S ⊆ Y, we have
Pr [M(D) ∈ S] ≤ 𝑒𝜖0 Pr(cid:2)M(D′) ∈ S(cid:3) + 𝛿.
(2)
Definition 3 (Rényi Differential Privacy - RDP [36]). A randomized
mechanism M : X𝑛 → Y is said to have 𝜖(𝜆)-Rényi differential
privacy of order 𝜆 ∈ (1,∞) (in short, (𝜆, 𝜖(𝜆))-RDP), if for any
neighboring datasets D ∼ D′ ∈ X𝑛, the Rényi divergence between
M(D) and M(D′) is upper-bounded by 𝜖(𝜆), i.e.,
𝐷𝜆(M(D)||M(D′)) =
(cid:34)(cid:18) M(D)(𝜃)
(cid:19)𝜆(cid:35)(cid:33)
E𝜃∼M(D′)
(cid:32)
M(D′)(𝜃)
1
𝜆 − 1 log
≤ 𝜖(𝜆),
where M(D)(𝜃) denotes the probability that M on input D gener-
ates the output 𝜃. For convenience, instead of 𝜖(𝜆) being an upper
bound, we define it as 𝜖(𝜆) = supD∼D′ 𝐷𝜆(M(D)||M(D′)).
Our objective in this paper is to characterize the Rényi differential
privacy of a shuffling mechanism M (see Section 2.3 for details) for
different values of order 𝜆.
2.2 RDP to DP Conversion and RDP
Composition
In this subsection, we state some preliminary results from the liter-
ature that we will use. Though our main objective in this paper is
to derive RDP guarantees of a shuffling mechanism, we also give
the central privacy guarantees of that mechanism. For that purpose,
we use the following result for converting the RDP guarantees of
a mechanism to its DP guarantees. To the best of our knowledge,
this result gives the best conversion.4
Lemma 2.1 (From RDP to DP [4, 12]). Suppose for any 𝜆 > 1, a
mechanism M is (𝜆, 𝜖 (𝜆))-RDP. Then, the mechanism M is (𝜖, 𝛿)-
DP, where 𝜖, 𝛿 are define below:
For a given 𝛿 ∈ (0, 1) :
𝜖 = min
𝜆
For a given 𝜖 > 0 :
𝜖 (𝜆) + log (1/𝛿) + (𝜆 − 1) log (1 − 1/𝜆) − log (𝜆)
𝛿 = min
𝜆
exp [(𝜆 − 1) (𝜖 (𝜆) − 𝜖)]
𝜆 − 1
1 − 1
𝜆
𝜆 − 1
(cid:18)
(cid:19)𝜆
.
As mentioned in Section 1, the main strength of RDP in com-
parison to other privacy notions comes from composition. The
following result states that if we adaptively compose two RDP
mechanisms with the same order, their privacy parameters add up
in the resulting mechanism.
Lemma 2.2 (Adaptive composition of RDP [36, Proposition 1]).
For any 𝜆 > 1, let M1 : X → Y1 be a (𝜆, 𝜖1(𝜆))-RDP mechanism
and M2 : Y1 × X → Y be a (𝜆, 𝜖2(𝜆))-RDP mechanism. Then, the
mechanism defined by (M1,M2) satisfies (𝜆, 𝜖1(𝜆) + 𝜖2(𝜆))-RDP.
4An optimal conversion from RDP to approximate DP was studied in [2]; however,
we observed numerically, that it does not give better performance as compared to the
conversion presented above.
Session 7D: Privacy for Distributed Data and Federated Learning CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea 2323the only information it can use from the messages is the histogram,
i.e., the number of messages that give any particular output in [𝐵].
We define a set A𝑛
𝐵 as follows
A𝑛
𝐵 =
𝒉 = (ℎ1, . . . , ℎ𝐵) :
ℎ 𝑗 = 𝑛
,
(4)
(cid:27)
𝐵∑︁
𝑗=1
(cid:26)
to denote the set of all possible histograms of the output of the
shuffler with 𝑛 inputs. Therefore, we can assume, without loss of
generality (w.l.o.g.), that the output of M is a distribution over A𝑛
for input dataset D of 𝑛 data points.
𝐵
A succinct summary of the notation used throughout the paper
is given in Table 1.
3 MAIN RESULTS
This section is dedicated to presenting the main results of this paper,
along with their implications and comparisons with related work.
We state two different upper bounds on the RDP of the shuffle
model in Section 3.1 and a lower bound in Section 3.2. We present a
detailed proof-sketch of our first upper bound in Section 3.3, along
with all the main ingredients required to prove the upper bound.
3.1 Upper Bounds
In this subsection, we will provide two upper bounds.
Theorem 3.1 (Upper Bound 1). For any 𝑛 ∈ N, 𝜖0 ≥ 0,and any
integer 𝜆 ≥ 2, the RDP of the shuffle model is upper-bounded by
𝜖(𝜆) ≤ 1
(cid:18)𝜆
(cid:19) (𝑒𝜖0 − 1)2
𝜆 − 1 log(cid:16)1 +
(cid:32)(cid:0)𝑒2𝜖0 − 1(cid:1)2
(cid:18)𝜆
(cid:19)
+ 𝜆∑︁
2𝑒𝜖0 ⌋ + 1 and Γ (𝑧) = ∫ ∞
𝑖Γ (𝑖/2)
2𝑒2𝜖0𝑛
𝑛𝑒𝜖0
2
𝑖
(cid:33)𝑖/2
8𝑒𝜖0(cid:17),
+ 𝑒𝜖0𝜆− 𝑛−1
(5)
0 𝑥𝑧−1𝑒−𝑥𝑑𝑥 is the Gamma
𝑖=3
where 𝑛 = ⌊ 𝑛−1
function.
We give a proof sketch of Theorem 3.1 in Section 3.3 and provide
its complete proof in Section 7.1.
When 𝑛, 𝜖0, 𝜆 satisfy a certain condition, we can simplify the
bound in (5) to the following:
Corollary 3.2 (Simplified Upper Bound 1). For any 𝑛 ∈ N,
9 , we can
𝜖0 ≥ 0, and any integer 𝜆 ≥ 2 that satisfy 𝜆4𝑒5𝜖0  0 :
𝛿 = min
𝜆
𝜆 − 1
𝑡=1 𝜖𝑡 (𝜆) − 𝜖(cid:17)(cid:105)
(cid:18)
(cid:19)𝜆
.
1 − 1
𝜆
𝜆 − 1
2.3 Problem Formulation
Let D = (𝑑1, . . . , 𝑑𝑛) be a dataset consisting of 𝑛 data points, where
𝑑𝑖 is a data point at the 𝑖’th client that takes values from a set X.
Let R : X → Y be a local randomizer that satisfies the following
two properties:
(1) R is an 𝜖0-LDP mechanism (see Definition 1).
(2) The range of R is a discrete set, i.e., the output of R takes
values in a discrete set [𝐵] = {1, . . . , 𝐵} for some 𝐵 ∈ N :=
{1, 2, 3, . . .}. Here, [𝐵] could be the whole of N.
Client 𝑖 applies R on 𝑑𝑖 (each client uses independent randomness
for computing R(𝑑𝑖)) and sends R(𝑑𝑖) to the shuffler, who shuffles
the received 𝑛 inputs and outputs the result; see Figure 1. To for-
malize this, let H𝑛 : Y𝑛 → Y𝑛 denote the shuffling operation that
takes 𝑛 inputs and outputs their uniformly random permutation.
We define the shuffling mechanism as
M (D) := H𝑛 (R (𝑑1) , . . . , R (𝑑𝑛)) .
(3)
Our goal is to characterize the Rényi differential privacy of M.
Since the output of M is a random permutation of the 𝑛 outputs
of R, the server cannot associate the 𝑛 messages to the clients; and
ServerShuffler𝑑1𝑑2𝑑3𝑑4𝑑5𝜖0-LDP𝜖0-LDP𝜖0-LDP𝜖0-LDP𝜖0-LDP𝑑6𝜖0-LDP𝑑7𝜖0-LDP𝓡(𝑑1)𝓡(𝑑2)𝓡(𝑑3)𝓡(𝑑4)𝓡(𝑑5)𝓡(𝑑6)𝓡(𝑑7)Session 7D: Privacy for Distributed Data and Federated Learning CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea 2324Symbol
[𝐵]
𝜖0
(𝜖, 𝛿)
(𝜆, 𝜖(𝜆))
R : X → [𝐵]
𝒑 = (𝑝1, . . . , 𝑝𝐵)
𝒑′ = (𝑝′
1, . . . , 𝑝′
𝐵)
𝑛1, . . . , 𝑝′
𝒑′
𝑛 = (𝑝′
𝑛𝐵)
P
P−𝑖
𝒑𝑖 = (𝑝𝑖1, . . . , 𝑝𝑖𝐵) for 𝑖 ∈ [𝑛]
PC, where C ⊆ [𝑛 − 1]
A𝑛
𝐵
𝒉
M(D)
𝐹(P)
Description
{1, 2, . . . , 𝐵} for any 𝐵 ∈ N
LDP parameter (see Definition 1)
Approximate DP parameters (see Definition 2)
RDP parameters (see Definition 3)
their data points to elements in [𝐵]
A discrete 𝜖0-LDP mechanism at clients for mapping
The output distribution of R when the data point is 𝑑
The output distribution of R when the data point is 𝑑′
The output distribution of R when the data point is 𝑑𝑖
The output distribution of R when the data point is 𝑑′
A collection of 𝑛 distributions {𝒑1, . . . , 𝒑𝑛}
A collection of (𝑛 − 1) distributions P \ {𝒑𝑖}
𝑛
A collection of 𝑛 distributions, where clients in the set C map
according to 𝒑′
𝑛, clients in the set [𝑛 − 1] \ C map according
to ˜𝒑𝑖 (see (18)), and client 𝑛 maps according to 𝒑𝑛 (see (19)-(21))
A set of all possible histograms with 𝐵 bins and 𝑛 elements (see (4))
𝒉 = (ℎ1, . . . , ℎ𝐵) with𝐵
𝑖=1 ℎ𝑖 = 𝑛 is an element of A𝑛
The shuffle mechanism M on the dataset D ∈ X𝑛;
Distribution over A𝑛
𝐵 (see (3))
according to the distribution 𝒑𝑖 (see (17))
M(D) is a distribution over A𝑛
𝐵 when client 𝑖 maps its data point
𝐵
Table 1: Notation used throughout the paper
𝜆 using convexity of the function (𝜆 − 1) 𝜖 (𝜆) as follows. From [39,
Corollary 2], the function (𝜆 − 1) 𝐷𝜆 (P||Q) is convex in 𝜆 for any
given two distributions P and Q. Thus, for any real order 𝜆 > 1, we
can bound the RDP of the shuffle model by
𝜖 (𝜆) ≤ 𝑎 · (⌊𝜆⌋ − 1) · 𝜖 (⌊𝜆⌋) + (1 − 𝑎) · (⌈𝜆⌉ − 1) · 𝜖 (⌈𝜆⌉)
(7)
where 𝑎 = ⌈𝜆⌉ − 𝜆, since 𝜆 = 𝑎⌊𝜆⌋ + (1 − 𝑎)⌈𝜆⌉ for any real 𝜆. Here,