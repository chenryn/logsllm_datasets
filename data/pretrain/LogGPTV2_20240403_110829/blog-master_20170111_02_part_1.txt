## Linux cgroup - memory子系统讲解  
### 作者       
digoal                                                                                              
### 日期                                                                                             
2017-01-11                                                                                                   
### 标签       
Linux , cgroup , memory , oom , buffer cache , page cache , oom notify , oom control , D        
----                                                                                            
## 背景         
Linux是一个很好的多用户平台，但是当我们在Linux中运行多个资源耗费很大的应用（比如数据库）时，应用间的资源争抢可能就比较严重。  
那么有什么好的方法可以隔离不同应用之间的资源使用呢？cgroup是一个不错的选择。  
cgroup目前已支持 cpu, 网卡, memory, io, 硬件设备 的隔离，详见kernel文档例如 :   
/usr/share/doc/kernel-doc-2.6.32/Documentation/cgroups/  
本文将详细介绍一下memory子系统的使用，memory子系统包括控制和状态报告两个部分的功能。    
## 正文  
大部分内容从  http://liwei.life/2016/01/22/cgroup_memory/  提炼    
## 一、Linux内存管理基础知识  
### free命令  
在Linux系统中，我们经常用free命令来查看系统内存的使用状态。在一个RHEL6的系统上，free命令的显示内容大概是这样一个状态：  
```  
[root@tencent64 ~]# free  
             total       used       free     shared    buffers     cached  
Mem:     132256952   72571772   59685180          0    1762632   53034704  
-/+ buffers/cache:   17774436  114482516  
Swap:      2101192        508    2100684  
```  
这里的默认显示单位是kb，我的服务器是128G内存，所以数字显得比较大。这个命令几乎是每一个使用过Linux的人必会的命令，但越是这样的命令，似乎真正明白的人越少（我是说比例越少）。  
一般情况下，对此命令输出的理解可以分这几个层次：  
1\. 不了解。这样的人的第一反应是：天啊，内存用了好多，70个多G，可是我几乎没有运行什么大程序啊？为什么会这样？Linux好占内存！  
2\. 自以为很了解。这样的人一般评估过会说：嗯，根据我专业的眼光看的出来，内存才用了17G左右，还有很多剩余内存可用。buffers/cache占用的较多，说明系统中有进程曾经读写过文件，但是不要紧，这部分内存是当空闲来用的。  
3\. 真的很了解。这种人的反应反而让人感觉最不懂Linux，他们的反应是：free显示的是这样，好吧我知道了。神马？你问我这些内存够不够，我当然不知道啦！我特么怎么知道你程序怎么写的？  
根据目前网络上技术文档的内容，我相信绝大多数了解一点Linux的人应该处在第二种层次。  
**大家普遍认为，buffers和cached所占用的内存空间是可以在内存压力较大的时候被释放当做空闲空间用的。**   
但真的是这样么？  
无论如何，free命令确实给我门透露了一些有用的信息，比如内存总量，剩余多少，多少用在了buffers/cache上，Swap用了多少，如果你用了其它参数还能看到一些其它内容，这里不做一一列举。  
那么这里又引申出另一些概念，什么是buffer？什么是cache？什么是swap？由此我们就直接引出另一个命令：  
```  
[root@zorrozou-pc ~]# cat /proc/meminfo  
MemTotal: 131904480 kB  
MemFree: 125226660 kB  
Buffers: 478504 kB  
Cached: 4966796 kB  
SwapCached: 0 kB  
Active: 1774428 kB  
Inactive: 3770380 kB  
Active(anon): 116500 kB  
Inactive(anon): 3404 kB  
Active(file): 1657928 kB  
Inactive(file): 3766976 kB  
Unevictable: 0 kB  
Mlocked: 0 kB  
SwapTotal: 2088956 kB  
SwapFree: 2088956 kB  
Dirty: 336 kB  
Writeback: 0 kB  
AnonPages: 99504 kB  
Mapped: 20760 kB  
Shmem: 20604 kB  
Slab: 301292 kB  
SReclaimable: 229852 kB  
SUnreclaim: 71440 kB  
KernelStack: 3272 kB  
PageTables: 3320 kB  
NFS_Unstable: 0 kB  
Bounce: 0 kB  
WritebackTmp: 0 kB  
CommitLimit: 68041196 kB  
Committed_AS: 352412 kB  
VmallocTotal: 34359738367 kB  
VmallocUsed: 493196 kB  
VmallocChunk: 34291062284 kB  
HardwareCorrupted: 0 kB  
AnonHugePages: 49152 kB  
HugePages_Total: 0  
HugePages_Free: 0  
HugePages_Rsvd: 0  
HugePages_Surp: 0  
Hugepagesize: 2048 kB  
DirectMap4k: 194816 kB  
DirectMap2M: 3872768 kB  
DirectMap1G: 132120576 kB  
```  
以上显示的内容都是些什么鬼？  
其实这个问题的答案也是另一个问题的答案  
### Buffers/Cached  
buffer和cache是两个在计算机技术中被用滥的名词，放在不通语境下会有不同的意义。  
在内存管理中，我们需要特别澄清一下，  
这里的buffer指Linux内存中的：Buffer cache(缓冲区缓存)。  
这里的cache指Linux内存中的：Page cache(页面缓存)。  
翻译成中文可以叫做缓冲区缓存和页面缓存。  
在历史上，它们一个（buffer）被用来当成对io设备写的缓存，而另一个（cache）被用来当作对io设备的读缓存，这里的io设备，主要指的是块设备文件和文件系统上的普通文件。  
但是现在，它们的意义已经不一样了。在当前的内核中，page cache顾名思义就是针对内存页的缓存，说白了就是，如果有内存是以page进行分配管理的，都可以使用page cache作为其缓存来使用。  
当然，不是所有的内存都是以页（page）进行管理的，也有很多是针对块（block）进行管理的，这部分内存使用如果要用到cache功能，则都集中到buffer cache中来使用。（从这个角度出发，是不是buffer cache改名叫做block cache更好？）然而，也不是所有块（block）都有固定长度，系统上块的长度主要是根据所使用的块设备决定的，而页长度在X86上无论是32位还是64位都是4k。  
而明白了这两套缓存系统的区别，也就基本可以理解它们究竟都可以用来做什么了。  
#### 什么是page cache  
Page cache主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有read/write操作的时候。  
如果你仔细想想的话，作为可以映射文件到内存的系统调用：  
mmap是不是很自然的也应该用到page cache？如果你再仔细想想的话，malloc会不会用到page cache？  
```  
man map  
  mmap, mmap64, munmap - map or unmap files or devices into memory  
man malloc  
  calloc, malloc, free, realloc - Allocate and free dynamic memory  
```  
以上提出的问题都请自己思考，本文档不会给出标准答案。  
在当前的实现里，page cache也被作为其它文件类型的缓存设备来用，所以事实上page cache也负责了大部分的块设备文件的缓存工作。  
#### 什么是buffer cache  
Buffer cache的主要功能：在系统对块设备进行读写时，对块进行数据缓存。但是由于page cache也负责块设备文件读写的缓存工作，于是，当前的buffer cache实际上要负责的工作比较少。这意味着仅某些对块的操作会使用buffer cache进行缓存，比如我们在格式化文件系统的时候。  
一般情况下buffer cache/page cache两个缓存系统是一起配合使用的，比如当我们对一个文件进行写操作的时候，page cache的内容会被改变，而buffer cache则可以用来将page标记为不同的缓冲区，并记录是哪一个缓冲区被修改了。这样，内核在后续执行脏数据的回写（writeback）时，就不用将整个page写回，而只需要写回修改的部分即可。  
问题：(page的部分? or 部分page? ， 是否还涉及到块设备的最小写单元?)    
有搞大型系统经验的人都知道，缓存就像万金油，只要哪里有速度差异产生的瓶颈，就可以在哪里抹。但其成本之一：需要维护数据的一致性。内存缓存也不例外，内核需要维持其一致性。在脏数据产生较快或数据量较大的时候，缓存系统整体的效率一样会下降，因为毕竟脏数据写回也是要消耗IO的。  
这个现象也会表现在这样一种情况下，当你发现free的时候，内存使用量较大，而且大部分是buffer/cache占用的。  
以一般的理解，都会认为此时进程如果申请内存，内核会将buffer/cache占用的内存当成空闲的内存分给进程，这是没错的。  
但是其成本是，在分配这部分已经被buffer/cache占用的内存的时候，内核会先对其上面的脏数据进行写回操作，保证数据一致后才会清空并分给进程使用。  
如果此时你的进程是突然申请大量内存，而且你的业务是一直在产生很多脏数据（比如日志），并且系统没有及时写回的时候，此时系统给进程分配内存的效率会很慢，系统IO也会很高。那么此时你还以为buffer/cache可以当空闲内存使用么？  
比如数据库应用，大量的导入数据，同时有业务发起了一个需要申请较大内存的读请求（比如用于HASH JOIN或者HASH 聚合，又或者排序等，用到较多的work_mem），此时就可能发生以上悲剧的事情。  
### 如何回收cache？  
Linux内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对buffer／cache的释放。尤其是cache空间，它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放cache，作为free空间分给相关进程使用。所以一般情况下，我们认为buffer/cache空间可以被释放，这个理解是正确的。  
但是这种清缓存的工作也并不是没有成本。清缓存必须保证cache中的数据跟对应文件中的数据一致，才能对cache进行释放。所以伴随着cache清除的行为，一般都是系统IO飙高。因为内核要对比cache中的数据和对应硬盘文件上的数据是否一致，如果不一致需要写回，之后才能回收。  
在系统中除了内存将被耗尽的时候可以清缓存以外，我们还可以使用下面这个文件来人工触发缓存清除的操作：  
```
echo 1 > /proc/sys/vm/drop_caches: 表示清除pagecache。  
echo 2 > /proc/sys/vm/drop_caches: 表示清除回收slab分配器中的对象（包括目录项缓存和inode缓存）。slab分配器是内核中管理内存的一种机制，其中很多缓存数据实现都是用的pagecache。  
echo 3 > /proc/sys/vm/drop_caches: 表示清除pagecache和slab分配器中的缓存对象。  
```
### cache都能被回收么？  
我们分析了cache能被回收的情况，那么有没有不能被回收的cache呢？当然有。  
#### 1. tmpfs  
大家知道Linux提供一种“临时”文件系统叫做tmpfs，它可以将内存的一部分空间拿来当做文件系统使用，使内存空间可以当做目录文件来用。现在绝大多数Linux系统都有一个叫做/dev/shm的tmpfs目录，就是这样一种存在。  
当然，我们也可以手工创建一个自己的tmpfs，方法如下：  
```  
[root@tencent64 ~]# mkdir /tmp/tmpfs  
[root@tencent64 ~]# mount -t tmpfs -o size=20G none /tmp/tmpfs/  
[root@tencent64 ~]# df  
Filesystem           1K-blocks      Used Available Use% Mounted on  
/dev/sda1             10325000   3529604   6270916  37% /  
/dev/sda3             20646064   9595940  10001360  49% /usr/local  
/dev/mapper/vg-data  103212320  26244284  71725156  27% /data  
tmpfs                 66128476  14709004  51419472  23% /dev/shm  
none                  20971520         0  20971520   0% /tmp/tmpfs  
```  
于是我们就创建了一个新的tmpfs，空间是20G，我们可以在/tmp/tmpfs中创建一个20G以内的文件。如果我们创建的文件实际占用的空间是内存的话，那么这些数据应该占用内存空间的什么部分呢？  
根据pagecache的实现功能可以理解，既然是某种文件系统，那么自然该使用pagecache的空间来管理。我们试试是不是这样？  
```  
[root@tencent64 ~]# free -g  
             total       used       free     shared    buffers     cached  
Mem:           126         36         89          0          1         19  
-/+ buffers/cache:         15        111  
Swap:            2          0          2  
[root@tencent64 ~]# dd if=/dev/zero of=/tmp/tmpfs/testfile bs=1G count=13  
13+0 records in  
13+0 records out  
13958643712 bytes (14 GB) copied, 9.49858 s, 1.5 GB/s  
[root@tencent64 ~]#   
[root@tencent64 ~]# free -g  
             total       used       free     shared    buffers     cached  
Mem:           126         49         76          0          1         32  
-/+ buffers/cache:         15        110  
Swap:            2          0          2  
```  
我们在tmpfs目录下创建了一个13G的文件，并通过前后free命令的对比发现，cached增长了13G，说明这个文件确实放在了内存里并且内核使用的是cache作为存储。  
再看看我们关心的指标： -/+ buffers/cache那一行。  
我们发现，在这种情况下free命令仍然提示我们有110G内存可用，但是真的有这么多么？  
我们可以人工触发内存回收看看现在到底能回收多少内存：  
```  
[root@tencent64 ~]# echo 3 > /proc/sys/vm/drop_caches  
[root@tencent64 ~]# free -g  
             total       used       free     shared    buffers     cached  
Mem:           126         43         82          0          0         29  
-/+ buffers/cache:         14        111  
Swap:            2          0          2  
```  