## 关于OpenSOC
OpenSOC是思科在BroCON大会上亮相了的一个安全大数据分析架构，它是一个针对网络包和流的大数据分析框架，它是大数据分析与安全分析技术的结合,
能够实时的检测网络异常情况并且可以扩展很多节点，它的存储使用开源项目Hadoop，实时索引使用开源项目ElasticSearch，在线流分析使用著名的开源项目Storm。
但是其部署上和使用上可能对于大部分中小企业来说，消耗的资源和精力可能有点过于庞大。本文着重介绍如何轻量级实现OpenSOC框架，即使日后升级或者添加了SEIM也可以快速迁入。
## OpenSOC介绍
我们先来看一下 OpenSOC 框架
### OpenSOC框架组成
OpenSOC框架主要包括六个部分
  * 数据来源（Source Systems）
  * 数据收集（Data Collection）
  * 消息通知（Messaging System）
  * 实时处理（Real Time Processing）
  * 数据存储（Storage）
  * 访问接口（Access）
### OpenSOC的工作流程：
**数据收集组件** 从 **数据来源** 收集日志等数据然后推送到 **消息通知组件** ，
通过 **消息通知组件** 分发给对应的 **实时处理组件**
由 **实时处理组件** 处理完后保存到 **数据存储组件** 中
最后由 **访问接口** 提供的API或者UI等供给用户查看或者调用
## 构建OpenSOC
### 使用的场景
本文将根据以下场景来构建OpenSOC。
  * 有多台Centos的WEB服务器
  * 需要获取所有的WEB服务器的访问日志
  * 推送到后台的规则匹配和机器学习分析部分
  * 用来判断和显示当前的访问情况
**注：** 如果有其他的数据源，配置好数据收集组件进行收集即可
此处只针对大部分的日志文件进行推送和处理，
### 工具和架构
由于是轻量级的框架，所以在架构上会稍微调整。
  * 数据来源（/var/log/httpd/*_log） 
    * 这里收集的是web服务器的日志。有其他的日志也是同样处理 
  * 数据收集 
    * 这里采用了Filebeat 一个轻量级的数据收集器
    * 感兴趣的也可以用logstash，不过性能损耗比Filebeat多
  * 消息通知 
    * 这里可以选择的很多 kafka，logstash 
    * 但是由于轻量级 我们直接使用 Filebeat的推送 
  * 实时处理 
    * 这里调用python写的处理脚本
      * 正则处理脚本 
      * 机器学习模型 
  * 数据存储
    * 实时存储 Elasticsearch 
      * 保存日志源记录 
    * 结果存储 mysql 
      * 分析的结果 
      * 预先规则
      * 其他配置信息
  * 接口和展示
    * flask写的一个简易管理后台 
整个系统结构如图：
## 搭建步骤
### 数据源
  * 使用的服务器是centos6.9 
  * 直接安装 php apache mysql等
  * 开启日志记录 
  * 安装web应用
    * dvwa
    * phpmyadmin
    * ...等
### 日志数据采集收集和推送
  * 使用RPM安装FileBeat(Elasticseach的安装也是一样)
  * 导入 rpm --import 
  * 编辑 elasticsearch.repo
    [elasticsearch-6.x]
        name=Elasticsearch repository for 6.x packages
        baseurl=https://artifacts.elastic.co/packages/6.x/yum
        gpgcheck=1
        gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
        enabled=1
        autorefresh=1
        type=rpm-md
  * yum install filebeat -y
### 安装elasticsearch
  * yum install elasticsearch -y
### 配置filebeat和elasticsearch
  * vi /etc/filebeat/filebeat.yml #给filebeat添加数据源
    filebeat.prospectors:
    - input_type: log
      paths: /var/log/httpd/access_log
    output.elasticsearch:
       hosts: ["IP:PORT"]
  * vi /etc/filebeat/filebeat.yml #给filebeat添加数据源
  * vi /etc/elasticsearch/elasticsearch.yml
    * 添加 network.bind_host: 你的IP
  * 访问一下一下刚才部署的网站
  * 访问 elastcisearch/_cat/indices?v 查看是否有 **filebeat-**** 索引建成
  * 访问 elastcisearch/filebeat- ***** /_search 查看刚才的访问记录是否已经同步到elastic search
### [注]
  * filebeat的paths 可以添加多个
  * 支持的类型具体可以自行查看filebeat的官方文档
### 分析和展示的UI
这里涉及的基本就是常规的网页编写和操作了。这里不具体展开。  
大概说一下我写的思路和用到的组件
  * 分析
    * 写了日志文件 每10分钟调用一次脚本 load.py
    * 脚本先判断数据是否有更新 有的话 调用分析的脚本 re_ana.py 和 knn_ana.py
    * 正则是 re_ana.py 
      * 正则的规则存储在mysql中，通过人工添加 
    * 机器学习是 knn_ana.py
      * 根据正则分析出来的数据 进行学习 学习完后 再去对新的数据进行分析 
    * 机器学习的模型用了最简单的分词+KNN去使用 
    * 为了降低分词带来的重复性很高的问题 添加了一个停用词表
  * UI
    * 用FLASK编写 
    * 模版用了elaadmin 
## 最后效果如图
基础的OpenSoc框架搭建完成，下一篇会介绍一下
  * 正则和机器学习的准确率比较
  * 我编写的一个简单的机器学习的模型
  * 如何低成本的搭建蜜罐和opensoc构建威胁情报 *（这个估计还会延后，资金不够）