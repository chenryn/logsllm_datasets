sources supports the supposition that, in addition to its other
useful properties for scientiﬁc analysis of attribution tasks,
the GCJ dataset is a valid and useful proxy for real-world
authorship attribution tasks.
The advantage of using the GCJ dataset is that we can
perform the experiments in a controlled environment where
the most distinguishing difference between programmers’ solu-
tions is their programming style. Every contestant implements
the same functionality, in a limited amount of time while at
each round problems are getting more difﬁcult. This provides
the opportunity to control the difﬁculty level of the samples and
the skill set of the programmers in the dataset. In source code
authorship attribution, programmers who can implement more
sophisticated functionality have a more distinct programming
style [16]. We observe the same pattern in executable binary
samples and gain some software engineering insights by an-
alyzing stylistic properties of executable binaries. In contrast
to GCJ, GitHub and Nulled.IO offer noisy samples. However,
our results show that we can de-anonymize programmers with
high accuracy as long as enough training data is available.
it
Previous work shows that coding style is quite prevalent
in source code. We were surprised to ﬁnd that
is also
preserved to a great degree in compiled source code. Coding
style is not just the use of particular syntactical constructs
but also the AST ﬂows, AST combinations, and preferred
types of operations. Consequently, these patterns manifest in
the binary and form a coding ﬁngerprint for each author. We
can de-anonymize programmers from compiled source code
with great accuracy, and furthermore, we can de-anonymize
programmers from source code compiled with optimization
or after obfuscation. In our experiments, we see that even
though basic obfuscation, optimization, or stripping symbols
transforms executable binaries more than plain compilation,
stylistic features are still preserved to a large degree. Such
methods are not sufﬁcient on their own to protect programmers
from de-anonymization attacks.
In scenarios where authorship attribution is challenging, an
analyst or adversary could apply relaxed attribution to ﬁnd a
suspect set of n authors, instead of a direct top–1 classiﬁcation.
In top–10 attribution, the chances of having the original author
within the returned set of 10 authors approaches 100%. Once
the suspect set size is reduced to 10 from hundreds, the
analyst or adversary could adhere to content based dynamic
approaches and reverse engineering to identify the author of
the executable binary sample. However, our experiments in
these cases are performed using the information-gain features
determined from the unoptimized case with symbol tables in-
tact. Future work that customizes the dimensionality reduction
step for these cases (for example, removing features from the
trees that are no longer relevant) may be able to improve upon
these numbers, especially since dimensionality reduction was
able to provide such a large boost in the unoptimized case.
Even though executable binaries look cryptic and difﬁcult
to analyze, we can still extract many useful features from them.
We extract features from disassembly, control ﬂow graphs,
and also decompiled code to identify features relevant to only
programming style. After dimensionality reduction, we see
that each of the feature spaces provides programmer style
information. The initial development feature set contains a
total of 705,000 features for 900 executable binary samples of
100 authors. Approximately 50 features from abstract syntax
trees and assembly instructions sufﬁce to capture enough key
information about coding style to enable robust authorship
attribution. We see that the reduced set of features are valid in
different datasets with different programmers, including opti-
mized or obfuscated programmers. Also, the reduced feature
set is helpful in scaling up the programmer de-anonymization
approach. While we can identify 100 programmers with 96%
accuracy, we can de-anonymize 600 programmers with 83%
accuracy using the same reduced set of features. 83% is a very
high number for such a challenging task where the random
chance of correctly identifying an author is 0.17%.
13
VIII. LIMITATIONS
IX. CONCLUSION
Our experiments suggest that our method is able to assist
in de-anonymizing a much larger set of programmers with
signiﬁcantly higher accuracy than state-of-the-art approaches.
However, there are also assumptions that underlie the validity
of our experiments as well as inherent
limitations of our
method which we discuss in the following paragraphs. First,
we assume that our ground truth is correct, but in reality pro-
grams in GCJ or on GitHub might be written by programmers
other than the stated programmer, or by multiple programmers.
Such a ground truth problem would cause the classiﬁer to train
on noisy models which would lead to lower de-anonymization
accuracy and a noisy representation of programming style.
Second, many source code samples from GCJ contestants
cannot be compiled. Consequently, we perform evaluation only
on the subset of samples which can be compiled. This has
two effects: ﬁrst, we are performing attribution with fewer
executable binary samples than the number of available source
code samples. This is a limitation for our experiments but
it is not a limitation for an attacker who ﬁrst gets access
to the executable binary instead of the source code. If the
attacker gets access to the source code instead, she could
perform regular source code authorship attribution. Second,
we must assume that whether or not a code sample can be
compiled does not correlate with the ease of attribution for
that sample. Third, we mainly focus on C/C++ code compiled
(except Nulled.IO samples) using the GNU compiler gcc in
this work, and assume that the executable binary format is
the Executable and Linking Format. This is important to note
as dynamic symbols are typically present in ELF binary ﬁles
even after stripping of symbols, which may ease the attribution
task relative to other executable binary formats that may not
contain this information. We defer an in depth investigation of
the impact that other compilers, languages, and binary formats
might have on the attribution task to future work.
Finally, while we show that our method is capable of
dealing with simple binary obfuscation techniques, we do not
consider binaries that are heavily obfuscated to hinder reverse
engineering. While simple systems, such as packers [2] or
encryption stubs that merely restore the original executable
binary into memory during execution may be analyzed by
simply recovering the unpacked or decrypted executable bi-
nary from memory, more complex approaches are becoming
increasingly commonplace. A wide range of anti-forensic
techniques exist [19], including methods that are designed
speciﬁcally to prevent easy access to the original bytecode
in memory via such techniques as modifying the process
environment block or triggering decryption on the ﬂy via guard
pages. Other techniques such as virtualization [3] transform
the original bytecode to emulated bytecode running on vir-
tual machines, making decompilation both labor-intensive and
error-prone. Finally, the use of specialized compilers that lack
decompilers and produce nonstandard machine code (see [17]
for an extreme but illustrative example) may likewise hinder
our approach, particularly if the compiler is not available and
cannot be ﬁngerprinted. We leave the examination of these
techniques, both with respect to their impact on authorship
attribution and to possible mitigations, to future work.
De-anonymizing programmers has direct implications for
privacy and anonymity. The ability to attribute authorship to
anonymous executable binaries has applications in software
forensics, and is an immediate concern for programmers
that would like to remain anonymous. We show that coding
style is preserved in compilation, contrary to the belief that
compilation wipes away stylistic properties. We de-anonymize
100 programmers from their executable binaries with 96%
accuracy, and 600 programmers with 83% accuracy. Moreover,
we show that we can de-anonymize GitHub developers or
hacker forum members with high accuracy. Our work, while
signiﬁcantly improving the limited approaches in programmer
de-anonymization, presents new methods to de-anonymize
programmers in the wild from challenging real-world samples.
We discover a small set of features that effectively represent
coding style in executable binaries. We obtain this precise
representation of coding style via two different disassemblers,
control ﬂow graphs, and a decompiler. With this comprehen-
sive representation, we are able to re-identify GitHub authors
from their executable binary samples in the wild, where we
reach an accuracy of 65% for 50 programmers, even though
these samples are noisy and products of collaborative efforts.
Programmer style is embedded in executable binary to a
surprising degree, even when it is obfuscated, generated with
aggressive compiler optimizations, or symbols are stripped.
Compilation, binary obfuscation, optimization, and stripping
of symbols reduce the accuracy of stylistic analysis but are
not effective in anonymizing coding style.
In future work, we plan to investigate snippet and function
level stylistic information to de-anonymize multiple authors of
collaboratively generated binaries. We also defer the analysis
of highly sophisticated compilation and obfuscation methods
to future work. Nevertheless, we show that identifying stylistic
information is prevalent in real-world settings and accordingly
developers cannot assume to be anonymous unless they take
extreme precautions as a countermeasure. Examples to possible
countermeasures include a combination of randomized coding
style, different programming language usage, and employment
of indeterministic set of obfuscation methods. Since incorpo-
rating different languages or obfuscation methods is not always
practical, especially in open source software, our future work
would focus on completely stripping stylistic information from
binaries to render them anonymous.
We also plan to look at different real-world executable
binary authorship attribution cases, such as identifying authors
of malware, which go through a mixture of sophisticated
obfuscation methods by combining polymorphism and encryp-
tion. Our results so far suggest that while stylistic analysis is
unlikely to provide a “smoking gun” in the malware case, it
may contribute signiﬁcantly to attribution efforts.
Moreover, we show that attribution is sometimes possible
with only small amounts of training binaries, however, having
more binaries for training helps signiﬁcantly. In addition, we
observe that advanced programmers (as measured by progres-
sion in the GCJ contest) can be attributed more easily than
their less skilled peers. Our results present a privacy threat for
people who would like to release binaries anonymously.
14
REFERENCES
the ultimate packer
for executables,” upx.sourceforge.net,
“Hex-rays decompiler,” November 2015. [Online]. Available: https:
//www.hex-rays.com/
“Upx:
November 2015. [Online]. Available: http://upx.sourceforge.net/
“Oreans technology: Code virtualizer,” 2015 November.
Available: http://www.oreans.com/codevirtualizer.php
“The github repository hosting service,” http://www.github.com, visited,
November 2015.
“Google Code Jam Programming Competition,” code.google.com/
codejam, visited, November 2015.
[Online].
[1]
[2]
[3]
[4]
[5]
[6] S. Afroz, M. Brennan, and R. Greenstadt, “Detecting hoaxes, frauds,
and deception in writing style online,” in Proc. of IEEE Symposium on
Security and Privacy.
IEEE, 2012.
[7] S. Afroz, A. Caliskan-Islam, A. Stolerman, R. Greenstadt, and D. Mc-
Coy, “Doppelg¨anger ﬁnder: Taking stylometry to the underground.” in
Proc. of IEEE Symposium on Security and Privacy, 2014.
[8] A. Aiken et al., “Moss: A system for detecting software pla-
giarism,” University of California–Berkeley. See www. cs. berkeley.
edu/aiken/moss. html, vol. 9, 2005.
[9] S. Alrabaee, N. Saleem, S. Preda, L. Wang, and M. Debbabi, “Oba2:
an onion approach to binary code authorship attribution,” Digital
Investigation, vol. 11, 2014.
[10] E. Backer and P. van Kranenburg, “On musical stylometry—a pattern
recognition approach,” Pattern Recognition Letters, vol. 26, no. 3, pp.
299–309, 2005.
[11] U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kruegel, and E. Kirda,
“Scalable, behavior-based malware clustering.” in NDSS, vol. 9. Cite-
seer, 2009, pp. 8–11.
[12] M. Brennan, S. Afroz, and R. Greenstadt, “Adversarial stylometry: Cir-
cumventing authorship recognition to preserve privacy and anonymity,”
ACM TISSEC, vol. 15, no. 3, pp. 12–1, 2012.
[13] S. Burrows and S. M. Tahaghoghi, “Source code authorship attribution
using n-grams,” in Proc. of the Australasian Document Computing
Symposium, 2007.
[14] S. Burrows, A. L. Uitdenbogerd, and A. Turpin, “Application of
information retrieval techniques for source code authorship attribution,”
in Database Systems for Advanced Applications, 2009.
[15] ——, “Comparing techniques for authorship attribution of source code,”
Software: Practice and Experience, vol. 44, no. 1, pp. 1–32, 2014.
[16] A. Caliskan-Islam, R. Harang, A. Liu, A. Narayanan, C. Voss, F. Ya-
maguchi, and R. Greenstadt, “De-anonymizing programmers via code
stylometry,” in Proc. of the USENIX Security Symposium, 2015.
[17] C. Domas, “M/o/vfuscator,” November 2015.
https://github.com/xoreaxeaxeax/movfuscator
[Online]. Available:
[18] R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin,
“Liblinear: A library for large linear classiﬁcation,” Journal of Machine
Learning Research (JMLR), vol. 9, 2008.
[19] P. Ferrie, “Anti-unpacker tricks–part one.” Virus Bulletin (2008): 4.
[20] G. Frantzeskou, E. Stamatatos, S. Gritzalis, and S. Katsikas, “Effective
identiﬁcation of source code authors using byte-level information,” in
Proc. of the International Conference on Software Engineering. ACM,
2006.
[21] M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H.
Witten, “The weka data mining software: an update,” SIGKDD Explor.
Newsl., vol. 11, 2009.
[22] M. A. Hall, “Correlation-based feature selection for machine learning,”
Ph.D. dissertation, The University of Waikato, 1999.
[23] E. R. Jacobson, N. Rosenblum, and B. P. Miller, “Labeling library func-
tions in stripped binaries,” in Proceedings of the 10th ACM SIGPLAN-
SIGSOFT workshop on Program analysis for software tools, 2011.
[24] P. Junod, J. Rinaldini, J. Wehrli, and J. Michielin, “Obfuscator-LLVM
– software protection for the masses,” in Proc. of the IEEE/ACM 1st
International Workshop on Software Protection, SPRO’15, 2015.
[25] A. Keromytis, “Enhanced attribution,” DARPA-BAA-16-34, 2016.
[26]
J. Kothari, M. Shevertalov, E. Stehle, and S. Mancoridis, “A probabilis-
tic approach to source code authorship identiﬁcation,” in Information
Technology, 2007. ITNG’07.
IEEE, 2007.
[27]
J. Lafferty, A. McCallum, and F. C. Pereira, “Conditional random ﬁelds:
Probabilistic models for segmenting and labeling sequence data,” 2001.
[28] R. C. Lange and S. Mancoridis, “Using code metric histograms and ge-
netic algorithms to perform author identiﬁcation for software forensics,”
in Proceedings of the Annual Conference on Genetic and Evolutionary
Computation. ACM, 2007.
[29] M. Marquis-Boire, M. Marschalek, and C. Guarnieri, “Big game hunt-
ing: The peculiarities in nation-state malware research,” in Proc. of
Black Hat USA, 2015.
[30] A. W. McDonald, S. Afroz, A. Caliskan, A. Stolerman, and R. Green-
stadt, “Use fewer instances of the letter “i”: Toward writing style
anonymization,” in Privacy Enhancing Technologies. Springer Berlin
Heidelberg, 2012, pp. 299–318.
[31] T. C. Mendenhall, “The characteristic curves of composition,” Science,
pp. 237–249, 1887.
[32] A. Narayanan, H. Paskov, N. Z. Gong, J. Bethencourt, E. Stefanov,
E. C. R. Shin, and D. Song, “On the feasibility of internet-scale author
identiﬁcation,” in Proc. of IEEE Symposium on Security and Privacy,
2012.
[33] pancake, “Radare,” radare.org, visited, October 2015.
[34] B. N. Pellin, “Using classiﬁcation techniques to determine source code
authorship,” 2000.
[35] A. Pfeffer, C. Call, J. Chamberlain, L. Kellogg, J. Ouellette, T. Patten,
G. Zacharias, A. Lakhotia, S. Golconda, J. Bay et al., “Malware analysis
and attribution using genetic information,” in 2012 7th International
Conference on Malicious and Unwanted Software.
IEEE, 2012.
J. Quinlan, “Induction of decision trees,” Machine learning, 1986.
[36]
[37] N. A. Quynh, “Capstone,” capstone-engine.org, visited, October 2015.
[38] K. Rieck, T. Holz, C. Willems, P. D¨ussel, and P. Laskov, “Learning
and classiﬁcation of malware behavior,” in Detection of Intrusions and
Malware, and Vulnerability Assessment. Springer, 2008.
[39] N. Rosenblum, X. Zhu, and B. Miller, “Who wrote this code? Identi-
fying the authors of program binaries,” ESORICS, 2011.
[40] N. Rosenblum, B. P. Miller, and X. Zhu, “Recovering the toolchain
provenance of binary code,” in Proc. of the International Symposium
on Software Testing and Analysis. ACM, 2011.
[41] N. E. Rosenblum, B. P. Miller, and X. Zhu, “Extracting compiler
provenance from program binaries,” in Proceedings of the 9th ACM
SIGPLAN-SIGSOFT workshop on Program analysis for software tools
and engineering. ACM, 2010.
[42] N. Science and T. Council”, “Federal cybersecurity research and devel-
opment strategic plan,” whitehouse.gov/ﬁles/documents, 2016.
[43] A. Stolerman, R. Overdorf, S. Afroz, and R. Greenstadt, “Classify, but
verify: Breaking the closed-world assumption in stylometric authorship
attribution,” in Working Group 11.9 on Digital Forensics.
IFIP, 2014.
[44] S. Tatham and J. Hall, “The netwide disassembler: NDISASM,” http:
//www.nasm.us/doc/nasmdoca.html, visited, October 2015.
[45] P. van Kranenburg, “Composer attribution by quantifying compositional
strategies.” in ISMIR, 2006.
[46] W. Wisse and C. Veenman, “Scripting dna: Identifying the javascript
programmer,” Digital Investigation, 2015.
[47] F. Yamaguchi, N. Golde, D. Arp, and K. Rieck, “Modeling and
discovering vulnerabilities with code property graphs,” in Proc. of IEEE
Symposium on Security and Privacy, 2014.
15