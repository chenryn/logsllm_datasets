### Contribution of Apps to Malware Detection
Even if an app employs new APIs that did not appear in the training phase, its contributions to malware detection can still be measured by associating its API vectors with the closest API clusters. Consequently, any app can be converted into a 1,000-dimensional binary vector for malware detection during the testing phase.

### B. SDAC Dataset
**Table IV: Evaluation of Differential Training with SDAC**

| **Metric** | **Value** |
|------------|-----------|
| Total Samples in the Whole Dataset | 69,933 |
| Benignware | 35,437 |
| Malware | 34,496 |
| Samples in Noisy Training Set | 56,650 |
| Number of Noises Added | 5,614 (9.91%) |
| True Positives Detected | 5,246 |
| Remaining Noises in Processed Dataset | 343 |
| False Positives Detected | 711 (1.26%) |
| F-score with Correctly-labeled Dataset | 97.71% |
| F-score with Noisily-labeled Dataset | 89.04% |
| F-score with Processed Dataset | 97.19% |

To ensure the quality of the dataset, we further downloaded scanning results from VirusTotal in June 2019 and removed 878 (1.24%) apps whose labels changed between July 2018 and June 2019. The final SDAC dataset consists of 69,933 app samples with relatively stable labels over three years, which we consider as "ground-truth." In this dataset, 35,437 apps are labeled benign, and 34,496 are labeled malicious.

### C. Performance of Differential Training with SDAC
Table IV summarizes the performance of the SDAC dataset and the effectiveness of Differential Training, measured on the correctly-labeled, noisily-labeled, and noise-reduced training sets. Differential Training correctly revised 5,246 labels and incorrectly revised 343 labels, reducing the percentage of noisy labels from 9.91% to 1.26%.

Figure 5 provides more details, showing the number of labels correctly and incorrectly revised in each iteration, along with the accuracy of the revised labels. When Differential Training converges, the accuracy of the revised labels reaches nearly 99%.

The F-score of SDAC improves from 89.04% to 97.19% after noise reduction, approaching its upper bound of 97.71%. These results demonstrate that Differential Training significantly reduces the number of wrong labels in the training set, thereby enhancing the performance of Android malware detection.

### D. Runtime Performance of Differential Training with SDAC
The total time cost for Differential Training with SDAC is approximately 55.34 hours, involving 58 iterations. Each iteration takes about 57.3 minutes on average, with 50.6 minutes spent on training the WS model and less than 4 minutes on the DS model. The remaining time is used for outlier detection and noise ratio estimation.

### VI. DIFFERENTIAL TRAINING WITH DREBIN
#### A. Introduction of Drebin
Drebin, published in 2014, is a lightweight Android malware detection solution based on static analysis. It extracts features such as hardware components, required missions, app components, filtered intents, critical API calls, permissions, suspicious API calls, and network address strings, converting each app into a 545,433-dimensional feature vector. Drebin uses a linear SVM classifier for malware detection and identifies significant features using linear weights.

Compared to the recently published SDAC, Drebin is a classic approach frequently cited in malware research since 2014. We evaluate the effectiveness of Differential Training on both SDAC and the older Drebin dataset.

#### B. Drebin Dataset
The Drebin dataset, collected in 2014, consists of 5,560 malware samples and 123,453 benign apps. We verified the dataset in June 2019 using VirusTotal, finding no contradictory labels except for some old apps with no reports. Unlike the balanced SDAC dataset, the Drebin dataset is highly imbalanced, with malware accounting for only 4.3% of all apps.

**Table V: Evaluation of Differential Training with Drebin**

| **Metric** | **Value** |
|------------|-----------|
| Total Samples in the Whole Dataset | 129,013 |
| Benignware | 123,453 |
| Malware | 5,560 |
| Samples in Noisy Training Set | 103,210 |
| Number of Noises Added | 10,009 (9.70%) |
| True Positives Detected | 9,121 |
| Remaining Noises in Processed Dataset | 605 |
| False Positives Detected | 1,805 (1.75%) |
| F-score with Correctly-laballed Dataset | 93.34% |
| F-score with Noisily-laballed Dataset | 73.20% |
| F-score with Processed Dataset | 84.40% |

Differential Training correctly revised 9,121 labels and mistakenly revised 605 labels, achieving an accuracy of nearly 98%.

### C. Performance of Differential Training with Drebin
Table V shows that Drebin's F-score improves from 73.20% to 84.40% when trained on the processed dataset, with the noise label percentage reduced from 9.70% to 1.75%. This improved F-score is closer to the upper bound of 93.34% achieved with the correctly-labeled dataset.

### D. Runtime Performance of Differential Training with Drebin
The total time cost for Differential Training with Drebin is approximately 62.52 hours, involving 68 iterations. Each iteration takes about 55.2 minutes on average, with 52.0 minutes for the WS model and 2.8 minutes for the DS model.

### VII. DIFFERENTIAL TRAINING WITH DEEPREFINER
#### A. Introduction of DeepReﬁner
DeepReﬁner, published in 2015-2016, is an Android malware detection approach that combines two deep learning models. The first model, a Multi-Layer Perceptron, efficiently detects significant malware samples based on XML files in APK packages. The second model, a Long Short-Term Memory (LSTM) model, detects more advanced malware by analyzing the semantic structures of Android bytecodes. The first model alone achieves 87.3% accuracy on a dataset of 110,440 apps.

#### B. DeepReﬁner Dataset
The original DeepReﬁner dataset includes 62,915 malicious and 47,525 benign applications collected from Google Play, VirusShare, and MassVet. We verified the dataset in June 2019 using VirusTotal, removing samples with different labels.

**Table VI: Evaluation of Differential Training with DeepReﬁner**

| **Metric** | **Value** |
|------------|-----------|
| Total Samples in the Whole Dataset | 110,440 |
| Benignware | 47,525 |
| Malware | 62,915 |
| Samples in Noisy Training Set | 88,352 |
| Number of Noises Added | 8,835 (10.00%) |
| True Positives Detected | 7,497 |
| Remaining Noises in Processed Dataset | 2,230 |
| False Positives Detected | 3,118 (3.53%) |
| F-score with Correctly-laballed Dataset | 93.59% |
| F-score with Noisily-laballed Dataset | 91.37% |
| F-score with Processed Dataset | 93.41% |

Differential Training correctly revised 7,497 wrong labels and mistakenly revised 2,230 correct labels, reducing 64.7% of the wrong labels and increasing the F-score from 91.37% to 93.41%, close to the F-score of 93.59% with the correctly-labeled dataset.

### D. Runtime Performance of Differential Training with DeepReﬁner
The total time cost for Differential Training with DeepReﬁner is approximately 102.12 hours, involving 77 iterations. Each iteration takes about 79.6 minutes on average, with 70.0 minutes for the WS model and 7.9 minutes for the DS model.

### VIII. THE IMPACT OF NOISE RATIO TO NOISE REDUCTION
Differential Training effectively reduces label noises at a 10% noise ratio across different datasets. To further investigate, we produced datasets with noise ratios of 5%, 10%, 15%, 20%, 30%, and 45%, and applied Differential Training to these datasets.

**Table VII: Noise Reduction on SDAC Dataset at Different Noise Ratios**

| **Noise Ratio** | **Training Set Size** | **Wrongly-labeled Samples** | **True Positives Detected** | **False Positives Detected** | **Noise Reduced (%)** | **Remaining Wrongly-labeled Samples** |
|-----------------|-----------------------|------------------------------|-------------------------------|--------------------------------|------------------------|--------------------------------------|
| 5%              | 56,550                | 2,833                        | 2,540                         | 281                            | 79.73%                 | 574                                  |
| 10%             | 56,550                | 5,614                        | 5,246                         | 343                            | 87.34%                 | 711                                  |
| 15%             | 56,550                | 8,497                        | 7,977                         | 472                            | 88.33%                 | 992                                  |
| 20%             | 56,550                | 11,330                       | 10,465                        | 377                            | 89.04%                 | 1,242                                |
| 30%             | 56,550                | 16,995                       | 15,762                        | 655                            | 88.89%                 | 1,888                                |
| 45%             | 56,550                | 25,493                       | 21,858                        | 4,500                          | 68.09%                 | 8,635                                |

These results show that Differential Training is effective in reducing noise, even at high noise ratios.