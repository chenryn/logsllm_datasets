title:Blind Seer: A Scalable Private DBMS
author:Vasilis Pappas and
Fernando Krell and
Binh Vo and
Vladimir Kolesnikov and
Tal Malkin and
Seung Geol Choi and
Wesley George and
Angelos D. Keromytis and
Steven M. Bellovin
2014 IEEE Symposium on Security and Privacy
Blind Seer: A Scalable Private DBMS
Vladimir Kolesnikov†, Tal Malkin∗, Seung Geol Choi‡, Wesley George§, Angelos Keromytis∗, Steven Bellovin∗
∗ Columbia University, {vpappas,binh,fkrell,smb,angelos,tal}@cs.columbia.edu
Vasilis Pappas∗, Fernando Krell∗, Binh Vo∗,
†Bell Labs, PI:EMAIL
§University of Toronto, PI:EMAIL
‡US Naval Academy, PI:EMAIL
Abstract—Query privacy in secure DBMS is an important
feature, although rarely formally considered outside the theoret-
ical community. Because of the high overheads of guaranteeing
privacy in complex queries, almost all previous works addressing
practical applications consider limited queries (e.g., just keyword
search), or provide a weak guarantee of privacy.
In this work, we address a major open problem in private
DB: efﬁcient sublinear search for arbitrary Boolean queries. We
consider scalable DBMS with provable security for all parties,
including protection of the data from both server (who stores
encrypted data) and client (who searches it), as well as protection
of the query, and access control for the query.
We design, build, and evaluate the performance of a rich
DBMS system, suitable for real-world deployment on today
medium- to large-scale DBs. On a modern server, we are able to
query a formula over 10TB, 100M-record DB, with 70 searchable
index terms per DB row,
in time comparable to (insecure)
MySQL (many practical queries can be privately executed with
work 1.2-3 times slower than MySQL, although some queries are
costlier).
We support a rich query set, including searching on arbitrary
boolean formulas on keywords and ranges, support for stemming,
and free keyword searches over text ﬁelds.
We identify and permit a reasonable and controlled amount of
leakage, proving that no further leakage is possible. In particular,
we allow leakage of some search pattern information, but protect
the query and data, provide a high level of privacy for individual
terms in the executed search formula, and hide the difference
between a query that returned no results and a query that
returned a very small result set. We also support private and
complex access policies, integrated in the search process so that
a query with empty result set and a query that fails the policy
are hard to tell apart.
I. INTRODUCTION
Motivation. Over the last two decades, the amount of data
generated, collected, and stored has been steadily increas-
ing. This growth is now reaching dramatic proportions and
touching every aspect of our life, including social, political,
commercial, scientiﬁc, medical, and legal contexts. With the
rise in size, potential applications and utility of these data,
privacy concerns become more acute. For example, the recent
revelation of the U.S. Government’s data collection programs
reignited the privacy debate.
We address the issue of privacy for database management
systems (DBMS), where the privacy of both the data and
the query must be protected. As an example, consider the
scenario where a law enforcement agency needs to search
© 2014, Vasilis Pappas. Under license to IEEE.
DOI 10.1109/SP.2014.30
359
airline manifests for speciﬁc persons or patterns. Because of
the classiﬁed nature of the query (and even of the existence of
a matching record), the query cannot be revealed to the DB.
With the absence of truly reliable and trusted third parties,
today’s solution, supported by legislation, is to simply require
the manifests and any other permitted data to be furnished
to the agency. However, a solution that allows the agency to
ask for and receive only the data it is interested in (without
revealing its interest), would serve two important goals:
• allay the negative popular sentiment associated with large
personal data collection and management which is not
publicly accounted.
• enhance agencies’ ability to mine data, by obtaining
permission to query a richer data set that could not be
legally obtained in its entirety.
In particular, we implement external policy enforcement on
queries, thus preventing many forms of abuse. Our system
allows an independent oblivious controller to enforce that
metadata queries satisfy the speciﬁcity requirement.
Other motivating scenarios are abundant, including private
queries over census data, information sharing between law
enforcement agencies (especially across jurisdictional and na-
tional boundaries) and electronic discovery in lawsuits, where
parties have to turn over relevant documents, but don’t want to
share their entire corpus [33], [43]. Often in these scenarios
the (private) query should be answered only if it satisﬁes a
certain (secret) policy. A very recent motivating example [3]
involves the intended use of data from automated license plate
readers in order to solve crimes, and the concerns over its use
for compromising privacy for the innocent.
While achieving full privacy for these scenarios is possible
building on cryptographic tools such as SPIR [24], FHE [21],
ORAM [27] or multiparty computation (MPC), those solutions
either run in polynomial time, or have very expensive basic
steps in the sublinear algorithms. For example, when ORAM
is used to achieve sublinear secure computation between two
parties [29], its basic step involves oblivious PRF evaluation.
[29] reports that it takes about 1000 seconds to run a binary
search on 220 entries; subsequent works [22], [39] remain too
expensive for our setting. On the other hand, for data sets of
moderate or large sizes, even linear computation is prohibitive.
This motivates the following.
Design goals. Build a secure and usable DBMS system,
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:22 UTC from IEEE Xplore.  Restrictions apply. 
with rich functionality, and performance very close to existing
insecure implementations, so as to maintain the current modus
operandi of potential users such as government agencies and
commercial organizations. At the same time, we must provide
reasonable and provable privacy guarantees for the system.
These are the hard design requirements which we achieve
with Blind Seer (BLoom ﬁlter INDex SEarch of Encrypted
Results). Our work can be seen as an example of apply-
ing cryptographic rigor to design and analysis of a large
system. Privacy/efﬁciency trade-offs are inherent
in many
large systems. We believe that the analysis approach we take
(identifying and permitting a controlled amount of leakage,
and proving that there is no additional leakage) will be useful
in future secure systems.
Signiﬁcance. We solve a signiﬁcant open problem in private
DB: efﬁcient sublinear search for arbitrary Boolean queries.
While private keyword-search was achieved in some models,
this did not extend to general Boolean formulas. Natural break-
ing of a formula to terms and individual keyword-searching
of each leaks formula structure and encrypted results for each
keyword, signiﬁcantly compromising privacy of both query
and data. Until our work, and the (very different) independent
and concurrent works [11], [31], it was not known how to
efﬁciently avoid this leakage. (See Section IX for extended
discussion on related work.)
A. Our Setting
Traditionally, DB querying is seen as a two-player engage-
ment: the client queries the server operated by the data owner,
although delegation of the server operation to a third player is
increasingly common.
Players. In our system, there are three main players: client C,
server S, and index server IS (there is another logical entity,
query checker QC, whose task of private query compliance
checking is technically secondary, albeit practically important.
For generality, we consider QC as a separate player, although
its role is normally played by either S or IS). We split off
IS from S mainly for performance reasons, as two-player
private DBMS querying has trivial linear in DB size lower
bounds1, while three non-colluding players allow for far better
privacy-performance trade-offs. We note also that our system
can be generalized to handle multiple clients in several ways
(presenting different trade-offs), but we focus our presentation
on the single client setting.
Allowed leakage. The best possible privacy for us would
guarantee that C learns only the result set, and IS and S
learn nothing at all. However, achieving this would be quite
costly, and almost certainly far too expensive as a replacement
for any existing DBMS. Indeed, practically efﬁcient equality
checking of encrypted data would likely require the use deter-
ministic encryption, which allows to identify and accumulate
access patterns. Additionally, for certain conjunctive queries,
1This lower bound can be circumvented if we allow precomputation, as
done for example in the ORAM based schemes mentioned above. However,
the resulting solution is far too inefﬁcient for practice, as even its online phase
is several orders of magnitude slower than our solution.
360
sublinear search algorithms are currently unknown, even for
insecure DBMS. Thus, unless we opt for a linear time for all
conjunctive queries, the running time already inevitably reveals
some information (see Section VI-B for more discussion).
As a result, we accept
that certain minimal amount of
leakage is unavoidable. In particular, we allow players C and IS
to learn certain search pattern information, such as the pattern
of returned results, and the traversal pattern of the encrypted
search tree. We stress that we still formally prove security of
the resulting system – our simulators of players’ views are
given the advice corresponding to the allowed leakage. We
specify the allowed leakage in more detail in Section VI.
We note that this work was performed under the IARPA
SPAR program [1]. Many of the privacy and functionality re-
quirements we address are suggested by IARPA. In Section X
we provide further motivation, examples and discussion of our
setting and choices.
B. Our Contributions
We design, prove secure, implement and evaluate the ﬁrst scal-
able privacy-preserving DBMS which simultaneously satisﬁes
all the following features (see the following sections for a more
complete description and comparison to previous works):
• Rich functionality: we support a rich set of queries
including arbitrary Boolean formulas, ranges, stemming,
and negations, while hiding search column names and
including free keyword searches over text ﬁelds in the
database. We note that
there is no standard way in
MySQL to obtain the latter.
• Practical
scalability. Our performance (similarly to
MySQL) is proportional to the number of terms in the
query and to the result set size for the CNF term with
the smallest number of results.
For a DB of size 10TB containing 100M records with 70
searchable index terms per DB row, our system executes
many types of queries that return few results in well under
a second, which is comparable to MySQL.
• Provable security. We guarantee the privacy of the data
from both IS and C, as well as the privacy of C’s query
from S and IS. We prove security with respect to well
deﬁned, reasonable, and controlled leakage. In particular,
while certain information about search patterns and the
size of the result set is leaked, we do provide some
privacy of the result set size, suited for the case when
identifying that there is one result as opposed to zero
results is undesirable (Section V-B).
• Natural integration of private policy enforcement. We
represent policies as Boolean circuits over the query, and
can support any policy that depends only on the query,
with performance that depends on the policy circuit size.
• Support for DB updates, deletions and insertions.
To our knowledge the combination of performance, features
and provable security of our system has never been achieved,
even without implementation, and represents a breakthrough
in private data management. Indeed, previous solutions either
require at least linear work, address a more limited type of
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:22 UTC from IEEE Xplore.  Restrictions apply. 





"

	




!













	

 





Figure 1. High-level overview of Blind Seer. There are three different
operations depicted: preprocessing (step 0), database searching (step 1-4) and
data modiﬁcations (step 5).
queries (e.g., just keyword search), or provide weaker privacy
guarantees. The independent and concurrent work of [11], [31]
(also performed under IARPA SPAR program) is the only
system comparable to ours, in the sense that it too features a
similar combination of rich functionality, practical scalability,
provable security, and policy enforcement. However, the trade
offs that they achieve among these requirements and their
technical approach are quite different than ours.
Our scale captures moderate-to-large data, which encom-
passes datasets in the motivating scenarios above (such as the
census data, on which we ran our evaluation), and represents
a major step towards privacy for truly “big data”. Our work
achieves several orders of magnitude performance improve-
ment as compared to the fully secure cryptographic solution,
and much greater functionality and privacy as compared to
practical single keyword search and heuristic solutions.
II. SYSTEM DESIGN OVERVIEW
Participants. Recall, our system consists of four participants:
server S, client C, index server IS, and query checker QC.
The server owns a database DB, and provides its encrypted
searchable copy to IS, who obliviously services C’s queries.
QC, a logical player who can be co-located with and may
often be an agent of S, privately enforces a policy over the
query. This is needed to ensure control over hidden queries
from C. Player interaction is depicted in Figure 1.