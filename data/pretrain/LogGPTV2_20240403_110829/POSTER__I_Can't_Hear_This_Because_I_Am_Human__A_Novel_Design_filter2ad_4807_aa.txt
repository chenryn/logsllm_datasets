title:POSTER: I Can't Hear This Because I Am Human: A Novel Design
of Audio CAPTCHA System
author:Jusop Choi and
Taekkyung Oh and
William Aiken and
Simon S. Woo and
Hyoungshick Kim
POSTER: I Can’t Hear This Because I Am Human: A Novel
Design of Audio CAPTCHA System
Jusop Choi
Sungkyunkwan University
Suwon, South Korea
PI:EMAIL
Taekkyung Oh
Sungkyunkwan University
Suwon, South Korea
PI:EMAIL
William Aiken
Sungkyunkwan University
Suwon, South Korea
PI:EMAIL
Simon S. Woo
SUNY-Korea/Stony Brook University
Songdo, South Korea
PI:EMAIL
Hyoungshick Kim
Sungkyunkwan University
Suwon, South Korea
PI:EMAIL
ABSTRACT
A CAPTCHA (Completely Automated Public Turing test to tell
Computers and Humans Apart) provides the first line of defense
to protect websites against bots and automatic crawling. Recently,
audio-based CAPTCHA systems are started to use for visually im-
paired people in many internet services. However, with the recent
improvement of speech recognition and machine learning system,
audio CAPTCHAs have come to struggle to distinguish machines
from users, and this situation will likely continue to worsen. Unlike
conventional CAPTCHA systems, we propose a new conceptual
audio CAPTCHA system, combining certain sound, which is only
understandable by a machine. Our experiment results demonstrate
that the tested speech recognition systems always provide correct
responses for our CAPTCHA samples while humans cannot pos-
sibly understand them. Based on this computational gap between
the human and machine, we can detect bots with their correct
responses, rather than their incorrect ones.
CCS CONCEPTS
• Security and privacy → Web application security; • Computing
methodologies → Speech recognition; Neural networks;
KEYWORDS
CAPTCHA; machine learning; speech recognition; bot
ACM Reference Format:
Jusop Choi, Taekkyung Oh, William Aiken, Simon S. Woo, and Hyoungshick
Kim. 2018. POSTER: I Can’t Hear This Because I Am Human: A Novel Design
of Audio CAPTCHA System. In ASIA CCS ’18: 2018 ACM Asia Conference on
Computer and Communications Security, June 4–8, 2018, Incheon, Republic of
Korea. , 3 pages. https://doi.org/10.1145/3196494.3201590
1 INTRODUCTION
A Completely Automated Public Turing test to tell Computers and
Human Apart system (CAPTCHA) [9], is a tool to prevent the bot
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5576-6/18/06.
https://doi.org/10.1145/3196494.3201590
activities on the Internet by generating a challenge, which can
be solved with high probability by a human, but only with low
probability by a program. The most frequently used CAPTCHAs
have traditionally relied on distorted characters represented in a
noisy image, and they require users to input the answer (response)
that matches the same characters in the given image (challenge).
Audio-based CAPTCHA systems are mainly designed to assist
people with visual impairments, which prohibit them from solving
text-based CAPTCHAs. When a user clicks the headset icon but-
ton, reCATPCHA system pronounces letters and numbers in the
presence of background noise. Audio-based CAPTCHAs typically
present obfuscated speech challenge and require users to enter
spoken numbers, letters, or words response. Background noise or
other obfuscation effects are added to prevent automatic speech
recognition systems from automatically transcribing speech into
text. This is a main feature to thwart automated attack and provide
high-level security assurance in the audio-based CAPTCHAs.
Recently, however, attackers have developed several techniques
to automatically solve audio CAPTCHA challenges with high ac-
curacy. Tam et al. [7] implemented an automatic attack on Google,
Digg, reCATPCHA using classification techniques (AdaBoost, SVM
and k-NN) with key features such as MFCC (Mel-Frequency Cep-
stral Coefficients). For Google, Digg and reCAPTCHA, their attack
implementation achieved attack success rates of 67%, 71% and 45%,
respectively. Bock et al. [1] also developed unCaptcha which can
break Google’s reCAPTCHA. They used 6 conventional online
speech-to-text engines: Google Cloud1, Bing Speech Recognition2,
IBM Bluemix3, Google Speech API, Wit-AI4, and Sphinx5. They
adopted a phonetic mapping and broke reCAPTCHA with 85.15% ac-
curacy in 5.42 seconds, on average. Since Audio-based CAPTCHAs
primarily use digits and letters for their challenges, the training
space of machine-learning attack becomes smaller. As a result, ma-
chine learning techniques have a small search space to focus, and
can increase their success rate.
In this paper, we introduce a novel design of audio CAPTCHA
system, which generates a challenge, which can be recognized
with high probability by computer programs, but only with low
1https://cloud.google.com/speech/
2https://microsoft.com/cognitive-services/en-us/speech-api
3https://ibm.com/watson/developercloud/doc/speech-to-text/
4https://wit.ai/
5http://cmusphinx.sourceforge.net/wiki/
Poster SessionASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea833probability by humans. Actually, it is a reversal of the conventional
CAPTCHA concept. We use three audio generating techniques
(Inverse MFCC, mosaic, and neural network). We focus on a fact that
certain highly obfuscated sounds cannot be understood by a human
user, but can confidently be recognized by a machine. Using this fact,
we mix machine-only understandable sound into the CAPTCHA’s
audio test. To show the feasibility of this idea, we generated 50
CAPTCHA test sounds and tested with 10 human participants
and a popularly used speech recognition program named Deep
Speech [6]. In our experiments, Deep Speech correctly recognized
all challenges while all human participants failed to hear them.
This computational gap can be exploited to develop more effective
audio-based CAPTCHA systems.
Figure 1: Procedure of the proposed CAPTCHA system.
2 DESIGN OF NEW AUDIO CAPTCHA SYSTEM
We propose a new method to generate audio CAPTCHA chal-
lenges using several different techniques. Our goal is to generate
sound samples that fall into the following three distinct categories:
1) sound that only humans can identify (human-only audio), 2)
sound that only machines can identify (machine-only audio), and
3) sound that both humans and machines can identify (human-
machine-audio). Human-only audio is similar to current audio-
based CAPTCHAs, where speech is usually combined with some
type of noise. However, we try to generate human-only audio with
not only noise but also a variety of techniques.
The machine-only audio is a new conceptual sound, which con-
fuses speech recognition systems. This sound type is either inaudi-
ble or incomprehensible sound to humans, but is recognizable by
machines. Humans can pass this challenge, as they recognize that
the audio form is nonsense and can input a “wrong answer” or
input nothing at all. However, machines must not only decipher
the noise but also need to determine whether this audio is human-
understandable as well, thus increasing the defense space of the
CAPTCHAs.
We assume attackers use the open-source implementation of
Deep Speech [6]. The overview of the proposed CAPTCHA system
is described in Fig. 1. First, our system randomly selects k numbers
among three types of sounds as shown in Fig. 1. The sound samples
are randomly assigned, and then the generated sound is played to
the user. After receiving the answer from the user, our CAPTCHA
system checks how the user answers the given sound samples. If the
user correctly answers the human-only audio and human-machine
audio samples and incorrectly answers the machine-only audio
samples, then the system assumes the user is judged to be human.
This process is quite different from that of conventional CAPTCHA
systems that check whether the answer is correct.
1. Inverse MFCC: Speech recognition systems use MFCC to
convert the input audio to text. Vaidya et al. [8] generated machine-
only audio based on modified acoustic features extracted from the
input audio using MFCC to deceive the Siri on iPhone, and OK