title:Resource-freeing attacks: improve your cloud performance (at your
neighbor's expense)
author:Venkatanathan Varadarajan and
Thawan Kooburat and
Benjamin Farley and
Thomas Ristenpart and
Michael M. Swift
Resource-Freeing Attacks: Improve Your Cloud
Performance (at Your Neighbor’s Expense)
Venkatanathan Varadarajan, Thawan Kooburat, Benjamin Farley,
Thomas Ristenpart and Michael M. Swift
University of Wisconsin–Madison
{venkatv,farleyb,rist,swift}@cs.wisc.edu, PI:EMAIL
ABSTRACT
Cloud computing promises great efﬁciencies by multiplexing re-
sources among disparate customers. For example, Amazon’s Elas-
tic Compute Cloud (EC2), Microsoft Azure, Google’s Compute
Engine, and Rackspace Hosting all offer Infrastructure as a Ser-
vice (IaaS) solutions that pack multiple customer virtual machines
(VMs) onto the same physical server.
The gained efﬁciencies have some cost: past work has shown
that the performance of one customer’s VM can suffer due to inter-
ference from another. In experiments on a local testbed, we found
that the performance of a cache-sensitive benchmark can degrade
by more than 80% because of interference from another VM.
This interference incentivizes a new class of attacks, that we call
resource-freeing attacks (RFAs). The goal is to modify the work-
load of a victim VM in a way that frees up resources for the at-
tacker’s VM. We explore in depth a particular example of an RFA.
Counter-intuitively, by adding load to a co-resident victim, the at-
tack speeds up a class of cache-bound workloads. In a controlled
lab setting we show that this can improve performance of synthetic
benchmarks by up to 60% over not running the attack. In the nois-
ier setting of Amazon’s EC2, we still show improvements of up
to 13%.
Categories and Subject Descriptors
D.4.6 [Operating System]: Security and Protection; D.4.1 [Operating
System]: Process Management—scheduling; K.6.5 [Management
of Computing and Information System]: Security and Protec-
tion—physical security
General Terms
Economics, Experimentation, Measurement, Performance, Secu-
rity
Keywords
cloud computing, virtualization, scheduling, security, resource-freeing
attacks
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.
INTRODUCTION
1.
Cloud computing provides high efﬁciency in part by multiplexing
multiple customer workloads onto a single physical machine. For
example, Amazon’s Elastic Compute Cloud (EC2) [3] runs multi-
ple customer virtual machines (VMs) on a single host. For small
instances, they offer each guest VM roughly 40% of a single CPU
by time slicing. Similarly, access to the local disk, network, mem-
ory, and cache are all shared by virtual machines from multiple cus-
tomers.
However, with this efﬁciency comes performance interference.
When two customer applications share a machine, they contend for
access to resources. Existing hardware and software virtualization
mechanisms do not provide perfect performance isolation. For ex-
ample, running two applications that make heavy use of memory
bandwidth can degrade the performance of both. Past work has
demonstrated the existence and amount of this interference [5, 19].
As a result, there have been numerous proposals on how to con-
struct hypervisors or processors that better isolate customer appli-
cations from each other. For example, ﬁne-grained accounting of
CPU usage [12], network trafﬁc [28] or disk-queue utilization [11]
can decrease the amount of interference. Unfortunately, the inher-
ent tension between efﬁciency and isolation means that, in practice,
cloud computing systems continue to provide poor isolation. In ex-
periments on a local Xen [4] testbed, we show, for example, that
certain cache-sensitive workloads take 5x longer when contending
with other memory-intensive workloads.
Unlike in private data centers, such contention in public clouds
arises between disparate customers. Unique to the public cloud set-
ting, then, is the incentive for greedy customers to attempt to free up
resources for their application by interfering with other customers’
use of them. A clear-cut example would be a malicious customer
crashing co-resident VMs, but this requires knowledge of an ex-
ploitable vulnerability and would be easily detectable. We are in-
terested in whether there exist more subtle strategies for freeing up
resources.
We explore an approach based on two observations. First, appli-
cations are often limited by a single bottleneck resource, such as
memory or network bandwidth. Second, we observe that an appli-
cation’s use of resources can change unevenly based on workload.
For example, a web server may be network limited when serving
static content, but CPU limited when serving dynamic content.
A resource-freeing attack (RFA) leverages these observations to
improve a VM’s performance by forcing a competing VM to satu-
rate some bottleneck. If done carefully, this can slow down or shift
the competing application’s use of a desired resource. For example,
we investigate in detail an RFA that improves cache performance
when co-resident with a heavily used Apache web server. Greedy
users will beneﬁt from running the RFA, and the victim ends up
281paying for increased load and the costs of reduced legitimate traf-
ﬁc.
We begin this paper with a comprehensive study of the resource
interference exhibited by the Xen hypervisor in our local testbed.
In addition to testing for contention of a single resource, these re-
sults show that workloads using different resources can contend as
well, and that scheduling choices on multicore processors greatly
affect the performance loss. We then develop a proof-of-concept
resource-freeing attack for the cache-network contention scenario
described above.
In a controlled environment, we determine the
necessary conditions for a successful resource-freeing attack, and
show that average performance of a cache-sensitive benchmark can
be improved by as much as 212% when the two VMs always share
a single core, highlighting the potential for RFAs to ease cache con-
tention for the attacker. If VMs ﬂoat among all cores (the default
conﬁguration in Xen), we still see performance gains of up to 60%.
When applied to several SPEC benchmarks [13], whose more bal-
anced workloads are less effected by cache contention, RFAs still
provide beneﬁt: in one case it reduces the effect of contention by
66.5% which translated to a 6% performance improvement.
Finally, we show that resource-freeing attacks are possible in un-
controlled settings by demonstrating their use on Amazon’s EC2.
Using co-resident virtual machines launched under accounts we
control, we show that introducing additional workload on one vir-
tual machine can improve the performance of our cache-sensitive
benchmark by up to 13% and provides speedups for several SPEC
benchmarks as well.
2. SCHEDULING AND ISOLATION IN VIR-
TUALIZED ENVIRONMENTS
A key reason to use hypervisors in cloud computing is their ability
to provide performance isolation between customer applications.
Indeed, isolation was a primary goal for the original development
of the Xen hypervisor used in EC2 [4]. Perfect performance isola-
tion should guarantee that the behavior of one guest virtual machine
does not affect the performance of other guest virtual machines. To
this end, Xen and other virtual machine monitors (VMMs) focus
on fairly allocating CPU time and memory capacity [33]. How-
ever, other hardware resources such as memory bandwidth, cache
capacity, network, and disk have received less attention.
In order to understand the sources and effects of performance
interference, we describe the Xen hypervisor mechanisms and poli-
cies for sharing resources between guest virtual machines while still
providing performance isolation.
CPU. The Xen scheduler provides both fair-share allocation of
CPU and low-latency dispatch for I/O-intensive VMs. We use the
credit scheduler [7] in our experiments, as it is most commonly used
in deployments. The scheduler views VMs as a set of virtual CPUs
(VCPUs), and its task is to determine which VCPUs should be run
on each physical CPU at any given time.
The scheduler gives VCPUs credits at a pre-determined rate. The
credits represent a share of the CPU and provide access to the CPU.
Every 10 ms a periodic scheduler tick removes credits from the cur-
rently running VCPU and if it has none remaining, switches to the
next VCPU in the ready queue. VCPUs are given more credits pe-
riodically (typically every 30 ms). Thus, if a CPU-bound process
runs out of credit, it must suspend for up to 30 ms until it receives
new credits to run. A process that runs for short periods may never
run out of credit, although the total amount it can accrue is limited.
In order to support low-latency I/O, Xen implements a boost
mechanism that raises the priority of a VM when it receives an in-
terrupt, which moves it towards the head of the ready queue. This
allows it to preempt the running VM and respond to an I/O request
immediately. However, a VM that has run out of credits cannot
receive boost. The boost mechanism is a key component of the
resource-freeing attack we introduce in Section 5.
The credit scheduler supports a work-conserving mode, in which
idle CPU time is distributed to runnable VMs, and a non-work-
conserving mode, in which VMs’ CPU time is capped. The lat-
ter mode reduces efﬁciency but improves performance isolation.
Though Amazon does not report which mode it uses, our experi-
ments indicate that EC2 uses non-work-conserving scheduling.
On a multiprocessor, Xen can either ﬂoat VPCUs, letting them
execute on any CPU, or pin them to particular CPUs. When ﬂoat-
ing, Xen allows a VCPU to run on any CPU unless it ran in the
last 1 ms, in which case it is rescheduled on the same core to main-
tain cache locality. We determined experimentally that EC2 allows
VCPUs to ﬂoat across cores.
Memory. Xen isolates memory access primarily by controlling the
allocation of memory pages to VMs. In cloud settings, Xen is often
conﬁgured to give each VM a static number of pages. It does not
swap pages to disk, actively manage the amount of memory avail-
able to each VM, or use deduplication to maximize use of mem-
ory [33]. Furthermore, x86 hardware does not provide the ability
to enforce per-VCPU limits on memory bandwidth or cache usage.
Hence, these are not managed by Xen.
Devices. By default, Xen seeks fair sharing of disk and network by
processing batches of requests from VMs in round-robin order [4].
For disks, this can lead to widely varying access times, as sets of
random requests may incur a longer delay than sequential accesses.
The Xen default is to make device scheduling work conserving, so
performance can also degrade if another VM that was not using a
device suddenly begins to do so. However, we observe that EC2 sets
caps on the network bandwidth available to an m1.small instance at
around 300 Mbps, but does not cap disk bandwidth.
3. RESOURCE-FREEING ATTACKS
The interference encountered between VMs on public clouds moti-
vates a new class of attacks, which we call resource-freeing attacks
(RFAs). The general idea of an RFA is that when a guest virtual
machine suffers due to performance interference, it can affect the
workload of other VMs on the same physical server in a way that
improves its own performance.
Attack setting. We consider a setting in which an attacker VM
and one or more victim VMs are co-resident on the same physical
server in a public cloud. There may be additional co-resident VMs
as well. It is well known that public clouds make extensive use of
multi-tenancy.
The RFAs we consider in Section 5 assume that the victim is run-
ning a public network service, such as a web server. This is a fre-
quent occurrence in public clouds. Measurements in 2009 showed
that approximately 25% of IP addresses in one portion of EC2’s
address space hosted a publicly accessible web server [25].
Launching RFAs that exploit a public network service require
that the attacker knows with whom it is co-resident. On many
clouds this is straightforward: the attacker can scan nearby internal
IP addresses on appropriate ports to see if there exist public network
services. This was shown to work in Amazon EC2, where for exam-
ple m1.small co-resident instances had internal IP addresses whose
numerical distance from an attacker’s internal IP address was at
most eight [25]. Furthermore, packet round-trip times can be used
to verify co-residence. We expect that similar techniques work on
other clouds, such as Rackspace.
282The attacker seeks to interfere with the victim(s) to ease con-
tention for resources on the node or nearby network. The attacker
consists of two logical components, a beneﬁciary and a helper. The
beneﬁciary is the application whose efﬁciency the attacker seeks to
improve. The helper is a process, either running from within the
same instance or on another machine, that the attacker will use to
introduce new workload on the victim. Without loss of generality,
we will describe attacks in terms of one victim, one beneﬁciary, and
one helper.
We assume the beneﬁciary’s performance is reduced because of
interference on a single contended resource, termed the target re-
source. For example, a disk-bound beneﬁciary may suffer from
competing disk accesses from victim VMs.
Conceptual framework. The beneﬁciary and the helper work to-
gether to change the victim’s resource consumption in a manner that
frees up the target resource. This is done by increasing the time the
victim spends on one portion of its workload, which limits its use
of other resources.
There are two requirements for an RFA. First, an RFA must raise
the victim’s usage of one resource until it reaches a bottleneck.
Once in a bottleneck, the victim cannot increase usage of any re-
sources because of the bottleneck. For example, once a web server
saturates the network, it cannot use any more CPU or disk band-
width. However, simply raising the victim to a bottleneck does not
free resources; it just prevents additional use of them. The second
requirement of an RFA is to shift the victim’s resource usage so
that a greater fraction of time is spent on the bottleneck resource,
which prevents spending time on other resources. Thus, the bot-
tleneck resource crowds out other resource usage. As an example,
a web server may be sent requests for low-popularity web pages
that cause random disk accesses. The latency of these requests may
crowd requests for popular pages and overall reduce the CPU usage
of the server.
There are two shifts in target resource usage that can help the
beneﬁciary. First, if the victim is forced to use less of the resource,
then there may be more available for the beneﬁciary. Second, even
if the victim uses the same amount of the resource, the accesses may
be shifted in time. For example, shifting a victim’s workload so that
cache accesses are consolidated into fewer, longer periods can aid
the beneﬁciary by ensuring it retains cache contents for a larger
percentage of its run time. A similar effect could be achieved for
resources like the hard disk if we are able to provide the beneﬁciary
with longer periods of uninterrupted sequential accesses.
Modifying resource consumption. The helper modiﬁes the vic-
tim’s resource usage and pushes it to overload a bottleneck resource.
This can be done externally, by introducing new work over the net-
work, or internally, by increasing contention for other shared re-
sources.
A helper may introduce additional load to a server that both in-
creases its total load and skews its workload towards a particular re-
source. The example above of requesting unpopular content skews
a web server’s resource usage away from the CPU towards the disk.
This can create a bottleneck at either the server’s connection limit
or disk bandwidth. Similarly, the helper may submit CPU-intensive
requests for dynamic data that drive up the server’s CPU usage until
it exceeds its credit limit and is preempted by the hypervisor.
The helper can also affect performance by increasing the load on
other contended resources. Consider again a web server that makes
use of the disk to fetch content. A helper running in the beneﬁ-
ciary’s instance can introduce unnecessary disk requests in order to
degrade the victim’s disk performance and cause the disk to become
a bottleneck. Similarly, the helper could slow the victim by intro-
Xen Version
Xen Scheduler
OS
Dom0
DomU
Network
Disk
4.1.1
Credit Scheduler 1
Fedora 15, Linux 2.6.40.6-0.fc15
4 VCPU / 6 GB memory / no cap / weight 512
8 instances each with 1 VCPU / 1 GB mem-
ory / 40% cap / weight 256
Bridging via Dom0
5 GB LVM disk partition of a single large
disk separated by 150GB
Figure 1: Xen conﬁguration in our local testbed.
ducing additional network trafﬁc that makes network bandwidth a
bottleneck for the server.
There exist some obvious ways an attacker might modify the
workload of a victim. If the attacker knows how to remotely crash
the victim via some exploitable vulnerability, then the helper can
quite directly free up the target resource (among others). However
this is not only noisy, but requires a known vulnerability. Instead,
we focus on the case that the attacker can affect the victim only
through use (or abuse) of legitimate APIs.
Example RFA. As a simple example of an RFA, we look at the
setting of two web servers, running in separate VMs on the same
physical node, that compete for network bandwidth. Assume they
both serve a mix of static and dynamic content. Under similar loads,
a work-conserving network scheduler will fairly share network ca-
pacity and give each web server 50% (indeed, our experiment show
that Xen does fairly share network bandwidth).
However, if we introduce CPU-intensive requests for dynamic
content to one web server that saturate the CPU time available to the
server, we ﬁnd that the other server’s share of the network increases
from 50% to 85%, because there is now less competing trafﬁc. We
note that this requires a work-conserving scheduler that splits ex-
cess network capacity across the VMs requesting it. A non-work
conserving scheduler would cap the bandwidth available to each
VM, and thus a decline in the use by one VM would not increase