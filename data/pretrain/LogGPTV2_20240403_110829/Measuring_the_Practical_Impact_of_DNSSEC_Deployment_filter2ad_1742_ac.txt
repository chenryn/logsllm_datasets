0.7539% - 0.8166%
0.9716% - 1.042%
2.649% - 2.672%
Table 4: Failure rates for each class of test re-
source.
raw failure rates across each class of test resource,
where the failure rate is deﬁned as one minus the
quotient of the number of successful test resource
loads and the number of attempted resource loads
across all UUIDs for which we received a comple-
tion signal. This table is suﬃcient to draw some
initial conclusions. First, as evidenced by the low
failure rate of badsec domains the vast majority of
end hosts and their recursive resolvers do not per-
form DNSSEC validation.
If all end hosts or re-
cursive resolvers veriﬁed DNSSEC, we would expect
a badsec failure rate of 100%,
instead of the ob-
served value of 2.661%. Thus, the increased security
value of DNSSEC-signing a domain is relatively low,
as most resolvers will not detect tampering against
DNSSEC-signed domains.
Second, DNSSEC-signed domains—even validly
signed domains—have a higher failure rate than non-
DNSSEC-signed domains:
just DNSSEC-signing
a domain increases the failure rate from around
7
USENIX Association  
22nd USENIX Security Symposium  579
Experiment Loading Dropoff
5
0
+
e
8
5
0
+
e
6
5
0
+
e
4
i
s
n
o
s
s
e
r
p
m
i
f
o
r
e
b
m
u
N
5
0
+
e
2
0
0
+
e
0
0
0
1
0
9
0
8
0
7
0
6
0
5
0
4
0
3
0
2
0
1
0
i
s
n
o
s
s
e
r
p
m
i
%
nosec
goodsec
badsec
e
t
a
r
e
r
u
l
i
a
F
5
3
0
.
0
0
3
0
.
0
5
2
0
.
0
0
2
0
.
0
5
1
0
.
0
0
1
0
.
0
5
0
0
.
0
Static ad Measurement
page
Driver
script
Completion
AfriNIC
APNIC
ARIN
Regional Internet Registry
LACNIC
RIPE
Figure 6: Plot of UUIDs that reached each stage
of the experiment.
Figure 7: Failure rates broken down by resolver
IP RIR. Error bars indicate a 95 percent binomial
proportion conﬁdence interval.
0.7846% to 1.006% (though this value is very sen-
sitive to geographic factors, as discussed in the fol-
lowing section). While this is not a huge diﬀerence,
it must be compared to the detection rate of bad do-
mains, which is also very small. Moreover, because
resolvers which cannot process DNSSEC at all ap-
pear to “detect” bogus DNSSEC records, the badsec
failure rate in Table 4 is actually an overestimate of
clients behind DNSSEC-validating resolvers, which
is probably closer to 1.655% (the diﬀerence between
the badsec and goodsec rates).
4.1.1 Geographic Eﬀects
As mentioned above, the raw numbers are somewhat
misleading because the failure rates are very geo-
graphically dependent. In order to explore this de-
pendence we categorized each test case (UUID) by
geographic area based on the resolver IP observed
performing resolution for a domain containing the
UUID.6 We used the CAIDA preﬁx-to-AS mapping
dataset [11] to determine the Autonomous System
Number (ASN) for each for client’s resolver IP ad-
dress and then assigned each client to the Regional
Internet Registry (RIR) which is responsible for that
AS, as listed in Table 5.
6If there was more than one resolver associated with a
particular UUID, our analytics package chose one arbitrar-
ily during the process of merging the records. If we restrict
our analysis to clients which only use one resolver, the overall
error rate goes down, but our results are qualitatively simi-
lar, with the error rates being 0.0046, 0.0055, and 0.0119, for
nosec, goodsec, and badsec, respectively.
As shown in Figure 7, resolution failure rates vary
widely by region, as does the diﬀerence in resolution
rates between nosec, goodsec, and badsec. In partic-
ular, while all ﬁve regions show a signiﬁcant diﬀer-
ence (2-proportion z-test, p < 0.0001) between ag-
gregate badsec-domain outcomes and nosec & good-
sec outcomes, only APNIC (Asia Paciﬁc) shows
a signiﬁcant diﬀerence between nosec and goodsec
(McNemar’s test, p < 0.0001). While AfriNIC
(Africa) shows a qualitative diﬀerence, we do not
have enough data points to determine whether it is
statistically signiﬁcant. Note that in general APNIC
seems to have an elevated resolution failure rate;
LACNIC (Latin America) does as well but still does
not show a signiﬁcant diﬀerence between nosec and
goodsec. We drilled down into the resolvers responsi-
ble for anomalous failure rates and present our ﬁnd-
ings in Sections 4.1.3, & 4.1.4.
4.1.2 The Impact of Packet Size and TCP
Fallback
One commonly-expressed concern with DNSSEC is
that it increases the size of DNS responses and, con-
sequently, failure rates. Ordinarily, DNS requests
and responses are carried over UDP, which limits
the maximum size of the responses. DNS has two
mechanisms to allow responses larger than the 512-
byte limit deﬁned in RFC 1035 [33]:
• Resolution can fall back to TCP if the server
supports it.
580  22nd USENIX Security Symposium 
USENIX Association
8
Name
Abbreviation Frequency Percentage
African Network Information Centre
American Registry for Internet Numbers
Asia-Paciﬁc Network Information Centre
Latin America and Caribbean Network Information Centre
R´eseaux IP Europ´eens Network Coordination Centre
Unclassiﬁable
AfriNIC
ARIN
APNIC
LACNIC
RIPE NCC
10,914
75,577
200,366
62,925
179,492
20
2.062%
14.28%
37.86%
11.89%
33.91%
< 0.001%
Table 5: Table listing the 5 Regional Internet Registries (RIRs). The Frequency and Percentage columns
indicate the number and relative prevalence of UUIDs for which at least one DNS query originated from each
region.
Failure rates vs. Transport Protocol
UDP
TCP
nosec
goodsec
badsec
e
t
a
r
e
r
u
l
i
a
F
6
0
.
0
5
0
0
.
4
0
0
.
3
0
0
.
2
0
0
.
1
0
0
.
0
0
0
.
Figure 8: Failure rates broken down by DNS trans-
port protocol. Error bars indicate a 95 percent bi-
nomial proportion conﬁdence interval.
• Clients can advertise a larger maximum UDP
datagram size via the EDNS0 OPT pseudo-
RR [39].
Unfortunately, both of these mechanisms can cause
problems for some intermediaries [7, 8, 10]. Because
the resolver behavior is observable on the server, we
can directly measure the impact of these strategies
on test resource load failures.
In order to look more closely at these eﬀects, we
ﬁrst ﬁltered out the data for the 4,739,669 (33.25%)
lookup requests we received which did not have the
DNSSEC OK ﬂag set. The DNSSEC OK ﬂag an-
nounces the query source’s willingness to receive
DNSSEC RRs, and thus when it is not set, our
resolver simply sends the requested records with-
out the DNSSEC RRs.7 Non-DNSSEC OK lookups
for DNSSEC resources appear to have similar suc-
cess rates to nosec resources. Out of the remaining
9,516,394 (66.75%) transactions where DNSSEC OK
was indicated, 4.22% of goodsec and 4.064% of badsec
lookups fell back to TCP. These TCP lookups had
dramatically higher failure rates: 6.011% for good-
sec and 6.531% for badsec compared to 0.6742% for
goodsec and 3.249% for badsec when UDP was used.
For nosec, resolution never fell back to TCP, and the
failure rate of 0.6% 8. was similar to that for goodsec
with UDP. Figure 8 summarizes these ﬁndings.
The similar UDP failure rates for nosec and good-
sec suggest that it is the TCP fallback that results
from DNSSEC’s increased response sizes, and not
the bigger responses themselves, that is the major
contributor to the elevated goodsec failure rate.
TCP fallback in the DNS resolution for one com-
ponent of a web page can have a negative impact on
the load rate of other components on the page, even
if their DNS lookups do not themselves fall back to
TCP. If we partition the UUIDs into those that fall
back to TCP for at least one test resource and those
that never fall back to TCP, we ﬁnd that the nosec
failure rates are 1.0791% for the former and 0.7617%
for the latter. We have not explored these eﬀects in
detail, but it seems likely that the failed resolution
slows down the retrieval of the rest of the resources,
thus causing failures.
We also found that accurate path MTU prediction
is crucial for maintaining high resolution success.
For 13,623 test resources (0.0953% of the 14,291,174
total), we observed that recursive resolvers overesti-
mated the UDP path MTU, advertised an inﬂated
7If multiple queries were present we considered the
DNSSEC OK ﬂag to be set if any of the queries had it. 2.771%
of test resources exhibited variation in this ﬂag.
8This nosec failure rate is lower than the one found in
Table 4 because, to be consistent with the goodsec and badsec
failure rate calculations in this section, it excludes failed test
resource loads for which we did not observe a DNS lookup
attempt.
USENIX Association  
22nd USENIX Security Symposium  581
9
value via EDNS0, and subsequently had to retry the
lookup with a smaller advertised value. Test re-
sources whose lookups included this path MTU dis-
covery behavior failed to load 14.09% of the time
compared to 2.519% for those that did not.
4.1.3 Case Study:
badsec-b8 validation
anomaly
We compared the failure rates of the badsec domains
and observed that the badsec-b8 variant exhibited
a signiﬁcantly lower failure rate (1.480%) than all
other badsec types (McNemar’s test applied pair-
wise against each other badsec variant, p < 0.01). In
badsec-b8, we simulated an invalid DNSKEY RRSIG
RR by incrementing the labels ﬁeld of the RR data
and signing it with a correctly-authenticated key.
The labels ﬁeld in an RRSIG RR is used for match-
ing RRSIGs to the RRsets they authenticate when
wildcards are involved. For example, if a zone de-
clares the *.foo.com wildcard name, then RRSIGs
for the RRsets of names matching *.foo.com (e.g.,
www.foo.com) would have a labels ﬁeld value of 2.
Section 5.3.1 of RFC 4035 [5] stipulates that an
RRSIG RR must have a labels ﬁeld value less than
or equal to the number of labels in the owner name
of the RRset that it authenticates.
To identify resolvers responsible for this valida-
tion anomaly, we ﬁrst partitioned the set of UUIDs
by the IP address of the resolver associated with