title:A measurement study on the impact of routing events on end-to-end
internet path performance
author:Feng Wang and
Zhuoqing Morley Mao and
Jia Wang and
Lixin Gao and
Randy Bush
A Measurement Study on the Impact of Routing Events on
End-to-End Internet Path Performance
Feng Wang
University of Mass., Amherst
PI:EMAIL
Zhuoqing Morley Mao
University of Michigan
PI:EMAIL
Jia Wang
AT&T Labs-Research
PI:EMAIL
Lixin Gao
University of Mass., Amherst
PI:EMAIL
Randy Bush
Internet Initiative Japan
PI:EMAIL
ABSTRACT
Extensive measurement studies have shown that end-to-end Inter-
net path performance degradation is correlated with routing dynam-
ics. However, the root cause of the correlation between routing
dynamics and such performance degradation is poorly understood.
In particular, how do routing changes result in degraded end-to-
end path performance in the ﬁrst place? How do factors such as
topological properties, routing policies, and iBGP conﬁgurations
affect the extent to which such routing events can cause perfor-
mance degradation? Answers to these questions are critical for im-
proving network performance.
In this paper, we conduct extensive measurement that involves
both controlled routing updates through two tier-1 ISPs and active
probes of a diverse set of end-to-end paths on the Internet. We
ﬁnd that routing changes contribute to end-to-end packet loss sig-
niﬁcantly. Speciﬁcally, we study failover events in which a link
failure leads to a routing change and recovery events in which a
link repair causes a routing change. In both cases, it is possible
to experience data plane performance degradation in terms of in-
creased long loss burst as well as forwarding loops. Furthermore,
we ﬁnd that common routing policies and iBGP conﬁgurations of
ISPs can directly affect the end-to-end path performance during
routing changes. Our work provides new insights into potential
measures that network operators can undertake to enhance network
performance.
Categories and Subject Descriptors
C.2.2 [Computer-Communication Networks]: Network Proto-
cols—Routing protocols; C.4 [Performance of Systems]: Relia-
bility, availability, and serviceability
General Terms
Measurement, Experimentation, Reliability
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’06, September 11–15, 2006, Pisa, Italy.
Copyright 2006 ACM 1-59593-308-5/06/0009 ...$5.00.
Keywords
Routing dynamics, BGP, active probing, failover event, recovery
event, packet loss, packet reordering
1.
INTRODUCTION
The deployment of interactive services such as VoIP and gaming
on the Internet demands the network to maintain good end-to-end
performance. Previous studies have shown that end-to-end perfor-
mance on the Internet is unpredictable [20], and degraded end-to-
end path performance is correlated with routing dynamics [15, 23,
6, 16, 19, 1]. Yet the causal relationship between routing changes
and degraded data plane performance has not been established. In
particular, very little is known about (1) how routing changes re-
sult in degraded end-to-end path performance in the ﬁrst place, and
(2) how factors such as topological properties, routing policies, and
iBGP conﬁgurations affect the extent to which such routing events
can cause performance degradation. The Internet is a system of
immense scale. Routing events such as link failures or link repairs
happen quite frequently as indicated by high volumes of routing
updates [19, 17]. Answers to the above questions are critical for
improving network performance and wide deployment of interac-
tive services in the Internet.
So far, researchers have taken either the analytical approach or
the measurement approach to understanding the impact of routing
events on end-to-end performance. Neither can answer the above
questions satisfactorily. In the analytical approach, artiﬁcial topol-
ogy and routing policies are used [21, 26]. In the measurement ap-
proach, only correlation between routing dynamics and degraded
end-to-end performance can be established [1].
In [15], similar
to our experiment methodology, routing failures are artiﬁcially in-
jected to understand their impact on end-to-end performance. How-
ever, what and how routing dynamics cause the degraded end-to-
end performance has not been fully explored. The establishment of
such a causal relationship can bring insight for the design of future
interdomain routing protocols.
In this paper, we aim to study end-to-end performance under re-
alistic topology and routing policies, while not limited by the black-
box approach that most of measurement studies have taken. We
control routing events by injecting well-designed routing updates
at known times to emulate link failures and repairs. To understand
the impact of routing events on the data plane performance, we
select geographic and topologically diverse probing locations from
the PlanetLab experiment testbed [22] to conduct active UDP based
measurement probing while routing changes are in effect. In ad-
dition, we deploy frequent ping and traceroute to probe network
routing states. This allows us to identify the root cause of intermit-
tent loss of connectivity and degraded end-to-end path performance
during routing changes. Our contributions are summarized as fol-
lows.
• To analyze the impact of routing events on end-to-end per-
formance, we investigate several metrics to characterize the
end-to-end loss, delay, and out-of-order packets. We ﬁnd that
while routing changes can lead to longer delay and out-of-
order packets, routing changes impact end-to-end loss more
signiﬁcantly and can lead to loss bursts lasting as long as
20 seconds. Furthermore, our results show that one routing
event can lead to multiple loss bursts. Our results have im-
portant implications for wide deployment of interactive ap-
plications such as VoIP.
• To understand the root cause for degraded end-to-end path
performance during routing changes, we characterize the kinds
of routing changes that can impact end-to-end path perfor-
mance. We analyze the impact of topology, routing policies,
and iBGP conﬁgurations on end-to-end path performance.
Our results show that routing policies and iBGP conﬁgu-
rations are the major causes of degraded performance ob-
served.
• To demonstrate that our results are not limited by our mea-
surement setup, we show that degraded end-to-end perfor-
mance is experienced by a diverse set of hosts when there is
a routing change. Further analysis shows that simply adding
physical connectivity does not necessarily minimize the im-
pact of routing changes on end-to-end path performance.
The paper is organized as follows. Section 2 provides the back-
ground to understand the causal relationship between routing events
and data plane performance. We describe our measurement method-
ology in Section 3. We provide detailed data analysis in Sections 4
and 5.
In Section 6, we argue that our measurement results are
representative enough for common network topologies and conﬁg-
urations. Finally we discuss related work in Section 7 and conclude
with Section 8.
2. BACKGROUND
In this section, we provide background to help illustrate the cor-
relation between routing events and data plane performance. Bor-
der Gateway Protocol (BGP) [27] is the interdomain routing pro-
tocol that Autonomous Systems (ASes) use to exchange informa-
tion on how to reach destination address blocks (or preﬁxes). BGP
routers at the periphery of an AS learn how to reach external des-
tinations through eBGP sessions with routers in other ASes. After
applying local policies to the eBGP-learned routes, a BGP router
selects a single best route and advertises it to other BGP routers
within the same AS through iBGP sessions. In the simplest case,
each router has an iBGP session with every other router (i.e., a full-
mesh iBGP conﬁguration). Large networks are often organized in-
ternally using route reﬂectors to make iBGP more scalable. Route
reﬂectors usually connect to each other as a full mesh. Each route
reﬂector and its clients (i.e., iBGP neighbors that are not route re-
ﬂectors themselves) form a cluster. A route reﬂector reﬂects routes
learned via one client to all other clients in the same cluster as well
as other route reﬂectors. Similarly, it also reﬂects routes learned
from other route reﬂectors to all its clients.
BGP is a path vector protocol. Each BGP advertisement usu-
ally includes the sequence of ASes for the path, along with other
attributes such as the next-hop IP address. Before accepting an ad-
vertisement, the receiving router checks for the presence of its own
AS number in the AS path to discard routes causing loops. By
representing the path at the AS level, BGP hides the details of the
topology and routing information inside each network.
BGP is a stateful protocol. Only routing changes are advertised.
A router sends an advertisement of a new route for a preﬁx or a
withdrawal when the route is no longer available. To limit the num-
ber of updates that a router has to process within a short time period,
a rate-limiting timer, called the Minimum Route Advertisement In-
terval (MRAI) timer, determines the minimum amount of time that
must elapse between routing updates to a particular destination [27]
for the same neighbor. This is beneﬁcial to reduce the number of
updates explored, as a single routing change might trigger multiple
transient routes during the path exploration or route convergence
process before the ﬁnal stable route is selected. If new routes are
selected multiple times while waiting for the expiration of MRAI,
the latest selected route shall be advertised at the end of MRAI.
Currently, the common default values of MRAI are 30 seconds for
eBGP sessions and 5 seconds for iBGP sessions. To avoid long-
lived black holes, RFC 1771 [27] speciﬁes that the MRAI timer is
only applied to BGP announcements, not to explicit withdrawals.
However, router implementations might apply MRAI timer to both
announcements and withdrawals. We show later that the MRAI
values can impact the data plane performance.
BGP is a policy-based protocol. Each BGP router selects a sin-
gle best route for each preﬁx by comparing the routes using their
attributes. Rather than simply selecting the route with the shortest
AS path, routers can apply complex policies to inﬂuence the best
route selection for each preﬁx and to decide whether to propagate
it to their neighbors. The policy conﬁguration is usually guided by
the commercial agreements between ASes, which determine AS
relationships.
In general, there are two dominant types of rela-
tionship: provider-to-customer and peer-to-peer [8]. In the former
case, a customer pays the provider to be connected to the Internet.
In peer-to-peer relationships, two ASes agree to exchange trafﬁc
on behalf of their respective customers free of charge. Note that
network providers offer transit service only to its customers (i.e., a
network provider only announces its own and its customer preﬁxes
to its peer ASes). There are two commonly adopted routing poli-
cies: “prefer customer” and “no-valley”. Under the “prefer cus-
tomer” routing policy, routes received from a network provider’s
customers are always preferred over those received from its peers or
any other routes. Under the “no-valley” routing policy, customers
do not transit trafﬁc from one provider to another, and peers do not
transit trafﬁc from one peer to another either. These rules directly
match the commercial incentives among the networks.
3. EXPERIMENT METHODOLOGY
In this section, we describe our controlled Internet measurement
and experiment methodology involving a BGP Beacon preﬁx from
the Beacon routing experiment infrastructure [18]. During the pe-
riod of a routing event, we actively probe a host in the Beacon
preﬁx from a diverse set of hosts on the Internet. Our measurement
methodology is also applicable to other studies correlating routing
dynamics with data plane performance.
3.1 Controlled Routing Changes
Beacon preﬁxes [18] are a set of IP preﬁxes designed for experi-
mental purposes. There are no real users using addresses within the
preﬁx. Their routing changes are well regulated: Beacon preﬁxes
00:00
16:00
22:00
20:00
1,2
14:00
1
18:00
2
1
1: ISP 1
2: ISP 2
2
06:00
02:00
1,2
12:00
04:00
10:00
08:00
Figure 1: Time schedule (GMT) for BGP Beacon routing tran-
sitions.
Table 1: Classiﬁcation of Beacon routing events
Beacon events
Failover 1
Failover 2
Recovery 1
Recovery 2
BGP updates
Withdrawing route via ISP 1
Withdrawing route via ISP 2
Restoring route via ISP 1
Restoring route via ISP 2
Time schedule (GMT)
00:00, 04:00
12:00, 16:00
02:00, 10:00
14:00, 22:00
are announced or withdrawn every 2 hours with speciﬁc regular
patterns. In our study, we use a multi-homed BGP Beacon, which
has been active since September 2003. This Beacon has two tier-1
providers to which we refer as ISP 1 and ISP 2. Every two hours,
the Beacon sends a route withdrawal or announcement to one or
both providers according to the time schedule shown in Figure 1.
Each circle denotes a state, indicating the providers offering con-
nectivity to the Beacon. Each arrow represents a routing event and
state transition, marked by the time that the routing event (either a
route announcement or a route withdrawal) occurs.
There are 12 routing events every day. We focus on 8 routing
events that keep the Beacon connected to the Internet; the other
four serve the purpose of resetting the Beacon connectivity. These
8 Beacon events are classiﬁed into two categories. For a failover
beacon event, we emulate a link failure scenario in which the Bea-
con originally announces routes through both providers but now
withdraws the route through one of the two providers. That is,
the Beacon changes from the state of using both providers to the
state of using only a single provider. In a recovery beacon event,
we emulate a link recovery or repair scenario in which the Beacon
re-advertises a route previously withdrawn. That is, the Beacon
changes from the state of using a single provider for connectivity
to the state of using both providers. These two classes of routing
changes emulate the control plane changes that a multi-homed site
may experience in terms of losing and restoring a link to one or
more of its providers; thus they represent real routing events on the
Internet. Table 1 shows the classiﬁcation of Beacon events and the
time for the events.
3.2 Active Probing
The goal of active measurements is to capture the impact of rout-
ing changes on the end-to-end path performance of a diverse set
of Internet paths. Knowing the time and the location of routing
changes, we actively probe a host within the Beacon preﬁx (i.e.,
the Beacon host) from a set of geographically diverse sites from the
PlanetLab infrastructure [22] using three probing methods: UDP
packet probing, ping, and traceroute. Probing is performed every
hour, thus both during injected routing events as well when there
are no routing events for calibration purposes.
At every hour, every probing source sends a UDP packet stream
marked by sequence numbers to the BGP Beacon host at 50msec
interval. The probing starts 10 minutes before each hour and ends
10 minutes after that hour. (i.e., the probing duration is 20 minutes
for each hour). Upon the arrival of each UDP packet, the Bea-
con host records the timestamp and sequence number of the UDP
packet. In addition, ping and traceroute are also sent from the probe
host towards the Beacon host, for measuring round-trip time (RTT)
and IP-level path information during the same 20 minutes time pe-
riod. Both ping and traceroute are run as soon as the previous ping
or traceroute probe completes. Thus, their probing frequency is
limited by the roundtrip delay and the probe response time from
routers.
3.3 Data Plane Performance Metrics
In our study, we use the following metrics to measure the impact
of routing events on end-to-end performance: loss, delay, and out-
of-order packets. These metrics are selected as they are very basic
and commonly used to capture data plane performance.
3.3.1 Packet Loss
We identify packet loss by observing gaps in sequence numbers
of UDP probing packets. In our measurement, we use bursty loss
size, which is deﬁned as the maximum number of consecutive pack-
ets lost during a routing event.
3.3.2 Packet Delay
Ideally, we want to measure one-way delays from the probe host
to the Beacon host to study the impact of routing changes on packet
delays. However, such measurements are subject to limitations due
to the clock skews on PlanetLab sites relative to the Beacon host.
Instead, we measure roundtrip packet delays from the probe host to
the Beacon host using ping probes.
3.3.3 Out-of-order Packets
Each PlanetLab probe site sends UDP packets with increment-
ing sequence numbers. However, packets may arrive out of order
at the Beacon host. For example, if multiple paths are used for
load balancing, packets can be reordered. Similarly, during routing
changes, a packet sent out earlier may take a longer route compared
to a later packet.
We identify out-of-order or reordered packets as follows. At
the BGP Beacon host, we record the value of the next expected
sequence number, which is the largest sequence number of the re-
ceived packets incremented by 1. Each new in-order arriving packet
has a sequence number greater than or equal to the value of the ex-
pected sequence number. The expected sequence number will be
updated upon arrival of each in-order packet. A reordered packet
occurs when the packet has a sequence number lower than the ex-
pected sequence number, which does not change upon the arrival
of out-of-order packets. For example, for arriving packets with se-
quence numbers {1, 2, 4, 5, 3, 6}, packet 3 is out-of-order, as 3 is
smaller than the expected sequence number of 6.
Let Si be the sequence number of ith arriving packet. Thus,
the expected sequence number Sexpi is max(Sj) + 1, ∀j ≤ i.
Therefore, for a packet with sequence number Si: if Si ≥ Sexpi , it
is in order. Otherwise, it is out of order.
We use two metrics to measure the degree of out-of-order deliv-
ery: number of reordering and reordering offset. The number of
reordering is simply the number of packets that are considered out
of order. The reordering offset measures for an out-of-order packet
the difference between the actual arrival order and the expected ar-
rival order. Using the above notation, reordering offset for Si is
i − Si, assuming the initial sequence number is 1. For example, if
arrived packets have sequence numbers {1, 2, 4, 5, 3, 6}, packet 3
is out-of-order, arriving as 5th packet, and its reordering offset is
5 − 3 = 2. The reordering offset provides insights into the buffer
size needed to restore proper order of received packets.
3.4 Identifying Routing Failures
We use a combination of active traceroute and ping measure-
ments to identify whether packet loss bursts are caused by routing
failures. Packet loss can be attributed to network congestion or
routing dynamics.
It has been shown that routing dynamics can
lead to temporary route loss or forwarding loops [26, 1, 21]. We
call such routing dynamics routing failures. An ideal method to
identify whether a packet loss burst can be attributed to routing
failures, is to correlate the loss burst with routing changes, includ-
ing BGP and IGP routing information, from all routers involving in
the burst. Unfortunately, identifying the root cause of packet loss
requires obtaining such a large set of routing information from mul-
tiple ISPs and multiple routers, which is extremely difﬁcult, if not
impossible. Instead, we use ICMP response messages, as measured
by traceroutes and pings to identify routing failures.
We derive loss bursts and correlate them with unreachable re-
In particular, we correlate
sponses from traceroutes and pings.
loss bursts with ICMP messages using the time window [-1 sec,
1 sec] since hosts in PlanetLab are time synchronized via NTP.
When a router does not have a route entry for an incoming packet,
it will send an ICMP network unreachable error message back to
the source to indicate that the destination is unreachable if it is al-
lowed to do so. Based on the ICMP response message, we can
determine when and which router does not have a route entry to
the Beacon host. Loss bursts that have corresponding unreachable
ICMP messages are attributed to routing failures.
In addition, if a packet is trapped in forwarding loops, its TTL
value will increase until the value reaches the maximum value at
some router. The router will send a “TTL exceeded” message back
to the source. We can also observe forwarding loops from the
traceroute data. In general, from traceroute and ping probes, we
can determine whether a router loses its route to the Beacon host
and whether there is a forwarding loop.
Since ICMP packets can be lost, disabled, or ﬁltered by routers,
it is possible that there is no corresponding ICMP message for some
loss bursts even if those loss bursts might be caused by routing fail-
ures. As a result, we may underestimate the number of loss bursts