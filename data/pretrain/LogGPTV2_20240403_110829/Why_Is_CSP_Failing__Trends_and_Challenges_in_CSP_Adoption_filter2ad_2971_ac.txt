as scripts or images. We observed extensions for blocking advertisements, exten-
sions injecting advertisements, price comparison toolbars, an anti-virus scanner,
a notetaking plugin, and even a BitTorrent browser extension. We could auto-
Why Is CSP Failing? Trends and Challenges in CSP Adoption
223
Table 5. Length of policies when whitelisting all violations from the report data set (a),
and with an additional ﬁlter for URL schemes of browser extensions (b). Most of the
policy entries correspond to injected resources; only few are intended to be included. (In
brackets, the number of unique policy entries when disregarding the protocol HTTP(S)
or alternative domains, such as the www subdomain.)
Site
A
B
C
D
# Entries (a)
# Entries, extension ﬁlter (b)
Correct Subset
14
14
1,113
1,090
3 (3) 14 (9) 38 (13) 22 (9)
221
212
226
215
Table 6. Most frequent Chrome extensions observed at site D
Name
# Reports
AdBlock
AdBlock Plus
Grooveshark Downloader
ScriptSafe
DoNotTrackMe
38 K
29 K
9.5 K
8.8 K
8.2 K
matically identify some browser extensions based on violation reports because
they attempted to load resource URIs that contained the chrome-extension or
safari-extension schemes followed by the unique identiﬁer of the extension.
AdBlock and AdBlock Plus were the most frequent extensions for the Chrome
browser (Table 6), while the most frequent Safari extension was Evernote. Yet,
automatically removing these reports (and a few other unexpected schemes, such
as about and view-source) accounted for fewer than 5 % of all incorrect policy
entries, as shown in the second row of Table 5. The remaining browser extensions
exhibited no such uniquely distinguishing features, often injecting libraries that
are used not only in browser extensions but also in many websites, such as Ajax
tools, Google Analytics, and resources from large content distribution networks.
When browsers send violation reports for modiﬁcations due to browser exten-
sions, the reverse conclusion is that websites enforcing CSP can cause browser ex-
tensions to stop functioning. Some browser extensions thus intercept CSP headers
and modify them in order to whitelist their own resources or disable CSP. We ob-
served reports caused by one such extension, which were sent because the modiﬁca-
tion resulted in a semantic error. We cannot quantify how often such modiﬁcations
were successful as they are not observable with our methodology.
In addition to browser extensions, “in-ﬂight” modiﬁcation of pages by ISPs or
web applications such as anonymity proxies can also cause violation reports. The
image loaded from 1.2.3.11 in the example above appeared to be injected by
a mobile Internet provider. These examples illustrate that even when CSP vio-
lations due to browser extensions were ﬁltered (or not reported by the browsers),
other non-attack scenarios can still cause websites to receive spurious reports.
224
M. Weissbacher, T. Lauinger, and W. Robertson
1.0
0.8
0.6
0.4
0.2
d
e
t
r
o
p
e
r
s
e
i
r
t
n
e
y
c
i
l
o
p
f
o
n
o
i
t
c
a
r
f
legitimate
invalid
0.0
0
6   2
1
4
b   1
e
F
4
1
0
3   2
b   2
e
F
r   0
M a
4
1
0
2   2
r   0
M a
4
1
0
9   2
r   1
M a
4
1
0
6   2
r   2
M a
4
1
0
3   2
date
Fig. 2. Fraction of new policy entries dis-
covered over time on site B (measurement
inactive during the dashed intervals). It
can take some time until all legitimate re-
sources have been accessed at least once;
in the meantime, many injected resources
are reported.
legitimate
invalid
107
106
105
104
103
102
101
d
e
t
r
o
p
e
r
s
e
i
r
t
n
e
y
c
i
l
o
p
f
o
y
c
n
e
u
q
e
r
f
100
100
101
102
rank
103
104
Fig. 3. Frequency of legitimate and in-
valid violations being reported on site D.
Some injected resources occurred orders
of magnitude more often than legitimate
resources.
Administrators who plan to generate a policy from reports submitted by their visi-
tors’ web browsers may need to manually verify a large number of policy entries in
order to avoid accidentally whitelisting resources injected by browser extensions
or ISPs (let alone attackers).
Time Delay Until a Policy can be Generated. On site B, it took around
two weeks to receive at least one report for each valid policy entry. The last
resource that was discovered was an embedded YouTube video. Another resource
that was discovered relatively late was an image loaded over HTTPS instead of
HTTP; all other valid policy entries could be generated within the ﬁrst two days
of the measurement. For the other sites, the durations were similar. In practice
we expect these numbers to vary, thus website operators will need some prior
knowledge about the resources used on their website so that they can decide
when it is safe to switch from report-only to enforcement mode without causing
any disruption. Operators could therefore be tempted to run the observation
period for as long as possible in order to minimize the risk of not receiving
reports for legitimate resources. However, as Figure 2 shows, the rate of newly
observed, invalid policy entries remained relatively constant over time, suggesting
that longer measurement periods can signiﬁcantly increase the number of policy
entries an operator needs to verify manually.
Report Frequency as a (Poor) Distinguishing Feature. Only about 4 % of
all reports received on site D during our measurement resulted in an invalid policy
entry. Hence, one might attempt to use the frequency of a report as an indicator for
its validity. However, this approach would be problematic for two reasons. First, an
attacker can easily inﬂuence the frequency distribution observed by the website
Why Is CSP Failing? Trends and Challenges in CSP Adoption
225
by submitting forged reports. Second, even in the absence of attacks, resources
injected into websites can be so popular that they cause reports more often than
some legitimate, but infrequently accessed, resources.
Figure 3 visualizes this phenomenon. The most frequently injected resource
(a script loaded from superfish.com for price comparison) was reported more
than 22,000 times. In contrast, connect-src ‘self’, which is used by a progress
meter on the site, was reported only 9,000 times, and reports corresponding to
alternative domain names of site D were received even less frequently.
4.4 Conclusions
Websites small and large observe CSP violation reports for injected resources.
Even in the absence of ostensibly malicious activity, which we did not observe, the
high number of injected resources complicates the process of generating a viable
policy from the received reports. At the moment, this task is mostly a tedious
and, from our own experience, error-prone manual process. As a semi-automated
approach to ﬁltering reports, it might be possible to generate signatures for the
most common browser extensions, either manually or by leveraging the fact
that an installed browser extension usually causes several violations to co-occur
(based on time, IP address, and user agent signature). These signatures could be
shared with the community and could be used to reduce the number of reports
that need to be veriﬁed manually.
5 Semi-automated Policy Generation
An alternative approach to generating a policy from appropriately ﬁltered and
veriﬁed reports submitted by visitors is to make use of trustworthy reports only.
In order to explore this approach further, we developed a proof-of-concept web
crawler that generates violation reports in a controlled environment.
5.1 Methodology
Our crawler is implemented as an extension for the Chromium browser based
on Site Spider, Mark II. The crawler follows at most 500 internal links on the
main domain of the crawled site in a non-randomized breadth-ﬁrst search. Af-
ter navigating to a page, the crawler pauses for 2.5 s to load all resources of a
document such as images, scripts, and external pages displayed in frames. The
browser accesses the web through an instance of the Squid web proxy with an
ICAP module. The proxy inserts the CSP report-only headers described in Sec-
tion 4.2 and collects the resulting reports. The proxy also intercepts encrypted
SSL traﬃc.
After crawling a site, we discarded all reports that did not match the site’s
main domain. These reports referred to external documents loaded in a frame
and were not necessary to generate a policy for the main document. (In CSP, a
document’s policy does not transitively apply to nested documents loaded inside
a frame.) From the remaining reports, we generated a policy as in Section 4.2.
226
M. Weissbacher, T. Lauinger, and W. Robertson
The crawler should be considered a proof-of-concept to explore the feasibil-
ity of automatically generating policies for websites. By following only hyper-
text links, the crawler cannot detect violations that conditionally occur after
load-time, such as clicking the “play” button in a Flash movie, or triggering
JavaScript-related events. We leave ways to increase the crawler’s coverage to
future work.
As a potentially more targeted alternative to automated crawling, we also
manually browsed websites in a fresh browser instance and used the proxy to
collect reports. This process included no feedback. The goal was to cover all areas
of the site and trigger as many diﬀerent violations as possible by speciﬁcally
exercising functionality implemented in JavaScript or browser plugins.
5.2 Evaluation
The question of whether semi-automated policy generation for websites is a
suitable approach—without requiring modiﬁcations to the sites—depends on
two opposing goals. First, the generated policy must not break the site. A policy
generation mechanism must discover all resources being included by a site, or a
superset thereof. Second, the generated policy should be as narrow as possible
in order to provide the maximum safety gain. Unnecessary resources should not
be allowed by the policy, and unsafe mechanisms should not be used. In the
ﬁrst part of this evaluation, we compare methods of collecting reports for policy
generation on sites where we know that a sound policy exists. In the second part,
we explore how well diﬀerent site architectures work with CSP; that is, whether
a sensible policy can be deployed without changing the sites.
Crawling and Manual Browsing of Our Own Sites. From the reports
submitted by visitors’ web browsers in Section 4.3, we know that stable policies
exist for our own four sites. Indeed, the sets of policy entries generated by crawl-
ing and manual browsing as shown in the upper part of Table 7 overlap, and
only a few entries were found by only one method. Especially when disregarding
diﬀerences due to alternative domain names and HTTP(S), both methods per-
formed similarly. However, neither method was perfect. The crawler discovered
resources in a rather hidden portion of site B that manual browsing did not
uncover. On site D, in turn, manual browsing discovered a resource inclusion
that the crawler was not able to ﬁnd, which was due to exercising JavaScript
code when submitting content to the site. The policy entries generated from
valid user-submitted reports were always a strict superset of those derived from
crawling and browsing (as shown in the lower two-thirds of the table), except
for site B where we found that a technical mistake had prevented CSP headers
from being sent to users in a small portion of the site. We conclude that the
crawler and manual browsing techniques need more reﬁnement before they can
fully replace user-submitted reports. Since both techniques are complementary,
combining them could prove useful to increase coverage.
Why Is CSP Failing? Trends and Challenges in CSP Adoption
227
Table 7. Overlap between the sets of policy entries generated by the crawler, through
manual browsing and from user-submitted reports. (In brackets, the number of com-
mon/diﬀerent policy entries when disregarding alternative domain names or HTTP(S).)
No method was fully reliable.
Site
crawler only
both
manual only
A
B
C
8 (8)
0 (0)
3 (3) 12 (9) 12 (10)
0 (0)