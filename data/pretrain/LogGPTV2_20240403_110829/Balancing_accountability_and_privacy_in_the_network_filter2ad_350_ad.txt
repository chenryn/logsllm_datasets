Transit Networks
Receiver
Source domain always knows a packet’s sender.
Source domain always knows a packet’s sender.
Other source domain customers.
Starts as source domain’s customers and grows
the farther the packet travels. By the time it reaches
the core, it could have come from anywhere.
The sender. The receiver decrypts the return
address, which is the sender’s address. If the sender
is concerned with anonymity from the receiver,
end-to-end encryption is not a viable option.
The sender. The sender’s address is observable
until the packet reaches the border router where
NAT is performed.
Source domain’s customers.
Source domain’s customers.
Table 2: Comparison of sender anonymity set, as seen by diﬀerent adversaries, for end-to-end encryption and NAT.
gate. The issue of delegate oversight is complex; given space
constraints, we can only hope to lay the groundwork for dis-
cussion and future work.
At one extreme, a single central authority could provide
some form of oversight over delegates, similar to how ICANN
accredits TLDs; veriﬁers would then only accept delegates
on a whitelist published by this authority. This has the
advantage that delegates can be monitored and misbehaving
delegates can be immediately removed from the whitelist,
creating an incentive for responsible delegate management.
On the other hand, vetting all delegates is a huge burden
for a single authority and the role (and power) of a single
organization in charge of such a critical function is likely to
raise political concerns.
The other extreme is a free-for-all: a host can pick any
host to be its delegate. This ﬂexibility opens the door for
many deployment models. Besides commercial (third party)
delegates, hosts can be their own delegates (similar to AIP),
use their source domain as their delegate (§7.4), or form a
peer-to-peer delegate network, in which hosts (or domains)
vouch for one other. The critical drawback of this ﬂexibil-
ity is weaker protection against attacks—bots in a botnet,
for example, can vouch for one another’s packets regardless
how many shutoﬀ()s they receive. It will clearly be harder
to defend against such attacks compared to the case where
there are only a limited number of vetted delegates.
Naturally, a pragmatic solution likely falls somewhere in
between these extremes. For example, a set of well-known
commercial “delegate authorities” could emerge, similar to
today’s certiﬁcate authority infrastructure, each publishing
a delegate whitelist. Alternatively, various groups could
maintain delegate blacklists based on historical incidents,
similar to today’s security companies’ publishing malware
signatures. Individual veriﬁers can then decide which dele-
gates to accept, a decision that could depend on many fac-
tors, including their position in the network (tier 1 versus
edge), local regulation, historical information, or the “trust
domain” they belong to [37]. Many other forms of semi-
structured self regulation are possible.
7.2 Attacking APIP
We need to ensure that hosts cannot use APIP mecha-
nisms to undermine APIP itself; two potential such attacks
are “veriﬁcation-ﬂooding” and “brief-ﬂooding.”
Veriﬁcation-Flooding Attackers could attempt to over-
whelm an accountability delegate with bogus veriﬁcation
requests—rendering it incapable of verifying honest hosts’
packets—by sending a large number of dummy packets with
accountability addresses pointing at the victim delegate. To
these bogus veriﬁcations, the delegate could respond DROP_HOST
(as opposed to DROP_FLOW). Source domains should track the
number of DROP_HOSTs their customers generate, taking ac-
tion if it is too high.
Brief-Flooding Similar to veriﬁcation ﬂooding, malicious
clients could target their own delegate by sending a ﬂood of
briefs. This attack is tricky, since it is hard to distinguish
from an honest host that happens to send lots of packets.
Delegates can enact their own policies (e.g.: will accept 1
brief per second; must use bloom ﬁlters), which should be
agreed upon when the client initially signs up for service.
7.3 Bootstrapping Trust
We now relax our initial assumption that HIDs are self-
certifying; doing so does not break APIP, but requires us to
do a small amount of extra work in brief(), verify(), and
shutoﬀ().
brief() Clients already encrypt brief()s using a symmetric
key established when the client registered for service, so no
change is required.
verify() Delegates use their private keys to sign veriﬁcation
responses. If keys are not bound to HIDs, a PKI can be used
instead; veriﬁers now need to check a delegate’s certiﬁcate
before trusting a response.
shutoﬀ() Victims sign shutoﬀ() messages to convince the
attacker’s delegate that the shutoﬀ truly came from the re-
cipient of the oﬀending packet. While we think it is reason-
able to assume delegates register keys with a PKI for signing
verify()s, there are many more hosts than delegates, so here
we instead rely on veriﬁcation. Upon receiving a shutoﬀ(),
the attacker’s delegate sends a veriﬁcation packet to the vic-
tim’s delegate to check that the shutoﬀ really came from the
original packet’s recipient:
briefpshutoﬀpPqq
R Ñ DR :
DS Ñ DR : X “ verify*pshutoﬀq
tVERIFIED || XuK´
DR Ñ DS :
DS
When verifying a shutoﬀ(), the delegate needs to look in-
side the shutoﬀ packet, at the header of the original packet
that prompted the shutoﬀ, and check that its destination
Figure 5: Design 1: 1 Host sends packet using its own
address as the source address. 2 The ISP’s border router
saves a hash of the packet and 3 performs address transla-
tion on the source address. 4 If the packet is malicious, the
receiver sends a shutoﬀ() to the border router, otherwise 5
it responds. 6 The border router translates the response’s
destination address back to the original sender’s address.
Design 1
Design 2
Delegate
Brieﬁng
Source Addr.
Return Addr. NAT
Source domain
Fingerprint collect. Recursive ver.
Separate ﬁelds
Single ﬁeld
NAT or encrypt
Third party
Table 3: Two possible instantiations of APIP.
(the victim) sent the shutoﬀ. (We denote verify() with this
additional check verify*().)
7.4 Concrete Designs
APIP is an architecture that allows routers and destina-
tions to identify an entity that is willing to take responsibil-
ity for the packet, but properties of APIP depend on how
it is deployed. For the sake of concreteness, we now sketch
two end-to-end instantiations of APIP with very diﬀerent
properties. Table 3 summarizes the two designs.
Design 1 In the ﬁrst design (Figure 5), the source domain
acts as the accountability delegate for its hosts. Hosts are
not aware of APIP and send packets with traditional source
addresses. The gateway routers for the domain use address
translation to mask the return address, turning the source
address into a combined accountability address and masked
return address. They also collect packet ﬁngerprints and re-
spond to verify() and shutoﬀ() requests. Gateway routers
could either collectively act as a distributed accountability
delegate and keep briefs locally, or they could periodically
send briefs to a shared accountability server. This ﬁrst de-
sign could be viewed as a variant of AIP, but implemented
at the source domain level instead of individual senders.
This design oﬀers a number of advantages. First, it is very
eﬃcient: gateway routers already naturally see all packets,
eliminating the overhead of brieﬁng a third party. Second,
the source domain can immediately block malicious ﬂows at
the source in response to a shutoﬀ, whereas external dele-
gates can typically only stop ﬂows indirectly. Third, hosts
do not need to be modiﬁed.
Finally, this ﬁrst design allows for incremental deployment
of APIP over IP. Domains could implement accountability
and address translation, as described. Packets would need
to be marked to indicate whether the source domain sup-
ports APIP (e.g., by repurposing an ECN bit). Since both
return traﬃc and verify()s/shutoﬀ()s would arrive at the
Figure 6: Design 2: 1 Host sends packet and 2 saves
hash.
3 First-hop router sends verify() to the packet’s
accountability delegate, which 4 forwards the veriﬁcation
to the host. 5 Using the accountability address, the receiver
can send a shutoﬀ(); otherwise 6 it responds using the
return address.
domain’s border routers, verify() and shutoﬀ() would each
be assigned a new IP protocol number so the border router
knows what to do with the packet. Since IP addresses are
not cryptographic, external keys would have to be used to
ensure the integrity of the verify() and shutoﬀ() opera-
tions, as described in §7.3.
Design 2 The second design (Figure 6) uses a commercial
third party that oﬀers accountability delegation as a ser-
vice (perhaps as part of a bundle with antivirus or ﬁrewall
software). In this design, senders insert both an accountabil-
ity address and a return address in the packet; the return
address can be masked either with encryption or a NAT.
Since the delegate is oﬀ-site, recursive veriﬁcation is attrac-
tive: rather than regularly sending briefs, hosts save packet
hashes and the delegate challenges clients when it itself is
challenged.
One advantage of this solution is that it allows companies,
universities, or small domains to avoid the hassle of manag-
ing delegate servers themselves by outsourcing delegation.
Another advantage is that it is harder for observers in the
network to determine what source domain the sender be-
longs to. The drawback is that there is more overhead than
in the ﬁrst design.
8. EVALUATION
The primary question we consider in the section is: “is
delegated accountability technically feasible?” Using a trace
of NetFlow data from the border routers of a mid-sized uni-
versity, we explore the costs of brief() and verify() and the
eﬃcacy of shutoﬀ(). The ﬁve minute trace was taken on
June 18, 2013 at noon and contains ten million ﬂows. We
then present a short privacy analysis.
8.1 Delegated Accountability
Brief() Brieﬁng the delegate incurs computational over-
head at the sender, storage overhead at the delegate, and
bandwidth overhead in the network. In §5.2 we suggested
that senders could report their traﬃc to their delegates by
sending a list of packet ﬁngerprints or by sending a bloom
ﬁlter of recent ﬁngerprints.
Computational Overhead Producing a packet ﬁngerprint re-
quires computing two hashes; we assume that computing the
MAC of the ﬁngerprint, in the worst case, costs one addi-
14236SenderReceiver5SENDER’S NETWORKRECEIVER’S NETWORKFingerprint Cache2cf24dba5fb0afd9c28230e26e83b2ac51bab7e4b9e29e1b161e58207ea11236SenderAccountabilityDelegateReceiver5SENDER’S NETWORKRECEIVER’S NETWORK4Fingerprint Cache2cf24dba5fb0afd9c28230e26e83b2ac51bab7e4b9e29e1b161e58207ea1tional hash. Commodity CPUs can compute in the neigh-
borhood of 5–20 MH/s [1], which translates to 0.9–3.4 Gbps
(conservatively assuming 64B packets). This is more than
reasonable for endhosts; for servers sending large volumes
of traﬃc, we expect data centers could outsource brieﬁng to
an in-path appliance built with ASICs—current ASIC-based
bitcoin miners perform 5–3,500 GH/s, translating to 0.9–600
Tbps.
Storage Overhead Next we consider the storage require-
ments at the delegate for saving briefs. Briefs are periodi-
cally purged from the cache; if a verify() arrives for a legit-
imate packet whose brief has been deleted, the sender must
retransmit the packet. Assuming a single delegate serves all
hosts in our trace, the ﬁrst two series in Figure 7 show the
size of the brief cache for diﬀerent expiration intervals as-
suming the delegate stores individual ﬁngerprints, each a 20
byte SHA-1 hash. The remaining series consider the space
required if, instead of sending a ﬁngerprint per packet, hosts
send a bloom ﬁlter every second for each active ﬂow1. We
assume that hosts size each ﬁlter appropriately based on how
many packets from the ﬂow were sent during the past sec-
ond. If briefs expire every n seconds, we report brief cache
sizes based on both the average and maximum number of
packets seen across n-second bins in our trace.
Bandwidth Overhead Figure 8 shows the bandwidth re-
quired for the same brieﬁng schemes discussed above. Send-
ing ﬁngerprints consumes an additional 2.5% of the original
traﬃc volume, which was just under 10 Gbps; the bloom ﬁl-
ter schemes consume 0.25%–0.5%. The bloom ﬁlter results
assume a simple update scheme: every second, each host
sends a bloom ﬁlter for packets sent in each ﬂow1 during
the last 30 seconds; when the delegate gets a new ﬁlter for
an existing ﬂow, it replaces the old ﬁlter (using a bloom ﬁlter
alternative that supports resizing is interesting future work).
Note brieﬁng overhead can be avoided entirely if (1) the ISP
is the accountability delegate, so border routers save hashes
directly, or (2) delegates use recursive veriﬁcation (§5.2).
Verify() The magnitude of veriﬁcation overhead is deter-
mined by the veriﬁcation interval and ﬂow granularity (fewer
ﬂows means fewer veriﬁcations; in our analysis, each “ﬂow”
is a TCP ﬂow, so our numbers are an upper bound). There
is a tradeoﬀ between long and short veriﬁcation intervals.
The longer the interval, the more whitelist space is required
at routers to remember which ﬂows have been veriﬁed and
the longer a malicious sender could transmit before being
shut oﬀ. On the other hand, shorter intervals mean more
work (more verify()s) for the delegate.
Computational Overhead Figure 9 shows how many ver-
ify()s per second an accountability delegate serving all the
hosts in our trace would see at various veriﬁcation intervals.
A key observation here is that after 10 seconds, increasing
the veriﬁcation interval does not signiﬁcantly decrease veri-
ﬁcation rate at the delegate since most ﬂows are short. This
knee suggests that 10 seconds might make a good interval
for use in practice.
In our trace, a veriﬁcation interval of 10 seconds gener-
ates a maximum of 78,000 verify()s per second, each caus-
1In practice, we think hosts should send one bloom ﬁlter for
all traﬃc each second, not one per ﬂow. Unfortunately, for
privacy reasons, our trace did not include local addresses, so
we could not merge ﬂows originating from the same sender.
ing a lookup in a table with 1.5 million entries (assuming