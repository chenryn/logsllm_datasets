activity. Finally, MediaCo stores all raw observations in
an encrypted store whose read accesses are disabled by
default. Access to this store is granted temporarily and
on a case-by-case basis to engineers who demonstrate the
need for statistics beyond those that Pyramid maintains.
In addition to targeting/personalization workloads,
MediaCo has other, potentially non-ML workloads, such
as business analytics, trend studies, and forensics; for
these, count featurization may not apply. Hence, Medi-
aCo gives direct access to the raw-data store to engineers
managing these workloads and isolates their computa-
tional resources from the targeting/personalization teams.
With this conﬁguration, MediaCo minimizes access to
its collected data on a needs basis. Assuming no entity
with full access to the historical raw data is malicious,
Pyramid guarantees the following (detailed in §II-B).
(1) Any observations preceding the hot window when
(cid:55)(cid:68)(cid:87)(cid:87)(cid:68)(cid:70)(cid:78)(cid:16)(cid:3)(cid:507)(cid:85)(cid:72)(cid:87)(cid:72)(cid:81)(cid:87)(cid:76)(cid:82)(cid:81)
(cid:55)(cid:68)(cid:87)(cid:87)(cid:68)(cid:70)(cid:78)(cid:16)(cid:3)(cid:507)(cid:75)(cid:82)(cid:87)
(cid:55)(cid:68)(cid:87)(cid:87)(cid:68)(cid:70)(cid:78)
(cid:55)(cid:68)(cid:87)
(cid:55)(cid:55) (cid:86)(cid:87)(cid:82)(cid:83)
(cid:78) (cid:55)(cid:68)(cid:87)(cid:87)(cid:68)(cid:70)(cid:78)
(cid:88)(cid:81)(cid:85)(cid:72)(cid:86)(cid:87)(cid:85)(cid:76)(cid:70)(cid:87)(cid:72)(cid:71)(cid:3)(cid:68)(cid:70)(cid:70)(cid:72)(cid:86)(cid:86)
(cid:11)(cid:70)(cid:68)(cid:81)(cid:3)(cid:69)(cid:72)(cid:3)(cid:70)(cid:82)(cid:80)(cid:83)(cid:85)(cid:82)(cid:80)(cid:76)(cid:86)(cid:72)(cid:71)(cid:12)
(cid:75)(cid:76)(cid:86)(cid:87)(cid:82)(cid:85)(cid:76)(cid:70)(cid:68)(cid:79)(cid:3)(cid:86)(cid:87)(cid:68)(cid:87)(cid:76)(cid:86)(cid:87)(cid:76)(cid:70)(cid:86)(cid:3)
(cid:11)(cid:70)(cid:82)(cid:88)(cid:81)(cid:87)(cid:86)(cid:12)(cid:3)(cid:86)(cid:87)(cid:82)(cid:85)(cid:72)
(cid:75)(cid:82)(cid:87)(cid:3)(cid:85)(cid:68)(cid:90)(cid:3)(cid:3)
(cid:71)(cid:68)(cid:87)(cid:68)(cid:3)
(cid:86)(cid:87)(cid:82)(cid:85)(cid:72)
(cid:85)(cid:72)(cid:86)(cid:87)(cid:85)(cid:76)(cid:70)(cid:87)(cid:72)(cid:71)(cid:3)(cid:68)(cid:70)(cid:70)(cid:72)(cid:86)(cid:86)
(cid:11)(cid:68)(cid:86)(cid:86)(cid:88)(cid:80)(cid:72)(cid:3)(cid:81)(cid:82)(cid:87)(cid:3)(cid:70)(cid:82)(cid:80)(cid:83)(cid:85)(cid:82)(cid:80)(cid:76)(cid:86)(cid:68)(cid:69)(cid:79)(cid:72)(cid:12)
(cid:75)(cid:76)(cid:86)(cid:87)(cid:82)(cid:85)(cid:76)(cid:70)(cid:68)(cid:79)(cid:3)(cid:85)(cid:68)(cid:90)(cid:3)(cid:71)(cid:68)(cid:87)(cid:68)(cid:3)(cid:86)(cid:87)(cid:82)(cid:85)(cid:72)
(cid:87)(cid:76)(cid:80)(cid:72)
(cid:71)(cid:68)(cid:87)(cid:68)(cid:3)(cid:72)(cid:91)(cid:83)(cid:82)(cid:86)(cid:88)(cid:85)(cid:72)(cid:3)
(cid:72)(cid:3)
(cid:87)(cid:82)(cid:3)(cid:68)(cid:87)(cid:87)(cid:68)(cid:70)(cid:78)
(cid:88)(cid:81)(cid:72)(cid:91)(cid:83)(cid:82)(cid:86)(cid:72)(cid:71)
(cid:88)(cid:81)(cid:72)(cid:91)(cid:83)(cid:82)(cid:86)(cid:72)(cid:71)
Fig. 1: Threat model. Tattack: time the attack starts; T stop
attack: time
the attack is eradicated; Δhot: hot window length; Δretention:
company’s data retention period.
(cid:88)(cid:81)(cid:72)(cid:91)(cid:83)(cid:82)(cid:86)(cid:72)(cid:71)
(cid:72)(cid:91)(cid:83)(cid:82)(cid:86)(cid:72)(cid:71)
an attack begins will be hidden from the attacker. (2)
Hiding is done at an individual observation level during
the retention period and in bulk past the retention period.
(3) Only in exceptional circumstances do engineers get
access to the historical raw data. With these guarantees,
MediaCo negotiates lower data loss insurance premiums
and gains PR beneﬁts for its efforts to protect user data.
II.B. Threat Model
Fig. 1 illustrates Pyramid’s threat model and guar-
antees. Pyramid gives guarantees similar to those of
forward secrecy: a one time compromise will not allow
an adversary to access all past data. Attacks are assumed
time, Tattack, when the
to have a well-deﬁned start
adversary gains access to the machines charged with
running Pyramid, and a well-deﬁned end time, T stop
attack,
when administrators discover and stop the intrusion.
Adversaries are assumed to not have had access to the
system before Tattack, nor to have performed any action
in anticipation of their attack (e.g., monitoring external
predictions, the hot window, or the models’ state), nor
to have continued access after T stop
attack. The attacker’s goal
is to exﬁltrate individual observations of user activities
(e.g., to know if a user clicked on a speciﬁc article/ad).
Historical raw data is assumed to be protected through
independent means and not compromised in this attack.
Pyramid’s goal is to limit the hot data in active use,
which is widely accessible to the attacker.
Examples of adversaries that ﬁt our threat model
can be found among both the internal and external
adversaries of a company. An external adversary may
be a hacker who breaks into the company’s computing
infrastructure at time Tattack and starts looking for data
that may prove of value (e.g., information about celebri-
ties’ speciﬁc activities, what they liked or disliked, where
they were in the past, etc.). An internal adversary may
be a privacy-transgressing employee who spontaneously
decides at Tattack to look into some past action of a family
member or friend (e.g., to check if the person has visited
or liked a particular page).
After compromising Pyramid’s internal state, the at-
tacker will gain access to data in three different rep-
resentations: the hot data store containing plaintext ob-
servations, the historical counts, and the trained models
80
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:25:23 UTC from IEEE Xplore.  Restrictions apply. 
themselves. The plaintext observations in the hot data
store are not protected in any way. The historical statis-
tics store contains differentially private count tables of
the recent past. The attacker will learn some information
from the count tables but individual records will be
protected with a differentially private guarantee. Pyramid
forces models to be retrained when observations are
removed from the hot raw data store, so the attacker will
not be able to learn anything from the models beyond
what they have already learned above.
Pyramid provides three protection levels:
P1 No protection for present or future observations.
Observations in the hot data store when the attack
begins, plus observations added to the hot data store
while the attack is ongoing, receive no protection;
i.e., observations received between (Tattack − Δhot)
and T stop
attack receive no protection.
P2 Protection for individual observations for the length
of the retention period. Statistics about observations
are retained in differentially private count tables for
a predeﬁned retention period Δretention. The attacker
may learn broad statistics about observations in the
interval [Tattack − Δretention, Tattack − Δhot] but will
not be able to conﬁdently determine if a speciﬁc
observation is present in the table.
P3 Protection in bulk past the retention period. Obser-
vations past their retention period (i.e., older than
Tattack − Δretention) have been phased out of the his-
torical statistics store and are protected separately
by the historical raw data store.
Finally, we assume that no states created based on the
hot raw data persist once the hot window is rolled over.
While we explicitly launch retraining of models regis-
tered with Pyramid, we operate under the assumption
that (1) the models’ states are securely erased [22] and
(2) no other state was created out of band based on the
raw hot data (such as copies made by programmers).
II.C. Design Requirements
Given the threat model, our design requirements are:
R1 Limit widely accessible data. The hot data window
is exposed to attackers; hence, Pyramid must limit
its size subject to application-level requirements,
such as the accuracy of models trained with it.
R2 Avoid accesses to historical raw data even for
evolving workloads. Pyramid must absorb as many
current and evolving workload needs as possible to
limit access to the historical raw data.
R3 Support retention policies. Pyramid must enforce
a company’s retention policies. Although Pyramid
provides a differential privacy guarantee, no protec-
tion is stronger than securely deleting data.
R4 Limit impact on accuracy, performance, scalability.
We intend to preserve the functional properties of
applications and models running on Pyramid.
III. The Pyramid Architecture
Pyramid, the ﬁrst selective data management archi-
tecture, builds upon the ML technique of count-based
featurization and augments it with new mechanisms to
meet the preceding design requirements.
III.A. Background on Count-Based Featurization
Training predictive models can be challenging on data
that contains categorical variables (features) with large
numbers of possible values (e.g., an ID or an interest
vector). Existing ML techniques that handle large feature
spaces often make strong assumptions about the data,
e.g., assuming a linear relationship between the features
and the label (e.g., Lasso [23]). If the data does not meet
these assumptions, results can be very poor.
Count-based featurization [13] is a popular approach
to handling categorical variables of high cardinality.
Rather than directly using the value of a categorical vari-
able, this technique featurizes the data with the number
of times a particular feature value (e.g., a user ID) was
observed with each label and the conditional probability
of the label given the feature value. This substantially
reduces dimensionality. Suppose the raw data contains
d categorical features with an average cardinality of K
and a label of cardinality L, where K (cid:2) L; e.g., in click
prediction K can be millions (number of users), while L
is 2 (click, non-click). Standard encoding of categorical
variables [24] results in a feature space of dimension
O(dK), whereas with count featurization it is O(dL).
Count featurization can also be applied to continuous
variables or continuous labels by ﬁrst discretizing them;
this increases dimensionality but only by a small factor.
The dramatic dimensionality reduction yields impor-
tant beneﬁts. It is known that fewer dimensions permit
more efﬁcient learning, both statistically and computa-
tionally, potentially at the cost of reducing predictive
accuracy. However, count featurization makes it feasible
to apply advanced, nonlinear models, such as neural
networks, boosted trees, and random forests. This com-
bination of succinct data representation and powerful
learning models enables substantial reduction of the
training data with little loss in predictive performance.
Quantiﬁed in §V, this is the insight behind our use of
count-based featurization to limit data exposure.
III.B. Architectural Components
Fig. 2 shows Pyramid’s architecture. Pyramid manages
collected data (observations) on behalf of application
models hosted by a model management system. In our
case, we use Velox [25], built on Spark. Velox facili-
tates ML-based targeting and personalization services by
implementing three functions: (1) fast, but incomplete,
incorporation of new observations into models that pro-
grammers register with Velox; (2) low-latency prediction
serving from these models; and (3) periodic retraining of
81
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:25:23 UTC from IEEE Xplore.  Restrictions apply. 
(cid:30)(cid:31)(cid:20)(cid:19)(cid:24)(cid:18)(cid:33)(cid:2)(cid:37)(cid:3)
(cid:26)
(cid:14)(cid:19)(cid:25)(cid:28)(cid:34)(cid:1)(cid:2)(cid:27)(cid:29)(cid:19)(cid:20)(cid:26)(cid:1)(cid:27)(cid:16)(cid:28)(cid:16)(cid:22)(cid:20)(cid:27)(cid:20)(cid:28)(cid:33)(cid:3)
(cid:27)(cid:29)(cid:19)(cid:20)(cid:26)(cid:1)(cid:13)(cid:8)
(cid:27)(cid:29)(cid:19)(cid:20)(cid:26)(cid:1)(cid:13)(cid:9)
(cid:27)(cid:29)(cid:19)(cid:20)(cid:26)(cid:1)(cid:13)(cid:10)
(cid:21)(cid:34)(cid:33)(cid:34)(cid:31)(cid:20)(cid:1)
(cid:27)(cid:29)(cid:19)(cid:20)(cid:26)(cid:1)(cid:13)(cid:11)
(cid:21)(cid:24)(cid:31)(cid:20)(cid:36)(cid:16)(cid:26)(cid:26)(cid:1)(cid:2)(cid:24)(cid:32)(cid:29)(cid:26)(cid:16)(cid:33)(cid:20)(cid:32)(cid:1)
(cid:34)(cid:28)(cid:27)(cid:16)(cid:28)(cid:16)(cid:22)(cid:20)(cid:19)
(cid:21)(cid:31)(cid:29)(cid:27)(cid:1)(cid:27)(cid:16)(cid:28)(cid:16)(cid:22)(cid:20)(cid:19)(cid:3)
(cid:22)(cid:20)(cid:33)(cid:15)(cid:31)(cid:16)(cid:24)(cid:28)(cid:14)(cid:20)(cid:33)(cid:2)(cid:3)
(cid:21)(cid:20)(cid:16)(cid:33)(cid:34)(cid:31)(cid:24)(cid:39)(cid:20)(cid:2)(cid:37)(cid:3)
(cid:37)(cid:40)
(cid:31)(cid:20)(cid:33)(cid:31)(cid:16)(cid:24)(cid:28)(cid:2)(cid:3)
(cid:2)(cid:3)(cid:37)(cid:40)(cid:4)(cid:26)(cid:4)(cid:1)(cid:30)(cid:16)(cid:24)(cid:31)(cid:32)(cid:3)
(cid:18)(cid:29)(cid:34)(cid:28)(cid:33)(cid:5)(cid:21)(cid:20)(cid:16)(cid:33)(cid:34)(cid:31)(cid:24)(cid:39)(cid:20)(cid:19)
(cid:23)(cid:29)(cid:33)(cid:1)(cid:19)(cid:16)(cid:33)(cid:16)
(cid:11)(cid:35)(cid:29)(cid:15)(cid:26)(cid:23)(cid:18)(cid:1)(cid:2)(cid:19)(cid:16)(cid:33)(cid:16)(cid:1)(cid:27)(cid:16)(cid:28)(cid:16)(cid:22)(cid:20)(cid:27)(cid:20)(cid:28)(cid:33)(cid:3)
(cid:37)
(cid:37)(cid:40)
(cid:6)(cid:28)(cid:32)(cid:27)(cid:31)(cid:5)(cid:16)(cid:15)(cid:30)(cid:19)(cid:18)(cid:1)
(cid:8)(cid:19)(cid:15)(cid:31)(cid:32)(cid:29)(cid:23)(cid:36)(cid:15)(cid:31)(cid:23)(cid:28)(cid:27)
(cid:10)(cid:28)(cid:23)(cid:30)(cid:19)(cid:1)
(cid:9)(cid:27)(cid:20)(cid:32)(cid:30)(cid:23)(cid:28)(cid:27)
(cid:7)(cid:15)(cid:31)(cid:15)(cid:1)
(cid:12)(cid:19)(cid:31)(cid:19)(cid:27)(cid:31)(cid:23)(cid:28)(cid:27)
(cid:6)(cid:28)(cid:32)(cid:27)(cid:31)(cid:1)
(cid:13)(cid:19)(cid:25)(cid:19)(cid:17)(cid:31)(cid:23)(cid:28)(cid:27)
(cid:32)(cid:27)(cid:26)(cid:15)(cid:27)(cid:15)(cid:21)(cid:19)(cid:18)(cid:1)
(cid:33)(cid:28)(cid:29)(cid:24)(cid:25)(cid:28)(cid:15)(cid:18)(cid:30)
(cid:2)(cid:31)(cid:29)(cid:32)(cid:30)(cid:31)(cid:19)(cid:18)(cid:4)(cid:1)
(cid:23)(cid:30)(cid:28)(cid:25)(cid:15)(cid:31)(cid:19)(cid:18)(cid:3)
(cid:29)(cid:17)(cid:32)(cid:20)(cid:31)(cid:35)(cid:20)(cid:2)(cid:37)(cid:4)(cid:26)(cid:3)
(cid:1)
(cid:25)
(cid:15)
(cid:17)
(cid:23)
(cid:29)
(cid:28)
(cid:31)
(cid:30)
(cid:22)
(cid:23)
(cid:1)
(cid:19)
(cid:29)
(cid:28)
(cid:31)
(cid:30)
(cid:30)
(cid:17)
(cid:23)
(cid:31)
(cid:30)
(cid:23)
(cid:31)
(cid:15)
(cid:31)
(cid:30)
(cid:37)(cid:8) (cid:12)(cid:15)(cid:32)
(cid:37)(cid:9) (cid:12)(cid:15)(cid:32)
(cid:6)(cid:6)(cid:6)
(cid:37)(cid:19) (cid:12)(cid:15)(cid:32)
(cid:6)(cid:6)(cid:6)
(cid:6)(cid:6)(cid:6)
(cid:6)(cid:6)(cid:6)
(cid:6)
(cid:6)
(cid:6)
(cid:6)
(cid:6)
(cid:6)
(cid:6)
(cid:6)
(cid:6)