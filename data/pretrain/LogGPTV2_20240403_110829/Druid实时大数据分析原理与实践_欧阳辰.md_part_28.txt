## Page 254
确定好一个Leader后，这个Leader就会定期运行一些任务。
式，从MySQL服务器获取规则和Segment的信息的。DruidCoordinator类图如图8-16所示。
MetadataSegmentManager和MetadataRuleManager这两个接口的实现类都是通过SQL查询方
Coordinator.java。大部分核心代码在相同目录中也可以找到。
管理工具或者参数来配置。这些规则包括：
集群的情况。
史节点获取Zookeeper上的指令来装载和移除Segment，所以每个历史节点不需要看到整个
直接和历史节点发生调用关系，而是将Zookeeper作为桥梁，将指令发送到Zookeeper上，历
230
DruidCoordinator引入了不少管理类，用于获取Segment与集群的信息和管理能力。例如，
Coordinator启动是从 start()开始的，首先通过Zookeeper的LeaderLatch选取一个Leader，
Coordinator装载和移除Segment的依据来自于一系列规则，这些规则可以通过Druid的
Coordinator的代码入口在$druid\server\src\main\java\io\druid\servercoordinator\Druid-
另外，也可以设置移除（Drop）规则，类似于装载规则。
·时间段装载（LoadByInterval）
·永久装载（LoadForever）
DruidCoordinator采用定期运行任务的设计模式，它包含一些不同目的的任务。它并不
·最近时段装载（LoadByPeriod）
inato
图8-16Druid Coordinator类图
SOLMetadataConector connector:
Druid实时大数据分析原理与实践
文
aSegmentManager
entManager
---
## Page 255
第8章
private LeaderLatch createNewLeaderLatch()
public void start()
@LifecycleStart
return leaderLatch.getAndSet(newLeaderLatch);
newLeaderLatch.addListener(
final LeaderLatch newleaderLatch=new LeaderLatch(...);
}catch （Exception e）{
try{
createNewLeaderLatch();
Execs.singleThreaded("CoordinatorLeader-%s")
new LeaderLatchListener()
throw Throwables.propagate(e);
leaderLatch.get().start();
public void notleader()
@Override
public void isLeader()
@0verride
核心源代码探析
DruidCoordinator.this.stopBeingleader();
DruidCoordinator.this.becomeLeader();
231
---
## Page 256
private void becomeLeader()
依附当前的Coordinator，开始定期执行任务。
232
try{
synchronized（lock）{
if （indexingServiceClient !=null）{
coordinatorRunnables.add(
final List> coordinatorRunnables=
final int startingleaderCounter =leaderCounter;
serviceAnnouncer.announce(self);
serverInventoryView.start();
metadataRuleManager.start();
metadataSegmentManager.start();
leader=true;
leaderCounter++;
if(!started）{
在becomeLeader（）方法中，由于已经确定当前节点为Leader，
coordinatorRunnables.add(
Pair.of(
return;
config.getCoordinatorIndexingPeriod()
Pair.of(
new CoordinatorHistoricalManagerRunnable(startingleaderCounter),
Lists.newArrayList(）;
startingLeaderCounter
new CordinatorIndexingServiceRunnable(makeIndexingServiceHelpers(),
Druid实时大数据分析原理与实践
一些Runnable对象就可以
---
## Page 257
public CoordinatorHistoricalManagerRunnable(final int startingLeaderCounter)
ingServiceRunnable.
第8章
super(ImmutableList.of(
new DruidCoordinatorSegmentInfoLoader(DruidCoordinator.this),
catch（...）{
newDruidCoordinatorCleanupOvershadowed(DruidCoordinator.this),
new DruidCoordinatorCleanupUnneeded(DruidCoordinator.this),
new DruidCoordinatorRuleRunner(DruidCoordinator.this),
CoordinatorHistoricalManagerRunnable包括多个具体的任务集合。
for (final Pair coordinatorRunnable
ScheduledExecutors.scheduleWithFixedDelay(
核心源代码探析
coordinatorRunnable.rhs,
config.getCoordinatorStartDelay(),
exec,
coordinatorRunnables）{
newCallable()
public ScheduledExecutors.Signal call()
private final CoordinatorRunnable theRunnable= coordinatorRunnable.lhs;
@Override
if (leader && startingleaderCounter ==leaderCounter）
theRunnable.run();
233
---
## Page 258
Y的Cost函数如图8-17所示。
ment，时间段分别为A、B和C，那么Cost(A,Bunion C)=Cost(A,B)+Cost(A,C)。
egy.java中的代码。
hub.com/druid-io/druid/pul/2972，可以直接查看$druid/server/coordinator/CostBalancerStrat-
同历史节点上，最大利用集群的能力，避免大量查询集中在集群中的某些机器上。
所覆盖到。
果两个Segment的时间靠近，它们就容易被同一个Query所覆盖到，因为查询的时间通常是
Segment的Cost Function，这个Cost是通过两个Segment被同时查询的可能性来定义的。如
234
这一改进最大的特点是Cost Function 中引人了可累加性（Additive），例如有3个Seg-
Druid0.9.1引入了更加高效的机制，算法也更为复杂，有兴趣的读者可以访问https://git-
Druid0.9.0之前的Balancer策略比较简单和粗暴。
Balancer的想法就是尽量让那些容易被同一个查询覆盖的 Segment分布在整个集群的不
new DruidCoordinatorLogger(DruidCoordinator.this)
在Druid0.9版本中，Balancer的策略是IntervalbasedCost，基本想法是定义任何两个
new DruidCoordinatorBalancer(DruidCoordinator.this),
·gapPenalty是考虑两个Segment的时间相邻性或者重叠。
·dataSourcePenalty是考虑数据源的同源性。
·Balancer：定时整理Segment分布的平衡性，移动部分 Segment 以平衡负载。
·RuleRunner：装载规则信息，并且应用到所有Segment。
·SegmentInfoLoader：装载Segment信息，删除无效的 Segment信息。
recencyPenalty是考虑当前时间两个Segment的时间距离。
Druid实时大数据分析原理与实践
---
## Page 259
public DruidCoordinatorRuntimeParams run(DruidCoordinatorRuntimeParams params)
//DruidCoordinatorBalancer.java
new DruidCoordinatorBalancer(DruidCoordinator.this),
Cost(B,B)，如图8-18所示。
//DruidCoordinator.java
二是两个 Segment 之间没有任何交集。
第8章
for（int iter=0;iter<maxSegmentsToMove;iter++）{
final BalancerSegmentHolder segmentToMove=Strategy.pickSegmentToMove(
在计算第一种情况时，假设交集的点为Y_0，那么Cost(X,Y)=Cost(A,Y)+Cost(B,C)+
if (segmentToMove != null && params.getAvailableSegments().contains(segmentToMove.
移动部分 Segment的逻辑代码如下：
在实际计算中，有两种情况：一是两个Segment之间有时间段交集，例如，xo<yo<x1；
final ServerHolder holder =strategy.findNewSegmentHomeBalancer(segmentToMove.
getSegment())){
核心源代码探析
ServerHolderList);
getSegment(),
ServerHolderList);
图8-18新算法的成本计算示意图
Cost(X,Y)=
Cost(X,Y)=Cost(A,Y)+Cost(B,C)+Cost(B,B)
图8-17新Cost公式
xo
x1
ry1
235
---
## Page 260
protected void moveSegment(
236
loadPeon.loadSegment(segment,
final DruidCoordinatorRuntimeParams params
final ImmutableDruidServer toServer,
final BalancerSegmentHolder segment,
new LoadPeonCallback()
public void execute()
@Override
if （holder =null）
}catch(Exception e){
moveSegment(segmentToMove,holder.getServer(),params);
try{
throw Throwables,propagate(e);
}else if（callback!=null）{
if (curator.checkExists().forPath(toServedSegPath) != null && curator.
callback.execute();
dropPeon.dropSegment(segment,callback);
getSegmentsToDrop().contains(segment))[
checkExists().forPath(toLoadQueueSegPath)== null &&!dropPeon.
Druid实时大数据分析原理与实践
---
## Page 261
周边工具和生态软件也变得更加容易。Druid拥有小而美的代码库，非常适合对数据库设计
体设计比较开放，包括对外JSON标准，内部元数据状态的设计也很清楚，因此，开发Druid
对于一些有复杂要求的数据和查询的场景来说，提供了很多扩展机会。另外，由于Druid整
式。Druid整体设计也充分考虑到扩展性，在数据索引和查询部分都支持一定程度的扩展，这
8.8小结
历史节点操作完成后将会删除该ZK节点。
作Zookeeper，把Segment的来源和目标机器都写入Zookeeper，等待历史节点进行实际操作，
ancer任务，通过BalancerStrategy对象获取最需要移动的若干Segment，而后通过curator操
第8章核心源代码探析
感兴趣的同学阅读和学习。
Druid的代码整体实现非常简洁，很少看到过多的余代码，也很少使用复杂的设计模
上面代码片段解释了Segment移动的管理过程，作为定期运行的DruidCoordinatorBal-
237
---
## Page 262
9.1.1Druid监控指标
法，因此我们可以轻松地利用这些特性对Druid进行有效监控。
整。幸运的是，正如其他成熟的项目一样，Druid自身提供了丰富的监控指标与指标输出方
标对系统状态做出数据化的衡量，对系统表象进行根因分析，并进一步对系统做出必要的调
（Monitoring），及时并全面地获取其主要运行指标（Metric）的实时数值，然后通过这些指
9.1Druid监控
配置中“druid.emitter”参数的值来设置发送开关。
外发送两种方式。不过，Druid系统默认不会主动发送Metric信息，因此用户需要通过更改
指标。Druid便提供了丰富的指标供系统监控使用，并且提供了直接写日志和通过HTTP往
Druid运维管理相关的知识。
知识也就成为了一门必修课。本章会从Druid系统的监控、告警和安全等方面分享一些关于
理，对于想成功实践Druid技术的用户来说，掌握监控Druid的必要技巧和了解其相关安全
状态下，那么该系统不仅很难充分发挥出其效能，而且会具有较高的运维风险。基于这个道
被有效监控，以及建立起完善的安全保护机制。因为如果一个系统运行在不可知甚至不可控
监控和安全
第
无论什么系统，如果想要被有效地监控，首要条件往往是其能够提供必要且充分的监控
为了精细化、实时地管理Druid系统，首当其冲的任务便是对Druid系统实施有效监控
一个应用系统的成功不仅仰仗该系统所能提供的功能性需求，还取决于该系统是否能够
---
## Page 263
来，我们将依次介绍一些主要的监控指标（注：主要基于Druid0.9.1.1版本）。
且拥有一些通用的字段。
第9章监控和安全
query/time
query/intervalChunk/time
query/node/ttfb
query/node/bytes
query/node/time
query/bytes
指标名称
查询节点的指标如下。
查询相关监控指标
一般来说，Druid的监控指标可分为查询相关、数据消费相关与协调相关等种类。接下
·value:Metric的值。
·host：发送Metric的主机名。
metric:
·timestamp：Metric生成的时间点的时间戳。
无论使用哪种方式往外发送Metric信息，
·http：直接通过HTTP往外发送Metric信息。
·logging：往日志里面写Metric信息。
·noop：默认值，
service:
Metric的名字。
发送Metric的服务名字。
，不往外发送任何Metric信息。
启用时本指标才有效
查询一个间隔块所花费的时间。单位为毫秒。仅当间隔块被
字节所花费的时间。单位为毫秒
数据量。单位为字节
在独立的历史节点/实时节点上执行完一条query后所返回的
间。单位为毫秒
在独立的历史节点/实时节点上执行完一条query所花费的时
执行完一条query后所返回的数据量。单位为字节
执行完一条query所花费的时间。单位为毫秒
查询节点首次从独立的历史节点/实时节点上收到查询返回的
描述
，所有的Metric信息都是JSON格式的数据，
<1秒
<1秒
<1秒
<1秒
常规值
并
239
---
## Page 264
240
*/hitRate
*/evictions
*/misses
*/hits
*/sizeBytes
*/numEntries
query/cache/total/*
query/cache/delta/*
指标名称
segment/scan/pending
query/segment/time
query/time
指标名称
query/cpu/time
Cache/time
query/segmentAnd-
segment/scan/pending
query/wait/time
query/segment/time
query/time
指标名称
Cache的指标如下。
实时节点的指标如下。
历史节点的指标如下。
Cache的收回数量
Cache的没命中数
Cache的条目字节大小
Cache的条目数量
总的Cache指标
自从上次发送后的Cache指标
等待被浏览的Segment的数量
盘读取到内存页所花费的时间。
查询一个Segment所花费的时间，其中包含将Segment从磁
执行完一条query所花费的时间。单位为毫秒
描述
执行完一条query所花费的CPU 时间。单位为微秒
历史节点上被启用）所花费的时间。单位为毫秒
查询一个 Segment或者在Cache中命中数据（如果Cache在
等待被浏览的 Segment的数量
Cache的命中率
Cache的命中数
描述
等待
盘读取到内存页所花费的时间。单位为毫秒
查询一个Segment 所花费的时间，其中包含将Segment从磁
执行完一条query所花费的时间。单位为毫秒
描述
一个Segment被浏览所花费的时间。单位为毫秒
单位为毫秒
Druid实时大数据分析原理与实践
约为40%
各有差异
各有差异
各有差异