in intervals w ranging from 167 ms (when n = 12) to 21 ms (when n = 96). Finally,
we conﬁgure ALE-E with 12 intervals and we refer to this conﬁguration as ALE-E(12).
To accommodate the high trafﬁc rates in our traces, we use CBFs with C = 30000
counters and 4 hash functions.
RTT Estimation Accuracy. We ﬁrst report on the per-sample RTT estimation accuracy
across the various methods. While this is not a very natural metric of comparison—
most applications would be in interested in some statistic over these—it does serve to
illustrate some of the intuition for why ALE performs comparably, and talks to its suit-
ability for certain situations. Fig. 3 presents a box and whisker plot of the differences
between the RTT reported by each method and tcptrace. In other words, it shows
the distribution of RTTtcptrace − RTTALE over all RTT samples in Trace 1 for dif-
ferent ALE conﬁgurations. Recall that the size of the interval bounds the accuracy for
ALE. To draw out how ALE might perform at different regimes, the plot is partitioned
into four latency regions (unrelated to w): (0, 60] ms, (60, 120] ms, (120, 300] ms, and
(300, 2000] ms. For example, the ﬁrst group (left) plots the distribution for all samples
where the baseline approach reported a latency between 0 and 60 ms. The horizontal
line in the center of the ﬁgure marks the region where the difference is zero (the val-
ues reported by the baseline and ALE are identical). The height of the box spans the
inter-quartile range of the differences in the RTT estimate and the point in the box is
the median difference.
Not surprisingly, across all latency ranges, increasing the number of buckets im-
proves accuracy. We also note that ALE-U(96), which almost completely agrees with
the far more expensive baseline approach. There are a few rare large differences, but
this may be quite acceptable considering the savings in memory; especially keeping
90
S. Gangam et al.
EXCESS
(0,60]
MISSED
(60,120]
VALID.SAMPLES
(300,2e+03
(120,300]
E(12)U(12)U(24)U(48)U(96)
0e+00
1e+05
2e+05
3e+05
4e+05
0
60000
80000
40000
20000
0
3e+05
2e+05
1e+05
0e+00
50000
100000
150000
Number of Samples
)
s
(
e
m
T
i
80
60
40
20
0
TCPTRACE
U(96)
0.1
0.2
0.4
0.3
0.5
Sampling Rate
0.6
0.7
Fig. 4. Comparison of excess and missed samples
across the different approaches
Fig. 5. Compute time for ALE-U(96)
and tcptrace and for different thinned
traces
in mind that per-sample RTT estimates are rarely used directly. In Fig. 3, we note that
ALE-E(12) does almost as well as ALE-U(96) for latencies less than 60 ms even though
ALE-E(12) uses 8 times less memory. The price, however, is reduced accuracy for la-
tencies above 60 ms.
Excess and Missed Samples. As discussed previously, the ALE algorithms sometimes
miss RTT samples reported by the baseline approach (RTT misses, e.g., when CBF false
positives decrement counters prematurely); and sometimes report RTTs not reported by
the baseline (excess RTTs, due to, e.g., CBF false positives or reordered packets). We
plot the absolute numbers of each, separated by latency regions in Fig. 4. We observe
that adding more memory (buckets) reduces both missed and excess RTTs. With respect
to ALE-E, we see that missed and excess RTTs are few when latencies are small, but
the excess samples are common for large latency values. As the CBFs for each bucket
in ALE-E are shifted and merged, they are increasingly attenuated and have higher false
positive rates. Nevertheless, ALE-E is still accurate up to 120 ms, which may be enough
for interactive applications.
Fig. 4 can qualitatively explain the contribution of the different sources of error. For
example, when ALE-U uses sufﬁciently large memory (e.g., U(96)) the effects of false
positives and negatives are mitigated. U(96) has few misses and excess values indicating
that there are few retransmitted and reordered packets in the CAIDA traces. If the results
in Fig. 3 and Fig. 4 do not improve with additional memory, one can conclude that the
errors are due to re-ordered and retransmitted packets.
Errors in Flow Latency Properties. Typical ﬂow performance monitoring applications
track some statistic of the ﬂow latencies, rather than use the RTT samples directly.
Consider the example of VoIP quality tracking, very sensitive to jitter. This involves
monitoring and tracking the variation in latencies of a ﬂow, relating this to the user
perceived quality of the session. We study the impact of the approximations native
to ALE on two relevant ﬂow statistics: (i) median latency of a ﬂow, which impacts
the quality of interactive applications (network games, web browsing), and (ii) jitter
(latency variation) in a ﬂow, which impacts the perceived quality of most real-time
streaming applications (VoIP, video conferencing).
Fig. 6a plots the distribution of differences in the median latency computed by the
baseline and ALE. Each curve is a distribution of the values of medianbaseline−medianALE
Estimating TCP Latency Approximately with Passive Measurements
91
E(12)
TCPTRACE
U(12)
U(24)
U(48)
U(96)
E(12)
TCPTRACE
U(12)
U(24)
U(48)
U(96)
F
D
C
1.0
0.8
0.6
0.4
0.2
0.0
−40
40
Median_B − Median_ALE (ms)
−20
0
20
0
=
x
F
D
C
1.0
0.8
0.6
0.4
0.2
0.0
−100
−50
50
SD_B − SD_ALE (ms)
0
100
(a) Difference in median latency.
(b) Difference in latency std. dev.
Fig. 6. Accuracy for latency statistics over all ﬂows
over all ﬂows. The vertical black line in the middle represents perfect agreement with
the baseline. In the ﬁgure, we note that ALE-U(96) performs best over the other in-
stances: at least 97% of the ﬂows have medians within 10 ms of the baseline (shown
by the vertical red lines). To put this in context, the acceptable latency for VoIP is be-
tween [20, 150] ms: being off by 10 ms does not affect the monitoring application to a
large degree. The other ALE-U instances perform as expected: larger number of buckets
tends to make the curve steeper (and more aligned with the center line). We also note
that ALE-E performs reasonably well: about 65% of the ﬂows have median latency es-
timate within 15 ms of the actual value. Since the median is robust to outliers, some of
the large errors that ALE-E reports for individual samples are ﬁltered out. Thus, along
with ALE-U(96) and perhaps ALE-U(48), ALE-E might be effective as a lightweight
method to monitor the quality of low latency sessions.
In a similar comparison, Fig. 6b plots the CDF of disagreement in the standard de-
viations of ﬂow latencies, i.e., σbaseline − σALE. The vertical black line (at x = 0)
marks the region where the std. dev. reported by ALE matches that of the baseline per-
fectly. Firstly, we notice that the baseline approach in general reports lower variance
than the ALE approaches (the cases when the difference is negative). This is because
the latencies are dispersed over a time interval w. In the ﬁgure, the red vertical lines
indicate the 20 ms boundary from zero. We again see that ALE-U(96) performs better
than any of the others, and 95.7% of the ﬂows have delay variance that differ from the
baseline reported version by at most 20 ms. We also see that ALE-E performs poorly
on this comparison. About 80% of the ﬂows disagree with the baseline reading by at
least 20 ms. This is most likely due to CBF attenuation in the larger intervals leading to
a large number of false positives.
Memory and Compute Overhead. We thin out the trace by sampling ﬂows uniformly
at random at rates 0.1, 0.2, . . . 0.7, such that there are 5 pcap sub-traces at each rate. For
a given rate, all the 5 pcap sub-traces have about the same number of ﬂows. A sub-trace
with higher sampling rate requires processing of more packets and ﬂows per unit time.
Using these sub-traces, we run ALE-U(96) and tcptrace (both implemented in GNU C),
on an AMD quad core 512 KB cache, 2.6 GHz, 8 processor machine with 32 GB RAM
to study the overhead. We use tstime [3] tool which leverages the GNU Linux taskstats
API to get user time, system time, high water RSS (resident segment size) memory and
high water VSS (virtual segment size) memory of a process.
92
S. Gangam et al.
As expected, ALE-U(96) takes constant high water RSS memory of 2.0 MB and
high water VSS memory 9.8 MB for all sampling rates. In contrasting, tcptrace requires
RSS memory ranging from ≈ 64 MB (at rate 0.1) to ≈ 460 MB (at rate 0.7). The VSS
memory requirement ranges from ≈ 74 MB to ≈ 468 MB. These experiments conﬁrm
our hypothesis that ALE has signiﬁcantly less memory overhead.
Fig. 5 shows the times taken to process at different sampling rates for ALE and
tcptrace. As the data rates increase, tcptrace takes increasingly longer time than ALE.
tcptrace has higher variability in compute times. ALE, by avoiding TCP state, has less
variability and takes constant per-packet processing time (on average) at all trafﬁc rates.
4 Discussion
Though our implementation does not incorporate computational optimizations, we hope
that a performance-focused implementation (e.g., parallelizing ACK lookups in the n
buckets) would be even faster. An optimized implementation can ﬁt the data required
by a wide range of ALE conﬁgurations in the caches of low-end Atom and ARMv8
processors (currently between 256 KiB and 1 MiB). The evaluated conﬁguration with 48
buckets and 30,000 4-bit counters per bucket would require about 700 KiB of memory
for processing 10 Gbit/s links. We note that ALE lends itself well to implementation in
hardware: ALE’s basic building blocks are hashing functions, 4-bit accumulators, and
4-bit comparators.
Current home DSL gateways usually run local area networks that run at 100 Mbit/s
and connect to the Internet with connections up to 28 Mbit/s. In an heavy-loaded sce-
nario with an Internet download at 28 Mbit/s and a local transfer at 100 Mbit per second,
the gateway would receive 11000 full-size (1500 B) packets/s (the absolute number of
ﬂows does not impact ALE in any way). Conﬁguring ALE-U(12) with 12 buckets and
W = 200 ms would require bucket sizes of 1058 counters per bucket, for a total mem-
ory utilization of 12 × 1058 × 4 ÷ 8 ÷ 1024 = 6.2 KiB. This ﬁts easily in the cache of
current MIPS and ARM processors used in home DSL gateways.
References
1. CAIDA: Passive network monitors,
http://www.caida.org/data/realtime/passive/
2. tcptrace, http://www.tcptrace.org/
3. tstime, https://bitbucket.org/gsauthof/tstime/
4. Web10G, http://www.web10g.org
5. Bonomi, F., Mitzenmacher, M., Panigrahy, R., Singh, S., Varghese, G.: An Improved Con-
struction for Counting Bloom Filters. In: Azar, Y., Erlebach, T. (eds.) ESA 2006. LNCS,
vol. 4168, pp. 684–695. Springer, Heidelberg (2006)
6. Dick, M., Wellnitz, O., Wolf, L.: Analysis of Factors Affecting Players’ Performance and
Perception in Multiplayer Games. In: Proc. ACM Netgames (2005)
7. Fan, L., Cao, P., Almeida, J., Broder, A.Z.: Summary cache: a scalable wide-area web cache
sharing protocol. IEEE/ACM Trans. Netw. 8(3), 281–293 (2000)
8. He, Y., Faloutsos, M., Krishnamurthy, S., Huffaker, B.: On Routing Asymmetry in the Inter-
net. In: Proc. IEEE GLOBECOM (2005)
9. ITU-T. Recommendation G.114: One-way Transmission Time (May 2000)
Estimating TCP Latency Approximately with Passive Measurements
93
10. Jaiswal, S., Iannaccone, G., Diot, C., Kurose, J., Towsley, D.: Inferring TCP connection char-
acteristics through passive measurements. In: Proc. IEEE INFOCOM (2004)
11. Jiang, H., Dovrolis, C.: Passive estimation of TCP round-trip times. SIGCOMM Comput.
Commun. Rev. 32(3), 75–88 (2002)
12. Lance, R., Frommer, I.: Round-trip time inference via passive monitoring. SIGMETRICS
Perform. Eval. Rev. 33(3), 32–38 (2005)
13. Lee, M., Dufﬁeld, N., Kompella, R.R.: Not all microseconds are equal: ﬁne-grained per-ﬂow
measurements with reference latency interpolation. In: Proc. ACM SIGCOMM (2010)
14. Lee, M., Dufﬁeld, N., Kompella, R.R.: Leave them microseconds alone: Scalable architecture
for maintaining packet latency measurements. Technical report, Purdue Univ. (2011)
15. Veal, B., Li, K., Lowenthal, D.: New Methods for Passive Estimation of TCP Round-Trip
Times. In: Dovrolis, C. (ed.) PAM 2005. LNCS, vol. 3431, pp. 121–134. Springer, Heidelberg
(2005)
16. Xiu, X., Cheung, G., Liang, J.: Delay-cognizant interactive streaming of multiview video
with free viewpoint synthesis. IEEE Trans. on Multimedia 14(4), 1109–1126 (2012)