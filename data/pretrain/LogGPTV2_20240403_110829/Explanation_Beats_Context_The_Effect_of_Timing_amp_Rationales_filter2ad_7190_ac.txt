5.4.2 Permission Clarity (Clarity)
The extent to which users understand why an app needs
a permission was shown to affect users’ permission deci-
sions [3, 5, 31]. Therefore, we developed a three item scale to
measure the clarity of permission purposes (α = 0.91). We
were particularly interested in whether interacting with the
app increases the initial clarity of a permission request. So
we used this scale once before (ClarityPre) and once after app
interaction (ClarityPost). Sample items are “It is clear to me
why this app needs access to my {permission protected re-
source}” and “I have no idea why this app wants access to my
{permission protected resource}” (reverse coded). Items are
scored on a 7-point scale (1 = strongly disagree; 7 = strongly
agree), where higher scores indicate greater clarity.
Additionally we recorded participants’ permission decisions
(Decision): “Based on your interaction with this app, would
you grant this app access to your {permission protected re-
source}?” We also asked participants about what they thought
was the purpose of the requested permission (PermPurp). An-
swer options included “for the main functionality of the app”,
“for some additional feature functionality”, “do not know”,
or “for some other reason.” Additionally, questions were also
asked when rationales were provided. We recorded who, in the
participants’ opinion, provided the rationale (RationaleOrigin):
“the mobile operating system”, “the app developer” or “some
other entity”. We also asked participants to recall the content
of the rationale (RationaleRecall).
5.4.3 Control Variables from Previous Work
Previous research identiﬁed several situational, app and user-
speciﬁc variables that may also inﬂuence users’ permission
decisions. Therefore, we included the following variables
in our study to control for their effects: (1) Permission pur-
pose (PurposeMain, PurposeVisible, PurposeHidden), the purpose
associated with a permission request is one of the major pre-
dictors for permission decisions [3–7]. That is why we classi-
ﬁed permission requests in one of three permission purpose
categories. (2) Permission sensitivity (PermSens), previous re-
search found that permissions that the user considers sensitive
were more likely to be denied [3, 4, 8]. (3) Privacy concerns
USENIX Association
30th USENIX Security Symposium    791
(PrivConc) and (4) prior privacy experience (PriorExp) are re-
lated to users’ attitude towards their private data, thus, both
may affect users’ permission decisions [3, 9]. Next, we ex-
plain how these variables were measured.
Permission Sensitivity (PermSens): Three items were used
to measure the perceived sensitivity of requested permissions,
adapted from prior literature [46] to ﬁt in the context of per-
mission requests (α = 0.80). The instructions for participants
were the following “When using mobile apps, many people
ﬁnd that there are some resource accesses (permissions) that
they are generally comfortable granting, some accesses that
they are only comfortable granting under certain conditions,
and some accesses are too sensitive that they never or only
rarely are comfortable granting. Given the information that
this app will request access to your {permission protected re-
source}. Please indicate to what extent you agree or disagree
with the following statements.” Sample items are “In general,
I do not feel comfortable granting access to my {permission
protected resource}” and “The access to my {permission pro-
tected resource} is very sensitive to me.” Items are scored on
a 7-point scale (1 = strongly disagree; 7 = strongly agree),
where higher scores indicate higher/greater sensitivity.
Privacy Concerns (PrivConc): We measured privacy con-
cerns using a 3-item scale from previous work [47], which was
originally developed by Smith et al. [48]. We slightly adapted
this scale to measure privacy concerns in apps (α = 0.85).
Sample items are “Compared to others, I am more sensitive
about the way mobile apps handle my personal information”
and “To me, it is the most important thing to keep my pri-
vacy intact from mobile apps.” Items are scored on a 7-point
scale (1 = strongly disagree; 7 = strongly agree), where higher
scores indicate higher/more privacy concerns.
Prior Privacy Experience (PriorExp): We measured prior
privacy experience using a 3-item scale from previous
work [48], which was adapted to measure prior privacy expe-
rience with apps (α = 0.80). Sample items are “How often
have you personally experienced incidents whereby your per-
sonal information was used by some mobile app without your
authorization?” and “How much have you heard or read dur-
ing the last year about the use and potential misuse of the
information collected from mobile apps?” Items are scored
on a 7-point scale (1 = never; 7 = very great extent), where
higher scores indicate more exposure to privacy experiences.
Other Control Variables: Because users might behave dif-
ferently when they expect and know something, we controlled
for predictability of permission requests and users’ familiarity
with the app in addition to user demographics.
5.5 App Selection
The user study covered a wide range of apps that requested
different permissions for various purposes to rule out pos-
Figure 6: Four different versions of the same app depending
on timing (upfront/in-context) and rationales (with/without).
sible alternative explanations for our results depending on
app-related differences. To achieve that, we selected a set
of apps from different categories, each requesting a permis-
sion for one of the three permission purposes (PurposeMain,
PurposeVisible, PurposeHidden). However, we could not rely on
the standard Play categories, as apps are organized into super-
ordinate topics, where one topic can contain apps with com-
pletely different functionalities (e.g., productivity category
contains both barcode scanner and calendar apps). Therefore,
we clustered the apps from the empirical analysis based on
their description into 25 clusters using the Latent Dirichlet
Allocation (LDA) topic modelling technique and randomly
selected 10 clusters for the user study. We then manually
choose three apps per cluster, each requesting a permission
for one of the three permission purposes. Based on our empir-
ical analysis, we limited the study to the six most commonly
found permissions (MICROPHONE, CONTACTS, PHONE, CAMERA,
LOCATION, and STORAGE). We excluded any app that required
login (e.g., banking and dating apps), since we did not analyze
those in our empirical analysis. A list of the apps used in this
study and their categories are shown in Appendix D.
In total, we used 30 apps, of which we captured screenshots
of the states that led to the permission request. We used these
screenshots to create interactive mockup apps that worked
similar to real-world apps. Each app was then modiﬁed to re-
quest a permission for each of the four possible combinations
of timing (upfront/in-context) and rationales (with/without),
resulting in a total of 120 app variations. Figure 6 shows such
an app with the four different versions.
5.6 Rationale Selection
To investigate the effect of presence/absence of rationales
as they are intended to be [49, 50], we decided to only use
rationales with additional information. We also focused on
one standardized rationale design to ensure comparability of
the results, which was informed by the empirical analysis.
792    30th USENIX Security Symposium
USENIX Association
with rationalewith rationaleupfrontin contextwithout rationalewithout rationaleOur study apps showed participants one permission request
preceded by a rationale (depending on the experiment ver-
sion). For that, we chose the dialog design because it has the
highest priority in conveying information to the user [51],
and because the alternatives are often used for different pur-
poses (e.g., fullscreen views explain multiple permissions and
snackbars are displayed after a permission request).
As for the wording of rationales, guidelines of Google and
Apple recommend that rationales should use sentence case,
be short, clear, accurate, and polite so people do not feel pres-
sured [49, 50, 52]. From the empirical analysis, we extracted
rationales that followed these guidelines (e.g., “Access to
camera is required to make new photos”, “This app needs
your permission to store images to your device,” and “This
application requires the manage phone call permission to be
approved in order to use the favorite store functionality” ) and
derived a general sentence structure to use in our study: This
app requires access to your {permission} to {list of purposes}.
A sample rationale used in this study is found in Figure 1b
The extracted sentence structure then had to be ﬁlled with
meaningful permission purposes for each user study app. For
that, we manually ran each app, checked the app’s source code,
description, and rationale (if available). Then, we manually
selected reasonable purposes from a list of most common
permission purposes that we extracted from our empirical
analysis and related work [11] using Part-of-Speech tagging
(POS tagging) [53]. Examples of purposes include: ﬁnd bus
stops nearby, block harassing calls, and use speech translation.
5.7 Ethical Considerations
The study design and protocol were reviewed and approved
by the Ethics Review Board of our institution. We followed
the guidelines for academic requesters outlined by MTurk
workers [54]. All server-side software (i.e., Limesurvey Com-
munity Edition software) was self-hosted on a maintained and
hardened server to which only the researchers involved in this
study have access. At the beginning of the study, there was
an informed consent procedure, which provided participants
with details about the purpose of the study and the type of
data being collected. We also informed participants about the
option to withdraw from the study at any time.
6 Results
We used multilevel regression analysis to evaluate the effects
of timing and presence/absence of rationales on users’ per-
mission decisions (Decision), the evaluation of their decisions
(DES: DesInform, DesSatis, DesControl), and the perceived clar-
ity of the permission purpose (ClarityPost). All analyses were
performed with R 4.0.2 [55] and the package LME4 [56]. As
a data preparation step, we calculated mean scores for mea-
surements with multiple items. We also centered all LevelUser
and LevelRequest variables by their total mean (grand mean
centering) to facilitate interpretation of regression models.
A correlation analysis showed that participants’ education,
their computer science background, their familiarity with the
app, the predictability of the requested permission, and the
requested permission type were highly correlated. We also
observed a high positive correlation between the perceived
sensitivity of permissions and participants’ privacy concerns,
meaning that participants who care about their privacy usually
tend to ﬁnd permissions more sensitive [3]. Additionally, we
found a signiﬁcant negative correlation between participants’
permission clarity prior app interaction and the purpose of the
permission, which is conclusive since the purpose of permis-
sions requested for the main functionality or a visible feature
may be more clear to users than for a hidden feature.
6.1 Model Construction
We used a linear multilevel model for DesInform, DesSatis,
DesControl, and ClarityPost, whereas Decision (binary) was
modeled using a generalized linear multilevel model. The
comparison between a simple and a multilevel regres-
sion model showed that multilevel models explain our data
signiﬁcantly better (see Appendix C). To prevent over-
parameterization of the models, we built and tested them in
a step-by-step approach, following recommendations in the
literature [41] in each step. All models were calculated using
maximum likelihood estimation to ensure their comparability.
Next, we explain the model building process, which was held
constant for all outcome variables.
In a ﬁrst step, after a simple regression model, we cre-
ated a random intercept model by adding app and user as
random effects. In a second step, we included all variables
that were identiﬁed from previous work: ClarityPre [3, 5, 31],
PrivConc [3], PriorExp [9], Purpose [3–7], and PermSens [3,4,8].
We also added participants’ decision (Decision) as a control
variable to the DES, because the decision outcome (i.e., grant-
ing or denying a permission request) has an inﬂuence on
users’ comfort level with their decisions [3]. In a third step,
we added the variables of interest, Timing (upfront, in-context)
and Rationales (with, without). Finally, in a fourth step, we
added the interaction between Timing and Rationales when
this improved the model ﬁt. For more details about the model
building process, see Appendix C.
6.2 Final Models
The ﬁnal models were recalculated using Restricted Maxi-
mum Likelihood Estimation, which leads to a more conser-
vative and less error-prone estimation of the parameters [41].
Table 1 shows the ﬁnal model for each outcome variable.
We followed suggestions of literature [57] to identify and
handle outliers. We checked for multi-construct outliers on the
aggregated LevelApp and found no conspicuous data points.
USENIX Association
30th USENIX Security Symposium    793
LevelUser
(Intercept)
PrivConc
PriorExp
LevelRequest
Purpose
VisibleFeature
HiddenFeature
ClarityPre
PermSens
Decision(Allow)
Table 1: The ﬁnal multilevel models.
Decision
Odds Ratio (std. β)
DesInform
β (std. β)
DesSatis
β (std. β)
DesControl
β (std. β)
ClarityPost
β (std. β)
2.92 (1.06)**
0.64 (-0.57)***
1.91 (1.00)***
3.90 (-0.54)***
-0.02 (-0.02)
-0.03 (-0.03)
6.17 (0.24)***
0.06 (0.07)
-0.25 (-0.35)***
5.34 (0.07)***
0.00 (0.00)
-0.29 (-0.32)***
4.53 (-0.21)***
-0.01 (-0.01)
-0.09 (-0.07)***
0.14 (0.07)
-0.48 (-0.23)**
0.59 (0.61)***
-0.03 (-0.02)
–
0.36 (0.18)***
0.93 (0.46)***
-0.37 (-0.18)**
1.35 (0.3)
0.35 (-1.05)*
2.06 (1.53)***
0.53 (-0.99)***
–
0.24 (0.18)*
-0.05 (-0.04)
0.18 (0.28)***
-0.01 (-0.01)
0.44 (0.32)***
0.03 (0.03)
0.07 (0.06)
0.09 (0.18)***
0.00 (0.01)
-0.57 (-0.53) ***
0.18 (0.13)
-0.05 (-0.04)