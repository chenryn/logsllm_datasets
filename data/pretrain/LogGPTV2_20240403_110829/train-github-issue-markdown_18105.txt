I installed pytorch, and my cuda version is upto date. But when I run my
command, I get the following error:  
My system:
Windows 10  
NVIDIA GeForce GTX 960M  
Python 3.6(Anaconda)  
PyTorch 1.1.0  
CUDA 10  
`import torch  
import torch.nn as nn  
from data_util import config  
use_cuda = config.use_gpu and torch.cuda.is_available()  
def init_lstm_wt(lstm):  
for names in lstm. _all_weights:  
for name in names:  
if name.startswith('weight_'):  
wt = getattr(lstm, name)  
wt.data.uniform_(-config.rand_unif_init_mag, config.rand_unif_init_mag)  
elif name.startswith('bias_'):  
# set forget bias to 1  
bias = getattr(lstm, name)  
n = bias.size(0)  
start, end = n // 4, n // 2  
bias.data.fill_(0.)  
bias.data[start:end].fill_(1.)  
def init_wt_normal(wt):  
wt.data.normal_(std=config.trunc_norm_init_std)  
class Encoder(nn.Module):  
def **init** (self):  
super(Encoder, self). **init** ()  
self.embedding = nn.Embedding(config.vocab_size, config.emb_dim)  
init_wt_normal(self.embedding.weight)  
self.lstm = nn.LSTM(config.emb_dim, config.hidden_dim, num_layers=1,
batch_first=True, bidirectional=True)  
init_lstm_wt(self.lstm)  
self.W_h = nn.Linear(config.hidden_dim * 2, config.hidden_dim * 2, bias=False)
class Decoder(nn.Module):  
def **init** (self):  
super(Decoder, self). **init** ()  
self.embedding = nn.Embedding(config.vocab_size, config.emb_dim)  
init_wt_normal(self.embedding.weight)  
class Model(object):  
def **init** (self, model_file_path=None, is_eval=False):  
encoder = Encoder()  
decoder = Decoder()  
if use_cuda:  
encoder = encoder.cuda()  
decoder = decoder.cuda()  
model=Model()` `Traceback (most recent call last):  
File "G:/public_workspace/pointer_summarizer-pytorch-2.7/data_util/test4.py",
line 41, in  
model=Model()  
File "G:/public_workspace/pointer_summarizer-pytorch-2.7/data_util/test4.py",
line 39, in **init**  
encoder = encoder.cuda()  
File "D:\soft\anaconda\lib\site-packages\torch\nn\modules\module.py", line
266, in cuda  
return self._apply(lambda t: t.cuda(device))  
File "D:\soft\anaconda\lib\site-packages\torch\nn\modules\module.py", line
194, in _apply  
module. _apply(fn)  
File "D:\soft\anaconda\lib\site-packages\torch\nn\modules\module.py", line
200, in _apply  
param.data = fn(param.data)  
File "D:\soft\anaconda\lib\site-packages\torch\nn\modules\module.py", line
266, in  
return self. _apply(lambda t: t.cuda(device))  
File "D:\soft\anaconda\lib\site-packages\torch\cuda_ _init__.py", line 176, in
_lazy_init  
torch. _C. _cuda_init()  
RuntimeError: CUDA error: unknown error`I annotated a part ,and the error
disappeared`import torch  
import torch.nn as nn  
from data_util import config  
use_cuda = config.use_gpu and torch.cuda.is_available()  
def init_lstm_wt(lstm):  
for names in lstm. _all_weights:  
for name in names:  
if name.startswith('weight_'):  
wt = getattr(lstm, name)  
wt.data.uniform_(-config.rand_unif_init_mag, config.rand_unif_init_mag)  
elif name.startswith('bias_'):  
# set forget bias to 1  
bias = getattr(lstm, name)  
n = bias.size(0)  
start, end = n // 4, n // 2  
bias.data.fill_(0.)  
bias.data[start:end].fill(1.)  
def init_wt_normal(wt):  
wt.data.normal(std=config.trunc_norm_init_std)  
class Encoder(nn.Module):  
def **init** (self):  
super(Encoder, self). **init** ()  
self.embedding = nn.Embedding(config.vocab_size, config.emb_dim)  
init_wt_normal(self.embedding.weight)  
# self.lstm = nn.LSTM(config.emb_dim, config.hidden_dim, num_layers=1,
batch_first=True, bidirectional=True)  
# init_lstm_wt(self.lstm)  
# self.W_h = nn.Linear(config.hidden_dim * 2, config.hidden_dim * 2,
bias=False)__
class Decoder(nn.Module):  
def **init** (self):  
super(Decoder, self). **init** ()  
self.embedding = nn.Embedding(config.vocab_size, config.emb_dim)  
init_wt_normal(self.embedding.weight)  
class Model(object):  
def **init** (self, model_file_path=None, is_eval=False):  
encoder = Encoder()  
decoder = Decoder()  
if use_cuda:  
encoder = encoder.cuda()  
decoder = decoder.cuda()  
model=Model()`