title:Pseudo-Randomness and the Crystal Ball
author:Cynthia Dwork
Pseudo-Randomness and the Crystal Ball
Cynthia Dwork
Harvard University
Department of Computer Science
Cambridge, MA, USA
ABSTRACT
The last decade has witnessed the emergence of algorithmic fairness
as a new frontier in the application of theoretical computer science
to problems of societal concern. The delay between academic in-
vestigation and industrial rhetoric acknowledging the concern has
been surprisingly brief. This alacrity has positive and negative con-
sequences, to wit, opportunity for quick adoption of technology
and pressure for quick fixes.
An early dichotomy in the literature differentiates between group
notions of fairness — based on comparing prediction/classification
statistics for (typically disjoint) demographic groups — and individ-
ual fairness, i.e., requiring that similar individuals be treated simi-
larly [2]. Both face challenges. Group fairness criteria are appealing
but can be meaningless [2, 8] or mutually incompatible [1, 7]; indi-
vidual fairness requires a task-specific metric specifying the degree
to which pairs of individuals are (dis)similar for the purposes of the
task at hand. Considerable progress toward learning such a metric
from an expert was made only recently [6]; see also [4].
Focus on similarity metrics has thrown into relief foundational
questions about randomness and uncertainty. Some questions are
specific to the philosophy of fairness, for example, questions about
the value of an ex ante guarantee of fairness offered by a roll of
the dice. Others involve the choice of metric, exposing the role of
context. For example, should the likelihood that a job candidate will
succeed in the advertised position be evaluated in the context of
the work culture of the specific company that listed the position, or
in an ideal, or even just a more egalitarian company with stronger
culture of inclusivity?
A third set of questions revolves around the meaning of a “prob-
ability” for non-repeatable events, such as: the probability that this
individual will succeed in this job, given that tenure in the job is a
non-repeatable event? In cryptography, parties are algorithms that
flip coins. Individuals flip their coins, interact with environments,
also endowed with coins, and the two sources together give us
well defined probability spaces. However, when the randomness
is no longer under the control of algorithms, this model no longer
applies.
Outcome Indistinguishability is a desideratum for prediction algo-
rithms. As with pseudo-randomness, Outcome Indistinguishability
is defined with respect to a computational class C of distinguishers.
Specifically, a prediction algorithm mapping individuals to [0, 1] is
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea.
© 2021 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-8454-4/21/11.
https://doi.org/10.1145/3460120.3482790
Outcome Indistinguishabile with respect to C if outcomes drawn ac-
cording to its predictions are indistinguishable, by any computation
in C, from outcomes drawn according to Nature [3]. In other words,
the model of the real world provided by the algorithm cannot be
falsified by members of C.
With this notion in place we obtain a natural hierarchy of Out-
come Indistinguishability, with the levels differing in the degree of
access that the distinguisher has to the prediction algorithm. The
lower levels of the hierarchy are equivalent to multi-accuracy and
multi-calibration, previously explored in an approach to fairness
aiming to bridge the gap between individual and group notions [5].
We will discuss some highlights of what is known, and what is
new, in this rapidly evolving area.
KEYWORDS
Algorithmic fairness; theory of algorithmic fairness; fairness; indi-
vidual fairness; indistinguishability; outcome indistinguishability;
machine learning; artificial intelligence; risk assessment; prediction
algorithms; individual probability; forecasting; calibration; multi-
calibration
ACM Reference Format:
Cynthia Dwork. 2021. Pseudo-Randomness and the Crystal Ball . In Proceed-
ings of the 2021 ACM SIGSAC Conference on Computer and Communications
Security (CCS ’21), November 15–19, 2021, Virtual Event, Republic of Korea.
ACM, New York, NY, USA, 2 pages. https://doi.org/10.1145/3460120.3482790
BIOGRAPHY
Cynthia Dwork, Gordon McKay Professor of Computer Science at
the Harvard Paulson School of Engineering, and Affiliated Faculty
at Harvard Law School and Harvard Department of Statistics, uses
theoretical computer science to place societal problems on a firm
mathematical foundation. Dwork’s earliest work in distributed com-
puting established the pillars on which every fault-tolerant system
has been built for decades. Her innovations have modernized cryp-
tography to withstand the ungoverned interactions of the internet
and the eventuality of quantum computing, and her invention of
Differential Privacy has revolutionized privacy-preserving statisti-
cal data analysis. In 2012 she launched the theoretical investigation
of algorithmic fairness. She is a winner of numerous award and a
member of the NAS, the NAE, the American Academy of Arts and
Sciences, and the American Philosophical Society.
REFERENCES
[1] Alexandra Chouldechova. 2017. Fair prediction with disparate impact: A study of
bias in recidivism prediction instruments. Big data 5, 2 (2017), 153–163.
[2] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel.
2012. Fairness through awareness. In Proceedings of the 3rd innovations in theoreti-
cal computer science conference. 214–226.
[3] Cynthia Dwork, Michael P Kim, Omer Reingold, Guy N Rothblum, and Gal Yona.
2021. Outcome indistinguishability. In Proceedings of the 53rd Annual ACM SIGACT
Symposium on Theory of Computing. 1095–1108.
Keynote Talk  CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1[4] Stephen Gillen, Christopher Jung, Michael Kearns, and Aaron Roth. 2018. Online
learning with an unknown fairness metric. arXiv preprint arXiv:1802.06936 (2018).
[5] Ursula Hébert-Johnson, Michael Kim, Omer Reingold, and Guy Rothblum. 2018.
Multicalibration: Calibration for the (computationally-identifiable) masses. In
International Conference on Machine Learning. PMLR, 1939–1948.
arXiv:1906.00250 (2019).
[6] Christina Ilvento. 2019. Metric learning for individual fairness. arXiv preprint
[7] Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan. 2017. Inherent Trade-
Offs in the Fair Determination of Risk Scores. In 8th Innovations in Theoretical
Computer Science Conference (ITCS 2017). Schloss Dagstuhl-Leibniz-Zentrum fuer
Informatik.
[8] Roland Neil and Christopher Winship. 2019. Methodological challenges and
opportunities in testing for racial discrimination in policing. Annual Review of
Criminology 2 (2019), 73–98.
Keynote Talk  CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2