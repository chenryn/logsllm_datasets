f = 2
f = 3
SYSTEM CONFIGURATIONS TOLERATING A PROACTIVE RECOVERY,
DISCONNECTED SITE, AND 1, 2, OR 3 INTRUSIONS.
TABLE I
correct replicas are available at all times, each of the two on-
premises sites must contain at least 2f + 2 total replicas (2f +
2 replicas− 1 recovering replica− f compromised replicas =
f + 1 available correct replicas). However, since we must still
have k strictly greater than the size of the largest site, this
adds the restriction k ≥ 2f + 3.
Together, the two above restrictions give us the requirement:
(cid:6)(cid:7)
(cid:4)
(cid:5)
k ≥ max
2f + 3,
3f + S + 1
S − 2
After ﬁnding the minimal value of k using this formula, the
total number of required replicas is calculated from the original
formula: n = 3f + 2k + 1. To distribute these replicas across
the sites, we must ﬁrst ensure that at least 2f + 2 replicas
are placed in each on-premises site, and then distribute the
remaining replicas across the sites such that the total number
of replicas per site is as even as possible. The results of
this process for several different system options are shown
in Table I. In Table I, we consider conﬁgurations tolerating
1-3 intrusions (f = 1, f = 2, and f = 3), with replicas
distributed across two on premises sites and 1-3 data centers.
The ﬁrst 2 numbers per cell denote the number of replicas in
each on-premises site, while the following numbers represent
the number of replicas in the data centers, and the ﬁnal number
in parentheses represents the total number of replicas. For
example, conﬁguration “4+4+3+3” represents 4 replicas in
each on-premises site, and 3 replicas in each data center, for
a total of 14 required replicas.
While the total number of replicas is considerably higher
than the typical 3f +1, this is because we (1) support proactive
recovery (which requires 3f + 2k + 1 replicas) and (2) provide
stronger guarantees, tolerating not only f compromises, but
also network attacks that can disconnect an entire site. This
threat model was ﬁrst introduced in [4], which showed that for
the case of f = 1, 12 replicas are needed. We slightly increase
that number to 14, but we believe this is justiﬁed to provide the
conﬁdentiality needed to trust a cloud provider and thus avoid
the need for the system operator to manage the large set of sites
and replicas themselves. If we consider a system operator who
already supports fault tolerance, deploying primary and backup
sites, each of which includes primary and backup replicas, we
only require that they add 2 on-premises servers per site: the
remaining sites and replicas are fully managed by the cloud
provider.
V. PROTOCOLS FOR PARTIALLY CLOUD-BASED BFT
Having described how to distribute replicas and set up the
system, we next describe the protocols used to submit and
process updates.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:54 UTC from IEEE Xplore.  Restrictions apply. 
19
A. Introducing Client Updates
Clients submit updates to the system through proxies. The
proxy digitally signs each update using its private key before
sending it to the on-premises servers. On-premises servers can
then verify the signature on the update, encrypt it, and inject
it into Prime for ordering.
However, our new model introduces a challenge, as data
center replicas need to verify that each update submitted
for ordering actually came from a correct client (and was
not maliciously generated by an adversary), yet data center
replicas do not have the ability to decrypt client updates. In
fact, they should not be required to maintain any information
about client identities or public keys (in some cases, client
IP address or locations may be a sensitive type of state
that system operators would like to avoid revealing [8]).
Requiring updates to be signed by the on-premises server
injecting them is not sufﬁcient, as any individual server could
be compromised and manufacture a large number of spurious
updates, forcing the system to work to order the bogus updates.
Our approach is for on-premises servers to cooperate to
generate a threshold signature on each introduced update. To
do this, we require each client to send its updates to 2f +k +1
on-premises replicas, which guarantees that at least f + 1
correct replicas will receive the request. Upon receiving a
client request, the on-premises replica ﬁrst checks its validity,
then encrypts the request message body. Then,
it creates
a partial threshold signature (using an (f + 1, n)-threshold
scheme) for the encrypted client update and multicasts this
partial threshold signature to all other on-premises replicas.
Upon collecting f +1 partial signatures, an on-premises replica
combines them to form the full threshold signature, and injects
the threshold-signed update into Prime for ordering. All other
replicas, including the data center replicas, can verify the full
threshold signature to validate that a request is legitimate.
Client update encryption presents one remaining challenge:
the individual on-premises replicas all need to perform the
encryption independently but come up with the same en-
crypted content, so that the threshold signature shares that they
independently generate will combine correctly. To do this, we
assume on-premises replicas maintain two shared secret keys
per client: the ﬁrst is the shared key used to perform symmetric
encryption and decryption of updates for that client, while
the second is used as one of the inputs to a pseudorandom
function used to generate initialization vectors, similarly to
the approach in [30]. Details about our implementation can be
found in Section VI-B. For now, we assume that all of these
per-client key pairs are stored in persistent read-only memory
and reloaded from there after proactive recovery, although we
discuss how to weaken this restriction in Section V-D.
B. Ordering Updates and Disseminating Results
Once an on-premises server generates a full threshold signa-
ture on an encrypted client update and injects it into Prime, it
is assigned an ordinal, or sequence number in the global total
ordering through the Prime agreement protocol [37], and then
delivered to the application to be decrypted and executed (in
the case of on-premises servers) or simply stored in encrypted
form along with its ordinal (at data center servers).
As part of executing an ordered update, application replicas
may generate a response message that needs to be sent to a
client. To generate a single response that can be veriﬁed by a
client proxy based on a single service public key, application
replicas generate a threshold signature on the response, again
using an (f + 1, n)-threshold scheme to ensure the message
is agreed on by at least one correct replica. This is the same
approach as in [4], but in our case, only on-premises replicas
can participate in generating the response. Our replica distri-
bution framework (Section IV-B) guarantees that it is always
possible to generate such a signature under the conditions of
our threat model.
C. Checkpoints and State Transfer
Since storing every ordered client request will eventually
exhaust replicas’ storage capacity, we keep only a limited
number of the latest encrypted client requests and replace older
requests by encrypted checkpoints. At speciﬁed checkpoint
intervals (i.e. every C ordered updates), each on-premises
replica creates and encrypts a checkpoint that represents its
state up through the execution of the last ordered client update
(similar to [12] and others). Note that an on-premises replica
does not consider itself to have fully executed a particular
update until
it has generated and sent a threshold-signed
client response message for any outgoing messages that were
generated as a result of its execution. The latest (threshold-
signed) outgoing message for each client is included in the
system state, since these may need to be retransmitted.
After generating an encrypted checkpoint, the on-premises
replica then creates and signs a checkpoint message that
contains the encrypted checkpoint, as well as the (cleartext) se-
quence number it corresponds to (the global sequence number
of the last ordered update that was executed and reﬂected in the
state). The replica then multicasts this checkpoint message to
all other replicas (including both on-premises and data center
replicas). When a replica (on-premises or data center) receives
f + 1 identical encrypted checkpoints from different replicas
for the same sequence number, then this encrypted checkpoint
can be marked as correct: at least 1 correct replica has agreed
that this checkpoint represents the system state at the given
sequence number.
Data center replicas do not create their own checkpoints.
Instead, when a data center replica collects a correct encrypted
checkpoint, it creates and signs a checkpoint message con-
taining that encrypted checkpoint, and then multicasts this
checkpoint message to all other replicas. When a replica (on-
premises or data center) receives 2f +k+1 identical encrypted
checkpoints from different replicas for the same sequence
number, then this encrypted checkpoint can be marked as
stable: even if f replicas sending checkpoints are malicious,
and k immediately become disconnected/unavailable, at least
f +1 correct replicas still remain that can help another replica
catch up to this checkpoint.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:54 UTC from IEEE Xplore.  Restrictions apply. 
20
randomly generate a new pair of keys and propose their
generated key pair by injecting it into Prime for ordering
together with the proposed client sequence number range it
should be valid for.
Since all correct replicas observe the ordered stream of
messages from Prime in the same way, they can use the global
ordering of proposals to determine the new key pair in a
consistent way. For example, we can determine the keys as
a combination of the ﬁrst f + 1 proposals, guaranteeing that it
includes random input from at least one correct replica, so that
the process cannot be controlled solely by malicious replicas.
Since the replica distribution process described in Section IV-B
guarantees that f + 1 correct on-premises are always available
under our threat model, it is always possible to collect f + 1
proposals, so this approach is live. A correct server will not
agree to inject a client message for ordering (i.e. will not
generate its signature share as described in Section V-A) unless
it has received f + 1 valid proposals ordered by Prime for the
sequence range covering that message and thus determined the
correct key to use for encryption.
While this process allows replicas to agree on new keys
to use for encrypting client updates such that all (correct)
replicas will apply the same new keys starting at the same
client sequence number, there are still several issues to resolve
to provide well deﬁned conﬁdentiality guarantees.
Encrypting Key Proposals. First, the new key proposals
themselves must also be encrypted, since they are disseminated
to data center replicas as part of the ordering process. It is
not possible to avoid storing these updates at the data center
replicas for exactly the same reason that data center replicas
must store general client updates: in order to ensure continuous
availability under our threat model, on-premises replicas that
have been disconnected and are rejoining the system must be
able to recover the state and resume executing updates based
only on input from the data center replicas.
But, what keys can we use to encrypt the key proposal
messages? Clearly, it is not safe to use the previous client
encryption key, since the purpose of the key refresh is to re-
cover from the case where the previous key was compromised.
But, if some other key is used, then rejoining/recovering on-
premises replicas must be able to recover that key from the
data centers, which means that key needs to be stored in
encrypted form, and we have the same problem again.
Upon collecting a stable checkpoint for a given sequence
number, a replica may safely garbage collect stored updates
and checkpoints for all prior sequence numbers (similar to [12]
and others), as long as it has also fully executed all sequence
numbers up through the sequence of the stable checkpoint
(note that since data center replicas do not participate in
generating client responses, they consider an update to be fully
executed as soon as it is ordered).
When a replica detects that it has fallen behind (e.g. because
it went through proactive recovery, or was disconnected and
missed some updates), it submits a state transfer request to
Prime for ordering. When this request is ordered, the other
replicas (including data center replicas) execute it by send-
ing the recovering replica their stable encrypted checkpoint,
digests for any correct checkpoints they have with sequence
numbers higher than the stable checkpoint, and the list of
ordered, encrypted client requests with sequence numbers
between the stable checkpoint and the global sequence number
of the state transfer request from this recovering replica.
In order to catch up to the latest state, the recovering replica
waits to receive a set of state transfer responses such that it
has (1) a correct checkpoint, with at least f + 1 matching
checkpoints/digests to guarantee its validity, and (2) a set
of updates such that for every sequence number between its
latest correct checkpoint and its target recovery ordinal (i.e.
the sequence number at which its state transfer request was
ordered), it has f + 1 identical updates from distinct replicas.
Once these requirements are met, if the recovering replica is
a data center replica, then it simply stores the latest correct
checkpoint and all following correct updates in the already
encrypted format. If the recovering replica is an on-premises
replica, it additionally decrypts the encrypted checkpoint and
the list of client requests, and then applies the decrypted
checkpoint and client requests in order of increasing global
ordinals to bring its application state up to date.
D. Key Renewal
As described so far, a single on-premises compromise can
leak encryption keys. If the keys are sent to a data center
replica, it will be able to decrypt all following updates and
checkpoints. While system operators could recover from such
a situation (if it was detected) by manually backing up the
system, taking replicas down, bringing them back up with new
keys, and re-instantiating the system, this is a labor intensive
operation that is likely to require system downtime.
Therefore, we extend the basic protocol with an automatic
key renewal mechanism that, combined with proactive recov-
ery, limits the amount of conﬁdential state a compromised
on-premises replica can disclose. The basic idea is that on-
premises servers maintain a separate shared symmetric en-
cryption key and shared pseudorandom function key for each
client in the system, and a given client key pair (encryption
key + pseudorandom function key) is only valid for a ﬁxed,
predetermined range of client update sequence numbers. When
servers get near the end of the range of sequence numbers the