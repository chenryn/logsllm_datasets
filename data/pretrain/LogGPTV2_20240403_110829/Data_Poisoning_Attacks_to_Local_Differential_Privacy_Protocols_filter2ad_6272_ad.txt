the attacker injects more fake users, the attacker promotes
more target items (except the kRR protocol), or the privacy
budget ε becomes smaller (i.e., security-privacy tradeoffs).
The (normalized) overall gain of MGA decreases as the total
true frequency of the target items (i.e., fT ) increases, though
the decrease of the overall gain is marginal. The (normalized)
overall gain of MGA increases for kRR but keeps unchanged
for OUE and OLH as d increases. We note that, for a given
USENIX Association
30th USENIX Security Symposium    955
Figure 4: Impact of different parameters on the success rates of the three attacks for PEM (heavy hitter identiﬁcation
protocol). The ﬁrst row is on Zipf, the second row is on Fire, and the third row is on IPUMS.
set of target items (i.e., fT is given), the trend of normalized
overall gain is the same as that of the overall gain with respect
to parameters β, r, ε, and d. Therefore, in the rest of the paper,
we focus on overall gain for simplicity.
Measuring RIA and MGA for OLH: The theoretical over-
all gain of RIA for OLH is derived based on the “perfect”
hashing assumption, i.e., an item is hashed to a value in the
(cid:5)] uniformly at random. Practical hash func-
hash domain [d
tions may not satisfy this assumption. Therefore, the theoreti-
cal overall gain of RIA for OLH may be inaccurate in practice.
We use xxhash [14] as hash functions to evaluate the gaps be-
tween the theoretical and practical overall gains. In particular,
Figure 5a compares the theoretical and practical overall gains
of RIA for OLH, where 1 item is randomly selected as target
item, β = 0.05, and ε = 1. We observe that the theoretical and
practical overall gains of RIA for OLH are similar.
Our theoretical overall gain of MGA for OLH is derived
based on the assumption that the attacker can ﬁnd a hash
function that hashes all target items to the same value. In
practice, we may not be able to ﬁnd such hash functions
within a given amount of time. Therefore, for each fake user,
we randomly sample some xxhash hash functions and use
the one that hashes the most target items to the same value.
Figure 5b compares the theoretical and practical overall gains
of MGA for OLH on the IPUMS dataset as we sample more
hash functions for each fake user, where we randomly select
5 items as target items, i.e., r = 5. Our results show that the
practical overall gains approach the theoretical ones with
several hundreds of randomly sampled hash functions when
r = 5. We have similar observations for the other two datasets
and thus we omit their results due to the limited space.
(a)
(b)
Figure 5: (a) Theoretical and practical overall gains of
RIA for OLH. (b) Theoretical and practical overall gains
of MGA for OLH on the IPUMS dataset as we sample
more hash functions for each fake user, where r = 5.
5.3 Results for Heavy Hitter Identiﬁcation
Figure 4 shows the empirical results of applying our three
attacks, i.e., RPA, RIA and MGA, to PEM on the Zipf, Fire,
and IPUMS datasets, respectively. By default, we randomly
select r = 10 target items that are not identiﬁed as top-k heavy
hitters by PEM before attack and use the three attacks to
promote them. Default values for the other parameters are
identical to those in Table 2. The success rate of an attack
is calculated as the fraction of target items that appear in
the estimated top-k heavy hitters. The results show that our
MGA attacks can effectively compromise the PEM protocol.
In particular, we observe that MGA only needs about 5% of
fake users to achieve a 100% success rate when r = 10 and
k = 20. In fact, with only 5% of fake users, we can promote
10 target items to be in the top-15 heavy hitters, or promote 15
target items to be in the top-20 heavy hitters. However, RPA
and RIA are ineffective. Speciﬁcally, even if we inject 10%
956    30th USENIX Security Symposium
USENIX Association
of fake users, neither RPA nor RIA can successfully promote
even one of the target items to be in the top-k heavy hitters.
Moreover, the number of groups g and the privacy budget ε
have negligible impact on the effectiveness of our attacks.
6 Countermeasures
We explore three countermeasures. The ﬁrst countermeasure
is to normalize the estimated item frequencies to be a prob-
ability distribution, the second countermeasure is to detect
fake users via frequent itemset mining of the users’ perturbed
values and remove the detected fake users before estimating
item frequencies, and the third countermeasure is to detect the
target item without detecting the fake users when there is only
one target item. The three countermeasures are effective in
some scenarios. However, our MGA is still effective in other
scenarios, highlighting the needs for new defenses against our
data poisoning attacks.
6.1 Normalization
The LDP protocols estimate item frequencies using Equation
(3). Therefore, the estimated item frequencies may not form a
probability distribution, i.e., some estimated item frequencies
may be negative and they may not sum to 1. For instance, our
experimental results in Section 5.2 show that the overall gains
of MGA may be even larger than 1. Therefore, one natural
countermeasure is to normalize the estimated item frequencies
such that each estimated item frequency is non-negative and
the estimated item frequencies sum to 1. For instance, one
normalization we consider is as follows: the central server
ﬁrst estimates the frequency ˜fv for each item v following a
LDP protocol (kRR, OUE, or OLH); then the server ﬁnds
the minimal estimated item frequency ˜fmin; ﬁnally, the server
calibrates the estimated frequency for each item v as ¯fv =
˜fv− ˜fmin
∑v( ˜fv− ˜fmin), where ¯fv is the calibrated frequency. Our overall
gain is calculated by the difference between the calibrated
frequencies of the target items after and before attack. We note
that there are also other methods to normalize the estimated
item frequencies [31, 63], which we leave as future work.
Note that the normalization countermeasure is not applicable
to heavy hitter identiﬁcation because normalization does not
impact the ranking of items’ frequencies.
6.2 Detecting Fake Users
RPA and MGA directly craft the perturbed values for fake
users, instead of using the LDP protocol to generate the per-
turbed values from certain items. Therefore, the perturbed
values for the fake users may be statistically abnormal. We
note that it is challenging to detect fake users via statistical
analysis of the perturbed values for the kRR protocol, because
the perturbed value of a user is just an item, no matter whether
User 1:
User 2:
User 3:
User 4:
Figure 6: An example itemset that are all 1’s in 3 of the 4
binary vectors. Each column corresponds to an item.
or not the attacker follows the protocol to generate the per-
turbed value. Therefore, we study detecting fake users in the
RPA and MGA attacks for the OUE and OLH protocols. Since
PEM iteratively applies OLH, we can also apply detecting
fake users to PEM.
OUE: Recall that MGA assigns 1 to all target items and l
randomly selected items in the perturbed binary vector for
each fake user. Therefore, among the perturbed binary vectors
from the fake users, a set of items will always be 1. However,
if the perturbed binary vectors follow the OUE protocol, it
is unlikely to observe that this set of items are all 1’s for a
large number of users. Therefore, our idea to detect fake users
consists of two steps. In the ﬁrst step, the server identiﬁes
itemsets that are all 1’s in the perturbed binary vectors of a
large number of users. In the second step, the server detects
fake users if the probability that such large number of users
have these itemsets of all 1’s is small, when following OUE.
Step I. In this step, the server identiﬁes itemsets that are
frequently all 1’s among the perturbed binary vectors. Figure 6
shows an example itemset that are all 1’s in 3 of the 4 binary
vectors. Identifying such itemsets is also known as frequent
itemset mining [6]. In our problem, given the perturbed binary
vectors from all users, frequent itemset mining can ﬁnd the
itemsets that are all 1’s in at least a certain number of users.
Speciﬁcally, a frequent itemset mining method produces some
tuples BBB = {(B,s)|s ≥ τ}, where B is an itemset and s is the
number of users whose perturbed binary vectors are 1’s for
all items in B.
Step II. In this step, we determine whether there are fre-
quent itemsets that are statistically abnormal. Speciﬁcally,
we predict a tuple (B,s) ∈ BBB to be abnormal if s ≥ τz, where
z = |B| is the size of the itemset B. When an itemset is pre-
dicted to be abnormal, we predict the items as the target items
and the users whose perturbed binary vectors are 1’s for all
items in the itemset to be fake. The threshold τz achieves a
tradeoff between false positive rate and false negative rate of
detecting fake users. Speciﬁcally, when τz is larger, a smaller
number of genuine users are predicted as fake (i.e., a smaller
false positive rate), while a larger number of fake users are
not detected (i.e., a larger false negative rate). Therefore, a
key challenge is how to select the threshold τz. We propose
to select the threshold such that the false positive rate is at
most η. Speciﬁcally, given a threshold τz > (n + m)pqz−1,
USENIX Association
30th USENIX Security Symposium    957
we can derive an upper bound of the false positive rate as
(n+m)pqz−1(1−pqz−1)
(see Appendix B for details). Therefore,
[τz−(n+m)pqz−1]2
to guarantee that the false positive rate is at most η and achieve
a small false negative rate, we select the smallest τz that sat-
isﬁes τz > (n + m)pqz−1 and (n+m)pqz−1(1−pqz−1)
[τz−(n+m)pqz−1]2 ≤ η. We set
η = 0.01 in our experiments.
OLH: To attack the OLH protocol, MGA searches a hash
function for each fake user that hashes as many target items
to the same value as possible. Suppose we construct a d-
bit binary vector yyy for each user with a tuple (H,a) such
that yv = 1 if and only if H(v) = a. Then, the target items
will be 1’s in the binary vectors for a large number of users.
Therefore, we can also leverage the method to detect fake
users in OLH. Speciﬁcally, in Step I, we ﬁnd frequent item-
sets in the constructed binary vectors. In Step II, we predict
an itemset B to be abnormal if its number of occurrences s
among the n + m binary vectors is larger than a threshold
τz, where z = |B| is the size of the itemset. Like OUE, we
select the threshold τz such that the false positive rate is at
most η. Speciﬁcally, we select the smallest τz that satisﬁes
I(qz−1;τz,n + m− τz + 1) ≤ η, where I is the regularized in-
complete beta function [5]. I(qz−1;τz,n + m− τz + 1) is the
false positive rate for a given τz (see Appendix B for details).
PEM: The heavy hitter identiﬁcation protocol PEM itera-
tively applies OLH to identify heavy hitters. Therefore, we
can apply the frequent itemset mining based detection method
to detect fake users in PEM. Speciﬁcally, in each iteration of
PEM, the central server applies the detection method in OLH
to detect fake users in PEM; and the central server removes
the predicted fake users before computing the top-k preﬁxes.
6.3 Conditional Probability based Detection
The frequent itemset mining based detection method above
requires at least two target items as it identiﬁes the abnor-
mal frequent itemset as the target items. When there is only
one target item, i.e., r = 1, it fails to detect the target item.
Therefore, we discuss another method to detect the target item
when r = 1, which leverages conditional probabilities. Note
that this method does not detect fake users.
OUE: Suppose yyy is a user’s perturbed binary vector. With a
little abuse of notation, we denote the j-th bit of yyy as y j. Given
the target item t and a random item j, we have the following
equations under our MGA attacks to OUE:
Pr(y j = yt = 1) = Pr(v = t)· Pr(y j = yt = 1|v = t)
+ Pr(v = j)· Pr(y j = yt = 1|v = j)
+ Pr(v (cid:4)= t, j)· Pr(y j = yt = 1|v (cid:4)= t, j)
+ Pr(fake)· Pr(y j = yt = 1|fake)
= n ft
n + m
+ n(1− ft − f j)
· pq + n f j
· pq
n + m
· q2 + m
n + m
l
d − 1
n + m
·
,
0.9
f j 0.01 0.01
0.01
0.01
ft
ˆfu 0.25 0.26 0.18 0.19 0.18 0.18 0.18 0.19
0.1
0.01
0.5
0.01
0.5
0
0.1
0
0.9
0
0
(a) β = 0.05
f j 0.01 0.01
0.01
ft
ˆfu
1.8
0
1.8
0.1
0
0.1
0.01
0.9
0.01
0.87 0.88 0.82 0.84 0.82 0.83
0.5
0.01
0.5
0
0.9
0
(b) β = 0.2
Table 3: Threshold ˆfu for different f j and ft.
Pr(yt = 1) = Pr(v = t)· Pr(yt = 1|v = t)
+ Pr(v (cid:4)= t)· Pr(yt = 1|v (cid:4)= t)
+ Pr(fake)· Pr(yt = 1|fake)
= n ft
n + m
· p + n(1− ft )
n + m
· q + m
n + m
Pr(y j = 1|yt = 1) = Pr(y j = yt = 1)
Pr(yt = 1)
f jq(p− q) + β
1−β · ( l
d−1
ft p + (1− ft )q + β
1−β
− q)
=q +
Given a non-target item u (cid:4)= j, we have the following:
,
(30)
(31)
(32)
.
(33)
Pr(y j = yu = 1)
= Pr(v = u)· Pr(y j = yu = 1|v = u)
+ Pr(v = j)· Pr(y j = yu = 1|v = j)
+ Pr(v (cid:4)= j,u)· Pr(y j = yu = 1|v (cid:4)= j,u)
+ Pr(fake)· Pr(y j = yu = 1|fake)
= n fu
n + m
· pq + n(1− fu − f j)
n + m
· q2
· pq + n f j
n + m
· l − 1
·
d − 2
l
d − 1
,
+ m
n + m
Pr(yu = 1)
= Pr(v = u)· Pr(yu = 1|v = u)
+ Pr(v (cid:4)= u)· Pr(yu = 1|v (cid:4)= u)
+ Pr(fake)· Pr(yu = 1|fake)
= n fu
n + m
n + m
Pr(y j = 1|yu = 1)
= Pr(y j = yu = 1)
· p + n(1− fu)
· q + m
n + m