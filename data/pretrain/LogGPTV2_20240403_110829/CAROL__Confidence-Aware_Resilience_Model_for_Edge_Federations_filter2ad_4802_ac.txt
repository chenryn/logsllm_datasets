node-shift sequences that give Gt, giving high estimated QoS.
Recent surrogate optimization techniques use gradient-based
optimization compared to evolutionary search strategies that
facilitate quick convergence [33]. However, in discrete search
spaces, such as graph topologies, such techniques typically
select the discrete point close to the converged point in the
continuous space. This may often lead to non-optimal solu-
tions [46, §19.1]. Another drawback of such methods is that
the parameters of the neural networks need to be periodically
ﬁne-tuned, leading to high overheads [47]. To reduce such
overheads, it is crucial to ﬁne-tune models only when the
system or workload conﬁgurations change. To do this, we
take motivation from conﬁdence-aware deep learning [48]
and a recently proposed class of generative models, called
Generative Optimization Networks (GONs) [25], to integrate
in CAROL a memory efﬁcient QoS surrogate. This is used to
predict a conﬁdence score, such that for low conﬁdence the
model can be ﬁne-tuned with online generated data.
GON based Neural Network. GANs are based on a pair
of neural networks, a generator and a discriminator where the
generator takes random noise samples and outputs samples
from a data distribution as inputs. The discriminator predicts
a likelihood score for the input belonging to the target dis-
tribution. Unlike traditional GANs, we leverage a memory-
efﬁcient Generative Optimization Network (GON) [25]. GONs
are similar to GANs, but do not use the generator, signiﬁcantly
reducing the memory footprint of the neural network. We now
describe the working of the GON model and conﬁdence-based
QoS prediction.
Consider a discriminator network D with parameters θ that
takes as input graph topology G, performance metrics M and
scheduling decision S. The output of D, i.e., D(M, S, G; θ)
is a likelihood score of G, M and S belonging to a distri-
bution. When trained for a dataset generated from the normal
execution of an edge federation, the GON model predicts a
high score for an input tuple (M, S, G) in the distribution
of the dataset and a low score for an unseen tuple. This
allows us to translate the likelihood score output as a measure
of the conﬁdence of the network. Essentially, for dynamic
Original topologyHigher broker countLower broker countSame broker countBrokersWorkersAlgorithm 1 Minibatch stochastic gradient based training of
GON model in CAROL. Input is dataset Λ and hyperparam-
eters m and γ.
Require: Dataset Λ = {Mt, St, Gt}T
1: for number of training iterations do
2:
Sample minibatch of size m performance metrics
i=0
3:
4:
5:
{M (1), . . . , M (m)} from Λ.
of
{Z (1), . . . , Z (m)}.
the following till convergence
Sample minibatch
samples
Generate new samples {Z∗(1), . . . , Z∗(m)} by running
size m noise
Z ← Z + γ · ∇Z log(cid:0)D(Z, S, G; θ)(cid:1).
(cid:2) log(cid:0)D(M (i), S, G; θ)(cid:1) + log(cid:0)1 − D(Z∗(i), S, G; θ)(cid:1)(cid:3).
Update the discriminator by ascending the stochastic
m(cid:88)
gradient.
∇θ
1
m
i=1
systems, when the conﬁdence score drops below a threshold, it
indicates us to ﬁne-tune the model. This enables parsimonious
model ﬁne-tuning, giving us an effective compromise between
prediction performance and training overheads.
To generate the performance scores for an input graph
topology G, we can randomly initialize M and maximize the
discriminator output by ascending the stochastic gradient
M ← M + γ∇M log(cid:0)D(M, S, G; θ)(cid:1),
(1)
where γ denotes the step size in the optimization loop. We
use log-likelihood instead of likelihood scores for training
stability [27]. Thus, starting from an input (S, G) pair, the
above optimization loop converges us to give performance
metrics M∗ and a conﬁdence score of D(M∗, S, G).
Ofﬂine Model Training. To train the GON model D,
we ﬁrst collect an execution trace Λ = {Mt, St, Gt}T
i=0. A
summary of the training process is presented in Algorithm 1.
We leverage an adversarial training process where we use the
generated data (say Z∗) as fake samples and datapoints from Λ
(say M) as real samples and train the model using the binary
cross-entropy loss
L = log(cid:0)D(M, S, G; θ)(cid:1) + log(cid:0)1 − D(Z∗, S, G)(cid:1),
(2)
where (M, S, G) ∈ Λ. Thus, the model is trained to optimize
the likelihood scores for fake and real samples in an adversarial
fashion using the same loss function. This adversarial style
training has a two-fold goal. First, the model learns to generate
new samples (Z∗) such that the tuple (Z∗, S, G) belongs to
the data distribution. Thus, with sufﬁcient training, converged
Z∗ are close estimates of the performance metrics for inputs G
and S. Second, for previously seen datapoints, i.e., (M, S, G)
tuples, the predicted conﬁdence scores are high. If the (S, G)
input is unseen during training, then the converged conﬁdence
score D(Z∗, S, G) would also be low. In practice, for the
scheduling interval It,
instead of starting from a random
6
Algorithm 2 The CAROL resilience model.
Require:
Trained GON Model D; Running dataset Γ
Broker set B; Worker set W
(cid:46) Initialize topology
St from underlying scheduler
Gt ← NodeShift(Gt−1)
for each broker b ∈ B do
if b fails do
G ∈ N (Gt, b)
Gt ← TabuSearch(G, Ω)
1: for t = 0 to T do
2:
3: Mt from edge system
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
Conﬁgure topology as Gt
Schedule tasks using St
if no broker in B fai do
Add datapoint (Mt, St, Gt) to Γ (cid:46) Save datapoint
C ← D(Mt, St, Gt; θ)
(cid:46) Conﬁdence score
P OT ← PeakOverThreshold(C) (cid:46) POT calculation
if C < P OT do
L = log(D(M, S, G; θ)) + log(1 − D(Z∗, S, G))
Fine-tune D using L and Adam
Clear Γ
(cid:46) Fine-tune
(cid:46) Random node-shift
(cid:46) Tabu Search
noise sample Z, we initialize M as Mt−1 and then converge
D(M, St, Gt) to Mt. This exploits the temporal correlation
between subsequent system states, facilitating quick conver-
gence of (1).
Finding optimal edge topology. Having a surrogate model,
at each scheduling interval It, we can now run optimization of
the QoS by taking a convex combination of the QoS metrics
in Mt. We denote this objective function as O(Mt). Now, if
a node fails in It−1, then we can create the graph topology
Gt by a node-shift operation on Gt−1 (line 4 in Alg. 2).
However, to decide the optimal node-shift operation, we can
run a local search in the topology space. We select the tabu
search algorithm due to its deterministic nature and empirically
faster convergence for the speciﬁc optimization problem we
consider [49]. Thus, in case of a node failure, we start from
graph Gt−1, apply a random node shift to generate G and use
tabu search to generate the graph Gt such that the QoS score
is optimized (line 8 in Alg. 2). We perform this iteratively for
each failed broker node to achieve the ﬁnal graph topology.
If no broker failed in It−1, then we add the datapoint to a
running dataset Γ (line 10 in Alg. 2).
The local neighbors of a graph G for a failed node, say
b, is obtained by performing all possible node-shift opera-
tions. We denote this neighbourhood set of G by N (G, b)
(line 7 in Alg. 2). The QoS score is obtained using the GON
model described previously, where we evaluate Mt using (1)
over D(M, St, G) and use the objective function O(Mt) for
our local search. For notational convenience, we deﬁne the
objective score of a graph G, parameterized by the GON
model D, scheduling decision St and objective function O
as Ω(G; D, St, O). As the network size increases, the number
of possible node-shift operations also increases. Thus, we use
Fig. 2. Visualizing the conﬁdence scores and POT threshold values for
1000 scheduling intervals in CAROL. We use the testbed and fault injection
module described in Section IV. The blue bands represent intervals where the
conﬁdence fell below threshold value and the model was ﬁne-tuned with the
latest collected data.
a tabu list of a ﬁxed size L in our search scheme.
Conﬁdence Aware Fine-Tuning. After performing opti-
mization in the topology space and obtaining Gt for interval
It, we also evaluate the conﬁdence score D(Mt, St, Gt; θ)
(line 11 in Alg. 2). We then use the Peak Over Threshold
(POT) method [38] that dynamically chooses threshold values
below which we ﬁne-tune our model (line 12). POT uses
extreme value theory to generate a threshold value from a
continuous record of past conﬁdence scores. It does this
by checking the peak values reached for any period during
which values fall below a certain threshold. This threshold is
dynamically updated based on incoming data to ensure that
the model adapts to non-stationary settings. In any interval, if
the conﬁdence score falls below the POT threshold, CAROL
ﬁne-tunes the GON network with the latest collected dataset
Γ (line 15). A visualization of the training process is shown
for a thousand scheduling intervals in Figure 2. The ﬁgure
clearly demonstrates that the model trains the GON network
only when there are dips in the conﬁdence scores, allowing our
technique to have much lower ﬁne-tuning overheads compared
to other methods that
tune their neural networks at each
scheduling interval.
IV. IMPLEMENTATION
A. GON Network.
It is crucial that the D network is able to capture the correla-
tion between system topology and scheduling decisions with
the performance metrics to effectively predict QoS and conﬁ-
dence scores. The model used in our approach is a composite
neural network shown in Figure 3 that infers the correlations
between performance metrics, scheduling decision and graph
topology to generate the discriminator output. Considering we
have p tasks running as a sum of new and active tasks, the
scheduling decisions of these are encoded as one-hot vectors
of size |H| (number of hosts in the system). We thus get a
matrix of scheduling decisions (S) of size [p×|H|]. Also, we
collect performance metrics of each host i ∈ H denoted by Mi
that includes resource utilization metrics CPU, RAM, Disk,
Bandwidth consumption with QoS metrics such as energy
consumption and SLO violation rates. We denote the resource
utilization metrics of host i as ui and QoS metrics as qi. We
also include the task resource utilization consumption with
SLO deadlines, denoted as ti. Thus, Mi = [ui, qi, ti]. The Mi
Fig. 3. Neural network used in CAROL. The three inputs to the model are
shown in red. Feed-forward, graph operations and activations are shown in
blue, purple and green.
vectors for all hosts are stacked together to form the matrix
M. To encode inputs M and S, we use feed-forward layers
to bring down the dimension size of the input and ReLU
activation:
E{M,S} = ReLU(FeedForward([W, S])).
(3)
The topology of the edge federation is represented as a
graph with nodes as edge hosts and edges corresponding to
edge groups. All edge workers are connected via undirected
edges to their respective broker, and all brokers are connected
to every other broker. The resource utilization characteristics of
each edge host are then used to populate the feature vectors of
the nodes in the graph. We denote the feature vector of host i
as ei that are computed from ui. We encode this graph G using
a graph attention network [50] for scalable computation over
the input graph. The motivation behind using a graph attention
network is to allow computation over the graph to be agnostic
to the number of nodes in the system topology. Graph attention
operation performs convolution operation for each node over
its neighbors and uses dot product self-attention to aggregate
feature vectors. Thus, we transform the input graph G using
graph-to-graph updates as:
ei = σ(cid:0) (cid:88)
W q · tanh(W ui + b)(cid:1),
j∈n(i)
(4)
where W q are the attention weights obtained by the weight
matrix W [50] and n(i) are the neighbors of host i in graph G.
The stacked representation for all hosts (ei) is represented as
7
EG. Now, we pass this representation through a feed-forward
layer with sigmoid activation as
D(M, S, G; θ) = Sigmoid(FeedForward([E{M,S}, EG])).
(5)
Here, the sigmoid function allows us to bring the output in the
range [0, 1], the same as that of the true normalized window.
B. Objective function.
For generating the objective function O(Mt) as part of Ω in
Alg. 2, we use a convex combination of the energy consump-
tion and SLO violation rates of the system as is commonly
used in prior work to estimate system performance [33], [47].
For the energy consumption (qenergy
) and SLO violation rates
(qslo
) of each host i, we generate scores for the complete
system
i
i
(cid:88)
(cid:88)
i∈H
i∈H
qenergy =
qslo =
qenergy