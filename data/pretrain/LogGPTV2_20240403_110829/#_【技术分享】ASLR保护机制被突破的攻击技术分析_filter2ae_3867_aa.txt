# 【技术分享】ASLR保护机制被突破的攻击技术分析
|
##### 译文声明
本文是翻译文章，文章来源：cs.vu.nl
原文地址：
译文仅供参考，具体内容表达以及含义原文为准。
****
作者：[shan66](http://bobao.360.cn/member/contribute?uid=2522399780)
预估稿费：300RMB
投稿方式：发送邮件至[linwei#360.cn](mailto:PI:EMAIL)，或登陆[网页版](http://bobao.360.cn/contribute/index)在线投稿
**摘要**
最近，基于硬件的攻击已经开始通过Rowhammer内存漏洞或旁路地址空间布局随机化保护机制来攻击系统了，这些攻击方式都是基于处理器的内存管理单元（MMU）与页表的交互交互方式的。这些攻击通常需要重复加载页表，以观察目标系统行为的变化情况。为了提高MMU的页表查找速度，现代处理器都使用了多级缓存，例如转译查找缓存（translation
lookaside
buffers，TLB）、专用页表缓存，甚至通用数据缓存。要想攻击得手，需要在访问页表之前可靠地刷新这些缓存。为了从非特权进程中刷新这些缓存，攻击者需要基于这些缓存的内部体系结构、大小以及缓存交互方式来创建专门的内存访问模式。虽然关于TLB和数据高速缓存的信息通常都会在供应商的处理器手册中发布，但是关于不同处理器上的页表高速缓存的特性方面的信息却鲜有提及。在本文中，我们改进了最近提出的针对MMU的EVICT
+
TIME攻击，对来自Intel、ARM和AMD的20种不同微架构中页表缓存与其他缓存的内部架构，大小以及其交互方式。同时，我们以代码库的形式将我们的发现公之于众，该代码库不仅提供了一个方便的接口来刷新这些缓存，同时还可以用来在新的体系结构上自动逆向页表缓存。
**引言**
由于添加到系统中的高级防御日益增加，致使针对软件的攻击的难度也是与日俱增，因此，针对硬件的攻击反而成为一种更有吸引力的替代方案。在这些攻击也是五花八门，既有利于Rowhammer漏洞攻击系统的，也有使用旁路攻击破坏地址空间布局随机化来泄漏加密密钥的，甚至还有用来跟踪鼠标移动的。
在这些针对硬件的攻击中，有许多攻击都是通过滥用现代处理器与内存来实现的。目前，所有的处理器的核心都是存储器管理单元（MMU），它通过在多个进程之间提供虚拟化内存来简化可用物理存储器的管理工作。MMU使用称为页表的数据结构来执行虚拟存储器到物理存储器之间的转换。页表是基于硬件的攻击的目标所在。例如，由Rowhammer漏洞导致的页表页中的单个位翻转，将会授予攻击者某种访问权限来访问本来无法访问的物理内存，从而进一步获得超级用户权限。此外，诸如ASLR和其他使用ASLR引导的安全防御机制都依赖于代码或数据都是被随机存储到虚拟存内存中这一特性的。由于这个（秘密）信息被嵌入在页表中，攻击者可以利用MMU与页表的交互方式进行旁路攻击，以获取这些机密信息。
从虚拟内存到物理内存的转换通常会很慢，因为它需要进行多次内存访问来解析原始虚拟地址。为了提高性能，现代处理器都使用多级缓存，例如转译查找缓存（TLB）、专用页表缓存，甚至通用数据缓存。为了成功攻击页表，攻击者经常需要重复刷新这些缓存，以观察系统在处理页表时的行为。通过参阅处理器手册，人们可以很容易找到TLB和数据高速缓存的各种详细信息。然而，关于页表缓存的信息，例如它们的大小和行为，通常是很难找到的。因为没有这些信息，攻击者需要借助于试错法，所以，如果他们要想打造可以适用于多种体系结构上的攻击的话，难度可想而知。
在本文中，我们对现有的AnC进行了重大的升级改造。AnC是一种针对MMU的EVICT +
TIME旁路攻击，它能够对Intel、ARM和AMD等公司的20多种微架构的处理器的页表缓存的大小、内部体系结构以及它们与其他缓存的交互方式进行逆向。AnC依赖于以下事实：MMU查找的页表将被存储在最后一级高速缓存（LLC）中，以供下一次查找时使用，从而提高地址转换速度。通过刷新LLC的部分内容和对页表查找进行定时，AnC可以识别出LLC的哪些部分是用来存储页表的。除了刷新LLC，AnC还需要刷新TLB以及页表缓存。由于有关TLB和LLC的大小的信息是可知的，所以攻击者可以使用AnC来逆向自己感兴趣的页表缓存的特性，如其内部结构和大小等。
简而言之，我们做出了以下贡献：
我们描述了一种新技术，可以用来对现代处理器中非常常见却无文档说明的页表缓存进行逆向工程。
我们利用Intel、ARM和AMD的20种不同微结构处理器对我们的技术进行了深入评估。
我们以开源软件的形式发布了用于刷新缓存的框架实现。我们实现的框架提供了一个方便的接口，可以方便地应用于我们已经测试的各种微架构上，来刷新页表缓存，并且它还可以用来自动检测新处理器上的页表缓存。更多信息，请访问：
**背景和动机**
在本节中，我们讨论分页内存管理机制和它在大多数现代处理器上的实现。此外，我们还将考察MMU是如何进行虚拟地址转换的，以及用于提高这种转换性能的各种缓存。
**页式技术和MMU**
页面技术已经成为现代处理器架构的一个组成部分，因为它能够通过虚拟化技术来简化物理内存的管理：由于地址空间有限，操作系统不再需要重新分配应用程序的整个内存，并且不再需要处理物理内存碎片。此外，操作系统可以限制进程访问的内存空间，防止恶意代码或故障代码干扰其他进程。
它所带来的直接后果，就是许多现代处理器架构都采用了MMU，一个负责将虚拟地址转换为相应物理地址的硬件组件。转换信息被存储在页表中——一种多级单向树，每个级别都可以由虚拟地址的一部分进行索引，从而选择下一级页表，或者在叶级别，也就是物理页面。因此，每个虚拟地址都能够从树的根节点到叶节点唯一地选出一条路径以找到对应的物理地址。
图1详细展示了MMU是如何在x86_64上执行虚拟地址转换的。首先，MMU读取CR3寄存器以找到顶级页表的物理地址。然后，用虚拟地址的前9位作为索引在该页表中选择页表项（PTE）。这个PTE包含对下一级页表的引用，然后用虚拟地址中接下来9位的作为索引继续选择页表项。通过对下两个级别重复该操作，MMU就可以在最低级页表中找到对应于0x644b321f4000的物理页了。
图1：在x86_64架构上，将0x644b321f4000转换成其对应的内存页的MMU的页表查询过程。
**缓存MMU的操作**
如果MMU可以避免从头开始解析其最近已解析过的虚拟地址的话，那么内存的访问性能就会得到极大的改善。为此，CPU会将解析过的地址映射存储到TLB高速缓存中。因此，如果在TLB中命中的话，就无需查询各个页表了，而这个过程是需要花费许多时间的。此外，为了提高TLB未命中时的性能，处理器会将页表数据存储到数据高速缓存中。
现代处理器还可以进一步提高TLB未命中情况下的地址转换性能，方法是使用页表缓存或转译缓存来缓存不同级别页表的PTE。虽然页表缓存使用物理地址和PTE索引进行索引，但是转换缓存使用的是已经过部分解析的虚拟地址。通过转译缓存，MMU可以查找虚拟地址并选择具有最长匹配前缀的页表，即选择存在于给定虚拟地址的高速缓存内的最低级页表。虽然这允许MMU免去部分页表的查询工作，但是转译缓存的实现同时也带来了额外的复杂性。
此外，这些高速缓存在实现方式也可以多种多样，不仅可以实现多个专用的高速缓存供不同的页表级使用，而且还可以实现单个高速缓存来供不同的页表级共享，或者甚至可以作为一个可以缓存PTE的TLB来加以实现。例如，AMD的Page
Walking Caches（就像在AMD K8和AMD K10微架构中发现的那样）采用的是统一页表缓存的方式，而Intel的Page-Structure
Caches的实现采用的是专用的转译缓存的方式。类似地，ARM在针对低功耗和硅利用率而优化的设计中实现了统一的页表缓存（页表查询缓存），同时它们在针对高性能而优化的设计中实现了统一的转换缓存（中间页表查找缓存）。
图2展示了当MMU翻译虚拟地址时不同高速缓存的交互方式。虽然TLB和缓存具有完整的文档说明，但是关于页表和翻译缓存的诸多细节仍然缺乏相关的文档说明。
图2：MMU的通用实现以及将虚拟地址转换为物理地址的所有组件。
**研究动机**
最近的基于页表滥用的硬件攻击，都要求能够正确刷新页表缓存，才能完成相应的操作。例如，预取攻击依赖于一个正确的时机，届时虚拟地址转换恰好在一个页表缓存中部分成功，借以了解内核中随机化地址方面的信息。而Rowhammer攻击在处理页表时则需要重复刷新TLB和页表缓存，以扫描物理内存中的敏感信息
另一个需要刷新页表缓存的例子是AnC攻击。MMU的页表查询结果会被缓存到LLC中。AnC利用这个事实来完成FLUSH +
RELOAD攻击，以确定出MMU在页表查询期间访问的页表内存页中的偏移量。知道这个偏移量后，就能找到经过随机化处理后的虚拟地址，从而攻陷ASLR防御机制。但是，为了完成一次可靠的攻击，AnC需要尝试多种不同的访问模式，并且每种模式都需要尝试许多次，并且每次都需要有效地刷新页表缓存以便触发完整的页表查询流程。因此，关于页表缓存的内部工作机制的知识，对于完成正确高效的AnC攻击来说是非常必要的。
在某些情况下，TLB用作页表缓存。在这些情况下，cpuid指令可以用来了解不同TLB的大小，这样就知道了不同页表缓存的大小了。但是，在一些x86_64微体系结构上，cpuid指令并不会给出所有TLB的大小。例如，尽管在Intel
Sandy Bridge和Ivy Bridge处理器上存在可以缓存1
GB页面的TLB，但这些信息根本无法通过cpuid指令获取。此外，在其他CPU体系结构上，可能没有办法获取TLB的大小，或者页表缓存可能已经实现为完全独立的单元。因此，我们需要一个更通用的方法来探索页表缓存的重要属性。
**页表缓存逆向技术**
我们现在开始讨论如何改造AnC技术，以探测页表缓存的各种属性。实际上，我们需要克服许多挑战，才能使AnC适用于不同的架构，这些将在后面展开详细的讨论。
**使用MMU的缓存信号**
代码清单1：设计原理示意代码
在了解页表缓存时，我们依赖于这样一个事实，即MMU的页表查询结束于目标处理器的数据缓存处。下面以Intel x86
64为例进行说明，这里假设使用了四个页表级别，那么给定虚拟地址v的MMU的页表查询会将来自4个页表内存页的4个缓存行放入L1数据缓存以及L3，假设L3包括L1。这样一来，如果高速缓存行仍然位于数据缓中的话，那么再次对虚拟地址v进行页面查询的时候，就会变得相当快。
CPU数据缓存被分为不同的缓存集。每个缓存组可以存储多达N个缓存行，这被称为N路组相关缓存。Oren等人发现，给定两个不同的（物理）内存页面，如果它们的第一个缓存行属于同一缓存组，那么页面中的其他缓存行也会共享（不同的）缓存组，即如果我们在一个与缓存行边界对齐的页面内选择了偏移t，那么另一内存页中的偏移t处的缓存行就会共享相同的缓存组。这是因为：为了让两个内存页的第一个缓存行位于同一个缓存组中，那么决定缓存组和切片（slice）的两个页面的物理地址的所有位必须是相同的，并且两个页面内的偏移将共享相同的低位。
利用缓存的这个特性，我们可以轻松利用一些内存页来用作驱逐缓冲区。假设用于转换虚拟地址v的四个页表项中的一个正好位于页表内存页的偏移零处。当我们访问驱逐缓冲区中所有页面的第一个缓存行的时候，我们将从缓存中驱逐掉MMU的最近转换虚拟地址v时的页表查询结果。因此，虚拟地址v的下一次页表查询将会变得稍微慢一些，因为它需要从内存获取前面提到过的页表项。这就是一个EVICT
+
TIME攻击的例子，通过它，AnC就能够在存储页表项的内存页面中，从潜在的64个缓存行中找出4个缓存行。注意，通过尝试来自虚拟地址v之外的各种偏移，我们可以弄清楚每个级别中的页表项对应于哪些缓存行中。例如，如果我们在v
+ 32 KB上执行EVICT + TIME，与在v上执行EVICT + TIME时相比发生变化的缓存行对应于级别1页表的缓存行。
这是因为在x86 64架构上，每个缓存行可以存储8个页表项，映射32 KB的虚拟内存。
假设一个页表缓存对应于一个页表级别，若不刷新该级别的页表缓存的话，我们就无法观察MMU在该级别上的活动。举例来说，假设有一个页表缓存，它用来缓存具有32个表项的2级页表。假设2级页表中的每个表项可以映射2