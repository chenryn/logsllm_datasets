need an initialization for machine learning and dynamic analysis
tools. For machine learning tools, we select all 1,260 malware
samples in GENOME, and 1,260 benign apps from Google Play
as their training set. For dynamic analysis tools, we implement a
driver in Python to simulate all possible triggers in our scope, e.g.,
starting an app, receiving an SMS message, changing the geography
location. Interested readers can refer to the trigger list in [1].
7.2 RQ1: Validity of Generated Malware
We validate the generated malware from two aspects.
Proof of Program Synthesis. We assure that the ﬂows of privacy
leakage in malware are logically true. In detail, we verify the two
phases of the automated malware generation: p1, feature selection
(§ 5.1), and p2, transformation from feature model to code (§ 5.2).
• Proof of p1. In the process of feature selection, we select appro-
priate candidate features, conforming to the constraints in the
feature model. It guarantees there are sufﬁcient and necessary
features to construct malware.
• Proof of p2. Constraints on the unique runtime environment
of Android (§ 5.2) should be satisﬁed. For example, consuming
operations in Android apps cannot be executed in the main thread,
and hence we have to create a child thread to execute consuming
operations. In code assembly, we write scripts to make sure all
the implementation constraints are satisﬁed.
To sum up, for given features, this step is to assure that all the
requirement and implementation constraints are satisﬁed.
Malware App Validation. The last step is to valid the ﬁnal malware
app to test whether it can leak privacy information. To this end, we
set the target URL and phone number to our honeypot that the
information would be sent to. We use the running example to
illustrative the validation process. We generate a malicious app
using the features of malware in the running example (Fig. 1). The
selected features are as follows:
Triggers-MAIN::STARTUP
Sources-TELEPHONY::IMEI, TELEPHONEY::PHONE NUMBER
Sinks-HTTP::APACHE POST
(dependencies) PERMISSION::READ PHONE STATE
We set the target URL to our honeypot web site, in which there
is a responding web page written in PHP to store the received
message from the generated malware. Since there are 30 types of
sources in the feature model, we use MYSTIQUE to generate 30
malicious apps accordingly, each of which contains one kind of
sources. For simplicity, we construct one ﬂow that satisﬁes the
constraints deﬁned in the feature model for the privacy leakage, by
selecting one satisﬁable trigger and sink, and setting up the acquired
Table 1: Detection ratio of privacy leakage malware in GENOME
Malware Family
DroidKungFu3
AnserverBot
BaseBridge
DroidKungFu4
Geinimi
Pjapps
KMin
GoldDream
DroidKungFu1
DroidKungFu2
# Samples
309
187
122
96
69
58
52
47
34
30
DA
0
0
0
0
0
0
0
0
0
0
Detection Ratio (%)
SA ML
53.7
100
99.7
51.0
99.2
60.7
100
10.2
99.3
40.1
45.6
98.9
100
37.8
100
55.6
100
60.2
67.0
100
AV
70.2
74.7
73.0
70.3
71.9
71.6
72.0
70.4
75.6
73.7
permissions. We execute them on a physical Android device. Our
honeypot successfully collects all sensitive information sent by these
malicious apps.
7.3 RQ2: Auditing of AMTs
In this section, we aim to evaluate the AMT using the generated
malware and test the four hypothesis.
First, we test the deployed AMTs on GENOME malware as the
baseline understanding of AMTs. Note that we only choose mal-
ware with privacy leakage attack, which contains 78% of the 1,260
samples in GENOME. The results are presented in Table 1, where
machine learning tools and anti-virus tools perform well in detecting
existing malware. As the dataset GENOME originated from 2010,
anti-virus tools (AVTs), which are mainly based on signature and
pattern matching, can accurately detect the malware with a recall of
71.9% on average. There are still some AVTs that perform poorly,
e.g., Bkav (0%), CMC (0%), Malwarebytes (0%) and TheHacker
(0%). Since machine learning tools use 60% of malware samples in
GENOME as the training set and the remaining 40% as the testing
set, they outperform the other tools with a higher recall.
Static analysis and dynamic analysis are more time-consuming
compared to the previous two approaches, due to the program anal-
ysis they conduct. Static analysis tools has yet achieved around
48.4% of detection ratio of GENOME malware. For the dynamic
tool TAINTDROID, it fails to detect existing malware in GENOME.
The problem is attributed to the limited support of TAINTDROID
to source or sink types, and the compatibility issues when running
out-of-date malware in latest Android OS.
Second, we use MYSTIQUE to generate 100 generations of mal-
ware without evasion features to evaluate the detection ratio (DR)
of AMTs. Then we add evasion features into the malicious apps
to re-evaluate the DR. As shown in Table 2, there are two columns
for each kind of AMTs, of which the ﬁrst column is the DR with-
out evasion features, and the second column “(E)” is the DR with
evasion features. All the values of DRs are calculated as the av-
erage values amongst tools of a speciﬁc type. We summarize the
hypothesis testing results as follows.
H1. The Susceptibility of AVs to Unknown Malware. Main-
stream AVs employ signature- or feature-based approaches. The
detection capabilities depend on the completeness and timeliness of
malware database, and also the abstraction of malware. Generally,
they perform very well in detecting known malware as in GENOME
experiment above: they achieve a 71.9% recall on average, and 27
(out of 57) AVs can even detect at least 99% of malware samples in
the experiment. However, they perform poorly in detecting our gen-
erated 0day malware. According to the detection results of our gen-
erated malware, only 18 generated malware samples can be detected
by the union of these AVs. For example, ESET-NOD32 detects 3
malware samples as “a variant of Android/TrojanSMS.Agent.BLY”.
By further inspection, we ﬁnd that the 3 samples steal the SMS
messages. Speciﬁcally, they share one common behavior: it mon-
372Type
Source
Source
Trigger
Trigger
Trigger
Source
Source
Trigger
Trigger
Sink
Feature
TELEPHONY::SIM SERIAL
TELEPHONY::SIM COUNTRY
BROADCAST::android.bluetooth.device.action.NAME CHANGED
BROADCAST::android.intent.action.ACTION SHUTDOWN
BROADCAST::android.intent.action.PACKAGE REMOVED
SMS::INCOMING SMS
BUILD::SDK INT
BROADCAST::android.provider.Telephony.SMS RECEIVED
BROADCAST::android.intent.action.PACKAGE RESTARTED
HTTP::SOCKET GET
DR (%)
21.1
12.5
12.5
12.5
12.5
1.6
1.6
1.6
1.6
1.6
Figure 6: The signiﬁcance of attack features in detection
Figure 5: Cumulative AFs in GENOME samples
Table 2: The objective value of generated malware during evolution
Detection Ratio (%)
Gen
10
20
30
40
50
60
70
80
90
100
#Vars
50
50
50
50
50
50
50
50
50
50
#Triggers
35.9
31.8
33.8
29.5
32.9
31.2
27.6
28.5
33.3
36.9
AFs
#Sources
13.4
7.6
9.8
9.9
8.2
10.5
10.5
10.3
9.0
10.0
#Sinks
4.6
4.5
3.1
2.4
2.4
2.2
2.4
4.8
2.9
4.0
#Perms
74.9
82.6
75.2
78.3
81.9
80.5
74.5
70.3
77.5
76.5
#EFs
5.6
7.5
4.8
5.1
8.0
7.5
6.2
3.1
6.6
5.4
DA
17.2
34.2