### Optimized Text

#### Section: Issues with Indexing and Stash
Instead of being added in smaller groups as they arrive, some entries remain in the local stash and are not read from the index. These two issues tend to offset each other.

#### Section: Reduction in Server Reads
Our scheme achieves a 94% reduction in the number of reads required by the server for a search query compared to a straightforward approach. This is illustrated in Figure 6, which compares the IO savings of our IO-DSSE scheme against an existing approach and an obliviously updatable index constructed using PATH ORAM. The relaxation of ORAM's security properties has proven to be effective in reducing both cost and latency in serving the first page of results. Specifically, we perform one read instead of 17 (the length of a full path for the chosen parameters), resulting in a 94.1% reduction. Our experiments show a 20% to 82% reduction in the IO needed to return a search result. Since search terms are selected uniformly at random from the set of results, many searches involve only 1 or 2 documents, requiring fewer reads from the naive index compared to one read from our obliviously updatable index. As the number of indexed documents increases, our scheme becomes more efficient. The variance in the number of results per search term also accounts for the variance in the measured results. Given that searches are less frequent than updates, this is not the most critical metric to optimize.

#### Section: Simulated Long-term Storage Usage
We now examine the storage requirements for IO-DSSE on both the server side (i.e., the size of the obliviously updatable index) and the client side (i.e., stored metadata). The size of the obliviously updatable index depends on the distribution of keywords, the rate of keyword arrival, and the amount of available local storage for buffering results on the client.

**Client Storage:**
Since the local client is trusted, there are no constraints on how the storage is organized, and access patterns do not need to be obscured. Client storage is directly proportional to the number of document-keyword pairs, with less than 8 bytes stored per unique keyword. For a 95th percentile user, we use 62.7 MB ± 13.2 KB, and for a 50th percentile user, we use 33.4 MB ± 11.8 KB.

**Server Storage for Partial-Block Index:**
Once the client's storage is full, entries must be evicted into the obliviously updatable index, starting with the most full. The frequency of keyword distribution plays a role here. Eventually, the index will be filled with infrequent words, forcing partial blocks to be evicted into the full-block index. The key questions are: 1) How often does this occur? 2) How large should the partial-block index be to prevent premature eviction?

To measure this, we conducted a Monte Carlo simulation, drawing words according to the measured token distribution and tracking when partial blocks are evicted. We assume a local store of 128 MB and 64-bit email identifiers, with the cost of adding a new keyword to the index being 100 bits. Our simulation shows that a 2 GB partial-block index is sufficient to hold ten years of email for a 95th percentile user and nearly 100 years for an average user.

**Figure 7:**
Simulated long-term storage for IO-DSSE. Left: The size of the obliviously updatable index (server-side storage) over time for users of different activity levels. Right: The size of the client’s storage under the same conditions.

**Deletes:**
Recall that emails can only be deleted from the obliviously updatable index, so any evicted entries are permanent. For a 95th percentile user, the most frequent word is evicted 6,724.8 ± 3.22490 times in 3,650 days, or about 2 evictions per day. This means all index entries for an email must be deleted within a day of arrival. For a 50th percentile user, where the most frequent word is evicted 319.4 ± 0.843274 times in 3,650 days, all index entries for an email can be removed if the email is deleted within an expected 11 days of arrival.

#### Section: Related Work and Attacks
**Related Work on Searchable Encryption:**
Searchable encryption has been extensively studied [5, 7, 8, 10, 15, 19], but few works have focused on efficiency or locality. Cash et al. [5] provide the best such approach, but it does not address the dynamic case, where each document ID associated with a given keyword is inserted into a random location in the index.

**Attacks:**
Zang et al. [22] constructed a highly effective query recovery attack on SSE schemes. The attack leverages the ability of an attacker to insert entries into the index, uniquely identifying the queried keyword. While this attack requires an adversary to insert files, making it infeasible for passive surveillance, our scheme is still vulnerable, especially in email settings where file insertion is easy. Forward private SSE schemes [3] can thwart adaptive versions of the attack but at a high locality cost. Without countermeasures, SSE in email is only secure against passive adversaries, regardless of its IO efficiency.

#### Section: Extensions and Conclusions
Encrypted search for email or similar messaging systems is a major challenge for end-to-end encrypted applications. Existing solutions place a prohibitively high IO cost on updating the index upon message arrival, requiring one random write per document-keyword pair and one random read per search. By using a hybrid approach with a dynamic ORAM-like index and a chunked index for static searchable encryption, we reduce total IO usage by 99%. Building a dynamic index that does not protect read privacy further reduces the upfront costs of search by 94%.

This approach comes at a cost. First, we slightly relax the leakage function for searchable encryption, allowing an attacker to learn when entries are moved from the partial to full-block index. Second, we only support deletes from the obliviously updatable index. Third, we only provide single keyword search.

**Future Work and Extensions:**
The techniques of Cash et al. [5] can be applied to our approach to enable conjunctive search. For deletes, we can incrementally rebuild the index by overwriting a block in the full index with one evicted from the partial index, storing the overwritten block locally and feeding non-deleted entries back. Finally, it is an interesting question whether similar relaxations to ORAM security can be used to build an obliviously updatable index with something other than Path ORAM and even better efficiency.

#### Acknowledgments
This work was supported in part by The National Science Foundation under award CNS-1228443. We would also like to thank David Cash, Seny Kamara, Charalampos Papamanthou, and the anonymous reviewers for their discussions and helpful comments.

#### References
[References remain unchanged]

---

This optimized text aims to improve clarity, coherence, and professionalism while maintaining the original content and intent.