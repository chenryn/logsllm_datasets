The following theorem states the reduction in the time of space
searching with our CGS algorithm:
Theorem 4.1. Given a graph 𝐺 with 𝑁 nodes, the reduction, de-
noted as 𝛽, in the time of space searching with coarse-grained search-
ing satisfies 𝛽 ≈ 𝑂(2𝜅4), where 𝜅 is the number of node clusters and
we assume 𝜅 ≪ 𝑁 .
Proof. See Appendix B.
□
4.4 Generating Adversarial Graphs via SignSGD
Now we present our sign stochastic gradient descent (signSGD)
algorithm to solve the attack optimization problem in Eq (7). Be-
fore presenting signSGD, we first describe the method to compute
𝑝(Θ), where only hard label is returned when querying the GNN
model; and then introduce a query-efficient gradient computation
algorithm to compute the gradients of 𝑝(Θ).
superlinksuperlinksupernodeSession 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea112With zeroth order oracle, we can estimate the sign of gradient
of 𝑝(Θ) via computing 𝑠𝑖𝑔𝑛 ((𝑝 (Θ + 𝜇𝑢) − 𝑝 (Θ))/𝜇𝑢), where 𝑢 is
a normalized i.i.d direction vector sampled randomly from a Gauss-
ian distribution, and 𝜇 is a step constant. The sign can be acquired
by computing 𝑝 (Θ + 𝜇𝑢) and 𝑝 (Θ) separately. However, we need
multiple queries to obtain the value of 𝑝(Θ). As we need to up-
date Θ with many iterations, it is query expensive to compute all
𝑝 (Θ𝑡 + 𝜇𝑢) and 𝑝 (Θ𝑡) at each iteration during the signSGD. For-
tunately, we only need to know which 𝑝 is larger instead of the
exact values of them. Thus, we propose a query-efficient gradient
computation (QEGC) algorithm to compute the sign of gradient with
only one query a time as shown in Figure 4 (b).
Suppose the current direction is Θ𝑜𝑙𝑑 with 𝑔 (Θ𝑜𝑙𝑑) = 𝑔𝑜𝑙𝑑
and 𝑝 (Θ𝑜𝑙𝑑) = 𝑝𝑜𝑙𝑑. Now the direction steps forward with an
increment of 𝜇𝑢, i.e., Θ𝑛𝑒𝑤 = Θ𝑜𝑙𝑑 + 𝜇𝑢. For simplicity of de-
scription, we assume Θ𝑜𝑙𝑑 and Θ𝑛𝑒𝑤 are both normalized vectors.
We want to judge if 𝑝𝑛𝑒𝑤 is larger than 𝑝𝑜𝑙𝑑 or not. The idea is
that we transfer 𝑝𝑛𝑒𝑤 and 𝑝𝑜𝑙𝑑 to 𝑔𝑛𝑒𝑤 and 𝑔𝑜𝑙𝑑 respectively and
compare their values. Specifically, for 𝑝𝑜𝑙𝑑, we find 𝑔∗ such that
𝑝∗ = ∥𝑐𝑙𝑖𝑝(𝑔∗Θ𝑛𝑒𝑤 − 0.5)∥1 = 𝑝𝑜𝑙𝑑. For 𝑝𝑛𝑒𝑤, the corresponding
𝑔𝑛𝑒𝑤 is the distance from 𝐴 to the classification boundary at the
direction Θ𝑛𝑒𝑤. Then we query the target model 𝑓 with graph
𝐴∗ = ℎ (𝐴, 𝑔∗Θ𝑛𝑒𝑤) to figure out whether 𝑔∗ exceeds the boundary
or not. We say that the classification boundary in the direction of
Θ𝑛𝑒𝑤 is closer than that of Θ𝑜𝑙𝑑 if 𝑓 (𝐴∗) ≠ 𝑦0 because we cross
the boundary with the same 𝑝𝑜𝑙𝑑 at the direction of Θ𝑛𝑒𝑤, while
we can only achieve the boundary (but not cross) at the direction
of Θ𝑜𝑙𝑑. Thus, 𝑝𝑛𝑒𝑤 is smaller than 𝑝𝑜𝑙𝑑 and the sign of gradient is
−1. Similarly, 𝑠𝑖𝑔𝑛 = +1 if 𝑓 (𝐴∗) = 𝑦0.
In summary, we compute the sign of a gradient as follows:
𝑠𝑖𝑔𝑛 (𝑝 (Θ + 𝜇𝑢) − 𝑝 (Θ)) =
𝑓 (𝐴∗) = 𝑦0,
𝑓 (𝐴∗) ≠ 𝑦0,
(8)
(cid:40)+1
−1
where 𝐴∗ is the graph whose value of 𝑝 equals to 𝑝 (Θ) in the
direction of Θ + 𝜇𝑢. We can use Eq. (8) to save the queries due to
the following theorem.
Theorem 4.2. Given a normalized direction Θ𝑜𝑙𝑑 with 𝑔𝑜𝑙𝑑 and
𝑝𝑜𝑙𝑑 , there is one and only one 𝑔∗ at the direction of Θ𝑛𝑒𝑤 that satisfies
𝑝∗ = ∥𝑐𝑙𝑖𝑝(𝑔∗Θ𝑛𝑒𝑤 − 0.5)∥1 = 𝑝𝑜𝑙𝑑 .
Proof. See Appendix C.
□
Solving the converted attack problem via sign Stochastic Gra-
dient Descent (signSGD). We utilize the sign stochastic gradient
descent (signSGD) algorithm [2] to solve the converted optimiza-
tion shown in Eq. (7). The reasons are twofold: (i) the sign operation
that compresses the gradient into a binary value is suitable to the
hard label scenario; (ii) the sign of the gradient can approximate the
exact gradient, which can significantly reduce the query overhead.
Specifically, during the signSGD process, we use Eq. (8) to com-
pute the sign of gradient of 𝑝(Θ) in the direction of 𝑢. To ease the
noise of gradients, we average the signs of 𝑄 gradients in different
directions to estimate the derivative of the vector 𝑝(Θ) as follows:
(cid:32) 𝑝(cid:0)Θ + 𝜇𝑢𝑞(cid:1) − 𝑝 (Θ)
(cid:33)
▽𝑝 (Θ) =
1
𝑄
𝑠𝑖𝑔𝑛
𝑢𝑞
,
(9)
𝜇
𝑄
𝑞=1
(a) Compute 𝑝(Θ) with binary search
(b) Compute gradient of 𝑝(Θ) with QEGC
Figure 4: Constructing adversarial graphs. (a) Computing
𝑔(Θ) and 𝑝(Θ) by querying the target model until we find
the classification boundary, which will incur many queries
when computing gradients of 𝑝(Θ) by using the zeroth order
oracle; (b) Query-efficient gradient computation (QEGC). To
compare 𝑝𝑛𝑒𝑤 and 𝑝𝑜𝑙𝑑 (i.e., compute the sign of gradient of
𝑝(Θ)), we find 𝑔∗ in the direction of Θ𝑛𝑒𝑤 such that 𝑝∗ = 𝑝𝑜𝑙𝑑,
and use the predicted label to judge if 𝑝𝑛𝑒𝑤 is larger than 𝑝𝑜𝑙𝑑
after querying 𝐴∗ = ℎ(𝐴, 𝑔∗Θ𝑛𝑒𝑤).
Computing 𝑝(Θ) via binary search. We describe computing
𝑝(Θ) with only hard label black-box access to the target model.
We first compute 𝑔(Θ) in Eq. (4) via repeatedly querying the
target model and further obtain 𝑝(Θ) using Eq. (6). As shown in
Figure 4 (a), each edge in the edge space of 𝐺 can be either existent
or nonexistent so that the searching space consists of lattice points
(i.e., a lattice point is a symmetrical binary matrix 𝑀 ∈ {0, 1}𝑁×𝑁 )
that have equal distance among each other. Suppose there is a
classification boundary in the direction of Θ. 𝑔(Θ) is the length of
direction vector ˆ𝑔(Θ) that begins at the target graph 𝐴 and ends at
the boundary. We can first find a graph 𝐴1 with a different label
from 𝑦0 using our CGS algorithm. Since there will be a classification
boundary between 𝐴 and 𝐴1, we can then conduct a binary search
between them, i.e., we query the middle point of the range [𝐴, 𝐴1]
(e.g., 𝑀1 in Figure 4 (a)) and update the endpoints of the range based
on the predicted label of the middle point in each iteration. The
query process ends when the length of range decreases below a
tolerance 𝜖. With such query process, we can obtain 𝑔(Θ), and then
we can compute 𝑝(Θ) easily.
Computing the gradient of 𝑝(Θ) via query-efficient gradient
computation (QEGC). We now propose a query efficient algo-
rithm to compute the sign of gradient of 𝑝(Θ), that aims at saving
queries used in signSGD in the next part.
M1M2query middle pointsGNNGNNM1M2query middle pointsGNN12M1M2query middle pointsGNN12M1M2query middle pointsGNN12GNN+1-1Boundary①②③④GNN+1-1Boundary①②③④Session 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea113where ▽𝑝 (Θ) is the estimated gradients of 𝑝(Θ), 𝑢𝑞, 𝑞 ∈ 1, 2, . . . , 𝑄
are normalized i.i.d direction vectors sampled randomly from a
Gaussian distribution, and 𝑄 is the number of vectors. Recently,
Maho et al. [34] proposed a black-box SurFree attack that also
involves sampling the direction vector 𝑢 from a Gaussian distribu-
tion. However, the purpose of using 𝑢 is different from our method.
Specifically, 𝑢 in the SurFree attack is used to compute the distance
from the original sample to the boundary, while 𝑢 in our attack is
used to approximate the gradients.
The sign calculated by Eq. (8) depends on a single direction
vector 𝑢. In contrast, Eq. (9) computes the sign of the average of
multiple directions, and can better approximate the real sign of
gradient of 𝑝(Θ). Then, we use this gradient estimation to update
the search vector Θ by computing Θ𝑡+1 ← Θ𝑡 − 𝜂𝑡▽𝑝 (Θ𝑡), where
𝜂𝑡 is the learning rate in the 𝑡-th iteration. After 𝑇 iterations, we
can construct an adversarial graph 𝐴′ = ℎ(𝐴, Θ𝑇) 2. The following
theorem shows the convergence guarantees of our signSGD for
generating adversarial graphs.
Assumption 1. At any time 𝑡, the gradient of the function 𝑝(Θ)
is upper bounded by ∥▽𝑝 (Θ𝑡) ∥2 ≤ 𝜎, where 𝜎 is a non-negative
constant.
𝑡=0 with probability 𝑃 (𝑅 = 𝑡) =
Theorem 4.3. Suppose that 𝑝 (Θ) has 𝐿-Lipschitz continuous gra-
𝜂𝑡𝑇−1
dients and Assumption 1 holds. If we randomly pick Θ𝑅, whose dimen-
sionality is 𝑑, from {Θ𝑡}𝑇−1
,
the convergence rate of our signSGD with 𝜂𝑡 = 𝑂(cid:16) 1√
𝑂(cid:16) 1√
(cid:112)𝑄 + 𝑑(cid:17),
E [∥▽𝑝 (Θ) ∥2] = 𝑂(cid:16)√
will give the following bound on E [∥▽𝑝 (Θ) ∥2]
𝑡=0 𝜂𝑡
and 𝜇 =
(cid:17)
(cid:17)
𝑑𝑇
𝑑𝑇
√
𝑑√
𝑄
+
𝑑𝐿√
𝑇
(10)
□
Proof. See Appendix D.
5 ATTACK RESULTS
In this section, we evaluate the effectiveness our hard label black-
box attacks against GNNs for graph classification.
5.1 Experimental Setup
Datasets. We use three real-world graph datasets from three dif-
ferent fields to construct our adversarial attacks, i.e., COIL [37, 39]
in the computer vision field, IMDB [57] in the social networks field,
and NCI1 [40, 45] in the small molecule field. Detailed statistics of
these datasets are in Table 1. By using datasets from different fields
with different sizes, we can effectively evaluate the effectiveness
of our attacks in different real-world scenarios. We randomly split
each dataset into 10 equal parts, of which 9 parts are used to train
the target GNN model and the other 1 part is used for testing.
Target GNN model. We choose three representative GNN models,
i.e., GIN [55], SAG [26], and GUNet [15] as the target GNN model.
We train these models based on the authors’ public available source
code. The clean training/testing accuracy (without attack) of the
three GNN models on the three graph datasets are shown in Table 2.
Note that these results are close to those reported in the original
2Our attack can be easily extended to attack directed graphs via only changing the
adjacency matrix for directed graphs.
Table 1: Dataset statistics.
Dataset
Num. of Graphs
Num. of Classes
Avg. Num. of Nodes
Avg. Num. of Edges
IMDB COIL NCI1
1000
4110
3900
100
21.54
54.24
2
29.87
32.30
2
19.77
96.53
Table 2: Clean accuracy of the three GNN models.
GIN
GNN model Dataset Train acc Test acc
77.95%
77.00%
77.37%
42.56%
68.00%
72.02%
31.03%
70.00%
76.16%
82.17%
69.44%
73.59%
40.85%
64.78%
73.18%
31.25%
64.44%
69.59%
COIL
IMDB
NCI1
COIL
IMDB
NCI1
COIL
IMDB
NCI1
GUNet
SAG
papers. We can see that GIN achieves the best testing accuracy.
Thus, we use GIN as the default target model in this paper, unless
otherwise mentioned. We also observe that SAG and GUNet per-
form bad on COIL, and we thus do not conduct attacks on COIL for
SAG and GUNet.
Target graphs. We focus on generating untargeted adversarial
graphs, i.e., an attacker tries to deceive the target GNN model to
output each testing graph a wrong label different from its original
label. In our experiments, we select all testing graphs that are cor-
rectly classified by the target GNN model as the target graph. For