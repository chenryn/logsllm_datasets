title:LEAPS: Detecting Camouflaged Attacks with Statistical Learning Guided
by Program Analysis
author:Zhongshu Gu and
Kexin Pei and
Qifan Wang and
Luo Si and
Xiangyu Zhang and
Dongyan Xu
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
LEAPS: Detecting Camouﬂaged Attacks with
Statistical Learning Guided by Program Analysis
Zhongshu Gu, Kexin Pei, Qifan Wang, Luo Si, Xiangyu Zhang, Dongyan Xu
Department of Computer Science and CERIAS, Purdue University
West Lafayette, IN, USA, 47907-2107
{gu16, kpei, wang868, lsi, xyzhang, dxu}@cs.purdue.edu
Abstract—Currently cyberinfrastructures are facing increas-
ingly stealthy attacks that implant malicious payloads under the
cover of benign programs. Existing attack detection approaches
based on statistical learning methods may generate misleading
decision boundaries when processing noisy data with such a
mixture of benign and malicious behaviors. On the other hand,
attack detection based on formal program analysis may lack
completeness or adaptivity when modeling attack behaviors.
In light of these limitations, we have developed LEAPS, an
attack detection system based on supervised statistical learning
to classify benign and malicious system events. Furthermore,
we leverage control ﬂow graphs inferred from the system event
logs to enable automatic pruning of the training data, which
leads to a more accurate classiﬁcation model when applied to
the testing data. Our extensive evaluation shows that, compared
with pure statistical learning models, LEAPS achieves consistently
higher accuracy when detecting real-world camouﬂaged attacks
with benign program cover-up.
Keywords—Attack Detection; Statistical Learning; Program
Analysis;
I.
INTRODUCTION
Enterprise cyberinfrastructures are facing more severe cy-
ber threats powered by sophisticated attack techniques. Such
attacks are driven by ﬁnancial interests for divulging privacy
records, collecting competitor’s intelligence, or concealing
unauthorized system accesses. They may exploit system vul-
nerabilities or leverage social engineering (i.e., psychological
manipulation of innocent people to perform harmful operations
unintentionally) to initiate attacks, leaving only inconspicuous
footprints. More recently, instead of only launching one-time
attacks, adversaries tend to implant stealthy and persistent
backdoors — which parasitize in the memory space of some
long-running benign applications or embed in the application’s
binaries — to facilitate future security penetrations. Based on
the cloaking properties of such attacks, in this paper we call
them camouﬂaged attacks.
Recent research efforts on host-based attack detection
can be divided into two categories: program analysis based
methods and statistical learning based methods.
Attack Detection Based on Program Analysis: Some ap-
proaches [1]–[5] perform static analysis on applications (as-
suming the availability of source or executable code) to obtain
precise program execution models. But the non-trivial over-
head, complexity of accurate binary analysis, and intentional
obfuscation limit
their applicability to real-world applica-
tions/environments. Other detection systems [6]–[8] perform
dynamic analysis in a training phase and build deterministic
program behavior models by proﬁling application-system in-
teractions.
Attack Detection Based on Statistical Learning: Instead of
achieving precise program models like in the former category,
detection systems in this category utilize statistical learning
techniques to build benign/malicious classiﬁcation models. For
example, in the work of [9], [10], association and frequency
rules are learned from training data for future detection. In
other systems [11], [12], histogram-based methods are applied
to proﬁling normal program behavior. A more sophisticated
hidden Markov model (HMM) is adopted in [13], [14] for in-
trusion detection. More recently, the works in [15]–[18] utilize
Support Vector Machine (SVM) to build binary classiﬁcation
models. One major advantage of these statistical learning based
systems is that they are robust in dealing with incomplete
data, and thus can usually achieve better classiﬁcation results
compared with program analysis based approaches.
We argue that, for the detection of camouﬂaged attacks,
current attack detection systems may encounter difﬁculties
in effectively discriminating between benign and malicious
behavior. The main reason is that
the extraction of pure
malicious behavior in a raw dataset (e.g., system execution
logs) is difﬁcult. For trojaned applications or runtime ap-
plication exploitations belonging to camouﬂaged attacks, the
malicious payload no longer executes independently. Instead,
it runs concurrently with the benign code of the application,
which generates a training dataset with interleaved benign
and malicious behaviors. Such noisy training datasets may
eventually lead to a biased classiﬁcation boundary.
In light of the limitation above, we have developed LEAPS1
to integrate the capabilities of the two camps. LEAPS is in-
spired by a recently proposed vision called “Learn-2-Reason”
[19], which promotes mutual enhancement between statistical
learning and formal analysis methods. Speciﬁcally, LEAPS
leverages program execution analysis to reﬁne its statistical
learning model, boosting its detection accuracy.
Taking a host-based system event log as input, we adopt the
supervised statistical learning model to classify benign and ma-
licious events. The classiﬁcation model is built upon system-
level features extracted from the log, such as system event,
libraries, and functions. The effectiveness of this approach is
based on the key observation that the system-level behavior
of anomalous execution, triggered by the malicious code, is
different from the system-level behavior of benign code.
1LEAPS stands for Learning Enhanced with Analysis of Program Support
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
DOI 10.1109/DSN.2015.34
DOI 10.1109/DSN.2015.34
57
57
Then, to address the noisy training dataset problem in
detecting camouﬂaged attacks, we use the control ﬂow graph
(CFG) of each benign application (which may not be complete)
as the oracle to guide the training. From our observation,
benign and malicious instructions by nature cluster separately
in the memory space. For each data point in the noisy training
dataset, we measure its distance to the benign CFG and
assign a corresponding weight, which indicates that outlying
data points are more likely to be events triggered by the
malicious payload. Although injecting malicious code near
benign code is not impossible (e.g., injecting malicious code
in free alignment areas between procedures), it is usually not
used in real-world attacks because such limited space greatly
restricts the functionality of injected code. Typical attacks
choose to allocate extra memory for malicious payloads and
then hijack benign control ﬂows.
Taking the assigned weights into consideration, we build a
Weighted Support Vector Machine (WSVM) classiﬁer to detect
benign and malicious behaviors. Deriving a complete and
accurate CFG using static analysis on a binary is a well-known
challenge due to binary obfuscation and software protection
mechanism. In LEAPS, we avoid static program analysis by
dynamically inferring the CFG of each application — based
on the stack walk trace in the system event log. We note that
such a CFG is by no means complete, but it presents a general
execution pattern of the application, which is sufﬁcient for our
distance approximation.
This paper makes the following contributions:
•
A better statistical learning model for detecting cam-
ouﬂaged attacks, guided by CFGs derived from pro-
gram trace analysis. This model is especially suit-
able for noisy training datasets mixed with be-
nign/malicious events.
•
•
An algorithm for CFG inference only based on the
stack walk trace in the system event
log, without
requiring static program analysis or program instru-
mentation.
Extensive evaluation of LEAPS for the detection of
camouﬂaged attacks with diverse combinations of
applications, malicious payloads, and attack methods,
demonstrating effectiveness of LEAPS.
We organize the rest of this paper as follows. Section II
presents the threat model and the overview of the workﬂow.
Section III provides the system design of LEAPS and Sec-
tion IV presents implementation details. Section V shows
extensive evaluation of LEAPS in different attack scenarios.
Section VI discusses current limitations and proposes future
work. Section VII describes related work and we conclude in
Section VIII.
II. SYSTEM OVERVIEW
In this section, we ﬁrst discuss the threat model and the
attacks we target. Then we present the general workﬂow of
LEAPS and give a brief introduction of the functionality of
each component.
5858
A. Threat Model
We assume that
the adversaries have already found a
way to inﬁltrate the system. They may achieve this through
physical access to a target computer, e.g., manually replacing
an application with a trojaned version, or using some social
engineering techniques to trick innocent users to click some
malicious web sites or open a disguised attachment in a phish-
ing email. They may also remotely exploit some unpatched
vulnerabilities and then implant a backdoor into some long-
running benign program. We do not intend to use LEAPS to
raise an alarm at the time of intrusion, instead we aim to detect
the anomalous behavior and backtrack to its entry point when
the remote adversary performs malicious actions through the
persistent backdoor implanted in the system.
In this paper we focus on camouﬂaged attacks, which run
under the cover of some benign program. This is a common
technique to make malicious behavior more difﬁcult to detect.
Finally, we require that system event
logging function be
turned on so that it can generate program execution traces
as input to our analysis.
B. Workﬂow of LEAPS
Similar to traditional anomaly detection systems, we divide
the workﬂow of LEAPS into two phases: Training Phase and
Testing Phase.
1) Training Phase: We illustrate the workﬂow of the Train-
ing Phase in Figure 1. Here we give a brief description of each
component and its input data format.
The initial input data consist of raw log ﬁles generated
by the system event logging engine. Event logging systems
are commonly equipped in modern operating systems for
diagnosing application performance problems, thus they are
able to walk the application stacks to backtrack execution
when system events are captured. These raw system event
log ﬁles are recorded in a controlled environment and will
be used as training data. The benign raw log is generated
when we execute a clean version of an application; whereas
the mixed raw log is generated when the parasitic malicious
payload (embedded in the binary or injected through remote
exploitation) and the benign application code run in the same
process context, leading to interleaved execution of benign and
malicious code.
Our Raw Log Parser is similar to the front end of Introperf
[20]. We parse the raw log ﬁle, correlate stack walk traces
with corresponding system events, and extract function and
library information sliced for each process in both the user and
kernel space. The output, which we term stack-event correlated
log, consists of itemized system events for the application of
interest. Moreover, each event is attached with its stack walk
trace annotated with libraries and functions.
The Stack Partition Module is for splitting the stack walk
trace of each event into two parts, application stack trace
and system stack trace. Application stack trace consists of
the stack walk within the application itself. We use this to
infer the application’s CFG because it contains both explicit
and implicit execution information. System stack trace consists
of stack walk trace in the shared libraries and the operating
Benign Raw Log 
Mixed Raw Log 
Raw Log 
Parser
Benign Stack-Event 
Correlated Log
Mixed Stack-Event 
Correlated Log
Stack Partition 
Module
Benign System 
Stack Trace
Mixed System 
Stack Trace
Benign Application 
Stack Trace
Mixed Application 
Stack Trace
Data Preprocessing 
Module
Benign Dataset
Mixed Dataset
Weighted Dataset
Training Phase
Supervised Statistical 
Learning Module
Benign/Malicious 
Model
Control Flow Graph 
Inference Module
Benign CFG
Mixed CFG
Fig. 1: Workﬂow of the Training Phase of LEAPS
system (OS) kernel. We note that the differences in system-
level behavior (e.g., system events, shared libraries, and li-
brary/kernel functions) are best suited for distinguishing the
benign functionality from the malicious functionality. Thus we
extract features used by the statistical learning model from the
system stack trace in the system event log.
The Data Preprocessing Module extracts features from the
system stack trace. Here we apply hierarchical clustering to
group the functions and libraries into clusters. This generates
both the benign dataset and the mixed dataset, which are ready
to be used by the statistical machine learning engine.
The Control Flow Graph Inference Module builds the CFG
of the application by inspecting the application stack trace. We
construct two CFGs separately from the benign application
stack trace and the mixed application stack trace. Then we
compare these two CFGs to measure the distance of each
execution path in the mixed CFG to the benign CFG. As we
can map each execution path to its afﬁliated system event,
we assign a weight (computed based on the distances of all
execution paths attached to this event) to each event in the
mixed dataset (generated by the Data Preprocessing Module)
and generate a weighted dataset.
Our Supervised Statistical Learning Module is a uniﬁed
learning system for building the benign/malicious classiﬁer.
We employ a Weighted Support Vector Machine, which is a
binary classiﬁcation model, to obtain the classiﬁer based on the
training data generated from the Data Preprocessing Module.
We treat the data in the benign dataset as the positive samples
in the statistical learning model, while the data in the weighted
mixed dataset are viewed as the negative samples. We can
apply the learned benign/malicious classiﬁer to detect attacks
from production system logs.
2) Testing Phase: After the Training Phase, we have
generated application-wise binary classiﬁers from the training
data. In the Testing Phase, ﬁrst we perform application slicing
on the system event log (same as in the Training Phase) to
generate the testing data. Then we apply the classiﬁcation
models (targeting different application/payload combinations)
to the testing data for detection.
We point out
that we use the application-wise binary
classiﬁer only for the convenience of evaluation. When applied
to attack detection in real situations, LEAPS can coalesce all
application data from the system event log to learn a universal
classiﬁer for testing.
III. SYSTEM DESIGN
Following the workﬂow in the previous section, we now
highlight some key techniques we have developed for LEAPS
and describe the algorithms behind them.
A. Data Preprocessing
Data preprocessing is the essential step before applying
any statistical learning model. It requires domain knowledge to
interpret the raw data, extract distinguishing features for clas-
siﬁcation, and discretize these features to be ready as the input
to statistical learning. Because the statistical learning model is
general and not speciﬁc to our raw data, data preprocessing
is critical to the effectiveness of the ﬁnal classiﬁcation model
generated.
In LEAPS, we choose to use system events and information
in their correlated system-level stack traces to characterize the
program behavior being executed. As mentioned in Section II,
after parsing the raw log ﬁle, we are able to correlate the stack
walk traces with their corresponding system events. Stack walk
trace entries contain the function invocations leading to this
event from the application. Then we partition the stack trace
and only select the system stack trace and system events as
input to the data preprocessing module.
Each entry in the system stack trace contains both the
library and function information. We aggregate the libraries
and functions of each event and generate a 3-tuple entry:
{Event_T ype, Lib, F unc}. Event_T ype stands for the type
of this system event. Lib and F unc stand for the set of
libraries and functions in the system stack trace of this event.
Event_T ype is well deﬁned in the system, and thus can be
naturally mapped to the integer space. For Lib and F unc,
we leverage hierarchical clustering [21] to group similar li-
brary/function sets into one cluster. We use set dissimilarity
as the metric to calculate a pairwise distance matrix, DM, as
follows:
DM[i][j] = set_dissimilarity(i, j) = 1 − (cid:2)seti ∩ setj(cid:2)
(cid:2)seti ∪ setj(cid:2)
(1)
We utilize this pairwise distance matrix in the hierarchical
clustering model to obtain optimal clusters. Finally we replace
Lib and F unc in the 3-tuple entry with its corresponding
cluster number and Event_T ype with the integer based on its
event type. Figure 2 gives a concrete example of preprocessing
a SysCallEnter event and its 3-tuple entry result. We use these
discretized 3-tuple entries as the input data to the statistical
learning model.
B. Control Flow Graph Inference
In our approach, we need the CFG of the benign application
execution as an oracle to process the log mixed with the benign
and malicious execution. While CFGs of binary executables
can be acquired using static or dynamic analysis, generating
CFGs statically from binaries is challenging due to various
5959
@107: EventType=SysCallEnter EventDataLength=8 SysCallAddress=0xfffff9600016e138 
            #0: StackAddress=0xfffff80001a7d3c5 ImageName="ntoskrnl.exe" OffsetToImage=0x713c5
            #1: StackAddress=0x757a2dd9 ImageName="wow64cpu.dll" OffsetToImage=0x2dd9
            #2: StackAddress=0x757a2d92 ImageName="wow64cpu.dll" OffsetToImage=0x2d92
            #3: StackAddress=0x7581d07e ImageName="wow64.dll" OffsetToImage=0xd07e
            #4: StackAddress=0x7581c549 ImageName="wow64.dll" OffsetToImage=0xc549
            #5: StackAddress=0x77b684c8 ImageName="ntdll.dll" OffsetToImage=0x484c8
            #6: StackAddress=0x77b67623 ImageName="ntdll.dll" OffsetToImage=0x47623
            #7: StackAddress=0x77b5308e ImageName="ntdll.dll" OffsetToImage=0x3308e
            #8: StackAddress=0x771a438d ImageName="user32.dll" OffsetToImage=0x2438d
            #17: StackAddress=0x77d39d72 ImageName="ntdll.dll" OffsetToImage=0x39d72
            #18: StackAddress=0x77d39d45 ImageName="ntdll.dll" OffsetToImage=0x39d45
Hierarchical Clustering
Event_Num  Event_Type   Lib   Func
        @107                7                2       40
Fig. 2: The Result of Conducting Hierarchical Clustering on a
System Event
Event 1
Event 2
Addr_5
Addr_4
Addr_3
Addr_2
Addr_1
Implicit Path
Addr_7
Addr_6
Addr_3
Addr_2
Addr_1
Explicit Path
Fig. 3: Example of Control Flow Graph Inference
difﬁculties such as identifying function boundaries [22], dis-