keys to infer which keys are related. To determine whether
keys have been modiﬁed together, Ocasta uses a sliding time
window and considers all keys written within the window to
have been modiﬁed together. Ocasta uses a default sliding
window of 1 second, which can be increased if needed by the
user. Some keys are modiﬁed very frequently, so the chances
of such a key being modiﬁed concurrently with unrelated
keys is high. Consequently, Ocasta only clusters together
keys that are often modiﬁed together, but rarely modiﬁed
individually on their own or with other keys. To do this, we
deﬁne a correlation metric between each pair of keys:
Correlation =
|A ∩ B|
|A|
+
|A ∩ B|
|B|
A and B denote the set of all writes to keys A and B
respectively, and the intersection of A and B denotes the
set of writes where both keys were written together. The
correlation metric is maximized at 2 when both keys are
always modiﬁed together and minimized at zero when both
keys are never modiﬁed together. The larger the correlation,
the more related the pair of keys. Note that the correlation is
only deﬁned when both keys have a non-zero number writes.
Since Ocasta assumes that the application worked initially,
any key that has not been modiﬁed from its initial value
cannot cause a conﬁguration error, and is thus excluded from
Ocasta’s search for a conﬁguration ﬁx.
Hierarchical agglomerative clustering [8] takes as input
a set of points, distances between each pair of points,
and a linkage criterion that deﬁnes how distances between
clusters are computed. It then iteratively merges clusters
together, forming a hierarchy with larger clusters at the
top of the hierarchy. In Ocasta, we use the “maximum
linkage criterion”, which deﬁnes the distance between a pair
clusters as the maximum distance between any two keys
across the clusters. Hierarchical clustering has the advantage
over other types of clustering, such as k-means or centroid-
481
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:26:43 UTC from IEEE Xplore.  Restrictions apply. 
based clustering, in that it does not require the number of
clusters to be speciﬁed in advance. To perform hierarchical
clustering, distances need to be smaller as keys become
more related, so we use the inverse of our correlation metric
as the distance for Ocasta’s clustering. To decide when to
stop clustering, Ocasta provides a tune-able threshold, which
deﬁnes the maximum distance between any two clusters. By
default, Ocasta uses a threshold equivalent to a correlation
value of 2 (i.e. a distance of 0.5), which only clusters keys
that are always modiﬁed together. If the user ﬁnds that
conﬁguration repair fails due to undersized clusters, she may
decrease the threshold to allow Ocasta to cluster together
keys that are modiﬁed together most of the time.
Like any black-box heuristic, Ocasta can fail under certain
circumstances, particularly for conﬁguration settings that
have had very few modiﬁcations from which Ocasta can
learn. For example, the user may modify several unrelated
settings at once, causing the application to store those
changes together into its conﬁguration store. Unless, these
settings are later modiﬁed separately, Ocasta will incorrectly
infer that they are related, resulting in an oversized cluster.
Similarly, it is possible that a user makes a single change
to an application that causes a change to only one level of
hierarchically dependent conﬁguration keys. For example,
she may disable the feature completely, which would only
change the higher-level key, modify the lower-level keys
without changing the higher-level key, or only modify a
subset of the lower-level keys. Again, if this was the only
instance of modiﬁcations to the key, then Ocasta may infer
an undersized cluster that separates related keys from each
other into different clusters. While only using black-box
information makes Ocasta more broadly applicable, Ocasta
can only work with the information it observes and as a
result, can be misled when there is inadequate history for
its clustering to work.
B. Automated repair
Ocasta’s automated repair tool uses the clustering infor-
mation to aid the user in ﬁxing conﬁguration errors. For ex-
ample, conﬁguration error #15, described in Table III, causes
the menu bar to disappear when certain PDF documents are
opened in Acrobat Reader. To use Ocasta, the user must ﬁrst
create a trial, which tells Ocasta how to recreate the error
and makes the symptoms of the error visible on the screen.
For example, in the case of error #15, the user starts Acrobat
Reader and uses it to open the PDF document that causes
the error. Since the menu bar disappears once the document
is opened, the error is visible on the screen. The user thus
ends the trial with the menu bar missing and document open
on the screen. Ocasta records the UI actions the user made
in the trial and automatically extracts the identity of the
application or applications that were used.
Ocasta’s repair tool
then asks the user to specify an
optional start time and an optional end time. The start time
is the earliest time the user believes the conﬁguration error
could have been introduced, and allows Ocasta to limit how
far back in time it searches for the cluster that causes the
error, which we call the offending cluster. If the user doesn’t
specify a bound, Ocasta will search all the cluster versions in
the recorded history of the application. The end time is the
latest time the user believes the conﬁguration error could
be introduced and should roughly coincide with time the
conﬁguration error is ﬁrst discovered. This is useful if the
user might have tried to ﬁx the error themselves and thus
may have made spurious conﬁguration changes that might
slow down the search. If the user does not specify an end
time, Ocasta uses all recorded values up to the end of the
recorded history.
In some cases Ocasta can identify a large number of
clusters in an application (as many as 220 in our measure-
ments). As a result, recovery will be signiﬁcantly faster if
Ocasta sorts clusters so that the ones that are likely to be
conﬁguration clusters are checked before the ones that are
likely to be non-conﬁguration clusters. We use the intuition
that changes to conﬁguration settings should be infrequent
because for them to change, the user must explicitly modify
a conﬁguration setting, which also happens infrequently.
Ocasta thus sorts the clusters by the number of times they
have been modiﬁed over the application’s history.
Ocasta then executes the user-provided trial on the histor-
ical values of the clusters by rolling back an entire cluster
of conﬁguration settings at a time and running the trial
in a sandbox, which prevents the execution to leave any
persistent changes. Ocasta can be conﬁgured to perform
either a breadth-ﬁrst (BFS) or depth-ﬁrst (DFS) search on the
historical values of each cluster. In DFS, Ocasta executes the
trial on all the historical values of a cluster before moving
onto the next cluster. In BFS, Ocasta executes the latest
historical value of each cluster before moving onto the next
historical value. DFS works well if Ocasta’s sort algorithm
successfully prioritizes the offending cluster early in the sort,
while the BFS algorithm provides performance that is less
inﬂuenced by how well the sort worked.
After each trial execution, the tool takes a screenshot.
Ocasta discards the screenshot if it is identical to either
the erroneous screenshot or any previous screenshots it has
recorded. The user can periodically check on the recorded
screenshots recorded to see if any of them display a ﬁxed
conﬁguration. When she see a ﬁxed conﬁguration, Ocasta
permanently rolls back the cluster to its corresponding value
and returns back to recording mode. A video demonstrating
the use of Ocasta is available online for viewing 1.
IV. IMPLEMENTATION
In this section we describe implementation details of Oca-
sta’s prototype. Ocasta works on both Windows and Linux.
1http://youtu.be/aRvJlTj-0F0
482
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:26:43 UTC from IEEE Xplore.  Restrictions apply. 
Ocasta supports applications that use the Windows registry
or the GConf conﬁguration system, as well as applications
that store conﬁguration state in XML, JSON, PostScript, INI
and plain text ﬁles. We describe the implementation of the
Ocasta time travel key-value store, the logger, as well as the
clustering and repair components of Ocasta.
A. Time travel key-value store
Ocasta records conﬁguration key-value activity in a time
travel key-value store (TTKV). We implemented Ocasta’s
TTKV using Redis, a commonly used key-value store [11].
Redis maps each key in the application to a record that
contains the number of writes and deletions, as well as a
list of historical values of the key including timestamps. A
special type of value is used to represent deletions of the
key, which are also recorded in the value history.
During regular application use, Ocasta’s loggers (de-
scribed in the next section) intercept accesses by applica-
tions to their conﬁguration store and record information
about these accesses in the TTKV. Ocasta then uses the
information stored in the TTKV to compute the clustering
information for the keys. In addition, Ocasta’s conﬁguration
error repair tool uses historical values in the TTKV when
performing its search for a conﬁguration error ﬁx.
B. Logger
The primary purpose of the logger is to intercept accesses
an application makes to its persistent storage and abstract
those into key-values that can be stored into the TTKV. As
a result, the logger is necessarily dependent on the way the
application stores its application state. Below we detail the
implementation of Ocasta loggers for the Windows registry,
GConf conﬁguration system, and various ﬁle formats used
by the applications we tested.
1) Windows registry: The Windows registry is a key-
value store provided by the Windows OS. Applications
write keys in the Windows registry using a well-documented
API provided by the OS. We implemented the Windows
registry logger as a user-space shared library. To intercept
registry API calls made by applications, we use the Windows
debug APIs to inject the shared library into Explorer, the
Windows shell. Once injected into Explorer,
the shared
library intercepts each Windows registry API by hooking
the ﬁrst ﬁve bytes of the instructions of the API call in
a way similar to Detours [12]. The shared library also
injects itself into new processes created by the process it is
loaded into by intercepting the Windows API call that creates
new processes. Virtually all regular applications are started
via the Explorer shell, which implements all the common
methods for starting applications such as the Start Menu,
desktop shortcuts, taskbar shortcuts, or double-clicking an
executable in a folder. As a result, the Ocasta logger is able
to monitor every application a user uses. We note that the
Windows registry logger only captures registry activity by
user applications, not by system services or the Windows
kernel, so our current prototype cannot ﬁx conﬁguration
errors in those components.
2) GConf conﬁguration system: The GConf conﬁguration
system, commonly found on Linux systems, implements
the handlers for its APIs in a shared library. We used the
standard approach of intercepting shared library calls on
Linux by using the LD_PRELOAD environment variable to
load our own shared library into the address space of every
process. Our library exports a set of shared library calls that
is identical to the set of shared library APIs exported by
the GConf shared library. By specifying our library in the
LD_PRELOAD environment variable, our library is always
loaded before the GConf library and thus all calls to those
APIs will invoke our functions, which will then subsequently
call the real functions in the GConf shared library after
logging the events to the TTKV.
3) Application-speciﬁc ﬁle formats: Applications that
don’t use OS-provided key-value storage facilities such as
the Windows Registry or GConf generally implement their
own ﬁle-based key-value store. We conducted a small study
on the common ﬁle formats used for conﬁguration storage
and found applications generally use standard ﬁle format:
JSON, XML, PostScript, or one of two key-value lists that
both had the format “key = value”, which we called INI if
it is hierarchical and plain text if it is ﬂat.
We elide the details of
the implementation of our
application-speciﬁc ﬁle parsers for the sake of space. One in-
herent shortcoming of Ocasta when dealing with application-
speciﬁc ﬁle formats is that applications typically read the
entire ﬁle into an in-memory key-value store. The applica-
tions then perform writes on the in-memory store and ﬂush
the in-memory store back to disk. To infer which keys are
changed, Ocasta compares the ﬁles before and after each
ﬂush. In practice, we observe that applications typically
ﬂush their in-memory store after each key modiﬁcation to
guarantee persistence, but if they do not, Ocasta will not
be able to tell if a key was modiﬁed several times between
ﬂushes. As shown in Section VI, despite the coarser level
of information available to Ocasta for applications that use
application-speciﬁc ﬁles, Ocasta is still able to offer good
clustering performance for these applications.
C. Ocasta clustering and repair tool
Ocasta’s clustering algorithm is based on an open source
clustering library [13]. However, the hierarchical clustering
API provided by this library does not allow a cluster
threshold to be used to restrict clustering. Hence, we added
functionality to prune the results returned by the hierarchical
clustering API according to a speciﬁed threshold.
Ocasta’s repair tool has three main components – a UI
record and replay tool, which records the user-provided trial
and re-executes it on the application, a screenshot
tool,
which takes and records screenshots of the application and
483
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:26:43 UTC from IEEE Xplore.  Restrictions apply. 
a controller, which coordinates the entire recovery search.
We have implemented the repair tool on both Windows and
Linux. To save time and effort, we made judicious use of
various open-source libraries and packages for recording UI
actions, as well as capturing and manipulating screenshots.
A limitation with our current implementation of the repair
tool is that it deterministically replays trials and thus does
not guarantee the same trial can be replayed correctly across
different conﬁguration settings. A robust adaptive replay
can probably address this limitation, but the current focus
of our work is to demonstrate the beneﬁts of clustering.
Nonetheless, we found our repair tool works well in our
evaluation and user study.
V. DATA COLLECTION
We deployed Ocasta on 24 Linux desktop computers
running Debian 6 and 5 Windows desktop computers. Ocasta
intercepts and records reads, writes and deletions of settings
into application conﬁguration stores such as the Windows
registry, GConf database and application conﬁguration ﬁles.
Conﬁguration settings are abstracted into keys and stored
into a key-value store called the Time Travel Key Value
Store (TTKV). Table I summarizes the characteristics of the
traces from these deployments, which we use in this paper.
The period of deployments range from one month to over
two months. All the computers were actively used during
the deployment.
All the Linux desktop computers are from four undergrad-
uate computing laboratories administrated by our depart-
ment. To reduce bias in the selection of the computers, we
choose 6 computers from each laboratory. These computers
are used mainly on site by undergraduate students for their
course work, and remotely by graduate students and faculty
members in our department. This study was approved by our
institutional ethics review board.
Because these machines are shared among many users,
we link usage of applications by the same user regardless of
what machine they are using – traces from one machine by
a particular user will be combined with traces from another
machine by the same user. Our ethics review board required
us to only instrument a fraction of the computers in any
one lab to give students who did not wish to participate
in the study ample opportunity to select an uninstrumented
machine. Unfortunately,
that we only got a
sampling of user-behavior since a student would not be
likely to use an instrumented machine every time they were
in the lab.
this meant
The 5 Windows desktop computers are personal comput-
ers used by four graduate students and one faculty member.
They run a variety of Windows OS including Windows 7,
Windows Vista, and Windows XP.
VI. EVALUATION
We evaluate 3 aspects of our Ocasta prototype. First, we
evaluate the accuracy of the clusters that Ocasta extracts.
Application
MS Outlook
Evolution Mail
Internet
Explorer
Chrome
Browser
MS Word
GNOME Edit
MS Paint
Eye of GNOME
Acrobat Reader
Explorer
Windows Media
Player
Total
Description
E-mail Client
E-mail Client
Web Browser
#Keys
182
183
33
#Clusters %Accuracy
33/82
18/65