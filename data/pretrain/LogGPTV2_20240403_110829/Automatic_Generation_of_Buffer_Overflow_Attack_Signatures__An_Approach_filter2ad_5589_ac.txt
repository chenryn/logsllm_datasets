1024
4096
4144
3477
1024
1049
2048
55
0
48
258
376
195
4144
3477
1024
1049
2048
N/A
N/A
N/A
N/A
N/A
N/A
0
0
1024
1049
2048
8.6
1
10.4
1.9
13.4
1.3
1
1
1
0.9
0.7
1
1.0
1.0
1
1.0
1
1.0
1
1
4.0
1.0
Figure 3. Effectiveness of our approach in signature generation.
used programs, and as a result, would have had obvious
bugs ﬁxed, thereby providing us with more sophisticated
attacks. These include the wu-ftpd FTP server, apache
web server, ntpd network time protocol server, ircd Inter-
net relay chat server, samba server that supports Windows-
compatible ﬁle and print sharing, and CVS server used for
source-code versioning. Of the remaining programs, pass-
logd (a passive syslog capture daemon) was chosen be-
cause it had a message subﬁeld overﬂow that did not in-
crease overall message length, thereby posing a problem
for length-based signature detection. oops (a freeware web
proxy server) was chosen because it represents perhaps the
hardest example for ARBOR, providing no useful current or
historical context information. Other examples were mod-
erately popular programs, including gtkftpd, a FTP server
with a Gtk-based GUI, lshd, the GNU secure shell server,
and epic4, a popular Internet relay chat client.
The examples were also chosen to exercise different
types of memory errors, including stack overﬂow, heap
overﬂow, and format string bugs.
Figure 3 shows the results obtained with these programs,
organized into four groups according to the nature of sig-
natures generated. In the ﬁrst group, current context was
enough to generate effective length-based signatures. Al-
though some of the programs receive inputs larger than the
attack-bearing input, the corresponding contexts were dif-
ferent. The second group consists of samba and epic4,
both of which read their inputs from a single location. This
means that the current context remains the same for all mes-
sage types. Since some of the messages, by their nature, are
very long, ARBOR could not generate a length-based sig-
nature. However, since both attacks use a sequence of mes-
sages, signatures can be generated using historical context.
In the third group, both current context and historical
context did not help to synthesize a length-based signature.
In the case of passlogd, there was only one message type,
so historical context was not applicable. Moreover, the at-
tack involved an overﬂow in a subﬁeld of the message, so
the overall length was still within the size of benign re-
quests. A similar situation applied in the case of CVS as
well. However, both these attacks were characterized by
a large fraction of non-ASCII characters, whereas benign
inputs consisted of mostly ASCII characters. Hence signa-
tures based on character distributions were generated.
The last group consists of oops which is a proxy web
server. By its nature, it simply passes on its requests to an
external web server. As a result, it reads its input requests
from the same program location. Moreover, its input re-
quests are independent of each other. As a result, no useful
current or historical context was available. As a result, AR-
BOR failed to generate a signature.
From these results, we can see that program context is
very important for generating accurate signatures. Without
context information, length-based signatures can be gener-
ated for less than 10% of the attacks. This increases to 55%
and 72% with current and historical context. Using both
contexts and length as well as character distribution crite-
ria, successful signatures are generated for 91% of attacks.
3.2 Evaluation of Runtime Overhead
Since analysis is an ofﬂine process, we have not tuned the
signature generator for performance. For this reason, we
did not study its performance in our experiments.
The runtime overhead due to inline components was 7%
for a CPU-intensive benchmark (compilation of Openssh
version 3.8.1p1), and 10% for an Apache server.
A 7% to 10% overhead is modest, and it can be further
Program
Compilation
httpd
Partial Logging
< 5%
< 5%
Full Logging
7%
10%
Figure 4. Performance overheads.
 1
 0.8
 0.6
 0.4
 0.2
y
t
i
l
i
b
a
l
i
a
v
A
httpd
httpd-ARBOR
 100
 200
 300
 400
 500
 600
Attack rate (per second)
 1
 0.8
 0.6
 0.4
 0.2
y
t
i
l
i
b
a
l
i
a
v
A
named
ntpd
named-ARBOR
ntpd-ARBOR
 0.1
 1
 10
 100
Attack rate (per second)
Figure 5. Availability Degradation under Repetitive Attacks
improved by logging only a fraction of the operations under
normal conditions, and switching to full logging during pe-
riods of attacks. For instance, if only 10% of the program
operations were logged during normal operation, this brings
the overheads to below 5%. With partial logging, logging
is turned on for a period of time (say 100 milliseconds) and
then turned off for a period (say, 900 milliseconds). The
potential downside to partial logging is that when the ﬁrst
attack occurs, the associated input data may not have been
logged. But this can be corrected right away, as the logger
can be reconﬁgured to perform full logging after the ﬁrst
attack. Thus, the only effect will be that of a slight delay
in signature generation. Note that the behavior model is al-
ways updated, so partial logging has no effect on the model.
3.3 Improvement in Server Availability
Figure 5 compares the availability of three key servers in
the face of repetitive buffer overﬂow attacks: the Apache
web server (httpd), the domain name server (named), and
the network time server (ntpd). The availability at a given
attack rate was measured as the ratio of server through-
put at that attack rate, expressed as a fraction of the server
throughput under no attacks.
In all experiments, attacks
were carried out by one or more clients, while the server
was accessed in a legitimate fashion by another client. For
servers protected by our approach, the input ﬁlter dropped
requests and reported an error to the server. For an unpro-
tected server, the server would crash after processing input
from an attacker. The server was restarted automatically
after a crash.
In the case of httpd, normal request ac-
cesses were simulated using WebStone. For other servers,
we wrote scripts to make repeated requests to the server.
In the absence of our protection, ntpd and named need
to be restarted after each attack, which is quite expensive.
As a result, our approach achieved about a factor of 10
to 100 improvement in their ability to withstand repetitive
attacks, i.e., for a given value of server availability, pro-
tected servers can withstand attacks at rates that are about
10 to 100 times higher than that of unprotected servers. In
the case of httpd, the Apache web server uses multiple
processes to serve requests, and attacks cause one of the
“worker processes” to die, not the main server. This means
that attacks do not require a server restart, but only that a
new process be created to replace the process that crashed
due to the attack. So the normal recovery process is more
efﬁcient than ntpd and named. As a result, the availability
improvement due to ARBOR was closer to 10 than 100.
3.4 False Positives
We did not encounter false positives in our experiments,
as our approach generates signatures only when the attack
input size exceeds all previously encountered benign input
sizes in a given context. The column “Attack to Benign Size
Ratio” in Figure 3 shows that there is a signiﬁcant differ-
ence between benign and attack input sizes, thus providing
a safety factor against false positives. It can also be seen
that for many programs, the BIN% ratio is 1, once again
providing a margin of safety from false alarms. To further
reduce the possibility of false positives, we can combine
length and character distribution into a single signature.
For samba and epic4, the maximum size of 0 indi-
cates that the corresponding historical context was never
witnessed in the presence of benign requests. Similarly, for
apache, the context corresponding to the attack was never
witnessed with benign requests. This is not reassuring from
a false positive stand-point, as there is a possibility that this
is due to insufﬁcient diversity among the clients we used.
Further analysis on apache revealed that the contexts cor-
responding to the legitimate and attack inputs were almost
the same — in fact, the difference was in a calling function
that appeared 15 frames higher in the call stack. If we rede-
ﬁned “context” to use only the top 15 return addresses, then
the maximum benign request size increases to 138, which
gives us more conﬁdence with respect to false positives.
We are currently investigating two ways to provide in-
creased assurances regarding false positives. The ﬁrst way
is to use an adaptive deﬁnition of current context that varies
the number of return addresses used. The second way is
to derive a conﬁdence metric for the signature based on the
number of benign samples seen in any given context.
3.5 False Negatives
In this section, we analyze several scenarios where signa-
ture generation may be expected to fail.
Attacks delivered through multiple packets. If an attack
is fragmented into multiple packets, then it may be neces-
sary for a server to perform multiple input operations to read
the attack input. Each input operation may return a small
amount of data, and hence fall below any size threshold
used in an attack signature. To address this limitation, we
observe that typically, a server will perform such read oper-
ations in a loop until the complete request is received. As
a result, all these input operations are made from the same
calling context, and there are no other input operations in
between. Our approach currently concatenates the results
of such a sequence of input operations, and is hence able to
deal with such fragmented attacks. However, it is possible
that some servers may read fragmented requests from differ-
ent parts of the program. In this case a more sophisticated
approach for assembling inputs will be needed.
Concurrent Servers. With concurrent servers, it is possi-
ble that operations associated with processing different re-
quests may be confused, which can be expected to make it
difﬁcult to synthesize accurate signatures. However, we ob-
serve that ARBOR already incorporates a search for identi-
fying the attack-bearing inputs from recent inputs. Concur-
rency simply increases the number of recent requests that
need to be considered in the search, and hence does not un-
duly increase false negatives. Indeed, many of the attacks
in our experiments involved concurrent servers.
Message ﬁeld overﬂows. Some attacks are characterized
by the fact that the input message is well within the max-
imum limits, but subﬁelds of the message are not. Such
attacks can pose problems in some cases, but not in oth-
ers. If a server reads different message ﬁelds from different
program locations, then a signature can still be generated.
This behavior is common in text-based protocols that make
use of hand-written parsing code. For instance, sendmail
uses repeated calls to getc to read its input, and uses con-