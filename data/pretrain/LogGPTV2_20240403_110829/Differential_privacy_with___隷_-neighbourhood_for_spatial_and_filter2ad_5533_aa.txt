title:Differential privacy with \(δ\)-neighbourhood for spatial and
dynamic datasets
author:Chengfang Fang and
Ee-Chien Chang
Differential Privacy with (cid:14)-Neighbourhood for Spatial and
Dynamic Datasets∗
Chengfang Fang
Huawei International
PI:EMAIL
Ee-Chien Chang
School of Computing
National University of Singapore
PI:EMAIL
ABSTRACT
Diﬀerential privacy provides a strong guarantee in protect-
ing privacy of individuals who contributed to a published
dataset. In this paper, we focus on spatial datasets and dy-
namic datasets, and attempt to exploit the intuition that
farther-apart entities should have lesser inﬂuences to each
other, and thus more privacy budget should be invested
to protect close-by entities. To capture such intuition, we
propose embedding the underlying spatial or temporal dis-
tance function into the notion of dataset neighbourhood.
We called the proposed neighbourhood δ-neighbourhood, and
discuss its implications in both spatial and dynamic dataset-
s. For dynamic datasets, while there are known negative
results on the standard diﬀerential privacy, it is possible to
continuously and indeﬁnitely publish under δ-neighbourhood
by reusing the privacy budgets. Although known mecha-
nisms, by deﬁnition, are also diﬀerentially private under δ-
neighbourhood, they are not designed to exploit the relaxed
notion for better utility. For spatial datasets, we propose an
approach on 2D spatial points that re-allocates more bud-
gets to nearby entities and thus obtains signiﬁcantly higher
utility. In addition, we give mechanisms that achieve “sus-
tainable privacy” on dynamic datasets under both online and
oﬄine setting.
Categories and Subject Descriptors
H.2.8 [Database management]: Database Administra-
tion—Security, integrity, and protection; K.4.1 [Computers
and Society]: Privacy
Keywords
Diﬀerential Privacy, Bounded Neighbourhood, Spatial and
Temporal Datasets
∗
This work is supported by the Singapore NRF under its IRC@SG
Funding Initiative and administered by the IDMPO.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org. Copyright 2014 ACM
978-1-4503-2800-5/14/06 ...$15.00. http://dx.doi.org/10.1145/2590296.2590320
ASIA CCS’14, June 4–6, 2014, Kyoto, Japan.
Copyright 2014 ACM 978-1-4503-2800-5/14/06 ...$15.00.
http://dx.doi.org/10.1145/2590296.2590320.
1.
INTRODUCTION
Many datasets contain useful statistical information for
public usage. To publish such information while preserving
privacy of each contributor is challenging. The recent notion
of diﬀerential privacy provides a strong form of assurance in
protecting individual contributors.
A probabilistic publishing mechanism A is ϵ-diﬀerentially
private if the published data is suﬃciently noisy, so that it
is diﬃcult to distinguish the membership of an entity in a
group. More speciﬁcally, the following bound holds for any
R ⊆ range(A):
P r(A(D1) ∈ R) ≤ exp(ϵ) · P r(A(D2) ∈ R),
(1)
for any two neighbouring datasets D1 and D2 that diﬀer on
at most one entity. A useful property of the formulation is
that, for two datasets D1 and D2 that diﬀer in more than
one entity, there is still protection but with a weaker bound
exp(cϵ), where c is the “distance” between D1 and D2.
In this paper, we focus on spatial datasets and dynamic
datasets, and attempt to exploit the intuition that farther-
apart entities should have lesser inﬂuence to each other, and
thus more budget should be invested to protect close-by en-
tities. To capture the notion of spatial and temporal dis-
tance, we adopt a alternative deﬁnition of neighbourhood.
Under the original neighbourhood (let us call it the standard
neighbourhood), two neighbouring datasets D1 and D2 d-
iﬀer by one entity, in the sense that D1 = D2 − {x}, or
D1 = D2 − {y} + {z} for some x, y, z.
In other word-
s, D1 and D2 are neighbours if one can be obtained from
another by either adding a new entity x or replacing an
entity y by z.1 We propose an alternative form of neigh-
bourhood: instead of having arbitrary entity x and z, they
have to meet some spatial conditions. The new x must be
near to some “sources” and the replacement z must near
to y within a threshold δ. Such neighbourhood naturally
arises from spatial datasets, for example locations of Twit-
ter users [12] where the distance between two entities is the
geographical distance between them. We call this variant
δ-neighbourhood, where δ is the threshold.
Similar deﬁnitions of dataset neighbourhood have been
considered before. For example, Kifer et al. [14] consid-
ered the attribute diﬀerential privacy, where two datasets
are considered neighbours iﬀ they diﬀer at one attribute in
one record. Konstantinos et al. [2] consider broadening the
neighbourhood relationship with arbitrary metrics. Our no-
1
There are a few versions of standard neighbourhood, for example,
unbounded diﬀerential privacy [11, 25], and bounded diﬀerential pri-
vacy [24, 14].
159tion of δ-neighbourhood can be viewed as a variant that
stresses on spatial and temporal locality.
There are a few ways to view the assurance provided by
the proposed neighbourhood. In some applications, the da-
ta are subject to some constraints and thus not all possible
datasets are valid. For example, Blocki et al. [1] consider so-
cial network graphs where the degree of any node is bound-
ed, instead of all possible graphs. When such constraints
are captured by δ-neighbourhood, the guarantee provided
by both notions are equivalent.
Viewing from another perspective, if the domain (where
the entities of the datasets are drawn from) is connected
and bounded w.r.t.
the underlying metric, then a mech-
anism that is diﬀerentially private under δ-neighbourhood
is also diﬀerentially private under the standard neighbour-
hood. However, the guaranteed bound (as in inequality (1))
is stronger when the entities are close-by. Hence, the pro-
posed δ-neighbourhood can be viewed as a “redistribution”
of assurance, instead of a relaxation of assurance when com-
pares to the standard neighbourhood. Illustrating examples
will be discussed in Section 4 and 6.
In addition, the δ-neighbourhood can also be adopted for
dynamic datasets where entities are added and removed over
time. One example is the scenario considered by Dwork et
al. [7], where aggregated information on users’ health condi-
tions in a region or building (say airport) is to be monitored
over time. Under the standard neighbourhood, due to the
ﬁxed budget, it is impossible to publish the dataset repeated-
ly with high utility. However, there are scenarios where en-
tities do not stay in the dataset for long and thus, intuitive-
ly, the eﬀect of information published earlier would diminish
over time, and hence we should be able to continuously pub-
lish with high utility. We can deﬁne a δ-neighbourhood that
captures the above intuition, so as to achieve sustainable
privacy on dynamic datasets.
Existing diﬀerential private mechanisms designed for the
standard neighbourhood are, by deﬁnition, also diﬀerentially
private under the δ-neighbourhood. However, these mecha-
nisms may not fully exploit the δ-neighbourhood for better
utility. For example, publishing equi-width histogram of 1D
datasets induces the same amount of sensitivity under both
standard and δ-neighbourhood, and thus following the well-
known method of adding Laplace noise proportional to the
sensitivity would not achieve higher utility. We propose an
optimization approach and give a mechanism for 2D spatial
points that achieve signiﬁcantly higher utility. Whereas for
dynamic dataset, we investigate how to allocate the privacy
budget to sustain the publishing process over time, so as to
minimize the expected total amount of noise in both oﬄine
and online settings. On the other hand, some mechanisms
can be naturally extended to δ-neighbourhood, such as pub-
lishing sorted 1D points, and median publishing as described
in Section 5.5.
The rest of the paper is organized as follow: Section 2 in-
troduces the background on diﬀerential privacy, followed by
the proposed notion of δ-neighbourhood in Section 3. The
motivating examples on spatial datasets are given in sec-
tion 4, and the mechanisms catered for δ-neighbourhood are
given in Section 5. Section 6 and 7 are devoted to dynam-
ic datasets. We discuss the related works in Section 8 and
conclude our work in Section 9.
2. BACKGROUND
In this section, we brieﬂy describe the notion of diﬀerential
privacy.
2.1 Neighbourhood and Differential Privacy
A dataset is a multiset (i.e. a set with possibly repeating
elements) of entities from the domain M, and let us denote
the collection of all datasets as D.
Deﬁnition (ϵ-diﬀerential privacy [4]) A mechanism A
satisﬁes ϵ-diﬀerential privacy if for all R ⊆ range(A), and
any pair of neighbours (D1, D2), we have:
P r(A(D1) ∈ R) ≤ exp(ϵ) · P r(A(D2) ∈ R).
(2)
In the above deﬁnition, two datasets D1 and D2 are neigh-
bours if they “diﬀer on one entity”. There are a few in-
terpretations of the above statement: some interpret it as
D1 = D2 ∪ {x} or D2 = D1 ∪ {x}, i.e. one dataset is a
proper subset of the other with one less in size [11][25]; and
in some literatures [24][14], it is interpreted as D1 − {x} =
D2 − {y} for some x, y. The former interpretation is also
known as the unbounded diﬀerential privacy, whereas the
latter as bounded diﬀerential privacy. In this paper, we con-
sider both, i.e. D1 and D2 are neighbours iﬀ D1 = D2 ∪{x}
or D1 −{x} = D2 −{y} for some x, y ∈ M, and call this the
standard neighbourhood. Such deﬁnition of neighbourhood
is also considered by Roth et al. [19].
A consequence of the bound provided by diﬀerential priva-
cy is that, when two datasets D1 and D2 diﬀer by c entities,
then if a mechanism A is ϵ-diﬀerentially private, we have:
(3)
P r(A(D1) ∈ R) ≤ exp(cϵ) · P r(A(D2) ∈ R),
for all possible R ⊆ range(A).
In other words, although
the deﬁnition only explicitly dictates the relationship among
neighbours, there are still protections on datasets that are
far apart, but with a weaker bound.
2.2 Sensitivity and Laplace Mechanism
k ≥ 1, the probabilistic mechanism A that outputs:
It is shown [6] that given a function f : D → Rk for some
f (D) + (Lap(△f /ϵ))k,
achieves ϵ-diﬀerential privacy, where (Lap(△f /ϵ))k is a vec-
tor of k independently and randomly chosen values from the
Laplace distribution, and △f is the sensitivity of the func-
tion f . The sensitivity of f is deﬁned as the least upper
bound on the ℓ1 diﬀerence of all possible neighbours:
△f := sup∥f (D1) − f (D2)∥1,
where the supremum is taken over pairs of neighbours D1
and D2. Here, Lap(b) denotes the zero mean distribution
with variance 2b2, and a probability density function:
ℓ(x) =
−|x|/b.
e
1
2b
3.
(cid:14)-NEIGHBOURHOOD
We assume that there is a distance function d : M×M →
R on the domain that captures the distance between a pair
of entities, and there is a set of sources S ⊆ M. With
this distance function and sources, for a threshold δ, we say
that two datasets D1, D2 are δ-neighbours if, and only if the
following holds:
1601. there exists x1 and x2 ∈ M, such that d(x1, x2) ≤ δ,
and D1 − {x1} = D2 − {x2}, or
2. there exists an x3 and s ∈ S s.t. d(x3, s) ≤ δ, and
D1 − {x3} = D2 or D2 − {x3} = D1.
In other words, either D1 can be obtained from D2 by re-
placing an entity x2 with a nearby entity x1, or by adding
a new entity x3 emerged near a source s. Note that if S is
empty, then the size of D1 and D2 must be the same.
Given two datasets D1, D2 ∈ D, we say that D1 and D2
are connected if there exists a ﬁnite sequence E0, E1, E2, . . . ,
Em with E0 = D1 and Em = D2 s.t. for any i, the consecu-
tive Ei and Ei+1 are δ-neighbours, and call the smallest such
m the distance between D1 and D2. If any two datasets in
D are connected, we say that D is connected, and call the
least upper bound on the distance, if it exists, the diameter
of D.
3.1 Differential Privacy under δ-Neighbourhood
We say that a mechanism A is ϵ-diﬀerential privacy under
δ-neighbourhood if for all R ⊆ range(A) and any pair of
δ-neighbours (D1, D2):
P r(A(D1) ∈ R) ≤ exp(ϵ) · P r(A(D2) ∈ R).
(4)
Similar to standard neighbourhood, we can deﬁne the sen-
sitivity of a function f : D → R with respect to the δ-
neighbourhood, which is
sup∥f (D1) − f (D2)∥1,
where the supremum is taken over all pairs (D1, D2) of δ-
neighbours.
3.2 Properties
Since δ-neighbours are also neighbours under the standard
neighbourhood, thus an ϵ-diﬀerentially private mechanism
under standard neighbourhood is also ϵ-diﬀerential private
mechanism under δ-neighbourhood. The converse also holds
but with a weaker bound, as stated in the following lem-
ma(proof omitted):
Lemma 1 If a mechanism A is ϵ-diﬀerential private under
the δ-neighbourhood and the diameter of D is d, then it is
(dϵ)-diﬀerential private under the standard neighbourhood.
The composition of two diﬀeren-
Sequential composition:
tially private mechanisms is also diﬀerentially private. It is
easy to show that this property also holds under δ-neighb-
ourhood: given a sequence of k mechanisms, A1,A2, . . .Ak,
where Ai is ϵi-diﬀerentially private under δ-neighbourhood,
then the mechanism
∑
A∗
(D) = A1(D,A2(D, . . .))
k
i=1 ϵi)-diﬀerentially private under δ-neighbourhood.
is (
4.1 Example 1
Consider a situation where the dataset is constrained, in
the sense that not all multisets of entities from M are in
D (recall that D is the set of all possible datasets). Let