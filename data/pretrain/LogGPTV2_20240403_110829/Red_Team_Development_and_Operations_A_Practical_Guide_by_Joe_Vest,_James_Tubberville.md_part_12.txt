The first post-engagement meeting is usually the executive outbrief. An executive brief is typically
performed soon after execution completes (within one or two days following execution). This meeting
is tailored toward management and should include key personnel from the target organization. This
meeting should not only include information security management but organizational management as
well. The outcome of a Red Team engagement may impact how an organization operates in the future,
potentially requiring funding to pursue mitigations or staffing modifications. Management awareness
and buy-in are critical if Red Team results will be used to improve an organization's security stance
to defend and respond to a threat.
The executive outbrief should focus on the big picture of the event and is best portrayed as a
chronological story of critical steps and observations. The story and actions will become the attack
narrative in the final report. At this point, the final report and analysis are not complete, but
management is looking for quick answers. If obvious issues were identified, they could be highlighted
in the brief. It should be pointed out that the final report may contain observations that will not be
discovered until all information has been analyzed.
Consider This
Most executive suites and senior managers aren’t as
interested in the technical details of the engagement. They
are more commonly interested in the impacts to business
functions, production, and reputation.
Attempt to correlate each major action or milestone to the
business aspects impacted. If possible, estimating total
costs (including lost revenue, time, remediation,
capability, etc.) facilitates executive understanding of the
impacts and reinforces interaction.
Executive Outbrief Checklist
● Occurs immediately after engagement execution
● Include organizational management (decision makers)
● Include key information security and technical staff
● Focus on the chronological summary of observations (story of the
event)
● Highlight critical observations
● Inform the audience that this brief is merely a summary. The final
report will contain all event details
Optional
● Include additional information security or technical staff
● Include critical system experts
● Include legal staff
Technical Outbrief
A technical outbrief (or tech-on-tech briefing) is extremely valuable to the organization, to the
Defensive/Blue Team, and to the Red Team itself. These technical exchanges do not always occur but
are too valuable to ignore and should be a required step for every engagement.
The tech-on-tech is a bi-directional technical exchange of information between the Red Team, the
Blue Team, and the organization. During this exchange, both the Red and the defensive elements
provide a highly detailed, step-by-step technical review of the actions and results (including all
associated details) of the engagement. This is where training and education meet and is one of the
most valuable opportunities for all parties to learn. More often than not, the defenders discover that
they had very little insight into Red Team actions on the network. The tech-on-tech allows both sides
to participate in a detailed walkthrough conjoined with a question and answer session.
The occurrence of the tech-on-tech is often more useful to those who will implement mitigations or
changes driven by red team activity than the final report. While the process is quite simple, the value
is unsurpassed. A few tech-on-tech actions/roles have been identified below to give you a better
understanding of what should take place.
Tech-on-Tech Briefing Checklist and Agenda Planning
The Red Team:
● Explains Red TTPs and intended IOCs.
● Explains their initial thought process for meeting the engagement
objectives.
● Steps through Red actions and associated activity/commands. (This
occurs simultaneously with the defender walkthrough.)
● Describes why those actions were executed. (What lead to each
specific action?)
● Provides the results of each action and how that action enabled the
next.
● Provides recommendations or techniques that would limit each
threat action.
The defensive team:
● Has the opportunity to ask the how and why.
● Explains the process for securing and defending the environment.
● Identifies any alerts, triggers, or anomalies within the environment
during the engagement.
● Steps through the Blue actions in response to Red Team activity.
(This occurs simultaneously with the Red Team walkthrough.)
● Identifies how Red Team activity could have been detected,
prevented, or leveraged (Red Team input is usually key during this
discussion period).
● Provides feedback on the Red Team actions and recommendations.
● Uses tech-on-tech information to perform a post-engagement
analysis prior to the receipt of the official report.
Responding to negative organizational feedback during briefings
Inevitably, a Red Team will be challenged in their observations. A Red Team must be prepared to
respond to negative questions or comments, such as "We gave you access," "A bad guy would never
do that," or "How is that fair?". These comments are all too common and typically come from
organizations that are immature or uninformed about threats and security.
In order to respond appropriately, a Red Team must remain professional and conduct a high-quality
engagement. Red Teaming can generate stress and cause people to become defensive, both personally
and professionally. A Red Team should not boast or belittle the target's staff during a briefing or in a
report. A Red Team that tells the story of an engagement with simple facts can convey a strong
message without blame. Even if an organization did poorly, the facts would be more than enough to
get the point across. Remember, a Red Team's job is not to demonstrate how elite their hacking skills
are but to exercise a threat scenario that allows an organization to learn and improve their security. A
Red Team's story should convey the significant failures that led to a successful compromise.
A good rule of practice is non-attribution, or not attributing failures to specific people. Many
organizations blame security failures on certain individuals instead of recognizing organizational gaps
or failures. Placing blame on individuals seems to present an easy fix but rarely improves security.
Blaming Bob in accounting for clicking a phishing email is not why all intellectual property was
stolen.
On occasion, a Red Team may be presented with an unusually hostile person or possibly a hostile
technical team. In these scenarios, diffusing hostilities becomes just as important as the information
being conveyed; otherwise, the information may not be ingested as intended. The Red Team can use
three simple questions to begin diffusing the situation.
Questions to Defuse Hostile Response to Red Team Activity
1. Did the action operate within scope?
A well-planned engagement will have a well-defined scope. If all activities operate within
scope, all activities are acceptable.
In cases where a Red Team is provided with information, state this upfront when describing
the scenario.
List the assumptions to help ensure that the audience agrees with the assumptions or, at a
minimum, understand why specific actions were taken.
2. Did the action operate within the Rules of Engagement?
The Rules of Engagement dictate everything about how an action will or will not be
performed. The ROE must be followed. Violating rules is a quick way for a Red Team to
lose the trust and confidence of the organization. As with operating in scope, if the Rules of
Engagement were not violated, the action is acceptable.
3. Has the action been performed in a real-world attack?
If an action or technique has been used in the real world, it has validity. Organizations can
quickly become skeptical of theoretical attacks. Being able to tie an action to a known
technique or threat will help validate its authenticity.
Key Chapter Takeaways
The culmination phase is a major milestone in a Red Team engagement. All activity is complete, and
data or logs are finalized. If data validation is not complete, there is a serious risk to developing a
quality report. This is the last opportunity to ensure logs are complete, screenshots exist, and the
engagement story can be told.
Culmination is the first official time the target organization receives information on the outcome of an
engagement. The success or failure of an engagement often lies in the quality of the briefing performed
in this phase.
If performed correctly, the Red Team lead should have everything needed to begin developing a
quality, professional report.
Homework
● Develop an engagement system modification tracking document
● Develop a sanitization and cleanup tracking document
● Ensure operator log verification is included in the engagement methodology or workflow
● Develop an agenda template for executive outbriefs
● Develop an agenda template for tech-on-tech outbriefs
Engagement Reporting
Reports are the final product and the only evidence of an engagement. The reporting phase is a
critical aspect of a Red Team engagement. Reports should enable the organization to replicate the
actions and results of the Red Team and are the last form of evidence that can be analyzed and used to
provide a base for improving security. They must be included as a final delivery for an engagement.
Some teams (especially internal teams) often do not produce formal reports. Some only provide a list
of findings and label as a report. While this is acceptable (assuming some detailed deliverable is
produced), it is strongly encouraged to develop a formal reporting process using a standard template.
This process ensures consistency and completeness in delivering a final product following an
engagement.
Rules Regarding Data Collection and Reporting
1. If an action is not logged, it did not happen.
2. If there is no report, there was no engagement
Reports not only document the activity that occurred during a specific engagement but also provide an
excellent reference that can be used as a reliable roadmap to plan and design other or future
engagements. Many engagements share similar approaches and goals. As the number of reports
grows, they can be analyzed together to understand common patterns and risks shared by various
environments. These can be used to understand how threats succeed or fail when facing varying
levels of defense.
Attack Flow Diagrams
Everyone has heard that an image is worth a thousand words. The same applies when generating
reports. This is especially true in those containing complex threads and activities. Red Teaming is
about understanding a threat's impact of actions against a target. Although this is documented in logs
and eventually written as observations, a visual diagram is extremely valuable and one of the most
effective ways to describe and highlight key activities and observations.
The diagram above is a sanitized example of a real Red Team engagement leveraging a simple
assumed breach model. This engagement was used to train a new red team using a small, simplified
engagement. The engagement goals included the following:
● Train and expose a new red team to the red team processes
● Measure the ability a threat has to move laterally
● Measure the defender’s ability to detect C2 traffic and binaries
● Measure the ability to perform and subsequently detect critical data exfiltration
This Red Team engagement was designed as C2 training for a new Red Team and to educate a Blue
Team on threat techniques. The Red Team designed and staged Command and Control with specific
IOCs and threat objectives using a threat profile to document the threat design. The diagram highlights
the actions, successes, and failures of the Red Team and was created using the commercial mind
mapping software XMind (http://www.xmind.net/) but could have easily been created in a number of
other diagraming tools.
A properly designed diagram can be used solely to present a Red Team engagement. The power of an
image is truly immense. Diagrams are not required but are highly encouraged.
Consider This
The authors of this book often only use diagrams to drive
executive or technical briefings verses using a long text
driven document or PowerPoint presentation. Graphical
presentations are a great way to convey the complex
actions of a Red Team engagement.
Observations vs. Findings
The Red Team engagement report can be quite different than reports generated in penetration tests or
vulnerability assessments. Engagement goals and associated impacts are the foundational data points
that directly feed a Red Team report. As previously discussed, Red Team engagements are highly
scenario-focused. This leads to a story-driven report that contains the Red Team's story (or flow) and
their ability to execute or meet their goals.
Penetration testing or vulnerability assessment reports focus on findings. For example, a penetration
test may discover a weak password policy that leaves an organization susceptible to a brute force
attack, or missing patches allowed the exploitation of end-user workstations. These findings are
typically mapped to some security control or policy. Perhaps these findings would lead to the
recommendations of modifying the password policy to require longer passwords, implementing two-
factor authentication, and ensuring that the patching policy is being followed. These are important
findings to discover, but these fall more in the line of security housekeeping and attack surface
reduction.
Red Team engagements have much different goals than other security tests. The methods to describe
goals in a Red Team report are better represented as observations rather than discrete findings. For
example, an out-of-date system may have flaws that allow an operator to compromise a workstation.
This provides command and control and is used to perform situational awareness on the target's
organization's assets. An operator continues to explore and move through the target's network and
eventually steals proprietary data as a planned goal. The technical flaw is important and should be
documented but is only one of a series of steps. This series of steps can be used to detail the
observation a threat has regarding freedom of movement.
Example Observation
The red team was able to move freely through the target’s
network with little to no resistance. The initial
compromised host provided the initial stepping stone but
was soon abandoned once freedom of movement was
established. The red team did not observe any preventive
or detective controls that would indicate the organization
was aware of the threat activity. This freedom of
movement was key in providing the ability to exfiltrate
sensitive data from the target.
The Red Team is driven by goals intended to stimulate or measure not only technical flaws but
security operations as a whole. This includes people, processes, and technology. A Red Team report
uses a story-based format where observations rather than of findings are listed.
Risk Rating and Metrics
Most security tests include a risk rating with a finding. A common scale uses risk matrix diagram
composed of Impact vs. Likelihood in High, Medium or Low assignments. It is most often represented
in a 3x3 square diagram. While this may give a general idea of risk, it is often too arbitrary and
subjective. The values chosen are at the discretion of the report writers. Unless the target organization
is included in the rating decision, these ratings include only the security tester perspective. These
types of ratings work well for vulnerability assessments, where individual vulnerabilities are the
primary goal and can be assigned associated CVE scores. It can also work for penetration tests when
measuring and validating levels of exploitability is the primary goal.
These types of ratings can be used in Red Team reports; however, they are not appropriate for the
observation methodology. Let's consider this example. If a Red Team had a goal of stealing
proprietary organizational data, the observation write-up would describe how and where the data
was taken and the volume of data acquired. This is difficult to summarize into a single dot on an
impact vs. likelihood risk matrix. Consider another option, using the metrics of Red Team goals. Red
Team goals were discussed earlier in the book. These goals have associated metrics in the form of
questions. Instead of rating risk using a subjective scale, a narrative that answers the questions can
describe the risk. This does not assign a High or Low value but provides an organization with
information that can be used to determine the level of action needed.
If an Impact vs. Likelihood risk matrix diagram is required, include both the Red Team goal narrative
and the vulnerability risk matrix. Remember, Red Teaming focuses on goals and not vulnerabilities.
Vulnerabilities will be discovered during a red team engagement and can be documented using the
traditional risk matrix grid in a secondary findings section of the report.
Risk Matrices Comparison
Risk matrices are a great way to add a visual element to a report to provide additional context and
understanding. This matrix is commonly used to estimate the degree of severity and the probability or
level of some impact to a specific discrete vulnerability or finding
3 × 3 risk matrix example
The 3x3 risk matrix is arguably the most common in security reports. It is relatively simple and
provides nine possible levels to assign risk. This type of rating is highly subjective. It is challenging
for a security tester (vulnerability, penetration, or red team) to accurately rate impact or probability in
terms of risk to operations. This leads to ratings focused at the technical level. While this is useful, it
doesn't always provide leadership the view needed to make an informed decision on applying
mitigations using their limited resources.
Likelihood: The probability that an event will occur:
● Low – Not likely to occur
● Medium – May occur
● High – Probably will occur
Impact: The expected result of an event (degree of injury, property damage, or other mission-
impairing factors) measured as:
● Low – Limited impact on operations
● Medium – Noticeable impact on operations
● High – Significant impact on operations
5 × 5 risk matrix example
The 5x5 risk matrix is an extended version of the 3x3. The usage is the same but provides a bit more
granularity. This can help fine-tune the rating but suffers from similar limitations. It does offer a
method to view risk in terms of operations instead of discrete vulnerabilities. The version presented
has been adopted and modified from the U.S. Army[21] and NIST[22] to focus on operation impact
instead of mission impact.
Probability: The likeliness that an event will occur:
● Frequent – Occurs often
● Likely – Occurs several times in x period
● Occasional – Occurs sporadically
● Seldom – Unlikely but could occur
● Unlikely – Probably will not occur
Severity: The expected result of an event (degree of injury, property damage, or other mission-
impairing factors) measure as:
● Catastrophic – Direct impact, usually of long duration if not permanent
● Critical – Significant impact: stops or halts operation
● Moderate – Noticeable loss: reduces/slows operation/production
● Marginal – Limited loss: noticed but does not halt operation
● Negligible – Some loss: unnoticed if not monitored closely
The key in these matrices construct is vulnerability. As stated several times throughout this book, Red
Teaming is not vulnerability focused. Given that thought process, a Red Team’s engagement should be
constructed as a narrative of threat actions. Below are a few questions that can help determine the
impact and shape Red Team’s goals. Refer to the Red Team Goals section of this book for more
details. These questions should directly reflect the goals created during engagement planning.