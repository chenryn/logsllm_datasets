- 启动新版本pod 删除旧版本pod
![屏幕截图 2020-09-14 135712](/assets/屏幕截图%202020-09-14%20135712.png)
### 使用rc进行滚动升级
书上通过rolling-update的方法已经过时
### 使用 Deployment 声明式升级
- 创建
```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kubia
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v1
        name: nodejs
```
```sh
kubectl create -f kubia-dep-v1.yaml --record # 加上该参数会记录历史版本号
```
- 更新版本
```sh
kubectl set image deployment kubia nodejs=luksa/kubia:v2
```
- 回滚
```sh
kubectl rollout undo deployment kubia
```
使用 - -to-revision=xxx 回滚到特定版本
- 升级速率控制
```yml
rollingUpdate :
  maxSurge: 1 # 最多允许超过的副本数
  maxunavailable: 0 # 最多允许多少百分比pod不可用
```
- 使用rollout pause 暂停滚动升级 部分软件版本就不一样 金丝雀发布
- minReadySeconds属性指定新创建的pod至少要成功运行多久之后 ， 才能 将其视为可用
如果 一 个新的pod 运行出错， 并且在minReadySeconds时间内它的就绪探针出现了失败， 那么新版本的滚动升级将被阻止
- 使用kubectl apply升级Deployment
## StatefulSet
如何复制有状态的pod？
Statefulset 保证了pod在重新调度后保留它们的标识和状态
每个pod都有专属于它的持久卷
K8S保证不会有两个相同标识和持久卷的pod同时运行
### 使用
- 创建持久卷
- 创建控制 Service
```yml
apiVersion: v1
kind: Service
metadata:
  name: kubia
spec:
  clusterIP: None
  selector:
    app: kubia
  ports:
  - name: http
    port: 80
```
- 创建StatefulSet
```yml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kubia
spec:
  serviceName: kubia
  replicas: 2
  selector:
    matchLabels:
      app: kubia # has to match .spec.template.metadata.labels
  template:
    metadata:
      labels:
        app: kubia
    spec:
      containers:
      - name: kubia
        image: luksa/kubia-pet
        ports:
        - name: http
          containerPort: 8080
        volumeMounts:
        - name: data
          mountPath: /var/data
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      resources:
        requests:
          storage: 1Mi
      accessModes:
      - ReadWriteOnce
```
- 使用一个 Service 来访问 Pod
```yml
apiVersion: v1
kind: Service
metadata:
  name: kubia-public
spec:
  selector:
    app: kubia
  ports:
  -  port: 80
     targetPort: 8080
```
### 发现伙伴节点
- 容器内部通过DNS SRV 记录
## 安全
### pod 使用宿主节点的Linux命名空间
- 使用宿主节点的网络命名空间
```yaml
spec:
  hostNetwork: true
```
- 使用宿主节点的端口而不使用宿主节点的网络命名空间
![屏幕截图 2020-09-16 142921](/assets/屏幕截图%202020-09-16%20142921.png)
如果使用hostport 一个节点只能有一个相同的pod
- 使用宿主的PID与IPC空间
```yml
spec:
  hostPID: true
  hostIPC: true
```
开启后 相同节点的pod的进程之间就是可见的 可通信的
### 安全上下文
```yml
spec:
  securityContext:
    # ... pod 级别的
  containers:
    securityContext:
      runAsUser: 405 # 以指定用户运行
      runAsNonRoot: true # 禁止以root运行
      privileged: true # 在特权模式下允许
      capabilities:
        add:
        - SYS_TIME # 开放硬件时间修改权限
        drop:
        - CHOWN # 禁用文件所有者修改权限
      readOnlyRootFilesystem: true # 禁止在根目录写文件
```
### pod 网络隔离
- 网络策略
```yml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: postgres-netpolicy
spec:
  podSelector:
    matchLabels:
      app: database # 对该标签的pod生效
  ingress: # 只允许来自匹配下面标签的pod请求
  - from:
    - podSelector:
        matchLabels:
          app: webserver
    ports:
    - port: 5432
```
## 计算资源管理
### 申请资源
```yaml
spec:
  containers:
  - image: busybox
    command: ["dd", "if=/dev/zero", "of=/dev/null"]
    name: main
    resources:
     requests:
       cpu: 200m # 申请200毫核 也就说20%CPU
       memory: 10Mi # 申请10M内存
```
添加了requests对调度的影响：
通过设置资源requests我们指定了pod对资源需求的最小值。
调度器不关心资源的实际使用了 而是关心各pod所定义的requests资源量 
![屏幕截图 2020-09-17 134722](/assets/屏幕截图%202020-09-17%20134722.png)
### 限制资源
```yml
resources:
  limits:
    cpu: 1 # 允许最大使用1核
    memory: 20Mi # 内存允许最大 20M
```
超过limits的情况：
- cpu：进程分配到的CPU不会超过指定的
- 内存：如果内存超过limit 则容器会被杀掉
### QoS 等级
通过定义优先级决定资源不足时杀谁
![屏幕截图 2020-09-17 142031](/assets/屏幕截图%202020-09-17%20142031.png)
- BestEffort 优先级最低
  - 没有设置requess和limits都属于这个级别
- Guaranteed 优先级最高
  - cpu和内存都要设置requests 和 limits
  - 所有容器都要设置资源量
  - requests 与 limits必须相等
- Burstable 其他的pod都属于这个等级
### 限制命名空间中的pod
- LimitRange插件
- ResourceQuota
### 监控 pod
- Heapster
![屏幕截图 2020-09-17 143016](/assets/屏幕截图%202020-09-17%20143016.png)
## 自动伸缩与集群
- 基于CPU使用率的自动伸缩
```sh
kubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5
```
- 纵向扩容
自动修改CPU与内存大小
### 集群节点扩容
新节点启动后，其上运行的Kubelet会联系API服务器，创建 一 个Node资源以注册该节点
当一 个节点被选中下线，它首先会被标记为不可调度， 随后运行其上的pod 将被疏散至其他节点
## 高级调度
### 污点和容忍度
限制哪些pod可以被调度到某 一 个节点
```sh
kubectl describe node minikube | grep Taints # 查看节点污点
```
![屏幕截图 2020-09-19 134744](/assets/屏幕截图%202020-09-19%20134744.png)
- NoSchedule 表示如果 pod 没有容忍这些污点， pod 则不能被调度到包含这些污点的节点上
- PreferNoSchedule 是 NoSchedule 的 一 个宽松的版本， 表示尽量阻止pod 被调度到这个节点上， 但是如果没有其他节点可以调度， pod 依然会被调度到这个节点上
- NoExecute会影响正在节点上运行着的 pod 。 如果在 一 个节点上添加了 NoExecute 污点， 那些在该节点上运行着的pod, 如果没有容忍这个 NoExecute 污点， 将会从这个节点去除
- 添加污点
```sh
kubectl taint node minikube node-type=production:NoSchedule
```
- pod添加容忍度
```yml
spec:
  replicas: 5
  template:
    spec:
      ...
      tolerations:
      - key: node-type
        operator: Equal
        value: production
        effect: NoSchedule
```
### 节点亲缘性
这种机制允许你通知 Kubemetes将 pod 只调度到某个几点子集上面
```yml
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: gpu
            operator: In
            values:
            - "true"
```
![屏幕截图 2020-09-19 142905](/assets/屏幕截图%202020-09-19%20142905.png)
## 最佳实践
![屏幕截图 2020-09-19 143453](/assets/屏幕截图%202020-09-19%20143453.png)
### pod 的生命周期
1. 应用必须意识到会被杀死或者重新调度
    - ip与主机名会发生变化
    - 使用卷解决数据写入问题
2. 不断重启的pod不会被重新调度
3. 固定顺序启动pod
    - 使用init容器
    - 应用要处理好其他依赖没有准备好的情况
4. 生命周期钩子
    - postStart
    - preStop
5. pod的关闭
![屏幕截图 2020-09-19 145717](/assets/屏幕截图%202020-09-19%20145717.png)
### 客户端请求处理
1. pod启动时避免客户端连接断开
    - 使用一个就绪探针来探测pod是否准备好接受请求了
2. pod关闭时避免请求断开
    - 停止接受新连接
    - 等待所有请求完成
    - 关闭应用
### 让应用方便运行与管理
1. 可管理的容器镜像
    - 镜像太大难以传输 镜像太小会缺失很多工具
2. 合理给镜像打标签
    - 不要使用latest 使用具体版本号
3. 使用多维度的标签
4. 使用注解描述额外信息
5. 使用/dev/termination-log 写入失败信息
6. 日志
    - 将日志打印到标准输出方便查看
    - 集中式日志系统
## 应用扩展
### CRD对象
- 创建
```yml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: websites.extensions.example.com
spec:
  scope: Namespaced
  group: extensions.example.com
  version: v1
  names:
    kind: Website
    singular: website
    plural: websites
```
- 创建CRD实例
```yml
apiVersion: extensions.example.com/v1
kind: Website
metadata:
  name: kubia
spec:
 gitRepo: https://github.com/luksa/kubia-website-example.git
```
### 服务目录
服务目录就是列出所有服务的目录。 用户可以浏览目录并自行设置目录中列出的服务实例