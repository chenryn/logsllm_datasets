I ∈ Rw×w and a kernel K ∈ Rk×k, we compute the convolved image Conv(I, K) ∈ RdK×dK by
Conv(I, K)i(cid:48),j(cid:48) =
Ki,j · Is·i(cid:48)+i,s·j(cid:48)+j
(cid:88)
0≤i,j<k
for 0 ≤ i(cid:48), j(cid:48) < dK = (cid:100)(w − k)/s(cid:101) + 1. Here (cid:100)·(cid:101) returns the least integer greater than or equal to the input.
It can be extended to multiple kernels K = {K (k)}0≤k<h as
Conv(I,K) = (Conv(I, K (0)),··· , Conv(I, K (h−1))) ∈ RdK×dK×h.
On the other hand, FC layer connects nI nodes to nO nodes, or equivalently, it can be speciﬁed by the
matrix-vector multiplication of an nO × nI matrix. Note that the output of convolution layer has a form
of tensor so it should be ﬂatten before FC layer. Throughout this paper, we concatenate the rows of the
tensor one by one and output a column vector, denoted by FL(·).
6.2 Homomorphic Evaluation of CNN
We present an eﬃcient strategy to evaluate CNN prediction model on the MNIST dataset. Each image is
a 28 × 28 pixel array, where the value of each pixel represents a level of gray. After an arbitrary number
of hidden layers, each image is labeled with 10 possible digits. The training set has 60,000 images and
the test set has 10,000 images. We assume that a neural network is trained with the plaintext dataset
in the clear. We adapted a similar network topology to CryptoNets: one convolution layer and two FC
layers with square activation function. Table 6 describes our neural networks to the MNIST dataset and
summarizes the hyperparameters.
The ﬁnal step of neural networks is usually to apply the softmax activation function for a purpose of
probabilistic classiﬁcation. We note that it is enough to obtain an index of maximum values of outputs
in a prediction phase.
In the following, we explain how to securely test encrypted model on encrypted multiple data. In
our implementation, we take N = 213 as a cyclotomic ring dimension so each plaintext vector is allowed
to have dimension less than 212 and one can predict 64 images simultaneously in a SIMD manner. We
describe the parameter selection in more detail below.
15
Table 6: Description of our CNN on the MNIST dataset
Layer
Convolution
1st square
FC-1
2nd square
FC-2
Description
Input image 28 × 28, kernel size 7 × 7, stride size of 3, number of output channels 4
Squaring 256 input values
Fully connecting with 256 inputs and 64 outputs: R64×256 × R256×1 → R64×1
Squaring 64 input values
Fully connecting with 64 inputs and 10 outputs: R10×64 × R64×1 → R10×1
6.2.1 Encryption of Images
At the encryption phase, the data owner encrypts the data using the public key of an HE scheme. Suppose
that the data owner has a two-dimensional image I ∈ R28×28. For 0 ≤ i(cid:48), j(cid:48) < dK = 8, let us deﬁne an
extracted image feature I[i(cid:48), j(cid:48)] formed by taking the elements I3·i(cid:48)+i,3·j(cid:48)+j for 0 ≤ i, j < 7. That is, a
single image can be represented as the 64 image features of size 7 × 7. It can be extended to multiple
images I = {I (k)}0≤k<64. For each 0 ≤ i, j < 7, the dataset is encoded into a matrix consisting of the
(i, j)-th components of 64 features over 64 images and it is encrypted as follows:
I (0)[0, 0]i,j I (1)[0, 0]i,j ··· I (63)[0, 0]i,j
I (0)[0, 1]i,j I (1)[0, 1]i,j ··· I (63)[0, 1]i,j
I (0)[7, 7]i,j I (1)[7, 7]i,j ··· I (63)[7, 7]i,j
 .
ct.Ii,j = Enc
...
...
. . .
...
The resulting ciphertexts {ct.Ii,j}0≤i,j<7 are sent to the public cloud and stored in their encrypted form.
6.2.2 Encryption of Trained Model
The model provider encrypts the trained prediction model values such as multiple convolution kernels’
values K = {K (k)}0≤k<4 and weights (matrices) of FC layers. The provider begins with a procedure
for encrypting each of the convolution kernels separately. For 0 ≤ i, j < 7 and 0 ≤ k < 4, the (i, j)-th
component of the kernel matrix K (k) is copied into plaintext slots and the model provider encrypts the
plaintext vector into a ciphertext, denoted by ct.K (k)
i,j .
Next, the ﬁrst FC layer is speciﬁed by a 64 × 256 matrix and it can be divided into four square
sub-matrices of size 64 × 64. For 0 ≤ k < 4, we write Wk to denote the k-th sub-matrix. Each matrix
is encrypted into a single ciphertext using the matrix encoding method in Section 3.2, say the output
ciphertext ct.Wk.
For the second FC layer, it can be expressed by a 10 × 64 matrix. The model provider pads zeros in
the bottom to obtain a matrix V of size 16 × 64 and then generates a 64 × 64 matrix ¯V containing four
copies of V vertically, say the output ciphertext ct.V . Finally, the model provider transmits three distinct
types of ciphertexts to the cloud: ct.K (k)
i,j , ct.Wk, and ct.V .
6.2.3 Homomorphic Evaluation of Neural Networks
At the prediction phase, the public cloud takes ciphertexts of the images from the data owner and the
neural network prediction model from the model provider. Since the data owner uses a SIMD technique to
batch 64 diﬀerent images, the ﬁrst FC layer is speciﬁed as a matrix multiplication: R64×256 × R256×64 →
R64×64. Similarly, the second FC layer is represented as a matrix multiplication: R10×64 × R64×64 →
R10×64.
i,j for 0 ≤ i, j <
Homomorphic convolution layer. The public cloud takes the ciphertexts ct.Ii,j and ct.K (k)
7 and 0 ≤ k < 4. We apply pure SIMD operations to eﬃciently compute dot-products between the
16
kernel matrices and the extracted image features. For each 0 ≤ k < 4, the cloud performs the following
computation on ciphertexts:
ct.Ck ← (cid:88)
0≤i,j<7
Mult(ct.Ii,j, ct.K (k)
i,j ).
By the deﬁnition of the convolution, the resulting ciphertext ctk represents a square matrix Ck of order
64 such that
...
...
Ck =
FL(Conv(I (0), K (k))) ··· FL(Conv(I (63), K (k)))
...
...
 .
That is, it is an encryption of the matrix Ck having the i-th column as the ﬂatten convolved result
between the the i-th image I (i) and the k-th kernel K (k) .
The ﬁrst square layer. This step applies the square activation function to all the encrypted output images
of the convolution in a SIMD manner. That is, for each 0 ≤ k < 4, the cloud computes as follows:
ct.S(1)
k ← SQR(ct.Ck)
where SQR(·) denotes the squaring operation of an HE scheme. Note that ct.S(1)
matrix Ck (cid:12) Ck.
The FC-1 layer. This procedure requires a matrix multiplication between a 64 × 256 weight matrix
W = (W0|W1|W2|W3) and a 256 × 64 input matrix C = (C0 (cid:12) C0; C1 (cid:12) C1; C2 (cid:12) C2; C3 (cid:12) C3). The
matrix product W · C is formed by combining the blocks in the same way, that is,
is an encryption of the
k
Thus the cloud performs the following computation:
(cid:88)
0≤k<4
W · C =
(Wk · (Ck (cid:12) Ck)).
ct.F ← (cid:88)
0≤k<4
HE-MatMult(ct.Wk, ct.S(1)
k ).
The second square layer. This step applies the square activation function to all the output nodes of the
ﬁrst FC layer:
ct.S(2) ← SQR(ct.F ).
The FC-2 layer. This step performs the rectangular multiplication algorithm between the weight cipher-
text ct.V and the output ciphertext ct.S(2) of the second square layer:
ct.out ← HE-RMatMult(ct.V, ct.S(2)).
6.2.4 The Threat Model
Suppose that one can ensure the IND-CPA security of an underlying HE scheme, which means that
ciphertexts of any two messages are computationally indistinguishable. Since all the computations on the
public cloud are performed over encryption, the cloud learns nothing from the encrypted data so we can
ensure the conﬁdentiality of the data against such a semi-honest server.
6.3 Performance Evaluation of E2DM
We evaluated our E2DM framework to classify encrypted handwritten images of the MNIST dataset. We
used the library keras [14] with Tensorﬂow [1] to train the CNN model from 60,000 images of the dataset
by applying the ADADELTA optimization algorithm [50].
17
6.3.1 Optimization Techniques
Suppose that we are given an encryption ct.A of a d × d matrix A. Recall from Section 3 that we apply
homomorphic liner transformations to generate the encryption ct.A((cid:96)) of a matrix φ(cid:96)◦ σ(A) for 0 ≤ (cid:96) < d.
Sometimes one can pre-compute φ(cid:96) ◦ σ(A) in the clear and generate the corresponding ciphertexts for
free. Thus this approach gives us a space/time trade-oﬀ: although it requires more space for d ciphertexts
d),
rather than a single ciphertext, it reduces the overhead of rotation operations from (3d+5
achieving a better performance. This method has another advantage, in that an input ciphertext modulus
is reduced by (log p + log pc) bits after matrix multiplication while (log p + 2 log pc) in the original method.
This is because the encryptions of φk ◦ σ(A) are given as fresh ciphertexts and it only requires additional
depths to generate the encryptions of ψk ◦ τ (B).
We can apply this idea to the FC layers. For each 0 ≤ k < 4 and 0 ≤ (cid:96) < 64, the model provider
representing the matrix φ(cid:96) ◦ σ(Wk) of the ﬁrst FC layer. For the second
generates a ciphertext ct.W ((cid:96))
FC layer, the provider generates an encryption ct.V ((cid:96)) of the matrix φ(cid:96) ◦ σ( ¯V ) for 0 ≤ (cid:96) < 16.
d) to (d+2
k
√
√
6.3.2 Parameters
The convolution layer and the square activation layers have a depth of one homomorphic multiplication.
As discussed before, the FC layers have depth of one homomorphic multiplication and one constant
multiplication by applying the pre-computation optimization technique. Therefore, the lower bound on
the bit length of a fresh ciphertext modulus is 5 log p + 2 log pc + log q0. In our implementation, we
assume that all the inputs had log p = 30 bits of precision and we set log pc = 30 for the bit precision
of constant values. We set the bit lengths of the output ciphertext modulus and the special modulus
as log q0 = log ps = log p + 10. We could actually obtain the bit length of the largest fresh ciphertext
modulus about log q ≈ 250 and took the ring dimension N = 213 to ensure at least 80 bits of security.
This security was chosen to be consistent with other performance number reported from CryptoNets.
Note that a fresh ciphertext has 0.488 MB under this parameter setting.
6.3.3 Ciphertext Sizes
Each image is a 28 × 28 pixel array, where each pixel is in the range from 0 to 255. The data owner ﬁrst
chooses 64 images in the MNIST dataset, normalizes the data by dividing by the maximum value 255,
and generates the ciphertexts {ct.Ii,j}0≤i,j<7. The total size of ciphertexts is 0.488× 49 ≈ 23.926 MB and
a single ciphertext contains information of 64 images, and therefore the total ciphertext size per image
is 23.926/64 ≈ 0.374 MB or 383 KB. Since each image has approximately 28 × 28 × 30 bits, it is 133
times smaller than the encrypted one. Meanwhile, the model provider generates three distinct types of
ciphertexts:
k
for 0 ≤ i, j < 7 and 0 ≤ k < 4;
for 0 ≤ k < 4 and 0 ≤ (cid:96) < 64;
– ct.K (k)
i,j
– ct.W ((cid:96))
– ct.V ((cid:96)) for 0 ≤ (cid:96) < 16.
The total size of ciphertexts is 0.488 × 468 ≈ 228.516 MB. After the homomorphic evaluation of E2DM,
the cloud sends only a single ciphertext to an authority who is the legitimate owner of the secret key of
the HE scheme. The ciphertext size is around 0.078 MB and the size per image is 0.078/64 MB ≈ 1.25
KB. Table 7 summarizes the numbers in the second and third columns.
Table 7: Total ciphertext sizes of E2DM
Data owner → Cloud
Model provider → Cloud
Cloud → Authority
Ciphertext size Size per instance
23.926 MB
228.516 MB
0.078 MB
18
383 KB
-
1.25 KB
6.3.4
Implementation Details
The key generation takes about 0.87 seconds for the parameters setting in Section 6.3.2. The data owner
takes about 121 milliseconds to encrypt 64 diﬀerent number of images. Meanwhile, the model provider
takes about 1.06 seconds to generate the encrypted prediction models. This procedure takes more time
than the naive method but it is an one-time process before data outsourcing and so it is a negligible
overhead.
In Table 8, we report timing results for the evaluation of E2DM. The third column gives timings
for each step and the fourth column gives the relative time per image (if applicable). The dominant
cost of evaluating the framework is that of performing the ﬁrst FC layer. This step requires four matrix
multiplication operations over encrypted 64 × 64 matrices so it expects to take about 0.6 × 4 ≈ 2.4
seconds from the result of Table 4. We further take advantage of the pre-computation method described
in Section 6.3.1, and thereby it only took about 1.36 seconds to evaluate the layer (1.8 times faster).
Similarly, we could apply this approach to the second FC layer, which leads to 0.09 seconds for the
evaluation. In total, it took about 1.69 seconds to classify encrypted images from the encrypted training
model, yielding an amortized rate of 26 milliseconds per image.
Table 8: Experimental results of E2DM for MNIST
Stage
Latency
Amortized time
per image
Data owner
Model provider
Encoding + Encryption
Encoding + Encryption
Cloud
Convolution
1st square
FC-1
2nd square
FC-2
Total evaluation
Authority
Decoding +Decryption
120.91 ms
1059.14 ms
219.34 ms
16.99 ms
1355.19 ms
6.41 ms
90.41 ms
1688.34 ms
0.72 ms