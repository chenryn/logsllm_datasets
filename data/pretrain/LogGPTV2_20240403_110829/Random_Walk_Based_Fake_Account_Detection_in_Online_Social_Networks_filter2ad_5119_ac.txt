SybilGuard [6]
SybilLimit [7]
SybilInfer [8]
SybilRank [10]
CIA [11]
SybilWalk
SybilWalk-Var
#Accepted Sybils
√
n log n)
O(g
O(g log n)
–
O(g log n)
–
O( g log n
d(s) )
O( g log n
d(s) )
every labeled benign node to be 0 and the badness score of
every labeled Sybil node to be 1, and we ﬁx the badness scores
of these labeled nodes. Moreover, for each unlabeled user, we
initialize its badness score to be 0.5. In each iteration, we
apply Equation 2 to update the badness score of each unlabeled
user. The process is repeated until the change of the badness
scores of all unlabeled users in two consecutive iterations is
−3) or the number
smaller than a given small threshold (i.e., 10
of iterations has reached a predeﬁned maximum number of
iterations. We denote the adapted version of SybilWalk as
SybilWalk-Var. We note that SybilWalk-Var can be viewed as
a semi-supervised learning method, which is known as label
propagation [39] in the machine learning community.
In Section V, we will demonstrate that SybilWalk-Var has
the same theoretical guarantees with SybilWalk. However, as
we will show in our empirical evaluations in Section VI,
SybilWalk is more accurate than SybilWalk-Var when the
social network has a weaker homophily (i.e., the number of
attack edges is larger). Moreover, SybilWalk is robust to a
larger amount of label noises in the training dataset
than
SybilWalk-Var.
V. THEORETICAL EVALUATION
We ﬁrst analyze the ranking accuracy of SybilWalk and
SybilWalk-Var. Then, we analyze their computational com-
plexity.
A. Ranking Accuracy
Our theoretical guarantee of SybilWalk and SybilWalk-Var
is summarized in the following theorem.
Theorem 1: Suppose the benign region is fast mixing and
the attacker randomly establishes g attack edges. Then, the
total number of Sybils whose badness scores are lower than
certain benign nodes in SybilWalk (or SybilWalk-Var) is
bounded by O( g log n
d(s) ), where n is the number of users in
the social network and d(s) is the average node degree in the
Sybil region.
Proof: See Appendix A.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:48 UTC from IEEE Xplore.  Restrictions apply. 
Our results imply that when Sybils are more densely
connected among themselves (i.e., the average degree d(s) is
larger), it is easier for SybilWalk to detect them. We note that,
when considering edge weights, the average node degree is
the average weighted node degree. Table I summarizes the
theoretical guarantees of various random walk based methods.
For SybilRank, CIA, SybilWalk, and SybilWalk-Var, the metric
#accepted Sybils means the number of Sybils that are ranked
lower than certain benign nodes. For the rest of methods,
#accepted Sybils means the number of Sybils are classiﬁed
as benign. As we can see, our SybilWalk achieves the tightest
bound on the number of accepted Sybils.
B. Computational Complexity
SybilWalk: Each iteration of SybilWalk traverses each edge
in the label-augmented social network. Therefore, one iteration
of SybilWalk has a time complexity of O(mu+ml), where mu
is the number of edges between users and ml is the number
of edges between users and the label nodes. In other words,
ml is the number of labeled benign nodes and labeled Sybil
nodes in the training dataset, since each labeled node has a
label edge. Therefore, the total complexity of SybilWalk is
O(t(mu + ml)), where t is the number of iterations.
SybilWalk-Var: Each iteration of SybilWalk-Var essentially
traverses each edge in the original social network. Therefore,
one iteration of SybilWalk has a time complexity of O(mu),
and the total time complexity is O(tmu), where t is the number
of iterations.
Both SybilRank and CIA have a time complexity of
O(tmu), where t is the number of
iterations. Although
SybilWalk theoretically has a higher time complexity than
SybilRank and CIA, we expect that they are almost the same
in practice. This is because the number of label
efﬁcient
is negligible compared to the number of edges
edges ml
between users in practice. Indeed, our empirical evaluation
results demonstrate that SybilWalk, SybilWalk-Var, CIA, and
SybilRank have almost
identical scalability. Other random
walk based methods including SybilGuard, SybilLimit, and
SybilInfer are known to be inefﬁcient, because their time
complexity is at least O(n2), where n is the number of users
in the social network.
VI. EMPIRICAL EVALUATION
We compare our methods with previous random walk based
methods with respect to: 1) detection accuracy, 2) robustness
to label noise, and 3) scalability.
A. Experimental Setup
Datasets: We compare our methods with previous random
walk based methods using 1) social networks with synthesized
Sybils and 2) a Twitter dataset with real Sybils.
1) Social networks with synthesized Sybils: We use a
real social graph as the benign region while synthesizing
the Sybil region and adding attack edges between the two
regions uniformly at random. There are different ways to
synthesize the Sybil region. For instance, we can use a network
model (e.g., Preferential Attachment model [40]) to generate a
Sybil region. A Sybil region that is synthesized by a network
model might be structurally very different from the benign
region, e.g., although the Preferential Attachment model can
generate graphs that have similar degree distribution with
real social networks, the generated graphs have very small
clustering coefﬁcients, which is very different from real-world
social networks. Such structural difference could bias Sybil
detection results [35]. Moreover, a Sybil region synthesized
by a network model like Preferential Attachment does not
have community structures, making it unrealistic. Therefore,
following recent studies [14, 35], we consider a Sybil attack in
which the Sybil region is a replicate of the benign region. This
way of synthesizing the Sybil region can avoid the structural
difference between the two regions, and both Sybil region and
benign region have complex community structures.
We utilize three social networks, i.e., Facebook (4,039
nodes and 88,234 edges), Enron (33,696 nodes and 180,811
edges), and Epinions (75,877 nodes and 811,478 edges), to rep-
resent different application scenarios. For each social network,
we use it as the benign region; replicate it as a Sybil region; and
then add attack edges uniformly at random. We obtained these
datasets from SNAP (http://snap.stanford.edu/data/index.html).
A node in Facebook dataset represents a user in Facebook, and
two nodes are connected if they are friends. A node in Enron
dataset represents an email address, and an edge between two
nodes indicate at least one email was exchanged between the
two corresponding email addresses. Epinions is a who-trust-
whom online social network of a general consumer review site
Epinions.com. The nodes in Epinions denote members of the
site. And in order to maintain quality, Epinsons encourages
users to specify which other users they trust, and uses the
resulting web of the trust to order the product reviews seem
by each person.
2) Twitter dataset with real Sybils: We obtained a directed
Twitter graph from Kwak et al. [41]. In this graph, a directed
edge (u, v) means that u follows v. We keep an undirected
edge between two nodes if there are directed edge(s) between
them. After processing, the dataset contains 41,652,230 nodes
and 1,202,513,046 edges. To perform evaluation, we need the
ground truth labels of the nodes. We obtained ground truth
labels from Wang et al. [17]. Speciﬁcally, around 205,000
nodes were suspended by Twitter, which are treated as Sybils;
around 36,157,000 nodes are still active, which are treated as
benign nodes; and the remaining nodes were deleted, which
are treated as unlabeled. The average number of attack edges
per Sybil is 100. Therefore, this Twitter network has a very
weak homophily.
Training and testing: Note that both the benign region and
the Sybil region have community structures. To cope with
community structure, for social networks with synthesized
Sybils, we sample 100 nodes from the benign region uniformly
at random and treat them as labeled benign nodes; and we
sample 100 nodes from the Sybil region uniformly at random
and treat them as labeled Sybil nodes. For the Twitter dataset
with real Sybils, we sample 50,000 nodes from the benign
region and 50,000 nodes from the Sybil region. This random
sampling process is highly likely to have labeled nodes in each
community. Once we have labeled nodes in each community,
our methods can detect Sybils even if there are rich commu-
nity structures. The training dataset consists of the randomly
279
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:48 UTC from IEEE Xplore.  Restrictions apply. 
1.0
0.9
0.8
0.7
0.6
0.5
C
U
A
0.4
1000
SybilWalk
SybilWalk-Var
CIA
SybilRank
1.0
0.9
0.8
0.7
0.6
0.5
C
U
A
40000
70000
Number of Attack Edges
(a) Facebook
100000
0.4
1000
SybilWalk
SybilWalk-Var
CIA
SybilRank
40000
70000
Number of Attack Edges
(b) Enron
1.0
0.9
0.8
0.7
0.6
0.5
C
U
A
100000
0.4
1000
SybilWalk
SybilWalk-Var
CIA
SybilRank
40000
70000
Number of Attack Edges
100000
(c) Epinions
Fig. 3: AUCs of compared methods for different number of attack edges.
sampled nodes, and the rest of nodes are treated as testing
dataset. Note that for the Twitter dataset, the unlabeled nodes
are not included in the testing dataset.
Compared methods: We compare the following methods.
•
•
•
•
SybilRank [10]. Given a training dataset, SybilRank
only leverages labeled benign nodes to assign an
initial probability distribution over the nodes of the
social network. Then, SybilRank performs a random
walk with the initial probability distribution. After
a small number of iterations of the random walk,
SybilRank normalizes probability for each node using
its degree and treats the normalized probability as its
benignness scores, which are used to rank test users in
an increasing order. The normalization step is essential
as shown by the authors of SybilRank.
CIA [11]. Given a training dataset, CIA only leverages
labeled Sybil nodes to assign an initial probability
distribution over the nodes of the social network.
Then, CIA performs a random walk with the initial
probability distribution. In each step of the random
walk, CIA restarts the random walk with the ini-
tial probability distribution with a certain probability,
which is conventionally called restart probability. We
set the restart probability to be 0.85 as suggested by
the authors. After the random walk converges to its
stationary probability distribution, the stationary prob-
ability of a node is treated as its badness score. Then,
we can rank the test users decreasingly according to
their badness scores. Note that SybilRank does not
restart the random walk in each step.
SybilWalk-Var. Variant of our SybilWalk. We set all
edge weights to be 1.
SybilWalk. We set weights of all edges in the con-
structed label-augmented social network to be 1. How-
ever, we believe learning edge weights is an interesting
future work.
We do not compare with SybilGuard, SybilLimit, and
SybilInfer because they are not scalable.
B. Detection Accuracy
AUCs on the social networks with synthesized Sybils: Each
compared method produces a ranking list of test nodes, in
which Sybils are supposed to rank higher than benign nodes.
Area Under
the Receiver Operating Characteristic Curve
(AUC) is a standard metric to measure quality of a ranking
method. In our case, AUC for a method is the probability
that the method ranks a test Sybil node, which is sampled
uniformly at random, higher than a test benign node, which is
also sampled uniformly at random.
A higher AUC means a better ranking quality. AUC is 1
if all test Sybil nodes are ranked higher than all test benign
nodes. AUC is 0 if all test benign nodes are ranked higher
than all test Sybil nodes. A method that ranks the test nodes
uniformly at random has an AUC of 0.5.
Fig. 3 shows AUCs of the compared methods as we
increase the number of attack edges from 1,000 to 100,000.
All methods have AUCs close to 1 when the number of attack
edges is less than 1000. Therefore, we do not show those
results in order to better contrast the results for large attack
edges.
We observe that our random walk based methods sub-
stantially outperform previous random walk based methods
when we have a large number of attack edges (i.e., the social
networks have weak homophily). The improvements of our
methods over previous ones are more signiﬁcant as we have
more attack edges. The reason is that our methods incorporate
both labeled benign nodes and labeled Sybil nodes. Moreover,
SybilWalk outperforms SybilWalk-Var, especially when the
social networks have weak homophily. We speculate the reason
is that real-world social networks often have some nodes with a
large number of neighbors [42]; when such nodes are selected
as training dataset, a random walk, which starts from any
node, is more likely to reach such nodes than other labeled
nodes; as a result, SybilWalk-Var’s performance is signiﬁcantly
inﬂuenced by the labeled nodes with large degrees. In contrast,
SybilWalk avoids the inﬂuence of labeled nodes with large
node degrees via augmenting the social network with label
nodes, and deﬁning the badness score as the probability of the
random walk reaching the label nodes.
280
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:48 UTC from IEEE Xplore.  Restrictions apply. 
1.0
0.8
0.6
0.4
0.2
s
l
i
b
y