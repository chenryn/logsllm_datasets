while the sixth column shows the relation between our selected
sample and the ones the CTI report is based on. For instance, the
reports of DeputyDog, Uroburos, and OceanLotus cover different
activities performed by a set of different samples, and our selected
sample is one of them. We have aggregated all those activities in
one query graph. For the other test cases, the sample we have exe-
cuted is different from the ones that the report is based on, which
could be considered as detecting a mutated malware. njRAT and
DustySky explicitly mention their analyzed sample, which are dif-
ferent from the one we have chosen. The Carbanak report mentions
109 samples, from which we have randomly selected one. Finally,
the sample of HawkEye malware is selected from an external source
and is not among the samples mentioned in the report.
 0 0.2 0.4 0.6 0.8 1 1 10 100 1000Percentage of |V(Gq)| (CDF)Number of CandidatesBSD-1BSD-2BSD-3BSD-4 0 0.2 0.4 0.6 0.8 1 1 10 100 1000Percentage of |V(Gq)| (CDF)Number of CandidatesWin-1Win-2 0 0.2 0.4 0.6 0.8 1 1 10 100 1000Percentage of |V(Gq)| (CDF)Number of CandidatesLinux-1Linux-2Linux-3Linux-4ﬁrefox61.130.69.232/etc/ﬁrefox/native-messaging-hosts/gtcache/bin/sh -c ./gtcache &>/dev/null &/etc/passwd/proc/30691/stat/home/admin/proﬁle/var/log/wdev/tmp/memtrace.so/var/log/mail/var/log/mail149.52.198.23128.55.12.10%Browser%23.194.99.39145.199.103.57*/hosts/pass_mgr%External IP        Address%                    *gtcache*/etc/passwd/etc/group                 *proﬁle*/var/log/wdev/tmp/memtrace.so/var/log/mail*mail*%External IP     Address%%Intranet IP Address%sendrecvsendrecv.*sendrecvwriteforkexecvereadreadread.*writewritereadwriteforkexecvesendrecvsendrecv/proc/*/stat*gtcache*AABBCCDDEEFFGGHHIIJJKKLMMLSession 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom1804Malware
Name
njRAT
DeputyDog
Uroburos
Carbanak
DustySky
OceanLotus
HawkEye
Report
Source
Fidelis [58]
FireEye [50]
Gdata [5]
Kaspersky [22]
Clearsky [65]
Eset [6]
Fortinet [7]
Year
2013
2013
2014
2015
2016
2018
2019
Sample
Relation
different
subset
subset
different
different
subset
different
Isolated
IOCs
153
21
26
230
250
117
3
RedLine
F×2+H+R
F+H
F+H
-
-
F+R
-
Splunk
Detection Results
Loki
F+H
F×2+H
F+H
PE
-
P
P+R
R
S
-
P+R
-
F+PE
PE
Poirot
B (score=0.86)
B (score=0.71)
B (score=0.76)
B (score=0.68)
B (score=1.00)
B (score=0.65)
B (score=0.62)
Reported
Samples
Analyzed Malware MD5
30
8
4
109
79
9
3
2013385034e5c8dfbbe47958fd821ca0
8aba4b5184072f2a50cbc5ecfe326701
51e7e58a1e654b6e586fe36e10c67a73
1e47e12d11580e935878b0ed78d2294f
0756357497c2cd7f41ed6a6d4403b395
d592b06f9d112c8650091166c19ea05a
666a200148559e4a83fabb7a1bf655ac
Table 4: Malware reports. In the Detection Results, B=Behavior, PE=PE-Sieve, F=File Name, H=Hash, P=Process Name,
R=Registry, S=Windows Security Event.
Comparison with Existing Tools. We compare Poirot with the
results of three other tools, namely RedLine[15], Loki[64], and
Splunk[59]. The input to these tools is extracted from the same
report we extract the query graphs and contains IOCs in different
types such as hash values, process names, file names, and registries.
We have transformed these IOCs to the accepted format of each
tool (e.g., RedLine accepts input in OpenIOC format [14]). The num-
ber of IOCs submitted to Redline, Loki, and Splunk are shown in
column-7, while the query graphs submitted to Poirot are shown in
Figs. 6 and 7. A detailed explanation of these query graphs demon-
strating how they are constructed can be found in appendix A. The
correspondence between node labels in the query graphs and their
actual names is represented in the second and third columns of
tables 5 and 6, while the alignments produced by Poirot are shown
in the last column.
As shown in the extracted query graphs, the design of Poirot ’s
search method, which is based on the information flow and causal
dependencies, makes us capable to include benign nodes (nodes C,
D, E, and F in DustySky) or attack nodes with exact same names of
benign entities (node E in Carbanak) in the query graph. However,
these entity names could not be defined as an IOC in the other
tested tools as will lead to many false positive alarms. As Redline,
Loki, and Splunk look for each IOC in isolation, they expect IOCs
as input that are always malicious regardless of their connection
with other entities. To this end, we do a preliminary search for
each isolated IOC in a clean system and make sure that we have
only extracted IOCs that have no match in a clean system. As a
result, for some test cases, like HawkEye, although the behavior
graph is rich, there are not so many isolated IOCs except a few hash
values that could be defined. This highlights the importance of the
dependencies between IOCs, which is the foundation of Poirot’s
search algorithm, and is not considered by other tools.
Detection Results. The last four columns of table 4 contain the
detection results, which show how each tool could detect the tested
samples. Keywords B, F, H, P, and R represent detection based on
the behavior, file name, hash value, process name, and registry,
respectively. In addition, some of the tested tools feature other
methods to detect anomalies, injection, or other security incidents.
Among these, we encountered some alarms from Windows Security
Mitigation and PE-Sieve [23], which are represented by keywords
S and PE, respectively. While for Poirot, a score is shown which
shows the goodness of the overall alignment of each query graph,
for the other tools, ×N indicates the number of hits when there has
been more than one hit for a specific type of IOC.
As shown in table 4, for all the test cases, Poirot has found an
alignment that bypasses the threshold value of 1
3 . After running
the search algorithm, in most of the cases, Poirot found a node
alignment for only a subset of the entities in the query graph,
except for DustySky, where Poirot found a node alignment for
every entity. The information flows and causal dependencies that
appear among the aligned nodes are often the same as the query
graph with some exceptions. For example, in contrast to how it
appears in the query graph of njRAT, where node A generates most
of the actions, in our experiment, node F generated most of the
actions, such as the write event to nodes C, G, K, L, and the fork
event of node I. However, since there is a path from node A to node
F in the query graph, Poirot was able to find these alignments and
measure a high alignment score.
The samples of njRAT, DeputyDog, Uroburous, and OceanLotus
are also detected by all the other tools, as these samples use unique
names or hash values that are available in the threat intelligence
and could be attributed to those malwares. For the other three
test cases, none of the isolated IOCs could be detected because of
different reasons such as malware mutations, using random names
in each run (nodes J and K in HawkEye query graph), and using
legitimate libraries or their similar names. Nevertheless, Splunk
found an ETW event related to the Carbanak sample, which is
generated when Windows Security Mitigation service has blocked
svchost from generating dynamic code. Loki’s PE-Sieve has also
detected some attempts of code implants which have resulted in
raising some warning signal and not an alert. PE-Sieve detects
all modifications done to a process even though they may not
necessarily be malicious. As such modifications happen regularly
in many benign scenarios, PE-Sieve detections are considered as
warning signals that need further investigations.
Conclusions. Our analysis results show that other tools usually
perform well when the sample is a subset of the ones the report
is written based on. This situation is similar to when there is no
mutations, and therefore, there are unique hash values or names that
could be used as signature of a malware. For example, DeputyDog
sample drops many files with unique names and hash values that
do not appear in a benign system, and finding them is a strong
indication of this malware. However, its query graph (Fig. 2) is not
very rich, and Poirot has not been able to correlate the modified
registry (node D) with the rest of the aligned nodes. Although the
calculated score is still higher than the threshold, but the other
tools might perform better when the malware is using well-known
IOCs that are strong enough to indicate an attack in isolation.
On the contrary, when the chosen sample is different from the
samples analyzed by the report, which is similar to the case that
malware is mutated, other tools usually are not able to find the
attacks. In such situations, Poirot has a better chance to detect the
attack as the behavior often remains constant among the mutations.
Session 6D: Cyber Thread CCS ’19, November 11–15, 2019, London, United Kingdom1805Malware
Carbanak
Node
A
B
C
D
E
F
G
H
I
Uroburos
DustySky
OceanLotus
J
A
B
C
D
E
F
G
H
I
J
K
L
A
B
C
D
E
F
G
H
I
A
B
C
D
E
F
G
H
I
J
K
L
M
Label
%Mail Application%
∗.%exe%
∗
%system32%\svchost
svchost
∗Sys$
%COMMON_APPDATA%\Mozilla\∗.%exe%
[HKCU]\Software\Microsoft\Windows\CurrentVersion \Internet Settings
%AppData%\Mozilla\Firefox\∗\prefs.js
%External IP address%
∗
%APPDATA%\Microsoft\credprov.tlb
%APPDATA%\Microsoft\shdocvw.tlb
rundll32
[HKCU]\Software\Classes\CLSID\42aedc87-2188-41fd-b9a3-
0c966feabec1\
∗\winview.ocx
∗\mskfp32.ocx
∗\msvcrtd.tlb
%APPDATA%\Microsoft\oleaut32.dll
%APPDATA%\Microsoft\oleaut32.tlb
%APPDATA%\Microsoft\libadcodec.dll
%APPDATA%\Microsoft\libadcodec.tlb
∗.%exe%
∗
%Microsoft Word%
∗\vboxmrxnp.dll