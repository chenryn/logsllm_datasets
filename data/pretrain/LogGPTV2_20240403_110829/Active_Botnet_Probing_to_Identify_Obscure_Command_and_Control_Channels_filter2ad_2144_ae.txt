if users are not educated to be familiar with such
Turing tests or have an unusually strong desire to be in a
channel, it is difﬁcult to perform generic Turing tests on IRC
or meebo networks. This also illustrates that although P0
probing seems simple and effective (if users are educated),
there is still a need for alternative and transparent techniques
that require no explicit user education (like our P1-P5
techniques).
V. POLICY IMPLICATIONS AND LIMITATIONS
A. Policy Concerns
It is likely that in some cases there are legal “bots,” e.g.,
some client-side legitimate programs or automatic scripts
that build their application logic over the chat protocols such
as IRC. For instance, some chat bots [8] can also be detected
by BotProbe. A possible solution is to whitelist these legiti-
mate applications if they are very important and critical, and
do not want to be disturbed (we expect such applications to
be very few). However, we think probing a pure chat bot is
not very critical, and arguably, the detection of such a chat
bot is not considered as a false positive. Furthermore, there
are several heuristics that can help differentiate these chat
bots from real malicious bots. For example, unlike malicious
bots, chat bots are unlikely to generate activity responses
(e.g., scan response). In addition, we can consider a group
property (similar to the group analysis in BotSniffer [14] and
BotMiner [12]) to differentiate a malicious botnet, where
clients in the same channel are mostly bots, from a normal
human chat channel with mostly human and very few chat
bots.
Our active probe techniques might be deemed contro-
versial because they alter network ﬂows to human users,
and may replay malicious commands. In Section III, we
have discussed the tradeoff between detection accuracy and
disturbance to human users and various means to mitigate
interference with legitimate chat sessions. We now consider
potential policy implications of replaying a “potentially ma-
licious command packet.” First, we argue that to minimize
liability issues, the only packets that should be tampered
with by BotProbe are packets that are inbound to the local
network. Second, this potentially malicious command has
already been transmitted into our network and executed on
the local host prior to our probing. Third, if the purpose of
the command is information gathering (e.g., .sysinfo),
then we argue that the ﬁrst command-response already leaks
enough information, and our further replay most
likely
does not leak more information or perform more harm. In
short, although controversial, we believe that the beneﬁts
of actively probing suspicious sessions could outweigh the
potential disturbance in many cases. We believe a more
formal study of cost-beneﬁt analysis and risk assessment
is needed in this area. We leave this as our future work.
B. Limitations and Potential Solutions
As stated in Section II, BotProbe has clear assumptions
to limit its application to a certain class of botnets that
use chatting-like C&C. Next, we describe some possible
evasions,12 although we have not observed real examples
yet, and discuss some potential solutions.
Strong encryption: Active probing techniques cannot
identify botnet C&C channels that use strong encryption
schemes (e.g., SSH, SSL) making them resilient to replay
attacks. Note, however, that existing passive perimeter mon-
itoring strategies cannot detect such channels either, and
most contemporary IRC bots avoid or use weak encryp-
tion/obfuscation schemes. At a minimum, BotProbe raises
the bar and forces all botnets to adopt strongly encrypted
communications. Arguably, using such strong encryption
channels sometimes may actually expose them as suspicious
and thus not desired by botmasters in some cases.13 We
envision that combining both networ- and host-based mon-
itoring could be helpful in recognizing botnets using strong
encryption, and leave it as our future work.
Timer-based evasions: Knowledgeable adversaries could
design bots to have programmed timers that greatly delay
the response time (the time between the command and
response), or limit the number of commands of the same
type that could be issued to the bot in a certain time window.
By using such timers, a bot can potentially evade our Single-
Binary-Response-Hypothesis algorithm. Note, however, this
would also reduce the efﬁciency of the botnet because the
botmaster cannot command the botnet promptly, or repeat
the same task for a certain time. Our potential solution
against such an attack is to randomize the delay in command
replays.
Stateful C&C protocols: Our P1 and P2 probing
techniques assume a stateless C&C protocol, i.e., we can
replay the observed command several times, and the bot
always responds similarly to the same command. In the
future, botmasters may create a stateful command proces-
sor that can detect duplicate commands, e.g., by using a
12Most of these evasions are against Single-Binary-Response-Hypothesis
the
and Interleaved-Binary-Response-Hypothesis
Turing-Test-Hypothesis algorithm could still work.
13In many cases, a simple obfuscation scheme such as substituting
”scan” with ”hello” is much less suspicious than using strong encryption
protection.
algorithms. That
is,
timestamp or sequence number with every command sent,
making simple replay ineffective. Note, most contemporary
IRC botnet command-response protocols are stateless and
deterministic. In addition, our P0 probing can still work
even in this evasion. Moreover, to counter this possible
future evasion, we describe a potential solution if there are
multiple command-response rounds and multiple clients in
the monitored network. Instead of replaying packets, we
could intercept and modify chatting packets sent to subse-
quent clients by using P4 and P5 probing techniques. By
intentionally modifying the command sent to some clients
while leaving commands to other clients untouched, we
could measure the difference in response between messages,
which would be analogous to replaying the command to the
same client several times in an Interleaved-Binary-Response-
Hypothesis test.14
Finally we envision that given the complex nature of
botnets, a combination of different techniques (network- and
host-based, passive and active) is probably necessary for
future botnet detection. Although BotProbe is imperfect and
limited, it has its unique detection merit to contribute to
multi-perspective botnet detection.
VI. RELATED WORK
Several recent papers propose different approaches to
the botnet detection problem. Livadas et al.
[20], [27]
proposed a machine-learning-based approach for botnet de-
tection using some general network-level trafﬁc features of
chat trafﬁc protocols such as IRC. Karasaridis et al.
[17]
studied network ﬂow-level detection of IRC botnet con-
trollers for backbone networks. Ramachandran et al. [24]
proposed using DNSBL counter-intelligence to ﬁnd botnet
members who generate spam. Rishi [10] is a signature-
based IRC botnet detection system that
tracks IRC bot
nickname patterns. BotGraph [35] is a tool to detect botnet
spamming attacks targeting major Web email providers.
Binkley and Singh [4] proposed combining IRC statistics
and TCP work weight for detection of IRC-based botnets.
Giroire et al.
[9] proposed to track the persistence of
new connection destination that is not already whitelisted to
identify suspicious C&C destinations. Wurzinger et al. [32]
proposed an automatic method to generate network-level
botnet signature/model of a given bot binary based on the
botnet command-response pattern. Yen and Reiter proposed
TAMD [34], a system that detects centralized botnets by
aggregating trafﬁc that shares the same external destination,
similar payload, and that involves internal hosts with similar
operating systems. BotHunter [13] is a passive bot detection
system that uses IDS dialog correlation to associate IDS
events to a bot infection dialog model. BotSniffer [14] and
BotMiner [12] are two botnet detection systems that utilize
14Here we assume the C&C is one-to-many, i.e., one command to many
clients in the network.
horizontal correlation to perform a spatio-temporal group
analysis across multiple hosts. In [8], entropy and machine-
learning-based approaches are proposed to detect chat bots
(not botnet C&C). This work has a similar limitation in that
it requires observing many chat messages before making a
decision and thus is not suitable for detecting infrequent
botnet C&C interactions. In a short summary, the afore-
mentioned systems are all passive, and this paper describes
several active botnet-probing techniques, which have unique
advantages and can complement existing detection schemes.
Several other papers discuss various means to modify net-
work trafﬁc for security purposes. Protocol-scrubbing [31]
techniques modify network ﬂows transparently to remove
ambiguities from ﬂows that can reveal
implementation-
speciﬁc details of a host’s operating system. Trafﬁc nor-
malization [15] is a technique to limit evasion opportunities
by eliminating potential ambiguities before the trafﬁc is
seen by the IDS monitor. Kaleidoscope is an in-line system
that protects honeynets by dynamically shufﬂing network
address blocks [33]. These techniques need to process and
then forward all packets sent to the network. In comparison,
BotProbe needs to inject packets very rarely and affects only
a very small number of ﬂows.
We plan to investigate these new potential utilities of active
techniques in the future.
ACKNOWLEDGMENT
The authors would like to thank Jon Gifﬁn, Nick Feamster,
Roberto Perdisci, and Junjie Zhang for comments on an early
version of this paper, and thank Mike Hunter for the help
in user study. This material is based upon work supported
in part by the National Science Foundation under grants
no. 0716570 and 0831300, the Army Research Ofﬁce under
Cyber-TA Grant no. W911NF-06-1-0316, the Department
of Homeland Security under contract no. FA8750-08-2-
0141, and the Ofﬁce of Naval Research under grant no.
N00014-09-1-1042 and N00014-09-1-0776. Any opinions,
ﬁndings, and conclusions or recommendations expressed in
this material are those of the authors and do not necessarily
reﬂect the views of the National Science Foundation, the
Army Research Ofﬁc, the Department of Homeland Security,
or the Ofﬁce of Naval Research.
REFERENCES
[1] Hi-performance protocol identiﬁcation engine. http://hippie.
ooﬂe.com/.
VII. CONCLUSION AND FUTURE WORK
[2] Shadowserver. http://shadowserver.org.
We proposed the idea of using active probing techniques
to detect botnet C&C communications that use chat-like
protocols. By requiring the observation of at most one
round of actual C&C interaction and then applying active
probing, this approach, unlike existing passive approaches,
can actively collect evidence and shorten the detection
time. We have developed a hypothesis testing framework
and a prototype system implementation that effectively
separates deterministic botnet communication from human
conversations, while providing control over false positives
and detection rates. We validated our system on several
contemporary malicious IRC bots and conducted an actual
user study on around 100 users. Our experimental results,
while preliminary, are encouraging. BotProbe is not intended
to replace existing passive detection approaches, but
to
complement them from a new perspective.
This work represents the ﬁrst feasibility study of the use
of active techniques in botnet detection; thus, we hope to
inspire new thoughts and directions in the research commu-
nity. While controversial and clearly limited, BotProbe has
demonstrated its effectiveness in detecting a large portion
of contemporary real-world botnets. In future work, we will
study robust, practical, and less controversial extensions of
active techniques and apply to a more general class of
botnet C&C detection (e.g., applicable to HTTP- and P2P-
based botnets). In addition to detection, active techniques
can be used for other purposes, e.g., server-side probing
and injecting watermarks to trace the location of botmasters.
[3] P. Barford and V. Yegneswaran. An inside look at botnets.
Special Workshop on Malware Detection.
[4] J. R. Binkley and S. Singh. An algorithm for anomaly-
In Proceedings of USENIX Steps
based botnet detection.
to Reducing Unwanted Trafﬁc on the Internet Workshop
(SRUTI), 2006.
[5] M. Collins, T. Shimeall, S. Faber, J. Janies, R. Weaver,
M. D. Shon, and J. Kadane. Using uncleanliness to predict
future botnet addresses. In Proceedings of the 2007 Internet
MeasurementConference (IMC’07), 2007.
[6] Cyber-TA. Multi-perspective malware analysis. http://www.
cyber-ta.org/releases/malware-analysis/public/.
[7] F. Freiling, T. Holz, and G. Wicherski. Botnet tracking:
Exploring a root-cause methodology to prevent denial of
service attacks. In Proceedings of ESORICS, 2005.
[8] S. Gianvecchio, M. Xie, Z. Wu, and H. Wang. Measurement
and classiﬁcation of humans and bots in internet chat.
In
Proceedings of the 17th USENIX Security Symposium (Secu-
rity’08), 2008.
[9] F. Giroire, J. Chandrashekar, N. Taft, E. Schooler, and K. Pa-
pagiannaki. Exploiting temporal persistence to detect covert
botnet channels. In 12th International Symposium on Recent
Advances in Intrusion Detection (RAID’09), 2009.
[10] J. Goebel and T. Holz. Rishi: Identify bot contaminated hosts
by IRC nickname evaluation. In USENIX Workshop on Hot
Topics in Understanding Botnets (HotBots’07), 2007.
[25] M. Roesch.
Snort - lightweight
intrusion detection for
networks. In Proceedings of USENIX LISA’99, 1999.
[26] SecureWorks.
Bobax trojan analysis.
http://www.
secureworks.com/research/threats/bobax/.
[27] W. T. Strayer, R. Walsh, C. Livadas, and D. Lapsley. Detect-
In 31st IEEE
ing botnets with tight command and control.
Conference on Local Computer Networks (LCN’06), 2006.
[28] A. Turing. Computing machinery and intelligence. In Mind
Vol.59, 1950.
[29] L. von Ahn, M. Blum, N. Hopper, and J. Langford.
In Pro-
CAPTCHA: Using hard AI problems for security.
ceedings of Eurocrypt, pages 294–311, 2003.
[30] A. Wald. Sequential Analysis. Dover Publications, 2004.
[31] D. Watson, M. Smart, G. R. Malan, and F. Jahanian. Pro-
tocol scrubbing: Network security through transparent ﬂow
modiﬁcation. IEEE/ACM Trans. Networking, 12(2):261–273,
2004.
[32] P. Wurzinger, L. Bilge, T. Holz, J. Goebel, C. Kruegel,
and E. Kirda. Automatically generating models for botnet
detection.
In 14th European Symposium on Research in
Computer Security (ESORICS’09), 2009.
[33] V. Yegneswaran, C. Alfeld, P. Barford, and J.-Y. Cai. Cam-
ouﬂaging honeynets. In Proceedings of IEEE Global Internet
Symposium, 2007.
[34] T.-F. Yen and M. K. Reiter. Trafﬁc aggregation for malware
detection.
the Fifth GI International
Conference on Detection of Intrusions and Malware, and
Vulnerability Assessment (DIMVA’08), 2008.
In Proceedings of
[35] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and
E. Gillum. Botgraph: large scale spamming botnet detection.
In NSDI’09: Proceedings of the 6th USENIX symposium on
Networked systems design and implementation, pages 321–
334, Berkeley, CA, USA, 2009. USENIX Association.
[36] J. Zhuge, X. Han, J. Guo, W. Zou, T. Holz, and Y. Zhou.
Characterizing the IRC-based botnet phenomenon. China
Honeynet Technical Report, 2007.
[11] J. B. Grizzard, V. Sharma, C. Nunnery, B. B. Kang, and
D. Dagon. Peer-to-peer botnets: Overview and case study. In
USENIX Workshop on Hot Topics in Understanding Botnets
(HotBots’07), 2007.
[12] G. Gu, R. Perdisci, J. Zhang, and W. Lee. BotMiner: Clus-
tering analysis of network trafﬁc for protocol- and structure-
independent botnet detection.
In Proceedings of the 17th
USENIX Security Symposium (Security’08), 2008.
[13] G. Gu, P. Porras, V. Yegneswaran, M. Fong, and W. Lee.
Bothunter: Detecting malware infection through IDS-driven
dialog correlation.
In 16th USENIX Security Symposium
(Security’07), 2007.
[14] G. Gu, J. Zhang, and W. Lee. BotSniffer: Detecting botnet
command and control channels in network trafﬁc.
In Pro-
ceedings of the 15th Annual Network and Distributed System
Security Symposium (NDSS’08), February 2008.
[15] M. Handley, V. Paxson, and C. Kreibich. Network intru-
sion detection: Evasion, trafﬁc normalization, and end-to-end
protocol semantics.
In Proceedings of the 10th Conference
on USENIX Security Symposium, Berkeley, CA, USA, 2001.
USENIX Association.
[16] J. Jung, V. Paxson, A. W. Berger, and H. Balakrishnan. Fast
portscan detection using sequential hypothesis testing.
In
IEEE Symposium on Security and Privacy 2004, Oakland,
CA, May 2004.
[17] A. Karasaridis, B. Rexroad, and D. Hoeﬂin. Wide-scale botnet
detection and characterization. In USENIX Hotbots’07, 2007.
[18] E. Kohler, R. Morris, B. Chen, J. Jannotti, and M. F.
Kaashoek. The click modular router. ACM Transactions on
Computer Systems, 18(3):263–297, 2000.
[19] R. Lemos. Bot software looks to improve peerage. http:
//www.securityfocus.com/news/11390.
[20] C. Livadas, R. Walsh, D. Lapsley, and W. T. Strayer. Using
machine learning techniques to identify botnet trafﬁc.
In
2nd IEEE LCN Workshop on Network Security (WoNS’2006),
2006.
[21] V. Paxson. BRO: A System for Detecting Network Intruders
In Proceedings of the 7th USENIX Security
in Real Time.
Symposium, 1998.
[22] P. Porras, H. Saidi, and V. Yegneswaran. A foray into
conﬁcker’s logic and rendezvous points.
In 2nd Usenix
Workshop on Large-Scale Exploits and Emergent Threats
(LEET), 2009.
[23] M. Rajab, J. Zarfoss, F. Monrose, and A. Terzis. A multi-
faceted approach to understanding the botnet phenomenon. In
Proceedings of ACM SIGCOMM/USENIX Internet Measure-
ment Conference, Brazil, October 2006.
[24] A. Ramachandran, N. Framster, and D. Dagon. Revealing
botnet membership using DNSBL counter-intelligence. In 2nd
USENIX Steps to Reducing Unwanted Trafﬁc on the Internet
(SRUTI), 2006.