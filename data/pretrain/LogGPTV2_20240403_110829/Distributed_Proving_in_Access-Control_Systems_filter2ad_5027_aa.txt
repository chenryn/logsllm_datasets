title:Distributed Proving in Access-Control Systems
author:Lujo Bauer and
Scott Garriss and
Michael K. Reiter
Distributed Proving in Access-Control Systems∗
Lujo Bauer†
Scott Garriss‡
Michael K. Reiter†‡§
Abstract
We present a distributed algorithm for assembling a
proof that a request satisﬁes an access-control policy ex-
pressed in a formal logic, in the tradition of Lampson et
al. [16]. We show analytically that our distributed proof-
generation algorithm succeeds in assembling a proof
whenever a centralized prover utilizing remote certiﬁcate
retrieval would do so. In addition, we show empirically
that our algorithm outperforms centralized approaches in
various measures of performance and usability, notably
the number of remote requests and the number of user
interruptions. We show that when combined with addi-
tional optimizations including caching and automatic tac-
tic generation, which we introduce here, our algorithm
retains its advantage, while achieving practical perfor-
mance. Finally, we brieﬂy describe the utilization of these
algorithms as the basis for an access-control framework
being deployed for use at our institution.
1. Introduction
In order to permit a requested operation, a reference
monitor must verify evidence that the request should be
granted. In classical approaches to access control, this ev-
idence may be the presence of an authenticated identity
on an access-control list, or the veriﬁcation of a capabil-
ity presented with the request. Several more recent pro-
posals encode access-control policy and supporting cre-
dentials in a formal logic (e.g., [16]). Of particular in-
terest here are those in which the evidence supporting a
request is a proof in this logic that the request satisﬁes the
access-control policy (e.g., [3]). That is, credentials (i.e.,
certiﬁcates) are encoded as formulas in the logic (e.g.,
“KAlice signed (KBob speaksfor Bob)”, using the no-
tation of [3]; see Section 3 for a summary) and used as
University
†CyLab, Carnegie Mellon University
‡Electrical & Computer Engineering Department, Carnegie Mellon
§Computer Science Department, Carnegie Mellon University
∗This research was supported in part by National Science Foundation
grant no. CNS-0433540, U.S. Navy grant no. N00014-04-1-0724, and
U.S. Army Research Ofﬁce contract no. DAAD19-02-1-0389.
premises, from which the policy is proved using inference
rules of the logic.
In this paper, we introduce a distributed strategy by
which this proof can be generated and show that the strat-
egy outperforms prior approaches in many contexts. All
prior works of which we are aware employ what we call an
eager strategy, in which the party assigned to submit the
proof1 (the reference monitor or requesting client) gen-
erates it singlehandedly, retrieving only certiﬁcates from
others when necessary. Instead, here we advocate a lazy
strategy, in which a party enlists the help of others to prove
particular subgoals in the larger proof—versus merely re-
trieving certiﬁcates from them—yielding a proof that is
assembled in a more distributed fashion.
There are compelling reasons to depart from the ea-
ger strategy employed in previous works. Fundamen-
tally, eager strategies place a burden on the prover to re-
quest certiﬁcates without knowledge of what certiﬁcates
are available or will be signed. As such, in systems where
delegations occur dynamically and at user discretion, an
eager strategy may request a certiﬁcate from a user that
the user will be unwilling to sign because it conveys too
much authority, or that conveys too little authority and so
dooms the user to be interrupted again later. For example,
an access-control policy requiring Alice says action(X)
in order to perform X (e.g., open a door) can be
satisﬁed by a request Bob says action(X) if Alice
signs Bob speaksfor Alice. However, as this con-
veys far more authority to Bob than merely the au-
thority to perform X—namely, the ability to perform
any action on behalf of Alice—Alice may refuse to
Similarly, asking Alice for a weak cer-
sign it.
tiﬁcate, e.g., KAlice signed (Bob says action(X) ⊃
Alice says action(X)), precludes Alice from making
more general statements that will save her from being
interrupted later to approve another action Y for Bob.
For example, Alice might instead add Bob to a group
(e.g., KAlice signed (Bob speaksfor Alice.Students))
to which she has already delegated the right to perform X
(e.g., Alice says (Alice.Students says action(X) ⊃
1In contrast to our goals here, most systems do not submit a formal
proof, but rather informal (but sound) evidence that a request should be
granted. Except where appropriate in Section 2, in the rest of this paper
we will nevertheless refer to this evidence as a “proof”.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
Alice says action(X))) as well
as other actions.
From this, Alice’s device can then assemble a proof
of Alice says (Bob says action(X) ⊃ Alice says
action(X)), which is exactly what was needed. More
importantly, Alice need not be contacted the next time
Bob needs to prove access to a resource to which
Alice.Students are authorized.
strategy, whereby (continuing our
As such, we advocate a distributed (“lazy”) prov-
example)
ing
Bob asks Alice to prove the subgoal (Alice says
(Bob says action(X) ⊃ Alice says action(X))).
In
addition to permitting Alice more ﬂexibility in choosing
how to prove this (if she chooses to at all), we show
empirically that
this approach can have signiﬁcant
performance and usability beneﬁts in a system that uses
a tactical theorem prover to assemble this proof. In par-
ticular, we demonstrate using an access-control policy for
physical access at our institution that the lazy approach
we advocate achieves signiﬁcantly better performance
and usability in natural measures, including the number
of messages sent and the number of interruptions to
users. We also describe extensions to lazy proving that
further improve these measures, even when compared
to the same improvements applied to an eager strategy,
and reduce overheads to practical levels. While some of
these extensions, notably caching, have been explored
elsewhere, we demonstrate that caching must be used
in unintuitive ways to achieve its potential, and we
further introduce a novel and more effective optimization
called automatic tactic generation.
These empirical
improvements are achieved despite the fact—which we
prove here—that our lazy strategy will always succeed in
completing a proof when the eager approach would.
Our motivation for pursuing this work is a system that
we are presently implementing at our institution to build
a robust and secure authorization device from a standard
converged mobile device (“smartphone”). In the context
of this paper, each phone is equipped with a tactical the-
orem prover for generating proofs of authorization to ac-
cess resources, which in our testbed include computer ac-
counts and physical rooms. At the time of this writing,
we are equipping a new building on campus to control ac-
cess to over 25,000 square feet of space, including over
60 doors, as well computer accounts and other virtual re-
sources for persons occupying this space. The algorithms
described here are central to this testbed.
The remainder of this paper is structured as follows.
We discuss related work in Section 2. We cover back-
ground in access-control logics and tactical theorem prov-
ing in Section 3. We detail our approach to distributed
proof generation in Section 4. We evaluate our ap-
proach empirically and introduce optimizations including
caching and automatic tactic generation in Section 5. We
conclude in Section 6.
2. Related Work
Distributed authorization has received considerable at-
tention from the research community. Much of the re-
lated research, however, revolves around formalizing and
analyzing the expressive power of authorization systems
(c.f., [1, 3, 12, 17]), and only a fraction of it addresses the
practical details and strategies for distributing and collect-
ing certiﬁcates.
Taos The Taos operating system made two main con-
tributions to distributed access control [23]:
its access-
control mechanism was inspired by a formal logic [2, 16];
and its access-control mechanism was built in at the OS,
rather than application, level. The former quality inspired
a greater degree of trust in the well-foundedness, and
therefore correctness, of the implementation. The latter
allowed the notion of identity to be embedded at a lower
level, making it easier, for example, to reason about the
security of communication channels within the OS.
In Taos, authority is initially derived from login cre-
dentials, and then partially or fully delegated via secure
channels to other processes. A credential manager builds,
checks, and stores the credentials as they are passed
around. An authentication agent determines whether a re-
questing process has the right to execute a particular ac-
tion by querying the credential manager and referring to
access-control lists (ACLs). A trusted certiﬁcation author-
ity (CA) maintains the mappings between cryptographic
keys and the names used in ACLs. Reasoning about cre-
dentials is performed locally by the credential manager,
and there are no provisions for identifying and locating
missing credentials.
PolicyMaker and KeyNote PolicyMaker [7] is a trust-
management framework which blurs the distinction be-
tween policies and credentials by expressing them both as
(possibly signed) programs. Determining whether a pol-
icy is satisﬁed involves executing the policy and the sup-
plied credentials. Execution is local to the entity that is
trying to verify whether a request is valid.
In the general case, allowing credentials to include ar-
bitrary programs causes the evaluation of these credentials
to become potentially intractable. However, by imposing
constraints on credentials (in particular, by requiring each
to be executable in polynomial time, monotonic, and au-
thentic) it is possible to specify a polynomial-time algo-
rithm for determining whether a set of credentials satis-
ﬁes a policy [8]. These and other constraints led to the
creation of KeyNote [6], which reﬁnes the ideas of Poli-
cyMaker into a more practical system.
Although credentials contain code to be executed and
can be authored by different entities, the credentials are
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
all collected by and executed in the local environment of
the entity that is evaluating a policy. Hence, at evaluation
time a credential cannot take advantage of any special-
ized knowledge present in the environment of the node on
which the credential originated. No provision is built into
PolicyMaker to automatically collect credentials as they
are needed. In fact, generalizing credentials in the style of
PolicyMaker may as a side effect make it more difﬁcult to
determine how to go about locating a missing credential.
SD3 and QCM SD3 [15] is a trust-management system
that further develops the idea of automatically distributing
and fetching certiﬁcates that was introduced in QCM [14].
SD3 is implemented as middleware, shielding users from
the details of using cryptographic primitives and certiﬁ-
cate distribution. Unlike most other distributed authoriza-
tion systems, but similarly to our approach, it produces
easily veriﬁable proofs of access—this makes it possible
for a potentially complex credential-collection algorithm
to reside outside of the system’s TCB. An SD3 query eval-
uator automatically fetches remote certiﬁcates needed to
fulﬁll access requests. In addition, it allows certiﬁcates
to be requested using wildcards and caches remote certiﬁ-
cates after they have been fetched. In this paper we in-
vestigate more powerful methods for fetching the needed
certiﬁcates while allowing the authors of the certiﬁcates
more control over which certiﬁcates are used.
Placeless Documents Balfanz et al. have developed a
distributed access-control infrastructure for Java applica-
tions [4], one of the ﬁrst implemented systems to be built
around a sound formal core. Requests to access resources
are accompanied by certiﬁcates that can be used to verify
the validity of the request. The system does not specify,
however, how certiﬁcates are collected or how a requester
determines which certiﬁcates should be attached to a par-
ticular request; this is a focus of the present paper. Once
a certiﬁcate is transmitted, it is cached by the recipient.
Proof-Carrying Authorization Appel and Felten [3]
proposed a distributed authorization framework that uses
a higher-order logic as a language for deﬁning arbitrary
application-speciﬁc access-control logics. The underlying
higher-order logic allows the application-speciﬁc logics to
be remarkably expressive. At the same time, proofs of ac-
cess constructed in any such application-speciﬁc logic can
easily be veriﬁed by a simple, general checker. Bauer et
al. [5] used this framework to develop an access-control
system for regulating access to web pages. Their sys-
tem also included a mechanism for automatically fetch-
ing and caching certiﬁcates needed to construct proofs of
access. Like SD3, this system implements only a simple
certiﬁcate-retrieval strategy, upon which we improve here.
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
SPKI/SDSI SPKI 2.0 [13], a merger of the SPKI [12]
and SDSI [21] efforts, is a digital-certiﬁcate scheme that
inherits the binding of privileges to keys proposed in SPKI
and the local names of SDSI. SPKI certiﬁcates are rep-
resented as tuples, and can bind names to keys, names
to privileges, and privileges to keys. The authorization
process for SPKI involves verifying the validity of certiﬁ-
cates, translating the uses of names to a canonical form,
and computing the intersection of the privileges described
in authorization tuples.
SPKI has recently been implemented as an access-
control mechanism for web pages [9, 19]. In the imple-
mented system, the web server presents a web browser
with the ACL protecting a requested page.
It is the
browser’s responsibility to provide the server with a set
of certiﬁcates which can be used to verify the browser’s
authority. Efﬁcient algorithms for selecting such a set of
certiﬁcates from a local cache have been proposed [10, 11]
and extended to retrieve certiﬁcates from a distributed cre-
dential store [18]; however, in each case the algorithm for
selecting this set is executed locally by the browser.
3. Background
To be able to precisely discuss the constructions of
proofs of access, we ﬁrst need to deﬁne a logic that will
allow us to describe our access-control scenarios. The
access-control logic we will use is straightforward and
developed in the style of Lampson et al. [16]. However,
we emphasize that our techniques are not speciﬁc to this
logic.
3.1. Access-Control Logic
Our access-control logic is inhabited by terms and for-
mulas. The terms denote principals and strings, which are
the base types of our logic.
The key constructor elevates strings representing pub-
lic keys to the status of principals. For example, if pubkey
is a particular public key, then key(pubkey) is the prin-
cipal that corresponds to that key.
Principals may want to refer to other principals or to
create local name spaces—this gives rise to the notion of
compound principals. We will write Alice.secretary to
denote the principal whom Alice calls “secretary.”
More formally, the terms of our logic can be described
as follows:
::= s | p
t
p ::= key(s) | p.s
where s ranges over strings and p principals.
The formulas of our logic describe principals’ beliefs.
If Alice believes that the formula F is true, we write
Alice says F . To indicate that she believes a formula F is
true, a principal signs it with her private key—the result-
ing sequence of bits will be represented with the formula
pubkey signed F .
To describe a resource that a client wants to access, we
introduce the action constructor. The ﬁrst parameter to
this constructor is a string that describes the resource. To
allow for unique resource requests, the second parameter
of the action constructor is a nonce. A principal believes
the formula action(resource, nonce) if she thinks that
it is OK to access resource during the session identiﬁed
by nonce. We will usually omit the nonce in informal
discussion and simply say action(resource).
Delegation is described with the speaksfor and
delegate predicates. The formula Alice speaksfor Bob
indicates that Bob has delegated to Alice his author-
ity to make access-control decisions about any resource.
delegate(Bob, Alice, resource) transfers to Alice only
the authority to access the particular resource called
resource.
The formulas of our logic are described by the follow-
ing syntax:
of the subgoals Bob says (Alice speaksfor Bob) and
Alice says action(resource).
Attempting to prove a goal simply by applying infer-
ence rules to it often leads to inefﬁciency or even non-
termination. Instead of blindly applying inference rules,
tactical theorem provers use a set of tactics to guide their
search. Roughly speaking, each tactic corresponds either
to an inference rule or to a series of inference rules. Each
tactic is a tuple (P, q), where P is a list of subgoals and
q the goal that can be derived from them. Each success-
ful application of a tactic yields a list of subgoals that re-
main to be proved and a substitution that instantiates the
free variables of the original goal. Suppose, for example,
that the SPEAKSFOR-E inference rule was a tactic which
we applied to Bob says action(resource). In this tac-
tic the names of principals are free variables (i.e., A and
B rather than Bob and Alice), so the produced substitu-
tion list would include the substitution of Bob for the free
variable A (Bob/A). A certiﬁcate is represented as a tactic
with no subgoals; we commonly refer to such a tactic as