int
$L1:mov
rax,r8
rax,0xFFFFFFFFE0000000
rax,0x20000000
$L1
3
rdx,[r8] #unsafe read
These checks guarantee that
the memory being read is
within the enclave region. If it is not, the program stops.
An alternative design would be to simply mask the bits
in the address to make sure they are within the enclave,
without stopping if they are not [66]. While that is more
efﬁcient, it is safer to stop the program when the error is
detected. Again, when memory accesses are guaranteed to not
violate region-read-write-integrity, for example direct accesses
to scalar variables on the enclave stack, the compiler elides the
read checks at compile time.
VIII. DISCUSSION
We now discuss several attack scenarios on VC3 which are
partly outside the adversary model from §III.
A. Information Leakage
One basic principle of MapReduce is that all key-value pairs
with the same key be processed by the same reducer. Thus,
inasmuch as a network attacker can count the number of
pairs delivered to each reducer, we should not expect semantic
security for the intermediate keys (as in “key-value pair”) as
soon as there is more than one reducer. Next, we discuss this
4747
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:24 UTC from IEEE Xplore.  Restrictions apply. 
information leakage in more detail: For the whole job, each
key Kinter is mapped to a ﬁxed, uniformly-sampled value
inter ∈ 0..R − 1. where R is the number of reducers for
K(cid:2)
the job chosen by the user (§VI). For each intermediate key-
value pair, the adversary may observe the mapper, the reducer,
and K(cid:2)
inter. Intuitively, the smaller the overall number of
unique intermediate keys Kinter in relation to R, the more
the adversary may learn on the actual distribution of keys.
For example, in the case of a presidential election vote count,
there are only two possible intermediate keys (the names of
both candidates). If R > 1, then the adversary easily learns
the distribution of the votes but not necessarily the name of
the successful candidate. Conversely, if there are many keys
(each with a small number of key-value pairs) relative to R,
then leaking the total number of pairs dispatched to each
reducer leaks relatively little information. In particular, when
all intermediate keys are unique, no information is leaked.
Attackers may also use more advanced trafﬁc analyses against
VC3 [16], [56], [68]. For example, by observing trafﬁc, an
attacker may correlate intermediate key-value pairs and output
key-value pairs to input splits; over many runs of different jobs
this may reveal substantial information about the input splits.
We plan to address these attacks with padding, clustering, and
distributed shufﬂe techniques [45].
B. Replay Attacks
The adversary could try to proﬁt in various ways from fully or
partially replaying a past MapReduce job. Such replay attacks
are generally prevented in case the online key exchange (§V-B)
is employed, as the user can simply refuse to give JCw a
second time to any enclave. This is different for the in-band
version of our approach (§V-C): an enclave is not able to tell
if it ran on a set of input data before as it cannot securely
keep state between two invocations. (The adversary can always
revert a sealed ﬁle and reset the system clock.) Given Cj,u and
JCw corresponding to a certain processor under their control,
the adversary is in the position to arbitrarily replay parts of
a job that the processor participated in before or even invoke
a new job on any input splits encrypted under kin contained
in JCw. This allows the adversary to repeatedly examine the
runtime behavior of E− from outside the enclave and thus
to amplify other side-channel attacks against conﬁdentiality.
The resilience of VC3 against such attacks can be enhanced
by hardcoding a job’s speciﬁcation into mappers to restrict the
input splits they should accept to process. Finally, Strackx et
al. recently proposed an extension to SGX that provides state
continuity for enclaves [57] and, if adopted, could be used in
VC3 to largely prevent replay attacks.
IX. IMPLEMENTATION
We implemented VC3 in C++ for Windows 64-bit and the
HDInsight distribution of Hadoop. Jobs are deployed as 64-
bit native code in the form of an executable (fw.exe) which
contains the framework code F , and a dynamic link library
(mapred.dll) that contains the enclave code E+ and E−.
A. SGX Emulation
We successfully tested our implementation in an SGX em-
ulator provided by Intel. However since that emulator is not
performance accurate, we have implemented our own software
emulator for SGX. Our goal was to use SGX as speciﬁed
in [32] as a concrete basis for our VC3 implementation and
to obtain realistic estimates for how SGX would impact the
performance of VC3. Our software emulator does not attempt
to provide security guarantees.
invoke our emulator via a call
The emulator is implemented as a Windows driver. It hooks
the KiDebugRoutine function pointer in the Windows
kernel that is invoked on every exception received by the
kernel. Execution of an SGX opcode from [32] will generate
an illegal instruction exception on existing processors, upon
which the kernel will
to
KiDebugRoutine. The emulator contains handler functions
for all SGX instructions used by VC3, including EENTER,
EEXIT, EGETKEY, EREPORT, ECREATE, EADD, EEX-
TEND, and EINIT. We use the same mechanism to handle
accesses to model speciﬁc registers (MSR) and control regis-
ters as speciﬁed in [32]. We also modiﬁed the SwapContext
function in the Windows kernel to ensure that the full register
context is loaded correctly during enclave execution.
The code in each handler function is modeled after the
corresponding pseudo code in [32]. We emulate the en-
clave page cache (EPC) by allocating a contiguous range
of physical memory (using the memory manager function
MmAllocateContiguousMemorySpecifyCache) and
using a data structure along the lines of the Enclave Page
Cache Map of [32] to keep track of it.
B. Performance Model
We are interested in estimating the performance of VC3
on a hypothetical SGX-enabled processor. We assume that
the performance of the existing processor instructions and
mechanisms would be unaffected by the extensions of [32].
Furthermore, the execution of most SGX instructions does
not appear to be relevant to VC3 performance. As the enclave
setup instructions ECREATE, EADD, EEXTEND and EINIT
constitute only a one-time cost at initialization of VC3, we
exclude them from the performance model. Other instruc-
tions (EGETKEY, EREPORT) are called only once during a
VC3 run and seem unlikely to have a noticeable impact on
performance. In all cases, we believe that the cost on our
emulator overestimates the cost on a hypothetical hardware
implementation.
These simpliﬁcations allow us to focus our performance
model on the cost of entering and exiting enclaves, which
we conservatively model as roughly the cost of an address
space switch. In particular, upon each transition, we perform
a kernel transition, do a TLB ﬂush, and execute a number
of delay cycles. We perform these actions in the handlers
for EENTER (enter enclave), ERESUME (enter enclave) and
EEXIT (exit enclave). As interrupts during enclave execution
also cause transitions, we also add the performance penalty
4848
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:24 UTC from IEEE Xplore.  Restrictions apply. 
at the beginning and end of each interrupt that occurs during
enclave execution. In particular, we patch the low-level in-
terrupt handling code in the Windows kernel to add the TLB
ﬂush and the delay cycles. We performed a sensitivity analysis
by running sample applications repeatedly while varying the
number of delay cycles, but we found that our optimizations to
control enclave transitions (batching of key-value pairs) allow
us to reduce the performance impact of transitions to negligible
levels even for large numbers of delay cycles. Therefore, for
the experiments described in the evaluation, we used 1,000
delay cycles, which is similar to the cost of crossing other
security boundaries such as performing system calls.
The SGX facility for encrypting and integrity protecting
data before they are written from CPU caches to platform
memory [41] could also affect performance. It is impossible
for us to model this effect accurately since the additional cost
of cache misses depends strongly on how the crypto pro-
tections for memory are implemented in hardware. However,
we can estimate the cache miss rate of typical VC3 appli-
cations. We have used the processor’s performance counter
for Last Level Cache Misses (LLC Misses) to measure the
memory bandwidth required by the enclave code of each
of the applications described in §X. In particular, we bound
the execution to one core and started that core’s counter
upon enclave entry and stopped it upon enclave exit. We
ran one application at a time. Several of the applications,
in particular the reducers, used hundreds of MB of memory,
which is signiﬁcantly larger than the processor’s L3 cache
size (6 MB). The measured memory bandwidths were well
below the bandwidths of modern memory encryption engines,
which indicates that SGX memory encryption should not have
a noticeable performance impact on VC3.
C. Enclave Creation
We implemented a driver (fw.sys) to provide functionality for
enclave creation. The driver obtains the physical addresses
of EPC memory from the emulator, maps pages into user
mode and calls SGX instructions involved in enclave creation.
Fw.sys is expected to be installed on all nodes; it would
typically be distributed with the operating system.
D. Enclave and Protocols
Fw.exe acts as the host process of the enclave. It performs un-
trusted I/O interaction with Hadoop via the streaming protocol
[5] over stdin/stdout. E+ implements the in-band variants of
both the key exchange and the job execution protocols, which
work on top of the Hadoop protocol. Our implementation uses
two optimizations: (i) We batch read/writes of key-value pairs
from within the enclave. This is important because transitions
in and out of the enclave come at a cost; we want to avoid
them when possible. Our implementation processes key-value
pairs in batches of 1000. (ii) We use the AES-NI instructions
[30] to accelerate our implementation of AES-GCM, including
the PCLMULQDQ instruction [25]. Our implementation of
E+ consists of roughly 5500 logical lines of code (LLOC)
of C, C++ and Assembly. About 2500 LLOC of these imple-
ment standard cryptographic algorithms. The user can inspect,
change and recompile the code of E+, or even use our protocol
speciﬁcation to completely re-implement it.
E. In-enclave Library
As a convenience for application development, we have cre-
ated an enclave-compatible C++ runtime library. Existing
C/C++ libraries which have operating system dependencies
cannot be used in an enclave environment because system
calls are conceptually not available [32]. Accordingly, we
could neither use common implementations of the Standard
C Library nor of the C++ Standard Template Library. Our
library contains functions which we found useful when writing
our sample applications: a set of mathematical functions, string
classes, containers, and a heap allocator which manages an in-
enclave heap and is the default backend for new. This library
is relatively small (3702 LLOC) and we stress that users may
choose to change it, use other libraries instead, or write their
own libraries.
F. Compiler
We implemented the compiler that supports our enclave self-
integrity invariants as a modiﬁcation to the Microsoft C++
compiler version 18.00.30501. The implementation consists
of two main parts: changes to code generation to emit our
runtime checks when needed, and changes to generate data
that our runtime library needs to initialize our enforcement
bitmaps in the enclave. We now describe each of the parts.
We inserted our new code generation module immediately
before the compiler phase that generates machine dependent
code. Although our implementation of VC3 is only for Intel
x64 processors at the moment, this will allow us to target
other architectures in the future. Our code generation module
is intra-function only, i. e., it does not perform global static
analysis. We do a pass over the instructions in a function to
ﬁnd any address-taken local variables; if we ﬁnd any such
variables, we emit code in the function’s prolog and epilog
to update the corresponding bits in our write bitmap. In the
prolog we set the bits in the bitmap, in the epilog we clear
them. Our implementation does this efﬁciently by generating
the appropriate bit masks and setting/resetting up to 64 bits
at a time. We also change the locations of these variables in
the function’s stack frame to make sure they do not share 8-
byte memory slots with other variables (recall that we keep
our bitmap information as 1 bit per every 8-bytes of enclave
memory). When iterating over the instructions in a function,
we insert a write check if we ﬁnd a store instruction that is not
a direct write to a local or a global variable. Direct writes to
local or globals are stores to ﬁxed offsets in the stack-frame or
the enclave base address and are guaranteed to be inside the
enclave. We also insert indirect call checks for every indirect
call instructions that we ﬁnd in the function. Note that we do
not insert checks on function returns, because the integrity of
the return addresses in the enclave stack is guaranteed by our
4949
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:24 UTC from IEEE Xplore.  Restrictions apply. 
write checks. We also perform a simple intra-function analysis
to simplify write checks when possible: when the write’s target
is a local or global variable, but the write is to a computed
offset in the variable, for example an array access, we replace
the full write check with a check of the form offset <
size. Finally, when generating code to enforce region-read-
write-integrity we also generate our read checks when we ﬁnd
load instructions whose target is not a local or global variable.
Our compiler also needs to generate data that our runtime
library uses to initialize our enforcement bitmaps when starting
the enclave. We generate two kinds of data: a list of addresses
of address-taken functions, and a list of the addresses and
sizes of address-taken global variables. These lists are simply
generated by emitting the addresses in special sections of the
object ﬁles whenever the compiler ﬁnds an instruction that
takes the address of a function or a global variable. We perform
this operation while iterating over all the code to generate the
runtime checks, i. e., we do not require an extra pass over
the code. We also iterate over all the initializers in global
data, to ﬁnd address-taken functions or address-taken global
variables there. The linker merges and removes duplicates
from this information when generating the binary to load into
the enclave. When we create the enclave, our runtime library
iterates over the addresses in these lists and sets the appropriate
bits in our enforcement bitmaps.
G. Other tools
We also created several other tools to support VC3, including
tools to generate symmetric and asymmetric keys, and tools to
encrypt and decrypt data. We created a tool called packer.exe
that encrypts E− and merges it with E+ to create the
self-contained and signed mapred.dll. E− and E+ are ﬁrst
compiled into distinct DLLs. The packer statically resolves
dependencies between the two DLLs and relocates both to a
ﬁxed virtual base address. It also makes sure that the DLLs’
sections (e. g., .text and .data) are page-aligned, as they
would be when loaded into a user mode process by the stan-
dard Windows image loader [53]. This is necessary to make
sure that the enclave code can be loaded into memory and
run unaltered without the help of the standard image loader.
Users need to be able to reliably compute the enclave digest in
advance. Otherwise, they could not verify statements by QEs.
Our tools are incorporated into the Microsoft Visual Studio
environment. They automatically create mapred.dll from a
user’s C++ MapReduce code.
X. EVALUATION
We used the applications listed in Table I to evaluate VC3.
We chose a mix of real-world applications and well-known