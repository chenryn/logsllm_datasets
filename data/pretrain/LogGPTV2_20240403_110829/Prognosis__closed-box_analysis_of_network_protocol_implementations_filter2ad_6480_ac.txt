+
+
+
+ }
agents . stopAll ()
connection . close ()
connection = newConnection ( conncetion . getConfig ())
agents = defaultAgentsWithConnection ( connection )
Most importantly, by using a reference implementation we can
rely on it to maintain the desired state in between multiple packets—
i.e., when a new abstract symbol request comes in, we can simply
resume from the state we left at the previous abstract symbol. This
last aspect is what allows us to not have to explicitly model any
of the protocol-specific logic, as it was done in prior work [22]. To
quantify this aspect, our instrumentation of the reference imple-
mentation of the TCP protocol only required an additional 300 lines
of mostly boilerplate code (which we envision can be automated in
the future), while the mapper implemented Fiterău-Broştean et al.
[22] to model the concretization function consisted of 2,700 lines
of code modeling the complex logic of TCP. For QUIC, our instru-
mentation required just over 2,000 lines of again mostly boilerplate
code. Given the complexity of QUIC (which involve cryptography
and other complex features), it is hard to imagine replicating the
approach from [22].
To make the approach more effective, we introduce a few op-
timizations. First, whenever the reference implementation sends
new packets (as part of an intermediate step) that do not match
our abstract query, we store such packets in a list and use them
to try to answer future queries. That is, when an abstract query
comes in, we first look into this list to check if any of the packets
has the desired abstract value and, if this is the case, we send that
packet to the Implementation. Second, we cache all intermediate
pairs between abstract I/Os and concrete I/Os in a data structure
called an Oracle Table 𝑂 ⊆ {(𝑎, 𝑐) | 𝑎 ∈ ((cid:98)Σ∗ ×(cid:98)Γ∗), 𝑐 ∈ (Σ∗ × Γ∗)}.
In Section 4, we use this cache to synthesize richer models that
go beyond finite abstract alphabets and can capture concrete packet
numbers and other numerical quantities. We keep track of received
packets for each query and also use this record to detect retrans-
mitted packets that should not be part of the response due to non-
determinism.
Now that we have constructed an abstraction that produces a
simplified abstract alphabet, and we have effective ways of query-
ing over this alphabet, we have built the interface necessary to
interact with the SUL module. We could then, for example perform
our 3-way TCP handshake by sending the input trace SYN(?,?,0)
ACK(?,?,0) and we would get the output trace ACK+SYN(?,?,0)
NIL, which accurately represents the flags of our 3-way TCP hand-
shake. However, because it uses our abstract alphabet the Adapter
cannot tell us the exact sequence or ack numbers it picked as this
would cause nondeterminism.
4 LEARNING MODULE
We now describe how the learning module interacts with the SUL
to learn models of the implementation. In Section 4.1, we formally
define the queries the learner is allowed to ask to construct a model.
In Section 4.2, we recall existing synthesis techniques for learning
Mealy Machines (i.e., automata with outputs). In Section 4.3 we
767
use program synthesis to learn a more detailed model that is capa-
ble of recovering register values and changes, like sequence and
acknowledgement numbers in the TCP protocol.
4.1 Learner Interface
Thanks to the techniques presented in Section 3, the SUL can be
treated as a query oracle that can answer the question "If I send this
input sequence, what will the implementation return?". With this
deterministic query oracle we have all we need to create an interface
for many model-learning algorithms for finite state machines. In
particular, we can use the query oracle to implement (or at least
approximate) two types of queries that a learner can ask:
Membership Queries: 𝑎𝑂 = 𝑚𝑞(𝑎𝐼)? where 𝑎𝐼 ∈(cid:98)Σ∗ and 𝑎𝑂 ∈
(cid:98)Γ∗. These are single traces 𝑎𝐼/𝑎𝑂 ∈(cid:98)Σ∗ ×(cid:98)Γ∗ of the system that give
the Learner knowledge about the specific traces produced by the
SUL so that it can build a hypothesis model 𝐻.
Equivalence Queries: 𝑒𝑞(𝐻)? where 𝐻 is a hypothesis model the
Learner believes to be correct and wants to know if it is equivalent
to the SUL; the answer is either 𝑎𝐼/𝑎𝑂, a counterexample trace that
distinguishes the SUL from the hypothesis 𝐻, or no counterexample
is returned, and the model is considered a correct abstraction of the
SUL, terminating the learning process.
In practice, Equivalence Queries require an oracle omniscient of
the SUL, and if we had that, we would not have to learn the system
in the first place. Instead, we can use heuristic Equivalence Oracles
such that when a counterexample is returned, it is guaranteed to
be a valid counterexample, but the absence of a counterexample no
longer guarantees equivalence. This approach still gives us approxi-
mation guarantees—i.e., the model is accurate with high probability
with respect to the set of inputs we use to test equivalence. It is now
a good point to remind the reader that the goal of this paper is to
unveil and discover potential incorrect behaviors of the SUL, rather
than provide behavior guarantees. Even if the learned models might
not be 100% accurate, they will still be helpful to analyze and detect
anomalies as we will show in our evaluation.
Learners that depend only on these two types of queries were
first studied in [11] to learn deterministic automata and have since
been extended to many types of state machines.
4.2 Learning Mealy Machines
With oracles capable of answering membership and equivalence
queries, we can use existing algorithms [25] to learn Mealy ma-
chines of the abstract behavior of the SUL. Intuitively, a Mealy
machine is a finite automaton that for every input symbol it reads,
it also produces an output.
Definition 4.1 (Mealy Machine). A Mealy Machine is a tuple
(𝑆, 𝑆0,(cid:98)Σ,(cid:98)Γ,𝑇 , 𝐺), such that: 𝑆 is a finite set of states, 𝑆0 ∈ 𝑆 is
the initial state,(cid:98)Σ is the abstract input alphabet,(cid:98)Γ is the abstract
output alphabet, 𝑇 is the transition function 𝑇 : 𝑆 ×(cid:98)Σ → 𝑆, and 𝐺
is the output function 𝐺 : 𝑆 ×(cid:98)Σ →(cid:98)Γ.
(cid:98)Σ = {SYN(?,?,0), ACK(?,?,0)} (cid:98)Γ = {ACK+SYN(?,?,0), NIL}
Example 4.1. The Mealy machine in Fig. 3(b) is a model of the
TCP 3-way handshake over input and output alphabets:
Prognosis: Closed-Box Analysis of Network Protocol Implementations
SIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
Given the input sequence [SYN(?,?,0), ACK(?,?,0)], this ma-
chine outputs the sequence [ACK+SYN(?,?,0), NIL]—starts in state
𝑠0, when reading SYN(?,?,0) it transitions to state 𝑠1 and outputs
ACK+SYN(?,?,0), and then reading ACK(?,?,0), it transitions to
𝑠2 and outputs NIL (no packet).
Mealy machines have been studied extensively and there are
many algorithms that can learn them using membership and equiv-
alence oracles [25]. At the high level, these algorithms issue mem-
bership queries to discover the behavior of the machine until they
can find a machine that is consistent—i.e., it correctly matches all
the traces for which it has issued membership queries. At this point,
the algorithm issues an equivalence query, which can either end
the learning process (in case of a yes answer) or cause the learning
process to ask more membership queries and repeat this process.
Prognosis uses the TTT algorithm [25] which is guaranteed to
learn a Mealy machine in time polynomial in the size of the machine.
For example, when we run TTT on the TCP implementation using
the abstract alphabet in Example 3.3, TTT learns the model in
Fig. 3(b) (we depict only transitions relevant to the handshake,
though the learned model is deterministic and total).
4.3 Synthesizing Rich Models
Mealy Machines can only model operations involving finite al-
phabets and cannot reason about numerical values—e.g., sequence
numbers. To capture the packet exchange in Figure 3(a) we need
not only the TCP flags currently learned in the model depicted in
Figure 3(b) but also certain quantities1—sequence and acknowl-
edgement numbers.
In this section, we present an extension of Mealy machines that
adds registers, and numerical inputs and outputs. We then show
how the ideas in Section 4.2 can be combined with constraint-based
synthesis techniques to learn these extended models. While we
could consider a wide range of enhancements to traditional au-
tomata, we limit ourselves to extending automata to read and write
integer values from packets, and to increment or set to input values
one of a finite number of registers (cid:174)𝑥. These extensions capture
common features of the protocols we are interested in. A transition
of an extended Mealy machine looks like the following:
𝐼 ((cid:174)𝑖)/𝑂(o((cid:174)𝑥))
(cid:174)𝑥=u((cid:174)𝑖,(cid:174)𝑥)
−−−−−−−−−−−→ 𝑞
𝑝
Informally, if the machine is in state 𝑝 and reads an abstract symbol
𝐼, possibly parametric on concrete numerical values (cid:174)𝑖, it updates
the registers (cid:174)𝑥 with values determined by u((cid:174)𝑖, (cid:174)𝑥), and it outputs an
abstract symbol 𝑂 parametric on the values determined by o((cid:174)𝑥).
The update function u(−) can take on quite complex values, but
in the following we consider each register is updated with either a
copy of a register, or an input value, or one of these incremented
by 1. Similarly, the output function o(−) can, for each parameter,
output the value of a register or that value plus 1.
We start from a Mealy machine where the register updates and
outputs are missing (as in Figure 4(left)) and our goal is to find
concrete terms u1, · · · , u9, and o1, o2 for each transition that result
1Existing extensions of the learning algorithm that handle automata with counters [25]
do not meet the needs described in this paper as they do not support complex compar-
ison operations and updates.
trace
in
in an extended machine correctly modelling the SUL with respect
to a given set of concrete traces.
We use the set of traces cached while learning the Mealy ma-
chine in the Oracle Table 𝑇 . For each pair (𝑎, 𝑐) ∈ 𝑇 of abstract
and concrete traces, we identify what path of the extended Mealy
machine is traversed by the abstract trace 𝑎 and use the concrete
trace 𝑐 to generate the constraints needed to identify the missing
terms of each transition in the path—i.e., the terms that make the
extended machine consistent with the concrete trace 𝑐. If needed,
the algorithm can solicit more example traces and add them to
𝑇 . The constraints are then solved using an SMT solver and the
solution is used to generate the needed terms.
concrete
following
appearing
Let us illustrate how we would synthesize the extended machine
in Figure 4(right) from the the sketch in Figure 4(left). We consider
the
𝑇 :
[(ACK(0, 3, 0)/NIL), (SYN(2, 5, 0)/ACK(4, 5, 0))]. This time, we want
to model that each symbol in the concrete trace also carries the
synchronization number (sn) and the acknowledgement number
(an)—e.g., for the first input these values are 0 and 3, respectively.
Given this trace, our algorithm generates constraints containing a
number of variables used to denote what we are trying to synthe-
size and what it means for the solution to be correct with respect
to the input trace. For each unknown term, we have a finite list
of possible terms we can instantiate it with. For example, the un-
known u1 can be instantiated with one of the 8 terms in the list:
[𝑟, 𝑟 + 1, 𝑝𝑟, 𝑝𝑟 + 1, 𝑝𝑖, 𝑝𝑖 + 1, sn, an]. In our constraints, we use an
integer variable 𝐸u1 to indicate the possible choices (indices start
at 0). For example, 𝐸u1 = 1 indicates that the term 𝑟 + 1 will be the
solution for the unknown u1.
As register values will change for each trace, our constraints need
to model how the values of the register are updated throughout the
execution. To do so, we introduce variables that track the values of
each register after reading the 𝑖-th input in the trace. For example,
𝑟[𝑖] indicates the value stored in register 𝑟 after reading the first
input packet. When generating constraints for multiple traces, we
will have a variable 𝑟𝜋 [𝑖] for each trace 𝜋 and index 𝑖.
The following simplified set of constraints capture the synthesis
problem we are trying to solve:
// The value of 𝐸u1 encodes the 8 possible terms for u1
𝐸u1 = 1 =⇒ 𝑟 [1] = 𝑟 [0] + 1
𝐸u1 = 3 =⇒ 𝑟 [1] = 𝑝𝑟 [0] + 1
𝐸u1 = 5 =⇒ 𝑟 [1] = 𝑝𝑖[0] + 1
𝐸u1 = 7 =⇒ 𝑟 [1] = 3
// Constraints for u1, u2, u3, u4, u5, u6
0 ≤ 𝐸u1 ≤ 7
𝐸u1 = 0 =⇒ 𝑟 [1] = 𝑟 [0]
𝐸u1 = 2 =⇒ 𝑟 [1] = 𝑝𝑟 [0]
𝐸u1 = 4 =⇒ 𝑟 [1] = 𝑝𝑖[0]
𝐸u1 = 6 =⇒ 𝑟 [1] = 0
. . .
// Constraints for o1, o2
0 ≤ 𝐸o2 ≤ 5
𝐸o2 = 0 =⇒ 𝑟 [2] = 5
𝐸o2 = 2 =⇒ 𝑝𝑟 [2] = 5
𝐸o2 = 4 =⇒ 𝑝𝑖[2] = 5
// The value of 𝐸o2 encodes the 6 possible terms for o2
𝐸o2 = 1 =⇒ 𝑟 [2] + 1 = 5
𝐸o2 = 3 =⇒ 𝑝𝑟 [2] + 1 = 5
𝐸o2 = 5 =⇒ 𝑝𝑖[2] + 1 = 5
Note that setting 𝐸u1 = 7 corresponds to selecting the term an
(i.e., the input ACK number) as a solution to the unknown u1. In
this case, the constraints model that the value of the register 𝑟
after reading the first packet (i.e., 𝑟[1]) should be equal to the ACK
number of the first input packet (i.e. 3). Similarly, setting 𝐸o2 to the
value 4 corresponds to selecting the term 𝑝𝑖 as a solution to the
unknown o2. In this case, the constraints model that the value of
the register 𝑟 after reading the second packet (i.e., 𝑟[2]) should be
equal to the ACK number of the second output packet (i.e., 5).
768
SIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
Ferreira et al.
ACK(sn, an, 0) / NIL
𝑟 = u1, 𝑝𝑟 = u2, 𝑝𝑖 = u3
𝑠0
SYN(sn, an, 0) / ACK(o1, o2, 0)
𝑟 = u4, 𝑝𝑟 = u5, 𝑝𝑖 = u6
SYN(sn, an, 0) / NIL
𝑟 = u7, 𝑝𝑟 = u8, 𝑝𝑖 = u9
𝑠1
ACK(sn, an, 0) / NIL
𝑟 = 𝑟 + 1, 𝑝𝑟 = 𝑝𝑟, 𝑝𝑖 = sn
𝑠0
SYN(sn, an, 0) / ACK(𝑝𝑟, 𝑝𝑟 + 1, 0)
𝑟 = 𝑝𝑟, 𝑝𝑟 = 𝑝𝑟, 𝑝𝑖 = 𝑝𝑖
SYN(sn, an, 0) / NIL
𝑟 = 𝑟 + 1, 𝑝𝑟 = 𝑝𝑟, 𝑝𝑖 = 𝑝𝑖
𝑠1
Figure 4: Extended machine with unknown terms (left) and corresponding synthesized machine (right).
Repeating
this
process
examples,
on more
e.g
[(SYN(2, 3, 0)/ACK(4, 5, 0)), (SYN(2, 3, 0)/NIL)], yields the automa-
ton in Figure 4(right). This automaton corresponds to the solution
that selects 𝐸u1 = 1 and 𝐸o2 = 3.
While this section shows a particular type of model, our frame-
work is general and allows to implement other synthesis and learn-
ing algorithms for more complex models (e.g., allowing more com-
plex constraints and updates) due to its interaction with the SUL.
Sometimes the synthesized models can contain incorrect register
patterns if the pattern is not completely covered by the Oracle Table
traces. These are detected through random equivalence testing, and
trigger new queries in the synthesis algorithm—i.e., the synthesizer
will restart with a larger set 𝑇 of traces to learn for as well as
negative example—i.e., traces that the model should not contain.
The constraints discussed in this section can be easily adapted to
handle negative examples.
5 ANALYSIS MODULE
The last module of Prognosis enables analysis techniques using
the outcomes of the learning modules to help the user infer be-
haviors of the SUL. Different abstraction levels allow us to expose
different types of anomalies, however the analysis module is lim-
ited to uncovering logic errors captured in the model, which is
restricted to observable events captured in the learning process.
Some more nuanced quantity specific bugs can be analysed through
the synthesized model, however these are limited to linear patterns.
We focus on analysing models for bug finding and knowledge
acquisition rather than providing verified guarantees due to not
all abstraction levels capturing enough information to fully verify
the specification. In this section, we present some of these analyses
and how they can be used to identify undesired behaviors.