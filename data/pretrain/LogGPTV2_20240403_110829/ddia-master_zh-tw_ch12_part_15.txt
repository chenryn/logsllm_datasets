让我们做一个思想实验，尝试用 **监视（surveillance）** 一词替换 **资料（data）**，再看看常见的短语是不是听起来还那么漂亮【93】。比如：“在我们的监视驱动的组织中，我们收集实时监视流并将它们储存在我们的监视仓库中。我们的监视科学家使用高阶分析和监视处理来获得新的见解。”
对于本书《设计监控密集型应用》而言，这个思想实验是罕见的争议性内容，但我认为需要激烈的言辞来强调这一点。在我们尝试制造软体 “吞噬世界” 的过程中【94】，我们已经建立了世界上迄今为止所见过的最伟大的大规模监视基础设施。我们正朝著万物互联迈进，我们正在迅速走近这样一个世界：每个有人居住的空间至少包含一个带网际网路连线的麦克风，以智慧手机、智慧电视、语音控制助理装置、婴儿监视器甚至儿童玩具的形式存在，并使用基于云的语音识别。这些装置中的很多都有著可怕的安全记录【95】。
即使是最为极权与专制的政权，可能也只会想著在每个房间装一个麦克风，并强迫每个人始终携带能够追踪其位置与动向的装置。然而，我们显然是自愿地，甚至热情地投身于这个全域监视的世界。不同之处在于，资料是由公司，而不是由政府机构收集的【96】。
并不是所有的资料收集都称得上监视，但检视这一点有助于理解我们与资料收集者之间的关系。为什么我们似乎很乐意接受企业的监视呢？也许你觉得自己没有什么好隐瞒的 —— 换句话说，你与当权阶级穿一条裤子，你不是被边缘化的少数派，也不必害怕受到迫害【97】。不是每个人都如此幸运。或者，也许这是因为目的似乎是温和的 —— 这不是公然胁迫，也不是强制性的，而只是更好的推荐与更个性化的营销。但是，结合上一节中对预测性分析的讨论，这种区别似乎并不是很清晰。
我们已经看到与汽车追踪装置挂钩的汽车保险费，以及取决于需要人佩戴健身追踪装置来确定的健康保险范围。当监视被用于决定生活的重要方面时，例如保险或就业，它就开始变得不那么温和了。此外，资料分析可以揭示出令人惊讶的私密事物：例如，智慧手表或健身追踪器中的运动感测器能以相当好的精度计算出你正在输入的内容（比如密码）【98】。而分析演算法只会变得越来越精确。
#### 同意与选择的自由
我们可能会断言使用者是自愿选择使用了会跟踪其活动的服务，而且他们已经同意了服务条款与隐私政策，因此他们同意资料收集。我们甚至可以声称，使用者在用所提供的资料来 **换取** 有价值的服务，并且为了提供服务，追踪是必要的。毫无疑问，社交网路、搜寻引擎以及各种其他免费的线上服务对于使用者来说都是有价值的，但是这个说法却存在问题。
使用者几乎不知道他们提供给我们的是什么资料，哪些资料被放进了资料库，资料又是怎样被保留与处理的 —— 大多数隐私政策都是模棱两可的，忽悠使用者而不敢开启天窗说亮话。如果使用者不了解他们的资料会发生什么，就无法给出任何有意义的同意。有时来自一个使用者的资料还会提到一些关于其他人的事，而其他那些人既不是该服务的使用者，也没有同意任何条款。我们在本书这一部分中讨论的衍生资料集 —— 来自整个使用者群的资料，加上行为追踪与外部资料来源 —— 就恰好是使用者无法（在真正意义上）理解的资料型别。
而且从使用者身上挖掘资料是一个单向过程，而不是真正的互惠关系，也不是公平的价值交换。使用者对能用多少资料换来什么样的服务，既没有没有发言权也没有选择权：服务与使用者之间的关系是非常不对称与单边的。这些条款是由服务提出的，而不是由使用者提出的【99】。
对于不同意监视的使用者，唯一真正管用的备选项，就是简单地不使用服务。但这个选择也不是真正自由的：如果一项服务如此受欢迎，以至于 “被大多数人认为是基本社会参与的必要条件”【99】，那么指望人们选择退出这项服务是不合理的 —— 使用它 **事实上（de facto）** 是强制性的。例如，在大多数西方社会群体中，携带智慧手机，使用 Facebook 进行社交，以及使用 Google 查询资讯已成为常态。特别是当一项服务具有网路效应时，人们选择 **不** 使用会产生社会成本。
因为一个服务会跟踪使用者而拒绝使用它，这只是少数人才拥有的权力，他们有足够的时间与知识来了解隐私政策，并承受得起代价：错过社会参与，以及使用服务可能带来的专业机会。对于那些处境不太好的人而言，并没有真正意义上的选择：监控是不可避免的。
#### 隐私与资料使用
有时候，人们声称 “隐私已死”，理由是有些使用者愿意把各种关于他们生活的事情释出到社交媒体上，有时是平凡俗套，但有时是高度私密的。但这种说法是错误的，而且是对 **隐私（privacy）** 一词的误解。
拥有隐私并不意味著保密一切东西；它意味著拥有选择向谁展示哪些东西的自由，要公开什么，以及要保密什么。**隐私权是一项决定权**：在从保密到透明的光谱上，隐私使得每个人都能决定自己想要在什么地方位于光谱上的哪个位置【99】。这是一个人自由与自主的重要方面。
当透过监控基础设施从人身上提取资料时，隐私权不一定受到损害，而是转移到了资料收集者手中。获取资料的公司实际上是说 “相信我们会用你的资料做正确的事情”，这意味著，决定要透露什么和保密什么的权利从个体手中转移到了公司手中。
这些公司反过来选择保密这些监视结果，因为揭露这些会令人毛骨悚然，并损害它们的商业模式（比其他公司更了解人）。使用者的私密资讯只会间接地披露，例如针对特定人群定向投放广告的工具（比如那些患有特定疾病的人群）。
即使特定使用者无法从特定广告定向的人群中以个体的形式区分出来，但他们已经失去了披露一些私密资讯的能动性，例如他们是否患有某种疾病。决定向谁透露什么并不是由个体按照自己的喜好决定的，而是由 **公司**，以利润最大化为目标来行使隐私权的。
许多公司都有一个目标，不要让人 **感觉到** 毛骨悚然 —— 先不说它们收集资料实际上是多么具有侵犯性，让我们先关注对使用者感受的管理。这些使用者感受经常被管理得很糟糕：例如，在事实上可能正确的一些东西，如果会触发痛苦的回忆，使用者可能并不希望被提醒【100】。对于任何型别的资料，我们都应当考虑它出错、不可取、不合时宜的可能性，并且需要建立处理这些失效的机制。无论是 “不可取” 还是 “不合时宜”，当然都是由人的判断决定的；除非我们明确地将演算法编码设计为尊重人类的需求，否则演算法会无视这些概念。作为这些系统的工程师，我们必须保持谦卑，充分规划，接受这些失效。
允许线上服务的使用者控制其隐私设定，例如控制其他使用者可以看到哪些东西，是将一些控制交还给使用者的第一步。但无论怎么设定，服务本身仍然可以不受限制地访问资料，并能以隐私策略允许的任何方式自由使用它。即使服务承诺不会将资料出售给第三方，它通常会授予自己不受限制的权利，以便在内部处理与分析资料，而且往往比使用者公开可见的部分要深入的多。
这种从个体到公司的大规模隐私权转移在历史上是史无前例的【99】。监控一直存在，但它过去是昂贵的、手动的，不是可伸缩的、自动化的。信任关系一直存在，例如患者与其医生之间，或被告与其律师之间 —— 但在这些情况下，资料的使用严格受到道德，法律和监管限制的约束。网际网路服务使得在未经有意义的同意下收集大量敏感资讯变得容易得多，而且无需使用者理解他们的私人资料到底发生了什么。
#### 资料资产与权力
由于行为资料是使用者与服务互动的副产品，因此有时被称为 “资料废气” —— 暗示资料是毫无价值的废料。从这个角度来看，行为和预测性分析可以被看作是一种从资料中提取价值的回收形式，否则这些资料就会被浪费。
更准确的看法恰恰相反：从经济的角度来看，如果定向广告是服务的金主，那么关于人的行为资料就是服务的核心资产。在这种情况下，使用者与之互动的应用仅仅是一种诱骗使用者将更多的个人资讯提供给监控基础设施的手段【99】。线上服务中经常表现出的令人愉悦的人类创造力与社会关系，十分讽刺地被资料提取机器所滥用。
个人资料是珍贵资产的说法因为资料中介的存在得到支援，这是阴影中的秘密行业，购买、聚合、分析、推断以及转售私密个人资料，主要用于市场营销【90】。初创公司按照它们的使用者数量，“眼球数”，—— 即它们的监视能力来估值。
因为资料很有价值，所以很多人都想要它。当然，公司也想要它 —— 这就是为什么它们一开始就收集资料的原因。但政府也想获得它：透过秘密交易、胁迫、法律强制或者只是窃取【101】。当公司破产时，收集到的个人资料就是被出售的资产之一。而且资料安全很难保护，因此经常发生令人难堪的泄漏事件【102】。
这些观察已经导致批评者声称，资料不仅仅是一种资产，而且是一种 “有毒资产”【101】，或者至少是 “有害物质”【103】。即使我们认为自己有能力阻止资料滥用，但每当我们收集资料时，我们都需要平衡收益以及这些资料落入恶人手中的风险：计算机系统可能会被犯罪分子或敌国特务渗透，资料可能会被内鬼泄露，公司可能会落入不择手段的管理层手中，而这些管理者有著迥然不同的价值观，或者国家可能被能毫无愧色迫使我们交出资料的政权所接管。
俗话说，“知识就是力量”。更进一步，“在避免自己被审视的同时审视他人，是权力最重要的形式之一”【105】。这就是极权政府想要监控的原因：这让它们有能力控制全体居民。尽管今天的科技公司并没有公开地寻求政治权力，但是它们积累的资料与知识却给它们带来了很多权力，其中大部分是在公共监督之外偷偷进行的【106】。
#### 回顾工业革命