ing the compiler and adding new RTL passes is to do code
instrumentation at the assembly level. Both shadow stack
operations and code to protect the shadow stack memory
region from being modiﬁed are instrumented by the LMP
compiler.
In the GCC RTL passes, we modify the source code in fi-
nal.c and insn-output.c that take care of assembler code
output for functions. Among them, final_end_function()
helps emit assembly code in function exit, we add our code
here to do instrumentation for shadow stack operations.
To implement shadow stacks, at each function call stack
operation when the function pushes return address, the com-
piler instruments the code to get the address and save a copy
to the thread’s shadow stack. The location of the shadow
stack is found by indexing into the stack region using the
calling thread’s Thread ID, which is retrieved via the sys-
tem call gettid(). At ﬁrst, it might seem like a system call
would be overly expensive, but such operations are highly
optimized and our measurements show that the cost of get-
tid() on modern Linux kernels is negligible. At each return
instruction, the compiler instruments the code to get the
Thread ID and ask the LMP runtime for the return address
stored in the shadow stack. If the address in the return in-
struction does not match the one in the shadow stack, it
sends a bound violation message to LMP runtime. In the
GCC passes, we identify the function calls by looking for the
RTL expression code call_insn, with the format:
(call
(mem : f m addr) nbytes)
where the addr is the address of that subroutine.
For bound checking of memory operations, we change the
RTL passes of GCC to ﬁnd RTL expressions containing
465Before
 ...
4007b5:   ADD    $0xc,(%rax)
...
After
…
   4005e1:  ADD      $0xc,(%rax)
   4005e5:  BNDCU %rax,%bnd1
   4005ea:  BNDCL  %rax,%bnd1   
...
)
s
(
e
m
T
n
o
i
Figure 5: An example of LMP instrumentation for store in-
struction.
i
t
u
c
e
x
E
1280
1120
960
800
640
480
320
160
0
Baseline
Baseline
LMPLMP
perlbench
gcc
gobmk
sjeng
h264ref
bzip2
mcf
hmmer
libquantum
memory operations that store values to main memory ad-
dress. The address is taken to compare with the upper and
lower boundary addresses of the shadow stack, which is s-
tored in the bound register BND1, where the bounds of the
memory region where the shadow stacks reside is stored. A
bound violation will be triggered if the address falls into the
memory range of the shadow stack which means the point-
er that the memory store uses as its target may have been
corrupted by an attacker.
We give an example of the code instrumentation results in
Figure. 5 to show the assembly code before and after instru-
mentation. The add instruction writes to main memory, and
the instrumented assembly code bndcu and bndcl checks if
the memory address to be changed is within the protected
shadow stack region.
4.2 LMP Runtime
The LMP runtime is implemented with approximately 700
lines of C source code. As this is a proof-of-concept proto-
type design, we allocate a virtual memory region of 2GB for
the shadow stacks. The reason behind the number of mem-
ory size is that in our test environment the OS has maximum
number of 62057 threads (from /proc/sys/kernel/threads-
max), and for each possible thread we give 32KB to the shad-
ow stack, which we believe is more than enough as the bench-
marks we used never exceed 8KB per thread in call stack. In
our implementation, both the numbers of maximum threads
and the space for each shadow stack are tunable. Since the
shadow stacks are allocated in the 64-bit virtual address s-
pace, they only take a tiny fraction of it. Also, because most
of the shadow stacks may never be written to, they only con-
sume virtual address space and the operating system never
needs to actually allocate physical memory to back them.
We could have also dynamically allocated shadow stacks
in memory, which would allow the shadow stack region to be
dynamically extended and reduced in size to accommodate
growth and reduction in shadow stack usage. This would
likely add some overhead in exchange for better virtual ad-
dress space utilization. However, given that virtual address
space is generally not a limiting factor on 64-bit architec-
tures, we do not believe that this extra overhead is justiﬁed.
When the instrumented program needs the LMP runtime
to store a function return address to the shadow stack, the
runtime takes the oﬀset between the base of the call stack
and the address that stores the return address, and a Thread
ID to process them in function LMP_push_ss(return_addr,
offset, threadID), then ﬁnds the shadow stack prepared
for that thread and stores the function return address in
the shadow stack. When the program function returns and
the address needs to be compared with the one stored in
the shadow stack, it calculates the oﬀset between the base
Figure 6: LMP overhead by comparison of execution time be-
tween baseline and LMP.
of the call stack and the address that stores the function
return address and uses return_addr=LMP_pop_ss(offset,
threadID), then LMP runtime will get the return address
stored in the shadow stack.
5. EVALUATION
In this section we evaluate the eﬀectiveness and diﬀerent
aspects of overheads of our LMP system. We run our exper-
iments on an Intel i5-6600K with 4 cores @3.5GHz in 64-bit
mode with 8G RAM. The benchmarks are run on Fedora 22
with Linux kernel 4.1.7.
5.1 Performance Overhead
We evaluate the overheads of the LMP system using CIN-
T 2006 benchmarks. All results are 5-time average numbers
that gathered from the non-reportable mode of SPEC bench-
mark. We compare the results with the baseline without ap-
plying LMP. As shown in Figure. 6, the average performance
overhead of LMP in comparison to the baseline performance
is 3.90%. The h264ref benchmark has the highest overhead
of 12.55%, mainly because it has many more function call-
s and RET instructions than others. Without the h264ref
benchmark the average overhead is only 2.12%.
To justify the main sources of overheads introduced by
the LMP system, we further separate them into three parts
of the system: context settings, bound-checking and shad-
ow stack operations. Context settings includes the runtime
library initialization, retrieving ThreadID via system calls
etc. Bound-checking involves the time that spent by MPX
bound instructions. Shadow stack operations consist of all
operations dealing with the shadows stacks.
We measure how much each component contributes to the
overall overhead by removing the other 2 components and
measuring the overhead with only one component added to
each benchmark. Over all the CINT 2006 benchmark result-
s, the average overhead of context settings is 0.1%, bound
checking is 0.52% and shadow stack operations is 3.27%.
From Figure 7 we can ﬁnd that context setting and bound-
checking almost contribute negligible amount of overheads.
Shadow stack operations are the main contributor, which on
average accounts for 84% of all the overheads. The perfor-
mance penalty of the memory protection is only 15% of the
overall overhead and the remaining 1% can be attributed
to infrequent setup and stack allocation/deallocation oper-
ations. The results here are inline with other heavily opti-
mized shadow stack implementations [10] that claim a few
466)
%
(
d
a
e
h
r
e
v
O
i
%
n
o
s
n
a
p
x
e
e
d
o
C
(cid:20)(cid:21)
(cid:28)
(cid:25)
(cid:22)
(cid:19)
(cid:38)(cid:82)(cid:81)(cid:87)(cid:72)(cid:91)(cid:87)
(cid:38)(cid:82)(cid:81)(cid:87)(cid:72)(cid:91)(cid:87)
(cid:37)(cid:82)(cid:88)(cid:81)(cid:71)(cid:3)(cid:38)(cid:75)(cid:72)(cid:70)(cid:78)(cid:76)(cid:81)(cid:74)
(cid:37)(cid:82)(cid:88)(cid:81)(cid:71)(cid:3)(cid:38)(cid:75)(cid:72)(cid:70)(cid:78)(cid:76)(cid:81)(cid:74)
(cid:54)(cid:75)(cid:68)(cid:71)(cid:82)(cid:90)(cid:3)(cid:54)(cid:87)(cid:68)(cid:70)(cid:78)
(cid:54)(cid:75)(cid:68)(cid:71)(cid:82)(cid:90)(cid:3)(cid:54)(cid:87)(cid:68)(cid:70)(cid:78)
(cid:83)(cid:72)(cid:85)(cid:79)(cid:69)(cid:72)(cid:81)(cid:70)(cid:75)
(cid:69)(cid:93)(cid:76)(cid:83)(cid:21)
(cid:74)(cid:70)(cid:70)
(cid:80)(cid:70)(cid:73)
(cid:74)(cid:82)(cid:69)(cid:80)(cid:78)
(cid:75)(cid:80)(cid:80)(cid:72)(cid:85)
(cid:86)(cid:77)(cid:72)(cid:81)(cid:74)
(cid:75)(cid:21)(cid:25)(cid:23)(cid:85)(cid:72)(cid:73)
Figure 7: Overhead components of LMP.
(cid:24)(cid:23)
(cid:23)(cid:27)
(cid:23)(cid:21)
(cid:22)(cid:25)
(cid:22)(cid:19)
(cid:21)(cid:23)
(cid:20)(cid:27)
(cid:20)(cid:21)
(cid:25)
(cid:19)
(cid:83)(cid:72)(cid:85)(cid:79)(cid:69)(cid:72)(cid:81)(cid:70)(cid:75)
(cid:69)(cid:93)(cid:76)(cid:83)(cid:21)
(cid:74)(cid:70)(cid:70)
(cid:80)(cid:70)(cid:73)
(cid:74)(cid:82)(cid:69)(cid:80)(cid:78)
(cid:75)(cid:80)(cid:80)(cid:72)(cid:85)
(cid:86)(cid:77)(cid:72)(cid:81)(cid:74)
(cid:75)(cid:21)(cid:25)(cid:23)(cid:85)(cid:72)(cid:73)
(cid:79)(cid:76)(cid:69)(cid:84)(cid:88)(cid:68)(cid:81)(cid:87)(cid:88)(cid:80)
Figure 8: Code Expansion of LMP.
variants of shadow stacks performance overheads around be-
tween 2% and 10% for the same benchmark set. As a result,
we believe this overhead is representative of the costs of LM-
P on current processors.
5.2 Code Expansion
LMP-enabled GCC emits assembly code to instrument the
target program in the RTL passes, so there is an increase in
code size. We directly compare the sizes of the binaries of
each benchmark and calculate the percentage of code expan-
sions that LMP introduces.
From Figure. 8, we can see that across the 9 benchmarks
we have run, the code at assembly level expands by 39.27%
in average. There is some variance among the code ex-
pansion numbers of the benchmarks, while the majority of
which is contributed by the bound checking instructions,
when there are more function calls/returns and memory s-
tore instructions of the benchmark, the more bound checking
instructions are instrumented. We note that our prototype
includes some extra debugging code which could be removed
to further reduce code expansion.
5.3 Memory Overhead
The memory overhead introduced to the benchmarks on
average is 19.3MB per program, and the average percentage
of the maximum resident memory overhead is 9.73%. The
memory overhead is mainly from the runtime library part
of LMP system which manages the shadow stacks. As men-
tioned in Sec. 4 the memory allocation is not optimized in
this research prototype implementation and we belive that
there is likely space for improvement. We expect the mem-
ory overhead could be decreased signiﬁcantly by adding dy-
namically allocating the mapping table as needed instead
of pre-emptively allocating it for the maximum number of
threads.
6. RELATED WORK
We review literature in the area of defense technologies to
protect programs from control ﬂow hijacking attacks.
Traditional attack methods using stack-smashing and code
injection [28] can be protected by applying recent adoption
of data execution prevention (DEP) [2]. Hardware support
for DEP is present in virtually all x86 processors as a non-
execute bit (NX bit, or called XD/XN bit depending on
processor architecture), such that code in the data segment
cannot be executed.
To counter the protection above, attackers have develope-
d more sophisticated methods that do not rely on injecting
new code, and that instead, rely on using existing code in the
program. One of the early examples is return-into-libc at-
tack [35], which can redirect program execution ﬂow through
libc functions. Similar exploitations such as return-oriented
programming (ROP) attack [29] can also execute arbitrary
computations by using a chain of existing code after chang-
ing return address at the function call stack. The latter has
been shown to be Turing-complete.
Randomization is practical in hiding information about
the memory layout of a program from attackers. Address S-
pace Layout Randomization (ASLR) [27] has been proposed
to defend against ROP attacks by mapping program process-
es and dynamic libraries into random virtual address space
every time. Address Space Layout Permutation (ASLP) fur-
ther re-orders sub-routines at the code segments on the basis
of the randomization provided by ASLR [22]. However, the
implementations of ASLR were soon to be found ineﬀec-
tive against de-randomization attack [31], costing only an
few hundred seconds of additional time to compromise the
target program. Similarly, ASLP is also vulnerable to de-
randomization attacks [24].
CFI (Control Flow Integrity) [1] is introduced to guaran-
tee that indirect control-ﬂow transfers point to legitimate
locations. To ensure that the return addresses in function
call stacks are not tampered with, shadow stacks to store
copies of return addresses are suggested. However, the per-
formance overhead of original CFI is reported as high as 2×
if the exact policy is enforced, so there are variants of coarse-
grained CFI proposed with changes to the original policy.