title:The Science of Guessing: Analyzing an Anonymized Corpus of 70 Million
Passwords
author:Joseph Bonneau
2012 IEEE Symposium on Security and Privacy
The science of guessing: analyzing an anonymized corpus of 70 million passwords
Computer Laboratory
University of Cambridge
Joseph Bonneau
PI:EMAIL
Abstract—We report on the largest corpus of user-chosen
passwords ever studied, consisting of anonymized password
histograms representing almost 70 million Yahoo! users, mit-
igating privacy concerns while enabling analysis of dozens of
subpopulations based on demographic factors and site usage
characteristics. This large data set motivates a thorough sta-
tistical treatment of estimating guessing difﬁculty by sampling
from a secret distribution. In place of previously used metrics
such as Shannon entropy and guessing entropy, which cannot
be estimated with any realistically sized sample, we develop
partial guessing metrics including a new variant of guesswork
parameterized by an attacker’s desired success rate. Our new
metric is comparatively easy to approximate and directly
relevant for security engineering. By comparing password
distributions with a uniform distribution which would provide
equivalent security against different forms of guessing attack,
we estimate that passwords provide fewer than 10 bits of
security against an online, trawling attack, and only about 20
bits of security against an optimal ofﬂine dictionary attack.
We ﬁnd surprisingly little variation in guessing difﬁculty;
every identiﬁable group of users generated a comparably
weak password distribution. Security motivations such as the
registration of a payment card have no greater impact than
demographic factors such as age and nationality. Even pro-
active efforts to nudge users towards better password choices
with graphical feedback make little difference. More surpris-
ingly, even seemingly distant language communities choose the
same weak passwords and an attacker never gains more than
a factor of 2 efﬁciency gain by switching from the globally
optimal dictionary to a population-speciﬁc lists.
Keywords-computer security; authentication; statistics; infor-
mation theory; data mining;
I. INTRODUCTION
Text passwords have dominated human-computer authen-
tication since the 1960s [1] and been derided by security
researchers ever since, with Multics evaluators singling pass-
words out as a weak point in the 1970s [2]. Though many
password cracking studies have supported this claim [3]–
[7], there is still no consensus on the actual level of security
provided by passwords or even on the appropriate metric
for measuring security. The security literature lacks sound
methodology to answer elementary questions such as “do
older users or younger users choose better passwords?” Of
more concern for security engineers, it remains an open
question the extent to which passwords are weak due to
a lack of motivation or inherent user limitations.
The mass deployment of passwords on the Internet may
© 2012, Joseph Bonneau. Under license to IEEE.
DOI 10.1109/SP.2012.49
538
provide sufﬁcient data to address these questions. So far,
large-scale password data has arisen only from security
breaches such as the leak of 32 M passwords from the
gaming website RockYou in 2009 [7], [8]. Password corpora
have typically been analyzed by simulating adversarial pass-
word cracking, leading to sophisticated cracking libraries but
limited understanding of the underlying distribution of pass-
words (see Section II). Our goal is to bring the evaluation
of large password data sets onto sound scientiﬁc footing
by collecting a massive password data set legitimately and
analyzing it in a mathematically rigorous manner.
This requires retiring traditional,
inappropriate metrics
such as Shannon entropy and guessing entropy which don’t
model realistic attackers and aren’t approximable using sam-
pled data. Our ﬁrst contribution (Section III) is to formalize
improved metrics for evaluating the guessing difﬁculty of a
skewed distribution of secrets, such as passwords, introduc-
ing α-guesswork as a tunable metric which can effectively
model different types of practical attack.
Our second contribution is a novel privacy-preserving
approach to collecting a password distribution for statistical
analysis (Section IV). By hashing each password at the time
of collection with a secret key that is destroyed prior to our
analysis, we preserve the password histogram exactly with
no risk to user privacy.
Even with millions of passwords, sample size has sur-
prisingly large effects on our calculations due to the large
number of very infrequent passwords. Our third contribution
(Section V) is to adapt
techniques from computational
linguistics to approximate guessing metrics using a random
sample. Fortunately, the most important metrics are also
the best-approximated by sampled data. We parametrically
extend our approximation range by ﬁtting a generalized
inverse Gaussian-Poisson (Sichel) distribution to our data.
Our ﬁnal contribution is to apply our research to a massive
corpus representing nearly 70 M users,
the largest ever
collected, with the cooperation of Yahoo! (Section VI).
We analyze the effects of many demographic factors, but
the password distribution is remarkably stable and security
estimates in the 10–20 bit range emerge across every sub-
population we considered. We conclude from our research
(Section VII) that we are yet to see compelling evidence that
motivated users can choose passwords which resist guessing
by a capable attacker.
(a) Historical cracking efﬁciency, raw dictionary size
(b) Historical cracking efﬁciency, equivalent dictionary size
Figure 1. The size of cracking dictionaries is plotted logarithmically against the success rate achieved in Figure 1a. In Figure 1b, the dictionary sizes are
adjusted to incorporate the inherent need for more guesses to crack more passwords. Circles and solid lines represent operating system user passwords,
squares and dashed lines represent web passwords.
II. HISTORICAL EVALUATIONS OF PASSWORD SECURITY
It has long been of interest to analyze how secure pass-
words are against guessing attacks, dating at least to Mor-
ris and Thompson’s seminal 1979 analysis of 3,000 pass-
words [3]. They performed a rudimentary dictionary attack
using the system dictionary and all 6-character strings and
recovered 84% of available passwords. They also reported
some basic statistics such as password lengths (71% were
6 characters or fewer) and frequency of non-alphanumeric
characters (14% of passwords). These two approaches, pass-
word cracking and semantic evaluation, have been the basis
for dozens of studies in the thirty years since.
A. Cracking evaluation
The famous 1988 Morris worm propagated in part by
guessing passwords using a 350-word password dictionary
and several rules to modify passwords [9]. The publicity
surrounding the worm motivated independent studies by
Klein and Spafford which re-visited password guessing [4],
[5]. Both studies broke 22–24% of passwords using more so-
phisticated dictionaries such as lists of names, sports teams,
movies and so forth. Password cracking evolved rapidly in
the years after these studies, with dedicated software tools
like John the Ripper emerging in the 1990s which utilize
mangling rules to turn a single password like “john” into
variants like “John”, “J0HN”, and “nhoj.” [10]. Research on
mangling rules has continued to evolve; the current state of
the art by Weir et al. [11] automatically generates mangling
rules from a large training set of known passwords.
Later studies have often utilized these tools to perform
dictionary attacks as a secondary goal, such as Wu’s study
of password cracking against Kerberos tickets in 1999 [12]
and Kuo et al.’s study of mnemonic passwords in 2006 [13],
which recovered 8% and 11% of passwords, respectively.
Recently, large-scale password leaks from compromised
websites have provided a new source of data for cracking
evaluations. For example, Schneier analyzed about 50,000
passwords obtained via phishing from MySpace in 2006 [6].
A more in-depth study was conducted by Dell’Amico et
al., who studied the MySpace passwords as well as those
of two other websites using a large variety of different
dictionaries [7]. A very large data set of 32M passwords
leaked from RockYou in 2009, which Weir et al. studied
to examine the effects of password-composition rules on
cracking efﬁciency [8].
Reported numbers on password cracking efﬁciency vary
substantially between different studies, as shown in Fig-
ure 1. Most studies have broken 20–50% of accounts with
dictionary sizes in the range of 220–230. All studies see
diminishing returns for larger dictionaries. This is clear in
Figure 1b, which adjusts dictionary sizes based on the per-
centage of passwords cracked so that the degree of upward
slope reﬂects only decreasing efﬁciency. This concept will
motivate our statistical guessing metrics in Section III-E.
There is little data on the efﬁciency of small dictionaries
as most studies employ the largest dictionary they can
process. Klein’s study, which attempted to identify highly
efﬁcient sub-dictionaries, is a notable exception [4]. There
is also little data on the size of dictionary required to break
a large majority of passwords—only Morris and Thompson
broke more than 50% of available passwords1 and their
results may be too dated to apply to modern passwords.
B. Semantic evaluations
In addition to cracking research, there have been many
studies on the semantics of passwords with psychologists
1A 2007 study by Cazier and Medlin claimed to break 99% of passwords
at an e-commerce website, but details of the dictionary weren’t given [14].
539
0.00.10.20.30.40.50.60.70.80.9α=proportionofpasswordsguessed05101520253035µ=lg(dictionarysize)MorrisandThompson[1979]Klein[1990]Spaﬀord[1992]Wu[1999]Kuo[2006]Schneier[2006]Dell’Amico(it)[2010]Dell’Amico(ﬁ)[2010]Dell’Amico(en)[2010]0.00.10.20.30.40.50.60.70.80.9α=proportionofpasswordsguessed05101520253035µ=lg(dictionarysize/α)MorrisandThompson[1979]Klein[1990]Spaﬀord[1992]Wu[1999]Kuo[2006]Schneier[2006]Dell’Amico(it)[2010]Dell’Amico(ﬁ)[2010]Dell’Amico(en)[2010]study
Riddle et al. [15]
Spafford [5]
year
1989
1992
1999 Wu [12]
1999
2006
2009
Zviran and Haga [18]
Cazier and Medlin [14]
RockYou leak [19]
length % digits % special
—
14.8
4.1
0.7
1.3
3.7
4.4
6.8
7.5
5.7
7.4
7.9
3.5
31.7
25.7
19.2
35.0
54.0
COMMONLY ESTIMATED ATTRIBUTES OF PASSWORDS
Table I
and linguists being interested as well as computer security
researchers. This approach can be difﬁcult as it either re-
quires user surveys, which may produce unrealistic password
choices, or direct access to unhashed passwords, which
carries privacy concerns. Riddle et al. performed linguistic
analysis of 6,226 passwords in 1989, classifying them into
categories such as names, dictionary words, or seemingly
random strings [15]. Cazier et al. repeated this process in
2006 and found that hard-to-classify passwords were also
the hardest to crack [14].
Password structure was formally modeled by Weir et
al. [11] using a context-free grammar to model the prob-
ability of different constructions being chosen. Password
creation has also been modeled as a character-by-character
Markov process, ﬁrst by Narayanan and Shmatikov [16] for
password cracking and later by Castelluccia et al. [17] to
train a pro-active password checker.
Thus methodology for analyzing password structure has
varied greatly, but a few basic data points like average
length and types of characters used are typically reported, as
summarized in Table I. The estimates vary so widely that it
is difﬁcult to infer much which is useful in systems design.
The main trends are a tendency towards 6-8 characters of
length and a strong dislike of non-alphanumeric characters in
passwords.2 Many studies have also attempted to determine
the number of users which appear to be choosing random
passwords, or at least passwords without any obvious mean-
ing to a human examiner. Methodologies for estimating this
vary as well, but most studies put it in the 10–40% range.
Elements of password structure, such length or the pres-
ence of digits, upper-case, or non-alphanumeric characters
can be used to estimate the “strength” of a password,
often measured in bits and often referred to imprecisely
as “entropy”.3 This usage was cemented by the 2006 FIPS
Electronic Authentication Guideline [20], which provided a
“rough rule of thumb” for estimating entropy from password
2It is often suggested that users avoid characters which require multiple
keys to type, but this doesn’t seem to have been formally established.
3This terminology is mathematically incorrect because entropy (see
Sections III-A and III-B) measures a complete probability distribution,
not a single event (password). The correct metric for a single event is
self-information (or surprisal). This is perhaps disfavored because it is
counter-intuitive: passwords should avoid including information like names
or addresses, so high-information passwords sound weak.
characteristics such as length and type of characters used.
This standard has been used in several password studies
with too few samples to compute statistics on the entire
distribution [21]–[23]. More systematic formulas have been
proposed, such as one by Shay et al. [22] which adds entropy
from different elements of a password’s structure.
C. Problems with previous approaches
Three decades of work on password guessing has pro-
duced sophisticated cracking tools and many disparate data
points, but a number of methodological problems continue
to limit scientiﬁc understanding of password security:
1) Comparability: Authors rarely report cracking results
in a format which is straightforward to compare with pre-
vious benchmarks. To our knowledge, Figure 1 is the ﬁrst
comparison of different data points of dictionary size and
success rate,
though direct comparison is difﬁcult since
authors all report efﬁciency rates for different dictionary
sizes. Password cracking tools only loosely attempt to guess
passwords in decreasing order of likeliness, introducing im-
precision into reported dictionary sizes. Worse, some studies
report
the running time of cracking software instead of
dictionary size [14], [24], [25], making comparison difﬁcult.
2) Repeatability: Precisely reproducing password crack-
ing results is difﬁcult. John the Ripper [10], used in most
publications of the past decade, has been released in 21 dif-
ferent versions since 2001 and makes available 20 separate
word lists for use (along with many proprietary ones), in
addition to many conﬁguration options. Other studies have
used proprietary password-cracking software which isn’t
available to the research community [6], [14]. Thus nearly
all studies use dictionaries varying in content and ordering,
making it difﬁcult to exactly re-create a published attack to
compare its effectiveness against a new data set.
3) Evaluator dependency: Password-cracking results are
inherently dependent on the appropriateness of the dictionary
and mangling rules to the data set under study. Dell’Amico
et al. [7] demonstrated this problem by applying language-
speciﬁc dictionaries to data sets of passwords in different
languages and seeing efﬁciency vary by 2–3 orders of
magnitude. They also evaluated the same data set as Schneier
three years earlier [6] and achieved two orders of magnitude
better efﬁciency simply by choosing a better word list. Thus
it is difﬁcult to separate the effects of more-carefully chosen
passwords from the use of a less appropriate dictionary. This
is particularly challenging in data-slicing experiments [8],
[23] which require simulating an equally good dictionary
attack against each subpopulation.
4) Unsoundness: Estimating the entropy of a password
distribution from structural characteristics is mathematically
dubious, as we will demonstrate in Section III-D, and in-
herently requires making many assumptions about password
selection. In practice, entropy estimates have performed
poorly as predictors of empirical cracking difﬁculty [8], [23].
540
III. MATHEMATICAL METRICS OF GUESSING DIFFICULTY
Due to the problems inherent to password cracking simu-
lations or semantic evaluation, we advocate security metrics
that rely only on the statistical distribution of passwords.
While this approach requires large data sets, it eliminates
bias from password-cracking software by always modeling
a best-case attacker, allowing us to assess and compare the
inherent security of a given distribution.
probability 0 < px ≤ 1, such that(cid:80) px = 1. We use N to
Mathematical notation: We denote a probability distribu-
tion with a calligraphic letter, such as X . We use lower-case
x to refer to a speciﬁc event in the distribution (an individual
password). The probability of x is denoted px. Formally, a
distribution is a set of events x ∈ X , each with an associated
denote the total number of possible events in X .
We often refer to events by their index i, that is, their
rank by probability in the distribution with the most probable
having index 1 and the least probable having index N. We
refer to the ith most common event as xi and call its prob-
ability pi. Thus, the probabilities of the events in X form a
monotonically decreasing sequence p1 ≥ p2 ≥ . . . ≥ pN .
← X
if it is drawn at random from X .
Guessing model: We model password selection as a ran-
dom draw X
← X from an underlying password distribution
X . Though X will vary depending on the population of
users, we assume that X is completely known to the attacker.
Given a (possibly singleton) set of unknown passwords
{X1, X2, . . . Xk}, we wish to evaluate the efﬁciency of an
attacker trying to identify the unknown passwords Xi given
access to an oracle for queries of the form “is Xi = x?”
A. Shannon entropy
We denote an unknown variable as X, denoting X
R
R
Intuitively, we may ﬁrst think of the Shannon entropy:
N(cid:88)
i=1
H1(X ) =
−pi lg pi
(1)
as a measure of the “uncertainty” of X to an attacker.
Introduced by Shannon in 1948 [26], entropy appears to
have been ported from cryptographic literature into studies
of passwords before being used in FIPS guidelines [20].
It has been demonstrated that H1 is mathematically inap-
propriate as a measure guessing difﬁculty [27]–[30]. It in fact
quantiﬁes the average number of subset membership queries
of the form “Is X ∈ S?” for arbitrary subsets S ⊆ X needed
to identify X.4 For an attacker who must guess individual
passwords, Shannon entropy has no direct correlation to
guessing difﬁculty.5