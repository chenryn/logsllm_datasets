title:A First Look at Performance in Mobile Virtual Network Operators
author:Fatima Zarinni and
Ayon Chakraborty and
Vyas Sekar and
Samir R. Das and
Phillipa Gill
A First Look at Performance
in Mobile Virtual Network Operators
Fatima Zarinni†, Ayon Chakraborty†, Vyas Sekar◦, Samir R. Das†, Phillipa Gill†
† Stony Brook University ◦ Carnegie Mellon University
ABSTRACT
Recent industry trends suggest a new phenomenon in the mobile
market: mobile virtual network operators or MVNOs that oper-
ate on top of existing cellular infrastructures. While MVNOs have
shown signiﬁcant growth in the US and elsewhere in the past two
years and have been successful in attracting customers, there is
anecdotal evidence that users are concerned about cellular perfor-
mance when choosing MVNOs over traditional cellular operators.
In this paper, we present the ﬁrst systematic measurement study
to shed light on this emerging phenomenon. We study the per-
formance of 3 key applications: web access, video streaming and
voice, in 2 popular MVNO families (a total of 8 carriers) in the US,
where each MVNO family consists of a major base carrier and 3
MVNOs running on top of it. We observe that some MVNOs do
indeed exhibit signiﬁcant performance degradation and that there
are key differences between the two MVNO families.
Categories and Subject Descriptors
C.2.1 [Network Architecture and Design]: Wireless Communica-
tion; C.2.2 [Network Protocols]: Applications; C.4 [Performance
of Systems]: Measurement Techniques.
Keywords
MVNO; Mobile measurements; Mobile performance; Cellular
Measurements; Cellular performance; QoE; Applications.
1 Introduction
A new trend has been emerging in the last few years in the cellu-
lar market both in the US and in Europe—the rise of mobile vir-
tual network operators or MVNOs [12, 14, 15]. At a high-level,
MVNOs use the existing cellular infrastructures that are owned by
the traditional cellular operators. MVNOs do not incur signiﬁcant
infrastructure or spectrum licensing costs and offer services that
are different from traditional cellular operators (e.g., better pre-paid
plans and multiple quotas).
While MVNOs started to appear in the market in the early 2000s,
they have only recently become more mainstream in terms of mar-
ket share. The growth is a culmination of several factors: increas-
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC’14, November 5–7, 2014, Vancouver, BC, Canada. 
Copyright is held by the owner/author(s). Publication rights licensed to ACM
ACM 978-1-4503-3213-2/14/11 ...$15.00.
http://dx.doi.org/10.1145/2663716.2663752.
ing prices of traditional cellular providers for consumers, users’
preference in avoiding contractual lock-ins, the popularity of “pre-
paid” services, regulatory intervention to ensure competition and
market segmentation focusing on niche demographics (e.g., tween
markets) [22]. As of Q1 2014, there are 20, 23, 11 and 35 MVNOs
running on top of the AT&T, T-Mobile, Verizon and Sprint net-
works in the US, respectively [5].
Even as MVNOs grow in market share, there are concerns among
users about their performance. For example, a quick sampling of
popular consumer complaints forums shows signiﬁcant concerns
related to both cost, billing, and service issues (e.g., poor cover-
age/signal, 3G/4G promised but getting 2G, poor application per-
formance, and frequent disconnections). Shown below are some
actual quotes from user forums about MVNOs:
[11]: I know that AIO is capped at 8mbps download speed.
Are all the other MVNOs like Straight Talk, Net10 and Air-
Voice also limited to 8mbps download speeds? Do they suffer
from higher latency?
[9]: I have been throttled every day since last week so each
day I lose my 4g/E symbol and once I regain it Im throttled
. . . I’ve used 1.4gb and I have only 3 days left on my 30 plan.
[13]: Does Sprint have means of degrading service to Ting
(and other MVNO) customers in favor of Sprint customers in
a particular crowded cell?
[10]: My only concern is if the service quality of the ser-
vice. With Straight Talk, for example, I’d be on AT&T’s GSM
network in Boston, I think . . . but I wonder if as an MVNO
customer I’d get second-tier access or service.
Motivated by the growth of MVNOs and the aforementioned
user concerns, this paper presents a ﬁrst study to shed light on the
performance of different MVNOs. While there is a lot of previous
work in analyzing mobile performance (e.g., [25, 20, 21, 3]), they
have not systematically analyzed performance in MVNOs. To ad-
dress this gap, we study two major MVNO families in the US. In
our study, each family includes the base carrier and three popular
MVNOs running on top of the base carrier. While this sample study
does not cover all base carriers in US or all MVNOs atop any base
carrier, the carrier/MVNO choices have been done systematically,
based on popularity (Section 2). In the performance analysis, we
hide the actual names of the carriers and MVNOs to protect their
business interests. To simplify presentation, we refer to the two
base carriers as carrier A and B. We refer to the MVNOs within the
carrier A as A1, A2 and A3, and within the carrier B as B1, B2
and B3. The base carrier along with its MVNOs (e.g., A, A1, A2,
A3) are refered to as ‘MVNO family’ or just ‘family.’(e.g., MVNO
family A)
As a starting point, we analyze the performance for three dom-
inant usage modes: web access, video streaming and voice calls.
165Using over 13,000 measurements collected across 11 locations over
a period of 3 months, we address the following questions:
• Does the performance vary across the MVNOs running atop the
same base carrier? (e.g., is MetroPCS worse than Straight Talk
given that they are both MVNOs running on T-Mobile network?)
• Do MVNOs perform worse compared to the base carrier in each
case? (e.g., is H20 Wireless, an MVNO on AT&T network,
worse than AT&T)?
• Are there differences across different MVNO families? (e.g., do
all MVNOs in a family, say the T-Mobile family, show signiﬁ-
cantly worse performance than those in another family, say the
AT&T family?)
We analyze application-speciﬁc quality-of-experience (QoE)
metrics to address these questions. We also perform factor anal-
ysis to correlate the observed application-level performance with
network-level performance, such as, TCP throughput, round-trip
times (RTTs), packet loss rates, DNS look up times, and PHY-layer
characteristics to attribute the observed performance differences (if
any) to structural differences across the operators.
Our key ﬁndings are:
• The base carrier often performs better than the MVNOs and
sometimes signiﬁcantly so. For instance, some MVNOs over
base carrier B fail to load a non-trivial (≥10%) fraction of
YouTube video requests and can have up to 6× worse page load
time.
• There is signiﬁcant diversity across MVNOs within the same
MVNO family, for both the A and B MVNO families. For in-
stance, often B2 performs considerably worse than B1 and B3
in MVNO family B.
• There are non-trivial differences between the two MVNO fami-
lies; overall the MVNOs running atop A have better performance
w.r.t the base carrier compared to their B counterparts.
• Finally, we see key differences across applications as well.
While voice quality is largely similar across all MVNOs and
base carriers, there is huge discrepancy in data performance both
for web access as well as video streaming.
We hope that this paper serves as a motivation for future large-scale
measurement studies in this direction, that would span wider areas,
larger number of MVNOs and wider variety of data plans.
2 Measurement Setup
In this section, we begin by describing the choice of phone, carriers,
and cellular plans. Then, we describe our data collection method-
ology.
Choice of phone: To ensure we do not have phone-speciﬁc ef-
fects (e.g. CPU speed/memory access latency/cache size) in our
measurements, we use the same phone model for all carriers –
Google’s Nexus 4 with 2GB RAM, Quad-core CPU and 2G/3G/4G
support (i.e., EDGE/UMTS/HSPA/HSPA+). All of our phones
run the Android 4.2.2 (JellyBean) OS. Since Nexus 4 only sup-
ports GSM-based carriers, this study is limited to such carriers and
their MVNOs only. We leave the investigation of performance in
CDMA-based carriers and their MVNOs for future work.
Choice of carriers and plans: We chose popular and widely-used
MVNOs that run atop two major base carriers in the U.S. We call
them carriers A and B, respectively. We used Google Trends [4] and
the list of all the available MVNOs [5] to ﬁnd the top 3 MVNOs
for each of these base carriers. The 6 MVNOs are summarized
in Table 1. A1, A2 and A3 run atop A; B1, B2 and B3 run atop
Carrier
A
A1
A2
A3
B
B1
B2
B3
$/Mo.
Plan (all pre-paid except B)
Type
Base
Unlimited talk/text, 2.5GB data @ 4G 60
MVNO Unlimited talk/text, 2.5GB data @ 4G 45
MVNO Unlimited talk/text, 3GB data @ 4G
50
MVNO Unlimited talk/text, 2.5GB data @ 4G 60
65
Base
Unlimited talk/text, 2GB data @ 4G
50
MVNO Unlimted talk/text, 2.5GB data @ 4G
50
MVNO Unlimited talk/text, 2GB data @ 4G
MVNO Unlimited talk/text, 2GB data @ 4G
50
Table 1: Mobile carriers and plans used in our study.
Figure 1: We conduct measurements at 11 different locations
spanning across a 3000 km2 wide area. The annotations show
the names of the measurement locations along with the type of
location, and the number of measurement sets.
B. Cellular providers offer a range of plans with different prices.
Hence, to provide a fair comparison between carriers, we select
similar plans for all the carriers (as summarized in Table 1), in
terms of features.When the exact plan was not available we picked
the closest comparable plan.
Data collection: We selected 11 reasonably diverse locations
spanning different usage scenarios: urban/suburban, shopping ar-
eas, residential, ofﬁce/lab and hospital. Figure 1 shows the geo-
graphical spread of our measurement locations. We acknowledge a
potential limitation, that all our measurements occurred in the Long
Island/New York region. However, this region is a major population
hotspot, covering part of New York city metro area and associated
suburbs.
We developed a suite of custom scripts and mobile applications
for web browsing, video streaming, and voice calls, representing
common usage modes. Our custom tools collect relevant user
quality-of-experience (QoE) metrics, and we defer application-
speciﬁc details to the following sections.
At each location, we use four identically conﬁgured Nexus 4
phones (one for base and three for MVNO carriers) to run the same
suite of experiments concurrently at that location. Our scripts run
these applications at each location typically hourly or half-hourly
for most of the day – often starting at early morning and going un-
til late night – over different days of the week modulo practical
constraints (e.g., shop/mall closures).
On average, we conducted about 150 sets of measurements for
each carrier, across different locations, during Jan-Mar 2014, on
different days. Each measurement set consists of a series of ap-
plication runs, e.g., web page access for a set of chosen web sites,
video streaming, voice calls, TCP upload throughput test, etc.
Flushing, Residential,144 Hicksville, Residential,162 Melville, Residential,151 Hauppauge, Shopping,107 Stony Brook, Lab,164  Ronkonkoma, Shopping,95 Bayshore, Residential,139 Selden, Residential,172 Stony Brook, Library,113 Stony Brook, Hospital,183 Port Jefferson, Residential,158 166Concurrent with the QoE measurements, we also log packet
traces using the tcpdump tool and a range of relevant phone char-
acteristics using the Android API (e.g., radio stats), to enable fur-
ther factor analysis. We veriﬁed separately via the top utility, that
this additional monitoring adds only a modest CPU overhead (≈
5%). This does not bias our measurements. Prior to conducting
actual measurements, we performed tests over WiFi, where we ran
our apps with and without additional logging, and we measured
the performance for web, video and voice applications, as well as,
network tests. The attained results showed negligible difference in
performance with this logging enabled or disabled.
Our analysis did not reveal any signiﬁcant location, time-of-day
or day-of-week speciﬁc change in terms of performance of carri-
ers with respect to each other. Thus, we present only aggregate
statistics (over all locations, times and days) and focus on perfor-
mance differences across carriers and MVNO families. Since the
experiments for base and MVNO carriers are always colocated in
both space and time, we believe it is a fair characterization of the
performance issues we describe in the rest of the paper.
3 Application Performance
In this section, we analyze the performance of the MVNOs and the
base carriers for three common modes of mobile usage: web ac-
cess, video streaming, and voice calls. In each case, we describe the
application-speciﬁc setup, and the relevant QoE metrics we mea-
sure. We also correlate the observations to key network-level and
PHY-layer characteristics.
3.1 Web Browsing
Setup and QoE Metric: We choose six popular websites with di-
verse characteristics: Youtube, Amazon, Wikipedia, Twitter, Bing,
and CNN. All of these sites had an overall Alexa rank ≤ 20 in
April 2014. We developed a custom browser application using An-
droid WebViewClient. At each measurement site, the app visits
each website’s mobile landing page (in random order across carri-
ers) and records the page load time QoE metric. We measure page
load time as the difference between the time the URL is requested
from the browser and the time when all the web objects (html text,
images, etc.) are fetched and the onPageFinished event [7] is
triggered.
Note that the set of webpages accessed is diverse in terms of
structure and content size, with CNN and Amazon constituting the
two largest median content sizes in the set (≈ 570 KB and 400 KB,
respectively) and Twitter and Bing having the smallest (≈ 89 KB
and 100 KB, respectively).
Evaluation of Page Load Times: Figure 2 shows the distribution
of page load time across all runs for the six websites.1 There are
three key observations here. First, typically the carriers in MVNO
family A perform better than their B counterparts; e.g., for CNN
all carriers in MVNO family A perform better than all carriers in
MVNO family B, and sometimes signiﬁcantly so. Second, while
the differences between base carrier A and its MVNOs are only
modest, we see signiﬁcant differences between base carrier B and
some of its MVNOs; e.g., B2 is almost 6× worse than B for CNN.
Finally, we see non-trivial variability across MVNOs within the
same MVNO family; e.g., B2 is often considerably worse than
other MVNOs in MVNO family B, and A1 is slightly worse than
other MVNOs in MVNO family A. We conﬁrmed that these differ-
ences between carrier page load times are statistically signiﬁcant
1Note that, >10 sec page load times are not surprising on a mobile
platform, as seen in prior work [38, 19, 36]. For example, Welsh
reports 75 seconds page load time for a webpage over a cellular
link [38].
A
    A1
    A2
    A3
YOUTUBE
CNN
AM AZON
WIKIPEDIA
T WITTER
(a) MVNO family A
B
    B1
    B2
    B3
)
s
c
e
s
(
i
e
m
T
d
a
o
L
e
g
a
P
 8
 6
 4
 2
 0
 50
 40
 30
 20
 10
)
s
c
e
s
(
i
e
m
T
d
a
o
L
e
g
a
P
BING
BING
 0
CNN
YOUTUBE
AM AZON
WIKIPEDIA
T WITTER
(b) MVNO family B
Figure 2: Distribution of page load times (median, 25th and
75th percentiles): We see that (a) MVNO family A usually per-
forms better than MVNO family B; (b) within each MVNO
family one or more MVNOs is worse than the base carrier; and
(c) some MVNOs (e.g., B2, B3) suffer more than others).
using the Kolmogrov-Smirnov (K-S) [8] statistical test, but do not
show these results for brevity.
Factor Analysis: To understand the causes of these performance
differences, we looked at lower-layer metrics such as DNS lookup
time, RTT, TCP retransmission rates, and signal strength. We com-
puted the Pearson’s correlation between the difference of page load
times for the base carrier and the MVNOs and that of different
lower-layer metrics, for every website. Based on this analysis, we
zoom in on two key factors – RTT and TCP retransmissions (Fig-
ure 3). First, we can see that MVNO family A has generally lower
RTTs and retransmission rates than MVNO family B. As prior stud-
ies have shown, lower RTTs imply lower page load times, which is
consistent with our observations that A and its MVNOs have lower
page load times [18]. Second, we see in Figure 3a that within the
MVNO family A, A1 which had higher page load times, indeed has
higher RTTs.2 Finally, Figure 3d shows that the MVNOs in MVNO
familyB (B2 and B3) with the highest page load times see very high
retransmission rates.
We also observe that B1 has the lowest retransmission rates in
its MVNO family, however, still higher RTTs than B, thus resulting
in B1 having a lower page load time than B2 and B3, but, higher
than B. However, this still does not explain some of the very high
(> 30s) page load times for B1 (e.g., CNN in Figure 2b). Further
analysis of the packet traces showed signiﬁcant TCP idle times as
shown in one example timeseries in Figure 4a. Figure 4b breaks
down the page load measurements in the B MVNO family in two
2Higher RTTs for both Twitter and Bing, as compared with other
webpages, could be due to the content-server locations that were
accessed for these sites, or due to the path from carrier A’s gateway
routers to these servers [35, 39].
167A
    A1
A2
    A3
B
    B1
    B2
    B3
 500