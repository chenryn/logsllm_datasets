composing homographs with target embedding makes it easier for
an impersonating domain to evade detection. Regardless, domains
with multiple forms of impersonation represent a small, but present,
portion of impersonating domains.
6 COORDINATED CAMPAIGNS
Our analysis in §5 identified hundreds of thousands of individual
instances of target embedding. In this section, we demonstrate
that many target embedding domains can be pattern-matched to
uncover what appear to be coordinated campaigns of impersonation.
To this end, we perform a case study analysis of four large-scale
campaigns that registered many unique domains with a common
structure to impersonate the same target. Safe Browsing identified
some of the domains in these campaigns as malicious, but using
our methodology we can determine Safe Browsing’s coverage of
these campaigns. We summarize the results in Table 8.
2We also check for confusable Unicode characters in the TLD token.
Campaign
starwars.com
runescape.com
*.net-
*.co-
Total Domains
3,071
4,522
11,765
1,926
Flagged by
Safe Browsing
(35.14%)
1,079
(18.89%)
854
7,439
(63.23%)
(73.16%)
1,409
Table 8: Total number of target-embedded domains & Safe
Browsing coverage for four campaigns with over 1,000
unique domains of similar structure.
StarWars This campaign had FQDNs of the form starwars.com.
p58vfa15.top and starwars.com.dvqdh83l6r.site. Of the
websites we detected, Safe Browsing flagged 35.14% as employing
social engineering. Subject Alternate Name lists on these certifi-
cates also included website names or products and services, such
as “amazon,” “android-browser-update,” “apple,” “facebook,” “mi-
crosoft,” and “security-alert”. Some of these certs had over 30 unique
FQDNs issued to the same actual domain. While containing the
e2LD of other targets, it is unknown why “starwars.com” was the
only target whose e2LD+TLD was embedded. Interestingly, Safe
Browsing only flagged domains in this campaign that used the .top
and .site TLDs. Domains with the .bid TLD may not have become
active in the campaign yet.
Runescape The Runescape campaign targeted runescape.com,
a massively multiplayer online role-playing game. Examples of
these domains include oldschool.runescape.com-ds.ml and
secure.runescape.com-kn.cf. Domains in this campaign were
issued with over 30 unique TLDs, the most common being .ml, .ga,
and .cf. Safe Browsing had the lowest coverage with this campaign,
flagging only 18.89% of the domains we identified.
Wildcard campaigns Our last two campaigns were discovered
from our analysis of wildcard domains in § 5.6. The *.net- campaign
saw domains of the form *.net-ak78.stream and *.net-x69.
stream. The *.co- campaign was similar, with domains like
*.co-j26.bid and *.co-m76.bid. While we do not know what
these campaigns targeted, we do know that Safe Browsing had
much better coverage of these campaigns than the previous two.
Safe Browsing had flagged 63.23% and 73.16% of the domains fitting
these structures, respectively. However, thousands of these domains
were not reported as malicious and still obtained certificates.
Summary There appear to be several very large, coordinated
campaigns of target embedding. Fortunately, with the global view
that CT Logs provide, such campaigns can be straightforward to find
through basic pattern matching. Interestingly, while Google Safe
Browsing identified large percentages (18–73%) of these domains
as unsafe, we are still able to find thousands that were not yet
blacklisted. This indicates that our techniques for identifying and
grouping together what appear to be domain impersonation at-
tacks can be used to help improve the coverage of other tools for
detecting misbehavior.
7 POTENTIAL COUNTERMEASURES
Our longitudinal study reveals several entities who play a signif-
icant role in how attackers launch target embedding attacks. In this
Session 10E: CertificatesCCS ’19, November 11–15, 2019, London, United Kingdom2499section, we ask: whose job should it be to help mitigate this attack?
We step through each of the relevant players and discuss what role
they could play, and the impact that their actions could have.
Browsers Modern browsers incorporate techniques to warn users
about potentially harmful, misleading, or insecure websites. Google
Safe Browsing [18] and other similar services, like PhishTank [35]
use the content of the web page to determine whether it is a threat.
HTTPS-only services, on the other hand, will not have any content
available until they acquire a certificate. Thus, a reactive solution
such as Safe Browsing inevitably misses many of the impersonation
attempts. Browsers have been incredibly successful at mitigating
homograph attacks by adopting Punycode (§3.2). Additional user-
interface updates, or inspecting domains accessed by users for the
presence of target embedding and other forms of impersonation,
may help prevent users from being deceived.
Third-Party Watchdog Certificate Transparency enables third-
party auditors and monitors to ensure the PKI is functioning as
intended. A third party monitor could collect a body of imperson-
ating domains on certificates, and determine if those domains are
phishing or engaging in other unacceptable behavior. They could
also gather a list of impersonating domains that have obtained
certificates but not yet hosted any content, and repeatedly mon-
itor these sites until they go live. A watchdog would know the
instant one of these domains began hosting malicious content, and
add such domains to a blacklist before they have an opportunity to
successfully attack any users.
Facebook now offers a Certificate Transparency Monitoring ser-
vice [14]; after submitting a possible target domain, Facebook issues
an alert when a potentially impersonating certificate is added to
a CT log. Cloudflare crawls CT logs and raises an alert when a
certificate is issued for a customer’s (legitimate) domain [39]. Our
techniques could be incorporated into such services and alert cus-
tomers when their website is the target of an impersonation attack..
However, flagging potential attacks is not enough; ideally, this in-
formation should also be shared with CAs and browsers, so that
they may take action that can directly protect users.
Certificate Authorities CAs are ultimately responsible for issu-
ing the certificates that attackers use. Before issuing certificates,
CAs could ostensibly apply techniques like those presented in this
paper to flag potential impersonating attacks, and then either deny
the certificate request or require a more in-depth vetting process.
Adoption of defenses by just three CAs could potentially address
95.37% of all target embedding attacks (§5.3). But should CAs be
expected to play a role at all?
Let’s Encrypt argues that CAs should not play a role in detect-
ing phishing, as they “make poor content watchdogs” [4]. On the
other hand, the CA/Browser Forum argues that the CA has a re-
sponsibility to flag “high risk” certificate requests and to follow
them up with additional verification (§4). With our techniques, it is
straightforward to identify the targets within a target embedding
domain; a natural extension to the automated CAs of today would
be to issue automated ACME challenges for each of the “apparent”
domains within a FQDN.
These requirements leave open to interpretation the extent to
which a CA must or ought to go to identify so-called high risk
certificate requests. The CA/Browser forum suggests using third-
party phishing repositories, in particular the Google Safe Browsing
list [18] or the Miller Smiles phishing list [31]. As discussed above,
these third-party services tend to use the content of a web page to
determine if it is a threat, and are thus not applicable at the time of
certificate issuance.
Unfortunately, wildcard certificates (§5.6) would complicate ef-
forts to mitigate impersonation attacks at the CA. Any innocuous-
appearing domain with a wildcard could ostensibly be turned into
a target embedding attack with hyphens. One possibility would be
for CAs to raise the bar for obtaining wildcard certificates. Perhaps
the most feasible approach would be for CAs to work alongside
browsers and third parties in determining when wildcard domains
are used for malicious purposes and to revoke those certificates
when necessary.
Summary There is no one entity that could fully defend against
impersonation attacks by target embedding. CAs can serve a pow-
erful role at the time of certificate issuance, but with wildcard
certificates, target embedding attacks may not become evident until
well after issuance. Conversely, browsers can detect impersonations
when users visit a website, but browser-based initiatives like Google
Safe Browsing and PhishTank are reactive, thus missing many of
the impersonations.
As is typical with the PKI [48], security appears to be possible
only if multiple parties work in tandem. We envision CAs submit-
ting to CT logs, third-party watchdogs monitoring and flagging
certificates using techniques like ours, and browsers incorporating
these flags in their Safe Browsing-like initiatives.
8 CONCLUSION
As an unexpected result of training users to look for a “secure lock
icon,” users have become more likely to trust websites hosted via
HTTPS [37]. In this paper, we have shown that this trust has also
made users more susceptible to domain impersonation attacks. We
have also identified a new classification of attack, target embedding,
that is the most effective attack against browsers today (browsers
already defend against homographs, the most effective attack). By
analyzing a longitudinal certificate dataset spanning all HTTPS
certificates collected by Censys, we find several alarming results:
target embedding is on the rise, it is free for attackers to launch, do-
mains include preceding and succeeding tokens indicating phishing
attacks, and attackers are adapting by composing attacks together.
Unfortunately, there is no one clear fix for target embedding: we
argue that multiple players will have to coordinate to effectively fix
this problem. To assist in this effort, we have made our code and
data publicly available at: https://securepki.org
ACKNOWLEDGMENTS
We thank Balakrishnan Chandrasekaran, Dave Choffnes, Bruce
Maggs, Nick Sullivan, Christo Wilson, our shepherd, Paul Pearce,
and the anonymous reviewers for their helpful feedback. This re-
search was supported by NSF CNS grants 1563320, 1564143, 1816802,
1900879, 1901090, and 1901325.
Session 10E: CertificatesCCS ’19, November 11–15, 2019, London, United Kingdom2500REFERENCES
[1] [n.d.]. Netcraft Pre-issuance Certificate Checking. https://www.netcraft.
com/services-for-certificate-authorities/pre-issuance-
certificate-checking/.
[2] 2017.
American Community
Survey
(ACS)
5-year Estimates.
https://www.census.gov/programs-surveys/acs/news/data-
releases/2017/release.html.
[3] 2018. The Spamhaus Project: The World’s Most Abused TLDs. https://www.
spamhaus.org/statistics/tlds/.
[4] Josh Aas. 2015. The CA’s Role in Fighting Phishing and Malware. https:
//letsencrypt.org/2015/10/29/phishing-and-malware.html.
[5] Pieter Agten, Wouter Joosen, Frank Piessens, and Nick Nikiforakis. 2015. Seven
Months’ Worth of Mistakes: A Longitudinal Study of Typosquatting Abuse. In
Network and Distributed System Security Symposium (NDSS).
[6] Devdatta Akhawe and Adrienne Porter Felt. 2013. Alice in Warningland: A
Large-scale Field Study of Browser Security Warning Effectiveness. In USENIX
Security Symposium.
[7] Anti-Phishing Working Group. [n.d.]. Phishing Attack Trends Report – 4th
Quarter, 2018. https://docs.apwg.org/reports/apwg_trends_report_
q4_2018.pdf.
[8] CA/Browser Forum. 2018. Baseline Requirements for the Issuance and Manage-
ment of Publicly-Trusted Certificates. https://cabforum.org/wp-content/
uploads/CA-Browser-Forum-BR-1.5.7-29-Apr-2018.pdf.
[9] Frank Cangialosi, Taejoong Chung, David Choffnes, Dave Levin, Bruce M. Maggs,
Alan Mislove, and Christo Wilson. 2016. Measurement and Analysis of Private
Key Sharing in the HTTPS Ecosystem. In ACM Conference on Computer and
Communications Security (CCS).
[10] A. Costello. 2003. Punycode: A Bootstring encoding of Unicode for Internation-
alized Domain Names in Applications (IDNA). RFC 3492 (Proposed Standard).
http://www.ietf.org/rfc/rfc3492.txt
[11] Rachna Dhamija, J. D. Tygar, and Marti Hearst. 2006. Why Phishing Works. In
ACM Conference on Human Factors in Computing Systems (CHI).
[12] Zakir Durumeric, David Adrian, Ariana Mirian, Michael Bailey, and J. Alex
Halderman. 2015. A Search Engine Backed by Internet-Wide Scanning. In ACM
Conference on Computer and Communications Security (CCS).
[13] Yahia Elsayed and Ahmed Shosha. 2018. Large Scale Detection of IDN Domain
Name Masquerading. In APWG Symposium on Electronic Crime Research (eCrime).
[14] Facebook. [n.d.]. Certificate Transparency Monitoring. https://developers.
facebook.com/tools/ct/subscriptions.
[15] Adrienne Porter Felt, Robert W. Reeder, Alex Ainslie, Helen Harris, Max Walker,
Christopher Thompson, Mustafa Emre Acer, Elisabeth Morant, and Sunny Con-
solvo. 2016. Rethinking Connection Security Indicators. In Symposium on Usable
Privacy and Security (SOUPS).
[16] Anthony Y. Fu, Xiaotie Deng, Liu Wenyin, and Greg Little. 2005. The Methodology
and an Application to Fight against Unicode Attacks. In Symposium on Usable
Privacy and Security (SOUPS).
[17] Evgeniy Gabrilovich and Alex Gontmakher. 2002. The Homograph Attack. Com-
[19] Crane Hassold. [n.d.]. The Mobile Phishing Threat You’ll See Very Soon: URL
Padding. https://info.phishlabs.com/blog/the-mobile-phishing-
threat-youll-see-very-soon-url-padding.
[20] Tobias Holgers, David E. Watson, and Steven D. Gribble. 2006. Cutting through
the Confusion: A Measurement Study of Homograph Attacks. In USENIX Annual
Technical Conference.
[21] Markus Jakobsson, Alex Tsow, Ankur Shah, Eli Blevis, and Youn-Kyung Lim.
2007. What Instills Trust? A Qualitative Study of Phishing. In Usable Security
(USEC).
[22] Panagiotis Kintis, Najmeh Miramirkhani, Charles Lever, Yizheng Chen, Roza
Romero-Gómez, Nikolaos Pitropakis, Nick Nikiforakis, and Manos Antonakakis.
2017. Hiding in Plain Sight: A Longitudinal Study of Combosquatting Abuse. In
ACM Conference on Computer and Communications Security (CCS).
[23] Viktor Krammer. 2006. Phishing Defense against IDN Address Spoofing Attacks.
In International Conference on Privacy, Security and Trust: Bridge the Gap Between
PST Technologies and Business Services.
[24] Ponnurangam Kumaraguru, Steve Sheng, Alessandro Acquisti, Lorrie Faith Cra-
nor, and Jason Hong. 2010. Teaching Johnny Not to Fall for Phish. ACM Transac-
tions on Internet Technology (TOIT) 10, 2 (2010).
munications of the ACM 45, 2 (2002).
[18] Google Safe Browsing [n.d.]. Google Safe Browsing. https://safebrowsing.
google.com.
[25] Chris Larsen. 2009.
Bad Guys Using Internationalized Domain Names
(IDNs). https://www.symantec.com/connect/blogs/bad-guys-using-
internationalized-domain-names-idns.
[26] Let’s Encrypt [n.d.]. Let’s Encrypt. https://letsencrypt.org/.
[27] Eric Lin, Saul Greenberg, Eileah Trotter, David Ma, and John Aycock. 2011. Does
Domain Highlighting Help People Identify Phishing Sites?. In ACM Conference
on Human Factors in Computing Systems (CHI).
//unicode.org/cldr/utility/confusables.jsp.
[28] List of Unicode Confusables [n.d.]. List of Unicode Confusables.
[29] Yabing Liu, Will Tome, Liang Zhang, David Choffnes, Dave Levin, Bruce Maggs,
Alan Mislove, Aaron Schulman, and Christo Wilson. 2015. An End-to-End Mea-
surement of Certificate Revocation in the Web’s PKI. In ACM Internet Measurement
Conference (IMC).
[30] D. Kevin McGrath and Minaxi Gupta. 2008. Behind Phishing: An Examination
of Phisher Modi Operandi. In USENIX Workshop on Large-scale Exploits and
Emergent Threats (LEET).
[31] Miller Smiles Phishing List [n.d.]. Miller Smiles Phishing List. http://www.
https:
millersmiles.co.uk/forum/index.php.
[32] Tyler Moore and Benjamin Edelman. 2010. Measuring the Perpetrators and
Funders of Typosquatting. In Financial Cryptography (FC).
[33] Nick Nikiforakis, Steven Van Acker, Wannes Meert, Lieven Desmet, Frank
Piessens, and Wouter Joosen. 2013. Bitsquatting: Exploiting bit-flips for fun,
or profit?. In International World Wide Web Conference (WWW).
[34] Nick Nikiforakis, Marco Balduzzi, Lieven Desmet, Frank Piessens, and Wouter
Joosen. 2014. Soundsquatting: Uncovering the Use of Homophones in Domain
Squatting. In International Conference on Information Security (ISC).
[35] PhishTank [n.d.]. PhishTank. https://www.phishtank.com.
[36] The Chromium Projects. [n.d.].
IDN in Google Chrome.
https:
//www.chromium.org/developers/design-documents/idn-in-
google-chrome.
[37] Scott Ruoti, Tyler Monson, Justin Wu, Daniel Zappala, and Kent Seamons. 2017.
Weighing Context and Trade-offs: How Suburban Adults Selected Their Online
Security Posture. In Symposium on Usable Privacy and Security (SOUPS).
[38] P. Saint-Andre and J. Hodges. 2011. Representation and Verification of Domain-
Based Application Service Identity within Internet Public Key Infrastructure
Using X.509 (PKIX) Certificates in the Context of Transport Layer Security (TLS).
RFC 6125. https://tools.ietf.org/rfc/rfc6125.txt
[39] Ben Solomon. [n.d.].
Introducing Certificate Transparency Monitor-
ing. https://new.blog.cloudflare.com/introducing-certificate-
transparency-monitoring/amp/.
[40] Proofpoint Staff. [n.d.].
Snowshoe Spamming Brings Scale to Savvy Sub-
domain Phishing Attacks.
https://www.proofpoint.com/us/threat-
insight/post/snowshoe-spamming-brings-scale-savvy-subdomain-
phishing-attacks.
[41] Janos Szurdi, Balazs Kocso, Gabor Cseh, Jonathan Spring, Mark Felegyhazi, and
Chris Kanich. 2014. The Long “Taile” of Typosquatting Domain Names. In USENIX
Security Symposium.
[42] Christopher Thompson, Martin Shelton, Emily Stark, Maximilian Walker, Emily
Schechter, and Adrienne Porter Felt. 2019. The Web’s Identity Crisis: Under-
standing the Effectiveness of Website Identity Indicators. In USENIX Security
Symposium.
[43] Ke Tian, Steve T.K. Jan, Hang Hu, Danfeng Yao, and Gang Wang. 2018. Needle in
a Haystack: Tracking Down Elite Phishing Domains in the Wild. In ACM Internet
Measurement Conference (IMC).
[44] Benjamin VanderSloot, Johanna Amann, Matthew Bernhard, Zakir Durumeric,
Michael Bailey, and J. Alex Halderman. 2016. Towards a Complete View of the
Certificate Ecosystem. In ACM Internet Measurement Conference (IMC).