### Composing Homographs with Target Embedding

Composing homographs with target embedding facilitates the evasion of detection by impersonating domains. Despite this, domains that employ multiple forms of impersonation represent a small but significant portion of all impersonating domains.

### 6. Coordinated Campaigns

Our analysis in §5 identified hundreds of thousands of individual instances of target embedding. In this section, we demonstrate that many target-embedding domains can be pattern-matched to uncover what appear to be coordinated campaigns of impersonation. To this end, we perform a case study analysis of four large-scale campaigns that registered numerous unique domains with a common structure to impersonate the same target. Safe Browsing flagged some of these domains as malicious, but using our methodology, we can determine the extent of Safe Browsing's coverage of these campaigns. The results are summarized in Table 8.

**Table 8: Total number of target-embedded domains and Safe Browsing coverage for four campaigns with over 1,000 unique domains of similar structure.**

| Campaign        | Total Domains | Flagged by Safe Browsing |
|-----------------|---------------|--------------------------|
| starwars.com    | 3,071         | 1,079 (35.14%)           |
| runescape.com   | 4,522         | 854 (18.89%)             |
| *.net-          | 11,765        | 7,439 (63.23%)           |
| *.co-           | 1,926         | 1,409 (73.16%)           |

#### StarWars Campaign
This campaign involved FQDNs of the form `starwars.com.p58vfa15.top` and `starwars.com.dvqdh83l6r.site`. Of the detected websites, 35.14% were flagged by Safe Browsing as employing social engineering. Subject Alternate Name lists on these certificates also included names or products and services such as "amazon," "android-browser-update," "apple," "facebook," "microsoft," and "security-alert." Some of these certificates had over 30 unique FQDNs issued to the same actual domain. While containing the e2LD of other targets, it is unclear why "starwars.com" was the only target whose e2LD+TLD was embedded. Interestingly, Safe Browsing only flagged domains in this campaign that used the `.top` and `.site` TLDs. Domains with the `.bid` TLD may not have become active in the campaign yet.

#### Runescape Campaign
The Runescape campaign targeted `runescape.com`, a massively multiplayer online role-playing game. Examples of these domains include `oldschool.runescape.com-ds.ml` and `secure.runescape.com-kn.cf`. Domains in this campaign were issued with over 30 unique TLDs, the most common being `.ml`, `.ga`, and `.cf`. Safe Browsing had the lowest coverage for this campaign, flagging only 18.89% of the domains we identified.

#### Wildcard Campaigns
Our last two campaigns were discovered from our analysis of wildcard domains in §5.6. The `*.net-` campaign saw domains of the form `*.net-ak78.stream` and `*.net-x69.stream`. The `*.co-` campaign was similar, with domains like `*.co-j26.bid` and `*.co-m76.bid`. While we do not know the specific targets, we do know that Safe Browsing had much better coverage of these campaigns than the previous two. Safe Browsing flagged 63.23% and 73.16% of the domains fitting these structures, respectively. However, thousands of these domains were not reported as malicious and still obtained certificates.

#### Summary
There appear to be several very large, coordinated campaigns of target embedding. Fortunately, with the global view provided by CT Logs, such campaigns can be straightforward to find through basic pattern matching. While Google Safe Browsing identified large percentages (18–73%) of these domains as unsafe, we are still able to find thousands that were not yet blacklisted. This indicates that our techniques for identifying and grouping together domain impersonation attacks can be used to improve the coverage of other tools for detecting misbehavior.

### 7. Potential Countermeasures

Our longitudinal study reveals several entities who play a significant role in how attackers launch target-embedding attacks. In this section, we discuss the roles these entities could play and the impact their actions could have.

#### Browsers
Modern browsers incorporate techniques to warn users about potentially harmful, misleading, or insecure websites. Google Safe Browsing and other similar services, like PhishTank, use the content of the web page to determine whether it is a threat. HTTPS-only services, on the other hand, will not have any content available until they acquire a certificate. Thus, a reactive solution such as Safe Browsing inevitably misses many impersonation attempts. Browsers have been successful at mitigating homograph attacks by adopting Punycode (§3.2). Additional user-interface updates, or inspecting domains accessed by users for the presence of target embedding and other forms of impersonation, may help prevent users from being deceived.

#### Third-Party Watchdog
Certificate Transparency enables third-party auditors and monitors to ensure the PKI is functioning as intended. A third-party monitor could collect a body of impersonating domains on certificates and determine if those domains are phishing or engaging in other unacceptable behavior. They could also gather a list of impersonating domains that have obtained certificates but not yet hosted any content and repeatedly monitor these sites until they go live. A watchdog would know the instant one of these domains began hosting malicious content and add such domains to a blacklist before they have an opportunity to successfully attack any users.

Facebook now offers a Certificate Transparency Monitoring service; after submitting a possible target domain, Facebook issues an alert when a potentially impersonating certificate is added to a CT log. Cloudflare crawls CT logs and raises an alert when a certificate is issued for a customer’s (legitimate) domain. Our techniques could be incorporated into such services and alert customers when their website is the target of an impersonation attack. However, flagging potential attacks is not enough; ideally, this information should also be shared with CAs and browsers, so that they may take action to directly protect users.

#### Certificate Authorities (CAs)
CAs are ultimately responsible for issuing the certificates that attackers use. Before issuing certificates, CAs could apply techniques like those presented in this paper to flag potential impersonating attacks and either deny the certificate request or require a more in-depth vetting process. Adoption of defenses by just three CAs could potentially address 95.37% of all target-embedding attacks (§5.3). However, there is debate over whether CAs should play a role in detecting phishing.

Let’s Encrypt argues that CAs should not play a role in detecting phishing, as they “make poor content watchdogs.” On the other hand, the CA/Browser Forum argues that CAs have a responsibility to flag “high risk” certificate requests and follow up with additional verification. With our techniques, it is straightforward to identify the targets within a target-embedding domain. A natural extension to the automated CAs of today would be to issue automated ACME challenges for each of the “apparent” domains within an FQDN.

These requirements leave open to interpretation the extent to which a CA must or ought to go to identify so-called high-risk certificate requests. The CA/Browser forum suggests using third-party phishing repositories, such as the Google Safe Browsing list or the Miller Smiles phishing list. As discussed above, these third-party services tend to use the content of a web page to determine if it is a threat and are thus not applicable at the time of certificate issuance.

Unfortunately, wildcard certificates (§5.6) would complicate efforts to mitigate impersonation attacks at the CA. Any innocuous-appearing domain with a wildcard could ostensibly be turned into a target-embedding attack with hyphens. One possibility would be for CAs to raise the bar for obtaining wildcard certificates. Perhaps the most feasible approach would be for CAs to work alongside browsers and third parties in determining when wildcard domains are used for malicious purposes and to revoke those certificates when necessary.

#### Summary
No single entity can fully defend against impersonation attacks by target embedding. CAs can serve a powerful role at the time of certificate issuance, but with wildcard certificates, target-embedding attacks may not become evident until well after issuance. Conversely, browsers can detect impersonations when users visit a website, but browser-based initiatives like Google Safe Browsing and PhishTank are reactive, thus missing many impersonations.

As is typical with the PKI, security appears to be possible only if multiple parties work in tandem. We envision CAs submitting to CT logs, third-party watchdogs monitoring and flagging certificates using techniques like ours, and browsers incorporating these flags in their Safe Browsing-like initiatives.

### 8. Conclusion

As an unexpected result of training users to look for a "secure lock icon," users have become more likely to trust websites hosted via HTTPS. In this paper, we have shown that this trust has also made users more susceptible to domain impersonation attacks. We have identified a new classification of attack, target embedding, which is the most effective attack against browsers today (browsers already defend against homographs, the most effective attack). By analyzing a longitudinal certificate dataset spanning all HTTPS certificates collected by Censys, we find several alarming results: target embedding is on the rise, it is free for attackers to launch, domains include preceding and succeeding tokens indicating phishing attacks, and attackers are adapting by composing attacks together.

Unfortunately, there is no one clear fix for target embedding: we argue that multiple players will have to coordinate to effectively fix this problem. To assist in this effort, we have made our code and data publicly available at: https://securepki.org

### Acknowledgments

We thank Balakrishnan Chandrasekaran, Dave Choffnes, Bruce Maggs, Nick Sullivan, Christo Wilson, our shepherd, Paul Pearce, and the anonymous reviewers for their helpful feedback. This research was supported by NSF CNS grants 1563320, 1564143, 1816802, 1900879, 1901090, and 1901325.

### References

[References remain unchanged and are listed as provided.]