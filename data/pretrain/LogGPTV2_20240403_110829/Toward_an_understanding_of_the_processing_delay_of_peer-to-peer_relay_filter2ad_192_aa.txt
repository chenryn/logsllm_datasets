title:Toward an understanding of the processing delay of peer-to-peer relay
nodes
author:Kuan-Ta Chen and
Jing-Kai Lou
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
Toward an Understanding of the Processing Delay
of Peer-to-Peer Relay Nodes
Kuan-Ta Chen and Jing-Kai Lou
Institute of Information Science, Academia Sinica
PI:EMAIL, PI:EMAIL
Abstract-Peer-to-peer relaying is commonly used in real(cid:173)
time applications to cope with NAT and firewall restrictions
and provide better quality network paths. As relaying is not
natively supported by the Internet, it is usually implemented at
the application layer. Also, in a modern operating system, the
processor is shared, so the receive-process-forward process for
each relay packet may take a considerable amount of time if the
host is busy handling some other tasks. Thus, if we happen to
select a loaded relay node, the relaying may introduce significant
delays to the packet transmission time and even degrade the
application performance.
In this work, based on an extensive set of Internet traces, we
pursue an understanding of the processing delays incurred at
relay nodes and their impact on the application performance.
Our contribution is three-fold: 1) we propose a methodology
for measuring the processing delays at any relay node on the
Internet; 2) we characterize the workload patterns of a variety
of Internet relay nodes; and 3) we show that, serious VoIP quality
degradation may occur due to relay processing, thus we have to
monitor the processing delays of a relay node continuously to
prevent the application performance from being degraded.
Index Terms-E-Model, Internet Measurement, Peer-to-Peer
Systems, QoS, VoIP
I.
INTRODUCTION
Voice communication over IP is becoming one of the most
profitable Internet businesses. It has been shown that VolP
users are willing to pay for value-added services, such as
intercommunication with a PSTN phone (dialing to a PSTN
phone and vice versa), voice mails, and call
forwarding.
Although one of the major players, Skype [25], was not the
first company to provide VolP service, but it did pioneer the
delivery of such services to an unprecedented wide range of
end-users. From a technical point of view, we believe that three
factors are responsible for Skype's popularity: the user-friendly
interface, the high quality audio codecs, and the sophisticated
peer-to-peer network infrastructure.
Skype is well-known, or perhaps notorious, for its capability
to "steal" computation and communication resources from
a computer with a Skype instance running. This is because
Skype employs a technique called peer-to-peer relaying, where
the network communications between two call parties can be
made through a third intermediate node, commonly called a
relay node. Peer-to-peer relaying brings the following advan(cid:173)
tages to VolP applications: 1) the voice quality can often be
This work was supported in part by Taiwan Infonnation Security Center
(TWISC), National Science Council of the Republic of China under the grants
NSC 96-2219-E-00I-001, NSC 96-2219-E-OII-008, and NSC 96-2628-E-001(cid:173)
027-MY3.
improved by detouring traffic via a better quality network path,
which can be achieved by using a relay node [21]; 2) a relay
node can help establish connections if both call parties are
behind NATs or firewalls [1, 6, 22]; and 3) relaying enables
data aggregation, which reduces network bandwidth usage
when more than two parties are involved in a conference call.
For these reasons, peer-to-peer relaying is widely employed
by VolP services, such as Skype and Google Talk [7], as
well as by video streaming services, such as AnySee [13] and
PPLive [10].
it
Even though peer-to-peer relaying is beneficial to real-time
applications in many aspects, we argue that its dark side might
be easily overlooked. As relaying is not natively supported
by the Internet,
is currently implemented by deploying
an overlay network at the application layer. In this way, a
packet "forwarded" by a relay node is actually a brand new
IP packet that the node "clones" from the packet to be relayed.
Also, since relay applications are usually run at a normal
priority, their execution could be deferred due to high-priority
tasks, such as system threads, device I/O request handlers,
or foreground jobs. Thus, the time needed for a relay node
to receive, process, and regenerate a relay packet could be
unpredictably long because it depends on the workload of
the node. For these reasons, the extra delays incurred at a
relay node could be considerable and even detrimental to the
application's performance.
In this paper, based on an extensive Internet measurement,
we consider whether peer-to-peer relaying leads to substantial
or even detrimental extra delays. Our analysis is divided into
three parts. First, we describe how we collect the processing
delays of relayed packets from a large set of relay nodes on the
Internet. Second, we analyze and characterize the processing
delays of the relay nodes, and show that the delays are closely
related to the host's activity. Third, we investigate whether the
relay process degrades the quality of VolP calls and whether
such degradation is a general or occasional phenomenon. To
the best of our knowledge, this paper is the first large-scale
study to measure the processing delays introduced by peer-to(cid:173)
peer relaying and their impact on an application's performance.
Our contribution is three-fold:
1) We propose a methodology that can measure the pro(cid:173)
cessing delays at any relay node on the Internet, without
modifying the existing network and system infrastruc(cid:173)
ture.
2) We collect the relay processing delays from a large set of
Internet nodes distributed all over the world. In addition,
1-4244-2398-9/08/$20.00 ©2008 IEEE
410
DSN 2008: Chen &Lou
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:21:03 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
we analyze the sampled processing delays to gain an
understanding of the workload pattern of Internet nodes,
the effect of packet size on relay processing, and the
instability of processing delays.
3) We show that the processing delays incurred at relay
nodes may significantly degrade VoIP quality based on
ITU-T E-model [12] and the delays at relay nodes are
generally unstable.
We consider this paper as a first step in focusing on the
extra processing delays introduced by peer-to-peer relaying.
From our results, we suggest that all real-time peer-to-peer
systems keep track of the workload on relay nodes to prevent
unexpected performance degradation.
The remainder of this paper is organized as follows. Sec(cid:173)
tion II describes related works. We then propose our process(cid:173)
ing delay inference methodology in Section III. In Section IV,
we describe the trace collection methodology and discuss the
quality of our collected traces. In Section V, we analyze a
number of characteristics of the collected relay processing
delays, such as typical workload patterns and stability. In
Section VI, we evaluate the impact of the processing delays
of relay nodes on VoIP quality. Finally, in Section VII, we
present our conclusions.
II. RELATED WORK
this paper is the first
To the best of our knowledge,
to
study the processing delays of peer-to-peer relay nodes and
their impact on the application performance. Thus, there are
no earlier studies directly related to our work. In [14], Liu
and Zimmermann mentioned that the average processing delay
at each overlay node of AudioPeer [29], a commercial voice
chat system, was approximately 30 ms. However, they did not
report how the measurement was conducted and how large and
representative the data set was. One closely related research is
probably that on peer-to-peer relay node selection. A number
of studies [3-5, 11, 15, 21, 27] have been devoted to selecting
relay nodes from a set of candidates to obtain a good quality
network path. However, the selection criteria are mainly based
on the network latency and loss rate, and do not consider
the processing delays introduced by relay nodes. Our work
complements these network-quality-based relay node selection
studies by emphasizing that relay processing delays should
also be considered when selecting the best relay node.
III. PROCESSING DELAY INFERENCE
In this section, we propose a methodology for measuring
the processing delays induced by relaying packets at an
intermediate node. The processing delay is defined as the
time an intermediate node takes to send a data packet to its
destination on behalf of a source host. Delays can be due to
a variety of operations, such as receiving a packet from the
source host, passing it to the relay application (mostly in user
mode) for processing, and forwarding the packet to the target
host.
The processing delay at a relay node is generally unmea(cid:173)
surable unless we place a sniffer to monitor the incoming
and outgoing traffic of the node. Note that even the relay
application cannot measure the processing delays of relayed
packets directly because it has no information about when
a packet arrives at or departs from the system. To measure
processing delays exactly, an application must exploit a kernel(cid:173)
mode packet filter, such as BPF [17], or raise its thread priority
to a high value so that it will always be served immediately.
However, either approach is inadequate for a large-scale de(cid:173)
ployment, as they incur additional resource overhead and may
disturb the execution of the user's own tasks.
Our methodology is designed to measure the processing
delays experienced by relayed packets at a relay node without
any modification to the existing network infrastructure and
peer-to-peer software. In the following, we first define the
terms used throughout this paper. We then explain the basic
rationale behind our inference methodology, and elucidate the
IPID filtering scheme for improving the estimation accuracy.
Finally we evaluate both the basic and improved methods
through an experiment.
A. Term Definition
In this paper, we assume a two-hop relaying scenario in
which every packet from a source host transits an intermediate
node before reaching the destination host.
• Source/destination: A pair of hosts that communicate
with each other through an intermediate host.
• Relay node (relay host): The intermediate host receives
packets from the source and forwards them to the desti(cid:173)
nation. The relay node might change the content of the
relayed packet slightly depending on the application's
context.
• Source packet: A data packet sent from the source host
to the relay node.
• Relay packet: The data packet sent from the relay node
to the destination, which is a copy (verbatim or with slight
changes) of the source packet.
• Ack packet: When a source packet is delivered to the
relay node by TCP, the relay node will acknowledge the
packet by sending a TCP acknowledgement packet back
to the source host. We call this an ack packet.
• Processing delay (PD): The time lapse from the instant
a source packet arrives at a relay node and the instant its
corresponding relay packet leaves the node.
• Data delivery time (DDT): The time lapse from the in(cid:173)
stant a source packet leaves the source host to the instant
its corresponding relay packet reaches the destination.
• Ack response time (ART): The time lapse from the
instant a source packet
to the
instant its corresponding ack packet is received by the
source host.
leaves the source host
B. The Basic Method
Our method is based on the following assumptions, which
are generally observable across current peer-to-peer implemen(cid:173)
tations:
1) The relay node forwards a relay packet to the destination
as soon as it receives a source packet, i.e., no intentional
delays are introduced in relay packet forwarding.
1-4244-2398-9/08/$20.00 ©2008 IEEE
411
DSN 2008: Chen & Lou
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:21:03 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
Source Packet
Relay Packet
Ack Packet
Sender I Receiver, , , , ,
'..
,,,,,.'
Traffic Monitor
Relay Node
2
10
5
50
Data delivery time (ms)
20
100
200
500
Fig. 1.
evaluating the accuracy of processing delay estimation.
Experiment setup for measuring ack packet generation delays and
Fig. 2. The scatter plot of data delivery time and ack response time.
2) The source transmits packets to the relay node by TCP;
therefore,
the relay node will respond with TCP ack
packets upon the receipt of every packet (or every two
packets if the delayed ack option is enabled [18]).
3) The TCP implementation (which generates ack packets)
is running at a high priority, while the relay application
is running at a relatively low priority. We require that ack
packets are elicited with an approximate constant delay
so that they can be taken as a reference for "relaying
without processing delay."
Our basic concept is that, on the arrival of a TCP source
packet, the relay node will respond with two packets: 1) an
TCP ack packet sent back to the source, and 2) a relay packet
forwarded to the destination. These packets are generated by
different parts of the relay node system. An ack packet is
generated by the TCP implementation, which is part of modem
operating systems and normally runs at a high scheduling
priority. On the other hand, a relay packet is generated by
the relay application, such as Skype and PPLive, which is
developed by a third-party vendor and runs at a normal
scheduling priority. As a result, an ack packet can always
be elicited promptly, while it usually takes some time to
generate a relay packet because the relay application can only
get its quantum when high-priority threads have completed
their tasks l . In this way, a relay packet's additional processing
delay can be computed as the time difference between the time
instant the relay packet and the instant its corresponding ack
packet left the relay node.
However, this technique requires us to monitor the incoming
and outgoing traffic of the relay node, which is not practical
for large-scale measurements. To overcome this restriction, we
tactically place the source and the destination hosts at the same
location, which ensures that the ack packet and relay packet
traverse the same network path to the target. By so doing, we
can estimate the processing delay as the difference between the
instant an ack packet arrives at the sender and the instant the
corresponding relay packet reaches the destination host. This
strategy renders large-scale measurements feasible because we
only need to monitor the traffic of the source and destination
hosts.
1) Constancy ofACK Generation Delay: Our method only
works if the TCP implementation generates ack packets with
a constant delay. To verify this assumption, we conduct
experiments on the network topology depicted in Fig. 1. In the
1This statement is somewhat simplified. Even if high-priority tasks have
not been completed, the scheduler will regularly give lower-priority tasks a
chance to be executed in order to avoid starvation.
experiment, all the computers are commodity PCs equipped
with Pentium III, 1 GB RAM, and Windows XP, but
the
traffic monitor is a SuSE Linux running tcpdump. During the
experiments, the source keeps sending 200-byte data packets
at a 30 pkt/sec frequency to the relay node, which then
forwards the packets to their destination. To emulate a heavy
workload on the relay node, 10 different movie clips are
played simultaneously, which generates a considerable CPU
workload (for video decoding and playout) and I/O workload
(for reading audio/video data from the disk).
Because the source/destination nodes and the relay node are
at the same Ethernet LAN, the network delay between them
is negligible. Fig. 2 plots the relationship between the data
delivery time (DDT) and the ack response time (ART) of each
source packet (note that the x-axis is with a log-scale). The
leftmost dense area indicates that a linear relationship between
DDT and ART exists when no other threads are competing
with the relay application for computation cycles. However,
when the relay node is busy handling other tasks, the DDT
increases by orders of magnitude (spread between 0 and 500
ms), while the ART is always less than 0.3 ms. The reason
for such a small ART is that the TCP/IP stack gives a high
priority to serving incoming TCP packets and generates ack
packets at the first opportunity [26]. In contrast, the execution
of a relay application can be deferred for a long time because
the processor serves high-priority jobs, such as kernel-related