title:Seven Months' Worth of Mistakes: A Longitudinal Study of Typosquatting
Abuse
author:Pieter Agten and
Wouter Joosen and
Frank Piessens and
Nick Nikiforakis
Seven Months’ Worth of Mistakes:
A Longitudinal Study of Typosquatting Abuse
Pieter Agten∗, Wouter Joosen∗, Frank Piessens∗ and Nick Nikiforakis†
∗ iMinds-DistriNet, KU Leuven,
{firstname}.{lastname}@cs.kuleuven.be
† Department of Computer Science, Stony Brook University,
PI:EMAIL
Abstract—Typosquatting is the act of purposefully registering
a domain name that is a mistype of a popular domain name.
It is a concept that has been known and studied for over 15
years, yet still thoroughly practiced up until this day. While
previous typosquatting studies have always taken a snapshot of
the typosquatting landscape or base their longitudinal results
only on domain registration data, we present the ﬁrst content-
based,
longitudinal study of typosquatting. We collected data
about the typosquatting domains of the 500 most popular sites of
the Internet every day, for a period of seven months, and we use
this data to establish whether previously discovered typosquatting
trends still hold today, and to provide new results and insights
in the typosquatting landscape. In particular we reveal that,
even though 95% of the popular domains we investigated are
actively targeted by typosquatters, only few trademark owners
protect themselves against this practice by proactively registering
their own typosquatting domains. We take advantage of the
longitudinal aspect of our study to show, among other results,
that typosquatting domains change hands from typosquatters
to legitimate owners and vice versa, and that typosquatters
vary their monetization strategy by hosting different types of
pages over time. Our study also reveals that a large fraction of
typosquatting domains can be traced back to a small group of
typosquatting page hosters and that certain top-level domains are
much more prone to typosquatting than others.
I.
INTRODUCTION
Domain names and the underlying domain name resolution
protocol are arguably one of the linchpin technologies that have
allowed the modern web to expand to its current dimensions.
Even though users increasingly rely on search engines to
ﬁnd interesting and relevant content, domain names are as
important as ever. This is exempliﬁed by ICANN’s constant
rollout of hundreds of new Top-Level Domains (TLDs) such
as .xxx, .guru, and .email, which were created to allow
institutes and individuals to obtain relevant domain names that
are long unavailable in the overcrowded traditional TLDs.
The importance of domain names has not gone by un-
noticed by unscrupulous individuals who wish to proﬁt at
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’15, 8-11 February 2015, San Diego, CA, USA
Copyright 2015 Internet Society, ISBN 1-891562-38-X
http://dx.doi.org/10.14722/ndss.2015.23058
the expense of others. In the nineties, some people started
registering domain names including trademarks and brand
names not belonging to them, with the hope of later selling
them to their rightful owners at a higher price. This practice
was named domain squatting and many variations of this type
of attack have emerged over the years, with perhaps the most
popular and exploited type being typosquatting.
In typosquatting, an attacker abuses the fact
that real
human users may mistype a URL while typing it in their
browser’s address bar or email client. As such, a typosquatter
can register vacebook.com and capture the trafﬁc of users
who mistype facebook.com and would otherwise receive
an error in their browsers. As a matter of fact, in May 2013,
Facebook was awarded 2.8 million dollars in damages caused
by typosquatting, as well as over 100 typosquatting domains
that were registered and monetized by typosquatters [22].
The prevalence of typosquatting has attracted the attention
of multiple researchers who attempted to map the typosquat-
ting landscape,
identify the domains that are targeted the
most, and discover the preferred monetization strategies of
typosquatters [2], [8], [16], [23], [25]. What these studies
have in common, is that they either characterize a snapshot of
typosquatting activity through a single crawling effort over a
limited period of time, or limit the longitudinal aspect of their
study to domain registration data only, without investigating
changes in the domains’ content.
In this paper, we present the ﬁrst content-based typosquat-
ting experiment that studies the typosquatting phenomenon
longitudinally, i.e., in time. Instead of reporting on a single
snapshot of the typosquatting landscape, we performed a
seven-month-long experiment
in which we visited the ty-
posquatting domains targeting the 500 most popular sites of
the Internet every day. Through the collection of more than
900 GB of typosquatting data, our study allows us not only to
measure typosquatting at a large scale but also to investigate
the changes of typosquatting domains over time, allowing us
to answer questions that could not be answered with a single
snapshot of typosquatting activity.
Among other results, we ﬁnd that, even though 95% of
the most popular domains on the Internet are targeted by
typosquatters, most of them do not use defensive registrations
as a means of protecting their identity and their clients. We also
ﬁnd that a large fraction of all possible typosquatting domains
for short popular authoritative domains is already registered,
and that typosquatters are hence increasingly targeting longer
domains. Making use of the longitudinal aspect of our study,
we discover that typosquatters are actively switching between
monetization strategies for the domains that they own, and
are also on the look-out for expiring registrations of popular
domain names. We also show that 50% of all typosquatting
domains can be traced back to just four typosquatting page
hosters. Finally, on the policy-side, we observe that differences
in domain price setting and the availability of out-of-court
domain dispute resolution procedures between different TLDs,
have a signiﬁcant effect on the prevalence of typosquatting.
Our main contributions are:
• We report on the ﬁrst content-based longitudinal study
of typosquatting abuse, consisting of over 900 GB of
data gathered over a period of seven months.
• We verify whether previously discovered typosquat-
ting trends still hold today.
• We provide new results and insights in the typosquat-
ting landscape, based on both the static and longitu-
dinal aspects of our data.
• We show that
the adoption of strict policies and
easy dispute-resolution procedures from registries, can
decrease typosquatting abuse.
The rest of this paper is structured as follows. In Sec-
tion II, we provide background information on typosquatting
in general and on the way our data gathering experiment
was set up. Section III describes the main results found by
our experiment. Section IV describes related work and ﬁnally
Section V concludes.
II. BACKGROUND
A. Typosquatting Models
The most frequently occurring domain name typos are
those that have a Damerau-Levenshtein distance of one from
a popular domain name [3],
i.e., domain names resulting
from a single character insertion, deletion, substitution or
adjacent character permutation from a popular domain. When
the inserted or substituted character is adjacent to the original
character on a QWERTY keyboard, we say the typosquat-
ting domain also has a “fat-ﬁnger distance” of one [16]. In
2006, Wang et al. categorized typosquatting domains into ﬁve
different categories [25]. Based on those categories and as-
suming the authoritative domain example.com and intended
URL www.example.com, we consider the following ﬁve
typosquatting models for our study:
1) Missing-dot typos: The dot following “www” is
2)
3)
4)
5)
forgotten, e.g., wwwexample.com
Character-omission typos: One character is omitted,
e.g., www.exmple.com
Character-permutation typos: Consecutive charac-
ters are swapped, e.g., www.examlpe.com
Character-substitution typos: Characters are re-
placed by their adjacent ones, given a speciﬁc key-
board layout, e.g., www.ezample.com where “x”
was replaced by the QWERTY-adjacent “z”.
Character-duplication typos: Characters are mistak-
enly typed twice, e.g., www.exaample.com
While one can likely come up with more ways of including
typos in a domain name, e.g., a wrong domain TLD, in this
work, we limit ourselves to the typosquatting domains that
can be generated following the aforementioned typo models.
We also limit ourselves to domains resulting from a single
application of one of these models, since those are more likely
to be typed by a user than domains containing multiple typos.
B. Data Gathering
To gather the data required for our longitudinal study, we
set up two automated crawlers, which where supplied with
the Alexa top 500 domains of April 1, 2013 as input. The
ﬁrst crawler generates the typosquatting domains for each
authoritative domain in the input, according to the aforemen-
tioned models. For each authoritative and generated domain,
the crawler ﬁrst determines whether the domain resolves to an
IP address. If so, the crawler visits the web page hosted on the
domain using PhantomJS1, a headless JavaScript-enabled web
browser. After loading the web page, the crawler waits for 10
seconds, allowing the page to load dynamic content or perform
a redirect. Finally, the crawler saves the IP address, ﬁnal URL,
HTML body and a screenshot of the page to disk. The crawler
was conﬁgured to process the entire list of domains daily, for a
period of 7 months starting at April 1, 2013 and running until
October 31, 2013. The crawl was duplicated onto a second
machine to provide redundancy in case of system failure. In
order to prevent excessive resource usage and to minimize
the chance of our crawlers being blocked by typosquatting
domains, duplicate typosquatting domains were ﬁltered out
and the rate at which the crawlers visit domains was set to the
minimum value that still allows a crawl to ﬁnish within a small
margin of 24 hours. In total, 28,179 potential typosquatting
domains were generated, out of which 17,172 resolved to an
IP address at least once during our study.
The second crawler was conﬁgured to perform a WHOIS
lookup for every domain ever successfully resolved by the
HTTP crawler. The WHOIS responses (if any) were parsed
using Ruby Whois2 and then saved to disk. The crawler was
conﬁgured to process all domains once per week, over the same
time period as the HTTP crawler. The slower one-week crawl
interval was needed to respect the acceptable use policies of
the queried WHOIS servers.
One irregularity that occurred during our data gathering
period is that the crawl rate of our crawlers had to be increased
during the week of August 21, to accommodate for a planned
power interruption of our crawling machines on August 27
and 28. The possible effects of this irregularity are discussed
in Section III-B.
C. Analysis
Our crawlers collected over 900 GB worth of data during
the data gathering period, consisting of 3,389,137 web pages
and 424,278 distinct WHOIS records. In order to analyze
this data, we classiﬁed the collected pages into the categories
listed in Table I. The third column of this table indicates for
each category whether we consider it a legitimate, malicious
or undetermined use of a domain name. Although most of
1http://phantomjs.org/
2http://ruby-whois.org/
2
the malicious categories are actually in a legal gray area, we
mark them as malicious because these practices are set up to
deceptively extract proﬁt from users’ mistypings.
As a ﬁrst step towards classifying the collected pages
into the selected categories, we tried to automatically divide
the pages into clusters. Since some types of typosquatting
pages (such as generic ad parking pages) are likely to target
many different authoritative domains, we decided to cluster
the pages based on visual appearance rather than domain-
speciﬁc properties such as the page’s domain name or the
corresponding authoritative domain. To measure the visual
appearance of a page, we used the concatenation of a per-
ceptual hash of the page’s screenshot and a locality-sensitive
hash of its HTML body. The perceptual hash of an image is
a ﬁxed-length bit vector that represents a ﬁngerprint of that
image. Unlike cryptographic hashes, which give a drastically
different output for small changes in the input, perceptual
hash functions are designed to produce similar outputs for
similar inputs. A locality-sensitive hash is based on the same
principle, but works on textual data instead of multimedia
ﬁles. These hashes allow us to programmatically compare the
screenshots and HTML bodies of the collected pages, in order
to group them into clusters of similar pages. The concrete
perceptual and locality-sensitive hash algorithms we used are
the aHash3 and the Nilsimsa4 algorithm respectively, which
were selected based on an evaluation of their performance on
a small subset of the dataset that was clustered manually. Using
these hash functions and a custom clustering algorithm based
on fastcluster [17], the 3,389,137 collected web pages were
automatically grouped into 8,102 clusters.
After this initial clustering, we spent approximately two