Web漏洞类型其实范围挺广泛，从扫描的角度来看，主要可以分为通用未知漏洞、第三方已知漏洞、主机弱口令、弱点规则等；比较麻烦的是第三方已知漏洞和弱点规则的收集整理，说实话没有捷径可走，只能通过人工去进行筛选收集；针对弱点规则，唯一比较欣慰的是可以通过SRC报告的历史漏洞进行查漏补缺，但对于第三方已知漏洞就只能通过公开漏洞库、官方安全消息进行补充，这需要专门的人力进行，特别针对历史的漏洞，更需要大量人力去搜集整理，这时候安全社区的优势就体现出来了，要么去和安全社区合作，要么就只能通过SRC以安全社区的思路进行收集，依靠小部分人力总会有所遗漏。
比较庆幸的是，我们有IDC全流量（其实全流量是个宝贝），将全流量导入到waf规则集，关注拦截的记录中是否存在扫描所遗漏的规则；同时针对waf未识别的流量进行流量分析，通过机器学习的方法来识别出潜在感兴趣记录，然后人工分析来识别规则是否覆盖；当然前提是需要拥有众多业务，攻击者也希望以此作为目标进行扫描探测或攻击尝试。
2.非传统扫描方式
Web存在一部分漏洞，按照传统思路其实不适合扫描，或者说很难扫描，这时候需要换种思路进行考虑，比如通过xss平台解决一部分存储型xss的难题，通过回显平台去解决无回显漏洞的难题，同时我们还会去尝试以扫描的方式去解决部分csrf，甚至去尝试解决越权访问的难题。
其实就是换种思路让不可能变成可能，接着说存储型xss，其扫描的难点就在于输出点定位，大部分扫描方式只能遍历同一域名的所有url来寻找输出点，这种检测思路对于大型互联网企业来说简直就是灾难（根据上面更快的分析逻辑），我们需要另寻思路，除了依赖上面的xss平台解决一部分case，还有其他方式吗？其实是有的，我们可以思考存储型xss最可能出现在哪？其实最有可能出现在一个请求的直接响应中，或者出现在一个请求后的紧接着的一个请求响应中（存储型xss必须要交互增加一些内容的，基于人的习惯，自己增加的内容自己往往会去查看是否成功等，这意味着下一个请求就很有可能是新增内容的输出点），基于这样的考虑，完全可以依靠全流量统计分析出访问链接直接的顺序关系，通过这种方式来解决部分存储型xss，而不至于遍历域名的所有url这种耗费资源和性能的事情。
3.数据中心
收集最全的url作为扫描输入源，这一直就是数据中心的终极目标，当然url唯一且干净也是数据中心的重要目标；为了收集更全的url绞尽了脑汁，除了IDC全流量，还考虑依托OA全流量，通过主机agent去收集线上业务访问日志、甚至收集线下流量导入到线上，当然还有爬虫，甚至还有用户主动上传；但不幸的是，库中收集的流量还是十分有限，绝大部分漏报都是流量缺失导致，这也是下一步需要考虑的重点。
4.异常监控
扫描平台后端是一个基于云的分布式扫描集群，逻辑相对比较复杂；为了监控异常，需要关注扫描任务的完整生命周期：一个url的漏扫，需要关注url是否存在于数据中心、是否推送到扫描集群扫描、是在集群的那个节点上扫描的、扫描过程中是否出现异常、当时是否扫出漏洞、漏洞是否推送成功、人工是否已经check发单等所有关键节点；同时为了监控扫描平台的异常，还需要关注每周漏洞产出的趋势、数据中心中url趋势、扫描的耗费时间趋势等等。
##### （三）更准（准确率）
更准：主要指准确率，要求更低的误报，误报产生的原因很多，这里仅列几点说明：
1.扫描方式引起
还是以反射型xss为例，以发送探测包的方式来替代遍历payloads的方式，虽然规避了漏报和提高了性能，但是误报也伴随而来；通过定位输出位置及场景来确定是否存在xss，但是xss的最终形成是需要依赖浏览器进行解析，所以必然存在误报：比如以json串输出，输出点在单引号或者双引号中，并且引号被转义不能被闭合，但是输出格式是html（本来json输出content-type应该正确设置为text/json等，但有些非要设置为text/html，通过场景来分析是不会存在xss的，但因为输出格式问题，浏览器会当做html进行解析从而形成漏洞）。
当然上面列举的这种情形，通过增加一步验证即可解决（根据场景构造特定payload进行验证确认）
2.扫描规则引起
扫描漏洞的确认一般都是通过匹配规则来进行的，规则考虑的欠妥都会引起误报。
最常见的就是扫描特征出现在正常响应中，比如命令执行，通过cat
/etc/passwd文件来检测是否存在漏洞，但是特征出现在搜索结果中明显就是误报；当然这里可以通过计算一些动态值予以规避，但悲剧的是动态值一样可能出现在响应中，这时候就需要考虑发两次包计算两次动态值（其实发包量对扫描而言弥足珍贵，多一次包就意味着扫描及时度没法达成，其实及时度、漏报率、准确率是相互制约的）
3.漏洞类型引起
一些不适合扫描的漏洞类型，比如越权访问，通过扫描方式进行必然伴随大量误报，这个除非革新的扫描思路出现，不然目前很难消除误报，而且这样的漏洞类型数目还不在少数。
4.扫描性能引起
为了扫描性能考虑，减少发包量，针对弱点规则，数量众多规则一起检测，除了规则本身不严谨造成的误报以外，更多需要关注规则的交叉影响：比如遇到这种场景，不仅仅请求正常路径响应泄露信息，而是请求任何路径都是响应泄露信息，这种就会造成规则的交叉影响。
##### （四）更智能
更智能：扫描平台寄希望尽量完全自动化的方式去解决一切问题，尽量减少人工的参与量及运维量，我们设计之初就是将更智能作为重要指标进行考量，这里列举几例说明：
1.热备上线
写第一篇文章时其实简单介绍过热备上线相关情况，安全扫描poc在方案调研及实现过程中，由于调研的不全面或者考虑的不严谨，肯定会出现误报或者漏报问题，这时候就需要通过更新poc予以解决，现在的难点是：扫描集群时刻都有任务在运行，为了更新任务只能热备上线，不然只能将未跑完的任务全部kill掉，这样既浪费扫描资源，又严重影响扫描及时度。
通过内置升级更新模块，当需要更新某个POC时，可以把POC及对应版本推送到POC更新模块，POC更新模块比对新旧两个版本并进行处理（只有当推送的POC版本大于当前版本时才更新，然后删除旧版本，给当前POC打上待升级标识）；当积累到一定数量的待升级POC，或者固定的周期时（这些都可以在调度程序中进行设置），调度程序启动升级准备工作，标识所有存活容器为待升级状态，当某个docker容器执行完当前基本单元（"单poc+单url"）返回结果后，调度程序发现该容器状态为待升级状态，则不再分配扫描任务，并且启动POC更新程序，POC更新程序去升级更新模块查询那些POC带有待升级标识，将所有待升级标识的POC自动拉取到docker容器中，并与容器中的当前版本进行比对，同样POC版本大于当前容器中的版本时才进行更新处理，更新完成以后，通知调度程序升级完成；调度程序获取到相关状态后，重置容器的状态为正常状态，并且可以继续进行扫描任务的派发及执行，基本可以做到不干扰当前运行任务情况下，更新升级，做到热备上线。
2.扫描能力自我完善
前面通过一系列动作使扫描平台日臻完善，但一时的优秀不是目的，持久的优秀才是最终目的，那么后期通过什么方式来持续保障或者完善扫描平台呢？除了前面介绍的通过全流量进行payloads自动收集、查漏补缺以外，我们还可以搭建众多主流扫描引擎来进行外界报告漏洞的自动能力对比，持续提升扫描能力；当然SRC
poc收集、第三方平台合作、通用漏洞实时分析&新增扫描poc也在同步进行中。
3.异常自动诊断恢复
监控到扫描体系中的任一阶段存在异常时，启动自动诊断程序进行判断，并根据具体场景来进行后续处理，续扫、重扫或者启动报警人工干预等，第一篇文章中讨论了部分case，这里就不再详细阐述了。
#### 三 总 结
整套体系化建设实践后，大家应该比较好奇我们最终的效果对吧？其实“分布式Web漏洞扫描服务建设实践”系列第一篇文章的时候，我们有简单说过衡量指标的一些统计数据：扫描出来的漏洞准确率达到了98%以上，基本可以做到无需人工check；输入源URL存在的情况下漏报率更是控制在0.5%以下，即使算上输入源URL缺失导致的漏扫，线上的自主发现率也已经达到了90%以上（扫描发现的漏洞占所有线上漏洞的比例，线上漏洞的发现途径有很多，比如扫描发现、外界SRC报告、友商报告、人工渗透测试等）；每天新增URL例行任务2小时内结束，全量URL例行任务2天内结束；随着漏洞检测能力的持续提升，安全事件中因常规型漏洞（扫描器很难自动扫描发现的漏洞，比如越权、逻辑、CSRF漏洞类型）引起的占比也由15年之前的52%降低到目前的18%左右；SRC外界白帽子报告的线上漏洞中常规型漏洞占比也由15年之前的72%降低到目前的34%左右，随着今年自研的白盒及灰盒检测能力的持续上线，这个占比肯定会下降得更加明显，当然随之我们的漏洞检测重心也会往越权、逻辑等漏洞探索，我们的目标很明确：期望尽最大可能通过自动化的方式低成本的去解决线上绝大部分漏洞问题（我们人力真的很少，哭样）。
今天就说到这里，感兴趣同学可以继续关注后续"分布式Web漏洞扫描服务建设实践"系列技术文章。最后这句感悟依然分享给大家“扫描技术虽已成熟，但只有精心耕耘方能知晓其精髓，而刚触及其精髓才知挑战依旧”，下篇文章“扫描框架实践”再见。
* * *