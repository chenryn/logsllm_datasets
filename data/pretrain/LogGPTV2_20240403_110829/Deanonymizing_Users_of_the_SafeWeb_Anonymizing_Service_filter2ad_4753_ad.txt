to 
communicate who had been infiltrated.  However, the 
local  identity  acquisition  threat  of  Section  5.8  would 
remain.   
spyware  might  be  unable 
the 
Client-side JavaScript’s access to network, cookie, and 
frame  functionality  are  generally  concentrated 
in 
externally  hosted  facilities,  such  as  the  Window  and 
Document object implementations made available by a 
Web  browser.    Therefore,  a  sandbox  constructed 
around JavaScript (and other scripting languages, such 
as  VBScript)  may  be  able  to  restrict  scripts  from 
mounting  our  attacks.    But  the  result  would  be  less 
effective than a network component  solution, since the 
tightrope balance threat of Section 5.6 would remain. 
7.  Related work 
Like  SafeWeb,  the  Anonymizer  [2]  and  SiegeSurfer 
[48] services also use a monolithic rewriting engine to 
provide  some  Web  user  anonymity.    Onion  Routing 
[54],  Crowds  [37],  Freedom.net  [4],  WebMIXes  [3], 
and  Tarzan  [16]  use  considerably  more  sophisticated 
techniques  to  provide  stronger  anonymity  against 
determined, distributed, and cooperating adversaries.   
Systems specifically designed for censorship resistance 
include  Publius  [62],  Tangler  [61],  Freenet  [8],  Free 
Haven  [10],  and  Infranet  [12];  of  these,  Infranet 
probably  has  the  strongest  focus  on  user  surveillance 
resistance.    Popular  peer  to  peer  file  sharing  systems 
such as Gnutella, Morpheus, and Kazaa are difficult for 
censors  to  shut  down,  but  their  design  emphasis  has 
more 
than 
censorship. 
the  “freedom 
to  do  with 
to  share” 
None of these systems sanitize JavaScript by rewriting 
it (although Anonymizer seems to be considering that 
approach); they either somehow remove the JavaScript 
they  see  or  direct  users  to  disable  JavaScript  at  the 
browser  level  when  applicable.      Many  of  these 
systems do not protect against attackers who use a Web 
cache timing approach to recognize users [14].   
Java  applets  run 
in  a  highly  studied  sandbox 
environment  [18]  that  probably  has  applications  to 
JavaScript  as  well.    A  recent  bibliography  of  code 
containment papers is available in [1]. 
8.  Discussion 
Although  SafeWeb  and  PrivaSec  also  attracted 
corporate  employees  trying  to  avoid  goof-off  filters 
such  as  Websense  and  SurfControl  [46],  the  class  of 
users most threatened by the SafeWeb weaknesses are 
citizens  of  countries  with  censorship  policies  that  are 
realized  in  part  through  national  content  blocking 
firewalls.    This  is  because  the  stakes  are  so  high  for 
these  users,  and  because  their  governments  have 
already  proven  their  interest  in  scrutinizing  network 
connections.  A government that wished to identify its 
SafeWeb  users  and  their  master  cookies  could  just 
periodically intercept HTTP connections crossing their 
firewall  and  respond  with  an  HTTP  redirect,  via 
SafeWeb,  to  their  own  server  containing  code  that 
grabs  master cookies.   Another approach  would be to 
use  cross-site  scripting  weaknesses  in  Web  bulletin 
board systems to deposit exploit code on sites likely to 
be  visited  by  misbehaving  users.    Easier  still,  they 
could  simply  buy  advertising  space  for  their  exploit 
code.   
Ironically,  SafeWeb  helps  the  censors  by  narrowing 
their search  to those  users  who clearly  know they are 
doing  something  evasive  when  they  contact  SafeWeb 
[9,47].    A  firewall  operator  can  generate  a  list  of 
SafeWeb users by looking for connections to the main 
SafeWeb  site  or  by 
(always 
unencrypted) SafeWeb certificate in SSL sessions. Our 
attacks  are  not  required  for  this;  they  really  target 
SafeWeb’s  anonymity,  not  its  censorship  avoidance. 
However, we again observe that a government with the 
power  to  block  Web  sites  at  a  national  firewall  may 
also be willing to punish those who try to circumvent 
the firewall. 
looking 
for 
the 
SafeWeb  has  readily  acknowledged 
that  foreign 
censors could easily identify  those in their population 
who  use  SafeWeb,  saying  that  using  such  evidence 
against  users  would  be  “draconian”  [25].    But  by 
obtaining  SafeWeb  master  cookies  or 
session 
transcripts with our attacks, the censors have increased 
leverage:  they  learn  not  only  who  uses  SafeWeb,  but 
they also learn which sites the users wanted to secretly 
visit.    Inspecting  the  cookie  values  might  reveal 
identification numbers possibly keyed to memberships, 
subscriptions,  commercial 
transactions,  or  even 
authentication  codes  [17].    While  using  this  type  of 
evidence against users may also count as draconian, it 
is potentially much better evidence. 
SafeWeb  has  basically  taunted  the  governments  of 
China,  Saudi  Arabia,  Bahrain,  and  United  Arab 
Emirates with this technology in a strange kind of BB-
gun diplomacy effort [21,39].  The stakes are real for 
users in these countries, yet we don’t see any evidence 
that they understood the limits of the SafeWeb system. 
We  don’t  even  know  whether  anyone  has  ever 
attempted  to  identify  SafeWeb  users  outside  of  a 
laboratory,  but  it’s  certainly  possible.    There  is  no 
visible  indication  to  the  user  when  the  attacks  are 
attempted,  and  since  the  attacks  do  not  target  the 
SafeWeb  server  computers  themselves,  there  is  little 
reason that SafeWeb would have detected them either.  
An  attacker  would  presumably  want  to  leave  the 
vulnerabilities intact in order to use them again later. 
8.1.  Web servers attacking their own users 
Attacks  such  as  these  could  be  a  very  useful  aid  to 
investigators.    For  example,  the  FBI  could  insert 
exploit  code  onto  its  “Amerithrax”  Web  page  [11]  in 
order  to  track  down  visitors  who  attempt  to  use 
SafeWeb  to  anonymously  read  about  its  investigation 
into  the  U.S.  anthrax  attacks  of  October  2001.    (The 
FBI’s  DCS-1000  Carnivore  system  would  not  help 
with  this:  it  is  only  useful  when  placed  near  the 
investigation target, which we assume is still unknown.  
Besides,  Carnivore  can’t  decrypt  the  SSL  connection 
between the suspect and SafeWeb [23].) 
8.2.  Passive attack resistance 
Some  of  SafeWeb’s  users  simply  do  not  want  their 
identity recorded in log files to be mined later and are 
not concerned that someone will actively try to identify 
them.    SafeWeb  does  help  keep  IP  addresses  out  of 
routinely  maintained  Web  server  log  files.    Although 
our  attack  samples  are  short,  they  seem  unlikely  to 
arise without malicious intent.   
However,  we  are  left  wondering  about  a  November 
2001  Usenet  article  [56],  in  which  a  SafeWeb  user 
wrote: 
I am trying out Safeweb which is a proxy server 
that  uses  SSL  between  my  computer  and 
safeweb.com.    For  a  lot  of  typical  sites  like 
yahoo.com  and  msnbc.com  I  get  the  prompt 
"This page contains both secure and nonsecure 
items.    Do  you  want  to  display  the  nonsecure 
items?"    Why  would  I  be  getting  nonsecure 
items if everything is going through a SSL proxy 
server? 
We see two possibilities.  The first is that some content 
evaded  the  rewriting  engine  unsanitized.  Internet 
Explorer saw that this non-SSL content (referred to by 
the  original,  bare  URL)  appeared  within  SSL  content 
delivered  from  safeweb.com,  and  so  it  raised  the 
dialog.  This is unlikely to be a malicious attack, since 
a clever attacker would have avoided the dialog simply 
by making sure that any URLs used in the attack also 
used SSL.   
The second possibility is that the user simply witnessed 
bugs in Internet Explorer prior to version 6.0 that can 
spuriously cause the warning dialog box to appear [30].   
9.  Vendor response 
We  notified  SafeWeb  of  our  first  discoveries  in 
October  2001.    At  that  time,  they  acknowledged 
vulnerabilities along the lines of our observations and 
indicated they would investigate.  We also submitted a 
draft  version  of  this  paper  to  both  SafeWeb  and 
PrivaSec  in  January  2002.    In  response,  SafeWeb 
explained  that  their  consumer  service  is  no  longer  in 
operation,  and  that  they  would  try  to  address  these 
vulnerabilities  if  they  reestablish  their  service.    They 
wrote  that  during  the  past  year  they  have  been 
concentrating  on  the  enterprise  security  market,  in 
which  these  vulnerabilities  are  unlikely  to  play  any 
role.  They also noted that they have no evidence that 
any  widespread  attacks  have  taken  place.    After  a 
version  of  this  paper  appeared  in  February  2002, 
SafeWeb  delivered  modified  code  to  PrivaSec  that 
allowed  its  service  to  work  even  if  JavaScript  is 
disabled at the browser level (cf. Section 6.2). 
PrivaSec  stated  that  they  are  reviewing  their  options 
before  launching  a  subscription  service  based  on  the 
SafeWeb  technology.    PrivaSec’s  service  deletes  the 
master  cookie  at  the  end  of  each  browser  session  by 
default, so the master cookie is not quite as valuable to 
an  attacker  when  it  is  first  obtained.    However,  as 
described in Section 5.1.1, this setting can be changed 
by  an  attacker  (unless  cookies  are  disabled  at  the 
browser  level).    At  the  time  of  writing,  all  of  our 
attacks  still  work  within  PrivaSec’s 
technology 
preview. 
10. Conclusion 
Privacy  and  anonymity  tools  face  the  surreal  task  of  
removing data intrinsic to an environment in the hope 
that this will measurably decrease real (and imagined) 
user risks.  When such an intangible service is offered, 
it  should  be  no  surprise  to  see  users  flocking  to  the 
friendliest solution that claims to work.  
Still,  we  were  surprised  to  find  that  a  high-profile 
external review team did not object to weaknesses such 
as 
to 
ComputerWorld magazine [60]: 
this  paper,  according 
those  described 
in 
Jon  Chun,  president  and  co-founder  of 
SafeWeb,  said  his  company's  relationship  with 
In-Q-Tel  has  been  critical  to  its  technology 
development.  
"It  has  put  SafeWeb  and  our  technologies 
through the rigors of the CIA's stringent review 
process, which far exceeds those of the ordinary 
enterprise  client,"  said  Chun.  "This  is  a  very 
significant seal of approval."  
Adding  in  privacy  and  security  features  can  put  the 
user at greater risk of privacy and security problems if 
an  attacker  can  co-opt  enough  of  the  infrastructure.  
We  have  seen  how  attackers  can  easily  evade 
SafeWeb’s  sanitization  effort  and  gain  unrestricted 
access  to  the  JavaScript  interpreter.    Once  there,  they 
can  exploit  SafeWeb’s  rejection  of  the  “same  origin” 
rule for JavaScript frames and its master cookie design 
to obtain the victim computer’s IP address and cookies, 
and  even  deposit  spyware  for  the  remainder  of  the 
SafeWeb  session.    SafeWeb’s  design  undermined  not 
only  the  privacy  properties  offered  by  SafeWeb,  but 
also the standard privacy features of Web browsers.  
SafeWeb’s  failure  to  sanitize  simple  equivalents  for 
dangerous  constructs  typifies  the  perils  of  ad  hoc 
security  programming.  Security  systems  ought  to  be 
designed  to  allow  only  what  is  believed  to  be  safe, 
rather  than  preventing  that  which  is  known  to  be 
unsafe. 
Finally,  centralizing  what  was  previously  separate  is 
not  an  ideal  way  to  provide  privacy.  Whereas  the 
Internet was designed in part on the principle of “don’t 
put all your eggs in one basket” (e.g., stateless routers), 
SafeWeb  appears  to  be  based  on  the  Pudd’nhead 
Wilson  design  principle:  “put  all  your  eggs  in  one 
basket – and watch that basket!” [57]. In the SafeWeb 
scheme, all cookies previously the separate property of 
a.com,  b.com,  c.com,  etc.,  now  all  belong 
to 
safeweb.com – thus allowing what would otherwise be 
cross-domain  cookie  scarfing.  Similarly,  what  would 
otherwise  be  cross-domain  frame  attacks  are  allowed 
because  everything  is  happening  under  SafeWeb’s 
auspices. And instead of a user scattering evidence of 
their Web site visits across a myriad of Web site logs, 
they  are  now  conveniently  stockpiled  at  a  single 
location, safeweb.com (albeit deleted after seven days). 
Some other anonymizing services share this same “all 
Study 
Security,  Case 
9  Matt  Curtin.  Developing  Trust:  Online  Privacy 
and 
#1:  Centralization 
Unexpectedly  Erodes  Privacy.  pp.  140-154,  Apress, 
December 2001. 
10  Roger  Dingledine,  Michael  J.  Freedman,  and 
David  Molnar.    The  Free  Haven  Project:  Distributed 
Anonymous  Storage  Service.    In  [13],  pp.  67-95.  
http://freehaven.net/ 
11  Amerithrax: Seeking Information. FBI Web page, 
January  2002.  http://www.fbi.gov/majcases/  anthrax 
/amerithraxlinks.htm 
12  Nick  Feamster,  Magdalena  Balazinska,  Greg 
Harfst, and Hari Balakrishnan. Infranet: Circumventing 
Web Censorship and Surveillance. Proceedings of the 
11th USENIX Security Symposium, August 2002. 
(Ed.).  Designing  Privacy 
13  Hannes  Federrath 
Enhancing  Technologies,  Proc.  Workshop  on  Design 
Issues  in  Anonymity  and  Unobservability.  LNCS  vol. 
2009, Springer-Verlag, 2001. 
14  Edward  W.  Felten  and  Michael  A.  Schneider. 
Timing Attacks on Web Privacy. Proceedings of ACM 
Conference  on  Computer  and  Communications 
Security,  November  2000.    http://www.cs.princeton. 
edu/sip/pub/webtiming.pdf 
15  David Flanagan. JavaScript: The Definitive Guide 
(3rd ed.). O’Reilly & Associates, 1998. 
16  Michael  J.  Freedman,  Emil  Sit,  Josh  Cates,  and 
Robert  Morris.      Introducing  Tarzan,  A  Peer-to-Peer 
Anonymizing Network Layer. Proceedings of 1st Intl. 
Workshop  on  Peer-to-Peer  Systems,  Cambridge,  MA, 
March 2002.  http://pdos.lcs.mit.edu/tarzan/papers.html 
17  Kevin Fu, Emil Sit, Kendra Smith, Nick Feamster. 
Dos and Don’ts of Client Authentication on the Web.  
Proceedings of the 10th USENIX Security Symposium, 
August 
http://www.usenix.org/publications/ 
library/proceedings/sec01/fu.html 
18  Li  Gong,  Marianne  Mueller,  Hemma 
Prafullchandra, and Roland Schemers.  Going Beyond 
the  Sandbox:  An  Overview  of  the  New  Security 
Architecture 
the  Java  Development  Kit  1.2. 
Proceedings  of  the  USENIX  Symposium  on  Internet 
Technologies 
1997.  