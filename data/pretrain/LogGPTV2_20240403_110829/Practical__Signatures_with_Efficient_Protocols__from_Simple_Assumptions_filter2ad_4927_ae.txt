invalid in Game 5. It comes that Pr[W5] = 1/2.
Finally, A’s advantage(cid:12)(cid:12)Pr[W0] − 1/2(cid:12)(cid:12) is bounded by
AdvDDHG
(λ) + AdvDDH
ˆG
(λ) +
which concludes the proof.
qO · qH
p
+
1
p3 ,
Lemma 1. In Game 4,
the adversary A wins the
anonymity game with negligibly diﬀerent probabilities
than in Game 3 if the DDH assumption holds in G.
Proof. Let us assume that an adversary A wins with
noticeably diﬀerent probabilities in Game 4 and Game 3.
We then construct a DDH distinguisher B from A.
Our reduction B takes as input a DDH instance
(ga, gb, η), where η = ga(b+c) and has to decide with non-
negligible probability ε whether c = 0 or c ∈R Zp. To
achieve this, B sets h = ga and computes the challenge
signature as C1 = gb and C2 = η. The rest of the game
continues like in Game 3 (which is also the same as in
Game 2). If A wins and correctly guesses d(cid:48) = d ∈ {0, 1},
B outputs 1, meaning that C2 = hb = gab. Otherwise, B
returns 0 meaning that (ga, gb, η) ∈R G3.
It is easy to see that B’s advantage as a DDH distin-
guisher is ε if | Pr[W4] − Pr[W3]| = ε.
Lemma 2. In Game 5, we have Pr[E5] ≤ qO · qH /p.
Proof. This proof uses idea similar to the security
proof of the Katz-Wang [37] signature scheme. In Game
5, event E5 happens if logg(C1) (cid:54)= logh(C2) and the ver-
iﬁcation equations (10) and (11) holds. In particular, we
−c
1
have R1 = gsθ · C
−c
2 , which can be
interpreted as a linear system with unknowns (c, sθ) ∈ Z2
p
and R2 = hsθ · C
(cid:40)
logg(R1) = sθ − logg(C1) · c modp,
logh(R2) = sθ − logh(C2) · c modp.
(12)
We can assume w.l.o.g. that each opening query is pre-
ceded by the corresponding random oracle query (oth-
erwise, the reduction can simply make the hash query
for itself). The input of each hash query contains a pair
(R1, R2) determining the non-homogeneous terms of the
linear system (12). Since logg(C1) (cid:54)= logh(C2), the sys-
tem is full-rank, so that for each (R1, R2), there is exactly
one pair (c, sθ) ∈ Z2
p that satisﬁes (12). The probability
that, in response to a random oracle query, the reduc-
tion returns the value of c which is uniquely determined
by (12) is at most 1/p. For all hash queries, the prob-
ability that one of them be answered with the uniquely
determined c ∈ Zq is at most qH /p. A union bound over
all opening queries implies that the probability that the
event E4 happens is smaller than Pr[E4] ≤ qO · qH /p.
The proof of security against misidentiﬁcation attacks
requires the reduction to rewind a the proof of knowl-
edge of ID at each execution of the join protocol with the
adversary attempting to escape traceability. For this rea-
son, we need to assume that users join the system sequen-
tially, rather than concurrently. However, this problem
can be solved as in [27] by having the user send an ex-
tractable commitment to ID and non-interactively prove
(via the Fiat-Shamir heuristic) that he did so correctly.
This allows the reduction to extract ID without rewind-
ing the user at each execution of Join. Then, the proof
of security against framing attacks must be modiﬁed by
having the reduction simulate the proof of knowledge of
ID (by programming a random oracle) and rely on the
hiding property of the extractable commitment.
Theorem 4. In the ROM,
the scheme is secure
against mis-identiﬁcation attacks under the SXDH as-
sumption in (G, ˆG).
Proof. The proof uses the forking technique [47]
which consists in implicitly rewinding the zero-knowledge
proof by running the adversary twice and changing the
outputs of the random oracle after the hash query that
involves the forgery message. The Forking Lemma [47]
– more precisely, its generalization given by Bellare and
Neven [10] – ensures that, after two runs of the adversary,
the reduction can extract witnesses of which knowledge
is demonstrated by the signature of knowledge.
Let us assume an attacker A against
the mis-
identiﬁcation game that wins with non-negligible prob-
ability ε. We build an adversary B against the chosen-
message security of the signature scheme of section 3.
Keygen. At the key generation, B invokes its own chal-
lenger for the chosen-message security game to obtain
the public key pks for the signature scheme. pks is em-
bedded in the group public key Y. Except for SGM, all
keys are generated as in the normal Keygen algorithm.
Join. To answer joining queries without knowing sks,
B uses the knowledge extractor of the proof of knowl-
edge of ID = logv(VID) to extract the identity to be
signed. Namely, on a Join query, the reduction B
1, R(cid:63)
3, R(cid:63)
ID, s(cid:63)
ID, ˜σ(cid:63)
2 , ˜σ(cid:63)
3 , R(cid:63)
1 , C (cid:63)
2 , C (cid:63)
z , C (cid:63)
σ, C (cid:63)
CS, ˜σ(cid:63)
3 , c(cid:63), s(cid:63)
rewinds the adversary A in order to extract the wit-
ness ID = logv(VID) of which A demonstrates knowl-
edge at step 3 of the join protocol. Having extracted
ID ∈ Zp, B invokes its own signing oracle on the mes-
sage ID to obtain (σ1, σ2, σ3, z, r). Then, B returns
certi = (i, VID, σ1, σ2, σ3, z, r) as in a normal execution
of the join protocol.
At some point, the attacker A produces a valid forgery
(M (cid:63), Σ(cid:63) = (C (cid:63)
θ)) for
which the opening algorithm does not reveal a prop-
erly registered identity. With all but negligible prob-
ability, A must have queried the random oracle value
H(M (cid:63), C (cid:63)
2, R(cid:63)
4) which would have
been unpredictable otherwise.
Thus, B replays the adversary A with the same input
In the second
and random tape as in the ﬁrst run.
run, the random oracle is also the same until the hash
query H(M (cid:63), C (cid:63)
4). At this point,
the forking occurs and B outputs fresh random oracle
values. By the Forking Lemma of [10], B obtains two
suitably related forgeries with non-negligible probability
ε·(ε/qH−1/p). Namely, B will obtain two matching tran-
†
scripts (C (cid:63)
θ) of
the Σ protocol for the commitment message com =
(C (cid:63)
CS, ˜σ(cid:63)
ID and
†
ID (that necessarily involve the same identiﬁer ID(cid:63) which
s
CS = (C (cid:63)
is uniquely determined by C (cid:63)
ID)),
B runs the knowledge extractor of to obtain ID(cid:63) ∈ Zp.
ID, s(cid:48)(cid:63)
Namely, given (c(cid:63), c(cid:48)(cid:63), s(cid:63)
θ, s(cid:48)(cid:63)
θ , s(cid:63)
θ (cid:54)= s
†
s(cid:63)
θ
1 , C (cid:63)
ID) ∈ Z6
p with
ID (cid:54)= s
†
s(cid:63)
ID
4). From the responses s(cid:63)
3 , c†, s
c(cid:63) (cid:54)= c
3 , c(cid:63), s(cid:63)
θ), (C (cid:63)
†
ID, s
CS, ˜σ(cid:63)
CS, ˜σ(cid:63)
2 , C (cid:63)
z , C (cid:63)
σ, C (cid:63)
2 , ˜σ(cid:63)
3 , R(cid:63)
2 , ˜σ(cid:63)
3 , R(cid:63)
CS, ˜σ(cid:63)
1, R(cid:63)
2, R(cid:63)
3, R(cid:63)
1, R(cid:63)
2, R(cid:63)
3, R(cid:63)
ID, s(cid:63)
2 , ˜σ(cid:63)
2 , ˜σ(cid:63)
2 , ˜σ(cid:63)
†
,
3, R(cid:63)
which veriﬁes the relation (10) , (11) for the same com-
4) ∈ G4, one can compute the
2, R(cid:63)
mitment (R(cid:63)
1, R(cid:63)
†
ID−s(cid:63)
c(cid:63)−c† mod p and θ(cid:63) = s
secrets ID(cid:63) = s
Finally B uses SOA to extract ˜σ(cid:63)
3 , ˜r(cid:63), ˜z(cid:63))(cid:1) as a forgery for the sig-
(cid:0)ID(cid:63), σ(cid:63) = (˜σ(cid:63)
†
θ−s(cid:63)
c(cid:63)−c† mod p.
1 , ˜r(cid:63), ˜z(cid:63) and outputs
1 , ˜σ(cid:63)
2 , ˜σ(cid:63)
ID
θ
nature scheme of Section 3.
against framing attacks under the SDL assumption
Theorem 5. In the ROM,
the scheme is secure
Proof. Let us assume that a PPT adversary A can
create, with advantage ε, a forgery (M (cid:63), σ(cid:63)) that opens
to some honest user i ∈ U b who did not sign M (cid:63). We
give a reduction B that uses A to break SDL.
Algorithm B takes as
j=1 of crs contained in pks, B chooses tk = {χj}6
input an SDL instance
(g, ˆg, ga, ˆga) and uses its interaction with the adversary
A to compute a ∈ Zp. To generate the group public
key Y, B runs all the steps of the real setup algorithm
Keygen except step 1. At step 1, B deﬁnes the gener-
ators g, ˆg in pks to be those of its input and computes
h = gαh , v = gαv , w = gαw , ˆgz = ˆgαz for randomly
R← Zp. In order to compute
chosen scalars αh, αv, αw, αz
{zj}3
j=1
of step 4 of the key generation algorithm of the signa-
ture scheme of Section 3 with (cid:96) = 1. (Note that when
(cid:96) = 1, n = 6 and that {zj}3
j=1 are QA-NIZK argu-
ment for the vectors (g, 1, 1, 1, 1, h), (v, g, 1, h, 1, 1) and
(w, 1, g, 1, h, 1). Moreover {ˆgi = ˆgχi
i=1 are the veri-
fying key.) As a result of this setup phase, B knows
tk. The adversary A is run on input of the group pub-
lic key Y := (pks, (Xz, Xσ, XID), H), which has the same
SGM = sks = ω, SOA =(cid:0)xz, yz, xσ, yσ, xID, yID
(cid:1) and even
z }6
distribution as in the real attack game.
Should A decide to corrupt the group manager or the
opening authority during the game, B is able to reveal
SGM = sks and SOA when requested. In addition, B must
be able to answer the following queries.
- Qb-join-queries: At any time A can act as a cor-
rupted group manager and introduce a new hon-
est user i in the group by invoking the Qb-join or-
acle. Then, B runs Juser on behalf of the honest
user in an execution of Join. At step 1 of Join,
R← Zp and uses tk to com-
B picks a random δi
pute the tuple (Vi, Zi, ˆG2,i, ˆG4,i), for an unknown
seci = IDi = a · δi ∈ Zp, that JGM expects at step
1 of the join protocol. Namely, B computes the
vector (cid:126)vi = (Vi, Gi, 1, Hi, 1, 1) = (v, g, 1, h, 1, 1)IDi
as
Vi = (ga)αv·δi , Gi = (ga)δi , Hi = (ga)αh·δi ,
and then computes Zi as a simulated QA-NIZK
proof for (cid:126)vi ∈ G6 using tk. A straightforward cal-
culation shows that Zi = zIDi
since the QA-NIZK
argument of Section 2.2 has a deterministic prov-
ing algorithm, so that (Vi, Zi, ˆG2,i, ˆG4,i) success-
fully passes the test of step 2. As for the last two
components, for each j ∈ {2, 4}, B computes
2
ˆGj,i := (ˆga)δi(αz χj +αr γj ) = (ˆgχj
z ˆgγj
r )IDi = ˆgIDi
,
j
At step 3 of Join, B simulates the interactive proof
of knowledge of IDi = logv(Vi) using the simula-
tor. In the rest of the protocol, B proceeds like the
actual run and obtains certi = (i, Vi, σ1, σ2, σ3, π).
Finally, B stores (certi, Zi, δi, ˆG2,i, ˆG4,i).
- Qsig-queries: When A requests user i ∈ U b to sign
a message M , B is able to use the membership cer-
tiﬁcate certi = (i, Vi, σ1, σ2, σ3, π) to compute the
ciphertext CCS at steps 1-2 of the signing algorithm.
While B does not know the witness IDi = a·δi ∈ Zp
to generate a proof at step 3, B is able to simulate
the non-interactive proof (c, sID, sθ), for a randomly
chosen challenge c R← Zp by programming the ran-
dom oracle. More precisely, B re-randomizes the
certiﬁcate certi by picking r R← Zp and computing
˜σ1 = σ1 · (Vi · w)r
˜π = π · (Zi · z3)r,
˜σ2 = σ2 · gr,
˜σ3 = σ3 · hr.
Then B encrypts ˜π, ˜σ1 and Vi as in the real sign-
ing algorithm to get CCS = (C1, C2, Cz, Cσ, CID).
Then, B chooses c, sID, sθ ∈ Zp and computes
R1, R2, R3, R4 as in (10) and (11) of Verify. Fi-
nally, B programs H to return c on inputs
(M, CCS, ˜σ2, ˜σ3, R1, R2, R3, R4). In the event that
H is already deﬁned at that point, B aborts. The
probability to fail at one signing query is ≤ qs/p3,
where qs is the number of signing queries.
When A halts, it presumably frames some honest user
i(cid:63) ∈ U b by outputting a signature
ID, ˜σ(cid:63)
Σ(cid:63) = (C (cid:63)