loose coupling approach. A similar approach to the one described here may be used to accommodate
instantiations of different methodologies to achieve similar results.
This work has been successful in achieving its objectives, but mapping efforts was needed in the earlier stages
of the project since various concepts could not be mapped easily. They are related to semantics that are deeply
embedded in a system and its specific operation/reasoning mechanism that may not necessarily be fully
understood or automatically translated by another system. How to enable arbitrary domain knowledge
mapping without any prior knowledge and with minimum effort thereby allowing full integration between
any arbitrary systems, especially in an automatic, on-demand and real-time fashion, is still an open-research
question.
6 Acknowledgement
This work is supported under the Advanced Knowledge Technologies (AKT) Interdisciplinary Research
Collaboration (IRC), which is sponsored by the UK Engineering and Physical Sciences Research Council
(EPSRC) under grant number GR/N15764/01. The AKT IRC comprises the Universities of Aberdeen,
Edinburgh, Open, Sheffield and Southampton. I-X research is supported by the Defense Advanced Research
Projects Agency (DARPA) and US Air Force Research Laboratory under agreement number F30602-03-2-0014.
The constraint fusing services were developed in the context of the KRAFT project, funded by the EPSRC and
British Telecom. Kit-Ying Hui’s work was performed while at The Aberdeen University as part of the AKT
project. The AKT IRC research partners and sponsors are authorized to reproduce and distribute reprints and
on-line copies for their purposes notwithstanding any copyright annotation hereon. The views and
conclusions contained herein are those of the authors and should not be interpreted as necessarily
representing the official policies or endorsements, either expressed or implied, of other parties.
References
1. Yun-Heh Chen-Burger and Jussi Stader. Formal support for adaptive workflow systems in a distributed environment. Workflow
Handbook 2003, April 2003.
2. Violeta Damjanovic. The semantic web trends in brief. AIS SIGSEMIS Bulletin 1(3) , October 2004.
3. Layna Fischer, editor. The Workflow Handbook 2004. Future Strategies Inc., USA, in association with Workflow Management
Coalition., 2004.
4. Kit-Ying Hui, Stuart Chalmers, Peter M D Gray, and Alun Preece. Experience in using rdf in agent-mediated knowledge
architectures. Technical report, Germany, 2004.
5. Kit-Ying Hui, Yun-Heh (Jessica) Chen-Burger, Steve Potter Peter Gray, Alun Preece, and Austin Tate. Kraft-i-x live demo, 2003.
http://www.aktors.org/technologies/kraftix/movie/tie-all.html.
6. Kit-Ying Hui, Peter M. D. Gray, Graham J. L. Kemp, and Alun D. Preece. Constraints as mobile specifications in e-commerce
applications. In 9th IFIP 2.6 Working Conference on Database Semantics (DS-9), Semantic Issues in e-Commerce Systems, pages 357–379, 2001.
7. Richard Mayer, Christopher Menzel, Michael Painter, Paula Witte, Thomas Blinn, and Benjamin Perakath. Information Integration for
Concurrent Engineering (IICE) IDEF3 Process Description Capture Method Report. Knowledge Based Systems Inc. (KBSI), September 1995.
http://www.idef.com/overviews/idef3.htm.
8. Craig Schlenoff, Michael Gruninger, Florence Tissot, John Valois, Joshua Lubell, and Jintae Lee. The process specification language
(psl): Overview and version 1.0 specification. ISTIR 6459, National Institute of Standards and Technology, Gaithersburg, MD (2000), 2000.
http://www.nist.gov/psl/.
9. Austin Tate. I-X: Technology for intelligent systems. www.i-x.info, AIAI, The University of Edinburgh, 2002.
78
AIS SIGSEMIS Bulletin 2(1) January-March 2005
RDF Technologies – Foundations, Applications and Developments
Columnist: Heiner Stuckenschmidt, Vrije Universiteit Amsterdam
There is a wide agreement that the Semantic Web will largely be built on top of RDF. Therefore, a flexible and
scalable infrastructure for storing, managing and retrieving RDF-based information is essential. An increasing
number of software tools is available supporting the complete life-cycle of RDF models. Editors and
converters are available for the generation RDF schema representations from scratch or for extracting such
descriptions from database schemas or software design documents. Storage and retrieval systems have been
developed that can deal with RDF models containing millions of statements, and provide query engines for a
number of RDF query languages. Annotation tools support the user in the task of attaching RDF descriptions
to web pages and other information sources either manually or semi-automatically using techniques from
natural language processing. Finally, special purpose tools support the maintenance of RDF models in terms
of change detection and validation of models. Further, an increasing number of applications that use RDF for
representing, integrating and reasoning about information are available. Example for such applications can be
found at http://challenge.semanticweb.org. Most of the existing applications of RDF are in the area of
information systems. In this area, the benefits of RDF in terms of conceptual representations, interoperability
and reasoning support are directly visible.
This column will discuss RDF as a key technology for intelligent information systems on the web. The
discussion be centered around there aspects of RDF technology:
Foundations
We will review the principles of RDF and relate them to other well established and emerging
technologies such as graph theory, relational databases, topic maps and XML. The discussion will
focus on identifying commonalities and differences and point to insights from other areas that can be
used to improve RDF technologies.
Applications
We will review existing and potential applications of RDF technologies and discuss the benefits and
problems of RDF in areas such as information integration and thesaurus-based information retrieval.
Besides surveying existing approaches and their features, we will try to summarize lessons learned and
open problems.
Developments
We will discuss recent research questions that have been raised in connection with RDF technologies.
Examples are topics like query language standards for RDF, the notion of views or provenance in RDF
representations. We will introduce the topic and its relevance, present the current status of the
discussion and review existing proposals for a solution.
The column will be targeted at members of the semantic web as well as the information systems community.
We aim to provide researchers and practitioners in information systems with a better understanding of the
benefits and trade-offs of using RDF for building information systems. Further, we want to point semantic
web researchers and practitioners engaged in the development of RDF technologies to the area of information
systems as a fruitful application area and provide more insight in the special needs and problems of that area.
In summary this column tries to strengthen the link between information systems and RDF technologies by
discussing topics that are at the border of the two disciplines.
79
AIS SIGSEMIS Bulletin 2(1) January-March 2005
COLUMN 1:
RDF is not Re-inventing the Wheel
RDF often faces the critiques of being well-understood technology in a new dress. The cause for this critique
can be seen in the fact that the widespread use of RDF as a format for storing and querying large datasets
raises all the well known questions that the database community has addressed over the last decades. In this
first edition of the column about RDF technologies I want to try to address this criticism by discussing the
relation of RDF to existing Database technology. I do not aim to give a comprehensive overview of all the
techniques that have been developed for different kinds of data models but rather compare RDF to a number
of paradigms that have been developed by the database community. For this purpose I introduce RDF as a
data model in the classical sense and compare it to other data models such as that have been proposed
focussing on the basic principles of these paradigms rather than concrete techniques. Judging which of the
technology developed in connection with one or the other paradigm is left to the reader.
A Data Model for Networked Data
A data model can be seen as “a collection of conceptual tools for describing real world objects to be modelled
in a database and the relationships amongst these entities”. In this sense RDF clearly is a data model as its
basic building blocks are unique identifiers (URIs) for representing real world objects (called resources) as well
as statements that describe binary relations between these objects. The limitation of statements to the use of
binary relations provides us with two ways of talking about RDF models. In the so-called triple interpretation
an RDF model can be seen as a set of logical axioms describing facts in the world. This view has some nice
properties with respect to the definition of operators over RDF models. In particular, the union the intersection
and even the difference of two RDF models can easily be defined and computed in terms of the set theoretic
union, intersection or difference of the sets of statements that form the model. At the same time, an RDF model
can be seen as a labelled graph. In this view resources are interpreted as nodes, statements involving two
resources are edges connecting the nodes representing these resources. Using so-called blank nodes, nodes
that do not correspond to a real world object represented by a unique ID, even more complex features like
reification can be represented as a graph. The equivalence between RDF models and graphs allows the
application of a number of graph theoretic techniques to RDF models. We can use efficient search algorithms
to find resources and their descriptions, graph matching algorithms provide the basis for querying and
comparing RDF models and graph layout algorithms help to visualize information stored in RDF.
Most classical data models distinguish between a schema language and a data language. While the data
language is used to describe objects in the world, the schema language defines structures that are used to
structure and access this information. In RDF the language for defining the schema is part of the data
language. Schemas can be defined using a special vocabulary for defining the domains and ranges of relations
as well as subclass and subproperty relations. Thus, a schema definition itself is an RDF model. What makes
schema definition special is their semantics with respect to the interpretation of data. In particular, schema
definitions can be used to derive implicit information from a given model. The semantics of schema
definitions is given in terms of a model theoretic semantics and can be implemented using a fixed set of rules
that define how to derive new statements the content of an RDF model and its schema. This is especially
relevant upon exchange as within a closed system, the programmer also knows the semantics and can
immediately reason about the data.
RDF and Databases
According to Jeffrey D. Ullmann, , the aim of database technologies is to deal with the largest amount of data
possible. In order to reach this goal he names very high-level languages and query optimization as important
subgoals. High level languages are necessary to be able to handle many different kinds of data in a uniform
way. Query optimization is necessary to be able to process large amounts of data in reasonable time. In this
context, we can see RDF as an answer to the first subgoal as it provides a high-level language for encoding and
accessing distributed data in a uniform way. Viewing RDF as a high level-data model raises the question of
80
AIS SIGSEMIS Bulletin 2(1) January-March 2005
how current work on RDF relates to the database research. In particular, the question is whether existing
methods from the database area can directly be used to process RDF. Answering this question is essential in
order to identify open problems of processing RDF that have not yet been addressed in the database
community and identify research challenges.
Of course we are not able to provide a detailed analysis of existing database methods and how they could be
used for RDF. We will rather compare RDF with some major paradigms that have been investigated in the
database community discussing commonalities and differences of RDF and the data model underlying the
corresponding paradigm.
The most well known paradigm in the database area is the relational paradigm. Here data is stored in named
relations. Manipulation and access of information stored in such relations can be formalized using relational
algebra. Based on the relational algebra efficient methods for optimizing and answering queries have been
developed that are ready to be used in existing products. If we compare this to the statement-based
representation of RDF, we recognize some commonalities. In particular RDF stores data in binary relations
where the property denotes the name of the relation and the subject and object of a statement correspond to
the data stored in the relation.
On the other hand, RDF shows a number of characteristics that do not correspond to the relational model. In
particular there are three points that distinguish RDF from the relational data model:
1. RDF restricts the storage of data to binary relations
2. RDF supports limited forms of reasoning about data
3. RDF supports and object-oriented way of modeling data
In the following, we will discuss these differences and relate it to the corresponding paradigms developed by
the database community, i.e. graph databases, object-oriented databases and deductive databases.
RDF and Graph Databases
The restriction of the data model to binary relations makes RDF equivalent to a graph data model. Dealing
with such data models has been investigated in connection with graph databases and more recently in
connection with querying the web. In graph databases, labelled graphs are used as a higher level model to
store and query data. In connection with the graph data model aspects like different storage models for graph
data and query languages for graph shaped data have been investigated. There are many examples of
techniques from graph databases that have been adopted in RDF technology. One example is the use of the
vertical storage model in which the graph structure is stored using a link table. Each entry in this table
corresponds to an edge in the graph and therefore to an RDF statement. Another example is the use of path
expressions as the basic building block of query languages. Most RDF query languages use path expressions to
define a graph structure that is further restricted by a number of constraints on labels of nodes and edges.
A significant difference of RDF compared to earlier work on graph databases is the fact that parts of the graph
to be queried is only present virtually. As mentioned above, RDF schema can be used to define implicit
knowledge about resources that imply additional statements not explicitly contained in the model. These
additional statements have to be taken into account when an RDF model is queried. Therefore, what
distinguishes RDF from a graph database is the need to integrate logical reasoning about the schema into the
query process.
RDF and Deductive Databases
The integration of logical reasoning into database technologies has been studied in connection with deductive
databases. For this purpose deductive databases distinguish between extensional and intentional relations.
Extensional relations are database relations in the classical sense. Intentional relations are defined in terms of
(a set of) logical rules over other relations (both extensional and intentional). Queries to a deductive database
81
AIS SIGSEMIS Bulletin 2(1) January-March 2005
can combine intentional and extensional relations. In order to answer such a query techniques from logic
programming are used to find all implied answers. In principle, schema-based RDF models can be seen as a
kind of a deductive database where the explicitly contained statements corresponds to the extensional part of
the data and the deduction rules for the RDF schema semantics defines additional data similar to intentional
relations in deductive databases. The advantages in terms of the need to only store a subset of the information
are common to both approaches. In fact, techniques from deductive databases have been used in RDF
repositories. Examples are the use of the RETE algorithm for computing derived facts from data and rules
using a forward chaining strategy.
There are also a number of significant differences between RDF and deductive databases that make it
impossible or unattractive to apply techniques that have been developed for deductive databases to RDF. One
point is that RDF does not make a clear distinction between extensional and intentional relations as new facts
can be derived with respect to any kind of relation. This is a consequence of the basic distinction between
closed world assumption normally made in databases and the open world assumption that underlies the Web.
Of course this can easily be modelled in a deductive database by introducing an intentional version of each
extensional relation that is defined in terms of the extensional relation and the rules that can be used to
compute additional facts, but it is a relevant conceptual difference. A more crucial difference lies in the specific
trade-off of representation and reasoning made by RDF. One of the goals of RDF was to enable “anybody to
say anything about everything”. As a result, RDF allows arbitrary combinations of statements including
statements about relations. On the other hand, reasoning about RDF models is limited to a fixed set of
deduction rules specified in the RDF schema definition. This implies that many techniques developed for
deductive databases do not directly apply to RDF because they are not able to deal with statements about
relations or they deal with the processing of complex rule definitions that do not occur in RDF. In summary,
we can say that techniques from deductive databases can only be applied to RDF in a very generic way by
considering a single ´statement´ relation. More specific methods that take the schema of an RDF model into
account need further investigations.
RDF and Object-Oriented Databases
Object-Oriented databases have been developed to better address the conceptual model that underlies a
dataset into the functionality of a database. For this purpose, data is organized according to classes of objects.
These classes are organized in an inheritance hierarchy that allows objects to inherit properties from their
super classes. The data objects themselves are described by the values of properties and by links to other
objects. In contrast to other database paradigms, data object have and identity that makes it possible to
distinguish between two objects with identical values. All these properties are shared by RDF: Resources are
organized in a class hierarchy, they are defined by values (literals) and relations to other resources and
resources have an identity in terms of their URI. This correspondence between RDF and object oriented
databases can be exploited in several ways. In particular, indexing techniques for object oriented data models
can be adopted to improve the access to RDF data. On a more practical level, object oriented databases have
been used to store and query RDF data. RDF also shares some of the problems of object oriented databases
such as the problem of object identity and the need to decide whether two objects actually represent the same
real world entity and thus need to be treated as one.
On the other hand, RDF shows a number of important differences with object oriented databases. These
differences mostly aim at avoiding some of the problems that have prevented object-oriented databases from
being widely used. In particular, RDF aims at providing a clear semantics and a simple and elegant way of
defining object oriented features. One of the problems of object-oriented databases is that the notion of
inheritance is often not well defined and adds significant complexity to the data model. Especially the
treatment of methods for computing values of properties on the fly is not clear in the case of inheritance. RDF
resolves this problem by using a very light weight notion of inheritance that only affects properties at the data
level and by not allowing methods in the data. As a result inheritance can be computed using simple forward
chaining rules. The other drawback of object oriented databases that is not shared by RDF is structural
complexity. Merging to models for example is a very complex task in the context of an object oriented
database. The restriction to a binary relations and the treatment of the schema as part of the data makes
merging a trivial operation in RDF, because it is defined as the set-theoretic union of the statement sets. In
82
AIS SIGSEMIS Bulletin 2(1) January-March 2005
summary we can say that RDF takes a very light-weight approach to object orientation than typically assumed
in object oriented databases.
Discussion
We introduced RDF as a data model for managing and exchanging networked data and compared its
properties with different database paradigms. The observations so far can be summarized as follows: the RDF
data model adopts and combines features from different paradigms in a novel way that is better suited to deal
with information in an open and distributed environment such as the Web. In such environment the focus is
more on exchange and interoperability than on indexing and query optimization. RDF combines the graph-
based representation used in graph databases with limited inference capabilities similar to the ones used in
deductive databases and a lightweight approach to object-orientation that shares basic principles with object-
oriented databases. As a consequence, many techniques developed in the database area a relevant for RDF and
their possible application should be investigated. This however does not mean that RDF is just old database
technology with a new name. In the following I will give three arguments for this claim:
1) the combination of features from the different database paradigms in order to best fit the needs of Web-
based data is already a scientific merit that has not been achieved before. Basic characteristics that influence
the design choices made are openness (in contrasts to closeness of database systems), decentralization and
scalability.
2) The second point is that the combination of different paradigms makes it impossible to directly apply