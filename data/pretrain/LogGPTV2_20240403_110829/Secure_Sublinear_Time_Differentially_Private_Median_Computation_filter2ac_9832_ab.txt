privacy are additive noise, e.g., the Laplace mechanism [18],
and probabilistic selection, namely, the exponential mechanism
[39]. To compute the differentially private median we use the
exponential mechanism [39], which provides selection proba-
bilities for possible median values. A simpler, but less accurate,
alternative is the Laplace mechanism [18], which adds noise,
sampled from the Laplace distribution, to a function result,
i.e., f (D) + Laplace (∆f /). The noise depends on ∆f, the
sensitivity of the function, and a privacy parameter  formalized
later. The sensitivity is the largest difference a single change in
any possible database can have on the function result. Smooth
sensitivity, developed by Nissim et al. [43], additionally ana-
lyzes the data to provide instance-speciﬁc additive noise which
is often much smaller. Li et al. [35] note that the Laplace
mechanism is ineffective for the median as the sensitivity, and
thus noise, can be high. As mentioned before, the accuracy
in the local model
is limited [5, 30, 38]. However, even
in the central model with smooth sensitivity the exponential
mechanism is usually more accurate. To demonstrate this we
evaluated the absolute error of the Laplace mechanism with
smooth sensitivity and the exponential mechanism for real-
world data sets [33, 54] in Fig. 2. In general, large differences
between elements close to the median or small , which corre-
sponds to strong privacy guarantees, increase noise magnitudes
and thus errors even with smooth sensitivity. Furthermore,
secure computation of smooth sensitivity requires access to the
entire dataset or the error further increases2, which prohibits
sublinear secure computation with high accuracy. Thus, our
reason for using the exponential mechanism to compute the
median is two-fold: It provides the best (known) accuracy
for small , and, as we will show, it can be implemented as
sublinear-time secure computation.
2Smooth sensitivity approximations exist that provide a factor of 2 approx-
imation in linear-time, or an additive error of max(U )/poly(n) in sublinear-
time [43, Section 3.1.1]. Note that this error e is w.r.t. smooth sensitivity s
and the additive noise is even larger with Laplace ((s + e)/).
3
0.10.250.502.557.51012.51517.520Avg.Abs.ErrorsSmoothsensitivityExponentialMechanism0.10.250.5024681012Avg.Abs.ErrorsSmoothsensitivityExponentialMechanismfor any probabilistic polynomial-time (in λ) adversary A, for
any neighboring data sets (DB, D(cid:48)
B)
A(DA, DB)) = 1]
Pr[A(VIEWΠ
≤ exp(B) · Pr[A(VIEWΠ
B)) = 1] + negl(λ).
A(DA, D(cid:48)
Likewise for B’s view for any neighbors (DA, D(cid:48)
A) and A.
For notational convenience let  = A = B. We operate
in the semi-honest model [24] (also called honest-but-curious)
where participants do not deviate from the protocol but try
to extract as much information from the protocol transcript
as possible. A protocol is consider secure in the semi-honest
model when the transcript does not reveal anything beyond the
computed functionality.
C. f-neighboring
He et al. [28] introduced the notion of f-neighbors: neigh-
bors that also have the same output w.r.t. to a function f. For
our security proof we require f-neighboring and adapt it to
our scenario.
Deﬁnition 3 (f-Neighbor). Given function f : U k × U l →
O, k, l ∈ N, and DA ∈ U k. Data sets DB and D(cid:48)
B are f-
neighbors w.r.t. f (DA,·) if
1)
2)
they are neighbors, and
f (DA, DB) = f (DA, D(cid:48)
B).
f-neighboring for DB is similarly deﬁned.
In [28] f-neighboring is applied to record matching, where
neighbors differ in at most one non-matching record. In our
scenario f is input pruning, the ﬁrst step of our protocol which
reduces the input set size and we denote it as PRUNE. PRUNE
is a partial execution of comparison-based pruning from [1]
described in Section IV-D. We distinguish two forms of
pruning: deterministic and randomized. Deterministic pruning,
such as PRUNE, might differ between neighboring data sets and
thus potentially violate differentially privacy for its common
neighboring notion. By considering PRUNE-neighbors, where
pruning outputs are the same, neighboring data sets cannot
be distinguished, and differential privacy holds. To verify
that PRUNE-neighboring is not too restrictive and can be used
in real-world applications we evaluated neighboring data sets
from real-world data sets [11, 33, 51, 54] and found they
are all also PRUNE-neighboring albeit with limited group
privacy. See Section VI for details of the experiment. In
randomized pruning each comparison result is randomized.
The probability that the half of the data containing the median
is never discarded decreases exponentially in the number of
comparisons [29]. Hence, accuracy is signiﬁcantly impacted
with high probability and we dismiss randomized pruning in
favor of PRUNE-neighboring.
D. Exponential Mechanism
The exponential mechanism, introduced by McSherry and
Talwar [39], expands the application of differential privacy
to functions with non-numerical output, and when the output
is not robust to additive noise. The exponential mechanism
selects a result from a ﬁxed set of outputs O while satisfying
differential privacy. The mechanism is exponentially more
4
likely to select “good” results where “good” is quantiﬁed via a
utility function u(D, o) which takes as input a data set D ∈ U n
and a potential output o ∈ O. The utility function provides
a utility score for o w.r.t. D and all possible output values
from O. Informally, a higher score means the output is more
desirable and its selection probability is increased accordingly.
The formal deﬁnition is according to [35].
Deﬁnition 4 (Exponential Mechanism). For any utility func-
(U n × O) → R and a privacy parameter ,
tion u :
the exponential mechanism M
u(D) outputs o ∈ O with
probability proportional to exp
(cid:16) u(D,o)
(cid:17)
2∆u
∆u = max
, where
∀o∈O,D(cid:39)D(cid:48)|u(D, o) − u(D(cid:48), o)|
(cid:17)
(cid:16) u(D,o)
is the sensitivity of the utility function. That is,
(cid:16) u(D,o(cid:48))
u(D) = o] =
Pr[M
exp
2∆u
(cid:80)
o(cid:48)∈O exp
2∆u
(cid:17) .
(1)
Median Utility Function: We focus on the median and
use the median utility function from Li et al. where rankD(x)
denotes the number of elements in D smaller than x.
Deﬁnition 5 (Median utility function). The median utility
function umed : (U n × U) → Z gives a utility score for each
x ∈ U w.r.t. D ∈ U n as
umed(D, x) = −
(cid:12)(cid:12)(cid:12)j − n
rankD(x)≤j≤rankD(x+1)
(cid:12)(cid:12)(cid:12).
min
2
Note that for the median O = U, i.e., every universe ele-
ment has to be considered as a potential output. The sensitivity
of umed is 1/2 since adding an element increases n/2 by 1/2
and j either increases by 1 or remains the same [35]. Thus,
the denominator 2∆u in the exponents of Equation (1) equals
1, and we will omit it in the rest of this work. The intuition
behind this utility deﬁnition is to use the rank of elements
to quantify their “closeness” to the median. The median itself
has the highest utility value, 0, all other elements have negative
utility. The further away an element in a sorted data set (i.e., its
rank) is from the median position, the smaller its utility. Note
that Deﬁnition 5 can be adapted to select elements of arbitrary
rank k, e.g., to ﬁnd the 25th- and 75th-percentile. In this work
we focus on the secure computation of the differentially private
median but this can easily be extended to securely compute the
differentially private kth-ranked element.
E. Secure Computation
We use secret sharing as well as garbled circuits as addition
and scalar multiplication are more efﬁcient with the former
whereas comparisons can be more efﬁciently implemented as
boolean circuits with the latter.
Additive Secret Sharing: We require all values to be in the
ring Z2b and perform all operations modulo Z2b. In additive
p-out-of-p secret sharing a party Pi, 1 ≤ i ≤ p, (or a separate
dealer) “splits” its secret value s ∈ Z2b into p shares and all
shares are required to reconstruct the secret. First, Pi creates
uniformly random values s1, . . . , sp−1 ∈ Z2b. Then, Pi sets
i=1 si. Intuitively, a shared secret is reconstructed
i=1 si. Privacy
sp = s−(cid:80)p−1
i.e., s = (cid:80)p
by adding all shares together,
follows from the fact that shares s1, . . . , sp are uniformly
random and the sum of any strict subset of the shares is also
random. We denote the sharing of s as (cid:104)s(cid:105) = (s1, . . . , sp).
Addition with shared secret values (cid:104)s(cid:105),(cid:104)r(cid:105) is straightforward
since (cid:104)s(cid:105)+(cid:104)r(cid:105) = (s1+r1, . . . , sp+rp), as is multiplication with
a public value t ∈ Z2b where t(cid:104)s(cid:105) = (ts1, . . . , tsp). We also
write (cid:104)s(cid:105)Pj instead of sj to highlight that it is Pj’s share of s.
In our implementation we use the ring Z264 as computations
modulo 264 are commonly supported on standard CPUs.
is a general
Garbled Circuits: A garbled circuit, ﬁrst described by
technique to securely evaluate any
Yao [56],
function by implementing it as a boolean circuit and “garbling”
each gate’s truth table. Informally speaking, given two parties,
the four possible inputs of a garbled table are not plaintext bits
but random labels. One party is the garbler who garbles the
gates and creates the labels. The other party, called evaluator,
receives the garbled circuit and evaluates it. The garbler
includes all her input labels in the garbled circuit (which look
random to the evaluator). However, the garbler cannot learn
the evaluator’s input and cannot send both input labels per
gate to the evaluator, otherwise the garbler’s input will be
revealed. To solve this problem 1-out-of-2 oblivious transfer
(OT) [23, 47] is used: The evaluator receives only her input
label and the garbler remains oblivious. Given the input labels
for both parties the evaluator can determine (decrypt) the
output label for a gate and use it as input for the next gate. An
output translation table, also provided by the garbler, maps the
ﬁnal random output label to the plain result. For a formalized
description see Appendix A.
IV. BUILDING BLOCKS FOR DP MEDIAN SELECTION
We implement an efﬁcient, secure computation of the
exponential mechanism which selects the differentially private
median from the entire data universe U. There are two chal-
lenges for secure computation of the exponential mechanism:
the runtime complexity is linear in |U| as probabilities
for all possible outputs in U are computed,
the general exponential mechanism is too inefﬁcient
with general secure computation as it requires |U|
exponentiations and divisions.
•
•
In this section we present building blocks for our practically ef-
ﬁcient, sub-linear time protocol overcoming those challenges.
A. Overview
For now we focus on a single data set as we later prune
and merge the data sets from the two parties into one data
set. For data set D with universe U we compute the median
selection probabilities for all of U using only D by utilizing
dynamic programming. To compute the probabilities efﬁciently
we ﬁrst deﬁne a simpliﬁed utility function utility, which
computes utility for all universe elements but only requires
D as input, in Section IV-B. The simpliﬁed utility provides
incorrect utility scores in the presence of duplicates. Thus,
we deﬁne gap to discard these incorrect scores and compute
the median selection probabilities, denoted as weight. The
sum of these probabilities is the basis for the cumulative
distribution function, which we denote with mass. Then, we
sample the differentially private median based on mass with
A
Secure
computation
between A, B
B
(I) Input Pruning [1]
c = mA < mB
mB
c
mA
c
loop: i = 0..s − 1
mA = median of Di
A
A is upper half
A if c = 1 else
Di+1
of Di
lower half
Generate list (cid:104)Ds(cid:105)A
of masking values
Ds
A, (cid:104)Ds(cid:105)A
(II) Oblivious Merge [31]
& Secret Sharing
(cid:104)Ds(cid:105)A+(cid:104)Ds(cid:105)B is
sorted Ds
A ∪ Ds
B
(III) Selection
probability: Com-
pute gaps (cid:104)gap(cid:105)A,
probability masses
(cid:104)mass(cid:105)A, draw lists
of nonces N 1
A, N 2
A
(cid:104)gap(cid:105)A,
(cid:104)mass(cid:105)A,
(cid:104)Ds(cid:105)A,
(cid:98)m
N 1
A, N 2
A
(IV) Median
Selection
Sample median (cid:98)m
Ds
B
(cid:104)Ds(cid:105)B
(cid:104)gap(cid:105)B,
(cid:104)mass(cid:105)B,
(cid:104)Ds(cid:105)B,
(cid:98)m
N 1
B, N 2
B
Fig. 3. High-level protocol overview with comments for A, where s is the
A is sorted DA, and (cid:104)Ds(cid:105)A, (cid:104)gap(cid:105)A, (cid:104)mass(cid:105)A
number of pruning steps, D0
are A’s shares for all values ds
i , gaps gap(i), and masses mass(i) respectively
(i ∈ {0, . . . , |Ds| − 1}).
inverse transform sampling described in Section IV-C. To
further reduce secure computation complexity we prune the
input D in Section IV-D. A high-level overview of our protocol
is visualized in Fig. 3, and we present our full protocol in
Section V. In the ﬁrst step, the parties prune their input. Then,
they securely merge and secret share their pruned data. In the
third step they compute selection probabilities and, in the last
step, sample the differentially private median.
Note that in the following we deﬁne gap, utility, and
weight such that direct access to the data D – and therefore the
need for secure computation – is minimized: Each party can
compute utility and weight without any access to D. Further-
more, gap has a static access pattern in dynamic programming,
independent of the elements in (sorted) D, which makes the
gap function data-oblivious, i.e., an attacker who sees the
access pattern cannot learn anything about the sensitive data.
B. Utility with Static Access Pattern
Recall that the exponential mechanism evaluates the utility
function umed for all elements in the data universe U. However,
per deﬁnition of umed certain outputs have the same utility,
namely, duplicates and elements in U\D. We use this obser-