P redirects
Meta-refresh tag
Link encoding
Pop-up
Dynamic javascript
Iframe
VBScript
P
O
ST link
Figure 5. Successful Link Traversals over Total Links by Technology Category, Averaged Over All Scanners.
0
0
Malware
Info leak
Conﬁg
Session
SQL 2nd order
SQL 1st order
CSRF
XCS
XSS advance
XSS type 2
XSS type 1
31.2
32.5
26.5
21.4
20.4
15
11.25
15
0% 10%
20%
30%
40%
50%
Figure 6. Average Scanner Vulnerability Detection Rate By Category
62.5
60%
classiﬁcation were dragged down by poor scanner detection
of more complex forms of ﬁrst-order SQL injection that use
different keywords. Aside from the XSS type 1 classiﬁcation,
there were no other vulnerability classiﬁcations where the
scanners as a group detected more than 32.5% of the
vulnerabilities. In some cases, scanners were unable to detect
testbed vulnerabilities which were an exact match for a cate-
gory listed in the scanning proﬁle. We also note how poorly
the scanners performed at detecting “stored” vulnerabilities,
i.e. XSS type 2 and second-order SQL injection, and how
no scanner was able to detect the presence of malware. We
will discuss our thoughts on how to improve detection of
these under-performing categories in Section VIII.
2) Cross-Site Scripting: Due to the preponderance of
Cross-Site Scripting vulnerabilities in the wild, we divided
Cross-Site Scripting into three sub-classes: XSS type 1, XSS
type 2, and XSS advanced. XSS type 1 consists of textbook
examples of reﬂected XSS, performed via the 
tag. XSS type 2 consists of stored XSS vulnerabilities,
where un-sanitized user input is written to the database and
later performs scripting when read from the database. XSS
advanced encompasses novel forms of reﬂected and stored
XSS, using non-standard tags and keywords, such 
and prompt() [16], or using alternative scripting tech-
nologies such as Flash. For XSS advanced tests using novel
keywords, we ﬁltered out any user inputs that did not contain
the appropriate keywords.
As previously mentioned, Figure 7 shows that the scanners
performed decently well on XSS type 1, with all scanners
detecting at least 50% of the vulnerabilities. For the other
categories, however, the scanners performed poorly as a
group, with only the leading performer detecting more than
20% of vulnerabilities, and numerous scanners failing to
detect any vulnerabilities.
3) SQL Injection: We also divided SQL Injection vulner-
abilities into two sub-classes, ﬁrst-order and second-order,
for the same reason as dividing the XSS classiﬁcation. First-
order SQL Injection vulnerabilities results in immediate
SQL command execution upon user input submission, while
second-order SQL Injection requires unsanitized user input
to be loaded from the database. The ﬁrst-order SQL vul-
nerability classiﬁcation also includes both textbook vulnera-
bilities as well as vulnerabilities dependent on non-standard
keywords such as LIKE and UNION, where user inputs not
338
11.25
15
20
20
20
20
20
20
0
0
0
0
0
0
0
0
XSS adv
XSS type 2
XSS type 1
40
50
50
50
50
50
50
50
62.5
8th
7th
6th
5th
4th
3rd
2nd
1st
Average
100
100
0%
10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Figure 7. XSS Detection Results Sorted By Scanner Rank in Category
SQL 2nd
0
0
0
0
0
0
0
0
0
SQL 1st 
0
0%
8th
7th
6th
5th
4th
3rd
2nd
1st
Average
42.8
21.4
28.5
28.5
28.5
14.2
14.2
14.2
10%
20%
30%
40%
Figure 8. SQL Injection Detection Results Sorted by Scanner Rank in Category
containing the appropriate keyword are again ﬁltered out.
Also, in all cases, malformed SQL queries in our testbed
result in a displayed SQL error message, so scanners do not
have to rely on blind SQL Injection detection.
Figure 8 shows that 7 of 8 scanners were able to detect
the basic ﬁrst-order SQL injection vulnerability (accounting
for the 14.2%), but only one scanner was able to exceed
40% rate of detection for all ﬁrst-order SQL injection
vulnerabilities. Similar to XSS results, second-order SQLI
vulnerability detection is signiﬁcantly worse than ﬁrst-order,
with no scanner able to detect even one such vulnerability.
4) Cross-Channel Scripting: As described in a previous
section, the Cross Channel Scripting classiﬁcation includes
all vulnerabilities allowing the attacker to inject code onto
the web server that manipulates the server or a client
browser. In our testbed, this classiﬁcation included vulner-
abilities in XPath injection, Malicious File Upload, Open
Redirects, Cross-Frame Scripting, Server Side Includes,
Path Traversal, Header Injection (HTTP Response Splitting),
Flash Parameter Injection, and SMTP Injection.
As Figure 9 demonstrates, the scanners as a group per-
formed fairly poorly on this class of vulnerabilities. Only
Server-Side Includes and Path Traversal were detected by a
majority of scanners.
5) Session Management: The Session vulnerability clas-
siﬁcation include session management ﬂaws as well as
authentication and cookie ﬂaws. The testbed authentica-
tion vulnerabilities include credentials being sent over un-
encrypted HTTP, auto-complete enabled in the password
ﬁeld, submitting sensitive information over GET requests,
weak password and password recovery questions, and weak
registration CAPTCHAs. The session management and
cookie vulnerabilities include insecure session cookies, non-
HttpOnly cookies, too broad cookie path restrictions, pre-
339
20.4
18.18
18.18
9.09
36.36
27.27
54.54
8th
7th
6th
5th
4th
3rd
2nd
1st
Average
10%
20%
30%
40%
50%
XCS
0
0
0%
Figure 9. Cross-Channel Scripting Detection Results Sorted by Scanner Rank in Category
Session
26.5
25
25
43.75
37.5
31.25
8th
7th
6th
5th
4th
3rd
2nd
1st
Average
18.7
18.7
12.5
0%
10%
20%
30%
40%
Figure 10. Session Management Vulnerability Detection Results Sorted by Scanner Rank in Category
dictable session and authentication id values, session ﬁxa-
tion, ineffective logout, mixed content pages, and caching
of sensitive content.
As a group, the scanners performed better at detecting this
vulnerability class than the SQLI, XSS, and XCS classes.
Figure 10 shows that scanner performance is fairly evenly
distributed between the best performer at 43.7% detection
and the worst at 12.5% detection.
6) Cross-Site Request Forgery: Nearly all forms on our
testbed application do not use any sort of randomized
authentication token, making them vulnerable to Cross-Site
Request Forgery. However, we only considered as requiring
CSRF protection the forms which are only available after
login. Our testbed contains post-login forms without any
authorization token and also post-login form which utilize
tokens with very few bits of entropy. In addition to the CSRF
vulnerabilities just mentioned, our testbed also included
session tokens that do not reset after form submission, GET-
method forms vulnerable to CSRF, and CSRF-like JSON
hijacking vulnerabilities.
Results in Figure 11 show that two scanners fared rela-
tively well at CSRF detection, each achieving 40% detection
rates. On the other extreme, four scanners detected none
of the vulnerabilities in this classiﬁcation, with one vendor
conﬁrming that they did not report CSRF vulnerabilities at
the time of testing.
7) Information Disclosure: Our testbed application leaks
sensitive information regarding SQL database names via the
die() function and existent user names via AJAX requests.
Backup source code ﬁles are also left accessible, and path
disclosure vulnerabilities are also present.
Figure 12 shows that this was one of two vulnerability
categories where the scanners as a group performed the
best. A majority of scanners detected all of the backup ﬁle
disclosures, as well as the path disclosure vulnerabilities.
8) Server and Cryptographic Conﬁguration: While
server and cryptography vulnerabilities do not technically
occur at the application layer, they affect web application
security all the same and should be detected by the vulnera-
bility scanners. Our server conﬁguration contained improper
PHP setting in the ‘open basedir’ and ‘allow url fopen’
variables and allowed the HTTP TRACE request. The SSL
of the server was also mis-conﬁgured, with a self-signed
SSL certiﬁcate and weak cipher strength.
Figure 13 shows that
this was the other of the two
vulnerability categories where the scanners as a group
340
15
20
20
10%
20%
30%
40
40
8th
7th
6th
5th
4th
3rd
2nd
1st
Average
40%
CSRF
0
0
0
0
0%
Figure 11. Cross-Site Request Forgery Detection Results Sorted by Scanner Rank in Category
Info leak
31.2
25
25
25
25
25
50
50
50
8th
7th
6th
5th
4th
3rd
2nd
1st
Average
0%
10%
20%
30%
40%
50%
Figure 12.
Information Disclosure Detection Results Sorted by Scanner Rank in Category
performed the best. Seven of eight scanners detected the
TRACE request vulnerability. On the other hand, we were
surprised that less than half of the scanners detected the self-
signed SSL certiﬁcate, as this seems to be a simple check
to prevent signiﬁcant impact on the user-experience of the
site, especially with newer browsers.
9) Detection of Malware: Finally, we decided to add the
detection of malware as a category in the scanner testbed.
With the proliferation of open-source code, it is uncertain
whether website operators are familiar with the entirety of
the codebase which operates their site. Malware detection
serves as a check that websites are not unwitting partners
aiding malicious third-parties in exploiting their users. This
feature is also useful as a defense-in-depth measure in the
case that attackers have succeeded in injecting malicious
code onto the site. Thus, we inserted simple pieces of
malware on our testbed site, a javascript keystroke logger
at the login page and a malicious ﬁle in the user-content
section. However, as Figure 6 demonstrates, no scanner
reported the presence of any malware on our testbed site.
D. False Positive Results
We designed two potential “traps” for false positives in
our testbed. The ﬁrst involves using javascript alert()
as intended site behavior,
to see if any scanner would
wrongly classify this as a sign of a Cross-Site Scripting
vulnerability. The second involves inserting user input into
the right-hand side of a Javascript string variable assignment
within a  block but not doing anything else with
that variable. Any quotation symbols in the user input that
would create a genuine XSS vulnerability are html-encoded
by the testbed, and all ‘;’ characters are ﬁltered. This in
effect creates a benign region within a  block
that reﬂects user input, which can trap scanners simply
searching for user-manipulable text within script blocks.
The “alert()” trap did not cause any false positives, but
341
32.5
20
20
20
20
60
60