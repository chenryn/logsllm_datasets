23
910
292
6s
16
17
26
36
1155
is much easier to detect later than earlier when the detection of
split nding is wrong. With real split time increase, we can see the
decrease of the number of N/A as well as the increase of corrected
instances, which means longer delay time is advantageous to split
nding. As shown in Table 6 and 8, we nd it is more dicult to
identify web pages on Tor. In addition, Table 7 and 8 illustrates that
the number of our true positive of all the split time is larger than
time-kNN. In a nutshell, we can conclude that our Balance-XGBoost
is better than time-kNN in both SSH and Tor scenario.
6.4 Evaluation of Chunk-Based Classication
In this section, we evaluate the performance of our new WF clas-
sier. Therefore, the attacker trains and classies with only the
initial chunk, i.e., the packets before the split point (corresponding
to one page). We perform experiments under the closed-world and
open-world settings. In the closed-world setting, we test our clas-
sier with a dataset where all web pages are monitored, while in
the open-world setting, the dataset consists of both monitored and
unmonitored web pages. In order to fairly compare with previous
classiers, we will use a short initial chunk to compare these ex-
isting classiers, which makes our classier the optimal choice for
the multi-tab scenario.
Figure 5: The split accuracy of BalanceCascade-XGBoost
compared to time-kNN on SSH and Tor dataset.
Table 5: TPR of split time detection with time-kNN on SSH.
With each real split time, the table shows the number of
network ows detected as each possible split time, where
bolded values represent correctly detected split time.
2s
961
46
34
21
28
160
3s
44
932
77
40
41
116
Real split
4s
28
20
1024
44
67
67
5s
29
24
32
1028
112
25
6s
40
21
30
21
1095
43
t 2s
3s
4s
5s
6s
N/A
i
l
p
s
d
e
t
c
e
t
e
D
client requests to open a new channel, it will issue an SSH-MSG-
CHANNEL-OPEN message of 100 bytes to SSH server. Because each
new page will ask for an SSH-MSG-CHANNEL-OPEN message, we
reduce the number of candidate points by abandoning these can-
didates whose length is not 100, which helps to improve the split
accuracy of SSH dataset. According to Figure 5, the split accuracy
of SSH dataset is much better than that of Tor. We can detect the
“true split” with an 89.41% split accuracy. Therefore, our algorithm
well outperforms time-kNN.
Splitting Time Evaluation. In this experiment, we use the de-
tected split time to evaluate the performance of our BalanceCascade-
XGBoost against time-kNN. We use the Tor_twop and SSH_two
to do the experiments, respectively. For instance, we use the half
of the Tor_twop dataset to train the classier. In each subset of
dierent delay time, each web page has 25 instances in the training
phase, and then we use the remaining to test. Due to that some true
split point is near the start of network ow, we want to detect all
the outgoing packets. We extract the same features as time-kNN
except for the features of mean, standard deviation, and maximum
inter-cell time for twenty cells before and after the candidate cell.
We measure all the outgoing packets, and set 0 to the feature by de-
fault if we cannot get enough packets to extract the corresponding
feature.
As we described above, time-kNN has ignored some instances
due to their start point of the second page is within 50 packets
of network ow. According to Table 5 and 6, each column has
1250 instances. N/A in the table means the number of instances that
cannot be captured by time-kNN. In each split time, BalanceCascade-
XGBoost has more true positive instances than time-kNN on SSH.
According to the columns shown in Table 6, the number of detected
later is larger than the number of detected earlier, which means it
334
A Multi-tab Website Fingerprinting Aack
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
datasets
SSH_normal (2s)
Tor_normal (2s)
Tor_normal (3s)
HTTPOS split (2s)
Trac morphing (2s)
Decoy pages (2s)
BuFLO (2s)
Before
TPR
93.96%
56.64%
68.04%
91.48%
78.16%
75.36%
13.08%
After Feature Selection
TPR
# of Features
95.84%
56.2%
68.72%
93.6%
83.64%
80.06%
13.2%
79
31
48
81
82
92
15
Table 9: Comparison of TPR before and after feature selec-
tion. The number of features before feature selection is 452,
where 2s and 3s indicate the split time of two seconds and
three seconds, respectively.
Results of Feature Selection. In the experiment, we evaluate the
TPR of our new WF attack after performing feature selection on
each dataset using IWSSembeddedNB, while limiting each packet
sequence to two seconds of the initial chunk. We calculate the
TPR using ten-fold cross-validation in the closed-world setting.
The datasets we use include both the SSH_normal and Tor_normal
datasets. We also do experiments on Tor_normal when the split
time is three seconds.
According to Table 9, we can see that our attack achieves higher
TPR after feature selection (except on the Tor_normal training
subset when the split time is two seconds), even though we are
using strictly less information after feature selection. The feature
subset each dataset uses is described in Appendix B. In the case
of SSH_normal, the jump in accuracy is especially surprising: an
almost two-percent increase in the true positive rate corresponds to
a one-third decrease in the false negative rate (6% to 4%). Our nal
TPR of 95.84% compares favorably with state-of-the-art attacks,
even though we only used two seconds of data. Against BuFLO,
feature selection left us with only 15 features that relate to time
statistics, as size and ordering features are removed by BuFLO. As
for Tor_normal, we are interested to nd that with feature selection
we only utilize 31 features, and we can achieve a similar TPR as
452 features in the Tor_normal dataset when the split time is two
seconds, even more, we have a slightly higher TPR with fewer
features when the split time is three seconds.
Attack Under the Closed-world Scenario. We compare our clas-
sier with k-FP [11] (which also uses random forests) and CU-
MUL [21] on three datasets above: SSH_normal, SSH_noisy, and
Tor_normal. For each dataset, we use the training subset to train the
classiers and the testing subset to test. In the closed-world setting,
we set the number of features k in the random subset I to 100. The
reason why we have such setting is that we do not consider feature
selection here such that we can systematically study the perfor-
mance of our attack without selection and our new WF attack can
achieve the highest TPR when k is set to 100 according to our stud-
ies. For k-FP, we set the parameters according to Hayes et al.’s code7,
and for CUMUL, we scale each feature linearly to the range of [-1,1]
and search from the range of parameters recommended by [21].
Figure 6, 7, and 8 show that TPR with the SSH_normal, SSH_noisy,
and Tor_normal datasets, respectively. According to the experiment
results, we made the following observations:
7https://github.com/jhayes14/k-FP
Figure 6: TPR of our classier compared to k-FP and CUMUL
while varying the initial chunk size between two seconds
and six seconds on the SSH_normal dataset.
Figure 7: TPR of our classier compared to k-FP and CUMUL
while varying the initial chunk size between two seconds
and six seconds on the SSH_noisy dataset.
• Our classier achieves better TPR on the initial chunk.
Our classier outperforms k-FP though they have similar ne-
grained features such as the number of packets and packet or-
dering. This may be because we also use high-level features, e.g.,
Fast Liechtenstein-like distance, which can be used to describe
the correlation between two network ows in a coarse manner.
CUMUL always had a low TPR even though we tried various
parameters. According to the previous studies [11], CUMUL does
not outperform k-FP, which is consistent with our results.
• Increasing the initial chunk size does not always increase
TPR. According to Table 6, on SSH_normal, the TPR of our
new WF classier slightly decreases when the split time in-
creases due to the limited number of instances. On SSH_noisy
and Tor_normal, the TPR increases when the split time increases.
In particular, on Tor_normal, our classier achieves a TPR of
50.4% for an initial chunk size of two seconds and 77.08% when
it is six seconds.
• Tor_normal is the most dicult to classify. This is followed
by SSH_noisy and SSH_normal is the easiest to classify. Previous
researchers [22] have also observed that Tor is more dicult than
SSH because all Tor cells have the same size.
The poor performance of our classier on Tor_normal is due to
large round-trip times: if we take a short initial chunk size, it may
leave us with almost no data to classify. To mitigate this eect, we
preprocess the training and testing data of Tor_normal, and remove
the rst ten packets in the network ow. Thus, each network ow
will start from the 11th packet if there are fewer than ten packets
in the rst three seconds. We repeat the above experiment with
335
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Y. Xu, T. Wang, Q. Li, Q. Gong, Y. Chen, and Y. Jiang
Figure 8: TPR of our classier compared to k-FP and CUMUL
while varying the initial chunk size between two seconds
and six seconds on the Tor_normal dataset.
Figure 11: The TPR of dierent specied split time on
Tor_two with two pages where true delay time is 3s
generates the distribution of instances close to the original datasets,
which outputs reliable generalization error for the comparison of
three attacks. As shown in Figure 10, our new WF classier performs
best when the initial chunk size is less than 17 seconds. k-FP is
slightly better than our classier if the whole network ow is used.
When the initial chunk size is 10 seconds, our TPR is 85.4%, while
we can have a TPR of 89.93% when the initial chunk size is 20
seconds. CUMUL performs well with the entire network ow and
achieves 91% TPR. Our classier is especially eective on a short
initial chunk.
Evaluation with Open-World Setting. We also compare our clas-
sier with k-FP and CUMUL on the more realistic open-world set-
ting using 10-fold cross-validation. We vary the size of the unmon-
itored part from 500 instances to 2500 instances on SSH_normal
training subset and Tor_normal training subset. Here, we use n-
gerprints of length 200 bytes recommended by [11] and set the
neighbor of kNN to one that is the default setting in Hayes et
al.’s code. For CUMUL, we use the same method as in closed-world
setting.
As shown in Table 10, our attack has a TPR of 86.56% and an
FPR of 0.52% when training on 2500 unmonitored web pages in
SSH_normal. We show that the FPR of all three attacks decreases
when we increase the number of unmonitored pages. Our attack
achieves a higher TPR and lower FPR than both k-FP and CUMUL.
When there are 500 unmonitored pages, we have a 90.23% TPR,
which beats CUMUL by more than 20%, and k-FP by 3%.
We can achieve a TPR of 65.64% and FPR of 0.1% when training
on 2500 unmonitored instances in Table 11. Although Tor_normal
presents a greater challenge for classication than SSH_normal, our
classier nevertheless beats both CUMUL and k-FP when the initial
chunk size is 3s. We can observe similar results with other initial
chunk sizes. Furthermore, as shown in Figure 10, the TPR increases
when the size of the initial chunk increases. The possible reason
is that larger initial chunk sizes allows more data for classication
and does not incur signicant noise due to the slow connections
on Tor.
The Impact of Wrong Split Time. In order to show the impact
of the wrong split time (i.e., wrong initial chunks), we use the
Tor_normal training subset with dierent assumed split points to
train classiers, where the delay ranges from two seconds to six
seconds, and test such a classier on the Tor dataset with two pages.
Figure 9: TPR of our classier compared to k-FP and CUMUL
while varying the initial chunk size between two seconds
and six seconds on the modied Tor_normal dataset.
Figure 10: TPR of our classier compared to k-FP and CU-
MUL while increasing the initial chunk up to the maximum
60 seconds on the Tor_normal dataset.
the modied Tor_normal dataset. Figure 9 shows that our modied
dataset improves the accuracy of all three classiers. When the split
time is four seconds, we achieve 78% TPR, which is much better
than Tor_normal. In particular, when the split time is six seconds,
we achieve 81.04% TPR.
Furthermore, we measure how TPR changes when increasing the
initial chunk size. We combine the training and testing subsets of
Tor_normal, and then use 10-fold cross-validation to test the three
classiers. Note that, the reason why the setting here is dierent
from the previous experiment setup in Section 6.4 is that we want
to fairly compare the performance of identifying pages in the single
tab and two-tab scenarios, where training on single tabs is required
for the two-tab scenario, while 10-fold cross-validation used here
336
A Multi-tab Website Fingerprinting Aack
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Table 10: TPR and FPR of our classier compared to k-FP and CUMUL on SSH_normal with an initial chunk size of two seconds.
Page number
500
1500
2500
CUMUL
TPR
69.68%
66.28%
64.32%
FPR
28.8%
16.2%
11.48%
k-FP
TPR
86.8%
86.36%
85.88%
FPR
10%
5.8%
4.48%
Our
TPR
90.23%
88.84%
86.56%
FPR
6.2%
1.1%
0.52%
Table 11: TPR and FPR of our classier compared to k-FP and CUMUL on Tor_normal with an initial chunk size of 3s.
Page number
500
1500
2500
CUMUL
TPR
58.8%