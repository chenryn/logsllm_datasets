implement. Furthermore, the structure used by modern shellcode
(i.e., [NOP][DECODER][ENC PAYLOAD][RETADDR]) is really just
a conventional design that happens to work. Nothing prevents the
attacker from modifying the sections between the sled and the re-
turn address. With some additional jmp instructions, it is not hard
to imagine seeing future shellcode of the forms:
[NOP][ENCRYPTED PAYLOAD][DECODER][RETADDR]
[NOP][DECODER 1][ENC. PAYLOAD][DECODER 2][RETADDR]
[NOP][PADDING][ENC. PAYLOAD][PADDING][DECODER][RETADDR]
and so on. These types of encoding will present dif(cid:2)culty for both
static and dynamic code analysis.
1.3 Contributions
Conventional wisdom has held that attackers retain a signi(cid:2)cant
advantage by using polymorphic tactics to disguise their shellcode.
To the best of our knowledge, however, there exists no quantitative
analysis of this advantage. Our work provides empirical evidence
to support this folk wisdom and helps improve understanding of the
polymorphic shellcode problem in the following ways:
(cid:15) We illustrate the ultimate futility of string(cid:150)based signature
schemes by showing that the class of n-byte decoder sam-
ples spans n-space. Although our results should not be inter-
preted as a call for the immediate abandonment of all signature(cid:150)
based techniques, we believe there is a strong case for inves-
tigating other protection paradigms.
(cid:15) As a corollary, we show that given any normal statistical
model, there is a signi(cid:2)cant probability that an attacker can
craft successful targeted attacks against it.
(cid:15) We propose metrics to gauge the relative strengths of poly-
morphic engines, and we use these to examine some of the
current state-of-the-art engines. We believe our methodol-
ogy is novel and helps provide some insight in a space that
has generally been lacking in quantitative analysis.
(cid:15) We show how to augment existing polymorphic engines and
demonstrate this process by presenting our implementation
of a proof-of-concept engine.
The problem we address can be stated as follows:
PROBLEM DEFINITION Given n bytes, there can be a set of
256n possible strings. The speci(cid:2)c class of x86 code of length n
that corresponds to decoders is a subset of this superset, i.e., span-
ning a subspace within this larger space. How dif(cid:2)cult is it to model
this subspace (cid:151) in other words, what is the magnitude of this span?
What are polymorphic threats we can expect to see in the immediate
future? Finally, what are the theoretical limits?
We combine a number of methods to answer this question. First,
we introduce a set of measures to assess the randomness of a pop-
ulation of samples. We employ these measures to analyze a pool
of decoders generated by existing polymorphic engines. Next, we
demonstrate our improvements to existing polymorphic techniques.
Finally, we analyze the theoretical limits of polymorphism by ex-
amining a (cid:2)xed size space of n-bytes. We explore this space using
ef(cid:2)cient genetic algorithms to characterize the span of all x86 code
that exhibits polymorphic behavior. Along the way, we explain
why signature(cid:150)based detection currently works, why it may work
in the short term, and why it will progressively become less valu-
able. We also discover that shellcode behavior varies enough to not
only present a challenge for signature systems, but also presents a
signi(cid:2)cant challenge for statistical approaches to model malcode.
2. POLYMORPHIC ENGINE ANALYSIS
This section explains the details of our approach for analyzing
the range of decoders generated by any given engine. We apply our
methods to analyzing six of the state-of-the-art polymorphic en-
gines used in the wild: ADMmutate, CLET, and four engines from
Metasploit: Shikata Gai Nai1, Jumpcall additive, Call4dword and
fnstenv mov. Previous research on automatic generation of exploit
signatures from polymorphic code [22, 28] reports successful de-
tection of exploits from many existing engines, some of which are
from Metasploit. Our work makes it easy to visually observe the ar-
tifacts that some of these engines leave in each shellcode instance
that they generate: artifacts which can be taken advantage of for
detection. We show, however, that these artifacts are not strongly
correlated with polymorphic behavior itself and look very different
across different engines (cid:151) thus they cannot be generalized to detect
polymorphic behavior outside of their training class. We designed
our measures2 around the following parameters:
VARIATION STRENGTH: Given sequences of length n, the varia-
tion strength of an engine measures that engineâ€™s ability to gener-
ate sequences of length n that span a suf(cid:2)ciently large portion of
n-space. This metric is meant to offer some insight into the mag-
nitude of the set of signatures that may be needed to accurately
encapsulate all decoders generated by a particular engine.
PROPAGATION STRENGTH: For the sequence of decoders, x1,. . . ,
xN that an engine can generate, the propagation strength of the
engine characterizes the ef(cid:2)cacy of the engine in making any two
samples xi, xj for all i; j = 1 : : : N, look different from one an-
other. The purpose of this metric is to quantify the amount of infor-
mation gain obtained by isolating a few samples from a particular
engine.
1A common Japanese cultural phrase meaning (cid:147)nothing can be
done about it.(cid:148)
2Notations used in this paper: all variables in bold text font such as
x and y denote column vectors. We use xi to denote the ith vector
of a set of vectors and we use x(i) to denote the ith component of
the vector x.
Using these metrics, we analyze six current polymorphic en-
gines and provide some measurements for their relative polymor-
phic strengths, yielding a scaled score for each engine which we
call the (cid:147)relative polymorphism strength score(cid:148) or p-score. We use
this score to compare the samples generated by the polymorphic
engines to sequences that we generate at random. In addition, we
leverage the concept of a spectral image, which allows easy visual-
ization of the amount of distortion in a sample pool. We combine
this technique with the above metrics to derive our results and con-
(cid:2)rm the folk wisdom that the class of x86 polymorphic shellcode
is too random to model.
SPECTRAL IMAGE
Given any polymorphic engine, we can use it to generate a set of
D decoders, each of length N. For non-(cid:2)xed length decoders, we
can add padding at the end to make the lengths equal so that they
can be displayed. We next sort these decoders and stack them to-
gether row-wise into a D(cid:2) N matrix, then display this matrix as an
image, considering the ith byte of decoder j as the intensity value
for the (i; j)th pixel of the image. A byte value of 0x00 produces a
black pixel; 0xFF produces a white pixel. Values within this range
exhibit a shade of gray. This representation helps us visualize the
randomness of a set of generated decoders. Salient bytes (cid:150) bytes
that exist in the same places within all generated decoders (cid:150) are
easily identi(cid:2)able artifacts since they show up as visible columns
within the spectral image. Figure 2 shows the spectral images of the
six engines we examined. They were generated by taking a single
shellcode sample and encrypting it with each engine 10,000 times
to generate 10,000 unique shellcode sequences for each engine. We
extracted the decoder portions from these sequences, sorted them,
down(cid:150)sampled (so that the number of samples used is on the order
of the dimensions of the samples), then generated the images.
Notice how Shikata Ga Nai generates roughly three subclasses
of decoders. The same blocks of code exist in the engine but not al-
ways at the same place. The weaknesses of the c4d and fnstenv
mov engines are apparent as the vertical columns show that these
engines always embed large artifacts in every decoder. These arti-
facts can be used as signatures and are easily recovered using cur-
rent techniques [22, 28]. As the images show, even though these
engines perform the same basic actions to decode a string within
a small distance of itself in memory, these invariants do not hold
across different engines. For example, the vertical band for CLET
represents clearing of registers (we con(cid:2)rmed this by reading their
documentation).
MINIMUM EUCLIDEAN DISTANCE
Any string x of (cid:2)xed length n can be considered as a single point
embedded in n-space, i.e., x 2 Rn. For n = 2, we can imagine
a 2-D plane (cid:150) the string (cid:147)ab(cid:148), where the ASCII character (cid:147)a(cid:148) is 97
and (cid:147)b(cid:148) is 98, can be considered as a single point in this 2-D plane,
embedded at (97,98). The string (cid:147)yz(cid:148) would likewise be embedded
at (121,122). The Euclidean (cid:147)distance(cid:148) between these two strings
quanti(cid:2)es the length of the line drawn from (97,98) to (121,122)
and is calculated using the Euclidean norm, denoted jj(cid:1)jj and de-
(cid:2)ned as: jjxjj = pPn
i=1(x(i))2. Without loss of generality, we
can see that this extends for strings up to higher order n-space for
any arbitrary n. We can therefore consider each decoder string a
single point within this n-space of all strings of length n.
The minimum Euclidean distance between two strings is de(cid:2)ned
as the normalized Euclidean distance between the strings under ar-
bitrary byte(cid:150)level rotation. We (cid:2)nd this de(cid:2)nition useful because
we expect decoders to employ forms of polymorphism that retain
the same ciphering methods but shift the order of operations.
(cid:14)(x; y) = min
r=1:::n(cid:20)jjx (cid:0) rot(y; r)jj
jjxjj + jjyjj
(cid:21)
(1)
rot(y; r) means rotate the string y to the left by r-bytes, with
wraparound. We divide by jjxjj + jjyjj to transform the metric
into a ratio of the distance between two vectors with respect to the
sum of their individual lengths. This normalizes the metric and re-
moves the number of dimensions (length) of a string as a factor in
the distance. This distance measure plays an important role in our
metrics, described more fully in the following sections.
VARIATION STRENGTH
Following our previously described notion of viewing decoders
as embedded points in n-dimensional space, we can conceptually
visualize a set of decoders generated by a particular engine as a
cloud of points in this n-space. The magnitude of the space covered
by the span of these points is what we refer to as the variation
strength of the engine. The magnitude and complexity of the span
is directly proportional to the dif(cid:2)culty of modeling the engine, i.e.
the number of signatures in the case of signature based methods
or model complexity in the case of statistical models. We present
a method to bound this magnitude, making use of the covariance
matrix, which is de(cid:2)ned as the following:
(cid:6) =
1
N
N
Xi=1
(xi (cid:0) (cid:22))(xi (cid:0) (cid:22))T
(2)
This gives us a symmetric matrix with dimensions n(cid:2)n for decoder
sequences of dimensionality n. Here, xi is a decoder sample and
i xi is the sample mean of the set of decoders. x and (cid:22)
(cid:22) = 1
are column vectors and T denotes the vector transpose operator.
N PN
The covariance matrix describes the shape of an n-dimensional
ellipsoid in n-space. Therefore, recovering the covariance matrix
for a set of decoders recovers hyper-ellipsoidal (cid:2) bound on the data
set. Calculating the span of the set is a problem of measuring the
radii of the principle axes of the ellipsoid, which is an eigenvec-
tor decomposition problem. Recall that eigenvector decomposition
(cid:2)nds a new set of basis vectors that spans a space de(cid:2)ned by any
given symmetric matrix. The new basis vectors are called eigenvec-
tors, and their corresponding eigenvalues reveal the scale of these
vectors. Thus, we recover v and (cid:21) such that (cid:6)v = v(cid:21), where v is
the set of n eigenvectors and (cid:21) is the set of n eigenvalues. We now
de(cid:2)ne the variation strength of a polymorphic engine as:
(cid:9)(engine) =
p(cid:21)i
1
n
n
Xi=1
(3)
The square roots of the eigenvalues are taken to whiten the distri-
bution, and we take the average of the eigenvalues since we are
interested in the relative scatter of the decoders in n-space; higher
dimensions should not increase the score. The utility of the nor-
malization procedures is shown in Table 1, where the distribution
spanning [0..128] is shown to exhibit half of the (cid:147)randomness(cid:148) of
one that spans [0..256].
To analyze the variation strength of an engine, we encoded a
shellcode sample 10,000 times and extracted the corresponding de-
coder sequences. After generating the covariance matrix according
to Equation 2, we recovered the eigenvalues and obtained the score
using Equation 3. The larger the number of samples used to gen-
erate the covariance matrix, the more accurate the estimate will be.
In practice, around a few hundred samples is usually enough3.
3De(cid:2)ning a full ranked covariance matrix requires more samples
(a)
(b)
(c)
(d)
(e)
(f)
Figure 2: Spectral images to show variation strength (a) Shikata Na Gai (b) jcadd (c) call4dword (d) fnstenv mov (e) ADMmutate (f)
CLET. Each pixel row represents a decoder from that engine and each individual pixel value represents the corresponding byte from that decoder.
A column of identical intensities indicates an identi(cid:2)able artifact left by the engine.
PROPAGATION STRENGTH
If the true decoder distribution happens to exhibit a large span
but lies on a lower-dimensional (cid:147)manifold(cid:148) in n-space where the
signi(cid:2)cant dimensions of the manifold is much less than n (in the
worst case, imagine a hollow n-dimensional sphere with large radii)
then the variation strength might overestimate the bound on the n-
space scatter since the decoders do not exist in the space between
the sphere and the origin. This is why we introduce a second com-
ponent to the engine strength metric based on the expected dis-
tances between decoders. To visualize this metric, imagine a fully
connected graph where each node is a decoder sample and the edge
weight is the distance between any two nodes. The average of the
edge weight is then proportional to the scale of the graph. We
call this metric the propagation strength because of its close re-
lationship to the problem of connecting any two decoder samples
together.
(cid:8)(engine) = (1 (cid:0)
(cid:17)
n
)Z Z p((cid:14)(x; y)))(cid:14)(x; y) dx dy
(4)
(cid:14)(x; y) is a function that returns the distance between any two de-
coder sequences. Flexibility in choosing the (cid:14) function allows us
to (cid:2)ne tune this metric. For our experiments we set delta as Equa-
tion 1, which is rotation invariant. If the engine performs a simple
shift in the different layers of cipher operations, then the bytes are
decoupled from one another, and the variance in the samples would
be great. The propagation strength, however, would be very low
since (cid:14) is shift invariant, thus lowering the overall score. In addi-
tion, we introduce the (cid:17) variable which is de(cid:2)ned as the number
of salient bytes within all of the decoder samples generated by an
engine. This parameter is used as a scaling factor to decrease the
strength of engines that leave consistent artifacts in their decoders
which signature(cid:150)based IDS implementation can lock on to. If prior
information is available in the form of probability density function
(pdf) for p((cid:14)(x; y)) such as a Gaussian then the above equation is
solvable in closed form and can act as a regularizer for this met-
ric. If not we can use a uniform prior i.e. p((cid:14)((cid:1))) = 1 and the
result can be approximated by generating the matrix D such that
Di;j = (cid:14)(xi; xj) and taking the average of this matrix. Since (cid:14)((cid:1))
is symmetric (Di;j = Dj;i), we only (cid:2)nd the average of the upper
diagonal of the matrix. We use this simpler estimation procedure
to derive the results presented in this paper.
A polymorphic engine might have a restricted span, but if the