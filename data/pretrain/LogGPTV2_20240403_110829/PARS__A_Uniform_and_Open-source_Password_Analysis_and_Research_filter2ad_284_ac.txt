Renren
−
− − −
−
Tianya
21.0
7.9 0.2 2.1
6.6
34.6
8.4 0.3 5.6
7.1
5.5
6.5 0.2 1.7
5.4
LinkedIn
Rockyou
Gamigo
−
69.1
69.5
73.8
72.3
50.6
62.2
37.4
36.1
42.6
42.2
39.9
−
29.7
36.7
22.5
6.2 0.3 1.9 20.6
4.9
− − −
−
−
10.8 19.4 0.2 1.4 27.6
10.9 15.0 0.3 1.7 25.3
11.5 20.1 0.3 1.7 26.7
6.6
6.0 0.0 0.4 15.4
6.0 0.1 1.2 20.2
6.8
6.0
5.1 0.0 0.4
4.9
3.6
1.9 0.3 2.9
2.5
2.5
10.6 0.1 0.8
9.5
5.7
15.5 18.9 0.3 3.4
9.4
17.5 21.9 0.4 5.7
5.1
14.0 14.1 0.3 3.9
−
−
− − −
17.2 27.5 0.1 5.9 17.0
15.3 23.4 0.0 1.4
6.0
22.6
−
26.8
24.3
26.4
11.5
18.7
5.2
4.3
14.4
15.5
13.7
14.0
−
22.5
19.1
6.9 0.5 8.1 21.1
5.3
12.4 23.8 0.3 1.8 19.0
−
− − −
−
24.7 32.6 0.6 5.9 29.4
15.4 25.3 0.6 5.3 29.5
11.6 12.3 0.1 1.8 14.5
12.2 12.9 0.2 4.3 22.7
10.2 10.3 0.0 1.4
4.4
9.2
2.8
5.4
8.7
15.7 22.8 0.4 5.7 12.4
17.5 25.2 0.5 8.2 16.2
14.1 16.9 0.5 6.8 12.8
16.4 31.3 0.1 4.0 18.8
− − −
−
−
6.9
14.9 27.4 0.1 2.5
23.3
36.4
−
30.0
35.6
20.9
26.0
16.1
10.7
26.2
26.5
22.1
25.9
30.2
−
26.8
13.2 14.6 1.7 25.0 48.5
24.0
11.8 17.5 0.9 5.1
23.4 30.0 1.4 12.7 52.4
−
− − −
−
14.7 19.9 1.9 15.6 53.1
10.0 15.5 0.3 5.0
32.8
11.2 15.9 0.5 11.7 50.6
8.5
10.3
13.1 0.1 3.7
1.3 0.2 2.1
1.4
7.5 0.1 0.9
7.4
10.6 12.5 0.1 2.6
11.5 13.7 0.3 3.6
9.6
9.1 0.2 3.0
11.2 17.3 0.0 2.1
11.5 17.9 0.1 4.4
−
− − −
3.6
2.7
5.2
7.0
4.9
11.1
12.9
−
51.5
57.2
58.1
−
59.3
46.8
53.9
37.3
4.2
10.7
11.3
9.3
10.5
14.1
15.7
−
Table 4: Training-free password cracking. Each
value indicates the percentages of passwords been
cracked.
7k7k CSDN Duduniu Renren Tianya LinkedIn Rockyou Gamigo
JtR-W 0.0 0.4
JtR-I 23.7 6.3
0.9
11.7
1.6
28.1
0.5
15.5
1.7
17.0
1.1
24.9
1.1
11.2
(1) By trying a dictionary consisting of frequently used
words (passwords), JtR-W can crack 1.7% and 1.6% pass-
words of LinkedIn and Renren, respectively. This implies
that some users of these two datasets just choose some com-
mon passwords. More impressively, without any training
knowledge, JtR-I can crack ∼ 1/4 passwords of Renren,
Rockyou, and 7k7k. This is because these three datasets
have more passwords that are short, simply composed, and
with popular structures.
(2) From Table 5, we can see that when cracking 7k7k,
Renren-trained JtR-M has the best performance; when crack-
ing CSDN, Duduniu-trained OMEN has the best performance;
and when cracking Rockyou, LinkedIn-trained VCT has the
best performance. Therefore, no cracking algorithm is al-
ways optimal. The actual cracking performance depends
on multiple factors, e.g., training data, targeting data, and
cracking algorithm.
(3) Following the above observation, when cracking a pass-
word/dataset, it is important to choose both proper train-
ing data and a proper cracking algorithm. For instance,
Duduniu-trained OMEN has much better performance to
crack CSDN than Gamigo-trained OMEN. This is because
the two Chinese datasets Duduniu and CSDN are more struc-
turally, syntactically, and semantically similar than that of
Gamigo and CSDN. In addition, Rockyou-trained VCT has
better performance than Rockyou-trained NS when cracking
LinkedIn. This is because although Rockyou and LinkedIn
are structurally, syntactically, and semantically similar, VCT
considers password structure, syntax, and semantics during
the training phase while NS only partially considers pass-
word structure and syntax.
(4) In most of the cases, VCT has better performance
than PCFG. This is because during the training phase, VCT
considers password structure, syntax, and semantics infor-
mation together while PCFG only considers password struc-
ture information (see Table 3). However, in the scenarios
that the training and targeting datasets are syntactically
and semantically diﬀerent (although this does not happen
frequently), PCFG may perform better than VCT.
(5) For the Markov model based algorithms, OMEN and
JtR-M have better performance than NS and 3g. The main
reason is that OMEN and JtR-M generate password guesses
in the decreasing order of likelihood (the optimal password
cracking strategy), while NS and 3g generate password guesses
above some predeﬁned threshold (not necessarily following
the decreasing order of likelihood). Furthermore, 3g per-
forms better than NS. This is because NS is actually a 1-
gram Markov model based algorithm, which implies that
3g considers more information when training the password
cracking model. Hence, 3g can generate more accurate guesses
than NS. However, as we analyzed before, among all the
Markov model based algorithms, NS has the largest guess
space, i.e., NS has the largest password space coverability.
(6) Gamigo only has at most 17.9% passwords cracked
among all the evaluation scenarios. The reason is that all
the other datasets are from diﬀerent lingual/cultural do-
mains other than Gamigo. Therefore, the cracking algo-
rithms trained by these datasets are not eﬀective when mak-
ing guesses. This can be conﬁrmed by the results in Table
2. Gamigo is not structurally, syntactically, or semantically
similar to other datasets. Similarly, LinkedIn has at most
27.5% passwords cracked since it has more passwords with
unpopular password structures than other Chinese and En-
glish datasets.
5. PASSWORD MEASUREMENT
5.1 Password Measurement Advances
Leveraging the single-sign-on passwords used by 25K fac-
ulty, staﬀ, and students at CMU, Mazurek et al. measured
the password guessability of university passwords [20]. An-
other interesting work is [21], where based on a survey of
470 CMU computer users, Shay et al. analyzed users’ atti-
tudes and behaviors when encountering stronger password
requirements. In [3], Li et al. conducted an empirical analy-
sis of Chinese web passwords. According to their statistical
results, user-chosen passwords have explicit regional diﬀer-
ences. In [4], Bonneau analyzed an anonymized corpus of
70M Yahoo! passwords.
In [8], Weir et al. evaluated testing metrics, e.g., NIST
entropy, for password creation policies by attacking revealed
passwords using their PCFG based cracking algorithm. They
found that the NIST entropy is not an eﬀective metric for
password security, and proposed new PCFG cracking based
password creation policies. Another work employing the
password cracking idea to measure password strength is [9],
where Kelley analyzed 12K passwords collected under seven
composition policies via an online study. In [5], Houshmand
and Aggarwal proposed a tool, named Analyzer and Modiﬁer
for Passwords (AMP), to help users choose stronger pass-
words. AMP ﬁrst estimates a password’s crackability based
on the PCFG cracking model, and then modiﬁes the weak
password slightly to meet the security requirement. Koman-
duri et al. implemented another tool, namely Telepathwords,
to help users create strong passwords [22]. In [23], Forget et
al. also developed a tool, namely Persuasive Text Passwords
(PTP), which leverages the persuasive technology principle
to inﬂuence users in creating more secure passwords.
In [6], Ur et al. studied the eﬀect of strength meters on
password creation. They found that signiﬁcant increases in
password resistance were only achieved using meters that
scored passwords stringently. Another work studying ex-