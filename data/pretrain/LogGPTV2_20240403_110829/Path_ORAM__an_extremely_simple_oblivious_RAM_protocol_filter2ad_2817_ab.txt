M corresponds to the oldest load/store operation.
Let A((cid:126)y) denote the (possibly randomized) sequence of
accesses to the remote storage given the sequence of data
requests (cid:126)y. An ORAM construction is said to be secure if (1)
for any two data request sequences (cid:126)y and (cid:126)z of the same length,
their access patterns A((cid:126)y) and A((cid:126)z) are computationally
indistinguishable by anyone but the client, and (2) the ORAM
construction is correct in that it returns on input (cid:126)y data that
is consistent with (cid:126)y with probability ≥ 1 − negl(|(cid:126)y|), i.e., the
ORAM may fail with probability negl(|(cid:126)y|).
Binary tree. The server stores a binary tree data structure
of height L = (cid:100)log2(N )(cid:101)− 1 and 2L leafs. The tree can easily
be laid out as a ﬂat array when stored on disk. The levels of
the tree are numbered 0 to L where level 0 denotes the root
of the tree and level L denotes the leafs.
Bucket. Each node in the tree is called a bucket. Each
bucket can contain up to Z real blocks. If a bucket has less
than Z real blocks, it is padded with dummy blocks to always
be of size Z. It suﬃces to choose the bucket size Z to be a
small constant such as Z = 4 (see Section 5.1).
Path. Let x ∈ {0, 1, . . . , 2L − 1} denote the x-th leaf node in
the tree. Any leaf node x deﬁnes a unique path from leaf x
to the root of the tree. We use P(x) to denote set of buckets
along the path from leaf x to the root. Additionally, P(x, (cid:96))
denotes the bucket in P(x) at level (cid:96) in the tree.
Server storage size. Since there are about N buckets in
the tree, the total server storage used is about Z · N blocks.
3.3 Client Storage and Bandwidth
The storage on the client consists of 2 data structures, a
stash and a position map:
Stash. During the course of the algorithm, the client locally
stores a small number of blocks in a local data structure
S called the stash. In Section 6, we prove that the stash
has a worst-case size of O(log N ) · ω(1) blocks with high
301N
S
position
Total # blocks outsourced to server
B
Z
P(x)
P(x, (cid:96))
L = (cid:100)log2 N(cid:101) − 1 Height of binary tree
Block size (in bits)
Capacity of each bucket (in blocks)
path from leaf node x to the root
the bucket at level (cid:96) along the path
P(x)
client’s local stash
client’s local position map
block a is currently associated with leaf
node x, i.e., block a resides somewhere
along P(x) or in the stash.
x := position[a]
Table 2: Notations.
probability. In fact, in Section 5.2, we show that the stash
is usually empty after each ORAM read/write operation
completes.
Position map. The client stores a position map, such that
x := position[a] means that block a is currently mapped to
the x-th leaf node — this means that block a resides in some
bucket in path P(x), or in the stash. The position map
changes over time as blocks are accessed and remapped.
Bandwidth. For each load or store operation, the client
reads a path of Z log N blocks from the server and then writes
them back, resulting in a total of 2Z log N blocks bandwidth
used per access. Since Z is a constant, the bandwidth usage
is O(log(N )) blocks.
Client storage size. Note that the position map is of
size N L = N log N bits, or equivalently, N/χ blocks with
block size B = χ · log N . In Section 3.7, we use this prop-
erty to recursively store the position map in log N/ log χ
separate Path ORAMs. This reduces the client storage to
O(log2 N/ log χ)·ω(1) at the cost of increasing the bandwidth
to O(log2 N/ log χ).
If the client stores its storage at the server, then at every
load/store operation the client needs to retrieve this storage
from the server. Since the client accesses the log N/ log χ
separate ORAMs one after another, the client only needs
suﬃcient storage for reading in a single path and stash of
each ORAM separately: This leads to a client storage of
O(log N ) · ω(1) and bandwidth O(log2 N/ log χ) · ω(1).
3.4 Path ORAM Initialization
The client stash S is initially empty. The server buckets are
intialized to contain random encryptions of the dummy block
(i.e., initially no block is stored on the server). The client’s
position map is ﬁlled with independent random numbers
between 0 and 2L − 1. The position map initially contains
null for the position of every block. The position null is a
special value indicating that the corresponding block has
never been accessed and the client should assume it has a
default value of zero.
3.5 Path ORAM Reads and Writes
In our construction, reading and writing a block to ORAM
is done via a single protocol called Access described in Fig-
ure 1. Speciﬁcally, to read block a, the client performs
data ← Access(read, a, None) and to write data∗ to block a,
the client performs Access(write, a, data∗). The Access proto-
col can be summarized in 4 simple steps:
S ← S ∪ ReadBucket(P(x, (cid:96)))
Access(op, a, data∗):
1: x ← position[a]
2: position[a] ← UniformRandom(0 . . . 2L − 1)
3: for (cid:96) ∈ {0, 1, . . . , L} do
4:
5: end for
6: data ← Read block a from S
7: if op = write then
8:
9: end if
10: for (cid:96) ∈ {L, L − 1, . . . , 0} do
11:
12:
13:
14:
15: end for
S ← (S − {(a, data)}) ∪ {(a, data∗)}
S(cid:48) ← {(a(cid:48), data(cid:48)) ∈ S : P(x, (cid:96)) = P(position[a(cid:48)], (cid:96))}
S(cid:48) ← Select min(|S(cid:48)|, Z) blocks from S(cid:48).
S ← S − S(cid:48)
WriteBucket(P(x, (cid:96)), S(cid:48))
16: return data
Figure 1: Protocol for data access. Read or write a
data block identiﬁed by a. If op = read, the input parameter
data∗ = None, and the Access operation reads block a from
the ORAM. If op = write, the Access operation writes the
speciﬁed data∗ to the block identiﬁed by a and returns the
block’s old data.
1. Remap block (Lines 1 to 2): Randomly remap the
position of block a to a new random position. Let x
denote the block’s old position.
2. Read path (Lines 3 to 5): Read the path P(x) con-
taining block a.
3. Update block (Lines 6 to 9): If the access is a write,
update the data stored for block a.
4. Write path (Lines 10 to 15): Write the path back
and possibly include some additional blocks from the
stash if they can be placed into the path. Buckets are
greedily ﬁlled with blocks in the stash in the order of
leaf to root, ensuring that blocks get pushed as deep
down into the tree as possible. A block a(cid:48) can be placed
in the bucket at level (cid:96) only if the path P(position[a(cid:48)])
to the leaf of block a(cid:48) intersects the path accessed P(x)
at level (cid:96). In other words, if P(x, (cid:96)) = P(position[a(cid:48)], (cid:96)).
Subroutines. We now explain the ReadBucket and the
WriteBucket subroutine. For ReadBucket(bucket), the client
reads all Z blocks (including any dummy blocks) from the
bucket stored on the server. Blocks are decrypted as they
are read.
For WriteBucket(bucket, blocks), the client writes the blocks
blocks into the speciﬁed bucket on the server. When writing,
the client pads blocks with dummy blocks to make it of size
Z — note that this is important for security. All blocks (in-
cluding dummy blocks) are re-encrypted, using a randomized
encryption scheme, as they are written.
Computation. Client’s computation is O(log N ) · ω(1) per
data access. In practice, the majority of this time is spent
decrypting and encrypting O(log N ) blocks per data access.
We treat the server as a network storage device, so it only
needs to do the computation necessary to retrieve and store
O(log N ) blocks per data access.
3023.6 Security Analysis
To prove the security of Path-ORAM, let (cid:126)y be a data
request sequence of size M . By the deﬁnition of Path-ORAM,
the server sees A((cid:126)y) which is a sequence
p = (positionM [aM ], positionM−1[aM−1], . . . , position1[a1]),
where positionj[aj] is the position of address aj indicated
by the position map for the j-th load/store operation, to-
gether with a sequence of encrypted paths P(positionj(aj)),
1 ≤ j ≤ M , each encrypted using randomized encryption.
The sequence of encrypted paths is computationally indis-
tinguishable from a random sequence of bit strings by the
deﬁnition of randomized encryption (note that ciphertexts
that correspond to the same plaintext use diﬀerent random-
ness and are therefore indistinguishable from one another).
The order of accesses from M to 1 follows the notation from
Deﬁnition 1.
Notice that once positioni(ai) is revealed to the server,
it is remapped to a completely new random label, hence,
positioni(ai) is statistically independent of positionj(aj) for
j < i with aj = ai. Since the positions of diﬀerent addresses
do not aﬀect one another in Path ORAM, positioni(ai) is
statistically independent of positionj(aj) for j < i with aj (cid:54)=
ai. This shows that positioni(ai) is statistically independent
of positionj(aj) for j < i, therefore, (by using Bayes rule)
j=1 P rob(positionj(aj)) = (2l)−M . This proves
that A((cid:126)y) is computationally indistinguishable from a random
sequence of bit strings.
Now the security follows from Theorem 1 in Section 6:
For a stash size O(log N ) · ω(1) Path ORAM fails (in that it
exceeds the stash size) with at most negligible probability.
P rob(p) =(cid:81)M
3.7 Recursion to Reduce Client Storage
For χ ≥ 2, we now explain how to reduce the client storage
from N/χ blocks to O((log N )2/ log χ) · ω(1) blocks using
an approach similar to the one introduced in [34]. The
reduction of client storage comes at the cost of increasing the
bandwidth from O(log N ) to O(log2 N/ log χ). Notice that
assuming that the block size B = χ · log(N ) bits with χ ≥ 2
is a reasonable assumption that has been made by Stefanov
et al. [33, 34] and Shi et al. [30]. For example, a standard
4KB block consists of 32768 bits and this assumption holds
for all N ≤ 216382.
The main idea is to recursively store the position map in
a smaller Path ORAM with N(cid:48) = N/χ blocks of size B bits.
After log N/ log χ recursions, this leads to a constant sized
position map of the ﬁnal Path ORAM. The position map
stored on the client is only the one O(1) sized position map for
the last level of recursion. The client still needs to store the
an O(log N )· ω(1) stash for each of the O(log N/ log χ) levels
of recursion, resulting in a total of O((log N )2/ log χ) · ω(1)
blocks for the total client storage.
Path ORAM access with recursion. Consider a recur-
sive Path ORAM made up of a series of ORAMs called
ORam0, ORam1, ORam2, . . . , ORamX where ORam0 contains
the data blocks, the position map of ORami is stored in
ORami+1, and the client stores the position map for ORamX .
To access a block in ORam0, the client looks up its position in
ORam1, which triggers a recursive call to look up the position
of the position in ORam2, and so on until ﬁnally a position
of ORamX is looked up in the client storage. Essentially,
we can replace lines 1–2 in Figure 1 with a recursive call to
Access.
3.8 Integrity
Our protocol can be easily extended to provide integrity
(with freshness) for every access to the untrusted server
storage. Because data from untrusted storage is always
fetched and stored in the form of a tree paths, we can achieve
integrity by simply treating the Path ORAM tree as a Merkle
tree where data is stored in all nodes of the tree (not just
the leaf nodes). In other words, each node (bucket) of the
Path ORAM tree is tagged with a hash of the following form
H(b1 (cid:107) b2 (cid:107) . . . (cid:107) bZ (cid:107) h1 (cid:107) h2)
where bi for i ∈ {1, 2, . . . , Z} are the blocks in the bucket
(some of which could be dummy blocks) and h1 and h2 are the
hashes of the left and right child. For leaf nodes, h1 = h2 = 0.
Hence only two hashes (for the node and its sibling) needs
to be read or written for each ReadBucket or WriteBucket
operation.
In [28], Ren et al. further optimize the integrity veriﬁcation
overhead for the recursive Path ORAM construction.
4. APPLICATIONS
4.1 Oblivious Binary Search Tree
Based on a class of recursive, binary tree based ORAM
constructions, Gentry et al. propose a novel method for
performing an entire binary search using a single ORAM
lookup [11]. Their method is immediately applicable to
Path ORAM. As a result, Path ORAM can be used to
perform search on an oblivious binary search tree, using
O(log2 N/ log χ) bandwidth. Note that since a binary search
requires navigating a path of O(log N ) nodes, using existing
generic ORAM techniques would lead to bandwidth cost of
O((log N )3/ log log N ).
4.2 Stateless ORAM
Oblivious RAM is often considered in a single-client model,
but it is sometimes useful to have multiple clients accessing
the same ORAM. In that case, in order to avoid complicated
(and possibly expensive) oblivious state synchronization be-
tween the clients, Goodrich et al. introduce the concept of
stateless ORAM [18] where the client state is small enough so
that any client accessing the ORAM can download it before
each data access and upload it afterwards. Then, the only
thing clients need to store is the private key for the ORAM
(which does not change as the data in the ORAM changes).
In our recursive Path ORAM construction, we can down-
load and upload the client state before and after each ac-
cess. Since the client state is only O(log2 N/ log χ) · ω(1)
and the bandwidth is O(log2 N/ log χ), we can reduce the
permanent client state to O(1) and achieve a bandwidth
of O(log2 N/ log χ) · ω(1). Note that during an access the
client still needs about O(log N ) · ω(1) transient memory to
perform the Access operation, but after the Access operation
completes, the client only needs to store the private key.
4.3 Secure Processors
In a secure processor setting, private computation is done
inside a tamper-resistant processor (or board) and main mem-
ory (e.g., DRAM) accesses are vulnerable to eavesdropping
303and tampering. As mentioned earlier, Path ORAM is partic-
ularly amenable to hardware design because of its simplicity
and low on-chip storage requirements.
Fletcher et al. [9, 10] and Ren et al. [29] built a simu-
lator for a secure processor based on Path ORAM. They
optimize the bandwidth cost and stash size of the recursive
construction by using a smaller Z = 3 in combination with a
background eviction process that does not break the Path
ORAM invariant.
Maas et al. [24] built a hardware implementation of a Path
ORAM based secure processor using FPGAs and the Convey
platform.
Ren et al. [29] and Maas et al. [24] report about 1.2X to 5X
performance overhead for many benchmarks such as SPEC
traces and SQLite queries. To achieve this high performance,
these hardware Path ORAM designs rely on on-chip caches
while making Path ORAM requests only when last-level
cache misses occur.
5. EVALUATION
5.1 Stash Occupancy Distribution
Stash occupancy. In both the experimental results and the
theoretical analysis, we deﬁne the stash occupancy to be the
number of overﬂowing blocks (i.e., the number of blocks that
remain in the stash) after the write-back phase of each ORAM
access. This represents the persistent local storage required
on the client-side. In addition, the client also requires under