# Algorithmic Approaches to Low Overhead Fault Detection for Sparse Linear Algebra

**Authors:**
- Joseph Sloan
- Rakesh Kumar
- Greg Bronevetsky

**Affiliations:**
- Joseph Sloan, Rakesh Kumar: University of Illinois, Urbana-Champaign
- Greg Bronevetsky: Lawrence Livermore National Laboratory, Livermore, CA

## Abstract
The increasing size and complexity of High-Performance Computing (HPC) systems make it more likely that individual circuits will produce erroneous results, especially when operated in a low-energy mode. Previous techniques for Algorithm-Based Fault Tolerance (ABFT) have been proposed for detecting errors in dense linear operations but are inefficient for sparse problems. In this paper, we propose a set of algorithmic techniques that minimize the overhead of fault detection for sparse linear algebra. These techniques leverage two key insights: first, many sparse problems have well-structured data (e.g., diagonal, banded diagonal, block diagonal), which allows for sampling techniques to produce good approximations of the checks used for fault detection. Second, many linear applications have sufficient reuse, enabling preconditioning techniques to make these applications more amenable to low-cost algorithmic checks. The proposed techniques reduce performance overhead by up to 2x compared to traditional ABFT checks for a variety of sparse problems. A case study using common linear solvers further illustrates the benefits of the proposed algorithmic techniques.

**Index Terms:** ABFT, sparse linear algebra, numerical methods, error detection

## I. Introduction
As High-Performance Computing (HPC) systems become more capable, they also grow larger and more complex. This growth increases the likelihood of faults, particularly soft faults in chip circuitry, which can corrupt computations and produce incorrect output. For example, ASCI Q experienced 26.1 CPU failures per week, and the 104K node BlueGene/L system at Lawrence Livermore National Laboratory had an L1 cache soft error approximately every five hours. Future Exascale systems, with 4 million electronic chips and feature sizes as low as 12nm, will face even higher soft error rates (SER). Hardware-based fault detection approaches, which rely on redundancy, are impractical for future HPC systems due to power constraints. Therefore, fault detection for exascale systems will increasingly rely on software or algorithmic approaches. This paper focuses on low-overhead fault detection for sparse linear algebra, which is central to many HPC and emerging recognition, mining, and synthesis (RMS) applications.

## II. Related Work
Sparse linear algebra, particularly iterative solvers for sparse linear systems, is crucial for scientific computing and research. While much research addresses parallelization and performance, this paper focuses on making these systems resilient to soft faults. Prior work on checksum-based algorithmic approaches to fault tolerance includes Algorithm-Based Fault Tolerance (ABFT), which encodes computations using linear error-correcting codes. However, traditional ABFT approaches are not efficient for sparse linear algebra problems due to their lower algorithmic time complexity. This paper proposes optimizations for low-overhead checksum-based fault detection for sparse linear algebra applications.

## III. Algorithmic Fault Detection
### A. Motivation
Sparse problems often have well-defined structures, such as diagonal, banded diagonal, and block diagonal matrices. These structures allow for sampling techniques to approximate the checks used for fault detection. Two key techniques are:

1. **Approximate Random (AR) Checking**: Randomly samples the problem, reducing the overhead by avoiding computations associated with dimensions containing zeros.
2. **Approximate Clustering (AC) Checking**: Samples based on the problem's structure, improving the quality of the sampled columns by clustering their sums.

### B. Preconditioning Techniques
Linear applications often have significant reuse, allowing for preconditioning to make them more amenable to low-cost algorithmic checks. Two preconditioning techniques are:

1. **Identity Conditioning (IC)**: Computes a code that creates additional structure for a given problem.
2. **Null Conditioning (NC)**: Creates structure by finding a code that lies in the null space of the sparse problem.

## IV. Methodology
The effectiveness of the proposed techniques is evaluated through a series of experiments. The methodology involves comparing the performance and fault detection accuracy of the proposed techniques with traditional ABFT checks for sparse matrix-vector multiplication (MVM) and as a subroutine in linear solvers.

## V. Results
The proposed sparse techniques reduce the detection overhead by up to 2x (average overhead is 17%) for the same fault detection accuracy. Implementations of linear solvers using the sparse techniques are 20% faster than those using traditional ABFT (dense checks).

## VI. Conclusion
This paper presents a set of algorithmic techniques that significantly reduce the overhead of fault detection for sparse linear algebra. By leveraging the inherent structure and reuse in sparse problems, these techniques offer a practical solution for ensuring the reliability of HPC and RMS applications in the presence of soft faults.

---

This version of the text is more structured, concise, and professional, making it easier to read and understand.