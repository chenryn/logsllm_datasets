### Race Conditions Using Symbolic Links

As a simple, well-known example, we will discuss an old classical attack involving the "lpr" command. This example is illustrative due to its simplicity and the fact that it highlights a common security issue. Although this specific problem was resolved, the solution did not involve updating or refining the security policy but rather modifying the "lpr" command itself to include ad-hoc inode number checking. This "patch-and-pray" approach proved ineffective, as other attacks, such as the /bin/mail vulnerability [12], rely on the same principle.

#### The "lpr" Attack Steps:
1. Disconnect the printer.
2. User A: `lpr -s /home/bob/mydoc.ps`
3. User B: `rm /home/bob/mydoc.ps`
4. User C: `ln -s /etc/shadow /home/bob/mydoc.ps`
5. Reconnect the printer.
6. The lpr daemon prints the contents of `/etc/shadow`.

In this scenario, the user exploits a side-effect of a standard, legitimate system feature (symbolic links) in a way that does not break any access control rules by itself. However, it leads to illegal behavior because it allows the user to print the contents of a file (`/etc/shadow`) even if they do not have read access permissions.

It is important to note that the initial request to print `/home/user/mydoc.ps` could be submitted by any user, including one with read access to `/etc/shadow`. Additionally, nothing prevents the user from creating symbolic links to `/etc/shadow` as long as they are subject to the same access rules as the file they link to. Thus, this attack involves no illegal operations in the access control sense.

However, the proposed model can detect the final step (Ω4) as a security policy violation. We assume that the lpr daemon itself is permitted to read `/etc/shadow` (which is often the case). Therefore, Ω4 is not forbidden by itself. We also consider that the user Bob operates with reference bags that do not contain references to read `/etc/shadow`.

When creating the symbolic link, operation Ω3 generates references to the symlink. By default, a symlink is considered writable, readable, and executable, depending on the type of the file it points to. Thus:

\[ \text{ref3} = \text{Ref}(\Omega_{\text{uid:bob}}^3) = \text{uid : bob} \cup \text{symref s} \]

where `symref s` denotes the read, write, and execute references to the file `/home/bob/mydoc.ps` in the bag `uid:bob`.

By creating the link, Ω3 writes to the `/home/bob` directory. Ω4 performs two steps:
1. **Ω4.1**: Reads the `/home/bob` directory and searches for the `mydoc.ps` file.
2. **Ω4.2**: Opens the file.

The reference propagation rule states that:

\[ \text{ref4.1} = \text{Ref}(\Omega_{\text{rs}}^{4.1}) = \text{ref3} \cup \{R_{\text{uid:bob}}(f_d.\text{read})\} \]

where `fd` is a file descriptor to the `/home/bob` directory.

Trivially, Ω4.1 implies Ω4.2. According to Unix semantics, a read operation on the symlink is permitted if it is permitted on the file the link points to. Therefore, opening `/home/bob/mydoc.ps` for reading requires both `RS(/home/bob/mydoc.ps.openread)` and `RS(/etc/shadow.openread)`. Since `RS(/etc/shadow.openread) \notin \text{ref4.1}`, Ω4.2 cannot be executed independently. In fact, the operation would be possible as `Ω_{\text{ref4.1} \cup \text{rs}}^{4.2}`, but this is by definition an intrusion symptom.

### OpenSSH Vulnerability

This vulnerability, published in November 2001 [13], is a well-known attack that originally affected the telnet daemon. It was recently discovered that a similar technique could be used against OpenSSH to achieve the same result (a regular user getting a root shell).

The OpenSSH daemon has a controversial feature that allows users to define their own environment variables on login. If configured, this can be exploited to introduce a Trojan horse that prevents the user’s login shell from being started with the correct uid. In practice, the `LD_PRELOAD` variable is used to load an attacker-supplied shared library (e.g., `libroot.so`) that overrides the `setuid` system call, effectively forcing the session to start with `uid` set to 0.

The attack includes the following major steps:
1. Create and install `libroot.so`.
2. Log in as a regular user.
3. Load `libroot.so`.
4. Set the session’s `uid` to 0.
5. Start a root shell.

It is evident that Ω1 implies Ω2. Similarly, the `libroot.so` file requires a buffer that is written by operation Ω2 and read by Ω3 when calling the executable code. Memory buffer access monitoring is needed to establish that Ω3 requires a read reference to this buffer. The only reference to allow reading this buffer is `R_{\text{uid:boblibroot.so.read}}`, which results from Ω2. Additionally, Ω3 requires `R_{\text{setuid:root.setuid.root}}` to perform the actual `setuid` call. As these requirements cannot be met within the same reference bag, Ω3 is an intrusion symptom.

### Discussion

We have described how two different, realistic attacks can be detected using the proposed model. In the first example, there is nothing specific to `lpr`; any race-condition attack involving symbolic links can be detected similarly. The reference propagation rules restrict the usage of symbolic links, requiring them to point to objects accessible within the same domain. This behavior, if implemented in Unix, would solve the problem and make such attacks impossible.

In the OpenSSH example, reference propagation forbids using a shared library to overload operations in another operation domain. While the model effectively prevents the attack, such a restriction on shared libraries may be too strong for practical use. Weaker reference propagation rules for dynamic library function calls should be explored.

The most promising aspect is that the model can detect various "intrusions by delegation" given a security policy specification, providing a policy-based intrusion detector. No knowledge of specific program behavior or attack scenarios is required for the policy definition.

Authentication is a delicate part. The model assumes the authentication process behaves correctly according to the security policy. While it can detect attacks that circumvent authentication, it cannot detect attacks based on authentication errors or cheating.

The examples show that the security policy definition depends on the granularity choice, reflecting the application context. A coarser approach, considering receiving a connection and opening a session as a single operation in OpenSSH, would provide a more straightforward view. However, this requires assumptions about the OpenSSH daemon's internals, which may or may not be true.

For hidden channels, the proposed approach falls short. For example, if the effect of a loop that copies data from one buffer to another is known, the reference in the read operation flows to the write operation. This is not apparent if only system operations are considered, and information flow control is needed.

### Related Work

The proposed approach belongs to the EM class of security policy enforcement mechanisms, as defined by F. B. Schneider [14]. In our case, sequences of steps are implicit, resulting from the causal dependency relation. The definition of an illegal step is trivial, making the proposed EM implementation suitable for cases where intrusion goals are well-defined but the ways to achieve them are unknown or hard to define.

Certain race-condition attacks can be detected by the noninterference-based intrusion detection model proposed by C. Ko and T. Redmond [9]. Their model requires knowledge of system call commutability, making it non-trivial to detect backdoor system calls. In contrast, our approach relies on the weaker assumption of knowledge of system calls' semantics in terms of reference creation and deletion, with the default behavior that references are preserved unless specified otherwise.

Research in information flow control is active, with robust formalisms [15,16] and applications for access control [17,18,19]. We will examine how reference flow control can implement such policies on a general-purpose operating system. However, real information flow control is not applicable without static program analysis, and hidden channel exploits cannot be detected using the proposed approach.

### Conclusion

We have presented an approach to detect intrusion symptoms by controlling the flow of references. This approach can detect the same symptom achieved in various scenarios, even those unknown at the time the security policy is defined. Controlling reference flow by observing executed system operations is straightforward.

We are currently experimenting with a reference flow simulator using actual execution traces and plan to develop a runtime implementation. Performance impact and intrusion detection accuracy will be key areas of focus. Distributed intrusion symptom problems, involving remote objects and distant reference authentication, remain to be addressed.

### References

1. J. Allen, A. Christie, W. Fithen, J. McHugh, J. Pickel, and E. Stoner. State of the practice of intrusion detection technologies. Technical Report SEI-99TR-028, CMU/SEI, 2000.
2. John McHugh. Intrusion and intrusion detection. International Journal of Information Security, July 2001.
3. D. Schnackenberg, K. Djahandari, and D. Sterne. Infrastructure for intrusion detection and response. In Proceedings of the DARPA Information Survivability Conference and Exposition (DISCEX’00), 2000.
4. Frédéric Cuppens. Managing alerts in a multi-intrusion detection environment. In Proceedings of the 17th Annual Computer Security Applications Conference (ACSAC 2001), December 2001.
5. R. P. Goldman, W. Heimerdinger, S. A. Harp, C. W. Geib, V. Thomas, and R. L. Carter. Information modeling for intrusion report aggregation. In Proceedings of the DARPA Information Survivability Conference and Exposition, June 2001.
6. Frédéric Cuppens and Alexandre Miège. Alert correlation in a cooperative intrusion detection framework. In Proceedings of the IEEE Symposium on Security and Privacy, 2002.
7. Benjamin Morin, Ludovic Mé, Hervé Debar, and Mireille Ducassé. M2D2: A formal data model for IDS alert correlation. In Proceedings of the Fifth International Symposium on the Recent Advances in Intrusion Detection (RAID’2002), 2002.
8. Prem Uppuluri and R. Sekar. Experiences with specification-based intrusion detection. In W. Lee, L. Mé, and A. Wespi, editors, Proceedings of the Fourth International Symposium on the Recent Advances in Intrusion Detection (RAID’2001), number 2212 in LNCS, pages 172–189, October 2001.
9. Calvin Ko and Timothy Redmond. Noninterference and intrusion detection. In Proceedings of the IEEE Symposium on Security and Privacy, 2002.
10. Daniel Hagimont, Jacques Mossiere, Xavier Rousset de Pina, and F. Saunier. Hidden software capabilities. In International Conference on Distributed Computing Systems, pages 282–289, 1996.
11. David F.C. Brewer and Michael J. Nash. The Chinese Wall security policy. In Proceedings of the IEEE Symposium on Research in Security and Privacy, pages 206–214. IEEE Computer Society Press, May 1989.
12. CMU CERT/CC. CA-1995-02: Vulnerabilities in /bin/mail. http://www.cert.org/advisories/CA-1995-02.html, January 26, 1995.
13. CMU CERT/CC. VU#40327: OpenSSH uselogin option allows remote execution of commands as root. http://www.kb.cert.org/vuls/id/40327, November 2001.
14. Fred B. Schneider. Enforceable security policies. Information and System Security, 3(1):30–50, 2000.
15. John Rushby. Noninterference, transitivity, and channel-control security policies. Technical Report CSL-92-02, SRI, December 1992.
16. J. McLean. A general theory of composition for trace sets closed under selective interleaving functions. In Proceedings of the IEEE Symposium on Research in Security and Privacy, May 1994.
17. E. Ferrari, P. Samarati, E. Bertino, and S. Jajodia. Providing flexibility in information flow control for object-oriented systems. In Proceedings of the IEEE Symposium on Security and Privacy, pages 130–140, 1997.
18. H. Mantel and A. Sabelfeld. A generic approach to the security of multi-threaded programs. In Proceedings of the 13th IEEE Computer Security Foundations Workshop, pages 200–214, June 2001.
19. Steve Zdancewic, Lantian Zheng, Nathaniel Nystrom, and Andrew C. Myers. Untrusted hosts and confidentiality: Secure program partitioning. In Proceedings of the 18th ACM Symposium on Operating Systems Principles, 2001.