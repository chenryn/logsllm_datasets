43rd International Conference on Software Engineering: Compan-
ion Proceedings (ICSE-Companion), 2021, pp. 192–193.
J. Coelho and M. T. Valente, “Why modern open source projects
fail,” in Proceedings of the 2017 11th Joint Meeting on Foundations
of Software Engineering, ser. ESEC/FSE 2017, Paderborn, Germany:
Association for Computing Machinery, 2017.
[50] C. Miller, S. Cohen, B. Vasilescu, and C. Kästner, ““Did You
Miss My Comment or What?” understanding toxicity in open
source discussions,” in In 44th International Conference on Software
Engineering (ICSE ’22), May 21–29, 2022, Pittsburgh, PA, USA:
ACM, May 2022.
[51] D. Sondhi, A. Gupta, S. Purandare, A. Rana, D. Kaushal, and
R. Purandare, “Dataset to study indirectly dependent documentation
in github repositories,” in 2021 IEEE/ACM 43rd International Con-
ference on Software Engineering: Companion Proceedings (ICSE-
Companion), 2021, pp. 215–216.
[52] R. Li, P. Pandurangan, H. Frluckaj, and L. Dabbish, “Code of
conduct conversations in open source software projects on github,”
Proc. ACM Hum.-Comput. Interact., vol. 5, no. CSCW1, Apr. 2021.
[53] D. Botta, R. Werlinger, A. Gagné, et al., “Towards understanding
it security professionals and their tools,” in Proceedings of the 3rd
Symposium on Usable Privacy and Security, ser. SOUPS ’07, Pitts-
burgh, Pennsylvania, USA: Association for Computing Machinery,
2007, pp. 100–111.
[54] M. Silic and A. Back, “Information security and open source dual
use security software: Trust paradox,” in Open Source Software:
Quality Verification, E. Petrinja, G. Succi, N. El Ioini, and A. Sillitti,
Eds., Berlin, Heidelberg: Springer Berlin Heidelberg, 2013, pp. 194–
206.
L. Bauer, L. F. Cranor, R. W. Reeder, M. K. Reiter, and K. Vaniea,
“Real life challenges in access-control management,” in Proceedings
of the SIGCHI Conference on Human Factors in Computing Systems,
2009, pp. 899–908.
[56] R. Barrett, E. Kandogan, P. P. Maglio, E. M. Haber, L. A. Takayama,
and M. Prabaker, “Field studies of computer system administrators:
Analysis of system management tools and practices,” in Proceedings
of the 2004 ACM conference on Computer supported cooperative
work, 2004, pp. 388–395.
[57] R. A. Bridges, M. D. Iannacone, J. R. Goodall, and J. M. Beaver,
“How do information security workers use host data? a summary of
interviews with security analysts,” arXiv preprint arXiv:1812.02867,
2018.
S. E. McGregor, P. Charters, T. Holliday, and F. Roesner, “Inves-
tigating the computer security practices and needs of journalists,”
in 24th USENIX Security Symposium (USENIX Security 15), 2015,
pp. 399–414.
S. E. McGregor, E. A. Watkins, M. N. Al-Ameen, K. Caine, and F.
Roesner, “When the weakest link is strong: Secure collaboration in
the case of the panama papers,” in 26th USENIX Security Symposium
(USENIX Security 17), 2017, pp. 505–522.
[60] C. Chen, N. Dell, and F. Roesner, “Computer security and privacy
in the interactions between victim service providers and human traf-
ficking survivors,” in 28th USENIX Security Symposium (USENIX
Security 19), 2019, pp. 89–104.
[61] W. Bai, M. Namara, Y. Qian, P. G. Kelley, M. L. Mazurek, and
D. Kim, “An inconvenient trust: User attitudes toward security and
usability tradeoffs for key-directory encryption systems,” in Twelfth
[55]
[58]
[59]
Symposium on Usable Privacy and Security (SOUPS 2016), 2016,
pp. 113–130.
[70]
[69]
[68]
[65]
[64]
[62] K. Gallagher, S. Patil, and N. Memon, “New me: Understanding
expert and non-expert perceptions and usage of the tor anonymity
network,” in Thirteenth Symposium on Usable Privacy and Security
(SOUPS 2017), 2017, pp. 385–398.
[63] M. Gutfleisch, J. H. Klemmer, N. Busch, Y. Acar, M. A. Sasse,
and S. Fahl, “How does usable security (not) end up in software
products? results from a qualitative interview study,” in 43rd IEEE
Symposium on Security and Privacy, IEEE S&P 2022, May 22-26,
2022, IEEE Computer Society, May 2022.
I. Steinmacher, T. Conte, M. A. Gerosa, and D. Redmiles, “Social
barriers faced by newcomers placing their first contribution in
open source software projects,” in Proceedings of the 18th ACM
Conference on Computer Supported Cooperative Work & Social
Computing, ser. CSCW ’15, Vancouver, BC, Canada: Association
for Computing Machinery, 2015, pp. 1379–1392.
S. Balali, U. Annamalai, H. S. Padala, et al., “Recommending
tasks to newcomers in oss projects: How do mentors handle it?” In
Proceedings of the 16th International Symposium on Open Collab-
oration, ser. OpenSym 2020, Virtual conference, Spain: Association
for Computing Machinery, 2020.
[66] W. Scacchi, J. Feller, B. Fitzgerald, S. Hissam, and K. Lakhani,
Understanding free/open source software development processes,
2006.
[67] K. Crowston, K. Wei, J. Howison, and A. Wiggins, “Free/libre open-
source software development: What we know and what we do not
know,” ACM Comput. Surv., vol. 44, no. 2, Mar. 2008.
S.-F. Wen, “Software security in open source development: A
systematic literature review,” in 2017 21st Conference of Open
Innovations Association (FRUCT), 2017, pp. 364–373.
L. P. Hattori and M. Lanza, “On the nature of commits,” in 2008
23rd IEEE/ACM International Conference on Automated Software
Engineering - Workshops, 2008, pp. 63–71.
J. C. S. Santos, A. Peruma, M. Mirakhorli, M. Galstery, J. V. Vidal,
and A. Sejfia, “Understanding software vulnerabilities related to ar-
chitectural security tactics: An empirical investigation of chromium,
php and thunderbird,” in 2017 IEEE International Conference on
Software Architecture (ICSA), 2017, pp. 69–78.
[71] D. Pletea, B. Vasilescu, and A. Serebrenik, “Security and emo-
tion: Sentiment analysis of security discussions on github,” in
Proceedings of the 11th Working Conference on Mining Software
Repositories, ser. MSR 2014, New York, NY, USA: Association for
Computing Machinery, 2014, pp. 348–351.
[72] G. Antal, M. Keleti, and P. Heged˘uns, “Exploring the security
awareness of the python and javascript open source communities,”
in Proceedings of the 17th International Conference on Mining Soft-
ware Repositories, ser. MSR ’20, New York, NY, USA: Association
for Computing Machinery, 2020, pp. 16–20.
[73] A. Bosu, J. C. Carver, M. Hafiz, P. Hilley, and D. Janni, “Identifying
the characteristics of vulnerable code changes: An empirical study,”
in Proceedings of the 22nd ACM SIGSOFT international symposium
on foundations of software engineering, 2014, pp. 257–268.
[74] H. Perl, S. Dechand, M. Smith, et al., “Vccfinder: Finding potential
vulnerabilities in open-source projects to assist code audits,” in
Proceedings of the 22nd ACM SIGSAC Conference on Computer
and Communications Security, Denver, CO, USA, October 12-16,
2015, ACM, 2015, pp. 426–437.
I. Abunadi and M. Alenezi, “Towards cross project vulnerability
prediction in open source web applications,” in Proceedings of
the The International Conference on Engineering & MIS 2015,
ser. ICEMIS ’15, Istanbul, Turkey: Association for Computing
Machinery, 2015.
[76] Y. Zhou and A. Sharma, “Automated identification of security issues
from commit messages and bug reports,” in Proceedings of the
2017 11th Joint Meeting on Foundations of Software Engineering,
ser. ESEC/FSE 2017, New York, NY, USA: Association for Com-
puting Machinery, 2017, pp. 914–919.
[77] N. Raman, M. Cao, Y. Tsvetkov, C. Kästner, and B. Vasilescu,
“Stress and burnout in open source: Toward finding, understand-
ing, and mitigating unhealthy interactions,” in Proceedings of the
ACM/IEEE 42nd International Conference on Software Engineer-
ing: New Ideas and Emerging Results, ser. ICSE-NIER ’20, Seoul,
[75]
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1894
[78]
South Korea: Association for Computing Machinery, 2020, pp. 57–
60.
S. Bugiel, L. V. Davi, and S. Schulz, “Scalable trust establishment
with software reputation,” in Proceedings of the sixth ACM work-
shop on Scalable trusted computing, 2011, pp. 15–24.
[85]
[79] M. Syeed, J. Lindman, and I. Hammouda, “Measuring perceived
trust in open source software communities,” in Open Source Sys-
tems: Towards Robust Practices, F. Balaguer, R. Di Cosmo, A.
Garrido, F. Kon, G. Robles, and S. Zacchiroli, Eds., Cham: Springer
International Publishing, 2017.
[80] M. Antikainen, T. Aaltonen, and J. Väisänen, “The role of trust in
oss communities — case linux kernel community,” in Open Source
Development, Adoption and Innovation, J. Feller, B. Fitzgerald,
W. Scacchi, and A. Sillitti, Eds., Boston, MA: Springer US, 2007,
pp. 223–228.
[81] V. S. Sinha, S. Mani, and S. Sinha, “Entering the circle of trust:
Developer initiation as committers in open-source projects,” in
Proceedings of the 8th Working Conference on Mining Software
Repositories, ser. MSR ’11, Waikiki, Honolulu, HI, USA: Associa-
tion for Computing Machinery, 2011, pp. 133–142.
[82] A. Bosu and J. C. Carver, “Impact of developer reputation on
code review outcomes in oss projects: An empirical investigation,”
in Proceedings of the 8th ACM/IEEE International Symposium on
Empirical Software Engineering and Measurement, ser. ESEM ’14,
Torino, Italy: Association for Computing Machinery, 2014.
[83] C. Thompson and D. Wagner, “A large-scale study of modern code
review and security in open source projects,” in Proceedings of
the 13th International Conference on Predictive Models and Data
Analytics in Software Engineering, Toronto, Canada: Association for
Computing Machinery, 2017.
[84] A.-K. Groven, K. Haaland, R. Glott, and A. Tannenberg, “Security
measurements within the framework of quality assessment models
for free/libre open source software,” in Proceedings of the Fourth
European Conference on Software Architecture: Companion Volume,
ser. ECSA ’10, Copenhagen, Denmark: Association for Computing
Machinery, 2010, pp. 229–235.
J. Ryoo, B. Malone, P. A. Laplante, and P. Anand, “The use of
security tactics in open source software projects,” IEEE Transactions
on Reliability, vol. 65, no. 3, pp. 1195–1204, 2016.
[86] V. N. Subramanian, I. Rehman, M. Nagappan, and R. G. Kula,
“Analyzing first contributions on github: What do newcomers do,”
IEEE Software, 2020.
[87] A. Hars and S. Ou, “Working for free? motivations for participating
in open-source projects,” Int. J. Electron. Commerce, vol. 6, no. 3,
pp. 25–39, Apr. 2002.
[88] C. Hannebauer and V. Gruhn, “Motivation of newcomers to floss
projects,” in Proceedings of the 12th International Symposium on
Open Collaboration, ser. OpenSym ’16, Berlin, Germany: Associa-
tion for Computing Machinery, 2016.
[89] G. Pinto, I. Steinmacher, and M. A. Gerosa, “More common than
you think: An in-depth study of casual contributors,” in 2016 IEEE
23rd International Conference on Software Analysis, Evolution, and
Reengineering (SANER), vol. 1, 2016, pp. 112–123.
[90] C. Miller, D. G. Widder, C. Kästner, and B. Vasilescu, “Why
do people give up flossing? a study of contributor disengagement
in open source,” in Open Source Systems, Springer International
Publishing, 2019, pp. 116–129.
S.-F. Wen, “Learning secure programming in open source software
communities: A socio-technical view,” in Proceedings of the 6th
International Conference on Information and Education Technology,
ser. ICIET ’18, Osaka, Japan: Association for Computing Machin-
ery, 2018.
I. Steinmacher, T. U. Conte, C. Treude, and M. A. Gerosa,
“Overcoming open source project entry barriers with a portal for
newcomers,” in Proceedings of the 38th International Conference
on Software Engineering, ser. ICSE ’16, Austin, Texas: Association
for Computing Machinery, 2016, pp. 273–284.
I. Steinmacher, C. Treude, and M. A. Gerosa, “Let me in: Guide-
lines for the successful onboarding of newcomers to open source
projects,” IEEE Software, vol. 36, no. 4, pp. 41–49, 2019.
J. Dominic, J. Houser, I. Steinmacher, C. Ritter, and P. Rodeghero,
“Conversational bot for newcomers onboarding to open source
projects,” in Proceedings of
the IEEE/ACM 42nd International
Conference on Software Engineering Workshops, ser. ICSEW’20,
[92]
[91]
[93]
[94]
Seoul, Republic of Korea: Association for Computing Machinery,
2020, pp. 46–50.
[95] G. Canfora, M. Di Penta, R. Oliveto, and S. Panichella, “Who is
going to mentor newcomers in open source projects?” In Proceed-
ings of the ACM SIGSOFT 20th International Symposium on the
Foundations of Software Engineering, ser. FSE ’12, Cary, North
Carolina: Association for Computing Machinery, 2012.
[96] K. Blincoe, F. Harrison, and D. Damian, “Ecosystems in github and
a method for ecosystem identification using reference coupling,” in
Proceedings of the 12th Working Conference on Mining Software
Repositories, ser. MSR ’15, Florence, Italy: IEEE Press, 2015,
pp. 202–207.
[97] C. Casalnuovo, B. Vasilescu, P. Devanbu, and V. Filkov, “Developer
onboarding in github: The role of prior social links and language
experience,” in Proceedings of the 2015 10th Joint Meeting on Foun-
dations of Software Engineering, ser. ESEC/FSE 2015, Bergamo,
Italy: Association for Computing Machinery, 2015, pp. 817–828.
J. Salter, Linux kernel
team rejects university of minnesota re-
searchers’ apology, https://arstechnica.com/gadgets/2021/04/linux-
kernel-team-rejects-university-of-minnesota-researchers-apology/,
Accessed: 2021-11-27, Apr. 2021.
T. Holz and A. Oprea, IEEE S&P’21 program committee statement
regarding the “hypocrite commits” paper, https : / / www . ieee -
security . org / TC / SP2021 / downloads / 2021 _ PC _ Statement . pdf,
Accessed: 2021-11-27, May 2021.
[98]
[99]
[100] K. Charmaz, Constructing Grounded Theory. Sage, 2014.
[101] A. Strauss and J. M. Corbin, Grounded theory in practice. Sage,
[102]
1997, p. 288.
J. Corbin and A. Strauss, “Grounded theory research: Procedures,
canons and evaluative criteria,” Qualitative Sociology, vol. 19, no. 6,
pp. 418–427, 1990.
[103] C. Urquhart, Grounded theory for qualitative research: A practical
guide. Sage, 2012.
[104] M. Birks and J. Mills, Grounded theory: A practical guide. Sage,
[105]
2015.
E. Kenneally and D. Dittrich, “The Menlo report: Ethical principles
guiding information and communication technology research,” SSRN
Electronic Journal, Aug. 2012.
[106] Guidelines for research on the kernel community, https://lwn.net/
Articles/888891/, Accessed: 2022-03-31, Mar. 2022.
APPENDIX A
RECRUITMENT CRITERIA
Our general recruitment approach in the repository channel
was a stratified sampling in quartiles of GitHub repositories
ranked by both a “popularity” and an “activity” score. We
based this score on repository-level metrics provided by the
GitHub API such as the number of commits and committers
as well as the number of stars and forks.
Our initial repository dataset was downloaded in July 2021
from GH Archive (https://www.gharchive.org/), a service
providing historical GitHub repository data, publicly avail-
able for further analysis. We limited our dataset
to code
repositories that received at least 40 commits from at least
20 distinct committers in the previous six months, which
sets a minimum threshold for any given selected project’s
activity. This was done with the intent of excluding inactive
and personal projects, in which our inquiry would either not
reach active contributors or where interpersonal trust processes
are irrelevant.
The resulting 15,256 repositories were enriched with up-to-
date data from GitHub’s API, such as programming language
usage, topic tags, as well as star and fork counts. Users usually
give out stars as a means of bookmarking a project or to
explicitly value a project’s merit. A project is “forked” into
a user’s namespace for them to be able to make changes
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1895
to its code base and consequently create a pull request for
their changes to be accepted into the main source tree. The
combination of the number of a project’s stars and forks can
thus serve as a proxy for its popularity. To ensure that the
selected projects recently went through the onboarding of new
contributors, we only proceeded with those that gained new
committers in July 2021, and which had not contributed to the
project before. After excluding duplicate repositories as well
as repositories exclusively containing markup languages, we
arrived at a set of 4,456 projects for final consideration.
We joined the popularity and activity indicators to a com-
bined ranking and divided the set of projects into quartiles.
This ensured high diversity across the indicators, while mini-
mizing the amount of strata. We then iteratively selected and
contacted projects from each stratum (e. g., first project from
1st quartile, first project from 2nd quartile, and so on) until we
reached interview saturation.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1896