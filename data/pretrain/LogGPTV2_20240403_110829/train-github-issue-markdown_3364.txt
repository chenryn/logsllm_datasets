 _Please make sure that this is a Bug or a Feature Request and provide all
applicable information asked by the template.  
If your issue is an **implementation question** , please ask your question on
StackOverflow or on the Keras Slack channel instead of opening a GitHub
issue._
**System information**
  * Have I written custom code (as opposed to using example directory): Yes
  * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6
  * TensorFlow backend (yes / no): Yes
  * TensorFlow version: 1.14.0
  * Keras version: 2.2.5
  * Python version: 2.7.16
You can obtain the TensorFlow version with:  
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"  
You can obtain the Keras version with:  
python -c 'import keras as k; print(k. **version** )'
**Describe the current behavior**  
Nested call to `_standardize_args` in superclass (`RNN`) `__call__` fails with
assertion failure:
>
>     assert initial_state is None and constants is None
>  
when a `ConvRNN2D` is `__call__`ed with a non-default `initial_state`.
**Describe the expected behavior**  
The non-default `initial_state` should be successfully passed through and used
by the convolutional RNN cell.
**Code to reproduce the issue**
    from keras.layers import Input, ConvLSTM2D
    input = Input(shape=(1,128,128,4))
    filter = ConvLSTM2D(4,7,strides=2,padding='same',return_state=True)
    shrunk = filter(input)
    filter(shrunk[0], initial_state = shrunk[1:])
**Other info / logs**  
It appears that `ConvRNN2D.__call__` replicates much of the logic from
`RNN.__call__` and that the replicated logic is the source of the error. Among
other things, `ConvRNN2D.__call__` begins by calling `_standardize_args`, and
then post-processes these in roughly the same way as `RNN.__call__`, including
adding `initial_state` and `constants` to both the list `full_input` and the
dict `kwargs`, meaning that the arguments are being passed in twice.  
Naively commenting out the lines that insert to `kwargs` results in a
different error:
> Traceback (most recent call last):  
>  File "", line 1, in  
>  File
> "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-
> packages/keras/layers/convolutional_recurrent.py", line 324, in **call**  
>  output = super(ConvRNN2D, self). **call** (full_input, **kwargs)  
>  File
> "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-
> packages/keras/layers/recurrent.py", line 576, in **call**  
>  output = super(RNN, self). **call** (full_input, **kwargs)  
>  File
> "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-
> packages/keras/engine/base_layer.py", line 434, in **call**  
>  self.assert_input_compatibility(inputs)  
>  File
> "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-
> packages/keras/engine/base_layer.py", line 293, in
> assert_input_compatibility  
>  str(inputs))  
>  ValueError: Layer conv_lst_m2d_1 expects 5 inputs, but it received 3 input
> tensors. Input received: [ shape=(?, 64, 64, 4) dtype=float32>,  'conv_lst_m2d_1_1/while/Exit_3:0' shape=(?, 64, 64, 4) dtype=float32>,
>  dtype=float32>]
This suggests that other of the duplicated code (perhaps the tinkering with
`self.input_spec`) is causing the base class to still expect to use the
`initial_state` twice, if it could be passed in without error.