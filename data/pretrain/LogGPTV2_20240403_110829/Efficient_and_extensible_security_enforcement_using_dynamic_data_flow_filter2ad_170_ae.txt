integers as format strings. (3) Finally, we check that our injected
vulnerability is not eliminated by our static analysis.
Table 5 presents our results with the standard SPEC workloads.
In all of the benchmarks, we demonstrate signiﬁcant performance
improvements over current software-based systems. The average
overhead of 12.9% improves upon the best previously reported av-
erages of 75-260% [48, 39]. Furthermore, in most cases, our sys-
tem’s overhead for compute-bound applications is essentially zero
even when the application does contain vulnerabilities. Thus, our
approach is less adversely affected by CPU-intensive programs than
all current software-based techniques.
The gzip benchmark is a worst case for taint tracking sys-
tems [44, 48, 39, 17] due to its complex behavior and sensitivity to
memory bandwidth. It operates on character data extensively and
propagates tainted data everywhere, reducing the ﬂows that our sys-
tem can statically eliminate and negatively impacting performance.
Nevertheless, our system’s overhead of 51% represents a signiﬁ-
cant improvement over prior software systems, with overheads of
106% for a compiler-based system [48] to over 600% for dynamic
instrumentation [39], and our result compares favorably with the
31% overhead for the most recent hardware-based solution [17].
5.3 File Disclosure Attacks
In addition to taint tracking, we evaluate our system’s ability to
prevent ﬁle disclosure attacks, as discussed in Section 4.3.2. Ta-
ble 6 shows our results. For pfingerd, our static analysis was
able to determine that it contained no FTP-like behaviors and there-
fore no instrumentation was required. For muh and bind, out
system was unable to rule out this possibility and therefore had
to insert a small amount of additional code. However, the delay in
response time was so small as to not be consistently measurable.
These results highlight the advantages of our system. First, in
some cases all instrumentation can be eliminated, giving 0% over-
head. Second, in the cases where some tracking is required, our
analysis is able to keep the additional code to a minimum, imposing
only a small or negligible overhead. Finally, this example shows
that without rewriting the compiler or its static analysis, our sys-
tem can be applied to complex problems that taint tracking cannot
directly handle. Moreover, if existing taint tracking systems were
extended to cover richer problems, they would require signiﬁcantly
greater memory usage to track additional bits of data, while our
system’s memory usage is not adversely affected by these richer
policies.
5.4 Policy Annotation Burden
We now brieﬂy evaluate the burden of providing the policy an-
notations that are required by our system. Our annotations come in
three types: (1) pointer annotations, which describe pointer rela-
tions; (2) analysis annotations, which deﬁne a data ﬂow analysis;
and (3) policy annotations, which use the results of the data ﬂow
analysis to enforce a policy.
Pointer annotations are common to all policies, because they de-
scribe the pointer relations of the arguments of each function, spec-
ifying what the function accesses and modiﬁes; this information is
used by the pointer analysis. Once a library has been annotated—
in our case the Standard C library—pointer annotations need not
be rewritten unless the library interface changes. For the Standard
C library, there are pointer annotations for 116 procedures, with a
median size of 3 lines and an average size of 4.68 lines.
Analysis and policy annotations can differ for different security
policies. For the format string policy, there are 44 annotations of
these types, with a median size of 6 lines each and an average size
of 5.75 lines each. However, the vast majority of these are essen-
tially duplicates. For example, the annotations for each member of
the printf family of functions are essentially identical. When
these “cut-and-paste” duplicates are eliminated, the total number is
only 21. For the ﬁle disclosure policy, there are 65 such annota-
tions, with a median size of 7 lines each and an average size of 6.52
lines. Again, the majority of these are essentially duplicates. When
these are accounted for, there are only 36 unique annotations.
To understand the difference between analysis and policy anno-
tations, we now discuss several different use cases. In the simplest
case, the desired policy exists and there is no need to touch any an-
notation ﬁle. In other cases, a security expert may wish to modify
an existing policy, for example, by calling a sanitization function
when a violation is detected. Here, only the policy annotations re-
quire changes to account for the sanitization code. Finally, in the
most invasive case, a new data ﬂow analysis must be deﬁned, in
which case new analysis and policy annotations must be written.
The annotations themselves are not difﬁcult to write. Our anno-
tation ﬁles only use seven major constructs, so the language is easy
to understand. All of these constructs are shown in the example in
Section 4.3.1, and the annotations shown are representative of the
kind that must be written. In any case, the information provided by
the annotations is required by any policy-enforcing system; in our
system such information is speciﬁed by annotation ﬁles rather than
being imbedded in the code.
6. CONCLUSIONS
In this paper we have presented a compiler-based system that en-
forces security policies by tracking dynamic data ﬂow through pro-
grams. We have demonstrated the generality of our system by using
it to enforce two security policies, one that prevents unwanted ﬁle
disclosure and another that prevents format string attacks. We have
also shown that our system produces low overhead when applied
to both compute-bound applications and I/O bound server applica-
tions.
Although our current implementation is a source-to-source trans-
lator for the C language, our techniques are applicable to other
modern languages and even binary code. For example, our static
data ﬂow analysis could be implemented in a static binary rewriting
system, producing a system that protects binary code from attacks
while using static analysis to reduce the runtime cost. Such a sys-
tem would have to deal with the difﬁculty of building the control
ﬂow graph (i.e., the difﬁculty of discovering all instructions), so in
many cases it would not produce the same low overheads that we
report in this paper.
Acknowledgments
This work was supported by NSF grant CNS-0509354, Air Force
Research Laboratory contract FA8750-07-C-0035 from the Disrup-
tive Technology Ofﬁce, and a grant from the Intel Research Coun-
cil. We thank Vitaly Shmatikov, Lili Qiu, and E Lewis for their
helpful comments on this paper.
7. REFERENCES
[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti.
Control-ﬂow integrity: Principles, implementations, and
applications. In Proceedings of the ACM Conference on
Computer and Communication Security, pages 340–353,
2005.
[2] K. Ashcraft and D. Engler. Using programmer-written
compiler extensions to catch security holes. In Proceedings
of the IEEE Symposium on Security and Privacy, pages
143–159, 2002.
[3] D. Avots, M. Dalton, V. B. Livshits, and M. S. Lam.
Improving software security with a C pointer analysis. In
Proceedings of the 27th International Conference on
Software Engineering, pages 332–341, 2005.
[4] A. Baratloo, N. Singh, and T. Tsai. Transparent run-time
defense against stack smashing attacks. In Proceedings of the
USENIX Annual Technical Conference, pages 251–262,
2000.
[5] D. E. Bell and L. J. LaPadula. Secure computer systems:
Mathematical foundations. Technical Report 2547, MITRE,
March 1973.
[6] E. D. Berger and B. G. Zorn. DieHard: Probabalistic
memory safety for unsafe languages. In Proceedings of the
ACM SIGPLAN Conference on Programming Language
Design and Implementation, pages 158–168, 2006.
[7] S. Bhatkar, R. Sekar, and D. C. DuVarney. Efﬁcient
techniques for comprehensive protection from memory error
exploits. In Proceedings of the 14th USENIX Security
Symposium, pages 271–286, 2005.
[8] K. J. Biba. Integrity considerations for secure computer
systems. Technical Report ES-TR-76-372, Electronic
Systems Division, Hanscom Air Force Base, April 1977.
[9] M. Castro, M. Costa, and T. Harris. Securing software by
enforcing data-ﬂow integrity. In Proceedings of the 7th
USENIX Symposium on Operating Systems Design and
Implementation, pages 147–160, 2006.
[10] S. Chen, J. Xu, N. Nakka, Z. Kalbarczyk, and R. K. Iyer.
Defeating memory corruption attacks via pointer taintedness
detection. In Proceedings of the International Conference on
Dependable Systems and Networks, pages 378–387, 2005.
[11] J. Clause, W. Li, and A. Orso. Dytan: A generic dynamic
taint analysis framework. In Proceedings of the 2007
International Symposium on Software Testing, pages
196–206, 2007.
[12] M. Costa, J. Crowcroft, M. Castro, A. Rwostron, L. Zhou,
L. Zhang, and P. Barham. Vigilante: End-to-end containment
of Internet worms. In Proceedings of the 20th ACM
Symposium on Operating System Principles, pages 133–147,
2005.
[13] C. Cowan, M. Barringer, S. Beattie, G. Kroah-Hartman,
M. Frantzen, and J. Lokier. FormatGuard: Automatic
protection from printf format string vulnerabilities. In
Proceedings of the 10th USENIX Security Symposium, pages
15–23, 2001.
[14] C. Cowan, S. Beattie, J. Johansen, and P. Wagle. PointGuard:
Protecting pointers from buffer overﬂow vulnerabilities. In
Proceedings of the 12th USENIX Security Symposium, pages
91–104, 2003.
[15] C. Cowan, C. Pu, D. Maier, H. Hinton, J. Walpole, P. Bakke,
S. Beattie, A. Grier, P. Wagle, and Q. Zhang. StackGuard:
Automatic adaptive detection and prevention of
buffer-overﬂow attacks. In Proceedings of the 7th USENIX
Security Symposium, pages 63–78, 1998.
[16] J. R. Crandall and F. T. Chong. Minos: Control data attack
prevention orthogonal to memory model. In Proceedings of
the 37th International Symposium on Microarchitecture,
pages 221–232, 2004.
[17] M. Dalton, H. Kannan, and C. Kozyrakis. Raksha: A ﬂexible
information ﬂow architecture for software security. In
Proceedings of the 34th International Symposium on
Computer Architecture, pages 482–493, 2007.
[18] D. E. Denning. A lattice model of secure information ﬂow.
Communications of the ACM, 19(5):236–243, May 1976.
[19] U. Erlingsson. The inlined reference monitor approach to
security policy enforcement. PhD thesis, Cornell University,
Ithaca, New York, 2003.
[20] D. Evans and D. Larochelle. Improving security using
extensible lightweight static analysis. IEEE Software,
19(1):42–51, January/February 2002.
[21] S. Z. Guyer. Incorporating Domain-Speciﬁc Information into
the Compilation Process. PhD thesis, The University of
Texas at Austin, Austin, TX, 2003.
[22] S. Z. Guyer and C. Lin. An annotation language for
optimizing software libraries. In Proceedings of the 2nd
Conference on Domain-Speciﬁc Languages, pages 39–52,
1999.
[23] S. Z. Guyer and C. Lin. Client-driven pointer analysis. In
Proceedings of the 10th Annual Static Analysis Symposium,
pages 214–236, June 2003.
[24] S. Z. Guyer and C. Lin. Broadway: A compiler for exploiting
the domain-speciﬁc semantics of software libraries.
Proceedings of the IEEE, Special issue on program
generation, optimization and adaptation, 93(2):342–357,
January-February 2005.
[25] M. Hauswirth and T. M. Chilimbi. Low-overhead memory
leak detection using adaptive statistical proﬁling. In
Proceedings of the 11th International Conference on
Architectural Support for Programming Languages and
Operating Systems, pages 156–164, 2004.
[26] J. C. Huang. Detection of data ﬂow anomaly through
program instrumentation. IEEE Transactions on Software
Engineering, SE-5(3):226–236, May 1979.
[27] T. Jim, G. Morrisett, D. Grossman, M. Hicks, J. Cheney, and
Y. Wang. Cyclone: A safe dialect of C. In Proceedings of the
USENIX Annual Technical Conference, pages 275–288,
2002.
[28] R. W. M. Jones and P. H. J. Kelly. Backwards-compatible
bounds checking for arrays and pointers in C programs. In
Proceedings of the 4th International Workshop on Automated
and Algorithmic Debugging, pages 13–26, 1997.
[29] J. B. Kam and J. D. Ullman. Global data ﬂow analysis and
iterative algorithms. Journal of the ACM, 23(1):158–176,
January 1976.
[38] A. Nguyen-Tong, S. Guarnieri, D. Greene, J. Shirley, and
D. Evans. Automatically hardening web applications using
precise tainting. In Proceedings of the 20th IFIP
International Information Security Conference, pages
295–308, 2005.
[39] F. Qin, C. Wang, Z. Li, H. seop Kim, Y. Zhou, and Y. Wu.
LIFT: A low-overhead information ﬂow tracking system for
detecting security attacks. In Proceedings of the 39th Annual
IEEE/ACM Symposium on Microarchitecture, pages
135–148, 2006.
[30] V. Kiriansky, D. Bruening, and S. Amarasinghe. Secure
[40] A. Sabelfeld and A. C. Myers. Language-based
execution via program shepherding. In Proceedings of the
11th Annual USENIX Security Symposium, pages 191–206,
2002.
[31] L. C. Lam and T.-C. Chiueh. A general dynamic information
ﬂow tracking framework for security applications. In
Proceedings of the 22nd Annual Computer Security
Applications Conference, pages 463–472, 2006.
[32] M. Martin, B. Livshits, and M. S. Lam. Finding application
errors and security ﬂaws using PQL: A program query
language. In Proceedings of the 20th Annual ACM SIGPLAN
Conference on Object Oriented Programming, Systems, and
Applications, pages 365–383, 2005.
information-ﬂow security. IEEE Journal on Selected Areas in
Communications, 21(1):5–19, 2003.
[41] F. B. Schneider. Enforceable security policies. ACM
Transactions on Information and System Security,
3(1):30–50, February 2000.
[42] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. Detecting
format string vulnerabilities with type qualiﬁers. In
Proceedings of the 10th USENIX Security Symposium, pages
201–218, 2001.
[43] R. Strom and S. Yemini. Typestate: A programming
language concept for enhancing software reliability. IEEE
Transactions on Software Engineering, 12(1):157–171, 1986.
[33] A. C. Myers. JFlow: Practical mostly-static information ﬂow
[44] G. E. Suh, J. W. Lee, D. Zhang, and S. Devadas. Secure
control. In Proceedings of the 26th ACM SIGPLAN
Symposium on Principles of Programming Languages, pages
228–241, 1999.
[34] National Security Agency Information Systems Security
Organization. Labeled security protection proﬁle version 1b,
October 1999.
program execution via dynamic information ﬂow tracking. In
Proceedings of the 11th International Conference on
Architectural Support for Programming Languages and
Operating Systems, pages 85–96, 2004.
[45] K. Thompson. Reﬂections on trusting trust. Communications
of the ACM, 27(8):761–763, August 1984.
[35] G. C. Necula, S. McPeak, and W. Weimer. CCured:
[46] L. Wall, T. Christiansen, and J. Orwant. Programming Perl.
Type-safe retroﬁtting of legacy code. In Proceedings of the
29th ACM SIGPLAN Symposium on Principles of
Programming Languages, pages 128–139, 2002.
[36] J. Newsome, D. Brumley, and D. Song.
Vulnerability-speciﬁc execution ﬁltering for exploit
prevention on commodity software. In Proceedings of the
Network and Distributed Security Symposium, 2006.
[37] J. Newsome and D. Song. Dynamic taint analysis for
automatic detection, analysis, and signature generation of
exploits on commodity software. In Proceedings of the
Network and Distributed Security Symposium, 2005.
O’Reilly & Associates, Sebastopol, California, United
States, third edition, 2000.
[47] M. Weiser. Program slicing. In Proceedings of the 5th
International Conference on Software Engineering, pages
439–449, 1981.
[48] W. Xu, S. Bhatkar, and R. Sekar. Taint-enhanced policy
enforcement: A practical approach to defeat a wide range of
attacks. In Proceedings of the 15th USENIX Security
Symposium, pages 121–136, 2006.