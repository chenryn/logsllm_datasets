C
A
Table 2: A list of new LRC bugs detected by LRSan. Modi. represents modification source, in which: U is user race, T is kernel
race, and I is the thread itself. Y. indicates the latent period in years. In the Status column, S is submitted, C is confirmed, and
A is patch applied.
5.3 Analysis Time
Our experimental platform is equipped with a Quad-Core 3.5 GHz
Intel Xeon E5-1620 v4 processor. The main memory is 32 GB, and
the operating system is Ubuntu 16.04 with Linux-4.4.0. LRSan fin-
ishes the analysis of the Linux kernel (with “allyesconfig”) within
four hours, which demonstrates the efficiency of LRSan. After in-
vestigating the analysis process, we found that more than 80% time
is consumed by the first pass (i.e., information collection) of LRSan.
This is reasonable because the first pass needs to iteratively build a
global CFG and collect the alias-analysis results. Given that there
is no dependency between these two tasks, it is possible to further
reduce the analysis time by parallelizing them, as multi-core proces-
sors have been broadly available in today’s machines. Alternatively,
the first pass needs to run only once, so we can save the collected
information and reuse it, instead of running it every time.
6 BUG-FIXING STRATEGIES
According to LRSan’s detection results, LRC bugs are common in
OS kernels. To avoid security issues, an LRC bug should be fixed
immediately once it is exposed. Based on our study and experience
in LRC bugs and our communication with Linux kernel maintain-
ers regarding patching the bugs found by LRSan, we summarize
possible bug-fixing strategies against LRC bugs as follows.
Enforcing a recheck. An intuitive fixing strategy is to enforce
a recheck after the identified modification. For example, to fix the
LRC bug in Figure 2, we can re-enforce the security check (line
10-11) right after the modification (line 16-19). Such a fixing strat-
egy is straightforward and particularly effective to cases in which a
checked variable needs to be intentionally updated after the check,
e.g., modification also happens in normal execution. However, such
a fix is to detect the potential security bleach from the modification,
but not to prevent a harmful modification—the root cause of the
bug. The shortcomings of this fixing strategy include: (1) introduc-
ing extra performance overhead; (2) duplicating checks can cause
cleanness concerns, due to which, Linux kernel maintainers may
become reluctant to apply the patch.
Caching checked variable. Another fixing strategy is to render
the modification ineffective by caching and reusing the checked vari-
able. After a security check, we can temporarily cache the checked
value in a separate variable. Later on, to prevent the security im-
pact from a harmful modification, we have two choices: either
immediately overwriting the potentially modified variable with the
cached value or using the cached value whenever the variable is
used. Such a fixing strategy is not applicable to cases in which a
security-checked variable needs to be intentionally updated (e.g.,
increasing an index variable of an array). Moreover, if the security
check and the following uses of a critical variable cross multiple
functions, especially when indirect calls are involved, such a fix
becomes complicated and requires deep understanding of the code.
Avoiding harmful modifications. A more fundamental bug-
fixing strategy is to avoid harmful modifications. For example, in
Figure 4, we can copy the whole info object in the first place to avoid
the second copy. Such a fixing strategy works for cases in which
there is no need to update the checked variable. Such a fix can be
expensive, especially when copying a large object, and complicated
if refactoring the code is required to avoid the modification.
Using transactional memory. An alternative to prevent harmful
modifications is to use transactional memory, which ensures a
Description
Value used for modification has been checked before
Modification satisfies the security check, e.g., assigning statically-known values
False Positive Cause
Checked modification
Satisfiable modification
Uncontrollable modification Modification is uncontrollable to attackers, e.g., internal kernel variables
Transient check
Unconfirmed race
Other
1
2
3
4
5
6
Table 3: A study of causes of false positives in the detection results of LRSan. Except false positives caused by transient checks,
others can be eliminated or reduced through automatic techniques such as symbolic execution.
Security check expires because the modified variable is redefined for other purposes
Source variable of modification may have kernel races, but is hard to confirm manually
Inaccurate global call graph, unreachable code, etc
Percentage
25%
20%
38%
6%
9%
2%
Elimination Technique
Symbolic execution
Symbolic execution
Taint analysis
N/A
Race detection
Analysis optimization
group of load and store instructions are executed in an atomic way.
DECAF [33] uses Intel transactional synchronization extensions
(Intel TSX) [12] to implement this fixing strategy, i.e., a transaction
will abort if a modification to the protected variable from other
threads occurs. Such a fixing strategy is expensive, often requires
hardware support and thus only works for special processors.
7 LIMITATIONS AND DISCUSSION
While LRSan has demonstrated the capability to find a large number
of LRC cases and expose real LRC bugs in the Linux kernel, LRSan
does have its own limitations. In this section, we discuss these
limitations as well as potential solutions. We will also discuss about
how to extend LRSan to detect LRC bugs in other software systems
such as web servers and database systems.
7.1 False Positives
As a static analysis system, LRSan inevitably suffers from false
positives. LRSan identifies 2,808 LRC cases for the entire Linux
kernel, which consists of 22+ millions source lines of code. For the
core Linux kernel, LRSan detects only 340 LRC cases. To filter out
false positives, we manually analyzed LRC cases detected by LRSan,
which took two researchers about 40 hours in total. We believe this
effort is moderate and manageable. Our manual analysis considers
an LRC case a false positive if it is safe to perform the modification.
For example, the source value used for the modification may be
checked before, and thus the modification is valid. Note that LRC
cases that are hard to manually confirm are also conservatively
treated as false positives. Table 3 summarizes our study of false
positives. We discuss each category in detail as follows.
Checked modification. Our manual investigation reveals that
many false positives stem from checked modifications in which
the source of the modification is already checked; therefore, the
modification is safe and would not cause an LRC bug. Such false
positives can be eliminated through symbolic execution. By sym-
bolically computing the value of the source of modification, we can
automatically verify whether the modified value will satisfy the
security check.
Satisfiable modification. Another common cause of false pos-
itives is satisfiable modifications. For example, a range-checked
index is incrementally updated in the computation on a list struc-
ture. Such a modification (i.e., updating) is valid as long as its
updated value still satisfies the security check, which is usually
enforced the next time when index is used. Similar to the case of
checked modification, we can also automatically eliminate false pos-
itives caused by satisfiable modification through symbolic execution—
by symbolically computing the value of the critical variable and
verifying whether it still satisfies its security check.
Uncontrollable modification. LRC cases in which the source
variable of a modification is uncontrollable to attackers are deemed
as false positives because they are not exploitable. For example, the
value of a modification may come from an internal kernel variable.
To eliminate such false positives, existing techniques such as taint
analysis track the source of a modification and figure out whether
it is controllable to the external world. Given that an LRC bug
in the kernel may be invoked only by a superuser and not by an
unprivileged user, which depends on the access control policy of
the target system, inferring exploitability may also require the
knowledge of access control.
Transient check. We also find a few false positives caused by
transient security checks. That is, a security check has a limited
liveness scope, and a modification occurs outside the liveness scope
of the security check. In other words, a variable is redefined (i.e.,
modified) for other purposes, and thus the previous security check
expires. Therefore, further modification to the variable may not
violate the previous security check. Automatically understanding
the purpose of a variable is hard because it is highly dependent on
program developers’ logic. Given that such cases are not common,
we leave the filtering for manual analysis.
Unconfirmed race. If the source variable of a modification is from
a shared variable (e.g., globals), it is extremely hard, if not impos-
sible, for manual analysis to figure out its possible values without
analyzing potential race conditions. As a result, we conservatively
classify such LRC cases as false positives. In the future, we plan to
equip LRSan with existing race detection techniques to understand
how the shared variable can be controlled by other threads.
Other. Some false positives are caused by typical limitations with
static analysis, e.g., inaccurate global call graph. While they are
orthogonal challenges, analysis optimization techniques such as
pointer analysis [10, 11] for finding targets of indirect calls can
further improve the analysis accuracy of LRSan.
7.2 False Negatives
LRSan also has potential false negatives. In current design, LRSan
leverages error codes to infer security checks because a majority of
security checks return an error code upon failures. However, such
an approach may miss some cases where no error code is returned
upon a failed security check. For example, if a size value is larger
than a default maximum number, the kernel code may choose to
reset its value to the default maximum number and does not return
any error code. Our current implementation adopts “MustAlias” (in
contrast to “MayAlias”) results in the taint tracking, which can also
cause false negatives when actual aliases are missed. Moreover, we
do not include kernel modules that cannot be successfully compiled
by LLVM. We manually modeled only commonly used assemblies
but not all. These issues may also cause false negatives.
7.3 Supporting More Systems
The techniques developed in LRSan are not limited to LRC bugs in
the Linux kernel. In fact, the automated security-check identifica-
tion and recursive critical-variable inference do not have specific
assumptions on the target bugs or programs. The only assumption
LRSan makes is the availability of error codes. Some higher-level
programming languages tend to use other error-handling mecha-
nisms. However, the concept of error code is general. For example,
in the C++ programming language, in addition to error codes, ex-
ceptions are also a common mechanism to handle errors. Similar
to error codes, developers define various exception handlers to
handle different kinds of exceptions. Moreover, widely-used system
software such as OS kernels, web servers, and database systems all
have error code–like mechanisms to handle errors and failures. By
specifying how to recognize such “error code,” we can naturally
extend LRSan to detect LRC bugs in other software systems.
8 RELATED WORK
LRSan employs static program analysis techniques to detect LRC
bugs in OS kernels. In this section, we identify differences between
LRSan and some related work that leverages kernel code analysis
techniques to find semantic bugs including missing-check bugs,
double-fetch bugs, and atomicity-violating bugs.
8.1 Kernel Code Analysis
OS kernels are attractive attack targets. A single vulnerability in
an OS kernel can have a critical and wide-ranging security im-
pact. Recent research on kernel code analysis has been focusing on
improving practicality, accuracy, and soundness.
K-Miner [8] is a new static analysis framework for OS kernels.
Its key idea is to partition the kernel code along separate execu-
tion paths using the system call interface as a starting point. This
way, it significantly reduces the number of relevant paths, allowing
practical inter-procedural data-flow analysis in complex OS kernels.
K-Miner is able to detect memory-corruption vulnerabilities such
as use-after-free. Dr. Checker [21] is also a static analysis tool for
identifying bugs in Linux kernel drivers. It reduces analysis scope
by focusing only on drivers, and improves scalability and precision
by sacrificing soundness in a few cases such as not following calls
into core kernel code. It is able to effectively detect known classes
(e.g., uninitialized data leaks) of vulnerabilities in drivers. Both
K-Miner [8] and Dr.Checker [21] aim to improve practicality and
precision of static kernel analysis by limiting analysis scope, and
they employ traditional bug detection techniques. LRSan instead
aims to detect LRC bugs, a specific class of semantic errors in OS
kernels, which has not been explored before, and to this end, LRSan
incorporates new analysis techniques such as automated security
check identification and recursive critical variable inference. More-
over, LRSan’s analysis scope covers the whole OS kernel, including
both drivers and core kernel modules.
KINT [43] and UniSan [19] both are capable of statically analyz-
ing whole OS kernels. KINT [43] uses taint analysis to find integer
errors in the Linux kernel while UniSan [19] uses taint analysis to
find uninitialized bytes that may be copied from kernel space to
user space. Smatch [3] employs Sparse [39] to construct syntax tree
with type and structure information. It provides lightweight, intra-
procedural static analysis to find shallow bugs such as NULL point-
ers and uninitialized uses. Coccinelle [26] is a pattern-matching
and transformation system for OS kernels. It uses a dedicated lan-
guage SmPL (Semantic Patch Language) to specify patterns and
transformations in C code. Coccinelle is highly scalable because
it does not perform expensive inter-procedural data-flow analysis.
Compared to these analysis tools, LRSan employs whole-kernel
inter-procedural data-flow analysis, which is flow sensitive, context
sensitive, and field sensitive. In addition, we design multiple new
analysis techniques in LRSan to detect LRC bugs.
Symbolic execution [17] “executes” programs using symbolic
values. As well as solving the imprecision in traditional static anal-
ysis, it can cover significantly more execution paths of a program
than dynamic analysis. With the substantial improvement in the
efficiency of symbolic execution, e.g., S2E [4], recent research has
been able to symbolically execute OS kernels. S2E is a platform
used to analyze properties and behaviors of software systems like
OS kernels. It enables selective symbolic execution to automatically
minimize the amount of code that has to be executed symbolically,
and relaxed execution consistency models to trade-off performance
and accuracy. APISan [48] detects API misuses by analyzing func-
tion usage patterns. It utilizes symbolic execution to reason about
program errors caused by API misuses. SymDrive [30] also uses
symbolic execution to verify properties of kernel drivers. LRSan
detects LRC bugs with a principled and general approach. Sym-
bolic execution, an orthogonal technique, can improve the analysis
precision of LRSan. For example, symbolic execution can precisely
reason about whether a modified value still satisfies the constraints
of the security check, which is an interesting research issue.
8.2 Missing-Check Bugs
Security checks validate inputs and operation status to ensure secu-
rity. Missing check, in which a check is completely absent, is a very
related class of bug as LRC. However, they are inherently different.
By definition, cases in which a check is completely missed are not
LRC bugs. On the other hand, in LRC, a security check is actually
present for a variable, and thus, it is not missing-check.
As the first step of detecting missing-check bugs, it is neces-
sary to find some evidence that a security check is required for
a case. While manual auditing is feasible, it is definitely not scal-
able. In order to automatically find such evidence, researchers have
employed static analysis to infer missing-check cases. A previous
approach [7] collects sets of programmer beliefs, which are then
checked for contradictions to detect various types of missing-check
bugs. JIGSAW [40] automatically constructs programmer expecta-
tion on adversarial control at a particular resource access to detect
missing checks. Chucky [47] uses check deviations to infer missing
check. For example, if a length variable is checked in 9 out of 10
functions in a program, it is evident that the last function may miss
the check. Similarly, Juxta [22] automatically infers high-level se-
mantics by comparing multiple existing implementations that obey
latent yet implicit high-level semantics. Deviations are detected as
potential missing checks. RoleCast [35] exploits universal and com-
mon software engineering patterns to infer missing checks in web
applications. MACE [23] identifies horizontal privilege escalation
(HP) vulnerabilities in web applications using program analysis to
check for authorization state consistency.