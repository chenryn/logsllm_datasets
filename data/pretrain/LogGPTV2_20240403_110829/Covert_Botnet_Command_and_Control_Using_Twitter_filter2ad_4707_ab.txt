Encode: M × K → N140 and Decode: N140 × K → M.
The modiﬁed stego system deﬁnition is shown in ﬁgure 3. A
message m ∈ M is broken up in to symbols of Σ: m1m2 . . . ma.
Each symbol mi is mapped to one of several possible values us-
ing Encode along with the appropriate key k to generate n ∈
N140, the appropriate tweet length value to use for this piece of
the message. This value is passed to Generate, which generates
a plausible cover message x(mi) ∈ X ∗ to be posted to Twitter.
The Extract function reads the posted tweets and calculates the
length n of each tweet. This value is passed to Decode along with
the original key k to reconstruct the original message m piece by
piece. This design assumes that |Σ| ≤ 140, and in fact, smaller
alphabets should improve the security of the channel. A smaller
alphabet allows mapping each symbol to more possible length val-
ues, so repetitions of each length value are less likely. We will
now present a simpliﬁed example to show the process of the stego
system.
EXAMPLE 3.1
(ENCODING TABLE GENERATION). In this
example, we will show the process for generating the encoding ta-
ble. Instead of using N140 (all possible length values), we will use
a reduced output alphabet of N10 (1, 2, . . . , 10) with an equal dis-
tribution. For the input alphabet, we will use Σ = {a, b} with an
equal distribution.
a
3
1
2
b
8
9
10
4
5
6
7
First, choose one element of the output alphabet for each ele-
ment of Σ. This guarantees that at least one output symbol will
be mapped to each input symbol. Remove the chosen values of the
output alphabet as options for future choices.
Botmaster
a
3
1
2
b
8
9
10
4
5
6
7
Now, choose one element from both sets probabilistically based
on the weights.
a
3
1
2
b
8
9
10
4
5
6
7
Continue this process until all elements of the output alphabet
have been used.
a
3
1
2
b
8
9
10
4
5
6
7
After all elements from the output alphabet have been used, the
encoding table is composed of all of the choices made:
Symbol
Possible Length Values
a
b
1, 3, 5, 7, 9
2, 4, 6, 8, 10
EXAMPLE 3.2
(SIMPLE MESSAGE ENCODING EXAMPLE).
In this example, we will use tweet lengths up to 10, i.e. we will use
N10 = {1, 2, . . . , 10} instead of N140. We will use Σ = {a, b}
and X ∗ = {x}+, i.e. secret messages will be composed of combi-
natiosn of a and b and cover messages will be strings of x.
Suppose we want to send the secret message m = abba using
the simple Encode map from example 3.1. First, the message is
broken in to the sequence of symbols a, b, b, a. The Encode func-
tion will then map each symbol to a possible length value, e.g. 3,
6, 2, 3. Note that because each input symbol from Σ can map to
more than one length value from N10, the same symbol may or
may not be mapped to the same length value in any given mes-
sage. The Generate function will then create cover messages
that match these length values from the set of possible cover mes-
sages X ∗: xxx, xxxxxx, xx, xxx. Each cover message would
then be posted to a Twitter account in the order of the original se-
cret message. The Extract function on the recipient’s side would
then take the tweets in the posted (chronological) order, returning
the length values 3, 6, 2, 3. The Decode function can then apply
the same map as the Encode function and reconstruct the original
message abba.
This system is generic in that it can be used with many possi-
ble input alphabets, e.g. the English alphabet or arbitrary half-byte
values (0x0, 0x1, . . . , 0xF). The English alphabet allows sending
simple messages. The half-byte alphabet allows sending arbitrary
binary data by splitting each byte of the input data in half and send-
ing each half as one symbol of the message. It is impossible to
Twitter Account
···
Twitter Account
Bot
Bot
Bot
Bot
Bot
···
Figure 4: The botnet C&C diagram for the system.
send an entire byte in one message using this system because the
maximum tweet length is only 140 characters. We chose half-bytes
because it is easy to deconstruct and reconstruct the original bytes
and because it is a relatively small alphabet with only 16 symbols,
so it is possible to map each input symbol to almost 10 different
tweet length values. To obtain symbol frequencies for the half-byte
values, it would be best to empirically sample the types of data be-
ing sent across the channel because, in general, each value would
likely have an equal weight. If the speciﬁc type of data being sent is
biased toward certain byte values, that should be considered when
weighting the alphabet.
The botnet command and control diagram for this system resem-
bles the diagram for a centralized botnet, as shown in ﬁgure 4. A
botmaster controls one or more Twitter accounts that have tweets
containing the commands and the bots read from these accounts.
3.1.2 The Tweet Generator
The Generate function is one of the most challenging aspects
of this type of stego system. As discussed in [1], generating ap-
propriate and plausible cover messages for a stego system is a non-
trivial problem. In this system, the generator must be capable of
generating messages that can convince a reader of the Twitter ac-
count page that they are viewing regular tweets. This component
has the largest impact on the detectability of the channel. In essence,
the generator must pass a simpliﬁed Turing test. Twitter bots are
not a new phenomenon, and in fact several bots were created that
successfully convinced other users that they were real people [2].
Additionally, chat bots exist, such as Cleverbot4 which are reason-
ably successful [3]. However, aside from competent English skills,
the generator must utilize the “language of Twitter” that consists of
many retweets5 and hashtags6. We consider a strong generator out
of the scope of this work, but we leverage the collected Twitter data
to create a Twitter language model based on tweet contents that can
be used to generate new tweets.
3.1.3 Posting to Twitter
Along with the Encode, Generate, Extract, and Decode
functions, we need a system that can post to Twitter. This is easy to
do for testing purposes thanks to Twitter’s ofﬁcial API7 and a third
party Java library, Twitter4J8. For a real botnet scenario, the imple-
menter would likely write their own system that uses raw HTTP
requests because the Twitter API requires authentication of every
call, detects the posting method, and limits the number of posts
allowed for each account. However, because this would violate
Twitter’s terms of use, we will only post tweets using the ofﬁcial
API and abide by all limitations for testing. Now that the rest of the
4http://www.cleverbot.com/
5https://support.twitter.com/articles/77606-faqs-about-retweets-rt
6https://support.twitter.com/articles/
49309-using-hashtags-on-twitter
7https://dev.twitter.com/docs/api
8http://twitter4j.org
Symbol Weight
14810
2715
4943
4200
. . .
A
B
C
F
. . .
O
. . .
14003
. . .
Encoding
32, 16, 19, 131, 84, 37, 106, 140, 76, 111
105, 138, 67
75, 36, 125, 46, 62
17, 122, 61, 87
. . .
35, 121, 43, 107, 92, 12
. . .
have included some common botnet commands as described in
[19]. The weights were decided somewhat arbitrarily, because in a
real scenario the botmaster would tailor the weights based on which
commands they believe that they are likely to send most often. In
this case, We are assuming the byte values (indices 0 to 15) are
more likely, because for some commands arguments must be sent
using these. We don’t assume any single command is more likely
than another.
Table 1: Sample encoding map example for a few English alpha-
bets.
Figure 5: Example showing posted tweets for secret message
F OO.
components have been explained, a more complete example will be
presented.
EXAMPLE 3.3
(COMPLETE EXAMPLE). In this example, we
will use the full range of tweet lengths N140. We will use Σ =
{A, B, . . . , Z} (the English alphabet), and X ∗ as a pre-constructed
list of various proverbs and phrases of lengths ranging from one to
140. The Generate function will lookup an appropriate phrase
for each length message provided by the Encode function. Table
1 shows a portion of a generated encoding map from English let-
ters to tweet lengths. The weights shown in the second column are
taken as letter frequencies9. Those weights were used to decide the
number of entries for each letter in the third column.
Suppose we want to send the message F OO. First, the message
is separated in to the sequence of symbols F, O, O. Each is passed
to the Encode function, which chooses appropriate lengths, e.g.
61, 35, 121. The Generate function then generates tweets and
they are posted to Twitter, as shown in ﬁgure 5. The ﬁgure should
be read from bottom up, because the newer messages are posted
on top of the older messages. The account shown is a test account
created for this work. The recipient then reads these tweets, obtains
the lengths, then uses Decode with the same table as was used for
the Encode process to get the original message.
3.1.4 The Botnet Command and Control Language
The stego system described in section 3.1.1 can be used with
an arbitrary input alphabet as long as its size is not larger than the
tweet length range (up to 140 characters), so for botnet command
and control we have developed a language that can be mapped to
tweet lengths and interpreted to execute botnet commands. We
9http://www.math.cornell.edu/~mec/2003-2004/cryptography/
subs/frequencies.html
Index Weight Description
0
1
2
. . .
16
17
18
19
25
25
25
. . .
5
5
5
5
Literal hex value 0
Literal hex value 1
Literal hex value 2
. . .
Take screenshot
Shutdown computer
Reboot computer
Perform DoS attack to IPv4 address in
next 4 bytes sent
Stop DoS attack
Download and execute ﬁle from address
in next k bytes (until delimiter)
Message delimiter
20
21
22
5
5
1
Table 2: Botnet command and control language for use with the
stego system.
3.1.5 Username Generation using
Markov Chains
It is necessary to have a system for generating user names from
an initial seed so that if the original botmaster account is blocked,
they can start a new account and the bots can also generate the new
account name and begin reading from it. To do this, we employ
Markov chains [14]. The Markov chain being used can generate
strings of letters, numbers, and underscores and is trained using an
existing corpus of such text (in our case, a collection of veriﬁed
Twitter usernames).
To use this Markov chain for generating a sequence of user-
names, both the bot and botmaster must have the same initial seed.
Using this seed and the same type of pseudorandom number gen-
erator, the Markov chains will generate the same sequences as long
as both bot and botmaster follow the same procedure. First, they
need to use the random number generator to choose a user name
length. Second, they use the Markov chain with this seed to choose
a starting character. Finally, they generate enough symbols to ﬁt
the length chosen. If one performs an action out of order, it will
affect the sequences generated after that action. For example, if the