title:REDQUEEN: Fuzzing with Input-to-State Correspondence
author:Cornelius Aschermann and
Sergej Schumilo and
Tim Blazytko and
Robert Gawlik and
Thorsten Holz
REDQUEEN: Fuzzing with
Input-to-State Correspondence
Cornelius Aschermann, Sergej Schumilo, Tim Blazytko, Robert Gawlik and Thorsten Holz
Ruhr-Universit¨at Bochum
Abstract—Automated software testing based on fuzzing has
experienced a revival in recent years. Especially feedback-driven
fuzzing has become well-known for its ability to efﬁciently
perform randomized testing with limited input corpora. Despite
a lot of progress, two common problems are magic numbers
and (nested) checksums. Computationally expensive methods such
as taint tracking and symbolic execution are typically used to
overcome such roadblocks. Unfortunately, such methods often
require access to source code, a rather precise description of the
environment (e.g., behavior of library calls or the underlying OS),
or the exact semantics of the platform’s instruction set.
In this paper, we introduce a lightweight, yet very effective
alternative to taint tracking and symbolic execution to facilitate
and optimize state-of-the-art feedback fuzzing that easily scales
to large binary applications and unknown environments. We
observe that during the execution of a given program, parts
of the input often end up directly (i.e., nearly unmodiﬁed)
in the program state. This input-to-state correspondence can
be exploited to create a robust method to overcome common
fuzzing roadblocks in a highly effective and efﬁcient manner.
Our prototype implementation, called REDQUEEN,
is able to
solve magic bytes and (nested) checksum tests automatically
for a given binary executable. Additionally, we show that our
techniques outperform various state-of-the-art tools on a wide
variety of targets across different privilege levels (kernel-space
and userland) with no platform-speciﬁc code. REDQUEEN is the
ﬁrst method to ﬁnd more than 100% of the bugs planted in
LAVA-M across all targets. Furthermore, we were able to discover
65 new bugs and obtained 16 CVEs in multiple programs and
OS kernel drivers. Finally, our evaluation demonstrates that
REDQUEEN is fast, widely applicable and outperforms concurrent
approaches by up to three orders of magnitude.
I.
INTRODUCTION
Fuzzing has become a critical component in testing the
quality of software systems. In the past few years, smarter
fuzzing tools have gained signiﬁcant
traction in academic
research as well as in industry. Most notably, american fuzzy
lop (AFL [44]) has had a signiﬁcant impact on the security
landscape. Due to its ease of use,
is now convenient
to more thoroughly test software, which many researchers
and developers did. On the academic side, DARPA’s Cyber
Grand Challenge (CGC) convincingly demonstrated that fuzzing
remains highly relevant for the state-of-the-art in bug ﬁnding:
all teams used this technique to uncover new vulnerabilities.
it
Network  and  Distributed  Systems  Security  (NDSS)  Symposium  2019 
24-27  February  2019,  San  Diego,  CA,  USA
ISBN  1-891562-55-X
https://dx.doi.org/10.14722/ndss.2019.23371
www.ndss-symposium.org
Following CGC, many new fuzzing methods were presented
which introduce novel
ideas to ﬁnd vulnerabilities in an
efﬁcient and scalable way (e.g., [10], [16], [19], [31], [34]–
[38]).
To ensure the adoption of fuzzing methods in practice,
fuzzing should work with a minimum of prior knowledge.
Unfortunately, this clashes with two assumptions commonly
made for efﬁciency: (i) the need to start with a good corpus of
seed inputs or (ii) to have a generator for the input format. In
absence of either element, fuzzers need the ability to learn
what interesting inputs look like. Feedback-driven fuzzing,
a concept popularized by AFL, is able to do so: Interesting
inputs which trigger new behavior are saved to produce more
testcases, everything else is discarded.
A. Common Fuzzing Roadblocks
To motivate our approach, we ﬁrst revisit the problem of
efﬁciently uncovering new code, with a focus on overcoming
common fuzzing roadblocks. In practice, two common prob-
lems in fuzzing are magic numbers and checksum tests. An
example for such code can be seen in Listing 1. The ﬁrst bug
can only be found if the ﬁrst 8 bytes of the input are a speciﬁc
magic header. To reach the second bug, the input has to contain
the string “RQ” and two correct checksums. The probability of
randomly creating an input that satisﬁes these conditions is
negligible. Therefore, feedback-driven fuzzers do not produce
new coverage and the fuzzing process stalls.
/* magic number example */
if(u64( input )== u64(" MAGICHDR "))
bug (1);
/* nested checksum example */
if(u64( input )== sum( input +8, len -8))
if(u64( input +8) == sum( input +16 , len -16) )
if( input [16]== ’R’ && input [17]== ’Q’)
bug (2);
Listing 1: Roadblocks for feedback-driven fuzzing.
In the past, much attention was paid to address such road-
blocks. Different approaches were proposed which typically
make use of advanced program analysis techniques, such as
taint tracking and symbolic execution [12], [13], [16], [22],
[23], [26], [35], [38], [40]. Notably, both ANGORA [16] and
T-FUZZ [34] fall into this category. These approaches usually
require a rather precise description of the environment (e.g.,
behavior of library calls or the underlying OS) and the exact
semantics of the platform’s instruction set. As a result, it is
hard to use this methods on targets that use complex instruction
set extensions (i. e., ﬂoating point instructions) or uncommon
libraries and operating systems. Therefore, such approaches
are the polar opposite of the approach pioneered by AFL: to a
large extend, AFL’s success is based on the fact that it makes
few assumptions about the program’s behavior. Based on this
insight, we investigate a novel fuzzing method that excels at
increasing code coverage on arbitrary targets, ranging from
open-source userland programs to closed-source OS kernels.
We demonstrate that this approach can outperform existing
fuzzing strategies.
B. Our Approach: Input-to-State Correspondence
In this paper, we propose a novel and lightweight method
that—in many cases— is able to replace the two complex
analysis primitives taint tracking and symbolic execution. In
contrast to the two aforementioned techniques, our method is
easy to implement and scales to large, complex targets and
diverse environments. Our approach is based on a simple yet
intuitive observation: in many cases, parts of the input directly
correspond to the memory or registers at run time. Hence,
there is a strong input-to-state correspondence between the
input and the current program state. This can be exploited
to implement an efﬁcient fuzzing approach. In practice, most
programs apply only a small number of decoding steps to the
input, before the inputs data is used. We found that the set
of encoding schemes used by real-world programs is typically
rather small: normally, these values are directly used in the
context of hard condition such as checks for a speciﬁc header
value (magic bytes). For example, it is common that input
bytes are interpreted as little-endian integers and then directly
compared against a checksums or speciﬁc magic bytes.
We exploit
this observation by tracing the program to
observe values used in compare instructions. By “colorizing”
the input with random bytes, we create a very lightweight
approximation to taint tracking. Then, we speculate that we
are able to control these values by changing the corresponding
input bytes. Finally, we use the fast fuzzing process to verify
whether we triggered new and potential interesting behav-
ior. Similarly, we swiftly discard false positives which arise
from this over-approximation. This method allows us to skip
complex sections of the code such as API calls or unknown
instructions, which would otherwise be difﬁcult
to handle
for taint tracking or symbolic execution. As a result, even
inputs which pass through unknown library functions, large
data-dependent loops, and ﬂoating point instructions do not
signiﬁcantly reduce the quality of the results. We continue to
use the same principle to implement a patching-based solution
to handle checksum tests. In contrast to similar approaches,
our approach entirely avoids symbolic execution, while always
maintaining a queue of inputs with valid checksums and no
false positives.
Feedback-driven fuzzers typically use the same instru-
mentation across all executions to measure code coverage
and other feedback information. For example, VUZZER uses
its full taint tracking capabilities on each input generated.
Since most fuzzing executions (millions to billions) happen
on top of the same few inputs (thousands to hundreds of
thousands), we propose to incorporate analysis into feedback-
driven fuzzing differently: we separate the more expensive
analysis process from the fuzzing process. In our case, we
perform the expensive search for path-speciﬁc input-to-state
correspondences only once per new input found. All actual
fuzzing is then performed without this additional overhead.
We found that this approach greatly reduces the cost associated
with more expensive analysis and allows the remaining fuzzing
process to take advantage of the knowledge gained during the
analysis phase.
While our approach can be seen as an approximation to
taint tracking and symbolic execution, our evaluation results
are quite competitive with tools using more expensive “real”
taint tracking and symbolic execution. To perform our eval-
uation, we implemented a prototype of our approach, called
REDQUEEN, that can handle binary-only targets. Our empirical
evaluation on the GNU binutils suite demonstrates, that
our approach is, in all cases, able to cover signiﬁcantly more
code than existing tools. Measuring the time to equal coverage
yields speedups in the range of 5x to 5000x when compared
to VUZZER [35] and KLEE [12], as well as 2x to 200x against
AFLFAST [10] and LAF-INTEL [2]. In addition, we are the
ﬁrst to ﬁnd signiﬁcantly more bugs (2600) than listed in the
LAVA-M data set (2265). In total, we found an additional 335
unlisted bugs, yielding over 114% of all listed bugs. We only
missed two of the 2265 listed vulnerabilities in the LAVA-M
data set (>99.9% bug coverage).
Moreover, our technique avoids a signiﬁcant amount of
implementation and performance overhead typically associated
with taint tracking and symbolic execution. Therefore, our
approach is applicable to a much more diverse set of targets
than aforementioned techniques, which require a detailed en-
vironment model. In fact, REDQUEEN is able to fuzz programs
with no need for source code or platform knowledge, as we
demonstrate by applying REDQUEEN to both kernel- as well
as user-space targets. In our evaluation, REDQUEEN found 10
bugs in 2 different Linux ﬁle system drivers and 55 bugs in
16 user-space programs and software libraries. Additionally,
16 CVEs have been assigned for some of the more critical
issues we uncovered.
C. Contributions
In summary, we make the following contributions:
• We introduce the concept of input-to-state correspon-
dence as a novel principle to signiﬁcantly accelerate
feedback-driven fuzzing.
• We show that input-to-state correspondence can be
used instead of taint tracking and symbolic execu-
tion to solve hard fuzzing problems such as dealing
with magic numbers, dynamic multi-byte compares,
and (nested) checksums without introducing any false
positives. The resulting mutation operator is more
efﬁcient than all other mutation operator used by AFL
(measured in new paths found over time used).
• We built a prototype implementation of our method in
a tool called REDQUEEN. Our comprehensive evalua-
tion results demonstrate that REDQUEEN outperforms
all state-of-the-art fuzzing tools in several metrics.
To foster research on this topic, we release our fuzzer at
https://github.com/RUB-SysSec/redqueen.
2
II. RELATED WORK
Fuzzing has been an active ﬁeld of research for decades.
Initially, much attention was focused on improving black-
box fuzzing (e.g., fuzzing strategies in which the fuzzer does
not inspect the program internals and treats it as a black-
box). Which results in improved scheduling algorithms [14],
[36], [41] and more effective mutation or input generation
strategies [4], [29]. Even machine learning techniques were in-
vestigated to infer semi-valid inputs as test cases [8], [24], [27].
Recently, more focus was put on white- and gray-box fuzzing.
Usually, the program under test is instrumented to generate
some kind of feedback (such as code coverage). The archetypal
gray-box fuzzer is AFL [44]. It uses coverage as a feedback
mechanism to learn which inputs are interesting and which
do not trigger new behavior. Much recent work is based on
AFL. The scheduling of AFL was analyzed and improved by
AFLFAST [10]. COLLAFL [19] and INSTRIM [30] improve
the performance of AFL, by decreasing the probability that two
distinct paths are considered the same. The performance of the
fuzzers itself were improved in many different ways [25], [42].
One notable example is go-fuzz [39] which was developed
independently and uses a similar idea as REDQUEEN. The
OSS-FUZZ project scaled the AFL fuzzing model to large
computing clusters and discovered a signiﬁcant amount of
vulnerabilities in highly relevant open-source software [1].
HONGGFUZZ [6] and KAFL [37] use algorithms inspired by
AFL and modern CPU extensions to demonstrate how binary-
only targets can be fuzzed in an efﬁcient manner. In this work,
we aim at solving problems commonly addressed by white-
box fuzzing techniques. We will, therefore, use this section to
differentiate our approach from existing work on fuzzing.
A. Symbolic/Concolic Execution-based Fuzzing
Several gray- or white-box fuzzing tools make use of sym-
bolic execution to improve test coverage [12], [13]. Symbolic
execution can ﬁnd vulnerabilities that are very hard to trigger
randomly, or even, with clever heuristics. However, it also
tends to become very slow on large targets and state explosion
has to be carefully taken into account. One common approach
to handle state explosion is to use concolic execution [21]–
[23], [26], [33], [38], [40]. In concolic execution, the program
path is constrained to a concrete path while the solver either
tries to trigger bugs on this path or to uncover a new path.
This approach greatly reduces the number of states that are
being explored and can—at least in some cases—be used
to reduce the complexity of the formulas encountered by
replacing complex expressions with their concrete values.
Additionally, symbolic execution has often been motivated by
the need to solve magic byte checks. Our results show that,
in our empirical evaluation, a much simpler approach is often
sufﬁcient to solve these cases.
B. Taint-based Fuzzing
Similar to symbolic execution, taint tracking is commonly
used by fuzzing tools. It allows learning which parts of the
input are affecting certain operations. In the past, taint tracking
was used to identify and focus on parts of the input that are
used as magic bytes [35], addresses [20], [26], [35], or integers
that might overﬂow [33]. In this paper, we show that input-to-
state correspondence can often be used as an approximation
to taint
tracking and does solve these common problems
much more efﬁciently. Recently, another taint-based fuzzing
approach called ANGORA [16] was proposed. Similarly to
our approach, ANGORA uses the expensive taint
tracking
step only sparsely to overcome hard-to-solve conditions. In
contrast, ANGORA relies on source code access and a special
compiler pass to perform efﬁcient taint tracking, while we
propose a binary-level fuzzer. Moreover, ANGORA cannot
handle checksums.
C. Patching-based Fuzzing
Most symbolic execution based tools are able to generate
valid checksums, but cannot use the faster fuzzing component
to explore the code after the check. Some fuzzers try to patch
hard checks to make a given program easier to fuzz. Three
examples of fuzzing methods that follow this approach are
FLAYER [18], TAINTSCOPE [40], and T-FUZZ [34]. Since we
also patch checksum tests to be able to fuzz efﬁciently, a more
thorough discussion of these tools is provided in Section III-B.
Our idea for checksum handling is inspired by both FLAYER
and TAINTSCOPE. However, FLAYER needs an explicit list of
conditional branches to patch. In addition, the user has to ﬁx
the input after the fuzzing process. In contrast, TAINTSCOPE
is able to infer the list of checks automatically and patch all
hard-to-solve branches during fuzzing. Then—after ﬁnishing
the fuzzing process—TAINTSCOPE uses symbolic execution
to ﬁx crashing inputs. Similar to TAINTSCOPE, our process is
entirely automated. In contrast, however, we use our idea of
input-to-state correspondence to avoid the complex and often
brittle taint tracking and symbolic execution methods. T-FUZZ
also uses an approach related to TAINTSCOPE: the program
is transformed to reach code after hard-to-solve conditions;
broken checks are later ﬁxed using symbolic execution. The
improvement in performance that REDQUEEN provides over T-
FUZZ can be explained by the fact that T-FUZZ needs to spawn
new fuzzing instances for each hard-to-reach part of the code.
Additionally, T-FUZZ does not remove false positives during
fuzzing. Hence, the number of fuzzing instances that are work-
ing on dead ends can grow nearly unbounded. In contrast, our
approach avoids these scalability issues all together by always
maintaining a queue of valid inputs. Therefore REDQUEEN
neither produces, nor spends time on false positives.
D. Binary-Only Fuzzers
Many fuzzers such as AFL, LAF-INTEL and ANGORA
need source code access to add the necessary instrumentation
and patches. As a result, proprietary systems cannot be ana-
lyzed with these fuzzers. To overcome this limitation, some
fuzzers use other mechanisms to obtain feedback. AFL has
spawned multiple forks that use PIN [32], DynamoRIO [11]
or QEMU [9] to obtain coverage information. Similarly, fuzzers
like VUZZER, TAINTSCOPE, FLAYER, T-FUZZ and DRILLER
make use of various dynamic binary instrumentation tools. We
found that the fastest binary-only fuzzer is AFL with QEMU,
which is signiﬁcantly slower (in executions per second) than
AFL with compile-time instrumentations.
E. The AFL Family
Due to the overwhelming success of the AFL design,
many different tools are heavily based on AFL [1], [2], [5],
3
[10], [16], [31], [37], [38]. Our work is based on KAFL—
an AFL-like fuzzer—and, therefore, it is paramount to have a