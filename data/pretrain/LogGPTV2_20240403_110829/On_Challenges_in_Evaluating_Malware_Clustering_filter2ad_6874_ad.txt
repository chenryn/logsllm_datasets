### Measuring the Rate of Degradation in Malware Clustering

To measure the rate of degradation from the ideal state as perturbations are introduced into the distance matrices, we compare the perturbed matrices to the reference matrices. 

#### Re-clustering with Perturbed Distance Matrices
When re-clustering a perturbed distance matrix, the cluster-size distribution may change, as hierarchical clustering might not produce an identical distribution to the original. To address this, we fit a parameterized distribution to the reference cluster-size distribution and stop hierarchical clustering at the point that maximizes the p-value of a chi-squared test between the test cluster-size distribution and the fitted reference distribution. We find that a Weibull distribution with shape parameter \( k = 0.7373 \) and scale parameter \( \lambda = 1.9887 \) fits well for the VXH-data dataset (p-value of 0.8817), while for the BCHKK-data, the corresponding values are \( k = 0.4492 \) and \( \lambda = 5.1084 \) (p-value of 0.8763).

#### Perturbing the Distance Matrix
Given only a distance matrix, a method is needed to perturb it while maintaining the properties of a distance (e.g., satisfying the triangle inequality). We achieve this by mapping the distance matrix into a d-dimensional space, creating d-dimensional points to represent malware instances separated according to the distances in the matrix. To perturb the distances, each point is moved to a random spot within a ball of radius \( r \) centered at that point. This process generates a new distance matrix for the perturbed points, which can then be re-clustered. By increasing \( r \), we increase the maximum perturbation to the distances.

### Results and Analysis

The results of this analysis are shown in Figure 4. The x-axis represents the radius \( r \) within which each point was perturbed from its original position in d-dimensional space. The y-axis shows the F-measure for each radius \( r \), averaged over five runs, with negligible standard deviations. As shown, the cluster-size distributions characteristic of the VXH-data were more sensitive to perturbations than those of the BCHKK-data. Additionally, Figure 5 displays the p-values of chi-squared tests comparing the cluster-size distribution of the clustering after perturbation and the fitted (Weibull) reference cluster-size distribution. The fact that these p-values do not significantly decrease indicates that the degradation in the F-measure was not primarily due to deviation from the intended cluster-size distributions.

To control for the discrepancy in the number of malware instances represented in the BCHKK-data and VXH-data datasets, we plot a "Downsized BCHKK-data" line in Figure 4. This involves randomly removing instances from BCHKK-data until the dataset size matches that of VXH-data (1,114 instances). Using the correspondingly downsized distance matrix, we applied hierarchical clustering with the same threshold as reported in [6], resulting in a clustering with estimated Weibull parameters \( k = 0.4307 \) and \( \lambda = 2.0399 \). The results, averaged over five runs, show that "Downsized" BCHKK-data is still more immune to perturbation than VXH-data.

### Further Examination of Cluster Size Distributions

To further examine the effects of cluster size distributions on precision and recall, Figure 6 plots the average F-measure for reference clusters \( D \) and test clusters \( C \) whose sizes are chosen from a Weibull distribution with the shape parameter \( k \) shown on the x-axis. Once the reference and test cluster sizes are chosen independently, the clusters are populated independently at random. As Figure 6 shows, the F-measure resulting from different values of \( k \) provides insight into the bias that cluster size distribution can introduce.

### Conclusion

In this paper, we investigate the impact of ground-truth selection on the accuracy reported for malware clustering techniques. We highlight the possibility that using the concurrence of multiple anti-virus tools to determine ground truth may bias the dataset toward easy-to-cluster instances. Our investigation, based on clustering using plagiarism detectors, suggests that the highly accurate results reported for a state-of-the-art malware classifier (BCHKK-algo) are tempered by a reduced significance due to a biased cluster-size distribution. We recommend that future evaluations employ data with a more even cluster-size distribution.

While our study introduces more questions than definitive answers, we believe it underlines the importance of further research in malware clustering, particularly in better methods for establishing ground truth and identifying more reliable features for clustering.

### Acknowledgements

We are deeply grateful to Ulrich Bayer, Engin Kirda, Paolo Milani Comparetti, and Christopher Kruegel for their assistance, access to the BCHKK-data dataset, and helpful discussions. This work was supported in part by NSF award CT-0756998 and by DRTech Singapore under grant POD0814140.

### References

[References listed as in the original text]