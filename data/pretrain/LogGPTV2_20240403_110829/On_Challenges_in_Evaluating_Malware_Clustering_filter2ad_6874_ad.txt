measure the rate of degradation from this ideal as the perturbations are introduced
into the distance matrices, compared to these references.
– When re-clustering a perturbed distance matrix, the cluster-size distribution might
be altered, in that hierarchical clustering simply might not produce an identical
cluster-size distribution as the original from the perturbed distance matrix. For this
reason, we ﬁt a parameterized distribution to the reference cluster-size distribu-
tion and stop hierarchical clustering at the point that maximizes the p-value of a
chi-squared test between the test cluster-size distribution and the ﬁtted reference
On Challenges in Evaluating Malware Clustering
251
distribution. In general, we ﬁnd that a Weibull distribution with shape parameter
k = 0.7373 and scale parameter λ = 1.9887 is a good ﬁt for the reference cluster-
ing (i.e., the initial test clustering resulting from BCHKK-algo, as described above)
of the VXH-data dataset (p-value of 0.8817), and that the corresponding values for
the BCHKK-data are k = 0.4492 and λ = 5.1084 (p-value of 0.8763).
– Given that we have only a distance matrix, a method of perturbing it so that its
entries maintain properties of a distance (notably, satisfying the triangle inequality)
is necessary. To do this, we map the distance matrix into a d-dimensional space,
i.e., creating d-dimensional points to represent the malware instances, separated
according to the distances in the matrix. To then perturb the distances, we simply
move each point to a random spot in the ball of radius r centered at that point.
We can then produce the corresponding distance matrix for these perturbed points,
and re-cluster. By increasing r, we then increase the maximum perturbation to the
distances.
The results of this analysis are shown in Figure 4. In this ﬁgure, the x-axis shows the ra-
dius r within which we perturbed each point from its original position in d-dimensional
space. The y-axis shows the F-measure that resulted for each radius r, averaged over
ﬁve runs; standard deviations were negligible. As this ﬁgure shows, the cluster-size dis-
tributions characteristic of the VXH-data were indeed more sensitive to perturbations
in the underlying data than were those characteristic of the BCHKK-data. In addition,
in Figure 5 we show the p-values of chi-squared tests comparing the cluster-size distri-
bution of the clustering after perturbation and the ﬁtted (Weibull) reference cluster-size
distribution. The fact that these p-values are not signiﬁcantly decreasing indicates that
the cause of degradation in the F-measure was not primarily due to deviation from the
intended cluster-size distributions.
We also plot a “Downsized BCHKK-data” line in Figure 4 to control for the discrep-
ancy in the number of malware instances represented in the BCHKK-data and VXH-
data datasets. To do this, we randomly removed instances from BCHKK-data (irrespec-
tive of the reference clusters in which they fall) until the size of the data set is the
same as that of VXH-data, i.e., 1, 114 instances. Using the correspondingly downsized
1
0.95
e
r
u
s
a
e
m
−
F
0.9
0.85
0.8
BCHKK−data
VXH−data
Downsized BCHKK−data
0.75
0 .04 .08 .12 .16 .20 .24 .28 .32 .36 .40 .44 .48 .52 .56 .60 .64 .68 .72 .76 .80
perturbation limit (r)
Fig. 4. Tolerance to perturbations
252
P. Li et al.
l
e
u
a
v
−
p
1
0.9
0.8
0.7
0.6
0.5
e
r
u
s
a
e
m
−
F
0.6
0.5
0.4
0.3
0.2
0.1
0
BCHKK−data
VXH−data
0 .04 .08 .12 .16 .20 .24 .28 .32 .36 .40 .44 .48 .52 .56 .60 .64 .68 .72 .76 .80
perturbation limit (r)
Fig. 5. p-values for perturbation tests
λ = 2
λ = 3
λ = 4
λ = 5
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
k
Fig. 6. F-measure of random test and reference clusterings with cluster sizes drawn from a
Weibull distribution with scale parameter λ ∈ [2, 5] and shape parameter k ∈ [0.2, 0.9], av-
eraged over 10 trials. Error bars show standard deviation. Note that the best-ﬁt (k, λ) value for
the BCHKK-data reference clustering is (0.4488, 4.8175) and for the VXH-data reference clus-
tering is (0.7803, 2.5151).
distance matrix, we applied hierarchical clustering using the same threshold to stop
clustering as reported in [6], resulting in a clustering whose cluster-size distribution has
corresponding estimated Weibull parameters k = 0.4307 and λ = 2.0399. We took this
clustering as the starting point for “Downsized” perturbation test and show the results
(averaged over 5 runs) in Figure 4. And as we can see, “Downsized” BCHKK-data is
still more immune to perturbation than VXH-data.
To further examine the effects of cluster size distributions on precision and recall,
in Figure 6 we plot the average F-measure for reference clusters D and test clusters C
whose cluster sizes are chosen from a Weibull distribution with the shape parameter
On Challenges in Evaluating Malware Clustering
253
k shown on the x-axis. Once the reference and test cluster sizes are chosen (indepen-
dently), the reference and test clusters are then populated independently at random (i.e.,
each point is assigned to a cluster in D and a cluster in C independently). As Figure 6
shows, the F-measure that results simply from different values of k provides further
insight into the bias that cluster size distribution can introduce.
We do not mean to suggest that the complete discrepancy between the results of the
BCHKK-algo clustering technique on the VXH-data and BCHKK-data is due solely to
the cluster size distributions underlying the two datasets. However, we do believe that
this case and our analysis of it offers sufﬁcient evidence to recommend that evaluation
of future clustering techniques be done on datasets with a variety of cluster size distri-
butions. It is also possible that measures of cluster accuracy other than precision and
recall better avoid this source of bias. For example, Perdisci et al [15] employed an
approach based on the compactness of each cluster and the separation among different
clusters, which may be preferable.
6 Conclusion
In this paper we have reported on our investigation of the impact that ground-truth se-
lection might have on the accuracy reported for malware clustering techniques. Our
starting point was investigating the possibility that a common method of determining
ground truth, namely utilizing the concurrence of multiple anti-virus tools in classifying
malware instances, may bias the dataset toward easy-to-cluster instances. Our investi-
gation of this possibility was based on clustering using a different set of tools developed
without attention to the subtleties of malware, namely plagiarism detectors. While our
application of these tools, ﬁrst to a dataset used in the evaluation of a state-of-the-art
malware clustering technique and second to a whole new malware dataset, arguably
leaves our conjecture unresolved, we believe that highlighting this possibility is impor-
tant to facilitate discussion of this issue in the community.
It has also led us to examine an issue that we believe to be important for future
analyses of malware clustering, namely the impact of the ground-truth cluster-size dis-
tribution on the signiﬁcance of results suggesting high accuracy. In particular, we have
shown that the highly accurate results reported for a state-of-the-art malware classiﬁer
(BCHKK-algo) are tempered by a reduced signiﬁcance owing to having tested on a
dataset with a biased cluster-size distribution. We consequently recommend that future
evaluations employ data with a cluster-size distribution that is more even.
We caution the reader from drawing more conclusions from our study than is war-
ranted, however. In particular, despite the similar performance of the BCHKK-algo
algorithm and the plagiarism detectors in clustering on the malware datasets we con-
sidered, it is not justiﬁed to conclude that these algorithms are equally effective for
malware clustering. The design of the BCHKK-algo algorithm should make it more
difﬁcult to evade, not to mention more scalable. It is evident, however, from our results
in Section 3 that either malware today is not designed to exploit differences in the clus-
tering abilities of BCHKK-algo and plagiarism detectors, or else that the ground-truth
selection of the test datasets eliminated malware instances that do so.
We recognize that our paper has perhaps introduced more questions than it has deﬁni-
tively answered. Nevertheless, we believe that in addition to the observations above,
254
P. Li et al.
multiple opportunities for future research can be drawn from our investigation. In par-
ticular, we believe our investigation underlines the importance of further research in
malware clustering, speciﬁcally in better methods for establishing ground truth, in iden-
tifying more reliable features for malware clustering, or in both.
Acknowledgements. We are deeply grateful to Ulrich Bayer, Engin Kirda, Paolo Milani
Comparetti, and Christopher Kruegel for helpful assistance, for providing access to the
BCHKK-data dataset, for applying BCHKK-algo to our VXH-data dataset, for helpful
discussions, and for useful comments on drafts of this paper. This work was supported in
part by NSF award CT-0756998 and by DRTech Singapore under grant POD0814140.
References
1. Threatexpert3, http://www.threatexpert.com/
2. Norman sandbox center (2008),
http://www.norman.com/security_center/security_tools/en
3. VX Heavens (2010), http://vx.netlux.org/
4. Aiken, A.: Moss: a system for detecting software plagiarism,
http://theory.stanford.edu/˜aiken/moss/
5. Bailey, M., Oberheide, J., Andersen, J., Mao, Z.M., Jahanian, F., Nazario, J.: Automated
classiﬁcation and analysis of internet malware. In: Kruegel, C., Lippmann, R., Clark, A.
(eds.) RAID 2007. LNCS, vol. 4637, pp. 178–197. Springer, Heidelberg (2007)
6. Bayer, U., Comparetti, P.M., Hlauschek, C., Kruegel, C., Kirda, E.: Scalable, behavior-based
malware clustering. In: Proceedings of the Network and Distributed System Security Sym-
posium (2009)
7. Bayer, U., Kruegel, C., Kirda, E.: Ttanalyze: A tool for analyzing malware. In: 15th European
Institute for Computer Antivirus Research (EICAR 2006) Annual Conference (2006)
8. Commtouch, Inc. Malware outbreak trend report: Bagle/beagle (March 2007),
http://www.commtouch.com/documents/Bagle-Worm_MOTR.pdf
9. Gheorghescu, M.: An automated virus classiﬁcation system. In: Proceedings of the Virus
Bulletin Conference, VB (1994)
10. Ha, K.: Keylogger.stawin,
http://www.symantec.com/security response/
writeup.jsp?docid=2004-012915-2315-99
11. Hu, X., Chiueh, T., Shin, K.G.: Large-scale malware indexing using function-call graphs. In:
Proceedings of 16th ACM Conference on Computer and Communications Security (2009)
12. Kamiya, T., Kusumoto, S., Inoue, K.: Ccﬁnder: A multi-linguistic token-based code clone
detection system for large scale source code. IEEE Trans. on Software Engineering, 654–
670 (2002)
13. Lee, T., Mody, J.J.: Behavioral classiﬁcation. In: 15th European Institute for Computer An-
tivirus Research (EICAR 2006) Annual Conference (2006)
14. McAfee. W97m/opey.c, http://vil.nai.com/vil/content/v_10290.htm
15. Perdisci, R., Lee, W., Feamster, N.: Behavioral clustering of http-based malware and sig-
nature generation using malicious network traces. In: USENIX Symposium on Networked
Systems Design and Implementation, NSDI 2010 (2010)
16. Rieck, K., Holz, T., Willems, C., Dussel, P., Laskov, P.: Learning and classiﬁcation of mal-
ware behavior. In: Zamboni, D. (ed.) DIMVA 2008. LNCS, vol. 5137, pp. 108–125. Springer,
Heidelberg (2008)
On Challenges in Evaluating Malware Clustering
255
17. Rieck, K., Trinius, P., Willems, C., Holz, T.: Automatic analysis of malware behavior using
machine learning. Technical Report 18-2009, Berlin Institute of Technology (2009)
18. Song, D., Brumley, D., Yin, H., Caballero, J., Jager, I., Kang, M.G., Liang, Z., Newsome, J.,
Poosankam, P., Saxena, P.: Bitblaze: A new approach to computer security via binary anal-
ysis. In: Proceedings of the 4th International Conference on Information Systems Security
(December 2008)
19. Symantec. Spyware.e2give,
http://www.symantec.com/security response/
writeup.jsp?docid=2004-102614-1006-99
20. Symantec. Xeram.1664,
http://www.symantec.com/security response/
writeup.jsp?docid=2000-121913-2839-99
21. Tamada, H., Okamoto, K., Nakamura, M., Monden, A., Matsumoto, K.: Dynamic software
birthmarks to detect the theft of windows applications. In: International Symposium on Fu-
ture Software Technology (2004)
22. Tan, P., Steinbach, M., Kumar, V.: Introduction to Data Mining. Addison-Wesley, Reading
(2006)
23. Wang, X., Jhi, Y., Zhu, S., Liu, P.: Detecting software theft via system call based birthmarks.
In: Proceedings of 25th Annual Computer Security Applications Conference (2009)
24. Whale, G.: Identiﬁcation of program similarity in large populations. Computer Journal, Spe-
cial Issue on Procedural Programming, 140–146 (1990)
25. Willems, C., Holz, T., Freiling, F.: Toward automated dynamic malware analysis using
cwsandbox. In: Proceedings of the 2007 IEEE Symposium on Security and Privacy (S&P
2007), pp. 32–39 (2007)
26. Wise, M.J.: Detection of similarities in student programs: Yaping may be preferable to
plagueing. In: Proceedings of the 23rd SIGCSE Technical Symposium (1992)