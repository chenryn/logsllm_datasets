Timing side-channel leaks Two vulnerabilities were re-
lated to timing side-channel leaks, where the observable
duration of cryptographic operations depended on cryp-
tographic secrets. These were implementation issues,
related to the use of variable-duration arithmetic oper-
ations. The PKCS1.5 padding of the premaster secret
is transmitted during an RSA key exchange. If the un-
padding fails, there is computationally no need to de-
crypt the received secret material. But omitting this step
leaks the information on whether the padding was cor-
rect through the time signature, and this can be used to
obtain the secret. A similar issue was discovered in 2014
in various TLS implementations [34].
nqsb-TLS mitigates this attack by always computing
the RSA operation, on padding failure with a fake value.
To mitigate timing side-channels, which a memory man-
aged programming language might further expose, we
use C implementations of the low level primitives (§4.2).
Usage of the libraries Of the examined bugs, 10 were
not in TLS implementations themselves, but in the way
the client software used them. These included the high-
proﬁle anonymisation software Tor [16], the instant mes-
senger Pidgin and the widely used multi-protocol data
transfer tool cURL.
TLS libraries typically have complicated APIs due to
implementing a protocol with a large parameter space.
For example, OpenSSL 1.0.2 documents 243 symbols in
its protocol alone, not counting the cryptographic parts of
the API. Parts of its API are used by registering callbacks
with the library that get invoked upon certain events. A
well-documented example of the difﬁculty in correctly
using these APIs is the OpenSSL certiﬁcate validation
callback. The library does not implement the full logic
that is commonly needed (it omits name validation), so
the client needs to construct a function to perform cer-
tiﬁcate validation using a mix of custom code and calls
to OpenSSL, and supply it to the library. This step is a
common pitfall: a recent survey [23] showed that it is
common for OpenSSL clients in the wild to do this in-
correctly. We counted 6 individual advisories stemming
from improper usage of certiﬁcate validation API, which
is a large number given that improper certiﬁcate valida-
tion undermines the authentication property of TLS and
completely undermines its security.
The root cause of this error class is the large and com-
plex legacy APIs of contemporary TLS stacks. nqsb-TLS
does not mirror those APIs, but provides a minimal API
with strict validation by default. This small API is suf-
ﬁcient for various applications we developed. OpenBSD
uses a similar approach with their libtls API.
4 The nqsb-TLS stack
We now describe how we structure and develop the nqsb-
TLS stack, following the approach outlined in the intro-
duction to avoid a range of security pitfalls.
228  24th USENIX Security Symposium 
USENIX Association
6
4.1 TLS Core
The heart of our TLS stack is the core protocol imple-
mentation. By using pure, composable functions to ex-
press the protocol handling, we deal with TLS as a data-
transformation pipeline, independent of how the data is
obtained or transmitted.
Accordingly, our core revolves around two functions.
One (handle tls) takes the sequence of bytes seen on
the wire and a value denoting the previous state, and
produces, as new values,
the bytes to reply with or
to transfer to the application, and the subsequent state.
Our state type encapsulates all the information about
a TLS session in progress, including the state of the
handshake, the cryptographic state for both directions
of communication, and the incomplete frames previ-
ously received, as an immutable value. The other one
(send application data) takes a sequence of bytes
that the application wishes to send and the previous state,
and produces the sequence ready to be sent and the sub-
sequent state. Coupled with a few operations to extract
session information from the state, these form the entire
interface to the core protocol implementation.
Below the entry points, we segment the records, de-
crypt and authenticate them, and dispatch to the appro-
priate protocol handler. One of the places where OCaml
helps most prominently is in handling of the combined
state machine of handshake and its interdependent sub-
protocols. We use algebraic data types to encode each
possible handshake state as a distinct type variant, that
symbolically denotes the state it represents and contains
all of the data accumulated so far. The overall state
type is simply the discriminated union of these variants.
Every operation that extracts information from state
needs to scrutinise its value through a form of multi-way
branching known as pattern match. This syntactic con-
struct combines branching on the particular variant of
the state present with extraction of components. The
resulting dispatch leads to equation-like code: branches
that deal with distinct states follow directly from the val-
ues representing them, process the state data locally, and
remain fully independent in the sense of control ﬂow and
access to values they operate on. Finally, each separately
materialises the output and subsequent state.
This construction and the explicit encoding of state-
machine is central to maintaining the state-machine in-
variants and preserving the coherence of state represen-
tation. It is impossible to enter a branch dedicated to a
particular transition without the pair of values represent-
ing the appropriate state and appropriate input message,
and, as intermediate data is directly obtained from the
state value, it is impossible to process it without at the
same time requiring that the state-machine is in the ap-
propriate state.
It is also impossible to manufacture a
state-representation ahead of time, as it needs to contain
all of the relevant data.
The beneﬁt of this encoding is most clearly seen in
CCS-injection-like vulnerabilities. They depend on ses-
sion parameters being stored in locations visible through-
out the handshake code, which are activated on receipt
of the appropriate message. In the OpenSSL case (CVE-
2014-0224), the dispatch code failed to verify whether
all of these locations were populated, which implies that
the handshake progressed to the appropriate phase.
In
our case, the only way to refer to the session parameters
is to deconstruct a state-value containing them, and it is
impossible to create this value without having collected
the appropriate session parameters.
All of core’s inner workings adhere to a predictable,
restricted coding style. Information is always communi-
cated through parameters and result values. Error prop-
agation is achieved exclusively through results, without
the use of exceptions. We explicitly encode errors dis-
tinct from successful results, instead of overloading the
result’s domain to mean error in some parts of its range.
The type checker veriﬁes both that each code path is
dealing with exactly one possibility, and – through the
exhaustiveness checker – that both forms have been ac-
counted for. The repetitive logic of testing for error re-
sults and deciding whether to propagate the error or pro-
ceed is then abstracted away in a few higher-order func-
tions and does not re-appear throughout the code.
This approach has also proven convenient when main-
taining a growing code-base: when we had to add sig-
niﬁcant new capabilities, e.g. extending the TLS version
support to versions 1.1 and 1.2 or implementing client
authentication, the scope of changes was localised and
the effects they had on other modules were ﬂagged by
the type checker.
4.2 Nocrypto
TLS cryptography is provided by Nocrypto, a separate
library we developed for that purpose.
It supports ba-
sic modular public-key primitives like RSA, DSA and
DH; the two most commonly used symmetric block ci-
phers, AES and 3DES; the most important hash func-
tions, MD5, SHA and the SHA2 family; and an imple-
mentation of the cryptographically strong pseudorandom
number generator, Fortuna [20].
One of the fundamental design decisions was to use
block-level symmetric encryption and hash cores written
in C. For hashing, DES, and the portable version of AES,
we use widely available public domain code. In addition,
we wrote our own AES core using the Intel AES-NI in-
structions.
There are two reasons for using C at this level. Firstly,
symmetric encryption and hashing are the most CPU-
USENIX Association  
24th USENIX Security Symposium  229
7
intensive operations in TLS. Therefore, performance
concerns motivate the use of C. Secondly, the security
impact of writing cryptography in a garbage-collected
environment is unclear. Performing computations over
secret material in this context is a potential attack vector.
The garbage collector pauses might act as an ampliﬁer to
any existing timing side-channel leaks, revealing infor-
mation about the allocation rate. We side-step this issue
by leaving the secret material used by symmetric encryp-
tion opaque to the OCaml runtime.
Such treatment creates a potential safety problem in
turn: even if we manage to prevent certain classes of bugs
in OCaml, they could occur in our C code. Our strategy
to contain this is to restrict the scope of C code: we em-
ploy simple control ﬂow and never manage memory in
the C layer. C functions receive pre-allocated buffers,
tracked by the runtime, and write their results there. The
most complex control ﬂow in these are driving loops that
call the compression function (in the case of hashes), or
the block transform (in the case of ciphers), over the con-
tents of the input buffer. AES-NI instructions are partic-
ularly simplifying in this respect, as the code consists of
a sequence of calls to compiler intrinsics.
Presently, only the AES-NI implementation of AES
is protected from timing side-channel leaks, since the
bulk of the cipher is implemented via constant-time ded-
icated instructions. The generic code path is yet to be
augmented with code to pre-load substitution tables in a
non-data-dependent manner.
More complex cryptographic constructions, like ci-
pher modes (CBC, CTR, GCM and CCM) and HMAC
are implemented in OCaml on top of C-level primitives.
We beneﬁt from OCaml’s safety and expressive power in
these more complex parts of the code, but at the same
time preserve the property that secret material is not di-
rectly exposed to the managed runtime.
Public key cryptography is treated differently. It is not
block-oriented and is not easily expressed in straight-
line code, while the numeric operations it relies on are
less amenable to C-level optimisation. At the same time,
there are known techniques for mitigating timing leaks
at the algorithmic level [28], unlike in the symmetric
case. We therefore implement these directly in OCaml
using GMP as our bignum backend and employ the stan-
dard blinding countermeasures to compensate for poten-
tial sources of timing side-channels.
Our Fortuna CSPRNG uses AES-CTR with a self-
rekeying regime and a system of entropy accumulators.
Instead of entropy estimation, it employs exponential
lagging of accumulators, a scheme that has been shown
to asymptotically optimally recover from state compro-
mise under a constant input of entropy of unknown qual-
ity [17]. To retain purity of the system and facilitate de-
terministic runs, entropy itself is required from the sys-
tem as an external service, as shown later in §6.
For the sake of reducing complexity in the upper lay-
ers, the API of Nocrypto is concise and retains the ap-
plicative style, mapping inputs to outputs. We did make
two concessions to further simplify it: ﬁrst, we use
OCaml exceptions to signal programming errors of ap-
plying cyptographic operations to malformed input (such
as buffers which are not a multiple of the block size in
CBC mode, or the use of RSA keys unsuitably small for
a message). Secondly, we employ a global and changing
RNG state, because operations involving it are pervasive
throughout interactions with the library and the style of
explicit passing would complicate the dependent code.
4.3 X.509
X.509 certiﬁcates are rich tree-like data structures whose
semantics changes with the presence of several optional
extensions. Although the core of the path-validation pro-
cess is checking of the signature, a cryptographic oper-
ation, the correct validation required by the standard in-
cludes extensive checking of the entire data structure.
For example, each extension must be present at most
once,
the key usage extension can further constrain
which exact operations a certiﬁcate is authorised for, and
a certiﬁcate can specify the maximal chain length which
is allowed to follow. There are several ways in which a
certiﬁcate can express its own identity and the identity of
its signing certiﬁcate. After parsing, a correct validation
procedure must take all these possibilities into account.
The ground encoding of certiﬁcates again beneﬁts
from algebraic data types, as the control ﬂow of func-
tions that navigate this structure is directed by the type-
checker. On a level above, we separate the validation
process into a series of functions computing individual
predicates, such as the certiﬁcate being self-signed, its
validity period matching the provided time or confor-
mance of the present extensions to the certiﬁcate ver-
sion. The conjunction of these is clearly grouped into
single top-level functions validating certiﬁcates in differ-
ent roles, which describe the high-level constraints we
impose upon the certiﬁcates. The entire validation logic
amounts to 314 lines of easily reviewable code.
This is in contrast to 7 000 lines of text in the RFC [9],
which go into detail to explain extensions – such as poli-
cies and name constraints – that are rarely seen in the
wild. For the typical HTTPS setting, the RFC fails to
clarify how to search for a trust anchor, and assumes in-
stead the presence of exactly one. Due to cross sign-
ing there can be multiple chains with different properties
which are not covered by the RFC.
nqsb-TLS initially strictly followed the RFC, but was
not able to validate many HTTPS endpoints on the In-
ternet.
It currently follows the RFC augmented with
230  24th USENIX Security Symposium 
USENIX Association
8
Mozilla’s guidelines and provides a self-contained con-
densation of these which can be used to clarify, or even
supplant, the speciﬁcation. We created an extensive test
suite with full code coverage, the code has been evalu-
ated (see §7.2) with the Frankencert tool, and it success-
fully parses most of ZMap’s certiﬁcate repositories. In
addition, we also support signing and serialising to PEM.
The interface to this logic is deterministic (it is made
so by requiring the current time as an input). Our X.509
library provides operations to construct a full authenti-
cator, by combining the validation logic with the current
time at the moment of construction, which the TLS core
can be parametrised with. We do not leave validation to
the user of the library, unlike other TLS libraries [23].
Instead, we have full implementations of path validation
with name checking [42] and ﬁngerprint-based valida-
tion, and we use the type system to force the user to in-
stantiate one of them and provide it to the TLS layer.
4.4 ASN.1