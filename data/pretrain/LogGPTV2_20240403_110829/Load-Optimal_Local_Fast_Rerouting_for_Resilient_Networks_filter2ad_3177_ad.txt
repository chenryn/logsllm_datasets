such a failure is hence only possible if the preﬁx of the reusing
n long. The multiple reuse of the second
rows is at least
type of failure has the same implication. Thus at least half
of the failures affecting the preﬁxes used are unique. In other
n elements of the rows can
words, the failures for the ﬁrst
n)
only be reused at most once and thus φ · √
n/2 = Ω(φ · √
√
√
failures are necessary.
F. Arbitrary Trafﬁc Patterns
With these solutions in mind, we are now ready to present
our main contribution: a resilient failover routing scheme for
arbitrary trafﬁc patterns (for n ﬂows), i.e., the ﬂows are not
restricted to share the same destination nor do we limit the
number of ﬂows with the same source.
Given a list of ﬂows, let δo(v) and δi(v) count the number
of ﬂows originating from v and destined to v respectively. The
maximum values of these quantities is denoted by δo
and δi
.
If we consider the directed multigraph induced by the list of
and δi
ﬂows, δo
correspond to the out-degree and in-degree
of this multigraph.
Using these deﬁnition, we show a general lower bound of
failures necessary for arbitrary ﬂow sets.
Theorem 6. Given a BIBD-failover matrix M , Ω(φ2) link
√
failures are necessary to generate a failover load of φ  φ/2 we could encounter a scenario
where φ/2 ﬂows with source w contribute to the highest load
on (w, u). Since we only consider the load caused by failover,
the destination of these ﬂows cannot be u, as in this case the
ﬂows would not contribute to the worst case load. Therefore
we can focus on the link failures necessary to reach u in the
affected rows. In this case, the preﬁxes of u are of interest and
using the same argument as above, the number of link failures
can be lower bounded by Ω(φ2) as well in this case.
When we have a bound on δo
and δi
for a ﬂow set, we can
prove an even higher bound.
Theorem 7. Given a BIBD-failover matrix M , Ω((φ − δo −
δi) · √
√
n + φ2) link failures are necessary to generate a load
of φ <
n .
Proof. Similarly to the proof before, we ﬁrst consider the case
where δi
is one, i.e., there is at most one ﬂow destined to
each node. Let link (w, u) be the link where the maximum
load manifests. Thus there are φ− 1 rows (set T ) in the BIBD
failover matrix M with a link failure for each element of the
preﬁx of u in those rows (there can be one row where u is the
target and does not need to appear in the preﬁx of elements
link failures).
√
We now lower bound the size of the set F of these link
failures. To contribute to the load, either i) w must appear in
the preﬁx of u on at least φ − 1 − δo
rows of T or ii) w
must be the source of the ﬂow of the remaining at most δo
nodes. Let us consider i) ﬁrst. w and u can only appear in
one BIBD-block together, thus there are φ − 2 − δo
rows in T
where only w can appear in the ﬁrst
n elements of the rows.
The arguments of the proof for Thm. 6 apply here as well
and thus at least (φ− 2− δo)
n link failures are accumulated
n length preﬁxes of T . In Case ii) where w is the
for the
source of ﬂows, only u needs to be in the preﬁxes, contributing
to lower bound of Ω(φ2). Thus the necessary failure set size
of both cases together is Ω((φ − δo)
n + φ2). For ﬂow sets
where up to δi
ﬂows share a destination, the number of rows
where w and u must in be in the preﬁx of failures is further
reduced, concluding the proof.
√
√
√
Our approach can be extended for more than n ﬂows,
parametrized by the number of failures to be tolerated. In
this case, the following construction can be used. Given a
(q2 + q + 1, q + 1, 1)-BIBD for q = n1/2 we can construct a
(23/2 log n−log k, k, 1)- BIBD. With this BIBD the number of
failures to be tolerated for O(n3/2) is in the order of log2 n,
resulting in an overhead load in the order of log n.
352
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:05 UTC from IEEE Xplore.  Restrictions apply. 
√
Corollary 1. Given λn ﬂows, it holds that Ω(φ2) link failures
are necessary to generate an overhead load of kφ < k
n. If
λ ∈ O(
n), it holds that Ω(φ2) link failures are necessary to
generate an overhead load of φ < log n.
√
V. SIMULATIONS
We complement our formal analysis with a simulation
study. In particular, in this section we shed light on the load
distribution in different failure scenarios and under different
alternative routing schemes.
A. Random Failures
Improved load compared to state-of-the-art. We ﬁrst investi-
gate random failures, to model more “average case” rather than
worst-case failures. Figure 5.a) shows the maximum link load
(across all links, depicting the average, the maximum and the
minimum over 100 runs, for a 183-node networks3) for all-to-
one routing as a function of the number of failures. Clearly, even
in the presence of a large number of concurrent failures, using
our approach, the max load is low. More precisely, failover
sequences with BIBDs incur a maximum load of less than
6 on average, even if almost 2/3 of the links failed. Even
though operating beyond the n− 1 tolerated failures studied in
Theorem 1, our scheme performs well under random failures.
For comparison, especially for large failure sets, the stochastic
failover scheme based on random permutations proposed in [3]
(indicated as “OPODIS” in the ﬁgures) does not perform as
well as the failover scheme based on BIBDs. In addition,
our approach has the advantage of providing deterministic
guarantees, and not just probabilistic ones.
Figure 5.b) shows the corresponding results for permutation
routing. Under permutation routing, the load is much lower.
The power of oblivious routing and remark on destination-
based routing. Next, we investigate to what extent our
approach beneﬁts from the high path diversity offered by the
oblivious BIBD routing policy, where (failover) paths can
be arbitrary (and not only destination-based). Nevertheless,
for comparison, we consider destination-based routing (as
it commonly used in legacy IP-networks): destination-based
routing schemes are conﬂuent, i.e., once two ﬂows toward the
same destination intersect, they will use the same remaining
path (the sufﬁx). Observe that in order to implement destination-
based routing, we need to set all rows in the failover matrix
to the same permutation for all-to-one routing. As can be seen
in Figure 5.c), if routing is restricted to be destination-based
(referred to as “DEST” in the ﬁgure), the resulting link load
is signiﬁcantly higher in the all-to-one scenario (note that the
experiment is only interesting in this scenario, as destinations
under permutation routing differ). Accordingly, we conclude
that the higher path diversity offered by destination and source
based routing is vital for a resource efﬁcient failover.
3We perform our analysis on a network of 183 nodes, since there exists
a (183,14,1)-BIBD which ﬁts perfectly for this size. As discussed in the
paper, any network size can be supported, but the construction becomes more
cumbersome and a simulation on 150 or 200 nodes does not reveal more
information than on 183 nodes.
B. Targeted Failures
We now turn our attention to scenarios with adversarial
failures. Indeed, we believe that the key strength of our
approach lies in such more challenging failure scenarios. We
consider an adversary that targets a particular node v and
fails |F| random links incident to this node v. In other words,
the adversary speciﬁcally targets the links of one node. For
all-to-one routing, the chosen node is the destination node vn,
for permutation routing any node can be picked.
Note that all rows of the BIBD failover matrices offer the
same properties due to the fact that they are generated from
symmetric BIBDs and form a latin square. As shown in [3],
the maximum load is generated by failing links incident to vn
for all-to-one routing.
Improved load for all-to-one and permutation routing.
Figure 5.d) plots the maximum load observed on any link
as a function of the number of failures up to n/24. Unlike in
the random failure experiments discussed above, we now see
that the load grows more quickly with an increasing number
of failures. Indeed, the results are reminiscent of the formal
worst-case analysis presented in the previous section.
When the failover matrix is constructed with random
permutations per row, the number of failures necessary to
generate a maximum load of φ is in Ω(φ2/ log n) [3]. The
deterministic BIBD failover matrix outperforms the random
permutation matrix by around 20%. Under permutation routing
the load is lower and BIBD achieves a more balanced link
load than the randomized approach from [3].
VI. RELATED WORK
There exist several empirical studies showing that link
failures, even simultaneous ones, do occur in different net-
works [19], [27], including wide-area [14] and data center
networks [12]. For example, it has been reported that in a wide
area network, a link fails every 30 minutes on average [16].
Commercial networks today usually rely on routing schemes
such as OSPF, IS-IS, and MPLS reroute trafﬁc, which however
do not come with formal guarantees under multiple failures.
Accordingly, backbone networks are usually largely over-
provisioned.
Existing resilient routing mechanisms can be classiﬁed
according to whether a single link/node failure [9], [20], [31],
[32] or multiple ones can be tolerated [8]. Alternatively, they
can be classiﬁed into static and dynamic ones. Dynamic tables
and using link reversals [11] can yield very resilient networks,
but dynamic tables are not supported in OpenFlow switches
today. Finally, one can also classify existing mechanisms as
basic routing schemes [4], schemes exploiting packet-header
rewriting, and routing with packet-duplication [13]. While
packet-header rewriting can improve resiliency, it can be
problematic in practice, especially under multiple failures, as
header space (and rule space) is limited. We in this paper hence
do not use header rewriting.
4 For a number of failure in O(n) the load will be in the order of
(n)
for targeted failures in the all-to-one case, therefore higher failure numbers
are not interesting
(cid:2)
353
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:05 UTC from IEEE Xplore.  Restrictions apply. 
●
method
● OPODIS
BIBD
●
●
●
●
●
●
●
●
●
i
k
n
L
a
n
o
d
a
o
L
m
u
m
x
a
M
i
●
●
●
Method
● OPODIS
BIBD
●
●
●
●
●
●
●
●
2.5
2.0
1.5
1.0
0.5
0.0
100
|F|
1000
10000
10
100
|F|
1000
10000
i
k
n
L
a
n
o
d
a
o