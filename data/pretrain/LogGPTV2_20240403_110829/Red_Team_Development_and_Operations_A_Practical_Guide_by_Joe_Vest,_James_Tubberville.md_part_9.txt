forces a Red Team to be highly diverse. They must have the ability to emulate highly advanced threats
and to limit themselves to a simple threat. Remember, Tradecraft and TTPs are core to a Red Team.
Weak Tradecraft equals a weak Red Team. A Red Team must be highly capable in order to
successfully emulate a threat with the fidelity needed to accomplish their goals as a threat.
General Guidance
Maintaining consistent TTPs is essential during Red Team engagements. Getting caught or stimulating
an effect at the wrong time in the engagement can compromise an entire mission. Guidance on TTPs
"do's and don'ts" for Red Team engagements are included below. These rules must always be applied
to the first set of operating procedures. This ruleset is a great starting point for developing high-level
TTPs.
If circumstances require a deviation, or a rule does not fit an engagement, a consultation with a senior
Red Team Operator is required. Anytime a TTP rule is violated, senior staff should be involved in the
decision and the reason and circumstances documented.
Log all significant actions (successes and failures)
Bottom line up front: Log, log, and log some more! Take screenshots of all significant actions,
including successful and failed attempts.
One of the most important aspects of the Red Team engagement is the collection of data (a.k.a. logs).
It is extremely common that an inexperienced team completes an engagement with subpar
documentation. Many actions are not fully captured, some actions are never captured, and often key
failures are ignored. Each action performed provides value to the target as well as the target
defenders. Incomplete logs prevent the Red Team from providing a complete and accurate depiction
of the actions, obstacles, and defensive strengths and weaknesses of the target (a.k.a. Red Team
mission failure).
As previously covered, there are several methods to ensure that logs are appropriately captured and
stored:
● Automated logging of the terminal: All terminal actions are logged, timestamped, and saved
to a predefined location
● Tool logs: Most commercial tools have some capability to log actions and produce a raw or
a final report
● Custom tools logs: If you write a custom tool/script, it should output a log of actions and
results
● Operator logs: By far, these are the most important logs. A log may show the action
performed and the result; however, only the operator can accurately note the way the action
was performed, which led them to the decision, and their interpretation of the result
● Screenshots: Terminal logs are great for the operator and even better as supporting artifacts;
however, they may mean nothing to senior-level executives (or even to some IT
professionals). Screenshots before, during, and following the execution of an action hold
much more weight than a terminal log, tool log, or operator log (often, it may just be a
screenshot of the terminal during execution)
Consult with Peers
No matter how long you have been performing IT or security, consult your peers before taking action.
This is especially true during exploitation and Command and Control setup. Simple mistakes often
lead to Red Team discovery too early in the engagement. Look at the command below. The command
could be run as to provide general situational awareness on a Linux system. What is the expected
output of the following command?
netstat –antb
The command above is a netstat command that can be executed on a Windows host. Linux does not
have the "b" option and produces an " invalid option " response. Think about it:
Have you ever typed ifconfig instead of ipconfig ?
Have you ever typed rm * in the wrong directory?
Have you ever entered credentials only to discover they were "fat fingered" (after an access error)?
While these are oversimplifications, they represent the need for peer review on tools, C2, setup,
execution, and even cleanup. Mistakes can lead to accidental exposure on a Red Team engagement.
This can cause significant setbacks and reduce the quality of an engagement.
Understand the Tools and Technologies Used
Knowing what functionality a tool provides is only one-third of the equation. Before a new tool
(script, application, binary, process, etc.) is used on a target system, it must be tested, undergo an
internal vetting process and be added to an official toolset.
So how do we complete the equation? By asking:
● What artifacts does the tool leave behind?
● Are any files modified during execution?
● Are there tales in the network traffic?
● Does the tool have negative impacts on specific versions of an OS? (It works fine on
Windows 8 but causes a system error on Windows 10)
● Does the tool attempt to run as a specific user or, worse, create a user/group?
● Does the tool try to call home for updates?
○ This can trigger defensive alerts identifying unauthorized persons or software on
the network
Think about psexec.. What is it? The most common answer refers to the PsExec.exe tool from
SysInternals[13].
What does it do? At a high level, it executes commands on local or remote Windows system.
What does it do in terms of indicators?
● Copies a service file to the remote system
● Enters a service key into the Registry
● Creates a prefetch file
● Creates an entry in the Application Compatibility Cache
● Creates a login event
● Creates a profile folder for the remote user
● Attempts to remove the service file and key when exiting (not always successful)
What happens when using the –e option? –s option?
How does this differ from psexec for PowerShell?
In short, you must understand how tools or technique interacts with a target, what network traffic it
may generate, and what traces it may leave behind. In the case of psexec, this can be considered a
lateral movement technique instead of a specific tool. There are multiple methods of achieving the
result PsExec.exe provide without the tool itself.
Perform Situational Awareness
After gaining access to a remote system or application, perform situational awareness before moving
on.
● Understand the environment you are in. (Is the target in scope?)
● What protections exist on the system or network?
● What are the risks of being caught, and what attack paths does the system provide?
● Are there pre-established connections to other network resources?
● Who is currently logged into the system?
● Who has recently logged into the system?
Minimize callback (C2) volume
Unless a host-based protection mechanism is triggered, it is more likely to be discovered or caught by
a defender's recognition or analysis of traffic on the network. To avoid early detection follow good
tradecraft procedure to limit and control the amount of traffic generated during an engagement. There
are several general concepts that, if followed, increase the success of the engagement while
decreasing the chances of being discovered:
● Keep traffic internal to a network: One of the most common issues, and one you should
always attempt to change, is the limited number of sensors inside a network. Most network
protections are currently applied at the boundary.
● Pivot Command and Control traffic to a minimal number of outbound sources: Maintain at
least two outbound sources for C2 redundancy; however, use only one for operations
(considered an interactive tier). The second (a long- or short-haul tier) is dormant or
extremely slow and used as a backup if/when the primary is discovered.
Do not use unencrypted channels for C2 (unless blending into
network traffic)
Command and Control data exiting the network must be encrypted. An IDS or other network defense
will detect cleartext data, such as uploading a binary, issuing an operating system command, or using
a web shell. It has become common for IPSs/IDSs to detect specific strings discovered in cleartext
traffic. For example, "C:\Windows\System32" has become a common trigger for investigation.
Some defenders have even gone the extra mile in legitimizing a potential threat. Assume the defenders
or IT staff uses a remote administration tool regularly. Ignoring recommendations, this traffic is
unencrypted. Rather than causing an alert each time the tool is used legitimately; the alert is
configured to look for inconsistencies in the usage. For example, most attackers are accustomed to
typing lowercase commands in Windows. The defender ignores "C:\Windows\System32" but alerts on
"c:\windows\system32"
Internal encryption is another example of where peers should be consulted to determine the best
course of action before deploying C2 further into a network.
The encryption of internal C2 traffic depends upon several different factors:
Are there sensors inside the network?
Are there other encrypted communications occurring between target systems?
Would encrypted traffic stand out more than unencrypted traffic?
Do not attempt to exploit or attack unencrypted websites or
applications
As tempting as it may be, do not attack unencrypted websites. Simple attacks can trigger IDSs.
Always know your target IP space. There are likely several websites available for review. Proper
reconnaissance or coordination should have discovered each. Create a list of sites in your target log.
Include IP addresses, URLs, an educated guess at the functions, ports, protocols, etc.
Focus Point
Prior to performing any exploitation and attacks against a
web server, refer to your Rules of Engagement and fully
understand:
Who actually owns the website?
Who owns the system where the website is
hosted?
Who owns the back-end application?
Have proper approvals been obtained for
testing?
Do not execute from non-executable locations
● Execution in a Windows environment must occur in a location typical of Windows
● Executable locations such as c:\programdata, c:\progam files, and c:\windows\ are common
● Execution from locations such as c:\windows\temp should never occur or be used with an
understanding of risk
Do not use binaries for initial capabilities
As a general rule, do not drop binaries on the system. First, use built-in commands to achieve your
goals. This is not always possible, and binaries may be required; however, binaries must be vetted,
obfuscated, and tested against detection before use.
● Ensure all other “Do's and Don’ts" are met for all binaries
● Consult a senior operator before dropping any binary
Do not download restricted datasets
NEVER download (or remove from the target network) any PII, HIPAA, PCI, or other restricted
datasets. A good rule of thumb is to annotate the type of data, location, access method, and level of
access to restricted data in the log.
● Ensure the log notes include a reference to the type of data discovered for quick reference
● Take a screenshot of the displayed filename and location (assuming the filename has no
restricted data included)
● Screenshot a portion of the dataset without capturing the restricted data. The operator may
do so for proof of access.
● If the data set is of concern, attempt to copy the file to a new name in the same location. This
will validate access without exposing the data.
● DO NOT take screenshots of the data itself!
Execution Concepts
Exploits
Exploitation is a technique a threat uses to take advantage of a vulnerability or weakness. This can be
due to a software flaw or misconfiguration. Unlike penetration testing, where validating exploits
against a vulnerability is a primary goal, exploitation is not an end goal for Red Team engagements.
Exploits are merely a means to an end; however, this does not reduce their importance. Exploitation
can be a critical part of a Red Team engagement. Exploitation must be used with caution as many
often trigger a Blue response. As with all decisions made during a Red Team engagement, risk vs.
reward must be measured to determine if the access gained from an exploit is worth the potential
exposure.
Exploits should be used to gain access only as a means to an end. Once exploitation occurs,
backdoors or other means of access should be established. The exploit should not be used as a means
to regain access to a target. For instance, assume a known remote code execution flaw exists in a web
application. A readily available public exploit exists, and using such an exploit may trigger a security
device, like an IDS. A Red Team weighs the risk and decides to move forward with the exploit. A
Red Team operator successfully uses the exploit from a burnable IP space. The exploit results in
remote command execution of the target webserver. Instead of using the exploit repeatedly to issue
commands, a web shell is deployed. This web shell can now be accessed from a different source
address. In this way, the exploit is used only one time. The web shell provides a useable backdoor to
access the webserver for further actions.
Exploiting Known Vulnerabilities
A threat will use what is available. Like real attackers, Red Teams will take advantage of a weakness
to support their goals. There is a key difference in how a Red Team should view and use an exploit
vs. other types of security testing. In Red Teaming, known (including pre-packaged or “canned”)
exploits should only be used to directly support a goal. This means an environment may have multiple
exploitable vulnerabilities that a Red Team does not exploit. This could be due to minimizing
detection or the fact that exploitation does not support a Red Team goal. It is important to remember
that a Red Team engagement is not a comprehensive view of a target's vulnerabilities.
In summary, many exploits have known signatures and can be easily detected or have code that causes
unintended damage or impacts to a target. A Red Team Operator should always understand the
exploit, its code, and know its IOCs to manage the risk of exposure or damage to a target.
Popular places to find exploits:
● Metasploit: www.metasploit.com – public exploits and zero days
● ExploitHub: www.exploithub.com – commercial exploit clearinghouse for nonzero days
● Exploit DB: www.exploit-db.com – repository of exploits maintained by Offensive Security
● Other exploit clearing houses
Focus Point
A target environment may have multiple exploitable
vulnerabilities. Only those that enable meeting the goals
and objectives of the engagement should be considered for
exploitation. Document all identified exploitable
vulnerabilities but use only those required to achieve
engagement objectives.
Always consider the risk in every action taken.
Exploitation without Exploits
Exploitation does not always require exploit based on code flaws. Experienced penetration testers
and Red Teamers will use the concept of Exploitation without Exploits. This is the idea of exploiting
or compromising a system by using the system design, functions, and configuration against itself. Poor
security controls and misconfigurations will often lead to compromise. Not only can using a system
against itself support a compromise, it usually involves a smaller IOC footprint. In many cases,
attacking a system without exploits looks very similar to the same activity performed by a network
administrator.
There are several techniques a threat can use to exploit, compromise, or gain access to a target
system. Do not fall into the trap of canned exploits being needed to achieve goals. Exploits can be
rare, costly, and ephemeral. When they work, they are great, but most exploits have a short lifetime.
Good Red Team Operators regularly explore and practice many means of remote exploitation or
compromise. This is an ever-changing area of security. Research and practice are needed to keep
current on modern techniques.
Web Application Vulnerability
Security has increased over the years, and the number of traditional memory corruption exploits has
dropped significantly. This has driven threats to search for alternate means of gaining access to a
target. Web applications are excellent targets for exploitation and remote code execution. Although
web applications have been around for years, their security is still quite weak and misunderstood.
This makes web applications prime doorways into a network as even the most basic application can
provide a backdoor to a threat. In short, web applications are one of the most effective ways to gain
remote access to an environment.
Security Misconfigurations
Security has improved over the years, and the number of traditional memory corruption exploits has
dropped significantly. This has driven threats to search for alternate means of gaining access to a
target. Web applications are excellent targets for exploitation and remote code execution. Although
web applications have been around for years, their security defenses are still quite weak and
misunderstood. This misunderstanding makes web applications prime doorways into a network as
even the most basic application can provide a backdoor to a threat. In short, web applications can be
one of the most effective ways to gain remote access to an environment.
Misconfigured network security rules often provide multiple paths for threat traversal. When systems
can communicate freely in a network, they can quickly exchange information. This includes a threat's
traffic. It is prevalent for an organization to configure externally facing traffic rules and leave internal
network communications wide open. It is also common for credentials to be stored in cleartext in
publicly available locations on a network. These credentials may be user or administrative. Either
way, when threats use valid credentials, they look and feel like insiders. It can be very difficult for a
Blue Team to distinguish between a threat and a valid user. These are important measurements of
security operations capability.
Poor or Lack of Security Monitoring
A lack of security monitoring allows a threat to use a more extensive toolset. Tools or techniques that
may be loud or trigger a response may work just fine in an unmonitored environment. This oversight
provides a threat with much greater flexibility and capability. A Red Team can take advantage of an
unmonitored network. A common operational impact is data exfiltration. Perhaps a target organization
has propriety sensitive intellectual property. Exposures of this information could significantly harm
the organization. A Red Team can test the ability a threat has to gain access and exfiltrate the data. A
lack of monitoring may allow the threat to access and steal the data without being noticed. Blue
Teams that have a weak security monitoring process will not identify malicious traffic or changes
made by a threat. Defensive tools are great but must be configured and tested to ensure they are
operating as expected. Remember, the primary role of the Red Team is to facilitate the improvement
of an organization's defensive posture.
Social Engineering (SE)
Social engineering is exploiting weaknesses in human nature. Red Team engagements often rely on
social engineering to support goals. This is typically used in the following areas:
Phishing
● Sending an email to entice an end-user to provide sensitive information or to deliver a payload
● Can be used to deliver a malicious payload
● Can be used to facilitate in-person SE
● Can be used to facilitate physical access
Telephoning/Texting
● Calling or texting to entice an end-user to provide sensitive information
● Can be used to facilitate either phishing or in-person SE
● Can be used to facilitate physical access
In-person pretexting
● In-person social engineering is typically used to support a physical breach
Use Caution
Social engineering (especially Phishing) works, period. But, this is not always the best option. There
are political risks associated with SE a user. For example, Phishing campaigns that work well may
harass or even embarrass end users. Use caution when creating a phishing campaign. Many targets of
phishing require the campaign to be approved before the emails are sent. This may protect the
organization but can also limit the success rate of a phish. In cases where phishing is risky, consider
white carding. A solid strategy is to send a phishing email to a trusted insider. That person will click
links or provide information as directed by the phish. This allows a phishing payload to be delivered
in a politically safe manner while allowing the phishing email to touch all the security defenses. This
model uses the assumption that a user will succumb to a phishing attack. The challenge for the Red
Team is to bypass the security protections designed to protect users from themselves.
A phish that leads to the compromise of a single system may be acceptable. A phish that leads to the
compromise of an organization is not acceptable as multiple failures must have occurred in