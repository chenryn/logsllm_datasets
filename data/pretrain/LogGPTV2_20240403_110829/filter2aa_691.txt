# Face Swapping Video Detection with CNN

**Authors:**
- Wang Yang
- Junfeng Xiong
- Liu Yan
- Hao Xin
- Wei Tao

**Affiliation:**
- Baidu X-Lab

## Abstract
This paper presents a method for detecting face-swapped videos using a simple and effective Convolutional Neural Network (CNN). The approach leverages both low-level and high-level features to distinguish between real and deepfake videos. Additionally, we explore the use of a FaceNet-based Support Vector Machine (SVM) classifier for improved detection accuracy.

## Deepfakes Video
Deepfakes are synthetic media in which a person's face is replaced with another's, often used to create misleading or fraudulent content. 

### Vulnerability of Face Recognition Systems
Face recognition systems can be vulnerable to deepfakes. For example:
- **Microsoft Azure**: 
  - Real vs. Fake: 86.0% similarity
  - Real vs. Fake: 70.5% similarity
- **Amazon AWS**:
  - Real vs. Fake: 95.1% similarity
  - Real vs. Fake: 87.3% similarity

## Face Swapping Video Generation
### Characteristics
- **Frame-by-Frame Manipulation**: Each frame is processed independently.
- **Non-End-to-End Process**: Only the central face area is manipulated.
- **Autoencoder**: Uses an encoder-decoder architecture to swap faces.
  - **Training Phase**: Person A's encoder and Person B's decoder.
  - **Generation Phase**: Gaussian blur, color averaging, and Poisson image editing are used to merge the swapped face back into the original image.

## Face Swapping Video Detection with CNN
### Methodology
- **Deepfakes Video Detection**: We propose a simple and effective CNN that captures low-level features of images.
- **Face Recognition Based Method**: This method captures high-level features of faces.

### A Simple and Effective CNN
#### Design Purpose
- **Input**: Includes background information.
- **Feature Extraction**: Captures low-level features such as contours and edges.

#### Training
- **Dataset**: VidTIMIT
  - 67,600 fake faces and 66,629 real faces
  - Low and high-quality images
- **Data Preprocessing**:
  - Cropped faces using MTCNN with a 1.5x scaled bounding box
  - Data augmentation: horizontal flipping, random zooming, and shearing transformations

#### Characteristics
- **Architecture**: 3 convolution layers
- **Accuracy**: 99%

### FaceNet-Based SVM Classifier
#### What is FaceNet?
- **State-of-the-Art (SOTA) CNN for Face Recognition**
- **Model Structure**: Triple Loss

#### Training
- **Input**: Central face area only (no background)
- **Dataset**: VidTIMIT

#### Characteristics
- **Feature Extraction**: FaceNet extracts face features
- **Classification**: SVM for binary classification
- **Accuracy**: 94%

## Summary
- **CNN for Image Classification**:
  - A simple architecture can achieve high accuracy.
  - Captures low-level features like contours and edges.
- **FaceNet-Based SVM Classifier**:
  - Uses FaceNet to extract high-level face features.
  - SVM for binary classification.
  - Achieves 94% accuracy, with a 64% accuracy rate for misclassified sets from the simple CNN-based classifier.

## Conclusion
Thank you for your attention. We have demonstrated that a simple CNN can effectively detect deepfake videos by capturing low-level features, while a FaceNet-based SVM classifier can further improve detection accuracy by leveraging high-level features.

## Q&A
We welcome any questions or comments.