speciﬁcally in Section VII. The vote score distribution of these
attacks is largely disjoint of that seen in typical benign or
malicious observations. Using an ensemble classiﬁer diversity
based approach, the majority of these attacks can be separated
from benign observations. Hence,
these attacks should be
considered weak mimicry attempts.
When all attributes of the classiﬁer are known, 33% of the
attacks are effective. However, when either the details of the
classiﬁer or the training set are withheld, the attack success rate
drops to 10% or lower. In addition to evaluation against the
Contagio data set, the mimicry attack data was tested against
the classiﬁer trained with the University data set. This results
in an alternate FC attack scenario because the training set is
unknown to the attacker. Figure 8 shows the distribution of
scores from applying the malware from the FTC attack sce-
7
051015200255075100PDFrate Contagio Classifer ScoreDocument CountFig. 5. Score Distribution for FT Mimicry Attack
Fig. 8. Scores for FC Mimicry Attack Using University Classiﬁer
TABLE VIII.
PDFRATE OUTCOMES FOR REVERSE MIMICRY ATTACKS
Contagio Classiﬁer
Benign
Malicious
University Classiﬁer
Benign
Malicious
0
0
0
80
0
23
Scenario
EXEembed
PDFembed
JSinject
Scenario
EXEembed
PDFembed
JSinject
Uncertain
1
22
0
7
67
3
Uncertain
16
4
0
19
22
55
77
93
30
0
81
0
Fig. 6. Score Distribution for FC Mimicry Attack
Fig. 7. Score Distribution for FTC Mimicry Attack
nario against the Contagio classiﬁer to the University classiﬁer.
The results are very similar between the two classiﬁers. In
both cases, only 7 of the 100 evasion attempts are classiﬁed
as benign. Carefully comparing Figure 6 and Figure 8 yields
the observation that the University classiﬁer provides a tighter
cluster of scores near the center of the disagreement region.
The results from the Contagio classiﬁer are similar to that of
the University classiﬁer because the Mimicus evasion attempts
use Contagio data for both baseline benign and attack data.
8
When mutual agreement is utilized, the majority of mimi-
cus attacks are labeled as uncertain, indicating known classiﬁer
failure and possible evasion. In the best mimicry attack sce-
nario, where all attributes of PDFrate are known, only 33% of
the mimicry attempts are successfully classiﬁed as benign. If
some details of the classiﬁer, such as the exact training set,
are not known by the attacker, then the mimicry success rate
is below 10%.
C. Reverse Mimicry
We also applied mutual agreement analysis to the Reverse
Mimicry attack proposed by Maiorca et al. [26], [27]. The
exact procedures required to replicate these attacks are not
publicly documented. However, Maiorca et al. provided us with
the documents used in their studies. Their most recent attacks
involved 500 documents in each evasion scenario. To remain
consistent with the Mimicus attack evaluation, we took a 100
sample random subset of each scenario for our evaluation.
In Table VIII, we present the results of applying mutual
agreement analysis to the Reverse Mimicry attacks against both
the Contagio and University classiﬁers. The score distributions
for these attacks against the University classiﬁer are shown in
Figures 9, 10, and 11. In spite of mutual agreement analysis,
67% of the Reverse Mimicry attacks are successful evasions
(considered benign) against the Contagio classiﬁer.
The University classiﬁer fares much better than the Con-
tagio classiﬁer. The only evasions against the University clas-
siﬁer are achieved by the PDFembed attack. This attack is
so successful because a complete malicious PDF is embedded
051015200255075100PDFrate Contagio Classifer ScoreDocument Count051015200255075100PDFrate Contagio Classifer ScoreDocument Count051015200255075100PDFrate Contagio Classifer ScoreDocument Count051015200255075100PDFrate University Classifier ScoreDocument CountFig. 9. Score Distribution for EXEembed Attack
Fig. 10. Score Distribution for PDFembed Attack
in an otherwise benign document. This embedded document
resides in a compressed data stream, which means that the
structural features cannot be observed by PDFrate’s feature
extractor. This is in contrast to the other scenarios, EXEembed
and JSinject, where despite efforts at minimization, some
indicators of malfeasance remain exposed.
The PDFembed scenario is effective against the detector
at pdfrate.com because it does not perform recursive decoding
and analysis as would be necessary in an operational system.
This failure is similar to malware analysis systems that assume
an input of an unpacked executable and fail when presented
with a packed executable or a Trojan document. When PDFrate
is deployed in operational detection systems,
is usually
done within a framework that provides both decoding of
PDF streams and extraction of PDFs from other containers
such as emails or zip ﬁles [3]. In all the PDFembed attacks,
the embedded document was identical. The Contagio and
University classiﬁers both easily detect this document with
high conﬁdence once it is extracted, returning scores of 97.6%
and 100% respectively.
it
For the isolated PDFrate implementation, the PDFembed
scenario represents a strong evasion scenario, where classi-
ﬁer introspection provides little beneﬁt because the feature
extractor is evaded so well. Even though the Contagio based
9
Fig. 11. Score Distribution for JSinject Attack
classiﬁer is a poor ﬁt for the malware used in the EXEembed
and JSinject, many of these samples still fall in the uncertain
outcome vote range. When the stronger University classiﬁer is
used, mutual agreement analysis ﬂags these evasion scenarios
that would otherwise be successful.
D. Drebin
To apply mutual agreement analysis to the Drebin Android
malware detector, we constructed an ensemble classiﬁer. We
employed a Random Forest classiﬁer, which required adapting
the features to ensure computational efﬁciency and to ensure
results comparable to the original
linear SVM. Instead of
using all string values as features, we used a subset of 891
features that comprise the most durable features. We used
all of the features for constrained categories such as API
calls and permissions. For arbitrarily named attributes, such as
components and intents, we utilized the most proliﬁc values,
selecting those which occur over 100 times in the training set.
Lastly, we ignored speciﬁc values for highly volatile items such
as URLs and network addresses, which compose over half the
features used by Drebin. Lastly, we summed the occurrences
of each category of features and used these counts as features.
As an optimization, we de-duplicated any equivalent feature
vectors during classiﬁer training (not during evaluation). This
de-duplication, using our narrow feature set, resulted in a
reduction from 123,453 to 63,379 unique benign and 5,560 to
2,185 unique malicious samples. Barring these transformations
of data, we used the published Drebin data sets including data
set partitions in our evaluation.
We tuned our Random Forest based classiﬁer to provide
classiﬁcation performance comparable to the linear SVM clas-
siﬁer of Drebin. The primary item we tuned was the ratio
of benign to malicious samples used in training each tree.
This was necessary because there is an extreme imbalance in
the benign to malicious ratio of the various training sets. We
tuned the ratio for individual tree training to 2.5 benign to 1
malicious in order to match the desired false positive rate of
1% chosen by Arp et al. We set the other tunable parameters
for Random Forest to standard values: each Random Forest
contained 1000 trees and the number of variables tried at each
split was set to the square root of the number of features. Our
Random Forest classiﬁer provided an average false positive
rate of 1.06% and a malware detection rate of 92.3% on
the published data set partitions using a traditional thresh-
old without an uncertain region. The Random Forest based
classiﬁer performance is very similar, albeit slightly inferior
to that provided by Drebin’s linear SVM. Figure 12 shows
051015200255075100PDFrate University Classifier ScoreDocument Count051015200255075100PDFrate University Classifier ScoreDocument Count0.02.55.07.510.012.50255075100PDFrate University Classifier ScoreDocument CountFig. 12. Score Distribution for Benign Samples
Fig. 14. Score Distribution for Unknown Family A
unknown malware. We applied our Random Forest based
classiﬁer and uncertain score region to this same problem.
Figure 15 compares the detection rates of the linear SVM
classiﬁer and our Random Forest based classiﬁer using mutual
agreement analysis.
As expected, the vast majority of unknown malware fam-
ilies have the score distribution of a weak evasion attack, in-
dicating that the classiﬁer considers these observations neither
similar to the benign or malicious samples seen in the training
set. As an example, the scores of malware family A are shown
in Figure 14. On average, 75.2% of every family is labeled
as uncertain and an additional 8.2% are labeled as malicious
using our Random Forest based classiﬁer, while 50.6% of
every family is labeled as malicious by the Drebin linear SVM.
Families Q and R represent strong evasion. Arp et al. note that
Family R cannot be reliably detected with the feature set used
by Drebin. While the features used by Drebin are sufﬁcient
for the detection of Family Q when included in the training
set, it is too different from other families in Drebin’s feature
space to be ﬂagged as an evasion. On the other hand, Family
P is so similar to other malware families in Drebin’s feature
space, that it is not necessary to have samples of this family in
the training set. Removing these 3 families, an average 89.7%
of the samples in the remaining 17 families are identiﬁed as
malicious or uncertain by the Random Forest classiﬁer, while
53.2% are detected by the linear SVM classiﬁer. It should be
considered advantageous to label these previously unknown
samples as uncertain so that the operator can take action to
improve the classiﬁer. While the linear SVM classiﬁer provides
the average classiﬁcation accuracy of a coin toss in these
scenarios, the mutual agreement conscious ensemble is able
to ﬂag the majority of the novel attacks as possible evasions.
Mutual agreement analysis is effective at identifying pos-
sible evasions in the PDFrate and Drebin malware detection
systems caused by both novel attacks and targeted mimicries.
VI. MUTUAL AGREEMENT THRESHOLD TUNING
For most of our evaluations, we used a 50% mutual
agreement threshold, which splits the classiﬁer voting score
region into four equal sized quadrants. It is possible to choose
an arbitrary mutual agreement threshold. Table IX contains
Drebin predictions for three mutual agreement threshold levels.
Fig. 13. Score Distribution for Malicious Samples
TABLE IX.
DREBIN RANDOM FOREST CLASSIFIER OUTCOMES AS
MUTUAL AGREEMENT THRESHOLD IS ADJUSTED
Benign Samples
Benign (%)
Malicious (%)
Uncertain
Mutual Agreement Threshold (%)
30
40
50
97.46
96.49
95.12
1.49
2.45
3.82
0.54
0.63
0.71
0.52
0.43
0.35
Malicious Samples
30
40
50
4.44
3.77
3.16
3.27
3.93
4.56
5.44
7.30
10.34
86.85
84.99
81.95
the distribution of scores for the benign samples using one of
the published data set partitions. Figure 13 shows the same
for the malicious samples. As expected, the score distributions
are shaped similar to that of PDFrate, but since the classiﬁer
accuracy is lower, the samples are distributed farther from the
respective ends of the score continuum. Table IX shows the
classiﬁer outcomes for typical mutual agreement thresholds.
An important facet of the original Drebin study is the
division of the malware by family and evaluation of the
classiﬁer on previously unknown malware families. This was
achieved by withholding the family to be evaluated from the
training set and then applying the resultant classiﬁer to the
malware samples in that family. It is noted by Arp et al. [4]
that Drebin provides relatively poor classiﬁcation of previously
10
05000100001500020000250000255075100Drebin Random Forests ScoreApplication Count01002003004005000255075100Drebin Random Forests ScoreApplication Count01002003000255075100Drebin Random Forests ScoreApplication CountFig. 15. Comparison of Detection Rate for Previously Unknown (excluded from training set) Malware Families
TABLE X.
PDFRATE UNIVERSITY CLASSIFIER PERFORMANCE AS
MUTUAL AGREEMENT THRESHOLD IS ADJUSTED
Benign Operational Evaluation
In Table X, we present
the PDFrate University classiﬁer
outcomes applied to the operational evaluation data set and the
FC Mimicus attacks across the full mutual agreement range.
The exact mutual agreement threshold chosen strikes a
balance between improvement in classiﬁcation failure detec-
tion and the number of classiﬁer predictions thrown out as
uncertain. Operators who wish to have a lower amount of
uncertain outcomes may choose a lower threshold. Taking the
PDFrate performance in Table X as an example, if 30% is se-
lected as a threshold, the uncertain region comprises ensemble
classiﬁer voting scores between 35% and 65% instead of 25%
and 75% with a 50% threshold. For the operational data set,
the uncertain rate for benign samples drops from 0.456% to
0.256%. However, the number of successful evasion attempts
rises from 7% to 12%. The optimal setting for this threshold
depends on the preferences of the operator. The sensitivity of
uncertain detection is adjusted by tuning the mutual agreement
threshold, setting the boundaries for the uncertain range.
VII. GD-KDE AND ENSEMBLE SVMS
Mutual agreement analysis should apply to all ensemble
classiﬁers that provide sufﬁcient diversity in individual classi-
ﬁers. To validate this, we studied the feasibility of countering
evasion against SVMs by applying mutual agreement analysis
to SVMs using an ensemble approach.
The Mimicus attack framework implements a Gradient
Descent and Kernel Density Estimation (GD-KDE) attack
against their PDFrate replica utilizing an SVM classiﬁer. This
attack operates by exploiting the known decision boundary of
a differentiable classiﬁer [8].
We reproduced the GD-KDE evasion attacks of Mimicus
and conﬁrm that they are indeed extremely effective. Using
the e1071 package of R [2], which relies on libSVM [10], we
calculated the average probability of 8.9% malicious (or 91.1%
benign) for both GD-KDE scenarios, putting these attacks
squarely within the evasion region. ˇSrndi´c and Laskov use the
11
Mutual
Agreement
Threshold
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
Threshold
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
Threshold
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
Uncertain
Score
Range
-
(45,55)