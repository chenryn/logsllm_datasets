Third, it’s an exceptionally flexible learning tool. An extracted keyboard controller can be quickly and easily
modified to respond to an array of inexpensive industrial sensors and switches, as well as custom concept switches
created by students. Simple input hardware—keyboards and mice—don’t require special software drivers or
computer ports, and they work with most computers and operating systems. Using standard hookup wire and simple
soldering tools, students can incorporate controllers, sensors, and switches into models built in wood, metal, plastic,
glass, textile, and other workshops. The models can then be connected to computer hardware via USB and can serve
as multi-sensory input devices for Digital Signal Processing (DSP) and other software applications.
We also relied on software sketching materials. Students used Macromedia Flash MX2004 and ActionScript to
capture data from input devices (keypresses and cursor coordinates), script for DSP, and author audio and visual
interface and content elements. Flash files (SWFs) can be published on the Web and can link to other Web sites and
datasources while receiving user input from an experimental physical interface; Flash can also be used to publish
Web-based design documentation. Flash is commonly installed as core software at art and design schools; it has a
vast user base and is the subject of a number of instructional books and Web sites. ActionScript is an accessible,
multi-purpose, and powerful object-oriented scripting language—ideal for experimentation.
Figure 2. Modifying a keyboard controller (wired and wireless)
These were the tools we relied on in our original version of the course: sketch-modeling with discarded hardware,
and software sketching with Flash. We chose them because they were accessible, easy to use, and environmentally
sound—and because they allowed students to work directly with the media, forcing them to be sensitive to its
possible use. These tools were helpful but limited. We could build multi-sensory physical input devices that would
control content on a screen, in speakers, and on the Web—but the Flash Player limited the ways in which data could
be received from and sent to hardware. Also, a modified keyboard allowed us only binary input (“A” key is “down,”
or “A” key is “up”). We wanted our students to have more: more technological options, more possibilities as
designers and thinkers.
Figure 3. Hardware and software system using a modified keyboard controller
We started testing popular software solutions. Cycling 74’s Max/MSP allowed for greater flexibility in input and
output data channels, and connected easily with popular analog and digital (A/D) converters (Teleo, iCube, etc.). But
in the end, we stayed with Flash. It’s highly accessible to designers (Max—and especially MSP—was originally
intended for computer music applications). It has a free and ubiquitous player and an internationally standardized
object-oriented scripting language—a subset of ECMAScript (ISO/IEC 16262) and a good starting point for students
eager to learn other programming and scripting languages. It can be used for drawing, typesetting, animating,
controlling audio and video playback and effects, streaming audio, video, and vector graphics. It facilitates easy
Web publishing; is easily integrated with Web applications; comes with a built-in XML object and socket; features
pre-built components that allow for rapid prototyping; and, last but not least, it was already installed on our students’
laptops.
There was one major problem: How could we connect Flash with popular A/D converters? We worked with the staff
of our consulting firm to explore solutions. Our first attempt was an elaborate system involving analog sensors;
Teleo Analog In; Power and USB modules; a computer with Linux, Apache, JRUN and a Java-based XML server
(FLOSC) installed; a Max Patch; and a Flash SWF that could send and receive XML and had some graphical
buttons and sliders. Incredibly, it worked. At least it allowed us to control an animation on a Web site from an
analog bend sensor, and to control an electrical motor by dragging a slider in the Flash movie. But it was an overly
complex and inefficient composition of hardware and software elements.
Our next stage of development was to try and streamline the signal flow between analog sensors (bend, touch, heat,
motion, proximity, etc.) and a Flash Movie, and between a Flash Movie and electrical devices (motors, lights,
thermostats, heating elements, etc.). Our design consultancy built a platform-independent application in Java, called
NADA, to allow more direct communication between A/D converters and Flash. This software is currently being
used in the our courses, as well as at several schools internationally.
Figure 4. Hardware and software system using analog and digital converters
6 
Results
Since the course was first offered, in 2001, we have seen a material change in its fortunes—and our own. The course
has been over-enrolled; the waiting list exceeds three times the classroom capacity. Past students enroll in courses
with the same faculty. A short video has been published about the course methodology. Other departments at RISD
have agreed to partner with the industrial design department to offer a similar course. We have been invited to
lecture at other institutions about the topics covered in the course. And Tellart has received contracts to apply the
course’s methods and tools to projects for clients.
None of these were explicit goals of the course; we didn’t design the course in order to achieve them. But together
they suggest that the course offers a meaningful, practical approach to HCI issues in a design studio—and beyond.
The goals of the course were to allow students to sketch in an unwieldy medium—the better to design solutions to
specific human needs. In other words, we wanted to humanize the studio, the student, the technology, and the design
process. In truth, our success is not easily measured. We can point to our students’ projects, many of which showed
a remarkable awareness of human use and environmental impact, or demonstrated exceptional skill in handling
materials or developing concepts. And we can point to our course materials, which (we hope) became more helpful
with each new session. But we would expect to have some talented students; and we would expect to provide every
student with the most useful supporting materials.
Perhaps the best way to measure the outcome of the course is to talk in broad strokes about what we saw in the
studio.
We saw students sketch with actual hardware and software—a process that allowed them to develop a vocabulary
that bridged the gap between designers and computer engineers. We exposed them to specific technologies at
specific times, with the aim of easing them into the science of their work. We developed demonstrations and
exercises and assignments—using computer hardware and software—that followed a studio practice and a design
process that they were already familiar with. We worked with each new technology ourselves, and we changed it to
adapt to the needs of each new class of students. We made the engineering side of HCI design seem familiar,
personal, possible.
We saw students design more robust products—because they understood their media at a deeper, more detailed
level. They went beyond the color and shape of a plastic housing; they examined hardware components and software
logic—enough to understand the qualities and capabilities of digital technologies. The most obviously useful
outcome of this process was that they could design more sensitively shaped housings and human interfaces. They
knew which questions to ask. Will the product require a lot of electrical power? Will it be heavy, or could it be light
enough to be handheld? Will it cost a million dollars to make something that could reasonably be sold for one
dollar? Will it require hard wiring to a wall outlet or to Ethernet? If it’s wireless, what other components will be
required? All of these questions affect the form and use of a product. If students have a solid understanding of them
and the vocabulary that comes with them, they can more effectively communicate with engineers and develop more
useful and robust products. Form really can follow function.
Finally, we saw students—equipped with a basic understanding of computer programming—research and design
with a sensitivity to both sides of human-computer interaction: cognitive and computational. They learned basic
principles like conditional logic: if this button is pressed, then turn on this light bulb; if this button is pressed in
combination with another button, then play this video and turn on the light bulb. And that knowledge allowed them
to design interactive scenes: when I input this information to the computer, it will interpret that information in this
way and output this (these) response(s). Students wrote—as text narratives, not code—and physically acted out such
scenes in class, a process that allowed them to develop concepts and make further discoveries though working and
playing with coding sketch models.
Students, in the end, saw the design process more clearly. The course removed several layers of abstraction between
process and product—between designing an interactive product and seeing it manifested as an object in a human
environment. And it removed several dense layers of engineering study—technical knowledge that often prevents
students from seeing clearly to the human experience of the product. Students explored the cognitive, social,
technological, and economic factors involved in designing digital products. They did it through experience; they did
it with a sound introduction to engineering and programming; and they did it, always, with an awareness of human
need.
Tellart, through it's Sketchtools Division (sketchtools.com), now offers NADA software and physical interface
design workshops to schools and professionals. Our goal is to continue bridging design and engineering disciplines,
and providing students and professionals with new means for thinking (sketching), designing and engaging their
audiences with articulate and meaningful forms.
7 
Acknowledgements
Special thanks to: Krzysztof Lenk who inspired me to teach; Mischa Schaub of Hyperwerk for first inspiring this
work; Andreas Krach for helping me hack my first keyboard; RISD for encouraging and supporting this course
development; Tellart for allowing us to do what we love at work; Nick Scappaticci—my trusty Tellart co-founder;
Brian Hinch for leading the development of NADA and making the diagrams for this paper; Jasper Speicher for all
the electronics lessons and teaching collaboration; Ryan Scott Bardsley for believing in the potential in bridging
design and engineering and leading the COMETS project with RISD; Rob Morris for his editorial help in making
this paper make sense; and all of our students for all of their bravery, work, and inspiration.
References
McCullough, M. (1996). Abstracting Craft: The Practiced Digital Hand, Reprint Edition. Cambridge: MIT Press.
Cooper, A. (1999). The Inmates Are Running the Asylum: Why High Tech Products Drive Us Crazy and How to
Restore the Sanity, 1st Edition. Indianapolis: SAMS.
Laurel, B. (1990). The Art of Human-Computer Interface Design. Reading: Addison-Wesley Publishing Company.
Tilley, A.R., Henry Dreyfuss Associates (2001). The Measure of Man and Woman: Human Factors in Design.
Indianapolis: John Wiley & Sons.
Sketchtools (NADA). http://www.sketchtools.com
Tellart. http://www.tellart.com
Rhode Island School of Design. http://www.risd.edu
Macromedia Flash MX2004 and ActionScript. http://www.macromedia.com
Making Things (Teleo). http://www.makingthings.com
Cycling 74. http://www.cycling74.com
Infusion Systems. http://www.infusionsystems.com
Open Sound Control (OSC). http://www.cnmat.berkeley.edu/OpenSoundControl
FLOSC. http://www.benchun.net/flosc
Umeå Institute of Design. http://www.dh.umu.se
Simulation Group, Center for Integration of Medicine and Innovative Technology, Massachusetts General Hospital.
http://www.medicalsim.org