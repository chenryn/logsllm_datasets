valued) to have an estimation error no more than pe,
the conditional entropy H(XjY ) has to be no more
than H(pe).
4.3. Applications to our problems
4.3.1. Modeling. As described in Section 3.2, when
a (convicted) router R1 would like to check whether one
of its neighbors R2 is infected, it queries the Bloom (cid:12)l-
ter at R2 with LR1. Here LR1 is the set of packets that
match the Bloom (cid:12)lter at R1 among the set of pack-
ets used for traceback (i.e., Lv).
(cid:15) Np: the number of attack packets used by the vic-
tim for traceback.
(cid:15) d1: the percentage of the attack packets that travel
through R1.
(cid:15) d2: the percentage of the attack packets that travel
through R2.
In the following, we introduce step by step the ran-
dom variables involved in the analysis. By conven-
tion, Binom(N ; P) represents the binomial distribu-
tion with constant parameters N and P, where N is
the number of trials and P is the \success" probabil-
ity. In some places below, we abuse the Binom nota-
tion slightly to put a random variable in the place of
N , which will be made mathematically rigorous next.
(Pr[X = x; Y = y]
We (cid:12)rst de(cid:12)ne some notations:
Let X be a random variable. The rigorous mathemati-
cal de(cid:12)nition for a random variable Y to have the dis-
tribution Binom(X; P) is that, the conditional distri-
bution of Y given that X = x is Binom(x; P), and this
holds for all values of x that X will take. This abuse
is not counterintuitive, and makes our reasoning much
more succinct.
(cid:15) Let Xt1 be the number of attack packets sam-
pled by R1. It has the probability distribution
Binom(Npd1; p).
(cid:15) Let Xf1 be the number of false positives when Lv
is queried against the Bloom (cid:12)lter at R1. Its prob-
ability distribution is Binom(Np (cid:0) Xt1 ; f ). Here f
is the false positive rate of the Bloom (cid:12)lter.
(cid:15) Let Xt2 be the number of attack packets sam-
Its probability distribution is
pled by R2.
Binom(Npd2; p).
(cid:15) Let Yt be the number of true positives (real
matches instead of Bloom (cid:12)lter false positives)
when the Bloom (cid:12)lter at R2 is queried with LR1 .
2(cid:0)p ).
Its probability distribution is Binom(Xt2 ;
The parameter
2(cid:0)p comes from the fact that
the correlation factor between the packets sam-
2(cid:0)p in our ORMS
pled by neighboring routers is
scheme.
1
1
1
(cid:15) Let Yf be the number of false positives when the
Bloom (cid:12)lter at R2 is queried with LR1 . Its proba-
bility distribution is Binom(Xt1 + Xf1 (cid:0) Yt; f ).
During the traceback process, we are able to observe
the values of the following two random variables:
(cid:15) Xt1 + Xf1: the total number of packets in the
packet set LR1.
(cid:15) Yt + Yf : the number of positives when the Bloom
(cid:12)lter at R2 is queried with LR1 .
We are interested in estimating the value of the follow-
ing random variable Z, which indicates whether R2 has
stored at least one attack packet in the set of the at-
tack packets used by the victim for traceback.
Z = (cid:26) 1
0
if Xt2 > 0
otherwise
By information theory, the accuracy of estimating Z
from observing Xt1 +Xf1and Yt+Yf is measured by the
conditional entropy H(ZjXt1 + Xf1; Yt + Yf ). The ac-
tual formula of H(ZjXt1 + Xf1; Yt + Yf ) in terms of
system parameters Np, d1, d2, and k is very involved.
The details on how to calculate the conditional en-
tropy can be found in Appendix A. We have written a
program to compute H(ZjXt1 + Xf1; Yt + Yf ) given a
set of parameters. Its results are used to plot the (cid:12)g-
ures related to H(ZjXt1 + Xf1 ; Yt + Yf ) in the rest
of the paper. In computing H(ZjXt1 + Xf1; Yt + Yf ),
we assume d1 = d2. This is because, given a typical
router-level Internet topology, when we trace routers
several hops away from the victim, with good prob-
ability R2 is the only upstream neighbor of R1 that
is infected (i.e., no more \branching" upstream). So
d1 = d2 = d captures the \common case". We also as-
sume pr[Z = 1] = pr[Z = 1] = 1=2, that is, we assume
no prior knowledge about Z.
4.3.2. Parameter tuning. As we discussed before,
our resource constraint is kp (cid:20) s. Here s is the num-
ber of bits of computation (i.e., the number of hash-
ing operations) devoted to each packet on the average,
k is the number of hash functions in each Bloom (cid:12)l-
ter, and p is the sampling probability. Clearly, the best
performance happens on the curve kp = s. Since s is
treated as a constant, only one parameter k needs to
be tuned (p = s=k). It remains to be found out which
k value will allow us to determine with best accuracy
whether R2 has been infected.
By information theory, our knowledge about Z from
observing Xt1 + Xf1and Yt + Yf is maximized when the
conditional entropy H(ZjXt1 + Xf1; Yt + Yf ) is mini-
mized. In other words, we would like to compute
k(cid:3) = argmin
H(ZjXt1 + Xf1; Yt + Yf )
(5)
k
subject to the constraint kp = s as discussed before.
In general, the value of H(ZjXt1 + Xf1 ; Yt + Yf ) not
only depends on the parameter k we would like to tune,
but also depends on other parameters such as d2 (we
assume d1 = d2). We can view the value of d2 (say
d2 = d) as a targeted level of concentration. In other
words, when k = k(cid:3), our system is most accurate in es-
timating the value of Z for those potential R2’s that
have the concentration d. One may wonder if we tar-
get a certain concentration, but a di(cid:11)erent concentra-
tion happens during an attack, our k(cid:3) may not be opti-
mal. However, our computation results show that if we
5000 , which approx-
target a low concentration such as
imately corresponds to 5,000 attackers attacking with
the same intensity, our k(cid:3) is optimal or close to optimal
for other higher concentrations as well. In other words,
the optimality of k is not sensitive to the concentra-
tion value we are targeting. Therefore, we can choose a
k for our scheme to work well even if we do not know
the accurate information of d1; d2. All we need is the
range of d1; d2.
1
We illustrate these results in Figure 2. Each curve
in Figure 2(c) shows how the value of H(ZjXt1 +
Xf1; Yt + Yf ) varies with di(cid:11)erent k values, given a
y
p
o
r
t
n
e
l
a
n
o
i
t
i
d
n
o
c
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
(a) d = 1/1000
Np =   50,000
Np =   75,000
Np = 100,000
 8
 10  12  14  16  18  20  22  24
number of hash functions k
y
p
o
r
t
n
e
l
a
n
o
i
t
i
d
n
o
c
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
(b) d = 1/2000
Np = 100,000
Np = 150,000
Np = 200,000
 8
 10  12  14  16  18  20  22  24
number of hash functions k
y
p
o
r
t
n
e
l
a
n
o
i
t
i
d
n
o
c
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
(c) d = 1/5000
Np = 250,000
Np = 375,000
Np = 500,000
 8
 10  12  14  16  18  20  22  24
number of hash functions k
Figure 2: Conditional entropy with respect to the number of hash functions used in a Bloom (cid:12)lter for s = 0:4 with
di(cid:11)erent concentrations
certain Np value (number of attack packets used for
traceback). The three curves in this (cid:12)gure corresponds
to Np = 250; 000, 375,000, 500,000 respectively. Here
the resource constraint is s = 0:4. The targeted con-
5000 . We can clearly see that the opti-
centration d is
mal k value is not sensitive to the parameter Np. Given
d = 1
5000 , Figure 2(c) shows that k = 12 or 13 results
in the lowest value for H(ZjXt1 + Xf1; Yt + Yf ).
1
1
1
1000 and 1
Figures 2(a) and 2(b) show how the value of
H(ZjXt1 + Xf1; Yt + Yf ) varies with di(cid:11)erent k val-
2000 , respectively. From
ues, when d is set to
these two (cid:12)gures, we see that k = 12 is very close to op-
2000 . This
timal for higher concentrations
demonstrates that the optimal value of k is not
very sensitive to the value of d. Therefore, in Sec-
tion 5, our scheme will adopt k = 12 when its resource
constraint is s = 0:4. Simulation results show that
k = 12 indeed allows our scheme to achieve the op-
timal performance. In other words, the information
theory indeed prescribes the optimal parameter set-
ting for our scheme.
1000 and
1
4.3.3. Application of Fano’s inequality. In this
section, we will show how Fano’s inequality can be
used to compute the minimum number of attack pack-
ets needed for achieving a certain traceback accuracy
and how this number scales to larger number of attack-
ers. According to Fano’s inequality for the estimation
of a binary-valued random variable (formula (4)), we
have
H(pe) (cid:21) H(ZjXt1 + Xf1; Yt + Yf ):
(6)
where pe = Pr[ ^Z 6= Z] is the probability that our
estimation ^Z is di(cid:11)erent from the actual value of
Z. Therefore, given a desired traceback error rate (cid:15),
the number of attack packets has to be larger than
Nmin, where Nmin is the minimum Np that makes
H(ZjXt1 + Xf1; Yt + Yf ) no more than H((cid:15)).
Figure 3 shows the fundamental trade-o(cid:11) between
the traceback error pe and Nmin. In this (cid:12)gure, s is set
to 0.4 and k is set to the aforementioned optimal value
12. The three curves in this (cid:12)gure correspond to the
r
o
r
r
e
n
o
i
t
a
m
i
t
s
e
 0.5
 0.45
 0.4
 0.35
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
 0
 0
 100
d = 1/1000
d = 1/2000
d = 1/5000
 300
 200
 600
number of attack packets Np (x1000)
 500
 400
 700
 800
Figure 3: The trade-o(cid:11) between the estimation error pe
and Nmin, given s = 0:4 and k = 12.
1
1
1000 ;
2000 , and
setting d = 1
5000 respectively. For ex-
ample, when there are 1,000 attackers attacking with
the same intensity, to be able to achieve the estima-
tion error rate of 0.1, the victim needs to receive and
use at least 80,000 attack packets. All curves go down-
ward, matching the intuition that larger number of at-
tack packets are needed for traceback when smaller es-
timation error rate is desired.
Figure 3 also shows how Nmin scales with the num-
ber of attackers. We can see that Nmin grows almost
linearly with the number of attackers for all desired
estimation accuracies. For example, when the desired
pe is 0.1, we need 80,000, 166,000, 450,000 packets for
scenarios which have 1,000, 2,000, and 5,000 attack-
ers with the same intensity, respectively.
5. Performance Evaluation
We have conducted extensive simulation on three
real-world network topologies to evaluate the perfor-
mance of the proposed scheme, using a simulation tool
we have developed. The goal of our simulation is two-
fold. First, we are interested in knowing how well our
information-theoretic results match with our simula-
tion results. We show that they agree with each other
very well. Second, we would like to investigate the per-
(a) Skitter I topology
(b) Skitter II topology
(c) Bell-lab’s topology
)
R
P
F
+