improve  the  average  access  speed  of  the  DRAM.    A 
common  example  of  this  is  extended  data  out  (EDO) 
DRAM, which places a D-type latch on the data line so 
that the next access cycle can be started as soon as the 
data  has  entered  the  latches.    Since  these  latches  are 
shared across the entire DRAM, there is little chance of 
any piece of data except the last one read before a long 
break in accesses to the DRAM remaining in them for 
more than an instant, and if this is really a concern they 
can  be  flushed  with  a  read  to  an  innocuous  memory 
location.    Synchronous  DRAMs  (SDRAMs),  which 
parallel load a quantity of data into a shift register and 
then  shift  it  out  one  bit  at  a  time,  have  similar 
properties. 
to 
in 
leading 
signals, 
5.2. Avoiding Long-term Retention Effects 
Long-term  retention  effects  are  most  likely  to  occur 
when the same data is repeatedly fed through a circuit, 
an example being the repeated use of a private key in a 
crypto  accelerator  for  large-integer  maths.    This  is  a 
phenomenon  which  only  occurs 
specialised 
hardware,  since  general-purpose  processors  are  fed 
such a variety of data that none of it has much effect on 
the circuitry.  In contrast a private key stored in tamper-
resistant hardware and fed repeatedly through a crypto 
processor will lead to some circuits always carrying the 
same 
long-term  hot-carrier 
degradation and electromigration effects. 
The most common solution to this problem (and that of 
device  protection  in  general),  embedding  the  crypto 
device in a tamper-resistant or tamper-sensing package 
which  zeroises  the  cryptovariables  when  tampering  is 
detected, is of little help since it’s currently not possible 
to quickly zeroise electromigration effects, at least not 
without  resorting  to  chemical  zeroisation  means.    One 
way  of  undoing  the  effects  of  electromigration  (apart 
from hoping that the system will eventually relax back 
to its ground state) is to apply a reverse current which 
reverses the electromigration stress, effectively undoing 
the  electromigration  damage  [46][47].    This  technique 
is  already  used  in  some  EEPROM/flash  devices  to 
reduce erase stress by applying a reverse-polarity pulse 
after an erase pulse [48]. 
A  somewhat more  complex and difficult-to-implement 
approach  is  to  have  the  crypto  processor  process 
dummy  data  when  it  isn’t  working  with  real  data  and 
keys.  A downside of this is that it requires that a crypto 
operation  be  interruptible  once  started  (it’s  no  good 
having to  wait for  a dummy RSA decrypt to complete 
each  time  you  want  to  decrypt  data),  and  leads  to 
increased  power  consumption  and  decreased  device 
lifetime.    In  addition,  it  assumes  that  the  device  isn’t 
occupied at all times with handling real data, leaving no 
chance to process any dummy data. 
Unfortunately  alternating  dummy  and  real  data  is 
complicated  by  the  design  of  typical  crypto  devices.  
For example encryption hardware will typically contain 
multiple key registers from which the currently selected 
key is expanded into storage reserved for the scheduled 
key, which is then used to encrypt a block of data.  This 
means that switching keys incurs the overhead of a key 
schedule  (although  many  devices,  particularly  DES 
hardware, will do  an on-the-fly  key schedule  which is 
effectively  free  in  hardware).    In  addition,  pipelined 
implementations  of  block  ciphers  are  generally  not 
interruptible, requiring completion of processing of the 
current block (and in some cases several more blocks to 
force  the  pipeline  to  be  flushed)  before  a  key  change 
can take effect. 
In order to economise on chip real estate (and therefore 
on  device  cost),  virtually  all  real-world/non-research 
DES  hardware  implementations  iterate  a  single  round 
16  times,  with  on-the-fly  key  scheduling.    Non-DES 
iterated  algorithms  (as  well  as  non-crypto  algorithms 
such  as  MD5  and  SHA-1)  are  also  implemented  by 
iterating  one  round  rather  than  by  unrolling  the 
operation.    These  can  (with  a  little  redesign)  be 
interrupted  at  any  point  in  the  encryption/decryption 
cycle and new data can be substituted.  In addition the 
fact that a single round is reused with multiple sets of 
key  bits  means  that  there’s  a  very  mixed  set  of  data 
patterns in use which minimises the effects of any one 
pattern. 
The  crypto  cores  of  large-integer  maths  accelerators 
(for  example  RSA  accelerators)  are  less  vulnerable  to 
long-term  effects  since  they  typically  iterate  a  simple 
operation  such  as  addition  or  bit  shifting  in  a  loop  to 
achieve multiplication, exponentiation, or whatever else 
is required.  For example a typical RSA accelerator [49] 
might  consist  of  one  of  more  512-  or  1024-bit  adders 
and/or  shift  registers  which  are  used  to  perform  RSA 
encryption  using  a  series  of  squaring  and  modular 
multiplication  steps,  with  a  1024-bit  multiplication 
being  performed  with  1024  additions.    Since  the 
operations  reuse  the  basic  add/shift  circuitry  with 
constantly-changing  bit  patterns,  the  problem  of  data 
retention  in  these  parts  of  the  circuit  are  greatly 
reduced.  However, the iterated application of the same 
keying data  exacerbates the retention problem in other 
parts  of 
single  modular 
exponentiation can result in key components travelling 
over the same data paths thousands or even millions of 
times.    The  RSA  accelerator  mentioned  above,  and 
others  like  it,  perform  a  1 kb  modular  multiplication 
with  1k  modular 
a  modular 
exponentiation  with  1k  modular  multiplications,  for  a 
total of 1M applications of the same cryptovariables per 
RSA operation, and potentially trillions of applications 
per day of operation in a loaded SSL server. 
the  circuit, 
additions, 
since  a 
and 
6. EEPROM Memory Cells 
Flash memory and EEPROMs are closely related, with 
flash  being  simply  an  extension  of  EEPROM 
technology  to  allow  higher  densities  in  exchange  for 
some  loss  in  flexibility.    All  EEPROM/flash  memory 
cells work in the  same general manner  and  employ as 
storage  element  a  MOS  transistor  with  a  floating  gate 
into  which  electrons  are  tunnelled  using  a  process 
known  as  Fowler-Nordheim  tunnelling,  a  quantum-
mechanical effect in which electrons tunnel through the 
energy  barrier  of  a  very  thin  dielectric  such  as  silicon 
dioxide [50]. 
6.1. FLOTOX Cells 
A typical older EEPROM technology is Intel’s floating-
gate  tunnelling  oxide  (FLOTOX)  technology,  with  a 
typical  transistor  structure  shown  in  Figure  10.    A 
cross-section  of  the  device  with  the  corresponding 
energy-band diagram is shown in Figure 11.  To store a 
charge,  the  control  gate’s  voltage  is  raised  with  the 
source  and  drain  grounded,  so  that  electrons  tunnel 
through to the floating gate.  To remove the charge, the 
process  is  reversed  and  the  electrons  tunnel  back  out.  
The  stored  charge  changes  the  threshold  of  the  MOS 
transistor which comprises the cell, typically by 3–3.5V 
for a 5V cell [51].  The change in the threshold depends 
on a number of factors including the programming time 
(the longer the time, the larger the change), temperature 
(the higher the temperature, the fewer the available hot 
electrons available to be injected), and the condition of 
the cell, which is covered in more detail further on. 
Floating
gate
Gate
Gate
oxide
N+
P-substrate
N+
Source
Drain
Tunnel
oxide
Figure 10: Typical EEPROM memory cell 
This example of cell operation is merely representative, 
the  details  vary  from  manufacturer  to  manufacturer 
[52].    In  particular,  some  issues  like  dielectric  scaling 
effects  and  various  program  and  erase  mechanisms 
aren’t  fully  understood  yet,  leading  to  a  variety  of 
technologies 
those 
technologies.    In  addition  the  interpretation  of  what 
represents a stored 0 or 1 varies from device to device 
in  that  cells  can  be  written  into  either  state,  with  one 
state being regarded as “programmed” and the other as 
“erased”.    In  some  cells the  low-stored-charge  state is 
called programmed, in others it’s called erased. 
continual 
and 
changes 
in 
Gate oxide
Gate
Floating gate
Tunnel oxide
Drain
eee
eeeeeeee
eeeeeeee
Gate at
+ve
Gate
at gnd
Figure 11: FLOTOX EEPROM program/erase 
process 
6.2. ETOX Cells 
A somewhat newer technology is represented by Intel’s 
EPROM tunnel oxide (ETOX) cell [53][54], which uses 
channel  hot  electron  (CHE)  injection  to  store  a  value 
and  Fowler-Nordheim  tunnelling  to  remove  it,  is 
illustrated in Figure 12.  This technique is widely used 
in flash memory, although the widely-used NAND flash 
again uses tunnelling for both programming and erasure 
(NAND  flash  cells  have  a  somewhat  specialised 
architecture which allows the use of the more efficient 
tunnelling for program and erase [55]). 
+12V
Source
Gate
Floating gate
Drain
CHE Injection
GND
GND
+~6V
Gate
Source
Drain
Floating gate
FN Tunneling
+12V
Figure 12: ETOX EEPROM program/erase process 
The  basic  EEPROM  cell  consists  of  the  storage 
transistor  described  above  and  a  second  transistor  to 
select  or  deselect  the  cell  (some  technologies  employ 
additional  error  detection and correction circuitry).   In 
and 
different  manufacturers, 
an  attempt  to  increase  storage  density,  manufacturers 
have  moved  towards  using  the  select  transistors  to 
handle  multiple  storage  cells.    When  the  cells  are 
organised  in  this  manner  only  the  programming  step 
can  be  done  in  a  bit-by-bit  basis,  the  erase  operation 
works by erasing all cells in a block and programming 
the new data bits as required (or rewriting the old data 
in  sections  where  no  change  is  to  occur).    Because 
programming is possible on a bit by bit basis, it’s usual 
to only program cells which are currently in the erased 
state  to  avoid  overprogramming  already-programmed 
cells and (in the case of flash memory) to avoid having 
to erase an entire sector just to change one or two bytes. 
The details of the erase operation again vary somewhat 
across 
unlike 
programming the  erase  operation functions on a  block 
of cells at a time.  Since the cells aren’t all uniform, a 
cell  array  may  contain  fast-erasing  bits  as  well  as 
typical-erase bits, so that a single  erase  pulse  may  not 
erase  all  the  cells.    Because  of  this  it’s  necessary  to 
verify the erase and reapply the erase pulse to catch the 
remaining  cells.    This  operation  is  repeated  until  all 
cells have been reduced to less than the cell erase verify 
level.    In  practice  the  erasure  process  is  a  speculative 
one,  with  the  initial  pulse  being  far  shorter  than  the 
typical erase time, followed by longer and longer pulses 
as required.  The reason for using this erase process is 
that  we  want  to  avoid  further  affecting  already-erased 
cells,  once  a  cell  is  erased  by  a  pulse  any  subsequent 
pulses  don’t significantly change  its threshold voltage.  
The programming process is usually performed using a 
similar  type  of  algorithm,  with  the  main  difference 
being that programming is possible on a bit-by-bit basis 
so  that  cells  which  are  already  at  the  required  level 
aren’t programmed further [56][57]. 
6.3. Flash Memory Technology 
The  simplest  flash  technology,  employing  a  NOR 
structure, allows access to individual cells but requires 
a  dual-voltage  supply  and  has  a  rather  low  block 
density.  More common is a NAND structure in which 
multiple transistors in series are controlled by a single 
select  transistor  as  shown  in  Figure  13.    NAND 
EEPROM/flash moves data to and from storage in large 
blocks, typically 64–256 bytes at a time, and has cells 
which  are  typically  one-quarter  the  size  of  equivalent 
conventional EEPROM cells.  Other size optimisations 
include tricks such as stacking the select transistor atop 
the  storage transistor and similar methods for  merging 
the function of the two transistors into a single, smaller 
unit, for example including the select gate as a second 
gate  in the  cell, the sidewall select-gate  or  SISOS cell 
[58].    Another  way  to  improve  density  is  to  use 
multilevel 
storage,  which  distinguishes  between 
multiple charge levels in a cell instead of just the basic 
programmed and erased states [59][60]. 
Bit line