ùëÜùëÜ ùêµ.Theoutputisthenthenumberofitemsinthedifferenceset
adoptitintracesamplingforitsabilityinmodelingthediversity.
|(ùëÜùëÜ ùê¥‚à™ùëÜùëÜ ùêµ)|‚àí|(ùëÜùëÜ ùê¥‚à©ùëÜùëÜ ùêµ)|.
DPPisaprobabilisticmodelthatprogressivelyselectsadissimi-
‚Ä¢ SpanCountDiff:ExtendedfromtheSpanNameDiff function,this
laritemintothedesiredsubsetuntilthebudgetisfulfilled.Ithas
functionadditionallymeasuresthedifferenceinthenumberof
beenwidelyusedinmanymachinelearningareas(e.g.,recommen-
spansbetweentwotracesatlevel-d.
dation[4],documentsummarization[2]).Ingeneral,DPPrequires
TheoutputsofStructureDiff andStatusDiff areBooleanvalues akernelmatrixthatcapturespairwisesimilarityamongallùëÅ data
(TrueorFalse),whiletheoutputsofLatencyDiff,LevelDiff,Span- itemsandthesamplingbudgetùêæastheinput.Duringsampling,the
NameDiff,andSpanCountDiff areNumericalvalues.Giventhetrace- approachfavorstheselecteditemstobemutuallydissimilar,which
tracedifferencefunctions,wecanfurthercomparethreetracesto alignswiththegoalofobservability-preservingtracesampling.
determinetheirrelativerelation.Specifically,fornumericaloutputs, However,previousstudies[4]onDPPusuallyworkonthedataof
weuseoperators(>,LevelDiff(A,C)
representationandsamplingeffectivenessinSec.5.2andSec.5.3
separately.TheoverheadofSTEAMispresentedinSec.5.4.By
injectingfaults,wedemonstratehowourmethodpreservesthe
observability and helps the detection and diagnosis in Sec. 5.5.
Sec.5.6showstheresultsofSTEAMonproductiontraces.
5.1 ExperimentalSettings
Inthissection,weexplaintheexperimentalsettingsandimplemen-
Figure4:AnillustrationofsamplingviafastDPP.
tationdetails.
Trace Collection: We collect traces from four widely-used
groupwiththemosttracesduringparallelism.So,weshouldtry
benchmarkmicroserviceapplications,including(i)TrainTicket[48];
tomakedifferentgroupshaveasimilaramountoftraces.2)how
(ii) Social Network [8]; (iii) Media Service [8]; (iv) Online Bou-
toassignthesamplingbudgetseparatelytoeachgroupwhilethe
totalsamplingbudgetisstillùêæ? tique[34].ThesebenchmarksareimplementedinJava,Python,
Go,C/C++,Scala,PHP,Ruby,etc.Thebenchmarkapplicationsare
Toanswerthefirstquestion,weiterativelysplitagroupoftraces
deployedinaKubernetesclusteronAzurewithanodepoolof12
intotwosmallergroupswiththeK-means[24]clustering(wherek
is2)algorithmuntilreachingùê∂groups.Theinitialgroupcontains virtualmachines(VM).EachVMhas2vcpu(16cores)and8GB
memory.Foreachapplication,wesynthesizetheworkloadviathe
alltraces.Ineachiteration,wechoosethelargestgroupfromall
loadtestingtoolLocust[26]tosimulatetheuseractivity.
candidategroupstosplit.Itistoforcethatalargegroupwould
Besidesthebenchmarkapplications,wealsoevaluatedSTEAM
befurthersplitintosmallpieceswhichhavesimilaramountsof
on an internal production system. The system is a Kubernetes-
traces.Forthesecondquestion,weassignthesamplingbudgetof
likedistributedsystemdeployedworldwidetoservecontainerized
eachgroupbasedonthetracedensityinthatgroup.Intuitively,a
services.Theproductiontracesarecollectedfromthecontrolplane
lessdensegroup(withmoredissimilartraces)shouldhavealarger
whichmanages(suchascreate,delete,andupdate)theunderlying
samplingbudget.Eachgroup‚Äôsdensityismeasuredbythemaximum
resourceslikevirtualmachines,network,andstorage.Table2shows
distancebetweentheclustercenteranditsmembertraces.Givena
totalsamplingbudgetùêæ,thenumbersofsamplestakenfromeach asummaryofourtracecollections.AllTracesisthetotalnumber
group(ùêæ 1,ùêæ 2,...,ùêæ ùê∂,whereùêæ =(cid:205)ùê∂ ùëñ=1ùêæ ùëñ)areinverselyproportional o thf etr fa oc re ms. eW rte ws op ali rt eit ui sn et do tt ora ti rn ai in ng a, nv dal ti ud nat eio thn e,a rn epd rt ee ss et nin tag tis oe nt, mw oh de ere
l,
tothedensityvalues.Atlast,weapplythevanillaDPPinparallel
andthelastdenotesthenumberoftracesusedforevaluation.
toeachgroupandmergethesampledtraces.
BaselineMethods:Weimplementedthebaselinesfromexist-
Tofurtherreducethecomputationcost,weimplementastream-
ingstudies[20,21].Inaddition,wecreatedabaselineusingGNN
ingK-meansclusteringalgorithm,similartotheSparkStreaming
modelstrainedbystandardcontrastivelearning.
K-means[38].Duringonlinesampling,thetracesarefedintothe
clusteringalgorithmonabatchbasis.Theclusteringstartsafter ‚Ä¢ Uniform:Weuniformlysampleatracesubsetfromthefulltrace
receivingthefirstbatch,wheretheclustercentersarelearnedand set.Itmimicstheheadsamplingstrategy.
keptinmemory;forfollow-upbatches,theclustercentersareup- ‚Ä¢ PERCH: Las-Casas et al. [20] proposed to represent the trace
datedwiththenewdatainsteadoflearningfromscratch. usingoccurrencecountembeddingsusinguser-specifiedevents,
e.g., how many times a microservice is invoked in the trace.
5 EXPERIMENTS
Then,theyadoptanextremeclusteringalgorithmPERCH[18]
Inthissection,wefirstpresenttheexperimentalsettingsinSec.5.1. togrouptracesandevenlypicktracesfromeachgroup.Forfair
Then,weevaluateonfourmicroserviceapplicationsthelearned comparisons,weextendittousethesamefeaturesetsasours.
1755
STEAM:Observability-PreservingTraceSampling ESEC/FSE‚Äô23,December3‚Äì9,2023,SanFrancisco,CA,USA
‚Ä¢ Sifter:Sifter[21]firstobtainsthetracerepresentationbyrecon- Table3:Accuracyonleveragingthetracerepresentationto
structingaspanfromitsneighborhoodspanswithaword2vec- measuretracesimilarityinthetestingtracetriplets.
like[32]technique.Then,itmeasuresthereconstructionlossof
anincomingtrace,whichiscomparedagainstothertracesto Name Sifter PERCH Contrast STEAM
computethesamplingweight.
TrainTicket 0.513 0.783 0.658 0.955
‚Ä¢ Contrast:WefollowtheTraceCRL[47]tobuildamodelthatran-
SocialNetwork 0.672 0.851 0.636 0.974
domlymanipulatesthetracedata(e.g.,masking).Afterobtaining
MediaService 0.459 0.860 0.671 0.912
therepresentation,weapplythevanillaDPPforsampling.
OnlineBoutique 0.372 0.791 0.649 0.933
Implementation: STEAM is implemented inside the Open-
TelemetryCollector[33]withover1.6KlinesofGolangcode(mainly
foronlinedeployment)and2KlinesofPythoncode(mostlyfor
datapreparationandmodeltraining).Wedesignedtwoconditions
totriggerthesampling:1)timetick:thesamplingwillbetriggered
periodically, e.g., every 30 seconds. 2) trace size: the number of
accumulatedtracesthatarereadyforsamplingreachesaprede-
finednumber,e.g.,10K.Ifeitherconditionissatisfied,thesampling
willstart.Forefficiencyconsideration,weparallelizedthestepof
constructingtrainingdatafromtraceswithmulti-processing.For
themodelpart,weusedPyTorch1.10toimplementtheGNNmodel
with2layersand32hiddendimensionsize.Wetrainedthemodel
onasingleP100GPUwithalearningrateof10‚àí3andabatchsize
of1024.Themargininthetripletlossis0.1.
Table2:Asummaryoftracedatacollectedfrombenchmark Figure5:Coverageofdifferentsamplingmethodsonfour
microserviceapplicationsandproductionsystem. benchmarkmicroserviceapplications.
Name Service Span AllTrace TestTrace
5.3 TraceSampling
TrainTicket 41 245 162,833 58,110
Inthispart,weevaluatedtheeffectivenessofSTEAMregarding
SocialNetwork 36 33 89,806 35,923
tracesampling.PriorworksuchasSifter[21]andPERCH[20]only
MediaService 38 30 70,894 28,358
evaluatethesamplingbyillustratingsomequalitativeexamples.
OnlineBoutique 11 51 32,253 12,902
Inthiswork,weusecoverageandentropy(Sec.3)toevaluatethe
ProductionSystem 335 589 73,965 29,586
samplingontest traces.Thehighervaluesbothmetricsachieve,
5.2 TraceRepresentation themoreobservabilitycouldbepreservedaftersampling.
Thetracetypesarelabeledbyconsideringdifferentaspectsofa
Wefirstevaluatewhetherthelearnedtracerepresentationcanbe
trace,includingoperation,structure,latency,andtheircombination.
usedtomeasurethesimilarity.Weleveragethetrainedmodelto
(i)operation:itdenotesthebusinessfunctionalityofatrace.For
predicttherelativerelationoftriplets(i.e.,whetherAiscloserto
example,inFig.1(a),the"GetAuth"operationmeansarequest
BthanC)onthetestdata.Notethatthemodelhasneverseen
askingfortheauthenticationfromtheserverside.(ii)structure:
thetracesinthetestdatabefore.Specifically,wefirstobtaineach
Toobtainthelabel,wemergetracesthathaveexactlythesame
trace‚Äôsrepresentationofthetriplet(A,B,C)andafterwardscom-
structure,i.e.,thespannameandtheirparent-childrelationshould