### 4.3 Decryption of Content Using Suspected Secret Key

The process of decrypting the content was relatively straightforward, involving approximately 200 lines of Java code and some trial-and-error to determine that the apps were using the Electronic Codebook (ECB) mode of AES. We confirmed that the contents could be decrypted using the suspected secret key. This attack was verified through a paid purchase of a recent issue in the My MS-UK app and free trial issues in the Business Money, Artists & Illustrators, The MagPi, and Popshot Magazine apps.

### 4.4 Raw Content on Internal Storage

According to the official Android development training material, files stored on internal storage are "accessible by only your app" and "neither the user nor other apps can access your file" [5]. Consequently, it is not surprising that some apps make strong assumptions about the confidentiality guarantees provided by internal storage. However, these assumptions can be invalidated with AInS(R).

#### Content Extraction Attacks

For concrete examples, we examined the 70 group-3 apps discussed in Sections 3.2 and 3.3. In their designs, each page of the publication is a JPEG image of about 0.7 megapixels. After downloading the content ZIP file of an authorized issue, the app extracts the content images and stores them on the app’s internal storage. The app then acts as an image viewer for displaying each page to the user. Since the images of each issue are left inside the internal storage without further scrambling [CWE-313], an AInS(R) adversary can easily access and make copies of the magazine issues, thereby attacking (AS3).

Through the in-app free previews, we found that the 16 group-8 apps also save each page of an issue as a JPEG image on the internal storage. Interestingly, even though the free previews should allow only a small number of pages, all the other pages of the selected issue are already downloaded. Consequently, with AInS(R), one can easily bypass the preview limit and access the saved pages directly.

### 4.5 Raw Encryption Key on Internal Storage

Similarly, developers might store encryption keys on the internal storage, assuming confidentiality [CWE-313]. However, in the face of the AInS(R) capability, such a design becomes an exploitable weakness on (AS2).

#### Key Extraction Attacks

We use the Counter Intelligence Plus app (group-2) as an example, which is also made by Apazine. Despite being older than the other group-1 apps, the Counter Intelligence Plus app appears to do a slightly better job in terms of hiding the secret key used in content encryption. Instead of storing the key on the “world-readable” external storage, it is stored on the device’s internal storage. However, with the AInS(R) capability, we managed a key extraction attack similar to what is described in Section 4.3.

### 4.6 Direct Content Source on Internal Storage

Leaving direct links to contents that do not enforce authentication and authorization [CWE-452] on internal storage is another exploitable weakness on (AS2).

#### Purchase Bypass Attacks

With the exception of The Rebel Media app, all the other 24 group-4–5 apps that offer articles (e.g., the Bloomberg Businessweek+ app) or video clips (e.g., the Outside TV Features app) leave direct URLs to their corresponding contents on the apps’ internal storage, organized by different issues. This allows an AInS(R) adversary to easily crawl for those and access contents without paying.

### 4.7 Client-Side Authorization

The assumptions on internal storage indeed present an interesting attack vector. In addition to confidentiality, one might also assume that the internal storage provides strong integrity guarantees. Such an assumption can be invalidated with AInS(R+W).

#### Purchase Bypass Attacks

Each of the 70 group-3 apps discussed in Section 3.2 also keeps a local database of published and available issues on the app’s internal storage. For each issue, the database records the name, date, brief description, price, and other metadata, including the purchase status. With the AInS(R+W) capability, we verified that one can modify the database and replace the default value of the purchase status column with appropriate values [CWE-642] to trick the app into granting access to magazine issues that were not paid for.

This shows that the authorization of these apps is localized and done unilaterally on the client’s device, without involving the back-end content distribution server [CWE-603]. Consequently, the robustness of such an authorization mechanism hinges on the assumption that the internal storage guarantees integrity [CWE-654], which does not hold given an AInS(R+W) adversary.

### 4.8 Raw Encryption Key in Memory

Even if raw secret keys are not left in the clear on permanent storage, they might be loaded into memory, presenting another opportunity for attacking (AS4). As a concrete example, we looked at the Amazon Music app (version 6.5.3), which offers both streaming and offline playback of music to its subscribers. There are two tiers of subscription: Amazon Prime and Amazon Music Unlimited, with the only difference being the size of the collection accessible (2 million versus 40 million songs). Both tiers allow subscribers to download music from their corresponding collections for offline playback. The downloaded songs are stored on the external storage of the Android device.

#### Storage Inspection

A quick inspection of the downloaded files shows that regardless of the subscription tier, songs appear to be encrypted and contain a human-readable PlayReadyHeader XML object in their metadata [37], suggesting that this entire streaming service uses the Microsoft PlayReady DRM framework. With the contents already available on the external storage, we focused on devising a key extraction attack.

We first leveraged the AInS(R) capability to inspect the internal storage and see if one can attack (AS2). As there were several secret key candidates (e.g., Base64 strings that decode into binary values of various lengths), we soon ran into the problem of not knowing how to verify whether a key candidate is the right one for content decryption.

#### Key Verification Oracle

Fortunately, the limited documentation publicly available regarding the PlayReadyHeader [37] turned out to be quite useful. The PlayReadyHeader metadata object contains the key ID, content encryption algorithm (in this case, AES CTR mode), and the key length (16-byte), so we knew what we were searching for. Better yet, it also contains a checksum used by the framework to protect against mismatched keys. According to the documentation, this is meant to prevent the case where decryption is done with an incorrect key, potentially damaging audio equipment during playback. Since the checksum is simply the first 8 bytes of encrypting the 16-byte key ID with the key in AES ECB mode, which is easily computable, we now had an oracle for verifying key extraction correctness without having to rely on decrypting the contents themselves.

A quick trial-and-error showed that none of our initial suspects were the right content encryption key. The publicly available documentation regarding the PlayReady framework [36] suggests that the content decryption keys are contained inside licenses. We then turned our attention to finding the license instead. We realized that there exists a .hds file, which, according to some discussions about Silverlight [1], seems to contain the licenses. Without documentation on how to parse and interpret this file, the format of licenses, and whether this file is obfuscated or encrypted, key extraction from it seemed quite complicated.

#### Key Extraction Attacks

Instead, we switched our focus to attack surface (AS4). The intuition is that, even if the local license store on internal storage has complex protection mechanisms in place, the content encryption key would still need to be read from the license store and might be loaded into memory in clear. Hence, we upgraded the adversary capability to AMem+BinIns, using the Frida dynamic instrumentation framework. While we were able to trace the app’s file read operations by hooking the read() system calls with AMem+BinIns, including those that read from the license store, it remained unclear how to interpret the bytes being read. Since tracing and interpreting the preparation phase seemed quite messy, we took a slightly different approach. With the intuition that sensitive information (e.g., content encryption key), if loaded into memory, might exhibit some recognizable structure and would need to be released at some point (e.g., after content playback), we tried to hook deallocation functions instead. While it might also work to hook the free() function calls, a quick inspection of the native libraries used by the app showed that they export some functions that seem to be used for deallocating sensitive information. Intercepting the entrance to some of those functions, tracing appropriate pointers, and then dumping a large enough portion of memory pointed by those, we successfully extracted the content encryption key, which verified against the oracle discussed earlier.

Unlike in previous work where PlayReady-protected video contents were reported to be partially encrypted [53], in this case, we observed that the entire original content is encapsulated in a so-called envelope file. Though we were unable to obtain documentation regarding the metadata (besides the PlayReadyHeader object), based on some header files publicly available on GitHub [35], we were able to guess and parse the metadata correctly. In the end, it took us about 260 lines of Java code to parse the envelope file and decrypt with AES CTR using the extracted secret key to get the raw audio tracks out.

One might wonder why AMem alone is not strong enough. We note that the key extraction problem has a two-dimensional search space, spanning memory layout and time. While ultimately it is the memory inspection that gets us the key, without binary instrumentation, it is difficult to pinpoint the exact timing, especially if the implementation tries to minimize key exposure by actively releasing and overwriting memory regions containing the secret key, a practice also recommended by previous work [27]. Not knowing when to dump the memory would make it hard for AMem to extract the key. Interestingly, in this app, we observed that sensitive information deallocation happens as early as the actual music playback starts. Our speculation is that, since the CTR mode generates keystream blocks by encrypting the next counter values, after a long enough keystream has been generated to allow decryption of the entire content, the app removes the key from memory as soon as possible to minimize exposure time. This is exactly why AMem+BinIns has an advantage in reducing uncertainties along the time dimension.

We further found that the Audible app (version 2.25.0) is also susceptible to this attack. Specifically, members are offered premium podcasts that can be downloaded for offline playback, in which case they are encrypted in the same manner as songs in Amazon Music. It appears that the PlayReady implementations in the two apps are quite similar, as our key extraction attack also worked. Since the downloaded Audible podcast tracks are partially encrypted ISMA files, instead of using our decryption code for Amazon Music, we used the Bento4 toolkit for successful decryption.

#### Key Scanning Heuristics

Curious readers might wonder how we recognized the 16-byte key from memory dumps. As explained in previous work, besides loading the raw secret key into memory, many cryptographic implementations speed up computation by precomputing the key schedules made of the different round keys [27]. This is because typical block ciphers, including AES, go through multiple rounds of operations to encrypt/decrypt a block, and each round involves a round key derived from the raw secret key. Having to repeatedly expand the raw key into the same key schedules for each block could be quite inefficient. It turns out that the key schedule observation also applies to this particular PlayReady implementation. Using the keyfind program [27], we were able to confirm the mathematical relation between the suspected raw key and the derived round keys, strongly suggesting that those bytes found in the memory dump indeed constitute a key schedule.

#### One Key to Rule Them All

Based on the handful of songs that we sampled in our proof-of-concept experiments, Amazon Music appears to be reusing content encryption keys across songs and different accounts, despite the fact that the PlayReady framework allows a much more granular key binding (e.g., per individual item), as noted in a previous work [53]. We speculate that this is to lower the load and management overhead on the back-end servers, though we are not sure whether the entire ecosystem uses only one single key or if keys differ across data centers in various locations. Consequently, songs made available for offline playback from many different albums across artists, regardless of which tier of subscription and user accounts they came from, might all be decrypted with the same key. This puts the whole collection of 40 million songs available on Amazon Music at excessive risk.

While the attack we presented is agnostic to key granularity and can be performed over and over again to exhaust all the possible keys, a more fine-grained key binding (e.g., per album or even per song) would have required more effort from an attacker and hindered automatic mass decryption of a large number of songs. Sharing keys across many accounts does not seem to be a good practice, as it is easy to have a single key leaked (e.g., by an insider) and cause large damage to the ecosystem. Interestingly, unlike Amazon Music, Audible seems to be much more granular with its content encryption keys. It appears that for each podcast track, a new key is used for encryption.

### 5 DISCUSSIONS

#### 5.1 Responsible Disclosure and Aftermath

We notified the content distributors of our findings and provided them with sufficient details to understand and reproduce the attacks. In all cases, we gave the vendors more than 90 days before this paper was made public.

In response to our initial report sent in February 2018 regarding bypass attacks with AInS(R+W) (Section 4.7), developers at Maz Systems implemented the use of an encrypted database on newer versions of some of the group-3 apps. This is a solution that we do not endorse, as it does not change the client-only nature of the authorization mechanism, so the pattern of [CWE-603] still holds. We followed up with reports on group-4–6 apps in June 2018. They expressed gratitude for our efforts and are working on app improvements.

We sent several reports to Apazine in February, April, and September 2018 regarding weaknesses in their group-1–2 apps. They replied in September 2018, suggesting that the magazines are in the public domain and do not contain any sensitive or valuable information, so our implied expectation of robustness is not relevant. We pointed out that if the contents indeed have no market value, then not using encryption can improve user experience, and that some publications in print (e.g., Business Money and My MS-UK) do not seem to be available for free.

Developers at Pugpig were notified in July 2018. They acknowledged and confirmed our findings, replying that they are aware of the weaknesses and that the apps are designed that way by choice to accommodate anonymous sharing of magazine pages, a feature requested by their clients (publishers).

Amazon was notified about the key extraction attack against the Amazon Music app in January 2018. They responded to our report with several new versions of their music app, implementing new obfuscation strategies and offline playback restrictions on rooted devices. However, despite our recommendation of considering the secret key compromised and switching to a new key, as of June 2018, we noticed that recent new releases are still encrypted using the same old key. The key extraction attack against Audible was reported to Amazon in June 2018, and new versions implementing various obfuscation strategies have since been released.

#### 5.2 Possible Countermeasures and Challenges

##### Bilateral Policy Enforcement

While a stateless server allows for a more simplistic deployment, as [CWE-603] has noted, a client-only authorization is weak and can potentially be bypassed, especially in an environment where execution/code can be reverse-engineered and tampered with. Since local adversaries are not able to directly tamper with the execution state of a remote server, considering the threats of AInS(R+W) and AMem+BinIns, policy enforcement can be done more robustly involving the back-end servers. For example, to avoid the attacks discussed in Sections 3.2, 3.4, and 4.7, the authorization logic should be shifted to the back-end server. Then, client-side modification of prices and purchase status would result in detectable discrepancies with records on the server, and the latter can refuse to serve contents in such cases.

##### Direct Content Sources

To hinder the attacks discussed in Sections 3.2, 4.1, and 4.6, content source URLs should not be left in a log file [CWE-532] and also not on a storage that an adversary has unlimited access to [CWE-921]. Instead of explicitly saving the URLs, it would perhaps be better to have them constructed dynamically during runtime, and the servers should request extra authentication and authorization. An AMem+BinIns adversary might still be able to figure out the URLs and the accompanying parameters, but it would be an improvement compared to the current deployments.

##### Certificate Pinning

To hinder the ANet(TLSInt) attacks discussed in Sections 3.3 and 3.4, instead of trusting the system CA store, the apps could adopt some forms of key/certificate pinning [7]. Even though AInS(R+W) and AMem+BinIns might still be used in tandem to defeat pinning, it would at least make ANet(TLSInt) more difficult to achieve than in the current implementations.

##### Denying Services to Rooted Devices

One might propose for the apps to stop providing services on rooted devices, as on unrooted ones, the adversary capabilities are greatly limited. This approach, however, has its own challenges. First, while a concrete global number of rooted devices is not available, it has been suggested that the number could be quite high in certain communities [6, 17]. Various rooting tools have reported millions of downloads [14, 33], and the superuser access management app has hundreds of millions of installs [3]. A content distributor denying service on rooted devices risks losing these customers. Second, determining whether a device is “rooted” is an ongoing arms race. Depending on the heuristics used and how the checks were implemented, binary instrumentation might be able to bypass those as well [44]. We observed that, as of version 7.5.4, the new Amazon Music restriction of no offline playback on rooted devices can be bypassed with RootCloak [34], a popular system modification module.

Google has since introduced the SafetyNet service for developers to detect if a device has been tampered with. Android Pay, Netflix, and Pokémon Go are some examples that deny service if SafetyNet finds the device is rooted. However, the cat-and-mouse game between SafetyNet and the Magisk systemless rooting technique in 2017 has been well documented [45, 46], and there are reports suggesting that on legacy Android versions, various bypasses and attacks against SafetyNet are possible [15].

##### Anti-Debugging and Anti-Instrumentation

Another possibility is to implement anti-debugging and anti-instrumentation techniques in the apps to hinder analysis, potentially even on rooted systems. Depending on what heuristics are being used, some might still be bypassable [41]. With the advancements of artifact detection [38], anti-instrumentation [23, 32], and transparent debugging [19, 42], this line of defense appears to be an ongoing cat-and-mouse game, similar to root detection.

##### Obfuscating Keys in Memory

While relying solely on obscurity for security lacks robustness [CWE-656], in the case where content encryption keys must be inevitably loaded into memory, one possibility is to make it harder for key scanning heuristics to identify secret keys in memory dumps.

Various TEE implementations have been made available in recent years, especially on mobile platforms, where it has been reported that there are multiple vendors offering various TEE solutions that do not conform to the same API standard [20], potentially hindering adoption.

Heuristics used in identifying memory regions of interest (e.g., those that contain content fragments and cryptographic keys) typically assume their targets to occupy a contiguous region of memory [27, 53]. Additionally, they might also leverage the mathematical relation between the raw secret key and its derived key schedules to pinpoint the targets [27]. It remains to be seen whether obfuscations can be used to defeat these assumptions and make it more difficult for an attacker to recover secret keys from memory.

##### Watermarking

An orthogonal line of protection is to use watermarking to make the origin of piracy traceable. Over the years, there are techniques developed to watermark multimedia like audios [11] and motion pictures [10], as well as textual contents [26, 52]. In some cases, however, attackers can remove trivially detectable watermarks. Resilience against detection and removal remains the main objective of watermarking research.

Another weakness of relying on watermarking for piracy tracking is that detection often relies on the content being leaked and shared on the Internet, and it remains difficult to detect offline sharing and contents that are stolen but not shared at all.

##### Trusted Execution Environments

A potential game-changer is the use of Trusted Execution Environments (TEEs). Since the traditional execution environment could potentially be under adversarial control, TEE vendors typically leverage separation mechanisms enforced by the hardware platform to create an isolated execution environment, the internal execution state of which even the OS cannot inspect. However, depending on implementations, cryptographic code running inside an isolated environment like Intel SGX might still be susceptible to cache timing attacks [13, 25].

In the TEE trust model, the vendors would typically serve as the trusted party, ensuring the integrity and confidentiality of the executed code and data.