### Protobuf Encoding and Model Identification

In Protobuf, each field is defined by a `field_number` and a `wire_type`. The `field_number` is the unique identifier for the field, while the `wire_type` specifies the data type of the field. A typical Protobuf model begins with a message where the first field defines the model name (e.g., `VGG_CNN_S`). This initial field usually has a `wire_type` of 2 (indicating a length-delimited string) and a `field_number` of 0, which corresponds to the encoded key "0A". This key is typically the first byte in the Protobuf-encoded model. Due to alignment, this key is placed at a four-byte aligned address within the buffer, serving as an encoding signature.

### Model Formats and Signatures

Different model formats and representations have their own content and encoding signatures. For example, TFLite models often include "TFL2" or "TFL3" as version numbers. Some models are stored in JSON format, with easily identifiable field names. Models from unknown frameworks or with unknown encoding formats can be challenging to identify in memory. In such cases, we assume that the buffer size of the decrypted model matches that of the encrypted model, which has proven to be a reliable method in practice. This is because, during decryption, programmers typically allocate a buffer of the same size as the encrypted content, making it both convenient and safe.

### ModelXtractor Workflow and Evaluation

#### Workflow
- **Model Loading and Decryption**: The left side of Figure 7 illustrates the typical workflow of model loading and decryption in mobile apps.
- **ModelXtractor Workflow**: The right side of Figure 7 shows the workflow of ModelXtractor, with matching colors indicating the same timing of strategies used.
- **SDK License Check**: Before releasing the decryption keys, a model provider will check the appâ€™s SDK license to protect its intellectual property.

#### Evaluation
- **Model Verification**: ModelXtractor performs a two-step verification: confirming the extracted model's validity and verifying that it matches the encrypted model. Publicly available parsers like protobuf decoder and Netron are used for validation.
- **Google Play Apps**: Out of 47 ML apps on Google Play that use encryption, ModelXtractor was applied to 23 randomly selected apps. Decrypted models were successfully extracted from 9 of them. The remaining 14 apps had various issues, such as not using encryption, not using ML, or being unable to be instrumented or installed.
- **Chinese App Markets**: Among 819 apps from Chinese markets, 59 were selected based on model popularity and app diversity. Despite non-technical difficulties, 16 apps were successfully analyzed, and decrypted models were extracted from 9 of them.
- **Limitations**: ModelXtractor failed to extract 11 models due to instrumentation strategy limitations. These strategies are designed to highlight the insufficient protection of ML models in mobile apps rather than to extract every protected model.

### Findings and Insights

#### Dynamic Model Extraction
- **Extraction Rate**: Among 29 apps with triggered ML functionalities, models were successfully extracted from 18 (66%). Considering model reuse, 347 apps were affected by the extraction, indicating a significant vulnerability in current model protection techniques.
- **Table 6**: Statistics on 82 analyzed apps, grouped by ML frameworks, showing the number of unique models, analyzed apps, triggered ML, extracted models, missed models, and affected apps.

#### Table 7: Overview of Successfully Dumped Models
| App Name | Downloads | Format | Framework | Model Functionality | Size (B) | Reuses | Extraction Strategy |
|----------|-----------|--------|-----------|---------------------|----------|--------|---------------------|
| Anonymous App 1 | 300M | FlatBuffer | TFLite | Liveness Detection | 160K | 18 | Freed Buffer |
| Anonymous App 2 | 10M | Protobuf | Caffe | Face Tracking | 1.5M | 4 | Model Loading |
| Anonymous App 3 | 27M | Protobuf | SenseTime | Face Tracking | 2.3M | 77 | Freed Buffer |
| ... | ... | ... | ... | ... | ... | ... | ... |

#### Key Observations
- **Memory Protection**: Most decrypted models (12 out of 15) were captured using the default strategy when model buffers were about to be freed, indicating a lack of proper in-memory data protection.
- **Popularity and Diversity**: Extracted models are highly popular and diverse, with some being security-critical. They span various frameworks and are used for functions like face recognition, liveness detection, and malware classification.
- **Reusability**: Over 81% of the extracted models can be directly used by attackers, with only a few requiring reverse engineering to recover feature vectors.
- **License Protection**: Poor protection of SDK/licenses was observed, making it possible to steal licenses and illegally use the SDKs.

### Interesting Cases of Model Protection

- **Encrypting Both Code and Model Files**: An app using the Anyline OCR SDK encrypts both the code and model files. Despite the extra protection, ModelXtractor was able to extract the TensorFlow model buffers from the heap memory.
- **Encrypting Feature Vectors and Formats**: A malware detection app encrypts the feature vectors instead of the model file. Although the model itself is not encrypted, the feature vectors are, adding an additional layer of protection.

These findings highlight the need for more robust and comprehensive protection mechanisms for ML models in mobile applications.