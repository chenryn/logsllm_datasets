title:Differentially Private Publishing of High-dimensional Data Using Sensitivity
Control
author:Wei-Yen Day and
Ninghui Li
Differentially Private Publishing of High-dimensional Data
Using Sensitivity Control
Wei-Yen Day
Department of Computer Science
Purdue University
West Lafayette, IN USA
PI:EMAIL
Ninghui Li
Department of Computer Science
Purdue University
West Lafayette, IN USA
PI:EMAIL
ABSTRACT
In this paper, we present DPSense, an approach to publish statis-
tical information from datasets under differential privacy via sensi-
tivity control. More speciﬁcally, we consider the problem of pub-
lishing column counts for high-dimensional datasets, such as query
logs or the Netﬂix dataset. The key challenge is that as the sen-
sitivity is high, high-magnitude noises need to be added to satisfy
differential privacy. We explore how to effectively performs sen-
sitivity control, i.e., limiting the contribution of each tuple in the
dataset. We introduce a novel low-sensitivity quality function that
enables one to effectively choose a contribution limit while satis-
fying differential privacy. Based on DPSense, we further pro-
pose an extension to correct the under-estimation bias, which we
call DPSense-S. Experimental results show that our proposed ap-
proaches advance the state of the art for publishing noisy column
counts and for ﬁnding the columns with the highest counts. Finally,
we give the analysis and discussion for the stability of DPSense
and DPSense-S, which beneﬁts from the high correlation between
quality function and error, as well as other insights of DPSense,
DPSense-S, and existing approaches.
Categories and Subject Descriptors
K.4.1 [COMPUTERS AND SOCIETY]: Privacy
General Terms
Algorithms
Keywords
Differential privacy; Private data publishing; High-dimensional data
1.
INTRODUCTION
Private data publishing has enabled researchers to utilize the data
without personal privacy breach. The statistics from dataset of-
ten contain useful information, such as the frequencies of terms in
query logs that users have used, the frequent items bought from cus-
tomers in transaction, or the information about medical prescrip-
tions of patients. Releasing such information may disclose personal
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
ASIA CCS’15, April 14 - 17, 2015, Singapore, Singapore
Copyright c(cid:13) 2015 ACM 978-1-4503-3245-3/15/04 ...$15.00.
http://dx.doi.org/10.1145/2714576.2714621.
sensitive information, e.g., a person used certain terms to query, or
a person has some diseases. Techniques for private data publishing
are thus needed. In recent years, -differential privacy [7] has grad-
ually become the de facto standard privacy deﬁnition in research
on private data publishing. Differential privacy ensures that any
person’s private information will not be inferred by perturbing data
with noise. The problem of data publishing under differential pri-
vacy has been widely investigated by researchers. Publishing infor-
mation about high-dimensional dataset while satisfying differential
privacy, however, remains a challenge.
In this paper, we study the problem of publishing column counts
for high-dimensional binary datasets. In this problem, each tuple
in the input dataset D is a binary vector in {0, 1}d, where d can
be very large. The count of a column is the number of 1’s in that
column. The goal is to release the counts for all columns. Exam-
ples of such datasets include query logs where each tuple represents
the keywords that one user has addressed in search query, transac-
tional datasets where each tuple represents the items purchased in a
transaction, and so on. Publishing the column counts does not pub-
lish all information in the original dataset, but the counts represents
important and useful statistical information for many applications,
such as top-used keywords in query logs or popularity of items in
an online store. The techniques we develop in this paper also apply
to non-binary datasets where a cell may contain a number larger
than 1.
The main challenge in this problem is the very large dimension-
ality of such dataset. For example, d in query logs data represents
the number of unique terms that all users have used in a certain
period, or in movie-rating dataset d stands for the total number of
movies. The naive approach of adding Laplacian noises to the out-
put vector of all column counts works poorly because the sensi-
tivity is very high. Since adding one tuple where all entries are
1 increases each column count by 1, the total sensitivity is d, the
number of columns. In most datasets, the number of columns is
much larger than the average column count, thus the amount of
noises added completely overwhelms the data.
One approach to deal with the high sensitivity is to set an upper
threshold θ on the row counts. If one row has total count larger than
θ, the row can be normalized such that each non-zero cell now has
a fraction count, or sampled to contain only θ non-zero cells. With
limited sensitivity, less noise is needed. This approach has been
proposed in [9, 3, 14]. The key challenge here is how to choose the
threshold θ, which depends on both the dataset D and the privacy
parameter . Increasing θ reduces errors caused by normalization,
but increases errors due to the added noise. In the literature so far,
it is assumed that θ is manually set. Choosing θ systematically in a
differentially private way, however, remains unresolved.
451In this paper, we solve this challenge by proposing DPSense
and DPSense-S. DPSense chooses a θ, computes a sensitivity-
limited dataset, and then adds noises to the column counts of such
dataset. To choose θ, we introduce a low-sensitivity quality func-
tion for θ that enables one to use the exponential mechanism to
choose a desired θ. We design the quality function to consider both
the property of dataset and the effect from adding noise. With θ-
limited dataset, less noise is injected and the published noisy counts
is more accurate. DPSense-S tries to also correct the systematic
underestimation caused by sensitivity limitation, by choosing both
θ and a scaling factor α simultaneously, generating noisy count
from θ-limited dataset, and multiplying the noisy count by α to
correct underestimation. The quality function used to choose (θ, α)
estimates the error after sensitivity limitation, noise addition, and
scaling.
We have conducted experiments on six datasets. These datasets
are from various domains and have different properties, such as
number of columns, maximum row counts, average column counts,
and so on. We use several utility metrics, including the Mean Ab-
solute Error (MAE) of all column counts and the Mean Relative Er-
ror (MRE), which were used in [15]. We observe that when given
a high-dimensional dataset, one may be more interested in ﬁnd-
ing information about the columns with the highest counts, since
for columns with low counts, the published noisy counts are likely
to be mostly noise. In this paper we also use four other metrics:
the accuracy for ﬁnding the k columns with the highest counts,
NDCG of ranking top k columns, and the MAE and MRE for the
k columns that have the highest true counts. Experimental results
show that DPSense and DPSense-S signiﬁcantly outperform ex-
isting methods for publishing column counts, and they also outper-
form existing methods for ﬁnding the k most frequent columns.
To summarize, the contributions of our paper are as follows:
1. We have advanced the state of the art for publishing column
counts in high-dimensional datasets while satisfying differ-
ential privacy, signiﬁcantly outperforming the methods in the
literature [15, 8, 23]. Our proposed approaches also outper-
form state of the art methods in ﬁnding the k most frequent
items [19]. We also show that these approaches can be ex-
tensible to non-binary dataset.
2. We have introduced a low-sensitivity quality function that
enables the use of the exponential mechanism to choose a
good threshold θ for limiting the sensitivity. We also demon-
strate interesting relationships between our quality function
and the actual MAE, further illustrating the advantage of the
quality function. This techniques could be applied for pub-
lishing other information of high-dimensional datasets.
3. We have introduced a way to correct the systematic under-
estimation caused by limiting sensitivity, and introduced a
novel method to choose a pair of (θ, α) that together per-
form well. The resulting DPSense-S method further en-
hances the utility preservation of DPSense and gives the
best result under the task of publishing column counts for
high-dimensional data.
The rest of this paper is organized as follows. Section 2 pro-
vides a brief introduction to -differential privacy and the common
mechanisms for achieving it. We describe the problem deﬁnition
and previous approaches in Section 3.
In Section 4, we present
DPSense and DPSense-S. Experimental results as well as their
analyses are given in Section 5. We discuss related work in Section
6, and conclude in Section 7.
2. PRELIMINARIES
Informally, differential privacy requires that the output of a data
analysis mechanism be approximately the same, even if any single
tuple in the input database is arbitrarily added or removed.
DEFINITION 1
(-DIFFERENTIAL PRIVACY [7, 8]). A random-
ized mechanism A gives -differential privacy if for any pair of
neighboring datasets D and D(cid:48), and any S ∈ Range(A),
Pr [A(D) = S] ≤ e · Pr(cid:2)A(D
) = S(cid:3) .
(cid:48)
In this paper we consider two datasets D and D(cid:48) to be neighbors
if and only if either D = D(cid:48)∪{t} or D(cid:48) = D∪{t}, where D∪{t}
denotes the dataset resulted from adding the tuple t to the dataset
D. We use D (cid:39) D(cid:48) to denote this. This protects the privacy of any
single tuple, because adding or removing any single tuple results in
e-multiplicative-bounded changes in the probability distribution
of the output. If any adversary can make certain inference about a
tuple based on the output, then the same inference is also likely to
occur even if the tuple does not appear in the dataset.
Differential privacy is composable in the sense that combining
multiple mechanisms that satisfy differential privacy for 1,··· , m
results in a mechanism that satisﬁes -differential privacy for  =
i i. Because of this, we refer to  as the privacy budget of a
privacy-preserving data analysis task. When a task involves mul-
tiple steps, each step uses a portion of  so that the sum of these
portions is no more than .
(cid:80)
There are several approaches for designing mechanisms that sat-
isfy -differential privacy. In this paper we use two of them. The
ﬁrst approach computes a function g on the dataset D in a differen-
tially privately way, by adding to g(D) a random noise. The mag-
nitude of the noise depends on GSg, the global sensitivity or the L1
sensitivity of g. In this method, g may output a vector value. Such
a mechanism Ag is given below:
Ag(D) = g(D) +
(D,D(cid:48)):D(cid:39)D(cid:48) ||g(D) − g(D(cid:48))||1,
max
2λ e−|x|/λ
GSg =
Lap

Pr [Lap (λ) = x] = 1
where
and
(cid:68)
(cid:16) GSg
(cid:17)(cid:69)
In the above, Lap (λ) denotes a random variable sampled from the
Laplace distribution with scale parameter λ, and (cid:104)Lap (λ)(cid:105) denote
a vector of the same dimension as that of g such that each element
is sampled independently according to Lap (λ). This is generally
referred to as the Laplacian mechanism for satisfying differential
privacy.
The second approach computes a function g on a dataset D by
sampling from the set of all possible answers in the range of g ac-
cording to an exponential distribution, with answers that are “more
accurate” will be sampled with higher probability. This is generally
referred to as the exponential mechanism [20]. This approach re-
quires the speciﬁcation of a quality function q : D×R → R, where
the real valued score q(D, r) indicates how accurate it is to return r
when the input dataset is D. Higher scores indicate more accurate
outputs which should be returned with higher probabilities. Given
the quality function q, its global sensitivity GSq is deﬁned as:
GSq = max
, r)|
The following method M satisﬁes -differential privacy:
(D,D(cid:48)):D(cid:39)D(cid:48) |q(D, r) − q(D
max
(cid:48)
r
Pr [M(D) = r] ∝ exp
(1)
For example, if q(D, r1) − q(D, r2) = 1, then r1 should be re-
turned exp
times more likely than r2. The larger the expo-
(cid:16) 
q(D, r)
2 GSq
(cid:17)
2 GSq
(cid:18) 
(cid:19)
452is, the more likely that M will return the higher quality
1. Random grouping.

2 GSq
nent
result.
such that the sensitivity is g ∆D
grouped together.
In this strategy, g is chosen to be
d
∆D
d = 1. Columns are randomly
(cid:17)
.
2. Sampling and sorting. In this strategy, g is chosen to be d
∆D
such that the sensitivity is ∆D g
d = 1. However, instead of
random grouping, grouping is based on noisy sampled col-
umn counts for all columns. More speciﬁcally, one ﬁrst ob-
tains a sampled dataset as follows: For each tuple that con-
tains 1’s, one randomly samples exactly one of the 1’s and
set other entries to 0. Since now each tuple can contribute an
increment of 1 to at most one among all columns, the sensi-
tivity of publishing all column counts of the sampled dataset
is 1. One then uses half of the privacy budget to add noises
to these column counts, and group columns by sorting the
columns based on their noise sample counts and dividing the
sorted columns into g equal-size groups. This aims at group-
ing columns with similar true counts together. Finally, one
uses the remaining half of the privacy budget to obtain noise
average column counts for each group.
3. Sampling, sorting, and choosing optimal group size. This
strategy is similar to sampling and sorting except that the
; instead using the
number of groups is not ﬁxed to be
noisy sampled group counts, one estimates the error of choos-
ing different number of groups and chooses g to minimize
such error.
d
∆D
In [15], it was shown that the last strategy (referred to as GS)
performs the best. We compare with this method in our experi-
ments.
3.2 Other Approaches
In [15], the Grouping and Smoothing approach was compared
with two other approaches. The naive Laplace Perturbation Algo-
rithm [8] (referred to as LPA) adds Laplacian noise to the column
counts. In our paper, as in [15], we use ∆D instead of d as the
sensitivity for the LPA method, in order to have a fair comparison
between GS and LPA.
The Fourier Perturbation Algorithm [23] (referred to as FPA),
was originally designed to publish noisy time-series data. The
centralized mechanism of [23] assumes the rows in database are
time-series, and columns are timestamps. FPA ﬁrst applies Dis-
crete Fourier Transform (DFT) on the column count Q(D).
It
then chooses the ﬁrst k (cid:28) d DFT coefﬁcients and injects Laplace
√
noise to them. The magnitude of noise in FPA is set to be λ =
k∆2(Q)/, where ∆2(Q) is the L2 sensitivity of query Q, and
 is the privacy budget. Finally, it applies inverse DFT on the noisy
coefﬁcients and then publishes the noisy column counts. It may
require less noise compared to LPA, but may also cause the utility
loss depending on the quality of the DFT approximation.
In addition to GS, LPA, and FPA, we also compare with the
Average Laplace Perturbation Algorithm (referred to as ALPA),
which injects Laplace noise on the average of all column counts in