16,384 KB 16,992 KB
17,280 KB 20,800 KB
(100%)
(120%)
262,144
16,992 KB
20,256 KB
(117%)
9.2 Power Consumption Overheads
The larger tag-store in Mirage has a higher static leak-
age power when idle and also consumes more energy per
read/write access. Table 9 shows the static and dynamic power
consumption for Mirage in 32nm technology estimated using
CACTI-6.0 [34], which reports the energy/access and static
leakage power consumption for different cache organizations.
We observe the LLC power is largely dominated by the static
leakage power compared to dynamic power (in line with prior
CPU power modeling studies [16]). The static power in Mi-
rage (reported by CACTI) increases by 3.5-4.1W (18%-21%)
in proportion to the storage overheads, whereas the dynamic
power, calculated by multiplying the energy/access (from
CACTI) by the total LLC-accesses per second (from our sim-
ulations), shows an insigniﬁcant increase of 0.02W on aver-
age. The increase in LLC power consumption of 4W (21%)
in Mirage is quite small compared to the overall chip power
budget, with comparable modern 8-core Intel/AMD CPUs
having power budgets of 95-140W [2].
Table 9: Energy and Power Consumption for Mirage
Design
Baseline
Mirage
Mirage-Lite
Energy /
Access (nJ) Power (W)
Dynamic Static Leakage
Total
0.61
0.78
0.73
0.06
0.08
0.08
Power (W)
Power (W)
19.2
23.3
22.7
19.3
23.4
22.8
9.3 Logic Overheads
Mirage requires extra logic for the set-index computation us-
ing the randomizing hash-function and FPTR-indirection on
cache-lookups, and for load-aware skew-selection and RPTR-
indirection based tag-invalidation on a cache-miss. Our syn-
thesis results in 15nm technology show that the PRINCE-
based randomizing hash-function occupies 5460 um2 area or
27766 Gate-Equivalents (GE - number of equivalent 2-input
NAND gates) and the FPTR-indirection based lookup circuit
requires 132 um2 area or 670 GE. The load-aware skew-
selection circuit (counting 1s among valid bits of 14 tags from
the indexed set in each skew, followed by a 4-bit comparison)
requires 60 um2 or 307 GE, while the RPTR-lookup circuit
complexity is similar to the FPTR-lookup. Overall, all of the
extra logic (including the extra control state-machine) can ﬁt
in less than 35,000 GE, occupying a negligible area compared
to the several million gates required for the LLC.
10 Related Work
Cache design for reducing conﬂicts (for performance or secu-
rity) has been an active area of research. In this section, we
compare and contrast Mirage with closely related proposals.
USENIX Association
30th USENIX Security Symposium    1391
10.1 Secure Caches with High Associativity
The concept of cache location randomization for guarding
against cache attacks was pioneered almost a decade ago,
with RPCache [54] and NewCache [55], for protecting L1
caches. Conceptually, such designs have an indirection-table
that is consulted on each cache-access, that allows mapping an
address to any cache location. While such designs can be im-
plemented for L1-Caches, there are practical challenges when
they are extended to large shared LLCs. For instance, the
indirection-tables themselves need to be protected from con-
ﬂicts if they are shared among different processes. While RP-
Cache prevents this by maintaining per-process tables for the
L1 cache, such an approach does not scale to the LLC that may
be used by several hundred processes at a time. NewCache
avoids conﬂicts among table-entries by using a Content-
Addressable-Memory (CAM) to enable a fully-associative
design for the table. However, such a design is not practical for
LLCs, which have tens of thousands of lines, as it would im-
pose impractically high power overheads. While Mirage also
relies on indirection for randomization, it eliminates conﬂicts
algorithmically using load-balancing techniques, rather than
relying on per-process isolation that requires OS-intervention,
or impractical fully-associative lookups and CAMs.
Phantom-Cache [51] is a recent design that installs an
incoming line in 1 of 8 randomly chosen sets in the cache,
each with 16-ways, conceptually increasing the associativity
to 128. However, this design requires accessing 128 locations
on each cache access to check if an address is in the cache or
not, resulting in a high power overhead of 67% [51]. Moreover,
this design is potentially vulnerable to future eviction set
discovery algorithms as it selects a victim line from only a
subset of the cache lines. In comparison, Mirage provides the
security of a fully-associative cache where any eviction-set
discovery is futile, with practical overheads.
HybCache [12] is a recent design providing fully-
associative mapping for a subset of the cache (1–3 ways),
to make a subset of the processes that map their data to this
cache region immune to eviction-set discovery. However, the
authors state that “applying such a design to an LLC or a
large cache in general is expensive” [12]. For example, im-
plementing a fully-associative mapping in 1 way of the LLC
would require parallel access to >2000 locations per cache-
lookup that would considerably increase the cache power and
access latency). In contrast, Mirage provides security of a
fully-associative design for the LLC with practical overheads,
while accessing only 24–28 locations per lookup.
10.2 Cache Associativity for Performance
V-Way Cache [41], which is the inspiration for our design,
also uses pointer-based indirection and extra tags to reduce
set-conﬂicts – but it does not eliminate them. V-Way Cache
uses a set-associative tag-store, which means it is still vulner-
able to set-conﬂict based attacks, identical to a traditional set-
associative cache. Mirage builds on this design and incorpo-
rates skewed associativity and load-balancing skew-selection
to ensure set-conﬂicts do not occur in system-lifetime.
Z-Cache [45] increases associativity by generating a larger
pool of replacement candidates using a tag-store walk and
performing a sequence of line-relocations to evict the best vic-
tim. However, this design still selects replacement candidates
from a small number of resident lines (up to 64), limited by
the number of relocations it can perform at a time. As a result,
a few lines can still form an eviction set, which could poten-
tially be learned by attacks. Whereas, Mirage selects victims
globally from all lines in the cache, eliminating eviction-sets.
Indirect Index Cache [21] is a fully-associative design
that uses indirection to decouple the tag-store from data-
blocks and has a tag-store designed as a hash-table with chain-
ing to avoid tag-conﬂicts. However, such a design introduces
variable latency for cache-hits and hence is not secure. While
Mirage also uses indirection, it leverages extra tags and power
of 2 choices based load-balancing, to provide security by
eliminating tag-conﬂicts and retaining constant hit latency.
Cuckoo Directory [15] enables high associativity for
cache-directories by over-provisioning entries similar to
our work and using cuckoo-hashing to reduce set-conﬂicts.
SecDir [62] also applies cuckoo-hashing to protect directories
from conﬂict-based attacks [61]. However, cuckoo-hashing
alone is insufﬁcient for conﬂict-elimination. Such designs im-
pose a limit on the maximum number of cuckoo relocations
they attempt (e.g. 32), beyond which they still incur an SAE.
In comparison, load-balancing skew selection, the primary
mechanism for conﬂict-elimination in Mirage, is more robust
at eliminating conﬂicts as it can ensure no SAE is likely to
occur in system-lifetime with 75% extra tags.
10.3
Isolation-based Defenses for Set-Conﬂicts
Isolation-based defenses attempt to preserve the victim lines
in the cache and prevent conﬂicts with the attacker lines. Prior
approaches have partitioned the cache by sets [10, 42] or
ways [26,28,54,64] to isolate security-critical processes from
potential adversaries. However, such approaches result in sub-
optimal usage of cache space and are unlikely to scale as
the number of cores on a system grows (for example, 16-way
cache for a 64-core system). Other mechanisms explicitly lock
security-critical lines in the cache [25, 54], or leverage hard-
ware transactional memory [17] or replacement policy [59]
to preserve security-critical lines in the cache. However, such
approaches require the classiﬁcation of security-critical pro-
cesses to be performed by the user or by the Operating-System.
In contrast to all these approaches, Mirage provides robust
and low-overhead security through randomization and global
evictions, without relying on partitioning or OS-intervention.
1392    30th USENIX Security Symposium
USENIX Association
11 Conclusion
Shared LLCs are vulnerable to conﬂict-based attacks. Exist-
ing randomized LLC defenses continue to be broken with
advances in eviction-set discovery algorithms. We propose
Mirage as a principled defense against such attacks. Provid-
ing the illusion of a fully-associative cache with random-
replacement, Mirage guarantees the eviction of a random
line on every cache-ﬁll that leaks no address information, for
104−1017 years. Mirage achieves this strong security with 2%
slowdown and modest area overhead of 17-20%, compared
to a non-secure set-associative LLC. Thus, Mirage provides a
considerable safeguard against current eviction-set discovery
algorithms and potentially against even future advances.
Acknowledgments
We thank Ananda Samajdar for help in setting up the RTL
synthesis tool-chain. We also thank the anonymous reviewers
and members of Memory Systems Lab, Georgia Tech for their
feedback. This work was supported in part by SRC/DARPA
Center for Research on Intelligent Storage and Processing-in-
memory (CRISP) and a gift from Intel. Gururaj Saileshwar is
partly supported by an IISP Cybersecurity PhD Fellowship.
References
[1] David H Albonesi. An architectural and circuit-level
approach to improving the energy efﬁciency of micro-
processor memory structures. In VLSI: Systems on a
Chip, pages 192–205. Springer, 2000.
[2] AnandTech. Intel 9th Generation Power Consumption.
https://www.anandtech.com/show/13400/intel-
9th-gen-core-i9-9900k-i7-9700k-i5-9600k-
review/21.
[3] Roberto Avanzi. The qarma block cipher family. almost
mds matrices over rings with zero divisors, nearly sym-
metric even-mansour constructions with non-involutory
central rounds, and search heuristics for low-latency s-
boxes. IACR Transactions on Symmetric Cryptology,
pages 4–44, 2017.
[4] Yossi Azar, Andrei Z Broder, Anna R Karlin, and Eli Up-
fal. Balanced allocations. SIAM journal on computing,
29(1):180–200, 1999.
[5] Daniel J. Bernstein. Cache-timing attacks on AES.
2005.
[6] David Biancolin, Sagar Karandikar, Donggyu Kim, Jack
Koenig, Andrew Waterman, Jonathan Bachrach, and
Krste Asanovic.
Fased: Fpga-accelerated simula-
In Proceedings of the
tion and evaluation of dram.
2019 ACM/SIGDA International Symposium on Field-
Programmable Gate Arrays, pages 330–339, 2019.
[7] Nathan Binkert, Bradford Beckmann, Gabriel Black,
Steven K Reinhardt, Ali Saidi, Arkaprava Basu, Joel
Hestness, Derek R Hower, Tushar Krishna, Somayeh
Sardashti, et al. The gem5 simulator. ACM SIGARCH
computer architecture news, 39(2):1–7, 2011.
[8] Rahul Bodduna, Vinod Ganesan, Patanjali SLPSK, Ka-
makoti Veezhinathan, and Chester Rebeiro. Brutus:
Refuting the security claims of the cache timing ran-
domization countermeasure proposed in ceaser. IEEE
Computer Architecture Letters, 19(1):9–12, 2020.
[9] Julia Borghoff, Anne Canteaut, Tim Güneysu, Elif Bilge
Kavun, Miroslav Knezevic, Lars R Knudsen, Gregor Le-
ander, Ventzislav Nikov, Christof Paar, Christian Rech-
berger, et al. PRINCE–a low-latency block cipher for
pervasive computing applications. In International con-
ference on the theory and application of cryptology and
information security, pages 208–225. Springer, 2012.
[10] Thomas Bourgeat, Ilia Lebedev, Andrew Wright, Sizhuo
Zhang, and Srinivas Devadas. Mi6: Secure enclaves in
a speculative out-of-order processor. In MICRO, 2019.
[11] Samira Briongos, Pedro Malagón, José M Moya, and
Thomas Eisenbarth. Reload+ refresh: Abusing cache
replacement policies to perform stealthy cache attacks.
In 29th USENIX Security Symposium (USENIX Security
20), 2020.
[12] Ghada Dessouky, Tommaso Frassetto, and Ahmad-Reza
Sadeghi. Hybcache: Hybrid side-channel-resilient
In 29th
caches for trusted execution environments.
USENIX Security Symposium (USENIX Security 20),
2020.
[13] Craig Disselkoen, David Kohlbrenner, Leo Porter, and
Dean Tullsen. Prime+ abort: A timer-free high-precision
l3 cache attack using Intel TSX. In 26th USENIX Se-
curity Symposium (USENIX Security 17), pages 51–67,
2017.
[14] John H. Edmondson, Paul I. Rubinfeld, Peter J. Bannon,
Bradley J. Benschneider, Debra Bernstein, Ruben W.
Castelino, Elizabeth M. Cooper, Daniel E. Dever, Dale R.
Donchin, Timothy C. Fischer, et al. Internal organization
of the alpha 21164, a 300-mhz 64-bit quad-issue cmos
risc microprocessor. Digital Technical Journal, 7(1),
1995.
[15] Michael Ferdman, Pejman Lotﬁ-Kamran, Ken Balet, and
Babak Falsaﬁ. Cuckoo directory: A scalable directory
for many-core systems. In 2011 IEEE 17th International
Symposium on High Performance Computer Architec-
ture, pages 169–180. IEEE, 2011.
USENIX Association
30th USENIX Security Symposium    1393
[16] Bhavishya Goel and Sally A McKee. A methodology
for modeling dynamic and static power consumption for
multicore processors. In 2016 IEEE International Par-
allel and Distributed Processing Symposium (IPDPS),
pages 273–282. IEEE, 2016.
[17] Daniel Gruss, Julian Lettner, Felix Schuster, Olya Ohri-
menko, Istvan Haller, and Manuel Costa. Strong and
efﬁcient cache side-channel protection using hardware
transactional memory. In 26th USENIX Security Sympo-
sium (USENIX Security 17), pages 217–233, 2017.
[18] Daniel Gruss, Clémentine Maurice, Anders Fogh,
Moritz Lipp, and Stefan Mangard. Prefetch side-channel
attacks: Bypassing smap and kernel aslr. In Proceedings
of the 2016 ACM SIGSAC conference on computer and
communications security, pages 368–379, 2016.
[19] Daniel Gruss, Clémentine Maurice, Klaus Wagner, and
Stefan Mangard. Flush+ ﬂush: a fast and stealthy cache
attack. In DIMVA, 2016.
[20] Daniel Gruss, Raphael Spreitzer, and Stefan Mangard.
Cache template attacks: Automating attacks on inclusive
last-level caches. In 24th USENIX Security Symposium
(USENIX Security 15), pages 897–912, 2015.
[21] Erik G Hallnor and Steven K Reinhardt. A fully asso-
ciative software-managed cache design. In Proceedings
of 27th International Symposium on Computer Architec-
ture, pages 107–116. IEEE, 2000.
[22] Julian Harttung. PRINCE Cipher VHDL implementa-
tion. https://github.com/huljar/prince-vhdl.
[23] Gorka Irazoqui, Thomas Eisenbarth, and Berk Sunar.