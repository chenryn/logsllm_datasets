dissemination (breach of confidentiality, disclosure, 
exposure, increased accessibility, blackmail, appro-
priation, distortion), and invasion (intrusion, deci-
sional interference).66 This concept begins with the 
data subject (the individual) from which various en-
tities (other people, governments, businesses) col-
lect information. The qualification of the processing 
of information depends on the harmfulness of the re-
spective activities. The next step consists in the in-
formation dissemination, which brings the potential 
control of the information even further away from 
the concerned individual. Finally, privacy could be 
(illegally) invaded by third persons.67
30	 More attention should also be paid to the perspec-
tive of understanding information privacy in a func-
tional sense as a type of public value since it benefits 
and shapes society. From this vantage point, infor-
mation privacy shows characteristics of a commons 
that requires some degree of social and legal con-
trol to construct and then maintain;68 consequently, 
data protection approaches are becoming a part of 
social policy.69 In this sense, the privacy commons 
is a multidimensional “territory” that should be or-
dered through legislation structuring anonymous 
and semi-anonymous information spaces; therefore, 
the propertization of personal information should 
be limited to the extent it undermines the privacy 
commons.70
31	 In a nutshell, the different models described rely to 
a great extent on individual autonomy. Autonomy 
as such could mean that the individual is entitled to 
control the information. However, such an approach 
does not take into account the public interests (such 
as ordre public, security interests, etc.). Therefore, 
the application of a balancing test seems to be un-
avoidable. Before going into the respective details, 
the theoretical approaches already discussed in this 
field will be evaluated. 
III. Privacy Risks’ Mitigation by 
Data Protection Rules 
1.  Potential Legal Responses 
a.  Overview
32	 The most extensive attempt to apply data protection 
principles in the context of the right to be forgotten 
has been undertaken by Mayer-Schönberger. In his 
seminal book Delete, which is inspiring intensive de-
bate in the United States but is not yet fully appre-
ciated in Europe, Mayer-Schönberger discusses in 
depth seven potential (legal) responses that could 
mitigate the ills of digital memory.71 Six of these re-
sponses are described in relatively short comments, 
while the seventh is explained in far-reaching detail: 
 f Digital abstinence:72 At first sight, the solution 
of digital abstinence seems to be simple and 
straightforward  since  it  is  based  on  choice 
and autonomy (at least in transparent circum-
stances): If persons are staying away as much as 
possible from interactions that require reveal-
ing information to others, less “critical” infor-
mation will be available. However, several prob-
lems cannot be overlooked: Digital abstinence is 
definitely based on individuals’ knowledge and 
preferences not being identical throughout the 
whole civil society. Consequently, people’s be-
2
125 
2011
Rolf H. Weber
havior would have to be influenced. Further-
more, the sharing of personal information of-
fers users values that contradict the limitation 
of digital memory; indeed, the participation of 
millions of Internet users around the world in 
creating content has unleashed innovative and 
beneficial forms of information production that 
would not have been possible in a world of digi-
tal abstinence.73 Businesses as well would have 
to adapt their practices and accept substantial 
limitations to digital remembering.
 f Information  privacy  rights:74  This  approach  is 
based on the notion and concept of informa-
tional self-determination: Individuals should 
have control over every phase and stage of the 
use of their personal information. As experience 
has shown in practice, however, the principle of 
consent to data collection as an expression of 
self-determination is very difficult to enact; fur-
thermore, a look at court practice also demon-
strates that liability claims against data collec-
tors not complying with data protection laws are 
very rare. Certain procedural measures could 
obviously be introduced, such as shifting the 
burden of proof to the data collector that the 
individual concerned has agreed to the digital 
remembering. Another approach tries to under-
lay the right to self-determination with a prop-
erty rights concept; the elements of this concept 
have already been outlined.75
 f Digital privacy rights infrastructure:76 More than 
10 years ago, Lawrence Lessig suggested using 
Digital Rights Management (DRM) infrastruc-
ture as a means to protect technical code.77 DRM 
was developed for intellectual property rights, 
mainly by the (Hollywood) entertainment in-
dustry in its attempt to prevent the copying of 
protected works. In the meantime, even DRM’s 
promoters are no longer so convinced that this 
infrastructure provides an adequate protection 
measure. Even more questions are justified if 
DRM is to control personal information. Any sys-
tem capable of making judgments would have 
to watch how users handle protected informa-
tion.78 Therefore, the risk exists that a technical 
infrastructure of pervasive surveillance would 
be created (a panopticon to protect from the In-
ternet society). Further problems concern the 
related costs and practicability of a new tech-
nological infrastructure.79
 f Cognitive adjustment:80 This approach would not 
require changing society through the adoption 
of law or the development and implementation 
of a novel technical infrastructure, but the nec-
essary changes would take place in the minds of 
civil society. Whether such a change could be re-
alized is another question; acknowledging cog-
nitive adaptation related to a comprehensive 
digital memory might be an expectation that is 
too ambitious.
 f Information ecology:81 Advocates for a more strin-
gent and comprehensive information ecology 
have been raising their voice for many years and 
asking information processors to slow down the 
speed of information collection and storage.82 
However, several conceptual weaknesses can-
not be overlooked – for example, the problem 
that mandated information ecology might be a 
binary tool and that practical experience with 
norms  trying  to  realize  information  ecology 
shows the difficulty of getting them politically 
enacted.  Finally,  such  norms  are  confronted 
with a certain lack of built-in flexibility. 
 f Perfect contextualization:83 This approach tries to 
apply the “knowledge” of technical systems in 
remembering information and in limiting data 
collection  of  information  not  related  to  the 
given context. Obviously, a technically perfect 
contextualization will never be possible. In ad-
dition, such systems need sustained attention, 
which is not always available. 
33	 Mayer-Schönberger summarizes the above six re-
sponses to the demise of forgetting under the head-
ings  of  “Information  Power”  and  “Cognition”  as 
follows.84
Information	
Power
(incl.	informa-
tion	privacy)
Individuals
Digital abstinence
Laws
Privacy rights
Technology
Privacy DRM
Cognition,
Decision-Making	
and	Time
Cognitive adjust-
ment
Information 
ecology
Full contextual-
ization 
b.  Expiration Dates on Digital Data in Particular
34	 The seventh response to the demise of forgetting is 
the already briefly mentioned introduction of expi-
ration dates on digital information:85 Mayer-Schön-
berger argues that, technically (design challenges 
for the most appropriate user interface aside), expi-
ration dates would be relatively easy to implement 
(just as another type of meta-information associated 
with a piece of information). Thereby, the role of in-
formation processors would become more impor-
tant, and the development of algorithms that would 
better approximate what kind of information should 
still be available for use would become crucial. If ex-
piration dates on information files are not sufficient, 
2
126 
2011
The Right to Be Forgotten
a more fine-grained approach is necessary, described 
by Mayer-Schönberger as the expiration of infor-
mation bits.86 Technologically, this concept looks at 
cookies as well as the expiration date for web page 
links and web search queries. The advantages of such 
measures are that individual users would not be re-
quired to become familiar with complex new tech-
nologies; they would only need to be aware of how 
to set expiration dates at any given moment.
35	 Furthermore, Mayer-Schönberger also discusses the 
possibility of negotiating expiration dates.87 Indeed, 
particularly in contractual transactions, two par-
ties often have different opinions about the expira-
tion date. In such a case, each individual should in-
dependently determine the duration of the digital 
memory; if the dates do not correspond, a joint un-
derstanding must be negotiated just like other con-
tractual issues. 
36	 The new concept of introducing expiration dates for 
digital information is a challenging approach. Nev-
ertheless, certain weaknesses cannot be overlooked: 
The ubiquity of social networking nowadays is so ex-
tensive that the introduction of “expiration dates”88 
requiring somebody (who?) to delete the informa-
tion is difficult to apply in practice. Furthermore, the 
proposal of “expiration dates” also seems to be in-
adequate and deficient in and of itself since the ap-
proach focuses on self-censorship or a lack thereof, 
contradicting the human desire to chronicle life (to 
the smallest and most trivial detail) and to immor-
talize previously fleeting memories.89 
2.  Potential Technological Responses 
37	 As already mentioned, technology also plays a role 
in the triangle between identity, memory, and pri-
vacy; as of now, governments and civil societies are 
still struggling with new technological realities. In-
deed, technology can provide solutions which - if 
embedded adequately - can contribute to overcom-
ing data protection concerns.90 In practical life, var-
ious factors are responsible for the prevailing public 
uncertainty with technology: Apart from a general 
reluctance to learn new techniques, the technology 
is often highly complex, making it difficult or at least 
cumbersome and time-consuming to apply (for ex-
ample, in the context of electronic signatures). In 
addition, the positive aspects of technology can eas-
ily morph into negative results (from self-control to 
being controlled by others). 
38	 The development and proliferation of devices that 
provide “Continuous Archival and Retrieval of Per-
sonal Experiences” (CARPE) is a good example: In 
realizing the concept of autonomy, such technolo-
gies could improve the control over, the access to, 
and the record of collective knowledge, but they can 
also be used by third persons to exert control in their 
own interest.91 Such technologies are based on the 
desire for individual control over the devices, and 
such individual control might prove determinative 
in the quest for individual and collective empower-
ment through these technologies; however, social 
forces undermine the ability of all netizens to en-
joy control equally.92 In other words, technological 
parameters that rest on an atomistic concept of rel-
atively autonomous individuals do not reflect the 
practical reality.93 Therefore, CARPE devices often 
do not live up to their perceived potential because 
they do not operate in a social vacuum.94 In the end, 
this question arises: How much privacy are individ-
uals prepared to surrender in order to achieve other 
purposes (such as social recognition or an increase 
in security)?95 
39	 The aforementioned evaluation demonstrating some 
reluctance as far as technologies are concerned does 
not mean that any single approach should not be im-
plemented. To the contrary, a number of technol-
ogies are available to achieve information privacy 
goals. In particular, Privacy Enhancing Technologies 
(PETs) can be oriented on the subject, the object, the 
transaction, or the system. Subject-oriented PETs 
aim at limiting the ability of other users to discern 
the identity of a particular organizational entity; 
object-oriented PETs endeavor to protect identities 
through the use of a particular technology; transac-
tion-oriented PETs have the goal of protecting trans-
actional data, e.g., through automated systems for 
destroying such data; and system-oriented PETs are 
designed to create zones of interaction where users 
are hidden and objects bear no traces of data streams 
handling them nor records of interactions.96 Further-
more, technical developments require assessment 
capacity and capability, which need to be pooled on 
a global level; some institutionalized format for pool-
ing available resources of data protection agencies 
on an international level will have to be found, thus 
dipping into the resources of technology assessment 
institutions worldwide.97
40	 Notwithstanding the fact that technology is able to 
substantially back up the idea of giving each indi-
vidual the possibility to autonomously control the 
life of his/her data, it cannot be overlooked that, in 
principle, technology should have a serving func-
tion; it cannot replace the legislator in designing the 
scope and limits of a new fundamental “right to be 
forgotten.” 
D. Outlook 
41	 With the increased tendency to make information 
of all kinds public, privacy is at risk. Notwithstand-
ing existing and planned data protection laws, new 
fundamental right concepts are being developed as 
a consequence. Some two years ago, the German 
2
127 
2011
Rolf H. Weber
Constitutional Court “invented” a so-called “com-
puter confidentiality and integrity right” designed 
to avoid third-party interference with the personal 
electronic communication network.98 About a year 
ago, as mentioned, a right to be forgotten was pro-
posed by France and then by the European Union 
in the context of the revision of the Data Protec-
tion Directive 95/46.99 Nevertheless, as of now there 
is still no concrete description of the right’s scope 
and contents.
1	
2	
tection of Personal Data,” supported by the General Research 
Fund of the University of Hong Kong.
Charte du droit à l’oubli dans les sites collaboratifs et les mo-