# Beyond the Lulz: Black Hat Trolling, White Hat Trolling, and Hacking the Attention Landscape

## Section 1: Understanding Trolling

### Definitions and Historical Context
Trolling, much like fishing, involves setting bait and waiting for a reaction. In the context of the internet, trolling is the act of posting provocative or deceptive content to elicit strong emotional responses from others. This practice has evolved over time, with various definitions and interpretations:

- **Anonymous usenet poster (1995)**: "Trolling on the Net is the same concept - someone baits a post and then waits for the bite on the line and then enjoys the ensuing fight."
- **PI:EMAIL, Troller’s FAQ (1996)**: "A well-constructed troll is a post that induces newbies and flamers to make themselves look even more clueless, while subtly conveying to the more experienced that it is a deliberate troll."
- **Urban Dictionary (2004)**: "Being a prick on the internet because you can, typically by unleashing cynical or sarcastic remarks on an innocent bystander."
- **Bruce Schneier (2007)**: "A smart vendor treats vulnerabilities as a PR problem. If we want software vendors to patch vulnerabilities, we need to make the PR problem more acute."
- **Gabriella Coleman (2014)**: "Laughter at the expense or misfortune of others."
- **Brad Troemel (2012)**: "The best challenge to authority is to find where its semantic or enforceable borders break down and exploit those shortcomings."
- **Adrian Chen (2014)**: "We’ve come up with the term 'troll' for someone who spreads hate and does other horrible things anonymously on the internet."
- **Whitney Phillips (2015)**: "Until sensationalist, exploitative media practices are no longer rewarded, the most aggressive forms of trolling will always have an outlet and an audience."

### Key Components of Trolling
- **Users looking to govern or police their communities**
- **Hackers looking to corral attention or pressure vendors**
- **Subcultural trolls looking for ‘lulz’**
- **Artists looking to critique cultural practices**
- **Political actors looking to destabilize the public sphere**
- **Political actors looking to corral attention or attack opponents**

### Elements of a Trolling Event
- **Troll**: The individual or group initiating the troll.
- **Bait**: The provocative or deceptive content.
- **Target**: The intended recipient of the troll.
- **Third-party interpretation**: The audience or community interpreting the exchange.
- **Intended outcome**: The desired result of the troll.
- **Possible amplification**: The spread of the troll through social media, news, etc.
- **Possible political reframing and subsequent amplification**: The recontextualization of the troll for political gain.

### Concepts and Theories
- **Cognitive Hacking**: Manipulating people's perceptions and beliefs.
- **Attention Hacking**: Exploiting the human need for attention.
- **Cognitive Denial of Service**: Overwhelming individuals with information to prevent them from processing it effectively.
- **Exploiting Socio-Technical Vulnerabilities**: Using weaknesses in both social and technical systems.
- **Poe’s Law**: It is difficult to distinguish between sincere extremism and parody.
- **Context Collapse**: The flattening of different social contexts into one.
- **Network Anonymity and Ephemerality**: The ability to remain anonymous and the temporary nature of online interactions.
- **Cross-Platform Ambiguity**: The confusion caused by the same content appearing in different contexts.
- **Attention Economics**: The high cost of verifying information.
- **Lack of Trust**: The erosion of trust in online interactions.

### Objectives of Trolling
- **Draw attention to ignored issues (agenda setting)**
- **Distract attention from issues**
- **Put pressure on entities (accountability)**
- **Elicit a telling response (transparency)**
- **Deny a response**
- **Diminish an opponent’s resources or morale**
- **Design vulnerabilities**
- **Intent (public good) vs. Reality (profit)**
- **Latent affordances**: Hidden features or uses of a system.

### Analogies
- **Trolling is to socio-technical systems what hacking is to technical systems**. Both involve exploiting vulnerabilities, but in different domains.

## Section 2: White Hat Trolling

### Agenda Setting and Attention Economics
- **Agenda Setting (from below)**: Influencing public discourse from grassroots levels.
- **Attention is a scarce resource**: Competing for attention in a crowded media landscape.
- **Legacy gatekeepers (media) vs. network gatekeepers (social media)**: Traditional media outlets versus new, decentralized platforms.

### Trolling as Social Engineering
- **Gaining access to closed systems**: Using social engineering techniques to access and influence audiences.
- **Key stakeholders**:
  - **Newspaper editors and reporters**
  - **Platform designers / vendors**
  - **Platform algorithms**
  - **Content moderators**
  - **Advertisers**
  - **Users with framing or curating capacity**

### Strategies and Tactics
- **Exploiting gatekeeper vulnerabilities**: Leveraging weaknesses in traditional and new media.
- **Eliciting changes to gatekeeping practices**: Pushing for reforms in how information is curated and presented.
- **Disclosing dynamics inherent to gatekeeping**: Revealing the mechanisms and biases in information control.
- **Posing as gatekeepers**: Impersonating authoritative figures to manipulate information.
- **Capturing legacy gatekeeper resources / audiences**: Redirecting traditional media audiences to new platforms.
- **Clickbait and breaking news**: Using sensational headlines to attract attention.
- **Network curation**: Selectively promoting or demoting content.
- **Asymmetric cost to debunk**: The high cost of verifying and countering misinformation.
- **Automated amplification (bots)**: Using bots to spread content.
- **Adtech**: Leveraging advertising technology to target and influence audiences.
- **Context collapse / Poe’s Law / Anonymity**: Utilizing the ambiguity and anonymity of online interactions.
- **Pepe as a Trojan Horse**: Using memes to convey hidden messages.
- **Vulnerabilities all the way down**: Recognizing that vulnerabilities exist at multiple levels of the information ecosystem.

### Ethical and Governance Questions
- **Gatekeeper responsibility to users**: What obligations do gatekeepers have to their audiences?
- **Codification of responsibilities**: How are these responsibilities defined and enforced?
- **Paternalistic gatekeeping**: Is it inherently authoritarian?
- **Network gatekeeping**: Is it inherently democratic?
- **Public interest**: When is gatekeeping in the public interest?

## Section 3: Non-Prescribed Engagement and System Alignment

### Non-Prescribed Engagement
- **Pushing private agendas**: Promoting personal or organizational interests.
- **Countering targets’ interests**: Acting against the goals of the target.
- **Demonstrating attack surfaces**: Showing vulnerabilities through proof-of-concept attacks.
- **Trolling as a revelatory moment**: Exposing underlying issues and vulnerabilities.
- **Increasing pressure on gatekeepers**: Forcing changes in information control.
- **Trolling back**: Responding to trolls with counter-trolls.
- **Aligning systems with intent**: Ensuring that systems function as intended.
- **Selective disclosure of vulnerabilities**: Sharing information with platforms and journalists.
- **Disabling non-prescribed engagement**: Reducing the potential for misuse through research and education.
- **Reducing attack surface**: Minimizing vulnerabilities.
- **Creating discursive patches**: Establishing norms and rules to mitigate trolling.

### Ethical and Practical Considerations
- **Incentives and responsibilities**: Who is tasked with responding to trolling, and what are their incentives?
- **Ethics of fun at others’ expense**: What are the ethical implications of deriving pleasure from others’ discomfort?
- **State and political radical adoption**: Has the use of trolling by states and radicals changed the nature of trolling for fun?

## Section 4: Political and Social Dynamics

### Political and Social Tactics
- **Political maneuvering**: Using trolling for political gain.
- **Chaos and scorched earth**: Creating disorder and destruction.
- **Perception management**: Controlling how events are perceived.
- **Denial of service**: Preventing access to information or services.
- **Lulz and drama**: Seeking amusement and creating conflict.
- **Agenda setting and priming**: Shaping public opinion and preparing the ground for future actions.
- **Incitement**: Encouraging harmful or illegal behavior.
- **Response seeking**: Eliciting reactions from targets.
- **Community building and governance**: Creating and managing online communities.
- **Demoralization and outrage**: Undermining morale and inciting anger.
- **Profit**: Financial gain from trolling activities.

### Techniques and Tools
- **Source hacking and journobaiting**: Manipulating news sources and journalists.
- **Attentional honeypots**: Attracting and trapping attention.
- **Keyword squatting**: Dominating specific search terms.
- **Capturing the narrative**: Controlling the story.
- **Cognitive denial of service**: Overwhelming individuals with information.
- **Brute force harassment**: Intensive, relentless attacks.
- **Ironical bait and switch**: Using irony to mislead.
- **Gaming databases and algorithmic control**: Manipulating data and algorithms.
- **Memetic trojan horses**: Using memes to spread hidden messages.
- **Controlled opposition**: Fostering the illusion of dissent.
- **Driving a wedge**: Dividing groups and communities.
- **Concern trolling**: Pretending to be concerned while actually causing harm.
- **Brigading and dogpiling**: Coordinating large-scale attacks.
- **Sockpuppetry**: Using fake identities to influence discussions.
- **Jiu Jitsu and self-victimization**: Turning the tables on attackers.
- **Doxing**: Revealing personal information.
- **Context distortion**: Misrepresenting the context of information.
- **Deep fakes and photoshops**: Using manipulated images and videos.

## Section 5: Addressing Trolling

### Fundamental Questions
- **Is trolling a bug or a feature?**: Is it a problem or a natural part of networked media dynamics?
- **Do nothing**: Allowing trolling to continue unchecked.
- **Incentivize diverse trolling perspectives**: Encouraging a variety of trolling approaches.
- **Trolling arms race**: Engaging in a continuous battle against trolls.
- **Trolling code of ethics**: Establishing ethical guidelines for trolling.
- **Technical re-design**: Redesigning systems to reduce trolling.
- **Policy change**: Implementing new policies to address trolling.
- **Content moderation**: Actively managing and moderating content.
- **Media literacy**: Educating users and gatekeepers about media consumption.
- **Norms like “Don’t Feed the Trolls” and “Strategic silence”**: Adopting strategies to ignore or minimize trolling.
- **Regulation**: Enforcing legal regulations on trolling.
- **Institutionalized trust and verification**: Building systems for trusted and verified information.
- **Right to speech vs. right to amplification**: Distinguishing between the right to speak and the right to be heard.
- **Media literacy vs. attention economics**: Balancing education with the economic value of attention.
- **Network gatekeeping vs. paternalism**: Weighing the benefits and drawbacks of centralized control.
- **Public interest and ethical systems**: Defining and implementing ethical standards.
- **Disclosure and verification**: Determining who discloses information, how, and to whom.
- **Monopolization of attention**: Addressing the issue of attention monopolies.
- **Finite lifetime problem**: Dealing with the limited time available to verify and investigate claims.
- **Inflammatory lies and profitability**: Acknowledging that false and inflammatory content often spreads more easily.
- **Moderation challenges**: Balancing under-counting and over-counting in moderation.
- **DIY moderation and tribalism**: The risks of user-driven moderation leading to tribalism.
- **Lessons from the Computer Fraud and Abuse Act**: Applying lessons from existing laws.
- **Chilling effect**: The potential for regulation to stifle free expression.
- **Trolls, platforms, and journalists**: The roles and responsibilities of different actors.
- **Negative externalities**: Addressing the broader impacts of trolling.
- **Current laws and standards**: Evaluating and updating existing legal frameworks.
- **Addressing specific issues**: Focusing on particular problems and solutions.
- **Red teaming and white hat trolls**: Using ethical hackers to test and improve systems.
- **External pressure from gray hat trolls**: Leveraging the influence of semi-ethical hackers.
- **Proof of concept and full disclosure**: Balancing the need for transparency with security concerns.
- **Security economics and markets**: Considering the economic aspects of security.
- **Selective disclosure and security research**: Sharing information selectively to protect and improve systems.
- **Bounty programs and penetration testing**: Incentivizing the discovery and reporting of vulnerabilities.
- **Professionalization**: Developing professional standards and practices for addressing trolling.
- **White hats, gray hats, and black hats**: Differentiating between ethical, semi-ethical, and unethical hackers.
- **More positions and issues**: Recognizing the complexity and diversity of the trolling landscape.
- **Politics of spectacle and agonistic politics**: Understanding the role of spectacle and conflict in political discourse.
- **Race to the bottom and norms or codes of ethics**: Avoiding a downward spiral and establishing ethical standards.

### Conclusion
While trolling presents significant challenges, it also offers opportunities for understanding and improving the socio-technical systems that underpin our digital world. By examining the various facets of trolling, we can develop more effective strategies to mitigate its negative impacts and harness its potential for positive change.