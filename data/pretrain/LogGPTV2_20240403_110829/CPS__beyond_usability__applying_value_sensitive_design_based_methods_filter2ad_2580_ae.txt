disliked (18%) by patients; however it was more disliked (42%) 
than liked (38%) by providers. In the case of the criticality-aware 
fail-open system, we suspect that this difference is primarily due 
to  providers’  higher  concern  regarding  the  lack  of  a  manual 
override if the system fails to recognize a medical emergency. The 
provider results suggest that this approach may not be a suitable 
solution for securing IMDs. 
The  patient  study  recommended  a  set  of  three  solution  choices 
that, if offered together, might satisfy the desires of most patients: 
a proximity-based system (System E), a fail-open/safety wristband 
(System  D),  and  a  UV-visible  tattoo  of  a  password  (System  C). 
Given 
tattoos  among 
providers  (50%  would  recommend  against),  however,  our  new 
results caution against their use in practice). 
the  strong  opposition 
to  UV-visible 
in 
the 
terms  of  similarity  of  perspective, 
In 
the  fail-open/safety 
wristband approach (System D) was the security concept that was 
least disliked (17% dislike, 13% recommend against) and the most 
liked  by  medical  providers  (58%  like,  46%  recommend).  This 
concept  was  also  the  most  liked  by  the  patients  (45%  like,  27% 
would choose to use it if it were available).  
7.  SECURITY DESIGN CONSIDERATIONS 
Drawing on a synthesis of the results from the study data, we now 
provide  concrete  design  considerations  for  security  researchers 
working in the implantable cardiac device domain. 
7.1  Access, Access, Access 
Access—and the related issue of compatibility—show up in both 
the initial perspectives and the security system concept data sets, 
and  are  particularly  emphasized 
latter.  Participants 
repeatedly indicated the importance of (different kinds of) access: 
(a) Providers must always be able to access the implanted device, 
and  security  systems  should  either  fail  to  an  open  state  or  offer 
some  kind  of  override;  (b)  “Unplanned”  access  does  not  only 
occur  in  emergencies,  since  patients  may  travel  or  change 
cardiologists, and records are not always transferred smoothly; (c) 
Access should not rely upon a centralized system, which could be 
unavailable  (due  to  technical,  geographic,  or  other  reasons)  and 
which merely defers the security problem; (d) Access cannot rely 
upon  a  conscious  or  compliant  patient;  (e)  Access  should  avoid 
relying on additional equipment, which can delay or block patient 
care or remove providers from the bedside; (f) Access should be 
timely, and should therefore require few steps. Perhaps, above all, 
in  the  words  of  one  of  our  participants:  “Please,  please,  please 
keep it SIMPLE.” 
7.2  Mechanics and Logistics 
Various aspects of IMD mechanics and logistics are raised in both 
the  initial  perspectives  and  the  system  concept  data  sets.  Any 
security system should avoid disturbing the status quo in terms of: 
(a)  cost,  which  can  also  affect  insurance  approval;  (b)  required 
training, particularly for non-cardiology staff; (c) implant battery 
usage; (d) implant size; or (e) any other aspect that might impact 
the surgical or healing processes. 
7.3  Safety Features and Incentives 
Participants  showed  interest  in  the  possibility  of  incorporating 
safety features into a security system for IMDs. The exact nature 
of such features and how they might be tuned should be further 
investigated;  for  example,  many  participants  expressed  concern 
that a 911 feature would result in many false-positive emergency 
notifications.  However,  if  well  designed,  safety  features  might 
function as incentives for patients to comply with using a security 
system. This is particularly relevant in the case of a system like 
the wristband (System D), which incorporates an external battery 
which can be used for safety features, and with which the patient 
only receives security if they choose to wear the band. 
7.4  Empowering Without Burdening 
Ideally, patients should be given some implicit or explicit role in 
the access control process, whether via overt action or by allowing 
someone  extended  skin  contact.  Generally  speaking,  such  a  role 
might  give  patients  a  feeling  of  empowerment,  but  more 
practically speaking, patients could provide human reasoning as to 
whether  or  not  their  device  should  be  accessed  in  a  given 
situation.  Conversely,  patients  should  not  be  unduly  mentally  or 
physically burdened by a security system. As one example of this, 
anything that visually indicates the patient’s condition should be 
opt-in; visual indicators such as medical alert bracelets are useful 
to  emergency  staff,  but  patients  should  be  able  to  weigh  the 
advantages  and  disadvantages  and  choose  whether  or  not  to 
participate.  Moreover,  this  consideration  raises  a  host  of  ethical, 
legal, and philosophical questions: Should a security design hinge 
upon  patients  being  able  to  choose  whether  or  not  they  wish  to 
comply?  How  many  patients  would  actually  comply?  Should  a 
security design strive to equally protect all patients from potential 
harm, or is that attitude paternalistic? What are the repercussions, 
legally or in terms of reputation, if a company’s IMD is attacked, 
and  security  was  optional?  The  domain  is  full  of  interesting 
questions that are ripe for consideration. 
8.  CONCLUSION 
The work reported here makes two important contributions. First, 
we  offer  domain-specific  findings  for  security  for  implantable 
cardiac  devices—cyber-physical  systems  that  perform  critical 
operations within patients’ bodies. The purpose of these findings 
is to facilitate designs with increased adoption, correct usage, and 
few negative side effects for patients and medical providers. 
Our  second  contribution  concerns  method.  Specifically,  we 
adapted  established  methods  from  value  sensitive  design—the 
Envisioning  Workshop  and  values  dams  and  flows—to  the 
security  domain:  we  gathered  feedback  on  classes  of  security 
systems  via  concrete  descriptions  of  systems  that  embody 
particular  properties  (security  and  non-security).  This  work 
demonstrates how security researchers can draw upon direct and 
indirect  stakeholders  to  understand  the  relevant  properties  of  a 
new  technology  domain;  the  techniques  we  used  were  in  the 
context  of  implantable  cardiac  devices,  but  could  be  used  to 
explore other emerging technology domains. 
Bridging the gap between technological innovation and the lives 
of  stakeholders  who  will  be  impacted  by  that  technology  is  not 
easy; however, it is critical to do so. Toward that end, the work 
reported  here  provides  one  specific  study  to  suggest  how  such 
work  could  be  done,  and  methods  for  making  progress  toward 
incorporating human values into technical security design.  
9.  ACKNOWLEDGMENTS 
This work was supported in part by the US National Science 
Foundation (NSF) under awards CNS-0846065, CNS-0905118, 
and CNS-0905384, by the US Department of Health & Human 
Services (HHS) under award HHS-2010-03958-09, and by an 
Alfred P. Sloan Research Fellowship. Any opinions, findings, and 
conclusions or recommendations expressed in this publication do 
not necessarily reflect the views of the funding agencies. We 
thank the medical providers who participated in this study. We 
thank M. Enev, D. Halperin, K. Koscher, B. Ransford, and A. 
Takakuwa for contributing to the data analysis process. This work 
was done while Tamara Denning was at the University of 
Washington. 
REFERENCES 
[1]  S. Avancha, A. Baxi, and D. Kotz. Privacy in Mobile 
Technology for Personal Healthcare. ACM Computing 
Surveys, 45(1), 2013. 
[2]  D. Balfanz. Usable Access Control for the World Wide Web. 
ACSAC 2003. 
[3]  S. Cherukuri, K. Venkatasubramanian, and S. Gupta. BioSec: 
A Biometric Based Approach for Securing Communication 
in Wireless Networks of Biosensors Implanted in the Human 
Body. ICPP Workshops 2003. 
[4]  S. Clark, T. Goodspeed, P. Metzger, Z. Wasserman, K. Xu, 
and M. Blaze. Why (Special Agent) Johnny (Still) Can’t 
Encrypt: A Security Analysis of the APCO Project 25 Two-
Way Radio System. USENIX 2011. 
[5]  L. Cranor and S. Garfinkel. Security and Usability. O’Reilly 
Media, Inc., 2005. 
[6]  A. Czeskis, I. Dermendjieva, H. Yapit, A. Borning, B. 
Friedman, B.T. Gill, T. and T. Kohno. Parenting From the 
Pocket: Value Tensions and Technical Directions for Secure 
and Private Parent-Teen Mobile Safety. SOUPS 2010. 
[7]  T. Denning, A. Borning, B. Friedman, B. T. Gill, T. Kohno, 
and W. H. Maisel. Patients, Pacemakers, and Implantable 
Defibrillators: Human Values and Security for Wireless 
Implantable Medical Devices. CHI 2010. 
[8]  T. Denning, K. Fu, and T. Kohno. Absence Makes the Heart 
Grow Fonder: New Directions for Implantable Medical 
Device Security. HotSec 2008. 
[9]  T. Denning, T. Kohno, H. M. and Levy. Computer Security 
and the Modern Home. Communications of the ACM, 56(1), 
94-103, 2013. 
[10] T. Dimkov, A. van Cleeff, W. Pieters, and P. Hartel. Two 
Methodologies For Physical Penetration Testing Using 
Social Engineering. ACSAC 2010. 
[11] J. L. Fleiss, B. Levin, and M. C. Paik. Statistical Methods for 
Rates and Proportions (3rd ed.). New York: John Wiley & 
Sons. 2003. 
[12] B. Friedman, D. Howe, and E. Felten. Informed Consent in 
the Mozilla Browser: Implementing Value Sensitive Design. 
HICSS 2002. 
[13] B. Friedman, D. Hurley, D. C. Howe, E. Felten, and H. 
Nissenbaum. Users’ Conceptions of Web Security: A 
Comparative Study. CHI 2002 (Extended Abstracts). 
[14] B. Friedman, P. H. Kahn Jr., and A. Borning. Value Sensitive 
Design and Information Systems: Three Case Studies. In P. 
Zhang and D. Galletta, editors, Human-Computer Interaction 
and Management Information Systems: Foundations. 2006. 
[15] S. Gollakota, H. Hassanieh, B. Ransford, D. Katabi and K. 
Fu. They Can Hear Your Heartbeats: Non-Invasive Security 
for Implanted Medical Devices. ACM SIGCOMM 2011. 
[16] S. K. S. Gupta, T. Mukherjee, and K. Venkatasubramanian. 
Criticality Aware Access Control Model for Pervasive 
Applications. IEEE PERCOM 2006. 
[17] D. Halperin, T. S. Heydt-Benjamin, K. Fu, T. Kohno, and W. 
H. Maisel. Security and Privacy for Implantable Medical 
Devices. IEEE Pervasive Computing, 7, 2008. 
[18] D. Halperin, T. S. Heydt-Benjamin, B. Ransford, S. S. Clark, 
B. Defend, W. Morgan, K. Fu, T. Kohno, and W. H. Maisel. 
Pacemakers and Implantable Cardiac Defibrillators: Software 
Radio Attacks and Zero-Power Defenses. IEEE S&P 
Symposium 2008. 
[19] A. Jøsang, B. AlFayyadh, T. Grandison, M. AlZomai, and J. 
McNamara. Security Usability Principles for Vulnerability 
Analysis and Risk Assessment. ACSAC 2007. 
[20] F. Kensing and K.H. Madsen. Generating Visions: Future 
Workshops and Metaphorical Design. In J. Greenbaum and 
M. Kyng, editors, Design at Work: Cooperative Design of 
Computer Systems. Lawrence Erlbaum, 1991.  
[21] J. Landis and G. Koch. The Measurement of Observer 
Agreement for Categorical Data. Biometrics, 33, 1977. 
[22] C. A. Le Dantec and W. K. Edwards. Designs on Dignity: 
Perceptions of Technology Among the Homeless. CHI 2008.  
[23] C. Li, A. Raghunathan, and N. K. Jha.  Hijacking an Insulin 
Pump: Security Attacks and Defenses for a Diabetes Therapy 
System. Healthcom 2011.   
[24] J. K. Miller, B. Friedman, G. Jancke, and B. Gill. Value 
Tensions in Design: The Value Sensitive Design, 
Development, and Appropriation of a Corporation's 
Groupware System. GROUP 2007. 
[25] L. I. Millett, B. Friedman, and E. Felten. Cookies and Web 
Browser Design: Toward Realizing Informed Consent 
Online. CHI 2001. 
[26] L. P. Nathan, B. Friedman, P. V. Klasjna, S. K. Kane, and J. 
K. Miller. Envisioning Systemic Effects on Persons and 
Society Throughout Interactive System Design. DIS 2008. 
[27] X. Ou. Ethnographic Fieldwork at a University IT Security 
Office. ACSAC 2013. 
[28] N. Paul and T. Kohno.  Security Risks, Low-tech User 
Interfaces, and Implantable Medical Devices: A Case Study 
with Insulin Pump Infusion Systems. HealthSec 2012.   
[29] A. Raij, A. Ghosh, S. Kumar, M. Srivastava.  Privacy Risks 
Emerging from the Adoption of Innocuous Wearable Sensors 
in the Mobile Environment. CHI 2011.   
[30] K. B. Rasmussen, C. Castelluccia, T. S. Heydt-Benjamin, 
and S. Capkun. Proximity-Based Access Control for 
Implantable Medical Devices. ACM CCS 2009. 
[31] M. Rushanan, C. Swanson, D. F. Kune, and A. D. Rubin. 
SoK: Security and Privacy in Implantable Medical Devices 
and Body Area Networks. IEEE S&P Symposium 2014. 
[32] S. Schechter. Security That Is Meant To Be Skin Deep: 
Using Ultraviolet Micropigmentation To Store Emergency-
Access Keys for Implantable Medical Devices. HealthSec 
2010. 
[33] S. Schechter, R. Dhamija, A. Ozment, and I. Fischer. The 
Emperor’s New Security Indicators. IEEE S&P Symposium 
2007. 
[34] J. Sorber, M Shin, R. Peterson, C. Cornelius, S. Mare, A. 
Prasad, Z. Marois, E. Smithayer, and D. Kotz.  An Amulet 
for Trustworthy Wearable mHealth. HotMobile 2012. 
[35] Symposium on Usable Privacy and Security. http://cups. 
cs.cmu.edu/soups/. 
[36] E. Troshynski, C. Lee, and P. Dourish. Accountabilities of 
Presence: Reframing Location-Based Systems. CHI 2008. 
[37] K. K. Venkatasubramanian and S. K. S. Gupta.  PSKA: 
Usable and Secure Key Agreement Scheme for Body Area 
Networks.  IEEE Transactions on Information Technology in 
Biomedicine, 14(1), 2010.  
[38] R. Wash. Folk Models of Home Computer Security. SOUPS 
2010. 
[39] A. Whitten and J. D. Tygar. Why Johnny Can’t Encrypt: A 
Usability Evaluation of PGP 5.0. USENIX 1999. 
[40] F. Xu, Z. Qin, C. C. Tan, B. Wang, and Q. Li. IMDGuard: 
Securing Implantable Medical Devices with the External 
Wearable Guardian. IEEE INFOCOM 2011.  
[41] D. Yoo, M. Lake, T. Nilsen, M. E. Utter, R. Alsdorf, T. 
Bizimana, L. P. Nathan, M. Ring, E. J. Utter, R. F. Utter, and 
B. Friedman. Envisioning Across Generations: A Multi-
Lifespan Information System for International Justice In 
Rwanda. CHI 2013.