### 4.2 “The Bad”: Potential Drawbacks of Slowly-Responsive Algorithms

We now turn our attention to two potential drawbacks of TCP-compatible SlowCC algorithms in highly variable environments: (i) unfairness with respect to TCP and other SlowCC algorithms, and (ii) potentially lower bottleneck link utilization. We will examine both long- and short-term fairness in dynamic environments.

#### 4.2.1 Long-term Fairness

To investigate long-term fairness in a rapidly-changing environment, we consider an extreme scenario where the available bandwidth periodically increases to three times its lower value. In this setup, ten long-lived flows (five TCP and five TFRC) compete with a "square-wave" CBR source, using the topology described in Section 3. The congested link has a capacity of 15 Mbps, with only 5 Mbps available to the long-lived flows when the CBR source is active. This results in a 3:1 variation in the bandwidth available to the long-lived flows.

During an extended high-bandwidth period, we expect the packet drop rate with ten long-lived flows to be approximately 0.7%, with an average TCP congestion window of 14.4 packets.

**Figure 7:** Throughput of TCP and TFRC flows when the available bandwidth changes by a 3:1 factor.
**Figure 8:** Throughput of TCP and TCP(1/8) flows when the available bandwidth changes by a 3:1 factor.
**Figure 9:** Throughput of TCP and SQRT(1/2) flows when the available bandwidth changes by a 3:1 factor.

In Figure 7, each column of marks shows the results from a single simulation, with one mark representing the observed throughput for each of the ten flows. The x-axis represents the length in seconds of a combined high- and low-bandwidth period, while the y-axis shows the throughput normalized by a single flow's fair share of the available bandwidth. The two lines represent the average throughput received by the TCP and TFRC flows.

As Figure 7 illustrates, overall link utilization is high when the period of the CBR source is low. However, it suffers when the period of the CBR source is 0.2 seconds (4 RTTs). When the period of the CBR source is between one and ten seconds, the TCP flows receive more throughput than the TFRC flows, indicating that varying network conditions favor TCP over TFRC.

To further explore scenarios where TFRC might compete unfairly with TCP, we ran simulations with various patterns for the competing CBR source, including "sawtooth" patterns and reverse sawtooth patterns. The results were similar to those in Figure 7, with the difference between TCP and TFRC being less pronounced. These results demonstrate that in many dynamic scenarios, TCP receives more bandwidth than competing TFRC flows. Despite extensive testing, we could not find any scenarios with varying bandwidths where TFRC receives more bandwidth than TCP in the long term. Over short periods, immediately after a reduction in available bandwidth, TFRC flows may achieve higher throughput than TCP flows, but in the long run, TCP flows are more competitive.

Figures 8 and 9 show similar results when TCP competes with TCP(1/8) or SQRT in this dynamic environment. Although not as agile as TCP, these SlowCC mechanisms are reasonably prompt in reducing their sending rate in response to extreme congestion. However, they are noticeably slower at increasing their sending rate when the available bandwidth increases. Our results suggest that there are no significant concerns about unfair competition with TCP over long-term durations, which should not prevent SlowCC from being safely deployed in the current Internet.

We observed similar trends when competing algorithms were subjected to an even more extreme 10:1 oscillation in the available bandwidth—the throughput difference was significantly more prominent in this case. In summary, SlowCC mechanisms lose to TCP under dynamic network conditions in the long run because their response to network conditions is slow; they do not send data fast enough when the bandwidth is available. Thus, two mechanisms that are TCP-compatible under static conditions do not necessarily compete equitably, even in the long term, in a more dynamic environment. In return for a smoother sending rate under more static conditions, SlowCC mechanisms pay the price of losing bandwidth relative to TCP in more dynamic environments.

#### 4.2.2 Transient Fairness

We now consider the effect of SlowCC algorithms on transient fairness under dynamic conditions. We discuss the time for convergence to fairness for two flows using identical SlowCC mechanisms but starting at different sending rates. Transient fairness is particularly important for short flows, whose entire lifetime might be contained in the transient period of convergence to fairness.

**Figure 10:** Time (in seconds) for convergence to 0.1-fairness for TCP(b) flows.
**Figure 11:** Number of ACKs for convergence to 0.1-fairness for TCP(b) flows.
**Figure 12:** Time (in seconds) for convergence to 0.1-fairness for TFRC(b) flows.

Figure 10 shows the results of simulations with two TCP(b) flows sharing a link of bandwidth B. Let \((X_1, X_2)\) denote the bandwidths of the first and second flows, respectively. We measure the 0.1-fair convergence time, defined in Section 3, for \(\alpha = 0.1\). We use a value of the bottleneck bandwidth \(B = 10 \times b_0\), much larger than \(b_0\), which is the bandwidth corresponding to 1 packet/RTT (our RTT is 50 ms). Thus, the 0.1-fair convergence time being measured corresponds roughly to the time taken for an initial unfair allocation of \((B, 0)\) to converge to \((0.55B, 0.45B)\). Figure 10 shows the 0.1-fair convergence times for two TCP(b) flows for a range of values of \(b\). If we decreased the link bandwidth, we would expect the convergence times to decrease accordingly.

We use an analytical model with the same framework to estimate the expected 0.1-fair convergence times for pure AIMD(a, b) flows in an environment with a steady-state packet mark rate \(\beta\), when \(B >> b_0\). (For simplicity, assume this is an environment with Explicit Congestion Notification (ECN) [15].) Let \(X_i^1\) and \(X_i^2\) denote the expected values of the congestion windows of the first and second flows after the arrival of the i-th ACK packet. The i+1-th ACK belongs to flow 1 with probability \(\frac{X_i^1}{X_i^1 + X_i^2}\), and to flow 2 with probability \(\frac{X_i^2}{X_i^1 + X_i^2}\).

After the i+1-th ACK, the expected values of the two congestion windows become:
\[ X_{i+1}^1 = \left(1 - \beta \frac{X_i^1}{X_i^1 + X_i^2}\right) X_i^1 \]
\[ X_{i+1}^2 = \left(1 - \beta \frac{X_i^2}{X_i^1 + X_i^2}\right) X_i^2 \]

The expected difference in the congestion windows of the two flows changes from:
\[ \Delta_i = |X_i^1 - X_i^2| \]
to:
\[ \Delta_{i+1} = \Delta_i \left(1 - \beta \frac{\Delta_i}{X_i^1 + X_i^2}\right) \]

Thus, the expected number of ACKs needed for a 0.1-fair allocation, starting from a highly skewed initial allocation, is essentially:
\[ \frac{\log(\Delta_0 / 0.1)}{\log(1 - \beta)} \]

This analysis provides insights into the transient behavior of SlowCC algorithms and highlights the importance of considering both long-term and short-term fairness in dynamic network environments.