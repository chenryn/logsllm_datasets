by the size of their 
of the unigrams 
the Jaccard Similarity, 
978-1-4799-3755-4/13/$31.00 
©2013 IEEE 
000869 
consistent 
with the other 
proposed 
three timing-based 
1) network delay defined as time between 
and TCP SYN+ACK packet (i.e., 
cap­
delay defined as 
2) processing 
a dummy HTTP request 
(i.e., 
workload 
than FFSN domain names. 
URLs have a higher similarity 
Edit Distance 
Finally, 
Levenshtein 
and S2 is calculated 
by finding the minimum  number 
of edit 
operations 
allowed are inserting 
from a string, 
character 
by another 
character. 
of two domain names S1 
deleting 
of a string 
into a string, 
or replacing 
a character 
a character 
to transform 
required 
Sl into S2. The edit operations 
a 
C. Spatial-based 
Features 
[8] proposed 
Recently, 
two spatial 
mechanism. 
metrics 
Given the list of IP 
to provide a 
into spatial 
map the IP  ad­
of these records 
distribution 
FFSN detection 
of A and NS records,  authors 
delay-free 
addresses 
dresses 
the uniform distribution 
address set Q, each IP address is mapped to a coordinate 
C(Q) =  where Cl(Q) and C2(Q) map to 
to GMT Time Zones, and finally Time 
degree of malicious 
Then, each IP address 
respectively. 
and longitude, 
hosts. Given an 
to assess 
to fetch a webpage. 
in order to make the timing features 
sets. In [6], the authors 
feature 
metrics 
as follows: 
HTTP GET request 
turing network congestion), 
the time to process 
of a server), 
required 
exchanges 
these features 
also identified 
and not strongly 
processing 
RTT and application 
feature 
delay metrics, 
of three connection 
the standard 
all computations 
deviation 
dependent 
attempts, 
set. In our calculations, 
and 3) document fetch delay defined as time 
Our system monitors 
the packet 
between the client and the server, 
and extracts 
on the fly. In addition 
the Round Trip Time (RTT) as a promising, 
to these features, 
we 
delay is also based on the subtraction 
of network 
on multiple 
IP addresses. 
Since 
level RTT, we exclude RTT from our 
in 
in order to get consistency 
are the averages 
and then the overall 
of the total 
average 
and 
of the delay metrics 
are calculated. 
TZE(C(Q)) 
=  - L (M(C(Q))/IQI)(Iog(M(C(Q)/IQI))), 
III. SYSTEM OVERVIEW 
IEGMT 
where M is the number of times C(Q) located 
zone for the given hosts. 
in the tth time 
TZE may be ineffective 
for CDNs since CDNs may have 
For this reason, 
deviation 
the authors 
of minimal 
spatial 
estimator 
relationship 
qmm', is calculated 
qm, to the each NS IP address 
FFSN-like 
distribution. 
defined the average and the standard 
service 
distance, 
section, 
qm', as a "service" 
deviation 
features 
FFSNs depending 
closer spatial 
on the assumption 
relationship 
of the minimum service 
which are expected 
distance. 
service 
than FFSNs. 
as a second feature. 
Euclidean 
from each IP address 
in the answer 
Then the average 
in the additional 
section, 
and the standard 
to help discriminating 
CDNs from 
that CDNs may have 
distances 
are designated 
D. Network-based 
Features 
Similar 
to the spatial-based 
the number of associated 
features, 
network-based 
features 
and autonomous 
in A records. 
networks 
identify 
system numbers (ASNs) of the IP addresses 
showed that benign hosts are mostly located 
geographical 
all members of the same autonomous 
the spatial-based 
which require 
GEOIP database, 
up of an up-to-date 
require 
Furthermore, 
characteristics 
[14] showed that ASNs together 
respond well to identify 
area and owned by the same company and are 
Compared to 
look­
an additional 
network-based 
features 
values. 
with spatial 
FFSNs. 
WHOIS command to extract 
potential 
the related 
features 
feature 
system. 
[5] 
in a circumscribed 
E. Timing-based 
Features 
The strength 
of the timing-based 
features 
relies 
sumption 
Although, 
based features 
requirement 
especially 
constructing 
that FFSNs may have a single associated 
FFSNs often consist 
of only a few bots, timing 
may well discriminate 
the FFSNs. However, 
of HTTP packets incurs additional 
overhead, 
when the traffic load is high. In addition, 
while 
dataset, 
only active FFSN URLs are processed 
on the as­
IP address. 
A. DNS Data Collection 
database1 
We have collected 
URLs from ATLAS Fast-Flux 
Tracker2 during the period of 4 months (from 
we  were able to 
and FastFlux 
October 2012 to January 2013). Overall, 
476 domains as fast-flux 
collect 
During the web page retrieval 
each DNS packet response 
[15] libraries 
before feeding 
with modified version 
to our detection 
and 1,853 as benign classes. 
and DNS queries, 
of the tshark 
we dissect 
system. 
In order to compare the textual 
differences of domain­
for the dataset 
we 
(DGA) to 
utilize 
algorithm 
algorithms 
until rallying 
embedded to binary 
domain generation 
between FFSNs recorded 
(e.g., Torpig uses DGA by seeding with the 
Botnets such as Conficker, 
botnet domain names from 
a list of the domain names as a rallying 
host 
from the predefined 
based features 
used and the recent traditional 
Torpig and Kraken, we collected 
Pc Tools3, and Damballa4. Note that except for Kraken botnet, 
other botnets 
construct 
computed 
code of the bots independently 
a response 
current 
use more complicated 
of occurrences 
of vowels, 
domain names with suffixes [7]. We also construct 
of domain names to measure distance 
between FFSNs and non-malicious 
collect 
Global Sites5 and Google most visited 
features 
operations 
domain names. Hence we 
as a total of over 5000 domain names from Alexa Top 
sites6. Some of the 
database 
and 
in Table II. 
space require 
additional 
along with the complexity 
[12]). 
methods by matching 
Kraken botnets 
the frequency 
and concatenating 
a whitelist 
date and a numerical 
and similarity 
host provides 
in our feature 
consonants 
parameter 
each listed 
metrics 
the 
I http://atlas.arbor.net/ 
2http://dnsbl.abuse.ch/fastftuxtracker.php 
3https://www.pctools.com 
4https:llwww.damballa.com 
5http://www.alexa.com 
6http://www.google.com/adplanner/static/toplOOO/ 
978-1-4799-3755-4/131$31.00 
©2013 IEEE 
000870 
TABLE II: COMPLEXITY AND A DDITIONAL OPERATIONS  OF 
FEATURE SUBSETS 
Operations 
Complexity  Additional 
Requirements 
Packet Analysis 
DNS Answer-based 
O(N) 
-
Domain-based 
KL Divergence  O(ND) 
Jaccard lndex 
Edit Distance 
O(ND'W)  Whitelist 
O(N'JY) 
of benign domain names 
Spatial-based 
Database Lookup 
O(NM) 
IP Coordinate 
Database 
Network-based 
WHOlS Processing O(N) 
WHOlS command 
Timing-based 
Delay Calculation O(N) 
HTTP Requests 
NotatIOn 
N  Number of test domain names 
W  Number of domain names in whitelist 
D  Max domain name size 
M  IP coordinate 
size 
B. The Classifier 
In this work the C4.5 algorithm 
[16] is used for classifi­
a decision 
gain is used to split the data into sub-groups, 
creates 
The C4.5 algorithm 
tree, where at 
with normalized 
cation. 
each node of the tree the feature(s) 
information 
tree should have the 
ending at the leaf nodes. A decision 
property 
of the 
samples belong to one class, which is also chosen as the 
predicted 
that at each leaf node, a strong majority 
class for samples belonging 
to that leaf node. 
largest 
The C4.5 algorithm 
test X is applied 
for numeric attributes 
uses two types of tests for each feature 
attributes, 
where e is a constant 
for discrete 
and 
X. The equality 
X  e is applied 
threshold. 
sorting 
obtaining 
The candidate 
threshold 
by 
values of X that appear in training 
set by 
values are specified 
the distinct 
a threshold between 
values. 
the adjacent 
one feature 
At each step of the algorithm, 
leaf nodes with the attribute 
normalized 
class random variable 
is selected 
from 
split that will 
information 
gain. With a given 
C and binary split of feature X, 
the set of current 
yield the greatest 
discrete 
normalized 
gain of a leaf node is obtained 
information 
as: 
NIG CX -
( I ) -H(C) -H(qX) 
H(C)  , 
and H(C) is defined as: 
where H is Shannon's 
entropy, 
(1) 
H(C) = -LP(C = Ci) log2(p(C = c1)) (2) 
and H(qX) is defined as: 
Cj 
H(qX) = -LP(X=xJ)LI'  (3) 
} 
where i is defined as p(C = cilX =x/) log2(p(C = cilX =x/)) 
In order to classify 
a given data sample, 
the leaf node to 
is found. This is performed by 
which the data sample belongs 
following 
that the data sample satisfies, 
from the root and ending at a leaf node. The class of that node 
the branches 
starting 
class. 
raising 
high class purity 
the C4.5 algorithm 
pruning, 
In our experiments, 
Moreover, 
algorithm 
to overcome 
and handling 
missing values. 
In this algorithm, 
such as error-reduced 
at a leaf node with a sufficient 
has 
avoiding 
over­
we 
associated 
becomes the predicted 
many options 
fitting, 
use the subtree 
problem. 
moved upwards towards the root of the tree to join with the 
parent node. Given a particular 
limits, 
for the error rate of the node. An error estimate 
is calculated 
leaves and itself. 
combined 
and we use that upper confidence 
sum of error estimates 
If the node's estimated 
from downward may be 
error estimate 
as a weighted 
confidence, 
of its leaves, 
we find confidence 
limit as an estimate 
for a subtree 
a subtree 
the overfitting 
for all its 
error is less than the 
they are pruned away. 
of the C4.5 
where classes 
are 
level is set 
per leaf is 
tree classifier 
builds a 
In our experiments, 
the classification 
process 
is treated 
The confidence 
As the decision 
phase, the features 
as a binary problem, 
as benign and fast-flux. 
algorithm 
labelled 
to 0.25 and the minimum number of instances 
set to 2 for pruning. 
tree during the training 
the benign  and 
The attributes 
considered 
obtained 
their calculated 
accuracy 
best discrimination 
can be used as a filter to rank features 
Finally, 
a set of features 
performance 
fast-flux 
resulting 
to have more discrimination 
of our dataset. 
can be clearly 
information 
in the highest 
can be decided 
threshold, 
gain values. 
classes 
that best separate 
observed. 
information 
gain are 
power, thus the results 
according 
with a given 
to 
with the 
IV. EXPERIMENTAL RESULTS 
cross validation 
In order to find the best subset of our features 
that result 
sets. 
rates 
that spatial 
subset by taking averages 
into 10 folds of approxi­
subsets. 
the same number 
the dataset 
by dividing 
We observed 
by network (4), DNS 
in Figure 2. We observe 
in all 10 folds. 
true positive 
for each feature 
gain of each feature 
of all feature 
set performs best, followed 
values of 
rates (TPR) and false positive 
for each subset and 
in minimum error rate, we use the 10-fold 
approach 
mately equal size which have proportionally 
of classes 
In Figure 1, the average 
accuracy, 
(FPR) on all 10 folds are presented 
combination 
(3) feature 
answer (J), domain name (2) and timing (5) feature 
The ranked results 
of information 