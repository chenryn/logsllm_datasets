## DuckDB 0.8.0 发布, 支持pivot语法, ASOF JOIN, 并行导入导出性能提升, 递归通配符解析文件, arrow 连接器等    
### 作者                                                                                                  
digoal                                                                                                  
### 日期                                                                                                  
2023-05-18                                                                                              
### 标签                                                                                                  
PostgreSQL , PolarDB , DuckDB , arrow , pivot , unpivot , 时序 , 就近JOIN , ASOF JOIN , fuzzy join , 通配符递归解析文件 , 并行导入 , 并行导出  
----                                                                                                  
## 背景      
https://duckdb.org/2023/05/17/announcing-duckdb-080.html  
0.8.0主要增强:  
- 新的 pivot 和 unpivot 语句 (行列转换)  
- 并行数据导入/导出的性能改进  
- 时间序列 时间就近fuzzy JOIN  
- 递归通配  
- 延迟加载存储元数据以缩短启动时间  
- Python 的用户定义函数  
- Arrow 数据库连接 (ADBC) 支持  
- 新的 Swift 集成  
## 例子  
1、PIVOT, 行列变换:  
```  
CREATE TABLE sales(year INT, amount INT);  
INSERT INTO sales VALUES (2021, 42), (2022, 100), (2021, 42);  
PIVOT sales ON year USING SUM(amount);  
```  
2021	|2022  
---|---  
84	|100  
https://duckdb.org/docs/sql/statements/pivot.html  
2、时间字段 fuzzy JOIN, ASOF JOIN:  
匹配最相近的一条记录, 而不需要匹配出所有的记录.  通常用在时序数据中, 弥补两段数据的GAP.   
```  
CREATE TABLE a(ts TIMESTAMP);  
CREATE TABLE b(ts TIMESTAMP);  
INSERT INTO a VALUES (TIMESTAMP '2023-05-15 10:31:00'), (TIMESTAMP '2023-05-15 11:31:00');  
INSERT INTO b VALUES (TIMESTAMP '2023-05-15 10:30:00'), (TIMESTAMP '2023-05-15 11:30:00');  
FROM a ASOF JOIN b ON a.ts >= b.ts;  
```  
a.ts	| b.ts  
---|---  
2023-05-15 10:31:00	| 2023-05-15 10:30:00  
2023-05-15 11:31:00	| 2023-05-15 11:30:00  
https://duckdb.org/docs/guides/sql_features/asof_join.html  
3、Default Parallel CSV Reader:  
```  
CREATE TABLE lineitem AS FROM lineitem.csv;  
```  
v0.7.1	| v0.8.0  
---|---  
4.1s	| 1.2s  
4、Parallel Parquet, CSV and JSON Writing:  
```  
COPY lineitem TO 'lineitem.csv';  
COPY lineitem TO 'lineitem.parquet';  
COPY lineitem TO 'lineitem.json';  
```  
Format	| v0.7.1	| v0.8.0  
---|---|---  
CSV	|3.9s	|0.6s  
Parquet	|8.1s	|1.2s  
JSON	|4.4s	|1.1s  
5、Recursive File Globbing using `**`  
This release adds support for recursive globbing where an arbitrary number of subdirectories can be matched using the `**` operator (double-star).  
`**`表示可以有任意个目录  
```  
FROM 'data/glob/crawl/stackoverflow/**/*.csv';  
```  
https://duckdb.org/docs/data/multiple_files/overview  
6、Lazy-Loading Table Metadata  
按实际查询的字段, 按需(查到对应文件时)再加载 parquet元数据:  
DuckDB’s internal storage format stores metadata for every row group in a table, such as min-max indices and where in the file every row group is stored. In the past, DuckDB would load this metadata immediately once the database was opened. However, once the data gets very big, the metadata can also get quite large, leading to a noticeable delay on database startup. In this release, we have optimized the metadata handling of DuckDB to only read table metadata as its being accessed. As a result, startup is near-instantaneous even for large databases, and metadata is only loaded for columns that are actually used in queries. The benchmarks below are for a database file containing a single large TPC-H lineitem table (120x SF1) with ~770 million rows and 16 columns:  
Query	| v0.6.1	|v0.7.1	|v0.8.0	|Parquet  
---|---|---|---|---  
SELECT 42	|1.60s|	0.31s	|0.02s|	-  
FROM lineitem LIMIT 1;	|1.62s	|0.32s	|0.03s	|0.27s  