    14:55:55 W0229 14:55:49.341238   14311 request.go:627] Throttling request took 194.963821ms, request: https://104.197.114.165/api/v1/namespaces/kube-system/events?fieldSelector=involvedObject.kind%3DNode%2CinvolvedObject.name%3Dgke-jenkins-e2e-f1ec7fe0-node-l2sf%2CinvolvedObject.namespace%3D%2Csource%3Dkubelet
    14:55:55 Feb 29 14:55:49.346: INFO: 
    14:55:55 Logging pods the kubelet thinks is on node gke-jenkins-e2e-f1ec7fe0-node-l2sf
    14:55:55 W0229 14:55:49.541273   14311 request.go:627] Throttling request took 193.107727ms, request: https://104.197.114.165/api/v1/proxy/nodes/gke-jenkins-e2e-f1ec7fe0-node-l2sf:10250/runningpods
    14:55:55 Feb 29 14:55:49.564: INFO: fluentd-cloud-logging-gke-jenkins-e2e-f1ec7fe0-node-l2sf started at  (0 container statuses recorded)
    14:55:55 Feb 29 14:55:49.564: INFO: kube-proxy-gke-jenkins-e2e-f1ec7fe0-node-l2sf started at  (0 container statuses recorded)
    14:55:55 Feb 29 14:55:49.564: INFO: nginx-controller-6tzlu started at  (0 container statuses recorded)
    14:55:55 Feb 29 14:55:49.564: INFO: nginx-controller-uub6h started at  (0 container statuses recorded)
    14:55:55 Feb 29 14:55:49.564: INFO: mutability-test-0u77q started at  (0 container statuses recorded)
    14:55:55 Feb 29 14:55:49.564: INFO: l7-lb-controller-v0.5.2-h3ffn started at  (0 container statuses recorded)
    14:55:55 Feb 29 14:55:49.564: INFO: heapster-v14-762qq started at  (0 container statuses recorded)
    14:55:55 W0229 14:55:49.741215   14311 request.go:627] Throttling request took 175.733913ms, request: https://104.197.114.165/api/v1/proxy/nodes/gke-jenkins-e2e-f1ec7fe0-node-l2sf:10250/metrics
    14:55:55 Feb 29 14:55:49.876: INFO: ERROR kubelet_docker_errors{operation_type="info"} => 1 @[0]
    14:55:55 Feb 29 14:55:49.876: INFO: ERROR kubelet_docker_errors{operation_type="inspect_image"} => 48 @[0]
    14:55:55 Feb 29 14:55:49.876: INFO: ERROR kubelet_docker_errors{operation_type="list_containers"} => 65 @[0]
    14:55:55 Feb 29 14:55:49.876: INFO: ERROR kubelet_docker_errors{operation_type="list_images"} => 15 @[0]
    14:55:55 Feb 29 14:55:49.876: INFO: ERROR kubelet_docker_errors{operation_type="pull_image"} => 26 @[0]
    14:55:55 Feb 29 14:55:49.876: INFO: ERROR kubelet_docker_errors{operation_type="stop_container"} => 38 @[0]
    14:55:55 Feb 29 14:55:49.876: INFO: ERROR kubelet_docker_errors{operation_type="version"} => 54 @[0]
    14:55:55 Feb 29 14:55:49.876: INFO: 
    14:55:55 Latency metrics for node gke-jenkins-e2e-f1ec7fe0-node-l2sf
    14:55:55 Feb 29 14:55:49.876: INFO: {Operation: Method:pod_start_latency_microseconds Quantile:0.99 Latency:3m46.644521s}
    14:55:55 Feb 29 14:55:49.876: INFO: {Operation:create Method:pod_worker_latency_microseconds Quantile:0.99 Latency:55.520147s}
    14:55:55 Feb 29 14:55:49.876: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:53.258439s}
    14:55:55 Feb 29 14:55:49.876: INFO: {Operation:create Method:pod_worker_latency_microseconds Quantile:0.9 Latency:46.526966s}
    14:55:55 Feb 29 14:55:49.876: INFO: {Operation:SyncPod Method:container_manager_latency_microseconds Quantile:0.99 Latency:38.112145s}
    14:55:55 Feb 29 14:55:49.876: INFO: {Operation:update Method:pod_worker_latency_microseconds Quantile:0.99 Latency:30.421105s}
    14:55:55 Feb 29 14:55:49.876: INFO: {Operation:stop_container Method:docker_operations_latency_microseconds Quantile:0.99 Latency:30.097734s}
    14:55:55 Feb 29 14:55:49.876: INFO: {Operation: Method:pod_start_latency_microseconds Quantile:0.9 Latency:27.688855s}
    14:55:55 Feb 29 14:55:49.876: INFO: {Operation:pull_image Method:docker_operations_latency_microseconds Quantile:0.99 Latency:20.27941s}
    14:55:55 Feb 29 14:55:49.876: INFO: Waiting up to 1m0s for all nodes to be ready
    14:55:55 W0229 14:55:49.941214   14311 request.go:627] Throttling request took 64.695123ms, request: https://104.197.114.165/api/v1/nodes
    14:55:55 STEP: Destroying namespace "e2e-tests-deployment-ezytf" for this suite.
    14:55:55 W0229 14:55:50.141262   14311 request.go:627] Throttling request took 194.312955ms, request: https://104.197.114.165/api/v1/namespaces/e2e-tests-deployment-ezytf
    14:55:55 W0229 14:55:50.341242   14311 request.go:627] Throttling request took 194.516203ms, request: https://104.197.114.165/api/v1/namespaces/e2e-tests-deployment-ezytf
    14:55:55 
    14:55:55 
    14:55:55 â€¢ Failure [615.210 seconds]
    14:55:55 Deployment
    14:55:55 /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/deployment.go:72
    14:55:55   deployment should label adopted RSs and pods [It]
    14:55:55   /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/deployment.go:71
    14:55:55 
    14:55:55   Expected error:
    14:55:55       : {
    14:55:55           s: "failed to wait for pods running: [gave up waiting for pod 'nginx-controller-cceta' to be 'running' after 5m0s gave up waiting for pod 'nginx-controller-h8inh' to be 'running' after 5m0s]",
    14:55:55       }
    14:55:55       failed to wait for pods running: [gave up waiting for pod 'nginx-controller-cceta' to be 'running' after 5m0s gave up waiting for pod 'nginx-controller-h8inh' to be 'running' after 5m0s]
    14:55:55   not to have occurred
    14:55:55 
    14:55:55   /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/deployment.go:837
    14:55:55 ------------------------------
Assigning to @bgrant0607 for triage.