仅仅专注于 SRE 校准不太可能产生企业成功。SRE 工作在企业框架内进行，依赖于 SRE 员工无法控制的资源、指导和目标。SRE 面临的问题与开发、基础设施、营销和客户支持活动密切相关。我们曾经提到，事件指向需要校准的位置。然而，这种需要并不局限于 SRE 员工队伍。事件是有关系统如何工作、它的能力以及将来可能做什么的最相关的经验数据。随着技术系统变得越来越复杂，校准的需求也变得更加迫切。需要在整个组织中共享事件及其含义的经验。如果系统的“线上”部分要在“线下”部分取得进展，则建立支持对事件及其含义进行连贯、相关描述的环境至关重要。
特别是当一个事件具有重大的底线后果时，从中提炼出意义很可能在充满压力甚至激烈的气氛中发生。努力“纽转”解释事件变得有吸引力，特别是在高度官僚化的组织中。内部政治纷争可能导致行为者根据其目的塑造事件故事。在这种环境下，实事求是、认认真真的进行事件调查和汇报，这对组织有更大的实际好处。在理解人们如何在实践的末端工作以及如何更好地支持这项工作（无论是从技术和组织上）方面，存在着重大改进的机会。我们的研究表明，该行业比过去更适应校准的需要，许多公司正在进行将组织和技术组件相结合的实验。这些实验的存在令人鼓舞。但试图利用这些实验来快速改进的时候，却由于分享实验结果十分困难，似乎有一种无形的漩涡在阻挠我们的努力，另外也因为缺乏从中汲取经验教训的工具。因此我们盼望业界有更多的努力，如 SNAFU Catcher 联盟推动的探讨，这将受到欢迎。
本章无意杀死 SRE 世界面临的任何怪兽，而只是素描他们，并告知它们所在的山洞在哪。 
你能做什么？
 "事件"是一个中性词，暗示着脱离和冷静的分析立场。但是，真正的“事件”往往伴随着强烈的情感，其后果对个人、组织或整个公司都是毁灭性的。随着公司越来越依赖技术来取得成功，该技术的故障带来了越来越大的威胁。应对这一挑战需要有能力不仅生存事件，而且有能力将事件作为资源加以利用。这样做需要一些实践、一些资源、一些管理层支持以及一些勇气，但大多数组织都能够做到这一点。首先，以下是四项建议的活动。经验表明，这些活动可能会带来早期的成功，并鼓舞进一步的工作：
构建自己的内部资源以执行事件分析
扩展目前围绕故障报告的 SRE 实践，以发展这种关于认知表现的更深层次的探究实践。将从事此工作的人员视为资源，并鼓励他们与组织外部的其他人互动。
选择几个事件进行更深入的分析
即使是一些经过仔细研究的事件，也能提供巨大的价值。对于中等价值事件，仔细检查和深入分析往往更容易；而高价值事件肯定会引起管理层和监管方面的注意，因此探索性研究变得困难甚至危险。从小开始。展示更彻底的分析是什么样子，以及可以通过它产生什么见解。包含意外、不确定性或歧义因素的案例可能特别有益。尽量避免在分歧出现时“和稀泥”，试图达成皆大欢喜的结论。相反，强调和捕捉响应者和参与者的个人观点。寻找一个论坛，与组织中的其他人进行讨论，并要求响应者参与更多讨论。
构建或调整工具以从事件中捕获数据流构建或调整工具以从事件中捕获数据流
许多数据流已经可用于帮助事件内期间的事故后重建。但其中很少为事件后的分析工作而准备。即使是用于扩展、整理和捕获这些数据流的少量工作也可能很有用。聊天记录、视频会议、数据库查询日志和其他源都非常有用（如果将它们进行梳理所需的工作量不是太大的话）。更大的挑战是记录人们在活动期间采取的无关行动，特别是那些最终证明没有帮助的行为。识别和描述（最终）无用的努力，这尤其有价值。
使公司范围的故障报告会议成为定期举办的活动
作为一种计划外投资，对事件的投资获取全部的价值就应该是一个业务优先事项。事件的陈述和讨论是构建系统及其运行组织的共同心理模型的一种方式。在事件发生后开始汇报也强调了组织对学习的主要承诺。
结论
我们对了解 SRE 认知工作的可能性感到兴奋。对认知工作的深入研究显露了大量的系统工作，无论是上层还是下层。不断发生的事件提醒我们，校准是重要和困难的。在事件期间和之后，对技术工具和协同工具的投入，以及相关的努力，证明了许多人非常期待这种校准。我们相信，其他高风险和高压力领域中使用的方法和方法也适用于 SRE 世界。应用这些方法需要时间和技巧，因此并不适合怯懦的人！即便如此，似乎有越来越多的从业者和研究人员采用认知系统工程师的外衣，其中许多人在我们的行业有直接的经验。这对我们大家的未来是个好兆头。     
参考
Allspaw, J. (2012). Blameless PostMortems and a Just Culture. (Etsy Code as Craft blog.) https://codeascraft.com/2012/05/22/blameless-postmortems/, accessed June 18, 2018.
Bainbridge, L. (1983). Ironies of Automation. Automatica 19(6): 775–779.Billings, C. E. (1996). Aviation Automation: The Search for a Human-Centered Approach. Boca Raton, FL: CRC Press.
Cook, R. I. (2010). How Complex Systems Fail. In Allspaw, J., ed. Web Operations: Keeping the Data On Time. Sebatopol, CA: O'Reilly, 108–116.
Cook, R. I. (2017). Medication Reconciliation is a Window into "Ordinary" Work. In Smith, P.J. and Hoffman, R.R., eds., Cognitive Systems Engineering: The Future for a Changing World. Boca Raton, FL: CRC Press, 53–78.Cook, R. I. (2017). Where Complex Systems Fail. (SNAFUcatchers blog.) https://www.snafucatchers.com/single-post/2017/11/14/void-Incidents-as-Untyped-Pointers, accessed July 2, 2018.
Cook, R. I., Woods, D. D., and MacDonald, J. S. (1991). Human Performance in Anesthesia: A Corpus of Cases (Tech. Report CSEL91.003). Columbus, OH: Ohio State University, Cognitive Systems Engineering Laboratory. https://www.dropbox.com/s/arojonf2q6bcne9/Cook.1991.CorpusOfCases.pdf, accessed May 1, 2018.Cook, R. I., Woods, D. D., McColligan, E., and Howie, M. B. (1991). Cognitive Consequences of Clumsy Automation on High Workload, High Consequence Human Performance. NASA, Lyndon B. Johnson Space Center, Proceedings of the Fourth Annual Workshop on Space Operations Applications and Research (SOAR 90), 543–546, accession number N91-20702. https://ntrs.nasa.gov/search.jsp?R=19910011398.Cook, R. I. and Woods, D. D. (1996). Implications of Automation Surprises in Aviation for the Future of Total Intravenous Anesthesia (TIVA). Journal of Clinical Anesthesia 8: S29–S37.
Deming, W. E. (1982). Out of the Crisis. Cambridge, MA: MIT Press.
Gentner, D. and Stevens, A. (1983). Mental Models. Mahwah, NJ: Lawrence Erlbaum Associates.Hirschhorn, L. (1998). Reworking Authority: Leading and Following in the Post-modern Organization (Vol. 12). Cambridge, MA: MIT Press.
Hollnagel, E. and Woods, D. D. (2006). Joint Cognitive Systems: Foundations of Cognitive Systems Engineering. Boca Raton, FL: CRC Press. [ISBN 9780849339332]
Hutchins, E. (1995). Cognition in the Wild. Cambridge, MA: MIT Press.Klein, G., Woods, D. D., Bradshaw, J. M., Hoffman, R. R., and Feltovich, P. J. (2004). Ten Challenges for Making Automation a “Team Player” in Joint Human-Agent Activity. IEEE Intelligent Systems 19(6): 91–95. [DOI: 10.1109/MIS.2004.74]
Lave, J. and Wenger, E. (1991) Situated Learning: Legitimate Peripheral Participation. Cambridge, UK: University of Cambridge Press.Nemeth, C. P., Cook, R. I., and Woods, D. D. (2004). The Messy Details: Insights from the Study of Technical Work in Healthcare. IEEE Transactions on Systems Man and Cybernetics, Part A: Systems and Humans, 34(6), 689–692.Nemeth, C., Nunnally, M., O'Connor, M., Klock, P. A., and Cook, R. (2005). Making Information Technology a Team Player in Safety: The Case of Infusion Devices. In: Henriksen, K., Battles, J. B., Marks, E. S., et al., eds. Advances in Patient Safety: From Research to Implementation (Volume 1: Research Findings). Rockville, MD: Agency for Healthcare Research and Quality (US). https://www.ncbi.nlm.nih.gov/books/NBK20467/.Roth, E. M, DePass, E. P., Scott, R, Truxler, R., Smith, S. F., and Wampler, J. L. (2017). Designing Collaborative Planning Systems: Putting Joint Cognitive Systems Principles into Practice. In Smith, P.J. and Hoffman, R.R., eds., Cognitive Systems Engineering: The Future for a Changing World. Boca Raton, FL: CRC Press: 247–268.Woods, D. D. and Cook, R. I. (1991). Nosocomial Automation: Technology-induced Complexity and Human Performance. Proceedings of the 1991 IEEE International Conference on Systems, Man and Cybernetics, Charlottesville, VA, 13–16 October 1991, Vol 2., 1279–82. https://ieeexplore.ieee.org/document/169863/.Woods, D. D. (1997). Human-Centered Software Agents: Lessons from Clumsy Automation. In Flanagan, J., Huang, T., Jones, P., and Kasif, S., eds., Human Centered Systems: Information, Interactivity, and Intelligence. Washington, DC: National Science Foundation, 288–293.
Woods, D. D. (2006). Essential Characteristics of Resilience. In Resilience Engineering: Concepts and Precepts. Aldershot, UK: Ashgate Publishing, 21–34.Woods, D. D., Dekker, S., Cook, R. I., and Johannsen, L. (2010). Behind Human Error. Boca Raton, FL: CRC Press.
Woods, D. D. (2017). STELLA: Report from the SNAFUcatchers Workshop on Coping With Complexity. Columbus, OH: The Ohio State University. https://snafucatchers.github.io/.
编者介绍
约翰·Allspaw 是自适应容量实验室的领袖，也是 Etsy 的前 CTO。他与杰西·罗宾斯合著了《网站运营》（O'Reilly，2010年）和《容量规划的艺术》（O'Reilly，2017年）。理查德·库克是自适应能力实验室的校长，也是俄亥俄州立大学的一名研究科学家。他最常引用的论文是“复杂的系统如何失败”。