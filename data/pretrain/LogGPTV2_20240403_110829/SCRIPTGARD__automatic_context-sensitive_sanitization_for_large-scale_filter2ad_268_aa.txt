title:SCRIPTGARD: automatic context-sensitive sanitization for large-scale
legacy web applications
author:Prateek Saxena and
David Molnar and
Benjamin Livshits
ScriptGard: Automatic Context-Sensitive Sanitization
for Large-Scale Legacy Web Applications
Prateek Saxena
UC Berkeley
Berkeley, CA
PI:EMAIL
David Molnar
Microsoft Research
Redmond, WA
PI:EMAIL
Benjamin Livshits
Microsoft Research
Redmond, WA
PI:EMAIL
ABSTRACT
We empirically analyzed sanitizer use in a shipping web ap-
plication with over 400,000 lines of code and over 23,244
methods, the largest empirical analysis of sanitizer use of
which we are aware. Our analysis reveals two novel classes
of errors: context-mismatched sanitization and inconsistent
multiple sanitization. Both of these arise not because san-
itizers are incorrectly implemented, but rather because they
are not placed in code correctly. Much of the work on cross-
site scripting detection to date has focused on ﬁnding miss-
ing sanitizers in programs of average size. In large legacy
applications, other sanitization issues leading to cross-site
scripting emerge.
To address these errors, we propose ScriptGard, a sys-
tem for ASP.NET applications which can detect and repair
the incorrect placement of sanitizers. ScriptGard serves
both as a testing aid to developers as well as a runtime mit-
igation technique. While mitigations for cross site scripting
attacks have seen intense prior research, we consider both
server and browser context, none of them achieve the same
degree of precision, and many other mitigation techniques
require major changes to server side code or to browsers.
Our approach, in contrast, can be incrementally retroﬁtted
to legacy systems with no changes to the source code and
no browser changes. With our optimizations, when used for
mitigation, ScriptGard incurs virtually no statistically sig-
niﬁcant overhead.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—in-
vasive software;
D.1.2 [Programming Techniques]: Automatic Program-
ming—program transformation, program modiﬁcation
General Terms
Security, Languages, Vulnerabilities
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’11, October 17–27, 2011, Chicago, Illinois, USA.
Copyright 2011 ACM 978-1-4503-0948-6/11/10 ...$10.00.
Keywords
Cross-site scripting, Runtime analysis, Web applications
1.
INTRODUCTION
Web applications are explosively popular, but they suf-
fer from cross-site scripting (XSS) [4, 32] and cross-channel
scripting (XCS) [5]. At the core of these attacks is injection
of JavaScript code into a context not originally intended.
These attacks lead to stolen credentials and actions per-
formed on the user’s behalf by an adversary.
Ideally, we
would create systems that resist attacks by construction.
Recent projects such as Blueprint have proposed primi-
tives to encode HTML output in a safe way [20]. Unfortu-
nately, these techniques are diﬃcult to apply to legacy web
applications because they make fundamental changes to the
way an application creates HTML for consumption by the
web browser. Mitigations are needed for XSS attacks against
web applications that can be incrementally retroﬁtted to ex-
isting code.
Prior work: Much work in this space has focused on miss-
ing sanitizers and was performed on relatively small appli-
cations. The eﬀort described in this paper goes well beyond
that, speciﬁcally focusing on applications approaching half a
million lines of code and above. We empirically analyze san-
itization in a widely used Web application with over 400,000
lines of code, the largest application analysis of which we are
aware. In this process, we discovered two novel classes of
errors: context-mismatched sanitization errors and inconsis-
tent multiple sanitization errors. These sanitization errors
arise from subtle nesting of HTML contexts and sharing
of dataﬂow paths in the application. Unlike previously re-
ported errors, mismatched sanitization is not due to faulty
or missing sanitizers; each individual sanitizer in our test ap-
plication is correct to the best of our knowledge. The new
categories of errors only became apparent because of the
scale and complexity of the applications we target, however,
we believe that they represent a new frontier of complexity,
shared by other applications of a similar scale.
As a point of comparison,
it is instructive to con-
sider HTML templating systems such as Google GWT
or CTemplates, which employs Google AutoEscape’s auto-
sanitization to remove the need for manual sanitization [10].
Such systems are much easier to sanitize as compared to
large-scale legacy code that we focus on. For instance, de-
velopers are forced to separate untrusted variables from
HTML structure explicitly in templates, unlike in legacy
code. Their mechanisms does not need to handle the nesting
601of HTML contexts and sharing of dataﬂow paths, because
they work with speciﬁc frameworks.
Consistent Sanitizer Placement: Context-mismatched
sanitization errors arise because developers accidentally mis-
match the choice of sanitizer with the web browser context,
the browser’s parsing state when processing the sanitized
data. This happens when the browser’s actual parsing state
or context is diﬀerent from what the developer expects, al-
lowing unintended characters like single quotes in sanitized
data. Moreover, we discover inconsistent multiple sanitiza-
tion errors, in which the combination of sanitizers leads to
problems. For example, we ﬁnd that two sanitizers in our
test application are not commutative: the order of applica-
tion matters, only one order is safe, yet both orders appear
in our empirical study.
We propose the problem of consistent sanitizer placement:
apply a sequence of sanitizers, chosen from a pre-speciﬁed
set, to an untrusted input such that it is safe for all the
possible browser contexts in which it is rendered. Sanitiza-
tion is also needed for cases where data must be encoded
to avoid causing functionality errors in a speciﬁc context,
such as encoding URLs in JavaScript. Prior work does not
model the notion of browser contexts precisely, rendering it
unable to detect these classes of errors. Depending on the
conﬁguration/policy of the application and the authority of
the adversary who controls the sanitized data, these incon-
sistencies may or may not yield cross site scripting attacks,
but these remain errors in sanitization practice.
ScriptGard: We develop ScriptGard, a system for de-
tecting these sanitization errors, and repairing them by au-
tomatically choosing the appropriate sanitizer. Our sys-
tem requires no changes to web browsers or to server side
source code. Instead, we use binary rewriting of server code
to embed a browser model that determines the appropri-
ate browser parsing context when HTML is output by the
web application. In contrast, projects such as Blueprint
have proposed primitives to encode HTML output in a safe
way [20], but at the cost of requiring large scale server code
changes.
Unlike existing template-based HTML writing systems,
such as ASP.NET’s web and HTML controls, ScriptGard
performs context-sensitive sanitization. ScriptGard al-
lows developers to create custom nesting of HTML contexts,
which we show in Section 6 is common in our test appli-
cation, without sacriﬁcing the consistency of the sanitiza-
tion process. During analysis, ScriptGard employs pos-
itive taint-tracking, which contrasts with traditional taint-
tracking because it is conservative (hence does not miss iden-
tifying sources of untrusted data) and can provide defense
against cross channel-scripting attacks [5, 13]. For example,
a recent vulnerability in Google Analytics was due to a non-
traditional source of untrusted input, namely event logs [30],
which our approach would detect.
We implement our analysis in ScriptGard, which uses
binary rewriting techniques to instrument applications run-
ning on the ASP.NET platform. We stress, however, that
the analyses we perform are general and could be ported to
other platforms with suﬃcient engineering work. Script-
Gard can be used either as a testing aid or as a runtime mit-
igation. As a testing aid, ScriptGard points out sanitizers
that are not correct for the runtime parsing context. Our dy-
namic technique ensures that these reports are for speciﬁc,
reproducible test cases that exhibit inconsistent sanitization.
As a runtime mitigation, we show how ScriptGard can
leverage a training phase where it runs with full instru-
mentation on a target application to learn correct sanitiz-
ers for diﬀerent program paths. Then in deployment, only
a lighter path detection instrumentation is necessary. We
adapt techniques from preferential path proﬁling [7]; with
this optimization trick, ScriptGard incurs virtually no sta-
tistically signiﬁcant overhead when auto-correcting inconsis-
tently sanitized paths we tested.
1.1 Contributions
This paper makes the following contributions.
Testing for sanitizer placement errors: In Section 2, we
identify two new classes of errors: context-mismatched san-
itization and inconsistent multiple sanitization. We imple-
ment a novel analysis that combines automatic server-side
instrumentation with a browser model to ﬁnd inconsistent
sanitization. We further reﬁne this analysis with positive
taint tracking to conservatively over-estimate potentially ad-
versarial inputs, which has been applied to SQL injection in
the past, but not to cross site scripting errors [13]. Because
we use both server and browser modeling, we ﬁnd potential
sanitization ﬂaws that would be missed with techniques that
focus exclusively on the server [2, 17, 21].
Runtime auto-sanitization: We show how our analysis
can determine the correct sanitization at runtime. While we
show the cost to run the full ScriptGard instrumentation is
a high multiple of the original run time, we propose a mech-
anism for using preferential path proﬁling techniques [7] to
shift most of this cost to a pre-deployment training phase.
With this optimization trick, deployed auto-correction in-
curs virtually negligible overhead. Our system changes only
the server side runtime, requiring no changes to server code
or to the browser.
Evaluation and empirical study: In Section 6 we eval-
uate both the testing approach as well as runtime auto-
sanitization on an application with over 400,000 lines of
code. We performed our security testing on a set of 53 large
web pages derived from 7 sub-applications built on top of our
test application. Each page contains 350–900 DOM nodes.
Out of 25, 209 total paths exercised, we found context-
mismatched sanitization on 1,207 paths ScriptGard an-
alyzed, 4.7% of the total paths analyzed. We also observed
an additional 285 instances of inconsistent multiple saniti-
zation errors. Our runtime mitigation technique safeguards
against these inconsistent uses of sanitizers by automatically
correcting them at runtime.
1.2 Paper Organization
The rest of this paper is organized as follows. Section 2
gives a description of the context-sensitive vulnerabilities
ScriptGard is designed to prevent. Section 3 provides an
overview of the ScriptGard architecture. Section 4 formal-
izes the vulnerabilities and provides a notion of correctness.
Section 5 provides speciﬁc details of ScriptGard imple-
mentation. Section 6 gives an experimental evaluation of
our techniques. Finally, Sections 7 and 8 describe related
work and conclude.
2. SANITIZER CONSISTENCY
In this section, we systematically explain the two new class
of sanitization errors we commonly observe in our empirical
602the standard recommended implementation for these sani-
tizers [27], even in widely deployed public web frameworks
and libraries (Django, GWT, OWASP, .NET) do not com-
mute. For instance, EcmaScriptStringEncode simply trans-
forms all characters that can break out of JavaScript string
literals (like the " character) to Unicode encoding (\u0022
for "), and, HtmlAttribEncode HTML-entity encodes char-
acters (&quot; for "). This is the standard recommended
behavior these sanitizers [27] with respect to respective con-
texts they secure.
document.write(`”; }{return “document.write(„‟); ” ; }B1B2B3B4C1C2C3603HTML output
Nesting of contexts
 JavaScript String Literal,
document.write(`
Html URI Attribute,
);
Html URI Attribute,
JavaScript Number
Html URI Attribute
 JavaScript String Literal,
document.write(‘  ');