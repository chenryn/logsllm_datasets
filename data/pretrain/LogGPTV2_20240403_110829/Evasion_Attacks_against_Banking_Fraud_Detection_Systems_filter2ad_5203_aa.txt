title:Evasion Attacks against Banking Fraud Detection Systems
author:Michele Carminati and
Luca Santini and
Mario Polino and
Stefano Zanero
Evasion Attacks against Banking Fraud Detection Systems
Michele Carminati, Luca Santini, Mario Polino, and Stefano Zanero
Politecnico di Milano
{michele.carminati, mario.polino, stefano.zanero}@polimi.it
PI:EMAIL
Abstract
Machine learning models are vulnerable to adversarial sam-
ples: inputs crafted to deceive a classiﬁer. Adversarial samples
crafted against one model can be effective also against related
models. Therefore, even without a comprehensive knowledge
of the target system, a malicious agent can attack it by training
a surrogate model and crafting evasive samples. Unlike the
image classiﬁcation context, the banking fraud detection do-
main is characterized by samples with few aggregated features.
This characteristic makes conventional approaches hardly ap-
plicable to the banking fraud context.
In this paper, we study the application of Adversarial Ma-
chine Learning (AML) techniques to the banking fraud detec-
tion domain. To this end, we identify the main challenges and
design a novel approach to perform evasion attacks. Using
two real bank datasets, we evaluate the security of several
state-of-the-art fraud detection systems by deploying evasion
attacks with different degrees of attacker’s knowledge. We
show that the outcome of the attack is strictly dependent on
the target fraud detector, with an evasion rate ranging from
60% to 100%. Interestingly, our results show that the increase
of attacker knowledge does not signiﬁcantly increase the at-
tack success rate, except for the full knowledge scenario.
1 Introduction
Nowadays, machine learning techniques are applied to sev-
eral data-driven tasks: from image identiﬁcation [22], face
recognition [30], and natural language processing [33] to mal-
ware [3, 27], and intrusion detection [28]. Machine learning
has gained importance also in the banking fraud detection do-
main [6,11,18,26]. Those systems present prominent beneﬁts,
but, unfortunately, they suffer from the typical weakness of
machine learning models: it is possible to signiﬁcantly reduce
their robustness and alter their performance through adversar-
ial samples [8, 19, 25]. Adversarial samples are inputs crafted
starting by legitimate samples that are iteratively perturbed
to make the detector to misclassify them. There are many
studies on how to craft adversarial samples that propose dif-
ferent approaches based on the gradient computation, which
have advantages and drawbacks depending on the domain of
application. There are also many works about transferability,
the property that captures the ability of an attack against a
machine learning model to be effective against a different,
potentially unknown, model [17, 23]. This property allows a
malicious user to design an attack against a machine learning-
based system also in the case in which he does not know the
target system [16, 24]. AML has been studied mainly in the
ﬁeld of image classiﬁcation in which, due to some intrinsic
characteristics of images, researchers obtained remarkable
results. In recent years, many studies applied AML to other
ﬁelds such as malware detection, where researchers had to
overcome the challenges of that domain [3, 20].
In this paper, we study the application of AML techniques
to the banking fraud detection domain, which, unlike the im-
age classiﬁcation one, is characterized by samples with few
aggregated features. This characteristic makes conventional
approaches hardly applicable to this context. Ergo, we present
a novel approach to perform evasion attacks against banking
fraud detection systems that adapts and extends some exis-
tent methods for crafting adversarial samples and mitigate
the challenges of the fraud detection domain. We study dif-
ferent threat models characterized by attackers with different
degrees of knowledge: Black-Box, with zero knowledge of
the target system; Gray-Box, with partial knowledge of the
system; White-Box, with complete knowledge of the system.
Using two real anonymized bank datasets with only legit-
imate transactions, we show how a malicious attacker can
compromise state-of-the-art banking fraud detection systems
by deploying evasion attacks, with an evasion rate ranging
from 60% to 100%. The contributions are the following:
• We present a novel machine learning-based approach to
perform evasion attacks against fraud detection methods
under different degrees of knowledge and simulating the
behavior of different types of fraudsters.
• We study the application of state-of-the-art AML algo-
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    285
rithms in the fraud detection domain, identifying the
challenges of existing approaches.
• We evaluate of state-of-the-art fraud detection methods
by measuring their performance against evasion attacks.
2 Background And Related Works
In recent years, the use of Internet banking services has in-
creased, allowing users to carry out operations remotely. As
a result, the number of bank frauds has also increased, and
every year banks have losses of billions of euros due to frauds.
Banking Fraud Detection. A banking fraud detection sys-
tem identiﬁes fraudulent transactions as deviations from his-
torical user behaviors. Current state-of-the-art fraud detec-
tion systems are based on machine learning, which can be
divided into two categories: supervised and unsupervised
learning-based. Examples of fraud detectors based on unsu-
pervised (and semi-supervised) machine learning techniques
are Banksealer [10, 11], self-organizing maps [36] and peer
group analysis [34]. The most used technique for supervised
fraud detection are Neural Networks (NN) [6, 18], Logistic
Regression, Support Vector Machines, Decision Trees, and
Hidden Markov Models [2]. However, Random Forest algo-
rithm [35] achieves the best performance in this domain.
AML for Fraud Detection. Adversarial samples are inputs
crafted by iteratively perturbing legitimate instances to make
the detector to misclassify them. Traditional AML algo-
rithms have shown good performances in the image detection
ﬁeld [8, 19, 25, 29]. In fact, it is possible to obtain an adver-
sarial image that is misclassiﬁed by the classiﬁer but at the
human eyes seems identical to the original one. We refer the
reader to Appendix B for an overview of the leading solutions
applied in the area. AML algorithms have also been applied to
other areas, such as malware detection [3,20], achieving good
results. As far as we know, in literature, there are no applica-
tions of AML algorithms to the fraud detection domain. The
only security evaluation of a fraud detection system was done
by Carminati et al. [12] through a mimicry attack. Indeed,
there are several challenges in applying AML algorithms to
this domain. As shown in Figure 1, when a user performs
a transaction, this transaction is processed by the banking
system and, then, classiﬁed. The result of the processing is an
aggregated transaction, whose features are an aggregation of
the current transaction with past transactions. Existing AML
algorithms take as input the aggregated transaction, and, ap-
plying perturbations to the original features, return as output
a new aggregated transaction. Instead, an attacker that wants
to perform an evasion against fraud detection frameworks
attack needs to inject in the banking system raw transactions
(not aggregated ones), since they represent the only input pro-
vided by customers in online banking applications. So an
attacker, after applying the AML algorithm, should ﬁnd the
raw transaction that, after being processed, leads to the same
Figure 1: Scheme of the interaction between user and typical
banking system
aggregated transaction returned by the AML algorithm. This
operation is very complicated because, in many cases, the cor-
responding raw transactions may not exist (i.e., the aggregated
transaction contains linked features with conﬂicting values).
Therefore, existing AML-based approaches are not directly
applicable for performing an evasion attack against a banking
fraud detection system. We can overcome some limitations
by inserting some constraints in the perturbations allowed
during the execution of the AML algorithm. In Appendix B.1,
we evaluate the theoretical performances of an AML-based
attack considering an internal attacker that directly injects
aggregated transactions into the banking system.
3 Threat Model
An essential step in designing AML-based attacks is to deﬁne
the threat model. Thus, we adapt to our domain the attack
taxonomy described in [4, 5, 17]. We describe the attacker’s
goal, knowledge, and capability of manipulating data.
3.1 Attacker’s Goal
We deﬁne the attacker’s goal in terms of the security violation,
the attack speciﬁcity, and the error speciﬁcity.
Security Violation. The objective of the attacker can be: (1)
compromising the integrity of the data (i.e., transactions) or
the model used by the detector, affecting the detection reliabil-
ity; (2) compromising the availability of the detector, denying
its functionalities to others (i.e., banking customers and ana-
lysts); (3) compromising the conﬁdentiality of the data (i.e.,
transactions) and model used by the detector, thus obtaining
unauthorized information such as privacy violating data or
inner parameters of the model.
Attack Speciﬁcity. The attack can be targeted if it targets
a speciﬁc user or group of users, or a generic if it targets a
generic user or group of users selected randomly.
Error Speciﬁcity. In generic multi-class classiﬁcation prob-
lems, the attacker may want a sample misclassiﬁed as a spe-
286    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
DataAggregationTransaction	ExecutedML	ClassifierRaw	TransactionUserIDAmountTimestampIBANIBAN_CCIP...AggregatedTransactionAmountCount1dSum1dMean1dCount7d...SameIBANcount1d...BANKING	SYSTEMUserLegitimateFraudFraud	Detectorciﬁc class or as any of the classes of interest. In a binary
classiﬁcation problem, like the fraud detection one, the at-
tacker wants the detector to classify a malicious transaction
(i.e., frauds) as legitimate or vice versa.
In our threat model, the attacker performs an evasion attack,
which is an integrity violation that can be generic or targeted.
The attacker carries out malicious transactions on behalf of
the user and wants the detector to classify them as legitimate.
3.2 Attacker’s Knowledge
We modeled the attacker with different degrees of knowledge,
extending the characterization of Biggio et al. [5], by adding a
term representing the knowledge the attacker has concerning
the past transactions of users. In fact, in the fraud detection
domain, we need to extract aggregated features to capture
user behavior. To perform transaction aggregation, an attacker
needs the last transactions of the user. In our approach, the
adversary needs just one month of the target victim’s transac-
tion history. Regarding our dataset, one month of transactions
corresponds to observe an average of 18± 28 transactions per
victim. The high standard deviation is due to the fact that our
dataset is highly skewed1, with the majority of users perform-
ing few transactions. For example, in a real case, the attacker
retrieves the victim’s transaction history from the banking
application, thanks to a malware injected into the victim’s
devices. We use the following terms to describe attacker’s
knowledge: training data D; feature set X (i.e., how to aggre-
gate samples); learning algorithm along with the loss function
to minimize f ; trained parameters/hyper-parameters w; past
data (i.e., transactions) of the victim user H . In summary,
the attacker’s knowledge can be characterized by the tuple
Θ = (D,X , f ,w,H )2. Based on the previous assumptions, we
can conﬁgure four scenarios:
White-Box. The attacker is assumed to know everything. For
example, he or she is an intern at the bank and collected
all the information. Even if this is a strong assumption, it
is advantageous to perform a worst-case evaluation of the
fraud detectors. It also provides an upper bound that we can
use to compare to other more restrictive scenarios. The tuple
describing this setting is Θwb = (D,X , f ,w,H )1.
Gray-Box. The attacker has partial knowledge about the de-
tection system. In particular, he/she knows how the fraud
detector aggregates data to compute the features (X ) but not
the training data, the learning algorithm, and the trained hyper-
parameters ( ˆD, ˆf , ˆw). As motivated before, we assume that the
attacker has retrieved one month of past transactions ( ˜H ) to
compute an estimation of the aggregated features. The tuple
describing this setting is Θgb = ( ˆD,X , ˆf , ˆw, ˜H ) 1.
1By considering only users with more than 5 monthly transactions, statis-
tics about the number of transactions per user are the following: µ = 18.41,
σ = 27.91, σ2 = 779, median = 11, mode = 6, Q1 = 7, Q3 = 19.
2The term x indicates a full knowledge of term x, ˜x indicates a partial
knowledge of term x, and ˆx indicates zero knowledge of x.
Black-Box with Data. The attacker has no knowledge about
the detection system ( ˆX , ˆf , ˆw), but he/she has at his/her dis-
posal the same training set used by the target system ((D and
H ) consisting of all the banking transactions of the last few
months. Thank to this dataset, the attacker can compute a pre-
cise estimate of the aggregated features. The tuple describing
this setting is ΘbbI = (D, ˆX , ˆf , ˆw,H )1.
Black-Box. The attacker has no knowledge about the detec-
tion system and training data ( ˆD, ˆX , ˆf , ˆw). However, as mo-
tivated before, we assume that the attacker has retrieved one
month of past transactions ( ˜H ) to compute an approximation
of the aggregated features. Also, the attacker has at his/her
disposal a set of transactions different from the ones used by
the target detection system (i.e., an old leaked dataset or a
dataset belonging to another ﬁnancial institution). The tuple
describing this setting is Θbb = ( ˆD, ˆX , ˆf , ˆw, ˜H )1.
3.3 Attacker’s Capability
This characteristic highlights the power of the attacker con-
cerning the system. It outlines the attacker’s inﬂuence of
manipulating data and the domain-speciﬁc data manipula-
tion constraints. If the attacker can manipulate only the test
set, the attack is called exploratory or evasion. If the attacker
can manipulate both the test set and the training set, the attack
is called causative or poisoning. In this work, we focus on
evasion attacks. Therefore, the attacker can manipulate the
test set and execute transactions on behalf of the user. Then,
the fraud detection system will process these transactions fol-
lowing the procedure described in Figure 1. State-of-the-art
fraud detectors extract information from the past user’s trans-
actions to compute aggregated features that capture the user’s
spending behavior. As anticipated in Section 2, the attacker
is, therefore, subjected to a strong limitation: he or she can di-
rectly modify only some features, while others also depend on
the past behavior of the user. We go deeper into this concept
in Appendix B.1. As anticipated in Section 3.2, our approach
needs just a short transaction history (one month) of the target
victim and the possibility to perform transactions. There are
several ways to recover the data to perform an evasion attack.
The attacker can infect bank customers’ device with a Trojans
(e.g., Zeus, Citadel). Alternatively, the attacker can use phish-
ing techniques to retrieve the victim’s bank access credentials
and One Time Password (OTP). At this point, the attacker can
obtain the transactions carried out by the user and execute
them on his or her behalf. The attacker retrieves the transac-
tion history of the victim from the banking application and
computes aggregated features (e.g., total money spent in one
month, average daily money spent). With this information, the
attacker performs one or more evasive transactions without
being detected. A careful reader will notice that transaction
history can also be obtained by passively observing a user
with a persistent malware sample for a while.
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    287
4 Datasets Analysis and Engineering
Our dataset comes from an important banking group; we
worked on two real datasets that have been thoroughly in-
spected and cleaned from frauds. Data is anonymized by
removing personal information related to users and replaced
with hashed values that preserve equality. In Table 1, we show
the number of users and transactions for each dataset. The
most relevant features are: the transaction amount (Amount);
the hashed unique ID associated to the user (UserID); the date
and the time of the execution of the transaction (Timestamp);
the hashed IP Address of the connection from which the
transaction is performed (IP); the hashed International Bank
Account Number of the beneﬁciary (IBAN); the country code
of the beneﬁciary IBAN (IBAN_CC); the country code and
the autonomous system number from which the connection
comes (CC_ASN); the identiﬁer of a session (SessionID).
4.1 Feature Extraction Strategies
To design a good fraud detection algorithm, a feature selec-
tion and extraction strategy need to be chosen [1, 15, 31].
A strategy, which captures the user spending pattern, is a
combination of direct derivable features (e.g., amount, coun-
try) and aggregated ones (e.g., average, total). In practice,
it consists of grouping transactions by features and, then,
computing aggregated metrics. First, we selected the direct
derivable features and aggregated features used in previous
works [1, 9, 12, 32, 35]. Then, with the support of the banking
domain experts, we combine them using different strategies
that capture different aspects of user spending proﬁles. Finally,
for each fraud detector algorithm considered in this work, we
selected the strategies that performed best with our data in
detecting synthetic frauds (see Section 4.2 using the holdout
validation method. In particular, we empirically evaluated
each strategy by using a wrapper approach [21] that maxi-
mizes the True Positives (TPs) and minimizes False Positives
(FPs). Table 2 summarizes the three best strategies – we will
refer to them as A, B, and C – that we selected for the fraud
detectors. For an exhaustive description of each feature and
aggregation function, we refer the reader to Appendix A.
4.2 Dataset Augmentation: Synthetic Frauds
To train the supervised learning models considered in this pa-
per, we enrich datasets with synthetic frauds generated thanks
Table 1: Number of transactions and users for each dataset
DATASET
2012-2013
2014-2015
USERS
53,243
58,481
TRANSACTIONS
548,833
470,801
TIME INTERVAL
01/2012 - 08/2013
10/2014 - 02/2015
to the collaboration with domain experts and based on fraud
scenarios that replicate typical real attacks performed against
online banking users. In particular, we focus on most spread
malicious schemes, which are driven by banking Trojans or
phishing: information stealing and transaction Hijacking. In
the information-stealing scheme, the attacker exploits a phish-
ing campaign or a Trojan that infects the victim device to
steal the credentials and the OTP that the victim inserts in
the web pages of the targeted bank. The attacker can then
use the stolen credentials to perform transactions on behalf of
the victim. The connection comes from the attacker device,
not from the victim one. In the transaction hijacking scheme,
the Trojan infects the victim device and hijacks legitimate
bank transfers made by the user. The main challenge of such
an attack is that connections come from the victim’s device
(i.e., from the same IP, Session ID, and ASN). Typically, a
fraudster may act according to different strategies: he or she
may execute a single transaction with a high amount or mul-
tiple transactions with lower amounts. Therefore, to deﬁne
these fraud patterns, we use three variables: Total Amount,
the target amount that the attacker wants to steal; Number of
Frauds, the number of frauds in which the attacker wants to
divide the attack; Duration of the Attack, the total duration
time of the attack. So, for example, if the attacker performs an
attack with Total_Amount = e 10,000, Number_of_Frauds =
24, Duration = 1 day, he carries out one fraud of about e 417
per hour for one day. Using different combinations of the
values of these three variables and the two schemes described
above, we inject frauds in the dataset by randomly selecting
the victims. The banking datasets are known to be extremely
unbalanced, usually containing from 0.1% [31] to 1% [11] of
frauds. Therefore, common oversampling and undersampling
techniques are used to overcome this problem. In this work,
we generate about 1% of frauds.
5 Approach
We generate evasive transactions by exploiting an Oracle that
predicts the anomaly of a transaction. The Oracle is not 100%
accurate, and its performance depends on the degree of the
attacker’s knowledge (see Section 3.2. We can use this Oracle
to generate candidate transactions that will likely not be con-
sidered fraudulent by the targeted fraud detector. As shown in
Figure 2, our approach is composed of two phases: training
phase, in which we train the Oracle, and a runtime phase,
in which we generate the evasive transactions. During the
training phase, we train the Oracle by aggregating historical
transactions, as described in Section 4.1. In particular, the
Oracle is a surrogate fraud detector that models the spending
behaviors of users. It is based on a machine learning model
that is used in the runtime phase to classify the candidate
transactions that the attacker wants to perform. During the
runtime phase, depending on the attacker’s knowledge, he or
she observes and collects the transactions the victim carries
288    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
Table 2: Summary of the features used in our models. Direct features are data not aggregated. Data is aggregated with several
time-frames; i.e., ‘mean30d’ is the mean computed over 30 days while ‘mean7d’ is the mean computed over 7 days
STRATEGY
DIRECT FEATURES
AGGREGATED FEATURES
A
B
C
count1h, count1d, count30d, sum1h, sum1d, sum30d,
iban_count1h ,iban_count1d ,iban_count30d, iban_sum1h, iban_sum1d, iban_sum30d,
ip_count1h, ip_count1d, ip_count30d, ip_sum1h,ip_sum1d,ip_sum30d,
distance_from_mean, iban_distance_from_mean, ip_distance_from_mean,
mean, iban_mean, ip_mean, is_new_iban, is_new_ip.
count7d, count30d, mean7d, mean30d, std7d, std30d,
ip_count7d, ip_count30d, ip_sum7d, ip_sum30d,
iban_cc_count7d, iban_cc_count30d, iban_cc_sum7d, iban_cc_sum30d,
asn_count7d, asn_count30d, asn_sum7d, asn_sum30d,
count, mean, std, count_iban, mean_iban, count_session, mean_session, is_new_iban.
count1d, sum1d, mean1d, count7d, sum7d, mean7d, count30d, sum30d, mean30d,
iban_count1d, iban_count7d, iban_count30d,
iban_cc_count1d, iban_cc_count7d, iban_cc_count30d,
is_national_iban, is_international,
ip_count1d, ip_count7d, ip_count30d, asn_count1d, asn_count7d, asn_count30d,
mean, iban_count, iban_mean, session_count,