kNN
kFP
AWF
Baseline
0.6
Recall
(a) Non-defended dataset
1
0.8
0.6
0.4
0.2
CUMUL
DF
SDAE
0.8
1
0
0
0.2
0.4
0.4
0.35
0.3
0.25
kNN
kFP
AWF
Baseline
0.6
CUMUL
DF
SDAE
0.8
1
Recall
(b) WTF-PAD dataset
Figure 7: Open World: Precision-Recall curves.
kNN
kFP
AWF
Baseline
0.6
CUMUL
DF
SDAE
0.8
1
0.2
0.4
Recall
(c) W-T dataset
traces (one instance for 20,000 unmonitored sites). In the following
open-world experiments, we mainly focus on the precision and
recall to avoid the base-rate fallacy as mentioned above.
Figure 7 shows the precision-recall curves for WF attacks in our
non-defended, WTF-PAD and W-T datasets. Precision-recall curves
are used to represent the performance of the classifier as an alter-
native to ROC curves in imbalanced datasets. Imbalanced datasets
have an impact on precision, an important metric to measure per-
formance, however, ROC curves do not take precision into account.
This choice is specially relevant in the open-world evaluation, as the
size of the monitored set is typically orders of magnitude smaller
than the unmonitored set and as such it should be represented in
our testing set, thus leading to an imbalance [20].
As we see in the figure, the DF attack outperforms the other
state-of-the-art WF attacks in all three cases. In the non-defended
dataset, it is highly effective for any threshold. The CUMUL and
AWF attacks in Figure 7a have high precision but a very wide range
of recall, which means the attacks miss many monitored visits.
For traffic defended by WTF-PAD, Figure 7b shows a reduction
of both precision and recall for all WF attacks. The DF attacker
does the best. Tuned for high precision, it achieves precision of 0.96
and recall of 0.68. Tuned for high recall, it reaches 0.67 precision
and 0.96 recall. All the other WF attacks get close to the baseline
(random guessing) as the threshold decreases. The result shows
that the otherwise robust WTF-PAD is significantly undermined
by the DF attack.
Figure 7c shows the precision-recall curves for the W-T dataset.
The attacks all perform quite poorly, with all except the DF attack
close to the baseline. The DF attack does moderately better but still
has a precision of less than 0.36 in all cases.
5.8 A Deeper Look at W-T
Top-N prediction for closed-world W-T Wang and Goldberg ex-
plain that any attack using the main features of the state-of-the-art
attacks can get at most 50% accuracy against W-T [41]. In our
closed-world results, the DF attack nearly reached this theoretical
maximum. We now examine prediction probability for DF against
W-T. We consider top-N prediction, in which we look at not only
the highest probability (Top-1 prediction), but also the top N prob-
ability values. Surprisingly, we only need to look at the case of
N = 2. Top-2 prediction accuracy reaches 98.44% accuracy. This
likely means that DF is correctly selecting the real site and the
decoy site and, as expected, having to guess randomly between
them. We discuss the importance of this result in Section 6.
Asymmetric Collision (Closed-World) W-T requires that the client
create symmetric collisions between pairs of websites (site A is
molded with site B and vice versa). Since this requires storing all
the pairs, a simpler implementation would ignore this requirement
and have the client random select the decoy site for each access,
resulting in asymmetric collisions. In this setting, the DF attack
is much more accurate at 87.2%, compared to 49.7% with symmet-
ric collisions. This shows the importance of creating symmetric
collisions in W-T.
Asymmetric Collision (Open-World) We next evaluate the scenario
that 10% of the users do not follow the W-T guidelines, in that
they visit a non-sensitive site and choose a non-sensitive site as a
decoy instead of a sensitive one, and when they visit a sensitive site
they choose a sensitive site as a decoy instead of a non-sensitive
one. In this scenario, TPR is increased to 0.85 TPR, and FPR is
significantly reduced to 0.23 TPR, compared to the case that all
users strictly follow the procedure to create symmetric collisions
which has 0.80 TPR and 0.76 FPR. Thus, the major goal of W-T to
create the confusion between sensitive websites and non-sensitive
websites could be undermined in some scenarios.
6 DISCUSSION
The results of our study show that deep learning, and the DF ap-
proach in particular, is a powerful tool for WF attacks against Tor.
Further, our results against defended traffic show that WTF-PAD is
potentially vulnerable against deep-learning-based WF, with high
precision even in the open-world setting. Based on what we have
observed during experimental evaluations, we now discuss several
new directions in both improving the attacks and exploring designs
for more effective defenses.
Session 10A: TORCCS’18, October 15-19, 2018, Toronto, ON, Canada1938In our study, we observed
Improving Open-World Classification.
that designing the CNN architecture and tuning hyperarameters are
specific to both the environment and input data. For example, the
gap in performance between DF and AWF was much larger for the
open-world setting than the closed world. Additional exploration of
models in the open-world scenario, such as the depth and number
of convolutional layers, different filter sizes, or different dropout pa-
rameters, may yield improved results beyond what we have found
so far. More training data may also help the classifier better distin-
guish between monitored and unmonitored pages. Our simple data
format might be extended to include, for example, statistical timing
information that is currently excluded.
Finally, we note that the attacker can perform a targeted attack
on users in a semi-open-world setting, in which the targeted users
can be profiled as likely going to a subset of sites. For example, if the
user is known to only read one or two languages, then many sites
in other languages can be eliminated from the set. Alternatively,
a user’s profile can help the attacker identify some likely sites
for her interests, such that the classification of statistically similar
monitored sites may be dismissed as likely false positives.
Attack Costs. The time and effort needed to collect and train on
large data sets can have practical implications for weaker attack-
ers. Collecting large data sets as used in our experiments requires
multiple PCs running for several days. Both Juarez et al. [19] and
Wang and Goldberg [40] show that after 10-14 days, the accuracy
of WF attacks goes down significantly. A weak attacker might need
to choose between limiting the scope of monitored sites, living
with the results of using stale and inaccurate data, or using fewer
training samples per site. We note that, even though deep learning
works best with more data, DF performs well in the closed-world
setting even with smaller datasets. Additionally, we found that
while k-FP, AWF, and DF can be trained quickly on large datasets,
k-NN and CUMUL do not scale well to larger data. In particular,
due to hyperparameters grid search, CUMUL took us days to train.
Further exploring the trade-offs between scalability and accuracy
remain important areas for future research.
WTF-PAD. As DF can break WTF-PAD with over 90% accuracy in
the closed-world setting, we now consider why the defense failed by
examining the adaptive padding algorithm at the heart of WTF-PAD.
Adaptive padding aims to detect large timing gaps between bursts
and use padding to make these gaps less distinctive. While Juarez et
al. showed that this is effective against prior WF attacks [20], DF can
still detect patterns that remain after WTF-PAD is applied. When
used in analyzing images, CNN can detect an object (e.g. a dog)
anywhere in an image due to its use of convolutional layers with
multiple filters. Similarly, DF can detect any small region or portion
of distinguishing patterns, no matter where those patterns are
located in the trace. Adaptive padding only randomly disrupts some
patterns in the trace, leaving other patterns relatively unperturbed.
Walkie-Talkie. Walkie-Talkie (W-T) has an advantage over WTF-
PAD, as it focuses directly on features used in WF attacks, and it
seeks explicitly to create collisions. Indeed, W-T performed much
better than WTF-PAD against DF, which would seem to make it a
strong candidate for Tor. We note, however, that there are several
downsides to deploying W-T that require further investigation to
overcome:
• It requires the directory server to collect and distribute to all
clients a database of website patterns that can be used to
set the padding patterns. The patterns need to be kept up to
date to provide effective plausible deniability.
• Half-duplex communication adds to the latency of fetching
a site, 31% according to Wang and Goldberg [41], which is
a direct cost to end-user performance in a system that is
already slower than regular browsing.
• According to Wang and Goldberg, the browser is expected
to pair sensitive and non-sensitive pages and, ideally, pay
attention to issues such as language to select realistic cover
pages. To be most effective, then, the browser has to have a
lot of context about the user and the nature of her activity,
which is hard to build into the system.
• Given that DF achieves very high Top-2 accuracy, the attacker
can use auxiliary information such as language to guess the
real site. Further, if the system does not assign a decoy site to
a particular sensitive site or page (e.g. beyond the homepage
of the site), then that site is effectively uncovered, because it
will not be used as a decoy for any non-sensitive sites.
Alternative Defenses. To improve effectiveness against DF without
requiring extensive interaction with the browser, defenses could
apply adversarial machine learning [9, 13] to generate the adversar-
ial website traces to confuse the classifier. This is challenging to
do compared to adversarial machine learning in image processing
tasks, since the web trace is happening live, where the Tor client
does not know the full picture of the trace in advance. Further, Tor
is limited in how it can manipulate the trace—it can add dummy
packets and delay packets but not delete packets or speed them up.
Addressing these challenges would be interesting for future work.
7 CONCLUSION
In this study, we investigated the performance of WF using deep
learning techniques in both the closed-world scenario and the more
realistic open-world scenario. We proposed a WF attack called Deep
Fingerprinting (DF) using a sophisticate design based on a CNN
for extracting features and classification. Our closed-world results
show that the DF attack outperforms other state-of-the-art WF
attacks, including better than 90% accuracy on traffic defended by
WTF-PAD. We also performed open-world experiments, including
the first open-world evaluation of WF attacks using deep learning
against defended traffic. On undefended traffic, the DF attack attains
a 0.99 precision and a 0.94 recall, while against WTF-PAD, it reaches
a 0.96 precision and a 0.68 recall. Finally, we provided a discussion
on our results along with suggestions for further investigation.
Overall, our study reveals the need to improve WF defenses to be
more robust against attacks using deep learning, as attacks only get
better, and we have already identified several directions to improve
the DF attack further.
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their helpful feedback. A
special acknowledgement to Vera Rimmer for providing feedback
Session 10A: TORCCS’18, October 15-19, 2018, Toronto, ON, Canada1939that helped improve the paper. We appreciate the interesting dis-
cussions with Vera Rimmer, Dr. Leon Reznik and Igor Khokhlov
that helped developing this paper.
This material is based upon work supported by the National Sci-
ence Foundation under Grants No. CNS-1423163 and CNS-1722743.
In addition, this work has been supported by the European Com-
mission through KU Leuven BOF OT/13/070 and H2020-DS-2014-
653497 PANORAMIX. Juarez is supported by a PhD fellowship of
the Fund for Scientific Research - Flanders (FWO).
REFERENCES
[1] 2017. Keras. https://keras.io/. (2017).
[2] 2017. Users - Tor metrics. https://metrics.torproject.org/userstats-relay-country.
html. (2017).
[3] K. Abe and S. Goto. 2016. Fingerprinting attack on Tor anonymity using deep
learning. In in the Asia Pacific Advanced Network (APAN).
[4] Y. Bengio, P. Simard, and P. Frasconi. 1994. Learning long-term dependencies
with gradient descent is difficult. IEEE Transactions on Neural Networks 5, 2 (Mar
1994), 157–166. https://doi.org/10.1109/72.279181
[5] Sanjit Bhat, David Lu, Albert Kwon, and Srinivas Devadas. 2018. Var-CNN and
DynaFlow: Improved Attacks and Defenses for Website Fingerprinting. "https:
//arxiv.org/pdf/1802.10215.pdf". (2018). (accessed: August, 2018).
[6] Xiang Cai, Rishab Nithyanand, and Rob Johnson. 2014. CS-BuFLO: A congestion
sensitive website fingerprinting defense. In Workshop on Privacy in the Electronic
Society (WPES). ACM, 121–130.
[7] Xiang Cai, Rishab Nithyanand, Tao Wang, Rob Johnson, and Ian Goldberg. 2014.
A systematic approach to developing and evaluating website fingerprinting
defenses. In ACM Conference on Computer and Communications Security (CCS).
ACM, 227–238.
[8] Xiang Cai, Xin Cheng Zhang, Brijesh Joshi, and Rob Johnson. 2012. Touching
from a distance: Website fingerprinting attacks and defenses. In ACM Conference
on Computer and Communications Security (CCS). ACM, 605–616.
[9] N. Carlini and D. Wagner. 2017. Towards evaluating the robustness of neural
networks. In 2017 IEEE Symposium on Security and Privacy (SP). 39–57. https:
//doi.org/10.1109/SP.2017.49
[10] Heyning Cheng and Ron Avnur. 1998. Traffic analysis of SSL encrypted
web browsing.
Available
at http://www.cs.berkeley.edu/~daw/teaching/cs261-f98/projects/final-reports/
ronathan-heyning.ps.
Project paper, University of Berkeley (1998).
[11] Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter. 2015. Fast and
accurate deep networks learning by exponential linear units (ELUs). In in the
International Conference on Computer Vision (ICCV15)).
[12] Kevin P. Dyer, Scott E. Coull, Thomas Ristenpart, and Thomas Shrimpton. 2012.
Peek-a-Boo, I still see you: Why efficient traffic analysis countermeasures fail. In
IEEE Symposium on Security and Privacy (S&P). IEEE, 332–346.
[13] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-
Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Genera-
tive adversarial nets.
In Advances in Neural Information Processing Systems
27, Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Wein-
berger (Eds.). Curran Associates, Inc., 2672–2680. http://papers.nips.cc/paper/
5423-generative-adversarial-nets.pdf
[14] Jamie Hayes and George Danezis. 2016. k-fingerprinting: A robust scalable
website fingerprinting technique. In USENIX Security Symposium. USENIX Asso-
ciation, 1–17.
[15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770–778.
[16] Dominik Herrmann, Rolf Wendolsky, and Hannes Federrath. 2009. Website
fingerprinting: attacking popular privacy enhancing technologies with the multi-
nomial Naïve-Bayes classifier. In ACM Workshop on Cloud Computing Security.
ACM, 31–42.
[17] Andrew Hintz. 2003. Fingerprinting websites using traffic analysis. In Privacy
Enhancing Technologies (PETs). Springer, 171–178.