### NS and A Queries Analysis for DomainA.nz

**(a) NS queries for DomainA.nz**

Figure 3a illustrates the NS queries sent to DomainA.nz by Google's resolvers (AS15169) on February 6, 2020, during the .nz TsuNAME event. The x-axis represents individual resolvers, while the right y-axis shows the number of queries each resolver sent. The left y-axis displays the inter-quartile range (IQR) of the time intervals between queries, with the median value indicated by a white line in milliseconds.

Given that the TTL for these records is 86400 seconds (one day), we would expect, under normal conditions and assuming low packet loss, that no resolver should send more than one query on this date. However, some resolvers, particularly those using multi-cache or anycast-based mechanisms [34, 44], may send multiple queries. Despite this, all observed resolvers sent fewer than 10,000 queries.

**(b) A queries for ns1.DomainA.nz**

Figure 3b presents the A record queries for ns1.DomainA.nz. We can categorize the resolvers into three groups based on their query volume:

1. **Heavy Hammers**: Sent 162-186k queries on this day, with a frequency of one query every 300 ms.
2. **Moderate Hammers**: Sent 75-95k daily queries, with a frequency of one query every 590 ms, approximately double the rate of the heavy hammers.
3. **Less Aggressive Resolvers**: Sent up to 10k daily queries each. Although they are less aggressive, their larger numbers make their aggregated contribution significant.

The results for AAAA records, shown in Appendix A, are similar to Figure 3b.

### Surprising Behavior of Google's Resolvers

The observed heterogeneity in Google's resolver behavior was unexpected. We notified Google, and they confirmed and fixed the issue with their Public DNS service on February 5, 2020. This is discussed in detail in Section 4.5.

### Reproducing TsuNAME

To better understand TsuNAME, we conducted controlled experiments to recreate the problem on the Internet. This includes examining the role of clients (Section 4.2), multiple-step cycles (Section 4.3), and recursive resolvers (Sections 4.4 and 4.5).

#### 4.1 Controlled Experiments on a New Domain

To determine the lower bound of traffic to authoritative servers during a TsuNAME event, we performed a controlled experiment using RIPE Atlas [47] to a new domain under our control. This ensures there is no prior caching or query history.

**Setup:**
- We configured two third-level domains with cyclic dependencies (Table 2). Third-level domains were chosen because TsuNAME traffic targets the parent of the cyclic domains, allowing us to isolate traffic in our second-level domain authoritative servers.
- We used BIND9 [22], a popular open-source software, to run our own authoritative servers on Linux VMs located in AWS EC2 in Frankfurt, Germany.
- To minimize caching effects, we set the TTL for every record in the zone to 1 second (Table 2). Short TTLs increase the likelihood of cache misses and prevent misbehavior from being hidden by caches.

**Vantage Points (VPs):**
- We used approximately 10,000 RIPE Atlas probes [47, 48] as VPs. RIPE Atlas provides over 11,000 active devices distributed across 6,740 global ASes (as of January 2021).
- Each probe was configured to query once for an A record for `PID.sub.verfwinkel.net.`, where PID is the unique identifier of the probe. Unique queries reduce the risk of accidentally warming up the resolverâ€™s caches with queries from other VPs.

**Results:**
- Table 3 shows the results for this measurement. Approximately 9,700 Atlas probes placed queries through 16,800 recursive resolvers, sending 18,715 queries to their first-level recursives. Most responses were either SERVFAIL status codes or timeouts, indicating domain name resolution issues.
- On the authoritative server side, we observed queries from about 11,000 IP addresses belonging to nth-level servers in approximately 2,600 ASes. In total, these resolvers sent about 8 million queries to both authoritative servers, resulting in a 435x amplification factor compared to the 18,000 queries at the client-side.

**Identifying Problematic Resolvers:**
- Figure 5 shows the timeseries of queries and resolvers observed at our authoritative servers. We identified three phases:
  - **Warm-up Phase (x < 14:30 UTC)**: Initial rush of queries, with over 150k queries per authoritative server from about 7,500 resolvers.
  - **Looping Phase (14:30 UTC to 19:30 UTC)**: Some problematic resolvers without query limits continued to loop indefinitely.
  - **Offline Phase (after 19:30 UTC)**: After stopping our authoritative servers, even problematic resolvers could not obtain answers and stopped looping.

**Other ASes Affected:**
- Figure 6 shows the histogram of queries per source ASes. Google (AS15169) was responsible for 60% of the queries, but other ASes, such as AS200050 (ITSvision) and AS30844 (Liquid Telecom), also showed looping traffic. In total, 37 ASes were found to be vulnerable to TsuNAME (Table 4).

### Conclusion

The experiments highlight the significant impact of TsuNAME events and the importance of identifying and mitigating problematic resolvers. The observed behavior of Google's resolvers and the subsequent fix demonstrate the need for continuous monitoring and improvement in DNS infrastructure.