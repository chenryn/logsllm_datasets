themodelhelpsusersmaketheirsummaries.Adaptivesummariesalsohaveanaddi-
tionaladvantage,whichisbeingveryinterpretable.
The rest of this paper is organized as follows. Section2 discusses state-of-the-art
methods.Section3presentstheproposedmethodandSect.4presentstheexperimental
results.Section5discussesandjustifiestheobtainedresults.
2 Related Work
Producingasummaryisquiteacomplicatedtaskevenforapersonwhohasthedomain
knowledgeofwordsandconcepts,andyetitcanbeevenmoredifficultformachines.
The machine should have the ability of natural language processing and producing a
human-understandable summary and background knowledge. This is even more chal-
lenging,consideringthatdifferentpeoplehavedifferentinterestsandconcernstomake
theirsummaries,thesubjectivityproblemofsummarization.Thereexistdifferentcat-
egorization for document summarization problem. There exist different categories for
document summarization. For instance, one is based on the goal of the summariza-
tion task, which includes generic, domain-based (topic-focused) [10], or query-based
summarizationalgorithm[34].Wealsohaveothercategoriesfordocumentsummariza-
tion which is based on the application of summarization such as article summariza-
tion [35], review summarization [18], news summarization [36], and also summariza-
tionforanomalydetection[1].Inthispaper,weconsidertheproblemofsummarization
fromatraditionalperspectiveaswellasrecentpersonalizedandinteractiveapproaches,
asdiscussedbelow.
2.1 TraditionalApproaches
Traditional state-of-the-art approaches produce only a single, globally short summary
for all users. There are different perspectives to categorize traditional summarization
approaches. The main aspect is considering the process and the output type of the
summarization algorithms, which include extractive and abstractive approaches. The
problem in both tasks is defined as summarizing a set of related articles and produc-
ing a short (e.g., 3–6 sentences) single summary, which conveys the most informa-
tiveinformation.Abstractiveapproachesgeneratesummariesbyinterpretingthemain
concepts of a document and then stating those contents in another format. Therefore,
abstraction techniques are a substitute for the original documents rather than a part
of it. Consequently, abstractive approaches require deep natural language processing,
such as semantic representation and inference. However, they are challenging to pro-
duce and yet have not arrived at a mature stage [15]. On the other hand, the extrac-
tivetextsummarizationapproachselectssomesentencesasrepresentativeoftheorig-
inaldocuments.Thesesentencesarethenconcatenatedintoashortertexttoproducea
AdaptiveSummaries 285
meaningful and coherent summary [17]. Early extractive approaches focused on shal-
low features, employing graph structure, or extracting the semantically related words.
Different machine learning approaches are also used for this purpose, such as naive-
Bayes, decision trees, log-linear, and hidden Markov models [13–15]. Recently, the
focusforbothextractiveandabstractiveapproachesismainlyonneuralnetwork-based
anddeepreinforcementlearningmethods,whichcoulddemonstratepromisingresults.
They employ word embedding [29] to represent words at the input level. Then, feed
thisinformationtothenetworktogaintheoutputsummary.Thesemodelsmainlyusea
convolutionalneuralnetwork[8],arecurrentneuralnetwork[9,25]orcombinationof
thesetwo[26,33].Theproblemisthattheseapproachesdonotconsidertheusers’opin-
ionsandarenotinteractive.Consequently,thesummariesarenotwell-tailoredfromthe
users’perspective.
2.2 PersonalizedandInteractiveApproaches
Whilemoststate-of-the-artapproachesproduceasinglegeneralsummaryforallusers,
afewattemptstotakeauser’spreferencesintoaccountaredefinedaspersonalizedor
interactivesummarizationtechniques.
Interactivesummarizationapproachesincludeapproacheswhichrequirehumanto
interactwiththesystemtomakesummaries.Unlikenon-interactivesystemsthatonly
present the system output to the end-user, Interactive NLP algorithms ask the user to
provide certain feedback forms to refine the model and generate higher-quality out-
puts tailoredtotheuser.Mostapproaches inthiscategory create asummary and then
require humans to cut, paste, and reorganize the critical elements to make the final
summary[27,28].Multipleformsoffeedbackalsohavebeenstudiedincludingmouse-
clicksforinformationretrieval[6],post-editsandratingsformachinetranslation[11],
error markings for semantic parsing [21], and preferences for translation [20]. Other
interactivesummarizationsystemsincludetheiNeATS[22]andIDS[19]systemsthat
allowuserstotuneseveralparameters(e.g.,size,redundancy,focus)tocustomizethe
producedsummaries.
TheclosestworktooursisproposedbyAvineshandMeyer[3],aninteractivesum-
marizationapproachthatasksuserstolabelimportantbigramswithincandidatesum-
maries.Thentheyusedintegerlinearprogramming(ILP)toextractsentences,covering
as many important bigrams a possible. However, importance is a binary value in this
system,importantandunimportant.TheworkbyOrasanandHasler[28]isalsoclosely
relatedtoourssincetheyassistusersincreatingsummariesforasourcedocumentbased
ontheoutputofagivenautomaticsummarizationsystem.However,theirsystemisnei-
therinteractivenorconsiderstheuser’sfeedbackinanyway.Instead,theysuggestthe
output of the state-of-the-art (single-document) summarization method as a summary
draftandasktheusertoconstructthesummarywithoutfurtherinteraction.Theproblem
ofconcept-basedILPsummarizationframeworkwasfirstintroducedby[7].However,
theyusedbigramsasconcepts[5,23]andeitherusedocumentfrequency(i.e.thenum-
berofsourcedocumentscontainingtheconcept)asweights[5,32].Asourinteractive
approachweallowsforanycombinationofwords,evensentenceasconceptsandalso
theweightsareuserdefinedparameters.
286 S.Ghodratnamaetal.
Ourmodelsalsoemployanoptimizationfunctiontomaximizeuser-desiredcontent
selection.AdaptiveSummariescreatesapersonalizedsummarythatbettercapturesthe
users’needsandtheirdifferentnotionsofimportancebykeepingthehumanintheloop.
Instead of binary labeling of concepts as important and unimportant, users can give
feedback to either select or reject a concept, define the level of importance or being
unrelated,andtheuser’slevelofconfidenceinprovidinganiterativefeedbackloop.In
thefollowingsection,weformalizetheproposedapproach.
3 AdaptiveSummaries
The goal of Adaptive Summary is to interact with users to maximize the user-desired
contentingeneratingpersonalizedsummariesforusersbyinteractionsbetweensystem
anduser.Inthisproblem,theinputisasetofdocumentswheretheoutputisahuman-
readable summary consisting of a set of sentences with the user’s preferred size. The
novelty of this paper is that the user can select the desired content in making person-
alized summaries. In this setting, users can choose either reject or accept action for
selectingaconceptbeingincludedinthesummary,theimportanceofthatconceptfrom
users’perspectives,andtheconfidencelevelofusers’feedback.Thisismodeledasan
objectivefunctiontomaximizethescoreofsentencesbasedontheuser-selectedbud-
get. Besides, to guarantee interactive speed to keep the user engaged, we propose a
heuristicapproachforselectingusers’queries.Inthefollowing,weformallydefinethe
summarizationtasksconsideredinthispaper.
3.1 ProblemDefinition
The input is a set of documents {D 1,D 2,...,D N} while each document consists of
a sequence of sentences S = [s 1,s 2,...,s n]. Each sentence s i is a set of concepts
{c 1,c 2,..,c k}whereaconceptcanbeaword(unigram)orasequenceofwords(Name
entityorbigram).Thisframeworkoptimizesthesummarizationoutcomeforaspecific
user. Therefore, the user interacts with the system and gives feedback to make sum-
maries.Thisfeedbackisintheformof:i)ActionAwhichperformonaconceptwhere
the values can be accept (A=1) or reject(A = −1), ii) concept weight, W, corre-
spondingtoconcepts’importanceaccordingtotheuser’sopinion,andiii)thelevelof
confidenceforthechosenaction,conf.TheoutputisasetofsentencesS defineasthe
summaryaccordingtothebudgetlimit(B)definedbytheuser.
3.2 Methodology
ThegoalofAdaptiveSummariesistoincorporatetheuserpreferenceiniterativelymak-
ing summaries. Therefore, a continuous objective function is defined for analytically
optimizingtheuserpreference.Inthefirstiteration,asummaryisgeneratedusingour
previous work, ExDos [12], that ranks sentences based on a general notion of impor-
tanceusingdynamiclocalfeatureweighting.Italsodemonstratessentencesingroups
basedonsimilaritydefinedin [12]tohelpusersinselectingcontent.Theuserthencan
selectanactionA,whichperformsonaconceptwherethevaluescanbeaccept(A=1)
AdaptiveSummaries 287
orreject(A=−1).Next,foreachconceptusercandefineaweight,W,corresponding
totheconcepts’importancebasedontheuser’sopinion.Next,theuserdefinesthelevel
of confidence, conf, for the chosen action. When the action is accepted, this weight
representstheimportanceoftheconcept,andwhentheactionisrejection,theweights
arethevalueforbeingunrelated.Thelogicbehindthisisthatnotallconceptshavean
equallevelofimportance.Forinstance,whenuserssearchforanillness’ssymptoms,a
headache may not be as important as sneezing from users’ perspectives. On the other
hand,afevermaynotbeasunrelatedasacne.Theoverallobjectivefunction,whichis
anIntegerLinearProgramming(ILP),isdefinedas:
(cid:2) (cid:2)
maximize A×conf(A)×W
cj
si∈Dc (cid:2)j∈si
(1)
s.t. length(s)<B
s∈Summary
Where A is the action, c j is the concept in a given sentence (s i), D the source
documents,W isthecorrespondinguser-preferenceweightfortheconceptc andB
cj j
isthesummarylengthgivenbyuser.Theobjectivefunction1maximizestheoccurrence
ofconceptswithmaximumweightsandconfidentlevel.Thesudo-codeoftheproposed
algorithmisreportedinAlgorithm1.Thefollowingisthehigh-leveldescriptionofour
approach:
– Toacceleratetheprocessofmakingasummary,infirstiterations,thesentencesare
rankedbyourpreviousapproach,ExDos.Thentheseweightsareupdatedbasedon
users’feedback.
– Inordertopreventusersfrombeingoverwhelmed,thesimilarsentencesusingour
previousapproach,ExDos,aregroupedandshowntotheusersimultaneously.
– Ifweightsofaconceptgetsupdatedinaniteration,theweightsareupdatedforevery
occurrenceofthatconcept.
– If the user rejects a sentence (A si = −1), then the weight of the sentence is set
to zero (W si = 0). However, the system does not update the weights of concepts
includedinthesentenceastheremaybedifferentreasonsforrejectionofasentence
suchasredundancyornotbeingimportant.
– Aconceptisonlyselectedifitispresentinatleastoneoftheselectedsentences.
– Thenumberofsentencesisauserparameterdefineineachiterationandtheconfi-
denceinfeedbackisset1bydefault.
– Iftherearenomoreconceptstoquery,theprocessterminated.Tooptimizethesum-
marycreationbasedonuserfeedback,conceptweightsiterativelychangetheinthe
objectivefunction.
4 Experiment
Inthissection,wepresenttheexperimentalsetupforimplementingandassessingour
summarization model’s performance. We discuss the datasets, give implementation
details,andexplainhowsystemoutputwasevaluated.
288 S.Ghodratnamaetal.
Algorithm1AdaptiveSummaries
Input:DocumentClusterD.
Output:OptimalSummaryGeneratedbyuser(S).
procedureADAPTIVESUMMARIES.
RankedSentences←ExDos(D)
whileuserisnotsatisfieddo
Concepts←ExtractNewConcepts(RankedSentences)
ifConcepts(cid:3)=∅then
Askuserforaction(A),importance(W),andconfidence(Conf).
SelectsentencestomaximizeEquation1.
endif
return Summary(S)
endwhile
return Summary(S)
4.1 Data
To compare the performance of Adaptive Summaries with the existing leading
approaches, experiments on two benchmark datasets, DUC20021 and CNN/Daily
Mail[16]2areperformed.Thedocumentsareallfromthenewsdomainandaregrouped
intovarioustopicclusters.Weanalyzeoursystembasedondifferentcriteria,including
selectingdifferentunitsofconcepts,numberofiterations,andtheROUGEscore.
4.2 Evaluation
WeevaluatethequalityofsummariesusingROUGE(Recall-OrientedUnderstudyfor
Gisting Evaluation) measure [24]3 defined below. It compares produced summaries
against a set of reference summaries. The three variants of ROUGE (ROUGE-1,
ROUGE-2, and ROUGE-L) are used. ROUGE-1 and ROUGE-2 are used to evaluate
informativeness, and ROUGE-L (longest common subsequence) is used to assess the
fluency.WeusedthelimitedlengthROUGErecall-onlyevaluation(75words)forcom-
parisonofDUCtoavoidbeingbiased.Besides,thefull-lengthF1scoreisusedforthe
evaluationoftheCNN/DailyMaildataset.
(cid:3) (cid:3)
Count (gram )
ROUGE n = S(cid:3)∈{ReferenceSummaries} g(cid:3)ramn∈S Coum na tt (c gh ram )n (2)
S∈{ReferenceSummaries} gramn∈S n
Intraditionalapproaches,toevaluateasummarizationsystem,themeanROUGEscores
acrossclustersusingallthereferencesummariesarereported.AdaptiveSummariesis
1ProducedbytheNationalInstituteofStandardsandTechnology(https://duc.nist.gov/).
2https://github.com/abisee/cnn-dailymail.
3We run ROUGE 1.5.5: http://www.berouge.com/Pages/defailt.aspx with parameters -n
2-m-u-c95-r1000-fA-p0.5-t0.
AdaptiveSummaries 289
Table1.ROUGEscorecomparisononCNN/DailyMailusingF1variantofROUGE.
Model Rouge-1Score Rouge-2Score Rouge-LScore
LEAD-3 39.2 15.7 35.5
NN-SE 35.4 13.3 32.6
SummaRuNNer 39.9 16.3 35.1
HSSAS 42.3 17.8 37.6
BANDITSUM 41.5 18.7 37.6
Adaptivedictionary 42.9 20.1 38.2
Adaptivereference 41.4 19.7 32.1
Table2.ROUGEscore(%)comparisononDUC-2002dataset.
Model Rouge-1Score Rouge-2Score Rouge-LScore
LEAD-3 43.6 21.0 N/A
NN-SE 47.4 23.0 N/A
SummaRuNNer 46.6 23.1 N/A
HSSAS 52.1 24.5 N/A
UpperBound 47.4 21.6 18.7
Avinesh-Al 44.8 18.8 16.8
Avinesh-Joint 44.4 18.2 16.5
Adaptivedictionary 50.4 22.1 18.4
Adaptivereference 46.5 20.1 18.8
evaluated based on the mean ROUGE scores across clusters per reference summary
in personalized summarization approaches. It is worth mentioning that this approach
aims at facilitating making summaries for individual users, not improving the general
accuracyofsummaries.Sincethisapproachisinteractive,itrequireshumanstointeract
withthesystemforauserstudybasedevaluation.However,collectingdatafordifferent
settings from different humans is too expensive. Thus we simulate the users’ behav-
ior by generating feedback. To simulate users’ behaviors, we analyze two variations
of the proposed approach. In the first approach (AdaptiveDictionary), to simulate the
users’behavior,wedefineadictionaryfortenclustersoftopics,includingtheessential
conceptsandweightswithdefinedactionsforeachconcept.Inthesecondone(Adap-
tiveReference), the reference summaries are considered as the users’ feedback. The
concepts are essential if they are presented in the reference summary. Therefore, we
assignthemaximumweightforthepresentedconcepts.Wecompareourapproachwith
bothtraditionalandpersonalizedapproaches.TheresultsarereportedinTables1and2
for both datasets. From the results, it can be seen that the proposed approach nearly
reachestheupperboundforbothdatasets.Besides,theROUGEanalysiswithrealusers
doesnotshowanypatternofincreasingordecreasing.However,itisanexpectedresult
since this approach aims to optimize the summary for individual users, not the gold
standardsummary.
290 S.Ghodratnamaetal.
Fig.2.ThleftimageshowstheROUGE1basedoniterationnumberandtherightimageshows
theROUGE2basedoniterationnumber.Thegreensamplesarewhenthepermittedconceptunit
areunigram,bluebigramandredthesentences.(Colorfigureonline)
Fig.3. 1) Number of iteration and ROUGE1 for DUC-2002. 2) Number of iterations versus
ROUGE2values.3)NumberofactionsversusiterationsforDUC2002.
To compare the concepts’ unit’s effect, we evaluate our approach based on three-
unitmeasures,includinguni-gram,bi-gram,andsentences.Althoughourmodelreaches
the upper bound when using unigram-based feedback, they require significantly more
iterations and much feedback to converge, as shown in Fig.2. We analyze the speed