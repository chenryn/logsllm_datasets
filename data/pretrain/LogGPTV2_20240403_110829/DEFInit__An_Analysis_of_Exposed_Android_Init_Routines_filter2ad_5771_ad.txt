Case Study 3: Reading sensitive logs. Three popular An-
droid vendors exposed sensitive system logs via Init services
that write the resulting log ﬁles on external storage. These
system logs provide a timestamped trace of messages, events,
and stack traces. Android offers a shared logging mecha-
nism wherein any app can write arbitrary log messages using
standard framework APIs. Processes do not always sanitize
sensitive user data prior to writing it to the log; therefore, the
Android system does not allow third-party apps to access the
global system log. Since Init services tend to run as privileged
users, they can access sensitive logs from all processes. In
each of the three cases, the vendors used an Init service to
execute a shell script as the root user to execute the logcat
command. Two of the three vendors also exposed the output
of the dumpsys command that calls routines in each frame-
work service to dump its state which tends to contain sensitive
information. Active monitoring and mining of these logs us-
ing regular expressions by an adversarial local process poses
a serious risk to user’s security and privacy.
Case Study 4: Screen recording. One vendor had ﬁve
ﬁrmware that exposed the capability to initiate a screen record-
ing wherein the resulting recording ﬁle is made available to
USENIX Association
30th USENIX Security Symposium    3695
other processes on external storage. A screen recording pro-
vides an actual screen capture and allows an adversary to mon-
itor the contents of device screen and the actions taken by a
user. The recordings can reveal data such as passwords, credit
card numbers, notiﬁcation and message content, and other
sensitive information. The screen recording was performed
in a shell script using the standard screenrecord command
where the recording has a duration of 30 min.
6.5 Runtime Performance of DEFINIT
We conclude our evaluation by providing measurements of
the runtime performance of DEFINIT. We implemented
DEFINIT in 7K-SLOCs of Python on top of BinaryNinja [26]
for ELF analysis and Kryptowire’s internal Android static
analysis engine [27] for app analysis. We conducted our anal-
ysis on one Ubuntu 20.04 server with 8-core Intel(R) Xeon(R)
E5-4620 2.20GHz and 512 GiB of RAM.
DEFINIT took about 5 min on average to unpack a
ﬁrmware, with 90% of the images ﬁnished unpacking in less
than 20 min. Processing Init ﬁles, collecting traces, and build-
ing IDGs took about 30 min on average, with 90% ﬁnishing
in less than 50 min. Analyzing pre-installed apps took 7 min
on average with 90% of the apps ﬁnishing in less than 10 min.
Each ﬁrmware image was analyzed to completion separate
from other images and we did not perform any particular opti-
mizations to improve the performance of DEFINIT. Overall,
90% of the ﬁrmware ﬁnished in less than 70 min end-to-end
which is reasonable in practice.
7 Discussion and Future Work
Analysis Limitations. The goal of this study is to explore
the impact of Init routines added by vendors to Android and
called from privileged apps with potentially lax app compo-
nent access control. Towards this end, we developed DEFINIT
to help us conduct this study. The goal of DEFINIT itself is
not to automatically reason whether an identiﬁed exposed
routine is exploitable or not, but to identify instances that are
of potential security impact, bringing them to the surface for
an analyst to further investigate and verify. Automatically
reasoning about exploitability is an extremely challenging
task that has no viable solution in practice [28, 29].
The analysis we performed in §5 is conservative as we
tuned our analysis to avoid the constructs that are known to re-
sult in false information ﬂows when performing static analysis.
These constructs are commonly handled in an unsound man-
ner in practice to avoid overapproximations that may result
in too much noise in the ﬁndings that analysts have to comb
through. For instance, the ICFGs constructed by DEFINIT
for ELF binaries and apps were under-approximated to avoid
noise in the results as we limited indirect/virtual call resolu-
tion to only indirect calls that have one possible candidate
callee based on the call receiver information available at an
indirect call site. Other constructs that we did not handle in-
clude reﬂection, ﬂows through containers, inter-component
communication, and ﬂows that cross between managed and
native code (e.g., ﬂows through JNI calls). We also considered
permission-protected components as unexported, regardless
of the permission protection level [30].
For trace collection, we could have opted for more involved
techniques or even ﬁrmware emulation [31, 32], though this
comes with a multitude of nontrivial challenges beyond the
scope of this work [33–35]. From a practical perspective,
we believe our analysis was at an adequate level given the
ﬁndings and goals of this study. More sophisticated analy-
sis can be incorporated in the future to detect obfuscated or
deeply-buried behaviors.
Manual Effort. The manual steps performed in this study
were pertinent to shortlisting sensitive commands and APIs,
developing the detection rules, and analyzing the annotated
traces produced from DEFINIT that matched interesting rules.
Enumerating and shortlisting the sensitive commands took
one day for three persons.
Developing the detection rules used in DEFINIT took about
four workdays for one person. We believe our selection pro-
vides reasonable coverage for the purpose of this study, though
it is straightforward to add more commands and rules in the
future as needed. This step is standard in behavioral binary
analysis in practice and is unlikely to get fully automated
as it requires expert knowledge. It may be possible to au-
tomate rule creation to some extent by using data mining
techniques [36, 37] on a large labeled corpus of traces of
Android-speciﬁc potentially sensitive behaviors or a generic
model of what constitutes a sensitive behavior on Android.
This can be an interesting direction for future work.
Analyzing and verifying the ﬁndings in Table 8 took about
seven workdays for one person. Since the execution paths
identiﬁed by DEFINIT cross multiple OS layers, this makes
end-to-end automated dynamic veriﬁcation extremely chal-
lenging, which, at a minimum, would requite a rooted tar-
get device and an advanced Android-aware, cross-layer dy-
namic symbolic execution engine. Overall, the manual effort
involved was quite reasonable given the number of ﬁrmware
and apps in our data set and the number of cases we veriﬁed.
SELinux and Exploitation. We made the assumption that
vendors have conﬁgured their ﬁrmware images properly for
their customizations to work as intended. This includes conﬁg-
uring the necessary SELinux labels, rules, and transitions for
their custom routines to function. This also extends to the use
of Vendor Init [38] where vendors are expected to place ven-
dor Init .rc ﬁles and binaries in /vendor as needed for them
to run under a SELinux domain separate from the system Init
domain. DEFINIT detects behaviors that can be exploited
through individual pre-installed apps, and all constructs (prop-
erty names, values, exceutables, commands and APIs) along
3696    30th USENIX Security Symposium
USENIX Association
a vulnerable path are hardcoded. Therefore, SELinux transi-
tions should not block these ﬂows since the involved actors
(pre-installed apps, Init routines and their executables) are
the ones expected by SELinux and intended to operate in
this manner, unless there are considerable errors on the part
of vendors due to a lack of testing. In the cases we dynami-
cally veriﬁed, we did not encounter any SELinux restrictions
preventing exploitation.
For the scenarios where one sensitive behavior could be
split between multiple apps (e.g., attacker invokes one pre-
installed app to record a video then a different app to move
ﬁles to external storage), it may be possible that SELinux
prevents exploitation of these behaviors if the triggered rou-
tines have different SELinux contexts and the vendor did not
add transitions that allow these behaviors to manifest. We
leave detecting these multi-app behaviors and handling their
SELinux constraints to future work.
Threats to Validity.
In our implementation of DEFINIT,
we did not check for dynamic access control constructs (e.g.,
dynamic permission checks, UID checks, conﬁrmation dia-
logues) that may fall on the path from a pre-installed app to the
call site setting a system property. We manually checked only
the ﬁndings in Table 8 for these constructs during veriﬁcation.
Therefore, the results provided in Tables 7 and A.6 should
be taken with this in mind. Reasoning about dynamic access
control automatically is a challenging task that requires mod-
eling relevant code constraints dominating a call site setting a
system property, modeling runtime environment constraints,
and solving these constraints using a symbolic solver, which
we leave for future work.
While we tried to cover a representative sample of the An-
droid market, our ﬁrmware data set was not uniform across
all vendors and Android versions. Some of the vendors in
our data set (e.g., Itel) also had signiﬁcantly smaller ﬁrmware
images and fewer Init routines compared to others. The un-
packing process of some of the proprietary image formats in
our data set may have also missed some ﬁles and partitions.
Therefore, the differences between vendors in our results may
not be statistically signiﬁcant to substantiate differences in
the overall security posture of the vendors and should be
interpreted carefully in this regard.
Potential Countermeasures. There are various measures
that AOSP, Google, and vendors can take to reduce the secu-
rity impact of Init customizations. The ﬁrst step is perhaps
for Android Init to default child processes spawned from Init
to an unprivileged user and SELinux domain (e.g., a nobody
user). Defaulting to a low-privilege user and domain can con-
ﬁne the impact of exploiting exposed routines and binaries
mistakenly leftover by vendors.
Second, given that Google has established a set of require-
ments as part of the Android Compatibility Deﬁnition Doc-
ument (CDD) [39] that vendors must adhere to in order to
brand their devices as Android-compatible, the CDD should
enforce strict requirements on vendors to not add privileged
custom Init routines that can be programmatically triggered
from outside Init itself unless the functionality is key for
normal system operation. This can be a mundane process
and may not be straightforward to test by the CDD, but it is
essential to conﬁne the impact of exploiting potential ﬂaws
introduced by Init customizations.
Third, Android can block interaction between unprivileged
apps and pre-installed apps that set system properties. In fact,
Android can go a step further by blocking interaction between
third-party apps and privileged apps by default unless the user
explicitly grants a third-party app the permission to interact
with a pre-installed app. This step, despite putting the burden
on the user, could easily thwart most privilege-escalation at-
tacks from third-party apps trying to parasitize on privileged
apps without user consent. Adopting this approach would
likely need to be phased in over time in order to not immedi-
ately break the current open communication model Android
employs among apps co-located on an Android device. In
addition, vendors should enforce proper access control at
the boundaries of their privileged apps to minimize confused
deputy attacks initiated by enterprising third-party apps trying
to indirectly trigger sensitive functionality.
Finally, Android SELinux policies could default to pre-
venting executables launched by Init routines from writing
to external storage. This could easily block multiple of the
ﬂaws identiﬁed in our study that capitalize on leaking infor-
mation to a publicly-readable path on external storage. A
better separation of pre-installed apps where the ones that
are likely to be interacted with by third-party apps are not
allowed to set Init properties or perform sensitive operations
may also help here. Some of the most severe cases (e.g., dis-
abling SELinux) should also display a clear warning and ask
the user if the action that was initiated programmatically can
proceed. Speciﬁcally, enforcing user interaction for many of
the extensive system logging routines can help to safeguard
the user. This is by no means a perfect solution, but if ex-
plained clearly, it will allow the user to have greater control
of the security of their device.
8 Related Work
Numerous prior works have studied the security issues intro-
duced by Android vendor customizations at different layers of
the Android OS. At at the application layer, Woodpecker [2]
was among the very ﬁrst studies to detect capability leakages
on Android. It analyzed eight devices and found that 11 out
of 13 privileged permissions can leak to unprivileged apps.
SEFA [3] analyzed 10 ﬁrmware images and found that over
85% of their pre-installed apps were overprivileged. Hare-
Hunter [4] discovered thousands of hanging attribute refer-
ences (Hares) in 97 ﬁrmware images, allowing unprivileged
USENIX Association
30th USENIX Security Symposium    3697
apps to claim access to potentially sensitive functionalities by
using attributes hardcoded in pre-installed apps.
More recently, Gamba et al. [40] conducted a comprehen-
sive study of multiple devices and identiﬁed several instances
of advertising and data collection without user consent. Firm-
Scope [11] performed a large scale static analysis study of
pre-installed apps in more than 2000 ﬁrmware images from
top Android vendors and identiﬁed numerous privilege esca-
lation vulnerabilities due to improper access control in pre-
installed apps. The authors of FirmScope identiﬁed a few
number of apps that were able to set arbitrary system prop-
erties, which while relevant to our study, they did not assess
the impact of setting these properties nor how they may be re-
lated to custom Init routines added by vendors. Nevertheless,
privilege-escalation ﬂaws in pre-installed apps in general can
potentially enable more attack vectors for launching sensitive
Init routines, e.g., by exploiting a command execution ﬂaw in
a privileged app to directly call an executable launched by a
sensitive Init routine running with the system UID.
For security issues introduced to the Android framework
layer (sometimes referred to as the Android middleware), Tian
et. al. [9] analyzed 2,000 ﬁrmware images and identiﬁed 3,500
AT Commands invokable over USB, multiple of which can
perform sensitive functionalities, such as bypassing the screen
lock and factory resetting the device. Most of these commands
were hardcoded in custom ELF libraries added by vendors to
the framework as part of the Radio Interface Layer (RIL) yet
a few of them were also introduced by privileged pre-installed
apps. ARF [10] analyzed the AOSP framework and identiﬁed
cases of confused deputies due to inconsistent access checks
in framework service components. FANS [41] fuzzed native
framework services on six Android 9.0 devices and identiﬁed
30 vulnerabilities and thousands of crashes. These studies are
complimentary to our work. Studying Init capabilities leaked
through vendor customizations to the Android framework
itself (e.g., via new framework APIs introduced by vendors)
is a possible interesting area for future work.
At the kernel level, ADDICTED [14] analyzed vendor de-
vice drivers and found multiple privilege escalation vulnera-
bilities that allow third-party apps to perform sensitive func-
tionalities without permission by talking to open interfaces
in custom device drivers. BootStomp [13] found eight vul-
nerabilities in the bootloaders used by a number of devices,
allowing attackers to potentially compromise the entire chain
of trust established at boot time or cause denial of service.
BigMac [16] analyzed the SELinux policies on two devices
and identiﬁed multiple policy inconsistencies that allow un-
privileged actors to load kernel modules and communicate
with root processes.
To the best of our knowledge, none of the prior studies have
analyzed vendor customizations of the Android Init process
that are visible at the application layer, and the security impact
of these changes, which is what we focus on in this study.
9 Conclusion
Android Init routines can provide privileged operation in-
terfaces to privileged system apps that can trigger them by
setting system properties. The privileged capabilities of these
Init routines can be exposed to unprivileged third-party apps
through open interfaces in privileged apps triggering the rou-
tines. To understand the prevalence and security impact of
exposed Init routines, we designed DEFINIT as a system
to help detect Init routines exposed by privileged apps and
their behaviors. We studied 259 ﬁrmware covering Android
8 to 11 from the top 21 vendors worldwide and identiﬁed
numerous vulnerabilities that allow unprivileged third-party
apps to perform sensitive functionalities, including capturing
network trafﬁc, reading system logs, and disabling SELinux,
among others. Our ﬁndings demonstrate the signiﬁcance of
these changes to Init and the need for rigorous Android regu-
lations to reduce and conﬁne the impact of potential security
weaknesses introduced by vendors.
Acknowledgments
We thank the anonymous reviewers and our shepherd, Antonio
Bianchi, for their insightful comments on earlier versions of
this work. We thank Jinghan Guo for assisting with ﬁrmware
unpacking and veriﬁcation. Part of this work was done while
Yuede Ji was at George Washington University.
Opinions expressed in this article are those of the authors
and do not necessarily reﬂect the ofﬁcial policy or position of
their respective institutions.
References
[1] “Mobile operating system market share worldwide,” https://gs.
statcounter.com/os-market-share/mobile/worldwide/.
[2] M. C. Grace, Y. Zhou, Z. Wang, and X. Jiang, “Systematic
detection of capability leaks in stock android smartphones.” in
NDSS, vol. 14, 2012.
[3] L. Wu, M. Grace, Y. Zhou, C. Wu, and X. Jiang, “The im-
pact of vendor customizations on android security,” in 2013
ACM SIGSAC Conference on Computer and Communications
Security (CCS).
[4] Y. Aafer, N. Zhang, Z. Zhang, X. Zhang, K. Chen, X. Wang,
X. Zhou, W. Du, and M. Grace, “Hare hunting in the wild an-
droid: A study on the threat of hanging attribute references,” in
22nd ACM SIGSAC Conference on Computer and Communi-
cations Security (CCS).
[5] J. Gamba, M. Rashed, A. Razaghpanah, J. Tapiador, and
N. Vallina-Rodriguez, “An analysis of pre-installed android
software,” in 2020 IEEE Symposium on Security and Privacy
(S&P).
[6] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bartel, J. Klein,
Y. Le Traon, D. Octeau, and P. McDaniel, “Flowdroid: Precise
context, ﬂow, ﬁeld, object-sensitive and lifecycle-aware taint
3698    30th USENIX Security Symposium
USENIX Association
analysis for Android apps,” Acm Sigplan Notices, vol. 49, no. 6,
2014.
[22] “disclosures/getsuperserial.md at master,” https://github.com/
rednaga/disclosures/blob/master/GetSuperSerial.md.
[7] F. Wei, S. Roy, X. Ou et al., “Amandroid: A precise and general
inter-component data ﬂow analysis framework for security
vetting of android apps,” in 2014 ACM SIGSAC Conference on
Computer and Communications Security (CCS).
[8] L. Zhang, Z. Yang, Y. He, Z. Zhang, Z. Qian, G. Hong,
Y. Zhang, and M. Yang, “Invetter: Locating insecure input vali-
dations in android services,” in 2018 ACM SIGSAC Conference
on Computer and Communications Security.
[9] D. J. Tian, G. Hernandez, J. I. Choi, V. Frost, C. Raules,
P. Traynor, H. Vijayakumar et al., “Attention spanned: Com-
prehensive vulnerability analysis of AT commands within the
android ecosystem,” in 27th USENIX Security Symposium,
2018.
[10] S. A. Gorski III and W. Enck, “Arf: identifying re-delegation
vulnerabilities in android system services,” in 12th Conference
on Security and Privacy in Wireless and Mobile Networks,
2019.
[11] M. Elsabagh, R. Johnson, A. Stavrou, C. Zuo, Q. Zhao,
and Z. Lin, “FirmScope: Automatic uncovering of privilege-
escalation vulnerabilities in pre-installed apps in Android
ﬁrmware,” in 29th USENIX Security Symposium, 2020.
[12] Y. Fratantonio, C. Qian, S. P. Chung, and W. Lee, “Cloak and
dagger: from two permissions to complete control of the ui
feedback loop,” in 2017 IEEE Symposium on Security and
Privacy (S&P).
[13] N. Redini, A. Machiry, D. Das, Y. Fratantonio, A. Bianchi,
E. Gustafson, Y. Shoshitaishvili, C. Kruegel, and G. Vigna,
“Bootstomp: on the security of bootloaders in mobile devices,”
in 26th USENIX Security Symposium, 2017.
[14] X. Zhou, Y. Lee, N. Zhang, M. Naveed, and X. Wang, “The
peril of fragmentation: Security hazards in Android device
driver customizations,” in 2014 IEEE Symposium on Security
and Privacy (S&P).
[15] H. Zhang, D. She, and Z. Qian, “Android ion hazard: The
curse of customizable memory management system,” in 2016
ACM SIGSAC Conference on Computer and Communications
Security (CCS).
[16] G. Hernandez, D. J. Tian, A. S. Yadav, B. J. Williams, and K. R.
Butler, “BigMAC: Fine-grained policy analysis of Android
ﬁrmware,” in 29th USENIX Security Symposium, 2020.
[17] “Android Init Language,” https://android.googlesource.com/
platform/system/core/+/master/init/README.md.
[18] F. B. Cohen and D. F. Cohen, A short course on computer
viruses.
John Wiley & Sons, Inc., 1994.
[19] “bash(1) — Linux manual page,” https://man7.org/linux/man-
pages/man1/bash.1.html.
[20] J. Six, Application Security for the Android Platform: Pro-
" O’Reilly Media,
cesses, Permissions, and Other Safeguards.
Inc.", 2011.
[23] “Cve-2020-26964,” https://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2020-26964.
[24] Y. Shao, J. Ott, Y. J. Jia, Z. Qian, and Z. M. Mao, “The misuse
of android unix domain sockets and security implications,” in
2016 ACM SIGSAC Conference on Computer and Communi-
cations Security (CCS).
[25] “Ransomware uses DDoS attacks to force victims to pay,”
https://www.bleepingcomputer.com/news/security/another-
ransomware-now-uses-ddos-attacks-to-force-victims-to-
pay/.
[26] “Binary Ninja,” https://binary.ninja/.
[27] “Kryptowire,” https://kryptowire.com/.
[28] A. Younis, Y. K. Malaiya, and I. Ray, “Assessing vulnerability
exploitability risk using software properties,” Software Quality
Journal, vol. 24, no. 1, 2016.
[29] Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino,
A. Dutcher, J. Grosen, S. Feng, C. Hauser, C. Kruegel et al.,
“Sok:(state of) the art of war: Offensive techniques in binary
analysis,” in 2016 IEEE Symposium on Security and Privacy
(S&P).
[30] “Component
permission
protection
level,”
https:
//developer.android.com/guide/topics/manifest/permission-
element#plevel.
[31] T. Eisenbarth, R. Koschke, and G. Vogel, “Static trace extrac-
tion,” in Ninth Working Conference on Reverse Engineering.
IEEE, 2002.
[32] A. A. Clements, E. Gustafson, T. Scharnowski, P. Grosen,
D. Fritz, C. Kruegel, G. Vigna, S. Bagchi, and M. Payer, “Halu-
cinator: Firmware re-hosting through abstraction layer emula-
tion,” in 29th USENIX Security Symposium, 2020.
[33] X. Meng and B. P. Miller, “Binary code is not easy,” in 25th
International Symposium on Software Testing and Analysis,
2016.
[34] D. Landman, A. Serebrenik, and J. J. Vinju, “Challenges for
static analysis of java reﬂection-literature review and empirical
study,” in 2017 IEEE/ACM 39th International Conference on
Software Engineering (ICSE).
[35] C. Wright, W. A. Moeglein, S. Bagchi, M. Kulkarni, and A. A.
Clements, “Challenges in ﬁrmware re-hosting, emulation, and
analysis,” ACM Computing Surveys (CSUR), vol. 54, no. 1,
2021.
[36] C. Yang, Z. Xu, G. Gu, V. Yegneswaran, and P. Porras, “Droid-
miner: Automated mining and characterization of ﬁne-grained
malicious behaviors in Android applications,” in European
Symposium on Research in Computer Security.
Springer,
2014, pp. 163–182.
[37] E. Raff, R. Zak, G. Lopez Munoz, W. Fleming, H. S. Anderson,
B. Filar et al., “Automatic yara rule generation using biclus-
tering,” in 13th ACM Workshop on Artiﬁcial Intelligence and
Security, 2020.
[21] “Cve-2018-6597,” https://cve.mitre.org/cgi-bin/cvename.cgi?
[38] “Vendor Init | Android Open Source Project,” https://source.
name=CVE-2018-6597.
android.com/security/selinux/vendor-init.
USENIX Association
30th USENIX Security Symposium    3699
[39] “Android Compatibility Deﬁnition Document,” https://source.
android.com/compatibility/cdd.
[40] J. Gamba, M. Rashed, A. Razaghpanah, J. Tapiador, and
N. Vallina-Rodriguez, “An analysis of pre-installed android
software,” in 2020 IEEE Symposium on Security and Privacy