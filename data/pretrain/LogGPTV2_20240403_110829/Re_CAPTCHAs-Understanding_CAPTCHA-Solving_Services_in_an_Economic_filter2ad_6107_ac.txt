will be used to circumvent the sites they are associated
with. To sidestep this concern, we chose not to solve
these CAPTCHAs ourselves. Instead, for each CAPTCHA
one of our worker agents was asked to solve, we proxied
the image back into the same service via the associated
retail interface. Since each CAPTCHA is then solved by
the same set of solvers who would have solved it any-
way, we argue that our activities do not impact the gross
outcome. This approach does cause slightly more money
to be injected into the system, but this amount is small.
Finally, we consulted with our human subjects liaison
on this work and we were told that the study did not re-
quire approval.
5 Solver Service Quality
In this section we present our analysis of CAPTCHA-
solving services based on actively engaging with a range
of services as a client. We evaluate the customer inter-
face, solution accuracy, response time, availability, and
capacity of the eight retail CAPTCHA-solving services
listed in Table 1.
We chose these services through a combination of Web
searching and reading Web forums focused on “black-
hat” search-engine optimization (SEO). In October of
2009, we selected the eight listed in Table 1 because
they were well-advertised and reﬂected a spectrum of
price offerings at the time. Over the course of our study,
two of the services (CaptchaGateway and CaptchaBy-
pass) ceased operation—we suspect because of compe-
tition from lower-priced vendors.
5.1 Customer Account Creation
For most of these services, account registration is accom-
plished via a combination of the Web and e-mail: con-
tact information is provided via a Web site and subse-
quent sign-up interactions are conducted largely via e-
mail. However, most services presented some obstacles
7
Service
Antigate (AG)
BeatCaptchas (BC)
BypassCaptcha (BY)
CaptchaBot (CB)
CaptchaBypass (CP)
CaptchaGateway (CG)
DeCaptcher (DC)
ImageToText (IT)
$/1K Bulk
$1.00
$6.00
$6.50
$1.00
$5.00
$6.60
$2.00
$20.00
Dates (2009–2010)
Oct 06 – Feb 01 (118 days)
Sep 21 – Feb 01 (133 days)
Sep 23 – Feb 01 (131 days)
Oct 06 – Feb 01 (118 days)
Sep 23 – Dec 23 (91 days)
Oct 21 – Nov 03 (13 days)
Sep 21 – Feb 01 (133 days)
Oct 06 – Feb 01 (118 days)
Requests
28,210
28,303
28,117
28,187
17,739
1,803
28,284
14,321
Responses
27,726 (98.28%)
25,708 (90.83%)
27,729 (98.62%)
22,677 (80.45%)
15,869 (89.46%)
1,715 (95.12%)
24,411 (86.31%)
13,246 (92.49%)
Table 1: Summary of the customer workload to the CAPTCHA-solving services.
to account creation, reﬂecting varying degrees of due
diligence.
For example, both CaptchaBot and Antigate required
third-party “invitation codes” to join their services,
which we acquired from the previously mentioned fo-
rums. Interestingly, Antigate guards against Western
users by requiring site visitors to enter the name of
the Russian prime minister in Cyrillic before grant-
ing access—an innovation we refer to as a “culturally-
restricted CAPTCHA”.7 Some services require a live
phone call for account creation, for which we used an
anonymous mobile phone to avoid any potential biases
arising from using a University phone number. In our ex-
perience, however, the burden of proof demanded is quite
low and our precautions were likely unnecessary. For ex-
ample, setting up an ImageToText account required a val-
idation call, but the only question asked was “Did you
open an account on ImageToText?” Upon answering in
the afﬁrmative (in a voice clearly conﬂicting with the
gender of the account holder’s name), our account was
promptly enabled. For one service, DeCaptcher, we cre-
ated multiple accounts to evaluate whether per-customer
rate limiting is in use (we found it was not).
Finally, each service typically requires prepayment by
customers, in units deﬁned by their price schedule (1,000
CAPTCHAs is the smallest “package” generally offered).
To fund each account, we used prepaid VISA gift cards
issued by a national bank unafﬁliated with our university.
5.2 Customer Interface
Most services provide an API package for uploading
CAPTCHAs and receiving results, often in multiple pro-
gramming languages; we generally used the PHP-based
APIs. BeatCaptchas and BypassCaptcha did not offer
7In principle, such an approach could be used to artiﬁcially restrict
labor markets to speciﬁc cultures (i.e., CAPTCHA labor protectionism).
However it is an open problem if such a general form of culturally-
restricted CAPTCHA can be devised that has both a large number of
examples and a low false reject rate from its target population.
8
pre-built API packages, so we implemented our own API
in Ruby to interface with their Web sites. The client APIs
generally employ one of two methods when interacting
with their corresponding services. In the ﬁrst, the API
client performs a single HTTP POST that uploads the im-
age to the service, waits for the CAPTCHA to be solved,
and receives the answer in the HTTP response; Beat-
Captchas, BypassCaptcha, CaptchaBypass and Captch-
aBot utilize this method.
In the second, the client performs one HTTP POST to
upload the image, receives an image ID in the response,
and subsequently polls the site for the CAPTCHA solu-
tion using the image ID; Antigate, CaptchaGateway, and
ImageToText employ this approach. These APIs recom-
mend poll rates between 1–5 seconds; we polled these
services once per second. DeCaptcher uses a custom pro-
tocol that is not based on HTTP, although they also offer
an HTTP interface. One interesting note about ImageTo-
Text is that customers must verify that their API code
works in a test environment before gaining access to the
actual service. The test environment allows users to see
the CAPTCHAs they submit and solve them manually.
5.3 Service Pricing
Several of
the services, notably Antigate and De-
Captcher, offer bidding systems whereby a customer can
offer payment over the market rate in exchange for higher
priority access to solvers when load is high. In our ex-
perience, DeCaptcher charges customers their full bid
price, while Antigate typically charges at a lower rate de-
pending on load (as might happen in a second-price auc-
tion). To effectively use Antigate, we set our bid price to
$2/1,000 solutions since we experienced a large volume
of load shedding error codes at the minimum bid price
of $1/1,000 (Section 5.9 reports on our experiences with
service load in more detail). We have not seen price ﬂuc-
tuations on the worker side of these services, and thus
we believe that this overage represents pure proﬁt to the
service provider.
5.4 Test Corpus
We evaluated the eight CAPTCHA-solving services in Ta-
ble 1 as a customer over the course of about ﬁve months
using a representative sample of CAPTCHAs employed
by popular Web sites. To collect this CAPTCHA work-
load, we assembled a list of 25 popular Web sites with
unique CAPTCHAs based on the Alexa rank of the site
and our informal assessment of its value as a target (see
Figure 5 for the complete list). We also used CAPTCHAs
from reCaptcha, a popular CAPTCHA provider used by
many sites. We then collected about 7,500 instances of
each CAPTCHA directly from each site. For the capacity
measurement experiments (Section 5.8), we used 12,000
instances of the Yahoo CAPTCHA graciously provided to
us by Yahoo.
5.5 Verifying Solutions
To assess the accuracy of each service, we needed to de-
termine the correct solution for each CAPTCHA in our
corpus. We used the services themselves to do this for
us. For each instance, we used the most frequent solution
returned by the solver services, after normalizing cap-
italization and whitespace. If there was more than one
most frequent solution, we treated all answers as incor-
rect (taking this to mean that the CAPTCHA had no cor-
rect solution). Table 1 shows the overall accuracy of each
service as given by our method.
To validate this heuristic, we randomly selected 1,025
CAPTCHAs having at least one service-provided solution
and manually examined the images. Of these, we were
able to solve 1,009, of which 940 had a unique plural-
ity that agreed with our solution, giving an error rate
for the heuristic of just over 8%. Of the 16 CAPTCHAs
(1.6%) we could not solve, seven were entirely unread-
able, six had ambiguous characters (e.g., ‘0’ vs. ‘o’, ‘6’
vs. ‘b’), and three were rendered ambiguous due to over-
lapping characters. (We note that Bursztein et al. [3] re-
moved CAPTCHAs with no majority from their calcula-
tion, which resulted in a higher estimated accuracy than
we found in our study.)
5.6 Quality of Service
To assess the accuracy, response time, and service avail-
ability of the eight CAPTCHA solving services, we con-
tinuously submitted CAPTCHAs from our corpus to each
service over the course of the study. We submitted a
single CAPTCHA every ﬁve minutes to all services si-
multaneously, recording the time when we submitted the
CAPTCHA and the time when we received the response.
Recall that ImageToText, Antigate and CaptchaGateway
require customers to poll the service for the response to
Figure 4: Median error rate and response time (in seconds) for
all services. Services are ranked top-to-bottom in order of in-
creasing error rate.
Figure 6: Median error rate and response time (in seconds) for
all CAPTCHAs. CAPTCHAs are ranked top-to-bottom in order of
increasing error rate.
a submitted CAPTCHA; we paused one second between
each poll call.
Table 1 also summarizes the dates, durations, and
number of CAPTCHA requests we submitted to the ser-
vices; Figure 5 presents the error rate and mean response
time at a glance for each combination of solver service
and CAPTCHA type. We used each service for up to 118
days, submitting up to 28,303 requests per service during
that period. We were not able to submit the same num-
ber of CAPTCHAs to all services for a number of rea-
sons. For example, services would go ofﬂine temporar-
ily, or we would rewrite parts of our client implementa-
tion, thus requiring us to temporarily remove the service
from the experiment. Furthermore, CaptchaGateway and
CaptchaBypass ceased operation during our study.
9
BypassCaptchaCaptchaBypassCaptchaBotAntigateCaptchaGatewayImageToTextDecaptcherBeatCaptchas20%15%10%5%0%19.9%13.4%13.3%12.4%11.9%11.3%10.3%10.3%Median Error Rate0510152014.115.912.89.621.39.417.117.3Median Response Time (seconds)YoukuSlashdotTaobaoreCaptchaBeboWikipediaAOLYandexGoogleConduitDailymotionMSNQQYahooMaktoobMySpaceSinadiggFC2BaiduFriendstereBayVKontakteSkyrockRediffPayPal20%15%10%5%0%57.4%30.9%29.5%27.9%25.2%23.6%20.5%15.3%14.0%13.4%13.4%12.8%11.8%11.6%11.5%10.9%10.3%10.1%10.1%9.5%9.3%8.5%7.6%6.9%5.0%4.9%Median Error Rate0510152017.115.714.817.315.017.316.015.415.713.814.516.012.915.213.815.915.014.015.112.915.114.813.916.314.813.9Median Response Time (seconds)Figure 5: Error rate and median response time for each combination of service and CAPTCHA type. The area of each circle upper
table is proportional to the error rate (among solved CAPTCHAs). In the lower table, circle area is proportional to the response time
minus ten seconds (for increased contrast); negative values are denoted by unshaded circles. Numeric values corresponding to the
values in the leftmost and rightmost columns are shown on the side. Thus, the error rate of BypassCaptcha on Youku CAPTCHAs is
66%, and for BeatCaptchas on PayPal 4%. The median response time of CaptchaGateway on Youku is 21 seconds, and 8 seconds
for Antigate on PayPal.
Accuracy
A CAPTCHA solution is only useful if it is correct. The
left bar plot in Figure 4 shows the median error rate for
each service. Overall the services are reasonably accu-
rate: with the exception of BypassCaptcha, 86–89% of
responses 8 were correct. This level of accuracy is in line
with results reported by Bursztein et al. [3] for human
solvers and substantially better than the accuracy of re-
CaptchaOCR (Section 3).
By design, CAPTCHAs vary in difﬁculty. Do the ob-
served error rates reﬂect such differences? The top half
of Figure 5 shows service accuracy (in terms of its er-
ror rate) on each CAPTCHA type. The area of each circle
is proportional to a service’s mean error rate on a par-
ticular CAPTCHA type. Services are arranged along the
y-axis in order of increasing accuracy, with the most ac-
curate (lowest error rate) at the top and the least accurate
(highest error rate) at the bottom. CAPTCHA types are ar-
ranged in decreasing order of their median error rate. The
median error rate of each type is also shown in Figure 6.
Accuracy clearly depends on the type of CAPTCHA.
The error rate for ImageToText with Youku, for instance,
is 5 times its PayPal error rate. Furthermore, the ranking
of CAPTCHA accuracies are generally consistent across
8The error rate is over received responses and does not include re-
jected requests. We consider response rate to be a measure of availabil-
ity rather than accuracy.
the services—all services have relatively poor accuracy
on Youku and good accuracy on PayPal.
Based on the data, one might conclude that a group
of CAPTCHAs on the left headed by Youku, reCaptcha,
Slashdot, and Taobao are “harder” than the rest. How-
ever an important factor affecting solution accuracy (as
well as response time) in our measurements is worker fa-
miliarity with a CAPTCHA type. In the case of Youku, for
instance, workers may simply be unfamiliar with these
CAPTCHAs. On the other hand, workers are likely famil-
iar with reCaptcha CAPTCHAs (see Section 6.6), which
may genuinely be “harder” than the rest. As a point of
comparison, MR. E reported in our interview that his ser-
vice experiences a 5–10% error rate. Since his CAPTCHA
mix is likely different, and less diverse, than our full set,
his claim seems reasonable.
Response Time
In addition to accuracy, customers want services that
solve CAPTCHAs quickly. Figure 7 shows the cumulative
distribution of response times of each service. The curves
of CaptchaBot, CaptchaBypass, ImageToText, and Anti-
gate exhibit the quantization effect of polling—either in
the client API or on the server—as a stair-step pattern.
The shape of the distributions is characteristically log-
normal, with a median response of 14 seconds (across
all services) and a third-quartile response time of 20
seconds—well within the session timeout of most Web
10
Error RateMedian Response TimeYoukuSlashdotTaobaoreCaptchaBeboWikipediaAOLYandexGoogleconduitDailymotionMSNQQYahooMaktoobMySpaceSinadiggFC2BaiduFriendstereBayVkontakteSkyrockRediffPayPalllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllAntigateImageToTextCaptchaBotBypassCaptchaBeatCaptchasDecaptcherCaptchaBypassCaptchaGateway121216151919192189131417161417llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllBypassCaptchaCaptchaBypassCaptchaBotAntigateCaptchaGatewayImageToTextDecaptcherBeatCaptchas6660595944525654123557554sites. For convenience, Figure 4 also shows median re-
sponse times for each service. In contrast to Bursztein et
al. [3], who used a different labor pool (Amazon Me-
chanical Turk), we found no signiﬁcant difference in re-
sponse times of correct and incorrect responses.
Services differ considerably in the relative response
times they provide to their customers. Antigate (for
which we paid a slight premium for priority service as
described in Section 5.3) and ImageToText provided the
fastest service with median response times of 9.6 seconds
and 9.4 seconds, respectively, with 90% of CAPTCHAs
solved under 25 seconds. CaptchaGateway was the slow-
est service we measured, with a median of 21.3 seconds
and 10% of responses taking over a minute; it was also
one of the two services that ceased operation during our