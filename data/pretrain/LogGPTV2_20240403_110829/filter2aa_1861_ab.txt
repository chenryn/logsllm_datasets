### Satan is on my Friends List

- **Source**: [BlackHat Presentation](http://www.blackhat.com/presentations/bh-jp-08/bh-jp-08-Moyer-Hamiel/BlackHat-Japan-08-Moyer-Hamiel-Satan-Friends-List.pdf)

**Slide 38: Virtual Plots, Real Revolution (Temmingh and Geers - 2009)**

In their 2009 paper, Temmingh and Geers explored the potential for disinformation in political campaigns. They posited that in the week before an election, if both left and right-wing blogs were seeded with false but credible information about a candidate, it could tip the balance in a close race.

- **Source**: R. Temmingh, [Virtual Battlefield](http://www.ccdcoe.org/publications/virtualbattlefield/21_TEMMINGH_Virtual%20Revolution%20v2.pdf)

**Slide 39: A Year Later...**

By 2010, these theoretical scenarios began to materialize. In the special election in Massachusetts to fill the Senate seat formerly held by Ted Kennedy, an anonymous source launched a "Twitter bomb" four days before the election. This smear campaign against Democratic candidate Martha Coakley quickly spread through Twitter, reaching tens of thousands of people within 138 minutes.

- **Source**: [Science News](http://www.sciencenews.org/view/feature/id/345532/description/Social_Media_Sway)

**Some Notes:**
- A single individual's decision to vote can have a significant impact due to the competing effects between the decay of influence and the growth in the number of acquaintances.
- As people tend to associate with like-minded individuals, the cascading effect of such decisions is not zero-sum.

**Truthy: Mapping the Spread of Astroturf in Microblog Streams**

- **Source**: [Indiana University Project](http://truthy.indiana.edu/site_media/pdfs/ratkiewicz_icwsm2011_truthy.pdf)
- **Description**: Truthy is a Twitter-based research tool designed to detect and track political abuse, including astroturfing, where political campaigns are disguised as spontaneous grassroots behavior.

**Slide 40: The Result of the Election**

Scott Brown won the 2010 Massachusetts special election, highlighting the real-world impact of such campaigns.

**Slide 41: Naming the Campaign**

**Slide 42: Swift-boating**

- **Definition**: "Swiftboating" is a term used pejoratively to describe unfair or untrue political attacks. It originated from the "Swift Boat Veterans for Truth" campaign against John Kerry in the 2004 U.S. Presidential election.
- **Source**: [Wikipedia](https://en.wikipedia.org/wiki/Swift_boating)

**Slide 43: Russian Presidential Elections 2012**

Allegedly, a pro-Kremlin organization paid hundreds of thousands of dollars to a network of internet users to create flattering coverage of Vladimir Putin prior to the 2012 Russian Presidential elections.

- **Sources**:
  - [The Guardian](http://www.guardian.co.uk/world/2012/feb/07/hacked-emails-nashi-putin-bloggers)
  - [The Economist](http://www.economist.com/blogs/easternapproaches/2012/02/hackers-and-kremlin)
  - [The Moscow Times](http://www.themoscowtimes.com/news/article/campaign-mudslinging-taken-to-new-lows/452583.html)

**Slide 44: Astroturfing vs. Smear Campaigns**

Astroturfing refers to political, advertising, or public relations campaigns designed to mask the sponsors of the message, giving the appearance of grassroots support. Unlike swift-boating, which is typically a smear campaign, astroturfing aims to create a false sense of public support.

- **Source**: [Temmingh & Geers, 2009]

**Slide 45: The Truthy Project**

- **Description**: The Truthy system evaluates thousands of tweets per hour to identify new and emerging bursts of activity around various memes. It also detects political smears, astroturfing, misinformation, and other social pollution.
- **Source**: [WSJ Video](http://live.wsj.com/video/the-truthy-project-ferrets-out-online-deception/219A2EA6-4D22-4F5B-8D96-81AF342104F7.html#!219A2EA6-4D22-4F5B-8D96-81AF342104F7)

**Slide 46: Fake Personas and SockPuppets**

In 2011, it was revealed that the U.S. government was exploring the use of fake personas. The HBGary email leak exposed discussions about such uses, including the creation of sockpuppets—online identities used for deception.

- **Source**: [Daily Kos](http://www.dailykos.com/story/2011/02/16/945768/-UPDATED-The-HB-Gary-Email-That-Should-Concern-Us-All#)

**Slide 47: Virtual Armies**

Temmingh and Geers' 2009 paper foresaw the potential for hackers to control virtual armies of artificial identities to support various agendas, including personal, business, political, military, or terrorist objectives.

- **Source**: [CCDCOE Publication](http://www.ccdcoe.org/publications/virtualbattlefield/21_TEMMINGH_Virtual%20Revolution%20v2.pdf)

**Slide 48: Fake Customer Service Accounts**

In December 2012, a fake customer service account (@MyEECare) emerged, mimicking the real EE telecoms provider. This incident highlighted the risk of harvesting user data through deceptive means.

- **Source**: [Troy Hunt Blog](http://www.troyhunt.com/2012/12/ee-k-dming-your-password-is-never-good.html)

**Slide 49: Misdirecting Emergency Resources**

After a BlackHat presentation in July 2013, concerns were raised about the potential for social bots to misdirect emergency resources. Professor Rob Proctor's research at the University of Manchester showed how rumors can spread quickly on Twitter, often outpacing the truth.

- **Source**: [JISC News](http://www.jisc.ac.uk/news/social-media-not-to-blame-for-inciting-rioters-08-dec-2011)

**Slide 50: Pacific Social**

Tim Hwang, following the Web Ecology project, created Pacific Social to further explore social networks and their potential for both positive and negative impacts.

- **Website**: [Pacific Social](http://pacsocial.com/)
- **Twitter**: [@pacsocial](https://twitter.com/pacsocial)

**Slide 51: Social Bots and Graph Distortion**

Tim Hwang's interest in social bots led to the examination of how they distorted the original graph of 500 users in the 2011 Social Bots competition.

**Slide 52: Social Bridge Building**

Pacific Social is exploring the use of social bots to connect separate online communities and maintain communication.

**Slide 53: Emotional Contagion and Happiness Buffering**

Inspired by Nicholas Christakis's work on social networks, Tim Hwang introduced the concept of "Happiness Buffering." This involves monitoring a group and injecting happier content when the sentiment dips below a certain level.

- **Source**: [MIT Press Journals](http://www.mitpressjournals.org/doi/abs/10.1162/artl_a_00034)
- **Video**: [Tim Hwang at HOPE 9](http://youtu.be/ZfQt6FWDi6c?t=26m44s)

**Slide 54-57: Implementing Happiness Buffering**

- **Step 1**: Monitor a group.
- **Step 2**: Detect when members' happiness (measured via sentiment analysis) dips below a certain level.
- **Step 3**: Inject happier tweets.
- **Step 4**: Restore a reasonable level of happiness in the social graph.

**Slide 58: Social Penetration Testing**

- **Steps**:
  1. Spread information with small inaccuracies.
  2. Observe where the inaccuracies are challenged and where they are not.
  3. Identify the most influential but least discerning individuals.
  4. Target them for further testing.

- **Source**: [Tim Hwang at HOPE 9](http://youtu.be/ZfQt6FWDi6c)

**Slide 59-60: Yazan Boshmaf and Socialbots**

Yazan Boshmaf from the University of British Columbia investigated social bots on Facebook, which led to the theft of 250GB of user data. His research emphasized the need to understand the factors influencing user decisions to befriend strangers, which is crucial for designing effective security controls.

- **Source**: [CNET News](http://news.cnet.com/8301-1009_3-20128808-83/socialbots-steal-250gb-of-user-data-in-facebook-invasion/)
- **Yazan’s Site**: [UBC Blogs](http://blogs.ubc.ca/boshmaf/)
- **USENIX Talk**: [Key Challenges in Defending Against Malicious Socialbots](https://www.usenix.org/conference/leet12/key-challenges-defending-against-malicious-socialbots)

**Slide 61: Understanding User Behavior**

- **Projects**:
  - Secure & Trustworthy Cyberspace (SaTC) program in the U.S.
  - Corporate Insider Threat Project at Oxford University
- **Key Areas**:
  - Scalability & compatibility
  - Policy-generated secure collaboration
  - Security metrics-driven education, design, development, and deployment
  - Resilient architectures
  - Understanding and accounting for human behavior

- **Sources**:
  - [SaTC Program](https://illinois.edu/blog/dialogFileSec/2434.pdf)
  - [Oxford CITD](http://www.cs.ox.ac.uk/projects/CITD/)

**Slide 62-63: Human Behavior and Bot Exploitation**

Bot creators are likely to target users who are more susceptible to engaging with strangers, making them attractive prospects for exploitation.

**Slide 64: Timing**

- **Duration**: ~18 minutes

**Slide 65: Image Source**

- **Source**: [Web Ecology Project](http://www.webecologyproject.org/2011/02/complete-source-code-from-socialbots-2011/)

**Slide 66: Participants**

- **Number**: 610 participants agreed to take part in a mystery experiment.

**Slide 67: Data Collection**

- **Data**: Twitter information, historic tweets for linguistic analyses, personality traits, and Klout scores.
- **Method**: Similar to the Dark Triad paper.
- **Source**: [Online Privacy Foundation](https://www.onlineprivacyfoundation.org/research_/PredictingdarkTriadPersonalityTraitsfromTwitter.pdf)

**Slide 68: Bot Assignment**

- **Groups**: Participants were divided into two groups, each assigned a bot (the same bot).

**Slide 69: Bot Model**

- **Model**: Based on the winning bot model from the Social Ecology Project, modified to mimic the tweeting style of old ladies with mildly humorous biographies.
- **Source**: [Winning Bot Code](http://www.webecologyproject.org/2011/02/complete-source-code-from-socialbots-2011/)