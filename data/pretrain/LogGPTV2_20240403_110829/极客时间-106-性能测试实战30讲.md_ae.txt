# 06丨倾囊相授：我毕生所学的性能分析思路都在这里了我还年轻的时候，经常听一些大会或者演讲。有些人说，思路逻辑非常重要。我那时就想，你肯定是瞎忽悠的，因为我怎么就没听懂你说的思路呢？而现在轮到自己来写或者讲一些东西的时候，才发现他们说得很对，而我之所以不理解，也是有原因的。性能分析思路和具体的实现之间，有一道鸿沟，那就是操作的能力。之前我为什么听不懂那些人的思路，其实是因为我没有操作的功底。而有了操作的功底之后，还有一个大的鸿沟要越过去，那就是从操作到对监控计数器的理解。这一步可以说让很多性能测试人员都望而却步了。但是这还不算完，这一步迈过去之后，还有一个跳跃，就是相关性分析和证据链分析的过程。如此一来，就会得到一张**性能测试分析的能力阶梯视图**，如下：![](Images/cbe9622abbffc356a3258e2d46a0c57a.png)savepage-src="https://static001.geekbang.org/resource/image/1d/f8/1dbe8969f74d0d314675cb8bc24965f8.jpg"}1.       工具操作：包括压力工具、监控工具、剖析工具、调试工具。        2.       数值理解：包括上面工具中所有输出的数据。        3.       **趋势分析、相关性分析、证据链分析**        ：就是理解了工具产生的数值之后，还要把它们的逻辑关系想明白。这才是性能测试分析中最重要的一环。        4.       最后才是调优：有了第 3    步之后，调优的方案策略就有很多种了，具体选择取决于调优成本和产生的效果。        那么怎么把这些内容都融会贯通呢？下面我们就来说说性能测试分析的几个重要环节。应该说，从我十几年的性能工作中，上面讲的这些内容是我觉得最有价值的内容了。在今天的文章中，我们将对它做一次系统的说明。我先把**性能分析思路**大纲列在这里：1.       瓶颈的精准判断；        2.       线程递增的策略；        3.       性能衰减的过程；        4.       响应时间的拆分；        5.       构建分析决策树；        6.       场景的比对。        瓶颈的精准判断TPS 曲线对性能瓶颈做出判断是性能分析的第一步，有了问题才能分析调优。之前有很多人在描述性能测试的过程中，说要找到性能测试中曲线上的"拐点"。我也有明确说过，大部分系统其实是没有明确的拐点的。举例来说，TPS 的视图如下：![](Images/c75690746e3bbf107ea33e408cdfe947.png)savepage-src="https://static001.geekbang.org/resource/image/67/4e/67613a7c330a115064167cac05d82d4e.png"}TPS 图 1显然，这是一个阶梯式增加的场景，非常好。但是拐点在哪呢？有人说，显然在1200TPS 左右的时候。也有人说了，显然是到 1500TPS才是拐点呀。但是也有人说，这都已经能到 2000TPS 了，显然 2000TPS是拐点。 我们再来看一下这张图对应的响应时间视图：![](Images/492dbed384c94ee926fb9fc10957ad7e.png)savepage-src="https://static001.geekbang.org/resource/image/67/51/67b8573993a39a68e923e78e19442151.png"}响应时间图 1是不是有人要说响应时间为 4.5ms时是拐点了？其实这些对拐点的判断，都是不合理的。如果我们对 TPS的增加控制得更为精准的话，那么这个 TPS的增加是有一个有清晰的弧度，而不是有一个非常清晰的拐点。但是至少我们可以有一个非常明确的判断，那就是瓶颈在第二个压力阶梯上已经出现了。因为响应时间增加了，TPS增加得却没有那么多，到第三个阶梯时，显然增加的 TPS更少了，响应时间也在不断地增加，所以，性能瓶颈在加剧，越往后就越明显。那么我们的判断就是：1.       有瓶颈！        2.       瓶颈和压力有关。        3.       压力呈阶梯，并且增长幅度在衰减。        如果你觉得上面的瓶颈还算清晰的话，那么我们再来看一张图：![](Images/5d6959373b2fab19cb8ddbf0404354c6.png)savepage-src="https://static001.geekbang.org/resource/image/16/58/16e821606d14d3a0061244c1740a3b58.png"}TPS 图 2在这个 TPS的曲线中，你还能判断出拐点在哪吗？显然是判断不出来拐点的，但是我们根据图得出以下几个结论：1.       有瓶颈！        2.       瓶颈和压力有关。        3.       压力也是阶梯的，但是并没有明确的拐点。        我们再来看一个 TPS 图：![](Images/cf52a96cb78cc332151add34568f9441.png)savepage-src="https://static001.geekbang.org/resource/image/3c/fb/3cc3ee474966a49f845fcfc52cb337fb.png"}TPS 图 3看到这张图，是不是明显感觉系统有瓶颈呢？那么瓶颈是不是和压力大小有关呢？这种比较有规律的问题，显然不是压力大小的原因。为什么呢？因为 TPS周期性地出现降低，并且最大的 TPS也都恢复到了差不多的水位上。所以，即使是压力降低，也最多降低最大的 TPS水位，会让问题出现得更晚一点，但是不会不出现。综合以上，如果画一个示意图的话，TPS的衰减过程大概会如下所示：![](Images/ef3ee1efea04f1a81a77b90af3c86cad.png)savepage-src="https://static001.geekbang.org/resource/image/a8/b4/a8ea90b0516f081058bf78bc24ed94b4.png"}1.       随着用户数的增加，响应时间也在缓慢增加。        2.       TPS    前期一直都有增加，但是增加的幅度在变缓，直到变平。        在这样的趋势图中，我们是看不到明确的拐点的。但是我们能做的清晰的判断就是：有瓶颈！所以对 TPS曲线来说，它可以明确告诉我们的就是：1.       有没有瓶颈：其实准确说所有的系统都有性能瓶颈，只看我们在哪个量级在做性能测试了。        2.       瓶颈和压力有没有关系：TPS    随着压力的变化而变化，那就是有关系。不管压力增不增加，TPS    都会出现曲线趋势问题，那就是无关。        这时你可能会问，为什么不看响应时间就武断地下此结论呢？其实响应时间是用来判断业务有多快的，而TPS 才是用来判断容量有多大的。响应时间的曲线我们还是来看看响应时间，下面看一张响应时间图：![](Images/40d6eb80d8283d95b5a25d1717086336.png)savepage-src="https://static001.geekbang.org/resource/image/06/a7/061e77ee8dc20c9c1cd1ae1f6a27d7a7.png"}它对应的线程图是：![](Images/2415509ccba0311f96de4764ffaf0f71.png)savepage-src="https://static001.geekbang.org/resource/image/32/8d/32ab933156f0ba11a1f08489bf62398d.png"}多明显的问题，随着线程的增多，响应时间也在增加，是吧。再来看它们对应的TPS 图： ![](Images/660869483db792983cbaf661830306e6.png)savepage-src="https://static001.geekbang.org/resource/image/c9/48/c9f48c144a3663b3779832f62e25e148.png"}到第 40 个线程时，TPS 基本上达到上限，为 2500左右。响应时间随着线程数的增加而增加了，系统的瓶颈显而易见地出现了。但是，如果只让你看 TPS曲线，你是不是也会有同样的判断？那就是：有瓶颈！并且和压力有关？所以说，其实TPS就可以告诉我们系统有没有瓶颈了，而响应时间是用来判断业务有多快的。后面我们还会提到响应时间会是性能分析调优的重要分析对象。线程递增的策略讲完响应时间之后，我们再来看下线程递增。在见识了很多性能测试人员做的场景之后，必须得承认，有些场景的问题太多了。首先，我们来看两个场景的执行对比。场景 1 的线程图：![](Images/be7259d24cc5773a70156b2ad8692305.png)savepage-src="https://static001.geekbang.org/resource/image/68/d7/68b4c0811e61657432a8b4ceb1c7dbd7.png"}场景 1 的 TPS 图：![](Images/2ee3b8a4aa7f82487c4893d4f202a5c6.png)savepage-src="https://static001.geekbang.org/resource/image/ac/b5/aca9cb229a4503b0ebba911c38cf0bb5.png"}场景 1 的响应时间图：![](Images/790415a7837a41c8b25e102394209e6c.png)savepage-src="https://static001.geekbang.org/resource/image/bd/af/bda2ca6d65527aa6f3a435573eaefeaf.png"}场景 2 的线程图：![](Images/91669b55c50db8672a5185d8a448a261.png)savepage-src="https://static001.geekbang.org/resource/image/b1/7a/b105147c5cfbdc66fa708daae0a1977a.png"}场景 2 的 TPS 图：![](Images/017440a805766ae3ba01082bcb55b67e.png)savepage-src="https://static001.geekbang.org/resource/image/8a/2a/8a849b11b9be9beffebf0c4579c4a12a.png"}场景 2 的响应时间图：![](Images/a5c0f5e185a6ac7000191c696d98002b.png)savepage-src="https://static001.geekbang.org/resource/image/a9/e4/a9e3d6318a1ef1d7fc28e9b45c4733e4.png"}这两个场景的比对如下：![](Images/a5c0f5e185a6ac7000191c696d98002b.png)savepage-src="https://static001.geekbang.org/resource/image/a9/e4/a9e3d6318a1ef1d7fc28e9b45c4733e4.png"}![](Images/6baaf01970bb10c3acd787dbe081faca.png)savepage-src="https://static001.geekbang.org/resource/image/dd/ef/dd574bd9ec73fa1625b456f1fadedaef.jpg"}有了这些对比数据之后，你是不是觉得哪里似乎是有问题的？对的！ TPS 都是达到400，但两个场景中线程递增的策略不同，产生的响应时间完全不同。虽然都没有报错，但是第一种场景是完全不符合真实的业务场景的。这是为什么呢？在场景的执行过程中，首先，响应时间应该是从低到高的，而在场景 1中不是这样。其次，线程应该是递增的，而场景 1并没有这样做（这里或许有人会想到秒杀的场景，认为场景 1符合秒杀的业务设定，这个问题我们稍后提及）。最后，在两个场景中，TPS的上限都达到了 400TPS。但是你可以看到，在场景 2 中，只要 40个线程即可达到，但场景 1 中居然用到了 500线程，显然压力过大，所以响应时间才那么长。其实在生产环境中，像场景 1这样的情形是不会出现的。如果它出现了，那就是你作为性能测试的责任，因为你没有给出生产环境中应该如何控制流量的参数配置说明。同时，我们从上面的场景对比可以看到，**对一个系统来说，如果仅在改变压力策略（其他的条件比如环境、数据、软硬件配置等都不变）的情况下，系统的最大TPS 上限是固定的**。场景 2使用了递增的策略，在每个阶梯递增的过程中，出现了抖动，这就明显是系统设置的不合理导致的。设置不合理，有两种可能性：1.资源的动态分配不合理，像后端线程池、内存、缓存等等；2.数据没有预热。我们再回到之前说的秒杀场景。说到秒杀场景，有人觉得用大线程并发是合理的，其实这属于认识上的错误。因为即使线程数增加得再多，对已经达到TPS上限的系统来说，除了会增加响应时间之外，并无其他作用。所以我们描述系统的容量是用系统当前能处理的业务量（你用TPS 也好，RPS 也好，HPS也好，它们都是用来描述服务端的处理能力的），而不是压力工具中的线程数。这一点，我在第5篇文章中已经做了详细的解析，你可以回去再看看。那么，对于场景中线程（有些工具中叫虚拟用户）递增的策略，我们要做到以下几点：1.       场景中的线程递增一定是连续的，并且在递增的过程中也是有梯度的。        2.       场景中的线程递增一定要和 TPS    的递增有比例关系，而不是突然达到最上限。后面在场景的篇幅中我们会再说它们之间的比例关系。        3.       上面两点针对的是常规的性能场景。对于秒杀类的场景，我们前期一定是做好了系统预热的工作的，在预热之后，线程突增产生的压力，也是在可处理范围的。这时，我们可以设计线程突增的场景来看系统瞬间的处理能力。如果不能模拟出秒杀的陡增，就是不合理的场景。        这里给出我做性能场景递增的经验值：![](Images/1dfe17af0a3a786200676cff224fe56e.png)savepage-src="https://static001.geekbang.org/resource/image/b4/fd/b4ea252a267281615b4e7d035600c0fd.jpg"}当然这里也不会是放在哪个系统中都适合的递增幅度，你还是要根据实际的测试过程来做相应的判断。有了这些判断之后，相信大家都能做出合理的场景来了。性能衰减的过程有了瓶颈的判断能力，也有了线程递增的意识，那么下面在场景执行中，我们就要有判断性能衰减的能力了吧。来，我们先看一个压力过程中产生的结果图。![](Images/b26ded67c95d8582ec79f4c15430aa63.png)savepage-src="https://static001.geekbang.org/resource/image/eb/ce/eb938af9e8bd5c4fcb170855102e23ce.png"}在递增的压力过程中，随着用户数的增加。我们可以做几次计算。第一次计算，在线程达到 24 时，TPS 为 1810.6，也就是每线程每秒发出75.44 个请求。第二次计算，在线程达到 72 时，TPS 为 4375.1，也就是每线程每秒发出60.77 个请求。第三次计算，在线程达到 137 时，TPS 为 5034，也就是每线程每秒发出36.74 个请求。通过这三次计算，我们是不是可以看到，每线程每秒发出的请求数在变少，但是整体TPS 是在增加的。我们有很多做性能测试的人，基本上，只看 TPS和响应时间的时候，在上面这个示例中，肯定会一直往上加用户。虽然响应时间在增加，但是增加得也不多嘛。但实际上，通过我们的计算可以知道，性能是在不断地衰减的。我们来看一张统计图：![](Images/8a1964f9b5c9709d6b43fee224c43434.png)savepage-src="https://static001.geekbang.org/resource/image/88/17/88f8facef19db7d6828fa64349483b17.png"}通过红线的大致比对可以知道，当每线程每秒的请求数降到 55左右的时候，TPS 就达到上限了，大概在 5000左右，再接着往上增加线程已经没有用了，响应时间开始往上增加了。这就是性能衰减的过程（题外话，在上图中，其实还有一个问题，就是在红线前面，性能在上升的过程中有几次抖动，这个抖动到后面变大了，也变频繁了，如果这是必然出现的抖动，那也是配置问题，希望你注意到这一点）。为什么要这么细致地描述性能衰减的过程呢？其实我就是想告诉你，**只要每线程每秒的 TPS开始变少，就意味着性能瓶颈已经出现了。但是瓶颈出现之后，并不是说服务器的处理能力（这里我们用TPS 来描述）会下降，应该说 TPS 仍然会上升，在性能不断衰减的过程中，TPS就会达到上限**。这也是前面我说的，性能瓶颈其实在最大 TPS之前早就已经出现了。那么我们是不是应该在性能衰减到最大 TPS时就停止场景呢？这个不一定的哦。因为停不停场景，取决于我们的场景目标，如果我们只是为了得到最大TPS，那确实可以停止场景了。但是，如果我们要扩大化性能瓶颈，也就是说为了让瓶颈更为明显，就完全不需要停止场景，只要不报错，就接着往上压，一直压到我们要说的下一个话题------响应时间变长，需要拆分。响应时间的拆分在性能分析中，响应时间的拆分通常是一个分析起点。因为在性能场景中，不管是什么原因，只要系统达到了瓶颈，再接着增加压力，肯定会导致响应时间的上升，直到超时为止。在判断了瓶颈之后，我们需要找到问题出现在什么地方。在压力工具上看到的响应时间，都是经过了后端的每一个系统的。那么，当响应时间变长，我们就要知道，它在哪个阶段时间变长了。我们看下这张图。![](Images/ef6276b6e3439ef33486857c61a16b8a.png)savepage-src="https://static001.geekbang.org/resource/image/8d/27/8d568429e396d31692b7672119a50427.jpg"}这应该是最简单的一个压力测试逻辑了。一个应用，一个 DB，结果也拆分出了8个时间段，这还是在我没有加上压力工具自己所消耗的时间的情况下。如果我们要分析压力工具中的响应时间，拆分的逻辑就是上面这个示意图。但是在真实的场景中，基本上不是这样的。如果是内网，那基本上都是连在一个交换机上，所以通常是这样的：![](Images/8c913dd25271e4be5b98c5d3be887c16.png)savepage-src="https://static001.geekbang.org/resource/image/94/71/94c161f0082262de076233415e5e1671.png"}在这样的拓扑中，我们仍然可以拆出来 t1 到 t8的时间。只是实际动手的时候，思路一定要清晰，时间拆分是从哪里到哪里，要画出来，不能混乱。我们有很多手段可以进行时间的拆分，当然要看我们的应用支持哪一种。如果我们是这样的架构，拆分时间应该是比较清楚的。![](Images/60b898c9868bef033284c7b8c1329476.png)savepage-src="https://static001.geekbang.org/resource/image/33/ea/33f181474342bb7865927198881fbfea.jpg"}首先我们需要查看 Nginx 上的时间。日志里就可以通过配置 [[[]{.strutstyle="height:0.85396em;vertical-align:-0.19444em;"}[r]{.mord.mathdefault style="margin-right:0.02778em;"}[e]{.mord.mathdefault}[q]{.mord .mathdefaultstyle="margin-right:0.03588em;"}[u]{.mord .mathdefault}[e]{.mord.mathdefault}[s]{.mord .mathdefault}[[t]{.mord.mathdefault}[[[]{.pstrut style="height:2.7em;"}[[t]{.mord.mathdefault .mtight}]{.sizing .reset-size6 .size3.mtight}]{style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"}]{.vliststyle="height:0.2805559999999999em;"}[​]{.vlist-s}]{.vlist-r}[[]{.vliststyle="height:0.15em;"}]{.vlist-r}]{.vlist-t.vlist-t2}]{.msupsub}]{.mord}[i]{.mord .mathdefault}[m]{.mord.mathdefault}[e]{.mord .mathdefault}]{.base}]{.katex-htmlaria-hidden="true"}]{.katexslate-string="true"}]}slate-type="inline-katex" slate-object="inline"upstream_response_time得到日志如下信息：    14.131.17.129 - - [09/Dec/2019:08:08:09 +0000] "GET / HTTP/1.1" 200 25317 0.028 0.028最后两列中，前面是请求时间的 28ms，后面是后端响应时间的28ms。 同时，我们再到 Tomcat上去看时间。    172.18.0.1 - - [09/Dec/2019:08:08:09 +0000] "GET / HTTP/1.1" 200 25317 28 27 http-nio-8080-exec-1请求时间消耗了 28ms，响应时间消耗了27ms。 接着再来看一下前端的时间消耗。![](Images/620d3448868d8002a3c41c847fb09922.png)savepage-src="https://static001.geekbang.org/resource/image/a6/04/a6821521f99df9f0a63df235b3395a04.png"}从这里可以看到，从发出请求到接收到第一个字节，即 TTFB 是55.01ms，内容下载用了 11.75ms。从这就可以看得出 Nginx基本上没消耗时间，因为它和 Tomcat上的请求响应时间非常接近。那么网络上的消耗时间怎么样呢？我看到有很多人用 TTFB来描述网络的时间。先来说明一下，TTFB中显然包括了后端一系列处理和网络传输的时间。如下图所示。![](Images/025c9b8586d67843b7dfe0b066757876.png)savepage-src="https://static001.geekbang.org/resource/image/78/9e/784de243714cceead81465b234f5bd9e.jpg"}下面的红色点是指要接收的内容。上面的红色线就是TTFB。 如果接收完了呢？就是这个状态。![](Images/8a46e1b481c67a1d30f571f74a931ad4.png)savepage-src="https://static001.geekbang.org/resource/image/6c/ad/6c662863313dab9ce466ea57391da9ad.jpg"}所以，我觉得用 TTFB 描述网络的健康状态并不合理。如果用 ContentDownload 来描述会更为合理。比如我们上面的这个例子中，那就是 11.75ms下载了 25317 Bytes 的内容。Tomcat 上基本上是消耗了处理的所有时间，当然这中间也包括了 MySQL花费的时间。而前端看到的其他时间就消耗在了网络中。在这个例子中，主要说明了响应时间怎么一步步拆。当然，如果你是下面这种情况的话，再一个个拆就比较辛苦了，需要换另一种方式。![](Images/4a47ba3ce9966948dcc8ee158ce8cf5f.png)savepage-src="https://static001.geekbang.org/resource/image/a6/da/a620653b0c0d7326c4fb1518bb2872da.jpg"}你肯定想知道每个系统消耗了多长时间，那么我们就需要链路监控工具来拆分时间了。比如像这样来拆分：![](Images/ef05cb00160bac86cdcf268407ee4b3c.png)savepage-src="https://static001.geekbang.org/resource/image/8f/36/8fb9d1d502be932c8a34b6e50344d336.png"}从 User开始，每个服务之间的调用时间，都需要看看时间消耗的监控。这就是时间拆分的一种方式。其实不管我们用什么样的工具来监控，最终我们想得到的无非是每个环节消耗了多长时间。用日志也好，用链路监控工具也好，甚至抓包都可以。当我们拆分到了某个环节之后，就有了下一步的动作：构建分析决策树。构建分析决策树关于分析决策树，我在很多场合也都有提及。分析决策树，对性能测试分析人员实在是太重要了，是性能分析中不可或缺的一环。**它是对架构的梳理，是对系统的梳理，是对问题的梳理，是对查找证据链过程的梳理，是对分析思路的梳理。它起的是纵观全局，高屋建瓴的指导作用**。性能做到了艺术的层级之后，分析决策树就是提炼出来的，可以触类旁通的方法论。而我要在这里跟你讲的，就是这样的方法论。应该说，所有的技术行业在面对自己的问题时，都需要有分析决策树。再广而推之的话，所有的问题都要有分析决策树来协助。通过上面的几个步骤，我们就会知道时间消耗在了哪个节点上。那么之后呢？又当如何？总要找到根本的原因才可以吧，我画了如下的分析决策图：![](Images/7357e1c054d08b9f4823837bc5eecbce.png)savepage-src="https://static001.geekbang.org/resource/image/aa/2b/aaa0c2e23aa5648a46d6a47b78c3c32b.jpg"}从压力工具中，只需要知道TPS、响应时间和错误率三条曲线，就可以明确判断瓶颈是否存在。再通过分段分层策略，结合监控平台、日志平台，或者其他的实时分析平台，知道架构中的哪个环节有问题，然后再根据更细化的架构图一一拆解下去。我在这里，以数据库分析和操作系统分析举一下例子。首先我们看一下数据库分析决策树。比如针对 RDBMS 中的MySQL，我们就可以画一个如下的决策树：![](Images/1e9a68d212622e8030aee91345b1868e.png)savepage-src="https://static001.geekbang.org/resource/image/5b/27/5b9c8e2f05ee467ffc834dad86dcb927.png"}由于这里面的内容实在过多，无法一次性展现在这里。我举几个具体的例子给你说明一下。MySQL中的索引统计信息有配置值，有状态值。我们要根据具体的结果来判断是否需要增加key_buffer_size值的大小。比如这种就无所谓了。        Buffer used     3.00k of   8.00M  %Used:   0.04从上面的数据可以看到，key buffer size 就用到了4%，显然不用增加。再比如，我们看到这样的数据：           __Tables_______________________        Open             2000 of 2000    %Cache: 100.00        Opened         15.99M     4.1/s这就明显有问题了。配置值为 2000 的 Open TableCache，已经被占满了。显然这里需要分析。但是，看到状态值达到配置值并不意味着我们需要赶紧加大配置值，而是要分析是否合理，再做相应的处理。比如说上面这个，Table确实打开得多，但是如果我们再对应看下这一条。        Slow 2 s        6.21M     1.6/s你是不是觉得应该先去处理慢 SQL的问题了？ 关于数据库的我们就不举更多的例子了。在这里只是为了告诉你，在分析决策树的创建过程中，有非常多的相互依赖关系。然后我们再来看一下操作系统分析决策树，我在这里需要强调一下，操作系统的分析决策树，不可以绕过。![](Images/e06dc1138f3a4edeac010531ab865b69.png)savepage-src="https://static001.geekbang.org/resource/image/79/1c/79420c5b099a09bc7b5120d98b968b1c.png"}如果你想到操作系统架构图就头大，那么这时候应该觉得有了希望。那就是我觉得操作系统上的问题判断是比较清晰的，所以基于此决策树，每个人都可以做到对操作系统中性能问题的证据链查找。但是！对嘛，总得有个但是。对操作系统的理解是个必然的前提。我看过很多人写的操作系统性能分析方面的书籍或资料，发现大部分人把描述计数器的数值当成性能分析。怎么理解这句话呢？比如说"CPU 使用率在 TPS 上升的过程中，从 10% 增加到 95%，超过了预期值。""内存使用率达到 99%，所以是瓶颈点。" "I/O 使用率达到 100%。"等等。 像这样的描述，在我的性能团队中，一定会被骂回去重写。我要这些描述有什么用？我要的是为什么达到了这样的值，原因在哪？怎么解决？就像分析决策树中所描述的那样，性能工程师要做的是一步步地细化分析，给出最终的原因。有人说，如果按这个路子，似乎操作系统的分析并不复杂嘛。大概三五个命令就可以跳到代码层了。是的，对于操作来说，确实不多，但是对于判断来说，那就复杂了。举个例子来说明一下：![](Images/7757650184a5cf85bacccde7d3dc1bf4.png)savepage-src="https://static001.geekbang.org/resource/image/62/23/62fe8e28939ba946aa409f643a826723.png"}看到这样的图，你是不是有种手足无措的感觉？中断能占 40%，sy CPU 也能占40%。这系统还用干业务的事吗？全干自己的事去了，可见操作系统有问题！你是不是要做这个判断了？而实际情况是，这个主机上只有一个网卡队列，而请求量又比较大。![](Images/23815baf004c9b03352b99583ae14fb0.png)savepage-src="https://static001.geekbang.org/resource/image/dc/16/dc87f5b31b707be5fa115bd4e5f1b416.png"}所以要解决的是网卡队列的问题，至于怎么解决，那手段就多了。可以换个服务器，可以多加几个队列，可以多接几个节点...以上只是给出几个性能分析过程中常见的决策树示例。在后续的分析过程实例中，我们将秉承着这种分析思路，一步步地走到瓶颈的面前。场景的比对为什么要写这一部分呢？因为我看到很多人对瓶颈的判断，并不那么精确，所以想写一下场景比对的建议。其实简单来说，就一句话：当你觉得系统中哪个环节不行的时候，又没能力分析它，你可以直接做该环节的增加。举例来，我们现在有一个如下的架构：![](Images/289536ca73772beb7a3f9d4767cb1d86.png)savepage-src="https://static001.geekbang.org/resource/image/b0/cf/b0fe41ba03784c3464f9d546af7ab2cf.png"}可以得到这样的结果：![](Images/98031731d91aab91cd8498c18848ec60.png)savepage-src="https://static001.geekbang.org/resource/image/78/db/78e2dcb7bba43e27cbe715d2434c4bdb.png"}从 TPS曲线中，我们可以明显看到系统是有瓶颈的，但是并不知道在哪里。鉴于系统架构如此简单，我们索性直接在某环节上加上一台服务器，变成这样：![](Images/c5c35ca02ea023cdf44e6a39fc59f7c7.png)savepage-src="https://static001.geekbang.org/resource/image/9c/21/9cd70c0d4c4c00029c755b2aa1549c21.png"}然后得到如下数据：![](Images/39d38fc691083042d296dd9576320749.png)savepage-src="https://static001.geekbang.org/resource/image/a2/77/a2dd11b1143c09578fbedf6574f3b277.png"}哟，没好使！怎么办？再接着加其他节点，我加了更多的 JMeter机器。 ![](Images/038cdab397dce3de69336845cfcb1d87.png)savepage-src="https://static001.geekbang.org/resource/image/11/d5/11ab4e8568aa68391ae3df1526078bd5.png"}再来看下结果：![](Images/b9671232b668af727de4a86b2af11715.png)savepage-src="https://static001.geekbang.org/resource/image/d5/7b/d59c58bd5a38efd9b397d5755330b27b.png"}真巧，TPS 增加了！看到了吧，这就是我说的场景比对。当我们不知道系统中哪个环节存在性能瓶颈时，对架构并不复杂的系统来说，可以使用这样的手段，来做替换法，以快速定位问题。总结在这一篇中，我说到了瓶颈的精准判断、线程递增的策略、性能衰减的过程、响应时间的拆分、构建分析决策树以及场景的比对，这几个环节，是性能分析过程中非常重要的环节。从我的经验上来说，这一篇文章可能是我工作十几年的精华所在了。而这里的每一个环节，又有非常多的细分，特别是构建分析决策树这一块，它需要太多的架构知识、系统知识、数据库知识等等。鉴于本文只是想起到一个提纲挈领的作用，所以无法展开描述，希望在后续的篇幅中，我们尽量细致拆解。思考题今天的内容虽然有点多，但总的来说，思路比较清晰，理解起来也比较容易。如果你认真学习了今天的内容，不妨思考两个问题，为什么线程递增过程不能断？构建分析决策树的关键是什么？欢迎你在评论区写下你的思考，我会和你一起交流，也欢迎把这篇文章分享给你的朋友或者同事，一起交流一下。
# 07丨性能测试工具：如何录制脚本？对于一个性能测试工具来说，如果能实现以下几大功能，那么就基本上就满足了性能测试工具的功能。1.       录制或编写脚本功能        2.       参数化功能        3.       关联功能        4.       场景功能        5.       报告生成功能        但是除此以外，在工作的细节上还有更多要求，就要看工具的实施能力了。有很多性能测试工程师希望工具能做得非常全面，又人性化，而纵观当前的性能工具，真正能够做到傻瓜式录制完脚本，自动设置好参数化、关联、场景，直接产出结果的工具是没有的。不管是云性能测试平台，还是分布式性能测试工具（当然性能测试工具几乎全部具有分布式能力），都需要性能测试人员来定义参数化数据、设置关联、配置场景。因此，在性能测试的过程中，对工具的配置就成为了性能测试工程师的基本能力。今天，我们就来看下在性能测试工具中，如何录制脚本。今天的文章有些特殊，可能是专栏中少有的，有详细操作的文章。性能工具的脚本能力性能测试工具的脚本编写能力分为两类，一个是录制，另一个是手工编写。现在市场上的性能测试工具虽然支持录制功能，但大部分也只是支持 HTTP协议。在我们熟知的工具中，也只有 LoadRunner支持更多协议的录制能力。不过幸好，现在我们所面对的应用大部分是 HTTP协议的应用。对手工编写脚本的部分，因为大部分都取决于业务场景，所以很难提出共性。如果有人提出针对性的场景，我们再做相应的示例就行。因此今天的文章将着重讲一下测试工具的录制功能。很多人以为性能工具录制功能非常简单，点几下就能生成一个脚本，但是录制完之后，针对脚本的增强完善就做得非常少了。事实上，针对脚本，我们不仅要录制下来，还要了解录制的原理和录制完之后的脚本增强。不然，在场景中还是会遇到各种各样的问题。性能工具中的录制功能录制功能从原理上来说，分成两种：1.       本地录制：通过截取并解析与服务器的交互协议包，生成脚本文件。比如说    LoadRunner 调起 IE 的时候，不用修改 IE 的代理设置，就可以直接抓取    HTTP    包，并通过自己的解析器解析成脚本。        2.       代理录制：通过代理服务器设置，转发客户端和服务器的交互协议包，生成脚本文件。JMeter    中的脚本录制功能就是这样做的。        这两者的不同点主要在于操作上。本地录制相对简单，但有些场景受限，比如说操作只能在某台服务器上，但是这台服务器又不允许安装工具；代理录制操作复杂一些，但可以满足更多的场景。通过这张图，我们可以简单看到代理录制的逻辑：![](Images/a1e7e3c8b2251a483cbb3f132d3e82d2.png)savepage-src="https://static001.geekbang.org/resource/image/2c/49/2c444b52c9b614bd7779394e6ed18849.jpg"}1.       我们在 IP 为 2.2.2.2 上的主机上，打开一个代理程序，开 81    端口，所有到 81 端口的都转发到 1.1.1.1 的 80    端口。    2.       当 3.3.3.3 主机要访问 1.1.1.1 的的 80 端口，可以通过访问 2.2.2.2    的 81 端口进行转发。        这里需要你注意的是，代理是用来转发数据包的，并不是重定向哦。不管是在本机用代理，还是远程用代理，这个逻辑都是不会变的。有了这个逻辑之后，你要明白的一点是，**客户机不一定要和代理服务器在同一台机器上**。为什么要强调这一点呢？因为有很多人用工具来录制时，都不知道这个逻辑，只知道工具是那么操作的。这也是很多人不能理解Port mapping 的原因。不同的工具录制方式略有不同。今天我们用常见的两个性能测试工具LoadRunner 和 JMeter做为示例工具。JMeter 的录制功能首先打开 JMeter，添加一个线程组，再添加一个 HTTP(S) Test ScriptRecorder。界面如下：![](Images/62f7b00cb08b529c222aaf2ac321f4fd.png)savepage-src="https://static001.geekbang.org/resource/image/df/f8/df8730ffbbfb0e68879a88e8699035f8.png"}这里有几个关键点说明一下：1.  Target    Controller：这里指定录制出的脚本要放到哪里去。如果你想把不同的脚本放到不同的线程组中去，在录制的时候就可以拆分开。        2.  Grouping：分组，这个分组功能很实用。但是如何分组就和具体的目标相关了，这一点下面我们再细说。        点击 start 按钮时，会提示创建一个根 CA 证书。这个证书生成在 bin目录中，文件名是：ApacheJMeterTemporaryRootCA.crt，七天有效期。这个证书将被用来客户端转发HTTPS 的请求。与此同时，还有另一个证书在同目录中生成，名字是proxyserver.jks，这是 JMeter自己生成的根证书。![](Images/1a4b943c1b66ac2c867943753c50253f.png)savepage-src="https://static001.geekbang.org/resource/image/be/19/be8ef3815ed27b60f11aae9679457219.png"}前面我们说到了，JMeter 是用代理的方式来录制的。如果服务端用了 SSL证书，在代理时也要加 SSL证书，那么代理录制的结构就会变成这样。![](Images/b4992390f80900fec94a72d06b270dde.png)savepage-src="https://static001.geekbang.org/resource/image/8f/c9/8f51e323947ca6b8109241f1c71e0ec9.jpg"}上面的 SSL证书就是用来处理上图中蓝色的这一部分。我们点击 ok之后，就会出现这个界面。在这个界面中，只有两个配置项。1.  Prefix：请求名的前缀。        2.  Create new transaction after    request(ms)：一个请求完成之后，如果下一个请求超出了这里设置的时间间隔，就创建一个新的事务。        ![](Images/eab5e060cf8db293542109a2884062c2.png)savepage-src="https://static001.geekbang.org/resource/image/bf/ff/bff35c026d490ec75425a0d6e41a36ff.png"}然后到主机上设置代理。注意，这里我要敲黑板了呀：这里的代理设置，是在需要访问的客户机上。这个客户机，不一定是压力机所在的机器。这里的localhost，也应该设置的是代理服务所在的主机IP。 ![](Images/39e3af8277f2fd36f314030e956cdf38.png)savepage-src="https://static001.geekbang.org/resource/image/74/49/74e3652701b526509b410790f0fa2549.png"}请注意，如果你要设置为录制HTTPS，还需要做如下两步。第一步是，浏览器代理要把 Secure Web Proxy(HTTPS)选择上，同时填上相应的代理 IP 和端口，下图是 macOS上的图示。 ![](Images/7dc0285df91a527411302749a23db0a9.png)savepage-src="https://static001.geekbang.org/resource/image/b3/46/b3ef5c0c4ce44566ee31157c17cd1846.png"}但你会发现，这时仍然录制不了 HTTPS应用，访问时会出现如下提示：![](Images/4f75eb69480624f7e4f4a30b47eef31c.png)savepage-src="https://static001.geekbang.org/resource/image/35/4f/3530bde553697ac448eac94e26ee524f.png"}这时就要在客户端机器上导入上面提到的ApacheJMeterTemporaryRootCA.crt。我们打开证书管理软件，在 macOS 上是Keychain Access，Windows 上是certmgr.msc。这里以 macOS 为例。首先打开 Keychain Access。![](Images/98f8d48732bfb20bf9b246929a0f1a3a.png)savepage-src="https://static001.geekbang.org/resource/image/68/2e/6861248706928c135e68bed9ee28232e.png"}点击上图中的 Import Items。选择ApacheJMeterTemporaryRootCA.crt，导入之后选择证书。会看到如下提示：![](Images/b4987f13cc44ecee37adb958a9911d4c.png)savepage-src="https://static001.geekbang.org/resource/image/dd/92/ddfdc4ef2050f922c9ea1b7ed3977d92.png"}因为这个证书不在系统信任的默认列表里，所以会提示证书不可信。另外这里我可以再多说一句，你注意的是，全球的可信任的根证书都是默认添加到系统中的，如果你在访问网站时，提示你要安装什么证书，一定要明确知道证书是从哪来的，不要随意安装未知来源的证书。目前国内的HTTPS 覆盖度不高，仍然有大量的 HTTP网页，这是需要推进的网络安全之一。然后我们双击此证书。![](Images/daf60194df423c96d92b74de4e8eaac0.png)savepage-src="https://static001.geekbang.org/resource/image/f7/16/f779bc63cd421ba92b1de098899b5616.png"}改为 Always Trust即可。提示如下：![](Images/36d9bf5d59134e55d164376b622b4bbf.png)savepage-src="https://static001.geekbang.org/resource/image/41/8c/417c1e58d3081ca6515ec8977532b78c.png"}这时，HTTP 和 HTTPS都会被录制下来。然后在客户机上打开浏览器，访问你的页面，这样就录制到脚本了。下面我们再来说下 Grouping这个功能。 Grouping的设置有如下几种，如果需要将脚本分开，先确定需要如何拆分。示例如下：![](Images/49d97916ecadb41830461d788a3969c7.png)savepage-src="https://static001.geekbang.org/resource/image/22/8b/2214f144340139acd8c84a15c86c938b.png"}第一个选项是 Do not groupsamples，也就是不分组。这是很多人使用的默认选项，这就相当于没有事务的概念了，每个请求都会单独统计TPS 和响应时间信息。![](Images/6c754291a3f1857cd46305c1269480fc.png)savepage-src="https://static001.geekbang.org/resource/image/41/83/41bb7af036a9910db9d8fd4bb6cf4083.png"}第二个选项是 Add separators betweengroups，在组间添加分隔，就为了好看！![](Images/9d5e0309138580c3ef5d74c4f28901d9.png)savepage-src="https://static001.geekbang.org/resource/image/25/35/251bcebb7e4451c881ba718ca21d6535.png"}第三个选项是，Put each group in a newcontroller，每个组放一个新的控制器。这是一个 SimpleController，它的作用也是只有一个：就为了好看！因为脚本太长了，看起来不方便，所以分个组，看着清晰一些。话说回来，你们见过在JMeter中有很长脚本的吗？是不是很多人都没有见过？![](Images/494e987954c6caf576924ae2822f0865.png)savepage-src="https://static001.geekbang.org/resource/image/74/0a/7451c99638e005cfe98d80ed0def060a.png"}第四个选项是，Put each group in a new transactioncontroller，将每个组放入一个新的事务控制器中。![](Images/dbf56da922f016a0986f9d5580f47412.png)savepage-src="https://static001.geekbang.org/resource/image/9b/34/9b5766b5a61fe76ed82a33f671ae9c34.png"}Transaction Controller 和 Simple Controller 的区别就是 TransactionController 会做为事务统计脚本执行的时间，而 Simple controller不会。 第五个选项是 Store 1st sampler for each grouponly，只存储每个组的第一个样本。网上大部分都只描述了上面这句，但是请注意我这里还有一句关键的：从 HTML文件获取所有内含的资源和自动重定向将开启。也就是说，虽说只记录了一个Sampler，但是资源也会下载，重定向也会开启。我们把这个过程抓出来看一下，因为 JMeter没有把这个过程显示出来。所以这里用 Chrome Developer Tool抓一下看看。举例来说，我们在浏览器里只输入了一个https://www.jd.com。抓出如下结果。![](Images/6ee868e1ff5d3af331334850ab6eb87b.png)savepage-src="https://static001.geekbang.org/resource/image/5a/a4/5a24f2adae925faac98b057a507525a4.png"}在上面的图中，你可以看到，www.jd.com，第一个就是 307 InternalRedirect。接着请求 Document，然后下面是静态资源。在录制时，选择 Store1st sampler for each group only之后，只会录制到第一个请求，而后面这些在回放脚本时也都会访问。在 JMeter的代理录制中，还有一个界面如下：![](Images/d7ba4c314b7c63e5a3b0a3b4552282ad.png)savepage-src="https://static001.geekbang.org/resource/image/96/0d/968fe93634c0f18c806fa922f300d50d.png"}中文界面中通常将之翻译为包含模式、排除模式。"模式"一词一加就显得格外高大上了。通常这里都会写上正则表达式，比如说常用的一些：    .*    .*.png    .*.gif    .*.jpg    .*.php    .*.jsp    .*.html    .*.htm    .*.js    ..(js|css|PNG|jpg|ico|png|gif).由于正则是一个很大的话题，这里我们就不展开了，只要你懂正则，在这里就可以适用。通过上面的内容，我们已经把 JMeter录制的原理和操作的过程都详细地描述了一遍，关于 JMeter的录制功能，就介绍到这里。在此重点提醒你一下，录制是通过代理做的，一定要知道代理的原理，代理就是转发的功能。承上启下的话为什么 JMeter这样的功能单一，性能又不好的性能测试工具能这么快的占领市场呢？在我看来，工具能不能用取决于它能不能满足需要。在很多的性能测试场景中，JMeter已经够用了。因为性能压力工具只需要两条曲线：TPS和响应时间（如果出错最多就再看一下错误率曲线）。这些功能，JMeter都可以提供。现在的性能项目中，我们要的压力其实并没有很大，并且大部分都是HTTP、TCP 之类的常见协议，脚本所使用的资源并不多。一般能达到万级 TPS的都很少很少，所以弄几个机器，JMeter也就够用了，再加上免费开源，何乐而不为呢？而 LoadRunner 的失败之处就是价格高，更新慢。一想到 HP 糟蹋了LoadRunner，我就伤心落泪。LoadRunner 中的录制功能我们都知道 LoadRunner其实可以录制很多协议，这也是它前期扩展市场的很重要的功能。应该说，在录制这个功能点上，所有的性能测试工具都不如LoadRunner。并且 LoadRunner在其他很多功能上都是强大的，强大到什么程度呢？就是有很多你不需要的，不常用的功能，它都具备。很多人都知道，LoadRunner 中的 Vuser Generator 只支持Windows。你有没有想过这是为什么？其实解释起来也简单，LoadRunner一开始是基于 WinInet 做的，就是 Windows Internet API。后来可能是觉得WinInet 太恶心了，于是换成了 Windows socket。而 Windows socket 跟 UNIXsocket 还是有一些小区别。所以从历史延续下来，Vuser Gnenerator 就一直在 Windows上了。 为什么不做 UNIX 的版本呢？其实在我看来，完全没有这个必要。因为 LoadGenerator 已经支持 UNIX 了。从使用的角度说，Vuser Gnenerator 没有必要做UNIX 的版本，因为它还有 Port Mapping 的功能，这样在 UNIX上的操作也照样录得下来。。下面我们就单说 LoadRunner的录制功能。常规录制首先，我们打开 Vuser Generator，点击 StartRecord，出现如下界面：![](Images/aceec482a2f6c098f589e758f5de65da.png)savepage-src="https://static001.geekbang.org/resource/image/c7/67/c79f3d7d072478b223d557987951c767.png"}在这个图中，首先的选择是：![](Images/a6f319770e07a3d90dd1557bc9ed8ae1.png)savepage-src="https://static001.geekbang.org/resource/image/0c/b7/0c0600701f1c6b71c8389eb243ab8bb7.png"}这里用 IE 或者应用程序都可以，只要支持我们选择的 HTTP协议就行。 Recording into action 这里是默认的 action，请你一定要注意的是init、action、end 这三个都是 action，并没有什么区别。控制 init 和 end只执行一遍和 action 会重复执行多次的功能也不在它们自己身上，而是在 runlogic里。这一点我将在后面的文章中再细说。点击 Options之后，跳出界面如下：![](Images/9c94ffc76de2f93aa26900e166a84b5a.png)savepage-src="https://static001.geekbang.org/resource/image/21/c9/21e1969112927b0e16adc2e013241cc9.png"}在这个界面中，有很多可以调的内容。这里举几个重要的点。首先是 HTML-based script 和 URL-basedscript。 ![](Images/5101e4b788ca128f90948794229655c4.png)savepage-src="https://static001.geekbang.org/resource/image/d5/16/d57f3c15ea014cf1502e136a590b4e16.png"}这个功能点之所以重要，是因为这两个选项录制出来的脚本有很大差别。其实这一点和 JMeter 的 Store 1st sampler for each group only是一样的含义。如果选择了 HTML-basedscript，就是一个页面一个请求了，而在回放和压力时，这个页面的所有资源都会请求。如果选择了 URL-basedscript，就是每个资源一个请求。这个选项有好处是，便于控制和查找问题。如果不想要某个资源，直接注释掉就好。其次，我们需要注意关联功能。![](Images/1067774749b01cd92cc438eb80a9b9e7.png)savepage-src="https://static001.geekbang.org/resource/image/52/43/52e00fd4eb4e6dab16f0acee5031d843.png"}你可以在这里事先设置好关联的规则，比如说这样的：    JSESSIONID=5687300192384o4^&&^&890523#123456;你就可以设置左边界为：JSESSIONID=，左边界为冒号，然后在你录制的时候，如果规则匹配到就会自动创建关联。点击 OK之后就开始录制了。出现一个工具条，如下所示：![](Images/f42ca6548cdab8ee5d0107b887e00843.png)savepage-src="https://static001.geekbang.org/resource/image/2d/93/2dac210c135e85e99d8e0405d72a3093.png"}在这个功能条上具有的功能是：暂停、停止、新建Action，创建集合点、创建事务的起点和终端、加备注、加文检查点。一般在业务流比较长的脚本中，性能测试工程师都会通过新建 Action把操作区分开，也会在录制过程中创建好必要的事务。最后录制出的脚本如下：![](Images/4969ae97837425b73fdbe53b55aaa42c.png)savepage-src="https://static001.geekbang.org/resource/image/9f/3c/9fe88180c56b27edd542db9ff715d73c.png"}注意哦，URL-based script 的时候，有一个 concurrentgroup，这个并发组是同时发出请求的。在 JMeter 中有一个 ParallelDownloads，你还记得吗？这两者功能一样。上面就是 LR 中常规的录制功能。录制前，看下 readme，看 LR支持什么浏览器。在版本 12.6 的 readme 中，已经声明支持 Windows 10 + IE了。但是我们在使用的过程中还是遇到各种各样的问题，比如调不出浏览器、录不出脚本、卡死的问题。还有，有些应用只支持Chrome，而有时，有些应用只能在某些特定的机器的执行，而那些机器又不能装Vuser Generator。在这样的场景中，我们只能使用 Port Mapping 的功能。是的，在 LoadRunner中，Port Mapping就是代理录制的方式。Port Mapping首先打开 Vuser Generator，点击 StartRecord，配置成如下界面：![](Images/27e7f521c7b79093d6cebffd577d6362.png)savepage-src="https://static001.geekbang.org/resource/image/55/37/554a3e2ef78259e73ecc4616bc176c37.png"}注意，这里一定要选择的是 LoadRunner 安装目录 bin 中的wplus_init_wsock.exe，从这个名字你也能知道它是基于 Windows Socket的。 然后，点击 Options - PortMapping，如下所示：![](Images/8e9eeb3be42a2e23522da0b6e91b1a55.png)savepage-src="https://static001.geekbang.org/resource/image/84/29/847bf5c6d80b59f3772cb07d12c95929.png"}点击 New Entry。配置如下：![](Images/f3eb5ec0ea3800921c7ea5cb03dcc62b.png)savepage-src="https://static001.geekbang.org/resource/image/b3/49/b39d5e0317acd982a42f97f5689a0d49.png"}从上图中你可以看到，它的代理功能是很全面和强大的，不仅支持不同的Service ID，也支持 SSL。这时的访问逻辑是下面这样的：![](Images/5a0c5a255b932a231a07c5cd52eb437f.png)savepage-src="https://static001.geekbang.org/resource/image/0a/8e/0ab937e601a8f2029527be1ccb0de08e.jpg"}一路OK，返回之后我们就可以开始录制了。会打开一个代理程序。截图如下：![](Images/77c8bf254ebb883adc7a2943f60a8847.png)savepage-src="https://static001.geekbang.org/resource/image/b8/36/b8cc2119b6eeb7164bbb47987d88ed36.png"}这时候本地会开一个 92的端口。 ![](Images/10d8d03794eecd47d52db041da9846fa.png)savepage-src="https://static001.geekbang.org/resource/image/59/74/591d5598781d5a107b2d56f93a2e6f74.png"}请注意，这时如果是远程访问，要注意不要让防火墙拦截了。接着打开浏览器，输入地址 http://10.211.55.3:92/，可以看到打开的是http://39.105.21.22:91/的界面。 ![](Images/41f027fb43140e28c85b377d98b992ea.png)savepage-src="https://static001.geekbang.org/resource/image/dc/ca/dc5d435bca5f519905a7e49db49e72ca.png"}同时，录制工具条中也显示出有事件产生。![](Images/b8a462fdb2aaefb0ef4c0e11b27bbc83.png)savepage-src="https://static001.geekbang.org/resource/image/5d/84/5d4e718b7cfd98398b4dc915180b5784.png"}当我们停止录制后，查看脚本如下：![](Images/39efd76b67967cb9a6e311c9fec380b6.png)savepage-src="https://static001.geekbang.org/resource/image/3a/98/3acc0dac595c23bedc5229f966d15398.png"}看到没有，这里的访问 IP 在直接回放时是不对的。所以要将 ip:port 换成39.105.21.22:91才能回放。替换后如下：![](Images/b96fafb1ab4ac76a58d908a82df278ff.png)savepage-src="https://static001.geekbang.org/resource/image/7d/eb/7d699171119d5aab83af784220e421eb.png"}这样就可以回放成功了。![](Images/8577a22595c1c14060edf9835f46b2f0.png)savepage-src="https://static001.geekbang.org/resource/image/61/d8/613e6d89e4480263bbce1c2aa08f0dd8.png"}如果回放不成功，我们就需要根据出错日志判断要做什么样的脚本增强。大部分的脚本都是需要做关联的，所以后面我们将讲一下关联的功能如何做，以及关联的原理。Loadrunner 的 Port Mapping 还可以支持 FTP、SOCKET、POP等协议。这个功能点也不复杂，操作起来也简单，只要想明白访问链路就可以了。LR的录制常用功能基本就这些了。总结这篇文章，应该是我写的所有的文章中，最最基础的一篇了，并且，从操作上，一步步地描述，也比较清晰。如果你有性能工具使用经验，肯定会觉得这篇过于简单。可是为什么还要写呢？因为在性能测试的过程中，有很多新手对录制的逻辑并不清楚。代理录制的这个动作他们也可以很快学会。但是很快就忘记了，我曾经给一些人手把手教过如何做代理录制。结果第二天就不记得了。其实并不是不记得动作，而是出了问题，脑子里没有判断问题的逻辑，所以根本无从下手排查。另外，你需要注意的是，录制功能并不是性能测试工具必备的功能。对性能测试工具来说，关键功能是能实现模拟批量的真实请求逻辑。至于脚本是如何实现的，怎么做就是可以的。所以我们可以用其他的工具，比如说BadBoby、Fiddler 甚至 Wireshark 抓到交互请求，再放到 JMeter中实现脚本，也完全是可以的。当然没有脚本就无从实现压力，所以脚本的实现是性能测试工程师必备的基础技术，理解原理也是必须的。思考题学完今天的文章后，你能用自己的话说一下代理录制的逻辑是什么吗？以及，当访问网页时，为什么第一个请求至关重要？欢迎你在评论区写下你的思考，也欢迎把这篇文章分享给你的朋友或者同事，一起交流进步一下。