# Data and Experimental Results

| 0.996 | 0.518 | 0.295 | 0.968 | 0.277 | 0.183 |
|---|---|---|---|---|---|
| DPS | DPSS | 0.999 | 0.999 | 0.999 | 0.999 |
| 0.998 | 0.998 | 0.999 | 0.999 | 0.999 | 0.999 |
| 0.999 | 0.999 | 0.999 | 0.999 | 0.999 | 0.999 |
| 0.986 | 0.995 | 0.993 | 0.989 | 0.987 | 0.984 |
| 0.999 | 0.999 | 0.999 | 0.999 | 0.999 | 0.999 |
| 0.997 | 0.992 | 0.991 | 0.990 | 0.984 | 0.976 |
| 0.951 | 0.957 | 0.979 | 0.979 | 0.951 | 0.948 |

**Table 4: NDCG in top-k columns for different approaches on datasets.**

## Methodology and Related Work

### Sensitivity Reduction and Differential Privacy
The approach of normalizing troublesome points to reduce sensitivity is employed, although the problem of choosing the scaling parameter remains unaddressed. The notion of (ε, δ)-differential privacy was used in [16, 9], while we use the stronger ε-differential privacy. Additionally, we present a differentially private method for selecting an optimal θ or (θ, α) pair, showing that the best choice depends on ε and the distribution beyond the average row count.

### Frequent Itemset Mining
Differentially private frequent itemset mining has been studied in [2, 19]. These works focus on identifying combinations of columns that are frequent. They use the exponential mechanism to select top-k columns, which we compare with, and do not consider the sensitivity control technique. Rastogi et al. [23] proposed a framework using Discrete Fourier Transform (DFT) to publish time-series data under differential privacy. We compare our approach with their Fourier Perturbation Algorithm in the experiments.

### Synopsis Publication for Range Queries
Several methods have been developed for publishing the synopsis of a dataset to enable accurate range queries [12, 25, 5, 17, 22]. Differentially private release of marginal tables has been studied in [1, 24, 18, 6, 10, 11]. Publishing a synopsis of two-dimensional datasets has also been explored in [5, 17, 22].

## Conclusions and Future Work

We have introduced the DPSense and DPSense-S approaches for publishing column counts in high-dimensional datasets. The key idea is to reduce sensitivity by setting a limit θ on the contribution of each record. Our main technical contribution is a quality function that enables the effective selection of the threshold and a correcting factor to reduce error in a differentially private manner. Experimental evaluation using various utility metrics demonstrates the effectiveness of our methods for publishing all columns or finding top columns with high counts. We also show that the efficiency of our algorithms makes private publishing of high-dimensional datasets practical. Our technique advances the state of the art in publishing column counts while satisfying differential privacy.

Given that high sensitivity is a major challenge in private data publishing and analysis, we conjecture that our novel sensitivity control technique can be applied to other problems. A future direction is to investigate the applicability of this technique to other issues involving the publication of information about high-dimensional datasets.

## Acknowledgments

This work was supported by the National Science Foundation under grant CNS-116991.

## References

[1] B. Barak, K. Chaudhuri, C. Dwork, S. Kale, F. McSherry, and K. Talwar. Privacy, accuracy, and consistency too: a holistic solution to contingency table release. In PODS’07, pages 273–282, 2007.

[2] R. Bhaskar, S. Laxman, A. Smith, and A. Thakurta. Discovering frequent patterns in sensitive data. In KDD, 2010.

[3] J. Blocki, A. Blum, A. Datta, and O. Sheffet. Differentially private data analysis of social networks via restricted sensitivity. In Proceedings of the 4th Conference on Innovations in Theoretical Computer Science, ITCS ’13, pages 87–96, New York, NY, USA, 2013. ACM.

[4] A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical privacy: the SuLQ framework. In PODS, pages 128–138, 2005.

[5] G. Cormode, M. Procopiuc, E. Shen, D. Srivastava, and T. Yu. Differentially private spatial decompositions. In ICDE, pages 20–31, 2012.

[6] B. Ding, M. Winslett, J. Han, and Z. Li. Differentially private data cubes: optimizing noise sources and consistency. In SIGMOD, pages 217–228, 2011.

[7] C. Dwork. Differential privacy. In ICALP, pages 1–12, 2006.

[8] C. Dwork, F. Mcsherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private data analysis. In Theory of Cryptography Conference (TCC), pages 265–284. Springer, 2006.

[9] M. Gotz, A. Machanavajjhala, G. Wang, X. Xiao, and J. Gehrke. Publishing search logs - a comparative study of privacy guarantees. IEEE Transactions on Knowledge and Data Engineering, 24(3):520–532, 2012.

[10] A. Gupta, M. Hardt, A. Roth, and J. Ullman. Privately releasing conjunctions and the statistical query barrier. In STOC, pages 803–812, 2011.

[11] M. Hardt, K. Ligett, and F. McSherry. A simple and practical algorithm for differentially private data release. In NIPS, pages 2348–2356, 2012.

[12] M. Hay, V. Rastogi, G. Miklau, and D. Suciu. Boosting the accuracy of differentially private histograms through consistency. PVLDB, 3:1021–1032, September 2010.

[13] K. Järvelin and J. Kekäläinen. Cumulated gain-based evaluation of IR techniques. ACM Trans. Inf. Syst., 20(4):422–446, Oct. 2002.

[14] S. P. Kasiviswanathan, K. Nissim, S. Raskhodnikova, and A. Smith. Analyzing graphs with node differential privacy. In Proceedings of the 10th Theory of Cryptography Conference on Theory of Cryptography, TCC’13, pages 457–476, Berlin, Heidelberg, 2013. Springer-Verlag.

[15] G. Kellaris and S. Papadopoulos. Practical differential privacy via grouping and smoothing. In PVLDB, PVLDB’13, pages 301–312. VLDB Endowment, 2013.

[16] A. Korolova, K. Kenthapadi, N. Mishra, and A. Ntoulas. Releasing search queries and clicks privately. In Proceedings of the 18th international conference on World wide web, WWW ’09, pages 171–180, New York, NY, USA, 2009. ACM.

[17] J. Lei. Differentially private m-estimators. In NIPS, pages 361–369, 2011.

[18] C. Li, M. Hay, V. Rastogi, G. Miklau, and A. McGregor. Optimizing linear counting queries under differential privacy. In PODS, pages 123–134, New York, NY, USA, 2010. ACM.

[19] N. Li, W. H. Qardaji, D. Su, and J. Cao. Privbasis: Frequent itemset mining with differential privacy. PVLDB, 5(11):1340–1351, 2012.

[20] F. McSherry and K. Talwar. Mechanism design via differential privacy. In IEEE Symposium on Foundations of Computer Science (FOCS), pages 94–103, 2007.

[21] D. Proserpio, S. Goldberg, and F. McSherry. Calibrating data to sensitivity in private data analysis. PVLDB, 7(8):637–648, 2014.

[22] W. Qardaji, W. Yang, and N. Li. Differentially private grids for geospatial data. In ICDE, 2012.

[23] V. Rastogi and S. Nath. Differentially private aggregation of distributed time-series with transformation and encryption. In Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data, SIGMOD ’10, pages 735–746, New York, NY, USA, 2010. ACM.

[24] J. Thaler, J. Ullman, and S. Vadhan. Faster algorithms for privately releasing marginals. In ICALP, pages 810–821, 2012.

[25] X. Xiao, G. Wang, and J. Gehrke. Differential privacy via wavelet transforms. IEEE Transactions on Knowledge and Data Engineering, 23:1200–1214, 2011.

## Appendix

### Proof of Lemma 2

We provide the proof of Lemma 2 here. Let \( D \) and \( D' \) be two neighboring datasets that differ in only one row. The sensitivity of the quality function \( q_s \), denoted as \( \Delta q_s \), is defined as the maximal possible difference of \( q_s \) given \( D \) and \( D' \). In other words,

\[
\Delta q_s = \max_{\forall \theta, \alpha, D, D', \varepsilon_p} \left| q_s(D, \theta, \alpha, \varepsilon_p) - q_s(D', \theta, \alpha, \varepsilon_p) \right|
\]

\[
= \max_{\forall \theta, \alpha, D, D'} \left| \left( -a_e(D, D|\theta) - \alpha \cdot \theta \right) - \left( -a_e(D', D'|\theta) - \alpha \cdot \theta \right) \right|
\]

\[
= \max_{\forall \theta, \alpha, D, D'} \left| a_e(D, D|\theta) - a_e(D', D'|\theta) \right|
\]

\[
= \max_{\forall \theta, \alpha, D, D'} \left| \sum_{j=1}^d \left| a_e(D, D|\theta)_j - a_e(D', D'|\theta)_j \right| \right|
\]

where \( c_j \) and \( c'_j \) denote the jth column count in \( D \) and \( D' \), respectively, and \( c^{\theta}_j \) and \( c'^{\theta}_j \) denote the jth column count in \( D|\theta \) and \( D'|\theta \), respectively. Since \( D \) and \( D' \) are neighboring datasets, \( c_j \) and \( c'_j \) can only differ by 1. If \( c_j = c'_j \), then the sensitivity is 0. So, let's assume \( c'_j = c_j + 1 \). Let \( \beta = c'^{\theta}_j - c^{\theta}_j \) be the value of the difference of the jth column between \( D|\theta \) and \( D'|\theta \). Since \( \theta \leq RC_i \) and \( RC_i \leq \Delta D \), we have the following inequality bound on \( \beta \):

\[
\frac{RC_i}{\theta} \leq \beta \leq \frac{\Delta D}{\theta}
\]

To compute the difference in error on the jth column between \( D \) and \( D' \), denoted as \( \delta_j \), we can discuss four different scenarios:

1. **If \( \alpha \cdot c^{\theta}_j \geq c_j \) and \( \alpha \cdot c'^{\theta}_j \geq c'_j \)**:
   \[
   \delta_j = \left| \alpha \cdot c^{\theta}_j - c_j \right| - \left| \alpha \cdot c'^{\theta}_j - c'_j \right|
   \]
   \[
   = \alpha \cdot c^{\theta}_j - c_j - (\alpha \cdot c'^{\theta}_j - c'_j)
   \]
   \[
   = \alpha \cdot c^{\theta}_j - c_j - \alpha \cdot c'^{\theta}_j + c_j + 1
   \]
   \[
   = 1 - \alpha \beta
   \]
   \[
   \leq 1 - \alpha \cdot \frac{\Delta D}{\theta}
   \]

2. **If \( \alpha \cdot c^{\theta}_j \geq c_j \) and \( \alpha \cdot c'^{\theta}_j < c'_j \)**:
   \[
   \delta_j = \left| \alpha \cdot c^{\theta}_j - c_j \right| - \left| \alpha \cdot c'^{\theta}_j - c'_j \right|
   \]
   \[
   = \alpha \cdot c^{\theta}_j - c_j - (c'_j - \alpha \cdot c'^{\theta}_j)
   \]
   \[
   = \alpha \cdot c^{\theta}_j - c_j - (c_j + 1 - \alpha \cdot c'^{\theta}_j)
   \]
   \[
   = \alpha \cdot c^{\theta}_j - c_j - c_j - 1 + \alpha \cdot c'^{\theta}_j
   \]
   \[
   = \alpha \cdot (c^{\theta}_j + c'^{\theta}_j) - 2c_j - 1
   \]
   \[
   \leq 1 - \alpha \beta \leq 1
   \]

3. **If \( \alpha \cdot c^{\theta}_j < c_j \) and \( \alpha \cdot c'^{\theta}_j \geq c'_j \)**:
   \[
   \delta_j = \left| \alpha \cdot c^{\theta}_j - c_j \right| - \left| \alpha \cdot c'^{\theta}_j - c'_j \right|
   \]
   \[
   = (c_j - \alpha \cdot c^{\theta}_j) - (\alpha \cdot c'^{\theta}_j - c'_j)
   \]
   \[
   = c_j - \alpha \cdot c^{\theta}_j - \alpha \cdot c'^{\theta}_j + c_j + 1
   \]
   \[
   = 2c_j - \alpha \cdot (c^{\theta}_j + c'^{\theta}_j) + 1
   \]
   \[
   \leq \alpha - 1
   \]

4. **If \( \alpha \cdot c^{\theta}_j < c_j \) and \( \alpha \cdot c'^{\theta}_j < c'_j \)**:
   \[
   \delta_j = \left| \alpha \cdot c^{\theta}_j - c_j \right| - \left| \alpha \cdot c'^{\theta}_j - c'_j \right|
   \]
   \[
   = (c_j - \alpha \cdot c^{\theta}_j) - (c'_j - \alpha \cdot c'^{\theta}_j)
   \]
   \[
   = c_j - \alpha \cdot c^{\theta}_j - (c_j + 1 - \alpha \cdot c'^{\theta}_j)
   \]
   \[
   = c_j - \alpha \cdot c^{\theta}_j - c_j - 1 + \alpha \cdot c'^{\theta}_j
   \]
   \[
   = \alpha \cdot (c'^{\theta}_j - c^{\theta}_j) - 1
   \]
   \[
   = \alpha \beta - 1 \leq \alpha - 1
   \]

Thus, \( \delta_j \leq \max_{\theta, \alpha} \{1, \alpha - 1\} \). The quality function computes the average of \( \delta_j \). Since the bound of \( \delta_j \) is independent of \( j \), we can directly infer that \( \Delta q_s \leq \max \{1, \alpha - 1\} \).