0.996
0.518
0.295
0.968
0.277
0.183
DPS DPSS
0.999
0.999
0.999
0.999
0.998
0.998
0.999
0.999
0.999
0.999
0.999
0.999
0.986
0.995
0.993
0.989
0.987
0.984
0.999
0.999
0.999
0.999
0.999
0.999
0.997
0.992
0.991
0.990
0.984
0.976
0.951
0.957
0.979
0.979
0.951
0.948
Table 4: NDCG in top-k columns for different approaches on datasets.
of normalizing troublesome points to reduce sensitivity, while the
problem of choosing the scaling parameter is not addressed. The
notion of (, δ)-differential privacy was used in [16, 9], and here we
use the stronger ()-differential privacy. Furthermore, we present
a differentially private way to choose a good θ or (θ, α) pair, and
show that the optimal choice depends on  and distribution beyond
the average row count.
Differentially private frequent itemset mining was studied in [2,
19]. These two papers focus on ﬁnding combinations of columns
that are frequent. They use the exponential mechanism to select
top-k columns, which we compare with, and do not consider the
sensitivity control technique. Rastogi et al.
in [23] proposed the
framework of using Discrete Fourier Transform (DFT) to publish
time-series data under differential privacy. We compare with their
Fourier Perturbation Algorithm in the experiments.
Several methods on publishing the synopsis of a dataset so that
range queries can be answered accurately have been developed [12,
25, 5, 17, 22]. Differentially private release of marginal tables were
studied in [1, 24, 18, 6, 10, 11]. Publishing a synopsis of two-
dimensional datasets has been studied in [5, 17, 22].
7. CONCLUSIONS AND FUTURE WORKS
We have proposed the DPSense and DPSense-S approaches
for publishing column counts for high-dimensional datasets. The
key idea is to reduce the sensitivity by setting a limit θ on the con-
tribution of each record, and our key technical contribution is a
quality function that enables the effective selection of the threshold
as well as the correcting factor to reduce error in a differentially
private way. Experimental evaluation using several utility metrics
demonstrates the effectiveness for publishing all columns or ﬁnd-
ing top columns with high count. We also demonstrate that the
efﬁciency of our proposed algorithms makes private publishing of
high dimensional datasets practical. Our technique has advanced
the state of the art on publishing column counts while satisfying
differential privacy.
As high sensitivity is a key hurdle to private data publishing and
analysis, we conjecture that our novel sensitivity control technique
can be fruitfully applied to other problems. A future direction is to
investigate whether this technique can be applied to other problems
that publishing information about high-dimensional datasets.
8. ACKNOWLEDGMENTS
This work reported in this paper is supported by National Science
Foundation under grant CNS-116991.
9. REFERENCES
[1] B. Barak, K. Chaudhuri, C. Dwork, S. Kale, F. McSherry,
and K. Talwar. Privacy, accuracy, and consistency too: a
holistic solution to contingency table release. In PODS’07,
pages 273–282, 2007.
[2] R. Bhaskar, S. Laxman, A. Smith, and A. Thakurta.
Discovering frequent patterns in sensitive data. In KDD,
2010.
[3] J. Blocki, A. Blum, A. Datta, and O. Sheffet. Differentially
private data analysis of social networks via restricted
sensitivity. In Proceedings of the 4th Conference on
Innovations in Theoretical Computer Science, ITCS ’13,
pages 87–96, New York, NY, USA, 2013. ACM.
[4] A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical
privacy: the SuLQ framework. In PODS, pages 128–138,
2005.
[5] G. Cormode, M. Procopiuc, E. Shen, D. Srivastava, and
T. Yu. Differentially private spatial decompositions. In
ICDE, pages 20–31, 2012.
[6] B. Ding, M. Winslett, J. Han, and Z. Li. Differentially private
data cubes: optimizing noise sources and consistency. In
SIGMOD, pages 217–228, 2011.
[7] C. Dwork. Differential privacy. In ICALP, pages 1–12, 2006.
[8] C. Dwork, F. Mcsherry, K. Nissim, and A. Smith. Calibrating
noise to sensitivity in private data analysis. In Theory of
Cryptography Conference (TCC), pages 265–284. Springer,
2006.
[9] M. Gotz, A. Machanavajjhala, G. Wang, X. Xiao, and
J. Gehrke. Publishing search logs - a comparative study of
461privacy guarantees. IEEE Transactions on Knowledge and
Data Engineering, 24(3):520–532, 2012.
[10] A. Gupta, M. Hardt, A. Roth, and J. Ullman. Privately
releasing conjunctions and the statistical query barrier. In
STOC, pages 803–812, 2011.
[11] M. Hardt, K. Ligett, and F. McSherry. A simple and practical
algorithm for differentially private data release. In NIPS,
pages 2348–2356, 2012.
[12] M. Hay, V. Rastogi, G. Miklau, and D. Suciu. Boosting the
accuracy of differentially private histograms through
consistency. PVLDB, 3:1021–1032, September 2010.
[13] K. Järvelin and J. Kekäläinen. Cumulated gain-based
evaluation of ir techniques. ACM Trans. Inf. Syst.,
20(4):422–446, Oct. 2002.
[14] S. P. Kasiviswanathan, K. Nissim, S. Raskhodnikova, and
A. Smith. Analyzing graphs with node differential privacy. In
Proceedings of the 10th Theory of Cryptography Conference
on Theory of Cryptography, TCC’13, pages 457–476, Berlin,
Heidelberg, 2013. Springer-Verlag.
[15] G. Kellaris and S. Papadopoulos. Practical differential
privacy via grouping and smoothing. In PVLDB, PVLDB’13,
pages 301–312. VLDB Endowment, 2013.
[16] A. Korolova, K. Kenthapadi, N. Mishra, and A. Ntoulas.
Releasing search queries and clicks privately. In Proceedings
of the 18th international conference on World wide web,
WWW ’09, pages 171–180, New York, NY, USA, 2009.
ACM.
[17] J. Lei. Differentially private m-estimators. In NIPS, pages
361–369, 2011.
[18] C. Li, M. Hay, V. Rastogi, G. Miklau, and A. McGregor.
Optimizing linear counting queries under differential privacy.
In PODS, pages 123–134, New York, NY, USA, 2010. ACM.
[19] N. Li, W. H. Qardaji, D. Su, and J. Cao. Privbasis: Frequent
itemset mining with differential privacy. PVLDB,
5(11):1340–1351, 2012.
[20] F. McSherry and K. Talwar. Mechanism design via
differential privacy. In IEEE Symposium on Foundations of
Computer Science (FOCS), pages 94–103, 2007.
[21] D. Proserpio, S. Goldberg, and F. McSherry. Calibrating data
to sensitivity in private data analysis. PVLDB, 7(8):637–648,
2014.
[22] W. Qardaji, W. Yang, and N. Li. Differentially private grids
for geospatial data. In ICDE, 2012.
[23] V. Rastogi and S. Nath. Differentially private aggregation of
distributed time-series with transformation and encryption.
In Proceedings of the 2010 ACM SIGMOD International
Conference on Management of Data, SIGMOD ’10, pages
735–746, New York, NY, USA, 2010. ACM.
[24] J. Thaler, J. Ullman, and S. Vadhan. Faster algorithms for
privately releasing marginals. In ICALP, pages 810–821,
2012.
[25] X. Xiao, G. Wang, and J. Gehrke. Differential privacy via
wavelet transforms. IEEE Transactions on Knowledge and
Data Engineering, 23:1200–1214, 2011.
APPENDIX
A. PROOF OF LEMMA 2
We give the proof of Lemma 2 here. Let D, D(cid:48) be two neighbor
datasets differ in only one row. The sensitivity of quality function
qs, ∆qs, is deﬁned as the maximal possible difference of qs giving
D, D(cid:48). In other words,
∆qs = max∀θ,α,D,D(cid:48),p
= max∀θ,α,D,D(cid:48),p
|qs(D, θ, α, p) − qs(D(cid:48), θ, α, p)|
(cid:12)(cid:12)(cid:12)(cid:16)−ae(D, D|θ) − α · θ
(cid:17)−
(cid:17)(cid:12)(cid:12)(cid:12)
(cid:16)−ae(D(cid:48), D(cid:48)|θ) − α · θ
(cid:80)d
|ae(D(cid:48), D(cid:48)|θ) − ae(D, D|θ)|
(cid:0)|α · cθ
p
p
j|(cid:1)
1
d
j=1
j − cj| − |α · c(cid:48)θ
= max∀θ,α,D,D(cid:48)
= max∀θ,α
j and c(cid:48)θ
j − c(cid:48)
j denote jth column count in D(cid:48) and in D(cid:48)|θ, re-
where c(cid:48)
spectively. Since D and D(cid:48) are neighbored dataset, cj and c(cid:48)
j can
only differ in 1. If cj = c(cid:48)
j, then the sensitivity apparently becomes
j − cθ
j = cj + 1. Let β = c(cid:48)θ
0. So let’s assume that c(cid:48)
j be the
value of the difference of jth column between D|θ and D(cid:48)|θ. Since
(θ ≤ RCi), and
the additional 1 in c(cid:48)
RCi ≤ ∆D, we have the following inequality bound on β:
j may be normalized to
RCi
θ
≤ β ≤ 1
θ
∆D
j − c(cid:48)
• If α · cθ
Let δj denote the difference of error on jth column between D and
D(cid:48), i.e. δj = |α · cθ
j − cj| − |α · c(cid:48)θ
j|. To compute δj, we can
discuss with four different scenarios:
j ≥ c(cid:48)
j − cj| − |α · c(cid:48)θ
j − cj − αc(cid:48)θ
j + c(cid:48)
j − c(cid:48)θ
j: Then we have
j − c(cid:48)
j|
j ) − cj + cj + 1
j ≥ cj and α · c(cid:48)θ
δj = |α · cθ
= αcθ
≤ α(cθ
= 1 − αβ
≤ 1 − α ·
j
≤ 1
θ
∆D
• If α · cθ
j ≥ cj and α · c(cid:48)θ
0 ≤ c(cid:48)
j: the bound of c(cid:48)
j − αc(cid:48)θ
j is
j ≤ c(cid:48)
j − αc(cid:48)θ
= cj + 1 − α(cθ
= cj − αcθ
≤ 1 − αβ ≤ 1
j
j + β)
j + 1 − αβ
The above also infers 0 ≤ αcθ
j − cj ≤ 1 − αβ ≤ 1. Thus,
• If α · cθ
j ≤ cj and α · c(cid:48)θ
j: the bound of αc(cid:48)θ
j − c(cid:48)
j is
j − cj| − |α · c(cid:48)θ
j − cj) − (c(cid:48)
j|
j − c(cid:48)
j − α · c(cid:48)θ
j )
δj = |α · cθ
= (α · cθ
≤ 1 − 0 = 1
j ≥ c(cid:48)
0 ≤ αc(cid:48)θ
= α(cθ
= αcθ
≤ αβ − 1
≤ α − 1
j
j − c(cid:48)
j + β) − cj − 1
j − cj + αβ − 1
The above also infers 0 ≤ cj − αcθ
j ≤ αβ− 1 ≤ α− 1. Then
δj = |α · cθ
j − cj| − |α · c(cid:48)θ
j − c(cid:48)
j|
= (cj − αcθ
j − c(cid:48)
j ) − (αc(cid:48)θ
j)
≤ (α − 1) − 0 = α − 1
• If α · cθ
j ≤ cj and α · c(cid:48)θ
δj = |α · cθ
j ≤ c(cid:48)
j − cj| − |α · c(cid:48)θ
j: Then we have
j − c(cid:48)
j|
= cj − α · cθ
j − c(cid:48)
j + α · c(cid:48)θ
j − cj − 1 + α · cθ
≤ cj − α · cθ
= αβ − 1 ≤ α − 1
j
j + αβ
Thus δj ≤ maxθ,α{1, α − 1}. The quality function computes
the average of δj. Since the bound of δj is independent of j, we
can directly infer that ∆qs ≤ max{1, α − 1}.
462