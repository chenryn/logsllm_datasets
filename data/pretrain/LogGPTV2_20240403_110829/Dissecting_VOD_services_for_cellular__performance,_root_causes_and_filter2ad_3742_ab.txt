implementations HLS and DASH.
HLS vs. DASH HTTP Live Streaming (HLS) [45] is a media
streaming protocol proposed by Apple Inc. In HLS, a media pre-
sentation is described by a Master Playlist, which specifies the
resolution, bitrate and the URL of corresponding Media Playlist of
each track. The URL and duration of media segments are specified
in the Media Playlist. Each media segment in HLS is a separate
media file3. At the beginning of playback, the client downloads
the Master Playlist to obtain information about each track. After it
decides to download segments from a certain track, it downloads
the corresponding Media Playlist and gets the URI of each segment.
Compared with HLS, the Dynamic Adaptive Streaming over
HTTP (DASH) [1] is an international standard specifying formats
to deliver media content using HTTP. Media content in DASH
is described by the Media Presentation Description (MPD), which
specifies each track’s declared bitrate, segment duration and URI etc.
Each media segment can be a separate media file or a sub-range of a
larger file. The byte-range and duration of segments may be directly
described in the MPD. The MPD can also put such information in
the Segment Index Box (sidx) of each track and specify the URI of
sidx. The sidx contains meta information about the track and is
usually placed at the beginning of the media file.
To accommodate the differences across the HAS protocol and
service variations, the traffic analyzer works as follows. It gets the
bitrate of each track from the Master Playlist for HLS, and then
extracts the URI and duration of each segment from it. For DASH,
it gets the bitrate of each track from the MPD, and generates the
mapping of byte ranges to segment information using different data
sources for different apps. D2, D3 and D4 put such information into
the sidx of each track, while D1 directly encodes it in the MPD. D3
encrypts the MPD file in application layer before sending it through
3From version 4, HLS also supports using a sub-range of a resource as a media segment.
But none of our studied services use this feature.
the network. However, the sidx is not encrypted and we can still
get segment durations and sizes.
2.4 UI monitor
The UI monitor aims at exposing QoE metrics that can be obtained
from the app UI on the client. Based on our exploration of all the
VOD apps in our study, we identify the seekbar to be a commonly
used UI element that indicates the playing progress, i.e. the position
of displayed frames in the video in time.
We investigate how to robustly capture the seekbar information.
As the UI appearance of the seekbar has a significant difference
across different apps, we do not resort to image process techniques.
Instead, we use the Xposed framework [13], an Android framework
which enables hooking Android system calls without modifying
apps, to log system calls from the apps to update the seekbar.
We find that despite the significant difference in visual appear-
ance, the usage of the seekbar is similar across the services. During
playback, the players update the status of the seekbar periodically
using the Android API ProgressBar.setProgress. Thus, we obtain in-
formation about playback progress and stall events from the API
calls. The update may occur even when the seekbar is hidden on
the screen. This methodology can be generally applied to apps that
use the Android seekbar component regardless of the UI layout and
visual appearance.
For the all apps we studied, the progress bar was updated at least
every 1s and we can therefore get the current playing progress at
at least 1s granularity.
2.5 Buffer inference
The client playback buffer status, including the occupancy and
the information regarding segments in the buffer, is crucial for
characterizing the player’s behavior. We infer the buffer occupancy
by combining information from the downloading process and the
playback process, collected by the traffic analyzer and UI monitor
respectively: at any time, the difference between the downloading
progress and playing progress should be the buffer occupancy,
and the details, such as the bitrate, and duration of the segments
remaining in the buffer, can be extracted from the network traffic.
2.6 Network emulator
We use the Linux tool tc to control the available network bandwidth
to the device across time to emulate various network conditions.
To understand designs such as the adaptation logic, we apply
carefully designed network bandwidth profiles. For instance, to
understand how players adapt to network bandwidth degradation,
we design a bandwidth profile where the bandwidth stays high
for a while and then suddenly drops to a low value. In addition, to
identify QoE issues and develop best practices for cellular scenarios,
it is important to compare the QoE of the different services in the
context of real cellular networks. To enable repeatable experimenta-
tions and provide apples-to-apples comparisons between different
services, we also replay multiple bandwidth traces from real cellular
networks over WiFi in the lab for evaluating the services.
To collect real world bandwidth traces, we download a large file
over the cellular network and record the throughput every second.
We collect 14 bandwidth traces from real cellular network in various
scenarios covering different movement patterns, signal strength
Dissecting Cellular VOD Services
IMC ’17, November 1–3, 2017, London, UK
and locations. We sort them based on their average bandwidth and
denote them from Profile 1 to Profile 14 (see Figure 3).
We run each of the services with the 14 collected cellular band-
width traces. Each experiment lasts for 10min and is repeated for
several runs to eliminate temporary QoE issues caused by the ex-
ternal environment, e.g. transient server load.
3 SERVICE CHARACTERIZATION
The interactions between different components of each VOD service
across multiple protocol layers on both the client and server side
together ultimately determine the QoE. Using our methodology
from §2, for each service, we identify critical design choices around
three key components: the server, the transport layer protocols, and
the client, and investigate their QoE implications. We summarize
the various designs in Table 1.
Our measurements reveal a number of
interesting QoE-
impacting issues caused by the various design choices (Table 2).
We shall present the design factors related to these issues in this
section and dive deeper into 3 most interesting problems in §4.
3.1 Server design
At the server-side, the media is encoded into multiple tracks with
different bitrates, with each track broken down into multiple seg-
ments, each corresponding to a few seconds worth of video. Un-
derstanding these server-side settings is important as they have
critical impact on the adaptation process and therefore the QoE.
For each service, we analyze the first 9 videos on the landing page
which span different categories. We find that for all studied services,
for the 9 videos in the same service, the settings are either identical
or very similar. We select one of these videos as a representative
sample to further illustrate the design for each service.
Separate audio track. The server can either encode separate
audio tracks or multiplex video and audio content in the same track.
Using separate audio tracks decouples video and audio content,
and gives a service more flexibility to accommodate different audio
variants for the same video content, e.g. to use a different language
or a different audio sample rate. We analyze a service’s manifest to
understand whether the service encodes separate audio tracks. We
find that all the studied services that use HLS do not have separate
audio tracks, while all services that use DASH or SmoothStreaming
encode separate audio tracks.
Track bitrate setting. Track settings such as track count (num-
ber of tracks), the properties of the highest and lowest tracks, and
the spacing (bitrate difference) between consecutive tracks all im-
pact HAS adaptation and therefore the QoE. We obtain the track
declared bitrate from the manifest of each service4.
The highest track represents the highest quality that a service
provides. We find across the services the highest track has diverse
bitrates from 2 Mbps to 5.5 Mbps. Note that the declared bitrate is
not the only factor that determines video quality, as it also depends
on other factors such as encoding efficiency.
The bitrate of the lowest track impacts the players’ ability to
sustain seamless playback under poor network conditions. Apple
4 This approach did not work for D3 as the manifest is encrypted at the application
layer and cannot be decrypted. Instead, we use the peak value of the actual segment
bitrates (which can be obtained by parsing the sidx) as the declared bitrate since other
DASH services such D1 and D2 follow such practice
recommends that the lowest track should be below 192 kbps for cel-
lular network [16]. However, the lowest track of 3 services is higher
than 500 kbps and significantly increases the possibility of having
stalls with slow network connection. For example, our evaluations
show with the two lowest bandwidth profiles, H5 always stalls for
more than 10 s, while apps with lower bit-rate bottom tracks such
as D2 and D3 do not have stalls under the same network conditions.
Because stalls severely impact QoE, we suggest setting the bitrate of
the bottom track to be reasonably low for mobile networks.
Tracks inbetween the highest and lowest track need to be se-
lected with proper inter-track spacing. If adjacent tracks are set
too far apart, the client may often fall into situations where the
available bandwidth can support streaming a higher quality track,
but the player is constrained to fetch a much lower quality, due
to the lack of choices. If adjacent tracks are set too close to each
other, the video quality improves very little by switching to the next
higher track and the higher track count unnecessarily increases
server-encoding and storage overheads. Apple recommends adja-
cent bitrate to a factor of 1.5 to 2 apart [16]. All services we study
are consistent with this guideline.
CBR/VBR Encoding. Services can use two types of video en-
coding scheme, i.e. Constant Bitrate (CBR) encoding which encodes
all segments into similar bitrates, and Variable Bitrate (VBR) en-
coding which can encode segments with different bitrates based on
scene complexity [9].
We examine the distribution of bitrates across segments from
the same track to determine the encoding. We get segment duration
information from the manifest. To get segment sizes, for services
using DASH, we directly get segment sizes from the byte range
information provided by the manifest and sidx. For services using
HLS and SmoothStreaming, we get the media URLs from the mani-
fest file and use curl [11] to send HTTP HEAD requests to get the
media size. We find that 3 services use CBR, while the others use
VBR with significant different actual segment bitrates in a single
track. For example, the peak actual bitrate of D1 is twice the average
actual bitrate.
With VBR encoding, using a single declared bitrate to represent
the required bandwidth is challenging. We look into how services
set the declared bitrate. For the highest track of each service, we
examine the distribution of actual segment bitrates normalized by
the declared bitrate. As shown in Figure 5, S1 and S2 set the declared
bitrate around the average actual bitrate, while other services set
the declared bitrate around the peak actual bitrate. We shall explore
further in § 4.2 the associated QoE implications.
Segment duration. The setting of segment duration involves
complex tradeoffs [3]. A short segment duration enables the client
to make track selection decision in finer time granularity and adapt
better to network bandwidth fluctuations, as segments are the small-
est unit to switch during bitrate adaptation. On the other side, a
long segment duration can help improve encoding efficiency and
reduce the server load, as the number of requests required to down-
load the same duration of video content reduces. We find significant
differences in the segment duration across the different services,
ranging from 2s to as long as 10s (see Table 1). We leave a deeper
analysis on characterizing the tradeoffs to future work. In addition,
as we find later in § 4.3, other factors such as startup buffer duration
need to be set based on the segment duration to ensure good QoE.
IMC ’17, November 1–3, 2017, London, UK
Shichang Xu, Z. Morley Mao, Subhabrata Sen, and Yunhan Jia
Figure 3: Collected cellular network band-
width profiles.
Figure 4: Declared bitrates of tracks for dif-
ferent services
Figure 5: The distribution of actual bitrate
normalized by declared bitrate
Server
Transport
layer
Startup
Download
control
Designs
Segment duration (s)
Separate audio track
Max #TCP
Persistent TCP
Startup buffer (s)
Startup bitrate (Mbps)
Pausing threshold (s)
Resuming threshold (s)
With constant bw Stability
With varying bw
Aggressiveness
Decrease buffer (s)
* The audio segment duration of D1 and S2 is 2s.
H1
4
N
1
Y
8
0.63
95
85
Y
N
-
H2
2
N
1
N
8
1.33
90
84
Y
N
40
H3
9
N
1
N
9
1.05
40
30
Y
N
-
H4
9
N
1
Y
9
0.47
155
135
Y
N
-
H5
6
N
1
N
12
1.85
30
20
Y
N
-
Table 1: Design choices
H6
10
N
1
Y
10
0.88
80
70
Y
N
-
D1
5*
Y
6
Y
15
0.41
182
178
Y
Y
-
D2
5
Y
2
Y
5
0.30
30
25
Y
N
-
D3