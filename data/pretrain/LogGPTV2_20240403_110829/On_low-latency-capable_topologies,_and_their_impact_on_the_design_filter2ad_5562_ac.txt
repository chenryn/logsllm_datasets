There are five paths that have lower latency than the great-
circle fiber path, and all 20 paths have lower latency than the
current Internet path. However, latency variability increases as
the path gets worse: path 20 has much more variable latency
than path 1, as it has fewer options available. In figure 12 we
see the one-way latency of path 20 in more detail. 10% vari-
ability is likely insufficient to trigger spurious TCP timeouts,
and increases in RTT are also unlikely to impact TCP. How-
ever, when latency decreases rapidly, reordering will occur,
causing TCP to incorrectly assume a loss has occurred and
triggering a fast retransmit.
5 RESEARCH AGENDA
A network such as Starlink raises many research questions,
both for the network itself, and for traffic traversing it. For
legacy Internet traffic, reordering must be avoided. Delay-
based congestion control such as BBR[3] may not perform
well over such a network. The network must be resilient to
failures. And it must be capable of routing with low delay,
even when traffic levels are high enough to saturate the best
paths. We briefly discuss some of these questions.
Reordering. Reordering is different from that seen on a
terrestrial network. So long as queues are not allowed to
build in satellites, reordering is completely predictable, as all
routes are known several hundred milliseconds in advance.
One solution is to maintain a reorder buffer at the receiving
groundstation. Packets that arrive over a lower delay path are
Figure 10: Phase 2a network showing just side links.
to zig-zag via SW and SE links. Can we do better?
Phase 2 Routing SpaceX’s proposals for phase 2 include
another 1,600 satellites in 53.8°inclination orbits. These orbits
closely parallel the 53°orbits of the phase 1 satellites, but they
are 40 km lower so complete an orbit in 53 seconds less than
phase 1 (a complete orbit takes ≈107 minutes). As with the
phase 1 satellites, it makes most sense to use the first laser
pair to connect along the orbital plane. We now have a choice
of how to use the remaining lasers.
We experimented with connecting adjacent 53°and 53.8°
satellites, but the velocity difference makes this problematic -
the direct East-West routing paths slowly become zig-zag be-
fore eventually the satellites switch to the next neighbor, and
this adversely affects latency. To avoid this drift problem, we
conclude that 53.8°satellites should connect to 53.8°satellites
in the next orbital plane, even though they are more distant.
As figure 1 shows, the best phase offset between neigh-
boring planes is 17/32. This larger phase offset changes the
options for the orientation of paths created by connecting to
the neighboring orbital plane. We already have good NW-SE,
NE-SW, and East-West connectivity from phase 1, and rout-
ing along the phase 2 orbital planes will increase the NW-SE
and NE-SW capacity. Using the remaining lasers to improve
the North-South direction is an attractive option. To do this,
we offset the lasers by 2, connecting satellite n in plane p to
satellite n− 2 in plane p − 1 and n + 2 in plane p + 1. Figure 10
shows just the side laser links of 53.8°satellites using this
offset. We cannot achieve perfect N-S orientation, but the
paths are very good at higher latitudes.
These N-S paths are complemented by the satellites in
higher inclination orbits. For these there are only a few orbital
planes too far apart to allow connections between neighboring
planes, except near the poles. We use their remaining three
lasers less methodically, allowing them to to opportunistically
connect to each other or to 53°and 53.8°orbits as they come
close. This provides reasonable polar coverage while allowing
them to be used for N↔S traffic at lower latitudes.
The blue curve in Figure 9 shows that adding the phase
2 satellites has improved the London-Johannesburg latency
by about 20% due to the more direct routing. The purple
curve shows the second best path, calculated by removing all
links used by the best path, and re-running Dijkstra on the
Figure 11: Phase 2 Multipath RTT, NYC-LON, best 20 disjoint paths.
Figure 12: Latency on path 20.
simply queued until their one-way delay matches that of the
higher delay paths. Doing this, the RTT on the 20th best path
is still approximately 74ms, less than current Internet RTT.
We can do even better if the sending groundstation can
annotate packets with a sequence number, a path ID, and the
time tlast since it sent the last packet on the previous path.
When the sending groundstation switches from a higher delay
path to a lower delay one, reordering may occur. The first
packet to arrive on the new path is identified by the receiving
groundstation from the change of path ID. Suppose the known
difference in path delays is tdif f . If any preceding packets
are missing, the receiving groundstation queues all packets
arriving on the new path until either all predicing packets
have arrived, or time equal to tdif f − tlast has elapsed. After
this, all packets sent on the old path should have arrived.
Finally, as the sending groundstation knows future path
latency, if there is a queue there that is longer than the dif-
ference in path delays, it may take packets from this queue
out-of-order, sending them over different latency paths so
that they arrive in-order at the receiving groundstation. For
high-priority latency-sensitive traffic, we would hope that no
such queue ever exists, but we expect that a large volume of
lower priority traffic will also be present and fill in around the
high-priority traffic. It is this traffic that might use a 20th best
path, and it too must not suffer excessive reordering.
Failures. Such a network is inherently resilient to failures. If
an RF transceiver fails, that satellite can still relay through traf-
fic; there are many other satellites within range of a ground-
station, so the impact on coverage is minimal. However,
all groundstations need to be informed of any failure, so
they can factor it in to their routing considerations. If the
five transceivers on a satellite are interchangable, then of
one failes, the constellation continues to perform almost un-
changed so long as the four remaining transceivers are used
for the links along the orbital plane, and for the side links. The
link between NE-bound and SE-bound satellites is less criti-
cal because latency-based routing will often try to avoid such
paths (see the latency spike in Figure 7), and other similar-
latency paths will be normally be available. Again, everyone
needs to know about the failure to factor it in to routing.
SpaceX have stated that they will have on-orbit spare satel-
lites for each orbital plane—it uses very little fuel to adjust
position along an orbital plane, but requires excessive fuel to
perform a plane change. However, even without spares, the
network has very good redundancy. Gaps in coverage can be
routed around - for example, Path 2 in Figure 11 shows the
latency achieved between London and New York is all the
satellites on Path 1 were unavailable. The same is likely not
true though for extreme latitudes, where coverage is much
sparser. We note that SpaceX propose 75 satellites per orbital
plane for the higher inclination orbits, rather than 50 in other
orbits; we speculate that this closer spacing may allow laser
links to bypass one failed satellite to reach the next.
Load-Dependent Routing. All the simulations above as-
sume that no significant queuing happens in the satellites
themselves. For high-priority (likely high cost) traffic, this
can be ensured by admission control, so long as it forms a
minority of the traffic. This is a similar model to that used
on the terrestrial microwave links used for high frequency
trading. Regular Internet traffic will not get such priority treat-
ment, so a LEO constellation operator needs to perform active
traffic engineering to avoid creating hotspots in the network.
Others have demonstrated that shortest-path routing on mesh
networks is particularly susceptible to creating hotspots[6].
In terrestrial networks, centralized load-dependent routing
schemes such as B4[9] and LDR[7] can pro-actively route so
as to achieve low latency without causing congestion. These
schemes, however, make routing decisions on a minute-by-
minute basis - too slow for routing on dense LEO constella-
tions. It is an open question whether such schemes can be
extended for this use, or if the latency between the controller
and groundstations will always be too high.
We postulate that a hybrid solution may work well. High
priority low-latency traffic always gets priority, admission
control limits its volume, preventing it causing congestion and
it gets explicit routing ensuring minimum latency. For the re-
maining traffic, satellites monitor link load; this is broadcast to
all groundstations globally, so everyone is aware of hotspots.
Because of the nature of a LEO constellation, these hotspots
tend to be geographic rather than topological. Groundstations
then randomize their path choice across slightly less favorable
paths to load-balance traffic away from hotspots. In a tradi-
tional topology, this would likely lead to instability, where
traffic flip-flops between the best path and a worse alternate.
As our simulations show, dense LEO constellations have very
many paths available, and many of them are of similar latency.
This allows groundstations to be much more conservative
about when they move traffic back to the lowest delay path,
using timescales much longer than the latency of the broad-
cast load reports, so avoiding instability. We believe this is an
interesting direction for future routing work on dense LEO
constellations.
 45 50 55 60 65 70 75 80020406080100120140160Time (s)RTT (ms)P20P19P18P17P16P15P14P13P12P11P10P9P8P7P6P5P4P3P2P1ﬁberInternet 33 34 35 36 37 38020406080100120140160Time (s)One way delay (ms)REFERENCES
[1] S. Anthony.
The secret world of microwave networks. Ars
Technica, https://arstechnica.com/information-technology/2016/11/
private-microwave-networks-financial-hft/, Mar. 2016.
[2] I. N. Bozkurt, B. Chandrasekaran, A. Aguirre, P. B. Godfrey, G. Laugh-
lin, B. Maggs, and A. Singla. Why is the internet so slow?! In Passive
and Active Measurement Conference, March 2017.
[3] N. Cardwell, Y. Cheng, C. S. Gunn, S. H. Yeganeh, and V. Jacob-
son. BBR: Congestion-based congestion control. ACM Queue, 14,
September-October:20 – 53, 2016.
[4] Corning Incorporated. SMF-28TM optical fiber product information,
2002.
[5] E. W. Dijkstra. A note on two problems in connexion with graphs.
Numerische Mathematik, 1:269–271, 1959.
[6] N. Gvozdiev, S. Vissicchio, B. Karp, and M. Handley. Low-latency
In Proceedings of the 16th ACM
routing on mesh-like backbones.
Workshop on Hot Topics in Networks, 2017.
[7] N. Gvozdiev, S. Vissicchio, B. Karp, and M. Handley. On low-latency-
capable topologies, and their impact on the design of intra-domain
routing. In Proc. ACM Sigcomm, 2018.
[8] M. Handley. Low latency routing in space (accompanying video).
https://youtu.be/AdKNCBrkZQ4, 2018.
[9] S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh,
S. Venkata, J. Wanderer, J. Zhou, M. Zhu, et al. B4: Experience with a
globally-deployed software defined wan. ACM SIGCOMM Computer
Communication Review, 43(4):3–14, 2013.
[10] B. Karp and H. Kung. Greedy perimeter stateless routing for wireless
networks. In Proceedings ACM/IEEE MobiCom, Aug. 2000.
[11] G. Moller. Ultra low latency microwave radio systems revolutionize
HFT. http://www.cielonetworks.com/site/white-papers.html.
[12] Space Exploration Technologies. SpaceX non-geostationary satellite
system Attachment A: technical information to supplement Sched-
ule S. https://licensing.fcc.gov/myibfs/download.do?attachment_key=
1158350, Nov. 2016.
[13] H. Zech, F. Heine, D. Tröndle, S. Seel, M. Motzigemba, R. Meyer, and
S. Philipp-May. LCT for EDRS: LEO to GEO optical communications
at 1.8 Gbps between Alphasat and Sentinel 1a. In Proc. SPIE Security
and Defence, 2015.