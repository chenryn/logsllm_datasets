To address this problem, the authors deﬁne a new primi-
tive they call a property-preserving hash (PPH). A PPH as
deﬁned and used in [15], allows one to expose a property
(speciﬁcally y ?= x + 1) of two (numerical) elements such
that nothing else is leaked. In particular, the outputs are
randomized, so same element hashed twice will have diﬀer-
ent hashes. Please refer to the original paper [15] for formal
correctness and security deﬁnitions.
Equipped with the PPH primitive, the algorithm “hashes”
the elements of the ciphertexts before outputting them. Due
to security of PPH, the adversary would not be able to count
how many elements two ciphertexts have in common, thus,
would not be able to tell the location of diﬀering bit.
Security. The strong side of the scheme is its security. The
scheme leaks L(·) an equality pattern of the most-signiﬁcant
diﬀering bits (satisfying Chenette et al. [18] deﬁnition). As
deﬁned in [15], the intuition behind equality pattern is that
for any triple of plaintexts m1, m2, m3, it leaks whether
m2 diﬀers from m1 before m3 does. We do not know of
any attacks against this construction (partially because no
implementation exists yet, see next subsection), but it is
inherently vulnerable to frequency attacks that apply to all
frequency-revealing ORE schemes (see Section 2).
Analysis and implementation challenges
On encryption, the scheme makes n calls to PRF, n calls
to PPH Hash and one call to PRP. Comparison is more
expensive, as the scheme makes n2 calls to PPH Test.
The scheme has two limitations that make it impractical.
The ﬁrst one is the square number of calls to PPH, which is
around 1024 for a single comparison.
The second problem is the PPH itself. Authors suggest
a construction based on bilinear maps. The hash of an ar-
gument is an element of a group, and the test algorithm is
computing a pairing. This operation is very expensive — or-
der of magnitude more expensive than any other primitive
we have implemented for other schemes.
We have implemented this scheme in C++ using the PBC
library [50] to empirically assess schemes’s performance, and
on our machine (see Section 5), a single comparison takes
1.9 seconds on average. Although we have produced the ﬁrst
(correct and secure) real implementation of this scheme in
C++, it is infeasible to use it in the benchmark (it will take
years to complete a single run). Therefore, for the purposes
of our benchmark, we implemented a “fake” version of PPH
— correct, but insecure, which does not use pairings. Con-
sequently, in our analysis we did not benchmark the speed
of the scheme, but measured all other data.
3.5 FH-OPE
Frequency-hiding OPE by Kerschbaum [39] is a stateful
scheme that hides the frequency of the plaintexts, so the
adversary is unable to construct a frequency histogram.
This scheme is stateful, which means that the client needs
to keep a data structure and update it with every encryption
and decryption. The data structure is a binary search tree
where the node’s value is the plaintext and node’s position
in a tree is the ciphertext. For example, consider the range
[1, 128]. Any plaintext that happens to arrive ﬁrst (for exam-
ple, 6), will be the root, and thus the ciphertext is 64. Then
any plaintext smaller than the root, say 3, will become the
left child of the root, and will produce the ciphertext 32. To
encrypt a value, the algorithm traverses the tree until it ﬁnds
a spot for the new plaintext, or ﬁnds the same plaintext. If
the same plaintext is found, the traversal pseudo-randomly
passes to the left or right child, up to the leaf. This way,
the invariant of the tree — intervals of the same plaintexts
do not overlap — is maintained. The ciphertext generated
from the new node’s position is returned.
Due to randomized ciphertexts, the comparison algorithm
is more complicated than in the regular deterministic OPE.
To properly compare ciphertexts, the algorithm needs to
know the boundaries — the minimum and maximum cipher-
texts for a particular plaintext. The client is responsible for
traversing the tree to ﬁnd the plaintext for the ciphertext
and then minimum and maximum ciphertext values. Hav-
ing these values, the comparison is trivial — equality is a
check that the value is within the boundaries, and other
comparison operators are similar.
Authors have designed a number of heuristics to minimize
the state size, however, these are mostly about compacting
the tree and the result depends highly on the tree content. In
our analysis, we consider the worst case performance with-
out the use of heuristics.
In our experimental evaluation,
however, we did implement compaction.
Security. The security of the scheme relies on the large
range size to domain size ratio. Authors recommend at
least 6 times longer ciphertexts than the plaintexts in bit-
length, which means ciphertexts should be 192-bit numbers
that are not commonly supported. It is possible to operate
over arbitrary-length numbers, but the performance over-
head would be substantial. We did a quick micro-benchmark
in C# and the overhead of using BigInteger is 15–20 times
for basic arithmetic operations.
This scheme satisﬁes IND-FAOCPA deﬁnition (introduced
along with the scheme [39]), meaning that it does not leak
the equality or relative distance between the plaintexts. This
deﬁnition has been criticized in [51], who claim that the deﬁ-
nition is imprecise and propose an enhanced deﬁnition along
with a small change to construction to satisfy this new def-
inition. Both schemes leak the insertion order, because it
aﬀects the tree structure. We do not know of any attacks
against this leakage, but it does not mean they cannot exist.
Grubbs et al. [27] describe an attack against this scheme (bi-
nomial attack), but it applies to any perfectly secure (leaking
only total order) frequency-hiding OPE.
Analysis and implementation challenges
If the binary tree grows in only one direction, at some point
it will be impossible to generate another ciphertext. In this
case, the tree has to be rebalanced. This procedure will
invalidate all ciphertexts already generated. This property
makes the scheme diﬃcult to use in some protocols since
they usually rely on the ciphertexts on the server being al-
ways valid. The authors explicitly mention that the scheme
works under the assumption of uniform input. However, the
rebalancing will be caused by insertion of just 65 consecutive
input elements for 64-bit integer range.
The scheme makes one tree traversal on encryption and
decryption. Comparison is trickier as it requires one traver-
sal to get the plaintext, and two traversals for minimum and
maximum ciphertexts. We understand that it is possible to
get these values in fewer than three traversals, but we did
not optimize the scheme for the analysis and evaluation.
For practitioners we note that the stateful nature of the
scheme implies that the client storage is no longer negligible
as the state grows proportionally to the number of encryp-
tions. We also note that implementing compaction exten-
sions will aﬀect code complexity and performance. Finally,
we stress again that some non-uniform inputs can break the
scheme by causing all ciphertexts to be invalid. It is up to
the users of the scheme to ensure uniformity of the input,
which poses serious restrictions on the usage of the scheme.
4. SECURE RANGE QUERY PROTOCOLS
We proceed by describing and analyzing the range query
protocols we have chosen. For the purpose of this paper, a
secure range-query protocol is deﬁned as a client-server com-
munication involving construction and search stages. Com-
munication occurs between a client, who owns some sensi-
tive data, and an honest server, who securely stores it. In
construction stage, a client sends the server the encrypted
datapoints (index-value tuples) and the server stores them
in some internal data structure. In search stage, a client asks
the server for a range (usually specifying it with encrypted
endpoints) and the server returns a set of encrypted records
matching the query. Note that the server may interact with
the client during both stages (e.g. ask the client to sort a
small list of ciphertexts). Also note that we do not allow
batch insertions as it would limit the use cases (e.g. client
may require interactive one-by-one insertions).
The ﬁrst protocol is a family of constructions where a
data structure (B+ tree in this case) uses ORE schemes in-
ternally. Then, we present alternative solutions with varying
performance and security proﬁles, not relying on ORE. Fi-
nally, we introduce two baseline solutions we will use in the
benchmark — one that achieves the best performance and
the other that achieves the maximal security.
4.1 Range query protocol from ORE
So far we have analyzed OPE and ORE schemes without
much context. One of the best uses of an ORE is within a
secure protocol. In this section we provide a construction of
a search protocol built with a B+ tree working on top of an
ORE scheme and analyze its security and performance.
The general idea is to consider some data structure that
is optimized for range queries, and to modify it to change all
comparison operators to ORE scheme’s Cmp calls. This way
the data structure can operate only on ciphertexts. Perfor-
mance overhead would be that of using the ORE scheme’s
Cmp routine instead of a plain comparison. Space overhead
would be that of storing ciphertexts instead of plaintexts.
In this paper, we have implemented a typical B+ tree [3]
(with a proper deletion algorithm [33]) as a data structure.
For protocols, we also analyze the I/O performance and
the communication cost. In particular, we are interested in
the expected number of I/O requests the server would have
made to the secondary storage, and the number and size of
messages parties would have exchanged.
The relative performance of the B+ tree depends only on
the page capacity (the longer the ciphertexts, the smaller
the branching factor). Therefore, the query complexity is
O (logB (N/B) + r/B), where B is the number of records (ci-
phertexts) in a block, N is the number of records (cipher-
texts) in the tree and r is the number of records (ciphertexts)
in the result (none for insertions).
Communication amount of the protocol is relatively small
as its insertions and queries require at most one round trip.
Security. The leakage of this protocol consists of leakage
of the underlying ORE scheme plus whatever information
about insertion order is available in the B+ tree. Please
note that Lewi-Wu [46] ORE is particularly well-suited in
this construction with its left / right framework, because
only the semantically secure side of the ciphertext is stored
in the structure. In this case, the ORE leakage becomes only
the total order and the security of the protocol is comparable
with other non-ORE constructions.
4.2 Kerschbaum-Tueno
Kerschbaum and Tueno [41] proposed a new data struc-
ture, which satisﬁes their own deﬁnitions of security (IND-
CPA-DS) and eﬃciency (search operation has poly-logarith-
mic running time and linear space complexity).
In short, the idea is to maintain a (circular) array of sym-
metrically encrypted ciphertexts in order. On insertion, the
array is rotated around a uniformly sampled oﬀset to hide
the location of the smallest element. Client interactively
performs a binary search requesting an element, decrypting
it and deciding which way to go.
Security. Authors prove that this construction is IND-
CPA-DS secure (deﬁned in the same paper [41]). The deﬁ-
nition assumes an array data structure and therefore serves
speciﬁcally this construction (as opposed to being generic).
It provably hides the frequency due to semantic encryption
and hides the location of the ﬁrst element due to random
rotations. Leakage-wise this construction is strictly bet-
ter than B+ tree with ORE — they both leak total order,
but [41] hides distance information and smallest / largest
elements. Speciﬁcally, for all pairs of consecutive elements
ei and ei+1 it is revealed that ei+1 ≥ ei except for one pair
of smallest and largest elements in the set.
4.2.1 Analysis and implementation challenges
Insertions are I/O-heavy because they involve rotation of
the whole data structure. All records will be read and writ-
ten, thus the complexity is O (N/B). Searches are faster
since they involve logarithmic number of blocks. The ﬁrst
few blocks can be cached and the last substantial number of
requests during the binary search will target a small number
of blocks. The complexity is then O (log2
N/B).
Communication volume is small as well. Insertion requires
log2 N messages from each side. Searches require double
that number because separate protocol is run for both end-
points.
The data structure is linear in size, and the client storage
is always small. Sizes of messages are also small as only a
single ciphertext is usually transferred.
For practitioners we have a few points. The construction
in the original paper [41] contains a typo as m and m(cid:48) must
be swapped in the insertion algorithm. Also, we have found
some rare edge cases; when duplicate elements span over the
modulo, the algorithm may not return the correct answer.
Both inconsistencies can be ﬁxed however. This protocol
is not optimized for I/O operations for insertions, and thus
would be better suited for batch uploads.
4.3 POPE
Roche et al. [58] presented a protocol, direct improve-
ment over mOPE [56], which is especially suitable for large
number of insertions and small number of queries. The con-
struction is heavily based on buﬀer trees [2] to support fast
insertion and lazy sorting.
The idea is to maintain a POPE tree on the server and
have the client manipulate that tree. POPE tree is similar
to B-tree, in that the nodes have multiple children and nodes
are sorted on each level. Each node has an ordered list of
labels of size L and an unbounded unsorted set of encrypted
data called buﬀer. Parameter L controls the list size, the
leaf’s buﬀer size, and the size of client’s working set. The
insertion procedure simply adds an encrypted piece of data
to the root’s buﬀer, thus we do not concentrate on insertion
analysis in this section.
The query procedure is more complex. To answer a query,
the server interacts with the client to split the tree according
to the query endpoints. On a high level, for each endpoint
the buﬀers are cleared (content pushed down to leaves), and
nodes in the paths are split. After that, answering a query
means replying with all ciphertexts in all buﬀers between
the two endpoint leaves.
n2
(cid:16)
(cid:17)
mL logL n − n
The authors provide cost analysis of their construction.
Search operations are expected to require O (logL n) rounds.
It must be noted that the ﬁrst queries will require many
more rounds, since large buﬀers must be sorted.
Security. This construction satisﬁes the security deﬁnition
of frequency-hiding partial order-preserving (FH-POP) pro-
tocol (introduced in the paper [58]). According to [58, The-
orem 3], after n insertions and m queries with local storage
of size L, where mL ∈ o(n), the POPE scheme is frequency-
in-
hiding partial order-preserving with Ω
comparable pairs of elements. Simply put, the construction
leaks pairwise order of a bounded number of elements. Aside
from this, the construction provably hides the frequency (i.e.
equality) of the elements.
4.3.1 Analysis and implementation challenges
In our analysis we count each request-response commu-
nication as a round. This is diﬀerent from [58] where they
use streaming a number of elements as a single round. The
rationale for our approach is that if we allow persistent chan-