1
sc, rc
rc
2 )
Figure 2: Issuer Setup algorithm
Figure 4: Issue protocol
To set up its keys, the issuer runs the randomized ISetup
algorithm displayed in Figure 2. This will generate groups
Apart from the issuer‚Äôs public key, the user‚Äôs input also
includes her state stU = (zU, P, fDB , CU, CredU), which is a
136DB(sk DB, pk DB, pk I) :
Transfer() :
K, fDB
PK{(h) : H = e(g, h)}
If(fDB = 0) then


U (œÉ, stU, pk I, pk DB, ERœÉ, ACLœÉ) :
Parse stU as (zU, P, fDB , CU, CredU)
If ACLœÉ (cid:6)‚äÜ CU then abort
$‚Üê Zp ; K ‚Üê (EœÉ)k
k
Parse ACLœÉ as {c1, . . . , c(cid:3)}
For i = 1, . . . , (cid:2) do
- fDB ‚Üê 1
(cid:2)
ti, t
i
t(cid:2)
$‚Üê Zp ; ÀúAi ‚Üê Aci uti ; Bi ‚Üê vti u
(cid:3)
i
PK
( ÀúAi, Bi)i=1,...,(cid:3)
(cid:9)(cid:2)
e(K, yDB)e(K, g)œÉ (cid:6) (cid:3)
(cid:10) (cid:3)
Bi = vti ut(cid:2)
(cid:2)
œÉ, k, zU, (ci, sci , rci , ti, t
i, Œ±i, Œ≤i)i=1,...,(cid:3)
(cid:11)
i=1 e(K, yi)ci = e(g, g)k
vŒ±i uŒ≤i ‚àß
i ‚àß 1 = B
‚àísci
i=1
i
:
(cid:12)(cid:13)
e( ÀúAi, yI )

e(g1, g1)
L ‚Üê e(h, K)
Return Œµ
‚àísci e(u, yI )ti e(u, g1)Œ±i e(h2, g1)rci e(h0, g1)zU e(h1, g1)ci
= e( ÀúAi, g1)
L, PK{(h) : H = e(g, h) ‚àß L = e(h, K)}- RœÉ ‚Üê BœÉ/(L
1/k)
Return RœÉ
Figure 5: Transfer protocol
tuple containing her master secret, her pseudonym, a bit
fDB indicating whether she already accessed the database,
the set of categories CU to which she currently has access,
and the corresponding credentials CredU. The input of the
issuer contains his secret and public key, the category c for
which the user wants a credential, and the pseudonym P of
the user, if she registered one before.
If the user runs the issuing protocol for the Ô¨Årst time, her
input will contain the empty state (stU = ‚ä•). In this case,
the user Ô¨Årst generates her master secret zU and calculates
her pseudonym P = hzU
0 , sends P to the issuer, and then
initializes her state as stU = (zU, P, 0,‚àÖ,‚àÖ).
As a result of the issuing protocol, the user will obtain an
access credential for the category c ‚àà C . This credential is a
tuple cred c = (Ac, sc, rc) which can be veriÔ¨Åed by checking
e(Ac, gsc
2 , g1). We assume that the user
and the issuer run the issuing protocol for each category for
which the user is allowed to obtain a credential individually.
It is not hard to see how to issue the credentials for all of
the user‚Äôs categories at once.
1 yI) = e(g1P hc
1hrc
We note that credential (Ac, sc, rc) is a signature as de-
Ô¨Åned in Section 3.3 on the set of messages (zU, c), where zU
is the user‚Äôs master secret.
Accessing a Record.
When the user wants to access a record in the database,
she engages in a Transfer protocol (Figure 5) with the
database server.
The input of the database server is her secret and pub-
lic key as well as the public key of the issuer. The input
of the user is the index œÉ of the record that she wants to
access, the encryption ERœÉ = (EœÉ, FœÉ) of that record, the
access control policy of the records, her state (containing all
her credential), and the public keys of the issuer and the
database.
If this is the Ô¨Årst transfer protocol she executes with this
database (i.e., fDB = 0), then the user asks the database
to execute a proof of knowledge of the database secret key
h. This zero-knowledge proof will enable to decrypt the
contents of the database in the security proof.
Then the user randomizes EœÉ and sends this randomized
version K to the database. Note that EœÉ is derived from
the database provider‚Äôs secret key, the index of the records,
and, most importantly all the categories of the record.
Next the user proves that K is correctly formed as a ran-
domization of some Ei for which she possesses all necessary
credentials.
If the database provider accepts the proof, it
computes L from h and K, sends L to the user, and proves
that L was computed correctly.
The protocol is easily seen to be correct by observing that
L = e(h, EœÉ)k, so therefore FœÉ/L
1/k = RœÉ.
5. SECURITY ANALYSIS
The security of our protocol is analyzed by proving indis-
tinguishability between adversary actions in the real proto-
col and in an ideal scenario that is secure by deÔ¨Ånition.
(cid:3)
Given a real-world adversary A, we construct an ideal-
such that no environment E can distin-
world adversary A
(cid:3)
guish whether it is interacting with A or A
. We organize
the proof in sublemmas according to which subset of parties
are corrupted. We do not consider the cases where all par-
ties are honest, where all parties are dishonest, where the
issuer is the only honest party, or where the issuer is the
only dishonest party, as these cases have no real practical
interest.
For each case we prove the indistinguishability between
the real and ideal worlds by deÔ¨Åning a sequence of hybrid
games Game-0, . . . , Game-n.
In each game we deÔ¨Åne a
simulator Simi that runs A as a subroutine and that pro-
vides E‚Äôs entire view. We deÔ¨Åne HybridE,Simi(Œ∫) to be the
probability that E outputs 1 when run in the world provided
by Simi. The games are always constructed such that the
Ô¨Årst simulator Sim0 runs A and all honest parties exactly like
in the real world, so that HybridE,Sim0(Œ∫) = RealE,A(Œ∫) ,
and such that the Ô¨Ånal simulator Simn is easily transformed
(cid:3)
so that HybridE,Simn(Œ∫) =
into an ideal-world adversary A
IdealE,A(cid:2)(Œ∫) . By upper-bounding and summing the mutu-
al game distances HybridE,Simi(Œ∫) ‚àí HybridE,Simi+1(Œ∫) for
i = 0, . . . , n ‚àí 1, we obtain an upper bound for the overall
distance RealE,A(Œ∫) ‚àí IdealE,A(cid:2)(Œ∫) .
137Theorem 5.1. If the (N + 2)-BDHE assumption holds
in G1, GT and the q-SDH assumption holds in G1, then
the AC -OT protocol depicted in Figures 1‚Äì4 securely imple-
ments the AC-OT functionality, where N is the number of
database records, qI is the number of issued credentials, and
q = max(qI, N + 1).
We prove the theorem by separately proving it for all rele-
vant combinations of corrupted parties in the lemmas below.
Lemma 5.2. For all environments E and all real-world
adversaries A controlling the issuer and the database there
exists an ideal-world adversary A
(cid:3)
such that
RealE,A(Œ∫) ‚àí IdealE,A(cid:2)(Œ∫) ‚â§ 2
‚àíŒ∫
Proof. Since the adversary can always simulate addi-
tional users himself, we can simplify the setting to a single
honest user U.
Game-1 : Simulator Sim1, at the Ô¨Årst transfer query dic-
tated by E, runs the extractor for the proof of knowledge
PK{(h) : H = e(g, h)} to extract from A the element h
such that e(g, h) = H. If the extractor fails, then Sim1 out-
puts ‚ä• to E; otherwise, it continues to run A interacting
with the honest user algorithm. The diÔ¨Äerence between the
two games is given by the knowledge error of the proof of
knowledge, i.e.,
HybridE,Sim0(Œ∫) ‚àí HybridE,Sim1(Œ∫) ‚â§ 2
‚àíŒ∫ .
Game-2 : Simulator Sim2 runs exactly like Sim1, except
that during each transfer phase it lets the user algorithm
query a record Rj chosen at random among those for which
it has the necessary credentials, rather than querying œÉi as
imposed by E. We claim that
HybridE,Sim1(Œ∫) = HybridE,Sim2(Œ∫) .
The claim follows from the (perfect) zero-knowledgeness of
the proof of knowledge of (œÉ, k, zU, . . .) [2].
We now construct, based on the real-world adversary A, an
(cid:3)
ideal-world adversary A
that plays the simultaneous roles
of the issuer and the database, and that incorporates all
(cid:3)
steps from the last game. The adversary A
simply relays
all messages between the environment E and A. A
(cid:3)
runs
A to obtain the issuer‚Äôs public key pk I and the encrypted
database EDB = (pk DB, (E1, F1), . . . , (EN , FN )). Upon re-
(cid:3)
ceiving (issue, U
, c) from T, it executes the user‚Äôs side of
the issue protocol with A, maintaining state as necessary.
(cid:3)
If the resulting credential is valid, A
returns b = 1 to T,
otherwise it returns b = 0. The Ô¨Årst time it receives a mes-
(cid:3)
sage transfer from T, A
extracts h from A in the Ô¨Årst
proof of knowledge, uses it to decrypt Ri as Fi/e(h, Ei) for
i = 1, . . . , N and sends (initdb, Ri, ACLi)i=1,...,N to T. It
then simulates an honest user querying for record Rj chosen
at random among those for which it has the necessary cre-
(cid:3)
dentials. If the transfer succeeds, A
sends b = 1 back to T;
if it fails, it sends back b = 0. Later transfer queries are
treated the same way, but without the Ô¨Årst step of decrypt-
ing the database.
One can see that A
provides A with exactly the same
(cid:3)
environment as Sim2 did, so we have
IdealE,A(cid:2)(Œ∫) = HybridE,Sim2(Œ∫) .
Summing up all the above equations yields the lemma state-
ment.
Lemma 5.3. For all environments E and all real-world
adversaries A controlling only the database there exists an
ideal-world adversary A
such that
(cid:3)
RealE,A(Œ∫) ‚àí IdealE,A(cid:2)(Œ∫) ‚â§ 2
‚àíŒ∫
The proof of Lemma 5.3 is almost identical to that of
Lemma 5.2. A full proof is given in the full version [9].
Lemma 5.4. For all environments E and all real-world
adversaries A controlling only some of the users, there exists
(cid:3)
an ideal-world adversary A
RealE,A(Œ∫) ‚àí IdealE,A(cid:2)(Œ∫) ‚â§ 2
such that
‚àíŒ∫ ¬∑ qT + AdvqI-SDH
(Œ∫) + (N + 1) ¬∑ Adv(N+2)BDHE
+ Adv(N+1)SDH
G1
(Œ∫) ,
(Œ∫)
G1,GT
G1
where qT is the total number of transfer queries, qI the num-
ber of issue queries, and N the number of records in the
database.
Proof. Since the AC-OT functionality prevents users
from pooling their credentials, we have to consider multi-
ple users here, some of which are corrupted, and some of
which are honest.
(cid:3)
, k, {cred
Game-1 : Simulator Sim1, at each transfer query by a cor-
rupted user dictated by E, runs the extractor for the proof
of knowledge PK{(œÉ, k, zU, . . .)} to extract from A the wit-
(cid:3)}). If the extractor fails, then Sim1
ness (œÉ
outputs ‚ä• to E; otherwise, it continues to run A interacting
with the honest database algorithm. The diÔ¨Äerence between
the two games is given by t times the knowledge error of the
proof of knowledge, i.e.,
c(cid:2)},{c
(cid:3)
HybridE,Sim0(Œ∫) ‚àí HybridE,Sim1(Œ∫) ‚â§ 2
‚àíŒ∫ ¬∑ t .
Note that the time required to execute these t extractions
is t times the time of doing a single extraction, because the
transfer protocols can only run sequentially, rather than con-
currently.
(cid:3)
Game-2 - Simulator Sim2 runs exactly like Sim1, except
that Sim2 outputs ‚ä• to E, if at least one of the extracted
values {cred
c(cid:2)} was not issued during any of the Issue proto-
cols. One can see that in this case Ac(cid:2) is a forged credential
(cid:3)
signature on c
. Note that this also includes the case that
corrupted users manage to pool their credentials. Since only
a single value zU is extracted, one of the pooled credentials
must have a diÔ¨Äerent zU value than when it was issue, and
hence must be a forged credential. The diÔ¨Äerence between
Game-1 and Game-2 is bounded by the following claim:
Claim 5.5. We have that
HybridE,Sim1(Œ∫) ‚àí HybridE,Sim2(Œ∫) ‚â§ AdvqI-SDH
It is obvious that if the extracted credentials were not legal-
ly issued then adversary A broke the credential signature
scheme. By the security proof given in [2], this directly gives
rise to an expected polynomial-time adversary with non-
negligible advantage in solving the qI-SDH problem, where
qI is the number issue queries made by the adversary.
(Œ∫) ,
G1
Game-3 - Simulator Sim3 runs exactly like Sim2, except
that Sim3 outputs ‚ä• to E, if the extracted number of the
(cid:3) (cid:7)‚àà {1, . . . , N} or the extracted set of categories {c
(cid:3)}
record œÉ
(cid:3)
does not match ACL