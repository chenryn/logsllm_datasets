1
sc, rc
rc
2 )
Figure 2: Issuer Setup algorithm
Figure 4: Issue protocol
To set up its keys, the issuer runs the randomized ISetup
algorithm displayed in Figure 2. This will generate groups
Apart from the issuer’s public key, the user’s input also
includes her state stU = (zU, P, fDB , CU, CredU), which is a
136DB(sk DB, pk DB, pk I) :
Transfer() :
K, fDB
PK{(h) : H = e(g, h)}
If(fDB = 0) then


U (σ, stU, pk I, pk DB, ERσ, ACLσ) :
Parse stU as (zU, P, fDB , CU, CredU)
If ACLσ (cid:6)⊆ CU then abort
$← Zp ; K ← (Eσ)k
k
Parse ACLσ as {c1, . . . , c(cid:3)}
For i = 1, . . . , (cid:2) do
- fDB ← 1
(cid:2)
ti, t
i
t(cid:2)
$← Zp ; ˜Ai ← Aci uti ; Bi ← vti u
(cid:3)
i
PK
( ˜Ai, Bi)i=1,...,(cid:3)
(cid:9)(cid:2)
e(K, yDB)e(K, g)σ (cid:6) (cid:3)
(cid:10) (cid:3)
Bi = vti ut(cid:2)
(cid:2)
σ, k, zU, (ci, sci , rci , ti, t
i, αi, βi)i=1,...,(cid:3)
(cid:11)
i=1 e(K, yi)ci = e(g, g)k
vαi uβi ∧
i ∧ 1 = B
−sci
i=1
i
:
(cid:12)(cid:13)
e( ˜Ai, yI )

e(g1, g1)
L ← e(h, K)
Return ε
−sci e(u, yI )ti e(u, g1)αi e(h2, g1)rci e(h0, g1)zU e(h1, g1)ci
= e( ˜Ai, g1)
L, PK{(h) : H = e(g, h) ∧ L = e(h, K)}- Rσ ← Bσ/(L
1/k)
Return Rσ
Figure 5: Transfer protocol
tuple containing her master secret, her pseudonym, a bit
fDB indicating whether she already accessed the database,
the set of categories CU to which she currently has access,
and the corresponding credentials CredU. The input of the
issuer contains his secret and public key, the category c for
which the user wants a credential, and the pseudonym P of
the user, if she registered one before.
If the user runs the issuing protocol for the ﬁrst time, her
input will contain the empty state (stU = ⊥). In this case,
the user ﬁrst generates her master secret zU and calculates
her pseudonym P = hzU
0 , sends P to the issuer, and then
initializes her state as stU = (zU, P, 0,∅,∅).
As a result of the issuing protocol, the user will obtain an
access credential for the category c ∈ C . This credential is a
tuple cred c = (Ac, sc, rc) which can be veriﬁed by checking
e(Ac, gsc
2 , g1). We assume that the user
and the issuer run the issuing protocol for each category for
which the user is allowed to obtain a credential individually.
It is not hard to see how to issue the credentials for all of
the user’s categories at once.
1 yI) = e(g1P hc
1hrc
We note that credential (Ac, sc, rc) is a signature as de-
ﬁned in Section 3.3 on the set of messages (zU, c), where zU
is the user’s master secret.
Accessing a Record.
When the user wants to access a record in the database,
she engages in a Transfer protocol (Figure 5) with the
database server.
The input of the database server is her secret and pub-
lic key as well as the public key of the issuer. The input
of the user is the index σ of the record that she wants to
access, the encryption ERσ = (Eσ, Fσ) of that record, the
access control policy of the records, her state (containing all
her credential), and the public keys of the issuer and the
database.
If this is the ﬁrst transfer protocol she executes with this
database (i.e., fDB = 0), then the user asks the database
to execute a proof of knowledge of the database secret key
h. This zero-knowledge proof will enable to decrypt the
contents of the database in the security proof.
Then the user randomizes Eσ and sends this randomized
version K to the database. Note that Eσ is derived from
the database provider’s secret key, the index of the records,
and, most importantly all the categories of the record.
Next the user proves that K is correctly formed as a ran-
domization of some Ei for which she possesses all necessary
credentials.
If the database provider accepts the proof, it
computes L from h and K, sends L to the user, and proves
that L was computed correctly.
The protocol is easily seen to be correct by observing that
L = e(h, Eσ)k, so therefore Fσ/L
1/k = Rσ.
5. SECURITY ANALYSIS
The security of our protocol is analyzed by proving indis-
tinguishability between adversary actions in the real proto-
col and in an ideal scenario that is secure by deﬁnition.
(cid:3)
Given a real-world adversary A, we construct an ideal-
such that no environment E can distin-
world adversary A
(cid:3)
guish whether it is interacting with A or A
. We organize
the proof in sublemmas according to which subset of parties
are corrupted. We do not consider the cases where all par-
ties are honest, where all parties are dishonest, where the
issuer is the only honest party, or where the issuer is the
only dishonest party, as these cases have no real practical
interest.
For each case we prove the indistinguishability between
the real and ideal worlds by deﬁning a sequence of hybrid
games Game-0, . . . , Game-n.
In each game we deﬁne a
simulator Simi that runs A as a subroutine and that pro-
vides E’s entire view. We deﬁne HybridE,Simi(κ) to be the
probability that E outputs 1 when run in the world provided
by Simi. The games are always constructed such that the
ﬁrst simulator Sim0 runs A and all honest parties exactly like
in the real world, so that HybridE,Sim0(κ) = RealE,A(κ) ,
and such that the ﬁnal simulator Simn is easily transformed
(cid:3)
so that HybridE,Simn(κ) =
into an ideal-world adversary A
IdealE,A(cid:2)(κ) . By upper-bounding and summing the mutu-
al game distances HybridE,Simi(κ) − HybridE,Simi+1(κ) for
i = 0, . . . , n − 1, we obtain an upper bound for the overall
distance RealE,A(κ) − IdealE,A(cid:2)(κ) .
137Theorem 5.1. If the (N + 2)-BDHE assumption holds
in G1, GT and the q-SDH assumption holds in G1, then
the AC -OT protocol depicted in Figures 1–4 securely imple-
ments the AC-OT functionality, where N is the number of
database records, qI is the number of issued credentials, and
q = max(qI, N + 1).
We prove the theorem by separately proving it for all rele-
vant combinations of corrupted parties in the lemmas below.
Lemma 5.2. For all environments E and all real-world
adversaries A controlling the issuer and the database there
exists an ideal-world adversary A
(cid:3)
such that
RealE,A(κ) − IdealE,A(cid:2)(κ) ≤ 2
−κ
Proof. Since the adversary can always simulate addi-
tional users himself, we can simplify the setting to a single
honest user U.
Game-1 : Simulator Sim1, at the ﬁrst transfer query dic-
tated by E, runs the extractor for the proof of knowledge
PK{(h) : H = e(g, h)} to extract from A the element h
such that e(g, h) = H. If the extractor fails, then Sim1 out-
puts ⊥ to E; otherwise, it continues to run A interacting
with the honest user algorithm. The diﬀerence between the
two games is given by the knowledge error of the proof of
knowledge, i.e.,
HybridE,Sim0(κ) − HybridE,Sim1(κ) ≤ 2
−κ .
Game-2 : Simulator Sim2 runs exactly like Sim1, except
that during each transfer phase it lets the user algorithm
query a record Rj chosen at random among those for which
it has the necessary credentials, rather than querying σi as
imposed by E. We claim that
HybridE,Sim1(κ) = HybridE,Sim2(κ) .
The claim follows from the (perfect) zero-knowledgeness of
the proof of knowledge of (σ, k, zU, . . .) [2].
We now construct, based on the real-world adversary A, an
(cid:3)
ideal-world adversary A
that plays the simultaneous roles
of the issuer and the database, and that incorporates all
(cid:3)
steps from the last game. The adversary A
simply relays
all messages between the environment E and A. A
(cid:3)
runs
A to obtain the issuer’s public key pk I and the encrypted
database EDB = (pk DB, (E1, F1), . . . , (EN , FN )). Upon re-
(cid:3)
ceiving (issue, U
, c) from T, it executes the user’s side of
the issue protocol with A, maintaining state as necessary.
(cid:3)
If the resulting credential is valid, A
returns b = 1 to T,
otherwise it returns b = 0. The ﬁrst time it receives a mes-
(cid:3)
sage transfer from T, A
extracts h from A in the ﬁrst
proof of knowledge, uses it to decrypt Ri as Fi/e(h, Ei) for
i = 1, . . . , N and sends (initdb, Ri, ACLi)i=1,...,N to T. It
then simulates an honest user querying for record Rj chosen
at random among those for which it has the necessary cre-
(cid:3)
dentials. If the transfer succeeds, A
sends b = 1 back to T;
if it fails, it sends back b = 0. Later transfer queries are
treated the same way, but without the ﬁrst step of decrypt-
ing the database.
One can see that A
provides A with exactly the same
(cid:3)
environment as Sim2 did, so we have
IdealE,A(cid:2)(κ) = HybridE,Sim2(κ) .
Summing up all the above equations yields the lemma state-
ment.
Lemma 5.3. For all environments E and all real-world
adversaries A controlling only the database there exists an
ideal-world adversary A
such that
(cid:3)
RealE,A(κ) − IdealE,A(cid:2)(κ) ≤ 2
−κ
The proof of Lemma 5.3 is almost identical to that of
Lemma 5.2. A full proof is given in the full version [9].
Lemma 5.4. For all environments E and all real-world
adversaries A controlling only some of the users, there exists
(cid:3)
an ideal-world adversary A
RealE,A(κ) − IdealE,A(cid:2)(κ) ≤ 2
such that
−κ · qT + AdvqI-SDH
(κ) + (N + 1) · Adv(N+2)BDHE
+ Adv(N+1)SDH
G1
(κ) ,
(κ)
G1,GT
G1
where qT is the total number of transfer queries, qI the num-
ber of issue queries, and N the number of records in the
database.
Proof. Since the AC-OT functionality prevents users
from pooling their credentials, we have to consider multi-
ple users here, some of which are corrupted, and some of
which are honest.
(cid:3)
, k, {cred
Game-1 : Simulator Sim1, at each transfer query by a cor-
rupted user dictated by E, runs the extractor for the proof
of knowledge PK{(σ, k, zU, . . .)} to extract from A the wit-
(cid:3)}). If the extractor fails, then Sim1
ness (σ
outputs ⊥ to E; otherwise, it continues to run A interacting
with the honest database algorithm. The diﬀerence between
the two games is given by t times the knowledge error of the
proof of knowledge, i.e.,
c(cid:2)},{c
(cid:3)
HybridE,Sim0(κ) − HybridE,Sim1(κ) ≤ 2
−κ · t .
Note that the time required to execute these t extractions
is t times the time of doing a single extraction, because the
transfer protocols can only run sequentially, rather than con-
currently.
(cid:3)
Game-2 - Simulator Sim2 runs exactly like Sim1, except
that Sim2 outputs ⊥ to E, if at least one of the extracted
values {cred
c(cid:2)} was not issued during any of the Issue proto-
cols. One can see that in this case Ac(cid:2) is a forged credential
(cid:3)
signature on c
. Note that this also includes the case that
corrupted users manage to pool their credentials. Since only
a single value zU is extracted, one of the pooled credentials
must have a diﬀerent zU value than when it was issue, and
hence must be a forged credential. The diﬀerence between
Game-1 and Game-2 is bounded by the following claim:
Claim 5.5. We have that
HybridE,Sim1(κ) − HybridE,Sim2(κ) ≤ AdvqI-SDH
It is obvious that if the extracted credentials were not legal-
ly issued then adversary A broke the credential signature
scheme. By the security proof given in [2], this directly gives
rise to an expected polynomial-time adversary with non-
negligible advantage in solving the qI-SDH problem, where
qI is the number issue queries made by the adversary.
(κ) ,
G1
Game-3 - Simulator Sim3 runs exactly like Sim2, except
that Sim3 outputs ⊥ to E, if the extracted number of the
(cid:3) (cid:7)∈ {1, . . . , N} or the extracted set of categories {c
(cid:3)}
record σ
(cid:3)
does not match ACL