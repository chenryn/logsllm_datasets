Here is the code for `get_encodings_from_content` in the requests.utils
module:
    def get_encodings_from_content(content):
        """Returns encodings from given content string.
        :param content: bytestring to extract encodings from.
        """
        charset_re = re.compile(r']', flags=re.I)
        pragma_re = re.compile(r']', flags=re.I)
        xml_re = re.compile(r'^]')
        return (charset_re.findall(content) +
                pragma_re.findall(content) +
                xml_re.findall(content))
Is there any reason to recompile the regexes on every call rather than making
them module-level constants?
More fundamentally, wouldn't it be more useful to have a function that just
returned the first match, rather than a tuple of all matches, and therefore
could often stop processing the input after a few lines, rather than always
having to do three passes through the entire thing? That way, if you're
fetching a large html document using `stream=True` from a server that may not
have sent the charset in a Content-Type header, we can write:
    encoding = get_encoding_from_headers(res.headers) or \
        get_encoding_from_content(raw)  # just get the first encoding declared in content, if any
which is all we care about.
(Assume `raw` has been set already with something like:
    bio = BytesIO()
    bytesread = 0
    for chunk in res.iter_content(chunk_size=CHUNK_SIZE):
        bio.write(chunk)
        bytesread += len(chunk)
        if bytesread > RES_MAX_BYTES:
            return _too_big()
    raw = bio.getvalue()
)