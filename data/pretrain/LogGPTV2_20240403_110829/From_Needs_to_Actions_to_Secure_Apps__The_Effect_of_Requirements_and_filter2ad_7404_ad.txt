“fewer security defects” against the four independent “need 
and mechanisms for security and privacy” scores. Non-italic 
figures highlighted in yellow indicate a statistically signifi-
cant result (p<0.01) 
Table 2: Pearson R Results (R, P) Correlating App Security Measurements with Developer-based Factors  
Independent: 
Expertise Support 
Requirements 
USENIX Association
29th USENIX Security Symposium    299
Dependent: 
Cryptographic API Misuse 
Privacy Leak 
SSL Security 
-0.17, 0.016 
-0.09, 0.20 
-0.14, 0.049 
-0.06, 0.37 
-0.01, 0.85 
0.01, 0.93 
Developer  
Knowledge 
-0.09, 0.17 
0.02, 0.81 
-0.02, 0.76 
Assurance  
Technique Use 
-0.13, 0.047 
0.02, 0.81 
-0.08, 0.20 
Figure 6 shows that more than 60% of the respondents con-
sider security to be very or extremely important to their users, 
and even more put the same value on privacy.  
Section 5.2’s combinations of assurance techniques used are 
particularly interesting in suggesting how security improve-
ment is happening. Though the analysis only covers a small 
fraction of the total population, those respondents it considers 
are the ones using only a proportion of the Assurance Tech-
niques and it therefore offers an insight into which techniques 
are adopted first. One would expect teams whose security is 
driven  by  external  experts  to  adopt  the  Threat  Assess-
ment/Penetration Test combination, since both of these activ-
ities can be carried out by the experts themselves; actually, 
rather more adopt tool-only techniques (Auto. Static Analysis 
and  Config.  Review),  or  code-review  based  techniques 
(Auto. Static Analysis and Code Review), perhaps because 
few have access to security experts (Section 5.2). 
This suggests that the adoption of assurance techniques is be-
ing driven by the developers themselves, rather than by ex-
ternal security experts, and so what we are seeing is devel-
oper-led security. This tallies with the reasons given for app 
security changes in Figure 11, where the most common rea-
son for changes was developer initiative. It also corresponds 
to  the  views  of  security  experts,  who  emphasize  the  im-
portance of developer initiative in improving software secu-
rity [53]. 
6.2. Appropriate Use of Security Techniques 
Using security assurance techniques usually has a cost, both 
in time and in financial terms [45], and therefore it is poor 
economics to adopt them in cases where they are not required. 
From Table 1 we see that this is correctly reflected in the An-
droid ecosystem: the use of Assurance Techniques increases 
in line with the importance of security for the app. We sug-
gest that the correlation with the involvement of security pro-
fessionals/champions and with developer knowledge of secu-
rity may be an effect (expert developers and security profes-
sionals will tend to work on products that need security) as 
much as a cause (their involvement causes increased assur-
ance technique use). 
Updating  apps  also  has  a  considerable  cost,  and  again  we 
would anticipate having more security updates in cases where 
security is important for the app. Again Table 1 confirms this 
behavior, and shows that, justifiably, there is no correlation 
between the security update frequency and the security expe-
rience of the developer.  
6.3. Impact on Real App Security 
It was disappointing that the use of assurance techniques did 
not appear to be a major factor leading to better security out-
comes when we analyzed the apps themselves. Even though 
the analysis tools can only detect a limited range of code level 
security  issues,  we  expected  more  security-experienced 
Figure 14: Worse Cryptosecurity with Expert Involvement? 
Only one result achieves significance and bizarrely that result 
suggests a negative correlation: the involvement of security 
professionals and champions is associated with worse Cryp-
tographic API misuse outcomes. 
Figure 14 explores this odd finding. It shows that the effect is 
not large, and that both experts and champions seem to be 
associated with the negative correlation, though experts more 
so. We note, as well, that the p-value is only just significant 
given the Bonferroni correction (Threshold for significance 
0.05/3 = 0.017).  
Disappointingly, use of assurance techniques was not associ-
ated with better security outcomes, nor was developer secu-
rity knowledge, nor was a user requirement for good security. 
6. Discussion 
At first sight, the findings in Sections 5.6 and 5.7 give a de-
pressing view of app security. From Section 5.6 we see that 
over  80%  of  apps  had  reported  defects  from  our  analysis 
tools. From Figure 10 we see that the majority of apps get 
security updates less than once a year. From the analysis of 
the app security measurements, Table 2 shows that security 
outcomes seem to have little correlation with an app’s per-
ceived need for security and privacy.  
And Figure 12 shows that GDPR’s new compliance rules for 
apps have had little real positive impact. Certainly, in many 
cases cosmetic changes may have been all that was needed; 
but  the  finding  suggests  that  GDPR  has  not  been  a  strong 
force to improve app security and privacy.  
6.1. Adoption of Security Techniques by Developers 
However, there are positive aspects too. Considering the find-
ings in Section 5.2, Figure 7 shows us that the vast majority 
of the respondents consider themselves to have at least some 
security knowledge, and thus are likely to be aware of secu-
rity as a possible issue in their software development. Indeed, 
300    29th USENIX Security Symposium
USENIX Association
developers and those using assurance techniques—especially 
Static Code Analysis—to generate fewer such issues.  
We conclude that other factors must drown out this effect. 
We observe, for example, that most app binary code will con-
sist of libraries, and even up-to-date libraries will differ enor-
mously in the number of such issues they may have. We hy-
pothesize that the scores generated by the tools we used de-
pend more on the nature of the libraries needed to implement 
the app functionality than on any attributes of the non-library 
code created by the developers; current tools cannot verify 
this effect (Section 4.5).  
More surprising is the finding that the involvement of profes-
sionals and champions seems to be associated with increased 
numbers of Cryptographic API issues. It seems unlikely that 
this is because they create the issues. Instead, we observe that 
our tools will not detect a failure to use cryptography in apps 
where it is required, whereas experts or champions will do so. 
We suggest that teams involving experts or champions will 
therefore tend to use cryptography more frequently, leading 
to more such issues. 
7. Summary and Conclusions 
This paper describes the creation and deployment of a survey 
to Android app developers, in which we asked them a range 
of questions related to their approach to security and privacy 
in app development; and a second phase in which we com-
pared the answers with the outcomes of running security anal-
ysis tools on one of their apps. The research addresses the 
questions as follows: 
RQ1: To what extent, and how, does a perceived need for 
security and privacy lead to security-enhancing activities and 
interactions in the development team? 
From the 335 survey responses analyzed, we found a high 
level of reported security need for the app development, but 
less use of practical security assurance techniques (Section 
5.2). Where such techniques were used, this was in propor-
tion to the perceived need, as was the involvement of profes-
sionals and security champions. The frequency of app secu-
rity updates followed a similar pattern (Sections 5.4, 6.2).  
Considering the “how” of RQ1: in the perception of respond-
ents to the survey, app security improvements have been pre-
dominantly driven by developers themselves (Section 6.1); 
this is supported by the observation that the assurance tech-
niques first adopted are those most easily available to devel-
opers. GDPR has also had an impact, though the resulting 
changes for GDPR have been mainly cosmetic (Section 5.3). 
RQ2: To what extent do the need for security, the involve-
ment of specialist roles, and the use of assurance techniques 
in a development team lead to fewer security defects? 
The results of the app analysis showed little relationship with 
the reported security drivers and development process from 
the survey; we believe this reflects the inability of the current 
generation of binary analysis tools to analyze libraries effec-
tively and separately from the main app code. We did how-
ever find the involvement of security specialists or champi-
ons  to  be  associated  with  more  Cryptographic  API  issues, 
probably since they correctly enforce much more Cryptog-
raphy use (Sections 5.7, 6.3) 
RQ3 What proportion of Android developers have access to 
security experts? 
Section 5.2 concludes that between 14% and 22% of devel-
opers work with security experts. 
RQ4 To what extent do Android developers actually use as-
surance techniques? 
Only between 22% and 30% regularly use assurance tech-
niques (Section 5.2) 
Further, contrasting the high need for security with the low 
use of assurance techniques and low availability of security 
professionals,  we  suggest  that  there  is  an  urgent  need  for 
ways to support app developers in adopting security assur-
ance techniques in the absence of security professionals.  
7.1. Future Work 
As Section 6.3 discusses, we need binary analysis tools capa-
ble of: 
1.  Detecting library versions 
2.  Performing  static  analysis  on  library  components 
separately from the main code.  
This is an active area of research; once such tools are availa-
ble, a further survey using these will provide both valuable 
results, and an indication of changes over time in Android 
developer security practices. 
More information is also needed to support developers in us-
ing these assurance techniques, starting with how developers 
currently  use  each  one.  Specific  questions  might  address 
where developers go to get security advice; what tools they 
use to analyze their code; the methods they use for library 
analysis; how they approach penetration testing; what forms 
of code review they use; and how they tackle threat assess-
ment. A further online survey can investigate these questions. 
7.2. Notes and Credits 
A privacy-preserving set of the survey data, along with the 
full questions and data description, is available online [52] 
First, we thank Christian Stransky of LU Hannover for ob-
taining the Google Play data and APK files used as a basis 
for the survey; and Dominik Wermke of LU Hannover for 
USENIX Association
29th USENIX Security Symposium    301
initiating the use of Python and Jupyter notebooks for statis-
tical analysis in this project. 
We thank Dr Tamara Lopez of the Open University, UK, for 
her helpful review of the survey questionnaire; Dr Yasemin 
Acar, of LU Hannover for practical guidance on creating and 
validating questionnaires; and Professor Ian White, of UCL, 
UK, for valuable advice on the statistical analysis. 
We also thank the eight anonymous reviewers of this and an 
earlier version of this paper, who have all contributed signif-
icantly; and particularly USENIX shepherd Professor Daniel 
Zappala of Brigham Young University. 
This  research  was  partially  funded  by  the  Deutsche  For-
schungsgemeinschaft (DFG, German Research Foundation) 
under Germany's Excellence Strategy - EXC 2092 CASA – 
390781972). 
8. References 
[1]  Acar, Y., Backes, M., Fahl, S., et al. Comparing the 
Usability of Cryptographic Apis. 2017 IEEE 
Symposium on Security and Privacy (SP), IEEE 
(2017), 154–171. 
[2]  Acar, Y., Backes, M., Fahl, S., Kim, D., Mazurek, 
M.L., and Stransky, C. You Get Where You’re 
Looking For: The Impact of Information Sources on 
Code Security. IEEE Symposium on Security and 
Privacy, (2016), 289–305. 
[3]  Anscombe, F.J. The Transformation of Poisson, 
Binomial and Negative-Binomial Data. Biometrika 35, 
3/4 (1948), 246. 
[4]  Arzt, S., Rasthofer, S., Fritz, C., et al. FlowDroid: 
Precise Context, Flow, Field, Object-sensitive and 
Lifecycle-aware Taint Analysis for Android Apps. 
Proceedings of the 35th ACM SIGPLAN Conference 
on Programming Language Design and 
Implementation, (2014). 
[5]  Assal, H. and Chiasson, S. Think Secure From the 
Beginning: A Survey With Software Developers. 
Conference on Human Factors in Computing Systems 
(CHI), (2019). 
[6]  Backes, M., Bugiel, S., and Derr, E. Reliable Third-
Party Library Detection in Android and Its Security 
Applications. Proceedings of the ACM Conference on 
Computer and Communications Security, (2016), 356–
367. 
[7]  Bai, J., Wang, W., Qin, Y., Zhang, S., Wang, J., and 
Pan, Y. BridgeTaint: A Bi-Directional Dynamic Taint 
Tracking Method for JavaScript Bridges in Android 
Hybrid Applications. IEEE Transactions on 
Information Forensics and Security 14, 3 (2019), 677–
692. 
[8]  Becker, I., Parkin, S., and Sasse, M.A. Finding 
Security Champions in Blends of Organisational 
Culture. Proceedings 2nd European Workshop on 
Usable Security, (2017). 
[9]  Bell, L., Brunton-Spall, M., Smith, R., and Bird, J. 
Agile Application Security: Enabling Security in a 
Continuous Delivery Pipeline. O’Reilly, Sebastopol, 
CA, 2017. 
[10]  Caputo, D.D., Pfleeger, S.L., Sasse, M.A., Ammann, 
P., Offutt, J., and Deng, L. Barriers to Usable 
Security? Three Organizational Case Studies. IEEE 
Security and Privacy 14, 5 (2016), 22–32. 
[11]  CONSORT. Checklist of Information to Include When 
Reporting a Randomized Trial. 2010, 11–12. 
http://www.consort-statement.org/consort-2010. 
[12]  Coopamootoo, K.P.L. and Gross, T. A Codebook for 
Evidence-Based Research: The Nifty Nine 
Completeness Indicators. Newcastle, 2017. 
[13]  Date, S. The F-Test for Regression Analysis - Towards 
Data Science. https://towardsdatascience.com/fisher-
test-for-regression-analysis-1e1687867259. 
[14]  Deborah J. Rumsey. Statistics Essentials For 
Dummies. Wiley, For Dummies, 2019. 
[15]  Derr, E., Bugiel, S., Fahl, S., Acar, Y., and Backes, M. 
Keep Me Updated: An Empirical Study of Third-Party 
Library Updatability on Android. Proceedings of the 
2017 ACM SIGSAC Conference on Computer and 
Communications Security - CCS ’17, ACM Press 
(2017), 2187–2200. 
[16]  Egelman, S. and Peer, E. Scaling the Security Wall : 
Developing a Security Behavior Intentions Scale 
(SeBIS). Conference on Human Factors in Computing 
Systems (CHI2015), (2015). 
[17]  Eichberg, M. and Hermann, B. A Software Product 
Line for Static Analyses: The OPAL Framework. 
Proceedings of the ACM SIGPLAN Conference on 
Programming Language Design and Implementation 
(PLDI) 2014-June, June (2014). 
[18]  Enck, W., Octeau, D., McDaniel, P., and Chaudhuri, S. 
A Study of Android Application Security. Proceedings 
of the 20th USENIX conference on Security, (2011). 
[19]  European Commission. General Data Protection 
Regulation (GDPR). 2019. 
https://ec.europa.eu/info/law/law-topic/data-
protection_en. 
[20]  Fahl, S., Harbach, M., Muders, T., Smith, M., 
Baumgärtner, L., and Freisleben, B. Why Eve and 
Mallory Love Android: An Analysis of Android SSL 
Security Categories and Subject Descriptors. 
Proceedings of the 2012 ACM conference on 
Computer and communications security - CCS ’12, 
ACM Press (2012). 
[21]  Fowler, F.J. Survey Research Methods. Sage. 
[22]  Glanz, L., Amann, S., Eichberg, M., et al. CodeMatch: 
Obfuscation Won’t Conceal Your Repackaged App. 
Proceedings of ESEC/FSE’17, (2017), 638–648. 
302    29th USENIX Security Symposium
USENIX Association
[23]  Haney, J.M. and Lutters, W.G. The Work of 
Cybersecurity Advocates. Proceedings of the 2017 
CHI Conference Extended Abstracts on Human 
Factors in Computing Systems - CHI EA ’17, ACM 
Press (2017), 1663–1670. 
[24]  Kline, T. Classical Test Theory: Assumptions, 
Equations, Limitations, and Item Analyses. In 