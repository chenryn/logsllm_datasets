used by individuals. Indeed, even in novel environments, where people have minimal informa-
tion on how different information affects outcome, they seem to develop strong preferences
over time (see coherent arbitrariness [56]). They may, nonetheless, prefer TRI due to social
convention (i.e. they use it because others seem to use it [57] or because they are accustomed
to relying on it [58]).
Lastly, the literature argues that TRI serves to reduce the uncertainty experienced in SE
environments [3,40]. However, across all studies users’ decision confidence was found to be
stable and overall high, regardless of the amount or type of TRI presented. The data favors our
interpretation that TRI produces a “positivity effect” on user judgement, rather than an
“uncertainty-reduction effect” (cf. [59]).
As a possible limitation to our findings and their implications (see next Section), it is worth-
while to remember that our research was an initial exploration into user judgment in the SE.
In order to minimize spurious effects from extraneous variables a number of controls, detailed
in the Methods Sections, were implemented in constructing our SE platform, while still main-
taining ecological validity with respect to its real-world counterparts. Yet, it can be argued that
our study used incentives that were hypothetical (i.e., lower than those in real-life) rather than
salient (i.e., comparable to those in real life). Is this likely to have mattered?
PLOS ONE | https://doi.org/10.1371/journal.pone.0209071 December 13, 2018
11 / 18
Digital Identity and user judgment
Within the literature on human judgment (across multiple fields; psychology, decision-mak-
ing, economics, etc.) the role of stakes (or motivation/incentive/rewards) has been found to be
rather complex. For instance, Camerer and Hogarth [60] reviewed 74 studies where incentives
were manipulated. The modal finding of their analysis was that incentives had no effect on mean
performance but affected performance variance instead. In 15 of the studies, there was no perfor-
mance standard but, in eight of them, higher incentives made participants more risk-averse. Holt
and Laury [61] similarly showed how the same task can result in different decision-making behav-
ior based on the stakes surrounding the task. In cases with performance standards, Camerer and
Hogarth found very mixed evidence: 27 studies showed no effect of incentives, 23 showed they
facilitated performance, and nine showed they impaired performance. Incentives helped when
better performance could be achieved by applying greater effort: such tasks include those that
involve memory recall (e.g., Kahneman & Peavler, [62]), binary choice, easy problem solving, and
simple clerical tasks. Conversely, incentives can have a detrimental effect on complex tasks (as
demonstrated by research on “choking under pressure”). Financial incentives also have no effect
when a task is very easy to perform well (ceiling effects), when it is very hard to improve perfor-
mance (floor effects), and when the intrinsic rewards from participating in the task are already
high. Many sequential bargaining and game-theoretical tasks come into these categories.
This begs the question: which category does our study fall within? If we consider the study
to be without a performance standard, the research mentioned above suggests that people
would be more risk-averse in their choices if they were more consequential (as in a real-life
scenario). However, we have no way of determining whether our participants were making
risk-seeking choices in the first place. If we consider a higher selection of properties offered by
more trustworthy hosts as an indication of higher performance, it is unlikely on the basis of
Camerer and Hogarth’s [60] conclusions that higher incentives would have changed this. Our
task was complex, but it did not involve memory, and while participating in it provided some
intrinsic rewards, participants were not rewarded/penalized based on outcome.
Implications
Decision-making in an online P2P environment can be a complex task. This process is com-
pounded by issues with the information provided to users to aid in their decision-making that
exist in the SE, two central ones being the overall positivity of such information and, consequently,
its low diagnosticity [4,25]. Indeed, ratings on SE platforms show a stronger bias towards high rat-
ings than on other P2P platforms [4,47], which severely reduces their usefulness to users.
Despite this, there is a trend for increased UGC on online platforms. Users seem more will-
ing to provide such information, even when private and potentially identifying, and platforms
themselves are incentivizing this type of information-sharing [63]. But, our data show that
more of such information may not assist people in any meaningful way, which in turn suggests
that both platforms and their users gain no benefit from collecting and sharing more informa-
tion than is currently available. However, these considerations do not necessarily imply that
limiting the proliferation of UGC would have no consequence.
First, research finds that users trust UGC more than objective metrics when making their
decisions, and carry more weight in the decision-making process than other forms of informa-
tion [30,64]. This is supported by the current data, finding that users show a preference for
selecting elements that result from the aggregate ratings or other users’ testimonials (e.g., guest
reviews), compared to platform-generated information (e.g., host verification).
Second, attempting to reduce the amount of TRI from existing or emerging platforms may
backfire in terms of user perception. Users may expect specific information to be present (even
if not used), with its absence leading to more negative appraisals or to avoidance [65].
PLOS ONE | https://doi.org/10.1371/journal.pone.0209071 December 13, 2018
12 / 18
Digital Identity and user judgment
Past research has argued that reputation systems and user-generated reviews may have the
primary purpose of allowing users to learn more about each other before engaging in any
interactions or transactions, acting as a monitoring and policing system [5,66,67]. However,
the current findings demonstrate that this information can also act as a strong influencer in
the perceptions of others, leading users to see peers in a more positive light.
A consideration that emerges from the current findings relates to the concept of online pri-
vacy and how people construct their digital identity. A culture of information-sharing is form-
ing, under the guise of more informed decision-making, which may force individuals wanting
to participate in these communities to share private and sensitive information without any
benefit to the community or individual decision-making outcomes. The current data show it is
unnecessary for users, beyond a certain point, to provide such information, and may even
prove detrimental in the long run. In this respect, we advise caution in how SE platforms
choose to expand and implement their reputation-based systems.
Future directions
As it has been argued [47], the current “5-for-5” culture in ratings drastically reduces the over-
all diagnosticity of TRI in favor of social cohesion and community participation. This moti-
vated our choice to limit the variance in the TRI shown to users to reflect real-world data (see
S2 Text). Within this specific context our findings show that the presence of some TRI, rather
than certain specific elements, is the main driver in trust between SE users. Future investiga-
tions should attempt to ground these findings in established theoretical models to provide a
wider context and understanding of user psychology. For instance, social exchange theory [68]
and reward motivation theory [69,70] may be useful to shed light on the currently observed—
paradoxical—behavior, according to which SE users overall decrease the information content
and diagnosticity of TRI on platforms, while uncritically relying on its mere presence to make
decisions.
The aim of the current research was not to assess whether specific reputation and trust ele-
ments are useful to discriminate among different options, but rather to understand how the
presence of such information affects user judgement and decision-making in a setting that
closely follows real-world patterns.
A natural extension of the current research is to understand how accurate individuals are at
classifying profiles based on their quality. The current design considered the effect of cue diag-
nosticity to the extent that no one particular element provided specific information to classify
a room as “good” or “bad”, but aimed to reflect the natural distribution seen on SE platforms
[4,47]. However, if the profiles users saw varied more in terms of quality and uncertainty,
would ratings reflect these differences or would they continue to show a positivity effect? Intro-
ducing variability and an element of diagnosticity into the information users see on such pro-
files may provide a more complete image of human behavior in the SE, for example varying
the type of profiles users see or analyzing behavioral patterns of “low-raters” (e.g., hyper-criti-
cal or ‘picky’ users) and “high-raters” (e.g., uncritical or lenient users). Similarly, this can
extend into considering the difference in effect and strength that negative information has on
judgments compared to positive information [71]. This research is currently being
undertaken.
Due to explorative nature of our studies, we did not attempt to synthesize our results into a
trust model along the lines, e.g., of the work by Meyer et al. [20] or more recent developments
in the Internet setting (see, e.g., [72]). Yet, we believe that our work, and the aforementioned
ongoing research, represent an important step towards the development of a trust model for
interactions in the SE.
PLOS ONE | https://doi.org/10.1371/journal.pone.0209071 December 13, 2018
13 / 18
Digital Identity and user judgment
Lastly, our work does not take into account the role of platforms as mediators of trust.
Indeed, it has been shown [12] that trust towards a specific platform correlates positively with
trust between its users. While we deliberately eliminated any explicit reference to real-world
SE platforms (e.g., Airbnb) from our artificial accommodation platform in order to suppress
any possible spurious enhancement in the perceived trustworthiness of hosts, it would be very
interesting to replicate our studies in specific platforms as a way to indirectly measure their
additional impact on trust.
Conclusion
Currently, the effect of TRI on user behavior in the SE was investigated. The focus was on how
presenting users with information about hosts’ DI, in an accommodation SE platform, would
impact their perceptions of hosts and the likelihood of renting their private rooms. Over three
studies, the data consistently shows that users find hosts whose profiles display TRI as more
trustworthy, credible, and sociable. More importantly, they also rent more properties if such
information exists. Despite users showing a consistent and strong preference for specific infor-
mation, they demonstrate this positivity in judgement from seeing any three elements relating
to the hosts’ DI. These findings illustrate how TRI can affect user decision-making, cautioning
people on the risks of relying too heavily on this information. Research should carefully con-
sider how information relating to trust and reputation on SE platforms can impact user
judgement.
Supporting information
S1 Text. Additional measures.
(PDF)
S2 Text. Profile elements.
(PDF)
S3 Text. Study 1 Demographics and supplementary analyses.
(PDF)
S4 Text. Triplet analysis.
(PDF)
S5 Text. Study 2 Demographics and supplementary analyses.
(PDF)
S6 Text. Study 3 Demographics and supplementary analyses.
(PDF)
S7 Text. Data processing ReadMe. Explanation of the data processing used for the three
reported studies and description of variables in the datasets.
(PDF)
Acknowledgments
Giacomo Livan and Mircea Zloteanu acknowledge support from an EPSRC Early Career Fel-
lowship in Digital Economy (Grant No. EP/N006062/1).
Author Contributions
Conceptualization: Mircea Zloteanu, Nigel Harvey, David Tuckett, Giacomo Livan.
PLOS ONE | https://doi.org/10.1371/journal.pone.0209071 December 13, 2018
14 / 18
Digital Identity and user judgment
Data curation: Mircea Zloteanu.
Formal analysis: Mircea Zloteanu, Giacomo Livan.
Funding acquisition: Giacomo Livan.
Investigation: Mircea Zloteanu.
Methodology: Mircea Zloteanu.
Project administration: Mircea Zloteanu, Giacomo Livan.
Supervision: Giacomo Livan.
Writing – original draft: Mircea Zloteanu.
Writing – review & editing: Mircea Zloteanu, Nigel Harvey, David Tuckett, Giacomo Livan.
Lessig L. Remix: Making art and commerce thrive in the hybrid economy. Penguin; 2008.
References
1.
2. Hawlitschek F, Teubner T, Adam MTP, Borchers NS, Mo¨hlmann M, Weinhardt C. Trust in the sharing
economy: An experimental framework. 2016 International Conference on Information Systems, ICIS
2016. 2016. Available: https://www.scopus.com/inward/record.uri?eid=2-s2.0-
85019453377&partnerID=40&md5=078cfb694febff08b8440bca530a48e5
3. Botsman R, Rogers R. What’s Mine Is Yours: The Rise of Collaborative Consumption. London, UK:
4.