title:Freezing the Web: A Study of ReDoS Vulnerabilities in JavaScript-based
Web Servers
author:Cristian-Alexandru Staicu and
Michael Pradel
Freezing the Web: A Study of ReDoS Vulnerabilities 
in JavaScript-based Web Servers
Cristian-Alexandru Staicu and Michael Pradel, TU Darmstadt
https://www.usenix.org/conference/usenixsecurity18/presentation/staicu
This paper is included in the Proceedings of the 
27th USENIX Security Symposium.
August 15–17, 2018 • Baltimore, MD, USA
ISBN 978-1-939133-04-5
Open access to the Proceedings of the 27th USENIX Security Symposium is sponsored by USENIX.A Study of ReDoS Vulnerabilities in JavaScript-based Web Servers
Freezing the Web:
Cristian-Alexandru Staicu
Department of Computer Science
TU Darmstadt
Department of Computer Science
Michael Pradel
TU Darmstadt
Abstract
Regular expression denial of service (ReDoS) is a class
of algorithmic complexity attacks where matching a reg-
ular expression against an attacker-provided input takes
unexpectedly long. The single-threaded execution model
of JavaScript makes JavaScript-based web servers partic-
ularly susceptible to ReDoS attacks. Despite this risk and
the increasing popularity of the server-side Node.js plat-
form, there is currently little reported knowledge about
the severity of the ReDoS problem in practice. This pa-
per presents a large-scale study of ReDoS vulnerabilities
in real-world web sites. Underlying our study is a novel
methodology for analyzing the exploitability of deployed
servers. The basic idea is to search for previously un-
known vulnerabilities in popular libraries, hypothesize
how these libraries may be used by servers, and to then
craft targeted exploits.
In the course of the study, we
identify 25 previously unknown vulnerabilities in popu-
lar modules and test 2,846 of the most popular websites
against them. We ﬁnd that 339 of these web sites suf-
fer from at least one ReDoS vulnerability. Since a single
request can block a vulnerable site for several seconds,
and sometimes even much longer, ReDoS poses a seri-
ous threat to the availability of these sites. Our results
are a call-to-arms for developing techniques to detect and
mitigate ReDoS vulnerabilities in JavaScript.
1
Introduction
Regular expressions are widely used in all kinds of
software. Since regular expressions are easy to get
wrong [42], which may help attackers to bypass
checks [18, 5], developers are trained to think about
the correctness of regular expressions. In contrast, an-
other security-related aspect of regular expressions is of-
ten neglected:
the performance, speciﬁcally, how long
it takes to match a string against a regular expression.
Unfortunately, given a speciﬁcally crafted input, match-
ing against a suboptimally designed regular expression
can easily take several minutes or even hours. For exam-
ple, matching the apparently harmless regular expression
/(a+)+b/ against a sequence of 30 “a” characters on the
Node.js JavaScript platform takes about 15 seconds on
a standard computer.1 Matching a sequence of 35 “a”
characters already takes over 8 minutes, i.e., the match-
ing time explodes exponentially.
If a server implementation suffers from this kind of
performance problem, then an attacker can exploit it to
overwhelm the server with hard-to-match inputs. This
attack is known as regular expression denial of service,
or short ReDoS. Such attacks are a form of algorithmic
complexity attack [10] that exploits the worst-case com-
plexity behavior of algorithms that match a string against
a regular expression. Since for some regular expres-
sions, the worst-case complexity is much higher than the
average-case complexity, an attacker can cause denial of
service with a few, relatively small inputs.
Even though ReDoS has been known for several years,
recent developments in the web server landscape bring
new and increased attention to the problem. The rea-
son is that JavaScript is becoming increasingly popular
not only for the client-side but also for the server-side of
web applications. However, the single-threaded nature of
JavaScript, where every request is handled by the same
thread, makes server applications much more susceptible
to ReDoS attacks. In practice, to avoid making the server
unresponsive by blocking this thread, developers try to
split any long-running computation into smaller events,
which are than handled asynchronously. The problem
is that in current JavaScript engines, matching a string
against a regular expression cannot be easily split into
multiple chunks of computation. As a result, a single re-
quest can effectively block the main thread, making the
web server unresponsive to any other incoming requests
and preventing it from ﬁnishing any other already estab-
lished requests.
1We use JavaScript syntax for regular expressions, i.e., a pattern is
either enclosed by slashes or given to the RegExp() constructor.
USENIX Association
27th USENIX Security Symposium    361
Despite the importance of ReDoS in web servers, there
is currently little reported knowledge about the preva-
lence of ReDoS vulnerabilities in real-world websites.
In this paper, we present the ﬁrst comprehensive study
of ReDoS across a large number of websites. We seek to
answer the following questions:
• How widespread are ReDoS vulnerabilities in the
server-side part of real-world JavaScript-based web-
sites?
• What is the effect of vulnerabilities on the response
• What kinds of vulnerabilities are the most prevalent?
• Are more popular websites less vulnerable to ReDoS?
• Are existing defense mechanisms in use and if so, how
time of web servers?
effective are they in preventing ReDoS attacks?
Answering these questions involves solving two
methodological challenges. First, how to identify Re-
DoS vulnerabilities in the server-side of websites when
their source code is not available. We address this chal-
lenge based on a set of 25 previously unknown vulnera-
bilities in popular libraries and by speculating how these
libraries may be used in servers. Second, how to ana-
lyze which websites are exploitable without actually per-
forming a denial of service attack against live websites.
We address this challenge by triggering requests with in-
creasing input size, using both manually crafted exploit
inputs and randomly generated, harmless inputs, and by
statistically comparing the response times.
Using this methodology, we identify 339 websites that
suffer from at least one ReDoS vulnerability. Based on
experiments with locally installed versions of the vulner-
able server-side libraries, attacking these websites with
crafted inputs can cause a web server to remain unre-
sponsive for several seconds or even minutes. These
problems are due to a very small number of vulnerabil-
ities, with a single vulnerability that causes 241 sites to
be exploitable. While this is encouraging from a mitiga-
tion point of view, it also implies that an attacker aware
of a single, previously unknown vulnerability can cause
serious harm to several websites.
Ojamaa and D¨u¨una [27] were the ﬁrst to identify Re-
DoS as a threat for the Node.js platform. Davis et al. [11]
conﬁrm that such problems exist in popular modules and
report that 5% of the security vulnerabilities identiﬁed in
Node.js libraries are ReDoS. No prior work has studied
the impact of ReDoS on real-world web sites. Existing
work on detecting ReDoS vulnerabilities mostly targets
languages other than JavaScript. For example, W¨ustholz
et al. [43] propose a static analysis of ReDoS vulnerabili-
ties in Java. The only available tool for JavaScript that we
are aware of is a small utility called safe-regex2, which
checks for simple AST-level patterns known to cause Re-
2https://www.npmjs.com/package/safe-regex
DoS. However, this approach is notoriously prone to both
false positives and false negatives, since it reasons nei-
ther about the context in which these patterns appear
nor about the actual performance of regular expression
matching. Our work shows the urgent need for effective
tools and techniques that detect and prevent ReDoS vul-
nerabilities in JavaScript.
In summary, this paper contributes the following:
• A novel methodology for analyzing the exploitability
of deployed servers. The key ideas are (i) to hypothe-
size how server implementations may use libraries that
have previously unknown vulnerabilities and (ii) to as-
sess whether an attack is feasible without actually at-
tacking the servers.
• The ﬁrst comprehensive study of ReDoS vulnerabil-
ities in JavaScript-based web servers. Out of 2,846
studied websites, we ﬁnd 12% to be vulnerable.
• Empirical evidence that ReDoS is a real and
widespread threat. Our work calls for novel tools and
techniques that detect and prevent ReDoS vulnerabili-
ties.
• A benchmark of previously unreported ReDoS vul-
nerabilities and ready-to-use exploits, which we make
available for future research on ﬁnding, ﬁxing, and
mitigating ReDoS vulnerabilities:
https://github.com/sola-da/ReDoS-vulnerabilities
2 Background
2.1 Regular Expression Matching
Regular expressions are used to check whether a given
sequence of characters matches a speciﬁed pattern. Most
implementations in modern programming languages ad-
dress this problem by converting the regular expression
into an automaton [38] and through a backtracking-based
search for a sequence of transitions from the initial to an
accepting state that consumes the given string. For ex-
ample, consider the regular expression /^(a+b)?$/ and
its equivalent automaton in Figure 1. Given the string
“aab”, the automaton starts from state s and has two
available transitions, to states 1 and 3. It ﬁrst takes the
transition to state 1, which leads to the accepting state
a. Since the input string was not consumed and there
are no available transitions, the algorithm backtracks to
s and explores the transition to state 3 etc. After multi-
ple explorations the algorithm identiﬁes the sequence of
transitions s → 3 → 4 → 5 → 4 → 5 → 6 → 7 → a, which
reaches the accepting state and consumes all characters
of the input string.
362    27th USENIX Security Symposium
USENIX Association
ε
s
1
3
ε
ε
ε
2
4
ε
a
ε
b
6
5
ε
7
ε
a
Figure 1: Automaton for
the regular expression
/^(a+b)?$/. s is the starting state and a is the accepting
state.
ε
s
ε
ε
3
a
4
11
ε
ε
a
b
5
10
ε
ε
ε
6
9
ε
ε
a
ε
7
8
Figure 2: Automaton for
the regular expression
/^a*a*b$/. s is the starting state and a is the accept-
ing state.
2.2 Regular Expression Denial of Service
(ReDoS)
The backtracking-based search may cause the algorithm
to backtrack a possibly large number of times. ReDoS
attacks exploit these pathological cases. For example,
consider the regular expression /^a*a*b$/, its automa-
ton in Figure 2, and the input string “aaa”. Each charac-
ter “a” can be matched using two transitions, 4 → 5 and
8 → 9. At each step, the algorithm needs to decide which
of these two transitions to take. Eventually, since there
is no character “b” in the input string, the algorithm will
always fail when reaching state 11. However, before con-
cluding that the input string does not match the pattern,
the algorithm tries all possible ways of matching the “a”
characters. The example is a regular expression of super-
linear complexity [43], since the number of transitions
during matching is quadratic in the input size. Other reg-
ular expression even have exponential complexity, e.g.,
because of nested repetitions, such as in /^(a*)*b$/.
In our study, we identify ReDoS vulnerabilities of both
these types and show that both are of importance for
server-side JavaScript.
2.3 Server-side JavaScript
JavaScript is becoming more and more popular, includ-
ing the server-side Node.js platform, which advocates a
single-threaded, event-based execution model that uses
asynchronous I/O calls. In Node.js, the main thread of
execution runs an event loop, called the main loop that
handles events triggered by network requests, I/O opera-
tions, timers, etc. A slow computation, e.g., matching a
string against a regular expression, slows down all other
incoming requests. Compared to multi-threaded web
npm modules
ReDoS analysis
of libraries
Usage scenarios
Exploits creation
Module level
vulnerabilities
Local machines
Live websites
List of websites
using Node.js
Exploits using
HTTP requests
ReDoS analysis
of websites
List of vulner-
able websites
Figure 3: Overview of the methodology.
servers, such as Apache, the single-threaded execution
model compounds the problem in JavaScript. For exam-
ple, consider a regular expression that takes more than
an hour to match, which we show to exist in widely used
JavaScript software. To completely block an Apache
web server, we need to send hundreds of such requests,
each blocking one thread. Depending on the number of
available parallel processing units, the operating system,
and the thread pool size, new requests can still be han-
dled even with hundred of busy threads running. In con-
trast, in Node.js one such request is enough to completely
block the server for an hour. To make matters worse,
even less severe ReDoS payloads can signiﬁcantly de-
grade the availability of a Node.js server, as we show in
Section 4.3.
3 Methodology
This section presents our methodology for studying Re-
DoS vulnerabilities in real websites. The overall goals of
the methodology are to understand (i) how widespread
such vulnerabilities are, (ii) whether an attacker could ex-
ploit them to affect the availability of live websites, and
(iii) to what extent existing defense mechanisms address
the problem. To answer these questions, our methodol-
ogy must address two major challenges. The ﬁrst chal-
lenge is a technical problem: Since the server-side source
code of most websites is not available, how to know what
vulnerabilities a website suffers from? The second chal-
lenge is an ethical concern: How to study the potential
impact of attacks on live websites without actually caus-
ing noticeable harm to these websites?
Figure 3 shows a high-level overview of the methodol-
ogy. We address the two challenges through experiments
performed on machines under our control and on live
websites. A main insight to address the ﬁrst challenge
is to use previously unknown vulnerabilities in popular
JavaScript libraries and to speculate how servers may
use these libraries. More precisely, we analyze third-
party libraries, called node package manager modules
USENIX Association
27th USENIX Security Symposium    363
(npm packages or npm modules for short), to ﬁnd vulner-
abilities that may be exploitable via HTTP requests. We
then hypothesize how the server implementation may use
these packages and create exploits for these scenarios.