browser statistics were collected over a 5-week period
from the CIS Department web server at the University of
Pennsylvania. As evidenced by the ﬁgure, one can expect
to check up to 6 versions of a particular client. We expect
USENIX Association
14th USENIX Security Symposium
137
Detection method Throughput/sensor
Content matching
APE
Payload Sifting
225 Mbit/s
190 Mbit/s
268 Mbit/s
Table 1: PC Sensor throughput for different detection
mechanisms.
that this distribution will be more stabilized around ﬁnal
release versions and expect to minimize the number of
different versions that need to be checked based on their
popularity.
4.2 Filtering and anomaly detection
ﬁrewall/load-balancer. We
IXP1200-based
ﬁrst
determine the performance of
the IXP1200-based
ﬁrewall/load-balancer. The IXP1200 evaluation board
we use has two Gigabit Ethernet interfaces and eight
Fast Ethernet interfaces. The Gigabit Ethernet interfaces
are used to connect to the internal and external network
and the Fast Ethernet interfaces to communicate with the
sensors. A set of client workstations is used to generate
trafﬁc through the ﬁrewall. The ﬁrewall forwards trafﬁc
to the sensors for processing and the sensors determine
if the trafﬁc should be dropped, redirected to the shadow
honeypot, or forwarded to the internal network.
Previous studies [38] have reported forwarding rates
of at least 1600 Mbit/s for the IXP1200, when used as a
simple forwarder/router, which is sufﬁcient to saturate a
Gigabit Ethernet interface. Our measurements show that
despite the added cost of load balancing, ﬁltering and co-
ordinating with the sensors, the ﬁrewall can still handle
the Gigabit Ethernet interface at line rate.
To gain insight into the actual overhead of our imple-
mentation we carry out a second experiment, using Intel’s
cycle-accurate IXP1200 simulator. We assume a clock
frequency of 232 MHz for the IXP1200, and an IX bus
conﬁgured to be 64-bit wide with a clock frequency of
104 MHz. In the simulated environment, we obtain de-
tailed utilization measurements for the microengines of
the IXP1200. The results are shown in Table 10. The re-
sults show that even at line rate and worst-case trafﬁc the
implementation is quite efﬁcient, as the microengines op-
erate at 50.9%-71.5% of their processing capacity. These
results provide further insight into the scalability of our
design.
PC-based sensor performance. We also measure the
throughput of
the PC-based sensors that cooperate
)
i
%
(
s
e
n
g
n
e
o
r
c
M
i
f
o
n
o
i
t
a
z
i
l
i
t
U
80
70
60
50
40
30
20
FWD
LB
SPLITTER
LB+FWD
64
512
1024
1518
Packet Size (bytes)
Figure 10: Utilization(%) of the IXP1200 Microengines,
for forwarding-only (FWD), load-balancing-only (LB), both
(LB+FWD), and full implementation (FULL), in stress-tests
with 800 Mbit/s worst-case 64-byte-packet trafﬁc.
with the IXP1200 for analyzing trafﬁc and performing
anomaly detection. For this experiment, we use a 2.66
GHz Pentium IV Xeon processor with hyper-threading
disabled. The PC has 512 Mbytes of DDR DRAM at
266 MHz. The PCI bus is 64-bit wide clocked at 66
MHz. The host operating system is Linux (kernel version
2.4.22, Red-Hat 9.0).
We use LAN traces to stress-test a single sensor run-
ning a modiﬁed version of snort that, in addition to basic
signature matching, provides the hooks needed to coor-
dinate with the IXP1200 as well as the APE and payload
sifting heuristics. We replay the traces from a remote sys-
tem through the IXP1200 at different rates to determine
the maximum loss-free rate (MLFR) of the sensor. For the
purpose of this experiment, we connected a sensor to the
second Gigabit Ethernet interface of the IXP1200 board.
The measured throughput of the sensor for signature
matching using APE and Earlybird is shown in Table 1.
The throughput per sensor ranges between 190 Mbit/s
(APE) and 268 Mbit/s (payload sifting), while stan-
dard signature matching can be performed at 225 Mbit/s.
This means that we need at least 4-5 sensors behind the
IXP1200 for each of these mechanisms. Note, however,
that these results are rather conservative and based on un-
optimized code, and thus only serve the purpose of pro-
viding a ballpark ﬁgure on the cost of anomaly detection.
False positive vs. detection rate trade-offs We deter-
mine the workload that is generated by the AD heuristics,
by measuring the false positive rate. We also consider
the trade-off between false positives and detection rate,
to demonstrate how the AD heuristics could be tuned to
138
14th USENIX Security Symposium
USENIX Association
Payload sifting performance
APE performance
 20
)
e
t
detection delay
false positives
u
n
m
i
 15
 50
 40
 30
 20
 10
)
d
e
t
c
e
f
n
i
%
(
y
a
e
d
l
n
o
i
t
c
e
t
e
D
 20
)
e
t
APE
u
n
m
i
 15
 10
r
e
p
(
s
e
v
i
t
i
s
o
p
l
e
s
a
F
 5
 0
 30
 35
 40
 45
 50
MEL threshold (number of sled instructions)
r
e
p
(
s
e
v
i
t
i
s
o
p
l
e
s
a
F
 10
 5
 0
 2
 3
 4
 5
 6
 7
 8
 9  10  11  12  13
 0
Distinct destination threshold
Figure 11: FPs for payload sifting
Figure 12: FPs for APE
increase detection rate in our shadow honeypot environ-
ment. We use the payload sifting implementation from
[8], and the APE algorithm from [48]. The APE ex-
periment corresponds to a tightly-coupled shadow server
scenario, while the payload sifting experiment examines
a loosely-coupled shadow honeypot scenario that can be
used for worm detection.
We run the modiﬁed snort sensor implementing APE
and payload sifting on packet-level traces captured on an
enterprise LAN with roughly 150 hosts. Furthermore,
the traces contain several instances of the Welchia worm.
APE was applied on the URIs contained in roughly one-
billion HTTP requests gathered by monitoring the same
LAN.
Figure 11 demonstrates the effects of varying the dis-
tinct destinations threshold of the content sifting AD on
the false positives (measured in requests to the shadow
services per minute) and the (Welchia worm) detection
delay (measured in ratio of hosts in the monitored LAN
infected by the time of the detection).
Increasing the threshold means more attack instances
are required for triggering detection, and therefore in-
creases the detection delay and reduces the false posi-
tives. It is evident that to achieve a zero false positives
rate without shadow honeypots we must operate the sys-
tem with parameters that yield a suboptimal detection de-
lay.
The detection rate for APE is the minimum sled length
that it can detect and depends on the sampling factor and
the MEL parameter (the number of valid instructions that
trigger detection). A high MEL value means less false
positives due to random valid sequences but also makes
the heuristic blind to sleds of smaller lengths.
Figure 12 shows the effects of MEL threshold on the
false positives. APE can be used in a tightly coupled
scenario, where the suspect requests are redirected to the
instrumented server instances. The false positives (mea-
sured in requests to the shadow services per minute by
each of the normal services under maximum load) can
be handled easily by a shadow honeypot. APE alone has
false positives for the entire range of acceptable opera-
tional parameters; it is the combination with shadow hon-
eypots that removes the problem.
5 Limitations
There are three limitations of the shadow honeypot de-
sign presented in this paper that we are aware of. First, the
effectiveness of the rollback mechanism depends on the
proper placement of calls to transaction()
for commit-
ting state changes, and the latency of the detector. The
detector used in this paper can instantly detect attempts
to overwrite a buffer, and therefore the system cannot be
corrupted. Other detectors, however, may have higher
latency, and the placement of commit calls is critical to
recovering from the attack. Depending on the detector
latency and how it relates to the cost of implementing
rollback, one may have to consider different approaches.
The trade-offs involved in designing such mechanisms
are thoroughly examined in the fault-tolerance literature
(c.f. [14]).
Second, the loosely coupled client shadow honeypot
is limited to protecting against relatively static attacks.
The honeypot cannot effectively emulate user behavior
that may be involved in triggering the attack, for exam-
USENIX Association
14th USENIX Security Symposium
139
ple, through DHTML or Javascript. The loosely coupled
version is also weak against attacks that depend on local
system state on the user’s host that is difﬁcult to replicate.
This is not a problem with tightly coupled shadows, be-
cause we accurately mirror the state of the real system. In
some cases, it may be possible to mirror state on loosely
coupled shadows as well, but we have not considered this
case in the experiments presented in this paper.
Finally, we have not explored in depth the use of feed-
back from the shadow honeypot to tune the anomaly de-
tection components. Although this is likely to lead to
substantial performance beneﬁts, we need to be careful
so that an attacker cannot launch blinding attacks, e.g.,
“softening” the anomaly detection component through a
barrage of false positives before launching a real attack.
6 Related Work
Much of the work in automated attack reaction has fo-
cused on the problem of network worms, which has taken
truly epidemic dimensions (pun intended). For example,
the system described in [56] detects worms by monitoring
probes to unassigned IP addresses (“dark space”) or inac-
tive ports and computing statistics on scan trafﬁc, such as
the number of source/destination addresses and the vol-
ume of the captured trafﬁc. By measuring the increase
on the number of source addresses seen in a unit of time,
it is possible to infer the existence of a new worm when
as little as 4% of the vulnerable machines have been in-
fected. A similar approach for isolating infected nodes
inside an enterprise network [41] is taken in [15], where
it was shown that as little as 4 probes may be sufﬁcient
in detecting a new port-scanning worm. [54] describes
an approximating algorithm for quickly detecting scan-
ning activity that can be efﬁciently implemented in hard-
ware.
[34] describes a combination of reverse sequen-
tial hypothesis testing and credit-based connection throt-
tling to quickly detect and quarantine local infected hosts.
These systems are effective only against scanning worms
(not topological, or “hit-list” worms), and rely on the as-
sumption that most scans will result in non-connections.
As such, they as susceptible to false positives, either ac-
cidentally (e.g., when a host is joining a peer-to-peer net-
work such as Gnutella, or during a temporary network
outage) or on purpose (e.g., a malicious web page with
many links to images in random/not-used IP addresses).
Furthermore, it may be possible for several instances of
a worm to collaborate in providing the illusion of several
successful connections, or to use a list of known repliers
to blind the anomaly detector. Another algorithm for ﬁnd-
ing fast-spreading worms using 2-level ﬁltering based on
sampling from the set of distinct source-destination pairs
is described in [50].
[55] correlates DNS queries/replies with outgoing con-
nections from an enterprise network to detect anomalous
behavior. The main intuition is that connections due to
random-scanning (and, to a degree, hit-list) worms will
not be preceded by DNS transactions. This approach can
be used to detect other types of malicious behavior, such
as mass-mailing worms and network reconnaissance.
[17] describes an algorithm for correlating packet pay-
loads from different trafﬁc ﬂows,
towards deriving a
worm signature that can then be ﬁltered [23]. The tech-
nique is promising, although further improvements are
required to allow it to operate in real time. Earlybird
[36] presents a more practical algorithm for doing pay-
load sifting, and correlates these with a range of unique
sources generating infections and destinations being tar-
geted. However, polymorphic and metamorphic worms
[46] remain a challenge; Spinelis [39] shows that it is
an NP-hard problem. Buttercup [25] attempts to detect
polymorphic buffer overﬂow attacks by identifying the
ranges of the possible return memory addresses for ex-
isting buffer overﬂow vulnerabilities. Unfortunately, this
heuristic cannot be employed against some of the more
sophisticated overﬂow attack techniques [26]. Further-
more, the false positive rate is very high, ranging from
0.01% to 1.13%. Vigna et al. [51] discuss a method for
testing detection signatures against mutations of known
vulnerabilities to determine the quality of the detection
model and mechanism.
In [52], the authors describe
a mechanism for pushing to workstations vulnerability-