P1 (Session-Replay-Probing). The BotProbe monitor
spoofs the address of the server and inserts additional TCP
5Sometimes there is no such a message response packet Pr, but rather
an activity response. We still use Pr to stand for this activity response.
6The false positive rate can be higher, particularly if Pr is only a message
response packet because it could be just a normal prompt chat message from
a human.
Server
time
Middlebox
Client
c
m
1
s
e
1r
d
Regular
round
c
m
d
2
’
q
e
,s
2
s
re
c
m
d
3
3
s
e
r
c
h
a
l
l
e
n
g
e
r
e
s
p
o
n
s
e
c
m
d
1
,
s
e
q
’
c
m
d
1
'
,
res1
s
e
q
’
res1'
P0
Explicit-
Challenge-
Response
P1
Session-
Replay-
Probing
P2
Session-
Byte-
Probing
c
m
d
2
,
s
e
q
’
s2
e
r
Keep regular
session
c
m
d
3
'
3
s
e
r
P4
Man-In-The-
Middle-
Probing
(a) P0,P1,P2,P4: Active probing by injecting packets in existing connection.
Server
time
Middlebox
c
m
1
s
e
1r
d
...
1
d
m
c
c
m
1
s
e
r
d
1
r
e
s
1
1'
d
m
c
r
e
s
1
'
c
m
1'
s
e
r
d
1
'
Client
Regular
round
Login as
another user
Session-Replay-
Probing
Session-Byte-
Probing
(b) P3: Active probing by establishing new connection.
Example active probing techniques. Here cmd(cid:2)
Figure 2.
modiﬁed command packet, seq(cid:2)
sequence/acknowledge number to keep the TCP session.
means a
means modiﬁcation is needed on the
packets that replay the same application command Pc to the
client several times. If the remote end point is a bot, it will
likely provide responses that are deterministic (with respect
to both content and timing).
P2 (Session-Byte-Probing). The BotProbe monitor ran-
domly permutes certain bytes of the application command.7
If the client is a bot, then we expect it to be highly sensitive
to modiﬁcations of commands and hence to respond differ-
ently or drop the modiﬁed packet. However, a human user
in an IRC chat channel would have a higher tolerance for
typographical mistakes in an IRC message. We may repeat
our test as many times as necessary by interleaving strategies
P1 and P2, until we have sufﬁcient evidence to validate our
hypothesis. We describe the algorithm (Interleaved-Binary-
Response-Hypothesis) in more detail in Section III-C.
Note that strategies P1 and P2 may break existing con-
nections (by injecting new packets) if subsequent C&C com-
munications occur in the same TCP connection. To recover
from this, our in-line botnet probing system should adjust
the TCP sequence/acknowledge numbers and checksums to
account for the new packets that were introduced because of
the probes. Also, the above two probing strategies introduce
some amount of interference into existing sessions at the
application level. Fortunately, we ﬁnd that, for our targeted
chat-like protocols, we have an alternate probing technique
(P3), which does not disturb existing sessions.
P3 (Client-Replay-Probing). Chat protocols like IRC and
IM allow users to directly message each other. In such
instances, we instantiate a new user that logs into the channel
7Since many common botnet command names (e.g., .dos, .scan) are
embedded in the initial bytes of IRC PRIVMSG or TOPIC message packets,
we recommend biasing the byte modiﬁcation algorithm to choose the early
bytes with higher probability.
and sends the observed command(s) Pc to the selected client
(pretending to be the botmaster). By doing this, we do not
break existing connections, but achieve an effect similar to
that above. Figure 2(b) illustrates this scenario.
P4 (Man-In-The-Middle-Probing). The above tech-
niques do not directly intercept a new command packet.
However, in some cases (as discussed in Section V) such
as highly stateful C&Cs where simple replaying may not
work, we intercept the new command, and launch a man-in-
the-middle-like chat message injection.
P5 (Multiclient-Probing). The above techniques discuss
probing sessions from a single client. However, when mul-
tiple likely infected clients in the monitored network are
communicating with the same C&C server, we distribute
the probes among multiple clients and reduce the number of
probing rounds needed to test our hypothesis.
C. Algorithm Design for Botnet Detection Using Active
Probing
Based on the active probe techniques, we now describe
several simple detection algorithms for isolating determinis-
tic botnet communication patterns from human chat dialogs
with controlled accuracy (i.e., to achieve a desired false
positive/negative rate). We use a sequential probability ratio
testing (SPRT [30]) technique, which has been successfully
applied in several other scenarios
[14], [16]. To illustrate
the algorithm, we start with a basic description of how to
apply a hypothesis testing framework using botnet probing
strategies.
Let us assume that we are given a (suspicious) IRC
session and we want to differentiate whether it is more
likely a botnet C&C channel or a human chat session. We
perform one or more rounds of P0 probing (i.e., inject a
challenge to the client, ask the local participant (within our
network boundary) to solve a puzzle). We denote H1 as
the hypothesis “botnet C&C,” H0 as the hypothesis “normal
chat.” Let a binary random variable D denote whether or
not we observe a wrong reply for a challenge from the
client (that is, D = 1 means an incorrect reply). We also
denote θ1 = P r(D = 1|H1), θ0 = P r(D = 1|H0).
is a bot, we presume θ1 ≈ 1, assuming
If the client
that bots are unable to reliably solve arbitrary puzzles on
demand. For a human, such a puzzle is easy to answer,
i.e., θ0 ≈ 0. If we want to have very high accuracy for
the hypothesis (let us denote α, β as the false positive
rate and false negative rate we want to achieve), we can
perform several rounds of probing. Then, after observing n
rounds, we get a likelihood ratio Λn = P r(D1,...,Dn|H1)
P r(D1,...,Dn|H0) .
Di represents our independent identical distribution (i.i.d.)
observation result from our client probe test. We deﬁne
Λn = ln
P r(Di|H0) . To calculate this
likelihood Λn, we are essentially performing a threshold
random walk (TRW). The walk starts from origin (0), goes
i ln P r(Di|H1)
P r(Di|H1)
P r(Di|H0)
(cid:2)
(cid:2)
i
i
(cid:3)
=
θ0 when Di = 1, and goes down
up with step length ln θ1
with step length ln 1−θ1
1−θ0 when Di = 0. If Λn is greater
than a threshold t1 = ln 1−β
α we declare H1 to be true,
i.e., it is a botnet C&C. If Λn is less than another threshold
t2 = ln β
1−α , this indicates a normal IRC dialog. If Λn is
in between t1 and t2 we proceed with additional rounds of
testing. A nice property of this SPRT/TRW algorithm is that
it can achieve bounded false positive and false negative rates
as desired, and it usually needs only a few rounds to reach
a decision [30]. We call our ﬁrst extension of the algorithm
Turing-Test-Hypothesis because it uses explicit challenge
response. This algorithm even does not require observing
any actual botnet C&C interaction.
Similarly, we can adapt
the algorithm to use the P1
technique in every round. Let Pc be a suspicious command
packet from the server to the client. We replay Pc in each
round and we denote D to indicate whether or not a response
from the client is observed. We call this Single-Binary-
Response-Hypothesis algorithm because this test considers
the probe response as a binary outcome. Depending on the
response we observe (IRC PRIVMSG message, scanning,
spamming, or third-party access), we iterate the TRW pro-
cess at different scales, because θ0, θ1 (the corresponding
probability associated with a bot or human) is different
for different responses. For example, a human-driven IRC
session is very unlikely to perform scanning when receiving
a chat message. Thus, we improve our conﬁdence when
we observe a scanning response corresponding to the re-
played (command) message. If we receive multiple different
types of responses corresponding to the same command, we
choose the one that provides highest conﬁdence (walks a
largest step). The exact number of rounds we need in this
case is discussed in the next section. In general, Single-
Binary-Response-Hypothesis is very effective if the replayed
command packet is scan, spam, or binary download related.
As shown in Section III-D, we may need only one extra
replay in addition to the original command, i.e., two rounds
to detect a botnet.
In addition to performing binary response testing, we
can further evaluate whether the response is similar to the
previous response observed, because bot responses may not
be perfectly identical across multiple command replays. We
hypothesize that for bot C&C communication, responses to
the same command are similar in structure and content. We
can design a new hypothesis algorithm that inspects whether
a response is correlated to previous responses using a simple
edit distance metric or a DICE metric as in [14]. We call this
extension the Correlation-Response-Hypothesis algorithm.
Finally, we introduce the Interleaved-Binary-Response-
Hypothesis algorithm. In each round, we perform inter-
leaved P1 and P2 probing, i.e., replaying the original Pc
packet, and then replaying a modiﬁed Pc packet. D = 1
denotes the observation of a response from the replayed
Pc, and D = 0 denotes no response from modiﬁed Pc.
The assertion is that bots reliably respond to Pc, but do
not recognize the modiﬁed command. This occurrence is
then observed as D = 1. To a human user, these two
are similar (a modiﬁed Pc is just
like a typographical
error (typo), and while chatting, a typo is normal and
generally not a problem). It is hard to predict how normal
users may respond when they receive these two replayed
IRC PRIVMSG messages, but the probability of obtaining
repeatable responses from replayed Pc and no responses
from modiﬁed Pc should diminish with rounds. A naive
assumption is that the human responses to tampered packets
are uniformly random, θ0 = P r(D = 1|H0) = 1/4.
In reality, normal users would quickly lose patience upon
receiving multiple similar IRC messages, and hence this
probability θ0 should be lower than the uniformly random
case. Our later user study (in Section IV-C) also conﬁrms
that θ0 is very low.
of
the
One
beneﬁt
Interleaved-Binary-Response-
Hypothesis algorithm is that we can have a general
way to detect a third-party access response and do not
rely on content signatures, e.g., PE header
(Microsoft
Windows executable) signature as used in BotHunter [13]
to detect egg downloading. This has the advantage when
we do not have signatures for detecting these third-party
accesses, e.g., the access is not for a Windows executable,
or