manifestation of the attack. For example, consider an attack
targeting a Web server called spider within the network
protected by the intrusion detection system. In this case, the
event space for that attack is composed of all the TCP trafﬁc
that involves port 80 on host spider.
Event spaces are expressed as disjunctions of clauses,
that is, Ejk = cjk0 _ cjk1 _ ::: _ cjk, where each clause
cjk is an expression of the type xRy. x denotes a value
derived from the frame fi (e.g., a part of the frame header)
while R speciﬁes an arithmetic relation (e.g., =, !=, <). y
can be a constant, the value of a variable, or a value de-
rived from the same frame. Clauses and event spaces may
be derived automatically from the attack descriptions, for
example from signatures written in attack languages such
as Bro [6], Sutekh [7], STATL [2], or Snort [8].
3.3 Frame Routing
Event spaces are the basis for the deﬁnition of the ﬁl-
ters used by the slicers to route frames to different chan-
nels. The ﬁlters are determined by composing the event
spaces associated with all the scenarios that are “active” on
a speciﬁc channel. More precisely, the set of active scenar-
ios is ACi = U j<	
j=0 Aj where Aj is the set of scenarios of
j 2 Ci. The event space ECi for a channel Ci is the dis-
junction of the event spaces of all active scenarios, which
corresponds to the disjunction of all the clauses of all the
active scenarios. The resulting overall expression is the ﬁl-
ter that each slicer uses to determine if a frame has to be
routed to that speciﬁc channel. Note that it is possible that
a certain frame will be needed by more than one scenario.
Therefore, it will be sent on more than one channel.
The conﬁguration of the slicers as described above is
static; that is, it is calculated off-line before the system is
started. The static approach suffers from the possibility
that, depending on the type of trafﬁc, a large percentage of
the network packets could be forwarded to a single channel.
This would result in the overloading of sensors attached to
that channel. The static conﬁguration also makes it impos-
sible to predict the exact number of sensors that are neces-
sary to deal with a Gigabit link. The load on each sensor
depends on the scenarios used and the actual trafﬁc. The
minimum requirement for the slicers is that the capacity of
their incoming and outgoing links must be at least equal to
the bandwidth of the monitored link.
One way to prevent the overloading condition is to per-
form dynamic load balancing. This is done by reassigning
scenarios to different channels at run-time. This variant ob-
viously implies the need to reconﬁgure the ﬁlter mechanism
at the trafﬁc slicers and update the assignment of clauses to
channels.
In addition to the reassignment of whole scenarios to dif-
ferent channels, it is also possible to split a single scenario
into two or more reﬁned scenarios. The idea is that each
reﬁned scenario catches only a subset of the attacks that the
original scenario covered, but each can be deployed on a dif-
ferent channel. Obviously, the union of attacks detectable
by all reﬁned scenarios has to cover exactly the same set of
attacks as the original scenario did.
This can be done by creating additional constraints on
certain attributes of one or more basic events. Each con-
straint limits the number of attacks a reﬁned scenario can
detect. The constraints have to be chosen in a way such that
every possible value for a certain attribute (of the original
scenario) is allowed by the constraint of at least one reﬁned
scenario. Then the set of all reﬁned scenarios, which each
cover only a subset of the attacks of the original one, are
capable of detecting the same attacks as the original.
A simple mechanism to partition a particular scenario is
to include a constraint on the destination attribute of each
basic event that represents a packet which is sent by the at-
tacker. One has to partition the set of possible destinations
such that each reﬁned scenario only covers attacks against a
certain range of hosts. When the union of these target host
ranges covers all possible attack targets, the set of reﬁned
scenarios is capable of ﬁnding the same attacks as the orig-
inal scenario.
Such an approach is necessary when a single scenario
causes too much trafﬁc to be forwarded to a single channel.
In addition, obviously innocent or hostile frames could
be ﬁltered out before the scenario clauses are applied,
thereby eliminating trafﬁc that needs no further processing.
This could be used, for instance, to prevent the system from
being ﬂooded by packets from distributed denial-of-service
slaves that produce trafﬁc with a unique, known signature.
4 Evaluation
The initial set of experiments were primarily aimed at
evaluating the effectiveness of the scatterer/slicer/ reassem-
bler architecture. For these experiments, we deployed three
trafﬁc slicers ( = 3) and four stream reassemblers ( = 4)
with one intrusion detection sensor per stream. The next
section presents the details of the hardware and software
used to realize the initial prototype, and the section after
that gives the details of each experiment and presents the
corresponding results.
4.1 Prototype Architecture
The prototype is composed of a number of hosts respon-
sible for the analysis of the trafﬁc carried by a Gigabit link.
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
The Gigabit
link is realized as a direct connection
(crossover cable) between two machines equipped with In-
tel Xeon 1.7 GHz processors, 512 MB RAM and 64-bit PCI
3Com 996-T Gigabit Ethernet cards running Linux 2.4.2
(Red Hat 7.1). One of the two machines simulates the net-
work tap and is responsible for creating the network trafﬁc
(via tcpreplay [12]). The other machine acts as the traf-
ﬁc scatterer and is equipped with three additional 100 Mbps
3Com 905C-TX Ethernet cards.
The scatterer functionality itself is realized as a kernel
module attached to the Linux kernel bridge interface. The
bridge interface provides a hook that allows the kernel to
inspect the incoming frames before they are forwarded to
the network layer (e.g., the IP stack). The scatterer mod-
ule intercepts frames coming from the Gigabit interface and
immediately forwards them to one of the outgoing links
through the corresponding Fast Ethernet card. The links
are selected in a round-robin fashion. The scatterer also
attaches a sequence number to each packet, which is later
used by the reassemblers. In order to overcome the problem
of splitting Ethernet frames with a length close to the maxi-
mum transferable unit (MTU), the sequence number has to
be integrated into the Ethernet frame without increasing its
size. To leave the data portion untouched, we decided to
modify the Ethernet header. We also wanted to limit the
modiﬁcations of the Ethernet frame to a minimum in order
to be able to reuse existing hardware (e.g., network interface
cards, network drivers). Therefore, the MTU had to remain
unchanged. For this reason, we decided to use the six-byte
Ethernet source address ﬁeld for sequence numbers. As a
result, before the trafﬁc scatterer forwards a frame, it writes
the current sequence number into the source address ﬁeld
and increments it.
The experimental setup demonstrates that the partition-
ing of trafﬁc is possible and that it allows for the detailed
analysis of higher trafﬁc volume (including defragmenta-
tion, stream reassembly, and content analysis). Because we
only use three trafﬁc slicers (with an aggregated bandwidth
of 300 Mbps), sustained incoming trafﬁc of 1 Gbps would
overload our experimental setup. However, the introduction
of additional trafﬁc slicers would allow us to handle higher
trafﬁc inputs.
The trafﬁc slicers (Intel Pentium 4 1.5 GHz, 256 MB
RAM, 3Com 905C-TX fast Ethernet cards running Linux
2.4.2 - Redhat 7.1) have the NIC of the link that connects
them to the trafﬁc scatterer set to promiscuous mode, in or-
der to receive all incoming frames. The data portion of each
incoming frame is matched against the clauses stored for
each channel. Whenever a clause for a channel is satisﬁed,
a copy of the frame is forwarded to that channel. Note that
this could (and usually does) increase the total number of
frames that have to be processed by the intrusion detection
sensors. Nevertheless, a sufﬁciently large number of sen-
sors combined with sophisticated partitioning enable one
to keep the amount of trafﬁc at each sensor low enough to
handle. In our test setup, the partitioning (i.e., the clauses)
was determined as follows. Similar to Snort [9], we distin-
guished between an inside network and an outside network,
representing the range of IP addresses of the protected net-
work and its complement, respectively. The protected net-
work address range is divided according to the existing class
C subnetworks. The network addresses are then grouped
into four sets, each of which is assigned to a different chan-
nel. This partitioning allows the system to detect both at-
tacks involving a single host and attacks spanning a sub-
network. As explained in Section 3.3 more sophisticated
schemes are possible by analyzing additional information
in the packet headers or even by examining the frame pay-
load.
Once the ﬁlters have been conﬁgured, the frames have to
be routed to the various channels. As in the case for the
transmission between the scatterer and the trafﬁc slicers,
we want to prevent frames from being split when sent to
the channels. This makes it necessary to include the des-
tination address information of the intended channel in the
Ethernet frame itself without increasing its size and with-
out modifying the payload. To do this we use the Eth-
ernet destination address. Therefore, the destination ad-
dress is rewritten with values 00:00:00:00:00:01,
00:00:00:00:00:02, etc., depending on the destina-
tion channel. There were two reasons for using a generic
link number instead of the actual Ethernet addresses as the
target address for sensors. First, a number of sensors may be
deployed on each channel, processing portions of the trafﬁc
in parallel. Since each sensor has to receive all packets on
the channel where it is attached, selecting the Ethernet ad-
dress of a single sensor is not beneﬁcial. Second, whenever
the NIC of a sensor has to be replaced, the new Ethernet
address would have to be updated at each trafﬁc slicer. In
order to save this overhead, each trafﬁc slicer simply writes
the channel number into the target address ﬁeld of outgoing
frames.
The actual frame routing is performed by a switch (a
Cisco Catalyst 3500XL) that connects trafﬁc slicers with
reassemblers. The MAC address-port table of the switch
holds the static associations between the channel numbers
(i.e., the target Ethernet addresses set by the trafﬁc slicers)
and the corresponding outgoing ports.
In general back-
planes of switches have very high bandwidth compared to
Ethernet links, so they are not likely to be overloaded by
trafﬁc generated by the scatterer.
In our setup,
the stream reassemblers are located at
each sensor node (using the same equipment as the traf-
ﬁc slicers), and they provide the intrusion detection sensors
with a temporally sorted sequence of frames by using the
encapsulated sequence numbers. The reassembly procedure
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
Outside
Internet
Tap
Inside
Figure 2. Single-node Snort setup.
has been integrated into libpcap so that every sensor that
utilizes these routines to capture packets can be run unmod-
iﬁed. For each frame, we assume that no other frame with a
smaller sequence number can arrive after a certain time span
(currently 500 ms). This means that when an out-of-order
packet is received, it is temporarily stored in a queue until
either the missing packets are received and the correctly-
ordered batch of packets is passed to the application, or the
reassembler decides that some packets have been lost be-
cause a timeout expired and the packet is passed without
further delay. Therefore, each received packet is passed to
the sensors with a worst case delay being the timeout value.
The timeout parameter has to be large enough to prevent
the situation where packets with smaller sequence numbers
arrive after subsequent frames have already been processed
but small enough so that the reaction lag of the system is
within acceptable limits. Since the processing and trans-
mission of frames is usually very fast and no retransmission
or acknowledgments are utilized, one can expect frames to
arrive at each reassembler in the correct order most of the
time. In principle, this allows one to safely choose a very
short time span. We expect to have no problems in reduc-
ing the current timeout value, but at the moment we have
no experimental evaluation of the effect of different timeout
values on the effectiveness of intrusion detection.
The network cards of the nodes would normally be re-
ceiving trafﬁc at rates close to their maximum capacity.
If administrative connections, such as dynamically setting
clauses, reporting alarms, or performing maintenance work
were to go through the same interfaces, these connections
could potentially suffer from packet loss and long delays.
To overcome this problem, each machine is connected to
a second dedicated network that provides a safe medium
to perform the tasks mentioned above. An additional com-
munication channel decoupled from the input path has the