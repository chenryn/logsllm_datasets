title:FACE-CHANGE: Application-Driven Dynamic Kernel View Switching in
a Virtual Machine
author:Zhongshu Gu and
Brendan Saltaformaggio and
Xiangyu Zhang and
Dongyan Xu
2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
FACE-CHANGE: Application-Driven Dynamic Kernel View Switching
in a Virtual Machine
Zhongshu Gu, Brendan Saltaformaggio, Xiangyu Zhang, Dongyan Xu
Department of Computer Science and CERIAS, Purdue University, West Lafayette, IN, USA, 47907-2107
{gu16, bsaltafo, xyzhang, dxu}@cs.purdue.edu
Abstract—Kernel minimization has already been established
as a practical approach to reducing the trusted computing
base. Existing solutions have largely focused on whole-system
proﬁling – generating a globally minimum kernel image that
is being shared by all applications. However, since different
applications use only part of the kernel’s code base, the
minimized kernel still includes an unnecessarily large attack
surface. Furthermore, once the static minimized kernel
is
generated,
it is not ﬂexible enough to adapt to an altered
execution environment (e.g., new workload). FACE-CHANGE
is a virtualization-based system to facilitate dynamic switching
at runtime among multiple minimized kernels, each customized
for an individual application. Based on precedent proﬁling
results, FACE-CHANGE transparently presents a customized
kernel view for each application to conﬁne its reachability
of kernel code. In the event that the application exceeds this
boundary, FACE-CHANGE is able to recover the missing code
and backtrace its attack/exception provenance to analyze the
anomalous behavior.
Keywords-Attack Surface Minimization; Attack Provenance;
Virtualization;
I. INTRODUCTION
Modern operating systems strive to shrink the size of the
trusted computing base (TCB) to ease code veriﬁcation and
minimize trust assumptions. For a general-purpose operating
system (OS) like Linux, kernel minimization has already
been established as a practical approach to reducing attack
surface. But existing approaches [1]–[4] have a number of
problems:
Coarse-Grained Proﬁling: In order to eliminate unnec-
essary code from the kernel, one must identify the kernel
code that is required to support the multiple applications
within a system. The conventional approach is to generate
typical workloads and measure all active kernel code in
a training session. Proﬁling is performed on the whole
system and does not distinguish between the requirements
of different applications [1]. This approach is well suited for
generating a customized kernel for a static, special-purpose
system (e.g., an appliance or embedded system). But for
a general-purpose operating system supporting a variety of
applications, whole-system proﬁling unnecessarily enlarges
the kernel attack surface of the system.
In practice, we observe that kernel code executed under
different application contexts varies drastically. Our experi-
ments show that two distinct applications may share as little
as 33.6% of their executed kernel code – thus system-wide
kernel minimization would over-approximate both applica-
tions’ kernel requirements. For example, the kernel function-
ality needed by task manager top is to read statistics data
from the memory-based proc ﬁle system and write to the tty
device. In sharp contrast, the Apache web server primarily
requires network I/O services from the kernel. If we proﬁle
a system running top and Apache simultaneously, we will
expose the kernel’s networking code to top simply because
Apache is in the same environment. Further, assume top is
the target of a malicious attack, the compromised top may
be implanted with a parasite network server as a backdoor
without violating the minimized kernel’s constraint.
Flexibility to Adapt to Runtime Changes: The output of
traditional kernel minimization approaches is a static kernel
image customized for a speciﬁc workload. However, it is
nearly impossible to cover all execution paths within an
application’s code to trigger every possible kernel request.
Even when leveraging automatic test case generation tech-
niques [5]–[7], proﬁling may still suffer from the path cover-
age problem for large programs. Insufﬁcient proﬁling may
lead to an underestimation of the kernel code required to
support some application(s) at runtime. Further, the required
kernel code may change when running a new application that
was not proﬁled before or when the workload of an existing
application suddenly changes. If this newly requested kernel
code is not included in the customized image, the violation
may crash the application or even panic the kernel.
To address these problems of whole-system-based ker-
nel minimization, we have developed FACE-CHANGE, a
virtualization-based system to support dynamic switching
among multiple minimized kernels, each for an individual
application. Throughout this paper, we use the term ker-
nel view to refer to the in-memory kernel code presented
to an individual application. In conventional kernels, all
concurrently running user-level processes share the same
kernel view containing the entire kernel code section, which
we refer to as a full kernel view. FACE-CHANGE aims to
present each process with a different, customized kernel
view, which is prepared individually in advance by proﬁling
the application’s needs. Any unnecessary kernel code is
eliminated to minimize the attack surface accessible to this
speciﬁc application. At runtime, FACE-CHANGE identiﬁes
978-1-4799-2233-8/14 $31.00 © 2014 IEEE
DOI 10.1109/DSN.2014.52
491
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:20:50 UTC from IEEE Xplore.  Restrictions apply. 
the current process context and dynamically switches to its
customized kernel view.
To support applications that were not previously proﬁled,
we are able to proﬁle them in independent (off-line) sessions
to generate their kernel views. We then load the kernel view
for a new application dynamically without interrupting the
system’s execution. This removes the burden of re-compiling
and/or installing a new customized kernel upon the addition
of a new application.
Furthermore, we include a kernel code recovery mecha-
nism for the event that an application tries to reach code
outside of the boundary of its kernel view. This may be
due to incomplete proﬁling (e.g., interrupt handler’s code
with no attachment to any process or some workload not
completely exercised) or malicious tampering (e.g., some
injected logic requests new/different kernel features). We
are able to recover the missing code and backtrack its
provenance to identify the anomalous execution paths. Such
capability can be leveraged by administrators to analyze the
attack patterns of both user-level and kernel-level malware.
This paper makes the following contributions:
• A quantitative study of per-application kernel require-
ments in a multi-programming system.
• A virtualization-based dynamic kernel view switching
technique. FACE-CHANGE is transparent to the guest
virtual machine (VM) and requires no patching or
recompilation of the guest OS kernel.
• A kernel code recovery mechanism to recover requested
but missing code and backtrack the provenance of such
an anomaly/exception.
The rest of this paper is organized as follows. Section II
presents the motivation, goals and assumptions of FACE-
CHANGE. Section III provides the detailed design of FACE-
CHANGE. Section IV gives case studies on the effective-
ness of FACE-CHANGE on user/kernel malware attacks and
evaluates its performance. Section V discusses limitations
and future work. Section VI describes related work and we
conclude in Section VII.
II. SYSTEM OVERVIEW
In this section, we introduce a quantitative method to mea-
sure the kernel code requirements of a speciﬁc application.
We then use these measurements to evaluate the similarity of
kernel code requirements between applications. The result of
this quantitative study motivates the development of FACE-
CHANGE. Finally, we present the goals and assumptions of
our design.
A. Motivation
Each application, including both the base program and any
libraries loaded into the user address space, interacts with the
OS through system calls to request services (e.g., manipulat-
ing ﬁles, spawning threads, IPC, etc.). The set of system calls
utilized by an application varies substantially across different
application types and workloads, and intuitively, different
system calls will reach different parts of the kernel’s code.
Further, different values passed as parameters to the same
system calls may lead to totally different execution paths
within the kernel. For example, because of Linux’s virtual
ﬁle system (vfs) interface, a read system call for disk-based
ﬁles in ext4-fs and memory-based ﬁles in procfs will be
dispatched to entirely different portions of the kernel’s code.
To accurately measure a target application’s kernel code
requirements, we monitor the system execution at the basic
block level. We brieﬂy describe the proﬁling tool here and
will present the detailed design in Section III-A. We record
any executed basic blocks which satisfy the following two
criteria:
1) The basic block belongs to the kernel, i.e., its memory
address is in kernel space.
2) The basic block is executed in the target application’s
context.
After merging any adjacent blocks, we get a range list K[app]
for a target application (denoted by subscript [app]) in the
form:
K[app] = {([B1, E1], T1),··· , ([Bi, Ei], Ti)}
Bi and Ei denote the beginning and end addresses for the
i-th in-memory code segment. Ti indicates the type for this
memory segment, where Ti can be either “base kernel” or
the name of a kernel module. For kernel modules, we record
addresses relative to the module’s base address because a
module’s loading addresses may change at runtime.
application’s kernel code requirements:
We introduce three deﬁnitions for comparing two distinct
1) K[app1] ∩ K[app2]
The intersection of two range lists outputs the overlap-
ping address ranges between them. The result is still
a range list.
2) LEN(K[app])
The LEN of a range list outputs the number of elements
in this list.
3) SIZE(K[app]) =
(cid:2)
i∈[1,LEN(K[app])](Ei − Bi)
The SIZE of a range list outputs the size of kernel code
in this range list.
We use Equation (1) below to deﬁne the similarity index
S between K[app1] and K[app2]:
SIZE(K[app1] ∩ K[app2])
S =
MAX(SIZE(K[app1]), SIZE(K[app2]))
(1)
A similarity index S indicates the proportion of the over-
lapping of kernel code required between two applications.
Besides common system call execution paths,
the over-
lapping kernel code also consists of functionality needed
by every application, e.g., process scheduler and interrupt
handling code. Through the proﬁling of well-known Linux
applications, we ﬁnd that similarity indices range from
492
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:20:50 UTC from IEEE Xplore.  Restrictions apply. 
33.6% for applications that are orthogonal in type (such as
top vs. Firefox) to 86.5% for similar applications (such as
Apache vs. vsftpd). Table I (Section IV) shows the similarity
indices for all proﬁled applications. These measurements
support our earlier hypothesis that kernel code execution
paths vary substantially across different application types.
This also indicates that application-speciﬁc kernel views can
minimize the kernel attack surface far beyond that of system-
wide kernel minimization.
B. Goals and Assumptions
We state the goals for our system in four aspects: strict-
ness, robustness, transparency and ﬂexibility.
Strictness: The kernel view generated for a speciﬁc appli-
cation should only contain the kernel code that is necessary
for the correct execution of this application under a normal
usage scenario. We should eliminate all other excessive code
from the kernel view to avoid enlarging the kernel’s attack
surface. If an application reaches kernel code that does not
belong to its kernel view, we should record the access in
detail for later analysis.
Robustness: If an application is running under the same
workload and same usage scenario as during proﬁling, the
behavior of this application running with a customized
kernel view should be no different than with a full kernel
view. If the application accesses any kernel code that is not
included in the customized kernel view, we should recover
the missing code and record this violation silently without
being detected by the application.
Transparency: There is no need to change any code in the
applications or operating system. The hypervisor controls all
FACE-CHANGE operations, which remain transparent to the
guest VM.
Flexibility: Administrators can dynamically load, unload,
and switch the kernel view for a speciﬁc application at any
time. This should neither jeopardize the functionality of the
currently running application nor the system as a whole.
We assume that, when we generate customized kernel
views in the proﬁling phase, the environment, including both
the applications and the kernel, should not be tampered with
by malware.
III. DESIGN AND IMPLEMENTATION
In this section, we give a detailed description of the overall
design of FACE-CHANGE, highlight the challenges we face
and the solutions we propose. Then we discuss the detailed
implementation of our prototype system.
We divide the whole system into two phases in chrono-
logical order: the proﬁling phase and the runtime phase.
The proﬁling phase monitors a target program’s execution
and, based on the active kernel code in this process’ con-
text, generates a conﬁguration ﬁle describing the applica-
tion’s customized kernel view. In the runtime phase, FACE-
CHANGE builds a new customized kernel view based on
each application’s conﬁguration ﬁle and forces the process
to use this customized kernel view whenever the guest OS
schedules it.
Figure 1 shows a high-level example of these two phases.
Assume we want to proﬁle Process 1 in the proﬁling phase.
When the kernel schedules Process 1 to run, we start to
record all the kernel code executed in its context. When
Process 1 is scheduled out, we pause the recording until the
process is re-scheduled. This procedure also applies to Pro-
cesses 2 and 3. At last we generate three conﬁguration ﬁles
for the kernel views of these three processes respectively. In
the runtime phase, we load each customized kernel view for
the corresponding process. For example, Process 1 can only
access [Process 1] kernel view when it is running.
A. Proﬁling Phase
1) Design of the Proﬁler: We implemented our proﬁler
as a component of the QEMU [8] 1.6.0 full system emulator.
This enables the proﬁler to track an application’s execution
at
the granularity of a basic block, and we use virtual
machine introspection (VMI) techniques to track context
switches within the guest OS. When the guest OS schedules
the target application, the proﬁler records any address ranges
of kernel code executed in this process’ context. For code
within a kernel module, we record addresses relative to
the module’s base address. Once the application has been
sufﬁciently proﬁled, the proﬁler exports all recorded kernel
code segments to a kernel view conﬁguration ﬁle.
2) Test Suite Selection: For each application to be pro-
ﬁled, the user should choose a test suite to simulate the
expected real-world workload for this application. For in-
stance, when proﬁling a server application, the user may
deploy it in the real environment to handle requests, or for an
interactive application, one may simulate the I/O operations
of a typical user. To give a speciﬁc example, when proﬁling
a mysql server, we set up a RUBiS1 [9] server and used its
own simulated client to generate workloads for the mysql
database.
It is difﬁcult to ensure that all code paths through an
application are executed during proﬁling, and thus it
is
possible that at runtime the application may access some
kernel code missed by the proﬁling phase. One alternative
to a test suite driven proﬁler is to use symbolic execution
to generate high-coverage test cases, but this approach may
not scale to large applications. To address this problem, we
employ a kernel code recovery mechanism in the runtime