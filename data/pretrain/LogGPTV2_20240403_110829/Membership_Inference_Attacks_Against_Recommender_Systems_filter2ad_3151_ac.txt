𝑖 is the ground truth label for the 𝑖𝑡ℎ target user. And y′
𝑖 is
the predicted possibility of the 𝑖𝑡ℎ target user belonging to members.
Besides, 𝑁𝑡𝑟𝑎𝑖𝑛 is the size of training data.
Test data D𝑡𝑒𝑠𝑡 for the attack model is generated from the
target recommender in the same way as the training data. The
trained attack model A′
conduct a prediction given a target
user feature vector z𝑡𝑎𝑟𝑔𝑒𝑡, i.e., A′
𝑎𝑡𝑡𝑎𝑐𝑘(z𝑡𝑎𝑟𝑔𝑒𝑡) = y𝑡𝑎𝑟𝑔𝑒𝑡, where
is a 2-dimension vector, and the values of 𝑎 and
y𝑡𝑎𝑟𝑔𝑒𝑡 =
𝑏 indicate the probabilities that the target user belongs to non-
members and members respectively. According to the predicted
results, the adversary infers the membership status of the target
user. Concretely, when 𝑎 < 𝑏, the target user is predicted to be a
member. Otherwise, they are predicted to be a non-member.
(cid:18) 𝑎
𝑎𝑡𝑡𝑎𝑐𝑘
(cid:19)
𝑏
3 EXPERIMENTS
In this section, we first demonstrate experimental setup, including
recommendation methods, datasets, preprocessing process, evalua-
tion metrics, implementation details, and notations in Section 3.1.
Then, we evaluate the performances of original recommender sys-
tems in Section 3.2. Moreover, we investigate membership inference
attacks against recommender systems in Section 3.3 and conduct de-
tailed analyses on the influences of hyperparameters in Section 3.4.
Finally, we present extensive analysis to comprehensively investi-
gate the attack model in Section 3.5.
3.1 Experimental Setup
Recommendation Methods. Personalized recommendation al-
gorithms are adopted for members, including Item-Based Collabo-
rative Filtering (Item) [40], Latent Factor Model (LFM) and Neural
Collaborative Filtering (NCF) [16]. Meanwhile, due to the lack of
non-members’ data, a recommender system provides non-members
with the most popular items, which is named the popularity recom-
mendation algorithm in our paper.
Datasets. We utilize three real-world datasets in our experiments,
including Amazon Digital Music (ADM) [15], Lastfm-2k (lf-2k) [4],
and Movielens-1m (ml-1m) [13], to evaluate our attack strategies.
All these datasets are commonly-used benchmark datasets for evalu-
ating recommender systems. Note that only ratings in these datasets
are used for our evaluation in the experiments. Scores range from 1
to 5, which indicates how much users like musics (ADM and lf-2k)
or movies (ml-1m).
Preprocessing. For each dataset, we divide it into three disjoint
subsets, i.e. a shadow dataset, a target dataset and a dataset for
extracting item features. Then, the following processing methods
are implemented to these subsets:
Session 3C: Inference Attacks CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea868• To generate feature vectors for users, the dataset for item
feature should contain all items of the target and shadow
recommenders.
• For the shadow or target dataset, we further divide it into
two disjoint parts, which are used to conduct recommenda-
tions to members and non-members, respectively. Moreover,
following the previous work [16], we filter out the users who
have less than 20 interactions.
In our experiments, recommender systems conduct recommen-
dations based on implicit feedback. We assign values of 1 to the
user-item pairs when there exist interactions between these users
and items. And other user-item pairs are assigned 0. In LFM and
NCF, recommender systems require both positive and negative in-
stances. We randomly sample negative user-item pairs from the
pairs scoring 0 and regard the pairs assigned 1 as positive instances.
We keep the same number of negative samples as positive samples
for the dataset balance.
Evaluation Metrics. We use AUC (area under the ROC curve) as
the metric to evaluate attack performances. Following the definition
of the attack, we regard members as positive data points and non-
members as negative data points. AUC indicates the proportion of
the prediction results being positive to negative. For example, if
the attack model utilizes Random Guess to conduct a membership
inference, the AUC is close to 0.5.
Implementation Details. We build a MLP with 2 hidden layers
as the attack model. The first hidden layer has 32 units and the
second layer has 8 units, both followed by a ReLU layer. And we
utilize a softmax layer as the output layer. For the optimizer, we
employ Stochastic Gradient Descent (SGD) with a learning rate of
0.01 and a momentum of 0.7. Besides, we use cross entropy as the
loss function and the model is trained for 20 epochs.
In the paper, members are recommended by Item, LFM and NCF
while non-members are recommended by the popularity recom-
mendation algorithm. Note that, Item and the popularity recom-
mendation algorithm do not need the iterative process of updating
parameters. The detailed model configurations of LFM and NCF are
shown as follows:
• LFM. We adopt the SGD algorithm to update parameters
with a learning rate of 0.01 and conduct LFM with a regular-
ization coefficient of 0.01 to enhance the model’s generaliza-
tion ability. Then we train the model for 20 epochs.
• NCF. We use Adam as the optimizer with a learning rate of
0.001. And we build the MLP part with 3 hidden layers con-
taining 64, 32 and 16 hidden units respectively. Meanwhile,
the embedding size of the Generalized Matrix Factorization
(GMF) part is 8 [16]. In addition, the number of negative sam-
ples corresponding to per positive sample is set to 4. Then
we train the model for 20 epochs with a batch size of 256.
Table 1: Notations for different settings. “∗” stands for any
algorithm or dataset used to construct or train the shadow
or target model.
Notation
A∗
L∗
M∗
∗I
∗L
∗N
AI∗∗
∗∗AI
AIMN
Illustrations
Trained on the ADM dataset.
Trained on the lf-2k dataset.
Trained on the ml-1m dataset.
Implemented by Item algorithm.
implemented by LFM algorithm.
implemented by NCF algorithm.
The shadow recommender is implemented
by Item algorithm on the ADM dataset.
The target recommender is implemented
by Item algorithm on the ADM dataset.
The shadow recommender is implemented
by Item algorithm on the ADM dataset, and
the target recommender is implemented by
NCF algorithm on the ml-1m dataset.
Figure 3: The attack performances under the assumption I.
In the experiments, there are two kinds of combinations in the
paper (i.e., 2-letter and 4-letter combinations). For the 2-letter combi-
nations, the first letter, i.e., “A,” “L” or “M”, indicates the shadow (or
target) dataset, and the second letter, i.e., “I,” “L” and “N”, indicates
the recommendation algorithm. For the 4-letter combinations, the
first two letters represent the dataset and algorithm of the shadow
recommender and the last two letters denote the dataset and algo-
rithm of the target recommender. For instance, “AIMN” means that
the adversary establishes a shadow recommender with Item on the
ADM dataset to attack a target recommender implemented by NCF
on the ml-1m dataset.
Notations. To clarify the experimental settings, notations are
demonstrated in Table 1, where “∗” stands for any algorithm or
dataset used to construct or train the shadow or target model. For ex-
ample, “A∗” could be the combination of “ADM+Item”, “ADM+LFM”
or “ADM+NCF”. Note that, not all possible combinations are listed
due to the space limit.
3.2 Recommendation Performance
We adopt HR@𝑘 as the metric to evaluate the recommendation
performance, where 𝑘 = 100 is consistent with the experimental
setting and Hit Rate (HR) presents the proportion of recommen-
dations including the ground truth. We can see from the results
in Table 2 that, in general, recommender systems achieve the best
AIAIALALANANLILILLLLLNLNMIMIMLMLMNMN0.00.20.40.60.81.0AUCOurAttackRandomGuessSession 3C: Inference Attacks CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea869Table 2: The HR@100 of the shadow and target recom-
menders.
ADM
shadow
target
lf-2k
shadow
target
ml-1m
shadow
target
Item
0.222
0.224
Item
0.652
0.650
Item
0.943
0.951
LFM
0.119
0.204
LFM
0.478
0.468
LFM
0.856
0.860
NCF
0.116
0.123
NCF
0.625
0.637
NCF
0.721
0.713
Table 3: The AUC of the attack model against the ADM
dataset, under the assumption II.
Shadow
Algorithm
Item
LFM
NCF
Item
0.926
0.843
0.513
Target Algorithm
LFM
0.885
0.775
0.494
NCF
0.750
0.554
0.987
Table 4: The AUC of the attack model against the lf-2k
dataset, under the assumption II.
Shadow
Algorithm
Item
LFM
NCF
Item
0.939
0.732
0.827
Target Algorithm
LFM
0.796
0.777
0.809
NCF
0.793
0.774
0.916
Table 5: The AUC of the attack model against the ml-1m
dataset, under the assumption II.
Shadow
Algorithm
Item
LFM
NCF
Item
0.998
0.931
0.976
Target Algorithm
LFM
0.792
0.871
0.914
NCF
0.706
0.670
0.998
performance on the ml-1m dataset. Specifically, the shadow recom-
mender obtains a hit rate of 0.856 when using LFM on the ml-1m
dataset.
3.3 Attack Performance
We perform experiments on the ADM, lf-2k and ml-1m datasets with
three typical recommendation algorithms, including Item, LFM and
NCF. Experimental results show that our method is able to achieve
strong attack performances. We draw the following conclusions:
First of all, the target recommender’s dataset
Assumption I.
distribution and algorithm are available. And, in the paper, these
information is the most knowledge that the adversary can gain from
the target recommender. The complete results are shown in Figure 3,
in which we compare our attack with Random Guess. Then, data