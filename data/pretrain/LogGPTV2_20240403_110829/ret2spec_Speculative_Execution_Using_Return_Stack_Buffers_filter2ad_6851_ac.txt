pages to leak data from the victim (using Flush+Reload [38]).
Victim: simulates the behavior of bash, i.e., waits for new
keystrokes and handles them when they are available.
We replicate the call chain similarly to bash from the
main loop to the read system call, and also return the
same values.
There are several challenges with this approach:
(1) ASLR: Given that RSBs predict virtual addresses of
jump targets, address space randomization in the vic-
tim makes tainting the RSB extremely difficult if not
impossible.
(2) Small speculation window: Since we use memory ac-
cesses as a feedback mechanism, there is a race condi-
tion between adversarial memory access in speculation
and reading the real return address off the stack.
(3) Post-Meltdown/Spectre ([22, 26]) patches: As RSBs
have already been identified as a potential future risk
that allows speculative execution, most modern OS
kernels nowadays already flush (technically, overwrite)
RSBs every time a user process switch to the kernel
occurs.
(4) Speculation gadgets: In bash, the character returned by
the read system call is moved into rax and the function
returns. We targeted this return for speculation; thus,
the required gadgets have to first shift rax at the
very least to a cache-line boundary (i.e., 6 bits to the
left), and then do a memory access relative to shared
memory (e.g., r10, which contains the return address
of the system call, pointing into libc: shl rax, 6; mov
rbx, [r10+rax])
Out of these challenges, (3) is a real limitation that cannot
be avoided. Flushing the RSB at context switches destroyed
the aforementioned attack. To show that this prophylactic
patch4 in modern OSes is indeed fundamental, we for now
assume RSBs are not flushed upon context switch. Challenge
(4) strongly depends on the compiler that was used to compile
the victim program. Therefore, each target requires its unique
set of gadgets to be found. Using an improved gadget finder,
or by scanning various dynamic libraries, we believe the issue
can be solved. For our demo, we added the required gadgets.
Limitation (2) can be overcome by using another thread that
evicts the addresses from the cache that correspond to the
victim‚Äôs stack. However, this requires revealing the address
space, i.e., challenge (1), first. We believe that our attack can
be tweaked to derandomize ASLR of other processes, but
given the fact that (3) is unavoidable, we did not further
investigate this issue. In our experiments, for simplicity, we
instead used clflush (an instruction invalidating the cache
line of the provided address) to evict the victim‚Äôs stack
addresses in order to increase the speculation time window.
4.4 Evaluation
In the following, we evaluate the efficacy of our proof-of-
concept implementation. We carried out our experiments
on Ubuntu 16.04 (kernel 4.13.0), running on Intel‚Äôs Haswell
CPU (Intel¬Æ Core‚Ñ¢ i5-4690 CPU @3.50GHz). We chose a
kernel released before the publication of Spectre, as newer
versions flush RSBs as part of their Spectre defense, and thus
interfere with our attack.
The execution environment was set according to the at-
tack description in the previous section. In the following, we
note some implementation specifics. So as to get resched-
uled after each read key, our Victim process did not use
standard input (stdin) buffering, which is in line with our
envisioned target programs bash and sudo. Additionally, a
shared memory region is mapped in Victim, which will be
shared with Measurer. In our case, it was an mmap-ed file, but
in reality this can be any shared library (e.g., libc). In order
to increase the speculation time, we used clflush in the
Victim. In practice, this has to be done by another thread
that runs in parallel to Victim and evicts the corresponding
address of the Victim‚Äôs stack. Finally, we also added the
required gadget to Victim: shl rax, 12; mov rbx, [r12 +
rax]. At the point of speculative execution (i.e., when re-
turning from read), rax is the read character and r12 points
to the shared memory region.
Measurer maps the shared (with Victim) memory in its ad-
dress space, and constantly monitors the first 128 pages (each
corresponding to an ASCII character). In our experiments,
we use Flush+Reload [38] as a feedback channel. Finally, to
be able to inject entries into Victim‚Äôs RSB, Attacker needs
to run on the same logical core as Victim. To this end, we
modify both Victim‚Äôs and Attacker‚Äôs affinities to pin them
4https://patchwork.kernel.org/patch/10150765/
to the same core (e.g., using taskset in Linux). After that,
Attacker runs in an infinite loop, pushing gadget addresses
to the RSB and rescheduling itself (sched_yield), hoping
that Victim will be scheduled afterwards.
To measure the precision of our attack prototype, we deter-
mine the fraction of input bytes that Measurer read success-
fully. To this end, we compute the Levenshtein distance [24],
which measures the similarity between the source (S) and
the destination (D) character sequences, by counting the
number of insertions, deletions, and substitutions required to
get D from S. To measure the technique for each character
in the alphabet, we used the famous pangram ‚ÄúThe quick
brown fox jumps over the lazy dog‚Äù. In the experiment, a
new character from the pangram was provided to Victim
every 50 milliseconds (i.e., 1200 cpm, to cover even very fast
typers). Running the total of 1000 sentences resulted in an
average Levenshtein distance of 7, i.e., an overall precision of
‚âà84%. It therefore requires just two password inputs to derive
the complete password entered by a user using RSB-based
speculative execution.
5 SPECULATIVE EXEC. IN BROWSERS
The cross-process attack presented in Section 4 has demon-
strated how a victim process might accidentally leak secrets
via RSB-based misspeculations. In this section, we consider
a different setting with just a single process, in which a
sandbox-contained attacker aims to read arbitrary memory
of a browser process outside of their allowed memory bounds.
5.1 Threat Model
Scripting environments in web browsers have become ubiq-
uitous. The recent shift towards dynamic Web content has
led to the fact that web sites include a plenitude of scripts
(e.g., JavaScript, WebAssembly). Browser vendors thus op-
timize script execution as much as possible. For example,
Just-in-Time (JIT) compilation of JavaScript code was a
product of this demand, i.e., compiling JavaScript into na-
tive code at runtime. Yet running possibly adversarial na-
tive code has its own security implications. Multiple attacks
have been proposed abusing JIT compilation for code injec-
tion [4, 27, 28, 35]. Consequently, browser vendors strive to
restrict their JIT environments as much as possible. One
such restriction, which our attack can evade, is sandboxing
the generated JIT code such that it cannot read or write
memory outside the permitted range. For example, browsers
compare the object being accessed and its corresponding
bounds. Any unsanitized memory access would escape such
checks, and thus enable adversaries to read browser-based
secrets or to leak data from the currently (or possibly all)
open tabs, including their cross-origin frames. Even in the
face of site isolation (i.e., one process per site), an adversary
can still gather code pointers to break ASLR, e.g., to identify
gadgets for privilege escalation (e.g., sandbox escapes) via
code-reuse attacks.
In our threat model, we envision that the victim visits an
attacker-controlled website. The victim‚Äôs browser supports
7
JIT-compiled languages such as WebAssembly or JavaScript,
as done by all major browsers nowadays. We assume that
the browser either has a high precision timer, or the attacker
has an indirect timer source through which precise timing
information can be extracted.
5.2 WebAssembly-Based Speculation
Our second attack scenario is also based on the general prin-
ciples described in Section 3. However, in contrast to the
scenario in Section 4, victim and target share the same pro-
cess. Furthermore, the attacker can now add (and therefore
control) code that will be executed by the browser. To this
end, an attacker just has to ship JavaScript or WebAssembly
code, both of which will be JIT-compiled by off-the-shelf
browsers. For illustration purposes and to have more control
over the generated code, we focus on WebAssembly.
WebAssembly is a new assembly-like language, that is
supported by all modern browsers (Edge from version 16,
Chrome from 57, Firefox from 52, and Safari from 11.2)5. As
it is already low-level, compiling WebAssembly bytecode into
native code is very fast. The key benefit of WebAssembly is
that arbitrary programs can be compiled into it, allowing
them to run in browsers. The currently proposed WebAssem-
bly specification considers 4 GiB accessible memory. This
makes sandboxing the generated code easier. For example,
in Firefox, usually a single register (r15 in x86) is dedicated
as the pointer to the beginning of the memory, called the
WebAssembly heap. Consequently, all the memory is accessed
relative to the heap. To restrict all possible accesses into the
4 GiB area, Firefox generates code that uses 32-bit x86 regis-
ters for encoding the offset. As a result, modifying a 32-bit
register in x86-64 will zero the upper bits (e.g., add eax, 1
will set the upper 32 bits of rax to 0).
For our browser-based attack, we leverage cyclic RSBs to
trigger misspeculation. More precisely, we define two recursive
functions ùê¥ and ùêµ, as shown in Figure 2. In step (1), ùê¥ calls
itself ùëÅùê¥ times and then calls ùêµ in step (2). In step (3), ùêµ
then calls itself recursively ùëÅùêµ times, ùëÅùêµ being the size of
the RSB in this case. The function ùêµ follows two purposes.
First, being a recursive function, ùêµ will overwrite all RSB
entries with return addresses pointing to the instruction in
ùêµ following its recursive call. Second, ùêµ includes code right
after calling itself to leak sensitive data using speculative
execution in the context of ùê¥. In step (4), ùêµ returns ùëÅùêµ
times to itself, consuming all ùëÅùêµ entries of the RSB. However,
since the RSB is cyclic, all the entries still remain there. At
this point, the return instruction in step (5) returns from
ùêµ to ùê¥ and triggers the first misprediction. In step (6), ùëÅùê¥
more returns will be executed, all of them mispredicting ùêµ as
the return target. The state of the RSB (shortened to ùëÅ = 4)
after each of these steps is also depicted in Figure 2.
5.3 Reading Arbitrary Memory
Compiling functions like those in Figure 2 into WebAssembly
bytecode will result in arbitrary speculation of the generated
5https://caniuse.com/#feat=wasm
Figure 2: Cyclic RSB with recursive functions A and B. Dashed
arrows show mispredicted returns, solid ones actual returns.
return & bytearray [ bytearray [loc [0]  0)
4
5
6
7 }
8 uint64_t A( int rec_N ) {
9
10
11
12
13
14
15
16 }
uint_64 res = 0;
if( rec_N > 0)
res += *B (16) ;
res += A(rec_N -1);
// <-- speculation context
else
return ADDRESS ; // attacker - controlled value
Listing 1: Arbitrary memory read in speculation
native code. As a next step, we need to generate speculated
code that leaks memory outside of the sandboxed memory
region. The key observation here is that whenever we trigger
a speculation, we execute instructions of one function in the
context of another. For example, in the case of the functions
A and B from Figure 2, after returning from B to A, code of
function B will be executed, while the register values will
stem from A. This confusion of contexts allows evasion of
defenses that are in place to sandbox JIT-compiled code. As
a simple example of context confusion, consider the following
instruction accessing memory: mov rbx, [rax]. In normal
execution, rax will always be sanitized, e.g., by using 32-
bit registers for offset calculation. However, in speculation,
triggered by another function (e.g., mov rax, 0x12345678;
ret), rax can be set to an arbitrary value, thus reading the
data at an arbitrary memory location.
8
A(1) call A(6) retB(3) call B(4) retùëÅùê¥(5) ret(2) call BùëÅùê¥ùëÅùêµùëÅùêµùëÅùê¥(5')(6')AAAAAAAABBBBBBBBBBBB(1)(2)(3)(4)(5)...
al , [ r15 + rax ] ; r15 =heap , rax = ADDRESS
eax , 12
al , [ r15 + rax ] ; report back the byte
1 B:
2 call B
3 mov
4 shl
5 mov
6
7 A:
...
8 mov
rax , ADDRESS
9 ret
; trigger speculation in A, at line 3
10 ; rax = ADDRESS will be used in speculation
; eax = leaked byte
Listing 2: Disassembly of functions A and B (important parts)
We will use these basic principles to generate speculative
code that reads arbitrary memory contents‚Äînotably outside
of the sandboxed region. To this end, we extend the general
concept presented in Figure 2 and derive WebAssembly code
that emits the required instructions after compilation (List-
ing 1). The key concept here stays the same: function A calls
itself recursively rec_N times before calling B, which then
recursively calls itself 16 times in order to fill up the RSB.
After 16 returns from B, A will return rec_N times, each time
triggering the speculation of instructions following the call
statement in B, notably with the register contents of A.
The disassembly of the compiled functions A and B from
Listing 1 are shown in Listing 2. After executing 16 returns
from B (all with correct return prediction), execution reaches
function A. In A, the return value (rax) is set (line 8) and
the function returns (line 9). At this point, as RSB was
underflowed by executing 16 returns, the return address is
mispredicted. Namely, RSB‚Äôs top entry will point to B (line
3). While the correct return address is being read from the
stack, lines 3 onwards are being executed speculatively. The
initial memory read operation (line 3) assumes a return value
(rax) to be set by B, which is supposed to be sanitized. The
base address, r15, is a fixed pointer to WebAssembly‚Äôs heap,
which is also assumed to remain the same. However, in our
case, rax was set in A with the attacker-controlled value. This