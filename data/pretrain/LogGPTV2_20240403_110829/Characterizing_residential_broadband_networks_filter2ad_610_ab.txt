10 ms and 30 ms, and the remote host responded with small
(∼ 40-byte) TCP RST packets. This packet train did not
saturate the downstream or upstream links.
2We used 1,488-byte probes because some DSL links running
PPPoE or PPPoA have an MTU of less than 1,500 bytes.
3.3 Measured broadband link properties
Our measurements rely on a simplifying assumption: that
the broadband access link is the only bottleneck along the In-
ternet path between our measurement hosts and the remote
broadband hosts (Figure 2). We validate this assumption in
the next section. This section describes how we measured
the properties of the broadband links based on this assump-
tion.
Link bandwidth: To estimate the allocated downstream
bandwidth, we calculated the fraction of answered probes in
the large-TCP ﬂood, which saturates the downstream link
only. For example, we estimate the downstream bandwidth
of a link to be 6 Mbps when 60% of packets in our 10 Mbps
large-TCP ﬂood are answered. We used the same technique
to estimate upstream bandwidths from the symmetric large-
ICMP ﬂood. The behavior of the large-ICMP ﬂood is driven
by the bandwidth of the slower link, which for cable and DSL
is the upstream link.
Our techniques yield incorrect estimates in the presence of
cross-traﬃc. We use IPID-based techniques described in [23]
to identify and eliminate all measurement probes aﬀected by
cross-traﬃc.
Packet latencies and jitter: We characterized three types
of packet delays and their variation (jitter) for each link:
queueing delay, propagation delay, and transmission delay.
We estimated the maximum possible queueing delays (or
queue lengths) by calculating the variation in RTTs of pack-
ets in our ﬂoods. To determine downstream queue lengths,
we calculated the diﬀerence between the 95th percentile
highest RTTs and minimum RTTs of packets in the large-
TCP ﬂood, which overﬂows only the downstream router
queues. A similar calculation for the large-ICMP ﬂood,
which overﬂows queues in both directions, estimated the sum
of downstream and upstream queue lengths. We subtracted
the downstream queue length from this estimate to obtain
the length of the upstream queue.
To study propagation delays of broadband links, we esti-
mated their last-hop delays. We calculated last-hop delay
as the diﬀerence between the latencies of small-TCP trickle
probes to the broadband host and to its last-hop router. By
comparing the last-hop delays for diﬀerent packet sizes, we
were able to infer the transmission delays in broadband links.
We discuss transmission delays in more detail in Section 4.2.
Packet loss: We estimated typical packet loss rates in
broadband networks by calculating the fraction of lost pack-
ets in the small-TCP trickle. To detect packet loss due to
queue management policies, such as RED, we examined how
the loss rate varies with the latencies of the packets. We
discuss the details of RED detection in Section 4.3.
3.4 Validating our assumptions
Next, we discuss ﬁve important concerns about our method-
ology:
1. To be accurate, our probes must traverse the entire In-
ternet path reaching the broadband host and not be
answered by an intermediate router. Do our measure-
ments reﬂect accurately the properties of broadband ac-
cess links?
2. We assumed that the broadband links are the bottle-
necks in the measured Internet paths. How often are
broadband links the bottlenecks along the measured In-
ternet paths?
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
1
0.8
0.6
0.4
0.2
0
Broadband hosts
Last-hop
routers
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
1
0.8
0.6
0.4
0.2
0
Last-hop
routers
Broadband hosts
Last-hop
routers
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
1
0.8
0.6
0.4
0.2
0
Broadband hosts
0
2,000
4,000
6,000
8,000
10,000
12,000
0
100
200
300
400
500
0%
20%
Available bandwidth (Kbps)
Increase in RTT (milliseconds)
60%
40%
Packet loss rate
80%
100%
Figure 3: The broadband link is the bottleneck: Comparison of the paths to the residential broadband hosts and their
corresponding last-hop routers. The former include the broadband link, while the latter do not. The two sets of paths have
very diﬀerent characteristics, which validates our assumption that broadband links are the bottlenecks along the Internet paths
to broadband hosts.
3. We assumed broadband hosts respond to all probes
without any delay. In practice, end hosts could drop
or rate limit their responses. How often do broadband
hosts delay or drop response packets?
4. Our probes can be interpreted as port scans or attacks.
What are the best practices we used in our measure-
ments?
5. Large-scale Internet studies suﬀer from limitations and
shortcomings. What are some of the limitations of our
study?
3.4.1 Do our measurements reﬂect accurately the
properties of broadband access links?
We ran controlled experiments using ﬁve broadband hosts
(two cable and three DSL) under our control, located in
North America and Europe. These experiments were per-
formed on a small scale because they required end-host co-
operation. Although we hoped to recruit more volunteers,
the eﬀort required to setup our experiments made it diﬃcult
to convince users to perform them. Our experiments require
root access and manual changes to the modems’ ﬁrewalls.
First, we checked whether the probe packets were being
sent over the broadband link or whether they were being
answered by a router in the middle of the network. We
found that in all cases the probes were being responded to
by the NAT-enabled modems in the customers’ premises.
By conﬁguring the modems to forward any arriving probe
packets to end hosts, we were able to receive the probes at
our end hosts (Figure 2). Note that the probes must cross
the broadband link to reach the modems.
Second, we checked whether the NAT-enabled modems
aﬀected the measurements by delaying or rate-limiting their
responses. We gathered two traces for each link: one when
the modem responded to the probes, and another when the
modem forwarded all probes to the broadband hosts. We
conﬁgured the broadband hosts to respond to the probes
without any delay (less than 100 µs) or rate-limiting. We
compared the two traces with respect to latencies and losses
of probes and responses. The two traces matched closely in
all cases, suggesting that the modems do not adversely aﬀect
our measurements.
Finally, we veriﬁed the accuracy of our bandwidth and
queue length measurements. We compared the measured
bandwidths of the access links with the rate speeds ad-
vertised by their ISPs. We found that these bandwidths
matched very closely – the average diﬀerence in downstream
bandwidths was less than 3%. To validate our queue length
estimates, we used our access to the end hosts to measure
the upstream and downstream queue lengths separately and
accurately. The measurements matched the estimated queue
lengths very well. The close match suggests that both our
bandwidth and queue length measurements are accurate.
3.4.2 How often are broadband links the bottlenecks
along the measured Internet paths?
Our methodology assumes the broadband link is the bottle-
neck on the Internet path measured. Because our probes
are sent from well-connected academic hosts, the broadband
links are likely to be the bottlenecks in these paths. To
validate this assumption, we sent a large-TCP ﬂood probe
train to the broadband host and another train to its last-hop
router. Comparing these two probe trains revealed that the
broadband links are in fact the bottlenecks.
Figure 3 compares the available bandwidth, the RTT in-
creases, and the packet loss rate of the two traces for 1,173
randomly selected broadband hosts. Most paths to the last-
hop routers achieved the full 10 Mbps throughput, experienc-
ing almost no losses or RTT ﬂuctuations. By contrast, the
paths including the broadband link had much lower through-
put, considerable RTT increases, and high packet loss. This
suggests that these variations are caused by the last hop (i.e.,
the broadband link).
3.4.3 How often do broadband hosts delay or drop
response packets?
Our methodology assumes broadband hosts respond to
probes without any delay. Several factors could prevent
hosts from responding to some or all of our probes. For
example, a ﬁrewall may block certain types of probes, such
as PINGs. Some routers add a delay between the arrival of
a probe and the departure of the response [21]. Also, a host
with limited processing power might delay or drop packets
arriving at high rates.
We removed all hosts that did not respond to our probes.
We also removed the broadband hosts that rate-limited their
probe responses. We identiﬁed such hosts by checking for
large loss episodes occurring periodically.
Finally, we performed the following experiment to check
whether our probe trains were too aggressive for the process-
ing power of some hosts. We sent probe trains at 10 Mbps
but with varying packet sizes. Although the trains consumed
the same bandwidth, their packet sending rates were diﬀer-
ent. We checked whether hosts experienced higher losses at
faster sending rates. A higher loss rate suggests that an end
host cannot process packets at fast rates. We checked how
Qwest
BT Broadband
PacBell
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
Ameritech
SWBell
BellSouth
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
Charter
Comcast
Chello
Rogers
Road Runner
0
0
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
0
0
1,000
2,000
4,000
Allocated link bandwidth (Kbps)
3,000
(a) DSL (downstream)
5,000
6,000
0
0
2,000
4,000
6,000
8,000
10,000
Allocated link bandwidth (Kbps)
(b) Cable (downstream)
BellSouth
Qwest
Ameritech
PacBell
BT Broadband
SWBell
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
Charter
Rogers
Road
Runner
Chello
Comcast
500
1,000
1,500
2,000
Allocated link bandwidth (Kbps)
(c) DSL (upstream)
0
0
500
1,000
2,000
Allocated link bandwidth (Kbps)
1,500
(d) Cable (upstream)
2,500
3,000
Figure 4: Allocated downstream and upstream link bandwidths: Most ISPs oﬀer upstream bandwidths of 500 Kbps
or less, even when the downstream bandwidths exceed 5 Mbps.
losses vary with packet sending rates for all broadband hosts
in our study. The loss rates remained constant for over 99%
of the hosts in our study, suggesting that the end hosts have
suﬃcient processing power to handle our probing rates.
3.4.4 What are the best practices we adopted?
Performing active measurements on the Internet raises im-
portant usage concerns. Although it is diﬃcult to address
and eliminate all such concerns, we adopted a set of precau-
tions to mitigate these concerns. We restricted our high rate
probe trains to no more than 10 s each. We also embedded
a custom message in each of our probe packets, which de-
scribed the experiment and included a contact email address.
To date, we have not received any complaints.
Another cause for concern was that users with a per-byte
payment model end up paying for our unsolicited traﬃc. To
mitigate this concern, we only measured hosts in ISPs that
oﬀer ﬂat-rate payment plans, and we restricted the total
amount of data sent to any single broadband host over our
entire study.
3.4.5 What are some of the limitations of our study?
Two important limitations aﬀect our measurements. First,
we studied only major cable and DSL ISPs in North Amer-
ica and Europe. Our conclusions are unlikely to generalize
to high-speed ﬁber-based broadband ISPs, such as those in
Japan or South Korea [12]. Second, we removed all hosts
that did not respond to our probes or that were rate-limited,
which could introduce some unknown bias.
4. CHARACTERIZING BROADBAND
LINKS
In this section, we analyze the data gathered from sending
probe packet trains to a large number of residential broad-
band hosts in several major ISPs (see Table 1). We exam-
ine three important characteristics of broadband networks,
namely link bandwidths, packet latencies, and packet loss.
Analyzing these properties is important because they af-
fect the performance of protocols and systems running over
broadband.
4.1 Allocated link bandwidth
Allocated link bandwidth refers to the bandwidth reserved
by a provider to a single broadband user. In cable networks,
allocated link bandwidth is the portion of the shared link’s
capacity assigned to an individual user, whereas in DSL net-
works it is the ISP’s cap on a user’s traﬃc rate. Characteriz-
ing allocated link bandwidths in broadband networks helps
to predict the maximum throughput any transport proto-
col (such as TCP Reno or TCP Vegas) or application (such
as BitTorrent) can achieve. As described in Section 3.3, our
probe streams measured allocated bandwidths by saturating
the broadband links.
4.1.1 What are the allocated link bandwidths?
Figures 4(a) and (b) show the cumulative distributions of