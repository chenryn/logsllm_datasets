title:Secure Multi-Party Computation
author:Fattaneh Bayatbabolghani and
Marina Blanton
Secure Multiparty Computation (MPC)
Yehuda Lindell
Unbound Tech and Bar-Ilan University
PI:EMAIL,PI:EMAIL
Abstract. Protocols for secure multiparty computation (MPC) enable a set of parties to
interact and compute a joint function of their private inputs while revealing nothing but the
output. The potential applications for MPC are huge: privacy-preserving auctions, private
DNA comparisons, private machine learning, threshold cryptography, and more. Due to this,
MPC has been an intensive topic of research in academia ever since it was introduced in the
1980s by Yao for the two-party case (FOCS 1986), and by Goldreich, Micali and Wigderson
for the multiparty case (STOC 1987). Recently, MPC has become eﬃcient enough to be used
in practice, and has made the transition from an object of theoretical study to a technology
being used in industry. In this article, we will review what MPC is, what problems it solves,
and how it is being currently used.
We note that the examples and references brought in this review article are far from compre-
hensive, and due to the lack of space many highly relevant works are not cited.
1
Introduction
Distributed computing considers the scenario where a number of distinct, yet connected, computing
devices (or parties) wish to carry out a joint computation of some function. For example, these
devices may be servers who hold a distributed database system, and the function to be computed
may be a database update of some kind. The aim of secure multiparty computation is to enable
parties to carry out such distributed computing tasks in a secure manner. Whereas distributed
computing often deals with questions of computing under the threat of machine crashes and other
inadvertent faults, secure multiparty computation is concerned with the possibility of deliberately
malicious behaviour by some adversarial entity (these have also been considered in the distributed
literature where they are called Byzantine faults). That is, it is assumed that a protocol execution
may come under “attack” by an external entity, or even by a subset of the participating parties.
The aim of this attack may be to learn private information or cause the result of the computation
to be incorrect. Thus, two important requirements on any secure computation protocol are privacy
and correctness. The privacy requirement states that nothing should be learned beyond what is ab-
solutely necessary; more exactly, parties should learn their output and nothing else. The correctness
requirement states that each party should receive its correct output. Therefore, the adversary must
not be able to cause the result of the computation to deviate from the function that the parties
had set out to compute.
Secure multiparty computation can be used to solve a wide variety of problems, enabling the
utilisation of data without compromising privacy. Consider, for example, the problem of comparing
a person’s DNA against a database of cancer patients’ DNA, with the goal of ﬁnding if the person
is in a high risk group for a certain type of cancer. Such a task clearly has important health
and societal beneﬁts. However, DNA information is highly sensitive, and should not be revealed to
private organisations. This dilemma can be solved by running a secure multiparty computation that
reveals only the category of cancer that the person’s DNA is close to (or none). In this example, the
privacy requirement ensures that only the category of cancer is revealed, and nothing else about
anyone’s DNA (neither the DNA of the person being compared nor the DNA of the patients in
the database). Furthermore, the correctness requirement guarantees that a malicious party cannot
change the result (e.g., make the person think that they are at risk of a type of cancer, and therefore
need screening).
In another example, consider a trading platform where parties provide oﬀers and bids, and are
matched whenever an oﬀer is greater than a bid (with, for example, the price of the trade being
some function of the oﬀer and bid prices). In such a scenario, it can be beneﬁcial from a game
theoretic perspective to not reveal the parties’ actual oﬀers and bids (since this information can be
used by others in order to artiﬁcially raise prices or provide bids that are lower than their utility).
Privacy here guarantees that only the match between buyer and seller and the resulting price is
revealed, and correctness would guarantee that the price revealed is the correct one according to the
function (and not some lower value, for example). It is interesting to note that in some cases privacy
is more important (like in the DNA example), whereas in others correctness is more important (like
in the trading example). In any case, MPC guarantees both of these properties, and more.
A note on terminology. In the literature, beyond secure multiparty computation (with acronym
MPC, and sometimes SMPC), there are also references to secure function evaluation (SFE). These
notions overlap signiﬁcantly, and are often used synonymously. In addition, special cases of MPC of-
ten have their own names. Two examples are private set intersection (PSI) which considers the secure
computation of the intersection of private sets, and threshold cryptography which considers the se-
cure computation of digital signatures and decryption, where no single party holds the private key.
2 Security of MPC
2.1 The Deﬁnitional Paradigm
As we have mentioned above, the setting that we consider is one where an adversarial entity controls
some subset of the parties and wishes to attack the protocol execution. The parties under the control
of the adversary are called corrupted, and follow the adversary’s instructions. Secure protocols should
withstand any adversarial attack (where the exact power of the adversary will be discussed later).
In order to formally claim and prove that a protocol is secure, a precise deﬁnition of security
for multiparty computation is required. A number of diﬀerent deﬁnitions have been proposed and
these deﬁnitions aim to ensure a number of important security properties that are general enough
to capture most (if not all) multiparty computation tasks. We now describe the most central of
these properties:
1. Privacy: No party should learn anything more than its prescribed output. In particular, the
only information that should be learned about other parties’ inputs is what can be derived
from the output itself. For example, in an auction where the only bid revealed is that of the
highest bidder, it is clearly possible to derive that all other bids were lower than the winning
bid. However, nothing else should be revealed about the losing bids.
2. Correctness: Each party is guaranteed that the output that it receives is correct. To continue
with the example of an auction, this implies that the party with the highest bid is guaranteed
to win, and no party including the auctioneer can inﬂuence this.
3. Independence of Inputs: Corrupted parties must choose their inputs independently of the honest
parties’ inputs. This property is crucial in a sealed auction, where bids are kept secret and parties
must ﬁx their bids independently of others. We note that independence of inputs is not implied
by privacy. For example, it may be possible to generate a higher bid, without knowing the value
of the original one. Such an attack can actually be carried out on some encryption schemes
(i.e., given an encryption of $100, it is possible to generate a valid encryption of $101, without
knowing the original encrypted value).
4. Guaranteed Output Delivery: Corrupted parties should not be able to prevent honest parties
from receiving their output. In other words, the adversary should not be able to disrupt the
computation by carrying out a “denial of service” attack.
5. Fairness: Corrupted parties should receive their outputs if and only if the honest parties also
receive their outputs. The scenario where a corrupted party obtains output and an honest party
does not should not be allowed to occur. This property can be crucial, for example, in the case
of contract signing. Speciﬁcally, it would be very problematic if the corrupted party received
the signed contract and the honest party did not. Note that guaranteed output delivery implies
fairness, but the converse is not necessarily true.
We stress that the above list does not constitute a deﬁnition of security, but rather a set of require-
ments that should hold for any secure protocol. Indeed, one possible approach to deﬁning security
is to just generate a list of separate requirements (as above) and then say that a protocol is secure
if all of these requirements are fulﬁlled. However, this approach is not satisfactory for the following
reasons. First, it may be possible that an important requirement was missed. This is especially true
because diﬀerent applications have diﬀerent requirements, and we would like a deﬁnition that is
general enough to capture all applications. Second, the deﬁnition should be simple enough so that
it is trivial to see that all possible adversarial attacks are prevented by the proposed deﬁnition.
The standard deﬁnition today [5] therefore formalizes security in the following general way. As
a mental experiment, consider an “ideal world” in which an external trusted (and incorruptible)
party is willing to help the parties carry out their computation. In such a world, the parties can
simply send their inputs to the trusted party, who then computes the desired function and passes
each party its prescribed output. Since the only action carried out by a party is that of sending its
input to the trusted party, the only freedom given to the adversary is in choosing the corrupted
parties’ inputs. Notice that all of the above-described security properties (and more) hold in this
ideal computation. For example, privacy holds because the only message ever received by a party is
its output (and so it cannot learn any more than this). Likewise, correctness holds since the trusted
party cannot be corrupted and so will always compute the function correctly.
Of course, in the “real world”, there is no external party that can be trusted by all parties.
Rather, the parties run some protocol amongst themselves without any help, and some of them are
corrupted and colluding. Despite this, a secure protocol should emulate the so-called “ideal world”.
That is, a real protocol that is run by the parties (in a world where no trusted party exists) is said
to be secure, if no adversary can do more harm in a real execution that in an execution that takes
place in the ideal world. This can be formulated by saying that for any adversary carrying out a
successful attack in the real world, there exists an adversary that successfully carries out an attack
with the same eﬀect in the ideal world. However, successful adversarial attacks cannot be carried
out in the ideal world. We therefore conclude that all adversarial attacks on protocol executions in
the real world must also fail.
More formally, the security of a protocol is established by comparing the outcome of a real
protocol execution to the outcome of an ideal computation. That is, for any adversary attacking
a real protocol execution, there exists an adversary attacking an ideal execution (with a trusted
party) such that the input/output distributions of the adversary and the participating parties in
the real and ideal executions are essentially the same. Thus a real protocol execution “emulates”
the ideal world. This formulation of security is called the ideal/real simulation paradigm. In order to
motivate the usefulness of this deﬁnition, we describe why all the properties described above are
implied. Privacy follows from the fact that the adversary’s output is the same in the real and ideal
executions. Since the adversary learns nothing beyond the corrupted party’s outputs in an ideal
execution, the same must be true for a real execution. Correctness follows from the fact that the
honest parties’ outputs are the same in the real and ideal executions, and from the fact that in an
ideal execution, the honest parties all receive correct outputs as computed by the trusted party.
Regarding independence of inputs, notice that in an ideal execution, all inputs are sent to the trusted
party before any output is received. Therefore, the corrupted parties know nothing of the honest
parties’ inputs at the time that they send their inputs. In other words, the corrupted parties’ inputs
are chosen independently of the honest parties’ inputs, as required. Finally, guaranteed output
delivery and fairness hold in the ideal world because the trusted party always returns all outputs.
The fact that it also holds in the real world again follows from the fact that the honest parties’
outputs are the same in the real and ideal executions.
We remark that in some cases, the deﬁnition is relaxed to exclude fairness and guaranteed output
delivery. The level of security achieved when these are excluded is called “security with abort”, and
the result is that the adversary may be able to obtain output while the honest parties do not. There
are two main reasons why this relaxation is used. First, in some cases, it is impossible to achieve
fairness (e.g., it is impossible to achieve fair coin tossing for two parties [11]). Second, in some cases,
more eﬃcient protocols are known when fairness is not guaranteed. Thus, if the application does
not require fairness (and in particular in cases where only one party receives output), this relaxation
is helpful.
2.2 Additional Deﬁnitional Parameters
Adversarial power. The above informal deﬁnition of security omits one very important issue:
the power of the adversary that attacks a protocol execution. As we have mentioned, the adversary
controls a subset of the participating parties in the protocol. However, we have not deﬁned what
power such an adversary has. We describe the two main parameters deﬁning the adversary: its
allowed adversarial behaviour (i.e., does the adversary just passively gather information or can it
instruct the corrupted parties to act maliciously) and its corruption strategy (i.e., when or how
parties come under the “control” of the adversary):