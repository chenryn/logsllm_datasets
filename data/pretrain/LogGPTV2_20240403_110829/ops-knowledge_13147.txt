User: My project requires being run on several different physical machines, which have shared file system among them. One problem arising out of this is how to synchronize write to a common single file. With threads, that can be easily achieved with locks, however my program consists of processes distributed on different machines, which I have no idea how to synchronize. In theory, any way to check whether a file is being opened right now or any lock-like solutions will do, but I just cannot crack out this by myself. A python way would be particularly appreciated.
Assistant: Just a thought...
Couldn't you put a 'lock' file in the same directory as the file your trying to write to?  In your distributed processes check for this lock file.  If it exists sleep for x amount and try again.  Likewise, when the process that currently has the file open finishes the process deletes the lock file?
So if you have in the simple case 2 processes called A and B:
Process A checks for lock file and if it doesn't exist it creates the lock file and does what it needs to with the file.  After it's done it deletes this lock file.
If process A detects the lock file then that means process B has the file, so sleep and try again later....rinse repeat.