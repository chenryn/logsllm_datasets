Since we may have to check each outgoing packet (to port i) against possibly many 
suspect strings inbound to port i, we need to concern ourselves with the computational 
costs and storage required for such a strategy. On a real server machine, e.g., a web 
server, there are large numbers of incoming requests but  very  few, if any, outgoing 
requests  to  port  80  from  the  server  (to  other  servers).  So  any  outgoing  request  is 
already quite suspicious, and we should compare each of them against the suspects. If 
the  host  machine  is  used  as  both  a  server  and  a  client  simultaneously,  then  both 
incoming and outgoing requests may occur frequently. This is mitigated somewhat by 
the  fact  that  we  check  only  packets  deemed  anomalous,  not  every  possible  packet 
flowing  to  and  from  a  machine.  We  apply  the  same  modeling  technique  to  the 
outgoing traffic and only compare the egress traffic we already labeled as anomalous.  
4.2   Automatic Worm Signature Generation 
There  is  another  very  important  benefit  that  accrues  from  the  ingress/egress  packet 
content  correlation  and  string  similarity  comparison:  automatic  worm  signature 
generation. The computation of the similarity score produces the matching substring 
or subsequence which represents the common part of the ingress and egress malicious 
traffic.  This  common  subsequence  serves  as  a  signature  content-filter.  Ideally,  a 
worm  signature  should  match  worms  and  only  worms.  Since  the  traffic  being 
compared is already judged as anomalous, and has exhibited propagation behavior – 
quite different from normal behavior – and the similar malicious payload is being sent 
to the same service at other hosts, these common parts are very possibly core exploit 
strings and hence can represent the worm signature. By using LCSeq, we may capture 
even polymorphic worms since the core exploit usually remains the same within each 
worm instance even though it may be reordered within the packet datagram. Thus, by 
correlating  the  ingress  and  egress  malicious  payload,  we  are  able  to  detect  the  very 
initial  worm  propagation,  and  compute  its  signature  immediately.  Further,  if  we 
distribute these strings to collaborating sites, they too can leverage the added benefit 
of  corroborating  suspects  they  may  have  detected,  and  they  may  choose  to  employ 
content filters, preventing them from being exploited by a new, zero-day worm.  
Anomalous Payload-Based Worm Detection and Signature Generation 
239 
4.3   Evaluation 
In  this  section,  we  evaluate  the  performance  of  ingress/egress  correlation  and  the 
quality of the automatically generated signatures. 
Since  none  of  the  machines  were  attacked  by  worms  during  our  data  collection 
time  at  the  three  sites,  we  launched  real  worms  to  un-patched  Windows  2000 
machines in a controlled environment. For testing purposes, the packet traces of the 
worm  propagation  were  merged  into  the  three  sites’  packet  flows  as  if  the  worm 
infection actually  happened at each site. Since PAYL only uses payload, the source 
and target IP addresses of the merged content are irrelevant.  
Without  a  complete  collection  of  worms,  and  with  limited  capability  to  attack 
machines, we only tested CodeRed and CodeRed II out of the executable worms we 
collected. After launching these in our test environment and capturing the packet flow 
trace,  we  noticed  interesting  behavior:  after  infection,  these  two  worms  propagate 
with  packets  fragmented  differently  than  the  ones  that  initially  infected  the  host.  In 
particular,  CodeRed  can  separate  “GET.”  and  “/default.ida?”  and  “NNN…N”  into 
different  packets  to  avoid  detection  by  many  signature-based  IDSes.  The  following 
table shows the length sequences of different packet fragmentation for CodeRed and 
CodeRed II. 
Table 2. Different fragmentation for CR and CRII 
Code Red (total 4039 bytes) 
Incoming 
1448, 1448, 1143 
Code Red II (total 3818 bytes) 
Incoming 
1448, 1448, 922 
Outgoing 
1460, 1460, 898 
Outgoing 
4, 13, 362, 91, 1460, 1460, 649 
4, 375, 1460, 1460, 740 
4, 13, 453, 1460, 1460, 649 
To  evaluate  the  accuracy  of  worm  propagation  detection,  we  appended  the 
propagation trace at the very end of one full day’s network data from each of the three 
sites. When we collected the trace from our attack network, we not only captured the 
incoming  port  80  requests,  but  also  all  the  outgoing  traffic  directed  to  port  80.  We 
checked  each  dataset  manually,  and  found  there  is  a  small  number  of  outgoing 
packets for the servers that produced the datasets W and W1, as we expected, and not 
a  single  one  for  the  EX  dataset.  Hence,  any  egress  packets  to  port  80  would  be 
obviously anomalous without having to inspect their content. For this experiment, we 
captured  all  suspect  incoming  anomalous  payloads  in  an  unlimited  sized  buffer  for 
comparison across all of the available data in our test sets. We also purposely lowered 
PAYL’s threshold setting (after calibration) in order to generate a very high number 
of  suspects  in  order  to  test  the  accuracy  of  the  string  comparison  and  packet 
correlation strategies.  In other words, we increased the noise (increasing the number 
of false positives) in order to determine how well the correlation can still separate out 
the important signal in the traffic (the actual worm content).  
240 
K. Wang, G. Cretu, and S.J. Stolfo 
Table 3. Results of correlation for different metrics 
SE 
LCS(0.5) 
LCSeq(0.5) 
Detect propagate 
No 
Yes  
Yes 
False alerts 
No 
No 
No 
The  result  of  this  experiment  is  displayed  in  the  following  table  for  the  different 
similarity  metrics.  The  number  in  the  parenthesis  is  the  threshold  used  for  the 
similarity score. For an outgoing packet, PAYL checks the suspect buffer and returns 
the highest similarity score. If the score is higher than the threshold, we judge there is 
a worm propagation. False alerts suggest that an alert was mistakenly generated for a 
normal  outgoing  packet.  The  reason  why  SE  does  not  work  here  is  obvious:  worm 
fragmentation blinds the method from seeing the worm’s entire matching content. The 
other  two  metrics  worked  perfectly,  detecting  all  the  worm  propagations  with  zero 
false alerts. 
To evaluate the false alerts more carefully, we decided to use some other traffic to 
simulate the outgoing traffic of the servers. For EX data, we used the outgoing port 80 
traffic of other clients in that enterprise as if it originated from the EX server itself. 
For  the  W1  and  W  datasets,  we  used  the  outgoing  port  80  traffic  from  the  CS 
department.  Then  we  repeated  the  previous  experiments  to  detect  the  worm 
propagation with the injected outgoing traffic on each server. The result remains the 
same - using the same thresholds as before, we can successfully detect all the worm 
propagations without any false alerts. 
As  we  mentioned  earlier,  the  worm  signature  is  a  natural  byproduct  of  the 
ingress/egress correlation. When we identified a possible worm propagation, the LCS 
or  LCseq  can  be  used  as  the  worm  signature.  Figure  6  displays  the  actual  content 
signatures computed for the CR II propagations detected by PAYL in a style suitable 
for deployment in Snort. Note the signature contains some of the system calls used to 
infect  a  host,  which  is  one  of  the  reasons  the  false  positive  rate  is  so  low  for  these 
detailed signatures. 
We  replicated  the  above  experiments  in  order  to  test  if  any  normal  packet  is 
blocked when we filter the real traffic against all the worm signatures generated. For 
our experiments we used the datasets from all the three sites, which have had the CRII 
attacks cleaned beforehand, and in all cases no normal packet was blocked.  
|d0|$@|0 ff|5|d0|$@|0|h|d0| @|0|j|1|j|0|U|ff| 
5|d8|$@|0 e8 19 0 0 0 c3 ff|%`0@|0 ff|%d0@|0  
ff|%h0@|0 ff|%p0@|0 ff|%t0@|0 ff|%x0@|0 ff|%| 
0@|fc fc fc fc fc fc fc fc fc fc fc fc fc fc  
fc fc fc fc fc 0 0 0 0 0 0 0 0 0 0 0 0 0|\EXP 
LORER.EXE|0 0 0|SOFTWARE\Microsoft\Windows NT 
\CurrentVersion\Winlogon|0 0 0|SFCDisable|0 0 
 9d ff ff ff|SYSTEM\CurrentControlSet\Service 
s\W3SVC\Parameters\Virtual Roots|0 0 0 0|/Scr 
ipts|0 0 0 0|/MSADC|0 0|/C|0 0|/D|0 0|c:\,,21 
7|0 0 0 0|d:\,,217|fc fc fc fc fc fc fc fc fc 
 fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc 
… 
Fig. 6. The initial portion of the PAYL generated signature for CodeRed II 
Anomalous Payload-Based Worm Detection and Signature Generation 
241 
In  these  experiments,  we  used  an  unlimited  buffer  for  the  incoming  suspect 
payloads.  The  buffer  size  essentially  stores  packets  for  some  period  of  time  that  is 
dependent upon the traffic rate, and the  number of anomalous packet alerts that are 
generated from that traffic. That amount is indeterminate a priori, and is specific to 
both the environment being sniffed and the quality of the models computed by PAYL 
for that environment. Since CR and CR II launch their propagations immediately after 
infecting their victim hosts, a buffer holding only the most recent 5 or 10 suspects is 
enough to detect their propagation. But for slow-propagating or stealthy worms which 
might  start  propagating  after  an  arbitrarily  long  hibernation  period,  the  question  is 
how  many  suspects  should  we  save  in  the  suspect  buffer? If  the  ingress  anomalous 
payloads  have  been  removed  from  the  suspect  buffer  before  such  a  worm  starts 
propagating, PAYL can no longer detect it by correlation. Theoretically, the larger the 
buffer the better, but there is tradeoff in memory usage and computation time. But for 
those worms that may hibernate for a long period of time, cross-site collaboration and 
exchange of suspect packet payloads might provide a solution. We discuss this in the 
next section.  
5   Anomalous Payload Collaboration Among Sites 
Most current attack detection systems are constrained to a single ingress point within 
an  enterprise  without  sharing  any  information  with  other  sites.  There  are  ongoing 
efforts that share suspicious source IP address [5, 10], but to our knowledge no such 
effort exists to share content information across sites in real time until now. Here we 
focus  on  evaluating  the  detection  accuracy  of  using  collaboration  among  sites, 
assuming  a  scaleable,  privacy-preserving  secured  communication  infrastructure  is 
available. (We have implemented a prototype in Worminator [10].) 
Recall that, in Section 3.4, we described experiments measuring the diversity of the 
models computed at multiple sites. As we saw, the different sites tested have different 
normal  payload  models.  This  implies  from  a  statistical  perspective  that  they  should 
also  have  different  false  positive  alerts.  Any  “common  or highly  similar  anomalous 
payloads” detected among two or more sites logically would be caused by a common 
worm  exploit  targeting  many  sites.    Cross-site  or  cross-domain  sharing  may  thus 
reduce the false positive problem at each site, and may more accurately identify worm 
outbreaks in the earliest stages of an infection.  
To test this idea, we used the traffic from the three sites. There are two goals we 
seek  to  achieve  in  this  experiment.  One  is  to  test  whether  different  sites  can  help 
confirm with each other that a worm is spreading and attacking the Internet. The other 
is  to  test  whether  false  alerts  can  be  reduced,  or  even  eliminated  at  each  site  when 
content alerts are correlated.  
In this experiment, we used the following simple correlation rule: if two alerts from 
distinct sites are similar, the  two alerts are considered true  worm attacks; otherwise 
they  are  ignored.  Each  site’s  content  alerts  act  as  confirmatory  evidence  of  a  new 
worm  outbreak,  even  after  two  such  initial  alerts  are  generated.  This  is  very  strict, 
aiming for the optimal solution to the worm problem.  
This is a key observation. The optimal result we seek is that for any payload alerts 
generated from the same worm launched at two ore more sites, those payloads should 
242 
K. Wang, G. Cretu, and S.J. Stolfo 
be  similar  to  each  other,  but  not  for  normal  data  from  either  site  that  was  a  false 
positive. That is to say, if a site generates a false positive alert about normal traffic it 
has  seen,  it  will  not  produce suspect  payloads  that  any  other  site  will  deem  to  be  a 
worm propagation. Since we conjectured that each site’s content models are diverse 
and highly distinct, even the false positives each site may generate will not match the 
false  positives  of  other  sites;  only  worms  (i.e.,  true  positives)  will  be  commonly 
matched as anomalous data among multiple sites.  
To make the experiment more convincing, we no longer test the same worm traffic 
against each site as in the previous section, since the sensor will obviously generate 
the  exact  same  payload  alert  at  all  the  sites.  Instead,  we  use  multiple  variants  of 
CodeRed  and  CodeRed  II,  which  were  extracted  from  real  traffic.  To  make  the 
evaluation strict, we tested different packet payloads for the same worm, and all the 
variant packet fragments it generates. We purposely lowered the PAYL threshold to 
generate many more false positives from each site than it otherwise would produce.  
As in the case described above the cross-site correlation uses the same metrics (SE, 
LCS  and  LCSeq)  to  judge  whether  two  payload  alerts  are  “similar”.    However, 
another  problem  that  we  need  to  consider  when  we  exchange  information  between 
sites is privacy. It may be the case that a site is unwilling to allow packet content to be 
revealed to some external collaborating site. A false positive may reveal true content.  
A  packet  payload  could  be  presented  by  its  1-gram  frequency  distribution  (see 
Figure 2). This representation already aggregates the actual content byte values in a 
form making it nearly impossible (but not totally impossible) to reconstruct the actual 
payload.  (Since  byte  value  distributions  do  not  contain  sequential  information,  the 
actual content is hard to recover. 2-gram distributions simplify the problem making it 
more likely to recover the content since adjacent byte values are represented. 3-grams 
nearly make the problem trivial to recover the actual content in many cases.)  
However,  we  note  that  the  1-gram  frequency  distribution  reordered  into  the  rank-
ordered frequency distribution produces a distribution that appears quite similar to the 
exponential decreasing Zipf-like distribution. The rank ordering of the resultant distinct 
byte  values  is  a  string  that  we  call  the  “Z-string”  (as  discussed  in  Section  3.1).  One 
cannot  recover  the  actual  content  from  the  Z-String.  Rather,  only  an  aggregated 
representation  of  the  byte  value  frequencies  is  revealed,  without  the  actual  frequency 
information. This representation may convey sufficient information to correlate suspect 
payloads, without revealing the actual payload itself. Hence, false positive content alerts 
would not reveal true content, and privacy policies would be maintained among sites.  
In  this  cross-domain  correlation  experiment  we  propose  two  more  metrics  which 
don’t require exchanging raw payloads, but instead only the 1-gram distributions, and 
the privacy-preserving Z-string representation of the payload: 
Manhattan  distance  (MD):  Manhattan  distance  requires  exchange  of  the  byte 
distribution of the packet, which has 256 float numbers. Two payloads are similar if 
they have a small Manhattan distance.  The maximum possible MD is 2. So we define 
the similarity score as (MD)/2, to normalize the score range to the same range of the 
other metrics described above. 
LCS of Z-string (Zstr): While maintaining maximal privacy preservation, we perform 
the LCS on the Z-string of two alerts. The similarity score is the same as the one for LCS, 
but here the score evaluates the similarity of two Z-strings, not the raw payload strings. 
Anomalous Payload-Based Worm Detection and Signature Generation 
243 
Figure  7  presents  the  results  achieved  by  sharing  PAYL  alerts  among  the  three 
sites using CR and CR II and their variant packet fragments. The results are shown in 
terms of the similarity scores computed by each of the metrics. Each plot is composed 
of  two  different  representations:  one  for  false  alerts  (histogram)  and  the  other  for 
worm alerts (dots on the x-axis). The bars in the plots are histograms for the similarity 
scores computed for false PAYL alerts. The x-axis shows the similarity score, defined 
within the range [0...1], and the y-axis is the number of pairs of alerts within the same 
score range. The similarity scores for the worm alerts are shown separately as dots on 
the  x-axis.  The  worm  alerts  include  those  for  CR  and  CR  II  and  their  variant 
fragments. Note that all of the scores calculated between worm alerts are much higher 
than  those  of  the  “false”  PAYL  alerts  and  thus  they  would  be  correctly  detected  as 
true worms among collaborating sites. The alerts that scored too low would not have 
sufficient corroboration to deem them as true worms.  
Fig. 7. Similarity scores of Zstr and LCSeq metrics for collaboration 
The above two plots show the similarity scores using Zstr and LCSeq metrics. LCS 
produced  a  similar  result  to  LCSeq.  String  equality  and  Manhattan  distance  metrics 
did not perform well in distinguishing true alerts from false ones, so their plots are not 
shown here. The other two metrics presented in figure 7 give particularly good results. 
The  worms  and  their  variant  packet  fragments  have  much  higher  similarity  scores 
than all the other alerts generated at each distinct site.  This provides some evidence 
that  this  approach  may  work  very  well  in  practice  and  provide  reliable  information 
that  a  new  zero-day  attack  is  ongoing  at  different  sites.  Note  too  that  each  site  can 
contribute to false positive reduction since the scores of the suspects are relatively low 
in  comparison  to  the  true  worms.  Furthermore,  the  Zstr  metric  shows  the  best 
separation  here,  and  with  the  added  advantage  of  preserving  the  privacy  of  the 
exchanged content. These two metrics can also be applied to the ingress/egress traffic 
correlation, especially for polymorphic worms that might re-order their content. 
There are two interesting observations from this data. The circle in the LCSeq plot 
represents the similarity score when exchanging the alerts among the sites that PAYL 
generated for CR and CR II. LCSeq is the only  metric that gave a relatively  higher 
score that is worth noticing, while all the others provide less compelling scores. When 
we looked back at the tcpdump of CR and CR II, both of them contained the string: 
244 
K. Wang, G. Cretu, and S.J. Stolfo 
“GET./default.ida?........u9090%u6858%ucbd3%u7801%u9090%u6858%ucbd3%” 
while CR has a string of repeated “N”, and CR II has string of repeated “X” padding 
their content.  Since subsequences do  not need to be adjacent in the  LCSseq  metric, 
LCSeq  ignored  the  repetitions  of  the  unmatched  “N”  and  X  substrings  and 
successfully  picked  out  the  other  common  substrings.  LCS  also  had  a  higher-than-
average  score  here,  but  not  as  good  as  LCSeq.  This  example  suggests  that 
polymorphic worms attempting to mask themselves by changing their padding may be 
detectable by cross-site collaboration under the LCSeq metric. 
Another  observation  is  that  the  LCSeq  and  LCS  results  display  several  packet 
content  alerts  with  high  similarity  scores.  These  were  false  alerts  generated  by  the 
correlation among the sites. The scores were measured at about 0.4 to 0.5. Although 
they are still much smaller than the worm scores, they are already outliers since they 
exceeded  the  score  threshold  used  in  this  experiment.  We  inspected  the  content  of 
these  packets,  and  discovered  that  they  included  long  padded  strings  attempting  to 
hide the HTTP headers. Some proxies try to hide the query identity by replacing some 
headers  with  meaningless  characters  –  in  our  case,  consisting  of  a  string  of  “Y”s. 
Such  payloads  were  correlated  as  true  alerts  while  using  LCSeq/LCS  as  metrics, 
although they are not worms. However, these anomalies did not appear when we used 
the Zstr metric, since the long string of “Y’s” used in padding the HTTP header only 
influences  one  position  in  the  Z-string,  but  has  no  impact  on  the  remainder  of  the  
Z-string. 
These  results  suggest  that  cross-sites  collaboration  can  greatly  help  identify  the 
early appearance of new zero-day worms while reducing the false positive rates of the 
constituent PAYL anomaly detectors. The similarity score between worms and their 
variants  are  much  higher  than  those  between  “true”  false  positives  (normal  data 
incorrectly deemed anomalies), and can be readily separated with high accuracy.  
When  several  sites  on  the  Internet  detect  similar  anomalous  payloads  directed  at 
them,  they  can  confirm  and  validate  with  each  other  with  high  confidence  that  an 
attack is underway. As we mentioned earlier, this strategy can also solve the limited 
buffer size problem described in Section 4.3.  If we only consider one single host, a 
stealthy worm can hibernate for a long period of time until a record of its appearance 
as an anomaly is  no longer stored in the buffer of suspect  packets. However, in the 
context of collaborating sites, the suspect anomaly can be corroborated by some other 
site that may also have a record of it in their buffer, as a remote site may have a larger 
buffer  or  may  have  received  the  worm  at  a  different  time.  The  distributed  sites 
essentially  serve  as  a  remote  long-term  store  of  information,  extending  the  local 
buffer  memory  available  at  one  site.    Further,  this  strategy  concurrently  generates 
content filtering signatures. Any two sites that correlate and validate suspects as being 
true  worms  both  have  available  the  actual  packet  content  from  which  to  generate  a 
signature, even if only Z-strings are exchanged between those sites. 
6   Conclusion 
In this paper, we provided experimental evidence that payload anomaly detection and 
content alert correlation, either on the host or across hosts and sites, hold promise for 
the early detection of zero-day worm outbreaks. It is important to note that the range 
Anomalous Payload-Based Worm Detection and Signature Generation 
245 