â€¢ Comparison with Informal Steganographic Work. In addi-
tion to the constructive contributions above, we survey the inse-
cure steganographic techniques present in recent work from the
NLP community [32â€“44]. We discuss modeling differences and
give intuition for why these protocols are not provably secure.
Limitations. We want to be clear about the limitations of our work.
â€¢ Our work does not address how well a machine learning model
can approximate an existing, â€œrealâ€ communication channel. An-
swering this question will be crucial for deployment and is the
focus of significant, machine learning research effort [51, 52].
Regardless of the current state of generative models and how
well they imitate real communication, our work is valuable for
the following reasons:
(1) The ever-changing and poorly defined nature of real communi-
cation channels makes sampling an inherently hard problem;
channels of interest are impossible to perfectly measure and
characterize. This means the imperceptibility of steganography
for these channels will always be bounded by the accuracy
of the available approximation techniques. The best approxi-
mation tool available in the existing literature is generative
modeling [55], and thus we focus on integrating them into
steganographic systems.
(2) We prepare for a future in which encrypted and pseudorandom
communications are suppressed, breaking existing tools. As
such, the current inadequacies of generative models should not
be seen as a limitation of our work; the quality of generative
models has steadily improved [52] and is likely to continue
improving. Once the techniques we develop are necessary in
practice, there is hope that generative models are sufficiently
mature to produce convincingly real output.
(3) Finally, there already exist applications in which sending model
output is normal. For instance, artificial intelligence powered
by machine learning models regularly contribute to news ar-
ticles [56, 57], create art [58, 59], and create other digital con-
tent [60, 61]. Theses channels can be used to facilitate crypto-
graphically secure steganographic communication using our
techniques today.
â€¢ In Meteor, we assume that the sender and receiver (along with the
censor) access the same generative model. While this requirement
might seem like a limitation, we reiterate that the security of
the scheme does not require that the model remain private. As
such, this model is similar to the common random string model
common in cryptography. Additionally, it is common practice to
share high quality models publicly [51, 52, 62], and these models
would outperform anything an individual could train. As such,
we believe that this assumption is reasonable and show it yields
significant performance gains.
Deployment Scenario. Our work focuses on the following sce-
nario: Imagine a sender (e.g. news website, compatriot) attempting
to communicate with a receiver (e.g. political dissident) in the pres-
ence of a censor (e.g. state actor) with control over the communica-
tions network. We assume that the sender and receiver agree on any
necessary key information out of band and select an appropriate
(public) generative model. Although we focus on English text in this
work, the generative model could be for any natural communica-
tion channel. The sender and receiver then initiate communication
over an existing communication channel, using a steganographic
encoder parameterized by the generative model to select the tokens
they send over the channel. The censor attempts to determine if
the output of the generative model being exchanged between the
sender and receiver is subversive or mundane. We note that practi-
cal deployments of these techniques would likely incorporate best
practices to achieve forward secrecy, post compromise security, and
asynchronicity, possibly by using parts of the Signal protocol [1].
Organization. In Section 2, we give background and assess re-
lated work on classical steganographic techniques from the cryp-
tographic community, how steganography is currently used in
practice, and generative models. In Section 3, we give formal def-
initions for steganography. In Section 4, we explore using exist-
ing techniques and steganographic schemes to build public-key
steganography for English text distributions. In Section 5, we give
a construction of a new, symmetric key steganographic system,
Session 5C: Messaging and Privacy CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea1531Algorithm 1: Public-Key Encoding Scheme from [54]
Input: Plaintext Message ğ‘š, Distribution D, Sampling
Bound ğ‘˜, public-key pk
Output: Stegotext Message ğ‘
ğ‘¥ â† PseudorandomPKEncrypt(pk, ğ‘š)
Let ğ‘¥0||ğ‘¥1|| . . . ||ğ‘¥|ğ‘¥ | â† ğ‘¥
ğ‘ â† ğœ€
for ğ‘– < |ğ‘¥| do
ğ‘ğ‘– â† Sample(D)
ğ‘— â† 0
while ğ‘“ (ğ‘ğ‘–) â‰  ğ‘¥ğ‘– and ğ‘— < ğ‘˜ do
ğ‘ğ‘– â† Sample(D)
ğ‘— â† ğ‘— + 1
ğ‘ â† ğ‘âˆ¥ğ‘ğ‘–
Output ğ‘
Figure 1: The public-key steganography scheme from [54].
PseudorandomPKEncrypt is the encryption routine for a pseu-
dorandom, public-key encryption scheme. Sample randomly
selects an token from the covertext space according to the
distribution D.
Meteor, and analyze its efficiency and security. In Section 6, we
give implementation details for Meteor and evaluate the efficiency
of using Meteor on different systems. Finally, in Section 7 we dis-
cuss existing work from the NLP community and show why it is
insecure.
2 BACKGROUND AND RELATED WORK
Classical Steganography. Since Simmonsâ€™ first formalization of
steganographic communication [25], significant effort has been de-
voted to theoretical steganography. Early work focused on achiev-
ing information-theoretic security [26, 27, 63, 64] before moving on
to cryptographic [28â€“30] and statistical [65â€“67] notions of steganog-
raphy. The are many symmetric-key constructions [27, 28, 68],
public-key constructions [29, 30, 69, 70], and even identity based
constructions [71]. Relatively little on formal steganography has
been in the last 15 years, although there are recent works consider-
ing the boundaries of steganography [72], the related problem of
backdoor resistance [73] and keyless steganography [74].
In general, the steganographic schemes presented in the litera-
ture rely on rejection sampling to find randomly selected elements
of the covertext distribution that hash to desired bits. Given space
constrains, we cannot describe and compare to all prior work. For
a representative example, consider the public-key steganographic
scheme from [29, 54] presented in Algorithm 1. First, the encoder
uses a pseudorandom, public-key encryption scheme to encrypt
the message. Then, one bit ğ‘¥ğ‘– at a time, the encoder uses rejection
sampling to find a token ğ‘ğ‘– in the covertext distribution D such
that ğ‘“ (ğ‘ğ‘–) = ğ‘¥ğ‘–, where ğ‘“ is a perfectly unbiased function over D.
We omit the formal description of the simple decoding algorithm,
in which the receiver simply computes ğ‘“ (ğ‘ğ‘–) for all ğ‘–, concatenates
the bits, and decrypts the result.
Security for such schemes is simple to see: each bit of the en-
crypted message is random, by the pseudorandomness of the ci-
pher, and each token in the stegotext is randomly sampled from
the true distribution, with no bias introduced by the hash function
(by definition). As such, the distribution of the stegotext matches
the covertext exactly. However, if no unbiased hash function exists,
as none do for infinitely many distributions [54], a universal hash
function can be used instead, and the bias it introduces must be
carefully controlled.
These rejection sampling algorithms fail when the distribution
has very low entropy. In such cases, it is unlikely an unbiased hash
function will exist, so a universal hash function must be used. One
of two possible problems is likely to occur. (1) During sampling,
it is possible that the sampling bound ğ‘˜ may be exceeded without
finding an acceptable token, after which the encoder simply ap-
pends a randomly sampled token. Importantly, the receiver can not
detect that this error has occurred, or indeed how many such errors
are contained in the message, and will just get a decryption error
during decoding. (2) If ğ‘˜ is set very high, it may be possible to find
a token that hashes to the correct value, at the cost of introducing
noticeable bias in the output distribution. As such, it is critical that
the distribution maintain some minimum amount of entropy. To
our knowledge, only two prior works [31, 54] build stateful stegano-
graphic techniques that avoid the minimum entropy requirement.
Focusing on asymptotic performance, both rely on error correcting
codes and have poor practical performance.
In the closest related work, the authors of [75] theoretically
analyze the limitations of using Markov Models as steganographic
samplers. The prove that any sampler with limited history cannot
perfectly imitate the true covertext channel. Our work overcomes
this limitations by considering the output of the model the target
covertext distribution.
In our work we consider more powerful machine learning models
and allow the sender and receiver to share access to the same public
model. This is a departure from prior steganographic work, moti-
vated by the public availability of high quality models [51, 52, 62]
and because this relaxation introduces significant efficiency gains.
As there has been, to our knowledge, no work testing the practi-
cal efficiency of secure steganographic constructions for complex
channels, no other work considers this model.
Current Steganography in Practice. The main contemporary
use for steganography is to connect to Tor ([8â€“10]) without being
flagged by the plethora of surveillance mechanisms used by cen-
sors [19]. Steganographic techniques include protocol obfuscation,
e.g., obfs4/ScrambleSuit [11], domain fronting [76], or mimicry,
e.g., SkypeMorph [12], FTEProxy [16], StegoTorus [13], Censor-
Proofer [17], and FreeWave [18]. Although these tools allow users
to circumvent censors today, they are quite brittle. For example, pro-
tocol obfuscation techniques are not cryptographically secure and
rely on censors defaulting open, i.e., a message should be considered
innocuous when its protocol cannot be identified. Protocol mimicry
techniques, encoding one protocol into another, are not always
cryptographic and often fail when protocols are under-specified or
change without warning [77].
Modern steganographic techniques that are cryptographically
secure include tools like SkypeMorph [12], CensorProofer [17],
Session 5C: Messaging and Privacy CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea1532and FreeWave [18], that tunnel information through Voice-Over-IP
(VoIP) traffic, which is usually encrypted with a pseudorandom
cipher. Once encrypted communication has started, a sender can re-
place the normal, VoIP encrypted stream with a different encrypted
stream carrying the secret message. By the security of the cipher,
a censor cannot detect that the contents of the encrypted chan-
nel have been replaced and the communication looks like normal,
encrypted VoIP traffic. If access to encrypted or pseudorandom
communication channels were suppressed, these tools would no
longer work.
There have been small-scale tests [78] at deploying cryptography
secure steganographic tagging via ISP level infrastructure changes,
as suggested in Telex [14] and TapDance [15]. These tags indicate
that a message should be redirected to another server, but stop
short of hiding full messages. These tags also critically rely on the
presence of (pseudo-)random fields in innocuous protocol traffic.
Practical work has been done in the field of format-transforming
encryption (FTE), such as [79â€“82]. These approaches require senders
to explicitly describe the desired covertext channel distribution, an
error-prone process requiring significant manual effort and is in-
feasible for natural communication. None of these applications,
however, provide any kind of formal steganographic guarantee.
Recently, there has also been work attempting to leverage machine
learning techniques to generate steganographic images, i.e. [83â€“88],
but none of these systems provide provable security.
Generative Neural Networks. Generative modeling aims to cre-
ate new data according to some distribution using a model trained
on input data from that distribution. High quality language mod-
els [51, 52], are generative neural networks, which use neural net-
work primitives. The model itself contains a large number of â€œneu-
ronsâ€ connected together in a weighted graph of â€œlayersâ€, which
â€œactivateâ€ as the input is propagated through the network. Unlike tra-
ditional feed-forward neural networks used in classification tasks,
generative networks maintain internal state over several inputs to
generate new text. Training these models typically ingests data in
an effort to set weights to neurons, such that the modelâ€™s output
matches the input data distribution; in other words, the network
â€œlearnsâ€ the relationships between neurons based on the input. The
first practical development in this field was the creation of long
short-term memory (LSTM) networks [89]. LSTM networks are
found in machine translation [90, 91], speech recognition, and lan-
guage modeling [55]. The transformer architecture [92], exemplified
by the GPT series of models [51, 52], is also becoming popular, with
results that are increasingly convincing [53].
After training, the model can be put to work. Each iteration of
the model proceeds as follows: the model takes as input its previous
state, or â€œcontextâ€. As the context propagates through the network,
a subset of neurons activate in each layer (based on previously
trained weights), up until the â€œoutput layerâ€. The output layer has
one neuron for output token, and uses the activated neurons to
assign each token a weight between 0 and 1. The model uses its
trained weights and the context input to generate a distribution of
possible tokens, each with a probability assigned. The model uses
random weighted sampling to select a token from this distribution,
returning the chosen token as output. Finally, the returned token is
appended to the context and the next iteration begins.
We note there is work focusing on differentiating machine-
generated text from human-generated text [93â€“95]. It has yet to be
seen if these techniques will remain effective as machine learning
algorithms continue to improve, setting the stage for an â€œarms raceâ€
between generative models and distinguishers [96].
3 DEFINITIONS
3.1 Symmetric Steganography
The new construction in this work is symmetric-key stenography,
so for completeness we include symmetric-key definitions. The
definitions for public-key steganography are a straightforward
adaptation of the definitions provided here and can be found in [54].
A symmetric steganographic scheme Î£D is a triple of possibly
probabilistic algorithms, Î£D = (KeyGenD, EncodeD, DecodeD)
parameterized by a covertext channel distribution D.
â€¢ KeyGenD(1ğœ†) takes arbitrary input with length ğœ† and generates
ğ‘˜, the key material used for the other two functionalities.
â€¢ EncodeD(ğ‘˜, ğ‘š,H) is a (possibly probabilistic) algorithm that
takes a key ğ‘˜ and a plaintext message ğ‘š. Additionally, the al-
gorithm can optionally take in a message history H, which is
an ordered set of covertext messages H = {â„0, â„1, . . . , â„|H|âˆ’1},
presumably that have been sent over the channel. Encode returns
a stegotext message composed of ğ‘ğ‘– âˆˆ D.