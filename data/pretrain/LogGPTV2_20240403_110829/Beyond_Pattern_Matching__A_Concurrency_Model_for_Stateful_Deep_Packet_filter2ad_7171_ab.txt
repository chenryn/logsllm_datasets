are processed sequentially by the same thread, in the order they
are received. For our simple scan detector, the scope is the source
address (c.src). Figure 1(c) depicts its implementation within this
paradigm: each connection is statically mapped (by simple hash-
ing, c.src%N) to one of the available threads, guaranteeing that (i)
no two threads access the same state at the same time, and (ii) all
events from the same source are processed sequentially. It should
be noted that scope can be non-trivial to deﬁne, especially for anal-
yses aggregating multiple connections at the application layer. §3
presents one such analysis (a worm detector), and discusses an ap-
proach to generalize the notion of scope to those cases.
2.3 A Parallel IDS Architecture
We now outline a concrete IDS architecture based on the concur-
rency model discussed above. We have implemented and evaluated
this architecture; results are discussed in §6.
Our proposed architecture, depicted in Figure 2, assumes a pre-
processing step (1) to efﬁciently parse raw packets and generate
events (in the case of our example portscan detector, new connec-
tion notiﬁcations). A scheduler (2) then determines the appropri-
ate context for each event (the address of the connection origina-
tor), and maps all related processing to the corresponding thread.
The resulting stream of scheduled events is analyzed using multi-
ple analysis threads (3), each in charge of a set of contexts. Each
thread maintains and updates its own private, local detection state.
The scalability of this model depends crucially on ﬁnding sufﬁ-
cient diversity in the analyzed trafﬁc (in terms of number of con-
texts) to distribute load and state evenly across threads. Previous
work has shown that partitioning trafﬁc at ﬂow level [40] and sim-
ilar units [37] balances well and provides good thread-scalability.
Our evaluation, presented in §6, supports these conclusions.
Our model relies on (i) the availability of a well-deﬁned scope
for each detection strategy, and (ii) the correctness of the event
scheduler. In §3 we discuss how scope can be generalized using
the concept of scheduling functions, and in §4 we propose an ap-
proach to automatically infer scope via program analysis. §5 then
gives a scheduling algorithm suited for our architecture.
3. GENERALIZING DETECTOR SCOPE
For simple analyses, the processing context of an event handler
is directly characterized by its input data. For example, in the
Low-level traffic parsing (per-connection)   Scheduler       (   ) Event context determination Event stream . . . detector_logic() Detector state . . . Network traffic Scheduled events 1 1 2 2 3 3 Detector threads Event ev1 Event ev2 portscan detector of Figure 1 the context is given by the address
of the connection originator. Similarly, for a detector performing
per-ﬂow signature matching each event’s context is determined by
its connection 5-tuple. Therefore, it is tempting to specify scope
as a subset of input parameters (such as c.src for the detector of
Figure 1(c)).
This assumption however does not hold for more complex anal-
yses, that may correlate multiple ﬂows and different classes of net-
work events. In this section we demonstrate the issue using a sim-
ple worm detector, and we show how to achieve a more general
deﬁnition of scope via the concept of scheduling functions.
3.1 Multistep: a Trojan Detector
Malicious network activity by an infected host tends to consist
of various operations that appear normal if considered individually
but become signiﬁcant once considered together. Our sample anal-
ysis implements a simple multi-step trojan detector (multistep in the
following), inspired by publicly available Bro didactic material [1].
Albeit referring to a ﬁctional malware, it is inspired by threats seen
in practice, making it a realistic case study.
The target of the detector is a backdoor application that is asso-
ciated with the following sequence of operations: (i) the infected
host receives an SSH connection on port 2222; (ii) the host initiates
three distinct downloads: an HTML ﬁle from a web server, and a
ZIP and an EXE ﬁle from a FTP server; (iii) the host generates IRC
activity. Note that order is relevant; the same events in a different
order do not constitute a ﬁngerprint.
We assume the availability of an underlying IDS layer that can
distill raw packet trafﬁc into high-level events, as described in §2.1.
These events are fed to the detection logic, which consists of three
event handlers:
• ProtocolConﬁrmation: Triggered by the IDS when an application-
level protocol is being used within a connection. Used to de-
tect both the initial inbound SSH connection, and the ﬁnal
outbound IRC connection.
• HttpRequest: Triggered when a host generates an HTTP re-
quest. Used to detect the HTTP download.
• FTPRequest: Used to detect both FTP downloads.
To maintain state the detector uses a persistent table, consisting
of an associative container indexed by IP addresses of potentially
infected hosts. The value associated with each IP is the current
detection state i.e., how many actions, from the sequence that ﬁn-
gerprints the trojan, the host has already performed. An entry is
created in the table for each host that receives an SSH connection
on port 2222, and updated every time the same host performs one
of the activities described earlier. If a host completes all the actions
in the described order, the detector raises an alert.
3.2 Parallelizing Multistep
To determine the appropriate scope for multistep, we begin by
considering how data ﬂows within an individual event handler, sum-
marized in Figure 3(a). Events from the input stream (1) are fed to
event handlers (2) as they arrive. Each handler derives a key from
input data (3), per the labels on the edges; and then uses that key
as an index to retrieve relevant detection state (4). First, just by
considering the inputs to each handler, it is evident that a per-ﬂow
approach to parallelism is infeasible, since the various event han-
dlers operate on different connections. If we look for another, more
general scope to partition the trafﬁc (connection originator? con-
nection responder?), a problem quickly becomes apparent: Each
Figure 3: Dataﬂows (a) and scheduling functions (b) for multistep
handler independently derives the index used to retrieve the detec-
tion state. As can be seen, there is no unique way to deﬁne a scope
that applies to all the components of the application, since the in-
formation of interest can be either the originator of a connection,
or the responder. It is not even possible to assign a well-deﬁned
scope to individual handlers: in the case of the ProtocolConﬁrma-
tion handler, the index can be either the connection originator or
responder depending on which protocol is being detected.
These considerations suggest that attempting to deﬁne scope from
a network perspective, i.e., statically and in terms of protocol-related
concepts (ﬂow, connection originator, etc.), is not suitable for cross-
layer, complex analyses. Instead, we propose considering the issue
from an “analysis-centric” point of view: all the possible inputs
that cause the same detection state to be accessed belong to the
same context. In other words, we make the deﬁnition of scope de-
pendent on the computation performed by the program itself.
3.3 A Flexible Approach to Scheduling
We observe that most analyses are structured around a set of ta-
bles, and their persistent state is fully deﬁned by the values of the
indices used to access said tables. Consider the ProtocolConﬁrma-
tion handler in Figure 3(a). The handler is executed each time a new
connection is observed, and receives an identiﬁer p for the protocol
being used. If p == IRC, the handler accesses the table based on
the source of the connection (c.src). If p == SSH, it does the same
using the destination of the connection (c.dst). The key point is that
once the table is accessed, the scope gets fully disambiguated.
This suggests a way to conceptually partition a set of events into
contexts: two events are within the same context if they cause the
detector to access the same index (indices) in its table(s). For ex-
ample, an IRC connection from address 192.168.1.12 and a SSH
connection to the same address will both cause multistep to update
the same table entry. At the same time, events generated by a an-
other infected host/IP will affect a different entry.
This rule can be directly used for scheduling, by mapping all
events resulting in the same table access(es) to the same context,
and therefore to the same thread. But there is a caveat: the value of
table indices can only be determined when the event handler exe-
cutes, i.e., after the scheduling decision has been done. However, a
large number of event-driven analyses, regardless of their complex-
ity, statelessly compute table indices from the values of their input
parameters (event data).
Host address Detection state  HTTP Request  FTP Request       Per-host detection state c.dst if p == SSH c.src if p == IRC c.src c.src Inputs: connection c string method string URI Inputs: connection c protocol p Inputs: connection c string command string argument 1 1 2 2 3 3 4 4 Protocol Confirmation (a) ProtocolConfirmation(c): if (p == SSH) return c.dst else return c.src HTTPRequest(c): return c.src FTPRequest(c): return c.src (b) Scheduling functions: Our approach then consists in annotating each event handler with
its index computation, which we call the scheduling function A.
Figure 3(b) outlines the simplest possible scheduling functions for
the handlers in the multistep example. The role of A is to guide
scheduling by deriving the scope from input values for each new
event, before processing it. Once scheduling functions are avail-
able, parallelization can proceed by executing the appropriate schedul-
ing function on each input, and using the result to map events
within the same context (i.e., accessing the same data) to the same
thread. As Figure 3(b) illustrates, expressing scope in terms of
scheduling functions does not introduce additional overhead: a min-
imal scheduling function expresses precisely the operations that the
IDS logic must perform to derive the appropriate context for an
event.
In §4 we give algorithms to automatically construct an efﬁcient
scheduling function A for a given program P via static program
analysis. An advantage of this technique is that the parallelization
strategy is derived ofﬂine, i.e., scheduling functions can be fully
constructed before running the program.
INFERRING SCOPE
4.
The approach outlined in §3 requires, for each analysis, a schedul-
ing function A. The simplest approach for generating A is to re-
quire the developer to annotate each program with an appropri-
ate scheduling function. This is however impractical, as it further
complicates the user’s already difﬁcult task of implementing effec-
tive trafﬁc analyses. Developing an analysis and the corresponding
scheduling function is cumbersome, and the duplication of code
with similar purpose makes programming errors more likely.
If
a program and its scheduling function become inconsistent, the
analysis risks incurring false negatives. Moreover, reasoning about
scheduling functions requires the user to focus on a technical as-
pect of the system—parallelization—unrelated to the main goal of
intrusion detection. Instead, our goal is to provide an IDS system
with transparent scalability, leaving the user free to concentrate on
developing effective analyses.
We therefore consider the problem of automatically generating
the scheduling function A for a given IDS program P . If Ind(i) is
the set of indices accessed by P , A is deﬁned so that Ind (i) ⊆
A(i) for all i ∈ I (where I is the set of all possible program
inputs). We begin by observing that the most obvious deﬁnition
of A is P itself. Making A equal to P results in a scheduling
function that is fully precise, since for every input i it always returns
exactly the set of indices Ind(i) that P will access. However, such
A is also terribly inefﬁcient, as it causes P to run twice on each
input: ﬁrst to perform scheduling and then to process the event. The
problem then becomes to construct A an as an over-approximation
of P , such that Ind (i) ⊆ A(i) and A executes faster than P .
To construct such an approximation, we observe that for many
IDS heuristics only a small part of the program is dedicated to com-
puting the indices in Ind(i), while the rest implements the detec-
tion logic. Therefore, a compact (with respect to the size of P )
scheduling function A can be obtained by pruning all the state-
ments, in P , that are irrelevant for the computation of Ind(i). In
the rest of this section, we describe static analysis algorithms that
constructs the scheduling function A by pruning P . As both the al-
gorithms are based on program slicing, we provide a brief primer.
4.1 Program Slicing Primer
Program slicing [27, 35, 47] is a program analysis technique that
provides two primitives: (i) determine which statements in a pro-
gram inﬂuence the value of a variable at a given point (backward
slicing), and (ii) determine which statements are inﬂuenced by the
value of a variable at a given point (forward slicing). It does so by
leveraging the program dependency graph (PDG), a graph repre-
sentation of a program where nodes are statements and edges rep-
resent data and control dependencies between statements. Thus for
example backward slices can be constructed by computing back-
ward reachability from the statements of interest. Figure 4(a-b)
presents an example of a simple program and its PDG. (We discuss
the ﬁgure in more detail below.)
In this paper, we use program slicing to isolate the portion of
analysis programs that generates table indices. Speciﬁcally, given
an input program P we want to extract the statements relevant to
the scheduling function A, i.e., those that transform an input i into a
set of table indices Ind(i). To do so, we generate a backward slice
including statements that affect the value of indices in Ind(i). The
resulting slice S will contain a superset of the statements of interest.
We then leverage the domain-speciﬁc nature of such programs to
reﬁne the output of slicing and generate scheduling functions in a
fully automated way. To the best of our knowledge this application
of program slicing to the domain of IDS parallelization is novel,
and an important contribution of our work.
We have developed two algorithms to generate the scheduling
function A via program slicing. The ﬁrst algorithm, presented in
§4.2, is optimized for the common case where the scheduling func-
tion A can be expressed as straight-line code. The second algo-
rithm, presented in §4.3, reﬁnes the ﬁrst to produce better results
when S includes conditional instructions.
4.2 Flow-insensitive Algorithm
In §3 we introduced the idea that IDS analyses can be divided in
two broad classes: simple analyses whose scope can be expressed
in terms of protocol-level units (e.g., analyses aggregating trafﬁc by
source address, connection, etc.) and more complex ones with non-
trivial scope (e.g., our multistep example). We begin by describing
an algorithm targeted at the former, simpler class.
Our algorithm is based on the insight that, for many simple anal-
yses, the index used to access analysis state is either an input pa-
rameter, or is obtained by a simple, straight-line computation from
the input parameters (e.g., extracting a struct ﬁeld, such as in Fig-
ure 1(c)). In these cases the value of the index does not depend on
conditional instructions. Therefore, scheduling function generation
can be greatly simpliﬁed by only considering data dependencies.
Algorithm 1: Flow-insensitive A generation
1
2
3
4
5
Compute DDG G from program P
Find the set of table accesses C in G
Compute the backward slice S from C
Remove redundant table accesses from S
Emit code for S
Algorithm 1 lists the high-level steps through which scheduling
functions are generated. We describe each step through an exam-
ple from the multistep application introduced in §3.1. The example
consists of one of the application’s event handlers, HttpRequest.
Pseudocode for the event handler is given in Figure 4(a).
Input
parameters are 1) the identiﬁer of the connection generating the re-
quest, 2) the request method (e.g., “GET” or “POST”), and 3) the
URI being requested. The handler ﬁrst checks whether the request