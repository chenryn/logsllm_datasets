example shows a response for the configuration when everything is working as expected. The commands
are run on VM13:
%rdqmstatus -m HAQM1
Node: mqhavm13.gamsworthwilliam.com
Queue manager status: Running
CPU: 0.00
Memory: 123MB
Queue manager file system: 606MB used, 1.0GB allocated [60%]
HA role: Primary
HA status: Normal
HA control: Enabled
HA current location: This node
HA preferred location: This node
HA preferred location: This node
HA blocked location: None
HA floating IP interface: eth4
HA floating IP address: 192.0.2.4
%rdqmstatus -m HAQM2
Node: mqhavm13.gamsworthwilliam.com
Queue manager status: Running elsewhere
HA role: Secondary
HA status: Normal
HA control: Enabled
HA current location: mqhavm14.gamsworthwilliam.com
HA preferred location: mqhavm14.gamsworthwilliam.com
HA blocked location: None
HA floating IP interface: eth4
HA floating IP address: 192.0.2.6
%rdqmstatus -m HAQM3
Node: mqhavm13.gamsworthwilliam.com
Queue manager status: Running elsewhere
HA role: Secondary
HA status: Normal
HA control: Enabled
HA current location: mqhavm15.gamsworthwilliam.com
HA preferred location: mqhavm15.gamsworthwilliam.com
HA blocked location: None
HA floating IP interface: eth4
HA floating IP address: 192.0.2.8
Note the following points:
• All three nodes are shown with an HA status of Normal.
• Each RDQM HA queue manager is running on the node where it was created, for example, HAQM1 is
running on vm13 and so on.
This scenario is constructed by preventing HAQM1 from running on vm14, and then attempting to move
HAQM1 to vm14. HAQM1 cannot run on vm14 because the file /var/mqm/mqs.ini on vm14 has an
invalid value for the Directory of queue manager HAQM1.
The preferred location for HAQM1 is changed to vm14 by running the following command on vm13:
rdqmadm -m HAQM1 -n mqhavm14.gamsworthwilliam.com -p
228 Troubleshooting and Support for IBM MQ
This command would normally cause HAQM1 to move to vm14 but in this case checking the status on
vm13 returns the following information:
$ rdqmstatus -m HAQM1
Node: mqhavm13.gamsworthwilliam.com
Queue manager status: Running
CPU: 0.15%
Memory: 133MB
Queue manager file system: 52MB used, 1.0GB allocated [5%]
HA role: Primary
HA status: Normal
HA control: Enabled
HA current location: This node
HA preferred location: mqhavm14.gamsworthwilliam.com
HA blocked location: mqhavm14.gamsworthwilliam.com
HA floating IP interface: None
HA floating IP address: None
Node: mqhavm14.gamsworthwilliam.com
HA status: Normal
Node: mqhavm15.gamsworthwilliam.com
HA status: Normal
HAQM1 is still running on vm13, it has not moved to vm14 as requested and the cause needs
investigating. Examining the status and including failed resource actions gives the following response:
$ rdqmstatus -m HAQM1 -a
Node: mqhavm13.gamsworthwilliam.com
Queue manager status: Running
CPU: 0.15%
Memory: 133MB
Queue manager file system: 52MB used, 1.0GB allocated [5%]
HA role: Primary
HA status: Normal
HA control: Enabled
HA current location: This node
HA preferred location: mqhavm14.gamsworthwilliam.com
HA blocked location: mqhavm14.gamsworthwilliam.com
HA floating IP interface: None
HA floating IP address: None
Node: mqhavm14.gamsworthwilliam.com
HA status: Normal
Node: mqhavm15.gamsworthwilliam.com
HA status: Normal
Failed resource action: Start
Resource type: Queue manager
Failure node: mqhavm14.gamsworthwilliam.com
Failure time: 2022-01-01 12:00:00
Failure reason: Generic error
Blocked location: mqhavm14.gamsworthwilliam.com
Take note of the Failed resource action section that has appeared.
The entry shows that when Pacemaker tried to check the state of HAQM1 on vm14 it got an error because
HAQM1 is not configured, which is because of the deliberate misconfiguration in /var/mqm/mqs.ini.
Correcting the failure
To correct the failure you must correct the underlying problem (in this case restoring the correct directory
value for HAQM1 in /var/mqm/mqs.ini on vm14). Then you must clear the failed action by using the
command rdqmclean on the appropriate resource, which in this case is the resource haqm1 as that is
the resource mentioned in the failed action. For example:
$ rdqmclean -m HAQM1
Then check the failed resource action status again:
IBM MQ troubleshooting and support 229
$ rdqmstatus -m HAQM1 -a
The failed action has disappeared and HAQM1 is now running on vm14 as expected. The following
example shows the RDQM status:
$ rdqmstatus -m HAQM1
Node: mqhavm13.gamsworthwilliam.com
Queue manager status: Running elsewhere
HA role: Secondary
HA status: Normal
HA control: Enabled
HA current location: mqhavm14.gamsworthwilliam.com
HA preferred location: mqhavm14.gamsworthwilliam.com
HA blocked location: None
HA floating IP interface: None
HA floating IP address: None
Node: mqhavm14.gamsworthwilliam.com
HA status: Normal
Node: mqhavm15.gamsworthwilliam.com
HA status: Normal
Problems after upgrading RDQM
If you encounter problems after upgrading one or more nodes in your RDQM configuration, you should
check that your installed DRBD kernel matches the OS kernel version.
RDQM configurations rely upon the DRBD module to provide data replication. When you upgrade RDQM,
it is important to ensure that the correct version of the DRBD kernel module is installed for the version
of RHEL kernel running on the system. If the versions do not match, you might experience problems of
varying severity. It might be that queue manager will not start, or that it does not run on the upgraded
node, even if that node is the preferred location.
You can use the rdqmstatus command to view information about installed versions, see Viewing RDQM
and HA group status, Viewing DR RDQM status, and Viewing DR/HA RDQM and HA group status.
For guidance on selecting the correct DRBD module to install, see Installing RDQM (replicated data queue
managers).
The following examples illustrate some potential mismatches and their effects.
Example 1
Node: mqhavm57.exampleco.com
OS kernel version: 3.10.0-1160.15.2
DRBD OS kernel version: 3.10.0-957
DRBD version: 9.1.2+ptf.3
DRBD kernel module status: Partially loaded
Queue manager name: QM1
Queue manager status: Running elsewhere
HA status: Unknown
HA current location: mqhavm58.exampleco.com
HA preferred location: This node
HA blocked location: None
DR role: Primary
DR status: Unknown
Queue manager name: QM2
Queue manager status: Running elsewhere
HA status: Unknown
HA current location: mqhavm58.exampleco.com
HA preferred location: This node
HA blocked location: None
Queue manager name: QM3
Queue manager status: Status not available
DR role: Secondary
DR status: Unknown
230 Troubleshooting and Support for IBM MQ
This summary status shows that the DRBD kernel module for RHEL 7.6 has been installed, while the OS
kernel version is for RHEL 7.9. As a result of this mismatch, the DRBD module is only partially loaded.
QM1 is an HA/DR queue manager and moves to another node, its HA status is unknown and its DR status
is unknown. QM2 is an HA queue manager, it fails to start on its preferred node and its HA status in
Unknown. QM3 is a DR queue manager and is meant to be the Primary instance, but since the DRBD
kernel module did not fully load, it reports as Secondary with a DR status of Unknown. To resolve these
failures the DRBD kernel module must be updated with the version target for the running OS kernel.
Example 2
Node: mqhavm07.exampleco.com
OS kernel version: 3.10.0-1160.15.2
DRBD OS kernel version: 3.10.0-1127
DRBD version: 9.1.1
DRBD kernel module status: Loaded
Queue manager name: RDQM7
Queue manager status: Running
HA current location: This node
HA preferred location: This node
HA blocked location: None
This summary status shows that the DRBD kernel module for RHEL 7.8 has been installed, while the OS
kernel version is for RHEL 7.9. This is not such a serious mismatch, the DRBD module is loaded, and
queue manager RDQM7 is running on this node. It is, however, recommended that you install the correct
DRBD module for your RHEL installation to ensure correct operation.
Troubleshooting security problems
Troubleshooting information to help you solve problems relating to security.
Related tasks
“Collecting information for security problems” on page 342
If an IBM MQ is incorrectly allowing or denying access to a user or application on Multiplatforms, you
might need to collect troubleshooting information to help with finding a solution.
“Collecting information for TLS channel problems” on page 344
If an IBM MQ queue manager or client application is failing to establish a secure channel using TLS on
Multiplatforms, you might need to collect troubleshooting information to help with finding a solution.
Troubleshooting channel authentication record problems
If you are having problems using channel authentication records, check whether the problem is described
in the following information.
What address are you presenting to the queue manager?
The address that your channel presents to the queue manager depends on the network adapter being
used. For example, if the CONNAME you use to get to the listener is "localhost", you present 127.0.0.1
as your address; if it is the real IP address of your computer, then that is the address you present to the
queue manager. You might invoke different authentication rules for 127.0.0.1 and your real IP address.
Using BLOCKADDR with channel names
If you use SET CHLAUTH TYPE(BLOCKADDR), it must have the generic channel name CHLAUTH(*) and
nothing else. You must block access from the specified addresses using any channel name.
CHLAUTH(*) on z/OS systems
On z/OS, a channel name including the asterisk (*) must be enclosed in quotation marks.
This rule also applies to the use of a single asterisk to match all channel names. Thus, where you would
specify CHLAUTH(*) on other platforms, on z/OS you must specify CHLAUTH('*').
IBM MQ troubleshooting and support 231
Behavior of SET CHLAUTH command over queue manager restart
If the SYSTEM.CHLAUTH.DATA.QUEUE, has been deleted or altered in a way that it is no longer accessible
i.e. PUT(DISABLED), the SET CHLAUTH command will only be partially successful. In this instance, SET
CHLAUTH will update the in-memory cache, but will fail when hardening.
This means that although the rule put in place by the SET CHLAUTH command may be operable initially,
the effect of the command will not persist over a queue manager restart. The user should investigate,
ensuring the queue is accessible and then reissue the command (using ACTION(REPLACE) ) before
cycling the queue manager.
If the SYSTEM.CHLAUTH.DATA.QUEUE remains inaccessible at queue manager startup, the cache of
saved rules cannot be loaded and all channels will be blocked until the queue and rules become
accessible.
Maximum size of ADDRESS and ADDRLIST on z/OS systems
On z/OS, the maximum size for the ADDRESS and ADDRLIST fields are 48 characters. Some IPv6 address
patterns could be longer than this limit, for example '0000-ffff:0000-ffff:0000-ffff:0000-
ffff:0000-ffff:0000-ffff:0000-ffff:0000-ffff'. In this case, you could use '*' instead.
If you want to use a pattern more than 48 characters long, try to express the requirement in a different
way. For example, instead of specifying
'0001-fffe:0001-fffe:0001-fffe:0001-fffe:0001-fffe:0001-fffe:0001-fffe:0001-
fffe' as the address pattern for a USERSRC(MAP), you could specify three rules:
• USERSRC(MAP) for all addresses (*)
• USERSRC(NOACCESS) for address '0000:0000:0000:0000:0000:0000:0000:0000'
• USERSRC(NOACCESS) for address 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff'
CipherSpec mismatches
Both ends of an IBM MQ TLS channel must use the same CipherSpec. Mismatches can be detected during
the TLS handshake or during channel startup.
A CipherSpec identifies the combination of the encryption algorithm and hash function. Both ends of an
IBM MQ TLS channel must use the same CipherSpec, although they can specify that CipherSpec in a
different manner. Mismatches can be detected at two stages:
During the TLS handshake
The TLS handshake fails when the CipherSpec specified by the TLS client is unacceptable to the TLS
support at the TLS server end of the connection. A CipherSpec failure during the TLS handshake
arises when the TLS client proposes a CipherSpec that is not supported by the TLS provision on the
TLS server. For example, when a TLS client running on AIX proposes the DES_SHA_EXPORT1024
CipherSpec to a TLS server running on IBM i.
During channel startup
Channel startup fails when there is a mismatch between the CipherSpec defined for the responding
end of the channel and the CipherSpec defined for the calling end of channel. Channel startup also
fails when only one end of the channel defines a CipherSpec.
See Specifying CipherSpecs for more information.
Note: If Global Server Certificates are used, a mismatch can be detected during channel startup even
if the CipherSpecs specified on both channel definitions match.
Global Server Certificates are a special type of certificate which require that a minimum level of
encryption is established on all the communications links with which they are used. If the CipherSpec
requested by the IBM MQ channel configuration does not meet this requirement, the CipherSpec is
renegotiated during the TLS handshake. This is detected as a failure during IBM MQ channel startup
as the CipherSpec no longer matches the one specified on the channel.
232 Troubleshooting and Support for IBM MQ
In this case, change the CipherSpec at both sides of the channel to one which meets the requirements
of the Global Server Certificate. To establish whether a certificate that has been issued to you is a
Global Server Certificate, contact the certificate authority which issued that certificate.
TLS servers do not detect mismatches when an TLS client channel on AIX, Linux, and Windows systems
specifies the DES_SHA_EXPORT1024 CipherSpec, and the corresponding TLS server channel on AIX,
Linux, and Windows systems is using the DES_SHA_EXPORT CipherSpec. In this case, the channel runs
normally.
Authentication failures during TLS handshake
There are a number common reasons for authentication failures during the TLS handshake.
These reasons include, but are not limited to, those in the following list:
A certificate has been found in a Certificate Revocation List or Authority Revocation List
You can check certificates against the revocation lists published by the Certificate Authorities.
A Certificate Authority can revoke a certificate that is no longer trusted by publishing it in a Certificate
Revocation List (CRL) or Authority Revocation List (ARL). For more information, see Working with
revoked certificates.
An OCSP responder has identified a certificate as Revoked or Unknown
You can check certificates using OCSP. An OCSP responder can return a response of Revoked,
indicating that a certificate is no longer valid, or Unknown, indicating that it has no revocation data for
that certificate. For more information, see Working with revoked certificates.
A certificate has expired or is not yet active
Each digital certificate has a date from which it is valid and a date after which it is no longer valid, so
an attempt to authenticate with a certificate that is outside its lifetime fails.
A certificate is corrupted
If the information in a digital certificate is incomplete or damaged, authentication fails.
A certificate is not supported
If the certificate is in a format that is not supported, authentication fails, even if the certificate is still
within its lifetime.
The TLS client does not have a certificate
The TLS server always validates the client certificate if one is sent. If the TLS client does not send a
certificate, authentication fails if the end of the channel acting as the TLS server is defined:
• With the SSLCAUTH parameter set to REQUIRED or
• With an SSLPEER parameter value
There is no matching CA root certificate or the certificate chain is incomplete
Each digital certificate is issued by a Certificate Authority (CA), which also provides a root certificate
that contains the public key for the CA. Root certificates are signed by the issuing CA itself. If the
key repository on the computer that is performing the authentication does not contain a valid root