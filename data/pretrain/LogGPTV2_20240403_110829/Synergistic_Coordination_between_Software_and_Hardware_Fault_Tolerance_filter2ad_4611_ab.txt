igate the  effect of  software  design  faults, we  must ensure 
consistency  among different  processes’ views on  verified 
correctness (validity)  of process  states and messages.  Ac- 
cordingly, the MDCD algorithms aim to ensure that the er- 
ror recovery mechanisms can bring the system into a global 
state that satisfies the following two properties: 
Consistency  If, in a global state S ,  m is reflected as a mes- 
sage received  by  a  process,  then  m must  also be  re- 
flected in S  as a message sent by the sending process, 
and  the  sending  and  receiving  processes  must  have 
consistent views on the validity of m. 
Recoverability  If, in  a global  state S ,  m is reflected  as a 
message sent by  a  process,  then  m must also be  re- 
flected  in  S  as  a  message received  by  the  receiving 
process(es), and  the  sending and receiving  processes 
must have consistent views on the validity of m, or the 
error recovery algorithm must be able to restore m. 
Note that the above definitions are extended versions of 
the definitions of global  state consistency and recoverabil- 
ity  presented  (in  different  forms) in  [7, 8, 41.  For  clarity 
of  illustration,  in  the  remainder of  this  paper,  we  use  the 
terms “validity-concerned global  state consistency  and re- 
coverability” and “basic global state consistency and recov- 
erability” to refer to the extended and original versions, re- 
spectively, whenever it is necessary  to distinguish  between 
the two versions. 
The key assumption used in the derivation of the MDCD 
algorithms is that an erroneous state of a process is likely to 
affect the correctness of its outgoing messages, while an er- 
roneous message received by an application  software com- 
ponent will  result  in  process state contamination  [9].  Ac- 
cordingly, we save the state of a process via checkpointing 
if and only  if the process is at one of the following points: 
I ) immediately before its state becomes potentially contam- 
inated, or 2) right after its potentially  contaminated state is 
validated  as  a  non-contaminated state.  By  a  “potentially 
contaminated process state,”  we mean  i)  the  process state 
of  Pyt in  which  we  have  not  yet established  enough  con- 
fidence,  or ii)  a process state that  reflects  the  receipt of  a 
not-yet-validated  message that is sent by a process when its 
process state is potentially  contaminated. 
Figure  1 illustrates  the  above concepts.  The horizontal 
lines  in  the figure represent the  software executions along 
the time horizon. Each of the shaded regions represents an 
execution interval during which the state of the correspond- 
ing  process  is  potentially  contaminated.  In  the  diagram, 
checkpoints BI;, A,,  and Bk+2 are established  immediately 
before  a  process  state  becomes  potentially  contaminated 
(we call them Type-1 checkpoints), while B k + l ,   A,+1,  and 
B I ; + ~  are established  right after a potentially  contaminated 
process state gets validated as a non-contaminated state (we 
call them Type-2 checkpoints). 
Upon the detection of an error, P:dw will take over Pyt’s 
active role and prepare to resume normal computation with 
Pa.  By  locally  checking its  knowledge about  whether its 
371 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:58:44 UTC from IEEE Xplore.  Restrictions apply. 
process  state is contaminated or not  (which is represented 
by  a dirty-bit), a process will  decide to roll back (to its 
most recent checkpoint) or roll forward (i.e., to continue its 
execution from the current state), respectively.  After a roll- 
back  or roll-forward  action,  Pidw will  “re-send’’ the  mes- 
sages in its message log or further suppress messages it in- 
tends to send (up to a certain point), based on the knowledge 
about the validity of Pyt’s messages. 
We have derived  theorems showing that the rollback or 
roll-forward recovery decisions made locally by the individ- 
ual processes guarantee the validity-concerned global state 
consistency  and  recoverability  properties.  The  proofs  of 
those theorems are given in [ 5 ] .  
2.2  Time-Based Checkpointing Protocol 
The second of  the  two  protocols that  form the basis  of 
our coordination  scheme  is  the  time-based  checkpointing 
protocol  proposed  by  Neves  and  Fuchs  [4].  Time-based 
protocols  allow  processes  to  establish  checkpoints  using 
approximately  synchronized  and  periodically  resynchro- 
nized timers, thus eliminating the need for costly message- 
exchange based  coordination  among processes  and reduc- 
ing performance overhead [ IO, 41. 
If the timers were exactly synchronized, all the processes 
would  initiate  their  checkpoint  establishments  at  exactly 
the same time, so that  no consistency violation could hap- 
pen. Further, if  timer synchronization was perfect and mes- 
sage delivery took a negligible amount of time, recoverabil- 
ity  would  never be violated,  because “in-transit” messages 
would  not occur.  However,  in  a distributed system, timers 
cannot be perfectly synchronized, and message delivery de- 
lay  is  often  non-negligible.  Figure  2(a)  illustrates  a  sce- 
nario  in  which  global  state consistency and recoverability 
are violated.  In the scenario,  1)  after establishing its check- 
point,  process  Pa sends  a  message  ml  that  is  read  before 
process Pb  establishes a checkpoint, which destroys consis- 
tency; and 2) before establishing its checkpoint, Pb  sends a 
message 1n2 that is read by Pa after it completes its check- 
point establishment, so that  m2  becomes an in-transit mes- 
sage, which destroys  recoverability.  To  circumvent those 
problems,  time-based  checkpointing  protocols  use  strate- 
gies that ensure global state consistency and recoverability 
by blocking messages during some critical time periods be- 
fore and/or  after a process starts to save a checkpoint  (see 
Figure 2(b)). 
To reduce performance cost, the time-based checkpoint- 
ing protocol developed by  Neves and Fuchs and described 
in  [4] uses a blocking period  after a process starts to write 
a checkpoint to stable storage to ensure consistency but the 
protocol  does not  use  blocking for recoverability.  To  en- 
sure recoverability, this protocol saves all the messages for 
which  it  has  not  received  acknowledge responses  as  part 
of the next checkpoint.  Thus, when  hardware error recov- 
ery  is  invoked, the  protocol  will  be able to re-send  all the 
pb 
... 
m.\ 
/-m2 
n 
U 
0 - - - - 
saving current state to disk 
blocking period for recoverability 
....I.  blocking period for consistency 
Figure 2: Global State Consistency and Recoverability 
uriacknowledged  messages.  This  protocol  minimizes  the 
performance overhead due to blocking  by  1) avoiding the 
“blocking-for-recoverability” periods, and 2) retaining  the 
“blocking-for-consistency” periods,  as each of them over- 
laps  with  the  time  interval  during  which  a  stable-storage 
checkpoint establishment is in progress. 
3  MDCD Protocol Modification 
Since its goal  is to mitigate the effects of  software  de- 
sign  faults,  the MDCD protocol  allows checkpoints  to  be 
saved in local volatile storage (RAM), instead of stable stor- 
age (disk), in order to keep performance overhead low. The 
protocol  also has  the potential to tolerate hardware faults, 
since it offers us the option to save checkpoints selectively 
in  stable storage.  Specifically, a  broadcasted  “passed  AT’ 
notification  message  would  trigger  each  of  the  processes 
tcl  establish  a Type-2 checkpoint.  Since the  key  assump- 
tion used  for the MDCD algorithm derivation (see Section 
2.1) implies that if an outgoing message is validated by AT, 
then  the  process  state  of  the  sending  process  and  all  the 
messages sent or received prior  to performing  the  AT  can 
be considered non-contaminated and valid, respectively, the 
resulting Type-2 checkpoints would constitute a consistent 
global state. Hence, it is possible to derive a variant MDCD 
protocol  which  lets  each  process,  including  Py’,  save  a 
(Type-2) checkpoint  in  stable  storage  upon  the  receipt  of 
a “passed AT’ notification message. When a hardware fault 
occurs,  all  the  processes  roll  back  to  their  stable-storage 
checkpoints for error recovery. Unfortunately, this approach 
(which we call the  “write-through’’ approach) is unable to 
ensure  low performance overhead and  error recovery  effi- 
ciency, because the frequency of and time between Type-2 
checkpoint establishments depend on the external  message 
sending rate; thus, a process may suffer an excessive roll- 
back  distance  when  a hardware fault  occurs.  In  contrast, 
when the MDCD protocol  is used  for software fault toler- 
ance, rollback distance of a process is minimized through its 
372 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:58:44 UTC from IEEE Xplore.  Restrictions apply. 
P yt 
Ci 
\ 
I 
T 
r 
T 
Cirl 
- 1  
I 
4 MI 
Figure 3: Modified MDCD Protocol 
flexible, confidence-adaptive recovery behavior. That is, the 
process is able to choose between rollback and roll-forward, 
based on whether it is potentially contaminated. 
To  circumvent  the  inefficiencies  associated  with  the 
write-through  mechanism,  we  seek  an  approach  that  will 
enable the MDCD protocol  to coordinate with some hard- 
ware fault tolerance protocol  to achieve simultaneous soft- 
ware  and hardware fault tolerance.  A careful  study  led  us 
to choose the time-based  checkpointing protocol proposed 
by  Neves  and  Fuchs  in  [4] (which  is  reviewed  in  Section 
2.2). The rationale for this choice is that this particular time- 
based  protocol  is  characterized  by  low  performance cost 
[ 1 I ]   and  shares  the  “no-direct-coordination” feature  with 
the MDCD protocol. 
In  order to facilitate a synergistic coordination between 
the two protocols, we begin with making modifications for 
the MDCD error containment algorithms.  The objective is 
to  enable  the  MDCD protocol  to  ensure  the  readiness  of 
the  information  that  the  TB  protocol  will  require  for  es- 
tablishing  stable-storage  checkpoints  that  satisfy  validity- 
concerned  consistency  and  recoverability  properties.  Ap- 
pendix  A  provides  the  modified  algorithms, and Figure  3 
illustrates the behavior of the modified protocol. 
Recall  that with  the original MDCD protocol, Pidw will 
take  over the  active role of  Py‘ when  error recovery  is in- 
voked.  Hence,  Py’  is  exempted  from performing  check- 
pointing.  Also, since Py’ is created  from a low-confidence 
software component, the process  is invariably regarded  as 
potentially  contaminated  during  guarded operation,  such 
that  Py”s  d i r t y b i t  has  a  constant  value  of  one.  But 
when  hardware error recovery  is  concerned,  Py’ must  be 
able, when a hardware fault occurs, to roll back to its stable- 
storage checkpoint  and  restart  with  other processes  in  the 
In  order  to  enable  Py‘ 
system  to  resume  computation. 
to participate  in  the establishment of  stable-storage  check- 
points that  satisfy  the validity-concerned  global  state con- 
sistency and recoverability properties, we let Py’ maintain a 
“pseudo dirty bit”  ( p s e u d o - d i r t y b i t ) ,  in addition to its 
“actual”  d i r t y b i t  (which has  a constant  value  of  one). 
The value of p s e u d o - d i r t y h i t  is reset to zero when Py‘ 
passes  an  AT  or receives  a “passed  AT’ notification  mes- 
sage,  and  is  set  to  one  immediately before  Pyt sends an 
internal  application-purpose message,  as indicated  in  Fig- 
ure  3, respectively,  by  the  dashed  lines  below  and  above 
the shaded line representing PY”s potentially contaminated 
state.  By  examining  the  value  of  p s e u d o - d i r t y b i t ,  
P y  will  determine whether it  should establish a (volatile- 
storage) checkpoint before it sends an internal application- 
purpose message.  Specifically, if the value is zero, meaning 
that the internal message Py‘ intends to send is the first out- 
going  internal message since the  last AT-based validation, 
Py’ will establish a checkpoint before it sends the message. 
Thus, this checkpoint will be consistent with the checkpoint 
that  will  be  established  by  the receiving  process,  after re- 
ceiving  the  message and  before  passing  it  to  the  applica- 
tion.  We  call  a  checkpoint  of  Py‘ a  “pseudo checkpoint” 
(represented by  a hollow rectangle  in  Figure  3) due to  its 
relationship with the value of p s e u d o - d i r t y b i t .  
As shown in Figure 3, the modified protocol eliminates 
the Type-2 checkpoint establishment.  This is because  the 
coordination between  the MDCD and TB protocols,  as de- 
scribed  in  Section  4.2,  allows  error  recovery  to  be  inde- 
pendent of Type-2  checkpoints.  However, the knowledge- 
updating  actions  (i.e.,  changing the  value  of  d i r t y b i t ,  
updating the valid message register V R ~ ~ ~ ,
etc.)  taken  by  a 
process when it passes an AT or receives a “passed AT’ no- 
tification message are preserved in the modified algorithms. 
Finally, since the adapted TB protocol (described in the 
next section) will enforce a blocking period when a process 
starts to save a checkpoint to stable storage upon the expi- 
ration of its checkpointing timer, the MDCD algorithms are 
accordingly modified such that during the blocking period: 
1)  An  incoming application-purpose message will not be 
passed to the application, and 
2)  When  a  “passed  AT’  notification  message  arrives, 
the  d i r t y b i t  (or  p s e u d o - d i r t y b i t )  will  be re- 
set if  and only  if  the  piggybacked  sequence number 