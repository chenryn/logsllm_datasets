using this symmetric key 3. Next, it creates a memory allocation tagged 
with read-write permissions using kernel32!VirtualAlloc() 4 and then copies 
the decrypted shellcode into it 5 ahead of execution. The function then 
changes the memory permissions of the new buffer to tag it as executable 6. 
Finally, the pointer to the buffer is passed to kernel32!CreateThread(), which 
executes the shellcode in a new thread 7, still under the context of excel.exe.
Delivering the Payload
We’ll assume that Binford’s inbound mail-filtering system allows XLL files 
to reach users’ inboxes, and we send our file to the white cell. Because the 
XLL needs to be run from disk, the white cell will download it to the inter-
nal host on which the EDR is deployed.
When the white cell executes the XLL, a few things will happen. First, 
excel.exe will be started with the path to the XLL passed in as a parameter. 
The EDR almost certainly collects this information from its driver’s process-
creation callback routine (though the Microsoft-Windows-Kernel-Process 
ETW provider can provide most of the same information). The EDR may 
have a generic detection built around the execution of XLL files, which the 
process command line could trigger, causing an alert.
Additionally, the EDR’s scanner may conduct an on-access scan of the 
XLL file. The EDR will collect attributes of the file, assess its contents, and 
attempt to decide whether the content should be allowed to run. Let’s say 
that we did such a great job obfuscating our payload that the shellcode and 
associated runner inside weren’t detected by the scanner.
We’re not in the clear yet, though. Remember that most EDRs are 
deployed in multiple large environments and process large amounts of 
data. With this perspective, EDRs can assess the global uniqueness of a file, 
Evading EDR (Early Access) © 2023 by Matt Hand
Case Study: A Detection-Aware Attack   241
meaning how many times it has seen the file in the past. Because we crafted 
this payload ourselves and it contains shellcode tied to our infrastructure, it 
most likely hasn’t been seen before.
Luckily, this isn’t the end of the road by any stretch of the imagination. 
Users write new Word documents all the time. They generate reports for 
their organization and doodle in Paint during the third hour of meetings 
on “cross-functional synergy to meet key quarterly metrics.” If EDRs flagged 
every single unique file they came across, they would create an untenable 
amount of noise. While our global uniqueness may trigger some type of 
alert, it probably isn’t severe enough to kick off an investigation and won’t 
come into play unless the security operations center (SOC) responds to a 
higher-severity alert related to our activity.
Executing the Payload
Since we haven’t been blocked yet, excel.exe will load and process our XLL. 
As soon as our XLL is loaded, it will hit the DLL_PROCESS_ATTACH reason code, 
which triggers the execution of our shellcode runner.
When our parent excel.exe process was spawned, the EDR injected its 
DLL, which hooked key functions unknown to us at this point. We didn’t 
use syscalls or include any logic to remap these hooked DLLs in excel.exe, 
so we’ll have to pass through these hooks and hope we don’t get caught. 
Thankfully, many of the functions commonly hooked by EDRs focus on 
remote process injection, which doesn’t affect us, as we’re not spawning a 
child process to inject into.
We also happen to know that this EDR makes use of the Microsoft-
Windows-Threat-Intelligence ETW provider, so our activities will be subject 
to monitoring by those sensors on top of the EDR vendor’s own function 
hooks. Let’s examine the riskiness of the functions we call in our payload:
kernel32!VirtualAlloc ()
Since this is the standard local-memory-allocation function in Windows 
and doesn’t allow for remote allocations (as in, memory being allocated 
in another process), its use likely won’t be scrutinized in isolation. 
Additionally, because we aren’t allocating read-write-execute memory, 
a common default for malware developers, we’ve mitigated pretty much 
all the risk that we can.
memcpy()
Similar to the previous function, memcpy() is a widely used function and 
isn’t subject to much scrutiny.
kernel32!VirtualProtect()
This is where things become riskier for us. Because we have to convert 
the protections for our allocation from read-write to read-execute, 
this step is unfortunately unavoidable. Since we’ve passed the desired 
protection level as a parameter to this function, EDRs can trivi-
ally identify this technique via function hooking. Additionally, the 
Evading EDR (Early Access) © 2023 by Matt Hand
242   Chapter 13
nt!EtwTiLogProtectExecVm() sensor will detect the changes in protec-
tion state and notify consumers of the Microsoft-Windows-Threat-
Intelligence ETW provider.
kernel32!CreateThread()
In isolation, this function doesn’t present much of a risk, as it is the 
standard way of creating new threads in multithreaded Win32 appli-
cations. However, since we’ve performed the previous three actions, 
which, combined, may indicate the presence of malware on the system, 
its use may be the proverbial straw that breaks the camel’s back in terms 
of causing an alert to fire. Unfortunately for us, we don’t really have 
many options to avoid its use, so we’ll just stick with it and hope that if 
we’ve gotten this far, our shellcode will execute.
This shellcode runner technique could be optimized in plenty of ways, 
but compared to the textbook kernel32!CreateRemoteThread()-based approach 
to remote process injection, it’s not too bad. If we assume that these indi-
cators fly under the radar of the EDR’s sensors, our agent shellcode will 
execute and begin its process of communicating back to our command-
and-control infrastructure.
Establishing Command and Control
Most malicious agents establish command and control in similar ways. The 
first message the agent sends to the server is a check-in saying “I’m a new 
agent running on host X!” When the server receives this check-in, it will 
reply “Hello agent on host X! Sleep for this period of time, then message 
me again for tasking.” The agent then idles for the time specified by the 
server, after which it messages it again saying “Back again. This time I’m 
ready to do some work.” If the operator has specified tasking for the agent, 
the server will pass that information along in some format understood by the 
agent, and the agent will execute the task. Otherwise, the server will tell 
the agent to sleep and try again later.
How do command-and-control agents evade detection? Most of the 
time, the communication happens over HTTPS, the favorite channel of 
most operators because it lets their messages blend in with the high volume 
of traffic commonly flowing to the internet over TCP port 443 on most 
workstations. To use this protocol (and its less-secure sister, HTTP), the 
communication must follow certain conventions.
For example, a request must have a Uniform Resource Identifier (URI) 
path for both GET requests, used for retrieving data, and POST requests, 
used for sending data. While these URIs don’t technically have to be the 
same in each request, many commercial command-and-control frameworks 
reuse one static URI path. Additionally, the agent and server must have an 
agreed-upon communication protocol that rides on top of HTTPS. This 
means that their messages generally follow a similar pattern. For instance, 
the lengths of check-in requests and polls for tasking will likely be static. 
They may also be sent at fixed intervals.
Evading EDR (Early Access) © 2023 by Matt Hand
Case Study: A Detection-Aware Attack   243
All of this is to say that, even when command-and-control traffic attempts 
to blend in among the noise, it still generates strong indicators of beaconing 
activity. An EDR developer who knows what to look for can use these to pick 
out the malicious traffic from the benign, probably using the network filter 
driver and ETW providers such as Microsoft-Windows-WebIO and Microsoft-
Windows-DNS-Client. While the contents of HTTPS messages are encrypted, 
many important details remain readable, such as the URI paths, headers, 
message lengths, and the time at which the message was sent.
Knowing this, how do we set up our command and control? Our 
HTTPS channel uses the domain blnfordtools.com. We purchased this 
domain a few weeks before the operation, set up DNS to point to a 
DigitalOcean virtual private server (VPS), and configured an NGINX web 
server on the VPS to use a LetsEncrypt SSL certificate. GET requests will 
be sent to the /home/catalog endpoint and POST requests to /search?q=6100, 
which will hopefully blend into normal traffic generated when browsing a 
tool manufacturer’s site. We set our default sleep interval to five minutes to 
allow us to quickly task the agent without being overly noisy, and we use a 
jitter of 20 percent to add some variability between request times.
This command-and-control strategy might seem insecure; after all, 
we’re using a newly registered, typo-squatted domain hosted on a cheap 
VPS. But let’s consider what the EDR’s sensors can actually capture:
• 
A suspicious process making an outbound network connection
• 
Anomalous DNS lookups
Notably missing is all the weirdness related to our infrastructure and indi-
cators of beaconing.
Although the EDR’s sensors can collect the data required to determine 
that the compromised host is connecting to a newly registered, uncatego-
rized domain pointing to a sketchy VPS, actually doing this would mean 
performing a ton of supporting actions, which could negatively affect sys-
tem performance.
For example, to track domain categorization, the EDR would need to 
reach out to a reputation-monitoring service. To get registration informa-
tion, it would need to query the registrar. Doing all of this for all connections 
made on the target system would be hard. For that reason, EDR agents typi-
cally offload these responsibilities to the central EDR server, which performs 
the lookups asynchronously and uses the results to fire off alerts if needed.
The indicators of beaconing are missing for nearly the same reasons. 
If our sleep interval were something like 10 seconds with 10 percent jitter, 
detecting the beaconing could be as simple as following a rule like this one: 
“If this system makes more than 10 requests to a website with nine to 11 sec-
onds between each request, fire an alert.” But when the sleep interval is five 
minutes with 20 percent jitter, the system would have to generate an alert 
anytime the endpoint made more than 10 requests to a website with four 
to six minutes between each request, which would require maintaining the 
rolling state of every outbound network connection for between 40 minutes 
and one hour. Imagine how many websites you visit on a daily basis, and you 
can see why this function is better suited for the central server.
Evading EDR (Early Access) © 2023 by Matt Hand
244   Chapter 13
Evading the Memory Scanner
The last big threat to the initial access phase of the engagement (as well as 
any future stages in which we spawn an agent) is the EDR’s memory scan-
ner. Like the file scanner, this component seeks to detect the presence 
of malware on the system using static signatures. Instead of reading the 
file from disk and parsing its contents, it scans the file after it has been 
mapped into memory. This allows the scanner to assess the content of the 
file after it has been de-obfuscated so that it can be passed to the CPU 
for execution. In the case of our payload, this means our decrypted agent 
shellcode will be present in memory; the scanner needs only to find it and 
identify it as malicious.
Some agents include functionality to obscure the presence of the 
agent in memory during periods of inactivity. These techniques have 
varying levels of efficacy, and a scanner could still detect the shellcode 
by catching the agent between one of these sleep periods. Even so, cus-
tom shellcode and custom agents are generally harder to detect through 
static signatures. We’ll assume that our bespoke, handcrafted, artisanal 
command-and-control agent was novel enough to avoid being flagged by 
the memory scanner.
At this point, everything has worked in our favor: our initial beacon-
ing didn’t fire off an alert worthy of the SOC’s attention. We’ve estab-
lished access to the target system and can begin our post-compromise 
activities.
Persistence
Now that we’re inside the target environment, we need to make sure we can 
survive a technical or human-induced loss of connection. At this stage of 
the operation, our access is so fragile that if something were to happen to 
our agent, we’d have to start over from the beginning. Therefore, we need 
to set up some form of persistence that will establish a new command-and-
control connection if things go south.
Persistence is a tricky thing. There are an overwhelming number of 
options at our disposal, each with pros and cons. Generally speaking, we’re 
evaluating the following metrics when choosing a persistence technique:
Reliability  The degree of certainty that the persistence technique will 
trigger our action (for example, launching a new command-and-control 
agent)
Predictability  The degree of certainty about when the persistence will 
trigger
Required permissions  The level of access required to set up this per-
sistence mechanism
Required user or system behaviors  Any actions that must occur on 
the system for our persistence to fire, such as a system reboot or a user 
going idle
Evading EDR (Early Access) © 2023 by Matt Hand
Case Study: A Detection-Aware Attack   245
Detection risks  The understood risk of detection inherent to the 
technique
Let’s use the creation of scheduled tasks as an example. Table 13-1 
shows how the technique would perform using our metrics. Things seem 
great initially. Scheduled tasks run like a Rolex and are incredibly easy 
to set up. The first issue we encounter is that we need local administrator 
rights to create a new scheduled task, as the associated directory,  
C:\Windows\System32\Tasks\, can’t be accessed by standard users.
Table 13-1: Evaluating Scheduled Tasks as a Persistence Mechanism
Metric
Evaluation
Reliability
Highly reliably
Predictability
Highly predictable
Required permissions
Local administrator
Required user or system  
behaviors
System must be connected to the  
network at the time of the trigger
Detection risks
Very high
The biggest issue for us, though, is the detection risk. Attackers have 
abused scheduled tasks for decades. It would be fair to say that any EDR 
agent worth its weight would be able to detect the creation of a new sched-
uled task. As a matter of fact, MITRE’s ATT&CK evaluations, a capability-
validation process that many vendors participate in every year, uses 
scheduled-task creation as one of its test criteria for APT3, an advanced per-
sistent threat group attributed to China’s Ministry of State Security (MSS). 
Because remaining stealthy is one of our big goals, this technique is off the 
table for us.
What persistence mechanism should we choose? Well, nearly every 
EDR vendor’s marketing campaign claims that it covers most catalogued 
ATT&CK techniques. ATT&CK is a collection of known attacker techniques 
that we understand well and are tracking. But what about the unknowns: the 
techniques about which we are mostly ignorant? A vendor can’t guarantee 
coverage of these; nor can they be assessed against them. Even if an EDR has 
the ability to detect these uncatalogued techniques, it might not have the 
detection logic in place to make sense of the telemetry generated by them.
To lower our likelihood of detection, we can research, identify, and 
develop these “known unknowns.” To that end, let’s use shell preview han-
dlers, a persistence technique that I, along with my colleague Emily Leidy, 
published research about in a blog post, “Life is Pane: Persistence via 
Preview Handlers.” Preview handlers install an application that renders a 
preview of a file with a specific extension when viewed in Windows Explorer. 
In our case, the application we register will be our malware, and it will kick 
off a new command-and-control agent. This process is done almost entirely 
in the registry; we’ll create new keys that register a COM server. Table 13-2 
evaluates this technique’s riskiness.
Evading EDR (Early Access) © 2023 by Matt Hand
246   Chapter 13
Table 13-2: Evaluating Shell Preview Handlers as a Persistence Mechanism
Metric
Evaluation
Reliability
Highly reliable
Predictability
Unpredictable
Required permissions
Standard user
Required user or 
 system behaviors
User must browse the target file type  
in Explorer with the preview pane enabled, or the search  
indexer must process the file
Detection risks
Currently low but trivial to detect
As you can see, these “known unknowns” tend to trade strengths in 
some areas for weaknesses in others. Preview handlers require fewer per-
missions and are harder to detect (though detection is still possible, as their 
installation requires very specific registry changes to be made on the host). 
However, they are less predictable than scheduled tasks due to user-inter-
action requirements. For operations in which detection isn’t a significant 
concern, reliability and usability may trump the other factors.
Say we use this persistence mechanism. In the EDR, sensors are now hard 
at work collecting telemetry related to the hijacked preview handlers. We had 
to drop a DLL containing a runner for our backup agent to disk from excel.
exe, so the scanner will probably give it a thorough examination, assuming 
that Excel writing a new DLL isn’t suspect enough. We also had to create a 
ton of registry keys, which the driver’s registry-notification callback routine 
will handle.
Also, the registry-related telemetry our actions generate can be a little 
difficult to manage. This is because COM object registration can be tricky 
to pick out from the large volume of registry data, and because it can be 
challenging to differentiate a benign COM object registration from a mali-
cious one. Additionally, while the EDR can monitor the creation of the new 
preview-handler registry-key value, as it has a standard format and location, 
this requires performing a lookup between the class identifier written as 
the value and the COM object registration associated with that class identi-
fier, which isn’t feasible at the sensor level.
Another detection risk is our manual enablement of Explorer’s preview 
pane. This isn’t crazy behavior on its own. Users can manually enable or 
disable the preview pane at any time through their file browser. It can also 
be enabled across the enterprise via a group policy object. In both of these 
instances, the process making the change (for example, explorer.exe in the 
case of manual enablement) is known, meaning that a detection targeting 
atypical processes setting this registry value may be possible. Excel.exe mak-
ing this change would be very much out of the ordinary.
Finally, Explorer has to load our DLL whenever the persistence is trig-
gered. This DLL won’t be signed by Microsoft (or likely signed at all). The 
driver’s image-load callback notification routine will be responsible for 
detecting this DLL being loaded and can investigate the signature, along 
with other metadata about the image, to tip off the agent to the fact that a 
Evading EDR (Early Access) © 2023 by Matt Hand
Case Study: A Detection-Aware Attack   247
piece of malware is about to be mapped into Explorer’s address space. Of 
course, we could mitigate some of this risk by signing our DLL with a valid 
code-signing certificate, but this is beyond the reach of many threat actors, 
both real and simulated.
We’ll make a trade-off in predictability in favor of lowering our detec-
tion risk. We choose to install a preview handler for the .docx file extension 
by dropping our handler DLL to disk, performing the requisite COM regis-
tration, and manually enabling Explorer’s preview pane in the registry if it 
is not already enabled.
Reconnaissance
Now that we’ve established persistence, we can afford to start taking more 
risks. The next thing we need to figure out is how to get to where we need 
to go. This is when you must think the hardest about detection because 
you’ll generate vastly different indicators based on what you’re doing and 
how you do it.
We’ll need a way to run reconnaissance tooling without detection. 
One of my favorite tools for performing local reconnaissance is Seatbelt, a 
host-based situational awareness tool written by Lee Christensen and Will 
Schroeder. It can enumerate a ton of information about the current system, 
including the running processes, mapped drives, and amount of time the 
system has been online.
A common way to run Seatbelt is to use built-in features of the com-
mand-and-control agent, such as Cobalt Strike Beacon’s execute-assembly, 
to execute its .NET assembly in memory. Typically, this involves spawning a 
sacrificial process, loading the .NET common language runtime into it, and 
instructing it to run a specified .NET assembly with provided arguments.
This technique is substantially less detection prone than trying to drop 