DSearch1.
ASearch2 linearly scans A outside of the enclave and checks
for each value v ∈ A if it falls in either range that was returned
by DSearch2. Finally, ASearch2 returns the RecordIDs rid of
the matching values.
ED3. This encrypted dictionary combines the repetition option
frequency revealing and the order option unsorted. Accordingly,
EncDB3 performs the frequency revealing column split and
randomly shufﬂes the unique values in D, resulting in an
unsorted dictionary. Afterwards, the ValueIDs in A are set
such that the split is correct and each v ∈ D is encrypted with
AEEnc under SK D. Fig. 3d shows an example for EncDB3
before AEEnc is performed. EncDB3 trivially has no order
leakage.
ED3’s unsorted dictionary prevents any dictionary search
with logarithmic runtime. Instead, DSearch3 performs a linear
scan over all values in eD.
ASearch3 compares each v ∈ A with each u ∈ vid returned
by DSearch3. Thus, the runtime complexity is O(|A| · |vid| ).
Integers are compared in this case, which is a highly optimized
operation in most CPUs and ASearch3 is easily parallelizable.
2) Frequency smoothing: The main problem of the fre-
quency revealing option is that an attacker can learn the
frequency of each value Dj ∈ D, even if the values are
encrypted. The reason is that the underlying plaintext values are
present only once with a unique ValueID. As a countermeasure,
the frequency smoothing option inserts plaintext duplicates into
D during the column split, bounding the frequency leakage.
The foundation of this repetition option is the Uniform Random
Salt Frequencies method [48].
In more detail,
the frequency smoothing column split
executes a parameterizable and probabilistic experiment for
each unique value v ∈ un(C) to determine how often v should
be inserted into D (see Algorithm 4). We say that a plaintext
value v is split into multiple buckets and every bucket has a
speciﬁc size. The random experiment receives the number of
occurrences of v in C (|oc(v, C)|) and a bucket size maximum
bsmax. The random size for an additional bucket is picked
from the discrete uniform distribution U{1, bsmax} until the
total size is above |oc(v, C)|. The size of the last bucket is then
set such that the total size matches |oc(v, C)|. The experiment
returns the bucket sizes Bsizes.
(cid:2)
(cid:2) repetitions of v into D.
For each i ∈ oc(v, C), it randomly inserts one of the
(cid:2)
(cid:2)
(cid:2)Bsizes
(cid:2)
possible ValueIDs into Ai. Each ValueID is used exactly as
often as deﬁned by Bsizes. As a result, the frequency leakage
has a bound, because the number of occurrences of each
ValueID in A is guaranteed to be between 1 and bsmax.
The column split inserts
(cid:2)
(cid:2)Bsizes
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:24:56 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 4 getRndBucketSizes( |oc(v, C)| , bsmax)
1: prevT otal = total = 0
2: Bsizes = ∅
3: while total < |oc(v, C)| do
4:
5:
6:
7:
8: end while
9: Bsizes.Last = |oc(v, C)| − prevT otal
10: return Bsizes
rnd $←− [1, bsmax]
Bsizes.Append(rnd)
prevT otal = total
total += rnd
bsmax can be chosen independently for each column. The
selection affects |D|, which impacts storage efﬁciency, search
time, and frequency leakage. For instance, a large bsmax leads
to few repeating entries in D, which slightly increases |D|
compared to the frequency revealing option. This decreases the
DSearch performance, because more data needs to be loaded
into the enclave, more decryptions are performed, and more
comparisons are necessary. The performance of ASearch also
decreases, because more values have to be compared. A small
bsmax leads to many repetitions in D, which further increases
|D| and the search time. Yet, it leads to a low frequency
leakage bound, as each ValueID in A is present at most bsmax
times.
Next, we explain how the frequency smoothing column split
impacts the three order options, which were introduced in
detail before. We omit the discussion of order leakage as it
is independent of the repetition option. We do not explain
ASearch4–ASearch6, because they are equal to ASearch1–
ASearch3.
ED4. EncDB4 performs the frequency smoothing column split
and sorts all values in D lexicographically determining the
order of repetitions randomly. Then, it adjusts the ValueIDs in
A such that the split is correct while considering how often
each ValueID can be used, which is deﬁned by Bsizes. Finally,
EncDB4 encrypts each v ∈ D with AEEnc under SK D. Note
the IND-CCA security of AE guarantees that an attacker cannot
distinguish ciphertexts with an equal underlying plaintext except
with negligible probability.
DSearch4 is equal
to DSearch1, because leftmost and
rightmost binary searches inherently handle repetitions. The
performance penalty compared to ED1 is small, because the
binary search only slows down logarithmically with a growing
|D|.
ED5. EncDB5 performs the frequency smoothing column split,
rotates the ValueIDs as described in EncDB2, sets the ValueIDs
in A such that the split is correct (considering Bsizes), and
encrypts each v ∈ D with AEEnc under SK D. Fig. 4 shows
an example for ED5 with bsmax = 3 and rndOffset = 1 not
considering the encryption.
The special binary searches are more complex for ED5
than for ED2, because they have to handle a corner case: the
plaintext value of the last and ﬁrst entry in D might be equal
and present more than two times (as in the example in Fig. 4).
Additionally, DSearch5 has to perform a more complicated
postprocessing of vidmin and vidmax compared to DSearch2.
444
Column
RecordID
0
1
2
3
4
5
6
FName
Jessica 
Ella
Archie
Jessica 
Jessica 
Archie
Archie
Dictionary
Value
Jessica 
Archie
Archie
Ella
Jessica 
Jessica 
ValueID
0
1
2
3
4
5
Attribute Vector
ValueID
0
3
2
4
5
2
1
RecordID
0
1
2
3
4
5
6
Fig. 4: Example for ED5 with bsmax = 3 and rndOffset = 1 without
encryption.
The performance penalty compared to ED2 is small, because
the binary search slows down logarithmically in |D|.
ED6. For columns that are protected with ED6, EncDB6
performs the frequency smoothing column split, randomly
shufﬂes the values in D, sets the ValueIDs in A such that
the split is correct (considering Bsizes), and encrypts each
v ∈ D with AEEnc under SK D. DSearch6 is equal to
DSearch3, but the linear scan loads, decrypts, and compares
more values if D contains duplicates. If DSearch6 returns more
values compared to DSearch3, the number of comparisons in
ASearch6 increases.
3) Frequency hiding: Now we discuss the column split of
the frequency hiding option, which prevents frequency leakage.
The idea is to add a separate entry into D for every value
in C, i.e., ∀ i ∈ [0,|C| − 1] : Di = Ci. In other words, each
unique value v ∈ un(C) is added |oc(v, C)| times into D.
The attribute vector is set such that the split is correct and each
ValueID is used once. The resulting dictionary encoding does
not provide compression anymore (|D| = |C| = |A| ), but
the frequency of every ValueID is perfectly equal, i.e., there is
no frequency leakage.
ED7, ED8 and ED9. EncDB7, EncDB8 and EncDB9 perform
the frequency hiding column split of C; sort, rotate, and
randomly shufﬂe D, respectively; adjusts the ValueIDs in A
such that the split is correct and every ValueID is only used
once in A; and encrypt each v ∈ D with AEEnc under SK D.
Frequency hiding can be interpreted as a special case of
frequency smoothing with a bsmax of 1. Therefore, the DSearch
and ASearch operations are equal as described for ED4, ED5,
and ED6, and the advantages and disadvantages are equivalent
to the ones described for a small bsmax.
A. Additional Functionality
Joins. Join operators are implemented by replacing the opera-
tions on ciphertexts with calls to the enclave. All join algorithms
(hash-based, merge-sort and nested loop) are compatible with
all encrypted dictionaries, although optimizations are feasible
but out of scope. The access pattern can be hidden using
oblivious joins [49]. However, since some of the dictionaries
already leak the access pattern,
the additional protection
only applies to some encrypted dictionaries. We present an
exemplary algorithm for hash-based joins with enclave calls
in Algo. 5.
Dynamic data. So far, we only discussed static data, i.e.,
the data owner prepares the data once and uploads it to an
EncDBDB-enabled cloud provider. This is sufﬁcient for most
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:24:56 UTC from IEEE Xplore.  Restrictions apply. 
(cid:3) Iterate attribute vector of C1
(cid:3) Iterate attribute vector of C2
D = ResolveDictionary(A)
h = CalculateHashInEnclave(D)
HashT able.Insert(h, D)
Algorithm 5 Hash-based join for columns C1 and C2
1: for all A ∈ A1 do
2:
3:
4:
5: end for
6: for all A ∈ A2 do
7:
8:
9:
10:
11:
12:
13:
14:
15: end for
D = ResolveDictionary(A)
h = CalculateHashInEnclave(D)
T = HashT able.Get(h)
for all T ∈ T do
if CompareInEnclave(D, T) == true then
ResultT able.Append(D, T)
end if
end for
analytical scenarios, because bulk loading of data is often used
in this context and complex, read-only queries are executed
afterwards [50], [22]. For other usage scenarios, we present an
approach on how EncDBDB can support dynamic data, i.e.,
data insertions, deletions, and updates.
We use a concept called delta store (or differential
buffer) [51], [52], [22]: the database—more speciﬁcally each
column—is split into a read optimized main store and a
write optimized delta store. Both stores have a validity vector
indicating whether a row is valid. New values are appended to
the delta store and the corresponding rows are marked valid.
For updated values, the new value is appended to the delta
store, the row is marked valid, and the corresponding old row
is marked invalid. Deletions are realized by an update of the
validity bit. The overall state of the column is the combination
of both stores. Thus, a read query becomes more complex: it
is executed on both stores normally and the results are merged
while checking the validity of the entries. The delta store should
be kept orders of magnitude smaller than the main store to
efﬁciently handle read queries. This is done by periodically
merging the data of the delta store into the main store. H¨ubner
et al. [52] describe different merging strategies.
For EncDBDB, any encrypted dictionary can be used for
the main store and ED9 should be employed for the delta
store. New entries can simply be appended to a column of type
ED9 by re-encrypting the incoming value inside the enclave.
Searches in the delta store use DSearch9 and ASearch9. As a
result, neither the data order nor the frequency is leaked during
the insertion and search. A drawback of ED9 is that it has a
high memory space overhead and low performance. However,
the periodic merges mitigate this problem. The enclave handles
the merging process as follows: First, it re-encrypts every value
in D. Then, it randomly re-rotated columns with the rotated
order option and reshufﬂes columns with the unsorted order
option. This process has to be implemented in a way that hides
the relationship between values in the old and new main store,
e.g., with oblivious memory primitives [53], [54].
Counts, aggregations, and average calculations. For ED1–
ED3 a count query is processed without any calls to the enclave
by simply scanning the attribute vector, counting the occurrence
of each ValueID, and returning the count together with the
corresponding encrypted dictionary entry. For ED4–ED9, a
count query is handled by the enclave with the following
process: it performs the ValueID counting, performs a dictionary
scan to merge the counts, and returns the counts together with
re-encrypted dictionary entries. For all encrypted dictionaries,
aggregations and average calculations are performed in the
enclave with a slight deviation of the just described process:
instead of merging the counts, the enclave uses the dictionary
scan to calculate the aggregate or average and returns the
encrypted result. These operations do not leak any information.
V. IMPLEMENTATION
For our experiments we implemented a prototype based
on MonetDB, an open-source, column-oriented, in-memory
DBMS [18], [21], [55]. MonetDB focuses on read-dominated,
analytical workloads and thus perfectly ﬁts our use case.
MonetDB uses a variant of dictionary encoding for all string
columns: The attribute vector contains offsets to the dictionary,
but the dictionary contains data in the order it is inserted (for
non-duplicates). The dictionary does not contain duplicates if
it is small (below 64 kB), and a hash table and collision lists
are used to locate entries. The collision list is only used as
long as the dictionary does not exceed a certain size. As a
result, the dictionary might store values multiple times.
We implemented the nine encrypted dictionaries as SQL
data types in the frontend and new internal data types in
the backend. The encrypted dictionaries can be used in SQL
create table statements like any other data type, e.g., CREATE
TABLE t1 (c1 ED7, c2 ED5, ...). We further split
each dictionary into a dictionary head and dictionary tail. The
dictionary tail contains variable length values that are encrypted
with AES-128 in GCM mode. The values are stored sequentially
in a random order. The dictionary head contains ﬁxed size offset
to the dictionary tail and the values are ordered according to
the selected encrypted dictionary. This split is done to support
variable length data while enabling an efﬁcient binary search.
Each dictionary search has an own call to the enclave (ECall),
which receives a pointer to the encrypted dictionary, and the
enclave directly loads the data from the untrusted host process.
Thus, only one context switch is necessary for each query.
Furthermore, all operations have been parallelized to the extent
possible.
VI. EVALUATION