SENSS clients have low incentive to misbehave. Clients are un-
likely to send excessive requests to the server because they need to
pay for each request. SENSS security mechanisms further ensure
that client actions only affect traffic and routes to their own prefixes.
However, a SENSS ISP cannot check if a victim is under attack,
and it does not need to. Any network can use SENSS to require its
traffic and routes to be handled in certain way by upstream ISPs,
even when it is not under attack. It is up to ISPs to set the pricing
scheme in such a way to fully recoup their costs of running SENSS,
and to discourage excessive messages.
SENSS servers could lie about their observations or fail to im-
plement control actions, for which they have charged the victim. In
replies to traffic_queries a SENSS server may claim that it sends or
receives more or less traffic than it does, and it may report a fake dis-
tribution of traffic over real or fake tags. In replies to route_queries
a SENSS ISP may make up AS path segments. Table 3 lists all the
possible ways a server may lie in its reports (column 2), and the
wrong decisions the victim may make (column 3).
The overall effect that a lying server has on SENSS operation
falls into only two categories: Legacy or Dropper. A Legacy liar has
no effect on victim’s traffic, but the victim pays for its reports. For
example, if a SENSS server lies about its traffic to make it smaller,
its effect is that of a legacy ISP. Legacy liars prolong the attack
mitigation and make it more costly for the victim, but they cannot
make the victim drop legitimate traffic, postpone attack mitigation
indefinitely or influence victim’s actions at other ISPs. A Dropper
liar can drop some victim’s traffic due to its lying, e.g., through the
victim installing unnecessary filters at the lying ISP. For example,
if a SENSS server reports a higher traffic on its links, it may create
a dropper effect. Dropper liars are already on the data path and can
drop traffic even without SENSS, so SENSS does not make the
situation any worse.
Attack
Flood w and w/o sig
Reflector
Cross-fire
Cross-fire
Message (Lie)
TR (IN  Actual)
None
TR (OUT = IN)
Action, effect at liar
No filter, Legacy
Filter, Dropper
None, Legacy
TR (OUT > Actual)
RR (fake seg.)
TR (fake seg.)
Demote larger seg., Legacy
Demote fake seg., Legacy
Demote fake seq., Legacy
Table 3: Lying ISP scenarios and their effect (TR: traffic query reply,
RR: route query reply)
A server may fail to render the requested services, but still charge
the victim for them, thus increasing own profits. A server could
also extort the victim by dropping its traffic and then charging for
diagnosis and mitigation. Both of these attacks are made possible by
SENSS, because it allows the ISPs to charge victims when handling
SENSS requests. While we cannot prevent these attacks, we sketch
here how a victim can build a reputation score for each server, and
use it to avoid underperforming or extortionist servers. The victim
can monitor the effect of each control message by measuring the
traffic it receives after the message was accepted and processed by a
SENSS server. Control messages, which fail to reduce attack traffic
would indicate underperforming servers. The victim can use each
instance of underperformance to internally assign some bad repu-
tation points to the given SENSS server. After a while these would
accrue, allowing the victim to identify and avoid such servers in
the future. Similarly, the victim can detect Dropper ISPs by running
our client program for cross-fire handling. If a given AS is a part of
the bottleneck segment, the victim can assign some bad reputation
points to this AS. When the reputation declines significantly, the
victim can conclude that that AS is a Dropper ISP and the victim
can use SENSS to demote routes containing this AS.
4 EVALUATION
In this Section we first evaluate SENSS’s effectiveness in sparse
deployment, using a simulation. We use an AS-level simulator of the
Internet, developed in Perl. We first illustrate how SENSS would help
in an attack scenario similar to the 2016 attack on Dyn [35]. We then
evaluate SENSS’s effectiveness in sparse deployment and show that:
(1) direct customers of SENSS ISPs have immediate benefits and
are fully protected against direct floods and reflector attacks – this is
an excellent deployment incentive for ISPs, (2) strategic deployment
at 0.1–0.8% of all ISPs (0.3–3% of transit ISPs) protects everyone
against 90% of floods, and (3) SENSS outperforms cloud-based
DDoS defenses, saving 2–4 times more bandwidth.
We next evaluate SENSS’s response speed, scalability and over-
head, using a SENSS prototype on the DeterLab testbed [2], in the
186-switch, Cogent topology from TopologyZoo. SENSS’s message
processing delay scales linearly with the number of switches and
concurrent requests and it is 0.05–0.25 seconds per request.
In this section we use AS and ISP terms interchangeably, for
simplicity.
4.1 Evaluation Methodology
Simulation methodology. For our effectiveness tests, we infer
AS-level topology and routing from CAIDA’s [5] AS relationships
SENSS Against Volumetric DDoS Attacks
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
(a) Flood w sig and reflector – top
(b) Flood w/o sig – top
(c) Cross-fire – top
(d) Flood w sig and reflector – random
(e) Flood w/o sig – random
(f) Cross-fire – random
Figure 5: DDoS attack filtered, versus the percentage of transit ASes deploying SENSS, given the top and the random deployment
strategy.
dataset, from May 1st, 2017. There are 57,552 ASes, 114,018 customer-
provider links and 133,795 peer-to-peer links. Routing is inferred
using the no-valley, customer-prefer approach [9].
In each attack instance we deploy SENSS on some ASes, follow-
ing one chosen deployment strategy, and we simulate legitimate and
attack traffic flows as aggregates on inter-AS links. We simulate just
the aggregate rate of each flow and not its packets, nor details (e.g.,
source and destination addresses, ports or transport protocol). When
we simulate flood w sig, we assume that attack traffic is so different
from the legitimate traffic, that it is possible to devise a header-level
signature for its filtering. Installing a filter on some SENSS ISP in
the simulation of flood w sig only removes attack traffic going to
the victim. When we simulate flood w/o sig, we assume that attack
and legitimate traffic are so similar that no header level signature is
possible. Installing a filter on some SENSS ISP in the simulation
of flood w/o sig removes both legitimate and attack traffic going to
the victim. We measure the amount of legitimate and attack traffic
dropped and the bandwidth consumed by the attack on inter-AS
links. We perform 1,000 random trials for each data point and show
the median (lines) and 25th and 75th percentile (errorbars).
Emulation methodology. For our evaluation of response speed,
scalability and overhead we have developed a SENSS prototype,
including client and server functionalities, and the client customiza-
tion programs described in this paper. We deployed our prototype
on the DeterLab testbed [2] and measured the time it takes to serve
a SENSS request under many concurrent requests. We replicated
the Cogent topology (186 nodes) from the Topology Zoo[18]. On
each node we ran Quagga as router software and Open vSwitch as
the SDN software. We used RYU as the SDN controller. There was
one SENSS server in the topology. For control plane requests, it
connected to the Quagga software on switches via telnet, and for
data plane requests it sent OpenFlow messages. We emulated large,
100 ms, end to end propagation delays between the SENSS server
and each victim.
On the Cogent topology we use gravity model [30] to emulate
legitimate and attack traffic. We generate legitimate traffic using
iPerf (TCP mode) and attack traffic using a custom tool to generate
UDP flood. We generate sufficient legitimate traffic to fill a 1 Gbit
link from our victim to the ISP and then launch the attack.
2016 attack on Dyn
4.2
We reproduce the attack on Dyn in 2016 by reproducing locations
of Mirai bots, using bot IP addresses from [24]. We divide 1.2 Tbps
equally among bots, then allocate each bot to its AS, based on the
bot’s IP address. We use 7015 and 13977 as victim ASes for Dyn.
We then strategically deploy SENSS on only four ASes, which are
close to Dyn and on path between most Mirai bots and Dyn. These
are AS 174 (Cogent), 3356 (Level 3), 6461 (Zayo Bandwidth) and
7922 (Comcast). With that deployment, and if attack signature were
possible, SENSS would filter 100% of the attack traffic with only
four filtering rules (one per ISP). Cogent filters 56% of the attack,
and Zayo filters 40%, so even two SENSS ISPs would filter almost
all the attack.
 0 20 40 60 80 100 0.01 0.1 1 10% attack fltered% transit ASes deploying SENSSuni-dir-singlereal-dir-singleuni-dir-multireal-dir-multiuni-remotereal-remote 0 20 40 60 80 100 0.01 0.1 1 10% attack fltered% transit ASes deploying SENSSuni-dir-singlereal-dir-singleuni-dir-multireal-dir-multiuni-remotereal-remote 0 20 40 60 80 100 0.01 0.1 1 10% attack fltered% transit ASes deploying SENSSuni-allreal-all 0 20 40 60 80 100 0.01 0.1 1 10% attack fltered% transit ASes deploying SENSSdir-singledir-multiremote 0 20 40 60 80 100 0.01 0.1 1 10% attack fltered% transit ASes deploying SENSSdir-singledir-multiremote 0 20 40 60 80 100 0.01 0.1 1 10% attack fltered% transit ASes deploying SENSSallACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Sivaramakrishnan, Jelena Mirkovic, Minlan Yu, and Ying Zhang
We also consider the case when attack signature is not possible.
We simulate legitimate traffic to Dyn by assuming that it flows
mostly from large US connectivity providers. We extract the top
10 providers from a 2017 survey [3], and simulate legitimate traffic
proportionally to each provider’s number of customers. Using α=5%,
SENSS filters 99% of traffic to AS 13977, and 90% of traffic to AS
7015. This requires around a 1,000 filtering rules, with 60% being at
Cogent and 40% being at Level 3, one rule per POP.
4.3 Effectiveness in Sparse Deployment
We now investigate how deployment strategy and the number of
deployment points influence effectiveness. We investigate two de-
ployment strategies. In top strategy, we deploy SENSS at the top
N = (1...10, 000) ASes, ordered in decreasing order by their cus-
tomer cone size. In random strategy, we deploy SENSS at the ran-
dom N = (1...10, 000) ASes. In both cases, we only consider deploy-
ment at ASes that have at least one customer link, i.e. transit ASes.
There are 13,123 such ASes in our topology – 23% of all ASes.
Uniform traffic: Since we cannot anticipate where the attack-
ers, legitimate clients and the victim may reside, we deploy them
at random. We first randomly select a victim, and then randomly
select 1,000 ASes to host attackers and the additional 1,000 ASes to
host legitimate clients. We distribute attack/legitimate traffic equally
among attackers/legitimate clients.
Realistic traffic: We randomly select a victim but distribute at-
tackers at Mirai bot locations, and legitimate clients at large US
residential ISPs, as we have done in Section 4.2. We show results
only for the top deployment, because the random deployment results
do not change with traffic distribution.
(a) Flood w sig – top
(b) Flood w sig – random
Figure 6: Comparison of SENSS versus several cloud-based
DDoS defenses, with regard to bandwidth consumed by attack.
We show the median percentage of attack traffic filtered, for flood
w sig and reflector attacks (Fig 5(a) and 5(d)), flood w/o sig (Fig
5(b) and 5(e)), and for cross-fire (Fig 5(c) and 5(f)). For flood w/o
sig we use α = 5%. Other values of α lower SENSS’s effectiveness
for small number of deployment points (up to 1,000 ASes) by up
to 50%, and we omit them for space reasons. They have no effect
for deployments higher than 1,000. For flood w and w/o sig and for
reflector attacks we show separately the benefits to direct customers
of the SENSS-deploying ISP, and to remote victims that may request
SENSS services when under attack. Cross-fire creates disturbance
far from the attack’s victim, and we show benefit to all ASes.
Flood w sig and reflector attacks. In case of these attacks, our
results are consistent for both uniform and realistic traffic patterns.
Direct, single-homed customers of SENSS ISPs receive almost total
protection at all times, both in top and in random deployments, and
under both uniform and realistic traffic.
Direct, multi-homed customers receive lower protection than
single-homed, because some of their traffic traverses non-SENSS
ISPs. During an attack, a multi-homed victim could temporarily
become single-homed, to increase its protection. It could do so by
selectively announcing its prefixes only to SENSS ISPs.
Remote ASes that request SENSS services (aka “remote cus-
tomers”) receive protection only after a certain number of deploy-
ment points is reached. This is where top deployment is vastly supe-
rior to random. Deployment at only 0.7% top ASes achieves 90%
protection for remote customers. On the other hand, 64% of ran-
domly chosen ASes must deploy SENSS to achieve 90% protection
for remote customers.
Flood w/o signature. In this simulation we assume that SENSS
deploys coarse-grained rules, filtering all traffic flowing to the at-
tack’s victim at select filter locations. For uniform traffic pattern,
SENSS needs large deployment for effective attack mitigation. This
is because SENSS must filter close to attack sources to meet the
requirement for collateral damage (controlled by α = 5%). At small
deployment, SENSS either misses some attack, or its filters would
cause too high collateral damage. Deployment at 1.5% top ASes
is needed to achieve more than 90% protection for direct, single-
homed customers and deployment at 3.8% top ASes is needed for
90% protection for direct, multi-homed and remote customers. Ran-
dom deployment does much worse against flood w/o sig, where 70%
deployment is needed for 90% protection for everyone.
For realistic traffic patterns, SENSS is very effective for direct,
single-homed customers, even with 1–10 deployment points (0.01–
0.1 on x-axis). This is similar to our result for the 2016 Dyn attack.
Cross-fire attacks. Results are similar for both traffic patterns.
Top deployment again vastly outperforms random deployment. De-
ployment at the top 1% of ASes can mitigate 90% of cross-fire
attacks, while 66% of randomly selected ASes must deploy SENSS
to achieve the same effectiveness.
SENSS Against Volumetric DDoS Attacks
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Cloud
ASes Providers Peers Avg. AS-path length
CloudFlare
Google
Akamai
Incapsula