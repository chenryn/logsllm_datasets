sequently our idealized design is that the only channel that will
accept authorization requests should be via dedicated chip pins that
are otherwise disconnected and require disassembly of the device
to access (e.g., direct access to the circuit board, if not its removal
from the device casing). Again, such a requirement may impose
significant reengineering costs and so a reasonable approximation
for fielded devices is to leverage the JTAG pins already implemented
by existing SoC implementations.21
5.2 Time-vaulting
Recall that the time-vaulting requirement is that any party seeking
to request access to the escrowed passcode will need to demonstrate
continuous physical possession over the lockup period (e.g., 72
hours).22 There are two aspects to implementing this requirement:
• Securely measuring the passage of time on the escrow agent
• Validating evidence of physical possession
The first of these is, by far, the most important since the benefits
of time-vaulting are weakened by the degree to which an adversary
can artificially manipulate the escrow agent’s perception of time.
Moreover, while simple on its surface, secure time measurement is
a tricky issue. Since the adversary may control the external envi-
ronment one cannot count on wireless timing signals such as via
GPS or cellular protocols to establish ground truth. Instead, one can
rely on the stability of an internal hardware time source (e.g., typi-
cally based on a combination of a local oscillator driving a periodic
signal and counters). Alternatively, one could implement a base
timer in terms of a tuned number of iterations through a complex
hardware function.23 Assuming some such form of hardware timer
is implemented directly on the escrow agent (with its memory and
I/O separate from the rest of the device) this is likely to be effective
against any purely software-based attack.24
However, a technically skilled attacker might choose to attack
the hardware and manipulate the “count” of any timer, either via
techniques such as electrical glitching or directly introducing faults
to key memory cells (e.g., via Focused Ion Beam probes). Such
vulnerabilities have been widely explored in the literature and can
be substantially mitigated by building logic circuits that embed
error correcting codes (i.e., that random glitches will be detected as
21JTAG is typically not exported to external interfaces and yet is flexible enough to
support the needs of our authorization protocol.
22Note that the 72-hour period, while arbitrary, was not selected at random. While
there are a range of normal opportunities for one to become temporarily separated
from a personal device, we hypothesize that most of those (e.g., a weekend trip) will
be shorter than three days. We would not recommend a time shorter than 72 hours for
this reason.
23This is how Apple implements its base 80ms passcode validation requirement using
the AES engine on the SEP [16].
24Memory disturbance attacks, such as RowHammer [56], are also unlikely to have
purchase given an isolated memory and memory interface.
faults and even specific changes will only be effective if multiple
particular bits can be changed together [44, 49]).
An even more sophisticated (and heavily resourced) attacker
might instead choose to attack the underlying time source itself
by injecting a faster clock signal (overclock) coupled with aggres-
sive heat transport (e.g., liquid nitrogen cooling) to convince the
processor that time is running faster while still maintaining the
processor’s integrity. For example, most common smartphones (in-
cluding those manufactured by Apple and Samsung) use a 24Mhz
crystal as a base frequency source (subsequently multiplied to drive
a PLL that defines the SoC’s clock rate). Replacing this crystal with
a faster one (or manipulating the multiplier) would in turn lead
to a faster clock rate and hence an accelerated model of real time.
That said, there are practical limits to how much time shifting can
be expected from such an attack as processors will increasingly
fail as they exceed their operating frequency range.25 Moreover, a
careful implementation might attempt to block overclocking (e.g.,
by imposing a bandpass filter at frequency input) or to detect it
(e.g., monitoring current draw, thermal load or monitoring changes
in the delay characteristics of key circuits [41, 43]).
We note that this need for a secure time measurement function
is not unique to this design. Indeed, the secure timer in Apple’s
SEP is essential to their defense against brute force attack (and it
was the request to bypass this function that was a key aspect of
the Department of Justice request to Apple in the San Bernardino
case [6]).
Finally, in addition to imposing a lockup period, we also wish
to obtain evidence that the requesting party maintains physical
possession throughout. This property is of secondary importance,
but is meant to reduce risks of covert use (e.g., where the requestor
acquires access to the device temporarily, starts the authorization
request process, returns the device and then reacquires it after 72
hours). The simplest solution is one that requires a regular “heart-
beat” message from the requestor (e.g., every 100ms) or else the
escrow agent’s lockup period restarts. To foreclose covert attacks
in which additional componentry is surreptitiously added to the
device we require that, during the lockup period, the device cannot
be unlocked and displays an appropriate warning message (e.g.,
“Lawful Access Attempt in Progress”). We note that while more
complex protocols could be employed to increase the demands on
the requestor (e.g., a series of regular computational challenges
from the escrow agent to the requestor) it is unclear what addi-
tional security would be provided by such designs beyond simply
increasing the costs borne by law enforcement.26
5.3 Authorization
After the completion of the lockup period, an escrow agent then
requires the requestor to present evidence that it is authorized to
unlock the device. Moreover, we desire that this evidence have
particularity—that it only be useful for one device, and should
25Aggressive PC overclockers have demonstrated speedups of up to 2x in PC settings,
although it is unclear if one could expect similar effects on smart phone SoCs [11].
26In a similar context, some have proposed using cost itself as a limiting factor—placing
an abstract computational demand on the requestor so high that only a state actor could
bear it [64]. While intriguing, we do not feel confident about how to select workfactors
such that they are feasible for the range of lawful criminal digital evidence needs and
yet still out of the reach of organized criminal actors. This problem is exacerbated by
ongoing changes in computational capability over time.
someone manage to steal such evidence, that it would provide no
value for accessing any other devices (i.e., no “master keys”).
5.3.1 Device protocol. We present one approach to address these
requirements as follows: for each device d the manufacturer main-
tains a unique random device identifier did and an associated ran-
dom authorization key dauth. The collection of these tuples—one
per device—forms the authorization key database and is maintained
by the manufacturer.27 Thus, at the time of device manufacture,
did is burned into fuses on the device, along with a cryptographi-
cally strong one-way hash of the corresponding secret H (dauth ).28
With physical access, a device’s escrow agent can be queried and
it will provide—only after the conclusion of the lockup period—its
unique identifier, did. However, learning did is only the first step
for lawful access and the requestor must then be able to provide
the corresponding dauth to the escrow agent. If the requestor is
able to produce such a value, the agent can validate it by hashing
the request and comparing with the locally stored value H (dauth );
if the hashes match, the escrow agent can unlock the phone using
the escrowed passcode. Note that even if an adversary is able to
use extraordinary methods (e.g., SEM, FIBs) to extract the value
H (dauth ) from the escrow agent, this still will not let them produce
the challenge value dauth, due to the one-way nature of H.
Passcode encryption. Thus far, this scheme assumes that the device
is able to maintain secure isolated storage (for the self-escrowed
passcode) and that the escrow agent logic used to validate the autho-
rization key is secure as well. However, this is an assumption that
might be reasonably contested. Indeed, the unknown nature of the
iPhone vulnerabilities exploited by Cellebrite and Greyshift have
led some in the security community to argue that such a secure
processor environment “does not currently exist” [37]. To address
this concern, we can reduce this risk by separately encrypting the
self-escrowed passcode so that compromising the secure environ-
ment after a passcode has been set provides no purchase on the
plain text passcode (obviously, if the device can be compromised
covertly before the passcode is set then there can be few meaningful
defenses).
One approach to achieve this goal, similar to that in Ozzie’s
CLEAR proposal, is for the manufacturer to generate, for each de-
−1), storing the per-device
vice, a public/private key pair (dseal ,dseal
−1, in the authorization key database (indexed
private key, dseal
by did) and the corresponding public key, dseal , burned into its
device’s fuses (along with did and H (dauth ) as described earlier).
Upon setting a new passcode p, the device encrypts it with dseal
and self-escrows the resulting value (dseal (p)). Thus, the stored
passcode data is only useful to a party with both a means to read
the value dseal (p) from protected storage and knowledge of the
−1 needed to decrypt it. An authorized
associated private key dseal
party, will be able (after the mandated lockout period), to present
the device with an authorization request message containing both
27In our design each did is a unique random value. An alternative approach would be
to encrypt each did using a block cipher keyed with a master secret. This approach
simplifies key generation, but theft of the master secret would allow arbitrary gen-
eration of did values for any device whose identifier could be obtained, which we
deemed an unnecessary risk.
28To guard against any future weaknesses discovered in H , it would be prudent to
further salt the input with did , this ensuring that any attack on H must scale with
the number of devices to be attacked.
the candidate authorization key (dauth) and the associated private
−1). If the authorization key is validated, the private key
key (dseal
can then then used to decrypt the escrowed passcode and unlock
the device. One drawback of this approach however is that the use
of asymmetric cryptography introduces additional implementation
complexities including a need for secure random number gener-
ation, a more complex hardware implementation (or a software
implementation and its attendant risks) and an unclear level of
protection in a future post-quantum world.
An alternative design would be to use symmetric keys, but within
a forward secure framework to protect against key recovery. As
a strawman design, we mandate that the manufacturer generate
an additional random initial key, dseed, for each device. This value
is stored in both the authorization key database (again indexed
by did) and used to initialize a key, dk, on the corresponding de-
vice in non-volatile storage managed by the escrow agent (i.e., the
initial value of dk = dseed). In addition, the escrow agent also main-
tains a non-volatile counter, c, to represent the number of times
the passcode had been set (initialized to 0). Each time a new pass-
code p is configured on the device, it is encrypted with the current
value of dk before self-escrow (i.e., the escrow agent stores dk (p)
in non-volatile memory), then dk is overwritten with H (dk ) and
c is incremented. Thus, the key necessary to decrypt the current
passcode is not stored on the device and the current key stored
on the device offers little value due the one-way nature of H. By
contrast, an authorized party can, after the lockout period and after
dauth is validated, present the device with the original dseed value
from the authorization key database. By applying H to dseed c − 1
times, the escrow agent can reconstruct the needed key, extract p
and unlock the device. This approach has the advantage that it can
be implemented entirely using conventional block ciphers and hash
functions that are built into existing secure processor hardware.29
To summarize, while adding some modest complexity, these
extensions (or variants thereof) significantly minimize the useful
attack surface on the device; even if a vulnerability is found allowing
an outside party to probe the protected memory in the escrow agent
or convince it to misbehave during its checking of the authorization
key, these provide no advantage for recovering the passcode or
unlocking the device absent additional secret information from the
manufacturer.
Manufacturer protocol. Under this scheme, upon receiving a valid
court order for a device with identifier did, the manufacturer pro-
vides the corresponding value dauth (and any associated secrets
−1 or dseed as discussed above).
protecting self-escrowed state, dseal
We chose the manufacturer to manage the authorization key data-
base for multiple reasons. First, as private enterprises, device man-
ufacturers have the potential to act independently of the state and
have demonstrated, at least in some situations, a willingness to
contest government actions they deemed problematic to their cus-
tomers [4, 36]. Second, we must already trust the manufacturer,
not only for the security of their design and implementation, but
also for the security of the post-sale software updates they provide.
For example, should Apple choose—either for its own reasons or
29For those seeking a construction with crisper formal security guarantees, Bellare
and Yee describe a more elaborate version using AES256 to drive a pseudo-random bit
generator [25].
via government compulsion—it could create an iPhone update that
would provide remote access to all stored data.
Some have argued that involving the manufacturer in the lawful
access process will itself create new and undue risk for insider threat.
The underlying contention is that, since lawful access requests will
be more common than software updates, a proportionately greater
number of the manufacturer’s employees would necessarily be ex-
posed to secret keys and that this would create undue opportunities
for abuse [9, 26, 54]. We believe this argument is predicated on a
highly simplistic insider threat model and what is likely a flawed
comparison of the comparative risks of rogue software updates and
the abuse of lawful access authorization keys.30 Moreover, we ob-
serve that technology companies’ legal process employees routinely
handle far more sensitive data under warrants (e.g., the contents of
our Gmail accounts, iCloud photos, Facebook posts, Twitter DMs,
etc. provided under ECPA) and we are unaware of significant in-
sider abuses in spite of this capability. However, putting aside these
issues, the underlying abuse concern is thankfully one that can be
substantially addressed through technical means.
The standard mechanism for storing cryptographic secrets in
an enterprise environment is to use a Hardware Security Module
(HSM), a strongly tamper-resistant device which effectively pro-
vides controlled, audited secret storage, frequently also combined
with physical security. Indeed, Apple uses HSMs for securing iCloud
escrowed keychain data [16]. HSMs are easily configured to require
multiple employees to contemporaneously provide passwords and
physical authentication credentials (e.g., via smartcards) before they
will perform certain sensitive operations. Moreover, since the HSM
is appropriately provisioned as an offline device (i.e., with no con-
nectivity), those with physical access should be the principal vector
for attack.31 Thus, by storing the authorization key database in an
HSM, any potential insider on the manufacturer’s team handling
legal process requests would face risks from the audit logs of such
a device and might also need to recruit (or at least deceive) one or
more co-conspirators as well. As another reasonable control the
HSM could limit the number of requests that can be accepted per