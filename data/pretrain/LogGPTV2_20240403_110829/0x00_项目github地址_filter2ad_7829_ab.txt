                        ThisWebInfo.print()
                        print("\033[32m使用tide指纹库识别的结果:\033[0m")
                        GetCmsFromTide.Get_rule_from_tide(title, headers, bodys)
                    if Dbs == "cms":
                        ThisWebInfo.print()
                        print("\033[32m使用cms指纹库识别的结果:\033[0m")
                        GetCmsFromCms.Get_rule_from_cms(url)
                    if Dbs == "all":
                        ThisWebInfo.print()
                        print("\033[32m使用tide指纹库识别的结果:\033[0m")
                        GetCmsFromTide.Get_rule_from_tide(title, headers, bodys)
                        print("\033[32m使用cms指纹库识别的结果:\033[0m")
                        GetCmsFromCms.Get_rule_from_cms(url)
                except Exception as error:
                    pass
                # 识别网站语言
            except Exception as error:
                print("-"*50)
                print("连接不到该网站:" + url)
            queue.task_done()
        # print(r.headers)  # 获得响应头信息
​
在这个文件中，我们对应用系统特定字段信息，页面关键字、特殊链接或者文件和路径、框架、插件、服务器版本、编写语言类型等这些特征信息进行收集，共用到了requests，user_agent，BeautifulSoup，lxml，urllib，urlparse，time，re，sqlite3共九个库，它们的作用如下：
包名 | 功能  
---|---  
user_agent | 实现请求头中的user_agent的随机，保证爬虫能够正常爬取到数据  
BeautifulSoup | 实现便捷地通过解析文档提供需要抓取的数据  
lxml | 实现HTML和XML的解析，支持XPath解析方式，而且解析效率非常高  
urllib | 操作网页 URL，并对网页的内容进行抓取处理。  
urlparse | 对url进行解析，获取到url中我们想要提取的部分  
requests | 实现网络爬虫的请求与接受数据包，并且获取相响应包中的内容  
re | 通过正则表达式提取目标数据  
sqlite3 | 导入数据库文件  
time | 确定扫描所需时间，提高用户可阅读性  
​ 同时我们建立了一个WebInfo对象，用来存储搜集到的网站信息：
``
    class WebInfo:
        def __init__(self, domain, title, http_server, language, set_Cookie, X_Powered_By, cms, body, header):
            self.header = header
            self.body = body
            self.set_Cookie = set_Cookie
            self.X_Powered_By = X_Powered_By
            self.language = language
            self.http_server = http_server
            self.domain = domain
            self.title = title
            self.cms = cms
        def print(self):
            print("\033[32m""domain:" + self.domain + "\033[0m")
            print("\033[33m""title:" + self.title + "\033[0m")
            print("\033[34m""http_server:" + self.http_server + "\033[0m")
            print("\033[35m""language:" + self.language + "\033[0m")
            print("\033[36m""X-Powered-By:" + self.X_Powered_By + "\033[0m")
            # print(self.__dict__) 原本用作遍历输出所有属性
​ 对网站使用语言，框架信息，服务器信息的识别主要通过与预先建立好的信息进行比对而得出结果。
**GetCmsFromTide.py**
``
    import re
    import sqlite3
    import time
    cms1 = "未识别出cms"
    def Match_rule_for_tide(key, title, header, body):
        re_header = re.compile(r'header="(.*)"')
        re_body = re.compile(r'body="(.*)"')
        re_title = re.compile(r'title="(.*)"')
        global cms1
        if "title=" in key:
            if re.findall(re_title, key)[0].lower() in title.lower():
                cms1 = re.findall(re_title, key)[0]
        if "header=" in key:
            if re.findall(re_header, key)[0].lower() in header.lower():
                cms1 = re.findall(re_header, key)[0]
        if "body=" in key:
            if re.findall(re_body, key)[0].lower() in body.lower():
                cms1 = re.findall(re_body, key)[0]
        if cms1 !="未识别出cms":
            return cms1
    def Get_rule_from_tide(title, header, body):
        start_time = time.time()
        conn = sqlite3.connect('cms_finger.db')
        cursor = conn.cursor()
        cursor.execute("SELECT keys  FROM `tide` ")
        global cms1
        for i in range(1, 1001):
            result = cursor.fetchone()
            if cms1 == "未识别出cms":
                Match_rule_for_tide(result[0], title, header, body)
            if cms1 != "未识别出cms":
                str1 = "cms识别结果(指纹库:tide):"+Match_rule_for_tide(result[0], title, header, body)
                print("\033[33m"+str1+"\033[0m")
                cms1 = "未识别出cms"
                break
        print("\033[32m""运行了"+str(time.time() - start_time)+"秒""\033[0m")
​ 在这个文件中，我们通过python正则库，将目标网站的特定信息与指纹库进行对比碰撞，如果碰撞成功，则认为CMS识别任务完成，识别流程如下：
​ **GetCmsFromCms.py**
​ ``
    #!/usr/bin/env python3
    # -*- coding: utf-8 -*-    # author: jeremy
    # github: https://github.com/cyber-word
    # 公众号： 剑南道极客
    import re
    import sqlite3
    import time
    import hashlib
    import requests
    import user_agent
    cms2 = "未识别出cms"
    def GetMd5(content):
        md5 = hashlib.md5()
        md5.update(content)
        return md5.hexdigest()
    def Match_rule_for_cms(url, cms_name, path, match_pattern, options):
        global cms2
        headers = {
            'User-Agent': user_agent.generate_user_agent()
        }
        # print(url+path)
        res = requests.get(url=url + path, headers=headers, timeout=5)
        res.encoding = "utf-8"
        contents = res.content
        body = res.text
        if res.status_code == 200:
            if options == "md5":
                # print("我进入了md5的检验")
                if match_pattern == GetMd5(contents):
                    cms2 = cms_name
                    # print("md5" + cms2)
                    # print(res.status_code)
                    print(url+path)
                    if cms2 != "未识别出cms":
                        return cms2
                    # print(body)
                    # print(contents)
            # if match_pattern == getMD5(contents):
            #     cms2 = cms_name
            if options == "keyword":
                if match_pattern in body:
                    print("响应码:"+str(res.status_code))
                    cms2 = cms_name
                    # print("keyword" + cms2)
                    print(url+path)
                    if cms2 != "未识别出cms":
                        return cms2
                    # print(booy)
                    # print(contents)
            # if match_pattern.lower() in body.lower():
            #     cms1 = cms_name
        if cms2 != "未识别出cms":
            return cms2
    def Get_rule_from_cms(url):
        # body : r.text
        # contents : r.content
        start_time = time.time()
        conn = sqlite3.connect('cms_finger.db')
        cursor = conn.cursor()
        cursor.execute("SELECT cms_name,path,match_pattern,options FROM `cms` ")
        global cms2
        for i in range(1, 1001):
            result = cursor.fetchone()
            # result =[cms_name, path, match_pattern, options]
            if cms2 == "未识别出cms":
                Match_rule_for_cms(url, result[0], result[1], result[2], result[3])
            if cms2 != "未识别出cms":
                str1 = "cms识别结果(指纹库:cms):" + cms2
                print("\033[33m" + str1 + "\033[0m")
                cms2 = "未识别出cms"
                dir = 'fuckurl.txt'
                fp = open(dir, 'w')
                fp.write(url+" "+str1)
                fp.close()
                break
        print("\033[32m""cms识别(指纹库:cms)运行了" + str(time.time() - start_time) + "秒""\033[0m")
​
在这个文件中，我们主要采用了基于特殊文件的关键词搜索以及MD5比对的方法来识别框架，其原理是基于许多框架或者建站程序固有的文件本身不易被修改，以及MD5算法的不可逆性，因此可以通过这些未修改文件的签名属性以及文本属性来实现框架的识别。该方法识别流程图如下：
​
### 三、 运行结果
##### 1.对单个url进行识别
​ 命令：`python webscan.py -u 指定的url`
​ 实验：
​ 实验结果：
属性 | 结果  
---|---  
x-powered-by | PHP/5.2.17，ASP.NET  
language | PHP  
http_server | Microsoft-IIS/7.5  
domain | qlwhdm.com  
title | 齐鲁文化动漫工程  
set-Cookie | 当前页面未设置Cookie  
​ 某网站扫描器的扫描结果：
​ 可以看出扫描的结果较为准确，且相较于该网站扫描器，实现了cms的识别。
##### 2.对多个url进行识别：
​ 命令：`python webscan.py -f 存放多个url的文本文件的路径`
​ 实验结果：
    结果从数据整体性上看仍较为准确。
    这样一来，我们自己的web指纹扫描器就实现了，不过毕竟是新手所作，还存在着很多问题，希望大佬们多多指教，在下一步也会尝试对更多的开源web指纹库进行分析，提高cms框架识别的准确率，并且尝试加入漏洞检测等功能。