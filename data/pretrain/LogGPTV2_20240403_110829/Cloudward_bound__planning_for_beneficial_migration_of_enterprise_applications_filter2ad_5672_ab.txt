´m
i=1, such that:
(MP) max
subject to
Beneﬁts(M ) − InternetCosts(M )
Policy Constraints P
Constraints on DelayIncrease(M )
Flow Balance Equations
Here, Beneﬁts(M ) are the beneﬁts of migration to the enterprise
(for instance, due to lowered operational and equipment costs),
InternetCosts(M ) is the increased communication costs since traf-
ﬁc between the data center and the cloud is now sent over the In-
ternet, and DelayIncrease(M ) is the increase in transaction de-
lay. Since DelayIncrease(M ) is a random variable, we impose
the constraints on its statistical summary measures such as mean,
variance, or percentiles. This will be discussed in more detail in
§3.4. The ﬂow balance equations guarantee that all the transactions
are handled and that requests are not lost midway. We now present
more details on how each of these terms may be modeled.
3.2 Flow balance equations
We represent the graph structure after migration as G0 = (V 0, E0).
Each node in V that corresponds to a component, say Ci, is split
into two nodes, CiL and CiR, corresponding respectively to the
servers running this application component at the local data center
Figure 2: An example hybrid cloud deployment. The ﬁgure also illustrates
the need to reconﬁgure security policies.
nal to the enterprise, as well as extensive wide-area communica-
tion. Replicating servers both locally and remotely could allow for
the two classes of users (internal and external) to be served from
different locations. From a data privacy perspective, enterprises
may wish to store sensitive databases (e.g., a database that stores
credit card information) locally. This may in turn make it desir-
able to place other components that extensively interact with such
databases local, from the perspective of reducing wide-area com-
munication costs and application response times. Finally, while we
do not explore in this paper (but brieﬂy discuss in § 7), hybrid ar-
chitectures may enable enterprises to better handle peak workloads.
In particular, servers may be instantiated in the cloud when needed,
while requests are in general served from the local data-center.
In this paper, we address two key challenges associated with re-
alizing hybrid cloud architectures:
Planning which servers to migrate: Planning a hybrid cloud lay-
out is a complex problem, where an application architect must take
several factors into account. The key factors are (i) honoring pol-
icy constraints regarding which components must be migrated; (ii)
ensuring application response times continue to meet desired tar-
gets; and (iii) ensuring the cost savings from migration are as high
as possible. The cost savings in turn depend both on compute and
storage components migrated, as well as the wide-area communi-
cation costs involved. The transaction delays as well as wide-area
communication costs in turn depend on (i) the location of users, i.e.
whether they are local to the enterprise, or external to it; and (ii) the
nature of interaction between components, i.e., which components
interact, and how much trafﬁc they exchange.
Ensuring correctness of security policies on migration: On mi-
grating application servers to the cloud, operators need to reconﬁg-
ure ACLs to ensure that the security policies are still met. Consider
the migration scenario in Fig. 2 with a security policy which only
permits front-end servers to reach back-end servers. Ensuring that
this policy continues to be upheld on migration requires operators
to change both the location of ACLs, as well as rules in the ACLs
themselves. In doing so, the primary consideration is to correctly
achieve security policy goals. A second consideration is to ﬁlter
unauthorized packets as early as possible. For instance, if trafﬁc
is not permitted from certain enterprise users to a server located in
the cloud, it is desirable to ensure that the unauthorized trafﬁc is
ﬁltered at the enterprise edge itself rather than ﬁlter it after it has
traversed the wide-area link to the cloud. Finally, the problem is
further complicated due to reassignment of IP addresses after mi-
gration as is the practice of certain cloud providers today.
3 Planning a migration strategy
In this section, we present a model that enables application archi-
tects to systematically plan which components of their application
R2R1ACL1ACL2R4ACL4R3ACL3245Figure 3: Partitioning requests after migration.
0
iR,jL + T
0
iL,jL + T
0
iR,jR
0
0
iL,jL + T
iR,jL
0
iR,jR
`1 − fi
´ = T
´ = T
`fi
`1 − fj
´ = T
`fj
´ = T
and at the cloud. If nodes i and j communicate in G, each replica
of i is connected to each replica of j in G0. The resulting trans-
action matrix, denoted as T0, must satisfy ﬂow balance equations
mentioned in §3.1. The increase in Internet communication costs
and transaction delay depend on T0. For an illustration, see Fig. 3.
Depending on the policies implemented at the component servers,
there are two ways to model the ﬂow balance equations:
• Flexible routing approach: In this approach, the component
server CiL is allowed to distribute trafﬁc differently than CiR to
its successor nodes. For instance, CiL and CiR may direct more
trafﬁc towards CjL and CjR respectively, so that the trafﬁc on the
Internet and the resulting costs and delays are reduced. Assume for
any node i, fi = ni
(fi denotes the fraction of servers to migrate).
Ni
The following ﬂow balances must be satisﬁed by the elements of T0
when partitioning the original trafﬁc Ti,j between various replicas
of component nodes i and j.
0
iL,jR
(1)
Ti,j
(2)
Ti,j
(3)
Ti,j
(4)
Ti,j
0
(5)
T
iL,jL, T
Constraints (1) and (2) model respectively that transaction requests
originating at CiL and CiR are transferred to some servers imple-
menting Cj. Constraints (3) and (4) model that the number of re-
quests received at the local and remote implementations of compo-
nent Cj are proportional to the number of servers at each location.
Constraints involving user nodes I and O may be easily derived in
similar fashion, and we omit details. If extra servers are allowed to
be deployed, then we introduce variables niL and niR instead of
ni and replace the constraint Nifi = ni with (1 − fi)Ni ≤ niL
and fiNi ≤ niR.
• Independent routing approach: The ﬂexible routing approach
requires making decisions based on the location of an application
component or user. Location-based routing does occur in prac-
tice - for e.g., users are typically routed to geographically close-by
front-ends in many applications. However, location-based routing
is harder to implement between application components in legacy
applications. To handle these application constraints, we also model
an approach where, the component server CiL distributes trafﬁc in
the same proportions as the CiR server.
iR,jR ≥ 0
0
0
iL,jR + T
0
iR,jL, T
0
iL,jR, T
Let f (i, A) = ni
Ni
if A = R and Ni−ni
Ni
easily shown that with an independent routing approach,
if A = L. Then, it is
T 0
iA,jB = Ti,j f (i, A)f (j, B)
(6)
It is apparent from the deﬁnition, that the constraint (6) is more
restrictive that constraints (1)-(5) and therefore admits fewer solu-
tions. As a result the optimal solution for (MP) with (6) instead of
(1)-(5) may be inferior.
3.3 Modeling Internet communication costs
The increase in Internet communication costs is easily modeled as:
CostL,I (Tr
L,I − TrL,I ) + CostR,I Tr
0
0
R,I
L,I (TrL,I) and Tr0
where CostL,I and CostR,I are respectively the per-unit Internet
communication cost of trafﬁc from the local and cloud data centers,
Tr0
R,I respectively denote the trafﬁc from the lo-
cal data center and the cloud to the Internet after (before) migration.
We believe a linear cost model for Internet transfers is a reasonable
starting point, and it matches the business model of multiple cloud
providers (e.g., Amazon, Azure).
Let C={Ci}m
L={CiL}m
i=1, L0=CL ∪ {I}
and R0=CR ∪ {O}. Let i0∈V 0 (j0∈V 0) be replicas of i∈V (j∈V ).
Clearly, if i6=j, S0
i0,j0=0. TrL,I consists of
trafﬁc from the external users to components and vice-versa and
can be expressed as:
i0,j0=Si,j, otherwise S0
R={CiR}m
i=1, C0
i=1, C0
`TO,iSO,i + Ti,OSi,O
´
X
i∈C
TrL,I =
Tr0
L,I includes the trafﬁc from the (i) external users to the lo-
cal data center and vice-versa, and (ii) trafﬁc between local nodes
(users or components) and remote components. Similarly, Tr0
R,I
includes the trafﬁc from the (i) external users to the cloud data cen-
ter and vice-versa, and (ii) trafﬁc between local nodes (users or
components) and remote components. In other words,
Tr0
L,I =
i,j S0
i,j + T 0
j,iS0
j,i
i,j S0
i,j + T 0
j,iS0
j,i
´ , Tr0
X
`T 0
R,I =
i∈L0∪{O},j∈C0
R
´ .
X
`T 0
i∈L0,j∈R0
3.4 Modeling increase in transaction delays
Our overall objective is to ensure the transaction delays after migra-
tion are not signiﬁcantly higher than the delays prior to migration.
We now discuss how constraints involving changes to mean delay,
variance and percentiles may be expressed:
• Mean delay of transactions: Let Ω be the random variable cor-
responding to a user’s request and the corresponding application.
For each i ∈ V ∪ E, let χi be a random variable denoting the
number of times a node/directed edge is encountered per transac-
tion, Di be the delay experienced per encounter. Recall that, if t is
the number of user requests per unit time and Ti,j is the number of
transactions on an edge e = (i, j) ∈ E, then Ti,j
t = E [χe]. We
assume that χi is independent of Di, i.e., the number of times i is
encountered in each transaction does not inﬂuence the delay expe-
rienced per encounter. Finally, let D be the delay experienced by a
user. Then, it is easily shown that:
X
i∈V
X
i∈V 0
E[D] =
E [χiDi] +
E [De]
X
„ Ti,j
t
e=(i,j)∈E
«
Similarly, after migration, for i ∈ V 0 ∪ E0, we deﬁne χ0
i as the
number of times i is encountered and D0
i as the delay per encounter
at i. Let D0 be the delay for each request after migration. As above,