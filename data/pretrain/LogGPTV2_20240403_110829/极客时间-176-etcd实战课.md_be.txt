# 24 \| 运维：如何构建高可靠的etcd集群运维体系？你好，我是唐聪。在使用 etcd过程中，我们经常会面临着一系列问题与选择，比如：1.  etcd    是使用虚拟机还是容器部署，各有什么优缺点？        2.  如何及时发现 etcd    集群隐患项（比如数据不一致）？        3.  如何及时监控及告警 etcd 的潜在隐患（比如 db    大小即将达到配额）？        4.  如何优雅的定时、甚至跨城备份 etcd    数据？    5.  如何模拟磁盘 IO 等异常来复现    Bug、故障？        今天，我就和你聊聊如何解决以上问题。我将通过从 etcd集群部署、集群组建、监控体系、巡检、备份及还原、高可用、混沌工程等维度，带你了解如何构建一个高可靠的etcd 集群运维体系。希望通过这节课，让你对 etcd集群运维过程中可能会遇到的一系列问题和解决方案有一定的了解，帮助你构建高可靠的etcd集群运维体系，助力业务更快、更稳地运行。整体解决方案那要如何构建高可靠的 etcd集群运维体系呢?我通过下面这个思维脑图给你总结了 etcd 运维体系建设核心要点，它由 etcd集群部署、成员管理、监控及告警体系、备份及还原、巡检、高可用及自愈、混沌工程等维度组成。![](Images/0a988cedf817882c6204aa61a08fe16f.png)savepage-src="https://static001.geekbang.org/resource/image/80/c2/803b20362b21d13396ee099f413968c2.png"}集群部署要想使用 etcd 集群，我们面对的第一个问题是如何选择合适的方案去部署etcd 集群。 首先是计算资源的选择，它本质上就是计算资源的交付演进史，分别如下：1.  物理机；        2.  虚拟机；        3.  裸容器（如 Docker    实例）；        4.  Kubernetes 容器编排。        物理机资源交付慢、成本高、扩缩容流程费时，一般情况下大部分业务团队不再考虑物理机，除非是超大规模的上万个节点的Kubernetes 集群，对CPU、内存、网络资源有着极高诉求。虚拟机是目前各个云厂商售卖的主流实例，无论是基于 KVM 还是 Xen实现，都具有良好的稳定性、隔离性，支持故障热迁移，可弹性伸缩，被etcd、数据库等存储业务大量使用。在基于物理机和虚拟机的部署方案中，我推荐你使用 ansible、puppet等自动运维工具，构建标准、自动化的 etcd 集群搭建、扩缩容流程。基于ansible 部署 etcd集群可以拆分成以下若干个任务:1.  下载及安装 etcd    二进制到指定目录；        2.  将 etcd 加入 systemd    等服务管理；        3.  为 etcd    增加配置文件，合理设置相关参数；        4.  为 etcd    集群各个节点生成相关证书，构建一个安全的集群；        5.  组建集群版（静态配置、动态配置，发现集群其他节点）；        6.  开启 etcd 服务，启动 etcd    集群。    详细你可以参考 digitalocean这篇博客文章，它介绍了如何使用 ansible去部署一个安全的 etcd 集群，并给出了对应的 yaml任务文件。 容器化部署则具有极速的交付效率、更灵活的资源控制、更低的虚拟化开销等一系列优点。自从Docker 诞生后，容器化部署就风靡全球。有的业务直接使用裸 Docker 容器来跑etcd 集群。然而裸 Docker容器不具备调度、故障自愈、弹性扩容等特性，存在较大局限性。随后为了解决以上问题，诞生了以 Kubernetes、Swarm为首的容器编排平台，Kubernetes 成为了容器编排之战中的王者，大量业务使用Kubernetes 来部署 etcd、ZooKeeper等有状态服务。在开源社区中，也诞生了若干个 etcd 的 Kubernetes容器化解决方案，分别如下：1.  etcd-operator；        2.  bitnami    etcd/statefulset；        3.  etcd-cluster-operator；        4.  openshit/cluster-etcd-operator；        5.  kubeadm。        etcd-operator目前已处于 Archived状态，无人维护，基本废弃。同时它是基于裸 Pod实现的，要做好各种备份。在部分异常情况下存在集群宕机、数据丢失风险，我仅建议你使用它的数据备份etcd-backup-operator。bitnami etcd提供了一个 helm 包一键部署 etcd集群，支持各个云厂商，支持使用 PV、PVC 持久化存储数据，底层基于StatefulSet实现，较稳定。目前不少开源项目使用的是它。你可以通过如下 helm 命令，快速在 Kubernete 集群中部署一个 etcd集群。     helm repo add bitnami https://charts.bitnami.com/bitnami    helm install my-release bitnami/etcdetcd-cluster-operator和openshit/cluster-etcd-operator比较小众，目前 star不多，但是有相应的开发者维护，你可参考下它们的实现思路，与 etcd-operator基于 Pod、bitnami etcd 基于 Statefulset 实现不一样的是，它们是基于ReplicaSet 和 Static Pod实现的。 最后要和你介绍的是kubeadm，它是 Kubernetes 集群中的 etcd高可用部署方案的提供者，kubeadm 是基于 Static Pod 部署 etcd集群的。Static Pod 相比普通 Pod 有其特殊性，它是直接由节点上的 kubelet进程来管理，无需通过kube-apiserver。创建 Static Pod 方式有两种，分别是配置文件和 HTTP。kubeadm使用的是配置文件，也就是在 kubelet 监听的静态 Pod 目录下（一般是/etc/kubernetes/manifests）放置相应的 etcd Pod YAML文件即可，如下图所示。![](Images/ac2cb7e68b32b94c1332d55bd1fe4fee.png)savepage-src="https://static001.geekbang.org/resource/image/d7/05/d7c28814d3f83ff4ef474df72b10b305.png"}注意在这种部署方式中，部署 etcd 的节点需要部署docker、kubelet、kubeadm组件，依赖较重。集群组建和你聊完 etcd集群部署的几种模式和基本原理后，我们接下来看看在实际部署过程中最棘手的部分，那就是集群组建。因为集群组建涉及到etcd成员管理的原理和节点发现机制。在特别放送slate-object="inline"里，超凡已通过一个诡异的故障案例给你介绍了成员管理的原理，并深入分析了etcd 集群添加节点、新建集群、从备份恢复等场景的核心工作流程。etcd目前通过一次只允许添加一个节点的方式，可安全的实现在线成员变更。你要特别注意，当变更集群成员节点时，节点的 initial-cluster-state参数的取值可以是 new 或existing。 1.  new，一般用于初始化启动一个新集群的场景。当设置成 new    时，它会根据 initial-cluster-token、initial-cluster    等参数信息计算集群 ID、成员 ID    信息。    2.  existing，表示 etcd 节点加入一个已存在的集群，它会根据 peerURLs    信息从 Peer 节点获取已存在的集群 ID    信息，更新自己本地配置、并将本身节点信息发布到集群中。        那么当你要组建一个三节点的 etcd集群的时候，有哪些方法呢?在 etcd 中，无论是 Leader选举还是日志同步，都涉及到与其他节点通信。因此组建集群的第一步得知道集群总成员数、各个成员节点的IP 地址等信息。这个过程就是发现（Discovery）。目前 etcd主要通过两种方式来获取以上信息，分别是 **staticconfiguration** 和 **dynamic servicediscovery**。**static configuration** 是指集群总成员节点数、成员节点的 IP地址都是已知、固定的，根据我们上面介绍的 initial-cluster-state原理，有如下两个方法可基于静态配置组建一个集群。1.  方法 1，三个节点的 initial-cluster-state 都配置为    new，静态启动，initial-cluster    参数包含三个节点信息即可，详情你可参考        [社区文档            slate-object="inline"    。        2.  方法 2，第一个节点 initial-cluster-state 设置为    new，独立成集群，随后第二和第三个节点都为    existing，通过扩容的方式，不断加入到第一个节点所组成的集群中。        如果成员节点信息是未知的，你可以通过 **dynamicservice discovery** 机制解决。etcd社区还提供了通过公共服务来发现成员节点信息，组建集群的方案。它的核心是集群内的各个成员节点向公共服务注册成员地址等信息，各个节点通过公共服务来发现彼此，你可以参考官方详细文档。监控及告警体系当我们把集群部署起来后，在业务开始使用之前，部署监控是必不可少的一个环节，它是我们保障业务稳定性，提前发现风险、隐患点的重要核心手段。那么要如何快速监控你的etcd 集群呢？正如我在14slate-object="inline"和15里和你介绍延时、内存时所提及的，etcd提供了丰富的 metrics 来展示整个集群的核心指标、健康度。metrics按模块可划分为磁盘、网络、MVCC 事务、gRPCRPC、etcdserver。磁盘相关的 metrics及含义如下图所示。![](Images/04928fef321b1442bc9307d0eeb48113.png)savepage-src="https://static001.geekbang.org/resource/image/7b/a5/7b3df60d26f5363e36100525a44472a5.png"}网络相关的 metrics及含义如下图所示。![](Images/fcb9c76ca502cb75f3572d0a2dfc8f21.png)savepage-src="https://static001.geekbang.org/resource/image/da/32/da489a9796a016dc2yy99e101d9ab832.png"}mvcc相关的较多，我在下图中列举了部分其含义，如下所示。![](Images/bb72b9c94597fdd52ec36231bae8ecbf.png)savepage-src="https://static001.geekbang.org/resource/image/d1/51/d17446f657b110afd874yyea87176051.png"}etcdserver 相关的如下，集群是否有 leader、堆积的 proposal数等都在此模块。![](Images/04def24ec860f73b5e243828e3b9642c.png)savepage-src="https://static001.geekbang.org/resource/image/cb/6e/cbb95c525a6748bfaee48e95ca622f6e.png"}更多metrics，你可以通过如下方法查看。    curl 127.0.0.1:2379/metrics了解常见的 metrics 后，我们只需要配置 Prometheus 服务，采集 etcd集群的 2379 端口的 metrics路径。 采集的方案一般有两种，静态配置slate-object="inline"和动态配置。静态配置是指添加待监控的 etcd target 到 Prometheus配置文件，如下所示。    global:      scrape_interval: 10s    scrape_configs:      - job_name: test-etcd        static_configs:        - targets:     ['10.240.0.32:2379','10.240.0.33:2379','10.240.0.34:2379'静态配置的缺点是每次新增集群、成员变更都需要人工修改配置，而动态配置就可解决这个痛点。动态配置是通过 Prometheus-Operator 的提供 ServiceMonitor机制实现的，当你想采集一个 etcd 实例时，若 etcd 服务部署在同一个Kubernetes 集群，你只需要通过 Kubernetes 的 API 创建一个如下的ServiceMonitor 资源即可。若 etcd 集群与 Promehteus-Operator不在同一个集群，你需要去创建、更新对应的集群Endpoint。 那 Prometheus 是如何知道该采集哪些服务的 metrics信息呢? 答案 ServiceMonitor 资源通过 Namespace、Labels 描述了待采集实例对应的Service Endpoint。    apiVersion: monitoring.coreos.com/v1    kind: ServiceMonitor    metadata:      name: prometheus-prometheus-oper-kube-etcd      namespace: monitoring    spec:      endpoints:      - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token        port: http-metrics        scheme: https        tlsConfig:          caFile: /etc/prometheus/secrets/etcd-certs/ca.crt          certFile: /etc/prometheus/secrets/etcd-certs/client.crt          insecureSkipVerify: true          keyFile: /etc/prometheus/secrets/etcd-certs/client.key      jobLabel: jobLabel      namespaceSelector:        matchNames:        - kube-system      selector:        matchLabels:          app: prometheus-operator-kube-etcd          release: prometheus采集了 metrics 监控数据后，下一步就是要基于 metrics监控数据告警了。你可以通过 Prometheus和Alertmanagerslate-object="inline"组件实现，那你应该为哪些核心指标告警呢？当然是影响集群可用性的最核心的 metric。比如是否有 Leader、Leader切换次数、WAL 和事务操作延时。etcd社区提供了一个丰富的告警规则slate-object="inline"，你可以参考下。最后，为了方便你查看 etcd集群运行状况和提升定位问题的效率，你可以基于采集的 metrics配置个 [grafana可视化面板  slate-object="inline"。下面我给你列出了集群是否有 Leader、总的 key 数、总的watcher 数、出流量、WAL持久化延时的可视化面板。![](Images/83417c0d3b0e48e8ded1a6db730c562b.png)savepage-src="https://static001.geekbang.org/resource/image/a3/9f/a3b42d1e81dd706897edf32ecbc65f9f.png"}![](Images/fb91a28932a275488cac4ec46f1edd55.png)savepage-src="https://static001.geekbang.org/resource/image/d3/7d/d3bc1f984ea8b2e301471ef2923d1b7d.png"}![](Images/bf2ea26b95cd5454b166052f4e1f2e13.png)savepage-src="https://static001.geekbang.org/resource/image/yy/9f/yy73b00dd4d48d473c1d900c96dd0a9f.png"}![](Images/063da99bffb3da79b51cc1f114a30dd6.png)savepage-src="https://static001.geekbang.org/resource/image/2d/25/2d28317yyc38957ae2125e460b83f825.png"}![](Images/01b0d44f906270d6c8c901d79664d1bc.png)savepage-src="https://static001.geekbang.org/resource/image/9c/b9/9c471d05b1452c4f0aa8yy24c79915b9.png"}备份及还原监控及告警就绪后，就可以提供给业务在生产环境使用了吗？当然不行，数据是业务的安全红线，所以你还需要做好最核心的数据备份工作。如何做呢？主要有以下方法，首先是通过 etcdctl snapshot命令行人工备份。在发起重要变更的时候，你可以通过如下命令进行备份，并查看快照状态。    ETCDCTL_API=3 etcdctl --endpoints $ENDPOINT     snapshot save snapshotdb    ETCDCTL_API=3 etcdctl --write-out=table snapshot status snapshotdb其次是通过定时任务进行定时备份，建议至少每隔 1个小时备份一次。然后是通过etcd-backup-operator进行自动化的备份，类似ServiceMonitor，你可以通过创建一个备份任务 CRD 实现。CRD如下：     apiVersion: "etcd.database.coreos.com/v1beta2"    kind: "EtcdBackup"    metadata:      name: example-etcd-cluster-periodic-backup    spec:      etcdEndpoints: [      storageType: S3      backupPolicy:        