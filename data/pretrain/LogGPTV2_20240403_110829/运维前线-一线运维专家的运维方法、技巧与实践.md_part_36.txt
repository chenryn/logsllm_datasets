cpu_data = psutil.cpu_times(percpu=TRUE)
Import psutil
，首先会想到的就是监控系统，监控系统的确是性能容量数据采集的
---
## Page 209
及资源类、系统软件运行指标等的数据。除了要获得每个节点的运行数据之外，还要获得每
载均衡或主备方式部署的服务器节点组成，服务器节点可通过传统专业的监控工具来采集涉
方式不会影响应用性能。
所示。
报文数据进行解码、清洗、合并等操作，获取以下数据信息。
理主要是在网络层面部署探针抓取应用报文，并将应用报文发送到集中的应用工具，通过对
常见的应用架构主要可以分为Web、队列、应用、缓存、数据库这5层，每一层均由负
我们利用监控工具解决了上面提到的容量性能与交易性能数据来源，采集方案如图8-3
APM工具往往可以提供实时数据或批量接口，数据来源更加稳定，且网络旁路抓包的
3.数据采集解决方案
口系统软件信息：数据库、中间件使用响应、并发、连接数情况等。
口网络通信信息：丢包、TCP重传、带宽、连接成功率等。
口交易报文类的信息：返回码、
第二种方式：借鉴基于网络旁路APM工具抓取应用性能数据。这类APM工具的工作原
但是需要记住一点，无论是数据库还是日志，都要通过异步方式来实现。
易笔数、响应时间、流水号、
交易关键信息3：
交易关键信息2：
张号等
交易关键信息1：预留信息，可以通过交易关键字直到交易，比如证件号、
交易返回信息：下游系统返回的处理状态
交易状态：交易是否成功、失败或超时等
交易类型：交易类型
终处理交易的系统
实际交易处理渠道：下游系统可能是网关等系统，实际交易处理渠道记录最
下游系统渠道：下游系统的渠道标识
上游系统渠道：上游系统的渠道标识
结束时间：下游系统返回处理结果的时间
开始时间：交易到应用系统的时间
下游系统流水号：下游系统流水号，配合下游系统排直问题所需要的关键字
上游系统流水号：上游系统流水号，配合上游系统排查问题所需要的关键字
流水号：唯一标识一笔交易流水的ID
图8-2数据运维流水表结构
、金融交易里的金额、账户等关键数据。
、交易码、操作码、成功率、渠道标识、交易响应率、交
第8章应用系统运行分析
193
---
## Page 210
指定的策略进行统计分析，并输出可供决策的报表数据。
略，由分析平台以定时批量的方式，对一个应用系统一段时期内的资源使用情况数据，按预
的数据分析模型简化分析方法，主要建立了以下几类数据模型：
8.1.2
工具获取站点与站点之间是否塞车情况的数据。
种组合方式，就如同我们的GPS 地图软件，传统监控工具获取每个坐标站点的情况，APM
之间的数据。
个节点之间的运行情况，在这里我们选用基于网络旁路抓取报文的APM工具来获取各个点
在应用运行分析的过程中，
194
通过传统的监控工具与APM工具，我们获取了点、线形成的二维平面的运行数据，这
口%idle：显示CPU处于空闲状态的时间百分比。
口%system：显示系统进程消耗CPU的时间百分比。
口%user：显示用户进程消耗CPU的时间百分比。
下面仍以CPU为例，CPU数据通常有以下3项需要关注。
对系统资源数据模型的分析，需要将日常分析系统资源的经验指标化，转化为分析策
我们在日常实时分析过程中，总结出以下经验。
1.系统资源数据模型
口交易性能数据模型。
口数据库数据模型。
口系统资源数据模型。
运维前线：一线运维专家的运维方法、技巧与实践
数据模型
Web联列应用级存数据库
不同应用系统的架构和业务逻辑均不一样，需要通过标准化
图8-3数据采集技术方案
集中监控工具
APM工具
APM工具，收集节点
收集每个节点的数据
专业的监控工具，
之间的数据
---
## Page 211
locking状态、SQL语句的信息等。：直
采集并分析数据库的使用情况，例如数据库缓冲池（buffer pool）的使用状况、即时的数据库
实现的。下面以DB2为例，我们往往使用Event Monitor和Snapshot，两者都可以用于实时
的性能情况。
应策略的制定需要有一个使用调优的过程。
致，则提交到基础设施团队，由基础设施团队评估扩容事宜。
运行分行模块报告，先由应用运维确认是否存在应用缺陷所导致的因素，如非应用缺陷所导
根据运维人员的需要进行调整。
潜在性能瓶颈时，才会输出容量不足的建议。
所以出现一次并不会马上输出CPU资源容量不足的建议。只有当连续3天出现上述情况的
在潜在性能瓶颈，这个潜在性能瓶颈可能由一个正常的操作引起并会在30分钟后得到释放，
间隔。连续 20次采样出现CPU性能超阈值（%usr+%system>80%或%idle 90%,%idle 80%，%idle30%：较好。
录数量等信息
UOW开始/结束时间、CPU使用情况、locking及logging等信息
SQL语句开始/结束时间、CPU使用情况、动态 SQL语句文本、语句执行结果，以及fetch记
只提供参与到deadlock的应用名
表8-1数据库运行指标类型
提供的信息
第8章应用系统运行分析
195
---
## Page 212
能数据模型。
用次数，删除无用的索引；也可以对索引是否重复进行分析，比如索引1（id,name），索引2
析有极为重要的意义。同样，数据库也为分析数据库索引提供了丰富的方法：分析索引的引
是否需要对该10张数据表进行数据迁移，以减少存量数据。
语句查到一个数据库中各表的数据（该表的数据需要在重整后才能得到最新的统计信息)：
做数据迁移或清理，将会导致数据库性能瓶颈的出现。仍以BD2为例，可以通过以下SQL
些数据库索引来提高应用的系统性能。
行时间最长，资源消耗最大的数据：
建议，还可以得到一些应用层面的调优建议，比如对Statements项的分析可以得到高峰期执
196运维前线：一线运维专家的运维方法、技巧与实践
（id），这里的索引2即为重复多余的索引。
tabschema and a.tabname=b.tabname order by a.card desc
time,stats_time from
Tables
Tablespaces
Bufferpools
事件类型
（3）另外，数据库索引在实际调优过程中是最直接、最快速、最有效的方法，索引的分
（2）通过数据库的数据统计信息可以得到数据量大的表，任由数据库表数据量增大而不
衡量一个交易系统的性能，还需要从交易层面进行分析，以下将介绍几个常见的交易性
3.交易性能数据模型
通过以上SQL语句可以导出数据量排行前10位的数据表，提供给运维人员以重点分析
select
有了这类SQL语句信息，就可以通过DB2的建议工具生成SQL优化建议，通过新增一
口消耗时间 top20 的 SQL。
口执行次数top20的 SQL。
通过在高峰期对数据库锁、SQL语句等进行分析，
stats_time：信息统计时间。
alter_time：表修改时间。
create_time：表创建时间
Cardinality：数据基数。
rows_num：数据行数。
上述代码各字段具体说明如下。
口返回记录数top20的SQL。
各数据库表的读/写行数
各 table space的预读、page切换及直接I/O等信息
各buffer pool的预读、page切换及直接I/O等信息
提供的信息
不仅可以得到一些数据库参数配置的
（续）
---
## Page 213
率明显高于其他系统，则有可能是该交易设计本身有问题，或者该功能有缺陷，失败率高。
型的一个补充。
按渠道分析的模型，该模型可以看出哪些下游系统处理能力比较差，
易数量变大时，可能会导致并发处理线程不能及时释放而无法处理更多的交易。所以还需要
接数为100，如果下游某个系统交易缓慢，每笔交易都是30秒才返回，那么当该下游系统交
的，关联系统的性能下降也可能会导致应用系统的性能下降，比如：分析应用系统的并发连
否下降等情况，再进行深人分析是什么因素引起的，最终提出优化建议。
析，运维人员可以查看交易的分布，分析交易是否呈上升的趋势，系统处理交易的成功率是
失败，交易失败可能是正常的，比如余额不足导致的交易失败)。通过连续一个月的数据分
笔数、交易成功率、交易失败率、交易异常比率（交易异常主要是指交易超时，有别于交易
数的分析中定义如下4种模型：
4）按交易返回码分析的情况。
3）按交易码分析的情况。
交易码分析的情况则是从某个功能设计的角度来分析，比如：如果某几个交易码的失败
上面是对应用系统的整体处理能力进行分析，但由于现在的交易系统往往不是孤立存在
2）按渠道分析的情况。
对交易总笔数进行分析，可以得到系统每天或每天的高峰期指定时间段的处理的交易总
错误码：
交交
1）按笔数分析的情况。
交易笔数的分析，
交
交
交
交
交
渠
交
交
交
交
（1）交易笔数
易成功笔数：
易总笔数：
易异常笔数：
易失败笔数：
易成功笔数：
易总笔数：
易码：
易异常笔数：
易失败笔类
易成功
易总笔数：
易异常笔数：
易成功笔数：
易总笔数：
笔
数
，主要是通过在指定时间内对交易发生的笔数进行分析，建议在交易笔
第8章应用系统运行分析197
是系统整体处理笔数模
总
---
## Page 214
10分钟。
小，计划后续在工作日与节假日的基础上，再细化为星期线，基线值由原来的1小时细化到
3时与4时的数据波动较大。为此，一是要去除干扰的运行数据，二是将基线粒度进一步缩
很强；或者每天凌晨3时50.分至4时15分之间因为批量定时任务导致数据库使用性能突增
现了一些分析误差，比如每天晚上凌晨1时到6时之间，实际发生的交易数据很少，波动性
在这个时间周期内数据采样的平均值。在实际运行过程中，我们发现每个小时的基线点都出
假日的系统基线，每一条基线由24个基线值组成，每个基线值是某一项运行指标数据模型
均值，作为这个时点的基线，图8-4是运行基线的建设方案。对各应用系统建立工作日和节
是建立运行基线，通过将当前运行数据与运行基线进行偏离分析来开展工作。
的运行问题。那么，如何判断当前运行数据是否存在潜在问题则十分关键。在这里我们主要
模型。
果坐席人力不足则会导致人工坐席满线而无法提供服务的情况。故有下面所述的这个分析
时，那么该交易将直接转接到人工坐席；如果异常交易过多，就需要更多的坐席支持，如
容易被发现，但其出现后影响又会比较大，比如在呼叫系统中如果IVR（自助语音）交易超
易失败以外，还有一些无反馈交易处理结果的数据，这类交易可能导致一些单边账交易，
面交易笔数的模型进行设计。
析，除了要对整体交易进行分析以外，还要分渠道、交易码进行分析。这两个模型可参考上
出来。
一般不会出现性能瓶颈。当存量数据越来越多时，系统每笔交易的平均处理性能就会显现
力是否下降。例如：一个应用系统在上线初期，虽然交易性能不高，但由于存量数据不多
统的平均处理能力，再通过一个周期的交易耗时来进行分析，可以看到平台整体的处理能
交易异常的类型是性能问题，还是功能设计问题。
时的，那么可能是某个下游系统的处理能力有问题所导致的。这样的分析模型可以帮助发现
198
－所谓运行基线即根据上一分析周期历史运行数据进行采样，并按一定的周期计算一个平
建立数据模型并非将数据做一个简单的汇总和展示，而是从当前运行的数据中发现潜在
4.数据模型解决方案
单独对异常交易建立一个分析模型，因为在实际的应用性能分析中，除了交易成功、
（3）异常交易笔数
2）按渠道、交易码统计交易耗时：类似于上面交易笔数的分析模型，对交易耗时的分
1）系统整体交易处理笔数：对应用系统整体交易处理耗时进行分析，可以看到当前系
（2）交易平均耗时
交易返回码是对一些交易渠道处理结果的反映，例如：如果有大量的交易码都是通信超
交易异常笔数：
交易失败笔数：
运维前线：一线运维专家的运维方法、技巧与实践
不
---
## Page 215
8.2.1数据采集接口
决策，以及数据可视化平台的建设方案。
可能会遇到如下这些问题：
考虑如何将运行分析推广下去。运行分析平台架构如图 8-5 所示。在运行分析的推广过程中，
8.2
坏。
在数据采集接口方面，我们最初考
本节主要介绍数据的采集、分析、
口分析的报告无法及时提交给决策
口需要手工采集运行数据，
通过前面所讲数据采集与数据模型的建立，数据分析的基本模块已经实现，接下来需要
口缺少一个可视化的系统。
口平均耗时120毫秒是正常的吗？
口清理干扰数据：主要是在分析过程中，针对波动性很强的数据进行清理，比如因为交
口按整体偏离趋势：仍以CPU为例，我们根据当前运行点的指标与基线进行对比，查
口按偏离次数：以CPU为例，我们将CPU值在基线上方超过25%的点取出，根据点的
为了减少误报率，主要从以下三个方面进行处理。