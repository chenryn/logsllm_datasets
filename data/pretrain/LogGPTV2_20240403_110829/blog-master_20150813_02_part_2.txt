 * The disk traffic is assumed to be 3/4ths sequential and 1/4th random  
 * accesses (XXX can't we refine that guess?)  
 *  
 * By default, we charge two operator evals per tuple comparison, which should  
 * be in the right ballpark in most cases.  The caller can tweak this by  
 * specifying nonzero comparison_cost; typically that's used for any extra  
 * work that has to be done to prepare the inputs to the comparison operators.  
 *  
 * 'pathkeys' is a list of sort keys  
 * 'input_cost' is the total cost for reading the input data  
 * 'tuples' is the number of tuples in the relation  
 * 'width' is the average tuple width in bytes  
 * 'comparison_cost' is the extra cost per comparison, if any  
 * 'sort_mem' is the number of kilobytes of work memory allowed for the sort  
 * 'limit_tuples' is the bound on the number of output tuples; -1 if no bound  
 *  
 * NOTE: some callers currently pass NIL for pathkeys because they  
 * can't conveniently supply the sort keys.  Since this routine doesn't  
 * currently do anything with pathkeys anyway, that doesn't matter...  
 * but if it ever does, it should react gracefully to lack of key data.  
 * (Actually, the thing we'd most likely be interested in is just the number  
 * of sort keys, which all callers *could* supply.)  
 */  
void  
cost_sort(Path *path, PlannerInfo *root,  
                  List *pathkeys, Cost input_cost, double tuples, int width,  
                  Cost comparison_cost, int sort_mem,  
                  double limit_tuples)  
        Cost            startup_cost = input_cost;  
        Cost            run_cost = 0;  
        double          input_bytes = relation_byte_size(tuples, width);  
        double          output_bytes;  
        double          output_tuples;  
        long            sort_mem_bytes = sort_mem * 1024L;  
        if (!enable_sort)  
                startup_cost += disable_cost;  
        path->rows = tuples;  
        /*  
         * We want to be sure the cost of a sort is never estimated as zero, even  
         * if passed-in tuple count is zero.  Besides, mustn't do log(0)...  
         */  
        if (tuples  0 && limit_tuples  sort_mem_bytes)  
        {  
                /*  
                 * We'll have to use a disk-based sort of all the tuples  
                 */  
                double          npages = ceil(input_bytes / BLCKSZ);  
                double          nruns = (input_bytes / sort_mem_bytes) * 0.5;  
                double          mergeorder = tuplesort_merge_order(sort_mem_bytes);  
                double          log_runs;  
                double          npageaccesses;  
                /*  
                 * CPU costs  
                 *  
                 * Assume about N log2 N comparisons  
                 */  
                startup_cost += comparison_cost * tuples * LOG2(tuples);  
                /* Disk costs */  
                /* Compute logM(r) as log(r) / log(M) */  
                if (nruns > mergeorder)  
                        log_runs = ceil(log(nruns) / log(mergeorder));  
                else  
                        log_runs = 1.0;  
                npageaccesses = 2.0 * npages * log_runs;  
                /* Assume 3/4ths of accesses are sequential, 1/4th are not */  
                startup_cost += npageaccesses *  
                        (seq_page_cost * 0.75 + random_page_cost * 0.25);  
        }  
        else if (tuples > 2 * output_tuples || input_bytes > sort_mem_bytes)  
        {  
                /*  
                 * We'll use a bounded heap-sort keeping just K tuples in memory, for  
                 * a total number of tuple comparisons of N log2 K; but the constant  
                 * factor is a bit higher than for quicksort.  Tweak it so that the  
                 * cost curve is continuous at the crossover point.  
                 */  
                startup_cost += comparison_cost * tuples * LOG2(2.0 * output_tuples);  
        }  
        else  
        {  
                /* We'll use plain quicksort on all the input tuples */  
                startup_cost += comparison_cost * tuples * LOG2(tuples);  
        }  
        /*  
         * Also charge a small amount (arbitrarily set equal to operator cost) per  
         * extracted tuple.  We don't charge cpu_tuple_cost because a Sort node  
         * doesn't do qual-checking or projection, so it has less overhead than  
         * most plan nodes.  Note it's correct to use tuples not output_tuples  
         * here --- the upper LIMIT will pro-rate the run cost so we'd be double  
         * counting the LIMIT otherwise.  
         */  
        run_cost += cpu_operator_cost * tuples;  
        path->startup_cost = startup_cost;  
        path->total_cost = startup_cost + run_cost;  
}  
```  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")