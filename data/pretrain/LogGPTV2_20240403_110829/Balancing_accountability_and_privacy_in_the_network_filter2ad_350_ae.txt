delegates save briefs for 30 seconds) and one signature gen-
eration at the delegate. We think these numbers are rea-
sonable and leave enough headroom to comfortably han-
dle larger networks—CuckooFilter [38] achieves more than
180,000 lookups per second in a table with one billion entries
and the Ed25519 signature system [8] can perform 109,000
signatures per second on a 2010 quad-core 2.4GHz Westmere
CPU.
Storage Overhead
As routers verify ﬂows, they keep a
whitelist of veriﬁed ﬂows so that every single packet need
not be veriﬁed. Whitelist entries expire at the end of each
veriﬁcation interval, at which point the ﬂow is re-veriﬁed.
We use our trace to estimate the size of this whitelist.
To account for network architectures with addresses sig-
niﬁcantly larger than IP’s, we assume each address is 60
bytes—20 bytes each for the NID, HID, and SID. (Many re-
search eﬀorts explore self-certifying IDs [6, 27, 4, 17] which
are typically the hashes of a name or public key; we choose
20 bytes since SHA-1 produces 20 byte digests.) Entries
identify ﬂows at a host-host granularity, so each one is 120
bytes (two 60 byte addresses).
Figure 10 shows the size of the whitelist as we vary the
veriﬁcation interval. For a given veriﬁcation interval, we
group the ﬂows in our trace into bins the size of that interval;
ﬂows belong to a bin if they were active during that time
period (so a ﬂow could belong to multiple bins). The ﬁgure
reports the whitelist size based on both the average number
of ﬂows across bins as well as the maximum seen in any
bin. A 10 second interval requires a maximum of 94 MB of
whitelist space.
Shutoﬀ() After receiving a shutoﬀ(), a delegate blocks
malicious ﬂows by ceasing to verify them. The next time
a router on the path from the attacker to the victim veri-
ﬁes the ﬂow, the delegate returns DROP_FLOW and the router
blocks the ﬂow. How quickly this happens after a shutoﬀ()
depends on how many on-path routers perform veriﬁcation
and how often they verify each ﬂow. Figure 11 shows the
expected delay before a shutoﬀ takes eﬀect for diﬀerent veri-
ﬁcation intervals as a function of the number of participating
routers.
8.2 Privacy
How much privacy does APIP buy? If a sender uses its
source domain as a delegate, this depends on the size of
that domain. Raghavan et. al. ﬁnd that, if ISPs were to
aggregate preﬁxes geographically, over half of the preﬁxes
advertised by many popular last-mile ISPs would include
more than 10 million IPs [30].
If a sender uses a third party delegate, the anonymity set
grows the farther a packet travels from the source domain.
To see how much, we use Route Views [2] data from Jan-
uary 1, 2014 to roughly estimate AS “fanout.” For each AS,
we track how many customer networks sit beneath it in the
AS hierarchy. (To be conservative, we only count an AS as
a customer if it originates a preﬁx. Transit networks with
no hosts do not contribute to an anonymity set.) For each
BGP announcement, we add the origin AS to its ﬁrst- and
second-hop providers’ customer sets. Figure 12 shows a CDF
of ﬁrst- and second-hop anonymity set sizes. Notably, 50%
of ASes originating preﬁxes have at least 180 ﬁrst-hop “sib-
lings” and 90% have over 900 second-hop siblings. Though
Figure 7: Brief cache size at delegate
vs. ﬁngerprint expiry interval.
Figure 8: Brieﬁng bandwidth overhead.
Figure 9: Veriﬁcation rate at delegate
vs. ﬂow veriﬁcation interval.
Figure 10: Size of whitelist of veriﬁed
ﬂows vs. ﬂow veriﬁcation interval.
Figure 11: Expected time to shutoﬀ vs.
number of on-path veriﬁers.
Figure 12: Anonymity Set Size
drawing conclusions about AS topology based on BGP an-
nouncements is imprecise, these ballpark ﬁgures give an idea
of the anonymity beneﬁts of delegated accountability.
9. RELATED WORK
Privacy Various techniques exist for hiding network source
addresses, including crowds [32], mixes [12], and onion rout-
ing [31]. Real-world implementations based on these ideas
include Anonymizer2 and Tor3. Liu et al. consider build-
ing onion routing into the network architecture itself [25].
NDN [20] takes a more radical approach by eliminating source
addresses altogether; data ﬁnds the sender by following “bread
crumbs” left by the request. The drawback to all of these
approaches is a complete lack of accountability; there is no
easy way to link malicious traﬃc with senders.
Raghavan et. al. [30] describe ISPs oﬀering NAT for pri-
vacy as a service but uses a single source address. LAP [19]
is similar to (but more secure than) our “NAT-at-every-hop”
approach but does not consider accountability.
Accountability Techniques like ingress/egress ﬁltering [16,
24] aim to provide some degree of accountability by reduc-
ing the prevalence of source address spooﬁng; more sophis-
ticated variants exist [29, 14, 21]. This class of approaches
has limitations we address: (1) source addresses are only
protected on a domain granularity, (2) ﬁltering by itself pro-
vides no “shutoﬀ” mechanism for misbehaving hosts who
do not send spoofed packets, and (3) it is not compati-
ble with schemes for hiding return addresses for the sake
of anonymity.
As described in §3.1, our verify() and shutoﬀ() mecha-
nisms borrow heavily from AIP [4], which in turn based its
mechanisms on ideas presented by Shaw [34] and in AITF
2http://www.anonymizer.com/
3https://www.torproject.org/
[5]. By modifying these mechanisms to work with delegates,
we make them privacy-preserving, enable long-term resolu-
tion, and avoid relying on self-certifying IDs.
Accountability delegates are described in [7], but the pro-
tocol is costly and is not evaluated; privacy receives only
passing mention.
Balancing Accountability and Privacy The idea of
identify escrow is not new (e.g., [10]).
In particular, our
notion of delegated accountability is similar in ﬂavor to the
contractual anonymity described in RECAP [33], in which
a service provider (e.g., an online forum) oﬀers its users
anonymity which can be broken only if they violate a pre-
arranged contract. The key diﬀerence is that RECAP pro-
vides contractual anonymity at the application layer while
we balance anonymity and accountability at the network
layer, which poses unique constraints (like requiring source
addresses to be both routable and anonymizable).
Addressing The use of addresses that consist of separate
network, host and socket IDs, creating separate identiﬁers
and locators, has been widely proposed [15, 26, 22]. [11, 9]
discuss the meaning of source addresses, though without our
focus on privacy and accountability.
10. CONCLUSION
This paper attempts to show that a balance between ac-
countability and privacy in the network is possible. By de-
coupling source addresses’ roles as accountability addresses
and return addresses, APIP strikes a balance between the
two seemingly incompatible goals. Delegated accountabil-
ity allows routers to verify that each packet they forward is
vouched for and allows attack victims to report the abuse
while at the same time permitting senders to hide their
return addresses. Furthermore, the changes to traditional
thinking about source addresses required to implement APIP
020406080100120Brief Expiration Interval (sec)0.00.51.01.52.02.53.03.5Brief Cache Size (GB)Fingerprint (Max)Fingerprint (Avg)Bloom 10e-7 (Max)Bloom 10e-7 (Avg)Bloom 10e-3 (Max)Bloom 10e-3 (Avg)050100150200250300350Time (sec)050100150200250300350Briefing Overhead (mbps)FingerprintsBloom (false pos rate: 10e-7)Bloom (false pos rate: 10e-3)020406080100120Verification Interval (sec)050100150200250300350400450Thousand Verifies per SecondMaximumAverage020406080100120Verification Interval (sec)0100200300400500600Whitelist Size (MB)MaximumAverage12345678910Number of Verifying Rotuers0102030405060Expected Time to Shutoff (sec)120 sec verify interval60 sec verify interval30 sec verify interval10 sec verify interval050001000015000200002500030000Anonymity Set Size (# ASes)0.00.20.40.60.81.0CDFFirst hopSecond hopare not radical; though more exploration is clearly required,
we think the ideas presented here could be applied to the
current Internet.
Acknowledgments
Many thanks to the reviewers and to our shepherd, John
Wroclawski, for their insightful suggestions. This research
was funded in part by NSF under award number CNS-1040801
and by DoD, Air Force Oﬃce of Scientiﬁc Research, Na-
tional Defense Science and Engineering Graduate (NDSEG)
Fellowship, 32 CFR 168a.
11. REFERENCES
[1] Mining Hardware Comparison.
https://en.bitcoin.it/wiki/Mining hardware comparison.
[2] University of Oregon Route Views Project.
http://www.routeviews.org.
[3] Wikipedia qatar ban ‘temporary’. http:
//news.bbc.co.uk/2/hi/technology/6224677.stm,
Jan. 2007.
[4] D. G. Andersen, H. Balakrishnan, N. Feamster, et al.
Accountable internet protocol (AIP). SIGCOMM ’08,
pages 339–350, New York, NY, USA, 2008. ACM.
[5] K. J. Argyraki and D. R. Cheriton. Active internet
traﬃc ﬁltering: Real-time response to denial-of-service
attacks. In USENIX Annual Technical Conference,
General Track, pages 135–148, 2005.
[6] T. Aura. Cryptographically Generated Addresses
(CGA). RFC 3972 (Proposed Standard), Mar. 2005.
Updated by RFCs 4581, 4982.
[7] A. Bender, N. Spring, D. Levin, and B. Bhattacharjee.
Accountability as a service. SRUTI, 7:1–6, 2007.
[8] D. J. Bernstein, N. Duif, T. Lange, P. Schwabe, and
B.-Y. Yang. High-speed high-security signatures.
Journal of Cryptographic Engineering, 2(2):77–89,
2012.
[9] M. B. Braun and J. Crowcroft. SNA: Sourceless
Network Architecture. Technical Report
UCAM-CL-TR-849, University of Cambridge,
Computer Laboratory, Mar. 2014.
[10] J. Camenisch and A. Lysyanskaya. An eﬃcient system
for non-transferable anonymous credentials with
optional anonymity revocation. In Advances in
Cryptology-EUROCRYPT 2001, pages 93–118.
Springer, 2001.
[11] C. Candolin and P. Nikander. IPv6 source addresses
considered harmful. In NordSec ’01, pages 54–68, 2001.
[12] D. Chaum. Untraceable electronic mail, return
address, and digital pseudonyms. Communications of
the ACM, 24(2):84–88, 1981.
[13] D. D. Clark, J. Wroclawski, K. R. Sollins, and
R. Braden. Tussle in cyberspace: deﬁning tomorrow’s
internet. SIGCOMM ’02, pages 347–356, New York,
NY, USA, 2002. ACM.
[14] Z. Duan, X. Yuan, and J. Chandrashekar.
Constructing inter-domain packet ﬁlters to control ip
spooﬁng based on bgp updates. In INFOCOM, 2006.
[15] D. Farinacci, V. Fuller, D. Meyer, and D. Lewis. The
Locator/ID Separation Protocol (LISP). RFC 6830
(Experimental), Jan. 2013.
[16] P. Ferguson and D. Senie. Network Ingress Filtering:
Defeating Denial of Service Attacks which employ IP
Source Address Spooﬁng. RFC 2827 (Best Current
Practice), May 2000. Updated by RFC 3704.
[17] D. Han, A. Anand, F. Dogar, et al. XIA: eﬃcient
support for evolvable internetworking. NSDI’12, pages
23–23, Berkeley, CA, USA, 2012. USENIX
Association.
[18] D. Harkins and D. Carrel. The Internet Key Exchange
(IKE). RFC 2409 (Proposed Standard), Nov. 1998.
Obsoleted by RFC 4306, updated by RFC 4109.
[19] H.-C. Hsiao, T.-J. Kim, A. Perrig, et al. Lap:
Lightweight anonymity and privacy. In Security and
Privacy (SP), 2012 IEEE Symposium on, pages
506–520. IEEE, 2012.
[20] V. Jacobson, D. K. Smetters, J. D. Thornton, et al.
Networking named content. CoNEXT ’09, pages 1–12,
New York, NY, USA, 2009. ACM.
[21] C. Jin, H. Wang, and K. G. Shin. Hop-count ﬁltering:
an eﬀective defense against spoofed ddos traﬃc. In
CCS ‘03, pages 30–41. ACM, 2003.
[22] V. Kaﬂe, K. Nakauchi, and M. Inoue. Generic
identiﬁers for id/locator split internetworking. In
K-INGN 2008., pages 299–306, 2008.
[23] S. Kandula, D. Katabi, M. Jacob, and A. Berger.
Botz-4-sale: Surviving organized ddos attacks that
mimic ﬂash crowds. In NSDI ‘05.
[24] T. Killalea. Recommended Internet Service Provider
Security Services and Procedures. RFC 3013 (Best
Current Practice), Nov. 2000.
[25] V. Liu, S. Han, A. Krishnamurthy, and T. Anderson.
Tor instead of ip. In HotNets ‘11.
[26] D. Meyer, L. Zhang, and K. Fall. Report from the IAB
Workshop on Routing and Addressing. RFC 4984
(Informational), Sept. 2007.
[27] R. Moskowitz and P. Nikander. Host Identity Protocol
(HIP) Architecture. RFC 4423 (Informational), May
2006.
[28] J. Naous, M. Walﬁsh, A. Nicolosi, et al. Verifying and
enforcing network paths with icing. CoNEXT ’11,
pages 30:1–30:12, New York, NY, USA, 2011. ACM.
[29] K. Park and H. Lee. On the eﬀectiveness of
route-based packet ﬁltering for distributed dos attack
prevention in power-law internets. In SIGCOMM
CCR, volume 31, pages 15–26. ACM, 2001.
[30] B. Raghavan, T. Kohno, A. C. Snoeren, and
D. Wetherall. Enlisting ISPs to improve online
privacy: IP address mixing by default. PETS ’09,
pages 143–163, 2009.
[31] M. G. Reed, P. F. Syverson, and D. M. Goldschlag.
Anonymous connections and onion routing. IEEE
Journal on Selected Areas in Communications, 1998.
[32] M. K. Reiter and A. D. Rubin. Crowds: Anonymity
for web transactions. TISSEC, 1(1):66–92, 1998.
[33] E. J. Schwartz, D. Brumley, and J. M. McCune. A
contractual anonymity system. In NDSS ‘10, 2010.
[34] M. Shaw. Leveraging good intentions to reduce
unwanted network traﬃc. In Proc. USENIX Steps to
Reduce Unwanted Traﬃc on the Internet workshop,
page 8, 2006.
[35] P. Srisuresh and K. Egevang. Traditional IP Network
Address Translator (Traditional NAT). RFC 3022
(Informational), Jan. 2001.
[36] X. Yang, D. Wetherall, and T. Anderson. TVA: A
DoS-limiting network architecture. Networking,
IEEE/ACM Transactions on, 16(6):1267–1280, 2008.
[37] X. Zhang, H.-C. Hsiao, G. Hasker, et al. SCION:
Scalability, control, and isolation on next-generation
networks. In Security and Privacy 2011(SP), 2011
IEEE Symposium on, pages 212–227, 2011.
[38] D. Zhou, B. Fan, H. Lim, M. Kaminsky, and D. G.
Andersen. Scalable, high performance ethernet
forwarding with cuckooswitch. CoNEXT ’13, pages
97–108, New York, NY, USA, 2013. ACM.