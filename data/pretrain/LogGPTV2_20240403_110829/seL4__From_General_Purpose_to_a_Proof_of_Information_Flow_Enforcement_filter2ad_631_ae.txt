for interrupts and preventing inter-partition communication
channels from being destroyed respectively. Neither of these
limitations is uncommon in deployed separation kernels.
Our proof also makes a number of extra-logical assump-
tions. Many of these are inherited directly from the seL4
functional correctness proof [27] on which our result builds.
These inherited assumptions are that the C compiler and
linker used to build the kernel correctly implement
the
formal C semantics [52] of the proof on the platform of
deployment (i.e. compiler and linker correctness), that the
behaviour of the deployment hardware matches the formal
machine model on which the proofs rest (i.e. hardware
424
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:26 UTC from IEEE Xplore.  Restrictions apply. 
ticks of a partition, ﬂushing caches on partition switches
or dividing caches between partitions using cache colouring
and so on. However, deciding on a particular implementation
necessarily involves a trade-off between performance and
covert channel bandwidth that can only be made within the
context of a particular deployment scenario. For seL4, this
analysis can also be made with reference to sound worst-case
execution time (WCET) calculations for the kernel [12].
Our proof says much more about the absence of covert
storage channels, particularly those that might be in the
kernel. We list several channels uncovered by the proof in
Section V-D; all were eliminated either through making the
abstract speciﬁcation more concrete (see below) or by adding
assumptions on the initial conﬁguration. Our proof certainly
rules out all storage channels present in the seL4 abstract
speciﬁcation, including all user-accessible physical memory,
CPU registers, and machine state such as the interrupt masks.
It also includes the abstract representation of the kernel heap
present in the abstract speciﬁcation. What is more, because
our formulation of information ﬂow security is preserved
under reﬁnement, it also rules out user-visible kernel storage
channels below the level of abstraction of the abstract
speciﬁcation, such as the raw memory of the C kernel heap.
This is because any such channel must show up as user-
visible nondeterminism exhibited by the kernel. In order to
be preserved by reﬁnement, our information ﬂow security
formulation tolerates no user-visible nondeterminism [36]:
such nondeterminism could always be reﬁned by an inse-
cure implementation that resolves the nondeterminism by
examining a secret piece of state, and therefore cannot be
tolerated by a reﬁnement-closed security condition [35].
Indeed, our proof of information ﬂow security uncovered
a number of cases where the kernel uses state present in
the C kernel heap to make choices that are visible to user-
space, but where that state was below the level of abstraction
of the abstract speciﬁcation. Each of these showed up as
user-visible nondeterminism in the abstract speciﬁcation,
and was ﬂagged by the proof as a potential covert storage
channel. To prove information ﬂow security, we had to
make the kernel speciﬁcation more concrete to remove the
user-visible nondeterminism [33], and then re-establish the
functional correctness and integrity results for the augmented
speciﬁcation. The remaining nondeterminism in the abstract
speciﬁcation is never revealed by the kernel to user-space—
our proof guarantees this—and includes for instance the
mapping between physical address space identiﬁers (ASIDs)
and the virtual pool of such ASIDs that seL4 maintains.
correctness), that the kernel’s 450 lines of assembly code
correctly match their speciﬁcation, including that caching-
and TLB-operations are placed correctly, and that the ker-
nel’s initialisation code that runs before it hands control to
the initial thread correctly establishes the kernel invariants.
Many of these assumptions are themselves amenable
to formal veriﬁcation, particularly compiler/linker correct-
ness [13], [50], assembly and context-switching code cor-
rectness [37] and correctness of the initialisation code, an
earlier version of which was veriﬁed at the design level [27].
The hardware model that we share with the seL4 functional
correctness proofs effectively assumes that DMA is disabled.
Our proof also brings a few new implicit assumptions.
Our formulation of information ﬂow security assumes that
the global static partition schedule is allowed to be known by
all partitions. Hence it does not prevent one partition from
knowing about the existence of another, nor does it prevent a
newly scheduled partition from inferring that the previously
running partition must have exhausted its timeslice.
Our model of interrupts, described in Section IV-B, im-
plies that partitions can observe the passage of global time.
Stronger separation where time is not visible to all partitions
could be imagined, but our proof does not enforce this.
A technicality placed on the interrupt oracle by our termi-
nation insensitive formulation of information ﬂow security is
that the oracle delivers an inﬁnite stream of timer interrupts.
This ensures that partition steps always terminate.
As mentioned in Section I, we implicitly assume that
DMA is not enabled. We also assume that user-space threads
have direct access to only those sources of information that
we model: machine registers and memory pages mapped
with read rights, so that user-space threads may be modelled
as a deterministic function of these inputs. Thus we implic-
itly assume that the initial conﬁguration prevents partitions
communicating via external devices.
C. Covert Channels
Our noninterference property, while true of the C imple-
mentation, is phrased against, and so has meaning at the
level of, the kernel’s abstract speciﬁcation. As explained in
Section I, the formal machine model on which our proofs
rest does not model time explicitly. While exposed coarsely
through the interrupt oracle (Section IV-B), our proof says
little about covert timing channels. Timing channels must
still be analysed and mitigated using traditional means.
As mentioned earlier, our partition-based scheduling im-
plementation is known to suffer from jitter, in that it allows
a partition to overrun its timeslice by performing a system
call just before the arrival of the next timer interrupt. Other
obvious timing channels that certainly exist in the current
seL4 implementation but are likewise not addressed by
our proof include timing channels due to shared caches or
devices. Each of these has obvious mitigation strategies,
such as preventing system calls during the last n timer
Our proof does not rule out
the possibility of covert
storage channels that are below the level of abstraction of
the abstract speciﬁcation, but that the kernel never reads. For
instance, suppose the kernel were ported to a new platform
that included extra CPU registers that the kernel never reads,
but that the port was done incorrectly such that the kernel
fails to clear these registers on a partition switch. It is
425
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:26 UTC from IEEE Xplore.  Restrictions apply. 
possible our proof would still hold despite the presence
of an obvious covert storage channel. Formally,
this is
captured by the hardware correctness assumption. Guarding
against it requires validating that the formal machine model
corresponds to the platform of deployment.
D. Lessons Learned
The proof was carried out over 21 months, and required
a total effort of roughly 51 person-months (pm). This
includes adding the partition scheduler (≈ 2 pm), making
the abstract speciﬁcation more deterministic (≈ 23 pm), and
the information ﬂow security proofs themselves (≈ 26 pm).
The proof of information ﬂow security comprises 27,756
lines of Isabelle/HOL not including whitespace and com-
ments. This ﬁgure excludes the changes made to the ab-
stract speciﬁcation, the repair to the functional correctness
proofs, and the necessary evolution and strengthening of the
integrity and authority conﬁnement results needed for them
to hook up with the information ﬂow statement.
While the total effort for information ﬂow control
is
higher than the 10 person-months reported by Sewell et al.
for integrity and authority conﬁnement [51], it is still far
below the 25 person-years of effort required for the original
functional correctness proofs for seL4 [27]. As with the
previous proof of integrity, we gained a signiﬁcant saving
in effort by being able to prove information ﬂow security
for seL4’s C implementation over its abstract speciﬁcation.
Sewell et al. estimate that proving integrity over seL4’s C
implementation directly would have required on the order
of the original 25 person-years to complete. We estimate
an even higher ﬁgure for information ﬂow security, even
assuming an initial proof of integrity on which to build
on. Unlike with integrity, however, proving information ﬂow
security over seL4’s abstract speciﬁcation came at the cost
of having to remove much of the nondeterminism from the
abstract speciﬁcation (see also Section V-C). Because the
effort required to do so (≈ 23 pm) was low in comparison,
proving information ﬂow security over the abstract speciﬁ-
cation was still undoubtedly the right thing to do.
The proof uncovered many channels in the kernel, some
of which were initially surprising even to those who had
worked with seL4 for years. Very early on in the proof,
the problem of seL4’s object deletion semantics (see Sec-
tion IV-E), in which an object is deleted only when the last
capability in existence to it is deleted, became apparent. That
this behaviour could give rise to a potential channel was
something that had not been explicitly considered before.
We decided to address this by adding an assumption on the
initial conﬁguration. We were then obliged to prove that this
assumption was sufﬁcient to remove the potential channel.
Another channel uncovered by the proof was connected
to the kernel’s interrupt delivery mechanism, namely that
the kernel does not isolate the interrupts of one partition
from another. Taking advantage of the fact that polling for
device interrupts is common practice in separation kernels,
we again decided to add the assumption that this API facility
is disabled at startup instead of rewriting seL4’s interrupt
handling code. The proof again forced us to show that this
was sufﬁcient to remove the channel.
Other channels that the proof forced us to reason about
were anticipated from the beginning: our rules for con-
structing the information ﬂow policy (cid:2) from the access
control policy explicitly allow a two-way ﬂow of information
between partitions connected by a synchronous endpoint, for
instance. The proof still forced us to show that synchronous
endpoints, while allowing a bidirectional ﬂow between
sender and receiver, do not leak information to anyone else.
Similarly, the original seL4 scheduler, before partition
scheduling was implemented, was known not to enforce
isolation. We could not prove information ﬂow security until
we had fully and correctly speciﬁed the partition scheduler
in the updated abstract speciﬁcation. Proving information
ﬂow security then required us to show that the scheduler’s
choice about which partition to schedule next can never be
affected by any other partition, as one would expect.
Apart from one minor change to simplify veriﬁcation,
the partition scheduler was the only change required to the
seL4 C code, which is what we expected when we began.
It provides some evidence of the security that can be gained
by going through the process of rigorously designing and
verifying a microkernel, even without a formal proof of
security. However, our formal proof of security is what
separates optimistic hope from well-founded conﬁdence,
grounded in formal proof.
Ultimately, our proof of information ﬂow security for
seL4 makes seL4 no more secure than it was to begin with
(excepting the implementation changes mentioned above).
However, it provides a very strong piece of evidence about
the security of seL4 and its suitability as a separation
kernel—the strongest such piece of evidence ever con-
structed for a general-purpose kernel.
VI. RELATED WORK
seL4 is a general-purpose microkernel, whose implemen-
tation we have proved can be conﬁgured to enforce static
information ﬂow security in the form of intransitive nonin-
terference. A number of kernels are designed speciﬁcally
to enforce information ﬂow control, such as HiStar [54]
whose size is comparable to seL4’s. HiStar implements a
simple semantics for enforcing information ﬂow control,
based on object labels and category ownership. However, to
our knowledge, there exists no formal proof that these rules
correctly model the behaviour of the HiStar implementation,
nor a formal connection between these rules and a high-level
security property like intransitive noninterference.
The ﬁrst serious attempts to verify an OS kernel ap-
peared in the late 1970s with UCLA Secure Unix [53]
and the Provably Secure Operating System (PSOS) [17],
426
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:53:26 UTC from IEEE Xplore.  Restrictions apply. 
and in the 1980s with KIT [11]. The design methodol-
ogy of PSOS was later used for the Kernelized Secure
Operating System (KSOS) [43] by Ford Aerospace. The
Secure Ada Target (SAT) [19] and the Logical Coprocessor
Kernel (LOCK) [49] are also inspired by the PSOS design
and methodology. The proof efforts of this time primarily
aimed at achieving functional correctness; security proofs
of the style presented here were not yet feasible. Klein [26]
provides a more comprehensive overview of this early work.
Functional correctness at the code level has only recently
been achieved by Klein et al. [27], on which we build, and
also independently by the Verisoft project [2].
Our proof further builds on the seL4 integrity proof by
Sewell et al. [51], and on the noninterference property and
associated proof calculus developed in earlier work [36].
Proofs of information ﬂow security for models of OS
kernels and hypervisors are not new. Below, we summarise
other recent work with similar goals. To our knowledge, ours
is the only mechanised proof that applies to the C code of a
general-purpose OS kernel/hypervisor. The C code level is
signiﬁcant, because no manual checking is needed to verify
the validity of the proof for the running artefact and it is easy
to validate that the proof still applies after code changes. The
proof check is mechanical and fully automatic, and all steps
from the C code on down are automatically generated by
compiler and linker, so any remaining errors are systematic
and not subject to error-prone human validation for every
new deployment or code version.
The work that comes closest to the one presented here is
INTEGRITY-178B, which is a real-time operating system
for which a machine-checked information ﬂow proof has
been completed [44]. However, unlike ours, this proof ap-
plies to a hand-written, detailed formal model of the kernel
that is not linked to its implementation by formal proof but
instead by careful informal argument. This leaves open the
possibility of implementation errors in INTEGRITY-178B
that
the
proof is not adequately updated when code or API change.
The isolation proved for INTEGRITY-178B is based on
the GWVr2 property [18], which bears similarities to our
formulation of information ﬂow security for seL4. The exact
relationship between the two deserves further study.