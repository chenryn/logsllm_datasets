87.5%
100%
100%
100%
94.7%
90.1%
94.7%
88.9%
100%
92.8%
49.7%
50.3%
94.3%
95.7%
91.8%
84.3%
95.2%
93.1%
99.3%
96.6%
97.2%
98.6%
93.2%
100%
100%
97.9%
98.6%
100%
100%
100%
100%
83.3%
100%
100%
100%
92.8%
Program Compilation-U1
Program Compilation-U2
FTP Server Login-U1
FTP Server Login-U2
Package Installation-U1
Package Deletion-U1
BS
13
13
28
10
24
27
6
10
10
10
13
24
103
5
8
480
165
26
41
33
75
13
39
116
9
52
Data Theft
Illegal Storage
Content Destruction
Backdoor Installation
Passwd-gzip-scp
Wget-gcc
Conﬁguration Leakage
Passwd-Reuse
Average
candidate, we ﬁrst randomly select one session of it and then
generate the corresponding behavior signature. Next, we use
the signature to predict similar behaviors in the remaining
5,279 sessions. Recall in Section III-F that
two behaviors
are considered similar if their cosine similarity is beyond the
merge threshold (0.85). The performance metrics are measured
using Recall, Precision, and F1 scores. Intuitively, they provide
a measure of true-positive rate, false-positive rate, and general
accuracy, respectively. We refer true positives to sessions cor-
rectly predicted with the behavior candidate and false positives
to sessions incorrectly predicted with the behavior candidate.
Table IV provides a summary of the experimental results.
WATSON demonstrates promising results (an average F1 score
of 92.8%) in behavior abstraction. Even for the complicated
behavior, the Code Reference-U2, WATSON still accomplishes
an F1 score of 83.5%. This is because by leveraging contextual
information of audit events, WATSON can reason the semantics
of behavior instances accurately. For example, when compiling
programs with gcc, child processes like cc1 and as will
create, read, and write temporary ﬁles for IPC. Such temporary
ﬁles are ﬁrst initialized randomly in the embedding space.
Through their contextual relationships with cc1 and as, WAT-
SON infers that they share similar semantics as the IPC medium
between cc1 and as, and thus enhances their proximity
in the embedding space. Consequently, WATSON boosts the
similarity of Program Compilation instances, although they
access different temporary ﬁles at ﬁrst glance.
Another interesting observation is that the precision is,
in most cases (20/25 in Table IV), higher than or equal to
the recall. The relatively low recall shows that the semantics
of behavior instances can be affected by noisy events even
after using IDF weighting and noise removal. That said, the
11
Fig. 6: F1 scores of ﬁve different embedding methods in
behavior abstraction.
high precision indicates that the impact caused by such noise
is limited. In particular, we discover that behavior instances
suffering from noisy events can drift away from the original
cluster. However, they will most likely form a new cluster
as false negatives instead of joining the existing one as false
positives. Furthermore, the average precision (92.8%) is lower
than the average recall (94.2%), although the precision is,
in most cases, higher than the recall. This primarily results
from two exceptional cases, the Program Submission-U1 and
Program Submission-U2 (PS1 and PS2 for short). PS1 and
PS2 signiﬁcantly pull down the average precision because they
are clustered together and continuously recognized as false
positives to each other. In fact, it is reasonable to predict PS2
given PS1 or vice versa as their only difference is using vim
or vi to edit documents. Consequently, WATSON still achieves
behavior abstraction with low false positives.
Next, the abstraction accuracy has no direct relationship
with the size of behavior signatures. For example, although
the Package Installation produces the largest signature, nearly
orders of magnitude larger than others, they manage to achieve
an F1 score of 96.6%, surpassing most cases. However, the
Package Deletion also generates a relatively large size signa-
ture but achieves one of the lowest accuracy (87.5%), which
even falls far behind the average. A plausible explanation is
that WATSON recognizes behaviors by representative patterns,
which do not necessarily coincide with spatial scale. The Apt
Update and Install using gpgv to authenticate keys is a unique
behavioral pattern. On the other hand, the Apt Purge uses
update-motd to examine the number of packets needed
for updates. However, this pattern is also in the Apt Update
and Install, which lowers its distinguishability. Moreover, the
abstraction accuracy does not rely on task types either. For
example, the Code Reference task simultaneously has 94.2%
and 83.5% accuracy for the Code Reference-U1 and Code
Reference-U2 behaviors. This suggests that it is system op-
erations that decide the recognizability of behaviors instead of
the task itself.
Finally, we observe that WATSON exhibits high accuracy at
categorizing malicious behaviors. For all eight attack scenarios,
WATSON can achieve, on average, 95.0% and 97.9% in terms
of recall and precision. In other words, 4 out of 80 malicious
sessions are missed, and 2 out of 5,200 benign sessions
are falsely predicted with malicious behaviors. Analysts can
further improve the recall and ﬁnally detect all 80 malicious
sessions by decreasing the merge threshold in HCA. Although
malicious behaviors can be seamlessly blended in background
activities by performing daily routines, most of them, if not all,
F1Scorenode2vecmetapath2vecTransHTransRTransE(a)
(b)
Fig. 7: Statistics of analysis workload (a) and behaviors (b) in our malicious dataset under raw audit logs (AL), KG (noise
removed) and behavior abstraction (WATSON). Each attack case corresponds to ten sessions, and we report the average results.
possess distinct operations. Take for example the Conﬁguration
Leakage and Backdoor Installation attacks. It is not an every-
day occurrence that vim collects system conﬁgurations and
sends them out remotely, or ProFTPD invokes a privileged
bash and downloads executable ﬁles. Accordingly, WATSON
can recognize malicious behaviors and separate them from
benign ones.
D. Comparison of Different Embedding Methods
To demonstrate the effectiveness in behavior semantics in-
ference, we compare TransE with four other embedding meth-
ods, namely node2vec [31], metapath2vec [24], TransH [81],
and TransR [51]. Before training these embedding models,
we have transformed our encodings of audit events to their
accepted input formats. For example, we deﬁne three types of
meta paths (i.e., ﬁle to process to ﬁle, socket to process to
socket, and process to process to process) for random walks
in the metapath2vec model.
• node2vec: This method deﬁnes the context of a node in
the graph based on its local neighborhood. It follows the
intuition that nodes from the same network community
should be mapped closely together in an embedding space.
• metapath2vec: This method treats meta-path based random
walks in a graph as natural language sentences in a corpus.
It then feeds these sentences into a skip-gram model to
learn node embeddings.
• TransH: To address the issue of TransE when modeling
relations that translate one entity to various entities (i.e., 1-
to-N problem, and similarly, N-to-1 and N-to-N problems),
this method extends TransE by introducing an additional
hyper-plane to learn relation embeddings.
• TransR: Unlike TransE and TransH, which assume that
entity and relation embeddings are within a shared space,
this method builds entity and relation in separate spaces. To
train embeddings, it ﬁrst projects entities from the entity
space to relation space and then calculates translations
among projected entities.
Figure 6 summarizes the behavior abstraction accuracy
of different embedding methods on our ﬁrst three datasets.
Translation-based embedding methods (i.e., TransE, TransH,
and TransR) consistently outperform the node2vec and meta-
path2vec, which well justiﬁes our design choice of using a
translation-based model to infer contextual semantics. Specif-
ically, the node2vec learns the semantics of elements based
on the behaviors they belong to. Its principle is that elements
from the same behavior share similar roles and thus should
have similar embeddings. However, for audit data, system
entity elements of a behavior are not necessarily similar. For
example, in the Program Compilation behavior, vim and gcc
are semantically irrelevant to each other. Moreover, the meta-
path2vec leverages meta-path based random walks to generate
heterogeneous neighborhoods for different types of elements
(e.g., processes and ﬁles). The downside is that it does not
consider relation elements when training the embedding space
for system entity elements. However, we note that relations
are critical to infer system entity semantics. For example,
(bash, read, /etc/passwd) and (bash, delete,
/etc/passwd) indicate completely different semantics for
the bash elements. As such, we hypothesize that this explains
why node2vec and metapath2vec are unable to achieve a
comparable abstraction accuracy as compared to translation-
based methods.
Within three translation-based embedding methods, TransR
slightly outperforms TransE and TransH through separating
the entity and relation embedding space. Notwithstanding, it
incurs a much larger runtime overhead. In our experiment,
the model training time of TransE, TransH, and TransR are
2.13, 3.47, and 5.70 hours, respectively. Different translation-
based methods demonstrate a trade-off between computational
efﬁciency and predictive accuracy. The fact that TransE and
TransR achieve almost the same accuracy, but TransE is around
three times faster suggests that TransE is more scalable for
long-term log analysis.
E. Efﬁcacy in Attack Investigation
We explore WATSON’s efﬁcacy by empirically measuring
the reduction of analysis workload in attack investigation.
In this paper, analysis workload is quantiﬁed as the number
of events an analyst would have to go through to identify
all behaviors in a session. More speciﬁcally, events of an
investigation before and after using WATSON refer to raw
audit logs and the sum of events for each behavior signature
identiﬁed. Although analysts do not necessarily search through
all related events to recognize a behavior, this metric provides
a reasonable way to demonstrate the proportion of reduced
events due to behavior abstraction. We evaluate WATSON
against our simulated malicious dataset, which includes eight
attack scenarios in Table II, as well as the DARPA TRACE
dataset, which includes ﬁve real-life APT attacks.
1) Evaluation on malicious dataset: Figure 7b summarizes
the resulting analysis workload reduction in our malicious
12
Count [log-scaled]DataTheftIllegalStorageContentDestructionBackdoor InstallationPasswd-gzip-scpWget-gccConfigurationLeakagePasswdReuseAverageCount DataTheftIllegalStorageContentDestructionBackdoor InstallationPasswd-gzip-scpWget-gccConfigurationLeakagePasswdReuseAverage(a)
(b)
Fig. 8: Case studies: (a) Conﬁguration Leakage. (b) Content Destruction.
bypasses the preﬁx check in vim, invokes a bash to collect
machine conﬁguration, and further transfers the information
remotely. To improve image prediction accuracy, the engineer
frequently seeks model optimization techniques online, which
introduces a bunch of noisy events.
As shown in Table IV, WATSON accurately recognizes
the Conﬁguration Leakage from other launched common be-
haviors. It can distinguish this behavior due to two reasons:
(1) Collecting and transferring machine conﬁgurations is a
unique behavioral pattern compared with daily routines like
material download and code submission; (2) The (vim, fork,
bash) triple is assigned high importance weight due to its low
frequency in the system. Any behavior instance containing it
would signiﬁcantly deviate from the rest. Furthermore, WAT-
SON clusters redundant behaviors like the Training Program
Submission and the Online Material Reference, thus efﬁciently
reducing analysis workload by avoiding duplicate inspection.
Content Destruction. This attack is an insider threat. Through
a downloaded malicious payload, an attacker ﬁrst exploits
the Serv-U FTP local escalation vulnerability to invoke a
privileged bash. After a successful initial compromise and
foothold establishment, he discovers a directory of classiﬁed
projects. However, the ﬁrewall blocks remote ﬁle transfer, so he
decides to randomly tamper with completed programs. Since
the knowledgeable insider is aware of the deployed IDS, he
simulates an extensive number of ordinary activities to disguise
himself as a regular developer, such as compiling programs
and receiving daily tasks. Therefore, although IDSs generate an
alert for this session, the attacker still wastes analysts intensive
labor and time to pinpoint all behaviors and reconstruct attack
scenarios. Traditionally, an analyst would have to investigate
all the behaviors in a session to verify the truth of alerts
reported by IDSs and explore other potential threats. To do
so, a total of 550,281 audit events, where most are noisy
information, are manually inspected. Fortunately, because most
noisy behaviors incorporated by the insider to bury attack
footprints are redundant, WATSON can efﬁciently assemble
them and save analysis workload by 284 times. For instance,
multiple Program Compilation instances are substituted with
one behavior signature for analysis. We ﬁnd WATSON partic-
ularly effective in insider threat investigation, which primarily
credits to its capability of clustering benign behaviors.
2) Evaluation on DARPA TRACE dataset: According to
the ground truth in the DARPA TC program report, DARPA
TRACE dataset contains ﬁve attack scenarios, namely Fire-
Fig. 9: Statistics of analysis workload and behaviors in DARPA
TRACE dataset under raw audit logs (AL), KG (noise removed)
and behavior abstraction (WATSON).
dataset. As a comparison, we also present intermediate work-
load reduction by removing noisy events deﬁned in Sec-
tion III-E. Combining the results in Table IV with Figure 7b,
we notice that WATSON signiﬁcantly decreases analysis work-
load without sacriﬁcing the accuracy of attack investigation.
In the analysis of eight attack scenarios in 80 malicious
sessions, WATSON shows two orders of magnitude (up to 284
times, with 134 times on average) workload reduction. We
also see a massive reduction in the number of behaviors, as
shown in Figure 7a. This is predictable as there are always
more behavior instances than representative behaviors in a
session, and WATSON can group them to prevent duplicate
investigations.
To gain further insights, we study behavior abstraction of
two attack cases from Table II: the Conﬁguration Leakage