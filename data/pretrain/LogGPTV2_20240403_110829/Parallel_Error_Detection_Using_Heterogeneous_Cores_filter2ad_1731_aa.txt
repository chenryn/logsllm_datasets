title:Parallel Error Detection Using Heterogeneous Cores
author:Sam Ainsworth and
Timothy M. Jones
2018 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Parallel Error Detection Using Heterogeneous Cores
Sam Ainsworth, Timothy M. Jones
University of Cambridge, UK
{sam.ainsworth,timothy.jones}@cl.cam.ac.uk
Abstract—Microprocessor error detection is increasingly impor-
tant, as the number of transistors in modern systems heightens
their vulnerability. In addition, many modern workloads in
domains such as the automotive and health industries are
increasingly error intolerant, due to strict safety standards.
However, current detection techniques require duplication of all
hardware structures, causing a considerable increase in power
consumption and chip area. Solutions in the literature involve
running the code multiple times on the same hardware, which
reduces performance signiﬁcantly and cannot capture all errors.
We have designed a novel hardware-only solution for error
detection, that exploits parallelism in checking code which may
not exist in the original execution. We pair a high-performance
out-of-order core with a set of small low-power cores, each of
which checks a portion of the out-of-order core’s execution. Our
system enables the detection of both hard and soft errors, with
low area, power and performance overheads.
Keywords—fault tolerance; microarchitecture; error detection
I. INTRODUCTION
Hardware faults, both soft (transient) and hard (permanent),
are increasingly common in microprocessors. As technology
nodes reduce and the number of transistors in a system
increases,
the likelihood of a failure is heightened. Small
transistors are more vulnerable to transient errors caused by
cosmic rays, and increased variability at smaller feature sizes
signiﬁcantly increases the occurrence of transient faults [1].
At the same time, the tolerance of many workloads to the
occurrence of errors has reduced. For example, strict safety
standards, along with suboptimal environmental conditions,
require error detection hardware within CPUs used for auto-
motive, health, nuclear power and machinery applications [2],
[3], [4]. Space applications require reliability for economic
reasons [3], and large scale HPC systems require reliability
due to having a large number of potential failures [5], [6], [7].
Certain industries mandate stringent safety standards to
achieve certiﬁcation, such as automotive, where redundancy
is required for ASIL-C and ASIL-D ratings [8]. The current
industry approach to address this is hardware lock-step error
detection [3], [9], [10]. This involves running multiple copies
of a program on separate, synchronised CPUs, and comparing
the results in hardware. However, this is both energy- and
silicon-area-intensive. As the computational requirements of
these systems grows [2], out-of-order cores are rapidly becom-
ing necessary to achieve the required performance. Duplicating
out-of-order cores comes at too high cost in energy, heat
dissipation and area to be practical.
Redundant multi-threading [1], [11], [12] has been pro-
posed, where simultaneous threads on the same core are used
to run two copies of a program, and the results compared.
However, as the same hardware is used for both copies,
permanent faults within the core can only be detected though
the addition of extra logic [13], and performance is also sig-
niﬁcantly reduced over the same code without error detection.
Prior work [14] has noted that parallelism is available in
the second, error-detecting run of a computation, and thus it is
possible to use homogeneous multi-core processors to reduce
energy cost by using dynamic frequency-voltage scaling at
the expense of tripling silicon area. In our approach, we focus
on a heterogeneous architecture specialised for exploiting far
larger amounts of error detection parallelism. We use the
principle of strong induction [15] to dramatically reduce the
overheads of using hardware to detect errors. We perform
delayed error detection on multiple small cores [16], which
check the computation carried out on a high-performance
out-of-order core. By taking periodic register checkpoints
and tracking the loads and stores carried out on the main
core, tiny checker cores can independently verify a portion
of the original computation each. The heterogeneity between
the computation core and its coupled checker cores allows
us to reduce area and power overheads signiﬁcantly, while
maintaining high performance.
II. BACKGROUND
We discuss the increasing prevalence of faults in microproces-
sors and standard error-detection schemes, before motivating
our approach in section III.
A. Faults
Hardware faults fall
into one of two distinct categories.
Permanent faults are the result of errors during manufacture
or wearout during the service life of the system. Transient
faults, on the other hand, are caused by strikes from cosmic
rays and alpha particles, and do not persist. However, there
is no effective way to shield a microprocessor from cosmic
rays [1], and while smaller transistors are individually less
likely to be hit by a ray, increasing numbers of transistors in
modern systems, coupled with the nominal energy required
to switch a transistor at
low source voltages [17], makes
chips increasingly vulnerable to transient faults [18]. Rapidly
increasing core counts for workloads such as HPC mean there
are more points of failure in systems, and therefore a higher
chance of hard faults [5], [6], [7]. Increased variance in chips at
lower source voltages [17], [19] make timing violations more
common, and the unfavorable conditions many safety critical
systems operate in, such as those in space or the automotive
industry [2], [3], [9], also serve to increase the number of
faults observed in modern systems.
2158-3927/18/$31.00 ©2018 IEEE
DOI 10.1109/DSN.2018.00044
338
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:27:31 UTC from IEEE Xplore.  Restrictions apply. 
(a) Lockstep
(b) RMT
(c) Desired
Overhead
Area
Energy
Performance
Lockstep
Large
Large
Negligible
(d) Comparison
RMT
Small
Large
Large
Desired
Small
Small
Negligible
Fig. 1: Running cores in lockstep, or running the same code twice on the same core via multi-threading, come with signiﬁcant
space and time overheads, respectively. However, we can optimise all of these signiﬁcantly if we can exploit parallelism in
the detection to run it on separate, simpler processors.
B. Detection
Current detection schemes use a combination of space and
information redundancy to cover faults [1]. Information re-
dundancy refers to using error-detecting codes, such as ECC,
to detect and correct errors in stored and transmitted data. As
errors in main memory are common, systems requiring relia-
bility, such as servers, have long been covered by ECC [20].
However, information redundancy techniques do not extend
to error checking within the computation itself, and thus the
processor logic must be covered by other schemes. Current
reliable systems favor lock-step error detection [3], [9], [10], a
space-based redundancy scheme where cores are duplicated in
their entirety. The program is executed on both simultaneously,
perhaps with some delay on the second core to avoid correlated
transient errors, and the results compared. This comes at both
a high chip area and power cost. Some techniques, such as
DIVA [21], [22], attempt to get around this by using simpliﬁed
duplicate hardware at the end of the pipeline, removing some
of the repeated work at the expense of requiring ECC on
all architectural state, including the register ﬁle. While some
architectures have featured parity bits on such state [23], full
ECC is too invasive to the microarchitecture and hence such
techniques have not seen implementation. Many time-based
schemes [1], [11], [12], [24], [25], which run duplicates of
a program on the same core twice at different times and
compare the results, have been proposed, exploiting techniques
such as simultaneous multi-threading to improve performance.
However, their high performance penalty and inability to cover
hard faults with additional logic [13] have meant that these
schemes have seen little use in practice.
III. MOTIVATION
The performance demands of common workloads are ever
increasing. As processors tend to be energy or heat limited,
due to current trends in silicon scaling [19], this translates
into a demand for high performance at low power. Hardware
duplication comes at the expense of performance, by reduc-
ing the power budget. Indeed, the cost of duplicating high-
performance out-of-order superscalar systems is typically too
high for practical error detection, as out-of-order superscalar
systems are already inefﬁcient [26].
We require fault detection with high performance,
low
power consumption and low chip area. Figure 1 shows
how existing techniques accomplish these. Lockstepping [9]
Fig. 2: We use register checkpoints to split dynamic execution
from a main core into small instruction streams. These are
run again on one of several small checker cores, to verify
execution. Each stream is independent of all others, allowing
parallelization of error detection.
(ﬁg. 1(a)), where we run the same program on two identi-
cal processors, only provides the former. Redundant multi-
threading [1], [11], [12] (ﬁg. 1(b)) only provides the latter.
If we can exploit heterogeneity between computation and
detection (ﬁg. 1(c)), we can achieve the low overheads and
minimal design invasiveness we require. In general, the smaller
the CPU, the more useful work can be done per unit area
and power [27]. For example, as of November 2017,
the
Green500 list [28] is topped by machines using arrays of tiny
cores. Modern GPUs and the Xeon Phi [29] follow a similar
design philosophy. Therefore, one way of achieving our goals,
provided we can parallelise the checking code, is to run the
fault detection on a set of very low power cores. However,
common CPU workloads tend to exhibit very little thread
level parallelism, so large out-of-order cores are necessary
to attain high performance [29], [30]. Despite this limitation,
in the next section we develop a scheme which realises the
parallelization of error detection for any program, enabling
us to take advantage of heterogeneity between the main and
checker cores, achieving full error detection with only minor
area, power and performance overheads.
IV. PARALLEL ERROR DETECTION
Our approach to error detection parallelizes the execution
of fault checking code, even when the original program is
sequential. We use the principle of strong induction [15] to
339
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:27:31 UTC from IEEE Xplore.  Restrictions apply. 
check multiple parts of the executed program at once. In other
words, we check each part of the application independently
assuming all previous parts were correct. Provided we prove
this for each part of the program, it is possible to ensure the
entire workload is free of hardware faults.
To realise parallel fault detection, we repeat computation
from a main high performance out-of-order core by executing
duplicate copies of all instructions. We take periodic register
checkpoints and use these to spawn checker threads which
repeat all computation between two checkpoints, executing
asynchronously and in parallel, since they are independent of
each other. During the original execution, we log load and
store values and addresses, redirecting duplicated memory ac-
cesses from checker threads to the log, which allows the main
application to overwrite memory locations without restriction.
The checker threads, executing on multiple low-power cores,
read the same memory values as the main core did, and check
the addresses and values of stores, and addresses of loads.
Figure 2 gives an example of how execution proceeds.
Each checker thread assumes that its starting checkpoint
is correct. It repeats all instructions up to its end register
checkpoint, which it validates, and which is also the starting
checkpoint for another checker thread. Additional hardware
checks stored data and their addresses against those from the
original computation as the checker threads execute.
We allow values potentially affected by a fault to propagate
into main memory. This is necessary to both avoid slowing
down the main core (as would occur with a large forwarding
table to forward unchecked stores), and to allow a large num-
ber of loads and stores be checked simultaneously, yielding
the parallelism that we exploit. This is common in software
schemes [31], [32]. If a check fails (either a check on a store or
a register checkpoint validation), all future computation must
be assumed to be faulty. This is because the assumption of
correctness of previous computation, required for the strong
induction hypothesis, does not hold. Correctness is only known
once all checks up to a given point successfully complete.
Similarly, if an error is detected within a check, we do not
know if it was the ﬁrst error until all previous checks complete.
Once that happens, our system provides sufﬁcient information
to identify that a fault has occurred, and the position of that
ﬁrst error, giving a practical error detection mechanism.
A. Overview
Figure 3 gives an overview of our system. We attach a col-
lection of small checker cores to a conventional out-of-order
core, in order to efﬁciently execute the duplicated instructions.
The loads and stores performed by the main core are stored in
a hardware load-store log [1], [11], [12], which is then split
into multiple segments, each checked by a different checker
core in parallel. There is a one-to-one mapping between log
segments and checker cores. The checker cores are also given
a copy of the register ﬁle at the start and end of each segment,
from which to start execution.
Loads are duplicated early by the load forwarding unit, to
ensure any errors within loaded values in the main CPU don’t
Fig. 3: Error detection is performed in parallel on a set of small
checker cores that execute duplicate instructions between two
register checkpoints, reading memory values from a load-store
log and validating store addresses and data.
propagate to the checker cores. We assume memory blocks
such as caches and DRAM are protected by ECC, since our
detection scheme is only designed to cover errors within the
core. Loaded values are copied within the cache at a point still
protected by ECC, ensuring that errors from the main core’s
load cannot propagate to the checker cores. We further assume
the instruction stream is read-only, such that the instructions
read by checker units will be identical to those read by the
main thread. This is a common design choice [1], [12], where
modiﬁcations to the instruction stream (e.g., in the case of
self-modifying code) require all checking to complete ﬁrst.
Our scheme provides only detection, rather than correction,
of soft and hard errors. This is equivalent to the dual-core lock-
step techniques used typically in the automotive industry [33],
where detection is mandatory and correction unnecessary, and
thus only detection is typically provided [9]. The detection
of an error triggers an exception within a program, which
can either be caught and handled, or cause termination of the
application, as with dual core lockstep implementations [34].
Errors detected within kernel code are reported to the kernel
itself. Incorrect values are deliberately allowed to propagate
into main memory and devices on a detected error:
the
exception trigger’s semantics take this into account.
Ours is a pure hardware scheme where detection is per-
formed without original program modiﬁcation. The main core
and checker cores execute identical code: differing load and
store behavior on checking, and stopping on reaching a register
checkpoint, are achieved using hardware logic. This is similar
to many redundant multi-threading schemes [1], [11], [12].
B. Checker Cores
Each of our small checker cores must implement the same
ISA as the main core, so that all cores can execute the same
340
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:27:31 UTC from IEEE Xplore.  Restrictions apply. 
"

#$
$%
"

 






































