There are a few parts to this ticket:
**Functionality**  
There is this logic (
elasticsearch/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AwarenessAllocationDecider.java
Line 222 in c579517
|  int averagePerAttribute = shardCount / numberOfAttributes;  
---|---  
) which prevents the allocation of shards when the number of shards per unique
node attribute used in the awareness (eg. rack_id) is exceeded (`if
(currentNodeCount > (requiredCountPerAttribute + leftoverPerAttribute)) {`).
In this particular use case, the user has 69 nodes with an index that has 1
primary shard defined with 68 replicas (so 69 copies of the shard). The
expectation is that it will put 1 shard on each node. The issue here is that
it doesn't and it ends up leaving 2 copies unassigned.
For example, one of the rack_id's used in allocation awareness is associated
to 5 different nodes in the cluster. It ended up allocating 1 shard on 4 of
the 5 nodes. At this point, (currentNodeCount > (requiredCountPerAttribute +
leftoverPerAttribute)), so it prevents the 5th node from getting a copy of
this shard. In this case averagePerAttribute is 2 (with 28 unique attributes)
so requiredCountPerAttribute is 2. totalLeftover is not 0, so
leftoverPerAttribute is 1. So 4 > 3 and it prevents the 5th node from getting
a shard copy.
There is quite an uneven distribution of nodes per rack_id, some rack_ids in
this setup has 1 node, others have up to 5 nodes in them. The allocation
decider logic is preventing all shards for that index from being allocated and
leaving a few unassigned.
For this use case, the user is not that concerned about distribution of shards
for this particular index across racks. But awareness is currently enabled for
the node/cluster and there does not appear to be a way to configure a specific
index to be excluded from the awareness logic.
**Documentation**  
Not much available on the above logic.
**Logging/Debugging**  
This may get a bit verbose so I am not sure about the feasibility of it. For
troubleshooting purposes, it will be helpful if we can write a trace line with
a bit more details than just the current message in the reroute explain
("explanation": "too many shards on nodes for attribute: [rack_id]"). Like it
will be useful if it will tell you the problem index, how many shards are
allowed, and how many are on there currently, etc.. Doesn't have to be logging
either, maybe add to the explanation string that is returned by reroute
explain to give some more specific information.