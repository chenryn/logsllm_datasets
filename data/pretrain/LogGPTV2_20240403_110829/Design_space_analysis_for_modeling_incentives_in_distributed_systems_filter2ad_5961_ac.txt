Stranger Policy: When interacting with an unknown peer
(stranger), past history cannot be used to inform actions. It is
therefore necessary to apply a policy to deal with strangers.
The way peers allocate resources to strangers is an important
aspect of this dimension.
Selection Function: When a peer requires interaction with others
this function determines which of the known peers should
be selected. This could include, for example, past behav-
ior (through direct experience or reputation system), service
availability and liveness criteria.
Resource Allocation: During peer interactions resources must be
allocated to the selected peers (given by the selection func-
tion). The way a peer divides its resources among the se-
lected peers, deﬁnes the resource allocation policy.
Some existing implemented protocols and proposed designs are
listed in Table 2. A protocol such as Give-to-Get (GTG) [21] em-
ploys unconditional cooperation with strangers as its stranger pol-
icy. A P2P replica storage design [30] presents a stranger policy
which defects on strangers when its set of regular partners is full.
For implementing the selection function, a deployed P2P reputa-
tion system like BarterCast [20] ranks peers in order of reputation
score and also proposes to ban peers below a certain reputation
score. P2P replica storage selects those peers which are closest
to the selecting peer’s own storage capacity. This selection pol-
icy is identical to the one proposed by us for implementing Birds in
BitTorrent-like ﬁle-sharing systems. For resource allocation, Maze
[32] allocates resources proportional to rank. These examples are
a few implemented systems and proposed designs; a large variety
of P2P systems that rely on eliciting cooperation from participating
nodes rely on similar dimensions.
4.2 Actualization of a Speciﬁc P2P Protocol
Design Space
We deﬁne some speciﬁc actualizations of a BitTorrent-like ﬁle
swarming system, as described in Section 2, based on the general
design space of Section 4.1. The ideas behind these actualizations
have been taken directly from, or inspired by, various works on co-
operation done in P2P and also some works done in biology and
social sciences in general [1, 10, 25]. We were motivated to take
inspiration from other ﬁelds, because eliciting cooperation in de-
centralized settings is a general problem that has been well-studied.
For the Stranger Policy, we deﬁne three different actualizations
and a value h for the number of strangers to cooperate with:
186B1) Periodic: Give resources to up to a certain number of
strangers periodically.
B2) When needed: Only give resources to strangers when set of
regular partners is not full. This particular implementation
has been inspired by [11].
B3) Defect: Always defect on strangers, i.e., give nothing to
strangers.
We set h, the number of strangers to cooperate with at any given
time, to be in the range [1,3]. This gives 3×3 = 9 different stranger
policies. We further add one more stranger policy, where the num-
ber of strangers is zero. This gives a total of 10 different stranger
policies.
We sub-divide the Selection Function into three parts: a candi-
date list, a ranking function over that candidate list, and ﬁnally a
value k for the number of peers to select from the ranked candidate
list.
For the ‘Candidate List’ we deﬁne two actualizations:
C1) TFT, used by default in BitTorrent, using which a peer only
places those peers in the candidate list who reciprocated to it
in the last round.
C2) TF2T, using which a peer places those peers in the candidate
list who reciprocated to it in either of the last two rounds.
TF2T has been taken from [1].
For the ‘Ranking Function’, we deﬁne six different actualiza-
tions:
I1) Sort Fastest, ranks peers in order of fastest ﬁrst.
I2) Sort Slowest, ranks peers in order of slowest ﬁrst.
I3) Sort Based on Proximity, ranks peers in order of proximity
to one’s own upload bandwidth, as in Birds.
I4) Sort Adaptive, ranks peers in order of proximity to an aspi-
ration level, which is adaptive and changes based on a peer’s
evaluation of its performance. This has been inspired from
[25].
I5) Sort Loyal, ranks peers in order of those who have cooper-
ated with the peer for the longest durations. This has been
inspired by [10].
I6) Random, does not rank peers and chooses them randomly.
This has been inspired by [15].
After applying the ranking function, a peer chooses the k top peers,
where k is the maximum number of partners that a peer can have.
Currently, we set k to be in the range [1,9]. This results in 2× 6×
9 = 108 different possibilities for the selection function. We further
add one more protocol, where the number of selected peers is zero.
This gives a total of 109 different selection policies.
For Resource Allocation, we deﬁne three actualizations:
R1) Equal Split, gives all selected peers equal resources (upload
bandwidth).
R2) Prop Share, gives others proportional to what they gave in
the past. This has been inspired by [16].
R3) Freeride, gives nothing to partners.
Based on the above, the total number of unique protocols comes
to 10× 109× 3 = 3270. We note that this number can be larger or
smaller based on what, and how many, speciﬁc implementations in
the space, designers want to explore2. Our purpose here is to show
the practicality of the DSA analysis by analyzing a considerable
space of unique protocols.
2For instance, we do not consider variants for resource allocation
to strangers. Also, we do not consider Peer Discovery.
4.3 Conducting the PRA quantiﬁcation
First we describe our simulation model. Then we discuss our
methodology for conducting the PRA quantiﬁcation on the design
space described in Section 4.2.
Simulation Model
4.3.1
We use a cycle-based simulation model, in which time consists
of rounds. For peer discovery we assume that all peers can con-
nect to each other. In each round, a peer decides to upload to a
given number of peers based on some selection criterion. It uses
its resource allocation policy to decide how much to give to each
of the selected partners. Furthermore, it decides to cooperate with
strangers based on its stranger policy. A peer also maintains a short
history of actions by others. At the same time a peer also has some
rate of requesting services from other peers that depends on speciﬁc
actualizations. This is the basic model on top of which we explore
the design space of Section 4.2. We run our simulation experiments
with 50 peers, which is a good approximation of an average BitTor-
rent swarm-size [9]. These peers interact with each other for 500
rounds. We use a cluster for running our experiments. In order to
lend realism to our experiments, we initialize the peers using the
bandwidth distribution provided by Piatek et al. [24]. We assume
that all peers always have data that others are interested in.
4.3.2 Methodology
Based on the PRA quantiﬁcation, as described in Section 3.2,
we ﬁrst measure the Performance of each protocol in the space.
For each protocol Π, we run simulations in which all peers execute
Π and measure the average performance of the population. We
perform 100 runs for each protocol. In these experiments we deﬁne
average performance as throughput of the population.
Next we run Robustness experiments. We run simulations, where
each protocol plays against every other protocol. We refer to a com-
petition in which two protocols are pitted against each other as an
encounter. For each encounter, the peer population is split up into
two equal halves where half the peers execute Π and the other half
executes another protocol. We chose 50% because this is the high-
est number that an invading protocol can have. Anything higher
than 50% means that the invading protocol actually becomes the
majority protocol. We hypothesize that if a protocol is robust when
50% of the population executes another protocol, then it will be
robust against small invading populations. To verify this hypothe-
sis, we also conduct simulations with the population split up into
90-10, where 90% of the peers follow protocol Π, while 10% ex-
ecute other protocols in the space, and observe similar results (the
Pearson’s correlation coefﬁcient of the two sets of results is 0.97).
We do 10 runs for each particular encounter between two protocols.
This means that a protocol Π plays against the same protocol ten
times. For each run, we compare the average performance of Π
with the average performance of the other protocol. If the perfor-
mance of Π is greater than the performance of the other protocol,
we mark it as a Win for Π, otherwise we mark it as a Loss for Π.
The robustness value for Π is calculated by number of games that
it wins against all opponents in all runs divided by the total number
of games that it plays, which is constant for all protocols.
For Aggressiveness we use the same setup as for Robustness ex-
periments, with the difference that the population is so divided that
10% of the peers execute Π while the rest execute another protocol.
Next, we present results of applying the PRA quantiﬁcation over
the design space3 described in Section 4.2.
3We note here that the entire series of simulations for PRA took
around 25 hours on a 50-node dual-core cluster.
187Figure 2: Scatter plot of all 3270 protocols in the design space with
Robustness against Performance. The results presented here are
a synthesis of over 107 million individual simulation runs. His-
tograms are also shown.
4.4 Results and Discussion
Figure 2 shows all the 3270 protocols actualized in Section 4.2,
with their normalized Robustness and Performance values. Given
the methodology of conducting the PRA quantiﬁcation as described
in Section 4.3.2, this ﬁgure represents a synthesis of 107 million
individual runs. For performance, each point represents the aver-
age normalized performance of a protocol Π, over 100 runs. The
robustness values are calculated as described in Section 4.3. The
maximum variance in the runs for each protocol’s performance and
robustness was as low as 0.0014 and 0.0206, respectively.
Performance. We shall start by looking at different regions of Fig-
ure 2. It can be seen that numerous protocols have both very low
performance and robustness in the range [0,0.2] (as can be seen
from the large histogram bars in the bottom left hand corner). Upon
inspection we discover that most of them are freeriders, although
different kinds of freeriders. The freeriders with low robustness
usually defect on strangers, while freeriders with low performance
usually defect on their partners. The maximum performance that
such freeriders get is 0.31. This can be seen in the form of two
clusters in Figure 2, where the lower and upper clusters are below
and above 0.4 performance, respectively.
The lower cluster for performance contains all freeriders that do
not reciprocate with their partners. It also contains some freeriders
that defect on strangers. The upper cluster for performance does
not contain any freeriders that defect on their partners but inter-
estingly does contain freeriders who defect on strangers. In fact,
the protocol with the highest performance (of 1), is the one that al-
ways defects on strangers, has the Sort Slowest ranking function,
and maintains one partner. We try to dissect why this particular
protocol performs so highly. By defecting on a stranger, a proto-
col in effect uploads nothing to the stranger. Since, all peers follow
the Sort Slowest ranking function, a peer p1 on downloading noth-
ing from another peer p2, immediately discards its partner p3 and
chooses p2 to be its partner. Peer p3 now ﬁnds itself partner-less.
However, it can also quickly ﬁnd a partner for itself by upload-
ing nothing to another peer. Thus by following this protocol, peers
rarely ﬁnd themselves without a fully occupied partner set and can
always download at full speed.
Thus, counter-intuitively, by maintaining a single partner, by not
uploading anything to strangers and by employing the Sort Slowest
Figure 3: Normalized Performance histograms for different partner
values. Darker squares represent high ‘partner value’ frequency for
a particular Performance interval.
ranking function, a very high performing protocol can be designed.
It is imperative of course in this case that the resource allocation
method should not be Prop Share. This is because Prop Share will
ensure that a peer on getting nothing from another peer, also up-
loads nothing in response. If that happens, the entire population
that follows this protocol will fail to bootstrap.
In Figure 3 we observe that in fact many of the top performing
protocols are those with one partner. In Figure 3, for each perfor-
mance interval, darker squares represent higher relative frequency
of the number of partners. The empty white spaces in Figure 3 re-
ﬂect the empty spaces in the scatter plot and the histogram of the
Performance values in Figure 2. All the top 15 performing proto-
cols maintain one partner each and the overall trend in the top per-
forming protocols shows a low number of partners. In the top hun-
dred performing protocols only 11 maintain more than 2 partners.
It can be seen from Figure 3, starting from the top, till the perfor-
mance interval [0.7,0.8], the frequency of low number of partners
is relatively higher than the frequency of high number of partners.
We analyze these high performing protocols with a low number
of partners more closely now. We have already discussed the fea-
tures of the highest performing protocol, which uses the Sort Slow-
est ranking function. However, not all high performing protocols
with low number of partners have the same features. Many of them
employ the Sort Loyal ranking function. With the Sort Loyal rank-
ing function, it can be conjectured that peers which come to form
cooperative relationships early on, stay committed in their relation-
ships. This stability of relationships increases the performance of
the system, because at no time do peers ﬁnd themselves short of
partners.
Apart from this, many such protocols often also use the When
needed stranger policy. This policy also leads to more committed
partnerships. With the When needed stranger policy, peers only co-
operate with strangers when their set of partners is not full. Thus
once its partner set is full, a peer will not cooperate with strangers.
By not cooperating regularly with strangers, a peer protects itself
from breaking relationships by avoiding temptation. This is be-
cause when a peer p defects against a stranger, it does not get back
anything in response from the stranger. In this way peer p does not
discover how much better or worse the stranger is than its current
partners, and thus continues to stick with them.
It could be assumed that in the presence of churn, protocols with
low number of partners will not perform so well. However, we ran
Performance tests for the whole space under churn rates of 0.01 and
0.1 per round, and found that it was still the protocols that employed
00.20.40.60.8100.20.40.60.81RobustnessPerformanceNumber of partnersPerformance01234567890.910.80.70.60.50.40.30.20.10188Figure 4: Normalized Robustness histograms for different partner
values. Darker squares represent high ‘partner value’ frequency for
a particular Robustness interval.
Figure 6: Robustness values using different resource allocation
methods. Each circle is a unique protocol. Bigger circles repre-
sent better performance.
the most robust protocol in that cluster, these protocols use a combi-
nation of the When needed stranger policy, the Sort Fastest ranking
function and the Prop Share reciprocation function. Figure 5 shows
that only those protocols which use the When needed stranger pol-
icy reach robustness levels greater than 0.99. Similarly, it can be
seen from Figure 7 that protocols which use the Sort Fastest rank-
ing function, are the most robust protocols. Figure 6, shows that
even though the Equal Split resource allocation policy does quite
well, it is the Prop Share policy that manages to get robustness val-
ues greater than 0.99.
Since this is a vital point, as it tells us about the features of proto-
cols that are almost completely robust, we consider these properties
in detail. As discussed previously, the When needed stranger policy
only cooperates with strangers when its set of partners is not full.
The Sort Fastest ranking function, as the name implies, ranks peers
in decreasing order of their speed, and ﬁnally the Prop Share re-
source allocation policy, allocates resources to peers in proportion
to their contribution.
This combination, ﬁrst of all, validates the claims about the ro-
bustness of the Prop Share mechanism [16]. However, it should
be noted that, unlike their proposal, these protocols do not recip-
rocate with everyone. In fact, the most robust protocol maintains
only 7 partners. Secondly, the combination of When needed with
Prop Share is very important to note. In [16] a cryptographic boot-
strapping technique was proposed to avoid exploitation by freerid-
ing strangers. Our results suggest that the combination of the When