ratio is reduced as the trace progresses. Once the algorithms reach
their theoretic grantees (ψ), the false positives are comparable to
these of previous works. In some cases, RHHH and 10-RHHH even
perform slightly better than the alternatives.
4.3 Operation Speed
Figure 5 shows a comparative evaluation of operation speed. Fi-
gure 5a, Figure 5b and Figure 5c show the results of the San Jose
14 trace for 1D byte hierarchy (H = 5), 1D bit hierarchy (H = 33)
and 2D byte hierarchy (H = 25), respectively. Similarly, Figure 5d,
Figure 5e and Figure 5f show results for the Chicago 16 trace on the
same hierarchical domains. Each point is computed for 250M long
packet traces. Clearly, the performance of RHHH and 10-RHHH
is relatively similar for a wide range of ε values and for different
data sets. Existing works depend on H and indeed run considerably
slower for large H values.
Another interesting observation is that the Partial and Full An-
cestry [14] algorithms improve when ε is small. This is because in
that case there are few replacements in their trie based structure,
as is directly evident by their O(H log(N ϵ)) update time, which
is decreasing with ϵ. However, the effect is significantly lessened
when H is large.
RHHH and 10-RHHH achieve speedup for a wide range of ε
values, while 10-RHHH is the fastest algorithm overall. For one
dimensional byte level hierarchies, the achieved speedup is up to
X3.5 for RHHH and up to X10 for 10-RHHH. For one dimensional bit
level hierarchies, the achieved speedup is up to X21 for RHHH and
up to X62 for 10-RHHH. Finally, for 2 dimensional byte hierarchies,
the achieved speedup is up to X20 for RHHH and up to X60 for
10-RHHH. Evaluation on Chicago15 and SanJose13 yielded similar
results, which are omitted due to lack of space.
5 VIRTUAL SWITCH INTEGRATION
This section describes how we extended Open vSwitch (OVS) to
include approximate HHH monitoring capabilities. For complete-
ness, we start with a short overview of OVS and then continue with
our evaluation.
5.1 Open vSwitch Overview
Virtual switching is a key building block in NFV environments, as it
enables interconnecting multiple Virtual Network Functions (VNFs)
in service chains and enables the use of other routing technologies
such as SDN. In practice, virtual switches rely on sophisticated
optimizations to cope with the line rate.
Specifically, we target the DPDK version of OVS that enables the
entire packet processing to be performed in user space. It mitigates
overheads such as interrupts required to move from user space to
Constant Time Updates in Hierarchical Heavy Hitters
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
(a) SanJose14 - 1D Bytes
(b) SanJose14 - 1D Bits
(c) SanJose14 - 2D Bytes
(d) Chicago16 - 1D Bytes
(e) Chicago16 - 1D Bits
(f) Chicago16 - 2D Bytes
Figure 4: False Positive Rate for different stream lengths.
kernel space. In addition, DPDK enables user space packet proces-
sing and provides direct access to NIC buffers without unnecessary
memory copy. The DPDK library received significant engagement
from the NFV industry [1].
The architectural design of OVS is composed of two main com-
ponents: ovs-vswitchd and ovsdb-server. Due to space constraints,
we only describe the vswitchd component. The interested reader is
referred to [39] for additional information. The DPDK-version of
the vswitchd module implements control and data planes in user
space. Network packets ingress the datapath (dpif or dpif-netdev)
either from a physical port connected to the physical NIC or from a
virtual port connected to a remote host (e.g., a VNF). The datapath
then parses the headers and determines the set of actions to be
applied (e.g., forwarding or rewrite a specific header).
5.2 Open vSwitch Evaluation
We examined two integration methods: First, HHH measurement
can be performed as part of the OVS dataplane. That is, OVS up-
dates each packet as part of its processing stage. Second, HHH
measurement can be performed in a separate virtual machine. In
that case, OVS forwards the relevant traffic to the virtual machine.
When RHHH operates with V > H, we only forward the sampled
packets and thus reduce overheads.
5.2.1 OVS Environment Setup
Our evaluation settings consist of two identical HP ProLiant
servers with an Intel Xeon E3-1220v2 processor running at 3.1
Ghz with 8 GB RAM, an Intel 82599ES 10 Gbit/s network card and
CentOS 7.2.1511 with Linux kernel 3.10.0 operating system. The
servers are directly connected through two physical interfaces. We
used Open vSwitch 2.5 with Intel DPDK 2.02, where NIC physical
ports are attached using dpdk ports.
One server is used as traffic generator while the other is used as
Design Under Test (DUT). Placed on the DUT, OVS receives packets
on one network interface and then forwards them to the second
one. Traffic is generated using MoonGen traffic generator [21], and
we generate 1 billion UDP packets but preserve the source and
destination IP as in the original dataset. We also adjust the payload
size to 64 bytes and reach 14.88 million packets per second (Mpps).
5.2.2 OVS Throughput Evaluation
Figure 6 exhibits the throughput of OVS for dataplane implemen-
tations. It includes our own 10-RHHH (with V=10H) and RHHH
(with V=H), as well as MST and Partial Ancestry. Since we only have
10 Gbit/s links, the maximum achievable packet rate is 14.88 Mpps.
As can be seen, 10-RHHH processes 13.8 Mpps, only 4% lower
than unmodified OVS. RHHH achieves 10.6 Mpps, while the fastest
competition is Partial Ancestry that delivers 5.6 Mpps. Note that a
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
R. Ben Basat, G. Einziger, R. Friedman, M.C. Luizelli, and E. Waisbard
(a) SanJose14 - 1D Bytes
(b) SanJose14 - 1D Bits
(c) SanJose14 - 2D Bytes
(d) Chicago16 - 1D Bytes
(e) Chicago16 - 1D Bits
(f) Chicago16 - 2D Bytes
Figure 5: Update speed comparison for different hierarchical structures and workloads
delivers ≈ 8.33 Mpps. Thus, 10-RHHH and RHHH can cope with
the line speed.
In Figure 7, we evaluate the throughput for different V values,
from V = H = 25 (RHHH) to V = 10·H = 250 (10-RHHH). Figure 7a
evaluates the dataplane implementation while Figure 7b evalua-
tes the distributed implementation. In both figures, performance
improves for larger V value. In the distributed implementation,
this speedup means that fewer packets are forwarded to the VM
whereas in the dataplane implementation, it is linked to fewer pro-
cessed packets.
Note that while the distributed implementation is somewhat
slower, it enables the measurement machine to process traffic from
multiple sources.
6 ANALYSIS
This section aims to prove that RHHH solves the(δ, ϵ, θ)−approximate
HHH problem (Definition 3.10) for one and two dimensional hierar-
chies. Toward that end, Section 6.1 proves the accuracy requirement
while Section 6.2 proves coverage. Section 6.3 proves that RHHH
solves the (δ, ϵ, θ)−approximate HHH problem as well as its me-
mory and update complexity.
We model the update procedure of RHHH as a balls and bins
experiment where there are V bins and N balls. Prior to each packet
Figure 6: Throughput of dataplane implementations (ε =
0.001, δ = 0.001, 2D Bytes, Chicago 16).
100 Gbit/s link delivering packets whose average size is 1KB only
Constant Time Updates in Hierarchical Heavy Hitters
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
methods to create confidence intervals. Formally, the dependence
is manifested as:
V1 Xi = N . This means that the number of balls in a certain bin is
determined by the number of balls in all other bins.
Our approach is to approximate the balls and bins experiment
with the corresponding Poisson one. That is, analyze the Poisson
case and derive confidence intervals and then use Lemma 6.2 to
derive a (weaker) result for the original balls and bins case.
Y K1 , ..., Y K
V
variables representing the number of balls in each bin from a set of
balls K. That is: {Y K
i } ∼ Poisson
i } ∼ Poisson
(cid:17) be independent Poisson random
(cid:16) K
(cid:16) K
(cid:17)
We now formally define the corresponding Poisson model. Let
s.t. {Y K
V
V
.
(a) Dataplane implementation
(b) Distributed implementation
Figure 7: Measured throughput in both dataplane and distri-
buted implementations.
arrival, we place the ball in a bin that is selected uniformly at
random. The first H bins contain an HH update action while the
next V − H bins are void. When a ball is assigned to a bin, we either
update the underlying HH algorithm with a prefix obtained from
the packet’s headers or ignore the packet if the bin is void. Our first
goal is to derive confidence intervals around the number of balls in
a bin.
Definition 6.1. We define X K
i
to be the random variable repre-
senting the number of balls from set K in bin i, e.g., K can be all
packets that share a certain prefix, or a combination of multiple
prefixes with a certain characteristic. When the set K contains all
packets, we use the notation Xi.
Random variables representing the number of balls in a bin are
dependent on each other. Therefore, we cannot apply common
Lemma 6.2 (Corollary 5.11, page 103 of [36]). Let E be an event
whose probability is either monotonically increasing or decreasing
with the number of balls. If E has probability p in the Poisson case
then E has probability at most 2p in the exact case.
6.1 Accuracy Analysis
We now tackle the accuracy requirement from Definition 3.10. That
is, for every HHH prefix (p), we need to prove:
Pr(cid:16)(cid:12)(cid:12)(cid:12)fp −(cid:98)fp
(cid:12)(cid:12)(cid:12) ≤ εN
(cid:17) ≥ 1 − δ .
In RHHH, there are two distinct origins of error. Some of the
error comes from fluctuations in the number of balls per bin while
the approximate HH algorithm is another source of error.
We start by quantifying the balls and bins error. Let Y
p
i
be the
Poisson variable corresponding to prefix p. That is, the set p contains
all packets that are generalized by prefix p. Recall that fp is the
number of packets generalized by p and therefore: E(Y
We need to show that with probability 1 − δs, Y
i ) = fp
V .
is within ϵs N
from E(Y
i ). Fortunately, confidence intervals for Poisson variables
are a well studied [38] and we use the method of [40] that is quoted
in Lemma 6.3.
p
i
p
p
Lemma 6.3. Let X be a Poisson random variable, then
Pr(cid:16)|X − E (X)| ≥ Z1−δ
E (X)(cid:17) ≤ δ,
(cid:112)
where Zα is the z value that satisfies ϕ(z) = α and ϕ(z) is the den-
sity function of the normal distribution with mean 0 and standard
deviation of 1.
Lemma 6.3, provides us with a confidence interval for Poisson
variables, and enables us to tackle the main accuracy result.
Theorem 6.4. If N ≥ Z1− δs2
V εs
pH − fp
Proof. We use Lemma 6.3 for δs2 and get:
Pr
≤ δs
2 .
To make this useful, we trivially bind fp ≤ N and get
p − fp
V
Pr(cid:0)(cid:12)(cid:12)Xi
(cid:32)(cid:12)(cid:12)(cid:12)(cid:12)Yi
(cid:32)(cid:12)(cid:12)(cid:12)(cid:12)Yi
−2 then
(cid:12)(cid:12) ≥ εs N(cid:1) ≤ δs .
(cid:33)
(cid:114) fp
(cid:12)(cid:12)(cid:12)(cid:12) ≥ Z1− δs2
(cid:33)
(cid:114)
(cid:12)(cid:12)(cid:12)(cid:12) ≥ Z1− δs2
N
V
V
≤ δs
2 .
Pr
p − fp
V
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
R. Ben Basat, G. Einziger, R. Friedman, M.C. Luizelli, and E. Waisbard
.
However, we require error of the form ϵs ·N
V
0.5
V −0.5
εs NV −1 ≥ Z1− δs2
−1
0.5 ≥ Z1− δs2
0.5
εs
V
−2
N ≥ Z1− δs2
V εs
−2, we have that:
Therefore, when N ≥ Z1− δs2
N
N
.
Pr
(cid:18)(cid:12)(cid:12)(cid:12)(cid:12)Yi
Pr(cid:0)(cid:12)(cid:12)Yi
Pr(cid:0)(cid:12)(cid:12)Xi
V
≤ δs
2 .
(cid:12)(cid:12)(cid:12)(cid:12) ≥ εs N
(cid:19)
(cid:12)(cid:12) ≥ εs N(cid:1) ≤ δs
(cid:12)(cid:12) ≥ εs N(cid:1) ≤ δs .
2 .
V εs
p − fp
V
pV − fp
pV − fp
We multiply by V and get:
Finally, since Y
p
i
balls (fp), we apply Lemma 6.2 to conclude that
is monotonically increasing with the number of
(cid:114) Z1− δs2
V
V εs
(cid:3)
−2. Theorem 6.4
To reduce clutter, we denote ψ (cid:44) Z1− δs2
proves that the desired sample accuracy is achieved once N > ψ.
It is sometimes useful to know what happens when N  εs. It also shows that εs(N)  ψ. Another
application of Corollary 6.5 is that given a measurement interval N ,
we can derive a value for εs that assures correctness. For simplicity,
we continue with the notion of εs.
.
N
Corollary 6.5. εs (N) ≥
The error of approximate HH algorithms is proportional to the
number of updates. Therefore, our next step is to provide a bound
on the number of updates of an arbitrary HH algorithm. Given
such a bound, we configure the algorithm to compensate so that
the accumulated error remains within the guarantee even if the
number of updates is larger than average.
Corollary 6.6. Consider the number of updates for a certain
Pr
(cid:19)
lattice node (Xi ). If N > ψ , then
Xi ≤ N
V
(cid:18)
(cid:17) ≤ δs . This implies that:
(1 + εs)