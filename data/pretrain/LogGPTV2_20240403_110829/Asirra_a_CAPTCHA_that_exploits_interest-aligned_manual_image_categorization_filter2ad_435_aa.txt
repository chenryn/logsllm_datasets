title:Asirra: a CAPTCHA that exploits interest-aligned manual image categorization
author:Jeremy Elson and
John R. Douceur and
Jon Howell and
Jared Saul
Asirra: A CAPTCHA that Exploits
Interest-Aligned Manual Image Categorization
Jeremy Elson, John R. Douceur,
Jon Howell
{jelson,johndo,howell}@microsoft.com
Microsoft Research
Jared Saul
Petﬁnder, Inc.
jared@petﬁnder.com
ABSTRACT
We present Asirra (Figure 1), a CAPTCHA that asks users to iden-
tify cats out of a set of 12 photographs of both cats and dogs. Asirra
is easy for users; user studies indicate it can be solved by humans
99.6% of the time in under 30 seconds. Barring a major advance
in machine vision, we expect computers will have no better than a
1/54,000 chance of solving it. Asirra’s image database is provided
by a novel, mutually beneﬁcial partnership with Petﬁnder.com. In
exchange for the use of their three million images, we display an
“adopt me” link beneath each one, promoting Petﬁnder’s primary
mission of ﬁnding homes for homeless animals. We describe the
design of Asirra, discuss threats to its security, and report early de-
ployment experiences. We also describe two novel algorithms for
amplifying the skill gap between humans and computers that can
be used on many existing CAPTCHAs.
Categories and Subject Descriptors: K.6.5 [Computing Milieux]:
Management of Computing and Information Systems—Security and
Protection; I.2.10 [Computing Methodologies]: Artiﬁcial Intelli-
gence—Vision and Scene Understanding
General Terms: Human Factors, Security
1.
INTRODUCTION
Over the past few years, an increasing number of public web
services have attempted to prevent exploitation by bots and auto-
mated scripts, by requiring a user to solve a Turing-test challenge
(commonly known as a CAPTCHA1 or HIP2) before using the ser-
vice. Because the challenges must be easy to generate but difﬁ-
cult (for non-humans) to solve, all CAPTCHAs rely on some secret
information that is known to the challenger but not to the agent
being challenged. For our purposes, we can divide CAPTCHAs
into two classes depending on the scope of this secret. In Class I
CAPTCHAs, the secret is merely a random number, which is fed
into a publicly known algorithm to yield a challenge, somewhat
analogous to a public-key cryptosystem. Class II CAPTCHAs em-
1“Completely Automated Public Turing test to tell Computers and Humans
Apart.” CAPTCHA is a trademark of Carnegie Mellon University.
2“Human Interaction Proof”
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’07,  October 29–November 2, 2007, Alexandria, VA, USA.
Copyright 2007 ACM 978-1-59593-703-2/07/0010 ...$5.00.
Figure 1: An Asirra challenge. The user selects each of the 12 images
that depict cats. As the mouse is hovered over each thumbnail, a larger
image and “Adopt me” link appear. “Adopt me” ﬁrst invalidates the
challenge, then takes the user to that animal’s page on Petﬁnder.com.
ploy both a secret random input and a secret high-entropy database,
somewhat analogous to a one-time-pad cryptosystem. A critical
problem in building a Class II CAPTCHA is populating the database
with a sufﬁciently large set of classiﬁed, high-entropy entries.
Class I CAPTCHAs have many virtues. They can be concisely
described in a small amount of software code; they have no long-
term secret that requires guarding; and they can generate a prac-
tically unbounded set of unique challenges. On the other hand,
their most common realization—a challenge to recognize distorted
text—evince a disturbingly narrow gap between human and non-
human success rates. Optical character recognition algorithms are
competitive with humans in recognizing distinct characters, which
has led researchers toward increasing the difﬁculty of segmenting
an image into distinct character regions [11]. However, this in-
crease in difﬁculty affects humans as well. Although laboratory
experiments suggest that humans can segment text characters accu-
rately [2], CAPTCHAs deployed on commercial public web sites
continue to use cleanly segmented challenges (e.g., Fig. 2a), some
of which are dialed-down versions (Figs. 2d and 2e) of CAPTCHAs
with difﬁcult segmentation challenges (Fig. 2c). The owners of
commercial web sites have apparently decided that a user’s success
at navigating a CAPTCHA depends not only on whether they are
able to solve the challenge, but also on whether they are willing
366categorized. Although this may seem trivial, it is not a priori clear
why the owner of such a database would be willing to release the
images for use in Turing-test challenges. The answer is that there
can exist—and, in at least one instance, does exist—an alignment of
interests between a database owner and web-service owners wish-
ing to secure their sites. Both parties can beneﬁt from selective,
wide-scale display of categorized images:
the latter for security
and the former for advertising.
We present Asirra3, a CAPTCHA that asks users to categorize
photographs depicting either cats or dogs. An example is shown in
Figure 1. Asirra’s strength comes from an innovative partnership
with Petﬁnder.com [9], the world’s largest web site devoted to ﬁnd-
ing homes for homeless animals. Petﬁnder has a database of over
three million cat and dog images, each of which is categorized with
very high accuracy by human volunteers working in thousands of
animal shelters throughout the United States and Canada. Petﬁnder
has granted ongoing access to its database, which grows by nearly
10,000 images daily, to the Asirra project.
In exchange, Asirra
provides a small “Adopt me” link beneath each photo, promoting
Petﬁnder’s primary mission of exposing adoptable pets to potential
new owners. This partnership is mutually beneﬁcial, and also pro-
duces the dual social beneﬁts of improving computer security and
animal welfare.
This paper describes Asirra and an analysis of its strengths and
weaknesses. We also report our deployment experience, and the
results of two user studies involving 332 test subjects.
Asirra is easy for users; it can be solved by humans 99.6% of the
time in under 30 seconds (Section 6, Table 1). Barring a major ad-
vance in machine vision or compromise of our database, we expect
computers will have no better than a 1/54,000 chance of solving it
(Section 6, Table 2). Anecdotally, users seem to ﬁnd the experience
of using Asirra much more enjoyable than a text-based CAPTCHA
that provides equal security.
The organization of this paper is as follows. In Section 2, we
review related work in more detail. In Section 3, we describe the
design of Asirra. §3.1 describes user experiments we performed
to quantify humans’ performance. §3.2 explores the other side of
the equation—potential attacks on Asirra, and how they can be re-
sisted. We developed two algorithms that can be used to improve
virtually all CAPTCHAs, including those that are text-based; these
improvements are described in Section 4. In Section 5 we describe
our scalable Asirra implementation. Finally, in Section 6, we sum-
marize our contributions and offer conclusions.
Asirra is available free at www.asirra.com.
2. RELATED WORK
Since the concept of a CAPTCHA was widely introduced by von
Ahn in 2000 [14], hundreds of design variations have appeared. By
far, most are text-based: The computer generates a challenge by se-
lecting a sequence of letters, rendering them, distorting the image,
and adding noise. Text CAPTCHAs are popular because they are
simple, small, and easy to design and implement. Challenges as
short as four characters are robust against random guessing; there
are 364 ≈ 1.7 million possible four-character challenges consisting
of case-insensitive letters and digits.
Unfortunately, computers can do far better than guess randomly.
Simard et al. showed that Optical Character Recognition (OCR) can
achieve human-like accuracy, despite distorted letters, as long as
the letters can be segmented reliably [11]. Mori and Malik demon-
strated that von Ahn’s original GIMPY CAPTCHA [13] can be
solved automatically 92% of the time [8].
3“Animal Species Image Recognition for Restricting Access”
Figure 2: A gallery of text CAPTCHAs. Simple text challenges, such
as a (register.com), are still common despite recent defeat by optical
character recognition. Researchers have begun to focus on schemes
that make letter segmentation difﬁcult, as seen in b (Carnegie Mellon
[13]) and c (Microsoft Research [2]). Webmasters, wary of what users
will tolerate, dial back researchers’ noise parameters, seen in d (Mi-
crosoft Hotmail) and e (Yahoo! Mail).
to put forth the effort. Informal discussions with MSN and other
web site owners suggest even relatively simple challenges can drive
away a substantial number of potential customers.
Class II CAPTCHAs have the potential to overcome the main
weaknesses described above. Because they are not restricted to
challenges that can be generated by a low-entropy algorithm, they
can exercise a much broader range of human ability, such as recog-
nizing features of photographic images captured from the physical
world. Such challenges evince a broad gulf between human and
non-human success rates, not only because general machine vision
is a much harder problem than text recognition, but also because
image-based challenges can be made less bothersome to humans
without drastically degrading their efﬁcacy at blocking automatons.
A signiﬁcant issue in building a Class II CAPTCHA is popu-
lating the secret database. Existing approaches take one of two
directions: (a) mining a public database or (b) providing entertain-
ment as an incentive for manual image categorization. Examples
of the ﬁrst group include the seminal work by Chew and Tygar [3],
which used Google Image Search [6]; hotcaptcha [1], which ref-
erences the HotOrNot database [7]; and KittenAuth [16], which
draws images from Wikimedia Commons [17]. A problem with
these approaches is that the public source of categorized images is
small or available to attackers, so a small, ﬁxed amount of effort
spent reconstructing the private database can return the ability to
solve an unbounded number of challenges. The second direction
was pioneered by the ESP-PIX CAPTCHA [13], whose database is
populated as a deliberate side effect of playing the ESP Game [15],
a very clever mechanism for enticing people to label images accu-
rately. Although potentially powerful, it is not yet clear whether
this approach will yield a sufﬁciently large set of categorized im-
ages. Furthermore, many of the images in the current implemen-
tation are rather abstract, which may make the challenge difﬁcult
enough to drive away users.
In this paper, we present a new direction for populating image
databases for Class II CAPTCHAs, namely re-purposing a large,
continually evolving, private database of images that are manually
Consequently, recent text-based CAPTCHAs have focused on
making image segmentation difﬁcult. Figure 2c shows a challenge
designed by Chellapilla et al., who claim the noise confounds known
automatic segmentation techniques [2]. Microsoft’s Hotmail (free
email) deployed it; however, they later selected noise parameters
demonstrated in Figure 2d. Yahoo’s current CAPTCHA, shown
in Figure 2e, seems to have suffered a similar fate. The noise
is not sufﬁcient to make automatic segmentation unreliable. Text
CAPTCHAs seem either too easy to be secure, or too difﬁcult to be
tolerated by users.
2.1 Image Classiﬁcation CAPTCHAs
Text-based CAPTCHAs seem to universally suffer from an un-
fortunate property: Making them hard for computers also makes
them hard for humans. This has led some researchers to use pho-
tographs instead. Because general machine vision is a much harder
problem than character recognition, there are opportunities to ﬁnd
and exploit larger gaps in the capabilities of humans and computers.
Chew and Tygar [3] were among the ﬁrst to describe using la-
belled photographs to generate a CAPTCHA. They generated a
database of labelled images by feeding a list of easily-illustrated
words to Google Image Search [6]. Unfortunately, this technique
does not yield well-classiﬁed results due to Google’s method of in-
ferring photo contents based on surrounding descriptive text. To
use Chew and Tygar’s example, the word pumpkin may refer to ei-
ther a large vegetable or someone’s pet cat Pumpkin. Because of
these errors, they manually cull bad images from their collection.
This is devastating to the security of the scheme. A database small
enough to be manually constructed by researchers is also small
enough to be manually re-constructed by an attacker.
Of course, applying automation to database construction is in-
herently problematic. If a researcher can populate a database by
writing a program to automatically classify images, an attacker can
write an analagous classiﬁer to beat the CAPTCHA.
A novel solution to this problem is described by von Ahn et al.:
They were able to entice humans to manually describe images by
framing the task as a game. Their “ESP Game” awards points to
teams of non-communicating players who can both pick the same
label for a random image, encouraging them to use the most obvi-
ous label [15]. Their PIX CAPTCHA displays four images from
the ESP Game database that have the same label, then challenges
the user to guess the label from a menu of 70 possibilities.
PIX is clever, but has several potential problems. First, its scale
seems insufﬁcient. By solving PIX repeatedly, it is not hard to get
repeated images, making the database easy to reconstruct. In addi-
tion, its menu of 70 choices makes it vulnerable to brute force at-
tacks (though potentially defensible using our token bucket scheme;
see §4.2). Even with a large number of categorized images, it may
be difﬁcult to add a large number of classes. As the number of
classes goes up, so does the number that can be used to describe
describe a set of photos. Finally, PIX photos are sometimes ab-
stract, making it potentially difﬁcult or frustrating as a CAPTCHA.
A fascinating use of a large-scale human-generated database is
the site HotCaptcha.com. HotCaptcha displays nine photographs
of people and asks users to select the three which are “hot.” Its
database comes from HotOrNot.com, a popular web site that in-
vites users to post photos of themselves and rate others’ photos as
“hot” or “not.” HotCaptcha is clever in its use of a pre-existing mo-
tivation for humans to classify photos at a large scale. However,
humans may have difﬁculty solving it because the answers are sub-
jective and culturally relative; beauty has no ground truth. It is also
offensive to many people, making it difﬁcult for serious web sites
to deploy.
Finally, worthy of mention is the similar-seeming KittenAuth
project [16]. Like Asirra, KittenAuth authenticates users by asking
them to identify photos of kittens. However, this is a coincidental
and superﬁcial similarity. KittenAuth is trivial to defeat because it