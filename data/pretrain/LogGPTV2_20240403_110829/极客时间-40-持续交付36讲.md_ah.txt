## 周三经过周一和周二的努力，本周的基本功能均已实现，"黑寡妇"开始对系统实施集成测试，并做一些压力测试。上午测试时，"黑寡妇"发现在某些场景下系统存在较大的延迟，这个问题在上周的版本中并不存在。她判断是本周新引入的功能导致了这个问题，但一下子又很难确定是怎么引起的。于是，"黑寡妇"决定修改 Smart Merge的配置，把嫌疑最大的分支剔除掉后再打包测试。通过这样的方式，最后查出是feature/thor 这个分支引入的问题，她把测试情况详尽地告诉了"雷神"。大半个下午雷神都在查问题，到下午四点钟时，问题终于被"雷神"修复了，他把feature/thor 分支做了push，然后向"黑寡妇"求助，请她合入自己的分支后再帮忙做测试。"黑寡妇"把"雷神"的分支重新加回到 Smart Merge中，并把编译包重新部署到了测试环境。经过测试验证：延时大的问题真的不见了。下班前，"黑寡妇"召集项目组开了个简短的质量会议，大家商量后认为本周计划内的四个开发任务集成后没有大的质量问题，周四可以一起上线。会后，"黑寡妇"看了看本周的四个合并请求，"美国队长"对四个请求意见都是赞成合入master，Sonar检查也都合格，加上自己测下来质量也过关，于是，她果断地接受了四个合并申请。在回家前，master 对应的最新 commit已经顺利地编译、打包后被发到用户验收测试环境，"黑寡妇"对这个环境启动了自动化测试服务。至此，测试加修复 Bug，忙碌了一整天，大家终于可以回家休息了。
## 周四"黑寡妇"一早上班时，首先查看了自动化测试的结果，显示 master分支构建出的包符合质量要求。于是，她又对没有设计自动化测试用例的部分，进行了手工测试，发现几个界面上存在文字描述的问题，随后通知开发做修复。开发在本地分支上修复问题后 push 到GitLab，再次发起合并请求，"黑寡妇"逐个接受了这几个 Fix 的请求。到中午时分，用于上线的产品包终于生成了。等到发布窗口开启时，"黑寡妇"通过公司的发布系统把合格的产品包发布到了线上。观察一段时间，线上运行都正常。对应本次上线，"黑寡妇"及时给 master 打了tag，然后把本周成功发布的消息通知到项目组，并向"钢铁侠"做了汇报。"钢铁侠"看大伙儿忙碌了这么多天，豪爽地请大家喝果汁，并告诉大家他又有几个紧急的用户需求，嘱咐大伙下周继续努力。
## 周五通常在这一天，项目组会一起清理过期的分支，删除本周已合并到 master的分支。而对于下周开发的新分支，项目组约定统一从 master上拉取。另外，利用这一天，项目组也会召开回顾和改进会议，以讨论解决目前的一些已有问题的方案，这些讨论即包含工作流程问题，也包含代码和系统等问题。
## 总结我介绍了由 6人组成的"两个披萨"团队代码管理的实践，通过周一到周五的具体活动，你可以看到采用特性分支开发的团队是如何创建分支、集成分支和删除分支的，希望能对你的日常工作也有所帮助。
## 思考题假设有 A、B、C 三个功能依次被合并到 master 并准备上线，此时发现 A功能有问题，不能上线，而 B 和 C 则必须上线，此时你会采取什么办法来解决？欢迎你给我留言。![](Images/69e5b7a8ed8eecd006aa3ce5f76f78af.png){savepage-src="https://static001.geekbang.org/resource/image/55/0a/55b7b7cb930ca733523be64e3a720d0a.jpg"}
# 08 \| 测试环境要多少？从现实需求说起在整个持续交付生命周期中，测试环境的易用程度会直接影响软件的交付速度，但因为以下两点，它又是最被容易忽略的一环。1.  我们总是把环境理想化，忽略了其管理的难度；2.  我们也很少设立专职的环境管理员，导致环境长期处于混乱状态。通常，我们在项目初期并不会关注测试环境的问题，然而在回顾时却发现在环境问题上浪费的时间非常惊人：硬件资源申请困难，测试环境配置繁琐，测试应用更新困难，基础设施稳定性差，服务调用异常，多项目并行造成互相干扰等等问题。而不管你是开发人员还是测试人员，相信你都或多或少地碰到过这些问题。在接下来的《环境管理》系列文章中，我会和你聊聊构建一整套好的测试环境的关键点以及具体实施方案。今天，我就先跟你说说和测试环境相关的两个问题：1.  测试环境的结构一般是怎样的？2.  什么才是好的测试环境？
## 互联网公司测试环境的结构当公司规模较小时，测试环境的维护相对容易。开发和测试共用一套数据库缓存等基础设施，因为应用数量不多，开发环境可以是单机的，无论是手动或半自动化的更新测试环境的应用，花费的时间都还在可接受范围内。这时，公司环境的结构很简单，分为开发环境，测试环境，生产环境即可。但实际上，我看到的大多数公司的研发过程及配套环境并没有这么简单，一般都会存在5套以上的大环境以及更多的子环境，每个环境的机器数量可能有数十台甚至更多。]{.orange}``{=html}那么为什么会需要这么多套环境呢？我把主要原因概括为了以下两个方面。1.  纵向上看，人员的增多提高了项目的并行度，如果这时还使用一套环境的话，就会发生以下问题：    -   开发同学在 debug 一个困难问题时，发现下游的应用突然就不可用了；    -   测试同学在跑了 10        多分钟测试脚本后，发现应用已经被开发更新掉了。\        这样的体验是让人崩溃的。2.  横向上看，公司的应用架构逐渐转为微服务化，完整的应用数量很容易就达到了几百甚至几千个的量级，建立一套独立而完整的环境变得越来越复杂，往往是研发团队想要构建一套新的环境却构建不出来。所以，[目前互联网公司常见的环境模型一般分为开发环境，功能测试环境，验收测试环境，预发布环境，生产环境这五个大套环境。]{.orange}**第一，开发环境**微服务架构下，单机已经无法完整地运行业务应用，这就需要开发环境内包含一套完整的业务应用依赖以及相关的基础设施，以保证业务开发同学能在本地完成开发测试。**第二，功能测试环境**在开发环境下，每个下游依赖应用都只有一个可用的 stable版本。而在实际的开发过程中，由于项目的并行开发，往往会同时存在多个可依赖的版本。而每个项目组的同学在测试时，都希望测试过程中的关键依赖应用是可以被独占的，版本是固定的，不会被其他项目组干扰。所以，一套独立的功能测试环境就很有必要了。通常，互联网企业会通过中间件的方式分割出一块隔离区域，在功能测试环境中创建多个子环境来解决这个问题。**第三，验收测试环境**验收测试环境和功能测试环境是完全隔离的。当功能测试通过后，你可以在验收测试环境进行最终的验收。它除了可以用作测试之外，还可以用作产品展示。所以，除了测试和开发人员，产品经理也是验收测试环境的主要使用者。**第四，预发布环境**到了预发布阶段，应用已经进入了生产网络，和真实的生产应用共享同一套数据库等基础设施。预发布是正式发布前的最后一次测试，在这个环境中往往可以发现线下环境中发现不了的Bug。这个环境的运维标准等同于生产环境，一般不允许开发人员直接登录机器。根据不同的业务需求和部署策略，不同公司对预发布环境的实现也有所不同：-   一种比较常见的方式是，将金丝雀发布作为预发布，从接入真实流量的集群中挑选一台或一小组机器先进行版本更新，通过手工测试以及自动化测试和监控系统验证，降低新版本发布的风险。-   另一种做法是，独立出一组始终不接入真实流量的机器，调用在预发布环境中形成闭环。相对于第一种方式，第二种方式对生产环境的影响更小，但需要额外的资源和维护成本。**第五，生产环境**生产环境是用户真实使用的环境，对安全性和稳定性的要求最高。
## 什么是好的测试环境？在和你分享什么是好的测试环境前，建议你先思考一下开发环境、功能测试环境、验收测试环境、预发布环境这四种测试环境形成的原因是什么，这样有利于你更好的理解好的测试环境的含义。首先，搭建测试环境的目的是保证最终交付的软件质量，但每套测试环境的用户并不完全一样：1.  开发环境的用户是开发同学；2.  功能测试环境的主要用户是测试同学；3.  验收测试环境的用户是产品经理和测试同学；4.  预发布环境的使用者是测试同学，但收益者却是运维同学。而每种角色对于产品研发流程中的需求也是不同的：1.  开发同学关注研发效率；2.  测试同学关注测试的可靠性；3.  产品经理更关注的是真实的用户体验和产品的完整性；4.  预发布环境的需求其实来自于运维同学，他们需要保证生产环境的稳定性，减少生产环境的变更，所以需要将预发布环境与线下环境完全隔离。如果你是一位测试环境治理工程师，在规划测试环境以及开发和实施工具的时候，最关键的就是要考虑到不同环境的主要用户是谁，环境要做成什么样才能满足用户在研发流程中的需求。当用户不用发愁环境问题时，研发效率也就自然而然地上去了。当然，不论一套环境用户是测试同学还是开发同学，以下几个需求都是必须被做到的。1.  可得性，即在开发一个新项目时，能快速获取构建一个环境需要的机器，基础设施。最好的情况是，能随时可得，随时归还。2.  快速部署，即在搭建新环境时，能以最快的速度构建出一整套完整的环境。测试环境的部署很频繁，在代码提交后，能在很短的时间内构建代码，在环境上更新，就能更早开始测试。3.  独立性，即一个环境在使用过程中，可以不受其他项目测试人员的干扰。4.  稳定性，即不会因为下游服务，基础设施的异常，造成测试中断、等待。5.  高仿真，主要分为两个方面："测试数据真实"，即能在测试环境构建出真实的测试用例；"环境真实"，即基础服务的架构和行为与线上环境保持一致，避免因为环境不一致造成测试结果不一致。但是，毕竟各个环境的用户和使用场景不同，它们的需求也是有差别的。比如，相对于开发环境，验收测试环境对测试数据的仿真性要求会更高，而开发环境的灵活性，决定了不会过于严格的维护测试数据的真实性。所以，如何评价一个好的测试环境，就是看它是否最终满足了核心使用者的需求。