the two attacks requires future work. Moreover, in our attack
simulations, we assume the adversary needs at least 10ms
to listen, process and attack, by referring to the current
parameters of hardware. The shorter delay may be achieved
by the future FPGA, and we need to further counteract it, such
as by exploring the potential of using shorter coding signals.
VII. RELATED WORK
Biometrics utilized for mobile devices can be classiﬁed into
two categories. Physiological biometrics are extracted from
static body traits, such as face, ﬁngerprint and iris. Behavioral
biometrics are a relatively new type of biometrics, which refer
to the inherent dynamic behavioral patterns of human motions,
such as gaits [37], voices [38], keystroke dynamics [39], and
ﬁnger gestures [40]. However, due to the advanced mobile
recording techniques (e.g., visual and acoustic), 3D printing
and robotics, the physiological and behavioral biometrics are
TABLE IV: Performance under daily noises and dedicated ultrasonic interference.
Noise Type
(Full-band SPL)
Ultrasound SPL
Ch.0
Ch.1
Ch.2
Ch.3
Ch.4
Ch.5
Ch.6
Ch.7
Ch.8
Ch.9
Average
4-digit PCR Code
6-digit PCR Code
Ofﬁce
(40 dB)
10 dB
0.920
0.962
0.944
0.931
0.958
0.929
0.973
0.932
0.961
0.957
0.947
0.979
1
Parking Lot
(55 dB)
15 dB
0.920
0.959
0.940
0.928
0.953
0.929
0.973
0.929
0.957
0.953
0.944
0.975
1
AC
(60 dB)
17 dB
0.920
0.959
0.938
0.927
0.951
0.927
0.971
0.928
0.955
0.950
0.943
0.973
1
Conversation
(65 dB)
22 dB
0.920
0.952
0.935
0.926
0.948
0.925
0.970
0.924
0.952
0.945
0.940
0.971
1
In Car
(70 dB)
25 dB
0.917
0.950
0.934
0.923
0.944
0.924
0.968
0.922
0.950
0.943
0.938
0.965
1
Train Station
(75 dB)
29 dB
0.914
0.948
0.932
0.921
0.940
0.922
0.965
0.920
0.945
0.941
0.935
0.962
1
Dedicated Ultrasonic Noise
50 dB
30 dB
0.838
0.916
0.872
0.951
0.851
0.934
0.925
0.847
0.869
0.940
0.842
0.921
0.891
0.962
0.858
0.925
0.881
0.947
0.939
0.853
0.860
0.936
0.891
0.962
0.932
40 dB
0.908
0.944
0.927
0.912
0.932
0.915
0.955
0.918
0.942
0.930
0.928
0.954
0.989
1
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:04 UTC from IEEE Xplore.  Restrictions apply. 
121045
both under a high risk to be obtained by an adversary [4], [41],
[42], [43]. Furthermore, the biometrics’ static nature makes
them easy to be reused by an adversary for replay attacks.
To improve biometric security, some studies focus on multi-
factor authentication, which combines multiple biometric and
knowledge factors to achieve enhanced security. For example,
the user’s face, teeth and voice can be veriﬁed visually and
acoustically for a fused decision [44], [45], [46], [47]. Safe
et al. propose to display a secret icon on the screen during
the face recognition and verify the eye gaze direction as a
second factor [48]. Ometov et al. propose to combine the
user’s biometrics such as voice and face with a PIN entry
for authentication [49]. But adding additional factors requires
multiple entries from the user, which scariﬁes the usabil-
ity. Some more advanced multi-factor authentication methods
focus on integrating knowledge secrets and biometrics in
one input, such as by extracting keystroke dynamics from a
password entry [50], [51], capturing ﬁnger gesture behaviors
from a signature [52], [53] or obtaining vibration signatures
from the user’s secret input on a solid surface [36]. But all
these methods still reuse the same biometric data for every
authentication session, which is vulnerable to replay attacks.
There is active research on liveness detection to defend
against replay attacks during face and voice authentications.
Fathy et al. propose a method, which asks the user to show
some motions during the face recognition and leverages the
video frames to verify a dynamic face [54]. Chen et al. [12]
ask the user to move the camera around the head to construct
a 3D face for authentication, and the liveness detection is
based on the consistency between the camera and the motion
sensor data. Chen et al. [55] detect the magnetic ﬁelds emitted
by machine speakers to prevent non-live human sounds from
attacking voice authentications. VoiceLive [56] and VoiceGes-
ture [57] derive the vocal tract movements and articulatory
gestures from human speech sounds to make sure the voice is
live. But these methods either require the user’s participation
to prove the liveness or are subject to additional overheads.
They are still unable to prevent the biometric data replay.
Challenge-response protocols are designed to prevent replay
attacks [58]. The initial success of using the handshake proto-
col to verify humans is based on behavioral biometrics. When
the user responds to a challenge (e.g, a task or a game), the
inherent motion behaviors are veriﬁed. For example, Mohamed
et al. design a game challenge for users to select from a
number of icons the preset secret ones. Both the selected
icons and the drag-and-drop behaviors are veriﬁed as a re-
sponse [13]. Sluganovic et al. propose to randomly show a dot
on the screen as the challenge and capture the user’s reﬂexive
eye movements as the response [14]. However, these methods
require cognitive and behavioral activities from the user during
authentication, which is intrusive and demands a long response
time. Moreover, the great variability caused by behavioral
inconsistency leads to high false rejection rates. The recent
work Velody [19] utilizes a vibration motor and receiver to
collect a large number of vibration responses from the user for
authentication, and every used response is disposed of. But this
method requires additional hardware and is thus hard to deploy
on most handheld devices. Moreover, the system demands
high efforts to train and reﬁll a biometric pool periodically
to support daily usage. Differently, PCR-Auth unobtrusively
veriﬁes the user’s PCR with most handheld devices. It creates
a huge biometric response universe at a minimum overhead
and saves the trouble of biometric pool maintenance. The
performance comparison with related work is in Table V.
VIII. CONCLUSION
In this work, we propose a challenge-response user authen-
tication system, PCR-Auth, based on the novel palm contact
response. It is associated with the user’s gripping hand bio-
metric and can be extracted by narrow-band ultrasonic pulses
unobtrusively, when the user holds a handheld device. The
proposed system is designed to verify the user by examining
both the biometric and the coding sequence. In particular, we
devise a biometric encoding technique, which uses acoustic
signals to encode the biometric into biometric codes to re-
spond to the current authentication challenge. The biomet-
ric encoding generates a large biometric response universe
to support massive CR authentication requests and prevent
replay attacks. Furthermore, we develop a deep learning-based
algorithm to decode the biometric code and investigate new
attacks by assuming that the adversary is able to break the
coding sequence, replay the biometric data, or replicate both,
respectively. Extensive experiments show that a 6-digit PCR
achieves a 97% accuracy to distinguish users and reject both
replay and synthesis attacks with 100% accuracy.
Acknowledgments. This work was partially supported by
LEQSF(2020-23)-RD-A-11. We would like to also thank our
anonymous reviewers for helping us improve the paper.
TABLE V: Comparison with related studies.
Work
Protocol
Modality
LivDet [7]
Erdogmus et al. [4]
Menotti et al. [6]
BiLock
BreathPrint
Taprint
VibWrite [36]
Physiological
Behavioral
Eye Movement [14]
Velody [19]
PCR-Auth
Challenge-response
FingerPrint
FaceID
Iris
Tooth click sound
Breathing gesture-induced sound
Tapping-induced vibration
Vibration response of dynamic gestures
Reﬂective eye movement
Vibration response
Vibration response of palm contact
FPR
User
Impersonation
Replay
Synthesis
Participation
Dedicated
Hardware
1.07%
1.1%
0.16%
1.5%
2%
1.74%
2%
6.3%
5.8%
2.9%
N.A.
N.A.
N.A.
5.6%
2%
N.A.
N.A.
0.06%
0%
0%
N.A.
N.A.
N.A.
N.A.
N.A.
N.A.
N.A.
N.A.
0%
0%
Low
Medium
Medium
High
High
High
High
Medium
Medium
Low
Yes
Yes
Yes
Yes
Yes
Yes