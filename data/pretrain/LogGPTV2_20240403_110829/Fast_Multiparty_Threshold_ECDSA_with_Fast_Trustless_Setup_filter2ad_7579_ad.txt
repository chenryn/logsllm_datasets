ˆKGD1 so that the committed value revealed is now ˆy1 =
We now prove a few lemmas about this simulation.
Lemma 1. The simulation terminates in expected polynomial time and is indistinguishable from
the real protocol.
Proof (Proof of Lemma 1). Since A is running on a good random tape, we know that the probability
over the random choices of F, that A will correctly decommit is at least 
2λc . Therefore we
will need to repeat the loop only a polynomial number of times in expectation.
2 > 1
The only diﬀerences between the real and the simulated views is that P1 runs a simulated
Feldman-VSS with free term in the exponent ˆy1 for which it does not know the discrete log. But
we have shown in Section 2.6 that this simulation is identically distributed from the real Feldman-
VSS. So the simulation of the protocol is perfect.
Lemma 2. For a polynomially large fraction of inputs y, the simulation terminates with output y
except with negligible probability.
Proof (Proof of Lemma 2). First we prove that if the simulation terminates on an output which is
not ⊥, then it terminates with output y except with negligible probability. This is a consequence of
the non-malleability property of the commitment scheme. Indeed, if A correctly decommits KGCi
twice it must do so with the same string, no matter what P1 decommits too (except with negligible
probability)6. Therefore ˆyi = yi for i > 1 and therefore ˆy = y.
Then we prove that this happens for a polynomially large fractions of input y. Let yA =(cid:81)n
i=2 yi,
i.e.the contribution of the adversary to the output of the protocol. Note that because of non-
malleability this value is determined and known to F by the time it rewinds the adversary. At that
point F rewinds the adversary and chooses ˆy1 = yy−1A . Since y is uniformly distributed, we have
that ˆy1 is also uniformly distributed. Because A is running on a good random tape we know that
2λc fraction of ˆy1 for which A will correctly decommit. Since there is
at this point there is an 
a 1-to-1 correspondence between y and ˆy1 we can conclude that for a 
2λc fraction of the input
y the protocol will successfully terminate.
2 > 1
2 > 1
6 This property is actually referred to as independence. This is introduced in [20] as a stronger version of
non-malleability and then proven equivalent to non-malleability in [4]).
14
Rosario Gennaro and Steven Goldfeder
4.6 Signature generation simulation
After the key generation is over, F must handle the signature queries issued by the adversary A.
When A requests to sign a message m, our forger F will engage in a simulation of the threshold
signature protocol. During this simulation F will have access to a signing oracle that produces
DSA signatures under the public key y issued earlier to F.
Semi-Correct Executions. Let k be such that R = gk−1
and let ˜k be the value deﬁned by the
inputs of the players in the MtA and MtAwc protocols. More speciﬁcally if ci is the encryption sent
by player Pi in the ﬁrst round of those protocols, then deﬁne ˜ki = Deci(ci) and ˜k =(cid:80)
˜ki.
i
We say that a protocol execution is semi-correct if in step (4) it holds that k = ˜k. Note that this
condition is well deﬁned since the values k, ˜k are uniquely determined by step (4). It is however
not feasible to decide if an execution is semi-correct or not.
Note that an execution is not semi-correct if the adversary “messes up” the computation of R
by revealing wrong shares in the computation of δ.
Bird-Eye View of Simulation. First we note that for semi-correct executions the adversary,
after Step 4 can already detect if the value Rs1 which will be broadcast in Step (5) by the good
player is correct or not. In fact by this point the adversary has si for i > 1 and for a “candidate”
Rs1 can check if
(cid:89)
Rsi = Rs = gmyr
i
Moreover in such executions when we arrive to step (5A) the simulator will be able to “extract”
the value s1 for the good player, which will allow the simulation to terminate successfully.
Second, we show that a simulation that is not semi-correct will fail at step (5D) with high
probability since the value U1 contributed by the good player is indistinguishable from random.
This allows us to simulate Phase (5) by simply using a random ˜s1 for P1.
The ﬁnal question is how do we detect if an execution is semi-correct or not. Here we use an
idea from [27]: the forging simulator will guess which one (if any) of the Q signature queries result
in an execution which is not semi-correct. Since this execution will be an aborting execution, the
simulation will stop there. With probability 1/(Q + 1) the guess will be correct and the simulation
will succeed, and the forger will be able to produce a forgery.
We now proceed with the details.
4.7 Semi-correct executions
We now present a simulation that works for a semi-correct execution.
the “public key” of P1, W1 = gw1 from the simulation of the key generation protocol.
We point out that F does not know the secret values associated with P1: its correct share w1
of the secret key, and the secret key of its public key E1. The latter is necessary in order to reduce
unforgeability to the semantic security of the encryption scheme.
However F knows the secret keys of all the other players, and their shares wj. It also knows
In the following simulation F aborts whenever the protocol is supposed to abort, i.e. if the
adversary (i) refuses to decommit in steps 4, 5B or 5D or (ii) fails the ZK proof in Step 2 or 5 or
(iii) the signature (r, s) does not verify.
– Phase 1 All the players execute the protocol by broadcasting Ci (F runs the protocol correctly
for P1).
– Phase 2
• All the players execute the MtA protocol for k and γ. F runs the protocol correctly for P1
but it cannot decrypt the share α1j during the execution of the protocol with Pj on input
k1, γj, so F sets αij to a random value in Zq
Fast Multiparty Threshold ECDSA with Fast Trustless Setup
15
• All the players execute the MtAwc protocol for k and x. Here F simulates P1 according to
the simulation described in Section 3. Moreover it extracts Pj resulting share ν1j from his
ZK proof.
In the protocol with Pj on input kj, w1, F does not know w1 so it just sends a random µj1
to Pj
Note that at this point F knows σi for the bad players. Indeed
(cid:88)
(cid:88)
σi = kiwi +
µij +
νji
– Phase 3 All the players execute the protocol by revealing δi. Let δ = (cid:80)
and F knows all the values on the right end side of the equation.
i δi (F runs the
protocol correctly for P1 with the random shares it chose in step 2 – therefore F is eﬀectively
broadcasting a random δ1).
j
j
– Phase 4
gms−1
1. Each player reveals Di to decommit to Γi
2. F queries its signature oracle and receives a signature (r, s) on m. It computes R =
yrs−1 ∈ G (note that H(cid:48)(R) = r ∈ Zq).
i>1 Γ −1
Rδ(cid:81)
F can compute the correct s1 held by P1 as s −(cid:80)
3. F rewinds A to the decommitment step, and for P1 changes the decommitment to ˆΓ1 =
Note that at this point F knows the value si held by the bad players since si = kim + σir. So
(cid:81)
i>1 Γi]δ−1
– Phase 5 All players execute all the steps in this phase. F uses s1 as the share for P1
. Note that [ ˆΓ1
i>1 si.
= R
i
We prove the following Lemma about the simulation.
Lemma 3. Assuming that
– The Strong RSA Assumption holds
– KG, Com, Ver, Equiv is a non-malleable equivocable commitment;
then the simulation has the following properties
– on input m it outputs a valid signature (r, s) or aborts.
– it is computationally indistinguishable from a semi-correct real execution
where k =(cid:80)
Proof (Proof of Lemma 3).
The only diﬀerences between the real and the simulated views is the following: In the MtA
protocol the values ci = Ei(ki) are published and in the real protocol R = gk−1
i ki,
while in the simulated execution R = gˆk−1
for the ˆk chosen by the signature oracle. This is easily
seen to be computationally indistinguishable under the semantic security of Paillier’s encryption.
Indeed, when F rewinds the adversary to ”ﬁx” the value of R, it implicitly changes the value
k1 that F contributes for P1 to R. If R = gˆk−1
i>1 ki. Note that Rˆk1 is
ki = g, therefore Rˆk1 = gR−k2. So to distinguish between the real execution
known since R
and the simulated one the adversary should detect if the ciphertext sent by F for P1 in the ﬁrst
round of the MtAwc protocol contains a random k1 or the random ˆk1 determined as logR(gR−k2 )
which is infeasible under the semantic security of Paillier’s encryption (given that all values are
proven to be “small” and no wraparound modN happens).
, let (implicitly) ˆk1 = ˆk −(cid:80)
ˆk1+(cid:80)
i>1
Note that we are simulating a semi-correct execution with an execution which is not semi-
correct, but that’s OK because the two are indistinguishable.
However, because the real execution is a semi-correct one, we know that the correct shares of
k for the adversary are the ki that the simulator knows. Therefore the value s1 computed by the
simulator is consistent with a correct share for P1 for a valid signature (r, s), which makes Phase
5 indistinguishable from the real execution to the adversary.
16
Rosario Gennaro and Steven Goldfeder
Let (r, s) be the signature that F receives by its signature oracle in Step 2 of Phase 4. This
is a valid signature for m. We prove that if the protocol terminates, it does so with output (r, s).
This is a consequence of the non-malleability property of the commitment scheme. Indeed, if the
adversary correctly decommits, its openings must be the same except with negligible probability.
4.8 Simulation of a non semi-correct execution
We now show how to simulate the last execution for a non semi-correct execution when ˜k (cid:54)= k.
Details follow.
aborting at Phase 4 if the adversary fails to decommit).
– Phases 1 to 3 The simulator runs the semi-correct simulation through Phase 3 (including
– Phase 4 F does not rewind the adversary to “ﬁx” the value of R, but runs the protocol normally
– Phase (5) F chooses ˜s1 ∈R Zq and runs Phase 5 with this value instead of s1, and choosing U1
for P1.
as a random group element.
Before we prove that this simulation is indistinguishable for non-semi-correct executions let us
give an intuition. Note that the only diﬀerence with the previous simulation is that here F uses
a random share ˜s1 instead of the s1 that it computed in the other simulation. The reason is that
the value s1 computed in the previous simulation is only guaranteed to be the “correct” share of s
if the execution is semi-correct. If the adversary shares ki don’t match anymore the value R then
s1 is incorrect, and therefore F chooses a random value instead. In turns this causes U1 to be
uniformly distributed and the check in step (5D) to fail.
The main point of the proof is that if the execution is not semi-correct then the value U1 is
(given the view of the adversary) computationally indistinguishable from uniform even in the real
execution (under the DDH assumption).
Our proof reﬂects the above intuition. First we prove that a real non-semi-correct execution
is indistinguishable from one in which P1 outputs a random U1. And then we prove that this is
indistinguishable from the simulation above, where the good player uses a random ˜s1 instead of
the correct s1.
Lemma 4. Assuming that
– KG, Com, Ver, Equiv is a non-malleable equivocable commitment;
– the DDH Assumptions holds
then the simulation is computationally indistinguishable from a non-semi-correct real execution
Proof (Proof of Lemma 4).
We construct three games between the simulator (running P1) and the adversary (running all
the other players). In G0 the simulator will just run the real protocol. In G1 the simulator will
follow the real protocol but will choose U1 as a random group element. In G2 the simulator will
run the above simulation.
Indistinguishability of G0 and G1 Let us assume that there is an adversary A0 that can distinguish
between G0 and G1. We show how this contradicts the DDH Assumption.
the decommitment of P1 to y1 = b(cid:81)
Let ˜A = ga, ˜B = gb, ˜C = gc be the DDH challenge where c = ab or random in Zq.
The distinguisher F0 runs A0, simulating the key generation phase so that y = ˜B = gb. It does
that by rewinding the adversary at the end of Phase 2 of the key generation protocol and changing
F(cid:48) also extracts the values xi from the adversary. Note that at this point y = ˜B and F0 knows
xi, but not b and therefore not x1. Moreover F0 extracts the secret key for the encryption keys Ei
for i > 1. In this simulation F0 also knows the secret key matching E1 (since we are not making
any reduction to the security of the encryption scheme).
i>1 y−1
.
i
Fast Multiparty Threshold ECDSA with Fast Trustless Setup
17
here we assume that we have a (t(cid:48), t(cid:48)) sharing of the secret key. So b =(cid:80)
wi for i > 1 but not knowing w1. Denote with wA =(cid:80)
since k = ((cid:80)
Then F0 runs the signature generation protocol for a not-semi-correct execution. Remember
i∈S wi with F(cid:48) knowing
i>1 wi (which is known to F0) and therefore
w1 = b − wA.
F0 runs the protocol normally for Phases 1,2,3,4. It extracts the value γi for i > 1 from the
adversary (and he knows γ1 since he ran P1 normally). Therefore F0 knows k such that R = gk−1
i γi)δ−1. It also knows k1 since it was chosen normally according to the protocol.