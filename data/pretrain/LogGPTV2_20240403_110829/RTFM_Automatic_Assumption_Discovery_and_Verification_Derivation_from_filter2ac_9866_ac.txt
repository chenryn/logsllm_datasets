we convert the dependency tree to a CD tree, which models the
relations between different verification code snippets (VCSes) as
derived from the grammatical relations between their descriptions.
Specifically, each leaf node of the CD tree is the entity representing
variables or constants, and other nodes are CDs. Two CDs are con-
nected if there exists a relation between them in the dependency
tree. For example, Figure 4 (d) shows the CD tree of the IA â€œthe
length of data in EVP_param_2 must be divisible by 4â€ (in Figure 4
(a)); here the CDs â€œthe length of â€ and â€œbe divisible byâ€ are linked
together since â€œlengthâ€ and â€œdivisibleâ€ are also connected in the
dependency tree (Figure 4 (a)). Also importantly, the directed edges
in the CD tree mostly inherit the orientations of those in the depen-
dency tree, with a CD related to a subtree. The exception is caused
by the temporal CD, which specifies the sequential order between
CDs (e.g., â€œafterâ€, â€œbeforeâ€): in this case, the directed edge always
starts from the temporal CD.
Over the CD tree, Advance generates the full verification code
for the IA by traversing the tree, as presented by Algorithm 1 in
Appendix. Specifically, our approach starts from the left-most leaf
of the tree to retrieve its parent and siblings (Line 2-4), where
the leaf nodes here are the parameters for the VCS template of
their CD parent (Line 5-6). For example, in Figure 4 (c), the CD
â€œthe length of â€ has a leaf EVP_param_2; using the VCS template in
Figure 4 (b), the generated VCS is array_length(EVP_param_2)
(Step 1 ). This process continues until there is only the root node
left in the CD tree. All the VCSes created (through parameterization)
and connected during the traversal then form the IAâ€™s verification
code. Again let us look at the example in Figure 4 (d): the VC
produced is array_length(EVP_param_2)% 4 = 0 (Step 2 ). In this
way, all pre-/post-/context conditions can be correctly represented
in the VC according to the description in the IA, and are ready for
the verification tool to use to discover API misuses.
4 Implementation
We implemented a prototype of Advance in our research on top
of a set of tools, as described in Table 3 in Appendix. Below we
elaborate on the implementation details of each component.
IA discovery. We trained the Word2vec class of gensim [56] for
100 iterations to build up our own word2vec model, whose word
vector was set to 300 (the commonly used value) and window size
(maximum distance between the current and predicted word within
a sentence) to 3. The training corpus of our Word2vec model was
crawled from the Linux manual pages of library functions [17]
(5.8MB with 40,000 sentences).
We utilized the default parameters of the word part of HAN [51]
to train the S-HAN model, except for a customized setting for
word embedding (dimension 300, batch size 16, and epoch 2). The
backbone of the S-HAN model consists of a bidirectional layer
(50 layers, regularization of L2 with a regularization factor of 1e-
8), a dense layer (100 layers, ReLU activation function, the same
regularization as the bidirectional layer), and an attention layer (1
layer, normal distribution initialization, supporting masking, and no
divisiblethelengthdataoftheinEVP_DecodeBlock_param_2mustbeby4depdepprepdetpreppobjnsubjcopauxprep43lengthbebetween1and32bytesprepofSSL_has_matching_session_id_param_3pobjthedetnsubjcopamodnum12(a) Two example dependency trees in OpenSSL document(d) The CD tree corresponding to the right IA in (a)be divisible bythe length of4array_length(EVP_param_2)% 4 = 0(c) Generating the final verification code of CD tree in (d)be divisible by4array_length(EVP_param_2)2the length of the data in EVP_DecodeBlock_param_2must be divisible by 4.the length of the SSL_has_matching_session_id_param_3 is between 1 and 32 bytes.pobjpobjdep1CDVCSargv1 be between argv2 and argv3 bytesargv1 in [argv2, argv3]the length of argvarray_length(argv)argv1 be divisible by argv2argv1% argv2 = 0(b) VCSesfor CDsEVP_param_2*(Abbreviated as EVP_param_2)regularization). Also, the categorical cross-entropy loss and Adam
optimizer with learning rate 0.001 were used in the model training.
IA dereference. Since the traditional references are in the forms
of pronouns, we combine several tools of anaphora resolution to-
gether, including NeuralCoref [29], AllenNLP [26] and Stanford-
CoreNLP [38]. As the accuracy of the tools is not high (e.g., 58%
for Winograd Schema Challenge), we accept the resolution results
only when the three tools come to the same result. In the process of
dereferencing implicit API and parameter, we perform the shallow
parsing using StanfordCoreNLP [38] to tag the POS of words in
IAs. The threshold of ğ‘ ğ‘–ğ‘š is set to the similarity at 10% of the all
the match result, which gives the highest accuracy according to
our evaluation. We select the shorter one among the noun phrase
and the API parameter name or type and then split them into char-
acters. The split characters are joined with â€œ.*â€ to form the regular
expression. Then the regular expression is used to match to the
longer one to decide whether a noun phrase is a abbreviation of
expansion of the API parameter names or types.
Verification Code Generation. In our implementation, we uti-
lized CodeQL [4], a popular code analysis engine capable of per-
forming information-flow analysis, as a verification tool.
In the process of building the initial CD dataset, a CD may not be
mined out even if it is commonly used. For example, the CD â€œshould
be releasedâ€ and the CD â€œshould be freedâ€ express the same meaning,
but use different words â€œfreedâ€ and â€œreleasedâ€. When Advance mines
the most frequently used sub-tree, they are viewed as different
CDs and may not be viewed as â€œfrequentlyâ€ used. To handle this
problem, we automatically build a dictionary of synonyms using
our trained Word2vec model and choose the most frequent word
as the representative word for each synonym group. When a word
in an IA appears in the dictionary, we replace the word with the
representative word before mining. In this way, the CDs with the
same meaning could be mined out.
Also, we view the subtree appearing more than 3 times (i.e., the
parameter â€œminimum-supportâ€ equals 3/(the total number of IAs))
as the CD. We mine the CDs from the two libraries (i.e., OpenSSL
and SQLite). In the evaluation, we find the mined CD can cover
75% of the CDs in the documents of other libraries. Details of the
analysis are shown in Section 5.2.
5 Evaluation
In this section, we describe our evaluation on Advance, including
the effectiveness of both its end-to-end operation and individual
components, as well as its run time performance. After that, we com-
pared Advance with static API misuse detectors [30, 52], dynamic
fuzzer [2] and other IA discovery and VC generation approaches,
before presenting an empirical analysis on the detected API misuses
and a case study.
5.1 Experiment Setting
Platform. All our experiments were conducted on one 64-bits
server running Ubuntu 16.04 with 8 cores (Intel(R) Xeon(R) CPU
E5-2620 v4 @ 2.10GHz), 128GB memory and 3TB hard drive and
2GPUs (12GB Nvidia GPU TiTan X) with CUDA 10.0.
Dataset. To evaluate the effectiveness of Advance, we utilized 5
datasets:
ğ·ğ‘‘ğ‘’ ğ‘“
Table 1: Datasets for model training and evaluation.
ğ·ğ‘£ğ‘
Libs
ğ‘ƒğ‘–ğ‘_ğ‘ğ‘‘
163
66
26
57
108
420
ğ‘ƒğ‘–ğ‘_ğ‘›ğ‘
228
123
54
54
336
795
ğ‘ƒğ‘–ğ‘_ğ‘£ğ‘
225
84
36
61
115
521
OpenSSL
SQLite
libpcap
libdbus
libxml2
Total
S
4686
140
100
177
608
1129
ğ·ğ‘–ğ‘ğ‘‘
IA
1305
102
60
127
521
859
Non
3381
38
40
50
87
270
â€¢ Corpora of library documentations (ğ¶ğ‘‘ğ‘œğ‘). We randomly selected
libraries from different categories on the Ubuntu software package
website [20], including cryptography (OpenSSL), database (SQLite),
XML file parser (libxml2), network packet capture (libpcap) and
inter-process communication (libdbus), and parsed their documents
to recover API related information through lxml [16]. Such infor-
mation is organized in the JSON format [API name, API parameter,
API return type and API description]. In total, we collected the infor-
mation from 3,581 APIs.
â€¢ Application dataset (ğ·ğ‘ğ‘ğ‘). For each selected library, we ran â€œapt-
cache rdependsâ€ (a Linux command to manage Linux packages) to
search for all the applications integrating the library on Github,
Gitlab or sourceforage. In this way, we gathered 39 applications (11
for OpenSSL, 8 for SQLite, 4 for libxml2, 11 for libpcap and 5 for
libdbus).
â€¢ Ground-truth API misuse dataset (ğ·ğ‘ğ‘ğ‘–). To evaluate false nega-
tives incurred by Advance, we collected a set of known API misuses
related to the aforementioned five popular libraries as the ground
truth. For this purpose, we manually went through CVEs [18] and
also checked the commit logs of the applications from Github [13],
Gitlab [14], and sourceforge [19], where code patches may be posted,
disclosing API misuses. After manually inspecting 6,257 commit
logs of 39 applications, we found 66 known API misuses in 27 appli-
cations. Among them, 38 misuses and 20 applications are associated
with libxml2, libpcap and libdbus. The information of these misuses
can be found in Table 5 in Appendix.
â€¢ Ground-truth dataset for IA discovery training and evaluation
(ğ·ğ‘–ğ‘ğ‘‘). To generate the training set for S-HAN, we manually anno-
tated 1,305 IAs and 3,881 non-IAs from OpenSSL, which is the largest
document used in our study. We also performed back-translation [25]
to augment the IA dataset using Google translation [15]. Altogether,
we collected 2,601 IAs (1,296 IAs from back-translation) and 3,881
non-IAs for model training and cross-validation.
To understand the effectiveness of IA discovery on the testing
library documentations, we randomly sampled around 10% of sen-
tences (Column â€œSâ€ in Table 1) from the other 4 library documenta-
tions (i.e., SQLite, libxml2, libpcap, libdbus), and annotated them as
IA (Column â€œIAâ€ in Table 1) and non-IA (Column â€œNonâ€ in Table 1)
for model evaluation.
â€¢ Ground-truth dataset for IA dereference evaluation (ğ·ğ‘‘ğ‘’ ğ‘“ ). To evalu-
ate IA dereference and VC generation, we randomly sampled around
10% of the IAs reported by the IA discovery step (Section 3.2), which
were manually confirmed, to manually inspect their IA dereferences.
For this purpose, we annotated 521 IA-VP pairs and 795 IA-NP pairs
as the ground truth for IA-API dereference and IA-parameter deref-
erence (Section 3.3) respectively, as shown in Table 1.
Table 2: Effectiveness of individual components
IA dereference
FNR
0
0.4
0.33
0.33
0.3
0.27
ACC
0.83
0.92
0.89
0.85
0.94
0.89
Parameter
FPR
F1
0.18
0.23
0.5
0.07
0.12
0.5
0.15
0.6
0.06
0.73
0.51
0.12
VC generation
FNR
0
0.29
0
0.14
0
0.09
Recall
0.55
0.54
0.82
0.68
0.84
0.69
FNR
0.45
0.46
0.18
0.32
0.16
0.31
CD-Cov
0.71
0.59
0.77
0.79
0.91
0.75
API
Libs
IA discovery
FPR
F1
0.08
0.92
0.78
0.11
0.12
0.80
0.13
0.78
0.06
0.80
0.82
0.1
FNR
0.09
0.18
0.23
0.16
0.09
0.15
ACC
0.98
0.96
0.83
0.98
0.97
0.94
ACC
0.91
0.87
0.84
0.86
0.94
0.88
FPR
0.02
OpenSSL
0.01
SQLite
0.15
libpcap
0
libdbus
0.01
libxml2
0.04
Average
â€¢ Ground-truth dataset for VC generation evaluation (ğ·ğ‘£ğ‘). To evalu-
ate the effectiveness of VC generation, we utilized the IAs in ğ·ğ‘‘ğ‘’ ğ‘“
and manually recovered their associated CDs. These IA-CD pairs
form ğ·ğ‘£ğ‘ and their number of for each library is shown under
â€œğ‘ƒğ‘–ğ‘_ğ‘ğ‘‘â€ of Table 1.
F1