title:Optimal security hardening using multi-objective optimization on attack
tree models of networks
author:Rinku Dewri and
Nayot Poolsappasit and
Indrajit Ray and
L. Darrell Whitley
Optimal Security Hardening Using Multi-objective
Optimization on Attack Tree Models of Networks
Rinku Dewri, Nayot Poolsappasit, Indrajit Ray and Darrell Whitley
Department of Computer Science
Colorado State University
Fort Collins, CO 80523, USA
{rinku,nayot,indrajit,whitley}@cs.colostate.edu
ABSTRACT
Researchers have previously looked into the problem of de-
termining if a given set of security hardening measures can
eﬀectively make a networked system secure. Many of them
also addressed the problem of minimizing the total cost of
implementing these hardening measures, given costs for in-
dividual measures. However, system administrators are of-
ten faced with a more challenging problem since they have
to work within a ﬁxed budget which may be less than the
minimum cost of system hardening. Their problem is how
to select a subset of security hardening measures so as to
be within the budget and yet minimize the residual damage
to the system caused by not plugging all required security
holes.
In this work, we develop a systematic approach to
solve this problem by formulating it as a multi-objective op-
timization problem on an attack tree model of the system
and then use an evolutionary algorithm to solve it.
Categories and Subject Descriptors
C.2.3 [Computer-Communication Network]: Network
Operations—Network management; C.2.0 [Computer-Co
mmunication Network]: General—Security and protec-
tion
General Terms
Security
Keywords
Security management, Attack trees, Multi-objective opti-
mization
1.
INTRODUCTION
Network-based computer systems form an integral part of
any information technology infrastructure today. The dif-
ferent levels of connectivity between these systems directly
facilitate the circulation of information within an organiza-
tion, thereby reducing invaluable wait time and increasing
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’07, October 29–November 2, 2007, Alexandria, Virginia, USA.
Copyright  2007  ACM  978-1-59593-703-2/07/0010  ...$5.00.
the overall throughput. As an organization’s operational
capacity becomes more and more dependent on networked
computing systems, the need to maintain accessibility to the
resources associated with such systems has become a neces-
sity. Any weakness or vulnerability that could result in the
breakdown of the network has direct consequence on the
amount of yield manageable by the organization. This, in
turn, requires the organization to not only consider the ad-
vantages of utilizing a networked system, but also consider
the costs associated with managing the system.
With cost-eﬀectiveness occurring as a major factor in de-
ciding the extent to which an organization would secure its
network, it is not suﬃcient to detect the presence or absence
of a vulnerability and implement a security measure to rec-
tify it. Further analysis is required to understand the con-
tribution of the vulnerabilities towards any possible damage
to the organization’s assets. Often, vulnerabilities are not
exploited in isolation, but rather used in groups to compro-
mise a system. Similarly, security policies can have a cover-
age for multiple vulnerabilities. Thus, cost-eﬀective security
management requires researchers to evaluate the diﬀerent
scenarios that can lead to the damage of a secured asset,
and then come up with an optimal set of security policies to
defend such assets.
Researchers have proposed building security models for
networked systems using paradigms like attack graphs [1,
11, 15, 18, 20] and attack trees [6, 13, 16, 17], and then
ﬁnding attack paths in these models to determine scenarios
that could lead to damage. However, determining possible
attack paths, although useful, does not help the system ad-
ministrators much. They are more interested in determining
the best possible way of defending their network in terms of
an enumerated set of hardening options [14]. Moreover, the
system administrator has to work within a given set of bud-
get constraints which may preclude her from implementing
all possible hardening measures or even measures that cover
all the weak spots. Thus, the system administrator needs to
ﬁnd a trade-oﬀ between the cost of implementing a subset of
security hardening measures and the damage that can po-
tentially happen to the system if certain weak spots are left
unpatched. In addition, the system administrator may also
want to determine optimal robust solutions. These are sets
of security hardening measures that have the property that
even if some of the measures within a set fail, the system is
still not compromised.
We believe that the problem should be addressed in a
more systematic manner, utilizing the diﬀerent tools of op-
timization at hand. A decision maker would possibly make a
204better choice by successively exploring the diﬀerent levels of
optimization possible, rather than accepting a solution from
an “oﬀ-the-shelf” optimizer. Towards this end, the current
work makes four major contributions. First, we reﬁne and
formalize the notion of attack trees so as to encode the con-
tribution of diﬀerent security conditions leading to system
compromise. Next, we develop a model to quantify the po-
tential damage that can occur in a system from the attacks
modeled by the system attack tree. We also quantify the
security control cost incurred to implement a set of security
hardening measures. Third, we model the system adminis-
trator’s decision problem as three successively reﬁned opti-
mization problems on the attack tree model of the system.
We progressively transform one problem into the next to
cater to more cost-beneﬁt information as may be required
by the decision maker. Last but not the least, we discuss
our thoughts and observations regarding the solutions, in
particular the robust solutions identiﬁed by our optimiza-
tion process, with a belief that such discussion will help the
system administrator decide what methodology to adopt.
The rest of the paper is organized as follows. We discuss
some of the previous works related to determining optimum
security hardening measures in Section 2. Section 3 gives
some background information on multi-objective optimiza-
tion.
In Section 4 we describe a simple network that we
use to illustrate our problem formulation and solution. The
attack tree model formalism and the cost model are pre-
sented in Sections 5 and 6 respectively. The three optimiza-
tion problems and the evolutionary algorithm used to solve
them are presented in Section 7 with results and discussion
following in Section 8. Finally we conclude in Section 9.
2. RELATED WORK
Network vulnerability management has been previously
addressed in a variety of ways. Noel et al. use exploit de-
pendency graphs [14] to compute minimum cost-hardening
measures. Given a set of initial conditions in the graph,
they compute boolean assignments to these conditions, en-
forced by some hardening measure, so as to minimize the
total cost of those measures. As pointed out in their work,
these initial conditions are the only type of network security
conditions under our strict control. Hardening measures ap-
plied to internal nodes can potentially be bypassed by an
attacker by adopting a diﬀerent attack path. Jha et al. [11]
on the other hand do not consider any cost for the hard-
ening measures. Rather, their approach involve ﬁnding the
minimal set of atomic attacks critical for reaching the goal
and then ﬁnding the minimal set of security measures that
cover the minimal set of atomic attacks.
Such analysis is meant for providing solutions that guaran-
tee complete network safety. However, the hardening mea-
sures provided may still not be feasible within the ﬁnan-
cial or other business constraints of an organization. Under
such circumstances, a decision maker must perform a cost-
beneﬁt analysis to understand the trade-oﬀ between hard-
ening costs and network safety. Furthermore, a minimum
cost hardening measure set only means that the root goal
is safe, and some residual damage may still remain in the
network. Owing to these real-world concerns, network vul-
nerability management should not always be considered as
a single-objective optimization problem.
A multi-objective formulation of the problem is presented
by Gupta et al. [10]. They consider a generic set of security
policies capable of covering one or more generic vulnerabili-
ties. A security policy can also introduce possible vulnerabil-
ities, thereby resulting in some residual vulnerabilities even
after the application of security policies. The multi-objective
problem then is to minimize the cost of implementing the
security policies, as well as the weighted residual vulnera-
bilities. However, the authors ﬁnally scalarize the two ob-
jectives into a single objective using relative weights for the
objectives.
3. BACKGROUND ON MULTI-OBJECTIVE
OPTIMIZATION
In real world scenarios, often a problem is formulated to
cater to several criteria or design objectives, and a decision
choice to optimize these objectives is sought for. An op-
timum design problem must then be solved with multiple
objectives and constraints taken into consideration. This
type of decision making problems falls under the broad cat-
egory of multi-criteria, multi-objective, or vector optimiza-
tion problem.
Multi-objective optimization diﬀers from single-objective
ones in the cardinality of the optimal set of solutions. Single-
objective optimization techniques are aimed towards ﬁnding
the global optima. In case of multi-objective optimization,
there is no such concept of a single optimum solution. This
is due to the fact that a solution that optimizes one of the
objectives may not have the desired eﬀect on the others. As
a result, it is not always possible to determine an optimum
that corresponds in the same way to all the objectives un-
der consideration. Decision making under such situations
thus require some domain expertise to choose from multiple
trade-oﬀ solutions depending on the feasibility of implemen-
tation.
Due to the conﬂicting nature of the objective functions,
a simple objective value comparison cannot be performed
to compare two feasible solutions to a multi-objective prob-
lem. Most multi-objective algorithms thus use the concept
of dominance to compare feasible solutions.
Definition 1. Dominance and Pareto-optimal set
In a minimization problem with M objectives, a feasible
solution vector (cid:2)x is said to dominate another feasible solu-
tion vector (cid:2)y if
fi((cid:2)x) ≤ fi((cid:2)y) and
fj ((cid:2)x) < fj((cid:2)y)
1. ∀i ∈ {1, 2, . . . , M}
2. ∃j ∈ {1, 2, . . . , M}
(cid:2)y is then said be dominated by (cid:2)x. If the two conditions do
not hold, (cid:2)x and (cid:2)y are said to be non-dominated w.r.t. each
other. The set of all non-dominated solutions obtained over
the entire feasible region constitutes the Pareto-optimal set.
The surface generated by the Pareto-optimal solutions in the
objective space is called the Pareto-front or Pareto-surface.
For a security optimization problem like ours, concentrat-
ing on the minimization of hardening measure costs and the
network damage, the dominance concept plays a crucial role
in evaluating solutions. A solution which reduces one of the
objectives would most likely increase the other. Dominance
based comparison would identify solutions with such trade-
oﬀ properties in the two objectives.
Evolutionary algorithms for multi-objective optimization
(EMO) have been extensively studied and applied to a wide
spectrum of real-world problems. An EMO works with a
population of trial solutions, trying to converge on to the
Pareto-optimal set by ﬁltering out the infeasible or domi-
nated ones. A number of algorithms have been proposed in
this context [5, 7]. We employ the Non-dominated Sorting
Genetic Algorithm-II (NSGA-II) [8] for the multi-objective
optimization in this study. NSGA-II has gained wide pop-
ularity in the multi-objective optimization community be-
cause of its eﬃciency in terms of the convergence and diver-
sity of solutions obtained.
4. A SIMPLE NETWORK MODEL
To illustrate our methodology, we consider the hypothet-
ical network as shown in Fig. 1. The setup consists of four
hosts. A ﬁrewall is installed with a preset policy to ensure
that only the FTP and SMTP servers are allowed to connect
to the external network. In addition, FTP and SSH are the
only two services an external user can use to communicate
with these servers. We assume that an external user wants
to compromise the Data Server which is located inside the
ﬁrewall. The ﬁrewall has a strong set of policies setup to
protect access to the internal hosts. There are six diﬀerent
attack scenarios possible to achieve the ultimate goal from
a given set of initial vulnerabilities and network topology as
listed in Table 1 and 2.
Figure 1: Example network model.
Host
Vulnerability
CVE#
FTP Server
196.216.0.10
SMTP Server
196.216.0.1
Terminal
196.216.0.3
Data Server
196.216.0.2
Ftp .rhost attack
1999-0547
Ftp Buﬀer overﬂow 2001-0755
Ssh Buﬀer overﬂow 2006-2421
1999-0547
Ftp .rhost attack
2001-0439
LICQ remote-2-user
2002-0004
“at” heap corruption
LICQ remote-2-user