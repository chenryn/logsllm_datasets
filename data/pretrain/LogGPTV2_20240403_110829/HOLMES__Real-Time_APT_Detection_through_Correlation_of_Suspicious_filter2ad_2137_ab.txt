+$"
	
$'(#"

##,
,
,
##, 
+&(
##, 
)#!# 
&
)'&!$!+++
##,'(('("!
)'&!$!+++
##,'(('("! 



 
#(&)'(
,(&#!
&''
Fig. 2. Provenance Graph of the Running Example.
ecutable. Next, the attacker gains control over the Nginx
process by using a reÔ¨Çective self-loading exploit.
‚Ä¢ C&C Communications. The compromised Nginx process
makes a connection (S2) to the C&C server to receive
commands from the attacker.
‚Ä¢ Privilege Escalation. The attacker exploits an existing
vulnerability to escalate the privilege of Nginx to root (U1).
‚Ä¢ Internal Reconnaissance. Next, the attacker issues com-
mands such as whoami (P5) and hostname (P6). These
commands were used by the red team to simulate access
to conÔ¨Ådential/proprietary data. The attacker also reads
usernames and password hashes (F2, F3, F4) and writes
all this information to a temporary Ô¨Åle.
‚Ä¢ ExÔ¨Åltration. Next, the attacker transfers the Ô¨Åle containing
‚Ä¢ Cleanup. In the last step of the attack, the attacker removes
the temporary Ô¨Åle (F5) to clean up any attack remnants.
the gathered information to her/his machine (S3).
This example illustrates many key challenges described below:
Stealthy Attacks. This attack leaves a minimal footprint on
the system. The Ô¨Årst step of the attack, the initial compromise
of the Nginx server, is executed in main memory and does not
leave any visible traces such as downloaded Ô¨Åles. Moreover,
the payload runs within the existing Nginx process. It is very
challenging to detect such stealthy attacks, where attacker
activities blend in seamlessly with normal system operation.
Needle in a haystack. Even a single host can generate tens of
millions of events per day. All but a very tiny fraction of these
‚Äî typically much less than 0.01% ‚Äî correspond to benign
activities. (The top portion of Fig. 2 shows a small subset
of benign activities in the audit log.) It is difÔ¨Åcult to detect
such rare events without a high rate of false alarms. More
importantly, it is very challenging to Ô¨Ålter out these benign
events from the attack summaries presented to analysts.
Real-time detection. We envision HOLMES to be used in
conjunction with a cyber-response system, so it is necessary
to detect and summarize an ongoing campaign in a matter of
seconds. Real-time detection poses additional challenges and
constraints for the techniques used in HOLMES.
To overcome these challenges, note that, despite blending
seamlessly into benign background activity, two factors stand
out regarding the attack. First, the attack steps achieve ca-
pabilities corresponding to some of the APT stages. Second,
the attack activities are connected via information Ô¨Çows. In
the next section, we describe the HOLMES approach based on
these two key observations.
III. APPROACH OVERVIEW
The central insight behind our approach is that even though
the concrete attack steps may vary widely among different
APTs, the high-level APT behavior often conforms to the same
kill-chain introduced in Section I (Figure 1). Our analysis of
hundreds of APT reports from [3] suggests that most APTs
consist of a subset, if not all, of those steps. More importantly,
we make the observation that these steps need to be causally
connected, and this connectedness is a major indication that
an attack is unfolding.
Note that the concrete manifestation of each APT step may
vary, e.g., an initial compromise may be executed as a drive-
by-download or as a spear-phishing attack with a malicious
Ô¨Åle that is executed by a user. Regardless, the APT steps
themselves represent a high-level abstraction of the attacker‚Äôs
intentions, and hence they must manifest themselves even if
the operational tactics used by attackers vary across APTs.
Moreover, information Ô¨Çow or causal relations must neces-
sarily exist between them since the APT steps are logically
dependent on each other, e.g., exÔ¨Åltration is dependent on
internal reconnaissance to gather sensitive data.
The research question, therefore, is whether we can base
our detection on
‚Ä¢ an APT‚Äôs most essential high-level behavioral steps, and
‚Ä¢ the information Ô¨Çow dependencies between these steps.
A major challenge in answering this question is the large
semantic gap between low-level audit data and the very high-
level kill-chain view of attacker‚Äôs goals, intentions, and capa-
bilities.
Bridging the Semantic Gap. To bridge the semantic gap
between low-level system-call view and the high-level kill-
(cid:18)(cid:18)(cid:20)(cid:26)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:10 UTC from IEEE Xplore.  Restrictions apply. 






	

	
 









	
	
	
	


Fig. 3. HOLMES Approach: From Audit Records to High-Level APT Stages
chain view, we build an intermediate layer as shown in
Fig. 3. The mapping to this intermediate layer is based on
MITRE‚Äôs ATT&CK framework [2], which describes close to
200 behavioral patterns deÔ¨Åned as Tactics, Techniques, and
Procedures (TTPs) observed in the wild.
Each TTP deÔ¨Ånes one possible way to realize a particular
high-level capability. For instance, the capability of persistence
in a compromised Linux system can be achieved using 11
distinct TTPs, each of which represents a possible sequence
of lower level actions in the ATT&CK framework, e.g., in-
stallation of a rootkit, modiÔ¨Åcation of boot scripts, and so on.
These lower level actions are closer to the level of abstraction
of audit logs, so it is possible to describe TTPs in terms of
nodes and edges in the provenance graph.
Technical challenges. The main technical challenges in real-
izing the approach summarized in Fig. 3 are:
‚Ä¢ efÔ¨Åcient matching of low-level event streams to TTPs,
‚Ä¢ detecting correlation between attack steps, and
‚Ä¢ reducing false positives.
We solve these challenges through several design innovations.
For efÔ¨Åcient matching, we use a representation of the audit
logs as a directed provenance graph (Section IV) in main
memory, which allows for efÔ¨Åcient matching. This graph also
encodes the information Ô¨Çow dependencies that exist between
system entities (such as processes and Ô¨Åles). TTPs are speciÔ¨Åed
as patterns that leverage these dependencies. For instance, in
order to match a maintain persistence TTP, an information
Ô¨Çow dependency must exist from a process matching an initial
compromise TTP to the maintain persistence TTP.
For detecting correlations between attack steps, we build
a High-level Scenario Graph (HSG) as an abstraction over
the provenance graph. Each node in the HSG represents a
matched TTP, while the edges represent information Ô¨Çow and
causality dependencies among those matched TTPs. An HSG
is illustrated in the middle layer of Fig. 3 by nodes and edges
in boldface. (We refer the reader to Fig. 5 for the HSG of the
running example.) To determine the edges among nodes in the
HSG, use the prerequisite-consequence patterns of among the
TTPs and the APT stages.
To reduce the number of false positives (i.e., HSGs that do
not represent attacks), we use a combination of: (a) learning
benign patterns that may produce false positive TTPs and, (b)
heuristics that assign weights to nodes and paths in the graph
based on their severity, so that the HSGs can be ranked, and
the highest-ranked HSGs presented to the analyst.
In summary, the high-level phases of an APT are opera-
tionalized using a common suite of tactics that can be observed
from audit data. These observations provide evidence that some
malicious activity may be unfolding. The job of HOLMES,
then, is to collect pieces of evidence and infer the correlations
among them and use these correlations to map out the overall
attack campaign.
IV. SYSTEM DESIGN
Like most previous works [12], [18], [34], [39] that rely
on OS audit data, we consider the OS kernel and the auditing
engine as part of the trusted computing base (TCB). In other
words, attacks on the OS kernel, the auditing system and the
logs produced by it are outside the scope of our threat model.
We also assume that the system is benign at the outset, so the
initial attack must originate external to the enterprise, using
means such as remote network access, removable storage, etc.
A. Data Collection and Representation
Our system relies on audit logs retrieved from multiple
hosts that may run different operating systems (OSes). 2 For
Linux, the source of audit data is auditd, while it is dtrace
for BSD and ETW for Windows. This raw audit data is
collected and processed into an OS-neutral format. This is the
input format accepted by HOLMES. This input captures events
relating to principals (users), Ô¨Åles (e.g., operations for I/O, Ô¨Åle
creation, ownership, and permission), memory (e.g., mprotect
and mmap) processes (e.g., creation, and privilege change),
and network connections. Although the default auditing system
incurs nontrivial overheads, recent research has shown that
overheads can be made small [12], [46].
The data is represented as a graph that we call the prove-
nance graph. The general structure of this graph is similar to
that of many previous forensic analysis works [27], [34], [39]:
the nodes of the graph include subjects (processes) and objects
(Ô¨Åles, pipes, sockets) and the edges denote the dependencies
between these entities and are annotated with event names.
There are some important differences as well: our subjects,
as well as objects, are versioned. A new version of a node is
created before adding an incoming edge if this edge changes
the existing dependencies (i.e., the set of ancestor nodes) of the
node. Versioning enables optimizations that can prune away
a large fraction of events in the audit log without changing
2The design of HOLMES makes it possible to take additional inputs such as
events and alerts from a variety of IDS/IPS, but we do not discuss this aspect
of the system further in paper.
(cid:18)(cid:18)(cid:21)(cid:17)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:10 UTC from IEEE Xplore.  Restrictions apply. 
APT Stage
TTP
Event Family
Initial
Compromise(P )
U ntrusted
Read(S, P )
READ
M ake M em
Exec(P, M )
MPROTECT
(Windows),
Events
FileIoRead
read/pread/readv/preadv
(Linux,BSD)
VirtualAlloc (Windows), mpro-
tect (Linux,BSD)
Establish
F oothold(P )
Shell
Exec(F, P )
EXEC
ProcessStart
execve/fexecve (Linux,BSD)
(Windows),
Severity
L
M
M
Prerequisites
S.ip /‚àà {Trusted IP Addresses}
$PROT EXEC$ ‚àà M.f lags
‚àß ‚àÉ U ntrusted Read(?, P
path f actor(P
F.path ‚àà {Command Line Utilities}
‚àß ‚àÉ Initial Compromise(P
(cid:2)) :
path f actor(P
(cid:2)) :
, P ) <= path thres
(cid:2)
(cid:2)
, P ) <= path thres
TABLE 4.
Example TTPs. In the Severity column, L=Low, M=Moderate, H=High, C=Critical. Entity types are shown by the characters: P=Process,
F=File, S=Socket, M=Memory, U=User.
the results of forensic analysis [23]. Moreover, this versioned
graph is acyclic, which can simplify many graph algorithms.
Another signiÔ¨Åcant point about our provenance graph is
that it is designed to be stored in main memory. We have
developed a highly compact provenance graph representation
in our previous work [22], [23] that, on average, required less
than 5 bytes of main memory per event in the audit log. This
representation enables real-time consumption of events and
graph construction over prolonged periods of time. It is on
this provenance graph that our analysis queries for behavior
that matches our TTP speciÔ¨Åcations.
B. TTP SpeciÔ¨Åcation
TTP speciÔ¨Åcations provide the mapping between low-level
audit events and high-level APT steps. Therefore, they are a
central component of our approach. In this subsection, we
describe three key choices in the TTP design that enable
efÔ¨Åcient and precise attack detection.
that
Recall
in our design, TTPs represent a layer of
intermediate abstraction between concrete audit logs and high-
level APT steps. SpeciÔ¨Åcally, we rely on two main techniques
to lift audit log data to this intermediate layer: (a) an OS-
neutral representation of security-relevant events in the form
of the provenance graph and (b) use of information Ô¨Çow
dependencies between entities involved in the TTPs. Taken
together, these techniques enable high-level speciÔ¨Åcations of
malicious behavior that are largely independent of many TTP
details such as the speciÔ¨Åc system calls used, names of
malware, intermediate Ô¨Åles that were created and the programs
used to create them, etc. In this regard, our information Ô¨Çow
based TTP speciÔ¨Åcation approach is more general than the use
of misuse speciÔ¨Åcations [32], [47] from the IDS literature. Use
of information Ô¨Çow dependencies is crucial in the detection of
stealthy APTs that hide their activities by using benign system
processes to carry out their goals.
In addition to specifying the steps of a TTP, we need to
capture its prerequisites. Prerequisites not only help reduce
false positives but also help in understanding the role of a TTP
in the larger context of an APT campaign. In our TTP speciÔ¨Å-
cations, prerequisites take the form of causal relationships and
information Ô¨Çows between APT stages.
Finally, TTP matching needs to be efÔ¨Åcient, and must not
require expensive techniques such as backtracking. We Ô¨Ånd
that most TTPs can be modeled in our framework using a
single event, with additional preconditions on the subjects and
objects involved.
An example of a TTP rule speciÔ¨Åcation is shown in Table
4, with additional rules appearing in Section V. In Table 4, the
Ô¨Årst column represents the APT stage, and the second column
represents the associated TTP name and the entities involved in
the TTP. The third column speciÔ¨Åes the event family associated
with the TTP. For ease of illustration, some of the speciÔ¨Åc
events included in this family are shown in the fourth column,
but note that they are not part of a TTP rule. (Event classes
are deÔ¨Åned once, and reused across all TTP rules.)
The Ô¨Åfth column represents a severity level associated with
each TTP. We use this severity level to rank alarms raised by
our system, prioritizing the most severe alarms. Our current as-
signment of the severity levels is based on the Common Attack
Pattern Enumeration and ClassiÔ¨Åcation (CAPEC) list deÔ¨Åned
by US-CERT and DHS with the collaboration of MITRE [4]
but can be tailored to suit the needs of a particular enterprise.
We also provide another customization mechanism, whereby
each severity level can be mapped to an analyst-speciÔ¨Åed
weight that reÔ¨Çects the relative importance of different APT
stages in a deployment context.
The last column speciÔ¨Åes the prerequisites for the TTP rule
to match. The prerequisites can specify conditions on the pa-
rameters of the TTP being matched, e.g., the socket parameter
S for the U ntrusted Read TTP on the Ô¨Årst row. Prerequisites
can also contain conditions on previously matched TTPs
and their parameters. For instance, the prerequisite column
of the M ake M em Exec(P, M ) TTP contains a condition
‚àÉ U ntrusted Read(?, P (cid:5)). This prerequisite is satisÔ¨Åed only
if an U ntrusted Read TTP has been matched for a process
P (cid:5)
earlier, and if the processes involved in the two TTPs have
a path f actor (deÔ¨Åned below) less than a speciÔ¨Åed threshold.
Prerequisites can capture relations between the entities
involved in two TTPs, such as the parent-child relation on
processes, or information Ô¨Çow between Ô¨Åles. They can also
capture the condition that two TTPs share a common parent.
Using prerequisites, we are able to prune many false positives,
i.e., benign activity resembling a TTP.
C. HSG Construction
Fig. 5 illustrates an HSG for the running example. The
nodes of this graph represent matched TTPs and are depicted
by ovals in the Ô¨Ågure. Inside each oval, we represent the
matched provenance graph entities in grey. For illustration
purposes, we have also included the name of the TTP, the
APT stage to which each TTP belongs, and the severity level
(Low, Medium or High) of each TTP. The edges of the graph
represent the prerequisites between different TTPs. The dotted
lines that complete a path between two entities represent the
prerequisite conditions. For instance, the M ake M em Exec
TTP has, as a prerequisite, an U ntrusted Read TTP, repre-
sented by the edge between the two nodes.
The construction of the HSG is primarily driven by the
prerequisites: A TTP is matched and added to the HSG if all
its prerequisites are satisÔ¨Åed. This factor reduces the number
(cid:18)(cid:18)(cid:21)(cid:18)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:10 UTC from IEEE Xplore.  Restrictions apply. 




