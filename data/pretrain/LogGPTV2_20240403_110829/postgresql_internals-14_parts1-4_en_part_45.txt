QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Finalize Aggregate (actual rows=1 loops=1)
−> Gather (actual rows=3 loops=1)
Workers Planned: 2
Workers Launched: 2
−> Partial Aggregate (actual rows=1 loops=3)
−> Hash Join (actual rows=983286 loops=3)
Hash Cond: (t.book_ref = b.book_ref)
−> Parallel Index Only Scan using tickets_book_ref...
Heap Fetches: 0
−> Hash (actual rows=2111110 loops=3)
Buckets: 4194304 Batches: 1 Memory Usage:
113172kB
−> Seq Scan on bookings b (actual rows=2111110...
(13 rows)
=> RESET enable_parallel_hash;
Hereeachprocesshashesthebookingstable,thenretrievesitsownshareofouter
rows via the Parallel Index Only Scan node, and matches these rows against the
resultinghashtable.
Thehashtablememorylimitisappliedtoeachparallelprocessseparately,sothe
totalsizeofmemoryallocatedforthispurposewillbethreetimesbiggerthanin-
dicatedintheplan(MemoryUsage).
v. Parallel One-Pass Hash Joins
Eventhougharegularhashjoincanbequiteefficientinparallelplans(especially
for small inner sets, for which parallel processing does not make much sense),
largerdatasetsarebetterhandledbyaspecialparallelhashjoinalgorithm.
Animportantdistinctionoftheparallelversionofthealgorithmisthatthehash
tableiscreatedintheshared memory,whichisallocateddynamicallyandcanbe
accessedbyallparallelprocessesthatcontributetothejoinoperation. Insteadof
several separate hash tables, a single common one is built, which uses the total
amount of memory dedicated to all the participating processes. It increases the
chanceofcompletingthejoininonepass.
430
22.1 HashJoins
Atthefirststage(representedintheplanbytheParallelHashnode),alltheparallel
processesbuildacommonhashtable,takingadvantageoftheparallelaccesstothe
innerset.1
work_mem×hash_mem_multiplier×
×numberofprocesses
inner
set
outer
set
Tomoveonfromhere,eachparallelprocessmustcompleteitsshareoffirst-stage
processing.2
Atthesecond stage(theParallel Hash Joinnode),theprocessesareagainrunin
paralleltomatchtheirsharesofrowsoftheoutersetagainstthehashtable,which
isalreadybuiltbythistime.3
outer
set
Hereisanexampleofsuchaplan:
=> SET work_mem = '64MB';
=> EXPLAIN (analyze, costs off, timing off, summary off)
SELECT count(*)
FROM bookings b
JOIN tickets t ON t.book_ref = b.book_ref;
1 backend/executor/nodeHash.c,MultiExecParallelHashfunction
2 backend/storage/ipc/barrier.c
3 backend/executor/nodeHashjoin.c,ExecParallelHashJoinfunction
431
Chapter22 Hashing
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Finalize Aggregate (actual rows=1 loops=1)
−> Gather (actual rows=3 loops=1)
Workers Planned: 2
Workers Launched: 2
−> Partial Aggregate (actual rows=1 loops=3)
−> Parallel Hash Join (actual rows=983286 loops=3)
Hash Cond: (t.book_ref = b.book_ref)
−> Parallel Index Only Scan using tickets_book_ref...
Heap Fetches: 0
−> Parallel Hash (actual rows=703703 loops=3)
Buckets: 4194304 Batches: 1 Memory Usage:
115392kB
−> Parallel Seq Scan on bookings b (actual row...
(13 rows)
=> RESET work_mem;
ItisthesamequerythatIshowedintheprevioussection,buttheparallelhashjoin
on wasturnedoffbytheenable_parallel_hashparameteratthattime.
Althoughtheavailablememoryisdownbyhalfascomparedtoaregularhashjoin
demonstratedbefore,theoperationstillcompletesinonepassbecauseitusesthe
memory allocated for all the parallel processes (Memory Usage). The hash table
getsabitbigger,butsinceitistheonlyonewehavenow,thetotalmemoryusage
hasdecreased.
v. ParallelTwo-Pass Hash Joins
Theconsolidatedmemoryofalltheparallelprocessesmaystillbenotenoughto
accommodate the whole hash table. It can become clear either at the planning
stageorlater,duringqueryexecution.Thetwo-passalgorithmappliedinthiscase
isquitedifferentfromwhatwehaveseensofar.
The key distinction of this algorithm is that it creates several smaller hash ta-
bles instead of a single big one. Each process gets its own table and processes
itsownbatchesindependently. (Butsinceseparatehashtablesarestilllocatedin
thesharedmemory,anyprocesscangetaccesstoanyofthesetables.) Ifplanning
432
22.1 HashJoins
showsthatmorethanonebatchwillberequired,1aseparatehashtableisbuiltfor
eachprocessrightaway. Ifthedecisionistakenattheexecutionstage,thehash
tableisrebuilt.2
Thus, at the first stage processes scan the inner set in parallel, splitting it into
batchesandwritingthemintotemporaryfiles.3 Sinceeachprocessreadsonlyits
own share of the inner set, none of them builds a full hash table for any of the
batches(evenforthefirstone).Thefullsetofrowsofanybatchisonlyaccumulated
inthefilewrittenbyalltheparallelprocessesinasynchronizedmanner.4 Sounlike
thenon-parallelandone-passparallelversionsofthealgorithm,theparalleltwo-
passhashjoinwritesallthebatchestodisk,includingthefirstone.
inner
set
outer
set
Oncealltheprocesseshavecompletedhashingoftheinnerset,thesecondstage
begins.5
Ifthenon-parallelversionofthealgorithmwereemployed,therowsoftheouter
set that belong to the first batch would be matched against the hash table right
away. But in the case of the parallel version, the memory does not contain the
hashtableyet,sotheworkersprocessthebatchesindependently. Therefore,the
second stage starts by a parallel scan of the outer set to distribute its rows into
batches,and each batch is written into a separate temporary file.6 The scanned
1 backend/executor/nodeHash.c,ExecChooseHashTableSizefunction
2 backend/executor/nodeHash.c,ExecParallelHashIncreaseNumBatchesfunction
3 backend/executor/nodeHash.c,MultiExecParallelHashfunction
4 backend/utils/sort/sharedtuplestore.c
5 backend/executor/nodeHashjoin.c,ExecParallelHashJoinfunction
6 backend/executor/nodeHashjoin.c,ExecParallelHashJoinPartitionOuterfunction
433
Chapter22 Hashing
rowsarenotinsertedintothehashtable(asithappensatthefirststage),sothe
numberofbatchesneverrises.
Oncealltheprocesseshavecompletedthescanoftheouterset,weget2Ntempo-
raryfilesondisk;theycontainthebatchesoftheinnerandoutersets.
inner
set
outer
set
Theneachprocesschoosesoneofthebatchesandperformsthejoin: itloadsthe
innersetofrowsintoahashtableinmemory,scanstherowsoftheouterset,and
matchesthemagainstthehashtable.Whenthebatchjoiniscomplete,theprocess
choosesthenextbatchthathasnotbeenprocessedyet.1
inner
set
outer
set
If no more unprocessed batches are left,the process that has completed its own
batch starts processing one of the batches that is currently being handled by an-
otherprocess; suchconcurrentprocessingispossiblebecauseallthehashtables
arelocatedinthesharedmemory.
1 backend/executor/nodeHashjoin.c,ExecParallelHashJoinNewBatchfunction
434
22.1 HashJoins
outer
set
Thisapproachismoreefficientthanusingasinglebighashtableforallthepro-
cesses: itiseasiertosetupparallelprocessing,andsynchronizationischeaper.
Modifications
Thehashjoinalgorithmsupportsanytypesofjoins: apartfromtheinnerjoin,it
canalsohandleleft,right,andfullouterjoins,aswellassemi-andanti-joins.But
asIhavealreadymentioned,thejoinconditionislimitedtotheequalityoperator.
Wehavealreadyobservedsomeoftheseoperationswhendealingwiththenested p.
loopjoin.Hereisanexampleoftherightouterjoin:
=> EXPLAIN (costs off) SELECT *
FROM bookings b
LEFT OUTER JOIN tickets t ON t.book_ref = b.book_ref;
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Hash Right Join
Hash Cond: (t.book_ref = b.book_ref)
−> Seq Scan on tickets t
−> Hash
−> Seq Scan on bookings b
(5 rows)
Note that the logical left join specified in the  query got transformed into a
physicaloperationoftherightjoinintheexecutionplan.
Atthelogicallevel,bookingsistheoutertable(constitutingtheleftsideofthejoin
operation),while the tickets table is the inner one. Therefore,bookings with no
ticketsmustalsobeincludedintothejoinresult.
435
Chapter22 Hashing
At the physical level, inner and outer sets are assigned based on the cost of the
joinratherthantheirlocationinthequerytext.Itusuallymeansthatthesetwith
asmallerhashtablewillbeusedastheinnerone.Thisisexactlywhatishappening
here: thebookingstableisusedastheinnerset,andtheleftjoinischangedtothe
rightone.
Andviceversa,ifthequeryspecifiestherightouterjoin(todisplaytheticketsthat
arenotrelatedtoanybookings),theexecutionplanusestheleftjoin:
=> EXPLAIN (costs off) SELECT *
FROM bookings b
RIGHT OUTER JOIN tickets t ON t.book_ref = b.book_ref;
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Hash Left Join
Hash Cond: (t.book_ref = b.book_ref)
−> Seq Scan on tickets t
−> Hash
−> Seq Scan on bookings b
(5 rows)
To complete the picture, I will provide an example of a query plan with the full
outerjoin:
=> EXPLAIN (costs off) SELECT *
FROM bookings b
FULL OUTER JOIN tickets t ON t.book_ref = b.book_ref;
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Hash Full Join
Hash Cond: (t.book_ref = b.book_ref)
−> Seq Scan on tickets t
−> Hash
−> Seq Scan on bookings b
(5 rows)
Parallelhashjoinsarecurrentlynotsupportedforrightandfulljoins.1
Notethatthenextexampleusesthebookingstableastheouterset,buttheplanner
wouldhavepreferredtherightjoinifitweresupported:
1 commitfest.postgresql.org/33/2903
436
22.2 DistinctValuesandGrouping
=> EXPLAIN (costs off) SELECT sum(b.total_amount)
FROM bookings b
LEFT OUTER JOIN tickets t ON t.book_ref = b.book_ref;
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Finalize Aggregate
−> Gather
Workers Planned: 2
−> Partial Aggregate
−> Parallel Hash Left Join
Hash Cond: (b.book_ref = t.book_ref)
−> Parallel Seq Scan on bookings b
−> Parallel Hash
−> Parallel Index Only Scan using tickets_book...
(9 rows)
22.2 Distinct Values and Grouping
Algorithmsthatgroupvaluesforaggregationandremoveduplicatesareverysim-
ilartojoinalgorithms. Oneoftheapproachestheycanuseconsistsinbuildinga
hashtableontherequiredcolumns. Valuesareincludedintothehashtableonly
if it contains no such values yet. As a result,the hash table accumulates all the
distinctvalues.
ThenodethatperformshashaggregationiscalledHashAggregate.1
Let’sconsidersomesituationsthatmayrequirethisnode.
Thenumberofseatsineachtravelclass():
=> EXPLAIN (costs off) SELECT fare_conditions, count(*)
FROM seats
GROUP BY fare_conditions;
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
HashAggregate
Group Key: fare_conditions
−> Seq Scan on seats
(3 rows)
1 backend/executor/nodeAgg.c
437
Chapter22 Hashing
Thelistoftravelclasses():
=> EXPLAIN (costs off) SELECT DISTINCT fare_conditions
FROM seats;
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
HashAggregate
Group Key: fare_conditions
−> Seq Scan on seats
(3 rows)
Travelclassescombinedwithonemorevalue():
=> EXPLAIN (costs off) SELECT fare_conditions
FROM seats
UNION
SELECT NULL;
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
HashAggregate
Group Key: seats.fare_conditions
−> Append
−> Seq Scan on seats
−> Result
(5 rows)
TheAppendnodecombinesbothsetsbutdoesnotgetridofanyduplicates,which
must not appear in the  result. They have to be removed separately by the
HashAggregatenode.
4MB The memory chunk allocated for the hash table is limited by the work_mem×
1.0 ×hash_mem_multipliervalue,justlikeinthecaseofahashjoin.
Ifthehashtablefitstheallocatedmemory,aggregationusesasinglebatch:
=> EXPLAIN (analyze, costs off, timing off, summary off)
SELECT DISTINCT amount FROM ticket_flights;
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
HashAggregate (actual rows=338 loops=1)
Group Key: amount
Batches: 1 Memory Usage: 61kB
−> Seq Scan on ticket_flights (actual rows=8391852 loops=1)
(4 rows)
438
22.2 DistinctValuesandGrouping
Therearenotsomanydistinctvaluesintheamountsfield,sothehashtabletakes
onlyk(MemoryUsage).
Assoonasthehashtablefillsuptheallocatedmemory,allthefurthervaluesare v.
spilled into temporary files and grouped into partitions based on several bits of
theirhashvalues.Thenumberofpartitionsisapoweroftwoandischoseninsuch
awaythateachoftheirhashtablesfitstheallocatedmemory.Theaccuracyofthe
estimationisofcoursedependentonthequalityofthecollectedstatistics,sothe
receivednumberismultipliedby.tofurtherreducepartitionsizesandraisethe
chancesofprocessingeachpartitioninonepass.1
Oncethewholesetisscanned,thenodereturnsaggregationresultsforthoseval-