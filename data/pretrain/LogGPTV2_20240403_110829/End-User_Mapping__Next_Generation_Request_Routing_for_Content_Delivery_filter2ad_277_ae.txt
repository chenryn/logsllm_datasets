/24
(a) Histogram of the cluster radius for /x client IP blocks.
(b) Number of /x client IP blocks with non-zero demand.
Figure 22: A smaller value of x yields fewer mapping units but larger cluster radius with less mapping accuracy.
ping units for end-user mapping is to use the IP blocks (i.e.,
CIDRs) in BGP feeds that are the units for routing in the In-
ternet. In particular, if a set of /24 IP blocks belong within
the same BGP CIDR, these blocks can be combined since
they are likely proximal in the network sense. We extracted
517K unique CIDRs with non-zero trafﬁc from BGP feeds
across the Internet from the network measurement compo-
nent of the mapping system. By combining /24 IP blocks
whenever they belong to the same BGP CIDR, we reduce the
number of mapping units from 3.76 million to 444K. Note
that the same technique may be applied to reduce the number
of mapping units for /x IP blocks, for any value of x.
After applying the BGP CIDRs to reduce the number of
mapping units, there is still the tradeoff of what /x client IP
blocks to choose as the mapping unit. One could reduce
the number of mapping units by using coarser /x client IP
blocks, i.e., by choosing a smaller value of x. However,
when coarser IP blocks are used, the set of clients in a given
block is larger and span a larger geographical area. This re-
duces mapping accuracy as the client clusters that are the
units of mapping have a larger radius. Figure 22 provides
the exact tradeoff between the cluster radius which is a proxy
for mapping accuracy and the number of clusters that need
to be measured and analyzed. It can be seen that /20 client
IP blocks are a worthy option as they reduce the number of
mapping units by a factor of 3 in comparison to /24 blocks.
However, the clusters are still relatively small with 87.3% of
the clusters having a radius of no more than 100 miles.
5.2 Dealing with greater DNS query rates
In NS-based mapping, each LDNS stores one resolution
per domain name. However, with end-user mapping, differ-
ent client IP blocks within the same client cluster may get
different resolutions for the same domain name. Thus, an
LDNS that serves multiple client IP blocks may store multi-
ple entries for the same domain name. Therefore, an LDNS
may make multiple requests to an authoritative name server
for the domain name, one for each client IP block. This
can lead to a sharp increase in the LDNS queries seen by
the authoritative name servers of the mapping system. Fig-
ure 23 shows the total DNS queries per second served by
the mapping system before, during, and after enabling end-
user mapping for clients who use public resolvers. Prior to
the roll-out, the total queries per second served by Akamai’s
name servers was 870K queries per second of which pub-
lic resolvers targeted by the roll-out accounted for roughly
33.5K queries per second. But after the rollout, the total
queries per second on the Akamai network was 1.17 million
queries per second of which public resolvers accounted for
270K queries per second. Thus, the queries from public re-
solvers increased by a factor of 270K/33.5K = 8, an increase
largely attributable to the roll-out10. The gradual increase in
query rate seen outside of the roll-out window is simply due
to the normal increase in Internet trafﬁc over time.
d
n
o
c
e
s
r
e
p
s
e
i
r
e
u
Q
1600000
1400000
1200000
1000000
800000
600000
Jan
Feb
Mar
Apr
May
Jun
Jul
Figure 23: DNS queries received by Akamai’s name servers
from LDNSes showed a signiﬁcant increase during the end-
user mapping rollout.
10DNS queries increase when public resolvers turn on the
EDNS0 extension. But, the performance improvements in
Section 4.3 occur when Akamai gradually turned on end-
user mapping for these public resolvers.
178
e
t
a
r
y
r
e
u
q
n
i
e
s
a
e
r
c
n
i
r
o
t
c
a
F
1000
100
10
1
0.1
0.2
0.5
0
1
Popularity of Domain name and LDNS pairs (in queries per TTL)
0.3
0.4
0.8
0.9
0.6
0.7
Figure 24: More popular domain name and LDNS pairs
show a greater increase in query rate after the roll-out.
The popularity of a domain name among the clients of
an LDNS inﬂuences the factor increase in DNS queries for
that domain name when EDNS0 and end-user mapping are
turned on. Prior to the end-user mapping roll-out, the query
rate for a domain name from a particular LDNS is at most
one query per TTL, since the LDNS can cache the transla-
tion for the time of the TTL. We bucket each domain name
and LDNS pair according to the number of queries received
per TTL prior to the roll-out. Figure 24 shows the factor in-
crease in query rate for domain name and LDNS pairs that
fall into each bucket. Note that the more popular domain
name and LDNS pairs that have pre-roll-out query rates close
to 1 query per TTL saw the largest increase in query rate
when end-user mapping was rolled out, while less popu-
lar domains saw little or no increase. The reason is that a
more popular domain name is more likely to be accessed
by clients in multiple client IP blocks of the LDNS’s client
cluster, each IP block requiring a separate domain name res-
olution when EDNS0 is used. Fortunately, the domain name
and LDNS pairs in the highest popularity bucket in Figure 24
accounted for only 11% of total pre-roll-out queries.
6. ROLE OF SERVER DEPLOYMENTS
Server deployments play an important role in determining
client performance. More server deployment locations mean
better performance for clients, since the mapping system has
more options to choose a proximal server for each client.
But, what role do deployments play in determining the ad-
ditional performance beneﬁts provided by end-user mapping
over NS-based mapping? Should a CDN with a small num-
ber of deployment locations adopt end-user mapping? For a
CDN with a given set of deployment locations, what is more
beneﬁcial: adding more deployment locations or incorporat-
ing end-user mapping? How much can NS-based mapping
be improved by making it client-aware?
To provide intuition on these key what-if questions, con-
sider a simpliﬁed model. Let a CDN have N deployment
locations. The deployments partition the IP address space
of the global Internet into sets Ei, 1  i  N, such that
Ei is the set of IPs for whom the ith deployment location
179
is the most proximal among all deployments. Observe that
for any client c, if c and its LDNS are both in some set Ei,
both end-user mapping and traditional NS-based mapping
will pick a server in the ith deployment location for client
c, i.e., there is no additional beneﬁt for client c from using
end-user mapping. Thus, if a CDN has fewer deployments,
each set Ei is likely larger and is hence more likely to con-
tain both the client and its LDNS. Thus, we would expect a
a CDN with fewer deployments to beneﬁt less from end-user
mapping than a CDN with more deployments. We quantify
answers to this and other key questions using simulations.
Simulation Methodology. We create a universe U of
possible deployment locations by using 2642 different lo-
cations around the globe with Akamai servers. These de-
ployments are spread over 100 countries and were chosen
to provide good coverage of the global Internet. Next, we
choose around 20K /24 IP blocks that account for most of the
load on the Internet and further cluster them into 8K “ping
targets”, so as to cover all major geographical areas and net-
works around the world. We then perform latency measure-
ments using pings from each deployment U to each of the
8K ping targets. For any client or LDNS, we ﬁnd the clos-
est of the 8K ping targets and use that as a proxy for la-
tency measurements, i.e., the latency measurements to the
ping target are assumed to be the latency measurements to
the client or LDNS. Using the ping latency measurements
described above, we simulate three mapping schemes, each
with a varying number of deployment locations.
(1) NS-based mapping (NS): Map client to the deployment
location that has the least latency to the LDNS of that client.
(2) End-user mapping (EU): Map client to the deployment
location that has the least latency to the client’s /24 IP block.
(3) Client-Aware NS-based Mapping (CANS): For each
client, ﬁnd the cluster of clients that shares its LDNS. Map
client to the deployment location that minimizes the trafﬁc-
weighted average of the latencies from the deployment to its
cluster of clients.
Note that CANS mapping is an enhancement of pure NS
mapping by using the latency measurements to the clients
of the LDNS, rather than just the latency measurement to
the LDNS. In situations where LDNS is far away from its
clients, but its clients are themselves relatively close together,
CANS mapping could provide low latency mappings. CANs
requires tracking client-LDNS associations on an ongoing
basis on the global Internet, an additional complexity in com-
parison with NS mapping. However, CANS can be viewed
as a hybrid between NS and EU that uses client measure-
ments but requires no speciﬁc knowledge about the client’s
IP, i.e., it does not require the EDNS0 protocol extension.
We simulated the three mapping schemes above for a vary-
ing number of deployment locations N chosen from the uni-
verse U. We performed 100 random runs of our simulation,
where we do the following in each run. We randomly or-
der the deployments in U. Then, for each N, we simulate all
three mapping schemes assuming the ﬁrst N deployments in
the random ordering. The simulation computes the trafﬁc-
weighted mean, 95th, and 99th percentile latencies achieved
by the three schemes. Finally, for each value of N, we av-
eraged the metrics obtained across the 100 simulation runs
and those values are reported in Figure 25.
behind a given LDNS provides sufﬁcient knowledge to im-
prove NS-based mapping for higher percentiles for latency.
)
s
m
(
y
c
n
e
t
a
l
g
n
P
i
250
200
150
100
50
0
●
40
● CANS mean
CANS 95pct
CANS 99pct
EU mean
EU 95pct
EU 99pct
NS mean
NS 95pct
NS 99pct
●
●
●
●
●
●
160
80
1280
Number of deployment locations
320
640
2560
Figure 25: Latencies achieved by EU, CANS, and NS map-
ping as a function of CDN deployment locations.
An important caveat in interpreting Figure 25 is that the
ping latencies shown are an underestimate of the actual la-
tency or RTT from the server to the client, since only a ping
target (typically a router) enroute to the client is “pinged”.
So, while the absolute values of the ping latencies are less
meaningful except as a lower bound on the actual latencies,
the relative values are still meaningful. As shown in the ﬁg-
ure, all mapping schemes provide smaller ping latencies with
a larger deployment. Further, mean ping latency is nearly
identical for all three mapping schemes, reﬂecting the fact
that in many cases a client and its LDNS are proximal to
each other and LDNS is a good proxy for the client. Even
so, EU performed the best of the three with mean ping la-
tency dropping from 35 ms for a small deployment to under
10 ms as the deployments increase.
However, mean latency across all clients on the globe is
less interesting than latency of the worst-performing clients.
In fact, both CDNs and content providers are focused on
improving the performance of the worst-performing client.
Thus, we computed the 95th and 99th percentiles of the la-
tencies, i.e, latencies for 1-5% of the worst clients.
It is
clear that EU provides a large beneﬁt over the other schemes
for higher percentiles of ping latency.
In particular, NS-
based mapping provides diminishing beneﬁts beyond 160
deployment locations for the 99th percentile latency, and is
in particular unable to reduce it below 186 ms even with
1280 deployment locations. The reason is that NS-based
mapping does not work well for clients whose LDNSes are
not proximal who are likely among the worst-performing
clients. However, EU continues to reduce the latencies with
increasing deployments, even beyond 1280 deployments. It
can also be seen in the ﬁgure that a CDN with larger de-
ployment locations sees a proportionally larger reduction in
higher percentiles of ping latency by switching to EU from
NS than a CDN with smaller deployments. CAN mapping
provides an intermediate point between the extremes of NS
and EUM. In particular, the knowledge of latencies to clients
7. RELATED WORK
While the EDSN0 extension provides a systematic mech-
anism for end-user mapping implementation, other mecha-
nisms have been explored in limited ways in industry. A
video CDN at Akamai in circa 2000 used metaﬁle redirec-
tion to implement end-user mapping. When a client starts a
video, the media player fetches a metaﬁle that contains the
server’s IP from which to download the video. The server
IP embedded in the metaﬁle is dynamically generated by
the mapping system using the client’s IP derived from the
metaﬁle download. However, such a mechanism is hard to
extend to the Web and other trafﬁc that do not use metaﬁles.
Analogous to metaﬁle redirection, systems that use http
redirection have also been built where the client is ﬁrst as-
signed a server using NS-based mapping. The ﬁrst server
uses its knowledge of the client’s IP to redirect the client to
a “better” second server if appropriate. The second server
then serves the content to the client. However, this process
incurs a redirection penalty that is acceptable only for larger
downloads such as media ﬁles and software downloads.
Tools for discovering client-LDNS pairings have also ex-
isted in industry for the past 15 years.
In principle, such
pairings can be used to create a client-aware NS-based map-
ping system (cf. Section 6), though it will not be effective
for LDNSes with large client clusters (cf. Section 3.3).
We think that the EDNS0 extension is key to building
large-scale end-user mapping that overcomes the short com-
ings of prior implementations. The EDNS0 extension re-
moves the overhead of explicit client-LDNS discovery, avoids
a redirection performance penalty, and is effective even for
LDNSes with large geo-distributed client clusters.
From a research perspective, client-LDNS distances and
their potential impact on server selection has been studied in
[24], and subsequently in [20, 17]. The prior literature ob-
served larger client-LDNS distances and poorer performance
for clients using public resolvers that are increasingly in use
[22]. Our measurement study of client-LDNS distances in
Section 3 is based on a much wider global cross-section
of clients and LDNSes than prior work and largely conﬁrm
prior conclusions on public resolvers. However, we go a step
further by describing an end-user mapping system to rem-
edy the issue. The EDNS0 extension has also been studied
as tool for ﬁguring out deployments of CDN providers who
support the extension such as Google [10, 27]. Extensions
other than EDSN0 for overcoming client-LDNS mismatch
have also been proposed [16].
8. CONCLUSION
In this paper, we described our experience in rolling-out a
new mapping system called end-user mapping. By analyz-
ing clients and LDNSes from around the world, we showed
that a signiﬁcant fraction of clients have LDNSes that are not
in their proximity and could beneﬁt from end-user mapping.
We conﬁrmed the performance beneﬁts by measuring map-
180
ping distance, RTT, Time-To-First-Byte (TTFB), and con-
tent download time during the roll-out. We showed that for
“high-expectation” countries, clients using public resolvers
saw an eight-fold decrease in mean mapping distance, a two-
fold decrease in RTT and content download time, and a 30%
improvement in the TTFB. We also quantiﬁed the scaling
challenges in implementing end-user mapping such as the 8-
fold increase in DNS queries and the greater number of map-
ping units that need to be measured and analyzed. Finally,
we shed light on the role of deployments and showed that a
CDN with a larger number of deployment locations is likely
to beneﬁt more from end-user mapping than a CDN with a
smaller number. While we only describe the roll-out of end-
user mapping to clients who are using public resolvers, our
analysis shows that a broad roll-out of this technology across
the entire Internet population will be quite beneﬁcial. For
such a roll-out to occur, more ISPs would need to support
the EDNS0 extension. We expect our work that quantiﬁes
the real-world beneﬁts of end-user mapping to provide im-
petus to a broader adoption of the EDNS0 extension.
9. ACKNOWLEDGEMENTS
First and foremost, we thank the many engineers at Aka-
mai who designed, implemented and rolled-out end-user map-
ping, making it possible for us to evaluate its impact. Special
thanks to Mike Conlen who helped collect DNS query data,
to Pablo Alvarez who made key contributions to end-user
mapping scoring, and to Jason Moreau who made major con-
tributions to name server design. We thank our anonymous
referees for copious reviews that helped improve the paper.
A special thanks to our shepherd Ethan Katz-Bassett who
provided lots of great feedback that strengthened the paper.
10. REFERENCES
[1] Akamai Edgescape. http://goo.gl/P68U6q.
[2] Akamai Facts & Figures. http://goo.gl/Megx1b.
[3] Akamai NetSession Interface. http://goo.gl/FOtjlz.
[4] Akamai Real User Monitoring. http://goo.gl/8oiQyC.
[5] Google Public DNS. https://goo.gl/p8cfJm.
[6] Navigation Timing. http://goo.gl/ePcQrG.
[7] OpenDNS. https://www.opendns.com/.
[8] Resource Timing. http://goo.gl/5eYQtL.
[9] Velocity and the bottom line. http://goo.gl/KTlcYR.
[10] M. Calder, X. Fan, Z. Hu, E. Katz-Bassett,
J. Heidemann, and R. Govindan. Mapping the
expansion of Google’s serving infrastructure. In
Proceedings of the ACM Internet Measurement
Conference, pages 313–326, 2013.
[11] C. Contavalli, W. van der Gaast, D. Lawrence, and
W. Kumari. Client subnet in DNS requests. IETF
Internet Draft, Nov. 2014.
[12] C. Crocker, A. Kulick, and B. Ram. Real user
monitoring at walmart.com: A story in three parts. In
San Francisco and Silicon Valley Web Performance
Group, Feb 2012. http://minus.com/msM8y8nyh.
[13] J. Dilley, B. M. Maggs, J. Parikh, H. Prokop, R. K.
Sitaraman, and W. E. Weihl. Globally distributed
content delivery. IEEE Internet Computing,
6(5):50–58, 2002.
[14] X. Fan, J. Heidemann, and R. Govindan. Evaluating
anycast in the domain name system. In Proceedings of
the IEEE INFOCOM, pages 1681–1689, 2013.
[15] T. Hardie. Distributing authoritative name servers via
shared unicast addresses. RFC 3258, Apr. 2002.
[16] C. Huang, I. Batanov, and J. Li. A practical solution to
the client-LDNS mismatch problem. SIGCOMM
Comput. Commun. Rev., 42(2):35–41, Mar. 2012.
[17] C. Huang, D. A. Maltz, J. Li, and A. Greenberg.
Public DNS system and global trafﬁc management. In
Proceedings of the IEEE INFOCOM, pages
2615–2623, 2011.
[18] S. Lohr. For impatient web users, an eye blink is just
too long to wait. New York Times, Feb 2012.
http://goo.gl/y70JgH.
[19] B. M. Maggs and R. K. Sitaraman. Algorithmic
nuggets in content delivery. SIGCOMM Comput.
Commun. Rev., July 2015.
[20] Z. M. Mao, C. D. Cranor, F. Douglis, M. Rabinovich,
O. Spatscheck, and J. Wang. A precise and efﬁcient
evaluation of the proximity between Web clients and
their local DNS servers. In USENIX Annual Technical
Conference, General Track, pages 229–242, 2002.
[21] E. Nygren, R. Sitaraman, and J. Sun. The Akamai
Network: A platform for high-performance Internet
applications. ACM SIGOPS Operating Systems
Review, 44(3):2–19, 2010.
[22] J. S. Otto, M. A. Sánchez, J. P. Rula, and F. E.
Bustamante. Content delivery and the natural
evolution of DNS: remote DNS trends, performance
issues and alternative solutions. In Proceedings of the
ACM Internet Measurement Conference, pages
523–536, 2012.
[23] S. Sarat, V. Pappas, and A. Terzis. On the use of
anycast in DNS. In Proceedings of the IEEE ICCCN,
pages 71–78, 2006.
[24] A. Shaikh, R. Tewari, and M. Agrawal. On the
effectiveness of DNS-based server selection. In
Proceedings of the IEEE INFOCOM, volume 3, pages
1801–1810, 2001.
[25] R. K. Sitaraman. Network performance: Does it really
matter to users and by how much? In Fifth
International Conference on Communication Systems
and Networks (COMSNETS), pages 1–10. IEEE, 2013.
[26] R. K. Sitaraman, M. Kasbekar, W. Lichtenstein, and
M. Jain. Overlay networks: An Akamai perspective. In
Advanced Content Delivery, Streaming, and Cloud
Services. John Wiley & Sons, 2014.
[27] F. Streibelt, J. Böttger, N. Chatzis, G. Smaragdakis,
and A. Feldmann. Exploring EDNS-client-subnet
adopters in your free time. In Proceedings of the ACM
Internet Measurement Conference, 2013.
181