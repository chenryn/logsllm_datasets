Response Time Characterization of
Microservice-Based Systems
Jaime Correia, Fa´bio Ribeiro, Ricardo Filipe, Filipe Araujo and Jorge Cardoso
CISUC, Department of Informatics Engineering, University of Coimbra
Coimbra, Portugal
Emails: PI:EMAIL, PI:EMAIL, PI:EMAIL, PI:EMAIL and PI:EMAIL
Abstract—In pursuit of faster development cycles, companies a system of microservices. This allows us to extract the de-
have favored small decoupled services over monoliths. Following pendencies between service endpoints, and, more importantly,
thistrend,distributedsystemsmadeofmicroserviceshavegrown
we are able to model the performance of each microservice.
in scale and complexity, giving rise to a new set of operational
Theobjectiveissimple,butveryambitious:obtaintheoptimal
problems. Even though this paradigm simplifies development,
deployment,managementofindividualservices,ithinderssystem zone of operation for each service. This can lead to multiple
observability.Inparticular,performancemonitoringandanalysis pathways, such as understanding when to scale in or out,
becomes more challenging, especially for critical production reducingtheinfrastructurecost,andensuringtheservicelevel
systems that have grown organically, operate continuously, and
agreements (SLAs). Additionally, the possibility of pinpoint-
cannot afford the availability cost of online benchmarking.
ing bottlenecks in the system without stressing it, is a major
Additionally, these systems are often very large and expensive,
thus being bad candidates for full-scale development replicas. advantage for system administrators.
Creating models of services and systems for characterization In this paper, we develop and instrument a microservice-
andformalanalysiscanalleviatetheaforementionedissues.Since based system, and resort to tracing, to model microservices
performance, namely response time, is the main interest of this
as multi-server queues (M/M/c). This makes it possible to
work, we focused on bottleneck detection and optimal resource
predict the distribution of response times and the optimal
scheduling. We propose a method for modeling production
services as queuing systems from request traces. Additionally, operation zone of a service, as well as determine how many
we provide analytical tools for response time characterization instances would be needed to maintain the desired service
and optimal resource allocation. Our results show that a simple level for a given workload. Moreover, having a performance
queuing system with a single queue and multiple homogeneous
model makes it possible to establish a notion of maximum
servers has a small parameter space that can be estimated in
capacity, and is the first step towards full system performance
production.Theresultingmodelcanbeusedtoaccuratelypredict
responsetimedistributionandthenecessarynumberofinstances optimizationandbottleneckdetection.Ourresultsdemonstrate
to maintain a desired service level, under a given load. that although simple, our model can accurately predict the
IndexTerms—Modeling;Performance;Microservices;Observ- behavior of a microservice, more precisely, the response
ability; Tracing; Availability.
timedistribution,withoutmakingthemodelingandparameter
estimation too complicated or too costly. Consequently, this
I. INTRODUCTION
type of model is adequate for online estimation and analysis.
In dynamic, elastic production environments that scale in
The rest of the paper is organized as follows. Section II
and out rapidly, tracking microservices performance can be a
describes the queue-based model we use to characterize mi-
huge challenge. Black-box monitoring can be effective and
croservices. Section III describes the experimental setting.
light-weight, such as in our previous work [1]. However,
Section IV shows the results of our experiments. Section V
the majority of these solutions lack an important feature:
evaluates the results. Section VI presents the related work.
identifying and predicting quality of service. Despite their
Section VII concludes the paper.
collected metrics, notifications and configurable dashboards,
theburdenofanalysisrestsontheadministrators.Wepropose
II. PERFORMANCEMODELING
modeling components, as homogeneous multi-server queues,
enabling a statistical characterization of fundamental perfor-
To analyze the performance of a system, and predictions
mance metrics, such as latency and throughput. Moreover,
its behavior, a suitable model is necessary. The detection of
since queues can be composed into networks, this approach
bottlenecks requires a notion of capacity limits, as a way to
can serve as the building block to model systems of mi-
compare two services in an execution path, and to predict
croservices. To accurately model individual services, we need
performance changes in response to resource allocation. In
detailed measurements of their performance. Since we want
thecontextofmicroservice-basedsystems,resourceallocation
to capture real workload conditions, we resort to tracing [2].
for scaling purposes is usually done at the instance level,
With the additional information given by tracing, we are
with virtual machines or containers. If those requirements are
able to create and update a dynamic dependency model for
fulfilled, it becomes possible to determine analytically which
978-1-5386-7659-2/18/$31.00c2018IEEE microservices have insufficient or excessive capacity.
Our requirements for a model are the ability to represent {λ,µ,c}, for clarity, we will sometimes use the notation
response time, throughput and parallelism, as we intend to CDF(λ,µ,c,t)=P(T t)
modeling microservices as M/M/c queues.  1− ΠW e−cµ(1−ρ)t+ 1− ΠW  e−µt ifc(1−ρ)=1
Our parameter space is quite small and intuitive, {λ,µ,c}. = 1−c(1−ρ) 1−c(1−ρ)
Here, λ and µ represent the rate parameters for the ex- 1−(µΠWt+1)e−µt ifc(1−ρ)=1
(1)
ponentially distributed inter-arrival and service times, and
c the number of homogeneous servers, representing service
parallelism. It is relevant to note that c does not necessarily A natural application here, in the context of determining
represent the number of instances, as, in some cases, service quality of service, is to compute the expected percentage of
instances will have some form of internal parallelism. requests with total system time bigger than a given threshold
r by computing 1−P(T 0, ∀i
i
this formula is context dependent on the queue parameters 1≤c≤N, c∈N
Although accurate under simulation, this method is very TABLEII
sensitive to time measurement imprecisions, typical of real- ESTIMATIONOFµFROMSAMPLESWITHDIFFERENTOCCUPATIONS(ρ).
life scenarios. These imprecisions can arise from parts of the
ρ c µ µ Error(%)
workflow that are hard to measure, typically time spent in 0.0333 1 30 29.24 3%
sockets, load balancers, in the operating system, and so on. 0.8333 1 30 5.02 83%
As we already have a method for estimating the service rate 0.8333 2 30 9.88 67%
0.8333 3 30 2.13 93%
µ , as well asa sample of request times, wecan calculate c to
  0.8889 3 30 8.50 72%
maximize the Mean Square Error (MSE) between observed
request time distribution eCDF and the prediction CDF
TABLEIII
made with the model resulting from {λ,µ , c}. PARAMETERESTIMATIONRESULTSANDERRORWITHSIMULATIONDATA.
III. EXPERIMENTALSETUP Setting λ µ c MSE Bias
S1 0.99 29.24 1 0.000028 -0.00300
We validated our model choice and parameter estimation
S2 24.89 29.24 1 0.001135 -0.02685
techniques against both a simulated and a real microser- S3 50.38 29.24 2 0.000613 -0.01476
vice. The simulation was used to validate the parametriza- S4 74.92 29.24 3 0.001202 -0.02473
S5 79.43 29.24 3 0.002472 -0.04344
tion methodology, in a situation where the assumptions were
known to hold true. The second experiment, with the real
microservice was meant to validate both the quality of the
to produce approximately exponential inter-arrival times [3].
parametrization in a real-world scenario, and measure the
To do this, we ran the experiments with a number of threads
quality of the resulting model.
muchlargerthanthetargetload,andhavethemwaitingauni-
formly distributed random time between requests. The larger
A. Simulation with qcomputer