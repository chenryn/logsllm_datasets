similar EMI. The exceptions, which we consider in more
544TV
Panasonic-42-A
Panasonic-42-B
Samsung-58-A
Samsung-58-B
Samsung-32
Sharp-42
Sharp-32-A
Sharp-32-B
Average
Standard Deviation
Average
Standard Deviation
Cross Correlation
Diﬀerent Content (%)
±12.83
±12.97
±10.22
±9.70
±16
±12.84
±5.10
±5.79
60.36
59.51
53.29
53.37
65.56
63.45
56.41
56.39
Cross Correlation
Same Content (%)
±2.77
±0.98
±1.97
±2.73
±5.21
±8.26
±8.12
±8.39
98.18
98.99
97.47
96.71
98.26
97.30
60.03
60.91
Table 5: Analysis of EMI signal similarity given identical and diﬀerent video content within a TV - averaged
over the 15 minute intro segment of all movies.
TV
Panasonic-42-A and B
Samsung-58-A and B
Sharp-32-A and B
Best Cross Correlation
Average
Standard Deviation
Same Content (%)
±4.67
±9.23
±18.84
96.82
94.96
77.21
Average
Best Cross Correlation
Diﬀerent Content (%)
±12.85
±10.09
±12.96
59.93
59.30
53.31
Standard Deviation
Table 6: Analysis of EMI signal similarity given identical and diﬀerent video content between TV pairs
(averaged over all movies). For this we used randomly selected 15 minute streams from each 60 minute movie
the power consumption characteristics of the circuitry. There
is also a possibility that this particular model incorporates a
ﬁxed frequency power supply.
9.2 Signal Matching and Query Length
Our initial experiments suggested that extracted EMI sig-
nals are consistent within TVs as well as between identical
models using cross correlations computed over 15 minute
segments of content. We next evaluated how varying the
length of EMI traces impacts signal repeatability and diﬀer-
entiability.
We designed a search procedure that would take as input a
full EMI trace of a movie and extract 10 query segments (of
variable lengths) from multiple (randomly chosen) starting
indexes along the 60 minute stream. Each query segment
would then be matched against the EMI signals of the en-
tire movie database (using sliding-window cross correlation),
and the highest correlated match would be returned. This
technique is also referred to as matched ﬁltering in signal
processing communities. We applied this procedure to ﬁnd
matching signals between TVs of the same model; query data
would be extracted from the EMI library of the ﬁrst TV in
the pair, and the database signals would come from the other
(e.g., query = EMI from Panasonic-42-A, database = EMI
from Panasonic-42-B).
We performed a series of runs using query lengths ranging
between 1 and 15 minutes (1, 3, 6, 9, 12 and 15 mins) and
in each instance computed the cross correlation between the
query and its best match (averaged across 10 samples for
each query length). The matching results for the three TV
model pairs are show in Figure 4. Even short length queries
tend to ﬁnd highly correlated matches in the database. In
particular, for TVs with repeatable EMI signals, once the
query length reaches 6 minutes the correlation reaches 93.7%.
Interestingly, for the Sharp-32-A and B TVs, longer queries
led to degraded performance. We attribute this to the weak
EMI signatures of these TVs (as previously mentioned) which
are susceptible to noise whenever the EMI signal is not being
modulated along its entire dynamic range. However, the
Sharp-42 performed very well with just short queries.
9.3 Reducing False Matches
Usually the best correlated match to a query (returned
by our search procedure) was taken from the trace of the
same movie in the database; however this was not always
the case and we address this issue in the current section.
To develop a method that would reduce false matches, we
modiﬁed our matching algorithm to withhold query responses
unless the top correlation match was a “clear winner” and
was separated from the next best candidate by a margin of
5%. We experimented with multiple settings of this threshold
parameter (including setting its value to be proportional to
the number of samples in the query) but found that the
5% level provided a good trade-oﬀ between numbers of false
positives and rejected samples given the query lengths and
dataset size we tested (we provide a lengthier discussion of
the threshold value choice in the Appendix B).
Given this modiﬁed search procedure, each query could be
classiﬁed into one of three bins:
• Miss: the search engine is conﬁdent in the match
(accept) but there is a mismatch between the search
engine’s best guess and the query origin. (Failure.)
• Hit: the search engine is conﬁdent in the match (accept)
and the match was the movie from which the query
itself was extracted. (Success.)
• Reject: the best match was a not a “clear winner,”
and the matching algorithm chooses not to respond.
(Neither success nor failure.)
In Figure 5 and Figure 6 we respectively show the distribu-
tion of queries into these bins as a function of query length
for the TVs which were the best (Panasonic 42
) and worst
) on the test for signal repeatability
performers (Sharp 32
within a model family.
(cid:2)(cid:2)
(cid:2)(cid:2)
(cid:2)(cid:2)
We note that the Sharp 32
A vs B data causes a very high
rejection rate due to the consistent lack of a “clear winner,”
545Figure 7: Distribution of queries into rejected, hit
and miss for lab vs home data for Panasonic-42.
Figure 8: Cross correlation for target (green) movies
embedded in broadcast content (blue).
(cid:2)(cid:2)
(cid:2)(cid:2)
in addition further strengthening the hypothesis that the
A & B are very sensitive to noise. Conversely the
Sharp 32
Panasonic 42
A vs B data quickly reaches a high hit rate
(and low rejection rate). In all cases the miss rate was low.
This method is therefore less inﬂuenced by noise; queries
that result in a match (non-reject) have a high probability of
being correct.
9.4 Home Results
Having found evidence of signiﬁcant information leakage
within a lab setting, we next turned to evaluating our ap-
proach in a more natural environment. We wanted to deploy a
TV in multiple homes and see if we could match queries from
home EMI to lab EMI datasets. In choosing which television
to utilize for our residential recordings, we initially restricted
the candidate pool to TVs for which we had duplicate models
(Panasonic-42-A&B, Samsung-58-A&B, and Sharp-32-A&B).
TVs based on their weak EMI
We rejected the Sharp 32
(cid:2)(cid:2)
signatures. Given the choice between the Panasonic 42
TVs
(cid:2)(cid:2)
TVs, we selected the smaller TVs because
and Samsung 58
they were signiﬁcantly easier to transport.
(cid:2)(cid:2)
We set up our system (Panasonic-42-B, PLI, and logging
equipment) in three diﬀerent homes (see Table 3, along with
Appendix C) and in each context recorded a smaller version
of our database (3 hours total — ﬁrst 15 minutes of the ﬁrst
12 movies). Next we matched queries extracted from home
EMI (Panasonic-42-B) against the EMI signature database
collected in the lab (Panasonic-42-A) using the search system
which had the capacity to reject searches that did not produce
“clear winners” (as described previously). The results of this
analysis are shown in Figure 7.The hit rate for 15 minute
queries drops from 96% in the lab environment with no misses
to 92% in the home environment with a 2% miss rate.
9.5 Searching for Target Content
The above results show that our small collection of 20
movies yield distinguishable EMI when displayed on modern
TVs; this emulates the target channel identiﬁcation adver-
sarial goal in Section 4. We now turn to experimentally
emulating a target video identiﬁcation attack scenario (recall
again Section 4). Under this scenario, a person might be
watching arbitrary TV content, and the attacker wishes to
Figure 9: Matching results for Panasonic-42-A EMI
queries against neural network database.
determine whether that content corresponds to some target
(e.g., censored, banned, sensitive) content. To explore this
adversarial goal, we recorded 20 hours of EMI while the TV
was tuned to over-the-air HD television broadcast.
Figure 8 shows the results of running our matching frame-
work on EMI from one hour long chunks of over the air broad-
cast interleaved with one hour movies (the targets) from our
database. Given a query length of 6 or more minutes the over
the air cable data never returned a match because matches
could not pass the conﬁdence threshold. Conversely, the con-
tent embedded from our “sensitive” database had a rejection
rate of 3.3% and a hit rate of 95.06%. This demonstrates
that target videos were clearly detectable when intermingled
with non-target videos.
10. EXTENSION: MODELS OF EMI
The results in the previous sections motivated us to ask
the following question: can we reverse engineer the method
by which a TV produces EMI as a function of its video input?
Such a tool could be used to build a database of EMI models
to predict noise signatures without needing physical access
546to target devices (after the training phase). It would also be
plausible to learn to recreate EMI from a home TV without
ever seeing a TV of that type, provided that there are samples
of data from periods during which the TV displays known
content (e.g., if the user is watching one of ﬁve news channels
in the morning, the system could build a model for the TV
to try and detect whether the user is watching some speciﬁc
show later).
We investigate the plausibility of learning a model to recre-
ate the EMI of one TV (Panasonic-42-A) by framing the
problem as an instance of supervised learning, where the
goal is to approximate how the various hardware components
of the device (taken together as a black box) modulate the
SMPS and produce EMI from video input. To tackle this
problem we chose to use recurrent neural networks (RNN)
because the EMI we are seeking to replicate is a continuous
time signal which exhibits non-stationarity (i.e., the current
state of the EMI depends on the past several samples) hence
ruling out the possibility of using popular stationary methods
for supervised learning (i.e., Support Vector Machines). A
further motivation to use RNNs comes from their ability to
accommodate for non-linear interactions between the input
and output which we could not rule out from the processes
that shape electromagnetic interference.
Features from Video Frames.
The input to our model,
is a sequence of video frames arriving at a rate of 30FPS
(NTSC) with typical DVD resolution of 720 x 480 pixels.
In its raw form the input dimensionality at each sample is
extremely high (3 x 720 x 480 per frame) and prohibitively
large for model training. Thus, we opted to compress each
video frame into a 11 element vector which extracts selected
features (meant to capture key statistics for each frame) from
the visual content and greatly reduce the complexity of the
learning problem. The features we compute from each frame
are listed below:
• Brightness: cumulative sum of averaged RGB inten-
sities (based on pixel values).
• Flux: change in brightness between consecutive frames.
• Edge Intensity: pixelsum of a Canny Edge ﬁlter.
• FFT: slope of the best ﬁt line to an FFT.
• Color: mean and standard deviations for gaussians
ﬁtted to R, G, and B color histograms (6 params).
• Bitrate: kbits/second computed using FFMPEG.
These features were post processed in a fashion very simi-
lar to the signal conditioning of the EMI. In particular, we
performed normalization (0 to 1 scale), smoothing (Butter-
worth ﬁlter with 10kHz cutoﬀ frequency) and decimation (10
samples per second).
Network Structure. RNNs are a class of neural networks
in which intermediate layers (i.e., those separating input and
output) have connections to neighboring layers as well as
(re)connections to themselves; these properties lead to self
feedback (memory) which enable dynamic temporal behavior
[20]. At time t the network input layer consisted of a video
frame represented as a 11 element feature vector. The input
layer was connected to the ﬁrst of 3 hidden layers (connected
in succession, each composed of 11 neurons to match the
dimensionality of the input) and the ﬁnal hidden layer was
connected to a scalar output layer representing the normalized
5
time series EMI at time t.
Training.
The training phase began with randomly initial-
ized network parameters which were tuned using backpropa-
gation through time (BPTT) via the Levenberg-Marquardt
gradient method. The criterion for performance was how
well the network output matched test EMI (measured as
mean squared normalized error). Each training session con-
cluded when the optimization converged or after 50 epochs
(whichever came ﬁrst).
Results. We used our neural network to generate a
database of synthetic EMI (i.e., given only video data) and
performed matching searches using real TV EMI traces as
queries. Prior to deﬁning our training and target sets, we sys-
tematically removed the ﬁve movies with the globally lowest
self similarity measures across all TVs (Wedding Crashers,
The Hangover, Meet the Parents, Oﬃce Space, Top Gear).
This eliminates noise artifacts during training and approxi-