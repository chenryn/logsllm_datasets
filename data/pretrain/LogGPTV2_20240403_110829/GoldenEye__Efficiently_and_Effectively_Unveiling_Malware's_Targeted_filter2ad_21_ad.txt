### Adware/Spyware Statistics

| Category | 0-10% | 10-50% | 50-100% | 100%+ |
|----------|-------|--------|---------|--------|
| Adware/Spyware | 29% | 39% | 43% | 21% |
| Adware/Spyware | 16% | 27% | 19% | 94% |
| Adware/Spyware | 99% | 96% | 98% | 6% |
| Adware/Spyware | 74% | 26% | 0% | 67% |
| Adware/Spyware | 9% | 86% | 14% | 0% |
| Adware/Spyware | 3% | 84% | 16% | 0% |
| Adware/Spyware | 4% | 69% | 31% | 0% |
| Adware/Spyware | 16% | 0% | 2% | 98% |
| Adware/Spyware | 19% | 0% | 1% | 99% |
| Adware/Spyware | 8% | 0% | 0% | 100% |
| Adware/Spyware | 17% | 0% | 2% | 98% |

### Additional Data

| Category | 0% | 36% | 34% | 47% | 29% | 34% | 32% | 28% | 41% | 5% | 0% | 4% | 2% | 27% | 28% | 11% | 24% | 29% | 33% | 37% | 23% | 1% | 1% | 0% | 0% | 33% | 44% | 76% | 68% | 0% | 0% | 0% | 0% | 100% | 100% | 100% | 100% |
|----------|-----|-----|-----|-----|-----|-----|-----|-----|-----|----|----|----|----|-----|-----|-----|-----|-----|-----|-----|-----|----|----|----|----|-----|-----|-----|-----|----|----|----|----|------|------|------|------|
| Worm     | 0%  | 36% | 34% | 47% | 29% | 34% | 32% | 28% | 41% | 5% | 0% | 4% | 2% | 27% | 28% | 11% | 24% | 29% | 33% | 37% | 23% | 1% | 1% | 0% | 0% | 33% | 44% | 76% | 68% | 0% | 0% | 0% | 0% | 100% | 100% | 100% | 100% |
| Downloader | 0%  | 36% | 34% | 47% | 29% | 34% | 32% | 28% | 41% | 5% | 0% | 4% | 2% | 27% | 28% | 11% | 24% | 29% | 33% | 37% | 23% | 1% | 1% | 0% | 0% | 33% | 44% | 76% | 68% | 0% | 0% | 0% | 0% | 100% | 100% | 100% | 100% |
| Trojan   | 0%  | 36% | 34% | 47% | 29% | 34% | 32% | 28% | 41% | 5% | 0% | 4% | 2% | 27% | 28% | 11% | 24% | 29% | 33% | 37% | 23% | 1% | 1% | 0% | 0% | 33% | 44% | 76% | 68% | 0% | 0% | 0% | 0% | 100% | 100% | 100% | 100% |

### Comparison of Approaches

The results are presented in Table 3. We use the following metrics for the comparison:

1. **Increased APIs**:
   - For each approach, we select the longest trace during any single run and compare it with the normal run.
   - We record the percentage of malware samples whose increased APIs fall into the ranges 0-10%, 10-50%, 50-100%, or 100% and above.
   - **Related Work I** performs the best, as it blindly explores all possible paths and selects the path with the most APIs.
   - **Pre-configured environment (Related Work II)** seldom exposes malware's hidden behaviors, increasing only 5% more APIs on average. This confirms that predicting malware’s targeted environment beforehand is impractical.
   - Our approach significantly outperforms Related Work II and is very close to Related Work I.

2. **Number of Rollbacks**:
   - **Related Work I** requires a rollback for each environment-sensitive branch, often resulting in over 500 rollbacks per sample.
   - **GOLDENEYE** efficiently controls the number of rollbacks, with a maximum of 126 and a median of 39, saving over 90% overhead compared to multi-path exploration.

3. **Memory Usage**:
   - **Related Work I** consumes around 3.5MB memory per snapshot, with an overhead of over 5MB due to recursive context maintenance.
   - **GOLDENEYE** uses only 1-2MB, significantly reducing memory/disk overhead.

4. **Total Analysis Time**:
   - The average analysis time for GOLDENEYE is around 44 minutes, while for Related Work I, it is 394 minutes, which is approximately 9 times slower.
   - The worst-case scenario for GOLDENEYE never exceeds 175 minutes, whereas 12% of tested malware takes longer than 12 hours for Related Work I.

In summary, our approach offers a better trade-off between effectiveness and efficiency. The main reason for the higher overhead and lower effectiveness of other solutions is that they are not designed to analyze malware’s targeted environment. Our approach is more proactive and dynamic, making it more effective for targeted malware analysis.

### Experiment on Known Environment-Targeted Malware Dataset

We aim to verify that our system can extract known targeted environments for malware samples. We collected ground truth data from multiple online resources, ensuring all samples are environment-targeted. We manually examined their analysis reports and categorized the interested environment elements into five categories: System Information, Network Status, Hardware, Customized Objects, and Library/Process.

#### Table 4: Test on Targeted Malware

| Malware Sample | System | Network | Hardware | Customized Objects | Library | Process |
|----------------|--------|---------|----------|--------------------|---------|---------|
| Conficker [43] | √      | √       |          |                    |         |         |
| Zeus [21]      |        | √       |          |                    |         |         |
| Sality [12]    | √      |         |          |                    |         |         |
| Bifrost [2]    |        |         | √        |                    |         |         |
| iBank [7]      |        |         |          | √                  |         |         |
| nuclearRAT [9] |        |         |          | √                  |         |         |
| Duqu [4]       |        |         |          | √                  |         |         |
| Nitro [16]     |        |         |          | √                  |         |         |
| Qakbot [11]    |        |         |          | √                  |         |         |

#### GOLDENEYE Environment Extraction Result

| Malware Sample | System | Network | Hardware | Customized Objects | Library | Process |
|----------------|--------|---------|----------|--------------------|---------|---------|
| Conficker      | √      | √       |          |                    |         |         |
| Zeus           |        | √       |          |                    |         |         |
| Sality         | √      |         |          |                    |         |         |
| Bifrost        |        |         | √        |                    |         |         |
| iBank          |        |         |          | ◦                  |         |         |
| nuclearRAT     |        |         |          | ×                  |         |         |
| Duqu           |        |         |          | √                  |         |         |
| Nitro          |        |         |          | √                  |         |         |
| Qakbot         |        |         |          | √                  |         |         |

- **√**: Correctly Extracted
- **◦**: Similar Element
- **×**: Not Extracted

#### Caveats in the Test

1. If the documentation does not clearly mention the sample’s MD5 or the specific MD5 cannot be found online, it may lead to inaccurate measurements.
2. The extraction result is concluded in three types:
   - **Correctly Extracted**: GOLDENEYE extracts the exact same environment element.
   - **Similar Element**: GOLDENEYE finds an element with similar functionality but a different name.
   - **Not Extracted**: GOLDENEYE fails to extract the environment element.

From the results, GOLDENEYE correctly detects 41 out of 44 targeted environment elements within a 5-minute analysis limit. The failures were due to:
1. Some hardware query functions not being in our labeled API list.
2. Some element checks occurring after interaction with a remote C&C server, which may not be active during the test.

### Case Studies

We study several cases in our analysis, focusing on environment targets that trigger malware activities.

#### Targeted Location

For Conficker A, GOLDENEYE successfully captures the system call.