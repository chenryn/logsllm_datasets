can all be executed from userspace.
Virtual machines: If attackers are only able to run code
inside a virtual machine, their ability to run disclosure primi-
tives to access the staging buffer will be limited. For example,
RDMSR is likely to be restricted or prohibited entirely, and
typically VMs also trap on CPUID, to allow the hypervisor to
restrict the information and capabilities which will be reported
to the guest. However, two disclosure primitives can still be
executed from userspace in the default conﬁgurations of many
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:49 UTC from IEEE Xplore.  Restrictions apply. 
1859
virtual machines: RDRAND and RDSEED. An attacker can use
one of these primitives to leak the output of the other.
When SMT is enabled, an attacker can make hypervisor
requests that involve disclosure primitives (a form of ‘confused
deputy’ attack), and then read the staging buffer from the ﬁll
buffer. For example, Xen will call RDMSR with 0x17 (platform
ID) when a guest attempts to read MSR 0x17. Even if MDS
mitigations (such as scheduling-based isolating strategies [20])
are in place, this allows an attacker to leak the contents of the
staging buffer from the sibling thread—disclosing data of a
victim running on a different core.
SGX: Although most relevant instructions are not available
within SGX, a theoretical attacker inside an SGX enclave
could (much as in the VM case) mount a cross-core attack
using RDRAND and RDSEED.
C. Synchronization
A probing primitive allows an attacker to detect accesses to
the staging buffer and synchronize with the victim. Since we
only need to check whether the byte we leak is the byte we
expect, this can be done with a single ﬂush and a single reload,
and the performance overhead is dominated by the execution
time of our leak primitive. However, to preserve synchro-
nization, an attacker armed with our information disclosure
primitive needs to leak data from the buffer at a sufﬁciently
high sampling rate to keep up with the consumption of random
numbers by the victim.
Each RDSEED or RDRAND instruction provides a maximum
of 8 random bytes (one 64-bit register). Many applications
require a larger amount of entropy, so these instructions can
potentially be called in a loop. Both instructions take approxi-
mately 370 cycles on Skylake, so generally, an attacker will not
have enough time (assuming a relatively fast victim loop) for
an attacker to complete leaking from FLUSH + RELOAD before
it is overwritten with the next value. Since up to two bytes
can be efﬁciently obtained in a single ‘round’ on Skylake,
and an attacker can use multiple cores at once, an attacker
with access to sufﬁcient CPUs/threads may be able to leak all
8 bytes at once. Even so, it appears impractical to leak the
full entropy from a victim which executes several (or many)
RDRAND instructions in quick succession.
In practice, a single byte (or less) is sufﬁcient for many
attacks [21]. However, where it is convenient or even necessary
to leak more bytes, we can use a performance degradation
attack to slow down the victim [22]. In the following, we ﬁrst
analyze how we will actually perform these leaks efﬁciently.
Then, we show how an attacker can induce performance
degradation on a realistic victim (an SGX enclave) to mount
practical and reliable exploits.
D. Optimizing Leakage
We found that an attacker can obtain better results where
SMT is available; they can run the FLUSH + RELOAD loop
on one logical thread, and a tight loop using a leak primitive
to fetch the staging buffer (here, we used RDRAND) on the
sibling thread. Both of these threads are controlled by the
attacker and in the same security domain; the victim is running
on a different physical core. We found this to be the best
way to almost guarantee that the leaked ﬁll buffer would
contain staging buffer content. Where SMT is not available,
we need to ensure that we leak the LFB which contains the
staging buffer. On our i7-7700K, we determined that
this
occurs when we use CLFLUSH to ﬂush 15 cache lines after
running the leak primitive; note that this can be done as part
of FLUSH + RELOAD. We made use of the TAA variant of
the MDS vulnerabilities to actually leak the ﬁll buffers, since
it is fast and works even on CPUs with mitigations against
other MDS attacks. Again, see Appendix A for an example
code listing. Where TSX is unavailable, an attacker can instead
obtain ﬁll buffers using MFBDS [5].
E. Performance Degradation
There are different ways to slow down a victim performing
a target security-sensitive computation. For instance, we can
use microarchitectural proﬁling to determine the resources
the victim is bottlenecked on and ﬂush such resources (e.g.,
last-level cache lines) from another core to slow down the
victim [22], [23]. If we are speciﬁcally targeting RDSEED
instructions, we can attempt a more targeted performance
degradation attack.
Since the amount of global entropy available is limited,
calls to RDSEED are unsuccessful (returning zero) when no
entropy is currently available. An unsuccessful call does not
overwrite the previous contents of the staging buffer. Hence,
an attacker can make their own calls to RDRAND or RDSEED,
consuming entropy and increasing the time period between
successful RDSEED calls by the victim. A successful call to
RDRAND or RDSEED will overwrite the previous data in the
buffer, which means that old data cannot be leaked after this
point. However, by then, an attacker may have already read
the bytes; FLUSH + RELOAD can complete after this point.
A practical avenue to mount generic performance degrada-
tion attacks is SGX, where an attacker can slow down the
execution of a victim enclave at will by inducing frequent
exceptions [24]. As such, and given that SGX enclaves rely
on RDRAND as a source of entropy (amplifying the impact
of the attack), we do not attempt to use other performance
degradation techniques but
instead speciﬁcally target code
running in an SGX enclave in our exploit.
F. Leaking RNG Output From SGX
Since an attacker is assumed to control the entire envi-
ronment, enclave code running in Intel’s SGX is unable to
trust local sources of random data, other than RDRAND. Even
typical forms of ‘additional entropy’, such as the timestamp
counter, are unavailable in most implementations of SGX.
Intel state that CPUs which support SGX2 allow it to be
used inside enclaves, but even then, attackers can determine
and/or control (at least within a narrow range) the value of
this counter. Although a coarse “trusted clock” source is also
available (sgx_get_trusted_time), this does not appear
to be widely used and is primarily intended against replay
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:49 UTC from IEEE Xplore.  Restrictions apply. 
1860
attacks. This trusted clock is provided by CSME, which has
itself been the subject of several recent vulnerabilities [25],
[26], and Intel acknowledge that CSME secure time remains
vulnerable to physical attackers on some platforms [27].
Many enclaves and SGX-based defenses explicitly use
RDRAND [28], [29]. Other enclaves use the SGX SDK’s
sgx_read_rand function, which generates entropy in a
loop using RDRAND to generate 32-bit random numbers, and
copies the results directly into the output buffer.
Hence, by dumping RDRAND data, we can leak all
the random entropy used by arbitrary security-sensitive
code running inside an SGX enclave, allowing recovery of
cryptographically-critical data such as random nonces. As
mentioned, one option is to induce controlled exceptions on
the victim SGX enclave and single step its execution using
SGX-Step [24]. We could then sample the buffer after every
RDRAND from the very same core. However, this exploitation
strategy can be easily mitigated in software or microcode (as
we propose in Section VII-E). As such, we instead opt for an
asynchronous exploitation strategy that is signiﬁcantly harder
to mitigate. In particular, we ﬁrst induce exceptions on the
SGX enclave only to mount a performance degradation attack
and slow down the execution of the victim. Then, we use
our leak primitives from a different core to mount a hard-to-
mitigate (asynchronous) but reliable (since the victim is much
slower than the attacker) cross-core attack.
As mentioned earlier, the primary challenge for an attacker
is to leak the RDRAND results fast enough to keep up with
the victim, since the reload step (after the buffer has already
been transiently accessed) is our primary bottleneck. If we can
use exceptions to prevent an enclave from executing RDRAND
faster than we can leak it, then we can reliably leak all of the
entropy used by the enclave.
In fact, this means that we only need to degrade the perfor-
mance of an enclave when it is actively calling RDRAND–
and we found that sgx_read_rand actually makes use
of another function, do_rdrand, to actually perform the
RDRAND calls. Due to the convenient placement of these
functions in different pages in all the enclaves we inspected,
we can simply use page faults on the pages containing the
two different functions to enforce one RDRAND call at a time.
If enclave authors attempt to mitigate our attacks by using
multiple calls to RDRAND in quick succession in a single page,
we can simply resort to a “standard” SGX-Step approach.
G. Attacking Crypto In SGX
To exemplify the exploitation capabilities of our primitives,
we present a cross-core exploit leaking random nonces used
by an (EC)DSA implementation running in an SGX enclave.
Previous research [21] shows that leaking a small number of
bits of a random nonce is sufﬁcient to recover private keys,
using a small number of ECDSA signatures. We show our
exploit exceeds such expectations by recovering all of the bits,
with just a single signature.
1
2
3
4
5
6
7
8
9
10
11
12
13
void get_SignedReport(char *p_report,
sgx_ec256_signature_t *p_sig) {
sgx_ecc256_open_context(&handle);
// sign g_rpt with g_priv_key
sgx_ecdsa_sign(g_rpt, g_rpt_size,
&g_priv_key, p_sig,
handle);
// return the signature contents
memcpy(p_report, g_rpt, g_rpt_size);
}
Listing 2: SGX enclave function
An ECDSA signature consists of a pair (r, s), where r
depends only on k, and s = k−1(z +rp)†, where z is based on
the hash of the input, and p is the private key. By rewriting this
as p = (sk − z)/r, an attacker who can generate a signature
(r, s) with a known nonce k can simply solve for p.
The SGX SDK provides an sgx ecdsa sign function for per-
forming ECDSA signatures with a private key. For example, it
is used by the certify enclave function of Intel’s Provisioning
Certiﬁcate Enclave.
The default conﬁguration for
Intel’s SGX SDK per-
forms cryptographic operations using the Intel IPP crypto
library. When generating ECDSA signatures, it uses a nonce
(ephemeral key) k based on the output of sgx ipp DRNGen,
which in turn calls the sgx read rand function discussed
above. This means that k can be calculated by an attacker
who can observe the output of RDRAND.
To demonstrate this is feasible, we attack a simple victim
SGX enclave that uses sgx ecdsa sign to sign a message,
and then returns both the message and the signature (r, s).
A simpliﬁed listing of the function can be seen in Listing 2.
To perform the attack, we start executing the victim enclave,
while our exploit running on another core collects random data
from the staging buffer as described above. Speciﬁcally, we
simply use SGX-Step to cause a page fault when execution
enters the page containing do rdrand, single-step for several
instructions (to ensure RDRAND has been executed), and then
wait for 1ms to ensure that our exploit code has collected
the staging buffer. In practice, 1ms is enough time to collect
thousands of results from the staging buffer, which allowed us
to exclude noise, and differentiate the enclave-collected en-
tropy from normal system entropy. If needed, synchronization
between stepping core and the leaking core could be used to
obtain better results.
Afterwards, we possess the signature (r, s), and can im-
mediately calculate z by hashing the message. We can then
attempt to recover the private key p by trying all likely values
for k – in our case, to ﬁnd candidates for k, we simply
identiﬁed all entropy which appeared in the staging buffer at
†For simplicity, we omit details such as the requirement that all calculations
are done modulo n.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:49 UTC from IEEE Xplore.  Restrictions apply. 
1861
1
2
3
4
5
6
7
8
9
msgHash, r, s = call_enclave()
recovered_entropy = get_leaked_entropy()
z = int(msgHash, 16)
for k in recovered_entropy:
p = ((s*k - z) * inverse_mod(r, n)) % n
if attemptSign(msgHash, p, k) ==
(cid:44)→
msgHash:
print "key is: " + hex(p)
Listing 3: ECDSA key recovery
a regular interval (slightly longer than our 1ms wait period),
and made a list containing all candidates.
We implemented the key recovery step in Python, using
the ecdsa library. An overview of our attack can be seen in
Listing 3. When the SGX enclave calls Intel’s IPP crypto
library, it computes k by making 8 calls to RDRAND, using 32
bits each time. We take every possible linear sequence of 8
values in the entropy observed in the staging buffer during our
attack, compute the relevant value of k, and check whether it is
the private key (by performing the signature again ourselves).
We performed this attack on an i7-7700K CPU with up-to-
date microcode as of January 2020, and with SMT disabled.
When encountering a page fault, we attempt 10 steps (the
do rdrand function executes at least 7 instructions), wait 1ms
and then re-protect the page. Each execution of the enclave
code causes exactly 29 page faults; by running the enclave
in debug mode, we can determine that only 10 of these were
calls to do rdrand, and the remainder were other enclave code
which happened to be located on the same page (in our case,
the top-level enter enclave function). Since our attack relies
only on degrading the performance of code calling RDRAND,
and does not rely on any synchronization, the presence of these
other page faults makes no difference.
Our leak code collected between 200 and 250 identical
values from the staging buffer for every conﬁrmed RDRAND
leak (one which successfully produced the private key), when
performing 3 iterations of FLUSH + RELOAD for each byte.
After making 100 unique attempts, we successfully recovered
the private key (and reproduced the signature) after just this
single enclave run in 92 of the attempts, a success rate of
>90%. This success rate is without any synchronization on
our entropy collection, and so without ﬁltering out entropy
which was generated by code other than the target enclave.
We also do not attempt to brute-force any incorrect bytes,
since we have ample time to collect the exact contents of the
staging buffer.
Note that if a private key is generated by the SGX enclave
itself, an even simpler attack is possible; an attacker can
instead observe the random values used during creation of the
key, and directly obtain the private key. This differs only from
the above-described attack in that we compute candidates for p
directly, rather than k, and a different approach must be taken
to verify the key (e.g., computing the public key or checking a
signature). We conﬁrmed this by successfully performing such
an attack against an example enclave using Intel’s IPP library.
Although many cryptographic libraries perform ECDSA sig-
natures or compute keys in this way, some (such as OpenSSL)
compute the nonce k using both random entropy and the
contents of the private key, which prevents this attack from
succeeding; see Section VII.
H. Affected Processors
We ran CROSSTALK on many recent Intel CPUs to check
whether they are vulnerable to our attacks by checking whether
RDRAND output could be leaked across cores. As shown in
Table IV, these attacks can be performed on many Intel CPUs,
even with up-to-date microcode at the time of our research.
We could not reproduce our results on our Xeon Scalable
CPU, which does not appear to leak a ‘staging buffer’ when
microcode is reading from internal resources. Intel informs us
that these ‘server’ class CPUs, which include Xeon E5 and
E7 CPUs, are not vulnerable to our attacks.
However, our results show that a variety of desktop, laptop
and workstation CPUs are vulnerable to our attacks, including
Xeon E3 and E CPUs. These ‘client’ class CPUs are used
by some cloud providers to provide support for SGX, which
is not yet supported on Intel’s ‘server’ CPUs. Both Alibaba
and IBM offer Xeon E3 v6 CPUs (like the Xeon E3-1220
v6 we tested) with SGX support, although they only offer
them as bare-metal dedicated machines. Other cloud providers
appear to use vulnerable CPUs in shared conﬁgurations; for
example, Azure’s preview SGX support appears to use the
Xeon E-2288G, which we have shown to be vulnerable. After
disclosure Intel released a complete list of the processors
affected by this vulnerability [30].
VI. COVERT CHANNEL
As a proof-of-concept, we implemented a covert channel
using CPUID and RDRAND, which are available to userspace
applications and could be used by applications which are
sandboxed or running inside a container. It implements com-
munication between two different physical cores.
To send a character, we call RDRAND repeatedly until the
least signiﬁcant 8 bits are the character we want to transmit,
and then call CPUID to signal that we are ready. The receiver
waits until they see CPUID output in the staging buffer, leaks
the ﬁrst byte of RDRAND, and then acknowledges reception
by overwriting the ready signal with another CPUID leaf at
the same offset. We again use the code in Appendix A.