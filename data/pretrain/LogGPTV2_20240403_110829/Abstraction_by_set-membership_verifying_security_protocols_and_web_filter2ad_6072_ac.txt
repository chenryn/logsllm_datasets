val(X1, 1, X2) →→ val(X1, 0, 1) ·
val(X3, 0, 0) →→ val(X3, 1, 0) ·
iknows(inv(val(X1, 0, 1)))
iknows(inv(val(X1, 1, X2)))
→
attack
Figure 1: The transition rules of the running example (LHS) and their abstraction (RHS).
Proof. We show this by induction over reachability. It
trivially holds for the initial state. For transitions, suppose
the property holds in state S, and S →r(cid:48) S(cid:48) for some labeled
rule r(cid:48) and let σ be the rule match. Consider any c ∈ Abs
that occurs in S(cid:48) with label (b1, . . . , bN ). We show for every
1 ≤ i ≤ N : bi is true iﬀ c ∈ sI occurs in S(cid:48). We distinguish
the following cases:
• c does not occur in S, so it was freshly created by the
transition to S(cid:48). Thus there is a variable X in the
fresh variables of r(cid:48) such that Xσ = c. By deﬁnition,
X (and thus every occurrence of c in S(cid:48)) is labeled
with bi = Ri(X) which is true iﬀ Xi ∈ si is contained
in the right-hand side of r(cid:48), which is the case iﬀ c ∈ si
is contained in S(cid:48).
• c occurs in S, and for no abstractable variable X in r(cid:48)
it holds that c = Xσ. Then c is simply not touched
by the transition and has the same label and set mem-
berships in both states.
• c occurs in S, and for some abstractable variable X
(Note there may be other
in r(cid:48), we have Xσ = c.
variables Y with Y σ = c.) We further distinguish:
– X ∈ si occurs in S+. Then c ∈ si occurs in S
and there is no variable Y such that both Y σ = c
and Y /∈ si occurs in S− (otherwise r(cid:48) would not
have been applicable to S under σ).
If for any
variable Y with Y σ = c, Y ∈ si occurs in RS,
then also X ∈ si must occur in RS otherwise
the rule is not consistent (cf. Deﬁnition 4). Thus
Ri(X) and bi is true and c ∈ si is contained in S(cid:48).
Otherwise, if for no variable Y with Y σ = c, Y ∈
si is contained in RS, then by the deﬁnition there
is a label change for X in r(cid:48), namely changing at
least the ith position from true to false. Then
c ∈ si is not in S(cid:48) and bi is false.
– X /∈ si occurs in S−. Then c ∈ si does not occur
in S, and there is no variable Y with Y σ = c and
Y ∈ si in S+. Suppose for any Y with Y σ =
c, Y ∈ si occurs in RS, then also X ∈ si in
RS (otherwise the rule were again inconsistent).
Thus there is a label change in the ith position
from false to true and bi is true and c ∈ si is
contained in S(cid:48). Otherwise, X is labeled on both
sides with false for the ith component, and bi is
false, and c ∈ si does not occur in S(cid:48).
– Neither X ∈ si occurs in S+ nor X /∈ si occurs
in S−. If X ∈ si occurs in the RS, then we have
a label change in the ith position of the labeling
of X, namely from arbitrary Xi to 1. Thus bi is
1 and c ∈ si occurs in S(cid:48). Otherwise, if X ∈ si
does not occur in RS, then X is not involved in
any set conditions. Then either c stays with the
same label and set membership in the transition
from S to S(cid:48), or there is another variable Y with
Y σ = c and any of the above cases can be applied
with Y in the role of X.
• c occurs in S but there is no abstractable variable X
in r(cid:48) such that Xσ = c. Then there is no change of set
memberships of c and no label change and the property
remains that the labeling is correct.
Labeled concrete model without set conditions.
The labels are thus a correct alternative representation of
the set conditions, and as a second step we now “upgrade”
the labels from a mere annotation to a part of term struc-
ture, i.e. considering @ as a binary (inﬁx) function sym-
bol. Then, upon rule matching the label does matter. In
turn, we can remove the set conditions from our model com-
pletely, because we can always reconstruct the set member-
ships from the labels (thanks to persistence and rule form,
no abstractable constants can get lost on a transition) and
the set conditions on the left-hand side of a rule are correctly
handled by the label matching. In this labeled model without
set conditions, the second rule of our running example is:
iknows(PK @(1, X1, X2))
=[NPK @(1, 0, 0)]⇒
iknows(signinv(PK @(0,X1,X2))(new, a, NPK @(1, 0, 0))) ·
P K@(1, X1, X2) (cid:55)→ P K@(0, X1, X2)
Note how close this rule is to the abstract model, while still
being a state transition rule. It is immediate from Lemma 1
356that this changes the model only in terms of representation:
Lemma 2. The labeled model and the labeled model with-
out set conditions have the same set of reachable states mod-
ulo the representation of set conditions in labels.
The abstraction.
All the previous steps were only changing the representa-
tion of the model, but besides that the models are all equiva-
lent. Now we ﬁnally come to the actual abstraction step that
transforms the model into an abstract over-approximation.
We deﬁne a representation function η that maps terms and
facts of the concrete model to ones of the abstract model:
Deﬁnition 9.
η(t@(b1, . . . , bN )) = val(b1, . . . , bN ) for t ∈ TA
η(f (t1, . . . , tn)) = f (η(t1), . . . , η(tn))
for any function or fact symbol f of arity n
We show that the abstract rules allow for the derivation
of the abstract representation of every reachable fact f of
the concrete model:
Lemma 3. Let R be a rule set in AIF, R(cid:48) be the corre-
sponding rule set in the labeled model without set conditions
of R, f be a fact in a reachable state of R(cid:48) (i.e. ∅ →∗
R(cid:48) S
and f ∈ S for some S). Let R be the translation into
Horn clauses of the rules R according to Deﬁnition 7, and
Γ = LF P (R). Then η(f ) ∈ Γ.
Proof. Again we show this by induction over reachabil-
ity. The initial state ∅ is clear. Let now S be any reachable
state and η(f ) ∈ Γ for every f ∈ S. We show that for every
S(cid:48) that is reached by one rule application and every f ∈ S(cid:48)
also η(f ) ∈ Γ.
Let the considered rule be
r = LF =[F ]⇒ RF · LM
where LM are the label modiﬁcations (see Deﬁnition 8)—
being part of the labeled model without set conditions there
are no set conditions in the rule. By our constructions, the
Horn clauses R contain a similar rule, namely
r = η(LF ) → η(RF ) · η(LM )
where we extend η to sets of facts as expected. The extension
of η to label modiﬁcations (and sets thereof in η(LM )) is also
straightforward:
η(t@l (cid:55)→ t@l
(cid:48)
) = val(l) →→ val(l
(cid:48)
)
Let now σ be the corresponding substitution for S →r S(cid:48).
Then LF σ ⊆ S and thus η(LF σ) ⊆ η(S). Thus the Horn
clause r is applicable and therefore η(RF σ) ⊆ Γ. It remains
only to show that all the modiﬁcations of facts by the label
modiﬁcation rule are also contained in Γ.
To that end, consider any fact f [c@l] ∈ (S ∪ RF )σ that
has exactly one occurrence of c@l and LM contains the rule
t@l (cid:55)→ t@l(cid:48) for some t with tσ = c. Since l →→ l(cid:48) is part of
the term implication of r and since we have η(f [c@l]) ∈ Γ,
we also have η(f [c@l(cid:48)]) ∈ Γ. If there is more than one occur-
rence of an abstractable constant in a fact that is aﬀected
by a label modiﬁcation, then we can repeatedly apply this
argument. Note that the term implication of the (general-
ized) Horn clauses only replace one occurrence at a time.
The reason is that from the label l we cannot be sure that
all its occurrences correspond to the same constant c@l in
the concrete model, so replacement of only part of the labels
is included.
We have thus shown that all the facts in S(cid:48) are also con-
tained in Γ, modulo the representation function η.
From Lemmata 2 and 3 immediately follows that the over-
approximation is sound:
Theorem 4. Given an AIF speciﬁcation with rules R. If
an attack state is reachable with R, then attack ∈ LF P (R).
5. ENCODING TERM IMPLICATION
We show how the term implication rules that we have in-
troduced can be encoded into Horn clauses. Intuitively, the
problem is that the rule s →→ t expresses C[s] =⇒ C[t]
for any context C, and thus summarizes an inﬁnite number
of Horn clauses. However, this inﬁnite enumeration can be
avoided by limiting ourselves to ones that can be instan-
tiated to a derivable fact. This can be done using a new
constant symbol  and two new binary fact symbols occurs
and implies (i.e. these symbols do not occur in the given
speciﬁcation). occurs(p, t) expresses that t is a subterm of
some fact that holds, and either
• p is , then t is a direct subterm of a fact that holds,
or
• p is also a subterm of a fact that holds, and t is a direct
subterm of p.
Further, implies(s, t) represents a rule of the form s →→ t.
For every n-ary fact symbol f (not including occurs and
implies), every m-ary operator g, every 1 ≤ i ≤ n and every
1 ≤ j ≤ m, we have the following Horn clauses:
f (x1, . . . , xn) → occurs(, xi)
occurs(x, g(y1, . . . , ym)) → occurs(g(y1, . . . , ym), yj)
occurs(g(x1, . . . , xm), xj) · implies(xj, y)
f (x1, . . . , xn) · implies(xi, y)
→ implies(g(x1, . . . , xm), g(x1, . . . , xj−1, y, xj+1, . . . , xm))
→ f (x1, . . . , xi−1, y, xi+1, . . . , xn)
Let us call these Horn clauses R0. Consider an arbitrary set
of Horn clauses Rh and term implication rules Rt. Call R(cid:48)
t
the Horn clauses that are obtained from Rt by replacing the
consequence s →→ t by the fact implies(s, t).
Theorem 5. LFP (Rh ∪ Rt) = LFP (R0 ∪ Rh ∪ R(cid:48)
t) \
{implies(·,·), occurs(·,·)}
Proof. Let Γ = LFP (Rh ∪ Rt) and Γ(cid:48) = LFP (R0 ∪ Rh ∪
t) and Γ(cid:48)(cid:48) = Γ(cid:48) \ {implies(·,·), occurs(·,·)}.
R(cid:48)
Soundness, i.e. Γ(cid:48)(cid:48) ⊆ Γ: occurs(·, t) ∈ Γ(cid:48) only holds for
subterms t of facts in Γ and implies(t1, t2) only holds if for
any fact C[t1] ∈ Γ also C[t2] ∈ Γ holds. As a consequence,
the last rule schema of R0 can only give facts that are in Γ.
Completeness, i.e. Γ ⊆ Γ(cid:48): Suppose f ∈ Γ \ Γ(cid:48), and sup-
pose f is the “shortest” counter-example,
it can be
derived with one rule application of Rt from Γ(cid:48) (it can-
not be a rule from Rh since Γ(cid:48) is closed under Rh). Let
φ1, . . . , φn → s →→ t be that rule, σ the substitution under
which it is applied and thus f = C[tσ] for some context C[·].
By the assumption of shortest counter-example, φiσ ∈ Γ(cid:48)
and C[sσ] ∈ Γ(cid:48). Thus we also have implies(sσ, tσ) ∈ Γ(cid:48).
i.e.
357Moreover, occurs(·, u) ∈ Γ(cid:48) for all subterms of C[sσ] and by
that we have the implies(·,·) over corresponding subterms
of C[sσ] and C[tσ]. Thus, ﬁnally, C[tσ] ∈ Γ(cid:48).
6. DECIDABILITY
It is straightforward to adapt, to our AIF formalism, the
classical proof of [13] that protocol veriﬁcation is undecid-
able. This is because this proof relies only on intruder deduc-
tion rules that can be applied without any bounds. More-
over, since it does not even use fresh constants, the proof
also applies to the abstracted model of an AIF speciﬁcation.
Thus, the security of AIF speciﬁcation is undecidable both
in the concrete and abstract model.
Let us consider the restriction that all rule variables can
be instantiated only with variables of a given depth. Such
a bounding of substitutions is without loss of attacks in a
typed model that can be justiﬁed for a large class of proto-
cols by tagging [14]. For the abstract model, decidability is
now obvious, because this makes the set of derivable terms
ﬁnite. For the concrete model, however, we now show that
veriﬁcation is undecidable even when bounding the message
depth. [12] shows this for veriﬁcation in a standard multi-set
rewriting approach, but their proof cannot be carried over
to AIF immediately because AIF only supports persistent
facts and membership conditions for a ﬁxed number of sets.
We show that it is expressive enough, however, to simulate
Turing machines and thus obtain the following decidability
results:
Theorem 6. Reachability of the attack fact is undecid-
able both in the concrete and in the abstract model (even
when using no sets and fresh data). With a depth restric-
tion on substitutions, the abstract model is decidable, while
the concrete model remains undecidable.
Proof. The idea for encoding Turing machines into mess-
age-bounded AIF is that every position of the tape is mod-
eled by a fresh constant, and the symbol is carried by set
containment.
In an initialization phase, we generate an
arbitrary long but ﬁnite tape—the length is chosen non-
deterministically:2
⇒ westend(c0)
westend(c0) · c0 /∈ initializing
=[X]⇒ c0 ∈ initializing · succ(c0, X) · X ∈ current
c0 ∈ initializing · X ∈ current
=[Y ]⇒ succ(X, Y ) · Y ∈ current · c0 ∈ initializing
c0 ∈ initializing · X ∈ current =[Y ]⇒
succ(X, Y ) · eastend(Y ) · c0 ∈ current·
c0 ∈ q0 · c0 ∈ computing
where q0 is the initial state of the machine. For every ma-
chine transition (q, s) → (q(cid:48), s(cid:48), L) the rule
c0 ∈ computing · X ∈ current · X ∈ q · X ∈ s · succ(Y, X)
⇒ c0 ∈ computing · Y ∈ current · Y ∈ q(cid:48) · X ∈ s(cid:48)
The rules for moving right and neutral are similar. Addi-
tionally, when the machine reaches the eastend of the tape
(which only exists in our model), we go to a sink state of
2The ﬁniteness is not a restriction as we use a special sink
state when reaching the eastend of the tape.
the model from which no further progress can be made:
c0 ∈ computing · X ∈ current · X ∈ q · X ∈ s · eastend(X)
⇒ c0 ∈ stuck
Note that one can easily also encode an initial value of the
tape. The Turing machine can reach a certain state q, if the
concrete model has a reachable state that contains c ∈ q for
some value c. This can, of course, also be formalized by an
attack rule. For this model, a depth bound for variables of
1 (i.e. variables can only be substituted by constants) is no
restriction. As reachability of states for a Turing machine is
undecidable, so is the reachability of an attack state in the
depth bounded concrete model.
7. EXPERIMENTAL RESULTS
We have implemented the translation from AIF to a set
of Horn clauses as described in the previous sections both
for the syntax of the theorem prover SPASS and for the
syntax of the protocol veriﬁer ProVerif. This implementa-
tion along with a library of AIF speciﬁcations is available,
including more detailed descriptions of the examples pre-
sented here [17].
Recall that above we explicitly said that we want to in-
terpret terms and Horn clauses in the free algebra: terms
are interpreted as equal iﬀ they are syntactically equal. For
instance, for diﬀerent constants a and b, a = b is false. The
same is not necessarily true in ﬁrst-order logic: it rather de-
pends the structure (i.e. universe and interpretation of all
function and relation symbols) in which a formula is inter-
preted. Thus, there are interpretations in which the formula
a = b holds. A formula is valid, if it holds in all interpreta-
tions (e.g. a = b → b = a).
The SPASS theorem prover allows us to declare a list of
It will then try to
axioms φ1, . . . , φn and a conjecture φ.
prove or disprove that φ1 ∧ . . . ∧ φn =⇒ φ is valid. We