### Data Storage and Access

The data utilized in our analysis are stored at the mobile carrier within a secure facility, isolated from the Internet. Consequently, physical access is necessary for conducting each experiment. Drawing inspiration from similar sensitive measurement experiments described in the literature (e.g., [54]), we developed and tested our experimental code remotely using synthetic records. Subsequently, an authorized co-author executed the code on real data within the secure facility. Only aggregated results were extracted for further analysis. Any personally identifiable information (e.g., IP addresses) was either removed or anonymized before the records were exchanged. The User ID in the logs is an internal, unique number assigned to each subscriber, which cannot be directly linked to any personally identifiable information (e.g., IMSI or phone number). Although a correspondence table may exist at the mobile carrier, it was not required and was not accessed.

### HTTP Traffic Collection

Our analysis relies on logs collected between April 1, 2017, and June 30, 2017. During this period, out of an initial pool of 20,895 consenting participants, 20,645 distinct smartphone users appeared in the logs. The remaining participants likely did not use cellular data during this time.

Each log entry includes:
- Timestamp of the HTTP request
- URL accessed
- Content of the HTTP Referer field
- Number of bytes uploaded and downloaded
- User-agent string
- Unique user ID corresponding to the customer

#### Limitations

- The dataset does not include HTTP contents (e.g., data sent via HTTP POST) or HTTPS requests.
- Only HTTP requests with a content-type of `text/html` are included, excluding image, script, or multimedia content.
- Collection is limited to the cellular network, excluding Wi-Fi traffic.

On a positive note, the collection process is entirely passive. Users do not need to change any mobile settings, install specialized software, or take any action beyond providing initial consent. Additionally, prior research has found that most malicious web traffic is served over HTTP.

### HTTP Log Processing

We define a browsing session as a temporally contiguous set of HTTP requests made by the same user. A session is considered to end when:
1. The user-agent changes, indicating a switch in browsers.
2. The user is idle for more than 20 minutes, consistent with prior work on "click streams" [85].

A small fraction (<2.2%) of HTTP requests in our dataset originated from traditional operating systems (e.g., Windows, Mac OS) connected via tethering. We treated this traffic similarly to other traffic, as our methods are not limited to mobile devices.

Initially, we classified each HTTP request as malicious or not based on the Google Safe Browsing v3 (GSB, [31]) database. We will address the limitations of this approach, particularly the fact that malicious URLs may not yet be in the GSB, in Section 4. Given the dynamic nature of the GSB database, we downloaded daily snapshots throughout our measurement interval.

GSB distinguishes between phishing and malware URLs. Phishing URLs aim to trick users into revealing private information, while malware URLs attempt to deliver unwanted programs. In practice, some GSB-labeled phishing URLs can lead to malware downloads or ad-fraud pages. Using VirusTotal [15], we found that 20 out of 25 randomly sampled domains classified as phishing by GSB are also classified as malware by other lists. For example, hxxp://applicationg29.com, previously classified as a phishing domain, leads to a page for downloading a fake antivirus. Therefore, both types of URLs are harmful to users and online services. For the rest of this paper, we consider all such entries as malicious.

We categorized URLs visited upon each HTTP request into categories (e.g., news, sports) using the taxonomy developed by DigitalArts for their i-Filter filtering system [39]. We trained a Convolutional Neural Network [92] to classify domain names into one of 99 topics, achieving approximately 90% accuracy. Finally, we classified users as exposed or unexposed. Exposed users visited at least one malicious page during our collection interval; unexposed users did not.

### Online Survey

A key contribution of our work is validating whether self-reported responses to computer-security surveys can predict user behavior. Specifically, we explored whether survey answers can predict exposure risk. To this end, we invited 600,000 eligible customers in Japan to participate in an online survey. As an incentive, respondents had the chance to win a 500 JPY (approximately $5) gift card. We received 23,419 responses, a 3.90% response rate, which is consistent with similar online security studies.

#### Demographics

- 61.5% male, 38.5% female (solicited pool: 55.6% male, 42.8% female, 1.6% unknown)
- Median age: 43 years, standard deviation: 11.8 years
- No significant bias in demographics

We did not collect information on iOS and Android users in the survey and elected not to perform user-agent matching due to potential inaccuracies. We also eliminated responses that failed attention checks, resulting in valid answers from 20,895 distinct users.

#### Questions

- Security incidents (e.g., stolen password)
- Anti-virus installation
- Types of app marketplaces used
- Actions taken when browsers warn about malicious webpages
- Proactive awareness sub-scale of RSeBIS
- Self-confidence in computer security knowledge

The survey was conducted in Japanese, with translations provided by experts fluent in both English and Japanese.

### Exposure to Malicious Content

Our analysis of the HTTP logs aims to:
1. Determine the extent of mobile users' exposure to malicious content.
2. Demonstrate the "window of opportunity" for attackers to compromise devices before a page is blacklisted.
3. Explore differences in behavior between exposed and unexposed users.

#### Overall Prevalence of User Exposure

Among the 20,645 users, 2,172 (11%) accessed a malicious page at least once. Most (1,995) were exposed to phishing pages, 153 to malware pages, and 24 to both. Overall, exposed users visited 3,491 unique malicious pages on 201 different domains. At least 0.81% of all users were exposed to confirmed malware, but we cannot estimate the infection rate. The 11% exposure rate underscores the importance of preventing such exposure.

#### Window of Exposure

We estimated the time users might be exposed to malicious pages before defenses are in place. Our approach is similar to measuring zero-day exploits by checking telemetry data. We observed logs of accesses to URLs before they were included in the GSB database. Figure 1 shows the number of accesses as a function of time relative to inclusion in the GSB.

Key observations:
- Some deceptive pages were accessed up to 87 days before inclusion in the GSB.
- Accesses increased 38 and 22 days before inclusion.
- A large spike occurred two days before inclusion, likely due to increased detection.
- Accesses decreased after inclusion, but some continued, possibly due to ignored warnings or non-GSB-filtered browsers.

Finding 1: There is evidence of non-negligible delays—potentially up to three months—between when a page becomes malicious and when it is blacklisted. The probability of exposure increases sharply about three weeks before blacklisting and even more sharply in the couple of days prior to inclusion.