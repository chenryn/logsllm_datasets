2.35
4.95
3.58
8.8 %
38.8 %
26.8 %
22.5 %
22.0 %
23.8 %
25.0 %
19.6 %
37.5 %
48.0 %
63.0 %
34.2 %
0.0 %
31.3 %
44.9 %
5.0 %
34.0 %
25.5 %
29.0 %
31.5 %
33.6 %
Total
6365
631 10.0 % 2960
4.69
31.7 %
have the same byte-level content as the sampled video, indicating traditional
cryptographic hash-based duplicate detection has only a limited ability to detect
duplicate videos.
Table 1 also shows a breakdown of sampled videos according to three
attributes along the rows: video category, video length, and popularity. The
columns of Table 1 give diﬀerent duplicate statistics. Here “duplicate ratio” is
deﬁned as:
244
Y. Liu et al.
Fig. 5. View count distribution
Fig. 6.
Duration(sampled video)
Duration(duplicate)
Fig. 7.
ViewCount(sampled video)
ViewCount(duplicate)
duplicate ratio =
# of duplicates found
# of sampled videos + # of duplicates found
(2)
Figure 5 shows the view count (i.e., popularity) of 6, 365 sampled videos.
5, 529 (87 %) videos are viewed fewer than 1,000 times (unpopular). This sta-
tistic is consistent with the ﬁndings in Zhou et al. [8] that only 14 % of videos
in a randomly sampled YouTube dataset have a total view count of more than
1,000.
Figure 6 shows the ratio between the duration of the sampled video and the
duration of the detected duplicate video. As shown in the ﬁgure, most duplicates
have the same duration as the sampled video. For Short, Medium, and Long
videos respectively, 1, 743 out of 2, 310 (75 %), 375 out of 596 (63 %), and 19 out
of 54 (35 %) have the same durations as the sampled video. For Long videos,
more than 40 % of their duplicates are shorter than the sampled video. These
shorter duplicates are excerpts from longer videos, extracted by users to meet
the video duration limits imposed by YouTube. Overall, among all the duplicates
found, 72 % have the same duration as the sampled video, indicating that
excerption occurs less frequently than operations that preserve the length of the
video.
We are also interested in determining if sets of duplicates have similar popu-
larities. Figure 7 shows the view count ratios of sampled videos versus those of
searched videos. Approximately 55 % of the searched video duplicates are
watched more frequently than the sampled video. These diﬀering frequencies
indicate that even if duplicates represent the same or similar visual content, the
popularities of individual copies of the same video can vary.
5.2 Uniqueness of Sampled Videos
Given that our duplicate assessment found that approximately one-third of the
videos in the YouTube database are duplicates, it seems counter-intuitive that
our original assumption holds that each of our 6, 365 sampled videos is unique.
A relatively short analysis, however, shows that this is a reasonable assumption.
This analysis is a specialization of the well-known Birthday paradox. Our setting
diﬀers from the standard Birthday paradox, where we would assume a uniform
distribution over birthdays. In our setting, a large number of people have a
unique birthday (i.e., a large number of videos have no duplicates and will be
A Quantitative Study of Video Duplicate Levels in YouTube
245
unique in our sample of 6, 365). The probability that two or more people in a
sample share a birthday, given this highly unbalanced distribution of birthdays,
can be computed using a recurrence which we describe below:
R(N, T ) =
⎧
(1 − q(T )) × (cid:7)
⎪⎨
⎪⎩
1
(1 − p) × R(N − 1, T )
(cid:8)
+ p × R(N − 1, T + 1)
if N > 0
if N = 0
(3)
where R(N, T ) indicates the probability that a sample of N videos does not
contain any duplicates, given that we have already drawn T videos that are
associated with copies in the YouTube database (or any video database), where
each of these T videos is distinct. The recurrence captures the idea that, if
we do not wish to include duplicates in our sample of original videos, we must
ﬁrst draw a non-duplicate given the set of T previously drawn videos associated
with a duplicate in the video database with probability 1 − q(T ). This video
must then be selected either from the set of videos with no associated duplicates
with probability 1 − p or from the set of videos that has at least one duplicate
with probability p.
The base case is R(0, T ) = 1, where have already drawn T videos that are
associated with duplicates in the YouTube database, and we have no further
videos that need to be selected.
To evaluate this recurrence, we ﬁrst need to estimate the total number of
videos in YouTube. During the random sampling phase, we retrieved 6, 365
unique video IDs using 1000 randomly generated preﬁxes. Using the method
proposed by Zhou et al. [8], we estimated the total number of videos on YouTube
≈ 849 million, indicating there were approximately 849 million
as 384 × 64× 6365
videos on YouTube at the time we collected the data (July 2013).
1000
Our measurement results indicate that approximately 10 % of the original
videos on YouTube have duplicates, meaning that we should set p = 0.1 in the
computation above. Given our result from the previous section, that each video
having one or more duplicates has on average, approximately 4.69 duplicates
associated with it, we can estimate the probability of drawing a duplicate for
given video as
Evaluating the above recurrence using a dynamic programming method for
181×106 and p = 0.1 yields R(6365, 0) = 0.989. This result means that
q(T ) =
if we resampled the set of 6, 365 videos over 100 separate trials, then we would
expect this set of 6, 365 sampled videos to contain duplicates in fewer than two
of these trials.
849×106 ≈
4.69
Further, we examined the set of sampled videos by ﬁrst querying the set of
searched video VIDs to determine if any match a sampled video VID. For the
small set of VIDs that matched, we ran a further DTW comparison. This DTW
phase produced much larger DTW distances than the duplicate threshold for all
pairs of videos examined, indicating that none of the 6, 365 sampled videos were
duplicates. We also performed a manual conﬁrmation step, providing further
evidence that the 6, 365 sampled videos are unique.
1
181×106 .
T
246
Y. Liu et al.
5.3 Extra Storage Space Occupied by Duplicate Videos
A direct negative impact of video duplication is the extra storage space consumed
by duplicate videos. To estimate the percentage of additional space needed by
YouTube to store duplicate videos, we grouped each sampled video and its
corresponding duplicates into a duplicate set, denoted by D. If no duplicates were
associated with a sampled video, v, then we constructed the duplicate set, D,
to contain only v, i.e., D = {v}. For each duplicate set, we selected the video with
the largest ﬁle size to be the representative video. We denote the set of all
duplicate sets by D and the representative video of set D by Dr. Note that
for all videos, we only retrieved the H.264 Baseline/AAC/MP4/360p version,
thus encoding rates for all videos in our dataset should be similar. Short videos
in D will likely be sub-videos of longer videos in D. Therefore selecting the video
with the largest ﬁle size as the representative video means that the other,
shorter, videos in the set are subvideos of the representative video. Given
these duplicate sets and corresponding representative videos, we computed
the space used to store duplicates as a percentage of the total storage space as
follows:
(cid:9)
1 −
(cid:9)
D∈D size(Dr)
(cid:9)
D∈D
d∈D size(d)
(4)
Our results show that the total size of representative videos is 91.9 GB, and
the total size of all videos in all duplicate sets is 121.0 GB. These space require-
ments indicate that roughly 24.0 % YouTube storage is occupied by duplicates.
6 Conclusion
Duplicate videos within large-scale video sharing services have wide ranging
potential impacts on data center and network level storage, caching, and energy
consumption. A critical ﬁrst step in determining the true cost of video duplica-
tion involves accurate measurement of duplicate levels.
In this work, we proposed a set of techniques for assessing duplicate lev-
els within large-scale video sharing services. These techniques combined video
sampling, video search, computing pairwise video similarity through a variation
of dynamic time warping, and a manual validation step. Applying these tech-
niques on YouTube produces a duplicate ratio estimate of 31.7 %. Furthermore,
we calculate that these duplicates occupy 24.0 % of YouTube’s video data stor-
age. These relatively high levels of duplication indicate that further work should
be conducted to evaluate speciﬁc system-level tradeoﬀs associated with datacen-
ter costs, as well as network-related concerns such as performance of in-network
caching under assessed duplicate levels.
To allow duplicate assessment on ever-increasing video databases, we plan
to extend our video duplicate assessment techniques so they can scale to much
larger video samples. A potentially necessary step toward scaling this assessment
would involve developing a system to index videos by semantic content. This
type of indexing system would be essential for reducing the number of video
A Quantitative Study of Video Duplicate Levels in YouTube
247
pairs that would need to be evaluated by a computationally-expensive pairwise
video comparison technique.
Acknowledgements. We appreciate constructive comments from anonymous referees
and our shepherd Dongsu Han. The work is partially supported by High-Tech Research
and Development Program of China (“863 China Cloud” Major Program) under grant
SQ2015AAJY1595, by China NSF under grant 61471217, by China Postdoctoral Sci-
ence Fund under grant 2014M550735, and by NSF under grants CNS-0746649 and
CNS-1117300.
References
1. FFmpeg. http://www.ﬀmpeg.org/
2. Sandvine Global Internet Phenomena Report 1H 2014. https://www.sandvine.
com/downloads/general/global-internet-phenomena/2014/1h-2014-global-internet-
phenomena-report.pdf.
3. YouTube Statistics. http://www.youtube.com/yt/press/statistics.html
4. Bolosky, W.J., Corbin, S., Goebel, D., Douceur, J.R.: Single instance storage in
windows 2000. In: Proceedings of USENIX WSS (2000)
5. Douze, M., Gaidon, A., Jegou, H., Marsza(cid:4)lek, M., Schmid, C., et al.: Inria-lears
video copy detection system. In: TREC Video Retrieval Evaluation (TRECVID
Workshop) (2008)
6. Dubnicki, C., Gryz, L., Heldt, L., Kaczmarczyk, M., Kilian, W., Strzelczak, P.,
Szczepkowski, J., Ungureanu, C., Welnicki, M.: HYDRAstor: a scalable secondary
storage. In: Proceedings of USENIX FAST (2009)
7. Hampapur, A., Hyun, K., Bolle, R.M.: Comparison of sequence matching tech-
niques for video copy detection. In: Electronic Imaging 2002, pp. 194–201. Inter-
national Society for Optics and Photonics (2001)
8. Zhou, J., Li, Y., Adhikari, V.K., Zhang, Z.-L.: Counting YouTube videos via ran-
dom preﬁx sampling. In: Proceedings of ACM IMC (2011)
9. J´egou, H., Douze, M., Gravier, G., Schmid, C., Gros, P., et al.: Inria lear-texmex:
video copy detection task. In: Proceedings of the TRECVid 2010 Workshop (2010)
10. Jin, K., Miller, E.L.: The eﬀectiveness of deduplication on virtual machine disk
images. In: Proceedings of ACM SYSTOR (2009)
11. Kathpal, A., Kulkarni, M., Bakre, A.: Analyzing compute vs. storage tradeoﬀ for
video-aware storage eﬃciency. In: Proceedings of USENIX HotStorage (2012)
12. Katiyar, A., Weissman, J.: ViDeDup: an application-aware framework for video
de-duplication. In: Proceedings of USENIX HotStorage (2011)
13. Lowe, D.G.: Object recognition from local scale-invariant features. In: Proceedings
of IEEE ICCV, vol. 2, pp. 1150–1157 (1999)
14. Mikolajczyk, K., Schmid, C.: A performance evaluation of local descriptors. IEEE
Trans. Pattern Anal. Mach. Intell. 27(10), 1615–1630 (2005)
15. Sakoe, H., Chiba, S.: Dynamic programming algorithm optimization for spoken
word recognition. IEEE Trans. Acoust. Speech Sign. Proces. 26(1), 43–49 (1978)
16. Shen, H.T., Zhou, X., Huang, Z., Shao, J., Zhou, X.: UQLIPS: a real-time near-
duplicate video clip detection system. In: Proceedings of ACM VLDB (2007)
17. Shen, S.-H., Akella, A.: An information-aware QoE-centric mobile video cache. In:
Proceedings of ACM MobiCom (2013)
248
Y. Liu et al.
18. Ungureanu, C., Atkin, B., Aranya, A., Gokhale, S., Rago, S., Cakowski, G.,
Dubnicki, C., Bohra, A.: HydraFS: a high-throughput ﬁle system for the HYDRAs-
tor content-addressable storage system. In: Proceedings of USENIX FAST (2010)
19. Wu, X., Ngo, C.-W., Hauptmann, A.G., Tan, H.-K.: Real-time near-duplicate elim-
ination for web video search with content and context. IEEE Trans. Multimed.
11(2), 196–207 (2009)
20. Wu, X., Hauptmann, A.G., Ngo, C.-W.: Practical elimination of near-duplicates
from web video search. In: Proceedings of ACM Multimedia (2007)
21. Yang, J., Jiang, Y.-G., Hauptmann, A.G., Ngo, C.-W.: Evaluating bag-of-visual-
words representations in scene classiﬁcation. In: Proceedings of ACM MIR (2007)
22. Zauner, C.: Implementation and benchmarking of perceptual image hash functions.
Master’s thesis, Upper Austria University of Applied Sciences, Hagenberg Campus,
43 (2010)
23. Zhu, B., Li, K.: Avoiding the disk bottleneck in the data domain deduplication ﬁle
system. In: Proceedings of USENIX FAST (2008)