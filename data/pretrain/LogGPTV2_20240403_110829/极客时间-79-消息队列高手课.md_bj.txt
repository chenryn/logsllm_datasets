## 注册中心是如何实现的？我们先来看看注册中心是如何实现的。一般来说，一个完整的注册中心也是分为客户端和服务端两部分的，客户端给调用方提供API，并实现与服务端的通信；服务端提供真正的业务功能，记录每个 RPC服务发来的注册信息，并保存到它的元数据中。当有客户端来查询服务地址的时候，它会从元数据中获取服务地址，返回给客户端。由于注册中心并不是这个 RPC框架的重点内容，所以在这里，我们只实现了一个单机版的注册中心，它只有客户端没有服务端，所有的客户端依靠读写同一个元数据文件来实现元数据共享。所以，我们这个注册中心只能支持单机运行，并不支持跨服务器调用。``{=html}但是，我们在这里，同样采用的是"面向接口编程"的设计模式，这样，你可以在不改动一行代码的情况下，就可以通过增加一个SPI插件的方式，提供一个可以跨服务器调用的真正的注册中心实现，比如说，一个基于HTTP协议实现的注册中心。我们再来复习一下，这种面向接口编程的设计是如何在注册中心中来应用的。首先，我们在 RPC 服务的接入点，接口 RpcAccessPoint中增加一个获取注册中心实例的方法：    public interface RpcAccessPoint extends Closeable{    /**     * 获取注册中心的引用     * @param nameServiceUri 注册中心 URI     * @return 注册中心引用     */    NameService getNameService(URI nameServiceUri);     // ...}这个方法的参数就是注册中心的URI，也就是它的地址，返回值就是访问这个注册中心的实例。然后我们再给NameService 接口增加两个方法：    public interface NameService {     /**     * 所有支持的协议     */    Collection supportedSchemes();     /**     * 连接注册中心     * @param nameServiceUri 注册中心地址     */    void connect(URI nameServiceUri);     // ...}其中 supportedSchemes方法，返回可以支持的所有协议，比如我们在这个例子中的实现，它的协议是"file"。connect方法就是给定注册中心服务端的 URI，去建立与注册中心服务端的连接。下面我们来看获取注册中心的方法 getNameService的实现，它的实现也很简单，就是通过 SPI 机制加载所有的 NameService的实现类，然后根据给定的 URI中的协议，去匹配支持这个协议的实现类，然后返回这个实现的引用就可以了。由于这部分实现是通用并且不会改变的，我们直接把实现代码放在RpcAccessPoint 这个接口中。这样我们就实现了一个可扩展的注册中心接口，系统可以根据 URI中的协议，动态地来选择不同的注册中心实现。增加一种注册中心的实现，也不需要修改任何代码，只要按照SPI 的规范，把协议的实现加入到运行时 CLASSPATH 中就可以了。（这里设置CLASSPATH 的目的，在于告诉 Java执行环境，在哪些目录下可以找到你所要执行的 Java 程序所需要的类或者包。）我们这个例子中注册中心的实现类是LocalFileNameService，它的实现比较简单，就是去读写一个本地文件，实现注册服务registerService 方法时，把服务提供者保存到本地文件中；实现查找服务lookupService时，就是去本地文件中读出所有的服务提供者，找到对应的服务提供者，然后返回。这里面有一点需要注意的是，由于这个本地文件它是一个共享资源，它会被 RPC框架所有的客户端和服务端并发读写。所以，这时你要怎么做呢？对，**必须要加锁！**由于我们这个文件可能被多个进程读写，所以这里不能使用我们之前讲过的，编程语言提供的那些锁，原因是这些锁只能在进程内起作用，它锁不住其他进程。我们这里面必须使用由操作系统提供的文件锁。这个锁的使用和其他的锁并没有什么区别，同样是在访问共享文件之前先获取锁，访问共享资源结束后必须释放锁。具体的代码你可以去查看LocalFileNameService 这个实现类。
## RPC 服务是怎么实现的？接下来，我们再来看看 RPC 服务是怎么实现的。RPC 服务也就是 RPC框架的服务端。我们在之前讲解这个 RPC 框架的实现原理时讲到过，RPC框架的服务端主要需要实现下面这两个功能：1.  服务端的业务代码把服务的实现类注册到 RPC 框架中 ;2.  接收客户端桩发出的请求，调用服务的实现类并返回结果。把服务的实现类注册到 RPC框架中，这个逻辑的实现很简单，我们只要使用一个合适的数据结构，记录下所有注册的实例就可以了，后面在处理客户端请求的时候，会用到这个数据结构来查找服务实例。然后我们来看，RPC 框架的服务端如何来处理客户端发送的 RPC请求。首先来看服务端中，使用 Netty 接收所有请求数据的处理类RequestInvocation 的 channelRead0 方法。    @Overrideprotected void channelRead0(ChannelHandlerContext channelHandlerContext, Command request) throws Exception {    RequestHandler handler = requestHandlerRegistry.get(request.getHeader().getType());    if(null != handler) {        Command response = handler.handle(request);        if(null != response) {            channelHandlerContext.writeAndFlush(response).addListener((ChannelFutureListener) channelFuture -> {                if (!channelFuture.isSuccess()) {                    logger.warn("Write response failed!", channelFuture.cause());                    channelHandlerContext.channel().close();                }            });        } else {            logger.warn("Response is null!");        }    } else {        throw new Exception(String.format("No handler for request with type: %d!", request.getHeader().getType()));    }}这段代码的处理逻辑就是，根据请求命令的 Hdader 中的请求类型 type，去requestHandlerRegistry 中查找对应的请求处理器RequestHandler，然后调用请求处理器去处理请求，最后把结果发送给客户端。这种通过"请求中的类型"，把请求分发到对应的处理类或者处理方法的设计，我们在RocketMQ 和 Kafka的源代码中都见到过，在服务端处理请求的场景中，这是一个很常用的方法。我们这里使用的也是同样的设计，不同的是，我们使用了一个命令注册机制，让这个路由分发的过程省略了大量的if-else 或者是 switch代码。这样做的好处是，可以很方便地扩展命令处理器，而不用修改路由分发的方法，并且代码看起来更加优雅。这个命令注册机制的实现类是RequestHandlerRegistry，你可以自行去查看。因为我们这个 RPC 框架中只需要处理一种类型的请求：RPC请求，所以我们只实现了一个命令处理器：RpcRequestHandler。这部分代码是这个RPC框架服务端最核心的部分，你需要重点掌握。另外，为了便于你理解，在这里我只保留了核心业务逻辑，你在充分理解这部分核心业务逻辑之后，可以再去查看项目中完整的源代码，补全错误处理部分。我们先来看它处理客户端请求，也就是这个 handle 方法的实现。    @Overridepublic Command handle(Command requestCommand) {    Header header = requestCommand.getHeader();    // 从 payload 中反序列化 RpcRequest    RpcRequest rpcRequest = SerializeSupport.parse(requestCommand.getPayload());    // 查找所有已注册的服务提供方，寻找 rpcRequest 中需要的服务    Object serviceProvider = serviceProviders.get(rpcRequest.getInterfaceName());    // 找到服务提供者，利用 Java 反射机制调用服务的对应方法    String arg = SerializeSupport.parse(rpcRequest.getSerializedArguments());    Method method = serviceProvider.getClass().getMethod(rpcRequest.getMethodName(), String.class);    String result = (String ) method.invoke(serviceProvider, arg);    // 把结果封装成响应命令并返回    return new Command(new ResponseHeader(type(), header.getVersion(), header.getRequestId()), SerializeSupport.serialize(result));    // ...}1.  把 requestCommand 的 payload 属性反序列化成为 RpcRequest；2.  根据 rpcRequest 中的服务名，去成员变量 serviceProviders    中查找已注册服务实现类的实例；3.  找到服务提供者之后，利用 Java 反射机制调用服务的对应方法；4.  把结果封装成响应命令并返回，在 RequestInvocation    中，它会把这个响应命令发送给客户端。再来看成员变量 serviceProviders，它的定义是：Map\ serviceProviders。它实际上就是一个Map，Key 就是服务名，Value 就是服务提供方，也就是服务实现类的实例。这个Map 的数据从哪儿来的呢？我们来看一下 RpcRequestHandler 这个类的定义：    @Singletonpublic class RpcRequestHandler implements RequestHandler, ServiceProviderRegistry {    @Override    public synchronized  void addServiceProvider(Class serviceClass, T serviceProvider) {        serviceProviders.put(serviceClass.getCanonicalName(), serviceProvider);        logger.info("Add service: {}, provider: {}.",                serviceClass.getCanonicalName(),                serviceProvider.getClass().getCanonicalName());    }    // ...}可以看到，这个类不仅实现了处理客户端请求的 RequestHandler接口，同时还实现了注册 RPC 服务 ServiceProviderRegistry接口，也就是说，RPC 框架服务端需要实现的两个功能------注册 RPC服务和处理客户端 RPC 请求，都是在这一个类 RpcRequestHandler中实现的，所以说，这个类是这个 RPC 框架服务端最核心的部分。成员变量serviceProviders 这个 Map 中的数据，也就是在 addServiceProvider这个方法的实现中添加进去的。还有一点需要注意的是，我们 RpcRequestHandler 上增加了一个注解\@Singleton，限定这个类它是一个单例模式，这样确保在进程中任何一个地方，无论通过ServiceSupport 获取 RequestHandler 或者 ServiceProviderRegistry这两个接口的实现类，拿到的都是 RpcRequestHandler这个类的唯一的一个实例。这个 \@Singleton 的注解和获取单例的实现在ServiceSupport 中，你可以自行查看代码。顺便说一句，在 Spring中，也提供了单例 Bean 的支持，它的实现原理也是类似的。
## 小结以上就是实现这个 RPC 框架服务端的全部核心内容，照例我们来做一个总结。首先我们一起来实现了一个注册中心，注册中心的接口设计采用了依赖倒置的设计原则（也就是"面向接口编程"的设计），并且还提供了一个"根据URI协议，自动加载对应实现类"的机制，使得我们可以通过扩展不同的协议，增加不同的注册中心实现。这种"通过请求参数中的类型，来动态加载对应实现"的设计，在我们这个 RPC框架中不止这一处用到，在"处理客户端命令并路由到对应的处理类"这部分代码中，使用的也是这样一种设计。在 RPC框架的服务端处理客户端请求的业务逻辑中，我们分两层做了两次请求分发：1.  在 RequestInvocation 类中，根据请求命令中的请求类型    (command.getHeader().getType())，分发到对应的请求处理器    RequestHandler 中；2.  RpcRequestHandler 类中，根据 RPC 请求中的服务名，把 RPC    请求分发到对应的服务实现类的实例中去。这两次分发采用的设计是差不多的，但你需要注意的是，这并不是一种过度设计。原因是，我们这两次分发分别是在不同的业务抽象分层中，第一次分发是在服务端的网络传输层抽象中，它是网络传输的一部分，而第二次分发是RPC 框架服务端的业务层，是 RPC框架服务端的一部分。良好的分层设计，目的也是让系统各部分更加的"松耦合，高内聚"。
## 思考题这节课的课后作业，我们来继续写代码。需要你实现一个 JDBC协议的注册中心，并加入到我们的 RPC框架中。加入后，我们的注册中心就可以使用一个支持 JDBC 协议的数据库（比如MySQL）作为注册中心的服务端，实现跨服务器的服务注册和查询。要求：1.  调用 RpcAccessPoint.getNameService()    方法，获取注册中心实例时，传入的参数就是 JDBC 的    URL，比如："jdbc:mysql://127.0.0.1/mydb";2.  不能修改 RPC 框架的源代码 ;3.  实现必须具有通用性，可以支持任意一种 JDBC 数据库。欢迎你在评论区留言，分享你的代码。感谢阅读，如果你觉得这篇文章对你有一些启发，也欢迎把它分享给你的朋友。![](Images/4daea3d1a08e48460d8df87c2a766cef.png){savepage-src="https://static001.geekbang.org/resource/image/de/23/de0a489e6b4fa9a49450bf9197593423.jpg"}
# 35 \| 答疑解惑（三）：主流消息队列都是如何存储消息的？你好，我是李玥。在我们一起做了两个实践案例以后，相信你或多或少都会有一些收获。在学习和练习这两个实践案例中，我希望你收获的不仅仅是流计算和RPC框架的设计实现原理，还能学会并掌握在实现这些代码过程中，我们用到的很多设计模式和编码技巧，以及代码背后无处不在的"松耦合"、"拥抱变化"这些设计思想。最重要的是，把这些学到的东西能最终用在你编写的代码中，才是真正的收获。照例，在每一模块的最后一节课，我们安排热点问题答疑，解答同学们关注比较多的一些问题。
## 1. 主流消息队列都是如何存储消息的？我在之前的课程中提到过，现代的消息队列它本质上是一个分布式的存储系统。那决定一个存储系统的性能好坏，最主要的因素是什么？就是它的存储结构。很多大厂在面试的时候，特别喜欢问各种二叉树、红黑树和哈希表这些你感觉平时都用不到的知识，原因是什么？其实，无论是我们开发的应用程序，还是一些开源的数据库系统，在数据量达到一个量级之上的时候，决定你系统整体性能的往往就是，你用什么样的数据结构来存储这些数据。而大部分数据库，它最基础的存储结构不是树就是哈希表。即使你不去开发一个数据库，在设计一个超大规模的数据存储的时候，你也需要掌握各种数据库的存储结构，才能选择一个适合你的业务数据的数据库产品。所以，掌握这些最基础的数据结构相关的知识，是很有必要的，不仅仅是为了应付面试。``{=html}在所有的存储系统中，消息队列的存储可能是最简单的。每个主题包含若干个分区，每个分区其实就是一个WAL（Write AheadLog），写入的时候只能尾部追加，不允许修改。读取的时候，根据一个索引序号进行查询，然后连续顺序往下读。接下来我们看看，几种主流的消息队列都是如何设计它们的存储结构的。先来看 Kafka，Kafka 的存储以 Partition 为单位，每个 Partition包含一组消息文件（Segmentfile）和一组索引文件（Index），并且消息文件和索引文件一一对应，具有相同的文件名（但文件扩展名不一样），文件名就是这个文件中第一条消息的索引序号。每个索引中保存索引序号（也就是这条消息是这个分区中的第几条消息）和对应的消息在消息文件中的绝对位置。在索引的设计上，Kafka采用的是稀疏索引，为了节省存储空间，它不会为每一条消息都创建索引，而是每隔几条消息创建一条索引。写入消息的时候非常简单，就是在消息文件尾部连续追加写入，一个文件写满了再写下一个文件。查找消息时，首先根据文件名找到所在的索引文件，然后用二分法遍历索引文件内的索引，在里面找到离目标消息最近的索引，再去消息文件中，找到这条最近的索引指向的消息位置，从这个位置开始顺序遍历消息文件，找到目标消息。可以看到，寻址过程还是需要一定时间的。一旦找到消息位置后，就可以批量顺序读取，不必每条消息都要进行一次寻址。然后我们再来看一下 RocketMQ，RocketMQ 的存储以 Broker为单位。它的存储也是分为消息文件和索引文件，但是在 RocketMQ 中，每个Broker 只有一组消息文件，它把在这个 Broker上的所有主题的消息都存在这一组消息文件中。索引文件和 Kafka一样，是按照主题和队列分别建立的，每个队列对应一组索引文件，这组索引文件在RocketMQ 中称为 ConsumerQueue。RocketMQ中的索引是定长稠密索引，它为每一条消息都建立索引，每个索引的长度（注意不是消息长度）是固定的20 个字节。写入消息的时候，Broker上所有主题、所有队列的消息按照自然顺序追加写入到同一个消息文件中，一个文件写满了再写下一个文件。查找消息的时候，可以直接根据队列的消息序号，计算出索引的全局位置（索引序号x 索引固定长度20），然后直接读取这条索引，再根据索引中记录的消息的全局位置，找到消息。可以看到，这里两次寻址都是绝对位置寻址，比Kafka 的查找是要快的。![](Images/3ead94f91b4e5be0ae7362ce7ed9a10c.png){savepage-src="https://static001.geekbang.org/resource/image/34/60/343e3423618fc5968405e798b7928660.png"}对比这两种存储结构，你可以看到它们有很多共通的地方，都是采用消息文件 +索引文件的存储方式，索引文件的名字都是第一条消息的索引序号，索引中记录了消息的位置等等。在消息文件的存储粒度上，Kafka以分区为单位，粒度更细，优点是更加灵活，很容易进行数据迁移和扩容。RocketMQ以 Broker为单位，较粗的粒度牺牲了灵活性，带来的好处是，在写入的时候，同时写入的文件更少，有更好的批量（不同主题和分区的数据可以组成一批一起写入），更多的顺序写入，尤其是在Broker 上有很多主题和分区的情况下，有更好的写入性能。索引设计上，RocketMQ 和 Kafka分别采用了稠密和稀疏索引，稠密索引需要更多的存储空间，但查找性能更好，稀疏索引能节省一些存储空间，代价是牺牲了查找性能。可以看到，两种消息队列在存储设计上，有不同的选择。大多数场景下，这两种存储设计的差异其实并不明显，都可以满足需求。但是在某些极限场景下，依然会体现出它们设计的差异。比如，在一个Broker 上有上千个活动主题的情况下，RocketMQ的写入性能就会体现出优势。再比如，如果我们的消息都是几个、十几个字节的小消息，但是消息的数量很多，这时候Kafka 的稀疏索引设计就能节省非常多的存储空间。