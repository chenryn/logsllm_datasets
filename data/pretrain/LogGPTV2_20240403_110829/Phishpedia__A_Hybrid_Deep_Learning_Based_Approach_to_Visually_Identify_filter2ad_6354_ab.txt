lt in the target brand list is higher than a predeﬁned threshold
q, then we report the corresponding brand as the phishing
Figure 5: Phishing target brand distribution (CDF), based
on (cid:24)30K collected phishing webpages. The top 5 phishing
brands are Microsoft (7962), Paypal (4811), Chase Personal
Banking (1085), Facebook (993), and Amazon (807).
target brand. In general, how accurately can we recognize
the brand logo we detect, partially depends on the number
of brands under protection. Since there are many brands in
the world, the general brand recognition may require a very
long target brand list. However, we argue that the length of
the target brand list is not necessarily that long. First, our
empirical study on around 30K phishing webpages based on
OpenPhish feed (Section 5.1) shows that the top 100 brands
cover 95.8% phishing webpages; see Figure 5. This empirical
result is aligned with the intuition that for phishing activities
to be proﬁtable, the attackers would have to target well-known
large enterprises or ﬁnancial entities [47]. Besides, a user can
add new brands along with their logos and domain names
(e.g., local banks) to customize the protected target list.
Logo comparison. The key technical challenge here is to esti-
mate the similarity of two logos. One straightforward solution
is to consider logo recognition as an image classiﬁcation task,
where the input is a logo image and the output is its brand.
However, image classiﬁcation models have two inherent draw-
backs. First, classiﬁcation models cannot support adding a
new brand in the target brand list during runtime [56]. Once
we add a new brand, we need to retrain the whole network.
Second, and more importantly, classiﬁcation models need us
to pre-deﬁne classes (i.e., brands in our settings). Thus, given
a logo with an unseen brand in the training dataset, the model
will always classify it as one of existing brands, which can
cause large false positives in real-world application.
In this work, we choose Siamese neural network model [18,
33, 70] to address the above challenges. In general, a Siamese
neural network model transforms an image into a representa-
tive vector; thus the similarity of two images can be estimated
by the similarity of their representative vectors (e.g., cosine
similarity). Typically, a Siamese model is trained by feeding
3796    30th USENIX Security Symposium
USENIX Association
Backbone NetworkInput (Webpage Screenshot)Region Proposal NetworkFast RCNN ModelOutput Feature MapooCLCIobjectness & boundary informationclassification & refined boundary information0.20.250.30.350.40.450.50.550.60.650.70.750.80.850.90.95111325374961738597109121133145157169181193205217229241253265277Fraction of Occupied Phishing WebpagesIndex of Ranked Brands (by phishing frequency in desceding order)the model with a pair of images. A positive sample is a pair
of images of the same class and a negative sample is a pair of
images of different classes. Then, a loss function (e.g., Triplet
loss [65]) that predicts high scores for positive samples and
low scores negative samples is employed.
(a) v1
(b) v2
(c) v3
Figure 6: Logo Variants for Adobe Brand
However, our experiments show that training a Siamese
model for comparing logos through the above conventional
way is ineffective. The conventional training procedure for
Siamese model selects three images hIc1, I0
c1, Ic2i as a sample
to calculate Triplet loss [65], where Ic1 and I0
c1 belong to class
c1, and Ic2 belongs to class c2. The goal of training is to make
sure the similarity of images in the same class (sim(Ic1;I0
c1))
should be larger than that in different classes (sim(Ic1;Ic2)).
The challenge in applying such training procedure lies in the
fact that the logos under the same brand can be very different
(e.g., Figure 6). It is difﬁcult to force the model to learn
similar representative vectors for different logo variants of the
same brand (e.g., Figure 6a and Figure 6b). Indeed, from the
experiments we carried out, we observe that if we force the
model to achieve this challenging goal, it incurs the side effect
of predicting brands of different classes as similar. Readers
can refer to Section 5.5 for the performance of conventional
Siamese model training procedure.
In this work, we leverage transfer learning [53, 54] to ad-
dress the above challenges. As shown in Figure 7, we ﬁrst
design a logo classiﬁcation task so that the backbone network
(e.g., Resnetv2 network [29]) captures the features of logo
images. Through the classiﬁcation task, we allow the model
to extract different features from different logo variants of the
same brand. We connect the backbone network with a fully
connected network with one hidden layer. We use Logo2K+
dataset [75] to train this task for classifying 2341 brands.
Then, we take the backbone network as a base and connect
it with a global average pooling (GAP) layer to construct a
representative vector of 2048 dimensions. The GAP layer
aggregates the feature map output from backbone network
and represents semantic features of logo images. Thus, differ-
ent representative vectors are learned for very dissimilar logo
variants (e.g., those in Figure 6). Without enforcing the model
to learn a uniﬁed representative vector for dissimilar images,
we avoid the risk of introducing false logo-matching results.
We then compute the cosine similarity of the representative
vectors of two logo images as their similarity.
Finally, to perform the logo brand classiﬁcation task, we
observe that we can optionally apply a ﬁne-tuning of the
model training to make the Siamese model more adaptive to
the protected logos in the target brand list. Assume the size
Figure 7: Transfer Learning Task
of target list is n; after training the model on the Logo2K+
dataset, we can replace the fully connected layer with another
fully connected layer with n output neurons, corresponding
to the number of target brands. Thus, we can train the model
speciﬁcally for the brands in the target list. Our experiment
(see Section 5.5) shows that such an optional training process
can improve the logo recognition while still preserving the
ﬂexibility of adding unseen new logos in the target brand list.
3.3 Defending against adversarial attacks
Deep learning models are known to be vulnerable to adver-
sarial attacks [15]. State-of-the-art adversarial attacks are de-
signed for both object detection models (e.g., DAG [78]) and
classiﬁcation models (e.g., DeepFool [48] and FGSM [25]).
Let a neural network be a function f (x), x being a sample.
Generally, most gradient-based approaches carry out attacks
based on the partial derivative ¶ f
¶x , to ﬁnd the minimum pertur-
bation d on x for obtaining x0 = x + d, such that the targeted
model can be deceived; i.e., f (x0) 6= f (x).
Traditional defense techniques against adversarial attacks
usually adopt various adversarial training approaches [37, 51,
66, 72]. However, adversarial training approaches also lowers
the original model’s performance and they may not work
well for some unseen adversarial samples [66, 72]. Instead,
we design a new simple adversarial defense technique to
transform our Faster-RCNN and Siamese model to counter
some of the well-known gradient-based adversarial attacks,
while (i) still preserving the model performance, and (ii) not
requiring additional (adversarial) training that increases the
system complexity.
Speciﬁcally, we replace the ReLU function in some layers
of both models with a step ReLU function. In this approach,
we design the step-ReLU function as Equation 1, where the
linear function of the traditional ReLU is replaced with a step
function; Figure 8 illustrates this. The parameter a determines
the gap size in the step function.
f (x) = max(0;a(cid:1)d x
a
e)
(1)
USENIX Association
30th USENIX Security Symposium    3797
Resnetv2Logo image in Logo2K+Output Feature Map Fully Connect NetworkResnetv2Logo ImageOutput Feature Map     Logo Brand Classification TaskGlobal Average PoolingRepresentative VectorSiamese Model Sturcture• RQ3: How does Phishpedia perform if the target brand
list is added with new logos during runtime (in other
words, when Phishpedia is presented new logos not seen
by the trained Siamese model)?
• RQ4: What are the alternative technical options for
Phishpedia and how do they perform?
• RQ5: How well does Phishpedia defend against state-
of-the-art adversarial attacks?
• RQ6: Does Phishpedia facilitate discovering of phishing
pages in the wild (i.e., the Internet)?
To answer RQ1, we conduct experiments comparing the
performance of Phishpedia with other baseline approaches
on (cid:24)30K phishing webpages (obtained by subscribing to
Openphish Premium Service) and another (cid:24)30K benign web-
pages (from Alexa’s top-ranked websites). To answer RQ2,
we evaluate the performance of our object detection model
and Siamese model separately. For RQ3 and RQ4, we con-
duct a controlled experiment to evaluate the performance of
Phishpedia when unseen logos are added to the target brand
list, and also when we adopt alternative technical options for
Phishpedia. To answer RQ5, we evaluate the model accuracy
and the success rate of adversarial attacks before and after
applying the gradient masking technique on the our models.
For RQ6, we conduct a phishing discovery experiment to com-
pare the performance of Phishpedia and ﬁve other solutions
in reporting real-world phishing webpages in the wild (see
Section 6). The experiment details are available at [7].
5.1 Datasets
To answer the above research questions, we collect relevant
datasets. The details are as follows:
Phishing Webpage Dataset. To collect live phishing web-
pages and their target brands as ground truth, we subscribed
to OpenPhish Premium Service [4] for a period of six months;
this gave us 350K phishing URLs. We ran a daily crawler
that, based on the OpenPhish daily feeds, not only gathered
the web contents (HTML code) but also took screenshots
of the webpages corresponding to the phishing URLs. This
allowed us to obtain all relevant information before the URLs
became obsolete. Moreover, we manually cleaned the dead
webpages (i.e., those not available when we visited them)
and non-phishing webpages (e.g., the webpage is not used
for phishing any more and has been cleaned up, or it is a
pure blank page when we accessed). In addition, we use
VPN to change our IP addresses while visiting a phishing
page multiple times to minimize the effect of cloaking tech-
niques [30, 81]. We also manually veriﬁed (and sometimes
corrected) the target brands for the samples. As a result, we
ﬁnally collected 29,496 phishing webpages for our experimen-
tal evaluations. Note that, conventional datasets crawled from
PhishTank and the free version of OpenPhish do not have
(a) Traditional ReLU
(b) Step ReLU
Figure 8: ReLU v/s Step-ReLU Activation Functions
The insight here is that the partial derivative ¶ f
¶x of step-relu
is either 0 or inﬁnite, which reduces the effect of gradient-
based attacks such as DeepFool [48], JSMA [24], StepLL [34],
and FGSM [35]. Moreover, the transformed layers of ReLU
activation function can largely preserve the precision of the
output values of activation function, which in turn helps in
preserving the performance of the original network model.
4
Implementation
We build Phishpedia on top of the components described
in the previous section. We select 181 brands in our target
list as these are the most popular phishing targets covering
99.1% of phishing attacks according to our empirical study
(see Figure 5). It is worth recalling that, Phishpedia requires
no phishing dataset for training.
Object detection model. We train our Faster-RCNN model
based on Detectron2 framework [77]. Different from the orig-
inal Faster-RCNN model [58] which trains region proposal
network and Fast-RCNN model interchangeably, our adopted
Detectron2 framework uses four feature pyramid layers and
trains both models jointly for better training efﬁciency. The
dataset used for training our model is described in Section 5.1.
Siamese model. We train our Siamese model via PyTorch
framework. We choose Resnetv2 [29] as the backbone net-
work. We use Logo2k+ dataset [75] for training the brand
classiﬁcation task as base model for transfer learning.
Both neural networks are trained on an Ubuntu16.04 server
with Xeon Silver 4108 (1.8GHz), 128G DDR4 RAM, and
NVIDIA Tesla V100 GPU. All experiments for evaluations
(Section 5) are conducted on the same server.
5 Performance evaluation
Next, we carry out comprehensive experiments to answer the
following research questions:
• RQ1: How accurate is Phishpedia in identifying phish-
ing pages, in comparison to state-of-the-art baselines?
• RQ2: What is the accuracy of the core components of
Phishpedia, namely, the object detection model and the
Siamese model?
3798    30th USENIX Security Symposium
USENIX Association
phishing target brand information. Though existing works
such as [36] and [80] use larger phishing datasets for phishing
detection experiments (i.e., without identifying target brands),
to the best of our knowledge, we collected the largest dataset
for phishing identiﬁcation experiments.
Benign Webpage Dataset. We collected 29,951 benign web-
pages from the top-ranked Alexa list [1] for this experiment.
Similar to phishing webpage dataset, we also keep the screen-
shot of each URL.
Labelled Webpage Screenshot Dataset. For evaluating the
object detection model independently, we use the (cid:24)30K Alexa
benign webpages collected (for the benign dataset) along with
their screenshots. We outsourced the task of labelling the
identity logos and user inputs on the screenshots.
We publish all the above three datasets at [7] for the re-
search community.
5.2 Comparing Phishpedia with state-of-the-
art baselines (RQ1)
5.2.1 Logo frequency in phishing webpages
We randomly sampled 5,000 webpages from the phishing
webpage dataset, and manually validated that 70 of them have
no logos. That is, the ratio of phishing webpages with logos
is about 98.6%. Figure 9 shows the screenshot of a webpage
reported by OpenPhish as a phishing webpage for Adobe.
However, without a logo, we argue that the phishing attack is
unlikely to be successful, as a user may not even know which
credential to provide at such a page. In other words, to be
effective, logo is an important feature for a phishing webpage.
5.2.2 Baselines for evaluations
We select EMD [21], PhishZoo [11], and LogoSENSE [13]
as the baseline phishing identiﬁcation approaches. Table 1
shows the details of baseline approaches. They are repre-
sentatives for different visual similarity based identiﬁcation
approaches, i.e., screenshot similarity (EMD), SIFT-based
similarity (PhishZoo), and HOG vector based similarity (Lo-
goSENSE). The target brand list is the same for PhishZoo
and Phishpedia, which consists of 181 brands.
Since EMD is basically a measurement technique for esti-
mating the similarity of two screenshots, it can perform differ-
ently (both in terms of identiﬁcation and runtime overhead)
based on the number of referenced screenshots. The larger
the number of referenced screenshots, the higher the recall
that can be achieved, but at a larger runtime cost. Therefore,
we deﬁne two versions of EMD for evaluations:
• EMDnormal: In this version, we equip EMD with 181 rep-
resentative screenshots (collected online) as its reference,
and evaluate its performance against the entire phishing
and benign webpage datasets (see Section 5.1).
Figure 9: An Adobe phishing webpage without logo, reported
by OpenPhish.
• EMDmore_ref: We performed digest matching across the
phishing webpage dataset and found that the screen-
shots in the ﬁrst temporal half can match 48% of the
screenshots in the second temporal half. This indicates
that EMD with more references can potentially achieve
higher recall. Therefore, in this version, we split the
phishing webpage dataset of six months, temporally, into
two equal halves. For improving the runtime efﬁciency
of EMDmore_ref, we apply the digest matching on the
(cid:24)15k screenshots in the ﬁrst temporal half; this reduces
the number of referenced screenshots to (cid:24)3k.
For LogoSENSE, we let it detect phishing webpages tar-
geting ﬁve speciﬁc brands — Paypal, Microsoft, Chase Per-
sonal Banking, DHL Airway, and Bank of America. We se-
lected these brands for their popularity in our empirical study
(see Figure 5). The list is limited to ﬁve brands because Lo-
goSENSE requires us to train a classiﬁer for each brand,