71.3% of large ﬂows, their bandwidth utilization ratios are below
50%. For 6.4% of the ﬂows, the used bandwidth is slightly larger
than the estimated bandwidth, possibly due to estimation error.
On average, the utilization ratio is 34.6%. Transferring the same
amount of data requires a longer period of time with lower band-
width utilization ratio, which incurs additional radio energy over-
head and more radio resource consumption [13].
Figure 22 shows two sample large TCP ﬂows and their estimated
bandwidth in the LTE data set. They belong to two users at dif-
ferent time and the time is aligned only for presentation purpose.
We observe that the available bandwidth varies signiﬁcantly over
time and even on the scale of seconds. This could be attributed to
network condition changes (e.g., signal strength) or changes of the
network load in associated eNB. In order to dissect the root cause of
such variability, more information, e.g., load information of eNB,
is needed.
To understand how well TCP performs under highly variable
available bandwidth, we use iptables to redirect packets to a
packet scheduler we designed, which changes the available band-
width following the variations observed in LTE networks. The
packet scheduler also injects varying delays to each packet helping
us to understand the impact of RTT. Intuitively, when RTT is larger,
TCP would adapt slower to the varying available bandwidth, as the
congestion window is updated only once per RTT. We measure the
 0 0.2 0.4 0.6 0.8 1-5 0 5 10 15 20 25 30CDFDownlink throughput (Mbps)Actual throughputError 1.0s windowError 0.1s windowEstimated bandwidth 0 5 10 15 20 0 200 400 600 800 1000 1200 1400 1600 1800TCP throughput (Mbps)Time (s)Error of estimated bandwidthActual throughput 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1CDFRatio of used bandwidth 0 0.2 0.4 0.6 0.8 1 0 50 100 150 200 250 300Normalized TCP throughputTime (s)BW estimation for sample flow 1BW estimation for sample flow 2372Figure 23: Full receive window slows Shazam player (a popular
app) in downloading a 30-second music ﬁle.
bandwidth utilization ratio with the packet scheduler changing the
available bandwidth every 500ms. We observe that under small
RTTs, TCP can utilize over 95% of the available bandwidth. How-
ever, when RTT exceeds 400ms, the utilization ratio drops to below
50%. We also observe that for the same RTT, higher bandwidth
variation leads to lower bandwidth utilization. These observations
further suggest that large RTTs can degrade TCP performance in
LTE networks, which have inherently varying available bandwidth
likely caused by changes in load and channel conditions.
7. NETWORK APPLICATIONS IN LTE
In this section, we characterize the network applications and traf-
ﬁc patterns in the LTE data set. Speciﬁcally, we study the application-
layer causes of inefﬁcient bandwidth usage observed in §6.
7.1 HTTP Content Characterization
HTTP dominates the application-layer protocol usage on mobile
devices [34]. We break down the total bytes of HTTP trafﬁc based
on content types. About 37.8% are video, followed by 19.5% for
images and 11.8% for text. Files in zip format contribute to 8.3%
of the HTTP trafﬁc and they mostly correspond to ﬁle downloads
such as app updates. Audio contents are responsible for 6.5% of
HTTP trafﬁc and other content types for 5.6%. The remaining
10.5% are unknown. Within video contents, we observe 12.9% to
be octet-stream type (byte stream in binary format), most of which
are generated by video players via byte-range requests.
Previous studies show that the multimedia contents (video and
audio) correspond to 40% of the trafﬁc generated by mobile hand-
held devices in DSL networks [19], and video contributes to 30%
of the 3G cellular trafﬁc [7]. Although we observe slightly higher
percentage of multimedia trafﬁc in this LTE network, the differ-
ence is insigniﬁcant. Overall, we observe multimedia contents still
dominate the LTE trafﬁc, followed by images.
7.2 Inefﬁcient Network Usage
We investigate the large ﬂows with under-utilized network band-
width and observe that the TCP receive window size [32] has be-
come the bottleneck in many cases.
Figure 23 shows one such example: an iOS user launches the
popular Shazam app [2] to download a 30-second music ﬁle of
1MB. Initially, the data transfer speed is high and between time 0s
and 2s the average downlink throughput is over 3Mbps. However,
between 2s and 9s, the average throughput decreases to less than
300Kbps. The total download time is 9 seconds and as indicated
by the ideal case curve, the download could have been completed
within 2.5s, based on our estimation of the available bandwidth.
In addition, we notice that the TCP connection is not immediately
closed after the ﬁle transfer is complete, although the HTTP request
speciﬁes the connection to be Connection:close. In fact, the
connection is torn down at 30s, after the music clip has ﬁnished
Figure 24: The periodic request behavior of Netﬂix player lim-
iting its overall throughput.
playing and the client sends some TCP receive window updates to
the server between 20s and 25s to increase receive window sizes.
Overall, the total download process keeps the radio interface on for
38 seconds. Assuming a tail time of 10 seconds [13], in the ideal
case, the active radio time is only 12.5 seconds.
The performance drop at 2s in Figure 23 is due to the TCP re-
ceive window becoming full. Between 0s and 2s, the window size
has gradually dropped to a small value, e.g., at the turning point
around 2s, the window size is 816 bytes, even smaller than the max-
imum packet payload size (1358 bytes in the trace). As TCP rate is
jointly controlled by the congestion window and the receive win-
dow, a full receive window would prevent the server from sending
more data regardless of the congestion window size, leaving the
bandwidth under-utilized.
The reason for the full TCP receive window is two-fold. First,
the initial receive window size is not large, e.g., 131.8KB in the case
of Figure 23, much smaller than the ﬁle size. We explore the initial
advertised receive window size in all TCP ﬂows, and observe that
the values fall in 131,712±600 bytes for over 99% of the ﬂows, for
iOS, Android and Windows Phone devices. Second, the application
is not reading the data fast enough from the receiving buffer at TCP
layer. Otherwise, even if the initial receive window is small, the
receive window size should not drop to close to 0 afterwards.
We further study the prevalence of such poor network perfor-
mance throttled by the TCP receive window. We ﬁnd that for all
downlink TCP ﬂows, 52.6% of them experience full receive win-
dow. And for 91.2% of these affected ﬂows, the receive window
bottleneck happens in the initial 10% of the ﬂow duration. These
observations suggest that about half of the TCP ﬂows in the dataset
are experiencing degraded network performance limited by the re-
ceive window size.
We also observe that some apps under-utilize the bandwidth due
to the application design. Figure 24 shows the network behavior
of the popular Netﬂix app [1] on iOS. The upper half of the ﬁgure
shows the HTTP requests and responses on different client ports.
At around 70s, the user browses through a list of video thumbnails
and switches to another video. We observe that all HTTP requests
for video download are HTTP byte-range requests and the corre-
sponding responses are mostly short in duration (smaller than 1s,
making them barely visible). The response sizes range from 1MB
to 4MB. The client periodically requests for video chucks every
10s, with each TCP connection typically reused by two consecutive
requests. The bottom half of the ﬁgure plots the aggregated down-
link throughput, showing a clear periodic pattern corresponding to
the periodic requests. While the peak throughput can reach up to
30Mbps, for most of the time, the network interface is idle. This
type of trafﬁc pattern is known for incurring high tail energy [24].
In this particular case, we know that the tail timer for the studied
network is 10s, and based on the LTE radio resource control (RRC)
state machine [13], the 10-second request periodicity would keep
 0 200000 400000 600000 800000 1e+06 1.2e+06 0 5 10 15 20 25 30Relative Sequence NumberTime (second)DataIdeal caseACK 55040 55060 55080 55100 55120 0 50 100 150 200 0 5 10 15 20 25 30Client portsThroughput (Mbps)Time (second)HTTP RequestHTTP ResponseAggregate throughput373the UE radio interface always at the high-power state, incurring
unnecessarily high energy overheads.
7.3 Discussions
We have shown that multimedia trafﬁc is dominant in LTE net-
works and the available bandwidth is far from being effectively uti-
lized by many popular apps. Hence optimizing the network uti-
lization for these apps is critical for improved user experiences and
battery life.
For the TCP receive window problem, existing studies [16] have
shown that smartphone vendors may have been reducing receive
window sizes to mitigate the “buffer bloat” problem, resulting in
TCP performance degradation. Dynamic receive window adjust-
ment (DRWA) [16] is proposed to address this issue. However,
such proposals require changes to TCP stacks, making their de-
ployment potentially challenging. As an orthogonal solution, ap-
plications should read downloaded data from TCP’s receiver buffer
quickly. For example, the desired behavior of the Shazam player
(§7.2) is to download the ﬁle as fast as possible, promptly move the
data to application-layer buffers, and close the connection immedi-
ately when the ﬁle transfer is complete. Doing so beneﬁts for both
the network and device energy efﬁciency.
Regarding to the periodical network activities of the Netﬂix player
(Figure 24), in addition to leveraging the application-layer buffer,
it is also recommended that it send fewer requests and download
more content for each request. Huang et al. [13] have shown that
transferring data in a large batch signiﬁcantly reduces the radio en-
ergy than otherwise. This also allows TCP to make better use of
the available bandwidth.
8. CONCLUSION
In this paper, we use a large-scale LTE data set to study the im-
pact of protocol and application behaviors on the network perfor-
mance. We observe that some TCP behaviors, such as not updat-
ing RTT estimation using duplicate ACKs, can cause severe per-
formance issues in LTE networks upon a single packet loss. By
devising a novel bandwidth estimation algorithm, we observe that
for 71.3% of the large ﬂows, the bandwidth utilization ratio is be-
low 50%. We also show that the available bandwidth for LTE net-
works has high variation and TCP is not able to fully utilize the
bandwidth as the congestion window cannot adapt fast enough, es-
pecially when RTT is large. We further notice that the limited re-
ceive window size throttles the TCP performance for 52.6% of the
downlink ﬂows.
In addition, we ﬁnd that the application design
may result in under-utilized bandwidth. All these ﬁndings provide
insights on developing transport protocol mechanisms and applica-
tions that are more LTE-friendly.
9. ACKNOWLEDGEMENTS
We thank Professor Elizabeth Belding for her constructive com-
ments serving as the shepherd for this paper. We also thank the
anonymous reviewers for their feedback. This research was sup-
ported in part by the National Science Foundation under grants
CNS-0643612, CNS-1039657, CNS-1059372 and CNS-0964545.
10. REFERENCES
[1] Netﬂix App. http://www.netflix.com/.
[2] Shazam App. http://www.shazam.com/.
[3] M. Allman, V. Paxson, and E. Blanton. Tcp congestion control. RFC 5681,
2009.
[4] M. Balakrishnan, I. Mohomed, and V. Ramasubramanian. Where’s That
Phone?: Geolocating IP Addresses on 3G Networks. In Proceedings of IMC,
2009.
[5] L. Brakmo and L. Peterson. TCP Vegas: end to end congestion avoidance on a
global Internet. Selected Areas in Communications, IEEE Journal on,
13(8):1465 –1480, 1995.
[6] X. Chen, R. Jin, K. Suh, B. Wang, and W. Wei. Network Performance of Smart
Mobile Handhelds in a University Campus WiFi Network. In IMC, 2012.
[7] J. Erman, A. Gerber, K. Ramakrishnan, S. Sen, and O. Spatscheck. Over The
Top Video: The Gorilla in Cellular Networks. In IMC, 2011.
[8] H. Falaki, R. Mahajan, S. Kandula, D. Lymberopoulos, and R. G. D. Estrin.
Diversity in Smartphone Usage. In MobiSys, 2010.
[9] A. Gember, A. Anand, and A. Akella. A Comparative Study of Handheld and
Non-Handheld Trafﬁc in Campus Wi-Fi Networks. In PAM, 2011.
[10] A. Gerber, J. Pang, O. Spatscheck, and S. Venkataraman. Speed Testing without
Speed Tests: Estimating Achievable Download Speed from Passive
Measurements. In IMC, 2010.
[11] E. Halepovic, J. Pang, and O. Spatscheck. Can you GET Me Now? Estimating
the Time-to-First-Byte of HTTP Transactions with Passive Measurements. In
IMC, 2012.
[12] N. Hu, L. E. Li, Z. M. Mao, P. Steenkiste, and J. Wang. Locating Internet
Bottlenecks: Algorithms, Measurements, and Implications. In SIGCOMM,
2004.
[13] J. Huang, F. Qian, A. Gerber, Z. M. Mao, S. Sen, and O. Spatscheck. A Close
Examination of Performance and Power Characteristics of 4G LTE Networks.
In MobiSys, 2012.
[14] J. Huang, Q. Xu, B. Tiwana, Z. M. Mao, M. Zhang, and P. Bahl. Anatomizing
Application Performance Differences on Smartphones. In MobiSys, 2010.
[15] M. Jain and C. Dovrolis. End-to-End Available Bandwidth: Measurement
Methodology, Dynamics, and Relation with TCP Throughput. In IEEE
Network, 2003.
[16] H. Jiang, Y. Wang, K. Lee, and I. Rhee. Tackling Bufferbloat in 3G/4G
Networks. In IMC, 2012.
[17] X. Liu, A. Sridharan, S. Machiraju, M. Seshadri, and H. Zang. Experiences in a
3G Network: Interplay between the Wireless Channel and Applications. In
MOBICOM, 2008.
[18] M. Mathis and J. Mahdavi and S. Floyd and A. Romanow. TCP Selective
Acknowledgment Options. RFC 2018, 1996.
[19] G. Maier, F. Schneider, and A. Feldmann. A First Look at Mobile Hand-held
Device Trafﬁc. In PAM, 2010.
[20] V. Paxson, M. Allman, J. Chu, and M. Sargent. Computing tcp’s retransmission
timer. RFC 6298, 2011.
[21] R. Prasad, C. Dovrolis, M. Murray, and kc claffy. Bandwidth Estimation:
Metrics, Measurement Techniques, and Tools. In IEEE Network, 2003.
[22] F. Qian, A. Gerber, Z. M. Mao, S. Sen, O. Spatscheck, and W. Willinger. TCP
Revisited: A Fresh Look at TCP in the Wild. In IMC, 2009.
[23] F. Qian, J. Huang, J. Erman, Z. M. Mao, S. Sen, and O. Spatscheck. How to
Reduce Smartphone Trafﬁc Volume by 30%? In PAM, 2013.
[24] F. Qian, Z. Wang, Y. Gao, J. Huang, A. Gerber, Z. M. Mao, S. Sen, and
O. Spatscheck. Periodic Transfers in Mobile Applications: Network-wide
Origin, Impact, and Optimization. In World Wide Web, 2012.
[25] F. Qian, Z. Wang, A. Gerber, Z. M. Mao, S. Sen, and O. Spatscheck.
Characterizing Radio Resource Allocation for 3G Networks. In IMC, 2010.
[26] F. Qian, Z. Wang, A. Gerber, Z. M. Mao, S. Sen, and O. Spatscheck. Proﬁling
Resource Usage for Mobile Applications: a Cross-layer Approach. In MobiSys,
2011.
[27] R. Braden. Requirements for Internet Hosts – Communication Layers. RFC
1122, 1989.
[28] P. Sarolahti and A. Kuznetsov. Congestion Control in Linux TCP. In USENIX
Annual Technical Conference, 2002.
[29] S. Sesia, I. Touﬁk, and M. Baker. LTE: The UMTS Long Term Evolution From
Theory to Practice. John Wiley and Sons, Inc., 2009.
[30] C. Shepard, A. Rahmati, C. Tossell, L. Zhong, and P. Kortum. LiveLab:
Measuring Wireless Networks and Smartphone Users in the Field. In
HotMetrics, 2010.
[31] J. Sommers and P. Barford. Cell vs. WiFi: On the Performance of Metro Area
Mobile Connections. In IMC, 2012.
[32] V. Jacobson and R. Braden and D. Borman. TCP Extensions for High
Performance. RFC 1323, 1992.
[33] Z. Wang, Z. Qian, Q. Xu, Z. M. Mao, and M. Zhang. An Untold Story of
Middleboxes in Cellular Networks. In SIGCOMM, 2011.
[34] Q. Xu, J. Erman, A. Gerber, Z. M. Mao, J. Pang, and S. Venkataraman.
Identifying Diverse Usage Behaviors of Smartphone Apps. In IMC, 2011.
[35] Q. Xu, J. Huang, Z. Wang, F. Qian, A. Gerber, and Z. M. Mao. Cellular Data
Network Infrastructure Characterization and Implication on Mobile Content
Placement. In SIGMETRICS, 2011.
[36] Y. Zhang, L. Breslau, V. Paxson, and S. Shenker. On the Characteristics and
Origins of Internet Flow Rates. In SIGCOMM, 2002.
[37] Z. Zhuang, T.-Y. Chang, R. Sivakumar, and A. Velayutham. A3:
Application-Aware Acceleration for Wireless Data Networks. In MOBICOM,
2006.
374