tack makes 28 system calls when Σ = R and n = 1,
while it becomes impossible for n ≥ 2 with the same
setting of Σ. It is clear from the graphs that growing
Σ or n makes mimicry attacks more diﬃcult.
It might not be obvious why the mimicry attack be-
comes impossible when Σ = R while it is possible
for Σ = P with the same setting of n.
(For ex-
ample, the graph of Apache httpd (chroot) in the
ﬁrst column of Figure 1 shows that the mimicry at-
tack is impossible when Σ = R and n ≥ 2.) Here
we explain with a simple example. In Figure 3, a
solid rectangle represents a state in the automaton,
and r, p and s represent a set of return addresses, a
program counter and a system call number respec-
tively. If the anomaly detector does not check return
addresses, the two states (r1, p, s) and (r2, p, s) will
collapse into one and the impossible path denoted
by the dashed line will be accepted, which makes a
mimicry attack possible. Thus, checking return ad-
dresses makes the automaton model more accurate.
Although the minimum number of system calls an
attack makes is a good measure of the diﬃculty of
a mimicry attack, in many cases attackers are free
to make any number of system calls, as long as they
do not set oﬀ any alarms in the anomaly detector.
However, in the case where Σ ∈ {P, R, P+, R+},
the attack has to forge all information that is in-
spected by the anomaly detection system (program
counters and return addresses). We thus provide a
second measure on the diﬃculty of the mimicry at-
tack, namely the size of the attack data, which is
shown by the graphs on the second column of Fig-
ures 1 and 2.
In this measure we only take into
account the attack data, which is the forged pro-
gram counter and the return addresses (and noth-
ing in the case of S and S+), with the assumption
of perfect compression. Again the graphs show that
growing Σ or n makes mimicry attacks consume sig-
niﬁcantly more space. Note that the size increase in
attack data could make mimicry attacks less eﬃ-
cient (due to the need to send more data), easier
to detect, or even make some mimicry attacks im-
possible due to limited space in the program buﬀer
where the attack code is inserted. For example, the
size of the attack data becomes a few kilobytes on
the proftpd program in some conﬁgurations.
fanout(q) = |δ(q)|, where δ(q)
The analysis so far has been focused on one
mimicry attack.
In an eﬀort to quantify the dif-
ﬁculty of mimicry attacks in general, we deﬁne a
property of an automaton state, called its fanout,
as follows:
:=
{(q, σ, q(cid:2))|(q, σ, q(cid:2)) ∈ δ}.
fanout(q) measures the
number of possible states that can follow an active
state q. If an attack compromises the program and,
in the course of performing its attack, activates q,
then only fanout(q) states can follow from q. As
such, fanout(q) is a coarse measure of the extent to
which a mimicry attack is constrained upon activat-
ing q. Graphs in the third column of Figures 1 and 2
show the percentage of states with fanout(q) = 1 in
n
o
i
t
c
n
u
f
n
o
i
t
i
s
n
a
r
t
f
o
e
z
i
s
s
n
o
i
t
i
s
n
a
r
t
e
v
i
t
c
a
f
o
#
e
g
a
r
e
v
a
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
0
0
7
0
0
6
0
0
5
0
0
4
0
0
3
0
0
2
0
0
1
0
0
0
5
2
0
0
0
2
0
0
5
1
0
0
0
1
0
0
5
0
0
5
2
0
0
2
0
5
1
0
0
1
0
5
0
0
0
8
0
0
6
0
0
4
0
0
2
0
RPS
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
6
5
4
3
2
1
0
5
0
4
0
3
0
2
0
1
0
0
2
5
1
0
1
5
0
5
4
3
2
1
8
6
4
2
0
1
=
t
u
o
-
n
a
f
h
t
i
w
s
e
t
a
t
s
f
o
%
)
s
e
t
y
b
(
a
t
a
d
k
c
a
t
t
a
f
o
e
z
i
s
s
e
k
a
m
k
c
a
t
t
a
e
h
t
s
l
l
a
c
s
y
s
f
o
#
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
0
0
1
0
8
0
6
0
4
0
2
0
0
0
1
0
8
0
6
0
4
0
2
0
0
0
1
0
8
0
6
0
4
0
2
0
0
0
1
0
8
0
6
0
4
0
2
0
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
0
0
5
0
0
4
0
0
3
0
0
2
0
0
1
0
0
0
0
6
0
0
0
5
0
0
0
4
0
0
0
3
0
0
0
2
0
0
0
1
0
0
0
2
0
5
1
0
0
1
0
5
0
0
0
4
0
0
3
0
0
2
0
0
1
0
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
RPS
6
5
4
3
2
1
0
8
0
6
0
4
0
2
0
0
0
4
0
0
3
0
0
2
0