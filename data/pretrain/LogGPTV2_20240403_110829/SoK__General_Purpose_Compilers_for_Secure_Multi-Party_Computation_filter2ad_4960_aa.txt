title:SoK: General Purpose Compilers for Secure Multi-Party Computation
author:Marcella Hastings and
Brett Hemenway and
Daniel Noble and
Steve Zdancewic
2019 IEEE Symposium on Security and Privacy
SoK: General Purpose Compilers for Secure
Multi-Party Computation
Marcella Hastings, Brett Hemenway, Daniel Noble, and Steve Zdancewic
University of Pennsylvania
{ mhast, fbrett, dgnoble, stevez } @cis.upenn.edu
Abstract—Secure multi-party computation (MPC) allows
a group of mutually distrustful parties to compute a joint
function on their inputs without revealing any informa-
tion beyond the result of the computation. This type of
computation is extremely powerful and has wide-ranging
applications in academia, industry, and government. Pro-
tocols for secure computation have existed for decades, but
only recently have general-purpose compilers for executing
MPC on arbitrary functions been developed. These projects
rapidly improved the state of the art, and began to make
MPC accessible to non-expert users. However, the ﬁeld is
changing so rapidly that it is difﬁcult even for experts to
keep track of the varied capabilities of modern frameworks.
In this work, we survey general-purpose compilers
for secure multi-party computation. These tools provide
high-level abstractions to describe arbitrary functions
and execute secure computation protocols. We consider
eleven systems: EMP-toolkit, Obliv-C, ObliVM, TinyGar-
ble, SCALE-MAMBA (formerly SPDZ), Wysteria, Share-
mind, PICCO, ABY, Frigate and CBMC-GC. We evaluate
these systems on a range of criteria, including language ex-
pressibility, capabilities of the cryptographic back-end, and
accessibility to developers. We advocate for improved doc-
umentation of MPC frameworks, standardization within
the community, and make recommendations for future
directions in compiler development. Installing and running
these systems can be challenging, and for each system,
we also provide a complete virtual environment (Docker
container) with all the necessary dependencies to run the
compiler and our example programs.
I. INTRODUCTION
Secure multi-party computation (MPC) provides a
mechanism by which a group of data-owners can com-
pute joint functions of their private data, where the
execution of the protocol reveals nothing more about
the underlying data than what is revealed by the output
alone. MPC can be viewed as a cryptographic method
for providing the functionality of a trusted party—who
would accept private inputs, compute a function and
return the result to the stakeholders—without the need
for mutual trust.
Thanks to these strong security guarantees, MPC has
broad potential for practical applications, ranging from
general computations of secure statistical analysis [22],
[23], [25], [52], [53], [54], [55], [96], to more domain-
speciﬁc uses like ﬁnancial oversight [2], [21], [26], [58],
biomedical computations [35], [32], [75], [84], [82],
[85], [132] and satellite collision detection [73], [74],
[86].
Despite the demand for MPC technology, practical
adoption has been limited, partly due to the efﬁciency
of the underlying protocols. General-purpose MPC pro-
tocols, capable of securely computing any function, have
been known to the cryptographic community for 30 years
[31], [68], [127], [128]. Until recently such protocols
were mainly of theoretical interest, and were considered
too inefﬁcient (from the standpoint of computation and
communication complexity) to be useful in practice.
To address efﬁciency concerns, cryptographers have
developed highly-optimized, special-purpose MPC pro-
tocols for a variety of use-cases. Unfortunately,
this
mode of operation does not foster widespread deploy-
ment or adoption of MPC in the real world. Even if
these custom-tailored MPC protocols are theoretically
efﬁcient enough for practical use, designing, analyzing
and implementing a custom-tailored protocol from the
ground up for each application is not a scalable solution.
General-purpose MPC compilers, could drastically
reduce the burden of designing multiple custom proto-
cols and could allow non-experts to quickly prototype
and deploy secure computations. Using compilers, the
engineering effort devoted to making general-purpose
MPC protocols practical and secure can be amortized
across all of the uses of such a system.
Many signiﬁcant challenges arise when designing and
building an MPC compiler. In general, implementing
any type of multi-round, distributed protocol robustly
and efﬁciently is a major engineering challenge, but
the MPC compilers have additional requirements that
make them especially challenging to build correctly.
For efﬁciency, both the compiler and the cryptographic
back-end need to be highly optimized. For usability, the
front-end compiler needs to be expressive, ﬂexible, and
intuitive for non-experts, and should abstract away many
of the complexities of the underlying MPC protocol,
including circuit-level optimizations (e.g. implementing
ﬂoating-point operations as a Boolean circuit) and back-
end protocol choice (e.g. selecting an optimal protocol
for a particular computation). With today’s compilers,
optimizing performance often still requires a fair degree
© 2019, Marcella Hastings. Under license to IEEE.
DOI 10.1109/SP.2019.00028
1220
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:48:10 UTC from IEEE Xplore.  Restrictions apply. 
of knowledge and effort on the part of the user.
Fairplay [99] was the ﬁrst publicly available MPC
compiler. It translated code written in a high-level Secure
Function Deﬁnition Language (SFDL) into a garbled
circuit representation, which could then be (securely)
evaluated by two parties. Fairplay was subsequently
extended to allow for true multi-party computation in
FairplayMP [14], using a modiﬁed version of the BMR
protocol [9]. It was followed shortly by VIFF [63],
[47] and SEPIA [28], which used the same basic ar-
chitecture: they took programs written in fairly high-
level languages, converted them to a circuit format, and
executed the circuit using a secure computation protocol.
These early compilers showed that general-purpose
MPC was achievable, and, although their performance
rendered them unsuitable for most real-world applica-
tions, they launched what is now a very active ﬁeld of
research in MPC compiler design and implementation.
Thanks to these efforts, dramatic improvements in
secure computation algorithms coupled with a steady
increase in hardware performance have made MPC a
viable solution to a large class of real-world problems.
Modern MPC protocol implementations are fast enough
to securely evaluate complex functions on moderately-
large data sets, such as the numerous implementations
of secure regression analyses with tens to hundreds
of thousands of observations, and tens to hundreds of
variables [23], [38], [62], [87], [104].
The rush of activity in this ﬁeld can be difﬁcult
to navigate: dozens of new compilers and supporting
frameworks encompass a wide variety of architectures
and features which inﬂuence their efﬁciency, usability
and suitability for different
tasks. The goal of this
Systematization of Knowledge paper is to provide a
guide to the powerful new breed of MPC compilers, and
is primarily aimed at four distinct types of readers.
1) Developers looking to choose a compiler with
which to implement a speciﬁc secure computation
2) Theoretical cryptographers looking to understand
state-of-the-art in practical, secure computation
3) Compiler designers looking to understand the lim-
itations of existing technology and identify new
research directions
4) Managers and policy-makers looking to under-
stand whether existing technology is mature
enough for their needs
This paper brieﬂy reviews necessary technical back-
ground about secure multi-party computation, then sur-
veys the state-of-the-art MPC frameworks, evaluating
them based on their general architecture, underlying
technology, threat models, and expressiveness. Our com-
parison focuses on usability features rather than perfor-
mance metrics, and we report on our experience with
implementing three small test programs in each case.
Casual readers may wish to skim Section VI, which
discusses each framework in greater depth, and focus on
the ﬁnal discussion section, where we advocate for im-
proved documentation and standardization and suggest
future directions in compiler research.
Many of these frameworks are themselves research
projects or works-in-progress: they have non-trivial build
dependencies and complicated work ﬂows. Indeed, im-
plementing our simple example programs in each sys-
tem required signiﬁcant engineering effort: we estimate
over 750 person-hours. To allow others to experiment
more easily with these systems, we have created an
on-line Github repository1 with two artifacts: (1) a
set of Docker containers, each of which provides a
development environment conﬁgured with the required
software infrastructure for each MPC framework, along
with executable examples of our test cases, and (2) a wiki
page that collects much of the evaluation presented here
with additional documentation about each framework.
a) Related Work: Archer et al.’s survey [6] of se-
cure computation tools across several paradigms, includ-
ing garbled circuit schemes, deﬁnes a maturity taxonomy
that aims to describe the practical readiness of several
schemes. Shan et al.’s survey [117] outlines different
threat models and computation techniques for securely
outsourcing many speciﬁc types of computation. The
authors of Frigate [101] include a short survey of existing
MPC frameworks, which focuses on correctness and
covers a slightly older body of work. The SSC protocol
comparison tool [105], [106], [107] allows users to ﬁnd
published protocols matching certain security or pri-
vacy criteria, but this tool classiﬁes theoretical protocols
rather than implementations and does not include proto-
cols developed in the past few years. The awesome-mpc
repository [115] provides an up-to-date list of compilers,
back-ends and special-purpose protocols, with a short
description of each. To the best of our knowledge, these
previous works did not actually install and experiment
with each of the systems they surveyed, but drew their
conclusions based on the descriptions of the systems
in their published papers and documentation. Unfortu-
nately, we have found that the features, functionality
and syntax of the actual implementations do not always
match those found in the documentation.
II. CRYPTOGRAPHIC BUILDING BLOCKS
In this section, we describe important cryptographic
primitives common to many MPC protocols.
A. Secret Sharing
Cryptographic secret sharing protocols [116], [20]
allow a dealer to break a secret value into shares and
distribute these shares to group of recipients with the
1https://github.com/MPC-SoK/frameworks
1221
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:48:10 UTC from IEEE Xplore.  Restrictions apply. 
x0, x1
(cid:2)
(cid:3)
2
1
-OT
b
xb
Fig. 1: Oblivious Transfer
property that any unqualiﬁed set of recipients learns
nothing about
the secret, while any qualiﬁed set of
recipients can reconstruct the secret from their shares.
In practice, most secret-sharing protocols are threshold
protocols, where any collection of fewer than t shares
reveals nothing about the secret – and any subset of
size at least t can reconstruct the secret. Many general
secret sharing schemes exist [17], [27], [19], [121], [42],
as well as constructions of secret-sharing schemes for
general (non-threshold) access structures [64], [76]. See
Beimel [11] for a survey of secret-sharing protocols.
In practice, most MPC protocols rely on a linear secret
sharing scheme: either simple, additive secret sharing or
Shamir sharing. Both satisfy linearity: the sum of two
secret shares is equal to the share of the sum.
B. Oblivious Transfer (OT)
Oblivious Transfer (OT) [110], [126], [57] is a cryp-
tographic protocol that allows a party to choose k of
n secrets from another party, without revealing which
-OT, where
secret they have chosen. Figure 1 shows
one secret is chosen from two options.
2
1
(cid:2)
(cid:3)
From a theoretical standpoint, MPC protocols can be
built from OT alone [91], [80], but the key feature that
makes OT suitable for building efﬁcient MPC proto-
cols is that OT is equivalent to a seemingly weaker
functionality called Random OT (ROT) [43], where the
choice bit b is not provided as an input, but instead is
randomly generated by the protocol itself. The output of
a ROT protocol is two correlated pairs of bits (x0, x1)
and (b, xb), where x0, x1, b are uniformly distributed
in {0, 1}. Given a random OT correlation (the pairs
(x0, x1) and (b, xb)) Alice and Bob can compute the OT
functionality using only three bits of communication.
Since ROT implies OT, parties can compute all the
necessary ROTs needed for a protocol in advance, in
an input-independent pre-processing (“ofﬂine”) phase.
Then, in the “online” phase, they consume these pre-
generated OTs and execute the protocol with mini-
mal communication cost and no computationally expen-
sive public-key operations. This ofﬂine-online separation
makes the online phase of such a protocol extremely
efﬁcient, but there is still the problem of making the pre-
processing phase efﬁcient. There are two fundamentally
different approaches to handling the ofﬂine phase, either
through a trusted dealer or a cryptographic batched
correlation-generation protocol.
In the trusted dealer model, a semi-trusted dealer sim-
ply distributes correlated randomness to all the parties.
The trusted dealer has no inputs, and never handles any
secret information, thus the dealer need only be trusted to
generate and distribute random values to the appropriate
parties. In the presence of a trusted dealer, the ofﬂine
phase of many MPC protocols can be extremely efﬁcient.
Even without a trusted dealer, OTs can be generated
efﬁciently through OT extension, where a small number
of “base” or “seed” OTs are converted into a mas-
sive number of ROTs [78] through the use of efﬁcient
symmetric-key primitives (e.g. AES). Since its introduc-
tion, there have been many variants of OT-extension [80],
[72], [103], [94], [89] and OT-extension has become an
essential feature in almost all MPC implementations.
III. SECURE MULTI-PARTY COMPUTATION
Secure multi-party computation protocols (MPC) al-
low a group of mutually distrustful stakeholders to
securely compute any function of their joint inputs in
such a way that the execution of the protocol provably
reveals nothing beyond the result of the computation.
Security is often deﬁned using a simulation paradigm,
where a protocol is said to be secure if there exists an
efﬁcient (polynomial-time) simulator that takes as input
the output of the computation and produces a protocol
transcript (the “views” of each participant) such that any
view (or some subsets of views) is indistinguishable from
the transcript created by a real execution of the protocol.
This ensures that each participant (or certain colluding
subsets of participants) learn nothing from executing the
protocol that they could not have learned from the output
alone. In this way, MPC cryptographically emulates a
trusted party who accepts each participant’s private input,
computes the desired function and returns the result.
Early MPC protocols used a circuit model for se-
cure computation, ﬁrst representing the target function
as either a Boolean or arithmetic circuit (over some
ﬁnite ﬁeld), then securely evaluating the circuit gate-by-
gate. Many of the compilers we analyzed still use this
circuit model of computation. In the remainder of this
section, we sketch key design characteristics of the major
protocol families that underpin modern MPC systems.
A. Garbled Circuits
Circuit garbling is a method for secure two-party
computation, originally introduced by Yao [127], [128].
In this framework, there are two participants, a garbler
and an evaluator. The participants begin by expressing
the desired function as a Boolean circuit. The garbler
then proceeds to garble the circuit gate-by-gate using a
standard symmetric-key cryptosystem (usually AES), as
1222
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:48:10 UTC from IEEE Xplore.  Restrictions apply. 
follows. For each wire in the circuit, the garbler selects
two uniformly random and independent “wire tokens.”
The garbler then expresses each gate in the circuit as a
truth table by encrypting each output wire token with
the two input wire tokens that generate it (for Boolean
circuits with fan-in two, each truth table will have four
rows). The garbler permutes the rows of the truth-table,
and sends the entire collection of “garbled” gates to the
evaluator. The garbling procedure is designed so that
learning one wire token for each input wire of a gate
allows you to decrypt exactly one row of its garbled
truth-table, revealing a single wire token belonging to the
output-wire of that gate. Thus an evaluator that learns a
single wire token for each input wire of the circuit can
iteratively produce the wire token for each wire in the
circuit, and completely evaluate the circuit.
To provide its secret inputs, the garbler sends the
correct wire tokens directly to the evaluator. For each bit
of the evaluator’s inputs, the garbler and evaluator en-
gage in an oblivious transfer where the evaluator secretly
selects one of two wire tokens offered by the garbler.
Once the evaluator has a wire token for each input bit,
it can evaluate the circuit (performing symmetric-key
decryptions for every gate) and learn the result. In the
semi-honest model, the evaluator forwards the result of
the computation to the garbler. For a formal description
of the garbling procedure, see Bellare et al. [13].
The initial garbled circuit protocol provided security
against semi-honest adversaries [95], but
there exist
many different improvements and implementations that
provide security against fully malicious adversaries.
Two key performance improvements are the “free
XOR trick” [93], which evaluates XOR gates in a single
round without any cryptographic operations required by
the garbled tables; and Half-Gates [130], which reduce
the number of ciphertexts required to garble AND gates.
The addition of the AES-NI instruction set made com-
puting AES encryptions on modern processors extremely
efﬁcient, and has dramatically reduced the computation
cost of garbled-circuit-based protocols.