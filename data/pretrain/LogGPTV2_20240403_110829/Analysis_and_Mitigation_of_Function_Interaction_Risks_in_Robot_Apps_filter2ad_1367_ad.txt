the responding actions before the user-defined timeout (i.e. 0.2s), it
will transmit the velocity action of flow2 with the second priority.
5.2 Security Service
This module aims at visualizing and mitigating risks of malicious
interactions at runtime. It consists of two subcomponents deployed
along with the robot app.
Data Collector. When the robot executes the app within the en-
vironment, all coordination nodes in the instrumented app keep
forwarding their information to this submodule (❹). Such infor-
mation is stored as a risk model, which consists of metadata and a
set of policy parameters (❺). As shown in Figure 8, the metadata
records basic information of a coordination node, including its ID,
node type, node description, trigger time and risk information. They
manage each coordination node and visualize to the users for risk
display and policy configuration.
Risk Controller. This submodule visualizes risk information and
enforces policies from users to each coordination node. Right after
the app is launched on the robot, the Risk Controller obtains all the
8
information of each coordination node from the Data Collector. It
then configures each coordination node by sending user-defined pol-
icy parameters (❼). When the Data Collector receives an event and
the corresponding coordination nodes’ actions at runtime, the Risk
Controller evaluates them against a collection of security policies.
Some policies are mandatory, while some are optional, depending
on the real-world demands (e.g. task or scenario) of end users.
The Risk Controller provides an interface for end users to check
the details of risks and select the optional policies (❻). Figure 7
presents the user consoles for three types of coordination nodes.
There are three components in each console. (1) The rule violation
summary component shows the violation cause and rule of this risk.
(2) The rule violation details component presents the trigger time
and detailed information, e.g., potential malicious nodes, flows. (3)
The policies options component provides optional policy to either
developers or end users in the different stages of RTron. Note that
the end users only have full control of policy selection for RSRCN
and MSRCN, and parameter configurations for two specific policies.
Taking RSRCN as an example (Figure 7(b)). End users can check
the current violation information and reset the corresponding policy
parameters at runtime. When a robot moves from an obstacle-
free environment (e.g., Highway) to a complex environment (e.g.
downtown area), users can select the Constrain policy in an RSRCN
to limit the robot’s maximal velocity.
5.3 Policy Configuration
To sum up, the protection is enforced by both the developer and
end user with the following steps:
Risk Identification. In the development stage, the developer first
launches the target robot app in the simulator, and uses just an
one-line command “rosrisk-search [gr|rsr|msr|all]” to automatically
identify potential risks in the app. Based on the identified infor-
mation, the developer needs to configure the name of predecessor
nodes and successor nodes in each coordination node configuration
file. Note that there is no need to modify the source code of the
original app in this step. Each coordination node would be launched
and deployed into the app automatically.
Risk Mitigation. Risks are mitigated in both the development
stage and operation stage. As shown in Figures 7(a) and (b), the
developer can choose the GRCN policy (blue button), and customize
GRCN and part of RSRCN parameters for each policy (blue square).
In the operation stage, the end users can get the console of RSRCN
and MSRCN. They can choose RSRCN and MSRCN policy (red
button), and customize MSRCN and part of RSRCN parameters for
each policy (blue square).
6 EVALUATION
We aim to answer the following questions:
• Can RTron effectively detect three types of interaction risks?
What is the relationship between the interaction risks and task
characteristics in each robot app? (§ 6.1)
• How many coordination nodes are required to deploy in a typical
robot app? How to configure the policy for an end user under
various environmental contexts? (§ 6.2)
• What is the performance overhead of RTron? (§ 6.3)
Analysis and Mitigation of Function Interaction Risks
in Robot Apps
RAID ’21, October 6–8, 2021, San Sebastian, Spain
Figure 9: Four simulated scenarios in the Gazebo/LGSVL.
Testbed. We study 110 open-source apps from the ROS showcase
website [17], covering 24 different robots including mobile base
(MB), mobile manipulator (MM), micro aerial vehicle (MAV) and
humanoid robot (HR). Table 5 summarizes the categories of these
apps, numbers and the applicable robot types. In addition, we also
perform analysis of more complex apps (Figure 9):
• Home scenario: home-based apps and robots are used to ac-
company people and conduct housework. These tasks include
teleoperation, chat, food/drink delivery, cleaning, safe detec-
tion, and object search. We use four ROS apps (Remote Control,
Face/Person Detection, Object Search and Voice Interaction) of
RosBot 2.0 Pro [22] to develop one home app (Figure 9a).
• AutoRace scenario [30]: this type of apps is designed for compe-
tition of autonomous driving robot platforms. To ensure that
the robot can drive on the track safely, there are six necessary
missions for the robot to execute, including lane detection &
control, traffic light detection, sign detection, parking, level
crossing detection and tunnel driving. We use the open-source
Autonomous Driving app of Turtlebot3 [29] which can realize
all six tasks in the autorace scenario (Figure 9b).
• Autonomous driving scenario: we consider two mainstream self-
driving apps: Autoware [6] and Apollo [7], which have been fully
deployed and tested in physical autonomous vehicles. These two
apps are more complex than the AutoRace scenario, with a richer
set of self-driving modules composed of sensing, computing,
and actuation capabilities (Figure 9c and 9d).
Experimental Setup. Since this paper focuses on the software
risks in robot apps, we mainly use simulation to validate our so-
lution. Implementation and evaluation on physical robots will be
demonstrated in § 7. We choose the Gazebo simulator [9] and ROS
Kinetic in the home and autorace scenarios, which run on a server
equipped with 1.6GHz 4-core Intel i5 processor and Nvidia MX110
Table 5: Analysis of open-source robot apps from the ROS
showcase website [17].
App Categories
Remote Control
Panorama
2D/3D Mapping
Navigation
SLAM
Exploration
Follower
Manipulation
Face/Person Detection
Object/Scene Detection
Object Search
Gesture Recognition
Voice Interaction
Autonomous Driving
# of apps Robot Type
23 (20.8%) MB, MM, HR, MAV Caster
2 (1.8%)
8 (7.3%)
22 (20%)
11 (10%)
5 (4.5%)
8 (7.3%)
8 (7.3%)
8 (7.3%)
5 (4.5%)
1 (1%)
3 (2.7%)
5 (4.5%)
1 (1%)
MB
MB
MB, MM, MAV
MB
MB
MB
MM
MB, MM, MAV
MM
MM
HR, MAV
MB, HR
MB
Example Robot
Turtlebot3
Xbot
Tiago++
Roch
Turtlebot2
Magni Silver
LoCoBot
ARI
Tiago
ROSbot 2.0 PRO
COEX Clover
Qtrobot
Turtlebot3
GPU. In the autonomous driving scenario, we use the LGSVL sim-
ulator [12] with ROS Indigo for Apollo 3.5, and ROS Melodic for
Autoware 1.14, running on a server with 4.2GHz 8-core Intel i7 and
Nvidia GTX 1080 GPU. We use Rviz [27] to visualize 3D information
from both the simulator and robot apps.
6.1 Risk Identification
Single-functional Apps. We successfully extract all the GRs and
MSRs from all 110 open-source apps. GRs are identified by checking
the nodes and topics based on their topology relationship. Some GRs
are ignored when they publish messages to the log/visualization
topic, which will not bring risks to the robot app. MSRs are identified
by inspecting if the standardized topic types are matched.
Different from the GR rule, the RSR rule involves the identi-
fication of specific topic names and types. We choose 15 image-
related apps (e.g., Face/Person Detection, Object/Scene Detection,
Object Search, Autonomous Driving) and 1 max_vel-related app
9
ROSBot2.0 ProPersonLevel CrossingSignParkingLaneTunnelTurtlebot3Traffic Lights6 Tasks1 Teleoperation3 Food Delivery5 Safe Detection2 Chat4 House Cleaning6 Object Search12 FunctionsPreprocessing, Localization, Mapping, Recognition, Path Planning, Global Planner, Path Tracking, Teleoperation, Speech Generation, Mobile Driver, Speaker Driver, Sensors Driver6 Tasks1 Lane Detection & Control2 Traffic Light Detection3 Sigh Detection  4 Parking5 Level Crossing Detection6 Tunnel Driving9 FunctionsPreprocessing, Localization, Mapping, Recognition, Path Planning, Global Planner, Path Tracking, Mobile Driver, Sensors Driver3 Tasks1 Lane Detection & Control2 Traffic Light Detection3 City Driving9 FunctionsPreprocessing, Localization, Mapping, Recognition, Path Planning, Global Planner, Path Tracking, Mobile Driver, Sensors Driver(a) Home(b) Autorace(c) AutowareJaguar2015XE(cid:37)(cid:82)(cid:85)(cid:85)(cid:72)(cid:74)(cid:68)(cid:86)(cid:36)(cid:89)(cid:72)(cid:48)(cid:68)(cid:83)(d) Baidu ApolloJaguar2015XE(cid:37)(cid:82)(cid:85)(cid:85)(cid:72)(cid:74)(cid:68)(cid:86)(cid:36)(cid:89)(cid:72)(cid:48)(cid:68)(cid:83)RAID ’21, October 6–8, 2021, San Sebastian, Spain
Yuan Xu, Tianwei Zhang and Yungang Bao
Policy Selection. RTron implements a variety of policies for three
types of CNs. How to select the appropriate policy for each CN is
critical for the secure operation of robot apps. We use the home
app as an example to illustrate the guideline for policy selection.
GRCN: this is designed to coordinate direct high-risk interactions
between multiple connected nodes. Based on the types of interacted
topics, we classify GRCN into three categories: perception, planning
and control. As shown in Table 8, the messages of interacted topics
in perception are related to the sensory information (e.g. images) or
preprocessed robot states (e.g. footprints, status). Typically, multiple
messages with the same type are published to the same target node,
and processed in parallel for either sensor fusion or state monitoring.
Thus, there is no contention among these messages.
Messages of the interacted topics in planning or control con-
tend with each other to get the long-term and instant control of
the robot. Specifically, when a message of a new planning goal is
received, the robot must first complete the previous goal before
executing the current one. For example, an object search task is
launched after the search_manager node publishes a goal to the
/move_base_simple/goal topic. An adversary can use a malicious
rviz node to send another arbitrary destination to this topic. The
object search task will be immediately interrupted and then the
robot is controlled to reach the designated position. Thus, a GRCN
with the ‘FIFO_Queue’ or ‘Priority_Queue’ policy can delay such
malicious actions without task interruption.
Different from the planning messages, the control messages need
to control the robot immediately. End users can select the ‘Preemp-
tion’ policy of GRCN for coordination. For instance, the malicious
teleop_twist_keyboard node can flood the /cmd_vel topic while
the robot is following a planned path to the destination. Then the
topic receives the messages from both teleop_twist_keyboard
and move_base nodes simultaneously, which causes the robot to
switch velocity in the two target directions. By assigning the high-
est priority to the move_base-related velocity control interaction
(i.e. /cmd_vel), the move_base node can control the robot first.
RSRCN: end users are not recommended to set the ‘Block’ or
‘Safe’ policy. These two options should be chosen by app devel-
opers after extensive evaluations. Instead, users can choose the
‘Constrain’ policy to set a maximal velocity value to limit the ro-
bot’s speed. This is very effective and safe, especially when the
robot’s working environment is highly complex and dynamic, and
the task completion time is not very critical. For example, if an
adversary compromises the move_base node and increases the ro-
bot’s speed to a dangerous level, this can cause a potential traffic
accident. By setting an appropriate threshold in the ‘Safe’ policy or
max_vel_limit in the ‘Constrain’ policy, the robot will slow down
its speed without object detection failures.
MSRCN: although there is only one policy option, users can
customize different rules to allow/block the actions of specific
robots under specific conditions. Taking the home app as an exam-
ple, the MSRCN receives messages from three event-related top-
ics (/objects, /person_detector/detections, /odom) and two
action-related topics (/audio/audio, /cmd_vel). Users can set a
rule to disallow the robot’s movement when it detects the target
object. This can identify and mitigate the interruption of the object
search task caused by the malicious rviz node mentioned above.
Figure 10: Numbers of high-risk nodes in four robot apps.
(Autonomous Driving). We successfully discover all 20 image-related
and 4 max_vel-related RSRs from these apps.
Multi-functional Apps. RTron is also scalable for analysis of
more complex apps. RTron successfully identifies 198 risk interac-
tions in the four target apps. Figure 10 lists the numbers of extracted
nodes with respect to each risk type. We can observe the numbers
of risk interactions in the autorace (blue bar) and autoware (yellow
bar) apps are larger than home (red bar) and apollo (green bar)
apps, although the home app has the largest number of functions.
This is caused by the differences in the internal structure of each
robot app. In the home scenario, each task is relatively independent.
However, in the autorace and autoware apps, all tasks are organized
as a monolithic component to control the robot to drive safely. To
achieve this, these two apps need to recognize various scenes from
sensory images and take the corresponding actions. Consequently,
the high dependency among those tasks increases the number of
GRs. Moreover, the requirement of image and scene recognition in-
creases the number of image-related RSRs and event-related MSRs.
Apollo is a special case where the number of topics is far smaller
than the other apps, thus the number of risks is also the smallest
(Table 9). Table 6 gives examples of the identified high-risk node
for each type in Home-based and AutoRace app. Texts marked in
red are for risk identification in our system.
6.2 Risk Mitigation
CN Analysis. RTron uses the extracted risk information to deploy
CNs. For GRs, the number of GRCNs depends on the number of
high-risk interactions linked to the same node. Thus, RTron checks
the GR information of “Pub Node” and deploys the GRCN between
high-risk nodes and their pub node. For RSRs, since RSRCNs directly
publish velocity messages to the Mobile Driver function, the num-
ber of RSRCN is always 1. The subscriptions of RSRCN is related
to the number of image-related nodes and max_vel-related nodes.
Besides, as described in § 4.1, each image-related node should be as-