10
i
s
e
g
a
P
g
n
d
n
a
L
f
o
r
e
b
m
u
N
0
10
0
20
40
60
80
100
String Classifier Prediction Probability (%)
Fig. 7: Histogram of string cluster classiﬁer probabilities for a
subsample of one million URLs. Distinct sets of features may
be included in an extremely large number of webpages.
the classiﬁer with the highest probability. Similarly for the
Random Sampling experiment, we chose URLs at random.
From the table, we make several observations. First, the
classiﬁer-based method detects a much lower percentage of
URLs than the rule-based system. Second, the detection rate
for the Highest Probability and Random Sampling methods
are roughly comparable. Third, the classiﬁer performs nowhere
near as well as Figure 4 might lead us to hope. That is, Figure
4 suggests that a false negative rate of less than 20% can be
achieved with essentially no false positives. In practice, Table
IV shows a false positive rate of 98.4%: the classiﬁer fails
to deliver the performance that it displayed on the test set in
training. We explore some of the reasons for this failure in
Section V.
Finally, in the following experiment, we seek to understand
the same
whether the classiﬁer-based approach can detect
sets of URLs that are detected by the rule based approach.
To do so, we compute the overlap of the rule-based system
compared to the classiﬁer-based system with High Probability
URL selection, ˆORB,HP :
ˆORB,HP =
| RBD ∩ HP D |
| HP D |
= 70.5%
(1)
where RBD is the set of detected URLs from the rule-based
method and HPD is the set of detected URLs from the high
probability classiﬁer method. By detected, we mean the set
of URLs predicted to be malicious by a method and later
conﬁrmed by the dynamic crawler. Similarly, the overlap of the
rule-based system with respect to the classiﬁer-based system
with Random Sampling URL selection is ˆORB,RS = 23.1%.
From these estimates, we note the rule-based method tends to
select landing pages which are predicted by the classiﬁer to
have a higher probability of being malicious. We also conﬁrm
that the classiﬁer-based approach only detects a subset of the
URLs detected by rule-based approach.
V. DISCUSSIONS
In the previous two sections, we proposed systems to
detect MDN landing pages utilizing either rules or a classiﬁer.
The results from Table IV clearly indicate that the rule-based
system outperforms the classiﬁer in terms of validation rate.
This improvement is primarily due to the inclusion of the false
positive pruning stage. As shown in Figure 7, the classiﬁer
predicts that some pages are more likely to be malicious than
others. At the start of the study, we expected that this would
allow us to select an operating threshold for the classiﬁer to
automatically detect malicious webpages while avoiding false
positive pruning. However, the results from Table IV failed to
support this hypothesis. As conﬁrmed by the dynamic crawler,
the false positive rates for the classiﬁer are signiﬁcantly
higher than expected given the DET results obtained during
training for both the high probability and random sampling
experiments.
One possible reason for the high false positives of the
classiﬁers is that our training data set, especially benign set,
has limited coverage. For example, we discovered that some
of the false positives produced by the classiﬁer were caused
by a string related to accessing an analytics service from
the Russian search engine Yandex. Upon further investigation,
we conﬁrmed that none of the content from our legitimate
webpages accessed this service, but several of the MDNs using
Russian URLs (i.e., .ru) did. This implies that if we include a
more comprehensive benign set (some of which may use this
analytic service), we can effectively reduce the false positives
of the classiﬁers.
A possible usage case for the second classiﬁer-based strat-
egy is to rank the detected webpages so that more malicious
webpages can be veriﬁed ﬁrst. At the present time, we cannot
use the dynamic crawler to scan all possible URLs detected
by our detector. However, one could consider verifying a
more targeted subset of URLs with a production dynamic
crawler. Instead of validating a random URL sample or a
sample corresponding to the highest classiﬁer probabilities,
one could instead sample a ﬁxed number of URLs (e.g. 100)
which include one or more of the features identiﬁed during
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:59:16 UTC from IEEE Xplore.  Restrictions apply. 
feature selection and validate individual features based on the
percentage of landing pages conﬁrmed to be malicious. This
is similar to the proposed false positive pruning strategy, but
instead of considering only URLs which have been scanned
by the dynamic crawler in the past, we verify all possible
injected strings. In this way, the method could consider new
string cluster features which have not been found on previously
detected webpages.
There are several cases where attackers could evade or
abuse the detection system. For example, in the false positive
pruning stage of rule-based detection, a feature is retained
if 60% or more of the pages containing the feature were
previously scanned by the dynamic crawler and detected as
malicious. Hypothetically, attackers can abuse the pruning
stage by including this feature in 41% of the landing pages
which do not launch an attack. However, we argue that this
is unlikely to happen in practice considering the overhead
and difﬁculty of injecting malicious code in legitimate landing
pages. Giving up 41% of injected landing pages is a big loss
for attackers.
In addition, polymorphic and obfuscated injection is an-
other challenge for our system. Today, attackers tend to hide
the real purpose of the injected code by making it unreadable.
There are limitless ways to obfuscate a piece of code to give
it a totally different and unreadable appearance. Our scheme
works against content that is either obfuscated or polymorphic,
but not both. In an extreme case where the attacker obfuscated
the code in different ways on every single landing page in the
MDN, the feature selection algorithm will fail to recognize
these malicious strings.
Our system works together with both the dynamic and
static crawlers. There are several common challenges that
crawlers have that may affect our system. First, the dynamic
crawler exposes vulnerable components to webpages and de-
tect malicious responses. Thus it is possible that the dynamic
crawler may fail to detect some of the attacks due to a limited
conﬁguration of vulnerable components. In addition, cloaking
is concern for both the static and dynamic crawlers. Attackers
can identify the crawler (e.g., by knowing the IP addresses
from which it operates or detecting the presence of the virtual
machine), and evade detection by not attempting to exploit a
vulnerability or returning legitimate content.
Finally, our system is limited in the fact that it requires
an initial set of MDNs. Thus our system can be considered
supplemental to other detection techniques rather than a stand-
alone system.
VI. RELATED WORK
To defend against drive-by download attacks, a number
of systems have been proposed from both the research and
industrial communities. These systems use different strategies
to detect drive-by downloads, including classifying malicious
URLs or web content, actively exploiting web servers with
client-side honeypot, identifying attacks from a single instance
or correlating multiple landing pages within a campaign. We
categorize these systems and techniques from the following
perspectives.
First, most systems start from landing pages: they visit
the malicious websites, execute the embedded script, and
traverses the secondary URLs while monitoring suspicious
state changes of the operating system in order to detect drive-
by downloads. For example, systems like [15], [16], [17], [18]
will dynamically execute the web content and capture drive-
by downloads based on either signatures or anomaly detection.
PhoneyC [19] and WebPatrol [20] use a signature-based, low-
interaction honeypot to detect rogue websites. In addition,
Nozzle [11] is a runtime monitoring infrastructure which
detects malicious heap spray attempts, while JSAND [21] takes
a machine learning approach to classify malicious javascript.
Rozzle [22] is another javascript virtual machine. It explores
multiple execution paths within a single execution in order
to expand the possibility of triggering the malicious scripts.
Finally, Blade [23] leverages user behavior models for drive-
by download detection. All of these systems have shown good
detection results. However, it is usually costly to follow the full
redirection path and monitor each script execution in runtime.
Moreover, their accuracy is highly dependent on the webpage’s
malicious response to vulnerable components.
Some systems work in the reverse direction: they start with
servers hosting malicious exploits and reverse the redirection
path to discover the corresponding landing pages. Leveraging
the drive-by download traces contributed by dynamic crawlers
or public anti-virus databases, these systems could discover
the campaign-like malware distribution networks (MDNs) [4].
Existing systems [8], [24] fall into this category. WebCop [24]
uses static hyperlinks to build a web graph of malware
distribution networks. The limitations of WebCop are the
static web graph and exact match approach, which are less
resilient to dynamic changes of the web. Arrow [8] detects and
generates URL signatures for the central server in complex
MDNs in order to detect more landing pages sharing these
central servers. In this paper, we also follow this approach
in discovering MDNs. Unlike [8], [24], we leverage both the
static and dynamic crawlers and focus on the malicious code
in the landing page content instead of URLs. Arrow can only
ﬁnd additional webpages which have previously scanned, but
undetected, by the dynamic crawler.
In addition, static analysis is a technique adopted by many
existing systems [12], [25], [26] to detect malicious webpages.
Most of these systems explore multiple features from malicious
javascript code: for example, Zozzle [12] focuses on the
contextual features in javascript code to detect heap spraying.
Systems like Prophiler [25] consider both javascript features
and additional features extracted from the HTML content and
URLs of malicious pages. A recent system EvilSeed [26]
generates gadgets by analyzing the page content, DNS traces
and link topology of known malicious pages, and then uses the
gadgets to discover similar pages. Unlike the dynamic analysis
of the honeypot approach, the mentioned static analysis is more
light-weight and less time-consuming. Our work differs from
existing work in this detection scope and considered features:
previous systems are generic detectors for generally malicious
content in webpages, while our system precisely targets the
landing page features of speciﬁc MDNs.
Finally, SURF [27] and deSEO [28] study the malware
distribution campaigns from the perspective of blackhat Search
Engine Optimization (SEO). In a typical drive-by download
attack, one important function of landing pages is to drive
trafﬁc to the exploit servers. Attackers have been trying differ-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:59:16 UTC from IEEE Xplore.  Restrictions apply. 
ent SEO techniques to rank malicious landing pages high in
the search results for popular queries. SURF uses the features
extracted from the search-then-visit browsing sessions to detect
malicious redirections from the search results. It can work as a
scanner in the dynamic crawler. deSEO, on the other hand, is
a signature-based detector using the patterns of the malicious
URLs in the search results. In our approach, we use URLs
in the redirection paths to discover large malware distribution
networks, but our detector focuses more on the malicious code
in the web content.
VII. CONCLUSIONS
In this paper, we analyze landing pages belonging to
malware distribution networks (MDNs) which lead to drive-
by download attacks. Using a large set of drive-by download
traces from a production dynamic crawler, we show that
landing pages within the same MDN have a certain level of
similarity in their malicious content that causes redirection.
With the aid of multiclass feature selection, we are able
to identify the MDN-speciﬁc features that best discriminate
landing pages of one MDN with those of other MDNs and
benign webpages.
We propose and implement two new solutions to efﬁciently
detect malicious landing pages. The ﬁrst, rule-based system,
which is based on matching clusters of strings, exhibits high
precision in identifying malicious injected code in the land-
ing pages within the MDN. This system produces a list of
URLs out of which over 57% are independently validated as
malicious by a production dynamic crawler. This success rate
remains constant in two large trials spaced ﬁve months apart.
This extends the known footprint of the MDNs studied by
17%.
The second system, which implements a classiﬁer, also
produces set of URLs of which approximately 1% are inde-
pendently conﬁrmed to be malicious. Compared to the rule-
based method, we conclude that the classiﬁer offers little utility
in this setting without using a far greater training set. We
include the results of the classiﬁer system in the paper for
completeness.
ACKNOWLEDGMENTS
The authors would like to thank the reviewers for their
feedback, Yinglian Xie and Fang Yu for providing software for
computing regular expressions, Christian Seifert for insights on
search engines and crawlers, and Sarmad Fayyaz for guidance
on running experiments.
REFERENCES
[1] C. Jackson, “Improving Browser Security Policies,” Ph.D. dissertation,
Stanford University, 2009.
[4] N. Provos, P. Mavrommatis, M. Abu Rajab and F. Monrose, “All your
iframes points to us,” in Proc. USENIX Security, 2008.
[5] Trustseer Security Advisory, “Flash Security Hole Advisory,” http://
www.trusteer.com/ﬁles/Flash Security Hole Advisory.pdf, 2009.
[6] S. S. David Wang and G. M. Voelker, “Cloak and dagger: Dynamics
of web search cloaking,” in Proc. ACM CCS, 2011.
[7] M. Roesch, “Snort - lightweight intrusion detection for networks,” in
Proc. USENIX LISA, 1999.
[8]
J. Zhang, C. Seifert, J. W. Stokes, and W. Lee, “Arrow: Generating
signatures to detect drive-by downloads,” in Proc. WWW, 2011.
[9] G. Ball and D. Hall, “ISODATA, a novel method of data analysis and
pattern classiﬁcation,” DTIC Document, Tech. Rep., 1965.
[10] C. D. Manning, P. Raghavan, and H. Schtze, An Introduction to
Information Retrieval. Cambridge University Press, 2009.
[11] P. Ratanaworabhan, B. Livshits, and B. Zorn, “Nozzle: A defense
against heap-spraying code injection attacks,” in Proc. USENIX Secu-
rity, 2009.
[12] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert, “Zozzle: Low-
overhead mostly static javascript malware detection,” in Proc. USENIX
Security, 2011.
[13] Y. Xie, F. Yu, K. Achan, R. Panigraphy, G. Hulten and I. Osipkov,
“Spamming botnets: Signatures and characteristics,” in Proc. ACM
SIGCOMM, 2008.
[14] C. Bishop, Pattern Recognition and Machine Learning. Springer, 2006.
[15] A. Moshchuk, T. Bragin, S. D. Gribble, and H. M. Levy, “A crawler-
based study of spyware on the web,” in Proc. NDSS, 2006.
[16] C. Seifert and R. Steenson, “Capture - honeypot client (capture-hpc),”
https://projects.honeynet.org/capture-hpc, 2006.
[17] C. Seifert, R. Steenson, T. Holz, B. Yuan and M. A. Davis, “Know your
enemy: Malicious web servers,” http://www.honeynet.org/papers/mws/,
2007.
[18] Y.-M. Wang, D. Beck, X. Jiang, R. Roussev, C. Verbowski, S. Chen and
S. King, “Automated web patrol with strider honeymonkeys: Finding
web sites that exploit browser vulnerabilities,” in Proc. NDSS, 2006.
[19]
J. Nazario, “Phoneyc: A virtual client honeypot,” in Proc. USENIX
LEET, 2009.
[20] K. Z. Chen, G. Gu, J. Zhuge, J. Nazario, and X. Han, “Webpatrol:
automated collection and replay of web-based malware scenarios,” in
Proc. ASIACCS, 2011.
[21] M. Cova, C. Kruegel and G. Vigna, “Detection and analysis of drive-
by-download attacks and malicious javascript code,” in Proc. WWW,
2010.
[22] C. Kolbitsch, B. Livshits, B. Zorn, and C. Seifert, “Rozzle: De-cloaking
internet malware,” in Proc. IEEE Symposium on Security and Privacy,
2012.
[23] L. Lu, V. Yegneswaran, P. Porras and W. Lee, “Blade: An attack-
agnostic approach for preventing drive-by malware infections,” in Proc.
ACM CCS, 2010.
[24]
J. W. Stokes, R. Andersen, C. Seifert and K. Chellapilla, “Webcop:
Locating neighborhoods of malware on the web,” in Proc. USENIX
LEET, 2010.
[25] D. Canali, M. Cova, C. Kruegel, and G. Vigna, “Prophiler: A fast ﬁlter
for the large-scale detection of malicious web pages,” in Proc. WWW,
2011.
[26] L. Invernizzi, S. Benvenuti, P. M. Comparetti, M. Cova, C. Kruegel,
and G. Vigna, “Evilseed: A guided approach to ﬁnding malicious web
pages,” in Proc. IEEE Symposium on Security and Privacy, 2012.
[2] R. Dhamija, J. D. Tygar, and M. Hearst, “Why phishing works,” in
[27] L. Lu, R. Perdisci, and W. Lee, “SURF: detecting and measuring search
Proc. CHI, 2006.
poisoning,” in Proc. ACM CCS, 2011.
[3] S. Schechter, R. Dhamija, A. Ozment, I. Fischer, “The Emperor’s New
Security Indicators: An evaluation of website authentication and the
effect of role playing on usability studies,” in Proc. IEEE Symposium
on Security and Privacy, 2007.
[28]
J. P. John, F. Yu, Y. Xie, A. Krishnamurthy, and M. Abadi, “eSEO:
Combating search-result poisoning,” in Proc. USENIX Security, 2011.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:59:16 UTC from IEEE Xplore.  Restrictions apply.