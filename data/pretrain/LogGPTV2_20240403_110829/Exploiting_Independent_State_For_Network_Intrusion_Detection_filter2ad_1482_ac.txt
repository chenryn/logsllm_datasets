### Dividing by IP Space

Efficiently dividing the local IP space requires a thorough understanding of the network to ensure that individual Network Intrusion Detection Systems (NIDS) receive comparable loads. From our operational experience, measuring traffic volume and leveraging the expertise of network administrators is relatively straightforward. The primary advantage of distributing based on IP space division is the ease with which additional systems can be introduced to further distribute the load. However, the main disadvantage is the loss of correlation between different subnets without communication, such as detecting scans.

To evaluate this approach, we analyzed Bro 0.8a53 policy scripts to determine the degree of communication they would require. We found that there is one dominant case where lack of communication would result in information loss: several scripts store information about individual hosts, typically in the form “host a.b.c.d did something [n times]”. For example, the worm detection script maintains a table of known worm-infected hosts. If this state is not propagated among concurrent Bro instances, two issues arise: (i) each instance will generate an alert if it detects the worm, and (ii) more critically, if an instance cannot identify the worm on its own, it cannot use this information in other contexts, such as treating signatures matching a known worm-infected host differently from other matches.

### Dividing by Application

To divide the load by application, we delegate applications that contribute significantly to the load to dedicated systems. For instance, if there is a large fraction of HTTP traffic, we could exclude HTTP processing from the main system and move its analysis to another machine. This is what we do operationally at LBNL. However, this approach lacks general scalability: the load is only significantly reduced if the NIDS spends a considerable amount of time processing the particular application. For Bro, this is true for HTTP (due to Bro’s detailed analysis of HTTP sessions) and a few other applications, but these are limited in number.

We also examined the scripts to assess where application-based division would require inter-Bro communication. While application-specific analysis generally does not need communication, one exception is the FTP analyzer, which parses the PORT negotiation of FTP data connections. A more general problem concerns analyzers that need to see traffic from all applications, such as Bro’s scan detector, which counts connection attempts to different ports per host. Other examples include the ICMP analyzer correlating ICMP “unreachable” messages with corresponding connections and the analyzer that derives vulnerability profiles.

It appears clear that the communication for these analyses can be addressed using spatially independent state, and we expect to gain operational experience in doing so at LBNL, where it has long been desired to coordinate the separate HTTP Bro.

### Sensor Model

A well-established architecture for distributed network intrusion detection is the sensor model, where sensors are placed at different points in the network to perform low-level analysis like protocol decoding or byte-signature matching. These sensors then send their results to an analyzer, which correlates the data from all input sources.

Bro is conceptually well-suited for this kind of deployment, as its architecture clearly separates low-level and high-level analysis through its event engine and policy script interpreter. The main interface between these layers is the events. Therefore, the most obvious way to apply the distributed sensor model to Bro is to spatially separate the event engine from the script layer (i.e., run them as separate processes). This becomes easy to achieve using spatially independent state.

However, as discussed in Section 5, propagating large volumes of data comes at a non-negligible cost. While propagating all of the event layer’s information works well for smaller setups, it does not scale to high-volume networks. In such environments, it is more promising to partition the processing a layer up. That is, the sensors would perform the usual script-level analysis in addition to their event engine processing, with those scripts synchronized as discussed in §4.3.1, and then dedicate an additional CPU to correlating their combined output at a meta-level, for example, by using correlation methods such as presented in [6, 13, 25].

As a first step in this direction, we implemented a simple but operationally very fruitful extension: combining all log messages coherently in a single place. In the MWN setup, a central server receives all output in real-time. We note that while this is available in other distributed NIDSs, their communication is often restricted to the exchange of log-like messages. With our architecture, centralized logging is an almost trivial application: each script-level log statement generates an event that gets propagated to the central server.

### Propagating Information

Another potentially valuable application of spatially independent state is using it to share information about our analysis with other systems. We discuss two examples here: intensifying analysis for suspicious hosts, which we have already experimented with, and propagating IPs that we have chosen to dynamically block, which we plan to implement in the near future.

**Suspicious Hosts:**
Due to the large load on a high-volume link, a single system cannot run detailed analysis on the full traffic. One solution is to run only coarse-grained analysis on all traffic but to intensify the inspection for hosts found to be suspicious. For example, attackers often perform scans of the network before targeting specific hosts. Large scans are easily detectable using coarse-grained analysis. After identifying a scanner, we can then look at the packets coming from the same source in more detail.

We implemented this by running two instances of Bro. The first instance watches a large fraction of the traffic but only runs a modest set of policy scripts (most notably the scan detector). When it generates an alert for some host, it also sends an event containing the host’s IP address to the second Bro instance. By default, the second instance does not see any traffic. But if it receives a suspicious address, it modifies its analysis to include all packets from that source. In addition to using more scripts and a large set of signatures, it saves the complete set of packets to disk.

**Propagating Blocked Hosts:**
Our LBNL environment currently runs several Bro instances at different entry points into the network. As discussed in [11], LBNL’s security policy includes dynamically blocking scanners detected by Bro by modifying the border router’s access control list. Because a scanner may probe multiple sets of addresses corresponding to different entry points, there is considerable operational interest in enabling the different Bro instances to communicate their blocking decisions to one another.

### Reconfiguration, Profiling, and Debugging

A final set of applications for independent state leverages the broader notion of independent state, encompassing not only data values but also functions and policy script event handlers. Such independent state allows us, first, to both tune and retarget the system without having to restart it; and, second, to inspect the system’s state during runtime in several different ways.

**Dynamic Reconfiguration:**
We can use the independence of broader forms of state (functions and event handlers) to dynamically reconfigure a running Bro. This supports both operational flexibility and tuning. During daily operations, the need often arises to change the configuration of the NIDS in response to a newly perceived threat or problem. For example, if we detect a break-in, we might want to alert on any return by the attacker; or if we learn a new attack signature, we might want to start using it immediately; or if a new source of benign traffic overwhelms the NIDS, we might want to skip processing it temporarily. These changes can occur in a firefighting mode, where immediate deployment is necessary. With independent state, we can introduce such changes, including modified function and event handler definitions, directly, without losing fine-grained state.

Another use of dynamic reconfiguration is to support tuning, i.e., optimizing the NIDS’s configuration for the local environment. From our experience, one of the most common problems with making configuration changes for tuning is that the effects of the changes often do not show up immediately. Until now, making such changes has required restarting the NIDS, with the consequent loss of the system’s state. Additionally, the effects of many changes are only visible when the system has built up a significant amount of state, which can take a long time after a conventional restart. This is particularly true for configuration parameters like timeouts and thresholds. We can ameliorate this problem by collecting traffic traces and testing against them offline, but such traces can be huge and unwieldy to work with.

**Proﬁling and Debugging:**
Understanding the behavior of a NIDS during operation is another significant problem. When developing policy scripts, we find they can work in unexpected ways due to programming errors or encountering network traffic with different characteristics than expected. These issues are hard to track down, as they often only manifest themselves after a considerable amount of runtime.

We find it helpful to inspect Bro’s current state. With independent state, this becomes easy to achieve, as the files generated by checkpoint contain all the necessary information. For example, Figure 2(a) shows the table containing all currently known port scanners at a given point in time, including timestamps when the entries were last accessed. Figure 2(b) shows the same table from about 1.5 hours later. For larger tables, the differences may be hard to see, but the ASCII output formats are suitable for processing with Unix utilities such as `sort` and `diff`, as illustrated in Figure 2(c). Now the differences become obvious, and we can actually see the scan detector working.

Along with data values, our implementation of independent state provides timestamping for script functions. Figure 2(d) shows a checkpoint of the `check_hot` function from the default scan detection script. The different basic blocks in the code are annotated with timestamps indicating the last time they were executed and with counts of how many times they have been executed. These annotations are invaluable for profiling, assessing code coverage, and detecting stale script elements. We can again use tools like `diff` to dynamically track which portions of the code are being executed and how frequently.

### Performance Evaluation

To examine the performance of our architecture in more detail, we assessed the communication system, as this encompasses most of the other components (e.g., the serialization framework). First, we used synthetic stress-tests to gauge the maximal throughput. Then we turned to real-world traffic captured in the MWN environment to assess the system’s performance on realistic data.

For all of our experiments, we used two machines, acting as sender and receiver. For most measurements, the systems ran a Linux 2.6.x kernel. For the experiments involving live-capture of network traffic, we used hosts running FreeBSD 5.2.1. In both cases, the sending systems were dual-Xeons, 3Ghz, with 2GB of RAM; the receivers were dual-Opterons, 1.8Ghz, with 2GB of RAM. Senders and receivers were connected by a 100Mb/s switch.

#### Benchmarks

First, we instrumented the sender to emit events at configurable rates. Starting with no output at all, we increased the rate by 1000 events every 5 seconds until either the sender or the receiver could not handle the load anymore. Simultaneously, the sender sent out ping messages every second to which the receiver responded with pongs, measuring the lapsed interval as a ping-time. At the time the sender’s main process sees the pong, the ping/pong combo has traversed four different processes (sender’s main, sender’s communication, receiver’s communication, receiver’s main, and back). Thus, the ping-time is a measure of the lag introduced by the communication. The smaller the ping-times, the faster events (and other information) are propagated. If the ping-times start to increase, it is a sign that some queue on the path is filling up, i.e., a limit has been reached.

Figure 3(a) shows the rate of emitted events as well as the ping-times. We see that with increasing output, the ping-times were roughly constant (with a median of 2ms) until the sender’s rate got to about 44,000 events per second (which comprise a volume of 8.3MB per second). At this point, the ping-times exceeded 0.1s for the first time and continued to increase. It turned out that it was the receiver that became overloaded. For every received event, its main process had to call a (empty) script-level handler, which became too much of a burden eventually. In our synthetic benchmark, the sender itself did not raise the events but only sent them out. Therefore, event handling was not a problem on its side.

Events have different types of arguments. The events used for Figure 3(a) carried two parameters: a string and a compound connection type, which is rather complex, containing more compound objects itself. If we reduce the complexity of the arguments, we are able to achieve higher rates, up to more than 100,000 events per second when sending events without any parameter at all. We conducted benchmarks for state-propagating (as `&synchronized` script variables; similar operations with triggered events) and found similar results.