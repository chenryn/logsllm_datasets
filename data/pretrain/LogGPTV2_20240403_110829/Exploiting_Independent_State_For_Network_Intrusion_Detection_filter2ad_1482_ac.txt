Dividing by IP space: Fruitfully spliting up the local
IP space requires knowledge of the network to ﬁnd a di-
vision so that individual NIDS receive comparable loads.
From our operational experience, measuring the volume
and leveraging the expertise of the network’s administra-
tors to do so is not hard. The main advantage of distribution
based on dividing the IP space is the ease of further dis-
tributing the load by introducing additional systems. The
main disadvantage is that, without any communication, we
cannot correlate trafﬁc between different subnets anymore,
such as detecting scans.
To assess this approach, we examined the Bro 0.8a53
policy scripts to determine the degree of communication
they would require. We found that there is one dominant
case where without communication we would lose infor-
mation: several scripts store information about individual
hosts, usually of the form “host a.b.c.d did something [n
times]”. For example, the worm detection script keeps a
table storing all already-known worm infectees. Not prop-
agating this state among the concurrent Bro’s would have
two effects: (i) each of the instances would alert individ-
ually if it recognizes the worm, and (ii) more importantly,
if an instance cannot identify the worm by itself, it obvi-
ously cannot use this information in other contexts (e.g.,
treat signatures matching a known worm infectee different
from other matches).
4E.g., the trafﬁc level in the MWN (UCB) environment sustains more
than 250 (400) Mbps averaged over an entire day.
With spatially independent state, however, we can
easily solve these problems by declaring the tables
&synchronized (per §3.2.2). Now each instance propa-
gates its state to the peers.
Dividing by application: To divide the load by appli-
cation, we delegate applications that make up a signiﬁcant
share of the load to dedicated systems. If, for example, there
is a large fraction of HTTP trafﬁc, we could exclude HTTP
processing from the main system and move its analysis to
another machine. This is in fact what we do operationally at
LBNL. But this approach lacks general scalability: the load
is only signiﬁcantly reduced if the NIDS does indeed spend
quite some time processing the particular application. For
Bro, this is true for HTTP (due to Bro’s detailed analysis of
the HTTP sessions), and also for a few other applications,
but these total only a handful.
Again we examined the scripts to assess where divi-
sion by application would require inter-Bro communication.
While usually for application-speciﬁc analysis no commu-
nication is needed, one exception is the FTP analyzer be-
cause it parses the PORT negotiation of FTP data connec-
tions. A more general problem concerns analyzers that need
to see trafﬁc from all applications, such as Bro’s scan de-
tector. To detect vertical port scans, it counts connection
attempts to different ports (applications) per host. Other ex-
amples include the ICMP analyzer correlating ICMP “un-
reachable” messages with corresponding connections, and
the analyzer that derives vulnerability proﬁles [20].
It appears clear that the communication for these anal-
yses can be addressed using spatially independent state,
and we expect to gain operational experience in doing so
at LBNL, where it has long been desired to coordinate the
separate HTTP Bro.
4.3.2 Sensor Model
A well-established architecture for distributed network in-
trusion detection is the sensor model [1],
in which we
place sensors at different points in the network, usually per-
forming low-level analysis like protocol-decoding or byte-
signature matching. The sensors then send their results to
an analyzer which correlates the data from all of its input
sources.
Bro is conceptually well-suited for this kind of deploy-
ment.
Its architecture already clearly separates between
low-level and high-level analysis by means of its division
into event engine and policy script interpreter. The main
interface between these two layers are the events. So, the
most obvious way to apply the distributed sensor model to
Bro is to spatially separate the event engine from the script
layer (i.e., run them as separate processes). This becomes
easy to achieve using spatially independent state.
However, as we will discuss in Section 5, propagat-
ing large volumes of data comes at a non-negligible cost.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:11:05 UTC from IEEE Xplore.  Restrictions apply. 
Therefore, while propagating all of the event layer’s infor-
mation will work well for smaller setups, it does not scale
to high-volume networks. Hence, in such environments it
is more promising to partition the processing a layer up.
That is, the sensors would perform the usual script-level
analysis in addition to their event engine processing, with
those scripts synchronized as discussed in §4.3.1, and then
we would dedicate an additional CPU to correlating their
combined output at a meta-level, for example by using cor-
relation methods such as presented in [6, 13, 25].
As a ﬁrst step in this direction we implemented a sim-
ple but operationally very fruitful extension: combining all
log messages coherently in a single place.
In the MWN
setup, a central server receives all output in realtime. We
note that while this is available in other distributed NIDSs,
their communication is often restricted to the exchange of
log-like messages. With our architecture, centralized log-
ging is an almost trivial application: each script-level log
statement generates an event which gets propagated to the
central server.
4.3.3 Propagating Information
Another potentially valuable application of spatially inde-
pendent state is using it to tell other systems some facts
about our analysis. We discuss two examples here, the
ﬁrst (intensifying analysis for suspicious hosts) of which we
have already experimented with, and the second (propagate
IPs that we have chosen to dynamically block) of which we
plan to set in place in the near future.
Suspicious hosts: As mentioned above, due to the large
load on a high-volume link, a single system cannot run de-
tailed analysis on the full trafﬁc. One solution is to run only
coarse-grained analysis on all of the trafﬁc, but to intensify
the inspection for hosts found to be conspicuous. For exam-
ple, often administrators observe that attackers ﬁrst perform
scans of the network before actually targeting some hosts.
Large scans are easily detectable using coarse-grained anal-
ysis. After identifying a scanner, we can then look at the
packets coming from the same source in more detail.
We implemented this by running two instances of Bro.
The ﬁrst instance watches a large fraction of the trafﬁc but
only runs a modest set of policy scripts (most notably the
scan detector). When it generates an alert for some host, it
also sends an event containing the host’s IP address to the
second Bro instance. By default, the second instance does
not see any trafﬁc at all. But if it receives such a suspicious
address, it modiﬁes its analysis to include all packets com-
ing from that source. In addition to using more scripts and
a large set of signatures, it saves the complete set of packets
to disk.
network. As discussed in [11], LBNL’s security policy in-
cludes dynamically blocking scanners detected by Bro by
modifying the border router’s access control list. Because
not infrequently a scanner ﬁrst probes a set of addresses cor-
responding to one entry point and then later another set cor-
responding to a different entry point, there is considerable
operational interest in enabling the different Bro’s to com-
municate their blocking decisions to one another.
4.4 Reconﬁguration, Proﬁling and Debugging
A ﬁnal set of applications for independent state leverage
the broader notion of independent state encompassing not
only data values but also functions and policy script event
handlers. Such independent state allows us, ﬁrst, to both
tune and retarget the system without having to restart it; and,
second, to inspect the system’s state during run-time in sev-
eral different ways.
Dynamic Reconﬁguration: We can use the indepen-
dence of broader forms of state (functions and event han-
dlers) to dynamically reconﬁgure a running Bro. Doing so
supports both operational ﬂexibility and tuning. In terms
of operational ﬂexibility, frequently during daily operations
the need arises to change the conﬁguration of the NIDS in
response to a newly perceived threat or problem. For exam-
ple, we have detected a break-in and now want to alert on
any return by the attacker; or, we have learned a new attack
signature and want to immediately start using it; or, a new
source of benign trafﬁc has appeared which is overwhelm-
ing the NIDS and we want to skip processing it for now.
These all can occur in a ﬁre-ﬁghting mode, i.e., we really
need to deploy the change immediately. With independent
state, we can introduce such changes—including modiﬁed
function and event handler deﬁnitions—directly, without in-
curring the loss of ﬁne-grained state that would occur using
our enhanced checkpointing.
Another use of dynamic reconﬁguration is to support
tuning, i.e., optimizing the NIDS’s conﬁguration for the
local environment. From our experience, one of the most
common problems with making conﬁguration changes for
tuning is that the effects of the changes often do not show
up immediately. Until now, making such changes has re-
quired restarting the NIDS, with the consequent loss of the
system’s state.
In addition, the effects of many changes
are only visible when the system has built up a signiﬁcant
amount of state, which can take a long time after a con-
ventional restart. This is particularly true for conﬁguration
parameters like timeouts and thresholds. We can ameliorate
this problem by collecting trafﬁc traces and testing against
them off-line, but such traces can be huge and unwieldy to
work with.
Propagating blocked hosts: Our LBNL environment
currently runs several Bro’s at different entry points into the
While our enhanced checkpointing can help, it does not
fully solve the problem. Often when making many small
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:11:05 UTC from IEEE Xplore.  Restrictions apply. 
changes in a short time, we do not actually want the con-
trolled loss of state which checkpointing achieves, but pre-
fer to keep all state. We want ideally to have the system
just pick up the changes and keep running, similar to the
ﬁre-ﬁghting changes discussed above.
The way we do such on-the-ﬂy changes in practice is as
follows. Consider an already-running Bro whose conﬁgura-
tion we would like to change in some respect. We ﬁrst make
the modiﬁcation to the conﬁguration, i.e., edit the scripts.
We then convert the full conﬁguration into persistent state,
stored in a ﬁle, as described in §3.2.1. Finally, we copy
the ﬁle into a directory regularly checked by the running in-
stance, which notices the update, loads it, and switches to
using it. No other state is lost.
Proﬁling and Debugging: Another signiﬁcant problem
when operating a NIDS is understanding its behavior during
operation. When developing policy scripts, we ﬁnd they can
work in unexpected ways, due to either programming er-
rors, or to encountering network trafﬁc with different char-
acteristics than we expected. These kinds of problems are
very hard to track down, as often they only manifest them-
selves after a considerable amount of run-time.
We ﬁnd it is a great help if we can take a look at Bro’s
current state. With independent state, this becomes easy to
achieve, since the ﬁles generated by checkpoint contain
all the necessary information. In Figure 2(a), for example,
we see the table containing all currently known port scan-
Included in the output are
ners at a given point of time.
timestamps when the entries were last accessed.
In Fig-
ure 2(b), we see the same table from about 1.5 hours later.
For larger tables, the differences may be hard to see, but the
ASCII output formats are suitable for processing with Unix
utilities such as sort and diff, as illustrated in Figure 2(c).
Now the differences become obvious; we can actually see
the scan detector working.
Along with data values, our implementation of indepen-
dent state provides timestamping for script functions, too.
Figure 2(d) shows a checkpoint of the check hot func-
tion from the default scan detection script. The different
basic blocks in the code are annotated with timestamps in-
dicating the last time they were executed, and with counts
of how many times they have been executed. These annota-
tions can be invaluable for proﬁling, assessing code cover-
age, and detecting stale script elements. We can again use
tools like diff to dynamically track which portions of the
code are being executed, and how frequently.
5 Performance Evaluation
To examine the performance of our architecture in more
detail, we assessed the communication system, as this en-
compasses most of the other components (e.g., the serial-
ization framework). First, we used synthetic stress-tests to
gauge the maximal throughput. Then we turned to real-
world trafﬁc captured in the MWN environment to assess
the system’s performance on realistic data.
For all of our experiments, we used two machines, act-
ing as sender and receiver. For most of the measurements,
the systems ran a Linux 2.6.x kernel. For the experiments
involving live-capture of network trafﬁc, we used hosts run-
ning FreeBSD 5.2.1.
In both cases, the sending systems
were dual-Xeons, 3Ghz, with 2GB of RAM; the receivers
were dual-Opterons, 1.8Ghz, with 2GB of RAM. Senders
and receivers were connected by a 100Mb/s switch.
5.1 Benchmarks
First, we instrumented the sender to emit events at con-
ﬁgurable rates. Starting with no output at all, we in-
creased the rate by 1000 events every 5 seconds until ei-
ther the sender or the receiver could not handle the load
anymore. Simultaneously, the sender sent out ping mes-
sages every second to which the receiver responded with
pongs, measuring the lapsed interval as a ping-time. At
the time the sender’s main process sees the pong,
the
ping/pong combo has traversed four different processes
(sender’s main, sender’s communication, receiver’s com-
munication, receiver’s main, and back). Thus, the ping-time
is a measure for the lag which the communication intro-
duces. The smaller the ping-times, the faster events (and
other information) are propagated. If the ping-times start to
increase, it is a sign that some queue on the path is ﬁlling
up, i.e. a limit has been reached.
Figure 3(a) shows the rate of emitted events as well as
the ping-times. We see that with increasing output the ping-
times were roughly constant (with a median of 2ms) un-
til the sender’s rate got to about 44,000 events per second
(which comprise a volume of 8.3MB per second). At this
point, the ping-times exceeded 0.1s for the ﬁrst time and
continued to increase. It turned out that it was the receiver
that became overloaded. For every received event, its main
process had to call a (empty) script-level handler, which be-
came too much of a burden eventually.
In our synthetic
benchmark, the sender itself did not raise the events but only
sent them out. Therefore, event handling was not a problem
on its side.
Events have different types of arguments. The events
used for Figure 3(a) carried two parameters: a string and a
compound connection type, which is rather complex, con-
taining more compound objects itself.
If we reduce the
complexity of the arguments we are able to achieve higher
rates, up to more than 100,000 events per second when
sending events without any parameter at all.
We
conducted
benchmarks
state-propagating
(as
&synchronzized script variables;
similar
operations
with
by
see §3.2.2) and
triggered
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:11:05 UTC from IEEE Xplore.  Restrictions apply. 
Figure 2: Visualizing state (addresses randomized)
ID reported_port_scans = {
ID reported_port_scans = {
[165.11.184.36, 148.126.197.84, 100]
[138.112.68.194, 108.45.144.114, 1000]
[138.112.68.194, 108.45.144.114, 100]
[138.112.68.194, 108.45.144.114, 10000] @01/21-11:01
[138.112.68.194, 108.45.144.114, 50]
[165.11.184.36, 148.126.197.84, 50]