:::
::: variablelist
[\"Snoop\"列]{.term}
:   显示总线事务.
[\'TLB Access\' 列]{.term}
:   显示 TLB 内存访问。
[\'Locked\' 列]{.term}
:   指示函数是否已被锁定或未锁定内存。
:::
在默认模式中，函数按照降序排列，其开销最先显示。
:::
:::
[]{#detecting-false-sharing_monitoring-and-managing-system-status-and-performance.html}
::: chapter
::: titlepage
# []{#detecting-false-sharing_monitoring-and-managing-system-status-and-performance.html#detecting-false-sharing_monitoring-and-managing-system-status-and-performance}第 26 章 检测错误共享 {.title}
:::
当对称多处理(SMP)系统上的处理器核心修改同一缓存行上供其他处理器用于访问处理器之间未共享的其他数据项时，就会进行错误共享。
这种初始修改要求使用缓存行的其他处理器将其副本失效并请求更新的处理器，尽管处理器不需要，甚至不必访问更新后的数据项版本。
您可以使用 `perf c2c`{.literal} 命令检测错误共享。
::: section
::: titlepage
# []{#detecting-false-sharing_monitoring-and-managing-system-status-and-performance.html#the-purpose-of-perf-c2c_detecting-false-sharing}perf c2c 的目的 {.title}
:::
`perf`{.literal} 工具的 `c2c`{.literal}
子命令启用共享数据缓存至缓存(C2C)分析。您可以使用 `perf c2c`{.literal}
命令检查缓存行争用来检测真实和错误的共享。
当单对称多进程(SMP)系统上的处理器核心修改其他处理器所使用的同一缓存行上的数据项时，就会发生缓存行争。所有其他使用此缓存行的处理器都必须将其副本失效并请求更新的副本。这会导致性能下降。
`perf c2c`{.literal} 命令提供以下信息：
::: itemizedlist
-   检测到竞争的缓存行
-   进程读取和写入数据
-   导致竞争的指令
-   争用中的非一致性内存访问(NUMA)节点
:::
:::
::: section
::: titlepage
# []{#detecting-false-sharing_monitoring-and-managing-system-status-and-performance.html#detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing}使用 perf c2c 检测缓存行竞争 {.title}
:::
使用 `perf c2c`{.literal} 命令检测系统中缓存行争用。
`perf c2c`{.literal} 命令支持与 `perf 记录`{.literal}
相同的选项，以及专用于 `c2c`{.literal}
子命令的一些选项。记录的数据存储在当前目录中的 `perf.data`{.literal}
文件中，以便稍后进行分析。
::: itemizedlist
**先决条件**
-   安装 `perf`{.literal} 用户空间工具。如需更多信息，请参阅 [安装
    perf](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf){.link}。
:::
::: itemizedlist
**流程**
-   使用 `perf c2c`{.literal} 检测缓存行争用：
    ``` screen
    # perf c2c record -a sleep seconds
    ```
    这个示例 `按照`{.literal} `sleep`{.literal} 命令规定的时间跨所有 CPU
    的缓存竞争数据进行抽样和记录。您可以使用您要通过收集缓存线争用数据的任何命令替换
    `sleep`{.literal} 命令。
:::
::: itemizedlist
**其它资源**
-   `perf-c2c(1)`{.literal} man page
:::
:::
::: section
::: titlepage
# []{#detecting-false-sharing_monitoring-and-managing-system-status-and-performance.html#visualizing-a-perf-data-file-recorded-with-perf-c2c-record_detecting-false-sharing}视觉化使用 perf c2c 记录记录的 perf.data 文件 {.title}
:::
这个步骤描述了如何视觉化 `perf.data`{.literal} 文件，该文件使用
`perf c2c`{.literal} 命令进行记录。
::: itemizedlist
**先决条件**
-   安装 `perf`{.literal} 用户空间工具。如需更多信息，请参阅 [安装
    perf](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf){.link}。
-   当前目录中提供了使用 ` perf c2c`{.literal} 命令记录的
    perf.data``{=html} 文件。如需更多信息，请参阅使用 [perf c2c
    检测缓存行争用](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/monitoring_and_managing_system_status_and_performance/detecting-false-sharing_monitoring-and-managing-system-status-and-performance#detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing){.link}。
:::
::: orderedlist
**流程**
1.  打开 `perf.data`{.literal} 文件进行进一步分析：
    ``` screen
    # perf c2c report --stdio
    ```
    这个命令将 `perf.data`{.literal} 文件视觉化为终端中的几个图形：
    ``` literallayout
    =================================================
               Trace Event Information
    =================================================
     Total records                     :     329219
     Locked Load/Store Operations      :      14654
     Load Operations                   :      69679
     Loads - uncacheable               :          0
     Loads - IO                        :          0
     Loads - Miss                      :       3972
     Loads - no mapping                :          0
     Load Fill Buffer Hit              :      11958
     Load L1D hit                      :      17235
     Load L2D hit                      :         21
     Load LLC hit                      :      14219
     Load Local HITM                   :       3402
     Load Remote HITM                  :      12757
     Load Remote HIT                   :       5295
     Load Local DRAM                   :        976
     Load Remote DRAM                  :       3246
     Load MESI State Exclusive         :       4222
     Load MESI State Shared            :          0
     Load LLC Misses                   :      22274
     LLC Misses to Local DRAM          :        4.4%
     LLC Misses to Remote DRAM         :       14.6%
     LLC Misses to Remote cache (HIT)  :       23.8%
     LLC Misses to Remote cache (HITM) :       57.3%
     Store Operations                  :     259539
     Store - uncacheable               :          0
     Store - no mapping                :         11
     Store L1D Hit                     :     256696
     Store L1D Miss                    :       2832
     No Page Map Rejects               :       2376
     Unable to parse data source       :          1
    =================================================
       Global Shared Cache Line Event Information
    =================================================
     Total Shared Cache Lines          :         55
     Load HITs on shared lines         :      55454
     Fill Buffer Hits on shared lines  :      10635
     L1D hits on shared lines          :      16415
     L2D hits on shared lines          :          0
     LLC hits on shared lines          :       8501
     Locked Access on shared lines     :      14351
     Store HITs on shared lines        :     109953
     Store L1D hits on shared lines    :     109449
     Total Merged records              :     126112
    =================================================
                     c2c details
    =================================================
     Events                            : cpu/mem-loads,ldlat=30/P
    	                                    : cpu/mem-stores/P
     Cachelines sort on                : Remote HITMs
     Cacheline data groupping          : offset,pid,iaddr
    =================================================
    	   Shared Data Cache Line Table
    =================================================
    #
    #                              Total      Rmt  ----- LLC Load Hitm -----  ---- Store Reference ----  --- Load Dram ----      LLC    Total  ----- Core Load Hit -----  -- LLC Load Hit --
    # Index           Cacheline  records     Hitm    Total      Lcl      Rmt    Total    L1Hit   L1Miss       Lcl       Rmt  Ld Miss    Loads       FB       L1       L2       Llc       Rmt
    # .....  ..................  .......  .......  .......  .......  .......  .......  .......  .......  ........  ........  .......  .......  .......  .......  .......  ........  ........
    #
          0            0x602180   149904   77.09%    12103     2269     9834   109504   109036      468       727      2657    13747    40400     5355    16154        0      2875       529
          1            0x602100    12128   22.20%     3951     1119     2832        0        0        0        65       200     3749    12128     5096      108        0      2056       652
          2  0xffff883ffb6a7e80      260    0.09%       15        3       12      161      161        0         1         1       15       99       25       50        0         6         1
          3  0xffffffff81aec000      157    0.07%        9        0        9        1        0        1         0         7       20      156       50       59        0        27         4
          4  0xffffffff81e3f540      179    0.06%        9        1        8      117       97       20         0        10       25       62       11        1        0        24         7
    =================================================
          Shared Cache Line Distribution Pareto
    =================================================
    #
    #        ----- HITM -----  -- Store Refs --        Data address                               ---------- cycles ----------       cpu                                     Shared
    #   Num      Rmt      Lcl   L1 Hit  L1 Miss              Offset      Pid        Code address  rmt hitm  lcl hitm      load       cnt               Symbol                Object                  Source:Line  Node{cpu list}
    # .....  .......  .......  .......  .......  ..................  .......  ..................  ........  ........  ........  ........  ...................  ....................  ...........................  ....
    #
      -------------------------------------------------------------
          0     9834     2269   109036      468            0x602180
      -------------------------------------------------------------
              65.51%   55.88%   75.20%    0.00%                 0x0    14604            0x400b4f     27161     26039     26017         9  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:144   0{0-1,4}  1{24-25,120}  2{48,54}  3{169}
    	   0.41%    0.35%    0.00%    0.00%                 0x0    14604            0x400b56     18088     12601     26671         9  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:145   0{0-1,4}  1{24-25,120}  2{48,54}  3{169}
    	   0.00%    0.00%   24.80%  100.00%                 0x0    14604            0x400b61         0         0         0         9  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:145   0{0-1,4}  1{24-25,120}  2{48,54}  3{169}
    	   7.50%    9.92%    0.00%    0.00%                0x20    14604            0x400ba7      2470      1729      1897         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:154   1{122}  2{144}
    	  17.61%   20.89%    0.00%    0.00%                0x28    14604            0x400bc1      2294      1575      1649         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:158   2{53}  3{170}
    	   8.97%   12.96%    0.00%    0.00%                0x30    14604            0x400bdb      2325      1897      1828         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:162   0{96}  3{171}
      -------------------------------------------------------------
          1     2832     1119        0        0            0x602100
      -------------------------------------------------------------
    	  29.13%   36.19%    0.00%    0.00%                0x20    14604            0x400bb3      1964      1230      1788         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:155   1{122}  2{144}
    	  43.68%   34.41%    0.00%    0.00%                0x28    14604            0x400bcd      2274      1566      1793         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:159   2{53}  3{170}
    	  27.19%   29.40%    0.00%    0.00%                0x30    14604            0x400be7      2045      1247      2011         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:163   0{96}  3{171}
    ```
:::
:::
::: section
::: titlepage
# []{#detecting-false-sharing_monitoring-and-managing-system-status-and-performance.html#interpretation-of-perf-c2c-report-output_detecting-false-sharing}perf c2c 报告输出的解读 {.title}
:::
本节论述了如何解释 `perf c2c report`{.literal} 命令的输出。
运行 `perf c2c report --stdio`{.literal}
命令将数据排序为多个表来显示的视觉化：
::: variablelist
[`跟踪事件信息`{.literal}]{.term}
:   此表提供了所有负载和存储样本的高级摘要，由
    `perf c2c record`{.literal} 命令收集。
[`全球共享缓存行事件信息`{.literal}]{.term}
:   此表提供有关共享缓存行的统计信息。
[`c2c 详情`{.literal}]{.term}
:   此表提供有关哪些事件被抽样的信息，以及 `perf c2c 报告数据`{.literal}
    如何在视觉化中组织的信息。
[`共享数据缓存行表`{.literal}]{.term}
:   此表为热门缓存行提供一个行摘要，其中检测到假共享，按照默认情况下每个缓存行检测到的远程
    [**Hitm**]{.strong} 数量来排列。
[`共享缓存行分发 Pareto`{.literal}]{.term}
:   这个表提供有关每个缓存行遇到争用的各种信息：
    ::: itemizedlist
    -   缓存行在 [**NUM**]{.strong} 列中编号，从 `0`{.literal} 开始。
    -   每个缓存行的虚拟地址都包含在 [**Data address Offset**]{.strong}
        列中，随后会在发生不同访问的缓存行中偏移。
    -   [**Pid**]{.strong} 列中包含进程 ID。
    -   [**Code Address**]{.strong} 列中包含指令指针代码地址。
    -   [**周期**]{.strong} 标签下的列显示平均负载延迟。
    -   [**cpu cnt**]{.strong} 列显示来自多少个不同的 CPU
        样本（基本而言，在该给定位置上等待索引的数据的不同 CPU 数量）。
    -   Symbol [**列**]{.strong} 显示函数名或符号。
    -   [**Shared Object**]{.strong} 列显示样本来自的 ELF
        镜像的名称（样本来自内核时使用
        \[`kernel.kallsyms`{.literal}\]）。
    -   [**Source:Line**]{.strong} 列显示源文件和行号。
    -   [**Node{cpu list}**]{.strong} 列中显示每个节点来自哪些特定 CPU
        样本。
    :::
:::
:::
::: section
::: titlepage
# []{#detecting-false-sharing_monitoring-and-managing-system-status-and-performance.html#detecting-false-sharing-with-perf-c2c_detecting-false-sharing}使用 perf c2c 检测错误共享 {.title}
:::
这个步骤描述了如何使用 `perf c2c`{.literal} 命令检测假共享。
::: itemizedlist
**先决条件**
-   安装 `perf`{.literal} 用户空间工具。如需更多信息，请参阅 [安装
    perf](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf){.link}。
-   当前目录中提供了使用 ` perf c2c`{.literal} 命令记录的
    perf.data``{=html} 文件。如需更多信息，请参阅使用 [perf c2c
    检测缓存行争用](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/monitoring_and_managing_system_status_and_performance/detecting-false-sharing_monitoring-and-managing-system-status-and-performance#detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing){.link}。
:::
::: orderedlist
**流程**
1.  打开 `perf.data`{.literal} 文件进行进一步分析：
    ``` screen
    # perf c2c report --stdio
    ```
    这会在终端中打开 `perf.data`{.literal} 文件。
2.  在\"Trace Event Information\"表中，找到包含 [**LLC Misses to Remote
    Cache(HITM)**]{.strong} 值的行：
    [**LLC Misses to Remote Cache(HITM)**]{.strong}
    行的值列中的百分比代表了修改的缓存行中 NUMA 节点之间发生 LLC
    丢失的百分比。
    ``` literallayout
    =================================================
                Trace Event Information
    =================================================
      Total records                     :     329219
      Locked Load/Store Operations      :      14654
      Load Operations                   :      69679
      Loads - uncacheable               :          0
      Loads - IO                        :          0
      Loads - Miss                      :       3972
      Loads - no mapping                :          0
      Load Fill Buffer Hit              :      11958