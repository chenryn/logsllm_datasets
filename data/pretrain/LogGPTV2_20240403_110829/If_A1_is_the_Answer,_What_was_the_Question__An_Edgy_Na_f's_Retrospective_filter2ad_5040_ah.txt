Hammonds,  Pete  Tasker,  Dan  Edwards,  Mario  Tinto, 
Roger  Schell,  Jim  Anderson,  Ted  Lee,  Steve  Lipner, 
Clark  Weissman,  Steve  Walker,  Larry  Noble,  Jim 
Studer, Gene Epperly, Jeff Makey, Warren Shadle, and 
me.  David  Bell  provided  strong  contributions  after  he 
joined  the  Center’s  research  organization.  We  later 
came to realize that no practitioners of contractual law 
were involved in the writing group’s activities or in the 
formal review process. 
impossible 
Of necessity, our schedule slipped dramatically and 
continually.  Comments  often  turned  into  lobbying. 
Developers wanted to ensure that their products would 
get the best possible earned rating and helped greatly to 
eliminate 
ambiguously-worded 
requirements.  A  series  of  drafts  was  published.  These 
presented  numbered  lines  and  employed  bold  faced
insertions  and  strikeout  deletions  to  help  reviewers 
make  it  through  the  growing  document’s  evolution. 
Drafts  were  published  on  15  November  1982  (white 
cover),  15  January  1983,  and  a  final  Draft  (in  an  ugly 
Olive Drab cover) on 27 January 1983. 
or 
Brand  maintained  a  growing  file  of  comments  and 
how  each  was  accommodated.  Rejected  comments 
were  noted  as  such  and,  depending  on  our  perception 
of the source’s credentials, justification for the decision 
was written into the file and sent to the reviewer. Based 
on  the  number  of  received  comments,  Brand  insisted 
that  references  to  dominance  in  the  security  lattice  be 
replaced with explicit wording on the rules for reading 
and  modifying  objects.    This  proved  to  be  a  decision 
that  aided  readers  unschooled  in  lattice  theory  and 
which  removed  ambiguities 
the  authors  did  not 
perceive at the time. 
The  definition  of  Class  (A2)  persisted  into  January 
1983. However, it was finally removed because it made 
no  sense  to  include  a  class  whose  requirements  were 
defined to be beyond the state of the art and that would 
have to be redefined at some point if code-level formal 
verification  technology  ever  advanced  to  a  practical 
state. It was replaced by a page entitled “Beyond Class 
16  Some  of  us  opposed  this  practice  on  the  grounds  that 
inclusion  of  some  features  without  supportive  assurances  would 
provide a vendor with meaningless hype for advertising a false sense 
of security. The majority prevailed on this issue. 
(A1)”  that  only  gave  a  characterization  of  what  might 
be required for higher assurance. 
The  Final  Draft  begat  a  broader  stream  of 
comments.  Sheila  Brand  made a management decision 
on  resolving  the  last  of  the  remaining  open  issues  and 
advised  Mel  Klein  that  the  time  had  come  to  publish 
CSC-STD-001-83, The Department of Defense Trusted 
Computer  System  Evaluation  Criteria.  This  appeared, 
in  a  bright  orange  cover,  with  a  Forward  by  Klein,  on 
15  August  1983.  The  new  “Orange  Book”  weighed  in 
at 117 pages.  
in 
their  contract  with 
Several  trusted  products  were  being  evaluated 
against drafts of the Criteria during this period. At first, 
vendors  insisted  that  the  draft  version  be  identified 
explicitly 
the  Center  and 
identified in the Final Evaluation Report. However, the 
vendors  later  realized  that  evaluation  against  any  but 
the  final  published  standard  would  be  a  mistake 
because  to  do  so  would  be  to  give  the  appearance  of 
failing to meet one or more of the “real” requirements. 
So  in  reality,  products  were  being  evaluated  against  a 
moving  target  during  the  period  from  early  1982 
through 15 August 1983.
3.2. Lack of deeper understanding 
We  thought  we  understood  what  we  were  writing.  We 
also thought the community would understand what we 
had  written  –  or  at  least  what  we  intended  to  have 
written. That turned out not to be the case. Indeed, for 
all our belief that we were writing with precision, only 
experience could show that we weren’t. 
We  were  fully  dedicated  to  not  introducing  faddish 
requirements and tried to justify each on the basis of an 
identifiable  need  and  technical  justification.  We  paid 
considerable  attention  to  the  entry-level  criteria  for 
each  division,  intending  to  ensure  that  it  would  be 
achievable  from  a  well-designed  product  at  the  top  of 
the  predecessor  division.  We  also  tried  to  limit  the 
nature of the hardest technical challenge in progressing 
to  evaluation  classes  by constraining our desire to add 
additional requirements because of strong advocacy for 
them. This attempt at following a discipline sometimes 
led  to  an  appearance  of  random  placement  of  some 
requirements. 
An  example  of  this  is  the  placement  of  the  first 
change  in  the  DAC  requirement  after  Class  (C2)  (the 
angle  brackets  morphed  into  parentheses  after  the 
Powder  Blue  Draft).  This  requirement is introduced at 
Class  (B3)(!)  and  specifies  (a)  that  there  be  access 
control  lists,  (b)  that  there  be  support  for  both 
individual  and  group  access  controls,  and  finally  (c) 
that  “it  shall  be  possible  to  specify  a  list  of  named 
individuals  and  a  list  of  groups  of  named  individuals 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
for which no access to the object is to be given.” Why 
at  B3?  Well,  Dan  Edwards  produced  the  following 
argument.  By  definition  the  requirement  could  not  be 
introduced  at  B1,  because  the  rule  for  an  entry-level 
product  would  be  just  the  addition  of  labeling  of  a 
defined subset of named subjects and objects. It didn’t 
make sense to add the requirement at B2 because of the 
difficulty  inherent  in  meeting  the  requirement  to 
control access between all subjects and all objects and 
to address the more important covert channel issue and 
strong  penetration-resistance  requirements.  Given  that 
Class (A1) added the difficult formal specification and 
formal  covert  channel  analysis  requirements  which 
were to be the only change from B3, we had the choice 
of adding the requirement at C2 or B3 or not to add it 
at  all.  We  decided  that  audit  was  a  hard  enough 
addition  to  the  C1  requirement,  and  that  narrowed  the 
choice to B3 or not at all. 
3.2.1. DAC algebra. We found out later that we made 
the wrong choice for Negative Access Control Lists (or 
NACLs)  as  the  requirement  came  to  be  called.  We 
either  should  not  have  added  them  or  we  should  have 
proposed  a  model  showing  the  relationship  between 
ACLs  and  NACLs  and  submitted  it  to  the  community 
for comment. In fact, we did not realize at the time that 
there was an issue present for us to disagree on.  
between 
listings 
contradictions 
The  problems  we  did  not  identify  focused  on 
apparent 
and 
determining  which  takes  precedence.  E.g.,  if  a  name 
appears both on a NACL and on an ACL, which takes 
priority? What if the name is in a group that appears on 
a NACL but the user’s name is explicit on an ACL for 
the  object?  What  if  the  user  created  the  object,  gave 
herself full rights to the object, and creates its NACL as 
well,  but  a  system  administrator  (not  knowing  of  the 
NACL’s  existence  or  its  organization)  then  places  this 
user in a group that is on that particular NACL? 
This problem came up a couple of times some years 
after  publication  of  the  final  DoD  Standard  5200.28-
STD  version  of  the  TCSEC  had  been  adapted.  To  my 
knowledge, 
issues  were  never  satisfactorily 
resolved. 
the 
3.2.2.  Questions  of  “high-assurance”  DAC.  By 
definition,  discretionary  access  control  conveys  rights 
between  unlabeled  (same  access  class)  subjects  and 
objects.  Consider  a  simple  Trojan  horse  attack.  If  a 
subject S can read A and modify B, then S can copy the 
contents  of  A  into  B  (if  this  is  consistent  with  the 
semantics  of  B,  else  S  can  encode  A’s  contents  such 
that they are compatible with B’s semantics). But what 
if there exists a subject S´ who is explicitly listed on a 
NACL  for  A  or  on  an  ACL  for  B? Has S violated the 
access  control  policy?  Or  is  the  system  required  to 
modify  the  access  controls  on  B  such  that  a  NACL  is 
created on B that includes S´? If S has control access to 
B, can S remove that NACL? 
Now,  under  the  MAC  rules  of  the  *-property, 
copying the contents of A into B is prohibited unless A 
and  B  are  at  compatible  security  levels.  But  is  the 
above  transaction  a  violation  of  DAC  that  must  be 
closed at the B3 level? Is it an “obvious” flaw that must 
be  closed?  Well…  no!  Because  it  is  an  intrinsic 
property  of  information  flow  within  an  access  class, 
and it cannot be eliminated. 
But this leads to a hard question that is sidestepped 
in  the  TCSEC.  When  the  derivable  principles  of 
information theory and a security policy are in conflict, 
which must take precedence? Similarly, when derivable 
consequences of two aspects of a security policy are in 
conflict, which much take precedence? To my shock, I 
learned  that  some  evaluators  interpreted  only  to  the 
explicit  wording  of  the  TCSEC,  however  impossible 
they  might  be  in  context,  to  take  precedence  over  the 
mathematical properties of information science. 
implementation  flaws).  But 
The  silence  of  the  TCSEC  on  such  points  has  led 
new  practitioners  into  making  assumptions  that  an  A1 
system  is  “more  secure”  for  single-level  applications 
than a C2 system. This is true (because of the ability of 
a  B2  or  higher  security  architecture  to  fend  off  large 
classes  of  penetration  attacks  that  exploit  architectural 
or 
the  full  suite  of 
structural  and  formal  A1  assurances  has  no  effect  on 
information confinement within that single access class. 
Indeed,  without 
integrity  and  recovery 
requirements,  a  single-level DAC-only implementation 
of an A1 architecture could fall victim to many attacks 
that  are  common  in  contemporary  virus-  or  worm-
bearing e-mails. 
the  TCB 
to  meet 
3.2.3.  Failed  “worked”  examples.  The  “worked 
examples”  identified  in  the  Powder  Blue  Draft  got 
forgotten  along  the  way.  Indeed,  RACF,  the  prototype 
for  C2  audit,  failed 
its  own  defining 
requirement because IBM understood that its customers 
wanted  to  have the ability to turn off audit to improve 
performance 
in  some  system  environments.  The 
consequence  was  that  RACF  became  the  only  product 
ever to be “awarded” a C1 rating. Bob Brotzman, then 
Director  of  the  NCSC,  and  I  were  more  embarrassed 
over the situation than IBM’s Tom Russell, to whom I 
presented the C1 Certificate. 
A trusted UNIX candidate for B1 or B2 would have 
been  automatically  disqualified  because  its  {Self, 
Group,  World}  form  of  access  control  would  fail  to 
meet  even  the  C2  requirement  on  groups  or  named 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
individuals  unless  it  limited  its  number  of  possible 
users to a very small number. 
Though  satisfying  all  the  security  architecture  and 
formal  verification  requirements  for  A1,  worked 
examples  KVM/370  and  another  A1  candidate  trusted 
VMM  would  also  have  failed.  They  were  deficient  in 
the  C2  individual  accountability  requirement  and  C1 
individual  discretionary  access  control  requirement 
because  the  security  kernel  within  the  virtual  machine 
monitor  could  not  see  how  accesses  were  controlled 
within  multiuser  virtual  machines.  Their  evaluation 
team  wanted  to  insist  that  every  virtual  machine  have 
no  more  than  a  single  human  user.  These  products 
would therefore have received a D rating, despite their 
architectures and assurances. 
3.2.4.  Imprecise  language.  Other  forms  of  imprecise 
wordings  plagued  evaluators  and  developers  alike. 
Long  position  papers  were  written  to  address  the 
meaning  of  requirements  such  as  the  C2  System 
Architecture  requirement:  “…Resources  controlled  by 
the  TCB  may  be  a  defined  subset  of  the  subjects  and 
objects in the ADP system. The TCB shall isolate the 
resources to be protected so that they are subject to 
the  access  control  and  auditing  requirements.”
Seemingly,  questions  were 
that  put 
evaluations on hold for indefinite periods. For example, 
“what are the rules for access by a subject not defined 
to be under control of the TCB to an object defined to 
be  under  control  of  the  TCB?”  “Should  the  TCB  be 
required to audit all accesses by subjects not under the 
TCB’s control?” Decisions were postponed for months 
at  a  time,  at  tremendous  cost  to  trusted  product 
developers  and  evaluators,  until 
there  was  near 
unanimous agreement over interpretive topics as absurd 
as these. 
invented 
Similar  problems  showed  up  in  the  evaluations  of 
Multics  (AIM)  for  B2  and  the  SCOMP  for  A1.  True, 
technical  problems  were  detected  and  corrected  in 
these  product  evaluations,  but  tremendous  time  was 
lost in attempts to resolve imprecisely stated evaluation 
requirements.
Copies  of  CSC-STD-001  were  distributed  for  official 
comment,  and  official  comments  came  in  a  near  tidal 
wave.  
stifle 
the 
research 
officially 
Some  agencies  objected  that  promulgation  of  the 
and 
TCSEC  would 
experimentation.  Others  were  concerned  over  wording 
that  could  have  an  adverse  effect  on  their  embedded 
system  applications.  Portions  of 
intelligence 
community objected that the TCSEC’s policies did not 
directly  support  their  multilevel  classification  and 
caveat  system  of  compartments,  categories,  warning 
notices,  and  other  dissemination  and  selective-
declassification  controls.  Because  B1  was  established 
as  the  entry  level  into  Division B, one agency insisted 
on the inclusion of a new class, C3, that would support 
their policy needs. 
Many  of  us  spent  a  summer  and  fall  in  sometimes 
heated meetings with executives in the Pentagon and at 
various  agencies.  Sheila  Brand,  Mario  Tinto,  Grant 
Wagner,  and  I  repeatedly  found  ourselves  having  to 
explain  and  defend  such  TCSEC  requirements  as 