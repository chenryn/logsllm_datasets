5
d
3(cid:96)
-
log(d/(cid:96))
√
3(cid:96) + 5
d + log(d/(cid:96))
Mult
-
-
(cid:96)
(cid:96)
4.3 Parallel Matrix Computation
Throughout Sections 3 and 4, we have identiﬁed the message space M = Rn with the set of matrices Rd×d
under the assumption that n = d2. However, most of HE schemes [9, 18, 13] have a quite large number
of plaintext slots (e.g. thousands) compared to the matrix dimension in some real-world applications,
i.e., n (cid:29) d2. If a ciphertext can encrypt only one matrix, most of plaintext slots would be wasted. This
subsection introduces an idea that allows multiple matrices to be encrypted in a single ciphertext, thereby
performing parallel matrix computation in a SIMD manner.
For simplicity, we assume that n is divisible by d2 and let g = n/d2. We modify the encoding map
in Section 3.2 to make a 1-to-1 correspondence ιg between Rn and (Rd×d)g, which transforms an n-
dimensional vector into a g-tuple of square matrices of order d. Speciﬁcally, for an input vector a =
(a(cid:96))0≤(cid:96)<n, we deﬁne ιg by
ιg : a (cid:55)→(cid:0)Ak = (ag·(d·i+j)+k)(cid:1)
0≤k<g .
The components of a with indexes congruent to k modulo g are corresponding to the k-th matrix Ak.
We note that for an integer 0 ≤ (cid:96) < d2, the rotation operation ρ(a; g · (cid:96)) represents the matrix-wise
rotation by (cid:96) positions. It can be naturally extended to the other matrix-wise operations including scalar
linear transformation and matrix multiplication. For example, we can encrypt g number of d× d matrices
into a single ciphertext and perform the matrix multiplication operations between g pairs of matrices at
once by applying our matrix multiplication algorithm on two ciphertexts. The total complexity remains
the same as Algorithm 2, which results in a less amortized computational complexity of O(d/g) per
matrix.
5 Implementation of Homomorphic Matrix Operations
In this section, we report the performance of our homomorphic matrix operations and analyze the per-
formance of the implementation. For simplicity, we assume that d is a power-of-two integer. In general,
we can pad zeros at the end of each row to set d as a power of two.
In our implementation, we employ a special encryption scheme suggested by Cheon et al. [13] (CKKS),
which supports approximate computation over encrypted data. A unique property of the HE scheme
is the rescaling procedure to truncate a ciphertext into a smaller modulus, which leads to rounding
of the plaintext. This plays an important role in controlling the magnitude of messages, and thereby
achieving eﬃciency of approximate computation. Recently, a signiﬁcant performance improvement was
made in [12] based on the Residue Number System (RNS) and Kim et al. [30] proposed a diﬀerent special
modulus technique to optimize the key-switching operation. We give a proof-of-concept implementation
using Microsoft SEAL version 3.3.2 [43] which includes this RNS variant of the CKKS scheme. All the
experiments were performed on a Macbook Pro laptop with an Intel Core i9 running with 4 cores rated
at 2.3GHz.
12
5.1 Parameter Setting
complex vectors. We use an RNS by taking a ciphertext modulus q = (cid:81)L
distinct primes. Based on the ring isomorphism Rq →(cid:81)L
We present how to select parameters of our underlying HE scheme to support homomorphic matrix
operations described in Sections 3 and 4. Our underlying HE scheme is based on the RLWE assumption
over the cyclotomic ring R = Z[X]/(X N + 1) for a power-of-two integer N . Let us denote by [·]q the
reduction modulo q into the interval (−q/2, q/2] ∩ Z of the integer. We write Rq = R/qR for the residue
ring of R modulo an integer q. The native plaintext space is represented as a set of (N/2)-dimensional
i=0 qi which is a product of
i=0 Rqi, a (cid:55)→ (a (mod qi))0≤i≤L, a polynomial
with a large modulus q can be represented as a tuple of polynomials with smaller coeﬃcients modulo qi.
If needed, we raise a ciphertext modulus from q to psq for a prime number ps, called the special modulus,
and perform the key-switching procedure over Rpsq followed by modulus reduction back to q. We note
that the RNS primes should be 1 modulo 2N to utilize an eﬃcient Number Theoretic Transformation
(NTT) algorithm.
Suppose that all the elements are scaled by a factor of an integer p and then converted into the nearest
integers for quantization. If we are multiplying a ciphertext by a plaintext vector, we assume that the con-
stant vector is scaled by a factor of an integer pc to maintain the precision. Thus, the rescaling procedure
after homomorphic multiplication reduces a ciphertext modulus by p while the rescaling procedure after
a constant multiplication reduces a modulus by pc. For example, Algorithm 2 has depth of two constant
multiplications for Step 1 and 2, and has additional depth of a single homomorphic multiplication for
Step 3. This implies that an input ciphertext modulus is reduced by (2 log pc + log p) bits after the matrix
multiplication algorithm. As a result, we obtain the following lower bound on the bit length of a fresh
ciphertext modulus, denoted by log q:
log q0
log q =
log q0 + 2 log pc + log p
log q0 + log pc
for HE-MatAdd;
for HE-MatMult;
for HE-MatTrans,
where q0 is the output ciphertext modulus. The ﬁnal ciphertext represents the desired vector but is scaled
by a factor of p, which means that log q0 should be larger than log p for correctness of decryption. In
other words, the chain of moduli for HE-MatMult can be deﬁned via a set of primes {q0, q1, q2, q3, ps} such
that log q1 ≈ log p and log q2 ≈ log q3 ≈ log pc. In our implementation, we take log p = log pc = 30 and
log q0 = log ps = 40.
We use the discrete Gaussian distribution of standard deviation σ = 3.2 to sample error polynomials.
The secret-key polynomials were sampled from the discrete ternary uniform distribution over {0,±1}N .
The cyclotomic ring dimension is chosen as N = 213 to achieve at least 80-bit security level against the
known attacks of the LWE problem based on the estimator of Albrecht et al. [2]. In short, we present
three parameter sets and sizes of the corresponding fresh ciphertexts as follows:
(213, 40, 80 KB)
(213, 130, 260 KB)
(213, 70, 140 KB)
for HE-MatAdd;
for HE-MatMult;
for HE-MatTrans.
(N, log q, size) =
5.2 Performance of Matrix Operations
Table 4 presents timing results for matrix addition, multiplication, and transposition for various ma-
trix sizes from 4 to 64 where the throughput means the number of matrices being processed in parallel.
We provide three distinct implementation variants: single-packed, sparsely-packed, and fully-packed. The
single-packed implementation is that a ciphertext represents only a single matrix; two other implemen-
tations are to encode several matrices into sparsely or fully packed plaintext slots. We use the same
parameters for all variants, and thus each ciphertext can hold up to N/2 = 212 plaintext values. For
example, if we consider 4 × 4 matrices, we can process operations over 212/(4 · 4) = 256 distinct matrices
simultaneously. In the case of dimension 16, a ciphertext can represent up to 212/(16 · 16) = 16 distinct
matrices.
13
Dim Throughput
1
16
256
1
4
16
1
4
16
64
Table 4: Benchmarks of homomorphic matrix operations
Message Expansion Encoding+ Decoding+
Relative time per matrix
size
0.06 KB
0.94 KB
15 KB
0.94 KB
3.75 KB
15 KB
15 KB
rate
4437
277
17.3
277
69.3
17.3
17.3
Encryption Decryption HE-MatAdd HE-MatMult HE-MatTrans
9.68 ms
9.87 ms
4.45 ms
9.72 ms
9.12 ms
10.23 ms
0.49 ms
0.87 ms
4.45 ms
0.57 ms
0.58 ms
0.93 ms
9.09 ms
0.54 ms
47.33 ms
2.96 ms
0.18 ms
35 µs
2.19 µs
0.14 µs
36 µs
9.25 µs
2.19 µs
152 ms
34.67 ms
9.04 ms
34 µs 600.59 ms
17.08 ms
1.12 ms
0.06 ms
33.79 ms
8.04 ms
2.01 ms
90.88 ms
Ciphertext sizes. As mentioned above, a ciphertext could hold 212 diﬀerent plaintext slots, and thus
we can encrypt one 64 × 64 matrix into a fully-packed ciphertext. We assumed that all the inputs had
log p = 30 bits of precision, which means that an input matrix size is bounded by 64 × 64 × 30 bits or 15
KB. Since a single ciphertext is at most 260 KB for an evaluation of matrix multiplication, the encrypted
version is 260/15 ≈ 17 times larger than the un-encrypted version. In Table 4, the third column gives the
size of input matrices and the fourth column gives an expansion ratio of the generated ciphertext to the
input matrices.
Timing results. We conducted experiments over ten times and measured the average running times for all
the operations. For the parameter setting in Section 5.1, the key generation takes about 60 milliseconds. In
Table 4, the ﬁfth column gives timing for encoding input matrices and encrypting the resulting plaintext
slots. Since matrix multiplication requires the largest fresh ciphertext modulus and takes more time
than others, we just report the encryption timing results for the case. In the sixth column, we give
timing for decrypting the output ciphertext and decoding to its matrix form. Note that encryption and
decryption timings are similar each other; but encoding and decoding timings depend on the throughput.
The last three columns give amortized time per matrix for homomorphic matrix computation. The entire
execution time, called latency, is similar between the three variant implementations, so the parallel matrix
computation provides roughly a speedup as a factor of the throughput.
Performance of rectangular matrix multiplication. We present the performance of Algorithm 3 described
in Section 4.2. As a concrete example, we consider the rectangular matrix multiplication R16×64 ×
R64×64 → R16×64. As we described above, our optimized method has a better performance than a simple
method exploiting Algorithm 2 for the multiplication between 64 × 64 matrices.
To be precise, the ﬁrst step of Algorithms 2 or 3 generates two ciphertexts ct.A(0) and ct.B(0) by
applying the linear transformations of U σ and U τ , thus both approaches have almost the same computa-
tional complexity. Next, in the second and third steps, two algorithms apply the same operations to the
resulting ciphertexts but with diﬀerent numbers: Algorithm 2 requires approximately four times more
operations compared to Algorithm 3. As a result, Step 2 turns out to be the most time consuming part
in Algorithm 2, whereas it is not the dominant procedure in Algorithm 3. Finally, Algorithm 3 requires
some additional operations for Step 4, but we need only log(64/16) = 2 automorphisms.
Table 5 shows more detailed experimental results of HE-MatMult and HE-RMatMult based on the same
parameter as in the above section. The total running times of two algorithms are 600 milliseconds and
283 milliseconds, respectively; therefore, Algorithm 3 achieves a speedup of 2× compared to Algorithm 2.
6 E2DM: Making Prediction based on Encrypted Data and Model
In this section, we propose a novel framework E2DM to test encrypted convolutional neural networks
model on encrypted data. We consider a new service paradigm where model providers oﬀer encrypted
14
Table 5: Performance comparison of homomorphic square and rectangular matrix multiplications
Algorithm
Step 1
Step 2
Step 3
Step 4
Total
HE-MatMult
HE-RMatMult
161.09 ms
Speedup
-
418.20 ms
114.15 ms
3.66×
20.99 ms
5.44 ms
3.86×
-
1.91 ms
-
600.28 ms
282.59 ms
2.12×
trained classiﬁer models to a public cloud and the cloud server provides on-line prediction service to data
owners who uploaded their encrypted data. In this inference, the cloud should learn nothing about private
data of the data owners, nor about the trained models of the model providers.
6.1 Neural Networks Architecture
The ﬁrst viable example of CNN on image classiﬁcation was AlexNet by Krizhevsky et al. [32] and it was
dramatically improved by Simonyan et al. [44]. It consists of a stack of linear and non-linear layers. The
linear layers can be convolution layers or FC layers. The non-linear layers can be max pooling (i.e., com-
pute the maximal value of some components of the feeding layer), mean pooling (i.e., compute the average
value of some components of the feeding layer), ReLu functions, or sigmoid functions.
Speciﬁcally, the convolution operator forms the fundamental basis of the convolutional layer. The
convolution has kernels, or windows, of size k × k, a stride of (s, s), and a mapcount of h. Given an image