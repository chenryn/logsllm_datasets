0 (T)+ai(T),
(11)
• The new request comes in and is added to the queue if the re-
i ∈[M],T =0,1,...,N −2.
quested object is not in the cache:
(i)
Z (T +1) = 1{σ(T)=i}·(1−x
(i)
0 (T +1)),
x
i ∈[M],T =0,1,...,N .
(12)
T =0,1,...,N −1−Z;
(i)
cch(T): object i along edge (Vcch,T ,Vcch,T +1),
f
T =Z ,1+Z ,...,N −2+Z;
(i)
evict(T): object i along edge (Vcch,T ,V
(T)
next,i),
T =Z ,1+Z ,...,N −1+Z .
(9)
f
x
(i)
(i)
0 (T)+1{Z
It can be proven that the state that evolves according to the dynamics
above satisfies that for any T =0,1,...,N −2,
τ (T)>0} ≤ 1.
(13)
This inequality states the fact that if object i is in the cache, then
there will not be requests for i in the queue, and if there are requests
of object i in the queue, then i is not in the cache.
At timestep T , object σ(T) is requested. If it is not in the cache nor
requested during the past Z timesteps, it will trigger a sequence of de-
layed hits when σ(T) is requested again during the next Z timesteps.
Therefore, the total latency can be written as:
τ =1x
N−2
T =0
(σ(T))
Z
x
(T +1)·Z−1
(cid:16)1−x
τ =1
(σ(T))
τ
(T +1)(cid:17)
·Z−1
t =0
1{σ(T +t)=σ(T)}·(Z−t).
(14)
Then the latency minimization problem is to find the cache sched-
ule subject to the constraints (7)–(9) such that the resulting states
minimize the total latency in (14).
A.2 Proof of Theorem 1
We first give some notation for the flow variables and state the
MCMCF problem with the notation. We define a flow variable for
each object on each edge, which takes values from {0,1} and repre-
sents the fraction of flow for the object routed along that edge. In
particular, we define the flow variables below:
(i)
mem(T): object i along edge (Vmem,T ,Vcch,T +Z),
f
(i)
mem(T) is always 0 if i (cid:44)σ(T) due to the infinite cost. Sim-
Note that f
(T)
ilarly, the flow variable for object j along edge (Vcch,T ,V
next,i) with
j (cid:44)i is also always 0. Here our formulation is a so-called ‘single-path
routing’ formulation, i.e., the flow variables are either 0 or 1 and they
together represent a path for each object. Additionally, for conve-
nience, for each vertex Vmem,T , we use P(j)(Vmem,T ) to denote the
set of vertices in the top row that have outgoing edges to Vmem,T as-
sociated with object j. Our goal is to minimize the following objective
function:
c
T =0
(σ(T))
mem (T),
(σ(T))(Vmem,T ,Vcch,T +Z)· f
(15)
where c(σ(T))(Vmem,T ,Vcch,T +Z) is the latency cost in (2). The min-
imization problem is subject to the following constraints for each
object i:
• Link capacity:
(σ(T))
mem (T)≤ 1,T =0,1,...,N −1,
f
N−1

(i)
cch(T)≤C,T =Z ,1+Z ,...,N −2+Z ,
f
i∈[M]
(i)
evict(T)≤ 1,T =Z ,1+Z ,...,N −1+Z .
f
(16)
(17)
(18)
Caching with Delayed Hits
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Here (17) models the constraint that we can have at most C ob-
jects in the cache. The constraints (16) and (18) are automatically
satisfied.
• Flow conservation:
(i)
mem(Ti) =1, where Vmem,Ti
f
total incoming flow to V

is the source of i,
(i)
sink is 1,
(i)
mem(T),i =σ(T),T >Ti ,
(19)
(20)
(21)
t : Vcch,t ∈P(i)(Vmem,T )
(i)
cch(T −1)+ f
f
f
(i)
evict(t) = f
(i)
mem(T −Z) = f
(i)
cch(T)+ f
(i)
evict(T),
T =Z ,1+Z ,...,N −1+Z .
(i)
cch(Z−1) = f
(22)
Here the constraints (19) and (20) at sources and sinks are straight-
forward. The constraint (21) is a flow conservation constraint at
vertexVmem,T . It implies that if object i was evicted from the cache
before T and has not been requested since, then its data will be
fetched from the backing store to the cache when it is requested at
T . The constraint (22) is a flow conservation constraint at vertex
(i)
cch(N −1+Z) =0 so (22) is valid at
Vcch,T . Let us set f
T = Z and T = N −1+Z. This constraint guarantees the obvious
requirement that an object is either in the cache or not in the cache.
Both the MCMCF problem and the latency minimization problems
are optimization problems. To show the equivalence of these two
problems, we first show in Lemma 1 below that the feasible set of
flow variables is ‘equivalent’ to the feasible set of caching schedules.
In particular, from any feasible cache schedule, we can define a set
of flow variables that are also feasible for the MCMCF problem; con-
versely,givenanyfeasiblesetofassignmentstoflowvariables,wecan
define a feasible cache schedule. Once we have this bijection, we can
show that the objective functions of these two problems are the same.
With equivalent feasible sets and objective functions, the MCMCF
problem and the latency minimization problem are thus equivalent.
Lemma. Given a sequence of object requests, there is a bijection
between the set of feasible flow variables and the set of feasible cache
schedules.
Proof of Lemma 1. We first prove that any feasible cache sched-
ule defines a set of feasible flow variables. Let ai(T),i ∈ [M],T =
0,1,...,N be a feasible cache schedule. We show that the flow vari-
ables defined below are feasible:
Z (T +1)·Z−1
(i)
(cid:16)1−x
τ (T +1)(cid:17)
(i)
τ =1
,
(23)
(i)
(i)
1 (T)·1{ai(T)=1},
0 (T)·1{ai(T)=0} +x
(i)
(i)
1 (T)·1{ai(T)=0}.
0 (T)·1{ai(T)=−1} +x
(24)
(25)
Let us first consider the capacity constraints (16)–(18). It is easy to
check that the constraints (16) and (18) are satisfied. Now we check
the constraint (17). By the definition of f
(i)
cch(T) in (24),
f
f
(i)
cch(T)
(i)
0 (T)·1{ai(T)=0} +x
x
i∈[M]
(i)
1 (T)·1{ai(T)=1}
(26)
When ai(T) = −1, the summand in (26) is 0; when ai(T) = 0, the
(i)
0 (T +1); otherwise, when ai(T) =1 and
summand equals x
(i)
(i)
0 (T +1) = 1.
1 (T) = 1, object i will be admitted to the cache so x
x
(i)
0 (T) =x
f
(i)
mem(T) =x
(i)
cch(T) =x
f
(i)
evict(T) =x

= 
i∈[M]
(cid:16)
(cid:17)
Combining these cases, we have that the summand in (26) is always
no larger than x
(i)
0 (T +1). Thus,
(i)
0 (T +1)≤C,
(27)

cch(T)≤ 
(i)
f
i∈[M]
x
i∈[M]
(cid:17)
(cid:16)1−x
and the constraint (17) is satisfied.
Next let us consider the flow conservation constraints (19)–(22).
It is easy to check that the constraints (19) and (20) are satisfied.
For the constraint (21), let i =σ(T). Let t∗ =max{t : t <T ,σ(t) =i}.
Then one can check that {t : Vcch,t ∈ P(i)(Vmem,T )} = {t∗ + 1,t∗ +
2,...,T}. So it suffices to show that
(i)
(i)
0 (t)·1{ai(t)=−1} +x
1 (t)·1{ai(t)=0}
T
(cid:16)
x
t =t∗+1
Z (T +1)·Z−1
(i)
τ (T +1)(cid:17)
(i)
.
=x
τ =1
(i)
t +1−u(u) = x
(28)
(i)
1 (t) = 1 for some t∗ < t ≤ T . Then
First, consider the case where x
we must have t ≤ t∗ +Z since there is no request for object i after t∗
and before T . This arrival at t will resolve all the requests for i in the
(i)
0 (u) = 0 for t∗ < u ≤ t
queue (if there exist any). We observe that x
(i)
(i)
1 (u) = 0 for t∗ < u < t
1 (t) = 1. Also x
by (13) and x
since otherwise it would have resolved the request and thus results
in no data arrival at t. If ai(t) =0, then the data is not admitted to the
cache. Also there is no request for object i on or after t (before T ). So
(i)
(i)
0 (u) =0 for t <u ≤T . Then when the request for i comes
1 (u) =x
x
in atT , it sees nothing in the cache nor the queue. So by the dynamics
(i)
Z (T +1) =1. Therefore, the right-hand-side (RHS)
in (12), we have x
of (28) is equal to 1, which is equal to the left-hand-side (LHS). For
the case that ai(t) = 1, the data is admitted to the cache at t. There