  chunk for _newly-inserted_ data. Existing chunks of data will not be  
  changed and may have more rows than this maximum value. The default  
  value is `10000`.  
View options for all tables with:  
```sql  
SELECT * FROM columnar.options;  
```  
You can also adjust options with a `SET` command of one of the  
following GUCs:  
* `columnar.compression`  
* `columnar.compression_level`  
* `columnar.stripe_row_limit`  
* `columnar.chunk_group_row_limit`  
GUCs only affect newly-created *tables*, not any newly-created  
*stripes* on an existing table.  
## Partitioning  
Columnar tables can be used as partitions; and a partitioned table may  
be made up of any combination of row and columnar partitions.  
```sql  
CREATE TABLE parent(ts timestamptz, i int, n numeric, s text)  
  PARTITION BY RANGE (ts);  
-- columnar partition  
CREATE TABLE p0 PARTITION OF parent  
  FOR VALUES FROM ('2020-01-01') TO ('2020-02-01')  
  USING COLUMNAR;  
-- columnar partition  
CREATE TABLE p1 PARTITION OF parent  
  FOR VALUES FROM ('2020-02-01') TO ('2020-03-01')  
  USING COLUMNAR;  
-- row partition  
CREATE TABLE p2 PARTITION OF parent  
  FOR VALUES FROM ('2020-03-01') TO ('2020-04-01');  
INSERT INTO parent VALUES ('2020-01-15', 10, 100, 'one thousand'); -- columnar  
INSERT INTO parent VALUES ('2020-02-15', 20, 200, 'two thousand'); -- columnar  
INSERT INTO parent VALUES ('2020-03-15', 30, 300, 'three thousand'); -- row  
```  
When performing operations on a partitioned table with a mix of row  
and columnar partitions, take note of the following behaviors for  
operations that are supported on row tables but not columnar  
(e.g. ``UPDATE``, ``DELETE``, tuple locks, etc.):  
* If the operation is targeted at a specific row partition  
  (e.g. ``UPDATE p2 SET i = i + 1``), it will succeed; if targeted at  
  a specified columnar partition (e.g. ``UPDATE p1 SET i = i + 1``),  
  it will fail.  
* If the operation is targeted at the partitioned table and has a  
  ``WHERE`` clause that excludes all columnar partitions  
  (e.g. ``UPDATE parent SET i = i + 1 WHERE ts = '2020-03-15'``), it  
  will succeed.  
* If the operation is targeted at the partitioned table, but does not  
  exclude all columnar partitions, it will fail; even if the actual  
  data to be updated only affects row tables (e.g. ``UPDATE parent SET  
  i = i + 1 WHERE n = 300``).  
Because columnar tables do not support indexes, it's impossible to  
create indexes on the partitioned table if some partitions are  
columnar. Instead, you must create indexes on the individual row  
partitions. Similarly for constraints that require indexes, e.g.:  
```sql  
CREATE INDEX p2_ts_idx ON p2 (ts);  
CREATE UNIQUE INDEX p2_i_unique ON p2 (i);  
ALTER TABLE p2 ADD UNIQUE (n);  
```  
## Converting Between Row and Columnar  
Note: ensure that you understand any advanced features that may be  
used with the table before converting it (e.g. row-level security,  
storage options, constraints, inheritance, etc.), and ensure that they  
are reproduced in the new table or partition appropriately. ``LIKE``,  
used below, is a shorthand that works only in simple cases.  
```sql  
CREATE TABLE my_table(i INT8 DEFAULT '7');  
INSERT INTO my_table VALUES(1);  
-- convert to columnar  
SELECT alter_table_set_access_method('my_table', 'columnar');  
-- back to row  
SELECT alter_table_set_access_method('my_table', 'heap');  
```  
# Performance Microbenchmark  
*Important*: This microbenchmark is not intended to represent any real  
 workload. Compression ratios, and therefore performance, will depend  
 heavily on the specific workload. This is only for the purpose of  
 illustrating a "columnar friendly" contrived workload that showcases  
 the benefits of columnar.  
## Schema  
```sql  
CREATE TABLE perf_row(  
    id INT8,  
    ts TIMESTAMPTZ,  
    customer_id INT8,  
    vendor_id INT8,  
    name TEXT,  
    description TEXT,  
    value NUMERIC,  
    quantity INT4  
);  
CREATE TABLE perf_columnar(LIKE perf_row) USING COLUMNAR;  
```  
## Data  
```sql  
CREATE OR REPLACE FUNCTION random_words(n INT4) RETURNS TEXT LANGUAGE plpython2u AS $$  
import random  
t = ''  
words = ['zero','one','two','three','four','five','six','seven','eight','nine','ten']  
for i in xrange(0,n):  
  if (i != 0):  
    t += ' '  
  r = random.randint(0,len(words)-1)  
  t += words[r]  
return t  
$$;  
```  
```sql  
INSERT INTO perf_row  
   SELECT  
    g, -- id  
    '2020-01-01'::timestamptz + ('1 minute'::interval * g), -- ts  
    (random() * 1000000)::INT4, -- customer_id  
    (random() * 100)::INT4, -- vendor_id  
    random_words(7), -- name  
    random_words(100), -- description  
    (random() * 100000)::INT4/100.0, -- value  
    (random() * 100)::INT4 -- quantity  
   FROM generate_series(1,75000000) g;  
INSERT INTO perf_columnar SELECT * FROM perf_row;  
```  
## Compression Ratio  
```  
=> SELECT pg_total_relation_size('perf_row')::numeric/pg_total_relation_size('perf_columnar') AS compression_ratio;  
 compression_ratio  
--------------------  
 5.3958044063457513  
(1 row)  
```  
The overall compression ratio of columnar table, versus the same data  
stored with row storage, is **5.4X**.  
```  
=> VACUUM VERBOSE perf_columnar;  
INFO:  statistics for "perf_columnar":  
storage id: 10000000000  
total file size: 8761368576, total data size: 8734266196  
compression rate: 5.01x  
total row count: 75000000, stripe count: 500, average rows per stripe: 150000  
chunk count: 60000, containing data for dropped columns: 0, zstd compressed: 60000  
```  
``VACUUM VERBOSE`` reports a smaller compression ratio, because it  
only averages the compression ratio of the individual chunks, and does  
not account for the metadata savings of the columnar format.  
## System  
* Azure VM: Standard D2s v3 (2 vcpus, 8 GiB memory)  
* Linux (ubuntu 18.04)  
* Data Drive: Standard HDD (512GB, 500 IOPS Max, 60 MB/s Max)  
* PostgreSQL 13 (``--with-llvm``, ``--with-python``)  
* ``shared_buffers = 128MB``  
* ``max_parallel_workers_per_gather = 0``  
* ``jit = on``  
Note: because this was run on a system with enough physical memory to  
hold a substantial fraction of the table, the IO benefits of columnar  
won't be entirely realized by the query runtime unless the data size  
is substantially increased.  
## Query  
```sql  
-- OFFSET 1000 so that no rows are returned, and we collect only timings  
SELECT vendor_id, SUM(quantity) FROM perf_row GROUP BY vendor_id OFFSET 1000;  
SELECT vendor_id, SUM(quantity) FROM perf_row GROUP BY vendor_id OFFSET 1000;  
SELECT vendor_id, SUM(quantity) FROM perf_row GROUP BY vendor_id OFFSET 1000;  
SELECT vendor_id, SUM(quantity) FROM perf_columnar GROUP BY vendor_id OFFSET 1000;  
SELECT vendor_id, SUM(quantity) FROM perf_columnar GROUP BY vendor_id OFFSET 1000;  
SELECT vendor_id, SUM(quantity) FROM perf_columnar GROUP BY vendor_id OFFSET 1000;  
```  
Timing (median of three runs):  
 * row: 436s  
 * columnar: 16s  
 * speedup: **27X**  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")