during training time is harmless as long as relatively few packets are dropped, as 
figure 4 shows.  
During detection, if a never-before-seen n-gram also appears in the bad content 
model, its detection score is further weighted by a factor t over other malicious n-
grams; in our experiment,  we set  t to 5. This enables  us  to further separate  mali-
cious packets from normal ones in order to achieve higher detection accuracy. To 
show the improvement we gain by using the bad content model, figure 5 compares 
the  false  positive  rate  before  and  after  using  it  for  different  n-gram  sizes  on  two 
datasets. The false positive rates are significantly reduced with the help of this bad 
content model.  
e
t
a
R
n
o
i
t
c
e
t
e
D
%
0
0
1
n
e
h
w
)
%
(
e
t
a
R
e
v
i
t
i
t
s
o
P
e
s
a
F
l
0.035
0.03
0.025
0.02
0.015
0.01
0.005
0
2
3
4
dataset www1-06, normal
dataset www1-06, supervised 
dataset www-06, normal
dataset www-06, supervised 
5
6
Value n of n-grams
7
8
9
Fig. 5. The false positive rate (with 100% detection rate) for different n-grams, under both 
normal and semi-supervised training 
2.4   Signature Generation and Privacy-Preserving Cross-Site Collaboration  
One other substantial advantage of Anagram is its ability to generate robust signa-
tures. When a suspicious packet is detected, the corresponding malicious n-grams 
are  identified  in  the  packet  for  free.  These  n-grams  are  good  target  for  further 
analysis  and  signature  generation.  It’s  also  particularly  important  to  note  that  the 
order  of  the  distinct  anomalous  n-grams  is  irrelevant,  since  it’s  just  a  set  of  n-
grams. An attempt to avoid detection by an attacker by reordering their attack vec-
tor code will therefore fail. 
Revisiting the php attack presented before, we show here the signatures gener-
ated by flattening out the detected malicious n-grams according to their positions, 
using  3-grams,  5-grams  and  7-grams,  respectively.  To  present  the  nonprintable 
characters  in  the  following  signatures,  we  use  “.”  as  in  tcpdump.    An  asterisk 
(“*”) represents a “don’t-care” wildcard, similar to a Kleene star match in a regu-
lar expression.  
                                                                     Anagram: A Content Anomaly Detector         237 
GET /modules/Forums/admin/admin_styles.phpadmin_styles.php?p
hpbb_root_path=http://81.174.26.111/cmd.gif?&cmd=cd%20/tmp;w
get%20216.15.209.4/criman;chmod%20744%20criman;./criman;echo
%20YYY;echo|..HTTP/1.1.Host:.128.59.16.26.User-Agent:.Mozill
a/4.0.(compatible;.MSIE.6.0;.Windows.NT.5.1;).. 
N=3:  
*?ph*bb_*//8*p;wg*n;c*n;./c*n;ec*0YYY;echo|H*26.U*1;).* 
N=5: 
*ums/ad*in/admin_sty*.phpadmin_sty*hp?phpbb_root_path=http:/
/81.174.26.111/cmd*cmd=cd%20/tmp;wget%20216*09.4/criman;chmo
d%20744%20criman;./criman;echo%20YYY;echo| HTT*6.26.Use*5.1;
)..* 
N=7: 
*dules/Forums/admin/admin_styles.phpadmin_styles.php?phpbb_r
oot_path=http://81.174.26.111/cmd.gi*?&cmd=cd%20/tmp;wget%20
216.15.209.4/criman;chmod%20744%20criman;./criman;echo%20YYY
;echo|  HTTP/*59.16.26.User-*T 5.1;)..* 
All of these signatures are quite accurate: no normal packet matches more than 
5% of the malicious n-gram signatures of the attack. Generally, low order n-grams 
produces less optimal signatures, since relatively few  n-grams  will be detected as 
malicious  and  they  are  not  long  enough  to  capture  useful  information.  7-grams 
produce the best signature; in theory, the longer the n-gram the better the generated 
signature, higher training and false positive costs notwithstanding.  
Besides the benefits of accurate signature generation, Anagram’s models enable 
cross-site  privacy-preserving  information  sharing  by  using  Bloom  Filters.  In  our 
previous PAYL work [11], we discussed the idea of cross-site collaboration and its 
use  for  zero-day  worm  detection  and  signature  generation,  followed  by  several 
approaches for alert information sharing. However, PAYL’s correlation techniques 
traded accuracy for privacy.  
Instead, Anagram can share Bloom Filters with no loss of accuracy. Suspect pay-
loads are identified by the sensor, and the particular anomalous n-grams (of any size) 
are stored in a Bloom Filter.7  The use of one-way hashes, combined with the large 
number of possible  n-grams,  makes reverse-engineering or  brute  forcing  infeasible. 
By checking  the  n-grams of  local alerts  against the remote  alert Bloom  Filters, it’s 
easy to tell how similar the alerts are to each other, and identify the common mali-
cious n-grams that can be used to construct a candidate attack signature.  
This is a substantial improvement over the previous approaches reported by sev-
eral researchers whereby most common tokens, longest common substrings, and/or 
longest  common  subsequences  are  computed  in  order  to  identify  common  sub-
strings between two or more suspect payloads. These computations intend to com-
pute  string  signatures  common  across  multiple  instances  of  a  polymorphic  worm 
attack.  Anagram  essentially  "pre-computes"  common  string  subsequences  via  the 
common anomalous n-grams stored in the Bloom Filter, irrespective of the order of 
appearance of any of these anomalous strings, and thereby speeds up correlation.  
7  The number of anomalous n-grams must also be transmitted, as it is used in the threshold 
logic to identify anomalous packets. 
238 
K. Wang, J.J. Parekh, and S.J. Stolfo 
Due to a lack of space, we refer the reader to [23] for further details on the me-
chanics and effectiveness of our correlation approaches.  
3   Randomized Models to Thwart Mimicry Attacks 
3.1    Anagram Against Mimicry Attack 
As mentioned earlier, mimicry attacks are perhaps the most significant threat to any 
anomaly detector, such as [1], which details a polymorphic mimicry worm targeting 
PAYL.  This  smart  worm  learns  a  site’s  normal  traffic  pattern  by  sniffing  then 
blends  the  exploit  packet  with  characters  to  simulate  the  normal  byte  frequency 
distribution  to  successfully  evade  PAYL’s  1-gram  models.  Since  this  mimicry 
attack pads  without considering the sequence  of bytes, Anagram can easily detect 
any variants of the crafted attacks8.   
We adapted this worm to launch a mimicry attack against Anagram. Instead of 
padding the packet to simulate the byte frequency, we padded attack packets with 
normal strings; in this case, long URLs of the target website which should be, by 
definition, composed of normal n-grams. Although the anomaly scores are greatly 
reduced by this padding, the  remaining portions of the crafted attack packets still 
have  enough  abnormal  n-grams  to  be  detected  by  Anagram.  Besides  the  “sled”, 
which provides the opportunity for crafted padding, the attack packet still requires a 
byte  sequence  for  the  polymorphic  decryptor,  the  encrypted  exploit,  encoded  at-
tacks, and the embedded mapping table. Since the amount of space in each packet 
is  limited,  the  mimicked  worm  content  containing  the  exploit  vector  is  purposely 
spread over a long series of fragmented packets. Thus, the worm is fragmented so 
that each packet on its own does not appear suspicious.  This strategy is described 
in the aforementioned paper and is akin to a multi-partite attack strategy where the 
protocol  processor  assembles  all  of  the  distributed  pieces  necessary  for  the  com-
plete attack.  
Using the blended polymorph  worm engine,  we generated different  variants of 
the worm. The following table shows the maximum padding length of each version. 
Each cell in the top row contains a tuple (x, y), representing a variant sequence of y 
packets of x bytes each. The second row represents the maximum number of bytes 
that can be used for padding in each packet. It’s obvious that there is a substantial 
chunk of packet that needs to be reserved for the exploit, where we conjecture ma-
licious higher order n-grams will appear to encode the encrypted exploit code or the 
decryptor code.  
Table 3. The padding length for a packet of different varieties of the mimicry attack 
418, 10 
125 
418, 100 
149 
730, 10 
437 
Version 
Padding length 
We tested Anagram over these modified mimicry attacks where the padding con-
tained  normal,  non-malicious  n-grams,  and  all  of  the  attacks  were  successfully 
8  We are very grateful to Wenke Lee and his colleagues for providing the polymorph engine 
1460, 100 
1191 
730, 100 
461 
1460, 10 
1167 
for use in our research.  
                                                                     Anagram: A Content Anomaly Detector         239 
detected. This is the case since the crafted attack packets still require at least 15%-
20% of the n-grams for code, which were detected as malicious. The false positive 
rates  grows,  however,  as  the  packet  length  gets  longer.  The  worst  case  for  the 
(1460,  100)  experiment  yields  a  false  positive  rate  around  0.1%.  The  semi-
supervised learning strategy employed in Anagram using a model of “malicious n-
grams” doesn’t help here since this mimicry worm uses encryption and data encod-
ing to obfuscate its content. We also tested Anagram against polymorphic  worms 
generated  by  the  CLET  engine  [24].  However,  since  CLET  encrypts  the  content 
and  is  not  designed  to  mimic  high  order  n-grams,  it’s  very  easy  for  Anagram  to 
detect them.9 
This experiment demonstrates that Anagram raises the bar for attackers making 
mimicry attacks harder since now the attackers have the task of carefully crafting 
the entire packet to exhibit a normal content distribution. Further effort is required 
by  mimicry attacks to encode the attack  vectors or code in a proper way that ap-
pears as normal high order n-grams. Without knowing exactly which value of n, the 
size of the modeled grams, they should plan for, the problem becomes even harder. 
We take this uncertainty and extend it in the next section for a more thorough strat-
egy to thwart mimicry attacks.   
3.2    Randomization 
The general idea of payload-based mimicry attack is simply to evade detection by 
crafting small pieces of exploit code with a large amount of “normal” padding data 
to make the whole packet look normal. But as we’ve seen in the example above, no 
matter  what  techniques  are  used  for  padding,  there  has  to  be  some  non-padded 
“exposed”  sections  of  data  to  decode  the  exploit  of  the  target  vulnerability.  The 
attacker  has  to  determine  where  to  pad  with  normal  data,  and  where  to  hide  the 
exploit code. Without knowing exactly what portions of the packet are tested by the 
detector,  the  task  is  complicated,  and  possibly  reduced  to  guessing,  even  if  the 
attacker knew what padding would be considered normal.  
We  performed  experiments  using  randomized  modeling  for  PAYL,  where  we 
computed  multiple  models  based  on  different  secret  partitions  of  the  data  stream. 
Although  the  strategy  successfully  thwarted  mimicry  attack,  it  substantially  in-
creased the overhead of the sensor. A future report will detail those experiments. 
Here,  we propose an alternative  general  strategy  to thwart  mimicry attacks  via 
Randomized Testing that does not incur any substantial overhead. Instead of testing 
and scoring the whole packet payload, we randomly partition packets into several 
(possibly interleaved) substrings or subsequences S1,S2,…,SN, and test each of them 
separately  against  the  same  single  normal  BF  model  and  the  single  bad  content 
model.  Since  the  partition  is  randomly  chosen  by  each  sensor  instance  and  kept 
secret,  we assume the attackers cannot  gain this information before they compro-
mise the machine. The attackers could only succeed if they can craft an attack vec-
tor ensuring that the data is normal with respect to any randomly selected portion of 
a packet; this  makes the attacker’s tasks  much harder than  before. This technique 
can be generally applied to any content anomaly detector.  
9  We  invite  the  security  community  to  work  with  us  in  continuing  the  development  and 
detection of mimicry attack-enabled worms. 
240 
K. Wang, J.J. Parekh, and S.J. Stolfo 
To demonstrate the effectiveness of this counter-evasion tactic, we developed a 
simple randomization framework for Anagram. We generate a random binary mask 
with some length l (say, 100 bytes), and repeatedly apply this mask to the contents 
of each packet to generate test partitions. The mask corresponds to subsequences of 
contiguous bytes in the packet tested against the model; each is scored separately. 
The sequence of bytes appearing at locations where the mask had bits set to 1 are 
tested  separately  from  those  byte  sequences  where  the  mask  had  zero  bits,  ran-
domly separating it into two non-overlapping parts.  The packet anomaly score is 
adapted  from  section  2.1  to  maximize  the  score  over  all  partitions,  i.e. 
 and  Ti  are  the  number  of  new  and  total  n-
Score
grams  in  partition  i,  respectively.  This  can  easily  be  extended  to  overlapping  re-
gions of the packet, and more than just two randomly chosen portions.  
,  where 
newiN
max
/
T
i
)
=
(
N
i
new
There are several issues to consider. First, we want to optimize binary mask gen-
eration.  While  the  mask  can  be  a  purely  random  binary  string,  we  may  then  lose 
information  about  sequences  of  bytes.  Since  Anagram  models  n-grams,  it’s  not 
surprising that this strategy performs poorly. Instead, we randomize the mask using 
a “chunked” strategy, i.e. any string of contiguous 0’s or 1’s in the mask must be at 
least X bits long (corresponding to X contiguous bytes in a partition), enabling us to 
preserve most of the n-gram information for testing. In our experiments, empirical 
testing yielded 10 bits as a good candidate size; automatically determining the op-
timal value is an interesting open question for future research.  
Another observation is that the length of the randomly chosen partitions is best 
balanced, i.e. a similar number of 1’s and 0’s. Such balancing avoids the extreme 
cases of too short payload snippets which lack sufficient statistical information. The 
false positive rate is usually much higher when the partitions have extremely unbal-
anced  lengths;  for  example,  a  partition  where  one  fragment  is  10%  of  the  total 
length and the other is 90% produces a poor false positive rate. 
For the results in figure 6, we use this “chunk-based binary mask strategy” and 
guarantee that one partition of the packet datagram is at most double the size of the 
other one. Again, we measure the false positive rate when we achieve 100% detec-
tion rate for our test traces. For each size n-gram,  we repeated the experiment 10 
times  to  show  the  average  (the  middle  plot)  and  standard  deviation  (the  vertical 
bars),  both  for  the  unsupervised  learning  (left  plot)  and  semi-supervised  learning 
(right  plot)  using  the  malicious  n-gram  content  model.  The  experiment  was  per-
formed  on  dataset  www1-06,  trained  for  90  hours  and  tested  on  the  following  72 
hours of traffic. 
On average, the randomized models produce comparable false positive rates to 
the non-randomized approach, especially when using semi-supervised learning. The 
lower order n-grams are more sensitive to partitioning, so they exhibit a high stan-
dard  deviation,  while  higher  order  n-gram  models  are  relatively  stable.  Further 
research needs to be done to determine a good partitioning approach that can reduce 
the deviation while keeping the essential randomization strategy intact. We believe 
randomization is the correct direction, and a valuable step toward complicating the 
task for the mimicry attacker. 
                                                                     Anagram: A Content Anomaly Detector         241 