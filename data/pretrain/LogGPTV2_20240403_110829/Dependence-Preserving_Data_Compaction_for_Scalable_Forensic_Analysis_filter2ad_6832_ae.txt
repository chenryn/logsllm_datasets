### 6.1 Implementation

Our implementation consists of three front-ends and a back-end, all written in C++. The front-ends collectively contain approximately 6,000 lines of code (LoC), while the back-end contains about 7,000 LoC. The front-ends are responsible for processing data from various audit sources. Specifically, one front-end parses Linux audit logs, while the other two parse Linux and Windows data from a red team engagement.

The back-end employs our BuildVer algorithm, incorporating the following optimizations:
- REO, RNO, and CCO (Section 4.2) to ensure FD preservation.
- The source dependence preservation technique described in Section 4.3.
- The compact main-memory representation presented in Section 5.2.

Additionally, our implementation can generate event logs in our CSR format, as detailed in Section 5.1. The back-end also has the capability to read data directly from CSR logs, which is particularly useful for experiments because CSR-formatted data can be processed much faster than data in Linux audit log format or the OS-neutral format used for red team engagement data.

#### Key Points About Our Implementation:

- **Network Connections:** We treat each distinct combination of (remote IP, port, time window) as a distinct source node. Currently, the time windows are set to approximately 10 minutes. This means that all reads performed within a 10-minute period from any IP/port combination are treated as coming from a single source, allowing FD and SD to aggregate them. After 10 minutes, it is considered a new source, enabling us to account for changes in remote site behavior over time (e.g., if the site is compromised). A similar approach applies to physical devices.

- **Handling `execve`:** The `execve` system call causes the entire memory image of a process to be overwritten. Consequently, dependencies acquired before `execve` are less significant compared to those acquired after. To reflect this, we limit REO from traversing past `execve` edges. While removing this restriction could make REO more effective, it would also increase the risk of eliminating important events from the graph.

- **REO* Optimization:** Almost all edges in our graph are between subjects and objects. For instance, if a subject `s` reads an object `o`, `o` could only be an ancestor but not a parent if `o` was read by another subject `s'` that then wrote to an object `o'` being read by `s`. Given the distant nature of this relationship, we did not find REO* to be very practical. Moreover, the high in- and out-degrees of subjects mean that a 3-hop search could involve examining a large number of edges.

### 6.2 Data Sets

Our evaluation uses data from live servers in a small laboratory and from a red team evaluation led by a government agency. Below, we describe these data sets in detail.

#### 6.2.1 Data from Red Team Engagement

This data was collected during the second adversarial engagement organized in the DARPA Transparent Computing program. Several teams were responsible for instrumenting operating systems and collecting data, while our team and others performed attack detection and forensic analysis using this data. The red team conducted attack campaigns over a week, generating both malicious and benign background activity, such as web browsing, emailing, and file editing.

- **Linux Engagement Data (Linux Desktop):** This data captures activity on an Ubuntu desktop machine over two weeks. The primary data source was the built-in Linux auditing framework, transformed into an OS-neutral format by another team. The data includes system calls like `open`, `close`, `clone`, `execve`, `read`, `write`, `chmod`, `rm`, `rename`, and others. Table 8 provides a breakdown of the total number of events and important event types. We excluded `open` and `close` from our analysis due to their coarser granularity compared to `read` and `write`.

- **Windows Engagement Data (Windows Desktop):** This data covers an 8-day period. The primary source was Event Tracing for Windows (ETW). The data set is similar to the Linux data, provided in the same OS-neutral format. However, some differences exist, such as the omission of network reads and writes (though network connects and accepts were reported). Additionally, Windows-specific events like `CreateRemoteThread` were included, and registry events were mapped into file operations. Table 8 shows a higher volume of "other" calls, primarily due to more renames and removes.

#### 6.2.2 Data from Laboratory Servers

To complement the red team data, we collected audit logs from our research lab's production servers, including a web server, mail server, and general-purpose file and remote access server (SSH/File Server) used by a dozen users. All systems ran Ubuntu Linux, and audit data was collected over a week using the Linux audit system, configured to record `open`, `close`, `read`, `write`, `rename`, `link`, `unlink`, `chmod`, etc.

### 6.3 Event Reduction: Comparison of LCD, FD, and SD

Figure 9 illustrates the event reduction factor (i.e., the ratio of the number of events before and after reduction) achieved by our techniques, FD and SD. For comparison, we reimplemented Xu et al.’s full-trackability reduction (LCD) as described in [42]. LCD, FD, and SD achieve average reduction factors of 1.8, 7, and 9.2, respectively. Across the data sets, LCD achieves reduction factors between 1.6 and 2.7, FD ranges from 4.6 to 15.4, and SD from 5.4 to 19.1.

FD provides significantly more reduction than LCD. For example, consider a process `P` that repeatedly reads file `A` and writes file `B`. The sequence might look like `read(A); write(B); read(A); write(B); ...`. Since there is a write edge between every pair of read edges into `P`, none of these edges can be merged under LCD. In contrast, FD can use non-local information to show that `A` has not changed during this period, allowing it to aggregate all reads and writes.

Further analysis of the data revealed that many applications on Linux open the same object multiple times. On average, a process opened the same object approximately twice on the laboratory servers. Since the objects typically did not change, FD could combine the reads following distinct opens, explaining a factor of about 2. Additionally, each open was accompanied by 3 to 5 reads/writes, which FD could also aggregate, explaining a further factor of 2 to 4. The actual reduction achieved by FD is within this explainable range for the laboratory servers. For the Windows desktop, the reduction factor was lower, mainly because the data does not include reads or writes on network data. For the Linux desktop, the FD reduction factor is significantly higher, partly due to long-running processes (e.g., browsers) that acquire new dependencies with new network connections but do not add new dependencies with subsequent operations.

Our implementation of SD builds on FD: if an edge cannot be removed by FD, the SD criterion is applied. This explains why SD always has a higher reduction factor than FD and provides additional benefits.

### 6.4 Log Size Reduction

Table 10 demonstrates the effectiveness of our techniques in reducing the on-disk size of log data. The second column shows the size of the original data, i.e., Linux audit data for laboratory servers and OS-neutral intermediate format for red team engagement data. The third column shows the reduction in size achieved by our CSR representation before any reductions are applied. The next two columns show the size reductions achieved by CSR combined with FD and SD, respectively.

From the table, it can be seen that the reduction factors from FD and CD are somewhat less than those shown in Figure 9. This is expected because they compress only events, not nodes. Nevertheless, the factors are fairly close, especially on larger data sets. For instance, on the Linux desktop data, where FD produces about 15× reduction, the CSR log size shrinks by about 12× over the base CSR size. Similarly, on the SSH/File server, the FD event reduction factor is 8×, and the CSR size reduction is about 6×. Additionally, the log sizes are 35.3× to 41.4× smaller than the input audit logs.

### 6.5 Dependence Graph Size

Table 11 illustrates the effect of different optimizations on memory use. On the largest dataset (Linux desktop), our memory use with FD is remarkably low: less than two bytes per event in the original data. On the other two larger data sets (Windows desktop and SSH/file server), it increases to 3.3 to 6.8 bytes per event. The arithmetic and geometric means (across all the data sets) are both less than 5 bytes/event.

Examining the Linux desktop and Windows desktop numbers closely, we find that the memory use is closely correlated with the reduction factors in Figure 9. For the Linux desktop, there are about 4.7M events left after FD reduction. Each event results in a forward and backward edge, each taking 6 bytes in our implementation (cf. Section 5). Subtracting this 4.7M*12B = 56.4MB from the 111MB, we see that the 1.1M nodes occupy about 55MB, or about 50 bytes per node. Recall that each node takes 32 bytes in our implementation, plus some additional space for storing file names, command lines, etc. A similar analysis of Windows data shows consistent results.

### 6.6 Runtimes for Dependence Graph Construction and Forensic Analysis

Runtimes for constructing the dependence graph and performing forensic analysis are discussed in Section 6.6.

### 6.7 Impact of Optimizations on Forensic Analysis Accuracy

The impact of our optimizations on forensic analysis accuracy is evaluated in Section 6.7.