Dianping. A reviewer can send a ﬂower to another reviewer
in order to present a sense of complement to the reviewer
who posts a nice review. We think these social links among
reviewers are weak, extraneous for characterizing elite Sybil
users on Dianping. Instead, we exploit user-community as a
zoom lens to take a particular micro-macro analysis of elite
Sybil users without using any user proﬁle information.
VIII. RELATED WORK
In this section, we survey the methodology used in previ-
ous research from four categories: graph-based approaches,
feature-based approaches, aggregate behavioral-based clus-
tering approaches, and crowdsourcing-based approaches. We
review each of these approaches as follows.
Graph-based approaches. Graph-based detection views ac-
counts as nodes and social links between accounts as edges.
For example, Liu et al. [26] considered the dynamic change
in the social graph. Much prior work [10, 18, 28] holds
the assumption that in a social graph, there exist a limited
number of attack edges connecting between benign and Sybil
users. The key insights behind this is that it becomes difﬁcult
for attackers to set up links to real users, and strong trusts
are lacking in real OSNs, such as RenRen [47] and Face-
book [5, 8, 12, 22]. Souche [46] and Anti-Reconnaissance [31]
also rely on the assumption that social network structure
alone separates real users from Sybil users. Unfortunately,
this was proven unrealistic since real users refuse to interact
with unknown accounts [37]. Recent research [7] relaxes these
assumptions and takes a combined approach that ﬁrst leverages
victim prediction to weigh the graph and upper bound the
aggregate weight on attack edges; then it performs a short
random walk on the weighted graph and distributes manually-
set scores to classify users. However, We argue that these
methods do not hold on URSNs and the nodes in URSNs
do not show a tight connectivity as those in general OSNs,
which renders the social network graph-connectivity-based
Sybil detection approaches less effective in URSNs.
Feature-based approaches. The advantage of behavioral pat-
terns is that
these can be easily encoded in features and
adopted with machine learning techniques to learn the signa-
ture of user proﬁles and user-level activities. Different classes
of features are commonly employed to capture orthogonal
dimensions of users’ behaviors [13, 24, 32, 34, 35, 43].
Other work [33, 38, 39] considers the associated content
information, such as reviews context, wall posts, hashtags,
and URLs, to ﬁlter Sybil users. Speciﬁcally, the Facebook
immune system [35] detects Sybil users based on features
characterized from user proﬁles and activities. COMPA [13]
is designed to uncover compromised accounts via sudden
change alerts according to the behavioral patterns of users.
In addition to user proﬁle, Song et al. [34] proposed a target-
based detection on Twitter approach which bases on features
of retweets. However, feature-based approaches are relatively
easy to circumvent by adversarial attacks [4, 9, 42, 51]. Further
work will also be needed to detect sophisticated strategies
exhibiting a mixture of realistic and Sybil users features.
Aggregate behavioral-based clustering approaches. Re-
cently, rather than classifying single users, much work [3, 11,
16, 29, 40, 43] focuses on detecting clusters of users. Specif-
ically, CopyCatch [3] and SynchroTrap [11], implementing
mixed approaches, score comparatively low false positive rates
with respect to single feature-based approaches. For Dianping,
the elite Sybil users, however, write elaborate reviews by
mimicking the real reviews and intentionally manipulate the
review temporal patterns within a Sybil campaign, so as to
change the behavior features to bypass detection.
Crowdsourcing-based approaches. Wang et al. [44] tested
the efﬁcacy of crowdsourcing (such as leveraging humans,
both expert annotators, and workers hired online), at detect-
ing Sybil accounts simply from user proﬁles. The authors
observed that the detection rate for hired workers drops off
over time, although majority voting can compensate for the
loss. However, two drawbacks undermine the feasibility of
this approach: (i) This solution might not be cost effective
for large-scale networks, such as Facebook and Dianping;
(ii) exposing personal information to external workers raises
privacy issue [14]. We observe that some recent work dis-
cusses how to identify the regular Sybil users in URSNs
(e.g., Yelp and Dianping) by exploiting crowdsourcing-based
approaches [23, 32, 34], or model-based detection [25] that
limits their broad applicability. Most recent work leverages
Recurrent Neural Networks (RNNs) to automate the genera-
tion of synthetic Yelp reviews [48]. However, we emphasize
that ELSIEDET is immune to the AI attack for two reasons: (i)
ELSIEDET does not accommodate any contextual features that
RNN-based attack is centered around. (ii) The attack dataset
used in [48] does not take in any human-crafted fake reviews,
which presumes that the proposed defense [48] cannot well
identify the fake reviews written by elite Sybil users deﬁned
in our paper. We believe that our research is the ﬁrst to deﬁne,
characterize, and perform a large-scale empirical measurement
study toward the elite Sybil attack in URSNs. We thus hope
that our results may serve as a supplement to other traditional
Sybil detection schemes and shed light on the novel Sybil
detection system for uncovering other evolved Sybil users.
IX. CONCLUSION
This paper illuminates the threat of large-scale Sybil activ-
ities in User-Review Social Networks. We ﬁrst demonstrated
that Sybil organizations of Dianping utilize a hybrid cascading
hierarchy to orchestrate campaigns. An in-depth analysis of
elite Sybil users leads us to several important conclusions:
elite Sybil users are more spread out temporally, craft better-
edited contents, but have fewer reviews ﬁltered. We showed
that most Sybil campaigns can be determined within the ﬁrst
two weeks by only monitoring detected elite Sybil users.
Strikingly, we also showed that a series of chains leverage
Sybil organizations to distort
the online rating, rendering
previous research outdated. We emphasize that sophisticated
manipulation of temporal patterns is key to orchestrating the
evasive strategy. Finally, we demonstrated that ELSIEDET is
both highly effective and scalable as a standalone system.
15
Although our study and experiments focus on Dianping,
we believe that the anti-Sybil defense as examined in this
paper provides an opportunity for all URSNs to stop the spread
of elite Sybil users in a way that has never been visible on
Dianping or other social networks like it.
ACKNOWLEDGMENT
This work was supported in part by the National Science
Foundation of China, under Grants 71671114, 61672350, and
U1405251. Corresponding author: Haojin Zhu.
REFERENCES
[1] (2017) Scikit-learn. [Online]. Available: http://scikit-learn.org/
[2] H. Allcott and M. Gentzkow, “Social Media and Fake News
in the 2016 Election,” National Bureau of Economic Research,
Tech. Rep., 2017.
[3] A. Beutel, W. Xu, V. Guruswami, C. Palow, and C. Faloutsos,
“Copycatch: Stopping Group Attacks by Spotting Lockstep
Behavior in Social Networks,” in Proc. WWW. ACM, 2013,
pp. 119–130.
[4] B. Biggio, G. Fumera, and F. Roli, “Security Evaluation of
Pattern Classiﬁers under Attack,” IEEE TKDE, vol. 26, no. 4,
pp. 984–996, 2014.
[5] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda, “All Your
Contacts are Belong to Us: Automated Identity Theft Attacks on
Social Networks,” in Proc. WWW. ACM, 2009, pp. 551–560.
[6] V. D. Blondel, J.-L. Guillaume, R. Lambiotte, and E. Lefebvre,
“Fast Unfolding of Communities in Large Networks,” Journal
of Statistical Mechanics: Theory and Experiment, vol. 2008,
no. 10, p. P10008, 2008.
[7] Y. Boshmaf, D. Logothetis, G. Siganos, J. Ler´ıa, J. Lorenzo,
M. Ripeanu, and K. Beznosov, “Integro: Leveraging Victim
Prediction for Robust Fake Account Detection in OSNs,” in
NDSS, vol. 15, 2015, pp. 8–11.
[8] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu, “The
Socialbot Network: When Bots Socialize for Fame and Money,”
in Proceedings of the 27th ACSAC. ACM, 2011, pp. 93–102.
[9] M. Br¨uckner, C. Kanzow, and T. Scheffer, “Static Prediction
Games for Adversarial Learning Problems,” JMLR, vol. 13, no.
Sep, pp. 2617–2654, 2012.
[10] Q. Cao, M. Sirivianos, X. Yang, and T. Pregueiro, “Aiding
the Detection of Fake Accounts in Large Scale Social Online
Services,” in NSDI 12, 2012, pp. 197–210.
[11] Q. Cao, X. Yang, J. Yu, and C. Palow, “Uncovering Large
Groups of Active Malicious Accounts in Online Social Net-
works,” in Proc. CCS. ACM, 2014, pp. 477–488.
[12] E. De Cristofaro, A. Friedman, G. Jourjon, M. A. Kaafar, and
M. Z. Shaﬁq, “Paying for Likes?: Understanding Facebook Like
Fraud Using Honeypots,” in Proc. IMC. ACM, 2014, pp. 129–
136.
[13] M. Egele, G. Stringhini, C. Kruegel, and G. Vigna, “COMPA:
Detecting Compromised Accounts on Social Networks,” in
NDSS, 2013.
[14] Y. Elovici, M. Fire, A. Herzberg, and H. Shulman, “Ethical
Considerations When Employing Fake Identities in Online
Social Networks for Research,” Science and Engineering Ethics,
vol. 20, no. 4, pp. 1027–1043, 2014.
[15] C. Erdman, J. W. Emerson et al., “BCP: An R Package for
Performing a Bayesian Analysis of Change Point Problems,”
Journal of Statistical Software, vol. 23, no. 3, pp. 1–13, 2007.
[16] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y. Zhao,
“Detecting and Characterizing Social Spam Campaigns,” in
Proc. IMC. ACM, 2010, pp. 35–47.
16
[17] S. A. Golder and M. W. Macy, “Diurnal and Seasonal Mood
Vary with Work, Sleep, and Daylength across Diverse Cultures,”
Science, vol. 333, no. 6051, pp. 1878–1881, 2011.
[18] N. Z. Gong, M. Frank, and P. Mittal, “Sybilbelief: A Semi-
supervised Learning Approach for Structure-based Sybil De-
tection,” IEEE TIFS, vol. 9, no. 6, pp. 976–987, 2014.
[19] A. Gupta, H. Lamba, and P. Kumaraguru, “$1.00 per rt#
bostonmarathon# prayforboston: Analyzing Fake Content on
Twitter,” in eCRS, 2013.
IEEE, 2013, pp. 1–12.
[20] P. Heymann, G. Koutrika, and H. Garcia-Molina, “Fighting
Spam on Social Web Sites: A Survey of Approaches and Future
Challenges,” IEEE Internet Computing, vol. 11, no. 6, 2007.
[21] X. Hu, J. Tang, Y. Zhang, and H. Liu, “Social Spammer
Detection in Microblogging,” in Proc. IJCAI. AAAI Press,
2013, pp. 2633–2639.
[22] M.
Ikram, L. Onwuzurike, S. Farooqi, E. De Cristofaro,
A. Friedman, G. Jourjon, D. Kaafar, and M. Z. Shaﬁq, “Mea-
suring, Characterizing, and Detecting Facebook Like Farms,”
TOPS, 2017.
[23] K. Lee, P. Tamilarasan, and J. Caverlee, “Crowdturfers, Cam-
paigns, and Social Media: Tracking and Revealing Crowd-
sourced Manipulation of Social Media,” in ICWSM, 2013.
[24] H. Li, Z. Chen, A. Mukherjee, B. Liu, and J. Shao, “Analyzing
and detecting opinion spam on a large-scale dataset via temporal
and spatial patterns,” in ICWSM, 2015.
[25] H. Li, G. Fei, S. Wang, B. Liu, W. Shao, A. Mukherjee, and
J. Shao, “Bimodal Distribution and Co-Bursting in Review
Spam Detection,” in Proc. WWW. ACM, 2017.
[26] C. Liu, P. Gao, M. Wright, and P. Mittal, “Exploiting Temporal
Dynamics in Sybil Defenses,” in Proc. CCS. ACM, 2015, pp.
805–816.
[27] M. Luca and G. Zervas, “Fake it Till You Make it: Reputation,
Competition, and Yelp Review Fraud,” Management Science,
2016.
[28] A. Mohaisen, A. Yun, and Y. Kim, “Measuring the Mixing Time
of Social Graphs,” in Proc. IMC. ACM, 2010, pp. 383–389.
[29] A. Mukherjee, B. Liu, and N. Glance, “Spotting Fake Reviewer
Groups in Consumer Reviews,” in Proc. WWW. ACM, 2012,
pp. 191–200.
[30] A. Mukherjee, V. Venkataraman, B. Liu, and N. Glance, “What
Yelp Fake Review Filter Might be Doing?” in ICWSM, 2013.
[31] A. Paradise, R. Puzis, and A. Shabtai, “Anti-Reconnaissance
Tools: Detecting Targeted Socialbots,” IEEE Internet Comput-
ing, vol. 18, no. 5, pp. 11–19, 2014.
[32] M. Rahman, B. Carbunar, J. Ballesteros, G. Burri, D. Horng
et al., “Turning the Tide: Curbing Deceptive Yelp Behaviors,”
in SDM. SIAM, 2014, pp. 244–252.
[33] A. Ramachandran, N. Feamster, and S. Vempala, “Filtering
ACM,
Spam with Behavioral Blacklisting,” in Proc. CCS.
2007, pp. 342–351.
[34] J. Song, S. Lee, and J. Kim, “Crowdtarget: Target-based Detec-
tion of Crowdturﬁng in Online Social Networks,” in Proc. CCS.
ACM, 2015, pp. 793–804.
[35] T. Stein, E. Chen, and K. Mangla, “Facebook Immune System,”
in Proc. SNS. ACM, 2011, p. 8.
[36] D.
Streitfeld,
Black Mark,
[Online].
technology/yelp-tries-to-halt-deceptive-reviews.html
Get
2012.
http://www.nytimes.com/2012/10/18/
“Buy
The
Available:
Reviews
Times,”
Yelp,
York
New
on
[37] G. Stringhini, C. Kruegel, and G. Vigna, “Detecting Spammers
on Social Networks,” in Proc. ACSAC. ACM, 2010, pp. 1–9.
[38] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song, “Design
and Evaluation of a Real-time URL Spam Filtering Service,” in
IEEE S&P.
IEEE, 2011, pp. 447–462.
[39] K. Thomas, C. Grier, D. Song, and V. Paxson, “Suspended
Accounts in Retrospect: An analysis of Twitter Spam,” in Proc.
IMC. ACM, 2011, pp. 243–258.
[40] K. Thomas, F. Li, C. Grier, and V. Paxson, “Consequences of
Connectivity: Characterizing Account Hijacking on Twitter,” in
Proc. CCS. ACM, 2014, pp. 489–500.
[41] B. Viswanath, A. Post, K. P. Gummadi, and A. Mislove,
“An Analysis of Social Network-based Sybil Defenses,” ACM
SIGCOMM CCR, vol. 40, no. 4, pp. 363–374, 2010.
Adversarial Learning,” in ICDM.
[42] F. Wang, W. Liu, and S. Chawla, “On Sparse Feature Attacks in
IEEE, 2014, pp. 1013–1018.
[43] G. Wang, T. Konolige, C. Wilson, X. Wang, H. Zheng, and B. Y.
Zhao, “You are How You Click: Clickstream Analysis for Sybil
Detection,” in USENIX Security, 2013, pp. 241–256.
[44] G. Wang, M. Mohanlal, C. Wilson, X. Wang, M. Metzger,
H. Zheng, and B. Y. Zhao, “Social Turing Tests: Crowdsourcing
Sybil Detection,” in NDSS, 2013.
[45] G. Wang, C. Wilson, X. Zhao, Y. Zhu, M. Mohanlal, H. Zheng,
and B. Y. Zhao, “Serf and turf: Crowdturﬁng for Fun and Proﬁt,”
in Proc. WWW. ACM, 2012, pp. 679–688.
[46] Y. Xie, F. Yu, Q. Ke, M. Abadi, E. Gillum, K. Vitaldevaria,
J. Walter, J. Huang, and Z. M. Mao, “Innocent by Association:
Early Recognition of Legitimate Users,” in Proc. CCS. ACM,
2012, pp. 353–364.
[47] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Y. Zhao, and Y. Dai,
“Uncovering Social Network Sybils in the Wild,” ACM TKDD,
vol. 8, no. 1, p. 2, 2014.
[48] Y. Yao, B. Viswanath, J. Cryan, H. Zheng, and B. Y. Zhao, “Au-
tomated Crowdturﬁng Attacks and Defenses in Online Review
Systems,” in Proc. CCS. ACM, 2017.
[49] H. Yu, P. B. Gibbons, M. Kaminsky, and F. Xiao, “Sybillimit:
A Near-optimal Social Network Defense against Sybil Attacks,”
in IEEE S&P.
IEEE, 2008, pp. 3–17.
[50] H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman, “Sybil-
guard: Defending against Sybil Attacks via Social Networks,”
in ACM SIGCOMM CCR, vol. 36. ACM, 2006, pp. 267–278.
[51] F. Zhang, P. P. Chan, B. Biggio, D. S. Yeung, and F. Roli,
“Adversarial Feature Selection against Evasion Attacks,” IEEE
Transactions on Cybernetics, vol. 46, no. 3, pp. 766–777, 2016.
[52] Y. Zhao, Y. Xie, F. Yu, Q. Ke, Y. Yu, Y. Chen, and E. Gillum,
“BotGraph: Large Scale Spamming Botnet Detection,” in NSDI,
vol. 9, 2009, pp. 321–334.
17