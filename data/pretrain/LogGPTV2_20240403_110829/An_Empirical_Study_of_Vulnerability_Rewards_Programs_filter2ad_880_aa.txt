title:An Empirical Study of Vulnerability Rewards Programs
author:Matthew Finifter and
Devdatta Akhawe and
David A. Wagner
An Empirical Study of Vulnerability 
Rewards Programs
Matthew Finifter, Devdatta Akhawe, and David Wagner, University of California, Berkeley
Open access to the Proceedings of the 22nd USENIX Security Symposium is sponsored by USENIXThis paper is included in the Proceedings of the 22nd USENIX Security Symposium.August 14–16, 2013 • Washington, D.C., USAISBN 978-1-931971-03-4An Empirical Study of Vulnerability Rewards Programs
Matthew Finifter, Devdatta Akhawe, and David Wagner
University of California, Berkeley
\{ ﬁnifter, devdatta, daw\} @cs.berkeley.edu
Abstract
We perform an empirical study to better understand two
well-known vulnerability rewards programs, or VRPs,
which software vendors use to encourage community
participation in ﬁnding and responsibly disclosing soft-
ware vulnerabilities. The Chrome VRP has cost approx-
imately $580,000 over 3 years and has resulted in 501
bounties paid for the identiﬁcation of security vulnerabili-
ties. The Firefox VRP has cost approximately $570,000
over the last 3 years and has yielded 190 bounties. 28%
of Chrome’s patched vulnerabilities appearing in secu-
rity advisories over this period, and 24% of Firefox’s,
are the result of VRP contributions. Both programs ap-
pear economically efﬁcient, comparing favorably to the
cost of hiring full-time security researchers. The Chrome
VRP features low expected payouts accompanied by high
potential payouts, while the Firefox VRP features ﬁxed
payouts. Finding vulnerabilities for VRPs typically does
not yield a salary comparable to a full-time job; the com-
mon case for recipients of rewards in either program is
that they have received only one reward. Firefox has far
more critical-severity vulnerabilities than Chrome, which
we believe is attributable to an architectural difference
between the two browsers.
1
Some software vendors pay security researchers for the re-
sponsible disclosure of a security vulnerability. Programs
implementing the rules for this exchange are known as
vulnerability rewards programs (VRPs) or bug bounty
programs. The last couple of years have seen an upsurge
of interest in VRPs, with some vendors expanding their
existing programs [1, 19], others introducing new pro-
grams [3, 34, 38], and some companies offering to act as
an intermediary between security researchers and vendors
offering VRPs [53].
Introduction
VRPs offer a number of potential attractions to software
vendors. Offering adequate incentives entices security re-
searchers to look for vulnerabilities, and this increased
attention improves the likelihood of ﬁnding latent vulner-
abilities.1 Second, coordinating with security researchers
allows vendors to more effectively manage vulnerability
disclosures, reducing the likelihood of unexpected and
1For instance, Linus’s Law suggests “Given enough eyeballs, all
bugs are shallow.” [48]
1
costly zero-day disclosures. Monetary rewards provide an
incentive for security researchers not to sell their research
results to malicious actors in the underground economy
or the gray world of vulnerability markets. Third, VRPs
may make it more difﬁcult for black hats to ﬁnd vulnera-
bilities to exploit. Patching vulnerabilities found through
a VRP increases the difﬁculty and therefore cost for mali-
cious actors to ﬁnd zero-days because the pool of latent
vulnerabilities has been diminished. Additionally, expe-
rience gained from VRPs (and exploit bounties [23, 28])
can yield improvements to mitigation techniques and help
identify other related vulnerabilities and sources of bugs.
Finally, VRPs often engender goodwill amongst the com-
munity of security researchers. Taken together, VRPs
provide an attractive tool for increasing product security
and protecting customers.
Despite their potential beneﬁts, there is an active de-
bate over the value and effectiveness of VRPs. A number
of vendors, notably Microsoft,2 Adobe, and Oracle, do
not maintain a VRP, with Microsoft arguing that VRPs
do not represent the best return on investment on a per-
bug basis [26]. Further, it is also not clear if the boun-
ties awarded are a sufﬁcient attraction for security re-
searchers motivated by money—underground economy
prices for vulnerabilities are far higher than those offered
by VRPs [20, 37].
Given the emergence of VRPs as a component of the
secure development lifecycle and the debate over the efﬁ-
cacy of such programs, we use available data to better un-
derstand existing VRPs. We focus on the Google Chrome
and Mozilla Firefox web browsers, both of which are
widely considered to have mature VRPs, as case studies.
We analyze these VRPs along several dimensions with
the intention of better understanding the characteristics,
metrics, and trajectory of a VRP.
We make the following contributions:
• We collect and analyze data on vulnerability rewards
over the last 3 years for the Google Chrome VRP
and the Mozilla Firefox VRP (Section 3).
• We assess the state of these VRPs along several
dimensions, including costs, beneﬁts, popularity, and
2On June 19, 2013, during ﬁnal preparation of this manuscript,
Microsoft announced a month-long VRP for the IE11 developer pre-
view [54].
USENIX Association  
22nd USENIX Security Symposium  273
efﬁcacy (Section 4), ﬁnding that these VRPs appear
both effective and cost-effective.
• We make concrete recommendations for software
vendors aiming to start or evolve their own VRP
(Section 5.2).
• We generate hypotheses, which identify opportuni-
ties for future research on VRPs and secure software
development.
2 Background
A secure software development lifecycle (SDLC) aims to
address software security throughout the entire software
development process, from before speciﬁcations are de-
veloped to long after software has been released [15]. A
vulnerability remediation strategy is any systematic ap-
proach whose goal is to reduce the number of software
vulnerabilities [57]. Vulnerability remediation strategies
are one important part of an SDLC, complemented by
things like incident response [32], operational security
considerations [46], and defense in depth [16].
Potential vulnerability remediation strategies include:
• Code reviews. These can range from informal, as-
needed requests for code review to systematized, for-
mal processes for mandatory code inspection. Typi-
cally, SDLCs also include an extra security review
for security critical features.
• Penetration testing. Software vendors may perform
in-house penetration testing or may hire external
companies who specialize in this service. Penetra-
tion testing ranges from manual to automated.
• Use of dynamic and static analysis tools. Special-
ized tools exist for catching a wide range of ﬂaws,
e.g., memory safety vulnerabilities, conﬁguration
errors, and concurrency bugs.
• Vulnerability rewards programs. The focus of
our study, VRPs have recently received increased
attention from the security community.
How such strategies are systematized and realized
varies widely between software vendors. One company
might require mandatory code reviews before code check-
in, while another might hire outside penetration testing
experts a month before product release. Vendors often
combine or innovate on existing strategies.
Vulnerability rewards programs (VRPs) appear to be
emerging as a viable vulnerability remediation strategy.
Many companies have them, and their popularity contin-
ues to grow [6, 9]. But VRPs have gone largely unstudied.
For a company considering the use of a VRP in their
SDLC, guidance is limited.
By studying mature, high-proﬁle VRPs, we aim to
provide guidance on the development of new VRPs and
the evolution and maturation of existing VRPs. Vendors
looking to grow their VRPs can beneﬁt from an improved
understanding of those VRPs we study.
Toward this end, we measure, characterize, and dis-
cuss the Google Chrome and Mozilla Firefox VRPs. We
choose these VRPs in particular because browsers are a
popular target for malicious actors today. Their ubiqui-
tous nature and their massive, complex codebase with
signiﬁcant legacy components make them especially vul-
nerable. Complex, high-performance components with a
large attack surface such as JavaScript JITs also provide
an alluring target for malicious actors. For the same rea-
sons, they are also widely studied by security researchers;
they therefore provide a large sample size for our study.
In addition, browser vendors were among the ﬁrst to of-
fer rewards for vulnerabilities: Mozilla’s VRP started in
2004 and Google introduced the Chrome VRP in 2010,
before the security community at large adopted VRPs as
a vulnerability remediation strategy.
2.1 Goals
We intend to improve our understanding of the following
characteristics of a mature VRP: (1) Expected cost, (2)
expected beneﬁts, (3) incentive levels effective for encour-
aging and sustaining community participation, and (4)
volume of VRP activity (e.g., number of patches coming
out of VRP reports).
We do so by studying available data coming out of two
exemplars of well-known, mature VRPs, that of Google
Chrome and Mozilla Firefox. Understanding these VRPs
will allow these vendors to evaluate and improve their
programs, and it will suggest targets for other vendors
to strive toward with their VRPs. At minimum, we hope
to arrive at a better understanding of the current state
of VRPs and how they have evolved. At best, we aim
to make concrete suggestions for the development and
improvement of VRPs.
2.2 Google Chrome VRP
The Google Chrome VRP3 is widely considered an ex-
emplar of a mature, successful VRP. When ﬁrst intro-
duced in January 2010, the Google Chrome VRP offered
researchers rewards ranging from $500 for high- and
critical-severity bugs, with a special $1337 reward for
particularly critical or clever bugs. Over time, the typical
payout increased to a $1000 minimum with a maximum
payout of $3133.7 for high-impact vulnerabilities. Addi-
tionally, the Chrome team, has provided rewards of up to
$31,336 for exceptional vulnerability reports [21].
3The program is ofﬁcially the Chromium VRP with prizes sponsored
by Google. We refer to it as the Google Chrome VRP for ease of
exposition.
274  22nd USENIX Security Symposium 
USENIX Association
2
Google also sponsors a separate, semi-regular exploit
bounty called the “pwnium” competition [23]. This pro-
gram focuses on full exploits; a mere vulnerability is not
enough. In return, it awards higher bounties (as high as
$150,000) for these exploits [8]. Reliable exploits for
modern browsers typically involve multiple vulnerabili-
ties and signiﬁcant engineering effort. For example, the
two winning entries in a recent “pwnium” contest required
six and ten vulnerabilities in addition to “impressive” en-
gineering in order to achieve a successful exploit [7, 45].
Our focus is on programs that provide bounties for vul-
nerabilities; we do not consider exploit bounties in this
work.
The severity of a vulnerability plays a key role in decid-
ing reward amounts. Google Chrome uses a clear guide-
line for deciding severity [12]. In short, a critical vulnera-
bility allows an attacker to run arbitrary native code on the
user’s machine; for instance, web-accessible memory cor-
ruption vulnerabilities that appear in the Chrome kernel4
are typically critical severity. A high-severity vulnerabil-
ity is one that allows an attacker to bypass the same-origin
policy, e.g., via a Universal XSS vulnerability (which en-
ables an attacker to mount an XSS attack on any web site)
or a memory corruption error in the sandbox. A vulner-
ability is of medium severity if achieving a high/critical
status requires user interaction, or if the vulnerability only
allows limited disclosure of information. Finally, a low-
severity vulnerability refers to all the remaining security
vulnerabilities that do not give the attacker control over
critical browser features. Medium-severity vulnerabili-
ties typically receive rewards of $500, and low-severity
vulnerabilities typically do not receive rewards.
2.3 Mozilla Firefox VRP
Mozilla’s VRP is, to the best of our knowledge, one of the
oldest VRPs in the industry. It was ﬁrst started in 2004 and
based on a similar project at Netscape in 1995 [41]. The
Mozilla VRP initially awarded researchers $500 for high-
or critical-severity security bugs. Starting July 1, 2010
Mozilla expanded its program to award all high/critical
vulnerabilities $3000 [1].
Mozilla’s security ratings are similar to that of Chrome.
Critical vulnerabilities allow arbitrary code execution on
the user’s computer. Vulnerabilities that allow an attacker
to bypass the same-origin policy or access conﬁdential
information on the user’s computer are high severity.
Due to the absence of privilege separation in the Fire-
fox browser, all memory corruption vulnerabilities are
critical, regardless of the component affected. Mozilla
is currently investigating a privilege-separated design for
Firefox [17, 36, 39].
Mozilla’s VRP also qualitatively differs from the
Google program. First, Mozilla awards bounties even
if the researcher publicly discusses the vulnerability
instead of reporting it to Mozilla.5 Second, Mozilla also
explicitly awards vulnerabilities discovered in “nightly”
(or “trunk”) versions of Firefox.
In contrast, Google
discourages researchers from using “canary” builds and
only awards bounties in canary builds if internal testing
would miss those bugs [55].
3 Methodology
For both browsers, we collect all bugs for which rewards
were issued through the browser vendor’s VRP. To evalu-
ate the impact of the VRP as a component of the SDLC,
we also collected all security bugs affecting stable releases.
We chose to look only at bugs affecting stable releases to
ignore the impact of transient bugs and regressions caught
by internal testing.
For each bug in the above two datasets, we gathered
the following details: (1) severity of the bug, (2) reward
amount, (3) reporter name, (4) report date. For bugs
affecting stable releases, we also aimed to gather the date
a release patching the bug became available for download.
As we discuss below, we were able to gather this data for
only a subset of all bugs.
For all bugs, we mark a bug as internally or externally
reported via a simple heuristic: if a reward was issued,
the reporter was external, and otherwise the reporter was
internal. Because low and medium severity vulnerabil-
ities usually do not receive bounties, we only look at
critical/high vulnerabilities when comparing internal and
external bug reports. While all high/critical vulnerabilities
are eligible for an award, a researcher can still refuse an
award, in which case, our heuristic falsely marks the bug
“internal.” We are aware of a handful of such instances,
but there are not enough of these in our dataset to affect
our analysis.
We are also aware of some researchers who transitioned
from external to internal over the course of our study pe-
riod. Because our heuristic operates on a per-bug basis
(as opposed to marking each person as internal or exter-
nal), the same person may be (intentionally) considered
internal for one bug and external for another.
In this section, we present how we gathered this dataset
for Chrome and Firefox. We ﬁrst discuss how we identify
the list of bugs affecting stable releases and bugs awarded
bounties, followed by a discussion on how we identiﬁed,
for each bug, other details such as severity. Finally, we
discuss threats to the validity of our measurement study.
3.1 Gathering the Google Chrome dataset
We gathered data from the ofﬁcial Chromium bug
tracker [13] after conﬁrming with Google employees that
4Chrome follows a privilege-separated design [4]. The Chrome
kernel refers to the privileged component.
5But Mozilla reports that this was a rare occurrence over the period of
time we consider, possibly because the VRP became widely known [56].
USENIX Association  
22nd USENIX Security Symposium  275
3
the bug tracker contained up-to-date, authoritative data
on rewards issued through their VRP. We search the bug
tracker for bugs marked with the special “Reward” label
to collect bugs identiﬁed through the VRP. Next, we
searched the bug tracker for bugs marked with the special
“Security-Impact: Stable” to collect bugs affecting stable
releases. Next, we remove the special Pwnium [23]
rewards from all datasets because Pwnium rewards
exploits instead of vulnerabilities as in the regular VRP.
This provides us with 501 bugs identiﬁed through the
VRP and 1347 bugs affecting stable releases.
The Chromium Bug tracker provides a convenient in-
terface to export detailed bug metadata, including severity,
reporter, and report date, into a CSV ﬁle, which we use
to appropriately populate our dataset. We identify the
reward amounts using the “Reward” label.
Unfortunately, the Chromium bug tracker does not in-
clude the release date of bug ﬁxes. Instead, we gather
this data from the Google Chromium release blog [27].
For each stable release of the Chromium browser, Google
releases a blog post listing security bugs ﬁxed in a release.
For the subset of bugs mentioned in these release notes,
we extract the release date of the stable version of Chrome
that patches the bug.
3.2 Gathering the Mozilla Firefox dataset
Similar to Google Chrome, we searched Bugzilla, the
Firefox bug tracker, for an attachment used to tag a bug
bounty.6 We identiﬁed 190 bugs via this search.
Unlike the Chrome bug tracker, Bugzilla does not pro-
vide a convenient label to identify bugs affecting stable
releases. Instead, Mozilla releases Mozilla Foundation
Security Advisories (MFSA) with every stable release of
Mozilla Firefox [40]. We scraped these advisories for
a list of bugs affecting stable releases. We also use the
MFSAs to identify the release date of a patched, stable
version of Firefox. We gathered 613 unique bugs from the
MFSA advisories dating back to March 22, 2010 (Firefox
3.6).
Similar to the Chromium Bug tracker, the Bugzilla
website provides a convenient interface to export detailed
bug data into a CSV ﬁle for further analysis. We used
Bugzilla to collect, for each bug above, the bug reporter,
the severity rating, and the date reported. The security
severity rating for a bug is part of the Bugzilla keywords
ﬁeld and not Bugzilla’s severity ﬁeld. We do not sep-
arately collect the amount paid because, as previously
discussed, Mozilla’s expanded bounty program awards
$3,000 for all critical/high vulnerabilities.
6The existence of this attachment is not always visible to the public.
We acknowledge the support of Mozilla contributor Dan Veditz for his
help gathering this data.
Chrome
Firefox
Severity
Low
Medium
High
Critical
Unknown
Total
Stable
226
288
793
32
8
1347
Bounty
1
72
395
20
13
501
Stable
16
66
79
393
59
613
Bounty
1
9
38
142
0
190
Table 1: Number of observations in our dataset.
3.3 Dataset
Table 1 presents information about the ﬁnal dataset we
used for our analysis. We have made our dataset available
online for independent analysis [33].
3.4 Threats to validity
In this section, we document potential threats to validity
so readers can better understand and take into account the
sources of error and bias in our study.
It is possible that our datasets are incomplete, i.e., there
exist patched vulnerabilities that do not appear in our
data. For example, for both Chrome and Firefox, we rely
heavily on the keyword/label metadata to identify bugs;
since this labeling is a manual process, it is possible that
we are missing bugs. To gather the list of bugs affecting
stable releases, we use the bug tracker for Chrome but
use security advisories for Mozilla, which could be in-
complete. Given the large number of vulnerabilities we
do have in our datasets, we expect that a small number of
missing observations would not materially inﬂuence the
conclusions we draw.
We treat all rewards in the Firefox VRP as $3,000
despite knowing that 8% of the rewards were for less
than this amount [56]. Data on which rewards were for
less money and what those amounts were is not publicly
available. Any results we present regarding amounts paid
out for Firefox vulnerabilities may therefore have as much
as 8% error, though we expect a far lower error, if any. We
do not believe this affects the conclusions of our analysis.
Parts of our analysis also compare Firefox and Chrome
VRPs in terms of number of bugs found, which assumes
that ﬁnding security vulnerabilities in these browsers re-
quires comparable skills and resources. It could be the
case that it is just easier to ﬁnd bugs in one over the
other, or one browser has a lower barrier to entry for
vulnerability researchers. For example, the popular Ad-
dress Sanitizer tool worked only on Google Chrome until
Mozilla developers tweaked their build infrastructure to
enable support for the same [31]. Another confound is
the possibility that researchers target a browser based on
personal factors beyond VRPs. For example, researchers
could look for vulnerabilities only in the browser they
personally use.
Assigning bug severity is a manual process. While
276  22nd USENIX Security Symposium 
USENIX Association
4
the severity assignment guidelines for both browsers are
similar, it is possible that vendors diverge in their actual
severity assignment practices. As a result, the bug severi-
ties could be incomparable across the two browsers.
We study only two VRPs; our results do not necessarily
generalize to any other VRPs. We caution the reader to
avoid generalizing to other VRPs, but instead take our
results as case studies of two mature, well-known VRPs.
4 Results
We study VRPs from the perspectives of three interested
parties: the software vendor, the independent security
researcher, and the security researcher employed full-time
by the software vendor.
4.1 Software vendor
We model the software vendor’s goal as follows: to in-
crease product security as much as possible while spend-
ing as little money as possible. There are many potential
strategies for working toward this goal, but in this paper
we consider the strategy of launching a VRP. We present
data on costs and beneﬁts for two VRPs, and generate
hypotheses from this data. The software vendor’s motiva-
tion can also include publicity and engaging the security
research community. We do not measure the impact of
VRPs on these.
4.1.1 Number of vulnerabilities
The intended beneﬁt of a VRP is to improve product se-
curity. A reduction in the number of latent vulnerabilities
is one way of improving product security. We ﬁnd that
the Chrome VRP uncovers about 2.6 times as many vul-
nerabilities as that of Firefox (501 vs. 190), despite the
fact that Chrome’s total number of security vulnerabilities
in our dataset is only 2.2 times that of Firefox (Table 1).
27.5% of bugs affecting Chrome releases originate from
VRP contributions (371 of 1347), and 24.1% of bugs af-
fecting Firefox releases (148 of 613) result from VRP
contributions.
Discussion Both VRPs yield a signiﬁcant fraction of
the total number of security advisories, which is a clear
beneﬁt. Chrome is seeing approximately 1.14 times the
beneﬁt of Firefox by our metric of fraction of advisories
resulting from VRP contributions. We only study bugs af-
fecting stable releases in this metric and caution the reader
from assuming that VRPs are competitive with internal
researchers. For both browsers, internal researchers ﬁnd
far more bugs during the months of testing that precede
a typical browser release. For example, from January to
May 2013, across all release channels, Google researchers
found 140 high or critical vulnerabilities in Chrome, while
the Chrome VRP only found 40 vulnerabilities in the same
time period.
8
.
6
.
l
s
h
t
n
o
m
5
t
s
a
l
s
u
p
t
n
e
r
r
u
c
n
i
s
n
u
v
n
o
i
t
c
a
r
F
l
4
.
2
.
0
7/09
1/10
7/10