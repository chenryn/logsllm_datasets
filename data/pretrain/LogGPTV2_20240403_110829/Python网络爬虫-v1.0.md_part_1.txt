# 前言
## 为什么使用 Python 编写网络爬虫？
Python 是一种结构严谨且库资源丰富的编程语言，这大大降低了计算机运行速度对程序的影响，并增强了其便于程序员思考和实现的特性。因此，选择 Python 来开发网络爬虫是一个理想的选择。
本教程将简要介绍如何利用 Python 的相关模块（如 `urllib2`）来构建一个基本的网络爬虫。

## 适用人群
- 对高效抓取网络内容有需求的开发者。
- 需要批量获取网页数据的专业人士或研究者。

## 学习前提
在开始学习本教程之前，请确保您已经具备了 Python 编程的基础知识。

## 版本信息
本书中的示例代码基于以下版本：
- Python 2.7.5

> 注意：由于 Python 3.x 版本与 2.x 版本存在较大差异，如果您的环境是 Python 3，请参考其他更合适的资料。

### 致谢
感谢 CSDN 博客提供的支持与灵感来源：[http://blog.csdn.net/column/details/why-bug.html](http://blog.csdn.net/column/details/why-bug.html)

---

# 目录
1. 引言
2. 第一章 抓取网页的意义及 URL 的基本构成
   - 1.1 网络爬虫定义
   - 1.2 浏览网页的过程
   - 1.3 URI 和 URL 概念解析
   - 1.4 URL 结构详解
   - 1.5 URI 与 URL 的比较
3. 第二章 使用 urllib2 通过指定 URL 抓取网页内容
   - 2.1 初识 urllib2
   - 2.2 发送 HTTP 请求
   - 2.3 处理不同类型的 URL
   - 2.4 发送表单数据
   
---

## 第一章 抓取网页的意义及 URL 的基本构成

### 1.1 网络爬虫定义
网络爬虫（Web Spider 或 Web Crawler）是一种形象化的名称，它模拟蜘蛛在网络（或称作“互联网”）上爬行，从某个起始页面出发，递归地访问该站点内的所有链接指向的页面直至遍历完毕。如果将整个互联网视为单一网站，则可以应用相同原理来抓取全网的所有网页。

### 1.2 浏览网页的过程
当你在浏览器中输入网址（如 www.baidu.com），实际上是向服务器发起了一次请求。浏览器作为客户端接收并解析服务器返回的数据（通常是 HTML 文档），然后将其呈现给用户。

### 1.3 URI 和 URL 概念解析
- **URI (Uniform Resource Identifier)**: 用于标识任何可用资源的位置。
- **URL (Uniform Resource Locator)**: 为 URI 的一种特定形式，不仅指定了资源位置还提供了访问方式等信息。

### 1.4 URL 结构详解
URL 标准格式如下:
```
scheme://host:port/path?query#fragment
```
其中各部分含义分别为：
- **scheme**: 访问协议（例如 http, https, ftp）
- **host**: 主机地址
- **port**: 端口号
- **path**: 文件路径
- **query**: 查询参数
- **fragment**: 锚点

### 1.5 URI 与 URL 的比较
虽然两者经常被混用，但它们之间存在细微差别。简单来说，所有的 URL 都是 URI，但并非所有 URI 都是 URL。后者侧重于定位具体资源所在位置及其访问方法。

---

## 第二章 使用 urllib2 通过指定 URL 抓取网页内容

### 2.1 初识 urllib2
`urllib2` 是 Python 中用来处理 URLs 的一个标准库，提供了一个名为 `urlopen()` 的简单接口用于打开并读取远程文件。

```python
import urllib2
response = urllib2.urlopen('http://www.baidu.com/')
html = response.read()
print(html)
```

这段代码会打印出百度首页的 HTML 源码。

### 2.2 发送 HTTP 请求
除了直接调用 `urlopen()` 方法外，还可以通过创建 `Request` 对象来自定义请求头信息等属性。

```python
import urllib2
req = urllib2.Request('http://www.baidu.com')
response = urllib2.urlopen(req)
the_page = response.read()
print(the_page)
```

### 2.3 处理不同类型的 URL
`urllib2` 不仅支持 HTTP 协议，也可以处理 FTP、FILE 等多种类型。

### 2.4 发送表单数据
当需要向服务器提交表单数据时，可以通过设置 `data` 参数来发送 POST 请求。

```python
import urllib
import urllib2
data = urllib.urlencode({'key': 'value'})
req = urllib2.Request(url='http://example.com', data=data)
response = urllib2.urlopen(req)
print(response.read())
```

以上就是关于使用 Python 进行基础网络爬虫开发的一些入门知识。希望对你有所帮助！