these three; for instance, F GC represents images that have
detected faces (F ), generic objects (G) and circles (C). The
ﬁfteen images are categorized into eight possible categories,
see Table 4.
No images contained only face and circle objects, so we
ignored this category and use only seven categories. The
number of regions and the ACP on the ﬁfteen images are
shown in Tables 4 and 5, respectively. We used them to
compute the percentage of ACP for each RoI by computing
the total number of ACP that fall into each RoI for each
category (see Table 5). Since the image corners have a dif-
ferent number of ACP based on their location, we consider
them separately: top-left (TL), top-right (TR), bottom-left
(BL), and bottom-right (BR).
The percentage for each region is calculated by dividing
the total number of ACP on each category of images ag-
gregated by the object type as seen in Table 5 by the total
number of regions in the same category as indicated in Ta-
ble 4. The result is the average of ACP per region which is
divided by the average number of ACP that have been made
on each image. Table 6 shows the percentage of the average
of ACP per region based on the object type and category
of the image. The lower the percentage for a given category
in Table 6, the less likely it is that a user will select that
location. For instance, in the F G row in Table 6, which rep-
resents images containing faces and generic objects, users
are unlikely to select a Nose object (0% likelihood), but are
more likely to select the top left corner (6%).
3.6 Password Entropy
As with the saliency calculations in Section 3.2, we used
entropy as a strength measure for the graphical passwords
created by the users in Zhao et al.’s study. We assigned a
likelihood of selection to each 19x19 pixel region in each of
133
Table 5: The number of ACP that fall in the de-
tected object aggregated by the object type and cat-
egory
Category
F
FG
FGC
G
GC
C
NONE
Face Eye Nose Mouth Generic Circle TL TR BL BR
0
3
3
7
1
1
6
110
357
326
343
223
215
112
225
239
759
0
0
0
0
0
272
111
596
156
0
0
6
302
47
0
0
0
0
0
165
55
0
0
0
0
59
0
276
0
0
0
0
1528
1788
0
2
3
6
0
4
5
2
3
1
6
0
4
4
1937
0
0
0
0
Table 6: The likelihood of each region aggregated
by the object type and category. The empty cells
have zero likelihood.
Eye Nose Mouth Generic Circle TL
Face
<1%
<1% 1%
<1% <1% 1%
1%
1%
1%
1%
<1%
<1%
1%
<1%
Category
F
FG
FGC
G
GC
C
NONE
BL
BR
TR
6% <1%
6%
<1% 5%
1%
1%
6% <1% <1% <1%
6%
5% <1% <1%
6% <1% <1% <1%
the ﬁfteen images based on the method described in Sec-
tion 3.5. We used this likelihood as input to calculating the
practical password space using entropy using the Shannon
equation [4], which is measured in bits.
Table 2 shows the entropy calculations per click point for
the 15 images in the dataset. Higher entropy implies a higher
practical password space, which means that there are more
possible passwords that must be guessed during an attack.
The highest entropy (5.88 bits per click) was for Image 4,
which means that this image is the most complex image
(in this dataset) since it has more regions that are less fre-
quently selected compared to more frequently selected re-
gions. Images 1 and 2, both of which show a jet against the
sky had the lowest entropy at 0.30 and 0.42 bits per click,
respectively, which means they are the least suitable images
because they have an insuﬃcient number of RoIs to allow
for selected points to be spread across the image. Therefore,
the lack of RoIs in an image may lead users to create (likely)
memorable but also predictable (e.g., weak) passwords, and
the existence of many and varied RoIs may lead users to
create stronger but (likely) less memorable passwords.
We computed the coeﬃcient of multiple correlation to
measure how the entropy of practical password space can
be predicted using a linear regression equation of a set of
variables that represent the number and type of RoIs. The
statistically signiﬁcant result indicated that the number and
type of regions predicted the entropy of practical password
space, F (6, 8) = 7.049; ρ< 0.05; r2 = 0.841. The value of
the multiple correlation coeﬃcient R = 0.92 means that the
model has a good level of prediction. Equation 2 shows the
model, where F , E, N , M , G, C are the number of de-
tected RoI in an image for face, eye, nose, mouth, generic,
and circle, respectively. Note that the weights in Equation 2
were experimentally determined during the regression calcu-
lation; they will vary depending on the input images used.
The model simpliﬁes computing the predicted entropy of
practical password space for an image because it depends
on the number and type of detected RoIs.
H(I)pred = W1 − (W2 ∗ F ) + (W3 ∗ E) − (W4 ∗ N )
+(W5 ∗ M ) + (W6 ∗ G) + (W7 ∗ C)
(2)
As a comparison point, the per-character entropy for a nu-
meric PIN is 3.32 bits per digit, for a case-sensitive password
with letters only is 4.7 bits per character, and for a textual
password made up of case insensitive letters (52 choices),
digits (10 choices) and special characters (10 choices) for a
total of 72 possible characters to choose from is 6.17 bits per
character. Therefore, the per-bit entropy for the best images
in our study (Images 4 and 6) were greater than that of nu-
meric PINs and case-sensitive passwords, but smaller than
that of stronger passwords that contained more characters.
This shows the possibility for strong graphical passwords
with these images, particularly if we consider increasingly
complex images with more possible objects that could be
selected.
4. USER STUDY
While the results from using the dataset from Zhao et
al. [37] provided base information for creating a suitability
measurement for graphical password guiding images, there
were still several outstanding questions regarding usability
and memorability that could not be answered using Zhao
et al.’s dataset. Therefore, we undertook a user study (ap-
proved by our institution’s IRB prior to its start) to gather
user data to answer questions the following questions:
1. Do participants tend to choose suitable images more
or less frequently than unsuitable images, where “suit-
able” and “unsuitable” are determined by the image
saliency Stage 1 procedure described in Section 3.2?
2. Do participants select 19x19 regions evenly, or are
there certain regions that are selected more frequently
than others?
3. Do participants ﬁnd graphical passwords easy or hard
to use?
4. Are passwords created using a more suitable guiding
image more memorable than those created with a less
suitable image?
The answer to question 2 above will have an eﬀect on the
determination of practical password space, as deﬁned pre-
viously in this paper. Theoretical password space assumes
that, of the regions actually chosen, that all of these are
equally likely to be chosen. Therefore, we wished to further
bound the theoretical password space estimates given in Ta-
ble 2 by providing information on how frequently each cho-
sen space was actually used in a password, thereby giving an
idea of whether the original theoretical password space also
overestimates the diﬃculty in cracking a given password.
4.1 Study Design
We developed an Android application for creating graph-
ical passwords and ran a two-session user study designed
to answer our research questions. We recruited a total of
33 participants (6 female and 27 male, mean age = 30.18
years) via email and personal invitation. Participants were
not required to have experience with graphical passwords,
although we required them to have experience with touch-
based mobile devices. The ﬁrst session, in which participants
enrolled with their chosen password and answered demo-
graphic and post-enrollment questionnaires, lasted around
30 minutes; the second session, which was to recall their
password after one week, lasted less than 5 minutes. The
sessions took place in a quiet environment with participants
seated in a chair throughout.
4.2 Procedure & Equipment
In the ﬁrst session, participants enrolled with their chosen
password. They ﬁrst chose a guiding image from the set of
15 images used in the Zhao et al. study [37]. Each chosen
image was reviewed using the image saliency procedure in
described in Section 3.2; if the image was considered un-
suitable, the participant was prompted to select a diﬀerent
image. This process was used to ﬁnd out how frequently
participants chose the unsuitable images from the original
set of 15 images; it is our intention that the saliency proce-
dure would be used to ﬁlter out images that would not be
shown to participants, we were not interested in studying
passwords created with these unsuitable images. Once the
participant had chosen a suitable guiding image, they cre-
ated a graphical password consisting of three points. Each
of the three points could be a tap, a line or a circle anywhere
on the guiding image and they were allowed to start again
if, for some reason, they did not like their original password.
After creating the password participants played a memory
rotations game to clear their short-term visual memory, and
then were asked to recall their password. We then asked
a few questions about their experience in a semi-structured
interview. During the second session, which was approx-
imately one week after the ﬁrst session, participants were
once again asked to recall their password, but did not play
the mental rotations game nor have an interview.
Participants used an LG Nexus 7 tablet when participat-
ing in both sessions. We chose to use a tablet rather than a
smartphone due to the larger screen; as an initial study we
did not want to conﬂate the usability of the device itself with
the creation of the password itself. The tablet had loaded a
bespoke app designed for the study. Its purpose was to ﬁrst
provide an interface for the participant to create and recall
their graphical password, as well as gathering data such as
the participant’s demographic information, the guiding im-
ages chosen, and the locations and types of actions chosen
by the user to make up their graphical password. We used
this app to gather timing information for the various stages
of the study including password creation and recall.
4.3 User Study Results
We now present the results of the user study in order to
answer the questions that we raised in this section. Our
results are categorized in terms of image selection, usability,
and password memorability.
4.3.1 Image Selection
To determine the answer to the ﬁrst research question re-
garding whether participants chose suitable or unsuitable
images more frequently, we examined the choices of images
the participants selected as guiding images for their pass-
words. Out of the 15 images initially provided, participants
selected only seven images, as shown in Figure 3. Figure 4
shows the total selections by the 33 participants. Note that
the totals add up to more than 33 selections because we are
also showing the initial unsuitable choices (blue bars, im-
ages 1, 2, 5, 12, 14, 15). 11 out of 33 participants selected
an unsuitable image and were required to select another im-
age before progressing. Given that the other 22 participants
chose a suitable image initially, this shows that participants
134
in our study were more likely to choose a visually more in-
teresting image even when simpler images were available.
Figure 3: Images selected by the participants in the
user study. Background images originally from [14]
(a) Img 4
(b) Img 6
(c) Img 7
(d) Img 8
Table 7: The Kruskal-Wallis test results for login,
recall, login-retry, and recall-retry. df = 6, N = 33,
and critical value = 12.5916, alpha = 0.05
H
Signiﬁcant diﬀerence?
Login
Recall
Login-Retry
Recall-Retry
-23.3805
-24.8478
-98.7848
-100.166
No
No
No
No
Figure 5: The average time of creating (small dashed
line),
logging (solid line) in and recalling (large
dashed line) graphical passwords for participant-
selected. Images are ordered from least suitable to
more suitable.
(e) Img 9