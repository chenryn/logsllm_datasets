results further substantiate our intuition that we ﬁlter only
irrelevant information with our approach.
USENIX Association
30th USENIX Security Symposium    2315
baseline-30369121314ScalingFactorΦ(dB)5.05.56.06.57.07.58.08.5WER(%)5.906.066.506.686.726.757.627.768.055.555.836.106.136.456.687.377.747.83w/oband-passw/band-pass0500100015002000Iteration0.050.0100.0150.0200.0250.0WER(%)KaldiKaldiw/hidingΦ=0Φ=6Φ=12Table 2: Number of successful Adversarial Examples (AEs) and Segmental Signal-to-Noise (SNRseg) ratio for the exper-
iments with the adaptive attacker. We report the numbers for all computed adversarial examples against the augmented models
as well as our two baselines (with and without psychoacoustic hiding). As the success rate and SNRseg depend on the learning
rate, we combine these in the last row. For this, we select the best (i.e., least noisy) AE for each utterance among the four learning
rates. For the SNRseg, we only consider successful AEs. The higher the SNSseg, the less noise (i. e., adversarial perturbation) is
present in the audio signal. Negative values indicate that the energy of the noise exceeds the energy in the original signal.
Learning
Rate
Metric
0.05
0.01
0.5
1
Best AEs
AEs
SNR
AEs
SNR
AEs
SNR
AEs
SNR
AEs
SNR
KALDI
baseline
w/o hiding
50/50
baseline
w/ hiding
17/50
5.80/ 14.44
13.48/ 18.50
50/50
28/50
2.15/ 10.59
9.36/ 15.81
49/50
-8.54/ -0.02
23/50
1.08/ 8.63
Φ = 0
Φ = 3
Φ = 6
Φ = 9
Φ = 12
Φ = 13
Φ = 14
DOMPTEUR
31/50
6.03/10.63
38/50
3.74/ 9.53
28/50
3.61/ 8.31
34/50
0.47/ 6.41
10/50
1.21/5.53
22/50
-0.68/3.60
4/50
1.50/ 3.23
10/50
-1.31/ 1.10
48/50
44/50
42/50
20/50
0/50
—
0/50
—
1/50
0/50
—
0/50
—
1/50
-3.78/ 3.24
-6.51/ 0.11
-7.74/-1.47
-8.69/-3.35
-13.56/-13.56
-15.69/-15.69
50/50
16/50
49/50
50/50
43/50
23/50
1/50
1/50
-13.68/ -5.03
-1.81/ 4.50
-7.44/-0.29
-10.50/-3.00
-10.99/-4.34
-11.98/-6.37
-17.69/-17.69
-11.73/-11.73
50/50
5.80/ 14.44
37/50
8.71/ 18.50
50/50
3.36/10.63
50/50
0.85/ 8.31
46/50
-4.71/5.53
27/50
-7.14/ 3.23
2/50
-15.62/-13.56
2/50
-13.71/-11.73
0/50
—
0/50
—
0/50
—
0/50
—
0/50
—
(5)
(6)
AEs: Successful adversarial examples; SNR: SNRseg/SNRsegmax in dB
4.3 Adaptive Attacker
We now want to evaluate how robust DOMPTEUR is against
adversarial examples. We construct a strong attacker with
complete knowledge about the system and, in particular, our
modiﬁcations. Ultimately, this allows us to create success-
fully adversarial examples. However, as inaudible ranges are
removed, the attacker is now forced into human-perceptible
ranges, and, consequently, the attack loses much of its mali-
cious impact. We provide further support for this claim in Sec-
tion 4.4 by performing a user study to measure the perceived
quality of adversarial examples computed with this attack.
Attack. We base our evaluation on the attack by Schön-
herr et al. [17], which presented a strong attack that works
with KALDI. Recent results show that it is crucial to design
adaptive attacks as simple as possible while simultaneously
resolving any obstacles for the optimization [55]. To de-
sign such an attacker against DOMPTEUR, we need to adjust
the attack to consider the augmentations in the optimization.
Therefore, we extend the baseline attack against KALDI to
include both the band-pass and psychoacoustic ﬁlter into the
computation. This allows the attacker to compute gradients
for the entire model in a white-box fashion.
More speciﬁcally, we extend the gradient descent step
s.t. (i) the band-pass ﬁlter and (ii) the psychoacoustic ﬁlter
component back-propagates the gradient respectively.
(i) Band-Pass Filter. For the band-pass ﬁlter we remove
those frequencies that are smaller and larger than the
cut-off frequencies of the band-pass ﬁlter. This is also
applied to the gradients of the back propagated gradient
to ignore changes that will fall into ranges of the removed
signal
∇T(n,k) = 0 ∀ fmax < k < fmin.
(ii) Psychoacoustic Filter. The same principle is used for the
psychoacoustic ﬁltering, where we use the mask M to
zero out components of the signal that the network will
not process
∇S = ∇T (cid:12) M.
Experimental Setup. We evaluate the attack against dif-
ferent versions of DOMPTEUR. Each model uses a 200 −
7000Hz band-pass ﬁlter, and we vary the degrees of the psy-
choacoustic ﬁltering (Φ ∈ {0,3,6,9,12,13,14}). We com-
pare the results against two baselines to evaluate the inconspic-
uousness of the created adversarial examples. First, we run
the attack of Schönherr et al. without psychoacoustic hiding
against an unaltered version KALDI. Second, we re-enable
psychoacoustic hiding and run the original attack against
KALDI, to generate state-of-the-art inaudible adversarial ex-
amples. As a sanity check, we also ran the original attack
(i. e., with psychoacoustic hiding) against DOMPTEUR. As
expected, this attack did not create any adversarial examples
since we ﬁlter the explicit ranges the attacker wants to utilize.
As a target for all conﬁgurations, we select 50 utterances
with an approximate length of 5s from the WSJ speech corpus
test set eval92. The exact subset can be found in appendix A.
We use the same target sentence send secret ﬁnancial report
for all samples.
2316    30th USENIX Security Symposium
USENIX Association
(a) Unmodiﬁed Signal
(b) Adversarial Example against KALDI
(c) Adversarial Example against DOMPTEUR (Φ = 12)
(d) Hearing Thresholds
Figure 5: Spectrograms of adversarial examples. Figure 5a shows the unmodiﬁed signal, Figure 5b depicts the baseline with
an adversarial example computed against KALDI with psychoacoustic hiding, Figure 5c an adversarial example computed with
the adaptive attack against DOMPTEUR, and Figure 5d shows the computed hearing thresholds for the adversarial example.
These parameters are chosen such that an attacker needs to
introduce ~4.8 phones per second into the target audio, which
Schönherr et al. suggests as both effective and efﬁciently
possible [17]. Furthermore, we picked the utterances and
target sentence to be easy for an attacker in order to decouple
the inﬂuence on our analysis. Speciﬁcally, for these targets
the baseline has a very high success rate and low SNRseg
(cf. Table 2). Note that the attack is capable of introducing
arbitrary target sentences (up to a certain length). In Section
4.3.2, we further analyze the inﬂuence of the phone rate,
and in particular, the inﬂuence of the target utterance and
sentence on the SNRseg. We compute adversarial examples
for different learning rates and a maximum of 2000 iterations.
This number is sufﬁcient for the attack to converge, as shown
in Figure 4, where the WER is plotted as a function of the
number of iterations.
Results. The main results are summarized in Table 2. We
report the average SNRseg over all adversarial examples, the
best (SNRsegmax), and the number of successful adversarial
examples created.
We evaluate the attack using different learning rates (0.05,
0.10, 0.5, and 1). In our experiments, we observed that while
small learning rates generally produce less noisy adversarial
examples, they simultaneously get more stuck in local optima.
Thus, to simulate an attacker that would run an extensive
search and uses the best result we also report the intersection
of successful adversarial examples over all learning rates. If
success rate is the primary goal, we recommend a higher
learning rate.
By increasing Φ, we can successfully force the attacker
into audible ranges while also decreasing the attack’s success
rate. When using very aggressive ﬁltering (Φ = 14), we can
prevent the creation of adversarial examples completely, al-
beit with a hit on the benign WER (5.55% → 7.83%). Note,
however, that we only examined 50 samples of the test corpus,
and other samples might still produce valid adversarial ex-
amples. We see that adversarial examples for the augmented
systems are more distorted for all conﬁgurations compared
to the baselines. When using Φ ≥ 12, we force a negative
SNRseg for all learning rates. For these adversarial examples,
the noise (i. e., adversarial perturbations) energy exceeds the
energy of the signal. With respect to the baselines, the noise
energy increases on average by 21.42 dB (without psychoa-
coustic hiding) and 24.33 dB (with hiding enabled). This
means there is, on average, ten times more energy in the ad-
versarial perturbations than in the original audio signal. A
graphical illustration can be found in Figure 5, where we plot
the power spectra of different adversarial examples compared
to the original signal.
4.3.1 Non-speech Audio Content
The task of an ASR system is to transcribe audio ﬁles with
spoken content. An attacker, however, might pick other con-
tent, i.e., music or ambient noise, to obfuscate his hidden
commands. Thus, we additionally evaluated adversarial ex-
USENIX Association
30th USENIX Security Symposium    2317
12345Time(s)02468Frequency(kHz)−40−200204012345Time(s)02468Frequency(kHz)−40−200204012345Time(s)02468Frequency(kHz)−40−20020400.511.522.533.544.55Time(s)02468Frequency(kHz)−70−60−50−40−30Table 3: Number of successful Adversarial Examples
(AEs) and mean Segmental Signal-to-Noise (SNRseg) ra-
tio for non-speech audio content. For each AE, we selected
the least noisiest example, from running the attack with learn-
ing rates ({0.05,0.1,0.5,1.}). For the SNRseg we only con-
sider successful AEs and report the difference to the baseline
(KALDI). We highlight the highest loss in bold.
Birds
Music
AEs
SNRseg (dB)
Loss
AEs
SNRseg (dB)
Loss
KALDI
w/o hiding
w/ hiding
DOMPTEUR
Φ = 0
Φ = 6
Φ = 12
50/50
5/50
50/50
31/50
5/50
11.83
17.76
9.58
-2.15
-12.25
( +5.93)
( -2.25)
(-13.98)
(-24.08)
45/50
3/50
50/50
45/50
3/50
23.26
28.06
26.35
16.03
1.94
( +4.80)
( +3.09)
( -7.23)
(-21.32)
Table 4: Attack for different cut-off frequencies of the
band-pass ﬁlter. We report the number of successful adver-
sarial examples (AEs) and the mean Segmental Signal-to-
Noise (SNRseg) ratio. For the SNRseg we only consider
successful AEs.
Band-pass
AEs
SNRseg
WER
300Hz-
7000Hz
18/20
7.82
5.90 %
300Hz-
5000Hz
18/20
7.55
5.94 %
300Hz-
3000Hz
11/20