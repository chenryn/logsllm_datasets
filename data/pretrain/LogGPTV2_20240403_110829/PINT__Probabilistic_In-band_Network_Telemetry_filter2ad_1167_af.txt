Flexible Transport Framework for Accommodating Diversity. ACM SIGCOMM
CCR (2013).
14
[30] Nikhil Handigol, Brandon Heller, Vimalkumar Jeyakumar, David Mazières, and
Nick McKeown. 2014. I Know What Your Packet Did Last Hop: Using Packet
Histories to Troubleshoot Networks. In USENIX NSDI.
[31] Brandon Heller, Srini Seetharaman, Priya Mahadevan, Yiannis Yiakoumis, Puneet
Sharma, Sujata Banerjee, and Nick McKeown. 2010. ElasticTree: Saving Energy
in Data Center Networks. In USENIX NSDI.
[32] T Ho, R Koetter, M Medard, DR Karger, and M Effros. 2003. The Benefits of
Coding over Routing in a Randomized Setting. In IEEE ISIT.
[33] IEEE. [n. d.]. Standard 802.3. https://standards.ieee.org/standard/802_3-2015.
html. ([n. d.]).
[34] Nikita Ivkin, Zhuolong Yu, Vladimir Braverman, and Xin Jin. 2019. QPipe:
Quantiles Sketch Fully in the Data Plane. In ACM CoNEXT.
[35] Svante Janson. 2018. Tail Bounds for Sums of Geometric and Exponential
Variables. Statistics & Probability Letters (2018).
[36] Vimalkumar Jeyakumar, Mohammad Alizadeh, Yilong Geng, Changhoon Kim,
and David Mazières. 2014. Millions of Little Minions: Using Packets for Low
Latency Network Programming and Visibility. In ACM SIGCOMM.
[37] Xin Jin, Xiaozhou Li, Haoyu Zhang, Robert Soulé, Jeongkeun Lee, Nate Foster,
Changhoon Kim, and Ion Stoica. 2017. NetCache: Balancing Key-Value Stores
with Fast In-Network Caching. In ACM SOSP.
[38] Raj Joshi, Ting Qu, Mun Choon Chan, Ben Leong, and Boon Thau Loo. 2018.
BurstRadar: Practical Real-Time Microburst Monitoring for Datacenter Networks.
In ACM APSys.
[39] Zohar S. Karnin, Kevin J. Lang, and Edo Liberty. 2016. Optimal Quantile Ap-
proximation in Streams. In IEEE FOCS.
[40] Dina Katabi, Mark Handley, and Charlie Rohrs. 2002. Congestion Control for
High Bandwidth-Delay Product Networks. In ACM SIGCOMM.
[41] Naga Katta, Aditi Ghag, Mukesh Hira, Isaac Keslassy, Aran Bergman, Changhoon
Kim, and Jennifer Rexford. 2017. Clove: Congestion-Aware Load Balancing at
the Virtual Edge. In ACM CoNEXT.
[42] Naga Katta, Mukesh Hira, Changhoon Kim, Anirudh Sivaraman, and Jennifer
Rexford. 2016. HULA: Scalable Load Balancing Using Programmable Data
Planes. In ACM SOSR.
[43] Anurag Khandelwal, Rachit Agarwal, and Ion Stoica. 2019. Confluo: Distributed
Monitoring and Diagnosis Stack for High-Speed Networks. In USENIX NSDI.
[44] Simon Knight, Hung X Nguyen, Nickolas Falkner, Rhys Bowden, and Matthew
Roughan. 2011. The Internet Topology Zoo. IEEE JSAC (2011).
[45] Yuliang Li, Rui Miao, Changhoon Kim, and Minlan Yu. 2016. FlowRadar: A
Better NetFlow for Data Centers. In USENIX NSDI.
[46] Yuliang Li, Rui Miao, Hongqiang Harry Liu, Yan Zhuang, Fei Feng, Lingbo Tang,
Zheng Cao, Ming Zhang, Frank Kelly, Mohammad Alizadeh, and Minlan Yu.
2019. HPCC: High Precision Congestion Control. In ACM SIGCOMM.
[47] Junda Liu, Aurojit Panda, Ankit Singla, Brighten Godfrey, Michael Schapira,
and Scott Shenker. 2013. Ensuring Connectivity via Data Plane Mechanisms. In
USENIX NSDI.
[48] Gurmeet Singh Manku, Sridhar Rajagopalan, and Bruce G. Lindsay. 1998. Ap-
proximate Medians and Other Quantiles in One Pass and with Limited Memory.
In ACM SIGMOD.
[49] Andrew Mcgregor, A. Pavan, Srikanta Tirthapura, and David P. Woodruff. 2016.
Space-Efficient Estimation of Statistics Over Sub-Sampled Streams. Algorithmica
(2016).
[50] Ahmed Metwally, Divyakant Agrawal, and Amr El Abbadi. 2005. Efficient
Computation of Frequent and Top-k Elements in Data Streams. In ICDT.
[51] Rui Miao, Hongyi Zeng, Changhoon Kim, Jeongkeun Lee, and Minlan Yu. 2017.
SilkRoad: Making Stateful Layer-4 Load Balancing Fast and Cheap Using Switch-
ing ASICs. In ACM SIGCOMM.
[52] Mininet. [n. d.]. Mininet: An Instant Virtual Network on your Laptop. http:
//mininet.org/. ([n. d.]).
[53] Radhika Mittal, Vinh The Lam, Nandita Dukkipati, Emily Blem, Hassan Wassel,
Monia Ghobadi, Amin Vahdat, Yaogong Wang, David Wetherall, and David Zats.
2015. TIMELY: RTT-Based Congestion Control for the Datacenter. In ACM
SIGCOMM.
[54] Radhika Mittal, Alexander Shpiner, Aurojit Panda, Eitan Zahavi, Arvind Krishna-
murthy, Sylvia Ratnasamy, and Scott Shenker. 2018. Revisiting Network Support
for RDMA. In ACM SIGCOMM.
[55] Robert Morris. 1978. Counting Large Numbers of Events in Small Registers. In
Communications of ACM. ACM.
[56] Srinivas Narayana, Mina Tashmasbi Arashloo, Jennifer Rexford, and David Walker.
2016. Compiling Path Queries. In USENIX NSDI.
[57] Srinivas Narayana, Anirudh Sivaraman, Vikram Nathan, Prateesh Goyal, Venkat
Arun, Mohammad Alizadeh, Vimalkumar Jeyakumar, and Changhoon Kim. 2017.
Language-Directed Hardware Design for Network Performance Monitoring. In
ACM SIGCOMM.
[58] Netronome. [n. d.]. Netronome Agilio CX SmartNIC. https://www.netronome.
com/blog/in-band-network-telemetry-its-not-rocket-science/. ([n. d.]).
[59] Donald J Newman. 1960. The Double Dixie Cup Problem. The American
Mathematical Monthly (1960).
[60] Remi Oudin, Gianni Antichi, Charalampos Rotsos, Andrew W. Moore, and Steve
Uhlig. 2019. OFLOPS-SUME and the art of switch characterization. IEEE JSAC
(2019).
[61] Diana Popescu, Noa Zilberman, and Andrew W. Moore. 2017. Characterizing the
Impact of Network Latency on Cloud-based Applicationsâ ˘A ´Z Performance. In
Technical Report, Number 914, UCAM-CL-TR-914. University of Cambridge.
[62] Arjun Roy, Hongyi Zeng, Jasmeet Bagga, George Porter, and Alex C. Snoeren.
2015. Inside the Social Network’s (Datacenter) Network. In ACM SIGCOMM.
[63] Pegah Sattari. 2007. Revisiting IP Traceback as a Coupon Collectorâ ˘A ´Zs Problem.
In PhD Dissertation. University of California, Irvine.
[64] Pegah Sattari, Minas Gjoka, and Athina Markopoulou. 2010. A network coding
approach to IP traceback. In IEEE Symposium on Network Coding (NetCod).
[65] Stefan Savage, David Wetherall, Anna Karlin, and Tom Anderson. 2000. Practical
Network Support for IP Traceback. In ACM SIGCOMM.
[66] Robert Schweller, Ashish Gupta, Elliot Parsons, and Yan Chen. 2004. Reversible
Sketches for Efficient and Accurate Change Detection over Network Data Streams.
In ACM IMC.
[67] Naveen Kr. Sharma, Antoine Kaufmann, Thomas Anderson, Arvind Krishna-
murthy, Jacob Nelson, and Simon Peter. 2017. Evaluating the Power of Flexible
Packet Processing for Network Resource Allocation. In USENIX NSDI.
[68] Anirudh Sivaraman, Changhoon Kim, Ramkumar Krishnamoorthy, Advait Dixit,
and Mihai Budiu. 2015. DC.P4: Programming the Forwarding Plane of a Data-
center Switch. In ACM SOSR.
[69] Alex C. Snoeren, Craig Partridge, Luis A. Sanchez, Christine E. Jones, Fabrice
Tchakountio, Stephen T. Kent, and W. Timothy Strayer. 2001. Hash-based IP
Traceback. In ACM SIGCOMM.
[70] Dawn Xiaodong Song and Adrian Perrig. 2001. Advanced and Authenticated
Marking Schemes for IP Traceback. In IEEE INFOCOM.
[71] Philip Taffet and John Mellor-Crummey. 2019. Understanding Congestion in High
Performance Interconnection Networks Using Sampling. In ACM SC.
[72] Praveen Tammana, Rachit Agarwal, and Myungjin Lee. 2016. Simplifying Data-
center Network Debugging with Pathdump. In USENIX OSDI.
[73] Praveen Tammana, Rachit Agarwal, and Mjungjin Lee. 2018. Distributed Network
Monitoring and Debugging with SwitchPointer. In USENIX NSDI.
[74] Cheng Tan, Ze Jin, Chuanxiong Guo, Tianrong Zhang, Haitao Wu, Karl Deng,
Dongming Bi, and Dong Xiang. 2019. Netbouncer: Active Device and Link
Failure Localization in Data Center Networks. In USENIX NSDI.
[75] The P4.org Applications Working Group. [n. d.]. In-band Network Telemetry
(INT) Dataplane Specification. https://github.com/p4lang/p4-applications/blob/
master/docs/telemetry_report.pdf. ([n. d.]).
[76] The University of Washington NS-3 Consortium. [n. d.]. NS3 official website.
[77] Wolfgang Theilmann and Kurt Rothermel. 2000. Dynamic distance maps of the
https://www.nsnam.org/. ([n. d.]).
Internet. In IEEE INFOCOM.
[78] Olivier Tilmans, Tobias Bühler, Ingmar Poese, Stefano Vissicchio, and Laurent
Vanbever. 2018. Stroboscope: Declarative Network Monitoring on a Budget. In
USENIX NSDI.
[79] Muhammad Tirmazi Tirmazi, Ran Ben Basat, Jiaqi Gao, and Minlan Yu. 2020.
Cheetah: Accelerating Database Queries with Switch Pruning. In ACM SIGMOD.
[80] P Van Mieghem, Gerard Hooghiemstra, and Remco Hofstad. 2001. A scaling law
for the hopcount in Internet. In PAM.
[81] Vladimir N Vapnik and A Ya Chervonenkis. 2015. On the Uniform Convergence
of Relative Frequencies of Events to their Probabilities. Measures of Complexity
(2015).
[82] Jeffrey S Vitter. 1985. Random Sampling with a Reservoir. Transactions on
Mathematical Software (1985).
[83] Xilinx. [n. d.]. 10G/25G Ethernet Subsystem. https://www.xilinx.com/products/
intellectual-property/ef-di-25gemac.html. ([n. d.]).
[84] Xilinx. [n. d.]. UltraScale Integrated 100G Ethernet Subsystem. https://www.
xilinx.com/products/intellectual-property/cmac.html. ([n. d.]).
[85] Xilinx. [n. d.]. Xilinx to Showcase Unprecedented Programmability and Visibility.
https://www.xilinx.com/news/press/2018/barefoot-networks-and-xilinx.html. ([n.
d.]).
[86] Minlan Yu, Lavanya Jose, and Rui Miao. 2013. Software Defined Traffic Mea-
surement with OpenSketch. In USENIX NSDI.
[87] Yibo Zhu, Nanxi Kang, Jiaxin Cao, Albert Greenberg, Guohan Lu, Ratul Mahajan,
Dave Maltz, Lihua Yuan, Ming Zhang, Ben Y. Zhao, and Haitao Zheng. 2015.
Packet-Level Telemetry in Large Datacenter Networks. In ACM SIGCOMM.
15
A ANALYSIS
A.1 Dynamic per-flow Aggregation
We now survey known results that Theorem 1 and Theorem 2 are
based on.
Quantiles. Classical streaming results show that by analyzing a
uniformly selected subset of O(ε−2
) elements, one can esti-
s
mate all possible quantiles [48, 81] to within an additive error of εs .
It is also known that if one is interested in a specific quantile (e.g.,
median), a subset size of O(ε−2
s
) is enough.
log ε−1
s
In our case, for each switch si through which flow x is routed,
we get a sampled substream of Si,x where each packet carries a
value from it with probability 1/k. This is not a fixed-size subset,
but a Bernouli sample. Nevertheless, Felber and Ostrovsky show
that a Bernouli sample with the same expected size is enough [23].
Therefore, for a specific quantile (e.g., median) we need to get O(ε−2
)
s
samples for each of the k switches on the path. Using a standard
Chernoff bound argument, we have that if z = O(kε−2
) packets reach
s
the PINT sink, all hops on the path will get at least O(ε−2
) samples
s
with probability 1 − e−Ω(z/k) = 1 − e−Ω(ε−2
s ).
the quantiles, we can use a(cid:101)O(ε−1
We run separate sketch for each of the k hops, thus needing(cid:101)O(kε−1
To compress the amount of per-flow storage needed for computing
a ) space sketch such as KLL [39].
a )
per-flow storage in total. The resulting error would be ε = εs + εa,
as the sampling adds an additive error of εs and the sketching an
additive error of εa.
Frequent Values. Using a standard Chernoff bound argument, one
can use a O(ε−2
)-sized substream of Si,x , one can estimate the frac-
s
tion in which each specific value appears, up to an additive error of
εs . We can then use a heavy hitters algorithm like Space Saving [50]
to estimate the frequency of values in the sampled substream to
within an additive error of εa, using O(ε−1
a ) space. As before, to get
the correct estimations for all hops, we need a factor k multiplicative
overhead to both the number of packets and space.
A.2 Static per-flow Aggregation
Before we can analyze the algorithm (§A.2.2), we start with some
auxiliary results.
A.2.1 Auxiliary Results. The first lemma gives a bound on
how many independent coins with probability p we need to flip until
we get k successes.
LEMMA 4. Let k ∈ N and p, δ ∈ (0, 1).
Denote N = k +2 ln δ −1+
p
and let X ∼ Bin(N , p). Then
√
2k ln δ −1
Pr[X ≤ k] ≤ δ .
(cid:113) 2 ln δ −1
PROOF. Using the Chernoff bound we have that for any γ > 0:
Pr[X 
(cid:16)√
This gives
N = x2/p ≥
x2 − x
√
2 ln δ−1 + 4k
2
(cid:17)2
ln δ−1 +
√
ln δ−1 + 2k
2p
√
ln δ−1 +
=
√
√
ln δ−1 + 2k
2
.
= k + 2 ln δ−1 +
√
2k ln δ−1
.
□
p
The next theorem provide a high-probability bound on the Double
Dixie Cup problem [59]. Specifically, consider trying to collect at
least Z copies from each of k coupons, where at each stage you get
a random coupon. The following bounds the number of samples you
need.
N = k ·(cid:16)
Z − 1 + ln(k/δ) +(cid:112)(Z − 1 + ln(k/δ))2 − (Z − 1)2/4
THEOREM 5. After seeing
(cid:17)
samples, our algorithm has at least Z copies of each of the k
coupons.
PROOF. Therefore, the number of copies of the i’th coupon isa