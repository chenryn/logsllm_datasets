Foundation and Practice. Springer, 2010.
[24] U. R¨uhrmair, S. Devadas, F. Koushanfar: Security based on
Physical Unclonability and Disorder. In: M. Tehranipoor and
C. Wang (Editors): Introduction to Hardware Security and
Trust. Springer, 2011
[25] U. R¨uhrmair, M. van Dijk: Practical Security Analysis of
PUF-based Two-Player Protocols. Cryptographic Hardware
and Embedded Systems (CHES 2012), Springer, 2012.
[26] U. R¨uhrmair, C. Jaeger, M. Algasinger: An Attack on PUF-
based Session Key Exchange and a Hardware-based Counter-
measure: Erasable PUFs. Financial Cryptography (FC 2011),
Springer, 2011.
[27] U. R¨uhrmair, C. Jaeger, M. Bator, M. Stutzmann, P. Lugli,
and G. Csaba: Cryptographic Applications of High-Capacity
Crossbar Memories. IEEE Transactions on Nanotechnology,
2011.
[28] U. R¨uhrmair, F. Sehnke, J. S¨olter, G. Dror, S. Devadas,
J. Schmidhuber: Modeling Attacks on Physical Unclonable
Functions. ACM Conference on Computer and Communica-
tions Security (CCS’10), 2010.
[29] U. R¨uhrmair, J. S¨olter, F. Sehnke: On the Foundations of
Physical Unclonable Functions. Cryptology ePrint Archive,
Report 2009/277, 2009.
[30] G. E. Suh, S. Devadas: Physical Unclonable Functions for
Device Authentication and Secret Key Generation. DAC 2007:
9-14
[31] P. Tuyls, G. J. Schrijen, B. Skoric, J. van Geloven, N.
Verhaegh, R. Wolters Read-Proof Hardware from Protective
Coatings. CHES 2006, pp. 369-383, 2006.
[17] J.-W. Lee, D. Lim, B. Gassend, G. E. Suh, M. van Dijk, and
S. Devadas. A technique to build a secret key in integrated
circuits with identiﬁcation and authentication applications. In
Proceedings of the IEEE VLSI Circuits Symposium, 2004.
[32] P. Tuyls, B. Skoric: Strong Authentication with Physical
Unclonable Functions. In: Security, Privacy and Trust
in
Modern Data Management, M. Petkovic, W. Jonker (Eds.),
Springer, 2007.
298
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:54:17 UTC from IEEE Xplore.  Restrictions apply. 
A. Strong PUFs
APPENDIX
Different subtypes of PUFs exist (see [28], [29], [24]),
each with their own security properties and applications.
Strong PUFs are an important and central of these subtypes.
They have also been called Physical Random Functions due
to their similarity with the more classical Pseudo-Random
Functions [10]. A Strong PUF is a PUF with the following
features (for formal deﬁnitions see [29], [23], [1]):
1) Public CRP interface: Its challenge-response mech-
anism is publicly accessible. Everyone who holds a
Strong PUF can apply challenges to it and read out
the corresponding responses.
2) Large CRP set: It has a very large number of chal-
lenges, ideally exponentially many in some system
parameter, such as the system’s physical size or the
challenge length. Together with the ﬁnite read-out
speed of the Strong PUF, the large number of chal-
lenges makes it impossible to read out all CRPs in a
limited time, such as days or even weeks.
3) Unpredictability: The CRP-behavior of Strong PUFs
is so complex that it cannot be modeled or machine
learned or otherwise predicted. An adversary who
knows a large subset of all CRPs nevertheless cannot
build a model that allows him to correctly predict the
response to a randomly chosen, previously unknown
challenge with high probability.
The above features imply that only the very party who
currently holds possession of a Strong PUF can determine
the correct response to a randomly chosen challenge with
high probability, even if the PUF has been in the possession
of other parties before. This observation can be exploited
cryptographically in various ways, as we will see later in this
paper. Typical examples of Strong PUFs include Pappu’s op-
tical PUF [19], [20], the Arbiter PUF [9], [30], the Crossbar
PUF [27], and the Bistable Ring PUF [4]. Modeling Attacks
on Strong PUFs have been reported, among other places, in
[28]. The authors show how to attack Arbiter PUFs and
variants up to a substantial level of size and complexity, but
at the same time indicate that a sufﬁciently large number
(≥ 8) of XORed Arbiter PUFs of sufﬁcient bitlength (≥ 64)
is resilient against current modeling strategies.
One advantage of Strong PUFs over other types of PUFs
(such as Weak PUFs/POKs, see again [28]) is that their
responses do not need to remain secret, and do not require
protection inside the embedding hardware.
B. OT-Protocol of Brzuska et al.
The OT protocol of Brzuska et al. [1] implements one-out-
of-two string oblivious transfer. It is assumed that in each
subsession the sender Pi initially holds two (fresh) bitstrings
s0, s1 ∈ {0, 1}λ, and that the receiver Pj holds a (fresh)
choice bit b.
299
Brzuska et al. generally assume in their treatment that
after error correction and the application of fuzzy extractors,
a PUF can be modeled as a function PUF :{0, 1}λ →
{0, 1}rg(λ). We often use this model throughout this paper,
too. In the upcoming protocol, they furthermore assume
that rg(λ) = λ, i.e., that the PUF implements a function
PUF :{0, 1}λ → {0, 1}λ (compare [1], [2]).
Protocol 1:
SIMPLIFIED DESCRIPTION)
PUF-BASED OT BY BRZUSKA ET AL. ([1],
External Parameters: The protocol has a number of
external parameters, including the security parameter λ, the
session identiﬁer sid, a number N that speciﬁes how many
subsessions are allowed, and a pre-speciﬁed PUF-family P,
from which all PUFs which are used in the protocol must
be drawn.
Initialization Phase: Execute once with ﬁxed session iden-
tiﬁer sid:
1) The receiver holds a PUF which has been drawn from
the family P.
2) The receiver measures l
randomly chosen CRPs
c1, r1, . . . , cl, rl from the PUF, and puts them in a list
L := (c1, r1, . . . , cl, rl).
3) The receiver sends the PUF to the sender.
and the receiver’s input is a bit b ∈ {0, 1}.
random.
{0, 1}λ and sends x0, x1 to the receiver.
Subsession Phase: Repeat at most N times with fresh
subsession identiﬁer ssid:
1) The sender’s input are two strings s0, s1 ∈ {0, 1}λ,
2) The receiver chooses a CRP (c, r) from the list L at
3) The sender chooses two random bitstrings x0, x1 ∈
4) The receiver returns the value v := c⊕xb to the sender.
5) The sender measures the responses r0 and r1 of the
PUF that correspond to the challenges c0 := v ⊕ x0
and c1 := v ⊕ x1.
6) The sender sets the values S0 := s0 ⊕ r0 and S1 :=
s1 ⊕ r1, and sends S0, S1 to the receiver.
7) The receiver recovers the string sb that depends on his
choice bit b as sb = Sb ⊕ r. He erases the pair (c, r)
from the list L.
Comments: The protocol implicitly assumes that the
sender and receiver can interrogate the PUF whenever they
have access to it, i.e., that the PUF’s challenge-response
interface is publicly accessible and not protected. This im-
plies that the employed PUF must possess a large number of
CRPs. Using a PUF with just a few challenges does not make
sense: The receiver could then create a full look-up table for
all CRPs of such a PUF before sending it away in Step 3 of
the Initialization Phase. This would subsequently allow him
to recover both strings s0 and s1 in Step 6 of the protocol
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:54:17 UTC from IEEE Xplore.  Restrictions apply. 
subsession, as he could obtain r0 and r1 from his look-up
table. Similar observations hold for the upcoming protocols:
Indeed, all protocols discussed in this paper do require PUFs
with a large number of challenges, a publicly accessible
challenge-response interfaces, and an unpredictable CRP-
behavior (or, in other words, Strong PUFs).
Furthermore, please note that no physical transfer of the
PUF and no adversarial access is envisaged during the
subsessions of the protocol, as already indicated in Section
II-B.
C. KE-Protocol of Brzuska et al.
Together with CRP-based identiﬁcation, key exchange
(KE) was among the ﬁrst security applications suggested
for PUFs. Pappu et al. were the ﬁrst
to mention “key
establishment” as a potential PUF application [20], and van
Dijk gives the ﬁrst concrete protocol in a patent writing
[5]. The KE protocol of Brzuska et al. [1] picks up these
known approaches. We again describe it in a simpliﬁed form,
partly without the UC-notation and merely with a high-level
description of error correction. The key exchange is carried
out between two parties, let us call them Alice and Bob.
Protocol 2:
FIED DESCRIPTION)
PUF-BASED KEY EXCHANGE ([1], SIMPLI-
External Parameters: The protocol has a number of
external parameters, including the security parameter λ, the
session identiﬁer sid, a number N that speciﬁes how many
subsessions are allowed, and a pre-speciﬁed PUF-family P,
from which all PUFs which are used in the protocol must
be drawn.
Initialization Phase: Execute once with ﬁxed session iden-
tiﬁer sid:
1) Alice holds a PUF which has been drawn from the
family P.
2) Repeat N times:
• Choose a challenge c at random, measure the
response r of the PUF, create helper data d,
and extract a secret st from r. Add the tuple
(c, r, st, d) to the list L.
3) Alice sends the PUF to Bob.
Subsession Phase: Repeat at most N times with fresh
subsession identiﬁer ssid:
1) Alice picks a tuple (c, r, st, d) from the list L at
random.
channel.
3) Bob measures a (possibly noisy) response r
2) Alice sends (c, d) to Bob over the authenticated binary
(cid:3) to the
challenge c. He uses the helper data d to recover the
same secret st as the Server.
the tuple (c, r, st, d) from the list L.
4) Both Alice and Bob set their key K = st. Alice erases
Comments: For the same reasons as discussed in
Section B, the above KE protocols assumes (and indeed
requires) a Strong PUF. If the PUF has only got a small CRP-
set, then the adversary can fully read out all CRPs when
the PUF is in transition from Alice to Bob. Furthermore,
no adversarial access is foreseen or allowed between the
different subsessions of the protocol.
D. An Unconditional BC-Protocol of Ostrovsky et al. in the
Malicious/Bad PUF Model
Ostrovsky et al. [18] give an unconditional BC-protocol
(i.e., one that does not use computational assumptions) in
Fig. 6 of their paper. The protocol purportedly is secure in
the malicious PUF model (however, we show an attack on
the protocol in this very model in Section III-E). We provide
the protocol below.
PUF-BASED BC IN THE MALICIOUS PUF
Protocol 3:
MODEL BY OSTROVSKY ET AL. [18]
Committer’s Input: Bit b ∈ {0, 1}.
Commitment Phase
1) Cuncon ⇒ Runcon :
to
and
FPUF
response
sid, q, a).
Committer
receives
Committer
sends
(initPUF, normal, sid, Cuncon)
and
(initializedPUF, sid). Committer
obtains
uniformly selects a query q ∈ {0, 1}n and sends
(evalPUF, sid, Cuncon, q)
response
(responsePUF,
obtains
(st, p) ← FuzGen(a), and sends p to Runcon.
Committer sends (handoverPUF, sid, Cuncon, Runcon)
to FPUF.
(cid:3) from the com-
mitter and (handoverPUF, sid, Cuncon) from FPUF. It
uniformly chooses r ∈ {0, 1}l and sends it to the
committer.
3) Cuncon ⇒ Runcon : If b = 0, committer sends y = st
to the receiver. Else it sends y = r ⊕ st.
2) Cuncon ⇐ Runcon : Receiver receives p
Decommitment Phase
1) Cuncon ⇒ Runcon : Committer sends (b, q) to receiver.
2) Cuncon ⇐ Runcon : Receiver receives (b
(cid:3)) from the
(cid:3)
(cid:3)) to FPUF
(cid:3)). It then computes
(cid:3) = y.
(cid:3)). If b = 0, it checks if st
(cid:3) = y ⊕ r. If the check passes, it
, q
committer and sends (evalPUF, sid, Runcon, q
and obtains (responsePUF, sid,q
(cid:3) ← FuzRep(a
, p
st
Else, it checks if st
accepts, else it rejects.
, a
(cid:3)
(cid:3)
Comments: We again stress that the above protocol
requires a Strong PUF: If the PUF has only a small set
of CRPs, the Committer can read out all CRPs and sub-
sequently may open his commitment in both ways without
being caught.
300
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:54:17 UTC from IEEE Xplore.  Restrictions apply.