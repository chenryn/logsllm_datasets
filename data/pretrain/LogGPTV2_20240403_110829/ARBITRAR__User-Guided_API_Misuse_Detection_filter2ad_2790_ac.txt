to learn from expert feedback and
accurately identify a suspicious data point that will be evaluated
by the human expert in each round. Finally, we show that MD-
KDE is highly efﬁcient as it can be updated in linear time per
round.
1) The Interactive Anomaly Detection (IAD) Problem:
Traditional Anomaly Detection (AD) [29], [10] methods operate
in a batch mode, i.e., a machine learning model trained on
a dataset with zero or only a few labeled data points is
responsible for predicting a set of anomaly candidates. This
setting is particularly challenging due to the sparsity of positive
signals—conﬁrmed misuses of the target API in our case—and
therefore these methods usually rely on additional distributional
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:25:07 UTC from IEEE Xplore.  Restrictions apply. 
1404
TABLE II: Features Used in ARBITRAR and Their Deﬁnitions in the Datalog Language.
Feature
ret.checked
ret.assumed zero
ret.assumed not zero
ret.stored
ret.derefed
ret.returned
ret.indirectly returned
ret.used in binary
ret.used in call
arg.is constantx
arg.is argx
arg.is localx
arg.is globalx
arg.pre.checkedx
arg.pre.assumed zerox
arg.pre.assumed not zerox
arg.pre.used in callx
arg.post.checkedx
arg.post.derefedx
arg.post.returnedx
arg.post.used in callx
invoked(g,r)
invoked multi(g,r)
share arg with target(g,r)
target uses g ret(g,r)
g uses target ret(g,r)
g ret checked(g,r)
g ret assumed zero(g,r)
g ret assumed not zero(g,r)
Rule
Return value features
checked( , ˆer)
assumed zero( , ˆer)
assumed not zero( , ˆer)
STORE( ,
, ˆer)
derefed( , ˆer)
RET(n, ˆer)
STORE( , ˆer, e1), belongs to ptr(e1, e2), RET(n, e2)
used in binary( , ˆer)
CALL( ,
, ¯ea), ˆer ∈ ¯ea
,
Argument features
,
¯ˆea[x] = c
¯ˆea[x] = αarg
¯ˆea[x] = αlocal
¯ˆea[x] = αglobal
i  k, checked(i, ¯ˆea[x])
i > k, derefed(i, ¯ˆea[x])
i > k, RET(n, ¯ˆea[x])
i > k, CALL(i,
i ∈ r, CALL(i,
, g, )
i ∈ r, j ∈ r, i (cid:54)= j, CALL(i,
, g, ¯ea), ¯ea ∩ ¯ˆea (cid:54)= ∅
i ∈ r, CALL(i,
i ∈ r, CALL(i, er, g, ), er ∈ ¯ˆea
i ∈ r, CALL(i,
, g, ¯ea), ˆer ∈ ¯ea
i ∈ r, CALL(i, er, g, ), checked(i, er)
i ∈ r, CALL(i, er, g, ), assumed zero(i, er)
i ∈ r, CALL(i, er, g, ), assumed not zero(i, er)
, ¯ea), ¯ˆea[x] ∈ ¯ea
, g, ), CALL(j,
,
, g, )
Causality relation features
Control ﬂow features
cf.has loop
cf.target inside loop
BEG LOOP( )
num beg loop before k(a),
num end loop before k(b), a − b > 0
Description
Return value is checked
Return value is assumed to be zero
Return value is assumed to be non-zero
Return value is stored to an existing location
Return value is dereferenced
Return value is returned to the outer context
Return value is stored into another pointer and returned
Return value has been used in a binary operation
Return value has been used as an argument of a call
x-th argument is a constant
x-th argument is a trace argument
x-th argument is a local variable
x-th argument is a global variable
x-th argument is checked before target call
x-th argument is assumed to be zero before target call
x-th argument is assumed to be non-zero before target call
x-th argument is used in a call before target call
x-th argument is checked after target call
x-th argument is dereferenced after target call
x-th argument is returned to outer context
x-th argument is used in a call after target call
Function g is called during scope r
Function g is invoked multiple times during scope r
Function g is called with at least one common argument as target call
The result of a call to g is used as an argument in the target call
The result of target call is used as an argument in a call to g
The result of a call to g is checked
The result of a call to g is assumed to be zero
The result of a call to g is assumed to be non-zero
The trace contains a loop
The target call is inside a loop
, e2, ), e1 = e or e2 = e.
checked(i, e) :− ASSUME(i, e1,
assumed zero(i, e) :− ASSUME(i, e, =, 0, true) or
ASSUME(i, e, (cid:54)=, 0, false).
assumed not zero(i, e) :− ASSUME(i, e, =, 0, false) or
ASSUME(i, e, (cid:54)=, 0, true) or
ASSUME(i, e, >, 0, true) or
ASSUME(i, e,  j.
num beg loop in range(i, j, c) :− i ≤ j, ENTER LOOP(i), c(cid:48) = c + 1,
num beg loop in range(i, j, c) :− i ≤ j,
num end loop in range(i, j, 0) :− i > j.
num end loop in range(i, j, c) :− i ≤ j, EXIT LOOP(i), c(cid:48) = c + 1,
num end loop in range(i, j, c) :− i ≤ j,
num beg loop in range(i + 1, j).
num end loop in range(i + 1, j, c(cid:48)).
num beg loop in range(i + 1, j, c(cid:48)).
num beg loop before k(c) :− num beg loop in range(0, k − 1, c).
num end loop before k(c) :− num end loop in range(0, k − 1, c).
num end loop in range(i + 1, j).
Fig. 4: Datalog rules deﬁning relations commonly used in
deﬁning features (Table II). The ‘:−’ operator is implication
(from right to left), ‘ ’ is projection, and comma is conjunction.
assumptions on anomalies and/or normal data points, such
as the “one-class” assumption [53], [57]. However, such an
assumption is unrealistic in our case, as it amounts to assuming
a single valid usage pattern of every target API. To address
this issue, we provide more signals to the machine learning
algorithm by allowing it to communicate with a human expert in
an iterative fashion. We deﬁne the interactive anomaly detection
problem below.
Deﬁnition 1 (Interactive Anomaly Detection): Given a dataset
X = {x1, x2,··· , xn} of n data points, and an expert oracle
f : X (cid:55)→ {0, 1} that maps a data point from X to 0 (normal) or
1 (anomaly), the learner can query f using one data point x(i)
in each round, for a total number of T rounds. The objective
of the Interactive Anomaly Detection (IAD) problem is to
maximize the total number of identiﬁed anomalies, i.e.,
{x(i)}T
i=1, s.t. x(i)(cid:54)=x(j) ∀i(cid:54)=j
max
I[f (x(i)) = 1],
(1)
where I[·] is the indicator function.
In the setting of API misuse detection, the data points are
the trace encodings generated by the method described in
Section III-B. The goal is to identify as many anomalous
traces as possible by querying a human expert for up to T
rounds. In each round, the learner selects one unlabeled data
point from the dataset and presents it to the human expert, who
provides binary (anomaly or not) feedback to the algorithm.
The overall performance is measured by the percentage of true
anomalies among the T queries, i.e., the overall precision.
Remark. Our problem formulation is different from another
existing formulation of AD under the interactive mode [22],
T(cid:88)
i=1
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:25:07 UTC from IEEE Xplore.  Restrictions apply. 
1405
[1], [21]. Instead of optimizing the precision within the T
queries, their setting focuses on obtaining a better classiﬁer,
which is measured by the ﬁnal prediction AUC scores on the
entire dataset. This objective is a reasonable choice for some
AD applications where false positives are tolerable. However
in the setting of API misuse detection, false positives are not
tolerable and every anomalous case needs to be conﬁrmed by
a developer. Therefore these extra queries should be counted
as part of the querying budget in our IAD formulation.
2) A Kernel Density Estimation based Active Learning
Algorithm: We present a novel kernel density estimation (KDE)
based active learning algorithm for the IAD problem. The
proposed algorithm follows the active learning framework in
Algorithm 2. In each round, given the current labeled dataset,
the learner ﬁrst computes the ranking score for each unlabeled
data point using the acquisition function, and then asks the
expert to evaluate the unlabeled data point with the maximum
score. Intuitively, such a data point corresponds to the trace
that the algorithm believes is the most likely to be a misuse of
the target API, based on the labels provided by the developer
thus far.
points L := ∅
f : X (cid:55)→ Y, acquisition function g.
Algorithm 2: The active learning algorithm framework.
Input: Data points X = {x1, x2,··· , xn}, expert
1 Initialize unlabeled data points U := X , labeled data
2 for t ← 1 to T do
3
4
5
6
7 return L
Select x(i) ← argmaxx∈U g(x,L)
Evaluate y(i) ← f (x(i))
Update U ← U \ x(i)
Update L ← L ∪ {(x(i), y(i))}
The acquisition function g is a scoring function for every
unlabeled data point in U using the labeled dataset L. Our
acquisition function is designed to choose the unlabeled data
point which achieves the maximum discrepancy between the
kernel density estimator of the positive (anomalous) and
negative (normal) data. More formally, with the labeled dataset
L represented using the positive and negative data points P
and N , the acquisition function is deﬁned as follows,
g(x,L = (P,N )) = Eu∼P [K(u, x)] − Ev∼N [K(v, x)], (2)
where
K(u, v) =
√
1
2π)d
(h
e− (cid:107)u−v(cid:107)2
2h
is a standard Gaussian kernel with bandwidth h. Here d is
the dimension of the feature space, i.e., u, v ∈ Rd. h is
a scalar hyperparameter selected by the leave-one-out cross
validation [59]. The expectation in Eq (2) can be estimated
using labeled data points in the following form,
g(x, (P,N )) =
1
|P|
K(u, x) − 1
|N|
K(v, x),
(3)
(cid:88)
u∈P
(cid:88)
v∈N
which is used to derive an efﬁcient update rule in Section III-C3.
We call
the active learning algorithm using the above
acquisition function as the Maximum Discrepancy Kernel
Density Estimation (MD-KDE) algorithm. Intuitively, MD-
KDE behaves as follows, in an explore-then-exploit fashion:
1) At the beginning, when there is no positive data point
detected, the algorithm simply chooses one unlabeled data
point which is the farthest away from existing labeled
(negative) data points. This can be viewed as the exploration
stage, or model variance minimization [13] in classical
active learning. This strategy of diversifying the samples
accelerates the process of ﬁnding the ﬁrst anomalous case.
2) When there are both positive and negative data points, the
algorithm favors a data point close to existing positive points
but far from existing negative points. In the presence of
multiple data points that satisfy these criteria, we pick a
random point from these data points. This can be viewed
as the exploitation stage with a KDE classiﬁer. Since
anomalous cases of the same kind tend to be close to
each other in the feature space, we ﬁnd that many similar
anomalous cases can be detected using this strategy.
Figure 5 illustrates an iteration in MD-KDE, including the
selection of the querying sample, and two possible evaluation
outcomes. We show the changes in the scoring landscape
(computed by the acquisition function in Eq (2)) after a
querying sample is evaluated. If the queried point is positive, it
will reinforce the current estimation of the acquisition scores.
Otherwise, the landscape will change abruptly to reﬂect the
new evidence.
MD-KDE is a novel algorithm designed for the IAD problem
setting where existing active learning-based anomaly detection
algorithms [22], [21] fail to perform well. These methods
optimize an one-class SVM [53], [57] like objective to classify
data points into positive and negative classes. In each round
of active learning, they query a data point on the decision
boundary to improve the classiﬁcation model but do not aim
for discovering anomalous cases during the interaction with
an expert. We highlight another key difference next.
3) Efﬁcient Update for MD-KDE: A major advantage of
MD-KDE over existing active learning-based anomaly detection
methods is its efﬁcient update between rounds of queries.
Instead of training a new machine learning model using the
updated labeled dataset per round, which usually takes an hour
to several days depending on the size of the dataset and the
choice of the model, MD-KDE enjoys exact round-to-round
update using linear time proportional to the number of current
unlabeled samples. Even in large databases with more than
50,000 traces, the update takes only a few seconds. This allows
an expert to stay engaged with our system throughout an
interaction session.
Suppose we already computed the acquisition value for an
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:25:07 UTC from IEEE Xplore.  Restrictions apply. 
1406
Fig. 5: The change of the (acquisition function) scoring landscape in one round of MD-KDE. We represent the positive, negative,
and the selected unlabeled data point(s) using yellow + signs, magenta × signs, and a green dot, respectively. Left: an unlabeled
data point is selected; Middle: the updated landscape when the point is evaluated to be positive; Right: the updated landscape
when the point is evaluated to be negative.
unlabeled x at time t using Eq (3):
g(x, (Pt,Nt)) =
=
K(u, x) − 1
|Nt|
u∈Pt
1
|Pt|
|Pt| SPt(x) − 1
1
|Nt| SNt(x),
(cid:88)
(cid:88)
v∈Nt
K(v, x)
where we use short-hand notations SPt(x) and SNt(x) to
denote the sums. Then at the next iteration, we can compute
g(x, (Pt+1,Nt+1)) in O(1) using,
g(x, (Pt+1,Nt+1)) =
(cid:40) 1|Pt|+1 (SPt(x) + K(x(i), x)) − 1|Nt| SNt (x),
|Nt|+1 (SNt(x) + K(x(i), x)),
if x(i) ∈ Pt+1
if x(i) ∈ Nt+1
1|Pt| SPt(x) − 1
Notice that after each round, a data point is added into either
P or N . For each unlabeled x, the mean of K(u, x) for u ∈ P
(or the mean of K(v, x) for v ∈ N ) can be updated in O(1).
Therefore the total update time is O(|U|), where U is the set of
the current unlabeled data points. The update operation could
be processed in batch to further optimize the constant factor
in the time complexity.
IV. IMPLEMENTATION
We implemented ARBITRAR in 3.5K and 2K Lines of Code
(LoC) of Rust and Python respectively. The trace generation
(under-constrained symbolic execution) and trace encoder
are implemented using Rust with 3.5K LoC. Our symbolic
execution is multi-threaded in order to achieve the performance
need for executing on large and complex code bases. Our
active learning framework, user interaction system and analysis
database system are implemented in Python.
A. Analysis setup
In our experience, making a program analysis ready, i.e.,
fetching the sources, conﬁguring and converting it to LLVM
bitcode—which is often assumed to be easy—hinders the usage
of many tools by its end-users.