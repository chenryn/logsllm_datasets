title:Integration and evaluation of Multi-Instance-Precommit schemes within
postgreSQL
author:Paolo Romano and
Francesco Quaglia
Integration and Evaluation of Multi-Instance-Precommit Schemes
within PostgreSQL
Paolo Romano and Francesco Quaglia
DIS, Sapienza Universit(cid:30)a di Roma
Abstract
Multi-Instance-Precommit (MIP) has been recently pre-
sented as an innovative transaction management scheme
in support of reliability for Atomic Transactions in multi-
tier (e.g. Web-based) systems. With this scheme, fail-
over of a previously activated transaction can be supported
via simple retry logics, which do not require knowledge
about whether, and on which sites, the original transac-
tion was precommitted. Mutual deadlock between the orig-
inal and the retried transaction are prevented via MIP fa-
cilities, which also support reconciliation mechanisms for
at-most-once transaction execution semantic. In this arti-
cle we present an extension of the open source PostgreSQL
database system in order to support MIP. The extension
is based on the exploitation of PostgreSQL native multi-
version concurrency control scheme. We also present an
experimental evaluation based on the TPC-W benchmark,
aimed at quantifying the relative overhead of MIP facil-
ities on transaction execution latency, system throughput
and storage usage.
1. Introduction
The design and development of supports for reliable
transaction management
in (Web-based) multi-tier dis-
tributed systems is a fundamental issue for most modern ap-
plications, such as e-business. One complex representative
case is when middle-tier servers drive the execution of dis-
tributed transactions involving multiple (autonomous) back-
end sites, and one cannot rely on application level compen-
sation mechanisms to guarantee atomicity despite failures.
In this scenario, the employment of an Atomic Commit Pro-
tocol (ACP) is mandatory.
The mainstream ACP is the so called Two-Phase-
Commit (2PC), which is based on the precommit state as the
expression of transactional sites endorsement for successful
execution of local data manipulation statements. For this
protocol, several frameworks have been proposed in order
to achieve integration with the multi-tier system organiza-
tion, among which we can mention classical Transaction
Processing Monitors [1] and the recent e-Transaction speci-
(cid:2)cation [2]. The base idea in all these solutions is to achieve
reliability via mutual fail-over capabilities across middle-
tier server replicas or incarnations. This is done via diffu-
sion of precommit/abort logs across the middle-tier (before
any commit/abort message is sent out) so to prevent that
different server replicas take different decisions on a same
distributed transaction, possibly leading to a violation of the
atomicity property. From a formal perspective, this means
reaching consensus on the outcome of the distributed trans-
action across the middle-tier.
On the other hand, the cost for achieving consensus can
become unaffordable in case of large scale geographical dis-
tribution of middle-tier servers, like in Application Deliv-
ery Network (ADN) infrastructures [9], namely representa-
tive expressions of the edge computing paradigm in service
oriented applications. In order to cope with this issue, we
have recently presented an innovative (application transpar-
ent) management model for distributed atomic transactions,
which is referred to as Multi-Instance-Precommit (MIP) [6],
which has been used as the building block for the con-
struction of multi-tier reliability protocols framed by the e-
Transaction speci(cid:2)cation.
With MIP, each replicated middle-tier server instance
can retry the execution of a given transaction (e.g. upon
client re-transmission), without explicit knowledge (and
therefore consensus) about the state of a previously acti-
vated instance (if any) of that same transaction. The two
transaction instances do not incur mutual deadlock and are
reconciliated at commit time just thanks to the capabilities
offered by MIP, hence obeying at-most-once semantic. We
note that the avoidance of explicit consensus on transac-
tion outcome across middle-tier servers means avoiding the
need for accurate failure detection capabilities across those
same servers. This further strengthens the relevance of the
MIP model. Concerning the design and formal correctness
of multi-tier reliability protocols (i.e. e-Transaction proto-
cols) based on the MIP model, we remind the readers to [6].
Instead, in this article we focus on the integration of MIP
within PostgreSQL (version 8.1.3).
We describe in a methodic manner the issues associ-
ated with the integration of MIP within PostgreSQL, includ-
ing non-intrusive modi(cid:2)cations to existing database kernel
subsystems (such as concurrency control). This descrip-
tion can be also used as a reference for possible integration
of MIP within the kernel of other database systems, espe-
cially those oriented to multi-version concurrency control
(natively adopted by PosgreSQL). Finally, we present an
experimental study relying on the TPC-W benchmark [8],
aimed at evaluating the overhead associated with MIP facil-
ities, in terms of transaction latency and system throughput,
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 20081-4244-2398-9/08/$20.00 ©2008 IEEE404DSN 2008: Romano & Quagliaas well as in terms of extra storage for tuples metadata.
2. The MIP Model
There are two main aspects that differentiate the MIP
model compared to traditional (distributed) transaction
management schemes, one is related to transaction demar-
cation and concurrency control, the other one is related to
precommit/commit logs.
Concerning the (cid:2)rst aspect, the basic idea is to allow
a transactional data manipulation request, to be (concur-
rently) activated, and effectively processed, multiple times.
This would permit fail-over of a previously activated trans-
action instance without its preventive extermination. Over-
all, the following features characterize demarcation and
concurrency control in MIP:
Transaction Demarcation. A MIP transaction is univocally
associated with a MIP-TID, which is formed by the cou-
ple , where XID is a base identi(cid:2)er,
and XIN ST is the so called instance identi(cid:2)er. Multiple
MIP transactions can have the same XID, but they cannot
have the same  pair. We say that all
the transactions associated with the same XID, but with
different XIN ST values, form a family of sibling transac-
tions.
Concurrency Control. In case a MIP transaction T requires
(read/write) access to some data item d previously accessed
(written/read) by a not yet committed (e.g. precommitted)
transaction T 0, T is granted access to the pre-image of d
with respect to the execution of T 0 if (A) T and T 0 are both
MIP transactions and (B) they share the same XID (i.e.
they are sibling transactions). Hence, any update performed
by a not yet committed MIP transaction T 0 is not visible
to any sibling transaction T . Operatively, this means that
a newly activated sibling transaction does not get blocked
waiting for commit/abort of a previously activated one, due
to data con(cid:3)icts. This building block allows effective fail-
over (with no need for accurate failure detection and ex-
plicit extermination protocols of the original pending trans-
action), to be activated in case whichever anomaly (also
including performance failures) occurs along the chain of
multi-tier components originally involved in the processing
of the transactional data manipulation request.
Concerning the other aspect of differentiation with standard
transactional schemes, namely the management of precom-
mit/commit logs, the MIP model relies on a data struc-
ture called MIP-Table (MIPT). The objective of this data
structure is to provide supports for both (A) reconcilia-
tion of sibling transactions (hence allowing at-most-once
semantic) and (B) retrievability of sibling transactions (non-
deterministic) results, in order to select the one associ-
ated with the data manipulation pattern representative of
reconciliation. Overall, the database is required to main-
tain a MIPT for each family of sibling transactions associ-
ated with a given XID. In the following, we will denote
with MIPTx the table keeping track of transactions with
XID = x. The y-th entry of MIPTx stores the follow-
ing information related to the transaction with XID = x
and XIN ST = y:
(1) state: a value, in the domain
fnull; prepared; abortg, re(cid:3)ecting the current transaction
state (null is the default initialization value); (2) result: the
(non-deterministic) output produced by the execution of the
transaction. Each MIPTx also keeps a special (cid:2)eld, namely
MIPTx:req which records the (client) request content that
gave rise to sibling transactions with XID = x. The lat-
ter information is useful in order to autonomously allow the
database server to trigger fail-over actions (e.g. via a stub)
through a request push mechanism towards the middle-tier,
which can simulate the client retransmission (see [6]), and
whose aim is to promptly yield to transaction commit/abort
so to improve data availability (by timely releasing any lock
held by a precommitted transaction). The MIPT is accessi-
ble via proper prepare/commit APIs, which are quite sim-
ilar to standard xa prepare/xa decide services pre-
scribed by the XA speci(cid:2)cation [7]. Via these APIs, the
middle-tier server coordinating the execution of whichever
sibling transaction can (i) prepare that speci(cid:2)c instance, (ii)
retrieve the state (and result) of all the sibling transactions
currently registered within the MIPT, and (iii) converge to a
univocally identi(cid:2)ed data manipulation path, representative
of reconciliation, associated with the minimum XIN ST
value identifying a distributed transaction instance success-
fully prepared at all the involved sites.
3. Integrating MIP within PostgreSQL
3.1. Transaction Demarcation
PostgreSQL automatically and transparently assigns a
unique scalar identi(cid:2)er TID to a transaction when it starts.
Many components of PostgreSQL use TIDs in different
ways, hence changing the way they are generated and as-
sociated with transactions, in order to support MIP demar-
cation, would not represent a viable option. To address this
issue, we associate each MIP transaction with two identi-
(cid:2)ers, namely, the original TID selected by PostgreSQL and
a MIP-TID, which is instead selected by the overlying ap-
plication and passed as a parameter to PostgreSQL when
the transaction is started up. To achieve this, we have ex-
tended the demarcation API with the user-level SQL com-
mand BEGIN MIP . We note that al-
lowing the MIP-TID to be de(cid:2)ned externally to the database
kernel is an intentional design choice since it allows the
transactional management logic (e.g.
at the application
server side) to easily correlate different (distributed) trans-
action instances with different instances of a same client
(re-transmitted) request. A similar approach is used in stan-
dard XA technology for allowing the coordinator of a dis-
tributed transaction to associated, at precommit time, an ap-
plication selected identi(cid:2)er with the transactions executing
at the different sites. The difference with our proposal is that
we allow global identi(cid:2)cation to be anticipated at transac-
tion start time. This will be re(cid:3)ected in the way the re-
engineered version of PostgreSQL manages sibling trans-
actions during their whole execution. Concerning the asso-
ciation between the MIP-TID and the original TID, this has
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 20081-4244-2398-9/08/$20.00 ©2008 IEEE405DSN 2008: Romano & Quagliabeen implemented via an in memory hash-table, indexed
via MIP-TID values, which also allows retrieving the MIP-
TIDs and the TIDs of all active sibling transactions. As it
will be discussed, this is required while handling the recon-
ciliation phase among sibling transactions during the com-
mit phase.
3.2. Concurrency Control
PostgreSQL, as well as several other mainstream com-
mercial DBMSs (such as Oracle [4]), implements a multi-
version concurrency control scheme. This is achieved by
creating a new version of a tuple whenever a write opera-
tion is executed on it, and by letting read operations access
the most recent committed version of the tuple at the time
the transaction started. PostgreSQL allows the existence of
at most one uncommitted version of each tuple, which we
refer to as the active version. Instead, the most recent ver-
sion generated by a committed transaction is referred to as
the valid version. To determine tuple visibility and detect
con(cid:3)icts the concurrency control scheme maintains within
the metadata associated with each tuple version a couple
of TIDs, namely , which represent
the identi(cid:2)ers of the transactions that, respectively, created
and updated that tuple version, and a pointer, namely t ctid,
which links the tuple to the successive version, if any. Ac-
cordingly, when a transaction Ti creates an active version
of a tuple, the tuple t xmax value is set to the special value
null, while the t xmax value associated with the valid tu-
ple version is set to Ti’s TID and its t ctid is linked to the
active version. At starting time, each transaction Ti identi-
(cid:2)es its database snapshot, which is determined by its own
TID as well as by its set of concurrent transactions, de(cid:2)ned
as those transactions that were already active upon activa-
tion of Ti (whose TIDs are stored within the in-memory
transactional context of Ti) plus any transaction possibly
activated after Ti (i.e. having TID greater than Ti’s TID).
The concurrency control mechanism exploits the above
described data structures to handle read/write operations as
follows:
Read - upon read access to a tuple by transaction Ti, the his-