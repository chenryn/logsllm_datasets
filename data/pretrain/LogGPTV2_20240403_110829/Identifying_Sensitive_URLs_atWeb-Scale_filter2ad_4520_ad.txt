Table 6 offers a detailed overview of the contributions of each
category, after applying the preprocessing steps discussed in Sec-
tion 3.1. The vast majority of the web pages belong to the Unknown
category, that includes URLs from Curlie categories that we did not
manually validate. For this reason we cannot use them to test our
classifier. Since our manual validation technique was specifically
designed for identifying sensitive web pages, we were able to cover
only 17% of all the Curlie URLs. At the same time, since we want
to deploy the classifier on the Web, we would like to train it on a
dataset that is as large as possible. In addition, our original training
set contains unequal proportions of sensitive and non-sensitive
web pages. This stems from the fact that the initial dataset is build
leveraging the 301 łpotentially sensitive keywordsž, and then fol-
lowing the technique outlined in Section 2.3. Because of this, the
sensitive elements outnumber the non-sensitive ones by a factor
of 2.4. Having the majority of web pages be sensitive, can lead
to over-fitting and poor performance over different sets of web
pages. This is particularly true for a Naïve Bayes classifier, which
is known to have performance problems with datasets involving
unbalanced classes [47]. To overcome these problems, we train a
second classifier using the same ratio of sensitive and non-sensitive
elements. To create such a balanced training set, we first run our
baseline classifier on the web pages that we did not validate manu-
ally (those with the Unknown label). From the 1,060,077 Unknown
URLs we extract elements that we use to augment each individual
category, and at the same time, balance the ratio between sensitive
and non-sensitive ones. A detailed overview of the URLs that are
included in each category is available in Table 6. In Appendix A we
provide additional details on how we extract sensitive URLs from
the Unknown elements and how we validate their correctness.
The final łbalancedž dataset contains 442,190 web pages, equally
split among sensitive and non-sensitive ones. Using this dataset,
we train a second classifier, that we will henceforth call balanced
classifier. Figure 4 presents the confusion matrix for this balanced
classifier and Table 7 reports the percentage values of each cell of
the confusion matrix alongside the Precision, Recall and F1 scores
Figure 4: Confusion matrix of the balanced classifier.
for each individual class (Last three columns from left to right). We
observe several benefits compared to the same matrix build for the
baseline classifier (Figure 3). First, the overall accuracy increases
by 5.2%. Second, only 6.2% of all the non-sensitive web pages are
occasionally labeled as sensitive. Third, the number of web pages
related to Political Beliefs that are mislabeled as non-sensitive drops
by half (from 21.9% to 11.7%). In the Sexual Orientation category,
the amount of web pages now considered non-sensitive increases
by 11.6%, which corresponds to a total of 173 new elements that
pass undetected. Given that Political Beliefs set is ten times bigger
than Sexual Orientation, the benefits for the former outweigh the
penalties for the latter. For the three remaining categories, the
percentages remain consistent with those obtained using the base-
line classifier. It is also worth noticing that the mis-classification of
non-sensitive web pages to sensitive categories decreases by 8.4%
with the new classifier. Nevertheless, for the Sexual Orientation
and Ethnicity classes, the F1 score remains low at 0.55 and 0.73,
respectively (Table 7 - last column)
3.5 Sensitivity to the Number of Features
In Figure 5 we report several performance metrics obtained by
gradually increasing the size of the feature vector of the balanced
classifier. We include the overall accuracy, the precision and recall
for each category, as well as their combination (F1 score). With
respect to the accuracy, we observe a marginal increase up to 1%
when we configure the classifier to use larger feature vectors. Such
increase is monotonic when using vectors with less than 10k fea-
tures, and stabilizes after the vector size has reached 30k elements.
For vectors with more than 30k elements the overall accuracy starts
gradually dropping following a trend that is inverse to the num-
ber of features that are used. For the majority of the categories,
increasing the size of the feature vector has positive effects both
on the precision and the recall. The main category in which we
observe a significant drop for both statistics is Sexual Orientation.
This category contains the smallest number of samples, and when
the feature vector becomes very large (i.e., more than 20k elements)
the classifier starts over-fitting causing negative impact on the re-
call. A similar behavior is observed for Ethnicity, where increasing
the number of feature improves the precision, but it affects nega-
tively the recall. Both those groups contain a significantly smaller
Non-sensitiveEthnicityHealthPoliticalBeliefsReligionSexualOrientationNon-sensitiveEthnicityHealthPoliticalBeliefsReligionSexualOrientationCorrect ClassPredicted ClassAcc: 88.75%Identifying Sensitive URLs at Web-Scale
IMC ’20, October 27–29, 2020, Virtual Event, USA
Table 7: Quantitative results of the balanced classifier depicted in Figure 4.
Non-sensitive
Non-sensitive
Ethnicity
Health
Political Beliefs
Religion
Sexual Orientation
93.8%
32.5%
15.3%
11.7%
10.7%
44.1%
Ethnicity Health
3.3%
0.5%
83.2%
0.5%
1.0%
6.0%
0.4%
62.5%
0.001%
0.5%
0.2%
0.0%
Political Beliefs Religion
Sexual Orientation
0.8%
1.1%
0.3%
86.5%
0.3%
1.7%
1.3%
3.3%
1.2%
0.8%
87.8%
2.0%
0.4%
0.001%
0.001%
0.001%
0.001%
46.3%
Precision Recall
0.94
0.63
0.83
0.87
0.88
0.46
0.87
0.86
0.88
0.93
0.94
0.68
F1-Score
0.90
0.73
0.85
0.90
0.91
0.55
Figure 6: The micro and macro-average AUC using the ba-
lanced classifier and the corresponding breakdown per cate-
gory.
In Figure 6 we plot the Area Under the Curve (AUC) for the
balanced classifier as well as the AUC values for each individual
sensitive category. The AUC depicts the performance of the classifi-
cation model at all classification thresholds (cut points), as opposed
to the overall accuracy that is based on a specific threshold, and can
provide an aggregate measure of performance across all possible
classification thresholds. We observe that the micro- and macro-
average AUC values are 0.98 and 0.97 respectively. With respect to
the individual categories, we observe that the lower AUC value at
0.95 belongs to the category Ethnicity followed by Non-sensitive at
0.96. Sexual Orientation is at 0.97 and Health at 0.98. Finally, Politi-
cal Belief and Religion show equal AUC value at 0.99. Our analysis
shows that the balanced classifier achieves very high accuracy. For
the rest of the paper we will use this classifier to analyze corpuses
of the Web to identify sensitive web pages.
4 SEARCHING FOR SENSITIVE WEB PAGES
IN THE WILD
We leverage our classifier to investigate the popularity of sensitive
content across the open Web, and we analyze the privacy and
security practices associated to this type of content. To perform
our study we use data obtained from a service with more than a
decade of experience in crawling the Web. In the following sections
we provide an overview of the dataset, we share our experience in
classifying Billions of web pages, we evaluate the extent of sensitive
web pages and we report potential privacy issues for the users
accessing this type of content. Our analysis identifies around 155
Figure 5: Accuracy, precision, recall and F1 scores Vs. num-
ber of features for the balanced classifier.
number of samples compared to other categories. This unbalance
is reflected in the scores of the macro- and micro-average. Micro-
average obtains much better results thanks to the fact that larger
categories such as Non-sensitive, Health and Religion have much
higher precision compared to those with fewer samples.
To select the most appropriate length of the feature vector, we
turn to the F1 scores. Using larger vectors, up to 30k features, gen-
erally benefits the overall scores (both micro- and macro-weights
increase). Unfortunately this behavior is limited only to categories
with a higher number of samples. The recall for Ethnicity drops
below 60% for vectors with more than 20k features, and in the case
of Sexual Orientation the peak value is observed when vectors con-
tain less than 20k elements. In an attempt to find the ideal trade-off
among the six categories, we decide to use a feature vector with 20k
elements. We choose such value because it is very close to the peak
value for four of the largest categories. In addition, such choice
allow us to maximize the overall accuracy, while not sacrificing the
recall in categories with fewer samples.
010k20k30k40k50k60k70k80k90k100kNumber of FeaturesSex. Orient.EthnicityHealthPol. BeliefsReligionNon-sensitivemacro-avg.micro-avg.0.890.8850.880.8750.90.80.70.60.80.60.40.80.60.4Overall AccuracyPrecisionRecallF1 Scoremicro-avg (AUC: 0.98)macr-avg (AUC: 0.97)Ethnicity (AUC: 0.95)Health (AUC: 0.98)Pol. Beliefs (AUC: 0.99)Religion (AUC: 0.99)Sex. Orient. (AUC: 0.97)Non-sensitive (AUC: 0.96)Multi-class Receiver Operating CharacteristicTrue Positive RateFalse Positive Rate00.20.40.60.8100.20.40.60.81IMC ’20, October 27–29, 2020, Virtual Event, USA
Matic et al.
Table 8: English-only web pages in the Common Crawl Oc-
tober 2019 snapshot after excluding duplicates, error pages
and content with less than 1,000 characters.
Table 9: Classifier results on the October 2019 snapshot. We
report the percentage of URLs in each category and the
FQDNs associated to those URLs. In the last column we re-
port the FQDNs where all the URLs belong to that category.
HTTP
HTTPS
HTTP+HTTPS
Homepages
URLs
276,876,278
709,263,254
-
9,148,978
FQDNs
6,561,287
8,005,488
540,230
9,148,978
ESLDs
5,286,123
6,294,040
586,622
7,827,525
Total
986,139,532
15,107,005
12,166,785
million sensitive URLs in more than 4 million domains, with Health,
Religion, and Political Beliefs to be the top-3 sensitive categories.
4.1 The Common Crawl Dataset
Common Crawl is a nonprofit organization that maintains an open
repository of Web crawl data [25]. The project was launched in 2007
and since then it periodically releases all the collected information
in the form of monthly snapshots. All the data is made publicly
available and a single snapshot contains more than 3 Billions of
web pages [26].
Common Crawl October 2019 corpus. Each corpus (or snapshot) con-
tains a list of URLs and corresponding web pages, with the addition
of metadata about crawling. This information is packaged in the
Web ARChive (WARC) format, combining the raw HTML content
together with the HTTP headers fetched from servers. As alterna-
tive, users can choose the WET archives that contain only plain
text extracted from the raw crawls, once HTML tags are removed.
Since our classifier works with web page content, we speed up
the analysis by downloading the WET archives for the October
2019 snapshot. Before starting to classify content, we leverage the
Common Crawl language annotations [24] to identify documents
written in English language. We also apply a preprocessing similar
to the one used for the Curlie dataset, to remove extremely short
documents and error pages.
In Table 8 we present an overview of the October 2019 snapshot,
after applying our preprocessing steps. The dataset contains almost
1 Billion web pages in English, collected from 15,107,005 different
web sites (column FQDN). For 60.5% of the visited web sites the
crawler successfully downloaded the homepage. Almost 72% of the
pages were downloaded through HTTPS and the vast majority of
web sites was accessed using a single protocol; only a small fraction
of 3.4% of FQDNs was accessed both with HTTP and HTTPS. From
60% of the FQDNs the crawler collected at most ten URLs, and in
30% of the cases a web site is represented only through a single
URL. However, the distribution has a long tail and 115,084 FQDNs
in the snapshot contribute with more than 1,000 URLs each.
To check the popularity of the domains that are included in the
snapshot, we use the list from the Tranco project [66]. Such list
aggregates the ranks from four widely used services which provide
daily updated lists of popular domains. We use the Tranco list
generated on the 31 October 20193 which covers the same period
when the Common Crawl snapshot was created. By comparing
the two sets of domains, we notice that 475,637 of the FQDNs that
3https://tranco-list.eu/list/5XQN/1000000
Category
Ethnicity
Health
Pol. Beliefs
Religion
Sexual Or.
Non-sensitive
Mixed
% URLs
0.52
7.1
3.28
3.59
1.29
84.22
# FQDNs
112,300
2,782,416
686,733
1,228,243
214,011
13,605,876
% URLs
0.03
1.78
0.17
0.75
0.55
38.11
58.28
# Ded. FQDNs
12,935
922,242
95,848
329,575
86,345
10,853,118