I am developing an aggregation application that scrapes data from multiple web sources and presents it through a unique interface. The websites I'm scraping update every few minutes, and I want to ensure that the data in my aggregator is current. 

What is the most effective method for periodically submitting fresh data to my App Engine application using an automated script, given the following constraints:

1. The application is written in Python.
2. The scraping process for each site takes longer than one second, so I cannot process the data within an App Engine handler.
3. The host on which the updater script will run is shared, and I prefer not to store my password on disk.
4. I intend to check the code for the application into our codebase. Although my colleagues are not malicious, they are pranksters, and I want to prevent them from injecting fake data into my app.
5. I am aware that App Engine supports a remote API, but I would need to secure that entry point with authentication (as per constraint 3) or hide the URL (as per constraint 4).

### Suggestions

The primary way to get data into App Engine is by calling your own web application and feeding it data via HTTP requests. This can be done using either GET requests (for short data) or POST requests (for longer or binary data).

To achieve this, you will need to create a custom data loader that acts as a web application. This data loader will receive the scraped data and then store it in the App Engine database. Hereâ€™s a step-by-step approach:

1. **Create a Data Loader Web Application:**
   - Develop a small web application in Python that will handle the incoming data.
   - This application should accept HTTP POST requests containing the scraped data.

2. **Implement Authentication:**
   - To secure the data loader, implement basic authentication or use a more robust method like OAuth.
   - Ensure that the credentials are securely managed and not stored on the shared host. You can use environment variables or a secure key management service.

3. **Automated Script for Scraping and Submitting Data:**
   - Write an automated script that performs the scraping and then sends the data to the data loader web application.
   - Use libraries like `requests` in Python to send HTTP POST requests with the scraped data.

4. **Handling Long-Running Tasks:**
   - Since the scraping process takes longer than one second, consider using a task queue like Google Cloud Tasks to offload the processing.
   - The task queue can trigger the data loader to fetch and process the data in the background, ensuring that the App Engine request handlers do not time out.

5. **Codebase Security:**
   - To prevent pranksters from injecting fake data, ensure that the data loader application validates the incoming data.
   - Implement checks to verify the integrity and authenticity of the data before storing it in the database.

6. **Environment Configuration:**
   - Store sensitive information such as API keys and authentication tokens in environment variables or a secure secrets manager.
   - Use a configuration management tool to manage these secrets and ensure they are not hard-coded in the source code.

By following these steps, you can create a secure and efficient system for periodically updating your App Engine application with fresh data.