### Normal Operations and Safety Violations

During normal operations, certain flight modes, such as `ALT_HOLD`, can be unsafe. To detect such violations, PGFUZZ employs Metric Temporal Logic (MTL) policies to capture temporal and causal relationships among the states of Robotic Vehicles (RVs). This approach allows PGFUZZ to identify a broader range of bugs.

### Related Work

Several approaches have been developed to find bugs specifically in RVs. For instance, RVFuzzer [41] targets input validation bugs by fuzzing configuration parameters and environmental factors like wind. MAYDAY [40] localizes bugs in the source code that lead to unstable attitudes or crashes. AR-SI [36] uses autoregressive system identification to detect control instability issues. Choi et al. [24] extract a control invariant model representing the RV's dynamics and control algorithm. This model predicts the next states related to attitude control (roll, pitch, and yaw angles). If a significant state difference is detected between the RV and the model, it indicates an undesired state change. These methods are primarily focused on detecting bugs that cause either unstable attitudes or flight path changes. Consequently, they may miss other types of bugs, such as those described in Section VII-C4. In contrast, PGFUZZ can discover a wider variety of bugs affecting RVs by detecting violations of any property expressible with MTL formulas.

Choi et al. [23] also proposed a technique to find bugs in safety checks of drones by mutating environmental conditions (e.g., wind and mass of physical objects) to verify if code snippets perform necessary sanity checks. They use the model from their previous work [24] as a bug oracle. PGFUZZ, however, tests the entire control software by allowing users to define functional requirements in the form of MTL formulas. This capability enables PGFUZZ to discover additional types of bugs, such as the lack of safety condition checks (e.g., when a drone opens a parachute, as explained in Section VII-C1), physical crashes due to incorrect parameter ranges (Section VII-C2), and incorrect altitude calculations (Section VII-C3).

Formal methods have also been used to detect bugs in RVs [30], [31]. However, these methods often suffer from state explosion problems, limiting their applicability to complex systems. Machine learning techniques have been explored for formal verification to detect safety issues [2], [3], but they focus more on malicious sensor/actuator faults and spoofing attacks rather than RV software bugs.

### Limitations and Discussion

#### Imperfection of RV Simulators

We use Software-in-the-Loop (SITL) as our testing environment. Imperfect simulations can cause two main issues:
1. **False-Positive Policy Violations**: If simulators incorrectly simulate the vehicle's states and/or hardware, PGFUZZ may identify false-positive policy violations. However, all policy violations found by PGFUZZ were reproducible on a real vehicle, specifically a 3DR IRIS+ UAV platform equipped with the Pixhawk 1 flight management unit board.
2. **Unsupported Hardware**: If the simulators do not support specific hardware (e.g., RFD 900 radio modem [14]), PGFUZZ cannot find bugs in those hardware modules. To address this, PGFUZZ can be integrated into Hardware-in-the-Loop (HIL) or Simulation-In-Hardware (SIH) environments where firmware runs on real flight controller hardware. However, HIL and SIH require numerous hardware devices to vet all configurations.

#### Monitoring Real-Time Properties of Temporal Logic

PGFUZZ checks policies at run-time during simulation. At time point \( t \), only data traces up to \( t \) are available. Therefore, MTL policies with unbounded future operators cannot be checked at run-time. Following online monitoring systems [16], [27], we define policies using a subclass of MTL that considers unbounded past and bounded future. For example, a policy stating that the altitude must eventually exceed 10 meters, defined as \( \Diamond (ALT > 10) \), cannot be checked at time \( t \) because it depends on future states. However, when restricted to a bounded future, such as \( \Diamond_{[0,5]} (ALT > 10) \) (the altitude must exceed 10 meters within 5 seconds), the policy can be checked at time \( t + 5 \).

#### Porting PGFUZZ to Other RVs

Users can port PGFUZZ to other types of RV software by following six steps:
1. **Create MTL (or LTL) Policies**: Define policies for the RV.
2. **Identify New States**: Add new states not included in the existing list.
3. **Update Synonym Table**: Update the synonym table (see Figure 5).
4. **Map MTL Formula Terms**: Map MTL formula terms to variables in the source code (see Figure 4).
5. **Verify and Update Policy Violation Predicates**: Ensure predicates are updated according to the new MTL formulas (see Figure 13).
6. **Exclude Self-Sabotaging Inputs**: Exclude inputs leading to false-positive policy violations (see Appendix C).

The effort required for porting depends on the similarity between platforms. For example, porting PGFUZZ from ArduPilot to PX4 took 6.3 hours, including modifying 54 lines of code in the pre-processing and 94 lines in the mutation engine to adapt to differences in the MAVLink protocol. The detailed manual porting effort is provided in Appendix D.

### Conclusions

We introduce PGFUZZ, a policy-guided fuzzing framework that leverages MTL policies to find bugs in RV control software. PGFUZZ addresses the unique challenges in fuzzing RVs by reducing the large input space through static and dynamic analysis and mutating fuzzing inputs to minimize a distance metric. We evaluated PGFUZZ on three popular flight control software packages: ArduPilot, PX4, and Paparazzi. PGFUZZ discovered 156 previously unknown bugs, with 128 of them being uniquely identified by PGFUZZ. We reported the bugs to the software developers, who acknowledged 106 of these bugs. Future work will expand our analysis to support more safety-critical systems and study the safety and security requirements engineering process to discover more complex policies.

### Acknowledgment

This work was supported in part by ONR under Grants N00014-20-1-2128 and N00014-17-1-2045. Any opinions, findings, and conclusions in this paper are those of the authors and do not necessarily reflect the views of the ONR.

### References

[References are listed as in the original text, with no changes made.]

### Appendix

#### A. List of Terms

Table XI shows the physical states extracted from policies presented in Table XII. We also include a list of InputP and InputE in the list of terms.

#### B. Automated Predicate Generation

To reduce users' manual effort, we automate the fifth step (i.e., creating code snippets to calculate propositional and global distances). We call this step the predicate generator. The predicate generator first parses and verifies MTL formulas based on the BNF definition in Section V-A1. We implemented the analyzer to facilitate this process.

| Type | ID | Position | State |
|------|----|----------|-------|
| S1   |    |          | roll, latitude, longitude, altitude |
| S2   | Attitude |        | roll, pitch, yaw, roll speed, ... |

This structured approach ensures that the text is clear, coherent, and professional.