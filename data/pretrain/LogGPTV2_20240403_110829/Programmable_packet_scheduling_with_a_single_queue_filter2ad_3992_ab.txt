(cid:6)
(cid:9)
(cid:8)
(cid:6)
(cid:6)
(cid:9)
(cid:8)
(cid:6)
(cid:2)(cid:17)(cid:3)(cid:1)(cid:12)(cid:21)(cid:26)(cid:27)(cid:28)(cid:4)(cid:13)(cid:24)(cid:1)(cid:12)(cid:21)(cid:26)(cid:27)(cid:28)(cid:4)(cid:14)(cid:29)(cid:28)(cid:1)(cid:2)(cid:12)(cid:13)(cid:12)(cid:14)(cid:3)(cid:5)
(cid:12)(cid:13)(cid:12)(cid:14)
(cid:7)
(cid:7)
(cid:6)
(cid:9)
(cid:8)
(cid:6)
(cid:7)(cid:4)(cid:6)(cid:5)(cid:2)(cid:1)(cid:3)
(cid:3)(cid:1)(cid:2)
(cid:7)
(cid:7)
(cid:6)
(cid:6)
(cid:10)(cid:19)(cid:23)(cid:21)(cid:27)(cid:27)(cid:21)(cid:25)(cid:24)(cid:1)(cid:11)(cid:25)(cid:24)(cid:28)(cid:26)(cid:25)(cid:22)
(cid:12)(cid:13)(cid:12)(cid:14)
(cid:2)(cid:18)(cid:3)(cid:1)(cid:10)(cid:19)(cid:23)(cid:21)(cid:27)(cid:27)(cid:21)(cid:25)(cid:24)(cid:4)(cid:13)(cid:24)(cid:1)(cid:12)(cid:21)(cid:26)(cid:27)(cid:28)(cid:4)(cid:14)(cid:29)(cid:28)(cid:1)(cid:2)(cid:10)(cid:13)(cid:12)(cid:14)(cid:3)(cid:5)
Figure 2: Motivating example of AIFO.
PIFO queue is a priority queue that sorts packets based on their
ranks. Packets are inserted into the queue based on their ranks, and
are dequeued from the head (i.e., the smallest rank).
Programmability lies in the rank computation component. Pro-
gramming a packet scheduling algorithm in the context of PIFO
refers to programming how a rank for each packet is computed.
One simple example is to program SRPT [41] for minimizing FCTs,
as shown in Figure 1. In this example, the rank of a packet is simply
the remaining processing time of the flow (or simply the remaining
bytes of the flow). Note that SRPT requires end hosts to put the
remaining processing time in an appropriate field in the packet
header [6, 41], which is orthogonal to packet scheduling in the
switch. Given such rank computation, the PIFO queue would sched-
ule the packet with the shortest remaining processing time first,
i.e., realizing SRPT.
A more complicated example is to program STFQ [13] for weighted
fairness, which is also shown in Figure 1. In this example, the rank
of a packet is the virtual start time of the packet in STFQ. The vir-
tual start time is computed as the maximum of the virtual time and
the virtual finish time of the previous packet of the same flow. The
virtual time maintains the virtual start time of the last dequeued
packet across all flows. The virtual finish time of a packet is the
virtual start time of the packet plus the length of the packet divided
by the flow weight. Given such rank computation, the PIFO queue
would schedule the packet with the smallest virtual start time first,
i.e., realizing STFQ.
Beyond these two example, it has been shown that PIFO can
support a wide range of packet scheduling algorithms, such as
Least-Slack Time-First [23], Service-Curve Earliest Deadline First
(SC-EDF) [40], etc.
2.2 Motivating Example
While PIFO is an appealing solution for programmable packet sched-
uling, it is challenging to implement in hardware, especially in
switch ASICs. The rank computation component is relatively easy.
It can be implemented as a packet transaction [46] in the data plane
of existing programmable switches. The major challenge is to im-
plement the PIFO queue. Existing switches do not support a sorted
queue in the data plane. There is a proposal on how to support
a sorted queue in the data plane at 1 GHz [47]. But the proposal
(cid:2)(cid:16)(cid:3)(cid:1)(cid:15)(cid:28)(cid:26)(cid:19)(cid:4)(cid:13)(cid:23)(cid:1)(cid:12)(cid:20)(cid:25)(cid:26)(cid:27)(cid:4)(cid:14)(cid:28)(cid:27)(cid:1)(cid:2)(cid:15)(cid:13)(cid:12)(cid:14)(cid:3)(cid:5)
(cid:15)(cid:13)(cid:12)(cid:14)
(cid:7)
(cid:6)
(cid:7)
(cid:9)
(cid:8)
(cid:6)
(cid:7)(cid:4)(cid:6)(cid:5)(cid:2)(cid:1)(cid:3)
(cid:3)(cid:1)(cid:2)
(cid:7)
(cid:6)
(cid:7)
(cid:6)
(cid:10)(cid:18)(cid:22)(cid:20)(cid:26)(cid:26)(cid:20)(cid:24)(cid:23)(cid:1)(cid:11)(cid:24)(cid:23)(cid:27)(cid:25)(cid:24)(cid:21)
(cid:12)(cid:13)(cid:12)(cid:14)
(cid:2)(cid:17)(cid:3)(cid:1)(cid:10)(cid:18)(cid:22)(cid:20)(cid:26)(cid:26)(cid:20)(cid:24)(cid:23)(cid:4)(cid:13)(cid:23)(cid:1)(cid:12)(cid:20)(cid:25)(cid:26)(cid:27)(cid:4)(cid:14)(cid:28)(cid:27)(cid:1)(cid:2)(cid:10)(cid:13)(cid:12)(cid:14)(cid:3)(cid:5)
Figure 3: An example that PIFO and AIFO dequeue the same
set of packets ({1, 1, 2, 2}), but the dequeueing orderings are
different ([1, 1, 2, 2] vs. [1, 2, 1, 2]).
only provides a design, not a real implementation, and the design
is not scalable as it can only support a few thousand flows. SP-
PIFO [3] provides an approximation of a PIFO queue using multiple
strict-priority queues. But strict-priority queues are precious hard-
ware resources as commodity switches have a limited number of
strict-priority queues and the operators would like to use them to
ensure strong physical isolation between multiple tenants. In this
paper, we aim to design a solution that has the minimal hardware
requirements for programmable packet scheduling.
Example. To find such a solution, let us get down to the funda-
mentals to analyze the problem. We consider the arrival traffic and
departure traffic of a queue. When the packet arrival rate is no
higher than the link speed (i.e., the upper bound of the departure
rate), the entire traffic is admissible and there is no persistent queue
buildup. It does not matter whether the queue is PIFO, FIFO, or
anything else. The distinction happens when the arrival rate is
higher than the link speed, which can be either due to a microburst
or a longer-term congestion. In this case, some of the packets are
not admissible and the queuing discipline matters.
We examine the examples in Figure 2. The example is simplified
to provide the intuition of our approach. In the example, there is
a burst of six packets arriving at the switch. The queue has four
slots and is empty in the beginning. For the first four packets, PIFO
would enqueue them one by one and the sorted queue becomes
[1, 1, 4, 5]. Then when the fifth packet with rank 2 arrives, PIFO
would insert the packet into the queue and the last packet in the
queue is dropped due to overflow. The queue becomes [1, 1, 2, 4].
Finally, when the sixth packet arrives, the last packet in the queue
is dropped again and the queue is [1, 1, 2 ,2] in the end.
In terms of FIFO, it enqueues the packets one by one. After four
packets, the queue is full, and the fifth and sixth packets cannot
be enqueued. The queue is [1, 4, 5, 1] in the end. PIFO and FIFO
behave very differently.
However, if there is an oracle that knows the precise arrival
pattern of the packets in advance, then the switch can perform
admission control before the packets are enqueued. Specifically for
the example in Figure 2, the admission control can use a threshold
of 3. If the rank of a packet is no bigger than 3, then the packet
can be enqueued; otherwise the packet is dropped. With this, the
second and third packets would be dropped and the queue is [1,
1, 2, 2] in the end. FIFO with such admission control behaves the
same as PIFO in this example.
181
SIGCOMM ’21, August 23–28, 2021, Virtual Event, Netherlands
Zhuolong Yu, et al.
3 DESIGN GOAL
Based on the insights from the motivating example, we can trans-
form the packet scheduling problem into an admission control
problem, and PIFO can be approximated by FIFO with admission
control.
We term this approach AIFO. Our goal is to minimize the gap
between the ideal case (i.e., PIFO) and the approximation (i.e., AIFO).
The gap can be measured quantitively with the following metric:
the difference between the packets dequeued by PIFO and those
dequeued by AIFO. Formally, let the set of packets dequeued (up to
time t ) by PIFO and AIFO to be P(t ) and A(t ), respectively. Then
we use
Δ(t ) =
|P(t ) \A( t )| + |A(t ) \P( t )|
|P(t )| + |A(t )|
(1)
to measure the gap between PIFO and AIFO. Here, |P(t ) \ A(t )|
is the cardinality of the set difference between P(t ) and A(t ), and
|A(t ) \ P(t )| is that between A(t ) and P(t ). |P(t )| and |A(t )| are the
cardinalities of sets P(t ) and A(t ), respectively.
We have Δ(t ) ∈ [0, 1], and a large value of Δ indicates a large gap
between AIFO and PIFO. When AIFO and PIFO dequeue the same
set of packets (i.e., no gap), Δ = 0; when AIFO and PIFO dequeue
completely different packets, Δ = 1. We theoretically prove that the
difference between AIFO and PIFO is negligible when the system
is stationary (§4), and empirically demonstrate that AIFO provides
close performance as PIFO with a range of real workloads (§5).
Packet ordering. Another possible metric would be to not only
count the number of different packets that are dequeued, but also
account for the difference in the dequeuing ordering. Figure 3 pro-
vides an example to illustrate this metric. The example is similar to
the one in Figure 2, and the only difference is that the third and the
fourth arrival packets are swapped in Figure 3. With this arrival
sequence of packets, AIFO still admits the same set of packets as
PIFO, which are {1, 1, 2, 2}. However, the orderings that the packets
are dequeued are different. AIFO uses the ordering [1, 2, 1, 2], which
PIFO uses the ordering [1, 1, 2, 2].
We argue that this metric is less important than the first metric,
and sometimes is even undesirable to optimize for. First, there
are two important trends for datacenter networking: (i) the trend
towards shallow buffers for low latency in modern datacenters [5];
and (ii) the trend towards tight control loops at end hosts [22]. The
confluence of these two trends ensures that the switch queues would
not buffer many packets, making the difference on the dequeueing
ordering between PIFO and AIFO minimal. As we are essentially
emulating PIFO with a FIFO queue, we want to keep the buffer
shallow so that the packets can have a short waiting time in the
queue. Empirically, we show in Section 5 that such a difference
would not impact the flow-level metrics like flow completion time
(FCT) much and AIFO behaves almost the same as PIFO.
Second, strictly following PIFO causes packet reorderings, which
is undesirable. SRPT achieves near optimality on minimizing FCTs [41];
it schedules flows based on the remaining flow size, so that small
flows are scheduled before big flows to minimize FCTs. Packet re-
orderings happen when PIFO is programmed to implement SRPT
by using the remaining flow size as the rank (like Figure 1). This
is because for the same flow, a latter packet would have a smaller
remaining flow size than its previous packet, and thus is scheduled
first by the switch if both packets are enqueued by the switch.
This is a known issue, and pFabric [6] addresses this issue by
adding an extra feature called starvation prevention to SRPT. Star-
vation prevention dequeues the packets of the same flow in the
order they arrive, so that the first packet of a flow would be de-
queued first if the flow is scheduled and the first packet would
not be starved. Between flows, pFabric uses SRPT to select which
flow to schedule first. Given the strong demand on low-latency
for datacenter networks, pFabric is arguably the killer application
of programmable packet scheduling. Yet, it cannot be supported
by PIFO [47]. Unexpectedly, a positive byproduct of AIFO is that
it naturally supports starvation prevention and eliminates packet
reordering by design.
Summary. To summarize, our goal is to design an algorithm that
has the minimal hardware requirements (i.e., a single queue) and
admits the right set of packets to minimize Δ and maintain shallow
buffers. The algorithm should be able to be implemented in the
data plane of existing hardware and run at line rate. We want to
ensure that the algorithm provides bounded performance to PIFO
with respect to Δ.
4 AIFO DESIGN
In this section, we first introduce the key ideas of AIFO. Then we
describe the AIFO algorithm, and theoretically prove that AIFO
closely approximates PIFO. Finally, we describe the switch data
plane design to implement AIFO on a programmable switch.
4.1 Key Ideas
AIFO only uses a single FIFO queue, instead of a PIFO queue or
multiple strict-priority FIFO queues. It adds admission control in
front of the FIFO queue to decide whether to admit or drop an ar-
riving packet. Admitted packets are buffered and sent by the queue
in FIFO order, and no extra scheduling is needed. The admission
control is designed to minimize Δ described in Section 3, in order
to minimize the gap between AIFO and PIFO.
AIFO achieves a close approximation of PIFO with two-dimensional
admission control by simultaneously considering both time and
space dimensions. Its temporal component considers the time dimen-
sion by changing the threshold over time based on the fluctuation
of the arrival rate; its spatial component considers the space dimen-
sion by deciding the threshold based on the ranks of the packets
at each time. These two together ensure AIFO admits a similar set
of packets as PIFO. At a high level, the two components work as
follows.
• Temporal component. The threshold of admission control is
dynamic, instead of fixed. It is updated based on the real-time
discrepancy between arrival rate and departure rate. When the
arrival rate significantly exceeds the departure rate, the threshold
becomes more aggressive. It ensures the rate of admitted packets
roughly matches the departure rate.
• Spatial component. The admission control treats packets differ-
ently based on their ranks, instead of using a naive rank-agnostic
criteria (e.g., randomly dropping 10% packets). It prefers to drop
high-rank packets over low-rank packets, as low-rank packets
are expected to be scheduled first. The threshold is decided based
182
Programmable Packet Scheduling with a Single Queue
Algorithm 1 AIFO
1: function Ingress(pkt )
// Admission Control
Update sliding window W with pkt
c ← Queue.lenдth
C ← Queue.size
if c ≤ k · C (cid:6) W .quantile(pkt ) ≤ 1
1−k
// Admit packet
Queue.enqueue(pkt)