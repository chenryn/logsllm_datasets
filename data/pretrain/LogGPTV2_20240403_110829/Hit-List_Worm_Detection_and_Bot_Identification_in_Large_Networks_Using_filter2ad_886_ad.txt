p
(
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
 100
 95
 90
 85
 80
 75
 70
 65
 60
 55
 50
 0
 0
75%
50%
25%
 15
 10
 5
 40
False positive rate (percentage)
 20
 25
 30
 35
 45
 50
PTMS)b(
75%
50%
25%
 15
 10
 5
 40
False positive rate (percentage)
 20
 25
 30
 35
 45
 50
elcarO)c(
PTF)d(
Fig. 6. Attacker identiﬁcation accuracy of (4); hitListPerc ∈ {25%, 50%, 75%},
|hidegree| = 10, |bots| = 5
point on a curve shows the true and false positive rates for a particular setting
of θ. More speciﬁcally, if hidegree ⊆ V (Λ) is a set of highest-degree vertices in
G(Λ), and if hidegreebots ⊆ hidegree denotes the bots in hidegree, then any point
in Figure 6 is deﬁned by
(cid:9)
true positive rate =
(cid:9)
false positive rate =
v∈hidegreebots isbotΛ,θ(v)
|hidegreebots|
v∈hidegree\hidegreebots isbotΛ,θ(v)
|hidegree \ hidegreebots|
As Figure 6 shows, a more aggressive worm (i.e., as hitListPerc grows) exposes
its bots with a greater degree of accuracy in this test, not surprisingly, and
the absolute detection accuracy for the most aggressive worms we consider is
very good for HTTP, SMTP and FTP. Moreover, while the curves in Figure 6
were calculated with |hidegree| = 10, we have found that the accuracy is very
robust to increasing |hidegree| as high as 100. As such, when identifying bots,
it does not appear important to the accuracy of the test that the investigator
ﬁrst accurately estimate the number of bots involved in the attack. We are more
thoroughly exploring the sensitivity of (4) to |hidegree| in ongoing work, however.
292
M.P. Collins and M.K. Reiter
)
e
g
a
t
n
e
c
r
e
p
(
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
 100
 95
 90
 85
 80
 75
 70
 65
 60
 55
 50
 45
 40
 35
 30
 25
 20
 15
 10
 5
 0
isbotΛ,θ(v)
isbot´Λ,θ(v)
)
e
g
a
t
n
e
c
r
e
p
(
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
 100
 95
 90
 85
 80
 75
 70
 65
 60
 55
 50
 45
 40
 35
 30
 25
 20
 15
 10
 5
 0
isbotΛ,θ(v)
isbot´Λ,θ(v)
 0  5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90  95 100
 0  5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90  95 100
False positive rate (percentage)
False positive rate (percentage)
(a) HTTP
(b) SMTP
Fig. 7. Accuracy of (4) versus (5); hitListPerc = 25%, |hidegree| = 10, |bots| = 5
Because we evaluate (4) on high-degree vertices in order to ﬁnd bots, a natural
question is whether degree in G(Λ) alone could be used to identify bots with
similar accuracy, an idea similar to those used by numerous detectors that count
the number of destinations to which a host connects (e.g., [24,17]). To shed light
on this question, we consider an alternative bot identiﬁcation predicate, namely
(cid:8)
(cid:4)
Λ,θ(v) =
isbot
1
0
if degreeΛ(v) > θ
otherwise
(5)
where degreeΛ(v) is the degree of v in G(Λ), and compare this test to (4) in
Figure 7. As this ﬁgure shows, using (5) oﬀers much less accurate results in
some circumstances, lending support to the notion that our proposal (4) for bot
identiﬁcation is more eﬀective than this alternative.
7 Implementation
Any worm detection system must be eﬃcient to keep up with the high pace of
ﬂows observed in some protocols. A strength of our detection approach based on
conditions (1) and (2) in Section 4 is that it admits very eﬃcient implementation
by well-known union-ﬁnd algorithms [7]. Such an algorithm maintains a collec-
tion of disjoint sets, and supports three types of operations on that collection: a
makeset operation creates a new singleton set containing its argument; a find
operation locates the set containing its argument; and a union operation merges
the two sets named in its arguments into one set. The size of each set in the
collection can be maintained easily because each set in the collection is disjoint:
a new set created by makeset has size one, and the set resulting from a union
is of size the sum of the sizes of the merged sets.
The implementation of a worm detection system using a union-ﬁnd algorithm
is straightforward: for each λ ∈ Λ, the sets containing λ.sip and λ.dip are lo-
cated by find operations (or created via makeset if the address has not yet
been observed in Λ), and if these sets are distinct, they are merged by a union
Hit-List Worm Detection and Bot Identiﬁcation in Large Networks
293
operation. |C(Λ)| is simply the size of the largest set, and |V (Λ)| is the sum of
the sizes of the sets.
The eﬃciency of this implementation derives from the use of classic techniques
(see [7]). A famous result by Tarjan (see [23]) shows that with these techniques,
a log ﬁle Λ can be processed in time O(|Λ|α(|V (Λ)|)), where α(·) is the inverse
of Ackermann’s function A(·), i.e., α(n) = arg mink : A(k) ≥ n. Due to the
rapid growth of A(k) as a function of k (see [1,23]), α(n) ≤ 5 for any practical
value of |V (Λ)|. So, practically speaking, this algorithm enables the processing of
ﬂows with computation only a small constant per ﬂow. Perhaps as importantly,
this can be achieved in space O(|V (Λ)|). In contrast, accurately tracking the
number of unique destinations to which each vertex connects—a component of
several other worm detection systems (e.g., [24,17])—requires Ω(|E(Λ)|) space, a
potentially much greater cost for large networks. Hence our approach is strikingly
eﬃcient while also being an eﬀective detection technique.
Once an alarm is raised for a graph G(Λ) = (cid:3)V (Λ), E(Λ)(cid:4) due to it vio-
lating condition (1) or (2), identifying the bots via the technique of Section 6
requires that we ﬁnd the high-degree vertices in V (Λ), i.e., the vertices that
have the most unique neighbors. To our knowledge, the most eﬃcient method
to do this amounts to simply building the graph explicitly and counting each
vertex’s neighbors, which does involve additional overhead, namely O(|E(Λ)|)
space and O(|Λ| log(|E(Λ)|)) time in the best algorithm of which we are aware.
However, this additional cost must be incurred only after a detection and so can
proceed in parallel with other reactive measures, presumably in a somewhat less
time-critical fashion or on a more resource-rich platform than detection itself.
8 Conclusion
In this paper, we introduced a novel form of network monitoring technique based
on protocol graphs. We demonstrated using logs collected from a very large
intercontinental network that the graph and largest component sizes of protocol
graphs for representative protocols are stable over time (Section 4.1). We used
this observation to postulate tests to detect hit-list worms, and showed how
these tests can be tuned to limit false alarms to any desired level (Section 4.2).
We also showed that our tests are an eﬀective approach to detecting a range of
hit-list attacks (Section 5).
We also examined the problem of identifying the attacker’s bots once a de-
tection occurs (Section 6). We demonstrated that the change in the number of
connected components caused by removing a vertex from the graph can be an
accurate indicator of whether this vertex represents a bot, and speciﬁcally can
be more accurate than examining merely vertex degrees.
Finally, we examined algorithms for implementing both hit-list worm detec-
tion and bot identiﬁcation using our techniques (Section 7). We found that
hit-list worm detection, in particular, can be implemented using more eﬃcient
algorithms than many other worm detection approaches, using classic union-ﬁnd
algorithms. For networks of the size we have considered here, such eﬃciencies
294
M.P. Collins and M.K. Reiter
are not merely of theoretical interest, but can make the diﬀerence between what
is practical and what is not. Our bot identiﬁcation algorithms are of similar
performance complexity to prior techniques, but need not be executed on the
critical path of detection.
Since a protocol graph captures only the traﬃc of a single protocol, our detec-
tor could be circumvented by a worm that propagates within a variety of diﬀerent
protocols. A natural extension of our techniques for detecting such a worm would
be to consider graphs that involve multiple protocols at once, though we have
not evaluated this possibility and leave this for future work.
Acknowledgements
We are grateful to Dawn Song for initial discussions on topics related to this
paper, and to the anonymous reviewers for comments that helped to improve
the paper. This work was supported in part by NSF grant CNS-0433540.
References
1. Aho, A.V., Hopcroft, J.E., Ullman, J.D.: The Design and Analysis of Computer
Algorithms. Addison-Wesley, Reading (1975)
2. Aiello, W., Chung, F., Lu, L.: A random graph model for massive graphs. In:
Proceedings of the 32nd ACM Symposium on Theory of Computing, pp. 171–180.
ACM Press, New York (2000)
3. Antonatos, S., Akritidis, P., Markatos, E.P., Anagnostakis, K.G.: Defending against
hitlist worms using network address space randomization. In: WORM ’05: Pro-
ceedings of the 2005 ACM Workshop on Rapid Malcode, New York, NY, USA, pp.
30–40. ACM Press, New York (2005)
4. Broder, A., Kumar, R., Maghoul, F., Raghavan, P., Rajagopalan, S., Stata, R.,
Tomkins, A., Wiener, J.: Graph structure in the web. In: Proc. of the WWW9
Conference, Amsterdam, Holland, pp. 309–320 (2000)
5. Chen, S., Tang, Y.: Slowing down Internet worms. In: Proceedings of the 24th
International Conference on Distributed Computing Systems, Tokyo, Japan, March
2004, pp. 312–319 (2004)
6. Ellis, D., Aiken, J., McLeod, A., Keppler, D., Amman, P.: Graph-based worm
detection on operational enterprise networks. Technical Report MTR-06W0000035,
MITRE Corporation (April 2006)
7. Galil, Z., Italiano, G.F.: Data structures and algorithms for disjoint set union
problems. ACM Computing Surveys 23, 319–344 (1991)
8. Jung, J., Paxson, V., Berger, A.W., Balakrishnan, H.: Fast portscan detection us-
ing sequential hypothesis testing. In: Proceedings of the 2004 IEEE Symposium on
Security and Privacy, May 2004, IEEE Computer Society Press, Los Alamitos (2004)
9. Karagiannis, T., Papagiannaki, K., Faloutsos, M.: BLINC: multilevel traﬃc classi-
ﬁcation in the dark. In: Proceedings of ACM SIGCOMM ’05, New York, NY, USA,
pp. 229–240. ACM Press, New York (2005)
10. Kreyszig, E.: Advanced Engineering Mathematics, 9th edn. J. Wiley and Sons,
Chichester (2005)
Hit-List Worm Detection and Bot Identiﬁcation in Large Networks
295
11. Kumar, A., Paxson, V., Weaver, N.: Exploiting underlying structure for detailed
reconstruction of an Internet scale event. In: Proceedings of the ACM Internet
Measurement Conference, New Orleans, LA, USA, October 2005, ACM Press, New
York (2005)
12. Lakkaraju, K., Yurcik, W., Lee, A.: NVisionIP: NetFlow visualizations of system
state for security situational awareness. In: Proceedings of the 2004 Workshop on
Visualization for Computer Security (October 2006)
13. Pouwelse, J., Garbacki, P., Epema, D., Sips, H.: A measurement study of the
BitTorrent peer-to-peer ﬁle-sharing system. Technical Report PDS-2004-007, Delft
University of Technology (April 2004)
14. Ripeanu, M., Foster, I., Iamnitchi, A.: Mapping the gnutella network: Properties of
large-scale peer-to-peer systems and implications for system design. IEEE Internet
Computing 6(1) (2002)
15. Saroiu, S., Gummadi, P.K., Gribble, S.D.: A measurement study of peer-to-peer
ﬁle sharing systems. In: Proceedings of Multimedia Computing and Networking
2002, San Jose, CA, USA (2002)
16. Schechter, S., Jung, J., Berger, A.: Fast detection of scanning worm infections. In:
Jonsson, E., Valdes, A., Almgren, M. (eds.) RAID 2004. LNCS, vol. 3224, Springer,
Heidelberg (2004)
17. Sekar, V., Xie, Y., Reiter, M.K., Zhang, H.: A multi-resolution approach to worm
detection and containment. In: Proceedings of the 2006 International Conference
on Dependable Systems and Networks, June 2006, pp. 189–198 (2006)
18. Shannon, C., Moore, D.: The spread of the Witty worm. IEEE Security and Pri-
vacy 2(4), 46–50 (2004)
19. Singh, S., Estan, C., Varghese, G., Savage, S.: Automated worm ﬁngerprinting. In:
Proceedings of the ACM/USENIX Symposium on Operating System Design and
Implementation, December 2005, ACM Press, New York (2005)
20. Staniford, S., Paxson, V., Weaver, N.: How to 0wn the Internet in your spare
time. In: Proceedings of the 11th USENIX Security Symposium, August 2002, pp.
149–167 (2002)
21. Staniford-Chen, S., Cheung, S., Crawford, R., Dilger, M., Frank, J., Hoagland, J.,
Levitt, K., Wee, C., Yip, R., Zerkle, D.: GrIDS – A graph-based intrusion detec-
tion system for large networks. In: Proceedings of the 19th National Information
Systems Security Conference, pp. 361–370 (1996)
22. Stolfo, S.J., Hershkop, S., Hu, C., Li, W., Nimeskern, O., Wang, K.: Behavior-based
modeling and its application to email analysis. ACM Transactions on Internet
Technology 6(2), 187–221 (2006)
23. Tarjan, R.E.: Data Structures in Network Algorithms. Regional Conference Series
in Applied Mathematics, Society for Industrial and Applied Mathematics, vol. 44
(1983)
24. Twycross, J., Williamson, M.W.: Implementing and testing a virus throttle. In: Pro-
ceedings of the 12th USENIX Security Symposium, August 2003, pp. 285–294 (2003)
25. Wright, C., Monrose, F., Masson, G.: Using visual motifs to classify encrypted traf-
ﬁc. In: Proceedings of the 2006 Workshop on Visualization for Computer Security
(November 2006)
26. Yin, X., Yurcik, W., Treaster, M.: VisFlowConnect: NetFlow visualizations of link
relationships for security situational awareness. In: Proceedings of the 2004 Work-
shop on Visualization for Computer Security (October 2006)
27. Zou, C., Gao, L., Gong, W., Towsley, D.: Monitoring and early warning for Internet
worms. In: Proceedings of the 10th ACM Conference on Computer and Communi-
cations Security, New York, NY, USA, pp. 190–199. ACM Press, New York (2003)