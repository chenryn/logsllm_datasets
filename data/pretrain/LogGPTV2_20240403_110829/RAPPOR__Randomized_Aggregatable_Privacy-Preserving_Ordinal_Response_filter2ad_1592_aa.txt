title:RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response
author:&apos;Ulfar Erlingsson and
Vasyl Pihur and
Aleksandra Korolova
RAPPOR: Randomized Aggregatable Privacy-Preserving
Ordinal Response
Úlfar Erlingsson
Google, Inc.
PI:EMAIL
Vasyl Pihur
Google, Inc.
PI:EMAIL
Aleksandra Korolova
University of Southern California
PI:EMAIL
ABSTRACT
Randomized Aggregatable Privacy-Preserving Ordinal Re-
sponse, or RAPPOR, is a technology for crowdsourcing statis-
tics from end-user client software, anonymously, with strong
privacy guarantees. In short, RAPPORs allow the forest of
client data to be studied, without permitting the possibil-
ity of looking at individual trees. By applying randomized
response in a novel manner, RAPPOR provides the mecha-
nisms for such collection as well as for eﬃcient, high-utility
analysis of the collected data. In particular, RAPPOR per-
mits statistics to be collected on the population of client-side
strings with strong privacy guarantees for each client, and
without linkability of their reports.
This paper describes and motivates RAPPOR, details its
diﬀerential-privacy and utility guarantees, discusses its prac-
tical deployment and properties in the face of diﬀerent attack
models, and, ﬁnally, gives results of its application to both
synthetic and real-world data.
1 Introduction
Crowdsourcing data to make better, more informed deci-
sions is becoming increasingly commonplace. For any such
crowdsourcing, privacy-preservation mechanisms should be
applied to reduce and control the privacy risks introduced
by the data collection process, and balance that risk against
the beneﬁcial utility of the collected data. For this purpose
we introduce Randomized Aggregatable Privacy-Preserving
Ordinal Response, or RAPPOR, a widely-applicable, practi-
cal new mechanism that provides strong privacy guarantees
combined with high utility, yet is not founded on the use of
trusted third parties.
RAPPOR builds on the ideas of randomized response, a
surveying technique developed in the 1960s for collecting
statistics on sensitive topics where survey respondents wish
to retain conﬁdentiality [27]. An example commonly used
to describe this technique involves a question on a sensi-
tive topic, such as “Are you a member of the Communist
party?” [28]. For this question, the survey respondent is
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage, and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/authors. Copyright is held by the authors.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
ACM 978-1-4503-2957-6/14/11, http://dx.doi.org/10.1145/2660267.2660348.
asked to ﬂip a fair coin, in secret, and answer “Yes” if it
comes up heads, but tell the truth otherwise (if the coin
comes up tails). Using this procedure, each respondent re-
tains very strong deniability for any “Yes” answers, since
such answers are most likely attributable to the coin coming
up heads; as a reﬁnement, respondents can also choose the
untruthful answer by ﬂipping another coin in secret, and get
strong deniability for both “Yes” and “No” answers.
Surveys relying on randomized response enable easy com-
putations of accurate population statistics while preserving
the privacy of the individuals. Assuming absolute compli-
ance with the randomization protocol (an assumption that
may not hold for human subjects, and can even be non-
trivial for algorithmic implementations [23]), it is easy to
see that in a case where both “Yes” and “No” answers can
be denied (ﬂipping two fair coins), the true number of “Yes”
answers can be accurately estimated by 2(Y − 0.25), where
Y is the proportion of “Yes” responses. In expectation, re-
spondents will provide the true answer 75% of the time, as
is easy to see by a case analysis of the two fair coin ﬂips.
Importantly, for one-time collection, the above random-
ized survey mechanism will protect the privacy of any spe-
ciﬁc respondent, irrespective of any attacker’s prior knowl-
edge, as assessed via the -diﬀerential privacy guarantee [12].
Speciﬁcally, the respondents will have diﬀerential privacy at
the level  = ln(cid:0)0.75/(1 − 0.75)(cid:1) = ln(3). This said, this
privacy guarantee degrades if the survey is repeated—e.g.,
to get fresh, daily statistics—and data is collected multiple
times from the same respondent. In this case, to maintain
both diﬀerential privacy and utility, better mechanisms are
needed, like those we present in this paper.
Privacy-Preserving Aggregatable Randomized Response,
or RAPPORs, is a new mechanism for collecting statistics
from end-user, client-side software, in a manner that pro-
vides strong privacy protection using randomized response
techniques. RAPPOR is designed to permit collecting, over
large numbers of clients, statistics on client-side values and
strings, such as their categories, frequencies, histograms, and
other set statistics. For any given value reported, RAPPOR
gives a strong deniability guarantee for the reporting client,
which strictly limits private information disclosed, as mea-
sured by an -diﬀerential privacy bound, and holds even for
a single client that reports often on the same value.
A distinct contribution is RAPPOR’s ability to collect
statistics about an arbitrary set of strings by applying ran-
domized response to Bloom ﬁlters [5] with strong -diﬀerential
privacy guarantees. Another contribution is the elegant
manner in which RAPPOR protects the privacy of clients
from whom data is collected repeatedly (or even inﬁnitely
often), and how RAPPOR avoids addition of privacy exter-
nalities, such as those that might be created by maintain-
ing a database of contributing respondents (which might be
breached), or repeating a single, memoized response (which
would be linkable, and might be tracked). In comparison,
traditional randomized response does not provide any lon-
gitudinal privacy in the case when multiple responses are
collected from the same participant. Yet another contribu-
tion is that the RAPPOR mechanism is performed locally
on the client, and does not require a trusted third party.
Finally, RAPPOR provides a novel, high-utility decod-
ing framework for learning statistics based on a sophisti-
cated combination of hypotheses testing, least-squares solv-
ing, and LASSO regression [26].
1.1 The Motivating Application Domain
RAPPOR is a general technology for privacy-preserving data
collection and crowdsourcing of statistics, which could be
applied in a broad range of contexts.
In this paper, however, we focus on the speciﬁc application
domain that motivated the development of RAPPOR: the
need for Cloud service operators to collect up-to-date statis-
tics about the activity of their users and their client-side
software. In this domain, RAPPOR has already seen lim-
ited deployment in Google’s Chrome Web browser, where
it has been used to improve the data sent by users that
have opted-in to reporting statistics [9]. Section 5.4 brieﬂy
describes this real-world application, and the beneﬁts RAP-
POR has provided by shining a light on the unwanted or
malicious hijacking of user settings.
For a variety of reasons, understanding population statis-
tics is a key part of an eﬀective, reliable operation of on-
line services by Cloud service and software platform oper-
ators. These reasons are often as simple as observing how
frequently certain software features are used, and measuring
their performance and failure characteristics. Another, im-
portant set of reasons involve providing better security and
abuse protection to the users, their clients, and the service
itself. For example, to assess the prevalence of botnets or
hijacked clients, an operator may wish to monitor how many
clients have—in the last 24 hours—had critical preferences
overridden, e.g., to redirect the users’ Web searches to the
URL of a known-to-be-malicious search provider.
The collection of up-to-date crowdsourced statistics raises
a dilemma for service operators. On one hand, it will likely
be detrimental to the end-users’ privacy to directly collect
their information. (Note that even the search-provider pref-
erences of a user may be uniquely identifying, incriminat-
ing, or otherwise compromising for that user.) On the other
hand, not collecting any such information will also be to the
users’ detriment: if operators cannot gather the right statis-
tics, they cannot make many software and service improve-
ments that beneﬁt users (e.g., by detecting or preventing
malicious client-side activity). Typically, operators resolve
this dilemma by using techniques that derive only the nec-
essary high-order statistics, using mechanisms that limit the
users’ privacy risks—for example, by collecting only coarse-
granularity data, and by eliding data that is not shared by
a certain number of users.
Unfortunately, even for careful operators, willing to uti-
lize state-of-the-art techniques, there are few existing, prac-
tical mechanisms that oﬀer both privacy and utility, and
even fewer that provide clear privacy-protection guarantees.
Therefore, to reduce privacy risks, operators rely to a great
extent on pragmatic means and processes, that, for exam-
ple, avoid the collection of data, remove unique identiﬁers,
or otherwise systematically scrub data, perform mandatory
deletion of data after a certain time period, and, in gen-
eral, enforce access-control and auditing policies on data
use. However, these approaches are limited in their ability
to provide provably-strong privacy guarantees. In addition,
privacy externalities from individual data collections, such
as timestamps or linkable identiﬁers, may arise; the privacy
impact of those externalities may be even greater than that
of the data collected.
RAPPOR can help operators handle the signiﬁcant chal-
lenges, and potential privacy pitfalls, raised by this dilemma.
1.2 Crowdsourcing Statistics with RAPPOR
Service operators may apply RAPPOR to crowdsource statis-
tics in a manner that protects their users’ privacy, and thus
address the challenges described above.
As a simpliﬁcation, RAPPOR responses can be assumed
to be bit strings, where each bit corresponds to a randomized
response for some logical predicate on the reporting client’s
properties, such as its values, context, or history. (Without
loss of generality, this assumption is used for the remainder
of this paper.) For example, one bit in a RAPPOR response
may correspond to a predicate that indicates the stated gen-
der, male or female, of the client user, or—just as well—their
membership in the Communist party.
The structure of a RAPPOR response need not be other-
wise constrained; in particular, (i) the response bits may be
sequential, or unordered, (ii) the response predicates may
be independent, disjoint, or correlated, and (iii) the client’s
properties may be immutable, or changing over time. How-
ever, those details (e.g., any correlation of the response bits)
must be correctly accounted for, as they impact both the uti-
lization and privacy guarantees of RAPPOR—as outlined in
the next section, and detailed in later sections.
In particular, RAPPOR can be used to collect statistics on
categorical client properties, by having each bit in a client’s
response represent whether, or not, that client belongs to a
category. For example, those categorical predicates might
represent whether, or not, the client is utilizing a software
feature. In this case, if each client can use only one of three
disjoint features, X, Y , and Z, the collection of a three-bit
RAPPOR response from clients will allow measuring the
relative frequency by which the features are used by clients.
As regards to privacy, each client will be protected by the
manner in which the three bits are derived from a single
(at most) true predicate; as regards to utility, it will suﬃce
to count how many responses had the bit set, for each dis-
tinct response bit, to get a good statistical estimate of the
empirical distribution of the features’ use.
RAPPOR can also be used to gather population statis-
tics on numerical and ordinal values, e.g., by associating re-
sponse bits with predicates for diﬀerent ranges of numerical
values, or by reporting on disjoint categories for diﬀerent
logarithmic magnitudes of the values. For such numerical
RAPPOR statistics, the estimate may be improved by col-
lecting and utilizing relevant information about the priors
and shape of the empirical distribution, such as its smooth-
ness.
Finally, RAPPOR also allows collecting statistics on non-
categorical domains, or categories that cannot be enumer-
ated ahead of time, through the use of Bloom ﬁlters [5]. In
particular, RAPPOR allows collection of compact Bloom-
ﬁlter-based randomized responses on strings, instead of hav-
ing clients report when they match a set of hand-picked
strings, predeﬁned by the operator. Subsequently, those re-
sponses can be matched against candidate strings, as they
become known to the operator, and used to estimate both
known and unknown strings in the population. Advanced
statistical decoding techniques must be applied to accurately
interpret the randomized, noisy data in Bloom-ﬁlter-based
RAPPOR responses. However, as in the case of categories,
this analysis needs only consider the aggregate counts of
distinct bits set in RAPPOR responses to provide good es-
timators for population statistics, as detailed in Section 4.
Without loss of privacy, RAPPOR analysis can be re-run
on a collection of responses, e.g., to consider new strings
and cases missed in previous analyses, without the need to
re-run the data collection step. Individual responses can be
especially useful for exploratory or custom data analyses.
For example, if the geolocation of clients’ IP addresses are
collected alongside the RAPPOR reports of their sensitive
values, then the observed distributions of those values could
be compared across diﬀerent geolocations, e.g., by analyz-
ing diﬀerent subsets separately. Such analysis is compatible
with RAPPOR’s privacy guarantees, which hold true even
in the presence of auxiliary data, such as geolocation. By
limiting the number of correlated categories, or Bloom ﬁl-
ter hash functions, reported by any single client, RAPPOR
can maintain its diﬀerential-privacy guarantees even when
statistics are collected on multiple aspects of clients, as out-
lined next, and detailed in Sections 3 and 6.
1.3 RAPPOR and (Longitudinal) Attacks
Protecting privacy for both one-time and multiple collec-
tions requires consideration of several distinct attack mod-
els. A basic attacker is assumed to have access to a single
report and can be stopped with a single round of random-
ized response. A windowed attacker has access to multiple
reports over time from the same user. Without careful mod-
iﬁcation of the traditional randomized response techniques,
almost certainly full disclosure of private information would
happen. This is especially true if the window of observation
is large and the underlying value does not change much. An
attacker with complete access to all clients’ reports (for ex-
ample, an insider with unlimited access rights), is the hard-
est to stop, yet such an attack is also the most diﬃcult to
execute in practice. RAPPOR provides explicit trade-oﬀs
between diﬀerent attack models in terms of tunable privacy
protection for all three types of attackers.
RAPPOR builds on the basic idea of memoization and
provides a framework for one-time and longitudinal privacy
protection by playing the randomized response game twice
with a memoization step in between. The ﬁrst step, called a
Permanent randomized response, is used to create a “noisy”
answer which is memoized by the client and permanently
reused in place of the real answer. The second step, called an
Instantaneous randomized response, reports on the “noisy”
answer over time, eventually completely revealing it. Long-
term, longitudinal privacy is ensured by the use of the Per-
manent randomized response, while the use of an Instanta-
neous randomized response provides protection against pos-
sible tracking externalities.
The idea of underlying memoization turns out to be cru-
cial for privacy protection in the case where multiple re-
sponses are collected from the same participant over time.
For example, in the case of the question about the Commu-
nist party from the start of the paper, memoization can allow
us to provide ln(3)-diﬀerential privacy even with an inﬁnite
number of responses, as long as the underlying memoized
response has that level of diﬀerential privacy.
On the other hand, without memoization or other limita-
tion on responses, randomization is not suﬃcient to maintain
plausible deniability in the face of multiple collections. For
example, if 75 out of 100 responses are “Yes” for a single
client in the randomized-response scheme at the very start
of this paper, the true answer will have been “No” in a van-
ishingly unlikely 1.39 × 10−24 fraction of cases.
Memoization is absolutely eﬀective in providing longitudi-
nal privacy only in cases when the underlying true value does
not change or changes in an uncorrelated fashion. When
users’ consecutive reports are temporally correlated, diﬀer-
ential privacy guarantees deviate from their nominal levels
and become progressively weaker as correlations increase.
Taken to the extreme, when asking users to report daily on
their age in days, additional measures are required to pre-
vent full disclosure over time, such as stopping collection
after a certain number of reports or increasing the noise lev-
els exponentially, as discussed further in Section 6.
For a client that reports on a property that strictly alter-
nates between two true values, (a, b, a, b, a, b, a, b, . . .), the
two memoized Permanent randomized responses for a and
b will be reused, again and again, to generate RAPPOR re-
port data. Thus, an attacker that obtains a large enough
number of reports, could learn those memoized “noisy” val-
ues with arbitrary certainty—e.g., by separately analyzing
the even and odd subsequences. However, even in this case,
the attacker cannot be certain of the values of a and b be-
cause of memoization. This said, if a and b are correlated,
the attacker may still learn more than they otherwise would
have; maintaining privacy in the face of any such correlation
is discussed further in Sections 3 and 6 (see also [19]).
In the next section we will describe the RAPPOR algo-
rithm in detail. We then provide intuition and formal justi-
ﬁcation for the reasons why the proposed algorithm satisﬁes
the rigorous privacy guarantees of diﬀerential privacy. We
then devote several sections to discussion of the additional
technical aspects of RAPPOR that are crucial for its poten-