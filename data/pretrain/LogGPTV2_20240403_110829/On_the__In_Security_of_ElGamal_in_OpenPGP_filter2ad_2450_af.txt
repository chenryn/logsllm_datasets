Environment. We target the function _gcry_mpi_powm of the lat-
est version gcrypt shipped by Ubuntu 18.04.5 LTS. The function
implements the approach described in Figure 2. The implemen-
tation takes a few precautions against the attacker described in
Section 6.1 to avoid leaking sensitive data and instruction cache
accesses. In particular, it hides i) whether the operation at line 40
is a modular multiplication or squaring; and ii) whether, at line 39,
𝑊 is initialised with 𝑅 or with an entry from table 𝑇 (and in that
case, it also hides which position 𝑒𝑖 of the table is loaded). This
is accomplished by way of a conditional memcpy-like operations
(mpi_set_cond) that – depending on whether a flag argument is one
or zero – copies a source operand into a destination operand, or
leaves the destination operand unchanged. Masking is employed to
ensure that an attacker cannot learn the nature of the operation by
observing the control flow or changes to data or instruction cache.
Furthermore, the flag is set using branchless operations.
Despite these precautions, considerable leakage can still be ob-
tained by an attacker who can observe control flow dependent
cache perturbations: in particular, the full set of values 𝑐1, . . . , 𝑐𝐿
can be recovered by counting the number of iterations of the for
loop at line 38 for each of the iterations of the loop at line 36. The
attacker may obtain this information by monitoring the state of the
instruction cache line that contains code that is executed as part of
an iteration of the outer loop and not of the inner loop. In practice,
this can be achieved with the FLUSH+RELOAD side channel applied
on a line of the instruction cache that is executed once per outer
loop before the start of the inner one. The probe reveals when such
a cache line is executed, and the time between two probes would
depend on the execution time of the inner for loop. Crucially, the
latter depends on the set of values 𝑐1, . . . , 𝑐𝐿, which would thus be
leaked. This strategy is applicable to the _gcry_mpi_powm function:
the implementation inlines the logic to determine the 𝑐𝑖 values
between the start of the first and the start of the second loop and
so it fills more than one cache line; the invocation of the multipli-
cation in the inner loop makes one iteration sufficiently long and
constant-time so that inter-probe timings measurably encode the
number of iterations of the inner loop.
Figure 5: FLUSH+RELOAD attack using 10,000 decryption
operations with gcrypt’s modular exponentiation function.
a): number of samples with an icache hit on the target cache
line across all runs. b): histogram of the running times (tsc
count) for the operation. c) as a) but only considering sam-
ples whose total running time lies in the [2.25 · 106, 2.31 · 106]
interval. d) as a) but only considering samples whose total
running time lies in the [2.2 · 106, 2.25 · 106] interval.
Session 6D: Authentication and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2076Evaluation. To validate that the assumptions are correct, we pro-
totype an end-to-end attack in the SMT-colocated threat model. The
prototype uses two SMT-colocated processes, attacker and victim.
The victim process may be triggered by the attacker to perform
ElGamal decryption. We use Crypto++ to generate a 2048-bit ElGa-
mal instance as detailed in Section 5.4.2. The attacker process uses
L1i FLUSH+RELOAD on the virtual address of the memory-mapped
libgcrypt.so shared object that contains code that is executed by
the outer loop before the inner loop begins. To collect side channel
data, the attacker partitions time into 𝑁 slots using the rdtsc in-
struction: at the beginning of each slot, the target line is loaded into
the cache and the access time measured; after that, the cache line
is flushed and finally the remaining (if any) time of the slot is spent
in a busy loop. As we shall discuss later, we do not have to change
any of the settings that might influence the running time of the
operation (e.g. c/p states or Turbo Boost). The attacker thus collects
𝑁 timing samples for load instructions from the target cache line.
We establish a threshold for the target system to determine whether
the load is likely to have been served from cache (cache hit). We
then collect 10,000 measurements by repeatedly triggering the vic-
tim. We keep track of each slot across all runs with a set of per-slot
counters, all initialised to zero. For each run, whenever the sample
of a slot indicates a hit based on the threshold, we increment the
value of the corresponding counter.
Figure 5a plots the value of the counter of each slot for all runs.
While patterns are discernible, the leakage cannot be obtained
yet without further data processing. We employ a clustering strat-
egy based on execution time, under the hypothesis that Figure 5a
contains samples that are generated at different clock frequencies.
Influencing factors are likely to include p-states, c-states, frequency
scaling and the power state of certain execution units. Figure 5b
confirms the hypothesis: it plots a histogram of the running times
for the operation. The distribution of running times has a long tail,
but most of the mass is concentrated in the three peaks. We use this
information to cluster samples and show the results of the cluster-
ing in Figure 5c and Figure 5d, showing probes whose running time
falls in the interval covered by the highest, and second highest peak,
respectively. The peak intervals in the two latter figures accurately
encode the 𝑐𝑖 leakage for the key used in the exponentiation. The
two figures are identical modulo a scaling factor which depends
on the difference in running time. With the leakage thus obtained,
we refer back to Section 5.4.2 for a detailed description of how the
secret exponent is fully recovered.
6.3 Fixed window: the case of Go
Environment. We target the function expNNMontgomery in Go 1.15.
The function implements the approach of Figure 2, with 𝑤 = 4. The
algorithm performs a secret-dependent table access: in particular, in
line 13, the accumulator 𝑅 is multiplied by the variable 𝑊 , which is
the results of a lookup into table 𝑇 performed in line 12. The index
𝑒𝑖 used for the lookup is the integer representation of the 𝑖-th four
bits of the secret exponent. The table lookup leaves a cache-level
side effect which leaks the value of all 𝑒𝑖.
Evaluation. We prototype an end-to-end attack in the SMT colo-
cated threat model against a 2048-bit modulus. Attacker and victim
Figure 6: PRIME+PROBE attack using 10,000 decryption op-
erations with Go’s modular exponentiation function. Each
row represents one iteration of the loop at line 7 of Figure 2;
each column represents an L1 cache set. Lighter represents a
higher probe time.
run on two separate, SMT-colocated processes. The victim pro-
cess loads the private key, performs ElGamal decryption using the
golang.org/x/crypto/openpgp/elgamal package and returns the re-
sulting cleartext data. The code internally calls the expNNMontgomery.
The attacker process uses PRIME+PROBE on L1d to observe the
cache side-effects left by the table lookup and recover the secret
index 𝑒𝑖. Ideally, this could be achieved by conducting the priming
phase right after the start of each loop iteration (line 7 of Figure 2)
and the probing phase right before the end of each loop iteration
(line 13 of Figure 2). Achieving this in practice from a separate
(though colocated) attacker process poses a set of challenges which
we analyse here. The first challenge is how to synchronise the
probes. Clearly it is impossible to practically achieve the ideal prob-
ing scenario described above, if anything because the victim cannot
be made to wait until the priming and probing loops of the attacker
complete. It is possible however to space them out – by busy wait
and invocations of rdtsc – so that the priming begins as closely as
possible to the start of the victim loop and the probing completes
as closely as possible to the end of the victim loop. According to
the assumptions of the threat model, the attacker can trigger the
victim and so it is able to synchronise the first probe. The correct
inter-probe delays to achieve the desired scheduling can be deter-
mined by profiling the execution of the victim. Running times in
modern CPUs however are not only affected by scheduling but
also by microarchitectural considerations such as temperature and
load. Consequently, the attacker must build not one but a set of
probing schedules, where each schedule has an associated victim
running time. The attacker then chooses one to perform the attack
and determines whether it is the appropriate one by comparing the
running time of the victim with the running time associated with
the chosen probing schedule. Whenever the schedule is not appro-
priate, the gathered sample has to be discarded, and the choice of
probing schedule must be corrected. The first loop must be treated
differently since the code is optimised to avoid the first 𝑤 squarings.
This means that the priming phase for the first operation must be
conducted ahead of the start of the loop.
Another issue stems from the fact that the running time of the
probe is roughly comparable to that of the multiplication operation
Session 6D: Authentication and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2077of line 13. This causes a noisy signal from the side channel since
not every probe is guaranteed to observe the instructions that load
the table entry. This issue is addressed by probing only half of the
cache sets, thus ensuring that load operations (which take place
close to the beginning of the multiplication) are always observed.
The set of excluded cache sets may be varied across runs to obtain
data for the missing ones.
We then collect 10,000 sample sets by repeatedly triggering the
victim. The attacker collects PRIME+PROBE data for the 64 iter-
ations of the loop. Priming and probing phases make use of the
pointer chasing and doubly-linked list to permit bi-directional tra-
versal described in by Tromer et al. [34] to minimise the effect of
prefetching. Figure 6 shows the results of the attack. The pixel array
has one row per loop iteration and one column per monitored cache
set (odd cache sets were excluded). Each cell displays the result of
the probe during the row’s iteration and the column’s cache set.
Lighter shades of grey mean a longer probing time for the cache set,
implying that it was accessed by the victim. The value of each row
is obtained by subtracting, from each sample, the average timing of
the cache set and then averaging the results. As we can see, patterns
are visible and we were able to verify that they correspond to the
indices 𝑒𝑖 for the considered exponent. At this point, if the attacker
knows the virtual addresses of the table entries, the value of the
secret exponent is leaked in full. Otherwise, the attacker knows
the pairwise equality of all four-bit sequences of the exponent (e.g.
with reference to Figure 6, that the four-bit sequence at position 59
is equal to that at position 61). This knowledge restricts the search
space for the exponent to the set of permutations of 16 symbols,
which has size 16! ≈ 244 and can be fully explored by a trivial
to parallelize exhaustive search easily done on commodity hard-
ware. Note that this complexity is independent from the size of the
modulus or the length of the secret exponent.
In our experiment we assume a short-lived victim process that
terminates after decrypting. We verify that for short-lived processes,
the absence of ASLR in Go coupled with the deterministic nature
of the allocator ensures that virtual addresses (and hence cache
sets) hosting the table 𝑇 are constant across runs. If the victim
application is long-lived however, the actual cache sets hosting
table entries may vary across runs since the table is allocated in the
course of each decryption. While this is clearly outside of the scope
of this work, we highlight here two strategies for the attacker: the
first one is to force the allocator into a specific state so that the table
is allocated on the same cache sets. We verify that this is not hard
to achieve since the attacker is afforded a high degree of control
over garbage collector triggers (time and heap consumption) and
allocation triggers caused by interacting with the victim. The other
strategy is to collect all samples and cluster them according to the
cache set layout of the table during the run.
7 CONCLUSIONS
We analyse one of the oldest, best understood and most historically
used asymmetric encryption schemes, ElGamal [14]. We reveal that
despite its popularity and longevity, when we speak about ElGamal
we are referring to several different flavours of it, with key choices
being left at the discretion of vendors and implementers. We show
how some of these choices create interoperability challenges that
lead to insecurity. We propose two “cross-configuration” attacks
that are attributable to different, and – from a security standpoint
– incompatible, configurations that operate together in the inter-
connected OpenPGP ecosystem. We believe our work can improve
the security of the OpenPGP community and influence the new
revision of the standard that is being drafted at the time of writing.
ACKNOWLEDGEMENTS
The authors would like to thank Werner Koch, Anil Kurmus, Yu-
taka Niibe and Filippo Valsorda for the discussions and feedback,
and the CCS’21 reviewers for their comments that helped us im-
prove the paper. This work received funding from the EU Horizon
2020 research and innovation programme under grant agreement
No 786725 OLYMPUS.
DISCLOSURE
We reached out to the OpenPGP users whose keys produce weak
ciphertexts to encourage revoking the affected subkey. The iden-
tities of the vulnerable users (which are known since most users
register OpenPGP keys associated to an email address) have been
kept on a server to which only the authors have access. Physical ac-
cess to that server is restricted. We have also informed the affected
vendors (gcrypt, Go and Botan) about the cross-configuration and
side-channel attacks. As a consequence, gcrypt (commit 632d80ef3)
and Botan (commit 9a23e4e3b) were patched to forbid the usage
of short encryption randomness. CVE-2021-33560 was issued to
track the side-channel vulnerability in gcrypt, and CVE-2021-40528,
CVE-2021-40529 and CVE-2021-40530 were issued to track the impact
of cross-configuration attacks in the various libraries.
REFERENCES
[1] 2018. CVE-2018-6594. https://www.cvedetails.com/cve/CVE-2018-6594/.
[2] 2018. CVE-2018-6829. https://www.cvedetails.com/cve/CVE-2018-6829/.
[3] 2021. OpenPGP server key dump from 15/01/2021. https://pgp.key-server.io/
dump/. [Online; accessed 15/01/2021].
[4] Onur Aciiçmez, Çetin Kaya Koç, and Jean-Pierre Seifert. 2007. Predicting Secret
Keys Via Branch Prediction. In CT-RSA 2007 (LNCS, Vol. 4377), Masayuki Abe
(Ed.). Springer, Heidelberg, 225–242. https://doi.org/10.1007/11967668_15
[5] Gorka Irazoqui Apecechea, Thomas Eisenbarth, and Berk Sunar. 2015. S$A: A
Shared Cache Attack That Works across Cores and Defies VM Sandboxing - and
Its Application to AES. In 2015 IEEE Symposium on Security and Privacy. IEEE
Computer Society Press, 591–604. https://doi.org/10.1109/SP.2015.42
[6] Gorka Irazoqui Apecechea, Mehmet Sinan Inci, Thomas Eisenbarth, and Berk
Sunar. 2014. Wait a minute! A fast, Cross-VM attack on AES. IACR Cryptol. ePrint
Arch. 2014 (2014), 435. http://eprint.iacr.org/2014/435
[7] Alessandro Barenghi, Alessandro Di Federico, Gerardo Pelosi, and Stefano San-
filippo. 2015. Challenging the Trustworthiness of PGP: Is the Web-of-Trust
Tear-Proof?. In ESORICS 2015, Part I (LNCS, Vol. 9326), Günther Pernul, Pe-
ter Y. A. Ryan, and Edgar R. Weippl (Eds.). Springer, Heidelberg, 429–446.
https://doi.org/10.1007/978-3-319-24174-6_22
[8] Daniel J. Bernstein. 2005. Cache-timing attacks on AES. Technical Report.
[9] Daniel Bleichenbacher. 1996. Generating ElGamal Signatures Without Knowing