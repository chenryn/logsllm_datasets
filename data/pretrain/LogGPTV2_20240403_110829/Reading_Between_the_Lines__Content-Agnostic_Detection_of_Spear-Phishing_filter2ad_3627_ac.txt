Known domain
Known sender
Algorithm kNN
SVM
kNN
SVM
kNN
SVM
Metric
FPR TPR FPR TPR FPR TPR FPR TPR FPR TPR FPR TPR
0.01% 90.9% 0.01% 92.4% 0.01% 72.7% 0.01% 78.1% 0.01% 48.1% 0.01% 30.1%
0.1% 90.9% 0.1% 92.4% 0.1% 72.7% 0.1% 78.2% 0.1% 48.2% 0.1% 30.2%
1% 91.1% 1%
92.5% 1%
73.7% 1%
79.3% 1%
48.9% 1%
30.4%
10% 91.9% 10% 92.9% 10% 78.4% 10% 84.1% 10% 53.2% 10% 33.9%
Fig. 7. ROC curves for the classiﬁcation of legitimate emails versus emails spoofed by
attackers with diﬀerent levels of knowledge.
from the domain of the spoofed sender by a diﬀerent sender to other recipients.
Finally, we select emails sent by the spoofed sender to diﬀerent recipients to
built the spoofed test set in the evaluation of the known sender attack.
During testing, we expect a legitimate email to be assigned to its true class
by the classiﬁer. On the contrary, a spoofed email should be assigned to any
of the other classes, resulting in a mismatch between the sender address from
which the email is sent and the output of the classiﬁer. There exists thus a trade-
oﬀ between the probability of detecting a spoofed email and the probability of
wrongly highlighting a legitimate email as spoofed. The ROC curves depicted
in Fig. 7 show the trade-oﬀ between the false-positive rate and the false-positive
rate for both classiﬁers.
If the attacker lacks any knowledge about the spoofed sender, we observe
that the kNN and SVM classiﬁers can identify a spoofed email with a true-
positive rate of 90.9% and 92.4% respectively at a low false-positive rate of
0.01%. If the attacker has access to emails originating from the same domain,
the performance decreases to 72.7% and 78.1% but the classiﬁer is still able to
eﬀectively operate at the same low false-positive rate. In the worst-case scenario,
the attacker has enough information to craft an email that resembles the learned
Content-Agnostic Detection of Spear-Phishing Emails
83
Fig. 8. Area under the ROC curve as a function of the number of training emails used
to learn each sender’s individual proﬁle.
proﬁle of the spoofed sender, which causes the performance of the classiﬁer to
deteriorate considerably. Table 3 speciﬁes numerically the detection achieved at
0.01%, 0.1%, 1% and 10% of false-positive rate for both classiﬁers in all scenarios.
As mentioned above, we set a lower threshold for the minimum number of
emails required to train an SVM classiﬁer. However, as shown in Fig. 3 a larger
number of emails above this threshold is available for many senders. Figure 8
shows in each scenario the relation between the number of emails from a sender
used to train the classiﬁer and the AUC averaged over all mailboxes and senders.
As described in Sect. 4.1, sender proﬁles tend to be more compact with an
increasing number of emails. However, this can aﬀect the performance diﬀer-
ently depending of the knowledge available to the attacker. For instance, in
threat scenarios (a) and (b), emails are classiﬁed with an AUC over 0.85 with a
small number of training samples. Spoofed emails lay here far enough from the
sender proﬁle, leading to a stable or increased performance when classes becomes
more populated. In particular, the SVM classiﬁer oﬀers a better performance at
a low number of available emails, while with an increasing training size, the kNN
classiﬁer surpasses the SVM.
On the contrary, in threat scenario (c)
the attacker is always able to craft an
email that resembles the proﬁle of the
spoofed sender, while a larger number of
training samples increases the variabil-
ity of the sender proﬁle. As each spoofed
email lay very close or within the tar-
get class, it becomes more diﬃcult for the
classiﬁer to correctly separate legitimate
emails from spooﬁng attempts when the
sample size increases. A possible approach
in such a high risk scenario, is to operate
the classiﬁer at a higher FPR point and to
retrain the model more often on a smaller
sample of the most recent emails received
Fig. 9. Distribution of scores per group
of traits as learned by the linear SVM
classiﬁer during training.
84
H. Gascon et al.
from each sender. Finally, the use of a linear SVM for classiﬁcation allows us
to study how the learning algorithm assigns diﬀerent weights to each type of
features according to its importance for the classiﬁcation. To this end, we deter-
mine the distribution of the normalized SVM weights and group them by trait
types. In Fig. 9, we can observe that, in comparison with behavior and composi-
tion features, transport related features manifest both a smaller dispersion and a
larger inﬂuence on the decision of the classiﬁer. Consequently, transport features
have the most discriminative power and, at the same time, are the most diﬃcult
traits to forge as even a skilled adversary is not able to fully control transport
features without having access to the same delivery infrastructure of the sender.
5 Discussion and Limitations
The evaluations in the previous section show that our method is capable of
reliably discriminating thousands of senders and identifying spoofed emails if
the attacker has limited knowledge of the email structure. Due to the problem
setting of detecting spooﬁng at the receiving side, however, our approach has
some inherent limitations which are discussed in the following.
Advanced Forgery. Although spear-phishing and other targeted email attacks
today focus on the forgery of visible features like the sender address, the subject
and the content of an email to mimic trustworthy emails [18,26], we likely have
to deal with more advanced attacks in the near future. If current attacks are no
longer successful because of increased user awareness and detection approaches
like ours, attackers will adapt their techniques. For our method, the best strat-
egy for evasion is to forge as many features from the original sender as possible.
An almost perfect forgery is thus a copy of an original mail including also its
true transport features as observed by the recipient and enriched with some
malicious content. However, the attacker needs to take care of several traits
that our method inspects, such as timestamps, IP addresses in received headers
and characteristics of the attachment. In the worst case, the attacker is able to
forge all of these details and hence the only indication of a spoofed email are
minor inconsistencies between IP addresses and hostnames. Our method fails
in this scenario, as only a few features diﬀer from the sender model. Nonethe-
less, the acquisition of emails from a sender and acquiring access to the senders
delivery infrastructure to control the transport features, clearly raise the bar for
conducting spear-phishing attacks. Therefore and with the current lack of alter-
native protection approaches, our approach is a valuable extension to current
defenses.
Privacy and Feature Extraction. We have implemented the feature extraction in
a privacy-friendly way in that all sensitive information of sender, transport and
recipients is only stored in an anonymized form by using a hash with random
salt. Only these anonymized features are kept and used in the initial creation
or retraining of the model. This makes it possible to implement the system for
Content-Agnostic Detection of Spear-Phishing Emails
85
example in a security appliance which receives all feature vectors for analysis but
does not store the mails. This also means, however, that the model cannot be
simply extended with new features and retrained with old data, since the original
mail as input for feature extraction is no longer available. Feature extraction is
therefore performed locally in every case. Although this limits how anonymized
data from diﬀerent sources can be combined for analysis, the recipient’s email
information never leaves the local machine, avoiding privacy issues and possible
attack vectors.
Mislabeled Data. The possibility of the training data containing spoofed emails
should not be ignored. However and due to their very nature, the prevalence of
spear-phishing emails can only be very low within all emails sent to a recipient.
This problem, known as label noise (see [8]), entails that training samples can
be considered subjected to an additive noise during training with a probability
of their labels being ﬂipped. In our setup, however, such probability will be very
low and the eﬀect during testing of such infrequent examples, while existent, will
be negligible.
6 Related Work
The detection of unwanted and malicious emails is a well-established problem in
security research. Several methods have been devised in the last years that are
related to our approach and which we brieﬂy discuss in the following.
For instance, several approaches exist that focus on the content of emails and
the style in which they are writtenx (e.g. [10,17,33]). The assumption behind
these features is that the writing style of one sender diﬀers signiﬁcantly from
another and that it is too hard for the attacker to write a mail in the same style
as the sender she is trying to spoof. The implementation of such content-based
features can be as simple as using a 5-gram tokenizer [27] but can also be more
complex and include character distributions, atypical words or more advanced
stylometric features [10,17,33]. In many cases, these stylometric features are used
in combination with further behavioral features, such as the time of writing.
While these approaches potentially provide a good detection of spoofed
emails, they present two problems. First, if text from the original sender is
available from any source stylometric traits can be easy to forge and second
such approaches require suﬃcient data to infer minor diﬀerences in stylometry
and can be computationally expensive. As a consequence, previous work often
operates with small datasets. For example, Lin et al. [27] conduct an evaluation
with only 6 senders due to a lack of available data. Similarly, Duman et al. [10]
discriminate only 215 senders in their experiments. Whether these techniques
can be scaled to cover thousands of senders is unclear and thus the application
stylometric features for spear-phishing detection is still an open issue.
The problem of limited learning data is addressed by Stringhini and Thon-
nard [33] who propose a detection approach that, while also relying on email
content, is capable of analyzing larger datasets. However, their method requires
86
H. Gascon et al.
a minimum of 1,000 emails per sender to be eﬀective. Moreover, they position
the defense at the sender’s server and require to include emails from diﬀerent
mailboxes to build a reliable behavioral proﬁle of a user. Such an approach
is orthogonal to our method which operates at the recipient’s side, who only
requires the information contained in her own mailbox to build an eﬀective
defense. Furthermore, recipient related features are based on the idea that dif-
ferent recipients have diﬀerent risk to get spear-phishing mails. Such features are
proposed by Amin [1] which determine the amount of information returned by
a search engine about a recipient and how often a person has received malicious
mails in the past. Unsurprisingly, the latter turns out to be a dominant feature,
i.e., those senders who got attacked in the past a lot will probably also get a lot
attacked in the future.
As in our work, infrastructure related features commonly include properties
of the transport like the senders IP address or her geographic location [17,27].
But also features of the used mail client belong in this category since a sender
will usually use only a single or few email clients. Features related to the infras-
tructure are often similar for all senders in the same domain which can be used to
increase model accuracy when only a few mails from a speciﬁc sender are avail-
able. Compared to stylometric features, infrastructural features do not model
the actual author but only her environment. Therefore, it is impossible to detect
a hacked account with these features. On the other hand infrastructural features
need less training data to create a well-performing model. Thus, it might be
useful to combine the strength of both approaches. Structural based features,
instead of content based features are the dominant ones in our evaluation. Such
features were already used by Amin [1]. Contrary to this work, our approach
makes use of a larger set of features from the mail client and from its transport
and is based on distinguishing diﬀerent senders based on these features instead
of globally distinguishing all spear-phishing mails from all benign mails.
Finally, a method recently proposed by Ho et al. [19] focuses on the identi-
ﬁcation of credential phishing and is designed to identify attacks from unseen
senders. Our approach is orthogonal to this work, as it addresses two of its main
shortcomings: First, Ho et al. [19] consider the problem of address spooﬁng irrel-
evant due to the availability of DKIM and DMARC. Our empirical analysis,
however, shows that both techniques are not widely available in practice and
thus alternative methods are needed. Furthermore, DKIM and DMARC need
to be implemented at the sending side, which enables the attacker to choose a
known sender with lacking support for this security feature. Second, the pro-
posed method requires the victim to interact with the phishing email by clicking
on a link. This poses a serious security risk and may result in the victim’s host
being compromised before the attack is actually detected. Our approach does
not require interaction and can block phishing attacks before they reach their
victim, for example, by removing links and attachments from emails.
Content-Agnostic Detection of Spear-Phishing Emails
87
7 Conclusions
In this paper, we show that a sender leaves several traits in the structure of
an email, resulting from her personal preferences, email client and infrastruc-
ture. Based on these traits, we present a detection method that is capable of
learning proﬁles for senders and identifying impersonated emails without relying
on its content or server-side implementations. In an empirical evaluation with
over 17,000 senders, we demonstrate that this method can identify over 90% of
spoofed emails with less than 1 false alarm in 10,000 emails, if the attacker has
no knowledge of the sender’s proﬁle. If the attacker has access to emails from the
same domain as the spoofed sender our method still attains a detection rate of
72% and thus raises the bar for an adversary to eﬀectively complete a spooﬁng
attack. Although our approach cannot detect an attack by an adversary with
vast resources, it provides a strong protection from attackers that are not able
to obtain original emails from a speciﬁc sender. In practice, our approach thus
provides a valuable tool for fending oﬀ spear-phishing attacks that would go
unnoticed without a proper anti-spooﬁng detection.
A Appendix
Tables 4, 5 and 6 provide an overview of the diﬀerent traits characterizing the
behavior, composition and transport of emails, respectively.
Table 4. List of behavior features.
Identiﬁer
Cardinality Description
attachment-
type
n
hdr-empty n
hdr-local-
domain
hdr-
related-
mails
hdr-count
hdr-x
msgid
reply-to
resent
return-
path
text-
quoted
frompart
from
n
n
n
n
n
n
1
n
1
n
n
Type of attachment
Headers with empty values
Headers indicating local
domains
Headers indicating relation to
other emails
Number of standard headers
and their values
Occurrences of non-standard
headers
Structural description of
Message-Id header
Hashed sender in Reply-To
header
Headers indicate redistribution
Sender in Return-Path
header
Ratio of quoted total text in
main part
2-grams of From ﬁeld
Multiple senders in From
header
Examples
attachment-type(image)
hdr-empty(cc)
hdr-local-domain(to:D0)
hdr-related-mails(subject:re)