  2/Isolate/security(audit,redirect,mirror,quaran;ne) Fig. 5: System Components
Fig. 7: Data Plane
Status message and the equivalent status of a virtual interface
is reported to the controller seamlessly. As a safeguard, a
ﬁngerprint of the key used to sign the package may be sent
to the PBS CONTROLLER for the purpose of application
validation, which allows for discerning of possible duplicate
identiﬁers which may arise from the application-level informa-
tion extraction.
Data Plane is the forwarding fabric that manages ﬁne-
grained ﬂows inside PBS-DROID. The functionality of the
Data Plane stems from its maintenance of ﬂow tables which
contain ﬂow rules, which are used for the enforcement of
access control logic as shown in Figure 7. The internal bridge
(layer-2 interface) is linked to the local network stack and
contains both physical and virtual interfaces in order to capture
layer 2 frames. When an interface receives packets, the Data
Plane checks the ﬂow table for matching ﬂow entries. If
there is a match (from layer 2), it executes the corresponding
actions (e.g., forwarding, drop, controller); otherwise, a new
ﬂow request message is sent to the controller for further ﬂow
decision making. We have two types of ﬂow tables to store
ﬂow entries, one in user space and the second in kernel
space. The kernel space table supports fast match lookups
via a kernel cache, while userspace table allows full match
lookups using a proactive tuple space search. Besides the
normal packet processing from a physical network interface,
an additional mechanism for handling application-aware ﬂows
through application-speciﬁc virtual interface is required. This
is because in order for packets from an application to pass
through the corresponding virtual interface, we must hook
the packets before they reach layer 2 and forward them
to the corresponding interface. Here, we utilize netﬁlter to
hook packets after the local network stack completes packet
processing. To do so, we install the netﬁlter hook inside the
data plane and capture the packets at NF POST ROUTING
level. When a packet is hooked, we extract a UID from the
socket buffer (struct sk buff ) and look up a matching package
name and UID. Then, we forward it to its mapped virtual
interface through the mapper which is generated in the Data
Plane via the abstraction layer. The operation is done by
redirecting the netdev pointer of sk buff in the kernel module.
This mechanism enables us to forward an application packet
to the virtual interface in a much faster and more effective
way than using the standard user-space network commands
such as ip, route. On the other hand, the reverse direction of
a packet from the network interface to an app is managed by
the controller by using a ﬂow rule. The application-aware ﬂow
Fig. 6: Application Abstraction Layer
1) Enabling Fine-grained Access Control: In order to pro-
vide application-aware ﬂow control with layer 2 granularity,
we present an Abstraction Layer and Data Plane as shown in
Figure 5.
two roles:
Abstraction Layer serves
(1) collecting
application-level semantics for PBS CONTROLLER, (2) adopt-
ing application-level control logic from PBS CONTROLLER.
For application-level semantics, we obtain a user identiﬁer
(UID), a package name for each application on a device,
which is extracted from the Android PackageManager at
the framework layer as shown in Figure 6. The UID serves
the purpose of identifying application ﬂows, this is because
the ﬂow-connection-information is not correlated with other
application unique identiﬁcation information. The package
name identiﬁes an application by name, however it is a long
character string and sending such a long name in a packet may
unnecessarily reduce system performance. Thus, we employ a
hashing mechanism to convert the string to an unsigned integer.
The UID and package name hash are then sent to the Data
Plane for further processing.
Upon receipt of the arbiter message containing the UID
and package name hash, the Data Plane creates an internal
virtual interface using another hash value, calculated from the
concatenation of the UID and package name hash. The virtual
interface is then added to the bridge of the datapath, via the
standard Linux function. Thereby, the bridge-registered virtual
network interface name uniquely ties both the Android package
name and the Linux network stack connection ﬂow. When the
status of an application changes, App Status Checker sends the
change of states to the Data Plane and the status is interpreted
to the status of corresponding virtual interface accordingly.
This abstraction scheme enables us to treat an application-
speciﬁc virtual interface as a normal network port with great
ease. That is, application attributes are informed to the con-
troller during a secure connection handshake through a Port-
6
App	
  1	
   App	
  2	
   App	
  n	
   … WiFi 3G/4G … Data	
  Plane Management	
  Plane vin.	
  1	
  vin.	
  2	
  vin.	
  n	
  Arbiter Control	
  Channel Policy	
  Table … PBS-­‐Droid … Applica?on	
  Abstrac?on	
  Layer	
  Flow	
  Table … NICs	
  Package	
  Manager Android	
  Framework	
  App	
  ID	
  Translator vIn:	
  1 vIn:	
  2 … vIn:	
  n App	
  Status	
  Checker … PBS-­‐Droid Map	
  App	
  to	
  vInf Event-­‐driven	
  Port	
  Status	
  Equivalent 	
   Data	
  Plane 	
  Flow	
  Rules	
   dl_src,	
  … … Match Ac1on vinf1	
  vinf2	
  wiﬁ	
  Local	
  Network	
  Stack Bridge	
  (internal)	
  App	
  1	
   App	
  2	
   App	
  n	
   … … vinfn	
  Flow	
  lookup 3G/4G	
  … Packets Hook	
  MUX	
  ID	
  App-­‐ﬂow	
  Slicing Fig. 8: Policy Registration in Management Plane
TABLE I: Policy Protocol
Type Direction
Message
OFPT FEATURE REPLY OF
OFPT PORT STATUS
OF
PBS REGISTER POLICY PBS To Device
PBS REMOVE POLICY PBS To Device
PBS To Device
PBS MODIFY POLICY
PBS REPORT
PBS From Device Result, Info
Description
From Device Device Info
From Device App Status
Add Policy
Remove Policy
Modify Policy
management scheme provides an application-ﬂow slicing by
the controller so that app-ﬂows can be easily isolated among
applications by the ﬂow rule.
2) Enforcing Dynamic Context-Aware Policy: In this sec-
tion, we describe the Management Plane which facilitates en-
terprise policy storage, device context update lookup, and PBS
CONTROLLER communication. It consists of three components
residing on the mobile device: Policy Engine, Arbiter, and
Control Channel.
The Policy Engine maintains an administrator-deﬁned pol-
icy table on the mobile device. Note that entries in the table are
not speciﬁed by user, instead they are composed by the PBS
CONTROLLER from our High-Level Policy Language (shown
in Figure 10) discussed in Section III-E. Each composed
entry in the policy table consists of three parts: predicates,
actions, and a match ﬁeld. Predicates are a set of multiple
conditions separated by conjunction, e.g., time is noon and
location is building a. Actions are associated with ﬂow rules
for policy enforcement. For example, an action may modify the
corresponding ﬂow rule or packet header ﬁelds in Data Plane
to redirect, mirror, or quarantine the ﬂow. This scheme allows
us to tightly couple a ﬂow with a user-context based policy,
which is not supported by existing SDN/OpenFlow. Lastly, a
match ﬁeld is used to identify policy to ﬂow rule associated.
The match ﬁeld allows a wildcard in order for multiple ﬂows
to be associated with a single common/global policy entry,
which saves the size of the policy table.
The Arbiter provides the function to retrieve Android
device context, which is done in real time by listening to
predeﬁned PBS-DROID relevant events, detailed in Table II.
The Arbiter serves the function of monitoring device speciﬁc
context updates and sending them to the Policy Engine. When
a policy entry predicate is satisﬁed with a context event, the
corresponding policy action is carried out. Figure 8 depicts
the procedure of the policy registration from Control Plane to
Management Plane via the Arbiter. The Arbiter not only causes
the Policy Engine to perform ﬂow-control actions in response
to context changes, but triggers the engine to notify the PBS
CONTROLLER of device contexts according to the policy via
the control channel.
7
Fig. 9: PBS CONTROLLER Flow Diagram and Interfaces
The control channel facilitates the secure communication
between the Management Plane and PBS CONTROLLER. The
connection is secured via SSL/TLS and serves two purposes.
First, the control channel allows for basic OpenFlow protocol
messages, such as ﬂow rule updates and controller decision
queries. Second,
the control channel processes our policy
protocol (as shown in Table I) allowing bi-direction commu-
nication between the controller and PBS-DROID for policy
management. The protocol borrows from OpenFlow in its
design, directly utilizing two existing OF messages without
modiﬁcation and adding four new PBS speciﬁc messages. This
is because we encode application information into the virtual
interface port name, feature reply and port status messages
allow us to query for the port name and status respectfully,
yielding application information transparently.
E. PBS CONTROLLER
In this section, we describe the PBS CONTROLLER which
provides a central programmable interface to the network ad-
ministrator. Our controller design involves utilizing an existing
SDN controller with new extensions, detailed as follows.
Network Programmability. As previously stated in Sec-
tion III-C, the controller provides functions via Northbound
APIs for network-ﬂow and policy management. These API
function calls are coded into the BYOD application in the
controller implementation language (e.g., Java). The resulting
application allows for modiﬁcation and enforcement of net-
work policies and actions in real time when it is loaded by
the controller. The power of our application stems from its
ability to use the controller APIs with high level language
and all of its features. Thereby, an administrator can utilize
sophisticated programming techniques to create intricate and
dynamic network policy enforcement applications. The po-
tential of such extensions is vast. For example, a network
behavior learning application can levy existing techniques such
as machine learning in order to more effectively police the
network.
In order to provide convenient facilities for BYOD ap-
plication development in the enterprise, PBS CONTROLLER
consists of three high-level components: (i) OF Channel,
(ii) Core, and (iii) Admin. OF Channel establishes a secure
channel to PBS-DROID. The Core component contains Flow
Manager and Policy manager to handle ﬂows and policies.
The Admin component includes an enterprise policy storage
database, Statistics/Context Trigger to manage device infor-
mation, statistics, and contexts as well as controller BYOD
policy applications. Figure 9 illustrates the ﬂow diagram and
interfaces of PBS CONTROLLER. OpenFlow/PBS messages
   Data	
  Plane 	
   Management	
  Plane Arbiter 1.	
  Condi)on	
  deﬁni)ons	
  per	
  app Control	
  Channel Policy	
  Engine	
   Time,	
  Loc,	
  Port, … Predicates Ac2ons Flow	
  Rules	
   … Match Link Control	
  Plane 1.	
  Deﬁne	
  a	
  policy	
  per	
  ﬂow 2.	
  Send	
  a	
  policy 3.	
  Register	
  a	
  policy Ac2on 4.	
  Associate ﬁlter	
  match OF	
  Channel OpenFlow	
  messages Messages PBS	
  messages Core Flow	
  Manager Policy	
  Manager BYOD	
  App Admin Policy Stat/Context	
  Trigger 1.	
  Parse	
  a	
  message 2.	
  Deliver	
  a	
  message	
  and	
  provide	
  interfaces 3.	
  Manage	
  ﬂows	
  &	
  policies	
   TABLE II: Events Tracked by PBS-DROID Arbiter
Description
When applications and NICs up/down is modiﬁed.
When a device enters/leaves a speciﬁc area according to the policy.