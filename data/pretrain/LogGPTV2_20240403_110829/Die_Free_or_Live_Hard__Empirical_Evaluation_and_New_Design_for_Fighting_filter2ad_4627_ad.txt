0.6
0.4
0.2
e
t
a
R
n
o
i
t
c
e
t
e
D
RF
DT
BN
DE
1
0.8
0.6
0.4
0.2
e
r
u
s
a
e
M
−
F
RF
DT
BN
DE
0
A
B
Feature Set 
C
D
0
A
B
Feature Set 
C
D
0
A
B
Feature Set
C
D
(a) False Positive Rate
(b) Detection Rate
(c) F-Measure
Fig. 4. Performance comparison with the existing approaches
As seen in Fig. 4, our approach outperforms existing work. Speciﬁcally, from
Fig. 4(a), we can ﬁnd that the false positive rates of our work under three machine
learning classiﬁers (RF, DT and BN), are the lowest and the false positive rate of
our work under the other classiﬁer (DE) is the second lowest. Especially, under
the decision tree classiﬁer (DT), which is a standard and prevalent machine
learning classiﬁer, the false positive rate of our work (0.5%) is less than half of
the best other existing approach (B) and a quarter of the worst one (D). From
Fig. 4(b), we can ﬁnd that the detection rates of our work under all four machine
learning classiﬁers are the highest. In particular, the detection rate of our work
(85%) is signiﬁcantly higher than the detection rate of 51% for the worst detector
4 The features used in these three approaches can be seen in Table 3.
5 F-measure [8] is a measure with the consideration of both precision and recall.
17
(D) and the detection rate of 73% for the best other existing detector (B). We
also evaluate our feature set based on the metric of F-measure [8]. Fig. 4(c)
shows that under all four classiﬁers, F-measure scores of our approach are the
highest. The above results validate that our new feature set is more eﬀective to
detect Twitter spammers.
Through these three ﬁgures, we can also observe that the performance of [32]
and [34] is better than that of
[35]. That is mainly because both [32] and [34]
utilize the feature of tweet similarity, and [35] only uses the feature of duplicate
tweet count. Since many spammers post tweets with similar terms but diﬀerent
combinations rather than simply repeatedly posting the same tweet, the feature
of tweet similarity is much more eﬀective than duplicate count. Also, [32] utilizes
a graph-based feature (number of bi-directional links) and a timing-based feature
tweet rate, leading its performance to be better than that of
[34].
Feature Validation: To further validate the eﬀectiveness of our newly de-
signed features, we make the comparison of the performance of two feature sets.
The ﬁrst one consists of the features in the previous experiment without our
newly designed features. The second one consists of all features used in the pre-
vious experiment. Table 4 shows that for each classiﬁer, with the addition of
our newly designed features, the detection rate (DR) increases over 10%, while
maintaining an even lower false positive rate (FPR). This observation implies
that the improvement of the detection performance is indeed proportional to our
newly designed features rather than the combination of several existing features.
Table 4. Comparison Without and With New Features
Without Our Features With Our Features
Classiﬁer
FPR DR F-Measure FPR DR F-Measure
Decorate
0.017 0.738
Random Forest 0.012 0.728
Decision Tree 0.015 0.702
BayesNet
0.040 0.644
0.774
0.786
0.757
0.730
0.010 0.858
0.006 0.836
0.011 0.846
0.023 0.784
0.877
0.884
0.866
0.777
7.2 Evaluation on Dataset II
In this section, to decrease possible eﬀect of sampling bias, we evaluate the ef-
fectiveness of our detection feature set by testing it on another data set contain-
ing 3,500 unclassiﬁed Twitter accounts. Our goal of the evaluation on another
crawled dataset is to test the actual operation and user experience without the
ground truth from URL analysis by computing the Bayesian detection rate [21]
– the probability of actually being at least a suspicious spammer, whenever an
account is reported by the detection system.
Speciﬁcally, we use Data set I, which has been labeled, as the training data
set, and Data set II as the testing data. Then, based on our detection feature
18
set, we use BayesNet classiﬁer to predict spammers on Data set II. This result
can be seen in Table 5.
Table 5. Classiﬁer Eﬀectiveness
Total Spammer Predictions 70
Veriﬁed as Spammers
37
Promotional Advertisers 25
Benign
Identiﬁed by GSB
8
17
When we manually investigated those 70 accounts that were predicted as
spammers, we found 37 real spammers, 25 promotional advertisers6 and only 8
real false positives. In this case, we have a high Bayesian detection rate of 88.6%
(62/70). Then, we further investigate these 8 false positive Twitter accounts.
We ﬁnd that all of them have odd behavior, but do not appear to have clear
malicious intentions. Speciﬁcally, 6 of them are actively tweeting about only
one topic. The other 2 have posted very few tweets, yet have a large number
followings with a high ratio of followings to followers. Also, we examined the
URLs that these 37 veriﬁed spammers posted to Twitter, and we found 17 of
them posted malicious URLs according to the Google Safe Browsing blacklist.
8 Limitation and Future Work
Due to practical limitations, we can only crawl a portion of the whole Twitter-
sphere and our crawled data set may still have sampling bias. However, collecting
an ideal large data set from Twitter, a real and dynamic OSN, without any bias
is almost an impossible mission.
In addition, it is challenging to achieve comprehensive ground truth for Twit-
ter spammers. Also, since we collect one major type of spammers, the number of
our identiﬁed spammers is a lower bound of them in our dataset. However, even
for a subset of spammers, we can ﬁnd that they are evolving to evade detection.
And our evaluation validates the eﬀectiveness of our newly designed features to
detect these spammers. We also acknowledge that some identiﬁed spam accounts
may be compromised accounts. However, since these accounts still behave fairly
maliciously in their recent histories and are dangerous to the Twittersphere, it
is also meaningful to detect them.
While graph-based features such as local clustering coeﬃcient and between-
ness centrality are relatively diﬃcult to evade, these features are also expensive
to extract. Thus, we extract the approximate values of these two features by
using a sampling technique that allowed us to compute these metrics piece-by-
piece. However, precisely estimating the values of such graph metrics on large
6 Since some consider Promotional Advertisements to be spam and others do not, we
label these accounts as another category. At least, These accounts are very suspicious.
19
graphs such as the one we have crawled is very challenging and a hot research
issue, which is out of scope of this work.
For future work, to overcome those limitations, we will design better crawling
strategies and crawl more data. We plan to design more robust features, evaluate
our machine learning detection scheme on larger data sets, and work directly
with Twitter. We also plan to broaden our targeted type of spammers, so that
we can perform a deeper analysis on the evasion tactics by diﬀerent types of
spammers. We also plan to make more quantitative models for the analysis of
the robustness of the detection features by deeper analyzing the envision tactics.
9 Conclusion
In this paper, we design new features to detect Twitter spammers based on an
in-depth analysis of current evasion tactics utilized by Twitter spammers. In
addition, we formalize the robustness of detection features for the ﬁrst time in
the literature. Finally, according to our evaluation, while keeping an even lower
false positive rate, the detection rate by using our new feature set increases over
10% than all existing detectors under four prevalent machine learning classiﬁers.
References
1. A new look at spam by the numbers. http://scitech.blogs.cnn.com/.
2. Acai
verts.
acai-berry-spammers-hack-twitter-accounts-spread-adverts/.
hack
ad-
http://www.sophos.com/blogs/gc/g/2009/05/24/
spammers
accounts
Twitter
spread
Berry
to
3. Auto Twitter. http://www.autotweeter.in/.
4. Betweenness Centrality. http://en.wikipedia.org/wiki/Centrality.
5. Botnet over Twitter. http://compsci.ca/blog/.
6. Buy a follower. http://http://buyafollower.com/.
7. Capture HPC. https://projects.honeynet.org/capture-hpc.
8. F-measure. http://en.wikipedia.org/wiki/F1_score.
9. Google Safe Browsing API. http://code.google.com/apis/safebrowsing/.
10. Local Clustering Coeﬃcient.
http://wikipedia.org/wiki/Clustering_
11. Low-Priced
coefficient#Local_clustering_coefficienty.
Under-
Kit
http://news.softpedia.com/news/
ground
Low-Priced-Twitter-Spam-Kit-Sold-on-Underground-Forums-146160.shtml.
Forums.
Twitter
Spam
Sold
on
12. New
Koobface
campaign
spreading
on
Facebook.
http://
community.websense.com/blogs/securitylabs/archive/2011/01/14/
new-koobface-campaign-spreading-on-facebook.aspx.
13. The 2000 Following Limit Policy On Twitter. http://twittnotes.com/2009/03/
2000-following-limit-on-twitter.html.
14. The
Twitter
Rules.
18311-the-twitter-rules.
15. Tweet spinning your way to the top.
tweet-spinning-your-way-to-the-top/.
16. TweetDeck. http://www.tweetdeck.com/.
http://help.twitter.com/entries/
http://blog.spinbot.com/2011/03/
20
17. Twitter
account
for
sale.
http://www.potpiegirl.com/2008/04/
buy-sell-twitter-account/.
18. Twitter API in Wikipedia. http://apiwiki.twitter.com/.
19. Twitter phishing hack hits BBC, Guardian and cabinet minister. . http://www.
guardian.co.uk/technology/2010/feb/26/twitter-hack-spread-phishing.
20. Twitter Public Timeline. http://twitter.com/public_timeline.
21. S. Axelsson. The base-rate fallacy and its implications for the diﬃculty of intru-
sion detection. In In Proceedings of the 6th ACM Conference on Computer and
Communications Security, pages 1–7, 1999.
22. F. Benevenuto, G. Magno, T. Rodrigues, and V. Almeida. Detecting Spammers on
Twitter. In Collaboration, Electronic messaging, Anti-Abuse and Spam Conﬀerence
(CEAS), 2010.
23. F. Benevenuto, T. Rodrigues, V. Almeida, J. Almeida, and M. Gonalves. Detecting
In ACM
Spammers and Content Promoters in Online Video Social Networks.
SIGIR Conference (SIGIR), 2009.
24. F. Benevenuto, T. Rodrigues, V. Almeida, J. Almeida, C. Zhang, and K. Ross.
In Int’l Workshop on
Identifying Video Spammers in Online Social Networks.
Adversarial Information Retrieval on the Web (AirWeb’08), 2008.
25. M. Cha, H. Haddadi, F. Benevenuto, and K. Gummadi. Measuring User Inﬂuence
in Twitter: The Million Follower Fallacy. In Int’l AAAI Conference on Weblogs
and Social Media (ICWSM), 2010.
26. Z. Chu, S. Gianvecchio, H. Wang, and S. Jajodia. Who is Tweeting on Twitter:
Human, Bot, or Cyborg? In Annual Computer Security Applications Conference
(ACSAC’10), 2010.
27. H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Zhao. Detecting and Character-
izing Social Spam Campaigns. In Proceedings of ACM SIGCOMM IMC (IMC’10),
2010.
28. C. Griery, K. Thomas, V. Paxsony, and M. Zhangy. @spam: The Underground on
140 Characters or Less. In ACM Conference on Computer and Communications
Security (CCS), 2010.
29. D. Ionescu. Twitter Warns of New Phishing Scam. http://www.pcworld.com/
article/174660/twitter_warns_of_new_phishing_scam.html.
30. G. Koutrika, F. Eﬀendi, Z. Gyongyi, P. Heymann, and H. Garcia-Molina. Com-
In Int’l Workshop on Adversarial Information
bating spam in tagging systems.
Retrieval on the Web (AIRWeb’07), 2007.
31. H. Kwak, C. Lee, H. Park, and S. Moon. What is Twitter, a Social Network or a
News Media? In Int’l World Wide Web (WWW ’10), 2010.
32. K. Lee, J. Caverlee, and S. Webb. Uncovering Social Spammers: Social Honeypots
+ Machine Learning. In ACM SIGIR Conference (SIGIR), 2010.
33. J. Leskovec and C. Faloutsos. Sampling from large graphs. In Proceedings of the
12th ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining (SIGKDD), 2006.
34. G. Stringhini, S. Barbara, C. Kruegel, and G. Vigna. Detecting Spammers On
In Annual Computer Security Applications Conference (AC-
Social Networks.
SAC’10), 2010.
35. A. Wang. Don’t follow me: spam detecting in Twitter.
In Int’l Conferene on
Security and Cryptography (SECRYPT), 2010.
36. C. Yang, R. Harkreader, and G. Gu. Die free or live hard? empirical evaluation and
new design for ﬁghting evolving twitter spammers (extended version). Technical
report, 2011.