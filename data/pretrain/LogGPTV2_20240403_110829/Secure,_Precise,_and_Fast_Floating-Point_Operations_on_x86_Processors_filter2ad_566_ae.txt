### Impact of Floating-Point Library

#### 7.1 Performance Evaluation

This section evaluates the performance impact of Escort on the SPEC floating-point benchmarks and a security-sensitive program, SVMlight, which is a machine-learning classifier.

**Evaluation Using SPEC Benchmarks:**
We used the C and C++ floating-point applications from the SPEC CPU 2006 benchmark suite with reference inputs. For each program, we generated two versions:
- **SPEC-LIBC:** Uses the standard C library functions.
- **SPEC-ESCORT:** Uses functions from the Escort library.

The SPEC-LIBC programs were compiled using Clang/LLVM 3.8 with the -O3 flag, while auto-vectorization was disabled for the SPEC-ESCORT programs. The results presented here represent the worst-case performance overhead of Escort, as all floating-point operations in SPEC-ESCORT were transformed to use the Escort library. We did not reduce the number of transformations using taint tracking or SMT solvers.

Table 9 shows that Escort's overhead is substantial, with a geometric mean of 32.6×. We expect a lower average overhead for applications that use secret data, as taint tracking would reduce the number of floating-point operations that need to be transformed.

| Test Case | Overhead |
|-----------|----------|
| #1        | 8.66×    |
| #2        | 30.24×   |
| #3        | 1.41×    |
| #4        | 12.75×   |
| GEO MEAN  | 8.28×    |

**Evaluation Using SVMlight:**
To evaluate Escort’s overhead on a security-sensitive benchmark, we measured its performance on SVMlight, an implementation of Support Vector Machines in C. We used four example test cases documented on the SVMlight website. We marked the training and classification data as secret. Before replacing floating-point computations, Escort's taint analysis identified all floating-point computations dependent on the secret data, thus reducing the list of replacements. We also instructed Escort to query the Z3 SMT solver to determine if candidate floating-point computations could use subnormal operands. Escort then replaced these computations with secure operations from its library.

The baseline (non-secure) program was compiled using Clang/LLVM 3.8 with the -O3 flag, and auto-vectorization was disabled for the SVMlight program with Escort. We measured the total execution time using the RDTSC instruction. Table 10 shows that Escort's overhead on SVMlight is substantially lower than on the SPEC benchmarks. Using the md5sum program, we verified that the output files before and after transformation of SVMlight are identical.

| Test Case | Training Overhead | Classification Overhead |
|-----------|-------------------|-------------------------|
| #1        | 8.66×             | 1.34×                   |
| #2        | 30.24×            | 0.96×                   |
| #3        | 1.41×             | 1.11×                   |
| #4        | 12.75×            | 0.92×                   |
| GEO MEAN  | 8.28×             | 1.07×                   |

### Impact of Control Flow Obfuscation

#### 7.2 Performance Comparison

To compare the performance impact of Escort’s control flow obfuscation technique with that of Raccoon, we used the same benchmarks that were used to evaluate Raccoon, compiling the baseline (non-transformed) application with the -O3 optimization flag. Although both Escort and Raccoon obfuscate control flow and data accesses, we compared only the cost of control flow obfuscation, as both tools use the same technique for data access obfuscation.

Table 11 shows the results. Programs compiled with Escort have significantly lower overhead than those compiled with Raccoon. Escort’s geometric mean overhead is 32%, while Raccoon’s is 5.32×. The worst-case overhead for Escort is 2.4× (for ip-tree).

| Benchmark      | Raccoon Overhead | Escort Overhead |
|----------------|------------------|-----------------|
| ip-tree        | 1.01×            | 2.40×           |
| matrix-mul     | 1.01×            | 1.01×           |
| radix-sort     | 1.01×            | 1.06×           |
| findmax        | 1.01×            | 1.27×           |
| crc32          | 1.02×            | 1.00×           |
| genetic-algo   | 1.03×            | 1.03×           |
| heap-add       | 1.03×            | 1.27×           |
| med-risks      | 1.76×            | 1.99×           |
| histogram      | 1.76×            | 2.26×           |
| map            | 2.04×            | 1.01×           |
| bin-search     | 11.85×           | 1.01×           |
| heap-pop       | 45.40×           | 1.44×           |
| classifier     | 53.29×           | 1.24×           |
| tax            | 444.36×          | 1.67×           |
| dijkstra       | 859.65×          | 1.10×           |
| GEO MEAN       | 5.32×            | 1.32×           |

The main reason for the vast difference in overhead is that Raccoon obfuscates branch instructions at execution time, which requires copying and restoring the stack for each branch instruction. Since the stack can be arbitrarily large, such operations add substantial overhead to the running time of the program. In contrast, Escort’s code rewriting technique obfuscates code at compile time using basic block predicates, resulting in significant performance improvements.

### Conclusions

In this paper, we presented Escort, a compiler-based tool that closes side channels stemming from floating-point operations. Escort prevents attackers from inferring secret floating-point operands through timing channels, micro-architectural state, and off-chip digital side channels, such as memory address traces.

Escort uses native SSE instructions to provide speed and precision. Its compiler-based approach supports a significantly larger number of floating-point operations (112) compared to FTFP (19).

Escort’s design motivates further research into hardware support for side-channel resistant systems. For example, by allowing software to control the timing of integer instruction latencies and their pipelined execution, Escort’s guarantees could be extended to instructions beyond floating-point instructions.

### Acknowledgments

We thank our shepherd Stephen McCamant and the anonymous reviewers for their helpful feedback. We also thank David Kohlbrenner for providing the Firefox timing attack code. We are grateful to Jia Chen for providing the pointer analysis library and Joshua Eversmann for help with code and discussions. This research was funded in part by NSF Grants DRL-1441009, CNS-1314709, and CCF-1453806, C-FAR (one of the six SRC STARnet Centers sponsored by MARCO and DARPA), and a gift from Qualcomm.

### References

[1] ABADI, M., ET AL. TensorFlow: Large-scale machine learning on heterogeneous distributed systems. Computing Research Repository abs/1603.04467 (2016).
...
[39] ZHANG, Y., AND REITER, M. K. Duppel: Retrofitting Commodity Operating Systems to Mitigate Cache Side Channels in the Cloud. In Conference on Computer and Communications Security (2013), pp. 827–838.