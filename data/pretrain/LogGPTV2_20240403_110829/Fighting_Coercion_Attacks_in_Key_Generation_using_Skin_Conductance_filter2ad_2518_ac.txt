participant believed that she had pressed the “ALT” key
which caused data loss on the computer (event D). We
purposely left the participant alone so that stress could
develop further and she could not get immediate help to
resolve the “problem”. After that, the researcher entered
the room and examined the keyboard and the computer
(event E) and then accused the participant of her negli-
gent act of pressing the “ALT” key (event F). This turned
9
)
S
µ
(
e
c
n
a
t
c
u
d
n
o
C
n
i
k
S
15
14
13
12
11
10
9
8
7
6
0
A
B
C
D
F
E
100
200
300
400
500
600
700
800
Time (sec)
Figure 6: Change of skin conductance in e2
out to be successful in making the participant stressed as
we observed that many participants were nervous at this
point in time. Some kept saying “sorry”; some tried very
hard to ﬁx the “problem”, and some started calling for
help. There were also voluntary confession statements
from the participants, e.g., “I hit the ALT key by mistake
in place of typing the ‘X’ key”, “It was a mistake from
my side.”.
5.4 Discussion
In this section, we discuss the difference of the emotional
state of a user in real life and in our user study, and limi-
tations of our experiment.
1. Training of the system
• Real life:
the user is in a (controlled) envi-
ronment speciﬁed by our system, in which the
stress level is low. This allows us to generate
the lookup table for that particular user with
the normal skin conductance level.
• User study:
the user is in exactly the (con-
trolled) environment speciﬁed by our system,
i.e., when watching a relaxation movie.
• Real life: a user can be forced/coerced in
many different ways, e.g., a gun to the head,
or a knife under the throat, etc.
• User study: watching a horror movie and be-
ing forced to plead guilty (having damaged a
notebook computer). We tried our best to ap-
proximate the real-life scenarios, but there is a
limit we could go when doing this to real hu-
man beings (e.g., IRB restriction). However,
we believe that what we did is a clever way of
studying human behavior when being coerced.
Discussions above highlight some limitations of our
scheme, e.g., we have not tested how it reacts to other
emotional status (happy, sad, angry, etc.) and how skin
conductance may change naturally (due to oily ﬁngers,
etc.). There are two other important limitations in the
present study. First, our study does not test the repeata-
bility of using our scheme, i.e., we did not ask the partici-
pants to come back and try again. The second limitation
comes with the over-controlled environment, e.g., quiet
ofﬁce (because of the use of voice), controlled temper-
ature and humidity [9](because of the use of skin con-
ductance), and etc. It remains further work to test our
scheme in different settings.
6 Evaluation and Discussion
In this section, we analyze the data collected in our user
study. We ﬁrst describe how we partition the data into
different groups (e.g., for training and test purposes), see
Section 6.1. We then present a series of analysis on the
false-positive and false-negative rates (Section 6.2). Fi-
nally we show the change in the password space where
an attacker has perfect knowledge of our design and the
content stored. We show that this change in the password
space in this worst case is small (Section 6.3).
2. Trying to generate the cryptographic key; no coer-
cion
6.1 Training and Testing Datasets
• Real life: a user could be in various emotional
states, including being happy, sad, angry, etc.
• User study: same as in training when the user
is watching a relaxation movie. In this work,
we only try to analyze how our system per-
forms when users are calm and relaxed.
It
remains future work to analyze how it works
when the user is in other emotional states. We
do expect the false-negative rate to rise when
the user is in other emotional states.
3. Trying to generate the cryptographic key; in coer-
cion
10
We have collected voice and skin conductance signals
for 39 participants. For each participant, we have col-
lected many samples of the signals when the participant
is either calm or stressed. Table 2 shows the number of
samples we collected in each experiment for each par-
ticipant. Voice signals are typically 2 to 3 seconds long,
while skin conductance signals are about 10 seconds long
to avoid ﬂuctuations.
Figure 7 shows how we obtain dataset to
• split original sample sets {ν full
e1n , ωtrain
e1n, ωfull
e2n} into
e2n } and {ν test
e1n,
e2n} to obtain datasets for training and test-
two equal halves {ν train
ωtest
e1n, ωtest
ing (see the half circles);
e1n, ωfull
e1n , ωtrain
Feature
Voice
SC
e1n
e1s
e2n
e2s
# of samples
Notation
# of samples
Notation
26
ν full
e1n
26
ωfull
e1n
5
ν full
e1s
60
ωfull
e1s
0
-
0
-
18
ωfull
e2n
60-80
ωfull
e2s
Table 2: Number of samples collected for each partici-
pant
• combine different voice samples and skin conduc-
tance samples to create new datasets to test our sys-
tem (see circles in the middle column). {ν train
e1n &
e2n }, {ν test
ωtrain
e1n }, {ν test
e1n
& ωtest
e1n},
{ξtrain
e2n} are combined to create {ξtrain
e1n & ωtrain
e1n & ωtest
e1n}, {ν train
e1n }, {ξtest
e2n }, {ξtest
e2n} respectively.
• to obtain the stress dataset {ν full
e2s} are combined to create {ξfull
ωfull
tively.
e1s & ωfull
e1s}, {ν full
e1s &
e2s} respec-
e1s}, {ξfull
rate is deﬁned as the percentage of failed detection of
attempts by illegitimate users or legitimate users in a
stressful situation, averaged over all users in a popula-
tion A.
Voice samples only We ﬁrst evaluate the voice samples
we collected in our experiments. The purpose is to check
out the false-positive and false-negative rates, in an event
if only voice samples are used to generate cryptographic
keys. The system is trained with ν train
e1n of user ai, and
is tested against ν full
e1n of user aj where i 6= j, ∀ j ∈
A to calculate the false-positive rates; and against ν test
of user ai to calculate the false-negative rates. Results
are averaged on all users in A. We try different random
αV vectors and choose the one that yields the smallest
sum of the false-positive and false-negative rates. We try
different settings of the hamming distance parameter d,
and ﬁnd that 2 gives a reasonable tradeoff between false-
positive and false-negative rates. The false-positive and
false-negative rates for different values of k are plotted
in Figure 8.
e1n
16
14
12
10
False Positive
False Negative
e
g
a
t
n
e
c
r
e
P
8
6
4
2
0
1.2
1.3
1.4
1.5
k −−>
1.6
1.7
1.8
Figure 8: False-positive and false-negative rates for spo-
ken passwords
Figure 8 shows that we manage to get a comparable
accuracy with the previous work [24] in terms of the
false-negative rate. False-positive rate was not reported
in [24].
Skin conductance only Next, we evaluate the skin
conductance samples to see how well they reﬂect the
change in the participants’ emotional status. We show
the results in Figure 9(a) and Figure 9(b) for experiment
e1 and e2, respectively. The different color lines denotes
different ‘k’ values in Figure 9 and Figure 10. The sys-
tem is trained with ωtrain
e2n , respectively) of user
ai, and is tested against the stressed full data set, ωfull
(and ωfull
e2s, respectively) of the same user ai to calculate
the false-positive rates; or against the normal test data
set, ωtest
e2n , respectively) of the same user ai to
calculate the false-negative rates. Results are averaged
over all users in A.
e1n (and ωtrain
e1n (and ωtest
e1s
Figure 7: Splitting and combining datasets
Note that the voice and skin conductance samples that
are combined together might not have been captured at
exactly the same time. We allow a time gap because an
attacker might record the voice of the victim to be used
in conjunction with the skin conductance of the victim at
a slightly different time. Both samples were captured in
the same part of the experiment, though, i.e., both from
e1s or both from e2s.
6.2 Accuracy of our model
The false-negative rate of our system is deﬁned as the
percentage of failed login attempts by a legitimate user
with her cryptographic key generated, averaged over all
users in a population A. Similarly, the false-positive
11
False Positive
50
40
30
20
10
>
−
−
e
g
a
t
n
e
c
r
e
P
k=1.875
k=1.25
k=1.375
k=1.5
k=1.625
k=1.75
k=1.875
a ξfull
e2n of user aj where i 6= j, ∀ j ∈ A: when a differ-
ent person tries to generate the key (Figure 10(a));
b ξfull
e2s of user ai: when the same user tries to generate
the key when she is being coerced (Figure 10(b));
c ξtest
e2n of user ai: when the same user tries to gen-
erate the key when she is not being coerced (Fig-
ure 10(c)).
We evaluate the false-positive rates in the ﬁrst two
cases and the false-negative rates in the third case. Re-
sults are averaged over all users in A. We use a hamming
distance parameter d = 4, and show the results in Fig-
ure 10.
False Positive
25
20
15
10
5
>
−
−
e
g
a
t
n
e
c
r
e
P
0
1
2
3
Threshold (t
4
)−−>
SC
6
5
k=1.25
k=1.375
k=1.5
k=1.625
k=1.75
k=1.875
k=1.875
k=1.25
2
1.5
>
−
k −
1
8
7
(a) False-positive against ξfull
e2n of user aj i 6= j
False Positive
30
25
20
15
10
5
>
−
−
e
g
a
t
n
e
c