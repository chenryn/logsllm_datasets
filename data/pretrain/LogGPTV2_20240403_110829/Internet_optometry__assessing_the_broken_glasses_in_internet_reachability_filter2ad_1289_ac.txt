(CCDF) of the number of ASes that can be reached from a random
source, given the BGP announcement of destinations propagates
one hop (to providers). Note that for the max default allocation
we can now reach 1000 ASes from approximately 50% of sources,
and over 2000 ASes from around 1/3 of sources. For the random
allocation of default routes, we can reach somewhat fewer destina-
tions, but the number is still substantial. The contrast between the
two allocation schemes is intuitive. By choosing (as our default) an
AS with more customers, we make available more potential desti-
nations at each step.
The ﬁgure also shows a curve under the assumption that BGP
advertisements propagate two AS hops away. We can see that this
has a dramatic impact on the number of ASes that are reachable
(6000 are reachable about 50% of the time, with a maximum of
nearly 19, 000). For simplicity, we only show this curve for the
max default allocation, but we see a similar decrease to the 1-hop
case when the random allocation rule is used.
These simulations obviously over-simplify much of the opera-
246access to this IP address would fail, and it would appear that ad-
ditional upstream providers exist. False positives such as this are
possible, but false negatives are less likely. They can happen if the
link to the hidden upstream is temporarily down during our exper-
iment, or if the hidden provider also uses the same upstreams as
the AS itself (it is unlikely that an AS would use such a provider
given the limited redundancy it provides). Hence, we regard 33 as
an upper bound on the number of missing customer-provider links
in our test, in actuality, it is likely that signiﬁcantly fewer upstream
providers are missing.
The results support the belief that standard AS-topology data
sees the vast majority of customer-provider links, i.e., BGP sources
give very good visibility of upstream providers.
5. TESTING REACHABILITY WITH DUAL
PROBING
The experiments described above showed that default routes and
hidden connectivity limit the ability to predict reachability from
control-plane observations. Such limitations should be kept in mind
before making claims based only on control-plane observations.
On the other hand, the type of data-plane measurements we have
used so far are limited as well. It is easy to ﬁnd situations where it
is hard to interpret the results of ping probes simply because end-
host (and middleware) behavior is so varied.
In this section, we describe a rigorous active probing method-
ology, called dual probing. Dual probing makes explicit the as-
sumptions and expectations behind different types of active mea-
surements, and uses them to calibrate expectations.
Before explaining our methodology, we need to better under-
stand the problem of testing reachability. Reachability can be as-
sessed from two different viewpoints:
(cid:129) How do I see the world?
(cid:129) How does the world see me?
The ﬁrst is based on the information a router receives from rout-
ing protocols. We addressed the limitations of BGP routing infor-
mation in previous parts of this paper. The converse question —
“how does the rest of the wold see me?” — is something operators
often would like to know in order to debug reachability problems.
Unfortunately, this information is not directly available from the
network layer.
The sampled world viewpoint.
There is data available to see how the world sees us. Services
such as BGP monitors, looking glasses, and traceroute servers pro-
vide public views of the Internet. However, only a sample of ASes
operate these as a public service, therefore it is hard to get direct
data from the world viewpoint. What we see when we combine data
from the available viewpoints is actually a sampled world view-
point.
A signiﬁcant problem with this sampled view is that the opera-
tors with the sophistication and resources to operate public view-
points tend to be larger ISPs, nearer the “core” of the Internet [6].
The bias in the viewpoints could mislead. For instance, we might
hypothesize that these large, densely connected ISPs have fewer
reachability problems than stub ISPs. There is a strong motivation
to see a much more complete world viewpoint.
Out-probes.
We advocate the use of data-plane probes to provide such a world
viewpoint. Suppose a network administrator wants to check that
external hosts can reach their network. A simple test would be to
AS 1
   AS 2                       
             AS 3
BGP
observation
point
Looking 
                    AS 4
glass
AS 5
anchor 
and test-
preﬁx
AS 6
AS 8
     AS 7
Test site
Traditional probe
Out-probe
Figure 6: Dual probing: “traditional probing” require looking
glass servers. Those are very sparsely distributed and highly
biased in what they show. “Out-probes” cover a large fraction
of the whole Internet, but, they require that reachability expec-
tations can be calibrated.
ping from a strategically located machine towards a large set of
external IP addresses covering much of the Internet. If those IP
addresses answer the probes, this indicates that the source machine
is reachable from the probe’s destination. As the units of Internet
routing are IP address preﬁxes, the administrator could assume that
reachability exists between this set of preﬁxes and their site. Ob-
viously there are exceptions, but an administrator is typically not
concerned about the end-point connectivity of distant systems. We
are concerned that network level reachability exists, such that the
end-points could in principle connect.
In this section, we term these outbound pings and traceroutes
out-probes, as probes are sent out from the address space to be
tested for reachability, even though it is the return packet that re-
veals the reachability of our preﬁx. Figure 6 illustrates this concept.
In the “traditional” case (black solid arrow), a probe is in-bound
from a public looking glass towards the test-site. In the out-probe
case (green dashed arrows), a probe is sent from the test-site to-
wards many destinations in the Internet. Note that the address space
under investigation must be the source address of the outgoing IP
packet. The probes are aimed outwards to many pingable IPs scat-
tered across the Internet, but it is the return trafﬁc (towards the test
address space) that reveals the reachability of the test IP address
space.
5.1 Dual-Probe Technique
When the ping probes are not answered, the administrator can-
not conclude that their system is unreachable. There are several
reasons why outward ping probes might not be answered, among
them: (1) the IP address simply does not answer pings, (2) the ping
probes are dropped by ﬁrewalls on the way towards the probed IP
addresses, (3) the IP address answers the ping probes but the an-
swers are dropped somewhere on the path back towards the prob-
ing host, or (4) there is no route from the IP address in question
back to the probing host or vice versa. Only the latter two cases
247concern reachability of our tester’s network. Even case (3) may be
a poor indication of unreachability because ICMP probes are often
given lower priority and may be dropped preferentially over TCP
trafﬁc. So an absense of response provides little information by it-
self. Useful interpretations can only be obtained when we already
know what answer to expect from a probe.
Calibrating expectations.
If we can calibrate our expectations we will know how to inter-
pret the responses of probes. This is is a similar to what we did in
Section 3 where we calibrated our expectations via a look-ahead,
i.e., we used two probes separated in time to allow for better inter-
pretation of the second probe. Other dimensions we might use for
calibration are: probing location, or target address space. We call
this approach dual probing, though in some cases more than two
probes may be involved.
For instance, we can compare probe answers against probes from
another preﬁx, called here an anchor-preﬁx. The anchor-preﬁx is an
old, well-established preﬁx known to have very good reachability.
By comparing the probing results between the test-preﬁx and the
anchor-preﬁx, we have the ability to decide if unanswered pings
and traceroutes initiated from the test-preﬁx are abnormal.
The key behind the success of dual probing is the comparison
between probes from a test- and anchor-IP. This comparison re-
veals far more information than a single probe from the test-preﬁx.
Lacking a reply from the anchor probe to a particular IP address
we know there is a problem probing this IP address, and so we can
discount test measurements as not useful. With a reply to both,
we can infer successful reachability. When we receive a ping re-
ply to an anchor probe, but no reply to a test probe we have some
evidence that there is a reachability problem. The evidence is not
conclusive (ICMP packets may be dropped), but over a series of
such measurements, we can build more conﬁdence in the results.
We also demonstrate that this dual probing approach has a wide
dynamic range of applications. It worked well when blockage of
the test preﬁx was sparse, e.g. when used to detect bogon ﬁlters (see
below), for which there was on the order of 5% blockage. It also
worked well at the opposite end of the spectrum, the propagation
of a /25 preﬁx, where visibility was on the order of 5%.
5.2 Bogus bogon ﬁlter detection
A bogon refers to a bogus routing announcement. These are sent
either accidentally, or deliberately to hijack address space, and so
ISPs commonly conﬁgure either control or data plane ﬁlters to pre-
vent trafﬁc to/from obviously bogus addresses. For instance, it is
common to refuse trafﬁc or announcements from unallocated ad-
dresses space. However, the conﬁguration of these ﬁlters does not
always keep up as new address space is allocated, so it is important
to be able to debug reachability problems caused by bogus bogon
ﬁlters.
In the past traceroutes from public servers have been used to
ﬁnd these ﬁlters [8] (as well as very limited out-probing), but the
small sample set of such servers limits the ability to detect bogon
ﬁlters to a small subsection of the Internet. Here we systematically
investigate bogus bogon ﬁlters using dual out-probes over a large
segment of the whole Internet.
ARIN allocated two large segments of newly allocated address
space3 for our experiment, and we used 5 smaller segments of
this address space. We announced those preﬁxes from ﬁve dif-
ferent locations that volunteered to participate in our experiment:
PSGNet in Seattle (USA), Verio in Ashburn (USA), SpaceNet in
3173.0.0.0/16 and 174.128.0.0/16
Munich (Germany), CityLink in Wellington (New Zealand), and IIJ
in Tokyo (Japan). Each test-site announced one of the test-preﬁxes.
The anchor-IP was the normal address of a machine inside the ISP
that ran the experiment. The test-IP was conﬁgured as a secondary
IP address on the same interface. We ran three different measure-
ment campaigns to see if bogon ﬁlters are removed over time: the
ﬁrst starting in April 14th 2008 (t1), the second starting on May
27th 2008 (t2), and the third starting on June 12th 2008 (t3). About
a week was necessary to run all our probes (to the set of target IP
addresses described in Section 6.1), so the dates given are approx-
imate. The ﬁrst measurement campaign occurred before ARIN an-
nounced that this address space had been issued. The goal of these
measurements was to provide a controlled experiment. We want
to understand how prevalent legitimate bogon ﬁlters are, i.e., how
much of the Internet is protected from trafﬁc from unallocated ad-
dress space.
After the ﬁrst campaign, the ARIN announced that the address
space had been issued, and that it should be removed from bogon
black-lists. In addition, we identiﬁed (in the ﬁrst campaign) a list
of ASes that deﬁnitely ﬁlter. The ASes in this list were looked up
in the IRR (where possible) and email was sent to operators asking
them to (1) conﬁrm our detected ﬁlters, and (2) if so to remove
them. Thus reachability problems identiﬁed in the second set of
measurements are genuine problems, which needed to be ﬁxed.
The third set of measurements was used to assess how the reach-
ability problems were changing over time. We will discuss later
(Section 6.1) how we chose the list of addresses to ping, and the
individual results of those pings, but for the moment let us focus on
the problems we discovered. We observed more than a thousand
ASes (1024) that replied to probes sent from the well-established
address space, but did not answer probes sent from the test address
space. We also saw that the test space showed problems months af-
ter it was ofﬁcially allocated, with little sign that the problem was
being corrected! The operator community is aware of this problem
but has had no tools to measure its extent or to see trends.
In testing for blockage, there are at least two reasons we would
wrongly conclude a lack of reachability: (1) ICMP drops and time-
outs and (2) upstream ﬁltering. A simple way to compensate for (1)
is to repeat probing over time, and from multiple viewpoints, hop-
ing that the concerned hosts or routers do not systematically drop
the probes. If we probe one AS several times and it never replies to
probes coming from the test address space but consistency replies
to probes from the anchor address space, it is likely that this AS
does not have reachability to the test space. However, the intent
of “debogoning” is that the registries would contact the administra-
tors of incorrectly conﬁgured ASes. We do not want to contact the
administrators of ASes that are not ﬁltering, as this would degrade
the credibility of the service, so false positives must be kept to a
minimum.
For an AS to be identiﬁed conclusively as having a reachability
problem, we require to have zero returns back to the test-IP, and at
least ﬁve returns to the anchor-IP. If there are zero returns to the
test address space, and less than ﬁve returns to the anchor IP, we
have some indication that the AS might have a problem, but it is
less conclusive because of the low sampling. We categorize these
as potential problems.
The probed AS will not have reachability to the test-preﬁx if its
upstream providers are ﬁltering (and do not use default routing).
This type of AS will appear in our list of problematic ASes, but
may not be to blame. However, the AS’s operator is likely to be
interested in knowing that they have limited reachability, and may
put upwards pressure on the guilty party to ensure that the problem
248l
)
e
a
c
s
−
g
o
l
(
s
e
S
A
#
0
0
0
0
5
0
0
0
0
1
0
0
0
2
0
0
5
0
0
1
filter
pot. filter
may ’08
AS ok
ASs in RV+RIS
jun ’08
jul ’08
apr ’08
Figure 7: The number of ASes showing conclusive, and proba-
ble evidence for reachability problems (log-scale).
is rectiﬁed. Hence, these identiﬁcations, while false, do not degrade
the detection service in the same way as other false positives.
It is quite possible that an AS is not conﬁgured uniformly, as we
saw in the case of default routing. Perhaps ﬁlters have been updated
on some routers, but not others. Interpreting results from such ASes
is much harder. We might try to enter an AS via a working path, or
via the blocked path and this may determine our results. Detection
is only possible if we have a large number of IP addresses that we
probe as well as a large number of probing locations (e.g., [9]).
Figure 7 shows the number of ASes that fall into each category.