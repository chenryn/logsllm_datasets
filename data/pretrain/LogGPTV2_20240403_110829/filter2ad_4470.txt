# Title: An Experimental Study on Instance Selection Schemes for Efficient Network Anomaly Detection

## Authors:
- Yang Li<sup>1,2</sup>
- Li Guo<sup>2</sup>
- Bin-Xing Fang<sup>2</sup>
- Xiang-Tao Liu<sup>2</sup>
- Lin-Qi<sup>3</sup>

### Affiliations:
1. China Mobile Research Institute, Beijing, China 100053
2. Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China 100190
3. University of Maryland, USA 21226

**Contact:** [PI:EMAIL]

---

## Abstract

Traditional research in network anomaly detection has primarily focused on the development and optimization of detection algorithms. However, the selection of normal training data, which significantly influences both detection performance and computational complexity, remains an underexplored area. In this study, we present two instance selection mechanisms—Enhanced Fuzzy C-Means (EFCM) and Genetic Algorithm (GA)—designed to reduce the size of the training dataset, thereby lowering computational costs and enhancing detection performance. Our experimental results, based on real network traffic traces, demonstrate the effectiveness of these methods when applied to several classic network anomaly detection algorithms.

To the best of our knowledge, the issue of instance selection for efficient network anomaly detection has not been adequately addressed in the literature. Most current detection algorithms are highly dependent on the quality and size of the training dataset. Poor-quality or overly large datasets can lead to significant degradation in detection performance and increased computational costs. Therefore, we propose EFCM and GA as instance selection schemes for anomaly detection algorithms and provide preliminary results.

In the EFCM algorithm, the original training dataset is clustered into three categories: notable data, obscure data, and redundant data. Notable data represents clusters with high membership grades, obscure data includes instances with very low membership grades, and redundant data comprises the remaining instances. We then select a subset of high-quality representatives from the notable data, which contribute most effectively to distinguishing between normal and abnormal traffic. 

Genetic Algorithms (GA), inspired by natural genetics and selection mechanisms, are used to perform instance selection. The training dataset, denoted as TR, is represented by a binary chromosome where each gene corresponds to an instance in TR. A gene value of 1 indicates that the instance is included in the subset, while a value of 0 indicates exclusion. After running the GA, the selected chromosomes form the reduced training dataset.

Our preliminary experiments on real network traffic traces (see Tables 1 and 2) reveal several key findings. First, the computational costs of the algorithms were significantly reduced, while their detection performance either remained high or improved. For example, the TCM-KNN algorithm saw a 90% reduction in training dataset size and a 77% reduction in training and detection time. Second, the false positive rate (FP) decreased, although there was a slight decrease in the true positive rate (TP). Third, both EFCM and GA methods showed comparable effectiveness in the context of network anomaly detection. Based on these results, EFCM is recommended for real-time network environments, while GA may be more suitable for scenarios where higher detection performance is prioritized over training speed.

---

## Tables

### Table 1: Comparison Results after Using Instance Selection for Various Algorithms

| Algorithm           | Without Instance Selection | EFCM   | GA     |
|---------------------|----------------------------|--------|--------|
| One-class SVM       | TP: 95.85%, FP: 8.67%      | TP: 94.98%, FP: 9.87% | TP: 95.72%, FP: 7.03% |
| Fixed-width Clustering | TP: 72.57%, FP: 15.37%    | TP: 72.77%, FP: 13.48% | TP: 72.55%, FP: 10.26% |
| KNN Score           | TP: 92.72%, FP: 10.63%     | TP: 88.78%, FP: 9.03% | TP: 92.08%, FP: 8.78% |
| TCM-KNN            | TP: 100%, FP: 1.29%        | TP: 99.38%, FP: 1.07% | TP: 99.46%, FP: 0.98% |

### Table 2: Computational Costs after Instance Selection for Various Algorithms

| Algorithm           | Without Instance Selection | EFCM   | GA     |
|---------------------|----------------------------|--------|--------|
| One-class SVM       | Training: 8680s, Detection: 213s | Training: 1398s, Detection: 0.1007s | Training: 1293s, Detection: 0.0987s |
| Fixed-width Clustering | Training: 26200s, Detection: 1098s | - | - |
| KNN Score           | Training: 29898s, Detection: 29898s | - | - |
| TCM-KNN            | Training: 40418s, Detection: 0.4558s | Training: 992s, Detection: 992s | - |

---

## References

1. Eskin, E., Arnold, A., Prerau, M., Portnoy, L., Stolfo, S.: A geometric framework for unsupervised anomaly detection: detecting intrusions in unlabeled data. In: Proc. ADMCS 2002, pp. 78–99 (2002)
2. Li, Y., Fang, B.X., Guo, L., Chen, Y.: Network Anomaly Detection Based on TCM-KNN Algorithm. In: Proc. ACM ASIACCS 2007, pp. 13–19 (2007)