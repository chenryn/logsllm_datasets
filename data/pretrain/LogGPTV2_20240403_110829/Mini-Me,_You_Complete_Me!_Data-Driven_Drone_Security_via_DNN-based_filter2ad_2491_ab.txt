monly used to conduct the control state checking in the controller
program binary. To simplify the state estimation, the previous esti-
mation works [27, 37] extract the nonlinear components using a
linear state space template. In the practical deployment of RAVs, the
assumptions of a linear system coverage do not always hold. For
instance, the nano quadcopter Crazyflie 2.0 [12] uses the quaternion
instead of Euler angles to calculate its rotations, which involves
the non-linear factors (e.g., sine, cosine). In addition, a high-level
state-space representation of control invariants may not cover some
indirect but safety-associated control state variables (e.g., ratio of
PID gains) and thus neglect the blind spots in the internal control
flow of controller software.
For the learning-based detection solutions [14, 24, 40, 44], the key
of their success is to train a classifier to distinguish the malicious
behaviors from benign behaviors. The classification objects could
be trends of sensor measurements [14], mutations [24], temporal
behaviors [40, 44], etc. However, most of these works are learning
a high-level mapping relation between sensor measurements and
system states, which is lack of transparency and explainability for
regarding those complicated and interconnected controller algo-
rithms as a big black-box. Specifically for RAVs, these works do
not pay adequate attention to the restrictions in such resource-
constrained embedded systems with limited computing power and
storage capability, which cause deployment difficulties (e.g., mem-
ory usage, performance overhead) in practical RAV applications.
Technical Challenges. Our insights in the aforementioned dis-
cussions motivate us to address the following technical challenges
when practically deploying a machine learning monitoring frame-
work on RAVs: (1) build a transparent model, that is, the inputs
and outputs of the model should be extracted in a clear definition
and learn from both the vehicle dynamics and controller programs
including linear and non-linear target control logic; (2) low perfor-
mance overhead, in other words, the model should be lightweight
(e.g., consume a relatively small amount of computing resources)
and run fast so that it can meet the soft real-time deadlines and stop
the unsafe operations before they actually harm the RAV system.
Threat Model. Mini-Me can detect data-oriented attacks on ex-
ternal physical surfaces2 and internal control parameter spaces3 of
RAVs. We assume that the attackers are capable to exploit existing
vulnerabilities in the external communication channels and per-
form spoofing attacks (e.g., GPS [46], acoustic noises [68], magnetic
fields [67]). Additionally, we assume the attackers know existing
control semantic bugs and their triggering conditions. Therefore,
the attacker may modify the vehicle parameters to generate the
bug-triggering conditions as presented in [48, 49] without the re-
quirement of code injection or control flow hijacking. For instance,
the attackers might exploit the control-semantic bugs (e.g., input
validation bugs reported by [49]) to compromise controller states,
which eventually harm the RV’s safe operations (e.g., steering the
drone towards a ground crash). In the following, we state the as-
sumptions regarding the requirements to ensure Mini-Me’s correct
functionality.
We assume that the control logic behaves securely as intended
based on benign operations before establishing the Mini-Me ap-
proximate model. This allows Mini-Me to learn from a legitimate
control logic by intercepting the embedded controller’s inputs (e.g.,
sensors and vehicle dynamics) and train a neural network-based
replica. We also assume the control flow integrity of RAV controller
software, that is, there are some trusted execution paths for us to de-
ploy the monitoring framework. Hence the attacker can not bypass
or corrupt the Mini-Me checking code. In this paper, the attacks
triggered by generic software vulnerabilities (e.g., buffer overflows)
or traditional program bugs (e.g., return-oriented programming)
are out of scope, as they have been effectively handled by existing
code and memory security efforts [30, 47, 51, 55, 58].
4 MINI-ME DESIGN
In this section, we present the approach of Mini-Me, a learning-
based online monitoring framework. We utilize the dataflow analy-
sis to establish the control state inputs and outputs for RAV con-
troller algorithms. Then we construct and train a lightweight neu-
ral network model to monitor and detect the data-oriented attacks
against the RAV system at runtime.
2The external sensor attacks seek to manipulate the sensor readings or inject erroneous
signals into actuators/sensors through external channels [46, 67, 68].
3Our focus of internal parameter attack is on the bug-triggering of control parameters
during the RAV’s execution using control-semantic bugs [49] against the controller
itself (as opposed to sensor attacks).
3
4304.1 Overview
Facing the sophisticated threats on the controller software and
physical components, we focus on protecting RAV systems against
data-oriented attacks. We analyze the control program and build an
NN-based approximate model as a safe reference, with which we
can validate the performed actuation by comparing output vectors
of the original control logic with those of the approximate model.
Therefore, regardless of the attack vector used to compromise the
controller software, Mini-Me can detect the final effect of such
attacks on their maliciously calculated actuation outputs. As a
clarification example, the controller software could be compromised
through either sensor spoofing attacks or input validation bugs
before the actuation commands are directly or indirectly corrupted
by the adversaries. Mini-Me monitors and detects the final output
corruption no matter how the controller software got compromised
initially.
As shown in Figure 2, the main procedures of Mini-Me can be
described as follows: (1) We reverse engineer the RAV’s controller
binary to obtain its control flow graph and perform dataflow anal-
ysis on critical controller functions. (2) We construct the learning
model with the identified inputs and outputs for specific controller
segments and train an approximate model using the training dataset
from benign experiments. (3) We deploy the learning model as an
online monitor and detect attacks by checking the estimation error
of expected outputs and perceived outputs.
We utilize a learning model to approximate linear and non-linear
controller functions since it can concretize the complicated numer-
ical relations between sensor inputs, controller state variables and
actuator outputs in a semantically-similar way [34] (a.k.a. Chal-
lenge 1). While execution speed and model accuracy are basically
trade-offs for neural networks, we only learn those critical con-
troller segments and accordingly train a well-defined neural net-
work model, which can be compressed to accelerate its inference
(a.k.a. Challenge 2). Meanwhile, we leverage the program-level
dataflow analysis [19, 32, 65] to improve the transparency and
explainability of our model instead of learning the entire control
program as a black-box. Note that our DNN-based model is more ex-
plainable 4 since we force it to reason about intermediate concepts,
as is done in concept bottleneck methods [52].
4.2 Control Program Instrumentation and
Dataflow Analysis
Identifying The Critical Controller Segments. To construct the
learning-based approximate model, Mini-Me needs to define the
input and output vectors instead of blindly training the model with
sensors and actuators. The monitoring function also needs to be
inserted into the main control loop of the RAV’s control program.
With the binary executable of the target RAV controller, we identify
the frequently executing controller functions such as PID controller
and extended Kalman filter (EKF). The mathematical functions span
the linear and non-linear controllers, which take the sensor mea-
surements and vehicle dynamics as inputs to calculate the outputs
for actuators. We reverse engineer the RAV’s controller firmware
4In interpretable AI domain, explainability is often referred as giving explanations of
a particular decision, and the root cause of the intrusion events for RAVs is studied
in [25, 48]
4
Figure 2: High-level architecture of Mini-Me
by lifting the binary executable to LLVM intermediate represen-
tative (IR). We obtain the memory-map I/O locations and resolve
the binary-lifting imprecision using memory layout information
(e.g., type of microcontroller unit (MCU) chip) and in-application
debugging tools [2, 6]. We apply symbolic taint analysis [66] on
its control flow graph (CFG) to trace all the functions calls that
correlate to the sensors and actuators.
Based on our empirical analysis during the drone’s actual flight
operations, the core controller functions often execute frequently
and thus take up the most significant share of the total time con-
sumption in the main control loop, especially those functions that
contain intensive numerical calculations (e.g., Jacobian matrix).
Therefore, we identify those critical controller functions by check-
ing their execution frequency and the arithmetical features (e.g.,
addition, multiplication operations of floating-point). Specifically,
we first locate the interested mathematical functions in the main
control loop through the CFG. We apply the time profiling and col-
lect their calling frequency information using the dynamic binary
instrumentation framework (e.g.,Valgrind [13]) as shown in [27].
Meanwhile, we recursively traverse their inner basic blocks to fetch
the arithmetical statistics (e.g., number of arithmetical instructions).
Through these analyses, we collect the metadata of interested con-
troller functions.
Pinpoint State Variables via Dataflow Analysis.
In order
to create an approximate model of the controller functions we ex-
tracted from previous steps, we need to determine the state variables
including critical control parameters and vehicle dynamics that are
used (e.g., target velocity) and defined (e.g., updated velocity) in
the function. Our goal in this analysis is to refine the interested
controller function and investigate the value changes of those state
variables and their mutual dependencies to build the input and
output vector of the learning model. This helps us to construct a
transparent model with explainable intermediate concepts [42, 52].
To pinpoint the memory locations of these variables, semantic
annotation works [45, 69] use the mathematical templates of con-
troller functions to decompose the control logic. These works need
extra information about the RAV platform (e.g., memory layout)
that varies for RAV applications. Instead, we use static dataflow
analysis via LLVM passes [8] to identify those state variables in the
interested code segment. Specifically, We design the dataflow anal-
ysis in three procedures as shown in Algorithm 1: (1) We extract
Controller BinaryControl Flow GraphDataflow AnalysisData CollectionLearning modelTraining Runtime Monitoring Control Program Instrumentation (Section 4.2)Approximate Model(Section 4.3)OnlineDetection(Section 4.4)431Figure 3: Dataflow analysis example for input and output nodes generation of neural network. Code segments are taken from
Crazyflie 2.0 firmware and simplified for readability.
its basic blocks list from entry point to exit point for the identified
controller segment (Line 3). (2) We build the input set, as the set
of variables that are used in the basic block before being defined,
and the output set, as the set of all the variables assignment within
each basic block (Line 4-7). (3) We merge this information through
instructions and solve the dataflow equations in a conservative
way (Line 10-12), that is, we will include both the variable itself
and possible alias of the same variable observed in intermediate
parameters, array accesses, and indirect reference processes. Note
that, alias objects are taken conservatively here by LLVM pointer
analysis [7, 53] because they will be marked as repeated features
and pruned in the preprocessing of the training dataset. For each
controller segment, we finalize the input and output set to describe
the value changes of state variables. In addition, we can also adjust
the final variable sets based on a few other factors outside of the
code segment such as macro definitions and global variables.
for all S ∈ CFG do
Input′ ←
Output′ ←
Algorithm 1 Dataflow analysis pass for basic blocks
1: Initialize: Input[S] ← ϕ; Output[S] ← ϕ; for all S ∈ CFG
2: Repeat
3:
4:
5:
6:
7:
8:
9: Until
10:
11:
12:
Input[S] ← use[S] ∪ Input′
Output[S] ← def [S] ∪ (Output′ − use[S])
end for
for all S ∈ CFG do
end for
▷ explore all basic blocks
n∈pr ed[S] Input[n]
▷ get inputs from predecessors
n∈pr ed[S] Output[n] ▷ get outputs from predecessors
▷ take use variable as input
▷ build output vector
Input′ = Input[S] and Output′ = Output[S]
▷ stop until all dataflow information get collected
4.3 Learning-based Approximate Model
Construction
After identifying the critical controller segment (e.g., velocity con-
trol) and its input vector (e.g., target velocity, PID sub-module
measurements) and output vector (e.g., updated velocity) in the
above steps, we collect the benign experimental dataset to train
the learning model and compress it for the practical deployment at
runtime.
Data Collection and Preprocessing. To collect an adequate
dataset for model training, we randomly generate the legitimate
path-following missions under different environmental conditions
(e.g., wind). Except for those physical dynamics already in the
default RAVs system logger (e.g., attitude angles in ArduCoper), we
employ Valgrind [13, 27] to trace the memory readings and writings
of intermediate state variables in the identified controller code
disassembly. Therefore, we collect the time-series dataset in real
benign experiments. Note that we can generate a good amount of
sample data in ArduCopter [11] since its default logging frequency
is about 16.67HZ (i.e., every 60 milliseconds), which means, about
900 to 1000 valid samples (e.g., input and output vector pairs) will
be generated in a typical 60 seconds mission (e.g., takeoff, follow
the paths and travel through 5 waypoints, land) with ArduCopter
simulators.
(a) Vector-to-vector training dataset
Case Study. The dataflow information is processed and cal-
culated in the LLVM IR level. Figure 3 presents a simplified case