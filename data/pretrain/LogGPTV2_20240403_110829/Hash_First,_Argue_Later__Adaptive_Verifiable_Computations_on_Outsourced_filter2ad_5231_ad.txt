δ · σx
k.
14
Theorem 4.3 (Adaptive Soundness of XP2). If the SXDH assumption holds in G1, then the XP2
construction above is adaptively sound (Deﬁnition 3.1 for multiple relations and a designated veri-
ﬁer).
We outline the intuition behind the proof of the Theorem. The values (H k
i )i are pseudorandom
(by SXDH), and thus so are (Ti)i. After making a hybrid step where their distribution is changed
to random, the value of δ becomes information-theoretically hidden from the adversary, making its
probability of cheating negligible.
For more details we refer the reader to the proof of Theorem C.1 in Appendix C since Theo-
rem 4.3 can be seen as its SXDH instantiation.
Interestingly, the scheme above can be
A publicly veriﬁable variant in the generic group.
modiﬁed to become publicly veriﬁable as follows: we publish (gδ
2 ) as part of VKF , and use these
elements with a pairing in the veriﬁcation algorithm. The resulting scheme has the advantage of
being more eﬃcient than XP1. As a drawback, we can only argue its security in the generic group
model, and leave this analysis for the full version of this work.
2, gk
Hash Extractability. We note that we can make the construction XP2 hash extractable by
incorporating a knowledge component, in the same way as we show for XP1.
4.4 Additional Properties of Our Instantiation
By plugging XP1 (or XP2) into the generic HPgen construction of Section 4.1 we obtain an eﬃcient
HP scheme that can handle any relation supported by the underlying SNARK system.
A useful property of the hash function of both our constructions XP1 and XP2 is its (additive)
homomorphism, i.e., Hash(x1) · Hash(x2) = Hash(x1 + x2). This property turns out to have several
applications, which we summarize below.
i
Incremental hashing for data streaming applications. The hash of our construction can be
computed incrementally as σi ← σi−1· H xi
(with σ0 = 1). This is particularly useful in applications
where a resource-constrained device outsources a data stream x1, x2, . . . to a remote server while
keeping locally only a small digest σi computed as above. Later, at any point, the client will be
able to verify a computation on the stream x1, . . . , xi by only using σi. Furthermore, when hash
extractability is not needed, the XP1 construction can be modiﬁed by letting Hi = RO(i) where RO
is a hash function that in the security proof is modeled as a random oracle (we omit a proof for this
case which is straightforward: simply simulate RO(i) as the Hi in the current proof). This simple
trick allows for constant-size public parameters and, more interestingly, to work with a potentially
unbounded input size n—a feature particularly useful in streaming scenarios.
updates. Given a hash σx = (cid:81)
Eﬃcient hash updates. Another application of the homomorphic property is eﬃcient hash
xi on a vector x = (x1, . . . , xn), one can easily update the
i-th location from xi to x(cid:48)
i. Instead of recomputing the hash from scratch (which would require
work linear in n), one simply does a constant-time computation σx(cid:48) = σx · Hi
i−xi. This trick
x(cid:48)
also generalizes to updating multiple locations in time linear only in the number of locations that
require an update.
i Hi
in a distributed manner. For instance, one user computes σx,k = (cid:81)
computes σx,(cid:96) =(cid:81)
Multiple data sources. The homomorphic property also implies that the hash can be computed
, a second user
, and then a veriﬁer who receives σx,k and σx,(cid:96) can reconstruct the
full digest on (x1, . . . , x(cid:96)) with a single multiplication. This feature is useful in those applications
where the data is provided by multiple trusted sources, in which case only small digests have to be
communicated. (For example, consider training a machine learning model using diﬀerent datasets.)
i∈[k+1,(cid:96)] H xi
i
i∈[1,k] H xi
i
15
Randomizing hash values. If one of the xi inputs of the hash is uniformly random in Zp, then
the output of Hash(pp, x) is a uniformly random element in G1. Showing that SNARK systems
randomized in this fashion do not leak anything about their hashed data is less trivial as the same
randomness is reused by σx and the cx values of diﬀerent relations. This is akin to randomness reuse
in ElGamal encryption, which is permissible. However, in most SNARK systems the group elements
used for commitment randomization have structure, precluding a straightforward reduction to DDH.
A detailed analysis of a multi-relation zero-knowledge property for speciﬁc VC schemes is thus an
interesting open problem.
From hashes to accumulators. Accumulators are often used as succinct representations of
sets that enable fast, limited, veriﬁable processing. For example, one can eﬃciently prove and
verify arguments on set operations by exploiting the structure of accumulators [38], with better
performance than by relying on a general-purpose VC scheme. To this end, we oﬀer schemes
that allow one to transition between proof systems that operate on hashes and accumulators. In
particular, we introduce Accumulate & Prove scheme which is a variant of HP that operates on
accumulators and builds on HP and XP (to verify that the hash and the accumulator were computed
from same data). We provide the detailed scheme in Appendix E.
5 Outsourcing Hash Computations
In our eﬃcient HP constructions of Section 4, the Hash algorithm computes a succinct digest σx
using one exponentiation for every element of x. Hence, when using instantiations with XP1 or
XP2, an HPgen veriﬁer that wishes to relate computations veriﬁed using σx to their actual inputs x
must still perform |x| exponentiations, or trust some data provider that associates σx to x. Though
the same σx could be used to verify many computations that involve x, thereby amortizing the cost
of hash computation, we are looking to further optimize this cost.
Next, we describe a complementary technique to outsource hash computations to an untrusted
party such that the veriﬁer (or its trusted data provider) only needs to perform |x| ﬁeld multi-
plications and one eﬃcient cryptographic hash on x, say SHA2, typically saving two orders of
magnitude.
We present our construction, called HP∗, as a generic extension of any HP system to which it
adds support for veriﬁable outsourcing of hash computations. The main beneﬁt of this extension is
that the veriﬁer does not need to run the Hash algorithm: instead, it can upload x to the untrusted
prover; obtain its hash σx together with a proof of hashing Πh, verify them; and ﬁnally keep σx.
Intuitively, the veriﬁer can then use σx to refer to x as if it had computed it itself.
5.1 Deﬁnition
We deﬁne HP∗ as an extension of a given hash & prove scheme HP. In particular, the functionality
of the trusted Hash algorithm is supplemented with a pair of new algorithms, HashProve and
HashVerify, run respectively by the untrusted prover and by the veriﬁer. HashProve computes a
hash of data x and augments it with a proof that the hash is computed correctly (that is, it is
computed according to Hash algorithm). HashVerify then accepts σx as the hash if the proof veriﬁes
correctly.
Formally, HP∗ is a multi-relation hash & prove scheme that supports hash outsourcing and con-
(Setup, Hash, HashProve, HashVerify, KeyGen, Prove,
sists
Verify). For completeness, we list Setup, Hash, KeyGen, Prove and Verify, however they are de-
ﬁned identically to those in HP (cf. Section 3).
algorithms
HP∗
of
7
=
16
pp, vp ← Setup(1λ) takes the security parameter and generates the public parameter for the scheme;
σx ← Hash(pp, x) produces a hash given some data x ∈ X;
Πh ← HashProve(pp, x, σx) produces a proof of RHash(x, σx) = (σx
?= Hash(pp, x)) given some data
bh ← HashVerify(vp, x, σx, Πh) either accepts (bh = 1) or rejects (bh = 0) a proof that σx is a hash
x ∈ X and hash σx;
of data x.
R ∈ Rλ;
EKR, VKR ← KeyGen(pp, R) generates evaluation key EKR and veriﬁcation key VKR given a relation
ΠR ← Prove(EKR, x, v ; w) produces a proof of R(x, v ; w) given an instance and a witness that
satisfy the relation.
b ← Verify(VKR, σx, v, ΠR) either accepts (b = 1) or rejects (b = 0) a proof of R given a hash of x
and the rest of its instance v.
In addition to being a Hash & Prove scheme (i.e., satisfying adaptive soundness or adaptive hash
soundness), HP∗ must be secure with regards to outsourcing, as deﬁned below.
Deﬁnition 5.1 (Sound Hash Outsourcing). Outsourcing of HP∗ hash computation is secure if every
p.p.t. adversaries wins the game below only with negligible probability.
Outsourced Hash Game
pp, vp ← Setup(1λ)
x, Πh ← A(1λ, pp, vp)
x, σ∗
A wins if HashVerify(vp, x, σ∗
x, Πh) = 1 and σ∗
x (cid:54)= Hash(pp, x)
This game is similar to the Hash Extraction game, but it does not involve extraction, as the
(The designated-veriﬁability variant is obtained by keeping vp
veriﬁer is given both x and σ∗
x.
private and, instead, giving the adversary oracle access to HashVerify.)
Hash outsourcing ensures that, when verifying composite arguments as in adaptive hash sound
schemes (cf. Section 3.2), one can safely replace calls to Hash with calls to HashVerify. In particular,
with HP∗, an argument can be passed to a relation either as data x, as a hash σ or as (x, σ∗). Our
deﬁnition can be trivially satisﬁed by ignoring Πh and setting HashVerify(pp, x, σ, Πh) = (σ ?=
Hash(pp, x)) but of course we are looking for more eﬃcient constructions.
5.2 Eﬃcient Construction (HP∗)
We build HP∗ out of any hash & prove scheme HP, and two additional tools: an almost universal
hash function h (recalled below) and a regular hash function H (that will be modeled as a random
oracle).
p to Zp, instantiated by hα(x) = (cid:80)n
Almost Universal Hash Functions. An -almost universal hash function h is such that, for all
x (cid:54)= x(cid:48) chosen before h is sampled, we have Prh[h(x) = h(x(cid:48))] ≤  [13]. We will use such functions
i=1 xiαi−1 and keyed with a random α ∈ Zp. These
from Zn
functions can be computed as hα(x) = x1 + α(x2 + . . . α(xn−1 + αxn))) using n additions and n− 1
multiplications by α, which is particularly eﬃcient in veriﬁable-computation schemes for arithmetic
circuits.
Lemma 5.1. hα is (n − 1)/p-almost universal.
17
Proof. Expanding the collision equality, we get (cid:80)n
i=1 xiαi−1 = (cid:80)n
iαi−1, that is, (cid:80)n
i=1(xi −
i)αi−1 = 0. If x (cid:54)= x(cid:48), we have a non-zero polynomial in α of degree at most n − 1, with at most
x(cid:48)
n − 1 roots, so this equality holds with probability at most (n − 1)/p.
i=1 x(cid:48)
Before delving into the details of the construction, let us describe its main ideas. The ﬁrst idea
is to build HP∗ by extending any HP with algorithms HashProve and HashVerify that allow to prove
?= Hash(x). Notably, HashVerify must be signiﬁcantly faster than
and verify the correctness of σx
recomputing Hash(x). To this end, our second idea is to let HashProve compute a (freshly sampled)
universal hash function hα(x) and generate a proof Πh that links hα(x) to the correct σx. Then our
HashVerify simply checks Πh (in constant time) and recomputes the universal hash hα(x), which
is much faster than the multi-exponentiation Hash. The security of universal hash functions relies
on their input being chosen before hα is sampled. To this end, we require that hα depend on the
input x by setting α = H(x, σx) where H is a hash function.
We are now ready to give our HP∗ construction. Let Rh be the relation deﬁned by Rh(x, α, µ) =
(µ ?= hα(x)), and let H be a hash function. We build HP∗ using any HP that supports relation Rh
and is hash-extractable.
Setup(1λ) runs setup and generates keys for outsourcing h:
pp(cid:48) ← HP.Setup(1λ);
EKh, VKh ← HP.KeyGen(pp(cid:48), Rh);
return pp = (pp(cid:48), EKh) and vp = VKh;
HashProve(pp, x, σx) computes α = H(x, σx); µ = hα(x); Πh ← HP.Prove(EKh, x, (α, µ)) and re-
turns Πh;
HashVerify(vp, x, σx, Πh) computes α = H(x, σx); µ = hα(x) and checks HP.Verify(VKh, σx, (α, µ), Πh).
We omit Hash, KeyGen, Prove and Verify algorithms as they are simply calls to their counterparts
in the HP scheme (for example, HP∗.KeyGen calls HP.KeyGen(pp(cid:48), R)).
We stress that, even if asymptotically our new construction is not better than the original one
(the veriﬁer performs Θ(n) operations), in practice, the operations performed by the veriﬁer in
HP∗.HashVerify are orders of magnitude faster than those in HP.Hash.
Discussion. Applying HP∗ to our eﬃcient constructions of Section 4 (either public or designated
veriﬁer), our proofs now carry a fourth representation µ = hα(x) of x in addition to its hash σx,
its commitment cx, and a proof Φx. Note that we rely on extraction only for the witnesses x of the
ﬁxed relation Rh.
To avoid random oracles, we can use an interactive, designated veriﬁer variant of HP∗, whereby
(1) the prover commits to x and σx; (2) the veriﬁer sends a fresh random α; (3) the prover produces
a proof of Rh; (4) the veriﬁer checks the proof against x and σx, as above.
Security. We ﬁnally state the security of hash outsourcing:
Theorem 5.1. In the random oracle model for H, if hα is an -almost universal hash function,
HP is adaptively sound and hash extractable in publicly veriﬁable (resp. designated veriﬁer) setting,
then HP∗ is sound for outsourcing of hash computations as per Deﬁnition 5.1 in publicly veriﬁable
(resp. designated veriﬁer) setting.
Proof Outline. Assuming H is a random oracle, the proof proceeds in a sequence of games. Let A
be the adversary in Deﬁnition 5.1 and x, σ∗
x, Πh be his forgery.
18
Game 0: Outsourced Hash Game.
Game 1: Let Aσ be the adversary obtained by taking pp, vp as input, running A, H internally,
and returning σ. Note that Aσ does not take auxiliary input since it takes pp, vp as input and
runs from the beginning of the experiment. Game 1 is the same as Game 0, except that for
every successful adversary we execute the challenger together with the knowledge extractor
Eσ whose existence is guaranteed by hash extractability. The game aborts without A winning
if Eσ fails to extract a value x(cid:48) from which we can reconstruct σ.
Game 2: The same as Game 1, except the game aborts if ¬Rh(x(cid:48), α, µ) where α ← H(x, σ) and
µ = hα(x).
In Appendix D.5 we show that the three games are indistinguishable as well as that any adversary
has negligible probability of winning in Game 2.
We note that all HP constructions in Section 4 can be made hash extractable (meeting require-
ments of Theorem 5.1) and can be used for secure hash outsourcing.
6 Evaluation
In this section, we analyze and measure the performance of our new HP constructions compared
to previous solutions.
Our evaluation is twofold. First we analyze the eﬃciency of our scheme HPgen from Section 4
(instantiated with Geppetto [20] and XP1) and we compare it against the inner encoding construc-
tion HPinn of Section 3.3 (also instantiated with Geppetto and various choices of the hash function).
Second, we report on the impact of our hash outsourcing technique of Section 5 in speeding up