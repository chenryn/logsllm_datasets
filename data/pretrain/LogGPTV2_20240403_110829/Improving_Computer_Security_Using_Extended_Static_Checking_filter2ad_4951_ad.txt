written pseudo-random number routines.
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
4.2 Run-time Checking
4.3 Static Checking
Most operating systems prevent programs from per-
forming grossly aberrant behavior (illegal memory ac-
cess for example), and some programming languages
and environments provide features for more advanced
monitoring. Perl uses a data tainting model to insure
that user-supplied commands are not executed directly
in UNIX setuid scripts [31].
Javascript uses a simi-
lar approach to protect a user’s privacy by preventing
user-speciﬁc data from being transmitted over the net-
work [12]. Java provides a ﬂexible mechanism for con-
trolling the run-time security policy enforced by the Java
virtual machine [15].
Some of C’s inherent weaknesses can be overcome
through the use of runtime checking too.
Jones and
Kelly [16] propose a scheme for adding object bounds
checks at compile-time, but standard libraries that are
not recompiled remain vulnerable to buffer overﬂow at-
tacks, and the performance of checked programs may
suffer. Similarly, program instrumentation approaches
like the one taken by Purify [14] are usually impracti-
cal because of performance degradation and increased
memory usage. Format string vulnerabilities, where an
attacker makes use of a function with a printf-style
format string argument to perform an attack with results
much like a buffer overﬂow, can be thwarted at runtime
with minimal computational overhead [5, 26].
Necula [22] proposes a combination of formal rea-
soning and load-time checking with his system for pack-
aging proofs with executable programs. Before a pro-
gram is executed, its proof can be checked in order to
make sure that the code will maintain the system’s safety
and security policies. Because the topic of the proof is
assembly code, the types of properties that can be easily
proven are at a correspondingly low level. Necula sug-
gests that his approach would be useful for determining
whether or not to allow a piece of code to execute in the
kernel’s address space by requiring a proof that the pro-
gram will maintain the consistency of the kernel’s data
structures. This would be efﬁcient because proof check-
ing is much faster than proof construction, and once a
piece of code had been approved, no further effort to
constrain its behavior would be necessary. In Necula’s
view, producing proofs should be part of the function of
a compiler.
LCLint is a C program checker [10]. Without adding
speciﬁcations to the program being checked, it’s abil-
ity to ﬁnd errors is limited to the same realm as most
lint programs. With programmer-supplied speciﬁca-
tions, it is able to perform additional checks by applying
compiler ﬂow analysis techniques. It can ﬁnd abstrac-
tion violations, unannounced modiﬁcations to global
variables, and possible use-before-initialization errors.
While these are all common sources of problems in C
programs, none of them are direct widespread causes of
security ﬂaws.
Larochelle and Evans have modiﬁed LCLint in order
to statically detect buffer overﬂow vulnerabilities [18].
Their method is similar to the one taken here, but limited
to reasoning about minimum and maximum array in-
dices that may be read or written. Programmer-provided
preconditions and postconditions combined with built-
in speciﬁcations for standard libraries are used in com-
bination with the program itself in order to generate a
set of constraints. If the constraints cannot be resolved,
then a buffer overﬂow ﬂaw may be present. Unlike the
approach taken here, a programmer cannot write addi-
tional speciﬁcations in order to use the modiﬁed version
of LCLint to ﬁnd new types of vulnerabilities.
Wagner et al. have developed a static checker that
uses integer range analysis in order to determine whether
or not a C program contains potential buffer overﬂow
errors [30]. While capable of ﬁnding many errors that
lexical analysis tools would miss, the checker is still
somewhat imprecise: it ignores statement order, it can-
not model interprocedural dependencies, and it ignores
pointer aliasing.
Inspired by Perl’s taint mode, Shankar et al. make
use of type qualiﬁers in order to perform a taint analysis
for the purpose of statically detecting format string vul-
nerabilities in C programs [27]. Their system requires
a programmer to annotate a small number of variables
as either tainted or untainted and then uses type infer-
ence rules (along with pre-annotated system libraries) to
propagate the qualiﬁers. Once the qualiﬁers have been
propagated, the system can detect format string vulnera-
bilities by performing type checking.
5 Conclusions
While it is inconceivable that any single method will
solve all computer security problems, we have shown
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
that signiﬁcant classes of vulnerabilities can be detected
in source code using extended static checking. While we
have focussed much of this paper on demonstrating that
point, another measure of the utility of the approach is
the range of security vulnerabilities that it cannot detect.
Flaws may go undetected because of the way that
Eau Claire models C programs. A vulnerability may de-
pend on the execution of a function pointer (an unmod-
eled construct) or the way the program behaves when an
illegal operation occurs (Eau Claire assumes that illegal
operations do not occur). While shortcomings like this
will probably always exist, they primarily betray a lack-
ing in our implementation rather than in our method.
Eau Claire can only ﬁnd security ﬂaws for which it
has speciﬁcations. Since new types of ﬂaws are rou-
tinely discovered, a program that meets all available
speciﬁcations today may prove to be insecure tomorrow.
Simplify, the theorem prover Eau Claire uses, does
not reason about induction. Consequently Eau Claire’s
speciﬁcation language does not contain any recursive
constructs. We have not encountered any real-world vul-
nerabilities that require recursion in their speciﬁcations,
so this has not yet been a problem.
Quite a number of security vulnerabilities are not the
result of programming logic errors. If a system’s design
is fundamentally insecure, then it is unlikely that a static
checker will reveal the problem. For example, if a sys-
tem design does not require that users select good pass-
words, then it is unlikely that a static checker could de-
termine that, although password authentication is imple-
mented correctly, the passwords might be easy to guess.
Finally, if tools like Eau Claire are not put to use, then
they will not ﬁnd ﬂaws. The most likely reason for a pro-
grammer to ignore extended static checking is because
they do not believe that their efforts will be rewarded.
However, one form of static checking, type checking,
has long been embraced by programmers. Although it
is imperfect, type checking has been successful because
the rewards it provides far outweigh the cost of its use.
Program veriﬁcation technology has not fared so well,
and perhaps part of the reason is that the rewards do not
appear to outweigh the cost. Conventional wisdom holds
that the undecidable nature of most static analysis ques-
tions implies that program veriﬁcation techniques are a
mirage, that there is no reward to be had. On the other
side of the equation, fully specifying the behavior of a
program is a daunting task.
In this case the conventional wisdom is wrong. ex-
tended static checking makes use of program veriﬁca-
tion techniques and is, as we have demonstrated, capa-
ble of detecting common types of security vulnerabili-
ties. This is a heafty reward because security problems
are difﬁcult to detect by other means and the penalty for
missing them can be severe. The cost of extended static
checking is variable. At the low end, a programmer can
make use of pre-existing speciﬁcation libraries to check
for common ﬂaws. The checker can be invoked much
like a compiler, and the time required to perform the
checking is typically a small multiple of a compiler’s
execution time. A user who is willing to invest effort
in writing speciﬁcations can improve the precision and
accuracy of the checker and also check for new types of
ﬂaws or ﬂaws that are speciﬁc to their problem domain.
Acknowledgements
We would like to thank Greg Nelson for his guidance
and patience and the anonymous referees for their con-
structive feedback.
References
[1] R. Back and J. von Wright. Reﬁnement Calculus:
A systematic Introduction. Graduate Texts in Com-
puter Science. Springer-Verlag, 1998.
[2] M. Bishop and M. Dilger. Checking for race
conditions in ﬁle accesses. Computing Systems,
9(2):132–152, Spring 1996.
[3] RSAREF buffer overﬂow. The bugtraq mailing list:
http://www.securityfocus.com. Vulnerability 843.
[4] Linux capabilities vulnerability. The bugtraq mail-
ing list: http://www.securityfocus.com. Vulnera-
bility 1322.
[5] C. Cowan, M. Barringer, S. Beattie, and G. Kroah-
Formatguard: Automatic protection
In Pro-
the USENIX Security Symposium,
Hartman.
from printf format string vulnerabilities.
ceedings of
2001.
[6] D. Detlefs. An overview of the extended static
checking system. In The ﬁrst Formal Methods in
Software Practice workshop collocated with ISSTA
96, 1995.
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
[7] D. L. Detlefs, K. R. M. Leino, G. Nelson, and J. B.
Saxe. Extended static checking. Technical Report
159, Compaq Systems Research Center, December
1998.
[20] K. R. M. Leino, J. B. Saxe, and Raymie Stata.
Checking Java programs via guarded commands.
Technical Report 1999-02, Compaq Systems Re-
search Center, May 1999.
[8] D. L. Detlefs, G. Nelson, and J. B. Saxe. Simplify:
the ESC theorem prover. Unpublished manuscript,
November 1996.
[21] M. S. Manasse and C. G. Nelson. Correct compila-
tion of control structures. Technical report, AT&T
Bell Laboratories, September 1984.
[9] E. W. Dijkstra. A Discipline of Programming.
Prentice-Hall, Englewood Cliffs, NJ, 1976.
[10] D. Evans, J. Guttag, J Horning, and Y. M. Tan.
LCLint: a tool for using speciﬁcations to check
code. In Symposium on the foundations of software
engineering. SIGSOFT, December 1994.
[11] C. Flanagan and J. B. Saxe. Avoiding exponential
explosion: Generating compact veriﬁcation condi-
tions. In Symposium on the Principles of Program-
ming Languages. ACM, 2001.
[12] D. Flanagan. JavaScript: The Deﬁnitive Guide.
O’Reilly & Associates, 1996.
[13] S. P. Harbison and G. L. Steele Jr. C, a Refer-
ence Manual. Prentice-Hall, Englewood Cliffs, NJ,
1995.
[14] R. Hastings and B. Joyce. Purify: Fast detection of
memory leaks and access errors. In Proceedings of
the Winter USENIX Conference, pages 125–136,
1992.
[15] The Java security home page. On the web as
http://java.sun.com/security/.
[16] R. W. M. Jones and P. H. J. Kelly. Backwards-
compatible bounds checking for arrays and point-
ers in c programs. In Third International Workshop
on Automated Debugging, 1997.
[17] C. E. Landwehr, A. R. Bull, J. P. McDermott, and
W. S. Choi. A taxonomy of computer security
ﬂaws. ACM Computing Surveys, 26(3):211–254,
September 1994.
[18] D. Larochelle and D. Evans. Statically detect-
ing likely buffer overﬂow vulnerabilities. In 2001
USENIX Security Symposium, August 2001.
[19] K. R. M. Leino. Toward Reliable Modular Pro-
grams. PhD thesis, California Institute of Technol-
ogy, 1995.
[22] G. Necula. Proof-carrying code. In Proceedings
of the Symposium on Principles of Programming
Languages. ACM, 1997.
[23] G. Nelson. Pointers are bad, records are bad, but
record-pointers are good. Technical report, Xerox,
Palo Alto Research Center, November 1982.
[24] M. Norrish. C Formalised in HOL. PhD thesis,
University of Cambridge, 1998.
[25] File access problems in lpr/lpd. Redhat Security
Advisory, October 1999. RHSA-1999:041-01.
[26] T. J. Robbins.
libformat.
On the web as
http://box3n.gumbynet.org/fyre/software
/libformat.pdf.
[27] U. Shankar, K. Talwar, J. S. Foster, and D. Wag-
ner. Detecting format string vulnerabilities with
type qualiﬁers. In Proceedings of the 10th USENIX
Security Symposium, August 2001.
[28] The Simplify home page, Compaq Systems Re-
search Center. On the web as http://research
.compaq.com/SRC/esc/Simplify.html.
[29] J. Viega, J. T. Bloch, T. Kohno, and G. McGraw.
ITS4: A static vulnerability scanner for C and C++
code.
In Proceedings of the Annual Computer
Security Applications Conference. Applied Com-
puter Security Associates, 2000.
[30] D. Wagner, J. S. Foster, E. A. Brewer, and A Aiken.
A ﬁrst step towards automated detection of buffer
overrun vulnerabilities. In Proceedings of the Net-
work and distributed system security symposium,
February 2000.
[31] L. Wall, T. Christiansen, and R. Schwartz. Pro-
gramming Perl. O’Reilly & Associates, 1996.
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE