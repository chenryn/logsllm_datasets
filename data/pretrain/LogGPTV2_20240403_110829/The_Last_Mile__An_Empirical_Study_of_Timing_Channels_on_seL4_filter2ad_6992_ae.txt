# Analysis of Timing Channels and Mitigation Strategies

## 1. Introduction
This document presents an empirical analysis of timing channels in the verified seL4 microkernel, focusing on both local and remote attacks. The study evaluates various mitigation strategies, including instruction-based scheduling (IBS), cache coloring, and scheduled delivery. The results highlight the importance of a systematic experimental approach to determining channel bandwidth and the challenges in closing timing channels even for small, high-assurance systems.

## 2. Experimental Setup and Results

### 2.1 Response Time Analysis
**Figure 13: Response times for OpenSSL 1.0.1c, intercontinental distance. 105 samples, 10µs bins.**

| P0.02 | P0.01 | P0 |
|-------|-------|----|
| M0    | 183   | 183.5 |
| M1    | 184   | 184.5 |
|       | 185   | 185.5 |
|       | 186   |      |

**Response time (ms)**

As shown in rows 2–4 of Table 3, while distinguishability (and hence vulnerability) decreases with increasing network distance, the reduction is very slow. The attack remains feasible even at the greatest separation tested—launching the attack from an Amazon EC2 instance in Oregon, USA, against a target machine in Sydney, Australia. Despite many routing hops, firewalls, and significant physical distance, the attacker still guesses correctly with 62% probability given only one observation. This indicates that network distance provides extremely poor protection against timing channels, and variations as small as 10µs are easily distinguishable across the internet with good connectivity. Figure 13 illustrates the two distributions, supporting the mathematical analysis summarized in Figure 2, which shows that adding noise (e.g., network jitter) provides inadequate protection against timing channels.

### 2.2 Scheduled Delivery
Our countermeasure to this channel is a system-level black-box approach that avoids the difficulty of producing portable constant-time algorithms. We leverage the fast context-switches and well-understood temporal behavior of seL4 [Blackham et al., 2011] to impose precise delays on communication. Recent work [Askarov et al., 2010] suggests policies for automatically setting such delays, and we provide an efficient mechanism.

The effect of a manually-tuned delay is shown by the central (SD) pair of peaks in Figure 12. As rows 5 and 6 of Table 3 show, we achieve a lower vulnerability than the constant-time implementation of OpenSSL (57% distinguishability or 0.03 b leak of min entropy vs. 62% and 0.07 b). Despite this, our countermeasure reduces latency by 6% compared to CD. The better matching between the curves occurs because nothing in our implementation is data-dependent, and the only intrinsic penalty is the cost of blocking and restarting the server, which is approximately 10µs. We have not yet identified the cause of the small remaining variation in response time. For a detailed analysis of this approach, see Cock [2014].

### 2.3 Performance and Overhead
**Figure 14: Performance and overhead of scheduled delivery, OpenSSL 1.0.1c, and 1.0.1e (constant-time).**

| CPU Load | Ingress Rate (packets/s) |
|----------|-------------------------|
| 0        | 0                       |
| 1.0.1c   | 1000                    |
| 1.0.1e   | 2000                    |
| 1.0.1c-sd 1 thread | 3000 |
| 1.0.1c-sd 2 threads |  |

Each curve in Figure 14 plots CPU load against packet ingress rate, up to the point where packet loss begins (single CPU). For the unmodified OpenSSL 1.0.1c (blue), load increases linearly, with loss beginning at 3000 packets per second due to saturation. The constant-time OpenSSL 1.0.1e (red) shows a 10% CPU overhead, consistent with the increased latency observed in Figure 12, and earlier saturation at 2800 p/s. The extra cycles are wasted ensuring that execution time is always worst case.

The next curve (green), for a single-threaded server under SD, is close to that for the vulnerable version, with only a 1.7% overhead. This is the benefit of not wasting time in a constant-time implementation. Instead of busy-waiting, we idle by entering a low-power sleep state, which is advantageous for mobile devices.

However, packet loss begins at 1400 p/s, as packets arriving while sleeping are dropped, limiting throughput. This is an extreme case, as the echo server does no work, so all CPU time is spent in OpenSSL itself. In any non-trivial system, the server will work while the packet handler sleeps, with no throughput loss once OpenSSL is less than half the load.

The orange curve shows that slack could be reused to run a second server thread. This is not secure (as it transforms latency variation into throughput variation) but demonstrates that we need not suffer a throughput overhead, given a non-trivial application. Except for the excursion between 1300 and 2200 p/s, due to our simplistic prototype ports of lwIP [Dunkels, 2001] and OpenSSL, we regain peak throughput of 2800 p/s, still with better overhead than constant-time.

## 3. Discussion
Our results highlight the importance of a systematic empirical approach to timing channels. It is easy to overlook potential channels, and without establishing sound bounds on bandwidth, one could be misled into a false sense of security.

For example, we expected cache coloring to be an effective countermeasure, even against an attacker with access to an accurate measure of wall-clock time. However, we found the cycle counter to be inaccurate on modern processors and influenced by cache misses, creating a timing channel of its own.

None of the examined countermeasures were perfect: IBS, cache coloring, constant-time implementations, and scheduled delivery all leave residual channels. Our local exploits were performed under the most pessimistic assumption of a malicious agent exploiting a covert channel. The remaining channels may provide sufficient protection in a side-channel scenario, such as a co-hosted cloud environment, but this cannot be stated with certainty.

We must also recognize the limitations of our approach: the precision of our estimates is limited by the quantity of data available. Given a finite number of observations, we can only rule out channels down to a certain bandwidth; there is always the possibility of a residual channel hiding below the limit of our statistical precision. For example, even for our best result, IBS on the iMX.31 showing a bandwidth of essentially zero after 10,000 samples per column, the confidence interval extends to 0.1 b/s, meaning there could be a channel of lower bandwidth that we simply cannot resolve.

Between the release of the iMX.31 in 2005 and the Exynos4412 in 2012, IBS has gone from an essentially perfect countermeasure to a highly ineffective one. This highlights the strong effect that subtle (and generally undocumented) hardware effects have on countermeasures and the value of careful empirical evaluation.

## 4. Related Work
Our empirical approach to timing channels is similar to that of Gay et al. [2013], who measured interrupt-related covert channels (IRCCs) by experimentally determining the channel’s Shannon capacity. However, they assume the channel output follows a binomial distribution to compute Shannon capacity in a closed form, avoiding large channel matrices. They empirically measure only the unmitigated channel bandwidth, while earlier work by Mantel and Sudbrock [2007] involved a theoretical comparison of IRCC mitigation techniques under an information-theoretic channel model.

Cache coloring was originally developed to assist real-time systems in partitioning the L2 cache into non-overlapping domains [Liedtke et al., 1997]. Various hardware mechanisms for cache partitioning have been proposed [Jaleel et al., 2012], although none are available in the platforms we analyze. Godfrey [2013] analyzed cache partitioning on the Xen hypervisor using an actual side-channel attack, while we build a synthetic covert-channel attack and measure the bandwidth reduction. Unlike Godfrey, we partition kernel as well as user memory.

STEALTHMEM [Kim et al., 2012] generalizes the idea of cache partitioning, offering a limited amount of stealth memory rather than partitioning the complete cache. While this leads to potentially less performance impact, it requires modifying applications and is only applicable to trusted entities (senders), while we treat applications as black boxes.

IBS works by correlating clocks and is related to deterministic execution techniques, originally used to debug systems [Aviram et al., 2010a,b; Bergan et al., 2010; Ford, 2012], although without requiring full determinism. It was implemented in the Hails web application framework [Stefan et al., 2013] to address timing channels. Martin et al. [2012] propose modifying the CPU to add noise to the timestamp counter (RDTSC), which we argue is inefficient for high-security applications.

Scheduled delivery considers only the external behavior of a component—its response time—which it delays to reduce leakage. Askarov et al. [2010] and Zhang et al. [2011] present adaptive delay policies to counter remote timing side-channels. We present an efficient mechanism to implement such a policy.

## 5. Conclusions
We have examined representative locally- and remotely-exploitable timing channels on the verified seL4 microkernel and suitable mitigation strategies. We find that IBS and cache coloring (against cache contention) and scheduled delivery against remote attacks are easy to implement in seL4 without impacting its generality. The exception is the L1 cache flush needed for cache coloring, which x86 does not allow, requiring expensive explicit cache trashing.

While these mechanisms are effective on older processors, performance optimization in newer processors introduces imprecision in hardware-generated events, manifesting as non-determinism. The degree of imprecision is frequently affected by user-controlled events, cache misses, or branch mis-predicts, introducing new channels. Thus, more effort is required to treat the cache channel, forcing the OS developer to play catch-up with processor manufacturers.

For remotely-exploitable channels, we find that, at least for the Lucky-13 attack on OpenSSL, OS-level black-box approaches are more effective and come with less latency penalty than the official "constant-time" mitigation.

In summary, closing timing channels remains difficult, even for a small, high-assurance system like seL4. Unexpected results show the importance of a systematic experimental approach to determining channel bandwidth to avoid a false sense of security.

## 6. Acknowledgements
NICTA is funded by the Australian Government through the Department of Communications and the Australian Research Council through the ICT Centre of Excellence Program.

## 7. References
[References listed here, formatted as in the original text]

---

This revised version aims to provide a clearer, more coherent, and professional presentation of the original content.