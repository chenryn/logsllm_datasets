{u1, u2, ..., uN} respectively, then we need to ﬁnd a subset,s(cid:48)
i,
corresponding to every si such that the union of each of these
subsets is strictly less than the total number of switches in
the cloud provider’s network, S. More speciﬁcally, if we let
boolean variables nij represent whether ith switch in set sj lies
in s(cid:48)
j or not, then our network should satisfy the following con-
N(cid:80)
|sj|(cid:80)
i=1
j=1
nij < S. We can express the given constraint as
straint:
Satisﬁability Modulo Theories (SMT) formula, and use a SMT
solver to determine which switches can be exposed to which
users without violating the constraints. Figure 1 shows our
conceptual framework for delegating network control under
certain constraints.
IV. FRAMEWORK INSTANTIATIONS AND TRADEOFF
DISCUSSION
In this section, we demonstrate two possible instantiations
of the framework using FlowVisor and ADVisor. Based on the
two instantiations, we discuss the kind of security tradeoffs
that such systems would face while providing different levels
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:46:41 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 2. Architecture for network control delegation using FlowVisor
Fig. 3. Architecture for network control delegation using ADVisor. Note that
switches C, D and G are masked using virtual links
of network abstractions to end users. Note that the following
architectures can be thought of as particular instantiations of
our conceptual framework in Figure 1. The difference between
the two architectures that follow is how the ‘logic for exposing
views to the users’ creates views for the users.
A. FlowVisor Based Architecture
As mentioned earlier, we leverage existing mechanisms
to achieve our goal of delegating some network control to
end users. As our ﬁrst attempt to provide users control over
their ﬂows we use FlowVisor. Figure 2 shows the proposed
architecture using FlowVisor. As mentioned in II-C, an admin
needs to ﬁrst deﬁne policies in terms of ﬂowspaces in the
FlowVisor. These policies serve to tell FlowVisor, which
controller can see which switches and which packets seen on
those switches should be controlled by a particular controller.
As an example consider what happens when a host A1
which is a VM belonging to UserA generates a packet. The
packet arrives at switchA and since switchA does not have any
ﬂow table entry, it does not know how to forward the packet.
The packet is thus sent to FlowVisor. At this point FlowVisor
checks to see the packet header and decides which ﬂow-
space or controller the packet belongs to. Since this packet
should be under the control of UserA, FlowVisor forwards
the packet to ControllerA for making ﬂow decision for this
packet. ControllerA on receiving this packet pushes new ﬂow
rules into switchA. Note that before this ﬂow rule is forwarded
to the switches, it is inspected and vetted by the FlowVisor
layer so as to ensure that ControllerA does not inadvertently
affect the packets under the ﬂow-space of ControllerB.
The direct visibility of all switches in the path of users’
ﬂows permits to satisfy several local properties, as the archi-
tecture of the underlying network infrastructure is exposed to
users with little mediation. The connectivity property is easily
satisﬁed as long as there is connectivity in the underlying
physical infrastructure. The datacenter consistency property
is satisﬁed, as the exposed physical infrastructure matches
the datacenter architecture. Multi-path is potentially possible,
as long as the underlying physical network provides such a
property.
such an architecture fails
In term of global properties, the non-interference among
users is satisﬁed by design by mediating network ﬂow.
However,
to provide views
satisfying the non-inference property, that is, preventing end
users from mapping the complete underlying topology. This
is true because if users collude with each other they could
put their views of the topology and potentially discover the
complete topology. For example, consider UserA and UserB
in our example, though most of the switches that they control
are not common to each other, sharing their views of the
network would inevitably expose the whole topology.
B. ADVisor Based Architecture:
To overcome this limitation, in our second instantiation we
replace FlowVisor with an instance of ADVisor as shown in
Figure 3. The advantage of using ADVisor over FlowVisor is
that we can abstract away some of the nodes in the physical
topology and present a subset of the resulting view to the users.
The intuition here is that even if a few cloud users collude with
each other and share their views of the network, they will
not be able to discover the exact underlying topology. Hence,
ADVisor permits creating subsets of user views that satisfy
the global property of non-inference. Note that if all the cloud
users collude then nothing can be done to protect the network
topology information but we argue that requiring more users
to collude to discover the topology can mitigate the risk in
practice. However, a limitation of this architecture is that it
provides relatively less ﬂexibility and control to end users as
compared to the FlowVisor based architecture because now
some of the switches have been abstracted away and become
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:46:41 UTC from IEEE Xplore.  Restrictions apply. 
ACDEBAGEFUser A’s ControllerUser B’s ControllerFlowVisorOpenFlowProtocolOpenFlowProtocol1010100DBOpenFlowProtocolA1A21010100ACGFEB1B2GFACDEBAGEFUser A’s ControllerUser B’s ControllerADVisorOpenFlowProtocolOpenFlowProtocolOpenFlowProtocolDBA1A21010100ACGFEB1B21010100GFpart of virtual links and hence are not controllable by the users
anymore. As the number of abstracted switches increases, the
user views lose properties such as datacenter consistency or
geographic consistency. Entire portions of the infrastructure
might be seen as being part of the same network, while actual
hosts might be distributed across data centers or geographic
regions.
ADVisor is useful in providing virtual links to mask some
of the physical switches on a given path between two physical
switches but it will be more useful to have a mechanism to not
only mask the physical switches as virtual links but to also add
virtual switches in the Views. This will enable cloud providers
to enrich the network view of the users while making sure that
underlying topology isn’t exposed completely. We believe that
ADVisor can be extended to provide such a functionality. We
leave this extension of ADVisor to future work.
C. Proof of Concept
To demonstrate feasibility and practicality of the frame-
work instantiation, we constructed a prototype implementation
for the FlowVisor-based architecture to enable separation of
network controls among cloud users. This section brieﬂy
describes the implementation details.
The ﬂowspace of each controller was speciﬁed using
FlowVisor’s policy language. Also, a topology that matches
the topology in Figure 2 was emulated in mininet [8]. All
the switches were directed to the port where FlowVisor was
listening. Then a network slice was created for each user
(UserA and UserB) through FlowVisor. Then, we conﬁgured
the controllers for each user in a way that packets only travel
over the switches speciﬁed in Figure 2 for each user. This was
achieved by using a dictionary with keys being 3-tupled values
composed of data path IDs (DPID), the physical port where
packet arrived (in port), and the source MAC address of the
packet (packet.src). Based on this key, the dictionary gives the
value of the output port to which the packet needs to be sent
out. This application was implemented as a python module for
POX controller. We were able to verify connectivity among the
hosts in one slice and isolation among hosts of different slices
using ICMP ‘ping’ messages.
D. Discussion
Instantiation examples above clearly demonstrate the need
to balance two requirements – the degree to which users get
control over their network ﬂows, and the security concerns
of the cloud provider. These two ends directly map to the
two ends of the virtualization spectrum: at one end there is
little or no virtualization, and switch resources in the network
are directly sliced; and at the other end is the completely
virtualized case where the topology visible to the cloud users is
fully decoupled from the underlying infrastructure (this is the
approach taken by Amazon EC2). The tradeoffs are different
in these two approaches. While the virtualized view of the
network provides users with an easy to use interface, it also
makes it harder for them to efﬁciently and precisely schedule
their ﬂows. Furthermore, this approach is widely adopted by
the current cloud providers because they don’t have to give
out any details regarding underlying topology, ensuring that
they maintain any competitive edge as well as preventing
users to infer any information about the network. On the other
hand providing users transparency over the underlying network
means that users will now have to take care of the failures in
the network themselves and reroute the trafﬁc when needed.
The downside of this approach is that it may expose too
much information about the cloud infrastructure and provide
users control over physical resources raising security concerns.
There is clearly a need to achieve a balance between these
two approaches – adopting completely virtualized network de-
prives the users of the ﬂexibility and control and is considered
more secure from provider’s viewpoint whereas fully non-
virtualized view though gives more control to the cloud users,
it may overwhelm users with the conﬁguration tasks and may
not be very secure. We believe that it will be beneﬁcial to come
up with metrics that can be used to quantitatively evaluate
network control delegation approaches. We hope to work on
developing these metrics and do a more detailed comparative
evaluation of the two proposed architectures in future.
V. RELATED WORK
We have already covered the role of ADVisor and FlowVisor
in Section II. Both of them act as hypervisors for the network
and allow multiple controllers to control the same network.
ADVisor improves over the FlowVisor by providing virtu-
alization of nodes along a path that connects two machines
of a cloud user. Quantum [9] is an API developed for the
OpenStack project. With this API, cloud provider can use
different plugins to create a network for each tenant. Quantum
is different from our work because it only provides cloud
provider different methods to implement
the network and
hasn’t been used yet to provide cloud users control over the
physical network.
FlowN [10] is a recent work that proposes a fully virtualized
solution for each tenant. This is in contrast
to our goals
where we are trying to achieve a vantage point by providing
cloud users control over some switches and yet preventing the
cloud infrastructure from cloud cartography attacks. Finally,
RouteFlow [11] is another project that aims to provide routing
algorithms to SDN users. RouteFlow can be thought of as a
tool that can enhance SDN but it can not be used as standalone
tool to provide different level of abstractions to cloud users and
hence their work is orthogonal to ours.
Recently, Self Service Cloud (SSC) [12] computing was
proposed to increase the ﬂexibility for users to deploy useful
services without having to rely on the cloud provider while at
the same time reducing the access that the cloud provider has
to client VMs. While this work focuses on the ﬂexibility and
user control over their VMs we focus on user control of their
network ﬂows.
Another recent work that is relevant is CloudWatcher [13],
which uses OpenFlow to provide security monitoring services
for cloud networks. CloudWatcher provides monitoring ser-
vices for cloud infrastructure administrators to ensure that
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:46:41 UTC from IEEE Xplore.  Restrictions apply. 
[11] “Routeﬂow,” https://sites.google.com/site/routeﬂow.
[12] S. Butt, H. A. Lagar-Cavilla, A. Srivastava, and V. Ganapathy,
“Self-service cloud computing,” in Proceedings of
the 2012 ACM
conference on Computer and communications security, ser. CCS ’12.
New York, NY, USA: ACM, 2012, pp. 253–264. [Online]. Available:
http://doi.acm.org/10.1145/2382196.2382226
[13] S. Shin and G. Gu, “CloudWatcher: Network Security Monitoring Using
Openﬂow in Dynamic Cloud Network,” in 7th Workshop on Secure
Network Protocols (ICNP-NPSec), Austin, Texas, USA, October 2013.
their network packets are always inspected by pre-installed
security devices (e.g., ﬁrewalls or intrusion detection systems).
In contrast, our framework uses SDN to delegate conﬁguration
and monitoring capabilities to end users, providing some level
of network abstractions without compromising the security of
the infrastructure.
VI. CONCLUSION
In this paper we looked at
the feasibility of providing
cloud users more control over their network using abstractions
provided by OpenFlow and software deﬁned networks while
balancing the concerns of cloud providers over giving users
direct access to underlying physical infrastructure. We pro-
posed a SDN based framework to enable delegation of some
network control to end users and discussed various properties
of the network views provided to users. We explored two
architectures that can be used to expose the network to the
cloud users and provided a brief overview of their pros and
cons. We also presented a prototype implementation of one
architecture.
For future work, we plan to further explore network con-
trol delegation to users and characterize more exhaustively
different properties of network views that can be presented
to end users and their security implications for the cloud
provider. We also intend to study the interference effect of
network control delegation and look at techniques to optimize
bandwidth sharing among users in multi-tenant clouds.
ACKNOWLEDGMENT
This work has been partially supported by the Air Force
Research Laboratory and the Air Force Ofﬁce of Scientiﬁc
Research under agreement number FA8750-11-2-0084.
REFERENCES
[1] N. Leavitt, “Is cloud computing really ready for prime time?” Computer,
vol. 42, no. 1, pp. 15 –20, jan. 2009.
[2] M. Al-Fares, S. Radhakrishnan, B. Raghavan, N. Huang, and A. Vahdat,
“Hedera: Dynamic ﬂow scheduling for data center networks,” in Pro-
ceedings of the 7th USENIX conference on Networked systems design
and implementation, 2010, pp. 19–19.
[3] S. Shin, P. Porras, V. Yegneswaran, M. Fong, G. Gu, and M. Tyson,
“Fresco: Modular composable security services for software-deﬁned
networks,” in To appear in the ISOC Network and Distributed System
Security Symposium, 2013.
[4] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L. Peterson,
J. Rexford, S. Shenker, and J. Turner, “Openﬂow: enabling innovation in
campus networks,” ACM SIGCOMM Computer Communication Review,
vol. 38, no. 2, pp. 69–74, 2008.
[5] R. Sherwood, G. Gibb, K. Yap, G. Appenzeller, M. Casado, N. McK-
eown, and G. Parulkar, “Flowvisor: A network virtualization layer,”
OpenFlow Switch Consortium, Tech. Rep, 2009.
[6] E. Salvadori, R. Corin, A. Broglio, and M. Gerola, “Generalizing virtual
network topologies in openﬂow-based networks,” in Global Telecommu-
nications Conference (GLOBECOM 2011), 2011 IEEE.
IEEE, 2011,
pp. 1–6.
[7] U. Hlzle, “Openﬂow @ Google,” Open Networking Summit, April 2012.
[8] N. Handigol, B. Heller, V. Jeyakumar, B. Lantz, and N. McKeown,
“Reproducible network experiments using container-based emulation,”
in Proceedings of the 8th international conference on Emerging net-
working experiments and technologies. ACM, 2012, pp. 253–264.
[9] “Openstack quantum,” http://wiki.openstack.org/Quantum.
[10] “Scalable network virtualization in software deﬁned networks,” http://
www.cs.princeton.edu/∼jrex/papers/ieeeinternet12.pdf.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:46:41 UTC from IEEE Xplore.  Restrictions apply.