# 8.2 Attacks

### Availability
RECAP is susceptible to several potential attacks, with the first being the unavailability of the Authentication Server (AS). If the AS is powered off or otherwise made unavailable, it cannot disclose the identity of users who have misbehaved. To mitigate this, a Service Provider (SP) can require an AS designed for high availability, such as one with redundant network links and power. Availability attacks are common in many protocols and can be addressed using standard fault-tolerant computing and cryptographic methods.

### Small Groups
In RECAP, user authentications are unlinkable among all other registered users within the same group, meaning the unlinkability set \( S_L \) (as defined in Section 3.1) consists of all registered users under the same SP and policy. In small groups, the SP can deduce that any two requests are likely from the same user. This issue is not unique to RECAP; similar problems arise in related works [9, 10, 31, 32]. RECAP, which relies on trusted computing, can address this by having the AS reveal the number of active users upon request. Each user can then set their own threshold for \( |S_L| \) (e.g., requiring at least 20 users for unlinkability). If the number of active users falls below this threshold, the service should not be used. Unlike similar systems [31, 32], RECAP considers this weakness in its design. Notably, a well-behaved user's real identity (e.g., trusted computing identifier) is known only to the AS, ensuring privacy regardless of the number of active users.

### Physical Attacks on TPM
Trusted Platform Modules (TPMs) provide strong protection against programmatic or software-based attacks but are not designed to withstand sustained physical attacks. If a TPM is physically compromised, its security properties are lost. Since RECAP relies on these properties, it is crucial to consider how to mitigate physical attacks. There are several options:
1. **Do Nothing**: Users must trust that the AS they use will not be physically compromised. A popular AS (or several) might be considered secure.
2. **Threshold Cryptography**: Extend RECAP to use threshold cryptography [17] so that a coalition of ASes is required to reveal a misbehaving user’s identity. If a user uses ASes controlled by distinct entities, it becomes difficult for an attacker to compromise all ASes.
3. **Secure Coprocessor**: Use a secure coprocessor (like the IBM 4758 cryptographic processor [27]) designed to withstand physical attacks instead of a TPM.

# 8.3 Policies and Unlinkability

### Unlinkability Problem
In our explanation of RECAP, we have abstracted some policy details. Two practical issues arise: the unlinkability problem and message matching implementation.

#### Unlinkability Problem
In RECAP, we have not specified how the SP knows when a policy is violated. For a policy dealing with a single message, the SP can run the policy function locally on each message. For example, a policy forbidding the string "badword" can be implemented with a function:
```python
def f(msg):
    if HASWORD(msg, "badword"):
        return VIOLATION
    else:
        return ALLOWED
```
However, for policies involving multiple messages, such as forbidding "badword" in one message and "terribleword" in another, the SP faces the unlinkability problem. The SP can easily verify that two messages violate the policy if sent by the same user but cannot determine if they were sent by the same user due to the unlinkability property.

A more efficient approach is to use k-times anonymous authentication [28], which allows the SP to detect when a user exceeds their threshold without excessive communication with the AS. RECAP still provides anonymity guarantees since k-TAA ensures unlinkability for users who have not exceeded their thresholds.

Unfortunately, there is no general solution to the unlinkability problem, especially for finite state machine-based policies. Future work could explore allowing the SP to run a trusted computing-supported hypervisor to perform necessary linking in a secure, isolated environment [21].

### Policy Message Matching
A contract policy can be seen as a function \( f : \{msg_1, \ldots, msg_n\} \rightarrow \{ALLOWED, VIOLATION\} \). When the SP submits multiple messages to the AS, it is unclear how to assign the correct messages to the policy function. For instance, with 50 messages and a policy that takes four, there are \(\binom{50}{4} = 230300\) possible assignments, making it impractical to try all combinations.

Instead, the AS should partition signed messages into sets based on the user (using GS OPEN) and execute the policy function on each set. For example, a matching policy can be implemented as follows:
```python
found_one = False
found_two = False
for m in messages:
    if HASWORD(m, "badword"):
        found_one = True
    if HASWORD(m, "terribleword"):
        found_two = True
if found_one and found_two:
    return VIOLATION
else:
    return ALLOWED
```

# 8.4 Verifier-Local Revocation
In the group signature scheme used, there is a trade-off between unlinkability and the runtime of GS VERIFY based on the size of the blacklist [8]. Verifying that a message signer is not on the blacklist can be done in \( O(1) \) time if a small proportion \( \epsilon \) of messages signed by the same user are linkable (\( \epsilon \approx \frac{\text{memory}}{\# \text{users}} \)), and in \( O(|BL|) \) time for perfect unlinkability (\( \epsilon \) is negligible).

For the \( O(1) \) scheme, \( \epsilon \) is controlled by the security parameter \( k \): \( \epsilon = \frac{1}{k} \). The SP must maintain a precomputed lookup table of size \( O(k \times |BL|) \), leading to a linkability-memory tradeoff. For example, with \( |BL| = 1024 \), \( k = 1024 \), and each table entry being about 128 bytes long, if the SP devotes 128MB to the lookup table, less than 0.1% of messages sent by the same user can be linked. In RECAP, all parties know which scheme is used, and security-conscious users can insist on services using the \( O(|BL|) \) algorithm.

# 9 Related Work
Group signature schemes are often motivated by the need for anonymous authentication [2, 5–8, 13–15]. These schemes typically assume a trusted group manager who does not reveal the secret keys of group members. RECAP provides a way to place such trust intelligently, with the AS acting as the group manager, and all parties can verify the manager's behavior.

Several researchers have proposed schemes for anonymous authentication without a trusted third party (TTP), including e-cash schemes [3, 4, 11, 26, 28, 29] and k-times anonymous authentication schemes [28]. These schemes do not support rich contract policies and are less scalable than RECAP [9, 10, 31, 32]. For example, BLAC [31] requires 0.46 seconds of computation for a blacklist with 400 entries, making it impractical for many applications. These schemes also do not bind anonymity to a contract.

We use trusted computing to ensure the AS can be verified as correct rather than simply trusted. Our work is based on Flicker [23], and Datta et al. [16] have proven that dynamic root of trust systems like Flicker allow verifiers to make strong conclusions about the software state. Other systems, such as Direct Anonymous Attestation [9], can anonymously attest to a software stack but have slower performance and do not achieve all contractual anonymity properties.

# 10 Conclusion
We introduced the concept of contractual anonymity, providing strong guarantees for both the user and the service provider. Unlike other schemes, contractual anonymity requires a binding, immutable contract before service use. We designed the RECAP protocol to achieve these properties and implemented and evaluated it to demonstrate its scalability and practicality. Our end-to-end implementation of RECAP depends on a very small trusted computing base, excluding the operating system, BIOS, and DMA-capable devices, enabling the use of a verifiable third party to enforce contracts. Our experiments show that RECAP scales well and can support services with realistic message rates.

# Acknowledgements
This research was supported by CyLab at Carnegie Mellon under grant DAAD19-02-1-0389 from the Army Research Office, and by gifts from AMD and Intel. The views and conclusions are those of the authors and should not be interpreted as representing the official policies or endorsements of ARO, CMU, or the U.S. Government.

We thank our anonymous reviewers and our shepherd, Scott Coull, for their valuable feedback and suggestions. We also thank Bryan Parno and Thanassis Avgerinos for their comments and discussions.

# References
[1] Advanced Micro Devices. AMD64 architecture programmer’s manual: Volume 2: System programming. AMD Publication no. 24593 rev. 3.14, Sept. 2007.
[2] G. Ateniese, J. Camenisch, M. Joye, and G. Tsudik. A practical and provably secure coalition-resistant group signature scheme. In CRYPTO, 2000.
[3] M. H. Au, S. S. M. Chow, and W. Susilo. Short e-cash. In INDOCRYPT, 2005.
[4] M. H. Au, W. Susilo, and Y. Mu. Constant-size dynamic k-TAA. In Security and Cryptography for Networks, 2006.
[5] M. Bellare, D. Micciancio, and B. Warinschi. Foundations of group signatures: Formal definitions, simplified requirements, and a construction based on general assumptions. In EUROCRYPT, 2003.
[6] D. Boneh and X. Boyen. Short signatures without random oracles. In EUROCRYPT, 2004.
[7] D. Boneh, X. Boyen, and H. Shacham. Short group signatures. In CRYPTO, 2004.
[8] D. Boneh and H. Shacham. Group signatures with verifier-local revocation. In CCS, 2004.
[9] E. F. Brickell, J. Camenisch, and L. Chen. Direct anonymous attestation. In CCS, 2004.
[10] E. F. Brickell and J. Li. Enhanced privacy ID: a direct anonymous attestation scheme with enhanced revocation capabilities. In Workshop on Privacy in the Electronic Society, 2007.
[30] Trusted Computing Group. Trusted platform module main specification, Part 1: Design principles, Part 2: TPM structures, Part 3: Commands. Version 1.2, Revision 103., 2007.
[31] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith. Blacklistable anonymous credentials: blocking misbehaving users without TTPs. In CCS, 2007.
[32] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith. PEREA: towards practical TTP-free revocation in anonymous authentication. In CCS, 2008.
[33] D. A. Wheeler. Linux kernel 2.6: It’s worth more! [Online]. Available: http://www.dwheeler.com/essays/linux-kernel-cost.html. [Accessed: May 1, 2009].
[34] XySSL Developers. XySSL cryptographic library. [Online]. Available: http://polarssl.org.
[11] J. Camenisch, S. Hohenberger, and A. Lysyanskaya. Balancing accountability and privacy using e-cash (extended abstract). In Security and Cryptography for Networks, 2006.
[12] J. Camenisch and A. Lysyanskaya. Dynamic accumulators and application to efficient revocation of anonymous credentials. In CRYPTO, 2002.
[13] J. Camenisch and A. Lysyanskaya. Signature schemes and anonymous credentials from bilinear maps. In CRYPTO, 2004.
[14] J. Camenisch and M. Stadler. Efficient group signature schemes for large groups (extended abstract). In CRYPTO, 1997.
[15] D. Chaum and E. van Heyst. Group signatures. In EUROCRYPT, 1991.
[16] A. Datta, J. Franklin, D. Garg, and D. Kaynar. A logic of secure systems and its applications to trusted computing. In IEEE Symposium on Security and Privacy, 2009.
[17] Y. Desmedt and Y. Frankel. Threshold cryptosystems. In CRYPTO, 1989.
[18] J. R. Douceur. The sybil attack. In International Workshop on Peer-To-Peer Systems, 2002.
[19] D. Grawrock. Dynamics of a Trusted Platform: A Building Block Approach. Intel Press, 2008.
[20] Intel Corporation. Trusted eXecution Technology – measured launched environment developer’s guide. Document number 315168005, 2008.
[21] G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock, P. Derrin, D. Elkaduwe, K. Engelhardt, M. Norrish, R. Kolanski, T. Sewell, H. Tuch, and S. Winwood. seL4: Formal verification of an OS kernel. In Proceedings of ACM SOSP, 2009.
[22] B. Lynn, H. Shacham, and J. Cooley. PBC sig group signature library. [Online]. Available: http://crypto.stanford.edu/pbc/sig. [Accessed: May 1, 2009].
[23] J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and H. Isozaki. Flicker: An execution infrastructure for TCB minimization. In EuroSys, 2008.
[24] A. J. Menezes, P. C. van Oorschot, and S. A. Vanstone. Handbook of Applied Cryptography. 1997.
[25] J. C. Mitchell, V. Shmatikov, and U. Stern. Finite-state analysis of SSL 3.0. In USENIX Security Symposium, 1998.
[26] L. Nguyen and R. Safavi-Naini. Dynamic k-times anonymous authentication. In Applied Cryptography and Network Security, 2005.
[27] S. W. Smith and S. Weingart. Building a high-performance, programmable secure coprocessor. In Computer Networks, 1998.
[28] I. Teranishi, J. Furukawa, and K. Sako. k-times anonymous authentication (extended abstract). In ASIACRYPT, 2004.
[29] I. Teranishi and K. Sako. k-times anonymous authentication with a constant proving cost. In Public Key Cryptography, 2006.