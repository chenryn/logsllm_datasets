work server from learning the IP address of a network
client. Tor could use RECAP to enforce policies regard-
ing proper use. A chat application could run on top of
Tor, and use RECAP to provide contractual anonymity
for chat sessions.
8.2 Attacks
Availability There are several potential attacks against
RECAP. The ﬁrst potential attack is that the AS could
be powered off or otherwise made unavailable. An AS
that is unavailable cannot reveal the identity of users
who misbehave. There are several possible ways to
counter this problem. An SP can insist upon an AS that
has been designed with high availability in mind, e.g., an
AS with redundant network links, power, etc. Attacks
on availability are present in most protocols, and can
be also addressed by standard methods in fault-tolerant
computing and cryptography.
Small Groups
In RECAP, user authentications are
unlinkable among all other registered users in the group,
e.g., the unlinkability set SL (from Section 3.1) is the
set of registered users with the same SP and policy. If
the group is small, and the SP knows this, then the SP
knows that any two requests are likely to be from the
same user. This concern is not unique to RECAP; the
problem of small group sizes also occurs in closely re-
lated works [9, 10, 31, 32]. Because RECAP relies on
trusted computing, it can mitigate the weakness of un-
linkability for small groups: the AS can reveal the num-
ber of active users upon request. Each user can then cre-
ate her own threshold for |SL| (e.g., the user may wish
to be unlinkable among at least 20 users). If the number
of active users is below the user’s threshold, then the ser-
vice should not be used. To the best of our knowledge,
similar systems [31, 32] do not consider this weakness
in their design. Note that in RECAP, a behaving user’s
real identity (e.g., trusted computing identiﬁer) is known
only to the AS, and thus is secret regardless of the num-
ber of active users.
Physical Attacks on TPM TPMs provide strong guar-
antees about programmatic or software-based attacks.
However, TPMs are not designed to withstand a con-
tinued physical attack from a determined adversary. If
a TPM is physically compromised, its security proper-
ties are lost. Since RECAP relies on those properties if
TPMs are used to provide the desired trusted computing
properties, it is important to consider how to mitigate
physical attacks. There are several options. The ﬁrst op-
tion is to do nothing; users would have to trust that the
AS they use will not be physically compromised. There
may be a popular AS (or several) that is believed to not
be physically compromised. Note that the only require-
ment for this AS is that it should not be physically com-
promised; the operating system, BIOS, human operator,
etc. can all be compromised. Second, RECAP can be
extended to use threshold cryptography [17] such that
a coalition of ASes are needed to reveal a misbehaving
user’s identity. If a user only uses ASes that are con-
trolled by distinct entities, it would be difﬁcult for an
attacker to physically compromise all of the ASes. Last,
the AS could use a secure coprocessor (like the IBM
4758 cryptographic processor [27]) that is designed to
withstand physical attacks, instead of the TPM.
8.3 Policies and Unlinkability
In our explanation of RECAP, we have abstracted
away some of the details of policies. There are two prac-
tical issues that arise in practice. The ﬁrst problem is the
unlinkability problem, or how to implement policies that
rely on linkability. The second problem is how message
matching should be implemented.
our
description
Unlinkability Problem In
of
RECAP, we have not speciﬁed how the SP knows
If the policy only deals
when a policy is violated.
with one message, then it is simple:
the SP can run
the policy function locally on each message.
For
instance, a matching policy that forbids the string
“badword” can be implemented using a function
f (msg1)
if HASWORD(msg1, “badword”) then
VIOLATION else ALLOWED. Since the policy only
needs to match one message, the SP can simply run
HASWORD itself on each message.
:
However, consider a policy that forbids a user from
including “badword” in one message, and “terrible-
word” in another message;
is okay to send one
message, but not both. Such a policy might look like:
g(msg1, msg2)
if HASWORD(msg1, “badword”)
and HASWORD(msg2, “terribleword”) then
it
:
VIOLATION else ALLOWED. Consider what
hap-
pens if the SP receives two messages: “. . . badword . . . ”
and “. . . terribleword . . . ”. The SP can easily verify that
the two messages would violate the policy if sent by the
same user, but cannot determine if they were sent by the
same user because of the unlinkability property. We call
this the unlinkability problem.
The obvious implementation of policies with the un-
linkability problem is not always the most efﬁcient. As
one example, threshold policies are commonly used to
prevent spamming, e.g., users should not send more than
k messages per day. Unlinkability prevents the linking
needed for the SP to easily count how many messages
each user sent. The obvious RECAP implementation,
in which the SP sends a large set of messages suspected6
to be created by the same user to the AS, is clearly very
inefﬁcient. A more efﬁcient implementation is to incor-
porate k-times anonymous authentication [28], a cryp-
tographic protocol which provides efﬁcient enforcement
of threshold policies. This allows the SP to efﬁciently
detect when a user exceeds her threshold without exces-
sive communication with the AS. The RECAP anonym-
ity guarantees still hold since k-TAA provides unlinka-
bility for users who have not exceeded their thresholds
(e.g., broken their contract).
Unfortunately, we are not aware of a more general
solution to the unlinkability problem. For instance, one
useful type of policy that we currently can not imple-
ment efﬁciently is ﬁnite state machine-based policies.
We leave solutions for ﬁnite state machine-based poli-
cies and the more general unlinkability problem for fu-
ture work. One potential research direction would be
to allow the SP to run an efﬁcient trusted computing
supported hypervisor which could perform the necessary
linking in a secure, isolated environment [21].
Policy Message Matching As has already been stated,
a contract policy can be thought of as a function
f : {msg1, . . . , msgn} → {ALLOWED, VIOLATION}.
However, if the SP submits 50 messages to the AS for
a policy that takes only four messages, it is not clear
how the correct messages are assigned to the inputs of
the policy function. Even for this example, there are
(cid:0) n
50(cid:1) = 230300 possible assignments of messages, as-
suming order does not matter; clearly, it is not practical
to simply try all combinations.
Instead, when the AS receives signed messages, it
should partition them into sets based on the user that
signed them (using GS OPEN). Then, the policy func-
tion is executed on each set of messages. This means
6For instance, all the messages sent during a high-trafﬁc period.
that, when implemented, policy functions take a set of
messages as input, and should not assume that only
the correct messages are included. For instance, the
matching policy described above could actually be im-
plemented as in Figure 6.
f oundone ← false
f oundtwo ← false
for all messages m do
if HASWORD(m, “badword”) then
f oundone ← true
end if
if HASWORD(m, “terribleword”) then
f oundtwo ← true
end if
end for
if f oundone ∧ f oundtwo then
return VIOLATION
else
return ALLOWED
end if
Figure 6. An Example Implementation of a
Matching Policy
8.4 Veriﬁer(cid:173)local Revocation
In the group signature scheme we use there is
a trade-off between unlinkability and the runtime of
GS VERIFY in the size of the blacklist [8]. Verifying
that a message signer is not on the blacklist can be per-
formed in O(1) time by the SP if the scheme allows for a
small proportion ǫ of messages signed by the same user
to be linkable (ǫ ≈ memory
#users ), and in O(|BL|) time for
perfect unlinkability (ǫ is negligible).
In the O(1) scheme, ǫ is controlled by the security
parameter k : ǫ = 1
k . However, the SP must maintain
a precomputed lookup table whose size is O(k ∗ |BL|),
and therefore there is a linkability-memory tradeoff.
As an example, if |BL| = 1024, k = 1024, each
table entry in a precomputed lookup table is about 128
bytes long, and the SP devotes 128MB to create a lookup
table, then less than 0.1% of the messages sent by the
same user can be linked by the SP. In RECAP, the SP,
AS, and users will all know which scheme is used, and
thus will know whether there is a chance messages will
be linkable. Security-conscious users can always insist
on using services that rely on the O(|BL|) algorithm.
9 Related work
Group signature schemes are often motivated by
the need for anonymous authentication [2, 5–8, 13–15].
Group signature schemes typically assume a group man-
ager. The group manager is trusted not to reveal the se-
cret keys of group members. Our system provides a way
of intelligently placing such trust. In RECAP, the AS
becomes the group manager, but all parties can verify
that the manager will act appropriately.
Several researchers have proposed schemes for anon-
ymous authentication that do not
involve a trusted
third party (TTP). The most basic of these are e-cash
schemes [3,4,11,26,28,29], and k-times anonymous au-
thentication schemes [28]. Such schemes do not allow
for richer contract policies, and are not appropriate for
many types of Internet-based anonymous authentication.
Further, existing TTP-free schemes are less scalable
than RECAP [9, 10, 31, 32]. Experimental results for
BLAC [31] showed that the SP required 0.46 s of com-
putation when the blacklist only contained 400 entries.
Because an authentication must occur for each unlink-
able message, these systems would not be practical for
many applications. These schemes also do not achieve
the property that anonymity is bound to a contract.
We use trusted computing so that the AS can be ver-
iﬁed correct instead of simply trusted. In particular, we
base our work on Flicker [23]. Datta et al. have proven
that dynamic root of trust systems like Flicker allow
veriﬁers to make strong conclusions about the software
state on a machine performing an attestation [16]. Oth-
ers have proposed using TPMs to help build anonymous
authentication. For example, Direct Anonymous Attes-
tation [9] can be used to anonymously attest to a soft-
ware stack. However, these systems have slower perfor-
mance, e.g., DAA and EPID require about 2 seconds of
computation on the SP per authentication on a modern
laptop [9, 10]. Further, these systems do not achieve all
the contractual anonymity properties.
10 Conclusion
We introduced the notion of contractual anonymity,
which provides strong guarantees for the user and ser-
vice provider. Unlike other schemes, contractual an-
onymity requires a user and service provider to agree
on a binding, immutable contract before the service is
used. We designed the RECAP protocol to achieve
the contractual anonymity properties, and implemented
and evaluated RECAP to demonstrate that it is scal-
able and practical. Our end-to-end implementation of
RECAP depends on a very small trusted computing
base that excludes the operating system, BIOS, and
DMA-capable devices, thereby enabling RECAP to use
a veriﬁable third party to enforce contracts. Our ex-
periments demonstrate that RECAP scales well, and is
fully capable of supporting services with realistic mes-
sage rates.
Acknowledgements
This research was supported by CyLab at Carnegie
Mellon under grant DAAD19-02-1-0389 from the Army
Research Ofﬁce, and by gifts from AMD and Intel. The
views and conclusions contained here are those of the
authors and should not be interpreted as necessarily rep-
resenting the ofﬁcial policies or endorsements, either ex-
press or implied, of ARO, CMU, or the U.S. Govern-
ment or any of its agencies.
We would like to thank our anonymous reviewers
and our shepherd, Scott Coull, for their valuable feed-
back and suggestions. We also thank Bryan Parno and
Thanassis Avgerinos for their comments and fruitful dis-
cussions.
References
[1] Advanced Micro Devices. AMD64 architecture pro-
grammer’s manual: Volume 2: System programming.
AMD Publication no. 24593 rev. 3.14, Sept. 2007.
[2] G. Ateniese, J. Camenisch, M. Joye, and G. Tsudik. A
practical and provably secure coalition-resistant group
signature scheme. In CRYPTO, 2000.
[3] M. H. Au, S. S. M. Chow, and W. Susilo. Short e-cash.
In INDOCRYPT, 2005.
[4] M. H. Au, W. Susilo, and Y. Mu. Constant-size dynamic
In Security and Cryptography for Networks,
k-TAA.
2006.
[5] M. Bellare, D. Micciancio, and B. Warinschi. Founda-
tions of group signatures: Formal deﬁnitions, simpliﬁed
requirements, and a construction based on general as-
sumptions. In EUROCRYPT, 2003.
[6] D. Boneh and X. Boyen. Short signatures without ran-
dom oracles. In EUROCRYPT, 2004.
[7] D. Boneh, X. Boyen, and H. Shacham. Short group sig-
natures. In CRYPTO, 2004.
[8] D. Boneh and H. Shacham. Group signatures with
veriﬁer-local revocation. In CCS, 2004.
[9] E. F. Brickell, J. Camenisch, and L. Chen. Direct anon-
ymous attestation. In CCS, 2004.
[10] E. F. Brickell and J. Li. Enhanced privacy ID: a direct
anonymous attestation scheme with enhanced revocation
capabilities. In Workshop on Privacy in the Electronic
Society, 2007.
[30] Trusted Computing Group. Trusted platform module
main speciﬁcation, Part 1: Design principles, Part 2:
TPM structures, Part 3: Commands. Version 1.2, Re-
vision 103., 2007.
[31] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith.
Blacklistable anonymous credentials: blocking misbe-
having users without TTPs. In CCS, 2007.
[32] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith.
PEREA: towards practical TTP-free revocation in anon-
ymous authentication. In CCS, 2008.
[33] D. A. Wheeler. Linux kernel 2.6: It’s worth more! [On-
line]. Available: http://www.dwheeler.com/
essays/linux-kernel-cost.html. [Accessed:
May 1, 2009].
[34] XySSL Developers. XySSL cryptographic library. [On-
line]. Available: http://polarssl.org.
[11] J. Camenisch, S. Hohenberger, and A. Lysyanskaya.
Balancing accountability and privacy using e-cash (ex-
tended abstract). In Security and Cryptography for Net-
works, 2006.
[12] J. Camenisch and A. Lysyanskaya. Dynamic accumula-
tors and application to efﬁcient revocation of anonymous
credentials. In CRYPTO, 2002.
[13] J. Camenisch and A. Lysyanskaya. Signature schemes
In
and anonymous credentials from bilinear maps.
CRYPTO, 2004.
[14] J. Camenisch and M. Stadler. Efﬁcient group signa-
In
ture schemes for large groups (extended abstract).
CRYPTO, 1997.
[15] D. Chaum and E. van Heyst. Group signatures. In EU-
ROCRYPT, 1991.
[16] A. Datta, J. Franklin, D. Garg, and D. Kaynar. A logic of
secure systems and its applications to trusted computing.
In IEEE Symposium on Security and Privacy, 2009.
[17] Y. Desmedt and Y. Frankel. Threshold cryptosystems.
In CRYPTO, 1989.
[18] J. R. Douceur. The sybil attack. In International Work-
shop on Peer-To-Peer Systems, 2002.
[19] D. Grawrock. Dynamics of a Trusted Platform: A Build-
ing Block Approach. Intel Press, 2008.
[20] Intel Corporation. Trusted eXecution Technology – mea-
sured launched environment developer’s guide. Docu-
ment number 315168005, 2008.
[21] G. Klein, K. Elphinstone, G. Heiser, J. Andronick,
D. Cock, P. Derrin, D. Elkaduwe, K. Engelhardt,
M. Norrish, R. Kolanski, T. Sewell, H. Tuch, and S. Win-
wood. seL4: Formal veriﬁcation of an OS kernel.
In
Proceedings of ACM SOSP, 2009.
[22] B. Lynn, H. Shacham, and J. Cooley.
PBC sig
group signature library.
[Online]. Available: http:
//crypto.stanford.edu/pbc/sig. [Accessed:
May 1, 2009].
[23] J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and
H. Isozaki. Flicker: An execution infrastructure for TCB
minimization. In EuroSys, 2008.
[24] A. J. Menezes, P. C. van Oorschot, and S. A. Vanstone.
Handbook of Applied Cryptography. 1997.
[25] J. C. Mitchell, V. Shmatikov, and U. Stern. Finite-state
In USENIX Security Symposium,
analysis of SSL 3.0.
1998.
[26] L. Nguyen and R. Safavi-Naini. Dynamic k-times anon-
In Applied Cryptography and
ymous authentication.
Network Security, 2005.
[27] S. W. Smith and S. Weingart.
Building a high-
In
performance, programmable secure coprocessor.
Computer Networks, 1998.
[28] I. Teranishi, J. Furukawa, and K. Sako. k-times anon-
In ASI-
ymous authentication (extended abstract).
ACRYPT, 2004.
[29] I. Teranishi and K. Sako. k-times anonymous authenti-
cation with a constant proving cost. In Public Key Cryp-
tography, 2006.