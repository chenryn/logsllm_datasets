title:POSTER: Detecting Malicious Web Pages based on Structural Similarity
of Redirection Chains
author:Toshiki Shibahara and
Takeshi Yagi and
Mitsuaki Akiyama and
Yuta Takata and
Takeshi Yada
POSTER: Detecting Malicious Web Pages based on
Structural Similarity of Redirection Chains
Toshiki Shibahara, Takeshi Yagi, Mitsuaki Akiyama, Yuta Takata, and Takeshi Yada
NTT Secure Platform
Laboratory
{shibahara.toshiki, yagi.takeshi, akiyama.mitsuaki, takata.yuta, yada.takeshi}
3-9-11 Midori-cho, Musashino-shi, Tokyo, 180-8585 Japan
@lab.ntt.co.jp
ABSTRACT
Detecting malicious web pages used in attacks and building
blacklists and signatures from them are done to protect users
against drive-by download attacks. Gathering the content
on web pages by crawling and evaluating it to check if it is
malicious can help in detecting malicious web pages. Meth-
ods that apply supervised machine learning to this evalua-
tion are proposed for detecting malicious web pages from a
massive amount of web pages. However, these methods need
manual inspections for preparing training data when classi-
ﬁers are retrained in accordance with changes in the content
on malicious web pages. In this paper, we propose a method
that evaluates whether web pages are malicious and needs
only the discrimination results of web pages identiﬁed by
high-interaction honeyclients to prepare training data. This
method evaluates maliciousness on the basis of the struc-
tural similarity of redirection chains arising from drive-by
download attacks. The results of our experiments with two
years of data showed that the accuracy of our method was
about 20% higher than that of the previous method.
Categories and Subject Descriptors
K.6.5 [Management of Computing and Information
Systems]: Security and Protection
General Terms
Security
Keywords
drive-by download, graph mining, retraining of classiﬁers
1.
INTRODUCTION
Recently, drive-by download attacks have been a great
threat. In the attacks, users who access web pages compro-
mised by attackers are steered to the attackers’ web pages
by redirections. As a countermeasure against attacks, it is
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for third-party components of this work must be
honored. For all other uses, contact the Owner/Author(s). Copyright is held by the
owner/author(s).
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
ACM 978-1-4503-3832-5/15/10.
DOI: http://dx.doi.org/10.1145/2810103.2810112.
eﬀective to block access to malicious web pages with black-
lists, which are lists of malicious web pages used by attacks.
To circumvent this countermeasure, attackers change the
domains of malicious web pages regularly [5]．To list these
malicious web pages on blacklists, it is necessary to analyze
a massive amount of web pages.
Supervised machine learning methods are applied to ana-
lyze a massive amount of web pages [3, 6, 2]. These meth-
ods extract features from the content on web pages. A lot
of malicious and benign content is necessary for training
classiﬁers. Not all of the content of malicious web pages in-
cludes malicious code because malicious web pages are made
usually by injecting malicious code into benign web pages.
Thus, it is essential to perform manual inspections to ver-
ify the maliciousness of the content on malicious web pages
identiﬁed by high-interaction honeyclients in order to pre-
pare training data.
The content on malicious web pages is easily changed by
attackers.
In that case, a large amount of malicious and
benign content is needed for retraining classiﬁers. However,
it is diﬃcult to prepare training data frequently because
manual inspections are needed. Therefore, it is assumed
that the previous methods are not to be able to maintain
accuracy in detection.
In this paper, we propose a method whose training data
is able to be prepared automatically by using only high-
interaction honeyclients. The proposed method evaluates
the maliciousness of web pages on the basis of the structural
similarity of redirection chains arising from drive-by down-
load attacks. Information of the redirections and whether
they are malicious or not can be automatically identiﬁed
by high-interaction honeyclients. Therefore, the proposed
method is able to detect malicious web pages continuously
and accurately because the classiﬁer can be retrained fre-
quently.
The main contributions of this paper are as follows.
• We propose a method that detects malicious web pages
continuously and accurately because classiﬁers can be
retrained without manual inspections.
• The detection rate of attacks based on blacklists is
able to be enhanced by detecting malicious web pages
from a massive amount of web pages with the proposed
method.
2. PROPOSED METHOD
Canali et al. developed Prophiler [2], which has three clas-
siﬁers for evaluating the maliciousness of HTML, JavaScript,
1671Figure 1: Extraction of features. (a) Clustering of training data. (b) Extracting maximum common subtrees.
(c) Calculating feature vectors.
and URL. The number of tags in HTML and the number of
functions in JavaScript etc. are used for the features of clas-
siﬁers.
However, features based on the structural similarity of
redirection chains are used for our proposed method. Source
URLs, destination URLs, and the labels of redirections are
gathered as information of redirections. Links based on
iframe tags, script tags, and so on are used as labels of redi-
rections.
2.1 Structural Similarity of Redirection Chains
Redirections on web pages form tree structures whose
nodes are URLs and whose edges are redirections. The
similarity of redirections is calculated on the basis of the
degree of correspondence between their subtrees. To detect
malicious web pages used by drive-by download attacks, the
paths of redirections from compromised web pages to attack-
ers’ web pages are important, and divarications of redirec-
tions are not important. Therefore, we focus on the paths of
redirections from the ﬁrst accessed URL to the last accessed
URLs.
To extract subtrees, ﬁrst, sequences of labels in redirection
paths from the ﬁrst URL to the ﬁnal URLs are extracted.
Second, the subsequences of each sequence of labels are
extracted. Finally, duplicated subsequences are removed.
Then, these subsequences are used as subtrees. A redirec-
tion chain of web pages is represented as a set R = {ti},
where ti is one of its subtrees.
The function S, which calculates the similarity of redirec-
S(Ri, Rj) =
tion chains Ri and Rj, is deﬁned as:
|Ri ∩ Rj|
|Ri ∪ Rj| ,
(1)
where |R| is the number of subtrees, Ri ∩ Rj is the product
set of Ri and Rj, Ri ∪ Rj is the union of sets Ri and Rj.
2.2 Feature Vectors
Training data are split into clusters composed of similar
redirection chains. If the maximum of the similarity between
redirection chain R and redirection chains belonging to clus-
ter C = {Rci} is greater than threshold st, R is added into
C [Figure 1(a)]. This process is started when each cluster
consists of one redirection and ﬁnished when no redirection
chain is added into any clusters. On the basis of our heuris-
tics, we used st = 0.9 as the threshold.
The templates of clusters are extracted from clusters com-
posed of two or more redirection chains. The template of
cluster C is the maximum common subtree of redirection
chains composing C: Tc = ∩Ri∈C Ri, where Tc is the tem-
plate of C and Ri is the redirection chains that belong to C
[Figure 1(b)].
Table 1: Data used in experiment
Category
Training data
Test data
Label
Time period
Jul. 2012 – Malicious
Dec. 2012
Benign
Jan. 2013 – Malicious
Benign
Dec. 2014
Number
693
1,540
1,033
2,578
The feature vector of redirection chain r is an n-dimensional
vector, where n is the number of clusters. Each component
of the feature vector is the similarity between redirection R
and templates Tci [Figure 1(c)]:
r = [S(R, Tc1), S(R, Tc2), ..., S(R, Tcn)].
The feature vectors are applied to supervised machine
learning. We use SVM with the RBF-kernel as the classiﬁer
for the sake of nonlinear classiﬁcation.
3. EXPERIMENT
We can automatically prepare the training data of pro-
posed method by using the information of redirections gath-
ered by crawling web pages and their discrimination results
identiﬁed by high-interaction honeyclients. However, if the
features of malicious content do not change, the classiﬁers
built by Prophiler are able to continuously evaluate the ma-
liciousness of web pages accurately. We implemented the
proposed method and Prophiler, compared the detection
performance, and investigated the necessity of retraining.
To detect a huge variety of malicious web pages correctly,
a large number of web pages is needed for training data.
Thus, to prepare the training data of Prophiler, we used
the discrimination results of web pages identiﬁed by high-
interaction honeyclients [1] as the labels of the content on
web pages without manual inspections. The time period
and the number of data are presented in Table 1. Assuming
that the methods are applied to detect malicious web pages,
the classiﬁers were trained by using data in training period,
and then, accuracy, recall, and precision were measured by
using subsequent test data. Figure 2-4 shows the change of
accuracy, recall, and precision every three months. Accuracy
is the ratio of data classiﬁed correctly in test data. Recall
is the ratio of data classiﬁed as malicious in malicious data.
Precision is the ratio of malicious data in data classiﬁed as
malicious.
The proposed method exceeded Prophiler in many periods
of time (Figure 2). However, the accuracy was less than 0.9,
except for Jan. – Mar. 2013 Thus, retraining the classiﬁer
is essential, but when to do so cannot be decided only by
the results. To decide when, an experiment to investigate
accuracy in a more precise time period should be done.
1672Figure 2: Change of accuracy
Figure 3: Change of recall
Figure 4: Change of precision
The recall and precision of the proposed method declined
in a certain time period. Benign pages classiﬁed as malicious
had a few redirections in the form of iframe tags. The rea-
son for the misclassiﬁcation was considered to be that these
pages were similar to malicious pages which obtained a few
exploit codes by using redirections in the form of iframe
tags. Malicious pages classiﬁed as benign had exploit codes
in the contents of ﬁrst accessed URL. They were classiﬁed as
benign because they had only redirections commonly used
in malicious and benign pages such as script tags.
In the Jan. – Mar. 2013 period, it seems that the methods
were not aﬀected by change of attackers’ tools and methods.
In that period of time, the proposed method classiﬁed almost
all web pages correctly. Prophiler identiﬁed all malicious
web pages, but it classiﬁed some benign pages as malicious.
4. DISCUSSION
The proposed method can maintain high accuracy if the
classiﬁer is retrained at regular intervals by using train-
ing data automatically prepared. Therefore, malicious web
pages can be continuously and accurately identiﬁed by eval-
uating massive redirections gathered by low-interaction hon-
eyclients.
The web pages misclassiﬁed by the proposed method had
redirections commonly used in malicious and benign web
pages. In this situation, the proposed method cannot clas-
sify web pages correctly because it uses only the information
of redirections. To solve this problem, we will develop the
method to use the information of the content on web pages.
For the training data of Prophiler, all of the content was
labeled as malicious on web pages where exploits were iden-
tiﬁed by high-interaction honeyclients. Thus, the content
that did not have exploit code in malicious web pages was
possibly labeled as malicious. As a result, the accuracy of
Prophiler in the Jan. – Mar. 2013 period declined from
0.89, which was reported in the paper [2], to 0.78.
5. RELATED WORK
5.1 Evaluation of Maliciousness
To detect malicious web pages, methods are proposed
that extract features from various perspectives and apply
machine learning to the evaluation of maliciousness. ZOZ-
ZLE [3] focuses on iterated processes such as for and while
statements. Revolver [6] focuses on the sequence of nodes in
an abstract syntax tree of JavaScript. Prophiler [2] builds
classiﬁers for HTML, JavaScript, and URL. The discrimina-
tion results of web pages identiﬁed by high-interaction hon-
eyclients are not detailed enough to prepare training data
because these methods classify the content on web pages.
SpiderWeb [7] focuses on the length of redirections in sets
consisting of redirections whose last accessed URLs are the
same. This method is costly because it needs a comparison
of many redirections, so it is diﬃcult to evaluate massive
web pages.
5.2 Classiﬁcation of Structural Data
How to analyze structural data is researched in the re-
search ﬁeld of graph mining. Methods are proposed that
classify structural data by using tree kernels [4]. The degree
of correspondence between subtrees is used for the value of
a tree kernel. These methods enable data to be classiﬁed
on the basis of structural similarity, but they are diﬃcult
to apply to huge data because calculating a tree kernel is
costly.
6. CONCLUSION
In this paper, we proposed a method that classiﬁes web
pages on the basis of the structural similarity of redirection
chains. The proposed method can maintain high accuracy
because the classiﬁer is able to be retrained at regular inter-
vals by using training data automatically prepared by using
discrimination results identiﬁed by high-interaction honey-
clients. Therefore, the proposed method enables malicious
web pages to be identiﬁed continuously and accurately.
7. REFERENCES
[1] M. Akiyama et al.. Design and implementation of high
interaction client honeypot for drive-by-download
attacks. IEICE Transactions on Communications,
93(5):1131–1139, 2010.
[2] D. Canali, et al. Prophiler: a fast ﬁlter for the
large-scale detection of malicious web pages. In
Proceedings of the 20th International Conference on
World Wide Web, pages 197–206, 2011.
[3] C. Curtsinger et al. Zozzle: Fast and precise in-browser
javascript malware detection. In USENIX Security
Symposium, pages 33–48, 2011.
[4] T. Gärtner. A survey of kernels for structured data.
ACM SIGKDD Explorations Newsletter, 5(1):49–58,
2003.
[5] C. Grier et al. Manufacturing compromise: the
emergence of exploit-as-a-service. In Proceedings of the
2012 ACM conference on Computer and
communications security, pages 821–832, 2012.
[6] A. Kapravelos et al. Revolver: An automated approach
to the detection of evasive web-based malware. In
USENIX Security Symposium, pages 637–652, 2013.
[7] G. Stringhini et al. Shady Paths: Leveraging surﬁng
crowds to detect malicious web pages. In Proceedings of
the 2013 ACM SIGSAC conference on Computer &
communications security, pages 133–144, 2013.
Jan. 2013Apr.Jul.Oct.Jan. 2014Apr.Jul.Oct.Accuracy00.20.40.60.81ProposedProphilerJan. 2013Apr.Jul.Oct.Jan. 2014Apr.Jul.Oct.Recall00.20.40.60.81ProposedProphilerJan. 2013Apr.Jul.Oct.Jan. 2014Apr.Jul.Oct.Precision00.20.40.60.81ProposedProphiler1673