### Title: The Need for End-to-End Evaluation of Cloud Availability

### Authors:
Zi Hu, Liang Zhu, Calvin Ardi, Ethan Katz-Bassett, Harsha V. Madhyastha, John S. Heidemann, and Minlan Yu

### Affiliations:
1. USC/CS Dept.
2. USC/ISI
3. U. of California, Riverside

### Abstract:
As more computing activities migrate to the cloud, understanding cloud availability becomes increasingly critical. Previous studies of Internet outages have relied on ICMP-based pings and traceroutes, which are effective for detecting network availability but can be inaccurate for estimating cloud availability. ICMP probes can underestimate availability due to their lower robustness compared to application-level measurements like HTTP. They can also overestimate availability by measuring only the reachability of the cloud's edge, missing failures in the back-end. We develop methodologies sensitive to five "nines" of reliability and compare ICMP and end-to-end measurements for both cloud VM and storage services. Our results highlight the importance of application-level retries for high precision. When feasible, we recommend using end-to-end measurements with application-level protocols to evaluate cloud service availability.

### 1. Introduction
Cloud computing is a distributed computing paradigm that enables users to access and configure remote computing resources in a scalable manner. As the cloud becomes more integral, it will host a wide range of applications and services, from small web applications to large-scale platforms like Amazon and Netflix.

The increasing reliance on cloud services necessitates high availability. Despite this need and reports of major cloud outages, there have been few systematic, third-party studies on cloud reliability. While recent systems may use one or multiple cloud providers to enhance reliability, there is a lack of reliable methods for externally and empirically measuring cloud reliability.

Many general network availability and measurement studies use ICMP-based methodologies, often focusing on routing problems or edge network outages. ICMP is favored because more routers respond to it and it is less likely to elicit complaints. However, the network operator community questions the accuracy and reliability of using only ICMP for availability measurements. While effective for network measurements, ICMP is not perfect and must account for filtering, rate limiting, and depreferential service.

### 2. Methodology
We use two methods to study cloud availability: ICMP probes at the network level and end-to-end probes with HTTP at the application level. We target both cloud VMs and storage services from three providers, resulting in four datasets (Table 1), all available upon request.

#### 2.1 Outage Causes
To measure outages, we take observations from multiple vantage points (VPs). Potential sources of failure include DNS lookup failures, routing problems, random packet loss, rate limiting, and service outages inside the cloud infrastructure. Some issues, like packet loss, are common and the user's responsibility to recover from, while others affect measurements differently. Our goal is to understand how different measurement methodologies emphasize different failures.

#### 2.2 Outage Detection at the Network and Application Level
We measure cloud status every 10 or 11 minutes, sending ICMP and HTTP probes with retries. A positive response is recorded if the initial probe or any of the retries succeed. For network-level tests, we send an ICMP echo request, considering only positive replies as successful. For end-to-end testing, we retrieve a short file over HTTP with curl, where a 200 OK status code indicates success. We record curl error codes to distinguish failure cases. If the initial request fails, we perform additional retries. We also record ICMP and TCP traceroutes to diagnose problems and calibrate measurements by probing control sites.

#### 2.3 Targets: Cloud Storage and VMs
We probe two cloud targets: virtual machines (VMs) and online storage.

- **Virtual Machines**: We test VMs on Amazon EC2, as Google's VM service is not yet public and Microsoft VMs filter ICMP traffic. We instantiate micro VMs running Ubuntu 12.04 in all eight regions, install lighttpd, and serve static 1 kB files. Both ICMP and HTTP probes should reach the VM at the kernel and application levels.

- **Storage**: We test storage on Amazon S3, Microsoft Azure, and Google Cloud Storage. Each provider exports an HTTP-based storage abstraction. We store 1 kB files in all available regions. ICMP probes contact the front-end, while HTTP probes retrieve data from the back-end. HTTP provides an end-to-end test for storage.

#### 2.4 Sources: Vantage Points
We probe each target from vantage points in PlanetLab, using 23 VPs starting from 2013-03-11 and 54 VPs starting from 2013-06-18. We select VPs from well-connected universities to focus on cloud availability and follow best practices for PlanetLab measurements.

### 3. Evaluating the Need for Retries
To understand what measurement says about the cloud, we must rule out mundane causes like packet loss. While packet loss is rare, cloud outages are even rarer, so random packet loss can dominate careless observations. We show that ICMP requires at least 5 retries, and even HTTP benefits from application-level retries in addition to kernel-level TCP retransmissions.

#### 3.1 A Simple Analytic Model
Packet loss in the network can be correlated (burst losses due to congestion, filtering) and random (queue overflow over medium timescales). We limit distortion from congestive loss by spacing probes 2 seconds apart, avoiding most short-term correlations.

### Table 1: Datasets Used in This Paper
| Duration (days) | Target (Provider) | Start Date | VPs | Tries/Interval |
|-----------------|--------------------|------------|-----|----------------|
| 33              | VM (Amazon)        | 2013-03-11 | 23  | 3× / 10 min.   |
| 33              | VM (Amazon)        | 2013-06-18 | 54  | 9× / 11 min.   |
| 75              | Storage (Amazon, Google, Microsoft) | 2013-06-18 | 54  | 9× / 11 min.   |

### Figure 1: Probability of False Positive Caused by Random Packet Loss
[Insert Figure 1 Here]

### Conclusion
Our results highlight the importance of application-level retries for high precision in cloud availability measurements. We recommend using end-to-end measurements with application-level protocols when possible to accurately assess cloud service availability.