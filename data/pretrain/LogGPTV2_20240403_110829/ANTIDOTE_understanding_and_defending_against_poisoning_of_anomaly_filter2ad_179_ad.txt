al. [16] and inject them into the Abilene data. While there
are disadvantages to this method, such as the conservative
assumption that a single volume size is anomalous for all
ﬂows, we adopt it for the purposes of relative comparison
between PCA and Robust PCA, to measure relative eﬀects
of poisoning, and for consistency with prior studies. We use
week-long training sets, as such a time scale is suﬃciently
large to capture weekday and weekend cyclic trends [28], and
previous studies operated on this same time scale [16]. There
is nothing inherent to our method that limits its use to this
time scale; our methods will work as long as the training
data is poisoned throughout. Because the data is binned in
5 minute windows (corresponds to the reporting interval of
SNMP), a decision about whether or not an attack is present
can be made at the end of each 5 minute window; thus
attacks can be detected within 5 minutes of their occurrence.
Starting with the ﬂow traﬃc matrix X for the test week,
we generate a positive example (an anomalous OD ﬂow) by
setting ﬂow f ’s volume at time t, Xt,f , to be a large value
known to correspond to an anomalous ﬂow (replacing the
original traﬃc volume in this time slot). This value is de-
ﬁned [16] to be 1.5 times a cutoﬀ of 8×107. After multiplying
by the routing matrix A, the link volume measurement at
time t is anomalous. We repeat this process for each time t
(each 5 minute window) in the test week to generate a set
of 2016 anomaly samples for the single target ﬂow f .
In order to obtain FPRs, we generate negative examples
(benign OD ﬂows) as follows. We ﬁt the data to an EWMA
model that is intended to capture the main trends of the
data without much noise. We use this model to select which
points in time, in an Abilene ﬂow’s time series, to use as
negative examples. We compare the actual data and the
EWMA model, and if the diﬀerence is small (not in the ﬂow’s
top one percentile) for a particular ﬂow at a particular time,
Xt,f , then we label the element Xt,f as “benign.” We do
this across all ﬂows; when we ﬁnd time slots where all ﬂows
are labeled as benign, we run our detectors and see whether
or not they raise an alarm for those time slots.
We simulate a DoS attack along every ﬂow at every time.
We average FNRs over all 144 possible anomalous ﬂows and
all 2016 anomaly times. When reporting the eﬀect of an
attack on traﬃc volumes, we ﬁrst average over links within
each ﬂow then over ﬂows. Furthermore we generally re-
port average volumes relative to the pre-attack average vol-
umes. Thus a single poisoning experiment was based on one
week of poisoning with FNRs computed during the test week
that includes 144 × 2016 samples coming from the diﬀerent
ﬂows and time slots. Because the poisoning is determinis-
tic in Add-More-If-Bigger this experiment was run once for
that scheme. In contrast, for the Random poisoning scheme,
we ran 20 independent repetitions of poisoning experiments
data because the poisoning is random.
To produce the ROC curves, we use the squared prediction
errors produced by the detection methods, that consist of
anomalous and normal examples from the test set. By vary-
ing the method’s threshold from −∞ to ∞ a curve of possible
(F P R, T P R) pairs is produced from the set of SPE’s; the
Q-statistic and Laplace threshold, each correspond to one
such point in ROC space. We adopt the Area Under Curve
(AUC) statistic from Information Retrieval to directly com-
pare ROC curves. The area under an ROC curve of detector
A estimates the conditional probability
AU C(A) ≈ Pr (SP EA(y1) > SP EA(y2)) ,
given anomalous and normal random link volume vectors
y1 and y2. The ideal detector has an AUC of 1, while the
random predictor achieves an AUC of 0.5.
5.3 Single Period & Boiling Frog Poisoning
We evaluate the eﬀectiveness of our attacker strategies us-
ing weeks 20 and 21 from the Abilene dataset to simulate
the Single-Training Period attacks. The PCA algorithm is
trained on the week 20 traﬃc matrix poisoned by the at-
tacker; we then inject attacks during week 21 to see how
often the attacker can evade detection. We select these par-
ticular weeks because PCA achieved the lowest FNRs on
these during testing.
To test the Boiling Frog attack we simulate traﬃc ma-
trix data, inspired by methods used in [16]. Our simula-
tions present multiple weeks of stationary data to the ad-
versary. While such data is unrealistic in practice, it is an
easy case on which PCA should succeed. Anomaly detec-
tion under non-stationary conditions is diﬃcult due to the
learner’s inability to distinguish between benign data drift,
and adversarial poisoning. Demonstrated ﬂaws of PCA in
the stationary case constitute strong results. We decided to
validate the Boiling Frog attack on a synthesized multi-week
dataset, because the 6 month Abilene dataset of [33] proved
to be too non-stationary for PCA to consistently operate
well from one week to the next. It is unclear whether the
non-stationarity observed in this data is prevalent in general
or whether it is an artifact of the dataset.
We synthesize a multi-week set of OD ﬂow traﬃc matrices,
with stationarity on the inter-week level. We use a three
step generative procedure to model each OD ﬂow separately.
First the underlying daily cycle of the OD ﬂow f time series
is modeled by a sinusoidal approximation. Then the times at
which the ﬂow is experiencing an anomaly are modeled by a
Binomial arrival process with inter-arrival times distributed
according to the geometric distribution. Finally Gaussian
white noise is added to the base sinusoidal model during
times of benign OD ﬂow traﬃc; and exponential traﬃc is
added to the base model during times of anomalous traﬃc.
We next describe the process of ﬁtting this generative model
to the week 20 Abilene data.
In step 1, we capture the underlying cyclic trends via
Fourier basis functions. We use sinusoids of periods of 7,
5 and 3 days, and 24, 12, 6, 3 and 1.5 hours, as well as
8a constant function [16]. For each OD ﬂow, we ﬁnd the
Fourier coeﬃcients from the ﬂow’s projection onto this basis.
We next remove the portion of the traﬃc modeled by this
Fourier forecaster and model the remaining residual traf-
ﬁc via two processes. One is a noise process modeled by
a zero-mean Gaussian to capture short-term benign traﬃc
variance. The second process models volume anomalies as
being exponentially distributed.
In step 2 we select which of the two noise processes is used
at each time interval. After computing our model’s residuals
(the diﬀerence between the observed and predicted traﬃc)
we note the smallest negative residual value −m. We as-
sume that residuals in the interval [−m, m] correspond to
benign traﬃc and that residuals exceeding m correspond to
traﬃc anomalies. We separate benign variation and anoma-
lies in this way since these eﬀects behave quite diﬀerently.
(This is an approximation but it works reasonably well for
most OD ﬂows.) Negative residual traﬃc reﬂects benign
variance, and since we assume that benign residuals have a
zero-mean distribution, it follows that such residuals should
lie within the interval [−m, m]. Upon classifying residual
traﬃc as benign or anomalous we then model anomaly ar-
rival times as a Bernoulli arrival process. Under this model
the inter-anomaly arrival times become geometrically dis-
tributed. Since we consider only spatial PCA methods, the
placement of anomalies is of secondary importance.
For the ﬁnal step, the parameters for the two residual
traﬃc volume and the inter-anomaly arrival processes are
inferred from the residual traﬃc using the Maximum Like-
lihood estimates of the Gaussian’s variance and exponential
and geometric rates respectively. Positive goodness-of-ﬁt re-
sults (Q-Q plots not shown) have been obtained for mouse,
medium and elephant ﬂows.
In our simulations, we constrain all link volumes to respect
the link capacities in the Abilene network: 10gbps for all but
one link that operates at one fourth of this rate. We cap chaﬀ
that would cause traﬃc to exceed the link capacities.
6. POISONING EFFECTIVENESS
6.1 Single Training Period Poisoning
We evaluate the eﬀectiveness of our three data poison-
ing schemes in Single-Training Period attacks. During the
testing week, the attacker launches a DoS attack in each 5
minute time window. The results of these attacks are dis-
played in Fig. 3. Although our poisoning schemes focus on
adding variance, the mean of the OD ﬂow being poisoned in-
creases as well, increasing the means of all links over which
the OD ﬂow traverses. The x-axis in Fig. 3 indicates the
relative increase in the mean rate. We average over all ex-
periments (i.e., over all OD ﬂows).
As expected the increase in evasion success is smallest
for the uninformed strategy, intermediate for the locally-
informed scheme, and largest for the globally-informed poi-
soning scheme. A locally-informed attacker can use the
Add-More-If-Bigger scheme to raise his evasion success to
28% from the baseline FNR of 3.67% via a 10% average in-
crease in the mean link rates due to chaﬀ. Although 28%
may not be viewed as a high likelihood of evasion, the at-
tacker success rate is nearly 8 times larger than the unpoi-
soned PCA model’s rate. This number represents an average
over attacks launched in each 5 minute window, so the at-
tacker could simply retry multiple times. With our Globally-
Informed with a 10% average increase in the mean link rates,
the unpoisoned FNR is raised by a factor of 10 to 38% and
eventually to over 90%. The big diﬀerence between the per-
formance of the locally-informed and globally-informed at-
tacker is intuitive to understand. Recall that the globally-
informed attacker knows a great deal more (traﬃc on all
links, and future traﬃc levels) than the locally-informed
one (who only knows the traﬃc status of a single ingress
link). We consider the locally-informed adversary to have
succeeded quite well with only a small view of the network.
An adversary is unlikely to be able to acquire, in practice,
the capabilities used in the globally-informed poisoning at-
tack. Moreover, adding 30% chaﬀ, in order to obtain a 90%
evasion success is dangerous in that the poisoning activity
itself is likely to be detected. Therefore Add-More-If-Bigger
presents a nice trade-oﬀ, from the adversary’s point of view,
in terms of poisoning eﬀectiveness, and attacker capabilities
and risks. We therefore use Add-More-If-Bigger, the locally-
informed strategy, for many of the remaining experiments.
We evaluate the PCA detection algorithm on both anoma-
lous and normal data, as described in Section 5.2, produc-
ing the Receiver Operating Characteristic (ROC) curves dis-
played in Fig. 4. We produce a ROC curve (as shown) by
ﬁrst training a PCA model on the unpoisoned data from
week 20. We next evaluate the algorithm when trained on
data poisoned by Add-More-If-Bigger.
To validate PCA-based detection on poisoned training
data, we poison exactly one ﬂow at a time as dictated by
the threat model. Thus, for relative chaﬀ volumes ranging
from 5% to 50%, Add-More-If-Bigger chaﬀ is added to each
ﬂow separately to construct 144 separate training sets and
144 corresponding ROC curves for the given level of poison-
ing. The poisoned curves in Fig. 4 display the averages of
these ROC curves (i.e., the average TPR over the 144 ﬂows
for each FPR).
We see that the poisoning scheme can throw oﬀ the bal-
ance between false positives and false negatives of the PCA
detector: The detection and false alarm rates drop together
rapidly as the level of chaﬀ is increased. At 10% relative
chaﬀ volume performance degrades signiﬁcantly from the
ideal ROC curve (lines from (0, 0) to (0, 1) to (1, 1)) and at
20% the PCA’s mean ROC curve is already close to that of
blind randomized prediction (the y = x line with 0.5 AUC).
6.2 Multi-Training Period Poisoning
We now evaluate the eﬀectiveness of the Boiling Frog strat-
egy, that contaminates the training data over multiple train-
ing periods. In Fig. 5 we plot the FNRs against the poisoning
duration for the PCA detector. We examine four diﬀerent
poisoning schedules with growth rates g as 1.01, 1.02, 1.05
and 1.15 respectively. The goal of the schedule is to increase
the attacked links’ average traﬃc by a factor of g from week
to week. The attack strength parameter θ (see Sec. 3) is
chosen to achieve this goal. We see that the FNR dramati-
cally increases for all four schedules as the poison duration
increases. With a 15% growth rate the FNR is increased to
more than 70% from 3.67% over 3 weeks of poisoning; even
with a 5% growth rate the FNR is increased to 50% over 3
weeks. Thus Boiling Frog attacks are eﬀective even when
the amount of poisoned data increases rather slowly.
Recall that the two methods are retrained every week us-
ing the data collected from the previous week. However, the
data from the previous week has been ﬁltered by the de-
9Single Poisoning Period: Evading PCA
Single Poisoning Period: ROC Curves
Uninformed
Locally−informed
Globally−informed
)
R
N
F
(
s
s
e
c
c
u
s
i
n
o
s
a
v
E
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
)
R
P
T
(
e
t
a
R
n
o
i
t
c
e
t
e
D
S
o
D
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
PCA − unpoisoned
PCA − 5% chaff
PCA − 10% chaff
PCA − 20% chaff
PCA − 50% chaff
Random detector
Q−statistic
Laplace threshold
0%
10%
20%
30%
40%
50%
0.0
0.2
0.4
0.6
0.8
1.0
Mean chaff volume
False Alarm Rate (FPR)
Figure 3: Evasion success of PCA under Single-Training
Period poisoning attacks using 3 chaﬀ methods.
Figure 4: ROC curves of PCA under Single-Training Pe-
riod poisoning attacks.
Boiling Frog Poisoning: Evading PCA
Boiling Frog Poisoning: PCA Rejections
)
R
N
F
t
s
e
t
e
g
a
r
e
v
a
(
s
s
e
c
c
u
s
i
n
o
s
a
v
E
0
.
1
8
.
0
6
0
.
4
.
0
2
.
0
0
.
0
Growth rates
1.01
1.02
1.05
1.15
d
e
j
t
c
e
e