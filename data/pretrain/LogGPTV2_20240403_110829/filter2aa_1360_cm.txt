option to generate a csv spreadsheet.
Real World Application: While investigating an "anonymous" website that displayed photo evidence of a 
reported felony, I discovered that the registration information was intentionally inaccurate. A search of the 
website on these services identified a Google Analytics ID and an additional website that possessed the same 
number. That additional website was the personal blog of the suspect An arrest was made the same day.
Domain Names 377
DNS Dumpster (dnsdumpster.com)
Robots.txt
http://www.cnn.com/robots.txt
https:/1 web.archive.org/web/*/cnn.com/robots.txt
Search Engine Marketing Tools
378 Chapter 23
Disallow: /cnnbeta
Disallow: /development
Disallow: /partners
Practically even,’ professional website has a robots.txt file at the "root" of the website. This file is not visible 
from any of the web pages at the site. It is present in order to provide instructions to search engines that crawl 
the website looking for keywords. These instructions identify files and folders within the website that should 
not be indexed by the search engine. Most engines comply with this request, and do not index the areas listed. 
Locating this file is relatively easy. The easiest way to view the file is to open it through a web browser. Type the 
website of interest, and include "robots.txt" after a forward slash (/). The file for CNN can be found at the 
following address, with partial contents underneath.
Most robots.txt files will not identify a secret area of a website that will display passwords, raunchy photos, or 
incriminating evidence. Instead, they usually provide insight into which areas of the site are considered sensitive 
by the owner. If you have a target website and have exhausted every' other search method, you should also visit 
this file. It may direct you toward a new set of queries to find data otherwise ignored by search engines.
If this technique produces no results, you can conduct a Google or Bing query' to identify' any files. A search of 
"site.-cnn.com robots exetxt" on either search engine identifies robots.txt files from the entire website. We can 
also query' the Wayback Machine to display changes of this file over time at the following URL structure.
https://www.cnn.com/cnnbeta
https:/1 www.cnn.com/development 
https://www.cnn.com/partners
The file identifies online folders which include a new beta website, temporary development page, and list of 
their partners. Much of this content would not be found in a search engine because of the "Disallow" setting. 
These Disallow instructions are telling the search engines to avoid scanning the folders "cnnbeta", 
"development", and "partners". It is likely that there is sensitive information in these directories that should not 
be available on Google or Bing. You can now type these directories after the domain name of your target to 
identify' additional information. Based on the robots.txt file in this demonstration, ty'ping the following addresses 
directly into a browser may generate interesting results.
The ultimate goal of most commercial websites is to generate income. These sites exist to bring in new 
customers, sell products, and provide the public face to a company. This has created a huge communin’ of 
sendees that aim to help companies reach customers. Search Engine Optimization (SEO) applies various 
techniques affecting the visibility' of a website or a web page in a search engine’s results. In general, the higher 
ranked on the search results page and more frequently' a site appears in the search results list, the more visitors 
it will receive.
This sendee relies on Host Records from the domain registrar to display' potential subdomains. While searching 
a target domain related to a stalking investigation, it displayed a blog hidden from the main domain. This 
presented more information than I could easily digest.
Similar Web (similan.veb.com)
Alexa (alexa.com)
Shared Count (sharedcount.com)
Domain Names 379
Similar Web is usually the most comprehensive of the free options. However, some of these details usually 
contradict other services. Much of this data is "guessed" based on many factors. A search ofinteltechniques.com 
produced the following partial information about the domain.
This website provides one simple yet unique sendee. It searches your target domain and identifies its popularity 
on social networks such as Facebook and Twitter. A search of labnol.org produced the following results. This
• 
The majority of the traffic is from the USA, followed by UK, DE, FR.
• 
There is no paid search or advertisements on search engines.
• 
There are 56 websites that possess links to the target, and 15 are visible.
• 
"Buscador" led more people to the site than any other search term followed by OSINT.
• 
Over 50,000 people visit the site monthly.
• 
There are five main online competitors to the target, and the largest is onstrat.com.
• 
71% of the visitors navigated directly to the domain without a search engine.
• 
12% of the traffic was referrals from other websites and search engines.
• 
The referrals included my other website (computercrimeinfo.com).
• 
3% of the traffic to this site originated from social networks Facebook and Twitter.
• 
Similar websites include onstrat.com and automatingosint.com.
This service is considered the standard when citing the global rank of a website. Most of the collected data is 
targeted toward ranking the overall popularity of a website on the internet. The following details were provided 
about inteltechniques.com.
• 
It is ranked as the 104,033rd most popular site on the internet
• 
The average visitor clicks on three pages during a visit.
• 
Popular searches used to find the domain include OSINT Links and IntelTechniques.
• 
Facebook, Twitter, and Google referred more traffic than any other source.
Both of these services provided some details about the target domain that were not visible within the content 
of the page. These analytical pieces of data can be valuable to a researcher. Knowing similar websites can lead 
you to other potential targets. Viewing sources of traffic to a website can identify where people hear about the 
target. Global popularity’ can explain whether a target is geographically tied to a single area. Identifying the 
searches conducted before reaching the target domain can provide understanding about how people engage with 
the website. While none of this proves or disproves anything, die intelligence gathered can help give an overall 
view of the intent of the target. Additional websites which provide a similar service include Search Metrics 
(suite.searchmetrics.com), SpyFu (spyfu.com), and Majestic (majesdc.com).
Search Engine Marketing (SEM) websites provide details valuable to those responsible for optimizing their own 
websites. SEM sendees usually provide overall ranking of a website; its keywords that arc often searched; 
backlinks; and referrals from other websites. SEO specialists use this data to determine potential advertisement 
relationships and to study their competition. Online investigators can use this to collect important details that 
are never visible on the target websites. Three individual services will provide easily digestible data on any 
domain. I will use my own domain for each example in order to compare the data. Only the free versions will 
be discussed.
Reddit Domains (reddit.com)
Small SEO Tools: Backlinks (smallseotools.com/backlink-checker)
Host.io Backlinks (host.io)
https://host.io/backlinks/inteltechniques.com
Host.io Redirects (hostio)
https://hoscio/redirects/inteltechniques.com
A summary of all details about a domain stored with Host.io
https://host.io/inteltechniques.com
Small SEO Tools: Plagiarism Checker (smallseotools.com/plagiarism-checkcr)
380 Chapter 23
information would lead me to focus on Pinterest and Facebook first. It tells me that several people arc talking 
about the website on these services.
Facebook Likes: 348
Facebook Shares: 538
Facebook Comments: 148
Facebook Total: 1034
Twitter Tweets: 0
Pinterest Pinned: 1
can be found via the following direct URL.
Reddit was discussed previously as a ven7 popular online community. The primary purpose of the service is to 
share links to online websites, photos, videos, and comments of interest. If your target website has ever been 
posted on Reddit, you can retrieve a listing of the incidents. This is done through a specific address typed directly 
into your browser. If your target website was phonelosers.org, you would navigate to 
reddit.com/domain/phonelosers.org. This example produced 16 Reddit posts mentioning this domain. These 
could be analyzed to document the discussions and usernames related to these posts.
After you have determined the popularity of a website on social networks, you may want to identify any websites 
that have a link to your target domain. This will often identify associates and people with similar interests of the 
subject of your investigation. There are several online sendees that offer a check of any "backlinks" to a specific 
website. Lately, I have had the best success with the backlink checker at Small SEO Tools. A search of my own 
website, intekechniqucs.com, produces 264 websites that have a link to mine. These results include pages within 
my own websites that have a link to inteltechniques.com, so this number can be somewhat misleading. Several 
of the results disclosed websites owned by friends and colleagues that would be of interest if I were your target
In 2021,1 discovered this service which seems to offer many additional backlinks which were not present within 
the previous option. The following direct URL displays 45 domains which are linking to my website.
If you have identified a web page of interest, you should make sure the content is original. On more than one 
occasion, I have been contacted by an investigator that had been notified of a violent threat on a person's blog. 
I was asked to track down the subject before something bad happened. A quick search of the content identified 
it as lyrics to a song. One of many options for this type of query is the plagiarism checker at Small SEO Tools. 
You can use this tool by copying any questionable text from a website and paste it into this free tool. It will 
analyze the text and display other websites that possess the same words. This service uses Google to identify 
anything of interest. The benefit of using this tool instead of Google directly is that it will structure several
This option displays any URLs which are forwarding their traffic to your target site. The following direct URL 
displays my own results. You can quickly identify three domains which I own that are forwarding visitors to my 
main site. Searching for historic records of these domains should reveal outdated websites and details.
Visual Site Mapper (visualsitemapper.com)
XML Sitemaps (xml-sitemaps.com)
Threat Data
VirusTotal (virustotal.com)
dev.client.appletv.cnn.com,dev.cnnmoney.ch,dev.content.cnnmoney.ch,dev.hypatia.api.cnn.io
Domain Names 381
queries based on the supplied content and return variations of the found text. Clicking the results will open the 
Google search page that found the text. Another option for this type of search is Copy Scape (copyscape.com).
This represents a new category for this chapter and I am quite embarrassed it took me so long to realize the 
value of the content. I use the term "Threat Data" to encompass the top four websites which monitor for 
malicious content. For a network security' analyst, this data might identify potentially malicious sites which 
should be blacklisted within internal networks. For us OSINT researchers, the data represented here can provide 
a unique glimpse into our target domain. Instead of explaining every facet of these services, I will only focus on 
the new evidence received after a query of various domains. All of these services are available in your search 
tools.
1 now know that cnn.io is directly associated with the target, which should then be investigated. The "Relations" 
tab identifies many new subdomains such as customad.cnn.com, go.cnn.com, and store.cnn.com. The "Files" 
section displays unique content from practically any other resource. It identifies files downloaded from the target 
site for analysis and files which have a reference to the target site. Let's analyze my own site as an example. 
Figure 23.07 displays two files which are present on my site. Both of these files have been analyzed by VirusTotal 
from either user submission or automated scanning. The first column displays the date of the scan and the 
second column identifies whether any virus databases detected the files as malicious (none out of 60 tested 
positive for a virus). The final two columns identify the file type and name. If I were to remove these files today, 
this evidence would stick around.
This service "crawls" a domain and creates an XML text file of all public pages. Scanning my own site and blog 
displayed direct URLs of 493 unique pages. Exporting the XML file provided documentation of the process. 
This is a great companion to visual site mappers, as the text can be easily imported into reporting systems. This 
often presents previously unknown content.
This option displays the most useful information in regard to OSINT, and this is likely the most popular threat 
data sendee of the four. Much of the details presented here are redundant to the previous options, so let's focus 
only on the unique data. The "Details" menu provides the most public data. The Whois and DNS records should 
be similar to other sites. The "Categories" area provides the general topics of the target site. For mine, it displays 
"Information Technology'". This can be useful to know a small detail about sites which have disappeared. The 
"HTTPS Certificate" section can become interesting very' quickly. The "Subject Alternative Name" portion of 
this section identifies additional domains and subdomains associated with the SSL certificate of your target site. 
When I search cnn.com, I receive dozens of additional URLs which could prove to be valuable. Below is a 
partial view.
When researching a domain, 1 am always looking for a visual representation to give me an idea of how massive 
the website is. Conducting a "site" search on Google helps, but you are at the mercy of Google's indexing, which 
is not always accurate or recent. This service analyzes the domain in real time, looking for linked pages within 
that domain. It provides an interactive graph that shows whether a domain has a lot of internal links that you 
may have missed. Highlighting any' page will display the internal pages that connect to the selected page. This 
helps identify pages that are most "linked" within a domain, and may lead a researcher toward those important 
pages. This visual representation helps me digest the magnitude of a target website.
Figure 23.07: A VirusTotal result identifying files from a domain.
2019-05-09
1 /60
Open Source Intelligence Techniques
Figure 23.08: A VirusTotal result identifying files referring to a domain.
Threat Intelligence (threatintelligenceplatform.com)
Threat Crowd (threatcrowd.org)
382 Chapter 23
2018*11*14
2018*11*25
0/59
0/60
tfmpeg.zip 
workbook.pdf
2019-02-11
2019-01-15
2019-01-06
1 160
2/58
1 /60
ZIP
PDF
Name 
OSCAR.exe
Doxing eBooks.zip
HawkEyo.exe
Hacklog2_zip
HacMog. Web Hacking - vol. 2.pdf
Doxing eBooks.zip
Type
Win32 EXE
ZIP
Win32 EXE
Office Open XML Docum
ent
ZIP
PDF
ZIP
Scanned 
2019-08-29
2019-08-04
2019-05-14
Detections 
1 /48 
1 /60 
3/73
Finally, the Community" tab can be a treasure of details if anything exists about your target domain. This is 
where members of the VirusTotal community can leave comments or experiences in reference to the target site. 
While there arc no comments currendy on my profile, I have seen helpful details on target "hacking" related 
sites. These included owner details and new domains created for illegal phishing purposes. Most sites will not 
have any comments, but this option should be checked while browsing through the other sections.
This service replicates many of the features already presented. However, I usually look to three specific sections 
in the domain report. The "Connected Domains" area identifies any external domains which are linked from 
your source. This can often display hidden links to third-party7 sendees otherwise unknown from previous 
queries. On my domain, you see a link to the icon service I use because I gave attribution within the footer of 
my page. In previous investigations, I have found additional domains owned by the suspect. From there, I focus 
on the "Potentially dangerous content" and "Malware detection" sections. Both of these offer a historical view 
into any malicious content hosted on the target domain. This can include suspicious files or phishing campaigns. 
While recently investigating a domain which currently possessed no content, this service confirmed the presence 
of a phishing page designed to steal credentials.
Figure 23.08 displays the result in the "Files Referring" section. These are files and programs, which are not 
present on my site, that refer to my domain. All of these display positive results for being malicious. These are 
basically files stored on other websites which mention my domain. If you were investigating me, you should tty 
to find these files for further analysis. The fourth file is a virus disguised as a digital copy of this book, attempting 
to fool would-be downloaders. If your target is mentioned within off-site files, you can learn a lot from analysis. 
Always use a virtual machine without network access if you plan to download or open anything found here.
This service provides a unique view of the domains associated with your target. Figure 23.09 displays a partial 
result for my own domain. It displays my server IP, primary7 domain, and additional domains which were once 
associated with my account. The upper-right domain was a small website created for a friend which was hosted 
as demonstration for a short amount of time.
■ f'
Figure 23.09: A Threat Crowd domain report.
Censys (censys.io)
WordPress Data
Data Breaches and Leaks
Domain Names 383
https://gf.dev/wordpress-security-scanner
https://hackertarget.com/wordpress-security-scan/
YOURCOMPUTERNERDS.COM
COMPUTERCRIMEINFO.COM
Similar to email addresses and usernames, domains 
familiar with breach data providers, so I will focus only
can possess valuable breach data. You should already be 
on methodology here.
©
j HUMPHREYINTERNAWNALEXPORTS.COM
Many websites displayed at domains are WordPress blogs. These can be customized in any way to have the 
appearance of a traditional website. You may want to identify any vulnerabilities which exist within the 
WordPress installation which may disclose interesting details about the site. The following three providers 
display the basics without the need to install any software. Please note the terms of service when you use these 
options. A search of my own domain revealed the version of WordPress; blog IP address; hosting provider; tide 
of the blog; any blacklist entries; installed plugins; custom themes; login usernames; linked websites; and overall 
security of the site.
Finally, I believe Censys has the overall best dam about the security certificates associated with a domain. It 
provides hyperlinks to every’ certificate within the chain and extreme details about each. Much of this data is not 
valuable to an OS1NT report, but I prefer to collect a screen capture for potential later analysis or comparison 
to live data. Overall, threat data is often considered minor bits of information designated only’ for the digital 
security community. OSINT practitioners should also be aware of the content available within these sites. While 
the majority of details are not immediately useful, small nuggets of valuable information which cannot be found 
anywhere else awaits you.
BLOG.COMPUTERCRIMEINF0.COM
WWW.COMPU^RCRIMEINFO.COM
•@ I 
lf4TELTECHNIQUES.COM