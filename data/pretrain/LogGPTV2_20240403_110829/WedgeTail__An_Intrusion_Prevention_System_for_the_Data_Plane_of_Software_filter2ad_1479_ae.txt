10. THE GOOD, THE BAD AND THE UGLY
10.1 Why WedgeTail and SPHINX?
At this point, we would like to draw a clear line between
network troubleshooting solutions and our work. Solutions
such as [18, 20, 34], mainly, focus on the elimination of con-
ﬁguration conﬂicts, the avoidance of routing loops and black
holes, the detection of policy inconsistency, and etc. How-
ever, even with a correct conﬁguration, the forwarding de-
vices may fail in execution due to bugs in switch software,
conﬂicts, limited memory space. A simple failure to exe-
cution is itself worrisome but a malicious forwarding device
is a serious threat to the network operators and associated
hosts. Recently, threat from state actors and insiders are
on the rise. With such strong adversaries, it is feasible to
expect the attackers to exploit forwarding device vulnera-
bilities in the core of the networks to achieve their goals
(e.g. surveillance, etc.). There are even simpler, and po-
tentially more dangerous scenarios, when compromised for-
warding devices are purposefully placed by insiders in such
networks. Hence, we strongly believe networks require to
have solutions built against such adversaries. One should
note that these solutions should not be, mainly, measured
regarding the detection time rather successful detection of
all threats within a reasonable time.
In summary, we re-
gard WedgeTail as complementary to solutions provided for
network troubleshooting and for this reason WedgeTail is
built on top of the most robust proposals in the network
troubleshooting domain including HSA [19].
10.2 Why WedgeTail?
Related works including [11], mainly, rely on administrator-
deﬁned policies for attack detection, are built against weaker
adversarial settings and fail to detect certain types of at-
tacks (see §9.2). Moreover, they do not discuss localization
of malicious forwarding devices, imposes some overhead to
network performance, cannot distinguish between malicious
actions such as packet drop or delay and do not prioritize
the inspection of forwarding devices.
10.3 Limitations and What’s Next?
We evaluated WedgeTail over various network setups, con-
ﬁgurations, and sizes equipped with diﬀerent SDN controllers
to prove its practicality under simulated environments closely
matching real-world networks. Speciﬁcally, WedgeTail’s high
accuracy and performance over Sprint Setup with a large
number of forwarding devices, rules, and trajectories forms
a solid ground motivating further development and evalua-
tion of our proposed solution. Furthermore, we remind that
858Figure 5: Attack detection in AARNet
Figure 6: Attack detection in Zib54 Setup
Figure 7: Attack detection in Sprint Setup
Setup (50 attacks).
(50 attacks).
(50 attacks).
Figure 8: Target identiﬁcation with respect
to the number of forwarding de-
vices.
Figure 9: Target identiﬁcation with respect
to the number of trajectories.
Figure 10: Average policy matching times
with increasing policies.
WedgeTail’s core detection and response techniques such as
trajectory-creation, scanning methodology and inspection
algorithms are platform independent and network dynam-
ics do not alter these. Therefore, our next step is to deploy
our solution over a real-world network setup focusing on
scalability.
We also admit that we would need exploring WedgeTail’s
accuracy under more attack scenarios and use-cases (e.g.
virtualization, VM migrations, and etc.). However, given
our current evaluations results we do not expect any major
hindrance for our steps forward.
Another issue to point out is that our system analyzes
snapshots and the stability of snapshots may be challenging
[41] – as with all other similar oﬄine systems proposed. Fi-
nally, WedgeTail’s compatibility with distributed SDN con-
trollers such as ONOS requires further investigation – al-
though we regard such platforms to be an enabler rather
than a barrier. We aim to address these limitations in the
near future.
11. CONCLUSION
In the era of cyber-war, cyber-terrorism and with insider
threats reportedly on the rise, it is to expect for attackers to
exploit the vulnerabilities of the network core infrastructure
to launch attacks against networks. Currently, Software De-
ﬁned Networks (SDN) is regarded as the networks of the
future. The SDN control plane security has been an ongo-
ing topic of research. However, malicious forwarding devices
could potentially be a more worrying threat as these are the
actual enforcement point of decisions made at the control
plane. Accordingly, SPHINX [11] was the ﬁrst attempt in
the literature to detect a broad class of attacks in SDNs with
a threat model not requiring trusted switches or hosts. With
the same set of goals, we proposed an alternative solution,
which we call WedgeTail. Our solution is designed against
stronger adversarial settings and outperforms prior solutions
in various aspects including accuracy, performance, and au-
tonomy.
Acknowledgments
The authors would like to express their gratitude and appre-
ciation to all the anonymous reviewers for their comments
on the paper. Speciﬁcally, we are grateful to our Shepherd
Dr. Cong Wang for his valuable feedback and assistance in
improving the quality of this work. The ﬁrst author also ac-
knowledges the technical suggestions and recommendations
of his former colleagues at Information Security Research
Group of University College London (UCL).
12. REFERENCES
[1] Mausezahn. http://www.perihel.at/sec/mz/.
[2] Open Networking Foundation (ONF).
https://www.opennetworking.org/.
[3] S. T. Ali, V. Sivaraman, A. Radford, and S. Jha. A survey
of securing networks using software deﬁned networking.
IEEE transactions on reliability, 64(3):1086–1097, 2015.
[4] G. Andrienko, N. Andrienko, S. Rinzivillo, M. Nanni, and
D. Pedreschi. A visual analytics toolkit for cluster-based
classiﬁcation of mobility data. In International Symposium
on Spatial and Temporal Databases, pages 432–435.
Springer, 2009.
[5] G. Andrienko, N. Andrienko, S. Rinzivillo, M. Nanni,
D. Pedreschi, and F. Giannotti. Interactive visual clustering
of large collections of trajectories. In Visual Analytics
Science and Technology, 2009. VAST 2009. IEEE
Symposium on, pages 3–10. IEEE, 2009.
[6] K. Benton, L. J. Camp, and C. Small. Openﬂow
vulnerability assessment. In Proceedings of the second ACM
SIGCOMM workshop on Hot topics in software deﬁned
networking, pages 151–152. ACM, 2013.
[7] Cbench. https:// goo.gl/ 10TLJk .
[8] T.-W. Chao, Y.-M. Ke, B.-H. Chen, J.-L. Chen, C. J.
Hsieh, S.-C. Lee, and H.-C. Hsiao. Securing data planes in
software-deﬁned networks. In 2016 IEEE NetSoft
01020304050424446485052AttacknumberDetectiontime(second)01020304050650700750800AttacknumberDetectiontime(second)0102030405045005000550060006500AttacknumberProcessingtime(second)0200004000060000800000100200300400NumberofswitchesProcessingtime(second)01000002000003000004000005000006000000100200300400500600700NumberoftrajectoriesProcessingtime(second)2004006008001000020406080100120No.ofPoliciesTime(ms)859Conference and Workshops (NetSoft), pages 465–470.
IEEE, 2016.
[9] CRATE datasets. ftp:// download.iwlab.foi.se/ dataset.
[10] Data Set for IMC 2010 Data Center Measurement.
http:// pages.cs.wisc.edu/ ˜tbenson/ IMC10 Data.html.
[11] M. Dhawan, R. Poddar, K. Mahajan, and V. Mann.
Sphinx: Detecting security attacks in software-deﬁned
networks. In NDSS, 2015.
[12] N. G. Duﬃeld and M. Grossglauser. Trajectory sampling
for direct traﬃc observation. In ACM SIGCOMM
Computer Communication Review, volume 30, pages
271–282. ACM, 2000.
[13] R. Ghannam and A. Chung. Handling malicious switches in
software deﬁned networks. In NOMS 2016-2016
IEEE/IFIP Network Operations and Management
Symposium, pages 1245–1248. IEEE, 2016.
[14] F. Giannotti, M. Nanni, F. Pinelli, and D. Pedreschi.
Trajectory pattern mining. In Proceedings of the 13th ACM
SIGKDD international conference on Knowledge discovery
and data mining, pages 330–339. ACM, 2007.
[15] N. Handigol, B. Heller, V. Jeyakumar, D. Mazi`eres, and
N. McKeown. I know what your packet did last hop: Using
packet histories to troubleshoot networks. In 11th USENIX
Symposium on Networked Systems Design and
Implementation (NSDI 14), pages 71–85, 2014.
[16] P. Hunter. Pakistan youtube block exposes fundamental
internet security weakness: Concern that pakistani action
aﬀected youtube access elsewhere in world. Computer
Fraud & Security, 2008(4):10–11, 2008.
[17] A. Kamisi´nski and C. Fung. Flowmon: Detecting malicious
switches in software-deﬁned networks. In Proceedings of the
2015 Workshop on Automated Decision Making for Active
Cyber Defense, pages 39–45. ACM, 2015.
[18] P. Kazemian, M. Chang, H. Zeng, G. Varghese,
N. McKeown, and S. Whyte. Real time network policy
checking using header space analysis. In Presented as part
of the 10th USENIX Symposium on Networked Systems
Design and Implementation (NSDI 13), pages 99–111,
2013.
[19] P. Kazemian, G. Varghese, and N. McKeown. Header space
analysis: Static checking for networks. In Presented as part
of the 9th USENIX Symposium on Networked Systems
Design and Implementation (NSDI 12), pages 113–126,
2012.
[20] A. Khurshid, X. Zou, W. Zhou, M. Caesar, and P. B.
Godfrey. Veriﬂow: Verifying network-wide invariants in real
time. In Presented as part of the 10th USENIX Symposium
on Networked Systems Design and Implementation (NSDI
13), pages 15–27, 2013.
[21] T. H.-J. Kim, C. Basescu, L. Jia, S. B. Lee, Y.-C. Hu, and
A. Perrig. Lightweight source authentication and path
validation. In ACM SIGCOMM Computer Communication
Review, volume 44, pages 271–282. ACM, 2014.
[22] R. Kl¨oti, V. Kotronis, and P. Smith. Openﬂow: A security
analysis. In 21st IEEE International Conference on
Network Protocols (ICNP), pages 1–6. IEEE, 2013.
[28] H. Mai, A. Khurshid, R. Agarwal, M. Caesar, P. Godfrey,
and S. T. King. Debugging the data plane with anteater. In
ACM SIGCOMM Computer Communication Review,
volume 41, pages 290–301. ACM, 2011.
[29] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar,
L. Peterson, J. Rexford, S. Shenker, and J. Turner.
Openﬂow: enabling innovation in campus networks. ACM
SIGCOMM Computer Communication Review,
38(2):69–74, 2008.
[30] S. Meloni, J. G´omez-Gardenes, V. Latora, and Y. Moreno.
Scaling breakdown in ﬂow ﬂuctuations on complex
networks. Physical review letters, 100(20):208701, 2008.
[31] A. T. Mizrak, Y.-C. Cheng, K. Marzullo, and S. Savage.
Fatih: Detecting and isolating malicious routers. In 2005
International Conference on Dependable Systems and
Networks (DSN’05), pages 538–547. IEEE, 2005.
[32] A. T. Mizrak, S. Savage, and K. Marzullo. Detecting
malicious packet losses. IEEE Transactions on Parallel and
distributed systems, 20(2):191–206, 2009.
[33] Open Networking Foundation (ONF). Sdn architecture, onf
tr-502. opennetworking.org/ images/ stories/ downloads/
sdn-resources/ technical-reports/ TR SDN ARCH 1.0
06062014.pdf .
[34] S. Orlowski, R. Wess¨aly, M. Pi´oro, and A. Tomaszewski.
Sndlib 1.0–survivable network design library. Networks,
55(3):276–286, 2010.
[35] N. Pelekis, I. Kopanakis, C. Panagiotakis, and
Y. Theodoridis. Unsupervised trajectory sampling. In
Machine learning and knowledge discovery in databases,
pages 17–33. Springer, 2010.
[36] J. Rasley, B. Stephens, C. Dixon, E. Rozner, W. Felter,
K. Agarwal, J. Carter, and R. Fonseca. Planck:
Millisecond-scale monitoring and control for commodity
networks. ACM SIGCOMM Computer Communication
Review, 44(4):407–418, 2015.
[37] Route Views. http:// www.routeviews.org.
[38] S. Scott-Hayward, S. Natarajan, and S. Sezer. A survey of
security in software deﬁned networks. IEEE
Communications Surveys & Tutorials, 18(1):623–654, 2015.
[39] N. Spring, R. Mahajan, D. Wetherall, and T. Anderson.
Measuring isp topologies with rocketfuel. IEEE/ACM
Transactions on networking, 12(1):2–16, 2004.
[40] J. Suh, T. T. Kwon, C. Dixon, W. Felter, and J. Carter.
Opensample: A low-latency, sampling-based measurement
platform for commodity sdn. In Distributed Computing
Systems (ICDCS), 2014 IEEE 34th International
Conference on, pages 228–237. IEEE, 2014.
[41] H. Zeng, S. Zhang, F. Ye, V. Jeyakumar, M. Ju, J. Liu,
N. McKeown, and A. Vahdat. Libra: Divide and conquer to
verify forwarding tables in huge networks. In 11th USENIX
Symposium on Networked Systems Design and
Implementation (NSDI 14), pages 87–99, 2014.
[42] X. Zhang, C. Lan, and A. Perrig. Secure and scalable fault
localization under dynamic traﬃc patterns. In Security and
Privacy (SP), 2012 IEEE Symposium on, pages 317–331.
IEEE, 2012.
[23] S. Knight, H. X. Nguyen, N. Falkner, R. Bowden, and
[43] X. Zhang, Z. Zhou, H.-C. Hsiao, T. H.-J. Kim, A. Perrig,
M. Roughan. The internet topology zoo. IEEE Journal on
Selected Areas in Communications, 29(9):1765–1775, 2011.
and P. Tague. Shortmac: Eﬃcient data-plane fault
localization. In NDSS, 2012.
[24] D. Kreutz, F. Ramos, and P. Verissimo. Towards secure
[44] Y. J. Zhu and L. Jacob. On making tcp robust against
spurious retransmissions. Computer communications,
28(1):25–36, 2005.
and dependable software-deﬁned networks. In Proceedings
of the second ACM SIGCOMM workshop on Hot topics in
software deﬁned networking, pages 55–60. ACM, 2013.
[25] D. Kreutz, F. M. Ramos, P. E. Verissimo, C. E.
Rothenberg, S. Azodolmolky, and S. Uhlig.
Software-deﬁned networking: A comprehensive survey.
Proceedings of the IEEE, 103(1):14–76, 2015.
[26] LBNL/ICSI Enterprise Tracing Project.
http:// www.icir.org/ enterprise-tracing/ .
[27] J.-G. Lee, J. Han, and X. Li. Trajectory outlier detection:
A partition-and-detect framework. In 2008 IEEE 24th
International Conference on Data Engineering, pages
140–149. IEEE, 2008.
860APPENDIX
A. NETWORK TOPOLOGIES
For the sake of completeness, we include a representation of
network topologies used in our evaluations in Figure 11. Fig-
ure 14a shows the topology used in AARNet Setup. The Image
and topology for this are extracted from the Internet Topology
Zoo [23]. Figure 14b illustrates the topology used in Zib54 Setup.
The image as well as topology are extracted from SNDlib [34].
Figure 14c shows the network topology used in Sprint Setup. In
this setup, each node of the ﬁgure is constituted of multiple inter-
connected forwarding devices. Image and topology are extracted
from [39].
a: AARNet network topology simulated in AARNet Setup.
b: Zib54 network topology simulated in Zib54 Setup.
c: Backbone topology of Sprint simulated in Sprint Setup.
Figure 11: Network Topologies used in WedgeTail Evaluations
861