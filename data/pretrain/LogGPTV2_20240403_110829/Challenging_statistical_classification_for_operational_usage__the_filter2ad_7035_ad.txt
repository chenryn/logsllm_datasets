characteristics have changed between the end of 2006 and
the beginning of 2008. The confusion matrix is a useful tool
to pinpoint problems. Figure 8 presents the confusion ma-
trix for the case of training over T-I trace and testing over
MS-I. We observe that a signiﬁcant fraction of FTP is cate-
gorized as MAIL. It turns out that the root of this problem
is that the distribution of packet sizes on diﬀerent sites for
FTP and MAIL classes sometimes overlap. For instance, we
present in Figure 7 the distribution of sizes of the second
packet for MS-I and T-I, where we observe this problem.
The above issue is a typical case of data overﬁtting where
the classiﬁer has learned overly speciﬁc site characteristics.
We made similar observations for other cases where a sig-
niﬁcant degradation was observed from static to cross-site
case.
Confusion matrix (Figure 8) shows that misclassiﬁcations
take place for almost all traﬃc classes. In most cases we ob-
serve signiﬁcant bias toward most popular classes, namely
EDONKEY and WEB. Some applications are also confused
with MAIL (like the FTP case discussed above) and OTH-
ERS.
One might argue that the overﬁtting problem we have
highlighted is directly related to the feature set we use. This
is however not the case as we will exemplify in the next
section with our second set of features.
6.3 Set B (Advanced statistics)
Similarly to the case of set A, we observed signiﬁcant
degradation during our cross-site study with set B. For in-
stance, the CHAT or BITTORRENT classes perform well
in the static case but signiﬁcantly degrade in cross-site stud-
ies. Set B consists of several features, each of them being a
5Note that the 99% accuracy in cross-site case comes from
the fact that size of some packets for each eMule transfer is
deterministic.
potential source of data overﬁtting. It would be a daunting
task to study each feature in isolation. We rather take the
stance of focusing on one feature, namely port number, for
which data overﬁtting is easy to explain.
It has been claimed in a number of studies [12, 13] that
ports have high predictive power and thus should increase
classiﬁcation accuracy. The use of port number is however
puzzling as it is treated as a quantitative and not qualita-
tive value. Indeed, most classiﬁcation algorithms make use
of similarity metrics (distances) among the features of the
diﬀerent samples, and from this perspective, port 80 is closer
to port 25 than to port 443 or 8080.
To gain a better understanding of the impact of the port
number, we applied our second set of features with and with-
out the port number on the static and cross-site cases. We
detail these two cases below.
Port impact - static case.
In all static cases, including port numbers increases both
accuracy and precision, typically by a few percent in the case
of p2p applications to as much as 38% in the case of FTP
class. Let us detail the results for WEB and p2p classes:
• The WEB class is almost unaﬀected, i.e., ports have
minor impact on this class. This is good news given
that Web use widely diﬀerent ports, esp. 80, 443, and
8080.
• Accuracy and precision of p2p classes, especially the
EDONKEY class, are signiﬁcantly increased when us-
ing the port number, even though we observed that
the legacy ports of those applications are rarely used:
18 to 40% of the ﬂows for EDONKEY and at most
16% for BITTORRENT.
Port impact - cross-site case.
In a cross-site study, using the port number is detrimental,
especially for p2p traﬃc. In fact, in the static case, when
the port number is used, the classiﬁer learns particular non
legacy port numbers of users. They are predictive in the
static case, but misleading in the cross-site case because the
non legacy port numbers are not the same between two sites.
This is illustrated by Figure 11 for the MS-I and R-II traces
(that were captured two weeks apart). We observe that the
distribution of remote port numbers is very similar for both
traces (Figure 11(b)) while the distribution of local ones
clearly diﬀer (Figure 11(a)). The former was to be expected
due to the way p2p networks work. As for the latter, it
is partly due to some heavy-hitters, i.e.
local clients that
generate a lot of transfers using e-Donkey. The presence
of heavy-hitter being a known and global phenomenon, we
can expect to observe a similar phenomenon irrespectively
of the actual size of a PoP. To sum up, the port number,
although it has a strong predictive power, must be used with
caution, as we might run into the problem of overﬁtting the
data. This issue is clearly related to the current usage of
p2p applications.
6.4 Impact of the Classiﬁcation Algorithm
So far, we have considered a single machine learning algo-
rithm, namely C4.5 and diﬀerent features sets. In this sec-
tion, we address the other dimension of the problem, namely
the impact of the classiﬁcation algorithm. We consider two
129(a) Set A - Sizes of packets
(b) Set B - ﬂow features
Figure 9: Cross site overall accuracy. (training trace on Y axis, test trace on X axis).
(a) WEB
(b) BITTORRENT
(c) CHAT
(d) FTP
(e) EDONKEY
(f) MAIL
(g) OTHERS
(h) GNUTELLA
Figure 10: Cross site accuracy per application using packet sizes. (training trace on Y axis, test trace on X
axis).
alternatives to C4.5: Naive Bayes with kernel estimation
and Bayesian Network. As we will see shortly, the issues
described in the previous sections persist and can be even
more pronounced with these algorithms.
In Figures 12(a) and 12(b) we depict the overall accuracy
for both algorithms considered using set A. While using C4.5
for the cross-site studies, we observed that the FTP case
turned out to be a complex one. In Figure 12(c), we present
accuracy for FTP using Bayesian Network. Detailed, per
application, results are omitted for the sake of clarity. From
those ﬁgures we conclude that:
• In almost all cases C4.5 performs the best in terms of
overall accuracy in both static (diagonal elements) and
cross-site experiments (non diagonal elements).
• Degradation of overall accuracy for Naive Bayes with
kernel density estimation and Bayesian Network in cross-
site cases is similar or higher (17 % in the worse case)
than with C4.5.
• Per application accuracy degradation, can be even more
pronounced for Naive Bayes with kernel density esti-
mation and Bayesian Network than with C4.5. We also
  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIT−I9091929394959697989997%90%90%89%94%94%95%99%91%97%97%94%91%97%97%94%  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIT−I848688909294969898 %91%92%93%87%98 %94%92%93%98 %95 %88%83%88%90%98 %  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIIT−I00.20.40.60.8199 %99 %99 %99 %98 %98 %85 %87 %87 %93 %93 %93 %99 %99 %95 %95 %  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIT−I00.20.40.60.8199 %99 %99 %99 %99 %99 %99 %99 %99 %97 %97 %90 %90 %82 %58 %58 %  MS−IR−IIR−IIIIT−IMS−IR−IIR−IIIT−I00.20.40.60.8199%99%99%99%99%96%96%98%97%55%58%58%75%65%65%90%  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIT−I00.20.40.60.8194%95%95%95%95%91%69%69%52%52%71%51%30%30%35%35%  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIT−I00.20.40.60.8199 %98 %  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIT−I00.20.40.60.8199 %99 %99 %99 %98 %98 %97 %98 %94 %94 %93 %93 %99 %99 %94 %94 %  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIIT−I00.20.40.60.8198%83%83%83%83%91%41%41%46%48%65%47%47%33%18%76%  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIT−I00.20.40.60.8174%71%71%70%97%97%97%97%92%56%56%43%45%47%47%8%130(a) Local port
(b) Distant port
Figure 11: Ports for EDONKEY MSI and RII.
(a) N.Bayes kernel estimation (overall)
(b) Bayesian Network (overall)
(c) Bayesian Network (FTP)
Figure 12: Cross site accuracy for other algorithms (features A). (training trace on Y axis, test trace on X
axis).
observed issues with the same classes of applications
(e.g., FTP) that caused problems for the decision tree.
Those results conﬁrm our previous ﬁndings. The data
overﬁtting issue turns out to be a complex problem that
apparently persists when one varies the features set or the
machine learning algorithm.
6.5 Cross site - Discussion
The main lesson from this cross-site study is that although
the degradation in terms of overall accuracy is often accept-
able, some classes, that work correctly in the static case,
might suddenly degrade. The above result persits for the
various features set or machine learning algorithms we used.
We have demonstrated that data overﬁtting is at the root
of the problem. To the best of our knowledge, such a phe-
nomenon was never pointed out before. From this point on,
the conclusion is twofold. On one hand, it shows that train-
ing a classiﬁer on one site before running on other can lead
to unpredictable results. On the other hand, it shows that
cross-site studies allow to pinpoint problems that can not be
observed otherwise.
A last conclusion suggested by our results is that once a
classiﬁer has been trained on a site, it can be used for a
signiﬁcant period of time on this site. However, more work
needs to be done to validate this observation that we made
for two traces collected two weeks away on the same PoP.
7. MINING THE UNKNOWN CLASS
benchmarked against the known traﬃc, i.e., the traﬃc iden-
tiﬁed by the ground truth tool that is used. The rest of
the traﬃc, that we term unknown traﬃc, is excluded from
further analysis. In this section, we go one step further and
investigate results obtained when the statistical classiﬁer is
used over the UNKNOWN class. Such a classiﬁer could be
included as a module of tools like ODT and used as source
of information or help in the process of the tool develop-
ment, in case an increase of unknown traﬃc is noted. To
the best of our knowledge this is the ﬁrst study that tackles
this problem using supervised methods.
7.1 Methodology
Study of the ﬁltering scenarios (see Table 4) revealed that
this class consists of a large fraction of connections (61%
to 84% depending on the trace) for which the beginning
is missing. Those truncated connections however carry the
majority of bytes in this class, from 79% to 86%. To max-
imize the number of bytes for which a prediction could be
made, we adopted the following strategy:
1. We used the second set of features. The ﬁrst one
(packet sizes) would have de facto reduced the num-
ber of ﬂows and bytes for which a prediction could be
made (see Table 4).
2. We trained the classiﬁer on all known traﬃc for which
a three-way handshake was observed (S/S).
3. We apply the classiﬁer on all ﬂows of the UNKNOWN
class, without any a priori ﬁltering.
In most studies where supervised machine learning algo-
rithms are used, results from the statistical classiﬁer are
4. Our classiﬁer outputs for each ﬂow a class prediction
associated with conﬁdence level.
01234567x 10400.20.40.60.81Local portCDF  RIIMSISingle, active, users listeningports01234567x 10400.20.40.60.81Distant port numberCDF  MSIRII4662  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIT−I7678808284868890929489%76%76%80%93 %93 %86%88%88%93 %93 %86%94%90%90%93 %  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIT−I758085909574 %92 %87 %87 %74 %92 %92 %94 %91 %91 %93 %95 %95 %95 %95 %79 %  MS−IR−IIR−IIIT−IMS−IR−IIR−IIIT−I102030405060708081 %89 %89 %89 %89 %80 %4 %4 %20 %41 %41 %41 %41 %36 %32 %32 %1315. We make use of the conﬁdence level returned by the
C4.5 algorithm to select the ﬂows for which we consider
the prediction as plausible.
High level procedure is presented in Figure 13.
In the
latter step of the methodology described above, we used a
threshold of conﬁdence level of 95%.
7.3 Validation
As in this section we operate on unknown traﬃc, ODT
does not provide us any reference point. We need to vali-
date the predictions of the statistical classiﬁer using some
other methods. In this section, we perform several side tests
to challenge the predictions we obtained for the unknown
traﬃc. We will mainly use the knowledge about the {IP,
port} pairs of the endpoints of the ﬂows.
7.3.1 Peer-to-peer predictions
For the case of peer-to-peer predictions we use the follow-
ing additional sources of information per ﬂow:
• Port numbers. Even for p2p applications, there is
still a fraction of users that use legacy ports [12]. List
of legacy ports for popular p2p applications is given in
Table 6. If ever such a port is observed for a ﬂow for
which the classiﬁer outputs “P2P class”, we consider
that this information backs the result of the classiﬁer.
Figure 13: Mining the unknown - schema.
• Endpoint information:
7.2 Predictions
Figure 14 depicts the cumulative distribution function of
per ﬂow conﬁdence levels for the ﬂows in the UNKNOWN
class. With a threshold of 95%, we observe that, depending
on the trace, a fraction between 40% to 70% of the ﬂows are
kept for further analysis.
Predictions (classiﬁcations) are reported in Table 5. We
present only results for classes that performed well in the
static case and carry at least 1% of bytes for at least one of
the traces. Those results are in line with the ones obtained
for the known traﬃc as we observe a majority of Web, e-
Donkey and BitTorrent traﬃc.
MSI
RII
RIII
TI
Class
EDO.
18%/32% 17%/46% 26%/42% 28%/71%
BT.
1%/15%
2%/9%
3%/≤1%
GNU.
1%/3%
WEB 8%/≤1% 5%/≤1% 9%/≤1% 3%/≤1%
28%/50% 28%/71% 45%/58% 36%/81%
5%/14%
1%/10%
8%/12%
2%/3%
P
Table
[ﬂows%/bytes%].
5:
Unknown
class
predictions,