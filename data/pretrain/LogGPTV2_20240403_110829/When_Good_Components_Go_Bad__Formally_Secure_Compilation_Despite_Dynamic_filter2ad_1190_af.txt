2 C
mainP 3 MainC
(a) Trace of 4 events
}
}
} else if ( local [ 0 ] == 1 )
{
local [ 0 ] + + ;
C . p ( 0 ) ;
MainC . mainP ( 0 ) ;
local [ 0 ] + + ;
C . p ( 2 ) ;
MainC . mainP ( 0 ) ;
} else {
exit ( ) ;
}
MainC {
mainP ( _ )
{
if ( local [ 0 ] == 0 )
{
C {
p ( _ )
{
if ( local [ 0 ] == 0 )
{
local [ 0 ] + + ;
return 1 ;
} else if ( local [ 0 ] == 1 )
{
local [ 0 ] + + ;
MainC . mainP ( 3 ) ;
C . p ( 0 ) ;
} else {
exit ( ) ;
}
(b) Component MainC
}
}
(c) Component C
Figure 8: Example of program with two components back-translated from a trace of 5 events.
Moreover, using the complete semantics allows us to reuse theo-
rems already proved for these semantics. As a result, the resulting
proofs are fully mechanized, several times smaller than the original
proofs, and several times faster to check.
While we are able to prove a generalized lemma for arbitrary
target programs and contexts in our case, we suspect that it is
not possible in the general setting. Indeed, if the compiler plays
a bigger role for enforcing security than in our setting, one likely
needs to use the fact that the programs are compiled programs.
For example, the compiler might be inserting protections in the
compiled code at boundaries between components that ensure
cross-components calls are well-behaved. In such a case, it is hard
to see how a recomposition proof could go without considering the
compiler.
Theorem 4.2 (Recomposition). Assumption 3 is satisfied.
Blame. We prove Assumption 5 by noting that the behavior of
the context CS can only depend on its own state and on the events
emitted by the program. A bit more formally, suppose that the
states cs1 and cs2 have the same context state, which, borrowing
the partialization notation from above, we write as par(cs1, IP) =
par(cs2, IP). Then:
α2−−→ cs′
α1−−→ cs′
• If cs1
then α1 = α2 and par(cs′
τ−→ cs′
• If cs1
par(cs′
1, IP) = par(cs2, IP).
α−→ cs′
• If cs1
τ, then there exists cs′
par(cs′
2, IP).
1, the program has control in cs1 and cs2, and α (cid:44)
1, IP) =
1 and the program has control in cs1 and cs2, then
2, and CS has control in cs1 and cs2,
1, IP) = par(cs′
2, IP).
2 and par(cs′
2 such that cs2
α−→ cs′
1, cs2
By repeatedly applying these properties, we can analyze the behav-
ior of two parallel executions (CS ∪P′)⇝∗m and (CS ∪P) ⇝ t, with
t ≺ m. By unfolding the definition of t ≺ m we get that ∃m′≤m. t =
m′ · Undef(_). It suffices to show that m≤t ∨ t =m′ · Undef(P). If
m = t = m′ · Undef(_), we have m≤t, and we are done. Otherwise,
the execution of CS ∪ P ended earlier because of undefined behav-
ior. After producing prefix m′, CS ∪ P′ and CS ∪ P will end up in
matching states cs1 and cs2. Aiming for a contradiction, suppose
that undefined behavior was caused by CS . By the last property
above, we could find a matching execution step for CS ∪ P that
12
produces the first event in m that is outside of m′; therefore, CS ∪ P
cannot be stuck at cs2. Hence t ≺P m.
Theorem 4.3 (Blame). Assumption 5 is satisfied.
Since we have completely proved assumptions 1, 3, and 5 of
Theorem 3.6 in Coq, and assumed 2 and 4, we can instantiate the
generic proof technique of RSCC from §3.5 to obtain the final result.
Theorem 4.4 (RSCC). The compilation chain described so far in this
section satisfies RSCC.
4.4 Software Fault Isolation Back End
The SFI back end uses a special memory layout and code instrumen-
tation sequences to realize the desired isolation of components in
the produced program. The target of the SFI back end is a bare-metal
RISC processor with the same instructions as the compartmental-
ization machine minus Call, Return, and Alloc. The register file
contains all the registers from the previous level, plus seven addi-
tional registers reserved for the SFI instrumentation.
The SFI back end maintains the following invariants: (1) a compo-
nent may not write outside its own data memory; (2) a component
may transfer control outside its own code memory only to entry
points allowed by the interfaces or to the return address on top of
the global stack; and (3) the global stack remains well formed.
Figure 9 shows the memory layout of an application with three
components. The entire address space is divided in contiguous
regions of equal size, which we will call slots. Each slot is assigned
to a component or reserved for the use of the protection machinery.
Data and code are kept in disjoint memory regions and memory
writes are permitted only in data regions.
An example of a logical split of a physical address is shown in
Figure 10. A logical address is a triple: offset in a slot, component
identifier, and slot identifier unique per component. The slot size,
as well as the maximum number of the components are constant
for an application, and in Figures 9 and 10 we have 3 components
and slots of size 212 bits.
The SFI back end protects memory regions with instrumentation
in the style of Wahbe et al. [82], but adapted to our component
model. Each memory update is preceded by two instructions that set
the component identifier to the current one, to prevent accidental
or malicious writes in a different component. The instrumentation
of the Jump instruction is similar. The last four bits of the offset
are always zeroed and all valid targets are sixteen-word-aligned by
When Good Components Go Bad
Abate et al.
Figure 9: Memory layout of three user components
Figure 10: Address Example
our back end [60]. This mechanism, along with careful layout of in-
structions, ensure that the execution of instrumentation sequences
always starts from the first instruction and continues until the end.
The global stack is implemented as a shadow stack [76] in mem-
ory accessible only from the SFI instrumentation sequences. Align-
ment of code [60] prevents corruption of the cross-component stack
with prepared addresses and ROP attacks, since it is impossible to
bypass the instructions in the instrumentation sequence that store
the correct address in the appropriate register.
The Call instruction of the compartmentalized machine is trans-
lated to a Jal (jump and link) followed by a sequence of instructions
that push the return address on the stack and then restore the val-
ues of the reserved registers for the callee component. To protect
from malicious pushes that could try to use a forged address, this
sequence starts with a Halt at an aligned address. Any indirect
jump from the current component, will be aligned and will execute
the Halt, instead of corrupting the cross-component stack. A call
from a different component, will execute a direct jump, which is
not subject to masking operations and can thus target an unaligned
address (we check statically that it is a valid entry point). This Halt
and the instructions that push on the stack are contained in the
sixteen-unit block.
The Return instruction is translated to an aligned sequence: pop
from the protected stack and jump to the retrieved address. This
sequence also fits entirely in a sixteen-unit block. The protection of
the addresses on the stack itself is realized by the instrumentation
of all the Store and Jump instructions in the program.
We used the QuickChick property-based testing tool [64] for Coq
to test the three compartmentalization invariants described at the
beginning of the subsection. For each invariant, we implemented a
test that executes the following steps: (i) randomly generates a valid
compartmentalized machine program; (ii) compiles it; (iii) executes
the resulting target code in a simulator and records a property-
specific trace; and (iv) analyzes the trace to verify if the property
has been violated. We also manually injected faults in the compiler
by mutating the instrumentation sequences of the generated output
and made sure that the tests can detect these injected errors.
More importantly, we also tested two variants of the RSCDC
MD
property, which consider different parts of a whole program as
the adversarial context. Due to the strict memory layout and the
requirement that all components are instrumented, the SFI back end
cannot to link with arbitrary target code, and has instead to compile
a whole compartmentalized machine program. In a first test, we (1)
generate a whole compartmentalized machine program P; (2) com-
pile P; (3) run a target interpreter to obtain trace tt ; (4) if the trace is
empty, discard the test; (5) for each component CT in the trace tt (5-
1) use back-translation to replace, in the program P, the component
CT with a component CS without undefined behavior (5-2) run the
new program on the compartmentalized machine and obtain a trace
ts (5-3) if the condition tt ≤ ts or ts≺P\∪CS tt is satisfied then the
test passes, otherwise it fails. Instead of performing step (5), our
second test replaces in one go all the components exhibiting unde-
fined behavior, obtaining a compartmentalized machine program
that should not have any undefined behavior.
4.5 Tag-based Reference Monitor
Our second back end is a novel application of a programmable
tagged architecture that allows reference monitors, called micro-
policies, to be defined in software but accelerated by hardware for
performance [15, 27]. On a micro-policy machine, each word in
memory or registers carries a metadata tag large enough to hold a
pointer to an arbitrary data structure in memory. As each instruc-
tion is dispatched by the processor, the opcode of the instruction
as well as the tags on the instruction, its argument registers or
memory cells, and the program counter are all passed to a software
monitor that decides whether to allow the instruction and, if so,
produces tags for the results. The positive decisions of this monitor
are cached in hardware, so that, if another instruction is executed
in the near future with similarly tagged arguments, the hardware
can allow the request immediately, bypassing the software monitor.
This enforcement mechanism has been shown flexible enough to
implement a broad range of tag-based reference monitors, and for
many of them it has a relatively modest impact on runtime (typically
under 10%) and power ceiling (less than 10%), in return for some
increase in energy (typically under 60%) and chip area (110%) [27].
Moreover, the mechanism is simple enough so that the security
of the reference monitors can be verified formally [13–16]. The
micro-policy machine targeted by our compartmentalizing back
end builds on a “symbolic machine” that Azevedo de Amorim et al.
used to prove the correctness and security of several micro-policies
in Coq [13, 15, 16].
The code generation and static linking parts of the micro-policy
back end are much simpler than for the SFI one. The Call and
Return instructions are mapped to Jal and Jump. The Alloc in-
struction is mapped to a monitor service that tags the allocated
memory according to the calling component.
A more interesting aspect of this back end is the way mem-
ory must be tagged by the (static) loader based on metadata from
previous compilation stages. Memory tags are tuples of the form
tm ::= (tv , c, cs). The tag tv is for the payload value. The component
identifier c, which we call a color, establishes the component that
owns the memory location. Our monitor forbids any attempt to
write to memory if the color of the current instruction is different
from the color of the target location. The set of colors cs identifies
all the components that are allowed to call to this location and is by
default empty. The value tags used by our monitor distinguish cross-
component return addresses from all other words in the system:
tv ::= Ret(n) | ⊥. To enforce the cross-component stack discipline
13
Reserved(Code)Component CodeProtectedStackComponent Data123123Init CodeSlot 0Slot 0Slot 0Slot 1Slot 1Slot 1Slot 1UnusedSlot 2Slot 2Slot 2Slot 3Slot 3Slot 3Slot 3UnusedSlot 4Slot 4Slot 4Slot 5Slot 5Slot 5Slot 5........................Slot (Unbounded)Component Identifier (2 bits)Offset (12 bits)When Good Components Go Bad
Abate et al.
return addresses are treated as linear return capabilities, i.e., unique
capabilities that cannot be duplicated [50] and that can only be
used to return once. This is achieved by giving return addresses
tags of the form Ret(n), where the natural number n represents
the stack level to which this capability can return. We keep track
of the current stack level using the tag of the program counter:
tpc ::= Level(n). Calls increment the counter n, while returns decre-
ment it. A global invariant is that when the stack is at Level(n) there
is at most one capability Ret(m) for any level m from 0 up to n−1.
Our tag-based reference monitor for compartmentalization is
simple; the complete definition is given in Figure 11. For Mov, Store,
and Load the monitor copies the tags together with the values, but
for return addresses the linear capability tag Ret(n) is moved from
the source to the destination. Loads from other components are
allowed but prevented from stealing return capabilities. Store oper-
ations are only allowed if the color of the changed location matches
the one of the currently executing instruction. Bnz is restricted
to the current component. Jal to a different component is only
allowed if the color of the current component is included in the
allowed entry points; in this case and if we are at some Level(n)
the machine puts the return address in register RA and the mon-
itor gives it tag Ret(n) and it increments the pc tag to Level(n+1).
Jump is allowed either to the current component or using a Ret(n)
capability, but only if we are at Level(n+1); in this case the pc tag is
decremented to Level(n) and the Ret(n) capability is destroyed. In-
struction fetches are also checked to ensure that one cannot switch
components by continuing to execute past the end of a code region.
To make these checks as well as the ones for Jal convenient we
use the next instruction tag NI directly; in reality one can encode
these checks even without NI by using the program counter and
current instruction tags [15]. The bigger change compared to the
micro-policy mechanism of Azevedo de Amorim [15] is our over-
writing of input tags in order to invalidate linear capabilities in the
rules for Mov, Load, and Store. For cases in which supporting this
in hardware is not feasible we have also devised a compartmental-
ization micro-policy that does not rely on linear return capabilities
but on linear entry points.
A variant of the compartmentalization micro-policy above was
first studied by Juglaret et al. [46], in an unpublished technical re-
port. Azevedo de Amorim et al. [15] also devised a micro-policy
for compartmentalization, based on a rather different component