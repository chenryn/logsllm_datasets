function to measure the differences.
In the following, we design a drifting detection module and
an explanation module to jointly address these challenges.
At the high-level, we ﬁrst use contrastive learning to learn a
compressed representation of the training data. A key beneﬁt
of contrastive learning is that it can take advantage of existing
labels to achieve much-improved performance compared to
unsupervised methods such as autoencoders [33] and Princi-
pal Component Analysis (PCA) [2]. This allows us to learn
a distance function from the training data to detect drifting
samples (Section 3.2). For the explanation module, we will
describe a distance-based explanation formulation to address
the aforementioned challenges (Section 3.3).
3.2 Drifting Sample Detection
The drifting detection model monitors the incoming data sam-
ples to detect incoming samples that are out of the distribution
of the training data.
Contrastive Learning for Latent Representations. We
explore the idea of contrastive learning to learn a good rep-
resentation of the training data. Contrastive learning takes
advantage of the existing labels in the training data to learn
an effective distance function to measure the similarity (or
contrast) of different samples [16]. Unlike supervised classi-
ﬁer, the goal of contrastive learning is not classifying samples
to known classes. It is learning how to compare two samples.
As shown in Figure 2, given the input samples (high dimen-
sional feature vectors), the contrastive learning model aims to
map them into a low-dimensional latent space. The model is
optimized such that, in the latent space, pairs of samples in the
same class have a smaller distance, and pairs of samples from
different classes have a larger distance. As such, the distance
metric in the latent space can reﬂect the differences in pairs
of samples. Any new samples that exhibit a large distance to
all existing classes are candidate drifting samples.
To implement this idea, we use an autoencoder augmented
with contrastive loss. Autoencoder is a useful tool to learn a
compressed representation (with a reduced dimensionality)
of a given input distribution [33]. Formally, let xxx ∈ Rq×1 be a
sample from the given training set. We train an autoencoder
that contains an encoder f and a decoder h. Note that f is
parameterized by θθθ; h is parameterized by φφφ. We construct
the loss function as the following:
(cid:104)
Exxx(cid:107)xxx− ˆxxx(cid:107)2
2 + λExxxi,xxx j
min
θθθ,φφφ
(1− yi j)d2
i j + yi j(m− di j)2
.
(1)
+
(cid:105)
Here, the ﬁrst term is the reconstruction loss of the autoen-
coder. More speciﬁcally, the goal of the encoder f is to learn
a good representation of the original input. Given an input xxx,
encoder f maps the original input xxx to a lower-dimensional
representation zzz = f (xxx;θθθ). Autoencoder ensures this latent
Figure 2: The high-level idea of contrastive learning.
representation zzz can be decoded to reconstruct the original
input with minimal reconstruction loss. Here, ˆxxx ∈ Rq×1 is the
reconstruction of this original input, i.e., ˆxxx = h(zzz). This loss
term represents the mean squared error between xxx and ˆxxx.
The second term of Eqn. (1) refers to the contrastive loss,
which takes a pair of samples (xxxi, xxx j) and their relationship
yi j as input. yi j = 1, if the two samples are from the different
classes; yi j = 0, if the two samples are from the same class.
(·)+ is a short notation for max(0,·), and di j is the Euclidean
distance between the latent space representations zzzi = f (xxxi;θ)
and zzz j = f (xxx j;θ), where zzz ∈ Rd×1 (d (cid:28) p). This loss term
minimizes the distance of xxxi and xxx j in the latent space if they
are from the same class, and maximizes their distance up
to a radius deﬁned by m > 0, such that the dissimilar pairs
contribute to the loss function only when their distance is
within this radius. λ is a hyper-parameter controlling the
weight of the second term in the loss function.
After contrastive learning, encoder f can map the input
samples to a low-dimensional latent space where each class
forms tight groups (as shown in Figure 2). In this latent space,
the distance function can effectively identify new samples
drifting away from these groups.
MAD-based Drifting Sample Detection.
After training
the contrastive autoencoder, we can use it to detect drift-
ing samples. Given a set of K testing samples {xxx(k)
t } (k =
1, . . . ,K), we seek to determine whether each sample xxx(k)
is a
t
drifting sample with respect to existing classes in the training
data. The detection method is shown in Algorithm 1.
Suppose the training set has N classes, and each class has
ni training samples, for i = 1,2, ...,N. We ﬁrst use the encoder
to map all the training samples into the latent space (line 2–
4). For each class i, we calculate its centroid ccci (by taking
the mean value for each dimension in a Euclidean space in
line 5). Given a testing sample xxx(k)
, we also use the encoder
t
to map it to the latent space representation zzz(k)
(line 14).
t
Then, we calculate the Euclidean distance between the testing
t − ccci(cid:107)2 (line
i = (cid:107)zzz(k)
sample and each of the centroids: d(k)
16). Based on its distance to centroids, we determine if this
testing sample is out of distribution for each of the N classes.
Here, we make decisions based on the sample’s distance to
the centroids instead of the sample’s distance to the nearest
training samples. This is because the latter option can be
easily affected by the outliers in the training data.
2330    30th USENIX Security Symposium
USENIX Association
High-dimensional spaceLow-dimensional spaceCAContrastive Auto-encoderAlgorithm 1 Drift Detection with Contrastive Autoencoder.
Input: Training data xxx( j)
i
, i = 1, . . . ,N, j = 1, . . . ,ni, N is the number of
classes, ni is the number of training samples in class i; testing data xxx(k)
,
t
t refers to the testing set, k = 1, . . ., K, K is the total number of testing
samples; encoder f ; a constant b.
Output: Drifting score for each testing sample A(k), the closest class y(k)
t
,
centroid of each class ccci, MADi to each class.
(cid:46) The latent representation of xxx( j)
i
.
(cid:46) The centroid of class i.
i − ccci||2 (cid:46) The distance between sample and centroid.
), j = 1, . . . ,ni
i − ˜di|), j = 1, . . . ,ni
;θθθ)
1: for class i = 1 to N do
for j = 1 to ni do
2:
i = f (xxx( j)
zzz( j)
3:
i
end for
4:
j=1 zzz( j)
ni ∑ni
ccci = 1
5:
i
for j = 1 to ni do
6:
i = ||zzz( j)
d( j)
7:
end for
8:
˜di = median(d( j)
9:
i
MADi = b∗ median(|d( j)
10:
11: end for
12:
13: for k = 1 to K do
zzz(k)
t = f (xxx(k)
;θθθ)
14:
t
for class i = 1 to N do
15:
t − ccci||2
i = ||zzz(k)
d(k)
16:
|d(k)
i − ˜di|
A(k)
i =
MADi
end for
A(k) = min(A(k)
i
if A(k) > TMAD then
17:
18:
19:
20:
21:
22:
23:
24:
25:
y(k)
26:
t = argmin
27: end for
xxx(k)
t
xxx(k)
t
end if
else
i
), i = 1, . . . ,N
(cid:46) TMAD is set to 3.5 empirically [40].
is a potential drifting sample.
is a non-drifting sample.
d(k)
i
, i = 1, . . . ,N
(cid:46) The closest class for xxx(k)
t
.
i
To determine outliers based on d(k)
( j = 1, . . . ,ni). Here d( j)
i
, the challenge is that
different classes might have different levels of tightness, and
thus require different distance thresholds. Instead of manually
setting the absolute distance threshold for each class, we use
a method called Median Absolute Deviation (MAD) [40].
The idea is to estimate the data distribution within each
class i by calculating MADi (line 6–10), which is the me-
dian of the absolute deviation from the median of distance
d( j)
depicts the latent distance be-
i
tween each sample in class i to its centroid, and ni is the
number of samples in class i (line 7). Then based on MADi,
we can determine if d(k)
is large enough to make the testing
sample xxx(k)
an outlier of class i (line 15–24). If the testing
t
sample is an outlier for all of the N classes, then it is deter-
mined as a drifting sample. Otherwise, we determine it is
an in-distribution sample and its closest class is determined
by the closest centroid (line 26). The advantage of MAD is
that every class has its own distance threshold to determine
outliers based on its in-class distribution. For instance, if a
cluster is more spread out, the threshold would be larger.
i
Figure 3: Illustration of the boundary-based explanation and
the distance-based explanation in our setup.
Note that MAD might suffer when a class does not have
enough samples as its median can be noisy. In our design,
contrastive learning can help to mitigate this issue since each
of the classes is mapped to a compact region in the latent
space which helps to stabilize the median.
Ranking Drifting Samples.
As shown in Figure 1, drift-
ing samples might need further investigations by analysts to
interpret the meaning of the drifting. Given the limited time
of analysts, it is important to rank the drifting samples so that
analysts can focus on the most novel variants. We use a simple
approach to rank drifting samples based on their distance to
the nearest centroid (calculated in line 26). This allows us to
prioritize the investigation of drifting samples that are furthest
away from their nearest centroid.
3.3 Explaining Drifting Samples
The explanation module aims to identify the most important
features that drive a testing sample away from existing classes.
To be speciﬁc, given a drifting sample xxxt, and its nearest
class yt in the training set, we want to identify a small set of
features that make xxxt an outlier of class yt. To achieve this
goal, one instinctive reaction is to convert it to the problem
of explaining a supervised learning model, which is a well-
studied area. For example, we can approximate our drifting
detector () as a classiﬁer, and derive explanations using
existing explaining methods developed for classiﬁers [28, 35,
53, 58, 62]. However, due to the high sparsity of the outlier
space, we ﬁnd it difﬁcult to move a drifting sample to cross
the decision boundary, and thus fail to derive meaningful
explanations. Motivated by this, we design a new explanation
method customized for drift detection, which explains the
distance between a drifting sample and the in-class samples
rather than the decision boundary. Below, we ﬁrst analyze the
“straightforward approach” and then describe our method.
Baseline Method: Boundary-based Explanation. Given
the rich literature on explaining supervised classiﬁers, a
straightforward approach is to convert the drifting detection
module into a supervised learning model, and then run exist-
ing explanation algorithms. Supervised explanation methods
are to explain the decision boundary between two classes
(e.g., classes A and B). The goal is to identify a minimal set of
features within xxxt, such that perturbing these features will let
USENIX Association
30th USENIX Security Symposium    2331
Explaining BoundaryExplaining DistanceDrifting sampleTraining out-distributionTraining in-distributionABxtxxxt cross the decision boundary. As is shown in Figure 3, class
A represents the in-distribution training samples from yt, and
class B represents the detected drifting sample in the testing
set. The decision boundary is illustrated by the blue dashed
line (the decision boundary is shown in the form of a norm ball
since it is based on distance threshold). Given a drifting sam-
ple xxxt (denoted by a star in Figure 3), the explanation method
pulls the sample into the in-distribution class (i.e. the region
with gray canvas) by perturbing a small set of important fea-
tures.2 We implemented this idea using existing perturbation-
based supervised explanation methods [13, 18, 21, 22] (imple-
mentation details in Appendix A).
The evaluation result later in Section 5 shows that this