看SASS汇编，比如x /i、display /i命令，或者disassemble命令。
(cuda-gdb) x/4i $pc-32
   0xa689a8 : MOV R0, c[0x0][0x34]
   0xa689b8 : MOV R3, c[0x0][0x28]
   0xa689c0 : IMUL R2, R0, R3
=> 0xa689c8 : MOV R0, c[0x0][0x28]
在使用Nsight调试时，可以在汇编语言窗口查看SASS指令，如图9-
10所示。
图9-10 当使用Nsight调试时在汇编语言窗口中查看SASS指令
在图9-10中，包含了三种代码：CUDA扩展后的C语言代码（行号
后带冒号）、Nvidia GPU程序的中间指令（称为PTX指令，后文将详细
介绍，该指令前有方括号）以及GPU硬件的SASS指令。每一条SASS指
令的显示包含三个部分：地址、机器码和指令的SASS反汇编表示，例
如以下代码。
0x000cf7f8           4c98078000270003         MOV R3, c[0x0][0x8];
对于无法得到SASS官方文档的人来说，在调试器下结合源代码和
有文档的PTX指令来学习SASS汇编是很好的方法。
9.3.2 指令格式
SASS指令的一般格式如下。
（指令操作符）（目标操作数）（源操作数1），（源操作数2）…
有效的目标操作数和源操作数如下。
普通寄存器Rx。
系统寄存器SR_x。
条件寄存器Px。
常量，使用c[X][Y] 表示。
举例来说，S2R R7, SR_TID.X用于把代表当前线程ID的系统寄存器
SR_TID的X分量赋值给普通的寄存器R7。再比如MOV R3, c[0x0][0x8]
用于把代表协作线程组（CTA）维度大小的常量读到R3寄存器中。
值得特别强调的是，Nvidia GPU硬件指令最大的特点是，所有指令
都属于标量指令，指令的操作数都是标量，而不是向量，与x86 CPU的
普通指令类似。x86 CPU的SIMD指令是典型的向量指令。
9.3.3 谓词执行
包括Nvidia GPU在内的大多数GPU都支持所谓的谓词执行
（predicated execution）技术，目的是减少程序中的分支。
举例来说，对于如下C语句：
if (i < n)
   j = j + 1;
可以使用PTX指令表示为以下代码。
    setp.lt.s32 p, i, n; // p = (i < n)
@p  add.s32 j, j, 1;     // if i < n, add 1 to j
前一条指令对i和n两个变量做“小于”（less than，lt）比较，把结果
写到谓词寄存器（predicate register）p中。第二条指令前的@p则表示根
据谓词寄存器p的值来决定是否要执行后面的加法指令。
谓词技术在3D图形应用中也大有用武之地，在微软的DirectX API
中有接口来使用这个技术[11]，可以调用CreatePredicate方法创建谓词变
量，调用SetPredication方法来动态设置谓词变量，详情参见DirectX
SDK的DrawPredicated示例（SDK root\Samples\C++\Direct3D10\
DrawPredicated）。
9.3.4 计算能力
虽然每一代微架构都尽可能与顶层软件保持稳定的接口，但因为新
增功能和设计改变等因素，还会导致一些差异。为了解决这个问题，
Nvidia使用名为计算能力（Compute Capability，CC）的版本机制来标识
微架构演变所导致的硬件差异。通常使用两位数字表示计算能力的版
本。一位代表主版本号，与前面介绍的微架构相对应，另一位代表同一
代微架构内的少量变化，比如G80的CC版本号为1.0，后来改进的GT200
版本为1.3。表9-3列出了目前已发布微架构所对应的计算能力版本号。
表9-3 微架构与计算能力版本号
微架
构
计算能力
版本号
说  明
特斯
拉
1. x
G80为1.0，G92、G94、G96、G98、G84、G86为1.1，GT218、
GT216、GT215为1.2，GT200为1.3
费米
2. x
GF100和GF110为2.0，其余为2.1
开普
勒
3. x
有3.0、3.2、3.5和3.7多个子版本
麦斯
威尔
5. x
GM107和GM108为5.0，还有5.2和5.3子版本
帕斯
卡
6. x
GP100为6.0，GP108为6.2
伏特
7. x
GV100为7.0
在编译CUDA程序时，经常见到这样的参数：-
gencode=arch=compute_61，其中，compute_61就是用来指定产生与计算
能力为6.1的硬件兼容的代码。
9.3.5 GT200的指令集
就像在硬件方面不断改进、不断优化一样，Nvidia也在不断调整与
改进每一代GPU的指令集。限于篇幅，这里选择第一代特斯拉微架构
（CC 1.x）和目前公开的最新一代伏特微架构（CC 7.0）的指令集进行
比较学习。表9-4列出了基于特斯拉微架构的GT200 GPU的指令集。
表9-4 GT200的指令集
操 作 码
描  述
A2R
把地址寄存器的内容移动到数据寄存器中
ADA
把立即数累加到地址寄存器上
BAR
协作线程组范围内（CTA-wide）的同步屏障（barrier）
BRA
按条件分支跳转
BRK
根据条件从循环中中断（break）
BRX
从常量内存区读取地址并跳转到该地址
C2R
把条件码复制到数据寄存器中
CAL
无条件调用子过程
COS
计算余弦值
DADD
双精度浮点数加法
DFMA
双精度浮点数融合乘加（fused multiply-add）
DMAX
对双精度浮点数取最大值
DMIN
对双精度浮点数取最小值
DMUL
双精度浮点数乘法
DSET
针对双精度浮点数按条件赋值（conditional set）
EX2
指数函数（指数为2）
F2F
从浮点数转换为浮点数并复制
F2I
从浮点数转换为整数并复制
FADD、
FADD32、
FADD32I
单精度浮点数加法
FCMP
单精度浮点数比较
FMAD、
FMAD32、
FMAD32I
单精度浮点数乘加
FMAX
对单精度浮点数取最大值
FMIN
对单精度浮点数取最小值
FMUL、
FMUL32、
FMUL32I
单精度浮点数乘法
FSET
针对双精度浮点数按条件赋值
G2R
把共享内存中的数据读到寄存器。如果带有.LCK后缀，则表示锁定
该共享内存块（bank），直到执行R2G.UNL时才解锁，用于实现原
子操作
GATOM.IADD
针对全局内存的原子操作（atomic operation）。执行原子操作,并返
回内存中原来的值,相当于x86 CPU中的互锁系列操作。除了IADD之
外，支持的操作还有EXCH、CAS、IMIN、IMAX、INC、DEC、
IAND、IOR和IXOR
GLD
从全局内存读
GRED.IADD
针对全局内存的整合操作（reduction operation）。只执行原子操
作，没有返回值，除了IADD之外，支持的操作还有IMIN、IMAX、
INC、DEC、IAND、IOR和IXOR
GST
写到全局内存中
I2F
从整数转换为浮点数并复制
I2I
从整数转换为整数并复制
IADD、
IADD32、
IADD32I
整数加法
IMAD、
IMAD32、
IMAD32I
整数乘加
IMAX
对整数取最大值
IMIN
对整数取最小值
IMUL、
IMUL32、
整数乘法
IMUL32I
ISAD、
ISAD32
对差的绝对值求和（sum of absolute difference）
ISET
针对整数按条件赋值
LG2
对浮点数取对数（以2为底数）
LLD
从局部内存读取
LST