not affect its precision.
III. ESTIMATING ATTACK PATH LATENCIES
Conducting the attack using a given set of reﬂectors requires
us to ﬁrst estimate each reﬂector’s attack path latency, for
which we employ the technique used by King. King operates
by issuing recursive DNS queries between two DNS servers
located close to the end servers in question. Figure 2, taken
from [8], illustrates its operation, where we have overlaid
labels representing the attacker, victim, and reﬂector, as used in
our attack. With a single recursive query, an attacker can form
an estimate for the attack path RTT by taking the difference
in time between when the attacker sends a query to when the
attacker receives a response.
King must address two conﬂicting caching issues. First,
it “primes” the resolver so that it caches the fact that the
victim is authoritative for its domain (i.e., cache the NS
189
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:02 UTC from IEEE Xplore.  Restrictions apply. 
Figure 3: Two “good” resolvers (Google public DNS and Eindhoven University of Technology) with minimal path latency
variation, an obviously “bad” resolver with high path latency variation, and a resolver that appears good over small samples
of time but is actually bad for lensing, respectively. We took samples 2 min apart, and show timeouts with marks along the
top of the plot.
an attack, or draw upon a longer period of statistics to identify
the resolver as problematic. However, given that most resolvers
do not suffer from widely varying latencies, even if the attacker
does not account for misleading resolvers and simply assumes
every resolver that appears good over a short period of time is
indeed good, the efﬁcacy of their attack will not signiﬁcantly
suffer.
Long-term variation and caching. We now turn to the
degree to which attackers can fruitfully rely upon measure-
ments taken further in the past than just a short period prior
to launching an attack. An ability to use older measurements
would enable attackers to better hide the “reconnaissance”
activity necessary to set up an attack.
To this end, we used our same sample of resolvers and
sent 50 packets through each every 4 hours for 10 days.
For each resolver we computed the standard deviation of
the median latency over each ﬂight of measurements. We
then divided these standard deviations by the mean of the
median latencies, obtaining coefﬁcients of variation (CoV).
We found that many resolvers’ path latencies exhibit very little
variance over time, indicating an attacker could cache latency
estimates for signiﬁcant periods of time. Attackers could also
compute such statistics over large groups of resolvers to
identify substantial subsets to save on a “short list” of high-
quality resolvers to employ in future attacks.
We also note that we did not ﬁnd many resolvers with very
high attack path latencies (many hundreds of msec). Such
resolvers (if exhibiting low variance) would enable an attacker
to increase their overall bandwidth gain because they would
provide longer periods of time over which to send packets (and
subsequently concentrate). However, we found that most such
high latency paths also exhibited high jitter and inconsistency.
IV. BUILDING AN OPTIMAL SCHEDULE
Given path latency estimates for the reﬂectors, the attacker
then needs to compute a sending schedule. This schedule
divides up the sending window into a set of time slots T ,
listing for each slot which reﬂector the attacker should send
to in that slot. The number of slots available for the attacker
to send is a function of the attacker’s maximum bandwidth
(which determines the idle time between adjacent slots) and
the range of path latencies measured for different reﬂectors.
We deﬁne the pulse window (or simply window) as the
duration of the pulse as seen at the victim. In trying to create a
maximal pulse, the attacker’s goal is to maximize the expected
number of packets that land in a predetermined window.
To do so, we use a greedy algorithm to compute an optimal
schedule given an initial set of reﬂectors and estimates of
their corresponding attack path latencies. According to our
algorithm, at each time slot t we simply choose the reﬂector
that provides the highest estimated probability of landing
within the window. Absent any restrictions on how often an
attacker can employ a given reﬂector, we can show that this
greedy algorithm is indeed optimal (see below).
These problem statements and the ensuing proofs do not
account for distortions in the attack path latencies due to the
attack itself—such as those caused by effects of over-taxing
resolvers, or congestion caused by the attack. By distributing
the attack over geographically diverse resolvers, congestion
should rapidly decrease at points further from the victim, so in
fact self-congestion might not actually prove detrimental to the
attack. In addition, our experimentation reveals little evidence
of congestion actually inhibiting our emulated attacks.
In addition, our proofs cover the simpliﬁed case where the
attacker can freely reuse any reﬂector for a given time slot.
The more complex case where the attacker throttles overall use
of any given reﬂector does not appear to readily lend itself to
proofs of optimality.
Finally, an actual pulsing attack will consist of multiple,
evenly spaced pulses. We can construct an optimal schedule
for this scenario in a fashion similar to the single pulse case
above. At each time slot t we choose the reﬂector that provides
the highest estimated probability of landing in any window.
We prove optimality for this case after ﬁrst addressing the
single-pulse case.
190
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:02 UTC from IEEE Xplore.  Restrictions apply. 
A. Proving Schedule Optimality: Single Pulse
For each time t ∈ T when we consider sending, and for
each reﬂector r ∈ R (the set of reﬂectors), let Pr(t, r) denote
the probability that if we send to reﬂector r at time t, the
reﬂected packet will land in the desired window. Note that
§ III provides estimates for this probability. We assume that
these probabilities are independent and time-invariant (for any
reﬂector, a given latency will occur with a given probability
regardless of when we send to the reﬂector, or what packets
we send at other times).
Suppose we have chosen a schedule for which at each time
t we send to reﬂector rt. Let X denote the random variable
representing how many packets arrive in the window. X =
(cid:80)
t∈T
Xt, where
(cid:40)
Xt =
1
0
if packet sent at t lands in window
otherwise.
So, E(Xt) = Pr(t, rt). Then, due to linearity of expectation,
(cid:88)
t∈T
(cid:88)
t∈T
(cid:88)
t∈T
E(X) = E(
Xt) =
E(Xt) =
Pr(t, rt).
Given this, we claim that any schedule that optimizes E(X)
must have the condition that for each t, we send to the reﬂector
with highest Pr(t, r) over r ∈ R. To see this, assume for
the sake of contradiction that an optimal schedule S exists
such that at time t∗ we do not send to the reﬂector r∗ that
yields the highest probability; instead, we send to r∗∗. By
construction, Pr(t∗, r∗) > Pr(t∗, r∗∗). Consider S(cid:48), the same
schedule as S except that at t∗, it sends to r∗. Let the expected
number of packets landing in the window of S and S(cid:48) be
E(X) and E(X(cid:48)) respectively; then the difference between
the expectation of the schedules is:
E(X(cid:48)) − E(X) =
=
t∈T
t∈T
E(Xt)
E(X(cid:48)
t) −(cid:88)
(cid:88)
Pr(t∗, r∗) +
(cid:88)
Pr(t∗, r∗∗) +
(cid:88)
t) − (cid:88)
(cid:88)
t∈T∧t(cid:54)=t∗
= [Pr(t∗, r∗) − Pr(t∗, r∗∗)]
t∈T∧t(cid:54)=t∗
E(X(cid:48)
−
+
E(X(cid:48)
t)
E(Xt)
t∈T∧t(cid:54)=t∗
t∈T∧t(cid:54)=t∗
= Pr(t∗, r∗) − Pr(t∗, r∗∗)
E(Xt)
However, we already established that this last term is greater
than 0. Thus, E(X(cid:48)) − E(X) > 0 and S(cid:48) provides a better
schedule than S, which contradicts our assumption that S is
optimal.
B. Proving Schedule Optimality: Multiple, Evenly-spaced
Pulses
We now extend the problem to scheduling optimally using
multiple, evenly-spaced windows. For deﬁning “optimal” in
this case, we consider two intuitive notions:
• Having the largest amount of packets land in any pulse
(that is, maximize the sum of packets in all pulse win-
dows)
and then show that it also accomplishes the second.
• Having the largest possible consistent pulses
We present an algorithm that trivially accomplishes the ﬁrst
The algorithm proceeds as follows. For each time slot t ∈ T ,
choose the reﬂector with the highest probability of landing in
any window. The justiﬁcation that this satisﬁes the ﬁrst criteria
follows trivially from the previous proof, and we omit it here.
To see how the algorithm fulﬁlls the second deﬁnition,
we claim that an attacker can repeatedly execute an optimal
schedule with the same period as the attack. Consider an
arbitrary time slot ti and the time slot p time units in the future,
ti + p, where p represents the period. Label the jth window
wj. Suppose a packet sent at ti to reﬂector r has probability
P rwj (ti, r) of landing in window wj. Then, at ti + p, reﬂector
r has probability P rwj+1(ti +p, r) = P rwj (ti, r) of landing in
window wj+1. In steady state, we can express the probability
that a packet sent at ti to r lands in any window as:
∞(cid:88)
j =−∞
∞(cid:88)
j=−∞
P rwj (ti, r) =
P rwj+1(ti + p, r)
(1)
Thus, the probability that it lands in any window is the same p
time units in the future. Since our optimal algorithm for each t
chooses the reﬂector r with the highest probability of landing
in any window, and because this chance is periodic, it follows
that its schedule is periodic.4
Since schedules are periodic, it follows that the expected
number of packets that land in any window is constant. Thus,
the algorithm produces a schedule that satisﬁes the second
deﬁnition of optimality.
V. CHARACTERIZING ATTACKS
Armed with the ability to estimate attack path latencies and
to build an optimal schedule from them, we now turn our
development of an approach to experimentally validate lensing
attacks.
A. Features measured
We explore the effectiveness of pulsing attacks in terms of
three dimensions:
1) attacker bandwidth (sending capacity of originating sys-
tem)
2) pulse window size (duration over which attacker wants
packets to arrive at target)
3) maximum bandwidth to employ for each reﬂector
4There is the possibility that two equally good reﬂectors exist for time slot
at ti, and we could send to one at ti and the other at ti + p. We assume the
schedule consistently chooses just one.
191
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:02 UTC from IEEE Xplore.  Restrictions apply. 
Regarding the last of these, along with considerations such
as rate-limiting that a given reﬂector imposes on its activity,
an attacker might want to throttle the bandwidth to any given
reﬂector to avoid arousing suspicion. For our purposes, since
we do not know the resources of the reﬂectors we employ,
we err on the side of caution when using them, sending to
each at a maximum bandwidth of 500 pps over a course of
20–100 ms (i.e., at most 5 KB per pulse).
We do not explicitly explore the number of reﬂectors used
as a dimension, because the number of reﬂectors heavily
depends on the existing dimensions of attacker bandwidth and
maximum bandwidth to each reﬂector.
B. Metrics
In § IV we deﬁned an optimal schedule as one that has the
greatest expected volume of packets falling within the pulse
window. This is intuitively a natural parameter to maximize.
However, if we solely use absolute number of packets as our
metric of efﬁcacy, it can be artiﬁcially inﬂated just by in-
creasing the uplink bandwidth of the attacker or increasing the
target window size. This issue motivates us to we incorporate
some additional, bandwidth-agnostic metrics:
bandwidth in pulse window at target
• bandwidth gain:
attacker’s maximum sending bandwidth
• concentration efﬁciency: # packets landing in window
The ﬁrst metric is the most important from the short-term
point of view of the attacker. It gives the attacker a sense of
how much extra bandwidth the attack can produce.
# total packets sent
The second metric, however, provides a good basis for deter-
mining how the attack scales with the attacker’s bandwidth. If
the size of the reﬂector pool remains constant, upon increasing
the sending (attacker) bandwidth, more time slots occur for
which the schedule fails to provide an available resolver to
send to (because we throttle bandwidth to any given reﬂector).
In this case, the bandwidth gain will artiﬁcially decrease. For
example, if (as an extreme case) we send a maximum of one
packet to each of 100 reﬂectors, then we can send at most
100 packets to the target. Thus, as our uplink bandwidth,
increases, the bandwidth gain will decrease (the bandwidth
gain numerator is capped at 100)—not because of poor scaling,
but because of an absence of suitable reﬂectors. However, all
other things equal, the concentration efﬁciency will remain
constant.