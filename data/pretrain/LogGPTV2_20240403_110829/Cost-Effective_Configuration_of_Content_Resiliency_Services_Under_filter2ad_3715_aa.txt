title:Cost-Effective Configuration of Content Resiliency Services Under
Correlated Failures
author:Jinliang Fan and
Tianying Chang and
Dimitrios E. Pendarakis and
Zhen Liu
Cost-Effective Conﬁguration of Content Resiliency Services
Under Correlated Failures
Jinliang Fan
Tianying Chang
Georgia Institute of Technology
{jlfan,tychang}@cc.gatech.edu
Dimitrios Pendarakis Zhen Liu
IBM T. J. Watson Research Center
{dimitris,zhenl}@us.ibm.com.
Abstract
Value-added content resiliency services help to migrate
the burden of resiliency provisioning and maintenance from
service users, especially home users and small/medium or-
ganizations, who have difﬁculty in handling correlated fail-
ures that impact large areas. For service providers to
achieve business success, however, the cost-effectiveness of
their resiliency strategies is critical: while the content re-
siliency requirements speciﬁed by the end users have to be
satisﬁed, excessive preventive operation costs caused by the
over-reaction to potential risks should be avoided. In this
paper, we study the problem of cost-effective conﬁguration
in content resiliency service networks under both indepen-
dent and geographically correlated failures. We propose
a new approach to modeling correlated failures in a rep-
resentable, quantiﬁable and consistent way, which allows
for both quantiﬁed availability guarantees and aggressive
prevention cost optimization. We then formulate the cost-
effective conﬁguration problem in content resiliency ser-
vices and develop both real optimal and heuristic-based al-
gorithms for solving the problem. Our experiments show
that with the help of good models for correlated failures, the
operation cost of the services can be signiﬁcantly reduced
without impairing the user-speciﬁed content resiliency.
1
Introduction
While engineers have invested a signiﬁcant amount of ef-
fort in improving the reliability of computer hardware and
software, failures are still common in today’s computer and
network systems. Failures can be caused by not only worn-
out devices and software bugs but also external factors such
as power outage, environmental conditions and operational
accidents. Replicating is one of the most important strate-
gies for improving the resilience of content in the presence
of failures[1][2][3]. It can signiﬁcantly improve the avail-
ability of the data even when multiple servers fail at the
same time, and reduce the potential damage caused by the
loss of data.
While content servers can be deployed by an organiza-
tion for its private use, in this paper we are most interested
in Content Resiliency Service Networks. As shown in Fig. 1,
a content resiliency service provider deploys a pool of con-
tent servers at different locations over the Internet. Users at
the end-systems access (i.e., upload to and download from)
their data at a local content server, which is then responsi-
ble to replicate the data to some of the other servers in the
pool. Such value-added services free users (especially home
users, small and medium organizations) from the burden of
resiliency planing and maintenance and provides proﬁt op-
portunities to the service provider. On one hand, a content
resiliency service provider contracts with service users in
the form of service agreement, which allows the users to
specify the desired level of content resiliency or the penalty
for loss of data. On the other hand, the content resiliency
service provider pays prevention costs, such as the com-
munication cost of replicating data among content servers,
storage costs, and types of management costs, to maintain
the normal operation of the content servers and achieve the
agreed content resiliency.
Cost-oriented conﬁguration optimization is especially
important for services deployed for proﬁt purposes. Fig.2
shows a content resiliency service network with a pool of
nine content servers. A user uploads its data to its local
content server S0, and S0 is responsible to choose a set
of remote replication locations from the other eight con-
tent servers and deliver the data to the chosen ones. For
example, it can choose servers S3 and S7 and form a repli-
cation set of {S0, S3, S7}, or choose servers S2 and S5 and
form a replication set of {S0, S2, S5}. Intuitively, the fur-
ther the servers replicating the same data reside from the
content origination and from each other, the more unlikely
the servers will fail in the same period but the more commu-
nication cost will be incurred. A good conﬁguration of con-
tent server replication relationship should maintain a target
level of content resiliency while minimizing the prevention
cost incurred by the conﬁguration and avoid excessive costs
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Internet 
End Users 
Data Servers 
Data Access 
Data Replication 
Internet 
S7
S3
S8
S1
S2
S0
S4
S5
S6
User
fault
1/c
N2
N1
N4
N3
N5
R
fault field
Figure 1. Content Resiliency Service Net-
works
Figure 2. Data Replica-
tion Conﬁguration
Figure 3. Correlated
Failure Model
caused by over-reaction to potential risks.
2 Correlated Failures and Modeling Ap-
proaches
In this paper we study the static and dynamic conﬁg-
uration problems in content resiliency service networks
impacted by both independent and geographically cor-
related failures. Geographically correlated failures are
those caused by events that impact geographical vicini-
ties, e.g., power-outages, weather and environmental dis-
asters, and catastrophic events. Some types of network as-
sociated failures can also be considered as geographically
correlated. Geographically correlated failures usually af-
fected relative large areas, which renders users’ private lo-
cal backup systems ineffective and makes the third-party
content resiliency service an attractive option. The impact
of geographically correlated failures on system resiliency
has drawn interest from both industry and academia (e.g.,
[1][2][3]) and the remote placement of system entities has
been proposed as a general solution to improve system re-
siliency. These efforts, however, suffer from the lack of
good models for geographically correlated failures. With-
out such models, the improvement in resiliency cannot be
fully quantiﬁed and aggressive methods of cost optimiza-
tion cannot be developed.
The remainder of this paper is organized as follows. In
Section 2, we describe a new approach to modeling corre-
lated failures. The approach is demonstrated using a model
for geographically correlated failures in Section 3, where
we also formulate the static conﬁguration problem in con-
tent resiliency service networks after identifying cost fac-
tors in the replication process.
In Section 4, we present
optimization algorithms, including ones that generate real
optimal solutions and heuristic-based ones, for solving the
static conﬁguration problem. In Section 5, we discuss the
dynamic conﬁguration problem in content resiliency service
networks. We conclude in Section 6.
Potential sources of failures can be either independent
or correlated.
In distributed systems composed of multi-
ple entities, independent failures are those local to a single
entity and caused by entity-speciﬁc hardware or software
conditions.
In contrast, correlated failures are caused by
fault events impacting multiple entities in the same time or
within a very short interval and have drawn attention from
researchers in various domains (e.g., software engineer-
ing, fault-tolerant systems, networking) of computer sci-
ence [4][5][6][7][8][9][10][11]. Modeling correlated fail-
ures is much more challenging than modeling independent
ones. Due to existence of multiple-way correlations and the
exponential number of subsets of entities, it is usually im-
practical for system designer to directly measure and spec-
ify the probability of simultaneous failures for every subset
of entities in the system.
Much of research work in modeling correlated failures
has been focused on building models that specify only
the two-way correlations between entities (e.g., conditional
probabilities that one entity fails given another entity fails)
and approximate multiple-way correlations using two-way
correlations. Weatherspoon et al. [2] cluster entities based
their two-way correlations and use the clustering as an
implicit measure of multiple-way correlations.
Such a
method generally helps in addressing correlated failures in
system design, but it does not produce quantiﬁable mod-
els and, hence, cannot be used in a service environment
where availability requirements are quantiﬁed. Some ap-
proaches, for example, Victor and Goyal’s beta-binomial
model [12] and Bakkaloglu and Wylie et al.’s recursive lin-
ear model [13][14] can be used to build models that approx-
imate multiple-way correlations from two-way correlations
in a quantiﬁable way. The limitation of these models is that
they are designed to capture failures of m-out-of-n enti-
ties and therefore do not allow for calculating the proba-
bility of failure for speciﬁc subsets of entities. To leverage
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
these models, system designers have to assume the level of
multiple-way correlations is homogenous across the system
(and sacriﬁce accuracy in availability) or choose an system-
wide upper-bound (and sacriﬁce the potential in cost opti-
mization). State-based models [7][15] are more expressive
and consistent than the above models in quantifying entity
correlations but they are also more complicated. Tang’s
model [7] can be used to derive correlated failures states
based on the two-way dependency between entities.
In
the context of content resiliency service networks, however,
the correlated failures of entities (i.e., content servers) are
mainly caused by external fault events (e.g., power outages,
environmental conditions) failure instead of dependency be-
tween entities (e.g, overload shifting). Also the transition
between intermediate states are relative difﬁcult to capture
in large distributed systems.
In this paper, we propose a new general approach to
modeling correlated failures:
instead of modeling failure
correlations between entities directly, we model the occur-
rence of fault events that impact the entities and cause cor-
related failures. Failure correlations between entities are
consequently inferred. The approach has two steps: ﬁrst,
entities are projected to a Euclidean fault ﬁeld and assigned
coordinates based on a certain distance metric. Depending
on the type of correlated failures under consideration, this
distance metric could be a physical one, such as geographic
distance, a logical one, such as distance in communication
networks and social networks, or simply the measured two-
way failure correlation between two entities. 1 Second, fault
events are modeled over the fault ﬁeld. Speciﬁcally, the lo-
cation of faults and their impact are modeled. Thus the fault
ﬁeld acts as a medium to establish correlation between the
fault events and the entities using their locations in the fault
ﬁeld. Models constructed in this way intuitively reﬂect the
nature and cause of correlated failures in content resiliency
services and provide a consistent view of failure correlation
between entities. In Section 3.3.1 we apply our approach
to the modeling of geographically correlated failures. The
model allows us to study cost-effective conﬁguration issues
in content resiliency service network in the presence of both
independent and geographically correlated failures.
3 Static Conﬁguration Problem in Content
Resiliency Service
For a formal discussion of the static conﬁguration prob-
lem in content resiliency service network, we ﬁrst describe
our failure models for independent and geographically cor-
related failures and discuss the meaning of data availability
under such failure models. We then identify the cost factors
1If the distance does not satisfy the triangular-inequality, the non-
Euclidean space can be converted to a Euclidean space, possibly with ad-
ditional dimensions.
in the data replication process and formulate the problem
of cost-effective data replication as a constrained minimiza-
tion problem. We use discrete time models in which the
time axis is divided into slots. In real systems, the length of
the time slot depends on the system’s response time to fail-
ures. In this section and Section 4, we assume that a system
has enough time to detect and complete its responses(e.g.,
recovering data, adjusting backup sets) by the end of a time
slot for all failures that have happened during that time slot.
The assumption will be relaxed in Section 5 when we dis-
cuss cost minimization over a sequence of time slots under
dynamic system conditions.
3.1 Failure Models
We assume the pool of content servers in the content re-
siliency service network are distributed over a 2-dimension
fault ﬁeld.2 We assume the geographic location of each con-
tent server is known to all other content servers (e.g., by an
administrator or through some information exchanging pro-
tocol) in the form of a coordinate in the 2-dimension fault
ﬁeld. We consider two categories of failures that could hap-
pen to the content servers: independent failures and geo-
graphically correlated failures.
Geographically Correlated Failure Model Instead of di-
rectly specifying the probability of content server failures
and their correlation, we model the geographical distribu-
tion and the impact of geographical fault events (e.g., power
outage) that could cause multiple content servers fail simul-
taneously in the same time slot.
First, we assume that in each time slot, the probabil-
ity that one geographical fault event occurs is Pcorr and
the probability that more than one such fault events oc-
cur is ignorable. Second, we assume that the center of a
fault event is distributed according to a uniform random
distribution over a circular fault ﬁeld with a radius R on
a 2-dimension plane. Third, to characterize the phenomena
that fault events affecting large geographical areas are much
rarer than those affecting small geographical areas, we as-
sume the impact of a fault event is exponential decaying and
model it as follows: the impact of a fault event reaches as
far as a distance r from the center of the fault, where r is a
random variable that is exponentially distributed with a pa-
rameter c; when a fault event happens, all content servers
within a radius of r to the center of the fault event fail si-
multaneously.
Fig. 3 shows a visual presentation of our model for geo-
graphically correlated failures. The fault ﬁeld is contained
2Note that for geographically correlated failures, the fault ﬁeld natu-
rally lies on a two-dimension plane and a server’s geographic location
serves as its coordinates in the fault ﬁeld. For other types of correlated
failures, the construction of the fault ﬁeld could be more complex (e.g.,
involving the conversion of a non-Euclidean space to a Euclidean one) and
the model for fault events could be different.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
within the solid-line circle and the impact of an example
fault event is represented with a dashed-line circle. Among
the ﬁve content servers (N1-N5) in the ﬁgure, two content
servers (N1 and N2) fail simultaneously because of the ex-
ample fault event.
Independent Failure Model In addition to correlated fail-
ures, we also consider independent failures. They are
caused by factors local to each speciﬁc content server, e.g.,
broken hardware and crashed software. For simplicity of
presentation, in this paper we assume that each content
server fails independently with a ﬁxed probability Pind in
each time slot.
3.2 Analysis of Data Availability
r=d(S,v)
(cid:1)
v
e−cr
c
(cid:1) +∞
Data loss happens all the content servers that store a
piece of data fail in the same time slot. When a fault
event occurs at center v, all content servers in a replication
set S will fail correlatively if and only if their maximum
distance to v is equal or less than the radius of the fault
event. That is, the probability that they all fail in this fault
is Fcorr(S, v) =
dr = e−c·d(S,v) where
d(S, v) = maxNi∈S d(Ni, v). If the probability of indepen-
dent failures is zero, the probability that all content servers
in S fail in the same time slot is simply the integral of the
above equation over all possible centers of this fault event
Fcorr(S, v) dv. When both
in the fault ﬁeld, i.e., Pcorr
πR2
independent failures and geographically correlated failures
are possible, however, the failure of a whole set of con-
tent servers can be the result of various combinations of in-
dependent failures and correlated failures (i.e., part of the
set fail independently and part of the set fail correlatively.)
Given a fault event that has happened at center v, we need
to consider separately the cases where the radius of the fault
event covers one server, or two servers, ..., or all servers
in the set S. Assume the content servers in S have been
sorted based on their distances to the center of fault, v, and
(cid:2)|S|
they are Ni1 , Ni2 , . . . , Ni|S| in increasing order, we have
Fcomb(S) = P rob{r ≥ d(Ni|S| , v)} +
s=1 P rob{r ∈
k=s P rob{Nikfails}, where we
[d(Nis−1 , v), d(Nis
−c·d(Ni|S| ,v) +