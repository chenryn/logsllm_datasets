picious” or “malicious” for the presence of symmetric crypto-
graphic primitives. For the sake of clarity, we remark that
the output of CryptoFinder is used as an additional, non-
essential feature. Hence, ShieldFS is able to detect even
samples that do not show any encryption process, as long as
the ﬁlesystem activity models are suﬃciently (i.e., at least
K positive ticks) triggered.
ShieldFS does not make any assumption on how the
cipher is implemented by the malware, save for the mate-
rialization of the key schedule. As a proof of concept, we
select AES as our target block cipher, due to its widespread
use. AES’s key schedule expands 128, 192 or 256 key bits
into 1408, 1664 or 1920 key schedule bits, respectively. As a
consequence, taking all the 264 possible positions in the ad-
dress space as candidates, and assuming that the accidental
occurrence of a key expansion for a location is independent
from it occurring for a diﬀerent one, the probability of a false
positive is 2642−1408 = 2−1344 (in the most favorable case),
which is negligible for practical purposes.
CryptoFinder receives the PIDs of suspicious processes by
the Detector, through IOCTL. When triggered, CryptoFinder
attaches to a process and obtains the list of its memory pages.
Speciﬁcally, CryptoFinder looks only at the committed pages,
deﬁned in Windows as the pages for which physical storage
has been allocated—either in memory or in the paging ﬁle on
disk. Then, CryptoFinder runs the key-schedule algorithm
on these memory regions and checks whether its expansion
occurs. For eﬃciency reasons, we stop the inspection of a
location as soon as there is a single byte mismatch.
4.3 Automatic File Recovery
We implemented Shielder as a Windows miniﬁlter driver
that monitors ﬁle modiﬁcations by registering a callback
for those IRP_MJ_CREATE operations which security context
parameter Parameters.Create.SecurityContext indicates
a “write” or “delete” I/O request. If the target ﬁle is not shad-
owed yet, ShieldFS creates a copy before letting the request
Figure 3: High-level overview of ShieldFS. The Detector
and the Shielder are Windows miniﬁlter drivers, and the
CryptoFinder is kernel driver.
For each IRP, the called function updates the feature val-
ues, using separate kernel worker threads for computation-
intensive functions (e.g., entropy calculation).
Feature Normalization. To keep the feature values nor-
malized (e.g., number of ﬁles read, normalized by the total
number of ﬁles), the ﬁrst time the ShieldFS service is run,
it scans the ﬁlesystem to collect the ﬁle extensions, number
of ﬁles per extensions, and overall number of ﬁles.
Since the normalization factors change over time (i.e., new,
deleted, or renamed ﬁles), ShieldFS updates them in two
ways. One mechanism uses a dedicated kernel thread to
update the normalization factors in real time. This has no
performance impact, since ShieldFS already keeps track
of the relevant ﬁle operations. However, an attacker could
exploit it to bias the feature values, by manipulating the
normalization factors (e.g., by creating many legitimate, low-
entropy ﬁles). The second mechanism raises the bar for
the attacker because it updates the normalization factors
periodically (e.g., once a day). In this way, even if an attacker
tries to manipulate our normalization factors, she will need
to wait until the next update before starting to access ﬁles
without triggering any of the features. Although the second
mechanism is more resilient to such attacks, it is prone to
false positives if users create many ﬁles between updates.
False positives, however, occur only if a signiﬁcant number
of ﬁles are accessed in a way that resembles a ransomware
activity (i.e., several folder-listing operations, followed by
ﬁle reads or renaming, and high-entropy writes). Taking our
dataset of benign machines monitored for about a month as
a reference, the impact of these false positives is very low
compared to the beneﬁts of increased resiliency.
Classiﬁer Details. Each classiﬁer is implemented as a ran-
dom forest of 100 trees. Each tree outputs either −1 (benign)
or +1 (malicious). The overall outcome of each process-
centric classiﬁer is the sum of its trees’ outcome, from −100
(highly benign) to 100 (highly malicious). In case of a tie (i.e.,
zero), ShieldFS marks the monitored process as “suspicious,”
and invokes the system-centric classiﬁer to take the decision.
In case of a second tie, we conservatively consider the process
as malicious.
Process 1address spaceProcess 2address space. . .Disk driveProcess 1Process 2...I/O Manager (minifilter driver interface)Process centric model 1...Process centric model 2"process 2 is benign", "process 1 is malicious: kill it and restore files"open("file.txt")read(fp1)...System centric modelCryptoFinderI/O Request Packets (IRPs)"process 1 is suspicious"User spaceKernel spaceVirtual memoryShadow drive"delete process 2 file copies""restore process 1files copies""search for crypto key schedule"ShielderFeaturevaluesDetectorAlgorithm 1 Detection routine for each process.
5 EXPERIMENTAL RESULTS
if enoughF ilesAccessedF orT ickOf (tier) then
result ← ProcessClassiﬁertier(f s f eatures)
resetF eatureV alues(tier)
if result < 0 then
crypto ← ⊥
for tier ∈ {1, ..., top} do
Ktier ← 0
crypto ← CryptoFinder(P ID)
if result = 0 then
1: procedure isRansomware(P ID, f s f eatures)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
if crypto ∨ ∃tier : Ktier ≥ Kthreshold then
Ktier + +
Ktier + +
else
return malicious
return benign
else
if SystemClassiﬁertier(f s f eatures) ≥ 0 then
through. With the same technique it monitors the destina-
tion of (potentially malicious) ﬁle-renaming operations, by
hooking the IRP_MJ_SET_INFORMATION requests having the
ReplaceIfExists ﬂag set. File handing and indexing in the
shadow drive is based on the FILE_ID identiﬁer assigned by
NTFS to each ﬁle.
Transaction Log. ShieldFS maintains a transaction log
of the relevant IRPs (e.g., those resulting from ﬁle mod-
iﬁcations). Whenever a process is classiﬁed as malicious,
ShieldFS inspects such log and restores each ﬁle aﬀected by
the oﬀending process.
File copies are deleted only when the processes that modi-
ﬁed the original ﬁle have been cleared as “benign.” ShieldFS
treats the shadow drive as a cache: It avoids shadowing the
same ﬁle if a fresh copy (i.e., not older than T hours) already
exists. According to our experiments, based on the work-
load of real-world users (obtained form our large-scale data
collection), the age T imposes acceptable overhead (below
1%) and can be safely set to any number between 1 and 4.
In Section 6 we discuss how the choice of T raises the bar
for the attacker who wants to successfully encrypt a large
portion of ﬁles.
Whitelisting of Support Files. Files that have no value
for a user are of no interest for ransomware attacks. An
example are application-support directories, which contain
cache or temporary ﬁles, which are frequently accessed by
benign applications. These folders can be safely whitelisted
to reduce the performance overhead due to the frequent
operations on such ﬁles. To avoid that an attacker could
exploit the whitelisted folders as a “demilitarized zone” where
to copy the target ﬁles (prior to encrypting them), we adopt
the following solution. Any process that has never accessed
a whitelisted folder is considered “suspicious” as soon as it
attempts to move ﬁles into it. The ﬁles oﬀended by this
operation are preemptively shadowed.
Windows Shadow Copy. Recent Windows versions have a
so-called Volume Shadow Copy Service. However, Windows
shadow copies have two issues. First, the copies are created
only during the next power down and boot cycle. Instead,
as we already mentioned, our approach is designed for short-
term backup that can allows users to restore recently modiﬁed
ﬁles. Secondly, shadow copies can be easily bypassed and
deleted, as most of recent ransomware families do before
starting the encryption process [8].
As we did for our preliminary analysis (Section 2.2), we
evaluated ShieldFS on an analysis environment with virtual
machines provisioned so as to mimic the ﬁle content and
organization of potential victim machines.
We ﬁrst performed a thorough cross validation to assess
(1) the generalization capabilities of our classiﬁers, and (2)
the impact of the parameter choice on the overall detection
quality and performance. Second, we infected physical ma-
chines in use by real users (for their day-to-day activities)
with 3 samples of ransomware families. ShieldFS was able
to detect their activity and fully recover all the compromised
ﬁles. Third, we evaluated the detection and ﬁle-recovery
capabilities against ransomware samples that ShieldFS has
never seen before. Last, we measured the performance over-
head of ShieldFS by considering the typical usage workload,
where “typical” refers to our initial large-scale collection of
I/O ﬁlesystem logs.
A video demo of ShieldFS in action is available on YouTube
at [17].
5.1 Detection Accuracy
Cross validation allows to reveal the presence of overﬁtting-
induced biases and thus is a crucial aspect of any machine-
learning-based approach. We conducted three cross-validation
experiments to evaluate the quality of the Detector on our
dataset of 383 ransomware samples and 2,245 benign appli-
cations from the 11 user machines. We count positive or
negative detections at the process granularity, and calcu-
late the TPR and FPR based on the true overall number of
benign and ransomware processes.
10-fold Cross Validation. We calculated the true- and
false-positive rate on 10 random train/test splits. Figure 4
and 5 show the TPR and FPR in function of the minimum
percentage of ﬁles, and #IRPs, respectively, needed to cast
the decision. The results show the beneﬁt of the system-
centric model as a tie breaker, and the incremental approach
as an early detector, which requires orders of magnitude less
IRPs to cast a decision, with almost no impact on the FPR
(i.e., from 0.0 to 0.00015 in the worst case).
One-machine-oﬀ Cross Validation. To further show the
independence of our detection results from the speciﬁc ma-
chine that generates the benign subset of training and testing
data, we performed a per-machine cross validation. We selec-
tively removed the data of one machine from the training set,
and used it as the testing set. We repeated this procedure
for each of the 11 machines.
Table 4 shows (1) that ShieldFS has no strong dependency
from the training-testing data split, and (2) conﬁrms that
the system-centric model is useful to reduce FPs by acting
as a tie breaker.
Causes of False Positives. We found only two cases of
false positives. For the ﬁrst user machine, the detector
triggered because explorer.exe biased the normalization,
by accessing a very large number of ﬁles (more than the
normalization factors, which were not up to date). This
motivated us to implement the mechanism that live-updates
the system-wide, feature counts for normalization (rather
than doing such an update periodically). This eliminates the
false positives, creating however a small opportunity for the
attacker to bias the normalization factors. This trade oﬀ is
clearly inherent in the statistical nature of ShieldFS.
R
P
T
R
P
F
1
0.98
0.96
0.04
0.02
0
Process centric
System centric
10−3
10−2
10−1
100
R
P
T
R
P
T
1
0.5
0
1
0.5
0
100
Without incremental, multi-tier models
Process centric
System centric
101
102
103
104
105
106
Fraction of ﬁles accessed (log. scale)
Number of I/O request packets (log. scale)
Figure 4: 10-fold Cross Validation: Average and stan-
dard deviation of TPR and FPR with process- vs.
system-centric detectors.
Figure 5: 10-fold Cross Validation: TPR of process- and
system-centric detectors, with and without the incremen-
tal, multi-tier approach. FPR ranges from 0.0 to 0.0015.
Interestingly, in 4 out of 11 machines we found activity of
the WinRar ﬁle-compression utility, which performed high-
entropy writes. Nevertheless, WinRar was correctly classiﬁed
as benign, thanks to the contribution of the remainder fea-
tures.
The second false positive was Visual Studio, which wrote
175 ﬁles, with a very high average entropy (0.948). This
was an isolated case, which happened only on one of the 32
Visual Studio session recorded in our dataset.
Parameter Setting. The choice of K, the number of con-
secutive positive detections required to consider a process as
malicious, can be set to minimize the FPR to zero, at the
price of a very small variation (within +/-0.5%) of TPR. Or
vice versa. Table 5 shows that setting K = 3 maximizes the
TPR, with very few false positives. Instead, with K = 6,
ShieldFS did not identiﬁed a sample that performed in-
jection into a benign process and that encrypted ﬁles very
slowly. Generally, false negatives are more expensive than
false positives in ransomware-detection problems, thus we
advise for values of K that maximize the TPR. This has the
additional beneﬁt of reducing the number of IRPs required
for a correct detection.
5.2 Protection of Production Machines.
In order to evaluate our system in real scenarios, we tested
ShieldFS on three distinct real machines (running Windows
7 and 10), in use by real users for their day-to-day activities
for years, containing 2,319, 165,683, and 144,868 ﬁles, respec-
tively. We randomly selected 3 samples1 from our dataset
(Critroni, TeslaCrypt, and ZeroLocker) and manually ana-
lyzed them to ensure that they were not stealing any personal
1
e89f09fdded777ceba6412d55ce9d3bc,
209a288c68207d57e0ce6e60ebf60729,
bd0a3c308a6d3372817a474b7c653097
Table 4: FPR with One-machine-oﬀ Cross Validation
User
False positive rate [%]
Machine Process System Outcome
1
2
3
4
5
6
7
8
9
10
11
0.53
0.00
0.00
0.00
0.22
0.00
0.00
0.00
0.00
0.00
0.00
23.26
0.00
0.00
1.20
45.45
4.76
88.89
0.00
0.00
0.00
0.00
0.27
0.00
0.00
0.00
0.15
0.00
0.00
0.00
0.00
0.00
0.00
information. After cloning the hard drives as a precaution,
we installed ShieldFS, and infected the machines. All the
three samples were correctly detected and all the aﬀected
ﬁles were correctly restored automatically.
5.3 Detection and Recovery Capabilities
We setup an environment as described in Section 2.2, with
dummy ﬁles to reproduce a real-user setting. Moreover, we
stored 9,731 ﬁles typically targeted by ransomware attacks
(e.g., images and documents of various formats), of which we
pre-calculated the MD5 for integrity veriﬁcation after each
experiment. We then trained ShieldFS on the large dataset