## üêõ Bug
max_norm in embedding layer modifies the embedding layer weight in-place which
makes it a non-leaf variable. This leads to issues when doing gradient
backpropogation.  
**Error: RuntimeError: leaf variable has been moved into the graph interior**
## To Reproduce
Script to reproduce the behavior:
    import torch
    import torch.nn as nn
    import numpy as np
    class sampleModel(nn.Module):
        def __init__(self):
            super(sampleModel, self).__init__()
            input_layer= nn.Embedding(500, 10, max_norm=1.0)
            output_layer = nn.Linear(10, 2)
            self.layers = nn.Sequential(input_layer, output_layer)
            self.loss_criterion = nn.NLLLoss()
        def forward(self, input, labels):
            em_x = self.layers[0](input).sum(1)
            out = self.layers[1](em_x)
            loss = self.loss_criterion(out, labels)
            return loss
    if __name__ == "__main__":
        device = torch.device('cpu')
        model = sampleModel().to(device)
        data = []
        for i in range(0,500):
            data.append(np.random.randint(0, 20, size=30))
        inputx = torch.LongTensor(data).to(device)
        labels = torch.LongTensor( [0]*250 + [1]*250 ).to(device)
        loss = model(inputx, labels)
        print(loss)
        loss.backward()
Stack trace:
    File "bug_report_script.py", line 34, in 
        loss.backward()
    File "/data/anaconda/envs/bletchley/lib/python3.6/site-packages/torch/tensor.py", line 118, in backward
        torch.autograd.backward(self, gradient, retain_graph, create_graph)
    File "/data/anaconda/envs/bletchley/lib/python3.6/site-packages/torch/autograd/__init__.py", line 93, in backward
        allow_unreachable=True)  # allow_unreachable flag
    RuntimeError: leaf variable has been moved into the graph interior
## Expected behavior
calculating max_norm should not make the embedding layer weight non leaf
variable.
## Environment
PyTorch version: 1.2.0  
Is debug build: No  
CUDA used to build PyTorch: 10.0.130
OS: Ubuntu 16.04.6 LTS  
GCC version: (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609  
CMake version: version 3.5.1
Python version: 3.6  
Is CUDA available: Yes  
CUDA runtime version: 10.0.130  
GPU models and configuration:  
GPU 0: Tesla M60  
GPU 1: Tesla M60
Nvidia driver version: 410.79  
cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.4.2
Versions of relevant libraries:  
[pip] numpy==1.17.2  
[pip] torch==1.2.0  
[pip] torchvision==0.4.0  
[conda] torch 1.2.0 pypi_0 pypi  
[conda] torchvision 0.4.0 pypi_0 pypi
## Additional context
Surprisingly, if the device is set to 'cuda', the script runs without error
cc @ezyang @ssnl @albanD @zou3519 @gqchen