215 buckets. Each bucket contains a linked list of meta data
records. A pointer in SlowPointer representation contains
the bucket ID in the upper 15 bits. The bucket ID is used to
identify the meta data record that belongs to the associated
memory object of this pointer.
Our allocator inserts meta data records for newly allocated
memory objects into the meta data store if the pointer
uses SlowPointer representation. Whenever a pointer in
SlowPointer representation is deallocated, we also delete
the entries in the meta data store. Since we switch pointer
representation between SlowPointer and FastPointer at run-
time, a meta data record might even exist for FastPointers.
2The system only breaks when the spare bits are deliberately changed
using integer arithmetic; Boundless does not protect against a malicious
software developer.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:38 UTC from IEEE Xplore.  Restrictions apply. 
0x00000x00010x00020x00030x7FFF0x0004...baseendbaseendbaseend18For example, a FastPointer might get copied and converted
to SlowPointer representation. If the original FastPointer
is used to deallocate the memory object, we still need to
delete the corresponding meta data record. Therefore, we
also have to access the meta data store even if a FastPointer
is deallocated. In the common case this access requires only
a single load operation and one comparison for FastPointers.
In order to look up a meta data record, we use the ID
stored in the SlowPointer representation to get the right
bucket. Next, we search the bucket for a meta data record
for which the given pointer is in-bounds. If no meta-data
record is found,
then the pointer is out-of-bounds. For
out-of-bounds pointers we access our out-of-bounds store
(Section V).
There is a probability that an out-of-bounds pointer is
falsely classiﬁed in-bounds if a bucket contains more than
one meta data record. For example, assume we have two
memory objects A and B. By chance both meta data records
reside in the same bucket. Consider an out-of-bounds pointer
p belonging to memory object A. There is a likelihood that p
points into the address range of memory object B. Thus, it is
possible that the out-of-bounds pointer p is falsely detected
as an in-bounds pointer to memory object B. However,
Boundless uses SlowPointers only as a fall back. In our
evaluation, we found that the SlowPointer representation
is rarely needed. Hence, in most experiments each bucket
contains at most one meta data record.
The probability of getting a false positive is inﬂuenced by
the calculation of the ID. We experimented with different
approaches, e.g. round robin and hashing. Finally, we chose
a very simple one: we use bits 4 to 18 of the end address of
the memory object. This approach is fast and sufﬁcient: we
never encountered a false positive. Furthermore, in contrast
to round robin and hashing, it enforces that two objects
sharing an ID have a minimal distance of 218 bytes.
V. TOLERANCE OF OUT-OF-BOUNDS ACCESSES
When using a spatial memory error detector, naturally one
question arises: What to do if a memory error is detected?
Most approaches implement fail-stop behavior. While this
can help during development
it does not help in many
real-world scenarios. Even with the best recovery strategies
the application’s availability is decreased. Furthermore, fail-
stop enables attackers to perform denial-of-service (DoS)
attacks. If an error can be deterministically triggered by an
attacker, aborting an application might result in a permanent
DoS. Three out of ﬁve applications presented in [15] expose
permanent DoS behavior in case a fail-stop approach is used.
In general, we cannot distinguish between a rightful user
doing something untested and a malicious attacker. As a
result, fail-stop is an option if and only if denial-of-service
is acceptable.
Instead of using a fail-stop approach, we tolerate out-of-
bounds accesses. Our tolerance runtime approximates the
theoretical concept of an inﬁnite heap [10]. Spatial memory
errors are impossible on an inﬁnite heap. We use an out-of-
bounds store to store out-of-bounds writes. Out-of-bounds
reads retrieve the value from the out-of-bounds store.
A. Inﬁnite Heap
We have adapted the concept of an inﬁnite heap [10] for
our tolerance approach. An inﬁnite heap has the following
properties:
• The heap area is inﬁnitely large.
• The distance between two allocated memory objects is
inﬁnite. We can never reach a different object by over-
or underﬂowing another one. Out-of-bounds errors are
contained, because the size of an object is virtually
inﬁnite. All objects are isolated from each other.
• The space between memory objects is initialized with
zero.
Obviously, it is impossible to implement a inﬁnite heap
using a machine with ﬁnite memory. However, we approx-
imate the inﬁnite heap by isolating all objects from each
other. We achieve object isolation by our pointer represen-
tation (see Section IV). Our instrumentation wraps all load
and store instructions completely. Any out-of-bounds access
is rerouted to our out-of-bounds store.
We apply our protection mechanism to the heap, the stack,
and the data segment. In this sense we do not only have
an inﬁnite heap, but we also have an inﬁnite stack and an
inﬁnite data segment.
B. Out-of-Bounds Store
All out-of-bounds pointers, except pointers to the end
address, are always represented as SlowPointer. However,
even in-bounds pointers can access out-of-bounds positions.
For example, loading a 64 bit value from a 1 byte large
allocation results in an out-of-bounds access. If an out-of-
bounds access uses a FastPointer, the pointer is converted to
SlowPointer representation ﬁrst. Next, we get the bucket for
this SlowPointer from the meta data store. In the common
case there is exactly one meta data record in this bucket.
This meta data record is associated with the memory object.
If there is more than one meta data record in this bucket, we
have to decide heuristically. We pick the meta data record
of the memory object closest to the out-of-bounds pointer.
We use a linked list as out-of-bounds store. Each entry in
this list corresponds to a currently allocated memory object
that experienced out-of-bounds write operations; the list is
normally very short. An entry is composed of an object
identiﬁer and another linked list. This linked list holds the
values stored by out-of-bounds operations. We use the end
address of the memory object as identiﬁer to isolate objects
in the out-of-bounds store. The end address is guaranteed
to be unique for all currently allocated objects. All entries
are allocated lazily; a load to an uninitialized out-of-bounds
position returns zero without any allocation.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:38 UTC from IEEE Xplore.  Restrictions apply. 
191
I f
i s
/ /
/ / one . O t h e r w i s e r e t u r n c b u f u n t o u c h e d
t h e o b j e c t
t o o s m a l l
r e t u r n a new
2
3 cp = enforceBufferSize(cbuf, 100);
4 fread(cp, s i z e o f (char), 100, stdin);
5
/ / merge b u f f e r s
i f (cp != cbuf) mergeBuffer(cp, cbuf);
i f n e c e s s a r y
6
Listing 4. Wrapping uninstrumented calls to enforce large enough buffers.
When a memory object is freed we also free all out-of-
bounds store entries of this memory object. A memory object
can be freed explicitly on the heap or implicitly on the stack
by destroying the stack frame the memory object belongs to.
C. Protecting Uninstrumented Functions
External libraries are not necessarily instrumented with
our compile time transformation, e.g., in case the source
code is not available. These uninstrumented functions them-
selves neither detect out-of-bounds memory access nor do
they tolerate them. However, we provide custom wrappers
to a set of common external functions. These wrappers
tolerate any out-of-bounds access caused by passing too
small buffers to these functions. We directly insert
the
wrapper code into the binary at compile time.
In order to prevent memory errors in these functions
we check the size of passed objects before the function is
called. Our wrappers encode semantic knowledge about the
functions behavior to calculate the necessary object size. For
example, for the standard C function fread we know the
passed buffer needs to be at least as large as the number of
requested bytes. Listing 4 shows the added code for a call to
fread. Function enforceBufferSize returns a newly
allocated object if the passed object is too small. Otherwise
is returns the passed object untouched. The returned object
is guaranteed to be large enough for the subsequent call to
fread. After the call we merge the values of the new object
back into the old object if necessary. All values that do not
ﬁt into the original buffer are stored in the out-of-bounds
store.
D. Compiler Optimizations
Most related work introduces compiler optimizations to
reduce the performance overhead. The common goal is to
remove runtime checks from the code. We also use static out-
of-bounds checks. If Boundless can prove at compile time
(using pointer analysis) that a memory access is always in-
bounds, the memory access is not checked at runtime. We do
not use compiler optimizations like, e.g., pool allocation [9].
However, pool allocation is orthogonal to our approach and
can be applied to Boundless, too.
Some common compiler optimizations are targeted at
detection only, fail-stop approaches. Redundant check elim-
ination (RCE) and loop hoisting checks [3] cannot be used
unmodiﬁed for tolerance.
RCE removes redundant checks from the source code.
All checks that are dominated by a check of the same
address can be removed. For example, if a value is loaded,
manipulated, and stored again then the check at the store
operation can be omitted in a fail-stop approach. However,
for tolerance the second check is still needed: if we tolerate
an out-of-bounds pointer on the ﬁrst access, we need to
tolerate again on the second access.
We use dynamic redundant check elimination, i.e., we
decide at runtime whether a check can be skipped. For
each potentially redundant check, we track whether the
dominating check failed. If it failed, the access is redirected
into the out-of-bounds store. Otherwise the check is skipped.
Instead of performing a full bounds check at the redundant
check, we only use a single boolean comparison.
Loop hoisting moves checks out of loops. Again, for
tolerance this approach cannot be used unmodiﬁed. The
argument is the same as for RCE: if we need to tolerate the
access to a memory object in one loop iteration, we might
need to do it in the next iteration, too. Our approach is
similar to how we handle calls to external functions. Before
entering the loop we check whether the memory object
accessed in the loop is large enough. To check the size of the
object, we use the function enforceBufferSize that we
introduced in Section V-C. The memory object returned by
enforceBufferSize is guaranteed to be large enough.
Within the loop we do not need to check for memory errors.
After the loop we merge the buffer with the original memory
object using mergeBuffer if necessary. In order to apply
this approach we need to statically infer symbolic bounds:
At compile time we need to be able to ﬁnd a formula that
allows us to calculate the necessary size at runtime. While
it is theoretically possible to use over-approximation, we
apply loop hoisting only if we can determine exact symbolic
bounds.
VI. AUTOMATIC PATCHING
It
is a good attitude to ﬁx a bug as soon as it
is
detected. However, often it takes considerable time until a
bug is completely ﬁxed. Automatic patching minimizes the
window of vulnerability. It creates patches that are ready for
distribution immediately.
Based on Boundless, we developed an automatic patching
approach that is safe and non-probabilistic. In combination
with automatic patch deployment systems it can be used
in scenarios in which full tolerance is too costly. Patching
offers a huge potential to decrease performance overhead:
usually only a very small subset of the code needs to be
instrumented.
Figure 6 illustrates our patching approach. We start with
a fully instrumented binary, which tolerates arbitrary spatial
memory errors. Whenever an error is tolerated, we add an
entry to an error log. The entry contains the instruction
which caused the memory error. Additionally, we log the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:46:38 UTC from IEEE Xplore.  Restrictions apply. 
20for memory bandwidth can be especially efﬁcient for all
applications with high memory load in Section VII-E.
Setup: All measurement are gathered on a 8-core
machine with Intel Xeon E5430 processors running at 2.66
GHz. The machine is equipped with 16 GB of main memory.
We use Fedora 10 as operating system. We report
the
trimmed mean (trimmed by 20%) of 10 measurements.
We measured the runtime using the time command. All
binaries are compiled using LLVM version 2.5.
A. Performance
We measured the performance slowdown caused by
Boundless for the Olden [21] and STAMP [20] benchmarks.
We used the Olden benchmarks to facilitate easy comparison
with related work [2, 3, 9]. We used the STAMP benchmarks
because they are CPU and memory intensive. For STAMP
benchmarks we used the provided non-simulation workload.
For the Olden benchmarks we used workloads at least as
large as the largest documented workload. For some Olden
benchmarks we increased the workload to get reasonable
long execution times. Figure 7 compares the slowdown of
Boundless with the slowdown caused by SoftBound. The
slowdown is calculated as the runtime of the instrumented
benchmark relative to the runtime of the uninstrumented
benchmark.
We used version 1.1.1 of SoftBound. Our measurements
deviate from those in [2]. Most notably, SoftBound reports
non-deterministic out-of-bounds accesses for some bench-
marks (intruder, yada, bh, and em3d). SoftBound detects
a false positive for bayes, because qsort is not handled
correctly (cf. Section II-D). Furthermore, SoftBound reports
a false positive for labyrinth because of unsupported inte-
ger arithmetic (cf. Section IV-B). For vacation SoftBound
crashes at compile time. Finally, treeadd produces wrong
output after being instrumented by SoftBound. Therefore,
we exclude the measurements of SoftBound with these
benchmarks from Figure 7.
For the STAMP benchmarks Boundless exhibits an aver-
age runtime slowdown of 2.55 (arithmetic mean) as shown
in Figure 7(a). The smallest slowdown is present at intruder
(1.23). The largest is caused by ssca2 (4.2). Boundless has
a average slowdown of 1.65 for the Olden benchmarks. The
largest is present at bh (2.26). Treeadd has the smallest
slowdown (1.35). For all Olden benchmarks except power,
Boundless exhibits a smaller overhead than SoftBound. Note
that we not only detect memory errors but we also tolerate
them. Our mean runtime overhead is 23.9% smaller than
SoftBound’s.
B. Memory Error Tolerance
In order to test the effectiveness of Boundless to guard
against memory errors, we applied Boundless to 5 differ-
ent applications containing memory errors (Table I). We
took gzip, polymorph, and squid from the BugBench
Figure 6.
instrumented binary.
The automatic patching process uses error logs of a fully
allocation site of the object the instruction operates on. For
memory objects on the heap or on the stack the allocation
site is the LLVM IR instruction that allocated the object.
Note that LLVM allocates every stack variable with an
explicit instruction. For objects in the data segment we use
the declaration as allocation site.
In order to distinguish between different allocation sites
we assign a unique 8 byte identiﬁer to each site at compile
time. When an object is allocated at runtime, we pad the
allocation with 8 bytes and store the identiﬁer into these
bytes. Eight bytes ensures that we can uniquely identify up