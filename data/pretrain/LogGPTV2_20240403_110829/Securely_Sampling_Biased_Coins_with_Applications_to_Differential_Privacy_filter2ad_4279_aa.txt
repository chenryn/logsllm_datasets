title:Securely Sampling Biased Coins with Applications to Differential Privacy
author:Jeffrey Champion and
Abhi Shelat and
Jonathan R. Ullman
Securely Sampling Biased Coins
with Applications to Diﬀerential Privacy
Jeﬀrey Champion1
abhi shelat1
Jonathan Ullman1
1Khoury College of Computer Sciences, Northeastern University
January 6, 2020
Abstract
We design an eﬃcient method for sampling a large batch of d independent coins with a
given bias p ∈ [0, 1]. The folklore secure computation method for doing so requires O(λ+log d)
communication and computation per coin to achieve total statistical diﬀerence 2−λ. We
present an exponential improvement over the folklore method that uses just O(log(λ + log d))
gates per coin when sampling d coins with total statistical diﬀerence 2−λ. We present a
variant of our work that also concretely beats the folklore method for λ ≥ 60 which are
parameters that are often used in practice. Our new technique relies on using specially
designed oblivious data structures to achieve biased coin samples that take an expected 2
random bits to sample.
Using our new sampling technique, we present an implementation of the diﬀerentially
private report-noisy-max mechanism [BLST10] (a more practical implementation of the cele-
brated exponential mechanism [MT07]) as a secure multi-party computation. Our benchmarks
show that one can run this mechanism on a domain of size d = 212 in 6 seconds and up to
d = 219 in 14 minutes. As far as we know, this is the ﬁrst complete distributed implementation
of either of these mechanisms.
1 Introduction
This paper presents asymptotically and concretely superior secure computation methods
for sampling a batch of d coins with bias p ∈ [0, 1]. The problem of sampling biased coins
plays a fundamental role in implementing many randomized algorithms, in running Monte Carlo
simulations, and in producing diﬀerentially private data summaries. Furthermore, as explained
in [DKM+06], the tasks of sampling from binomial, Poisson, Laplace, or geometric distributions
can all be reduced to the task of sampling biased coins. Thus, we consider this task an essential
primitive in the area of secure computation.
Biased Sampling with (and without) Secure Computation. In order to explain our
contributions, we provide some background on methods for sampling biased coins and their
complexity. If we are willing to sample “in the clear,” then the folklore method for sampling a
coin with bias p is to ﬁrst sample a uniform number r ∈ [0, 1] and then output heads if r ≤ p
and tails otherwise. A na¨ıve implementation of this ﬁrst method that achieves error at most 2−λ
is to sample r discretely in the following way: ﬂip λ fair coins, interpret these coins as the binary
expansion of r, and perform the comparison. A downside of this method is that it ﬂips λ coins
1
to sample one biased coin, and thus the running time is at least Ω(λ). One can address this issue
using the following lazy ﬂipping strategy: ﬂip the ﬁrst coin and compare against the ﬁrst digit in
the binary expansion of p, if the digits diﬀer than a decision can be made, and otherwise, the
process is repeated with a fresh coin and the next digit of the expansion. A simple calculation
shows that lazy ﬂipping requires just 2 coins and O(1) time in expectation, regardless of λ!
Thus, sampling biased coins “in-the-clear” is essentially solved in a Turing-machine model of
computation. In this work we focus on achieving complexity similar to the lazy ﬂipping method
but in a secure computation.
Unfortunately, the lazy ﬂipping method cannot be easily implemented in a two- or multi-party
secure computation. Recall that the goal of Secure Multi-Party Computation is to allow a set
of parties P1, . . . , Pn to securely evaluate a function y = f (x1, . . . , xn), where each Pi provides
input xi. Here securely evaluating a function means computing the function jointly in such a
way that no Pi learns anything other than what is revealed by the output y and their own input
xi. In particular, each Pi must not learn xj for i (cid:54)= j, nor any intermediate value derived from
xj during the computation of f . To achieve this property, implementing an MPC version of an
algorithm usually requires that all parts of the algorithm be converted into static circuits. This
means that loops for example cannot stop early, since the stopping time may reveal something
about the inputs.
Since the lazy ﬂipping method implicitly leaks the number of fair coins that were ﬂipped, it
cannot be directly implemented as a secure computation while preserving its eﬃciency. Speciﬁcally,
if we transform the algorithm to a binary circuit, the circuit that samples r must have size
proportional to the worst case where all λ bits are compared against the binary expansion of
p. Thus a secure computation for the folklore sampling mechanisms generally requires λ fair
coins per sample instead of an expected 2. When expressed in terms of boolean gates—which
generically represents the running time and communication complexity of such a protocol—this
requirement leads to O(λ) gates per coin.
A natural approach to overcome this ineﬃciency is to use a secure computation protocol
along with an oblivious RAM data structure, implemented as a circuit, to emulate lazy sampling.
Oblivious RAM data structures, ﬁrst introduced by Goldreich and Ostrovsky [GO96] allow the
implementation of a RAM program while hiding the addresses of the memory locations that
are accessed during the execution. By hiding the memory access pattern, this approach could
allow the lazy sampling of coins that requires only an expected 2 fair coins per sample. However,
to implement one read operation on a memory of size λ, most ORAM data-structures require
polylog(λ) additional read and write memory operations [GO96, LO14, SCSL11, WCS15].
The state of the art in relation to asymptotic complexity is Panorama [PPRY18], which
requires ˜O(log λ) extra operations (albeit with astronomically high constants). However, even
ignoring the large constants, all known ORAM schemes require read operations on machine
words of size log(λ) bits when accessing a memory with λ elements. Since our application only
requires reads of single bits to implement lazy sampling, all of the schemes will incur ˜O(log2 λ)
overhead which is asymptotically worse than our scheme. Ignoring asymptotics, the most recent
practical implementations of ORAM for secure computation [Das17] concretely perform worse
than our approach (and also only support two-party secure computation).
Our Contributions. The ﬁrst main contribution of this paper is to develop a new secure
computation sampling procedure that takes a string of fair coins1 and samples a string of d biased
coins that has statistical distance at most 2−λ from a string of d independent coins with bias
1The fair coins can be obtained securely by taking the xor of fair coins obtained from each party.
2
p, using an amortized O(log(λ + log d)) and gates per coin. This result improves exponentially
over the folklore technique that uses O(λ + log d) gates per coin, and is polynomially better than
schemes that use the state-of-the-art ORAM techniques.
Our main technique is to employ new oblivious data structures that allow us to amortize the
cost of the lazy sampling method by “blurring” when the sampling of one biased coin ends the
the next begins. In §2.1, we describe these two data structures that enable our improvements: an
oblivious push-only stack, and an oblivious pop-only stack with reset. The ﬁrst push-only stack
allows obliviously pushing elements onto a stack. When the stack is full, the data structure
obliviously ignores the operations and does not change the underlying data. The second data
structure allows the opposite—it only supports pop operations, and returns the last element
repeatedly when it is empty. It additionally supports an oblivious reset which returns the stack
to an arbitrary original conﬁguration. Both of these data structures are inspired by the oblivious
stack proposed by Zahur and Evans [ZE13].
Using these data structures, our new sampling method works as follows. We ﬁrst initialize a
pop-only stack with the binary expansion of the bias p. At each step, we pop from the stack
and compare against the next fair coin. We obliviously compare the coins and if they agree, we
make an “empty” oblivious push to the push-only stack, and we simply repeat the procedure
by popping and comparing with the next fresh fair coin. If the two coins disagree, then we can
output a biased coin sample by performing a true oblivious push to the push-only stack and
obliviously resetting the pop-only stack. Thus, each iteration of the loop requires one oblivious
push, one oblivious pop, one oblivious reset, and one comparison. As we show in §2.1, these
operations can all be done in O(log(λ + log d)) gates per coin.
While our method asymptotically beats the standard secure sampling methods, our implemen-
tation eﬀorts2 reported in §5 show that the constant overheads in our careful stack implementation
only beat the standard methods when the statistical parameter λ > 200, i.e., when the sampling
error is set to be quite small. As a second contribution, we show that for larger statistical errors
λ ∈ [60, 512], an alternative method often beats the na¨ıve strategy. In particular, let Cp(·) be a
circuit that on input j produces the jth bit in the binary expansion of bias p. We can replace
the pop-only stack that holds the bits of p used in the method described above by this circuit.
We show that for an appropriate range of λ ∈ [60, 512], it is indeed possible to build such circuits
for any arbitrary bias p. In §5, we utilize circuits that output the ﬁrst 128 bits of any p using at
most 13 and gates. Such a circuit is simply a 7-bit boolean predicate, and Peralta et al. [C¸ TP18]
show that every 6-bit predicate can be computed in at most 6 and gates. Our result follows
from simply muxing the top and bottom halves of the 7-bit predicate truth table. In practice, we
implemented this for many p and found that all of them could in fact be expressed in 11 gates.
However, as the statistical parameter increases, the size of our predicate also increases linearly,
and thus this method eventually becomes more expensive than the pop-only data structure. We
evaluate the cross-over point and determine this to be λ > 512. In all cases, these methods
surpass the na¨ıve sampling circuit at λ ≥ 60. We summarize all (asymptotic) amortized gate
complexities and random coins used to make a single biased coin in Table 1.
Application to Diﬀerential Privacy. As an application of our sampling methods, we give
improved secure multiparty implementations of fundamental algorithms from diﬀerential privacy
[DMNS06]. Diﬀerential privacy is a strong formal model of data privacy tailored to statistical
applications. Intuitively, a randomized algorithm is diﬀerentially private if it does not reveal “too
much” about the data of any one individual. At a high level, these algorithms introduce random
2Our code can be found at https://www.gitlab.com/neucrypt/securely sampling.
3
noise that masks the contribution of one individual, while preserving the overall utility of the
dataset when the number of users is suﬃciently large. Diﬀerential privacy has been the subject
of an enormous body of literature (see e.g. [DR14] for a textbook treatment) and has now been
implemented by companies such as Apple [TVV+17a, TVV+17b] and Google [EPK14, BEM+17]
and statistical agencies such as the U.S. Census Bureau [HMA+17].
The most powerful diﬀerentially private algorithms are designed in a centralized model where
a trusted party collects the data and agrees to publish only the output of the algorithm. In
many industrial applications, this trust assumption is problematic, and so companies have mostly
opted to use the local model [War65, DMNS06, KLN+08], which is essentially a weak model
of information-theoretic secure computation where each party applies a separate diﬀerentially
private algorithm to their own data. Unfortunately the local model severely limits the utility of
the algorithm both in theory [KLN+08, CSS11, DJW13, Ull18] and in practice, often requiring
billions of users to achieve reasonable utility (see e.g. [BEM+17]).
To resolve this tension between the central and local models, the prescient work of Dwork et
al. [DKM+06] posed the question of secure multi-party implementations of diﬀerentially private
algorithms, and gave algorithms for sampling the noise required to implement simple counting
mechanisms. Using our secure sampling methods, we give improved algorithms for sampling the
noise in fundamental diﬀerentially private algorithms.
In particular, as far as we are aware, we give the ﬁrst full secure implementation of the report-
noisy-max mechanism (which is a more practical implementation of the celebrated exponential
mechanism [MT07]). This is a highly versatile mechanism that is the driving force in numerous
applications of diﬀerential privacy (see e.g. [BLST10, BLR13, HLM12, TTZ15] for a tiny sample).
This mechanism is particularly crucial in applications of distributed diﬀerential privacy, as any
implementation of this mechanism in the local model provably suﬀers an exponential loss of
utility [KLN+08, Ull18], even in some of its simplest applications. This application is well suited
to our methods due to its need for many biased coins and because the need to securely take a
maximum makes it more amendable to circuit-based protocols rather than the sorts of tailored
algebraic protocols that have been applied to computing sums (e.g. [RN10, SCR+11, BIK+17]).
Our experiments reported in §5 show that datasets of size 212 up to 219 can easily be handled
in seconds to minutes. These ﬁgures give encouraging evidence that one can process moderate-
sized datasets using the noisy-max mechanism. In our evaluation we consider only the simple
two-party semi-honest model, for which we can achieve reasonable concrete eﬃciency. But since
our main contribution is more eﬃcient circuits, our improvements apply equally to multi-party
and malicious models.
Discussion of Prior Work. The closest prior work is the celebrated result of Dwork et
al. [DKM+06], which presents the idea of using secure computation protocols to implement
diﬀerentially private processing of datasets by the data owners themselves. Indeed, our results
in §3.2 make use of their observation that sampling Poisson and related distributions can be
reduced to sampling several fair coins with diﬀerent biases. Their paper also makes note of the
ineﬃciency of standard sampling, however the approaches that they suggest to overcome the λ
coin bottleneck have very large gate overheads.
Anandan and Clifton [AC15] present a two-party protocol based on homomorphic encryption
to generate a single sample from a Laplace distribution in the presence of a malicious adversary.
Their ﬁrst protocol takes the approach of inverting the CDF and therefore is computationally
expensive and was not implemented. They propose a second cut-and-choose style protocol that
oﬀers only polynomial security and report that 500 samples can be generated in 9 seconds.
4
Several prior works present tailored MPC protocols for speciﬁc diﬀerentially private algo-
rithms. The problem of computing a diﬀerentially private sum was ﬁrst considered by Dwork et
al. [DKM+06] and has many follow-up works [BNO08, SCR+11, CRFG12, BDG+13, EKM+14].
Shi et al. [SCR+11] also present a DP mechanism for computing sums that uses a single round,
allows users to drop out, but does not match the accuracy achievable in the central model,
and require a trusted setup phase. Pettai and Laud [PL15] use the sharemind MPC system
to report on another implementation of the sum-and-aggregate mechanism for diﬀerentially
private processing of counts, averages, medians, etc. These mechanisms are much simpler than
report-noisy-max.
Eigner et al. [EKM+14] present PrivaDA as an architecture for distributed diﬀerential privacy
that uses secure computation on ﬂoating point arithmetic to compute the distributed Laplace, the
distributed discrete Laplace, and the distributed exponential mechanism. Their main technical
contribution is to explain how to handle ﬂoating-point arithmetic, exponentiation and logarithm
functions in secure computation, as well as converting between integer and ﬂoating representations.
These operations are extremely complicated as secure computations; their experimental results
for computing a single logarithm take 10s of seconds. In comparison, we are able to sample
roughly 8000 geometric samples in the same time. As a result of these costs, they were unable to
implement any full DP mechanisms. More concerning, Mironov [Mir12] shows the hazards of
using ﬂoating point approximations in diﬀerential privacy applications.
Several works have shown the necessity of secure computation (i.e. oblivious transfer) to
achieve optimal accuracy without a trusted aggregator [MPRV09, MMP+10, GMPS13, GKM+16].
Other work has considered securely implementing diﬀerentially private algorithms for gradient
descent [BIK+17], continually monitoring sums [RN10, SCR+11, EKM+14], the private record-
linkage problem [HMFS17], and heavy-hitters [CLSX12].
Algorithm
and Gates
ODO-1 [DKM+06] O((λ + log d)2 log d)
ODO-2 [DKM+06] O(λ + log d)
ODO-3 [DKM+06] O(d(λ + log d))
ODO-4 [DKM+06] O((λ + log d) log(λ + d))
Random Bits
2
O(λ + log d)
2
2
MNM-1
MNM-2
O(log(λ + log d))
O((λ + log d) log(λ + log d))
2
2
Table 1: Amortized O(·) cost per biased coin. The amortization is over d coins in total. We
denote λ as the total statistical error for d coins. ODO-1, ODO-2, ODO-3, and ODO-4 are
from [DKM+06] in the order they appear in that work starting at section 4.3. ODO-2 is the
algorithm we implement due to its simplicity and low gate count. MNM refers to our coin ﬂipping
algorithm, and our numbering is 1 for the algorithm with asymptotic improvements and 2 for
the algorithm used in practice.
2 Securely Flipping Many Coins of the Same Bias
The fundamental problem we solve in this paper is to design a boolean circuit C(d, p; λ) that can
sample d coins of a bias p eﬃciently in both gates, communication, and number of random input
5
bits required to perform the sampling with overall statistical diﬀerence 2−λ. The na¨ıve circuit
described in the introduction C0(d, p; λ) has amortized gate count |C0(d, p; λ)| = O(log d + λ).
Our circuit Cmnm-1(d, p; λ) reduces this complexity to O(log(log d + λ)) by taking advantage of
the expected two random bits needed per biased coin. Our algorithm does this by ending every
comparison when the ﬁrst diﬀerence in the p bias and stream of unbiased bits occurs. Informally,
doing this privately requires the following functionalities:
1. Sequential production of p’s binary expansion