

Fig. 2. IC Development Process. As ICs have become increasingly complex, both the reuse of 3rd party IP and the size of design teams has increased [3].

		
 
the HDL into a gate-level netlist (also described using HDL)
targeting a speciÔ¨Åc process technology, a process analogous
to software compilation. After synthesis, designers lay out the
circuit components (i.e., logic gates) on a 3-dimensional grid
and route wires between them to connect the entire circuit.
CAD tools encode the physical layout in a Graphics Database
System II (GDSII) format, which is then sent to the fabrication
facility. Finally, the foundry fabricates the IC, and returns it
to the designers who test and package it for mounting onto
a printed circuit board. HDL-level Trojans inserted at design
time compromise the Ô¨Ånal chip‚Äîeven if the tools, back-end
design, and fabrication are secure.
B. Hardware Trojans
Hardware Trojans are malicious modiÔ¨Åcations to a hardware
design for the purpose of modifying the design‚Äôs behavior.
In Fig. 3 we adopt a hardware Trojan taxonomy that makes
characterizations according to 1) where in the IC development
process (Fig. 2) they are inserted, and 2) their architec-
tures [25], [26]. SpeciÔ¨Åcally, hardware Trojans can be inserted
at design time [7], [11], [13], [27], at fabrication time [28]‚Äì
[30], or during packaging/deployment [31]. In this paper, we
focus on design-time Trojans, speciÔ¨Åcally Trojans inserted
during front-end (i.e., HDL) design.
Hardware Trojans are comprised of two main components:
a trigger and payload [32]‚Äì[34]. The trigger initiates the
delivery of the payload upon reaching an activation state. It
enables the Trojan to remain dormant under normal operation,
e.g., during functional veriÔ¨Åcation and post-fabrication testing.
Conversely, the payload waits for a signal from the trigger to
alter the state of the victim circuit. Given the focus of this
work is identifying a speciÔ¨Åc class of Trojans deÔ¨Åned by their
trigger, we further classify Trojans accordingly.
There are two main types of triggers: always-on and initially
dormant. As their names suggest, always-on triggers indicate
a triggerless Trojan that is always activated, and are thus
trivial to detect during testing. Always-on triggers represent an
extreme in a trigger design trade-space‚Äînot implementing a
trigger reduces the overall Trojan footprint at the cost of sacri-
Ô¨Åcing stealth. Alternatively, initially dormant triggers activate
when a signal within the design, or an input to the design,
changes as a function of normal, yet rare, operation, ideally
inÔ¨Çuenced by an attacker. initially dormant triggers enable
stealthy, controllable, and generalizable hardware Trojans. As
prior work shows, it is most advantageous for attackers to
be able to construct triggers that hide their Trojan payloads




























	





	





		
				
Fig. 3. Taxonomy of Hardware Trojans. Hardware Trojans are malicious
modiÔ¨Åcations to a hardware design that alter its functionality. We focus on
time-based Trojans (TTTs) and categorize them by design and behavior.
to evade detection during testing [8]‚Äì[10], [13], [22], so we
focus on initially dormant triggers.
Initially dormant
triggers consist of two sub-categories:
data-based and time-based [11], [13], [22]. Data-based trig-
gers, or cheat codes, wait to recognize a single data value
(single-shot) or a sequence of data values to activate. Alter-
natively, time-based triggers, or ticking timebombs, become
increasingly more likely to activate the more time has passed
since a system reset. While, ticking timebombs can implement
a indirect and probabalistic notion of time (¬ßIV), a simple
ticking timebomb trigger is a periodic up-counter, where every
clock cycle the counter increments, as shown in Fig. 4A. In
this work, we eliminate the threat of TTTs to force attackers
to implement data-based Trojans that require post-deployment
attacker interaction to trigger [11].
III. THREAT MODEL
Our threat model follows that used by prior work on design-
time Trojan attacks and defenses [11], [13], [16], [21], [22],
[35], [36]. SpeciÔ¨Åcally, we focus on malicious modiÔ¨Åcations
that are embedded in in-house, 3rd party, or netlist HDL
(Fig. 2). Our focus, on design-time attacks is driven by current
design trends and economic forces that favor reliance on
untrusted 3rd parties and large design teams [3]. Additionally,
without a trusted HDL design, any result of back-end design
and fabrication cannot be trusted.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:57 UTC from IEEE Xplore.  Restrictions apply. 
972
We assume that a design-time adversary has the ability to
add, remove, and modify the RTL or netlist HDL of the core
design in order to implement hardware Trojans. This can be
done either by a single rogue employee at a hardware design
company, or by entirely rogue design teams. We also assume
an attacker only makes modiÔ¨Åcations that evade detection
during design veriÔ¨Åcation. Thus, no part of the design can
be trusted until vetted by Bomberman and other heuristics-
based tools [8]‚Äì[10]. Like prior work [8]‚Äì[10], [13], [21], [22],
we assume that malicious circuit behavior triggered by Trojan
activation is caught via veriÔ¨Åcation testing.
We focus on identifying TTTs as we deÔ¨Åne them in ¬ßIV.
In doing so, we force attackers to implement data-based
(cheat code) Trojans, which require large state machines to
achieve stealth during design veriÔ¨Åcation [14], [15], sub-
sequently making them detectable post-fabrication via side
channels [37]‚Äì[43]. Moreover, data-based Trojans have limited
deployability‚Äîe.g., they cannot target air-gapped machines‚Äî
since they require post-deployment attacker interaction [11].
Our defense can be deployed at any point throughout the
front-end design process‚Äîi.e., directly verifying 3rd party IP,
after RTL design, or after synthesis‚Äîafter which the design
is trusted to be free of TTTs.




















#



"

 
   




    

   "


#
!
 

Fig. 4. Ticking Timebomb Trigger Behaviors. There are four primitive
ticking timebomb trigger counting behaviors, in order of increasing com-
plexity, captured by our deÔ¨Ånition (Properties 1 & 2 in ¬ßIV-A). A) The
simplest counting behavior is both periodic and uniform. Alternatively, more
sophisticated counting behaviors are achieved by: B) encrypting the count to
make the sequence non-uniform, C) incrementing it sporadically, or D) both.
clever attacker may choose to hide the monotonically increas-
ing behavior of a periodic up-counter by either 1) obscur-
ing the relationship between successive counter values (e.g.,
AES counter mode sequence, Fig. 4B), or 2) sporadically
incrementing the counter (e.g., a non-deterministic TTTs [22],
Fig. 4). Even more sophisticated, the attacker may choose to
do both (Fig. 4D).
IV. TICKING TIMEBOMB TRIGGERS
B. TTT Components
First, we deÔ¨Åne TTTs by their behavior. Based on this
deÔ¨Ånition, we synthesize the fundamental components required
to implement a TTT in hardware. Finally, using these fun-
damental components we enumerate six total TTT variants,
including previously contrived TTTs that resemble contiguous
time counters [11], [13], to more complex, distributed, non-
uniform, and sporadic [21], [22] designs.
A. DeÔ¨Ånition
We deÔ¨Åne TTTs as the set of hardware Trojans that im-
plement a time-based trigger that monotonically approaches
activation as the victim circuit continuously operates without
reset. More succinctly, we deÔ¨Åne a ticking timebomb trigger
based on two properties of the values it exhibits while still
dormant yet monotonically approaching activation:
Property 1: The TTT does NOT repeat a value without a
Property 2: The TTT does NOT enumerate all possible val-
system reset.
ues without activating.
Property 1 holds by deÔ¨Ånition, since, if a TTT trigger repeats
a value in its sequence, it is no longer a ticking timebomb, but
rather a data-based ‚Äúcheat code‚Äù trigger [11], [13]. Property 2
holds by contradiction in that, if a TTT trigger enumerates all
possible values without triggering, i.e., no malicious circuit
behavior is observed, then the device is not malicious, and
therefore not part of a TTT. Upon these two properties, we
derive the fundamental hardware building blocks of a TTT.
Figs. 4A‚ÄìD illustrate example ticking timebomb behaviors
that are captured by our deÔ¨Ånition, in order of increasing
complexity. The most naive example of a ticking timebomb
trigger is a simple periodic up-counter. While effective, a
From our deÔ¨Ånition, we derive the fundamental components
required to implement a TTT in hardware. Fig. 1 depicts these
components. For TTTs to exhibit the behaviors summarized
in Fig. 4, they must implement the notion of an abstract time
counter. TTT time counters require three components to be
realized in hardware: 1) State-Saving Components (SSCs),
2) increment value, and 3) increment event.
The SSC deÔ¨Ånes how the TTT saves and tracks the trigger-
ing state of the time counter. SSCs can be either coalesced
or distributed. Coalesced SSCs are comprised of one N-bit
register, while distributed SSCs are comprised of M, N-bit
registers declared across the design. Distributed SSCs have
the advantage of increasing stealth by combining a subset of
one or multiple coalesced SSCs whose count behaviors indi-
vidually violate the deÔ¨Ånition of a TTT trigger (i.e., Properties
1 and 2), but when considered together comprise a valid TTT.
Distributed SSCs can also reduce hardware overhead through
reuse of existing registers.
The TTT increment value deÔ¨Ånes how the time counter is
incremented upon an increment event. The increment value
can be uniform or non-uniform. Uniform increments are hard-
coded values in the design that do not change over time, e.g.,
incrementing by one at every increment event. Non-uniform
increments change depending on device state and operation,
e.g.,
incrementing by the least-signiÔ¨Åcant four bits of the
program counter at every increment event.
Lastly, the TTT increment event determines when the time
counter‚Äôs value is incremented. Increment events may be
periodic or sporadic. For example, the rising edge of the clock
is periodic, while the rising edge of an interrupt is sporadic.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:57 UTC from IEEE Xplore.  Restrictions apply. 
973
C. TTT Variants
From the behavior of the fundamental TTT components,
we extrapolate six TTT variants that represent the TTT design
space as we deÔ¨Åne. We start by grouping TTTs according
to their SSC construction. Depending on their sophistication
level,
the attacker may choose to implement a simplistic
coalesced TTT, or construct a larger, more complex, dis-
tributed TTT. If the attacker chooses to implement a coalesced
TTT, they have four variants to choose from, with respect to
increment uniformity and periodicity. The most naive attacker
may choose to implement a coalesced TTT with uniform
increment values and periodic increment events. To make the
coalesced TTT more difÔ¨Åcult to identify, the attacker may
choose to implement non-uniform increment values and/or
sporadic increment events.
To increase stealth, an attacker may choose to combine two
or more coalesced TTTs, that alone violate the deÔ¨Ånition of
being a TTT trigger, but combined construct a valid distributed
TTT. An attacker has two design choices for distributed TTTs.
Seeking to maximize stealth,
the attacker may choose to
combine several copies of the same coalesced TTT with non-
uniform increment values and sporadic increment events, thus
implementing a homogeneous distributed TTT. Alternatively,
the attacker may seek integration Ô¨Çexibility, and choose to
combine various coalesced TTTs to implement a heteroge-
neous distributed TTT. For homogeneous distributed TTTs,
an attacker has the same four design choices as in coalesced
TTTs. However, for heterogeneous distributed TTTs, the de-
sign space is much larger. SpeciÔ¨Åcally, the number of sub-
categories of heterogeneous distributed TTTs can be computed
n
, with n, the number of
using the binomial expansion,
k
coalesced sub-triggers, and k,
the number of unique sub-
trigger types. We summarize all six TTT variants and their
behaviors in Figs. 3 and 4, respectively, and provide example
implementations in Verilog in Appendix A.
(cid:2)
(cid:3)
V. BOMBERMAN
Now that we have deÔ¨Åned what a TTT is, and how
it behaves, how do we automatically locate them within
complex RTL designs? To address this question, we design
and implement Bomberman, a dynamic Trojan veriÔ¨Åcation
framework.2 To summarize, Bomberman locates potential
TTTs by tracking the sequences expressed by all SSCs in
a design, as SSCs are one of the fundamental building
blocks of TTTs. Initially, Bomberman classiÔ¨Åes all SSCs as
suspicious. Then, any SSCs whose sequence progressions,
recorded during simulation, violate either Properties in ¬ßIV-A,
are marked benign.
Bomberman takes as input 1) a design‚Äôs HDL, and 2) veri-
Ô¨Åcation simulation results, and automatically Ô¨Çags suspicious
2Unfortunately, no commercial veriÔ¨Åcation tool exists to track complex state
that deÔ¨Ånes TTT invariants, i.e., asserting no repeated values or distributed
state exhaustion. Moreover, the closest such tools‚ÄîJasperGold [44] and VC
Formal [45]‚Äîdeploy bounded static analysis approaches that suffer from
state-explosion when applied to such invariants.
 
!%$
"$ "
"$ (	%$ ")
	"&"#()

%$!%$

	
)
$$ 
 "




" $'


*
*

$' &
"!
"$ "



%"$ 




)
##$ 














Fig. 5. Bomberman Architecture. Bomberman is comprised of two stages:
A) SSC IdentiÔ¨Åcation, and B) SSC ClassiÔ¨Åcation. The Ô¨Årst stage (A) identiÔ¨Åes
all coalesced and distributed SSCs in the design. The second stage (B)
starts by assuming all SSCs are suspicious, and marks SSCs as benign as it
processes the values expressed by each SSC during veriÔ¨Åcation simulations.