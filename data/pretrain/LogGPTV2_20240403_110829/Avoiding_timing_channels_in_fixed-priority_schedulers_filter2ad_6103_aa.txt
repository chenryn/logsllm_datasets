title:Avoiding timing channels in fixed-priority schedulers
author:Marcus V&quot;olp and
Claude-Joachim Hamann and
Hermann H&quot;artig
Avoiding Timing Channels in Fixed-Priority Schedulers
Marcus Völp, Claude-Joachim Hamann, Hermann Härtig
{voelp, hamann, haertig}@os.inf.tu-dresden.de
Technische Universität Dresden
Department of Computer Science
01062 Dresden
ABSTRACT
A practically feasible modiﬁcation to ﬁxed-priority sched-
ulers allows to avoid timing channels despite threads having
access to precise clocks.
This modiﬁcation is rather simple: we compute at admis-
sion time a static predicate that states whether a thread
may possibly leak information; if such a thread blocks we
switch to the idle thread instead.
We describe the modiﬁed scheduler, provide a mechanical
PVS-based proof of noninterference and show how common
admission algorithms can be reused to give real-time guar-
antees for this modiﬁed scheduler. While providing sim-
ilar isolation guarantees, our approach outperforms time-
partitioning schedulers in terms of achieved real-time guar-
antees.
Categories and Subject Descriptors
D.4.6 [Software]: Operating SystemsSecurity and Protec-
tion[Information ﬂow controls]; D.4.1 [Software]: Operat-
ing SystemsProcess Management[Scheduling]
General Terms
Security, Veriﬁcation
Keywords
real-time, ﬁxed-priority scheduling, security, information ﬂow,
noninterference
1.
INTRODUCTION
We envisage open systems (though we do not restrict our-
selves to) as described in Deng et al. [4], and H¨artig et
al. [7], where not necessarily trustworthy virtualised legacy
operating systems and their applications execute next to
security-sensitive and real-time critical applications on top
of a small microhypervisor. In these systems potentially un-
trusted and malicious legacy code is used even for security
c(cid:13)ACM, (2008). This is the author’s version of the work. It is posted here
by permission of ACM for your personal use. Not for redistribution. The
deﬁnitive version was published in ASIACCS’08, March 18-20
critical operations. Therefore appropriate countermeasures
must be applied to enforce that these systems preserve the
conﬁdentiality of the secret data they process. As an exam-
ple application mix of such systems imagine a nonreal-time
legacy operating system used for compiling and text process-
ing, nonreal-time banking transactions, the bank credentials
of which require protection and real-time network and disk
drivers streaming cryptographic-protected video content to
a real-time video player for display. Naturally, these diﬀer-
ent components get assigned diﬀerent priorities (legacy OS,
bank transaction — low priority, no real-time; drivers, video
— high priority, real-time) and they are classiﬁed into diﬀer-
ent security classes (or levels) to reﬂect their conﬁdentiality
requirements (legacy OS, drivers — low security level, pub-
lic; bank transaction, video — high security level, secret).
This paper is concerned with illegal information ﬂows
through the ﬁxed-priority scheduling subsystem. Precisely,
we investigate how malicious code (e.g., a virus or a Tro-
jan Horse executing inside a virtual machine) can exploit
the scheduling subsystem to illegally transfer information
and how this information leakage can be prevented by mod-
ifying a budget-enforcing ﬁxed-priority scheduler to treat
potentially-leaking blocked threads as if they were ready.
We provide a machine checked proof that this countermea-
sure not only prevents all direct information ﬂows but also
information ﬂows that happen indirectly via components we
trust not to leak information intentionally (like for example,
the cryptographic wrapper connecting the real-time disk and
network drivers with the real-time video player).
Naturally, modifying the scheduler aﬀects which real-time
guarantees can be given. To determine whether a thread
set will meet their real-time requirements under a given
scheduler (i.e., to decide whether they are schedulable), an
admission algorithm is run. For ﬁxed-priority schedulers,
such admission algorithms typically consider blocking times
that may occur for example as a side eﬀect of resource
contention and self-suspension. So, by adjusting blocking
times, we can reuse this large class of acceptance algorithms
that are available for ﬁxed-priority scheduling to determine
whether a thread set is schedulable with our modiﬁed sched-
uler. The thread set may thereby contain real-time threads
and nonreal-time application threads and the virtual CPUs
which are the scheduling entities of virtual machines visible
to the hypervisor.
The remainder of this paper is structured as follows. In
Section 2 we brieﬂy introduce our scheduling model which
supports arbitrary statically created thread sets run on a
budget-enforcing ﬁxed priority scheduler. In particular,
strictly-periodic threads are contained in this model. We in-
vestigate how information ﬂow can occur through alterations
in a thread’s scheduling related behaviour in Section 3 and
present how the scheduler must be modiﬁed to prevent this
illegal information ﬂow in Section 4. A sketch of the nonin-
terference proof for this scheduler is given in Section 5. We
deduce in Section 6 that not only unauthorised information
ﬂow is prevented, but also that our modiﬁcation isolates
threads with no authorised information ﬂows in a timely
fashion. After that we restrict ourselves to strictly-periodic
threads when we discuss how our approach aﬀects real-time
guarantees in Section 7. This restriction is partially lifted in
the discussion on further practical factors in Section 8. Sec-
tion 9 relates our work to other work in the area; Section 10
concludes.
2. BUDGET-ENFORCING
FIXED-PRIORITY SCHEDULING
In classical real-time scheduling systems, threads are typ-
ically executed unconstrained according to their schedul-
ing parameters after a worst-case analysis has been per-
formed. Programming errors or attacks from malicious pro-
grams may, however, cause threads to exceed their worst-
case execution times. Budget-enforcing schedulers are ro-
bust against these attacks.
If in between two releases, a
thread τi has executed for an amount of time equal to its
worst-case execution budget (wcet i) any further execution is
deferred to the next release. Likewise, if blocking is consid-
ered, further execution is deferred to the next release after
a total worst-case budget wct i := wcet i + wcbt i is depleted
where wcbt i is the worst-case blocking time.
Figure 1: Scheduling according to ﬁxed priorities.
During times when τh blocks, the lower prioritised
thread τl may run.
We describe an arbitrary thread τi ∈ T (i = 1, ..., n) of the
thread set T through a possibly inﬁnite sequence of releases.
The kth release (k = 0, 1, ...) is parametrised by a release
point πi,k, the budgets for this release wcet i,k and wct i,k
which get reﬁlled at this release point and a relative deadline
di,k. A real-time thread must have completed its work for
this release latest at πi,k + di,k. Otherwise it is said to miss
this deadline. Execution is deferred if either the budgets
have expired or the deadline has passed.
Examples for releases include the beginning of a period
for periodic threads and the arrival of publicly visible events
such as the arrival of a network package. Because we con-
strain these events to be publicly visible, no information is
leaked due to the fact that a thread is released.
The above model is suﬃcient to express the real-time
properties of a wide range of common real-time thread sets.
For example, strictly-periodic threads are described by an
inﬁnite sequence of equidistant release points (i.e., πi,k+1 −
πi,k = const). In addition, strictly-periodic threads are as-
signed the same worst case budgets in each period. The
events activating aperiodic threads are directly reﬂected by
the releases, provided these are public. Deferred servers can
be described as a sequence of releases where each release de-
scribes the arrival of a thread executed on these servers and
the budget of this release corresponds to the worst case exe-
cution time of this thread. The total budget of the deferred
server in a given period is the sum of the budgets assigned
to the releases in this period. Thread sets consisting of vir-
tual machines that have been assigned a share of processor
times can be mapped to the above model by assigning them
budgets proportional to their share and by releasing all vir-
tual machines at equidistant release points whose distance
corresponds to the sum of assigned budgets. Thread sets
under a time-partitioning scheduler can be mapped by set-
ting the release points to the respective partition begins and
by setting the budgets to their size.
Threads are scheduled in a ﬁxed-priority based manner.
Hence, a priority prioi is a further parameter of a thread τi.
We assume, that the scheduler supports suﬃciently many
priorities so that each two threads are assigned diﬀerent pri-
orities. High-priority threads may preempt lower prioritised
threads at any instant. It is a common approach to disre-
gard context switching overhead or to include it in the worst
case execution time.
Furthermore, threads may suspend themselves (e.g., when
waiting for I/O completion in a blocking systemcall) and
temporarily disable preemptions (e.g., during critical sec-
tions). Otherwise, threads are assumed to be independent,
that is, there are no temporal precedence constraints.
In
Section 7f, we show how these restrictions can partially be
lifted and investigate in detail blocking due to self suspen-
sion (Section 7.1), blocking due to nonpreemptibility (Sec-
tion 7.2), resources (Section 8.1) and precedence constraints
(Sections 8.2) for strictly-periodic thread sets. In addition,
we will investigate how real-time guarantees are preserved
for aperiodic and sporadic threads in Section 8.3.
A thread may be in one of the following four commonly-
used states:
running the thread is assigned a processor and is executing
ready the thread is not executing but ready for execution
(it has all required resources with the exception of a
processor)
blocked the thread has suspended itself and waits for some
external event or for some signal from another thread
inactive the thread budgets have been depleted respective-
ly the deadline has passed. A thread is inactive until
its next release point. At this time, its worst case
budgets get reﬁlled to the budgets of this release.
In addition to these states, we deﬁne the term active
to denote a thread which is not inactive, i.e., which has a
positive remaining worst case budget. Such a thread may
lτhτrelease pointdeadline (absolute)hτhτhτpriorityactiveinactivewct0time0l,0l,1dl,0etet’btwct = wcet + wcbtet +  et’     wcetbt    wcbt≤≤ππbe running, ready, blocked or it may have completed its
execution in its current release without having exhausted
its budgets. In this latter case, the thread remains active
until an amount of time equal to the remaining budget has
passed. A thread which has not consumed its worst case
budgets for a given release we say has stopped early.
Throughout the paper, τh denotes a high prioritised thread
and τl denotes a low (or lower than τh) prioritised thread.
We write prio(τh) > prio(τl) despite of the numerical val-
ues of the priorities. Furthermore, let Thigh (τ ) and Tlow (τ )
be the set of threads with higher respectively lower prior-
ity than τ . We write TP,high for the set of threads in Thigh
which in addition fulﬁl a given predicate on threads P (re-
spectively TP,low for threads in Tlow ). Figure 1 illustrates
the introduced notions.
3.
INFORMATION FLOW
Obviously, higher prioritised threads can directly inﬂuence
when and for how long lower prioritised threads run. When
a higher prioritised thread τh blocks, the scheduler will select
a lower prioritised thread τl; when it executes this selection
will be deferred until τh blocks or its budget is depleted
(see Foss et al. [25] for a more detailed analysis describing
which information can be deduced in rate-monotonic sched-
uling). In the presence of legitimate communication between
threads, indirect inﬂuences become possible by directly in-
ﬂuencing a sender which in turn relays timing information
in its messages. In Section 3.2, we investigate this indirect
inﬂuence in detail.
The actions leading to direct or indirect inﬂuences we call
run — the thread executes some code — and block — the
thread has invoked some blocking systemcall.
Before deﬁning the noninterference property let us clarify
our security-related assumptions.
1. The scheduling parameters, the scheduling algorithm
and therefore the resulting schedule are public infor-
mation. In particular, the events which trigger releases
must be publicly visible.
2. All threads have access to precise clocks. 1
Note it is still possible to hide the existence of threads
by scheduling them hierarchically (see e.g., [18]) on top of
a thread that is visible in the public schedule. Note fur-
ther that hierarchical scheduling is a means of supporting
dynamic thread creation, a functionality which is not per se
supported by our approach. Other means to create threads
dynamically are discussed in the course of this paper.
3.1 Noninterference
Noninterference [19] characterises the absence of illegal in-
formation ﬂows through a system, in our case the scheduling
subsystem. Suppose no information may ﬂow from a thread
τ to a thread τ0 via the scheduling system S. We qualify
1The authors are aware that fuzzy time [5] successfully re-
duces the bandwidth of scheduling-related covert channels.
We maintain this assumption for two reasons: Firstly, the se-
lected noninterference property cannot be proven while some
information is leaked over a covert channel. Secondly, some
real-time applications require precise time stamps and pre-
cisely triggered events. Precise clocks are a precondition for
both unless dedicated hardware is available for this purpose
(e.g., capture-compare units).
this by asserting that what τ0 can observe about S remains
unchanged despite diﬀering behaviour (i.e., diﬀering action
sequences) of τ .
More formally, we deﬁne an information-ﬂow policy as a
triple (C,≤, dom) where (C,≤) is a bounded lattice over the
ﬁnite set of domains (or security classes) C, ≤ is a partial
order on security levels. In particular, ≤ is transitive. dom :
T → C is a function, which assigns each thread τ ∈ T a
security class c ∈ C.
Information may ﬂow from τ0 to τ
provided dom(τ0) ≤ dom(τ ). We write dom(τ ) (cid:2) dom(τ0)
to denote that no such information ﬂow may happen (thus,
(cid:2) is the complement of ≤). > ∈ C denotes the top (or
greatest) element of the lattice (C,≤), that is, ∀c ∈ C. c ≤ >
holds (analogously, ⊥ denotes the bottom element).
Given access to a precise clock, a thread τ may observe
the precise points in time when it gets selected by the sched-
uler. In addition, it may learn through messages about the
points in time when other threads τ0 run, provided τ may
legitimately receive messages from these threads.
Following Rushby [19], we can now formally deﬁne our
noninterference property:
Deﬁnition 1. Noninterference.
Let output(S)(τ, t) be a function which returns for each
point in time t the thread τ0 that was selected by the sched-
uler to run at t, provided that τ may receive from τ0 (i.e.,
provided dom(τ0) ≤ dom(τ )) and which otherwise returns
the special symbol − /∈ T . (We will give a precise formal
deﬁnition of this function in Section 5.) Let purge(S)(τ ) be
a function which removes from S all the actions — though
not the threads themselves — of those threads τ0 from which
no information must ﬂow to τ (i.e., for which dom(τ0) (cid:2)
dom(τ ) holds). Then the scheduling system S is noninter-
ference secure if the following predicate holds at any time
t ∈ N:
noninterference(S ) := ∀τ ∈ T.∀t ∈ N.
output(S)(τ, t) = output(purge(S))(τ, t)
Noninterference states that whatever sequences of actions
higher classiﬁed threads τ0 execute, their behaviour as seen
by τ is identical to a system in which these threads do not
act at all.
Note that for this predicate to hold, actions of these higher
classiﬁed threads may not change the points in time at which
threads with a lower security class than τ execute. Thus,
they may only act during the holes reported by the output
function (i.e., at those points in time when the output func-
tion returns −).
In fact they have to act such, that the
occurrence of holes does not vary over time. Our proposed
modiﬁcation is to treat active, blocked or early stopping
threads that may possibly leak information as if they were
ready. This ensures that during those times when output
returns −, either the original thread runs if an appropriate
run action is contained in its action sequence or the idle
thread runs if the original thread blocks or stops early. In
the latter case, the idle thread, which runs eﬀectively at the