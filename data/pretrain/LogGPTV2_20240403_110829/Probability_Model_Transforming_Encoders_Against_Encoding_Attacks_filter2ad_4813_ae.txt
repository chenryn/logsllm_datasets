For a fair comparison, we use the same datasets as the pre-
vious literature [10, 14, 18]: a password dataset RockYou
and a password vault dataset Pastebin for password vault
schemes [10, 14], real genomic datasets from HapMap [1] for
the genomic data protection scheme [18]. RockYou is a pass-
word dataset widely used in password security research, some
notable ones like [4, 25, 27, 41], which includes 32.6 million
passwords. To the best of our knowledge, Pastebin is the only
publicly available dataset for real password vaults so far, and
it contains 276 real vaults. Because RockYou and Pastebin
are already public and no further harm will be caused, we
believe it is ethical to use them for experiments. Multiple
types of genomic datasets from HapMap are used, including
a diploid genotype dataset, a haploid genotype dataset, allele
frequency (AF) and linkage disequilibrium (LD) datasets, and
recombination rates. The diploid genotype dataset contains
165 persons’ SNV sequences. For other details of the above
datasets, please refer to [10, 18].
6.3 Evaluating Password Vault PMTEs
As shown in Figure 4a and Table 1, in Chatterjee et al.’s
PMTE [10], the average ranks r of real vaults under the feature
USENIX Association
28th USENIX Security Symposium    1583
(a) Chatterjee et al.’s PMTE [10]
(b) Golla et al.’s static PMTE [14]
(c) Golla et al.’s adaptive PMTE [14]
(d) Huang et al.’s PMTEs [18] under the PCA+SVM attack
Figure 4: Rank cumulative distribution functions (RCDFs) F(x) of the existing PMTEs
Table 1: The existing PMTEs under encoding attacks or distribution difference attacks
Application
PMTE/Probability model
Chatterjee et al.’s PMTE [10]
Password vault
Golla et al.’s static PMTE [14]
Golla et al.’s adaptive PMTE [14]
Genomic data
protection [18]
Uniform distribution model
Public LD model
0-th order Markov model
1-st order Markov model
2-nd order Markov model
Recombination model
Attack
KL divergence attack
Feature UR attack
Feature DR attack
Weak encoding attack
Strong encoding attack
KL divergence attack
Feature ED attack
Feature PN attack
Weak encoding attack
Strong encoding attack
KL divergence attack
Feature ED attack
Feature PN attack
Weak encoding attack
Strong encoding attack
PCA+SVM attack
r
α
88.17%
84.86%
73.04%
91.26%
98.56%
51.74%
93.96%
89.97%
97.75%
99.52%
46.42%
94.82%
91.40%
97.99%
99.42%
F−1(1)
F(0)
98.80%
1.82%
11.83%
42.24%
0.36%
15.14%
54.95%
0.00%
26.96%
19.42%
0.36%
8.74%
15.02%
70.55%
1.44%
98.70%
0.00%
48.26%
41.14%
26.23%
6.04%
99.20%
53.28%
10.03%
26.03%
58.20%
2.25%
80.74%
16.12%
0.48%
0.00% 100.00%
53.58%
35.44%
28.69%
5.18%
91.79%
55.74%
8.60%
21.22%
59.02%
2.01%
77.87%
17.22%
0.58%
0.00%
0.00% 100.00% 100.00%
0.20%
0.00% 100.00%
99.39%
0.00%
0.00% 100.00% 100.00%
1.30%
99.39%
0.01%
0.53%
55.76%
23.92%
99.90%
47.88%
23.46%
99.99%
99.47%
76.54%
1584    28th USENIX Security Symposium
USENIX Association
KLdivergenceattackFeatureURattackFeatureDRattackWeakencodingattackStrongencodingattackBaseline0.00.20.40.60.81.00.00.20.40.60.81.0KLdivergenceattackFeatureEDattackFeaturePNattackWeakencodingattackStrongencodingattackBaseline0.00.20.40.60.81.00.00.20.40.60.81.0KLdivergenceattackFeatureEDattackFeaturePNattackWeakencodingattackStrongencodingattackBaseline0.00.20.40.60.81.00.00.20.40.60.81.0UniformdistributionmodelPublicLDmodel0-thorderMarkovmodel1-storderMarkovmodel2-ndorderMarkovmodelRecombinationmodelBaseline0.00.20.40.60.81.00.00.20.40.60.81.0UR attack and the feature DR attack are 15.14% and 26.96%
respectively, the accuracies α are 84.86% and 73.04%. More-
over, under the feature UR attack, the max rank (i.e., F−1(1))
is 42.24%; under the feature DR attack, this number is 54.95%.
This means the feature UR attack can exclude at least 57.76%
(i.e., 1− F−1(1)) decoy vaults for every real vault and the
feature DR attack can exclude at least 45.05%. Figures 4b,
4c and Table 1 show the performance of Golla et al.’s static
PMTE and adaptive PMTE [14], the average ranks under the
feature ED attack are 6.04% and 5.18%, while under the fea-
ture PN attack are 10.03% and 8.60%. Further, in Golla et al.’s
static PMTE, the feature ED attack excludes all decoy vaults
for 26.23% (i.e., F(0)) real vaults and meanwhile, it excludes
at least 58.86% decoy vaults for each real vault. F(0) and
1− F−1(1) under the feature PN attack are 53.28% and 0.8%
respectively. In Golla et al.’s adaptive PMTE, these numbers
are 28.69%, 64.56% under the feature ED attack, and 55.74%,
8.21% under the feature PN attack.
Compared to the above feature attacks, the weak encoding
attack has a signiﬁcant improvement, where the average ranks
r of Chatterjee et al.’s PMTE [10] and Golla et al.’s (static
and adaptive) PMTEs [14] are 8.74%, 2.25%, and 2.01% re-
spectively. The excluded proportions 1− F−1(1) are 80.58%,
78.78%, and 73.97%. The strong encoding attack has a fur-
ther signiﬁcant improvement compared to the weak encoding
attack. The average ranks r of these three PMTEs are 1.44%,
0.48%, and 0.57% respectively, which decrease by 84.99%,
83.88%, and 82.78% . Excluded proportions 1− F−1(1) are
84.99%, 83.88%, and 82.78% respectively, which also slightly
increase by 5.47%, 13.40%, and 5.08%.
Because the KL divergence attack performs better than
SVM attacks on all existing PMTEs for password vaults [14],
we use it for comparison. As shown in Figures 4a, 4b, 4c
and Table 1, the KL divergence attack performs well on the
Chatterjee et al.’s PMTE [10], achieving 88.17% accuracy, but
it performs almost the same as the randomly guessing attack
on Golla et al.’s PMTEs [14], only achieving 46.42%–51.74%
accuracy. Further, the RCDFs on Golla et al.’s PMTEs under
the KL divergence attack are close to the baseline (the RCDFs
under the randomly guessing attack).
For all the existing PMTEs, the curves of RCDFs under
the strong encoding attack are all above those under the KL
divergence attack. This means that every metric in Table 1
under the strong encoding attack is better than that of the
KL divergence attack. More speciﬁcally, the average ranks
of these three PMTEs under the KL divergence attack are
11.83%, 48.26%, and 53.58%, the accuracies α are 88.17%,
51.74%, and 46.42%. In contrast, the accuracies of the strong
encoding attack are 98.56%, 99.52%, and 99.43%, which are
11.78%, 92.35%, and 114.20% higher than those of the KL
divergence attack.
In addition, metric values in Table 1 under the KL diver-
gence attack are different from those given in [14], owing to
a couple of reasons: 1) for Chatterjee et al.’s PMTE [10], the
version of NoCrack used by Golla et al. [14] cannot decode
some seeds correctly, therefore have to remedy and reimple-
ment it in the experiments; 2) for Golla et al.’s PMTEs [14],
we set the pseudocount of Markov for Laplace smoothing
as 1, because under this setting the PMTEs achieve the best
security (see Appendix B).
To conclude, the Chatterjee et al.’s PMTE [10] and Golla
et al.’s PMTEs [14] are all vulnerable to encoding attacks;
meanwhile, Golla et al.’s PMTEs [14] are perfectly secure
against the best-reported distribution difference attack.
6.4 Evaluating Genomic Data PMTEs
Different from encoding attacks, the PCA+SVM attack is
a distribution difference attack which needs a training set
consisting of real and decoy data. We randomly pick 83 indi-
vidual’s SNV sequences in the real dataset1, generate a decoy
sequence for each real sequence, and use them to train our
PCA and SVM in the PCA+SVM attack. Then we use remain-
ing 82 individual’s sequences in the real dataset and generate
N (= 999) decoy sequences for each of them as the test set to
compute the RCDF F(x) with the weight function pPCA+SVM.
To avoid the impact of randomness on results, we repeat the
attack 10 times with different random divisions of the real
SNV sequences and newly generated decoy sequences for
training/testing, and calculate the average of F(x).
As shown in Figure 4d and Table 1, the PCA+SVM at-
tack achieves more than 99.47% accuracy for all probability
models except the recombination model. Even for the recom-
bination model, this attack achieves 76.54% accuracy. This
is consistent with Huang et al.’s result [18] that the recom-
bination model performs best. However, it still falls short of
the desired security, as our attack excludes all decoy data for
47.88% persons.
To summarize, Huang et al.’s PMTEs for all six models [18]
resist encoding attacks but none of them can resist distribution
difference attacks. Even the recombination model cannot be
rejected at the signiﬁcance level of 0.2. This means the chi-
square goodness-of-ﬁt test is unable to correctly evaluate the
security of probability models for generating decoy data.
6.5 Evaluating IS-PMTEs
As stated in Section 5.4, IS-PMTEs resist any encoding at-
tack in theory, we conﬁrm that in practice with IS-PMTEs
transformed from existing password vault models. Formally,
Theorem 5 demonstrates that the IS-PMTE of an accurate
GPM resists arbitrary attacks including encoding attacks. In
fact, the IS-PMTE for an arbitrary GPM resists the weak en-
coding attack. The weight function of the weak encoding
attack is constant because every generating path has a chance
to be chosen when encoding. This means the weak encoding
1We use the small dataset published with the code of GenoGuard on
GitHub, which includes 165 persons’ SNV sequences of length 1000.
USENIX Association
28th USENIX Security Symposium    1585
from the existing GPMs have a signiﬁcant improvement on
security. As shown in Figure 5 and Table 2, all RCDFs of the
IS-PMTEs under the strong encoding attack are approaching
to the baseline, i.e., the RCDF under the randomly guessing
attack. Average ranks r are all near to the expected value of
50%, which are 47.44%, 53.62%, and 54.25%, respectively.
Meanwhile, the accuracies are 52.56%, 46.38%, and 45.75%,
respectively. Recall that accuracies of existing PMTEs under
the strong encoding attacks are 98.56%, 99.52%, and 99.42%,
respectively.
Note that our IS-PMTEs have the same decoy message
distributions with the corresponding GPMs. This means our
IS-PMTEs achieve the same security as the existing PMTEs
for the same GPMs under distribution difference attacks. Due
to the good performance of Golla et al.’s PMTEs [14] against
the best-reported distribution difference attack, our IS-PMTEs
for Golla et al.’s GPMs achieve the expected security under
both encoding attacks and distribution difference attacks.
7 Conclusion
With encoding attacks and distribution difference attacks, we
evaluate three typical existing PMTEs, including two for pass-
word vaults and one for genomic data. Using a PCA and an
SVM, a distribution difference attack can distinguish real and
decoy genomic data with high accuracy. Different from dis-
tribution difference attacks exploiting the difference between
real and decoy message distributions, encoding attacks are a
new type of attack we propose, which exploit the difference
between probability models and PMTEs. Encoding attacks
can exclude most decoy password vaults/seeds, without any
knowledge of real vault distributions.
Further, we introduce a generic conceptual probability
model—generative probability model (GPM)—to formalize
probability models. With the formalization by GPMs, the prin-