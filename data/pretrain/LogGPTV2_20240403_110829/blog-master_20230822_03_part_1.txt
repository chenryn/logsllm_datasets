## 沉浸式学习PostgreSQL|PolarDB 2: 电商高并发秒杀业务、跨境电商高并发队列消费业务  
### 作者          
digoal          
### 日期          
2023-08-22        
### 标签          
PostgreSQL , PolarDB , 数据库 , 教学       
----          
## 背景      
非常欢迎数据库用户提出场景给我, 在此[issue](https://github.com/digoal/blog/issues/121)回复即可, 一起来建设沉浸式数据库学习教学素材库, 帮助开发者用好数据库, 提升开发者职业竞争力, 同时为企业降本提效.      
本文的实验可以使用永久免费的阿里云[云起实验室](https://developer.aliyun.com/adc/scenario/exp/f55dbfac77c0467a9d3cd95ff6697a31)来完成.        
如果你本地有docker环境也可以把镜像拉到本地来做实验:      
x86_64机器使用以下docker image:      
- [《amd64 , 使用Dockerfile+docker build制作PolarDB | PostgreSQL 开源docker镜像, 集成大量插件方便学习, 并推送到阿里云镜像服务》](../202307/20230710_03.md)      
Apple Chip机器使用以下docker image:      
- [《arm64 , 使用Dockerfile+docker build制作PolarDB | PostgreSQL 开源docker镜像, 集成大量插件方便学习, 并推送到阿里云镜像服务》](../202308/20230814_02.md)      
## 业务场景1 介绍: 高并发秒杀业务  
秒杀业务在电商中最为常见, 可以抽象成热点记录(行)的高并发更新. 而通常在数据库中最细粒度的锁是行锁, 所以热门商品将会被大量会话涌入, 出现锁等待, 甚至把数据库的会话占满, 导致其他请求无法获得连接产生业务故障.  
### 实现和对比      
创建商品表, 测试扣减库存操作.  
```  
drop table IF EXISTS tbl;  
create unlogged table tbl (   -- 测试使用unlogged table减少redo   
  id int primary key,  -- 商品id  
  cnt int,             -- 库存  
  ts timestamp        -- 修改时间  
);  
```  
插入一条记录, 初始设置20亿库存.    
```  
insert into tbl values (1, 2000000000, now());    
```  
增加实验环境数据库最大连接数  
```  
postgres=# alter system set max_connections =2000;  
ALTER SYSTEM  
docker stop pg  
docker start pg  
docker exec -ti pg bash  
```  
#### 传统方法 设计和实验       
编写测试脚本, 扣件商品id=1的库存.  
```  
vi t1.sql  
update tbl set cnt=cnt-1, ts=now() where id=1;  
```  
使用1920个并发连接进行测试:  
```  
pgbench -M prepared -n -r -f ./t1.sql -P 1 -c 1920 -j 8 -T 120   
```  
结果:  
```  
transaction type: ./t1.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 1920  
number of threads: 8  
duration: 120 s  
number of transactions actually processed: 31875  
latency average = 7729.207 ms  
latency stddev = 15626.227 ms  
initial connection time = 1784.073 ms  
tps = 230.270300 (without initial connection time)  
statement latencies in milliseconds:  
      7722.072  update tbl set cnt=cnt-1, ts=now() where id=1;  
```  
tps: 230.270300  
#### PolarDB|PG新方法1 设计和实验      
使用skip locked跳过被锁的行, 减少冲突等待时长.    
编写测试脚本, 扣件商品id=1的库存.  使用skip locked跳过被锁的行, 减少等待. 如果能返回商品id, 表示更新成功, 如果返回0条记录, 表示没有拿到锁.   
```  
vi t1.sql  
with tmp as (  
  select id from tbl where id=1 for update skip locked  
)  
update tbl set cnt=cnt-1, ts=now() from tmp where tbl.id=tmp.id returning tbl.id;    
```  
使用1920个并发连接进行测试:  
```  
pgbench -M prepared -n -r -f ./t1.sql -P 1 -c 1920 -j 8 -T 120   
```  
结果:  
```  
transaction type: ./t1.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 1920  
number of threads: 8  
duration: 120 s  
number of transactions actually processed: 2847721  
latency average = 77.784 ms  
latency stddev = 138.536 ms  
initial connection time = 1703.949 ms  
tps = 23915.353056 (without initial connection time)  
```  
tps: 23915.353056  
#### PolarDB|PG新方法2 设计和实验      
清理环境垃圾:  
```  
vacuum full tbl;    
```  
编写测试脚本, 扣件商品id=1的库存. 同时使用pg_try_advisory_xact_lock预判是否能拿到商品id=1的锁, 如果能返回商品id, 表示更新成功, 如果返回0条记录, 表示没有拿到锁.  
```  
vi t2.sql  
update tbl set cnt=cnt-1, ts=now() where id=1 and pg_try_advisory_xact_lock(1) returning id;    
```  
使用1920个并发连接进行测试:  
```  
pgbench -M prepared -n -r -f ./t2.sql -P 1 -c 1920 -j 8 -T 120   
```  
结果:   
```  
transaction type: ./t2.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 1920  
number of threads: 8  
duration: 120 s  
number of transactions actually processed: 13917081  
latency average = 12.053 ms  
latency stddev = 30.646 ms  
initial connection time = 1879.213 ms  
tps = 116928.030422 (without initial connection time)  
statement latencies in milliseconds:  
        12.056  update tbl set cnt=cnt-1, ts=now() where id=1 and pg_try_advisory_xact_lock(1) returning id;  
```  
tps: 116928.030422     
#### 对照    
test case | 传统方法 tps | skip locked方法 tps | advisory lock方法 tps | 性能提升倍数    
---|---|---|---|---  
高并发秒杀(热点记录更新) | 230.270300 | 23915.353056 | 116928.030422 | 507.785982    
## 业务场景2 介绍: 高并发队列消费业务    
[《高并发队列处理业务的数据库性能优化 - IO扫描|CPU计算浪费 , 锁冲突 , 垃圾索引扫描浪费》](../202308/20230805_01.md)    
在跨境电商业务中可能涉及这样的场景, 由于有上下游产业链的存在,   
- 1、用户下单后, 上下游厂商会在自己系统中生成一笔订单记录并反馈给对方,   
- 2、在收到反馈订单后, 本地会先缓存反馈的订单记录队列,   
- 3、然后后台再从缓存取出订单并进行处理.    
这个过程的核心流程:   
- 1、高速写入队列、  
- 2、从队列按先后顺序提取并高速处理、  
- 3、从队列清除已处理订单记录.      
如果是高并发的处理, 因为大家都按一个顺序获取, 容易产生热点, 可能遇到取出队列遇到锁冲突瓶颈、IO扫描浪费、CPU计算浪费的瓶颈. 以及在清除已处理订单后, 索引版本未及时清理导致的回表版本判断带来的IO浪费和CPU运算浪费瓶颈等.    
- 文末的《打车与宇宙大爆炸的关系》一文有相似问题和优化方法, 思路类似.    
接下来的实验将给出“队列处理业务的数据库性能优化”优化方法和demo演示. 性能提升10到20倍.      
### 实现和对比      
1、上游写入订单处理队列表    