So if the ratio ∥ ⃗w∥/GH(L) is relatively small, ⃗w may be
relatively short.
While in the actual experiments, we need to adjust the
value of δ so that ⃗w is within the ability of the lattice reduc-
tion algorithm. In [9], Gamma and Nguyen gave a picture of
the actual behavior of lattice reduction algorithms by exper-
iments. For example, the length of the (cid:12)rst vector output
by the reduction algorithm BKZ with blocksize 20 is ap-
proximately (1.0128)n|L|1=n. So we choose the value of δ
such that the length of target vector ∥ ⃗w∥ ≈ (1.0128)n|L|1=n
and make a little adjustment to it to increase the success
probability if we use BKZ-20.
Note that if the dimension of the lattice is very low(6 70),
we need not to consider the ability of the lattice reduction
algorithm, since it behaves just like a SVP solver [9].
3.3 Analysis of the Basic Attack
Assume our attack is applied to the curve secp256k1.
According to Section 3.1, we can obtain on average 105.8 bits
of information per signature. So in theory, three signatures
would be enough to recover the 256-bit secret key.
We mount the attack with signatures being 3 to 7 sepa-
rately using the BKZ-20 algorithm, but the results turn out
to be very disappointing. Neither three signatures nor four
signatures can succeed. For (cid:12)ve signatures, we only succeed
once among 100 times of attacks, i.e., the success probability
1509q
ru
δ/q
δ/2(cid:22)1;1
q
r1
ρ1;1
...
ρ1;l1
. . .
. . .
. . .
β1
. . .
M =
ρu;1
...
ρu;lu
βu
(5)
. . .
δ/2(cid:22)1;l1
. . .
δ/2(cid:22)u;1
. . .
δ/2(cid:22)u;lu
δ/2
δ/2
. . .
δ/2
. . .
δ/2
. . .
δ/2
δ/2
4.
IMPROVEMENTS
⃗w
=
,
is 1%. When the attack is mounted to six and seven signa-
tures, the dimension of the lattice becomes too large for the
lattice reduction algorithm to execute, let alone obtain the
right solution. As there are average 50.4 non-zero digits on
average in the wNAF representation of each k, the dimen-
sion of the lattice is 50.4u + u + 2 = 51.4u + 2, which means
that, for u = 3, 4, 5, 6, . . . , the dimension of the lattice is
separately 157, 208, 259, 311, . . . . For u > 6, the dimension
is larger than 300, which makes it relatively hard for the
LLL algorithm or the BKZ algorithm to (cid:12)nd a short vector,
meanwhile it takes a relatively long time to execute a lattice
reduction algorithm.
We seek for solutions to make the lattice reduction algo-
rithm easier to (cid:12)nd the target vector and to increase the
success probability. One direct way is to reduce the lattice
dimension.
In order to do this, we use the method of e-
limination and merging to reduce the number of unknown
variables.
Furthermore, we carefully exploit the double-and-add chain
to recover the MSD and determine whether the second MSD
is positive or negative in some cases, which can be used to
not only decrease the dimension of lattice, but also increase
the determinant of the lattice. At last, we enumerate the
MSDs which can not be recovered, so we can further de-
crease the dimension, thus improve the success probability
with the sacri(cid:12)ce of a little more time.
In most of our improvements, we can decrease the ratio
∥ ⃗w∥/GH(L) so that the key recovery can be made easier.
4.1 Reducing Lattice Dimension
There are mainly two ways to reduce the dimension of
the lattice. The (cid:12)rst one is the method of elimination, and
the second one is to reduce the number of non-zero digits of
ephemeral key k, which we name as the method of merging.
4.1.1 Elimination
As observed from Equation (4), the secret key α can be
eliminated to establish a set of new equations, thus reducing
the lattice dimension of L.
Denote the i-th equation in simultaneous Equations (4)
as Ei. For 2 6 i 6 u, we compute r1Ei − riE1 and get the
following equations:
l1∑
(2(cid:21)1;j +1s1ri)d1;j − li∑
(2(cid:21)i;j +1sir1)di;j − γi + tiq = 0,
j=1
j=1
where γi = r1(siki − H(mi)) − ri(s1k1 − H(m1)) mod q.
0 6 d1;j, di;j 6 2(cid:22)i;j − 1 and ti are unknown. Let τj;i =
2(cid:21)1;j +1s1ri mod q (1 6 j 6 l1) and σi;j = −2(cid:21)i;j +1sir1
mod q (1 6 j 6 li). As before, we can construct a lattice
′
L
, which is de-
(cid:12)ned by Equation (6), where δ is again a parameter with an
appropriate value.
) spanned by the basis matrix M
= L(M
′
′
′
In lattice L
′
′
= L(M
u
i=1 li.
√
2
,··· ,
du;1
2(cid:22)u;1
T + 1, where
′
), there exists a vector
(
= (t2,··· , tu, d1;1,··· , d1;l1 ,··· , du;1,··· , du;lu ,−1) · M
′
0,··· , 0,
δ − δ
2
··· ,
du;lu
∑
2(cid:22)u;lu
.
Its Euclidean norm satis(cid:12)es that ∥ ⃗w
T =
)
,··· ,
d1;l1
2(cid:22)1;l1
∈ L
′
d1;1
2(cid:22)1;1
δ − δ
2
δ − δ
2
,− δ
2
δ − δ
2
′∥ 6 (cid:14)
′
The dimension of lattice L
) is n
= L(M
= T + u, 2
′
dimensions less than that of L, while the determinant of L
′| = qu−1· δT +1/2U +1, 1/δ times of that of lattice L.
being |L
Since δ is always a very small number, the method of elim-
ination reduces the dimension of the lattice and the length
of the target vector, meanwhile increase the determinant of
the lattice. As a result, the ratio of ∥ ⃗w∥/GH(L) is reduced,
which makes it easier for the lattice reduction algorithms to
(cid:12)nd the vector ⃗w
. On the other hand, the reduction of the
lattice dimension leads to a more e(cid:14)cient execution of the
lattice reduction algorithm.
Note that, unlike the case of the basic attack that exists
a very short vector ⃗v = (0,··· , 0, δ, 0,··· , 0), there is no
′
after the elimination, so the
similar vector in the lattice L
target vector ⃗w′ is likely to be the (cid:12)rst vector of a reduced
lattice basis.
4.1.2 Merging
The method of merging aims to reduce the number of
non-zero digits l of each ephemeral key k in Equation (2),
meanwhile keeping the number of unknown bits as small
In the language of lattice, it correspondingly
as possible.
′
reduces the dimension of lattice L or L
and keeping the
determinant as large as possible.
′
′
1510q
τ1;2
...
τl1;2
σ2;1
...
σ2;l2
. . .
. . .
. . .
. . .
γ2
. . .
q
τ1;u
...
τl1;u
σu;1
...
σu;lu
γu
′
M
=
δ/2(cid:22)1;1
. . .
δ/2(cid:22)1;l1
δ/2(cid:22)2;1
. . .
δ/2(cid:22)2;l2
. . .
δ/2(cid:22)u;1
. . .
δ/2
. . .
δ/2
δ/2
. . .
δ/2
. . .
δ/2
. . .
δ/2
δ/2
δ/2(cid:22)u;lu
(6)
The core idea is to merge two or more consecutive non-
zero digits as one new non-zero digit. The distance of two
adjacent non-zero digits in the wNAF form of k can be com-
puted as λi+1 − λi, where λi+1 − λi > w + 1 (1 6 i 6 l − 1).
From Section 3.1, di has a one-to-one correspondence with
the non-zero digit ki, the merging of digit di is equivalent to
the merging of ki, so we only consider the merging of digit
di. The position of di is de(cid:12)ned to be the same with that of
ki.
Theorem 1. For h > 1, suppose h + 1 consecutive digits
′
i. Then we have 0 6
di, ..., di+h are merged as a new digit d
i 6 2(cid:22)i − 1, where µi = λi+h − λi + w is de(cid:12)ned as the
′
d
window size of d
′
i.
Proof. Suppose that h + 1 consecutive digits are merged
i = di + 2(cid:21)i+1−(cid:21)i di+1 + 2(cid:21)i+2−(cid:21)i di+2 + ··· +
′
as one, i.e., d
2(cid:21)i+h−(cid:21)i di+h .
We can easily obtain the following inequalities:
0 6 di 6 2w − 1
0 6 2(cid:21)i+1−(cid:21)i di+1 6 2(cid:21)i+1−(cid:21)i+w − 2(cid:21)i+1−(cid:21)i
0 6 2(cid:21)i+2−(cid:21)i di+2 6 2(cid:21)i+2−(cid:21)i+w − 2(cid:21)i+2−(cid:21)i
······
0 6 2(cid:21)i+h−(cid:21)i di+h 6 2(cid:21)i+h−(cid:21)i+w − 2(cid:21)i+h−(cid:21)i
′
i 6 2(cid:21)i+h−(cid:21)i+w +
Adding the above inequalities gives 0 6 d
(2(cid:21)i+h−1−(cid:21)i+w − 2(cid:21)i+h−(cid:21)i ) + ··· + (2w − 2(cid:21)i+1−(cid:21)i ) − 1 6
2(cid:21)i+h−(cid:21)i+w − 1. This (cid:12)nishes the proof.
h
∑
Theorem 1 indicates that if h + 1 consecutive digits di, ...,
di+h are merged, the unknown bits increase from (h + 1)w
to λi+h − λi + w. It is easy to check that λi+h − λi + w =
j=1(λi+j − λi+j−1) > h(w + 1) + w and the equality
w +
holds if only if for all 1 6 j 6 h, λi+j − λi+j−1 = w + 1.
Heuristically, from Equation (4) and (5), the smaller the
number of unknown bits is, the larger the determinant of
corresponding lattice is, and the easier we can recover the
secret key. So those consecutive non-zero digits such that
the distance of each adjacent two non-zero digits is w + 1
are preferred to be merged.
In this case, the number of
unknown bits increase from (h + 1)w to (h + 1)w + h. 2 In
other word, the number of non-zero digits is decreased by
h at the cost of h-bit information loss, which equivalently
means the number of non-zero digits is decreased by 1 at
the cost of 1-bit information loss. This is the best we can
achieve.
From the above analysis, we propose a strategy of merg-
ing, in which only the consecutive non-zero digits such that
the distance of each two adjacent non-zero digits is w + 1
are merged. The concrete method of merging is introduced
in Algorithm 3. By this strategy, we can reduce the number
of non-zero digits to about a half meanwhile keep the num-
ber of unknown bits as small as possible. Here we give an
illustrative example.
We generate a 257-bit ephemeral key k using OpenSSL
(w = 3), and get its wNAF form like this (we only list the
positions of non-zero digits):
3 7 12 18 22 28 34 39 43 48 52 56 64 69
73 77 82 88 92 96 100 106 112 117 122 126
131 135 139 144 150 154 161 165 169 173 177
181 185 189 194 198 202 207 214 219 226 233
238 244 248 252 257
We do the merging as follows:
18 22
12
28
3bits
3bits
88 92 96 100
7bits
3 7
7bits
82