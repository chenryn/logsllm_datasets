src/encodings.c to copy DUA value off
later
use. The function lava_set saves the DUA value in a
static variable. PANDA taint analysis and the FIB algorithm
determines that the ﬁrst four bytes of buf are suitable for
use in creating the bug.
into
for
1 ...
protected int
3 file_trycdf(struct magic_set *ms,
..., size_t nbytes) {
5
7
9
...
if (cdf_read_header
(( (&info)) + (lava_get())
* (0x6c617661 == (lava_get())
|| 0x6176616c == (lava_get())), &h) == -1)
return 0;
Fig. 8: Code injected into ﬁle’s src/readcdf.c to use
DUA value to create a vulnerability. The function lava_get
retrieves the value last stored by a call to lava_set.
an argument to a function call that can be made vulnerable
by adding a DUA to it. This means the argument can be a
pointer or some kind of integer type; the hope is that changing
this value by a large amount may trigger a buffer overﬂow.
Note that as with taint queries, LAVA attack point selection is
clearly far from complete. We might imagine attacking pointer
reads and writes, their uses in conditionals, etc.
D. Inject and test bugs
For each DUA/attack point pair, we generate the C code
which uses the DUA to trigger the bug using another custom
Clang tool. At the source line and for the variable in the DUA,
we inject code to copy its value into a static variable held by
a helper function. At the attack point, we insert code that
retrieves the DUA value, determines if it matches a magic
value, and if so adds it to one of the function arguments.
The ﬁnal step in LAVA is simply compiling and testing the
modiﬁed program on a proof-of-concept input ﬁle, in which
the input ﬁle bytes indicated as tainting the DUA have been
set to the correct value. An example of the pair of source
code insertions plus the ﬁle modiﬁction in order to inject a
115115
21 def update_liveness(tainted_branch):
for tainted_file_offset in tainted_branch:
23
liveness[tainted_file_offset]++
25 def collect_bugs(attack_point):
for dua in duas:
27
29
31
33
35
37
39
viable_count = 0
for file_offset in dua:
if (check_liveness(file_offset)):
viable_count ++
if (viable_count >= bytes_needed):
bugs.add((dua, attack_point))
for event in Pandalog:
if event.typ is taint_query:
collect_duas(event);
if event.typ is tainted_branch:
update_liveness(event);
if event.typ is attack_point:
collect_bugs(event);
Fig. 6: Python-style pseudocode for FIB. Panda log is pro-
cessed in temporal order and the results of taint queries on
values and branches are used to update the current set of DUAs
and input byte liveness. When an attack point is encountered,
all currently viable DUAs are considered as potential data
sources to inject a bug.
speciﬁc program point and variable name, and only the last
encountered DUA is retained in the viable set. This means
that if a DUA is a variable in a loop or in a function that is
called many times, the set will only have one entry (the last)
for that variable and source location, thus ensuring that value
is up to date and potentially usable at an attack point.
Information about the liveness of ﬁle input bytes is updated
whenever a log entry describing a tainted branch instruction
is encountered. Tainted branch information in the pandalog
updates liveness for all input bytes involved, in the function
update_liveness.
Finally, when FIB encounters an attack point in the pan-
dalog, the function collect_bugs considers each DUA in
the set, and those that are still viable with respect to liveness
are paired with the attack point as potentially injectable bugs.
In the current implementation of LAVA, an attack point is
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:15:56 UTC from IEEE Xplore.  Restrictions apply. 
bug into the program file can be seen in Figures 7, and 8.
The original input to file was the binary /bin/ls, and the
required modiﬁcation to that ﬁle is to simply set its ﬁrst four
bytes to the string ‘lava’ to trigger the bug. Note that the taint
analysis and FIB identiﬁes a DUA in one compilation unit and
an attack point in another compilation unit.
VI. RESULTS
We evaluated LAVA in three ways. First, we injected large
numbers of bugs into four open source programs: ﬁle, readelf
(from binutils), bash, and tshark (the command-line version
of the packet capture and analysis tool Wireshark). For each
of these, we report various statistics with respect to both the
target program and also LAVA’s success at injecting bugs.
Second, we evaluated the distribution and realism of LAVA’s
bugs by proposing and computing various measures. Finally,
we performed a preliminary investigation to see how effective
existing bug-ﬁnding tools are at ﬁnding LAVA’s bugs, by
measuring the detection rates of an open-source fuzzer and
a symbolic execution-based bug ﬁnder.
Counting Bugs
Before we delve into the results, we must specify what it
is we mean by an injected bug, and what makes two injected
bugs distinct. Although there are many possible ways to deﬁne
a bug, we choose a deﬁnition that best ﬁts our target use case:
two bugs should be considered different if an automated tool
would have to reason about them differently. For our purposes,
we deﬁne a bug as a unique pair (DU A, attackpoint). Ex-
panding this out, that means that the source ﬁle, line number,
and variable name of the DUA, and the source ﬁle and line
number of the attack point must be unique.
Some might object that this artiﬁcially inﬂates the count of
bugs injected into the program, for example because it would
consider two bugs distinct if they differ in where the ﬁle input
becomes available to the program, even though the same ﬁle
input bytes are used in both cases. But in fact these should be
counted as different bugs: the data and control ﬂow leading up
to the point where the DUA occurs will be very different, and
vulnerability discovery tools will have to reason differently
about the two cases.
A. Injection Experiments
The results of injecting bugs into open source programs are
summarized in Table I. In this table, programs are ordered
by size, in lines of C code, as measured by David Wheeler’s
sloccount. A single input was used with each program to
measure taint and ﬁnd injectable bugs. The input to file
and readelf was the program ls. The input to tshark
was a 16K packet capture ﬁle from a site hosting a number
of such examples. The input to bash was a 124-line shell
script written by the authors. N (DU A) and N (AT P ) are
the number of DUAs and attack points collected by the FIB
analysis. Note that, in order for a DUA or attack point to be
counted, it must have been deemed viable for some bug, as
described in Section V-C. The columns Potential Bugs and
Validated Bugs in Table I give the numbers of both potential
bugs found by FIB, but also those veriﬁed to actually return
exitcodes indicating a buffer overﬂow (-11 for segfault or -6
for heap corruption) when run against the modiﬁed input. The
penultimate column in the table is Yield, which is the fraction
of potential bugs what were tested and determined to be actual
buffer overﬂows. The last column gives the time required to
test a single potential bug injection for the target.
Exhaustive testing was not possible for a number of reasons.
Larger targets had larger numbers of potential bugs and take
longer to test; for example, tshark has over a million
potential bugs and each takes almost 10 minutes to test. This
is because testing requires not only injecting a small amount
of code to add the bug, but also recompiling and running the
resulting program. For many targets, we found the build to be
subtly broken so that a make clean was necessary to pick
up the bug injection reliably, which further increased testing
time. Instead, we attempted to validate 2000 potential bugs
chosen uniformly at random for each target. Thus, when we
report in Table I that for tshark the yield is 17.7%, this is
because 306 out of 2000 bugs were found to be valid.
As the injected bug is designed to be triggered only if a
particular set of four bytes in the input is set to a magic
value, we tested with both the original input and with the
modiﬁed one that contained the trigger. We did not encounter
any situation in which the original input triggered a crash.
Yield varies considerably from less than 10% to over 50%.
To understand this better, we investigated the relationship be-
tween our two taint-based measures and yield. For each DUA
used to inject a bug, we determined mT CN, the maximum
TCN for any of its bytes and mLIV , the maximum liveness
for any label in any taint label set associated with one of its
bytes. More informally, mT CN represents how complicated a
function of the input bytes a DUA is, and mLIV is a measure
of how much the control ﬂow of a program is inﬂuenced by
the input bytes that determine a DUA.
Table II shows a two-dimensional histogram with bins
for mT CN intervals along the vertical axis and bins for
mLIV along the horizontal axis. The top-left cell of this
table represents all bug injections for which mT CN = 1000 and mLIV >= 1000. Recall that
when mT CN = mLIV = 0, the DUA is not only a direct
copy of input bytes, but those input bytes have also not been
observed to be used in deciding any program branches. As
either mT CN or mLIV increase, yield deteriorates. However,
we were surprised to observe that mLIV values of over 1000
still gave yield in the 10% range.
TABLE II: Yield as a function of both mLIV and mT CN
mT CN
[0, 10)
[10, 100)
[100, + inf]
[0, 10)
51.9%
–
–
mLIV
[10, 100)
22.9%
0
–
[100, 1000)
17.4%
0
–
[1000, + inf]
11.9%
0
0
116116
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:15:56 UTC from IEEE Xplore.  Restrictions apply. 
TABLE I: LAVA Injection results for open source programs of various sizes
Name
ﬁle
readelf
bash
tshark
Version
5.22
2.25
4.3
1.8.2
Num
Src Files
19
12
143
1272
Lines
C code
10809
21052
98871
2186252
N(DUA)
631
3849
3832
9853
N(ATP)
114
266
604
1037
Potential
Bugs
17518
276367
447645
1240777
Validated
Bugs
774
1064
192
354
Yield
38.7%
53.2 %
9.6%
17.7%
Inj Time
(sec)
16
354
153
542
Fig. 9: A cartoon representing an entire program trace, anno-
tated with instruction count at which DUA is siphoned off to
be used, I(DU A), attack point where it is used, I(AT P ), and
total number of instructions in trace, I(T OT ).
B. Bug Distribution
It would appear that LAVA can inject a very large number
of bugs into a program. If we extrapolate from yield numbers
in Table I, we estimate there would be almost 400,000 real
bugs if all were tested. But how well distributed is this set of
bugs?
For programs like file and bash, between 11 and 44
source ﬁles are involved in a potential bug. In this case, the
bugs appear to be fairly well distributed, as those numbers
represent 58% and 31% of the total for each, respectively. On
the other hand, readelf and tshark fare worse, with only
2 and 122 source ﬁles found to involve a potential bug for
each (16.7% and 9.6% of source ﬁles).
The underlying cause for the low numbers of ﬁles in which
bugs appear seems to be poor dynamic coverage. For tshark,
much of the code is devoted to parsing esoteric network
protocols, and we used only a single input ﬁle. Similarly, we
only used a single hand-written script with bash, and made
little attempt to cover a majority of language features. Finally,
we ran readelf with a single command line ﬂag (-a); this
means that functionality such as DWARF symbol parsing was
not exercised.
C. Bug Realism
The intended use of the bugs created by this system is as
ground truth for development and evaluation of vulnerability
discovery tools and techniques. Thus, it is crucial that they be
realistic in some sense. Realism is, however, difﬁcult to assess.