title:Measuring intrusion detection capability: an information-theoretic
approach
author:Guofei Gu and
Prahlad Fogla and
David Dagon and
Wenke Lee and
Boris Skoric
Measuring Intrusion Detection Capability:
An Information-Theoretic Approach
Guofei Gu, Prahlad Fogla, David Dagon,
Wenke Lee
Georgia Institute of Technology, U.S.A.
{guofei,prahlad,dagon,wenke}@cc.gatech.edu
Boris ˇSkori´c
Philips Research Laboratories, Netherlands
PI:EMAIL
ABSTRACT
A fundamental problem in intrusion detection is what met-
ric(s) can be used to objectively evaluate an intrusion detec-
tion system (IDS) in terms of its ability to correctly classify
events as normal or intrusive. Traditional metrics (e.g., true
positive rate and false positive rate) measure diﬀerent as-
pects, but no single metric seems suﬃcient to measure the
capability of intrusion detection systems. The lack of a sin-
gle uniﬁed metric makes it diﬃcult to ﬁne-tune and evaluate
an IDS. In this paper, we provide an in-depth analysis of ex-
isting metrics. Speciﬁcally, we analyze a typical cost-based
scheme [6], and demonstrate that this approach is very con-
fusing and ineﬀective when the cost factor is not carefully se-
lected. In addition, we provide a novel information-theoretic
analysis of IDS and propose a new metric that highly com-
plements cost-based analysis. When examining the intru-
sion detection process from an information-theoretic point
of view, intuitively, we should have less uncertainty about
the input (event data) given the IDS output (alarm data).
Thus, our new metric, CID (Intrusion Detection Capability),
is deﬁned as the ratio of the mutual information between the
IDS input and output to the entropy of the input. CID has
the desired property that: (1) It takes into account all the
important aspects of detection capability naturally, i.e., true
positive rate, false positive rate, positive predictive value,
negative predictive value, and base rate; (2) it objectively
provides an intrinsic measure of intrusion detection capa-
bility; and (3) it is sensitive to IDS operation parameters
such as true positive rate and false positive rate, which can
demonstrate the eﬀect of the subtle changes of intrusion de-
tection systems. We propose CID as an appropriate perfor-
mance measure to maximize when ﬁne-tuning an IDS. The
obtained operation point is the best that can be achieved
by the IDS in terms of its intrinsic ability to classify input
data. We use numerical examples as well as experiments of
actual IDSs on various data sets to show that by using CID,
we can choose the best (optimal) operating point for an IDS
and objectively compare diﬀerent IDSs.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS ’06, March 21-24, 2006, Taipei, Taiwan.
Copyright 2006 ACM 1-59593-272-0/06/0003 ...$5.00.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Network]: Security
and Protection; C.4 [Performance of Systems]: Mea-
surement techniques; H.1.1 [Systems and Information
Theory]: Information theory
General Terms
Security, Measurement
Keywords
Intrusion detection, performance measurement, information-
theoretic
1.
INTRODUCTION
Evaluating intrusion detection systems is a fundamental
topic in the ﬁeld of intrusion detection. In this paper, we
limit our focus of evaluation to measure the eﬀectiveness
of an IDS in terms of its ability to correctly classify events
as normal or intrusive. Other important IDS performance
objectives, such as economy in resource usage, resilience
to stress [20], and ability to resist attacks directed at the
IDS [19, 17], are beyond the scope of this paper. Policy-
dependent IDS evaluation is also beyond the scope.
Measuring the capability of an IDS (to correctly classify
events as normal or intrusive) is essential to both practice
and research because it enables us to better ﬁne-tune an IDS
(selecting the best IDS conﬁguration for an operation envi-
ronment) and compare diﬀerent IDSs. For example, when
deploying an anomaly-based IDS, we need to adjust some
parameters (e.g., the threshold of deviation from a normal
proﬁle) to tune the IDS at an optimal operating point. Each
adjustment (setting) is a diﬀerent conﬁguration. If we can
measure the capability of an IDS at these conﬁgurations,
we can simply choose the conﬁguration that maximizes this
capability metric.
There are several existing metrics that measure diﬀerent
aspects of intrusion detection systems, but no single met-
ric seems suﬃcient to objectively measure the capability of
intrusion detection systems.
The most basic and commonly used metrics are true pos-
itive rate (T P , i.e., the probability that the IDS outputs
an alarm when there is an intrusion) and false positive rate
(F P , i.e., the probability that the IDS outputs an alarm
when no intrusion occurs). Alternatively, one can use false
negative rate F N = 1 − T P and true negative rate T N =
1−F P . When we ﬁne-tune an IDS (particularly an anomaly
detection system), for example, by setting the threshold of
0
Equivalent Terms from IDS Literature Meaning
Term
F P , or α P (A|¬I)
T P
(1 − β), P (A|I)
F N , or β P (¬A|I)
T N
(1 − α), P (¬A|¬I)
“Bayesian detection rate”, P (I|A)
P P V
N P V
P (¬I|¬A)
B
P (I)
False positive rate. The chance that there is an
alert, A, when there is no intrusion, ¬I.
True positive rate. The chance the there is an
alert, A, when there is an intrusion, I.
False negative rate. The chance there is no alert,
¬A, when there is an intrusion, I.
True negative rate. The chance there is no alert,
¬A, when there is no intrusion, ¬I.
Positive predictive value. The chance that an in-
trusion, I,
is present when an IDS outputs an
alarm, A.
Negative predictive value. The chance that there
is no intrusion, ¬I, when an IDS does not output
an alarm, ¬A.
Base rate. The probability that there is an intru-
sion in the observed audit data.
Table 1: Terminology used in this paper. For readability, we will use the terms listed in the leftmost column.
a deviation from a normal proﬁle, there may be diﬀerent
T P and F P values associated with diﬀerent IDS operation
points (e.g., each with a diﬀerent threshold). For example,
at one conﬁguration, T P = 0.8, F P = 0.1, while at another
conﬁguration, T P = 0.9, F P = 0.2. If only the metrics of
T P, F P are given, determining the better operation point is
diﬃcult. This naturally motivates us to ﬁnd a new compos-
ite metric. Clearly, both T P and F P need to be considered
in this new metric. The question is then how to use these
two basic metrics together.
A popular approach is to use an ROC (receiver operating
characteristic) curve [9] to plot the diﬀerent T P and F P
values associated with diﬀerent IDS operation points. For
example, an ROC curve can show one (operation) point with
 and another with . An ROC curve shows the relationship
between T P and F P , but by itself, it cannot be used to
determine the best IDS operation point. ROC curves may be
used for comparing IDSs. If the ROC curves of the two IDSs
do not “cross” (i.e., one is always above the other), then the
IDS with the top ROC curve is better because for every F P ,
it has a higher T P . However, if the curves do cross, then
there is no easy way to compare the IDSs. It is not always
appropriate to use the area under the ROC curve (AUC)
for comparison because it measures all possible operation
points of an IDS. One can argue that a comparison should
be based on the best operation point of each IDS because in
practice an IDS is ﬁne-tuned to a particular conﬁguration
(e.g., using a particular threshold).
One approach to integrating the metrics T P and F P is
through cost-based analysis. Essentially, the tradeoﬀ be-
tween a true positive and a false positive is considered in
terms of cost measures (or estimates) of the damage caused
by an intrusion and inconvenience caused by a false alarm.
Gaﬀney and Ulvila [6] used such an approach to combine
ROC curves with cost analysis to compute an expected cost
for each IDS operation point. The expected cost can be
used to select the best operation point and to compare dif-
ferent IDSs. The quality of cost-based analysis depends on
how well the cost estimates reﬂect the reality. However,
cost measures in security are often determined subjectively
because of the lack of good (risk) analysis models. Thus,
cost-based analysis cannot be used to objectively evaluate
and compare IDSs. As shown in Section 3, this approach [6]
is very confusing and ineﬀective when the cost factor is not
carefully selected. Moreover, cost-based analysis does not
provide an intrinsic measure of detection performance (or
accuracy).
In addition to T P and F P , two other useful metrics are
the positive predictive value (P P V ), which is the probability
of an intrusion when the IDS outputs an alarm, and the
negative predictive value (N P V ), which is the probability of
no intrusion when the IDS does not output an alarm. These
metrics are very important from a usability point of view
because ultimately, the IDS alarms are useful to an intrusion
response system (or administrative staﬀ) only if the IDS has
high P P V and N P V . Both P P V and N P V depend on T P
and F P , and are very sensitive to the base rate (B), which
is the prior probability of intrusion. Thus, these two metrics
can be expressed using Bayes theorem (and PPV is called
Bayesian detection rate [1] in IDS literature) so that the base
rate can be entered as a piece of prior information about
the IDS operational environment in the Bayesian equations.
Similar to the situation with T P and F P , both P P V and
N P V are needed when evaluating an IDS from a usability
point of view, and currently, there is no objective method
to integrate both metrics.
We need a single uniﬁed metric that takes into account
all the important aspects of the detection capability, i.e.,
T P , F P , P P V , N P V , and B. That is, this metric should
incorporate existing metrics because they are all useful in
their own right. This metric needs to be objective. That is,
it should not depend on any subjective measure. In addi-
tion, it needs to be sensitive to IDS operation parameters to
facilitate ﬁne-tuning and ﬁne-grained comparison of IDSs.
We use T P and F P as the surrogates of IDS operation pa-
rameters (e.g., threshold) because changes to the operation
parameters usually result in changes to T P and F P . Al-
though it is diﬃcult or sometimes impossible to control the
base rate in an IDS, we still consider it as an operation
parameter because it is a measure of the environment in
which the IDS operates. T P, F P, B can be measured when

we evaluate an IDS because we have the evaluation data set
and should know the ground truth.
We propose an information-theoretic measure of the intru-
sion detection capability. At an abstract level, the purpose
of an IDS is to classify the input data (i.e., events that the
IDS monitors) correctly as normal or an intrusion. That
is, the IDS output (i.e., the alarms) should faithfully reﬂect
the “truth” about the input (i.e., whether an intrusion re-
ally occurs or not). From an information-theoretic point
of view, we should have less uncertainty about the input
given the IDS output. Thus, our metric, called the Intru-
sion Detection Capability, or CID, is simply the ratio of the
mutual information between the IDS input and output to
the entropy of the input. Mutual information measures the
amount of uncertainty of the input resolved by knowing the
IDS output. We normalize it using the entropy (the orig-
inal uncertainty) of the input. Thus, the ratio provides a
normalized measure of the amount of certainty gained by
observing IDS outputs. This natural metric incorporates
T P , F P , P P V , N P V , and B, and thus, provides a uniﬁed
measure of the detection capability of an IDS. It is also sen-
sitive to T P , F P , and B, which can demonstrate the eﬀect
of the subtle changes of intrusion detection systems.
This paper makes contributions to both research and prac-
tice. We provide an in-depth analysis of existing metrics and
provide a better understanding of their limitations. We ex-
amine the intrusion detection process from an information-
theoretic point of view and propose a new uniﬁed metric
for the intrusion detection capability. CID is the appro-
priate performance measure to maximize when ﬁne-tuning
an IDS. The obtained operation point is the best that can
be achieved by the IDS in terms of its intrinsic ability to
classify input data. We use numerical examples as well as
experiments of actual IDSs on various data sets to show that
by using this metric, we can choose the best (optimal) op-
erating point for an IDS and objectively compare diﬀerent
IDSs.
Note that this new metric, CID, is not intended to re-
place existing metrics such as T P , F P . In fact, T P, F P are
used as basic inputs to compute CID. Thus, CID presents
a composite/uniﬁed measure and a nature tradeoﬀ between
T P and F P . Furthermore, CID is just one possible measure
for IDS evaluation. It is not to replace cost-based analysis,
but instead, it greatly complements the cost-based approach,
particularly in the cases that risk model is not clear or not
available. Finally, although our measure can be used in
other domains, we focus on intrusion detection (speciﬁcally
network-based intrusion detection) as a motivating example.
The rest of this paper is organized as follows. Section 2
provides an information-theoretic view of the intrusion de-
tection process. After reviewing some essential information
theory concepts, we introduce our uniﬁed metric of the in-
trusion detection capability, CID. Section 3 analyzes exist-
ing metrics and compares them with CID. Section 4 de-
scribes how CID can be used to select the best operation
point of an IDS and to compare diﬀerent IDSs. Section 5
discusses limitations and extensions. Section 6 introduces
related work, and Section 7 concludes the paper and dis-
cusses future work.
2. AN INFORMATION-THEORETIC VIEW
OF INTRUSION DETECTION
Let us revisit the intrusion detection process from an information-
theoretic point of view. At an abstract level, an IDS accepts
and analyzes an input data stream and produces alerts that
indicate intrusions. Every unit of an input data stream has
either an intrusive or normal status. Thus, we can model
the input of an IDS as a random variable X, where X = 1
represents an intrusion, and X = 0 represents normal traf-
ﬁc. The output alerts of an IDS is also modeled as a random
variable Y , where Y = 1 indicates an alert of an intrusion,
and Y = 0 represents no alert from the IDS. We assume here
that there is an IDS output (decision) corresponding to each
input. The exact encoding of X, Y is related to the unit of
the input data stream, which is in fact related to IDS anal-
ysis granularity, or the so-called unit of analysis [15]. For
network-based IDSs such as Snort [22], the unit of analysis
is a packet. The malicious packets are encoded as X = 1.
The IDS examines every packet to classify it as malicious
(Y = 1) or normal (Y = 0). There are also IDSs such as
Bro [17] which analyze events based on ﬂows. In this case,
the malicious ﬂow is encoded as X = 1, and the output in-
dicates whether this ﬂow contains an attack (Y = 1) or not
(Y = 0).
An abstract model for intrusion detection is shown in Fig-
ure 1. In this model, p(X = 1) is the base rate, which is the
X
1
P(x=1)=B
P(x=0)=1-B
0
FN
FP
1-FN
1-FP
Y
1
0
Figure 1: An abstract model for intrusion detection.
prior probability of intrusion in the input event data exam-
ined by the IDS. We denote it as B. An intrusion event
has a probability p(Y = 0|X = 1) of being considered nor-
mal by the IDS. This is the false negative rate (F N ), de-
noted as β. Similarly, a normal event also has a probability
p(Y = 1|X = 0) of being misclassiﬁed as an intrusion. This
is the false positive rate (F P ), denoted as α. We will use
the notations (B, α, β) throughout this paper. Table 1 lists
the terms used by this paper and their meaning. Note that
when we evaluate an IDS, we should have an evaluation data
set of which we know the ground truth. Thus, once the eval-
uation data set is given and the tests are run, we should be
able to calculate B, α and β.
This model is useful because intrusion detection can be
analyzed from an information-theoretic point of view. We
will ﬁrst review a few basic concepts in information the-
ory [3], the building blocks of our proposed metric of the
intrusion detection capability.
2.1
Information Theory Background
Deﬁnition 1. The entropy (or self-information) H(X) of a
discrete random variable X is deﬁned by [3]
H(X) = −x
p(x) log p(x)

Let us revisit the intrusion detection process from an information-
This deﬁnition is commonly known as the Shannon en-
tropy measure, or the uncertainty of X. A larger value of
H(X) indicates that X is more uncertain. We use the con-
vention that 0 log 0 = 0, which is easily justiﬁed by continu-
ity because x log x → 0 as x → 0. The deﬁnition of entropy
can be extended to the case of jointly distributed random
variables.
Deﬁnition 2. If (X, Y ) is jointly distributed as p(x, y),
then the conditional entropy H(X|Y ) is deﬁned as [3]
H(X|Y ) = −y x
p(x, y) log p(x|y)
(1)
Conditional entropy is the amount of remaining uncer-
tainty of X after Y is known. We can say H(X|Y ) = 0
if and only if the value of X is completely determined by
the value of Y . Conversely, H(X|Y ) = H(X) if and only if
X and Y are completely independent. Conditional entropy
H(X|Y ) has the following property:
0 ≤ H(X|Y ) ≤ H(X)
Deﬁnition 3. Consider two random variables X and Y
with a joint probability mass function p(x, y) and marginal
probability mass functions p(x) and p(y). The mutual in-
formation I(X; Y ) is deﬁned as [3]
I(X; Y ) =x y
p(x, y) log
p(x, y)
p(x)p(y)
Mutual information tells us the amount of information
shared between the two random variables X and Y . Obvi-
ously, I(X; Y ) = I(Y ; X).
Theorem 1. Mutual information and entropy [3]:
I(X; Y ) = H(X) − H(X|Y ) = H(Y ) − H(Y |X)
This equation shows that we can interpret mutual infor-
mation as the amount of reduction of uncertainty in X af-
ter Y is known, H(X|Y ) being the remaining uncertainty.
This theorem shows the relationship between conditional en-
tropy and mutual information. We can also express this
relationship in a Venn diagram shown in Figure 2. Here,
mutual information I(X; Y ) corresponds to the intersection
of the information in X with the information in Y . Clearly,
0 ≤ I(X; Y ) ≤ H(X).
2.2 CID: A New Metric of The Intrusion De-