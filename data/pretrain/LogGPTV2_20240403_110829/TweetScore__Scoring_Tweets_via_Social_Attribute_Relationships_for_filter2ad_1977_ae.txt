### Evaluation of Classification Results

The Area Under the Receiver Operating Characteristic Curve (AUC) is utilized to evaluate the classification results. AUC represents the probability that a classifier will rank a randomly selected spam tweet higher than a randomly selected non-spam tweet. A higher AUC score indicates better performance of the spam detection classifier. Figure 8 illustrates the AUC values for TweetScore, SybilSCAR, and Chen6M. TweetScore outperforms both Chen6M and SybilSCAR. As the pseudo-honeypot running time increases, the AUC values for all three solutions decrease, but the AUC curve of TweetScore decreases at a much slower rate compared to SybilSCAR and Chen6M. This demonstrates the advantage of TweetScore over existing solutions in online spam classification.

### Scalability of TweetScore

This experiment evaluates the scalability of TweetScore in terms of time cost by varying the sizes of the training and test datasets. The training dataset sizes were varied from 100 hours, 200 hours, to 300 hours, while the test dataset sizes increased by 10 hours each time. Figure 9 shows the time cost of TweetScore with different training and test dataset sizes. For the 700-hour data, the first 100, 200, and 300 hours were used as the training datasets, and the testing process started after 100, 200, and 300 hours, respectively, as shown on the x-axis of Figure 9.

All three curves in Figure 9 rise nearly linearly, indicating that TweetScore has almost linear complexity with respect to the fixed training dataset size. The running times increase as the training dataset sizes grow (from 100 hours to 300 hours), even under the same test dataset size. This is because the dominant time cost of TweetScore lies in the neural network model training, which requires more time for larger datasets.

### Testing on New Data

To demonstrate the performance of TweetScore, SybilSCAR, Chen6M, and Gradient Boosting (GB), we used our 100-hour labeled ground truth dataset as the training data and selected a 10-hour data segment from the remaining 600-hour dataset for testing. We adopted diversified approaches to label this 10-hour data for comparison. Figure 6 depicts the Receiver Operating Characteristic (ROC) curves of TweetScore, SybilSCAR, Chen6M, and GB. Each point on the curve represents the pair of True Positive Rate (TPR) and False Positive Rate (FPR) for a given decision threshold. A curve positioned at the upper left indicates better performance. The results show that TweetScore is highly competitive in terms of accuracy.

### Online Learning and Testing Accuracy

We illustrate the performance of TweetScore in online spam detection over a total of 700 hours. Since it is technically challenging to label all 700 hours of data, we combined multiple state-of-the-art methods [12, 24, 36] to label the most confident spams and track suspended accounts included in our test dataset. In our tweets collection procedure, we implemented TweetScore, SybilSCAR, and Chen6M, complemented by a pseudo-honeypot for online spam classification.

#### Accuracy of TweetScore in Online Spam Classification

The pseudo-honeypot reports collected tweets every 10 hours. In this experiment, the first 100 hours of data were used as the training set. Figure 10 and Figure 11 show the number of spams and spammers, along with their hit ratios, captured in the pseudo-honeypot network using different features. The hit ratio (Hr) for spams and the hit ratio (Ĥr) for spammers are defined as the ratio of captured spams or spammers over the collected tweets or user accounts, respectively.

From Figures 10 and 11, we observe that pseudo-honeypots capture more spams and spammers with trending-based features compared to hashtag-based features. Specifically, we collected a total of 169,121 spams using trending-based features and 83,158 spams using hashtag-based features. The top three hashtag-based features have hit ratios of 22.41% (entertainment), 18.97% (technology), and 14.01% (general). For trending-based features, the hit ratios are 20.09% (trending-pop), 19.97% (trending-up), and 18.25% (trending-down).

Figure 11 shows the number of spammers and their hit ratios. The top six features with the highest spammer hit ratios are technology (11.61%), entertainment (9.03%), business (8.26%), trending-down (6.34%), general (6.31%), and trending-up (6.29%).

### Performance of Pseudo-Honeypot Systems

We detail the effectiveness of the pseudo-honeypot system in capturing spams and spammers under different features. Figures 12 and 13 compare the hit ratios (Hr and Ĥr) of the pseudo-honeypot and non-pseudo-honeypot systems within 300 hours of experiments. According to these figures, the hit ratios of the pseudo-honeypot solution are almost four times higher than those of the non-pseudo-honeypot system. This demonstrates the advantage of the pseudo-honeypot in capturing tweets and user accounts with a higher probability of containing spam messages and spammers.

### Comparison to Honeypot-Based Solutions

Constructing large-sized honeypot systems, especially with specific attributes, is challenging. We compared our results with earlier prominent studies, such as Stringhini [28], Lee [18], and Yang [36]. Our findings indicate that one pseudo-honeypot node can capture an average of 1.03 spammers per hour, whereas each honeypot node in the mentioned studies captures 0.0067, 0.12, and 0.087 spammers per hour, respectively. This highlights the superior efficiency of the pseudo-honeypot system in capturing spammers.

### Conclusion

This paper explores the novel pseudo-honeypot framework and TweetScore solution for efficient spam monitoring and classification in the Twitter network. The pseudo-honeypot network is constructed over users with features that attract spammers, significantly increasing the spam ratio in the collected tweets. Additionally, TweetScore profiles the intrinsic attribute relationships among neighboring users and their tweets for better spam classification. Experiments demonstrate that the pseudo-honeypot yields four times and eleven times higher spammer capture ratios compared to non-pseudo-honeypot and traditional honeypot systems, respectively. TweetScore achieves 93.50% accuracy, 93.71% precision, and 1.52% false positive in online spam detection.

### Acknowledgment

The authors thank the anonymous reviewers for their valuable comments. This research was supported in part by the Louisiana Board of Regents under Contract Number LEQSF(2018-21)-RD-A24. The opinions and findings expressed in the paper are those of the authors and do not necessarily reflect the position of their employers or the view of the funding agency.

### References

[References remain unchanged]

---

This revised text aims to enhance clarity, coherence, and professionalism, making it easier to understand and follow.