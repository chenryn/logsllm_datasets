ing hours. The Area Under the Receiver Operating Characteristic
Curve (AUC) is used here to evaluate the classification results.
AUC can represent the probability that a classifier will rank ran-
domly selected spam tweet higher than a randomly selected non-
spam tweet. A higher AUC score means the better performance of
spam detection classifier. Figure 8 exhibits the AUC for TweetScore,
SybilSCAR and Chen6M, respectively. TweetScore is seen to out-
perform Chen6M and SybilSCAR. With the increasing of pseudo-
honeypot running time, AUC values for all these three solutions
keep decreasing. But the AUC curve of TweetScore decreases much
slower than that from SybilSCAR and Chen6M. This demonstrated
the advantage of TweetScore when compared to the existing solu-
tions in online spam classification.
Scalability of TweetScore. This experiment aims to evaluate the
scalability of TweetScore in terms of time cost by varying the sizes
of training and test datasets. We vary the training dataset sizes
from 100 hours, 200 hours, to 300 hours data, while the test dataset
sizes increment by 10 hours data each time. Figure 9 shows the time
cost of TweetScore with various training and test dataset sizes. With
the 700-hour data, we take the first 100, 200, and 300 hours as the
training datasets, so the testing process starts after 100, 200 and 300
hours, respectively, in the x-axis of Figure 9.
All three curves in Figure 9 are seen to rise nearly linearly. We
find all these three curves are likely linearly increasing in Figure 9.
This implies that our TweetScore has almost linear complexity with
respect to the fixed training dataset size. From these three curves,
the running times are found to increase when training dataset sizes
grow (from 100 hours to 300 hours) even under the same test dataset
size. The reason is that the dominating time cost of TweetScore lies
in the neural network model training time, which requires longer
time to train larger datasets.
Figure 8: The AUC curves of TweetScore, SybilSCAR and
Chen6M on the 600-hour data.
Testing on new data. We take our 100-hour labeled ground truth
dataset as the training data and pick a 10-hour data from the re-
maining 600-hour dataset for testing to show the performance of
TweetScore, SybilSCAR, Chen6M, and Gradient Boosting (GB). We
again adopt the diversified approaches to label this 10-hour data
for comparison. Figure 6 depicts the Receiver Operating Character-
istic (ROC) curves of TweetScore, SybilSCAR, and Chen6M, and GB.
The point on each curve represents the pair of TPR (true positive
rate) and FPR (false positive rate) for a given decision threshold. A
curve at the upper left represents that the solution has better per-
formance than the one at the lower right. This result demonstrates
the accuracy of TweetScore is highly competitive.
5.3 Online Learning and Testing Accuracy
We now illustrate the performance of TweetScore in online spam
detection for a total of 700 hours. As it is technically hard to label
all 700-hour dataset, we combine multiple state-of-the-art methods
[12, 24, 36] to label most confident spams and keep tracking Twitter
system to spot suspend accounts included in our test dataset. In
our tweets collection procedure, we implement the TweetScore,
SybilSCAR, and Chen6M complementing with the pseudo-honeypot
to achieve online spam classification.
Accuracy of TweetScore in online spam classification. We let
the pseudo-honeypot to report the collected tweets every 10 hours.
In this experiment, we use the first 100 hours data as the training
100200300400500600700TestData(hours)0.8000.8250.8500.8750.9000.9250.9500.9751.000Accuracy&Precision0.000.020.040.060.080.10FalsePositiveaccuracyprecisionfalsepositive100200300400500600700TestData(hours)0.50.60.70.80.91.0AUCTweetScoreChen6MSybilSCAR100200300400500600700Trainingdataset+Testdataset(hours)300400500600700800Timecost(s)Trainingsize:100-hourdataTrainingsize:200-hourdataTrainingsize:300-hourdataSession 5A: Web SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand388Figure 10: The number of spams and the hit ratios captured
in the pseudo-honeypot network using different features.
Figure 12: The comparison of spam hit ratio under pseudo-
honeypot and non pseudo-honeypot solutions within 300
hours of experiments.
Figure 11: The number of spammers and the hit ratios cap-
tured in the pseudo-honeypot network using different fea-
tures.
5.4 Performance of Pseudo-honeypot Systems
We illustrate the details of captured spams and spammers under
each of hashtag-based and trending-based features. To measure the
effectiveness of pseudo-honeypot on spams and spammers collec-
tion, we refer to the hit ratio as the ratio of captured spam (or
spammers) over collected tweets (or users accounts). Denote the
hit ratio of spams and of spammers by Hr and ˆHr , respectively.
Figure 10 depicts the number of spams and its hit ratio captured
by pseudo-honeypots under each feature. From this figure, we ob-
serve pseudo-honeypots captures more spams with trending-based
features than with hashtag-based features. Specifically, we collect
a total of 169, 121 spams using trending-based features and a total
of 83, 158 spams using hashtag-based features. The hit ratios of
the top three hashtag-based features are 22.41% (entertainment),
18.97% (technology), and 14.01% (general). On the other hand, ratios
of trending-pop, trending-up, and trending-down are 20.09%, 19.97%,
and 18.25%, respectively.
Figure 11 illustrates the number of spammers and the hit ratio
captured by pseudo-honeypots under each feature. We can see tech-
nology, entertainment, business, trending-down, general, and trending-
up to be the top 6 features that have the highest spammer hit ratios
Figure 13: The comparison of spammer hit ratio under
pseudo-honeypot and non pseudo-honeypot solutions within
300 hours of experiments.
of 11.61%, 9.03%, 8.26%, 6.34%, 6.31% and 6.29%, respectively. The
results from Figures 10 and 11 can guide us in the future design of
pseudo-honeypots by selecting features with high hit ratios.
From Figures 10 and 11, we select the features of the top 5 spam
hit ratios and the top 5 spammer hit ratios. These features are used
to sample a more effective pseudo-honeypot system. That is, the
pseudo-honeypot network randomly selects 300 users accounts,
with each one possessing at least one of these features. The pseudo-
honeypot network shift time is set to be 1 hour. For comparison, we
arbitrarily select 300 user accounts every hour to perform tweets
monitoring and execute this experiment with a total of 300 hours.
This experiment is called as the non pseudo-honeypots counterpart.
Comparison to non pseudo-honeypot system. Figures 12 and
13 show the comparison of Hr and ˆHr , respectively, for non pseudo-
honeypot and pseudo-honeypot systems. According to Figures 12
and 13, both Hr and ˆHr of the pseudo-honeypot solution are almost
four times more than those of non pseudo-honeypot. This demon-
strates the advantages of pseudo-honeypot in capturing tweets
(user accounts) that include a higher probability of spam messages
(spammers).
Comparison to honeypot-based solutions. A large-sized hon-
eypot systems is hard to be constructed, especially with some spe-
cific attributes. We select to compare the results of earlier prominent
studies, i.e., Stringhini [28], Lee [18], and Yang [36]. We find that
one pseudo-honeypot node can capture an average of 1.03 spam-
mers per hour, whereas each honeypot node in Stringhini [28], Lee
entertainmenttrending-poptechnologytrending-uptrending-downgeneralbusinessenvironmenteducationastrologysocial0100k200k300k400k#oftweetsspamsnon-spams5101520SpamHitRatio(%)SpamHitRatiotechnologyentertainmentbusinesstrending-downgeneraltrending-uptrending-popeducationsocialenvironmentastrology050k100k150k#ofusersspammersnon-spammers4681012SpammerHitRatio(%)SpammerHitRatio050100150200250300Time(hours)05101520SpamHitRatioHr(%)pesudo-honeypotnonpseudo-honeypot050100150200250300Time(hours)246810SpammerHitRatioˆHr(%)pesudo-honeypotnonpseudo-honeypotSession 5A: Web SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand389[18], and Yang [36] captures 0.0067, 0.12, 0.087, spammers per hour,
respectively. This demonstrates the advantage of pseudo-honeypot
system over the existing honeypot system in terms of spammers
capture efficiency.
6 CONCLUSION
This paper has explored the novel pseudo-honeypot framework
and TweetScore solution for efficient spam monitoring and classi-
fication in the Twitter network. The pseudo-honeypot network is
constructed over users with features that have much more poten-
tials of attracting spammers, thus significantly lifting the spam ratio
included in the collected tweets when compared to collecting tweets
blindly. Additionally, TweetScore allows us to explore the intrinsic at-
tribute relationships among neighboring users of respective tweets.
By scoring these relationships into a vector of numerical values,
we profile the users’ relationship and their tweets for better spam
classification. We implemented the pseudo-honeypot system in
Twitter network for tweet monitoring and collection, and employed
TweetScore to perform the spam classification based on 700-hour
collected data. The experiments have demonstrated that the pseudo-
honeypot yields four times and eleven times spammer capture ratios
when compared respectively with non pseudo-honeypot and the
traditional honeypot systems. The results confirm that TweetScore
achieves 93.50% accuracy, 93.71% precision, and 1.52% false positive
in online spam detection.
ACKNOWLEDGMENT
The authors would like to thank the anonymous reviewers for
their fruitful comments. This research was supported in part by
Louisiana Board of Regents under Contract Number LEQSF(2018-
21)-RD-A24. Any opinion and findings expressed in the paper are
those of the authors and do not necessarily reflect the position of
their employers or the view of funding agency.
REFERENCES
[1] Arasu, A., Novak, J., Tomkins, A., and Tomlin, J. Pagerank computation and
the structure of the web: Experiments and algorithms. In ACM International
World Wide Web Conference (WWW), Poster Track (2002), pp. 107–117.
[2] Benevenuto, F., Magno, G., Rodrigues, T., and Almeida, V. Detecting spam-
mers on twitter. In Collaboration, Electronic messaging, Anti-abuse and Spam
conference (CEAS) (2010).
[3] Bengio, Y., Ducharme, R., Vincent, P., and Jauvin, C. A neural probabilistic
language model. Journal of Machine Learning Research 3, Feb (2003), 1137–1155.
[4] Boshmaf, Y., Logothetis, D., Siganos, G., Lería, J., Lorenzo, J., Ripeanu, M.,
and Beznosov, K. Integro: Leveraging victim prediction for robust fake account
detection in osns. In Network and Distributed System Security Symposium (NDSS)
(2015), pp. 8–11.
[5] Castillo, C., Donato, D., Gionis, A., Murdock, V., and Silvestri, F. Know your
neighbors: Web spam detection using the web topology. In ACM SIGIR Conference
on Research and Development in Information Retrieval (2007), pp. 423–430.
[6] Chen, C., Wang, Y., Zhang, J., Xiang, Y., Zhou, W., and Min, G. Statistical
features-based real-time detection of drifted twitter spam. IEEE Transactions on
Information Forensics and Security 12, 4 (2017), 914–925.
[7] Chen, C., Zhang, J., Chen, X., Xiang, Y., and Zhou, W. 6 million spam tweets:
A large ground truth for timely twitter spam detection. In IEEE International
Conference on Communications (ICC) (2015), IEEE, pp. 7065–7070.
[8] Chen, W., Yeo, C. K., Lau, C. T., and Lee, B. S. A study on real-time low-quality
content detection on twitter from the users’ perspective. PloS One 12, 8 (2017).
[9] Corporation, L. Hashtag analytics for your brand, business, product, service,
event or blog. http://www.hashtags.org, 2018.
[10] Danezis, G., and Mittal, P. Sybilinfer: Detecting sybil nodes using social
networks. In Network and Distributed System Security Symposium (NDSS) (2009),
pp. 1–15.
[11] Grover, A., and Leskovec, J. node2vec: Scalable feature learning for networks. In
ACM SIGKDD International Conference on Knowledge Discovery and Data mining
(2016), pp. 855–864.
[12] Herzallah, W., Faris, H., and Adwan, O. Feature engineering for detecting
spammers on twitter: Modelling and analysis. Journal of Information Science 44,
2 (2018), 230–247.
[13] Jia, J., Wang, B., and Gong, N. Z. Random walk based fake account detec-
tion in online social networks. In Annual IEEE/IFIP International Conference on
Dependable Systems and Networks (DSN) (2017), pp. 273–284.
[14] Koren, Y., Bell, R., and Volinsky, C. Matrix factorization techniques for recom-
mender systems. Computer, 8 (2009), 30–37.
[15] Langville, A. N., and Meyer, C. D. Deeper inside pagerank. Internet Mathematics
1, 3 (2004), 335–380.
[16] Langville, A. N., and Meyer, C. D. Google’s PageRank and beyond: The science
of search engine rankings. Princeton University Press, 2011.
[17] Larsson, A. O., and Moe, H. Studying political microblogging: Twitter users in
the 2010 swedish election campaign. New Media & Society 14, 5 (2012), 729–747.
[18] Lee, K., Caverlee, J., and Webb, S. Uncovering social spammers: Social honey-
pots + machine learning. In ACM SIGIR Conference on Research and Development
in Information Retrieval (2010), pp. 435–442.
[19] Lee, K., Eoff, B. D., and Caverlee, J. Seven months with the devils: A long-term
study of content polluters on twitter. In ICWSM (2011).
[20] Mccord, M., and Chuah, M. Spam detection on twitter using traditional classi-
fiers. In International Conference on Autonomic and Trusted Computing (2011),
pp. 175–186.
[21] Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and Dean, J. Distributed
representations of words and phrases and their compositionality. In Advances in
Neural Information Processing Systems (NIPS) (2013), pp. 3111–3119.
[22] Miller, Z., Dickinson, B., Deitrick, W., Hu, W., and Wang, A. H. Twitter
spammer detection using data stream clustering. Information Sciences 260 (2014),
64–73.
[23] Robbins, H., and Monro, S. A stochastic approximation method. In Herbert
[24] Sedhai, S., and Sun, A. Semi-supervised spam detection in twitter stream. IEEE
[25] Shrivastava, A., and Li, P. In defense of minhash over simhash. In Artificial
[26] Site, W. W. W. A. Twitter usage statistics. http://www.internetlivestats.com/
Robbins Selected Papers. Springer, 1985, pp. 102–109.
Transactions on Computational Social Systems 5, 1 (2018), 169–175.
Intelligence and Statistics (2014), pp. 886–894.
one-second/#tweets-band, 2019.
[27] Steinbach, M., Karypis, G., and Kumar, V. A comparison of document clustering
techniques. In KDD Workshop on Text Mining (2000), pp. 525–526.
[28] Stringhini, G., Kruegel, C., and Vigna, G. Detecting spammers on social
networks. In Annual Computer Security Applications Conference (ACSAC) (2010),
pp. 1–9.
[29] Thomas, K., Grier, C., Song, D., and Paxson, V. Suspended accounts in ret-
rospect: an analysis of twitter spam. In ACM SIGCOMM conference on Internet
measurement conference (2011), pp. 243–258.
[30] Thomas, K., McCoy, D., Grier, C., Kolcz, A., and Paxson, V. Trafficking fraud-
ulent accounts: The role of the underground market in twitter spam and abuse.
In USENIX Security Symposium (2013), pp. 195–210.
[31] Wang, A. H. Don’t follow me: Spam detection in twitter. In IEEE International
Conference on Security and Cryptography (SECRYPT) (2010), pp. 1–10.
[32] Wang, B., Zhang, L., and Gong, N. Z. Sybilscar: Sybil detection in online social
networks via local rule based propagation. In IEEE International Conference on
Computer Communications (INFOCOM) (2017), pp. 1–9.
[33] Wang, G., Wang, T., Zheng, H., and Zhao, B. Y. Man vs. machine: Practical
adversarial detection of malicious crowdsourcing workers. In USENIX Security
Symposium (2014), pp. 239–254.
[34] Wu, T., Liu, S., Zhang, J., and Xiang, Y. Twitter spam detection based on deep
learning. In ACM Australasian Computer Science Week Multiconference (2017),
pp. 3:1–3:8.
[35] Yang, C., Harkreader, R., Zhang, J., Shin, S., and Gu, G. Analyzing spammers’
social networks for fun and profit: a case study of cyber criminal ecosystem
on twitter. In ACM International World Wide Web Conference (WWW) (2012),
pp. 71–80.
[36] Yang, C., Zhang, J., and Gu, G. A taste of tweets: reverse engineering twitter
spammers. In ACM Annual Computer Security Applications Conference (ACSAC)
(2014), pp. 86–95.
[37] Yu, H., Gibbons, P. B., Kaminsky, M., and Xiao, F. Sybillimit: A near-optimal so-
cial network defense against sybil attacks. IEEE/ACM Transactions on Networking
(ToN) 18, 3 (2010), 885–898.
[38] Yu, H., Kaminsky, M., Gibbons, P. B., and Flaxman, A. Sybilguard: defend-
ing against sybil attacks via social networks.
In ACM SIGCOMM Computer
Communication Review (2006), vol. 36, pp. 267–278.
[39] Zhang, Y., Zhang, H., Yuan, X., and Tzeng, N.-F. Pseudo-honeypot: Toward effi-
cient and scalable spam sniffer. In 49th Annual IEEE/IFIP International Conference
on Dependable Systems and Networks (DSN) (2019).
Session 5A: Web SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand390