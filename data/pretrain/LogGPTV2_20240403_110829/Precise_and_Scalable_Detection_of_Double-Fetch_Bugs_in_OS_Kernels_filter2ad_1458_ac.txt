to change it, say uattr->size = 0xFFFFFFFF, which will be
copied to attr->size and cause trouble if it is later used
without caution (line 24). The memory access pattern is also
visualized in Figure 4b, which clearly shows that the two
fetches have an overlap of four bytes and the constraints on
this overlapped region across different fetches are different.
Given that both control dependence (i.e., the sanity checks)
and data dependence (i.e., size is used in the second fetch)
are established between the two fetches, the correct way to
check for a double-fetch bug is to try an equality proof (i.e.,
proving that size == attr->size), as explained in §III. Since
this cannot be proved, DEADLINE ﬂags this multi-read as a
double-fetch bug.
The symbolic execution procedure is shown in Figure 4c.
Note that, for illustration purpose, we use $X to denote the
symbolic value of the variable and @X to denote the object in
memory that is pointed to by $X. If $X is not a pointer, @X is
1If there are multiple paths inside the loop body, DEADLINE unrolls the
loop multiple times, each covers one path.
666
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply. 
nil. A memory object can be accessed by a triple ,
which means a memory access from byte i to byte j. The label
L can be either K or U, indicating whether this is a kernel or
userspace access, and for userspace accesses, the labels can be
U 0, U 1, etc. to denote that this is the ﬁrst or second access to
that memory object region.
Due to space constraints, a much more complicated example
that illustrates two additional features of DEADLINE, loop
handling and pointer resolving, is shown in Appendix §A,
Figure 7.
B. Transforming IR to SR
Transforming the LLVM IR to SR is the same as symbolically
executing the LLVM instructions along the path. In particular,
each variable has an SR while the instructions and function
calls deﬁne how to derive these SRs and the constraints
imposed. All the SRs are derived from a set of root SRs, which
could be function arguments, global variables (both denoted
as PARM), or two special types of objects, KMEM and UMEM, that
represent memory blobs in kernel and userspace, respectively.
Function arguments and global variables are considered roots
because their values are not deﬁned by any instructions along
the execution path. Similarly, the initial contents in KMEM
and UMEM are unknown, and therefore we also treat them as
root SRs, although along the execution their contents can
be deﬁned through operations such as memcpy, memset, and
copy_from_user.
Symbolic execution of the majority of LLVM instructions is
straightforward. For example, to symbolically execute an add
instruction %3 = add i32 %2 16, DEADLINE simply creates
a new SR, $3, and sets it to $3 = $2 + 16. However, three
types of instructions need special treatment: branch instructions,
library functions/inline assemblies, and memory operations.
Branch instructions. As stated before, DEADLINE does not
perform new path discovery during symbolic execution; instead,
it only follows along a speciﬁc path (i.e., a sequence of
IR instructions) prepared before the symbolic execution, as
illustrated in detail in §V-B. Therefore, whenever DEADLINE
encounters a branch instruction, it looks ahead on the path,
checks which branch is taken, and uses this information to infer
the constraints that must be satisﬁed by taking that branch,
i.e., whether the branch condition is true or false. After doing
that, DEADLINE adds this constraint to its assertion set so that
later when solving (or proving), it ensures that this constraint
is met (or cannot be met). In the running example in Figure 4,
line 10, 11 in 4c illustrate this procedure. This is in contrast to
traditional symbolic executors [13], [14], [15] which fork states
and try to cover both branches upon encountering a branch
instruction.
Library functions and inline assemblies. Although the
kernel does not have the notion of standard libraries like
libc, common functionalities such as memory allocation are
abstracted out, and most of them reside in the lib directory
in the kernel source tree. These library functions can be
generally categorized into ﬁve types: 1) memory allocations
(e.g., kmalloc), 2) memory operations (e.g., memcpy), 3) string
operations (e.g., strnlen), 4) synchronization operations (e.g.,
mutex_lock), and 5) debug and error reporting functions
(e.g., printk). We choose to not let DEADLINE symbolically
execute into these functions;
instead, we manually write
symbolic rules for each of these functions to capture the
interactions between their function arguments and return values
symbolically. Fortunately, for the purpose of double-fetch bug
detection, there are only 45 and 12 library functions we need
to handle for the Linux and the FreeBSD kernel, respectively,
which incurs a reasonable amount of manual effort.
In terms of inline assemblies, although they are commonly
found in kernel code, not many of them are related to double-
fetch bug detection and hence will be ﬁltered out early without
showing in the execution path. For those that commonly appear
in the execution paths (e.g., bswap), we write manual rules to
approximate their effects on the symbolic values and ignore
the rest, i.e., assuming them to have no effects.
C. Memory model
Traditional symbolic executors model memory as a linear
array of bits or bytes and rely on the select-store axioms
and its extensions [20], [21] to represent memory read and
write. The select expression, select(a, i), returns the value
stored at position i of the array a and hence models a memory
read, while a store(a, i) returns a new array identical to a,
but on position i it contains the value v and hence models
a memory write. This model has been proven successful by
symbolic executors like KLEE [14] and SAGE [15]. However,
it cannot be directly applied in DEADLINE for double-fetch
bug detection.
One missing piece in this memory model is that two reads
from the same address are assumed to always return the same
value if there is no store operation to that address between
the reads. While this is true for single-threaded programs (or
multi-threaded programs with interleavings ﬂattened), it does
not hold for userspace accesses from kernel code, as a user
process might change the value between the two reads, but
those operations will not be backed by a store in the trace. In
fact, if DEADLINE adopts this assumption, DEADLINE would
never ﬁnd a double-fetch bug.
To address this issue, DEADLINE extends the model by
encoding a monotonically increasing epoch number in the reads
from userspace memory to represent that the values copied
in at different fetches can be different. However, for kernel
memory reads, DEADLINE does not add the epoch number
and does assume that every load and store to the address is
enclosed in the execution path. Otherwise, it becomes a kernel
race condition, which is out of the scope for DEADLINE and is
assumed to be nonexistent. To infer whether a pointer points to
userspace or kernel memory, DEADLINE relies on the __user
mark and considers that any pointer marked as __user is a
userspace pointer (e.g., variable uattr in line 2, Figure 4a),
and a pointer without the __user mark points to kernel memory
(e.g., variable attr, in line 3, Figure 4a).
Another extension DEADLINE has to make to the memory
model is that instead of assuming the whole memory to be an
667
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply. 
u32 size;
return -EFAULT;
// sanity checks
if (size > PAGE_SIZE ||
(struct perf_event_attr __user *uattr,
struct perf_event_attr *attr) {
// first fetch
if (get_user(size, &uattr->size))
1 static int perf_copy_attr_simplified
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21 }
22 // Example: if attr->size is used later
23 // BUG: attr->size can be very large
24 memcpy(buf, attr, attr->size);
// second fetch
if (copy_from_user(attr, uattr, size))
size = PERF_ATTR_SIZE_VER0
12 ---
13 // second fetch
14 fetch(F2) is {A = $0, S = $2}
15 @1(0, $2 - 1, K) = @0(0, $2, U1)
16 ---
17 // check fetch overlap
18 assert F2.A  satisfiable with @0(4, 7, U)
21
22 // check double-fetch bug
23 prove @0(4, 7, U0) == @0(4, 7, U1)
24 // --> fail, no constraints on @0(4, 7, U1)
(c) Symbolic representation and checking
(a) C source code
(b) Memory access patterns
Fig. 4: A double-fetch bug in perf_copy_attr, with illustration on how it ﬁts the formal deﬁnition of double-fetch bugs (4b) and DEADLINE’s
symbolic engine can ﬁnd it (4c).
int x1, x2;
get_user(x1, uptr1);
if(x1 == 0)
(struct request __user *up,
struct request *kp) {
// up buf)
1 static int not_buggy1
(int __user *uptr1,
2
int __user *uptr2) {
3
// uptr1 buf;
// cannot prove ubuf == up, so
// ubuf buf, kp->len);
return kbuf;
get_user(x2, uptr2);
return x2;
return -EINVAL;
return -EINVAL;
array of bytes (or bits), DEADLINE uses an array of bytes to
represent each single memory object and maps each pointer
to one memory object. DEADLINE uses a few empirical rules
to create this mapping: 1) Different function arguments or
global variables are assumed to be pointing to different memory
objects (if they are pointers or integers that can be casted to
pointers); 2) Newly allocated pointers (via kmalloc, etc) are
assumed to be pointing to new memory objects; 3) When an
assignment occurs, the object is also transferred (e.g., assigning
a function argument to a local variable), meaning that the local
variable is pointing to the same object as the argument. In fact,
this is implicitly handled by the SSA form of the LLVM IR;
4) For any other pointer, if we cannot prove that its value falls
in the range of any existing object, assume it points to a new
object. For example, a pointer like (&req->buf) is considered
as pointing to a subrange of the req object, while req->buf is
considered as pointing to a new object.
Furthermore, when checking for double-fetch bugs,
DEADLINE considers only the cases where the address pointers
668
are pointing to the same userspace object. For example, in
both cases shown in Figure 5, DEADLINE cannot prove that
the two fetches come from the same userspace memory object.
Therefore, DEADLINE does not mark them as double-fetch
bugs. This design decision is made based on some implicit
programming practices. For example, there is no need to pass
in two pointers that point to the same memory region (i.e., the
case of uptr1 == uptr2 on the left side of Figure 5); or it is
very uncommon to copy from cyclic buffers (i.e., the case of
up->buf == up on the right side of Figure 5). However, in the
case where DEADLINE can prove that two pointers have the
same value, the memory object reference is also transferred,
as shown in the case of Figure 7c, line 20.
D. Checking against the deﬁnitions
Upon ﬁnishing the translation from IR to SR, DEADLINE
invokes the SMT solver to check whether all conditions listed
in §III can be met.
DEADLINE ﬁrst checks whether the two fetches, F0 =, F1 =, share an overlapped memory
region. To do this, on top of the path constraints (which are
already added to the solver during symbolization), DEADLINE
further adds the constraint (A1 ≤ A0  and should be interpreted
as that byte i to j in userspace object N being copied into the
kernel twice in this multi-read. In the running example, there
is one overlap, , as shown in line 20.
If there are no overlapped regions, this multi-read is consid-
ered safe. Otherwise, for each overlap identiﬁed, DEADLINE
further checks whether there is control dependence or data
dependence established based on this region:
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:58 UTC from IEEE Xplore.  Restrictions apply. 
• In the case of control dependence only, collect
the
(denoted as C0) and
constraints
@N (i, j, U 1) (denoted as C1) and prove that C1 is the
same as C0 or is even more restrictive than C0.
for @N (i, j, U 0)
of
data
that
@N (i, j, U 0) == @N (i, j, U 1), as shown in line
23 of the running example.
dependence,
prove
• In the very rare cases where there is no relation found,
• In
the
case
there is a redundant fetch.
Depending on the result, DEADLINE marks the multi-read
as safe if the above proofs succeed and a bug otherwise.
VII. IMPLEMENTATION
DEADLINE is implemented as an LLVM pass (6,395 LoC)
based on LLVM version 4.0 and uses Z3 [22] version 4.5 as
its theorem prover. The rest of this section covers the most
important engineering problems we solved when developing
DEADLINE, including maximizing code coverage and compil-
ing and linking kernel source into LLVM IR. Due to space
constraints, interested readers might refer to Appendix §B for
the program slicing and loop unrolling algorithms used in
execution path construction.
A. Maximize code coverage
To detect double-fetch bugs for the whole kernel, we need
to compile not only the kernel base but also as many modules
as possible, including drivers, ﬁle systems, and peripheral
modules that are rarely compiled in the generic conﬁguration.
In addition, within a source ﬁle, the actual code compiled is