20%
30%
20%
18%
20%
10%
3%
3%
10%
10%
20%
20%
Video engagement growth
35%
20%
40%
15%
20%
25%
60%
35%
10%
43%
40%
40%
25%
Table 1: Video traffic growth and video engagement growth
for selected countries.
Figure 6: Global Average Bad Session Rate (BSR) and country
rates for US and India.
Figure 7: BSR evolution in main European countries.
diversity (making sure every continent is represented) and size
(including major markets for Facebook like India and the US).
As shown in Table 1, we notice a significant gap in growth rates
between peak video traffic and daily video engagement in a number
of countries. While we cannot pinpoint the exact reason for this
gap, it could be an indicator of deteriorating network conditions
and bandwidth limitations forcing a dynamic adaptation of video
bitrates.
Video QoE Overview: To better understand these gaps in growth
rates we now look at changes in video Quality of Experience (QoE).
Note that our usage of QoE here is in line with existing research [4,
11, 12, 24].
In order to assess video QoE, we use a composite metric called
bad session rate (BSR). A video session is considered bad if it satisfies
one or more of the following conditions: it has a slow start (> 1
sec), it witnesses frequent stalls (mean time between rebuffering <
1 min) or if the video encoding resolution is poor given the used
Figure 8: BSR evolution for selected South American coun-
tries.
screen. BSR is the ratio of video sessions classified as bad of all
video sessions delivered in a given timeframe or geography. The
higher BSR the more significant is the number of users witnessing
a poor video QoE.
Figures 6, 7 and 8 showcase a surge in the percentage of bad video
sessions globally during the second half of March, with the highest
percentage (about 8%) around March 25.2 Global BSR eventually
recovered to pre-Covid-19 levels beginning of April and contin-
ued to decline afterwards. Looking at regional and country-level
curves we notice that video QoE degradation did not happen in
all countries and regions. Namely, video QoE degradation mainly
happened in India, some countries in Sub-Saharan Africa, and some
South American countries while North America and Europe did
not witness major video QoE regressions. We infer that BSR surge,
when applicable, was driven by Covid-19-induced traffic growth for
the following reasons. First, BSR surges and traffic surges happened
simultaneously (around the same dates) in impacted countries. Sec-
ond, while BSR degradation happened before, the level of BSR
degradation in the most impacted countries (India and South Africa)
is unprecedented which parallels the fact that Covid-19-induced
traffic growth is also unprecedented. Finally, BSR recovered to its
normal pre-Covid-19 values in the most impacted countries only
after operator intervention (e.g., video bitrate capping or rate limit-
ing) and traffic volumes eventually stabilized. We also note that the
countries where BSR degraded have a significant gap between their
video traffic and video engagement growth rates, which confirms
our hypothesis of network stress.
Overflow to transit and public peering: After looking at the
impact to user perceived quality of experience, we now look at the
underlying network and how it performed over the same period
of time. For a variety of economic and performance reasons, many
ASes have a preference for direct interconnections over interconnec-
tions via a public exchange or via a transit intermediary. While there
are business-strategic reasons to not use the most cost-effective
interconnection in some cases, this order of preference is valid in
the vast majority of cases. This is important as increased usage of
indirect interconnection links can be seen as a sign for congestion
on the preferred, direct connection links.3 For a detailed discussion
2Note that all three figures show a correlated peak across all metrics in the second
half of April. While we cannot pinpoint the exact cause, we acknowledge that this
specific peak might have been caused by our systems rather being Covid-19 induced.
3While direct congestion measurements might yield better results, we did not have
such available for this paper.
37
0%2%4%6%8%10%12%14%MarAprMayAvg. Bad Session RateGlobalINUS0%1%2%3%4%5%MarAprMayAvg. Bad Session RateFRITESGBCH0%2%4%6%8%10%12%14%MarAprMayAvg. Bad Session RatePECOECBRHow the Internet reacted to Covid-19 – A perspective from Facebook’s Edge Network
IMC ’20, October 27–29, 2020, Virtual Event, USA
Figure 9: Indirect traffic Growth Global
Figure 11: Average round-trip time globally and for selected
countries. Normalized against values of March 01, 2020. Gl
is global RTT.
Figure 10: Growth of indirect traffic for selected countries.
of routing and overflow policies and their technical implementation
see the papers by Schlinker et al. [28, 29].
In Figure 9, we showcase the growth of indirect traffic globally,
computed as the ratio between the daily observed peak of indirect
traffic post March 01, 2020 and peak indirect traffic on March 01,
2020. At a global level, we see between 5% and about 25% growth in
indirect traffic flowing through transit and public peering during
the second half of March, coinciding with the global surge in traffic.
While not shown in this figure, we equally see that the indirect
traffic contributes more to global egress in the second half of March,
although this additional contribution is less than 1% globally. This
indicates that, due to congestion, traffic started to overflow from
direct links towards public peering and transit routes. The growth
in indirect traffic eventually stabilizes in April.
When looking at per country figures in Figure 10, we observe
variable growth rates of indirect traffic. For instance, countries
that experienced degradation in QoE for video – like India and
South Africa – show higher growth rates for traffic over transit and
public peering compared to the growth of similar traffic in the USA
and other countries where video QoE remained stable. We observe
similar tendencies when we look at different South American or
European countries.
This comparison reveals that globally the Internet was able to
cope with the increased demand. While we see more traffic over-
flowing to indirect links, the additional contribution of indirect
traffic to overall traffic did not exceed 1%. For those individual coun-
tries where we saw a non-negligible impact on user experience, we
also see a higher growth in indirect traffic. India is a clear case with
indirect traffic almost doubling early April with respect to begin-
ning of March. However, even for India, the extra contribution of
indirect traffic to overall traffic remained less than 1%. Traffic over-
flow to indirect paths hints at congestion on the preferred direct
traffic links which, along with a possible access network congestion,
is likely to be one of the factors contributing to the reduced user
experience we observed.
Round Trip Times: Path congestion typically goes hand in
hand with increased round trip times. Figure 11 shows observed
round-trip times of client connections measured from our servers.
Similar to the other metrics we observe, we see an increase in
average global round trip time in the second half of March. From
April onwards RTT values start to decrease again. At the end of
the observation period, the average global round trip time is only
slightly elevated at 1.1x the value of the beginning of March.
On a country level we see differences between those countries
that showed regression in video quality versus those that showed
less pronounced regressions. Server-side round trip times are rea-
sonably stable for the USA and Spain, which is in line with their
stable video performance. Italy shows slightly more pronounced
variation of RTTs, which again is in line with the relatively small
degradations in video performance we observed. The last two coun-
tries in this figure, South Africa and India, show significant increases
in RTT. And again, these are two countries in which we also ob-
served significant degradations in user-perceived video quality. This
reinforces our finding that the degradations in video performance
we observed in some countries can be attributed to limited capacity
and thus congestion in the country’s networks.
Discussion: For all the countries in our observation set we see
that degraded video experience always coincides with an increase
in network metrics like RTT and the amount of traffic overflowing
to indirect links. While RTT and video QoE degradation could
be attributed to traffic rerouting to secondary CDN locations via
indirect links, we do believe that these metrics are strong pointers
towards network congestion, both from the CDN side and on the
last-mile network for the following reasons. First, traffic rerouting
to indirect and distant CDN locations is usually triggered by a
congestion of direct traffic links. Second, the amount of degradation
in video QoE and in RTT cannot be explained by the relatively
small additional contribution of indirect traffic to overall traffic.
Therefore, the hypothesis of a last-mile congestion causing video
QoE degradation and longer RTTs, followed by a congestion on
the CDN direct peering links triggering traffic overflow to indirect
links, is the most plausible for the most impacted countries.
38
 0.85 0.9 0.95 1 1.05 1.1 1.15 1.2 1.25MarAprMayIndirect traffic 0.6 0.8 1 1.2 1.4 1.6 1.8 2 2.2 2.4 2.6MarAprMayIndirect trafficINUSZA 1 1.2 1.4    rel. Avg. RTTGlZAINITUSES 0.9 1 1.1MarAprMayJunIMC ’20, October 27–29, 2020, Virtual Event, USA
Timm Böttger, Ghida Ibrahim and Ben Vallis
In summary, while Covid-19 did not cause widespread conges-
tion, the induced additional traffic load did indeed cause localized
congestion in some countries.
6 RELATED WORK
The Covid-19 pandemic is not the first event that forced the Internet
to react. It has always adapted to predictable one-off events like New
Year’s Eve and major broadcasts as well as to unpredictable events
like flash crowds. Ari et al. and Stading et al. study flash crowds
and how flash crowds can be characterized and modeled [3, 30].
There are also works providing a characterization of a wider range
of traffic anomalies, including denial of service attacks, network
outages, and traffic engineering [21].
Beyond these organic outages caused by user behavior, there are
also works studying outages caused by externalities. These studies
cover for example (severe) weather conditions like Hurricanes [13],
the impact of rain [25] or power outages on the Internet [5].
Although the Covid-19 pandemic is a recent event only, its impact
on Internet infrastructure has already been widely been discussed
through blog posts from individual companies [1, 2, 10, 15, 18, 31]
as well as at network operator meetings [8, 19].
The academic community has also turned to studying the im-
pact of Covid-19. Ribeiro et al. study how Wikipedia received sig-
nificantly more user requests and how the user’s interest shifted
towards medical topics with the outbreak of Covid-19 [27]. Vu et al.
investigate how cybercrime has risen during the pandemic [32]. Za-
karia et al. rely on passive WiFi sensing in order to study the impact
of Covid-19 policies on campus occpuancy and mobility [38]. Favale
et al. utilise a campus network dataset to study how e-Learning has
changed their traffic profile [16]. Similar to our work, Feldmann et
al. and Lutu et al. [17, 23] also study how the pandemic has changed
Internet traffic. These studies use IXP or ISPs with a local (albeit
country-wide) footprint, whereas our study draws conclusions from
the vantage of a global network. We believe (and encourage the
reader to do so) that these studies should be read in conjunction,
as their perspectives differ because of the different vantage points
that were used.
7 DISCUSSION
The changes in user behavior and increased demand caused by the
Covid-19 pandemic have put unprecedented stress on the Internet.
In fact, it is the largest traffic surge we have ever observed on a
global level. In this section we discuss what we have learned from
an operator’s perspective and suggest measures the Internet might
take to better cope with future events.
At the beginning of the pandemic Facebook, as well as many
other organizations, was able to quickly add additional network
capacity in sufficient amounts to mitigate the largest increases in
user demand. This capacity augmentation was only possible due to
network gear already in place inside many networks, which now
could quickly be utilized to activate more capacity. This highlights
the importance of building network infrastructure with a long
enough outlook that also factors in headroom to quickly react to
changes.
These capacity augmentations however mostly helped at peering
points and traffic exchanges that are on the edge of the Internet but
not the actual last mile to the end user. Adding a similar amount of
39
capacity to last mile access networks is significantly more challeng-
ing and expensive. During this pandemic we have seen that, while
the core of the Internet handled traffic increases relatively well, the
middle and last mile access networks especially in less-developed
regions have struggled. It is also clear these aspects of the Internet
are crucial for good product performance.
Large hypergiants [7, 20] have long realized and tried to combat
this issue. One way is to embed off-network caching servers deeply
in the access network to relieve middle-mile pressure from their
peering exchange point to the end user [6, 9]. Last mile networks
have their own set of challenges, and companies like Google and
Facebook have long running initiatives to help develop open, cost
effective solutions to help with this aspect of providing network
service [14, 22, 26]. These initiatives exist as the burden to build
infrastructure to cope with large increases is often too high for ISPs
in less developed countries. We believe that open standards and
open technology are one way to decrease this burden.
Lastly, this pandemic has shown that the Internet is an ecosystem
that thrives through the cooperation of all stakeholders. It is this
cooperation that made the Internet scalable and reliable in face of
the pandemic. We therefore believe that open communication and
discussion between all stakeholders, e.g., traffic consumers, traffic
producers and intermediaries is vital for the success story of the
Internet to continue.
8 CONCLUSION
In this paper we used Facebook’s edge network serving content to
users across Facebook’s family of apps to provide a perspective on
how the Internet coped with and reacted to the surge in demand
induced by Covid-19.
We showed that the increase in traffic demand was substantial
but that this surge was limited to a short period of time, with traffic
subsequently stabilizing at heightened levels.
We then studied how these significant changes in user behav-
ior translated into new traffic trends across products and access
types. While a surge in the popularity of livestream and messag-
ing products was accompanied by significant traffic increases for
those products, the largest traffic impact resulted from the relatively
lower traffic growth of video products. Moreover, we found that
traffic increases occurred mainly on broadband networks.
Finally, we assessed the impact of this traffic surge on network
stress and performance, where we observed an uneven regional
distribution. While North America and Europe did not show any
signs of stress in their networks, India and parts of Sub-Saharan
Africa and South America did witness signs of network stress trans-
lating into degraded video experience, higher amount of traffic
overflowing to indirect links and secondary CDN locations, and
higher network round trip times. While we cannot pinpoint the
exact causes of network stress, we do know that it can be caused
by a variety of factors including congestion of direct CDN peer-