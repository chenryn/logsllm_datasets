Although both queries look similar, when it comes to tail queries, Lucene‚Äôs implementation can be very inefficient, due to the follow-ing reasons.
The iterators implemented in Lucene only support one-way iterations. Therefore, for tail queries, we have to iterate through all data till the end, as is shown in Figure 7. The complexity of this process is ùëÇ(ùëõ), where ùëõ is the number of the documents that meet the condition.Even if we add support for reverse iteration on top of Lucene, tail queries would still be inefficient. The reason is that the reverse access to disks would render the file cache provided by operating systems ineffective.
Therefore, to address the inefficiency of tail queries, we propose the Reverse Binary Search algorithm. The algorithm is implemented
66
Figure 9: Optimization for histogram queries. The number of logs in certain bins are directly calculated using the docids of the endpoints. For example, for bin [ti, tj), the corresponding number of logs is calculated as docid_j - docid_iOur solution is that, instead of checking the timestamp of every hit log document, we only need to gather the edge of each bin of the histogram. The reason is that since the logs are sorted, the number of logs within a particular bin can be directly calculated by the docids of the two endpoints. With such technique, we reduce the number of look-ups from tens of thousands to under ten.The process is shown in Figure 9.
5 	EXPERIMENTAL EVALUATION
The experimental evaluations are mainly to demonstrate the effec-tiveness of the design of the search engine in TencentCLS.Overall, the experiments consist of two parts: offline experiments with open benchmarks and online experiments with real world data. The first part of experiments is relatively cheap to perform, we use them to analyze the performance gains of our methods under various scenarios. The second part, on the other hand, provide more convincing evidences of the effectiveness of our solution, since it utilizes real-world data at TencentCLS.5.1 	Open Benchmark Evaluation
In the open dataset experiments, we quantitatively investigate the effectiveness of the query optimizations in a single-machine sce-nario.
The experiment is performed on Tencent Cloud machines, each with a 16-core vCPU and 64 GB of ram. The storage devices are local NVMe SSD drives (IT3.4XLARGE64), local SATA HDD drives (D3.4XLARGE64) and Tencent Premium Cloud Storage.The benchmark we use is the NYC taxi benchmark provided by esrally R. The dataset consists of taxi rides information in New York in 2015, and contains up to a total of 12 billion documents. Some important statistics for this benchmark are listed in Table 1.
	The experiments are designed with the goal of analyzing the performance increases in the following scenarios.(1) Different types of queries: head queries, tail queries, and his-togram queries (defined in Section 4.5.2 and Section 4.5.3).
7
Table 2: Performances when turning on and off different optimization techniques. Multiplier refers to the boost mul-tiplier of current optimization config, compared with the previous one. Accumulative Multiplier refers to the accumu-lative boost multiplier of the current optimization config. CPU / query refers to the CPU usage per query (CPU usage percentage * time). rMB refers to the disk read per query.Head Query 
Service Time CPU / query rMB / query
 No Optimizations 604124.0 200.5 452.7
(a) Head Queries
| O0 
Multiplier 
Acc. Multiplier | 50318.2 
12.0 
12.0 | 7.3 
27.6 
27.6 | 37.3 
12.1 
12.1 |
|---|---|---|---|
| O0 + O1  Multiplier  Acc. Multiplier |17224.8  2.9  35.1 |5.5  1.3  36.5 |12.5  3.0  36.2 |
| O0 + O1 + O2 + O3 Multiplier  Acc. Multiplier |15904.2  1.1  38.0 |5.2  1.1  38.9 |12.1  1.0  37.3 ||  |Tail Query Service Time |CPU / query |rMB / query |
(b) Tail Queries No Optimizations 585014.0 196.0 438.4
(c) Histogram Queries
Figure 10: Performances for three types of queries with dif-ferent optimization options
On top of that, the turning on the secondary index (O1) further increases the head query performances by 3x, but has little effect on the performances of other types of queries.Furthermore, the Reverse Binary Search Optimization technique (O2) increases the tail query performances by 3.5x, while the His-togram Optimization technique (O3) increases the histogram query performances by 1.6x.
	The results are shown in Figure 10, distinguishing the perfor-mances under different user counts, as well as in Table 2.5.1.3 	RQ3. How does the choice of the storage option affect the query performance, before and after the optimization? Tencent Cloud provides a series of customizable storage options, among which
8
Table 3: The specifications of different storage solutions at Tencent Cloud. IOPS is tested with 4 KiB IO, and throughput is tested with 256 KiB IO.
| Disk Type | IOPS | Throughput |
|---|---|---||---|---|---|
| Premium Cloud Storage NVMe SSD  SATA HDD |6,000  650,000 200 |150 MB/s 2.8 GB/s 190 MB/s |
important, because they not only show the comparison of effective-ness of the optimization techniques, but also serve as a guidance for choosing the storage option.
Tencent Cloud Premium Cloud Storage is a hybrid storage option. It adopts the Cache mechanism to provide a high-performance SSD-like storage, and employs a three-copy distributed mechanism to ensure data reliability.SATA HDD is the most economical option suitable for scenarios that involve sequential reading and writing of large files, but its random access performance is relatively low.
	NVMe SSD has the highest performance. But its low cost perfor-mance ratio restricts its strength in the log service scenarios.
	Table ?? shows the comparison of the specifications of the three storage options.The experimental results with different storage options are shown in Table 4. We can draw the following conclusions. First, the NVMe SSD option consistently outperform other storage options, while the Tencent Premium Cloud Storage option is less than an order of magnitude behind. Second, compared with the NVMe SSD, the Tencent Premium Cloud Storage consistently enjoys more benefits from the query optimization techniques.5.1.4 	RQ4. Will the increase of timestamp precision level impact the query performances? It is also the goal of Cloud Log Service to sup-port storing and querying higher-precision timestamps. Therefore, it is important to check how does the increase of the timestamp pre-cision level impact the query performance. To this end, we change the timestamp from second to millisecond, and analyze the query performance. The data also comes from the experiments using Tencent Premium Cloud Storage.Interestingly, as is shown in Figure 11, increasing the timestamp precision has almost no impact on the query performance, thanks to the search engine design in TencentCLS.The reason is that although the precision increases, the frequency of the log writes stays the same. Although theoretically some oper-ations such as locating the endpoints will get slower, after applying the secondary index optimization, the difference in costs is sig-nificantly reduced. Also, those precision-sensitive operations do not take up a large proportion of the total service time. Therefore, generally speaking, the performance is virtually unaffected by the time precision.In fact, the online version of TencentCLS is running with microsecond-level time precision thanks to the search engine design, while many vendors are providing second-level time precision log services.
9Table 4: Comparison of performance improvements among different storage solutions. For each storage solution, three rows list the native performances, the performances after optimizations, and the multipliers for performance improve-ments, respectively. The results are tested under 200 concur-rent users for Premium Cloud Storage and NVMe SSD, and under 150 concurrent users for SATA HDD because of the its limited performance.| Head Query 
Service Time | Head Query 
Service Time | Head Query 
Service Time | CPU / query | rMB / query |
|---|---|---|---|---|
| Premium Cloud Storage |604124.0 15904.2 |200.5  5.2 |200.5  5.2 |452.7  12.1 |
| NVMe SSD |38.0  84986.6 2704.1 |38.9  405.6  9.0 |38.9  405.6  9.0 |37.3  459.4  9.6 |
| SATA HDD |31.4  1426810.0 108863.0 |45.3  215.7  8.6 |45.3  215.7  8.6 |47.6  423.9  14.0 || 13.1 |13.1 |25.1 |25.1 |30.2 |
| Tail Query  Service Time |Tail Query  Service Time |CPU / query |CPU / query |rMB / query |
| Premium Cloud Storage |585014.0 23931.0 |196.0  34.4 |196.0  34.4 |438.4  17.1 |
| NVMe SSD |24.4  77402.1  13134.5  5.9  1448450.0 183195.0 |5.7  370.8  61.1  6.1  211.7  35.7 |5.7  370.8  61.1  6.1  211.7  35.7 |25.6  449.6  17.3  26.0  433.2  17.7 || SATA HDD |24.4  77402.1  13134.5  5.9  1448450.0 183195.0 |5.7  370.8  61.1  6.1  211.7  35.7 |5.7  370.8  61.1  6.1  211.7  35.7 |25.6  449.6  17.3  26.0  433.2  17.7 |
| 7.9 |7.9 |5.9 |5.9 |24.5 |
| Histogram Query  Service Time 	CPU / query |Histogram Query  Service Time 	CPU / query |Histogram Query  Service Time 	CPU / query |Histogram Query  Service Time 	CPU / query |rMB / query || Premium Cloud Storage |584511.0 76893.0 |116.4  39.8 |116.4  39.8 |438.0  57.0 |
| NVMe SSD |7.6 53759.4 17333.5 |2.9  237.7  77.4 |2.9  237.7  77.4 |7.7  425.5  48.9 |
| SATA HDD |3.1  1326030.0 465770.0 |3.1  130.9  42.4 |3.1  130.9  42.4 |8.7  411.9  58.1 |
| 2.8 |2.8 |3.1 |3.1 |7.1 || 5.1.5 	RQ5. What is the bottleneck of our system? We have also investigated the bottlenecks of our system, by analyzing the CPU usage and the disk IO during the above experiments. As is shown in Table 4, the IO performances the main bottleneck for Premium-Cloud-Storage-based solutions and SATA-HDD-based solutions, while the CPU performances becomes the bottleneck for NVMe-SSD-based solutions. |5.1.5 	RQ5. What is the bottleneck of our system? We have also investigated the bottlenecks of our system, by analyzing the CPU usage and the disk IO during the above experiments. As is shown in Table 4, the IO performances the main bottleneck for Premium-Cloud-Storage-based solutions and SATA-HDD-based solutions, while the CPU performances becomes the bottleneck for NVMe-SSD-based solutions. |5.1.5 	RQ5. What is the bottleneck of our system? We have also investigated the bottlenecks of our system, by analyzing the CPU usage and the disk IO during the above experiments. As is shown in Table 4, the IO performances the main bottleneck for Premium-Cloud-Storage-based solutions and SATA-HDD-based solutions, while the CPU performances becomes the bottleneck for NVMe-SSD-based solutions. |5.1.5 	RQ5. What is the bottleneck of our system? We have also investigated the bottlenecks of our system, by analyzing the CPU usage and the disk IO during the above experiments. As is shown in Table 4, the IO performances the main bottleneck for Premium-Cloud-Storage-based solutions and SATA-HDD-based solutions, while the CPU performances becomes the bottleneck for NVMe-SSD-based solutions. |5.1.5 	RQ5. What is the bottleneck of our system? We have also investigated the bottlenecks of our system, by analyzing the CPU usage and the disk IO during the above experiments. As is shown in Table 4, the IO performances the main bottleneck for Premium-Cloud-Storage-based solutions and SATA-HDD-based solutions, while the CPU performances becomes the bottleneck for NVMe-SSD-based solutions. |(a) Head query performance
(b) Tail query performance
(c) Histogram query performance
Figure 11: Performances with second-level timestamp preci-sion and millisecond-level timestamp precision, evaluated using the total service time (in milliseconds).
5.2 	Online Test
In addition to the offline experiments with open benchmarks, we have also tested the system with real world data.The experiments involve two clusters, one equipped with Elas-ticSearch (version 7.10.1), and the other equipped with the search engine of TencentCLS. Each cluster consists of 3 master nodes as well as 40 data nodes. We select a single large log topic as input, and its data is written to those clusters at the same time.
1010
[13] Matteo Catena, Craig Macdonald, and Iadh Ounis. 2014. On Inverted Index 	Compression for Search Engine Efficiency. In Advances in Information Retrieval 	(Lecture Notes in Computer Science), Maarten de Rijke, Tom Kenter, Arjen P. de 	Vries, ChengXiang Zhai, Franciska de Jong, Kira Radinsky, and Katja Hofmann 	(Eds.). Springer International Publishing, Cham, 359‚Äì371.[14] 990. Optimization for Dynamic Inverted Index Main-	tenance. In Proceedings of the 13th Annual International ACM SIGIR Conference 	on Research and Development in Information Retrieval - SIGIR ‚Äô90. ACM Press, 	Brussels, Belgium, 405‚Äì411. 
[15] Marcus Fontoura, Ronny Le005. Inverted 	Index Support for Numeric Search.[16] Xiaoming Gao, Vaibhav Nachankar, and Judy Qiu. 2011. Experimenting Lucene 	Index on HBase in an HPC Environment. In Proceedings of the First Annual 	Workshop on High Performance Computing Meets Databases - HPCDB ‚Äô11. ACM 	Press, Seattle, Washington, USA, 25. [17] Maurice Herlihy, Yossi Lev, Victor Lue 	Optimistic Skiplist Algorithm. In Structural Information and Communication 	Complexity, Giuseppe Prencipe and Shmuel Zaks (Eds.). Vol. 4474. Springer11