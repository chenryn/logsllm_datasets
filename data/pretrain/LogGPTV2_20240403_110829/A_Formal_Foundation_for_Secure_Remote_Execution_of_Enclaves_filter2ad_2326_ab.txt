e (σ )),
and besides the random bits (I R
e (σ )) from an entropy source, there
are no other sources of non-determinism — we only assume single
threaded enclaves in this work. Since we make this determinism
assumption while defining an enclave’s semantics, we must prove
that the platform does not allow non-determinism.
e (σ ) and I R
The enclave computes by performing steps, where in each step
the enclave platform first identifies the instruction to execute (based
on the current state of vmem and pc), and then transitions to the next
state based on the operational semantics of the platform’s instruc-
tions. The instructions include bitvector operations on registers,
memory accesses, and the enclave primitives for generating attested
statements, randomness, and exiting enclave mode — the platform
also includes privileged instructions (e.g., MSR instructions in x86)
which can cause arbitrary updates to Ae (σ ). This model of execu-
tion lets us define the platform’s transition relation ;, where (σi,
σj ) ∈ ; indicates that the platform can transition from σi to σj;
from hereon, we write this in infix form as σi ; σj. We treat ;
as a relation as opposed to a function to allow non-determinism
for the platform. The non-determinism includes randomness from
entropy sources, direct memory accesses from I/O peripherals, etc.
Let us refer to these bits of non-determinism in a particular state
as I P (σ ), which is only available to the privileged software — the
enclave’s source of non-determinism is captured in Ie (σ ). We re-
quire that the platform be deterministic relative to I P (σ ). A secure
platform must also ensure an enclave program e is deterministic
relative to its input Ie (σ ). We state two properties in § 3 that imply
these determinism guarantees.
2.2 Formal Model of the Adversary
An enclave executes in the presence of a privileged adversary that
has compromised all software layers including the OS, except for the
enclave platform. In this section, we abstractly define the effect of
the adversary’s operations and observations. § 4.2 precisely defines
the set of attacker operations and observations for the TAP.
2.2.1 Adversary Tampering. The privileged adversary may
pause the enclave at any time, and execute arbitrary instructions
that modify the attacker’s state Ae (σ ), enclave’s input IU
e (σ ) for
any enclave e, and launch or destroy any number of enclaves. We
model the adversary’s effect through the tamper relation over pairs
of states: (σ1, σ2) ∈ tamper if the attacker can change the machine’s
state from σ1 to σ2, with the constraint that Ee (σ1) = Ee (σ2). That
is, the attacker may modify Ae (σ1), Ie (σ1), and Oe (σ1), but not the
enclave’s state Ee (σ1). The constraint that tamper does not affect
an enclave’s state is assumed while defining the enclave’s semantics.
Our integrity property (§ 3) for enclave platforms must prove that
this constraint is forced upon the attacker’s operations.
3
tamper ⊂ ; because a software attacker uses the platform’s
instructions to update the platform’s state. Furthermore, tamper is
reflexive because the adversary can always leave state unmodified:
∀σ . (σ , σ ) ∈ tamper. In addition to running concurrently with an
enclave e, the adversary may tamper the machine’s state prior to
launch and modify e’s launch state inite and configuration confige.
2.2.2 Adversary Observations. Untrusted software may also
observe an enclave’s execution, depending on the confidentiality
guarantees provided by the enclave platform. At the very least,
the adversary observes any output, but it may also observe certain
side channels such as memory access patterns. Observations are
performed by executing arbitrary instructions (e.g., any x86 instruc-
tion) and invoking the platform’s primitives (e.g., launching other
enclaves), and then observing the results of these operations. Let
obse (σ ) denote the result of an observation for the machine state σ.
For instance, an attacker that only observes outputs enjoys the ob-
servation function obse (σ ) (cid:17) (Oe (σ )). We specify the observation
functions in detail in § 4.2.
2.3 Enclave Execution with an Attacker
An execution trace of the platform is an unbounded-length se-
quence of states denoted π = ⟨σ0, σ1, . . . , σn⟩, such that ∀i. σi ;
σi +1; π[i] refers to the ith element of the trace. Since the attacker
may pause and resume e at any time, we define e’s execution to
be the subsequence of states from π where e is executing. To that
end, let the function curr (σ ) denote the current mode of the plat-
form, where curr (σ ) = e iff the platform executes enclave e in
state σ. Using this function, we can filter out the steps in π where
e is not executing. We write the resulting sequence as ⟨σ ′
0, σ ′
1,
0)) ∧ ∀i. curr (σ ′
. . . , σ ′
i ) = e. This subse-
quence is the enclave’s execution trace: ⟨(Ie (σ ′
0), Oe (σ ′
0), Ee (σ ′
0)),
. . . , (Ie (σ ′
m ))⟩. Since an execution trace of e only
includes the steps where e invokes an instruction, the attacker may
perform tamper between any two consecutive steps of e’s execution
trace. Therefore, we also have the property that ∀i. (σ ′
i +1) ∈
tamper. This has the effect of havocing Ae (σ ) and IU
e (σ ) in all these
The semantics of an enclave e, denoted(cid:74)e(cid:75), is the set of finite
steps, thus supplying the enclave with fresh inputs at each step.
m⟩2 where inite (Ee (σ ′
m ), Oe (σ ′
or infinite execution traces, containing an execution trace for each
input sequence, i.e., for each value of non-enclave memory and
randomness at each step of execution.
m ), Ee (σ ′
i , σ ′
′
0), Ee (σ
′
0), Oe (σ
′
0)), . . .⟩ | inite (Ee (σ0))}
contain traces of any length, and also contain prefixes of any other
(cid:74)e(cid:75) = {⟨(Ie (σ
We must account for all potential input sequences in(cid:74)e(cid:75) because e
may receive any value of input at any step. We note that(cid:74)e(cid:75) may
trace in(cid:74)e(cid:75), i.e., it is prefix-closed. We adopt this definition of(cid:74)e(cid:75)
because the attacker can pause and destroy the enclave at any time;
denial of service is not in scope. Due to the determinism property
of enclave programs, a specific sequence of inputs ⟨Ie (σ ′
0), Ie (σ ′
m )⟩ uniquely identifies a trace from(cid:74)e(cid:75) and determines
1),
. . . , Ie (σ ′
the expected execution trace of e under that sequence of inputs.
(1)
2⟨σ′
0, σ′
1, . . . , σ′
m⟩ = filter(λσ . curr (σ ) = e, π ).
3 SECURE REMOTE EXECUTION OF
ENCLAVES
Imagine a user who wishes to outsource the execution of an en-
clave program e onto a remote platform. The user desires that the
platform respect the semantics(cid:74)e(cid:75) by executing trace(s) from(cid:74)e(cid:75).
However, the privileged software layers on the platform are un-
trusted, therefore the user’s trust is based on guarantees provided
by the enclave platform. We propose the following notion of secure
remote execution (SRE) of enclaves:
Definition 3.1. Secure Remote Execution of Enclaves. A remote
platform performs secure execution of an enclave program e if
any execution trace of e on the platform is contained within(cid:74)e(cid:75).
Furthermore, the platform must guarantee that a privileged soft-
ware attacker only observes a projection of the execution trace, as
defined by the observation function obs.
It is important to note that SRE does not force the platform
to execute e — the attacker may deny service, and this is easily
detectable by the user because the attacker cannot forge attested
statements as if they originated from the user’s enclave. Nor are
we forcing the platform to execute e a fixed number of times. The
attacker has the capability to execute e as many times as it wishes,
and a user can easily defend against these attacks by refusing to
provision secrets to other copies of the enclave. With that said, SRE
requires the platform to execute traces from(cid:74)e(cid:75), and recall that(cid:74)e(cid:75)
enclave (see Equation 1). Furthermore, this definition of(cid:74)e(cid:75) assumes
only contains enclave executions that start in the initial state of the
secure execution of e in that the attacker only affects e’s execution
by affecting the inputs, which are assumed to be untrusted anyway
— we later state an integrity property that validates this assumption
of the enclave platform.
3.1 Proof Decomposition of SRE
A rational user will outsource the enclave only to a platform that
provides a formal guarantee of SRE. To that end, we describe a
method for formally verifying that an enclave platform provides
SRE to any enclave program. We provide machine-checked proofs
of SRE for the TAP in § 4, and show how this applies to models of
Intel SGX and MIT Sanctum in § 5. The key idea is to decompose
the SRE property into the following set of properties.
• Secure Measurement: The platform must measure the en-
clave program to allow the user to detect any changes to
the program prior to execution, i.e., the user must be able to
verify that the platform is running an unmodified e.
• Integrity: The enclave program’s execution cannot be af-
fected by a privileged software attacker beyond providing
inputs, i.e., the sequence of inputs uniquely determines the
the enclave’s semantics(cid:74)e(cid:75).
enclave’s execution trace, and that trace must be allowed by
• Confidentiality: A privileged software attacker cannot dis-
tinguish between the executions of two enclaves, besides
what is already revealed by obs.
3.1.1 Secure Measurement. During launch, the platform com-
putes a hash of the enclave’s initial contents (init) along with rele-
vant configuration bits (config). The hash-based measurement acts
as a unique identity for the enclave, which follows directly from the
4
collision resistance assumption of the cryptographic hash function,
and therefore finds use in authenticating the enclave. Any devia-
tion from the desired enclave program will be detected when the
enclave sends an attested statement to the user — we assume that
attested statements are produced using a quoting scheme that is
unforgeable under chosen message attacks (UF-CMA); we do not
model the cryptography of this scheme, and refer the reader to [58]
for a formal treatment of this subject. The secure measurement
property states that any two enclaves with the same measurement
must also have the same semantics: they must produce equivalent
execution traces for equivalent input sequences.
Let µ (e) be the measurement of enclave e, computed when
launching the enclave. The operation must be such that two en-
claves with the same measurement have identical initial states.
∀σ1, σ2. inite1 (Ee1 (σ1)) ∧ inite2 (Ee2 (σ2)) ⇒
µ (e1) = µ (e2) ⇐⇒ Ee1 (σ1) = Ee2 (σ2)
(2)
Next we need to ensure that the if two enclaves e1 and e2 have
the same state, then they produce equivalent execution traces for
equivalent input sequences. This is the determinism property we
assumed (while defining(cid:74)e(cid:75) in § 2.1) of the enclave platform, so we
must prove it here.
(cid:16)
∀π1, π2.
Ee1 (π1[0]) = Ee2 (π2[0])
(cid:17)
∀i. (curr (π1[i]) = e1) ⇐⇒ (curr (π2[i]) = e2)
(cid:16)∀i. Ee1 (π1[i]) = Ee2 (π2[i]) ∧ Oe1 (π1[i]) = Oe2 (π2[i])
∀i. (curr (π1[i]) = e1) =⇒ Ie1 (π1[i]) = Ie2 (π2[i])
(3)
∧
∧
=⇒
(cid:17)
Equation 3 states that if: (i) the two traces π1 and π2 start with
the same initial state for enclaves e1 and e2, (ii) if π1 and π2 enter
and exit the enclaves in lockstep (i.e., the two enclaves execute for
the same number of steps), (iii) if the input sequence to the two
enclaves is the same, then the two enclaves execute identically in
both traces: they have the same sequence of state and output values.
3.1.2 Integrity. The integrity guarantee ensures that the execu-
tion of the enclave in the presence of attacker operations is identical
to the execution of the program without the attacker’s operations.
In other words, the attacker only impacts an enclave’s execution
by controlling the sequence of inputs — all other operations, such
as controlling I/O peripherals and executing supervisor-mode in-
structions, has no effect on the enclave’s execution. Any two traces
(of the same enclave program) that start with equivalent enclave
states and have the same input sequence will produce the same
sequence of enclave states and outputs, even though the attacker’s
operations may differ in the two traces.
(cid:16)
∀π1, π2.
Ee (π1[0]) = Ee (π2[0])
(cid:17)
∀i. (curr (π1[i]) = e) ⇐⇒ (curr (π2[i]) = e)
(cid:16)∀i. Ee (π1[i]) = Ee (π2[i]) ∧ Oe (π1[i]) = Oe (π2[i])
∀i. (curr (π1[i]) = e) =⇒ Ie (π1[i]) = Ie (π2[i])
(cid:17)
(4)
∧
∧
=⇒
5
σ0
E
≈
σ′
0
A1
A2
. . .
σi
O
≈
,
E
≈
i
σ′
. . .
σi +1
≈
O
≈
I
,
E
σ′
≈
i +1
e
e
σi +2
. . .
σj
A1
σk
O
≈
,
E
σ′
≈
i +2
O
≈