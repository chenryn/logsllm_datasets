input feature matrix t′ and 2D coordinate (u
′
(i)) to denote its
location. t′ is transformed from an arbitrary instance t where t ∈ St
by applying a homography matrix H(θ, τ , ϵ). The location of t(i)
can be derived as t′
We use t′
′
(i), v
Notice that here, τx/τy has a fixed ratio tan θ since the translation is
performed along the r axis shown in Fig. 7 (1). Since θ is dependent
on the spoofed input feature matrix we provide for performing
the transformation, we align the spoofed input feature matrix in
advance to the x axis where θ = 0 and accordingly τy = τx tan θ = 0.
Therefore, we can optimize τx alone. Also, this process is equivalent
to scaling so we remove ϵ.
We use the differentiable bilinear interpolation [34] to calculate
t′
(i):
t(q)(1 − |u(i) − u(q)|)(1 − |v(i) − v(q)|),
(4)
(i) = 
′
t
q∈N(u(i),v(i))
where N(u(i), v(i)) represents the 4-pixel neighbors (top-left, top-
right,bottom-left, bottom-right) at the location (u(i), v(i)) .
(i) as follows:
(u(i), v(i), 1)T = H · (u
′
ϵ(cos θ − sin θ)
′
(i), v
cos θ)
ϵ(sin θ
0
0
(i), 1)T ,
τx
τy
1
w.r.t.
H =
(3)
Figure 7: Attack capability in perturbing 3D Point Cloud T
around the LiDAR, it is possible to spoof at any horizontal
angle. From the perspective of spoofed 3D point cloud T ,
this can be modeled as rotating the spoofed points with the
LiDAR sensor as the pivot point on the horizontal plane by
angle ∆θ (Fig. 7 (c)).
Therefore, we model the attack capability A by applying these
three modifications to the given spoofed 3D point cloud T . Here
the spoofed 3D point cloud is collected by reproducing the sensor
spoofing attack. The point number of T can be 20, 40 and 60 to
represent different attack capabilities as mentioned before. In the
next section, the attack capability A modeled here is used to model
the perturbation of the input feature matrix x.
6.2 Input Perturbation Modeling
After analyzing spoofing attack capability A, to formulate x ⊕ t′ in
Equation 1, We need to have the following steps: (1) formulating the
merging function ⊕; (2) modeling the spoofed input feature matrix
spoofing capability Φ(A) based on known spoofing attack capabil-
ity A. In this section, we first formulate the merging function ⊕ by
analyzing the pre-processing program. Then we model the spoofed
input feature matrix spoofing capability Φ(A) by expressing t′ with
spoofed input feature matrix t in a differentiable function using
global spatial transformations. Here, spoofed input feature matrix t
can be attained with a given spoofed 3D point cloud T by t = Φ(T).
Formulating merging function (⊕). To model the merging
function ⊕ operated on x and t′, which are in the domain of input
feature matrix, we need to first analyze the pre-processing program
Φ(·) that transforms the 3D point cloud X into the input feature
matrix x. As described in §2.1, the pre-processing process consists
of three sub-processes: coordinate transformation, ROI filtering and
input feature matrix extraction. The first two processes make minor
effects on the adversarial spoofed 3D point cloud T ′ generated by
the spoofing attack we conducted in §6. The coordinate transforma-
tion process has no effect because the adversarial spoofed 3D point
cloud T ′ will be transformed along with the 3D point cloud X. As
for the ROI filtering process, it filters out 3D point cloud located
outside of the road from a bird’s-eye view. Therefore, as long as we
spoof points on the road, the ROI filtering process makes no effect
on the adversarial spoofed 3D point cloud T ′. The feature extraction
process, as we mentioned in Section 2.1, extracts statistical features
such as average height (Iavд_h), average intensity (Iavд_int ), max
height (Imax_h) and so on.
Further, we can observe that the input feature matrix contains
the height information as shown in Table 1. So we also optimize
a global scale scalar sh to the height features when generating
adversarial spoofed input feature matrix t′. Define S(t, sh) as the
scaling function that multiplies the features which contain the
height information by sh. Based on this transformation, Equation 4
will be changed as follows. For simplification, we denote the whole
transformation progress as Gt . So Gt(θ, τx , sh; t) represents the
transformed adversarial spoofed input feature matrixgiven spoofed
input feature matrix t with transformation parameters θ, τx , sh.
′
(i) = Gt(i)(θ, τx , sh; t)
t
= 
q∈N(u(i),v(i))
S(t(q), sh)(1 − |u(i) − u(q)|)(1 − |v(i) − v(q)|)
(5)
7 GENERATING ADVERSARIAL EXAMPLES
After modeling the input perturbation, in this section we design
the objective function with an effective adversarial loss Ladv, and
leverage an optimization method to find the attack transformation
parameters that minimize such loss.
Design the adversarial loss Ladv. Unlike previous work that
performs the analysis only at the machine learning model level,
there is no obvious objective function reflecting our attack goal of
spoofing front-near obstacles. Yet, creating an effective objective
function has been shown to be essential in generating effective
adversarial examples [21]. In order to design an effective objective
function, we analyze the post-processing step for the machine
learning output. As shown in §2.1, in the clustering process, each
cell of the model output is filtered by its objectness value. After
the clustering process, candidate object clusters are filtered by
their positiveness values. Upon such observation, we designed the
adversarial loss Ladv as follows,
Ladv =(1 − Q(x′, positiveness)Q(x′, objectness))M(px, py)
(6)
where Q(x′,·) is the function to extract the probabilities of · at-
tribute from model M by feeding in adversarial example x′. M is a
standard Gaussian mask with center coordinate (px, py) which is
an attack target position chosen by the attacker. We attain (px, py)
by mapping the attack target position in the real world onto the
corresponding coordinates of the cell in the input feature matrix
using Φ. The adversarial loss is then the summation over all the
cells in the input feature matrix of the weighted value described
above. By minimizing this designed adversarial loss, it equals to
increasing the probability to detect the obstacle of the adversarial
spoofed 3D point cloud given the machine learning model M.
Optimization algorithm and our improvement using sam-
pling. With the Ladv design above, the optimization problem can
be directly solved by using the Adam optimizer [35] to obtain the
transformation parameters θ, τx and scalar sh by minimizing the
following objective function:
(1 − Q(x′, positiveness)Q(x′, objectness))M(px, py)
f = arg minθ,τx ,sh
(7)
where t′ can be obtained by Equation 5 and x′ = x ⊕ t′. In this
paper, we call this direct solution vanilla optimization.
We visualize the loss surface against the transformation parame-
ters in Fig. 9. During the vanilla optimization process, we observe
that the loss surface over the transformation parameters is noisy at
a small scale (green line) and quite flat at a large scale (red line). This
leads to the problem of choosing a proper step size for optimization-
based methods. For example, choosing a small step size will trap the
optimizing process near a local minimum while choosing a large
step size will be less effective due to noisy local loss pointing to
the wrong direction. Different from Carlini et al. [21] that directly
chose multiple starting points to reduces the trap of local minima,
the optimization process under our setting is easy to get stuck in
bad local minima due to the hard constraints of the perturbations.
We propose a way to use sampling at a larger scale and to optimize
at a smaller scale. To initiate the optimization process at different
positions, we first calculate the range of the transformation param-
eters so that the transformed spoofed 3D point cloud is located in
the target area. Then we uniformly take n samples for rotation and
translation parameters and compose n2 samples to initiate with.
Generating adversarial spoofed 3D point cloud. To further
construct the adversarial 3D point cloud X ′, we need to construct
adversarial spoofed 3D point cloud T ′. Using the transformation
parameters θ, τ , ϵ, sh, we can express the corresponding adversarial
spoofed 3D point cloud T ′ such that t′ = Φ(T ′) with a dual trans-
formation function GT of Gt . We use Twx ,Twy ,Twz to denote value
of coordinate (wx, wy, wz) and Ti to denote the value of intensity
for all points in spoofed 3D point cloud T . With transformation pa-
rameters θ, τ , ϵ, sh, we can express T ′
wz of the transformed
adversarial spoofed 3D point cloud T ′ in Equation 8.
wy ,T ′
wx ,T ′
T ′
wx
T ′
wy
T ′
wz1
 =
′
i = Ti
T
cos θ − sin θ
cos θ
sin θ
0
0
0
0
 ·
τx
0
0
1
Twx
Twy
Twz
1
0
0
sh
0
(8)
Therefore, we can use T ′ = GT (θ, τx , sh;T) represents the trans-
formed adversarial spoofed 3D point cloud given spoofed 3D point
cloud T with transformation parameters θ, τx , sh.
Overall adversarial example generation process. Fig. 8 pro-
vides an overview of the overall adversarial example generation
process. Given 3D point cloud X and spoofed 3D point cloud T
(Fig. 8 (a)), we first map them via Φ to get corresponding input
feature matrix x and spoofed input feature matrix t. Then we apply
the sampling algorithm to initialize the transformation parameters
θ, τx , sh as shown in Fig. 8 (b). After the initialization, we leverage
optimizer opt to further optimize the transformation parameters
(θ, τx , sh) with respect to the adversarial loss function Ladv (Fig. 8
(c)). With the transformation parameters θ, τx , sh and T , we apply
the dual transformation function GT using the Equation 8 to get
adversarial spoofed 3D point cloud T ′. At last, to obtain the adver-
sarial 3D point cloud X ′, we append T ′ to 3D point cloud X (Fig. 8
(d)). The entire adversarial example generation algorithm including
the optimization parameters is detailed in Appendix A.
Figure 8: Overview of the adversarial example generation process.
Figure 9: Loss surface over transformation parameters θ (ro-
tation) and τx (translation). Using a small step size (green
line) will trap the optimizing process near a local extreme
while choosing a large step size (red line) will be less effec-
tive.
8 EVALUATION AND RESULTS
In this section, we evaluate our adversarial example generation
method in terms of attack effectiveness and robustness.
Experiment Setup. We use the real-world LiDAR sensor data
trace released by Baidu Apollo team with Velodyne HDL-64E S3,
which is collected for 30 seconds on local roads at Sunnyvale, CA.
We uniformly sample 300 3D point cloud frames from this trace in
our evaluation. The attack goal is set as spoofing an obstacle that is
2-8 meters to the front of the victim AV. The distance is measured
from the front end of the victim AV to the rear end of the obstacle.
8.1 Attack Effectiveness
Fig. 10 shows the success rates of generating a spoofed obstacle
with different attack capabilities using the vanilla optimization and
our improved optimization with global sampling (detailed in §7). As
shown, with our improvement using sampling, the success rates of
spoofing front-near obstacles are increased from 18.9% to 43.3% on
average, which is a 2.65× improvement. This shows that combining
global sampling with optimization is effective in addressing the
problem of trapping in local minima described in §7.
Figure 10: Attack success rate of spoofing a front-near obsta-
cle with different number of spoofed points. V-opt refers to
vanilla optimization which is directly using the optimizer
and S-opt refers to sampling based optimization. We choose
Adam [35] as the optimizer in both cases.
Fig. 10 also shows that the success rates increase with more
spoofed points, which is expected since the attack capability is
increased with more spoofed points. In particular, when the attacker
can reliably inject 60 spoofed points, which is the attack capability
observed in our experiments (§4), the attack success rate is able to
achieve around 75% using our improved optimization method.
In addition, we observe that the spoofed obstacles in all of the
successful attacks are classified as vehicles after the LiDAR-based
perception process, even though we do not specifically aim at spoof-
ing vehicle-type obstacles in our problem formulation.