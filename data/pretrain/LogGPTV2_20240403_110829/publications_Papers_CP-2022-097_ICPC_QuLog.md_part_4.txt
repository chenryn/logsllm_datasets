developerswithmanyincorrectpredictions.Thelatterisrelevant
e.g.,"refused",andconsiderschangingeitherthelevelortheword.
forQuLog‚Äôspracticalusability.
Thatway,QuLogautomaticallyaidsdevelopersinimprovingthe
logquality.Theoutputoftheexplanationmoduleisanordered 4.2.1 Comparisonagainstbaselines. IntheevaluationofQuLog
listoftokens,orderedbytheirintensity(fromhighesttolowest), againstbaselines,weconsideredtwoQuLogmodels.Theyhave
examinedbydevelopersinthatorder. thesamearchitecturaldesignbutdifferintheinputdatausedto
trainthem.Thefirstmodel,wereferredtoasQuLog-8,istrained
4 EXPERIMENTALEVALUATION ondatafromeightsoftwaresystemslistedinTable1.Sincethese
systemsarecharacterizedbygoodloggingpractices,weassume
thatthemajorityoftheloglevelsarecorrectlyassigned,similaras
4.1 ExperimentalSetup inpreviousstudies[34].Thisaccountsforthequalityofthelearning
data.ThesecondmodelforloglevelassignmentwecallQuLog*
4.1.1 CodeRepositoryCollection. Alongsidethestudiedsoftware
istrainedonthecollectionof100GitHubsystems.WhileQuLog*
systems,wecollectedloginstructionsfrom100othersystemsfrom
doesnotaccountveryrigorouslyfortheinstructionquality(despite
GitHub.Tocollectthisdata,wecrawledGitHubandsearchedfor
thepseudoindicatorofhavingmanystars),itenablestestingfor
differentsystemsfromthefollowingtopics:Java,Python,Angular,
cross-softwareusefulnessofthestatictextinloglevelassignment.
Ruby,andPHP,selecting7039systems.Additionally,wecollected
Assuch,italignswiththesystem-agnosticnatureofQuLog.Thisis
thenumberofGitHubstarsforeachsystem.Similartoprevious
importantinscenariosoflogqualityassessmentwherethesoftware
works[22],weassumedthatthenumberofstarsisagoodindicator
systemisintheinitialdevelopmentstage,andtherearenotmany
forthequalityofloggingandconsideredthetop100intheexper-
loginstructionsfortrainingamodel.Asanevaluationdataset,we
iments.Theusageofthisdataisdescribedinthecorresponding
consideredtheloginstructionsfromoneoftheninesystemslisted
evaluationsettingwhereused.
inTable1,suchthattheinstructionsfromtheevaluationdataset
4.1.2 EvaluationCriteria. ToevaluateQuLog,weusedseveraleval- areneverseenduringtrainingthemodel,preventingdataleakage.
uationcriteria.First,wedescribethecriteriaevaluatingexactpre- ExperimentDesign.WecompareQuLogagainsttwobaselines:
dictions.Forthemulti-classevaluation,weusedaccuracy.Itgives DeepLV[34]andSupportVectorMachines(SVM)[10].DeepLV
thepercentageofcorrectpredictionsoutofallofthepredictions. addressestheproblemofloglevelassignmentasanordinalregres-
Duetotheimbalancesofthetargetclasses(e.g.,differentsystems sionandtrainsLSTM‚Äìadeep-learningarchitecture,onfeatures
haveadiversenumberof"error","warning",and"info"instructions), extracted from the log instruction. It is reported as the current
accuracycanbemisleading[17].Therefore,wefurtherconsidered bestperformingmethodforloglevelassignment.SVMisapopular
precision,recall andF1 scores.Precisionevaluatesthefractionof multi-classclassificationmethodtrainedonthevectorrepresen-
correctpredictionsoutofallclasspredictions.Recallevaluatesthe tation of the static text from general-purpose language models
ICPC2022,May21‚Äì22,2022,Pittsburgh,PA,USA Bogatinovski,etal.
Table4:Evaluationonloglevelqualityassessment Table5:Loglevelmisclassificationcontingencytable(the
averagingisdoneoverninesoftwaresystemsgiveninTable1)
AUC Accuracy
Systems QuLog-8 DeepLV SVM QuLog* QuLog-8 DeepLV SVM QuLog* True/Predicted Info Warning Error
Cassandra 0.94 0.78 0.80 0.96 0.63 0.61 0.64 0.67
Elasticsearch 0.93 0.71 0.71 0.94 0.59 0.51 0.55 0.60 Info - 21.1% 16.1%
Flink 0.94 0.74 0.77 0.95 0.62 0.60 0.62 0.71 Warning 10.7% - 40.3%
HBase 0.91 0.77 0.80 0.92 0.59 0.61 0.64 0.63
JMeter 0.92 0.73 0.74 0.95 0.59 0.55 0.53 0.68 Error 4.3% 19.3% -
Kafka 0.93 0.68 0.70 0.98 0.58 0.51 0.51 0.69
Karaf 0.93 0.73 0.79 0.94 0.63 0.57 0.58 0.64
Wicket 0.94 0.74 0.75 0.95 0.75 0.56 0.59 0.78 4.2.2 LogLevelProblemInstances. Thepreviousexperimentshows
Zookeeper 0.92 0.68 0.74 0.94 0.59 0.50 0.57 0.62 that QuLog performs better than the baselines on log level as-
Average 0.93 0.74 0.75 0.95 0.62 0.56 0.58 0.67
signments. However, the results between 0.60-0.78 on accuracy
across different systems, although good, indicate that there are
(BERT) [12] previously used for log level assignment [18]. The incorrectassignments.Themisclassificationscanimpairthepracti-
hyper-parametersofthebaselinemethodsaresettotherecom- calusabilityofQuLog.Therefore,westudythemisclassification
mendedvaluesbytheauthors.Asevaluationcriteria,weusedAUC types.Basedontheobservations,weidentifiedinstancesofthelog
andaccuracyfollowingliteraturestandards[29,34].Regardingthe levelassignmentproblemhavingimprovedresultsfacilitatingthe
consideredhyper-parametersforQuLog‚Äôsloglevelarchitecture, practicalapplicabilityofQuLog.TostudyQuLog‚Äôsmisclassifica-
wesetthenumberofheadstotwo,themodelsizeto16,thenum- tiontypes,wecalculatedthemisclassificationcontingencytable.It
beroflayersissettotwo,andthemaximalnumberoftokensto showsthepercentageofmisclassificationpredictionratesforthe
ùëöùëéùë•_ùëôùëíùëõ=50.FortrainingthemodelweusedAdamoptimizer[26] threeclasses.Table5givesthecontingencytable.Itisseenthat
withlearningrate10‚àí4 andhyperparametersùõΩ1 = 0.9,ùõΩ2 = 0.99. someclasspairshavealowmisclassificationrate(e.g.,true"error"
Thebatchsizewassetto2048. predictedas"info"is4.3%),howeverforothers,itissignificantly
Resultsanddiscussion.Table4givestheresultsoftheevaluation high(e.g.,true"warning"predictedas"error"is40.3%).Tounder-
ofQuLogagainstbaselines.WefirstcomparetheQuLog-8model standthepotentialreasons,weexaminedthen-gramfrequency
againstthetwobaselines.FollowingtheAUCcriteria,itisseen sharedbetweenthedifferentloglevelssimilartothepreliminary
that QuLog-8 achieves the best performance for all of the nine study (Section2.2.1). We findthat n-grams sharedbetween the
systems.SinceAUCevaluateshowgoodamodelisinpredicting loglevelpairs"error-warning"is14.2%,anditishighercompared
thetruelevel(e.g.,"error")ascorrect(as"error")ratherthanpredict to"error-info"(4.9%)and"warning-info"(9.7%).Relatingittothe
incorrectlevelasthetrueone(e.g.,"warning"insteadof"error"),it contingencymatrix,weseethattheclasspairswithhighern-grams
meansthatQuLog-8candiscriminatethedifferentloglevelsbetter. overlaphavehighermisclassificationrates.Weusethisobservation
However,AUCevaluatesscoresinsteadofexactdecisionsfora toconstructthreesimplifiedinstancesoftheloglevelqualityas-
particularloglevel.Bydecidingforaloglevel(i.e.,maximalscore signment.Insteadofpredictingthethreeclasses,weconsideredthe
estimateasaclassprediction),weassignanactualloglevelforthe predictionoftwoclasses,namely"info-warning"(IW),"info-error"
giveninputinstruction.Toevaluatethecorrectnessoftheloglevel (IE)and"error-warning"(EW).Theexaminationofindividualclass
decisions,weuseaccuracy.ComparingQuLog-8againstDeepLVit pairshaspracticalrelevancebecausedifferentstakeholdershave
isseenthatitisoutperformingitin8/9systemswhilefailingtodo differentexpectationsfromlogs.Forexample,theoperatorsusually
soin1/9(HBase)systems.ComparingQuLog-8againstSVMshows examinetheloglevels"error"and"warning".Therefore,misclassi-
thatQuLogperformsbetteron6/9datasets,performsworsein2/9 fyinganerroreventas"info"(e.g.,JiraissueHDFS-4048)canhide
systemsandtieson1/9(Flink).Theevaluationcriteriashowthat importanteventsfromoperators,increasingthemaintenancecosts.
ourapproachisusefulinassessingthecorrectnessofloglevelsfor Experimentdesign.WeconsideredQuLog*loglevelassignment
theconsideredsystemsoutperformingthebaselines. approachbecauseitissystem-agnostic.TotrainQuLog*onthe
Next,wecompareQuLog-8againstQuLog*.Theresultsonthe threetwo-classproblems,wemodifiedtheoutputlayertohave
twoevaluationcriteriashowthatQuLog*outperformsQuLog-8by twoclassesinsteadofthree.Theexperimentisdesignedasfollows.
1-9%onaccuracyand1-5%onAUCfordifferentsystems.These Westartwiththe100softwaresystemscollectedduringthedata
resultsindicatetheexistenceofsharedsystem-agnosticproperties collectionprocedure.Werandomlysampled60%oftherepositories
ofthestatictextandtheloglevels,independentofthesoftware fortraining,20%forvalidationand20%forevaluation.Toreducethe
systemsexaminedinthepreliminarystudy.Theinstructionsorigi- varianceoftheresultsduetotherandomrepositoriesselection,we
natefromdifferentprogramminglanguagesandpubliclyaccessible repeatedthesamplingprocedure30timesandreportedtheaverage
softwaresystemsfromGitHub,representingdiversedevelopers resultsalongsidethestandarddeviations.Toassessthecorrectness
writingstyles.Therefore,bytheirleveraging,QuLog*learnsawide ofthedecisions,weusedF ,precisionandrecall,insteadofaccuracy
1
rangeofcharacteristicsofthestatictextconcerningtheloglev- becausetheyareexposingtheimbalancesoftheclassdistributions
els(e.g.,largevocabularyusedinsimilareventdescriptions).The betterthanaccuracy.Weusedthesamebaselinesasintheprevious
goodperformanceacrossdifferentsystemsandthesystem-agnostic experimenttrainedwiththesamedataasQuLog*.
trainingofQuLog*suggestthatQuLogissuitableforanautomatic Resultsanddiscussion.Table6enliststheperformancescoresfor
assessmentofthequalityoftheloginstructions,representedby thefourprobleminstancesofloglevelqualityassessment.Com-
their correct log level assignment. Examples of when QuLog is paringtheabsolutevaluesforthescoresacrossthefourscenarios
outperformingthebaselinescanbefoundinAppendixA. revealsthattheIEproblemachievesthehighestvaluesonF score
1
QuLog:Data-DrivenApproachforLogInstructionQualityAssessment ICPC2022,May21‚Äì22,2022,Pittsburgh,PA,USA
Table6:Performancescoresonthetaskofloglevelassign- 4.3.2 Results and discussion. Table 7 enlists the evaluation re-
ment.Thebestresultsperscenarioarebolded. sults.ItisseenthatQuLogachievesahighaverageF scoreof
1
0.98 while outperforming the baselines by slight margins. The
Scores Scenario QuLog DeepLV BERT_SVM goodperformanceofthethreemethodsisattributedtothedis-
IE 0.88¬±0.03 0.82¬±0.02 0.87¬±0.04 criminative linguistic features between the two classes. For ex-
IWE 0.73¬±0.03 0.67¬±0.03 0.73¬±0.04 ample,theHBase‚Äôsloginstruction"failedparse",fromtheclass
F
1 IW 0.68¬±0.06 0.61¬±0.08 0.64¬±0.05 hadoop.hbase.zookeeper.ZKListener,hasalinguisticstructure"verb
WE 0.61¬±0.04 0.56¬±0.06 0.54¬±0.05 noun".Notably,itdoesnotcontaininformationtowhichthepars-
IE 0.88¬±0.02 0.79¬±0.04 0.92¬±0.01 ing failure refers (i.e., lacks sufficient linguistic structure). As a
comparison,inanotherloginstruction"failedparsedataforznode
IWE 0.72¬±0.03 0.66¬±0.03 0.74¬±0.05
Precision *"withinthesameclassofHBase,thelinguisticstructure"verb
IW 0.75¬±0.04 0.72¬±0.06 0.58¬±0.05
noun"hasfouradditionallinguisticproperties,i.e.,ithastheform
WE 0.69¬±0.09 0.59¬±0.08 0.51¬±0.07
"verbnounnounappositionnounparameter".Thisadditionallin-
IE 0.89¬±0.05 0.86¬±0.06 0.84¬±0.06
guisticstructurehastwoadvantages.Fromalearningperspective,
IWE 0.73¬±0.03 0.68¬±0.03 0.73¬±0.04
Recall thericherlinguisticstructureisusefulfordiscriminatingbetween
IW 0.62¬±0.08 0.54¬±0.1 0.72¬±0.09
theclasses.Fromacomprehensionperspective,itencodesverbose
WE 0.56¬±0.07 0.54¬±0.08 0.59¬±0.08
informationonthetypeoffailedparsing.Thebetterperformance
ofQuLogagainstthebaselinescanbeattributedtoitsabilityto
(averageof0.88),i.e.,trades-offtheprecision(0.88)andrecall(0.89) extractabetterrepresentationofthelinguisticstructure.QuLog
quitewell.Therefore,thismodelisveryreliableforcorrectlyassess- exploitslogspecificconcepts,whilethegeneral-purposelanguage
ingthe"info"and"error"loginstructions.Thegoodperformanceis modelsaretrainedondatasetsfromgeneralliterature,whichmay
attributedtotheobserveddifferencesinthevocabularybetween average-outlogspecificproperties.
the"error"and"info"loginstructions(i.e.,a4.9%n-gramoverlap). The results on specificity are high for both QuLog and SVM
Therefore,thismodelwon‚Äôtoverwhelmdeveloperswithmanyin- whilebeingabitlowerforRF.Sincespecificityevaluatesmethods‚Äô
correctpredictions.OntheIWandEWprobleminstances,although performance in the correct prediction for the insufficient class
QuLogdoesnotperformasgood,stilloutperformthebaselines (truenegativeclass),theresultsshowthatQuLogcancorrectly
whendifferentsoftwaresystemsareconsidered. identifytheinstructionswithaninsufficientlinguisticstructure.
BycombingtheseresultswiththehighperformanceonF (asa
1
4.3 LinguisticQualityAssessmentEvaluation trade-offbetweenincorrectsufficientpredictions),weconcludethat
4.3.1 ExperimentalDesign. Toevaluatethesufficiencyinthelin- QuLogdetectsthelinguisticallyinsufficientinstructionswithout
guisticstructureofthestatictext,weusedthedatafromthepre- compromisingtheperformanceonthesufficientclass.Thehigh