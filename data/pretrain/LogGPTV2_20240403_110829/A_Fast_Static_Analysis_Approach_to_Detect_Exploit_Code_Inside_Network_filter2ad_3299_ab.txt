as data, leading to false negatives. This is a harder problem to solve and we pay
attention to this aspect during algorithm design wherever relevant.
These two aspects in cohesion form the core of our exploit code detection
methodology, which we call convergent static analysis. We have evaluated our
approach using the Metasploit framework [3], which currently supports several
exploits with features such as payload encryption and metamorphic NOOP sleds.
We are interested mainly in evaluating eﬀectiveness in detecting exploit code
and resistance to evasion. Also, given the popularity of the 32-bit x86 processor
family, we consider the more relevant and pressing problem of detecting exploit
code targeted against this architecture.
As our second contribution, we describe the design and architecture of an
network ﬂow based exploit code detection sensor hinging on this methodology.
Sensor deployment in a real-world setting raises several practical issues such as
performance overheads, sensor placement and management. In order to gain in-
sight into these issues, we have performed our evaluation based on traces (several
gigabytes in size) collected from an 100Mbps enterprise network over a period
of 1-2 weeks. The dataset consists of ﬂows that are heterogeneous in terms of
operating systems involved and services running on the hosts.
1.3 Summary of Results
As a primary exploit detection mechanism, our approach oﬀers the following
beneﬁts over signature-based detection systems.
– It can detect zero-day and metamorphic exploit code. Moreover, it can also
detect polymorphic code, but the mileage may vary.
– It does not incur high maintenance costs unlike signature-based detection
systems where signature generation and updates are a constant concern.
While our approach can operate in a stand-alone manner, it can also comple-
ment signature-based detection systems, oﬀering the following beneﬁt.
– If signature-based detection is to be eﬀective, then the signature repository
has to be kept up-to-date; a practically impossible task without automated
tools. Our approach, by virtue of its ability to separate data and exploit code,
identify portions of a network ﬂow which correspond to an exploit. Therefore,
it also serves as a technique which can automatically generate precise and
high quality signatures. This is particularly invaluable since signiﬁcant eﬀort
goes into maintaining the signature repository.
290
R. Chinchani and E. van den Berg
The rest of the paper is organized as follows. Related work is discussed in
Section 2. Our ﬁrst contribution is presented in Section 3. The core exploit code
detection mechanism is described in Section 4.
2 Related Work
The two broad areas which are relevant to our work are exploit code detection
inside network ﬂows and static analysis, and signiﬁcant advances have been made
in both these areas. We review and compare some of them to put our work in
perspective.
Several research eﬀorts have acknowledged these evasion tactics and proposed
possible solutions to deal with them, but they have their limitations. Hittel [16]
showed how a metamorphic sled can be constructed and in the same paper,
developed Snort rules for detection; however, their number can be very large.
Toth and Kruegel [35], also concentrating on the NOOP sled, went one step fur-
ther. They used binary disassembly to ﬁnd sequences of executable instructions
bounded by branch or invalid instructions; hence, longer the sequence, greater
the evidence of a NOOP sled. However, this scheme can be easily defeated by
interspersing branch instructions among normal code [16], resulting in very short
sequences. In our approach, although we perform binary disassembly, its purpose
is to assist static analysis. Recently, Pasupulati et al. [31] proposed a technique
to detect the return address component by matching against candidate buﬀer
addresses. While this technique is very novel and perhaps the ﬁrst to address
metamorphic and polymorphic code, there are caveats. First, the return address
component could be very small so that when translated to a signature, it is not
speciﬁc enough. Secondly, even small changes in software are likely to alter buﬀer
addresses in memory. Consequently, this approach runs into similar administra-
tive overheads as existing signature-based detection systems. We do not focus
on the return address component and changes in software do not impact our
approach. Wang et al. [38] proposed a payload based anomaly detection system
called PAYL which works by ﬁrst training with normal network ﬂow traﬃc and
subsequently using several byte-level statistical measures to detect exploit code.
But it is possible to evade detection by implementing the exploit code in such a
way that it statistically mimics normal traﬃc [22].
Instruction recovery is central to static analysis and there are two general
approaches - 1) linear sweep, which begins decoding from the ﬁrst byte, and
2) recursive traversal [9], which follows instruction ﬂow as it decodes. The ﬁrst
approach is straightforward with the underlying assumption that the entire byte
stream consists exclusively of instructions. In contrast, the common case for
our approach is the byte stream exclusively contains data. The second approach
tries to account for data embedded among instructions. This may seem similar to
our approach but the major diﬀerence is that the execution entry point must be
known for recursive traversal to follow control ﬂow. When the branch targets are
not obvious due to obfuscations, then it is not trivial to determine control ﬂow.
To address this issue, an extension called speculative disassembly was proposed
A Fast Static Analysis Approach
291
by Cifuentes et al. [12], which as the name suggests attempts to determine via
a linear sweep style disassembly whether a portion of the byte stream could be
a potential control ﬂow target. This is similar to our approach since the main
idea is to reason whether a stream of bytes can be executable code. In general,
all these approaches aim for accuracy but for our approach although accuracy is
important, it is closely accompanied by the additional design goal of eﬃciency.
The diﬀerences between static analysis of malicious programs and exploit code
inside network ﬂows notwithstanding, there are lessons to be learnt from stud-
ies of obfuscation techniques which hinder static analysis as well as techniques
proposed to counter them. Christodorescu et al. reported that even basic ob-
fuscation techniques [11] can cause anti-virus scanners to miss malicious code.
They go on to describe a technique to counter these code transformation us-
ing general representations of commonly occurring virus patterns. Linn et al.
describe several obfuscation techniques [26] which are very relevant to our ap-
proach, such as embedding data inside executable code to confuse automatic
disassembly. Kruegel et al. devised heuristics [24] to address some of these ob-
fuscations. These algorithms tackle a much harder problem and aim for accuracy
in static analysis, while our approach does not for reasons of eﬃciency and only
partial knowledge being available.
3 Convergent Binary Disassembly
Static analysis of binary programs typically begins with disassembly followed
by data and control ﬂow analysis. In general, the eﬀectiveness of static analysis
greatly depends on how accurately the execution stream is reconstructed. This
is still true in our case even if we use static analysis to distinguish data and exe-
cutable code in a network ﬂow rather than in the context of programs. However,
this turns out to be a signiﬁcant challenge as we do not know if a network ﬂow
contains executable code fragments and even if it does, we do not know where.
This is a signiﬁcant problem and it is addressed in our approach by leveraging
the self-correcting property of Intel binary disassembly [26]. In this section, we
perform an analysis of this property in the context of network ﬂows.
3.1 Convergence in Network Flows
The self-correcting property of Intel binary disassembly is interesting because
it tends to converge to the same instruction stream with the loss of only a few
instructions. This appears to occur in spite of the network stream consisting
primarily of random data and also when disassembly is performed beginning
at diﬀerent oﬀsets. These observations are based on experiments conducted over
network ﬂows in our dataset. We considered four representative types of network
ﬂows - HTTP (plain text), SSH (encrypted), X11 (binary) and CIFS (binary). As
for the exploit code, we used the Metasploit framework to automatically generate
a few instances. We studied the eﬀects of binary disassembly by varying the
oﬀsets of the embedded exploit code as well as the content of the network ﬂow.
292
R. Chinchani and E. van den Berg
Fig. 2. General IA-32 instruction format
Convergence occurred in every instance but with diﬀerent number of incorrectly
instructions, ranging from 0 to 4 instructions.
The phenomenon of convergence can be explained by the nature of the Intel
instruction set. Since Intel uses a complex instruction set computer architecture,
the instruction set is very dense. Out of the 256 possible values for a given
start byte to disassemble from, only one (0xF1) is illegal [2]. Another related
aspect for rapid convergence is that Intel uses a variable-length instruction set.
Figure 2 gives a overview of the general instruction formation for the IA-32
architecture [2]. The length of the actual decoded instruction depends not only
on the opcode, which may be 1-3 bytes long, but also on the directives provided
by the preﬁx, ModR/M and SIB bytes wherever applicable. Also note that not
all start bytes will lead to a successful disassembly and in such an event, they
are decoded as a data byte.
3.2 Analysis
We give a more formal analysis for this phenomenon. Given a byte stream, let’s
assume that the actual exploit code is embedded at some oﬀset x = 0, 1, 2, . . ..
Ideally, binary disassembly to recover the instruction stream should begin or at
least coincide at x. However, since we do not know x, we start from the ﬁrst
byte in the byte stream. We are interesting in knowing how soon after x does our
disassembly synchronize with the actual instruction stream of the exploit code.
To answer this question, we model the process of disassembly as a random
walk over the byte stream where each byte corresponds to a state in the state
space. Disassembly is a strictly forward-moving random walk and the size of
each step is given by the length of the instruction decoded at a given byte.
There are two random walks, one corresponding our disassembly and the other
corresponding to the actual instruction stream. Note that both random walks
do not have to move simultaneously nor do they take the same number of steps
to reach the point where they coincide.
Translating to mathematical terms, let L = {1, . . . , N} be the set of possible
step sizes or instruction lengths, occurring with probabilities {p1, . . . , pN}. For
the ﬁrst walk, let the step sizes be {X1, . . . ,|Xi ∈ L}, and deﬁne Zk =
Xj.
Similarly for the second walk, let step sizes be { ˜X1, . . . ,| ˜Xi ∈ L} and ˜Zk =
(cid:1)k
˜Xj. We are interested in ﬁnding the probability that the random walks
{Zk} and { ˜Zk} intersect, and if so, at which byte position.
(cid:1)k
j=1
j=1
A Fast Static Analysis Approach
293
Gi.
i=1
(cid:1)T
One way to do this, is by studying ‘gaps’, deﬁned as follows: let G0 = 0,
G1 = | ˜Z1 − Z1|. G1 = 0 if ˜Z1 = Z1, in which case the walks intersect after 1
step. In case G1 > 0, suppose without loss of generality that ˜Z1 > Z1. In terms of
our application: {Zk} is the walk corresponding to our disassembly, and { ˜Zk} is
the actual instruction stream. Deﬁne k2 = inf{k : Zk ≥ ˜Z1} and G2 = Zk2 − ˜Z1.
In general, Z and ˜Z change roles of ‘leader’ and ‘laggard’ in the deﬁnition of
each ’gap’ variable Gn. The {Gn} form a Markov chain. If the Markov chain is
irreducible, the random walks will intersect with positive probability, in fact at
the ﬁrst time the gap size is 0. Let T = inf{n > 0 : Gn = 0} be the ﬁrst time the
walks intersect. The byte position in the program block where this intersection
occurs is given by ZT = Z1 +
In general, we do not know Z1, our initial position in the program block,
because we do not know the program entry point. Therefore, we are most inter-
ested in the quantity
Gi, representing the number of byte positions after
the dissassembly starting point that synchronization occurs.
Using partitions and multinomial distributions, we can compute the ma-
trix of transition probabilities pn(i, j) = P (Gn+1 = j|Gn = i) for each i, j ∈
{0, 1, . . . N − 1}. In fact pn(i, j) = p(i, j) does not depend on n, i.e. the Markov
chain is homogeneous. This matrix allows us e.g. to compute the probability that
the two random walks will intersect n positions after disassembly starts.
The instruction length probabilities {p1, . . . , pN} required for the above com-
putations are dependent on the byte content of network ﬂows. The instruction
length probabilities were obtained by disassembly and statistical computations
over the same network ﬂows chosen during empirical analysis (HTTP, SSH, X11,
Gi > n), that inter-
CIFS). In Figure 3, we have plotted the probability P (
section (synchronization) occurs beyond n bytes after start of disassembly, for
n=0, . . . , 99.
(cid:1)T
i=1
(cid:1)T
i=1
P(No intersection after n disassembled bytes)
HTTP
SSH
X11
CIFS
y
t
i
l
i
b
a
b
o
r
p
8
.
0
6
.
0
4
.
0
2
.
0
0
0
.
0
20
40
60
80
100
n
Fig. 3. Probability that the walk corresponding to our disassembly and the actual
instruction ﬂow will not have intersected after n bytes
294
R. Chinchani and E. van den Berg
It is clear that this probability drops fast, in fact with probability 0.95 the
disassembly walk’ and the ’program walk’ will have intersected on or before
the 21st (HTTP), 16th (SSH), 15th (X11) and 16th (CIFS) byte respectively,
after the disassembly started. On average, the walks will intersect after just 6.3
(HTTP), 4.5 (SSH), 3.2 (X11) and 4.3 (CIFS) bytes respectively.
4 Static Analysis Based Detection
From a security standpoint, static analysis is often used to ﬁnd vulnerabilities
and related software bugs in program code. It is also used to determine if a given
program contains malicious code or not. However, due to code obfuscation tech-
niques and undecidability of aliasing, accurate static analysis within reasonable
time bounds is a very hard problem. On one hand, superﬁcial static analysis
is eﬃcient but may lead to poor coverage, while on the other, a high accuracy
typically entails a prohibitively large running time.
4.1 Working Premise
In our approach, we use static analysis over network ﬂows, and in order to realize
an online network-based implementation, eﬃciency is an important design goal.
Normally, this could translate to poor accuracy, but in our case we use static
analysis only to devise a process of elimination. which is based on the premise
that an exploit code is subject to several constraints in terms of the exploit code
size and control ﬂow. Subsequently, these constraints will help determine if a
byte stream is data or program-like code.
Exploit Code Size. For every vulnerable buﬀer, an attacker can potentially
can write arbitrary amount of data past the bounds of the buﬀer, but this will
most likely result in a crash as the writes may venture into unmapped or invalid
memory. This is seldom the goal of a remote exploit and in order to be successful,
the exploit code has to be carefully constructed to ﬁt inside the buﬀer. Each
vulnerable buﬀer has a limited size and this in turn puts limits on the size of
the transmitted infection vector.
Branch Instructions. The interesting part of a branch instruction is the branch
target and for an exploit code, the types of branch targets are limited - 1) due
to the uncertainty involved during a remote infection, control ﬂow cannot be
transferred to any arbitrary memory location, 2) due to the size constraints,
branch targets can be within the payload component and hence, calls/jumps
beyond the size of the ﬂow are meaningless, or 3) due to the goals which must
be achieved, the exploit code must eventually transfer control to a system call.
Branch instructions of interest [2] are jmp family, call/ret family, loop family
and int.
System Calls. Even an attacker must look to the underlying system call subsys-
tem to achieve any practical goal such as a privileged shell. System calls can be
invoked either through the library interface (glibc for Linux and kernel32.dll,
A Fast Static Analysis Approach
295
ntdll.dll for Windows) or by directly issuing an interrupt. If the former is cho-
sen, then we look for the preferred base load address for libraries which on Linux
is 0x40—— and 0x77—— for Windows. Similarly, for the latter, then the corre-
sponding interrupt numbers are int 0x80 for Linux and int 0x2e for Windows.
A naive approach to exploit code detection would be to just look for branch
instructions and their targets, and verify the above branch target conditions.
However, this is not adequate due to the following reasons, necessitating addi-
tional analysis. First, in our experience, although the byte patterns satisfying
the above conditions occur with only a small probability in a network ﬂow, it
is still not suﬃciently small to avoid false positives. Second, the branch targets
may not be obvious due to indirect addressing, that is, instead of the form ‘call