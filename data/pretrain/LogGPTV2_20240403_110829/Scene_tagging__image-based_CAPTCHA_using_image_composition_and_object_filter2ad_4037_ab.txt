generate the final image used for the test. 
The object images are depictions of the associated objects that 
utilize  transparent  backgrounds  to  ensure  that  only  the  object  is 
present,  and  not  any  extraneous  object  background  information. 
The  use  of  these  irregularly  shaped  objects  also  makes  it  more 
difficult for automated attacks to determine object boundaries in 
the presence of image distortion and clutter. 
3.2  Question Types 
Question and answer pairs are generated from the relationships 
between objects placed in a scene tagging image. Our prototype 
generates the following three types of questions:  
346 
rest are objects selected randomly from the object database. The 
user selects their answer choice via mouse. 
Image  Point  Selection:  The  second  response  format  asks  the 
user to click the center of the object in the image that corresponds 
to  the  correct  answer.  A  circular  tolerance  region,  the  radius  of 
which has been set in our prototype system based on a user study, 
is used to compensate for inaccuracies in user point selection. 
It should be noted that we conducted portions of a preliminary 
user study with a text-entry response format, but later abandoned 
it  based  on  user  feedback  and  poorer  task  success  rates.  Many 
users prefer questions that may be answered quickly via use of a 
mouse  over  keyboard-based  answer  entry.  Further  benefits  of 
avoiding text-entry are that it helps minimize the cultural issues of 
dealing  with  multiple  names  for  an  object  and  avoids  problems 
involving user misspellings or typographical errors. 
4.  AUTOMATED ATTACK METHODS 
4.1  Attack Model 
The attack model we utilize first assumes that an attacker may 
know the algorithm utilized to create scene tagging instances. It is 
also assumed that the attacker has access to the database of tagged 
image objects that the system uses in composite image generation. 
This model satisfies the definition of a CAPTCHA [1] in that the 
system’s  security  is  based  on  the  assumed  difficulty  of  an  AI 
problem, not on “the secrecy of a database or a piece of code”. 
4.2  Randomized Guess Attacks 
The first method of attack that must be considered is that of a 
randomized guess attack. The user may be asked to answer more 
than  one  question  to  strengthen  resistance  to  such  attacks.  A 
combination of two 16-answer multiple choice questions and one 
50-pixel  tolerance  radius  image  point  selection  question  would 
mean that 1 in every 10,000 guess-based attacks would succeed. 
The detailed analysis is omitted due to space limitations. 
4.3  Composite Image Similarity Attacks 
In  a  composite  image  similarity  attack,  an  attacker  collects  a 
large set of scene tagging instance images and manually tags the 
objects  involved.  The  attacker  then  measures  the  similarity 
between the presented image and those in the stored set, returning 
an  answer  based  on  the  closest  stored  scene  tagging  instance. 
However, this type of attack is not practical against our system, as 
the  object  combination-based  manner  of  image  generation  our 
system  utilizes  results  in  an  extremely  large  space  of  possible 
images, even when utilizing a relatively small object database. 
4.4  Object Recognition Attacks 
An object recognition attack utilizes machine vision techniques 
in order to determine a) the number of objects that are present in 
the  image,  b)  the  identity  of  these  objects,  and  c)  the  image 
location of each of these objects.  
The first form of object recognition algorithms we consider are 
the  simplest  –  those  that  measure  the  difference  in  pixel  color 
values  between  object  database  images  and  possible  object 
locations in the problem image. This measurement may be coarse-
grain, as in comparing regional color histograms, or fine-grain, as 
in  measuring  corresponding  pixel  value  differences  between 
objects and potential image locations. A representative candidate 
from  the  group  used  in  our  testing  is  template  matching  via 
measuring normalized pixel-wise difference (PWD). 
Figure  1.  Scene  Tagging  CAPTCHA  image  with  a  frog,  a 
second frog, a butterfly, and a soccer ball present. 
Relative Spatial Location: In this type of question, a user must 
identify and determine the relative spatial location of the objects 
present  in  the  test  image.  An  example  that  might  accompany 
figure 1 is “Name the object that is directly to the upper-left of the 
butterfly”, to which the answer would be “soccer ball”.  Care is 
taken  by  the  system  to  only  generate  questions  to  which  there 
exists  a  clearly  correct  answer,  avoiding  questions  which  may 
cause  confusion  due  to  the  existence  of  multiple  reasonable 
answers.  
Object  Quantity:  This  type  of  question  requires  a  user  to 
identify  an  object  based  on  the  number  of  that  particular  object 
present  in  the  test image. For example, the user might be asked 
"Name  the  object  of  which  there  are  two  present  in  the  image” 
when  presented  with  figure  1,  to  which  the  correct  answer  is 
“frog”.  The  database  may  contain  multiple  image  depictions  of 
each object, such that the multiple instances of the object present 
may take different image forms. 
Logical  Association:  This  type  of  question  asks  a  user  to 
determine the objects present in the scene, and also to determine 
the logical associations between these objects. A question of this 
type  that  might  accompany  figure  1  is  “Name  the  object  that  is 
least  like  the  others  present”  and  the  answer  would  be  “soccer 
ball”  given  that  the  other  three  objects  are  all  animals.  These 
associations  are  based  on  being  members  of  a  shared  logical 
object  group  and  are  set  during  object  database  creation  via 
appropriate  object-group 
the  question 
correctly  typically  requires  recognition  of  all  or  most  of  the 
objects  in  the  image,  making  it  more  difficult  for  automated 
attacks. It is possible that in the future a lexical database such as 
WordNet [14] could be used to automatically set the strength of 
concept associations [4]. 
tagging.  Answering 
3.3  Response Formats 
For  a  given  scene  tagging  problem,  the  question  instructs  the 
user  to  provide  an  answer  via  one  of  the  following  response 
formats. 
Multiple Choice: The first response format is that of selecting 
the correct answer from a list of choices presented to the user. In 
our  prototype  system,  the  user  is  presented  with  16  choices  of 
which one is the correct answer to the associated question and the 
347 
The second, higher-level form of object recognition algorithms 
we  consider  searches  for  correlation  between  object  database 
images  and  the  scene  image  with  regards  to  various  distinctive 
image  locations,  such  as  the  intersections  of  detected  edges  or 
points of great discontinuity in scale-space representations. Strong 
feature matches may then be used in a voting process to determine 
object  presence  and  location.  One  representative  algorithm  that 
has been shown to outperform many others [13] is Scale Invariant 
Feature Transform (SIFT) [12]. Another method for image feature 
generation is Speeded Up Robust Features (SURF) [3]. SURF is 
faster than SIFT and is claimed to be more robust than SIFT to 
various image transformations. We test our system using both of 
these object recognition algorithms. 
5.  SEQUENCE OF SYSTEMATIC IMAGE 
DISTORTIONS 
5.1  Distortion Criteria 
Our  system  of  distortions  consists  of  two  sets,  the  first  being 
applied  only  to  the  background  image  and  the  second  being 
applied  to  the  composite  of  the  background  and  object  images. 
The  need  for  two  different  sets  of  distortions  is  due  to  the 
different  purposes  served  by  these  sets.  Distortion  of  the 
background  image  is  performed  to  impede  attacks  that  utilize 
knowledge  of  the  database  of  background  images.  There  is  no 
necessity  to  preserve  human  recognition  of  background  images, 
thus  drastic  distortions  may  be  considered.  Distortion  of  the 
composite image, conversely, primarily attempts to make machine 
recognition  of  objects  more  difficult.  At  the  same  time,  human 
recognition  of  these  objects  is  crucial.  Thus,  the  sequence  of 
distortions  must  be  chosen  as  to  make  things  difficult  for 
automated  attacks  without  distorting  the  objects  in  the  image 
beyond the point of human recognition. 
5.2  Distortions applied to background image 
Randomized  Clutter:  Primary  distortion  of  the  background 
image  is  done  via  the  use  of  randomly  placed  image  clutter  of 
randomly determined shape and color. While the primary benefit 
of  this  distortion  is  that  it  impairs  attempts  to  identify  the 
background image utilized, an additional benefit is that it may add 
elements  of  interest  to  areas  of  the  background  image  that  may 
otherwise be uninteresting. This not only makes object isolation 
more  difficult,  it  also  results  in  a  larger  number  of  extraneous 
image interest points. 
Global Color Shifting: The color channel values of every image 
pixel  are  shifted  by  a  randomly  determined  amount.  This  color 
shifting  is  performed  to  hamper  attempts  to  utilize  information 
about  the  background  in  reversing  the  more  involved  and 
extensive color shifting that follows during image composition. 
5.3  Distortions applied to composite image 
To  perform  distortions  that  are  localized  in  a  randomly 
determined  fashion,  a  number  of  the  system’s  image  distortions 
utilize  randomly  generated  orthogonal  image  partitions.  These 
divide  the  image  such  that  every  image  location  is  contained  in 
exactly one of these contiguous, rectangular regions. 
Object Scaling: Before their composition with the background, 
object images are scaled horizontally and vertically in a random 
fashion. The dimensions of scaling are independent, and thus the 
aspect ratio of the object image may change. This impairs object 
recognition techniques that rely heavily on the relative position of 
object  image  features  in  order  to  determine  object  presence  and 
location. 
Mesh Warping: Mesh warping [16] warps the images by means 
of  two  2-d  arrays  of  image  coordinates  S  and  D,  such  that  the 
values  of  the  control  pixels  specified  in  S  are  moved  to  the 
destination  coordinates  in  D  and  all  other  pixel  values  are 
calculated  via  means  of  interpolation  between  the  grids.  The 
resulting nonlinear transformation between source and destination 
coordinates  is  valuable  as  a  large  number  of  object  recognition 
algorithms have great difficulty in dealing with non-linear image 
transformations. 
Localized  Color  Shifting:  The  image  is  first  divided  into  a 
randomly  chosen  number  of  orthogonal  partitions.  Then,  on  a 
partition  by  partition  basis,  a  random  value  is  chosen  for  each 
color  channel  (red,  green,  and  blue)  and  the  color  values  of  the 
pixels contained therein are shifted by these amounts. A new set 
of  orthogonal  partitions  is  then  chosen  and  the  color  shifting 
process  is  repeated.  This  results  in  a  large  number  of  image 
segments that have undergone different color shifts. This impacts 
local  color  information  strongly,  breaks  up  contiguous  object 
color segments, and introduces a large number of discontinuities 
to the image.  
Semi-Regular  Object  Clutter:  The  system  places  lines  of 
random  color  and  thickness  in  a  random,  semi-regular  fashion 
over the image. The use of clutter in this stage attempts to exploit 
the  Gestalt  perception  abilities  of  humans,  namely  that  human 
have  a  strong  ability  to  recognize  and  understand  images  in  the 
face  of  incomplete  or  fragmented  visual  information  while 
machines have a difficult time doing the same thing. The partial 
object  occlusions  that  result  are  especially  effective  against 
machine  vision  techniques  that  rely  heavily  upon  object  shape, 
edges, or segmentation. 
Localized  Texture  Effects:  The  image  is  first  divided  into  a 
randomly  chosen  number  of  orthogonal  partitions.  For  each  of 
these  partitions,  the  corresponding  sub-image  will  be  either  be 
dithered  to  a  random  number  of  colors  using  Floyd-Steinberg 
error  diffusion,  quantized  to  a  random  number  of  colors  via  the 
octree  color  quantization  algorithm,  or  have  colored  Gaussian 
noise added. These effects have the most effect on machine vision 
techniques that rely on local texture information, including many 
interest point detectors. 
The scene shown in figure 1 is shown again in figure 2,  having 
had  the  full  sequence  of  image  distortions  applied  during  its 
composition. 
6.  EXPERIMENTAL RESULTS 
6.1  System Design 
A  prototype  of  the  proposed  image-based  CAPTCHA  was 
implemented for use in our preliminary experiments. The system 