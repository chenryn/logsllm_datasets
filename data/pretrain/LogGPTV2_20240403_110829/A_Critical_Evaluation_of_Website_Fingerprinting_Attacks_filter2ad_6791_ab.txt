### Adversary Capabilities and Experimental Assumptions

The adversary is assumed to be capable of replicating client-side settings, including the operating system, network connection, or Tor Browser Bundle (TBB) version. This assumption enables researchers to train and test their models using data collected under consistent conditions. However, for certain types of attacks, particularly non-targeted ones, it may be challenging for the adversary to detect and replicate the user's configuration accurately.

#### Assumptions and References
- **Closed-world**: [11, 26]
- **Browsing behavior**: [11]
- **Page load parsing**: [3, 11, 23, 26, 32]
- **No background noise**: [3, 11, 23, 26, 32]
- **Replicability**: [11, 26]
- **Template websites**: [3]

### Evaluation of Assumptions

In this section, we challenge the assumptions described in Section 3: closed-world, browsing behavior, no background traffic, and replicability. Our goal is to measure the impact of these variables on the accuracy of website fingerprinting (WF) attacks.

#### Datasets

We used two different lists of URLs for our experiments:
1. **Alexa Top Ranking**: A well-known list of the most visited URLs, widely used in previous WF studies and other research domains.
2. **Active Linguistic Authentication Dataset (ALAD)** [15]: A dataset of web visits from real-world users, collected for behavioral biometrics evaluation. It includes data from 80 paid users in a simulated work environment, who performed tasks such as open-ended blogging and summary writing of news articles.

**Statistics of ALAD Dataset:**
- Total unique URLs: 38,716 (excluding news articles)
- Total page loads: 89,719
- Distribution of sites:
  - Top Alexa 100: 4.84%
  - Top Alexa 1000: 50.34%
  - Top Alexa 10000: 68.01%
  - Not in Alexa 100: 44.82%
  - Not in Alexa 1000: 33.93%
  - Not in Alexa 10000: 25.66%

#### Data Collection

To collect network traces, we used the Tor Browser Bundle (TBB) combined with Selenium2 to visit the pages and recorded the network packets using dumpcap. We used the Stem library to control and configure the Tor process, extending the circuit renewal period and disabling UseEntryGuards to avoid fixed guard nodes. We also parsed Tor cells and removed noise by filtering acknowledgments and SENDMEs.

We crawled webpages in batches, visiting each page 4 times and collecting between 5 and 10 batches per crawl, resulting in 20 to 40 visits per webpage. We waited 5 seconds after each page load and left 5-second pauses between each batch. The data collection was conducted using two physical and three cloud-based virtual machines, ensuring identical configurations through Linux Container (LXC) virtualization.

#### Methodology

To reduce the confounding effects of other variables, we crawled the same set of webpages multiple times, changing the value of the variable under evaluation while fixing the rest. For each variable, we defined a control crawl (default value) and a test crawl (value of interest). We used cross-validation and minimized the time gap between control and test crawls.

**Steps:**
1. **k-fold Cross-Validation**: Using data from the control crawl.
2. **Evaluate Classifier Accuracy**: Training on the control crawl and testing with data from the test crawl.

The accuracy obtained in Step 1 serves as a baseline for comparison. We then compare the accuracy in Step 2 with this baseline.

#### Classifiers and Features

Classifiers for WF attacks are based on features extracted from network packet lengths, direction, and inter-arrival times. We evaluated the following classifiers:

- **H [11]**: Naive Bayes, Packet lengths
- **P [23]**: SVM, Packet lengths
- **D [9]**: N-grams, Order, Total bytes, Total time, Up/Downstream bytes, Bytes in traffic bursts
- **W [32]**: SVM (Fast-Levenshtein), Cell traces
- **T**: Decision tree, Same features as P

**Classification Parameters:**
- **k**: Number of sites in the world
- **ntrain/test**: Number of batches for training/testing
- **Ttrain/test**: Number of instances for training/testing
- **p**: Total number of correct predictions
- **m**: Number of trials

**Accuracy Metrics:**
- **Acc_control**: Average accuracy for m trials in control crawl (Step 1)
- **Acc_test**: Average accuracy for m trials in Step 2

#### Time Impact

Webpage content changes over time, affecting traffic traces and WF attack accuracy. We evaluated the effect of staleness by training a classifier on traces from t = 0 and testing it on traces collected within 90 days. The accuracy drops rapidly, falling below 50% within 10 days. Therefore, for subsequent experiments, we chose control and test crawls within a 5-day period.

#### Multitab Browsing

We evaluated the success of a classifier trained on single-tab browsing and tested on multitab browsing. To simulate multitab behavior, we crawled the home pages of Alexa Top 100 sites while loading another random page in the background with a delay of 0.5-5 seconds.

This comprehensive evaluation helps us understand the robustness of WF attacks under various realistic scenarios.