User: I am building a logging-bridge between rabbitmq messages and Django application to store background task state in the database for further investigation/review, also to make it possible to re-publish tasks via the Django admin interface.
I guess it's nothing fancy, just a standard Producer-Consumer pattern.

Web application publishes to message queue and inserts initial task state into the database
Consumer, which is a separate python process, handles the message and updates the task state depending on task output

The problem is, some tasks are missing in the db and therefore never executed.
I suspect it's because Consumer receives the message earlier than db commit is performed. 
So basically, returning from Model.save() doesn't mean the transaction has ended and the whole communication breaks.
Is there any way I could fix this? Maybe some kind of post_transaction signal I could use?
Thank you in advance.
Assistant: Web application publishes to message queue and inserts initial task state into the database

Do not do this.
Web application publishes to the queue.  Done.  Present results via template and finish the web transaction.
A consumer fetches from the queue and does things.  For example, it might append to a log to the database for presentation to the user.  The consumer may also post additional status to the database as it executes things.
Indeed, many applications have multiple queues with multiple produce/consumer relationships.  Each process might append things to a log.  
The presentation must then summarize the log entries.  Often, the last one is a sufficient summary, but sometimes you need a count or information from earlier entries.