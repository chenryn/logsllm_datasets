### Environment Details

- **Elasticsearch Version**: 5.0.0~alpha2
- **JVM Version**:
  - Java version: 1.8.0_91
  - Java(TM) SE Runtime Environment (build 1.8.0_91-b14)
  - Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)
- **Operating System**:
  - Linux ip-10-10-155-12 3.13.0-74-generic #118-Ubuntu SMP Thu Dec 17 22:52:10 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

### Problem Description

#### Expected Behavior
- The `delete-by-query` plugin should successfully delete a large number of documents without causing system instability or resource exhaustion.

#### Actual Behavior
- When attempting to delete a large number of documents using the `delete-by-query` plugin with a `match_all` query, the operation fails and causes system instability, including high CPU usage, excessive memory consumption, and unresponsive nodes.

### Steps to Reproduce

1. Create a large number of documents.
2. Attempt to delete the documents using a `match_all` query and the `delete-by-query` plugin.
3. Observe the system failure.

### Relevant Logs

The following log entries may be observed:

```
[2016-05-15 00:38:29,675][ERROR][action.deletebyquery] [client] scroll request [...] failed, scrolling document(s) is stopped
Failed to execute phase [query], all shards failed; shardFailures {
  RemoteTransportException[[worker][10.10.155.231:9300][indices:data/read/search[phase/query/scroll]]]; nested: SearchContextMissingException[No search context found for id [3894]];
  RemoteTransportException[[worker][10.10.155.184:9300][indices:data/read/search[phase/query/scroll]]]; nested: SearchContextMissingException[No search context found for id [3894]];
  RemoteTransportException[[worker][10.10.155.83:9300][indices:data/read/search[phase/query/scroll]]]; nested: SearchContextMissingException[No search context found for id [3897]];
  RemoteTransportException[[worker][10.10.155.181:9300][indices:data/read/search[phase/query/scroll]]]; nested: SearchContextMissingException[No search context found for id [3894]];
  RemoteTransportException[[worker][10.10.155.192:9300][indices:data/read/search[phase/query/scroll]]]; nested: SearchContextMissingException[No search context found for id [3897]];
}
...
```

or

```
2016-05-15 23:38:55,644 WARN rest.suppressed /_bulk Params: {}
CircuitBreakingException[parent Data too large, data for  would be larger than limit of 2994274304/2.7gb]
at org.elasticsearch.indices.breaker.HierarchyCircuitBreakerService.checkParentLimit(HierarchyCircuitBreakerService.java:211)
at org.elasticsearch.common.breaker.ChildMemoryCircuitBreaker.addEstimateBytesAndMaybeBreak(ChildMemoryCircuitBreaker.java:128)
...
```

### Additional Observations

- Multiple worker nodes experienced CPU usage spikes up to 200%, and consumed all available swap and RAM (up to 44 GB in most cases).
- Searches took approximately 15 minutes to complete.
- A significant backlog of scroll requests and `delete-by-query` tasks was observed, none of which could be canceled.
- The `delete-by-query` plugin appears to build a bulk delete request without considering the potential size, leading to excessively large queries.

### Suggested Improvements

1. **Make the Plugin Cancellable**:
   - Introduce a cancellation mechanism that can be checked between pages of the scroll request to allow for graceful termination.

2. **Error Handling for Large Queries**:
   - Implement a check in the search loop to compare the `BulkRequest#estimatedSizeInBytes` against the cluster's maximum request size limits and error out if the estimated size exceeds the limit.

3. **Chunk Bulk Requests**:
   - Break down bulk delete requests into smaller, more manageable components and process them piecemeal to avoid overwhelming the system.

By addressing these issues, the `delete-by-query` plugin can be made more robust and less likely to cause system instability when handling large datasets.