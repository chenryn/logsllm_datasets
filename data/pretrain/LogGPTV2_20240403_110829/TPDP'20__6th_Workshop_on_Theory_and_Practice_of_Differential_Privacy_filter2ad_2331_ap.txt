objective function on L is at most a factor of KG < 1.783 larger than on L0, which implies that
(cid:96)∗(L) ≤ KG · (cid:96)∗(L0) = O((cid:112)|Q| · d).
To summarize, the algorithm for the set Q of 2-way parities operates as follows:
1. Calculate the exact answers
y = ax = (q(x))q∈Q ∈ K ⊆ Rd2
.
2. Add Gaussian noise to the coordinates of y:
O((cid:112)|Q| · log(1/δ))
˜y = y +
εn
· N(0, 1)|Q|.
3. Project back to L: Let
ˆy = argminz∈L (cid:107)z − ˜y(cid:107)2.
By the analysis we did earlier, the average error per query we obtain is at most
E
coins of M, q ∈ Q
[|yq − ˆyq|] ≤ O
≤ O
as desired.
(cid:32)(cid:112)log(1/δ)
(cid:112)|Q| · εn
(cid:32)(cid:112)d · log(1/δ)
εn
(cid:33)1/2
(cid:33)1/2
· (cid:96)∗(L)
,
The theorems above show that we can bypass the intractability of producing diﬀerentially private
summaries by focusing on speciﬁc, structured query classes, and by avoiding synthetic data. We
summarize the state of knowledge about t-way marginals in Table 7.1. (Results for all marginals,
i.e. Qconj(d) roughly correspond to the case t = d, but in some cases will be oﬀ by a logarithmic
factor, and we don’t include the result based on the hereditary partial discrepancy of Qconj(d) being
˜Θ((2/
3)d) [76].)
√
As can be seen from the table, there are still important gaps in our state of knowledge, such as:
65
(d) when t (cid:28) d with (ε, δ)-diﬀerential privacy on a dataset of size
Table 7.1: Error bounds for Qconj
n. Computational lower bounds hold under plausible cryptographic assumptions (e.g. exponentially
secure digital signatures with linear-time veriﬁcation). “synth?” indicates whether the entry refers
to algorithms that generate synthetic data.
t
type
upper O
upper O
upper α
upper
εn
(cid:19)
bound
d log(1/δ)
εn
log(1/δ)·log log d
√
(cid:18) dt/2·√
(cid:19)1/2
(cid:18) t log d
(cid:16) ˜O(dt/4) ·(cid:112)log(1/δ)/εn
(cid:17)1/2
(cid:17)(cid:27)
(cid:26) ˜Ω(dt/2)
(cid:16) 1√
(cid:110) t log(d/t)
(cid:111)(cid:17)
(cid:16)
(cid:27)
(cid:26)
(cid:16) t
(cid:17)1/2
, ˜Ω
n
, 1
, Ω(1)
n
√
d
εn
constraints
runtime
synth?
ref
poly(n, dt)
no
Thm. 2.7
poly(n, 2d)
yes
Thm. 4.3
poly(n)
poly(n, dt)
any
any
any
≤ 2d1−o(1)
no
no
no
no
no
Thm. 7.5
Thm. 7.7
[65]
[14]
Thm. 5.23
yes
Thm. 6.12
√
n ≥ dc
t·log(1/α)/ε
t even
t = O(1)
n ≤ dO(1)/ε
t ≥ 2
lower min
n
lower Ω
min
lower min
˜Ω
lower Ω(1)
Open Problem 7.8. Is there a polynomial-time diﬀerentially private algorithm for estimating all
(higher-order) marginals with vanishing error α = o(1) on a dataset with n = poly(d) rows from
data universe X = {0, 1}d? Or at least all t-way marginals for some t = ω(1)?
Open Problem 7.9. Is there a polynomial-time diﬀerentially private algorithm for estimating all
3-way marginals with vanishing error α = o(1) on a dataset with n = o(d) rows from data universe
X = {0, 1}d?
Open Problem 7.10. For what other classes of queries can one bypass the intractability of
generating diﬀerentially private synthetic data and answer more than n2 queries with polynomial-
or subexponential-time algorithms?
8 Private PAC Learning
We now examine the possibility of machine learning in Valiant’s PAC Model [105], under diﬀerential
privacy. (See [69] for background on the PAC Model.)
8.1 PAC Learning vs. Private PAC Learning
Recall that PAC Learning considers for each input length d, two sets of functions:
• a concept class C = Cd = {c : {0, 1}d → {0, 1}}, from which the unknown concept c we are
trying to learn comes.
• an hypothesis class H = Hd = {h : {0, 1}d → {0, 1}}, which contains the functions we will
use to try to represent our learned approximation of c.
66
Deﬁnition 8.1 (PAC learning). A concept class C is PAC-learnable if there exists an algorithm
L (called the learner) and a number n polynomial in d (called the sample complexity) such that
for every distribution D on {0, 1}d and every c ∈ C, if we sample points x1, . . . , xn, xn+1 chosen
independently according to D, with high probability L(x1, c(x1),··· , xn, c(xn)) returns a function
h ∈ H such that h(xn+1) = c(xn+1).
If H = C, we call L a proper learner and say that C is properly PAC-learnable. If L is poly-time
computable as are the functions in H (given a poly(d)-bit description of a function h ∈ H as output
by L and an input w ∈ {0, 1}d, we can evaluate h(d) in time poly(d)), then we say that L is an
eﬃcient learner and say that C is eﬃciently PAC-learnable.
Deﬁnition 8.2 (private PAC learning). Private PAC Learning is deﬁned in the same way as
PAC Learning, but with the additional requirement that L is diﬀerentially private. That is, for
n) that diﬀer in one coordinate i ∈ [n],
all sequences (x1, y1), . . . , (xn, yn) and (x(cid:48)
L((x1, y1), . . . , (xn, yn)) and L((x(cid:48)
n)) are (ε, δ)-indistinguishable for some constant
ε (e.g. ε = 1) and δ negligible in n and d.
1, y(cid:48)
1), . . . , (x(cid:48)
1), . . . , (x(cid:48)
n, y(cid:48)
n, y(cid:48)
1, y(cid:48)
Taking ε to be a constant is WLOG due to a generic reduction for improving ε (increase the
sample size by a factor of ε/ε(cid:48), and run the original learner on random ε/ε(cid:48) subsample). The success
probability of the learner can also be ampliﬁed via “boosting,” which has a diﬀerentially private
analogue [42].
Note that while the deﬁnition of PAC Learning only speaks of inputs that consist of i.i.d. samples
from an unknown distribution that is consistent with some concept c ∈ C, we require privacy on all
(worst-case) pairs of neighboring input sequences. Indeed, if our modelling assumptions about the
world are wrong, we naturally expect that our learner might fail, but we do not want the privacy
promises to the data subjects to be broken. Also note that we consider the output of the learner
to be the entire description of the hypothesis h, not just its prediction h(xn+1) on the challenge
point.
Amazingly, there is no gap between PAC Learning and Private PAC Learning, if we do not care
about computation time:
Theorem 8.3 (generic private learner [66]). If C is (non-privately) PAC-learnable (equivalently,
VC(C) ≤ poly(d)), then it is privately and properly PAC-learnable with sample complexity O(log |C|) ≤
O(d · VC(C)) = poly(d).
The relation log |C| ≤ d · VC(C) is the Perles-Sauer-Shelah lemma. (See [69].)
Proof. We use the exponential mechanism (Proposition 4.2). Let H = C. On input (x1, y1)··· (xn, yn),
we:
output h ∈ H with probability ∝ e−ε·|{i:h(xi)(cid:54)=yi}| .
Since score(x, h) = −|{i : h(xi) (cid:54)= yi}| has sensitivity 1 as a function of the dataset x, Proposition 4.2
tells us that this mechanism is 2ε-diﬀerentially private.
To prove that the learner succeeds with high probability, consider x1,··· , xn that are taken
If n ≥ O(VC(C) · log(1/α)/α2), then by Occam’s Razor from learning theory (cf. [69]) tells us
according to some unknown distribution D, and let yi = c(xi).
that with high probability over x1 ··· xn, we have:
− Pr
w∼D
[h(w) = c(w)]
(cid:12)(cid:12)(cid:12)(cid:12) ≤ α.
∀h ∈ C
(cid:12)(cid:12)(cid:12)(cid:12) #{i : h(xi) = c(xi)}
n
67
Combining this with Proposition 4.2, we know that with high probability the hypothesis h we
output satisﬁes:
Pr
w∼D
[h(w) = c(w)] ≥ #{i : h(xi) = c(xi)}
− α
n
≥ argmaxh∗#{i : h∗(xi) = c(xi)} − O(log |C|)/ε
− α
n
n − O(log |C|)/ε
=
≥ 1 − 2α,
n
− α
provided n ≥ O(log |C|)/εα.
We are done when taking
(cid:18)
n = O
max
(cid:26) log |C|
εα
,
VC(C) · log(1/α)
α2
(cid:27)(cid:19)
(cid:28) 1.
8.2 Computationally Eﬃcient Private PAC Learning
Unfortunately, as is often the case with the exponential mechanism, Theorem 8.3 does not pro-
duce computationally eﬃcient private learners. Thus, we now investigate what can be learned in
polynomial time under diﬀerential privacy.
Non-privately, most examples of computationally eﬃcient PAC learners are learners in the
statistical query model of Kearns [68]. This is a model where the learner does not get direct access
to labelled samples (xi, c(xi)), but is allowed to obtain additive approximations to the expectation of
any (eﬃciently computable) function f : {0, 1}d × {0, 1} → [0, 1] on the labelled distribution. That
is, on specifying statistical query f , the learner obtains an answer in the range Ew←D[f (w, c(w))]±
1/ poly(n). Eﬃcient statistical query learners can be simulated by eﬃcient PAC learners because
expectations Ew←D[f (w, c(w))] can be estimated to within ±1/ poly(n) by taking the average of
f (xi, c(xi)) over m = poly(n) random samples xi ← D. Such estimations are also easily done with
diﬀerential privacy, as an average of f (xi, yi) over m samples (xi, yi) has global sensitivity at most
2/m as a function of the dataset, and thus can be estimated via the Laplace Mechanism. Thus we