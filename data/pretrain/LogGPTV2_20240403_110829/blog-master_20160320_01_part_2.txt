truncate() {    
psql -h $IP -p $PORT -U $USER $DBNAME 0;x++))     
do     
# ------------------------------------------------------    
echo "Round $x test start: `date +%F%T` `date +%s`"    
for ((i=1;i>./$i.log 2>&1 &     
done     
wait    
echo "Round $x test end: `date +%F%T` `date +%s`"    
# ------------------------------------------------------    
if [ $((`date +%s`-$START)) -gt 86400 ]; then    
  echo "end `date +%F%T` `date +%s`"    
  echo "duration second: $((`date +%s`-$START))"    
  exit 0    
fi    
echo "Round $x test end, start truncate `date +%F%T` `date +%s`"    
truncate    
echo "Round $x test end, end truncate `date +%F%T` `date +%s`"    
done    
```    
测试        
```    
nohup ./test.sh xxx.xxx.xxx.xxx 1921 postgres postgres postgres >./test.log 2>&1 &    
```    
## 测试结果    
24小时完成12轮测试，平均每轮测试耗时7071秒。     
506万行/s（每行360字节），1.78GB/s，全天插入4372亿，154TB数据。        
## 查询性能    
```    
postgres=# select min(crt_time),max(crt_time) from test1;    
            min             |            max                 
----------------------------+----------------------------    
 2016-04-08 00:32:26.842728 | 2016-04-08 02:29:41.583367    
(1 row)    
postgres=# explain select count(*) from test1 where crt_time between '2016-04-08 00:32:00' and '2016-04-08 00:33:00';    
                                                                            QUERY PLAN                                                                                 
-------------------------------------------------------------------------------------------------------------------------------------------------------------------    
 Aggregate  (cost=1183919.81..1183919.82 rows=1 width=0)    
   ->  Bitmap Heap Scan on test1  (cost=14351.45..1180420.19 rows=1399849 width=0)    
         Recheck Cond: ((crt_time >= '2016-04-08 00:32:00'::timestamp without time zone) AND (crt_time   Bitmap Index Scan on idx_test1  (cost=0.00..14001.49 rows=1399849 width=0)    
               Index Cond: ((crt_time >= '2016-04-08 00:32:00'::timestamp without time zone) AND (crt_time <= '2016-04-08 00:33:00'::timestamp without time zone))    
(5 rows)    
Time: 0.382 ms    
postgres=# select count(*) from test1 where crt_time between '2016-04-08 00:32:00' and '2016-04-08 00:33:00';    
  count      
---------    
 2857968    
(1 row)    
Time: 554.474 ms    
```    
## 如何潇洒地做到每天写入百TB数据  
1、合理的环境部署和数据库部署，请参考  
[《PostgreSQL on Linux 最佳部署手册》](../201611/20161121_01.md)    
2、异步提交  
```  
set synchronous_commit=off;  
```  
3、关闭被写入表的autovacuum_enable和toast.autovacuum_enable开关。建议不需要进行海量输入的表，不要关闭autovacuum。  
```  
postgres=# alter table test_1 set (autovacuum_enabled =off);  
ALTER TABLE  
postgres=# alter table test_1 set (toast.autovacuum_enabled =off);  
ALTER TABLE  
```  
4、使用UNLOGGED TABLE（不建议生产使用）  
避免XLOG writer lock瓶颈。  
5、使用2-4倍CPU核数的连接  
例如32核，建议64-128个连接。少了发挥不了CPU的性能，多了无益（反而增加CPU时间片切换带来的开销）。  
6、每个连接写不同的表。  
减少表的extend file exclusive lock的锁冲突。如果不好实现的话，可以使用PostgreSQL提供的动态函数功能。在[《PostgreSQL on ECS多云盘的部署、快照备份和恢复》](../201708/20170812_01.md)有介绍。        
7、使用批量提交（COPY或INSERT INTO TABLE VALUES (),(),...();）  
批量提交减少交互开销，减少代码路径，提高性能。  
8、如果需要使用时序查询，建议使用BRIN索引，不要使用B-TREE索引。请参考  
[《PostgreSQL 物联网黑科技 - 瘦身几百倍的索引(BRIN index)》](../201604/20160414_01.md)    
9、如果你的业务需要实时的分析。参考[《"物联网"流式处理应用 - 用PostgreSQL实时处理(万亿每天)》](201512/20151215_01.md)  
另一组测试数据，以及对应的测试方法参考：  
[《PostgreSQL on ECS多云盘的部署、快照备份和恢复》](../201708/20170812_01.md)    
将PostgreSQL部署在ECS虚拟机上，也已经接近每秒千万行、一天接近1万亿行的写入速度。  
里面附录了数据结构的定义、批量写入的方法、动态函数等。  
## 小结      
1\.  这个CASE主要的应用场景是实时的大数据入库，例如 物联网 的应用场景，大量的 传感器 会产生庞大的数据。      
又比如传统的 运营商网关 ，也会有非常庞大的流量数据或业务数据需要实时的入库。      
索引方面，用到了PostgreSQL黑科技BRIN。       
2\.  除了实时入库，用户如果需要流式实时处理，可以参考基于PostgreSQL的流式处理方案，       
一天处理1万亿的实时流式处理是如何实现的？         
[《"物联网"流式处理应用 - 用PostgreSQL实时处理(万亿每天)》](../201512/20151215_01.md)    
3\.  瓶颈, 还是在IO上面 , 有几个表现，TOP大量进程处于D(front io)状态  。      
```    
       w: S  --  Process Status    
          The status of the task which can be one of:    
             ’D’ = uninterruptible sleep    
             ’R’ = running    
             ’S’ = sleeping    
             ’T’ = traced or stopped    
             ’Z’ = zombie    
```    
所有块设备的使用率均达100%  。       
清理数据时 ：     
```    
Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %util    
dfa               0.00     0.00 5807.39 167576.65 1464080.93 1340613.23    16.18   535.69    3.02   0.01 116.77    
dfb               0.00     0.00 5975.10 185132.68 1506714.40 1481061.48    15.63   459.46    2.32   0.01 110.62    
dfc               0.00     0.00 5715.56 182584.05 1440771.98 1460672.37    15.41   568.02    2.93   0.01 112.37    
```    
插入数据时 ：    
```    
Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %util    
dfa               0.00     0.00    0.00 235936.00     0.00 1887488.00     8.00  2676.34   11.17   0.00  99.10    
dfb               0.00     0.00    0.00 237621.00     0.00 1900968.00     8.00    66.02    0.10   0.00  99.10    
dfc               0.00     0.00    0.00 239830.00     0.00 1918632.00     8.00    10.66    0.04   0.00 101.30    
```    
IO层面的性能问题，可以通过优化代码（例如 PostgreSQL bgwriter 在写出数据时，尽量顺序写出），便于OS层进行IO合并，来缓解IO压力，从这个信息来看，单次写IO的大小还可以再大点。      
有几个工具你可能用得上，perf, systemtap, goprof.         
如果要较全面的分析，建议把PostgreSQL --enable-profiling打开用于诊断。        
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")