### DITL/B-Root Dataset
This dataset was collected from the B-Root nameserver as part of the DITL-2013 initiative and is also available through DNS-OARC. We chose B-Root because, at the time of collection, it did not use anycast, allowing this dataset to capture all traffic directed to a single root DNS instance. Although B-Root is one of 13 instances, it represents only a fraction of the total root traffic. This dataset is used to represent an authoritative server, as commercial authoritative server data is generally not accessible.

### Generality of Datasets
These datasets cover each class of DNS resolver (as described in § II-A), thus spanning a wide range of behaviors within different parts of the DNS system. However, each dataset is unique, and we do not claim that any one dataset represents all servers of its class. We are aware of specific characteristics and anomalies in each dataset. Additionally, we treat each source IP address as a distinct computer, although NAT may introduce some optimism in our analysis, particularly for home routers with DNS proxies.

### Trace Replay and Parameterization
To evaluate connection hits for various timeout windows, we replay these datasets through a simple simulator. The simulator allows us to adjust the timeout window from 10 to 480 seconds and track active connections to determine the number of concurrent connections and the fraction of connection hits. We exclude the first 10 minutes of trace replay to avoid transient effects due to a cold cache.

We convert the number of concurrent connections to hardware memory requirements using two estimates:
1. **Experimental Measurement**: We measured idle TCP connections by opening 10,000 simultaneous connections to Unbound and measuring the peak heap size with Valgrind. On a 64-bit x86 computer running Fedora 18, we estimate each TCP connection to require approximately 260 kB, and each TLS connection to require 264 kB. Adding an estimated 100 kB of kernel memory per connection, we arrive at a very loose upper bound of 360 kB.
2. **Google's Optimizations**: Google transitioned Gmail to TLS without additional hardware, reporting a memory usage of 10 kB per connection with minimal CPU cost due to TLS [44]. Based on their optimizations, we conservatively estimate a per-connection memory cost of 150 kB.

### Concurrent Connections and Hit Fraction
The trace replay of the three datasets provides several observations:
1. **Usage Over Time**: The variation in the number of active connections over the course of the day is surprisingly small. For Level 3, connections vary by ±10% when measured over one-second intervals, with slightly more variation for DNSChanger and less for B-Root (graphs omitted due to space). Connection hit fractions are even more stable, varying by only a few percent.
2. **Summary Statistics**: Given this stability, Figure 2 summarizes the usage with medians and quartiles. The three servers have very different absolute numbers of active connections, consistent with their client populations. All servers show asymptotic hit fractions with diminishing benefits beyond timeouts of around 100 seconds (Figure 2c). The asymptote varies by server: with a 120-second window, DNSChanger is at 97-98%, Level 3 at 98-99%, and B-Root at 94-96%. These fractions indicate that connection caching will be highly effective.

**Recommendations**:
- **Timeouts**: We propose timeouts of 60 seconds for recursive resolvers and 20 seconds for authoritative servers, based on the data in Figure 2 and a conservative approach to server load. We recommend that clients and servers maintain connections for as long as they have resources, rather than preemptively closing them.
- **Memory Requirements**: With 60-second and 20-second timeouts for recursive and authoritative servers, respectively, the required RAM is as follows:
  - **DNSChanger**: 0.3 GB (2k connections)
  - **Level 3**: 3.6 GB (24k connections)
  - **B-Root**: 7.4 GB (49k connections)
  These values are based on the 75th percentiles in Figure 2 and include both user and kernel memory, with some optimization, in addition to memory for actual DNS data. These requirements are well within the capabilities of current commodity server hardware. With Moore's Law, memory growth outpaces root DNS traffic, making future deployment even easier. Older servers with limited memory may set smaller timeouts and rely on clients to use TCP Fast Open and TLS Resume to quickly restart terminated connections.

### Performance Under Attack
We next consider the role of DNS in denial-of-service (DoS) attacks, focusing on both amplification attacks and the performance of a DNS server under attack. In both cases, we show that TCP mitigates the problem, and TLS does not exacerbate it.

#### DNS: Amplifying Attacks on Others
Recent amplification attacks use DNS servers to magnify the impact on victims [74], [48]. An attacker's botnet spoofs traffic with the victim's source address, and the DNS server amplifies a short query into a large reply. Table IV shows our measurements of amplification factors for three classes of attacks: DNS over UDP, and DNS over TCP without and with SYN cookies. DNS over UDP can amplify an attack by up to 40 times, while TCP can amplify by up to 6 times. With SYN cookies, TCP does not retransmit SYN-ACKs, eliminating amplification.

**Rate Limiting**: DoS prevention also requires rate limiting, which can help defuse UDP-based amplification. During a transition from UDP to TCP, wider use of TCP can allow more aggressive rate limits for TCP, as shown in § V-B. Partial use of TCP can also enable more aggressive rate limiting.

#### Direct Denial-of-Service on the DNS Server
We consider UDP and TCP attacks designed to overwhelm the DNS server itself. While some DoS attacks target link bandwidth, UDP attacks on DNS often target server CPU usage, and TCP attacks can overwhelm OS limits on active connections. Current DNS operators overprovision by a factor of three [11] to absorb attacks. We aim to show that UDP attacks are a threat, and naive TCP services are vulnerable, but TCP services using SYN cookies force attackers to use far more resources.

**Evaluation Setup**: To evaluate a DoS attack, we deployed the network topology shown in Figure 3 in the DETER testbed. We sent foreground traffic from F to a DNS server S, then evaluated the effects of attack traffic (A1 to Am) sent to the server. The traffic merges at a router (IXP, an Internet Exchange Point) and is sent to the server behind a bottleneck link. The server hosts a DNS domain with 6.5M names in example.com, and the attacker queries random names that exist in this domain. The server is a single-core 2.4 GHz Intel Xeon running Linux Ubuntu-14.04 (64-bit).

**Protocol Combinations**: We compared several combinations of protocols for attacker and legitimate, foreground traffic (Table V). We focused on all-UDP traffic and three cases of all-TCP use to compare current DNS with proposed TCP deployments. While the future will include both TCP and UDP usage, these "pure" cases show the limits. We used NSD-4.1.0 as our DNS server, with the OS and application configured to support either 65k or 4k TCP connections.

This setup represents a scaled-down version of a typical deployment, providing insights into the effectiveness of different protocol combinations in mitigating DoS attacks.