-20.06% -2.72%
LCOM 58 74
20.00% 72.50% NOA
NORM
-21.67% -3.75%
NSC 300 386
-3.75% 7.50% EC
WMC
-18.03% -3.20%
11
DIT -1.27% 2.07% PCCPF 11
RMD
-9.98% -0.00%
RMA UF28 35
-0.00% 45.45%
RMI
-0.00% 5.64%
563 623
CE -0.00% 130.00% EVTS
CA
-0.00% 100.00%
3 7
NBD -8.00% -1.53% SES
PAR
-0.43% 22.96%
2 3
VG DEV
-16.77% -2.77%
0 50 100
Variation 0 500 1000
0.50
0.25
0.00
-0.25
-0.50
Eclipse E cE lidi pt so er - VF iil e Ee c w l- iE L pd si ot ei n n g Vg ieMe wt -h EPEo cad ld i c it k- psaU eg n e E Ed cdo E li ix t pp o sl r e-o r F EEie l cr d le i i t poC srl e-o Fs Ui Ve l i ne e aEw tO c- elp i gGe p oon s rd ie zeC Vl i da -es F Jis w al -e v- F a eS a Ea t dv u Eie tr cle o i r pE sRn eE u v ldy i e V Et ir- ce lS iC i w po -n sp Eg D ely xue e- p V cl iiC uel c ti i Ea wc t cn- lk e igT d py T spC a ee s Eo k cd VC l ise i-h epe s wMc -eak i Cn Vn ou ig a del e wE - Sv Ge mit en lt l ES t clEa V ii cg l psi i sun p ea g sli e z ia eVt ii weEo -dn wi C-t E o- cM dlP ie ea t ps rt Ssie ec ms eV li lV i ee Pw a-w cO kaut gli e ne Ex Upl no E cVr i ad te eitr e- w gsD o- re S il zhet eoe d Rw - e fEV aci F l ci ie tl p oew s r- Pie rE n ox g cM -p eao sDrr set k le et Mt ip e El n ca i lRc inee pgs so eP lur u Vc igie es n- w-Ab Meo tu rt ics N- as vr ic E gd ai tt e- -FiC l Ou e pt - eI n mp Do er ct laration
V
c
TEAM High VG Reduction, High PCC Low VG Reduction, High PCC
Figure8: Teams(11Avs. 51)withdistinctVGvariancepositioningbutsimilarPCClevels
were less complex, and that is confirmed by the UF, NOA and PCC metrics.
5.2. RQ2. Is there any association between software complex-
ity and the underlying development activities in refactoring
practices?
With the evidences shown in RQ1 for the two distinct refactoring meth-
ods, one may question if the product complexity reduction gains are mono-
tonically correlated with the development activities which originated them.
28
We used the Spearman correlation coefficient to measure the strength of
correlation between metrics of these two dimensions, product and process
complexities. This coefficient ranges from -1 to 1, where -1 and 1 correspond
to perfect negative and positive relationships respectively, and 0 means that
the variables are independent of each other.
Tovalidateourresults, weperformedasignificancetesttodecidewhether
based upon this sample there is any or no evidence to suggest that linear cor-
relation is present in the population. As such, we tested the null hypothesis,
H , and the alternative hypothesis, H , to gather indication of which of
0 1
these opposing hypotheses was most likely to be true.
Let p be the Spearmans’ population correlation coefficient both for au-
s
tomatic and manual refactoring, then we can thus express this test as:
H : p = 0 : No monotonic correlation is present in the practice.
0 s
H : p (cid:54)= 0: A monotonic correlation is present in the practice.
1 s
Automatic Refactoring. After computing the Spearman correlation coef-
ficient on the subset of teams doing automatic refactoring, and despite the
fact that some correlations were slightly negative as we expected, we got no
significant statistics on the correlation of ∆VG and PCC or any other pair
of metrics, as shown by Spearmans’ rho and p-value in Table 4.
Observation 4: No significant correlation was found between
product and process metrics on automatic refactoring practices.
Hence, we can say that we cannot reject the null hypothesis, H , meaning
0
that a monotonic correlation cannot said to be found between code cyclo-
matic complexity and process cyclomatic complexity or any other process
metric.
29
Table 4: Spearmans’ Correlation - Refactoring Tasks
Automatic Refactoring Manual Refactoring
∆VG ∆VG
Factors Spearmans’ rho p-value Spearmans’ rho p-value
PCC -0.02 0.9707 0.43 0.0432*
UF 0.01 0.5218 0.32 0.3427
SES 0.15 0.7489 0.24 0.2814
DEV -0.05 0.7342 0.03 0.8193
NPER -0.19 0.4976 0.32 0.0197*
NISP -0.10 0.6875 0.35 0.0120*
PCCPF -0.01 0.7787 0.45 0.0059*
NCAT -0.11 0.6309 0.39 0.0096*
NCOM -0.05 0.6240 0.42 0.0712
*Statistically significant if p-value < 0.05
Manual Refactoring. When analyzing the dataset with manual refactor-
ing activities, we found that product complexity reduction was moderately
correlated with the process cyclomatic complexity and several other metrics
process related. Table 4 presents Spearmans’ rho and p-value, highlighting
the significant correlations16.
Observation 5: A moderate correlation was found between prod-
uct metrics and process metrics on manual refactoring tasks. It
is relevant to highlight the presence of a moderate positive correlation be-
tween the product cyclomatic complexity reduction (∆VG) and the overall
process cyclomatic complexity(PCC) and per unique file touched(PCCPF).
This means that the more actions the teams have done within the IDE the
bigger the gains obtained in complexity reduction.
16Other product and process metrics were omitted due to the absence of significant
correlations
30
NCAT 0.77
NFILES 0.53 0.58
PCC 0.91 0.56 0.68
NISP 0.42 0.41 0.37
rho
1.0
0.5
SES 0.63 0.64 0.52 0.46 0.54
0.0
-0.5
-1.0
DEV 0.28 0.32 0.38
PCCPF 0.4 0.43 0.42
VG 0.45 0.35 0.43 0.39
NPER 0.32 0.3 0.19 0.38 0.34
VG PCCPF DEV SES NISP PCC NFILES NCAT NCOM
Figure 9: Manual Refactoring correlation results
Observation 6: Weak to moderate correlations were found be-
tween product complexity reduction and IDE command categories.
Weak to moderate correlations emerge when we pair the product complex-
ity reduction with the number of the IDE command categories(NCAT), IDE
perspectives activated(NPER) and the number of distinct physical locations
from where the task was performed(NISP). Based on the significance tests,
we can reject H , and accept H , meaning that a monotonic correlation ex-
0 1
ists between code cyclomatic complexity and process cyclomatic complexity
as well as with the other highlighted metrics.
31
Observation 7: No significant correlations were found between
any process metrics and product metrics, except for ∆VG. All prod-
uct and process metrics collected are shown in Tables A.7 and A.8.
Figure 9 plot only the significant correlations17 among all those we stud-
ied. As expected, process metrics show strong correlations between them-
selves, however, we find this result obvious and not relevant withing the
context of this study.
5.3. RQ3. Using only process metrics, are we able to predict with
high accuracy different refactoring methods?.
Process metrics have been confirmed as suitable predictors for many soft-
ware development prediction models. They were found not only suitable,
theyperformedsignificantlybetterthancodemetricsacrossalllearningtech-
niques in several studies [78, 28].
Our goal was to use the process metrics described in Table A.8, to predict
if a refactoring task executed by a group of teams had been done automat-
ically, using the JDeodorant features, or manually, using only the Eclipse
native functionalities or driven by developers skills. Each subject in our
dataset has the class to predict labelled as AR and MR for automatic and
manual refactoring, respectively. In this case, we did not use metrics from
Table A.9 because that would introduce bias in our models since the process
extended metrics can easily be used to understand if developers used or not
IDE built in features or their own skills during a refactoring practice.
Table5presenttheresultsforthe5bestmodelswegotoutofthe≈30,000
we evaluated on our research. In this context, the machine learning models
used were built by assembling and testing supervised or unsupervised al-
gorithms adjusted with feature selection and hyperparameter optimization.
From the models built, the ones with higher ROC were chosen. A brief ex-
planation of each algorithm can be found in Appendix A.3, as well as the
code obtained from training Model 1.
Observation 8: Random Forest confirms its accuracy. Random
Forest models were found to be the ones with higher accuracy in predicting
refactoring opportunities in previous studies [16]. We observe the same be-
haviour. Random Forest shows twice in the top 5 of our best models, with a
ROC value of 0.983 and 0.939 for Model 1 and 2, respectively. In both cases,
the models were computed by a meta learner which builds an ensemble of
randomizable base classifiers, the Random Committee.
17Blank squares means non significant values
32
Table 5: Detailed Model Evaluation
Model TP FP Pre. Rec. F-M. MCC ROC PRC
Model 1, RandomCommittee/RandomForest, Accuracy = 92.95%
AR 0.906 0.051 0.935 0.906 0.921 0.858 0.983 0.980
MR 0.949 0.094 0.925 0.949 0.937 0.858 0.983 0.987
W. Avg. 0.930 0.075 0.930 0.930 0.929 0.858 0.983 0.984
Model 2, RandomCommittee/RandomForest, Accuracy = 90.14%
AR 0.875 0.077 0.903 0.875 0.889 0.801 0.939 0.923
MR 0.923 0.125 0.900 0.923 0.911 0.801 0.939 0.948
W. Avg. 0.901 0.103 0.901 0.901 0.901 0.801 0.939 0.937
Model 3, Logistic Model Trees, Accuracy = 90.14%
AR 0.906 0.103 0.879 0.906 0.892 0.802 0.945 0.938
MR 0.897 0.094 0.921 0.897 0.909 0.802 0.945 0.951
W. Avg. 0.901 0.098 0.902 0.901 0.902 0.802 0.945 0.945
Model 4, RandomSubSpace/REPTree, Accuracy = 88.73%
AR 0.844 0.077 0.900 0.844 0.871 0.772 0.929 0.907
MR 0.923 0.156 0.878 0.923 0.900 0.772 0.929 0.935
W. Avg. 0.887 0.120 0.888 0.887 0.887 0.772 0.929 0.922
Model 5, Logistic Regression, Accuracy = 83.09%
AR 0.750 0.103 0.857 0.750 0.800 0.659 0.939 0.940
MR 0.897 0.250 0.814 0.897 0.854 0.659 0.939 0.950
W. Avg. 0.831 0.184 0.833 0.831 0.829 0.659 0.939 0.945
TP-True Positive, FP-False Positive, Pre-Precision, Rec-Recall,
F-M-F-Measure, MCC-Matthews Correlation Coefficient,
ROC-Receiver Operating Characteristic, PRC-Precision-Recall Curve,
AR-Automatic Refactoring, MR-Manual Refactoring,
W. Avg-Weighted Average
Our dataset is not imbalanced, thus, we have almost the same number
of subjects for each class, meaning we may use also the Accuracy metric
to complement our analysis. Model 1 and 2 had respectively, an accuracy of
92.5% and 90.14%.
33
serutaeF
100.00%
NOA
96.75%
DEV
92.22%
EC
91.13%
EVTS
84.25%
NCOM
77.63%
NCS
76.92%
NOT
76.90%
PCC
70.67%
NFILES
69.97%
NSS
62.11%
SES
56.45%
NVER
55.01%
PCCPF
48.73%
NCAT
44.47%
NPLA
17.22%
NISP
7.31%
NOS
0.00%
NPER
0 25 50 75 100
Importance
Figure 10: Feature importance for models on Table 5
During models computation phase, we also assessed which of the fea-
tures were more or less important to predict the refactoring practices: auto-
matic(AR) or manual(MR). Figure 10 shows their average importance.
Observation 9: Number of Activities, Developers and Com-
mands are the most relevant model features. These features show
among the ones with highest importance in the models we computed. We
recall that the number of activities (NOA) is a composite metric obtained
by the process mining extraction plugin using a hierarchical structure com-
posed of the filename, command category and commands issued during the
coding phase. Having a mid level importance we find the process cyclomatic
complexity and the number of development sessions.
Observation 10: Distinct IDE Perspectives and Operating Sys-
34
tems have almost irrelevant importance. In our models, the different
types operating system used by the developers, the different number of IDE
perspectives and number of development locations (NISP) are irrelevant pre-
dictors in modeling the type of refactoring performed. We argue that, partic-