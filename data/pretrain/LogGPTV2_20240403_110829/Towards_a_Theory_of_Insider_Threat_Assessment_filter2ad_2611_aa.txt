title:Towards a Theory of Insider Threat Assessment
author:Ramkumar Chinchani and
Anusha Iyer and
Hung Q. Ngo and
Shambhu J. Upadhyaya
Towards A Theory Of Insider Threat Assessment(cid:3)
Ramkumar Chinchani, Anusha Iyer, Hung Q. Ngo, Shambhu Upadhyaya
University at Buffalo
Buffalo, NY 14260, USA
Email: {rc27, aa44, hungngo, shambhu}@cse.buffalo.edu
Abstract
Insider attacks are a well-known problem acknowl-
edged as a threat as early as 1980s. The threat is at-
tributed to legitimate users who abuse their privileges,
and given their familiarity and proximity to the compu-
tational environment, can easily cause signi(cid:2)cant dam-
age or losses. Due to the lack of tools and techniques,
security analysts do not correctly perceive the threat,
and hence consider the attacks as unpreventable. In this
paper, we present a theory of insider threat assessment.
First, we describe a modeling methodology which cap-
tures several aspects of insider threat, and subsequently,
show threat assessment methodologies to reveal possible
attack strategies of an insider.
1 Introduction and Motivation
Insider threat is typically attributed to legitimate
users who maliciously leverage their system privileges,
and familiarity and proximity to their computational en-
vironment to compromise valuable information or in(cid:3)ict
damage. According to the annual CSI/FBI surveys con-
ducted since 1996, internal attacks and insider abuse
form a signi(cid:2)cant portion of reported incidents. The
strongest indication yet that insider threat is very real is
given by the recent study [2] jointly conducted by CERT
and the US Secret Service; the (cid:2)rst of its kind, which
provides an in-depth insight into the problem in a real-
world setting. However, there is no known body of work
which addresses this problem effectively. There are sev-
eral challenges, beginning with understanding the threat.
(cid:15) Insider threat is a low base rate problem. Perpre-
tators of insiders attacks are users with legitimate
(cid:3)Research supported in part by Telcordia Technologies Subcon-
tract: FA8750-04-C-0249 from the DARPA SRS Program
authorization, and therefore, it is dif(cid:2)cult to predict
or protect against these attacks. Consequently, se-
curity of(cid:2)cers view these attacks as unpreventable,
resulting in inaction.
(cid:15) Insider threat is misperceived. Organizations
often concentrate on external attacks, almost ex-
clusively, mainly because security audit tools and
modeling techniques are readily available which
aid in (cid:2)nding vulnerabilities and (cid:2)xing them. On
the other hand, insider threat is not correctly per-
ceived because it is dif(cid:2)cult to measure it, and the
lack of tools and techniques doesn’t help the sit-
uation. Therefore, any good model or assessment
methodology is already a signi(cid:2)cant advance.
(cid:15) Insider threat is high impact. Although insider
attacks may not occur as frequently as external at-
tacks, they have a higher rate of success, can go un-
detected and pose a much greater risk than external
attacks. This is due to the fact that insiders enjoy
certain important advantages over external adver-
saries. They are familiar about their targets and the
security countermeasures in place. Therefore, very
damaging attacks can be launched with only a short
or non-existent reconnaissance phase.
In a nutshell, insider threat is a complex problem involv-
ing both computational elements and human factors. As
a long-term process to mitigate this threat, steps such
as pre-hire screening of employees, training and educa-
tion can be undertaken. While all these practical mea-
sures will reduce the threat, they cannot eliminate it al-
together, and some incidents can still occur. A possible
solution it would seem is an overall increase in moni-
toring, logging and security countermeasures. However,
it only leads to general inconvenience. Moreover, in an
organization, it sends wrong signals of distrust between
the management and the employees. We seek a method-
ology by which very speci(cid:2)c and targeted countermea-
1
sures can be deployed. This approach occupies a sweet
spot between complete inaction and intrusive solutions.
Central to such an approach is an effective threat mod-
eling methodology, accompanied by threat assessment
and analysis, with the goal of discovering likely tactics
and strategy of an adversary so that appropriate counter-
measures can be taken.
Insiders can cause damage either by: 1) remaining
within their default set of privileges, or 2) exceeding
them by seeking new information and capability through
a repertoire which contains not only common attacks
but also unconventional ones such as social engineering.
The problem of insider threat assessment is precisely the
problem of evaluating the damage which can potentially
occur in these two cases.
Threat assessment methodologies are not new in gen-
eral and techniques such as attack graphs [16, 19, 21, 20]
and privilege graphs [7, 17] are already known. How-
ever, these techniques have been proposed to primarily
model external attacks, and hence, have a limited ap-
peal to insider threat. Moreover, there are also scal-
ability concerns regarding both model speci(cid:2)cation as
well as subsequent threat analysis. Specifying a model
requires information in very exacting detail, making it
impractical to generate the model manually.
Instead,
current approaches generate models automatically [20]
via information obtained from live penetration testing of
an organization network. However, given the possibility
of systemic failures, a large part of the network is typi-
cally excluded during testing, resulting in an abbreviated
model instance. Consequently, any further inferences
drawn from the model are questionable. Also, threat
analysis following model speci(cid:2)cation very quickly runs
into the problem of intractability. To summarize, these
modeling techniques are not suitable for addressing in-
sider threat both for technical and practical reasons. We
seek to devise a more appropriate modeling and assess-
ment methodology.
1.1 Summary of Contributions
There are two prominent contributions in this paper.
As our (cid:2)rst contribution, we propose a new threat model
called key challenge graph. The main idea behind in-
sider threat modeling is to focus on a legitimate user’s
view of an organization’s network.
In order to esti-
mate the threat when insiders remain within their privi-
lege levels, we only need to represent the basic network
connectivity and access control mechanisms that are in
place. Additionally, to assess the threat when insiders
exceed their privilege levels, we also need to represent
2
knowledge and location of key information and capa-
bility, not normally accessible, which may assist him
in his attack. The overall goal, like attack graphs, is
to understand insider threat from a global perspective
rather than just single-point incidents. In terms of threat
variety, our model supports not only conventional at-
tacks, but also more complex scenarios such as social
engineering. One important design consideration is the
granularity of information and the nature of represen-
tation. Due to the unavailability of tools to scan for
weaknesses in the context of insider threat, a signi(cid:2)-
cant portion of the model speci(cid:2)cation task can fall upon
the security analyst. Our modeling methodology allows
models to be manually speci(cid:2)ed and the resulting model
instances are only polynomially-sized in the input in-
formation. To demonstrate applications of our model,
we have constructed some typical scenarios motivated
by the CERT/USS insider threat study which analyzed
threats in the banking and (cid:2)nancial sector.
As our next contribution, we investigate and analyze
the problem of automated threat analysis. It turns out
that the problem is NP-hard. Nevertheless, we have
designed two algorithms for this purpose - one which
solves the problem to optimality but takes exponential
time, and the other which is a polynomial-time heuris-
tic. We benchmark the algorithms for scalability and
quality of threat analysis. The impact of threat analy-
sis is manifold. Given a organization network and its
people, it is possible to assess whether existing security
countermeasures are adequate. If not, threat analysis al-
lows recommendations to be made to improve security.
In the face of insider threat, sometimes the only coun-
termeasure is installing monitoring and logging systems
for non-repudiability. Finally, if several intrusion detec-
tion systems are installed, threat analysis can also assign
appropriate weights to intrusion detection sensors based
on the likely areas of insider activity inside the organi-
zation.
Paper Organization. The rest of the paper is organized
as follows. We present our model in Section 2 and show
its application on representative illustrations in Section
3. Next, we describe the threat analysis methodology in
Section 4 and also present insights into the complexity
of the problem. Related work is discussed in Section 5
and (cid:2)nally, closing remarks are in Section 6.
2 Modeling Insider Threat
In this section, we elaborately discuss our modeling
methodology. But before that we state some working
assumptions based on generally accepted notions about
insider threat along with results from the recent study
[2].
2.1 Background
De(cid:2)ning the term "insider" in an airtight manner is
hard because the boundary between insiders and out-
siders is fuzzy. We assume that every legitimate user
is an insider. Note that the term (cid:147)insider(cid:148) can have both
physical and logical connotation. Physical outsiders can
be logical insiders and vice versa. For example, an au-
thorized user who may be physically far away from an
organization but has wireless or VPN connectivity. Sim-
ilarly, users may be physically inside an organization but
have no authorized access to use the computation infras-
tructure. Insiders are in a unique position with the priv-
ileges entrusted to them and the knowledge about their
computational environment, and this already translates
directly to a certain amount of capability. Insider abuse
can occur within this default capability, but more dan-
gerous scenarios occur when an insider widens his realm
of capability. Since insiders have access privileges to use
the computational infrastructure, it represents resources
at their disposal that can be used against the parent or-
ganization, so resources for an insider attack are freely
available. Unlike external attackers who use the Inter-
net as an umbrella of anonymity and can be sloppy, in-
siders have a strong incentive to avoid detection. They
are a part of an organization and bound by the orga-
nization policy, and if caught, an organization has all
the necessary information about the insider and the legal
resources to prosecute him. External attackers can be-
come insiders too by compromising an internal system
and learning about the computers in the neighborhood.
However, there is an inherent risk to the attacker that the
compromise may be discovered and the corresponding
security hole patched.
The insider threat study [2] reports that (cid:2)nancial gain
is the main motivating factor behind most insider at-
tacks; any other motive is simply not worth the risk. The
(cid:2)nancial gain can be realized in different ways depend-
ing on the organization. In a (cid:2)nancial institution such
as a bank, likely targets are customer account records or
perhaps company accounts, where there is a direct ac-
cess to funds. In other cases, an insider may not obtain
immediate monetary gain, such as in a software com-
pany where the real value lies in the proprietary software
code. While it is possible to envision several other sce-
narios, it is not realistic to expect that each and every
one of them can be modeled, mainly because it entails a
signi(cid:2)cant effort on the part of the security of(cid:2)cer.
2.2 Our Model
In our model, we assume that an attacker is goal-
oriented. Also, he is already aware of the location of
his potential targets and how to reach them, obviating
the need for reconnaissance. These assumptions closely
model an insider and this is one of the reasons why our
model is most suitable for this class of threats. We also
assume that a successful compromise of a target is not
possible if there is no channel of interaction. Finally,
an attacker may not be able to use an existing channel
of interaction with a potential target due to a strong se-
curity mechanism in place on that channel. This may
force him to seek alternate routes to reach the target.
Each sub-target that is compromised requires extra ef-
fort but can provide the attacker with additional infor-
mation/capability and another front to continue the at-
tack. Given a model speci(cid:2)cation, the goal of vulnera-
bility analysis is to exhaustively (cid:2)nd the different ways
in which attacker can reach the target.
Preliminaries. Prior to the formal de(cid:2)nition of our
model, which we call a key challenge graph, we describe
the various components. Figure 1 shows the basic build-
ing block of the key challenge graph.
(keyw, c1, c2)
u
keyu
v
keyv
Figure 1. Basic building block of a key chal›
lenge graph
(cid:15) Any physical entity on which some information or
capability can be acquired is represented as a ver-
tex of the graph. Let the set of vertices be denoted
by V. Typically, vertices are points in the network
where some information may be gained such as
a database server or simply any computer system
whose resources can be used or misused.
(cid:15) Each piece of information or capability that is
present at any vertex is represented as a key. Let the
set of keys be denoted as K. For example, records
in a database, passwords stored on a computer, or
computational resources of a computer can be rep-
resented as keys. When an attacker visits a vertex,
he is empowered with this additional information
or capability. Note that this should not be confused
with cryptographic "keys". A key in our model is
only an abstraction.
(cid:15) If there is a channel of access or communication be-
tween two physical entities which facilitates inter-
3
action, then a directed edge is created between the
two corresponding vertices, pointing to the direc-
tion of the allowed interaction. Multiple channels
of communication are possible, hence there can be
more than one edge between two vertices. Let the
set of edges be denoted by E. For example, assume
a ssh server and a client computer. A channel of
communication exists from the client to the server
and a directed edge is drawn.
(cid:15) The presence of a security measure or an enforced
security policy protects the resources and allows
only authorized interaction. This deterrence is rep-
resented as a key challenge on the corresponding
channel of communication. An example of a key
challenge is the password authentication required
prior to accessing to a server. A key challenge is an
abstraction to capture access control.
(cid:15) If a user does not have the right key to the key chal-
lenge, then he incurs a signi(cid:2)cant cost in break-
ing or circumventing the security policy; legitimate
access incurs only a smaller cost of meeting the
key challenge. For example, when password au-
thentication is used, if a user knows the password,
he incurs little or no cost, while another user who
doesn’t know the password will incur a higher cost
in breaking the password. The cost metric is a rel-
ative quantity signifying the amount of deterrence
offered by one security measure over another.
It
has been abstracted as a non-negative integer for
the purposes of our model.
(cid:15) The starting point of an attack could be one or more
vertices in the graph, which are assumed to be ini-
tially in the control of an adversary. Let this set be
denoted as V0.
(cid:15) The target of an attack could also be one or more
vertices in the graph. In case of multiple targets,
the goal is to compromise all of them. Let the set
of target vertices be denoted byVs. An example of a
target is a source code repository for a commercial
product.
Table 1 provides a summary of all the abstractions
captured by our model.
De(cid:2)nition 2.1 (Key Challenge Graph). A Key Chal-
lenge Graph or KG is a tuple:
KG = (V;E;K;V0;Vs;p;d);
where V is the set of vertices, E is the set of edges, V0
is the initial set of compromised vertices, Vs is the set of
Model Component Abstraction
Hosts, People
Vertex
Connectivity, Reachability
Edge
Information, Capability
Key
Access Control
Key Challenge
Starting Vertex
Location of insider
Actual target
Target Vertex
Cost of Attack
Threat analysis metric
Table 1. Model components and the cap›
tured abstractions
target vertices, p : V ! K is a function that assigns keys
to vertices, d : E ! K (cid:2) N (cid:2) N is a function that assigns
key challenges and costs to edges, and N is the set of
natural numbers.
For example, p(v1) = k0 means that the key k0 can
be obtained at vertex v1, d(e1) = (a;c1;c2) implies an
assignment of a key challenge to edge e1, which requires
an attacker to produce the key a. If he cannot do so, then
he incurs a cost c1, which could be signi(cid:2)cant depending
on the access control mechanism; otherwise, he incurs a
smaller cost c2.
An adversary begins his attack at some point in the
set of compromised nodes in the graph and proceeds
by visiting more and more vertices until the target(s) is
reached. At each visited vertex, the attacker adds the
corresponding key to his collection of keys picked up
at previous vertices. Once an attacker compromises a
vertex, he continues to have control over it until an at-
tack is completed. Therefore, any vertex appears exactly
once in the attack description. While a trivial attack can
be performed by visiting all vertices until the target is
reached, cost constraints occlude such free traversals.
We shall now develop useful metrics for analysis of our
model.
Lets assume that initially V0 and Vs are disjoint sets,
that is, an attacker has not successfully compromised
any targets yet. We can de(cid:2)ne a successful attack as
follows.
De(cid:2)nition 2.2 (Successful Attack). A successful at-
tack is de(cid:2)ned as a (cid:2)nite ordered sequence of a subset
of vertices (v1;v2; : : : ;vm), where Vs (cid:18) fv1; : : : ;vmg, and
V0 \ fv1; : : : ;vmg = /0.
In other words, a successful attack is a sequence of
zero or more vertices not in the initial set V0 but eventu-
ally containing all the target nodes in Vs. (Note that this
sequence in general does not represent a path or a walk.
4
We elucidate this point in illustrations in the following
sections.)
The next important aspect of the model is the cost
metric. Although an attack is de(cid:2)ned exclusively in
terms of vertices, the cost incurred by the attacker at a
vertex is mainly dependent on the edge that he chooses
to visit the vertex. We (cid:2)rst de(cid:2)ne the cost of traversing
an edge and then the cost of visiting a new vertex. The
latter is the basic unit of cost metric in our model.
De(cid:2)nition 2.3 (Cost of Traversing an Edge). Let V (cid:3) be
the set of visited vertices so far, including the initially
compromised vertices, i.e. V0 (cid:18) V (cid:3). For u 2 V (cid:3) and
v =2 V (cid:3), the cost of traversing the edge e = (u;v) 2 E,
given that d(e) = (k;c1;c2), is c1 if k =2 fp(w) j w 2 V (cid:3)g.
Otherwise, it is c2. (In general, c1 > c2.) If (u;v) =2 E,
for technical convenience we assume that c1 = c2 = ¥,