PPI, as well as devices such as the hard disk.
When referring to applications, we use the term
\trust level" instead of \integrity level." Benign appli-
cations are those that are known to be benign, and may
include applications that are obtained from a trusted
source such as an OS vendor. Hence the (cid:12)les that
constitute benign applications will have high integrity.
Moreover, benign applications will remain trustworthy
(i.e., produce high-integrity outputs) as long as they
are never exposed to low-integrity (and hence poten-
tially malicious) inputs. A subset of benign applica-
tions may be designated as trusted. These applications
are deemed to su(cid:14)ciently validate their inputs that
they can produce high-integrity outputs even when
some of their inputs have low-integrity. Untrusted ap-
plications are those that are obtained from untrusted
sources, e.g., downloaded from an unknown website or
those arriving via email from unauthenticated sources.
An unspeci(cid:12)ed subset of these applications may be ma-
licious.
Since trusted applications are being exempted from
information (cid:13)ow policies, it is important that only a
small number of well-tested applications are designated
this way.
In addition, the scope and purpose of this
trust should be minimized as much as possible. We
defer these issues until Section 4.
2.2. Integrity Labels Versus Policies
Given our goal of preserving system integrity, the Biba
model is an obvious starting point [6]. However, a
traditional interpretation of multi-level security (MLS)
can lead to a rigid system that is di(cid:14)cult to use. To
address this problem, we distinguish between integrity
labels and policies. In our view, an integrity label on
a (cid:12)le simply indicates whether its content is trustwor-
thy, but does not dictate whether trustworthiness must
be preserved, say, by preventing low-integrity subjects
from writing to that (cid:12)le. A policy, on the other hand,
indicates whether a certain read or write access should
be permitted. This separation yields (cid:13)exibility in de-
veloping policies that preserve system integrity without
unduly impacting usability. For instance, we have the
following choices for policies when a high-integrity sub-
ject (process) attempts to read a low-integrity object:
(cid:15) deny: deny the access
(cid:15) downgrade: downgrade the process to low-integrity
(cid:15) trust: allow the access without downgrading the pro-
cess, trusting the process to protect itself
The following examples illustrate the need for this
(cid:13)exibility. Consider a utility such as cp that ac-
cesses high-integrity objects in some runs (e.g., copy
/etc/passwd), and accesses low-integrity objects in
other runs (e.g., copy user (cid:12)les). Downgrading (the
second alternative above), which corresponds to the
low-water mark (LOMAC) policy [6, 7, 12], permits
such dual use. However, this choice of downgrading
is inappropriate in some cases, and leads to the well-
known self-revocation problem: consider a process that
has opened a high-integrity (cid:12)le H for writing, and sub-
sequently attempts to read a low-integrity (cid:12)le L. If the
process is downgraded at this point, we need to revoke
its permissions to H. Applications typically assume
that access permissions cannot be revoked, and hence
may not handle the resulting access errors gracefully.
On the other hand, if we deny the read access to L, it
is likely to be better handled by the application.
To justify the third choice, consider an SSH server
that reads low-integrity data from remote clients. The
server code anticipates that clients may be malicious,
and can reasonably be expected to protect itself ade-
quately, thereby ensuring that the low-integrity input
will not corrupt any high-integrity outputs.
In con-
trast, the other two choices (deny or downgrade) will
prevent the server from carrying out its function.
Analogous to the choices above, the following op-
tions are available when a low-integrity process at-
tempts to write a high-integrity (cid:12)le (i.e., a (cid:12)le con-
taining trustworthy data).
(cid:15) deny: deny the access
(cid:15) downgrade: downgrade the object to low-integrity,
and allow the write operation
(cid:15) redirect: redirect the access to a (cid:12)le f so that it ac-
cesses another (cid:12)le fu instead. All subsequent accesses
by an untrusted application to f will be redirected to
fu, while accesses by a benign application wonâ€™t be
redirected.
To justify the second choice, consider a (cid:12)le that is cre-
ated by copying a high-integrity (cid:12)le. By default, the
copy would have a high-integrity label, but if the copy
is subsequently used only in low-integrity applications,
downgrading it is the best option, as it would permit
this use. As a second example, consider a commonly
executed shell command such as cat x > y. Here, the
shell will (cid:12)rst create the output (cid:12)le y before cat is
launched. If the shell has high integrity, then y would
be created with high integrity, but subsequently, if x
251
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:10:00 UTC from IEEE Xplore.  Restrictions apply. 
turns out to have low integrity, the best option is to
downgrade y rather than to deny access to x. On
the other hand, if a (cid:12)le is known to be used by high-
integrity applications, it should not be downgraded,
and the write access must be denied.
To justify the third choice, consider a benign ap-
plication that is sometimes used with untrusted ob-
jects, e.g., a word-processor that is used on a (cid:12)le from
the Internet. During its run, this application may
need to modify its preferences (cid:12)le, which would have
a high-integrity label, since the application itself is be-
nign. Denying this write operation can cause the word-
processor to fail. Permitting the access would lower the
integrity of the preferences (cid:12)le, leading to all future
runs of the word-processor to have low integrity. How-
ever, by redirecting accesses to a low-integrity copy of
the preferences (cid:12)le, both problems can be avoided.
In summary, there are several ways to resolve poten-
tial integrity violations (con(cid:13)icts), and di(cid:11)erent resolu-
tions are appropriate for di(cid:11)erent combinations of ob-
jects, subjects, and operations. Our (low-level) policy
speci(cid:12)es, for each combination of object O and subject
S, which of the six di(cid:11)erent choices mentioned above
should be applied. The sheer number of objects and
subjects on modern operating systems (e.g., >100K
(cid:12)les in system directories on typical Linux distribu-
tions) makes manual policy development a daunting
task. We have therefore developed techniques to auto-
mate this task in the next section.
Although we discussed only (cid:12)le read/write opera-
tions above, the same concepts are applicable to other
operations, e.g., (cid:12)le renames, directory operations, de-
vice accesses, and inter-process communication. We
omit the details here, covering them brie(cid:13)y in the im-
plementation sections.
3. Automating Policy Development
The large number of objects and subjects in a modern
OS distribution motivates automated policy develop-
ment. We envision policy development to be under-
taken by a security expert | for instance, a member
of a Linux distribution development team. The goal
of our analysis is to minimize the e(cid:11)ort needed on the
part of this expert. The input to the policy generation
algorithm consists of:
(cid:15) software package information, including package con-
tents and dependencies,
(cid:15) a list of untrusted packages and/or (cid:12)les
(cid:15) the list of integrity-critical objects
(cid:15) a log (cid:12)le that records resource accesses observed dur-
ing normal operation on an unprotected system.
We use these to compute dependencies between ob-
jects and subjects in the system, based on which trust
labels and policies are generated. Ideally, all accesses
observed in the log would be permitted by these policies
without generating user prompts or application fail-
ures, but in practice, some failures may be unavoid-
able. Naturally, it is more important to minimize fail-
ures of benign applications as opposed to untrusted
ones. Given this goal of policy analysis, it becomes im-
portant to ensure coverage of all typical uses of most
applications in the log, with particular emphasis on be-
nign applications. Since usage is a function of users and
their environments, better coverage can be obtained by
analyzing multiple logs generated on di(cid:11)erent systems.
3.1. Computing Dependencies, Contexts and
Labels
Critical to the success of our approach was the observa-
tion that software package information, such as those
contained in RPM or Debian packages, can be lever-
aged for extracting subject/object dependencies. The
package information indicates the contents (i.e., (cid:12)les)
in each package, and the dependencies between di(cid:11)er-
ent packages.
Since some of the dependences, such as those on con-
(cid:12)guration or data (cid:12)les, may not be present in the pack-
age database, we analyze the access log to extract addi-
tional dependency information. The dependencies can
vary for the same application depending on the context
in which it is used. For instance, when used by system
processes (such as a boot-time script), bash typically
needs to be able to write high-integrity (cid:12)les, and hence
must itself operate at a high-level of integrity. How-
ever, when used by normal users, it can downgrade
itself when necessary to operate on untrusted (cid:12)les. In
the former context, bash reads and writes only high-
integrity (cid:12)les, whereas in the latter context, it may read
or write a mixture of high and low integrity (cid:12)les. To
identify such di(cid:11)erences, we treat each program P as
if it were several distinct programs, one corresponding
to each of the following execution contexts: Ps that is
used by system processes, Pa that is used by processes
run by an administrator, and Pui for processes run by
a normal user ui. (The distinction between Ps and Pa
is that in the second case, the program is run by a
descendant of an administratorâ€™s login shell.) For sim-
plicity, we will assume that there is only one normal
user u.
Once the logs are generated, it is straight-forward to
compute the set of (cid:12)les read, written, or executed by
a program in each of the above contexts. In addition,
for each program and (cid:12)le read (written or executed) by
that program, we compute the fraction of runs of that
252
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:10:00 UTC from IEEE Xplore.  Restrictions apply. 
program in each context during which the (cid:12)le was read
(written, or executed).
(a) Ps
(i.e., P operating
in system context)
reads/executes Q.
Deriving Initial Object Labels.
Initial object la-
bels are derived using the following steps. The assump-
tion behind this algorithm is that all packages and (cid:12)les
on the system are benign unless speci(cid:12)ed otherwise:
(cid:15) Mark all packages that depend on untrusted packages
as untrusted.
(cid:15) Label all objects that belong to untrusted packages
(or are explicitly identi(cid:12)ed as untrusted) with low
integrity.
(cid:15) Label any object that was written by an untrusted
subject (i.e., a process whose executable or one of
its libraries are from low-integrity (cid:12)les) with low in-
tegrity.
(cid:15) Label all other objects as having high integrity.
We reiterate that object labels do not dictate policy:
an object may have a high label initially, but the policy
synthesized using the algorithm below may permit it to
be written by an untrusted subject, which would cause
its label to become low.
3.2. Policy Generation
The policy generation algorithm consists of four phases
as described below. The (cid:12)rst phase identi(cid:12)es the set
of \preserve-high" objects, i.e., objects whose integrity
needs to be preserved. In the second phase, we gener-
ate the low-level policies for each (subject, object, ac-
cess) combination, re(cid:13)ecting one of the policy choices
described in Section 2.2. Phase III re(cid:12)nes the policies
by simulating the accesses contained in the log. Phase
IV consists of ongoing policy re(cid:12)nement, as new appli-
cations are installed.
Phase I: Identi(cid:12)cation of objects whose in-
tegrity needs to be preserved.
1. Initialize:
(cid:15) For every package P such that an integrity-critical
package depends on it, add P to the set of integrity-
critical packages.
(cid:15) For every object that belongs to an integrity-
critical package (or object that is explicitly labeled
as integrity-critical), mark it as \preserve-high."
(cid:15) For every program P that is ever executed in the
system context, mark P as preserve-high.
2. Propagate from object to subject.
If a program P
writes an object Q that is marked preserve-high, then
mark P as preserve-high.
3. Propagate from subject to object.
If a program P
reads or executes an object Q then mark Q as
preserve-high if any of the following hold:
(b) Pa reads or executes object Q in non-negligible
fraction of runs, say, over 10% of the runs.
(c) P is marked preserve-high and Pu almost always
reads or executes Q, say, in over 95% of the runs.
Every program that is run in system context is ex-
pected to be run in high-integrity mode, and hence
the (cid:12)rst rule. Most activities performed in adminis-
trator context have the potential to impact system
integrity, and hence most of these activities should
be performed in high integrity mode, and hence the
second rule. For the third rule, if a benign program
P almost always reads or executes a speci(cid:12)c (cid:12)le Q,
then, if Q has low integrity, it will prevent any use
of P in high integrity mode. It is unlikely that a be-
nign program would be installed on a system in such
a way that it is only executed at low-integrity level,
and hence the third rule.
4. Repeat the previous two steps until a (cid:12)xpoint is
reached.
If any low-integrity (cid:12)le gets marked as preserve-high,
there is a con(cid:13)ict and the policy generation cannot pro-
ceed until it is manually resolved. Such a con(cid:13)ict is in-
dicative of an error in the input to the policy generation
algorithm, e.g., a software package commonly used in
system administration has been labeled as untrusted.
Phase II: Resolution of con(cid:13)icting accesses.
This phase identi(cid:12)es which of the policy choices dis-
cussed in Section 2.2 should be applied to each con-
(cid:13)icting access involving (subject, object, access).
(cid:15) Deny policy: For every object labeled preserve-
high, the default policy is to permit reads by any
subject but deny writes by low-integrity subjects.
Similarly, for every object labeled with low-integrity,
the default policy is to permit reads by low-integrity
subjects but deny reads by high-integrity subjects.
Exceptions to these defaults are made as described
below, depending upon the program executed by a
subject, and its trust level.
(cid:15) Downgrade subject policy: A high-integrity sub-
ject P running in context c will be permitted to down-
grade itself to low-integrity if there are runs in the
log (cid:12)le where Pc read a low integrity (cid:12)le, and did not
write any high integrity objects subsequently. Such
runs show that Pc can run successfully, without ex-
periencing security violations.
If there are no such
runs, then the downgrade policy is not used for Pc.
Note that at runtime, a subject running Pc may still
be denied read access if it has already opened an ob-
ject O such that the policy associated with O pre-
253
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:10:00 UTC from IEEE Xplore.  Restrictions apply. 
vents its label from being downgraded.
Finally, note that the use of context makes the down-
grade policy more (cid:13)exible. For instance, we may per-
mit bash to downgrade itself when running in user
mode, but not when it is run in system mode.
(cid:15) Trust policy: Each subject P that reads a low-
integrity object and writes to an object marked
preserve-high is a candidate for the \trust" policy.
Such candidates are listed, and the policy developer
needs to accept this choice. If this choice is not ac-
cepted, the log analyzer lists those operations from
the log that would be disallowed as a result of this
decision.
(cid:15) Downgrade object policy: Any object that is not
marked as preserve-high can be downgraded when it
is overwritten by a low-integrity subject.
(cid:15) Redirect policy: A redirect policy is applied to the
combination (P; O; write) if (a) O is marked preserve-
high, (b) P reads O in almost every run, and (c) P
writes O in a non-negligible fraction of runs 1.