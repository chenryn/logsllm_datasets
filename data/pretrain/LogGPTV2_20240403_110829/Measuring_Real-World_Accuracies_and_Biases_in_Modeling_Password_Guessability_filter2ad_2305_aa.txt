title:Measuring Real-World Accuracies and Biases in Modeling Password Guessability
author:Blase Ur and
Sean M. Segreti and
Lujo Bauer and
Nicolas Christin and
Lorrie Faith Cranor and
Saranga Komanduri and
Darya Kurilova and
Michelle L. Mazurek and
William Melicher and
Richard Shay
Measuring Real-World Accuracies and Biases in 
Modeling Password Guessability
Blase Ur, Sean M. Segreti, Lujo Bauer, Nicolas Christin, Lorrie Faith Cranor,  
Saranga Komanduri, and Darya Kurilova, Carnegie Mellon University; Michelle L. Mazurek, 
University of Maryland; William Melicher and Richard Shay, Carnegie Mellon University
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/ur
This paper is included in the Proceedings of the 
24th USENIX Security Symposium
August 12–14, 2015 • Washington, D.C.
ISBN  978-1-939133-11-3
Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXMeasuring Real-World Accuracies and Biases
in Modeling Password Guessability
Blase Ur, Sean M. Segreti, Lujo Bauer, Nicolas Christin, Lorrie Faith Cranor,
Saranga Komanduri, Darya Kurilova, Michelle L. Mazurek†, William Melicher, Richard Shay
Carnegie Mellon University, †University of Maryland
password
Abstract
guessability—how many
Parameterized
guesses a particular cracking algorithm with particular
training data would take to guess a password—has
become a common metric of password security. Unlike
statistical metrics, it aims to model real-world attackers
and to provide per-password strength estimates. We
investigate how cracking approaches often used by
researchers compare to real-world cracking by profes-
sionals, as well as how the choice of approach biases
research conclusions.
We ﬁnd that semi-automated cracking by profession-
als outperforms popular fully automated approaches, but
can be approximated by combining multiple such ap-
proaches. These approaches are only effective, however,
with careful conﬁguration and tuning; in commonly used
default conﬁgurations, they underestimate the real-world
guessability of passwords. We ﬁnd that analyses of large
password sets are often robust to the algorithm used for
guessing as long as it is conﬁgured effectively. However,
cracking algorithms differ systematically in their effec-
tiveness guessing passwords with certain common fea-
tures (e.g., character substitutions). This has important
implications for analyzing the security of speciﬁc pass-
word characteristics or of individual passwords (e.g., in a
password meter or security audit). Our results highlight
the danger of relying only on a single cracking algorithm
as a measure of password strength and constitute the ﬁrst
scientiﬁc evidence that automated guessing can often ap-
proximate guessing by professionals.
1
Introduction
Despite decades of research into alternative authen-
tication schemes,
text passwords have comparative
advantages—familiarity, ease of implementation, noth-
ing for users to carry—that make a world without text
passwords unlikely in the near future [5]. Two-factor
authentication, single-sign-on systems, password man-
agers, and biometrics promise to obviate remembering a
distinct password for each online account, but passwords
will not disappear entirely.
Text passwords have been compromised with alarm-
ing regularity through both online and ofﬂine attacks.
While online attacks are mitigated through rate-limiting
password-entry attempts, faulty rate limiting contributed
to the iCloud photo leak [39].
In ofﬂine attacks, in-
cluding recent ones on LinkedIn [7], eHarmony [62],
Gawker [2], and Adobe [48], an attacker steals a database
of (usually) hashed passwords and tries to recover pass-
words through ofﬂine guessing. Because password reuse
is common [14], recovered passwords can often be used
to access accounts on other systems.
A key aspect of improving password security is mak-
ing passwords more computationally expensive to guess
during ofﬂine attacks. Cracking tools like the GPU-
based oclHashcat [57] and distributed cracking bot-
nets [13, 17] enable attackers to make 1014 guesses in
hours if passwords are hashed using fast hash func-
tions like MD5 or NTLM. These advances are offset by
the development of hash functions like bcrypt [52] and
scrypt [47], which make attacks more difﬁcult by requir-
ing many iterations or consuming lots of memory.
Unfortunately, users often create predictable pass-
words [7, 29], which attackers can guess quickly even
if the passwords are protected by a computationally ex-
pensive hash function. In some cases, predictable pass-
words are a rational coping strategy [54, 60]; in other
cases, users are simply unsure whether a password is
secure [66]. System administrators encourage strong
passwords through password-composition policies and
password-strength meters. The design and effectiveness
of such mechanisms hinges on robust metrics to measure
how difﬁcult passwords are to guess.
In recent years, traditional entropy metrics have fallen
out of favor because they do not reﬂect how easily a
password can be cracked in practice [3, 31, 69]. It has
USENIX Association  
24th USENIX Security Symposium  463
1
instead become common to measure password strength
by running or simulating a particular cracking algo-
rithm, parameterized by a set of training data [4, 31, 69].
This approach has two main advantages. First, it cal-
culates the guessability of each password individually,
enabling data-driven strength estimates during password
creation [10, 33]. Second, it estimates real-world secu-
rity against existing, rather than idealized, adversarial
techniques. A disadvantage of this approach is that the
(simulated) cracking algorithm may not be conﬁgured or
trained as effectively as by a real attacker, leading to in-
accurate estimates of password strength.
This paper reports on the ﬁrst study of how vari-
ous cracking approaches used by researchers compare to
real-world cracking by professionals, as well as how the
choice of approach biases research conclusions. We con-
tracted a computer security ﬁrm specializing in password
recovery to crack a set of passwords chosen for their di-
versity in password-composition policies. We then com-
puted the guessability of these passwords using four pop-
ular approaches. We tested many conﬁgurations of two
well-known password-cracking toolkits: John the Rip-
per [49] and oclHashcat [57]. We also tested two ap-
proaches popular in academia: Weir et al.’s probabilis-
tic context-free grammar (PCFG) [70] and Ma et al.’s
Markov models [40].
Unsurprisingly, a professional attacker updating his
strategy dynamically during cracking outperformed fully
automated, “ﬁre-and-forget” approaches (henceforth
simply referred to as automated), yet often only once bil-
lions or trillions of guesses had been made. We found
that relying on a single automated approach to calculate
guessability underestimates a password’s vulnerability to
an experienced attacker, but using the earliest each pass-
word is guessed by any automated approach provides a
realistic and conservative approximation.
We found that each approach was highly sensitive to
its conﬁguration. Using more sophisticated conﬁgura-
tions than those traditionally used in academic research,
our comparative analysis produced far more nuanced re-
sults than prior work. These prior studies found that
Markov models substantially outperform the PCFG ap-
proach [18, 40], which in turn substantially outperforms
tools like John the Ripper [16, 69, 72]. We found that
while Markov was marginally more successful at ﬁrst, it
was eventually surpassed by PCFG for passwords cre-
ated under typical requirements. Furthermore, the most
effective conﬁgurations of John the Ripper and Hash-
cat were frequently comparable to, and sometimes even
more effective than, the probabilistic approaches.
Both the differences across algorithms and the sensi-
tivity to conﬁguration choices are particularly notable be-
cause most researchers use only a single approach as a
security metric [10, 12, 19, 42, 56, 65, 69].
In addition,
many researchers use adversarial cracking tools in their
default conﬁguration [11, 14, 15, 20, 21, 28, 34, 71]. Such
a decision is understandable since each algorithm is very
resource- and time-intensive to conﬁgure and run. This
raises the question of whether considering only a single
approach biases research studies and security analyses.
For instance, would substituting a different cracking al-
gorithm change the conclusions of a study?
We investigate these concerns and ﬁnd that for com-
parative analyses of large password sets (e.g., the ef-
fect of password-composition policies on guessability),
choosing one cracking algorithm can reasonably be ex-
pected to yield similar results as choosing another.
However, more ﬁne-grained analyses—e.g., exam-
ining what characteristics make a password easy to
guess—prove very sensitive to the algorithm used. We
ﬁnd that per-password guessability results often vary by
orders of magnitude, even when two approaches are sim-
ilarly effective against large password sets as a whole.
This has particular signiﬁcance for efforts to help sys-
tem administrators ban weak passwords or provide cus-
tomized guidance during password creation [10, 33]. To
facilitate the analysis of password guessability across
many password-cracking approaches and to further sys-
tematize passwords research, we introduce a Password
Guessability Service [9] for researchers.
In summary, this paper makes the following main con-
tributions: We show that while running a single crack-
ing algorithm or tool relatively out-of-the-box produces
only a poor estimate of password guessability, using mul-
tiple well-conﬁgured algorithms or tools in parallel can
approximate passwords’ vulnerability to an expert, real-
world attacker. Furthermore, while comparative analy-
ses of large password sets may be able to rely on a single
cracking approach, any analysis of the strength of indi-
vidual passwords (e.g., a tool to reject weak ones) or the
security impact of particular characteristics (e.g., the use
of digits, multiple character classes, or character substi-
tutions) must consider many approaches in parallel.
2 Related Work
In this section, we discuss commonly used metrics of
password strength (Section 2.1) and describe popular cat-
egories of password-cracking attacks (Section 2.2).
2.1 Password Security Metrics
While estimated entropy was once a leading password
strength metric [8], it does not reﬂect what portion of a
set can be cracked easily [3, 31, 69]. Two main classes
of metrics have emerged in its place: statistical metrics
and parameterized metrics. Both classes focus on guess-
464  24th USENIX Security Symposium 
USENIX Association
2
ability, the number of guesses needed by an adversary to
guess a given password or a fraction of a set.
Statistical metrics are particularly valuable for exam-
ining password sets as a whole. For example, Bonneau
introduced partial guessing metrics [3] for estimating the
number of guesses required for an idealized attacker,
who can perfectly order guesses, to guess a given frac-
tion of a set. Since password distributions are heavy-
tailed, very large samples are required to determine a
set’s guessability accurately.
Parameterized metrics instead investigate guessability
under a cracking algorithm and training data [4, 31, 69].
These metrics thus model an adversary using existing
tools, rather than an idealized attack, though the metric is
only as good as the chosen algorithm and training data.
Parameterized metrics can also be used to compare pass-
word sets without fully running the algorithm [40].
In contrast to statistical metrics, parameterized met-
rics have two important properties. First, they estimate
the guessability of each password individually. Estimat-
ing guessability per-password is important for security
audits (e.g., identifying weak passwords) and to provide
feedback to a user about a password she has created. This
latter promises to become more widespread as proac-
tive feedback tools move from length-and-character-
class heuristics [15] to data-driven feedback [10, 33].
Second, parameterized metrics aim to estimate security
against real-world, rather than idealized, attacks. Re-
searchers previously assumed automated techniques ap-
proximate real-world attackers [31, 69]; we are the ﬁrst
to test this assumption against attacks by professionals.
Parameterized metrics have been used to measure
password strength in a number of previous studies [10,
14, 16, 20, 21, 31, 34, 40, 42, 53, 56, 65, 68, 69, 72]. While
there are many different methods for cracking passwords,
as we detail in Section 2.2, time and resource constraints
lead many researchers to run only a single algorithm per
study. However, it remains an open question whether
this strategy accurately models real-world attackers, or
whether choosing a different algorithm would change a
study’s results. We address this issue.
Throughout the paper, we refer to the guess number of
a password, or how many guesses a particular parameter-
ized algorithm took to arrive at that password. Because
the algorithm must be run or simulated, there is neces-
sarily a guess cutoff, or maximum guess after which re-
maining passwords are denoted “not guessed.”
2.2 Types of Guessing Attacks
Researchers have long investigated how to guess pass-
words. A handful of studies [12, 16, 53] have compared
the aggregate results of running different cracking ap-
proaches. Other studies have compared results of run-
ning different cracking approaches based on guess num-
bers [11, 18, 40]. We are the ﬁrst to examine in de-
tail the magnitude and causes of differences in these ap-
proaches’ effectiveness at guessing speciﬁc passwords;
we also compare approaches from academia and adver-
sarial tools to a professional attacker. In this section, we
highlight four major types of attacks.
Brute-force and mask attacks Brute-force attacks are
conceptually the simplest. They are also inefﬁcient and
therefore used in practice only when targeting very short
or randomly generated, system-assigned passwords.
Mask attacks are directed brute-force attacks in which
password character-class structures, such as “seven
lowercase letters followed by one digit” are exhausted in
an attacker-deﬁned order [58]. While this strategy may
make many guesses without success, mask attacks can be
effective for short passwords, as many users craft pass-
words matching popular structures [37, 63]. Real-world
attackers also turn to mask attacks after more efﬁcient
methods exhaust their guesses. We evaluated mask at-
tacks in our initial tests. Unsurprisingly, we found them
signiﬁcantly less efﬁcient than other attacks we analyzed.
Probabilistic context-free grammar
In 2009, Weir et
al. proposed using a probabilistic context-free grammar
(PCFG) with a large training set of passwords from ma-
jor password breaches [67] to model passwords and gen-
erate guesses [70]. They use training data to create a
context-free grammar in which non-terminals represent
contiguous strings of a single character class. From the
passwords observed in its training data, PCFG assigns
probabilities to both the structure of a password (e.g.,
monkey99 has the structure {six letters}{two digits}) and
the component strings (e.g., “99” will be added to the list
of two-digit strings it has seen). A number of research
studies [11, 16, 19, 31, 40, 42, 56, 65, 69, 72] have used
PCFG or a close variant to compute guessability.
Kelley et al. proposed other improvements to Weir et
al.’s PCFG algorithm, like treating uppercase and lower-
case letters separately and training with structures and
component strings from separate sources [31]. Because
they found these modiﬁcations improved guessing effec-
tiveness, we incorporate their improvements in our tests.
In addition, multiple groups of researchers have pro-
posed using grammatical structures and semantic tokens
as PCFG non-terminals [53, 68]. More recently, Koman-
duri proposed a series of PCFG improvements, including
supporting hybrid structures and assigning probabilities
to unseen terminals [32]. We incorporate his insights,
which he found improves guessing efﬁciency.
USENIX Association  
24th USENIX Security Symposium  465
3
Markov models Narayanan and Shmatikov ﬁrst pro-
posed using a Markov model of letters in natural lan-
guage with ﬁnite automata representing password struc-
tures [45]. Castelluccia et al. used a similar algorithm for
password meters [10]. John the Ripper and Hashcat offer
simple Markov modes in their cracking toolkits as well.
Recently, Duermuth et al. [18] and Ma et al. [40] in-
dependently evaluated many variations of Markov mod-
els and types of smoothing in cracking passwords, using
large sets of leaked passwords for training. Both groups
compared their model with other probabilistic attacks,
including Weir et al.’s original PCFG code, ﬁnding par-
ticular conﬁgurations of a Markov model to be more ef-
ﬁcient at guessing passwords for some datasets. We use
Ma et al.’s recommended model in our tests [40].
Mangled wordlist attacks Perhaps the most popular
strategy in real-world password cracking is the dictio-
nary attack. First proposed by Morris and Thompson
in 1979 [43], modern-day dictionary attacks often com-
bine wordlists with mangling rules, string transforma-
tions that modify wordlist entries to create additional
guesses. Wordlists usually contain both natural language
dictionaries and stolen password sets. Typical mangling
rules perform transformations like appending digits and
substituting characters [50, 59].
Many modern cracking tools, including John the Rip-
per [49], Hashcat [57], and PasswordsPro [30], support
these attacks, which we term mangled wordlist attacks.
The popularity of this category of attack is evident from
these tools’ wide use and success in password-cracking
competitions [36,51]. Furthermore, a number of research
papers have used John the Ripper, often with the default
mangling rules [11,14,15,20,21,28,34,71] or additional
mangling rules [16, 19, 72].
Expert password crackers, such as those offering
forensic password-recovery services, frequently perform
a variant of the mangled wordlist attack in which hu-
mans manually write, prioritize, and dynamically update
rules [23]. We term these manual updates to mangling
rules freestyle rules. As we discuss in Section 3, we
evaluate guessability using off-the-shelf tools relying on
publicly available wordlists and mangling rules. We also
contract a password recovery industry leader to do the
same using their proprietary wordlists and freestyle rules.
3 Methodology
We analyze four automated guessing algorithms and one
manual cracking approach (together, our ﬁve cracking
approaches). We ﬁrst describe the password sets for
which we calculated guessability, then explain the train-
ing data we used. Afterwards, we discuss our ﬁve crack-
ing approaches. Finally, we discuss computational limi-
tations of our analyses.
3.1 Datasets
We examine 13,345 passwords from four sets created
under composition policies ranging from the typical
to the currently less common to understand the suc-
cess of password-guessing approaches against passwords
of different characteristics. Since no major password
leaks contain passwords created under strict composi-
tion policies, we leverage passwords that our group col-
lected for prior studies of password-composition poli-
cies [31, 42, 56]. This choice of data also enables us
to contract with a professional computer security ﬁrm
to crack these unfamiliar passwords. Had we used any
major password leak, their analysts would have already
been familiar with most or all of the passwords contained
in the leak, biasing results.
The passwords in these sets were collected using Ama-
zon’s Mechanical Turk crowdsourcing service. Two re-
cent studies have demonstrated that passwords collected
for research studies, while not perfect proxies for real
data, are in many ways very representative of real pass-
words from high-value accounts [20, 42].
Despite these claims, we were also curious how real
passwords would differ in our analyses from those col-
lected on Mechanical Turk. Therefore, we repeated our
analyses of Basic passwords (see below) with 15,000
plaintext passwords sampled from the RockYou gaming
site leak [67] and another 15,000 sampled from a Yahoo!
Voices leak [22]. As we detail in Appendix A.4, our Ba-
sic passwords and comparable passwords from these two
real leaks yielded approximately the same results.
Next, we detail our datasets, summarized in Table 1.
The Basic set comprises 3,062 passwords collected for a
research study requiring a minimum length of 8 charac-
ters [31]. As we discuss in Section 4, the vast majority
of 8-character passwords can be guessed using off-the-
shelf, automated approaches. Hence, we give particular
attention to longer and more complex passwords, which
will likely represent best practices moving forward.
System administrators commonly require passwords
to contain multiple character classes (lowercase letters,
uppercase letters, digits, and symbols). The Complex set
comprises passwords required to contain 8+ characters,
include all 4 character classes, and not be in a cracking
wordlist [46] after removing digits and symbols. They
were also collected for research [42].
Recent increases in hashing speeds have made pass-
words of length 8 or less increasingly susceptible to of-
ﬂine guessing [24, 31]. We therefore examine 2,054
LongBasic passwords collected for research [31] that re-
quired a a minimum length of 16 characters. Finally, we
466  24th USENIX Security Symposium 
USENIX Association
4
Table 1: Characteristics of passwords per set, including
the percentage of characters that were lowercase (LC) or
uppercase (UC) letters, digits, or symbols (Sym).
Set
Basic
Complex
LongBasic
LongComplex
Length
# Mean (σ)
9.6 (2.2)
10.7 (3.2)
18.1 (3.1)
13.8 (2.6)
3,062
3,000
2,054
990
% of Characters
LC UC Digit
26
68
25
51
20
73
57
22
4
14
4
12
Sym
1
11