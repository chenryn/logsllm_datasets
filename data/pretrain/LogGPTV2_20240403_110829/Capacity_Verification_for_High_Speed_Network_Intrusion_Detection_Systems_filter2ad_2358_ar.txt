The relevance score is calculated on a scale from 0 to 255.  0 indicates that the in-
cident  vulnerabilities  required  for  the  successful  execution  of  the  reported  security
incident  were  not  matched  to  the  known  topology  of  the  target  host.    An  unknown
alert, incompletely specified dependency information in the fact base, or  incomplete
topology information regarding the target host, results in a neutral relevance score of
127 (i.e., the score does not contribute positively or negatively to the overall incident
rank  for  that  security  incident).    Scores  nearer  to  255  indicate  that  the  majority  of
required  dependencies  of  the  reported  security  incident  were  matched  to  the  known
topology of the target host.
2.3   Priority Formulation
 The  objective  of  mission  impact  analysis  is  to  fuse  related  alerts  into  higher-level
security incidents, and rank them based on the degree of threat each incident poses to
the mission objectives of the target network.   A mission is defined with respect to an
administrative network domain.   Mission-impact analysis seeks to isolate the highest
threat security incidents together, providing the analyst with an ability to  reduce  the
total number of incidents that must be reviewed.  Abstractly, we define security inci-
dent prioritization as follows:
Stream = {e1, e2, e3, …., en}
Stream = {e1, e2, e3, …., en}
Stream = {e1, e2, e3, …., en}
Let 
Let 
Let 
Find      HighImpact = {e , e , …., e } ⊆ Stream
Find      HighImpact = {e , e , …., e } ⊆ Stream
∀
∀
∀
∈ HighImpact
∈ HighImpact
∈ HighImpact
ei    
ei    
ei    
Threat_Rank(ei, Mission) > Tacceptable
Threat_Rank(ei, Mission) > Tacceptable
Threat_Rank(ei, Mission) > Tacceptable
The mission is the underlying objective for which the computing resources and data
assets of the monitored network are brought together and used.   We express this con-
cept of mission through a mission specification, which is defined by the analyst.    A
mission  specification  is  defined  in  two  parts:    (1)  an  enumeration  by  the  analyst  of
those data assets and services that are most critical to the client users of the network,
and (2) an identification of which classes of intrusion incidents are of greatest concern
to the analyst.   With respect to the critical assets and services of the protected net-
work, the analyst must register the following items within the mission specification:
100
P.A. Porras, M.W. Fong, and A. Valdes
n  Critical computing assets (such as file servers on which the user community de-
pends)
n  Critical network services (such as web server, a DBMS)
n 
Sensitive  data  assets  (these  are  primarily  files  and  directories  considered  highly
sensitive or important to the mission of the network)
n  Administrative and untrusted user accounts such as might be used by consultants
Next,  the  analyst  can  specify  those  intrusion  incidents,  or  classes  of  incident,  of
greatest  concern  given  the  analyst’s  responsibilities  within  the  organization.    This
portion of the mission specification is referred to as the interest profile.  Interest pro-
files may be user specific, just as the responsibilities of analysts may be distinct.  Each
alert processed by M-Correlator is associated with a unique incident class type.   Each
incident  signature  listed  in  the  incident  handling  knowledge  base  is  associated  with
one of the following incident classes, which were derived, in part, from a review of
previous work in incident classifications and vulnerability analysis [15, 2, 11]:
n 
Privilege  Violation  —  Theft  or  escalation  of  access  rights  to  that  of  system  or
administrative privileges.
n  User  Subversion  —  An  attempt  to  gain  privileges  associated  with  a  locally  ad-
ministered account.  This may include reports of user masquerading.
n  Denial of Service — An attempt to block or otherwise prevent access to an inter-
nal asset, including host, application, network service, or system resource, such as
data or a device.
Probe - An attempt to gain information on assets or services provided within the
monitored domain.
n 
n 
n  Access Violation — An attempt to reference, communicate with, or execute data,
network traffic, OS services, devices, or executable content, in a manner deemed
inconsistent with the sensor's surveillance policy.
Integrity Violation — An  attempt  to  alter  or  destroy  data  or  executable  content
that is inconsistent with the sensor's surveillance policy.
System Environment Corruption — An unauthorized  attempt  to  alter  the  opera-
tional  configuration  of  the  target  system  or  other  system  asset  (e.g.,  network
service configuration).
n 
n  User  Environment  Corruption  —  An  unauthorized  attempt  to  alter  the  environ-
ment configuration of a user account managed within the monitored domain.
n  Asset Distress — Operational activity indicating a current or impending failure or
significant degradation of a system asset (e.g., host crash, lost service, destroyed
system process, file system, or processtable exhaustion).
Suspicious  Usage  —  Activity  representing  significantly  unusual  or  suspicious
activity worthy of alert, but not directly attributable to another alert class.
n 
n  Connection Violation — A connection attempt to a network asset that occurred in
violation of the network security policy.
A Mission-Impact-Based Approach to INFOSEC Alarm Correlationˆ
101
Incident Rank:  An assessment and ranking of events {e1,. ..., en, …}
with respect to
{
 Mission Profile = {CR
 Probability of Success --> {Alert Outcome, Relevance}
, CR resources, CR users, Incidentweight}
assets
Fig. 1.  Incident Rank Calculation
n  Binary  Subversion  —  Activity  representing  the  presence  of  a  Trojan  horse  or
virus.
n  Action Logged — A security relevant event logged for potential use in later fo-
rensic analyses.
n  Exfiltration — An attempt to export data or command interfaces through an un-
expected or unauthorized communication channel.
M-Correlator allows analysts to specify low, medium-low, medium, medium-high,
and high interest in a particular incident type.
2.4   Incident Rank Calculation
Incident ranking represents the final assessment of each security incident with respect
to (a) the incident’s impact on the mission profile as reflected by the priority calcula-
tion, and (b) the probability that the security incident reported by the INFOSEC de-
vice(s)  has  succeeded.    Most  sensors  provide  little  if  any  indication  regarding  the
outcome of an observed security incident, providing strong motivation for the produc-
tion of a relevance score, where possible.  It should be noted that the concept of out-
come is decoupled here from that of the relevance analysis, in that outcome represents
a  sensor  provided  conclusion  produced  from  a  method  unknown  to  the  correlation
engine.   Relevance represents an assessment of the target system’s susceptibility to an
attack given vulnerability dependencies and the attack target’s configuration.   While
both outcome and relevance may reinforce each other in increasing an overall incident
rank score, so too can they neutralize each other in the face of disagreement.
Once a mission profile is specified, security incidents may be assessed and ranked
against the profile.  We concisely define incident ranking as illustrated in Figure 1.
2.4.1   The Bayes Calculation
Mathematically,  relevance,  priority,  and  incident  rank  calculations  are  formulated
using an adaptation of the Bayes framework for belief propagation in trees, described
in [17] and [21]. Our adaptation of the Bayes  framework  employs  simultaneous  ob-
servable attributes (cf., per attribute updates of a network).  Additionally, this Bayes
network produces values for relevance, priority, and incident rank even when only a
limited  set  of  observed  attributes  are  available  —  a  behaviour  that  is  unachievable
with continuous variable calculations.  In this framework, belief in hypotheses at the
root node is related to propagated belief at other nodes and directly observed evidence
102
P.A. Porras, M.W. Fong, and A. Valdes
at leaf nodes by means of conditional probability tables (CPTs).  At each node, “prior”
probabilities  SDUHQW are propagated from the parent, and “likelihoods”  FKLOG are
propagated  to  the  parent.    The  branch  and  node  structure  of  the  tree  expresses  the
three major aspects of the calculation, namely, outcome, relevance, and priority.
Bayes networks compute belief in a number of hypothesis states.  In our adaptation,
the root node considers the hypothesis “criticality” and states “low”, “medium”, and
“high”.  A mapping function transforms this to a single value on a scale of 0 to 255.
The predefined CPTs encode the mathematical  relationship  between  observable  evi-
dence and derived intermediate node values to the overall criticality of the alert with
respect to the mission.  The predefined conditional probability tables were created by
interactively  training  the  network  with  exemplar  attribute  sets.    Although  all  such
calculations  are  ultimately  subjective,  we  tuned  the  CPTs  to  provide  "reasonable"
trade-offs and balance between relevance-, priority-, and outcome-related attributes to
best match our (human) expert's intuitive alert ranking.  In effect, the process of tuning
the Bayes network CPTs is similarly to tuning an expert system via knowledge engi-
neering.
While CPT initialization begins with expert tuning, we recognize the need to adapt
the framework for specific environments.  To this end, we include an adaptive mode
wherein the analyst presents simulated alerts, which are ranked by the system.  At this
time the analyst either accepts the outcome or enters a desired ranking.  This causes
the CPTs to adapt slightly in order to more accurately reflect the administrator’s pref-
erence.  The adaptation occurs with no knowledge of the underlying Bayes formalism
on the part of the administrator.  The analyst may optionally revert to the original CPT
values as well.
2.4.2 The Rank Tree
Figure 2 represents the complete incident rank tree, which brings together the contri-
butions of alert outcome (when provided by the INFOSEC device), relevance score,
and security incident priority score.  These three contributors are represented by the
three  major  branches  of  the  incident  rank  tree.    The  priority  subtree  represents  a
merger of the incident class importance, as defined by the analyst, and the criticality of
the  attack  target  with  respect  to  the  mission  of  the  network.        The  elements  of  the
respective CPTs reflect P(criticality = c|priority = p).  Each of these matrices repre-
sents two values of criticality by three values of priority.  Therefore, the local knowl-
edge base consists of a set of CPTs linking the attribute to the appropriate node on its
main branch.  If the attribute is not observed in a given alert, the state of the corre-
sponding node is not changed, and thus this attribute does not influence the result one
way  or  the  other.    If  this  attribute  is  observed  in  a  subsequent  update  for  the  same
alert, our system adjusts the previous prioritization for the new information.
A Mission-Impact-Based Approach to INFOSEC Alarm Correlationˆ
103
Rank
Outcome
Priority
Relevance
Attack Code
Interest
As-
Vuln OS
Vuln HW
App
    Service
Port
User
              File
  Host
          Net Service
           Protocol
Fig.2.  Incident Rank Calculation
As discussed in Section 2.2, our model identifies five equally weighted contributing
attributes  that  formulate  the  relevance  score:  vulnerable  OS,  vulnerable  hardware,
service suite, bound ports, and application.  The relevance subtree in Figure 2 illus-
trates these elements.  Again, the Bayes net is robust in cases where the alert does not
provide values for all these attributes.
3   Alert Clustering Algorithm
M-Correlator employs an alert clustering algorithm, which is used to consolidate both
network and host-based INFOSEC alerts that occur in close (dynamically adjustable)
temporal proximity into correlated security-incident reports.  INFOSEC alerts regard-
ing  network  communications  are  merged  through  an  analysis  of  common  network
session, as defined by port and IP address matches, and common observer, alert type,
or, more liberally, by common alert classification as defined in the incident handling
fact base.   INFOSEC alerts regarding host activity are merged through an analysis of
common session, as defined through user session attributes such as process ID or user
ID, common observer, alert type, or more liberally by common alert classification.
Figure 3, shows an example M-Correlator clustering policy.  (Note that we are de-
liberately  restricting  this  discussion  to  the  more  straightforward  properties  of  these
policies.)  Given a new security-incident report, the M-Correlator  first  determines  if
the report is a candidate for the policy.  In this example, if the report originates from
either  a  network  sensor  or  a  host-based  sensor  in  which  the  source  process  ID  and
source user names are known, then the report is a candidate for further processing.
104
P.A. Porras, M.W. Fong, and A. Valdes
     Profile       Cross_Sensor_Signature_And_Session_Match
     Policy        Liberal
     Candidate_If   [ OR
             [ IN_GROUP        observer_name Network_Sensor ]
             [ AND
                 [ IN_GROUP    observer_name Host_Sensor ]
                 [ NOT
                     [ AND
                         [ NULL source_pid ]
                         [ NULL source_username ]
                     ]
                 ]
             ]
         ]
     Match_If [ AND
                [ EQ            incident_signature ]
                [ NULL_OR_EQ    observer_stream ]
                [ OR
                   [ AND
                       [ IN_GROUP observer_name Network_Sensor ]
                       [ ELEMENTS_EQ            source_IParray ]
                       [ ELEMENTS_EQ            target_IParray ]
                   ]
                   [ AND
                       [ IN_GROUP observer_name Host_Sensor ]
                       [ ELEMENTS_EQ            target_IParray ]
                       [ NULL_OR_EQ             source_pid ]
                       [ NULL_OR_EQ             source_username ]
                   ]
                ]
            ]
     Delay_Until_Expire      600
     Delay_Until_Flush       90
     Initial_Flush_Delay     90
     Enable                  true
     Unique_Match            true
     Merge_Action            fuse
Fig. 3.  Example Alert Cluster Policy Specification
The  clustering  policy’s  Match_If  clause  defines  the  criteria  by  which  reports  are
clustered.  Thus, in this case, all clustered report incident signatures and their observer
stream  identifiers  (if  extant)  must  match.    Also,  if  the  sensor  is  network-based,  the
reports  must  have  matching  source  and  target  IP  addresses;  while  if  host-based,  the
A Mission-Impact-Based Approach to INFOSEC Alarm Correlationˆ
105
reports must have matching target IP addresses, and, if extant, matching source proc-
ess IDs and source user names.
A clustering policy also specifies the longevity of a clustered report when there are
no subsequent candidate reports; the delay before a clustered report is initially issued,
and the refresh interval between clustered report updates, again whose purpose is to
reduce report traffic.
The incident-handling fact base also supports the specification of a set of attributes
that  represent  loose  relationships  among  alerts  of  different  classes.    For  example,
consider a firewall that reports a series of connection violations between external host
A and internal host B, and suppose this activity temporally overlaps an internal net-
work IDS report of a port sweep on several ports.  That is, the port sweep manifested
itself by two sets of activity:  (1) connection attempts that were blocked by the firewall
filtering  policy,  and  (2)  connections  that  were  allowed  through  the  firewall,  but  in
aggregate caused the network IDS to consider the flurry of connections as a potential
port  scan.    Alert  clustering  tags  are  established  by  the  incident  handling  fact  base
maintainer, and allow M-Correlator a greater ability to leverage associations unique to
specific known scenarios.  In this example, a shared cluster name within the incident-
handling fact base allows M-Correlator to merge the connection violation reports with
the port scan alerts.
4   An Example Mission Specification
A brief example mission specification is subsequently used here to illustrate mission-
based impact analysis.  This example is based on a simulated heterogeneous network,
illustrated in Figure 4.  The network consists of hosts employing four different oper-
ating systems and protected by several distributed INFOSEC devices.  Four Sun So-
laris  systems  are  protected  by  host-based  intrusion  detection  sensors  (SRI’s
EMERALD  eXpert-BSM  [14]),  and  three  network  intrusion  detection  systems
(eBayes-TCP [21], eXpert-Net, and RealSecure).  Traffic entering the LAN is filtered
Fig. 4.  An Experimental Simulation Network
106