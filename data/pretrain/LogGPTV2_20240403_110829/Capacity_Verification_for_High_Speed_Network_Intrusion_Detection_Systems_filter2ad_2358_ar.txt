### Relevance Score Calculation

The relevance score is computed on a scale from 0 to 255. A score of 0 indicates that the incident vulnerabilities required for the successful execution of the reported security incident were not matched to the known topology of the target host. An unknown alert, incomplete dependency information in the fact base, or incomplete topology information regarding the target host, results in a neutral relevance score of 127. This neutral score neither positively nor negatively affects the overall incident rank. Scores closer to 255 indicate that the majority of the required dependencies of the reported security incident were matched to the known topology of the target host.

### 2.3 Priority Formulation

The objective of mission impact analysis is to aggregate related alerts into higher-level security incidents and rank them based on the degree of threat each incident poses to the mission objectives of the target network. A mission is defined within the context of an administrative network domain. Mission-impact analysis aims to isolate the highest-threat security incidents, providing the analyst with the ability to reduce the total number of incidents that need to be reviewed.

Abstractly, we define security incident prioritization as follows:

- **Stream** = {e1, e2, e3, …, en}
- **HighImpact** = {ei, ej, …, ek} ⊆ Stream
- ∀ ei ∈ HighImpact, Threat_Rank(ei, Mission) > Tacceptable

The mission is the underlying objective for which the computing resources and data assets of the monitored network are utilized. We express this concept through a mission specification, which is defined by the analyst. A mission specification consists of two parts:
1. An enumeration by the analyst of the data assets and services that are most critical to the client users of the network.
2. An identification of the classes of intrusion incidents that are of greatest concern to the analyst.

For the critical assets and services of the protected network, the analyst must register the following items within the mission specification:
- Critical computing assets (e.g., file servers on which the user community depends)
- Critical network services (e.g., web servers, database management systems)
- Sensitive data assets (primarily files and directories considered highly sensitive or important to the network's mission)
- Administrative and untrusted user accounts (e.g., those used by consultants)

Next, the analyst can specify the intrusion incidents or classes of incidents that are of greatest concern given the analyst’s responsibilities within the organization. This portion of the mission specification is referred to as the interest profile. Interest profiles may be user-specific, reflecting the distinct responsibilities of different analysts.

Each alert processed by M-Correlator is associated with a unique incident class type. Each incident signature listed in the incident handling knowledge base is associated with one of the following incident classes, derived in part from previous work in incident classifications and vulnerability analysis [15, 2, 11]:

- **Privilege Violation**: Theft or escalation of access rights to system or administrative privileges.
- **User Subversion**: An attempt to gain privileges associated with a locally administered account, including reports of user masquerading.
- **Denial of Service**: An attempt to block or prevent access to an internal asset, such as a host, application, network service, or system resource.
- **Probe**: An attempt to gain information on assets or services provided within the monitored domain.
- **Access Violation**: An attempt to reference, communicate with, or execute data, network traffic, OS services, devices, or executable content in a manner inconsistent with the sensor's surveillance policy.
- **Integrity Violation**: An attempt to alter or destroy data or executable content in a manner inconsistent with the sensor's surveillance policy.
- **System Environment Corruption**: An unauthorized attempt to alter the operational configuration of the target system or other system asset (e.g., network service configuration).
- **User Environment Corruption**: An unauthorized attempt to alter the environment configuration of a user account managed within the monitored domain.
- **Asset Distress**: Operational activity indicating a current or impending failure or significant degradation of a system asset (e.g., host crash, lost service, destroyed system process, file system, or process table exhaustion).
- **Suspicious Usage**: Activity representing significantly unusual or suspicious behavior worthy of alert but not directly attributable to another alert class.
- **Connection Violation**: A connection attempt to a network asset that occurred in violation of the network security policy.
- **Binary Subversion**: Activity representing the presence of a Trojan horse or virus.
- **Action Logged**: A security-relevant event logged for potential use in later forensic analyses.
- **Exfiltration**: An attempt to export data or command interfaces through an unexpected or unauthorized communication channel.

M-Correlator allows analysts to specify low, medium-low, medium, medium-high, and high interest in a particular incident type.

### 2.4 Incident Rank Calculation

Incident ranking represents the final assessment of each security incident with respect to:
- The incident’s impact on the mission profile as reflected by the priority calculation.
- The probability that the security incident reported by the INFOSEC device(s) has succeeded.

Most sensors provide little to no indication regarding the outcome of an observed security incident, making it essential to produce a relevance score where possible. It should be noted that the concept of outcome is decoupled from that of relevance analysis. Outcome represents a sensor-provided conclusion produced from a method unknown to the correlation engine, while relevance assesses the target system’s susceptibility to an attack given vulnerability dependencies and the attack target’s configuration. Both outcome and relevance can reinforce or neutralize each other in the overall incident rank score.

Once a mission profile is specified, security incidents may be assessed and ranked against the profile. We concisely define incident ranking as illustrated in Figure 1.

#### 2.4.1 The Bayes Calculation

Mathematically, relevance, priority, and incident rank calculations are formulated using an adaptation of the Bayes framework for belief propagation in trees, as described in [17] and [21]. Our adaptation employs simultaneous observable attributes and produces values for relevance, priority, and incident rank even when only a limited set of observed attributes are available. In this framework, belief in hypotheses at the root node is related to propagated belief at other nodes and directly observed evidence at leaf nodes by means of conditional probability tables (CPTs). At each node, “prior” probabilities are propagated from the parent, and “likelihoods” are propagated to the parent. The branch and node structure of the tree expresses the three major aspects of the calculation: outcome, relevance, and priority.

Bayes networks compute belief in a number of hypothesis states. In our adaptation, the root node considers the hypothesis “criticality” and states “low,” “medium,” and “high.” A mapping function transforms this to a single value on a scale of 0 to 255. The predefined CPTs encode the mathematical relationship between observable evidence and derived intermediate node values to the overall criticality of the alert with respect to the mission. These CPTs were created by interactively training the network with exemplar attribute sets. Although all such calculations are ultimately subjective, we tuned the CPTs to provide "reasonable" trade-offs and balance between relevance-, priority-, and outcome-related attributes to best match our (human) expert's intuitive alert ranking. Tuning the Bayes network CPTs is similar to tuning an expert system via knowledge engineering.

While CPT initialization begins with expert tuning, we recognize the need to adapt the framework for specific environments. To this end, we include an adaptive mode wherein the analyst presents simulated alerts, which are ranked by the system. The analyst either accepts the outcome or enters a desired ranking, causing the CPTs to adapt slightly to more accurately reflect the administrator’s preference. The adaptation occurs without the administrator needing to understand the underlying Bayes formalism. The analyst may optionally revert to the original CPT values.

#### 2.4.2 The Rank Tree

Figure 2 represents the complete incident rank tree, which integrates the contributions of alert outcome (when provided by the INFOSEC device), relevance score, and security incident priority score. These three contributors are represented by the three major branches of the incident rank tree. The priority subtree merges the incident class importance, as defined by the analyst, and the criticality of the attack target with respect to the mission of the network. The elements of the respective CPTs reflect P(criticality = c|priority = p). Each of these matrices represents two values of criticality by three values of priority. Therefore, the local knowledge base consists of a set of CPTs linking the attribute to the appropriate node on its main branch. If the attribute is not observed in a given alert, the state of the corresponding node is not changed, and thus this attribute does not influence the result. If this attribute is observed in a subsequent update for the same alert, our system adjusts the previous prioritization for the new information.

As discussed in Section 2.2, our model identifies five equally weighted contributing attributes that formulate the relevance score: vulnerable OS, vulnerable hardware, service suite, bound ports, and application. The relevance subtree in Figure 2 illustrates these elements. The Bayes net is robust in cases where the alert does not provide values for all these attributes.

### 3 Alert Clustering Algorithm

M-Correlator employs an alert clustering algorithm to consolidate both network and host-based INFOSEC alerts that occur in close (dynamically adjustable) temporal proximity into correlated security-incident reports. Network communications alerts are merged through an analysis of common network session, defined by port and IP address matches, and common observer, alert type, or, more liberally, by common alert classification as defined in the incident handling fact base. Host activity alerts are merged through an analysis of common session, defined through user session attributes such as process ID or user ID, common observer, alert type, or more liberally by common alert classification.

Figure 3 shows an example M-Correlator clustering policy. Given a new security-incident report, M-Correlator first determines if the report is a candidate for the policy. In this example, if the report originates from either a network sensor or a host-based sensor where the source process ID and source user names are known, then the report is a candidate for further processing.

The clustering policy’s Match_If clause defines the criteria by which reports are clustered. Thus, in this case, all clustered report incident signatures and their observer stream identifiers (if extant) must match. Also, if the sensor is network-based, the reports must have matching source and target IP addresses; if host-based, the reports must have matching target IP addresses, and, if extant, matching source process IDs and source user names.

A clustering policy also specifies the longevity of a clustered report when there are no subsequent candidate reports, the delay before a clustered report is initially issued, and the refresh interval between clustered report updates. The incident-handling fact base supports the specification of a set of attributes that represent loose relationships among alerts of different classes. For example, consider a firewall that reports a series of connection violations between external host A and internal host B, and suppose this activity temporally overlaps an internal network IDS report of a port sweep on several ports. Alert clustering tags established by the incident-handling fact base maintainer allow M-Correlator to leverage associations unique to specific known scenarios. In this example, a shared cluster name within the incident-handling fact base allows M-Correlator to merge the connection violation reports with the port scan alerts.

### 4 Example Mission Specification

A brief example mission specification is used here to illustrate mission-based impact analysis. This example is based on a simulated heterogeneous network, illustrated in Figure 4. The network consists of hosts employing four different operating systems and protected by several distributed INFOSEC devices. Four Sun Solaris systems are protected by host-based intrusion detection sensors (SRI’s EMERALD eXpert-BSM [14]), and three network intrusion detection systems (eBayes-TCP [21], eXpert-Net, and RealSecure). Traffic entering the LAN is filtered.