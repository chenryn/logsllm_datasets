the proposed mechanisms, then present their efﬁcacy in tol-
erating injected faults.
4.2.1. Fault-free Performance. To determine the overhead
of the proposed fault tolerance mechanisms, we ﬁrst con-
centrate on supposed fault-free models. Figure 5 presents
the impact of FTplan on the system behavior.
Note that results in W4 must be treated with caution, as
Figure 5. Impact of FTplan (without injected
faults): This ﬁgure studies the impact of the FTplan com-
ponent on fault-free system behavior by comparing three
different robots: Robot1 uses our ﬁrst model, Robot2 uses
our second model, and Robot1/2 contains an FTplan com-
ponent that uses successively our ﬁrst and second models.
For each considered activity (M1W1 to M4W4), the ﬁgure
shows ﬁve different measures: (a) (b) (c) three failure pro-
portions to reach the different types of goals in a mission
(resp. photos, communications, and returns to initial po-
sition), (d) failure proportion of the whole mission (a mis-
sion is considered failed if one or more mission goals were
not achieved), and (e) the mean number of replanning op-
erations observed during one experiment (in the case of
Robot1/2, this number is equivalent to the number of model
switches during the mission).
this world contains large obstacles that may cause naviga-
tional failures and block the robot path forever. As our work
focus on planning model faults rather than limitations of
functional modules, we consider that success in this world
relies more on serendipity in the choice of plan rather than
correctness of the planner model. It is however interesting
to study the system reaction to unforeseen and unforgiving
situations that possibly arise in an open and uncontrolled en-
vironment. Note that these results show that different mod-
els give rise to different failure behaviors: particularly in
W4, the three systems fail differently.
W4 set aside, results are globally very good: Robot1 and
Robot1/2 succeed in all their goals, while Robot2 fails a
few goals in M3, and all its return goals in M4W1. These
failures may be attributed to a larger set of constraints in
this model that may be costly in performance, and under-
estimated distance declarations. The mean activity time of
the systems (that is the time until the system stops all activ-
ity in a mission) is an average of 404 seconds for Robot1,
376 seconds for Robot2, and 405 seconds for Robot1/2.
Time performance-wise, the three systems are thus roughly
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:20 UTC from IEEE Xplore.  Restrictions apply. 
05M1 W1W2W3W4M2 W1W2W3W4M3 W1W2W3W4M4 W1W2W3W4#Replan050100M1 W1W2W3W4M2 W1W2W3W4M3 W1W2W3W4M4 W1W2W3W4%Bad Missions050100M1 W1W2W3W4M2 W1W2W3W4M3 W1W2W3W4M4 W1W2W3W4%¬Return050100M1 W1W2W3W4M2 W1W2W3W4M3 W1W2W3W4M4 W1W2W3W4%¬Comms050100M1 W1W2W3W4M2 W1W2W3W4M3 W1W2W3W4M4 W1W2W3W4%¬Photos(a)(b)(c)(d)(e)Robot1Robot2Robot1/237th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Figure 7. Impact of planner redundancy (with
injected faults): This ﬁgure presents overall results
achieved for all 28 mutations, both with and without the
heavily-constrained world W4.
the time is 456 seconds for Robot1* and 535 seconds for
Robot1/1*, indicating an overhead of 17%. We deem these
results as quite acceptable considering the negative impact
of discarding plan repair.
4.2.2. Fault-tolerance efﬁcacy. To test the efﬁcacy of the
proposed mechanisms and the FTplan component, we in-
jected 38 faults in our ﬁrst model, realizing more than 3500
experiments equivalent to 1200 hours of testing. We dis-
carded 10 mutants that were unable to ﬁnd a plan for any
of the four missions5. We believe that ﬁve of the remaining
mutants are equivalent to the fault-free model. However,
the non-deterministic nature of autonomous systems makes
it delicate to deﬁne objective equivalence criteria. We thus
include the results obtained with these ﬁve mutants.
The 28 considered mutations are categorized in the fol-
lowing manner: three substitutions of attribute values, six
substitutions of variables, ten substitutions of numerical val-
ues, four substitutions of operators, and six removals of
constraints. The mutants were executed on Robot1 and
Robot1/2. The results are presented in Figure 7.
These results give objective evidence that model diver-
siﬁcation favorably contributes to fault tolerance of an au-
tonomous system considering the proposed faultload: fail-
ure decreases for photo goals of 62% (respectively, 50% in-
cluding W4), 70% (64%) for communication goals, 80%
(58%) for returns goals, and 41% (29%) for whole missions.
Note, however, that RobotFT in the presence of injected
faults is less successful than a single fault-free model. This
apparent decrease in dependability is explained by the fact
that incorrect plans are only detected when their execution
has failed, possibly rendering one or more goals unachiev-
able, despite recovery. This underlines the importance of
plan analysis procedures to attempt to detect errors in plans
before they are executed.
5. Conclusion
To our knowledge, the work presented in this paper is the
ﬁrst proposition of fault tolerant mechanisms based on di-
5In this case, Robot1/2 gives the same results as the fault-free Model2:
nearly perfect success rates in W1, W2 and W3.
Figure 6. Impact of switching overhead (with-
out injected faults): This ﬁgure presents the impact
of numerous model switches on fault-free system behavior
by comparing two different robots: Robot1* uses our ﬁrst
model, and Robot1/1* contains an FTplan component that
switches between two exact copies of our ﬁrst model. Con-
sequently, neither of the robots is fault-tolerant. The results
concern only the cost of model switches. To provoke many
model switches, both robots use a version of the IxTeT plan-
ner without the optimizing functionality of plan repair: any
failed action systematically leads to complete replanning,
with an additional model switch for Robot1/1*.
equivalent.
Although the results are mostly positive, showing that
FTplan’s main execution loop does not severely decrease
goal achievement or performance in the chosen scenarios,
they are still insufﬁcient to assess the overhead of planner
switches as very few occurred in these fault-free experi-
ments. This overhead is further studied in experiments pre-
sented in Figure 6.
We effectively see that there are many more replannings
(and thus model switches) than in the previous experiments
(a mean per experiment of 8.3 against 0.3 for Robot1*, and
8.9 against 0.4 for Robot1/1*). M1W2 appears as a singu-
larity for Robot1/1* as after a few minutes of execution, the
IxTeT planner ﬁnds no solution in its current situation. We
believe this due to an elusive bug in either the model, FT-
plan, or the IxTeT planner. However, the same experiment
with Robot1/2* (using diversiﬁcation through the ﬁrst and
second models) gives successful missions, suggesting that
the bug lies in our modiﬁed version of IxTeT.
Apart from this singularity, Robot1/1* only fails more
goals than Robot1* in the over-stressing W4 execution con-
texts, as well as the complex M4W3. Setting aside W4
(and the M1W2 singularity), the mean activity time of the
systems is 381 seconds for Robot1* and 431 seconds for
Robot1/1*, indicating an overhead of 13%. Including W4,
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:20 UTC from IEEE Xplore.  Restrictions apply. 
0102030M1 W1W2W3W4M2 W1W2W3W4M3 W1W2W3W4M4 W1W2W3W4#Replan050100M1 W1W2W3W4M2 W1W2W3W4M3 W1W2W3W4M4 W1W2W3W4%Bad Missions050100M1 W1W2W3W4M2 W1W2W3W4M3 W1W2W3W4M4 W1W2W3W4%¬Return050100M1 W1W2W3W4M2 W1W2W3W4M3 W1W2W3W4M4 W1W2W3W4%¬Comms050100M1 W1W2W3W4M2 W1W2W3W4M3 W1W2W3W4M4 W1W2W3W4%¬Photos(a)(b)(c)(d)(e)Robot1*Robot1/1*Robot1Robot1/2(a)(b)(c)(d)050100W1-W4W1-W3%Bad Missions050100W1-W4W1-W3%¬Return050100W1-W4W1-W3%¬Comms050100W1-W4W1-W3%¬PhotosM1-M4 / W1-W4M1-M4 / W1-W337th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007versiﬁed planning models. We proposed a component pro-
viding error detection and recovery appropriate for fault-
tolerant planning, and implemented it in the LAAS archi-
tecture. This component can use four detection mechanisms
(watchdog timer, plan failure detector, on-line goal checker
and plan analyzer), and two recovery policies (sequential
planning and concurrent planning). Our current implemen-
tation is that of sequential planning associated with the ﬁrst
three error detection mechanisms.
To assess the performance overhead and the efﬁcacy
of the proposed mechanisms, we developed a validation
framework that exercises the software on a simulated robot
platform, and carried out what we believe to be the ﬁrst ever
mutation experiments on declarative models. These experi-
ments were conclusive in showing that the proposed mech-
anisms do not severely degrade the system performance in
the chosen scenarios, yet usefully improve the system be-
havior in the presence of model faults.
There are many directions for future research. First, im-
plementation of a plan analyzer should allow much better
goal success levels to be achieved in the presence of faults
since it should increase error detection coverage and pro-
vide lower latency. Implementation of the concurrent plan-
ning policy and comparison with the sequential planning
policy are also of interest. Moreover, we would like to eval-
uate diversiﬁcation on planning heuristics rather than just
models and investigate also the additional detection capa-
bilities of recent additions to the LAAS architecture [21].
Finally, many more experiments are needed to improve the
statistical relevance of the results. The use of a large com-
puter grid would drastically improve the number of experi-
ments that could be executed in reasonable time and elim-
inate the need for manual inspection to remove trivial mu-
tants.
References
[1] R. Alami, R. Chatila, S. Fleury, M. Ghallab, and F. Ingrand. An
Architecture for Autonomy. The International Journal of Robotics
Research, 17(4):315–337, April 1998.
[2] M. Becker and D. R. Smith. Model Validation in Planware. In ICAPS
2005 Workshop on Veriﬁcation and Validation of Model-Based Plan-
ning and Scheduling Systems, Monterey, California, June 6-7, 2005.
[3] D. E. Bernard, E. B. Gamble, N. F. Rouquette, B. Smith, Y. W.
Tung, N. Muscettola, G. A. Dorias, B. Kanefsky, J. Kurien, W. Mil-
lar, P. Nayal, K. Rajan, and W. Taylor. Remote Agent Experiment
DS1 Technology Validation Report. Ames Research Center and JPL,
2000.
[4] I. R. Chen. On the Reliability of AI Planning Software in Real-Time
Applications. IEEE Transactions on Reliability, 46(1):81–87, March
1997.
[5] I. R. Chen, F. B. Bastani, and T. W. Tsao. On the Reliability of AI
IEEE Transactions
Planning Software in Real-Time Applications.
on Knowledge and Data Engineering, 7(1):14–25, February 1995.
[6] Y. Crouzet, H. Waeselynck, B. Lussier, and D. Powell. The SESAME
In
from assembly languages to declarative models.
experience:
Proceedings of the 2nd Workshop on Mutation Analysis (Muta-
tion’2006), Raleigh, NC, November 7, 2006.
[7] M. Daran and P. Thévenod-Fosse. Software error analysis: a real
case study involving real faults and mutations. In Proceedings of the
1996 ACM SIGSOFT international symposium on Software testing
and analysis, San Diego, California, January 8-10, 1996.
[8] E. Gat. On Three-Layer Architectures. In Artiﬁcial Intelligence and
Mobile Robots, D. Kortenkamp, R. P. Bonnasso, and R. Murphy edi-
tors, MIT/AAAI Press, pages 195-210, 1997.
[9] A. E. Howe. Improving the Reliability of Artiﬁcial Intelligence Plan-
IEEE Trans-
ning Systems by Analyzing their Failure Recovery.
actions on Knowledge and Data Engineering, 7(1):14–25, February
1995.
[10] R. Howey, D. Long, and M. Fox. VAL: Automatic Plan Validation,
Continuous Effects and Mixed Initiative Planning using PDDL. In
16th IEEE International Conference on Tools with Artiﬁcial Intelli-
gence, Boca Raton, Florida, November 15-17, 2004.
[11] H. M. Huang, editor. Autonomy Levels for Unmanned Systems (AL-
FUS) Framework. Number NIST Special Publication 1011. 2004.
[12] S. Joyeux, A. Lampe, R. Alami, and S. Lacroix. Simulation in
the LAAS Architecture. In Proceedings of Principles and Practice
of Software Development in Robotics (SDIR2005), ICRA workshop,
Barcelona, Spain, April 18, 2005.
[13] K. H. Kim and H. O. Welch. Distributed Execution of Recovery
Blocks: An Approach for Uniform Treatment of Hardware and Soft-
ware Faults in Real-Time Applications. IEEE Transactions on Com-
puters, C-38:626–636, 1989.
[14] S. Lemai and F. Ingrand. Interleaving Temporal Planning and Ex-
In Proceedings of AAAI-04, pages
ecution in Robotics Domains.
617–622, San Jose, California, July 25-29, 2004.
[15] B. Lussier. Fault Tolerance in Autonomous Systems. PhD thesis,
Institut National Polytechnique de Toulouse, 2007 (in French).
[16] B. Lussier, A. Lampe, R. Chatila, F. Ingrand, M. O. Killijian, and
D. Powell. Fault Tolerance in Autonomous Systems: How and How
In Proceedings of the 4th IARP/IEEE-RAS/EURON Joint
Much?
Workshop on Technical Challenge for Dependable Robots in Human
Environments, Nagoya, Japan, June 16-18, 2005.
[17] M. Monterlo, S. Thrun, H. Dahlkamp, D. Stavens, and S. Strohband.
Winning the DARPA Grand Challenge with an AI Robot. In Amer-
ican Association of Artiﬁcial Intelligence 2006 (AAAI06), Boston,
MA, July 17-20, 2006.
[18] N. Muscettola, G. A. Dorais, C. Fry, R. Levinson, and C. Plaunt.
IDEA: Planning at the Core of Autonomous Reactive Agents.
In
AIPS 2002 Workshop on On-line Planning and Scheduling, Toulouse,
France, April 22, 2002. http://citeseer.nj.nec.com/593897.html.
[19] N. Muscettola, P. P. Nayak, B. Pell, and B. C. Williams. Remote
Agent: To Boldly Go Where No AI System Has Gone Before. Arti-
ﬁcial Intelligence, 103(1-2):5–47, 1998.
[20] J. L. Pearce, B. Powers, C. Hess, P. E. Rybski, S. A. Stoeter, and
N. Papanikolopoulos. Using virtual pheromones and cameras for
dispersing a team of multiple miniature robots. Journal of Intelligent
and Robotic Systems, 45:307–21, 2006.
[21] F. Py and F. Ingrand. Real-Time Execution Control for Autonomous
Systems. In Proceedings of the 2nd European Congress ERTS, Em-
bedded Real Time Software, Toulouse, France, January 21-23, 2004.
[22] B. Randell. System Structure for Software Fault Tolerance. IEEE
Transactions on Software Engineering, SE-1:220–232, 1975.
[23] R. Volpe, I. Nesnas, T. Estlin, D. Mutz, R. Petras, and H. Das.
CLARAty: Coupled Layer Architecture for Robotic Autonomy.
Technical Report D-19975, NASA - Jet Propulsion Laboratory, 2000.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:20 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007