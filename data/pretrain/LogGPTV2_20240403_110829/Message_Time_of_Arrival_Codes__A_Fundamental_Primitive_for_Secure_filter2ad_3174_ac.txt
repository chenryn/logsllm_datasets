symbol-wise mean to produce the correct bits a the receiver. This he can
achieve with high likelihood using a power-increase strategy. However, there
does not exist any reliable strategy for decreasing the normalized error
variance. An attacker can only do so by maintaining an edge in guessing
pulse polarities. This we model by over-approximating the attacker, e.g.,
by giving him a pulse-guessing bias ρ.
strongest. Therefore, we can deﬁne the strongest attacker ˆA
as the one that is closest in the KL-sense over all times:
ˆA := arg max
Adv(A)
A
np
Xj=1
min
= arg min
A
= arg min
A
= arg min
A
j
DKL(Aj(A) + N k N )
np DKL(Aj(A) + N k N )
DKL(A(A) + N k N )
The strategy that produces the smallest statistical distance at
any j can be converted into the best strategy over the entire
signal, by applying the same technique at any other time,
since the noise is i.i.d. Therefore, we argue that the attacker
that is locally optimal at any time is also optimal over the
entire process. The strongest attacker is, therefore, the one
that can produce a residual distribution A + N (0, σn) that
has smallest relative entropy compared to the legitimate noise
distribution N (0, σn). Under the condition that the attacker’s
error has nonzero energy, the process A that minimizes
relative entropy to the AWGN only is also a Gaussian.
Therefore, as an over-approximation, we can model the
attacker residual signal process as normally (i.e., maximum
entropy) distributed stochastic process with zero mean and
a variance given by the pulse-level guessing performance,
which we over-approximate. This is equivalent to assuming
maximum ignorance about the attacker’s process beyond the
existence of some residual energy. Under these conditions,
e.g. from [39], we know that the signal energy is a sufﬁcient
statistic for distinguishing two i.i.d. N (0, σ1), N (0, σ2)-
distributed processes.
Observation 1 The signal residual variance constitutes a
sufﬁcient statistic for detection of a guessing attack with a
maximum-entropy residual under AWGN noise.
ttb1b1b2b3b2b3power-increase strategygoalIdealpulse guessingbenign noiseρ-over-approximationFigure 8. We model two different over-approximations for the attacker’s
error variance level: An ideal bias, where an attacker knows a fraction ρ
of the pulse polarities and a non-ideal bias, where we give the attacker a
bound l on the number of power levels for a successful power-increase
attack.
Basing the classiﬁcation on the residual energy is optimal if
we can extract the attacker’s error perfectly and within the
assumptions, we can universally impose on the attacker’s
error process (i.e., being close to satisfying the three goals). A
practical attacker will likely deviate from these assumptions,
but in ways that add distinctive properties (i.e., non-zero
higher moments) to the residual distribution. Conversely, an
attacker that gets mean and variance right will win.
Observation 2 The attacker getting the mean per bit right
and minimizing signal residual variance together constitute
a sufﬁcient condition for attack success.
We have seen that, without countermeasures, a power-
increase strategy leads to a guessing bias in the receiver-side
security parameter (i.e., the bits). As an over-approximation
for the course of a power-increase strategy, we can tilt the
guessing performance in the attacker’s favor on the pulse
level. For instance, we can assume that the attacker never
makes a wrong guess twice in a row. This means, after at most
two interferences (i.e., pulses), the attacker is guaranteed to
have made a positive net contribution to the receive statistics.
We refer to this attacker as having a non-ideal bias of l = 2
and illustrate it in Figure 8. There, we contrast it to an
ideally-biased attacker, which knows a given fraction ρ of
pulses.
In Figure 7, we highlight the two-dimensional nature of
the attack strategy. It is easy for an attacker to steer the mean
by varying his energy levels, i.e., to move along the x-axis.
However, he cannot control the error variance at the same
time. So, any practical attacker strategy will be concerned
with trading off those two goals. Providing the attacker an
ideal bias results in a diagonal towards the desired spot of
high mean and low variance. In addition, as part of any
over-approximation, we assume the attacker to be successful
regarding the mean (e.g., through a power-increase strategy).
This means the attacker can move arbitrarily on the x-axis. In
the following, we motivate a speciﬁc over-approximation for
the error variance, i.e., the attacker’s position on the y-axis.
Observation 3 For an attacker, reducing the signal error
variance, while increasing its mean, is ’pulse-guessing-
hard’. This means, without a systematic guessing bias,
the (normalized) error variance is bound to increase in
a guessing attack.
2
/
2
1
0.8
0.6
0.4
0.2
0
0
2
/
2
1
0.8
0.6
0.4
0.2
0
0
0.5
1
0.5
1
Figure 9. Normalized error variance vs. mean under over-approximation
(blue) and continued interference (dashed lines). The goal of the attacker
is to get mean to 1 while minimizing variance. Given an ideal bias above
a certain threshold (ρcont ≈ 0.2), an attacker has nothing to gain from
continued interference. The dashed lines show the 0.1th percentile of the
variance for unbiased (left) and non-ideally (l = 2) biased (right) guessing
continuation.
In Figure 9, we display simulation results underlining
this. The results show the normalized residual energy of
an ideally-biased attacker (blue line) as a function of the
number of interferences, as well as the effect of continued
interference without bias (left) and with a non-ideal bias
(right). Without bias, the normalized variance is (mostly)
monotonically increasing, converging to its maximum value
of 1. With a non-ideal bias, the gain that can be maintained
is limited. Even with such a consistent bias, only at low
values for ρ is there any incentive to continue interfering.
Especially, for ρ > 0.2, there is no incentive to continue,
even with a consistent but non-ideal bias.
Observation 4 Once the attacker has succeeded in shifting
the mean for all symbols, there is (almost) no utility in
continued interference, unless the attacker has a lasting
pulse-guessing bias. But even then we can ﬁnd an ideal bias
ρcont, such that there is no utility.
We see in Figure 9 that persistent interference with a
non-ideal bias alone (i.e., no ideal bias, red curve) results
in a normalized variance of more than 0.8. We can estimate
the strength of this over-approximation as 0.75np/2. This
results from the fact that for every two pulses guessed by
an attacker, we omit the possibility of two wrong guesses,
an event with probability 0.25. By comparing this value
to the bit-equivalent MTAC security level of 2−nb , we can
see that an over-approximation with ρ = 0.2 is actually
stronger than the bit-equivalent MTAC target security level
for modulations with nppb > 2 log(0.5)
log(0.75) ≈ 4.82, i.e., at least
ﬁve pulses per bit. A decrease of the relative variance to
0.8 or, equivalently, an ideal bias of ρ = 0.2 are, therefore,
very strong over-approximations, i.e., on the order of the
(receiver-side) security parameter, that become even stronger
(less likely) for modulations over longer communication
distances.
5. Existing MTACs
Based on our insights on the attack, we need an MTAC to
verify the physical-layer integrity of a signal by measuring
the (normalized) signal residual variance. To the best of
our knowledge, there are three existing classes of MTACs
ttttthat, as we argue, aim for this implicitly. Each class is
parametrized by a performance parameter that allows to trade
off performance and security. Note that, in the following,
the robustness deﬁnition does not directly apply to the ﬁrst
two classes since those do not entail reliable information
transmission.
5.1. Sequences of single-pulse bits
To allow for longer range while using short symbols, one
could encode each bit as a single pulse and tolerate up to a
certain pre-conﬁgured rate of bit errors TBER in the veriﬁ-
cation step, as is currently proposed in 802.15.4z LRP [37].
This results in a secure MTAC under the condition that the
message m is pre-shared between transmitter and receiver.
Since relying on a single pulse makes bit transmission
unreliable, this is a purely physical-layer construct and
does not allow for integrity-protected data transmission. In
particular, a MAC will fail if there is a nonzero number of
expected bit errors per message. The resulting security and
performance level both depend on the BER tolerance level.
For c ← m ⊕ x, where x is an ideal random sequence, the
attacker’s advantage can be estimated using Sanov’s theorem,
provided in [38], as
P (X np ≥ (1 − TBER)) = 2−npDKL(P ||S).
Here, P and S capture the empirical and theoretical bi-
nomial distributions, with P = (1 − TBER, TBER) and
S = (0.5, 0.5), respectively. The random variable X np
denotes the number of bits guessed correctly by the attacker.
For TBER  T ′
D]
!
≤ FER.
The effective threshold is then chosen as the maxi-
mum threshold over the entire performance region, i.e.,
ˆTD = maxp∈P TD(p). As a result, ˆTD results in a robust
test under any performance tradeoff within the performance
region P.
repetitioncodingXORbit detectionXORsecuredistortion testtemplategeneration5
0
5
0
5
0
5
0
-5
0
10
20
t
30
-5
0
10
20
t
30
-5
0
10
20
t
30
-5