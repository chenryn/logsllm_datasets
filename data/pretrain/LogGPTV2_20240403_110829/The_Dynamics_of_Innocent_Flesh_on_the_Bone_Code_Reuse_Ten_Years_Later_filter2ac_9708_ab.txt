ditional functionality to support the command manager API (see
§4.4). The steps of the analysis are as following:
(1) Initial tainting. We model attacker-controlled memory by
initially marking regions under the attacker’s control as
tainted. To easily model different defenses, Newton ex-
poses taint limiting commands that allow control over how
the initial taint is applied (see §4.4). Newton’s DTA engine
propagates the taint information to callsites and arguments.
(2) Tracking dependencies. We configure our taint engine
with a unique tag for each byte in memory, allowing us
to track attacker-controlled memory dependencies at byte
granularity. Our dynamic taint analysis engine is capable
of tracking the taint source address for each tainted value
or pointer in memory. For each tainted byte, this tells us ex-
actly by which memory addresses it was tainted. This allows
us to track, when a tainted callsite is discovered, where the
taint originated for the associated function pointer and each
of the arguments. The source of the taint is then a candidate
value for the attacker to corrupt, to control the callsite and
mount a code-reuse attack.
libdft’s original implementation implements a basic taint-
ing strategy [39], able to track only direct attacker-controlled
memory dependencies (i.e., callsite X uses code pointer at
′ uses
tainted address Y) and not indirect ones (i.e., callsite X
′).
code pointer read via data pointer at tainted address Y
To support the latter, we implemented pointer tainting for
memory reads in libdft [39] (i.e., taint every value read
via a tainted pointer), allowing us to model an attacker cor-
rupting data pointers and non-pointers to indirectly control
code pointers (and arguments) used by tainted callsites.
(3) Logging. When an indirect call is executed, Newton logs
the relevant taint information for this callsite. Specifically,
for each tainted callsite, we emit information detailing the
taint dependencies for the callsite’s target, and the first six
arguments.
Session H2:  Code Reuse AttacksCCS’17, October 30-November 3, 2017, Dallas, TX, USA16784.3 Target Constraint Manager
Like the write constraint manager, the target constraint manager
models constraints imposed by code reuse defenses. It uses static
and dynamic analysis to extract callsite and callee information,
which it then uses to impose the user-defined constraint policy.
Static analysis. We use a static analysis based on DWARF
debugging symbols to extract all callsites and potential callees
from the target binary and shared libraries, along with associated
type information. Newton uses the extracted information (if in-
structed) to simulate a number of policies for existing defenses,
such as type-based CFI [50, 66, 68].
Dynamic analysis. In addition to the aforementioned static
analysis, we also use dynamic analysis to scan user-defined ranges
of writable memory (such as .data, or the heap) for code point-
ers. We define a live code page as a memory page pointed to by
a live code pointer, i.e., a code pointer stored in live data memory
that can be leaked and overwritten. Our dynamic analysis allows
us to track live code pointers and code pages. We use this infor-
mation to model target constraints imposed by defenses such as
Readactor [19], which limit an attacker to using “live” gadgets in
memory.
The target constraint manager logs the valid targets for each
callsite based on the constraints derived by the static and dynamic
analysis, as guided by the user-defined script modeling the defense.
4.4 Command Manager
As mentioned, Newton includes write constraint and target con-
straint managers which model the constraints imposed by a partic-
ular defense, based on a user-defined script. To handle the scripting
commands, Newton includes a command manager. The command
manager is a preloaded library that loads along with the analyzed
binary, and listens for commands on a Unix domain socket. When
a command is received, the command manager dispatches it to the
right constraint manager, which handles it as needed.
Newton exposes the following command functions, sufficient
to map all of the defenses we evaluate in §6. In §5, we show exam-
ples of these commands used in practice to model defenses.
(cid:15) taint-mem: This command instructs the taint analysis en-
gine to mark all writable memory as tainted, simulating
the arbitrary read/write primitive we assume in our threat
model (see §2). It initializes the source taint for each value
to its own address. In §5, we show how among other things,
we use taint-mem to taint all memory after bringing a vic-
tim server program into a quiescent state.
(cid:15) taint-flip: This command untaints all tainted data, and
taints all untainted data. We use the ability to flip taint when
crafting history-flushing attacks against context-sensitive
CFI defenses, as explained further in §5.
(cid:15) taint-prop-toggle: This command pauses or resumes
the propagation of taint (also implies taint-log-toggle)
by Newton’s DTA engine. Default: on.
(cid:15) taint-log-toggle: Similarly to taint-prop-toggle, this
command pauses or resumes the logging of tainted callsites.
This is used to avoid logging uninteresting callsites. Taint
propagation continues normally. Default: on.
(cid:15) taint-ptr-toggle: This command enables or disables
pointer tainting on memory reads. Default: on.
(cid:15) taint-wash (CPtr|Ptr|AddressRange): This command
clears the taint for particular memory locations: locations
with code pointers, data pointers, or in a given address
range.
(cid:15) constrain-targets: This command specifies target con-
straints to enforce on tainted callsites.
(cid:15) get-gadgets: This command retrieves all gadgets collected
during the execution.
5 MAPPING DEFENSES IN Newton
As mentioned in §4, for the purpose of finding gadgets for code
reuse with Newton, we model the security provided by code-reuse
defenses along two axes: (1) write constraints imposed by the de-
fense, and (2) the imposed target constraints. In this section, we
map the defenses from §3 according to these constraints. This map-
ping allows us to easily create scripts that teach Newton about
the constraints (security restrictions) imposed when searching for
attacker-controllable gadgets (callsites and possible targets).
5.1 Deriving Constraints
Table 1 summarizes the constraints imposed by each defense class.
We now discuss each class in detail.
Control-Flow Integrity. We distinguish five subclasses within
the CFI class of defenses: (1) TypeArmor, (2) IFCC/MCFI, (3) Safe
IFCC/MCFI, (4) HCFI, and (5) CsCFI.
TypeArmor imposes target constraints which enforce that call
sites can only target functions with a type matching the call site’s
type; such types are approximated by statically analyzing the pro-
gram binary (Bin types). Since TypeArmor is the only defense
which offers function type-based CFI at the binary level, it has its
own dedicated subclass in Table 1.
The IFCC/MCFI subclass provides similar constraints as the Ty-
peArmor subclass, except that function type information is com-
puted at the source rather than at the binary level. This leads to
a stronger target constraint (Src types) and hence security. This is
because source information allows IFCC/MCFI to compute more
accurate type information and derive a smaller legal target set.
Safe IFCC/MCFI comprises the same defenses as the IFCC/M-
CFI subclass, except that in this case the defenses run in a “safe”
mode, where type information is less strict for compatibility rea-
sons with real-world programs—discussed in the original IFCC pa-
per [66]. For instance, in this mode, pointer parameters such as
int* or void* are each considered to be interchangeable with
other pointer types. This leads to a weaker target constraint (Safe
src types) compared to the non-safe variant of this subclass.
In the HCFI (history-based CFI) subclass, the set of valid targets
for each call site is determined by the set of code pointers that
have been computed during the execution. This is a dynamic target
constraint (Computed), which can be used in isolation or combined
with other static target constraints.
All the CFI subclasses thus far have been modeled using target
constraints. Somewhat counterintuitively, we model the CsCFI sub-
class using only write constraints. The reason is that this makes it
much easier to write a Newton CsCFI-aware script for a low-effort
Session H2:  Code Reuse AttacksCCS’17, October 30-November 3, 2017, Dallas, TX, USA1679Table 1: Mapping of code-reuse defenses to Newton constraints. Empty entries for write/target constraints indicate that the
defense imposes no write/target constraints, respectively.
Class
CFI
IH
RR
PI
Defense
Subclass
TypeArmor
Safe IFCC/MCFI
IFCC/MCFI
HCFI
CsCFI
Oxymoron
XoM
XoM++
CodeRR
TASR
PtrRR
ASLR-Guard
CCFI/CPS
CPI
Solutions
[68]
[50, 66]
[50, 66]
[51]
[16, 28, 34, 44, 54, 67]
[4]
[3, 12, 19, 29, 30, 56, 65, 72]
[15, 20]
[15, 70, 73]
[7]
[31, 45]
[46]
[43, 47]
[43]
attacker. Formulating CsCFI in terms of target constraints would
require us to provide Newton with knowledge about the context-
sensitive analysis, the branch history size, and the time of valida-
tion (e.g., syscall time). Furthermore, when assuming a "perfect"
(but practical) implementation of CsCFI, the branch history can be
arbitrarily large (but not unlimited), allowing a "perfect" context-
sensitive analysis to always detect invalid targets in the large con-
text provided. In other words, the only way for an attacker to by-
pass the defense is to force the application to flush the (arbitrarily
large) branch history [14] before triggering the exploit. This leaves
CsCFI with no context to constrain the controlled target set.
For this purpose, the attacker needs to (1) corrupt some segre-
gated (independent and stable) application state, (2) send an arbi-
trarly large number of idempotent history-flushing inputs to the
application that do not interfere with the segregated state, (3) send
the final input to trigger the exploit based on the segregated state.
This translates to a write constraint (Segr) that limits writes to the
segregated state specified by the attacker. At first glance, identify-
ing such state and the history-flushing input seems complicated. In
practice, this is possible even for a low-effort attacker. For example,
for common server applications that handle multiple connections
in a single worker process (e.g., nginx), we can simply instruct
Newton to use the connection-specific data of a first connection
as segregated state and a simple request over a second connection
as the history-flushing input (as done in §5.2).
Information Hiding. We distinguish three subclasses within
the IH class of defenses: (1) Oxymoron, (2) XoM, and (3) XoM++.
The Oxymoron subclass allows only targets contained in live
code pages. This translates to a target constraint (Live +page) that
limits the set of valid (i.e., attacker-leaked) targets to pages pointed
to by live code pointers.
The XoM subclass contains defenses that hide the code layout
from an attacker. This translates to a target constraint (Live) that
limits the set of valid targets to live code pointers (again stored
Write constraints
Details
Dynamic
Target constraints
Details
Bin types
Segr
:CPtr
:Ptr
:CPtr
:Ptr
3
3
3
3
3
3
3
3
3
3
Safe src types
Src types
Computed
Live +page
Live :GOT
Live
Live
Live
Live
Live
Live
Live
and then leaked from memory), given that the attacker can make
no assumptions on the other code pointers.
Finally, defenses in the XoM++ subclass implement XoM seman-
tics and additionally hide the GOT from an attacker. This translates
to a stronger target constraint (Live :GOT) than XoM’s, where live
code pointers in the GOT are no longer valid. Since the GOT itself
is no longer reachable and thus not corruptable, this also trans-
lates to a write constraint (:GOT), which, for simplicity, we leave
implicit in our analysis and presentation of the results (its impact
typically aligns with its target constraint counterpart).
Re-randomization. We distinguish three subclasses within
the RR class of defenses: (1) CodeRR, (2) TASR, and (3) PtrRR. Since
all these subclasses hide the code layout under ideal conditions,
they all impose a target constraint that allows only live code point-
ers to be used as valid targets (Live). However, the subclasses differ
in terms of their write constraints.
First, the CodeRR subclass only hides (i.e., re-randomizes) the
code layout and imposes no additional write constraints. The sec-
ond RR subclass, TASR, does impose an additional write constraint.
Not only does TASR periodically re-randomize the code layout,
but it also re-randomizes the code pointer representation (even
for code pointers stored in data memory). In doing so, it prevents
attackers from successfully overwriting code pointers. This trans-
lates to a write constraint (:CPtr) that forbids writes to mem-
ory locations containing code pointers. In other words, this con-
straint teaches Newton that the only way to find gadgets that by-
pass CodeRR is to corrupt data pointers (or non-pointers) to force
the program to access an attacker-controlled live code pointer
rather than the original intended target (e.g., corrupting c to hi-
jack c->handler()).
Finally, the PtrRR subclass is similar to TASR, except that the
imposed write constraint is stronger. Not only code pointers but
all pointers are re-randomized and thus “protected” against over-
writes. This translates to a write constraint (:Ptr) that forbids
writes to memory locations containing either code or data pointers.
Session H2:  Code Reuse AttacksCCS’17, October 30-November 3, 2017, Dallas, TX, USA16801
2
3
4
5
6
7
1
2
3
4
5
6
7
8
9
10
11
$ start server
constrain-targets $Cons
$ C1 = open connection
taint-mem
$ send request over C1
get-gadgets
(a) No write constraints.
$ start server
constrain-targets $Cons
$ C1 = open connection
taint-mem
taint-wash Ptr
$ send request over C1
get-gadgets
(c) :Ptr.
1
2
3
4
5
6
7
1
2
3
4
5
6
7
8
9
10
11
$ start server
constrain-targets $Cons
$ C1 = open connection
taint-mem
taint-wash CPtr
$ send request over C1
get-gadgets
(b) :CPtr.
$ start server
constrain-targets $Cons
taint-prop-toggle off
taint-mem
$ C1 = open connection
taint-flip
$ C2 = open connection
$ send N requests over C2
taint-prop-toggle on
$ send request over C1
get-gadgets
(d) Segr.
Figure 2: Mapping of defense classes to write (x-axis) and
target (y-axis) constraints in Newton. Constraints on the
two axes are sorted based on their effectiveness in reducing
the number of gadgets available to a low-effort attacker on
nginx, when sending a plain HTTP GET request.
In other words, this constraint teaches Newton that the only way
to find gadgets that bypass PtrRR is to corrupt non-pointers such as
integers (e.g., corrupting idx to hijack func[idx]->handler()).
Figure 3: Newton command scripts for finding gadgets un-
der different modeled write constraints.
Pointer Integrity. We distinguish three subclasses within the
PI class of defenses: (1) ASLR-Guard, (2) CCFI/CPS, and (3) CPI. All
three of these prevent an attacker from crafting new code pointers
from scratch, thus enforcing a target constraint that limits targets
to live code pointers (Live).
ASLR-Guard does not impose any additional constraints. It
implements the aforementioned target constraint by using per-
pointer secret keys to encrypt all code pointers. Thus, while an at-
tacker cannot introduce new code pointers, it is still possible to re-
place a code pointer with another arbitrary live code pointer, given
that the secret key is not location-aware.
The second PI subclass, CCFI/CPS, does impose an additional
write constraint that forbids writes to memory locations contain-
ing code pointers (:CPtr). In the case of CCFI (Cryptographically-
enhanced CFI), this is implemented by encrypting pointers with a
memory location-dependent key. In the case of CPS, the same ef-