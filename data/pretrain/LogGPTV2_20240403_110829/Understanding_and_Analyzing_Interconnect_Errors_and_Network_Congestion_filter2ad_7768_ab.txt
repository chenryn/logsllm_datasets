Cabinets Rows
Fig. 4: Spatial distribution of lane degrades inside and across
cabinets. Due to the folded 3D-torus design, cross-cabinet
links connect to alternate cabinets.
  Per−cabinet distribution of link inactive errors count
l
s
n
m
u
o
C
s
t
e
n
b
a
C
i
7
6
5
4
3
2
1
0
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
Cabinets Rows
70
60
50
40
30
20
10
0
Fig. 5: Spatial distribution of link inactive errors inside and
across cabinets. Due to the folded 3D-torus design, cross-
cabinet links connect to alternate cabinets.
the Kolmogorov-Smirnov test (K-S test) to test whether our
sample of spatial distribution of lane degrades per cabinet has
a uniform distribution. The test results show D-statistic = 1,
p-value = 2.2e-16. For our sample size of 200 cabinets, the
critical D-value for a 0.05 level of signiﬁcance is 0.0960, and
therefore the null hypothesis (i.e., the sample is taken from
a uniform distribution) can be rejected. This shows that the
spatial distribution of lane degrades per cabinet is signiﬁcantly
different than uniform. This behavior can be a combination of
factors, although accurate root-cause analysis is not possible.
External transient effects, overloading of links, uneven usage,
and complex interaction between applications and interconnect
network contribute toward such a behavior.
Interestingly, we note that the hot spots for links contained
4
within the cabinet are not the same as the hot spots for links
crossing cabinet boundaries. Second, when we compare lane
degrade hot spots with the hot spots of link inactive errors
(Fig. 4 vs. Fig. 5), we ﬁnd that
they do not necessarily
match. This also explains why their high intensity periods do
not match (Fig. 2). This indicates that it is not possible to
determine the location of link inactive/failed errors by only
observing the time and location of lane degrade events.
Next, we investigate other interconnect errors: Bad Send
EOP error, Send Packet Length error, Routing Table Corrup-
tion error, and HSN ASIC LCB lane reinit failed error.
Bad Send EOP error: Each packet in Gemini Interconnect
has a single phit end-of-packet that contains the last phit of a
packet, and the status bits for error handling [1]. If a packet
is corrupted, the end-of-packet is marked as bad and will be
discarded at its destination.
Send Packet Length error: Send Packet Length error
occurs when the length of a packet does not match with the
expected length value at destination.
Routing Table Corruption error: A routing table is a data
table stored in a router that contains the information necessary
to forward a packet along the best path toward its destination.
When a packet is received, a network device examines the
packet and matches it to the routing table entry providing the
match for its destination. The table then helps in guiding the
packet to the next hop on its route across the network. A
routing table corruption results in link failure and eventually
causes network congestion.
HSN ASIC LCB lanes reinit failed error: This error
occurs when all the 256 attempts to bring up a downgraded
lane are exhausted.
All these errors also show hot spots in and across cabinets,
although we found that
the magnitude of these errors is
relatively small. For example, Routing Table Corruption error
occurs only 200 times while HSN ASIC LCB lane(s) reinit
failed error happens only 187 times throughout the entire ob-
servation period. On deeper investigation, we found that most
of these errors are highly correlated with link inactive/failed
errors. Table II shows the correlation of these interconnect
errors with link inactive errors. This indicates that link inactive
errors can be used to predict other interconnect errors. We also
found that more than 80% of link failed errors lead to Bad
Send EOP, Send Packet Length, and Routing Table Corruption
errors. We also found that HSN ASIC LCB lane(s) reinit failed
error has a weak correlation with link failed errors. This can
be explained by our previous ﬁndings where it showed that
lane degrades and link failed errors are not correlated and
ASIC errors are an outcome of failed repair attempts of lane
degrades.
IV. ANALYSIS OF NETWORK CONGESTION
Understanding network congestion in conjunction with in-
terconnect errors is important since it is likely that one may
cause the other. A daemon on the compute cluster monitors
the percentage of time that network tiles are stalled due to
increased trafﬁc or other reasons. When these values cross a
05101520Cabinets Rows01234567Cabinets Columns.7488
.,-309/897-:94341,30/07,/00;0398.4:39400008000012000016000020000024000005101520Cabinets Rows01234567Cabinets Columns.7488
.,-309/897-:9434133,.9;0077478.4:3950100150200250300350TABLE II: Correlation factor between link inactive and other
interconnect errors.
Errors
Link Inactive
Bad Send EOP Error
Send Packet Length Error
Routing Table Corruption Error
ASIC Error
0.99
0.96
0.84
0.04
0
2
t
n
u
o
C
0
1
Throttle events                     
 filter one hour
%
6
%
4
n
o
i
t
c
a
r
F
%
2
Throttle events                     
 filter one hour
0
2014-01
2014-07
Time
2015-01
%
0
2014-01
2014-07
Time
2015-01
Fig. 7: Network throttle events with 1-hour ﬁltering (left), and
relative frequency of throttle events with 1-hour ﬁlter (right).
Throttle events                     
100%
0.00033
80%
n
o
i
t
c
a
r
F
60%
40%
60%
50%
40%
n
o
21.924
i
t
c
a
r
F
30%
20%
Throttle events                    
%
6
1
%
8
n
o
i
t
c
a
r
F
t
n
u
o
C
0
0
2
1
0
0
6
0
2014−01
2014−07
Time
2015−01
%
0
2014−01
2014−07
Time
2015−01
Fig. 6: Count of network throttle events over time (left), and
relative frequency of throttle events over time (right).
set threshold, the daemon communicates this data to the xtnlrd
daemon running on the SMW. After the congestion subsides,
the daemon again passes this information to the SMW.
In this section, we ﬁrst attempt to understand the character-
istics of network throttle events. Fig. 6 (left) plots the network
throttle events over time. We note that a large fraction of
throttle events occur in a short period of time. We also note
that each throttle event is typically 20-30 seconds, but it can
also last up to a few minutes depending on the magnitude of
the congestion observed. As shown in Fig. 6 (right), network
throttle events can be quite bursty. An application that is caus-
ing network congestion can induce multiple throttles in a very
short amount of time (< 20 mins). Fig. 7 shows the network
throttle events over time, counting only one event at maximum
per hour. We experimented with multiple time windows and
found that a 1-hour time window removes the skewness.
However, this type of time window ﬁltering cannot completely
remove the skewness since a long-running communication-
intensive application may cause multiple throttle events over
multiple hours. For example, Fig. 8 shows that without 1-
hour ﬁltering the mean time between throttle events is less
then 1 minute, with 90% of the events occurring within the
ﬁrst hour of the preceding throttle event. Even when we
apply 1-hour ﬁltering, the meantime between throttle events
is approximately 22 hours. Therefore, to better understand
the characteristics of network throttle events we analyze our
subsequent results without any time window based ﬁltering
and with 1-hour time window based ﬁltering.
the
that
Naturally, one may hypothesize
lane de-
grades/failures may induce the network throttle events or vice
versa. Therefore, we investigate the possibility of temporal cor-
relation between the time series of throttle events and intercon-
nect errors, in particular lane degrades and link failed events.
We found the Spearman correlation coefﬁcient to be very weak
(0.03). This result indicates that lane degrades/failures alone
cannot be used to predict throttling events.
Next, we plot the heatmap of compute blades that were
throttled due to these network throttle events. Fig. 9 shows
5
20%
0%
0
28
MTB throttle events in hours
14
21
7
10%
0%
0
28
MTB throttle events in hours
14
21
7
Fig. 8: Mean time between network throttling events without
ﬁlter (left) and with 1-hr ﬁlter (right).
Cabinet distribution of blades throttled events count
l
s
n
m
u
o
C
s
t
e
n
b
a
C
i
7
6
5
4
3
2
1
0
1800
1700
1600
1500
1400
1300
1200
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
Cabinets Rows
Fig. 9: Spatial distribution of throttled blades without ﬁlter.
the heatmap without any ﬁltering and Fig. 10 shows the
same heatmap with 1-hour ﬁltering. As expected, we observe
that not all blades are throttled equally over the period of
observation. Interestingly, hot spots remain similar even after
applying ﬁlter. We again conduct the K-S test to test whether
our sample of the spatial distribution of blades throttle events
per cabinet without and with one hour ﬁlter has a uniform
distribution. The test results show D-statistic = 1, p-value =
2.2e-16 in both cases. For our sample size of 200 cabinets,
the critical D-value for a 0.05 level of signiﬁcance is 0.0960,
and therefore the null hypothesis (i.e., the sample is taken
from a uniform distribution) can be rejected. This shows that
the spatial distribution of blade throttled events per cabinet
is signiﬁcantly different
than uniform. As a next step in
our analysis, we want to investigate the role that congestion
information at the node and application levels can play in
improving our understanding of congestion behavior at the
 Cabinet distribution of blades throttled events count − filter one hour
s
n
m
u
o
C
s
t
l
i
e
n
b
a
C
7
6
5
4
3
2
1
0
1700
1600
1500
1400
1300
1200
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
Cabinets Rows
Fig. 10: Spatial distribution of throttled blades with 1-hr ﬁlter.
Cabinet distribution of top 10 congested nodes count
s
n
m
u
o
C
s
t
l
i
e
n
b
a
C
7
6
5
4
3
2
1
0
6000
5000
4000
3000
2000
1000
0
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
Cabinets Rows
Fig. 11: Spatial distribution of congested nodes without ﬁlter.
Note that the top 10 congested nodes are calculated for each
throttle event. This plot is aggregated over all throttle events.
Cabinet distribution of top 10 congested nodes count − filter one hour
100%
90%
80%
F
D
C
70%
60%
0
Number of unique applications
100
200
100%
80%
F
D
C
60%
40%
0
Number of unique applications
40
80
Fig. 13: Distribution of unique applications over congested
node events without ﬁlter (left), and with 1-hr ﬁlter (right).
A 54.48%
F 7.88%
B 5.91%
G 5.42%
H 2.96%
A 27.34%
s
n
m
u
o
C
s
t
l
i
e
n
b
a
C
7
6
5
4
3
2
1
0
12
10
8
6
4
2
0
B 6.67%
C 5.03%
D   2 . 1 5 %
5 %
E   2 . 0
Others 29.63%
Others 50.49%
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
Cabinets Rows
Fig. 12: Spatial distribution of congested nodes with 1-hr ﬁlter.
blade-level.
Node-level congestion data provides information about the
nodes which are heavily congested at the time of throttling.
Fig. 11 and 12 show the spatial distribution of congested nodes
in the Titan supercomputer for the no ﬁlter and 1-hour ﬁlter
cases, respectively. We make two observations. First, some
nodes are much more congested than others as shown by
the uneven distribution of congested nodes. This is because
the applications creating signiﬁcant network trafﬁc may be