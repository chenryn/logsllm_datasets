SELECT type, count(*) count  
FROM events  
WHERE repo.name = 'duckdb/duckdb'  
GROUP BY type  
ORDER BY count DESC;  
```  
type	|count  
---|---  
PullRequestEvent	|35  
IssueCommentEvent	|30  
WatchEvent	|29  
PushEvent	|15  
PullRequestReviewEvent	|14  
IssuesEvent |	9  
PullRequestReviewCommentEvent	|7  
ForkEvent	|3  
这是很多拉取请求活动！请注意，这并不意味着当天打开了 35 个拉取请求，拉取请求中的活动也被计算在内。如果我们搜索那天的拉取请求，我们会发现只有 15 个。这比平时要多，因为大多数 DuckDB 开发人员都在忙于修复 0.7.0 版本的错误。  
现在，让我们看看谁最活跃：  
```  
SELECT actor.login, count(*) count  
FROM events  
WHERE repo.name = 'duckdb/duckdb'  
  AND type = 'PullRequestEvent'  
GROUP BY actor.login  
ORDER BY count desc  
LIMIT 5;  
```  
login	|count  
---|---  
Mytherin	|19  
Mause	|4  
carlopi	|3  
Tmonster	|2  
lnkuiper	|2  
不出所料，Mark（Mytherin，DuckDB Labs 联合创始人）最活跃！我的活动（lnkuiper，DuckDB Labs 的软件工程师）也出现了。  
## 处理不一致的 JSON 模式  
到目前为止，我们已经忽略了`"payload"`事件的发生。我们忽略了它，因为该字段的内容因事件类型而异。我们可以看到它们与以下查询有何不同：  
```  
SELECT json_group_structure(payload) structure  
FROM (SELECT *  
  FROM read_json(  
    'gharchive_gz/*.json.gz',  
    columns={  
      id: 'BIGINT',  
      type: 'VARCHAR',  
      actor: 'STRUCT(id UBIGINT,  
                     login VARCHAR,  
                     display_login VARCHAR,  
                     gravatar_id VARCHAR,  
                     url VARCHAR,  
                     avatar_url VARCHAR)',  
      repo: 'STRUCT(id UBIGINT, name VARCHAR, url VARCHAR)',  
      payload: 'JSON',  
      public: 'BOOLEAN',  
      created_at: 'TIMESTAMP',  
      org: 'STRUCT(id UBIGINT, login VARCHAR, gravatar_id VARCHAR, url VARCHAR, avatar_url VARCHAR)'  
    },  
    lines='true'  
  )  
  WHERE type = 'WatchEvent'  
  LIMIT 2048  
);  
```  
|structure|  
|---|  
|`{“action”:”VARCHAR”}`|  
对于 `"payload"` 类型的事件，该字段很简单`WatchEvent`。但是，如果我们将类型更改为`PullRequestEvent`，则在使用 JSON 格式化程序进行格式化时，我们会得到超过 500 行的 JSON 结构。我们不想查看所有这些字段，所以我们不能使用我们的自动架构检测，它会尝试获取所有字段。相反，我们可以手动提供我们感兴趣的字段的结构。DuckDB 将跳过读取其他字段。另一种方法是将该`"payload"`字段存储为 DuckDB 的 JSON 数据类型，并在查询时对其进行解析（请参阅本文后面的示例！）。  
我已经将`"payload"`事件的JSON 结构剥离PullRequestEvent为我真正感兴趣的东西：  
```  
{  
   "action":"VARCHAR",  
   "number":"UBIGINT",  
   "pull_request":{  
      "url":"VARCHAR",  
      "id":"UBIGINT",  
      "title":"VARCHAR",  
      "user":{  
         "login":"VARCHAR",  
         "id":"UBIGINT",  
      },  
      "body":"VARCHAR",  
      "created_at":"TIMESTAMP",  
      "updated_at":"TIMESTAMP",  
      "assignee":{  
         "login":"VARCHAR",  
         "id":"UBIGINT",  
      },  
      "assignees":[  
         {  
            "login":"VARCHAR",  
            "id":"UBIGINT",  
         }  
      ],  
  }  
}  
```  
这在技术上不是有效的 JSON，因为有尾随逗号。但是，我们尝试在 DuckDB 中尽可能允许尾随逗号，包括 JSON！  
我们现在可以将其插入到`columns`的参数中`read_json`，但我们需要先将其转换为 DuckDB 类型。我很懒，所以我更愿意让 DuckDB 为我做这件事：  
```  
SELECT typeof(json_transform('{}', '{  
   "action":"VARCHAR",  
   "number":"UBIGINT",  
   "pull_request":{  
      "url":"VARCHAR",  
      "id":"UBIGINT",  
      "title":"VARCHAR",  
      "user":{  
         "login":"VARCHAR",  
         "id":"UBIGINT",  
      },  
      "body":"VARCHAR",  
      "created_at":"TIMESTAMP",  
      "updated_at":"TIMESTAMP",  
      "assignee":{  
         "login":"VARCHAR",  
         "id":"UBIGINT",  
      },  
      "assignees":[  
         {  
            "login":"VARCHAR",  
            "id":"UBIGINT",  
         }  
      ],  
  }  
}'));  
```  
这给了我们一个 DuckDB 类型，我们可以将该类型插入到我们的函数中！请注意，因为我们没有自动检测架构，所以我们必须提供`timestampformat`能够正确解析时间戳的信息。键`"user"`必须用引号括起来，因为它是 SQL 中的保留关键字：  
```  
CREATE TABLE pr_events as  
SELECT *  
FROM read_json(  
  'gharchive_gz/*.json.gz',  
  columns={  
    id: 'BIGINT',  
    type: 'VARCHAR',  
    actor: 'STRUCT(id UBIGINT,  
                   login VARCHAR,  
                   display_login VARCHAR,  
                   gravatar_id VARCHAR,  
                   url VARCHAR,  
                   avatar_url VARCHAR)',  
    repo: 'STRUCT(id UBIGINT, name VARCHAR, url VARCHAR)',  
    payload: 'STRUCT(  
                action VARCHAR,  
                number UBIGINT,  
                pull_request STRUCT(  
                  url VARCHAR,  
                  id UBIGINT,  
                  title VARCHAR,  
                  "user" STRUCT(  
                    login VARCHAR,  
                    id UBIGINT  
                  ),  
                  body VARCHAR,  
                  created_at TIMESTAMP,  
                  updated_at TIMESTAMP,  
                  assignee STRUCT(login VARCHAR, id UBIGINT),  
                  assignees STRUCT(login VARCHAR, id UBIGINT)[]  
                )  
              )',  
    public: 'BOOLEAN',  
    created_at: 'TIMESTAMP',  
    org: 'STRUCT(id UBIGINT, login VARCHAR, gravatar_id VARCHAR, url VARCHAR, avatar_url VARCHAR)'  
  },  
  json_format='records',  
  lines='true',  
  timestampformat='%Y-%m-%dT%H:%M:%SZ'  
)  
WHERE type = 'PullRequestEvent';  
```  
对于磁盘数据库（结果大小为 478MB），此查询在大约 36 秒内完成，而对于内存数据库，则在 9 秒内完成。如果您不关心保留插入顺序，您可以使用此设置加快查询速度：  
```  
SET preserve_insertion_order=false;  
```  
使用此设置，查询在磁盘上数据库大约 27 秒内完成，内存数据库在 8.5 秒内完成。磁盘上和内存中情况之间的区别在这里非常大，因为 DuckDB 必须压缩和保存更多数据。  
现在我们可以分析拉取请求事件了！让我们看看受让人的最大数量是多少：  
```  
SELECT max(length(payload.pull_request.assignees)) max_assignees  
FROM pr_events;  
```  
|max_assignees|  
|---|  
|10|  
这是很多人审查一个拉取请求！  
我们可以检查谁被分配得最多：  
```  
WITH assignees AS (  
  SELECT payload.pull_request.assignee.login assignee  
  FROM pr_events  
  UNION ALL  
  SELECT unnest(payload.pull_request.assignees).login assignee  
  FROM pr_events  
)  
SELECT assignee, count(*) count  
FROM assignees  
WHERE assignee NOT NULL  
GROUP BY assignee  
ORDER BY count DESC  
LIMIT 5;  
```  
assignee	|count  
---|---  
poad	|494  
vinayakkulkarni	|268  
tmtmtmtm	|198  
fisker	|98  
icemac	|84  
这是很多任务！尽管我怀疑这里有重复项。  
## 存储为 JSON 以在查询时解析  
指定字段的 JSON 模式`"payload"`很有帮助，因为它允许我们直接分析那里的内容，并且后续查询要快得多。尽管如此，如果模式很复杂，它也会非常麻烦。如果不想指定字段的架构，可以将类型设置为`'JSON'`：  
```  
CREATE TABLE pr_events AS  
SELECT *  
FROM read_json(  
  'gharchive_gz/*.json.gz',  
  columns={  
    id: 'BIGINT',  
    type: 'VARCHAR',  
    actor: 'STRUCT(id UBIGINT,  
                   login VARCHAR,  
                   display_login VARCHAR,  
                   gravatar_id VARCHAR,  
                   url VARCHAR,  
                   avatar_url VARCHAR)',  
    repo: 'STRUCT(id UBIGINT, name VARCHAR, url VARCHAR)',  
    payload: 'JSON',  
    public: 'BOOLEAN',  
    created_at: 'TIMESTAMP',  
    org: 'STRUCT(id UBIGINT, login VARCHAR, gravatar_id VARCHAR, url VARCHAR, avatar_url VARCHAR)'  
  },  
  json_format='records',  
  lines='true',  
  timestampformat='%Y-%m-%dT%H:%M:%SZ'  
)  
WHERE type = 'PullRequestEvent';  
```  
这会将字段加载`"payload"`为 JSON 字符串，我们可以在查询时使用 DuckDB 的 JSON 函数对其进行分析。例如：  
```  
SELECT DISTINCT payload->>'action' AS action, count(*) count  
FROM pr_events  
GROUP BY action  
ORDER BY count DESC;  
```  
箭头`->>`是我们函数的简写`json_extract_string`。将整个`"payload"`字段创建为具有类型的列JSON并不是仅获取`"action"`字段的最有效方法，但此示例只是为了展示`read_json`. 查询结果如下表：  
action	|count  
---|---  
opened	|189096  
closed	|174914  
reopened	|2080  
正如我们所见，只有少数拉取请求被重新打开。  
## 结论  
DuckDB 试图成为一个易于使用的工具，可以读取各种数据格式。在 0.7.0 版本中，我们添加了对读取 JSON 的支持。JSON 有多种格式和各种模式。Duckdb 对嵌套类型 ( `LIST`, `STRUCT`) 的丰富支持使其能够将 JSON 完全“切碎”为柱状格式，以进行更高效的分析。  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
#### [PolarDB 云原生分布式开源数据库](https://github.com/ApsaraDB "57258f76c37864c6e6d23383d05714ea")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、内核开发公开课、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")