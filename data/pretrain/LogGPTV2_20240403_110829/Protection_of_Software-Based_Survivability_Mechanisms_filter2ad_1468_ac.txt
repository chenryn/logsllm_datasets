### 6.1. NP-Hard Argument

**Theorem 1:** In the presence of general pointers, determining precise indirect branch target addresses is an NP-hard problem.

**Proof:**
Our proof involves a polynomial-time reduction from the 3-SAT problem to the problem of determining precise indirect branch targets. This approach is similar to the proof originally proposed by Myers, who demonstrated that various data-flow problems are NP-hard in the presence of aliases [12]. Landi later provided a similar proof to show that alias detection is NP-hard in the presence of general pointers [16]. The detailed reduction can be found in other extended documents [21, 22].

The NP-hardness proof establishes that statically determining branch target addresses is NP-hard in the presence of general pointers. This result applies to the set of general programs (with general pointers), which, at first glance, may not be the same as the set of programs produced by our transformations. We must further establish that the set of transformed programs does not represent a restricted class of programs and that the proof also applies. We approach this as follows:

Let \( A \) be the set of general programs and \( A' \) be the set of programs produced by our transformations. To show that \( A' \) is not a restricted subset of \( A \) (with respect to the NP-hard proof), it suffices to show:
1. There is a polynomial-time mapping for every instance \( a \) in \( A \) to a functionally equivalent instance in \( A' \).
2. If there is a polynomial-time algorithm to resolve indirect branch targets for any instance in \( A' \), then this algorithm can be used to resolve indirect branch targets for instances of \( A \).

**Establishing a Polynomial-Time Mapping:**
A polynomial-time mapping from instances of \( A \) to instances of \( A' \) is straightforward; this mapping consists of exactly the code transformations we described in Sections 4 and 5.

Because the transformations introduced in Sections 4 and 5 are semantics-preserving, an algorithm that resolves indirect branch targets for an instance in \( A' \) will, by definition, resolve indirect branch targets for its functionally equivalent instance in \( A \). Intuitively, if all the indirect branching targets for an instance in \( A' \) are resolved to direct jumps, it is a polynomial-time task to restore the original control-constructs (from the flattened if-else-goto constructs) and therefore deduce the branch targets for the original program in \( A \).

The reduction from 3-SAT does not make use of any program characteristics other than multiple levels of pointer dereferencing and conditional branches. The transformations described in Sections 4 and 5 preserve the presence of conditional branches and arbitrary levels of pointers and pointer dereferencing. From an intuitive standpoint, this suggests that the reduction from 3-SAT also stands for the transformed program.

### 6.2. Complexity Evaluation for Approximation Analysis Methods

While the NP-hard result bodes well for the alias-based code transformations, we still need to evaluate our approach against possible heuristics and approximation methods. In this section, we explore the effect of two analysis methods: brute-force search and alias approximations.

**Brute-Force Search Method:**
To determine the execution order of the code blocks that appear in the degenerate form of the program, an adversary might employ a brute-force search method in which all combinations of the code block ordering are explored. This is a naive exhaustive search heuristic in which each block is considered equally likely to be the immediate successor of the current block (including the current block itself). The time complexity of such a brute-force method is \( O(n^k) \), where \( n \) is the number of distinct program blocks and \( k \) is the number of blocks that will be executed. Clearly, this represents the worst-case time complexity and is extremely inefficient when the values of \( n \) and \( k \) are sufficiently large.

**Alias-Detection Approximation Methods:**
The problem of precise alias detection in the presence of general pointers and recursive data structures is undecidable [11, 16]. In practice, however, approximation algorithms are often used [11]. An alias analysis algorithm may analyze aliases intra-procedurally as well as across procedural boundaries.

Intra-procedural alias analysis requires as input the alias set holding at the entry node of the procedure, the alias set propagated back from any procedure called within the current procedure, and the alias processing functions (transfer functions) of each pointer assignment statement. Well-known data-flow frameworks [11, 17] exist for handling intra-procedural alias analysis. They are divided into flow-sensitive and flow-insensitive methods. Flow-sensitive methods make use of control-flow path information and are more precise than flow-insensitive methods. The transformations described in Sections 4 and 5 produce a degenerate form of static control flow. As a result, flow-sensitive analysis conducted on this form of control flow loses the precision advantage it has over flow-insensitive methods. Figure 7 illustrates such an example.

The CFG in Figure 7 shows that the assignment \( q = &c \) overwrites the alias relation \( \{ p, q \} \), and \( p = &b \) overwrites \( \{ p, r \} \). The degenerate control flow in Figure 7(b) essentially represents the set of all possible paths with these blocks. Even a flow-sensitive analysis algorithm at best must conclude with the alias set \( \{ p, q, r \} \). Horwitz [14] presented a definition of precise flow-insensitive alias analysis. Under this definition, the flow-sensitive analysis result obtained from the CFG in Figure 7(b) is exactly the same result as a precise flow-insensitive algorithm would have concluded with the CFG in Figure 7(a). We thus conjecture that, with the degenerate form of control flow, a flow-sensitive analysis can be no more precise than its flow-insensitive counterpart.

The transformations presented in this paper are intra-procedural transforms in the sense that they do not affect a control-flow analysis on the procedural level. However, an inter-procedural alias analysis is inherently based on the result of intra-procedural alias analysis, and therefore, its precision suffers similarly. A step beyond the current scheme is to generalize the transformations to produce degenerate ICFGs, which will further degrade analysis results. A detailed discussion on this topic, as well as an in-depth study of the complexity of existing alias analysis frameworks, can be found in [21].

### 7. Implementation and Performance Results

We implemented the transformations in a source translator for ANSI C in the SUIF programming environment [1]. In our implementation, we developed compiler passes for the code transformations. Each pass traverses the SUIF representation and performs the desired modifications. The exact transformations are determined by a random seed: that is, the resulting program is different for each compilation. For example, the layout of the global array, the exact percentage of the control-transfers that are transformed, and the number of dead blocks that are added are all determined by a random number generated from the seed.

We tested performance results obtained with experimental transformations on the SPEC95 benchmark programs. The key measures here are three: run-time performance of the transformed program, performance of static analysis, and precision of static analysis.

**Run-Time Performance of the Transformed Programs:**
By run-time performance, we mean the execution time and the executable object size after transformation. These measures reflect the cost of the transformation.

**Performance of Static Analysis:**
By performance of static analysis, we mean the time taken for the analysis tool to reach closure and terminate. A related but equally important criterion is the precision of static analysis, which indicates how accurate the analysis result is compared to the true alias relationships.

### 7.1. Performance of the Transformed Program

The following data was obtained by applying our transforms to SPEC95 benchmark programs. Three SPEC programs were used in this experiment: Compress95, Go, and LI. Go is a branch-intensive implementation of the Chinese board game GO. Compress95 implements a tightly-looping compression algorithm, and LI is a typical input-output bound program for a LISP interpreter. These programs are standard benchmarks used in the compiler community. They embody three major classes of high-level language constructs that are widely used in general programming. It would be more satisfying, however, to test our results on the class of networking programs for which this solution was intended. But in the absence of that, we believe that these test programs are good representatives of real-world programs.

We conducted experiments on both optimized (with the gcc -O option) and non-optimized versions of the programs. The experiments were executed on a SPARC server. The experimental results show that, in both cases, the performance slowdown increases exponentially with the percentage of transformed branches in the program. On average, the performance speedup due to optimization is significantly reduced when a more substantial portion of the program is obfuscated.

This is an encouraging result; it is highly suggestive (albeit not conclusive) that our transformations considerably hindered the optimization that the compiler is able to perform.

**Figure 8: Execution Time (Non-Optimized)**
**Figure 9: Execution Time (Optimized)**
**Figure 10: Executable Size (Non-Optimized)**

The performance of Go and LI were similar for both optimized and non-optimized code. Of the three original programs, compiler optimization performed best on Compressâ€”a whopping 80% decrease in the execution time due to optimization. However, as can be seen in Figure 9, our transforms removed significant optimization potential from Compress; the execution speed of the transformed and optimized Compress diverges most significantly from the performance of the original optimized program. As Compress is a loop-intensive program, it is likely that certain analyses that enabled significant loop or loop kernel optimization were no longer possible after our transform was performed.

The object size of the three benchmarks grew with the percentage of transformed branches, indicating that the transformations increased the size of the executable.