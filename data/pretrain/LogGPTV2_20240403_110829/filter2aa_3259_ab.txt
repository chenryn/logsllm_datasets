. 存储组件
. 安全 Agent
其中，kube-system/kube-proxy 是 Kubernetes 的默认设计，他的 ServiceAccount ⼀般不做修改，利⽤价值
有限。
3. 提权
node_to_clusteradmin-如何从Kubernetes节点权限提升⾄集群管理员权限.md
5/23/2022
5 / 8
最终我们发现其中⼀个 DaemonSet: 安全 Agent，其配置⽂件⾥给 ServiceAccount 设置了 RBAC 权限，绑定
了⼀个权限较⼤的 Cluster role，并且可以 list 和 get secret 信息。虽然，其他 DaemonSet 的
ServiceAccount 也设置了不同 RBAC 权限，但当我们拥有了 kube-system 命名空间下的 Secret 权限时，我
们就等同拥有了 K8s Cluster Admin 的权限。也由于我们本次的靶标在集群内，所以最终我们达成了⽬标。
（画外⾳：这个 DaemonSet 还配置了很多重复且杂七杂⼋的 Capability，安全 Agent 配置特定的 Capability
来提升权限并不少⻅，但研发者可能并不能很好的把握每个 Capability 的作⽤，有些甚⾄配置了特权容器以
求⽅便。由于 DaemonSet 的配置⼀般不会经由 PodSecurityPolicy 或 K8s Admission Webhook 所限制，权
限过⼤和权限滥⽤的情况还是⽐较多的，建议集群管理员也注意此处的权限收敛。
这⾥红队朋友们可以使⽤⼀条简单的命令来测试当前的服务器上的所有容器的 ServiceAccount 是否拥有列举
Secret 的权限，⽐较好的⽅式是使⽤ kubectl auth can-i 来检测，但节点和POD上⼀般不安装 kubectl，所以
我更倾向⽤ curl 进⾏简单测试。
docker ps | grep -v "/pause" | awk -F" " '{print $1}' | grep -v CONTAINER 
| while read line; do echo $line; docker exec -t $line sh -c 'curl -k 
"https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT/api/v1/namespac
es/kube-system/pods?limit=2" -H "Authorization: Bearer `cat 
/var/run/secrets/kubernetes.io/serviceaccount/token`"'; done; 
当然，这个⽅法并不优雅；熟悉我的同学知道我还维护了⼀个容器安全⼯具 📦  CDK，集成了很多容器和
Kubernetes安全测试的特性；有⼀个功能“检测节点上 ServiceAccount 可⽤于提权的权限”⼀直躺在我的
TODO ⾥，但⼀直没得空去实现出来，欢迎PR，或者催我更新😭
除了列举和查看 secret 的权限，还有很多集群内的⽬标和权限与 Cluster Admin 等价，我之前画了⼀张图可
以作为参考：
node_to_clusteradmin-如何从Kubernetes节点权限提升⾄集群管理员权限.md
5/23/2022
6 / 8
锅不能全给集群管理员
看到这⾥，⼤家可能会认为这⾥问题主要是集群管理员的错误配置导致的。其实不然，很多集群在从云⼚商
购买下来的时候就已经内置了⼀些 DaemonSet，⽤来增强集群和节点上的能⼒，提升运维和⽹络通讯的效
率；这⾥不乏错误配置的情况，AKS(微软), EKS(AWS), GKE(Google), OpenShift 此前都有这样的问题，轻则
可以控制POD，重则可以提权⾄ Cluster Admin 权限；同时像 Antrea, Calico, Cilium, WeaveNet 这些应⽤⼴
泛的 CNI 插件也存在可以提权⾄ Cluster Admin 权限的问题；不过现在都修的差不多了，这块 Palo Alto
Networks 的研究员们梳理的最好，⼤家可以看他的结果。
这块也是我去年的意难平呀，可惜当时没钱也没时间搞，其实是⼀个很不错的 bugbounty IDEA。国内的平台
估计也会有同样的问题，不过国内的漏洞赏⾦计划对集群内的权限提升问题并不关注，所以给到的奖励会很
有限，我就不⼀⼀去测了；如果那家的师傅觉得可以给到不错的赏⾦可以和我说⼀下，我来试试看能不能找
到可以提权的点。
本⽂提到的我历史的PPT可以在 https://github.com/neargle/my-re0-k8s-security/tree/main/slide 查看，我把
Palo Alto Networks PPT 也附在⽂末了，⼤家可以参考。第三⽅的PPT我就不放 Github了，有点侵权。
除了 CNI 插件和安全组件，⽇志组件的 DaemonSet 默认配置也经常配置过⼤的权限和挂载过⼤的⽬录，如
很多⼈使⽤ filebeat 配置：
apiVersion: apps/v1
kind: DaemonSet
node_to_clusteradmin-如何从Kubernetes节点权限提升⾄集群管理员权限.md
5/23/2022
7 / 8
metadata: 
  name: filebeat-logsystem 
  namespace: kube-system 
  labels: 
    k8s-app: filebeat
spec: 
  template: 
    metadata: 
      labels: 
        k8s-app: filebeat 
    spec: 
      serviceAccountName: filebeat 
      terminationGracePeriodSeconds: 30 
      hostNetwork: true 
      dnsPolicy: ClusterFirstWithHostNet 
      containers: 
      - name: filebeat 
        image: docker.elastic.co/beats/filebeat:%VERSION% 
        args: [ 
          "-c", "/etc/filebeat.yml", 
          "-e", 
        ] 
        env: 
        - name: ELASTICSEARCH_HOST 
          value: elasticsearch 
        - name: ELASTICSEARCH_PORT 
          value: "9200" 
        - name: ELASTICSEARCH_USERNAME 
          value: elastic 
        - name: ELASTICSEARCH_PASSWORD 
          value: changeme 
        - name: ELASTIC_CLOUD_ID 
          value: 
        - name: ELASTIC_CLOUD_AUTH 
          value: 
        - name: NODE_NAME 
          valueFrom: 
            fieldRef: 
              fieldPath: spec.nodeName 
        securityContext: 
          runAsUser: 0 
          # If using Red Hat OpenShift uncomment this: 
          privileged: true 
        resources: 
          limits: 
            memory: 200Mi 
          requests: 
            cpu: 100m 
            memory: 100Mi 
        volumeMounts: 
        - name: logpath 
          mountPath: /hostfs/ 
      volumes: 
      - name: logpath 
node_to_clusteradmin-如何从Kubernetes节点权限提升⾄集群管理员权限.md
5/23/2022
8 / 8
        hostPath: 
          path: /
归根结底，还是最⼩权限原则的问题。⽼⽣常谈了，但在 Kubernetes 的实践⾥却⼜有很多新的东⻄需要安全
从业者们去把握。这⾥还是有挺多有趣的点的，希望还有机会和⼤家聊聊。