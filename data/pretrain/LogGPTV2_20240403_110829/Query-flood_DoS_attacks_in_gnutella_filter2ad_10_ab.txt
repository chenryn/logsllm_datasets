and how many queries to accept from remote peers when
the total number of queries sent to it exceeds cj. (If the
total number of queries sent to it does not exceed cj, the
supernode simply processes all the queries sent to it.)
More formally, if |Gj(t − 1)| ≤ ρcj, then Pj(t) ←
Gj(t−1). Otherwise, we select ρcj queries from Gj(t−1).
Queries that are not selected from Gj(t − 1) for process-
ing at time t can be queued for future time steps (or
even discarded). The remaining capacity, cj − |Pj(t)| is
183now allocated among the queries arriving from remote
peers. We will refer to ρcj as node j’s local query band-
width (LQB), and (1 − ρ)cj as node j’s remote query
bandwidth (RQB).
There are several combinations of policies that we
shall consider for allocating the RQB amongst queries
arriving from remote peers. There are two questions
that these policies answer:
1) how many queries should be accepted from each
remote peer?, and
2) if there are more queries arriving from a remote
peer than we decide to accept, which ones should we
accept?
The policy used to answer the ﬁrst question is the in-
coming allocation strategy, and the policy used to answer
the second question is the drop strategy.
3.2 Incoming Allocation Strategy
There are two key incoming allocation strategies (IASs)
that we cover in this paper: Weighted and Fractional.
We describe how each of these strategies select which ad-
jacent nodes to process queries from in this section. In
our descriptions, queries are represented as two-tuples
q = (o, t) where o is the node at which the query origi-
nated 1, and t is the query’s current TTL. We refer to
the components of the tuple using a dot notation such
that q.o refers to the origin node (at which the query
was ﬁrst generated) and q.t refers to the TTL. Many
distinct queries can have the same origin and TTL, and
we will refer to η distinct queries with the same origin
and TTL as ηq.
We will describe options for IASs and illustrate them
using examples. In our examples, assume a graph with
three nodes V = {1, 2, 3} and E = {(1, 2), (1, 3)}. Also,
for each of the nodes j, cj = 100, 1 ≤ j ≤ 3, and
each node has ρ = 0.2.
In each of the examples, we
present how node 1 decides how many and which queries
to accept from nodes 2 and 3.
Weighted IAS. Weighted IAS is intended to model a
“naive” Gnutella node in which the likelihood that a
query from a particular incoming link will be accepted
is proportional to the number of queries arriving on that
link.
We assume that queries arriving at node j from remote
peers are equally likely to be accepted. Thus, the more
queries a neighbor sends, the more will get accepted.
If a total of less than (1−ρ)cj queries are sent by remote
peers, then all queries that are sent are accepted for
processing. If more than (1 − ρ)cj queries are sent by
remote peers, then the number of queries accepted from
each remote peer is weighted by the fraction of the total
queries sent. If a node has κ remote peers that send it
α1, α2, ...ακ queries, it will accept up to
(1 − ρ)cj
Σ∀iαi
queries2 from the λth remote peer, 1 ≤ λ ≤ κ.
αλ
1Current Gnutella networks do not stamp queries with
the nodes at which they originated, but this feature
could be added to support load balancing.
2To keep our explanation of policies conceptually clear,
we will not add ﬂoors and ceilings to quantities. In our
For instance, let |O2,1(t−1)| = 100 and |O3,1(t−1)| = 20
with (1 − ρ)c1=80 and the LQB fully utilized. The
Weighted IAS divides the RQB such that |I2,1(t)| =
100
120 (1−0.2)100 = 67 and |I3,1(t)| = 20
120 (1−0.2)100 = 13.
Fractional IAS. Fractional IAS is geared at giving each
of a node’s incoming links an equal fraction of query
bandwidth. If a node has κ remote peers, a Fractional
IAS allocates up to 1/κ of its query bandwidth for han-
dling the queries from each of its remote peers. Any
extra query bandwidth that is unused by a remote peer
is allocated to remote peers. Also, if the LQB is not
completely utilized by local peers, any leftover LQB is
allocated to servicing queries from remote peers.
For example, let |O2,1(t − 1)| = 100 and |O3,1(t − 1)| =
20, and node 1’s RQB is 80, as before. Assume also,
If
as before, that the LQB is completely utilized.
node 1 uses a Fractional IAS, (1−ρ)c1
=40
queries are allocated to each remote peer, but the extra
20 queries per unit time that are not used by node 3 are
allocated to node 2. As a result, |I2,1(t)| = 40 + (40 −
|O3,1(t − 1)|) = 40 + 20 = 60 and |I3,1(t)| = 20.
Other policies.
There exist many other possible IAS
policies (i.e., least queries ﬁrst, preferred neighbors ﬁrst,
etc.). For the remainder of this paper, we only consider
Fractional and Weighted IASs. However, other IASs
may warrant examination in future study.
= (1−0.2)100
2
2
3.3 Drop Strategy (DS)
This section describes drop strategies (DSs). When
the IAS used for node j determines that no more than
m queries may be accepted from a remote peer i, and i
sends |Oi,j(t − 1)| = m + ∆ queries (where ∆ > 0), node
j uses a DS to determine speciﬁcally which ∆ queries to
drop. In our examples below, node j receives Oi,j(t −
1) = {2q1, 2q2, 6q3} where q1 = (a, 5), q2 = (a, 4), and
q3 = (b, 4).
The Proportional and Equal strategies described be-
low make decisions about which queries to drop by con-
sidering the nodes at which the queries in Oi,j(t − 1)
originated as well as their TTL.
Proportional. Let node j receive Oi,j(t − 1) = { η1q1,
η2q2, ... ηnqn}. If j uses a Proportional DS, it will accept
up to
queries of type qχ, 1 ≤ χ ≤ n.
ηχ
Σn
χ=1ηχ
In our example, if m = 5, then Proportional DS chooses
Ii,j(t) = {q1, q2, 3q3}.
Equal. The Equal DS chooses queries uniformly based
on the origin of the query. If queries arrive at j from β
diﬀerent sources (not necessarily neighboring nodes), the
Equal DS will attempt to choose m
β queries from each
source. If some sources sent fewer than m
β queries, then
the extra query bandwidth will be shared equally across
queries from sources that sent more than m
For instance,
Ii,j(t) = {q1, q2, q3}.
if m = 3, then the Equal DS chooses
β queries.
simulations, ﬂoors are taken for most calculated quan-
tites, and policies are run in multiple “rounds” to ensure
that all available query bandwidth is used up.
184PreferHighTTL / PreferLowTTL. These strategies are
used to drop either those queries with the lowest or high-
est TTLs, regardless of the nodes at which they origi-
nated.
If m = 1, PreferLowTTL gives either {q2} or {q3}. (Ties
are broken arbitrarily.) Alternatively, for m = 1, Prefer-
HighTTL gives {q1}.
4. METRICS
To evaluate whether or not (and how well or how
badly) the policies above may help us manage queries
distributed by malicious nodes, we deﬁne a work metric,
the concept of a service guarantee, and a damage metric
that allow us to quantitatively determine the service loss
a malicious node may be able to inﬂict on a network. In
addition, we will describe how we model “good” nodes
(that use our policies) and how we model “malicious”
nodes (that attempt to ﬂood the network, possibly ig-
noring reasonable policies).
4.1 Work
Our deﬁnitons for work broadly measure the number
of queries processed by one or more nodes in the net-
work. More speciﬁcally, for a particular node j, Wj(t)
is the work or cumulative number of queries processed
at node j from time 0 to time t. Furthermore, we dis-
tinguish local work from remote work. The local work,
Lj(t) is the cumulative number of queries that node j
receives from its local peers and processes from time 0 to
time t. Similarly, remote work, Rj(t) is the cumulative
number of queries that node j receives and processes
from its remote peers from time 0 to time t. Of course,
Wj(t) = Lj(t) + Rj(t).
To understand how local and remote work changes
with ρ, let us consider what happens if we start with
ρ = 0 and slowly increase it.
If ρ = 0 for all nodes, then each of the nodes allo-
cates all of its query bandwidth to queries arriving from
remote peers. Unfortunately, nodes send out ρcj = 0
queries during each time step. While each node is “all
ears,” no node is sending out any work. As a result, the
total local work and total remote work are both 0.
As ρ increases, more and more queries are accepted
from local peers, and more and more queries will be
processed by the network. Both the local and remote
work will increase. However, at some point, each node
will be processing the maximum number of queries pos-
sible (as speciﬁed by its capacity, cj). After this point,
if ρ increases any further, nodes will have to start drop-
ping remote queries, and the amount of remote work
will start decreasing. However, since we make the as-
sumption that local peers always generate ρcj queries,
the amount of local work will continue increasing as ρ
increases.
Once ρ = 1, then each of the nodes allocates all of its
query bandwidth to queries arriving from local peers,
and do not service any queries from each other. The
total local work will be maximum and the total remote
work will be 0.
While the query bandwidth of each of the nodes may
be fully utilized when ρ = 1, users do not receive the
beneﬁt of having their queries processed at other nodes.
To maximize the number of queries processed at remote
nodes, we can set ρ to maximize the remote work.
In
the following section, we show how to set ρ to do this.
4.2 “Good” nodes
In our model, “good” nodes have two important char-
acteristics. Firstly, we make the simplifying assumption
that the processing capacity cj is the same for all nodes
in the graph. In particular, ∀jV, cj = C, where C is
some constant. Secondly, good nodes are compelled to
ﬁnd a setting for ρ that maximizes the remote work 3.
Definition 4.1. Optimal Rho, ˆρ. Let ˆρ be the setting
for ρ that maximizes ΣjV Rj(t).
We may analytically solve for ˆρ for simple network
topologies, as we will demonstrate shortly, and we may
approximate or experimentally determine ˆρ for more
complex topologies.
Also, it is the case that for certain topologies the opti-
mal value for ρ may be diﬀerent for diﬀerent nodes in the
network. However, for simplicity, we will assume that we
would like to have a common setting for ρ for all nodes.
We will have to sacriﬁce some remote work to have a
common ρ, but doing so will simplify the implementa-
tion of our load balancing policies in a real network.
Consider the network topology K3 = ( V = {1, 2, 3},
E = {(1, 2),(1, 3),(2, 3)}) in which we have a network of
three nodes with three edges completely connecting the
nodes, cj = 100, 1 ≤ j ≤ 3, and τ = 1. For K3, the
reader can verify that the setting at which ρ maximizes
the remote work is 1
3 . (At this setting, the amount of
new work generated and sent to any given node is exactly
equal to the amount of work that it can accept.)
While the appropriate setting for ρ might be obvious
in our small example, it is important for good nodes in
our network to be able to compute or approximate ˆρ for
arbitrary networks. We provide a formula for computing
ˆρ for “symmetric” networks (such as complete, cycle, or
hypercube networks) below, following some elementary
deﬁnitions.
Definition 4.2. Distance, d(j, k). Let d(j, k) be the
length of the shortest path between nodes j and k. Note
that d(j, j) = 0.
Definition 4.3. Radial Node Set, δ(j, h). Let δ(j, h)
= { v | d(j, v) = h }. That is, δ(j, h) is the set of nodes v
such that the shortest distance between j and v is exactly
h.
= (cid:83)h
Definition 4.4. Arial Node Set, D(j, h). Let D(j, h)
i=1 δ(j, i). That is, D(j, h) is the set of nodes v such
that the distance between j and v is greater than or equal
to 1 but less than or equal to h. Note that j /∈ D(j, h).
Informally, D(j, h) is the set of nodes that are within h
hops of j, not including j itself.
3Alternatively, we can maximize the total work, but
maximizing the remote work has the beneﬁt that it gives
us the smallest possible setting for ρ for which the total
work is maximized and the minimum number of remote
queries are dropped. A more detailed discussion appears
in [23].
185Theorem 4.1. Optimal Rho (ˆρ) for Symmetric Net-
works. Suppose that for all nodes j ∈ V have cj = C for
some constant C > 0, |D(j, τ )| = D for some constant
D > 0, and all nodes have ρ set to the same value, then
ˆρ = 1/(D + 1).
We provide the proof of this theorem in Appendix A.
For more complex networks, such as those studied in
our evaluations in Section 5, we experimentally deter-
mined ˆρ. In future work, we plan to study how to calcu-
late good approximations for ˆρ for arbitrary networks.
In summary, good nodes in our model set cj = C,
and ρ = ˆρ to maximize the remote work done by the
network.
4.3 Malicious Nodes
We are interested in studying ﬂooding-based attacks,
and we model a malicious node such that it generates
as many queries as it is capable of. However, there exist
many other behaviors that a malicious node may engage
in to cause harm to other nodes in the network. While
there are many such options available to the adversary,
we focus speciﬁcally on query ﬂoods in this paper.
To construct a query ﬂood attack, a malicious node
dedicates all of its processing capacity to generating
“useless” queries. Malicious nodes may be able to gen-
erate more than C queries. However, since a good node
knows that other good nodes can send at most C queries,
it only examines the ﬁrst C queries from each incoming
link during a given time step, and ignores the rest. While
a malicious node can generate more than C queries,
the eﬀect will be the same as if it generates exactly C
queries. Hence, we set cm = C, where m is a malicious
node.
After generating queries in a given time step, a mali-
cious node has no processing capacity left over. In addi-
tion, it does not have any incentive to process or forward
queries that are sent to it by remote peers. To model a
ﬂood generated by a malicious node, we have the mali-
cious node set ρ to 1, whereas good nodes typically set
ρ to a signiﬁcantly lower value.
4.4 Service
A key metric that we can use to understand the eﬀects
of a malicious node in the network will be “service.” The
service, Si,j(t), is the number of queries that originate at
node i and are processed at node j at time t. The service
Si,j(t) tells node i how many of its queries are processed
by node j at time t. For example, if node 2 processes 5
of node 1’s queries at time t = 3, then S1,2(3) = 5.
We now more formally deﬁne the notion of service,
and two variations of it, radial and arial service, that we
use in our evaluations.
Definition 4.5. Service, Si,j(t). Let
Si,j(t) = σq.o=i((cid:91)vV
Iv,j(t))
Note that we use σ to be selection over multi-sets, as
deﬁned in bag-relational algebra.
Definition 4.6. Radial Service, Rj(h, t). Let Rj(h, t) =
Σvδ(j,h)Sj,v(t). Rj(h, t) denotes the total service that
node j receives from all of the nodes whose shortest dis-
tance from j is exactly h. (Informally, Rj(h, t) is the