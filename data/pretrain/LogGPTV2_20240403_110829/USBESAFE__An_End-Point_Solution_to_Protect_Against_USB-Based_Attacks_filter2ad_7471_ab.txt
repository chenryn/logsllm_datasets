which contains all Traces in the dataset. For each trace in the
TraceLibrary, we sort existing traces into TraceLists which
contain all the traces with the same (busID, deviceID) tuple.
USBESAFE uses the class codes ﬁeld in the device and in-
terface descriptors to determine the device type and expected
functionality. While USBESAFE has an extensible design,
we focus speciﬁcally on USB HIDs including USB keyboard
trafﬁc and the features that characterize such trafﬁc as benign.
This focus stems from our goal which is to determine whether
a covert HID conﬁguration is present and active on a device.
3.1.2 Protection Engine
The protection engine is central to the security model pro-
posed in USBESAFE which decides whether a new, previ-
ously unseen set of USB packets is potentially malicious. In
the following, we explain the features we employed to char-
acterize the USB packets, and train the detection model in
USBESAFE.
Packet Interarrival Times Packet interarrival times char-
acterize the USB keyboard trafﬁc across a bus and, specif-
ically, the timing information of packets. The timing infor-
mation can help reveal user’s typing patterns by serving as a
proxy for inter-keystroke times, or how the bus manages the
URBs of different kinds. Interarrival time values are measured
in milliseconds, between one packet and the next for all the
TraceEvents. Note that a user may enter a keystroke after a
longer pause, ranging from a few seconds to hours. To tackle
the problem of potentially unbounded interarrival time values
in these situations, we explicitly deﬁne an upper bound for
the interarrival time value between two interrupt packets. We
explain this procedure and the selection of speciﬁc threshold
values in more details in Section 5.
Event Type USBESAFE monitors the value that deﬁnes
the type of each USB packet. More precisely, a URB event
type can take two values which indicate whether there is an
onging transaction (URB_SUBMIT (0×53)) or if a transaction
is complete (URB_COMPLETE (0× 43)).
Transfer Type USBESAFE also monitors the value of
URB transfer type between the host and the USB de-
vice. The transfer type can take four possible values
which are URB_INTERRUPT, URB_CONTROL, URB_BULK, and
URB_ISOCHRONOUS. This value is selected for a USB device
according to the requirements of the device and the software
which is determined in the endpoint descriptor.
Post-enumeration Time USBESAFE monitors when the
post-enumeration activity starts. For example, in a normal
scenario, a user connects a USB keyboard to the host, and
starts interacting with it. Along with other features, looking
at millions of URBs allows USBESAFE to observe the nor-
mal start of post-enumeration activity of a HID device after
attaching the device to the host. The system incorporates this
feature as a numerical value by calculating the time period
between a successful enumeration and the start of data packet
transfer.
Packet Payload USBESAFE monitors the payload of indi-
vidual USB packets. USBESAFE examines the payload to
determining patterns in data by using a byte histogram to
measure value frequencies within each TraceEvent. The his-
togram represents a space of 256 values ([0,255]) by bucketiz-
ing values into 16 equal intervals or bins. For each TraceEvent,
the system generates a feature vector which contains in-
terarrival_time, event_type, transfer_type, post_enumeration,
data_histogram. The feature vector is then used to construct a
detection model which will be used as an augmented service
in the operating system.
To analyze the URB payloads, we extracted all the n-grams
of EventTraces that appeared in a sliding window of the length
n where the value of n varied from 2 to 4. Each unique se-
quence of length n is added to the detection model for the
USB HID class. The intuition here is that those n-grams are
characteristics of benign USB packets, and any trafﬁc that
does not follow similar patterns compared to the extracted
model for a given user is a novel observation, and with high
likelihood correspond to a new typing pattern. In Section 5.3,
we provide more details on our model searching process since
we should take into account several conﬁguration parame-
ters to achieve the highest detection rate and the lowest false
positive rate.
92          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Association4
Implementation
In this section, we provide more details on the implementation
of USBESAFE’s prototype which relies on the Linux USB
stack. The implementation of USBESAFE consists of three
independent modules which were discussed in Section 3.1: (1)
a USB event monitor which interposes the bus transactions, (2)
a protection module which constructs the feature vector and
validates whether the incoming USB packets comply with
the generated model, and (3) a notiﬁcation module which
produces an alert and notiﬁes the user if a novel trafﬁc pattern
is detected. In the following, we provide more details on the
implementation details of each module.
4.1 USB Event Monitor
We used the usbmon Linux kernel module, as a general USB
layer monitor, to capture all the URBs transmitted across the
monitored USB bus. In user space, USBESAFE implements
the transaction ﬂow introspection module by extracting device
information using sysfs, lsusb and device activities using
usbmon and tcpdump. Monitoring the USB devices starts at
the boot time. USBESAFE collects self-reported device infor-
mation as well as actions taken by associated drivers during
the normal usage. The USB event monitor module is a user
space program which is developed in Python. This module is
loaded prior to the device’s enumeration phase by updating
the udev database. We deﬁned a set of datastructure to collect
interface information (e.g., Descriptor Type, Interface Num-
ber, Interface Class and protocol), conﬁguration information
(e.g., max power), and device information (e.g., manufacturer)
for each connected device.
4.2 Protection Engine
As mentioned earlier in Section 3.1, the protection engine
in USBESAFE is responsible for determining whether a set
of USB packets from a connected device to the host are, in
fact, new observations and whether the USB device should
be disabled or not. In cases where the USBESAFE identi-
ﬁes a set of USB packets as new observations, it notiﬁes the
user as well as kernel space components to block the corre-
sponding interface. As the protection engine is the core part
of the USBESAFE, we want to make sure that the model is
constructed based on a suitable algorithm. To this end, we
evaluated multiple machine learning algorithms by measuring
their detection accuracy on the labeled dataset. In Section 5,
we provide more details on the detection accuracy of the al-
gorithms as well as the parameter conﬁgurations. The results
of our analyses revealed that one-class SVM [14] achieved
the highest detection rate with a very low false positive rate.
In our detection model, the one-class SVM can be viewed
as a regular two-class SVM where all the training data is be-
nign and lies in the ﬁrst class, and the unseen data by a large
margin from the hyperplane is taken as the second class. In
fact, the constructed model in USBESAFE solves an optimiza-
tion problem to ﬁnd a term with maximal geometric margin.
Therefore, if the geometric margin is less than zero, the test
sample is reported as a novel observation. As USBESAFE
has a high privilege, it automatically unbinds the offending
USB port by calling /sys/bus/usb/drivers/usb/unbind
without involving the user.
4.3 Notiﬁcation Module
The notiﬁcation module is deployed as a user space dae-
mon which produces alerts whenever the protection mod-
ule identiﬁes a novel observation. We should mention that
there are several design choices for implementing the notiﬁ-
cation module. However, the core requirement of the module
is that the notiﬁcation should be always stacked on top of the
screen contents, and cannot be obscured, interrupted, or inter-
fered with by other processes. We achieve this by leveraging
libnotify-bin module which is usually used to send desk-
top notiﬁcations to users. To prevent the notiﬁcation module
from being killed programmatically by a potentially mali-
cious process with the same user ID, we recommend creating
another user ID to run the process. Consequently, only root
could kill the process. As the notiﬁcation module is not the
core part of our contributions, we do not explore the notiﬁca-
tion module further in this paper.
5 Evaluation
To test USBESAFE we conducted two experiments. In the
ﬁrst experiment, we train and test USBESAFE with a labeled
dataset, and in the second experiment, we test the derived
model on a previously unseen dataset to evaluate the detection
capability of the system in a real-world deployment. Although
our design is sufﬁciently general to be applied to different
operating systems, we built our prototype for Ubuntu 14.04
LTS with the Linux kernel 3.19. In the following, we ﬁrst
describe how we created our dataset, and then provide the
details of evaluation and benchmarks.
5.1 Data Collection
In order to create the training dataset, we monitored USB
packet exchanged between a set of devices and ﬁve machines.
Each time a USB device was connected, USBESAFE gener-
ated a new trace, named it based on the bus and device ID of
the USB device, and created logs for real-time USB packets
across the monitored USB bus. On the system shutdown, the
module saved the generated trace ﬁle to the disk. We sorted
each TraceEvent based on USB device class code which was
extracted from the interface descriptor. The HID class, which
keyboards, mouses, headsets, and game joysticks fall under, is
deﬁned by the class code 3. During 14 months of data collec-
tion, several types of USB devices such as different keyboards,
storage devices, cameras, and headsets were connected to the
machines. We considered a connected USB device as a HID
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 93URBs
No. of Traces
5.1.1 Preprocessing the Dataset
Machine
Machine1
Machine2
Machine3
Machine4
Machine5
3,385,445
2,394,345
2,884,345
943,984
1,620,265
124
90
101
50
58
423
Total
11,228,384
Table 1: The collected USB Packets over 14 months. We collected
423 HID trace ﬁles which contained more than 11 million USB Pack-
ets. The trace ﬁles were collected from several types of keyboards,
mouses, headsets. The dataset also includes traces of other USB
devices such as cameras, storage devices which are not HID devices,
but registered themselves as a HID device in addition to their main
driver.
device, if it requested HID driver from the operating system.
For example, we found a benign USB printer that registered
itself both as a printer and a HID device to enable the touch-
screen. Although standard USB printers are not considered as
a HID device, we considered the corresponding traces in the
training phase as the device potentially had the capability to
run commands.
In total, 423 trace ﬁles were collected from HID devices,
consisting of 11,228,384 URBs. Note that the actual number
of USB packets that crossed the bus was greater than this value
as any usbmon-based packet actually represented two or three
USB packets on the bus, depending on whether the interaction
included a payload or not. Table 1 illustrates a summary of the
data collected over 14 months from ﬁve different machines.
Note that our approach is not an outlier detection method,
but a novelty detection technique. This means that we need
to have a clean training dataset representing the population
of regular observations for building a model and detecting
anomalies in new observations. Therefore, the malicious data
used in our experiments was solely collected for testing pur-
poses. To generate this malicious dataset, we used a Rubber
Ducky USB drive [2], updated the ﬁrmware, and generated
a set of scripts that establish covert channels, inject code for
data exﬁltration, and connect to a remote server. Such attacks
have several forms, and an adversary has signiﬁcant freedom
to generate such attacks. For example, it is quite feasible to
write a malicious script that checks an active session and ver-
iﬁes whether a user is logged in or not before launching an
attack. In Section B, we provide some case studies, and show
how USBESAFE identiﬁes these attacks as a set of novel
observations.
For our experiments, we created eight realistic attack sce-
narios. In each experiment, we connected the device to the
measurement machine and made sure the attack executed
while logging the USB packets from the device enumeration
to device termination. The malicious dataset contains 202,394
USB packets, which was signiﬁcantly smaller than the benign
dataset, reﬂecting the expected low base rate of BadUSB-style
attacks.
Over the course of the data collection, we found several un-
predicted situations during the device enumeration phase. For
example, a subset of USB keyboards used in our experiments
were not reported as the USB class code 3, but were instead
reported as the USB class code 0. Though this occurred, each
observed instance of these event sequences yielded a success-
fully enumerated device, and the host accepted the keyboard
input immediately after receiving the device descriptor. For
this reason, we worked around the issue during class bucke-
tization in the feature extraction phase, moving all the class
code 0 trafﬁc into the class code 3 bucket.
Another issue we had to account for in processing the trace
ﬁles was to determine what action to take when encounter-
ing malformed packets. In some instances, when the host
requested a device descriptor, the device would respond with
a malformed descriptor packet, forcing the host to make the
request again. For the purposes of prototype evaluation, we
chose to ignore these request/response pairs when they oc-
curred.
5.2 Model Selection
One of the ﬁrst questions that arises is which machine learning
algorithm achieves the highest detection results if it is trained
with the labeled dataset. To this end, we used ﬁve different
algorithms that are known to model anomaly detection prob-
lems. We also considered the local and global features of the
anomaly detection approaches in order to determine whether
the novelty score of an incoming URB should be determined
with respect to the entire training data or solely based on a
subset of previous URBs. To run the experiment, we used
one-class SVM as a classiﬁer-based approach [14], k-NN as a
global Nearest-neighbor [13], and Local Outlier Factor (LOF)
as a local Nearest-neighbor-based approach [13]. We also in-
corporated Cluster-based Local Outlier Factor (CBLOF) [12]
as a global Clustering-based approach and Local Density
Cluster-based Outlier Factor (LDCOF) [12] as a local Clus-
tering-based approach.
To identify the best detection algorithm, we performed an
analysis on the 423 traces we collected from ﬁve machines
(see Section 5.1). More speciﬁcally, we split the USB traces
of each machine to a training and a testing set using 4-fold
cross-validation, and averaged the value of the detection rate
and false positive rate for each algorithm. As shown in Table
2, the analyses reveal that LDCOF and LOF, which use local
data points, produce lower false positive cases. However, the
empirical evidence suggests that the one-class SVM achieves
the best detection results among the selected algorithms on
the same dataset. Based on our analysis, one likely reason
is that the one-class SVM classiﬁer maps the USB trafﬁc
to a high dimensional feature space more accurately. This
results in producing less false positive cases by identifying
the maximal margin hyperplane that best separates the new
94          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX AssociationMetric
OCSVM