381.06
381.57
20.85
20.90
25.88
25.96
23.46
23.56
(MB)
27.01
27.07
34.57
34.65
22.59
22.64
23.24
23.32
57.82
57.94
286.97
288.03
221.09
211.71
201.40
200.03
23.16
23.23
23.64
23.75
68.91
68.51
28.37
28.44
25.76
25.84
39.59
39.60
26.07
26.19
48.18
47.64
24.64
24.77
22.93
22.98
43.97
43.65
22.42
22.54
23.07
23.15
54.49
54.36
212.91
212.58
208.15
208.66
20.68
20.72
25.36
25.42
23.20
23.28
TABLE I.
PERFORMANCE EVALUATION OF KLEE WITH CPT
(AVERAGE OVER 3 TRIALS)
maxMem
avgMem
2,073.72
2,073.82
25.79
25.99
25.23
25.40
1,496.51
1,497.35
25.46
25.59
24.89
25.01
execute a suite of target programs. Following what had been
previously investigated in the original KLEE paper [14], we
use the GNU coreutils package1 for our evaluation, which
consists of various basic tools like cat and ls used on many
Unix-like operating systems. Over the years, coreutils itself
has been tested extensively, so we do not intend to ﬁnd new
bugs or achieve a higher code coverage in our experiments.
We follow the experiment setup [1] used in the KLEE paper
[14] to run 2 different versions of KLEE on coreutils version
6.11 [2], that is, the original version of KLEE, and the one
with CPT v2.0. For each version, we repeat the execution on
each coreutil program 3 times and report the average values
of runtime and memory measurements. The experiments were
conducted on a machine powered by an Intel Core i7-6700
3.40GHz CPU and with 32GB RAM. Table I shows our
1https://www.gnu.org/software/coreutils/coreutils.html
4
measurements on the ﬁrst 30 programs in coreutils.
To obtain measurement numbers in each experiment, we
use the klee-stat tool provided by KLEE toolchain. For
memory usage, we report both the peak (maxMem) and average
consumption (avgMem), averaged over the 3 executions. Since
some of the target programs need an enormous amount of
time to ﬁnish, following previous work [1], [14], we halt an
execution after 1 hour, which explains why some programs
in Table I have a total runtime of about 3600 seconds (e.g.,
base64, cat, and chcon). In such cases, the mere total
execution time is insufﬁcient in showing the time overhead.
Hence we also report the average number of completed paths
during the 3 executions, which can be used to compare the
runtime efﬁciency of the different versions of KLEE.
To make the number of completed paths comparable, and
since we are not focused on code coverage, we also changed
the search heuristic used by KLEE into a depth-ﬁrst search
(DFS), instead of a random search as prescribed by the recipe
[1], to avoid non-determinism. We also increased the maximum
memory usage for each execution to 16GB from the prescribed
1GB [1]. However, as can be seen in Table I, none of the tested
programs approached close to this limit.
All in all, the two versions of KLEE yielded comparable
total runtime (or, paths completed) and memory usages. CPT
v2.0 in general consumes a little more memory and is slightly
slower than the original KLEE, though the overheads are in-
signiﬁcant. In the rest of the paper, unless explicitly mentioned,
we will be using KLEE with CPT v2.0 by default.
IV. A CASE STUDY ON PKCS#1 V1.5 RSA SIGNATURE
VERIFICATION
We center our analysis around the problem of PKCS#1
v1.5 signature veriﬁcation. This is particularly suitable for
showcasing the merit of enhancing symbolic execution with
meta-level searching, as it features diverse glue components
including explicitly terminated padding with implicit length, as
well as a sophisticated ASN.1 structure. Despite the PKCS#1
family has newer algorithms like RSA-PSS [RFC8017], the
v1.5 signature scheme continues to be widely-used in Web
PKI and other security-critical network protocols like SSH
[RFC4253] and IKEv2 [RFC7296] for authentication purposes.
A. Technical Background
In this section, we provide a brief overview of RSA
signature veriﬁcation while using PKCS#1 v1.5 as the padding
scheme. For the ease of exposition, we provide a list of the
notations we use and their meaning in Table II.
Following the usual RSA notations, we use d, e, and n
to denote the RSA private exponent, public exponent, and
modulus, respectively. (cid:104)n, e(cid:105) constitutes an RSA public key.
We use |n| to denote the size of the modulus in bits. Suppose m
is the message for which an RSA signature is to be generated.
In the context of X.509 certiﬁcates (and CRLs), m would be
the ASN.1 DER-encoded byte sequence of tbsCertificate
(and tbsCertList) [RFC5280].
Benign signature generation. For generating an RSA sig-
nature of message m in accordance to PKCS#1 v1.5, the
signer ﬁrst computes the hash of m, denoted H(m), based
TABLE II.
NOTATION USED
Description
RSA modulus
RSA Private Exponent
message to be signed
Symbol
Description
e
|n|
mv
RSA Public Exponent
length of modulus in bits
message received by veriﬁer
formatted input to the signer’s RSA operation
Signature, S ≡ I d mod n in benign cases
veriﬁer’s RSA output, O ≡ Se mod n
signer’s version of H(m), contained inside O
veriﬁer’s computed hash of mv
veriﬁer’s construction of I given H(mv)
Description
Block Type
Symbol
PB
Description
Padding Bytes
ASN.1 Structure, containing H(ms)
ASN.1 Length of AS.DigestInfo
ASN.1 Length of algorithm OID
ASN.1 Length of AlgorithmIdentifier
ASN.1 Length of parameters
ASN.1 Length of Digest
Symbol
n
d
m
I
S
O
H(ms)
H(mv)
Iv
Symbol
BT
AS
w
u
x
y
z
on the hash algorithm of choice (e.g., SHA-1). Then, H(m)
and the corresponding meta-data identifying the used hash
algorithm and other relevant parameters (if any) are packed
into an ASN.1 DER-encoded structure. The necessary amount
of padding and other meta-data are prepended to the ASN.1
structure to create a structured input I of size |n|, which is
then used as an input to the signer’s RSA operation. The exact
format of I is discussed below. Then, the signature will be
S = I d mod n.
Signature veriﬁcation. Upon receiving a signed object (say an
X.509 certiﬁcate), the veriﬁer parses S from it and computes
O := Se mod n, where O represents the output of the
veriﬁer’s RSA operation, formatted just like I in correct cases.
Given mv (say tbsCertificate of a received certiﬁcate),
the veriﬁer then computes H(mv) and compare it against the
H(ms) contained in O. Like previous work has discussed [27],
this comparison could be done in the following two manners.
Construction-based veriﬁcation. Using this approach, the
veriﬁer takes H(mv) and prepares Iv, similar to how the signer
is expected to prepare I prior to signing. If Iv ≡ O then the
signature is accepted.
Parsing-based veriﬁcation. Many implementations seem to
prefer a parsing-based approach, and this is where things can
potentially go wrong. In essence, the goal of this approach
is to parse H(ms) out of O. Many parsers are, however, too
lenient even when O is malformed, which gives room for the
so-called Bleichenbacher low-exponent brute-force attack.
Structured input (I) and output (O) format. In the benign
case, I and O should be formatted as follows:
0x00 || BT || PB || 0x00 || AS
BT is often referred to as the block type [RFC2313],
and PB represents the padding bytes. For
the purpose
of signature generation and veriﬁcation, BT ≡ 0x01 and
PB ≡ 0xFF 0xFF . . . 0xFF. Additionally, PB has to be at
least 8-byte long, and also long enough such that there would
be no extra bytes following AS. The 0x00 after PB signiﬁes
the end of padding. AS is an ASN.1 DER-encoded byte stream
that looks like this (assuming H() being SHA-1):
/** all numbers below are hexadecimals **/
/* [AS.DigestInfo] */
30 w
// ASN.1 SEQUENCE, length = w
/* [AlgorithmIdentifier] */
30 x
// ASN.1 SEQUENCE, length = x
5
06 u 2B 0E 03 02 1A
05 y
// ASN.1 OID, length = u
// ASN.1 NULL parameter, length = y
/* [Digest] */
04 z
// ASN.1 OCTET STRING, length = z
/* H(m), H()=SHA-1(), m = "hello world" */
2A AE 6C 35 C9 4F CF B4 15 DB
E9 5F 40 8B 9C E9 1E E8 46 ED
Since DER encoded ASN.1 structures are essentially a tree
of {Tag, Length ,Value} triplets, the length of a parent triplet
is deﬁned by the summation of the length of its child triplets.
Assuming SHA-1, we can derive the following semantic re-
lations among the different length variables for benign cases:
u = 5; z = 20; x = 2 + u + 2 + y; w = 2 + x + 2 + z.
For most common hash algorithms like MD5, SHA-1, and
the SHA-2 family, the algorithm parameter has to be NULL
and y ≡ 0 [RFC2437, RFC4055]. Historically there were
confusions on whether the NULL algorithm parameter can be
omitted, but now both explicit NULL and absent parameters are
considered to be legal and equivalent [RFC4055]. This could
be a reason why some prefer parsing-based over construction-
based, as in the latter approach the veriﬁer would have to
try at least two different constructions {Iv1, Iv2} to avoid
falsely rejecting valid signatures. We focus on the explicit NULL
parameter case in this paper, as it had been shown that the
lenient processing of the parameter bytes can lead to signature
forgery [27], and rejecting absent parameter is a compatibility
issue easily identiﬁable with one concrete test case.
When PKCS#1 v1.5 signatures are used in other protocols
like SSH and IKEv2 not involving X.509 certiﬁcates, the afore-
mentioned steps work similarly with a different input message
m (e.g., m could be the transcript containing parameters that
were exchanged during a key exchange algorithm).
B. Testing Deployed Implementations with Our Approach
We now discuss the different challenges and engineering
details of how to make the implementations amenable to
symbolic analysis. As discussed before, we use KLEE with
CPT as our choice of symbolic analysis tool. Building an
implementation for KLEE generally takes a few hours of trial-
and-error to tune its build system into properly using LLVM.
1) Scalability Challenges: Since the length of O is given
by |n|, for the best coverage and completeness, ideally one
would test the veriﬁcation code with a |n|
8 -byte long symbolic
buffer mimicking O. For implementations that use the parsing-
based veriﬁcation approach, however, since there are possibly
many parsing loops and decisions depend on values of the
input buffer, using one big symbolic buffer is not scalable.
To workaround scalability challenges, we use a two-stage
solution. We ﬁrst draw on domain knowledge to decompose
the original problem into several smaller subproblems, each of
which symbolic analysis can then efﬁciently and exhaustively
search. Then for each subproblem we apply the meta-level
search technique to automatically generate concolic test cases.
Stage 1. Coarse-grained decomposition of input space.
In the ﬁrst stage, we partition the input space inﬂuencing the
exploration of the PKCS#1 v1.5 implementations in a coarse-
grained fashion. Our coarse-grained partitioning resulted in
three partitions, each corresponds to a dedicated test harness.
For each implementation, the 3 test harnesses focus on testing
various aspects of signature veriﬁcation while avoiding scal-
ability challenges. Across different implementations, each of
the 3 test harnesses—denoted {TH1, TH2, TH3}—is focused
on the same high-level aspect of testing. The test harnesses
would invoke the implementations’ PKCS#1 v1.5 signature
veriﬁcation functions,
like a normal application does.
Depending on the API design of a speciﬁc implementation,
the test harnesses also provide the appropriate veriﬁcation
parameters like an RSA public key, H(mv) (or in some cases,
mv directly) and a placeholder signature value.
just
Among the different harnesses, TH1 is designed to in-
vestigate the checking of BT, PB, z the length of H(ms),
and the algorithm parameters, while TH2 is geared towards
the matching of OID in AlgorithmIdentifier. Both
TH1 and TH2 use a varying length of PB but the ASN.1
length variables u, w, x, y, z are kept concrete. In contrast,
TH3 has everything else concrete, reminiscent of a correct
well-formed O, but u, w, x, y, z are made symbolic, to see
how different length variables are being handled and whether
an implementation would be tricked by absurd length values.
In general, loops depending on unbounded symbolic variables
poses threats to termination, however, as we would discuss
below, in the context of PKCS#1 v1.5 signatures, one can
assume all the length variables are bounded by some linear
functions of |n| and still achieve meaningful testing.
|n|
8
Stage 2. Meta-level search using relations between glue
components. Following the meta-level search idea discussed in