and potentially unsafe way.
3.2.4 Call Procedure By Name Some IRPLs have the capability of
resolving at runtime and programmatically the names of the rou-
tines to be called (“late binding”). For example,a developer may
use a construct like CallByName(fun_name) in order to call a func-
tion, where fun_name is a string variable containing the function
to be called. If this variable originates from an untrusted source and
there is no input validation, the program is vulnerable: An attacker
may subvert the control flow of the program, with varying effects
according to the semantics of the loaded module(s).
Example. We found an instance of this programming pattern in
an ABB RAPID program we found online (Listing 3 presents a
simplified version). This program implements a server with multi-
ple functionalities; to select the functionality to be called, instead
of using a chain of if constructs, the name of the functionality
is received from the socket and then passed as a parameter to a
“late binding” construct. An attacker can exploit this instance of
vulnerability to call any other function in the same task program.
3.3 Malicious Patterns
Enumerating all potential abuses of primitives for malicious pat-
terns is an endless game and only limited by the creativity of the
malware author, and it is intrinsically harder to compile an exhaus-
tive list of malicious behaviors. In Table 4, we limit our focus to
two examples of classic behaviors commonly found in modern mal-
ware, first to confirm that they can be implemented in IRPLs, and
secondly to show how they appear in terms of code patterns.
The information stealer pattern is particularly relevant in in-
dustrial settings because both the configuration parameters and
the programs residing on the robot controller are considered high
valuable intellectual property, and therefore attractive assets for
attackerss. A malicious IRPL making use of the information stealer
patter will, for example, exfilitrate confidential information from
! ... variable declaration
! ... socket creation and initialization
WHILE TRUE DO
SocketReceive clientsock, \Str:=data;
name := ParseName(data)
Open diskhome + "/" + name + ".mod", f;
WHILE data DO
SocketReceive clientsock, \Str:=rec;
Write f, rec;
ENDWHILE
Load \Dynamic, diskhome \File:=name + ".mod";
%name + ":main"%; ! call function by name
ENDWHILE
ENDPROC
ENDMODULE
Listing 4: Example of dropper malware. (RAPID)
local files through an outbound connection. Note that our attack
model assumes that the attacker has not straight read-access to
the file system, but rather infects an existing task program with an
information-stealing malicious routine like in the case of a mali-
cious, or compromised system integrator.
In the dropper case, the attacker is able to download and execute
any second-stage malware like we capture in Listing 4. Contrary
to previous research on PLC malware [10, 16, 17], we purposely
decided not to focus on the functionalities of the downloaded mal-
ware (e.g., network target enumeration, file harvesting), but rather
representing this as a generic pattern.
4 A Source Code Static Analyzer for IRPLs
To quantify and analyze the extent of unsafe programming patterns
in task programs, we conceived and implemented a prototype static
source code analyzer for IRPLs. On one hand, we used our tool
to perform an analysis of publicly available IRPL code and show
which, and to what extent, unsafe and vulnerable patterns are found.
As described thoroughly in section 5, none of the programs that
we analyzed implemented proper input sanitization. On the other
hand, we propose the use of static analysis to verify task programs
before upload on robots, in order to anticipate the security (and
safety) impact of the use of such programs in production.
Our proposed tool processes task programs and uses taint anal-
ysis to detect data flowing from one or more sensitive sources
(e.g., data from the network) to one or more sensitive sinks (e.g. move-
ment, file open, late binding). The analyzer is modular with respect
to the supported IRPLs, and the searched code patterns are config-
urable by means of queries on the data flow. Our proof-of-concept
implementation supports ABB’s RAPID and KUKA’s KRL.
Table 4: Examples of malicious patterns.
Case
Feature
Information stealer Exfiltration
Exfiltration
Harvesting
Download
Execute
Dropper
6
Source Sink
File → Outbound Network
Config → Outbound Network
Dir. list → File
Communication → File (code)
File (code) → Call by name
Detecting Insecure Code Patterns in Industrial Robot Programs
ASIA CCS ’20, October 5–9, 2020, Taipei, Taiwan
Figure 2: High-level workflow of the proposed source code analyzer.
Taint analysis techniques have been successfully applied to find-
ing vulnerabilities in general-purpose programming languages,
such as C and web development languages, but, to the best of our
knowledge, there are no security-oriented applications to IRPLs. We
show that taint analysis is efficient in detecting vulnerable uses of
untrustworthy data and malicious patterns as outlined in Section 3,
as they all can be expressed by means of source–sink paths.
4.1 System Overview and Workflow
Figure 2 shows a high-level workflow of our analyzer, which con-
sists of the following steps: parsing, control-flow graph (CFG) gen-
eration, interprocedural control-flow graph (ICFG) generation, and
data-flow analysis.
We start by parsing a task program’s source code, and walking
through the parse tree to generate the CFG of each function. We
then produce an ICFG with the goal of representing the control
flow between functions. We do this by linking the functions’ CFG
at function call statements. Finally, we perform a data-flow analysis
on the constructed ICFG to detect potentially sensitive data flows
from sources to sinks.
The final output of our analyzer consists of the list of sensitive
data flows (source–sink pairs), along with some context useful to the
analyst, including, for example, code lines information and relevant
function names. An example is given in Listing 5, in which our tool
detected a vulnerable pattern from the code of eki_hw_iface_get
to the code of kuka_eki_hw_interface. In particular, it found a
path from eki_getreal (i.e., parse a numerical value from incom-
ing network data) to joint_pos_tgt (i.e., move joint to position).
4.2 Implementation Details
We implemented our prototype analyzer in Python 3, using the
networkx8 library for graph-manipulation tasks.
Steps 1–2: Parsing and CFG Generation. We implement the
parser by using Antlr9 to generate both the lexical analyzer and the
LL(*) parser from a specification of the IRPL grammar. We devel-
oped the grammars from the information available in the reference
manuals of the robot languages, and by looking at existing pro-
grams. In general, writing the grammar for a new language is not
8https://networkx.github.io/
9https://www.antlr.org/
necessarily a hard task: As an example, the official language refer-
ence for ABB’s RAPID [1] includes portions of the EBNF grammar,
which we ported to Antlr.
Once an IRPL program is parsed, we visit its parse tree and build
the CFG in memory. Each node of the CFG (also known as basic
block, in program-analysis terminology) contains a list of instruc-
tions. These instructions are expressed in a language-independent,
simplified, intermediate representation10. We adopted a modular
approach to make our tool easily extensible to different robot lan-
guages. In particular, the only analyzer’s components that are IRPL-
specific are the grammar specification and the CFG generator, im-
plemented through Antlr’s visitor pattern.
Once the CFG is built, we run a set of (language-agnostic) simpli-
fication passes: For example, we add CFG edges at goto statements,
we enforce a single exit point (return) for the CFG of each function,
and we eliminate dead code blocks.
Step 3: ICFG Generation. The second step of our analysis con-
sists in generating the ICFG. To this extent, we visit the CFG of
each function, and substitute all those nodes with calls to func-
tions defined in the same module (i.e., functions where the CFG is
available) with two CFG edges:
10Our intermediate representation does not preserve the complete semantics of the
instructions, but only their data flow. This is all we need for taint analysis.
{
}
"sources": [
{
}
"src_var": "joint_pos_cmd",
"source": "eki_getreal",
"source_fn": "eki_hw_iface_get",
"source_line_no": 180,
"source_filename": "kuka_eki_hw_interface.src"
],
"sink_var": "joint_pos_tgt",
"sink": "ptp",
"sink_fn": "kuka_eki_hw_interface",
"sink_line_no": 73,
"sink_filename": "kuka_eki_hw_interface.src"
Listing 5: Output of the analysis of a task program that
implements externally controlled movements (Listing 1
shows an excerpt of that).
7
Task program’s source codeParsingCFG GenerationDataﬂow AnalysisRAPID parserKRL parser…-Unsafe patterns (leading to vulnerabilities)-Malicious patternsList of potential vulnerabilitiesList of potentially abused featuresMoveJ point0WaitTime 4MoveL point1       WaitTime 5...ICFG Generation1234ASIA CCS ’20, October 5–9, 2020, Taipei, Taiwan
M. Pogliani et al.
• an edge from the instruction immediately preceding the call
to the entry basic block of the callee’s CFG. To properly
model the data flow from the function calls’ actual parame-
ters to the function’s formal parameters, we add additional
assignment nodes along this edge.
• an edge from the exit basic block of the callee’s CFG to the
instruction following the call. We also add further nodes to
correctly propagate the returned value to the caller, as well
as to propagate the value of any output parameter declared
as such in the function prototype.
With this procedure, we build an “exploded super graph” of all the
functions in the program under analysis.
Step 4: Dataflow Analysis. We follow a forward-only dataflow
analysis for taint tracking, which propagates taint information
from the functions defined as sources (e.g., inbound network data)
towards all the basic blocks (nodes) in the program. Afterwards, we
check whether any input parameter of the functions defined as sink
(e.g., coordinate passed to robot-movement functions) was tainted,
and by which source. To do so, the analysis algorithm keeps track
of the set of “taints” (i.e., the set of sources that influenced the value
of the variable) for wach variable in every ICFG node.
To compute the result of our analysis, we use a work-list based
iterative algorithm. In its essence, the dataflow analysis is defined
by a carrier lattice, which represents the information computed for
each node of the ICFG, and a transfer function, which defines how
the information is propagated according to the semantics of each
instruction. Elements in the carrier lattice are the set of sources
that taint each variable. The transfer function forward-propagates
the taint information from the variables used by the instruction to
the variables defined by the instruction. For example, the transfer
function for a binary operation adds to the taint information of the
result the union of the taint information of its two operands.
Some function calls refer to functions whose implementation
is not present in the analyzed programs: They may be calls to
library functions or to functions defined in a file not available to
the analyzer. As the analyzer doesn’t have the function’s CFG,
we approximate the behavior of such functions assuming that the
function uses all the parameters to compute the return value, if
any. Hence, the default transfer function for function calls adds—to
the taint information of the return value—the union of the taint
information of all the parameters. However, many library functions
do not work this way: They may have output parameters, as well as
accepting parameters that do not influence the result in a security-
sensitive way. Ignoring this fact would lead to an imprecise analysis.
Hence, we model calls to library functions in a language-specific
fashion: For each supported language, and for each library function,
we specify which parameters are considered inputs and which
parameters are considered outputs for taint propagation purposes.
Finally, our transfer function supports the concept of sanitization,
that is an operation that removes the taint from a variable. This
reflects the behavior of functions that are used for input sanitization,
or that change the handled resource. For example, to track whether
some data is written (exfiltration) to a user-contorlled file, we can
consider the Close instruction as a sanitizer, as further uses of the
same (closed) file descriptor would necessarily refer to a different
file. Our tool supports a configuration-defined set of sanitizers.
4.3 Source and Sink Configuration
The searchable code patterns are configurable by means of source–
sink pairs, so that our tool is generic with respect to them. For our
evaluation, we used source–sink pairs that express the vulnerable
patterns described in Section 3.
KUKA’s KRL Configuration. As sources, we consider those func-
tions receiving data from network via the KUKA.Ethernet KRL
extension: functions starting with eki_get such as eki_getreal,
and functions belonging to the KUKA.Ethernet KRL XML package,
(e.g., EKX_GetIntegerElement). As sinks, we consider instruction
movements such as ptp, lin, and circ.
ABB’s RAPID Configuration. To detect vulnerable uses of sen-
sitive primitives, our sources are the parameters of the function
SocketReceive (i.e., Str and RawData). Our sinks include move-
ment, file- and configuration-handling functions and late bind-
ing: Move, Open, OpenDir, SaveCfgData, WriteCfgData, Load, and
CallByVar.
Malicious Behavior Detection. When detecting potentially ma-
licious behavior, it is possible to configure our tool to use sources
and sinks that reflect the patterns proposed in Table 4. For exam-
ple, to detect exfiltration in ABB’s RAPID, we monitor taints from
ReadRawBytes (and other device read functions) to SocketSend.
Since there is no universal definition of “malicious behavior,” this
list is not exhaustive and other patterns can be used.
5 Evaluation
Our analysis tool can detect both security-sensitive code patterns
that could lead to vulnerabilities in task programs as well as ma-
licious patterns that could lead to malware. First, using our tool
we were able to confirm the path-traversal vulnerability that the
authors of [18] found manually. Such vulnerability resulted in ABB
removing the vulnerable application from the online repository. We
found the very same vulnerability automatically, with no guidance.
We also discovered several instances of task programs that handled
unsanitized data received from sensitive sources, and used it to
control the movements of the robot. Notable examples of this case
are the various ROS-Industrial adapters, which consist of IRPL code
that interface the communication protocol of the major robot ven-
dors with that of ROS-Industrial. An attacker on the network could
exploit such vulnerability to influence the movements of a robot’s
arm. Secondly, we ran our analyzer against a proof-of-concept of
malware that we implemented, as described in Section 3.3. Our tool
detected the malicious code patterns, showing that it is helpful to
implement code-vetting systems.
5.1 Dataset
Our dataset11 consists of publicly-available IRPL programs that
we collected via open resources. Specifically, we used the search
functionality of popular source-code repositories (like GitHub and
BitBucket) and Google’s advanced-search operators, searching for
files with RAPID and KRL’s extensions, plus some language key-
words (e.g. MoveJ or MoveL for RAPID) to filter false positives. Out
of the found programs, we filter only ones that use at least one of
11The dataset is available from: https://robosec.org/data/asiaccs2020
8
Detecting Insecure Code Patterns in Industrial Robot Programs
ASIA CCS ’20, October 5–9, 2020, Taipei, Taiwan
Table 5: Summary of findings including the number of detected insecure patterns per analyzed program. Only the programs
having at least a sensitive source are considered in the analysis. Note that the label “false positive” refers to the presence of at
least one case of false positive among the detected patterns. Note that ptp, lin and circ are movement instructions in KRL.
#Patterns Language Details
#LOC Purpose
#Files
Vulnerability Class: network −→ code execution
130 Demonstrator
123 Demonstrator
Vulnerability Class: network −→ filesystem
Vulnerability Class: network −→ movement
974 Web server
4
1
1
10
9
1
1
1
2