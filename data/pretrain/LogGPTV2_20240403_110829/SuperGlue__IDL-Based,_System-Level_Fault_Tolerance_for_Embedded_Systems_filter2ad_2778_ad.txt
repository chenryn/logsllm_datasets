(ret, IDL params) corresponds to the template for track-
ing descriptor state, respectively. Each template is only used
if their predicates evaluate to true, thus the resulting generated
code is the composition only of the relevant templates for a
given SuperGlue speciÔ¨Åcation.
V. EVALUATION
We evaluate the fault
tolerance properties provided by
SuperGlue in a component-based embedded system, using a
bit-Ô¨Çip based Software Implemented Fault Inject (SWIFI) ap-
proach. We Ô¨Årst describe the fault model and SWIFI technique
we used to inject faults into system components. We then
proceed to describe the experiments performed and analyze
the results.
A. Fault Model and SWIFI
The ever-decreasing physical footprint of on-chip transistors
increases the impact of transient faults in pipelines [11],
and therefore leads to errors that corrupt OS state [5] [20].
234
This work focuses on tolerating transient faults (assuming a
Single Event Upset (SEU) fault model) and assumes a fail-
stop model. We ignore SEUs at the memory level, assuming
solutions such as error-correcting codes (ECC) [12] imple-
mented in hardware to be available, and instead we focus
on SEUs in functional units of the CPU (registers) and their
effects in system-level components. Nicolaidis [21] showed
that SWFI-based single-bit Ô¨Çip in registers can accurately
model transient faults in pipeline logic, which have error rates
that are currently higher than memory [22], [23], [24], [25].
We used a runtime SWIFI technique that injects faults
into registers to mimic transient faults by Ô¨Çipping bits within
the chosen registers. Instructions are encoded as single-word
(32bits) opcode and registers are also single-word sized in
the platform, so the fault type can be deÔ¨Åned by a 32-bit
fault mask in which the bits to be affected are set to ‚Äú1‚Äù
and the bits that should be left untouched set to ‚Äú0‚Äù. During
the evaluation, a fault mask of 0xFFFFFFFF is chosen and
the faults are injected by iterating through all threads and
Ô¨Çipping register‚Äôs bits only if they are executing within one
of the target server components that provides system-level
service: scheduler, memory manager, Ô¨Åle system, lock, event
manager, and timer manager. We mimic the fault distribution
by randomly selecting a register from eight 32-bit registers (6
general purpose registers and 2 special registers ESP and EBP)
periodically and Ô¨Çipping a random bit in the selected register.
Notice that in practice the fault distribution is not uniform,
but it is a Ô¨Årst order approximation used by previous fault
injection approaches [26] [27]. In [28], the calculation shows
that at most one fault occurs over a window of 509.15 seconds
with probability 99.999999% (assuming the distribution of the
transient faults in any Ô¨Åxed time interval follows a Poisson
distribution).
B. Benchmark Workloads
Using above-mentioned SWIFI technique, faults are in-
jected into system components that provide system-level ser-
vices: scheduler, memory manager, Ô¨Åle system, lock, event
manager, and timer manager. We Ô¨Årst describe for each system
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:19:10 UTC from IEEE Xplore.  Restrictions apply. 






	
	
	



	



(a) Infrastructure Overhead (Œºs)
 9
 8
 7
 6
 5
 4
 3
 2
 1
 0
C^3
SuperGlue
Sched
MM
FS
(b) Descriptor Recovery Overhead (Œºs)
Lock
Event
Timer
	
















	



(c) Recovery Code in LOC
Fig. 6: SuperGlue micro-benchmarks for each system component (compared with C3): (a) infrastructure overhead with
descriptor state tracking (Œºs). (b) per-descriptor recovery overhead (Œºs). (c) LOC for stub-based recovery code added to
each system component.
component the workload used in fault injection campaign:
‚Ä¢ Scheduler (Sched): Two threads perform a ping-pong,
blocking and waking each other in turn using sched blk
and sched wakeup.
‚Ä¢ Memory Manager (MM): A thread is granted memory
pages, and these pages are aliased into a different component,
and then revoked, which removes all aliases.
‚Ä¢ RAM File System (FS): A Ô¨Åle is opened, a byte is written
to it, read from it, and then it is closed.
‚Ä¢ Lock (Lock): A thread holds a lock and another thread
contends the same lock. After the owner thread releases, the
other thread acquires the lock.
‚Ä¢ Event (Event): A thread is blocked waiting for an event
and the other thread triggers the event from a different
component.
‚Ä¢ Timer Manager (Timer): A thread wakes up, then blocks
for a certain amount of time periodically.
C. Micro-Benchmark Results
The experiments reported in this section have been per-
formed in COMPOSITE component-based OS on an Intel i7-
2760QM running at 2.4 Ghz with only one core enabled.
SuperGlue is evaluated with six system-level components:
scheduler, memory manager, Ô¨Åle system, lock, event manager,
and timer manager. In Fig 6, we compare SuperGlue with
C3 [7] and present the micro-benchmarks results for each
system component.
Fig 6(a) shows the average infrastructure overhead (in
microseconds, with standard deviation) for tracking descrip-
tor state in SuperGlue and in C3, where the infrastructure
overhead is deÔ¨Åned as the base execution time of the micro-
benchmark plus the average (stdev) time needed to track
descriptor state. The result shows that SuperGlue has the
similar amount of overhead as C3. Fig 6(b) for each system
component compares the per-descriptor recovery overhead
in SuperGlue and C3, which is the average (stdev) time to
recover a descriptor to its ‚Äúexpected‚Äù state from the fault
state. The recovery overhead correlates with the number of
steps determined from Section III. For example, the cost of
recovering an event descriptor is higher than the cost for a lock
descriptor because the event server relies on all mentioned
recovery mechanisms, except (D0) , whereas a lock descriptor
only needs eager recovery (T0), base recovery (R0), and on-
demand recovery (T1).
Fig 6(c) shows the lines of code (LOC) in SuperGlue IDL
header Ô¨Åle, which is written in SuperGlue IDL, for each
system component and compares the LOC of recovery code
added by SuperGlue and by C3. The result shows with only a
small amount of declarative code written in SuperGlue IDL,
SuperGlue compiler is able to generate interface-driven fault
recovery code for many system-level services in a component-
based OS. For example, with only 32 LOC written in
SuperGlue IDL, the compiler generates 464 LOC that recovers
the memory manager from faults. These results show that
SuperGlue can be both efÔ¨Åcient and effective in recovering
low-level system services. SuperGlue seeks to make the pro-
cess of constructing dependable embedded system ‚Äúcorrect-
by-construction,‚Äù, instead of ‚Äúconstruct-by-correction‚Äù which
is time-consuming and error-prone.
D. Fault Injection Campaign Results
We evaluate the effectiveness of SuperGlue through a fault
injection campaign. Depending on the effects of a fault, and
if they are detected, we deÔ¨Åne injected faults in the target
system component as follows:
‚Ä¢ Fa is the set of injected faults that cause the target
component to deviate from its expected behavior and are
detected (e.g., as the fault generates a hardware exception,
triggers an assertion, causes a system hang or even crashes
the system). This type of fault is deÔ¨Åned as an activated
fault in [6].
‚Ä¢ Fr is the set of activated faults in the target component
that are recovered by SuperGlue successfully. A successful
recovery is deÔ¨Åned by the continued execution that abides
by the target component and workload speciÔ¨Åcations post-
recovery.
‚Ä¢ |Fr|
|Fa| is fault recovery success rate, which denotes how
many activated faults in the target component have been
recovered successfully.
‚Ä¢ Fu is the set of injected faults that are not detected
(undetected faults).
235
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:19:10 UTC from IEEE Xplore.  Restrictions apply. 
System
Component
Sched
MM
FS
Lock
Event
Timer
Injected
Recovered Faults
500
500
500
500
500
500
436
431
455
433
450
460
Not recovered
(segfault)
54
35
18
33
16
26
Not recovered
(propagated)
0
1
0
2
2
0
Not recovered
(other reason)
2
4
0
0
0
0
Undetected
9
30
29
31
33
18
Activation Ratio
Fault
98.36%
94.26%
94.7%
93.82%
93.83%
97.23%
Recovery
Success Rate
88.58%
91.48%
96.14%
92.35%
96%
94.62%
TABLE II: SWIFI-based Fault Injection Campaign with SuperGlue
|Fa|
The total number of injected faults is given by |Fa ‚à™ Fu|
|Fa‚à™Fu|. During each
and the fault activation ratio is given by
campaign, a maximum number of faults (i.e., |Fa‚à™Fu| = 500)
were injected into each low level system component while
the workload is running. After each injection, the executing
thread resumes and the program is run to completion (unless
the system crashes and we need reboot the machine). After
each workload execution, the system is rebooted to clear any
residual errors before the next run. We record the number of
recovered faults Fr, the number of non recovered activated
faults and report both the fault activation ratio and the
fault recovery success rate. For each system component, we
evaluate SuperGlue by executing that component‚Äôs workload
repeatedly while a SWIFI thread in a separate component
is responsible for injecting faults into the target component
periodically, for example randomly Ô¨Çipping bits in chosen
registers every 1 second. Note that register bit-Ô¨Çips do not
always lead to errors (e.g., a Ô¨Çipped register can be overwritten
before it is read) and those are undetected faults. The system,
without being rebooted, continues execution with the next
fault being injected when one of the following conditions is
observed: if the injected component is recovered successfully
from the activated fault, or the injected fault is not activated
at all (undetected fault). Otherwise, the system needs to be
rebooted and resumes the fault injection campaign until the
maximum number of faults have been reached.
Table II shows the result of fault injection campaign for
each system component with SuperGlue and it can be seen
that most of activated faults in the server component can
be effectively recovered. For example 96.14% of activated
faults in FS component have been successfully recovered.
This work focuses on recovering faults rather than detect-
ing faults, however, we also report our observations on the
effect of injected faults in Table II. Very few activated faults
propagate to non system-level client components and cause an
unrecoverable fault, due to hardware-based isolation between
components. For example, Table II shows that only 1 out
of 470 detected faults (about 0.2%) became unrecoverable
due to propagation when the faults are injected into the MM
component. Although this situation can be improved with
well speciÔ¨Åed interfaces with pervasive error checking and
validation of inputs (as in [29], [30]), SuperGlue focuses on
the recovery of system-level components in this work.
Among all unrecoverable faults, we observed that some
activated faults lead to segfault crashes (i.e., the system exits
with segmentation fault). For example, Sched component has
the most segfault crashes (10% of injected faults lead to
segfault crash), and for Event component this is around 3%.
This is the main impact on the fault recovery success rate;
further investigation might be necessary. There are also some
activated faults that cause the system to hang, rather than
crash, and we label these as ‚ÄúNot recovered (other reason)‚Äù in
Table II. Injected faults might cause inÔ¨Ånite loops in the target
component. This type of fault is deÔ¨Åned as latent fault and has
been discussed in C‚ÄôMON [28]. The result of fault activation
ratio, which is deÔ¨Åned as the percent of activated faults in all
injected faults, shows that our SWIFI can effectively inject and
activate faults in the target component. For example, 98.36%
of injected faults were activated in Sched component when
using SWIFI.
E. A Web Server Benchmark Workload
To thoroughly evaluate the degradation and overheads, that
is, the holistic cost of recovery, we use an application web
server that
is system and I/O intensive in which average