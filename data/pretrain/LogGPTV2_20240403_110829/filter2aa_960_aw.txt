    return newAuthenticate(domain, user, workstation, buf, buf, c)
}
Listing 6-15: Calculating hashes (/ch-6/smb/ntlmssp/ntlmssp.go)
The logic to call the appropriate function is defined elsewhere, but 
you’ll see that the two functions are similar. The real difference is that 
password-based authentication in the NewAuthenticatePass() function com-
putes the hash before generating the authentication message, whereas the 
NewAuthenticateHash() function skips that step and uses the supplied hash 
directly as input to generate the message.
Recovering the NTLM Hash
In Listing 6-16, you can see a utility that recovers a password by cracking a 
supplied NTLM hash.
func main() {
    if len(os.Args) != 5 {
前沿信安资讯阵地  公众号：i nf osrc
Interacting with SMB and NTLM    151
        log.Fatalln("Usage: main    ")
    }
    hash := make([]byte, len(os.Args[4])/2)
    _, err := hex.Decode(hash, []byte(os.Args[4]))u
    if err != nil {
        log.Fatalln(err)
    }
    f, err := ioutil.ReadFile(os.Args[1])
    if err != nil {
        log.Fatalln(err)
    }
    var found string
    passwords := bytes.Split(f, []byte{'\n'})
    for _, password := range passwordsv {
        h := ntlmssp.Ntowfv2(string(password), os.Args[2], os.Args[3]) w
        if bytes.Equal(hash, h)x {
            found = string(password)
            break
        }
    }
    if found != "" {
        fmt.Printf("[+] Recovered password: %s\n", found)
    } else {
        fmt.Println("[-] Failed to recover password")
    }
}
Listing 6-16: NTLM hash cracking (/ch-6/password-recovery /main.go)
The utility reads the hash as a command line argument, decoding it to 
a []byte u. Then you loop over a supplied password list v, calculating the 
hash of each entry by calling the ntlmssp.Ntowfv2() function we discussed 
previously w. Finally, you compare the calculated hash with that of our sup-
plied value x. If they match, you have a hit and break out of the loop.
Summary
You’ve made it through a detailed examination of SMB, touching on proto-
col specifics, reflection, structure field tags, and mixed encoding! You also 
learned how pass-the-hash works, as well as a few useful utility programs 
that leverage the SMB package. 
To continue your learning, we encourage you to explore additional 
SMB communications, particularly in relation to remote code execution, 
such as PsExec. Using a network sniffer, such as Wireshark, capture the 
packets and evaluate how this functionality works.
In the next chapter, we move on from network protocol specifics to 
focus on attacking and pillaging databases. 
前沿信安资讯阵地  公众号：i nf osrc
前沿信安资讯阵地  公众号：i nf osrc
Now that we’ve covered the majority of 
common network protocols used for active 
service interrogation, command and control, 
and other malicious activity, let’s switch our 
focus to an equally important topic: data pillaging.
Although data pillaging may not be as exciting as initial exploitation, 
lateral network movement, or privilege escalation, it’s a critical aspect of the 
overall attack chain. After all, we often need data in order to perform those 
other activities. Commonly, the data is of tangible worth to an attacker. 
Although hacking an organization is thrilling, the data itself is often a 
lucrative prize for the attacker and a damning loss for the organization. 
Depending on which study you read, a breach in 2020 can cost an orga-
nization approximately $4 to $7 million. An IBM study estimates it costs an 
organization $129 to $355 per record stolen. Hell, a black hat hacker can 
make some serious coin off the underground market by selling credit cards 
at a rate of $7 to $80 per card (http://online.wsj.com/public/resources/documents 
/secureworks_hacker_annualreport.pdf). 
7
A BU SING DATA B A SE S 
A N D F IL E S Y S T E M S
前沿信安资讯阵地  公众号：i nf osrc
154   Chapter 7
The Target breach alone resulted in a compromise of 40 million cards. 
In some cases, the Target cards were sold for as much as $135 per card 
(http://www.businessinsider.com/heres-what-happened-to-your-target-data-that-was 
-hacked-2014-10/). That’s pretty lucrative. We, in no way, advocate that type of 
activity, but folks with a questionable moral compass stand to make a lot of 
money from data pillaging.
Enough about the industry and fancy references to online articles—let’s 
pillage! In this chapter, you’ll learn to set up and seed a variety of SQL and 
NoSQL databases and learn to connect and interact with those databases 
via Go. We’ll also demonstrate how to create a database and filesystem data 
miner that searches for key indicators of juicy information.
Setting Up Databases with Docker
In this section, you’ll install various database systems and then seed them 
with the data you’ll use in this chapter’s pillaging examples. Where pos-
sible, you’ll use Docker on an Ubuntu 18.04 VM. Docker is a software con-
tainer platform that makes it easy to deploy and manage applications. You 
can bundle applications and their dependencies in a manner that makes 
their deployment straightforward. The container is compartmentalized 
from the operating system in order to prevent the pollution of the host 
platform. This is nifty stuff. 
And for this chapter, you will use a variety of prebuilt Docker images 
for the databases you’ll be working with. If you don’t have it already, install 
Docker. You can find Ubuntu instructions at https://docs.docker.com/install 
/linux/docker-ce/ubuntu/.
N O T E 
We’ve specifically chosen to omit details on setting up an Oracle instance. Although 
Oracle provides VM images that you can download and use to create a test database, 
we felt that it was unnecessary to walk you through these steps, since they’re fairly 
similar to the MySQL examples below. We’ll leave the Oracle-specific implementation 
as an exercise for you to do independently.
Installing and Seeding MongoDB
MongoDB is the only NoSQL database that you’ll use in this chapter. Unlike 
traditional relational databases, MongoDB doesn’t communicate via SQL. 
Instead, MongoDB uses an easy-to-understand JSON syntax for retrieving 
and manipulating data. Entire books have been dedicated to explaining 
MongoDB, and a full explanation is certainly beyond the scope of this 
book. For now, you’ll install the Docker image and seed it with fake data. 
Unlike traditional SQL databases, MongoDB is schema-less, which means 
that it doesn’t follow a predefined, rigid rule system for organizing table 
data. This explains why you’ll see only insert commands in Listing 7-1 
前沿信安资讯阵地  公众号：i nf osrc
Abusing Databases and Filesystems   155
without any schema definitions. First, install the MongoDB Docker image 
with the following command:
$ docker run --name some-mongo -p 27017:27017 mongo
This command downloads the image named mongo from the Docker 
repository, spins up a new instance named some-mongo—the name you give 
the instance is arbitrary—and maps local port 27017 to the container port 
27017. The port mapping is key, as it allows us to access the database instance 
directly from our operating system. Without it, it would be inaccessible.
Check that the container started automatically by listing all the run-
ning containers:
$ docker ps
In the event your container doesn’t start automatically, run the follow-
ing command:
$ docker start some-mongo
The start command should get the container going. 
Once your container starts, connect to the MongoDB instance by using 
the run command—passing it the MongoDB client; that way, you can inter-
act with the database to seed data:
$ docker run -it --link some-mongo:mongo --rm mongo sh \
  -c 'exec mongo "$MONGO_PORT_27017_TCP_ADDR:$MONGO_PORT_27017_TCP_PORT/store"'
>
This magical command runs a disposable, second Docker container 
that has the MongoDB client binary installed—so you don’t have to install 
the binary on your host operating system—and uses it to connect to the 
some-mongo Docker container’s MongoDB instance. In this example, you’re 
connecting to a database named test. 
In Listing 7-1, you insert an array of documents into the transactions 
collection. (All the code listings at the root location of / exist under the 
provided github repo https://github.com/blackhat-go/bhg/.)
> db.transactions.insert([
{
    "ccnum" : "4444333322221111",
    "date" : "2019-01-05",
    "amount" : 100.12,
    "cvv" : "1234",
    "exp" : "09/2020"
},
前沿信安资讯阵地  公众号：i nf osrc
156   Chapter 7
{
    "ccnum" : "4444123456789012",
    "date" : "2019-01-07",
    "amount" : 2400.18,
    "cvv" : "5544",
    "exp" : "02/2021"
},
{
    "ccnum" : "4465122334455667",
    "date" : "2019-01-29",
    "amount" : 1450.87,
    "cvv" : "9876",
    "exp" : "06/2020"
}
]);
Listing 7-1: Inserting transactions into a MongoDB collection (/ch-7/db/seed-mongo.js)
That’s it! You’ve now created your MongoDB database instance and 
seeded it with a transactions collection that contains three fake documents 
for querying. You’ll get to the querying part in a bit, but first, you should 
know how to install and seed traditional SQL databases.
Installing and Seeding PostgreSQL and MySQL Databases
PostgreSQL (also called Postgres) and MySQL are probably the two most 
common, well-known, enterprise-quality, open source relational database 
management systems, and official Docker images exist for both. Because 
of their similarity and the general overlap in their installation steps, we 
batched together installation instructions for both here.
First, much in the same way as for the MongoDB example in the previ-
ous section, download and run the appropriate Docker image:
$ docker run --name some-mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=password -d mysql
$ docker run --name some-postgres -p 5432:5432 -e POSTGRES_PASSWORD=password -d postgres
After your containers are built, confirm they are running, and if they 
aren’t, you can start them via the docker start name command.
Next, you can connect to the containers from the appropriate client—
again, using the Docker image to prevent installing any additional files on 
the host—and proceed to create and seed the database. In Listing 7-2, you 
can see the MySQL logic.
$ docker run -it --link some-mysql:mysql --rm mysql sh -c \
'exec mysql -h "$MYSQL_PORT_3306_TCP_ADDR" -P"$MYSQL_PORT_3306_TCP_PORT" \
-uroot -p"$MYSQL_ENV_MYSQL_ROOT_PASSWORD"'
mysql> create database store;
mysql> use store;
mysql> create table transactions(ccnum varchar(32), date date, amount float(7,2), 
    -> cvv char(4), exp date);
Listing 7-2: Creating and initializing a MySQL database
前沿信安资讯阵地  公众号：i nf osrc
Abusing Databases and Filesystems   157
The listing, like the one that follows, starts a disposable Docker shell 
that executes the appropriate database client binary. It creates and connects 
to the database named store and then creates a table named transactions. 
The two listings are identical, with the exception that they are tailored to 
different database systems.
In Listing 7-3, you can see the Postgres logic, which differs slightly in 
syntax from MySQL.
$ docker run -it --rm --link some-postgres:postgres postgres psql -h postgres -U postgres
postgres=# create database store;
postgres=# \connect store
store=# create table transactions(ccnum varchar(32), date date, amount money, cvv 
        char(4), exp date);
Listing 7-3: Creating and initializing a Postgres database
In both MySQL and Postgres, the syntax is identical for inserting your 
transactions. For example, in Listing 7-4, you can see how to insert three 
documents into a MySQL transactions collection.
mysql> insert into transactions(ccnum, date, amount, cvv, exp) values 
    -> ('4444333322221111', '2019-01-05', 100.12, '1234', '2020-09-01');
mysql> insert into transactions(ccnum, date, amount, cvv, exp) values 
    -> ('4444123456789012', '2019-01-07', 2400.18, '5544', '2021-02-01');
mysql> insert into transactions(ccnum, date, amount, cvv, exp) values 
    -> ('4465122334455667', '2019-01-29', 1450.87, '9876', '2019-06-01');
Listing 7-4: Inserting transactions into MySQL databases (/ch-7/db/seed-pg-mysql.sql)
Try inserting the same three documents into your Postgres database.
Installing and Seeding Microsoft SQL Server Databases
In 2016, Microsoft began making major moves to open-source some of its 
core technologies. One of those technologies was Microsoft SQL (MSSQL) 
Server. It feels pertinent to highlight this information while demonstrating 
what, for so long, wasn’t possible—that is, installing MSSQL Server on a 
Linux operating system. Better yet, there’s a Docker image for it, which you 
can install with the following command:
$ docker run --name some-mssql -p 1433:1433 -e 'ACCEPT_EULA=Y' \
-e 'SA_PASSWORD=Password1!' -d microsoft/mssql-server-linux 
That command is similar to the others you ran in the previous two 
sections, but per the documentation, the SA_PASSWORD value needs to be 
complex—a combination of uppercase letters, lowercase letters, numbers, 
and special characters—or you won’t be able to authenticate to it. Since 
this is just a test instance, the preceding value is trivial but minimally meets 
those requirements—just as we see on enterprise networks all the time!
前沿信安资讯阵地  公众号：i nf osrc
158   Chapter 7
With the image installed, start the container, create the schema, and 
seed the database, as in Listing 7-5.
$ docker exec -it some-mssql /opt/mssql-tools/bin/sqlcmd -S localhost \
-U sa -P 'Password1!'
> create database store;
> go
> use store;
> create table transactions(ccnum varchar(32), date date, amount decimal(7,2), 
> cvv char(4), exp date);
> go
> insert into transactions(ccnum, date, amount, cvv, exp) values 
> ('4444333322221111', '2019-01-05', 100.12, '1234', '2020-09-01');
> insert into transactions(ccnum, date, amount, cvv, exp) values 
> ('4444123456789012', '2019-01-07', 2400.18, '5544', '2021-02-01');
> insert into transactions(ccnum, date, amount, cvv, exp) values 
> ('4465122334455667', '2019-01-29', 1450.87, '9876', '2020-06-01');
> go
Listing 7-5: Creating and seeding an MSSQL database
The previous listing replicates the logic we demonstrated for MySQL 
and Postgres earlier. It uses Docker to connect to the service, creates and 
connects to the store database, and creates and seeds a transactions table. 
We’re presenting it separately from the other SQL databases because it has 
some MSSQL-specific syntax.
Connecting and Querying Databases in Go
Now that you have a variety of test databases to work with, you can build 
the logic to connect to and query those databases from a Go client. We’ve 
divided this discussion into two topics—one for MongoDB and one for 
traditional SQL databases.
Querying MongoDB
Despite having an excellent standard SQL package, Go doesn’t maintain a 
similar package for interacting with NoSQL databases. Instead you’ll need 
to rely on third-party packages to facilitate this interaction. Rather than 
inspect the implementation of each third-party package, we’ll focus purely 
on MongoDB. We’ll use the mgo (pronounce mango) DB driver for this.
Start by installing the mgo driver with the following command:
$ go get gopkg.in/mgo.v2
You can now establish connectivity and query your store collection (the 
equivalent of a table), which requires even less code than the SQL sample 
code we’ll create later (see Listing 7-6). 
前沿信安资讯阵地  公众号：i nf osrc
Abusing Databases and Filesystems   159
package main
import (
    "fmt"
    "log"
    mgo "gopkg.in/mgo.v2"
)
type Transaction struct { u
    CCNum      string  `bson:"ccnum"`
    Date       string  `bson:"date"`
    Amount     float32 `bson:"amount"`
    Cvv        string  `bson:"cvv"`
    Expiration string  `bson:"exp"`
}
func main() {
    session, err := mgo.Dial("127.0.0.1") v
    if err != nil {
        log.Panicln(err)
    }   
    defer session.Close()
    results := make([]Transaction, 0)
    if err := session.DB("store").C("transactions").Find(nil).All(&results)w; err != nil {
        log.Panicln(err)
    }   
    for _, txn := range results { x
        fmt.Println(txn.CCNum, txn.Date, txn.Amount, txn.Cvv, txn.Expiration)
    }
}
Listing 7-6: Connecting to and querying a MongoDB database (/ch-7/db /mongo-connect/main.go)
First, you define a type, Transaction, which will represent a single 
document from your store collection u. The internal mechanism for data 
representation in MongoDB is binary JSON. For this reason, use tagging 
to define any marshaling directives. In this case, you’re using tagging to 
explicitly define the element names to be used in the binary JSON data.
In your main() function v, call mgo.Dial() to create a session by establish-