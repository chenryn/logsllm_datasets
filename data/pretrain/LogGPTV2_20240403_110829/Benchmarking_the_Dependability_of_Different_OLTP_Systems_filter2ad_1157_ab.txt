TPC-C specification.  
(cid:131)(cid:3)AvtC  –  Availability  from  the  end-users  (terminals) 
point-of-view  in  the  presence  of  the  faultload  during 
Phase 2 (measures the time the system is available from 
the  client’s  point-of-view).  The  system  is  available  for 
one  terminal  if  it  responds  to  a  submitted  transaction 
within the minimum response time defined for that type 
of transaction by the TPC-C specification. The system is 
unavailable  for  that  terminal  if  there  is  no  response 
within that time or if an error is returned. 
It  is  worth  noting  that  in  the  context  of  the  DBench-
OLTP  benchmark,  availability  is  defined  based  on  the 
service  provided  by  the  system.  This  way,  the  system  is 
considered available when it is able to provide the service 
defined by the transactions. For example, from the client’s 
point-of-view  the  system  is  not  available  if  it  submits  a 
transaction  and  gets  no  answer  within  the  specified  time 
or  gets  an  error.  In  this  case,  the  unavailability  period  is 
counted  from  the  moment  when  a  given  client  submits  a 
transaction  that  fails  until  the  moment  when  it  submits  a 
transaction  that  succeeds.  From  the  server  point-of-view, 
the  system  is  available  when  it  is  able  to  execute 
transactions  submitted  by  the  clients.  AvtS  and  AvtC  are 
given as a ratio between the amount of time the system is 
available and the Phase 2 duration. 
2.2. Faultload 
A faultload can be based on three major types of faults: 
operator  faults,  software  faults,  and  hardware  faults.  The 
faultload  considered  in  this  dependability  benchmark  is 
based  on  operator  faults,  as  these  faults  are  unanimously 
considered  as  one  of  the  major  causes  for  failures  in 
transactional systems [3, 4]. 
As  today’s  transactional  systems  use  a  database 
management  system  (DBMS)  as  transactional  engine, 
transactional  systems  are  strongly  influenced  by  database 
technology, which turns the problem of operator faults in 
this type of system essentially into a problem of database 
administrator mistakes. End-user errors are not considered 
as  operator  faults,  as  the  end-user  actions  do  not  affect 
directly the dependability of a DBMS.  
The  types  of  faults  considered  for  the  faultload  are 
presented  in  table  1.  The  faultload  is  composed  by  a 
number  of  faults  from  these  types,  injected  in  different 
instants.  Note  that  the  faultload  is  dependent  on  the  size 
and  configuration  of  the  SUT.  For  detailed  guidelines  on 
how to implement the faultload see [2]. 
Type of Fault 
Target 
Abrupt OS shutdown  Ten faults injected at the following injection times: 3, 5, 7, 9, 10, 11, 12, 13, 14, and 15 minutes. 
Abrupt transactional 
Ten faults injected at the following injection times: 3, 5, 7, 9, 10, 11, 12, 13, 14, and 15 minutes. 
engine shutdown 
Kill set of user 
sessions 
Delete table 
Delete user schema 
Delete file from disk 
Five faults injected at the following injection times: 3, 7, 10, 13, and 15 minutes. The set of sessions to be 
killed in each fault injection must be randomly selected during the benchmark run and consists of 50% of all 
the active sessions from the users holding the TPC-C tables. 
Three faults for each one of the following TPC-C tables: ware, order, new-order, and order-line (a total of 12 
faults). The injection times to be considered are the following: 3, 10, and 15 minutes. 
Three faults using the following injection times: 3, 10, and 15 minutes. The user to be considered is the one 
that holds the TPC-C tables. If the objects are distributed among several users then the user holding the 
greater number of TPC-C tables must be selected. 
For each TPC-C table, the set of faults to inject is defined performing the following steps: 
1) Select randomly 10% of the files containing data from the table being considered (a minimum of 1). 
2) Inject 3 faults for each disk file selected, using the following injection times: 3, 10, and 15 minutes. 
Delete set of files 
from disk 
Delete all files from 
one disk 
Three faults for each set of files containing each TPC-C table (a total of 27 faults). The injection times are 
the following: 3, 10, and 15 minutes. 
The set of faults to inject is defined performing the following steps: 
1) Select randomly 10% of the disks containing data from any TPC-C table (in a minimum of 1). 
2) Inject 3 faults for each disk selected before, using the following injection times: 3, 10, and 15 minutes. 
Table 1. Faultload definition guidelines. 
Detection Time
0 Seconds 
30 Seconds 
0 Seconds 
2 Minutes 
1 Minute 
4 Minutes 
2 Minutes 
1 Minute 
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:27:42 UTC from IEEE Xplore.  Restrictions apply. 
2.3. Dependability benchmark properties 
A  useful  benchmark  must  be  repeatable,  portable  and 
representative  [5,  6].  To  be  credible  a  dependability 
benchmark must report similar results when run more than 
once  in  the  same  environment.  Concerning  the  DBench-
OLTP benchmark, several tests have been done to confirm 
the  fulfillment  of  this  important  requirement.  It  is  worth 
noting, however, that repeatability has to be understood in 
statistical terms, as  it is  virtually impossible to reproduce 
exactly the same conditions concerning target system state 
during the benchmark run. In practice, small deviations in 
the measures in successive runs are normal and just reflect 
the  asynchronous  nature  of  transaction  submission  in  an 
OLTP  system.  This  is  well  known  for  TPC-C,  as  the 
number of transactions measured in successive runs in the 
same system normally has small fluctuations.  
experiments  is  based  on  a  server  that  executes  the 
transactions  submitted  by  several  clients  (client/server 
architecture).  The  server  is  composed  by  three  main 
components: the hardware platform, the operating system, 
and  the  transactional  engine.  Most  of  the  transactional 
systems  available  today  use  a  database  management 
system  (DBMS)  as  transactional  engine.  For  that  reason, 
the  DBMS  is  the  most  important  component  in  the 
system.  However,  from  the  DBench-OLTP  benchmark 
point-of-view, the SUT includes all the elements required 
to execute the workload and not just the DBMS. 
Table 2 shows the systems that have been benchmark-
ked. The hardware platform used is the same and the main 
differences among the systems are related to the operating 
system  and  transactional  engine  (DBMS)  used.  Two 
different  versions  of  the  Oracle  DBMS  and  two  different 
Microsoft operating systems have been considered.  
Another 
important  property 
is  portability,  as  a 
benchmark  must  allow  the  comparison  of  different 
systems  in  a  given  application  domain.  Concerning 
dependability  benchmarking, 
the 
component  that  has  more  influence  on  portability.  The 
DBench-OLTP  bench-mark 
the 
faultload  was  defined 
common 
functionalities  found  in  all  transactional  systems  [7]  and 
not based on implementation details. 
is  portable  because 
based  on 
faultload 
the 
the 
is 
In  order  to  report  relevant  results,  a  benchmark  must 
represent  real  world  scenarios  in  a  realistic  way.  In  de-
pendability  benchmarking,  representativeness  is  mainly 
influenced  by  the  workload  and  faultload  characteristics. 
As  we  have  adopted  the  TPC-C  workload,  which  is  well 
accepted as a realistic OLTP scenario, the representative-
ness of the workload is assured. In terms of the faultload, 
the  type  of  faults  used  (operator  faults)  is  unanimously 
considered as one of the major causes for failures in trans-
actional  systems.  Furthermore,  these  types  of  faults  also 
emulate  the  high-level  hardware  failures  (e.g.,  disks, 
network, etc.) normally found in OLTP environments. 
OS 
DBMS 
System
2KOra8i Win 2K Prof.  Oracle 8i (8.1.7) 
XPOra8i Win XP Prof.  Oracle 8i (8.1.7) 
2KOra9i Win 2K Prof.  Oracle 9i (9.0.2) 
XPOra9i Win XP Prof. Oracle 9i (9.0.2) 
Hardware Platform 
800 MHz 
• Processor: Intel PIII 
• Memory: 256MB 
• Disks: 4 20GB/7200rpm 
• Network: Fast Ethernet  
Table 2. Systems under benchmarking.
It  is  important  to  note  that  all  systems  have  a  similar 
size and have been configured to provide a good tradeoff 
between  performance  and  recovery.  Concerning 
the 
operating  system  configuration,  we  tried  to  reproduce  a 
typical  configuration  of  a  transactional  system  with  as 
many  resources  as  possible  allocated  to  the  DBMS.  The 
DBMS  configuration  has  been  chosen  based  on  results 
from a previous  work on the  evaluation of the Oracle re-
covery mechanisms in the presence of operator faults [8]. 
As  mentioned  earlier  in  the  paper,  the  faultload  is 
dependent  on  the  size  and  configuration  of  the  system 
under  benchmarking.  It  is  important  to  note  that,  due  to 
the  similar  size  and  configuration  of  the  four  SUT,  the 
faultload used is the same for all systems. Table 3 summa-
rizes the faultload used. 
3. Systems under benchmarking
Type of fault 
# of faults % of faults
e-commerce 
The goal of the benchmarking process presented in this 
work  is  to  compare  and  rank  four  different  transactional 
systems (see table 2). All these systems can be considered 
as possible alternatives  for small and  medium size OLTP 
applications such as typical client-server database applica-
tions  or 
the 
benchmark  does  not  include  security  aspects  normally 
needed  in  e-commerce).  In  this  sense,  the  dependability 
benchmarking experiments presented in the paper give the 
answer  to  the  following  question:  which  one  of  the  four 
benchmarked  systems  is  the  best  choice  for  a  typical 
OLTP 
and 
dependability aspects? 
performance 
application, 
considering 
applications
(although 
In  a  simplified  approach,  a  transactional  system  like 
the  present  benchmarking 
the  ones  considered 
in 
Abrupt operating system shutdown 
Abrupt transactional engine shutdown 
Kill set of user sessions 
Delete table 
Delete user schema 
Delete file from disk 
Delete set of files from disk 
Delete all files from one disk 
Total 
10 
10 
5 
12 
3 
27 
27 
3 
97 
10.3 
10.3 
5.2 
12.4 
3.1 
27.8 
27.8 
3.1 
100 
Table 3. Faultload used in the experiments. 
4. Benchmark results and discussion 
As mentioned before, four different systems have been 
benchmarked.  The  following  sub-sections  present  and 
discuss  the  results  for  each  set  of  measures  provided  by 
the benchmark  and propose  a possible ranking for the 
SUT. 
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:27:42 UTC from IEEE Xplore.  Restrictions apply. 
4.1. Baseline performance measures 
The  baseline  performance  measures  reported  by  the 
DBench-OLTP benchmark are the number of transactions 
executed  per  minute  (tpmC)  and  price  per  transaction 
($/tpmC).  These  measures,  obtained  during  the 
benchmark Phase 1, are calculated as defined in the 
TPC-C  standard  specification  [1].  Figure  3  shows 
the baseline performance results obtained. 
2300
2000
1700
1400
Results  show  that  the  baseline  performance 
depends  mainly  on  the  DBMS  used.  In  fact,  a 
considerable difference in the baseline performance 
was  observed  between  systems  based  on  the  two 
DBMS.  The  systems  using  the  Oracle  9i  DBMS 
achieve  a  better  number  of  transactions  executed  per 
minute  (tpmC),  showing  that  this  DBMS  is  quite  faster 
than  its  predecessor.  In  terms  of  the  price  per  transaction 
($/tpmC), the systems based on Oracle 9i present a lower 
cost in spite of being more expensive systems (due to the 
better performance reached). 
4.2. Performance measures in the presence of the 
faultload 
The performance measures in the presence of the fault-
load reported are the number of transactions executed per 
minute in the presence of the faultload (Tf), the price per 
transaction in the presence of faults ($/Tf), and the system 