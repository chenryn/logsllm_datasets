trained on 20 million crisis-related tweets using the Skip-gram model of the
word2vectoolfromalargecorpusofdisaster-relatedtweets.Thecorpuscontains
57, 908 tweets and 9.4 million tokens.
4.2 Applying Classification Techniques
We performed our experiments using three models with the following hyper-
parameters initialisation.
a. Machine Learning Model: Chosen parameter values for SVM - regular-
ization were (C) = 100, kernel type = ‘rbf’, gamma value = 0.1. For Random
Forest- max depth = 5, n estimators = 10, max features = 1.
Thelabelencodesthetargetvariable-ThisisdonetotransformCategorical
data of string type in the data set into numerical values. Next step is word
vectorization by using TF-IDF Vectorizer - This is done to find how important
a word in a document is in comparison to the corpus. After fitting the data, we
run the machine learning algorithm to check accuracy.
b. CNN Model.Valuesofparameters:Filtersno.=250,Poolsize=2,Hidden
size = 128, Kernel size = 3.
We have re-implemented the CNN and Crisis embedding model from [14] to
compareitwiththeothermodels.WeusedamultilayerperceptronwithaCNN.
c. MT-DNN Model. Values of parameters: Learning rate = 5e–5, global gra-
dient clipping = 1.0, Learning gamma = 0.1, epoch = 30, Variable batch sizes
= (16,32,64).
WeappliedthelatestMicrosoftMT-DNN[11]modelonourdatasetlooking
for better classification performance.
4.3 Data Sets and Labels
We have used the CrisisNLP data set for our classification task and measuring
the accuracy of all the three models. We modified the labels of tweets such
that each crisis event data set has two labels - Event (a situation produced
duringadisaster)andAction(representsreactionstoevents).Table1showsthe
number of tweets for each set. The class “Event” includes tweets which subject
isrelatedtoanyoccurrenceorincidencehappeningduringorafterthecrisis.For
example, “damage happened to a building” or “people are trapped in buildings
in downtown”. For “Action” we consider those tweets that focus on operations
taking place during or after the crisis. Such as government or NGOs providing
help to the affected people.
We performed a set of experiments on California and Nepal earthquake,
Typhoon Hagupit and Pakistan Flood data sets (see Table2). The distribution
ofdataisshowninTable2:train(70),validation(10)andtestsets(20).Column
Labels show the total number of annotations for each class.
Classifying Micro-text Document Datasets 453
Table 1. Description of the classes in the data sets.
Class Total label Description
Event 1869 Tweets reporting occurrence
and happening of events during
the crisis. Reports deaths,
injuries, missing, found, or
displaced people, infrastructure
and utilities damage
Action 2684 Tweets reporting responses
and measures taken by people
during crisis. Messages
containing donations or
volunteering offers also
sympathy-emotional support
Table 2. Class distribution of events under consideration and all other crises.
Class Nepal California Typhoon Pakistan
Event 688 574 271 356
Action 1535 255 462 432
Total 2203 829 733 788
4.4 Classification Results
Table3 reports the performance of the five models applied to the California,
Nepal,HagupitandPakistancrisisdatasets.Notethatforagivenmodel,dataset
quality across different disaster events is not similar and also tweets were noisy
andafter cleaning therecan besomedata loss which could affect thecontextual
understanding of models. Hence the models learn and generalise better events
with higher data quality and uniform class label distribution. Note that among
all the machine learning models (i.e., SVM, RF and NB), the accuracy score of
SVMiscomparativelyhigherthanRFandNB.Forexample,theaccuracyscore
of the California dataset using SVM is 88.17, whereas the accuracy score for
RF and NB are 87.36 and 86.56, respectively. For the CNN model with crisis
embedding,theaccuracyscoresfortheCaliforniadatasetis90.13andforNepal
88.62. This is also true for the Typhoon Hagupit and Pakistan Flood datasets,
with SVM core accuracy of 87.61 and 92.82, respectively.
CNN model outperforms the machine learning models in terms of accuracy
score. For the MT-DNN model the accuracy scores were: for California crisis
= 91.72 and for Nepal crisis = 90.31. For Typhoon Hagupit = 91.22 and for
Pakistan Flood = 95.72. We can see that the MT-DNN model surpasses the
machine learning and the CNN model and have the best accuracy score.
Several works have done crisis tweets classification research [7,14]. Existing
work has addressed different labels using several classes applying RF, linear
454 M. Farokhnejad et al.
Table 3.AccuracyscoreofSVMs,RF,NB,CNNandMT-DNNwithrespecttocrisis
tweet data.
Data sets SVM NB RF CNN MT-DNN
California 88.17 86.56 87.36 90.13 91.72
Nepal 87.21 83.83 86.95 88.62 90.31
Hagupit 87.61 80.75 85.43 89.31 91.22
Pakistan 92.82 91.25 90.64 93.34 95.72
regression (LR), SVM and CNN. The best accuracy results were obtained with
CNNontheNepalandCaliforniaEarthquakes,datasetsthetyphonHagupitand
the cyclone PAM (resp. 86,89, 81.21, 87,83 and 94,17). Our binary classification
leads to acceptable accuracy results ranging from 87.36, 86.95, 85.43 and 90.64.
OurresultsinTable3showthatMT-DNNmodelperformsbetterthanCNN
and ML models used in previous experiments, however from computing com-
plexity point of view, since CNN performance was very close to MT-DNN we
can also use CNN instead of MT-DNN which will save computation power and
cost.
4.5 Models Compared: Classification vs Non-classification
Inthis section, wehave presentedan ablation studyinwhich wehave compared
the performance of our proposed classification based query expanding method
againstthetraditionalqueryexpandingmethod.WeusetheavailablecrisisNLP
pre-trained word embedding via word2vec method [7] to obtained query and
expansion terms vectors. In the vector space model, all queries and terms are
represented as vectors in dimensional space 300. Documents similarity is deter-
mined by computing the similarity of their content vector. To obtain a query
vector, we represent keywords in user queries as vectors, and then sum all the
keywordvectorsfollowedbyaveragingthem.Forouranalysis,wecalculatedthe
average similarity between the query vector and ’m’ keyword vectors obtained
for a given query by using the formula 1.
(cid:2)
Similarity(Candidate terms,Query)= m i=1(Cosine(Queryvector,Termvector[i])) (1)
m
where ‘m’ is a hyper-parameter in query expansion-based retrieval, which
showsthenumberofexpansionterms(ET).Usingasreferencethestudies[3,23],
wesetthenumberofexpansiontermsto10,20and30(ET@10,ET@20,ET@30).
Werepeatthistaskfor100queriesandreportthemeanofaverageofeachET@
set in Table4. The experimental results show that the expanded query terms
obtainedfromtheclassifiedqueryexpansionmodelaremoresimilarandrelevant
thanthenon-classificationmodel.TheET@10,ET@20andET@30scoresofour
proposed classification model surpassed the transition non-classification based
model. Also, we observe that when we set the number of expansion terms to 10,
we achieve the best performance.
Classifying Micro-text Document Datasets 455
Table4.ThemeanaverageofCosineSimilarity(MACS)betweenqueryandexpanded
query terms with and without classification model.
Query expansion model ET@10 ET@20 ET@30
Classification 0.420 0.377 0.371
Non-classification 0.401 0.366 0.369
5 Conclusions and Future Work
Thispaperintroducedaclassificationbasedqueryexpansionmethod.Forclassi-
ficationpurpose,variousmachinelearningalgorithmsstudiedandwerevalidated
through experiments using crisis tweet datasets that compared the performance
of the applied models. Also, we showed that query expansion base on classifica-
tion method obtains better candidate expansion words, which are semantically
close to the user query. We are currently exploring more robust and advanced
NLP models for processing and analyzing crisis data to improve the achieved
results. Our future work includes the use of classified vocabularies for exploring
data collections using different techniques like queries as answers, query morph-
ing and query by example.
References
1. Abberley, D., Kirby, D., Renals, S., Robinson, T.: The THISL broadcast news
retrieval system (1999)
2. Acar, A., Muraki, Y.: Twitter for crisis communication: lessons learned from
Japan’s Tsunami disaster. Int. J. Web Based Communities 7(3), 392–402 (2011)
3. Azad, H.K., Deepak, A.: Query expansion techniques for information retrieval: a
survey. Inf. Process. Manage. 56(5), 1698–1735 (2019)
4. Burel,G.,Alani,H.:Crisiseventextractionservice(CREES)-automaticdetection
and classification of crisis-related content on social media (2018)
5. Cameron, M.A., Power, R., Robinson, B., Yin, J.: Emergency situation aware-
ness from twitter for crisis management. In: Proceedings of the 21st International
Conference on World Wide Web, pp. 695–698. ACM (2012)
6. Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., Kuksa, P.:
Naturallanguageprocessing(almost)fromscratch.J.Mach.Learn.Res.12,2493–
2537 (2011)
7. Imran, M., Mitra, P., Castillo, C.: Twitter as a lifeline: human-annotated Twitter
corpora for NLP of crisis-related messages. In: Proceedings of the Tenth Interna-
tionalConferenceonLanguageResourcesandEvaluation(LREC2016).European
Language Resources Association (ELRA), Paris, France, May 2016
8. Imran, M., Mitra, P., Srivastava, J.: Cross-language domain adaptation for classi-
fying crisis-related short messages. arXiv preprint arXiv:1602.05388 (2016)
9. Kim, Y.: Convolutional neural networks for sentence classification. arXiv preprint
arXiv:1408.5882 (2014)
10. Li, L., Xu, G., Yang, Z., Dolog, P., Zhang, Y., Kitsuregawa, M.: An efficient app-
roachtosuggestingtopicallyrelatedwebqueriesusinghiddentopicmodel.World
Wide Web 16(3), 273–297 (2013)
456 M. Farokhnejad et al.
11. Liu, X., He, P., Chen, W., Gao, J.: Multi-task deep neural networks for natu-
ral language understanding. In: Proceedings of the 57th Annual Meeting of the
AssociationforComputationalLinguistics,pp.4487–4496.AssociationforCompu-
tational Linguistics, Florence, Italy, July 2019. https://doi.org/10.18653/v1/P19-
1441. https://www.aclweb.org/anthology/P19-1441
12. Miyanishi,T.,Seki,K.,Uehara,K.:Improvingpseudo-relevancefeedbackviatweet
selection. In: Proceedings of the 22nd ACM International Conference on Informa-
tion & Knowledge Management, pp. 439–448 (2013)
13. Nguyen, D.T., Joty, S., Imran, M., Sajjad, H., Mitra, P.: Applications of online
deep learning for crisis response using social media information. arXiv preprint
arXiv:1610.01030 (2016)
14. Nguyen, D.T., Mannai, K.A.A., Joty, S., Sajjad, H., Imran, M., Mitra, P.: Rapid
classification of crisis-related data on social networks using convolutional neural
networks. arXiv preprint arXiv:1608.03902 (2016)
15. Palen,L.,Vieweg,S.:Theemergenceofonlinewidescaleinteractioninunexpected
events:assistance,alliance&retreat.In:Proceedingsofthe2008ACMConference
on Computer Supported Cooperative Work, pp. 117–126. ACM (2008)
16. Priya, S., Bhanu, M., Dandapat, S.K., Ghosh, K., Chandra, J.: TAQE: tweet
retrieval-based infrastructure damage assessment during disasters. IEEE Trans.
Comput. Soc. Syst. 7(2), 389–403 (2020)
17. Sakaki, T., Okazaki, M., Matsuo, Y.: Earthquake shakes Twitter users: real-time
event detection by social sensors. In: Proceedings of the 19th International Con-
ference on World Wide Web, pp. 851–860. ACM (2010)
18. Spink,A.,Wolfram,D.,Jansen,M.B.,Saracevic,T.:Searchingtheweb:thepublic
and their queries. J. Am. Soc. Inform. Sci. Technol. 52(3), 226–234 (2001)
19. Varga, I., et al.: Aid is out there: looking for help from tweets during a large
scale disaster. In: Proceedings of the 51st Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), pp. 1619–1629 (2013)
20. Vieweg, S., Hughes, A.L., Starbird, K., Palen, L.: Microblogging during two nat-
ural hazards events: what Twitter may contribute to situational awareness. In:
ProceedingsoftheSIGCHIConferenceonHumanFactorsinComputingSystems,
pp. 1079–1088. ACM (2010)
21. Wang, Y., Huang, H., Feng, C.: Query expansion based on a feedback concept
modelformicroblogretrieval.In:Proceedingsofthe26thInternationalConference
on World Wide Web, pp. 559–568 (2017)
22. Xu, B., Lin, H., Lin, Y., Xu, K., Wang, L., Gao, J.: Incorporating semantic word
representations into query expansion for microblog information retrieval. Inform.
Technol. Control 48(4), 626–636 (2019)
23. Zhai, C., Lafferty, J.: Model-based feedback in the language modeling approach
toinformationretrieval.In:ProceedingsoftheTenthInternationalConferenceon
Information and Knowledge Management, pp. 403–410 (2001)
Data Centered and Usage-Based Security Service
B
JingyaYuan ,FrédériqueBiennier( ) ,andNabilaBenharkat
UniversityofLyon,CNRS,INSA-Lyon,LIRIS,UMR5205,Lyon,France
{jingya.yuan,frederique.biennier,nabila.benharkat}@liris.cnrs.fr
Abstract. ProtectingInformationSystems(IS)reliestraditionallyonsecurityrisk
analysismethods.Designedforwell-perimetrisedenvironments,thesemethods
relyonasystematicidentificationofthreatsandvulnerabilitiestoidentifyeffi-
cientcontrol-centeredprotectioncountermeasures.Unfortunately,thisdoesnotfit
securitychallengescarriedoutbytheopenedandagileorganizationsprovidedby
theSocial,Mobile,bigdataAnalytics,CloudandInternetofThings(SMACIT)
environment.Duetotheirinherentlycollaborativeanddistributedorganization,
suchmulti-tenancysystemsrequiretheintegrationofcontextualvulnerabilities,
dependingontheaprioriunknownwayofusing,storingandexchangingdatain
openedcloudenvironment.Moreover,asdatacanbeassociatedtomultiplecopies,
differentprotectionrequirementscanbesetforeachofthesecopies,whichmay
leadtheinitialdataownerlosecontrolonthedataprotection.Thisinvolves(1)
turningthetraditionalcontrol-centeredsecurityvisiontoadynamicdata-centered
protectionandeven(2)consideringthatthewayadataisusedcanbeapotential
threatthatmaycorruptdataprotectionefficiency.Tofitthesechallenges,wepro-
poseaData-centricUsage-basedProtectionservice(DUP).Thisserviceisbased
onaninformationsystemmeta-model,usedtoidentifyformallydataassetsand
storetheprocessesusingcopiesoftheseassets.Todefineausage-enteredprotec-
tion,weextendtheUsageBasedAccessControlmodel,whichismostlyfocused
onmanagingCRUDoperations,tomorecomplexoperationfittingtheSMACIT
context. These usage rules are used to generate smart contracts, storing usage
consentsandmanagingusagecontrolforcloudservices.
Keywords: Privacy·Data-drivenorganization·Blockchain·GDPR·Usage
governance
1 Introduction
TheexplosionofSocialnetworks,Mobileenvironment,bigdataAnalytics,Cloudcom-
puting or Internet of Things, known as SMACIT services, has created unprecedented
opportunities and fundamental security and privacy challenges. First, asset identifica-
tionismorecomplexthaninclassicalInformationSystems(ISforshort)asdataarenot
just “big” but also unstructured and multi-modeled [1]: this makes harder identifying
precisely potential vulnerabilities and threats. Second, the complexity of the software
stackinvolvesintegratingspecificsecurityrequirementsrelatedtothecloudtechnology
[2]andtomobileaccesstothiscloudarchitecture[3].Third,theintrinsicopennessof
©SpringerNatureSwitzerlandAG2021
H.Hacidetal.(Eds.):ICSOC2020Workshops,LNCS12632,pp.457–471,2021.
https://doi.org/10.1007/978-3-030-76352-7_42
458 J.Yuanetal.
SMACITsystemsinvolvesintegratingdifferentstakeholders,sharingdataandprocesses
withoutclearandcommonsecuritypolicies.Thiscontextleadstoinconsistentprotection
aseachpartydeploysandmanagesitsownsecuritystrategy.Fourth,analyticprocesses
are also threating agents, carrying privacy vulnerabilities: whereas privacy-preserving
processes, as anonymization algorithms, are designed for well-identified datasets [4],
analyticprocessesmixingdifferent“protected”datasetsmayleadtoidentifyusersfrom
initiallyanonymizeddata.