3425740
21827
5 hours(1)
56 hours(1)
40 minutes
(1) Computed time using 10 computers.
172 features were discovered among all the diﬀerent types of messages. These
features represent items order, diﬀerent lengths and values of ﬁelds where non
protocol knowledge except its syntax grammar had been used. Between two dif-
ferent devices the distance of diﬀerent features ranges between 26 to 95 features,
where most of the lower values correspond to diﬀerent versions of the same
device. Usually, up to 46 features are identiﬁed in one message.
Table 4 summarizes the sensitivity, speciﬁcity and accuracy. The results were
obtained using the test data set.
Table 4. Accuracy results obtained with the system
True Positive False Positive Positive Predictive
Classiﬁcation
18881
20
False Negative True Negative Negative Predictive
2909
Sensitivity
0.866
435780
Speciﬁcity
0.999
Value
0.998
Value
0.993
Accuracy
0.993
In this table we can observe that the results are very encouraging due to the
high speciﬁcity and accuracy. However, some observations can be made about
the quantity of false negatives. About 2/5 of them belong to only one imple-
mentation (percentage that represents 50% of its messages), 2/5 belongs to 3
more device classes (representing 18% of their messages), the ﬁnal 1/5 belongs
to 8 classes (representing 10% of their messages) and the 7 classes left do not
have false negatives. This issue can be a consequence of the irregularity in the
quantity from the set of messages in each device. Three of the higher mentioned
classes had been used in our test-bed to acquire most features of SIP. A second
explanation can be that in fact many of those messages do not contain valuable
information (e.g. intermediary messages). Table 5 shows all the 38 types of mes-
sages collected in our test with information concerning their miss-classiﬁcation
(i.e. False Negatives).
Finally, we created a set of messages which have been manually modiﬁed.
These modiﬁcations include changing the User-Agent, Server-Agent and refer-
ences to device name. As a result, deleting a few such ﬁelds did not inﬂuence
386
H.J. Abdelnur, R. State, and O. Festor
Table 5. False Negative classiﬁcation details
Type of Message False Negatives Message quantity Miss percentage
(710, 561, 347)
(4663, 1802, 2893)
(15%, 31%, 11%)
9358
17%
1613
824
3414
24%
892, 176(cid:2) (cid:0) 65%, 11%, 100%
11%, 67%(cid:2)
33%
636
(cid:0) 257, 215, 148
104, 100(cid:2) (cid:0) 385, 1841, 148
213
84, 57, 28
21, 13, 6
2, 1, 1
(cid:3)
(cid:4)
(cid:5)
(cid:6)
(cid:3)
(cid:4)
84, 230, 118
52, 42, 18
2, 38, 51
(cid:5)
(cid:6)
(cid:3)
(cid:4)
200, 100, ACK
501, 180, 101
BYE, 486
489, 487, 603
202, 480, 481
380, 415, 400
INVITE, OPTIONS
REGISTER, CANCEL
SUBSCRIBE
INFO, REFER
PRACK, NOTIFY
PUBLISH
11 other
Response Codes
(cid:3)
(cid:4)
117
38, 34
25, 19
1
0
0
(cid:5)
(cid:6)
(cid:3)
(cid:4)
(cid:3)
(cid:4)
5694
3037, 628
1323, 297
409
2223
1830, 163
117, 77
36
492
(cid:5)
(cid:6)
(cid:5)
(cid:6)
(cid:5)
(cid:6)
100%, 24%, 23%
40%, 30%, 33%
100%, 2%, 2%
2%
1%,
1%,
5%
6%
.00%
0%
(cid:5)
(cid:6)
(cid:3)
(cid:4)
0%
the decision of the system; neither did it changing their banners to another im-
plementation name. However, as more modiﬁcations were done, less precise the
system became and more mistakes were done.
6 Related Work
Fingerprinting became a popular topic in the last few years. It started with the
pioneering work of Comer and Lin [8] and is currently an essential activity in
security assessment tasks. Some of the most known network ﬁngerprinting oper-
ations are done by NMAP [9], using a set of rules and active probing techniques.
Passive techniques became known mostly with the P0F [10] tool, which is capa-
ble to do OS ﬁngerprinting without requiring active probes. Many other tools
like (AMAP, XProbe, Queso) did implement similar schemes.
Application layer ﬁngerprinting techniques, speciﬁcally for SIP, were ﬁrst de-
scribed in [11,12]. These approaches proposed active as well as passive ﬁnger-
printing techniques. Their common baseline is the lack of an automated approach
for building the ﬁngerprints and constructing the classiﬁcation process. Further-
more, the number of signatures described are minimal which leaves the systems
easily exposed to approaches as the one described by D. Watson et al. [13], that
can fool them by obfuscation of such observable signatures. Recently, the work
by J. Caballero et al. [6] described a novel approach for the automation of Active
Fingerprint generation which resulted in a vast set of possible signatures. It is one
of the few automatic approaches found in the literature and it is based in ﬁnding
a set of queries (automatically generated) that identify diﬀerent responses in the
diﬀerent implementations. While our work addresses speciﬁcally the automation
Advanced Network Fingerprinting
387
for passive ﬁngerprinting, we can imagine this two complementary approaches
working together.
There have been recently similar eﬀorts done in the research community aim-
ing however at a very diﬀerent goal from ours. These activities started with
practical reverse engineering of proprietary protocols [14] and [15] and a simple
application of bioinformatics inspired techniques to protocol analysis [16]. These
initial ideas matured and several other authors reported good results of sequence
alignment techniques in [17], [18], [19] and [20]. Another major approach for the
identiﬁcation of the structure in protocol messages is to monitor the execution
of an endpoint and identify the relevant ﬁelds using some tainted data [21], [22].
Recently, work on identifying properties of encrypted traﬃc has been reported
in [23,24]. These two approaches used probabilistic techniques based on packet
arrivals, interval, packet length and randomness in the encrypted bits to identify
Skype traﬃc or the language of conversation. While all these complementary
works addressed the identiﬁcation of the protocol building blocks or properties
in their packets, we assumed a known protocol and worked on identifying speciﬁc
implementation stacks.
The closest approach to ours, in terms of message comparison, it is the work
developed by M. Chang and C. K.Poon [25] for collection training SPAM de-
tectors. However, in their approach as they focus in identifying human written
sentences, they only consider the lexical analysis of the messages and do not
exploit an underlying structure.
Finally, two other solutions have been proposed in the literature in this research
landscape. Flow based identiﬁcation has been reported in [26], while a grammar/
probabilistic based approach is proposed in [27] and respectively in [28].
7 Conclusions
In this article we described a novel approach for generating ﬁngerprinting sys-
tems based on the structural analysis of protocol messages. Our solution auto-
mates the generation by using both formal grammars and collected traﬃc traces.
It detects important and relevant complex tree like structures and leverages them
for building ﬁngerprints. The applicability of our solution lies in the ﬁeld of in-
trusion detection and security assessment, where precise device/service/stack
identiﬁcation are essential. We have implemented a SIP speciﬁc ﬁngerprinting
system and evaluated its performance. The obtained results are very encourag-
ing. Future work will consist in improving the method and applying it to other
protocols and services. Our work is relevant to the tasks of identifying the pre-
cise vendor/device that has generated a captured trace. We do not address the
reverse engineering of unknown protocols, but consider that we know the un-
derlying protocol. The current approach does not cope with cryptographically
protected traﬃc. A straightforward extension for this purpose is to assume that
access to the original traﬃc is possible. Our main contribution consists in a novel
solution to automatically discover the signiﬁcant diﬀerences in the structure of
388
H.J. Abdelnur, R. State, and O. Festor
protocol compliant messages. We will extend our work towards the natural evo-
lution, where the underlying grammar is unknown.
The key idea is to use a structural approach, where formal grammars and
collected network traﬃc are used. Features are identiﬁed by paths and their
associated values in the parse tree. The obtained results of our approach are very
good. This is due to the fact that a structural message analysis is performed.
Most existing ﬁngerprinting systems are built manually and require a long lasting
development process.
References
1. Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston, A., Peterson, J., Sparks,
R., Handley, M., Schooler, E.: SIP: Session Initiation Protocol (2002)
2. Crocker, D.H., Overell, P.: Augmented BNF for Syntax Speciﬁcations: ABNF
(1997)
3. Buttler, D.: A Short Survey of Document Structure Similarity Algorithms. In:
Arabnia, H.R., Droegehorn, O. (eds.) International Conference on Internet Com-
puting, pp. 3–9. CSREA Press (2004)
4. Broder, A.Z.: On the Resemblance and Containment of Documents. In: SE-
QUENCES 1997: Proceedings of the Compression and Complexity of Sequences
1997, Washington, DC, USA, p. 21. IEEE Computer Society, Los Alamitos (1997)
5. Nash, J.F.: Non-Cooperative Games. The Annals of Mathematics 54(2), 286–295
(1951)
6. Caballero, J., Venkataraman, S., Poosankam, P., Kang, M.G., Song, D., Blum, A.:
FiG: Automatic Fingerprint Generation. In: The 14th Annual Network & Distrib-
uted System Security Conference (NDSS 2007) (February 2007)
7. DParser, http://dparser.sourceforge.net/
8. Comer, D., Lin, J.C.: Probing TCP Implementations. In: USENIX Summer, pp.
245–255 (1994)
9. Nmap, http://www.insecure.org/nmap/
10. P0f, http://lcamtuf.coredump.cx/p0f.shtml
11. Yan, H., Sripanidkulchai, K., Zhang, H.: Incorporating Active Fingerprinting into
SPIT Prevention Systems. In: Third Annual VoIP Security Workshop (June 2006)
12. Scholz, H.: SIP Stack Fingerprinting and Stack Diﬀerence Attacks. Black Hat Brief-
ings (2006)
13. Watson, D., Smart, M., Malan, G.R., Jahanian, F.: Protocol scrubbing: network
security through transparent ﬂow modiﬁcation. IEEE/ACM Trans. Netw. 12(2),
261–273 (2004)
14. Open Source FastTrack P2P Protocol (2007),
http://gift-fasttrack.berlios.de/
15. Fritzler, A.: UnOﬃcial AIM/OSCAR Protocol Speciﬁcation (2007),
http://www.oilcan.org/oscar/
16. Beddoe, M.: The Protocol Informatics Project. Toorcon (2004)
17. Gopalratnam, K., Basu, S., Dunagan, J., Wang, H.J.: Automatically Extracting
Fields from Unknown Network Protocols. In: Systems and Machine Learning Work-
shop 2006 (2006)
18. Wondracek, G., Comparetti, P.M., Kruegel, C., Kirda, E.: Automatic Network
Protocol Analysis. In: Proceedings of the 15th Annual Network and Distributed
System Security Symposium (NDSS 2008) (2008)
Advanced Network Fingerprinting
389
19. Newsome, J., Brumley, D., Franklin, J., Song, D.: Replayer: automatic protocol
replay by binary analysis. In: CCS 2006: Proceedings of the 13th ACM conference
on Computer and communications security, pp. 311–321. ACM, New York (2006)
20. Cui, W., Kannan, J., Wang, H.J.: Discoverer: automatic protocol reverse engineer-
ing from network traces. In: SS 2007: Proceedings of 16th USENIX Security Sym-
posium on USENIX Security Symposium, Berkeley, CA, USA, pp. 1–14. USENIX
Association (2007)
21. Brumley, D., Caballero, J., Liang, Z., Newsome, J., Song, D.: Towards automatic
discovery of deviations in binary implementations with applications to error detec-
tion and ﬁngerprint generation. In: SS 2007: Proceedings of 16th USENIX Secu-
rity Symposium on USENIX Security Symposium, Berkeley, CA, USA, pp. 1–16.
USENIX Association (2007)
22. Lin, Z., Jiang, X., Xu, D., Zhang, X.: Automatic Protocol Format Reverse En-
gineering through Context-Aware Monitored Execution. In: 15th Symposium on
Network and Distributed System Security (2008)
23. Bonﬁglio, D., Mellia, M., Meo, M., Rossi, D., Tofanelli, P.: Revealing skype traﬃc:
when randomness plays with you. SIGCOMM Comput. Commun. Rev. 37(4), 37–
48 (2007)
24. Wright, C.V., Ballard, L., Monrose, F., Masson, G.M.: Language identiﬁcation of
encrypted VoIP traﬃc: Alejandra y Roberto or Alice and Bob? In: SS 2007: Pro-
ceedings of 16th USENIX Security Symposium on USENIX Security Symposium,
Berkeley, CA, USA, pp. 1–12. USENIX Association (2007)
25. Chang, M., Poon, C.K.: Catching the Picospams. In: Hacid, M.-S., Murray, N.V.,
Ra´s, Z.W., Tsumoto, S. (eds.) ISMIS 2005. LNCS (LNAI), vol. 3488, pp. 641–649.
Springer, Heidelberg (2005)
26. Haﬀner, P., Sen, S., Spatscheck, O., Wang, D.: ACAS: automated construction
of application signatures. In: MineNet 2005: Proceedings of the 2005 ACM SIG-
COMM workshop on Mining network data, pp. 197–202. ACM, New York (2005)
27. Borisov, N., Brumley, D.J., Wang, H.J.: Generic Application-Level Protocol Ana-
lyzer and its Language. In: 14th Symposium on Network and Distributed System
Security (2007)
28. Ma, J., Levchenko, K., Kreibich, C., Savage, S., Voelker, G.M.: Unexpected means
of protocol inference. In: IMC 2006: Proceedings of the 6th ACM SIGCOMM
conference on Internet measurement, pp. 313–326. ACM, New York (2006)