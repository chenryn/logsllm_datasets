![Installing software](img/image_07_006.jpg)
然后，我们创建目录，Ansible 将从该目录中获取文件、证书和配置以复制到节点:
```
mkdir files/
```
我们现在将之前创建的所有证书从`certs/`目录复制到`files/`:
```
cp certs/* files/
```
最后，我们在`files/agent.yml`中定义 Flocker 配置文件，内容如下，适配 AWS 区域，修改`hostname`、`access_key_id`、`secret_access_key`:
```
control-service:
 hostname: ""
 port: 4524
dataset:
 backend: "aws"
 region: "us-east-1"
 zone: "us-east-1a"
 access_key_id: ""
 secret_access_key: ""
version: 1
```
这是核心的 Flocker 配置文件，将在每个节点上的`/etc/flocker`中。在这里，您可以指定和配置所选后端的凭据。在我们的例子中，我们选择了基本的 AWS 选项 EBS，所以我们包括了我们的 AWS 凭证。
有了库存、`agent.yml`和`files/`中准备好的所有凭证，我们就可以继续了。
## 安装控制节点
安装控制节点的剧本是`flocker_control_install.yml`。该播放器执行软件安装脚本，复制集群证书、控制节点证书和密钥、节点证书和密钥、客户端证书和密钥、插件证书和密钥，为 SSH、Docker 和 Flocker 配置防火墙打开端口，并启动这些系统服务:
*   `flocker-control`
*   `flocker-dataset-agent`
*   `flocker-container-agent`
*   `flocker-docker-plugin`
最后，它刷新`docker`服务，重新启动它。
让我们运行它:
```
$ export ANSIBLE_HOST_KEY_CHECKING=False
$ ansible-playbook \
-i inventory \
--private-key keys/flocker \
playbooks/flocker_control_install.yml
```
## 安装集群节点
同样，我们用另一个剧本`flocker_nodes_install.yml`安装其他节点:
```
$ ansible-playbook \
-i inventory \
--private-key keys/flocker \
playbooks/flocker_nodes_install.yml
```
步骤和之前差不多，只是这个剧本没有复制一些证书，没有启动`flocker-control`服务。只有弗洛克代理和弗洛克 Docker 插件服务在那里运行。我们等了一段时间，直到 Ansible 退出。
![Installing the cluster nodes](img/image_07_007.jpg)
## 测试是否一切正常
为了检查是否正确安装了 Flocker，我们现在登录控制节点，检查 Flocker 插件是否正在运行(唉，它有`.sock`文件)，然后使用`curl`命令安装`flockerctl`实用程序(参考[https://docs . cluster HQ . com/en/latest/Flocker-features/Flocker CTL . html](https://docs.clusterhq.com/en/latest/flocker-features/flockerctl.html)):
```
$ docker-machine ssh aws-104
$ sudo su -
# ls /var/run/docker/plugins/flocker/
flocker.sock  flocker.sock.lock
# curl -sSL https://get.flocker.io |sh
```
我们现在设置一些`flockerctl:`使用的环境变量
```
export FLOCKER_USER=client
export FLOCKER_CONTROL_SERVICE=54.84.176.7
export FLOCKER_CERTS_PATH=/etc/flocker
```
我们现在可以列出节点和卷(当然，我们还没有卷):
```
flockerctl status
flockerctl list
```
![Testing whether everything is up and running](img/image_07_008.jpg)
现在，我们可以去集群的另一个节点检查 Flocker 集群的连接性(特别是如果插件和代理可以到达并认证到控制节点)，比如`aws-108`，创建一个卷并向其中写入一些数据:
```
$ docker-machine ssh aws-108
$ sudo su -
# docker run -v test:/data --volume-driver flocker \
busybox sh -c "echo example > /data/test.txt"
# docker run -v test:/data --volume-driver flocker \
busybox sh -c "cat /data/test.txt"
example
```
![Testing whether everything is up and running](img/image_07_009.jpg)
如果我们回到控制节点`aws-104`，我们可以通过用 docker 和`flockerctl`命令列出它们来验证是否创建了具有持久数据的卷:
```
docker volume ls
flockerctl list
```
![Testing whether everything is up and running](img/image_07_010.jpg)
太棒了！现在我们可以移除退出的容器，从 Flocker 中删除测试卷数据集，然后我们准备安装 Swarm:
```
# docker rm -v ba7884944577
# docker rm -v 7293a156e199
# flockerctl destroy -d 8577ed21-25a0-4c68-bafa-640f664e774e
```
# 安装和配置 Swarm
我们现在可以用我们最喜欢的方法安装 Swarm 了，如前几章所示。我们将有 **aws-101** 到 **aws-103** 作为经理，其余节点除 **aws-104** 外，都是工人。这个集群可以进一步扩展。实际上，我们将保持 10 节点大小。
![Installing and configuring Swarm](img/image_07_011.jpg)
我们现在添加一个专用的`spark` 覆盖 VxLAN 网络:
```
docker network create --driver overlay --subnet 10.0.0.0/24 spark
```
## 火花的体积
我们现在连接到任何 Docker 主机，并创建一个`75G`大小的卷，用于保存一些持久的 Spark 数据:
```
docker volume create -d flocker -o size=75G -o profile=bronze --
    name=spark
```
这里讨论的选项是`profile`。这是一种存储风格(主要是速度)。如链接[中所述，集群总部为 AWS EBS 维护三个可用的配置文件:](https://docs.clusterhq.com/en/latest/flocker-features/aws-configuration.html#aws-dataset-backend)
*   **黄金** : EBS 供应的 IOPS /名为 io1 的原料药。针对其最大 IOPS 配置- 30 IOPS/GB，最大 20，000 IOPS
*   **银色** : EBS 通用固态硬盘/ API 命名为 gp2
*   **青铜** : EBS 磁性/ API 命名标准
我们可以在 Flocker 控制节点上用`flockerctl list`检查这个卷是否生成。
# 再次部署火花
我们选择一个我们想要运行 Spark 独立管理器的主机，成为`aws-105`，并将其标记为:
```
docker node update --label-add type=sparkmaster aws-105
```
其他节点将托管我们的 Spark 工作人员。
我们在`aws-105`启动星火大师:
```
$ docker service create \
--container-label spark-master \
--network spark \
--constraint 'node.labels.type == sparkmaster' \
--publish 8080:8080 \
--publish 7077:7077 \
--publish 6066:6066 \
--name spark-master \
--replicas 1 \
--env SPARK_MASTER_IP=0.0.0.0 \
--mount type=volume,target=/data,source=spark,volume-driver=flocker 
    \
fsoppelsa/spark-master
```
首先是形象。我发现谷歌图片中包含了一些烦人的东西(比如取消设置一些环境变量，所以从外部进行配置，用`--env`开关，不可能)。因此，我为自己创建了一对 Spark 1.6.2 主映像和工作映像。
然后，`--network`。在这里，我们对这个容器说，连接到用户定义的覆盖网络称为火花。
最后是存储:`--mount`，它与 Docker 卷一起工作。我们将其指定为:
*   使用卷:`type=volume`
*   将容器内的容积安装在`/data` : `target=/data`上
*   使用我们之前创建的`spark`体积:`source=spark`
*   用弗洛克作为`volume-driver`
当您创建服务并装载某个卷时，如果卷不存在，它将被创建。
### 注
当前版本的 Flocker 仅支持 1 的副本。原因是 iSCSI/数据块级装载不能跨多个节点连接。因此，在给定时间点，只有一个服务可以使用复制因子为 1 的卷。这使得 Flocker 在存储和移动数据库数据方面更加有用(尤其是它的用途)。但是在这里，我们将使用它来展示一个在 Spark 主容器的`/data`中有持久数据的小例子。
因此，有了这个配置，让我们添加老黄牛，三个 Spark 工人:
```
$ docker service create \
--constraint 'node.labels.type != sparkmaster' \
--network spark \
--name spark-worker \
--replicas 3 \
--env SPARK\_MASTER\_IP=10.0.0.3 \
--env SPARK\_WORKER\_CORES=1 \
--env SPARK\_WORKER\_MEMORY=1g \
fsoppelsa/spark-worker
```
这里，我们将一些环境变量传递到容器中，以将资源使用限制在每个容器 1 个内核和 1G 内存。
几分钟后，系统启动，我们连接到`aws-105`，端口`8080`，看到这个页面:
![Deploying Spark, again](img/image_07_012.jpg)
## 测试火花
因此，我们访问 Spark shell 并运行 Spark 任务来检查事情是否正常运行。
我们准备一个带有一些 Spark 实用程序的容器，例如`fsoppelsa/spark-worker`，并运行它来使用 Spark 二进制`run-example`计算 Pi 的值: