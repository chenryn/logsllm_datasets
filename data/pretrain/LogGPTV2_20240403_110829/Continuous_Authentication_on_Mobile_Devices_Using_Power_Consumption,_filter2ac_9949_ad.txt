5.0 35.8
2.7 21.0 12.1 47.8
6.7
8.5
B 30.1 12.2 14.8
C 17.1
2.5
D 42.1
E 19.8
r
e
s
U
t
s
e
T
8.9
0.8
B
C
A
%
Baseline Users
D
s A 20.4 40.8 25.1 30.6
5.4 52.3 11.6
7.5 90.7
7.4
E
5.7
B 3.6
1.8
C 13.5 71.2
2.8
D 2.2 24.8 71.1
5.5
E 11.9 61.4 21.5 64.0 18.2
r
e
s
U
t
s
e
T
Table 5. Randomly selected 5 users
from mixture of both apps for power
modality
Baseline Users
D
B
A
%
E
C
5.4 16.3
s A 10.8 11.3 11.3
2.7 13.3
B 8.8 18.3 17.1
3.3 15.8
C 7.8
2.0 15.3
3.2 17.0 41.6 22.3
D 10.6
E 3.9
4.5
0.5 16.0
r
e
s
U
t
s
e
T
4.7
increases in Table 5. User’s behavior is not similar across Chrome and Facebook
applications and thus the identiﬁcation accuracy is dramatically reduced when
we mix the datasets. In Fig. 7, we present the ROC curves for overall performance
of the system on the combined data of Chrome and Facebook with the context
removed. It can be observed that the overall performance has deteriorated.
8 Lessons Learned
It is not uncommon to encounter very noisy data when mining in the real-world.
The same is the case with the behavioral biometrics dataset collected for this
research. Despite moderately controlling the environment during data collection,
the rate of anomalies due to noise is high, in comparison to misclassiﬁcation error.
Most research work in continuous authentication resort to one of two techniques:
(1) Data cleansing by removing chunks of data whose class predictions contradict
the ground truth during training, and (2) Assume the data to be clean, and
consider the contradictions as misclassiﬁcation error during testing. In truth,
the nature of the data is changing so constantly that it is required to not only
assume but explicitly model the noise. This research, therefore, considered the
rate of anomalies generated by a user while testing against his own baseline
to be a virtue of his own user proﬁle. As seen in Tables 3 and 4, the rate of
anomalies considered “normal” for diﬀerent users cover a wide range of values.
This indicates the assumption could be true, resulting in the need to build models
that are error-aware.
422
R. Murmuria et al.
Fig. 7. ROC from ensemble model without application context
This research also showed that authentication accuracy is aﬀected by applica-
tion context; any user’s behavior diﬀers from application to application. The per-
formance of the authentication engine therefore depends not only on which mobile
application is being used (application context), but also on whether the mobile
application can be modeled well or not. Diﬀerent categories of applications can be
identiﬁed, as described below, that will show high false accepts and false rejects
depending upon how users are meant to interact with the application.
1. Randomized UI
2. Static UI
Mobile Applications that have completely randomized UI will have high false
rejects. Some examples include Game applications that appear randomized
on all of the modalities used in this research.
On the other hand, apps that have completely static UI can have very high
false accepts. Some examples include Camera, Flashlight, Sound Recorder
and Navigation. While these apps appear static from the point of view of
the chosen biometric modalities, some of them can be incorporated into the
system by introducing modalities such as voice recognition.
3. Mixed UI
In general, apps that have a mix of UI inputs yield the best results for
authentication. Chrome and Facebook were tested in this research, but other
apps in this category include email and word processors.
Since diﬀerent applications need diﬀerent levels of security, it can be argued
that some apps that need higher data security can employ the use of a rich set
of user interactions in order to beneﬁt from an overall improved authentication
performance from their users.
9 Future Work
As discussed in Sect. 4, we presented results using a dataset that was generated
while controlling environmental interference. One direct progression of this work
Continuous Authentication on Mobile Devices Using Power Consumption
423
is to study the impact on performance when allowing volunteers to perform their
daily routine tasks. Such a test would warrant the need for much longer data col-
lection sessions where the volunteer uses the mobile device over multiple days. In
addition, we believe that further investigation of the scalability of the individu-
alized parameters when we increase the number of users, apps, and modalities is
warranted. The current testing was done to determine the eﬃcacy of identifying
users through their device interactions. Future work will assess the usability of
the approach now that the eﬃcacy has been established.
10 Conclusion
We have introduced a novel system that performs authentication on Android
mobile devices by leveraging user behavior captured though three distinct modal-
ities – power consumption, touch gestures, and physical movement (using both
accelerometer and gyroscope). To the best of our knowledge, we are one of the
ﬁrst research groups to propose the use of mobile power measurements and lever-
age the application context in the authentication process. We further demon-
strated that by using individualized thresholds for rate of anomalies expected
from every user, we were able to improve performance signiﬁcantly. To that end,
we implemented a full set of algorithms and applications for the measurement,
evaluation, and deployment of the framework to Nexus 5 Android phone and
demonstrated our capability to perform continuous authentication in real time.
By leveraging data collected from 73 volunteer participants, we evaluated our
system while the end-user was utilizing two popular applications – Chrome and
Facebook. We were able to achieve good performance with an equal error rate
between 6.1 % and 6.9 % for 59 selected users who had generated suﬃcient data
for evaluation. Given that the approach in this paper solves the problem of noise
and context in very deployable ways, it is more viable as a real-world solution
than other competing approaches in literature.
References
1. Aviv, A.J., Gibson, K., Mossop, E., Blaze, M., Smith, J.M.: Smudge attacks on
smartphone touch screens. In: Proceedings of the 4th USENIX Conference on
Oﬀensive Technologies, pp. 1–7. USENIX Association (2010)
2. Muslukhov, I., Boshmaf, Y., Kuo, C., Lester, J., Beznosov, K.: Know your enemy:
the risk of unauthorized access in smartphones by insiders. In: Proceedings of
the 15th International Conference on Human-Computer Interaction with Mobile
Devices and Services, pp. 271–280. ACM (2013)
3. Karlson, A.K., Brush, A.J., Schechter, S.: Can i borrow your phone?: understanding
concerns when sharing mobile phones. In: Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems, pp. 1647–1650. ACM (2009)
4. Clarke, N.L., Furnell, S.M.: Advanced user authentication for mobile devices. Com-
put. Secur. 26, 109–119 (2007)
5. Shi, E., Niu, Y., Jakobsson, M., Chow, R.: Implicit authentication through learning
user behavior. In: Burmester, M., Tsudik, G., Magliveras, S., Ili´c, I. (eds.) ISC 2010.
LNCS, vol. 6531, pp. 99–113. Springer, Heidelberg (2011)
424
R. Murmuria et al.
6. Riva, O., Qin, C., Strauss, K., Lymberopoulos, D.: Progressive authentication:
deciding when to authenticate on mobile phones. In: Proceedings of the 21st
USENIX Security Symposium (2012)
7. Frank, M., Biedert, R., Ma, E., Martinovic, I., Song, D.: Touchalytics: on the
applicability of touchscreen input as a behavioral biometric for continuous authen-
tication. IEEE Trans. Inf. Forensics Secur. 8, 136–148 (2013)
8. Bo, C., Zhang, L., Jung, T., Han, J., Li, X.-Y., Wang, Y.: Continuous user identiﬁ-
cation via touch and movement behavioral biometrics. In: 2014 IEEE International
Conference on Performance Computing and Communications (IPCCC), pp. 1–8.
IEEE (2014)
9. Yampolskiy, R.V., Govindaraju, V.: Behavioural biometrics: a survey and classiﬁ-
cation. Int. J. Biometrics 1, 81–113 (2008)
10. Kwapisz, J.R., Weiss, G.M., Moore, S.A.: Cell phone-based biometric identiﬁcation.
In: 2010 Fourth IEEE International Conference on Biometrics: Theory Applications
and Systems (BTAS), pp. 1–7. IEEE (2010)
11. Killourhy, K.S., Maxion, R.A.: Comparing anomaly-detection algorithms for key-
stroke dynamics. In: 2009 IEEE/IFIP International Conference on Dependable
Systems and Networks, DSN 2009, pp. 125–134. IEEE (2009)
12. Shen, C., Cai, Z., Maxion, R.A., Xiang, G., Guan, X.: Comparing classiﬁcation
algorithm for mouse dynamics based user identiﬁcation. In: 2012 IEEE Fifth Inter-
national Conference on Biometrics: Theory, Applications and Systems (BTAS), pp.
61–66 (2012)
13. Zhang, L., Tiwana, B., Qian, Z., Wang, Z., Dick, R.P., Mao, Z.M., Yang, L.: Accu-
rate online power estimation and automatic battery behavior based power model
generation for smartphones. In: Proceedings of the Eighth IEEE/ACM/IFIP Inter-
national Conference on Hardware/Software Codesign and System Synthesis, pp.
105–114. ACM (2010)
14. Murmuria, R., Medsger, J., Stavrou, A., Voas, J.M.: Mobile application and device
power usage measurements. In: 2012 IEEE Sixth International Conference on Soft-
ware Security and Reliability (SERE), pp. 147–156 (2012)
15. Shye, A., Scholbrock, B., Memik, G.: Into the wild: studying real user activity
patterns to guide power optimizations for mobile architectures. In: Proceedings of
the 42nd Annual IEEE/ACM International Symposium on Microarchitecture, pp.
168–178. ACM (2009)
16. Barbar´a, D., Domeniconi, C., Rogers, J.P.: Detecting outliers using transduction
and statistical testing. In: Proceedings of the 12th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, pp. 55–64. ACM (2006)
17. Keogh, E., Lin, J., Fu, A.: Hot sax: eﬃciently ﬁnding the most unusual time
series subsequence. In: Fifth IEEE International Conference on Data Mining. IEEE
(2005)
18. Vovk, V., Gammerman, A., Saunders, C.: Machine-learning applications of algo-
rithmic randomness. In: Proceedings of the Sixteenth International Conference on
Machine Learning (ICML 1999), pp. 444–453 (1999)