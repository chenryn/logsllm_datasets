title:DNS to the rescue: discerning content and services in a tangled
web
author:Ignacio Bermudez and
Marco Mellia and
Maurizio M. Munafò and
Ram Keralapura and
Antonio Nucci
DNS to the Rescue: Discerning Content
and Services in a Tangled Web
Ignacio N. Bermudez
Politecnico di Torino,
Torino, Italy
Marco Mellia
Politecnico di Torino,
Torino, Italy
Maurizio M. Munafò
Politecnico di Torino,
Torino, Italy
PI:EMAIL
PI:EMAIL
PI:EMAIL
Ram Keralapura
Narus Inc.,
Sunnyvale, CA
PI:EMAIL
Antonio Nucci
Narus Inc.,
Sunnyvale, CA
PI:EMAIL
ABSTRACT
A careful perusal of the Internet evolution reveals two major
trends - explosion of cloud-based services and video stream-
ing applications. In both of the above cases, the owner (e.g.,
CNN, YouTube, or Zynga) of the content and the organiza-
tion serving it (e.g., Akamai, Limelight, or Amazon EC2) are
decoupled, thus making it harder to understand the associ-
ation between the content, owner, and the host where the
content resides. This has created a tangled world wide web
that is very hard to unwind, impairing ISPs’ and network
administrators’ capabilities to control the traﬃc ﬂowing in
their networks.
In this paper, we present DN-Hunter, a system that lever-
ages the information provided by DNS traﬃc to discern the
tangle. Parsing through DNS queries, DN-Hunter tags traf-
ﬁc ﬂows with the associated domain name. This association
has several applications and reveals a large amount of use-
ful information: (i) Provides a ﬁne-grained traﬃc visibility
even when the traﬃc is encrypted (i.e., TLS/SSL ﬂows), thus
enabling more eﬀective policy controls, (ii) Identiﬁes ﬂows
even before the ﬂows begin, thus providing superior net-
work management capabilities to administrators, (iii) Un-
derstand and track (over time) diﬀerent CDNs and cloud
providers that host content for a particular resource, (iv)
Discern all the services/content hosted by a given CDN or
cloud provider in a particular geography and time interval,
and (v) Provides insights into all applications/services run-
ning on any given layer-4 port number.
We conduct extensive experimental analysis and show re-
sults from real traﬃc traces (including FTTH and 4G ISPs)
that support our hypothesis. Simply put, the information
provided by DNS traﬃc is one of the key components re-
quired for understanding the tangled web, and bringing the
ability to eﬀectively manage network traﬃc back to the op-
erators.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’12, November 14–16, 2012, Boston, Massachusetts, USA.
Copyright 2012 ACM 978-1-4503-1705-4/12/11 ...$15.00.
Categories and Subject Descriptors
C.2 [Computer-Communication Networks]: Miscella-
neous; C.4 [Performance of Systems]: Measurement Tech-
niques
General Terms
Measurement, Performance
Keywords
DNS, Service Identiﬁcation.
1.
INTRODUCTION
In the past few years, the Internet has witnessed an ex-
plosion of cloud-based services and video streaming appli-
cations.
In both cases, content delivery networks (CDN)
and/or cloud computing services are used to meet both scal-
ability and availability requirements. An undesirable side-
eﬀect of this is that it decouples the owner of the content and
the organization serving it. For example, CNN or YouTube
videos can be served by Akamai or Google CDN, and Far-
mville game can be accessed from Facebook while running on
Amazon EC2 cloud computing platform, with static content
being retrieved from a CDN. This may be even more com-
plicated since various CDNs and content owners implement
their own optimization mechanisms to ensure “spatial” and
“temporal” diversity for load distribution. In addition, sev-
eral popular sites like Twitter, Facebook, and Google have
started adopting encryption (TLS/SSL) to deliver content to
their users [1]. This trend is expected to gain more momen-
tum in the next few years. While this helps to protect end-
users’ privacy, it can be a big impediment for eﬀective secu-
rity operations since network/security administrators now
lack the required traﬃc visibility. The above factors have
resulted in “tangled” world wide web which is hard to un-
derstand, discern, and control.
In the face of this tangled web, network/security adminis-
trators seek answers for several questions in order to manage
their networks: (i) What are the various services/applications
that contribute to the traﬃc mix on the network? (ii) How
to block or provide certain Quality of Service (QoS) guar-
antees to select services?
While the above questions seem simple, the answers to
these questions are non-trivial. There are no existing mech-
413anisms that can provide comprehensive solutions to address
the above issues. Consider the ﬁrst question above. A typ-
ical approach currently used by network administrators is
to rely on DPI (deep packet inspection) technology to iden-
tify traﬃc based on packet-content signatures. Although
this approach is very eﬀective in identifying unencrypted
traﬃc, it severely falls short when the traﬃc is encrypted.
Given the popularity of TLS in major application/content
providers, this problem will amplify over time, thus render-
ing typical DPI technology for traﬃc visibility ineﬀective.
A simple approach that can augment a DPI device to iden-
tify encrypted traﬃc is to inspect the certiﬁcate during the
initial handshake1. Although this approach gives some vis-
ibility into the applications/services, it still cannot help in
identifying speciﬁc services. For instance, inspecting a cer-
tiﬁcate from Google will only reveal that it is Google service,
but cannot diﬀerentiate between Google Mail, Google Docs,
Blogger, and Youtube. Thus administrators need a solution
that will provide ﬁne-grained traﬃc visibility even when the
traﬃc is encrypted.
Let us now focus on the second question which is even
more complex. Consider the scenario where the network ad-
ministrator wants to block all traﬃc to Zynga games, but
prioritize traﬃc for the DropBox service. Notice that both
of these services are encrypted, thus severely impairing a
DPI-based solution. Furthermore, both of these services
use the Amazon EC2 cloud. In other words, the server IP-
address for both of these services can be the same. Thus us-
ing IP-address ﬁltering does not accomplish the task either.
In addition the IP-address can change over time according
to CDN optimization policies. Another approach that can
be used in this context is to introduce certain policies di-
rectly into the local name servers. For example, the name
server does not resolve the DNS query for zynga.com in the
above example, thus blocking all traﬃc to Zynga. Although
this approach can work eﬀectively for blocking certain ser-
vices, it does not help when administrators are interested in
prioritizing traﬃc to certain services. Administrators face
the same situation when they want to prioritize traﬃc to
mail.google.com and docs.google.com, while de-prioritizing
traﬃc blogspot.com and youtube.com since all of these ser-
vices can run over HTTPS on the same Google platform.
In this work, we propose DN-Hunter, a novel traﬃc mon-
itoring system that addresses all of the above issues in a
completely automated way. The main intuition behind DN-
Hunter is to correlate the DNS queries and responses with
the actual data ﬂows in order to eﬀectively identify and label
the data ﬂows, thus providing a very ﬁne grained visibility
of traﬃc on a network. It helps network administrators to
keep track of the mapping between users, content owners,
and the hosts serving the content even when this mapping
is changing over time, thus enabling them to enforce poli-
cies on the traﬃc at any time with no manual intervention.
In addition, network administrators could use DN-Hunter to
dynamically reroute traﬃc in order to use more cost-eﬀective
links (or high bandwidth links as the policies might dictate)
even as the content providers change the hosts serving the
content over time for load balancing or other economic rea-
sons.
At a high level, the methodology used in DN-Hunter seems
to be achievable by performing a simple reverse DNS lookup
1During TLS negotiation, the server certiﬁcate contains a
plain text string with the name being signed.
using the server IP-addresses seen in traﬃc ﬂows. However,
using reverse DNS lookup does not help since it does not
return accurate domain (or the sub-domain) names used in
traﬃc ﬂows.
The main contributions of this work are:
• We propose a novel tool, DN-Hunter, that can pro-
vide ﬁne-grained traﬃc visibility to network adminis-
trators for eﬀective policy controls and network man-
agement. Unlike DPI technology, using experiments on
real traces, we show that DN-Hunter is very eﬀective
even when the traﬃc is encrypted clearly highlight-
ing its advantages when compared to the current ap-
proaches. DN-Hunter can be used either for active or
passive monitoring, and can run either as a stand-alone
tool or can easily be integrated into existing monitor-
ing systems, depending on the ﬁnal intent.
• A key property of DN-Hunter is its ability to identify
traﬃc even before the data ﬂow starts. In other words,
the information extracted from the DNS responses can
help a network management tool to foresee what kind
of ﬂows will traverse the network. This unique abil-
ity can empower proactive traﬃc management policies,
e.g., prioritizing all TCP packets in a ﬂow (including
the critical three-way-handshake), not just those pack-
ets that follow a positive DPI match.
• We use DN-Hunter to not only provide real-time traf-
ﬁc visibility and policy controls, but also to help gain
better understanding of how the dynamic web is or-
ganized and evolving today. In other words, we show
many other applications of DN-Hunter including: (i)
Spatial Discovery: Mapping a particular content to the
servers that actually deliver them at any point in time.
(ii) Content Discovery: Mapping all the content deliv-
ered by diﬀerent CDNs and cloud providers by aggre-
gating the information based on server IP-addresses.
(iii) Service Tag Extraction: Associating a layer-4 port
number to the most popular service seen on the port
with no a-priori information.
• We conduct extensive experiments using ﬁve traﬃc
traces collected from large ISPs in Europe and North
America. The traces contain full packets including the
application payload, and range from 3h to 24h. These
ISPs use several diﬀerent access technologies (ADSL,
FTTH, and 3G/4G) to provide service to their cus-
tomers, thus showing that DN-Hunter is eﬀective in
several diﬀerent contexts. Furthermore, DN-Hunter
has been implemented and currently deployed in three
operative vantage points since March 2012.
Although DN-Hunter is a very eﬀective tool in any net-
work administrator’s arsenal to address issues that do not
have a standard solution today, there are some limitations as
well. First, the eﬀectiveness of DN-Hunter depends on the
visibility into the DNS traﬃc of the ISP/enterprise. In other
words, DN-Hunter will be rendered useless if it does not have
visibility into the DNS queries and responses along with the
data ﬂows from the end-users. Second, DN-Hunter does not
help in providing visibility into applications/services that do
not depend on DNS. For instance, some peer-to-peer appli-
cations are designed to work with just IP-addresses and DN-
Hunter will be unable to label these ﬂows. Third, automatic
414Table 1: Dataset description.
Trace
Start Duration Peak DNS #Flows
[GMT]
Responses
TCP
US-3G
EU2-ADSL
EU1-ADSL1
EU1-ADSL2
EU1-FTTH
15:30
14:50
8:00
8:40
17:00
3h
6h
24h
5h
3h
Rate
7.5k/min
22k/min
35k/min
12k/min
3k/min
4M
16M
38M
5M
1M
and smart algorithms must be devised to dig into the infor-
mation exposed by DN-Hunter. In this paper, we provide
some examples of how the information extracted from the
DNS traﬃc can be used. We believe that the applications
of DN-Hunter are not limited to the ones presented in this
work, and novel applications can leverage the information
exposed by DN-Hunter.
The rest of the paper is organized as follows: Sec. 2 intro-
duces the datasets we use in this paper. In Sec. 3 we describe
the architecture and design details of DN-Hunter. Sec. 4
presents some of our advanced analytics modules while Sec. 5
provides extensive experimental results. We discuss correct
dimensioning and deployment issues in Sec. 6. We highlight
the major diﬀerences between DN-Hunter and some existing
approaches in Sec. 7 and conclude the paper in Sec. 8.
2. DATASETS AND TERMINOLOGY
In this section, we provide insight into the datasets used
for experimental evaluation along with some basic DNS ter-
minology used henceforth in this paper.
2.1 Experimental datasets
All our datasets are collected at the Points-of-Presence
(PoP) of large ISPs where the end customers are connected
to the Internet. The ﬁve datasets we use in this paper are
reported in Tab. 1.
In all of these traces activities from
several thousands of customers are monitored. In all the 5
datasets, we capture full packets including the application
payload without any packet losses. For the sake of brevity,
Tab. 1 only reports the start time and trace duration, the
peak time DNS response rate, and the number of TCP ﬂows
that were tracked. Each trace corresponds to a diﬀerent
period in 2011. The ﬁrst dataset is a trace collected from
a large North American 3G/4G mobile operator GGSN ag-
gregating traﬃc from a citywide area. The second dataset
originates from a European ISP (EU2) which has about 10K
customers connected via ADSL technology. The last three
datasets correspond to traﬃc collected from diﬀerent van-
tage points in the same European ISP (EU1). The vantage
points are located in three diﬀerent cities - two ADSL PoPs
and one Fiber-To-The-Home (FTTH) access PoP.
Currently, DN-Hunter has been implemented in a com-
mercial tool as well as Tstat [2]. The latter has been de-
ployed in all the three vantage points in EU1 and has been
successfully labeling ﬂows since March 2012. Some of the
results in this paper are derived from this deployment.