and the return statement becomes an inner output vari-
able. Note, that during the protocol execution all inner
wires are not assigned to any party, instead they con-
nect global and sub circuits. Yet, to keep compatibility
with CBMC-GC a concrete assignment for the party PA
is speciﬁed. The later exported mapping information is
used to distinguish between inner wires and actual input
wires of both parties. In the same step, the global func-
tion dot product(), printed in Listing 4, is transformed
by ParCC to replace and unroll the loop.
1 void d o t _ p r o d u c t () {
2
int I N P U T _ A _ a [100] , I N P U T _ B _ b [100];
int res = 0;
3
4
5
6
7
8
9
10
11
12
13
int O U T P U T _ S U B _ a [100];
int O U T P U T _ S U B _ b [100];
int i ;
for ( i = 0; i <= 99; i ++) {
O U T P U T _ S U B _ a [ i ] = I N P U T _ A _ a [ i ];
O U T P U T _ S U B _ b [ i ] = I N P U T _ B _ b [ i ];
}
int I N P U T _ A _ S U B _ r e s [100];
for ( i = 0; i <= 99; i ++)
res += I N P U T _ A _ S U B _ r e s [ i ];
int O U T P U T _ r e s = res ;
14
15 }
Listing 4: Rewritten dot product(). The loop has been re-
placed by inner input/output variables (marked with SUB).
Therefore,
the two input arrays INPUT A a and
INPUT B b are exposed as inner output variables begin-
ning in Line 4. Therefore, two new output arrays using
CBMC-GC notation are added based on the statically de-
termined information about parallel variables. Further-
more, an inner input array for the intermediate results is
introduced in Line 11. Finally, the reduction statement is
substituted by synthesized additions over all intermediate
results in Line 13.
In the third and fourth compilation step, the two cir-
cuits are compiled and the mapping of wires between
global and sub circuits is exported.
5
Inter-Party Parallelization (IPP)
In this section, we describe a novel protocol extension
to Yao’s protocol to balance computation between par-
ties, assuming symmetric efﬁciently parallelizable func-
tionalities. We refer to this protocol extension as inter-
party parallelization (IPP). Without compromising secu-
rity, we show in § 6 that the protocol runtime can be re-
duced in practical applications when using IPP. This is
also the case when using only one CPU core per party.
We recap the initial motivation: The computational
costs that each party has to invest in semi-honest Yao
is driven by the encryption and decryption costs of the
garbled tables as well as the communication costs. Con-
sidering the garbling technique with the least number of
cryptographic operations, namely GRR combined with
free-XOR, the generator has to compute four ciphertexts
per non-linear gate, whereas the evaluator has to compute
only one ciphertext per non-linear gate. When consider-
ing the communication optimal half-gate approach [36],
the generator has to compute four and the evaluator two
ciphertexts per non-linear gate. Assuming two parties
that are equipped with similar computational power, a
better overall resource utilization would be achieved, if
both parties could be equally involved in the computa-
tion process. This can be realized by sharing the roles
generator and evaluator. Consequently, the overall pro-
tocol runtime could be decreased. Figure 3 illustrates this
efﬁciency gain.
In the following sections we ﬁrst discuss how to ex-
tend Yao’s protocol to use IPP for purely parallel func-
tionalities. In a second step we generalize this approach
by showing how mixed functionalities proﬁt from IPP.
5.1 Parallel functionalities
We assume that two parties PA and PB agree to compute a
functionality f (x,y) with x being PA’s input and y being
PB’s input. Moreover, we assume f (x,y) to be paralleliz-
able into two (or more) sub functionalities f0, . . . , fn:
f (x,y) = f0(x,y)(cid:30) f1(x,y)(cid:30) . . .(cid:30) fn(x,y).
Given such a decomposition, all sub functionalities
can be computed independently with any TPC proto-
cols (secure against semi-honest adversaries) without
USENIX Association  
24th USENIX Security Symposium  537
7
(a) Original
(b) Independence
analysis
(c) Inter-party
Parallelization
Figure 3: The idea and performance gain of IPP visualized.
The OT phase and output sharing are omitted. In Figure 3(a)
the sequential execution of Yao’s protocol is visualized. Given
a parallel decomposition by two circuits representing parallal
program regions as displayed in Figure 3(b), the protocol run-
time can be reduced when sharing the roles generator and eval-
uator, as displayed in Figure 3(c).
any sacriﬁces towards the security [12]. This obser-
vation allows us to run two independent executions of
Yao’s protocol, each for one half of f ’s sub functional-
ities, instead of computing f with a single execution of
Yao’s protocol. Hence, PA could garble one half of f ’s
sub functionalities, for example feven = f0, f2, . . ., and
PA could evaluate the other half fodd = f1, f3, . . .. Vice
versa, PB could evaluate feven and garble fodd. Follow-
ing this approach, PA and PB have to switch their roles
for the OT phase of Yao’s protocol. In the output phase,
both parties share their output labels and description ta-
bles (ODT) with each other.
Analytical performance gain. As discussed, the com-
putational costs for Yao’s protocol are dominated by en-
crypting and decrypting garbled truth tables. Thus, ide-
alizing and highly abstracted, the time spent to perform
a computation ttotal is dominated by the time to garble a
circuit tgarble. Using GRR with free-XOR and assuming
that tgarble is approximately four times the time to evalu-
ate a circuit teval, by symmetrically sharing this task the
total time could be reduced to:
t(cid:31)total ≈
≈ 2.5·teval.
This result
translates to a theoretical speed-up of
ttotal/t(cid:31)total = 4/2.5 = 1.6. When using the half-gate ap-
proach the approximate computational speed-up is 1.33.
(4·teval +teval)
(tgarble +teval)
2
≈
2
5.2 Mixed functionalities
To exploit IPP in mixed functionalities, a protocol ex-
tension is required, allowing to switch from sequential
(dedicated roles) to IPP (shared roles) without violating
the privacy property of TPC. Therefore, we introduce the
notion of transfering roles to securely interchange be-
tween IPP and sequential execution.
Transferring roles We introduce the idea of transfer-
ring roles in two steps. First we sketch an insecure pro-
tocol, which is then made secure in a second step. To
switch the roles of evaluator and generator during execu-
tion, we consider two parties PA, PB and the sequentially
composed functionality f (x,y) = f2( f1(x,y),x,y). In the
following description, f1 is computed using Yao’s proto-
col with PA being generator and PB being evaluator, f2 is
computed with reversed roles.
The transfer protocol begins by computing f1(x,y)
with Yao’s original protocol. Once f1 is computed, the
roles have to be switched. Na¨ıvely, the parties ‘open’
the circuit by interchanging output wires and the ODT.
This reveals the intermediate result o1 = f1(x,y) to both
parties. In the second phase of the protocol, f2 is com-
puted using Yao’s protocol. This time, PA and PB switch
roles, such that PB garbles f2 and PA evaluates f2. The de-
crypted output bits o1 = f1(x,y) are used by PA as input in
the OT protocol. After garbling f2, the output labels and
the ODT are shared between both parties. This proto-
col resembles a pause/continue pattern and preserves cor-
rectness. However, this protocol leaks o1 to both parties,
which violates the privacy requirement of TPC. There-
fore, we propose to use an XOR-blinding during the role
switch. The full protocol is printed below.
Protocol: Transferring Roles
PA and PB agree to securely compute the se-
quentially decomposable functionality f (x,y) =
f2( f1(x,y),x,y) without revealing the intermediate
result f1(x,y) to either party, where x is PA’s input
bit string, y is PB’s input bit string. The protocol
consists of two phases, one per sub functionality.
Phase 1: Secure computation of f1(x,y)
1.
f1 is extended with a XOR blinding for ev-
ery output bit. Thus, the new output o(cid:31)1 =
f (cid:31)1(x,y||yr) = f1(x,y)⊕ yr is calculated by xor-
ing the output of f1 with additional, randomly
drawn input bits by the evaluator of f1.
2. PA and PB securely compute f (cid:31)1 using Yao’s pro-
tocol. We assume PA to be the generator. Addi-
tional randomly drawn input bits are then input
of PB.
3. The blinded output o(cid:31)1 of the secure computa-
tion is only made visible to the generator PA.
This is realized by transmitting the output wire
labels to PA, but not sharing the ODT with PB.
Phase 2: Secure computation of f2(o1,x,y)
1. The circuit representing f2 is extended with
a XOR unblinding for every input bit of o(cid:31)1.
Hence, f (cid:31)2(o(cid:31)1,x,y,yr) = f2(o(cid:31)1 ⊕ yr,x,y).
538  24th USENIX Security Symposium 
USENIX Association
8
PAPBGENEVLtPAPBGENGENtEVLEVLtPAPBGENEVLGENEVL2. PA and PB securely compute f (cid:31)2 using Yao’s pro-
tocol. We assume PB to be the generator. PA
provides the input o(cid:31)1 and PB provides the input
bits for the blinding with yr.
3. The output of the computation is shared with
both parties.
We observe that, informally speaking the protocol pre-
serves privacy, since the intermediate state o1 is shared
securely between both parties. A detailed formal proof
on sequential decomposed functionalities is given by
Hazay and Lindell [12, page 42ff]. Correctness is pre-
served due to blinding and unblinding with the equal bit
string yr:
f (cid:31)2( f (cid:31)1(x,y||yr),x,y,yr) = f (cid:31)2( f1(x,y)⊕ yr,x,y,yr)
= f2( f1(x,y)⊕ yr ⊕ yr,x,y)
= f2( f1(x,y),x,y).
Finally, we note that transferring roles protocol can
further be improved. Demmler et al. [8] presented an
approach to securely share a state of Yao’s protocol that
uses the point-and-permute bits [27] as a blinding. This
approach has equivalent costs in the number of cryp-
tographic operations, yet removes the need of an ODT
transfer. Our implementation uses this optimization.
Transferring roles for mixed functionalities. With
the idea of transferring roles, IPP can be realized for
mixed functionalities. In the following paragraphs, we
show how to switch from IPP to sequential computation.
Switching into the other direction, namely from sequen-
tial to IPP can be realized analogously. With protocols to
switch in both directions, it is possible to garble and eval-
uate any functionality that consists of an arbitrary num-
ber of sequential and parallel regions.
To show the switch from IPP to sequential computa-
tion, we assume a functionality that is sequentially de-
composable into a parallel and a sequential functionality:
f (x,y) = f3( f1(x,y)(cid:28) f2(x,y),x,y).
Note that f1,
f2 and f3 could further be composed of
any sequential and parallel functionalities. We observe
that f3 can be merged with f1 (or f2) into one combined
functionality fc. Thus, f (x,y) can also be decomposed
as f (x,y) = fc( f2(x,y),x,y) with fc being the sequen-
tial composition of f3 and f1. Given such a decomposi-
tion, fc and f2 can be computed with alternating roles in
Yao’s protocol by following the transferring roles proto-
col. Hence, fc could be garbled by PA while f2 could be
garbled by PB to securely compute f .
Figure 4: The IPP protocol for a mixed functionality with a
switch from parallel to sequential computation. Functionality
f1 (cid:28) f2 is garbled in parallel using IPP, f3 is garbled sequen-
tially in combination with f1. No interaction between parties is
shown. The blinded output o(cid:31)1 of f1 is only made visible to PA
and used as additional input for the computation of f2 using the
transferring roles protocol.
As a second observation we note that the output of f2
is not required to start the computation of fc. Therefore,
the computation of fc can start in parallel to the compu-
tation of f2. This inter-party parallelism can be exploited
to achieve further speed-ups. Figure 4 illustrates this ap-
proach. Party PA garbles fc and PB garbles f2. The ﬁrst
part of fc, namely f1 can be garbled in parallel to f2.
Once the blinded output o(cid:31)1 of f2 is computed, the par-
ties can start computing the second part of fc, namely
f3. Switching from sequential to IPP computation can be
realized in the same manner.
We remark that FGP, CGP and IPP can be combined
to achieve even further speed-ups. Therefore, every par-
allel region has ﬁrst be decomposed in two parts for IPP.
If the parts can further be decomposed in parallel func-
tionalities, these could be garbled following the ideas of
CGP and FGP.
Overhead.
Investigating the overhead of IPP, we ob-
serve that during the cost intensive garbling and evalua-
tion phase, no computational complexity is added. Par-
ticularly, the number of cryptographic operations and
messages is left unchanged. However, when using OT
Extension, a constant one-time overhead for base OTs
in the size of the security parameter k is introduced to
establish bi-directional OT Extension. To switch from
and to IPP in mixed functionalities, additional OTs in the
size of the intermediate state are required. Thus, the per-
formance gain through IPP for mixed functionalities not
only depends on the ratio between parallel and sequen-
tial regions, but also on the ratio of circuit size and shared
state. These ratios are application dependent. A practical
evaluation of the trade-off between overhead and perfor-
mance gain is presented in § 6.5.
USENIX Association  
24th USENIX Security Symposium  539
9
EVLGENEVLGENGENEVLPAPBf1,f2f3xyyro1'OTPOTPOTPOTPInp5.3 Security implications and applications
6 Evaluation
As discussed in the previous section, Yao’s protocol and
IPP are secure against semi-honest adversaries. Never-
theless, semi-honest Yao’s garbled circuits are often used
to bootstrap TPC protocols secure against active adver-
saries. Therefore, in this section, we sketch the security
implications of IPP and its compatibility with the most
common techniques to strengthen Yao’s protocol. Fur-
thermore, we depict applications and protocols the could
proﬁt from IPP.
Yao’s original protocol is already secure against ma-
licious evaluators (when using an OT protocol secure
against malicious adversaries), yet not secure against ma-
licious generators. We note that this one-sided secu-
rity does not longer hold when using IPP because both
parties incorporate the role of a circuit generator. Con-
sequently, cut-and-choose protocols [24], which garble
multiple copies of the same circuit to achieve active se-
curity, are incompatible with IPP because they are built
on the assumption that only one party can actively ma-
nipulate the protocol. A similar observation can be made
for Dual-execution protocols [29, 16] that prevent an ac-
tive adversary from learning more than a small number
of bits during the protocol execution. Even so the con-
cept of Dual-execution is close the the idea of IPP, i.e.,
symmetrically sharing the roles of generator and evalua-
tor, it also requires one-sided security against malicious
evaluators and is therefore incompatible with IPP.
Applications of IPP. IPP can be applied in all appli-
cation scenarios where semi-honest model is sufﬁcient.
These are scenarios where either the behaviour is oth-
erwise restricted, e.g. limited physical access, or where
the parties have sufﬁcient trust into each other. More-