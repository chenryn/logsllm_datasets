    output{
        stdout{ }
    }
最终匹配如下：
  * `client`: 127.0.0.1
  * `method`: GET
  * `path`: /index.php
  * `bytes`: 87344
  * `duration`: 0.061
我们可以使用[Grok表达式在线调试](https://grokdebug.herokuapp.com/)进行调试表达式，这样我们就不用每次都去重启`logstash`测试表达式了
### 测试
简单的实例：
使用-e选项允许你在命令行快速配置而不必修改配置文件，这个示例将从标准输入来读取你的输入，并将输出以结构化的方式输出至标准输出。
    bin/logstash -e 'input { stdin { } } output { stdout {} }'
现在我们吧output源设为es，同时配置好我们的es的http地址，将标准输入的收集到es上
    bin/logstash -e 'input { stdin { } } output { elasticsearch { hosts => ["127.0.0.1:9200"] } stdout { codec => rubydebug }}'
然后就可以在es看到我们输入的数据了
现在将输入源改为file，路径为：`/var/log/secure`
    input {
        file {
            path => "/var/log/secure"
            type => "auth"
            start_position => "beginning"
            }
    }
    output {    
             elasticsearch {
                    hosts => ["127.0.0.1:9200"]
                    index => "system-%{+YYYY.MM.dd}"
                }
    }
然后可以看到我们的日志已经收集到es上了
## Kibana
Kibana 是一款开源的数据分析和可视化平台，它是`Elastic Stack` 成员之一，设计用于和 Elasticsearch 协作。您可以使用
Kibana 对 Elasticsearch
索引中的数据进行搜索、查看、交互操作。您可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。Kibana
可以使大数据通俗易懂。它很简单，基于浏览器的界面便于您快速创建和分享动态数据仪表板来追踪 Elasticsearch 的实时数据变化。
`kibana`下载地址：
### 配置
常见配置项，参考自[官网手册](https://www.elastic.co/guide/cn/kibana/current/settings.html)
  * `server.port`：配置Kibana的端口，默认为5601
  * `server.host`：指定后端服务器的主机地址
  * `server.name`：配置`Kibana`对外展示的名称
  * `server.MaxPayloadBytes`：服务器请求的最大负载，单位字节
  * `elasticsearch.url`：`Elasticsearch`实例的url，默认值为：`http://localhost:9200`
  * `elasticsearch.username`和 `elasticsearch.password`：若es配置了权限认证，该配置项提供了用户名和密码。
  * `server.ssl.enabled`：是否启用SSL，默认为false，如果为true，则需要配置`server.ssl.certificate`和 `server.ssl.key`
  * `server.ssl.certificate` 和 `server.ssl.key`：SSL 证书和 SSL 密钥文件的路径。
  * `server.ssl.keyPassphrase`：解密私钥的口令，该设置项可选，因为密钥可能没有加密。
  * `server.ssl.certificateAuthorities`：可信任 PEM 编码的证书文件路径列表。
  * `kibana.index`：`Kibana`在es建立的索引名称，默认为`.Kibana`
  * `logging.dest`：Kibana日志输出的文件，默认为：`stdout`
  * `logging.silent`：是否设置为静默模式，如果为true，则禁止所有日志输出，默认为false
  * `logging.quiet`：默认值: false 该值设为 true 时，禁止除错误信息除外的所有日志输出。
  * `logging.verbose`：默认值: false 该值设为 true 时，记下所有事件包括系统使用信息和所有请求的日志。
### 测试
简单配置一下`kibana`
`vim config/kibana.yml`
    server.port: 5601
    server.host: "0.0.0.0"
    elasticsearch.hosts: ["http://127.0.0.1:9200"]
    kibana.index: ".kibana"
启动
    bin/kibana
检查服务是否正常启动
    [qiyou@hack2fun config]$ netstat -unlt|grep 5601
    tcp        0      0 0.0.0.0:5601            0.0.0.0:*               LISTEN
然后就可以通过`http://IP:5601`访问到`kibana`了
然后配置一下索引，就可以看到我们刚刚收集到es上的日志了
然后我们可以通过Kibana筛选功能筛选出你想要内容，如：筛选出ssh登陆失败的日志
## ELK实战
基本了解了ELK之后，我们可以使用ELK来进行收集我们的日志，这里以`apache`、`nginx`、`ssh`以及`history`为例
### 收集apache日志文件
修改`apache`配置文件如下：
    LogFormat "{ \
            \"@timestamp\": \"%{%Y-%m-%dT%H:%M:%S%z}t\", \
            \"@version\": \"1\", \
            \"tags\":[\"apache\"], \
            \"message\": \"%h %l %u %t \\\"%r\\\" %>s %b\", \
            \"clientip\": \"%a\", \
            \"duration\": %D, \
            \"status\": %>s, \
            \"request\": \"%U%q\", \
            \"urlpath\": \"%U\", \
            \"urlquery\": \"%q\", \
            \"bytes\": %B, \
            \"method\": \"%m\", \
            \"site\": \"%{Host}i\", \
            \"referer\": \"%{Referer}i\", \
            \"useragent\": \"%{User-agent}i\" \
    }" json
    CustomLog "logs/access_log" json
此时查看apache的日志：
    [root@hack2fun httpd]# cat access_log 
    {         "@timestamp": "2020-12-19T00:06:37-0800",         "@version": "1",         "tags":["apache"],         "message": "::1 - - [19/Dec/2020:00:06:37 -0800] \"GET / HTTP/1.1\" 403 4897",         "clientip": "::1",         "duration": 111368,         "status": 403,         "request": "/",         "urlpath": "/",         "urlquery": "",         "bytes": 4897,         "method": "GET",         "site": "localhost",         "referer": "-",         "useragent": "curl/7.29.0"        }
    {         "@timestamp": "2020-12-19T00:09:04-0800",         "@version": "1",         "tags":["apache"],         "message": "::1 - - [19/Dec/2020:00:09:04 -0800] \"GET / HTTP/1.1\" 403 4897",         "clientip": "::1",         "duration": 862,         "status": 403,         "request": "/",         "urlpath": "/",         "urlquery": "",         "bytes": 4897,         "method": "GET",         "site": "localhost",         "referer": "-",         "useragent": "curl/7.29.0"        }
用`logstash`测试
如果想保留apache默认的日志格式，我们也可以不用修改，可以直接使用官方提供的gork规则来进行匹配即可
    HTTPDUSER %{EMAILADDRESS}|%{USER}
    HTTPDERROR_DATE %{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}
    # Log formats
    HTTPD_COMMONLOG %{IPORHOST:clientip} %{HTTPDUSER:ident} %{HTTPDUSER:auth} \[%{HTTPDATE:timestamp}\] "(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})" (?:-|%{NUMBER:response}) (?:-|%{NUMBER:bytes})
    HTTPD_COMBINEDLOG %{HTTPD_COMMONLOG} %{QS:referrer} %{QS:agent}
    # Error logs
    HTTPD20_ERRORLOG \[%{HTTPDERROR_DATE:timestamp}\] \[%{LOGLEVEL:loglevel}\] (?:\[client %{IPORHOST:clientip}\] ){0,1}%{GREEDYDATA:message}
    HTTPD24_ERRORLOG \[%{HTTPDERROR_DATE:timestamp}\] \[%{WORD:module}:%{LOGLEVEL:loglevel}\] \[pid %{POSINT:pid}(:tid %{NUMBER:tid})?\]( \(%{POSINT:proxy_errorcode}\)%{DATA:proxy_message}:)?( \[client %{IPORHOST:clientip}:%{POSINT:clientport}\])?( %{DATA:errorcode}:)? %{GREEDYDATA:message}
    HTTPD_ERRORLOG %{HTTPD20_ERRORLOG}|%{HTTPD24_ERRORLOG}
    # Deprecated
    COMMONAPACHELOG %{HTTPD_COMMONLOG}
    COMBINEDAPACHELOG %{HTTPD_COMBINEDLOG}
### 收集nginx日志文件
修改`nginx`配置文件如下：
    http块配置
    log_format json '{"@timestamp":"$time_iso8601",'
                   '"@version":"1",'
                   '"client":"$remote_addr",'
                   '"url":"$uri",'
                   '"status":"$status",'
                   '"domain":"$host",'
                   '"host":"$server_addr",'
                   '"size":$body_bytes_sent,'
                   '"responsetime":$request_time,'
                   '"referer": "$http_referer",'
                   '"ua": "$http_user_agent"'
    '}';
    server块配置：
    access_log /var/log/nginx/access_json.log json;
此时查看nginx的日志：
    [root@hack2fun qiyou]# cat /var/log/nginx/access.log 
    {"@timestamp":"2020-12-18T23:29:18-08:00","@version":"1","client":"127.0.0.1","url":"/index.html","status":"200","domain":"localhost","host":"127.0.0.1","size":612,"responsetime":0.000,"referer": "-","ua": "curl/7.29.0"}
    {"@timestamp":"2020-12-18T23:40:41-08:00","@version":"1","client":"127.0.0.1","url":"/index.html","status":"200","domain":"localhost","host":"127.0.0.1","size":612,"responsetime":0.000,"referer": "-","ua": "curl/7.29.0"}
用`logstash`测试一下
    input {
       file {
          path => "/var/log/nginx/access.log"
          codec => "json"
       }
    }
    output {
       stdout {
          codec => "rubydebug"
       }
    }
效果如下：
### 收集所有用户的历史命令
`vim /etc/bashrc`
    HISTDIR='/var/log/command.log'
    if [ ! -f $HISTDIR ];then
    touch $HISTDIR
    chmod 666 $HISTDIR
    fi
    export HISTTIMEFORMAT="{\"TIME\":\"%F %T\",\"HOSTNAME\":\"$HOSTNAME\",\"LOGIN_IP\":\"$(who -u am i 2>/dev/null| awk '{print $NF}'|sed -e 's/[()]//g')\",\"LOGIN_USER\":\"$(who am i|awk '{print $1}')\",\"CURRENT_USER\":\"${USER}\",\"CMD\":\""
    export PROMPT_COMMAND='history 1|tail -1|sed "s/^[ ]\+[0-9]\+  //"|sed "s/$/\"}/">> /var/log/command.log'
用`logstash`测试
### 收集ssh的登陆信息
Linux认证的日志默认保存在：`/var/log/secure`（`debian/Ubuntu`保存在`/var/log/auth.log`）
    authpriv.*                                              /var/log/secure
我们可以将ssh的日志分离出来，修改ssh配置文件，日志收集类型改为用户自定义的：
    SyslogFacility local6
修改rsyslog配置文件，自定义ssh日志文件路径，然后重启`rsyslog`和`ssh`即可
    local6.*                                                /var/log/sshd.log
因为`ssh`没有像`apache`、`nginx`那样可以自定义日志输出格式，所以我们得自己写一个`filter`，我这里就直接套用了[这里](https://gist.github.com/tsaarni/bb54e158fd453cb6d7cb)的filter了
    "message", "%{SYSLOGTIMESTAMP:date} %{SYSLOGHOST:host} %{DATA:program}(?:\[%{POSINT}\])?: %{WORD:login} password for %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}",
    "message", "%{SYSLOGTIMESTAMP:date} %{SYSLOGHOST:host} %{DATA:program}(?:\[%{POSINT}\])?: message repeated 2 times: \[ %{WORD:login} password for %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}",
    "message", "%{SYSLOGTIMESTAMP:date} %{SYSLOGHOST:host} %{DATA:program}(?:\[%{POSINT}\])?: %{WORD:login} password for invalid user %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}",
    "message", "%{SYSLOGTIMESTAMP:date} %{SYSLOGHOST:host} %{DATA:program}(?:\[%{POSINT}\])?: %{WORD:login} %{WORD:auth_method} for %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}"
logstash配置文件如下：
    input {
       file {
          path => "/var/log/sshd.log"
       }
    }
    filter {
      grok {
        match => [
          "message", "%{SYSLOGTIMESTAMP:date} %{SYSLOGHOST:host} %{DATA:program}(?:\[%{POSINT}\])?: %{WORD:login} password for %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}",
          "message", "%{SYSLOGTIMESTAMP:date} %{SYSLOGHOST:host} %{DATA:program}(?:\[%{POSINT}\])?: message repeated 2 times: \[ %{WORD:login} password for %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}",
          "message", "%{SYSLOGTIMESTAMP:date} %{SYSLOGHOST:host} %{DATA:program}(?:\[%{POSINT}\])?: %{WORD:login} password for invalid user %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}",
          "message", "%{SYSLOGTIMESTAMP:date} %{SYSLOGHOST:host} %{DATA:program}(?:\[%{POSINT}\])?: %{WORD:login} %{WORD:auth_method} for %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}"
        ]