route corresponds to a “slot” for registering the public key of
some node. The adversary can fake l distinct random routes
of length l that cross the attack edge and enter the honest
region. This means that the adversary will have 1 + 2 +
... + l = Θ(l2) = Θ(n log2 n) slots for the sybil nodes in
SybilGuard.
√
In SybilLimit, the tail of each random route corresponds
In any given s-instance, the
to a “slot” for registration.
adversary can fake w distinct random routes of length w that
cross the attack edge and enter the honest region. Notice
that here SybilLimit reduces the number of such routes by
using a w that is much smaller than l. Further, because we
are concerned only with tails now, in the given s-instance,
√
the adversary will have only w slots. With r s-instances, the
adversary will have r · w = Θ(
m log n) such slots total,
√
for all the sybil nodes. This reduction from Θ(n log2 n) slots
to Θ(
m log n) slots is the ﬁrst key step in SybilLimit.
But doing r random routes introduces two problems. The
1As an engineering optimization, a degree-d node in SybilGuard can
n log n), but this does not improve
√
perform d random routes of length Θ(
SybilGuard’s asymptotic guarantees.
10
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:45 UTC from IEEE Xplore.  Restrictions apply. 
j,k,201511S intersects with 3 of V’s tails: and. Tail  has the smallest load, so Vincrements its load, checking  to make sure the load doesnot exceed the threshold. V’s tails101iLoad (c ’s)lj j kl rSybilLimit relies on its (new) balance condition to address
this fraction of escaping routes. To obtain some intuition, let
us imagine the veriﬁer V ’s tails as bins that can accommo-
date up to a certain load. When V accepts a suspect S, out
of all of V ’s tails that intersect with S’s tails, S conceptually
increments the load of the least loaded tail/bin. Because of
the randomness in the system, one would conjecture that
all of V ’s tails should have similar load. If this is indeed
true, then we can enforce a quota on the load of each tail,
which will in turn bound the number of sybil nodes accepted
by V ’s escaping tails. Later, we will show that the balance
condition bounds the number within O(g log n).
Benchmarking technique. The SybilLimit protocol in Fig-
ures 3 and 6 assumes that r = Θ(
m) is known. Obviously,
without global knowledge, every node in SybilLimit needs
to estimate r locally. Recall that SybilGuard also needs to es-
timate some system parameter (more speciﬁcally, the length
√
of the walk). SybilGuard uses the sampling technique to do
so, which only works for g = o(
n/ log n). To allow any
g = o(n/ log n), SybilLimit avoids sampling completely.
Instead, it use a novel and perhaps counter-intuitive bench-
marking technique that mixes the real suspects with some
random benchmark suspects that are already known to be
mostly honest. The technique guarantees that a node will
never over-estimate r regardless of the adversary’s behavior.
If the adversary causes an under-estimation for r, somewhat
counter-intuitively, the technique can ensure that SybilLimit
still achieves its end guarantees despite the under-estimated
r. We will leave the detailed discussion to Section 7.
√
6. Provable guarantees of SybilLimit
While the intersection and balance conditions are simple
at the protocol/implementation level, it is far from obvious
why the designs provide the desired guarantees. We adopt the
philosophy that all guarantees of SybilLimit must be proved
mathematically, since experimental methods can cover only
a subset of the adversary’s strategies. Our proofs pay spe-
cial attention to the correlation among various events, which
turns out to be a key challenge. We cannot assume inde-
pendence for simplicity because after all, SybilLimit exactly
leverages external correlation among random routes. The
following is the main theorem on SybilLimit’s guarantee:
Theorem 3 Assume that the social network’s honest region
is fast mixing and g = o(n/ log n). For any given constants
(potentially close to zero)  > 0 and δ > 0, there is a set of
(1 − )n honest veriﬁers and universal constants w0 and r0,
such that using w = w0 log n and r = r0
m in SybilLimit
will guarantee that for any given veriﬁer V in the set, with
probability at least 1 − δ, V accepts at most O(log n) sybil
nodes per attack edge and at least (1 − )n honest nodes.
√
For the remaining small fraction of n honest veriﬁers, Sybil-
Limit provides a degraded guarantee that is not provable.
Because of space limitations, we will provide mostly intu-
itions in the following and leave formal/complete proofs to
our technical report [41].
6.1. Intersection condition
Preliminaries: Classifying tails and nodes. As prepara-
tion, we ﬁrst carefully classify tails and nodes. Consider
a given veriﬁer V (or suspect S) and a given v-instance (or
s-instance). We classify its tail into 3 possibilities: i) the
tail is an escaping tail (recall Section 5.1), ii) the tail is not
escaping and is drawn from the (uniform) edge stationary
distribution (i.e., a uniform tail), or iii) the tail is not escaping
and is drawn from some unknown distribution on the edges
(i.e., a non-uniform tail).2 In a given v-instance, the routing
tables of all honest nodes will entirely determine whether
V ’s tail is escaping and in the case of a non-escaping tail,
which edge is the tail. Thus, the adversary has no inﬂuence
over non-escaping tails.
Because we do not know the distribution of the non-
uniform tails, few probabilistic properties can be derived
for them. Escaping tails are worse because their distribution
is controlled by the adversary. Assuming that the honest
region of the social network is fast mixing, our technical
report [41] proves the following:
Lemma 4 Consider any given constant (potentially close to
zero)  > 0. We can always ﬁnd a universal constant w0 > 0,
such that there exists a set H of at least (1 − )n honest
nodes (called non-escaping nodes) satisfying the following
property: If we perform a length-w random walk starting
from any non-escaping node with w = w0 log n, then the
tail is a uniform tail (i.e., a uniformly random directed edge
in the honest region) with probability at least 1 − O( g log n
n ).
As a reminder, the probability in the above lemma is de-
ﬁned over the domain of all possible routing table states—
obviously, if all routing tables are already determined, the
tail will be some ﬁxed edge.
It is still possible for the tail of a non-escaping node to
be escaping or non-uniform—it is just that such probabil-
ity is O( g log n
n ) = o(1) for g = o(n/ log n). An honest
node that is not non-escaping is called an escaping node.
By Lemma 4, we have at most n escaping nodes; such
nodes are usually near the attack edges. Notice that given
the topology of the honest region and the location of the
attack edges, we can fully determine the probability of the
tail of a length-w random walk starting from a given node V
being a uniform tail. In turn, this means whether a node V
2A ﬁnite-length random walk can only approach but never reach the
stationary distribution. Thus a small fraction of tails will be non-uniform
(also see Theorem 1).
11
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:45 UTC from IEEE Xplore.  Restrictions apply. 
is escaping is not affected by the adversary. In the remainder
of this paper, unless speciﬁcally mentioned, when we say
“honest node/veriﬁer/suspect”, we mean “non-escaping (hon-
est) node/veriﬁer/suspect”. We will not, however, ignore
escaping nodes in the arguments since they may potentially
disrupt the guarantees for non-escaping nodes.
its
each veriﬁer V ,
{(i, e) | e is V ’s tail in the ith v-instance}.
tail set U(V ) is deﬁned as:
U(V ) = {(i, e) | e is V ’s tail in the ith v-instance and
tail
as:
V ’s uniform
deﬁne
For
set
e is a uniform tail}
Notice that the distribution of U(V ) is not affected by the
adversary’s strategy. We similarly deﬁne the tail set and
uniform tail set for every suspect S. We deﬁne the tainted
tail set ∇ as: ∇ = ∪r
i=1∇i, where
∇i = {(i, e) | e is a tainted tail in the ith s-instance}
Again, the deﬁnition of ∇ is not affected by the behavior
of the adversary, as all these tails are in the honest region.
Further notice that in a given s-instance for each attack edge,
we can have at most w tainted tails. Thus |∇i| ≤ g × w and
|∇| ≤ rgw = O(rg log n).
them as:P
With slight abuse of notation, we say that a tail set in-
tersects with a tail e as long as the tail set contains an ele-
ment (i, e) for some i. The number of intersections with e
is deﬁned to be the number of elements of the form (i, e).
We double count e in different instances because for every
element (i, e), an arbitrary public key can be registered un-
der the name of e in the ith s-instance. For two tail sets
T1 and T2, we deﬁne the number of intersections between
(j,e)∈T2 (# intersections between e and T1). For
example, {(1, e1), (2, e1)} and {(2, e1), (3, e1)} have 4 in-
tersections. T1 and T2 intersect if and only if the number of
intersection between them is larger than 0.
Tail intersection between the veriﬁer and honest sus-
pects. The intersection condition requires that for a veri-
ﬁer V to accept a suspect S, V ’s tail set and S’s tail set
must intersect with S being registered at some intersect-
ing tail. We claim that for any given constant δ > 0, a
veriﬁer V and an honest suspect S will satisfy the inter-
section condition with probability 1 − δ when r = r0
m,
with r0 being an appropriately chosen constant. This is
true because with 1 − δ
2 probability, they will both have
(1 − O( g log n
n )) · r = (1 − o(1))r > 0.5r uniform tails
when g = o(n/ log n). A straight-forward application of the
Birthday Paradox will then complete the argument. Notice
that we are not able to make arguments on the distribution
of non-uniform tails and escaping tails, but uniform tails by
themselves are sufﬁcient for intersection to happen.
Tail intersection between the veriﬁer and sybil suspects.
By deﬁnition, all uniform tails of V are in the honest region.
√
From the secure random route property, the tainted tail set
∇ contains all tails that the sybil nodes can possibly have in
the honest region. We would like to bound the number of
sybil nodes with (tainted) tails intersecting with V ’s uniform
tails. V ’s non-uniform tails and escaping tails will be taken
care of later by the balance condition.
Each tail in ∇ allows the adversary to potentially register
a public key for some sybil node. The adversary has com-
plete freedom on how to “allocate” these tails. For example,
in one extreme, it may create |∇| sybil nodes each with one
tainted tail. In such a case, most likely not all these |∇| sybil
nodes will be accepted because each has only one tainted
tail. In the other extreme, it can create one sybil node and
register its public key with all tails in ∇.
We need to understand what is the adversary’s optimal
strategy for such an allocation. Interestingly, we can prove
that regardless of what U(V ) is, to maximize the number of
sybil nodes with tails intersecting with U(V ), the adversary
should always create |∇| sybil nodes and allocate one tail
for each sybil node. To understand why, let random variable
X be the number of intersections between ∇ and U(V ). It
is obviously impossible for more than X sybil nodes to have
tails intersecting with U(V ). On the other hand, with the
previous strategy, the adversary can always create X sybil
nodes with tails intersecting with U(V ).
With this optimal strategy (of the adversary), we know
that it sufﬁces to focus on the probabilistic property of X.
A tricky part in reasoning about X is that those tails in ∇
are neither uniformly random nor independent. For exam-
ple, they are more likely to concentrate in the region near
the attack edges. However, each tail in U(V ) is still uni-
formly random. From linearity of expectation, we know
that each tail in U(V ) has on expectation |∇|
2m = O( rg log n
m )
intersections with ∇. This in turn means:
E[X] ≤ r · O( rg log n
√
) = O(g log n), for any r = O(
m)
m
A Markov inequality [25] can then show that for any given
constant δ > 0, with probability at least 1 − δ, X is
O(g log n).
6.2. Balance condition
In this section, for any veriﬁer V , we treat all of its non-
uniform tails as escaping tails. Obviously, this only increases
the adversary’s power and makes our arguments pessimistic.
The goal of the balance condition is to bound the number of
sybil nodes accepted by V ’s escaping tails, without signiﬁ-
cantly hurting honest suspects (who are subject to the same
balance condition). While the condition is simple, rigorously
reasoning about it turns out to be quite tricky due to the
external correlation among random routes and also adversar-
ial disruption that may intentionally cause load imbalance.
12
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:45 UTC from IEEE Xplore.  Restrictions apply. 
r )).
This introduces challenges particularly for proving why most
honest suspects will satisfy the balance condition despite all
these disruptions.
Effects on sybil suspects. We ﬁrst study how the bar of
b = h · max(log r, a) (Steps 5–7 in Figure 6) successfully
bounds the number of sybil nodes accepted by V ’s escaping
tails. The argument is complicated by the fact that when
a > log r, the bar b is a ﬂoating one. Namely, as more
suspects are accepted, a and thus b will increase, allowing
further suspects to be accepted. If all n honest suspects are
accepted, the bar may rise to Θ( n
r ). We use such a ﬂoating
bar because n is unknown (otherwise we could directly set
the bar to be Θ( n
But on the other hand, it may also appear that as the