### Document Usage and Download Information
- **Authorized Use:** Tsinghua University
- **Download Date:** March 20, 2021
- **Download Time:** 05:38:03 UTC
- **Source:** IEEE Xplore
- **Usage Restrictions:** Apply

### Error Handling in STEM Cells
We explain the various possible events that occur within the STEM cell and the associated recovery mechanisms used in case of an error. The system employs either a single-cycle or three-cycle fast local recovery based on the values of the ERROR and PANIC signals, as shown in Figure 2.

#### Table 2: Possible Error Scenarios
| CASE | R1 | R2 | R3 | ERROR | PANIC | RECOVERY ACTION |
|------|----|----|----|-------|-------|-----------------|
| I    | EN | EN | EN | 0     | 0     | No Recovery     |
| II   | IS | EN | EN | 1     | 0     | Load R3 into R1, R2 |
| III  | IN | ES | EN | 1     | 0     | Load R3 into R1, R2 |
| IV   | EN | EN | ES | 0     | 1     | Load R2 into R3 |
| V    | TE | EN | EN | 1     | 0     | Load R3 into R1, R2 |
| VI   | IE | SE | EN | 1     | 0     | Load R3 into R1, R2 |

- **CASE I (No Error):** Both ERROR and PANIC signals remain low, and system operation is not interrupted.
- **CASE II, III, V, VI (Single Register Corruption):** One of the registers (R1 or R2) is corrupted, with ERROR = 1 and PANIC = 0. In this scenario, R3 is not updated, and the system recovers by loading R3 into R1 and R2, triggering re-computation. A three-cycle global recovery process is initiated, including:
  - One cycle stall for loading data back into R1 and R2 using the LBKUP signal.
  - Two cycles for re-computation to prevent recurrent system failures due to potential over-clocking errors.
- **CASE IV (R3 Corruption Only):** Only R3 is corrupted, with ERROR = 0 and PANIC = 1. No re-computation is required, but it is necessary to flush the erroneous data from R3. "Golden" data present in R2 is loaded into R3, requiring a single cycle system stall, during which all STEM cells perform local correction using the LPANIC signal.

### Fault Tolerance Analysis
The STEM technique detects and recovers from all possible soft and timing error scenarios, where the soft error is only of the SET type. The design ensures that the scenario where ERROR = 1 and PANIC = 1 never occurs. Silent data corruption can occur if an SEU happens in R3, but since R3 is only used as a checkpointing register, a corrupted R3 value may lead to failure only if an error occurs in R1 or R2 in the next cycle. This mitigates the possibility of system failure due to an SEU in R3.

For Case VI, we expect that a TE or SE affects several STEM cells, and the likelihood of all cells having a TE in R1 and SE in R2 is insignificant. Thus, one of the STEM cells will have the error signal triggered, preventing R3 from being loaded. If ERROR = 1, the PANIC signal is not considered. The fault coverage is similar to the SEM technique, except that in case of false positives, appropriate corrective action is still needed.

### Pipeline Design
The basic step in using SEM or STEM cells in a pipeline is to replace all pipeline registers with one of them. Input clocks are constrained to provide fault tolerance capabilities against soft and timing errors when STEM cells are used. Our discussion focuses on the use of STEM cells in place of pipeline registers.

Figure 3 illustrates how STEM cells are integrated into a processor pipeline, showing the data and control flow for a five-stage pipeline processor. An extra write buffer is added to the last stage (writeback, WB) to ensure that data written to the register file or memory is free from timing errors. Every pipeline stage register is replaced with STEM cells, except for the write buffer registers.

All error signals from a pipeline stage are logically OR-ed to generate the stage error. The global error signal, GERROR, is generated from all pipeline stage error signals using another OR function. Similarly, the global LPANIC signal is generated from individual PANIC signals from all STEM cells.

Timing errors may occur once the operating frequency exceeds the worst-case frequency estimate. The data latching scheme of STEM cells guarantees sufficient time before latching values in registers R2 and R3. However, data latched in all three registers are susceptible to soft errors uniformly distributed in time and space.

### Error Recovery Process
We explain the pipeline operation for ERROR = 1 and PANIC = 0 (Cases II, III, V, VI), as this is the most complicated case. When an error is detected in any pipeline stage, the global error signal is asserted, and in every stage, registers R3 of the STEM cells are not updated with incoming data. In the next clock cycle, the load backup signal, LBKUP, is asserted, and in each STEM cell, the content of register R3 is loaded into corresponding R1 and R2 registers. The clock to the pipeline is then stalled for two cycles to complete the error recovery process.

#### Timing Diagrams
Figure 4 shows the timing relationship between various control signals. The global recovery takes three clock cycles, and the following description explains the events that take place during the entire process.

- **CLK1G, CLK2G, and CLK3G:** Generated from the main clock signal, CLK, using an LCM.
- **CLK1P, CLK2P, and CLK3P:** Routed to the pipeline, these are gated versions of CLK1G, CLK2G, and CLK3G, respectively, and are stalled to enable the pipeline to recover from different error scenarios.
- **ERRORN:** Indicates an error happening in pipeline stage N. Error signals from all pipeline stages are OR-ed together to generate the global error signal, GERROR, which is latched in the clock control unit.

Once an error is detected, the very next clock edge of CLK3G is gated, and in the next cycle, the LBKUP signal is asserted high for one clock cycle. Using CLK1P and CLK2P, recovery data from register R3 is loaded back into registers R1 and R2. During the next cycle, all clock signals (CLK1G, CLK2G, and CLK3G) are clock-gated to give the pipeline sufficient time for re-computation. Clock gating is achieved through control signals CLKSTALL12 and CLKSTALL3, generated by the clock control unit.

To illustrate the error recovery mechanism, an error occurrence is highlighted in Cycle 3. The error occurs during the execution of INST1 of pipeline stage N, triggering the error recovery mechanism that spans from Cycle 4 to Cycle 6. During Cycle 4, data is loaded into registers R1 and R2 from the corresponding stage golden register R3. The pipeline is allowed to perform the computation during Cycles 5 and 6. Results are checked at the end of Cycle 6. Since no error is detected in this cycle, normal pipeline operation resumes.

From the waveforms, we see that on error detection, the entire pipeline goes back by one instruction. Similar recovery actions are performed for a panic situation, involving stalling the clock signals CLK1G and CLK2G for just one cycle. In this case, the pipeline does not roll back, and just the corresponding stage R3 register is updated.

### Dynamic Frequency Scaling
We derive the limits of frequency scaling within which a system integrated with STEM cells operates reliably. The pipeline starts execution with a minimal phase shift required between the clocks, and the clock frequency is gradually increased while satisfying the error rate constraint. To support reliable dynamic overclocking, certain governing conditions must be met at all times during pipeline operation.

Assume the pipeline operates reliably between clock frequencies FMIN and FMAX, governed by time periods TMAX and TMIN, respectively. TMAX is estimated by the worst-case design settings and is equal to the worst-case clock period, TWC. The following clocking constraints decide TMIN:

- **D1:** Phase shift provided for CLK2 with respect to CLK1 for soft and timing error mitigation when the system is clocked with period TMIN.
- **D2:** Phase shift provided for CLK3 with respect to CLK1 for proper error recovery when the system is clocked with period TMIN.

The value of TMIN, satisfying Equation (6), corresponds to the maximum frequency at which the system can possibly recover after a timing error occurs.

\[
T_{\text{MIN}} + D_1 \geq T_{\text{PD}} \quad \text{(Equation 6)}
\]
\[
D_2 - D_1 \geq T_{\text{PW}} \quad \text{(Equation 7)}
\]
\[
T_{\text{CD}} \geq D_2 \quad \text{(Equation 8)}
\]

### Performance Analysis
A key factor limiting frequency scaling is the error rate. As frequency is scaled higher, the number of input combinations resulting in delays greater than the new clock period increases. The impact of the error rate on frequency scaling is analyzed as follows:

- **twc:** Worst-case clock period.
- **tov:** Clock period after overclocking the circuit.
- **n:** Number of cycles needed to recover from an error.
- **N:** Number of clock cycles required for execution under normal conditions.
- **tdiff:** Time difference between the original clock period and the new clock period.

The total execution time is reduced by \( t_{\text{diff}} \times N \) if there is no error. Assuming the application runs at the overclocked frequency of period \( t_{\text{ov}} \) with an error rate of \( k\% \), Equation (9) must be satisfied:

\[
N \times t_{\text{ov}} + n \times N \times k \times t_{\text{ov}} < N \times t_{\text{wc}} \quad \text{(Equation 9)}
\]
\[
k < \frac{t_{\text{wc}} - t_{\text{ov}}}{n \times t_{\text{ov}}} \quad \text{(Equation 10)}
\]

For the STEM technique, an error can happen in five different scenarios, and the error recovery penalty paid is not the same for all cases. Assuming all these error scenarios are equally likely, the average error penalty in cycles is:

\[
n = \frac{4 \times 3 + 1 \times 1}{5} = 2.6
\]

According to Equation (10), for a frequency increase of 15%, the error rate must not be higher than 5.76% for the STEM technique to yield no performance improvement. For error rates less than 1%, a frequency increase of 2.6% is enough for the STEM scheme to have a performance improvement over non-fault-tolerant designs.

### Overheads
One of the main overheads incurred by our scheme is fixing the circuit contamination delay to a required value. Increasing this delay involves a rapid increase in silicon area, as buffers need to be inserted in short-circuit delay paths. This problem needs to be addressed from different design perspectives, including developing new synthesis algorithms and delay buffer designs with minimal area consumption.

Both SEM and STEM cells require metastability mitigation circuits, as flip-flops may enter a metastable state when overclocked or when a soft error reaches the registers during the latching window. We envisage the incorporation of a metastability detection circuit, similar to the one developed in [7].

### Local Clock Generation
A reliable dynamic overclocking technique has been proposed earlier in [16] to improve system performance by tuning the clock frequency beyond the conservative worst-case clock period. It requires a dynamic phase shift (DPS) between the clock signals to support aggressive dynamic clock tuning. At higher frequencies, controlling the phase shift precisely is a challenge and often restricts possible operating frequency configurations.

To avoid dynamic phase shift between the clock signals, we incorporate a constant phase shift (CPS) between the clocks configured to run between frequencies corresponding to the time periods TMAX and TMIN. Consider a case where TMAX = 10 ns, TMIN = 6 ns, and TCD = 4 ns. With a dynamic phase shift between the clock signals, when we scale the system clock period down to 8 ns, a phase shift of 2 ns is needed. Similarly, a phase shift of 3 ns is required for a 7 ns clock period.

Since the circuit contamination delay is increased to 4 ns to aggressively clock the system, computed data will remain stable for \( (T + 4) \) ns, where \( T \) is the current operating frequency of the system. Instead of requiring a dynamic phase shift along with frequency scaling, we provide a constant phase shift of at most TCD at all times.