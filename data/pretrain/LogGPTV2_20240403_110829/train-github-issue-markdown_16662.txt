The separation of string to text and keyword is awesome. The only remaining
item in my opinion is the not-tokenized-but-lowercased case - it is common
enough but will still require some rigorous configuration. It probably makes
sense now to allow specifying "token-filters" to execute on "keyword" fields
directly in that field's mapping (because different approaches to
normalization can be taken - ascii folding, etc). I'm aware of tokenizing
tokenfilters (e.g. word-delimiter) but think we can ignore that edge-case for
this purpose. WDYT?