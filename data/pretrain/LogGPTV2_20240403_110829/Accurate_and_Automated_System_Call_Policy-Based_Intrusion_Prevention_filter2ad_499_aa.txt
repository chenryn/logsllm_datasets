title:Accurate and Automated System Call Policy-Based Intrusion Prevention
author:Lap-Chung Lam and
Wei Li and
Tzi-cker Chiueh
Accurate and Automated System Call Policy-Based
Intrusion Prevention
Lap Chung Lam Wei Li Tzi-cker Chiueh
Computer Science Department
Stony Brook University
PI:EMAIL
Abstract
One way to prevent control hijacking attack is to com-
pare a network application’s run-time system calls with
a pre-deﬁned normal system call behavior model, and
raise an alert upon detecting a mismatch. This paper de-
scribes a system called PAID, which can automatically
derive an accurate system call pattern from the source
code of an application, and use it to detect any anoma-
lous behavior at run time with minimal overhead. Be-
cause each application’s system call pattern is directly
derived from its source code, PAID never raises false
positive alarms. Moreover, its false negative rate is very
close to zero because PAID uses the sequence of return
addresses on the user/kernel stack to uniquely identify
each system call instance. Experiments on a fully oper-
ational PAID prototype show that PAID can indeed stop
all known control hijacking attacks. The run-time la-
tency and throughput penalty of PAID are under 13.02%
and 11.52%, respectively, when it is tested against a set
of production-mode network applications.
1 Introduction
Many modern worms rely on control hijacking at-
tacks to take over the control of vulnerable network ap-
plications, and spread themselves further. These attacks
employ various overﬂowing methods to modify control-
sensitive data structures of target programs such as re-
turn address, function pointers, import table, etc. Be-
cause many production-mode network applications con-
tain software bugs that allow overﬂowing, control hi-
jacking attacks are among the most common and thus
dangerous exploits. For example, in a recent quarterly
CERT Advisory summary (03/2003) [1], seven out of
ten vulnerabilities can lead to control hijacking attacks.
An effective way to thwart control-hijacking attacks
is to compare the system calls a network application
makes at run time with a pre-determined system call
model, and to raise an alert whenever there is a mis-
match. The assumption of this system call pattern check
approach is that as long as an attacker cannot make ar-
bitrary system calls, it is less likely that she can inﬂict
any damage after hijacking the control of a victim ap-
plication. While detecting intrusions based on anomaly
in run-time system call pattern is well known, so far the
technology has not seen much use, because it is techni-
cally challenging to derive an application-speciﬁc nor-
mal system call behavior model that can minimize both
false positives and negatives.
Wagner and Dean [11] ﬁrst introduced the idea of us-
ing a compiler to capture an application’s system call
model from its source code. At run time, any system
call that deviates from the statically determined model
is considered as an act of intrusion and thus should be
prohibited. A call graph derived from a program’s con-
trol ﬂow graph (CFG) is a non-deterministic ﬁnite-state
automaton (NFA) due to such control constructs as if-
then-else and function call/return. The degree of non-
determinism in a CFG determines the number of im-
possible paths [11] and thus the latitude available to
mimicry attack [12], which evades system call pattern
check by faithfully following the hijacked application’s
system call pattern in the injected code until reaching
a desired system call. Wagner [11] and Gifﬁn [4] both
attempted to use a push-down automaton (PDA) model
to mitigate the impossible path problem. Although the
PDA model is more precise than the NFA model, it
incurs expensive run-time checking overhead [11, 4].
Therefore, the challenge in system call based intrusion
prevention is to reduce the vulnerability to mimicry at-
tacks while minimizing the run-time overhead.
This paper describes the design, implementation, and
evaluation of a system call pattern check system called
PAID, which consists of a compiler that can automati-
cally extract by far the most complete system call model
from an application’s source code, even in the pres-
ence of function pointers, signals, and setjmp/longjmp
calls, and an in-kernel run-time veriﬁer that efﬁciently
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:27:46 UTC from IEEE Xplore.  Restrictions apply. 
compares an application’s run-time system call behav-
ior against its statically derived system call model. In
particular, PAID supports the following features:
(cid:127) PAID uniquely identiﬁes each system call
in-
stance by the sequence of return addresses on the
user/kernel stack after the associated trap instruc-
tion is executed. This approach completely elimi-
nates the non-determinism due to multiple call sites
to the same function.
(cid:127) The system call model that PAID produces is very
close to but not exactly a deterministic ﬁnite-
state automaton (DFA), due to loop and if-then-
else construct. However, PAID’s novel run-time
graph-traversing algorithm can efﬁciently remove
all the ambiguities associated with the residual non-
determinism in a PAID model.
(cid:127) PAID applies program slicing and symbolic con-
stant propagation to derive full or partial constraints
on system call arguments, which could further re-
duce an application’s window of vulnerability to
mimicry attacks.
(cid:127) PAID introduces a notify system call, which is
part of the ﬁnal system call model, to inform its
run-time veriﬁer of information that cannot be de-
termined statically such as function pointers, signal
delivery, dynamically loaded modules, etc.
(cid:127) PAID inserts random null system calls at load time,
which become part of the ﬁnal system call model,
to exert additional control over the application’s
run-time execution path, making it even more difﬁ-
cult to mount mimicry attacks.
The combination of these techniques enables PAID to
derive the most accurate application-speciﬁc system call
behavior model, and at the same time achieve the best
run-time checking performance when compared with
systems using a similar approach. In particular, the idea
of using a return address chain as a unique identiﬁer for
each system call instance is both simple and efﬁcient.
Consequently, PAID is able to completely eliminate all
false positives and reduce the number of false nega-
tives from control hijacking attacks to a negligible level,
while keeping the performance overhead under 14%.
2 System Call Model Construction
Many recent anomaly detection systems [11, 3, 10,
8, 4, 13, 9] deﬁne normal behavior model using run-time
application activities. The early works such as [10, 8]
use proﬁling to build the normal behavior model. How-
ever, proﬁling requires time and may produce incom-
plete model. The most accurate way to construct the
normal behavior model of an application is to use static
analysis to extract the system call pattern from the ap-
plication. In this section, we will review some of the
existing static analysis implementations.
f()
{
 char buf[10];
 strcpy(buf, ...);
 getuid();
}
g()
{
Entry(g)
open()
V
V’
write()
ε
ε
ε
Entry(f)
ε
getuid()
Exit(f)
 fd=open("FOO", ...);
 f();
 write();
 f();
close()
W
W’
S1
 close();
 exec("/bin/ls");
}
exec()
Exit(g)
Entry(g)
open()
V
V’
write()
W
W’
close()
S1
exec()
Exit(g)
ε 
ε
push(V’)
pop(V’)
ε
push(W’)
ε pop(W’)
Entry(f)
getuid()
Exit(f)
(A) Program Source
(B) Callgraph Model
(C)NDPDA Model
Figure 1. An example C program, its associ-
atedcallgraph/NFAmodel,andNDPDAmodel.
The simplest way to use a compiler to derive an ap-
plication’s system call model from its source code is the
callgraph model [11] proposed by Wagner and Dean,
who deduced an application’s callgraph model directly
from its control ﬂow graph (CFG) by abstracting away
everything except the function and system call nodes,
as shown in Figure 1(B). The resulting CFG is a Non-
Deterministic Finite State Automaton or NFA because
of such control constructs as if-else-then, loops, and
functions that are called by multiple call sites. A call site
V is represented by a call node V and a return node V’.
Edges are labeled by the corresponding system call or
. The symbol  means no system call is made. During
the execution of an application, the system calls made
by the application are used as inputs to traverse the cor-
responding NFA. If any system call is not accepted by
the NFA, it is considered as an intrusion.
One limitation of the callgraph model is the impos-
sible path problem as indicated by the dash line in Fig-
ure 1(B), which arises because the function f is called
from two call sites, V and W. The graph allows an impos-
sible path {v->Entry(f)->Exit(f)->W’}, which
should not happen in any actual execution. This impos-
sible path problem provides opportunities for mimicry
attacks [12]. A mimicry attack issues system calls ac-
cording to the order captured in the callgraph model un-
til reaching a system call that can actually cause dam-
age. For example, assume a buffer overﬂow attack hap-
pens in the function f in Figure 1(A). After f returns,
the execution is transferred to the injected attack code,
which then issues the system call sequence {close(),
exec(‘‘/bin/sh’’)}. Since the attack code issues
the system calls in the order deﬁned by Figure 1(B), the
callgraph model cannot detect this attack. This limita-
tion of the callgraph model is due to the fact that it only
veriﬁes the ordering among system calls as deﬁned by
an application, but not their sites.
To eliminate impossible paths, Wagner et al. simu-
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:27:46 UTC from IEEE Xplore.  Restrictions apply. 
lated the stack operation using a non-deterministic push-
down automaton (NDPDA) [11] as depicted in Figure
1(C). The key idea of the NDPDA model is when a call
state V is encountered, the corresponding return state V’
is pushed into a simulated stack before the control is
transferred to the callee, and is popped from the stack
when the callee returns the control back. This imple-
mentation guarantees that a function always returns to
its caller no matter how many call sites the function has.
However, for each incoming system call, the NDPDA
model has to calculate a set of possible stack conﬁgu-
rations based on the previous system call in order to re-
solve the non-determinism due to if-else-then and loop
statements This set of conﬁgurations can grow inﬁnitely
large, especially for left-recursive calls. Despite a com-
plicated algorithm to reduce the complexity of the ND-
PDA model, the worst-case running time is still cubic in
the length of the system call trace. This leads to unac-
ceptably high run-time overheads for large applications.
Both previous PAID [9] and the Dyck model [5] use
null system call insertion to transform applications to re-
move the non-determinism due to if-then-else and loop
constructs. However, the Dyck model can cause un-
predictable performance overhead due to extensive null
system call insertion. Furthermore, the Dyck model is
not a deterministic model because it does not insert null
system call in recursive functions. Previous PAID uses
graph in-lining to remove the impossible path problems.
Although the previous PAID model is deterministic, the
model it generates is two to three times larger, and it
requires extensive modiﬁcation of the system call stubs
and the I/O library functions.
site. For each incoming system call they extract all call
site addresses currently on the user stack to form a vir-
tual stack list (VSL) and feed it to a deterministic push-
down automaton or DPDA as shown in Figure 2. The
symbols r1 to r4 in the DPDA represents the call site ad-
dresses. Assume the VSL for a previous system call Sp
is {a1, a2,···, al, b1, b2,···, bm}, and the VSL for the cur-
rent system call Sc is {a1, a2,···, al, c1, c2,···, cn}. The
sequence {a1, a2,· · ·, al} is a common preﬁx for both
VSLs. Their traversal algorithm uses {bm, bm−1,···, b1}
to generate input symbols that simulate function re-
turn operations, and {c1, c2,· · ·, cn} to generate in-
put symbols to simulate function call operations. After
getuid in Figure 2 is called, the VSL for setuid is
{r1, r2, r3}, the VSL for getuid is {r1, r2, r4}, and
their common preﬁx is {r1, r2}. Assume the current
state is S setuid, the algorithm uses {r3} and {r4}
to generate the following traversal operations:
1. Consume nothing and move
to
the
state
Exit(f3)
2. Pop the stack. If the top of the stack is r3, move to
the state C3’
3. Consume r4 and move to the state C4
4. Push r4 and move to the state Entry(f4)
5. Move to the getuid state whose program counter
the current
matches the program counter of
getuid call
If all above operations are accepted by the DPDA model,
then the current system call getuid is legitimate.
Entry(main)
Entry(f1)
Entry(f2)
Entry(main)
Entry(f1)
Entry(main)
Entry(f1)
Entry(f2)
Entry(f3)
C1
push(r1)
C2
push(r2)
r1
r2
S_getuid
push(r2)
r1
C1
C1’
r2
C2
C2’
push(r1)
pop(r1)
Exit(main)
Exit(f1)
pop(r2)
r3
C3
C3’
r4
C4
C4’
Exit(f2)
S_setuid
push(r3)
pop(r3)
push(r4)
S_setuid
Exit(f3)
Entry(f4)