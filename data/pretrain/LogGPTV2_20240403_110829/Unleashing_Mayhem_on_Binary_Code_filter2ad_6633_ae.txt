 1000
 500
xtokkaetama
sharutils
ghostscript
socat
htpasswd
a2ps
 60
 70
 80
 90
 100
Normalized precondition size (%)
 0
 50
Figure 10: Exploit generation time versus precondition size.
utility. The results are shown in Figure 9.
We used the 21 tools with the smallest code size, and 4
bigger tools that we selected. MAYHEM achieved a 97.56%
average coverage per application and got 100% coverage on
13 tools. For comparison, KLEE achieved 100% coverage
on 12 coreutils without simulated system call failures (to
have the same conﬁguration as MAYHEM). Thus, MAYHEM
seems to be competitive with KLEE for this data set. Note
that MAYHEM is not designed speciﬁcally for maximizing
code coverage. However, our experiments provide a rough
comparison point against other symbolic executors.
F. Comparison against AEG
We picked 8 different programs from the AEG working
examples [2] and ran both tools to compare exploit generation
times on each of those programs using the same conﬁguration
(Table IV). MAYHEM was on average 3.4× slower than AEG.
AEG uses source code, thus has the advantage of operating at
a higher-level of abstraction. At the binary level, there are no
types and high-level structures such as functions, variables,
buffers and objects. The number of instructions executed
(Table IV) is another factor that highlights the difference
between source and binary-only analysis. Considering this,
we believe this is a positive and competitive result for
MAYHEM.
Precondition Size. As an additional experiment, we mea-
sured how the presence of a precondition affects exploit
generation times. Speciﬁcally, we picked 6 programs that
require a crashing input to ﬁnd an exploitable bug and
started to iteratively decrease the size of the precondition and
392
)
%
(
s
n
o
i
t
c
u
r
t
s
n
i
d
e
t
n
a
i
t
f
o
r
e
b
m
u
N
 5
 4.5
 4
 3.5
 3
 2.5
 2
 1.5
 1
 0.5
 0
24 different Linux applications
Figure 12: Tainted instructions (%) for 24 Linux applications.
measured exploit generation times. Figure 10 summarizes
our results in terms of normalized precondition sizes—for
example, a normalized precondition of 70% for a 100-byte
crashing input means that we provide 70 bytes of the crashing
input as a precondition to MAYHEM. While the behavior
appeared to be program-dependent, in most of the programs
we observed a sudden phase-transition, where the removal
of a single character could cause MAYHEM to not detect the
exploitable bug within the time limit. We believe this to be
an interesting topic for future work in the area.
G. Performance Tuning
Formula Optimizations. Recall from §IV-E MAYHEM uses
various optimization techniques to make solver queries faster.
To compare against our optimized version of MAYHEM, we
turned off some or all of these optimizations.
We chose 15 Linux programs to evaluate the speedup
obtained with different levels of optimizations turned on.
Figure 11 shows the head-to-head comparison (in exploit
ﬁnding and generation times) between 4 different formula
optimization options. Algebraic simpliﬁcations usually speed
up our analysis and offer an average speedup of 10% for
the 15 test programs. Signiﬁcant speedups occur when the
independent formula optimization is turned on along with
simpliﬁcations, offering speedups of 10-100×.
Z3 supports incremental solving, so as an additional
experiment, we measured the exploit generation time with
Z3 in incremental mode. In most cases solving times for
incremental formulas are comparable to the times we obtain
with the independent formulas optimization. In fact, in half of
our examples (7 out of 15) incremental formulas outperform
independent formulas. In contrast to previous results, this
implies that using the solver in incremental mode can alleviate
the need for many formula simpliﬁcations and optimizations.
A downside of using the solver in incremental mode was
that it made our symbolic execution state mutable—and thus
was less memory efﬁcient during our long-running tests.
Tainted Instructions. Only tainted instruction blocks are
evaluated symbolically by MAYHEM—all other blocks are
executed natively. Figure 12 shows the percentage of tainted
instructions for 24 programs (taken from Table I). More than
95% of instructions were not tainted in our sample programs,
and this optimization gave about 8× speedup on average.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:45 UTC from IEEE Xplore.  Restrictions apply. 
Indep. Formula + Simplification
Inc. Formula + Simplification
Indep. Formula
Simplification
Timeout
 1000
 100
 10
 1
i
w
c
o
nfig
s
q
uirr
el 
m
ail
x
g
ala
g
a
glftp
d
o
r
z
http
d
a
e
o
n
tip
x
d
n
c
o
m
p
r
e
s
s
g
h
o
sts
c
ript
xto
k
k
a
eta
m
a
s
h
a
r
utils
a
s
p
ell
s
o
c
at
p
s
utils
atp
http
d
 10000
l
)
e
a
c
s
g
o
l
n
i
.
c
e
s
(
e
m
T
i
.
n
e
G
t
i
l
o
p
x
E
Figure 11: Exploit generation time of MAYHEM for different optimizations.
IX. DISCUSSION
Most of the work presented in this paper focuses on
exploitable bug ﬁnding. However, we believe that the main
techniques can be adapted to other application domains under
the context of symbolic execution. We also believe that
our hybrid symbolic execution and index-based memory
modeling represent new points in the design space of
symbolic execution.
We stress that the intention of MAYHEM is informing a
user that an exploitable bug exists. The exploit produced
is intended to demonstrate the severity of the problem, and
to help debug and address the underlying issue. MAYHEM
makes no effort to bypass OS defenses such as ASLR and
DEP, which will likely protect systems against exploits we
generate. However, our previous work on Q [25] shows that
a broken exploit (that no longer works because of ASLR
and DEP), can be automatically transformed—with high
probability—into an exploit that bypasses both defenses on
modern OSes. While we could feed the exploits generated by
MAYHEM directly into Q, we do not explore this possibility
in this paper.
Limitations: MAYHEM does not have models for all
system/library calls. The current implementation models
about 30 system calls in Linux, and 12 library calls in
Windows. To analyze larger and more complicated programs,
more system calls need to be modeled. This is an artifact of
performing per-process symbolic execution. Whole-system
symbolic executors such as S2E [28] or BitBlaze [5] can
execute both user and kernel code, and thus do not have
this limitation. The down-side is that whole-system analysis
can be much more expensive, because of the higher state
restoration cost and the time spent analyzing kernel code.
Another limitation is that MAYHEM can currently analyze
only a single execution thread on every run. MAYHEM cannot
handle multi-threaded programs when threads interact with
each other (through message-passing or shared memory).
Last, MAYHEM executes only tainted instructions, thus it
is subject to all the pitfalls of taint analysis, including
undertainting, overtainting and implicit ﬂows [24].
Future Work: Our experiments show that MAYHEM can
generate exploits for standard vulnerabilities such as stack-
based buffer overﬂows and format strings. An interesting
future direction is to extend MAYHEM to handle more
advanced exploitation techniques such as exploiting heap-
based buffer overﬂows, use-after-free vulnerabilities, and
information disclosure attacks. At a high level, it should be
possible to detect such attacks using safety properties similar
to the ones MAYHEM currently employs. However, it is still
an open question how the same techniques can scale and
detect such exploits in bigger programs.
X. RELATED WORK
Brumley et al. [7] introduced the automatic patch-based
exploit generation (APEG) challenge. APEG used the patch
to point out the location of the bug and then used slicing
to construct a formula for code paths from input source to
vulnerable line. MAYHEM ﬁnds vulnerabilities and vulnerable
code paths itself. In addition, APEG’s notion of an exploit is
more abstract: any input that violates checks introduced by
the path are considered exploits. Here we consider speciﬁcally
control ﬂow hijack exploits, which were not automatically
generated by APEG.
Heelan [14] was the ﬁrst to describe a technique that takes
in a crashing input for a program, along with a jump register,
and automatically generates an exploit. Our research explores
the state space to ﬁnd such crashing inputs.
AEG [2] was the ﬁrst system to tackle the problem of both
identifying exploitable bugs and automatically generating
exploits. AEG worked solely on source code and introduced
preconditioned symbolic execution as a way to focus sym-
bolic execution towards a particular part of the search space.
MAYHEM is a logical extension of AEG to binary code. In
practice, working on binary code opens up automatic exploit
generation to a wider class of programs and scenarios.
There are several binary-only symbolic execution frame-
works such as Bouncer [10], BitFuzz [8], BitTurner [6]
FuzzBall [20], McVeto [27], SAGE [13], and S2E [28],
which have been used in a variety of application domains.
The main question we tackle in MAYHEM is scaling to
ﬁnd and demonstrate exploitable bugs. The hybrid symbolic
execution technique we present in this paper is completely
different from hybrid concolic testing [19], which interleaves
random testing with concolic execution to achieve better code
coverage.
393
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:45 UTC from IEEE Xplore.  Restrictions apply. 
XI. CONCLUSION
We presented MAYHEM, a tool for automatically ﬁnding
exploitable bugs in binary (i.e., executable) programs in an
efﬁcient and scalable way. To this end, MAYHEM introduces
a novel hybrid symbolic execution scheme that combines
the beneﬁts of existing symbolic execution techniques (both
online and ofﬂine) into a single system. We also present index-
based memory modeling, a technique that allows MAYHEM
to discover more exploitable bugs at the binary-level. We
used MAYHEM to analyze 29 applications and automatically
identiﬁed and demonstrated 29 exploitable vulnerabilities.
XII. ACKNOWLEDGEMENTS
We thank our shepherd, Cristian Cadar and the anonymous
reviewers for their helpful comments and feedback. This
research was supported by a DARPA grant to CyLab at
Carnegie Mellon University (N11AP20005/D11AP00262), a
NSF Career grant (CNS0953751), and partial CyLab ARO
support from grant DAAD19-02-1-0389 and W911NF-09-1-
0273. The content of the information does not necessarily
reﬂect the position or the policy of the Government, and no
ofﬁcial endorsement should be inferred.
REFERENCES
[1] “Orzhttpd, a small and high performance http server,”
http://code.google.com/p/orzhttpd/.
[2] T. Avgerinos, S. K. Cha, B. L. T. Hao, and D. Brumley, “AEG:
Automatic exploit generation,” in Proc. of the Network and
Distributed System Security Symposium, Feb. 2011.
[3] D. Babi´c, L. Martignoni, S. McCamant, and D. Song,
“Statically-Directed Dynamic Automated Test Generation,” in
International Symposium on Software Testing and Analysis.
New York, NY, USA: ACM Press, 2011, pp. 12–22.
[4] G. Balakrishnan and T. Reps, “Analyzing memory accesses
in x86 executables.” in Proc. of the International Conference
on Compiler Construction, 2004.
[5] “BitBlaze
binary
analysis
project,”
http://bitblaze.cs.berkeley.edu, 2007.
[6] BitTurner, “BitTurner,” http://www.bitturner.com.
[7] D. Brumley, P. Poosankam, D. Song, and J. Zheng, “Automatic
patch-based exploit generation is possible: Techniques and
implications,” in Proc. of the IEEE Symposium on Security
and Privacy, May 2008.
[8] J. Caballero, P. Poosankam, S. McCamant, D. Babic, and
D. Song, “Input generation via decomposition and re-stitching:
Finding bugs in malware,” in Proc. of the ACM Conference on
Computer and Communications Security, Chicago, IL, October
2010.
[9] C. Cadar, D. Dunbar, and D. Engler, “KLEE: Unassisted
and automatic generation of high-coverage tests for complex
systems programs,” in Proc. of the USENIX Symposium on
Operating System Design and Implementation, Dec. 2008.
[10] M. Costa, M. Castro, L. Zhou, L. Zhang, and M. Peinado,
“Bouncer: Securing software by blocking bad input,” in
Symposium on Operating Systems Principles, Oct. 2007.
394
[11] J. R. Crandall and F. Chong, “Minos: Architectural support
for software security through control data integrity,” in Proc.
of the International Symposium on Microarchitecture, Dec.
2004.
[12] L. M. de Moura and N. Bjørner, “Z3: An efﬁcient smt solver,”
in TACAS, 2008, pp. 337–340.
[13] P. Godefroid, M. Levin, and D. Molnar, “Automated whitebox
fuzz testing,” in Proc. of the Network and Distributed System
Security Symposium, Feb. 2008.
[14] S. Heelan, “Automatic Generation of Control Flow Hijacking
Exploits for Software Vulnerabilities,” Oxford University, Tech.
Rep. MSc Thesis, 2002.
[15] I. Jager, T. Avgerinos, E. J. Schwartz, and D. Brumley, “BAP:
A binary analysis platform,” in Proc. of the Conference on
Computer Aided Veriﬁcation, 2011.
[16] J. King, “Symbolic execution and program testing,” Commu-
nications of the ACM, vol. 19, pp. 386–394, 1976.
[17] Launchpad, https://bugs.launchpad.net/ubuntu, open bugs in
Ubuntu. Checked 03/04/12.
[18] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney,
S. Wallace, V. J. Reddi, and K. Hazelwood, “Pin: Building
customized program analysis tools with dynamic instrumen-
tation,” in Proc. of the ACM Conference on Programming
Language Design and Implementation, Jun. 2005.
[19] R. Majumdar and K. Sen, “Hybrid concolic testing,” in Proc.
of the ACM Conference on Software Engineering, 2007, pp.
416–426.
[20] L. Martignoni, S. McCamant, P. Poosankam, D. Song, and
P. Maniatis, “Path-exploration lifting: Hi-ﬁ tests for lo-ﬁ emula-
tors,” in Proc. of the International Conference on Architectural
Support for Programming Languages and Operating Systems,
London, UK, Mar. 2012.
[21] A. Moser, C. Kruegel, and E. Kirda, “Exploring multiple
execution paths for malware analysis,” in Proc. of the IEEE
Symposium on Security and Privacy, 2007.
[22] T. Newsham, “Format string attacks,” Guardent, Inc., Tech.
Rep., 2000.
[23] J. Newsome and D. Song, “Dynamic taint analysis for
automatic detection, analysis, and signature generation of
exploits on commodity software,” in Proc. of the Network and
Distributed System Security Symposium, Feb. 2005.
[24] E. J. Schwartz, T. Avgerinos, and D. Brumley, “All you ever
wanted to know about dynamic taint analysis and forward
symbolic execution (but might have been afraid to ask),” in
Proc. of the IEEE Symposium on Security and Privacy, May
2010, pp. 317–331.
[25] E. J. Schwartz, T. Avgerinos, and D. Brumley, “Q: Exploit
hardening made easy,” in Proc. of the USENIX Security
Symposium, 2011.
[26] K. Sen, D. Marinov, and G. Agha, “CUTE: A concolic unit
testing engine for C,” in Proc. of the ACM Symposium on the
Foundations of Software Engineering, 2005.
[27] A. V. Thakur, J. Lim, A. Lal, A. Burton, E. Driscoll, M. Elder,
T. Andersen, and T. W. Reps, “Directed proof generation for
machine code,” in CAV, 2010, pp. 288–305.
[28] G. C. Vitaly Chipounov, Volodymyr Kuznetsov, “S2E: A
platform for in-vivo multi-path analysis of software systems,”
in Proc. of the International Conference on Architectural
Support for Programming Languages and Operating Systems,
2011, pp. 265–278.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:45 UTC from IEEE Xplore.  Restrictions apply.