Self-published with legal obligations The software
developer hands their source code to a publisher. The pub-
lisher builds the binary and signs it before handing it oﬀ to
the service provider. The publisher also promises (e.g. by
incorporating a clause in their terms and conditions) that
enclaves they sign exhibit certain properties.
Enterprise-local audit An enterprise might maintain
a set of policies for secure services it runs internally. They
can have an internal audit team that vets service updates.
This way they can have the beneﬁts of protection from in-
sider attacks as well as local control.
5.4
Incremental deployment — clients
We present an incremental deployment path for Attesta-
tion Transparency that makes it immediately useful for to-
day’s clients while improving security guarantees for future
8
clients.
Current clients
Initially, clients without Certiﬁcate
Transparency support will beneﬁt from the existence of the
CT/AT ecosystem, as independent entities can monitor the
published certiﬁcates and statements. However, there are no
guarantees for such clients and targeted attacks are possible.
While the CT logs might include a valid certiﬁcate for some
domain, a client without CT support can be presented with
a valid certiﬁcate that does not appear in the logs, and the
client would be none the wiser.
Clients supporting Certiﬁcate Transparency
Once clients support Certiﬁcate Transparency, a process
which is already in motion, they will get most of the beneﬁts
of Attestation Transparency as well. Suppose a service
has subscribed to our secure service paradigm, promising
to publish in the AT log in conjunction with the CT log.
Then, by checking the Signed Certiﬁcate Timestamps when
setting up a connection, a client can be sure that the server
published its attestation if it has one. A user still needs
to rely on manual veriﬁcation or word-of-mouth to know
whether a particular service at a particular domain is in
fact a secure service.
Clients supporting Attestation Transparency A
client that can check the attested statements will be able to
indicate to the user that it is in fact connected to a secure
service.
Clients supporting remote attestation Clients
supporting remote attestation get even stronger guarantees
than those just supporting Certiﬁcate Transparency. With
remote attestation, a client can verify that the server they
are connected to is actually running inside a secure enclave.
This is helpful in case a server’s TLS private key got leaked
inadvertently. A third party could run a modiﬁed service
with the TLS private key thus impersonating the secure
service under the previous three mechanisms. When using
remote attestation directly, this third party could not
produce a correct attestation if the service were modiﬁed.
6. EVALUATION
Since Intel SGX is not yet available at the time of writ-
ing,6 we performed our evaluation by implementing secure
services on top of CloudProxy [25]. CloudProxy provides an
abstraction over security primitives similar to the ones Intel
SGX provides. A current implementation is available using
Linux with a hardware root-of-trust based on the Trusted
Platform Module (TPM) interface. This implementation
has a much larger TCB than pure SGX would have, in-
cluding the bootloader, the CloudProxy hypervisor, and the
entire OS kernel.7
We do two case studies on secure services to evaluate
developer eﬀort and performance loss. First, to see how
diﬃcult programming with our secure service paradigm
would be, we implemented a secure web server “from
scratch.”Second, we molded an existing web application
stack into our secure service model to test the performance
loss incurred. The original CloudProxy technical report [25]
includes further performance measurements. We do expect
6Hardware with SGX is currently available in both Core and
Xeon E3 processors, but Intel had yet to release the required
additional software support.
7The OS kernel could be signiﬁcantly reduced or even re-
placed by a small run-time library but we have not done
this.
slightly better performance on CloudProxy than we would
see on real SGX hardware, since there is no runtime mem-
ory encryption overhead. All our tests were performed on
an Intel NUC 5i5MYHE with Intel Core i5-5300 processor,
8GB RAM and a Samsung 850 EVO SSD, running Ubuntu
15.04 with a Linux 4.0.7 kernel.
6.1 File hosting service
We implemented the secure service interface in a memory-
safe and type-safe but fast language, Rust [31]. The interface
library is designed in a way that makes it easy to swap out
diﬀerent parts (such as OpenSSL for another TLS library or
CloudProxy bindings for an SGX runtime).
On top of that we implemented an HTTPS server that
runs a simple ﬁle storage service. A user can login using a
username and password. They can then upload ﬁles which
will be encrypted with a key derived from their password.
Users can later retrieve these ﬁles by logging in again. The
webserver is entirely self-contained—the binary includes all
HTML, JavaScript, CSS and images that are going to be
served to the user.
The webserver itself is 425 SLOC of Rust and 168 SLOC
of HTML/JavaScript/CSS plus the jQuery framework and
the Bootstrap theme. The interface library is 983 SLOC
of Rust, plus an additional 262 SLOC of Rust and 1154
SLOC of C/C++ for the CloudProxy bindings. In addition,
the webserver and library pull in an additional 59000 SLOC
of Rust for statically linked dependencies. These numbers
represent an upper bound on the actual number of lines as
they include inline unit tests and feature-gated code that is
not compiled—such as 18000 lines in unused Windows API
bindings, and 5000 lines in an unused HTTP/2 implementa-
tion. The CloudProxy bindings pull in another 17000 SLOC
of C/C++ for statically linked dependencies in addition to
libprotobuf. We link to OpenSSL and common system li-
braries as well.8
6.2 Web forum
While the goal of this paper is not to show that legacy
applications can be ported to our architecture—others have
already shown similar results [6]—we do want to show that
the architecture is ﬁt for running large and complex Internet
services. We mold an existing web server stack consisting of
Apache, PHP, SQLite and phpBB to ﬁt in our secure service
architecture using CloudProxy and Linux OS features. The
insecure ﬁlesystem, networking and IPC are provided as nor-
mal by the OS. Secure storage and attestation is provided
by a small set of binaries that provide access to the Cloud-
Proxy interface. Secure networking is provided by Apache’s
mod ssl and the keying interface by OpenSSL. Database en-
cryption is provided by SQLCipher, [41] an enhanced version
of SQLite that encrypts the on-disk ﬁles using AES. The
database encryption key itself is stored in sealed storage.
To make the web stack measurable, all ﬁles (binaries, sys-
tem libraries, web content, etc.) are bundled into a sin-
gle bootstrap binary. The bootstrap binary creates a new
root ﬁlesystem namespace—isolating this process’s view of
the ﬁlesystem from the rest of the system—from an empty
RAM-disk and ﬁlls it with the bundled ﬁles. It then starts
an initialization script that sets up the keys according to
8To be precise:
libgcc s, libc.
libz,
libdl,
libpthread,
libm,
libstdc++,
9
s
b
o
j
f
o
n
o
i
t
c
a
r
f
e
v
i
t
a
l
u
m
u
C
1
0.8
0.6
0.4
0.2
0
0.5
Plain
Encrypted
Encrypted+CloudProxy
1
1.5
2
2.5
3
t (s)
Figure 5: Cumulative Distribution Functions of the
processing times for 3 diﬀerent phpBB setups. For
each line, n = 1692.
Figure 4 as well as the database encryption key and then
launches the Apache web server. The bundle is about 76MB.
We measure the performance of three related web forum
setups to see the eﬀect encryption and the CloudProxy plat-
form have. The ﬁrst setup, plain is a vanilla Apache, PHP,
SQLite and phpBB installation. The second, encrypted,
swaps out SQLite for SQLCipher. The ﬁnal setup, en-
crypted+CloudProxy, runs the aforementioned bundled mea-
sured web stack.
For each setup, we load a small real forum dataset with 21
users, 94 topics and about 1300 initial posts. We then run
a set of workers that access the forum over HTTPS simul-
taneously. Each user gets their own worker. Each worker
selects a random topic they want to post to and performs
the following procedure:
login, navigate to the appropri-
ate topic listing, visit the topic, go to the last page, go to
the reply screen, and post a reply. Each topic is visited 6
times in total. We measure the aggregate time it takes to
complete each topic-posting procedure from login to post.
We perform the entire test procedure 3 times, for a total of
3 · 6 · 94 = 1692 measurements per setup total.
The average processing time for the plain version is µ =
1.671s (σ = 0.693). For the encrypted version µ = 1.731s
(σ = 0.633) and for the encrypted+CloudProxy version µ =
1.738s (σ = 0.646). The encrypted /encrypted+CloudProxy
setups are about 4% slower than the plain version. There
is no signiﬁcant diﬀerence between the encrypted and
encrypted+CloudProxy setups (Two-sample Kolmogorov-
Smirnov test, p > 0.73). The CDFs in Figure 5 show
that all requests in the encrypted setups are just slightly
slower than in the plain version, as opposed to the tim-
ing distribution being completely diﬀerent.
It also clearly
shows the lack of diﬀerence between the encrypted and en-
crypted+CloudProxy setups, either setup being faster than
the other at diﬀerent percentiles.
7. DISCUSSION
7.1 Possible applications
The previous case studies are examples of possible appli-
cations of this technology, but many more exist. We discuss
some.
10
7.1.1 Browser-based cryptographic systems
One of the arguments against doing in-browser cryptogra-
phy using JavaScript is its poor auditability [23,30]. Even if
a user assures themselves of the quality of the cryptographic
system by carefully inspecting a page’s DOM tree, there is no
guarantee the server will send you the exact same page the
next time you visit it. With an Attestation Transparency-
supported secure service, a user does get that guarantee. Be-
cause the logic for sending HTTP responses is ﬁxed within
the unalterable secure service’s identity, a client will receive
the same script every time. This in combination with the
Web Crypto API [34] brings us closer to being able to do
browser-based crypto properly and securely.
7.1.2 Bootstrapping secure web applications
In the web application world, many production updates
are pushed out every day. Having to go through the up-
date process and requesting a new TLS certiﬁcate every time
might not be practical. It is not necessary, however, to in-
clude an entire website within the secure enclave.
Instead, one can create a small core web page at a well-
known URL (e.g. https://example.com) that will load fur-
ther web content. Even untrusted content (e.g.
from not-
audited.example.com) can be included when using a tech-
nique such as HTML5 privilege separation [3]. The small
core is secure and veriﬁed and provides only security func-
tionality to the web application, which should require in-
frequent changes. The untrusted part of the website can
be developed and updated frequently as normal, while not
being able to cause harm because of the privilege separation.
Including static external content, e.g. from Content De-
livery Networks, is supported securely through the recent
Subresource Integrity draft [2]. Websites can include a hash
with a URL on an external resource which will be checked
by the browser.
Including dynamic external content is trickier. If an ex-
ternal site is known to be a secure service deﬁned in this
paper, verifying its known public key should be suﬃcient to
ensure the safety of loading its contents. The Subresource
Integrity mechanism could be extended to allow public key
pinning on an external resource.
7.1.3 Encrypted e-mail storage server
An e-mail provider could run their SMTP/IMAP stack as
two separate secure services. The IMAP server, storing the
user’s e-mails, will maintain an internal directory of users
and corresponding encryption keys. Only the user will have
access to their e-mails which are encrypted at rest. The
SMTP server, when receiving mail for a local user, will ob-
tain the local public key for that user from the IMAP server
and encrypt the received message before handing it to the
IMAP server for storage.
This setup provides secure encrypted e-mail storage for
legacy IMAP clients including the inability of an insider to
obtain the user’s e-mails or credentials. Additionally, an
SMTP client could verify the server’s identity before sub-
mitting mail, making sure that the e-mail will get delivered
to a secure mailbox.
7.2 Limitations and open research questions
The research in this paper does not address availability
questions at all. Denial of service is a valid attack that an
adversary might perform. Worse, destruction of user data is
also possible. In order to get the cloud environment closer
to the desktop model, these issues need to be resolved.
Secure enclaves don’t keep any presistent state. As such
enclaves can’t know whether the untrusted party it’s relying
one for data storage is returning the most recent version
of its encrypted state. This attack against the freshness of
data is called a rollback attack. Generic solutions for this
problem—such as Memoir [28]—exist and can be applied to
the design proposed in this paper.
In order for a user to be able to fully trust a ‘secure web
application’ as deﬁned in the previous section, they need
to know that the data they see or the input they provide
is handled securely. The current web hardly provides such
mechanisms. JavaScript and CSS on a page can arbitrarily
change page elements to re-order information, capture user
input, or even read cross-origin data [36]. More research
eﬀort is needed to provide the user with a secure and trust-
worthy user interface on the web.
The security of our system relies on an adversary not being
able to break in to the secure enclave. Even if the hardware
is infallible—which it isn’t—a simple software bug could leak
sensitive information or provide an attacker with code ex-
ecution capabilities. Bugs are exacerbated by being com-
pletely transparent about the code running on a machine.
The transparency makes it much easier for an attacker to
automate exploitation of known vulnerabilities. We propose
using only safe languages such as Rust to write secure ser-
vices, but even then there is no guarantee against compiler
bugs or developer errors. Further guarantees could be ob-
tained by using formal methods.
While SGX in theory provides good isolation, in practice it
might have security ﬂaws. In addition, SGX does not aim to