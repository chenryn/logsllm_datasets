It is painful to manually identify “safe” functions. But
two reasons make it a manageable task. First, there are
only a few such functions, even though they accounted
for a signiﬁcant portion of the type errors (Table 2). Sec-
ondly, these functions are relatively stable across kernel
releases. So with a high probability this task only needs
to be done once and the results can be reused in future
kernel releases. After the “safe” functions are identiﬁed,
we only need to verify that they do not change in new
kernel releases, or that the changes do not affect their
intended functionality.
Table 2 shows the reduction in terms of both path and
source type errors after removing the “safe” functions
for the four kernel subsystems we tested. This reduces
the number of type errors by around 75% for both path
and source type errors.
While this is a signiﬁcant improvement, other means
for removing false positives are being examined. First,
there may be a signiﬁcant number of other “safe” func-
tions. Second, there are several cases where a variable
is assigned from another variable that is checked. In
the ﬁle system, often the dentry is authorized, then
the inode is assigned from the dentry->d_inode.
Unfortunately, CQUAL cannot yet reason that a ﬁeld
extracted from a checked structure is also checked
(see Section 5.2). Third, we have not yet fully examined
kernel-initiated paths that lead to type errors.
Subsystems
File System
Memory Management
Networking
IPC
Path Type Errors
With “Safe” Without “Safe”
Functions
Functions
%
Reduction
Source Type Errors
With “Safe” Without “Safe”
Functions
Functions
%
Reduction
73
18
431
2
37
14
73
2
49%
22%
83%
0%
57
17
308
2
31
13
55
2
45%
24%
82%
0%
Table 2: Error reduction after eliminating “safe” functions.
5 Discussion
Here we examine the effectiveness of our approach and a
possible extension to CQUAL that may improve its util-
ity.
5.1 Effectiveness of Our Approach
Given the extensive nature of static analysis, we are
somewhat surprised that we have only found a couple of
exploitable CQUAL type errors in our analysis. Some of
the analyses are fairly new, so we may ﬁnd more errors,
but this is a bit of a surprise.
We are encouraged by one of the exploits that we did
ﬁnd. The Category 1 TOCTTOU exploit is one that
would be difﬁcult to ﬁnd via runtime analysis. Typi-
cally, the association between the ﬁle descriptor and the
ﬁle would not change, so benchmarks consisting of be-
nign programs would not uncover this error. With static
analysis, the inconsistency was clear.
Another aspect of the effectiveness of our approach is
its ease of use, since most of the analysis process is au-
tomated. It is straightforward to apply the process to a
modiﬁed kernel or new releases of the kernel. We tested
this by running the tool against Linux version 2.4.18.
After the kernel source tree is downloaded, and a few
small changes are applied to the Makeﬁle and two source
ﬁles (see Section 3.2.1), the rest of the process requires
little manual effort (except for identifying false posi-
tives). The time it takes to complete the process is also
quite reasonable. As a matter of fact, most of the time
is spent on kernel builds - our modiﬁed version of GCC
collects information on controlled types while compiling
the source code.
Here we present the times for the major steps. These
numbers are only intended for a ballpark measure of the
effort needed to perform analysis, so they should not be
interpreted as representing the optimized performance of
the tools. The test platform was a 667 MHz Pentium
III machine with 128MB of memory. It took about 30
minutes to do the three clean kernel builds using our ex-
tended GCC to generate the annotation information. It
should be possible to perform all this analysis in one ker-
nel build, however. Most of that time is contributed by
the GCC backend that generates machine code (whereas
our GCC analysis code only works on the AST tree). We
compared normal kernel build time with the build time
that has our GCC analysis code enabled, and the differ-
ence is negligible. Annotation of the source by the Perl
scripts took about 1 minute, And ﬁnally, it took about
10 minutes for CQUAL to perform the analysis. With
the additional analysis overhead of a 15 minutes or less,
we expect that an optimized process can be done suf-
ﬁciently quickly for these tools to be useful for kernel
programmers.
5.2 Possible CQUAL Extension
A possible extension to CQUAL would enable us to cor-
rectly verify mediation between the controlled opera-
tions and all security-sensitive operations. The CQUAL
team has an interim solution and are looking into a gen-
eral solution [8]. We describe the problem here.
Currently, structures in CQUAL are treated as a collec-
tion of ﬁelds, so there is no relationship between a struc-
ture and its member ﬁelds. For example, in the code
below, var->bar would not have type checked even
though var does. Since structures are used extensively
in the kernel, we believe it would greatly enhance the
tool if CQUAL supports user-deﬁned rules for inferring
the types of member ﬁelds from the types of structures.
struct foo {
int bar;
};
$checked struct foo *var;
For instance, for case 3 in Section 3.2.5, we would
want the inode that is extracted from a checked den-
try to be checked as well.
In the case that a den-
try is unchecked, the inode of the dentry is implicitly
unchecked as well.
In addition, with current version of CQUAL, all in-
stances of a structure type share the same qualifer type.
For example, if bar is qualiﬁed as a checked type, all
instances of foo would have a checked ﬁeld for bar.
What we want is to assign qualiﬁer types to members on
a per-instance basis.
For verifying that the controlled operations mediate the
security-sensitive operations, we would also want any
structure ﬁeld accessed through a checked type to be
checked as well. This would enable us to propagate
authorizations through the structure completely. Then,
we could ﬁnd any members of a security-sensitive data
type that is not accessed through a controlled data type.
Note that this approach is not always applicable depend-
ing on the semantics of the qualiﬁcations. This would
not be appropriate for the type of qualiﬁers used by Wag-
ner et. al. [14].
6 Related Work
We are unaware of any other research work on static ver-
iﬁcation of LSM. However, a number of static analysis
tools that were successfully applied to the security do-
main. Here, we compare their work to ours.
Wagner et. al. [14] used CQUAL to identify format
string vulnerabilities. Their work motivated us to ap-
ply CQUAL to the more complicated problem of LSM
veriﬁcation. The main difference between our usage of
CQUAL and theirs lies in the annotation process. In their
work, the target code for annotations is well-deﬁned and
has a limited number of occurrences. Therefore, the an-
notations are done by hand. In our case, the scope of an-
notated code is much larger, and thus we employ GCC
to automatically detect the code to be annotated. We au-
tomate the process of marking as well.
Engler et al enables extension of GCC, called xgcc,
to do source analyses, which they refer to as meta-
compilation [7, 1]. A rule language, called metal, is
used to express the necessary analysis annotations in a
higher-level language. Since the rules match multiple
statements, the amount of annotation effort is reduced.
A variety of software bugs, including security vulnera-
bilities, have been found by this tool. While it appears
that xgcc could be used for the static analysis we per-
form, xgcc is not available at this time, so we are unable
to evaluate it. A key difference may be that metal rule
expressions will have to be extended to reference GCC
AST structures rather than the source directly.
Larochelle et. al. [11] enhanced their LCLint tool to de-
tect likely buffer overﬂows in C programs. The LCLint
tool bases static analysis on annotations of the programs
(or the libraries) that restrict the range of values a refer-
ence can have. The strength of LCLint is that the analy-
sis is ﬂow-sensitive, and thus more accurate. The down-
side of the LCLint tool is its inﬂexibility. The current
LCLint tool is customized to deal with a set of prede-
ﬁned software bugs. It appears that extending LCLint
for LSM veriﬁcation would require a signiﬁcant amount
of effort (i.e. adding new annotation types). CQUAL,
on the other hand, is more extensible by employing user-
deﬁned type qualiﬁer lattices.
Necula et.
al. [12] deﬁne the CCured type system.
CCured leverages the fact that most C source is writ-
ten in a type-safe manner to perform a variety of static
checks on the source during compilation for things like
buffer overﬂows. For things that cannot be checked stat-
ically, CCured introduces runtime checks into the code.
This enables certain kinds of errors to be caught regard-
less of whether they can be found statically or dynami-
cally. While we agree with this approach to veriﬁcation,
as yet the types of errors that CCured can ﬁnd do not
include authorization hook placement.
Koved et. al. [10] presented a technique for comput-
ing the access rights requirements of Java applications.
Their approach uses more powerful programming anal-
ysis techniques: a context-sensitive interprocedural data
ﬂow analysis is employed. Although the analysis is per-
formed on Java code, it is conceivable that such tech-
niques can be applied to our problem domain as well.
7 Conclusion
This paper presented a novel approach to the veriﬁcation
of LSM authorization hook placement using CQUAL, a
type-based static analysis tool. With a simple CQUAL
lattice conﬁguration and some simple GCC analysis,
we were able to verify complete mediation of opera-
tions on key kernel data structures. Our results re-
vealed some potential security vulnerabilities in the cur-
[9] J. Foster, M. Fahndrich, and A. Aiken. A theory of type
qualiﬁers. In ACM SIGPLAN Conference on Program-
ming Language Design and Implementation (PLDI ’99),
pages 192–203, May 1999.
[10] L. Koved, M. Pistoia, and A. Kershenbaum. Access
rights analysis for java.
In Proceedings of the 17th
Annual ACM Conference on Object-Oriented Program-
ming, Systems, Languages, and Applications (OOPSLA
2002), November 2002. Accepted for publication.
[11] D. Larochelle and D. Evans. Statically detecting likely
buffer overﬂow vulnerabilities.
In Proceedings of the
Tenth USENIX Security Symposium, pages 177–190,
2001.
[12] G. C. Necula, S. McPeak, and W. Weimer. CCured:
Type-safe retroﬁtting of legacy code. In Proceedings of
the 29th ACM Symposium on Principles of Programming
Languages (POPL02), January 2002.
[13] NSA. Security-Enhanced Linux (SELinux). Available at
http://www.nsa.gov/selinux.
[14] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner. De-
tecting format string vulnerabilities with type qualiﬁers.
In Proceedings of the Tenth USENIX Security Sympo-
sium, pages 201–216, 2001.
rent LSM framework, one of which we demonstrated to
be exploitable. We further showed that given authoriza-
tion requirements, CQUAL could be used to verify com-
plete authorization as well. Our results demonstrate that
combinations of conceptually simple tools can be pow-
erful enough to carry out fairly complex analyses.
Our main problem is the elimination of false positives.
Static analysis generally errs on the conservative side,
so we initially had a large number of type errors. How-
ever, we have identiﬁed techniques for secondary anal-
yses that can eliminate many of those false positives.
Extensions to CQUAL are necessary to eliminate some
types of false positives, but this is ongoing work.
8 Acknowledgments
We would like to thank Jeff Foster from UC Berkeley
for his timely responses to our numerous questions on
CQUAL and for his suggestions and advices on the early
draft of this paper. We also thank the anonymous review-
ers for their valuable comments.
References
[1] K. Ashcraft and D. Engler. Using programmer-written
compiler extensions to catch security holes. In Proceed-
ings of the IEEE Symposium on Security and Privacy
2002, May 2002.
[2] M. Bishop and M. Dilger. Checking for race conditions in
ﬁle accesses. Computing Systems, 9(2):131–152, 1996.
[3] LSM Community. Linux Security Module. Available at
http://lsm.immunix.org.
[4] Wirex Corp. Immunix security technology. Available at
http://www.immunix.com/Immunix/index.html.
[5] A Edwards.
[PATCH] add lock hook to pre-
vent race, January 2002.
Linux Security Modules
mailing list at http://mail.wirex.com/pipermail/linux-
security-module/2002-January/002570.html.
[6] A. Edwards, T. Jaeger, and X. Zhang. Verifying autho-
rization hook placement for the Linux Security Modules
framework. Technical Report 22254, IBM, December
2001.
[7] D. Engler, B. Chelf, A. Chou, and S. Hallem. Checking
system rules using system-speciﬁc, programmer-written
compiler extensions. In Proceedings of the Fourth Sym-
posium on Operation System Design and Implementation
(OSDI), October 2000.
[8] J. Foster. Personal communication, January 2002.
A “Safe” Functions List
Subsystems
File System
”Safe” Functions
put super
kill super
clean inode
iput
ﬁle operations.poll
super operations.write super
super operations.read inode
super operations.read inode2
super operations.put inode
super operations.clear inode
super operations.put super
block device operations.release
ﬁle operations.release
shmem recalc inode
shmem get inode
oom kill task
skb unlink
skb insert
skb reserve
Memory Management
Networking
Source Files
fs/super.c
fs/super.c
fs/inode.c
fs/inode.c
include/linux/fs.h
include/linux/fs.h
include/linux/fs.h
include/linux/fs.h
include/linux/fs.h
include/linux/fs.h
include/linux/fs.h
include/linux/fs.h
include/linux/fs.h
mm/shmem.c
mm/shmem.c
mm/oom kill.c
include/linux/skbuff.h
include/linux/skbuff.h
include/linux/skbuff.h