### Attack Performance on Graph-based CF (i.e., KGCN)

Next, we evaluate the performance of our availability and target attacks under the KGCN model using the ml-100k, am-d, and tr datasets. We compare our availability attack (ReverseA) with a random attack (RandomA) and our target attack (ReverseT) with another random attack (RandomT). The results, presented in Table 8, show the attack performance across various attack ratios, ranging from 0.1% to 5%.

**Table 8: Attack Results on KGCN**

| Attack Ratio (%) | PRE@10 (%) | HT@10 (%) |
|------------------|-------------|------------|
| **Dataset**      | **RandomA** | **ReverseA** | **RandomT** | **ReverseT** |
| **ml-100k**      | 1.57        | 3.40       | 0.66        | 1.04         |
| **am-d**        | 1.67        | 5.30       | 0.82        | 1.27         |
| **tr**          | 1.18        | 5.36       | 0.93        | 1.10         |
| **0.1**         |             |            |             |              |
| **ml-100k**      | 2.30        | 5.89       | 0.74        | 3.97         |
| **am-d**        | 2.80        | 7.26       | 1.01        | 5.36         |
| **tr**          | 1.94        | 7.10       | 1.00        | 3.29         |
| **0.3**         |             |            |             |              |
| **ml-100k**      | 3.74        | 12.54      | 1.34        | 11.74        |
| **am-d**        | 7.25        | 17.56      | 2.42        | 16.30        |
| **tr**          | 3.82        | 18.50      | 1.97        | 11.23        |
| **1.0**         |             |            |             |              |
| **ml-100k**      | 5.05        | 18.53      | 2.08        | 17.62        |
| **am-d**        | 11.36       | 42.08      | 5.30        | 30.11        |
| **tr**          | 4.72        | 36.11      | 3.22        | 15.39        |
| **3.0**         |             |            |             |              |
| **ml-100k**      | 7.64        | 25.87      | 5.77        | 22.78        |
| **am-d**        | 15.27       | 56.36      | 8.05        | 38.42        |
| **tr**          | 9.26        | 49.04      | 5.49        | 30.60        |
| **5.0**         |             |            |             |              |

Our availability and target attacks significantly outperform the random attacks across all datasets. Specifically, for the am-d dataset under the availability attack, our method achieves PRE@10 values of 5.30%, 7.26%, 10.33%, 17.56%, 42.08%, and 56.36% as the attack ratio increases from 0.1% to 5%. In contrast, RandomA only achieves PRE@10 values of 1.67%, 2.80%, 4.55%, 7.25%, 11.36%, and 15.27%. For the target attack, our method yields the best HT@10 of 38.42% compared to 8.05% for RandomT.

### Practicality of Our Attacks

The experimental results in Section 6.3 demonstrate the advantage of our proposed availability and target attacks over their counterparts across various dataset sizes. In real-world scenarios, it is impractical and rare to attack entire websites or large categories with many users. Instead, an attacker is more likely to focus on specific subcategories. To validate the practicality of our solutions, we conduct experiments on two subcategories: 'Crime/Documentary' from the ml-20m dataset and 'Blues' from the am-d dataset. The 'Crime/Documentary' subcategory includes 40 items and 858 users, while the 'Blues' subcategory has 3205 items and 6772 users.

We use the NCF recommender system to train the original datasets and then inject 100,000 sampled data points to train our surrogate model and generate attack strategies. The crafted fake users and their operations are injected into the original dataset to distort the recommendation results for the subcategories.

**Figure 8: Availability and Target Attacks on NCF for Subcategories**

- **(a) Availability Attack**: Figure 8(a) shows the PRE@10 values of our availability attack under the two subcategories. As the number of fake users increases, the attack performance improves. For example, adding 100 fake users results in PRE@10 values of 50.75% and 58.87% for 'Crime/Documentary' and 'Blues', respectively.
- **(b) Target Attack**: Figure 8(b) shows the HR@10 values of our target attack. Adding 100 fake users achieves HR@10 values of 39.65% and 42.89% for 'Crime/Documentary' and 'Blues', respectively. Despite the 'Blues' subcategory having more users and items, our attack performs better due to the lower average rating (3.14) compared to 'Crime/Documentary' (748).

To further validate the practicality, we explore 21,967 subcategories defined by eBay and find that a significant portion of these subcategories contain fewer than 10,000 items. This indicates that subcategories commonly have limited numbers of items in real-world websites.

We also evaluate our attack performance on more complex and dynamic recommender systems, with detailed results provided in Appendices A.9 and A.10.

### Discussion

Our work presents a novel black-box attack solution for social websites that employ CF-based recommender systems, demonstrating higher practicality and effectiveness. Here are some key points:

1. **Targeting Specific Subcategories**: Social websites typically have large numbers of users and items, making it unrealistic to target the entire website. Instead, attackers are more likely to focus on specific subcategories. Effective real-world attacks can be achieved by targeting multiple subcategories simultaneously, which is more practical and effective.

2. **Data Sampling and Compliance**: Our data sampling strictly follows the rate limitations set by social websites, ensuring that we do not trigger any abnormal behavior detection mechanisms. Our experiments never caused any blocking by the social websites, and our real attacks were performed on local datasets to avoid causing spam or malicious behaviors in the real world.

3. **Recommender Systems with Features**: Our solution aims to learn the item proximities via a surrogate model, which can capture the complex patterns from the recommender systems. This approach ensures that our attack remains effective even when the recommender systems incorporate additional features. The strong reproductive capability of our surrogate model, as shown in Section 6.2, validates its effectiveness.

### Conclusion

This paper introduces a novel black-box poisoning attack for CF-based recommender systems embedded in social websites. By collecting data from social websites and learning their implicit patterns, we trained a surrogate model that can reproduce the recommendation functionality of the original system. We then developed attack strategies for the surrogate model and applied them to the original recommender systems. Extensive experimental results demonstrate that our proposed solutions are more effective than their counterparts across four categories of CF recommender algorithms.

### Acknowledgments

This work was supported in part by NSF under Grants 1763620, 1948374, and 2019511. Any opinions and findings expressed in the paper are those of the authors and do not necessarily reflect the view of the funding agency.