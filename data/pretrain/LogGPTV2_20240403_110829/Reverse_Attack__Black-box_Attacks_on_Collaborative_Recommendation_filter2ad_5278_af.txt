upon injecting 5% fake users.
Attack Performance on Graph-based CF (i.e., KGCN ). We next
perform our availability attack and target attack under the KGCN
with the ml-100k, am-d, and tr datasets. We compare our availability
attack to RandomA and compare our target attack to RandomT , over
three datasets. Table 8 lists the attack results with various attack
ratios, ranging from 0.1% to 5%. Our availability and target attacks
both are seen to significantly outperform other methods, across
Figure 7: Target attack on neural network-based recom-
mender system under ml-1m and am-b datasets.
Table 8: The results of our availability attack, target attack,
RandomA, and RandomT under graph-based CF, i.e., KGCN
PRE@10(%)
RandomA
ml-100k
am-d
tr
ReverseA
ml-100k
am-d
tr
HT @10(%)
RandomT
ReverseT
ml-100k
am-d
tr
ml-100k
am-d
tr
0.1
1.57
1.67
1.18
3.40
5.30
5.36
0.1
0.66
0.82
0.93
1.04
1.27
1.10
0.3
2.30
2.80
1.94
5.89
7.26
7.10
0.3
0.74
1.01
1.00
3.97
5.36
3.29
1.0
3.74
7.25
3.82
12.54
17.56
18.50
Attack Ratio (%)
0.5
2.51
4.55
2.07
7.69
10.33
10.25
Attack Ratio (%)
0.5
1.25
1.89
1.54
6.72
10.02
7.82
1.0
1.34
2.42
1.97
11.74
16.30
11.23
3.0
5.05
11.36
4.72
18.53
42.08
36.11
3.0
2.08
5.30
3.22
17.62
30.11
15.39
5.0
7.64
15.27
9.26
25.87
56.36
49.04
5.0
5.77
8.05
5.49
22.78
38.42
30.60
all datasets. Specifically, with am-d under availability attack, our
method achieves PRE@10 of 5.30%, 7.26%, 10.33%, 17.56%, 42.08%,
and 56.36% when r increases from 0.1% to 0.3%, 0.5%, 1%, 3% and
5%, while RandomA only has the PRE@10 of 1.67%, 2.80%, 4.55%,
7.25%, 11.36% and 15.27%. For target attack, our attack yields the
best HT @10 of 38.42% while RandomT only has HT @10 of 8.05%.
6.4 Practicality of Our Attacks
The experimental results in Section 6.3 have exhibited the advantage
of both proposed availability and target attacks over the compared
counterparts on various dataset sizes. In the real-world scenario,
it is impractical and rare to attack the entire websites or a large
category with many users; instead, an attacker may more likely be
interested in a specific subcategory. Hence, we next conduct ex-
periments to show our attack performance on some subcategories,
024Attackratio(%)0102030PRE@10(%)NCFCMLDCFFASTNCFACMLADCFAFASTA024Attackratio(%)0204060PRE@10(%)NCFCMLDCFFASTNCFACMLADCFAFASTA024Attackratio(%)01020HR@10(%)NCFTCMLTDCFTFASTTBaseline024Attackratio(%)01020304050HR@10(%)NCFTCMLTDCFTFASTTBaselineSession 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea62(a) Availability attack
(b) Target attack
Figure 8: Availability attack and target attack on NCF for
‘Crime/Documentary’ and ‘Blues’ subcategories.
for validating the practicality of our solutions. We extract two sub-
categories ‘Crime/Documentary’ and ‘Blues’ from the ml-20m and
am-d dataset, respectively. The former subcategory includes 40
items and 858 users whereas the latter one has 3205 items and 6772
users. The recommender system NCF is employed as the underlying
algorithm to train the original dataset, i.e., ml-20m, and am-d, for
recommendation. For each subcategory, we take 100, 000 sampling
trails, and use the collected data for training our surrogate model
and for generating our availability and target attack strategies. The
crafted fake users and their operations from our solution will be
injected into the original dataset for distorting the recommendation
results of the subcategory. Figure 8(a) shows the PRE@10 values
of our availability attack under the two subcategories. From this
figure, we observe that attack performance rises with an increase
in the fake user amounts. Specifically, when adding 100 fake users,
our attack can achieve the PRE@10 values of 50.75% and 58.87%,
respectively, on ‘Crime/Documentary’ and ‘Blues’ subcategories.
Figure 8(b) shows the HR@10 of our target attack on the two subcat-
egories. It is seen that when adding 100 fake users, our target attack
achieves the HR@10 values of 39.65%, and 42.89%, respectively. We
also observe that although the ‘Blues’ subcategory includes more
users and items, our attack performance is better under it than
under the ‘Crime/Documentary’ subcategory. The reason is that,
the items in am-d have less ratings (i.e., 3.14 rating in average) than
those in ml-20m (i.e., 748 ratings in average), thereby making it
easier for the item relationships to be distorted.
To further validate the practicality, we explore 21, 967 subcat-
egories defined by eBay[21] and then browse each subcategory
name from two largest E-commerce websites (eBay and Amazon),
to see the size of each category. We found that, in eBay, 19.39% of
the subcategories contain less than 1000 items and 41.98% of the
subcategories contain less than 10, 000 items. In Amazon, 26.91% of
subcategories contains less than 1000 items and 76.51% of the sub-
categories contain less than 10, 000 items. The detailed distribution
of all subcategory sizes are shown in Figure 11 of Appendix A.8.
Such results evidence subcategories commonly have limited num-
bers of items in real-world websites.
We further evaluate our attack performance upon the compli-
cated recommender systemsthe and the dynamic recommender
systems, with results deferred to Appendix A.9 and Appendix A.10,
respectively, due to the page limit.
7 DISCUSSION
Our work presents a novel black-box attack solution to the social
websites that employ the CF-based recommender systems, with
higher practicality and effectiveness. This section gives some dis-
cussions on our work below.
First, the social websites possess large numbers users and items,
so it is unrealistic and uncommon to target the entire websites or a
large category with many users, for achieving the attack purpose.
Instead, an attacker may more likely be interested in the specific
subcategories to attack. For performing an effective real-world
attack, one can let each attack target a subcategory/group of items
(with fewer items as what pervasively exists in social websites
detailed in Section 6.4) and then launch multiple parallel attacks to
different subcategories simultaneously. This way of attack is more
practical and effective.
Second, our data sampling collection strictly follows the social
websites’ rate limitation, never triggering their incorporated abnor-
mal behavior detection mechanisms. The ‘robots.txt’ file stipulates
the crawler’s behaviors, which can only acquire resources that are
publicly available from the social websites. Our experiments in Sec-
tion 6 never trigger any blocking by the social websites. On the other
hand, our real attacks are only performed on the local dataset for
testing, rather than the actual websites themselves, avoiding from
causing spam/malicious behaviors to the real-world. In practice, an
attacker my leverage clusters to boost the number of requests to a
specific website.
Third, this work aims to demonstrates the plausibility of our
black-box attack on a collection of CF-based recommender systems.
Definitely, some recommender systems may incorporate certain
features extracted from users/items to enhance their recommen-
dation outcomes. Given that the nature of our solution is to first
learn the item proximities via a surrogate model, able to capture the
complicated patterns from the recommender systems, our proposed
attack shall still work on those systems. The strong reproductive ca-
pability of our surrogate model on the online social data presented
in Section 6.2 has validated that our surrogate model is powerful
enough to learn the item proximity regardless of the underlying
algorithms. Our experimental results in Section A.9 on attacking
the recommender system with features incorporated have validated
this point. More exploration is left in our future work.
8 CONCLUSION
This paper has developed a novel black-box poisoning attack to the
CF recommender systems embedded in social websites. Without
prior knowledge about the recommender algorithm or historical
data information, we collected data from social websites and learned
their implicit patterns for training a surrogate model, which can
reproduce the recommendation functionality of the original rec-
ommender system. We then crafted solutions for surrogate model
attack before applying them to attack the original recommender sys-
tems for similar goals. Extensive experimental results have demon-
strated that our proposed solutions are more effective in all four
categories of CF recommender algorithms than their counterparts.
ACKNOWLEDGMENTS
This work was supported in part by NSF under Grants 1763620,
1948374, and 2019511. Any opinion and findings expressed in the
paper are those of the authors and do not necessarily reflect the
view of funding agency.
20406080100#offakeusers2040PRE@10(%)Crime/DocumentaryBlues20406080100#offakeusers10203040HR@10(%)Crime/DocumentaryBluesSession 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea63REFERENCES
[1] Airbnb. 2021. robots.txt. https://www.airbnb.com/robots.txt.
[2] Amazon. 2020. Amazon.com. https://www.amazon.com/.
[3] Amazon. 2021. robots.txt. https://www.amazon.com/robots.txt.
[4] Aminer. 2020. Aminer.org. https://aminer.org/citation/.
[5] Frederick Ayala-Gómez, Bálint Daróczy, András Benczúr, Michael Mathioudakis,
and Aristides Gionis. 2018. Global citation recommendation using knowledge
graphs. Journal of Intelligent & Fuzzy Systems 34, 5 (2018), 3089–3100.
[6] Oren Barkan and Noam Koenigstein. 2016. Item2vec: neural item embedding
for collaborative filtering. In Proceedings of the 26th International Workshop on
Machine Learning for Signal Processing (MLSP). 1–6.
[7] Léon Bottou. 2010. Large-scale machine learning with stochastic gradient de-
scent. In Proceedings of the International Conference on Computational Statistics
(COMPSTAT). 177–186.
[8] John S Breese, David Heckerman, and Carl Kadie. 1998. Empirical analysis
of predictive algorithms for collaborative filtering. In Proceedings of the 14th
Conference on Uncertainty in Artificial Intelligence. 43–52.
[9] Robin Burke, Bamshad Mobasher, and Runa Bhaumik. 2005. Limited knowledge
shilling attacks in collaborative filtering systems. In Proceedings of 3rd Interna-
tional Workshop on Intelligent Techniques for Web Personalization (ITWP), 19th
International Joint Conference on Artificial Intelligence (IJCAI). 17–24.
[10] Robin Burke, Bamshad Mobasher, Roman Zabicki, and Runa Bhaumik. 2005.
Identifying attack models for secure recommendation. Beyond Personalization
(2005).
[11] John Canny. 2002. Collaborative filtering with privacy via factor analysis. In
Proceedings of the 25th Annual International ACM SIGIR Conference on Research
and Development in Information Retrieval. 238–245.
[12] Dong-Kyu Chae, Jin-Soo Kang, Sang-Wook Kim, and Jung-Tae Lee. 2018. Cfgan:
A generic collaborative filtering framework based on generative adversarial
networks. In Proceedings of the 27th ACM International Conference on Information
and Knowledge Management. 137–146.
[13] Hsinchun Chen, Xin Li, and Zan Huang. 2005. Link prediction approach to
collaborative filtering. In Proceedings of the 5th ACM/IEEE-CS Joint Conference on
Digital Libraries (JCDL’05). 141–142.
[14] Konstantina Christakopoulou and Arindam Banerjee. 2018. Adversarial recom-
mendation: Attack of the learned fake users. (2018).
[15] Konstantina Christakopoulou and Arindam Banerjee. 2019. Adversarial attacks
on an oblivious recommender. In Proceedings of the 13th ACM Conference on
Recommender Systems. 322–330.
[16] Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks
for youtube recommendations. In Proceedings of the 10th ACM Conference on
Recommender Systems. 191–198.
[17] James Davidson, Benjamin Liebald, Junning Liu, Palash Nandy, Taylor Van Vleet,
Ullas Gargi, Sujoy Gupta, Yu He, Mike Lambert, Blake Livingston, et al. 2010. The
YouTube video recommendation system. In Proceedings of the 4th ACM Conference
on Recommender Systems. 293–296.
[18] Jason V Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and Inderjit S Dhillon. 2007.
Information-theoretic metric learning. In Proceedings of the 24th International
Conference on Machine Learning. 209–216.
[19] Chrysanthos Dellarocas. 2000. Immunizing online reputation reporting systems
against unfair ratings and discriminatory behavior. In Proceedings of the 2nd ACM
Conference on Electronic Commerce. 150–157.
[20] Tommaso Di Noia, Daniele Malitesta, and Felice Antonio Merra. 2020. TAaMR:
Targeted adversarial attack against multimedia recommender systems. In Pro-
ceedings of the 50th Annual IEEE/IFIP International Conference on Dependable
Systems and Networks Workshops (DSN-DSML’20).
[21] eBay. 2021. US new category structure. https://ir.ebaystatic.com/pictures/aw/
pics/catchanges/2021/May/NTF-update/US_New_Structure_(May2021)_NFT-
update.csv.
[22] Wenqi Fan, Tyler Derr, Xiangyu Zhao, Yao Ma, Hui Liu, Jianping Wang, Jiliang
Tang, and Qing Li. 2020. Attacking Black-box Recommendations via Copying
Cross-domain User Profiles. (2020).
[23] Minghong Fang, Neil Zhenqiang Gong, and Jia Liu. 2020. Influence function
based data poisoning attacks to top-n recommender systems. In Proceedings of
The Web Conference. 3019–3025.
[24] Minghong Fang, Guolei Yang, Neil Zhenqiang Gong, and Jia Liu. 2018. Poisoning
attacks to graph-based recommender systems. In Proceedings of the 34th Annual
Computer Security Applications Conference (ACSAC). 381–392.
[25] fast.ai. 2020. collab. https://docs.fast.ai/collab.html.
[26] Francois Fouss, Alain Pirotte, Jean-Michel Renders, and Marco Saerens. 2007.
Random-walk computation of similarities between nodes of a graph with appli-
cation to collaborative recommendation. IEEE Transactions on Knowledge and
Data Engineering 19, 3 (2007), 355–369.
[27] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial
nets. In Proceedings of the Advances in Neural Information Processing Systems.
2672–2680.
[28] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and
harnessing adversarial examples. (2014).
[29] Mihajlo Grbovic and Haibin Cheng. 2018. Real-time personalization using em-
beddings for search ranking at airbnb. In Proceedings of the 24th ACM SIGKDD
International Conference on Knowledge Discovery & Data Mining. 311–320.
[30] Asnat Greenstein-Messica and Lior Rokach. 2018. Personal price aware multi-
seller recommender system: Evidence from eBay. Knowledge-Based Systems 150
(2018), 14–26.
[31] Ihsan Gunes, Alper Bilge, and Huseyin Polat. 2013. Shilling attacks against
memory-Based privacy-preserving recommendation algorithms. KSII Transac-
tions on Internet & Information Systems 7, 5 (2013).
[32] Ihsan Gunes, Cihan Kaleli, Alper Bilge, and Huseyin Polat. 2014. Shilling attacks
against recommender systems: A comprehensive survey. Artificial Intelligence
Review 42, 4 (2014), 767–799.
[33] Larry Hardesty. 2020. The history of Amazon’s recommendation algorithm. https:
//www.amazon.science/the-history-of-amazons\-recommendation-algorithm.
[34] F Maxwell Harper and Joseph A Konstan. 2016. The movielens datasets: History
and context. ACM Transactions on Interactive Intelligent Systems (TIIS) 5, 4 (2016),
19.
[35] Ruining He and Julian McAuley. 2016. Ups and downs: Modeling the visual
evolution of fashion trends with one-class collaborative filtering. In Proceedings
of the 25th International Conference on World Wide Web (WWW). 507–517.
[36] Xiangnan He, Zhankui He, Xiaoyu Du, and Tat-Seng Chua. 2018. Adversarial
personalized ranking for recommendation. In Proceedings of the 41st International
ACM SIGIR Conference on Research & Development in Information Retrieval. 355–
364.
[37] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng
Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th International
Conference on World Wide Web (WWW). 173–182.
[38] Cheng-Kang Hsieh, Longqi Yang, Yin Cui, Tsung-Yi Lin, Serge Belongie, and
Deborah Estrin. 2017. Collaborative metric learning. In Proceedings of the 26th
International Conference on World Wide Web (WWW). 193–201.
[39] Rui Hu, Yuanxiong Guo, Miao Pan, and Yanmin Gong. 2019. Targeted poison-
ing attacks on social recommender systems. In Proceedings of the IEEE Global
Communications Conference (GLOBECOM). 1–6.
[40] Yifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for
implicit feedback datasets. In Proceedings of the 8th IEEE International Conference
on Data Mining. 263–272.
[41] Hai Huang, Jiaming Mu, Neil Zhenqiang Gong, Qi Li, Bin Liu, and Mingwei
Xu. 2021. Data poisoning attacks to deep learning based recommender systems.
In Proceedings of the Annual Network & Distributed System Security Symposium
(NDSS).
[42] Tao Huang, Huan Zhou, and Kai Zhou. 2017. Food recommender system on
Amazon. San Diego: University of California San Diego (2017).
[43] Bar Ifrach. 2020. How Airbnb uses machine learning to detect host prefer-
ences. https://medium.com/airbnb-engineering/how-airbnb-uses\-machine-
learning-to-detect-host-\preferences-18ce07150fa3.
[44] Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech-
niques for recommender systems. IEEE Computer 8 (2009), 30–37.
[45] Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech-
niques for recommender systems. Computer 8 (2009), 30–37.
[46] Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2016. Adversarial examples
in the physical world. (2016).
[47] Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. 2010. What is
Twitter, a social network or a news media?. In Proceedings of the 19th International
Conference on World Wide Web (WWW). 591–600.
[48] Shyong K Lam and John Riedl. 2004. Shilling recommender systems for fun and
profit. In Proceedings of the 13th International Conference on World Wide Web
(WWW). 393–402.
[49] Jure Leskovec and Julian J Mcauley. 2012. Learning to discover social circles in
ego networks. In Proceedings of the Annual Conference on Advances in Neural
Information Processing Systems (NIPS). 539–547.
[50] Omer Levy and Yoav Goldberg. 2014. Neural word embedding as implicit ma-
trix factorization. Proceedings of the Annual Conference on Advances in Neural
Information Processing Systems 27 (2014), 2177–2185.
[51] Bo Li, Yining Wang, Aarti Singh, and Yevgeniy Vorobeychik. 2016. Data poison-
ing attacks on factorization-based collaborative filtering. In Proceedings of the
Advances in Neural Information Processing Systems (NIPS). 1885–1893.
[52] Sheng Li, Jaya Kawale, and Yun Fu. 2015. Deep collaborative filtering via marginal-
ized denoising auto-encoder. In Proceedings of the 24th ACM International on
Conference on Information and Knowledge Management (CIKM). 811–820.
[53] Chen Lin, Si Chen, Hui Li, Yanghua Xiao, Lianyun Li, and Qian Yang. 2020.
Attacking Recommender Systems with Augmented User Profiles. (2020).
[54] Greg Linden, Brent Smith, and Jeremy York. 2003. Amazon.com recommendations:
Item-to-item collaborative filtering. IEEE Internet Computing 1 (2003), 76–80.
[55] Dong Liu and Wenjun Jiang. 2018. Personalized app recommendation based
on hierarchical embedding. In Proceedings of the IEEE SmartWorld, Ubiquitous
Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing &
Session 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea64Communications, Cloud & Big Data Computing, Internet of People and Smart City
Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI). 1323–1328.