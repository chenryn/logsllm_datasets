### The Complete Guide to Distributed Tracing

**Author: Daniel “Spoons” Spoonhower, Lightstep CTO and Co-Founder**

#### About the Author
Daniel "Spoons" Spoonhower, the CTO and co-founder of Lightstep, has published papers on the performance of parallel programs, garbage collection, and real-time programming. He holds a PhD in programming languages but is still searching for one he truly loves.

- Follow on Twitter: [@save_spoons](https://twitter.com/save_spoons)
- Connect on LinkedIn: [spoons](https://www.linkedin.com/in/spoons)

---

### Introduction

In the context of DevOps and distributed architectures, it is crucial for organizations, especially larger ones with mission-critical demands, to enable loosely coupled work across teams for fast, independent problem solving. This requires building strong abstractions not only between teams but also between services. On a human level, this involves developing common tools, strategies, and best practices for inter-team communication. At the software level, these abstractions include orchestration layers, common build and deployment tools, and shared monitoring services.

However, what about observability? How do you understand what your users are experiencing? Can metrics alone solve this? How do you communicate effectively across teams during an incident? This guide will address these questions and more by exploring how to establish true observability with distributed tracing.

1. **Decision Making Based on User Impact:** Learn how to focus on symptoms that directly affect users.
2. **Connecting Cause and Effect:** Discover how to perform root cause analysis during incidents and proactively improve efficiency and customer experience through performance optimization.

---

### A Review of Distributed Tracing

Distributed tracing is a diagnostic technique that reveals how a set of services coordinate to handle individual user requests. It is a critical part of observability, providing context for other telemetry and helping to define which metrics are most valuable in a given situation.

A single trace shows the activity for an individual transaction or request as it propagates through an application, from the browser or mobile device down to the database and back. In aggregate, traces can highlight which backend service or database is most impacting performance and user experience.

Microservices and serverless architectures offer advantages in application development but reduce visibility. While teams can manage, monitor, and operate their individual services more easily, tracking global system behavior becomes more challenging. During an incident, without tracing, it is nearly impossible to pinpoint the responsible service from those merely affected by the issue.

Tracing provides end-to-end visibility, revealing service dependencies and showing how services interact. By visualizing transactions in their entirety, you can compare anomalous traces against performant ones, identifying the culprit and addressing performance bottlenecks directly.

---

### Anatomy of a Trace

In distributed tracing, a single trace contains a series of tagged time intervals called spans. A span represents a unit of work with a start and end time, and may include metadata like logs or tags. Spans have relationships, including parent-child relationships, to show the specific path a transaction takes through the services or components.

- **Trace:** Represents an end-to-end request, made up of one or multiple spans.
- **Span:** Represents work done by a single service with time intervals and associated metadata.
- **Tag:** Metadata to help contextualize a span.

Traces provide a request-centric view, enabling all teams to understand issues from the user’s perspective, even as the architecture allows for independent work.

---

### Understanding Trace Data

A single trace represents an end-to-end request and may consist of one or thousands of spans. Each span is a timed event with metadata, representing the work done by a particular service. Time moves from left to right in a trace, with the start on the left and the finish on the right. The duration, service name, and operation (endpoint or description) are provided. The critical path, highlighted in yellow, shows the combination of work determining the overall action's completion time.

For a detailed look at the mechanics of tracing, refer to the technical report by Benjamin Sigelman, Lightstep CEO and co-founder, on Dapper, a large-scale distributed tracing infrastructure developed at Google.

---

### Let Users Drive Decision Making

Service owners, engineers, and operators should consider:
- What do users expect from the application?
- How will they measure success?
- What will they do if expectations are not met?
- Are you prepared to handle failures?

These questions are vital for addressing service performance and can be formalized through service levels.

- **Service Level Indicator (SLI):** Measurable data such as latency, uptime, and error rate.
- **Service Level Objective (SLO):** Defines the target for SLIs, e.g., p99 latency < 1s; 99.9% uptime; <1% errors.
- **Service Level Agreement (SLA):** Financial or contractual consequences for failing to meet SLOs, such as refunds or cancellations.

From an engineering perspective, service levels reflect customer expectations and help prioritize responses to performance demands.

---

### Choosing the Correct Scope for Your Service Levels

The correct granularity for your SLI depends on the specific operations of your service. For example, a service with two endpoints (read and write) might require separate SLIs for each operation to provide meaningful insights.

- **High Percentile Latency:** Outlier latency issues can compromise performance.
- **Error Rate:** Real-time alerts for system problems.
- **Throughput:** Important but tricky to set due to its independence from user behavior.
- **Saturation:** Utilization of resources, crucial for understanding scaling needs.

Focus on what is critical to your users. For instance, a low-frequency trading company might prioritize correctness over uptime.

---

### Understanding Latency Percentiles in Distributed Systems

Latency percentiles are crucial in distributed systems. Consider a search system spanning many shards. If the bottom services have an average latency of one millisecond but a 99th percentile latency of one second, one percent of traces are one thousand times slower than the average.

If a request involves a hundred of these services, 63% of end-user requests will take more than a second. As system complexity increases, rare behaviors like 99th percentile latency can be magnified. Measuring 99th percentile metrics throughout the stack helps understand how latencies are magnified as they travel up the stack.

---

This guide aims to provide a comprehensive understanding of distributed tracing and its importance in modern, distributed architectures.