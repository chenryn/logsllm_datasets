for the rest of the evaluation. This leads to very eﬃcient
implementations since the parties only need to store inter-
mediate values and garbled gates on disk. Moreover, it im-
proves the latency of the protocol since the garbler and the
evaluator can operate simultaneously. Previous work, how-
ever, has only shown how to pipeline garbled circuits in the
presence of semi-honest adversaries.
1.2 Our Contributions
Secure function evaluation is an important and powerful
cryptographic primitive and many of its underlying tech-
niques, such as garbled circuits, oblivious transfer and secret
sharing, are important in their own right. As such, SFE and
the underlying primitives that enable it have a wide array of
applications and if made practical could have a large impact
on the design of secure and privacy-preserving technologies.
Today, the server-aided approach seems to be one of the
most promising directions for scaling SFE and overcoming
the inherent limitations of the optimization techniques dis-
covered in previous work. In addition, given the recent emer-
gence of public clouds, such as Amazon EC2 and Microsoft
Azure, server-aided SFE can be implemented broadly and
at low-cost.
In this work, we revisit the server-aided setting from a
more practical point of view and explore the extent to which
we can take advantage of this model and design protocols
that are more eﬃcient and practical than what was previ-
ously known [18, 32]. Our ﬁndings are quite positive as we
make the following contributions.
Fairness. We extend the server-aided model to provide fair-
ness, which guarantees that either all parties will receive
their outputs or none will. Fairness is an important prop-
erty to achieve in the context of practical SFE as it provides
an incentive for parties not to abort the protocol after re-
ceiving their outputs.
A generic transformation. In the full version of the pa-
per we give a black-box transformation from any two-party
SFE protocol secure against malicious adversaries to a multi-
party server-aided SFE protocol. This yields a generic com-
piler for designing eﬃcient server-aided SFE protocols and
provides a point of comparison for custom-designed con-
structions.
Efficient server-aided protocols. We design two new
single-server-aided multi-party SFE protocols. Both are based
on garbled circuits, achieve fairness and are more eﬃcient
than any of the previously-known protocols [18, 32], or the
generic construction mentioned above. In addition, the eﬃ-
ciency of the ﬁrst protocol can be increased if it is used in
the presence of a covert server (i.e., a server that wants to
cheat but does not want to be caught) [2].
One of the reasons behind the improved eﬃciency is a
new input checking mechanism for the cut-and-choose step
that only requires a linear number of commitments (in the
total length of the inputs), as opposed to previously-known
alternatives that either require a quadratic number of com-
mitments (in the security parameter) or a linear number of
exponentiations.
In settings where the total input length is relatively small
compared to the square of the security parameter (which is
roughly 17, 000) our approach is signiﬁcantly more eﬃcient.
For example, for the AES circuit our construction reduces
the total size of the commitments from more than 100MB
(in the quadratic case) to around 1MB.
Pipelining with malicious adversaries. We introduce
a new pipelining technique that works in the presence of a
malicious adversary. As discussed above, previous solutions
799were only applicable to the semi-honest setting and did not
work when considering malicious adversaries. We note that
in independent and concurrent work, Kreuter, shelat and
Shen [36] describe an approach similar to ours.
Experimental evaluation. We implement our protocols
and evaluate their eﬃciency empirically over two large cir-
cuits: (1) the AES circuit which has roughly 30, 000 gates;
and (2) the edit distance circuit for 50 character strings of
8 bits each which has roughly 250, 000 gates. Naturally,
all parties but P1 have to do very little work. Interestingly,
however, our experiments show a signiﬁcant reduction in the
total running times—even for the server and P1. For AES,
our ﬁrst protocol (which is secure against a covert server)
is roughly 6× faster than the covert protocol of [52]. Our
second protocol (which secure against a malicious server), is
roughly 4× faster than the most optimized 2SFE implemen-
tation [55]. Moreover, a nice property that our experiments
illustrate is that the running time of our second protocol is
almost independent of the number of the parties involved.
2 Model and Deﬁnitions
Practical server-aided SFE with a single server has only been
achieved in certain speciﬁc adversarial models. In particu-
lar, as shown in [32], the garbled-circuit-based protocol of
Feige, Killian and Naor from [18] is a secure sever-aided SFE
protocol against a set of non-colluding semi-honest adver-
saries, that is, adversaries that follow the protocol and are
independent in the sense that they do not share any infor-
mation before or after the protocol execution. [32] also gives
protocols that are secure in the presence of non-cooperating
adversaries which, roughly speaking, are adversaries that de-
viate from the protocol but do not send information other
than what prescribed by the protocol (note that a non-
cooperating adversary is stronger than a semi-honest ad-
versary).
A natural question, therefore, is whether these relaxations
of the adversarial model are necessary in order to achieve
practical server-aided SFE and all the advantages it pro-
vides, such as asymmetric eﬃciency (i.e., diﬀerent parties
needing diﬀerent amounts of resources) and sub-linear work.
Asymmetric efficiency in the standard model? Con-
sider a solution that does not make use of the relaxations de-
scribed above. In particular, one might attempt to design an
eﬃcient server-aided protocol between parties (P1 . . . , Pn)
and a server S, such that: (1) a subset of the parties do sub-
linear work; and (2) the server and the remaining parties
do work that is polynomial in the size of the circuit. Such
a protocol with security in the standard adversarial model,
however, would yield a 2SFE protocol with low communica-
tion and computation for one party 1 which, currently, can
only be constructed based on FHE [14].
Server-aided SFE from any two-party SFE. A sec-
ond promising attempt (and a successful one) is to take
advantage of the fact that the server and P1 are never si-
multaneously malicious. With this assumption in place, one
can indeed design practical protocols wherein all the parties
1Given such a server-aided SFE protocol one can construct
a standard two-party protocol by having the ﬁrst party sim-
ulate the subset of the parties who perform sub-linear work
and having the second party simulate the server S and the
remaining parties.
but P1 perform very little work (only proportional to their
own input). The idea is as follows: the players (P2, . . . , Pn)
share their inputs between S and P1, and let them run a
general-purpose 2SFE protocol (with security against mali-
cious adversaries) for computing the desired function on the
players’ inputs. This approach is promising but for it to
work one needs to enhance the 2SFE protocol with mecha-
nisms to convince the players that: (1) their real inputs were
used (note that the security of 2SFE does not imply this);
and (2) the output of the 2SFE is delivered back to them
(2SFE guarantees output correctness but not honest delivery
of the output to P2 through Pn). In the full version of the
paper we describe an eﬃcient solution that addresses both
issues, and works with any general-purpose 2SFE protocol
with security against malicious adversaries.
Better efficiency than 2SFE? An important question
is whether the server-aided setting can lead to more eﬃcient
protocols than the standard setting or whether the best we
can hope for is to achieve the complexity of existing 2SFE
protocols. Unfortunately, the latter is indeed the case in
general, i.e., if we insist on security with respect to all pos-
sible adversarial settings. Suppose, for example, that we
require the server-aided protocol to be secure in the pres-
ence of either: (1) a malicious server and a single malicious
party (say Pt); or (2) an honest server and all but one ma-
licious parties. The overall complexity of such a protocol
(even if carefully optimized) will always be greater than the
complexity of the most eﬃcient 2SFE protocol with security
against malicious adversaries.
To see why, we sketch how one can use such a protocol to
construct a 2SFE protocol secure against malicious adver-
saries. Let A and B be the two parties who want to engage
in a 2SFE protocol. A runs the server-aided protocol sim-
ulating the server and Pt with A’s input, and B runs the
protocol simulating the rest of the parties (and sharing his
input between them). If A is malicious, the security of the
server-aided protocol against a malicious server and a mali-
cious Pt guarantees security. If B is malicious, the security
of the server-aided protocol against an honest server and a
colluding set of all but one malicious parties (Pt in this case)
implies security for the 2SFE protocol.
On a positive note, we show that if we restrict ourselves
to certain adversarial settings then we can indeed do better
than 2SFE. More precisely, we show that by only requiring
security in the presence of a non-cooperative server, we can
do much better.
2.1 Formal Model
We recall the ideal/real-model security deﬁnition for MPC
in the presence of non-cooperative adversaries presented in
[32]. At a high level, the deﬁnition compares the real-model
execution of a protocol for computing an n-party function f
to the ideal-model evaluation of f by a trusted party in the
presence of m independent adversaries (A1, . . . , Am) that
are assumed not to collude.
Non-collusion in MPC. The standard adversarial models
for MPC include: (1) semi-honest adversaries which follow
the protocol but attempt to learn extra information from
their view of the execution; and (2) malicious adversaries
which can deviate arbitrarily from the protocol. The re-
cently proposed notion of non-cooperative adversaries [32]
captures adversaries that may deviate from the protocol but
800that do not share any information that is not prescribed by
the protocol.
Definition 2.1
(Non-cooperative adversary [32]).
An adversary Ai is non-cooperative with respect to adversary
Aj if the messages Ai sends to Aj reveal no information
about Ai’s private values (i.e., its coins and input) to Aj
beyond what can be inferred from Aj ’s output fj (x).
Note that the notion of non-cooperation only restricts the
information revealed by Ai’s messages and does not imply
that Ai is semi-honest. Indeed, Ai could deviate from the
protocol without revealing any information to Aj about its
private values, e.g., by garbling a function f ′
6= f when
required to garble f .
2.2 Security Deﬁnition
Our security deﬁnition is similar to the one presented in [32]
with the exception that it guarantees fairness and handles
the case when the server is covert. (See [22] for more details
about the idea-model/real-model security for MPC.) At a
high level, fairness is guaranteed by modifying the behavior
of the trusted party in the ideal-model execution so that it
sends ⊥ to all parties if any party chooses to abort (note
that the fairness guarantee does not extend to the server).
We capture covertness using the explicit cheat formulation of
[2] which augments the ideal-model execution by allowing a
covert adversary A to send a cheat instruction to the trusted
party. Upon receiving this instruction, the trusted party
sends A all the inputs and takes one of two possible actions:
with probability ǫ it discloses to all parties that A cheated
and with probability 1 − ǫ it does not.
Real-model execution. The real-model execution of pro-
tocol Π takes place between parties (P1, . . . , Pn), server Pn+1
and adversaries (A1, . . . , Am+1), where m ≤ n.
At the beginning of the execution, each party (P1, . . . , Pn)
receives its input xi, a set of random coins ri, and an aux-
iliary input zi while the server Pn+1 receives only a set of
random coins rn+1 and an auxiliary input zn+1. Each ad-
versary (A1, . . . , Am) receives an index i ∈ I that indicates
the party it corrupts, while adversary Am+1 receives a set of
indices that indicate the parties it will corrupt (this captures
the fact that these parties collude).
For all honest parties Pi, let outi denote its output and
for all corrupted parties Pi, let outi denote its view during
the execution of Π. The ith partial output of a real-model
execution of Π between parties (P1, . . . , Pn+1) in the pres-
ence of adversaries A = (A1, . . . , Am+1) is deﬁned as
real(i)(k, x; r)
def
= (cid:8)outj : j ∈ H(cid:9) ∪ outi.
where H denotes the set of honest parties and r = (r1, . . . ,
rn+1).
Ideal-model execution. In the ideal-model execution, all
the parties interact with a trusted party that evaluates f .
As in the real-model execution, the ideal execution begins
with each party (P1, . . . , Pn) receiving its input xi, its coins
ri and an auxiliary input zi, while the server Pn+1 receives
only its coins rn+1 and an auxiliary input zn+1. Each party
(P1, . . . , Pn) sends x′
i = xi
if Pi is semi-honest and x′ is an arbitrary value if Pi is ei-
ther malicious or non-cooperating. If any x′
i = ⊥ or if the
server sends an abort message, the trusted party returns ⊥
i to the trusted party, where x′
to all parties.
If the server Pn+1 is covert, it can send a
cheat instruction to the trusted party. Upon receiving this
instruction, the trusted party tosses some coins and with
probability 1 − ǫ discloses the server’s cheating (and the
other parties output ⊥) and with probability ǫ does not.
In the latter case, the trusted party sends (x′
n) to
the server, receives (y1, . . . , yn) in response, and returns yi
to Pi.
If the server did not send cheat, the trusted party
returns fi(x′
n) to party Pi.
1, . . . , x′
1, . . . , x′
For all honest parties Pi, let outi denote the output re-
turned to Pi by the trusted party, and for all corrupted par-
ties let outi be some value output by Pi. The ith partial
output of an ideal-model execution between parties (P1, . . . ,
Pn+1) in the presence of independent simulators S = (S1, . . . ,
Sm+1) is deﬁned as
ideal(i)(k, x; r)
def
= (cid:8)outj : j ∈ H(cid:9) ∪ outi.
where H denotes the set of honest parties and r = (r1, . . . ,
rn+1).
We now present our formal deﬁnition of security which,
intuitively, guarantees that executing a protocol Π in the
real model is equivalent to executing Π in an ideal model
with a trusted party.
Definition 2.2
(Security). A n-party protocol Π se-
curely computes f if there exists a set {Simi}i∈[m+1] of
polynomial-size transformations such that for all polynomial-
size adversaries A = (A1, . . . , Am+1), for all x and z, and