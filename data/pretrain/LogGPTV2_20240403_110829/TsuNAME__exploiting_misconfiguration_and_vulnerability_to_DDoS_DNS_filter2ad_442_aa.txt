title:TsuNAME: exploiting misconfiguration and vulnerability to DDoS DNS
author:Giovane C. M. Moura and
Sebastian Castro and
John S. Heidemann and
Wes Hardaker
TsuNAME: exploiting misconfiguration and
vulnerability to DDoS DNS
Giovane C. M. Moura (1)
Sebastian Castro (2)
John Heidemann (3) Wes Hardaker (3)
1: SIDN Labs
2: InternetNZ
3: USC/ISI
ABSTRACT
TheInternet’s Domain Name System (DNS) is a part of every web re-
quest and e-mail exchange, so DNS failures can be catastrophic, tak-
ing out major websites and services. This paper identifies TsuNAME,
a vulnerability where some recursive resolvers can greatly amplify
queries, potentially resulting in a denial-of-service to DNS services.
TsuNAME is caused by cyclical dependencies in DNS records. A
recursive resolver repeatedly follows these cycles, coupled with
insufficient caching and application-level retries greatly amplify
an initial query, stressing authoritative servers. Although issues
with cyclic dependencies are not new, the scale of amplification has
not previously been understood. We document real-world events
in .nz (a country-level domain), where two misconfigured domains
resulted in a 50% increase on overall traffic. We reproduce and
document root causes of this event through experiments, and de-
mostrate a 500× amplification factor. In response to our disclosure,
several DNS software vendors have documented their mitigations,
including Google public DNS and Cisco OpenDNS. For operators
of authoritative DNS services we have developed and released
CycleHunter, an open-source tool that detects cyclic dependencies
and prevents attacks. We use CycleHunter to evaluate roughly 184
million domain names in 7 large, top-level domains (TLDs), finding
44 cyclic dependent NS records used by 1.4k domain names. The
TsuNAME vulnerability is weaponizable, since an adversary can
easily create cycles to attack the infrastructure of a parent domains.
Documenting this threat and its solutions is an important step to
ensuring it is fully addressed.
ACM Reference Format:
Giovane C. M. Moura, Sebastian Castro, John Heidemann. 2021. TsuNAME:
exploiting misconfiguration and vulnerability to DDoS DNS . In ACM Inter-
net Measurement Conference (IMC ’21), November 2ś4, 2021, Virtual Event,
USA. ACM, New York, NY, USA, 21 pages. https://doi.org/10.1145/3487552.
3487824
1 INTRODUCTION
The Internet’s Domain Name System (DNS) [27] provides one of the
core services of the Internet, by mapping hosts names, applications,
and services to IP addresses and other information. Every web
page visit requires a series of DNS queries, and large failures of the
DNS have severe consequences that make even large websites and
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
IMC ’21, November 2ś4, 2021, Virtual Event, USA
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-9129-0/21/11. . . $15.00
https://doi.org/10.1145/3487552.3487824
other Internet infrastructure fail. For example, the Oct. 2016 denial-
of-service (DoS) attack against Dyn [5] made many prominent
websites such as Twitter, Spotify, and Netflix unreachable to many
of their customers [40]. Another DoS against Amazon’s DNS service
affected large number of services [61] in Oct. 2019.
The DNS can be seen as a hierarchical and distributed database,
where DNS records [28] are stored in and distributed from authorita-
tive servers [18] (for instance, the Root DNS servers [51] distribute
records from the Root DNS zone [52]). As such, all information
about an end domain name in the DNS are served by authoritative
servers for that domain. This information is typically retrieved by
recursive resolvers [18], which answer questions originally posed
by users and their applications. Resolvers are typically operated
by a user’s ISP, or alternatively public DNS resolvers operated by
Google [15], Cloudflare [1], Quad9 [43], Cisco OpenDNS [38], and
others.
The configuration of authoritative servers and their records is
prone to several types of errors [2, 25, 27, 39, 55]. Here we are
concerned about loops where records required for resolution point
at each other. Cyclic dependencies occur when resolving a name
requires resolution of another name, that in turn refers back to
the first [39]. Loops can involve CNAMEs (ğ 3.6.2, [27]) or NS
records (ğ 2, [25]). For example, if the NS record for example.org
points to example.com and vice versa, then an attempt to resolve
any name within either domain will fail because the IP address for
both servers cannot be confirmed.
The first contribution of this paper is to report that, in the wild,
cyclic dependencies can result in a query cascade that greatly in-
creases traffic to authoritative servers. We call this amplification
TsuNAME (inspired by the destructive potential of a tsunami) and
describe the several factors that contribute to it in ğ2. TsuNAME am-
plifcation has happened multiple times in the real world. ğ3 shows
an event on 2020-02-01 at .nz, where a configuration error (not an
intentional attack) in two domains each having cyclic nameservers
(NS records). While normally these domains result in only a few
queries to .nz’s authoritative DNS servers, the misconfiguration
resulted in 50% increase in aggregate traffic volume (from 800M to
1.2B daily queries, the shaded area in Figure 1). While these servers
handled this increase in load, this large amplification shows the risk
a malicious attack could pose. Others have seen greater increases:
ğ6 shows a European ccTLD that experienced a 10× increase in
traffic due to TsuNAME.
These accidental events raise the question of what a motivated
attacker could do to exploit this problem. An intentional attack
could leverage multiple cycles to amplify moderate client traffic to
overwhelm authoritative servers. In addition, since DNS providers
often host multiple domains on shared infrastructure, other services
could suffer collateral DoS damage(we discuss this threat model in
Appendix F). This threat poses a great concern for any domains
and registrations points, such as TLDs and ccTLDs, who often
398
IMC ’21, November 2–4, 2021, Virtual Event, USA
G. C. M. Moura et al.
The potential of DNS cycles was documented in the initial speci-
fication in 1987 [27] and was called out as an implementation risk
in 1993 [25]. Nevertheless, cyclic dependencies were noted as a
continuing risk in 2004 [39], and they cause huge traffic volumes
even in 2020 (ğ3). The contribution of our paper is not to document
cyclic dependencies as a new problem, but to show that their im-
pact can be huge even today, and that impact can be amplified by
modern recursive resolver architectures.
DNS cycles cause a problem when an end-user’s query results in
excessive traffic to authoritative DNS servers. However, the amount
of traffic depends on the interaction of a number of components of
the DNS system:
(1) The injection rate of client queries to the cycle.
(2) Stub resolvers query retries and parallel queries [62].
(3) The number of independent caches in recursive resolver
services [44, 53].
(4) If recursive resolvers cache negative replies.
(5) If recursive resolvers send additional requests for an unre-
solved pending request.
(6) Recursive resolver limits on the number of queries made
when responding to an incoming request.
We careful example components (3) to (6) in this paper, since as
infrastructure, they are easier to mitigate.
The Threat: The risk of TsuNAME is that it is łweaponizablež.
The authoritative servers of any zone with third-party registration
are at risk. An adversary can register two or more domains, later
reconfigure them to create a cyclic dependency, then inject client
traffic from a botnet. TsuNAME causes recursive resolvers amplify
injected traffic; in some prior events by more than 500×. Regis-
trating domains without cycles is easy, cheap, and benign. The
adversary can then activate the attack by reconfiguring to create a
cycle and triggering traffic from a botnetÐnone of these steps are
visible to the authoritative operator until the attack takes effect.
Although we (ğ3) and others (ğ6) encountered the problem by
accident, we want to prevent its intentional use. We expand on this
threat in Appendix F.
Recommendation: Our recommendation is the same as 1987 [27]
(and repeated in 1993 [25]): resolver implementations must łbound
the amount of work. . . so a request can’t get into an infinite loop or
start a chain reaction. . . even if someone has incorrectly configured
some dataž.
We add one prescription and one recommendation to this guide-
line: all recursive resolvers must implement negative caching, so they
do not repeatedly retry a cyclic question. Negative caching means
recording (and replying) replies that are errors, replying imme-
diately to a query from a new client rather than repeating the
amplification. This design choice would have mitigated the prob-
lems that we report on below, and has been deployed by Google
Public DNS (ğ4.5 and other vendors ğ5.3).
We also recommend that operators of parallel resolution systems
to share caches between resolvers, and we strongly encourage
recursive resolvers to avoid making duplicate requests for the same
content when one request is still being resolved. (Authoritative
servers typically already łcachež results in memory; additional
caching does not reduce their network traffic.)
Figure 1: Daily queries to .nz for all domains (top) and the
cyclic dependent domains (bottom two lines).
host domains that provide essential services to their users, such as
government websites, banking, and online shopping.
Our second contribution is to demonstrate this threat in con-
trolled conditions in ğ4. We emulate a TsuNAME event by setting
up multiple cyclic dependent domain names under our control on
our servers (so as to not harm others) and measure the consequence,
reaching an amplification factor of more than 500×. Google operates
Google Public DNS (GDNS), a large, popular public resolver ser-
vice [15] and makes up 8% of all queries sent to .nz [30]. We show
that GDNS was responsible for the bulk of queries, but we also found
other vulnerable resolvers in 260 Autonomous Systems (ASes). Fol-
lowing responsible disclosure practices, we notified Google, Cisco
OpenDNS, and other TLD and resolver operators (ğ6.) We worked
with Google about GDNS (ğ4.5) and Cisco about OpenDNS, both of
which have since been fixed.
Our third contribution is to develop CycleHunter, a tool that
finds cyclic dependencies in DNS zone files (ğ5). This tool allows
authoritative server operators (such as ccTLD operators) to identify
and mitigate cyclic dependencies, preemptively protecting their
authoritative servers from possible TsuNAME attacks. We use
CycleHunter to evaluate the Root DNS zone and 7 other TLDs
(∼185M domain names altogether), and found cyclic dependent do-
mains in half of these zones. We made CycleHunter publicly avail-
able on GitHub and we thank the various contributors that have
helped improve the tool. We have carefully disclosed our findings
with the relevant DNS communitiesand include their contributions
and feedback (ğ6) and discuss ethics around our disclosure and data
release policies in ğ7.
2 THE TSUNAME PROBLEM
The Cause: The fundamental problem in TsuNAME is a cyclic de-
pendency that amplifies a traffic sent to authoritative servers. When
two zones have name server (NS) records that point at each other,
a recursive resolver trying to resolve a name in that zone will loop
between the two, trying to break the cycle. These queries mean a sin-
gle query from a client to result in recursive resolvers placing many
queries against the authoritative servers, perhaps overwhelming
authoritative server capacity. Amplification in TsuNAME amplifi-
cation is this end-to-end effect, with several contributing factors
described belowÐa more complex process than traditional DNS
amplification where a short query directly creates a large reply [23].
399
 0 200 400 600 800 1000 12002020-01-302020-02-062020-02-132020-02-202020-02-27all domainscyclic domains A and B[--- Cyclic Dependency Event ---]Daily Queries (million)Day (2020)TsuNAME
IMC ’21, November 2–4, 2021, Virtual Event, USA
We encourage zone operators to scan for cycles using our tool
to detect accidental cycles (ğ5).
While cycles were recognized as a problem more than 30 years
ago, the problem is pressing today because evolution of the system
has amplified query rates: the łhappy eyeballsž algorithm doubles
queries [62] and large public resolvers often use parallelism across
many machines without shared caches [44]. Recommendations
from 1987 and 1993 emphasize the role of the single recursive re-
solver without considering the interactions in today’s DNS ecosys-
tem.
3 TSUNAME’S IMPACT IN .NZ
On 2020-02-01, two domains in .nz (DomainA and DomainB) had their
NS records misconfigured to be cyclically dependent. DomainA’s NS
records were set to ns[1,2].DomainB.nz, while DomainB’s NS records
pointed to ns[1,2].DomainA.nz. This misconfiguration increased the
query volume to .nz’s authoritative servers by 50%. Figure 1 shows
this problem, as measured at the authoritative servers of .nz. The
.nz operators manually fixed this misconfiguration more than two
weeks later on 2020-02-17, returning query volumes to normal.
We describe this problem here, reproduce it in ğ4, and discuss
detection in ğ5. While this traffic increase was large, .nz servers are
overprovisioned and handle other bursts (such as those on 2020-02-
20 and -23 in Figure 1), but a malicious attack could create much
greater traffic volumes using more domains and more initial traffic.
3.1 Query sources
During the sixteen-day period of this TsuNAME event (2020-02-[01ś
17]), there were 4.07B combined queries for DomainA and DomainB,
with a daily average of 269M. Figure 2a and Table 11 show the
top 10 ASes by query volume during the event period. The over-
whelming majority (99.99%) of all traffic originated from Google
(AS15169), with only 324k queries originating from 579 other ASes.
Queries from Google outnumbered the other sources by 4 orders of
magnitude.
For comparison, Figure 2b shows the top 10 ASes for both do-
mains during the łnormalž periods when there was no cyclic depen-
dency, spanning over the 16 days before and after the TsuNAME
period (2020-01-[24ś30] and 2020-02-[18ś28]). During this łnor-
malž period, Google sent no more than 100k daily queries for
both DomainA and DomainB. During the TsuNAME period, however,
Google’s query volume multiplied 5453× (Figure 2c). No other AS
had an traffic growth greater than 100× in the same period.
3.2 Scrutinizing Google queries
To understand Why was Google responsible for so many queries? we
turn to: How long and how many times should resolvers retry when
resolving domains with cyclic dependencies? And how aggressive
should they be when finding answers?
Previous research has shown resolvers will hammer unrespon-
sive authoritative servers [34], generating up to 8× typical query
rates, depending on the DNS records’ time-to-live (TTL) value. But
in the case of cyclic dependencies, authoritative servers are respon-
sive and resolvers bounce from one authoritative server to another,
asking the same sequence of questions repeatedly. This difference
allows recursive resolvers to generate even more traffic than with
unresponsive servers.
(a) TsuNAME period
(b) Normal period
(c) Growth rate
Figure 2: Top 10 ASes querying for Domains A and B, for .nz.
TsuNAME period: Feb. 1ś17, normal period: Jan. 24ś30, Feb.
18ś28, 2020.
Given that Google was responsible for virtually all queries during
the .nz TsuNAME event for the cyclic dependent domains (ğ3.1),
we isolate and study the queries from Google. Table 1 shows the
breakdown of the query names and types from Google during the
.nz event. We see that most queries to .nz are for A and AAAA
records for each of the two domain’s own NS records (NS records
store the authoritative server names of a domain, while A [27] and
AAAA records [57] store each server’s IPv4 and IPv6 addresses,
respectively.) With a cyclic dependency, these queries can never
be resolved, since each authoritative server refers resolvers to the
other. The NS records for the zones, however, were readily available
within the parent .nz zone ś which explains the lower volume of
queries compared to the A/AAAA requires.
3.2.1
Interquery interval. How frequently did GDNS resolvers
send .nz queries for these domains during the TsuNAME event?
We estimate this query rate by measuring the inter-query interval
for queries with the same query name and type from GDNS to the
.nz authoritative servers on one day (2020-02-06).
Figure 3 shows the results (for space constraints, we show only
results for the queries highlighted in the green rows of Table 1). We
400
 1 1000 1x106 1x109151692396910013366923928935613462165091123345142Total Queries (log) AS number 1 1000 1x106 1x109151692396910013366923928935613462165091123345142 1 1000 1x106 1x10915169165099500387934816477117623639494217621Total Queries (log) AS number 1 1000 1x106 1x10915169165099500387934816477117623639494217621 1 10 100 1000 1000015169306077018366921627612212494062088236506939Growth Rate AS number 1 10 100 1000 1000015169306077018366921627612212494062088236506939IMC ’21, November 2–4, 2021, Virtual Event, USA
G. C. M. Moura et al.
ns1.DomainA.nz
DomainB.nz
DomainA.nz
NS
NS
A
Query Name Query Type Queries(v4) Queries(v6)
10.9M
3.0M
281.3M
281.4M
281.2M
281.4M
237.9M
237.7M
237.7M
237.5M
13.0M
4.3M
266.1M
266.2M
266.1M
266.1M
222.6M
222.5M
222.5M
222.3M
A
A
A
AAAA
AAAA
AAAA
AAAA
ns2.DomainA.nz
ns1.DomainB.nz
ns2.DomainB.nz
Table 1: Google queries during the .nz event