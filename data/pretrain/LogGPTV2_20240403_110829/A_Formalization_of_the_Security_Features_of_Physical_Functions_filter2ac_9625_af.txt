entropy is a notion from information theory measuring the
uncertainty any adversary has about a particular value5. This
means that min-entropy provides a strict lower bound for
the unpredictability against any adversary. It must be noted
that, in general, estimating the min-entropy of a physical
function response is very difﬁcult and relies on statistical
tests that offer only limited assurance. For SRAM PUFs,
min-entropy was nonetheless estimable due to their simple
structure. Moreover, it was shown that their relative min-
entropy content is relatively high (up to 95%). This can be
explained by two reasons:
1) The bias of the bits of the response of a typical SRAM
PUF is very low, i.e., on average the number of ones
and zeros in an SRAM PUF response is almost equal.
2) Since every single SRAM PUF response bit is gener-
ated by a spatially separate piece of physical material
(i.e., an individual silicon SRAM cell),
is very
reasonable to assume that the produced bits are to a
it
5Formally, the min-entropy of a distribution D over a set X is deﬁned
as H∞(D) = − log2 max{Pr[x ← D : x ∈ X ]}.
410
It is clear that both effects greatly increase the unpredictabil-
ity of SRAM PUF responses.
Following this, we assume the SRAM PUF discussed in
the previous example sections to have a min-entropy of 80%,
which is a very safe estimation given the experimental ob-
servations discussed in the previous paragraph. This means
that every 255-bit response of the SRAM PUF contains on
average 204 bits of min-entropy, i.e., any adversary can
guess the correct SRAM PUF response with a probability
of at most 2−204, which is negligible. However, we must
assess the unpredictability of the PF system output. For that
we need to take the extractor algorithm and the helper data
into account. The fuzzy extractor construction, as described
in Section IV-C and shown in Figure 2, outputs besides the
SRAM PUF response z = y also some helper data h, which
is the offset between y and a random codeword c from the
BCH[255, 13, 59] error correcting code. Since there are only
213 possible codewords c and since the helper data h is
stored or transferred publicly, the adversary knows that the
255-bit output of the PF system has the form z = c ⊕ h,
which can only take one of 213 possible values. Hence,
the effective uncertainty of the adversary about z is at
most 13 bits, and due to the 80% relative min-entropy, we
estimate it to be 10.4 bits per 255-bit response. This is
a signiﬁcant reduction, which illustrates the cost we have
to pay for achieving high robustness. Indeed, the extent of
this min-entropy loss is directly related to the required error
correction capability of the underlying error correction code.
On the other hand, the remaining min-entropy provides a
strong lower bound for the predictability. More in detail,
no matter how strong the adversary is, its best guess of z
will be correct only with a probability of at most 2−10.4.
Hence, the example PF system based on an SRAM PUF
and a fuzzy extractor is (2−10.4, 28 − 1)-unpredictable for
PL = PC = {PFS}, both in the weak and the strong sense.
This means that, even if all but one of the PF system outputs
is learned, an adversary cannot predict the last output with a
probability greater than 2−10.4. Since the assumptions made
above can be generalized to many SRAM PUFs, equivalent
unpredictability bounds hold for PL = PC = P.
If the PF system is used to generate a secret key, it
must be evaluated on different challenges multiple times to
collect enough min-entropy. For instance, to generate a 128-
bit key using the PF system in our example, it is required
to obtain at
least 13 challenge-response-pairs leading to
13 · 255 = 3315 response bits containing 13 · 10.4 = 135.2
bits of min-entropy. In order to obtain the 128-bit key from
the PF responses, these 3315 bits have to be compressed by
an appropriate strong extractor. This can be done using a
universal hash function [40]. Typically, the strong extractor
is integrated into the PF system as part of the Extract
algorithm to ensure that the PF system generates full entropy
outputs. This process is called privacy ampliﬁcation and is
typically part of a fuzzy extractor construction [34].
In general, it is more difﬁcult to obtain strong quantitative
unpredictability bounds for other PUF types since there are
no known methods to estimate the min-entropy content of
their responses. Moreover, statistical dependencies between
responses on different challenges and of different PUF
instantiations need to be taken into account but can be
difﬁcult to detect. Note that min-entropy provides a very
strict information-theoretical lower-bound on unpredictabil-
ity, even against computationally unlimited adversaries.
However, typically the computational power of the adversary
is limited in practice. This means that even PUFs with
a low min-entropy content can still produce unpredictable
responses if their simulation is computationally complex.
Alternatively, the unpredictability of a particular type of PUF
can be assessed w.r.t. the effort of the best known modeling
attack, as is done for symmetric cryptographic primitives
(see Section V-C).
VII. CONCLUSION
Physically Unclonable Functions (PUFs) have been pro-
posed in literature to exploit physical characteristics for
security purposes. Various practical instantiations of PUFs
exist, ranging from real-life products to theoretical PUF-
based primitives and protocols (e.g., for identiﬁcation and
authentication). In view of the very different physical fea-
tures they are based on, PUFs have mainly been developed in
independent models and under different assumptions that are
specialized for the corresponding applications. This absence
of a unifying view typically makes the integration of PUFs
in secure information systems a difﬁcult task, hence limiting
their further development and deployment. In this paper, we
consequently formalized the security features of physical
functions, in accordance to the existing literature on PUFs.
More precisely, we proposed a new general security model
for physical functions, that modularly captures the most
important properties required for the integration of PUFs
into cryptographic primitives and security applications. Our
current model focuses on the minimum requirements on
PUFs and can be easily extended by deﬁning additional
security-relevant properties required by future use cases.
In fact,
the extension of the model
to other security
properties is one of the important remaining challenges,
e.g., for covering tamper-evidence, meaning the property that
unauthorized manipulations of PUFs are detectable. Another
challenge is to develop new cryptographic mechanisms
based on PUFs where the security can be reduced to the
(alleged) properties of the deployed PUFs. Moreover, our
present examples are mainly based on SRAM PUFs. Hence,
a scope for further research would be to analyze other PUF
types w.r.t. the properties formalized in our model.
ACKNOWLEDGEMENTS
We thank Pim Tuyls for several useful discussions and the
anonymous reviewers for their helpful comments. This work
has been supported in part by the European Commission
under grant agreement ICT-2007-238811 UNIQUE and ICT-
2007-216676 ECRYPT NoE phase II, and in part by the IAP
Programme P6/26 BCRYPT of the Belgian State. François-
Xavier Standaert is an associate researcher of the Belgian
Fund for Scientiﬁc Research (FNRS-F.R.S.). Roel Maes is
funded by a specialisation grant (nr. 073369) of the Flemish
Agency for Innovation by Science and Technology (IWT).
REFERENCES
[1] R. S. Pappu, “Physical one-way functions,” Ph.D. dissertation,
Massachusetts Institute of Technology, March 2001.
[2] R. S. Pappu, B. Recht, J. Taylor, and N. Gershenfeld, “Phys-
ical one-way functions,” Science, vol. 297, pp. 2026–2030,
2002.
[3] D. Bauder, “An anti-counterfeiting concept for currency sys-
tems.” Sandia National Labs, Albuquerque, NM, Tech. Rep.
PTK-11990, 1983.
[4] K. Tolk, “Reﬂective particle technology for identiﬁcation of
critical components.” Sandia National Labs, Albuquerque,
NM, Tech. Rep. SAND-92-1676C, 1992.
[5] Commission on Engineering and Technical Systems (CETS),
Counterfeit Deterrent Features for the Next-Generation Cur-
rency Design. The National Academic Press, 1993.
[6] K. Lofstrom, W. R. Daasch, and D. Taylor, “IC identiﬁcation
circuit using device mismatch,” in IEEE International Solid-
State Circuits Conference (ISSCC), 2000, pp. 372–373.
[7] B. Škori´c, P. Tuyls, and W. Ophey, “Robust key extraction
from physical uncloneable functions,” in Applied Cryptog-
raphy and Network Security (ACNS), ser. LNCS, vol. 3531,
2005, pp. 407–422.
[8] D. Lim, J. W. Lee, B. Gassend, G. E. Suh, M. van Dijk, and
S. Devadas, “Extracting secret keys from integrated circuits,”
IEEE Transactions on VLSI Systems, vol. 13, no. 10, pp.
1200–1205, 2005.
[9] F. Armknecht, R. Maes, A.-R. Sadeghi, B. Sunar, and
P. Tuyls, “Memory leakage-resilient encryption based on
physically unclonable functions,” in Advances in Cryptology
(ASIACRYPT), ser. LNCS, vol. 5912, 2009, pp. 685–702.
[10] Verayo, Inc., “Verayo product page,” http://www.verayo.com/
product/products.html, November 2010.
[11] Intrinsic ID, “Intrinsic ID product page,” http://www.
intrinsic-id.com/products/, November 2010.
[12] K. Kursawe, A.-R. Sadeghi, D. Schellekens, B. Skoric, and
P. Tuyls, “Reconﬁgurable physical unclonable functions —
Enabling technology for tamper-resistant storage,” in IEEE
Workshop on Hardware-Oriented Security and Trust (HOST),
2009, pp. 22–29.
411
[13] R. Maes and I. Verbauwhede, “Physically unclonable func-
tions: A study on the state of the art and future research
directions,” in Towards Hardware-Intrinsic Security, ser. In-
formation Security and Cryptography, D. Basin, U. Maurer,
A.-R. Sadeghi, and D. Naccache, Eds.
Springer Berlin
Heidelberg, 2010, pp. 3–37.
[14] P. Tuyls, B. Skoric, S. Stallinga, T. Akkermans, and W. Ophey,
“An information theoretic model for physical uncloneable
functions,” in IEEE Symposium on Information Theory (ISIT),
2004.
[15] P. Tuyls, G.-J. Schrijen, B. Škori´c, J. van Geloven, N. Ver-
haegh, and R. Wolters, “Read-proof hardware from protective
coatings,” in Workshop on Cryptographic Hardware and
Embedded Systems (CHES), ser. LNCS, vol. 4249, 2006, pp.
369–383.
[16] B. Gassend, D. Clarke, M. van Dijk, and S. Devadas, “Silicon
physical random functions,” in ACM Conference on Computer
and Communications Security (CCS), 2002, pp. 148–160.
[17] G. E. Suh and S. Devadas, “Physical unclonable functions for
device authentication and secret key generation,” in Design
Automation Conference, 2007, pp. 9–14.
[18] C.-E. D. Yin and G. Qu, “LISA: Maximizing RO PUF’s
secret extraction,” in IEEE Symposium on Hardware-Oriented
Security and Trust (HOST), 2010, pp. 100–105.
[19] A. Maiti, J. Casarona, L. McHale, and P. Schaumont, “A large
scale characterization of RO-PUF,” in IEEE Symposium on
Hardware-Oriented Security and Trust (HOST), 2010, pp. 94–
99.
[20] J. W. Lee, D. Lim, B. Gassend, G. E. Suh, M. van Dijk, and
S. Devadas, “A technique to build a secret key in integrated
circuits for identiﬁcation and authentication application,” in
Symposium on VLSI Circuits, 2004, pp. 176–159.
[21] E. Ozturk, G. Hammouri, and B. Sunar, “Physical unclonable
function with tristate buffers,” in IEEE Symposium on Circuits
and Systems (ISCAS), 2008, pp. 3194–3197.
[22] L. Lin, D. Holcomb, D. K. Krishnappa, P. Shabadi, and
W. Burleson, “Low-power sub-threshold design of secure
physical unclonable functions,” in ACM/IEEE international
symposium on Low power electronics and design (ISLPED),
2010, pp. 43–48.
[23] M. Majzoobi, F. Koushanfar, and M. Potkonjak, “Techniques
for design and implementation of secure reconﬁgurable
PUFs,” ACM Transactions on Reconﬁgurable Technology and
Systems, vol. 2, no. 1, pp. 1–33, 2009.
[24] U. Rührmair, F. Sehnke, J. Sölter, G. Dror, S. Devadas, and
J. Schmidhuber, “Modeling attacks on physical unclonable
functions,” in ACM conference on Computer and communi-
cations security (CCS), 2010, pp. 237–249.
[25] J. Guajardo, S. S. Kumar, G. J. Schrijen, and P. Tuyls, “FPGA
intrinsic PUFs and their use for IP protection,” in Workshop
on Cryptographic Hardware and Embedded Systems (CHES),
ser. LNCS, vol. 4727, 2007, pp. 63–80.
[26] D. E. Holcomb, W. P. Burleson, and K. Fu, “Initial SRAM
state as a ﬁngerprint and source of true random numbers
for RFID tags,” in Conference on RFID Security (RFIDSec),
2007.
[27] R. Maes, P. Tuyls, and I. Verbauwhede, “Intrinsic PUFs
from ﬂip-ﬂops on reconﬁgurable devices,” in Workshop on
Information and System Security (WISSec), 2008, p. 17.
[28] V. van der Leest, G.-J. Schrijen, H. Handschuh, and P. Tuyls,
“Hardware intrinsic security from D ﬂip-ﬂops,” in ACM
Workshop on Scalable Trusted Computing (STC), 2010, pp.
53–62.
[29] Y. Su, J. Holleman, and B. Otis, “A 1.6pJ/bit 96% stable
chip-ID generating circuit using process variations,” in IEEE
International Solid-State Circuits Conference (ISSCC), 2007,
pp. 406–611.
[30] S. Kumar, J. Guajardo, R. Maes, G.-J. Schrijen, and P. Tuyls,
“Extended abstract: The butterﬂy PUF protecting IP on every
FPGA,” in IEEE Workshop on Hardware-Oriented Security
and Trust (HOST), 2008, pp. 67–70.
[31] J. D. R. Buchanan, R. P. Cowburn, A.-V. Jausovec, D. Petit,
P. Seem, G. Xiong, D. Atkinson, K. Fenton, D. A. Allwood,
and M. T. Bryan, “Forgery: ‘ﬁngerprinting’ documents and
packaging,” Nature, vol. 436, no. 7050, p. 475, 2005.
[32] P. Bulens, F.-X. Standaert, and J.-J. Quisquater, “How to
the paper case,” IET
strongly link data and its medium:
Information Security, vol. 4, no. 3, pp. 125–136, 2010.
[33] U. Rührmair, J. Sölter, and F. Sehnke, “On the foundations
of physical unclonable functions,” Cryptology ePrint Archive,
Report 2009/277, 2009.
[34] Y. Dodis, L. Reyzin, and A. Smith, “Fuzzy extractors: How to
generate strong keys from biometrics and other noisy data,”
in Advances in Cryptology (EUROCRYPT, ser. LNCS, vol.
3027, 2004, pp. 523–540.
[35] P. Tuyls, B. Skoric, and T. Kevenaar, Eds., Security with Noisy
Data — On Private Biometrics, Secure Key Storage, and Anti-
Counterfeiting. Springer-Verlag, 2007.
[36] P. Tuyls and L. Batina, “RFID-tags for anti-counterfeiting,” in
The Cryptographers’ Track at the RSA Conference (CT-RSA),
ser. LNCS, vol. 3860. Springer Verlag, 2006, pp. 115–131.
[37] B. Gassend, D. Lim, D. Clarke, M. van Dijk, and S. Devadas,
“Identiﬁcation and authentication of integrated circuits,” Con-
currency and Computation: Practice and Experience, vol. 16,
no. 11, pp. 1077–1098, 2004.
[38] K. Pietrzak, “A leakage-resilient mode of operation,” in
Advances in Cryptology (EUROCRYPT), ser. LNCS, A. Joux,
Ed., vol. 5479. Springer, 2009, pp. 462–482.
[39] F. Willems, Y. Shtarkov, and T. Tjalkens, “The context-tree
weighting method: basic properties,” IEEE Transactions on
Information Theory, vol. 41, no. 3, pp. 653–664, 1995.
[40] J. L. Carter and M. N. Wegman, “Universal classes of hash
functions,” in ACM Symposium on Theory of Computing
(STOC), 1977, pp. 106–112.
412