the entire year) in Fig. 1c. We ﬁnd that relays with lower mean advertised band-
widths were associated with higher variation, with the one-third of the relays
advertising less than 3.71 Mbit/s accounting for the highest variance. The same
absolute change in throughput (such as that caused by a single client) could
result in a larger relative change in advertised bandwidth (and thus the RSD)
for slower relays than for faster relays, which could help explain this result.
Selection Probability. We compare weekly RSDs across relays with diﬀerent
ranges of selection probabilities (the mean normalized weight from all consen-
suses in which it appeared throughout the year) in Fig. 1d. Relays with the lowest
one-third of selection probability were correlated with higher mean weekly RSDs,
while relays with the highest one-third of selection probability were correlated
with lower variation. Since selection probability is directly associated with the
amount of traﬃc a relay will observe, it follows that relays that are chosen most
consistently report advertised bandwidths with the least variation.
Overall, we ﬁnd signiﬁcant variation in relays’ advertised bandwidth, and
that lower capacity and lower uptime relays are correlated with higher variation.
However, we are unable to deduce the true causes of the observed associations
because correlation does not imply causation. Next we conduct an active mea-
surement experiment to help us further understand error in capacity estimates.
4 Tor Relay Speed Test Experiment
Our analysis of variation in advertised bandwidths suggests that there is signif-
icant error in Tor’s system for determining relay capacities. However, without
more information, it seems diﬃcult to tell why and to what extent these errors
are made. Based on our understanding of the TorFlow system, though, we can
hypothesize that the predominant error is to underestimate the true capacity
of Tor relays. This hypothesis seems plausible because the observed bandwidth
is a self-measurement that mostly is limited by how much client traﬃc is sent
through a relay, and it has been observed that there is a slow feedback process
in which some client traﬃc is attracted, the observed bandwidth increases and
causes the relay weight to increase, and then more client traﬃc is attracted [8].
On the Accuracy of Tor Bandwidth Estimation
487
To test this hypothesis, we perform a speed test on the live Tor network
by actively attempting to send 1 Gbit/s of Tor traﬃc through each relay. If a
relay is not already receiving suﬃcient client traﬃc to reach its true capacity
(at least for 10 ss every 5 days), the extra traﬃc we add should increase its
observed bandwidth, as reported in its server descriptors. The resulting observed
bandwidths should increase our overall estimate of Tor’s capacity and give us a
more accurate estimate of how much total client traﬃc it could forward.
Moreover, as suggested by our capacity variation analysis, we may be able to
identify diﬀerences in the amount of underestimation depending on the relays’
positional ﬂags (e.g. Guard and Exit), advertised bandwidth, and uptime. For
example, our previous results may lead us to hypothesize that relays with lower
uptime will have a larger increase in observed bandwidth due to the speed test
(i.e., their current observed bandwidths are larger underestimates of their for-
warding capacity). Such non-uniform errors would imply that Tor’s load balanc-
ing is suboptimal, where relays with higher degrees of capacity underestimation
receive too little traﬃc and relays with lower degrees receive too much.
Setup: We added 487 lines of code to Tor v0.3.5.7 in support of our speed test
experiment. Our changes include the addition of a new SPEEDTEST cell; when a
SPEEDTEST cell that was sent by a client running our version of Tor is received
by a relay running our version of Tor, the relay will simply return the cell back
to the client over the same circuit. When creating a circuit that starts and ends
with a client and relay running our version of Tor, the SPEEDTEST cell allows us
to send a burst of traﬃc in both directions through the circuit. We also added
Tor client controller commands to enable us to instruct a client (through the
control port) to build speed test measurement circuits through a path of relays,
to start and stop sending SPEEDTEST cells through a measurement circuit, and
to extract information about each measurement result.
We conduct our speed test experiment from a single dedicated machine with
32 GiB of RAM, 8 CPU cores, and a 1 Gbit/s symmetric network link. We set up
10 Tor clients (C1, . . . , C10) and 10 Tor relays (R1, . . . , R10) on this machine that
each run our enhanced version of Tor. We connect our relays to the Tor network
so they function as regular Tor relays; we set the MaxAdvertisedBandwidth Tor
option to the minimum allowed value (300 Kbits/s) to ensure that our relays do
not receive a large weight and are seldom used by Tor clients that we do not
control. The speed test experiment proceeds sequentially as follows:
1. We download the latest list of relays from a Tor directory mirror;
2. We randomly choose an untested target relay T from the list;
3. For i ∈ [1, 10], we command Ci to build a circuit Ci (cid:2) T (cid:2) Ri;
4. For i ∈ [1, 10], we command Ci to send SPEEDTEST cells to Ri through the
circuit with T for 20 s as fast as Tor (and TCP) will allow;
5. Upon receiving the SPEEDTEST cells from T , Ri sends them back to T ;
6. T simply forwards the cells in each direction as it would on any other circuit;
7. When the 20 s measurement is complete, we close the measurement circuits,
mark T as tested, and continue from 1.
488
R. Jansen and A. Johnson
Fig. 2. The eﬀects of the speed test on Tor relays (≈200 Gbit/s of capacity discovered).
By using 10 circuits in parallel (20 sockets in parallel on T ), we increase the
traﬃc rate through T while mitigating any potential rate limits imposed by Tor’s
stream and circuit ﬂow control or by TCP congestion control. Our measurement
has the potential to send a burst of traﬃc at an aggregate rate of 1 Gbit/s
through each target T . The measurement eﬀect will be reﬂected in the following
server descriptor that T publishes, in which it will report its observed bandwidth
(the highest throughput that it was able to sustain for any 10 s period).
Our experiment is designed to minimize Tor network relay overhead. We
add load to only one remote target relay at a time and only for a short period.
We submitted our experimental design and plans to the Tor Research Safety
Board [1] for feedback. We received encouraging feedback and a “no objections”
decision. We also explained our plans to the Tor community through a post to
the public tor-relays mailing list [16]. We gave instructions on how to opt out and
allowed one week to collect feedback. Finally, we served a web page containing
a link to the mailing list post on the IP addresses used in the experiment.
Results: Our speed test experiment ran for just over 2 days (51 h) starting on
2019-08-06. We plot in Fig. 2a the sum of the most-recently published adver-
tised bandwidths of all online relays over time. The ﬁrst green region shows
the period during which the speed test was active, and the second gray region
shows the period during which the eﬀects of the speed test expired. Note that
the delay in the increase and decrease in advertised bandwidth relative to our
experiment is caused by: (i) the 18 h server descriptor publishing interval; and
(ii) the observed bandwidth algorithm which stores history for each of the last 5
days. We successfully tested 4,867 relays, while 2,132 relays were untested due to
circuit building timeouts. On average, the tested relays represent 341/382 Gbit/s
(89%) and 525/570 Gbit/s (92%) of the total advertised bandwidth before and
after the speed test took eﬀect, respectively, whereas the untested relays repre-
sent 41/382 Gbit/s (11%) and 45/570 Gbit/s (8%).
In the remainder of our analysis, we consider only those 4,867 relays that we
successfully tested. We take the relay capacity before the test to be the max-
imum advertised bandwidth over the period from 2019-08-01 until the speed
test starts on 2019-08-06, and we take the relay capacity afterwards to be the
maximum advertised bandwidth from the speed test start until 2019-08-12.
On the Accuracy of Tor Bandwidth Estimation
489
Fig. 3. Rank is by the capacity after the speed test. Discovered capacity is after−before,
whereas relative discovered is (after − before)/after. Summary of relay capacities after
the speed test (in Mbit/s): min=0.262, Q1=12.4, med=53.6, Q3=135, max=998.
Relay Results. Fig. 2b shows the per-relay capacities before and after the speed
test: we observe that many relays increased their capacity estimates, some by
a 10× or greater factor. We do see some relays with slightly reduced capacity
estimates, which could be due to reasons such as reduced bandwidth rates (i.e.,
average bandwidths) or increased background traﬃc from other applications.
Network Results. We ﬁnd that the estimated network capacity (the sum of relay
capacities) increases by about 50% after our speed tests push relays into reporting
higher observed bandwidths. Speciﬁcally, the network increases from 360 Gbit/s
before the experiment to 550 Gbit/s afterwards, which gives a 52.9% increase in
estimated total capacity. The capacity increase among exit relays (i.e., with the
Exit ﬂag) is 30.0 Gbit/s (32.6%), the increase among guard relays (i.e., with the
Guard ﬂag but not the Exit ﬂag) is 91.2 Gbit/s (40.1%), and the increase among
the middle relays (i.e., those remaining) is 61.3 Gbit/s (157%). Because exit band-
width limits Tor’s overall throughput, we therefore could expect that Tor could
handle 30.0 Gbit/s (32.6%) more traﬃc than previously expected. We emphasize
that these results may still underestimate the true capacity of the network: our
test setup was limited by a 1 Gbit/s network link and we were unable to test many
relays, so our results should be taken as a lower bound on both Tor’s true capacity
and on the degree of error in its current capacity estimates.
Eﬀects of Capacity. There are at least a couple of reasons to expect that the
capacity of a relay may aﬀect the amount by which its capacity is currently
underestimated. First, the variance of client traﬃc is likely lower on higher-
capacity relays, as the number of clients they attract is larger, and so by the law
of large numbers we expect the variance in the sum of client traﬃc to decrease.
Because observed bandwidths take the maximum bandwidth over several days,
small relays are more likely by chance to attract a large amount of traﬃc relative
to their size. Second, large relays have fewer peers that they can be paired with
during TorFlow measurements without the other relay acting as a bottleneck
during the measurement. We therefore investigate how the capacity of a relay
aﬀects the amount of capacity “discovered” during the speed test, that is, the
change in the advertised bandwidth after the speed test.
490
R. Jansen and A. Johnson
Fig. 4. Capacity after and discovered by speed test by relay position.
Figure 3a shows the capacity discovered per relay ranked by the capacity
after the speed test. The capacity after the speed test should be closer to the
true capacity. We notice that at all capacity ranks, the discovered capacity ranges
from none to all of the post-speed-test capacity. To better understand the quan-
titative relationship between relay capacity and discovered capacity, Fig. 3b plots
CDFs for relative discovered capacity after ranking relays by capacity afterwards
and dividing that list into quartiles. Note that the discovered capacity is calcu-
lated relative to the capacity after the speed test, and thus is almost always a
value between 0% and 100%.
We observe that higher-capacity relays have higher discovered capacity, even
relative to their capacity. The median increase is 0.0% for the quartile with the
lowest-capacity relays, 0.0% for the second quartile, 0.9% for the third quartile,
and 32.5% for the highest quartile. This result shows that the largest Tor relays
have the most inaccurate capacity estimates, on both an absolute and relative
basis. It also suggests that the Tor weights may be too low for such relays,
reducing load-balancing and thus Tor performance overall. We do notice that for
all but the smallest relays, there is a high degree of capacity underestimation:
at P90 the relative discovered capacity is 4.74% for the ﬁrst quartile, 53.8% for
the second, 72.7% for the third, and 89.4% for the fourth.
Eﬀects of Position. We might also expect that relays in diﬀerent positions have
diﬀerent degrees of capacity underestimation. An exit relay, for example, carries
more traﬃc relative to its capacity than other relays because the exit position
has the least total bandwidth, and so we may expect that it has a better estimate
of its true capacity. Figure 4a shows the distribution of advertised bandwidths
after the speed test. We again (and throughout the paper) consider relays with
the Exit ﬂag to be exits, relays with the Guard but not Exit ﬂag to be guards,
and the remaining relays to be middles. There were 764 exits, 2,049 guards,
and 1,943 middles. We see that exit and guard relays have similar distributions,
with medians of 109 Mbit/s and 92.3 Mbit/s, respectively. The middle relays
have signiﬁcantly smaller capacities, with a median of 10.0 Mbit/s. Figure 4b
shows the amount of discovered capacity by position. While the median values
are all at or near zero, we discovered a relatively large amount of bandwidth for
On the Accuracy of Tor Bandwidth Estimation
491
Fig. 5. The eﬀects of uptime on discovered capacity. (a) Relay uptime, where relays are
ranked by absolute discovered capacity (after− before). Absolute discovered capacities
summary (in Mbit/s): min = −169, Q1 = 0.00, med = 0.01, Q3 = 20.8, max = 881. (b)
Relay capacity after the speed test of exits with ≥ 75% uptime (379 such exits). Relays
are ranked by relative discovered capacity ((after − before)/after). Relative discovered
capacities summary: min = −96.6%, Q1 = 0.00%, med = 0.00%, Q3 = 10.2%, max =
91.0%.
a signiﬁcant fraction of relays in each position, with third quartile (P75) values
of 39.1 Mbit/s for exits, 31.1 Mbit/s for guards, and 5.35 Mbit/s for middles.
These results show surprisingly that exit relays generally had the most discovered
capacity, despite their relatively high traﬃc load.
Eﬀects of Uptime. To investigate the capacity estimation errors, we next consider
how a relay’s uptime aﬀects its discovered capacity. We expect that increased
uptime will lead to lower discovered capacity because of the slow feedback
between increasing the observed bandwidth, which attracts additional client traf-
ﬁc, which then further increases the observed bandwidth [8].
We compute uptime as the fraction of consensuses (i.e., hours) in which
the relay was present during the year preceding our speed test (2018-08-01 to
2019-07-30). Figure 5a shows that increased uptime is correlated with decreased
discovered capacity. The median annual uptime of the top quartile of relays (i.e.,
those with the largest discovered capacities) is 56.6%, while the median uptime
of the bottom quartile is 93.2%. We note that the bottom two quartiles each have
nearly zero discovered capacity, explaining their similar uptime distributions. If
we consider the uptimes by position, we observe the same general pattern: guards
generally have higher uptime and middles generally have lower. These results
support the observed phenomenom that relays’ observed capacities increase over
time towards the true amounts [8].
We have shown that position, capacity, and uptime separately lead to diﬀer-
ent amounts of error in the advertised bandwidth. To somewhat disentangle these
eﬀects, we consider now the discovered capacity for the exit position (other posi-
tions are similar and appear in the Appendix), and we only consider relays with an
uptime of at least 75% during the year preceding our experiment. By considering
only the relays that were online for many months, we expect to largely remove the
slow-increase phase of Tor’s measurement system. Moreover, by considering just
492
R. Jansen and A. Johnson