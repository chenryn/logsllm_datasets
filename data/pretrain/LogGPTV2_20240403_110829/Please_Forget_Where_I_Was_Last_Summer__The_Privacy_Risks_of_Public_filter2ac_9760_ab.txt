conﬁdence in placing users in other sensitive locations, as dis-
cussed in Section III-C. It is imperative to note that our system
incorporates heuristics that are built upon intuitive assumptions
regarding common human behavior and legislative norms (e.g.,
8-hour shifts) in the US (location of our study’s users) and
many other countries as well (e.g., in the European Union).
While highly effective, these heuristics may require tweaking
for countries with vastly different social norms or legislature;
such cases are out of the scope of this work.
To capture the temporal characteristics of each cluster and
understand the user’s activity and tweeting patterns, our system
identiﬁes active time windows, i.e., windows with at least one
geotagged tweet. Apart from days or weeks, time windows can
be set to represent weekdays, weekends, or even speciﬁc time
frames at a granularity of hours (e.g., afternoon, late night).
Homes. Due to the non-ephemeral relationship people
have with their home, the temporal characteristics of a user’s
tweeting behavior can sufﬁciently distinguish this location
from other visited locations. One exception could be users
that are considerably privacy-cautious and refrain from posting
geotagged tweets from their home or surrounding areas. Our
approach for identifying a user’s home cluster is based on the
following intuitions: (i) as the user spends time at home every
day, we expect to repeatedly observe activity from this cluster
(i.e., multiple active windows in the cluster’s timespan), and
(ii) the tweets will not occur solely within a speciﬁc time frame
– we expect tweets that correspond to almost all hours in the
day. In other words, while other clusters may follow a speciﬁc
well-deﬁned temporal pattern, we expect the home cluster to
exhibit a more “chaotic” behavior in the long term, having
tweets that were posted at different times throughout the day,
from early in the morning to very late at night.
While experimenting with two approaches for specifying
the time windows (i.e., only weekends vs entire weeks), we
observed that a week-based time window may introduce uncer-
tainty for users that exhibit considerable activity from multiple
clusters. As such, we design a robust home-inferring algorithm
by only considering weekends. We determine which are the
3
than 20% of their daily time frames exceeding the ten-hour
threshold (i.e., one workday per week) based on reported
average overtime hours in the US [2] and the European Union’s
limit for 48 hours per week. Finally, we select the cluster with
the largest number of active weeks as the user’s workplace.
It is important to note that our approach provides the ﬁrst
adaptive approach that dynamically identiﬁes shifts or common
working hours for each individual user, contrarily to previous
approaches that followed a simplistic approach of considering
ﬁxed working hours for all users (e.g., “09:00-17:00”).
An example of the tweeting activity of two users from
both home and work is given in Figure 1. Both users’ locations
were correctly identiﬁed by LPAuditor. For the top user, tweets
from work fall in a well-deﬁned time frame (08:00-16:00), in
contrast to tweets posted from home, which cover almost all
times of day. The bottom user exhibits a more erratic behavior
with different work shifts within a week, highlighting the need
for our dynamic approach that adapts to different patterns.
C. Identifying Highly-Sensitive Places
While identiﬁcation of a user’s home and workplace is
a signiﬁcant privacy risk, our goal
is to also explore the
feasibility of uncovering personal user information that may
be considered even more sensitive. As such, we want
to
identify other places a user has visited that could be used
to infer such sensitive information. LPAuditor identiﬁes a
user’s Potentially Sensitive Clusters (PSCs) which are in close
proximity to highly-sensitive venues, and determines whether
the user actually visited these venues. To label a cluster as a
PSC, we estimate the cluster’s mid-point and use Foursquare’s
venue API to retrieve information about the nearest venues.
We consider venues that are within a 25 meter radius from
the cluster’s mid-point coordinates; we set a more restrictive
threshold compared to the key location clustering process to
avoid potential false positives due to the small number of
tweets per cluster and density of PSCs. In practice, if LPAu-
ditor is offered as an auditing tool to users, these thresholds
can be user-conﬁgurable to allow for ﬂexibility for areas of
different venue density (e.g., downtown metropolitan areas vs
rural areas). The Foursquare API returns the name of each
venue as well as its type, selected from an extensive list of
predeﬁned categories. As such, we have identiﬁed which of
the venues returned by the API are associated with sensitive
categories or subcategories (which are shown in Figure 8).
Content-based corroboration. Proximity to a sensitive
venue does not necessitate that the user has actually visited
it (at least on that occasion). It could quite possibly be a case
of simply passing by or visiting a different (potentially non-
sensitive) nearby venue. To determine if the user is associated
with the sensitive venue, we analyze the content of the cluster’s
tweets in an effort to capture terms that indicate the user’s
presence at that venue. It is important to note that despite the
user including some relevant keyword in the tweet, location
metadata allows attackers to obtain more context and infer
sensitive information that the user did not intend to disclose.
LPAuditor uses three manually-curated wordlists of related
terms based on numerous online domain-speciﬁc corpora that
contain keywords related to our sensitive categories. Speciﬁ-
cally, our wordlists contain medical- and health-related terms,
4
Fig. 1: An example diagram representing the tweeting activity
of two users in our dataset from their home and work clusters.
User1 exhibits a more “traditional” activity pattern, while
User2 exhibits erratic patterns with different work-shifts.
user’s ﬁve most active clusters “horizontally”, i.e., those with
the highest number of active weekends, and estimate the time
frame and active hours of each of these clusters. Following our
intuition that the home will exhibit more widespread temporal
activity from a macroscopic viewpoint, we choose the cluster
with the broadest time frame as the user’s home.
Work. We expect that, for most users, tweets posted from
work will follow a well-deﬁned time frame that corresponds
to the working hours. We set the time window to the entire
week and identify the ﬁve most active clusters, i.e., those
with the highest number of active weeks (in the horizontal
dimension). We ignore the home cluster when assembling this
set. For each remaining candidate cluster we try to identify
the cluster’s most dominant time frame; we identify all the
distinct days in which the user has posted more than one
tweet, and use the day’s earliest and latest tweet for calculating
that day’s time frame. After estimating the time frame of each
active day, we superimpose all these time frames and consider
as the dominant time frame the set of hours that appears in
more than half of the cluster’s active days. This allows us to
avoid including insigniﬁcant hours, e.g., days where the user
happened to go to work a little earlier or later than usual. This
also allows us to handle users that have a more lax schedule
or work in shifts. We also account for users that work night
shifts which span two consecutive dates; we consider instances
of active time windows that span two days, have a duration of
up to eight hours [12], terminate by 07:00,3 and are followed
by a period of inactivity of at least eight hours.4
Next, we exclude all tweets not belonging to the dominant
time frame. We also exclude clusters that repeatedly have daily
activity of more than ten hours, as they most likely do not
correspond to the user’s work (since we assume that most
jobs have eight-hour shifts). However, as sometimes people
are required to work overtime, or stay at work longer than
usual, we are ﬂexible and only exclude clusters with more
3In the United States the night shift is typically 23:00-07:00 while the
European Union identiﬁes it as including the 00:00-05:00 period [3].
4The US Department of Labor considers that a normal shift is followed
by “at least an eight-hour rest” [12] while the European Union’s 2003/88/EC
directive establishes a “minimum rest period of 11 consecutive hours.”
 User 1 Activity from HomeActivity from WorkWeekend Period00:00  03:00  06:00  09:00  12:00  15:00  18:00  21:00                                                   Time of dayUser 2Day00:00  03:00  06:00  09:00  12:00  15:00  18:00  21:00  1      8      15      22      29      36      43       terms associated with various religions, and sex/nightlife. We
remove relevant keywords that are overtly ambiguous in con-
text, as they can lead to false positives (e.g., “joint” may refer
to a part of the body, some type of establishment, or may be
drug-related). Our wordlists are available online.5
LPAuditor ﬁrst pre-processes users’ tweets (i.e., tokeniza-
tion, lemmatization, removes punctuation, emojis, mentions,
stop-words and URLs) using the NLTK library. Then it uses
term frequency - inverse document frequency (tf-idf) to
identify the most signiﬁcant terms within the tweets of each
PSC. For each cluster we consider the cluster’s tweets as the
document and the entirety of the user’s tweets as the collection
(with each cluster considered as a document). As tf-idf
assigns a score to the terms of the cluster, we check the three
terms with the highest score against the respective wordlist, to
determine if the context of these terms can be associated with
a nearby sensitive venue.
Duration-based corroboration. Due to the sensitive na-
ture of these venues, users will not always include content in
their tweets that enables us to place them in a sensitive venue.
For this reason, we introduce another approach that does not
depend on the content of tweets, but on the repetitiveness and
duration of user visits to a speciﬁc geographic area, in order to
identify places the user has likely visited. More speciﬁcally,
with this approach we identify PSCs that have consecutive
tweets in the span of a few hours, which indicate that the user
has spent a considerable amount of time at that place. In order
to avoid cases where the users did not visit a sensitive place but
posted multiple tweets while passing by it, we exclude cases
of consecutive tweets that have been posted in short periods of
time (within ﬁve minutes). We also identify tweets posted from
the same cluster on different days, which shows that the user
tends to repeatedly visit that place. Obviously this approach
does not work for clusters with a single tweet, and it lacks the
additional conﬁdence in placing the user at the sensitive venue
that we obtain with the content-based approach. Nonetheless,
it highlights a signiﬁcant source of privacy leakage.
D. Implementation Details
LPAuditor has been designed as a completely modular
framework, allowing for each individual component
to be
trivially changed or extended (e.g., incorporating a new data
source, or implementing a different clustering method etc.).
Our system has been fully implemented in Python, and all
collected data is stored into a Mongo database. In more detail,
we leverage the Tweepy package for interacting with Twitter’s
API and collecting users’ timelines. For the ﬁrst-level cluster-
ing and address validation we rely on the Geopy package
(via which we interact with the ArcGIS and Google APIs),
while our second-level clustering is based on the default imple-
mentation of DBSCAN as provided by the scikit-learn
package. For collecting venue information LPAuditor uses the
Foursquare package, while the NLTK package is used for
all tweet preprocessing and procedures related to tf-idf. Given
the importance of scalability when processing large collections
of users, we have designed LPAuditor to be able to use multiple
API keys in parallel. This allows us to speed up the more
inefﬁcient parts of the process which rely on communicating
5https://www.cs.uic.edu/∼location-inference/
with external, and often rate-limited, APIs. Finally, as each
user is processed completely independently from other users at
all stages, multiple instances of our framework can be executed
in parallel for increasing efﬁciency.
IV. DATA COLLECTION
We ﬁrst describe our automatically-collected Twitter
datasets, and then outline our methodology for manually creat-
ing a ground truth dataset used for the experimental evaluation.
Datasets. We used Twitter’s streaming API for collecting
a set of tweets within a bounding box that covers the mainland
area of the United States. While LPAuditor can be applied to
any country with similar working norms (e.g., shift duration)
we opted for users in the US as our sensitive location inference
also requires the tweet content and we currently only support
English. Furthermore, it is also the one country common across
the datasets of all the prior studies we compare to in Section V.
Nonetheless, an interesting future direction is to explore these
privacy risks for users in other countries.
An initial set of tweets was collected in November 2016,
through which we obtained 308,593 unique user identiﬁers
(UIDs). Then we collected each user’s proﬁle information and
timeline (the 3,200 most recent tweets, according to Twitter’s
policy). This dataset contains 456,856,444 tweets, which have
been generated from 15,094 distinct sources (including unof-
ﬁcial Twitter client apps and websites).
Apps may handle geolocation data differently as Twitter’s
Geo Guidelines [11] are neither mandatory nor enforceable. To
avoid inconsistencies, we only consider ofﬁcial Twitter apps
and Foursquare in this study, which also account for the vast
majority of collected tweets. After this ﬁltering, we end up
with 290,162 users and 345,643,445 tweets. We break down
our dataset in Table I; users who posted tweets from multiple
apps are counted in all the respective categories. Figure 2 (left)
shows the number of tweets in each user’s timeline. We ﬁnd
that only ∼0.5% of the users have more than 3000 tweets, and
less than 0.06% reached Twitter’s API limit of 3,200.
As we are interested in the privacy implications that stem
from geolocation metadata, we identify all users with at
least one tweet containing GPS coordinates in the metadata.
We identiﬁed 87,114 such users, which have contributed
15,263,317 geotagged tweets in total. In Figure 2 (right) we
present the number of users’ geotagged tweets. Surprisingly
we ﬁnd that for 30.03% of the users the Twitter API reveals
some precise geolocation information, with 8.01% of the users
having less than 10 geotagged tweets. We also observe that
15.55% of the users have between 10 and 250 geotagged
tweets, and approximately 5% and 2% of the users have more
than 330 and 655 geotagged tweets, respectively.
Users with many geotagged tweets may have patterns that
differ from those of users with a signiﬁcantly lower number.
For this reason we conduct our analysis on two different sets of
users. The ﬁrst set (Top-6K) consists of the top 6,010 users in
our dataset that have the most geotagged tweets (approximately
top 2% of users in Figure 2), while the second set (Low-10K)
consists of 9,841 randomly selected users that have between
10 and 250 geotagged tweets. We use these two sets of users
for our main analysis (instead of all collected users), due to the
5
TABLE I: Breakdown of tweets’ sources in our dataset.
Application (source) Geoloc.
Twitter for Android
Twitter for iOS
Twitter for Web
Foursquare




Users
99,979
328,320
253,616
13,192
Tweets
50,188,992
291,820,742
39,655,850
3,633,711
Fig. 2: Total number of tweets per user (left), and the number
of tweets per user that are geotagged (right).
rate limits imposed by the API providers that we use for our
clustering process. Also, by including users with as few as 10
geotagged tweets, we can explore the privacy risk that users
face even when very few location data points are available.
Geotag accuracy. While certain location-based services
may add some form of noise or obfuscate the user’s loca-
tion [53], that is not the case with Twitter. The GPS coordinates
returned by the API match those provided by the user’s device.
Ground truth collection. As we aim to demonstrate the
true extent of this privacy issue by identifying key locations at
a postal address granularity, a signiﬁcant challenge is obtain-
ing the ground truth for evaluating our accuracy. While our
home/work identiﬁcation algorithms focus on spatiotemporal
characteristics, creating the ground truth mandates an analysis
of the tweets’ content. Due to strict requirements for veracity,
we did not resort to an automated process but opted for an
arduous and painstaking manual process that required over 6
weeks of continuous effort. While we have explicitly limited
our collection to publicly available data offered by the ofﬁcial
Twitter API, we took extra precautions during our manual
analysis phase for protecting users’ privacy. Speciﬁcally, users’
account information (name, username) was not included in the