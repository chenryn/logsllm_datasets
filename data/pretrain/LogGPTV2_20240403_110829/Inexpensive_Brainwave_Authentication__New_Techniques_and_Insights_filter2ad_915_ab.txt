kept rather dark and quiet, in order not to disturb the subjects.
Next, their brainwave activity was recorded while performing
the authentication tasks. As shown in Figure 2, the recording
starts with baseline measurements of brain activity while rest-
58    30th USENIX Security Symposium
USENIX Association
in the experiment, conducted between May 8 and July 2, 2019.
We recorded ERPs from 23 females (41.1%) and 33 males
(58.9%), leading to an slightly imbalanced gender distribution.
With regard to age, our population is skewed towards young
adults because most of the experiments were conducted with
university students. The majority, 28 subjects (50%), fall in
the age range 18-24, followed by 16 (28.6%) participants aged
between 25 and 31, and 8 (14.6%) in the range 32-38. The
remaining 4 persons (7.2%) were over 39 years old.
4 Brainwave Data Processing
Before we can get useful brainwave data for the classiﬁcation
algorithms that implement authentication, raw EEG signals
must undergo a two-step preparation process to: 1) remove
undesirable artifacts, and 2) extract relevant features for au-
thentication. This section summarizes the data preparation
steps, following common practices in the literature [28], and
the classiﬁcation models we apply to these data.
4.1 Pre-processing and Feature Extraction
The data recorded during the experiment contains continuous
EEG measurements of about 20 minutes length, captured at a
sampling rate of 256 Hz. However, only speciﬁc relevant sec-
tions around the presentation of stimuli, i.e., the ERP waves,
are required for authentication. These sections are also called
epochs and constitute a user sample. To extract the ERPs,
we cut 1-second length epochs from 100ms before stimulus
presentation until 900ms thereafter to guarantee that we get
the potential’s information, considering variances in the peak
latency [69]. After epoch extraction, we ﬁltered electrical
noise and removed samples with bad quality measures or con-
taining large artifacts that contaminate the EEG signal (e.g.,
eye or muscle movements). With the clean EEG signal, the
next step is to obtain discriminant features that represent and
encode the mental activity of a user [28]. We chose the most
common features in the time and frequency domains applied
in previous works [1, 3, 6, 28, 82], and used them as a basis
to further identify which features work best for our proposed
tasks (see Section 5.2.3). First, considering the ERP epoch
a 1-second time series, we ﬁt it to an Autoregressive (AR)
model with 10 coefﬁcients and take them as features. Second,
we split each 1-second epoch into ﬁve segments of 200ms and
calculate their Power Spectrum (PS) in different frequency
bands (α [10-13Hz], β [13-30Hz], and γ [30-50Hz]). More-
over, we generated 15 cumulative features by aggregating the
PS of all 14 channels per segment, and 3 highly aggregated
features, by grouping the PS of all segments into one feature
per frequency band. Table 1 shows the ﬁnal datasets after
pre-processing, linked in Appendix 8.
Figure 2: Graphical ﬂow of the experiment tasks to record
users’ brainwave activity for authentication. Each task is
brieﬂy described, labeled with the potential meant to be
evoked (P300 or N400), and tagged with its duration.
ing. Then, it follows with several sequences and repetitions
of the authentication tasks4, to acquire multiple samples for
training and testing the classiﬁcation algorithms. After the
recording, participants ﬁlled out a paper questionnaire to as-
sess the usability of a brainwave authentication system based
on the performed tasks and headset (details in Section 6). All
experiment materials are linked in Appendix 8.
Apparatus. We use the Emotiv EPOC+ headset [25] to
record brainwave activity. We chose this device because it is
the prevalent choice in scientiﬁc studies and it offers a higher
number of recording channels (14) than other consumer grade
products, which leads to more accurate measurements5. The
experiment ﬂow was programmed with PsychoPy [58], an
open source tool for conducting experiments in behavioral
sciences, and connected to the EPOC’s reading software to
synchronize stimuli presentation with brainwave recording.
Recruitment and Ethical Aspects. We recruited partici-
pants following a self-selection sampling approach [39]. The
study was advertised through different channels asking for
volunteers, including online posts, ﬂyers spread at different
university locations and brief announcements during lectures.
Each participant received information about the experiment
and about how we would treat their personal data fulﬁlling the
EU General Data Protection Regulation (GDPR) [26], in order
to get informed consent. To avoid biasing the subjects, we dis-
closed the actual purpose of the experiment, i.e., building an
authentication system, at the end of the recording session and
before the usability questionnaire. The approximate average
duration of the whole study was 45 minutes and we compen-
sated participants with 5C and a report on their brainwaves
containing information about interest, stress, and focus level
during the study. Subjects were also told that participation
was voluntary and the experiment could be abandoned at any
time. The whole procedure is IRB-approved.
Participant Demographics. In total, 56 subjects took part
4Element D in the study ﬂow depicted in Figure 2 was included to test
subliminal manipulations Since we did not obtain conclusive results in this
regard, we just report it as a study item without giving further details
5The reader is referred to [65] for a comprehensive review and comparison
of consumer grade EEG readers, including research applications
USENIX Association
30th USENIX Security Symposium    59
Dataset
P300:Selected
P300:Assigned
N400:Words
N400:Sentences
N400:Faces
#users
52
52
52
50
50
#samples
911
910
1733
276
424
Table 1: Brainwave datasets for ﬁve authentication tasks.
4.2 Classiﬁcation
For the purpose of authentication, the recorded data samples
of each user need to be compared to stored samples of the
same subject and classiﬁed as matching or not. We compare
and discuss the applicability of two authentication model
approaches: 1) one-class classiﬁers (aka anomaly detectors),
which only require training data from the genuine user; and
2) two-class classiﬁers, which are trained on data from both
authentic and impostor users. For each category, we chose a
small set of representative approaches suited for our dataset
dimension, namely:
One-class classiﬁcation. We
k-Nearest-
Neighbour (kNN) method to classify users based on
distance to training instances, and a one-class Support
Vector Machine (SVM).
implement
a
Two-class classiﬁcation. We chose a probabilistic Gaussian
Naïve Bayes (GNB) classiﬁer, and the two most com-
mon linear algorithms, Logistic Regression, and linear
Support Vector Machines (SVM).
We refer the interested reader to related work for more
details on these models and their applications [28, 40].
5 Authentication
This section evaluates the performance obtained for the pro-
posed authentication tasks, comparing one-class vs two-class
classiﬁcation algorithms, analysing feature relevance, and
contextualizing the results with regard to related work.
5.1 Evaluation Metrics
Several methods can be applied to evaluate classiﬁcation sys-
tems. In the case of a binary problem, there are four pos-
sible classiﬁcation results: 1) authenticate a legitimate user
(True Positive or TP), 2) authenticate an illegitimate user
(False Positive or FP), 3) deny an illegitimate user (True Neg-
ative or TN), and 4) deny a legitimate user (False Negative
or FN). Based on the frequency counts of these results, the
performance of the system is typically assessed by its False
Acceptance Rate (FAR), False Rejection Rate (FRR), and
Accuracy (ACC). The FAR compares the number of false
positives to the sum of false positives and true negatives, i.e.,
how often an impostor is authenticated as legitimate. In turn,
the FRR compares the number of false negatives to the sum
of true positives and false negatives, giving an idea of the
frequency at which the system rejects legitimate users. Fi-
nally, the ACC represents the number of correct predictions
over the total number of predictions made by the classiﬁer.
These metrics, however, are tied to a speciﬁc conﬁguration of
the classiﬁcation threshold. Instead, we visualise results with
Receiver-Operating-Characteristic (ROC) curves, which plot
the FAR and True Positive Rate (=1-FRR) as a parametric
function of the threshold. We also report Equal Error Rates
(EER), as a summary metric that represents the point where
FAR and FRR are equal. This reporting scheme, as suggested
by Sugrim et al. [68], allows for a better understanding of
the operation capabilities of authentication methods, and how
they can be conﬁgured for different use-cases.
5.2 Results
We evaluated user authentication for the ﬁve deﬁned tasks
using one-class and two-class classiﬁers. We remove users
with less than 5 samples from the datasets to have enough data
for training. The one-class SVM (with Radial Basis Function
kernel) and kNN (k=2) classiﬁers were trained on the sam-
ples of one single user6, considered the legitimate user, and
then tested with samples from both the legitimate user, which
should be recognised based on the learned model, and all
the other illegitimate users, which should be rejected as out-
liers. For two-class classiﬁcation, we followed a one-vs.-all
approach [61]. According to this scheme, we built specialized
classiﬁers per user by assigning all the samples from this user
with the “authenticated” class label, and all the others with
the “rejected” label. We applied grid search to select the best
features (based on their statistical signiﬁcance to classify the
authentic user) within a nested stratiﬁed 5-fold cross vali-
dation loop7. For every classiﬁcation algorithm, we run the
evaluation process for all the users in each dataset and we
report the average EERs.
5.2.1 One-class vs Two-class Classiﬁers
The overall results are summarized in Table 2. As expected,
the performance with two-class learning is better than that
of one-class classiﬁers. Binary classiﬁers are usually more
powerful, since they characterise the legitimate user in con-
trast to others, whereas anomaly detectors can only check for
deviation from the legitimate user’s behaviour. In practice,
this means that a set of anonymous user’s data needs to be
pre-loaded in the application or device that offers brainwave
authentication. Then the classiﬁcation model can be realized
6We used a split ratio of 0.6 to 0.4 for training and testing sets
75-folds in inner and outer loops
60    30th USENIX Security Symposium
USENIX Association
Equal Error Rate (%)
One-Class
Task
P300:Selected
P300:Assigned
N400:Words
N400:Sentences
N400:Faces
kNN
49
49
49
48
47
SVM GNB
24.89
23.45
21.21
20.34
14.5
44
42
40
43
40
Two-Class
LG
30.85
30.53
30.21
26.14
30.21
SVM
33.5
34.14
31.22
29.31
32.76
Table 2: Average Equal Error Rate (EER) for ﬁve authentica-
tion tasks comparing one-class vs two-class classiﬁers.
by combining the data of genuine users. While this type of
implementation is feasible and has been proposed for other
behavioral biometrics [17, 70], further research is needed on
how to anonymize brainwave data.
5.2.2 ROC-based Performance of Authentication Tasks
Overall Performance. With regard to authentication tasks,
our results establish the N400 protocols as better authentica-
tion options than the P300 protocols, and the best performing
task is the N400:Faces, with an average EER of 14.5%. Fig. 3
shows the ROC curves for the best classiﬁers, illustrating the
operational range of the ﬁve authentication models. The area
under the curve (AUC) represents the probability that a ran-
dom illegitimate user is scored lower than a random genuine
user, i.e., how well the classiﬁer can separate users. Look-
ing at these metrics, while the N400:Faces outperforms the
rest of the tasks in the tested conditions, all schemes show
potential for discerning users and could therefore be feasible
for brainwave-based authentication. However, there is a high
variability from the average ROC curves. In this regard, an
important factor to consider in the comparison is the different
number of samples and users per task. As it can be observed in
Fig. 3a, the N400:Words task has the highest number of sam-
ples (1730 for 51 users), which almost doubles those available
for the P300 tasks (911 and 910 for 52 users). In the case of
the remaining N400 protocols, the datasets are reduced to 33
users and 198 samples for the N400:Sentences and 44 users
and 406 samples for the N400:Faces. Accordingly, it can be
observed that protocols with less users perform better, which
can be related to a higher probability of having similar users
in the datasets or having more users for whom the acquisition
process failed to achieve brainwave data with good enough
quality. In the case of N400:Sentences, the performance can
be negatively impacted by the low number of samples per
user (6 on average), which leads to very few data for training,
testing, and validation.
Applicability. In real world authentication scenarios, sys-
tems do not operate at the EER, but at conﬁguration points
were the FAR is lower than the FRR, to minimize the prob-
ability of impostors accessing the system. In general, most
biometric systems have a FRR ranging from being falsely
rejected one out of ﬁve times up to one for every thousand
times (i.e., 20% to 0.1%) [34]. The FAR is more critical for
security and usually ranges from 1%, for low security appli-
cations, to 0.00001% for very high security applications [18].
In this sense, our ROCs show that authentication based on
the N400:Face task can be conﬁgured for best accuracy at a
FAR of 1.8% and associated FRR equal to 46%. While the
FAR value is close to the needs of low-security application
scenarios, the FRR is unacceptably high. This same trend is
observed in the ROCs for the rest of the tasks. However, we
expect lower error rates in real implementations with person-
alized stimuli. We measure and report the FAR calculated by
directly comparing impostors’ ERP samples to the legitimate
user model. But if we consider the dynamics of the authen-
tication protocols, those ERPs should appear in response to
the target stimuli (e.g., unfamiliar faces within a series of
familiar ones). Checking this condition before accepting an
ERP will yield lower FARs, as it is highly unlikely that an
impostor reacts to the stimuli designed for the legitimate user.
Therefore, the obtained FAR is to be understood as a rough
upper bound.
5.2.3 Feature Relevance
In addition to classiﬁcation performance, we analyzed the
importance of the features for classiﬁcation to inform future
designs of brainwave authentication prototypes. Fig. 4 shows
a heatmap of selected features across the different user clas-
siﬁers for the ﬁve authentication tasks. The most commonly
removed features are located in the α frequency band. This is
reasonable, since brainwaves in this band are the most domi-
nant rhythm and correlate with mental states of no attention,
being stronger when the eyes are closed [4]. They have been
proved useful in brainwave authentication based on relaxation
tasks [50], but are not applicable for the tasks proposed in
this paper. Instead, the β and γ waves are usually exhibited
in states of focused attention and active information process-
ing [1], which can be the reason why they are more relevant
for classiﬁcation in our visual and semantic processing tasks.
5.2.4 Comparison with Related Work
Performance. Comparison with existing works on brain-
wave authentication is challenging due to the frequent under-
reporting of metrics (usually presented for an optimized con-
ﬁguration without providing ROCs) and the differences in the
number and diversity of samples, algorithms, experimental
conditions, and other aspects that inﬂuence performance. Ac-
knowledging these difﬁculties, we ﬁrst compare against sys-
tems8 using consumer-grade EEG readers that report EERs,
and then, to broaden the comparison, we contextualize our
results with regard to other relevant works in the literature.
8Excluding multi-modal and multi-factor authentication approaches
USENIX Association
30th USENIX Security Symposium    61
(a) Samples
(b) ROC P300:Selected with GNB
(c) ROC P300:Assigned with GNB
(d) ROC N400:Words with GNB
(e) ROC N400:Sentences with GNB
(f) ROC N400:Faces with GNB
Figure 3: Performance comparison of ﬁve authentication tasks using Gaussian Naïve Bayes (GNB). Fig. (a) shows the number
of samples per subject and task available for classiﬁcation, using a minimum threshold of ﬁve samples per user. Figs. (b), (c), (d),
(e) and (f) depict the ROC curves for each authentication task.
Nakanishi et al.
investigated various authentication
tasks [47, 49, 51–53], including resting (EER=11%, n=23),
driving (EER=22-24%, n=10-30), low intensity visual stimuli
(EER= 23%, n=20), and ultrasound stimulation (EER=26.2%,
n=10). In all cases, our N400:Faces protocol has better or
similar performance9. Furthermore, when compared to the
ultrasound and visual tasks, which are based on ERPs and
therefore closer to our proposal, we decrease the EER from
23%-26.2% to 14.5% for the N400:Faces task, which means a
relative error reduction of 37-44%. These results indicate that
visual tasks based on cognitive semantic processing are more
suitable for brainwave authentication than current ERP-based
proposals in the literature. The only other works reporting
lower EERs use multi-modal fusion [6, 52] (EER=4.4% and
EER=0%) or a second factor [2] (EER=0.89%) to comple-
ment brainwaves, which suggests these are viable paths to
further improve the applicability of our tasks.
Though not reporting EER, the study by Chuang et al. [20]
is specially relevant because they get high authentication ac-
curacy using a 1-electrode EEG reader. Their best performing
task is moving a ﬁnger, with FAR=4% and FRR=76% (n=15).
9We computed the variation of EER with the number of subjects for the
implemented tasks at points n={5,10,15,20,25,30,35} and use the closest
EER value when comparing with related works tested on a smaller sample.
Subjects were randomly selected and the EER averaged across 5 repetitions.
But applying customized thresholds per user, they move up
to a 0% FAR and FRR=9% using a mental singing task for
authentication. If we apply a simple threshold selection (max-
imizing TPR-FAR) to the N400:Faces protocol, our perfor-
mance also improves, achieving a point where FAR=8.5%
and FRR=10.4%. This is a good result for practical applicabil-
ity, considering that the FAR is already an upper bound (see
Section 5.2.2), and we expect even better performance with
more personalized thresholds and additional optimizations.
Looking at the literature using medical-grade EEG read-
ers, the work by Das et al. [21] is the closest to ours. They
use P300 ERPs for authentication, achieving EERs around
13% (n=50) with 17 sensors. We show that it is possible to
achieve comparable results with N400 potentials and a sim-
pler headset. There are also relevant studies demonstrating
the value of ERPs for biometric identiﬁcation, such as CERE-
BRE [62], which provides 100% accuracy in identifying 52
users. Though not directly comparable, it provides interest-
ing insights on how to optimize classiﬁcation through voting
schemes, which could be also applicable to improve perfor-
mance on the authentication case.
Participant Pool Size Considerations. The ISO-19795
[31] for biometric testing recommends 300 samples (as a
minimum lower bound) for 95% conﬁdence on a FAR <=1%.
We targeted approximately this minimum size in our datasets,
62    30th USENIX Security Symposium