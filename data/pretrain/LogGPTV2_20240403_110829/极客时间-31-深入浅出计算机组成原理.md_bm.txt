## 总结延伸这一讲，我从第一代 TPU 的设计目标讲起，为你解读了 TPU的设计。你可以通过这篇文章，回顾我们过去 32 讲提到的各种知识点。第一代TPU，是为了做各种深度学习的推断而设计出来的，并且希望能够尽早上线。这样，Google才能节约现有数据中心里面的大量计算资源。从深度学习的推断角度来考虑，TPU并不需要太灵活的可编程能力，只要能够迭代完成常见的深度学习推断过程中一层的计算过程就好了。所以，TPU的硬件构造里面，把矩阵乘法、累加器和激活函数都做成了对应的专门的电路。为了满足深度学习推断功能的响应时间短的需求，TPU 设置了很大的使用 SRAM 的Unified Buffer（UB），就好像一个 CPU里面的寄存器一样，能够快速响应对于这些数据的反复读取。为了让 TPU 尽可能快地部署在数据中心里面，TPU 采用了现有的 PCI-E接口，可以和 GPU一样直接插在主板上，并且采用了作为一个没有取指令功能的协处理器，就像 387之于 386 一样，仅仅用来进行需要的各种运算。在整个电路设计的细节层面，TPU也尽可能做到了优化。因为机器学习的推断功能，通常做了数值的归一化，所以对于矩阵乘法的计算精度要求有限，整个矩阵乘法的计算模块采用了8 Bits 来表示浮点数，而不是像 Intel CPU 里那样用上了 32 Bits。最终，综合了种种硬件设计点之后的TPU，做到了在深度学习的推断层面更高的能效比。按照 Google论文里面给出的官方数据，它可以比 CPU、GPU 快上 15～30倍，能耗比更是可以高出 30～80 倍。而 TPU，也最终替代了 Google自己的数据中心里，95% 的深度学习推断任务。
## 推荐阅读既然要深入了解 TPU，自然要读一读关于 TPU 的论文[In-DatacenterPerformance Analysis of a Tensor ProcessingUnit](https://arxiv.org/ftp/arxiv/papers/1704/1704.04760.pdf)。除了这篇论文之外，你也可以读一读 Google 官方专门讲解 TPU 构造的博客文章An in-depth look at Google's first Tensor ProcessingUnit(TPU)](https://cloud.google.com/blog/products/gcp/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu)。
## 课后思考你能想一想，如果我们想要做一个能够进行深度学习模型训练的TPU，我们应该在第一代的 TPU 的设计之上做怎么样的修改呢？欢迎留言和我分享你的想法。如果这篇文章对你有收获，你也可以把他分享给你的朋友。![](Images/79d06107d349635530fbf82aa8dfb625.png){savepage-src="https://static001.geekbang.org/resource/image/28/29/281ca28b90c8aa0aecbb5adc08394f29.jpg"}
# 34 \| 理解虚拟机：你在云上拿到的计算机是什么样的？上世纪 60年代，计算机还是异常昂贵的设备，实际的计算机使用需求要面临两个挑战。第一，计算机特别昂贵，我们要尽可能地让计算机忙起来，一直不断地去处理一些计算任务。第二，很多工程师想要用上计算机，但是没有能力自己花钱买一台，所以呢，我们要让很多人可以共用一台计算机。
## 缘起分时系统为了应对这两个问题，[分时系统](https://en.wikipedia.org/wiki/Time-sharing)的计算机就应运而生了。无论是个人用户，还是一个小公司或者小机构，你都不需要花大价钱自己去买一台电脑。你只需要买一个输入输出的终端，就好像一套鼠标、键盘、显示器这样的设备，然后通过电话线，连到放在大公司机房里面的计算机就好了。这台计算机，会自动给程序或任务分配计算时间。你只需要为你花费的"计算时间"和使用的电话线路付费就可以了。比方说，比尔·盖茨中学时候用的学校的计算机，就是GE 的分时系统。![](Images/3df4b2939c9e6d13e01ea01d8cc07c4e.png){savepage-src="https://static001.geekbang.org/resource/image/d1/9d/d107e645e1f849ebcafab0e4d4b73a9d.png"}```{=html}```图片来源](https://commons.wikimedia.org/wiki/File:Unix_Timesharing_UW-Madison_1978.jpeg)```{=html}``````{=html}```图片里面的"计算机"其实只是一个终端而已，并没有计算能力，要通过电话线连接到实际的计算机上，才能完成运算]{.reference}```{=html}```
## 从"黑色星期五"到公有云现代公有云上的系统级虚拟机能够快速发展，其实和分时系统的设计思路是一脉相承的，这其实就是来自于电商巨头亚马逊大量富余的计算能力。和国内有"双十一"一样，美国会有感恩节的"[黑色星期五](https://en.wikipedia.org/wiki/Black_Friday_(shopping))（BlackFriday）"和"[网络星期一](https://en.wikipedia.org/wiki/Cyber_Monday)（CyberMonday）"，这样一年一度的大型电商促销活动。几天的活动期间，会有大量的用户进入亚马逊这样的网站，看商品、下订单、买东西。这个时候，整个亚马逊需要的服务器计算资源可能是平时的数十倍。``{=html}于是，亚马逊会按照"黑色星期五"和"网络星期一"的用户访问量，来准备服务器资源。这个就带来了一个问题，那就是在一年的365 天里，有 360天这些服务器资源是大量空闲的。要知道，这个空闲的服务器数量不是一台两台，也不是几十几百台。根据媒体的估算，亚马逊的云服务器AWS 在 2014 年就已经超过了 150 万台，到了 2019年的今天，估计已经有超过千万台的服务器。平时有这么多闲着的服务器实在是太浪费了，所以，亚马逊就想把这些服务器给租出去。出租物理服务器当然是可行的，但是却不太容易自动化，也不太容易面向中小客户。直接出租物理服务器，意味着亚马逊只能进行服务器的"整租"，这样大部分中小客户就不愿意了。为了节约数据中心的空间，亚马逊实际用的物理服务器，大部分多半是强劲的高端8 核乃至 12 核的服务器。想要租用这些服务器的中小公司，起步往往只需要 1个 CPU核心乃至更少资源的服务器。一次性要他们去租一整台服务器，就好像刚毕业想要租个单间，结果你非要整租个别墅给他。这个"整租"的问题，还发生在"时间"层面。物理服务器里面装好的系统和应用，不租了而要再给其他人使用，就必须清空里面已经装好的程序和数据，得做一次"重装"。如果我们只是暂时不用这个服务器了，过一段时间又要租这个服务器，数据中心服务商就不得不先重装整个系统，然后租给别人。等别人不用了，再重装系统租给你，特别地麻烦。其实，对于想要租用服务器的用户来说，最好的体验不是租房子，而是住酒店。我住一天，我就付一天的钱。这次是全家出门，一次多定几间酒店房间就好啦。而这样的需求，用虚拟机技术来实现，再好不过了。虚拟机技术，使得我们可以在一台物理服务器上，同时运行多个虚拟服务器，并且可以动态去分配，每个虚拟服务器占用的资源。对于不运行的虚拟服务器，我们也可以把这个虚拟服务器"关闭"。这个"关闭"了的服务器，就和一个被关掉的物理服务器一样，它不会再占用实际的服务器资源。但是，当我们重新打开这个虚拟服务器的时候，里面的数据和应用都在，不需要再重新安装一次。