We craft, trace, and have ARCUS analyze exploits for
known CVEs and EDBs in real programs. ARCUS suc-
cessfully handles 27 exploits and even discovers 4 new
0-day vulnerabilities, which we examine in additional
case studies (Subsections 4.2 and 4.5).
3. Are ARCUS’ root cause reports consistent with real-
world advisories and patches? We manually verify that
ARCUS’ root cause reports are consistent with public
disclosures and, where available, ofﬁcial patches (Sub-
section 4.3).
4. Is ARCUS feasible to deploy in terms of runtime and
Table 3: RIPE and Juliet Test Cases
Overall Results (Detection by ≥ 1 Strategies)
RIPE
BSS
Data
Heap
Stack
Juliet
CWE-134
CWE-415
CWE-416
Symbolic IP
BSS
Data
Heap
Stack
Int Overﬂow
BSS
Data
Heap
Stack
TP
170
190
190
260
TP
1,200
818
393
TN FP
170
0
0
190
0
190
260
0
TN FP
0
0
0
2,600
2,212
1,222
By Locating Strategy (RIPE)
TP
154
171
154
211
TP
60
60
60
150
TN FP
0
170
0
190
190
0
260
0
TN FP
0
170
0
190
190
0
0
260
By Locating Strategy (Juliet)
Symbolic Args.
CWE-134
Track Frees
CWE-415
R/W Freed Addrs.
CWE-416
TP
1,200
TP
818
TP
393
2,600
2,212
TN FP
0
TN FP
0
TN FP
0
1,222
FN
0
0
0
0
FN
0
0
0
FN
16
19
36
49
FN
110
130
130
110
FN
0
FN
0
FN
0
Acc.
100%
100%
100%
100%
Acc.
100%
100%
100%
Acc.
95.3%
95.0%
90.5%
90.6%
Acc.
67.6%
65.8%
65.8%
78.8%
Acc.
100%
Acc.
100%
Acc.
100%
storage overhead? We measure the performance and
storage overheads of tracing programs using the SPEC
CPU 2006 benchmark and Nginx (Subsection 4.4).
Experimental Setup & Runtime Monitor Selection. We
use 2 distinct servers to represent the production and analysis
systems, each running Debian Buster and containing an Intel®
Core™ i7-7740X processor, 32GB of memory, and solid state
storage. To serve as end-host runtime monitors, we use an
open source CFI system [1] and our own segmentation fault
handler. The former is used for the exploits that leverage code
reuse attacks and the latter for crashes. We pick this particular
CFI monitor because it is asynchronous and only guarantees
detection of control ﬂow violations by the next system call,
which requires ARCUS to handle traces containing activity
past the initial exploit.
4.1 Accuracy on Micro-Benchmarks
Before deploying ARCUS on real-world programs, we eval-
uate on benchmark test cases where there is known ground
1996    30th USENIX Security Symposium
USENIX Association
truth for the location and behavior of every bug. This is nec-
essary in order to measure false negatives (i.e., executions
where a bug is triggered but ARCUS yields no report) and
cannot be known for real-world programs.9 False positives
are measurable by manually reviewing reports.
Dataset & Selection Criteria. For the overﬂow modules
(stack, heap, and integer), we use the complete RIPE [59]
benchmark, which systematically exploits the provided test
binary with different bugs (memcpy, strlen, etc.), strategies
(ROP, code injection, etc.), and memory locations (stack,
heap, etc.). We port the benchmark to 64-bit and manually
create a second patched (bug-free) version of the test binary
to measure false positives (FPs), false negatives (FNs), true
positives (TPs) and true negatives (TNs). RIPE yields 810
working exploits in our environment.
RIPE does not contain tests for UAF, double free, or for-
mat string bugs. We address this shortcoming with the NIST
C\C++ Juliet 1.3 suite [60], which contains 2,411 buggy and
6,034 bug-free binaries for CWE-416 (UAF), CWE-415 (dou-
ble free), and CWE-134 (format string). These are all the test
cases provided by Juliet for these CWEs.
Results. As presented at the top of Table 3, ARCUS cor-
rectly analyzes all the test cases across all suites with no FPs
or FNs. That is, each TP is detected by at least 1 module and
TN by none. We manually verify that the root cause reports
for the TP cases correctly identify the buggy functions and
the recommendations prevent the memory corruptions.
On closer investigation, we realize that ARCUS is so accu-
rate on the RIPE cases because there are multiple opportuni-
ties for detecting overﬂows. For example, an integer overﬂow
that corrupts a return pointer can be detected either by the
integer overﬂow module when the register wraps around or
by the stack overﬂow module when the pointer is overwritten.
Detecting either behavior (or both) yields an accurate report.
Based on this observation, we present the middle and bottom
portions of Table 3, which separates the RIPE and Juliet re-
sults by the locating strategies from Table 1. For the modules
tested by the Juliet cases, their capabilities do not overlap
and yield the same numbers as in the overall table. For the
strategies relevant to RIPE, we discover that the symbolic IP
detection is 92.9% accurate, on average, whereas the integer
overﬂow detection is 69.5%. The latter is expected given the
challenges described in Subsection 3.3, like inferring signed-
ness in binaries. We observe that the accuracy is consistent
across exploit locations for symbolic IP (4.8% variation), but
less so for integer overﬂow (13%) where it performs better
on stack-based tests. Since each strategy yields 0 FPs, their
capabilities compliment each other, covering their individual
weaknesses and enabling ARCUS to operate effectively.
9If we knew the location and behavior of every bug in real-world pro-
grams, we could produce new versions that are guaranteed to be bug-free,
4.2 Locating Real-World Exploits
With ARCUS veriﬁed to be working accurately on the micro-
benchmarks, we turn our attention to real-world exploits.
Dataset & Selection Criteria. We select our vulnerabili-
ties starting with a corpus of proof of compromises (PoCs)
gathered from the LinuxFlaw [78] repository and Exploit-
DB [79], distilled using the following selection procedure:
1. First, we ﬁlter PoCs pertaining to bug classes not cov-
ered by our modules (Subsection 3.3).
2. Next, we ﬁlter PoCs that fail to trigger in our evaluation
environment.
3. Finally, for PoCs targeting libraries (e.g., libpng), we
select a large real-world program that utilizes the vul-
nerable functionality (e.g., GIMP) for evaluation.
In total, we consider 34 PoCs pertaining to our covered bug
classes (Step 1). Of these, 7 failed to trigger and were ﬁltered
(Step 2). The primary cause of failure is older PoCs written
for 32-bit that cannot be converted to 64-bit. We decide to use
GIMP for evaluating image library CVEs, GOOSE Publisher
for CVE-2018-18957, exif for CVE-2007-2645, and PHP for
CVE-2017-12858 (Step 3).10
This yields PoCs targeting 27 unique vulnerabilities across
20 programs, covering a diverse range of multimedia libraries,
client applications, parsers, and web services. Some are com-
monly evaluated in related work (e.g., libexif [80]), whereas
others align with our motivation of protecting production
servers (e.g., nginx, ftp) and require ARCUS to handle more
complex behaviors like multi-threading, inter-process com-
munication, and GUIs (e.g., GIMP). For vulnerabilities that
lead to arbitrary code execution, we develop the PoCs into
exploits that use code reuse attacks like ROP. We create
crashing exploits only as a last resort.
Results. Table 4 shows that our system is able to success-
fully localize all 27 exploited vulnerabilities. Surprisingly,
ARCUS also uncovers 4 new 0-day vulnerabilities — 3 is-
sued CVE IDs — that are possible to invoke along the same
control ﬂow path, bringing the total count to 31. An example
of how this occurs is presented in Subsection 4.5. For ex-
ploited libraries evaluated in the context of a larger program
(e.g., CVE-2004-0597), we show the traced program’s name
alongside the library.
Table 4 includes the number of basic blocks recorded in
each trace (“# BBs” column) and size in megabytes (“Size
(MB)” column). Traces range from 53,000 basic blocks to
over 78,000,000. Sizes are from 600 KB to 56 MB. The larger
sizes correlate with programs containing GUIs and complex
plug-in frameworks.
which is obviously not possible with existing techniques.
10We could not ﬁnd larger programs in the Debian repositories that trigger
CVE-2007-2645 or CVE-2018-18957.
USENIX Association
30th USENIX Security Symposium    1997
CVE / EDB
CVE-2004-0597
CVE-2004-1279
CVE-2004-1288
CVE-2009-2629
CVE-2009-3896
CVE-2017-9167
CVE-2018-12326
EDB-15705
CVE-2004-1257
CVE-2009-5018
CVE-2017-7938
CVE-2018-12327
CVE-2018-18957
CVE-2019-14267
* EDB-47254
EDB-46807
CVE-2006-2025
CVE-2007-2645
CVE-2013-2028
CVE-2017-7529
CVE-2017-9186
CVE-2017-9196
* CVE-2019-19004
CVE-2017-11403
CVE-2017-14103
CVE-2017-9182
* CVE-2019-17582
CVE-2017-12858
* CVE-2019-19005
CVE-2005-0105
CVE-2012-0809
Program
GIMP (libpng)
jpegtoavi
o3read
nginx
nginx
autotrace
Redis
ftp
abc2mtex
gif2png
dmitry
ntpq
GOOSE (libiec61850)
pdfresurrect
abc2mtex
MiniFtp
GIMP (libtiff)
exif (libexif)
nginx
nginx
autotrace
autotrace
autotrace
GraphicsMagick
GraphicsMagick
autotrace
PHP (libzip)
PHP (libzip)
autotrace
typespeed
sudo
Average:
* New vulnerability discovered by ARCUS.
Type
Heap
Heap
Heap
Heap
Heap
Heap
Heap
Heap
Stack
Stack
Stack
Stack