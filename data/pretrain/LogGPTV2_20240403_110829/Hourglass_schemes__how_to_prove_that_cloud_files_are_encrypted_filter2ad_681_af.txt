[23] D. Perito and G. Tsudik. Secure code update for embedded
devices via proofs of secure erasure. In ESORICS, pages
643–662, 2010.
[24] R. Rivest. All-or-nothing encryption and the package
transform. In Fast Software Encryption, pages 210–218,
1997.
[25] R. L. Rivest, A. Shamir, and D. A. Wagner. Time-lock
puzzles and timed-release crypto. Technical report, 1996.
[26] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and
P. Khosla. Pioneer: Verifying code integrity and enforcing
untampered code execution on legacy systems. In SOSP,
pages 1–16, 2005.
[27] H. Shacham and B. Waters. Compact proofs of
retrievability. In ASIACRYPT, pages 90–107, 2008.
[28] R. Sion. Query execution assurance for outsourced
databases. In VLDB, pages 601–612, 2005.
APPENDIX
A. ENCODINGS
We now elaborate on Phase 1 of our generic hourglass pro-
tocol that we presented in Section 3. We give more details
on how the server generates an encoded version of F , as well
as a proof of correct encoding. In both the case of encryp-
tion and watermarking encoding, the provider must encode
ﬁle F into G using a secret unknown to the veriﬁer, i.e., the
client. In the case of encryption, the secret is the key κ. For
watermarking, the secret consists of multiple digital signa-
tures produced by the server that attest to the provenance
of the ﬁle; the signatures, if divulged, can be used to frame
the provider. Thus proving that G is correctly encoded cre-
ates a diﬃculty: The cloud provider has provided the veriﬁer
(client) with the encoded ﬁle G and must prove to the veriﬁer
that G is correctly computed from F , but without revealing
the secret used to produce encoding G.
Encryption encoding. For the case of encryption, the idea
is as follows. The prover encodes F under a pseudorandom
permutation (PRP), and partitions the ﬁle into n blocks. It
uses master key κ to derive a set of keys {κi}n
i=1, encrypting
the ith block of the ﬁle under κi. To verify that G is cor-
rectly formatted, the veriﬁer challenges the prover to reveal
a subset of the keys for randomly chosen blocks. The PRP
ensures that revealing a subset of the shares does not reveal
κ and therefore doesn’t permit decryption of the full ﬁle.
Figure 5 (left) speciﬁes our protocol for a server to prove
to a client that G represents a correct encryption of F . Here,
P RPκ(cid:48) denotes a keyed PRP, and Eκi,κ∗ denotes encryption
under keys κi and κ∗ (the two keys could be hashed together,
for instance, to obtain the ﬁle block encryption key). Also,
KD(κ, i) denotes an indexed key-derivation function that
takes master key κ as input. The number q of challenged
blocks can be adjusted to obtain a desired conﬁdence prob-
ability that ﬁle blocks are correctly encrypted.
The client supplies some randomness (in the form of a key
κ∗) that is used in combination with the secret key gener-
ated by the server for generating ﬁle block encryption keys.
The randomness provided by the client serves the goal of
enforcing that ﬁle block encryption keys are generated with
proper randomness.
As with any cryptographic scheme, it is important that the
server protect the encryption key κ. There are various well-
studied techniques for ensuring that the key is kept secret
such as using hardware security modules, trusted hardware,
or secure co-processors.
Watermark encoding. Figure 5 (right) speciﬁes our pro-
tocol for a server to prove to a client that G represents the
application of an hourglass function to F under a correct
incorporation of a provenance tag π. We let σ(M ) denote a
digital signature by the server on message M .
The main idea is to divide the ﬁle into n blocks and em-
bed a signature σi with each block Fi so that no block Fi
can be retrieved without revealing the signature embedded
with Fi. This property is achieved by applying an AONT
transformation [24] to each ﬁle block and the corresponding
signature. Block Gi of encoded ﬁle G is then computed as
AoNT[σi, Fi], where σi is a signature by the server on the
ﬁle handler handler and block index i.
The provenance tag π consists of the ﬁle handler and
hashes on signatures σi and is published by the server. A
proof of leakage by an external entity consists of a number
v of correct signatures, i.e., v signatures corresponding to
hashed signatures in π. The value v is a security parameter
such that q < v ≤ n.
The challenge procedure is exactly like that for ﬁle en-
cryption. The client challenges q randomly selected segments
278Client / Veriﬁer
Server / Prover
Input: ﬁle F = F1 . . . Fn
κ∗ R← {0, 1}l
{κ∗
i = KD(κ∗, i)}n
i=1
{zi
F (cid:48)
1 . . . F (cid:48)
{Gzi
R← {1, 2, . . . , n}}q
n ← P RPκ(cid:48) (F )
]}q
?= Eκzi
[F (cid:48)
zi
,κ∗
i
i=1
i=1
F,κ∗−→
κ(cid:48) ,G←−
{zi}q
i=1−→
{κzi
}q
i=1←−
n ← P RPκ(cid:48) (F )
κ R← {0, 1}l
κ(cid:48) R← {0, 1}l
1 . . . F (cid:48)
F (cid:48)
{κi = KD(κ, i)}n
i = KD(κ∗, i)}n
{κ∗
G = {Eκi ,κ∗
i ]}n
[F (cid:48)
i=1
i
i=1
i=1
Client / Veriﬁer
Input: ﬁle F = F1 . . . Fn
F−→
R← {1, 2, . . . , n}}q
{zi
{h(σzi ) ?= hzi}q
{Gzi
?= AoNT[σzi , Fzi ]}q
i=1
i=1
i=1
π,G←−
{zi}q
i=1−→
}q
←−
,σzi
i=1
{Gzi
Server / Prover
{σi = σ(handler||i)}n
{hi = h(σi)}n
π = (handler, {hi}n
i=1)
G = {AoNT[σi, Fi]}n
i=1
i=1
i=1
Figure 5: Proof of correct encodings: The cases of ﬁle encryption (left) and watermarking encoding (right).
of the ﬁle, and the server replies with the corresponding
signatures. The client veriﬁes that the AoNT encoding is
performed correctly on the challenged segments and that
signature hashes match those published in the provenance
tag. Using large sized blocks reduces the additional storage
expansion for signatures. At the same time, a large block
size reduces the challenge space and incurs overhead in the
challenge procedure of Phase 1, as large ﬁle blocks have to
be retrieved to check signature correctness. Thus, we have
to achieve a balance among diﬀerent metrics of interest. A
good choice is a block size of O((cid:112)|F|) bits, resulting in
n = O((cid:112)|F|) blocks.
File binding encoding. In some scenarios, it might be
useful to verify that multiple ﬁles are stored together (i.e.,
that they have been bound together). This feature can be
useful if, for example, we want to verify that source code
is stored together with its corresponding license. The pro-
tocol for ﬁle binding can very easily be constructed from
watermarking. A pair of ﬁles, F1 and F2 are bound together
or encoded via application of AoNT. Subsequent application
of an hourglass function, setup, and the challenge-response
protocol are then similar to the watermarking encoding pro-
tocol. This can easily be generalized to any number of ﬁles.
B. FORMAL SECURITY DEFINITION
We assume that the server is controlled by an adversary
A who has resources polynomially bounded in l. We let s de-
note an upper bound on the size of A’s storage (expressed in
bits). Both s and the ﬁle size n are polynomial in l. Also, A
is stateless, in the sense that distinct adversarial algorithms
(e.g., A(Store) and A(ChalRes)) cannot intercommunicate.
(The two algorithms represent the state of cloud at diﬀer-
ent times, so the only channel between them is the stored
value H.)
General security deﬁnition. Figure 6 presents the ex-
periment ExpHGA [l, n, s, δ] that characterizes the security of
general hourglass schemes. We deﬁne succHGA [l, n, s, δ] (cid:44)
Pr[ExpHGA [l, n, s, δ] = 1].
We found that coming up with the right deﬁnition for
an hourglass system (one of the paper’s technical contribu-
tion) is quite subtle. The adversary’s objective is to leak F ,
i.e., to store a ﬁle representation from which F can be re-
covered without decoding/decryption. We model the adver-
sary’s goal, however, as leakage of a random string ρ embed-
ded in F . We can think of ρ as the underlying entopy of F or
a maximally compressed version of F . If F is compressible,
Security experiment ExpHGA [l, n, s, δ]:
Initialize:
ρ R← {0, 1}δs
F ∈ Bn ← A(FileGen, ρ)
κ1 ← keygen-enc(l)
(κ2, κ3) ← keygen-hg(l)
G ∈ Ln ← encode(κ1, F )
H ∈ Dn ← hourglass(κ2, κ3, G)
Generate Storage:
H(cid:48) ∈ {0, 1}s ← Aencode(κ1 ,·),decode(κ1,·)(Store, ρ, F, G, H, κ2)
Recover Raw Data:
ρ(cid:48) ← A(RecRaw, H(cid:48), κ2)
Challenge-Response:
c R← challenge
r ← Astorage(H(cid:48),·),encode(κ1,·),decode(κ1,·)(ChalRes, c, κ2)
Finalize:
return (ρ(cid:48) ?= ρ) AND (verify(H, c, r) ?= 1)
Figure 6: General hourglass security experiment.
then it is easier for the adversary to recover ρ than to recover
the longer representation F directly. In our experiment, the
adversary may encode ρ in F arbitrarily.
In an honest execution of the protocol, a server will store
a ﬁle encoding H that has two properties: (1) By accessing
stored data format H, the server can respond correctly to
client challenges with overwhelming probability; and (2) H
is a function of G and, in this sense, prevents disclosure of
ρ unless decode is called.
In contrast, the goal of the adversary A is to construct
some H(cid:48) for storage with a diﬀerent pair of properties, namely:
(1) By accessing stored data H(cid:48), the adversary can respond
correctly, with high probability, to client challenges; and (2)
The adversary can extract ρ from H(cid:48) without calling decode.
In other words, A would like to appear to store a valid ﬁle
encoding H that does not contain raw data, but actually
store a ﬁle encoding H(cid:48) that leaks raw data.
In the experiment above, we model storage as an ora-
cle storage(H(cid:48),·) that reﬂects resource bounds on access to
stored ﬁle H(cid:48) ∈ Ls/l of size s bits. Oracle storage(H(cid:48),·) takes
an index i as input, and outputs either the i-th block of H(cid:48),
or ⊥ if the modeled resource bound has been exceeded.
On modeling leakage. In our experiment A aims to re-
cover ρ from H(cid:48) (while correctly answering challenges). Our
experiment requires that A(RecRaw,·) do so without access to
decode(κ1,·). The decode oracle models the underlying cryp-
tographic access-control mechanism. For instance, in prac-
tice, decode might correspond to a module based on trusted
279hardware that decrypts ciphertext data. Denying adversary
A(RecRaw,·) access to decode models the presumption that
an attacker can’t breach the trusted hardware module. (For
technical reasons, it also doesn’t have access to encode(κ1,·).)
Compression assumption. We assume that the output of
the encode function G on input raw ﬁle F ∈ Bn is uniformly
distributed in domain Ln. G is thus a string independent
of plaintext ﬁle F that can not be further compressed by
the adversary. This assumption is necessary in our security
analysis in order to provide meaningful lower bounds on the
amount of extra storage incurred by a cheating server.
We brieﬂy justify the compression assumption for our three
encodings of interest detailed in Appendix A. For the encryp-
tion encoding, we can model the (encode, decode) operations
as an ideal cipher. In this case, the ciphertext G resulting
after encrypting plaintext ﬁle F is uniformly distributed and
independent on the plaintext. For the watermark encoding,
the all-or-nothing transformation AoNT can be modeled as
a random oracle, resulting again in uniformly distributed
output G. File binding encoding is a simple extension of
watermark encoding and as such the same random oracle
modeling of the AoNT transform can be used to justify the
compression assumption.
Partitioning assumption. We make a simplifying techni-
cal assumption on A throughout our security proofs (which
are omitted for lack of space). This partitioning assumption
G|.
, H(cid:48)
F , κ2) → ρ.
F
• H(cid:48)
F and H(cid:48)
F , i.e., there is an algorithm
requires that A(Store,·) output H(cid:48) of the form H(cid:48) = (H(cid:48)
F (cid:107)
H(cid:48)
G), where H(cid:48)
G are distinct substrings as follows:
• H(cid:48)
F is a raw representation of F . In other words, A can
recover ρ from H(cid:48)
A(RecRawH(cid:48)
G is “extra” storage used by A to help it respond to
challenges. We can think of H(cid:48)
G as the storage overhead
imposed on A in order to cheat and answer challenges
correctly while it is leaking F . We assume that A com-
putes H(cid:48)
G over G and H, without knowledge of F . (But
A is allowed to use all of H(cid:48) to respond to challenges.)
The partitioning assumption renders security analysis of
our concrete hourglass constructions simpler. We conjecture,
however, that the assumption doesn’t in fact result in a
weaker class of adversary.8 It seems implausible that mixing
together H(cid:48)
G into a combined representation would
advantage A. After all, G is uniformly distributed in domain
Ln and therefore an independent string in the view of A. We
leave this conjecture on the partitioning assumption as an
open problem. In our security analysis, we use s(cid:48) to denote
|H(cid:48)
8In particular, our conjecture applies to hourglass schemes
that are valid, as deﬁned in Section 2.2. Clearly, for a degen-
erate scheme with challenges constructed over F , A would
beneﬁt from computing H(cid:48)
F and H(cid:48)
G as a function of F .
280