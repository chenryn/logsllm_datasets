# Table 4: Location-Shift Estimates for MWU Test Results

| Adversary | Capability | Control vs. Long (Survey) | Control vs. Experimental (App) |
|-----------|------------|---------------------------|-------------------------------|
| ISP       | S          | 0.00                      | -0.67* 0.00                    |
|           | A          | 0.00* 0.00                | 0.00 1.00                      |
| Server Hacker | S      | 0.00                      | 0.00                          |
|           | A          | 0.00                      | n/a                           |
| Government | S        | A                         | -1.00* -0.33                  |
|           | A          | 0.00                      | 0.00 n/a                      |
| Unlocked   | A          | S                         | 0.00 0.00                     |
|           | S          | 0.00 0.00                 | n/a 0.00                      |
| Malware    | A          | S                         | 0.67* 0.00                    |
|           | S          | 0.00 0.00                 | n/a                           |

* indicates a statistically significant result (p < 0.05).

## Analysis of Adversary Capabilities in Table 4

The left column for each adversary-capability compares the Control to Long conditions in the survey study, while the right column compares the Control to Experimental conditions in the app study. The results suggest that some adversaries, such as the government and server hacker, have negative effects (in the correct direction) in the app study. Although this is encouraging, it is not clear if these are real effects or just noise, given the small sample size. Further research would be needed to validate these trends.

### Ceiling Effects in Survey and App Studies

Similar to the survey study, we observe ceiling effects with non-end-to-end (e2e) encryption and metadata capabilities for most adversaries. This suggests that participants may already have a high level of understanding or skepticism about these features.

## Definitions of End-to-End Encryption

We asked interview participants to define e2e encryption. The most common response (n=8) was that only the sender and intended recipient could view the message content. For example, P13 stated, "A message that you send out is encrypted and the only person who can unencrypt it to read it would be the receiver of the message." Other definitions (n=5) emphasized who could not view, alter, or intercept the message. Three participants used the key-lock metaphor, and three mentioned the metadata weakness. Only two participants were unsure about the meaning of e2e encryption.

## Recognition of Protection from Non-Endpoint Threats

When asked to explain what e2e encryption protects against, about half of the participants (n=10) generally described it as effective against non-endpoint adversaries. For instance, P23 said, "Probably anyone who would interrupt or interfere in between the messaging, in between where you sent it and someone else received it."

Participants frequently mentioned protection from adversaries highlighted in the educational messages and/or the communications privacy questionnaire. Four mentioned a server hacker, four mentioned the ISP, and three mentioned the government. Additionally, three mentioned ambiguous adversaries like "hackers," and three incorrectly suggested e2e encryption would protect against malware.

## Understanding of e2e Encryption Weaknesses

When asked what e2e encryption does not protect against, participants again referenced adversaries from the educational messages and questionnaires. Most mentioned an unlocked phone (n=14). In both studies, participants largely had a correct mental model for this before our intervention. A few participants mentioned the government (n=4), an app company employee (n=2), or a server hacker (n=1). Three specifically noted that e2e encryption could not protect against all "hackers." In total, nine of 19 participants gave answers that at least partially contradicted the principles we attempted to convey in the educational messages. For example, P11 said, "The company essentially has access to it. They don’t necessarily look at it, but if the proper legal methods are observed, there is a chance that someone else might be able to see it, for instance, the government."

## Discussion

### Effectiveness of Educational Messages

Our educational messages were effective in isolation, but when embedded into app workflows, they did not show statistically significant effects. This is likely due to participants noticing the messages but ignoring their contents, possibly out of habituation to informational messages. The difference may also reflect short-term recall in the survey study compared to longer-term recall in the app study. This suggests that messages like ours may need to be more intrusive to be useful.

### Success in the Survey Study

In the survey study, our educational interventions worked reasonably well, with minimal unintended consequences. Participants easily grasped core principles related to confidentiality, and to some extent, gained understanding about metadata weaknesses. However, in the app study, we found evidence that our intervention may have oversold the capabilities of e2e encryption with respect to metadata. Many participants already possessed strong mental models regarding the risks of non-e2e encryption and physical access at endpoints. These findings reflect somewhat more knowledge than observed in prior work, which may be due to differences in study populations or increased user exposure to e2e encrypted apps over time.

### Need for More Intrusive Interventions

Unfortunately, we were unable to replicate the successes of the survey study in a more realistic in-workflow context. We attribute this to the messages failing to attract sufficient user attention. However, quantitative and qualitative results suggest that participants did not find our interventions intrusive or unusable. Thus, there may be room to make such interventions more noticeable without causing significant user annoyance. Future work should explore whether changes like making the messages bigger, bolder, or using graphics can achieve better results without harming usability.

### Experimental Setup Discrepancies

The discrepancy between the two studies could also be attributed to the differing experimental setups. The survey study involved one intervention with questions less than 10 minutes later, while the app study involved 20 days of participation with interventions every 1-2 days. This suggests that we measured short-term recall in the survey study and longer-term impact on mental models in the app study. Additional controlled experiments are needed to determine the lasting impact of our survey study on mental models.

### Other Kinds of Interventions

Our results underscore that in-workflow messages are only one way to influence mental models of secure communication. As in our prior work, when participants were focused on our educational content, they did learn functional information. While it is not realistic to expect most users to seek out training on secure communication, well-designed educational materials should be available to those who do. Organizations like the Electronic Frontier Foundation (EFF) and the Library Freedom Project have developed such materials, and future work should evaluate their effectiveness and potential improvements.

Additionally, there is increasing emphasis on teaching everyday privacy and security concepts in elementary and secondary schools. Including functional models of secure communication in these curricula could help students make appropriate choices about their communication mechanisms in an increasingly networked world.

## Conclusion

In this work, we created educational messages to improve functional mental models of e2e encryption and evaluated them in both a controlled and a more realistic setting. We find that conveying functional mental models of e2e encryption is possible in isolation, but in-app nudging may require more intrusiveness to be effective. More experiments are needed to further validate these findings.

## Acknowledgements

We thank our participants. This material is based upon work supported by the United States Air Force and DARPA under Contract No FA8750-16-C-0022. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the United States Air Force and DARPA.

## References

[1] WhatsApp hack: Is any app or computer truly secure? BBC, 2019.
[2] Ruba Abu-Salma, Elissa M Redmiles, Blase Ur, and Miranda Wei. Exploring User Mental Models of End-to-End Encrypted Communication Tools. In FOCI, 2018.
[3] Ruba Abu-Salma, M Angela Sasse, Joseph Bonneau, Anastasia Danilova, Alena Naiakshina, and Matthew Smith. Obstacles to the adoption of secure communication tools. In IEEE S&P, 2017.
[4] Alessandro Acquisti, Idris Adjerid, Rebecca Balebako, Laura Brandimarte, Lorrie Faith Cranor, Saranga Komanduri, Pedro Giovanni Leon, Norman Sadeh, Florian Schaub, Manya Sleeper, Yang Wang, and Shomir Wilson. Nudges for Privacy and Security: Understanding and Assisting Users’ Choices Online. ACM Comput. Surv., 50(3), August 2017.
[5] Hazim Almuhimedi, Florian Schaub, Norman Sadeh, Idris Adjerid, Alessandro Acquisti, Joshua Gluck, Lorrie Faith Cranor, and Yuvraj Agarwal. Your Location Has Been Shared 5,398 Times! A Field Study on Mobile App Privacy Nudging. In CHI, 2015.
[6] Apple Inc. Privacy - Approach to Privacy. (Last accessed on Sep. 2019).
[7] Farzaneh Asgharpour, Debin Liu, and L. Jean Camp. Mental Models of Security Risks. In USEC, 2007.
[8] Wei Bai, Moses Namara, Yichen Qian, Patrick Gage Kelley, Michelle L Mazurek, and Doowon Kim. An Inconvenient Trust: User Attitudes Toward Security and Usability Tradeoffs for Key-Directory Encryption Systems. In SOUPS, 2016.
[9] Wei Bai, Michael Pearson, Patrick Gage Kelley, and Michelle L Mazurek. Improving Non-Experts’ Understanding of End-to-End Encryption: An Exploratory Study. In EuroUSEC, 2020.
[10] James Ball. NSA collects millions of text messages daily in 'untargeted' global sweep. The Guardian, 2014.
[11] John Brooke. SUS: a Quick and Dirty Usability Scale. In Usability Evaluation in Industry. CRC press, 1996.
[12] José Carlos Brustoloni and Ricardo Villamarín-Salomón. Improving Security Decisions with Polymorphic and Audited Dialogs. In SOUPS, 2007.
[13] L. J. Camp. Mental Models of Privacy and Security. IEEE Technology and Society Magazine, 28(3):37–46, Fall 2009.
[14] John L Campbell, Charles Quincy, Jordan Osserman, and Ove K Pedersen. Coding In-Depth Semistructured Interviews: Problems of Unitization and Intercoder Reliability and Agreement. Sociological Methods & Research, 42(3):294–320, 2013.
[15] Jacob Cohen. A power primer. Psychological bulletin, 112(1):155, 1992.
[16] Joseph Cox. China Is Forcing Tourists to Install Text-Stealing Malware at its Border. Vice, 2019.
[17] S. Dechand, A. Naiakshina, A. Danilova, and M. Smith. In Encryption We Don’t Trust: The Effect of End-to-End Encryption to the Masses on User Perception. In EuroS&P, 2019.
[18] A Demjaha, JM Spring, I. Becker, S Parkin, and MA Sasse. Metaphors Considered Harmful? An Exploratory Study of the Effectiveness of Functional Metaphors for End-to-End Encryption. In USEC, 2018.
[19] Andrea A. diSessa. Models of Computation. In Donald A. Norman and Stephen W. Draper, editors, User Centered System Design: New Perspectives on Human-Computer Interaction, pages 201–218. Lawrence Erlbaum Associates, 1986.
[20] Electronic Frontier Foundation. Communicating with others. https://ssd.eff.org/en/module/communicating-others.
[21] Antonio M. Espinoza, William J. Tolley, Jedidiah R. Crandall, Masashi Crete-Nishihata, and Andrew Hilts. Alice and Bob, Who the FOCI Are They?: Analysis of End-to-End Encryption in the LINE Messaging Application. In FOCI, 2017.
[22] Facebook. Secret conversations. https://www.facebook.com/help/messenger-app/1084673321594605.
[23] Facebook. WhatsApp security. https://www.whatsapp.com/security/.
[24] Sascha Fahl, Marian Harbach, Thomas Muders, Matthew Smith, and Uwe Sander. Helping Johnny 2.0 to Encrypt His Facebook Conversations. In SOUPS, 2012.
[25] Simson L. Garfinkel and Robert C. Miller. Johnny 2: A User Test of Key Continuity Management with S/MIME and Outlook Express. In SOUPS, 2005.
[26] Shirley Gaw, Edward W. Felten, and Patricia Fernandez-Kelly. Secrecy, Flagging, and Paranoia: Adoption Criteria in Encrypted Email. In CHI, 2006.
[27] Nina Gerber, Verena Zimmermann, Birgit Henhapl, Sinem Emeröz, and Melanie Volkamer. Finally Johnny Can Encrypt: But Does This Make Him Feel More Secure? In ARES, 2018.
[28] Joseph A Gliem and Rosemary R Gliem. Calculating, Interpreting, and Reporting Cronbach’s Alpha Reliability Coefficient for Likert-Type Scales. Midwest Research-to-Practice Conference in Adult, Continuing, and Community Education, 2003.
[29] Eszter Hargittai and Yuli Patrick Hsieh. Succinct Survey Measures of Web-Use Skills. Social Science Computer Review, 30(1):95–107, 2012.
[30] Kashmir Hill. 'God View': Uber allegedly stalked users for party-goers' viewing pleasure. Forbes, 2014.
[31] Myles Hollander, Douglas A Wolfe, and Eric Chicken. Non-parametric Statistical Methods, volume 751. John Wiley & Sons, 2013.
[32] Sture Holm. A Simple Sequentially Rejective Multiple Test Procedure. Scandinavian Journal of Statistics, pages 65–70, 1979.
[33] Patrick Gage Kelley, Sunny Consolvo, Lorrie Faith Cranor, Jaeyeon Jung, Norman Sadeh, and David Wetherall. A conundrum of permissions: installing applications on an Android smartphone. In Financial Crypto, 2012.
[34] Klaus Krippendorff. Reliability in Content Analysis: Some Common Misconceptions and Recommendations. Human communication research, 30(3):411–433, 2004.
[35] Priya C. Kumar, Marshini Chetty, Tamara L. Clegg, and Jessica Vitak. Privacy and Security Considerations For Digital Technology Use in Elementary Schools. In CHI, 2019.
[36] Alexander De Luca, Sauvik Das, Martin Ortlieb, Iulia Ion, and Ben Laurie. Expert and Non-Expert Attitudes towards (Secure) Instant Messaging. In SOUPS, 2016.
[37] Hiroaki Masaki, Kengo Shibata, Shui Hoshino, Takahiro Ishihama, Nagayuki Saito, and Koji Yatani. Exploring Nudge Designs to Help Adolescent SNS Users Avoid Privacy and Safety Threats. In CHI, 2020.
[38] Arunesh Mathur, Josefien Engel, Sonam Sobti, Victoria Chang, and Marshini Chetty. "They Keep Coming Back Like Zombies": Improving Software Updating Interfaces. In SOUPS, 2016.
[39] Nora McDonald, Sarita Schoenebeck, and Andrea Forte. Reliability and Inter-Rater Reliability in Qualitative Research: Norms and Guidelines for CSCW and HCI practice. Proceedings of the ACM on Human-Computer Interaction, 3(CSCW):1–23, 2019.
[40] Alena Naiakshina, Anastasia Danilova, Sergej Dechand, Kat Krol, M Angela Sasse, and Matthew Smith. Poster: Mental Models-User Understanding of Messaging and Encryption. In EuroUSEC, 2016.
[41] Eyal Peer, Serge Egelman, Marian Harbach, Nathan Malkin, Arunesh Mathur, and Alisa Frik. Nudge Me Right: Personalizing Online Security Nudges to People’s Decision-Making Styles. Computers in Human Behavior, 109:106347, 2020.
[42] Library Freedom Project. Library freedom resources. https://libraryfreedom.org/index.php/resources/.
[43] Rakuten.