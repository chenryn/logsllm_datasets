4,729 (1.0%)
2,776 (-0.4%)
2,600 (0.4%)
Table 6: User space (AArch64) performance evaluation results with multiple
android benchmarks. The scores are the higher the better.
on the latency and bandwidth of the server program—Apache web
server. The ApacheBench ran in the laptop connected to our desk-
top machine with an one Gigabit cable. We used Apache with its
default configurations. We first used a 1KB file to evaluate the
latency when the concurrency (i.e., simultaneous connections) was
set to be 1, 50, 100, 150, 200, and 250. Then we used files with
different sizes (100B, 1KB, 10KB, 100KB, and 1MB) to measure
the bandwidth (i.e., throughput) of the web server. In the bandwidth
evaluation, the concurrency was set to be 32; the network I/O was
not saturated except when the file size was 1MB. The request for
each experiment was repeated 10,000 times. The evaluation results
show that the blind mode incurs an average slowdown of 0.7% in
the concurrency experiment and 0.9% in the bandwidth experiment.
In contrast, UniSan imposes an unobservable slowdown (10x) is too
high for them to be adopted as prevention tools.
Differently, MemorySanitizer [39] relies on compile time instru-
mentation and shadow memory to detect uninitialized data use at
run-time. Its performance is much better than dynamic instrumen-
tation based tools; however, it still imposes a 3-4x performance
overhead. Usher [44] proposes value-flow analysis to reduce the
number of tracked allocations to reduce the performance overhead
of MemorySanitizer to 2-2.5x.
Memory safety and model checking. Many memory safety tech-
niques [26–28, 35] have been proposed to prevent spacial memory
errors (e.g., out-of-bound read) and use-after-free bugs, and model
checking techniques [3, 25] can detect semantic errors caused by
developers. These tools are effective to detect or prevent kernel
leaks caused by spacial memory errors, use-after-free, or semantic
errors, and thus are orthogonal to UniSan. DieHard [4] probabilis-
tically detects uninitialized memory uses for heap but not stack.
Cling [2] constrains memory allocation to allow address space reuse
only among objects of the same type, which can mitigate exploits
of temporal memory errors (e.g., use-after-free and uninitialized
uses). StackArmor [7] is a sophisticated stack protection that also
prevents uninitialized reads in binaries. Since StackArmor uses
stack layout randomization to prevent inter-procedural uninitialized
reads, such a protection is probabilistic. Type systems [12, 15]
can prevent dangling pointer and uninitialized pointer dereferences,
and out-of-bound accesses; however uninitialized data leaks are not
covered.
Protections using zero-initialization. Zero-initialization has been
leveraged to achieve protections in previous works. Secure deal-
location [8] zero-initializes the deallocated memory to reduce the
lifetime of data, thus reducing the risk of data exposure. Lacuna [13]
allows users to run programs in “private sessions”. After a session
is over, all memory of its execution is erased. In general, zeroing-
upon-deallocation has two issues: 1) deallocations are not always
available (e.g., deallocation is missing in the case of memory leak);
2) it is hard to selectively zero deallocations for efficiency, as dis-
cussed in §3.2. StackArmor [7] only zero-initializes intra-procedural
allocations (i.e., not be passed to other functions) that cannot be
proven to be secure against uninitialized reads.
8. DISCUSSION AND FUTURE WORK
Custom heap allocator.
In the current implementation, UniSan
only tracks typical heap allocators (kmalloc and kmen_cache_alloc).
To handle custom heap allocations (e.g., alloc_skb), UniSan can
use the specifications of allocators provided by developers.
In
fact, for user space programs, LLVM already provides an API
isMallocLikeFn to test whether a value is a call to a function that
allocates uninitialized memory based on heuristics. We plan to also
use heuristics to infer “malloc-like” functions in the kernel.
Source code requirement. Source code is required. In case that
some kernel drivers are close-sourced, we have to carefully identify
all possible calls that target these drivers and assume all such calls as
sinks. Failures in identifying such calls will result in incompleteness
of call-graph and thus false negatives.
Security impacts of zero-initialization. Some systems use unini-
tialized memory as the source of randomness. For example, the
SSLeay implementation of OpenSSL uses uninitialized buffer as en-
tropy source to generate random number (see ssleay_rand_bytes()).
Zero-initialization will clearly reduce the entropy of such a source
of randomness; however, we argue that using such a source of ran-
domness is insecure and should be avoided—reading uninitialized
data is classified as memory error.
False positives. In many cases, UniSan eliminates false negatives
by sacrificing accuracy (i.e., increasing the false positive rate). There
is still room to reduce the false positives. For example, point-to
analysis [16] can help find indirect call targets, and dynamic taint
analysis [34] can help handle cases like inline assembly.
Considering that false positives do not affect program semantics
but just introduce more performance overhead and that UniSan is
already efficient, we leave these optimizations for future work.
More kernel modules.
In our experiments, we included only
modules enabled by the default kernel configurations. Since the
current Linux kernel has around 20,000 modules total, a majority
of them have not been included in our evaluation. Unfortunately,
due to some GCC-specific features, some modules are still not
compilable by LLVM and require extra engineering effort to patch.
Since UniSan is a proof-of-concept research project, we believe
supporting these additional modules is out-of-scope. We may be
able to rely on the open source community to provide the required
patches (e.g., the LLVMLinux project [23]) or port UniSan to GCC.
Beyond kernels. UniSan’s detection and instrumentation work on
the LLVM IR level, and thus it can be naturally extended to protect
user space programs. Specifically, to support user space program,
IR of libraries should also be included, and sources (for heap) and
sinks should be re-defined. As a future work, we will use UniSan
to detect and prevent information leaks in security- and privacy-
sensitive programs (e.g., OpenSSL).
9. CONCLUSION
Information leaks in kernel pose a major security threat because
they render security protection mechanisms (e.g., kASLR and Stack-
Guard) ineffective and leak security-sensitive data (e.g., crypto-
graphic keys and file caches). In particular, uninitialized data read is
the most critical vulnerability because it is the cause of most infor-
mation leaks in kernel. Furthermore, none of the existing defenses
can completely and efficiently prevent uninitialized data leaks.
The key idea behind UniSan is to use byte-level, flow-sensitive,
and context-sensitive reachability analysis and initialization analysis
to identify any allocation that leaves kernel space without having
been fully initialized, and to automatically instrument the kernel
to initialize this allocation. UniSan has no false negatives. That is,
it prevents all possible uninitialized data leaks in kernel. We have
applied UniSan to the latest Linux kernel and Android kernel and
found that UniSan can successfully prevent 43 known uninitialized
data leaks, as well as many new ones. In particular, 19 of the new
data leak vulnerabilities in the latest kernels have been confirmed
by the Linux community and Google. Extensive evaluation has
also shown that UniSan is robust and imposes only a negligible
performance overhead.
10. ACKNOWLEDGMENT
We thank Byoungyoung Lee, Herbert Bos, Anil Kurmus and the
anonymous reviewers for their valuable feedback, as well as our
operations staff for their proofreading efforts. This research was
supported in part by the NSF award CNS-1017265, CNS-0831300,
CNS-1149051, CNS-1563848 and DGE-1500084, by the ONR
under grant N000140911042 and N000141512162, by the DHS
under contract N66001-12-C-0133, by the United States Air Force
under contract FA8650-10-C-7025, by the DARPA Transparent
Computing program under contract DARPA-15-15-TC-FP-006, by
the ETRI MSIP/IITP[B0101-15-0644]. Any opinions, findings,
conclusions or recommendations expressed in this material are those
of the authors and do not necessarily reflect the views of the NSF,
ONR, DHS, United States Air Force, DARPA or MSIP.
References
[1] LLVM Classes Definition, 2016. http://llvm.org/docs/doxygen/
html/annotated.html.
[2] P. Akritidis. Cling: A memory allocator to mitigate dangling
pointers. In Proceedings of the 19th USENIX Security Sympo-
sium (Security), Washington, DC, Aug. 2010.
[3] T. Ball, E. Bounimova, B. Cook, V. Levin, J. Lichtenberg,
C. McGarvey, B. Ondrusek, S. K. Rajamani, and A. Ustuner.
Thorough static analysis of device drivers. In Proceedings
of the 1st ACM SIGOPS/EuroSys European Conference on
Computer Systems 2006, EuroSys ’06, 2006.
[4] E. D. Berger and B. G. Zorn. Diehard: Probabilistic memory
safety for unsafe languages. In Proceedings of the 2006 ACM
SIGPLAN Conference on Programming Language Design and
Implementation (PLDI), Ottawa, Canada, June 2006.
[5] D. Bruening and Q. Zhao. Practical memory checking with dr.
memory. In Proceedings of the 2004 International Symposium
on Code Generation and Optimization (CGO), Washington,
DC, Mar. 2011.
[6] H. Chen, Y. Mao, X. Wang, D. Zhou, N. Zeldovich, and M. F.
Kaashoek. Linux kernel vulnerabilities: State-of-the-art de-
fenses and open problems. In Proceedings of the 2nd Asia-
Pacific Workshop on Systems (APSys), Shanghai, China, July
2011.
[7] X. Chen, A. Slowinska, D. Andriesse, H. Bos, and C. Giuffrida.
StackArmor: Comprehensive Protection from Stack-based
Memory Error Vulnerabilities for Binaries. In Proceedings
of the 2015 Annual Network and Distributed System Security
Symposium (NDSS), San Diego, CA, Feb. 2015.
[8] J. Chow, B. Pfaff, T. Garfinkel, and M. Rosenblum. Shredding
your garbage: Reducing data lifetime through secure deallo-
cation. In Proceedings of the 14th Conference on USENIX
Security Symposium, Berkeley, CA, USA, 2005.
[9] K. Cook. Kernel address space layout randomization, 2013.
http://outflux.net/slides/2013/lss/kaslr.pdf.
[10] C. Cowan, C. Pu, D. Maier, H. Hintony, J. Walpole, P. Bakke,
S. Beattie, A. Grier, P. Wagle, and Q. Zhang. Stackguard: Au-
tomatic adaptive detection and prevention of buffer-overflow
attacks. In Proceedings of the 7th USENIX Security Sympo-
sium (Security), San Antonio, TX, Jan. 1998.
[11] C. Details. Vulnerabilities By Type, 2016.
cvedetails.com/vulnerabilities-by-types.php.
http://www.
[12] D. Dhurjati, S. Kowshik, and V. Adve. Safecode: enforcing
alias analysis for weakly typed languages. In Proceedings of
the 2006 ACM SIGPLAN Conference on Programming Lan-
guage Design and Implementation (PLDI), Ottawa, Canada,
June 2006.
[13] A. M. Dunn, M. Z. Lee, S. Jana, S. Kim, M. Silberstein, Y. Xu,
V. Shmatikov, and E. Witchel. Eternal sunshine of the spotless
machine: Protecting privacy with ephemeral channels.
In
Proceedings of the 10th USENIX Symposium on Operating
Systems Design and Implementation (OSDI), Hollywood, CA,
Oct. 2012.
[14] J. Erickson, M. Musuvathi, S. Burckhardt, and K. Olynyk.
Effective data-race detection for the kernel. In Proceedings of
the 9th USENIX Symposium on Operating Systems Design and
Implementation (OSDI), Vancouver, Canada, Oct. 2010.
[15] D. Grossman, G. Morrisett, T. Jim, M. Hicks, Y. Wang, and
J. Cheney. Region-based memory management in cyclone.
In Proceedings of the 2002 ACM SIGPLAN Conference on
Programming Language Design and Implementation (PLDI),
Berlin, Germany, June 2002.
[16] B. Hardekopf and C. Lin. The ant and the grasshopper: Fast
and accurate pointer analysis for millions of lines of code.
In Proceedings of the 2007 ACM SIGPLAN Conference on
Programming Language Design and Implementation (PLDI),
San Diego, CA, June 2007.
[17] V. P. Kemerlis, G. Portokalidis, and A. D. Keromytis. kguard:
Lightweight kernel protection against return-to-user attacks.
In Proceedings of the 21st USENIX Security Symposium (Se-
curity), Bellevue, WA, Aug. 2012.
[18] V. P. Kemerlis, M. Polychronakis, and A. D. Keromytis.
Ret2dir: Rethinking kernel isolation. In Proceedings of the
23rd USENIX Security Symposium (Security), San Diego, CA,
Aug. 2014.
[19] M. Krause. CVE-2013-1825: various info leaks in Linux ker-
nel, 2013. http://www.openwall.com/lists/oss-security/2013/
03/07/2.
[20] A. Kurmus and R. Zippel. A tale of two kernels: Towards end-
ing kernel hardening wars with split kernel. In Proceedings of
the 21st ACM Conference on Computer and Communications
Security (CCS), Scottsdale, Arizona, Nov. 2014.
[21] LLVM. LLVM Alias Analysis Infrastructure, 2016. http:
//llvm.org/docs/AliasAnalysis.html.
[22] LLVM. The LLVM Compiler Infrastructure, 2016. http://llvm.
org/.
[23] LLVMLinux. The LLVMLinux Project, 2016. http://llvm.
linuxfoundation.org/index.php/Main_Page.
[24] L. W. McVoy and C. Staelin. Lmbench: Portable tools for per-
formance analysis. In USENIX Annual Technical Conference,
1996.
[25] C. Min, S. Kashyap, B. Lee, C. Song, and T. Kim. Cross-
checking semantic correctness: The case of finding file system
bugs. In Proceedings of the 25th ACM Symposium on Operat-
ing Systems Principles (SOSP), Monterey, CA, Oct. 2015.
[26] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic.
SoftBound: Highly compatible and complete spatial memory
In Proceedings of the 2009 ACM SIGPLAN
safety for C.
Conference on Programming Language Design and Implemen-
tation (PLDI), Dublin, Ireland, June 2009.
[27] S. Nagarakatte, J. Zhao, M. M. Martin, and S. Zdancewic.
CETS: compiler enforced temporal safety for C. In Interna-
tional Symposium on Memory Management, 2010.
[28] S. Nagarakatte, M. M. K. Martin, and S. Zdancewic. Watch-
doglite: Hardware-accelerated compiler-based pointer check-
ing. In Proceedings of the 2014 International Symposium on
Code Generation and Optimization (CGO), Orlando, FL, Feb.
2014.
[29] N. Nethercote and J. Seward. Valgrind: A Framework for
Heavyweight Dynamic Binary Instrumentation. In Proceed-
ings of the 2007 ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI), San Diego, CA,
June 2007.
[30] B. Niu and G. Tan. Modular control-flow integrity. In Proceed-
ings of the 35th ACM SIGPLAN Conference on Programming
Language Design and Implementation, 2014.
[31] V. Nossum. Getting Started With kmemcheck, 2015. https:
//www.kernel.org/doc/Documentation/kmemcheck.txt.
[32] S. Peiró, M. M. noz, M. Masmano, and A. Crespo. Detecting
stack based kernel information leaks. In International Joint
Conference SOCO’14-CISIS’14-ICEUTE’14, 2014.
[33] J. Rentzsch.
Data alignment:
Straighten up and
fly right – Align your data for speed and correct-
ness, 2005. https://www.ibm.com/developerworks/library/
pa-dalign/pa-dalign-pdf.pdf.
[34] E. J. Schwartz, T. Avgerinos, and D. Brumley. All you ever
wanted to know about dynamic taint analysis and forward
symbolic execution (but might have been afraid to ask). In
Proceedings of the 2010 IEEE Symposium on Security and
Privacy, SP ’10, 2010.
[35] K. Serebryany, D. Bruening, A. Potapenko, and D. Vyukov.
AddressSanitizer: A fast address sanity checker. In Proceed-
ings of the 2012 USENIX Annual Technical Conference (ATC),
Boston, MA, June 2012.
[36] J. Seward and N. Nethercote. Using Valgrind to detect unde-
fined value errors with bit-precision. In Proceedings of the
2004 USENIX Annual Technical Conference (ATC), Anaheim,
CA, June–July 2005.
[37] H. Shacham. The geometry of innocent flesh on the bone:
Return-into-libc without function calls (on the x86). In Pro-
ceedings of the 14th ACM Conference on Computer and Com-
munications Security (CCS), Alexandria, VA, Oct.–Nov. 2007.
[38] C. Song, B. Lee, K. Lu, W. R. Harris, T. Kim, and W. Lee.
Enforcing Kernel Security Invariants with Data Flow Integrity.
In Proceedings of the 2016 Annual Network and Distributed
System Security Symposium (NDSS), San Diego, CA, Feb.
2016.
[39] E. Stepanov and K. Serebryany. MemorySanitizer: fast de-
tector of uninitialized memory use in C++. In Proceedings of
the 2015 International Symposium on Code Generation and
Optimization (CGO), San Francisco, CA, Feb. 2015.
[40] P. Team. PaX - gcc plugins galore, 2013. https://pax.grsecurity.
net/docs/PaXTeam-H2HC13-PaX-gcc-plugins.pdf.
[41] C. Tice, T. Roeder, P. Collingbourne, S. Checkoway, Ú. Er-
lingsson, L. Lozano, and G. Pike. Enforcing forward-edge
control-flow integrity in gcc & llvm. In 23rd USENIX Security
Symposium, 2014.
[42] X. Wang, H. Chen, A. Cheung, Z. Jia, N. Zeldovich, and M. F.
Kaashoek. Undefined behavior: What happened to my code?
In Proceedings of the 3rd Asia-Pacific Workshop on Systems
(APSys), Seoul, South Korea, July 2012.
[43] X. Wang, H. Chen, Z. Jia, N. Zeldovich, and M. F. Kaashoek.
Improving Integer Security for Systems with KINT. In Pro-
ceedings of the 10th USENIX Symposium on Operating Sys-
tems Design and Implementation (OSDI), Hollywood, CA,
Oct. 2012.
[44] D. Ye, Y. Sui, and J. Xue. Accelerating dynamic detection of
uses of undefined values with static value-flow analysis. In
Proceedings of the 2014 International Symposium on Code
Generation and Optimization (CGO), Orlando, FL, Feb. 2014.