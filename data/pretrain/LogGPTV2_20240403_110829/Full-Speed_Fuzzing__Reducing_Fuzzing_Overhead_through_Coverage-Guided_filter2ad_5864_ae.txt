D. Timeouts
Coverage tracing is affected by pre-deÔ¨Åned execution time-
out values. Timeouts act as a ‚Äúhard limit‚Äù‚Äîterminating a
test case‚Äôs tracing if its duration exceeds the timeout‚Äôs value.
Though timeouts are necessary for halting inÔ¨Ånitely-looping
test cases, small timeouts prematurely terminate tracing. For
long-running test cases, this results in missed coverage in-
formation. In cases where missed coverage causes coverage-
increasing test cases to be misidentiÔ¨Åed as non-coverage-
increasing, this will have cascading effects on test case gener-
ation. As coverage-guided fuzzers explore the target binary by
mutating coverage-increasing test cases, exclusion of timed-
out‚Äîbut otherwise coverage-increasing‚Äîtest cases results in
a higher likelihood of generated test cases being non-coverage-
increasing, and thus, slowing coverage indeÔ¨Ånitely.
Small timeouts, when hit frequently, distort tracers‚Äô over-
heads, making their performance appear closer to each others‚Äô.
In early experiments with timeouts of 100ms (AFL‚Äôs default),
we observed that, for some datasets, our worst-performing
tracers (e.g., AFL-Dyninst, AFL-QEMU) had similar perfor-
mance to otherwise faster white-box-based tracing (i.e., AFL-
Clang). Upon investigating each tracer‚Äôs logs, we found that all
were timing-out on a signiÔ¨Åcant percentage of the test cases.
This was striking given that
the baseline (forkserver-only)
benchmark versions had signiÔ¨Åcantly fewer timeouts. Thus,
a 100ms timeout was too restrictive. We explored the effect of
several different timeout values, with the goal of making each
Per-benchmark relative overheads of UnTracer versus white-box
Fig. 8.
binary tracer AFL-Clang.
tracer‚Äôs number of timeouts close to the baseline‚Äôs (assumed
ground truth).
E. UnTracer versus Coverage-agnostic Tracing
We examine our evaluation results to identify each fuzzing
tracer‚Äôs overhead per benchmark. For each tracer‚Äôs set of trials
per benchmark dataset, we employ trimmed-mean de-noising
(shown to better reveal median tendency [55]) at test case
level‚Äîremoving the top and bottom 33% outliers‚Äîto reduce
impact of system interference on execution speeds. We then
take the resulting Ô¨Åve trimmed-mean dataset overheads for
each tracer-benchmark combination and average them to obtain
tracer-benchmark overheads. Lastly, we convert all averaged
tracer-benchmark overheads to relative execution times with
respect
to baseline (e.g., a relative execution time of 1.5
equates to 50% overhead).
In the following sections, we compare the performance
of UnTracer to three popular coverage-agnostic tracing ap-
proaches. We Ô¨Årst explore the performance of two black-
box binary fuzzing tracers: AFL-QEMU (dynamic) and AFL-
Dyninst (static). Secondly, we compare UnTracer‚Äôs perfor-
mance against that of the white-box binary fuzzing tracer AFL-
Clang (static assembler-instrumented tracing).
1) Black-box binary tracing: As shown in Figure 7, we
compare UnTracer‚Äôs performance to two popular black-box
binary fuzzing tracers‚ÄîAFL‚Äôs dynamically-instrumented trac-
ing via QEMU user-mode emulation (AFL-QEMU) [58],
and Dyninst-based static binary rewriting-instrumented tracing
(AFL-Dyninst) [10]. For one benchmark (sfconvert), AFL-
QEMU and AFL-Dyninst have similar relative execution times
(1.2 and 1.22, respectively) to UnTracer (1.0); however; by
looking at the different datasets for sfconvert, we observe
a clear trend between higher number of timeouts and lower
tracing overheads across all tracers (Table III). In our evalu-
ations, a 500ms test case timeout signiÔ¨Åcantly overshadows a
typical test case execution of 0.1‚Äì1.0ms.
(bsdtar, readelf, tcpdump), but as
AFL-Dyninst outperforms AFL-QEMU in three bench-
marks
these
benchmarks all vary in complexity (e.g., number of basic
blocks, execution times, etc.), we are unable to identify which
benchmark characteristics are optimal for AFL-Dyninst‚Äôs per-
formance. Across all benchmarks, UnTracer achieves an aver-
(cid:24)(cid:26)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:59 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 9. Distribution of each tracer‚Äôs relative execution time averaged per-
test case for one 24-hour cjson dataset. The horizontal grey dashed line
represents the average baseline execution speed. Red dots represent coverage-
increasing test cases identiÔ¨Åed by UnTracer.
Fig. 10. Averaged relative performance of all tracers over the percentage
of test cases processed for one 24-hour bsdtar dataset. Here, 1.0 refers to
baseline (maximum) performance. Each grey dashed vertical line represents a
coverage-increasing test case.
age relative execution time of 1.003 (0.3% overhead), while
AFL-QEMU and AFL-Dyninst average relative execution
times of 7.12 (612% overhead) and 6.18 (518% overhead),
respectively. The average Relative Standard Deviation (RSD)
for each tracer was less than 4%. In general, our results show
UnTracer reduces the overhead of tracing black-box binaries
by up to four orders of magnitude.
Mann Whitney U-test
scoring: Following Klees et
al.‚Äôs [59] recommendation, we utilize the Mann Whitney U-
test to determine if UnTracer‚Äôs execution overhead is stochasti-
cally smaller than AFL-QEMU‚Äôs and AFL-Dyninst‚Äôs. First we
compute all per-dataset execution times for each benchmark6
and tracer combination;
then for each benchmark dataset
we apply the Mann Whitney U-test with 0.05 signiÔ¨Åcance
level on execution times of UnTracer versus AFL-QEMU
and UnTracer versus AFL-Dyninst. Averaging the resulting
p-values for each benchmark and tracer combination is less
than .0005 for UnTracer compared (pair-wise) to AFL-QEMU
and AFL-Dyninst. Given that these p-values are much smaller
than the 0.05 signiÔ¨Åcance level, we conclude there exists
a statistically signiÔ¨Åcant difference in the median execution
times of UnTracer versus AFL-QEMU and AFL-Dyninst.
Vargha and Delaney ÀÜA12 scoring: To determine the
extent to which UnTracer‚Äôs execution time outperforms AFL-
QEMU‚Äôs and AFL-Dyninst‚Äôs, we apply Vargha and Delaney‚Äôs
ÀÜA12 statistical test [60]. For all comparisons among benchmark
trials the resulting ÀÜA12 statistic is 1.0‚Äîexceeding the conven-
tionally large effect size of 0.71. Thus we conclude that the
difference in execution times between UnTracer versus either
black-box tracer is statistically large.
2) White-box binary tracing:
In Figure 8, we show the
benchmark overheads of UnTracer, and AFL‚Äôs white-box bi-
nary (static assembly-time instrumented) tracer AFL-Clang.
AFL-Clang averages a relative execution time of 1.36 (36%
overhead) across all eight benchmarks, while UnTracer aver-
ages 1.003 (0.3% overhead) (average RSD for each tracer was
less than 4%). As is the case for black-box binary tracers AFL-
6We ignore sfconvert in all statistical evaluations as its high number of
timeouts results in all tracers having similar overhead.
(cid:24)(cid:26)(cid:23)
QEMU and AFL-Dyninst, in one benchmark with a large num-
ber of timeouts‚Äîsfconvert‚ÄîAFL-Clang‚Äôs performance is
closest to baseline (nearly matching UnTracer‚Äôs).
Mann Whitney U-test scoring: On average per dataset,
the resulting p-values ranged from .00047 to .015‚Äîthough
only in one instance did the p-value exceed .0005. Thus we
conclude that there is a statistically signiÔ¨Åcant difference in
median execution times of UnTracer versus AFL-Clang.
Vargha and Delaney ÀÜA12 scoring: Among all trials the
resulting ÀÜA12 statistics range from 0.76 to 1.0. As the minimum
of this range exceeds 0.71, we conclude UnTracer‚Äôs execution
time convincingly outperforms AFL-Clang‚Äôs.
Figure 9 shows the distributions of overheads for each
tracer on one dataset of the cjson benchmark. The coverage-
increasing test cases (red dots) are clearly separable from
the non-coverage-increasing test cases for UnTracer, with the
coverage-increasing test cases incurring double the overhead
of tracing with AFL-Dyninst alone.
Figure 10 shows how UnTracer‚Äôs overhead evolves over
time and coverage-increasing test cases. Very early in the
fuzzing process,
the rate of coverage-increasing test cases
is high enough to degrade UnTracer‚Äôs performance. As time
progresses, the impact of a single coverage-increasing test
case is inconsequential and UnTracer gradually approaches 0%
overhead. In fact, by 1000 test cases, UnTracer has 90% of
the native binary‚Äôs performance. This result also shows that
there is an opportunity for a hybrid coverage-guided tracing
model, where initial test cases are always traced until the rate
of coverage-increasing test cases diminishes to the point where
UnTracer becomes beneÔ¨Åcial.
F. Dissecting UnTracer‚Äôs Overhead
While Untracer achieves signiÔ¨Åcantly lower overhead com-
pared to conventional coverage-agnostic tracers (i.e., AFL-
QEMU, AFL-Dyninst, AFL-Clang), it remains unclear which
operations are the most performance-taxing. As shown in
Algorithm 1, UnTracer‚Äôs high-level workÔ¨Çow comprises the
following: (1) starting the interest oracle and tracer binary
forkservers; (2) identifying coverage-increasing test cases by
executing them on the oracle; (3) tracing coverage-increasing
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:59 UTC from IEEE Xplore.  Restrictions apply. 
	
	


	 	!"
"
	
	#!




































	


The rates of coverage-increasing test cases encountered over the
Fig. 12.
total number of test cases processed, per benchmark.
(e.g., fork(), execve()) and inter-process communica-
tion (e.g., pipe(), read(), write()). Previous work
looks at optimizing these system calls for fuzzing [61], but
given UnTracer‚Äôs low overhead in our evaluation, further
optimization adds little performance improvement. However,
we can imagine niche contexts where such approaches would
yield meaningful performance improvements.
G. Overhead versus Rate of Coverage-increasing test cases
Below, we discuss the potential performance advantage of
a hybrid approach combining coverage-guided and coverage-
agnostic tracing (e.g., AFL [5], libFuzzer [6], honggFuzz [4]).
In contrast to existing fuzzing tracers, which face high over-
head due to tracing all generated test cases, UnTracer achieves
near-zero overhead by tracing only coverage-increasing test
cases‚Äîthe rate of which decreases over time for all bench-
marks (Figure 12). Compared to AFL, UnTracer‚Äôs cover-
age tracing is slower on average‚Äîlargely due to its trace
reading/writing relying on slow Ô¨Åle input/output operations.
Thus, as is the case in our evaluations (Table III), coverage-
guided tracing offers signiÔ¨Åcant performance gains when few
generated test cases are coverage-increasing. For scenarios
where a higher percentage of test cases are coverage-increasing
(e.g., fuzzers with ‚Äúsmarter‚Äù test case generation [7], [39], [9]),
our approach may yield less beneÔ¨Åt.
In such cases, overhead may be minimized using a hy-
brid fuzzing approach that switches between coverage-guided
and coverage-agnostic tracing, based on the observed rate of
coverage-increasing test cases. We Ô¨Årst identify a crossover
threshold‚Äîthe rate of coverage-increasing test cases at which
coverage-guided tracing‚Äôs overhead exceeds coverage-agnostic
tracing‚Äôs. During fuzzing, if the rate of coverage-increasing
test cases drops below the threshold, coverage-guided tracing
becomes the optimal tracing approach; its only overhead is
from tracing the few coverage-increasing test cases. Con-
versely, if the rate of coverage-increasing test cases exceeds the
threshold, coverage-agnostic tracing (e.g., AFL-Clang, AFL-
QEMU, AFL-Dyninst) is optimal.
To develop a universally-applicable threshold for all tracing
approaches, we average the overheads of coverage-increasing
test cases across all trials in our tracer-benchmark evaluations.
We then model overhead as a function of the rate of coverage-
Fig. 11. Visualization of the overheads per UnTracer‚Äôs four components
related to coverage-increasing test case processing for each benchmark.
test cases‚Äô code coverage by executing them on the tracer; (4)
stopping the oracle‚Äôs forkserver; (5) unmodifying (removing
interrupts from) basic blocks in the oracle; and (6) restarting
the oracle‚Äôs forkserver. Since UnTracer identiÔ¨Åes coverage-
increasing test cases as those which trigger the oracle‚Äôs in-
terrupt, non-coverage-increasing test cases‚Äîthe overwhelm-
ing majority‚Äîexit the oracle cleanly without triggering any
interrupts. Thus, executing non-coverage-increasing test cases
on the oracle is equivalent to executing them on the original
(baseline) binary. Based on this, UnTracer‚Äôs only overhead is
due to processing coverage-increasing test cases.
In our evaluation of UnTracer‚Äôs overhead, we add timing
code around each component run for every coverage-increasing
test case: coverage tracing with the tracer (trace), stopping
the oracle‚Äôs forkserver (stop fsrvr), unmodifying the ora-
cle (unmodify), and restarting the oracle (start fsrvr).
We average all components‚Äô measured execution times across
all coverage-increasing test cases, and calculate their respective
proportions of UnTracer‚Äôs total overhead. Figure 11 shows the
breakdown of all four components‚Äô execution time relative
to total overhead. The graph shows that
the two largest
components of UnTracer‚Äôs overhead are coverage tracing and
forkserver restarting.
Tracing: Unsurprisingly, coverage tracing (trace) con-
tributes to the almost 80% of UnTracer‚Äôs overhead across
all benchmarks. Our implementation relies on Dyninst-based
static binary rewriting-instrumented black-box binary tracing.
As our evaluation results (Figure 7) show,
in most cases,
Dyninst adds a signiÔ¨Åcant amount of overhead. Given Un-
Tracer‚Äôs compatibility with other binary tracers, there is an op-
portunity to take advantage of faster tracing (e.g., AFL-Clang
in a white-box binary tracing scenario) to lower UnTracer‚Äôs
total overhead.
In binaries with shorter
Forkserver restarting: Restarting the oracle‚Äôs forkserver
(start fsrvr) is the component with second-highest over-
head.
test case execution times
(e.g., cjson, readelf, and tcpdump), the proportion of
tracing time decreases, causing more overhead to be spent
on forkserver restarting. Additionally, in comparison to Un-
Tracer‚Äôs constant-time forkserver-stopping operation (stop
fsrvr), forkserver-restarting relies on costly process creation
(cid:24)(cid:26)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:59 UTC from IEEE Xplore.  Restrictions apply. 























	