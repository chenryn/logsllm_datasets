graph for an example policy is shown in Fig. 2(a).
The policy graph shows the relation between variables and
events. If the graph is not connected we modify the policy by
adding a common ﬁctitious resource that connects the two
parts of the policy. However, we believe that unconnected
polices are rare as they would be the equivalent of a SQL
join of two tables without a “where” condition.
Using the graph, a policy is rewritten as a resource ruleset
in two steps. First, we choose an order for the correlation
steps by computing a spanning tree of the graph that we call
policy tree. Then, we generate the resource ruleset from the
tree. As the root of the spanning tree represents the ﬁnal step
of the correlation process, we choose the root to be one of
the resources that appear in the ﬁnal violation notiﬁcation
message, so that information about such a resource is readily
available for creating the notiﬁcation. Fig. 2(b) provides an
example of the conversion of a policy graph to a policy tree.
The steps necessary for such a conversion are as follows.
1) We remote variable nodes connected to only one predi-
cate node. In Fig. 2(a), we remove the node IP .
2) We explicitly represent the relations between resources
by adding edges between variable nodes. We create a
new edge between variable nodes of distance 2 (i.e.,
we ignore predicate nodes and we connect directly
neighboring variable nodes). In our example of Fig. 2(a),
we mark such edges with dashed lines.
3) We compute the spanning tree by selecting a root and
by removing redundant edges. For each predicate node,
we maintain only one edge. We select the edge to ensure
that each variable node is connected to at least one event
containing a reference to the variable node’s parent. In
Fig. 2(b), we mark the removed edges with dotted lines.
This transformation connects each predicate node (i.e.,
events) to a variable representing one of the resources con-
tained in the event. Events are forwarded to the broker
managing the resource represented by the value of the variable.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:22 UTC from IEEE Xplore.  Restrictions apply. 
For example, we can take a predicate connected(H, N ) with
an edge to N . An event connected(host1, net1) is forwarded
to the broker managing net1. For the rest of the section we
indicate with N the resource associated with the value of the
variable N .
A broker managing a resource N can perform a partial
matching of the policy. For each variable node, we create a rule
of the resource ruleset by considering the incoming edges. At
the lower heights of the tree, all incoming edges of a variable
node are connected to predicate nodes. These predicate nodes
all share the same variable H. For example, the body of
the rule associated with the variable node N in Fig. 2(b)
is internal(N ), connected(H, N ). For a violation of the
policy to exist, the variable N must have the same value on all
predicates contained in the policy. As the broker managing N
receives all events that share the same value for the variable,
the partial matching is complete. The head of the partial
rule is a predicate that has the variables used in the partial
rule as parameters. In this case, the result is encoded with
partialN (H, N ). This predicate is treated as a new event,
and it is forwarded up in the tree. In our example, the event is
sent to the broker H. Step 3 in the conversion of the graph to
the tree ensures that the broker always has at least one event
that carries both the information about the current resource
and about the resource one level higher in the tree.
A variable node can have incoming edges connected to other
variable nodes. These edges are considered as connected to
events representing the partial execution. In our case, the node
H is associated to the rule partialS(H, S), conn(H, S, IP ),
partialN (H, N ). If the variable node is the root, the rule
is directly associated with the presence of a violation. When
multiple policies are present, each policy uses a different name
for the partial execution predicates.
During the execution of this algorithm there is no single
broker managing the resolution for an entire policy: depending
on the resources mentioned in the events, different brokers are
in charge of the different steps of the aggregation and of the
ﬁnal identiﬁcation of violations.
2) Remove unnecessary information: We remove unnec-
essary data from partial execution statements to reduce the
amount of information sent to other brokers. If a variable
is not used anywhere else in the rule, we can drop it from
a partial statement without affecting the equivalence to the
original policy. For each variable node V , we build a set of
variables we call shared set. The shared set is constructed by
removing the subtree of V from the policy tree and by taking
all variables used in the remaining tree. We drop from the
partial execution statements of V the variables that do not
appear in the shared set.
3) Distribute information about critical resources: A pure
resource-based distribution of events offers little protection
against attackers interested in acquiring information about
a speciﬁc critical resource in the system. An attacker can
acquire these events by identifying the broker managing such
a resource and by compromising it. Our algorithm provides a
protection against this type of attack by spreading events about
critical resources across multiple brokers. As different types of
events about the same resource are generally used in different
policies, we add a policy-dependent preﬁx in the selection of
the broker. When a resource is identiﬁed as critical, instead
of relying only on the resource name r for the identiﬁcation
of the broker H(r), we add a preﬁx pi that depends on the
policy in which the resource is used. Different types of events
about a critical resource are sent to different brokers H(pi|r).
We consider critical all resources representing data about the
monitoring servers. In this way, We limit the possibility that an
attacker could use information collected from the compromise
of a monitoring server to compromise another server.
C. Correctness argument
Our algorithm is correct and complete if it identiﬁes the
same set of violations that would be identiﬁed if all events
were integrated in a global KB. We show the equivalence in
two steps. First, we show that the processing of each rule in
the resource ruleset on a broker is equivalent to the processing
of the same resource-ruleset rule in a global knowledge base.
Second, we show that the combination of the resource ruleset
is equivalent to the original rule.
All predicates in a resource-ruleset rule share a common
variable V . For any instantiation V = v, the rule is triggered
only if events have the same value v for the variable V . Our
algorithm ensures that if a predicate p is part of the resource-
ruleset rule for a variable V , all events having V = v are
sent to the same broker. Hence, such a broker can identify all
inference for which V = v. As the same rule is repeated in
all brokers, we obtain the same result for every value of V .
Second, we show the equivalence between the resource
ruleset and the original rule by noticing that
the rewrite
algorithm is, in fact, a simple logical manipulation of the
rule. The rule-generation algorithm can be seen as a set of
rewriting steps that preserve the equivalence. We choose a
variable V1 and create a rule ruleV1 that has a body containing
all the predicates predi(Ai) (where Ai is a set of variables)
such that V1 ∈ Ai. The head of the rule is a new predicate
partialv1(AV1 ) where AV1 = {∪Ai|V1 ∈ Ai} . We remove
the selected predicates from the body of the original rule
and we substitute them with the partialv(Av). For each
rulev, because the predicate partialv is unique for the rule,
we have that a particular assignment of partialV1(AV1 )
is possible if and only if all predicates predi(Ai) in the
rule body are also true. Hence, at the end of the rewrite
process, the initial rule has been rewritten as partialV1(AV1 ),
. . . , partialVk (Ak) → violation(A). Because each of the
partialv is true if one only if the body of its rule is true,
and AV1 , . . . , AVk still represent the entire set of variables,
we have that violation(A) is generated if and only if it is
generated by the original rule.
VI. EXPERIMENTAL EVALUATION
We measure the ability of our event distribution to protect
the system’s information against the three types of attackers
identiﬁed in Section IV. We show that our resource-based
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:22 UTC from IEEE Xplore.  Restrictions apply. 
!"#$%&’"()*#"+,-.#,
1"2345(*#%6(’2-(*%
!"#$%
!"#&%
/,
!"#’%
!"#()*+"%
!),"#"-#%
./*0/,%%
*"#),-#%
!"#()*+"75/#"8%>?#%
8)*2’3%*"82#-*25)0(’%
!),"73"’"*/-"8%"9"’-#:%
;/*0/,%;(,2+<%*"#),-#:%/’8%
92(,/0(’%’(0=+/0(’#%
Fig. 3.
Internal structure of our broker implementation. It receives events
and adds them to the appropriate resource-based KB. The Datalog resource
rulesets are added to the KB obtained by the union of the resource-based KBs.
The events generated by the rules are forwarded to the appropriate brokers. In
case of a changes in the availability of other brokers, the neighbors monitor
sends and receives resource-based KBs from other brokers.
mapping provides a better protection of event-conﬁdentiality
than other types of event distributions, and that our technique
only introduces a delay limited within a few seconds in the
detection of violations.
A. Implementation
We implement
the policy compliance algorithm in our
distributed monitoring system. Our agent-based system pro-
vides monitoring of SNMP data, running processes, network
connections, and logged users. Information is integrated in a
set of monitoring servers communicating using a 1-hop DHT.
The hash of the resource name is used for mapping resources
to brokers. The system is implemented in Java. Rules are
distributed to the servers before starting the process.
Each broker analyses the policies and creates resource
rulesets and queries. Events received by brokers are placed
in a resource-KB depending on the resources contained in the
event. Rulesets and queries are applied on the KB obtained
by taking the union of all resource-KBs. Once inference is
performed, the monitoring server applies the queries deﬁned
from the rules and creates the set of events to send to other
brokers. Such events contain the partial executions of the
policies or specify the detection of a violation. If a violation
is detected, the broker forwards it to the brokers subscribed to
receiving violation notiﬁcations about the rule or about the
resources involved (e.g., the monitoring server in the sub-
organization managing the resources).
Mapping between resources and brokers can change over
time (e.g., because we add a new broker). A component, the
neighbors’ monitor, detects when a resource becomes mapped
to another broker and moves the proper part of the knowledge
base to such a broker.
Failures of a broker are handled by remapping automatically
resources to new brokers. Such a process is managed by the
neighbors monitor. However, when a broker fails, its current
knowledge base is lost. For the cases in which events are
correlated within a limited time window, a failure would
only affect
temporarily the ability of detection violations
until
the
new broker would have received all relevant events and the
event correlation becomes complete again. For the cases in
the time window is passed. After such a time,
which correlation requires to store longer term information,
devices are conﬁgured to send periodically such information
about the state to brokers. For example, SNMP information is
generally long-lived. A device could periodically (e.g., every
10 minutes) send again its entire state to the brokers. A proper
handling of timestamps (such as the one described in Walzer
et al. [24]) ensures that policy violations that occurred during
the downtime are still detected, even if with a delay. An
architectural description of a broker is shown in Fig. 3.
The evaluation of our system requires having policies and
events to correlate. To evaluate our system in a wide range of
realistic conditions, we generate events from publicly available
data traces and from monitoring a set of systems in our
research infrastructure. The ﬁrst dataset we use is a network
trace collected during the three days of the 2010 Network
Warfare Competition [27]. We use Snort1 to analyze the
trace and generate 60152 security-relevant events carrying
information such as type of alert, source IP, destination IP,
protocols, and ports. The second dataset
is composed of
syslog data collected by monitoring the wireless network
infrastructure of Dartmouth college [28]. It is composed of
30 million syslog entries describing the state of the wireless
access points. It reports events such as association of wireless
devices to access points, interactions between access points,
and errors. The third dataset contains SNMP data about
conﬁgurations of hosts, network connections, running services,
and running programs. We collected this dataset by monitoring
using SNMP the state of different types of machines: servers,
development desktops, and laptop computers. We choose the
datasets to show the applicability of our technique to different
data used in policy compliance: network trafﬁc data, network
management data, and security management data.
B. Event Dataset Analysis
We start our evaluation by analyzing the characteristics of
the events generated in network management and intrusion
detection. Such an analysis shows that a resource-based map-
ping can provide a more uniform distribution of data than a
mapping based on event-type.
First, we analyze our datasets to characterize the distri-
bution of events and of resources. We identify event types
and resource types. We have 24 types of events in the IDS
dataset, 42 in the wireless management dataset, and 14 in the
SNMP dataset. Each dataset has several types of resources. We
identify source ip, dest ip, source port, dest port, and ICMP
type as different resources for the IDS dataset2. We identify
access point IDs and MAC addresses for the wireless dataset,
and we identify IP, programs, network ports, and services as
resources for the SNMP motoring dataset.
We show that the distribution of the number of messages is
more ﬂat if we distribute messages by resource, while it is far
from uniform when we distribute messages by type (i.e., each
resource has a similar number of messages related to them,
1http://www.snort.org
2We consider source and destination IPs and ports as different resources to
better understand the dataset characteristics.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:22 UTC from IEEE Xplore.  Restrictions apply. 
IDS Resource
Event type
Src port
Dst port
Src IP
Dst IP
ICMP type
Wireless Resource
Event type
Access point ID
MAC address
SNMP Resource
Event type
Host IP
Program
Network Port
Services
24
357
704
742
1299
108
42
8944
59473
Cardinality With type
24
180
249
75
171
6
Cardinality With type
42
544
9251
Cardinality With type
14
4145
493
20770
56
14
4147
493
24222
56
Avg Msgs
stddev
4.17%
12.0%
0.556%
1.97%
0.402%
1.31%
1.33%
4.64%
0.585%