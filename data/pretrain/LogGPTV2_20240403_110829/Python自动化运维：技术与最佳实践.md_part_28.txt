0123456
return [self.mr(mapper=self.mapper),
reducer(self,httpcode,occurrences):
for httpcode in line.split():
i=0
Linux公社www.linuxidc.com
=='_main
i+=1
self.mr(reducer=self.reducer)]
：
7891011121314151617181920212223
图12-15业务流量趋势图
，可以帮助我们了解网站的可用度及健康状态，
#对排序后的key对应的value作sum累加
第12章
#在steps 方法中添加调用队列
Python大数据应用详解
219
---
## Page 248
始为1，以便作累加统计，详细源码如下：
关注。本示例以分钟为单位对网站的访问数进行统计，原理与12.4.2类似，区别是value初
12.4.4
220第二部分高级篇
from mrjob.job import MRJob
【/home/test/hadoop/http_minute_conn.py 】
一个网站的请求量大小，直接关系到网站的访问质量，非常有必要对该数据进行分析且
我们可以根据结果数据输出比例饼图，如图12-17所示。
分析结果见图12-16。
importre
com/20140215
生成hadoop 任务，分析数据源保持不变，输出目录改成/output/httpstatus，执行：
网站分钟级请求数统计
Linux公社 www.linuxidc.com
020
图12-17生成HTTP状态码饼图
图12-16任务分析结果
dfs
-cat
nndno/
--jobconfmapreduce.job.
https
---
## Page 249
reducer操作时作累加（sum）统计，详细源码如下：
捕捉攻击来源。实现原理是定义匹配IP正则字符串作为key，将value 初始化为1，执行
12.4.5
统计用户的访问来源IP可以更好地了解网站的用户分布，同时也可以帮助安全人员
分析结果见图12-18。
job.priority=VERY_HIGH -o hdfs:///output/http_minute_conn hdfs:///user/root/
生成 Hadoop任务，输出目录/output/http_minute_conn，执行：
website.com/20140215
if
class MRCounter(MRJob):
网站访问来源IP统计
name
def reducer(self,
def mapper(self, key, line):
yield key, sum(occurrences)
for
i=0
/home/test/hadoop/http_minute_conn.py-rhadoop
Linux公社 www.linuxidc.com
i+=1
dt in line.split():
yield hm,1
hm=timerow[1]+":"+timerow[2]
timerow= dt.split(":")
main_
key,occurrences):
图12-18任务分析结果（部分截图）
#获取时间字段，位于日志的第4列，内容如“L06/Aug/2010:03:19：44”
第12章Python大数据应用详解221
dfs
#获取“小时：分钟”，作为key
CG
--jobconf-mapreduce
---
## Page 250
12.4.6
222第二部分高级篇
通过统计网站文件的访问次数可以帮助运维人员了解访问最集中的文件，以便进行有针
分析结果见图12-19。
com/20140215
priority=VERy_HIGH-o hdfs:///output/ipstat hdfs:///user/root/website
生成Hadoop任务，输出目录/output/ipstat，执行：
if
class MRCounter(MRJob):
IP_RE=re.compile(r"\d{1,3}\.\d(1,3)\.\d(1,3)\.\d{1,3)"）#定义IP正则匹配
from mrjob.job import MRJob
【/home/test/hadoop/ipstat.py】
#python
importre
网站文件访问统计
MRCounter.run()
name
def reducer(self,
def mapper(self,
yield ip, sum(occurrences)
for ip in IP_RE.findall(line):
#匹配IP正则后生成key:value，
/home/test/hadoop/ipstat.py
Linux公社 www.linuxidc.com
yield ip,1
main_
key,line):
ip，
图12-19任务分析结果（部分截图）
us
occurrences):
其中key为IP地址，value初始值为1
-rhadoop
dFs
--jobconf
mapreduce.job
---
## Page 251
系统及版本、浏览器内核等信息，为更好地提升用户体验提供数据支持。
源码如下：
现原理是将访问文件作为key，初始化value为1，执行reducer 时作累加（sum）统计，详细
对性的优化，比如调整静态文件过期策略、优化动态cgi 的执行速度、拆分业务逻辑等。实
?
考标
同理，我们可以使用以上方法对User-Agent域进行分析，包括浏览器类型及版本、操作
执行结果如图12-20所示。
from mrjob.job import MRJob
【/home/test/hadoop/httpfile.py】
if
class MRCounter(MRJob):
importre
MRCounter.run()
12.2.1小节原生Python编写mapreduce示例参考htp://www.michael-noll.com/tutorials/
def reducer(self,url,occurrences):
def mapper（self,key,line):
name
yield url, sum(occurrences)
for url in line.split():
Linux公社 www.linuxidc.com
i+=1
if i==6:
yieldurl，1
main
ginfol.gif"
图12-20任务分析结果（部分截图）
gtt
ne.
6:
mf
ew.qif"
#获取日志中URL文件资源字段，作为keY
oe
9
665
合
99
第12章Python大数据应用详解223
---
## Page 252
Linux公社 www.linuxidc.com
---
## Page 253
Linux公社 www.linuxidc.com
案例篇
第三部分7t
第16章
第15章
第14章
第13章
构建桌面版C/S自动化运维平台
构建分布式质量监控平台
打造Linux系统安全审计功能
从零开始打造B/S自动化运维平台
---
## Page 254
Chatc3第13章
营平台当中。平台首页如图13-1所示。
的业务特点对OMServer平台进行扩展，比如与现有资产平台进行对接，或整合到现有的运
户体验方面，采用前端异步请求，模拟Linux终端效果接收返回串。任何人都可以根据自身
率方面，管理员只需选择操作目标对象及操作模块即可完成一个现网变更任务。另外，在用
面，采用加密（RC4算法）指令传输、操作日志记录、分离WebServer与主控设备等；在效
前端HTML表单参数动态定制，可灵活实现日常运维远程操作、文件分发等任务；在安全方
理基础平台，提供了模块扩展的支持，可以随意添加集群操作任务模块，服务器端模块支持
的名称，后面的内容将使用它作为平台的称号。OMServer实现了一个集中式的Linux集群管
13.1平台功能介绍
展性强、安全、高效的自动化运维平台，从而提高运营人员的工作效率。（本章的源码也可从
质量与成本管理、运营效率建设等。本章将介绍如何使用Python从零开始打造一个易用、扩
模式已迫在眉睫，可以从以下几个方面入手，包括定制符合企业特点的IT制度、流程规范
事故，技术部的每个人都会加人“救火”行列，最后弄得疲惫不堪。因此，构建高效的运营
员将面临越来越多的挑战。目前，很多企业还处在传统的“半自动化”状态，一旦出现运维
作为ITIL体系当中的一部分，本平台同样遵循ITIL标准设计规范。OMServer是本平台
随着企业业务的不断发展，在运营方面，如何保障业务的高可用及服务质量，系统管理
从零开始打造B/S自动化运维平台
Linux公社www.linuxidc.com
京民案
---
## Page 255
持 Saltstack、Ansible、Func等平台。具体见如图13-2所示的系统架构图。
离，提高整体安全性，同时具备第三层的多机服务的能力；第三层为集群主控端服务层，支
层，采用rpyc 分布式计算框架实现，作为第一层与第三层的数据交互及实现主控端物理分
js+MySQL实现，服务器端采用了Nginx+uwsgi构建高效的Web服务；第二层为分布式计算
13.2
OMServer平台采用了三层设计模式，第一层为Web交互层，采用了Django+prototype.
OMServer
系统构架设计
Linux公社 www.linuxidc.com
2
888
图13-1平台首页界面
图13-2系统架构图
第13章从零开始打造B/S自动化运维平台227
第二层
保吴吴
---
## Page 256
13.3.2
该数据库总共有4张表，表信息说明如下。
13.3.1
13.3
给系统管理员，整个任务模块分发执行流程结束。
业务服务器集群发送执行任务，执行完毕后，将返回的执行结果加解密处理，最后逐级返回
key”进行解密，解析成OMServer调用的任务模块，结合Saltstack、Ansible或Func 向目标
Saltstack、Ansible、Func等的主控端，主控端将接收到的数据通过“RC4+b64decode+密钥
进行加密，再作为rpyc客户端向rpyc服务器发送加密指令串，rpyc服务器端同时也是
发起HTTP请求，OMServer接收HTTPPOST的数据并采用“RC4+b64encode+密钥key”
228
app_categ_name
server_categ_id
server_categ_name
OMServer平台采用了开源数据库MySQL作为数据存储，将数据库命名为OMServer，
server_list 服务器列表。
server_app_categ服务应用分类表。
server_fun_categ服务功能分类表。
口server_app_categ：服务应用分类表。
口server_fun_categ：服务功能分类表。
从图13-2可以看出系统的三个层次，首先管理员向OMServer平台所在Web服务器
字段名
字段名
module_list：模块列表。
口server_list：服务器列表。
第三部分案例篇
数据库结构设计
数据字典
数据库分析
Linux公社 www.linuxidc.com
数据类型
数据类型
char(30)
int(11)
int(11)
char(20)
int(11)
默认值
默认值
允许非空
允许非空
NO
NO
NO
NO
自动递增
自动递增
是
是
服务应用分类名称
服务功能分类ID
服务应用分类ID
服务功能分类名称
服务功能分类ID
备注
备注
---
## Page 257
置为外键，与 server_fun_categ 表中的 ID字段进行关联。
server_app_categ表中的ID字段进行关联；server_app_categ表中的 server_categ_id字段被设
10.11.100.10（服务器归bbs.domain.com类别），详见图13-3所示的数据库模型图。
次关系的定义，例如，Linux.Web（一级功能类别），bbs.domain.com（二级应用类别）
子类为“应用分类”，在最小单位的“服务器”中指定“应用分类”进行关联，完成其层
13.3.3
server_wip
server_name
module_extend
module_caption
module_name
ID
server_app_id
server_op
server_lip
从模型关系图中可以看出，server_list表中的 server_app_id字段被设置为外键，与
在ITIL体系中有一种比较典型的资产定义方法，
字段名
module_list模块列表。
字段名
数据库模型
Linux公社
varchar(2000)
char(255)
char(20)
int(11)-
数据类型
char(10)
char(12)
char(15)
char(13)
数据类型
int(11)
(doa
server_list
IDINT(11)
module_list
(T）INIpddeaas
server_ameCHAR(13)
module_extendVARCHAR(200）
module_capfionCHAR(255)
默认值
默认值
www.linuxidc.com
图13-3
第13章
数据库模型
允许非空
允许非空
NO
NO
NO
#
#
从零开始打造B/S自动化运维平台
server_categ_id INT(11)
serverapp_categ
serverfun_categ
app_categ_nameCHAR（30）
DINT(11)
，即采用“功能分类”作为根类，
自动递增
自动递增
主机外网IP
主机名称
服务应用分类ID
主机操作系统
主机内网IP
模块前端扩展
模块功能描述
模块名称
模块ID号
备注
备注
229
其
---
## Page 258