major operation is still adding edges.
2Line 252 of SalaDP.java in src/anonymize/ of SecGraph.
Fig. 2: A schematic view of our graph recovery attack. Dashed lines in the graph represent fake added edges; sA(A, B) represents
the plausibility of edge {A, B} (Section III); A [1.2, 5.7, -3.2, 0.9] represents an example embedding vector of A (Section III).
Our graph recovery attack could also be carried out by a
service provider (e.g., OSN operator) to check whether there
are potential ﬂaws in its anonymized graph data before release.
III. EDGE PLAUSIBILITY
To verify our hypothesis that an edge is fake if the users it
connects are structurally distant, we ﬁrst need to quantify two
users’ structural proximity in a social graph. Previous work
on link prediction provides numerous proximity metrics [25],
[6], [2]. However, these metrics are manually designed and
only capture partial information of structural proximity. The
recent advancement of graph embedding provides us with an
alternative approach [35], [45], [14], [4], [16], [38]. In this
context, users in a social network are embedded into a continu-
ous vector space, such that each user’s vector comprehensively
reﬂects her structural property in the network. Then, for an
edge in the anonymized graph, we can deﬁne its two users’
structural proximity as the similarity of their vectors, and use
this similarity as the edge’s plausibility.
In this section, we ﬁrst recall the methodology of graph
embedding, and then formally deﬁne edge plausibility.
A. Graph Embedding
Graph embedding aims to learn a map f from users in GA
to a continuous vector space, i.e.,
f : U → Rd,
(cid:89)
(cid:89)
where d, as a hyperparameter, is the dimension of each user’s
vector. We adopt the state-of-the-art optimization framework,
namely Skip-gram [29], [30], to learn f; the corresponding
objective function is deﬁned as:
arg max
f
u∈U
u(cid:48)∈ω(u)
P (u(cid:48)
|f (u)).
(1)
[14]. Concretely, we start a random walk from each user in GA
for a ﬁxed number of times t, referred to as the walk times.
Each random walk takes l steps, referred to as the walk length.
The procedure results in a set of truncated random walk traces,
and each user’s neighborhood includes the users that appear
before and after her3 in all these random walk traces. Similar
to the vector dimension (d), walk length and walk times (l
and t) are also hyperparameters. We will choose their values
experimentally.
Objective function (Equation 1) implies that if two users
share similar neighborhoods in GA, then their learned vectors
will be closer than those with different neighborhoods. This
results in each user’s vector being able to preserve her neigh-
borhood and to eventually reﬂect her structural property in GA.
To optimize Equation 1, we rely on stochastic gradient descent
(SGD) with negative sampling [30]. We omit the details here
due to space limitation.
B. Quantifying Edge Plausibility
Given the vectors learned from graph embedding, we deﬁne
an edge plausibility as the cosine similarity between its two
users’ vectors. Formally, for {u, u(cid:48)
} ∈ EA, its plausibility is
deﬁned as:
sA(u, u(cid:48)) =
f (u) · f (u(cid:48))
||f (u)||2 ||f (u(cid:48))||2
where ||·||2 denotes the L2-norm. Consequently, if the vectors
of two users have higher (cosine) similarity, then the edge
connecting these users is more plausible. It is worth noting
that as f (u) ∈ Rd, the range of sA(u, u(cid:48)) lies in [-1, 1] instead
of [0, 1].
|f (u)) is modeled with
IV. GRAPH RECOVERY
Here, the conditional probability P (u(cid:48)
a softmax function
P (u(cid:48)
|f (u)) =
(cid:80)
exp(f (u(cid:48)) · f (u))
v∈U exp(f (v) · f (u))
,
where f (u(cid:48)) · f (u) is the dot product of the two vectors, and
ω(u) represents u’s neighborhood in GA. To deﬁne ω(u), we
use a random walk approach following previous works [35],
In this section, we ﬁrst evaluate the effectiveness of our
edge plausibility metric on differentiating fake edges from
original ones without determining a decision threshold on
the edge plausibility a priori. Then, we present a method to
automatically decide whether an edge is fake, which allows us
to eventually recover the original graph.
4
A  [1.2, 5.7, -3.2, 0.9]
B  [0.8, -3.4, 5.2, 1.3]
C  [0.9, -1.2, 0.2, 4.3]
D  [-3.2, 0.4, 0.7, 1.1]
E  [7.7, 2.4, -0.2, 0.3]
F  [3.8, -9.3, 0.3, 3.2]sA(A, B)
sA(A, C)
sA(A, D)
sA(A, F)
sA(B, E)
sA(C, E)
sA(C, F)
sA(D, E)
sA(D, F)EFABCDGraph EmbeddingPlausibility MetricGraph RecoveryEFABCD(a) k-DA (k = 50)
(b) k-DA (k = 75)
(c) k-DA (k = 100)
(d) SalaDP ( = 100)
(e) SalaDP ( = 50)
(f) SalaDP ( = 10)
Fig. 3: [Higher is better] AUC scores for detecting fake edges for different datasets, structural proximity, distance metrics, and
anonymity levels (k resp. ). The embedding approach clearly outperforms all three traditional structural proximity metrics.
Moreover, cosine similarity performs best, only matched by Bray-Curtis distance.
TABLE II: Statistics of the datasets.
Number of users
Number of edges
Average degree
Average clustering coefﬁcient
Number of triangles
Enron
36,692
183,831
10.020
0.497
727,044
NO
SNAP
63,731
817,090
25.642
0.221
3,501,542
4,039
88,234
43.691
0.606
1,612,010
A. Experimental Setup
Datasets: We utilize three datasets for our experiments.
The ﬁrst one, referred to as Enron, is a network of Email
communications in the Enron corporation.4 The second dataset
(NO) is collected from Facebook users in the New Orleans area
by Viswanath et al. [47]. The third dataset (SNAP) by McAuley
and Leskovec is obtained through a survey study [27]. Note
that Enron and NO are the two datasets used in the evaluation
of SecGraph as well [18]. Table II presents some basic statistics
of the three datasets.
Baseline Models and Evaluation Metrics: To demonstrate
3We select 10 users before and after the considered user following previous
works [35], [14], [4].
4https://snap.stanford.edu/data/email-Enron.html
the effectiveness of our plausibility metric, which is essen-
tially a structural proximity metric, we compare it with three
classical structural proximity metrics, namely, embeddedness
(number of common friends), Jaccard index, and Adamic-Adar
score [1]. Their formal deﬁnition is as the following.
Embeddedness : |κA(u) ∩ κA(u(cid:48))|
Jaccard index : |κA(u) ∩ κA(u(cid:48))|
(cid:88)
|κA(u) ∪ κA(u(cid:48))|
1
Adamic-Adar score :
v∈κA(u)∩κA(u(cid:48))
log |κA(v)|
Recall that cosine similarity is adopted for measuring edge
plausibility based on the users’ vectors learned from graph
embedding. We also test two other vector similarity (distance)
metrics, namely the Euclidean distance and the Bray-Curtis
distance, deﬁned as follows:
Euclidean : ||f (u) − f (u(cid:48))||2
(cid:80)d
(cid:80)d
i=1 |f (u)i − f (u(cid:48))i|
i=1 |f (u)i + f (u(cid:48))i|
Here, f (u)i is the i-th element of vector f (u).
Bray-Curtis :
5
EnronNOSNAP0.00.20.40.60.81.0AUCCosineEuclideanBray-CurtisEmbeddednessJaccardAdamic-AdarEnronNOSNAP0.00.20.40.60.81.0AUCEnronNOSNAP0.00.20.40.60.81.0AUCEnronNOSNAP0.00.20.40.60.81.0AUCEnronNOSNAP0.00.20.40.60.81.0AUCEnronNOSNAP0.00.20.40.60.81.0AUCFor evaluation metrics, we ﬁrst use the AUC, which
measures the area under the ROC curve. The ROC curve
projects the relation between false-positive rate (on the x-
axis) and true-positive rate (on the y-axis) over a series of
thresholds for a given prediction task. A ROC curve closer to
the top-left border of the plot (high true-positive rate for low
false-positive rate), thus a larger AUC value, indicates higher
prediction performance. Morever, there exists a conventional
standard to interpret AUC values:5 AUC = 0.5 is equivalent to
random guessing, whereas an AUC greater than 0.9 implies an
excellent prediction. Many recent works on assessing privacy
risks have adopted AUC as the evaluation metric [4], [37],
[15], [13], [41], [21]. We also make use of the F1 score for
the method that automatically detects fake edges. Due to the
randomness of the anonymization alogrithms, we repeat our
experiments ﬁve times and report the average results.
Parameters in Anonymization Mechanisms: We rely on
SecGraph to perform k-DA and SalaDP [18]. Each anonymiza-
tion mechanism has its own privacy parameter. For k-DA, we
need to choose the value k, i.e., the minimal number of users
sharing a certain degree for all possible degrees in GA. Greater
k implies stronger privacy. In our experiments, we choose
k to be 50, 75, and 100, respectively, to explore different
levels of privacy protection [18]. For SalaDP,
the privacy
parameter is  which controls the noise added to the dK-2
series of G: The smaller  is, the higher its privacy provision is.
Following previous works [40], [18], we experiment with three
different  values: 10, 50, and 100. As stated before, both k-DA
and SalaDP’s principal operation is adding fake edges to the
original graph. By running the two anonymization mechanisms
on our three datasets, we discover that this is indeed the case.
For instance, SalaDP ( = 10) adds 120% more edges to the
NO dataset, while only deleting 1.7% of the original edges.
Hyperparameter Setting: There are mainly three hyperpa-
rameters in the graph embedding phase: walk length (l), walk
times (t) and vector dimension (d). For both k-DA and SalaDP,
we choose l = 100 and t = 80. Meanwhile, we set d = 128
for k-DA and d = 512 for SalaDP. These values are selected
through cross validation (see Section IV-C). For reproducibility
purposes, our source code will be made publicly available.
B. Prediction Results
Figure 3 depicts the AUC values of using our edge plau-
sibility metric (Cosine in Figure 3) to differentiate fake edges
from original ones. In most of the cases, we achieve excellent
performance with AUC values above 0.95. In particular, for
the SalaDP-anonymized SNAP dataset ( = 100), the average
AUC value is 0.971 (see Figure 3d). The only case where our
edge plausibility does not achieve an excellent performance is
when applying SalaDP on the Enron dataset where the AUC
values are between 0.76 and 0.83. However, we emphasize
that for most of the classiﬁcation tasks, such AUC is already
considered good.
We also notice that our method performs better against
SalaDP on the SNAP dataset than the the other two. One
reason is that SNAP has the highest number of average degrees
(Table II), which implies more diverse dK-2 series. This
5http://gim.unmc.edu/dxtests/roc3.htm
results in SalaDP adding more fake edges on SNAP, which
leads to high performance of fake edge detection. However, we
do not observe a similar trend for k-DA-anonymized datasets.
The AUC values for other vector similarity (distance)
metrics are presented in Figure 3 as well. Cosine similarity
performs slightly better than both Euclidean distance and
Bray-Curtis distance on k-DA-anonymized graphs. On the
other hand, for SalaDP-anonymized graphs, we can observe
that cosine similarity performs better than Euclidean distance
(around 10% performance gain), while the performance of
Bray-Curtis and cosine similarity is still very close. This shows
that cosine similarity (as well as Bray-Curtis distance) is a
suitable choice for our edge plausibility metric.
Figure 3 also shows that our edge plausibility signiﬁcantly
outperforms the traditional structural proximity metrics. For
instance, on the SalaDP-anonymized NO dataset ( = 50), our
approach achieves 0.944 AUC while the result for the best
performing structural proximity, i.e., Jaccard index, is around
0.7. It also appears that embeddedness outperforms the other
two metrics on k-DA-anonymized dataset in most of the cases,
while Jaccard index is rather effective for SalaDP.
C. Hyperparameter Sensitivity
We study the inﬂuences of the three hyperparameters (l, t
and d) on the prediction performance. Here, l and t are directly
related to the size of the random walk traces, which essentially
decides the amount of data used for learning embedding
vectors. For both anonymization mechanisms, we observe that
increasing l and t improves the AUC values. However, the
increase is smaller when both of these values are above 60.
Therefore, we set l = 100 and t = 80.
Meanwhile, we observe interesting results for the vector
dimension d: different anonymization mechanisms have differ-
ent optimal choices for d (Figure 4 and Figure 5). It appears
that when detecting fake edges on k-DA-anonymized graphs,
d = 128 is a suitable choice for all datasets. On the other
hand, for SalaDP, d = 512 is able to achieve a stronger
prediction. We conﬁrm that the vector dimension is indeed a
subtle parameter, as was observed in other data domains, such
as biomedical data [3] and mobility data [4]. In conclusion, our
default hyperparameter settings are suitable for our prediction
task.
D. Optimizing Fake Edge Detection
Next, we investigate how to concretely determine whether
an edge in an anonymized graph is fake given its plausibility,
such that the adversary can recover the original graph from
the anonymized one.
Figure 1a and Figure 6 depict the histograms of both fake
and original edges’ plausibility in anonymized NO dataset (by
both k-DA and SalaDP). We see that both follow a Gaussian
distribution with different means and standard deviations.
Similar results are observed on Enron and SNAP datasets.
Given that the general population (plausibility of all edges)
consists of a mixture of two subpopulations (plausibility of
fake and original edges) with each one following a Gaussian
distribution, we can ﬁt the general population with a Gaussian
mixture model (GMM). With the ﬁtted GMM, we can obtain
6
(a) Enron
(b) NO
(c) SNAP
Fig. 4: [Higher is better] Sensitivity of the AUC with respect to the embedding vector dimension for k-DA-anonymized datasets.
(a) Enron
(b) NO
(c) SNAP
Fig. 5: [Higher is better] Sensitivity of the AUC with respect to the embedding vector dimension for SalaDP-anonymized datasets.
each edge’s posterior of being fake or original given its
plausibility. If the former is higher than the latter, then we
predict the edge to be fake, effectively performing a maximum
a posteriori (MAP) estimate. This means GMM and MAP
estimate provide us with a concrete threshold to determine
whether an edge is fake given the observed data.
Gaussian Mixture Model: To formally deﬁne our GMM, we
ﬁrst introduce two random variables: B and S. B represents
whether an edge is original (B = 0) or fake (B = 1), while S
represents the plausibility of an edge. The probability density
function of our GMM is formally deﬁned as: