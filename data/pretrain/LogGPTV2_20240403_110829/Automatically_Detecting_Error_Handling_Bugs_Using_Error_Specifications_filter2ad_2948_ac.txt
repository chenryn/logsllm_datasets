performed for exit functions inside checkPreCall.
To check the satisﬁability conditions of Algorithm 2
and Algorithm 3, we use Clang’s built-in constraint
solver.
running it on large projects
Outputs. EPEX can be run on any single source
ﬁle (say,
foo.c) using the command clang -cc1
-analyze -analyzer-checker=EPEx foo.c.
For
like OpenSSL,
mbedTLS, etc. we used Clang’s scan-build utility
such that EPEX can be run as part of the regular build
process.
Scan-build overrides different environment
variables (e.g., CC, CPP) to force the build system (e.g.,
make) to use a special compiler script that compiles
the input source ﬁle and invokes EPEX on it. We pass
the -analyze-header option to the clang analyzer
USENIX Association  
25th USENIX Security Symposium  351
7
core to ensure that the functions deﬁned in any included
header ﬁles are also analyzed.
The output of EPEX contains one line for each ana-
lyzed error path, as shown in Table 3. Each line in the
output has four components: name of the caller function,
call-site of FT, candidate error-handling location (i.e. re-
turn instruction, exit call or error logging), and EPEX’s
diagnosis about whether the error has been handled cor-
rectly or not. As each output line represents an error
path and multiple error paths may pass through the same
call-site, a call-site for a given FT might be repeated in
the output. For example, lines 1 and 2 in Table 3 have
the same call-site (ssl_lib.c:1836) but their error handling
locations are different (ssl_lib.c:1899 and ssl_lib.c:1905
respectively). Note that we implement Step-III as a sep-
arate script and execute it on the output of EPEX before
producing the ﬁnal bug report.
Table 3: Sample EPEx output for OpenSSL function under test:
RAND_pseudo_bytes.
Call-site
ssl_lib.c:1836
ssl_lib.c:1836
d1_srvr.c:1683
Error Handling
Location
ssl_lib.c:1899
ssl_lib.c:1905
d1_srvr.c:1736
Diagnosis
handled
unhandled
maybe_handled
Caller
Function
SSL_CTX_new
SSL_CTX_new
dtls1_send_ne-
wsession_ticket
5 Results
5.1 Study subjects
To check whether errors are handled correctly in differ-
ent functions of popular SSL/TLS libraries as well as ap-
plications using them, we ran EPEX on four libraries:
OpenSSL, GnuTLS, mbedTLS (formerly known as Po-
larSSL), and wolfSSL (formerly known as cyaSSL), and
ﬁve applications that use OpenSSL: cURL, mod_ssl
of the Apache HTTP server, Lynx, Mutt, and Wget (see
Table 4). For the libraries, we primarily focused on the
source ﬁles implementing core functionality (e.g., src, lib
sub-directories, etc.) as opposed to the test ﬁles, as de-
tecting bugs in the test code may not be a high prior-
ity. All the applications but the HTTP server were small
enough to run EPEX on the entire program, although it
eventually only produced results for the source ﬁles that
used the OpenSSL library. For Httpd we only checked
mod_ssl. The second column of Table 4 shows the
modules investigated by EPEX for each tested library.
For each library, we generate a call graph using a tool
named GNU cflow 1. From the call graph, we choose
top functions that are frequently called by other func-
tions within the same library. Note that here we did
not distinguish between internal library functions and
1http://www.gnu.org/software/cﬂow/
library functions exposed to the outer world as APIs.
We further ﬁltered out functions based on their return
types—functions returning integer, boolean, and pointers
are chosen because Clang’s symbolic analysis engine can
currently only handle these types. In addition, we only
selected those functions that can fail and return at least
one error value. For the applications, we tested all the
OpenSSL APIs that the applications are using. We found
such APIs by simply using grep. Further, we only chose
those APIs for which documentations are available, and
the APIs that could return errors as integers, booleans or
pointers. The third column of Table 4 shows the number
of functions tested for a studied program.
Table 4: Study subjects
Projects
Modules
OpenSSL v1.0.1p
GnuTLS v3.3.17.1
mbedTLS v1.3.11
wolfSSL v3.6.0
curl v7.47.0
httpd v2.4.18
lynx v2.8.8
mutt v1.4.2.3
wget v1.17.1
Total
ssl, crypto
src, lib
library
wolfcrypt, src
all
mod_ssl
all
all
all
#Functions
tested
46
50
37
20
17
14
3
3
5
195
#Call
sites
507
877
505
138
49
86
23
9
13
2207
#Error
paths
3171
3507
1621
418
2012
4368
494
5
2409
18005
5.2 General ﬁndings
We evaluated EPEX on 195 unique program-API func-
tion pairs from 2207 call-sites, and covered 18005 er-
ror paths (see Table 4). EPEX found 102 new error-
handling bugs from 4 SSL/TLS libraries and 5 applica-
tions: 48 bugs in OpenSSL, 23 bugs in GnuTLS, 19 bugs
in mbedTLS, and 0 bugs in wolfSSL, 2 in cURL, 7 in
httpd, 1 in Lynx, 2 in Mutt, and 0 in Wget (see Table 5).
We evaluate EPEX’s performance after completion of
Step-II and Step-III separately. Since we are using re-
cent versions of real code, and ﬁnding all potential bugs
in such code is an extremely difﬁcult problem, we do not
have a ground truth for bugs against which to compare
the reports. Also, EPEX is not designed to detect all
types of error handling bugs. For this paper, we deﬁne a
bug to be any error path whose output behavior is identi-
cal to that of a non-error path, e.g., no logging takes place
and the same values as in the non-error paths are propa-
gated upwards through all channels. Thus, for counting
false positives and negatives, we do not consider bugs
due to incomplete handling, for example, where failures
are only logged, but the required cleanup is missing. Ta-
ble 5 presents the detailed result. After Step-II, EPEX
reported 154 bugs in the library code and 29 bugs in the
application code. After a manual investigation, we found
61 of them to be false positives. Step-III reduced this
false positive to 28 out of 130 reported bugs (106 in li-
brary and 24 in application code). Thus, overall, EPEX
352  25th USENIX Security Symposium 
USENIX Association
8
detected bugs with 84% precision in the library code and
50% precision in the application code with an overall
precision of 78%.
In general, measuring false negatives for static analy-
sis tools is non-trivial as it is hard to be conﬁdent about
the number of bugs present in the code at any given point
of time. However, for the sake of completeness, we
checked false negatives by randomly selecting 100 cases
at the end of Step-II, where EPEX conﬁrmed that error
handling was indeed implemented correctly. We did not
ﬁnd any false negatives in any of those examples, i.e. we
did not ﬁnd any bugs that were ﬁltered out at Step-II.
However, after Step-III’s optimization, among the bugs
that did pass Step-II, we found 15 and 5 false negatives
in Library and Application code respectively. Thus, the
overall recall of EPEX was approximately 83%.
Table 5: Evaluation of EPEX
Step II
Step III
Summary
Reported
Bugs
False
+ve
Reported
Bugs
False
+ve
True
Bugs
Prec-
ision
51
41
35
27
154
6
13
5
3
2
29
183
2
15
16
7
40
2
6
2
1
1
12
52
50
25
21
10
106
4
13
3
3
1
24
130
2
1
2
2
16
2
6
2
1
1
12
28
48
23
19
0
90
2
7
1
2
0
12
102
0.96
0.96
0.90
0.80
0.84
0.5
0.53
0.33
0.67
0.00
0.50
0.78
Library
OpenSSL
GnuTLS
mbedTLS
WolfSSL
Total
Application
Curl
Httpd
Lynx
Mutt
Wget
Total
Grand Total
In general, EPEX performs better for libraries than ap-
plications. There are three main reasons behind this: (i)
unlike libraries, applications’ error handling behavior is
heavily dependent on their conﬁguration parameters. For
example, users can conﬁgure the applications to ignore
certain errors. EPEX currently cannot differentiate be-
tween paths that have different values for these conﬁgu-
ration parameters; (ii) Applications are more likely to use
complex data types (e.g., error code is embedded within
an object) for propagating errors than libraries that are
not currently supported by EPEX; and (iii) Applications
prioritize user experience over internal consistency, so
if the error is recoverable, they will attempt to use a fall-
back non-error value instead. However, none of these are
fundamental limitations of our approach. EPEX can be
enhanced to support such cases and improve its accuracy
for applications too.
In the following section, we discuss the nature of the
detected bugs and the vulnerabilities caused by them in
detail with code examples from libraries in Section 5.3
and from applications in Section 5.4. All the described
bugs have been reported to the developers, who, for
almost all cases, have conﬁrmed and agreed that they
should be ﬁxed.
5.3 Bugs in libraries
From the four SSL/TLS libraries that we tested, we de-
scribe seven selected examples. They arise due to various
reasons including ignoring error codes, missing checks
for certain error codes, checking with a wrong value,
and propagating incorrect error values upstream. These
bugs affect different modules of the SSL/TLS implemen-
tations, and at least 42 of them result in critical security
vulnerabilities by completely breaking the security guar-
antees of SSL/TLS, as discussed below.
Incorrect random number generation.
EPEX found
21 instances in OpenSSL where callers of the func-
tion RAND_pseudo_bytes do not implement the er-
ror handling correctly. We provide two such exam-
ples below.
RAND_pseudo_bytes returns cryp-
tographically secure pseudo-random bytes of the de-
sired length. An error-free execution of this func-
tion is extremely important to OpenSSL as the secu-
rity guarantees of all cryptographic primitives imple-
mented in OpenSSL depend on the unpredictability of
the random numbers that RAND_pseudo_bytes re-
turns. The cryptographically secure random numbers,
as returned by RAND_pseudo_bytes, are used for
diverse purposes by different pieces of OpenSSL code,
e.g., creating initialization vectors (IVs), non-repeatable
nonces, cryptographic keys.
In case of a failure,
RAND_pseudo_bytes returns 0 or −1 to indicate any
error that makes the generated random numbers insecure
and unsuitable for cryptographic purposes.
Example 1.
1
2
3
4
5
6
int PEM_ASN1_write_bio(...)
{
int ret = 0;
...
/* Generate a salt */
if (RAND_pseudo_bytes(iv, enc->iv_len) <
0)
goto err;
...
ret = 1;
err:
7
8
9
10
11
12
13
14
Example 2.
}
OPENSSL_cleanse(iv, sizeof(iv));
...
return ret;
int bnrand(...)
{
goto err;
int ret = 0;
...
if (RAND_pseudo_bytes(buf, bytes) == -1)
...
ret = 1;
...
return ret;
err:
}
1
2
3
4
5
6
7
8
9
10
11
12
9
USENIX Association  
25th USENIX Security Symposium  353
two examples of
The above code shows
error handling at different
in-
call-sites of
correct
In Ex-
RAND_pseudo_bytes in OpenSSL code.
ample 1, function PEM_ASN1_write_bio checks
In Example 2, function
only if < 0, but not if = 0.
bnrand only checks for the −1 value but not for the
0 value. bnrand is used by all bignumber routines,
which are in turn used for key generation by many
cryptographic implementations like RSA. These bugs
completely break the security guarantees of any crypto-
graphic implementations (RSA, AES, etc.) and security
protocol
implementations (e.g., SSL/TLS, SMIME,
etc.) in OpenSSL that use such buggy code for random
number generation. An attacker can leverage these
bugs to launch man-in-the-middle attacks on SSL/TLS
connections setup using OpenSSL.
The sources of errors in random number generation
functions are diverse and depend on the underlying ran-
dom number generation mechanism (see Listing 3 in the
Appendix for a sample random number generation im-
plementation in OpenSSL). For example, an error can
occur due to memory allocation failures or module load-
ing errors. Note that some of these failures can be trig-
gered remotely by an attacker through denial-of-service
attacks. Thus, if the errors are not handled correctly, an