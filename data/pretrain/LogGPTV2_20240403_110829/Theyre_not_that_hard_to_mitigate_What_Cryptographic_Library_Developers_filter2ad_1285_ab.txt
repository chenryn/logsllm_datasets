SSL/TLS channels using padding oracle attacks [14]. In 2011,
B. Brumley and Tuveri showed that such remote attacks are
still possible [15]; i.e., that the underlying weaknesses in the
OpenSSL library had not been suitably fixed. SSL libraries
continued to be the target of timing attacks; examples include
the “Lucky 13” attack by AlFardan and Paterson, which ex-
ploits timing variation in the processing of padding in the CBC
mode of operation in multiple common SSL/TLS libraries [16]
similar in principle to the paper by Canvel et al. [14]. In
2015, Albrecht and Paterson presented a variant of the attack
targeting Amazon’s s2n implementation of TLS [17]. In 2016,
Yarom, Genkin, and Heninger presented the “CacheBleed”
attack, which showed that the “scatter-gather” implementation
technique recommended by Intel [18] and implemented in
OpenSSL as cache-timing attack countermeasure, is insuffi-
cient to thwart attacks [19]. In the same year, Kaufmann et
al. showed that even carefully implemented C code may be
translated to binaries that are vulnerable to timing attacks [20].
We conclude this paragraph with a few attacks related to
certification and standardization. Certification schemes such
as Common Criteria often require certified products to have
countermeasures to a range of side-channel attacks, including
timing attacks. However, certified hardware did not avoid be-
ing a target of timing attacks, as shown by the recent Minerva
group of vulnerabilities in ECDSA implementations, including
a Common Criteria certified smartcard [21]. In recent years,
various timing attacks were proposed against implementations
of post-quantum cryptography (PQC) including attacks against
the BLISS signature scheme used in the strongSwan IPsec
implementation [22]–[24] and attacks against candidates in
NIST’s PQC standardization effort [25]–[27].
Despite all these academic timing attacks, their practical ex-
ploitability is often questioned by practitioners. Security Audit
companies try to catch timing vulnerabilities in software [28].
However, they make the following statements:
“Even though there is basic awareness of timing side-
channel attacks in the community, they often go unnoticed
or are flagged during code audits without a true under-
standing of their exploitability in practice.”
B. Tools included in the survey
We provide a brief overview of the tools considered in our
survey. We classify tools according to the broad approach they
use: runtime statistical tests, dynamic-instrumentation based,
or formal-analysis based. Our approach as well as our choice
of included tools is based on an earlier paper [8], but amended
with tools some authors know to be in current use.
Broadly speaking, statistical test tools [29] compute the
execution time of a large number of runs of the target program
and verify whether secret data influences the execution time.
These tools are generally easy to install and run, even at scale,
and operate on executable code, ruling out the possibility
of compiler-induced violations of the constant-time policy.
However, they only provide weak, informal guarantees.
In contrast, dynamic instrumentation based tools [6], [30]–
[41] instrument programs to track how information flows
during (concrete or symbolic) execution of programs. They
are generally reasonably easy to install and to use, even at
scale, and can be implemented at source, intermediate, or
assembly levels, and provide formal guarantees. However, as
with all tools based on dynamic techniques, these guarantees
are generally limited; for instance, dynamic analysis of loops
may be unsound, i.e., miss constant-time violations.
Finally,
formal-analysis-based tools
[42]–[52] provide
strong guarantees that programs do not violate constant-
timeness; in addition, some tools are precise, in that they only
reject programs that violate constant-timeness. Their other
criterion is soundness, which ensures the absence of constant-
time violations. However, these tools are often implemented
at source or intermediate levels, frequently require user inter-
action, and are sometimes hard to install or use at scale.
Table I presents some key tools and summarizes their main
characteristics. Since our focus is not an in-depth technical
comparison of the features of the tools, we deliberately keep
descriptions simple, and only consider their target and whether
they provide some formal guarantees (No, Partial, Yes, Other).
For the cognizant, “Partial guarantees” cover tools that perform
dynamic analysis, whereas “Guarantees” cover tools that are
sound and detect all constant-time violations; in particular,
our classification does not reflect if tools are precise. Even for
such coarse criteria, classification is sometimes challenging
so we err on the generous side. Finally, we tag tools as
“Other” if they establish another property than constant-time;
comparing these properties with constant-time is often tricky,
so we choose not to qualify the difference.
While the CoCo-Channel authors wrote [33]: “We also
evaluate CoCo-Channel against two recent tools for detecting
side-channel vulnerabilities in Java applications, Blazer and
Themis. Neither are publicly available[...]”, their tool was not
found by us either.
We do not claim our list to be comprehensive, especially in
this currently active field of research. In particular, we did not
ask about Constantine [54], Pitchfork-angr [55], Cachefix [56],
and ENCoVer [57], just to name a few.
C. Libraries included in the survey
Cryptographic libraries have diverse threat models, but
with their usual use in protocols like TLS and connected
applications often running on shared hardware, resistance
against timing attacks is an important property. In our survey,
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:37:33 UTC from IEEE Xplore.  Restrictions apply. 
634
Tool
ABPV13 [42]
Binsec/Rel [30]
Blazer [43]
BPT17 [31]
CacheAudit [44]
CacheD [32]
COCO-CHANNEL [33]
ctgrind [6]
ct-fuzz [34]
ct-verif [45]
CT-WASM [46]
DATA [35], [36]
dudect [29]
FaCT [47]
FlowTracker [48]
haybale-pitchfork [37]
KMO12 [49]
MemSan [38]
MicroWalk [39]
SC-Eliminator [53]
SideTrail [50]
Themis [51]
timecop [40]
tis-ct [41]
VirtualCert [52]
C
Target
Binary
Java
C
Techn.
Formal
Symbolic
Formal
Symbolic
Formal
Binary
Symbolic
Trace
Symbolic
Java
Dynamic
Binary
LLVM Dynamic
LLVM
Formal
WASM Formal†
Dynamic
Binary
Binary
Statistics
Formal†
DSL
LLVM
Formal
LLVM Symbolic
Binary
Formal
LLVM Dynamic
Binary
Dynamic
Formal†
LLVM
Formal
LLVM
Java
Formal
Dynamic
Binary
Symbolic
Formal
C
x86
(cid:32)
(cid:71)(cid:35)
(cid:32)
(cid:71)(cid:35)
■
(cid:35)
(cid:32)
(cid:71)(cid:35)
(cid:35)
(cid:32)
(cid:32)
(cid:71)(cid:35)
(cid:35)
(cid:32)
(cid:32)
(cid:71)(cid:35)
■
(cid:71)(cid:35)
(cid:71)(cid:35)
(cid:32)
■
(cid:32)
(cid:71)(cid:35)
(cid:71)(cid:35)
(cid:32)
Targets: LLVM - intermediate representation, DSL - domain-specific language,
WASM - Web Assembly
Technique: † - also performs code transformation/synthesis
Guarantees: (cid:32) - sound, (cid:71)(cid:35) - sound with restrictions, (cid:35) - no guarantee, ■ -
other property
TABLE I
CLASSIFICATION OF TOOLS INCLUDED IN THE SURVEY.
we invited developers of all widely used TLS libraries and
other smaller but popular libraries and relevant primitives.
We focused on libraries implemented in C/C++ as it is the
target language of most tools and the most used language for
cryptographic libraries. However, we included some libraries
implemented in Java, Rust and Python if some tools can
analyse them or they contain parts implemented in C.
Our choice of libraries is underpinned not only by our
knowledge of them but also by quantitative data of user
and developer numbers. We included some newer primitives
not (yet) fulfilling this criterion to complement the answers
given by the first group. Nemec et al. [58] gave numbers for
OpenSSL: “The prevalence of OpenSSL reaches almost 85%
within the current Alexa top 1M domains and more than 96%
for client-side SSH keys as used by GitHub users.” We only
included libraries with an open development model to allow
us to get data for our recruiting choice.
Table II contains a list of libraries included in the survey
and whether at least one of their developers participated in our
survey. The table also lists the actions that the libraries perform
in their Continuous Integration (CI) pipelines. We draw this
information from documentation and the public CI pipelines
of the libraries. One author extracted this, a second author
double-checked, with disagreements discussed and resolved.
D. Additional Related Work
Having already discussed timing attacks and tools for
constant-time analysis, we briefly cover other related work.
Guarantees
Library
Particip.
Build
Test
Continuous integration
Fuzz‡
CT test
OpenSSL
LibreSSL
BoringSSL
BearSSL
Botan
Crypto++
wolfSSL
mbedTLS
Amazon s2n
MatrixSSL
GnuTLS
NSS
libtomcrypt
libgcrypt
Nettle
Microsoft SymCrypt
Intel IPP crypto
cryptlib
libsecp256k1
NaCl
libsodium
monocypher
BouncyCastle*
OpenJDK
dalek-cryptography†
ring†
RustCrypto†
rustls†
python-ecdsa
micro-ecc
tiny-AES-c
PQCrypto-SIDH
csidh
constant-csidh-
c-implementation
ARMv8-CSIDH
SPHINCS+
Total = 36
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓