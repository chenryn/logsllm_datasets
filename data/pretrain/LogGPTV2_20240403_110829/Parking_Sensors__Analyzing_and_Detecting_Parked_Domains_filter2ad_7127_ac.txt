is a big threat to their business model. For each investigated
service, we tested whether the domains parked with them tried
to detect or bypass the workings of ad-blocking extensions.
Note that since these services have full control of their parked
domains, the discovery of a parked domain being involved in a
speciﬁc practice equates to the parking service being involved
in that same practice. Overall, we discovered that 2 out of the
15 studied services attempted to detect and bypass advertising
blockers.
a) NameDrive: NameDrive ships their parked websites
with an additional detection mechanism for ad blockers. They
include an external ﬁle called advertisements.js. However,
unlike the ﬁle name suggests, this ﬁle does not contain any
code related to advertisements: it is just a single statement
that sets a variable to false. This ﬁle is basically a honeypot
for ad blockers: it deliberately attempts to trigger the blocking
of resources by exposing a very obvious advertising-related
ﬁlename for its JavaScript code. The ﬁle is detectable by
in the EasyList [1]
the "/advertisements." present
blacklist, one of the most common blacklists used by a range
of ad-blocking extensions,
including the popular AdBlock
Plus. Later on, another script included on the page veriﬁes
if the variable was actually set
to false or not. If not,
the user is automatically redirected to a completely different
website for PPR monetization, as described in Section III-F,
since no money can be made from this user from regular
PPC advertising schemes. As such, we expect the number of
redirections to be higher for users browsing with ad-blocking
extensions.
b) Fabulous.com: Websites parked with Fabulous con-
tain JavaScript code that veriﬁes whether the JavaScript object
named google exists. This object is normally initialized by
a Google Adsense script
included in the parked page. If
this object does not exist, one can reasonably assume that
advertisements are blocked. Subsequently, the web page reacts
by creating iframes with content generated from other Fabulous
pages. The generated content contains internal advertisement
links, which when clicked, eventually redirect the user to the
websites of advertisers.
H. Summary of Findings
By analyzing more than 8 million parked domains, hosted
with 15 different services, we found that the lion’s share of
the domain parking ecosystem is under the control of a small
fraction of the involved entities. For instance, we discovered
that the majority of domains are in the hands of a small
fraction (16%) of all domain owners, and that just the three
most popular parking services are accommodating over 60% of
the examined domains. This trend continues when it comes to
the monetization through advertisements, as a single, popular,
advertising syndicator provides PPC ads for 90%±1.1% of all
visits to parked domains. Since only a handful of parties is
responsible for the majority of the ecosystem’s monetization
chain, we argue that a change in policy or the business
model of these large players, could drastically and effectively
inﬂuence the domain parking scene.
In terms of abuse, we found that only one parking service
did not
include typosquatting domains in their managing
portfolios, with all other services accepting and proﬁting
from these abusive domains. Speciﬁcally, through automatic
measurements, we conservatively estimated that a service’s
domain portfolio may contain over 4% typosquatting domains.
In a more in-depth manual sample analysis, however, we found
16%±3.2% of parked domain names to be either trademark
or typosquatting abuse. A reasonable assumption is that ty-
posquatting domains receive more visitors than most generic
parked domain names, thus contributing to a large extent to
the proﬁts generated in the domain parking industry. As such,
foregoing the proﬁts associated with accepting typosquatting,
and other cybersquatting domains, is likely not something that
these services will do voluntarily.
Furthermore, we examined the Pay-Per-Redirect (PPR)
phenomenon, which is used as a secondary monetization
source, performed in 7%±0.9% of the visits to parked do-
mains. All ten services deploying this redirection strategy have
been found to unexpectedly send their visitors to malware-
laden websites, scams or explicit adult content. This phe-
nomenon shows that parking services are not reluctant
to
deploy malicious monetization strategies at the expense of user
safety.
IV. DETECTING PARKED DOMAINS
The previous section analyzed the ecosystem of domain
parking and mapped out the practices involved in their business
model. Based on our ﬁndings, we do not consider it much
of a stretch to claim that, at their current state-of-practice,
domain parking services act in a parasitic way. As such, it
is important to implement countermeasures in order to reduce
their prevalence or at least minimize the user’s exposure to
them. We approach this problem by proposing and developing
a classiﬁcation model that is able to detect parked pages. This
model is meant to be robust, meaning that it does not rely
on any parking services’ speciﬁcs, such as their speciﬁc name
servers, but rather relies on features inherent to the conceptual
operations of parked domains. Applications for this model exist
on various levels, e.g., it could be part of a search engine
crawler, where the detection could be used to discard parked
pages from their search results, or part of a browser extension
that detects and blocks parked pages when a browsing user
encounters one.
In this section, we walk through the construction of the
classiﬁcation model by describing how the data was gathered,
which features were used, how the model was tuned, and how
the classiﬁer was trained and evaluated.
A. Gathering data
We begun this process by ﬁrst obtaining a random sample
of 3,000 veriﬁed parked pages and 3,000 pages from the Alexa
top 1 million. We automatically veriﬁed that the sampled pages
from Alexa are not parked by examining their name servers and
ensuring that they do not match the name servers of any of the
studied parking services. Next, we crawled all 6,000 pages and
collected data from several different sources. More speciﬁcally,
we gathered the HTML source code of every loaded frame
recursively, recorded a trace of all HTTP requests initiated by
9
the web page (HAR), as well as the redirection chains of the
main page and every frame. Finally, we inspected properties
of the domain itself, such as typosquatting occurrence and
WHOIS records. From this data, we can extract discriminative
features that can serve as input for our classiﬁer.
B. Feature set
When creating features to detect parked pages, we try to
target the inherent nature of the parking services’ operation
model. This approach results in more robust detection, as
opposed to searching for traces of speciﬁc parking services
or looking for ﬁxed keywords.
We focus on detecting the omnipresence of third-party
advertising, dynamic and on-the-ﬂy page generation, lack of
content, malicious redirections, and abusive domains. In total,
we construct eleven HTML features, ﬁve HAR features, four
frame features and one domain feature. We elaborate on the
extraction of each feature and our rational for choosing them
in the following paragraphs:
HTML Features: The HTML features are extracted from the
source code of every loaded frame. From this code we can
analyze the content and the scripts deployed on the page.
•
•
•
Average and maximum link length. We count the
number of  elements present on the page and
measure the string length of the destination addresses.
From these numbers, we can calculate the average
and maximum link length of the page. The rationale
behind this feature is that advertisement links, which
usually form the majority on domain parked websites,
pass more and longer parameters along with the link
in order to track the click on the PPC ad. They might,
for example, include the publisher’s identiﬁer, the ﬁnal
link destination, tokens, timestamps, etc.
Average source length. Similar to the previous fea-
ture, source addresses for banners and other advertise-
ment media, tend to pass parameters of campaigns, im-
age dimensions, etc. We expect non-parked websites
to have more static media sources and thus shorter
address lengths.
External link and external source ratio. We deﬁne
an external link or source as one with an address point-
ing to a another domain. Links and media generated
by third-party advertisement syndicators will generally
reside on domains of that syndicator. We expect non-
parked websites to have a lower ratio of external links,
because they commonly also have links to pages and
media hosted on the same domain.
• Website directory presence. Since parked domains
are undeveloped websites that display content
that
is generated on-the-ﬂy, it is uncommon for them to
have dedicated directories on their website. We search
within the HTML source and link addresses for the
presence of a directory and use this as a boolean
feature.
Link-to-global text ratio. Many parked pages have
hardly any text on their page that is not part of a
link. On a typical parked page, text is either part
•
•
•
•
of an ad or part of the “Related links”. To assess
this characteristic, we extract all text from the HTML
pages with Python’s Natural Language Toolkit [16],
which omits the HTML tags and returns the textual
content. We compare the amount of text that resides
within links ( elements and their child nodes) to
the global amount of text present on the page.
Amount of non-link characters. To more robustly
test
the characteristic of the previous feature, we
incorporate an additional feature that counts the ac-
tual amount of characters not belonging to any link
element, instead of solely relying on the ratio.
Text-to-HTML ratio. We also measure the ratio of
text to the total amount of characters in the HTML ﬁle.
This feature focuses more on the dynamic generation
of content.
Redirection mechanisms Parked pages use redi-
rection mechanisms to lead visitors to other pages
or domains. Although non-parked pages might
also deploy such mechanisms, we still believe
that
this feature, when considered together with
other ones, can assist classiﬁcation. We detect
two different
feature
records the presence of JavaScript redirection code
by searching for window.location, while the
other ﬁnds HTML meta refreshes by looking for
http-equiv="refresh".
redirection methods. One
HAR Features: These features are derived from the HTTP
archive (HAR) that is constructed while loading a page. We
focus on the following discriminative characteristics of HTTP
requests:
•
•
•
•
Third-party requests ratio. We extract the number of
HTTP requests to third-parties (other domains) and the
total amount of requests. Next, we calculate the ratio
between those two. This feature is motivated by the
amount of third-party content and media generated on
parked pages. In addition, HTTP requests conducted
after redirecting to a different domain, are all con-
sidered third-party requests, with respect to the initial
domain.
Third-party data ratio. Similarly, we calculate the
ratio between data (number of bytes) coming from
third-party sources and all incoming data.
Third-party HTML content ratio. This feature fur-
ther incorporates the characteristics of third-party con-
tent. We expect most third-party content on regular
websites to be generally JavaScript libraries and media
ﬁles. Parked websites, however, are known to include
html/text content pulled from third-party services,
such as through the use of iframes generated by ad
syndicators. For this reason, we include a speciﬁc
feature that represents the ratio of HTML content
brought in by third-party requests.
Initial response size and ratio. For this feature,
we ﬁrst record the size of the initial response when
making the ﬁrst request to the web page. Next, we
compare this with the total amount of received data
10
after completely loading the website. This feature
attempts to capture the dynamic generation of content
on parked pages which is a core concept of the
modus operandi of domain parking services. With this
feature, we expect to identify the initial lightweight
page skeleton, which stands in contrast with the ﬁnal
amount of received data.
Frame Features: The following frame features are extracted
by tracking every loaded frame on the web page.
Amount of frames. While manually inspecting the
structure of parked pages, we found that the presence
of iframes is very common. In order to take this into
account, we recursively count all frames and iframes
present on a page and its child frames.
• Main frame and iframe redirections. The redirection
chain of every frame was tracked when we crawled
the domains. For every chain, we extract the number
of redirections that occur on the main frame as well
as all other frames. As noted in previous sections,
malicious redirects initiating at parked pages contain
many different trafﬁc distributors and redirection hops,
e.g., as shown in Figure 6. Thus, we expect a benign
redirection chain to consist of a limited amount of
intermediate steps.
Different ﬁnal domain. This feature checks if the
main frame (i.e.
the frame of which the address
is visible in the browser’s URL bar) was redi-
rected to a different domain. It excludes internal
redirections, such as from www.domain.com to
blog.domain.com, which is a more common redi-
rection process on regular websites.
•
•
•
Domain name feature: This feature focus on characteristics
inferred from the domain name itself.
Typosquatting domain. The current domain name is
checked for typosquatting abuse with the algorithm de-
scribed in III-C. Regular, authoritative websites should
not be ﬂagged by this feature.
C. Classiﬁcation
Our objective is to construct a classiﬁer that can reliably
detect parked websites when visiting them. When loading a
web page, the aforementioned features are extracted and are
treated as the features of a particular instance. The classiﬁ-
cation model’s goal is to take an unknown instance as input,
process the features, and assign a probability of that instance
belonging to a certain class. More speciﬁcally,
the model
calculates whether or not any given web page is likely a parked
one. Given these probabilities, a threshold value can be used to
actually classify the instance as either parked or non-parked.
This threshold can then be appropriately varied to tune the
sensitivity of the model.
In order to build the classiﬁer, we ﬁrst select an appropriate
learning algorithm for our model. Afterwards, this model needs
to be given a sufﬁcient amount of parked and non-parked
instances for it to learn from. Once a model is learned, we
can evaluate the performance of the classiﬁer with unseen test
instances.
11
1) Learning method: We aim for high interpretability of
our classiﬁer, as it is important to comprehend the prediction