# Title: An Empirical Study of Prioritizing JavaScript Engine Crashes via Machine Learning

## Authors
- Sunnyeo Park, KAIST
- Dohyeok Kim, KAIST
- Sooel Son, KAIST

## Abstract
Early detection of security bugs in JavaScript (JS) engines is crucial for protecting Internet users from adversaries exploiting zero-day vulnerabilities. Browser vendors, bug bounty hunters, and security researchers use advanced fuzzers and their domain expertise to find such security bugs. A crash during the execution of a JS test is often an early indicator of a potential bug. However, determining whether a crash indicates a security bug is challenging, especially for unskilled bug reporters. Currently, this classification process is entirely manual and relies on the verdicts from JS engine vendors.

In this study, we investigated the feasibility of using various machine learning classifiers to determine if a crash triggers a security bug. We designed and implemented CRScope, a tool that classifies security and non-security bugs from given crash-dump files. Our experimental results, based on 766 crash instances, show that CRScope achieved Area Under Curve (AUC) values of 0.85, 0.89, and 0.93 for Chakra, V8, and SpiderMonkey crashes, respectively. Additionally, CRScope achieved precision values of 0.84, 0.89, and 0.95 for Chakra, V8, and SpiderMonkey crashes, respectively. These results outperform previous studies and existing tools like Exploitable and AddressSanitizer. CRScope can learn from past verdicts on reported bugs and automatically classify JS engine security bugs, thereby improving the scalable classification of security bugs.

## CCS Concepts
- **Security and Privacy**: Domain-specific security and privacy architectures; Browser security
- **Computing Methodologies**: Machine learning

## Keywords
- Crash analysis
- Machine learning
- Security bugs
- JavaScript
- Browser security

## ACM Reference Format
Sunnyeo Park, Dohyeok Kim, and Sooel Son. 2019. An Empirical Study of Prioritizing JavaScript Engine Crashes via Machine Learning. In *ACM Asia Conference on Computer and Communications Security (AsiaCCS '19)*, July 9â€“12, 2019, Auckland, New Zealand. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3321705.3329840

## 1 Introduction
Security bugs in popular web browsers pose a significant threat to billions of Internet users. Adversaries exploit zero- or one-day vulnerabilities to exfiltrate sensitive information, perform remote code execution, and bypass sandbox policies. According to Kaspersky Lab's 2018 statistics, web browsers are the second most frequently exploited applications, accounting for one-fourth of all observed attacks.

Among browser components, the JavaScript (JS) engine is the most frequently targeted by adversaries. The majority of websites (95.2%) use JavaScript, and its Turing-complete nature allows adversaries to compose attack code. JS engines have become increasingly complex with the addition of HTML5 features, making them attractive targets for exploitation.

Browser vendors rely on tech-savvy users, bug bounty hunters, and security researchers to report these security bugs. They also use state-of-the-art fuzzers and cloud computing resources to find defects. Bug Tracking Systems (BTSs) are used to track and reward bug reporters. Promptly patching security bugs is critical, so vendors ask reporters to label whether their reports are security-related. This process requires domain expertise, making it manual and non-scalable. False positive reports waste engineering resources, and mislabeling security bugs delays proper patching, providing opportunities for attackers.

Previous studies have focused on pinpointing bug locations, determining exploitability, and processing natural language in bug reports. Tools like Exniffer, Exploitable, and AddressSanitizer determine the exploitability of crashes but do not classify security bugs in JS engines. In this paper, we demonstrate that these tools are unsuitable for classifying security bugs in JS engines and introduce CRScope, a new tool that leverages machine learning to classify security bugs.

### Contributions
- We demonstrate that off-the-shelf tools like Exploitable and AddressSanitizer are unsuitable for classifying security bugs in JS engines.
- We build the first well-labeled dataset containing 165 security and 174 non-security JS engine bugs, along with their JS test code and crash-dump files. The dataset is available at https://github.com/WSP-LAB/CRScope.
- We design, implement, and evaluate CRScope, the first tool to classify JS engine security bugs via machine learning, achieving AUCs of 0.85, 0.89, and 0.93 for Chakra, V8, and SpiderMonkey crashes, respectively.

## 2 Background and Motivation

### 2.1 Security and Non-Security Bugs
JS engines, such as V8 for Google Chrome, JavaScriptCore for Apple Safari, SpiderMonkey for Mozilla Firefox, and Chakra for Microsoft Internet Explorer/Edge, are interpreters that execute JS code. These engines are frequent targets for adversaries due to their widespread use and the increasing complexity of HTML5 features. Zero-day or one-day vulnerabilities in JS engines pose a critical threat, as adversaries can exploit them by luring victims to visit webpages with malicious JS code, leading to remote code execution.

Browser vendors, including Google, Mozilla, and Microsoft, offer substantial rewards for reporting security bugs. Zerodium pays even more for these vulnerabilities. The monetary incentives and research interests have led to a significant number of reported bugs, such as 161 Chrome CVEs in 2018 alone.

Each browser vendor has developed a Bug Tracking System (BTS) to manage and track reported bugs. BTSs require specific details when a new bug is filed, including the component affected, whether the bug causes a crash, and whether it is security-related. This security label is crucial for prioritizing patches, as vendors aim to address security-related bugs within 90 days of public disclosure. Mislabeling can lead to delayed patching, as seen in two Chrome bug reports that were initially filed as non-security bugs but later found to be security-related after several months.

To make the prioritization process prompt and scalable, we propose CRScope, which uses machine learning models trained on past verdicts to classify security bugs without requiring domain-specific expertise.

### 2.2 Crash-Dump
Fuzzing is a common technique for finding JS engine bugs. It generates invalid or unexpected input to a program and monitors for crashes. When a bug causes a JS engine to crash, the operating system creates a crash-dump file, which contains a snapshot of the process state at the time of termination, including main memory, CPU registers, and terminal signals. Crash-dumps are used for debugging and triaging the cause of a crash.

Tools like Exploitable and AddressSanitizer analyze crash-dumps to determine the exploitability of a bug. Exploitable is a gdb extension that inspects the state of a crashed Linux application and classifies the difficulty of exploitation. AddressSanitizer assigns a memory corruption label to a crash, which is used by Mozilla and Google to rate the security severity. However, these tools are designed to gauge exploitability, not to classify security bugs. Our experiments show that Exploitable and AddressSanitizer are not suitable for classifying security bugs in JS engines, producing high false positive and false negative rates.

To address these shortcomings, we designed and implemented CRScope, which leverages machine learning to classify security bugs in JS engines. CRScope can be used by both novice and experienced users to confidently report security bugs and help vendors filter spurious bug reports.

## 3 Dataset
CRScope is a binary classifier that assigns "security bug" or "non-security bug" labels to JS engine crash-dump files. To train the classifier, we built a ground truth dataset of manually classified JS engine crash-dump files. We collected past classification verdicts from BTSs and GitHub repositories for V8, SpiderMonkey, and Chakra.

### Collecting PoCs
For security bugs, we collected CVEs with Proof of Concept (PoC) code reported between 2011 and 2018. From each Chakra release note in the GitHub repository, we collected patched CVEs. From the Chrome BTS, we collected bug reports, each of which...