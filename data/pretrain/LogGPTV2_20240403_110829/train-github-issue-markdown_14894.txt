**Apache Airflow version** : 2.0.0
**What happened** :
While investigating issues relating to task getting stuck, I saw this sql
error in postgres logs. I am not entirely sure of what it impacts but I
thought of letting you know.
    ERROR:  column "connection.password" must appear in the GROUP BY clause or be used in an aggregate function at character 8
    STATEMENT:  SELECT connection.password AS connection_password, connection.extra AS connection_extra, connection.id AS connection_id, connection.conn_id AS connection_conn_id, connection.conn_type AS connection_conn_type, connection.description AS connection_description, connection.host AS connection_host, connection.schema AS connection_schema, connection.login AS connection_login, connection.port AS connection_port, connection.is_encrypted AS connection_is_encrypted, connection.is_extra_encrypted AS connection_is_extra_encrypted, count(connection.conn_id) AS count_1 
            FROM connection GROUP BY connection.conn_id 
            HAVING count(connection.conn_id) > 1
    ERROR:  current transaction is aborted, commands ignored until end of transaction block
    STATEMENT:  SELECT connection.password AS connection_password, connection.extra AS connection_extra, connection.id AS connection_id, connection.conn_id AS connection_conn_id, connection.conn_type AS connection_conn_type, connection.description AS connection_description, connection.host AS connection_host, connection.schema AS connection_schema, connection.login AS connection_login, connection.port AS connection_port, connection.is_encrypted AS connection_is_encrypted, connection.is_extra_encrypted AS connection_is_extra_encrypted 
            FROM connection 
            WHERE connection.conn_type IS NULL
**How to reproduce it** :
  1. Run `docker-compose run initdb`
  2. Run `docker-compose run upgradedb`
Here's my docker-compose
    version: "3.2"
    networks:
        airflow:
    services:
        postgres:
            container_name: af_postgres
            image: postgres:9.6
            environment:
                - POSTGRES_USER=airflow
                - POSTGRES_DB=airflow
                - POSTGRES_PASSWORD=airflow
            volumes:
                - ./postgresql/data:/var/lib/postgresql/data
            command: >
                postgres
                -c listen_addresses=*
                -c logging_collector=on
                -c log_destination=stderr
            networks:
                - airflow
        initdb:
            container_name: af_initdb
            image: docker.io/apache/airflow:2.0.0-python3.7
            environment:
                - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
            depends_on:
                - postgres
            entrypoint: /bin/bash
            command: -c "airflow db init"
            networks:
                - airflow
        upgradedb:
            container_name: af_upgradedb
            image: docker.io/apache/airflow:2.0.0-python3.7
            environment:
                - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
            depends_on:
                - postgres
            entrypoint: /bin/bash
            command: -c "airflow db upgrade"
            networks:
                - airflow
**Anything else we need to know** :
Upon looking the code, I believe having `Connection.conn_id` here will resolve
the sql syntax error.