- 数据按 位/条带 并行传输到多个磁盘上，同时校验数据存放到专用校验盘上
![批注 2020-02-08 205227](/assets/批注%202020-02-08%20205227.png)
### RAID5
- 数据按条带分布在不同磁盘上，校验信息被均匀分散到各磁盘上
![批注 2020-02-08 205428](/assets/批注%202020-02-08%20205428.png)
### RAID6
为每4 位数据存储2 位的冗余信息，这样系统可容忍两张磁盘 发生故障
### RAID10
- 结合RAID1和RAID0，先镜像，再条带化
![批注 2020-02-08 205601](/assets/批注%202020-02-08%20205601.png)
### RAID01
- 结合RAID0和RAID1，先条带化, 再镜像
![批注 2020-02-08 205654](/assets/批注%202020-02-08%20205654.png)
只能容忍一个磁盘故障，如0号盘损坏，左边RAID0失效，只能使用右边的RAID0，不能再有盘损坏，故冗余度为1
### 实现方式
- 软件RAID
  - 功能都依赖于主机CPU完成,没有第三方的控制处理器和I/O芯片
- 硬件RAID
  - 专门RAID控制处理器和I/O处理芯片处理RAID任务，不占用主机CPU资源
在空闲时期，控制器会对每张磁盘的每一个厨区进行读取，如果发现某个扇区无法读取，会从其余磁盘中进行恢复
一些硬件RAID实现允许热交换：在不切断电濒的情况下梅出错磁盘用新的磁盘替换
### 比较
![批注 2020-02-08 205826](/assets/批注%202020-02-08%20205826.png)
### 选择考量
- 所需的额外存储代价
- 在IO方面的性能问题
- 磁盘故障时的性能：例如，在RAID 5中，当一个硬盘故障时，RAID控制器需要对数据进行重建，这可能导致性能下降
- 数据重建过程：当一个硬盘故障时，RAID控制器需要将数据从其他硬盘中重建。数据重建可能需要很长时间
## 存储技术的趋势
- 价格和性能折中
- 不同存储技术的价格与属性以不同的速率变化
## 对程序数据引用的局部性
## 取指令的局部性
## 多体交叉存储器
其基本思想是在不提高存储器速率、不扩展数据通路位数的前提下，通过存储芯片的交叉组织，提高CPU单位时间内访问的数据量，从而缓解快速的CPU与慢速的主存之间的速度差异。
### 高位多体交叉存储器
![批注 2020-01-16 113946](/assets/批注%202020-01-16%20113946.png)
### 低位多体交叉存储器
![批注 2020-01-16 113919](/assets/批注%202020-01-16%20113919.png)
![批注 2020-02-08 161132](/assets/批注%202020-02-08%20161132.png)
## 高速缓存存储器
内存中的指令、数据，会被加载到 L1-L3 Cache 中，而不是直接由 CPU 访问内存去拿
CPU 从内存中读取数据到 CPU Cache 的过程中，是一小块 Cache Line 来读取数据的，而不是按照单个数组元素来读取数据的，大部分 Cache Line的大小通常是64个字节，[Disruptor](/编程语言/JAVA/JAVA并发编程/Disruptor.md#Disruptor) 利用了这点
### cache的工作过程
![批注 2020-02-08 161925](/assets/批注%202020-02-08%20161925.png)
- 如何判断数据在Cache中?
- Cache中的数据是有效吗？（DMA【直接存储访问】修改主存）
![批注 2020-02-08 162227](/assets/批注%202020-02-08%20162227.png)
### cache地址映射机制
![批注 2020-02-08 162555](/assets/批注%202020-02-08%20162555.png)
![内存地址到 Cache Line](/assets/202275204524.webp)
这种映射机制跟我们在应用层维护缓存是很像的
### cache的结构
- Cache被分成若干行，每行的大小与主存块相同
- Cache每行包含四部分，是Cache要保存的信息。Tag从CPU访问主存的地址中剥离得到、Data是与主存交换的数据块、Valid表示Cache中的数据是否有效、 Dirty表示主存中的数据是最新
![批注 2020-02-08 162726](/assets/批注%202020-02-08%20162726.png)
### 相联存储器
- 如何快速地查找
  - 如何快速地判断数据是否存在
### Cache地址映射与变换方法
- 主存数据如何迁至Cache才能实现快速查找
#### 全相联映射
![批注 2020-02-08 164919](/assets/批注%202020-02-08%20164919.png)
- 主存分块，Cache行 （Line），两者大小相同
- 设每块4个字，主存大小为1024个字，则第61个字的主存地址为：
  - 00001111 01 （块号 块内地址）
- 主存分块后地址就从一维变成二维
- 映射算法：主存的数据块可映射到Cache任意行，同时将该数据块地址对应行的标记存储体中保存
**特点**
- Cache利用率高
- 块冲突率低
- 淘汰算法复杂
所以应用在小容量cache
#### 直接映射
![批注 2020-02-08 165705](/assets/批注%202020-02-08%20165705.png)
- 主存分块，Cache行 （Line），两者大小相同
- 主存分块后还将以Cache行数为标准进行分区
- 设每块4个字，主存大小为1024个字，Cache分为4行，第61个字的主存地址为
  - 000011 11 01 （区号，区内块号，块内地址）
  - 主存地址从一维变成三维
- 映射算法：Cache共n行，主存第j块号映射到Cache 的行号为 i=j mod n
  - 即主存的数据块映射到Cache特定行
**特点**
- Cache利用率低
- 块冲突率高
- 淘汰算法简单
应用在大容量cache
#### 组相联映射
![批注 2020-02-08 185829](/assets/批注%202020-02-08%20185829.png)
- 主存分块，Cache行 （Line），两者大小相同；
- Cache分组（每组中包k行），本例假定K=4
- 主存分块后还将以Cache组数为标准进行分组；
- 设每块4个字，主存大小为1024个字，Cache分为4行，第61个字的主存地址为：
  - 0000111 1 01 （组号，组内块号，块内地址）
  - 主存地址从一维变成三维；
- 映射算法：
  - Cache共n组，主存第j块号映射到Cache 的组号为：i=j mod n
  - 即主存的数据块映射到Cache特定组的任意行
### 替换算法
程序运行一段时间后，Cache存储空间被占满，当再有新数据要调入时，就需要通过某种机制决定替换的对象
#### 先进先出法-FIFO
![批注 2020-02-08 191721](/assets/批注%202020-02-08%20191721.png)
#### 最不经常使用法---LFU
![批注 2020-02-08 191910](/assets/批注%202020-02-08%20191910.png)
#### 近期最少使用法--- LRU
![批注 2020-02-08 192722](/assets/批注%202020-02-08%20192722.png)
#### 替换算法的抖动
- 刚刚淘汰的块在下一时刻又被访问...
### MESI
- 要解决缓存一致性问题，首先要解决的是多个 CPU 核心之间的数据传播问题
是一种写失效协议：只有一个 CPU 核心负责写入数据，在这个 CPU 核心写入 Cache 之后，它会去广播一个“失效”请求告诉所有其他的 CPU 核心。其他的 CPU 核心，只是去判断自己是否也有一个“失效”版本的 Cache Block，然后把这个也标记成失效
相对应的就是写广播协议：一个写入请求广播到所有的 CPU 核心，同时更新各个核心里的 Cache，写广播还需要把对应的数据传输给其他 CPU 核心
- M：代表已修改（Modified）
- E：代表独占（Exclusive）
- S：代表共享（Shared）
- I：代表已失效（Invalidated）
```mermaid
stateDiagram-v2
  M --> M: 本地读/写
  M --> S: 总线读/发出写回信号
  M --> I: 总线写/发出写回信号
  E --> M: 本地写
  E --> E: 本地读
  E --> S: 总线读
  E --> I: 总线写/发出写回信号
  S --> S: 本地写/发出总线写信号
  S --> S: 本地读
  S --> I: 总线写/发出写回信号
  I --> S: 本地读/发出总线读信号
  I --> E: 本地读/发出总线读信号
  I --> M: 本地写/发出总线写信号
```
## 虚拟存储器
- 计算机能执行比主存空间大的程序吗？
### 概述
- 处于主存 –辅存存储层次
- 解决主存容量不足的问题，为程序设计者提供比主存空间大的编程空间
- 分类：页式虚拟存储器、段式虚拟存储器 、段页式虚拟存储器
### 必须解决的问题
![批注 2020-02-08 200857](/assets/批注%202020-02-08%20200857.png)
- CPU访问存储系统的地址属性（采用MMU(Memory Management Unit):管理虚拟存储器与物理存储器）
- 如何判断CPU要访问的信息是否在主存中（采用页表来判断）
### 地址划分
虚拟地址 = 虚页号+页偏移量
### 逻辑地址与物理地址的转换
## TLB (Translation Lookaside Buffer)
### 虚实地址转换过程中存在的问题
- 缺页异常
![批注 2020-02-08 202837](/assets/批注%202020-02-08%20202837.png)
### 工作原理
TLB类似页表，也是PTE的集合。为实现对TLB的快速访问，类似于Cache中的映射方法，对来自于CPU的虚页号进行逻辑划分，得到相应的标记和索引字段
![批注 2020-02-08 204051](/assets/批注%202020-02-08%20204051.png)
## 缓存写
## 高速缓存参数的性能影响
- 不命中率
- 命中率
- 命中时间
- 不命中处罚
## 存储器层次结构中的缓存
缓解快速CPU与慢速的主存之间的速度差异
### 工作工程
- 缓存命中
- 缓存不命中
  - 冷不命中
  - 冲突不命中
- 缓存管理
# 编写高速缓存友好的代码
# 高速缓存对程序性能的影响