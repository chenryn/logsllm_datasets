tion solutions are here to stay.
3.2 Our Transient Attack Model
and Examples
As a concrete example that we can test and observe, we
devised a simple rootkit that exhibits transient characteris-
tics. The rootkit acts similar to the traditional Linux kernel
rootkits in the wild.
Inspired by J. Wei et al.’s work, we
implemented the rootkit to repeat modiﬁcation and rever-
sion in a ﬁxed time interval using the Linux timer. Our
example rootkit modiﬁes the system call function pointers
in sys call table to hijack the control ﬂow of the system call.
To be more speciﬁc on Linux system call hooking, the Linux
system call table takes a form of an array of pointers. Each
entry in the table points to a corresponding system call such
as sys read, sys write, and many more. The adversary could
eﬀortlessly hijack these system calls by inserting a function
between the sys call table and the actual system call. The
example rootkit simply performs the old-fashioned system
call hooking, but the timer-triggered operation allows us to
illustrate the transient rootkit characteristics.
3.3 Difﬁculties of Detecting Transient Attacks
In order to successfully detect transient attacks, the de-
tection system needs to operate on an event-triggered mech-
anism; snapshot analysis or other periodic checks are likely
to miss out the events in between the snapshots. Imagine
a snapshot-based integrity monitor was launched to detect
the transient attack model shown in Figure 1. If the author
of the kernel rootkit can properly adjust the duration of the
attack tactive and the time of dormancy tinactive, he could
completely evade the snapshot-based monitors; by staying
dormant at the time of memory snapshot and becoming ac-
tive in between the snapshots, the rootkit can capably fool
the snapshot-based monitor. In the experiment, we designed
our rootkit to have tinactive inﬁnite, in order to measure the
abilities of monitors to detect single pulse of attack.
A possible temporary solution to the limitation of the
Figure 1: This ﬁgure shows the behavior of tran-
sient attack. Transient attack compromises the ker-
nel “transiently” for tactive and remove its trace for
tinactive to avoid being detected. Assuming that
there exist a snapshot-based integrity monitor, it
may detect the second pulse but fail to detect the
ﬁrst one. The transient attack with lower tactive may
have more chance to attack the host system success-
fully
snapshot-based approach would be to increase the rate of
memory snapshot-taking or to randomize the snapshot in-
terval. Frequent memory snapshots will, however, inevitably
impose a high performance overhead on the host system.
Also, random snapshot timings may not properly represent
the system status and will produce either snapshots with
little diﬀerences or snapshots with a long time interval in
between. Therefore, we conclude that snapshot-based in-
tegrity monitors are simply not apt for detection of transient
attacks. That is, an event-triggered solution is essential to
cope with transient kernel attacks.
4. VIGILARE SYSTEM REQUIREMENTS
Vigilare is designed to collect the data stream in the host
system’s memory bus to overcome the limitations of memory-
snapshot inspection. Figure 2 shows high level design of the
Vigilare system. The Vigilare system is mainly composed of
two components: Snooper and Veriﬁer. Snooper is a hard-
ware component which collects the traﬃc and transfers it to
Veriﬁer. Veriﬁer is a compact computer system optimized to
analyze the data in order to determine the integrity of the
host system. In our prototype, Veriﬁer is placed along with
Snooper for simplicity and performance. There are several
requirements that the Vigilare system needs to meet, so that
it does not fail to detect important kernel status changes
that appear in the bus traﬃc. In this section, we describe
these requirements of the Vigilare system.
4.1 Selective Bus-trafﬁc Collection
and Sufﬁcient Computing Power
In the Vigilare system, Veriﬁer analyzes the ﬁltered col-
lection of bus traﬃc that Snooper provides. A bus band-
width that is higher than Vigilare’s computing speed can be
problematic. The AHB (Advanced High-performance Bus)
(cid:3)(cid:8)(cid:7)(cid:9)(cid:10)(cid:8)(cid:7)(cid:6)(cid:11)(cid:5)(cid:4)(cid:12)(cid:8)(cid:10)(cid:7)(cid:13)(cid:14)(cid:3)(cid:5)(cid:6)(cid:4)(cid:9)(cid:16)(cid:10)(cid:16)(cid:4)(cid:7)(cid:14)(cid:11)(cid:7)(cid:8)(cid:4)(cid:15)(cid:13)(cid:4)(cid:12)(cid:3)(cid:4)(cid:5)(cid:6)(cid:5)(cid:7)(cid:5)(cid:8)(cid:5)(cid:9)(cid:5)(cid:10)(cid:3)(cid:8)(cid:5)(cid:11)(cid:5)(cid:4)(cid:5)(cid:6)(cid:5)(cid:7)(cid:5)(cid:8)(cid:5)(cid:9)(cid:5)(cid:10)(cid:5)(cid:12)(cid:13)(cid:5)(cid:14)(cid:5)(cid:11)(cid:5)(cid:8)(cid:5)(cid:7)(cid:5)(cid:14)(cid:5)(cid:15)(cid:5)(cid:5)(cid:9)(cid:10)(cid:3)(cid:4)(cid:8)(cid:10)(cid:8)(cid:6)(cid:10)(cid:8)(cid:7)(cid:4)(cid:8)(cid:10)(cid:8)(cid:6)(cid:10)(cid:8)(cid:7)30traﬃc so that the Veriﬁer can avoid the handling of unre-
lated bursty traﬃc.
4.3 Integrity of the Vigilare System
Hardware-based integrity monitor has its advantage in the
independence from the host system. Since it does not rely
on the core functionalities of the host system kernel, the in-
tegrity of the host system does not aﬀect the integrity of
the Vigilare system. To further augment this strength of
Vigilare, the memory interface of the Vigilare system and
interrupt handling of Veriﬁer were designed with considera-
tions for independence.
The memory of the Vigilare system contains all the pro-
grams and data used by the Vigilare system. The host sys-
tem must not be able to access this memory in any way.
There are two possible ways of meeting this requirement.
The use of separate memory for the Vigilare system is the
ﬁrst option. By using a separate memory and memory con-
troller inaccessible from the host system, the Vigilare mem-
ory becomes physically tamper-free. The second option is
to implement a memory region controller which speciﬁcally
drops all memory operation requests from the host system.
The second option may reduce the cost of hardware imple-
mentation compared to that of building a completely sepa-
rate memory for Vigilare.
The interrupt handling in Veriﬁer can be a factor that
undermines the independence from the host system. Thus,
any circumstances that might trigger interrupts to Veriﬁer
should be carefully designed. More speciﬁcally, the periph-
erals controlled by host system should have no or limited
ways of introducing interrupts to the Vigilare system.
5. PROTOTYPE DESIGN
In this section, we describe our prototypes that we used
for evaluating snoop-based monitoring. We designed and im-
plemented two SoC prototypes: SnoopMon and SnapMon.
Each SoC consists of a host system and an integrity moni-
tor. SnapMon is an example of a snapshot-based monitor,
and SnoopMon, which is a prototype of the Vigilare system,
exhibits a snoop-based integrity monitoring scheme. Each
monitor investigates the integrity of immutable regions of
the Linux kernel. We ﬁrst explain the host system and the
immutable regions of Linux kernel as background informa-
tion, and then we describe the details of SnoopMon and
SnapMon designs.
5.1 Host System
We used the Leon3 processor as a host system’s main pro-
cessor which is a 32-bit processor [5] based on SPARC V8
architecture [27] provided by Gaisler. It is designed for em-
bedded software with low complexity and low power con-
sumption. The Leon3 processor has seven stage pipeline
with Harvard architecture and runs at 50MHz in our pro-
totype SoC. It has 16KB instruction cache and 16KB data
cache. The system uses 64MB SDRAM as a main mem-
ory and has some peripherals for debugging.
It runs the
Snapgear Linux [15] which is an embedded Linux customized
for the processor and runs kernel version of 2.6.21.1. We
monitored the integrity of the Linux kernel with two mon-
itors: SnoopMon and SnapMon. We provide more details
about the speciﬁc target of monitoring and discuss an issue
related to the use of virtual memory in Linux kernel.
Figure 2: This is a high-level design of the Vigi-
lare system. C1 through CN indicates the hardware
components of the host system which connects each
other via the system bus, such as main processor,
memory controller, or network interface. The Vig-
ilare system includes a Snooper that has hardware
connections to the system bus of the host system to
be monitored. Veriﬁer analyzes the ﬁltered traﬃc
that Snooper provides.
included in AMBA 2 (Advanced Microcontroller Bus Archi-
tecture) [6], which was used in the host system of our proto-
type is a good example of such problem. Every cycle, 4 byte
address and 4 byte data is transferred to memory controller
through the bus along with a few more bits of bus-speciﬁc
signals. Thus, we cannot process the stream of bus traﬃc
in one cycle with a general purpose 32 bit machine. There-
fore, Snooper must be designed with a selective bus-traﬃc
collection algorithm; it should recognize only meaningful in-
formation while truncating other unnecessary traﬃc data
ﬂow.
The required time to process a ﬁltered collection of traf-
ﬁc is also related to the computing power of Veriﬁer. The
more computing power Veriﬁer has, the less time would be
required to process the same collection of traﬃc. Veriﬁer’s
computing power must be predetermined in the design pro-
cess, so that it provides just enough processing power yet
does not introduce excessive power consumption.
4.2 Handling Bursty Trafﬁc
Just ﬁltering out some traﬃc may not allow suﬃcient time
to process all collections of traﬃc to Veriﬁer. Filtering may
reduce the processing load imposed on Veriﬁer processor and
enables Vigilare to cooperate with high bandwidth systems.
However, even selective ﬁltering does not guarantee that the
rate of bus traﬃc collected is steady and expect-able. That
is, a deluge of meaningful information may coincidentally
congregate within a short period of time, overwhelming the
computing power of Veriﬁer.
The most intuitive workaround would be to add a FIFO
(ﬁrst-in ﬁrst-out) queue to Snooper to address the problem.
Unfortunately, it does not eﬀectively remedy the problem.
First of all, implementing a FIFO for the speciﬁc architec-
ture will inevitably bring up the hardware cost. In addition,
it is rather diﬃcult to estimate the proper size of FIFO and
we cannot aﬀord to discard the critical information when
FIFO becomes full.
A better approach is to build a more abstract, interpretable
data from the raw bus-traﬃc data in Snooper. It would re-
quire more logic implementation to make Snooper more com-
plex. However, it would be much more eﬃcient than simply
increasing FIFO queue or equipping Veriﬁer with powerful
processor, since Snooper can ﬁlter and summarize the bus
(cid:4)(cid:9)(cid:12)(cid:7)(cid:10)(cid:6)(cid:3)(cid:5)(cid:13)(cid:11)(cid:12)(cid:6)(cid:8)(cid:14)(cid:15)(cid:11)(cid:12)(cid:3)(cid:5)(cid:13)(cid:11)(cid:12)(cid:6)(cid:8)(cid:3)(cid:4)(cid:5)(cid:13)(cid:11)(cid:12)(cid:6)(cid:8)(cid:3)(cid:16)(cid:17)(cid:11)(cid:18)(cid:7)(cid:20)(cid:7)(cid:21)(cid:19)(cid:10)(cid:6)(cid:3)(cid:5)(cid:13)(cid:11)(cid:12)(cid:6)(cid:8)(cid:5)(cid:9)(cid:15)(cid:15)(cid:22)(cid:6)(cid:10)(cid:5)(cid:9)(cid:15)(cid:15)(cid:22)(cid:6)(cid:10)(cid:3)(cid:5)(cid:3)(cid:6)(cid:18)(cid:6)(cid:10)(cid:7)(cid:23)(cid:7)(cid:6)(cid:10)(cid:18)(cid:6)(cid:10)(cid:7)(cid:23)(cid:7)(cid:6)(cid:10)(cid:24)(cid:10)(cid:19)(cid:23)(cid:23)(cid:7)(cid:25)(cid:24)(cid:10)(cid:19)(cid:23)(cid:23)(cid:7)(cid:25)(cid:26)(cid:7)(cid:21)(cid:12)(cid:6)(cid:10)(cid:6)(cid:27)(cid:24)(cid:10)(cid:19)(cid:23)(cid:23)(cid:7)(cid:25)(cid:26)(cid:7)(cid:21)(cid:12)(cid:6)(cid:10)(cid:6)(cid:27)(cid:24)(cid:10)(cid:19)(cid:23)(cid:23)(cid:7)(cid:25)315.2 Immutable Regions of Linux Kernel
5.4 SnoopMon
We ﬁrst describe immutable regions of the Linux kernel
that we monitored in the experiment. We deﬁne immutable
regions as the regions that are critical to the operating sys-
tem integrity such that any modiﬁcations on the regions are
deemed malicious. Protecting the integrity of immutable
regions should be the highest priority, since modiﬁcation to
immutable regions in the attacker’s favor would be the most
critical because the immutable kernel region constitutes crit-
ical component in the OS and any compromise in this region
would seriously aﬀect all the application running on top of
the OS. Therefore, our prototype of SnoopMon focuses on
monitoring the immutable regions of kernel and it is the
main issue in this paper.
As the target of integrity monitoring, we included kernel
code region, system call table and Interrupt Descriptor Ta-
ble (IDT). Kernel code region is the most obvious example
of immutable regions; the basic functionalities of the ker-
nel must not be modiﬁed after the bootstrap. These should
never be modiﬁed at runtime. The system call table is an-
other good example of immutable regions. Hijacking the
kernel’s system call often serves as an eﬃcient way to con-
trol the kernel in the favor of an attacker. Modifying the
system call table of the Linux kernel is a popular way to
intercept the execution ﬂow of the victimized system. The
Linux system call table takes a form of an array of point-
ers. Each entry in the table points to a corresponding sys-
tem calls such as sys read, sys write, and many more. The
adversary could eﬀortlessly hijack these system calls by in-
serting a function between the syscall table and the actual
system call handlers. Most user mode applications as well
as kernel mode ones, rely on the basic system calls to com-
municate with ﬁle system, networking, process information,
and other functionalities. Therefore, taking control of the
system call table enables one to control the entire kernel
from the bottom.
IDT is also an important immutable region as a critical
gateway that kernel system calls pass through. By subvert-
ing such a low level system call invocation procedure, it is
possible to hijack the system calls before even reaching the
system call table.
5.3 Physical Addresses of Immutable Regions
As stated in [20], the virtual memory space used by the
Linux generates semantic gap between the host system and
the external monitor; independent monitors like Vigilare has
no access to the paging ﬁles that manages the mapping be-
tween the virtual address space and physical memory ad-
dress. Moreover, the operating system’s paging mechanism
often swaps out less frequently used pages to hard disk space.
However, the location in the kernel memory space in which
the static region of kernel resides, is determined at boot
time. Thus, we can reliably locate and monitor the impor-
tant symbols within the static region. The virtual address of
the kernel text is found in “/boot/System.map” ﬁle, which
lists a numerous symbols used by the kernel; it is a look-up
table that contains physical addresses of symbol names. The
symbol text and etext signiﬁes the start and the end of the
kernel’s text section. The physical address of syscall table
and IDT is also determined at compile time so we can make
use of them for monitoring.
We describe our SnoopMon design and explain how our
design meets the requirements we proposed in Section 4.
Figure 3 shows key design features of SnoopMon. To prevent
any modiﬁcations to the immutable region that we explained
in Section 5.2, we speciﬁcally capture any write operation on
those intervals of addresses.
We implemented our SnoopMon as a separate computer
system that consists of one Leon3 processor, Snooper, 2MB
SRAM, several peripherals and the bus that interconnects
them. This conﬁguration makes the memory and the mem-
ory interface of the Vigilare system to be separate from the
host system. Moreover, the host system cannot access any
peripheral of the Vigilare system and is also incapable of