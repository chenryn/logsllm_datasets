are being computed by using the state estimator as a predic-
tor. Finally, the fail-safe is disabled so that the cars collide
if they come too close to each other.
The distance between the leader and the follower is
shown in Figure 7, and the corresponding deviation of the
leader from its trajectory is plotted in Figure 8. The initial
increase in the distance between the two cars is due to the
cars catching up with their trajectories during start-up. This
)
m
m
(
y
r
o
t
c
e
a
r
t
j
m
o
r
f
n
o
i
t
a
v
e
d
i
70
60
50
40
30
20
10
0
0
800
700
600
)
m
m
(
s
r
a
c
500
200
400
600
800
1000
time (ms)
1200
1400
1600
1800
2000
y = 1.0769*sqrt(x)
y = 0.127x
Prediciton error
Figure 6. Growth of error in state prediction
Distance between cars(mm)
Time of controller failure
Time of controller restart
Elapsed time to recover (ms)
t
n
e
e
w
e
b
e
c
n
a
t
s
D
i
400
300
200
100
0
420
1002
1523
621
220
501
1292
2
4
6
8
10
12
time (milliseconds)
14
x 104
2044
Figure 7. Distance between centers of cars in the motorcade
transient is resolved in about 10s and the cars stay pretty
close to their trajectories for the rest of the experiment.
The effect of restarting the controller of the leading car
is clearly reﬂected in both ﬁgures. In particular, for restart
delays of less than 1.3 seconds, the distance between the
cars does not vary by more than 50mm. This is consistent
with the behavior observed in Figure 6. However, when the
restarts are delayed for longer intervals, we see that the dis-
tance reduces as the follower comes closer to the leader. In
particular, for the two second restart at about 100s into the
experiment, the future controls in the control buffer of the
actuator are exhausted and the car stops. Consequently, we
see that the cars collide as expected. We conclude that the
experimental results validate the conclusions of Section 4,
and our approach signiﬁcantly improves system robustness
by extending deadlines in control loops.
6. Related Work
Failure tolerance in control systems can be modeled by
fail-bounded models [16], which ensure that wrong outputs
have a bounded deviation from the correct output. In our
approach, we employ a similar approach, where we deter-
mine deviation bounds by analyzing the estimator using the
plant model in section 4. Fault-tolerance mechanisms in
distributed control systems have relied primarily on redun-
dancy and replication of components [10, 23, 7]. While
replication is an effective technique against hardware fail-
ures and transient errors, it is expensive. More importantly,
it does not address software errors that would cause all repli-
)
m
m
(
y
r
o
t
c
e
a
r
t
j
m
o
r
f
n
o
i
t
a
v
e
D
i
700
600
500
400
300
200
100
0
0
Deviation from trajectory (mm)
Time of controller failure
Time of controller restart
Elapsed time to recover (ms)
2044
420
1002
1523
621
220
501
1292
2
4
6
8
10
12
time (milliseconds)
14
x 104
Figure 8. Deviation of leader from its trajectory
cas to fail on identical inputs. The problem of replica deter-
minism in real-time systems has been shown to be a chal-
lenging one [21]. Proactive recovery [20] is another tech-
nique used to proactively prevent errors which arise in cer-
tain contexts, e.g., resource errors. However, it is difﬁcult to
predict errors due to software bugs or transients, and hence
restart based recovery is perhaps the only viable solution in
these scenarios.
The problem of tolerating delays and errors in sensor
feedback has been addressed from a control theoretic per-
spective in previous work. For instance, the effect of such
delays on the operation and stability of a controller has
been studied in [17] and [25], and Nilsson [18] has ana-
lyzed the utility of state estimation to stabilize controllers
in the presence of random delays. However, the focus of
such research has been to improve the performance of con-
trol algorithms in the presence of delays in sensor updates.
In particular, software robustness issues based on real-time
deadline extension through graceful degradation, and toler-
ance to changes such as component restarts and upgrades
have not been addressed. Other techniques [5, 14] have
demonstrated mechanisms to detect delays in control sys-
tems through timestamps and clock synchronization. How-
ever, these techniques do not provide mechanisms to toler-
ate such delays and usually simply ignore delayed updates
or control outputs.
Restarts of individual components for recovery, pro-
actively as well as reactively, have been described in
software rejuvenation [24] and recovery-oriented comput-
ing [11, 6] techniques. While their work used fast restarts
of individual components in a system as a tool to improve
system availability, our work maintains timely operation in
the presence of delayed restarts. This increases the mean
time to failure (MTTF) of the system, thus improving both
reliability and availability.
The importance of low-cost fault-tolerance techniques
without the use of redundant controllers is motivated in [15]
and [8], where the notion of fault tolerance in distributed
control systems in [15] is deﬁned with respect to system op-
eration instead of the operation of an individual controller.
In this work, we adopt a similar model of fault-tolerance
where we guarantee failure-free system operation in the
presence of delays in sensor updates and controller outputs.
Simplex [22] is an architecture that uses analytic redun-
dancy to provide robustness against controller failure, and
online upgrades using a back-up controller which runs in
parallel. However, some control systems may not have a
back-up controller, and have to rely on fast restarts for re-
covery. Also, simplex does not offer a solution to tolerate
communication delays. Our co-design based approach also
employs a fail-safe in the presence of failures, but is orthog-
onal to the Simplex architecture since it provides a mech-
anism to prevent frequent transitions to the fail-safe state
through graceful degradation techniques.
7. Conclusions
System engineers increasingly use COTS components
and wireless networks in networked control systems. Un-
predictable delays in wireless networks, and restarts and
online upgrades of the individual components usually result
in missed deadlines for sensor feedback and controller out-
puts. This violates the periodicity assumptions made in the
digital control design of such systems. Consequently, the
traditional approach would require the system to frequently
invoke inefﬁcient fail-safe actions.
In this paper, we have described a co-design based ap-
proach for graceful degradation that enables systems en-
gineers to design systems that communicate over wireless
networks, and are robust to component restarts, while sat-
isfying the periodic requirements of digital control design.
This enables control design and the systems engineering to
retain their modularity. The deadline extensions obtained
by our approach ensures that the system does not invoke
fail-safe action for the large class of errors due to deadline
misses.
We have illustrated our approach by describing its
application to a trafﬁc control testbed.
In particular, we
have analytically and experimentally shown a sizable
deadline extension (4x) in the conservative worst-case
analysis, and a signiﬁcantly higher extension (13x) in
practice. This extension enables graceful degradation, and
facilitates mechanisms such as restart-based recovery and
online upgrades in feedback control systems. Our approach
is fairly general, and can be applied to most control systems
that use state estimation to address noise in sensor feedback.
Acknowledgments
We thank the anonymous referees for detailed feed-
back on this paper. This research is sponsored in part
by NSF CCR 02-09202, by ONR N00014-02-1-0102, and
by MURI N00014-01-0576. This material is also based
upon work partially supported by NSF under Contract
Nos. NSF ANI 02-21357 and CCR-0325716, USARO
under Contract Nos. DAAD19-00-1-0466 and DAAD19-
01010-465, DARPA/AFOSR under Contract No. F49620-
02-1-0325, DARPA under Contact Nos. N00014-0-1-1-
0576 and F33615-0-1-C-1905, and AFOSR under Contract
No. F49620-02-1-0217.
References
[1] IT
Convergence
Lab,
CSL,
UIUC.
http://decision.csl.uiuc.edu/(cid:24)testbed/.
[2] B. Albert and A. P. Jayasumana. FDDI and FDDI-II: Ar-
chitecture, Protocols, and Performance. Artech House Pub-
lishers, Jan 1994.
[3] G. Baliga, S. Graham, L. Sha, and P. R. Kumar. Etherware:
Domainware for wireless control networks. In Proc. of the
7th IEEE International Symposium on Object-oriented Real-
time distributed Computing (ISORC 2004), pages 155–162,
Vienna, Austria, May 2004.
[4] G. Baliga, S. Graham, L. Sha, and P. R. Kumar. Service
continuity in networked control using etherware. IEEE Dis-
tributed Systems Online, Sep 2004.
[5] A. Bondavalli, E. De Giudici, S. Porcarelli, S. Sabina, and
F. Zanini. A freshness detection mechanism for railway
applications. In 10th IEEE Paciﬁc Rim International Sym-
posium on Dependable Computing (PRDC’04), pages 292–
301, Papeete, Tahiti, French Polynesia, March 03 - 05 2004.
[6] G. Candea, J. Cutler, A. Fox, R. Doshi, P. Garg, and
R. Gowda. Reducing recovery time in a small recursively
restartable system. In Proceedings of the International Con-
ference on Dependable Systems and Networks, Washington,
D.C., June 2002.
[7] D. Chen and M. Sanfridson. Introduction to distributed sys-
tems for real-time control. Technical Report KTH/MMK/R–
98/22–SE, Mechatronics Lab, Royal Institute of Technol-
ogy, KTH, Stockholm, Sweden, Nov 2000.
[8] J. Cunha and M. Rela. On the use of disaster prediction for
failure-tolerance in feedback control systems. Washington
D.C., USA, June 2002.
[9] K. Etschberger. Controller Area Network. IXXAT Automa-
tion GmbH, Aug 2001.
[10] J. D. F. Cristian, B. Dancey. Fault-tolerance in air trafﬁc
control systems. ACM Transactions on Computer Systems,
14(3):265–286, Aug 1996.
[11] A. F. George Candea. Crash-only software.
In Proc. 9th
Workshop on Hot Topics in Operating Systems (HotOS IX),
Lihue, HI, May 2003.
[12] A. Giridhar. Scheduling trafﬁc on a road network. Master’s
thesis, University of Illinois at Urbana-Champaign, Decem-
ber 2002.
[13] S. Graham. Issues in the convergence of control with com-
munication and computation. PhD thesis, Univ. of Illinois
at Urbana-Champaign, 2004.
[14] S. Graham and P. R. Kumar. Time in general-purpose con-
trol systems: The control time protocol and an experimental
evaluation. In Proceedings of the 43rd IEEE Conference on
Decision and Control, pages 4004–4009, Bahamas, Dec 14-
17 2004.
[15] M. R. J.C. Cunha, R. Maia and J. Silva. A study on the fail-
ure models in feedback control systems. Goteborg, Sweden,
July 2001.
[16] M. R. J.G.Silva, P.Prata and H. Madeira. Practical issues in
the use of abft and a new failure model.
In Fault Toleran
Computing Symposium (FTCS-28), pages 26–35, Munich,
Germany, 1998.
[17] Q. Ling and M. Lemmon. Soft real-time scheduling of
networked control systems with dropouts governed by a
markov chain. Denver, CO, June 2003.
[18] J. Nilsson. Real-time control systems with delays. PhD the-
sis, Lund Institute of Technology, 1998.
[19] B. O’Hara and A. Petrick. The IEEE 802.11 Handbook: A
Designer’s Companion. IEEE, Dec 1999.
[20] S. Pertet and P. Narasimhan. Proactive recovery in dis-
tributed corba applications. In IEEE Conference on Depend-
able Systems and Networks, Florence, Italy, June 2004.
[21] S. Poledna. Fault Tolerant Real-time Systems. Kluwer Aca-
demic Publishers, Nov 1995.
[22] L. Sha. Dependable system upgrades.
In Proceedings of
IEEE Real Time System Symposium, 1998.
[23] K. K. Toutireddy. A testbed for fault-tolerant real-time sys-
tems. Master’s thesis, Univ. of Mass. at Amherst, 1996.
[24] N. K. Y. Huang, C. Kintala and N. Fulton. Software re-
juvenation: analysis, module and applications.
In Proc.
of the 25th Int. Symposium on Fault-Tolerant Computing,
Pasadena, CA, June 1995.
[25] W. Zhang. Stability analysis of networked control systems.
PhD thesis, Case Western Reserve University, 2001.