title:From Patching Delays to Infection Symptoms: Using Risk Profiles for
an Early Discovery of Vulnerabilities Exploited in the Wild
author:Chaowei Xiao and
Armin Sarabi and
Yang Liu and
Bo Li and
Mingyan Liu and
Tudor Dumitras
From Patching Delays to Infection Symptoms: 
Using Risk Profiles for an Early Discovery of 
Vulnerabilities Exploited in the Wild
Chaowei Xiao and Armin Sarabi, University of Michigan;  
Yang Liu, Harvard University/UC Santa Cruz; Bo Li, UIUC; Mingyan Liu, University of 
Michigan; Tudor Dumitras, University of Maryland, College Park
https://www.usenix.org/conference/usenixsecurity18/presentation/xiao
This paper is included in the Proceedings of the 
27th USENIX Security Symposium.
August 15–17, 2018 • Baltimore, MD, USA
ISBN 978-1-939133-04-5
Open access to the Proceedings of the 27th USENIX Security Symposium is sponsored by USENIX.From Patching Delays to Infection Symptoms: Using Risk Proﬁles for an
Early Discovery of Vulnerabilities Exploited in the Wild
Chaowei Xiao
University of Michigan
Armin Sarabi
University of Michigan
Yang Liu
Harvard University / UC Santa Cruz
Bo Li
UIUC
Mingyan Liu
University of Michigan
Tudor Dumitras,
University of Maryland, College Park
Abstract
At any given time there exist a large number of soft-
ware vulnerabilities in our computing systems, but only
a fraction of them are ultimately exploited in the wild.
Advanced knowledge of which vulnerabilities are being
or likely to be exploited would allow system administra-
tors to prioritize patch deployments, enterprises to assess
their security risk more precisely, and security compa-
nies to develop intrusion protection for those vulnerabil-
ities. In this paper, we present a novel method based on
the notion of community detection for early discovery of
vulnerability exploits. Speciﬁcally, on one hand, we use
symptomatic botnet data (in the form of a set of spam
blacklists) to discover a community structure which re-
veals how similar Internet entities behave in terms of
their malicious activities. On the other hand, we analyze
the risk behavior of end-hosts through a set of patch de-
ployment measurements that allow us to assess their risk
to different vulnerabilities. The latter is then compared
to the former to quantify whether the underlying risks are
consistent with the observed global symptomatic com-
munity structure, which then allows us to statistically de-
termine whether a given vulnerability is being actively
exploited in the wild. Our results show that by observ-
ing up to 10 days’ worth of data, we can successfully
detect vulnerability exploitation with a true positive rate
of 90% and a false positive rate of 10%. Our detection
is shown to be much earlier than the standard discovery
time records for most vulnerabilities. Experiments also
demonstrate that our community based detection algo-
rithm is robust against strategic adversaries.
1
Introduction
Most software contains bugs, and an increased focus on
improving software security has contributed to a grow-
ing number of vulnerabilities that are discovered each
year [12]. Vulnerability disclosures are followed by
ﬁxes, either in the form of patches or new version re-
leases. However, the installation/deployment of software
patches on millions of vulnerable hosts worldwide are
in a race with the development of vulnerability exploits.
Owing to the sheer volume of vulnerability disclosures, it
is hard for system administrators to keep up with this pro-
cess. The severity of problem was highlighted in 2017
by the the WannaCry and NotPetya outbreaks, as well as
the Equifax data breach exposing sensitive data of more
than 143 million consumers; in all three cases the under-
lying vulnerability had been patched (but not deployed)
months before the incident [46, 47, 20]. Prior research
suggests that, on median, at most 14% of the vulner-
able hosts are patched when exploits are released pub-
licly [30].
On the other hand, many vulnerabilities are never ex-
ploited. For instance, Nayak et al. [32] found that only
15% of known vulnerabilities are exploited in the wild.
In an ideal world, all vulnerabilities should be patched as
soon as they are identiﬁed regardless of their possibility
of eventual exploitation. However, in reality, we live in a
resource-constrained world where risk management and
patch prioritization become important decisions. Even
though patches may be released before or shortly after
the public disclosure of a software vulnerability, many
enterprises do not patch their systems in a timely manner,
sometimes caused by the need or desire to test patches
before deploying them on their respective machines [6].
Within this context, the ability to detect critical vulnera-
bilities prior to incidents would be highly desirable, as it
enables enterprises to prioritize patch testing and deploy-
ment. Furthermore, identifying actively exploited-in-
the-wild vulnerabilities that have not yet been addressed
by the software vendor can also guide them in prioritiz-
ing patch development.
However, determining critical software vulnerabilities
is non-trivial. For example, intrinsic attributes of vul-
nerabilities, such as the CVSS score [28], are not strong
predictors of eventual exploitation [36], underlining the
USENIX Association
27th USENIX Security Symposium    903
10 days of post-disclosure data can signiﬁcantly improve
the accuracy of detecting active exploitation. Moreover,
the median time between vulnerability disclosure and re-
ports of exploitation in our dataset is 35 days, with 80%
of reported exploits appearing beyond 10 days after the
public disclosure of the underlying vulnerability. This in-
dicates that our proposed method can improve detection
times for active exploits. Note that compared to other
techniques such as detection of exploits from social me-
dia posts (which usually appear around the time exploits
are discovered) [36], we base our detection on statistical
evidence of exploitation from real-world measurements,
which can capture much weaker indications of exploits
shortly after the public disclosure of a vulnerability.
Our main contributions are summarized as follows:
1. We use a community detection [51] method for cor-
relating and extracting features from user patching
data and IP level malicious activities. We show that
the resulting features can detect active exploitation,
validated using a ground-truth set of vulnerabilities
known to be exploited in the wild.
2. Using these features, combined with other intrinsic
features of a given vulnerability, we show that accu-
rate detection can be achieved within 10 days of vul-
nerability disclosure. This is much earlier than the
state-of-the-art on average, and thus provides sig-
niﬁcant time advantage in patch development and
deployment. We also evaluate retrospective analy-
sis of pre-disclosure data on the disclosure date to
detect and promptly respond to zero-day exploits.
3. The community structure generated during feature
extraction can also be used to identify groups of
hosts at risk to speciﬁc vulnerabilities currently be-
ing exploited, adding to our ability to strengthen
preventative and protective measures.
4. We evaluate the robustness of our technique against
strategic adversaries, observing graciously degrad-
ing performance even when the adversary can con-
trol a signiﬁcant number of hosts within many ISPs.
The rest of paper is organized as follows. In Section 2
we outline the conceptual idea behind our methodology
and how community detection is used as a feature extrac-
tion tool. We describe our datasets and data processing in
Sections 3 and 4. Section 5 details the community detec-
tion technique. Section 6 presents our classiﬁer design,
detection performance, and comparison with a number
of alternatives. In Section 7 we present case studies of
our system’s output, evaluate the robustness of our tech-
nique against strategic adversaries, and discuss how our
proposed methodology could be used in practice. Sec-
tion 8 summarizes related work and Section 9 concludes
the paper.
Figure 1: Vulnerability disclosure, exploits and
detection time line. Early detection in this study refers
to the ability to detect after tC, i.e., post-disclosure, but
much earlier than tE, the current state of the art.
need for detection techniques based on ﬁeld measure-
ments. In this paper, we ask the question: How early can
we determine that a speciﬁc vulnerability is actively be-
ing exploited in the wild? To put this on the appropriate
time scale, we illustrate the sequence of events associ-
ated with a vulnerability in Figure 1: its introduction at tA
with application installation, disclosure at tC, patching at
tF; and for those eventually exploited in the wild, detec-
tion at tE. However, real exploitations may occur much
earlier, shown at tD (post-disclosure) and sometimes tB
(pre-disclosure). In this study, by early detection we refer
to the ability to detect exploits after tC (post-disclosure)
but before tE (before the current state of the art).
We show that this early detection can be well accom-
plished by using two datasets: end-host software patch-
ing behavior and a set of reputation blacklists (RBLs)
capturing IP level malicious (spam) activities. Speciﬁ-
cally, when viewed at an aggregate level (e.g., an ISP),
the patching delays for a given vulnerability constitute a
risk proﬁle for that ISP. If a symptom that often follows
exploitation (e.g., increased spam or malicious download
activities) occurs in a group of ISPs that share a certain
risk proﬁle, then it is likely that the vulnerabilities as-
sociated with that risk proﬁle are being exploited in the
wild. We show that there is strong empirical evidence of
a strong correlation between risk proﬁles and infection
symptoms, which enables early detection of exploited
vulnerabilities, even in cases where the exploit was not
yet discovered and where causal connection between ex-
ploitation and the symptom is not known.
By observing these signals up to 10 days after vulner-
ability disclosure (tC), we can detect exploits with true
and false positive rates of 90% and 10%, respectively.
Note that intrinsic attributes of a vulnerability (e.g., re-
mote exploitability) are available immediately after dis-
closure, however, we show that features extracted from
904    27th USENIX Security Symposium
USENIX Association
Application installedVulnerability disclosedExploitsExploitsDetection in the real world (Upper bound)   Risk to be exploited Patch deployedCurrent detection delayA                            B       C        D                                                                       E         F                                    (t)Early detection(a) Symptom pattern
(b) Risk behavior 1
(c) Risk behavior 2
Figure 2: Detecting active viral strain by comparing population symptom pattern and risk behavior pattern. There are
two strains of viruses: those exposed to air contamination are more at risk/susceptible to strain 1, while those exposed
to water contamination are more at risk/susceptible to strain 2. By comparing the symptom group to the risk groups
we can infer which strain is likely to be the underlying cause of the infection.
2 Overview of Concept and Methodology
strain 2 is likely not active.
Our study is premised on a simple observation, that vul-
nerability exploitation leads to host infection, which then
leads to manifestation of symptoms such as malicious ac-
tivities. However, using the latter to detect the former is
far from trivial: observed signs of infection do not reveal
which vulnerability is the underlying culprit.
This led us to consider a more veriﬁable hypothesis:
entities (to be precisely deﬁned shortly) that exhibit sim-
ilar patching behavior in a particular vulnerability (and
thus their vulnerability state) might also exhibit similar
patterns of infection associated with that vulnerability
if it is being actively exploited; on the other hand, the
same similarity association should not exist if the vulner-
ability is not being actively exploited. If this hypothesis
holds, then it follows that one should be able to assess
the strengths of association between patching behavior
and infection symptoms and use it to detect whether a
vulnerability is likely being actively exploited.
2.1 Main idea
We illustrate the above idea using an analogy shown in
Figure 2. Suppose in any given year multiple strains
of a virus may be active in a particular region. Each
strain works through a different susceptibility:
some
through contaminated air, some through contaminated
water, shown in Figure 2b and 2c respectively. When in-
fected, regardless of the active strain, the outward symp-
toms are indistinguishable. However, if we know the in-
fected population, then by identifying the underlying risk
pattern it becomes possible to infer which strain may be
active. Comparing Figure 2b to 2a and then 2c to 2a, we
see a large overlap between the symptom group and the
group at risk to strain 1 (through air contamination), in-
dicating a likelihood that stain 1 is active; by contrast,
the symptom group and those at risk to strain 2 (through
water contamination) are largely disjoint, suggesting that
To apply this analogy in our context, the symptom
pattern refers to malicious activities while risk behav-
ior refers to host patching. More speciﬁcally, infected
population maps to hosts showing explicit signs of bot-
net activities, and exposure to active (non-active) viral
strains maps to having vulnerabilities that are (not) being
actively exploited.
2.2 Challenges
This example illustrates the conceptual idea behind our
methodology, though it is a gross simpliﬁcation as we
elaborate below. In particular, we face two challenges.
First, the telemetry that many security vendors collect on
end-hosts is often anonymized, for user privacy reasons,
and omits attributes that may identify the host, such as
its IP address. This makes it impossible to correlate the
risky behaviors (reﬂected in this telemetry) with symp-
toms (reﬂected in RBLs) at the host or IP level. Yet since
we are correlating behavioral and symptomatic data, it
is essential that both are associated with the same entity.
To resolve this, we use aggregation to assess this idea at
a higher level. Speciﬁcally, while the patching data does
not contain IP addresses, it shows ISP information asso-
ciated with each host. This allows us to aggregate patch-
ing behavior at the ISP level. On the RBL side, we use a
separate IP intelligence database to aggregate malicious
behavior at the ISP level by using IP to ISP mappings.
In other words, each unit in the population shown in the
above example now maps to an ISP. With this aggrega-
tion, the above hypothesis essentially states that ISPs be-
having similarly in patching a certain vulnerability (risk
patterns) are most likely to show similar infection symp-
toms if that vulnerability is being exploited.
This technique can be adapted for a more ﬁne-grained
aggregation, such as autonomous systems (ASs), or
not using any aggregation when both risk behavior and
symptoms are available at the host level. However, as is
USENIX Association
27th USENIX Security Symposium    905
evident from our results in Section 6.2, aggregation at the
ISP level is not too coarse so as to impede our technique
from detecting actively exploited vulnerabilities.
Our second challenge is in determining the right met-
ric to use to capture “similarity” both in the patching be-
havior and in the symptoms. Unlike what is shown in
the example, in our context neither the symptoms (spam
activities from an ISP) nor the risk behaviors (patching
records of end-hosts in an ISP) are binary, or even nec-
essarily countable as they are extracted from time series
data. This makes identifying either pattern within the
population much less straightforward. One natural ﬁrst
step is to compute pairwise correlation for each pair of
ISPs’ time series. This results in two similarity matri-
ces, one from the patching behavior data for a speciﬁc
vulnerability, one from the symptomatic infection data
(collected following that vulnerability’s disclosure from
spam lists).
It is the second-order similarity compari-
son between these two matrices that is hypothesized to
be able to tell apart exploited vulnerabilities from non-
exploited ones. To this end, we present the use of com-
munity detection [10, 51] over the symptom similarity
matrix to identify groups of similar ISPs; this is then fol-
lowed by quantifying the consistency between the risk
behavior similarity matrix and the detected community