exact number of repetitions. If we divide the packet into
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:31:51 UTC from IEEE Xplore.  Restrictions apply. 
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006Payload
Offset
fmt=mp3fmt=mp3fmt=mp3player=player=player=.exe.exe.exe
0123456789012345678901234567890123456789012345678901234
1
2
3
4
5
Figure 4. A packet payload that causes rule matching to backtrack excessively.
P1
4
P2
28
P2
31
P3
51
P4
59
46
4
P2
7
P3
P1
11
P2
14
P3
18
P2
21
P3
28
35
42
28
35
42
28
35
42
P4
50
54
46
P4
50
54
46
P4
50
54
46
P4
50
54
46
P4
50
54
46
P4
50
54
46
P4
50
54
46
P4
50
P4
54
46
54
50
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
67
Match found!
Figure 5. Predicate evaluation trees in Snort. The left tree represents the 6 predicate evaluations
performed on the payload in Figure 2, and the right tree shows the 43 evaluations performed for the
payload in Figure 4. Numbers on edges indicate payload offsets where a predicate matched.
(cid:1)k
(cid:1)k
i=1 ni) = O(nk/(kk
k equal-sized portions, each ﬁlled with repetitions of one
of these strings, we obtain ni = (cid:1)(cid:1)n/k(cid:2)/si(cid:2). The cost
of the attack is O(
i=1 si)).
Other factors such as the amount of overlap between
these strings, the length of the strings needed to match
predicates that do not cause backtracking, and the details
of the processing costs of the predicates also inﬂuence
the processing cost. These factors remain hidden by the
constants inside the O-notation.
Approximately 8% of the 3800+ rules in our ruleset were
susceptible to backtracking attacks to some degree. Our fo-
cus is on the most egregious attacks, which typically yielded
slowdowns ranging from three to ﬁve orders of magnitude.
We quantify the strength of these attacks experimentally in
Section 6.
MemoizedMatchRule(P reds):
Stack ← (P reds[0].getNewInstance(0));
M emoizationT able ← ∅;
while Stack.size > 0 do
if Stack.top.getNextMatch() then
if Stack.size == P reds.size then return T rue;
ofst ← Stack .top.getMatchOﬀset();
if (Stack.top, ofst) /∈ MemoizationTable then
M emoizationT able ←
M emoizationT able ∪ {(Stack.top, ofst)};
Push(Stack, P reds[Stack.size].getNewInstance(ofst));
1
2
3
4
5
6
7
8
9
10
else Pop(Stack);
return F alse;
11
Figure 6. The memoization-enhanced rule-
matching algorithm. Lines 2, 7, and 8 have
been added.
5. Memoization, a remedy for backtracking
As illustrated above, rule-matching engines are open to
backtracking attacks if they retain no memory of inter-
mediate results, which for Snort are predicate evaluations
that have already been determined to fail. Thus, match-
ing engines can be forced to unnecessarily evaluate the
same doomed-for-failure predicates over and over again, as
Figure 5 indicates.
Figure 6 shows our revised algorithm for rule matching
that uses memoization [7,16]. It is based on the observation
that the outcome of evaluating a sequence of predicates de-
pends only on the payload and the offset at which process-
ing starts. The memoization table holds (predicate, oﬀset)
pairs indicating for all predicates, except the ﬁrst, the offsets
at which they have been evaluated thus far. Before evaluat-
ing a predicate, the algorithm checks whether it has already
been evaluated at the given offset (line 7). If the predicate
has been evaluated before, it must have ultimately led to
failure, so it is not evaluated again unnecessarily. Other-
wise, the (predicate, oﬀset) pair is added to the memoiza-
tion table (line 8) and the predicate is evaluated (line 9).
Note that memoization ensures that no predicate is evalu-
ated more than n times. Thus, if a rule has k(cid:1)
predicates per-
forming work at most linear in the packet size n, memoiza-
tion ensures that the amount of work performed by the rule
matching algorithm is at most O(k(cid:1) · n· n) = O(k(cid:1)n2). Fig-
ure 7 updates Figure 5 to reﬂect the effects of memoization.
The greyed out nodes in the large tree from Figure 7 corre-
spond to the predicates that would not be re-evaluated when
using memoization. For the most damaging backtracking
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:31:51 UTC from IEEE Xplore.  Restrictions apply. 
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 20064
Monotonicity
P2
7
P3
P1
11
P2
14
P3
18
CPS
P2
21
P3
28
35
42
28
35
42
28
35
42
P4
50
46
54
46
P4
50
54
46
P4
50
54
46
P4
50
54
46
P4
50
54
46
P4
50
54
46
P4
50
54
46
P4
50
P4
54
46
54
50
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
P5
Figure 7. The memoization algorithm performs only 13 predicate evaluations instead of 43 as it
avoids the grayed-out nodes. The CPS optimization reduces the number of predicate evaluations
to 9, and the monotonicity optimization further reduces the evaluations to 5.
attacks against rules in Snort’s default rule set, memoization
can reduce the time spent matching a rule against the packet
by more than four orders of magnitude (with the optimiza-
tions from Section 5.1, more than ﬁve orders of magnitude).
To implement memoization, we used pre-allocated bit-
maps for the memoization table, with a separate bitmap for
each predicate except the ﬁrst. The size of the bitmaps (in
bits) is the same as the size v (in bytes) of the largest virtual
packet. Thus if the largest number of predicates in a rule is
m, the memory cost of memoization is v(m − 1)/8 bytes.
In our experiments, memoization increases the amount of
memory used in Snort by less than 0.1%.
A naive implementation of memoization would need to
initialize these bitmaps for every rule evaluated. We avoid
this cost by creating a small array that holds up to 5 offsets
and an index into the array. When a rule is to be evaluated,
only the index into the array needs to be initialized to 0. If
the number of offsets a predicate is evaluated at exceeds 5,
we switch to a bitmap (and pay the cost of initializing it). It
is extremely rare that packets not speciﬁcally constructed to
trigger backtracking incur the cost of initializing the bitmap.
5.1. Further optimizations
We present three optimizations to the basic memoiza-
tion algorithm: detecting constrained predicate sequences,
monotonicity-aware memoization, and avoiding unneces-
sary memoization after single-match predicates. The ﬁrst
two of these signiﬁcantly reduce worst case processing
time, and all optimizations we use reduce the memory re-
quired to perform memoization. Most importantly, all three
optimizations are sound when appropriately applied; none
of them changes the semantics of rule matching.
Constrained predicate sequences: We use the name
marker for predicates that ignore the value of the offset pa-
rameter. The outcome of a marker and of all predicates
subsequent to the marker are independent of where pred-
icates preceding the marker matched. As a result, mark-
ers break a rule into sequences of predicates that are inde-
pendent of each other. We use the name constrained pred-
icate sequence (CPS) for a sequence of predicates begin-
ning at one marker and ending just before the next marker.
For example, P3 in Figure 1 looks for the string player=
in the entire payload, not just after the offset where the
previous predicate matches because P3 does not have the
relative modiﬁer. Thus the rule can be broken into two
CPSes: P1-P2 and P3-P4-P5.
Instead of invoking the rule-matching algorithm on the
entire rule, we invoke it separately for individual CPSes and
fail whenever we ﬁnd a CPS that cannot be matched against
the packet. The algorithm does not need to backtrack across
CPS boundaries. Less backtracking is performed because
the ﬁrst predicate in each CPS is invoked at most once. For
the example in Figure 7, detecting CPSes causes the algo-
rithm not to revisit P1 and P2 once P2 has matched, thus
reducing the number of predicate invocations from 13 to 9.
Monotone predicates: Some expensive multiple-match
predicates used by Snort have the monotonicity property
which we deﬁne below. For these predicates we use the
more aggressive lowest-offset memoization.
In this opti-
mization, we skip calls to a monotone predicate if it has
previously been evaluated at an offset smaller than the offset
for the current instance. For example, say we ﬁrst evaluate
a monotone content predicate starting at offset 100 that
does not lead to a match of the entire rule. Later we evalu-
ate the same predicate starting at offset 200. The second in-
stance is guaranteed to ﬁnd only matches that have already
been explored by the ﬁrst instance. With basic memoiza-
tion, after each of these matches of the second instance we
check the memoization table and do not evaluate the next
predicate because we know it will lead to failure. But, the
content predicate itself is evaluated unnecessarily. With
monotonicity-aware memoization, we do not even evaluate
the content predicate at offset 200.
The monotonicity property generalizes to some regular
expressions too, and it can be deﬁned formally as follows:
let S1 be the set of matches obtained when predicate p is
evaluated at offset o1, and S2 the matches for starting offset
o2. If for all packets and ∀o1 ≤ o2 we have S2 ⊂ S1, then p
is monotone. In our example from Figure 1, all contents
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:31:51 UTC from IEEE Xplore.  Restrictions apply. 
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006and pcres are monotone with the exception of the ﬁrst
pcre, P2, because it matches at most once immediately
after the position where the previous predicate matched.
Lowest-offset memoization helps reduce worst case pro-
cessing because for some predicates the number of worst-
case invocations is reduced from O(n) to 1. For the exam-
ple in Figure 7, this optimization would have eliminated the
second and third evaluations for predicates P4, and P5 (and
for P3 also if CPSes are not detected). This further reduces
the number of predicate instances evaluated from 9 to 5.
Unnecessary memoization: Basic memoization guar-
antees that no predicate is evaluated more than n times.
For some rules with single-match predicates we can pro-
vide the same guarantee even if we omit memoizing some
predicates. If we employ memoization before evaluating a
single-match predicate, but not before evaluating its suc-
cessor, we can still guarantee that the successor will not
be evaluated more than n times (at most once for every
evaluation of our single-match predicate). Also, if we have
chains of single-match predicates it is enough to memoize
only before the ﬁrst one to ensure that none is evaluated
more than n times. Thus, our third optimization is not to
perform memoization after single-match predicates, such as
byte test and byte jump (see Table 1), except when
they are followed by a monotone predicate. For our rule set,
this optimization reduces by a factor of two the amount of
memory used for memoization.
6. Experimental results
We performed empirical evaluations with traces and in
a live setting.
In Section 6.1, we present measurements
comparing backtracking attack packets with traces of typ-
ical network trafﬁc. Our results show that three to six or-
ders of magnitude slowdowns achieved with the backtrack-
ing attack are reduced to less than one order of magnitude
slowdown under memoization. In Section 6.2, we show ac-
tual evasion using a non-memoized implementation, and the
resulting recovery with the memoized version.
For our experiments we used the Snort NIDS, version
2.4.3, conﬁgured to use the Aho-Corasick [2] string match-
ing algorithm. Snort is run on a 2.0 GHz Pentium 4 pro-
cessor and is loaded with a total of 3812 rules. We instru-
mented Snort using cycle-accurate Pentium performance
counters. When enabled, instrumentation introduced less
than 2% overhead to the observed quantities of interest. We
found that our measured observations were consistent with
the instrumentation results collected in [4].
6.1. Trace-based results
For benign trafﬁc, we obtained two groups of three traces
each captured on different days at distinct times. The ﬁrst
benign traffic, unmodified Snort
attack traffic, no memoization
attack traffic, w/ memoization+opt
1000000