â€¢ Time Series Analysis. We analyze the longitudinal data
collected by Censored Planet to automatically detect censor-
ship events and trends (Â§5.3).
The modular design allows easy additions to Censored Planet, such
as adding new measurement techniques or performing new kinds
of analysis, an essential component of a longitudinal measurement
platform. Moreover, some components act as a feedback loop to
others; for instance, the results from our data processing module
inform the vantage point selection for the next round. Before ex-
plaining each of the components of our modular design in detail, we
provide an elaborate discussion on the ethics of our measurements.
3.1 Ethics
Most censorship measurement studies involve prompting hosts
in censored countries to transmit data to trigger the censor. This
carries at least a hypothetical risk that local authorities might re-
taliate against the operators of some hosts. The measurement re-
search community has considered these risks at length at many
workshops, panel discussions, and program committee meetings [1,
29, 56, 66, 76, 119]. Part of the outcome of these discussions is an
emerging consensus that remote measurement techniques can be
applied ethically if there are suitable protections in place, includ-
ing technical practices to minimize risk to individuals, as well as
thoughtful application of the principles in the Belmont and Menlo
reports [34, 68]. This community-driven approach has been neces-
sary in part because institutional review boards (including at our
institution) typically consider network measurement studies to be
outside of their purview when they do not involve human subjects
or their personally identifiable data.
In the design and implementation of Censored Planet, we care-
fully followed the risk-minimization practices proposed in the stud-
ies that introduced each remote measurement technique. Chief
among these is the use of hosts in Internet infrastructure (e.g.,
routers two traceroute hops away from the end user (Augur), name-
server resolvers (Iris), infrastructural echo servers (Quack), infras-
tructural web servers (Hyperquack)) rather than typical edge hosts,
with the rationale that in the â€œunlikely case that authorities decided
to track down these hosts, it would be obvious that users were
not running browsers on themâ€ [106], and â€œbecause these adminis-
trators are likely to have more skills and resources to understand
the traffic sent to their servers, the risk posed to them by these
methods is lower than the risk posed to end usersâ€ [100]. Although
this restriction significantly reduces the pool of hosts, there are still
adequately many to achieve broad global coverage.
Additionally, we are careful to minimize the burden on remote
hosts by limiting the rate at which we conduct measurements.
For Internet-wide scans, we follow the ethical scanning guidelines
developed by the ZMap [36]. We closely coordinate with our net-
work administrators and our upstream ISP. All our machines have
WHOIS records and a web page served from port 80 that indicates
that measurements are part of a censorship research project and
offer the option to opt-out. Over the past 20 months of performing
measurements, we received an average of one abuse complaint
per month, some of them being automated responses generated by
network monitoring tools. So far, no complaints indicated that our
probes caused technical or legal problems, and one ISP administra-
tor even helped us diagnose a problem by providing a detailed view
of what they observed.
4 DATA COLLECTION
Once we receive test requests with scan configurations, our Input
Scanner and Interference Scanner perform the tasks for measure-
ment data collection.
4.1 Input Scanner
Our modularized design allows custom inputs for both longitudinal
measurements and more focused custom measurements based on
the configuration. The Input Scanner performs the crucial role of
synchronizing test lists across measurement techniques, ensuring
continuity in vantage points, and updating important dependencies.
4.1.1 Vantage Point Selection. The Input Scanner follows the rig-
orous ethical standards introduced in Â§3.1 to select infrastructural
vantage points for each measurement technique:
â€¢ Augur. Infrastructural routers which are two ICMP hops
away from the end-user and have a sequentially increment-
ing IP ID value (from CAIDA ARK data [22]).
â€¢ Satellite. Open DNS resolvers which are name servers (from
â€¢ Quack. Infrastructural servers with TCP port 7 (Echo) or
â€¢ Hyperquack. Web servers that have valid EV (Extended
Validation) certificates (from Censys [35]).
The Input Scanner applies several additional constraints to ensure
the quality of vantage points. For example, Augur only uses routers
whose IP ID increment is less than five to reduce noise.
Port 9 (Discard) open (from Internet-wide scans).
Internet-wide scans).
Session 1A: Anonymous Routing and Censorship CCS '20, November 9â€“13, 2020, Virtual Event, USA52For our longitudinal measurements, the Input Scanner updates
the list of vantage points every week. We find currently active
vantage points by either scanning the IPv4 address space (in case
of Quack and Satellite) or obtaining the latest data from other
sources (for Hyperquack and Augur). For techniques in which we
have to select a subset of available vantage points due to resource
constraints, we select vantage points from different countries in
a round-robin manner, prioritizing vantage points from the â€œNot
Freeâ€ and â€œPartly Freeâ€ countries from the 2019 Freedom on the Net
report [46]. We also try to select vantage points from different /24
networks to ensure a representative distribution inside the country.
While updating the list of vantage points, the Input Scanner
tries to select the same vantage points as in the previous week
of measurements to ensure continuity, and replaces any vantage
points that are no longer active. This is an important step as time
series analysis of censorship data requires data collected from the
same source. This is because censorship may vary between different
vantage points inside a country, as we show in Â§6.3. We evaluate
the continuity in vantage point selection in Â§6.1. For rapid focus
measurements, the Input Scanner selects vantage points at higher
scale in specific countries. For example, we selected 34 Augur van-
tage points for our rapid focus study in Turkmenistan that we do
not use in our longitudinal measurements (Â§7.3).
4.1.2 Test List Selection. The Input Scanner selects different do-
mains for testing in longitudinal measurements and rapid focus
measurements. For longitudinal measurements, we follow the test
list selection process of previous studies [7, 78, 100, 106] and select
all the domains from the Citizen Lab Global Test List (CLTL) [27].
CLTL is a curated list of websites that have either previously been
reported unavailable or are of interest from a political or human
rights perspective. At the time of writing, the list has around 1,400
domains. We complement this list by including the top domains
from the Alexa list of popular domains to test for blocking of ma-
jor services. Totally, we test 2,000 domains per week. The Input
Scanner updates both of these lists weekly, and performs liveness
checks in order to ensure the domains are active. Synchronizing
test lists among different measurement techniques is an essential
step in introducing comparability between them. Note that Augur
only performs tests for domains from the CLTL because of time and
resource constraints. For rapid focus, our Input Scanner selects do-
mains based on the specific event being investigated. For example,
we selected many IPs of DNS-over-HTTPS services and Cloudflare
for our rapid focus study in Turkmenistan (Â§7.3).
4.1.3 Other Inputs. Our Input Scanner also generates other inputs
for specific techniques. For instance, the scanner tests whether
the test domains are anycasted by performing measurements from
geographically-distributed machines, as this information is required
by Augur to detect certain kinds of blocking [77]. The Input Scanner
also verifies that all the dependencies required by the measurement
techniques such as the ZMap blacklist [36] are up to date.
4.2 Interference Scanner
The Interference Scanner first ensures that our machines are ready
to perform measurements. This includes verifying spoofing ca-
pability and ensuring the absence of firewalls. Our measurement
scheduler maintains a global vantage point work state and manages
synchronization of measurements so that vantage points are not
overloaded and there is no noise introduced in measurement. This
is important since techniques like Quack use overlapping vantage
points for Echo and Discard measurements.
For our longitudinal measurements, the scheduler performs
reachability scans twice a week for Hyperquack, Quack and Satel-
lite, and once a week for Augur. Note that Augur measurements
were started in November 2019. While performing scans, our health
monitoring submodule logs any measurement or vantage point
errors appropriately and ensures that overall scan statistics are as
expected. For instance, the health monitoring ensures that there
is enough hard disk space to store measurement data. When pre-
processing our data (Â§5.1), we use these errors and statistics to
eliminate failed measurements. We also mark vantage points fre-
quently failing control tests for removal in the Input Scanner. For
rapid focus measurements, the Interference Scanner performs more
in-depth scans, such as increasing the number of trials in Augur, or
checking for particular certificate patterns in Hyperquack.
We employ the same technique for measurements as described
in Â§2, with some improvements. We add the capacity for testing
reachability to custom ports (not only on Port 80) for Augur, and
remove the browser-trusted TLS certificate heuristic from Satellite
as we discovered this heuristic introducing some false negatives.
5 DATA PROCESSING
Accurately deriving observations about censorship from raw mea-
surement data involves several important steps that have often
been overlooked by previous studies [7, 77, 78, 106]. Our analysis
process includes the sanitization of raw data in a pre-processing
step, followed by a censorship and time series analysis. We demon-
strate in Â§6 how such comprehensive analysis steps are crucial to
deriving accurate observations.
The analysis steps of Censored Planet is shown in the bottom half
of Figure 1. In the pre-processing step, we aggregate the raw mea-
surement results to a common schema and use recently introduced
clustering techniques [100] to remove false positives. This even-
tually provides us with confirmed instances of censorship (Â§5.1).
In the next step, we apply optimized weights to vantage points
to ensure they are representative for the state of censorship in a
particular country, after which we obtain a measure of censorship
per country (Â§5.2). Finally, we perform time series analysis to find
anomalies and trends (Â§5.3).
5.1 Pre-Processing
Initial Sanitization. As an initial sanitization step, we remove
5.1.1
all measurements that failed due to technical issues, such as loss of
measurement machine connectivity and file system failures using
health monitoring information from the Interference Scanner (Â§4.2).
5.1.2 Aggregating to Common Schema. Censored Planet collects
synchronized censorship measurement data on six Internet proto-
cols which enables unified analysis of global Internet censorship.
Since each measurement technique collects different measurement
data (such as resolved IP in case of Satellite and HTML response
in case of Hyperquack), we need to design a common aggregated
Session 1A: Anonymous Routing and Censorship CCS '20, November 9â€“13, 2020, Virtual Event, USA53schema to introduce comparability and interoperability for the re-
sults. We attribute all measurements performed in a week to the
start of the week (Sunday) and model our common schema as:
id | protocol | date | vp | domain | blocked
Based on the vantage point (vp) and the domain tested, we also
collect and add metadata such as the country and the AS of the
vantage point, and the topic category of the website hosted at the
domain. We obtain country information from Maxmind [62] and
combine data from Maxmind, the Routeviews project [91], and
Censys [35] for obtaining AS information. Country information
was available for 99.96 % and AS information for 99.86 % of vantage
points. For the domains, we refer to the pre-defined categories of
CLTL [27], and use the Fortiguard URL classification service [45]
for the remaining Alexa domains. Our category information spans
33 topics and covers 99.3 % of the test domains.
5.1.3 Removing False Positives. Although we perform control mea-
surements for all of our techniques (Â§2), some benign responses may
still get classified as censorship. For instance, Cloudflare endpoints
frequently perform bot checks on measurements, which introduces
discrepancies between the test and control measurements. Such
issues can affect both remote and direct measurements [100, 104].
We use the clustering approach introduced by Sundara Raman et
al. [100] to identify and filter out false positives in the measurement
results of Quack, Hyperquack, and Satellite. Specifically, we use a
two-step clustering technique to identify confirmed instances of
censorship (blockpages) and false positives. The iterative classifica-
tion step first identifies large groups of identical HTML responses.
The image clustering step then uses the DBSCAN algorithm [39] to
cluster dynamic HTML pages. Each cluster is then labeled as either
a false positive or blockpage, achieving complete coverage.
In our dataset, we extract all the responses marked as blocked
from Quack and Hyperquack data; for Satellite, we fetch the re-
solved IP for blocked responses and then fetch the webpages of the
resolved IP. We then use existing blockpage clusters from previous
work [100] and extend them by creating new clusters using iterative
classification and image clustering. From our data, we form 457
new clusters of responses, out of which 308 are blockpages, and
149 are potential false positives. Note that we follow an extremely
conservative approach in confirming a blockpage, and only do so
when there is clear evidence of blocking on the webpage (such as
â€œÂ¡PÃ¡gina Web Bloqueada!â€). We consider all cases of
TCP resets and connection timeouts as true cases of blocking, since
they are confirmed through the control measurements.
This step involves manual effort in labelling each new cluster
as either a blockpage or a false positive. Fortunately, our synchro-
nized measurement and analysis process reduces this effort since a
blockpage or false positive instance found in one techniqueâ€™s mea-
surements can avoid redundant effort in identifying it with others.
Moreover, since each cluster is manually verified, we generate high
confidence in identifying censored measurements. For avoiding
false positives in Augur data, we use hypothesis testing at high
confidence levels (ğ›¼ = 10âˆ’5) [77].
5.1.4 Confirmed Results. In the time from August 2018â€“March
2020, we conducted 21.8 billion measurements. After the initial
pre-processing, we remove 1.2 billion measurements (5.9 %) from
the raw data set, and of this we mark around 1.5 billion (7 %) as
blocked. The false positive filtering removes around 500 million
measurements from the this set, which leaves around 1 billion con-
firmed blocked measurements. After this stage we consider only
the confirmed cases of blocking as censorship.
5.2 Censorship Analysis
Censorship policies and methods can vary in different networks
inside the country [85, 118], complicating the analysis process. For
example, ISPs in Russia use various methods and policies to en-
act censorship, and thus users experience differences when they
connect to distinct networks [85]. Organizational policies further
exacerbate the issue, causing a wide range of blocking patterns
in measurements from different vantage points inside the coun-
try [100]. We provide a thorough evaluation of heterogeneity in
blocking within a country in Â§6.3. To ensure a representative mea-
sure of censorship within a country, i.e., avoiding the effects of
outlier vantage points subject to a harsher or more lenient policy
compared to the rest of the country, we build an optimization model
that levels out contributions from outlier vantage points.
5.2.1 Censorship Metric. Before performing the optimization, we
first need to define a metric for censorship. At the lowest granularity
of an individual vantage point vp, we define the censorship in week
t as a percentage value:
Censvp,t =
(1)
For a more focused view of the types of content that is blocked, we
drill down Censvp,t by domain categories.
# Domains blocked
# Domains tested Â· 100
To find an initial estimate of censorship in a country cc with n
vantage points, we aggregate Equation 1 as:
ğ‘–=1 Censvpğ‘–
, t
ğ‘›
Censcc,t(Raw) =
(2)
We use Equation 2 as a raw metric for censorship in a country, and
it serves as the input to our optimization model.
5.2.2 Optimization. To obtain a representative measure of censor-
ship within a country that is not affected by anomalous vantage
points, we build a numerical optimization model to derive weights
for measurement points that allow to smooth the censorship re-
sults. To perform the optimization, we assign individual weights
ğœ” ğ‘— for each autonomous system ASğ‘— in the data set. As an AS can
contribute to multiple different measurements, we first gather all
available results of ASğ‘— in country cc, which results in a vector
of measurements for the same AS and country at different points
in time (AScc,ğ‘—,t). In the second step, we extend the vector by the
target values (Censcc,t(ğ‘…ğ‘ğ‘¤)) for each scan in cc :
ğ‘›
(cid:169)(cid:173)(cid:173)(cid:173)(cid:173)(cid:171)
AScc,ğ‘—,1, Censcc,1(Raw)
AScc,ğ‘—,2, Censcc,2(Raw)
...
AScc,ğ‘—,t, Censcc,t(Raw)
(cid:170)(cid:174)(cid:174)(cid:174)(cid:174)(cid:172)
(3)
Given the subset of results for a specific ASğ‘—, we optimize a
weight factor ğœ” ğ‘— that minimizes the discrepancies between the indi-
vidual measurement results and the target value. The optimization
relies on the assumption that the overall blocking percentage of a
Session 1A: Anonymous Routing and Censorship CCS '20, November 9â€“13, 2020, Virtual Event, USA54ğ‘›
and changing vantage points. Thus, we define the absolute change
in censorship between two weeks (tğ‘, tğ‘; tğ‘ < tğ‘) as:
Î”(Censvp,tğ‘âˆ’tğ‘) = Censvp,tğ‘ âˆ’ Censvp,tğ‘
(6)
5.3.2 Anomaly Detection in Censorship Time Series. We build our
anomaly detection models based on the absolute change in censor-
ship (cf. Equation 6). Censvp,t is highly auto-correlated (Kendallâ€™s
correlation coefficient ğœ = 0.93, 95 % confidence level) and hence,
an extremely high absolute change in censorship is a very good in-
dicator of incidents. Since we want to find anomalies at the country
level, we take the weighted average of Equation 6 for all vantage
points within a country cc to calculate the change in censorship:
ğ‘—=1 ğœ” ğ‘— Â· Î”(Censvpğ‘— ,tğ‘âˆ’tğ‘)
(7)
ğ‘—=1 ğœ” ğ‘—
Î”(Censcc,tğ‘âˆ’tğ‘ (Smooth)) =
Next, we test different anomaly detection techniques regarding