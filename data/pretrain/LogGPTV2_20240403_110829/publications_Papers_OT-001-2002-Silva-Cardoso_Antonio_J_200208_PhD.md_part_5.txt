An example of a mapping scale for quantitative and qualitative values is shown inT able
2-2. The workflow designer is responsible for the creation of the mapping table. The table
is created by first selecting a set of qualitative terms that characterize the fidelity. The use
of qualitative terms may facilitate the human understanding of the fidelity concept
exhibited by workflows in some cases .
39
Table 2-2 – Example of a fidelity-mapping table
Qualitative Quantitative
Fidelity Fidelity
Unacceptable [0.00.. 0.20]
Poor [0.21.. 0.40]
Satisfactory [0.41.. 0.60]
Good [0.61.. 0.80]
Perfect [0.81.. 1.00]
Depending on the task type, a task uses different strategies to set fidelity attributes.
Three scenarios can be drawn: automatic tasks controlling hardware, automatic tasks
controlling software, and human tasks. For an automated task controlling a hardware
device, the fidelity attribute can be set after reading the output status line of the device.
For example, the task Sequencing controls DNA sequencing, which is carried out
automatically by a sequencer. When the sequencing finishes, the machine generates
several output files to describe how the process was executed. These values can be passed
on to the task, which automatically updates its fidelity attributes. For automated tasks
controlling a software application, the same procedure can be applied. For example, the
task Sequence Processing executes various algorithms on the sequences received. One of
the algorithms used is BLAST (Altschul, Gish et al. 1990). This algorithm searches DNA
sequences in a database to identify macromolecules with related structures and functions.
Once the search is concluded, the algorithm returns a value indicating the confidence of
the matching. For this task, the returned value from the execution of the algorithm will be
used to describe the fidelity of the task’s execution. For human tasks, the procedure has
to be manual. Therefore, it is the responsibility of the user to manually input information
40
relative to the fidelity of the task executed. In the case of the task Prepare Sample, the lab
technician sets the fidelity attribute quality of clones manually, after a visual
identification. For quality assurance reasons the attributes should be set or checked by a
person other than the one who that carried out the task execution. If evaluating the
fidelity of a task cannot be accurately done by a human, an option is to place – when
possible – an automatic task after the human task to automatically check the fidelity .
The fidelity information can be used to effectively monitor workflow executions.
Typically, during the lifetime of an instance, qualitative information describing task
fidelity is displayed on graphical monitors as the tasks are executed. Managers can easily
identify tasks which exhibit unsatisfactory fidelity metrics .
2.4.6 QOS MODEL DISCUSSION
One of the most popular workflow classifications distinguishes between ad hoc
workflows, administrative workflows, and production workflows. This classification was
first mentioned by (McCready 1992). The main differences between these types include
structure, repetitiveness, predictability, complexity, and degree of automation.
We recognize that the QoS model presented here is better suited for production
workflows (McCready 1992) since they are more structured, predictable, and repetitive.
Production workflows involve complex and highly-structured processes, whose execution
requires a high number of transaction accessing different information systems. These
characteristics allow the construction of adequate QoS models for workflow tasks. In the
case of ad hoc workflows, the information, the behavior, and the timing of tasks are
largely unstructured, which makes the procedure of constructing a good QoS model more
difficult and complex.
41
2.5 CREATION OF QOS ESTIMATES
In order to facilitate the analysis of workflow QoS, it is necessary to initialize task QoS
metrics and also initialize stochastic information which indicates the probability of
transitions being fired at runtime. Once tasks and transitions have their estimates set,
algorithms and mechanisms, such as simulation, can be applied to compute overall
workflow QoS.
2.5.1 QOS ESTIMATES FOR TASKS
Having previously defined the QoS dimensions for tasks, we now target the estimation of
QoS metrics of tasks. The specification of QoS metrics for tasks is made at design time
and re-computed at runtime, when tasks are executed. During the graphical construction
of a workflow process, the designer sets QoS estimates for each task. The estimates
characterize the quality of service that the tasks will exhibit at runtime .
Setting initial QoS metrics for some workflow tasks may be relatively simple. For
example, setting the QoS for a task controlling a DNA sequencer can be done based on
the time, cost, and reliability specifications given by the manufacturer of the DNA
sequencer. In other cases, setting initial QoS metrics may prove to be difficult. This is the
case for tasks that heavily depend on user input and system environment. For such tasks,
it is convenient to study the workflow task based on real operations. The estimates are
based on data collected while testing the task. The idea is to test the task based on
specific inputs. This can be achieved by the elaboration of an operational profile( Musa
1993). In an operational profile, the input space is partitioned into domains, and each
input is associated with a probability of being selected during operational use. The
probability is employed in the input domain to guide input generation. The density
function built from the probabilities is called the operational profile of the task. At
runtime, tasks have a probability associated with each input. Musa (1999) described a
detailed procedure for developing a practical operational profile for testing purposes.
42
The task runtime behavior specification is composed of two classes of information
(Table 2-3): basic and distributional. The basic class associates with each task’s QoS
dimension the minimum value, average value, and maximum value the dimension can
take. For example, the cost dimension corresponds to the minimum, average, and
maximum cost associated with the execution of a task. The second class, the
distributional class, corresponds to the specification of a constant or of a distribution
function (such as Exponential, Lognormal, Normal, Rayleigh, Time-Independent,
Weibull, and Uniform) which statistically describes task behavior at runtime. For
example, Table 2-3 and Table 2-4 show the QoS dimensions for an automatic task (the
SP FASTA task) and for a manual task (the Prepare Sample task; see section 2.3.2 for
tasks descriptions).
Table 2-3 – Task QoS for an automatic task
Basic class Distributional class
Min value Avg value Max value Dist. Function
Time 0.291 0.674 0.895 Normal(0.674, 0.143)
Cost 0 0 0 0.0
Reliability - 100% - 1.0
Fidelity.a 0.63 0.81 0.92 Trapezoidal(0.7,1,1,4)
i
43
Table 2-4 – Task QoS for a manual task
Basic class Distributional class
Min value Avg value Max value Dist. Function
Time 192 196 199 Normal(196, 1)
Cost 576 576 576 576.0
Reliability - 100% - 1.0
Fidelity.a - - - -
i
The values specified in the basic class are typically employed by mathematical
methods in order to compute workflow QoS metrics, while the distributional class
information is used by simulation systems to compute workflow QoS. To devise values
for the two classes, the designer typically applies the functions presented in the previous
section to derive the task’s QoS metrics. We recognize that the specification of time, cost,
fidelity, and reliability is a complex operation, which when not carried out properly can
lead to the specification of incorrect values. Additionally, the initial specification may nto
remain valid over time. To overcome this difficulty, a task’s QoS values can be
periodically re-computed for the basic class, based on previous executions. The
distributional class may also need to have its distribution re-computed. At runtime, the
workflow system keeps track of actual values for the QoS dimensions monitored. QoS
runtime metrics are saved and used to re-compute the QoS values for the basic class
which were specified at design time. The workflow system re-computes the QoS values
for each dimension; this allows the system to make more accurate estimations based on
recent instance executions.
The re-computation of QoS task metrics is based on data coming from designer
specifications and from the workflow system log. Four scenarios can occur: a) For a
44
specific task t and a particular dimension Dim, the average is calculated based only on
information introduced by the designer (designer average); b) the average of a task t
dimension is calculated based on all its executions independently of thew orkflow that
executed it (multi-workflow average); c) the average of the dimension Dim is calculated
based on all the times task t was executed in any instance from workflow w (workflow
average); and d) the average of the dimension of all the times task t was executed in
instance i of workflow w (instance average). Scenario d) can only occur when loops exist
in a workflow.
The averages described in Table 2-5 are computed at runtime and made available to
the workflow system. While Table 2-5 shows only how to compute average metrics,
similar formulae can be used to compute minimum and maximum values .
Table 2-5 – Designer, multi-workflow, workflow and instance average
Designer Average (t) Average specified by the designer in the basic
Dim
class for dimension Dim
Multi-Workflow Average (t) Average of the dimension Dim for task t
Dim
executed in the context of any workflow
Workflow Average (t, w) Average of the dimension Dim for task t
Dim
executed in the context of any instance of
workflow w
Instance Average (t, w, i) Average of the dimension Dim for task t
Dim
executed in the context of instance i of
workflow w
45
The task QoS for a particular dimension can be determined at different levels; it is
computed following the equations described in Table 2-6.
Table 2-6 – QoS dimensions computed at runtime
a) QoS (t) Designer Average (t)
Dim Dim
b) QoS (t) wi * Designer Average (t) + wi * Multi-Workflow
Dim 1 Dim 2
Average (t)
Dim
c) QoS (t, w) wi * Designer Average (t) + wi * Multi-Workflow
Dim 1 Dim 2
Average (t) + wi *Workflow Average (t, w)
Dim 3 Dim
d) QoS (t, w, i) wi * Designer Average (t) + wi * Multi-Workflow
Dim 1 Dim 2
Average (t) + wi * Workflow Average (t, w) + wi *
Dim 3 Dim 4
Instance Workflow Average (t,w, i)
Dim
The workflow system uses the formulae from Table 2-6 to predict the QoS of tasks.
The weights wi are set manually. They reflect the degree of correlation between the
j
workflow under analysis and other workflows for which a set of common tasks is shared.
Since the values entered by the designer may contain extraneous data and therefore be
imprecise, a Bayesian approach (Bernardo and Smith 1994) might be considered to make
use of prior knowledge in order to improve the accuracy of the weights wi.
j
Let us assume that we have an instance i of workflow w running and that we desire
to predict the QoS of task t ˛ w. The following rules are used to choose which formula to
apply when predicting QoS. If task t has never been executed before, then formula a) is
chosen to predict task QoS, since there is no other data available. If task t has been
executed previously, but in the context of workflow w , and w != w , then formula b) is
n n
chosen. In this case we can assume that the execution of t in workflow w will give a
n
46
good indication of its behavior in workflow w. If task thas been previously executed in
the context of workflow w, but not from instance i, then formula c) is chosen. Finally, if
task thas been previously executed in the context of workflow w, and instance i, meaning
that a loop has been executed, then formula d) is used.
2.5.2 PROBABILITIES ESTIMATES FOR TRANSITIONS
In the same way we seed tasks’ QoS, we also need to seed workflow transitions. Initially,
the designer sets the transition probabilities at design time. At runtime, the transitions’
probabilities are re-computed. The method used to re-compute the transitions’
probabilities follows the same lines of the method used to re-compute tasks’ QoS. When
a workflow has never been executed, the values for the transitions are obviously taken
from initial designer specifications. When instances of a workfloww have already been
executed, then the data used to re-compute the probabilities come from initia ldesigner
specifications for workflow w, from other executed instances of workflow w, and if
available, from the instance of workflow w for which we wish to predict the QoS. This
corresponds to the use of functions similar to the ones previously defined for tasks’ QoS
(see Table 2-6).
2.6 QOS COMPUTATION
Once QoS estimates for tasks and for transitions are determined, we can compute overall
workflow QoS. We describe two modeling techniques that can be used to compute QoS
metrics for a given workflow process: mathematical modeling and simulation modeling.
The selection of the method is based on a tradeoff between time and the accuracy of
results. The mathematical method is computationally faster, but it yields results which
may not be as accurate as the results obtained by simulation. (Note that our mathematical
models could be extended to queuing network models (Lazowska, Zhorjan et al. 1984),
but this requires making some simplifying assumptions) .
47
2.6.1 MATHEMATICAL MODELING
The stochastic workflow reduction method consists of applying a set of reduction rules to
a workflow until only one atomic task (Kochut, Sheth et al. 1999) exists. Each time a
reduction rule is applied, the workflow structure changes. After several iterations only
one task will remain. When this state is reached, the remaining task contains the QoS
metrics corresponding to the workflow under analysis.
The set of reduction rules that can be applied to a given workflow corresponds to the
set of inverse operations that can be used to construct a workflow. We have decided to
only allow the construction of workflows which are based on a set of predefined
construction systems; this protects users from designing invalid workflows. Invalid
workflows contain design errors, such as non-termination, deadlocks, and split of
instances (Aalst 1999). While in this paper we do not prove that a workflow graph can be
reduced by using the proposed set of reduction systems, this can be accomplished,
proving that all the reduction systems form a “finite Church-Rosser” transformation.
Work on graph reduction can be found in Allen (1970) and Knuth (1971).
To compute QoS metrics, we have developed the SWR(w) algorithm (Cardoso 2002),
which uses a set of six distinct reduction rules: (1) sequential, (2) parallel, (3) conditional,
(4) fault-tolerant, (5) loop, and (6) network.
Additional reduction rules can be developed. We have decided to present the
reduction concept with only six reduction rules, for two reasons. The first reason is
because a vast majority of workflow systems support the implementation of the reduction
rules presented. Based on a study on fifteen major workflow systems and the workflow
patterns that they support (Aalst, Barros et al. 2002), fifteen of the workflow systems
studied supported the reduction rules (1)(2)(3), ten supported the reduction rule (5), and
eight supported the reduction rules (4). The study does not discuss network patterns. The
network pattern is intended to provide a structural and hierarchical division of a given
48
workflow design into levels, in order to facilitate its understanding by the grouping of
related tasks into functional units. The second reason is that the reduction rules are
simple, making it easy to understand the idea behind the workflow reduction process.
2.6.1.1 REDUCTION SYSTEMS
Reduction of a Sequential System. Figure 2-3 illustrates how two sequential workflow
tasks t and t can be reduced to a single task t . In this reduction, the incoming transitions
i j ij
of t and outgoing transition of tasks t are transferred to task t .
i j ij
p
j
t t t
i j ij
(a) (b)
Figure 2-3 - Sequential system reduction
In a sequential system, p = 1. This reduction can only be applied if the following two
j
conditions are satisfied: a) t is not a xor/and split and b) t is not a xor/and join. These
i j
conditions prevent this reduction from being applied to parallel, conditional, and loop
systems. To compute the QoS of the reduction, the following formulae are applied:
T(t ) = T(t) + T(t)
ij i j
C(t )= C(t) + C(t)
ij i j
R(t ) = R(t) * R(t)
ij i j
F(t ).a = f(F(t), F(t))
ij r i j
Reduction of a Parallel System. Figure 2-4 illustrates how a system of parallel tasks t ,
1
t , …, t , an and split task t , and an and join task t can be reduced to a sequence of three