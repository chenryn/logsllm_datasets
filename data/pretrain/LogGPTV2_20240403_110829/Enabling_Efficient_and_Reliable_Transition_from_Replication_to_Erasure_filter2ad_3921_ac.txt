Node
Rack
Figure 6. Revised ﬂow graph with target racks.
We elaborate it via an example. Suppose that we encode
three data blocks with (6, 3) erasure coding over a CFS with
R = 6 racks. If we only require single-rack fault tolerance
(i.e., c = n − k = 3), then we can choose R(cid:4) = 2 target
racks and construct the ﬂow graph as shown in Figure 6.
Then we can ensure that after encoding, all data and parity
blocks are placed in the target racks.
IV. IMPLEMENTATION
We implement EAR as an extension to Facebook’s HDFS
[11]. In this section, we describe the implementation details.
A. Overview of Erasure Coding in HDFS
The original HDFS architecture [28] comprises a single
NameNode and multiple DataNodes, such that the NameN-
ode stores the metadata (e.g., locations) for HDFS blocks,
while the DataNodes store HDFS blocks. Facebook’s HDFS
implements erasure coding based on a middleware layer
called HDFS-RAID [16], which manages the erasure-coded
blocks on HDFS. On top of HDFS, HDFS-RAID adds
a new node called the RaidNode, which coordinates the
encoding operation. The RaidNode also periodically checks
for any lost or corrupted blocks, and activates recovery for
those blocks. Currently, Facebook’s HDFS supports inter-ﬁle
encoding, such that the data blocks of a stripe may belong
to different ﬁles.
HDFS-RAID executes encoding through MapReduce [9],
which uses a single JobTracker to coordinate multiple Task-
Trackers on MapReduce processing. To perform encoding,
the RaidNode ﬁrst obtains metadata from the NameNode
and groups every k data blocks into stripes. It then submits
a map-only MapReduce job (without any reduce task) to
the JobTracker, which assigns multiple map tasks to run on
different TaskTrackers, each of which performs encoding
for a subset of stripes. For each stripe,
the responsible
TaskTracker issues reads to k data blocks in parallel from
different DataNodes. Once all k data blocks are received,
the TaskTracker computes the parity blocks and writes them
to HDFS. Currently, we use the Reed-Solomon codes [26]
implemented by HDFS-RAID as our erasure coding scheme.
Finally, the replicas of the data blocks are deleted.
B. Integration
Figure 7 depicts how we modify HDFS to integrate EAR.
Our modiﬁcations are minor, and they can be summarized
in three aspects.
Our ﬁrst modiﬁcation is that we add the replica placement
algorithm of EAR into the NameNode. EAR returns the
following information: (i) which DataNodes the replicas of
a data block are to be stored, (ii) which data blocks are
encoded into the same stripe in the subsequent encoding
operation, and (iii) which replicas of a data block are to
be deleted after encoding while ensuring rack-level fault
tolerance. We implement a pre-encoding store in the Na-
meNode to keep track of each stripe and the list of data
block identiﬁers that belong to the stripe.
Our second modiﬁcation is to modify how the RaidNode
instructs MapReduce to perform encoding of a stripe in the
core rack. To achieve this, we note that the MapReduce
framework provides an interface to specify which preferred
node to run a map task. Speciﬁcally, the RaidNode ﬁrst
obtains the list of data block identiﬁers for each stripe
from the pre-encoding store. It then queries the NameNode
for the replica locations (in terms of the hostnames of the
DataNodes) of each data block. With the returned locations,
the RaidNode identiﬁes the core rack of each stripe. When
the RaidNode initializes a MapReduce job for encoding, it
ensures that a map task encodes multiple stripes that have
a common core rack. This is done by attaching the map
function with a preferred node, which we choose to be one
of the nodes in the common core rack. In this case, the
JobTracker tries to schedule this map task to run on the
preferred node, or nearby nodes within the core rack, based
on locality optimization of MapReduce [9].
The above modiﬁcations still cannot ensure that the en-
coding operation is performed in the core rack, since all
nodes in the core rack may not have enough resources
to execute a map task for encoding and the JobTracker
assigns the map task to a node in another rack. This
leads to cross-rack downloads for the encoding operation.
Thus, our third modiﬁcation is to modify the MapReduce
framework to include a Boolean ﬂag in a MapReduce job to
differentiate if it is an encoding job. If the ﬂag is true, then
the JobTracker only assigns map tasks to the nodes within
the core rack. Note that this modiﬁcation does not affect
other non-encoding jobs.
V. EVALUATIONS
In this section, we present evaluation results for EAR. Our
evaluations comprise three parts: (i) testbed experiments,
in which we examine the practical deployment of EAR on
HDFS; (ii) discrete-event simulations, in which we evaluate
EAR in a large-scale setting subject to various parameter
choices, and (iii) load balancing analysis, in which we justify
EAR maintains load balancing as in RR.
NameNode
EAR
Pre-encoding store
stripe 1: [block list]
stripe 2: [block list]
stripe 3: [block list]
stripe 4: [block list]
RaidNode
JobTracker
map1
map 2
Encoding job
map1(preferred node: rack1/node1)
  stripe1(core rack: rack1)
  stripe3(core rack: rack1)
map2(preferred node: rack2/node4)
  stripe2(core rack: rack2)
  stripe4(core rack: rack2)
TaskTracker
TaskTracker
TaskTracker
TaskTracker
DataNode
node1
DataNode
node2
DataNode
node3
DataNode
node4
rack1
rack2
Figure 7.
Integration of EAR into Facebook’s HDFS.
A. Testbed Experiments
We conduct testbed experiments on a 13-machine HDFS
cluster. Each machine has an Intel Core i5-3570 3.40GHz
quad-core CPU, 8GB RAM, and a Seagate ST1000DM003
7200RPM 1TB SATA disk, and runs Ubuntu 12.04. All
machines are interconnected via a 1Gb/s Ethernet switch.
One limitation is that our testbed is of a small scale.
Nevertheless, our testbed experiments provide insights into
how EAR performs in real deployment.
To mimic a CFS architecture as in Figure 1, we conﬁgure
each machine to reside in a rack by associating each machine
with a unique rack ID, such that one machine (called the
master) deploys the NameNode, RaidNode, and JobTracker,
and each of the remaining 12 machines (called the slaves)
deploy one DataNode and one TaskTracker. We have val-
idated that the network transfer over the 1Gb/s Ethernet
switch is the bottleneck in our testbed.
We ﬁx the block size as 64MB, the default of HDFS.
Since each rack (machine) has only one DataNode in our
testbed, we use 2-way replication and distribute two replicas
of each data block in two racks (machines), so as to
provide single-rack fault tolerance as in the default HDFS
(see Section II-A). For each encoding job, we conﬁgure
the RaidNode to launch 12 map tasks. All our results are
averaged over ﬁve runs.
Experiment A.1 (Raw encoding performance): We ﬁrst
study the raw encoding performance without write requests.
We consider (n, k) erasure coding with n = k + 2, where k
ranges from 4 to 10. We write 96×k data blocks (i.e., 24GB
to 60GB of data) to HDFS with either RR or EAR. The
RaidNode then submits an encoding job to encode the data
blocks, and a total of 96 stripes are created. We evaluate
the encoding throughput, deﬁned as the total amount of
data (in MB) to be encoded divided by the encoding time.
Figure 8(a) shows the encoding throughputs of RR and EAR
versus (n, k). The encoding throughputs increase with k for
both RR and EAR, as we generate proportionally fewer
parity blocks. If k increases from 4 to 10, the encoding
154154
RR
EAR
)
s
/
B
M
(
t
p
h
t
i
g
n
d
o
c
n
E
500
400
300
200
100
0
(6,4)
(8,6)
(10,8)
(n,k)
)
s
/
B
M
(
t
p
h
t
i
g
n
d
o
c
n
E
500
400
300
200
100
0
(12,10)
RR
EAR
200
0
800
Injected traffic (Mbps)
500
(a) Different (n, k)
(b) Different UDP sending rates
Figure 8.
Experiment A.1: Raw encoding performance of encoding 96
stripes. Each bar shows the minimum and maximum values over ﬁve runs,
represented by the endpoints of the error bars.
throughput gain of EAR over RR increases from 19.9% to
59.7%, mainly because more data blocks are downloaded
for encoding with a larger k.
We also compare the encoding throughputs of RR and
EAR under different network conditions. We group our 12
slave machines into six pairs. For each pair, one node sends
UDP packets to another node using the Iperf utility [18].
We consider different UDP sending rates, so that a higher
UDP sending rate implies less effective network bandwidth,
or vice versa. We ﬁx (10, 8) erasure coding and re-run the
above write and encoding operations. Figure 8(b) shows
the encoding throughputs of RR and EAR versus the UDP
sending rate. The encoding throughput gain of EAR over
RR increases with the UDP sending rate (i.e., with more
limited network bandwidth). For example, the gain increases
from 57.5% to 119.7% when the UDP sending rate increases
from 0 to 800Mb/s. We expect that if a CFS is severely over-
subscribed [1, 15], the beneﬁts of EAR will be prominent.
Experiment A.2 (Impact of encoding on write perfor-
mance): We now perform encoding while HDFS is serving
write requests. We study the performance impact on both
write and encoding operations. Speciﬁcally, we ﬁx (10, 8)
erasure coding. We ﬁrst write 768 data blocks, which will
later be encoded into 96 stripes. Then we issue a sequence of
write requests, each writing a single 64MB block to HDFS.
The arrivals of write requests follow a Poisson distribution
with rate 0.5 requests/s. To repeat our test for ﬁve runs, we
record the start time of each write request in the ﬁrst run,
and regenerate the write requests at the same start times in
the following four runs. After we generate write requests
for 30s, we start the encoding operation for the 96 stripes.
We measure the response time of each write request and the
total encoding time.
Figure 9 plots the response times of the write requests
for both RR and EAR. Initially, when no encoding job
is running (i.e., before the time 30s), both RR and EAR
have similar write response times at around 1.4s. When
the encoding operation is running, EAR reduces the write
)
s
(
e
m
i
t
e
s
n
o
p
s
e
R
3
2
1
0
0
RR
EAR
300
100
200
Request time (s)
Figure 9. Experiment A.2: Impact of encoding on write performance under
RR and EAR. The horizontal lines represent the average write response
time during encoding and the duration of the whole encoding operation.
For brevity, each data point represents the averaged write response time of
three consecutive write requests.
response time by 12.4% and the overall encoding time
by 31.6% when compared to RR. This shows that EAR
improves both write and encoding performance.
Experiment A.3 (Impact of EAR on MapReduce): We
study how EAR inﬂuences the performance of MapReduce
jobs before encoding starts. We use SWIM [30], a MapRe-
duce workload replay tool, to generate synthetic workloads
of 50 MapReduce jobs derived from a trace of a 600-node
Facebook production CFS in 2009. The generated workloads
specify the input, shufﬂe, and output data sizes of each
MapReduce job. Based on the workloads, we ﬁrst write
the input data to HDFS using either RR or EAR. Then
we run MapReduce jobs on the input data, and write any
output data back to HDFS, again using either RR or EAR.
We conﬁgure each TaskTracker to run at most four map
tasks simultaneously. We measure the runtime of the whole
job, which includes a combination of reading and processing
input data from HDFS, shufﬂing data, and outputting ﬁnal
results to HDFS.
Figure 10 shows the number of completed jobs versus
the elapsed time under either RR or EAR. We observe
very similar performance trends between RR and EAR.
This shows that EAR preserves MapReduce performance
on replicated data as RR.
B. Discrete-Event Simulations
We complement our testbed experiments by comparing
RR and EAR via discrete-event simulations in a large-scale
CFS architecture. We implement a C++-based discrete-event
CFS simulator using CSIM 20 [8]. Figure 11 shows our sim-
ulator design. The PlacementManager module decides how
to distribute replicas across nodes under RR or EAR during
replication and how to distribute data and parity blocks in
the encoding operation. The Topology module simulates the
155155
RR
EAR
l
s
b