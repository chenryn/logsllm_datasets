estimating the performance of each individual IDS. While the
conditional independence assumption might not guarantee theoret-
ically optimal rules, it is still an efﬁcient and principled method
for fusing information, as shown in our experiments and in other
practical applications [3, 28, 37, 21].
Creating more accurate models that avoid the “high variance”
problem, and comparing their effectiveness as fusion rules in IDSs
against more practical approximations (such as the conditional
independence assumption), is a challenging problem and one we
plan to explore in future work.
6.4 A Robust Consideration for Cost Evalua-
tion
We showed in previous section that the LRT technique is very
robust
to parameter estimation errors up to a certain degree.
Here we propose another robust way to evaluate the expected (or
total) cost to address the concern of a possible large deviation of
estimation errors and uncertainties of the parameters in practice.
For a robust evaluation with uncertain parameters, we again
consider the situation where the estimated base rate, false positive
rate and false negative rate deviate from the actual values to certain
degree. Now instead of calculating the expected (or total) cost
with a static setting of parameters, we use a range (bounded with
largest possible deviation to tolerate estimation errors), and among
all possible ﬁnal cost values, we take the highest value (which
stands for the worst cases with all possible situation of estimated
parameters) as the ﬁnal result. By doing this, we are actually
ﬁnding the highest cost against the worst situation with worst
possible estimation errors (similar to the idea in [9]). Thus, we
can make sure that this ﬁnal cost is robust in a sense that it is the
upper-bound in all cases of possible estimated range of parameters.
The real cost evaluation is guaranteed to be better than this robust
result given the largest possible estimation error bound.
6.5 Runtime Performance
The runtime performance of our LRT fusion rule is efﬁcient. For
example, we test the running time in the ﬁrst experiment using four
IDSs. It only takes 0.187 seconds to ﬁnish LRT fusion processing
on all 311,029 records, which is about 0.6 microseconds per record
(on a machine with 512M memory, 2.4GHz Pentium IV processor,
Windows 2K OS). Although it is poorer than the performance of
the AND rule and the OR rule (about 0.2 microsecond/record),
the runtime of our LRT fusion is almost as good as that of the
VOT fusion rule, which is about 0.5 microsecond per record. We
can improve the computation efﬁciency if we calculate the log
probabilities and thresholds once off-line, store them and simply
145
020406080100020406080100Estimation Error Tolerance Bound (%)Robustness (%)C01=C10=1   C01=10,C10=1C01=1,C10=10use them in the actual fusion decision (instead of calculating again).
In addition, if we consider the fact that the fusion is primarily
performed only when there are alerts generated by IDSs (or even
performed off-line),
the LRT rule is computationally efﬁcient
enough for practical usage.
6.6 Multi-class Extension
The LRT technique discussed so far is on two-class (anomaly
or normal) alert fusion.
It can also be extended to multi-class
situation. The extension is similar to the method of extending two-
class SVM to multi-class cases, i.e., we can use a tree structure to
perform LRT along some tree path (i.e., it is a sequence of two-class
LRT runs). For example, we run the ﬁrst LRT to decide whether it
is class 1 or not, the second LRT to decide whether it is class 2 or
not, and so on. The running time (the number of LRT run) is at
most O(m), at least O(log(m)), where m is the number of classes
to classify.
7. CONCLUSION AND FUTURE WORK
In this paper, we proposed a decision-theoretic alert fusion
technique for an IDS ensemble and reported our empirical
experience from using this technique in practice. We provided
formal interpretation of the LRT ensemble based on ROC curve
analysis, and discussed the reasoning of why it is better than other
approaches. We empirically veriﬁed its effectiveness in practice
through experiments using several machine learning based IDSs
and real IDSs on multiple data sets. The theoretical reasoning
and empirical results show that this approach outperforms other
existing fusion techniques in practice in terms of achieving low
overall cost. Furthermore, this technique is adaptive to different
base rates and different risk scenarios (or cost models). In addition,
in our simulation test, we showed that this approach can tolerate a
reasonable bound of parameter estimation error.
It is also important to notice that the LRT fusion rule is not only
an optimal rule in the sense that it minimizes the expected cost, but
also optimal in a Neyman-Pearson [38] way. That is, the LRT rule
maximizes the probability of detection for a given upper bound on
the false alarm rate. The intuition for this notion of optimality can
be reﬂected in the analysis done in Section 5, where the ROC of the
ensemble was shown to have superior performance to the ROC of
the individual detectors. However, due to space constraints we omit
the detail analysis of this property in this paper. For future work, we
will study robust and realistic approaches to involve probabilistic
techniques and inference models. And we plan to further explore
how to obtain better independent (diverse) detectors, which is a
very important and interesting problem for IDS research.
The LRT ensemble rule is not limited to applications in intrusion
detection. However, we have not encountered a formal treatment
of the rule as presented in this paper in other applications such
as machine learning. We are currently exploring its use in more
general classiﬁcation systems and voting algorithms, and plan to
extend this work to other applications.
8. ACKNOWLEDGMENTS
This work is supported in part by NSF grant CCR-0133629, the
Army Research Ofﬁce contract W911NF0510139 and by TRUST,
which receives funding from NSF grant CCF-0424422. The
contents of this work are solely the responsibility of the authors
and do not necessarily represent the ofﬁcial views of NSF and the
U.S. Army.
9. REFERENCES
146
[1] Kdd cup 1999 data.
http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html,
2005.
[2] Nahla Ben Amor, Salem Benferhat, and Zied Elouedi. Naive
bayes vs decision trees in intrusion detection systems. In
SAC ’04: Proceedings of the 2004 ACM symposium on
Applied computing, pages 420–424, New York, NY, USA,
2004. ACM Press.
[3] Anish Arora, Dennis Hall, C. Ariel Pinto, Dwayne Ramsey,
and Rahul Telang. Measuring the risk-based value of it
security solutions. IT Professional, 6(6):35–42, Nov.-Dec.
2004.
[4] S. Axelsson. The base-rate fallacy and its implications for
the difﬁculty of intrusion detection. In Proceedings of ACM
CCS’1999, November 1999.
[5] Marco Barreno, Alvaro A. Cardenas, and J. D. Tygar.
Optimal roc curve for a combination of classiﬁers. In
Proceedings of Neural Information Processing Systems
(NIPS) 20, 2008.
[6] Tim Bass. Intrusion detection systems and multisensor data
fusion. Commun. ACM, 43(4):99–105, 2000.
[7] J. De Bonet, C. Isbell, and P. Viola. Mimic: Finding optima
by estimating probability densities. Advances in Neural
Information Processing Systems, 9, 1997.
[8] L. Breiman. Bagging predictors. Machine Learning,
24(2):123–140, 1996.
[9] Alvaro Cardenas, John Baras, and Karl Seamon. A
Framework for the Evaluation of Intrusion Detection
Systems. In Proceedings of the 2006 IEEE Symposium on
Security and Privacy, Oakland, California, May 2006.
[10] Chih-Chung Chang and Chih-Jen Lin. LIBSVM: a library for
support vector machines, 2001. Software available at
http://www.csie.ntu.edu.tw/~cjlin/libsvm.
[11] F. Cuppens and A. Miege. Alert correlation in a cooperative
intrusion detection framework. In Proceedings of IEEE
Symposium on Security and Privacy 2002, 2002.
[12] Herve Debar and Andreas Wespi. Aggregration and
correlation of intrusion-detection alerts. In Proceedings of
the 4th International Symposium on Recent Advances in
Intrusion Detection (RAID’01), 2001.
[13] Luca Didaci, Giorgio Giacinto, and Fabio Roli. Ensemble
learning for intrusion detection in computer networks.
http://citeseer.ist.psu.edu/533620.html.
[14] Thomas G. Dietterich. Ensemble methods in machine
learning. Lecture Notes in Computer Science, 1857:1–15,
2000.
[15] W. Fan, W. Lee, S. Stolfo, and M. Miller. A multiple model
cost-sensitive approach for intrusion detection. In
Proceedings of The Eleventh European Conference on
Machine Learning (ECML’00), 2000.
[16] W. Fan, S. Stolfo, and J. Zhang. Adacost: cost-sensitive
boosting. In Proceedings of International Coference on
Machine Learning (ICML’99), 1999.
[17] Y. Freund and R. E. Schapire. Experiments with a new
boosting algorithm. In Thirteenth International Conference
on Machine Learning (ICML), pages 148–156, 1996.
[18] G. Giacinto and F. Roli. Intrusion detection in computer
networks by multiple classiﬁer systems. In Proceedings of
16th International Conference on Pattern Recognition (ICPR
2002), 2002.
[19] Guofei Gu, Prahlad Fogla, David Dagon, Wenke Lee, and
[36] John McHugh. Testing intrusion detection systems: A
critique of the 1998 and 1999 darpa off-line intrusion
detection system evaluation as performed by lincoln
laboratory. ACM Transactions on Information and System
Security, 3(4), November 2000.
[37] Tom Mitchell. Machine Learning. McGraw-Hill, 1997.
[38] J. Neyman and E. S. Pearson. On the problem of the most
efﬁcient tests of statistical hypotheses. Philosophical
Transactions of the Royal Society of London, Series A,
Containing Papers of a Mathematical or Physical Character,
231:289–337, 1933.
[39] Peng Ning, Yun Cui, and Douglas S. Reeves. Constructing
attack scenarios through correlation of intrusion alerts. In
Proceedings of the 9th ACM Conference on Computer &
Communications Security (CCS’02), 2002.
[40] Roberto Perdisci, Guofei Gu, and Wenke Lee. Using an
ensemble of one-class svm classiﬁers to harden
payload-based anomaly detection systems. In Proceedings of
the IEEE International Conference on Data Mining
(ICDM’06), December 2006.
[41] Phillip A. Porras, Martin W. Fong, and Alfonso Valdes. A
mission-impact-based approach to infosec alarm correlation.
In Proceedings of the 5th International Symposium on
Recent Advances in Intrusion Detection (RAID’02), 2002.
[42] Rain Forest Puppy. Libwhisker ofﬁcial release v2.1, 2004.
Available at http://www.wiretrip.net/rfp/lw.asp.
[43] Martin Roesch. Snort: Lightweight intrusion detection for
networks. In LISA, pages 229–238, 1999.
[44] M. Shankar, N. Rao, and S. Batsell. Fusing intrusion data for
detection and containment. In Proceedings of
MILCOM2003, 2003.
[45] Sal Stolfo, Wei Fan, Wenke Lee, Andreas Prodromidis, and
Phil Chan. Cost-based modeling for fraud and intrusion
detection: Results from the jam project. In Proceedings of
the 2000 DARPA Information Survivability Conference and
Exposition (DISCEX ’00), 2000.
[46] Eric Totel, Frederic Majorczyk, and Ludovic Me. COTS
diversity intrusion detection and application to web servers.
In Proceedings of RAID’2005, September 2005.
[47] F. Valeur, G. Vigna, C.Kruegel, and R. Kemmerer. A
Comprehensive Approach to Intrusion Detection Alert
Correlation. IEEE Transactions on Dependable and Secure
Computing, 1(3):146–169, July-September 2004.
[48] V.N. Vapnik. The Nature of Statistical Learning Theory.
Springer, 1995.
[49] P. Varshney. Distributed Detection and Data Fusion.
Spinger-Verlag, New York, NY, 1996.
[50] Ke Wang and Salvatore J. Stolfo. Anomalous payload-based
network intrusion detection. In Proceedings of RAID’2004,
September 2004.
[51] D. H. Wolpert. Stacked generalization. Neural Networks,
5:241–259, 1992.
[52] L. Xu, A. Krzyzak, and CY Suen. Methods of combining
multiple classiﬁers and their applications to handwriting
recognition. IEEE Trans. Systems Man Cybernet,
22(3):418–435, 1992.
Boris Skoric. Measuring intrusion detection capability: An
information-theoretic approach. In Proceedings of the 2006
ACM Symposium on Information, Computer, and
Communication Security (ASIACCS’06), March 2006.
[20] Guofei Gu, Prahlad Fogla, David Dagon, Wenke Lee, and
Boris Skoric. Towards an information-theoretic framework
for analyzing intrusion detection systems. In Proceedings of
the 11th European Symposium on Research in Computer
Security (ESORICS’06), September 2006.
[21] Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The
Elements of Statistical Learning. Springer-Verlag New York,
Inc., 2003.
[22] Imad Y. Hoballah and Pramod K. Varshney. Distributed
Bayesian signal detection. IEEE Transactions on
Information Theory, 35(5):995–1000, 1989.
[23] Wenjie Hu, Yihua Liao, and V. Rao Vemuri. Robust support
vector machines for anomaly detection in computer security.
In Proc. 2003 International Conference on Machine
Learning and Applications (ICMLA’03), 2003.
[24] Finn V. Jensen. Bayesian Networks and Decision Graphs.
Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2001.
[25] Michael I. Jordan, editor. Learning in graphical models. MIT
Press, Cambridge, MA, USA, 1999.
[26] C. Kruegel and G. Vigna. Anomaly Detection of Web-based
Attacks. In Proceedings of the 10th ACM Conference on
Computer and Communication Security (CCS ’03), pages
251–261, Washington, DC, October 2003. ACM Press.
[27] C. Kruegel, G. Vigna, and W. Robertson. A Multi-model
Approach to the Detection of Web-based Attacks. Computer
Networks, 48(5):717–738, August 2005.
[28] Christopher Kruegel, Darren Mutz, William Robertson, and
Fredrik Valeur. Bayesian Event Classiﬁcation for Intrusion
Detection . In Proceedings of the Annual Computer Security
Applications Conference (ACSAC 2003), Las Vegas, NV,
December 2003.
[29] Ludmila I. Kuncheva. Combining Pattern Classiﬁers:
Methods and Algorithms. Wiley, 2004.
[30] W. Lee, W. Fan, M. Miller, S. Stolfo, and E. Zadok.
Cost-sensitive modeling for intrusion detection and response.
Journal of Computer Security, 10(1,2), 2002.
[31] Wenke Lee and Salvatore J. Stolfo. A framework for
constructing features and models for intrusion detection
systems. ACM Transactions on Information and System
Security (TISSEC), 3(4):p.227–261, 2000.
[32] Yihua Liao and V. Rao Vemuri. Using text categorization
techniques for intrusion detection. In 11th USENIX Security
Symposium, August 5–9, 2002., pages 51–59, 2002.
[33] R. P. Lippmann, D. J. Fried, I. Graf, J. W. Haines, K. P.
Kendall, D. McClung, D. Weber, S. E. Webster,
D. Wyschogrod, R. K. Cunningham, , and M. A. Zissman.
Evaluating intrusion detection systems: The 1998 darpa
off-line intrusion detection evaluation. In Proceedings of the
2000 DARPA Information Survivability Conference and
Exposition (DISCEX’00), 2000.
[34] M. Mahoney. Network trafﬁc anomaly detection based on
packet bytes. In Proceedings of 18th ACM Symp. on Applied
Computing, pages 346–350, November 2003.
[35] M. Mahoney and P. Chan. An analysis of the 1999
darpa/lincoln laboratory evaluation data for network anomaly
detection. In Proceedings of the 6th International Symposium
on Recent Advances in Intrusion Detection (RAID’03), 2003.
147