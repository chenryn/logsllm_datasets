sequences formed by the known 6-bits prefix and all the possible
remaining 122 bits, while the д function assigns 1 to the sequences
whose 7-th bit agrees with the stored password, and 0 otherwise.
Thus д is a partition gain function [4], and its particularity is that
for such kind of functions data pre-processing and channel pre-
processing coincide. This is because дpw, xq is either 0 or 1, so in
both cases we generate exactly one pair pw, yq for each pair px, yq
for which дpw, xq “ 1. Note that in this case the data pre-processing
transformation does not increase the training set, and the channel
pre-processing transformation does not introduce any additional
noise. The RC matrix (cfr. Section 4.1) is a 2ˆ 128 stochastic matrix.
The experiments are done with training sets of 10K, 30K and 50K
samples. The results are reported in Figure 11. We note that the
estimation error is quite small, especially in the ANN case. This
is because the learning problem is particularly simple since, by
100003000050000Training set size before preprocessing0.000.020.040.060.080.10normalized estimation errordispersion: 0.032total error: 0.062dispersion: 0.006total error: 0.045dispersion: 0.011total error: 0.021dispersion: 0.005total error: 0.030dispersion: 0.010total error: 0.016dispersion: 0.004total error: 0.024ANNk-NN100003000050000Training set size0.000.020.040.060.08normalized estimation errordispersion: 0.025total error: 0.059dispersion: 0.006total error: 0.040dispersion: 0.008total error: 0.012dispersion: 0.004total error: 0.027dispersion: 0.003total error: 0.005dispersion: 0.005total error: 0.022ANNk-NNpoint, consider a modification of the last experiment, and assume
that the password checker is not leaky, i.e., the observables are
only fail or success. A pair px, successq would have a negligible
probability of appearing in the training set, hence our method, most
likely, would estimate the vulnerability to be 0. This is fine if we are
trying to estimate the Bayes vulnerability, which is also negligible.
But the д-vulnerability may not be negligible, in particular if we
consider a д that gives an enormous gain for the success case.
If we can ensure that all the pairs px, yq are represented in the
training set in proportion to their probability in PX Y , then the
above "magnification" in д-vulnerability is not a problem, because
our method will ensure the also the pairs pw, yq would be magnified
(with respect to the the pairs pw, yq) in the same proportion.
6 CONCLUSION AND FUTURE WORK
We have proposed an approach to estimate the д-vulnerability of a
system under the black-box assumption, using machine learning.
The basic idea is to reduce the problem to learn the Bayes classifier
on a set of pre-processed training data, and we have proposed two
techniques for this transformation, with different advantages and
disadvantages. We have then evaluated our approach on various
scenarios, showing favorable results. We have compared our ap-
proach to the frequentist one, showing that the performances are
similar on small observable domains, while ours performs better
on large ones. This is in line with what already observed in [14] for
the estimation of the Bayes error.
As future work, we plan to test our framework on more real-life
scenarios such as the web fingerprinting attacks [13, 15] and the
AES cryptographic algorithm [22]. We also would like to consider
the more general case, often considered in Information-flow secu-
rity, of channels that have both “high” and “low” inputs, where
the first are the secrets and the latter are data visible to, or even
controlled by, the adversary. Finally, a more ambitious goal is to use
our approach to minimize the д-vulnerability of complex systems,
using a GAN based approach, along the lines of [33].
ACKNOWLEDGMENTS
This research was supported by DATAIA “Programme d’Investis-
sement d’Avenir” (ANR-17-CONV-0003). It was also supported by
the ANR project REPAS, and by the Inria/DRI project LOGIS. The
work of Catuscia Palamidessi was supported by the project HYPA-
TIA, funded by the European Research Council (ERC) under the Eu-
ropean Union’s Horizon 2020 research and innovation programme,
grant agreement n. 835294. The work of Prof. Pablo Piantanida
was supported by the European Commission’s Marie Sklodowska-
Curie Actions (MSCA), through the Marie Sklodowska-Curie IF
(H2020-MSCAIF-2017-EF-797805-STRUDEL).
REFERENCES
[1] 2011. Gowalla dataset. https://snap.stanford.edu/data/loc-Gowalla.html.
[2] Mário S. Alvim, Konstantinos Chatzikokolakis, Annabelle McIver, Carroll Mor-
gan, Catuscia Palamidessi, and Geoffrey Smith. 2014. Additive and Multiplicative
Notions of Leakage, and Their Capacities. In IEEE 27th Computer Security Foun-
dations Symposium, CSF 2014, Vienna, Austria, 19-22 July, 2014. IEEE, 308–322.
https://doi.org/10.1109/CSF.2014.29
[3] Mário S. Alvim, Konstantinos Chatzikokolakis, Annabelle McIver, Carroll Morgan,
Catuscia Palamidessi, and Geoffrey Smith. 2016. Axioms for Information Leakage.
In Proceedings of the 29th IEEE Computer Security Foundations Symposium (CSF).
77–92. https://doi.org/10.1109/CSF.2016.13
Figure 11: Password checker scenario, k-NN and ANN esti-
mation with data and channel pre-processing
considering the д-leakage and the preprocessing, we have managed
to reduce the problem to learning a function of type Y Ñ W,
rather than Y Ñ X, and there is a huge difference in size between
W and X (the first is 2 and the latter is 2128). Also the frequentist
approach does quite well (cfr. Appendix H) , and this is because Y
is small. With a finer bucketing (on top of the Laplace delay), or no
bucketing at all, we expect that the difference between the accuracy
of the frequentist and of the ML estimation would be much larger.
5.8 Discussion
In almost all the experiments, our method gives much better result
than the frequentist approach (see Figure 2 and the other plots in
the appendix Appendix H). The exception of the second experiment
can be explained by the fact that the observable space is not very
large, which is a scenario where the frequentist approach can be
successful because the available data is enough to estimate the real
distribution. In general, with the frequentist approach there is no
real learning, therefore, if |Y| is large and the training set contains
few samples, we cannot make a good guess with the observables
never seen before [14]. In ML, on the contrary, we can still make an
informed guess, as ML models are able to generalize from samples,
especially when the Bayes error is small.
We observe that ANN outperforms the k-NN in all experiments.
This is because usually ANN models are better at generalizing, and
hence provide better classifiers. In particular, k-NN are not very
good when the distributions are not smooth with respect to the
metric with respect to which the neighbor relation is evaluated [14].
The data pre-processing method gives better results, than the
channel pre-processing in all experiments except the third one
(DP), in which the difference is very small. The main advantage of
using the channel pre-processing method is when the gain function
is such that the data pre-processing would generate a set too large,
as explained in Section 4.3.
The experiments show that our method is not too sensitive to the
size of |Y|. On the other hand, the size of |X| is important, because
the ML classifiers are in general more precise (approximate better
the ideal Bayes classifier) when the number of classes are small. This
affects the estimation error of both the Bayes vulnerability and the
д-vulnerability. However, for the latter there is also the additional
problem of the magnification due to the д. To better understand this
100003000050000Training set size before preprocessing0.0000.0020.0040.0060.0080.010normalized estimation errordispersion: 0.002total error: 0.003dispersion: 0.003total error: 0.007dispersion: 0.002total error: 0.003dispersion: 0.002total error: 0.004dispersion: 0.002total error: 0.003dispersion: 0.002total error: 0.004ANNk-NNSpringer. I–XX, 1–738 pages. http://www.worldcat.org/oclc/71008143
[4] Mário S. Alvim, Konstantinos Chatzikokolakis, Catuscia Palamidessi, and Ge-
offrey Smith. 2012. Measuring Information Leakage Using Generalized Gain
Functions. In 25th IEEE Computer Security Foundations Symposium, CSF 2012, Cam-
bridge, MA, USA, June 25-27, 2012, Stephen Chong (Ed.). IEEE Computer Society,
265–279. http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6265867
[5] Christopher M. Bishop. 2007. Pattern recognition and machine learning, 5th Edition.
[6] Nicolás E. Bordenabe and Geoffrey Smith. 2016. Correlated Secrets in Quantitative
Information Flow. In CSF. IEEE Computer Society, 93–104. http://ieeexplore.
ieee.org/xpl/mostRecentIssue.jsp?punumber=7518122
[7] Michele Boreale. 2009. Quantifying information leakage in process calculi. Inf.
Comput 207, 6 (2009), 699–725.
[8] S. Boucheron, G. Lugosi, and P. Massart. 2013. Concentration Inequalities: A
Nonasymptotic Theory of Independence. OUP Oxford.
[9] Konstantinos Chatzikokolakis, Tom Chothia, and Apratim Guha. 2010. Statistical
Measurement of Information Leakage. In TACAS (Lecture Notes in Computer
Science, Vol. 6015). Springer, 390–404.
[10] Konstantinos Chatzikokolakis, Natasha Fernandes, and Catuscia Palamidessi.
2019. Comparing systems: max-case refinement orders and application to differ-
ential privacy. In Proceedings of the 32nd IEEE Computer Security Foundations Sym-
posium. Hoboken, United States, 442–457. https://doi.org/10.1109/CSF.2019.00037
[11] Konstantinos Chatzikokolakis, Catuscia Palamidessi, and Prakash Panangaden.
2008. Anonymity protocols as noisy channels.
Inf. Comput 206, 2-4 (2008),
378–401.
[12] Konstantinos Chatzikokolakis, Catuscia Palamidessi, and Prakash Panangaden.
2008. On the Bayes risk in information-hiding protocols. Journal of Computer
Security 16, 5 (2008), 531–571. https://doi.org/10.3233/JCS-2008-0333
[13] Giovanni Cherubin. 2017. Bayes, not Naïve: Security Bounds on Website Finger-
printing Defenses. PoPETs 2017, 4 (2017), 215–231.
[14] Giovanni Cherubin, Konstantinos Chatzikokolakis, and Catuscia Palamidessi.
2019. F-BLEAU: Fast Black-box Leakage Estimation. IEEE Symposium on Security
and Privacy abs/1902.01350 (2019). http://arxiv.org/abs/1902.01350
[15] Giovanni Cherubin, Jamie Hayes, and Marc Juárez. 2017. Website Fingerprinting
Defenses at the Application Layer. PoPETs 2017, 2 (2017), 186–203.
https:
//doi.org/10.1515/popets-2017-0023
[16] Lénaïc Chizat and Francis Bach. 2020.
Implicit Bias of Gradient Descent for
Wide Two-layer Neural Networks Trained with the Logistic Loss. In Conference
on Learning Theory, COLT 2020, 9-12 July 2020, Virtual Event [Graz, Austria]
(Proceedings of Machine Learning Research, Vol. 125), Jacob D. Abernethy and
Shivani Agarwal (Eds.). PMLR, 1305–1338. http://proceedings.mlr.press/v125/
chizat20a.html
[17] Tom Chothia and Apratim Guha. 2011. A Statistical Test for Information Leaks
Using Continuous Mutual Information. In CSF. IEEE Computer Society, 177–190.
http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=5991608
[18] Tom Chothia, Yusuke Kawamoto, and Chris Novakovic. 2013. A tool for es-
timating information leakage. In International Conference on Computer Aided
Verification (CAV). Springer, 690–695.
[19] Tom Chothia, Yusuke Kawamoto, and Chris Novakovic. 2014. LeakWatch: Esti-
mating Information Leakage from Java Programs. In ESORICS (2) (Lecture Notes
in Computer Science, Vol. 8713), Miroslaw Kutylowski and Jaideep Vaidya (Eds.).
Springer, 219–236.
[20] David Clark, Sebastian Hunt, and Pasquale Malacaria. 2001. Quantitative Analysis
of the Leakage of Confidential Data. Electr. Notes Theor. Comput. Sci 59, 3 (2001),
238–251.
[21] George Cybenko. 1992. Approximation by superpositions of a sigmoidal function.
MCSS 5, 4 (1992), 455.
[22] Eloi de Chérisey, Sylvain Guilley, Olivier Rioul, and Pablo Piantanida. 2019. Best
Information is Most Successful - Mutual Information and Success Rate in Side-
Channel Analysis.
IACR Trans. Cryptogr. Hardw. Embed. Syst. 2019, 2 (2019),
49–79. https://doi.org/10.13154/tches.v2019.i2.49-79
[23] Luc Devroye, László Györfi, and Gábor Lugosi. 1996. Vapnik-Chervonenkis Theory.
Springer New York, New York, NY, 187–213. https://doi.org/10.1007/978-1-4612-
0711-5_12
[24] Dheeru Dua and Casey Graff. 2017. UCI Machine Learning Repository (Heart
Disease Data Set). https://archive.ics.uci.edu/ml/datasets/heart+Disease
[25] Cynthia Dwork. 2006. Differential Privacy. In 33rd International Colloquium on
Automata, Languages and Programming (ICALP 2006) (Lecture Notes in Computer
Science, Vol. 4052), Michele Bugliesi, Bart Preneel, Vladimiro Sassone, and Ingo
Wegener (Eds.). Springer, 1–12. http://dx.doi.org/10.1007/11787006_1
[26] Cynthia Dwork, Frank Mcsherry, Kobbi Nissim, and Adam Smith. 2006. Cali-
brating noise to sensitivity in private data analysis. In In Proceedings of the Third
Theory of Cryptography Conference (TCC) (Lecture Notes in Computer Science,
Vol. 3876), Shai Halevi and Tal Rabin (Eds.). Springer, 265–284.
[27] Ehab ElSalamouny and Catuscia Palamidessi. 2020. Full Convergence of the
Iterative Bayesian Update and Applications to Mechanisms for Privacy Protection.
arXiv:1909.02961 [cs.CR] To appear in the proceedings of EuroS&P.
[28] Ian J. Goodfellow, Yoshua Bengio, and Aaron C. Courville. 2016. Deep Learning.
MIT Press. 1–775 pages. http://www.deeplearningbook.org/
[29] T. Hastie, R. Tibshirani, and J. Friedman. 2001. The Elements of Statistical Learning:
Data Mining, Inference and Prediction. Springer-Verlag.
[30] Boris Köpf and David A. Basin. 2007. An information-theoretic model for adaptive
side-channel attacks. In Proceedings of the 2007 ACM Conference on Computer
and Communications Security, CCS 2007, Alexandria, Virginia, USA, October 28-31,
2007, Peng Ning, Sabrina De Capitani di Vimercati, and Paul F. Syverson (Eds.).
ACM, 286–296.
[31] Boris Köpf and Markus Dürmuth. 2009. A Provably Secure and Efficient Counter-
measure against Timing Attacks. In Proceedings of the 2009 22nd IEEE Computer
Security Foundations Symposium (CSF ’09). IEEE Computer Society, USA, 324–335.
https://doi.org/10.1109/CSF.2009.21
[32] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. 1998. Gradient-based learning
[34] S. Y. Sekeh, B. Oselio, and A. O. Hero. 2020. Learning to Bound the Multi-Class
applied to document recognition. Proc. IEEE 86, 11 (1998), 2278–2324.
[33] Marco Romanelli, Catuscia Palamidessi, and Konstantinos Chatzikokolakis. 2020.
Generating Optimal Privacy-Protection Mechanisms via Machine Learning, In
Proceedings of the IEEE International Symposium on Computer Security Foun-
dations (CSF). CoRR. arXiv:1904.01059 http://arxiv.org/abs/1904.01059
Bayes Error. IEEE Transactions on Signal Processing 68 (2020), 3793–3807.
[35] Shai Shalev-Shwartz and Shai Ben-David. 2014. Understanding machine learning
: from theory to algorithms. http://www.worldcat.org/search?qt=worldcat_org_
all&q=9781107057135
Jean-Yves Le Boudec, and
In IEEE
Jean-Pierre Hubaux. 2011.
IEEE Computer Society, 247–262.
Symposium on Security and Privacy.
http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=5955408;http:
//www.computer.org/csdl/proceedings/sp/2011/4402/00/index.html
[36] Reza Shokri, George Theodorakopoulos,
Quantifying Location Privacy.
[37] Reza Shokri, George Theodorakopoulos, Carmela Troncoso, Jean-Pierre Hubaux,
and Jean-Yves Le Boudec. 2012. Protecting location privacy: optimal strategy
against localization attacks. In the ACM Conference on Computer and Communi-
cations Security, CCS’12, Raleigh, NC, USA, October 16-18, 2012, Ting Yu, George
Danezis, and Virgil D. Gligor (Eds.). ACM, 617–627. http://dl.acm.org/citation.
cfm?id=2382196
[38] Geoffrey Smith. 2009. On the Foundations of Quantitative Information Flow. In
Foundations of Software Science and Computational Structures, 12th International
Conference, FOSSACS 2009, Held as Part of the Joint European Conferences on Theory
and Practice of Software, ETAPS 2009, York, UK, March 22-29, 2009. Proceedings
(Lecture Notes in Computer Science, Vol. 5504), Luca de Alfaro (Ed.). Springer,
288–302.
[39] Kagan Tumer and Joydeep Ghosh. 2003. Bayes Error Rate Estimation Us-
International Journal of Smart Engineering Sys-
https://doi.org/10.1080/10255810305042
ing Classifier Ensembles.
tem Design 5, 2 (2003), 95–109.
arXiv:https://doi.org/10.1080/10255810305042
[40] David H. Wolpert. 1996. The Lack of A Priori Distinctions Between Learning
Algorithms. Neural Computation 8, 7 (1996), 1341–1390.
A AUXILIARY RESULTS
ř
[8]). Let
Proposition A.1
(Bernstein’s
Z1, . . . , Zn „ Z be i.i.d. random variables such that Z P ra, bs almost
i“1 Zi ´ErZs and v “ VarpZq the variance
surely and let Sn “ 1
ˆ
of Z. Then, for any ε ą 0, we have:
´
PrSn ě εs ď exp
ineqality
˙
(35)
n ε
n
n
2
.
2 v ` 2pb´aqε{3
Compared to the Hoeffding’s inequality, it is easy to check that, for
regimes where ε is small, Bernstein’s inequality offers tighter bounds
for v ! pb ´ aq2.
Lemma A.2. Let σ
variable such that for all 0 ă t ď σ
2 “ VarpZq and let Z be a real-valued random
Then,
ż
σ 2
0
2,
PpZ ě tq ď 2q exp
PpZ ě tqdt ď qr
?
π erf
ˆ
2
2
´ t
r
˙
ˆ
.
2
σ
r
˙
,
(36)
(37)
˘
.
2q
(38)
where, for large x,
Proof. ż
erfpxq « 1 ´ expp´x
?
π
x
` O
2q
ż
σ 2
0
PpZ ě tqdt ď
2q exp
σ 2
0
“ qr
?
π erf
`
x´1 expp´x
ˆ
˙
ˆ
˙
´ t
r
2
2
2
σ
r
,
dt
and eq. (38) follows from the Taylor’s expansion of the erf function.
□
B PROOFS FOR THE STATISTICAL BOUNDS
The following lemma is a simple adaption of the uniform deviations
of relative frequencies from probabilities theorems in [23].
Proof.
Vд ´ Vpf ‹
Lemma B.1. The following inequality holds:
Vд ´ Vpf ‹
mq ď 2 max
f PH
ˇˇ.
ˇˇpVmpf q ´ Vpf q
mq `pVmpf ‹
mq “ Vpf ‹q ´pVmpf ‹
ˇˇpVmpf ‹
ˇˇ
ď Vpf ‹q ´pVmpf ‹
ˇˇpVmpf ‹
ˇˇ
ď Vpf ‹q ´pVmpf ‹q `
ˇˇpVmpf ‹
ˇˇ `
ˇˇVpf ‹q ´pVmpf ‹q
ˇˇ
ˇˇ ` max
ˇˇpVmpf q ´ Vpf q
ˇˇpVmpf q ´ Vpf q
ˇˇ
ˇˇpVmpf q ´ Vpf q
ˇˇ.
mq ´ Vpf ‹
mq
mq ´ Vpf ‹
mq
mq ´ Vpf ‹
mq
mq ´ Vpf ‹
mq
ď
ď max
f PH
ď 2 max
f PH