proposed a compilation-based approach instead, showing that
it increases execution performance as well as the overall ex-
ploration capability of the resulting system. SymCC hooks into
compilers and instruments target code at compile time, inject-
ing calls to a run-time support library. Symbolic execution thus
becomes an integral part of the compiled program. Moreover,
the analysis code beneﬁts from compiler optimizations, and
instrumentation work is not duplicated at every execution.
Figure 4 illustrates the design.
SymCC’s compilation-based approach fundamentally re-
quires a compiler—it is therefore applicable only when source
code of the program under test is available. Nonetheless, we
considered the approach promising enough to search for a
way to apply it to binary-only symbolic execution. A ma-
jor contribution of the present paper is to demonstrate how
compilation-based symbolic execution can, in fact, be made to
work efﬁciently on binaries.
III. SYMQEMU
We now present the design and implementation of our
binary-only symbolic executor SymQEMU. It draws from
previous work and combines the advantages of state-of-the-art
systems with novel ideas to create a fast yet ﬂexible analysis
engine.
A. Design
The system has two main goals:
1)
2)
Achieve high performance in order to scale to real-
world software.
Stay reasonably platform-independent,
i.e., adding
support for a processor architecture should not require
a major effort.
Based on the survey in Section II-C, we observe that
popular state-of-the-art systems typically achieve one of those
goals, but not both: among those presented, S2E and angr are
highly ﬂexible yet fall behind in performance [19], whereas
QSYM is very fast but intimately tied to the x86 platform [28].
We have seen that current solutions which are platform-
independent translate the program under test to an intermediate
4
SymCCCompilerfrontendSourcecodeCompilerbackendPassLLVMbitcodeHostmachinecodeSymbolic or concreteexecution on the host CPU(based on demand)InstrumentedLLVM bitcodeFig. 5. Overview of regular QEMU: the target program is translated to TCG
ops, which are subsequently compiled to machine code and executed on the
host CPU.
place: The CPU executes machine code much faster than an
interpreter can run the intermediate representation, such that
we achieve performance comparable to a non-translating sys-
tem while retaining the advantage of architecture independence
that comes with program translation.
B. Implementation
We implemented SymQEMU on top of QEMU [3], as
suggested by the name. We have chosen QEMU because
it is a robust system emulator that supports a plethora of
architectures. Building on it, we are able to achieve our
goal of platform independence. Note that S2E is similarly
based on QEMU, presumably for similar reasons. But there is
another characteristic of QEMU that caters to our needs and
differentiates it from other translators: QEMU does not only
translate binaries to a processor-independent intermediate rep-
resentation, it also has facilities for compiling the intermediate
language down to machine code for the host CPU. We leverage
this mechanism to achieve our second goal: performance.
Note that
the Valgrind framework supports a simi-
lar mechanism, which its authors call “disassemble-and-
resynthesize” [17]; the main advantage of QEMU over Val-
grind for our purposes is that QEMU can translate binaries
from a given guest architecture into machine code for a
different host architecture, as well as emulate an entire system,
which makes it a better basis for future extensions supporting
cross-architecture ﬁrmware analysis.
Concretely, we extend a component in QEMU called Tiny
Code Generator (TCG). In unmodiﬁed QEMU, TCG is re-
sponsible for translating blocks of guest-architecture machine
code to an architecture-independent
language called TCG
ops, then compile those TCG ops to machine code for the
host architecture (see Figure 5). The translated blocks are
subsequently cached for performance reasons, so translation
needs to happen only once per execution. SymQEMU inserts
one more step into the process: While the program under test is
being translated to TCG ops, we emit not only the instructions
that emulate the guest CPU but also additional TCG ops to
construct symbolic expressions for the results (see Figure 6).
For example, suppose that a function in a target program
adds the constant 42 to an input integer (using C code for the
example):
int add42(int x) {
return x + 42;
}
With optimization enabled, GCC inlines the function and
translates it to this assembly instruction when compiling for
the x86-64 architecture:
lea
esi,[rax+0x2a]
The machine code is all that SymQEMU gets; it does
not have access to the source code (which we display for
illustration purposes only). When we execute the target, TCG
produces the following architecture-independent representation
of the machine code:
movi_i64 tmp12, $0x2a
add_i64 tmp2, rax, tmp12
ext32u_i64 rsi, tmp2
Note that
the arguments of TCG ops are ordered like
x86 assembly in Intel syntax, i.e., the destination is the ﬁrst
argument of any instruction. The instructions above perform
a 64-bit addition and store the result as a 32-bit
integer.
Regular QEMU would translate these TCG ops to machine
code for the host architecture. SymQEMU, however, inserts
additional instructions for symbolic computation before the
code is translated to the host architecture:
movi_i64 tmp12_expr, $0x0
movi_i64 tmp12, $0x2a
call sym_add_i64, $0x5, $1, tmp2_expr,
rax, rax_expr, tmp12, tmp12_expr
add_i64 tmp2, rax, tmp12
movi_i64 tmp12, $0x4
call sym_zext, $0x5, $1, rsi_expr,
tmp2_expr, tmp12
ext32u_i64 rsi, tmp2
Each block of code corresponds to one of the TCG ops
produced by QEMU originally; in fact, the last instruction of
every block is identical with the respective original instruction.
In the ﬁrst block, we set the expression pertaining to the
constant 42 to null (i.e., we declare the value to be concrete). In
the second block, the helper sym_add_i64 creates a symbolic
expression representing the addition of two 64-bit integers
(using rax_expr, the expression corresponding to the function
input). Finally, the last block calls the helper sym_zext with
argument 4 to build an expression that translates the result
of the addition to a 4-byte (i.e., 32-bit) quantity. Crucially,
SymQEMU does not perform any of these calls to the support
library at translation time (as an interpreter would)—it only
emits the corresponding TCG ops and relies on the regular
QEMU mechanisms to translate them to machine code. This
way, symbolic formulas are constructed in native machine code
without incurring the overhead associated with interpreting an
intermediate language.
For the support library that constructs symbolic expressions
and solves queries over them, we reuse code from SymCC,
which is in turn based on QSYM. This has the advantage,
in addition to saving us from having to reimplement what
works well in QSYM, that it eliminates a source of noise
from our evaluation: since SymQEMU and QSYM use the
same logic for building up and simplifying expressions, as
well as for interaction with the solver, we can be sure that
5
QEMUTCG lifterBinaryTCGcompilerTCG opsHostmachinecodeConcreteexecution on the host CPUFig. 6. Overview of SymQEMU: the target program is translated to TCG
ops as in regular QEMU (see Figure 5), but before the compilation to host
machine code we insert instructions to perform symbolic execution at run
time.
observed performance differences do not originate from those
orthogonal design aspects.
We currently use QEMU’s Linux user-mode emulation,
i.e., we emulate only the user space of the guest system.
System calls are translated to fulﬁll the host architecture’s
requirements, and they are executed against the host kernel
(using normal QEMU mechanics). Consequently, our symbolic
analysis stops at the system-call boundary, similar to QSYM
and angr. Compared to full-system emulation (as performed
by S2E), this saves the effort of preparing OS images for
each target architecture, and increases performance by running
kernel code concretely and without emulation. Note, however,
that SymQEMU could be extended to work with QEMU’s full-
system emulation if necessary (see Section V).
Overall, SymQEMU adds about 2,000 lines of C code
to QEMU. Furthermore, we added a few lines of C++ (less
than 100) to SymCC’s support library in order to support our
approach to memory management (see Section III-E).
C. Platform independence
We stated that support for multiple CPU architectures was
an important goal for SymQEMU from the start. Therefore, we
now examine in detail to which extent our system achieves it.
(SymQEMU’s claim to the second design goal, performance,
is validated experimentally in Section IV.)
First of all,
it
is important
to distinguish between the
architecture of the computer that runs the analysis (typically
called the host) and the architecture that the program under test
is compiled for (the guest in QEMU parlance). Especially in
ﬁrmware analysis, it is desirable for host and guest architecture
to be different—the embedded device that a ﬁrmware under
test runs on may lack the computing power to perform sym-
bolic analysis at a reasonable pace, so one would typically run
the symbolic executor (and, in general, any ﬁrmware tests [9])
on a more powerful machine. SymQEMU is well prepared for
this use case: QEMU runs on all major host architectures.4
But what about guest architectures? SymQEMU lever-
ages QEMU’s TCG translators, which cover a wide range
of processor types—the online documentation5 currently lists
22 platforms including x86, ARM, MIPS and Xtensa, each
comprising numerous processor types. Moreover, our modiﬁ-
cations are almost entirely independent of the target platform:
4Our prototype currently requires a 64-bit host system for implementation
simplicity.
5https://wiki.qemu.org/Documentation/Platforms
out of the 2,000 lines of C code that we added to QEMU,
only 10 are speciﬁc to the guest architecture (i.e., x86 in our
experiments). In particular, they perform the following tasks:
•
•
6 lines add space for symbolic expressions to the data
structure describing the registers of the emulated CPU.
Adapting them to other CPU architectures is a simple
copy-paste task.
The remaining 4 lines of code insert TCG ops on
guest-level call and return instructions. This is op-
tional, but it allows the code borrowed from QSYM
to maintain a shadow call stack (see Section III-G). In
order to support another target architecture, one just
has to identify the architecture’s respective call and
return primitives.
We conﬁrmed the claim to easy adaptability by adding
support for AArch64 to SymQEMU. It required 17 lines of
C code, excluding the optional call and return instrumentation.
Note that
implementation expects 64-bit guest
architectures (so that host addresses can be passed in guest reg-
isters), but there is no fundamental reason for this limitation—
it could be eliminated with a one-time development effort.
the current
In summary, SymQEMU runs on all relevant host archi-
tectures and supports the analysis of binaries compiled for
any guest architecture that QEMU can handle, with negligible
effort.
D. Comparison with previous designs
We would like to point out how SymQEMU differs from
the state-of-the-art systems presented in Section II.
Like angr and S2E, SymQEMU follows the traditional
approach of implementing symbolic handling at the level of
an intermediate representation, which signiﬁcantly reduces the
complexity of the implementation. However, in contrast with
those two, SymQEMU performs compilation-based symbolic
execution, allowing it to achieve much higher performance (see
Section IV).
Compared with QSYM, the most important advantage of
SymQEMU’s design is architectural ﬂexibility while maintain-
ing high execution speed. Building on top of QEMU allows it
to beneﬁt from the large number of platforms that the emulator
supports.
SymCC, although unable to analyze binaries, shares the
compilation-based approach with SymQEMU. Both insert
symbolic handling into the target program by modifying its
intermediate representation, and both compile the result down
to machine code that can be executed efﬁciently. However,
SymCC is inherently designed to work in a compiler, whereas
SymQEMU addresses the different set of challenges encoun-
tered in binary-only symbolic execution (see Section II-B):
where SymCC instruments LLVM bitcode during (source-
based) compilation, SymQEMU instruments TCG ops during
dynamic binary translation. See Section III-F for challenges
that are speciﬁc to working on top of a dynamic binary
translator. Moreover, SymQEMU handles mismatches between
target and host architectures, an issue that does not arise in
SymCC’s setting because source code is mostly independent
of the target architecture. In this context, we would like
6
SymQEMUTCG lifterBinaryCustominstrumenterTCG opsHostmachinecodeSymbolic or concreteexecution on the host CPU(based on demand)TCGcompilerInstrumentedTCG opsto emphasize that SymQEMU can support cross-architecture
analysis, i.e., the CPU architecture that the program under test
is compiled for does not need to match the architecture of the
machine performing the analysis.
In summary, we believe that our approach combines the
main advantages of angr and S2E on the one hand (i.e.,
platform independence) and QSYM on the other (i.e., per-
formance), but avoids their respective disadvantages (lower
performance and dependence on a particular architecture,
respectively). Moreover, we found a way to apply SymCC’s
core idea of compilation-based symbolic execution to binaries.
Table I summarizes the comparison. Speed refers to a focus
on execution speed, multiarch means easy portability to various
guest CPU architectures, binary-only refers to support for
analysis without source code, and cross-architecture means the
ability to analyze programs targeting a different architecture
than the host.
We now discuss some of the challenges that we faced when
building SymQEMU.
E. Memory management
As SymQEMU executes the program under analysis, it
builds up symbolic expressions that describe intermediate
results and path constraints. The amount of memory required
for those expressions increases over time, so SymQEMU needs
a way to clean up expressions that are not needed anymore.
Before we describe SymQEMU’s approach to memory
management, let us discuss why managing memory is nec-
essary in the ﬁrst place. After all, intermediate results in any
reasonable program should either have an impact on control
ﬂow or become part of the ﬁnal result—in the former case,
the corresponding expressions are added to the set of path
constraints and thus cannot be cleaned up, and in the latter
case the expressions become subexpressions in the description
of the end result. So how can symbolic expressions ever
become unneeded? The key insight is that program output is
conceptually part of a program’s result, but it may be produced
well before the end of execution. Consider the example of an
archive tool which lists the contents of an archive, printing ﬁle
names one by one: after each piece of output is produced, the
program can delete the associated string data, and SymQEMU
should clean up the corresponding symbolic expressions. Oth-
erwise, expressions would accumulate and, in the worst case,
consume all available memory.
Ideally, we would delete symbolic expressions precisely
after their last use. QSYM, whose backend we reuse, employs
C++ smart pointers to this end. However, we cannot easily
follow the same approach in our modiﬁed version of QEMU:
TCG, the QEMU component at the center of our execution
mechanism, is a dynamic translator—for performance reasons,
it does not conduct any extensive analysis of translated code
(unlike static compilers, which typically collect a signiﬁcant
amount of information related to variable scope and lifetime).
This makes it difﬁcult to efﬁciently determine the right place
for inserting cleanup code in the translated program. Moreover,
experience shows that most programs contain relatively little
symbolic data and even less expressions that become garbage
during execution, so we do not want our cleanup scheme to
incur signiﬁcant overhead in the most common case where all
expressions can reside in memory until the end of program
execution.
We opted for an optimistic cleanup scheme based on
an expression garbage collector: SymQEMU keeps track of
all symbolic expressions obtained from the backend, and if
their number grows too large it triggers a collection. The
core observation is that all live expressions can be found by
scanning (1) the symbolic registers of the emulated CPU and
(2) the shadow regions in memory that store symbolic expres-
sions corresponding to symbolic memory contents; both are
known to the backend. After enumerating all live expressions,
SymQEMU can compare the resulting set with the set of all
expressions ever constructed, and free those that are not live
anymore. In particular, when a program removes the results of
a computation from registers and memory (as in the example
of the archiver above), the corresponding expressions are not
considered live anymore and will thus be freed. We have
connected the expression garbage collector to QSYM’s smart-
pointer based memory management—both mechanisms need
to agree that an expression is unused before it can be freed.
F. Modifying TCG ops
Our approach fundamentally requires the ability to insert
new instructions into the list of TCG ops that represent a
piece of target code. However, TCG was never meant to allow
for such extensive modiﬁcations during translation—being a
dynamic translator,
it has a strong focus on speed. As a
consequence, there is little support for programmatic editing of
TCG ops. Whereas LLVM, for example, provides an extensive
API for compiler passes to inspect and modify LLVM bitcode,6
TCG simply stores instructions in a ﬂat linked list without any
navigable higher-level structure like basic blocks. Moreover,
control ﬂow is expected to be linear within a translation block
(with very limited exceptions), precluding optimizations such
as SymCC’s embedded concreteness checks [20].
In order to minimize friction with the TCG infrastructure,
our implementation emits symbolic handling for each target
instruction when the instruction itself is generated. While this
prevents issues with TCG’s optimizer and code generator, it
renders advanced static optimizations infeasible because our
view is limited to only a single instruction at a time. In par-
ticular, we have very little opportunity to determine statically
whether a given temporary value is concrete. Similarly, we
cannot emit jumps that directly skip symbolic computations
if all operands turn out to be concrete at run time. Instead,
we settled on a compromise that accounts for the constraints
of TCG’s operating environment (in particular, the need for
fast dynamic translation) while still allowing us to achieve
relatively high execution speed: We perform concreteness
checks in the support library—this way, we can still skip
symbolic computations when the inputs are concrete, but the
check costs an additional library call.
G. Shadow call stack
QSYM introduced the concept of context-sensitive basic-
block pruning [28], a technique that suppresses symbolic
6https://llvm.org/docs/ProgrammersManual.html#helpful-hints-for-
common-operations
7
TABLE I.
COMPARISON OF SYMQEMU WITH STATE-OF-THE-ART SYMBOLIC EXECUTION SYSTEMS.
Symbolic executor
Reference
Implementation
language
Intermediate