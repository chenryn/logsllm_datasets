applicability.
Due to our recruitment approach aiming for a high diversity
in projects, our participants reported a wide range of projects
and backgrounds, ranging from operating system components,
over libraries, to scientific computing frameworks. For each
individual participant, we report project categories and com-
mits of the largest project they mentioned in Table I. Project
contributors are often highly distributed, with five of 27
participants reporting to know other contributors only virtually.
E. g., as P17 reported: “Everybody that I’ve encountered has
just been virtually: I can see the profile picture of some people,
and that’s the only image I have of them.” (P17). Although
this does not seem to impair collaboration: “But to be honest,
I don’t really mind. As long as one has the same interests, it’s
still easy to collaborate if you have the same goal.” (P17). At
the other extreme, four participants mentioned very close con-
nections such as working at the same company or university.
We sorted our participants into their highest project role with
a roughly ascending order of responsibility: contributors (4),
maintainers (3), team leaders (7), and founders or owners (9).
Overall, we found our participants to be more experienced
than we expected, often having been involved for multiple
years and possessing high-level commit rights. We assume this
high level of experience was due to our recruiting focusing
on “expert channels” such as project-specific communication
channels or dedicated contact addresses, as well as being
referred further up in projects until reaching founders and
owners.
Summary: Project Demographics. The majority of our
participants are highly experienced in the open source
environment, often with multiple years of work and high-
level commit rights.
B. Security Challenges
In this section, we explore past security challenges en-
countered by our participants as well as their opinion of
the widely reported “hypocrite commits” incident. More than
half (16) of our participants reported never having encountered
a direct security incident in the past. The most commonly
reported security challenges (that did not necessarily lead to an
incident) included: suspicious or low quality commits (15) and
vulnerabilities introduced by dependencies (8). Overall, our
participants seem to be mostly ambivalent about potentially
malicious commits: “I mean, there’s definitely been people
that have intentionally tried to put malicious code in projects,
but it’s always very easy to spot immediately. It’s like those
spam emails where they have bad grammar and stuff.” (P06).
Same holds true for vulnerabilities in dependencies, which
apparently often turn out to be false positives or to be irrelevant
for participants’ projects:
the time,
“Most of
the vulnerabilities I deal with
are transitive dependencies, have a CVE, and 99.99
percent of
they are false positives for
every other use case: it’s a real vulnerability in the
dependency, but it’s not in the way almost anyone
uses it.” — P06.
the time,
The majority of our participants were aware of the “hyp-
ocrite commits” incident in early 2021 (23 of 27). For the
remaining four, we provided a short, factual summary of the
incident during the interview. Of the 16 participants with a
generally negative opinion of the incident, many considered
the research approach as outright malicious: “[t]he shocking
and surprising part was, that an academic institution would
essentially do evil and justify it by saying that the ends justify
the means.” (P06). This is likely a misconception, as the
researchers stated that they did not intend to, and objectively
did not, introduce any vulnerability in Linux [10]. Of the
remaining participants with a mixed (7) or no opinion (4),
some considered the research approach similar to that of a
“White Hat Hacker”, although with a flawed execution. E.g., “I
do understand both sides of this [. . .] It would be much better
if this kind of research was done in cooperation with somebody
at the Linux kernel, who knew that it’s happening and without
disclosing that to a lot of people.” (P11). We could not identify
a single participant with an outright positive opinion of the
incident. We assume this skew was likely exaggerated by the
generally negative, sometimes misinformed reporting by open
source aligned news sources and communities.
Summary: Security Challenges. Only few projects have
experienced an outright security incident, although many of
our participants were familiar with suspicious or low quality
commits as well as potential vulnerabilities introduced
by dependencies. The majority of our participants were
generally aware of the “hypocrite commits” incident and
had an overall negative opinion of the research approach.
C. Guidance and Policies
In this section, we examine guidance and best practices pro-
vided by the projects, as well as the content and applicability
of security and disclosure policies.
Guidance: Most commonly, our participants mentioned guid-
ance for contributing to the project (14) and programming
language-specific guidance such as style guides (13), followed
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1886
by general guidance for project setup and infrastructure (8).
As reasons for not providing specific guidance documents,
participants mention time and money constraints: “Somebody
would have to write the guide, and I am the only one who can
write it. I mean, there is nobody paid to write it and I am also
not paid to write it.” (P26). More generally, our participants
are somewhat divided in their opinions of the helpfulness
of guidance for their projects, ranging from very positive:
“I personally think that documentation is one of the most
important aspects of an open source project, both for users and
also developers.” (P27), to less helpful, as for P02’s project:
“I’m also honestly not quite sure that’s really that helpful [. . .]
Of course, it’s quite nice to have overviews and stuff like that
somewhere, but there aren’t too many people who then read
something like that.” (P02). Instead, P02 mentions that they
prefer to coach new contributors: “Most of the people who
are interested show up in the communication channels. And
then it depends on [project members] being communicative by
helping the other person.” (P02). Similarly, P11 mentions an
approach outside of classical guidance documents: “We answer
very detailed answers to questions of users, which then become
the kind of searchable result of answers for guides, including
security fixes.” (P11). This difference in approaching guidance
appears to be between projects with a more technical developer
audience preferring coaching or static testing, vs. projects
with less technical contributors such as scientists preferring
extensive guidance, although our interview coverage of these
aspects was too low to statistically confirm this.
Security Policies: Next, we were interested in the content
and applicability of our participants’ security and disclosure
policies. Of our 27 participants, eight mention that
their
projects do not have specific security policies. P06 offers one
possible explanation for this:
“So in the same way as people don’t make a security
policy on their repo unless something pushes them to
do it or unless they have a security incident, people
aren’t going to document security best practices
unless they’ve had a problem. Part of that is because
they may not know to do so. But part of that is also
because is there a need?” — P06.
The most commonly mentioned security policy aspect (10)
was related to providing a security-specific contact for the
project and/or to a dedicated security team. Less common
security policies include air gapping: “The policy of [the
project] is that any released software has to be built on
a machine controlled by the release manager.” (P11) and
programming language-specific policies: “Everything that is
related to crypto or network code or parsing and so on is all
written in Rust. That’s already a kind of policy.” (P02).
Only four of our participants explicitly mentioned not
having any form of disclosure policy or security contact.
Disclosure approaches mentioned by the other participants
included a policy or plan for coordinated disclosure (10), pri-
vate channels for disclosure (5), and plans for full disclosure,
e. g., as public issue (2). The often heated debate regarding
coordinated disclosure in open source projects extends to our
participants: “[the projects] say: we’re just putting our users
at too much risk. We’re not sitting on patches, the people
out there have installations on the front line, and because
somebody likes to coordinate something, we’re not waiting
three months longer.” (P01).
Testing and Reviews: Being closely related to policies, we
also queried our participants about their security testing and
review setup, with many participants mentioning automated
tests and mandatory reviews: “There are standard practices
like there is a test suite, we’ve unit tests, integration tests, and
as soon as we find any bugs or you write regression tests and
there are codes, there’s peer reviews of our codes and larger
reviews of bigger PRs as well.” (P05).
Summary: Guidance and Policies. Our participants appear
to diverge in their opinions regarding the helpfulness of
(written) guidance. For security policies, larger projects
mentioned dedicated security teams, while smaller projects
mentioned a security contact channel. Most projects in-
cluded some type of disclosure policy or at least contact
for security issues.
D. Project Structure
With this section, we wanted to explore structures that
are often not directly visible from repository artifacts, such
as how build and deploy steps are set up, selection criteria
and vulnerability checks for dependencies, and any additional
infrastructure such as project websites and communication
tools. The specific project setups appear to be as diverse as
our participants’ projects. As probably expected of open source
projects, most development approaches appear to be somewhat
open:
“It’s an open-source project, everything from [build]
stages to CI is in the same repository, and everyone
can contribute to it. However, no one has direct
control over anything because everything executed
is a series of scripts and tests in the main reposi-
tory, meaning that anyone can send a pull request
tomorrow and modify them.” — P25.
Code submissions are at the heart of open source collabo-
ration, making pull request handling and build pipeline setup
part of the overall security and trust strategy.
Pull Requests: Specifically for
requests,
projects provide a number of controls, e. g., by protecting the
main branch: “The main branch is protected. Of course, we do
everything through forks. Meaning, each developer has their
own fork, opens a pull request and there’s a limited number
of people who have the permissions to do the final merge.”
(P19).
incoming pull
Our participants opt for a number of different strategies
for merging code contributions, such as only rebasing on
main: “We actually always require from the author to rebase
their changes on top of the main, so that we don’t have the
whole complex structure of merges [. . .] which actually helps
to pinpoint any kind of problems [. . .]” (P11), a majority
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1887
vote before merging pull requests: “So on each PR you
can review it and then give a thumbs-up or thumbs-down.
And that’s done by at least three of the main contributors,
[. . .] and that means that it’s a majority of them think that
it’s a worthy contribution.” (P17), or an optimistic merging
approach with resolving problems in follow-up pull requests:
“[Y]ou optimistically merge code as long as it passes some
basic sanity checks. If someone thinks that the code which is
merged isn’t actually perfect, there is some way to improve it,
they need to send a follow-up pull request.” (P16). Overall,
project structure and code submission handling appear to be
specialized to the project’s needs and community.
Build Pipeline: In the interviews, 23 participants mentioned
using CI/CD or or other automatic build systems in their
projects, with the majority relying on GitHub Actions (10).
Aside from GitHub Actions, many different systems were
mentioned, sometimes even within the same project: “But
basically we use everything,
like Travis, Azure Pipelines,
GitHub Actions, CircleCI, custom build machines and so
on. It’s quite a hodgepodge.” (P02). A few participants (3)
mentioned that they prefer manual builds and publishing for
a number of reasons, e. g., “I don’t like the one click deploy,
I like to actually see, you know, things fly by in the console.”
(P04). Running tests as part of the build pipeline is a common
practice, with some of our participants taking advantage of
this, e. g., “[. . .] we have a huge number of tests, actually.
More than 10,000 tests and 70 static check analyses.” (P11)
and “Every pull request automatically goes through our full
test suite [. . .] There are at least 1,000 files, each testing one
area.” (P12). Thoroughly testing every commit might include
some trade-offs in the context of attracting contributors, as
pointed out by P16: “If the tests run in five seconds, then
people will contribute, if the tests run in five hours, then people
will contribute less.” (P16).
Only four participants mentioned that they PGP sign com-
mits in their projects, although not always for security rea-
sons: “I PGP sign all my commits. The main reason I do
that is because it gives me a pretty little verified badge on
all my commits.” (P06). Reasons for not signing commits
included technical limitations: “[Commit signing] is one of
the things that is rather difficult to do if you are using the
GitHub workflow” (P11) and different workflows: “I don’t
make everybody do it, because eventually, the commit will get
squashed when I merge it, and then it’s going to be signed
by GitHub automatically.” (P24). Some of these issues might
be alleviated by a recent Git patch introducing SSH-based
signatures and verification, although it remains to be seen if
and how collaborative platforms will adapt.
‘Let’s avoid using that’.” (P24). Other participants had more
involved criteria for including a dependency:
“What I usually do before including any dependency
is I send them a pull request fixing something. And if
they don’t react on this or don’t merge that one, then
they don’t become my dependency because they are
obviously not interested in improving the software.”
— P18.
Some of such elaborate selection criteria even benefited all
involved parties: “As it happened also with [dependency]:
we reached out, we got a good response. We worked on
a few issues together, even I personally fixed one of those
issues [. . .]” (P11). Few mentioned that they manually review
third party dependencies: “Whenever we include a library in
a project, we examine the project beforehand and two or
three core contributors actually need to confirm that it looks
okay.” (P03). One participant mentioned looking for usages of
specific language features that may affect security: “I always
go to the source code. I searched for all uses of unsafe and I
check if they are, if they are like, if they make sense or not.”
(P22).
Summary: Project Structure. Our participants appear to
fully utilize modern build systems, including during testing
and deployment. Only few projects explicitly use signed
commits, often due to incompatibilities with their workflow
or threat model. Selection criteria for dependencies range
from readily available metrics over security reviews, to
elaborate collaborations or even rewrites.
E. Releases and Updates
In this question section, we were interested in the projects’
release decisions and schedules, whether there were guidelines
in place regarding release deprecation, how the releases are
distributed, and whether releases are digitally signed. The
release decisions of our participants broadly fit
into two
approaches: either as periodical releases (9) or when specific
features or patches are ready (10). Different communities
seem to favor different release approaches, as our participants
describe both feature-driven and cycle-driven release schedules
based on community input: “Periodically, we’ll reach consen-
sus in the community, and say, ‘Hey, we ought to do a release’,
and so we’ll stop developing for a few days and just make sure
there aren’t any major bugs.” (P09) and “We try to aim for
three times a year, mostly because the real reason for the three
times a year rough cycle is that we polled the community and
the kind of the averaging that three times a year seemed like
what suited people the most.” (P13). Some participants utilize
both approaches, depending on, e. g., project maturity:
Dependencies: Common criteria for selecting a dependency
included activity: “Our most important criteria, in general, is
that we do not want to rely on inactive projects.” (P25) and
reputation metrics like GitHub stars: “If somebody was pulling
in a package and I go to their GitHub and its got two stars
and it’s only used in this project, I’m probably going to say:
“Mainline development continues just normally under
main branch, and we have this temporary release
branch where we merge in only bug fixes that come
in during this time. This is for the most mature
projects [. . .] For projects that move faster and don’t
have for example, back-holding strategy for bugs