title:Scheduling for performance and availability in systems with temporal
dependent workloads
author:Ningfang Mi and
Giuliano Casale and
Evgenia Smirni
Scheduling for Performance and Availability in Systems with Temporal
Dependent Workloads∗
Ningfang Mi, Giuliano Casale, and Evgenia Smirni
Computer Science Department, College of William and Mary
{ningfang,casale,smirni}@cs.wm.edu
Abstract
Temporal locality in workloads creates conditions in
which a server, in order to remain available, should quickly
process bursts of requests with large service requirements.
In this paper, we show how to counteract the resulting peak
congestions and maintain high availability by delaying se-
lected requests that contribute to the temporal locality.
We propose and evaluate SWAP, a measurement-based
scheduling policy that approximates the shortest job ﬁrst
(SJF) scheduling without requiring any knowledge of job
service times. We show that good service time estimates can
be obtained from the temporal dependence structure of the
workload and allow to closely approximate the behavior of
SJF. Experimental results indicate that SWAP signiﬁcantly
improves system performability. In particular, we show that
system capacity under SWAP is largely increased compared
to ﬁrst-come ﬁrst-served (FCFS) scheduling and is highly-
competitive with SJF, but without requiring a priori infor-
mation of job service times.
1 Introduction
Temporal dependence in workloads processed by multi-
tier architectures, disk drives, and grid services, signif-
icantly reduces performance and availability by creating
peak congestions that can make service unavailable [9, 12,
14]. With temporal locality, requests with large service re-
quirements frequently appear clustered together, reducing
system throughput for a period that is usually much longer
than the duration of the arrival burst. Thus, system avail-
ability is strongly dependent on the response given to these
workload peaks and efﬁcient schemes to address bursts be-
come fundamental for performance and availability.
The characterization and the deﬁnition of remedies for
temporal dependence congestion effects have been exhaus-
tively studied in networking, leading to the development
∗This work was supported by the National Science Foundation under
grants ITR-0428330 and CNS-0720699.
of accurate models of autocorrelated trafﬁc processes (e.g.,
MMPP, fractional Brownian motion, M/G/∞) [18], and
to measurement-based load-control schemes for network
availability under rapidly changing ﬂows [7]. Unfortu-
nately, because of systematic violations of the underlying
assumptions, these schemes cannot be easily applied to sys-
tems. Deterministic or Erlang service time distributions in
ATM networks are replaced in systems by highly-variable
service demands [2, 14]; similarly, the usual assumption
that a channel multiplexes a sufﬁciently large number of
trafﬁc ﬂows to enable Gaussian approximations [7] is not ﬁt
for systems where restrictive constraints on the maximum
concurrency level exist, e.g., limits on the maximum num-
ber of simultaneous HTTP sessions or DB locking condi-
tions.
In this paper, we address
the lack of effective
measurement-based schemes to maintain performance and
availability in systems with temporal dependent workloads.
We focus on the difﬁcult case where processing the en-
tire workload is mandatory and where work reduction tech-
niques such as request drop cannot be applied. Our main
contribution is to show that signiﬁcant performance gains
and high system availability can be obtained by delaying se-
lected requests that contribute to temporal locality. We ob-
serve that request delaying results in signiﬁcant throughput
improvement throughout the network, thus allowing delay-
based scheduling to increase the amount of request that a
server can process at a given time and therefore avoiding
harmful congestion conditions. We interpret the signiﬁcant
performance improvement as an outcome of the autocorre-
lation reduction in the service process of the resource where
requests are delayed. Since the temporal dependence prop-
agates through the entire network [12], by decreasing the
autocorrelation at the resource with delay-based schedul-
ing, we also reduce the autocorrelation in the arrival process
of the other servers in the network, which results in gen-
eralized throughput improvement. We observe that larger
throughput lets the system sustain more customers, there-
fore improving the overall availability. We also remark that
this simple approach can be more effective than hardware
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 20081-4244-2398-9/08/$20.00 ©2008 IEEE336DSN 2008: Mi et al.upgrades, i.e., doubling the speed of a server is not as effec-
tive as implementing a delay-based scheduling technique at
the server with temporal dependent workload.
Delay-based scheduling is investigated throughout the
paper by deﬁning a new scheduling policy, called SWAP.
SWAP is a fully measurement-based policy that classiﬁes
(i.e., “predicts”) requests as short or long based on the tem-
poral dependence of the workload service process. That is,
we leverage on the structure of temporal locality to forecast
the size of upcoming requests and deﬁne self-adjusting cri-
teria to discriminate (i.e., delay) requests that the algorithm
deems as large, to be delayed. Experimental results indi-
cate that SWAP can increase throughput up to 30% − 40%
under temporal dependent workloads, without service rejec-
tion while maintaining the fraction of delayed requests low.
These results show that SWAP works comparably to Short-
est Job First (SJF), despite the fact that it does not require
any a priori knowledge of future workload.
Sensitivity analyses with respect
to device relative
speeds, to different degrees of temporal dependence, to sys-
tem load, and to network size show that SWAP is effective
and robust in many different environments. Furthermore,
we also show that in all cases, the performance under SWAP
is very close to that of the SJF policy, thus suggesting the
effectiveness of the workload prediction used by SWAP.
This paper is organized as follows.
In Section 2, we
present the SWAP scheduling algorithm. In Section 3 we
use simulation to validate the effectiveness and robustness
of SWAP. In Section 4 we give an overview of the previous
work in networking on scheduling and availability control
under temporal dependent workloads. Finally, in Section 5,
we draw conclusions and outline future work.
service center, and is immediately minimized if Sk ≤ Sk+1,
i.e., when short jobs are served ﬁrst.
Outside the above assumptions, SJF is not in general op-
timal, but yet provides signiﬁcant gains with respect to sim-
pler scheduling policies such as FCFS. We therefore inves-
tigate how the performance of SJF could be approximated
with an online policy that does not require a priori knowl-
edge. That is, the well-know problem of SJF is that it re-
quires information on the job service times, which in prac-
tice may not be available. The basic idea behind SWAP is
to use the measured serial correlation of the service times
to estimate this missing information. Once these reliable
estimates of the job service times are available, we delay
large jobs up to a ﬁxed number of times by putting them
at the tail of the queue. In such a way, long jobs are more
likely to be served after most short jobs have been com-
pleted. Estimated-short jobs are not delayed by SWAP.
Summarizing, the basic ideas of SWAP are as follows:
1. approximate the behavior of the SJF scheduling disci-
pline by proper use of job delaying;
2. estimate the expected service times of the jobs wait-
ing in queue from the process temporal dependence, as
modeled by the correlation between successive service
time values.
We stress that SWAP does not assume any a priori knowl-
edge of the length of any of the enqueued jobs. The system
knows the exact service time received by a job only after
the job completes execution. Estimation of service times
for the remaining jobs is based only on the past history of
the system. We also stress that we provide mechanisms to
avoid job starvation. In the following subsections we detail
the SWAP policy and its implementation.
2 Delay-Based Scheduling Policy: SWAP
2.1 Forecasting Job Service Times
In this section we introduce SWAP, a new delay-based
scheduling policy that improves performance and availabil-
ity in systems with temporal dependent workloads. The ba-
sic idea behind SWAP can be summarized as follows. Con-
sider a system processing jobs with a ﬁrst-come ﬁrst-served
(FCFS) scheduling policy. Assume that the exact job size
information is available to the scheduler. If we want to max-
imize performance given that the future instants of new job
arrivals are unknown, then the optimal scheduling is short-
est job ﬁrst (SJF) as it is well-know from classic scheduling
theory [15]. That is, if the resource has K enqueued jobs
having ordered service times Sk, 1 ≤ k ≤ K, being S1 the
service time required by the job at the head of the queue,
the total completion time CT under the FCFS discipline is
CT = KS1 + (K − 1)S2 + . . . + SK,
which represents the time interval from the moment that the
ﬁrst job arrives to the moment that the last job leaves the
The effectiveness of the new proposed policy depends on
the accuracy of forecasting job service times. If prediction
is done effectively, then long jobs to be delayed can be ac-
curately identiﬁed and SWAP performs optimally. We ﬁrst
present SWAP service time forecasting methodology which
is speciﬁcally tailored to temporal dependent workloads.
Exploiting Service Time Variability
Our service time forecasting relies on two system aspects:
service time variability and temporal dependence of work-
loads. Concerning the former, we leverage on the fact that
service time distributions found in systems are typically
characterized by high variance [2, 14] and therefore the dis-
crimination between small and large service times can be
performed effectively and used to improve performability.
In particular, SWAP uses a large-job threshold (LT )
LT = µ−1(1 + k · CV ),
(1)
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 20081-4244-2398-9/08/$20.00 ©2008 IEEE337DSN 2008: Mi et al.where µ−1 is the mean service time at the resource, CV is
the coefﬁcient of variation of service times (i.e., the ratio of
the standard deviation to the mean), and k ≥ 1 is a constant
determined online. If a job service time is greater than LT ,
then SWAP regards the job as “long” (also referred through-
out the paper as “large”). Otherwise SWAP classiﬁes it as
“short”. Note that the policy can successfully measure the
parameters for computing LT in an online fashion, i.e., the
mean µ−1 and the coefﬁcient of variation CV of the service
times are continuously updated in SWAP using Welford’s
one-pass algorithm [8].
Exploiting Temporal Dependence
Given a classiﬁcation into large and short jobs, the next step
to effective forecasting is to exploit the structure of tem-
poral dependence in order to “guess” if a job in the queue
is long or short. This is the critical information needed to
approximate the behavior of SJF scheduling. We assume
that the scheduler is able to measure correctly the service
times of jobs completed by the server; this is readily avail-
able in most systems. Let T be the time instant in which
a forecasting decision is needed, which in SWAP always
corresponds to the departure instant of a long job depart-
ing from the queue. Also assume that during the period
[T − TW , T ], the system has completed n jobs with service
times S1, S2, . . . , Sn. TW , 0 ≤ TW ≤ T , is an update
window monitoring past history. Given the sequence {Si},
1 ≤ i ≤ n, our forecasting is based on the estimates of the
conditional probabilities
P [L|L]j =P [St+j ≥ LT |St ≥ LT ],
P [S|L]j =P [St+j < LT |St ≥ LT ] = 1 − P [L|L]j,
which are computed using the samples St ∈ {Si} for
t = 1, . . . , n − j. Here j is called the lag of the con-
ditional probability and denotes the distance between the
service completions considered in the conditional probabil-
ities. Given that the last completed job is long, P [L|L]j
measures the fraction of times that the j-th job that had ar-
rived after it is also long; similarly, P [S|L]j estimates how
many times the lag-j arrival is short. Using these estimates,
we forecast that the lag-j arrival after the last completed job
is going to receive large service time if the following condi-
tion holds
P [L|L]j ≥ P [S|L]j,
(2)
i.e., there is higher probability that the j-th arrival is going
to be long than short. SWAP is triggered only when the
last ﬁnished job is long; therefore, since we focus on closed
systems only, i.e., systems with constant population N , we
only make use of the conditional probabilities P [L|L]j, for
1 ≤ j < N .
1.
initialize:
a. maximum allowable delay limit D;
b. arrival index i ← 0;
c.
large threshold LT ← µ−1(1 + k · CV );
2. upon each job arriving at queue
i ← i + 1;
a.
b. set that job’s arrival index to i;
c.
d.
initialize that job’s predicted result as UnChecked;
initialize that job’s num. of delays d ← 0;
3. upon each job completion at queue
a. measure conditional probabilities P [L|L]j, 1 ≤ j < N;
b.
if its service time is greater than LT ,
then trigger one round of the delaying;
I.
II.
initialize j ← 1;
if predicted result of the j-th job is not UnChecked,
then keep using its predicted result;
if predicted result of the j-th job is UnChecked,
then predict the size of the j-th job;
– calculate the lag apart the two jobs as j-th job’s
III.
arrival index - completed job’s arrival index ;
– if P [L|L]lag ≥ P [S|L]lag,
then set that job’s predicted result as large;
else set that job’s predicted result as small;
IV. j ← j + 1;
V.
if reaching the end of the queue,
then for each large job with num. of delays d ≤ D
delay it to the end of the queue and set d ← d + 1;
else, go to step 3-c-II;
c. else, go to step 3;
Figure 1. Description of SWAP.
2.2 The Delaying Algorithm: SWAP
We now describe SWAP in detail. For presentation sim-
plicity, we assume here that the large threshold LT that is
fundamental for forecasting is given; in the next subsection,
we present how SWAP self-adjusts LT on-the-ﬂy, i.e., no
a priori knowledge of LT is required and SWAP becomes
truly autonomic.
Upon the completion of a long job, the entire queue is
scanned and the size of the j-th queued job is predicted by
using the conditional probabilities introduced in the pre-
vious subsection.
If the j-th job is estimated as large,
SWAP marks it as such. All jobs that are marked long are
delayed by moving them at the end of the queue. After all
jobs in the queue have been examined and long jobs have
been delayed, SWAP admits for service the ﬁrst job in the
queue. Delaying is not triggered again before completion of
another long job.
Jobs are “reshufﬂed” in the queue based on their antic-
ipated service times; the order of the jobs in the service
process is therefore altered (attempting to approximate SJF
scheduling) and this modiﬁes both the throughput at the
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 20081-4244-2398-9/08/$20.00 ©2008 IEEE338DSN 2008: Mi et al.queue and the serial correlation of the process. Concern-
ing the latter, we point to [1] for an accurate analysis of the
effects of shufﬂing in stochastic processes that can be mod-
eled using Markovian methods.
SWAP does not re-forecast the length of a job whose ser-
vice time has been already forecasted to be long. This is
done by recording an absolute arrival index Ai for each job.
That is, once a job has been marked as long it remains as
such for all the duration of its stay in the queue and is never
forecasted as short in successive activations of SWAP; the
same property holds also for short jobs. We apply the con-
ditional probabilities on the sequence of jobs in the queue
obtained by ordering the jobs according to the arrival in-
dexes only.
To avoid starvation of long jobs, we introduce the delay
limit D, i.e., the maximum number of times a single job
can be delayed. When the number of times a job has been
delayed is more than D, the policy does not delay this job
any longer and allows it to wait for service in its current
position in the queue. Figure 1 gives the pseudocode of
SWAP and summarizes the above discussion.
2.3 Self-Adjusting the Threshold LT
Now, we discuss how SWAP adjusts the threshold LT
for large values, aiming at controlling the strength of delay-
ing to strike a good balance between being too aggressive
or too conservative. Intuitively, when the threshold LT is
too large, the policy becomes conservative by delaying few
long jobs, the performance improvement is then negligible.
Conversely, when LT becomes too small, more jobs (even
short ones) are delayed and therefore throughput is reduced.
As a result of this, performance may be improved very lit-
tle. Therefore, the choice of an appropriate large threshold
LT is critical for the effectiveness of SWAP.
As observed in Section 2.1, the computation of LT is
a function of the updating window TW used by SWAP.
We express TW as the maximal time period in which the
system has completed exactly W requests; in the experi-
ments presented here, we set W = 100, 000. The algo-
rithm in Figure 2 describes how the threshold LT is dynam-
ically adjusted every W requests. At the end of a period of
length TW , we update LT while keeping as upper and lower
bounds for its value the 90th and the 50th percentiles of the