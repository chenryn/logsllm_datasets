# Scheduling for Performance and Availability in Systems with Temporal Dependent Workloads

**Authors:** Ningfang Mi, Giuliano Casale, and Evgenia Smirni  
**Affiliation:** Computer Science Department, College of William and Mary  
**Emails:** {ningfang, casale, smirni}@cs.wm.edu

## Abstract
Temporal locality in workloads can lead to bursts of requests with large service requirements, which, if not managed properly, can cause peak congestion and reduce system availability. In this paper, we introduce SWAP, a measurement-based scheduling policy that approximates the shortest job first (SJF) scheduling without requiring prior knowledge of job service times. By leveraging the temporal dependence structure of the workload, SWAP effectively delays selected requests, thereby mitigating peak congestions and maintaining high availability. Our experimental results show that SWAP significantly improves system performance, with capacity increases comparable to SJF and superior to first-come, first-served (FCFS) scheduling.

## 1. Introduction
Temporal dependencies in workloads, common in multi-tier architectures, disk drives, and grid services, can severely impact performance and availability by creating peak congestions. These peaks, characterized by bursts of requests with large service requirements, can overwhelm the system, leading to reduced throughput and unavailability [9, 12, 14]. Efficient schemes to manage these bursts are essential for maintaining performance and availability.

While significant research has been conducted on managing temporal dependencies in networking, such as the development of accurate models for autocorrelated traffic processes (e.g., MMPP, fractional Brownian motion, M/G/âˆž) [18] and load-control schemes [7], these solutions often fail in systems due to differing assumptions. For example, deterministic or Erlang service time distributions in ATM networks do not apply to systems with highly variable service demands [2, 14]. Additionally, the assumption of a large number of traffic flows enabling Gaussian approximations [7] is not valid in systems with restrictive concurrency constraints, such as limits on simultaneous HTTP sessions or database locking conditions.

In this paper, we address the need for effective, measurement-based schemes to maintain performance and availability in systems with temporal dependent workloads. We focus on scenarios where processing the entire workload is mandatory and request dropping is not an option. Our main contribution is demonstrating that significant performance gains and high system availability can be achieved by delaying selected requests that contribute to temporal locality. This approach reduces peak congestion and improves overall system throughput, making it more effective than hardware upgrades in many cases.

## 2. The SWAP Scheduling Policy
### 2.1 Forecasting Job Service Times
SWAP is a delay-based scheduling policy designed to improve performance and availability in systems with temporal dependent workloads. The key idea is to approximate the behavior of the shortest job first (SJF) scheduling discipline by delaying long jobs. Since SJF requires a priori knowledge of job service times, which is often unavailable, SWAP uses the measured serial correlation of service times to estimate this information.

#### Exploiting Service Time Variability
SWAP leverages the high variance in service time distributions typically found in systems [2, 14]. It classifies jobs into "short" and "long" based on a large-job threshold (LT):
\[ LT = \mu^{-1}(1 + k \cdot CV) \]
where \(\mu^{-1}\) is the mean service time, \(CV\) is the coefficient of variation, and \(k \geq 1\) is a constant determined online. If a job's service time exceeds \(LT\), it is classified as "long"; otherwise, it is "short". The parameters \(\mu^{-1}\) and \(CV\) are continuously updated using Welford's one-pass algorithm [8].

#### Exploiting Temporal Dependence
To forecast whether a job is long or short, SWAP uses conditional probabilities based on the temporal dependence of the workload. Given a sequence of completed jobs, the conditional probability \(P[L|L]_j\) measures the likelihood that the \(j\)-th job after a long job is also long. If:
\[ P[L|L]_j \geq P[S|L]_j \]
then the \(j\)-th job is predicted to be long. This process is triggered when a long job completes, and it only considers the next \(N-1\) jobs in the queue, where \(N\) is the total number of jobs in the system.

### 2.2 The Delaying Algorithm: SWAP
Upon the completion of a long job, SWAP scans the queue and predicts the size of each queued job. If a job is estimated to be long, it is marked and delayed to the end of the queue. This process continues until all jobs have been examined. The first job in the queue is then admitted for service. Delaying is not triggered again until another long job completes.

To avoid starvation, SWAP introduces a delay limit \(D\), which is the maximum number of times a job can be delayed. Once a job has been delayed \(D\) times, it remains in its current position in the queue. Figure 1 provides the pseudocode for SWAP.

### 2.3 Self-Adjusting the Threshold \(LT\)
The effectiveness of SWAP depends on the appropriate setting of the large-job threshold \(LT\). If \(LT\) is too high, few jobs are delayed, resulting in minimal performance improvement. Conversely, if \(LT\) is too low, too many jobs (including short ones) are delayed, reducing throughput. To address this, SWAP dynamically adjusts \(LT\) every \(W\) requests, where \(W\) is the number of requests completed in the update window \(TW\). The new \(LT\) is bounded by the 90th and 50th percentiles of the service times in the update window. Figure 2 describes the algorithm for adjusting \(LT\).

## 3. Experimental Results
We validate the effectiveness and robustness of SWAP through simulations. Our results show that SWAP can increase throughput by up to 30% to 40% under temporal dependent workloads, without service rejection and while keeping the fraction of delayed requests low. SWAP's performance is comparable to SJF, despite not requiring a priori knowledge of future workloads.

## 4. Related Work
Previous work in networking has extensively studied the characterization and control of temporal dependence congestion effects, leading to the development of accurate models and load-control schemes [18, 7]. However, these solutions are not directly applicable to systems due to differing assumptions about service time distributions and concurrency constraints. Our work addresses this gap by providing a practical, measurement-based solution for managing temporal dependent workloads in systems.

## 5. Conclusions and Future Work
In this paper, we introduced SWAP, a measurement-based scheduling policy that effectively manages temporal dependent workloads by delaying selected requests. Our experimental results demonstrate that SWAP significantly improves system performance and availability, making it a viable alternative to SJF and superior to FCFS scheduling. Future work will explore the application of SWAP in different system environments and further refine the self-adjusting mechanism for the large-job threshold \(LT\).

---

This optimized version of the text is more structured, clear, and professional, with improved flow and coherence.