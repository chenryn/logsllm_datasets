# 七、扩展您的平台
在本章中，我们将扩展我们在[第 6 章](06.html "Chapter 6. Deploy Real Applications on Swarm")、*中看到的在 Swarm* 上部署真实应用。我们的目标是在 Swarm 之上部署一个实际的生产级 Spark 集群，增加存储容量，启动一些 Spark 作业，并为底层基础架构设置监控。
为此，本章主要面向基础设施。事实上，我们将看到如何将 **Libnetwork** 、 **Flocker** 和 **Prometheus** 与 Swarm 联合起来。
对于网络，我们将使用基于 Libnetwork 的基本 Docker 网络覆盖系统。有一些很棒的网络插件，比如 Weave 和其他插件，但是要么它们还不兼容新的 Docker Swarm 模式，要么它们被 Swarm 集成的路由网格机制淘汰了。
仓储方面，情况比较红火，因为选择多了很多(参考[https://docs.docker.com/engine/extend/plugins/](https://docs.docker.com/engine/extend/plugins/))。我们和弗洛克一起去。Flocker 是 Docker 存储的“T2”祖父，可以配置大量存储后端，使其成为生产负载的最佳选择之一。被弗洛克的复杂性吓到了？不合理:我们将在几分钟内看到如何为任何用途设置多节点 Flocker 集群。
对于监控，最后我们来介绍一下普罗米修斯。它是目前 Docker 可用的监控系统中最有前途的，它的 API 可能很快就会集成到 Docker 引擎中。
因此，我们将在这里介绍:
*   Swarm 上的火花示例，准备运行任何火花作业
*   大规模自动安装用于基础设施的 Flocker
*   演示如何在本地使用 Flocker
*   在群体模式下使用闪烁
*   扩展我们的火花应用
*   使用普罗米修斯监控此基础架构的运行状况
# 火花的例子，又来了
我们将重新构建[第 6 章](06.html "Chapter 6. Deploy Real Applications on Swarm")、*在 Swarm* 上部署真实应用的示例，因此我们将在 Swarm 上部署 Spark，但这次采用的是真实的网络和存储设置。
Spark 存储后端通常运行在 Hadoop 上，或者在文件系统上运行在 NFS 上。对于不需要存储的作业，Spark 将在 workers 上创建本地数据，但是对于存储计算，您将需要每个节点上的共享文件系统，这不能由 Docker 卷插件自动保证(至少到目前为止)。
在 Swarm 上实现这一目标的一种可能性是在每个 Docker 主机上创建 NFS 共享，然后将它们透明地安装在服务容器中。
我们这里的重点不是说明 Spark 的工作细节及其存储组织，而是为 Docker 引入一个固执己见的存储选项，并给出如何在 Docker Swarm 上组织和扩展一个相当复杂的服务的想法。
# Docker 插件
关于 Docker 插件的详细介绍，我们可以建议阅读官方文档页面。这里有一个起点[https://docs.docker.com/engine/extend/](https://docs.docker.com/engine/extend/)还有，Docker 很可能会发布一个工具，用一个命令就能获得插件，参考[https://docs . Docker . com/engine/reference/command line/plugin _ install/](https://docs.docker.com/engine/reference/commandline/plugin_install/)。
如果你想探索如何将新功能集成到 Docker 中，我们建议你参考*扩展 Docker* 一书，Packt。这本书的重点是 Docker 插件，卷插件，网络插件，以及如何创建自己的插件。
对于 Flocker， **ClusterHQ** 提供了一种自动部署机制，可以使用 **CloudForm** 模板在 AWS 上部署 Flocker 集群，您可以使用 **Volume Hub** 安装该模板。注册和启动这样一个集群，请访问[https://flocker-docs . cluster HQ . com/en/latest/docker-integration/cloud formation . html](https://flocker-docs.clusterhq.com/en/latest/docker-integration/cloudformation.html)。有关详细程序的分步说明，请参考 Packt 的*扩展 Docker* 的第 3 章。
这里我们将手动进行，因为我们必须集成 Flocker 和 Swarm。
# 实验室
在本教程中，我们将在 AWS 上创建基础架构。理想情况下，对于生产环境，您应该设置三个或五个 Swarm 管理器和一些工作人员，并最终根据负载在以后添加新的工作人员节点。
这里我们将设置一个 Swarm 集群，其中有三个 Swarm 管理器、六个 Swarm 工作器和一个带有 Machine 的 Flocker 控制节点，并且不会添加新的工作器。
安装 Flocker 需要几个手动步骤，这些步骤可以是自动化的(正如我们将看到的)。因此，为了使示例尽可能不那么复杂，我们将首先以线性顺序运行所有这些命令，而不重复增加系统容量的过程。
如果你不喜欢 Ansible，可以很容易地将流程适配到你喜欢的工具上，无论是**木偶**、**盐**、**厨师**还是其他。
## 一把独特的钥匙
为了简单起见，我们将使用临时生成的 SSH 密钥来安装我们的实验室，并且我们将安装 Docker Machines，该密钥复制到`authorized_keys`中的主机。我们的目标是拥有一个唯一的密钥来在以后验证 Ansible，我们将使用它来自动化许多我们应该手动执行的步骤。
因此，我们首先生成一个`flocker`键，并将其放入`keys/`目录:
```
ssh-keygen -t rsa -f keys/flocker
```
## Docker 机器
为了配置我们的 Docker 主机，我们将使用 Docker Machine。以下是本教程的系统详细信息:
AWS 实例将从 aws-101 调用到 aws-110。稍后，当我们需要为 Flocker 生成和创建节点证书时，这种标准化命名将非常重要:
*   节点 aws-101、102、103 将是我们的 Swarm 管理器
*   节点 aws-104 将是弗洛克控制节点
*   从 aws-105 到 aws-110 的节点将是我们的 Swarm 工作人员。
实例类型为`t2.medium` (2 个 vCPUs，4G 内存，EBS 存储)
味道将是 Ubuntu 14.04 Trusty(用`--amazonec2-ami`参数指定)
安全组将是标准`docker-machine`(几秒钟后我们将再次总结需求)
弗洛克版本将是 1.15。
具体使用的 AMI ID 可以在[https://cloud-images.ubuntu.com/locator/ec2/](https://cloud-images.ubuntu.com/locator/ec2/)上搜索。
AWS 计算器计算出该设置的成本约为每月 380 美元，不包括存储使用。
![Docker Machine](img/image_07_001.jpg)
因此，我们创建了基础设施:
```
for i in `seq 101 110`; do
docker-machine create -d amazonec2 \
--amazonec2-ami ami-c9580bde \
--amazonec2-ssh-keypath keys/flocker \
--amazonec2-instance-type "t2.medium" \
aws-$i;
done
```
跑步。
一段时间后，我们会让它开始运行。
## 安全组
此外，我们还需要在 EC2 控制台的安全组中打开三个新端口，用于本项目(`docker-machine`)。Flocker 服务使用的端口有:
*   港口`4523/tcp`
*   港口`4524/tcp`
另外，以下是 Swarm 使用的端口:
*   Port `2377/tcp`
    ![Security groups](img/image_07_003.jpg)
## 网络配置
我们使用带有附加覆盖网络的标准配置，称为**火花**。流量数据将通过 spark 网络传输，这使得扩展实验室配置成为可能，新的主机和工作人员甚至可以在其他提供商上运行，如**数字海洋**或**开放栈**。当新的 Swarm 工作人员加入该集群时，该网络会传播给他们，并可供 Swarm 服务使用。
## 存储配置和架构
如前所述，我们选择了 Flocker([https://clusterhq.com/flocker/introduction/](https://clusterhq.com/flocker/introduction/))，这是顶级 Docker 存储项目之一。集群总部将其描述为:
> *Flocker 是一个开源的容器数据卷管理器，适用于您的 Dockerized 应用。通过提供数据迁移工具，Flocker 为运营团队提供了运行容器化有状态服务(如生产中的数据库)所需的工具。与绑定到单个服务器的 Docker 数据卷不同，称为数据集的 Flocker 数据卷是可移植的，可以与集群中的任何容器一起使用。*
Flocker 支持非常广泛的存储选项，从 AWS EBS 到 EMC、NetApp、戴尔、华为解决方案，再到 OpenStack child 和 Ceph，仅举几例。
它的设计很简单:Flocker 有一个**控制节点**，它公开了它的服务 API 来管理 Flocker 集群和 Flocker 卷，一个 **Flocker 代理**和 Docker 插件一起运行在集群的每个**节点**上。
![Storage configuration and architecture](img/image_07_004.jpg)
要使用 Flocker，在命令行中，您需要使用 Docker 运行类似这样的程序，在容器内装载为`/data`的 Flocker `myvolume`卷上读取或写入有状态数据:
```
docker run -v myvolume:/data --volume-driver flocker image command
```
此外，您可以使用`docker volume`命令管理音量:
```
docker volume ls
docker volume create -d flocker
```
在本教程的架构中，我们将在 aws-104 上安装 flocker 控制节点，这将是专用的，并在所有节点(包括节点-104)上安装 Flocker 代理。
此外，我们将安装用于与 Flocker 控制节点 API 交互的 Flocker 客户端，以便管理集群状态和卷。为了方便起见，我们也将从 aws-104 使用它。
# 安装弗洛克
要让 Flocker 集群运行，需要一系列操作:
1.  安装`flocker-ca`实用程序生成证书。
2.  生成授权证书。
3.  生成控制节点证书。
4.  生成节点证书，每个节点一个。
5.  生成 flocker 插件证书。
6.  生成客户端证书。
7.  从软件包中安装一些软件。
8.  向弗洛克集群分发证书。
9.  配置安装，添加主配置文件，`agent.yml`。
10.  在主机上配置数据包过滤器。
11.  启动并重新启动系统服务。
您可以在一个小集群上手动执行它们，但是它们是重复且繁琐的，所以我们将使用一些发布到[https://github.com/fsoppelsa/ansible-flocker](https://github.com/fsoppelsa/ansible-flocker)的不言自明的 Ansible 行动手册来说明这个过程。
这些戏很琐碎，可能还没有制作好。也有针对弗洛克角色的官方 ClusterHQ 行动手册(参考[https://github.com/ClusterHQ/ansible-role-flocker](https://github.com/ClusterHQ/ansible-role-flocker))，但是为了解释的线性，我们将使用第一个存储库，所以让我们克隆它:
```
git clone PI:EMAIL:fsoppelsa/ansible-flocker.git
```
## 生成弗洛克证书
对于证书生成，需要`flocker-ca`实用程序。如何安装的说明可以在[https://docs . cluster HQ . com/en/latest/flocker-standalone/install-client . html](https://docs.clusterhq.com/en/latest/flocker-standalone/install-client.html)上找到。对于 Linux 发行版，这是一个安装软件包的问题。相反，在 Mac OS X 上，可以使用 Python 的`pip`实用程序来拉取该工具。
**在 Ubuntu** 上:
```
sudo apt-get -y install --force-yes clusterhq-flocker-cli
```
**在 Mac OS X** 上:
```
pip install https://clusterhq-
    archive.s3.amazonaws.com/python/Flocker-1.15.0-py2-none-any.whl
```
一旦拥有了这个工具，我们就会生成所需的证书。为了使事情变得简单，我们将创建以下证书结构:
包含所有证书和密钥的目录`certs/`:
*   `cluster.crt`和`.key`是权限证书和密钥
*   `control-service.crt`和`.key`是控制节点证书和密钥
*   `plugin.crt`和`.key`是 Docker Flocker 插件证书和密钥
*   `client.crt`和`.key`是弗洛克客户端证书和密钥
*   从`node-aws-101.crt`和`.key`到`node-aws-110.crt`和`.key`是节点证书和密钥，每个节点一个
以下是步骤:
1.  生成授权证书:`flocker-ca initialize cluster`
2.  一旦拥有了权限证书和密钥，就在同一个目录下生成控制节点证书:`flocker-ca create-control-certificate aws-101`
3.  然后生成插件证书: `flocker-ca create-api-certificate plugin`
4.  然后生成客户端证书: `flocker-ca create-api-certificate client`
5.  最后，生成每个节点的证书:`flocker-ca create-node-certificate node-aws-X`
当然，我们必须欺骗并使用`ansible-flocker`存储库中可用的`utility/generate_certs.sh`脚本，它将为我们完成以下工作:
```
cd utils
./generate_certs.sh
```
在这个脚本执行之后，我们现在在`certs/`中拥有了所有可用的证书:
![Generating Flocker certificates](img/image_07_005.jpg)
## 安装软件
在每个 Flocker 节点上，我们必须执行以下步骤:
1.  将 ClusterHQ Ubuntu 存储库添加到 APT 源列表。
2.  更新包缓存。
3.  安装这些软件包:
    *   `clusterhq-python-flocker`
    *   `clusterhq-flocker-node`
    *   `clusterhq-flocker-docker-plugin`
4.  创建目录`/etc/flocker`。
5.  将弗洛克配置文件`agent.yml`复制到`/etc/flocker`。
6.  将适用于该节点的证书复制到`/etc/flocker`。
7.  通过启用 **ufw** ，并打开 TCP 端口`2376`、`2377`、`4523`、`4524`来配置安全性。
8.  启动系统服务。
9.  重新启动 docker daemon。
同样，我们喜欢机器为我们工作，所以让我们边喝咖啡边用 Ansible 设置它。
但是，在此之前，我们必须指定谁将是 Flocker 控制节点，谁将是裸节点，所以我们用节点的主机 IP 填充`inventory`文件。文件为`.ini`格式，只需要指定节点列表即可: