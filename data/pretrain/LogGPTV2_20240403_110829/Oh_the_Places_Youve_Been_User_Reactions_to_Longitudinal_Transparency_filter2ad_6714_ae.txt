Impact on attitudes. We asked participants to respond to seven
statements measuring their attitudes of tracking and ad targeting.
Broadly, participants agreed that transparency is valuable and track-
ing can be creepy, but expressed divergent and complex opinions re-
garding the usefulness of relevant ads, inferencing, and third-party
tracking (Figure 5). In particular, it may appear as a contradiction
that a majority of participants agreed it was “creepy for companies
to track websites I visit to show relevant ads,” but more than a
third of participants also agreed they would be “comfortable with
companies guessing my interests based on websites I visit.” How-
ever, this actually reveals subtle differences between comfort with
Figure 5: Participants’ attitudes about online tracking after
using Tracking Transparency for one week.
inferring interests compared to perceiving creepiness in tracking
for advertising purposes. Nevertheless, Tracking Transparency did
not appear to impact these broader attitudes overall. For six of the
seven questions, responses did not significantly change after using
the extension, and we did not observe significant differences across
conditions in our repeated-measures regression models. Except as
noted, we report the distribution of post-usage responses.
Usefulness of ads & tracking. Participants were split regarding
the usefulness of personalization. 44.7% agreed they “would like
to see ads that are relevant to my interests, as opposed to generic
ad,” while 32.0% disagreed. Furthermore, whereas 40.0% agreed “I
would be comfortable with online advertising companies guess-
ing my interests based on which websites I visit,” 44.9% disagreed.
While participants overwhelmingly (71.3%) considered it creepy
for “for advertising companies to track which websites I visit in
order to show me ads that are relevant to my interests,” they were
split regarding whether the tracking is fair, with 30.6% agreeing
and 52.9% disagreeing. These results are in line with prior work
revealing that some users find personalization useful, but many are
uncomfortable with the methods of web tracking [90].
Understanding of tracking. Participants’ agreement that they
understand tracking increased significantly from 70.1% pre-usage
to 82.8% post-usage (β = −0.967, p = 0.002). Further, 48.5% of
participants agreed “I would like to use a system that shows me
what information has been collected,” whereas 64.9% disagreed that
ad companies adequately explain why they receive particular ads.
Privacy attitudes. We also studied how Tracking Transparency
may have impacted participants’ broad privacy attitudes, not ob-
serving any effect. Both pre- and post-usage, participants completed
the Awareness and Collection subscales of the IUIPC privacy in-
dex. They responded to each item on scales from strongly disagree
(coded as -3) to strongly agree (coded as 3). Even in the pre-usage
survey, participants expressed high privacy concern. The median
participant’s response, averaged across items, on the Awareness
sub-scale was 2.7 (µ = 2.3, σ = 0.8), between “agree” and “strongly
0%25%50%75%100%Strongly agreeStrongly disagreeNeitherWould like to see relevant ads Comfortable with companies guessing  my interests based on websites I visit Would like to use system that  shows info collected about me Companies explain why I received a particular ad Understand how companies determine which ads I see Fair for companies to track  websites I visit to show relevant ads Creepy for companies to track  websites I visit to show relevant adsdata, the median participant encountered 148 unique trackers over
the week. In conditions that made tracking more transparent, partic-
ipants’ post-usage estimates sharply increased, and these variations
across conditions were significant.
The extension’s more fully featured conditions helped partici-
pants improve their accuracy. Post-usage, all estimates varied by
condition, with participants who saw longitudinal data unsurpris-
ingly more closely aligned with the telemetry data. The close align-
ment between post-usage estimates and our telemetry data for lon-
gitudinal conditions is unsurprising because the extension showed
them these numbers. More surprising are participants’ consistent
underestimates of both the number of trackers and the amount they
browsed absent this data.
6 DISCUSSION
In visualizing third-party web tracking and the inferences that
could be made, we aimed to facilitate conversations about the preva-
lence of third-party tracking. Advertisers’ obscure dashboards and
technical knowledge previously formed barriers to retrieving trans-
parent information about online tracking in one’s own browsing.
Tracking Transparency allows researchers to understand how sup-
plying more information to non-technical users can affect their
reactions. Despite previous work that would predict users to be
unmotivated [97], our field study indicated that users are interested
in learning about how they are profiled from their browsing.
In the realm of online privacy, knowledge is power. A better
understanding of how online privacy is affected enables better
decision making. This parallels security psychology research, which
posits that accurate risk perception enables better security decision
making [25, 35, 97]. The Tracking Transparency prototype is a step
in this direction, as participants who used the fully featured tool
were significantly better at quantifying online tracking than those
who used a controlled representation of current user interfaces.
As P290 explained, “I learned that Google is watching wherever I
go and my local news page has more trackers than anyone, which
was quite surprising. I knew my ad-blocker stopped a lot of ads
there but I had no idea they were still tracking me.” Future privacy
tools should empower users to learn how such technologies impact
them so they can be informed in discussions about tracking and
understand the use cases for privacy-preserving measures.
Finally, there is significant room for additional tools and policies
to support online privacy. Related work has explored users’ contex-
tual preferences regarding web tracking and subsequent technical
tools [59, 60]. In this light, future work should explore providing
users not only with transparency, but also with greater control over
tracking. Additionally, our results highlight the need for companies
to provide more transparency about how they infer interests and
use them for targeting. Some recent initiatives begin to partially
support this goal [73]. There has been increasing media attention
about the misuse of tracked data, especially regarding discrimina-
tory contexts and political purposes. The Tracking Transparency
interface takes an important first step in motivating users to con-
sider behavioral changes, learning, and public policy demands.
Figure 6: Choices participants preferred in four privacy
tradeoffs, which did not vary by condition. Darker colors in-
dicate stronger preferences.
agree.” The median participant’s average response to items on the
Collection sub-scale was 2.0 (µ = 1.7, σ = 1.2).
5.5 Perceptions of Tradeoffs
Targeted advertising, as well as efforts to stop it, manifests as a
series of tradeoffs for users. To understand how our extension
might have influenced these considerations, we asked participants
to pick between four pairs of tradeoffs, choosing whether they
would “definitely” or “probably” prefer one of the pair, or whether
they were unsure. Making explicit the privacy literature’s observa-
tions that users have sometimes conflicting or paradoxical attitudes,
participants expressed divergent preferences about balancing these
tradeoffs (Figure 6). These preferences did not vary by condition.
Whereas 48.7% of participants reported that they preferred the
internet be free and have tracking, 29.2% reported preferring to
pay for an internet with no tracking. This supports previous work
that found some people are willing to pay a premium for privacy,
especially if privacy information is made transparent [26, 88].
Similarly, 69.4% preferred that search results not be tracked (and
thus not be personalized), while 21.6% preferred the opposite. Tools
that block tracking can sometimes “break” web pages. Among par-
ticipants, 43.5% wanted to block tracking even if it would sometimes
break web pages, yet 41.9% preferred that web pages always work.
Currently, tracking is necessary for targeting ads because adver-
tisers otherwise would not know users’ interests. A radical alterna-
tive to this model would be for users to explicitly tell advertisers
their interests. While 43.5% of participants preferred the current
system of tracking to learn users’ interests, 37.2% would prefer to
tell companies their interests and not be tracked.
5.6 Estimates of Browsing and Tracking
In both surveys, participants were asked to numerically estimate
how much they browsed the web and how many trackers they
encountered. Before using the extension, participants consistently
underestimated both, with no variance by condition. However, the
extension’s longitudinal conditions helped participants better quan-
tify their web browsing (see median estimates by condition, pre-
and post-usage, in Table 3 in the appendix). Pre-usage, the median
participant per condition estimated visiting 100–200 pages across
22.5–35 domains each week. According to our telemetry data, the
median participant actually visited 1,682 web pages on 68 unique
domains over the week of the study. Prior to using the extension,
the median participant in each condition estimated that they en-
countered between 10–20 trackers each week. Per our telemetry
0%25%50%75%100%Free internet with trackingPay for no trackingBlock trackers but break sitesBlock no trackers but all sites workSearch activity not trackedSearch results personalizedAd networks track you Tell ad networks your interests, no tracking 17 CONCLUSION
In this paper, we presented Tracking Transparency, a browser ex-
tension we created to communicate more information about online
tracking to users and to support research into the impact of trans-
parency. Even before using our tool, participants were often aware
of the existence of online tracking. However, when confronted with
detailed descriptions of tracking in their own browsing, they were
often surprised by tracking’s extent and prevalence. Further, par-
ticipants who saw detailed information about potential inferences
reported greater intentions to take privacy-protective actions.
Our field study demonstrated the importance of providing de-
tailed, longitudinal tracker data to users. The Tracking Transparency
prototype approximates information that advertising companies
have little incentive to provide and is otherwise onerous for users
to obtain. After completing our study, a number of our partici-
pants expressed that they wanted to keep Tracking Transparency
installed. This suggests our interface addresses a much-needed in-
termediate step in the privacy-consciousness spectrum: educating
the public about how their own browsing data is collected and used
without their explicit permission. Without greater public aware-
ness about the scope and practices of online tracking, advancing
privacy-friendly policies or regulatory options is unlikely.
ACKNOWLEDGMENTS
We gratefully acknowledge support from the Data Transparency
Lab and Mozilla, as well as from a UMIACS contract under the
partnership between the University of Maryland and DoD. We
thank Lorrie Cranor, Oliver Hahn, Dimitri Vasilkov, Mark Cohen,
Juliette Hainline, and Andrew McNutt for their assistance.
REFERENCES
[1] Gunes Acar, Christian Eubank, Steven Englehardt, Marc Juarez, Arvind
Narayanan, and Claudia Diaz. 2014. The Web Never Forgets: Persistent Tracking
Mechanisms in the Wild. In Proc. CCS.
[2] Alexa. Fetched on October 5, 2017. Top 1 Million Sites. http://s3.amazonaws.
com/alexa-static/top-1m.csv.zip.
[3] Hazim Almuhimedi, Florian Schaub, Norman Sadeh, Idris Adjerid, Alessandro
Acquisti, Joshua Gluck, Lorrie Cranor, and Yuvraj Agarwal. 2015. Your Location
has been Shared 5,398 Times! A Field Study on Mobile App Privacy Nudging.
In Proc. CHI.
[4] Athanasios Andreou, Giridhari Venkatadri, Oana Goga, Krishna P. Gummadi,
Patrick Loiseau, and Alan Mislove. 2018. Investigating Ad Transparency Mech-
anisms in Social Media: A Case Study of Facebook’s Explanations. In Proc.
NDSS.
[5] Julia Angwin and Terry Parris. 2016.
ers Exclude Users by Race.
facebook-lets-advertisers-exclude-users-by-race.
Facebook Lets Advertis-
https://www.propublica.org/article/
[6] Rebecca Balebako, Jaeyeon Jung, Wei Lu, Lorrie Faith Cranor, and Carolyn
Nguyen. 2013. “Little Brothers Watching You:” Raising Awareness of Data Leaks
on Smartphones. In Proc. SOUPS.
[7] Rebecca Balebako, Pedro Leon, Richard Shay, Blase Ur, Yang Wang, and L. Cranor.
2012. Measuring the Effectiveness of Privacy Tools for Limiting Behavioral
Advertising. In Proc. W2SP.
[8] Muhammad Ahmad Bashir, Sajjad Arshad, and William Robertson. 2016. Trac-
ing Information Flows Between Ad Exchanges Using Retargeted Ads. In Proc.
USENIX Security.
[9] Muhammad Ahmad Bashir, Umar Farooq, Maryam Shahid, Muhammad Fareed
Zaffar, and Christo Wilson. 2019. Quantity vs. Quality: Evaluating User Interest
Profiles Using Ad Preference Managers. In Proc. NDSS.
[10] Muhammad Ahmad Bashir and Christo Wilson. 2018. Diffusion of User Tracking
Data in the Online Advertising Ecosystem. PoPETS 2018, 4 (Oct. 2018), 85–103.
[11] Better. 2019. Trackers Collections. https://better.fyi/trackers/.
[12] David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet
Allocation. Journal of Machine Learning Research 3 (2003), 993–1022.
[13] Károly Boda, Ádám Máté Földes, Gábor György Gulyás, and Sándor Imre. 2011.
User Tracking on the Web via Cross-Browser Fingerprinting. In Proc. NordSec.
[14] John Brooke. 1996. SUS – A Quick and Dirty Usability Scale. Usability Evaluation
in Industry 189, 194 (1996), 4–7.
[15] Yinzhi Cao, Song Li, and Erik Wijman. 2017. (Cross-)Browser Fingerprinting
via OS and Hardware Level Features. In Proc. NDSS.
[16] N. Chaignaud Chahine, C. Abi and J.-Ph. Kotowicz. 2008. Context and Keyword
Extraction in Plain Text Using a Graph Representation. In Proc. SITIS.
[17] Farah Chanchary and Sonia Chiasson. 2015. User Perceptions of Sharing, Ad-
vertising, and Tracking. In Proc. SOUPS.
[18] Prabhakar Raghavan Christopher D. Manning and Hinrich Schütze. 2008. Intro-
duction to Information Retrieval. Cambridge University Press.
[19] Cliqz. 2019. Ghostery. https://www.ghostery.com/.
[20] Amit Datta, Michael Carl Tschantz, and Anupam Datta. 2015. Automated
Experiments on Ad Privacy Settings. PoPETS 2015, 1 (2015), 92–112.
[21] Martin Degeling and Jan Nierhoff. 2018. Tracking and Tricking a Profiler -
Automated Measuring and Influencing of Bluekai’s Interest Profiling. In Proc.
WPES.
[22] DisconnectMe. Accessed November 2018. Disconnect-Tracking-Protection.
https://github.com/disconnectme/disconnect-tracking-protection.
[23] Claire Dolin, Ben Weinshel, Shawn Shan, Chang Min Hahn, Euirim Choi,
Michelle L. Mazurek, and Blase Ur. 2018. Unpacking Privacy Perceptions of
Data-Driven Inferences for Online Targeting and Personalization. In Proc. CHI.
[24] DuckDuckGo. 2019. Browser Extension. https://duckduckgo.com/app.
[25] Janna Lynn Dupree, Richard DeVries, Daniel M. Berry, and Edward Lank. 2016.
Privacy Personas: Clustering Users via Attitudes and Behaviors toward Security
Practices. In Proc. CHI.
[26] Serge Egelman, Adrienne Porter Felt, and David Wagner. 2012. Choice Archi-
tecture and Smartphone Privacy: There’s A Price for That. In Proc. WEIS.
[27] Steven Englehardt and Arvind Narayanan. 2016. Online Tracking: A 1-million-
site Measurement and Analysis. In Proc. CCS.
[28] Steven Englehardt, Dillon Reisman, Christian Eubank, Peter Zimmerman,
Jonathan Mayer, Arvind Narayanan, and Edward W. Felten. 2015. Cookies
That Give You Away: The Surveillance Implications of Web Tracking. In Proc.
WWW.
[29] Motahhare Eslami, Karrie Karahalios, Christian Sandvig, Kristen Vaccaro, Aimee
Rickman, Kevin Hamilton, and Alex Kirlik. 2016. First I like it, then I hide it:
Folk Theories of Social Feeds. In Proc. CHI.
[30] Mohtarre Eslami, Sneha R Krishna Kumaran, Christian Sandvig, and Karrie
Karahalios. 2018. Communicating Algorithmic Process in Online Behavioral
Advertising. In Proc. CHI.
[31] Motahhare Eslami, Kristen Vaccaro, Karrie Karahalios, and Kevin Hamilton.
2017. “Be careful; things can be worse than they appear”: Understanding Biased
Algorithms and Users’ Behavior around Them in Rating Platforms. In Proc.
AAAI.
[32] Facebook. 2019. About The Ads You See From Facebook. https://www.facebook.
[33] J.L. Fleiss. 1981. Statistical Methods for Rates and Proportions (2nd ed.). John
com/ads/settings.
Wiley.
[34] Evgeniy Gabrilovich and Shaul Markovitch. 2007. Computing Semantic Relat-
edness using Wikipedia-based Explicit Semantic Analysis. In Proc. AAAI.
[35] Vaibhav Garg and Jean Camp. 2012. End User Perception of Online Risk Under
Uncertainty. In Proc. HICSS.
[36] Google. 2019. Ad Settings. https://adssettings.google.com.
[37] Gabor Gyorgy Gulyas, Doliere Francis Some, Nataliia Bielova, and Claude Castel-
luccia. 2018. To Extend or not to Extend: on the Uniqueness of Browser Exten-
sions and Web Logins. In Proc. WPES.
[38] Google Ads Help. Accessed November 2018. Add Topics to Ad Groups. https:
//support.google.com/adwords/answer/156178.
[39] Alex Hern. 2018.
into
cambridge-analytica-how-turn-clicks-into-votes-christopher-wylie.
Cambridge Analytica: how did it
turn clicks
https://www.theguardian.com/news/2018/may/06/
[40] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-Term Memory.
votes?
Neural Computation 9, 8 (1997), 1735–1780.
[41] Umar Iqbal, Zubair Shafiq, and Zhiyun Qian. 2017. The Ad Wars: Retrospective
Measurement and Analysis of Anti-Adblock Filter Lists. In Proc. IMC.
[42] Ruogu Kang, Stephanie Brown, Laura Dabbish, and Sara Kiesler. 2014. Privacy
Attitudes of Mechanical Turk Workers and the U.S. Public. In Proc. USENIX
Security.
[43] Saranga Komanduri, Richard Shay, Greg Norcie, and Blase Ur. 2011. Adchoices?
Compliance with Online Behavioral Advertising Notice and Choice Require-
ments.
I/S: A Journal of Law and Policy for the Information Society 7 (2011),
603.
[44] Georgios Kontaxis and Monica Chew. 2015. Tracking Protection in Firefox For
Privacy and Performance. In Proc. W2SP.
[45] Balachander Krishnamurthy, Delfina Malandrino, and Craig E Wills. 2007. Mea-
suring Privacy Loss and the Impact of Privacy Protection in Web Browsing. In
Proc. SOUPS.
[46] Oksana Kulyk, Annika Hilt, Nina Gerber, and Melanie Volkamer. 2018. “This
Website Uses Cookies”: Users’ Perceptions and Reactions to the Cookie Dis-
claimer. In Proc. EuroUSEC.
[47] J. Richard Landis and Gary G. Koch. 1977. The Measurement of Observer
Agreement for Categorical Data. Biometrics 33, 1 (1977), 159–174.
[48] Mathias Lecuyer, Riley Spahn, Yannis Spiliopolous, Augustin Chaintreau, Rox-
ana Geambasu, and Daniel Hsu. 2015. Sunlight: Fine-grained Targeting Detec-
tion at Scale with Statistical Confidence. In Proc. CCS.
[49] Linda Naeun Lee, Richard Chow, and Al M. Rashid. 2017. User Attitudes Towards
Browsing Data Collection. In Proc. CHI EA.
[50] Pedro Leon, Blase Ur, Richard Shay, Yang Wang, Rebecca Balebako, and Lorrie
Cranor. 2012. Why Johnny Can’t Opt out: A Usability Evaluation of Tools to
Limit Online Behavioral Advertising. In Proc. CHI.
[51] Pedro Giovanni Leon, Justin Cranshaw, Lorrie Faith Cranor, Jim Graves, Manoj
Hastak, Blase Ur, and Guzi Xu. 2012. What do Online Behavioral Advertising
Privacy Disclosures Communicate to Users?. In Proc. WPES.
[52] Pedro Giovanni Leon, Blase Ur, Yang Wang, Manya Sleeper, Rebecca Balebako,
Richard Shay, Lujo Bauer, Mihai Christodorescu, and Lorrie Faith Cranor. 2013.
What Matters to Users? Factors that Affect Users’Willingness to Share Informa-
tion with Online Advertisers. In Proc. SOUPS.
[53] Adam Lerner, Anna Kornfeld Simpson, Tadayoshi Kohno, and Franziska Roesner.
2016. Internet Jones and the Raiders of the Lost Trackers: An Archaeological
Study of Web Tracking from 1996 to 2016. In Proc. USENIX Security.
[54] Zhiyuan Liu, Peng Li, Yabin Zheng, and Maosong Sun. 2009. Clustering to Find
Exemplar Terms for Keyphrase Extraction. In Proc. ACL.
[55] Naresh K Malhotra, Sung S Kim, and James Agarwal. 2004.
Internet Users’
Information Privacy Concerns (IUIPC): The Construct, the Scale, and a Casual
Model. Information Systems Research 15, 4 (2004), 336–355.
[56] Arunesh Mathur and Jessica Vitak. 2018. Characterizing the Use of Browser-
Based Blocking Extensions To Prevent Online Tracking. In Proc. SOUPS.
[57] Jonathan R Mayer and John C Mitchell. 2012. Third-party Web Tracking: Policy
and Technology. In Proc. IEEE S&P.
[58] Aleecia M McDonald and Lorrie Faith Cranor. 2010. Americans’ Attitudes About
Internet Behavioral Advertising Practices. In Proc. WPES.
[59] William Melicher, Mahmood Sharif, Joshua Tan, Lujo Bauer, Mihai Christodor-
escu, and Pedro Giovanni Leon. 2016. (Do Not) Track Me Sometimes: Users’
Contextual Preferences for Web Tracking. PoPETS 2 (2016), 135–154.
[60] Wei Meng, Byoungyoung Lee, Xinyu Xing, and Wenke Lee. 2016. TrackMeOrNot:
Enabling Flexible Control on Web Tracking. In Proc. WWW.
[61] Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing Order into Texts. In
[62] Mozilla. 2019. Lightbeam. https://addons.mozilla.org/en-US/firefox/addon/
Proc. EMNLP.
lightbeam/.