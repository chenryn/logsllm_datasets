# Blacklistable Anonymous Credentials: Blocking Misbehaving Users without TTPs

**Authors:**
- Patrick P. Tsang†
- Man Ho Au§
- Apu Kapadia†‡
- Sean W. Smith†

**Affiliations:**
- †Department of Computer Science, Dartmouth College, Hanover, NH, USA
- ‡Institute for Security Technology Studies, Dartmouth College, Hanover, NH, USA
- §Centre for Computer and Information Security Research, School of Computer Science and Software Engineering, University of Wollongong, Australia

**Contact:**
- {patrick, akapadia, sws}@cs.dartmouth.edu, PI:EMAIL

## Abstract
Several credential systems have been proposed where users can authenticate to services anonymously. Anonymity, however, can lead to misbehavior as users may feel they are unaccountable. Some systems allow selective deanonymization (or linking) of misbehaving users upon a complaint to a trusted third party (TTP). This approach, however, grants the TTP the power to revoke a user's privacy at any time, which is too severe a punishment for most misbehaviors.

To address this, we present the first anonymous credential system in which services can "blacklist" misbehaving users without involving a TTP. Blacklisted users remain anonymous, allowing subjective judgments of misbehavior without the fear of arbitrary deanonymization by a TTP.

**Categories and Subject Descriptors:**
- K.6.5 [Operating Systems]: Security and Protection—Authentication
- E.3 [Data Encryption]: Public Key Cryptosystems

**General Terms:**
- Algorithms, Security

**Keywords:**
- Privacy, anonymous blacklisting, revocation, anonymous authentication, user misbehavior

## 1. Introduction
Cryptographic schemes that enable users to authenticate to service providers (SPs) anonymously offer a high degree of privacy. However, this anonymity can also encourage misbehavior, as users may act without fear of retribution. For example, Wikipedia has allowed anonymous editing, leading to instances of inappropriate content being posted. SPs, therefore, need some level of accountability against misbehaving users.

Existing anonymous credential systems often rely on TTPs, such as the Open Authority (OA), to selectively deanonymize or link misbehaving users. These TTPs can revoke a user's privacy at any time, which is an overly punitive measure. Other systems, like e-cash, limit deanonymization to specific types of well-defined misbehavior, such as double spending, but these techniques cannot be generalized to more subjective definitions of misbehavior.

Instead of deanonymizing users, it is often sufficient to block misbehaving users from future accesses while maintaining their anonymity. We call this property "anonymous blacklisting." For example, SPs like Wikipedia and YouTube may want to penalize users who deface webpages or post copyrighted material, but it is crucial to preserve the anonymity of well-behaving users, such as political dissidents.

### 1.1 Related Solutions
Syverson et al. [31] propose a scheme that allows users to perform anonymous and serial transactions with SPs. The SP issues blind tokens to users, which are renewed after each transaction. The SP can block future connections by not issuing a new token if the user misbehaves. However, this approach requires misbehavior to be judged while the user is online, which is impractical for many applications.

The Nymble system [25] allows SPs to block misbehaving users hiding behind anonymizing networks like Tor. Nymble supports subjective judging but relies on multiple entities that can collude to deanonymize users.

### 1.2 Our Contributions
We introduce the BLacklistable Anonymous Credential (BLAC) system, the first cryptographic construction of an anonymous credential system that supports anonymous blacklisting and subjective judging without relying on TTPs. We formalize the security model for such a system and prove that our construction is secure. We also provide an implementation and evaluate its performance both analytically and experimentally.

**Paper Outline:**
- Section 2: Overview of the BLAC system.
- Section 3: Formalization of the model and security properties.
- Section 4: Preliminary information on cryptographic tools and assumptions.
- Section 5: Detailed construction of the BLAC system.
- Section 6: Experimental evaluation.
- Section 7: Discussion of several issues.
- Section 8: Conclusion.
- Appendix: Detailed security model and full version of the paper [35].

## 2. Our Approach
In our BLAC system, users authenticate to SPs anonymously using credentials issued by a Group Manager (GM). The GM enrolls legitimate users into the system by issuing credentials, which are private to the users. The GM is not a TTP and is only trusted to enroll legitimate users and issue at most one credential per user.

SPs serve anonymous users as long as they are legitimate and have not misbehaved, as subjectively judged by the SP. The novelty of our approach is that SPs maintain their own blacklists of misbehaving users without knowing their identities. Users must prove they are not on the SP's blacklist before authenticating. If a user is on the blacklist, authentication fails, and the SP learns only that an anonymous blacklisted user was refused a connection.

### Tickets
Tickets are a key component of our BLAC system. A ticket is the only part of the authentication protocol transcript that contains information about the user's identity. Tickets must be:
- The output of a non-invertible mapping of the user's credential to ensure anonymity.
- Unlinkable to prevent SPs from identifying repeated authentications by the same user.
- Verifiable to ensure that a ticket is correctly formed and does not belong to a given user, preventing blacklisted users from re-authenticating.

**Remark:**
Our BLAC system can be configured to allow or disallow the sharing of blacklist entries (tickets) between SPs. Sharing would enable multiple SPs to block a user who misbehaved at one SP.

## 3. Model
We present the syntax of the BLAC system and the security properties that any construction must satisfy.

### 3.1 Syntax
The entities in the BLAC system are the Group Manager (GM), a set of Service Providers (SPs), and a set of users. The system consists of the following protocols:

#### 3.1.1 Setup
- **Algorithm:** Executed by the GM to set up the system.
- **Input:** One or more security parameters.
- **Output:** A pair consisting of a group public key (gpk) and a group private key (gsk).
- **Action:** The GM publishes gpk and keeps gsk private.

#### 3.1.2 Registration
- **Protocol:** Executed between the GM and a legitimate user to register the user into the system.
- **Outcome:** The user obtains a credential (cred), which they keep private, and is enrolled as a member of the group.

#### 3.1.3 Authentication
- **Protocol:** Executed between a user with a credential and an SP.
- **Outcome:** The SP outputs a binary value indicating success or failure.
- **Success:** The SP establishes an authenticated session with the user.
- **Failure:** The user is denied access.
- **Note:** The protocol transcript of a successful authentication is useful for the SP to blacklist the user.

#### 3.1.4 Blacklist Management
- **Algorithms:** Extract, Add, and Remove, executed by SPs for managing blacklists.
- **Extract:** Extracts a ticket from an authentication protocol transcript.
- **Add:** Adds a ticket to the blacklist.
- **Remove:** Removes a ticket from the blacklist.
- **Blacklisted User:** A user is blacklisted if their ticket is in the SP's blacklist.
- **Misbehaving User:** A user is misbehaving if they are blacklisted by the SP.

### 3.2 Correctness
A construction of the BLAC system is correct if all entities follow the system's specification, ensuring that a registered, legitimate user can successfully authenticate to an SP with overwhelming probability if they are not blacklisted.

### 3.3 Security Notions
[Detailed security notions and proofs will be provided in the full version of the paper [35].]

---

This revised text aims to improve clarity, coherence, and professionalism, making it easier to understand and more suitable for academic and professional contexts.