3.4 Event Attribution
To use an individual’s context, such as their job description or social network,
we had to attribute each event to a user. Unfortunately, not all sessions, and
thus not all events, had information about the user who produced them. For
example, unprotected Windows ﬁle shares and web sites requiring no authenti-
cation generated events without identifying information. In the database, such
events have null values for their user ids.
Our collection contained three types of events: unattributed events, indirectly-
attributed events, and events directly attributed to a user because of an observed
successful authentication. For example, most smb sessions begin with an au-
thentication, and we can then attribute subsequent events of the session to the
authenticated user. Indirectly attributed events are those with some type of user
context, such as the sender’s address in an e-mail. Of the more than 91 million
events, 14.7% were directly attributed, 2.3% were indirectly attributed, and 83%
were initially unattributed.
With network engineers familiar with the network environment, we devised
two oﬀ-line methods to label unattributed events. Both used events occurring
before and after an unattributed event. The ﬁrst was a nearest-neighbor method
that attributes an unattributed event to the user of the closest attributed event,
as measured by time. The second method uses a kernel function to give more
weight to the attributed events closer to the unattributed event. To reﬂect the
152
M.A. Maloof and G.D. Stephens
uncertainty of attribution sources (e.g., due to conﬁguration or human errors),
network engineers determined measures of conﬁdence for each, assigning print
events a weight of .999, send events a weight of .99, and ftp events a weight of
.9. Directly attributed events had a weight of 1 and unattributed events had a
weight of 0.
An attribution event ei is then a 3-tuple (cid:2)ui, wi, ti(cid:3), where ui is the id of the
attributed user, wi is the weight, and ti is the time of occurrence. For a given
client ip address, there is a sequence of attribution events with and without
attribution. Let S be a sequence of n events ordered by ti, and let S(u) be the
sequence of events from S attributed to user u:
S(u) = {(cid:2)ui, wi, ti(cid:3) : (cid:2)ui, wi, ti(cid:3) ∈ S ∧ ui = u} .
If ei is an unattributed event (i.e., ui = ∅) occurring in the middle of sequence
S (i.e., i = n/2), then we attribute ei to the user in the sequence whose actions
have the maximum weight. That is, given the kernel function
K(ei, ej) = wj e
−γ(ti−tj)2
,
where γ determines the width of the kernel,
(cid:2)(cid:3)
(cid:4)
ej∈S(u) K(ei, ej)
ui = argmax
u∈S
.
For each unattributed event in a sequence, we applied both methods. With
the kernel method, we set γ = 5×10−5 and used overlapping sequences of events
that were 16 hours in length. If the weight calculated for an unattributed event
was less than 1 × 10−5, then the event remained unattributed. If both methods
returned the same user id, then we set the id of the unattributed event to the
inferred id. If the methods did not agree, then the event remained unattributed.
To evaluate this procedure, we compared performance to our two network en-
gineers. We randomly selected 100 unattributed events and applied our attribut-
ion procedure. We provided the same events to both experts, who independently
attributed the events. They then resolved any diﬀerences to produce a single
set of attributed events. Our procedure agreed with the experts on 99 of the
100 events. The disagreement involved an ambiguous event from a multi-user
machine that belonged either to the end of one user’s session or the beginning
of another’s.
Applying this procedure to all of the events, we were able to infer attribution
for 65% of the previously unattributed events. About 28.6% of the events in
the collection remained unattributable, but 82% of these originated from 25
hosts running automated processes. Those remaining were ambiguous events
from clients with multiple, concurrent users.
3.5 The Need for Meta-Events
Early on, we noticed that users initiating certain simple actions produced an
inordinate number of information-use events. Executing a ﬁnd command on a
elicit: A System for Detecting Insiders Who Violate Need-to-Know
153
Table 4. Scenarios and Their Descriptions
Scenario Description
s1
s2
s3
s4
s5
Employee who gathers technical information about aviation and aero-
nautics, topics that are outside the scope of the employee’s duties.
System administrator who obtains ﬁnancial information, such as internal
reports, disclosure statements, labor rates, and the like.
Disgruntled employee who is to leave the company and gathers a large
amount of widely varying documents containing sensitive, proprietary
information.
Employee who collects a large volume of information about knowledge
management, which is unrelated to the employee’s duties.
Employee who gathers software relating to aviation from a proprietary,
internal repository.
large, shared ﬁle system is one example. We also found that software automat-
ically updating ﬁles on clients or servers often accounted for most of a user’s
“browsing” activity (e.g., software updating a public calendar from a personal
calendar). While the information-use events of these sequences are interesting
themselves, we did not want the number of events in a sequence to skew certain
types of analyses.
As a result, we grouped certain sequences of directory and ﬁle events into
meta-events. We segmented a user’s events when there was a change in protocol,
a change in the server’s ip address, or when the separation between two events
was greater than ten seconds. Over each segment, we computed the number of
events in the segment, the rate at which the events occurred, and the percentage
of list events in the segment. If a segment was longer than 20 events and the
frequency of events was greater than two per second, then we labeled the segment
as a meta-event. If the percentage of list events within the segment was greater
than 90%, then we further labeled the segment as being the result of a ﬁnd
command. In the database, we used a unique identiﬁer to label events of a meta-
event. An additional ﬁeld indicated whether the meta-event was the result of a
list or ﬁnd command. Although we determined these thresholds empirically, we
found that this heuristic method worked well for our events.
3.6 Scenario Development and Execution
The data set described so far consists of activity for 3, 983 users. It has proven
invaluable for analysis and the development of detectors. However, it contains
no known malicious activity, which limits our ability to evaluate our approach.
In response, a red team constructed ﬁfteen scenarios inspired by public cases
that involved the gathering of illicit information by individuals such as Aldrich
Ames, Ryan Anderson, and Brian Regan. Domain experts reviewed the scenar-
ios and adapted them to the network we monitored. Once approved, the red team
154
M.A. Maloof and G.D. Stephens
ELICIT
Network
Events
Contextual
Information
.
.
.
Detectors
...
...
User
Interface
Bayesian Network
Fig. 1. elicit’s architecture
executed the ﬁve scenarios listed in Table 4 during normal network operation.
Three of the ﬁve scenarios were executed by two diﬀerent members of the red
team (i.e., s2, s3, and s4) in an eﬀort to assess the role that individual person-
ality might play in scenario execution and detection. This resulted in a total of
eight scenario executions. (We did not execute the remaining scenarios because
members of the red team were assigned to other projects; we plan to use the
scenarios in future work.)
The red team used their legitimate accounts to execute scenarios during nor-
mal network operation, which let the trusted agent process the “benign” and
scenario data together. Using the red team’s detailed logs of their activity and
demarcation events sent via e-mail, the trusted agent isolated and then removed
the scenario events from the benign collection of information-use events. This
let the trusted agent insert and remove individual scenarios at will.
The members of the red team were knowledgeable about insider activity and
investigations. They were given the scenario and its translation, and instructed
to achieve an objective (i.e., steal information) in a manner consistent with the
scenario and its insider. These instructions identiﬁed speciﬁc topics, documents,
and systems (e.g., ﬁnancial), but their actions were not tightly scripted. Members
were not told how to achieve their objective or the time over which an attack
must occur. To make inserting and removing the scenario events possible, they
were told not to intermix benign and malicious activity between demarcation
events. While not all insider attacks follow this proﬁle, many do because insiders
often take advantage of windows of opportunity.
The research team and the red team worked in isolation with the trusted
agent mediating interactions. The teams did not share domain experts, and the
research team had no insight into the development, execution, collection, and
insertion of scenarios and their events until after the completion of elicit’s de-
velopment and evaluation. Although the teams worked in isolation, in retrospect,
they independently proﬁled some of the same insiders, such as Regan, Ames, and
Hanssen. However, the red team also proﬁled insiders that the research team did
not, such as Ryan Anderson and Ana Montes. The research team did not know
how the red team would translate the scenarios (e.g., that aviation would be a
topic of interest).
elicit: A System for Detecting Insiders Who Violate Need-to-Know
155
4 The elicit System
elicit is a research prototype designed to help analysts investigate malicious
insiders. As shown in Fig. 1, it consists of four main components: a database of
events and contextual information, a set of detectors, a Bayesian network, and
a user interface.
As described previously, we processed packet data from the network and stored
the resulting events in a relational database system. Based on our analysis of
these events, consultation with experts, and public information about past cases,
we designed and built detectors that, over speciﬁed periods of time, examine
events in the database and return a set of alerts. A Bayesian inference network
uses the alerts as evidence and computes, for each user, an overall threat score.
Finally, elicit presents the users and their scores to an analyst through the user
interface.
4.1 Detectors for Anomalous Activity
To date, we have developed 76 detectors that examine events for volumetric
anomalies, suspicious behavior, and evasive behavior. We deﬁne each detector
along three dimensions: the activity’s type, its characteristics, and its context.
The type of activity can be browsing, searching, downloading, and printing.
Each detector examines characteristics of the activity, such as when the activity
occurred, where it occurred, and how (or to what extent) it occurred. Finally,
each detector evaluates activity in context with past activity, with the activity
of organizational or professional peers, or with the activity of the peers in some
social network.
Each detector works by taking as arguments a time period and a set of para-
meters, by examining each person’s activity during the time period and relevant
contextual information, and by issuing an alert, provided that the user’s activity
meets the detector’s criteria for reporting. Some detectors use only the user’s
events that occurred during the speciﬁed period of time, while others analyze
events of other types, of other users, or from other periods of time. Some detec-
tors alert when users engage in speciﬁc activities, such as conducting searches
using inappropriate terms. Others alert when some aspect of user activity is ex-
cessive or anomalous, which means that some measure of that activity falls into
a rejection region.
We based each detector on a hypothesis about the activities in which malicious
insiders might engage. We formed and supported each hypothesis with analysis
of the events in our data collection, with advice from domain experts, with
information from public cases, or with some combination thereof. As one might
expect, we could not always support a hypothesis because one or more of the
other sources refuted it. For example, if we found evidence of suspicious activity,
but an expert advised that it was not indicative of malicious insiders, then a
detector for that activity would be of little use, at least for the environment we
monitored. It is important to note that detectors suitable for one environment
may not be suitable for another.
156
M.A. Maloof and G.D. Stephens
Since we had no traces of real insider attacks and no models of insider behav-
ior for the network we monitored, we consulted with three domain experts. For
several years, they have performed technical analysis of active insider cases in-
volving the theft or misuse of information. They were familiar with the network
we monitored and its users. They advised us on the activities in which insiders
might engage and helped determine the parameters of detectors.
To implement detectors, we used a variety of methods, including hand-coded
rules, and parametric and nonparametric density estimation. We also exploited
social networks. To set their parameters, we described and presented to our
experts the observed activity in both textual and graphical form using events
from the database and histograms of the activity of individual users and groups
of users (e.g., with the same job title). The experts came to a consensus about
what they considered excessive or anomalous, and we used this information to
set the parameters and thresholds of the detectors. We make no claims that these
are optimal settings, but based on observation and expert feedback, they seem
to be reasonable estimates. Unfortunately, due to space restrictions, we cannot
describe all 76 detectors, so we describe a representative few.
Sensitive Search Terms. Insiders use search engines to ﬁnd, evaluate, and collect
information. Most organizations can deﬁne a set of sensitive terms that appear
in documents, but that would be inappropriate for use as query terms. The term
proprietary is an example. With the help of domain experts, we constructed a
list of thirteen such search terms, and if someone’s query contains one of the
terms on this list, then the detector issues an alert.
Printing to a Non-Local Printer. It is important to note that in the organizations
of interest to us, printing a document is often the only way of removing informa-
tion. Computers are on networks isolated from the Internet and have their usb
ports and external storage systems disabled. Evidence from publicly-available
documents suggests that insiders collect and print documents on topics outside
the scope of their duties. Presumably, the insider’s co-workers would recognize if
the topic of a printed document were inappropriate. Consequently, to avoid sus-
picion, an insider may print inappropriate documents to a distant or non-local
printer.
s
t
n
e
m
u
c
o
D
f
o
r
e
b
m
u
N
 35000
 30000
 25000
 20000
 15000
 10000
 5000
 0
 0
 5  10  15  20  25
Printer Distance in Floors
(a)
s
t
n
e
m
u
c
o
D
f
o
r
e
b
m
u
N
 100
 80
 60
 40
 20
 0
 5
 10  15  20  25
 0
Printer Distance in Floors
(b)
Fig. 2. Number of documents printed plotted against the distance of the printer from
the user’s oﬃce. (a) The fully scaled graph. (b) A version scaled to emphasize the bars
right of the mode.
elicit: A System for Detecting Insiders Who Violate Need-to-Know
157
In the environment we monitored, an overwhelming majority of users printed
to their local printer, as shown in Fig. 2. The graphs show the number of doc-
uments printed plotted against the distance to the printer when the user prints
from his or her oﬃce. The distance is the number of ﬂoors from an individual’s
oﬃce to the printer.