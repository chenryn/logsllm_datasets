number of DNS requests.
Al-mashhadi et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.640
17/34
H(q) is the randomness number of DNS queries rate within a predeﬁned time interval. It
is calculated according to the Shannon entropy stated in Eq. (1). Thus, the deﬁnition of the
third feature (F3) is calculated by:
H q
ð Þ ¼ 
X
N
x¼1
qx
PN
x¼1 qx
log
qx
PN
x¼1 qx
!
(4)
where qx represents the number of DNS queries in an x time interval, and N refers to the
total number of DNS queries type (Qi et al., 2018).
DDt is the number of resolved DNS record types within a predeﬁned time interval. The
deﬁnition of the fourth feature (F4) is as follows:
DDt ¼
X
N
i¼1
ðDi
Þ
(5)
where Dt represents the predeﬁned time, Di represents the number of the i-th DNS request
type as tabulated in Table 5, and N denotes the total number of DNS requested.
The average of the resolved domain name TTL in a predeﬁned time interval, which is
the deﬁnition of the ﬁfth feature (F5), is measured by:
TTLl ¼
PN
i¼1 TTLi
N
(6)
The total number of various values for TTL within a predeﬁned-time (F6).
The total number of different sizes of DNS packets within a predeﬁned-time (F7).
The number of different DNS destinations within a predeﬁned-time (F8).
The total number of unsuccessful (error) DNS response within a predeﬁned-time (F9).
The ratio of successful DNS response in a predeﬁned-time (F10).
Building training dataset step
The objective of this step is to construct a training dataset to train the machine learning
classiﬁers. The training dataset comprises a set of enriched features computed through
a feature engineering process. As mentioned earlier, the features are calculated based on
5 s running time series of the source IP that resulted in a network trafﬁc ﬂow deﬁned as
unidirectional trafﬁc with certain packet features that represent a ﬂow tuple (Krmicek,
2011). In this study, the features that describe the ﬂow are the source IP, destination IP
(DNS server), and protocol (DNS). Furthermore, the total number of domain requests is
one of the features available in the ﬂow but not in the individual packet (Haddadi &
Zincir-Heywood, 2015). The use of trafﬁc ﬂow helps to reduce both the training time and
the number of process instances. Even though the per-packet analysis is accurate, it
requires extensive resources and cannot efﬁciently deal with encrypted network trafﬁc
(Zhao et al., 2013).
Al-mashhadi et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.640
18/34
Additionally, to avoid being misled while building the rule model, the rule extraction
process will remove the source IP address feature used for ﬂow creation since the source IP
address in the actual trafﬁc might differ from data collection trafﬁc.
Furthermore, the dataset is presented as a grouped aggregated ﬂow. For a uniﬁed
grouped aggregated ﬂow time during the calculation of the computed features, the
predeﬁned time used for each calculated group is 5 s based on previous studies (Alieyan,
2018; Qi et al., 2018). Additionally, by aggregating the ﬂow in a ﬁxed interval of 5 s, the
dataset size and the processing time are reduced. Table 6 tabulates the extracted set of
basic features with enriched features.
Stage 3: hybrid rule-based detection model
This stage presents a hybrid rule-based detection model to detect botnet attacks in DNS
trafﬁc. The hybrid-rule model is built using the PART and JRip machine learning
algorithms. To properly assess the proposed approach’s performance, a ten-fold cross-
validation method (Kohavi, 1995) is utilised to select the best model for rule detection.
The PART classiﬁcation algorithm is a Java-based variation of the C4.5 algorithm
(Salzberg, 1994; Thankachan, 2013) and different SVM kernels (Hsu, Chang & Lin, 2003;
Chang & Lin, 2011). C4.5 is a popular decision tree supervised classiﬁer widely used in data
mining. The C4.5 decision tree is generated based on the provided classes and feature
sets (Alazab et al., 2011).
JRip (Repeated Incremental Pruning) is the Weka variant of Repeated Incremental
Pruning to Produce Error Reduction (RIPPER), suggested by William W. Cohen as an
enhanced version of IREP (Hall et al., 2009). JRip offers a range of capabilities that could
improve detection accuracy, such as a technique to revise and replace generated rules,
deal with noisy data, and ﬁx over-the-counter issues. In addition, JRip optimises the rule
set by the re-learning stage, leading to higher accuracy as the rules are regularly revised. Its
classiﬁer performs well even for imbalanced class distribution (Hall & Joshi, 2005; Qazi &
Raza, 2012; Napierala & Stefanowski, 2016).
Table 6 The resulted subset of features in the training dataset.
F# Feature Name
Description
1
Avg_domain_ent
Average requested domains entropy at a predeﬁned-time.
2
No_suc_resp
The total number of successful responses in predeﬁned-time.
3
rand_query
The randomness of the number of DNS queries rate in the predeﬁned-time interval.
4
number_of _record type
The number of records requested in a predeﬁned-time.
5
Avg_TTL
Average Time to Live in a predeﬁned-time, TTL deﬁnes how long the response record for a domain should be cached
in the DNS server or the host.
6
No_Distinct_TTL
The total number of different values for TTL values in the predeﬁned-time.
7
No_Distinct_Packet
The total number of different sizes of packets in predeﬁned-time.
8
No_Distinct_Destination The total number of different destinations in predeﬁned-time.
9
No_error_resp
The total number of unsuccessful (error) responses in predeﬁned-time.
10 Ratio_suc_resp
The ratio of successful response in a predeﬁned-time.
Al-mashhadi et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.640
19/34
In this study, we selected PART and JRip machine learning classiﬁers for several
reasons. Firstly, JRip and PART are sets of non-complex rules and could be integrated
easily with any IDS system. Secondly, even though other classiﬁcation algorithms are
available, JRip and PART classiﬁers are used by many researchers in their recent work
(Faizal et al., 2018; Kumar, Viinikainen & Hamalainen, 2018; Adewole et al., 2019).
Thirdly, the proposed approach assumed that the hybridisation of the two classiﬁers would
improve the output result; thereby, the ﬁnal detection model rule is a hybrid of extracted
rules from both PART and JRip output. Both JRip and PART classiﬁers require a
training dataset. The extracted model for each classiﬁer output, including the hybrid set of
rules, is evaluated using 10-fold cross-validation. Figure 12 illustrates the process of the
proposed hybrid rule-based model for the detection of DNS-based botnets.
Implementation environment
The software used includes Microsoft’s Windows 10 (64-bit) operating system, WEKA
version 3.8, Microolap TCPDUMP for Windows 4.9.2, Wireshark 3.02, and Python 2.8.
We also utilised the WEKA tool to extract the detection rules using the built-in JRip and
PART algorithms. It is a set of machine learning algorithms for different data-mining
tasks, such as data pre-processing, classiﬁcation, and clustering.
In addition, Microolap TCPDUMP for Windows, a network trafﬁc sniffer and
analyser software, was used to extract DNS trafﬁc from the benchmark dataset. Wireshark
is a network protocol analyser tool used for detailed analysis and basic feature extraction of
DNS packets. We used a python script in conjunction with Wireshark to calculate the
Figure 12 Process of a proposed hybrid rule-based model.
Full-size
DOI: 10.7717/peerj-cs.640/ﬁg-12
Al-mashhadi et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.640
20/34
new enriched features. The results of feature extraction, tabulated in Table 6, were stored in
a comma-separated values (CSV) ﬁle. Furthermore, having the ﬁnal training ﬁle in CSV
ﬁle format ensures seamless compatibility since it is fully supported and readable by
WEKA.
Finally, The hardware used in this study consists of a CPU with an Intel CoreTM
i5-8250u processor, 8 GB of memory, and a 256 GB Solid State Drive (SSD) hard disk.
Benchmark datasets
The experiment of this research is validated using two benchmark datasets: Network
Information Management and Security Group (NIMS) dataset (Haddadi & Zincir-
Heywood, 2016) and CTU13 dataset (Garcia et al., 2014).
The NIMS dataset by the Network Information Management and Security Group of
Dalhousie University in Halifax, Nova Scotia, Canada, contains four distinct traces: a
normal trafﬁc trace based on Alexa domain ranks and three different traces of malicious
trafﬁc from Citadel, Zeus, and Conﬁcker botnets. Table 7 lists the number of domain
names inside the dataset for each trace.
The experiment in this study utilised the regular DNS trafﬁc data within the CTU13
dataset (“Index of/publicDatasets/CTU-Normal-4-only-DNS,” 2016; https://mcfp.felk.
cvut.cz/publicDatasets/CTU-Normal-4-only-DNS/). The CTU13 dataset contains 5,966
normal DNS trafﬁc packets. The dataset comprises trafﬁc collected from music streaming
service 20songstogo.com, Gmail, Twitter, and regular web surﬁng via the Google Chrome
browser.
Recently, many researchers used the CTU13 dataset in their work (Haddadi, Phan &
Zincir-Heywood, 2016; Chen et al., 2017; Pektaş & Acarman, 2019).
The non-malware trafﬁc used in this experiment is from the normal part of CTU13,
which is CTU4 and CTU6 (“Malware Capture Facility Project: Normal Captures—
Stratosphere IPS”; https://www.stratosphereips.org/datasets-normal). The normal trafﬁc
for CTU4 is from a home computer network and includes only regular DNS trafﬁc for
privacy reasons. Similar to CTU4, the CTU6 comprises regular DNS trafﬁc generated from
a Linux-based notebook in a university network.
Finally, for our static analysis purpose, two enriched datasets were extracted using
feature engineering. The ﬁrst dataset is a mixed dataset that combines both NIMS and
CTU13 (normal trafﬁc) datasets, and the second dataset is based only on NIMS datasets.
Table 7 NIMS dataset domains count.
Dataset
Record count
Size (MB)
Alexa (normal trafﬁc)
654
2.2
Citadel
1,331
9
Zeus
707
11
Conﬁcker
98,606
1,800
Al-mashhadi et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.640
21/34
The combination of normal trafﬁc is to reduce overﬁtting resulted from an imbalance class.
Figure 13 shows a sample snapshot of training dataset instances.
It can be noticed that the datasets used for evaluating our proposed approach were from
2014 and 2016. However, using these datasets will not impact the presented result for the
following reasons: (i) in our approach, we analysed botnet’s DNS communication patterns,
which are totally different from human DNS communication. There is no newer dataset
publicly available that fulﬁls our requirement (DNS-based botnet trafﬁc), and (ii) these
datasets were also used by other researchers in their works (as recent as 2020) that we are
comparing with. Therefore, we also need to benchmark our proposed work using the same
dataset for fair evaluation and comparison.
Furthermore, our proposed work relies on the core DNS features that will always exist in
the DNS-based botnet lifecycle, which remains the same as long as it uses the conventional
DNS protocol. Therefore, the use of these datasets should not render our proposed
approach ineffective in detecting novel or future DNS-based botnets.
Design of the proposed technique
The design of the proposed technique, illustrated in Fig. 9, consists of three stages. This
section describes the design of each stage.
Figure 13 Snapshot of training dataset instances.
Full-size
DOI: 10.7717/peerj-cs.640/ﬁg-13
Al-mashhadi et al. (2021), PeerJ Comput. Sci., DOI 10.7717/peerj-cs.640
22/34
Design of pre-processing stage
In this stage, ﬁrst, the TCPDUMP tool selected and ﬁltered DNS trafﬁc from the network
trafﬁc, which reduced network trafﬁc by 68%. This process will reduce the time and
resources needed to analyse the remaining trafﬁc. Then, several Wireshark DNS packet
ﬁlters are used to extract several basic features from the DNS trafﬁc.
Table 8 shows the extracted features and the corresponding Wireshark ﬁlters used. The
basic extracted DNS features are stored in a CSV ﬁle as input for the next stage.
Design of DNS traffic analysis stage
In this stage, the enriched features are calculated based on the basic extracted DNS features
from the previous stage. The datasets had been prepared and normalised to calculate the
features as tabulated in Table 6.
Table 8 List of extracted features using Wireshark ﬁlters.
Feature
name
Feature description
Type of Wireshark ﬁlter
Time
The time a packet is captured
UTC date, as YYYY-MM-DD and
time
Source IP
address
The IP address for sender machine
DNS and ip.src
IP-TTL
(Time To
Live)
The time interval for cache before expiring for IP address
ip.ttl
Query ID
A 16-bit unique identiﬁer assigned by the program that generates any query; allows the server to
associate the answer with the question (query).
DNS.id
QR (Query/
Response)
A one-bit ﬁeld that speciﬁes whether this message is a query (0), or a response (1).
dns.ﬂags.response == 0 (query) dns.
ﬂags.response == 1 (response)
RCODE
This 4-bit ﬁeld is set as part of responses with these values:
1. No error
2. Format error
3. Server failure
4. Name Error Not Implemented
dns.ﬂags.rcode
QNAME
A domain name represented as sequence of labels, where each label consists of a length octet
followed by that number of octets
dns.qry.name