suming its domain is interval (0, 256]). Several approaches
have been proposed to create concept hierarchies for con-
tinuous attributes in data mining. For example, one simple
approach organizes a hierarchy into multiple levels, where
each level has different number of equal-length intervals.
Example 3 Consider a JVM Malfunction alert with a sen-
sitive attribute CPUProcessingTime = 82.6 milliseconds.
Using the concept hierarchy in Figure 1(b), we let CPUPro-
cessingTime = (64, 128].
To design a satisfactory concept hierarchy for sanitiza-
tion, or choose an appropriate interval to replace an original
value in a concept hierarchy, we use differential entropy [3],
an uncertainty measure for continuous attributes.
We ﬁrst discuss how to compute differential entropy.
When sanitizing a continuous attribute a, an original value
vo is replaced with an interval vg that includes value vo. The
length of vg is critical to the calculation of the attribute un-
certainty. We let Length(vg) denote the difference between
the upper and lower bounds of interval vg. We denote the
differential entropy of a associated with vg as Ha(vg).
f(a) log2 f(a)da,
(1)
vg
(cid:2)
Ha(vg) = −
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:08:53 UTC from IEEE Xplore.  Restrictions apply. 
where f(a) is the probability density function for attribute
a over interval vg.
form of differential entropy [3].
Ha(Dom(a)) = −(cid:3)
Equation 1 is derived and simpliﬁed from the standard
In the standard form,
Dom(a) fo(a) log2 fo(a)da, where
fo(a) is the probability density function over attribute do-
main Dom(a). Under our sanitization technique, although
we cannot know the exact value of attribute a, we are certain
that it is in interval vg, where vg may be a part of Dom(a).
Then we know that the probability density function f(a) is
0 outside interval vg. Thus the integration in Equation 1
only needs to be performed over vg
1.
β
Based on Equation 1, we can compute differential en-
tropy for sanitized attributes where their original values are
in different distributions. As an example, we derive a for-
mula for uniformly distributed attributes. The original at-
tributes in other distributions can be computed in a simi-
lar way. Assume an attribute a is in uniform distribution
and is sanitized to interval [α, β]. Thus its probability den-
sity function f(a) is 1/(β − α) when α ≤ a ≤ β; other-
−(cid:3)
wise f(a) = 0. Based on Equation 1, we have Ha(vg) =
α f(a) log2 f(a)da = log2(β−α) = log2 Length(vg).
This equation tells us that differential entropy can be
greater than, equal to, or less than 0. Consider a ran-
dom variable X uniformly distributed over an interval with
length 1. For a sanitized continuous attribute, if its differen-
tial entropy is greater than 0, then its uncertainty is greater
than variable X; if its differential entropy is equal to 0, its
uncertainty is equal to X; otherwise its uncertainty is less
than X. As noted by Shannon [16], an important differ-
ence between the differential entropy and the entropy for
categorical attributes is that differential entropy is “relative
to the coordinate system”. In other words, if the measure-
ment units are changed (e.g., from milliseconds to seconds),
differential entropy values may also change. To continue
Example 3, further assume attribute CPUProcessingTime is
uniformly distributed in interval (64, 128]. The differential
entropy of CPUProcessingTime associated with (64, 128] is
log2(128 − 64) = 6.
The differential entropy can help design a satisfactory
concept hierarchy. For example, assume the domain of an
attribute is [0, 64] with uniform distribution. If we require
a differential entropy value 5, we can build a concept hier-
archy with two levels, where the root node is [0, 64], and
there are two leaf nodes [0, 32] and (32, 64]. The differen-
tial entropy can also help us choose an appropriate interval
to replace an original value. For example, consider an orig-
inal attribute CPUProcessingTime=82.6 milliseconds and a
concept hierarchy in Figure 1(b). Assume attributes are in
If we require a differential entropy
uniform distribution.
1To let the probability density function f (a) satisfy (cid:0)vg
f (a)da = 1,
fo(a)da = q ≤ 1. We
f (a) can be derived from fo(a). Assume (cid:0)vg
can let f (a) = fo(a)/q in interval vg; otherwise f (a) = 0. Another
method to get f (a) is to compute the distribution parameters, which is
straightforward for uniformly distributed attributes.
value 6 for sanitization, we can choose (64, 128] to replace
the original value.
3 Correlation Analysis of Sanitized Alerts
The second phase of our approach is sanitized alert cor-
relation. As we stated in the Introduction, examining the
similarity between alert attributes and building attack sce-
narios are two focuses in current correlation approaches. In
Subsections 3.1 and 3.2, we discuss how to compute the
similarity between sanitized attributes and building attack
scenarios for sanitized alerts, respectively.
3.1 Similarity between Sanitized Attributes
Sanitized Categorical Attributes. Several functions or
heuristics (e.g., techniques in [19, 17]) have been proposed
to calculate the similarity between (original) attribute val-
ues. Here we ﬁrst give a simple heuristic, and then discuss
how to revise this heuristic to calculate the similarity be-
tween sanitized categorical attributes. Other simple heuris-
tics can be revised using a similar approach.
If two original attributes xo and yo are known, we give a
similarity function between them as follows.
(cid:4)
Sim(xo, yo) =
if xo = yo,
1,
0, otherwise.
(2)
After sanitization, xo and yo become generalized values
xg and yg, respectively. There are several ways to compute
the similarity between xg and yg. For example, we can treat
the sanitized attributes as the original ones, and use Equa-
tion 2 to compute their similarity. This is a coarse-grained
similarity measurement because even if the sanitized val-
ues are the same, their corresponding original values may
be different. We propose to compute their similarity by es-
timating the probability that xg and yg have the same orig-
inal value.
Intuitively, in a concept hierarchy, two nodes
Node(xg) and Node(yg) are possible to have the same orig-
inal value only if they are in the same path from the root
to a leaf node (Node(xg) and Node(yg) may be the same).
In other words, there is a speciﬁc-general relation between
xg and yg. If the probability that xg and yg have the same
original value is large, we interpret it as a high similarity
between them; otherwise their similarity is low.
Now we show how to compute the probability that xg
and yg have the same original value. To simplify our discus-
sion, we assume leaf node values in the concept hierarchy
have equal probabilities. Using probability theory, the re-
vised similarity function based on Equation 2 is as follows.
where “(cid:3)” denotes speciﬁc-general relations.
Sim(xg, yg) =
1
Leaf Count(xg) ,
Leaf Count(yg) ,
0,
1
if yg (cid:3) xg,
if xg (cid:3) yg,
otherwise,
(3)
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:08:53 UTC from IEEE Xplore.  Restrictions apply. 
When the leaf node values in a concept hierarchy are not
evenly distributed, to compute the similarity value for xg
and yg, we can ﬁrst compute the probability for each origi-
nal value based on attribute frequencies, then calculate the
similarity value based on xg, yg, the concept hierarchy, and
the probability for each leaf node.
Sanitized Continuous Attributes. The similarity func-
tion between continuous attributes is different from that of
categorical attributes due to various reasons. For example,
due to the clock drift, two CPUProcessingTime may not be
reported the same even if their actual time is the same. Con-
sidering these situations, here we ﬁrst give a simple similar-
ity function as follows. (Other similarity functions are pos-
sible and may be revised in a similar way to our approach.)
(cid:4)
Sim(xo, yo) =
if |xo − yo| ≤ λ,
1,
0, otherwise,
(4)
where xo and yo are original attribute values, and λ is a pre-
deﬁned threshold. For example, if the difference between
two CPUProcessingTime is less than 5 milliseconds, we say
their similarity is 1.
When xo and yo are generalized to intervals xg and
yg, respectively, there are several ways to compute the
similarity between xg and yg. For example, assuming
Length(xg) = Length(yg) > λ, their similarity is 1 if
xg = yg, and 0 otherwise. This certainly is a rough, impre-
cise estimation, because even if xg and yg are not the same
interval, it is possible that the difference between their orig-
inal values is less than λ. Similar to the categorical case, we
propose to compute their similarity by estimating the prob-
ability that the difference between their original values is
within threshold λ.
To simplify our discussion, suppose that original val-
ues of xg and yg are independent and uniformly distributed
over intervals xg and yg, respectively, and we also assume
Length(xg) = Length(yg) > λ. More sophisticated cases
such as Length(xg) (cid:6)= Length(yg) can be covered by an ap-
proach similar to the following calculation. We notice the
difference between two original values may be within λ
only if xg and yg fall into any of the following two cases.
(1) xg and yg are the same interval, or (2) for xg and yg, the
difference between the lower bound of the higher interval
and the upper bound of the lower interval is within λ. Intu-
itively, this second case means xg and yg either are adjacent
intervals (e.g., [0, 5] and (5, 10]), or there is a small “gap”
between them (e.g., [0, 5] and [6, 11]).
Using probability theory, the revised similarity function
based on Equation 4 is as follows.
2
2λ[Length(xg )]−λ
[Length(xg )]2
(λ−d)2
2[Length(xg)]2 ,
0,
,
if xg = yg,
if 0 ≤ d ≤ λ,
otherwise,
Sim(xg, yg) =
(5)
where d is the difference between the lower bound of the
higher interval and the upper bound of the lower interval.
Note that similarity computation based on Equation 5 is
symmetric (Sim(xg, yg) = Sim(yg, xg)).
We notice that
in the probability computation, we
have taken several assumptions such as Length(xg)=
Length(yg)> λ to simplify our calculation. However, the
essential steps involved in the probability computation have
been demonstrated. More sophisticated cases can be cov-
ered by a similar approach.
3.2 Building Attack Scenarios
An attack scenario is a sequence of steps adversaries per-
formed to attack victim machines. The essence of creating
attack scenarios from security alerts is to discover causal re-
lations between individual attacks. For example, there is a
causal relation between an earlier SCAN NMAP TCP attack
and a later FTP Glob Expansion attack if the earlier one is
used to probe a vulnerable ftp service for the later one.
We extend a previous correlation method [11], which
targets at building attack scenarios from original alerts, to
build attack scenarios from sanitized alerts. In the follow-
ing, we ﬁrst give an overview of that correlation method
with a slight modiﬁcation, which simpliﬁes our discussion
without losing the essence of the previous method.
A Previous Method for Building Attack Scenarios
[11]. The correlation method in [11] models each attack
type through specifying its prerequisite and consequence,
where the prerequisite is the necessary condition to launch
the attack successfully, and the consequence is the possi-
ble outcome if the attack succeeds. Prerequisites and con-
sequences are modeled by predicates. For example, the
consequence of a port scanning attack may be ExistSer-
vice(DestIP, DestPort), denoting that an open port DestPort
is found on host DestIP. Formally, given an alert type T ,
the prerequisite of T is a logical combination of predicates,
and the consequence of T is a set of predicates, where the
variables in the predicates are attribute names in type T .
Example 4 Consider alert types T1=SCAN NMAP TCP
and T2=FTP Glob Expansion. T1’s prerequisite is Ex-
istHost(DestIP), and {ExistService(DestIP,DestPort)} is its
T2’s prerequisite is ExistService(DestIP,
consequence.
DestPort) ∧ VulnerableFtpRequest(DestIP), and its conse-
quence is {GainAdminAccess(DestIP)}.
Given a type T alert t, the prerequisite and consequence
of t can be obtained through instantiating T ’s prerequisite
and consequence using t’s attribute values and timestamps.
We model causal relations between alerts (i.e., detected at-
tacks) as prepare-for relations. Intuitively, an earlier alert
t1 preparesfor a later alert t2 if the consequence of t1 can
contribute to the prerequisite of t2. Formally, t1 prepares
for t2 if and only if (1) one of the instantiated predicates in
t1’s consequence implies one of the instantiated predicates
in t2’s prerequisite, and (2) t1.EndTime < t2.StartTime.
Example 5 To continue Example 4, consider a type T1
alert t1 and a type T2 alert t2.
Assume that t1
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:08:53 UTC from IEEE Xplore.  Restrictions apply. 
and t2 both have DestIP=10.10.1.1 and DestPort=21,
t1’s EndTime is 11-15-2004 20:15:10, and t2’s Start-
Time is 11-15-2004 20:15:15.
Through predicate in-
stantiation, t1’s consequence is {ExistService(10.10.1.1,
21)}, t2’s prerequisite is ExistService(10.10.1.1, 21) ∧
VulnerableFtpRequest(10.10.1.1). Notice t1.EndTime <
t2.StartTime. Then we know t1 preparesfort2.
Alert correlation graphs are used to represent the at-
tack scenarios discovered through alert correlation. For-
mally, an alert correlation graph is a directed graph (N, E),
where each node n ∈ N is an alert, and each directed edge
(n1, n2) ∈ E represents that n1 preparesfor n2. For con-
venience, we may use causal relations and prepare-forrela-
tions interchangeably in this paper. Given two alerts t1 and
t2, where t1 preparesfor t2, we call t1 the preparing alert,