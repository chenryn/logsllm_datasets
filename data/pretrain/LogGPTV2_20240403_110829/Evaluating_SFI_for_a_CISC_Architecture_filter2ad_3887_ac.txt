jumps outside its code region or writes outside its data
region. In general, this property is impossible to decide,
but it is tractable if we are willing to accept one-sided
error: we do not mind if the veriﬁer fails to recognize
that some programs have the safety property, as long as
whenever it concludes that one does, it is correct. If the
original program was correct, it already had this safety
property; the rewriting simply makes the property mani-
fest, so that the veriﬁer can easily check it.
The veriﬁcation process essentially computes, for each
position in the rewritten instruction stream, a conserva-
tive property describing the contents of the processor’s
registers at any time when execution might reach that
point. For instance, directly after an appropriate and
instruction not at a chunk boundary, we might know that
the contents of the target register are appropriately sand-
boxed for use in accessing the data region. The major
part of the safety proof is to show that these properties
are sound for any possible execution; it is then easy to see
that if the properties always hold, no unsafe executions
will be possible. An important aspect of the soundness
is that it is inductive over the steps in the execution of
the rewritten code: for instance, it is important that none
of the instructions in the code region change during exe-
cution, as new instructions would not necessarily match
the static properties. We can be conﬁdent of this only be-
cause in previous execution up to a given point, we can
assume we were successful in preventing writes outside
the data section. In program veriﬁcation terminology, the
soundness property is an invariant that the veriﬁer checks
as being preserved by each instruction step.
6 Prototype implementation
To test the practicality of our approach, we have con-
structed a prototype implementation, named PittSFIeld.
PittSFIeld instantiates a simple version of the technique,
incorporating only the most important optimizations.
However, PittSFIeld was designed to address some im-
portant practical considerations for a real tool, such as the
separate veriﬁcation model and scalability to large and
complex programs.
In particular, PittSFIeld makes no
fundamental compromises with respect to the rigorous
security guarantees that the technique offers. The perfor-
mance of code rewritten by PittSFIeld (described in the
next section) should also give a reasonable upper bound
on the overhead of this general approach, one which
could be somewhat improved by further optimization.
(However, other aspects of the prototype are not repre-
sentative of a practical implementation: for instance, the
rewriter is unrealistically slow.)
The rewriting performed by PittSFIeld is a version of
214
Security ’06: 15th USENIX Security Symposium
USENIX Association
the techniques described in Sections 3 and 4, chosen to
be easy to perform. The register %ebx is reserved (us-
ing the --fixed-ebx ﬂag to GCC), and used to hold
the sandboxed address for accesses to both the data and
code regions. The effective address of an unsafe opera-
tion is computed in %ebx using a lea instruction. The
value in %ebx is required to be checked or sandboxed di-
rectly before each data write or indirect code jump (reads
are unrestricted). Both direct and indirect jumps are con-
strained to chunk-aligned targets. Guard regions are 64k
bytes in size: %ebp and %esp are treated as usually-
sandboxed. Accesses are allowed at an offset of up to 64k
from %ebp, and of up to 255 bytes from %esp; %esp is
also allowed to be modiﬁed up to 255 times, by as much
as 255 bytes each time, between checks. Both %ebp and
%esp must be restored to safe values before a jump. A
safe value in %esp may be copied to %ebp or vice-versa
without a check. Chunks are padded using standard no-
op instructions of lengths 1, 2, 3, 4, 6, and 7 bytes, to a
size of 16 or 32 bytes.
Because it operates on assembly code, our prototype
rewriting tool is intended to be used by a code pro-
ducer. A system that instead operates on off-the-shelf
binaries without the code producer’s cooperation is often
described as a goal of SFI research, but has rarely been
achieved in practice. The key difﬁculty is that binaries
do not contain enough information to adjust jumps when
instructions are added: for instance, it may not be pos-
sible to distinguish between an address referring to an
instruction and an integer with the same numeric value.
A more feasible approach is to operate on binaries sup-
plemented with additional relocation information, such
as the debugging information used by the Vulcan library
in [1], or the SELF extension to ELF proposed in [8].
Both the rewriting and the veriﬁcation in PittSFIeld
are performed as single top-to-bottom passes, essentially
as ﬁnite-state machines. While this prohibits some op-
timizations (for instance, labels that are targets only of
direct jumps need not necessarily be aligned), it allows
PittSFIeld to rewrite very large programs, and guaran-
tees that the veriﬁcation’s running time will be linear. (A
veriﬁcation technique with bad worst-case performance
can allow a denial-of-service attack [12]).
The rewriting phase of PittSFIeld is implemented as a
text processing tool, of about 720 lines of code, operat-
ing on input to the GNU assembler gas. In most cases,
alignment is achieved using the .p2align directive to
the assembler, which computes the correct number of no-
ops to add; the rewriter uses a conservative estimate of
instruction length to decide when to emit a .p2align.
The rewriter adds no-ops itself for aligning call instruc-
tions, because they need to go at the end rather than the
beginning of a chunk. The rewriter notices instructions
that are likely to be used for their effect on the processor
status ﬂags (e.g., comparisons), and saves and restores
the ﬂags register around sandboxing operations when the
ﬂags are deemed live. However, such save and restore
operations can be costly on modern architectures, so to
prevent GCC from moving comparisons away from their
corresponding branches, we disable instruction schedul-
ing with the -fno-schedule-insns2 option when
compiling for PittSFIeld. An example of the rewriter’s
operation on a small function is shown in Figure 3.
We have implemented two prototypes for the veriﬁ-
cation phase of PittSFIeld, which implement the same
algorithm. Because they use a single disassembly pass,
the veriﬁers enforce alignment by checking that an in-
struction in the single stream must appear at each chunk
starting address. The veriﬁers currently verify only the
style of rewriting in which pointers are modiﬁed, and not
the style in which they are checked and execution halted
if they are incorrect. As mentioned in Section 5, the ver-
iﬁers are essentially ﬁnite-state: at each code location,
they keep track of variations from the standard safety in-
variant, checking them and then updating their knowl-
edge for each instruction. Operations that ‘strengthen’
the invariant (for instance, sandboxing a pointer value in
%ebx) expire after one instruction or at a chunk bound-
ary, whichever comes ﬁrst. Operations that ‘weaken’ the
invariant (for instance, loading a new value into %ebp)
persist until corrected, and must not reach a jump.
Our ﬁrst veriﬁer is implemented using the same text-
processing framework as the rewriter: it is a ﬁlter that
parses the output of the disassembler from the GNU
“binutils” package (the program named objdump), and
represents about 500 lines of code. Our second veriﬁer
is implemented directly in the program that loads and
executes sandboxed code objects, using a pre-existing
disassembly library; this allows for a better assessment
of the performance overheads of veriﬁcation. Though it
does not yet check the complete safety policy, the sec-
ond veriﬁer is complete enough to give rough perfor-
mance estimates: for instance, it can verify the 2.7MB
of rewritten code for GCC, the largest of the programs
from Section 7, in about half a second. Both of our ver-
iﬁers are much smaller than the disassemblers they use,
so the total amount of trusted code could be reduced by
disassembling only to the extent needed for veriﬁcation,
but using existing disassemblers takes advantage of other
users’ testing. Performing more targeted disassembly in
this way would also be a way to further improve perfor-
mance. PittSFIeld supports a large subset of the x86 32-
bit protected mode instruction set, but supervisor mode
instructions, string instructions, and multimedia SIMD
(e.g. MMX, SSE) instructions are not supported; the ver-
iﬁer will reject any program containing an instruction it
does not recognize.
USENIX Association
Security ’06: 15th USENIX Security Symposium
215
%ebp
%esp, %ebp
8(%ebp), %edx
48(%edx), %eax
1(%eax), %ecx
%ecx, 48(%edx)
%ebp
f: push
mov
mov
mov
lea
mov
pop
ret
f:
push
mov
mov
mov
lea
lea
lea
lea
lea
and
mov
pop
lea
and
andl
ret
%ebp
%esp, %ebp
8(%ebp), %edx
48(%edx), %eax
1(%eax), %ecx
0(%esi), %esi
48(%edx), %ebx
0(%esi), %esi
0(%edi), %edi
$0x20ffffff, %ebx
%ecx, (%ebx)
%ebp
0(%esi), %esi
$0x20ffffff, %ebp
$0x10fffff0, (%esp)
Figure 3: Before and after example of code transformation. f is a function that takes an array of integers, increments the 12th, and
returns (in %eax) the value before the increment. The assembly code on the left is produced by GCC; that on the right shows the
results of the PittSFIeld rewriter after assembly. Rules separate the chunks, and no-op instructions are shown in gray. (Though they
look the same here, the ﬁrst three no-ops use different instruction encodings so as to take 4, 6, and 7 bytes respectively).
7 Performance results
To asses the time and space overheads imposed by our
technique, we used our PittSFIeld tool to run stand-
alone applications in fault-isolated environments. The
programs were not chosen as code one might partic-
ularly want to run from an untrusted source, merely
as computation-intensive benchmarks. The ‘untrusted’
code in each case consisted of the application itself, and
some simple standard library routines. More complex li-
brary routines and system calls were treated as ‘trusted,’
and accessed via special stubs allowing controlled access
out of the sandbox. In a realistic application, these stubs
would include checks of their arguments to enforce de-
sired security policies. In our prototype, the trusted load-
ing application and stub trusted calls consisted of ap-
proximately 800 lines of C code, including blank lines
and comments. A previous technical report [18] gives
results for an older version of PittSFIeld run on a set of
microbenchmarks, and some larger applications. For bet-
ter comparison with other work, we here concentrate on
a standard set of compute-intensive programs, the integer
benchmarks from the SPEC CPU2000 suite.
The SPECint2000 suite consists of 12 programs and
reference inputs intended to test the performance of
CPUs, compilers, and memory subsystems. One of the
programs is written in C++, and the rest in C. In our
tests, we compiled the programs with GCC or G++ ver-
sion 3.3.5 at the -O3 optimization level. The test system
was a 3.06GHz Pentium 4 “Northwood”, with 512KB
of cache and 2GB of main memory, running Debian
Linux 3.1 with kernel version 2.4.28 and C library ver-
sion 2.3.2. We changed the layout of the code and data
sandbox areas to allow a larger data area. Each test was
run ﬁve times with the reference inputs using the stan-
dard SPEC scripts; we discarded the slowest and fastest
runtimes and took the average of the remaining three.
In order to measure the effect on performance of dif-
ferent aspects of PittSFIeld’s rewriting, we ran the pro-
grams using a number of treatments, representing in-
creasing subsets of the transformation the real tool per-
forms. Figure 4 shows the increase in runtime over-
head as each transformation is enabled, from bottom
to top. The base treatment uses PittSFIeld’s program
loader, but compiles the programs with normal optimiza-
tion and uses none of the features of the rewriter. The
measurements of Figure 4 are all measured as percent-
age overhead relative to the base treatment. The ﬁrst
(bottom) set of bars in Figure 4 represents disabling in-
struction scheduling with an option to GCC. Disabling
this optimization has a small performance penalty, but
avoids higher overheads later by reducing the need to
save and restore the EFLAGS register as discussed in
Section 6. The next set of bars represents the effect of
directing GCC to avoid using the %ebx register in its
generated code, reducing the number of general purpose
registers from 6 to 5; PittSFIeld requires %ebx to be
available to hold the effective address of indirect writes
and jumps. The next treatment, labelled “padding”, re-
ﬂects the basic cost of requiring chunk alignment: the
rewriter adds enough no-op instructions so that no in-
struction crosses a 16-byte boundary, and every jump
target is 16-byte aligned. The next set of bars, labelled
“NOP sandboxing”, attempts to measure all of the ad-
ditional overheads related to PittSFIeld’s code size in-
crease, beyond those measured in “padding”. To achieve
this, this treatment adds just as many bytes of new in-
structions as PittSFIeld normally would, but makes all
of them no-ops: this includes both sandboxing instruc-
tions, and additional padding required for the new in-
216