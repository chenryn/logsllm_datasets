### 3.3 ChkPassword: A Running Toy Example

Ensuring state continuity is a non-trivial task that can only be achieved by a module provider taking the necessary safety precautions. We provide a library that offers state-continuous storage. To illustrate the subtle vulnerabilities that need to be addressed, consider ChkPassword, a password-checking module shown in Listing 1. This module exposes two functions: `set_passwd` for modifying the user's password and `check_passwd2` for handling login attempts. To prevent dictionary attacks, ChkPassword will lock out a user indefinitely after three incorrect attempts. We assume that when the module is created, the `INIT` function is called before any service call is handled.

When ChkPassword runs on the platform for the first time, a default password is selected (line 7). Otherwise, its previous state is restored (line 10).

To ensure state continuity, ChkPassword must meet three requirements:

1. **Protection Against Timing Attacks**: An attacker should not be able to infer whether a provided password is correct based on timing differences. If an attacker can determine that a password is incorrect, they may crash the system before the login attempt is recorded. Ensuring that each execution path takes exactly the same amount of CPU cycles is challenging. Similar to Parno et al. [20], we take a simpler approach by storing the state with the newly provided input before it is used in any computation. Thus, ChkPassword stores its current state (the number of attempts left and the correct password) together with the provided guess (lines 17-20) before checking the password. If the system crashes while the password is being verified (i.e., after line 20), the current state is restored, and execution is restarted, rechecking the same provided password. We assume that `restore_and_restart` restores the current state and restarts execution of the last called entry point (line 10). If the system crashes before the input is recorded, the provided guess can simply be discarded.

2. **Determinism**: To guarantee that re-execution of the same input on the same state always leads to the same result, modules must be deterministic. This means that all sources of non-determinism (e.g., the result of a random number generator) must be considered as input and stored before use.

3. **State Size Consistency**: An attacker must not be able to infer any value from the size of the stored states on disk; therefore, modules must ensure that all stored states are of equal size.

### 3.4 ICE Libraries

We provide state-continuous storage in two steps. In Section 3.4.1, we introduce `libice0`, a library that provides support at the cost of scarce platform resources for every instance. In Section 3.4.2, we present `libicen`, which alleviates resource pressure by storing freshness information in a single, state-continuous module `ice0`. Both `libice0` and `libicen` provide the same interface: `store(State *)` and `retrieve(State **)`. To avoid repeated TPM or `ice0` accesses, both libraries keep a cached copy. We reference these copies similarly to fields of a struct. For example, the encryption and MAC keys stored in the TPM chip are referenced as `tpm.keys`. The variables used by the ICE algorithm are referenced as `ice.keys`, and so on. Besides storing keys and the guard, we also track the state of the algorithm using a `mode` variable. Stored inside the TPM chip (`tpm.mode`), this variable indicates whether ICE was initiated correctly. In `libice0` (`ice.mode`), this variable indicates whether ICE was initiated or recovered since reboot. We assume that when a module is resurrected after a crash, `ice.mode` is initialized with the value `Clear`. As a shorthand, we also assume that setting this variable takes exclusive access to guarded memory. Listing 2 uses these variables to differentiate between an initial state being stored and a state being updated. Similarly, `tpm.mode` is used to determine whether a state was ever stored.

#### 3.4.1 libice0: State-Continuous Storage for One Module

To provide state continuity, we must ensure that an attacker cannot fabricate recorded states (called cubes) and that no stale cubes can be provided as fresh. The former is trivially guaranteed by including a message authentication code in each cube. Guaranteeing freshness is more challenging, but as modules maintain their state between invocations, we only need to consider power-off and reboot events. Let's call events during such power cycles an execution stream. An execution stream starts either by storing an initial state of a module or when the state of a module is recovered after a crash. It ends when the system crashes or when it is shut down properly.

To keep track of the fresh cube, we generate a (base) guard when the execution stream starts and store it securely in TPM NVRAM. For every state the module requests storage of in the current execution stream, we increment the guard and include it in the generated cube. Using guarded memory, we ensure that only the guard included in the last (and thus fresh) cube is leaked at the moment the system crashes. As no preceding guards were leaked (and cannot be calculated), it serves as a pointer to the fresh cube. Upon recovery, knowledge of the guard stored in the provided cube proves that the cube is fresh.

**Creation of an Initial State:**

When storage of the initial state of the module is requested, a new base guard and keys are generated (see Listing 3). Next, a new cube is constructed and written to disk. Exclusive access to guarded memory is taken by setting the `ice.mode` variable to `Activated`, and the fresh guard is written to guarded memory. If exclusive access cannot be assigned (i.e., another module already received it), the module stops its execution. Finally, the keys and guard are stored in the TPM’s NVRAM, and `tpm.mode` is set to `Activated`, committing the start of a new execution stream.

**Updating a State:**

When storage of a new input-state pair is requested in the same execution stream, the previously used guard and keys are still stored in `libice0`'s memory, and no TPM accesses are required. To safely store the input-state pair, a new cube is created with the subsequent guard and stored on disk (Listing 4). Finally, the fresh guard is written to guarded memory, committing the step.

**Recovering from a Crash:**

Recovering from a crash is more challenging and is performed in two steps (see Listing 5, error handling is omitted for clarity). First, the last stored cube is read from disk. By verifying three properties, its freshness is ensured:
- **Validity**: Cubes must not have been forged. This is ensured by the MAC stored in each cube and the accompanying key stored securely in the TPM (line 17).
- **Correct Execution Stream**: The cube received from the untrusted OS must have been created during the last execution stream. Starting each execution stream, a new base guard is generated and stored safely in TPM NVRAM. All guards used during this execution stream are successors of this base guard. Hence, the cube was created during the last execution stream if (line 18): `tpm.guard ≤ cube.guard`.
- **Public Guard**: `libice0` ensures that guarded memory always contains the same guard as the last (fresh) cube stored on disk, and that no preceding guards leak or can be calculated. Hence, if the guard stored in guarded memory matches the guard included in the cube at hand and the two previous properties hold, it is guaranteed that the cube is fresh (line 19).

In the second step, the fresh state is re-stored as part of a new execution stream: `libice0`'s variables are restored from TPM NVRAM, a new base guard is generated, the fresh state is packaged in a new cube, and the base guard is written to guarded and TPM NVRAM memory. To ensure that after an unexpected crash during the execution of this step, recovery can be restarted, `libice0` must (1) back up the previous fresh guard before overwriting it in guarded memory. As this value is public, any persistent storage can be used.