architecture and dataset they used. We achieved 89% accuracy, a
slightly higher accuracy than the one Abe and Goto reported in
their paper. We believe that using different Python DL modules
(Kera and Tensorflow) and randomly initializing the weights ac-
counts for this difference. Furthermore, we slightly changed their
SDAE model’s hyperparameters to improve its performance in our
experiments.
5.1.3 AWF. Rimmer et al. provided us with their source code to
re-produce their results. We strictly followed their proposed hy-
perparameters and evaluate the model in our dataset to make a
fair comparison for our model and the previous state-of-the-art WF
attacks.
5.1.4 DF. To develop our DF model to effectively perform WF at-
tacks on both non-defended and defended dataset, we have followed
techniques in the deep learning literature [21, 22, 36] to improve the
performance of the model, such as using the appropriate number of
convolutional layers, mitigation and prevention of overfitting [34]
and a suitable activation function for our WF input data [25]. These
studies helped us design the sophisticate architecture and tune the
model’s hyperparameters that best fit for WF.
We adapted the base CNN model of DF to our needs, as there
are important differences between traffic analysis and traditional
applications of CNN-based models such as image recognition. For
example, standard activation functions such as sigmoid and rectified
linear unit (ReLU) do not activate on negative values and thus will
not use the information conveyed by the sign of the input (i.e., cell
direction). Activation functions that can handle negative inputs
include tanh, leaky ReLU (LReLU), parametrized ReLU (PReLU)
and Exponential Linear Unit (ELU). Prior work has shown that
ELU provides fast and accurate classification [11, 25]. We compared
ELU with other activation functions during hyperparameter tuning
and it performed the best among all the functions we tested (see
Section 5.2). Although the traditional tanh function can also handle
negative inputs, it is vulnerable to the vanishing gradient issue [4],
which slows down optimization.
Another difference between traffic and image data is that images
are two-dimensional, whereas our data is a vector. This means that
filter and pool sizes cannot be two-dimensional (e.g., 2x4) but have
to be cast to one dimension (e.g., 1x4).
5.2 DF’s Hyperparameter Tuning
A fundamental process in supervised classification is to tune the
hyperparameters of the classification model, such as the kernel
used in an SVM or the number of hidden layers in a CNN. This
process involves adjusting the trade-off between variance, bias and
classification performance, so that the model fits the training data
while still generalizing to samples that it has not been trained on. For
DF, however, the large amount of training data and the large number
of hyperparameters the model has render an exhaustive search
prohibitive in terms of computational resources. To demonstrate
our attacks, we thus only aim at a good-enough classifier and we
Session 10A: TORCCS’18, October 15-19, 2018, Toronto, ON, Canada1933acknowledge that someone with more resources might be able to
optimize our model further.
To select the hyperparameters for our models, we perform an
extensive search through the hyperparameter space, in which we
build each layer of the deep learning model block by block. In
each building block, we vary the hyperparameters to estimate the
gradient of the parameter and determine whether we must increase
or decrease its value. Once this process is done, we select the best
top-n parameters and use them as the initial parameters for the
optimization in the next block. When all layers are set, we select
the best combination of hyperparameters.
By the transferability property of neural networks [42], WF at-
tacks based on other models can use the values we found for the DF
hyperparamters to bootstrap the hyperparameters of their model.
We thus used the transferability property to find the parameters
for the defended datasets from the hyperparameters found using
the undefended dataset. We only needed to slightly adjust some
hyperparameters to optimize our model, significantly reducing the
time spent in hyperparameter tuning. We thoroughly illustrate and
explain our design of DF model in Appendix A. The search space
as well as the final selected values are shown in Table 1.
Evaluating overfitting Even though deep neural networks (DNN)
are a powerful supervised classification model, they are, as with as
most machine learning models, vulnerable to overfitting. Overfit-
ting occurs when the model errs on samples that it has not been
trained on, meaning that the model cannot generalize. For small
datasets, overfitting can be measured with cross-validation tech-
niques. For large datasets like ours, however, we can just split the
data into three mutually exclusive sets: training, validation and
testing, with a ratio of 8:1:1. We then measure the difference in
error rate between different sets. In case of overfitting, the model
would achieve a substantially higher accuracy on the training set
than on the testing set.
During the training of our DF model, we applied Dropout [34]
and Batch Normalization (BN) [18] to prevent overfitting. These
are regularization techniques that loosen the model and allow for
greater generalization. In dropout, the model randomly selects
hidden units, including their incoming and outgoing connections,
and temporarily removed them from the network while training.
BN normalizes the fully-connected and convolutional layers’ out-
puts and helps accelerate learning while also reducing overfitting.
Moreover, we analyze the error rates between training and testing
datasets during hyperparameter tuning to ensure that our model is
not overfitting.
Figure 4 depicts the training and testing error rates. The differ-
ence between training and testing error of the DF model is less than
2%, suggesting that overfitting is unlikely.
5.3 Differences Between DF and AWF
We now explain the significant differences of the DF model com-
pared to the AWF model proposed by Rimmer et al. [31] that help
explain the superior performance of DF.
Basic Block Design. The basic block is the group of convolutional
layer(s), max pooling layer, filters and activation layer(s) that per-
form feature extraction in a CNN. Generally, the basic block is
repeatedly appended to create deeper networks.
Figure 3: Comparison between AWF and DF models
We observe that the AWF model is similar to Imagenet [22], one
of the earliest CNN models proposed in 2012. The basic block of this
model only contains one convolutional layer followed by one max
pooling layer as shown in Figure 3(a). In contrast, our DF model
is inspired by modern large image classification networks such
as VGG [21], GoogleNet [36] and ResNet [15] that apply at least
two consecutive convolutional layers before a max pooling layer
as shown in Figure 3(b). Max pooling typically reduces the data to
a smaller size, so it is not possible to have deeper networks when
pooling after every convolutional layer. Adding more convolutional
layers in each basic block thus enables more convolutional layers in
total and a deeper network with more effective feature extraction.
Overfitting Concerns. Rimmer et al. criticized the CNN model for
having a higher risk of overfitting which was shown in their ex-
perimental results. We argue that a more carefully crafted model
can mitigate overfitting. The AWF model includes a dropout layer
before the first basic block as shown in Figure 3(a). While dropout
is a common technique to help prevent overfitting, this placement
is atypical in CNN designs, as it may result in the loss of meaning-
ful features extracted from the input and may not be sufficient to
prevent overfitting. In DF, we used overfitting-contention mech-
anisms that are applied in the state-of-the-art CNN networks for
computer vision, including a batch normalization (BN) layer that
is added right after each convolutional layer and a dropout layer
after the activation function, as explained in Section 5.2. With these
mechanisms, the DF model shows no evidence of overfitting in our
experiments.
Varying Hyperparameters In the AWF model, the value of some
hyperparameters are fixed such as using 32 filters in every convo-
lutional layer. Using a fixed number of filters over all the layers
reduces the capability of the model to learn. In contrast, the DF
model follows the state-of-the-art in computer vision by varying
hyperparameter values for different layers [21]. For example, we
increase the number of filters as we get deeper in the network. The
intuition behind varying the values is that the CNN uses hierarchi-
cal features in its processing pipeline. The features in lower layers
(close to the input) are primitive, like edge detection, while features
Session 10A: TORCCS’18, October 15-19, 2018, Toronto, ON, Canada1934in upper layers are high-level abstract features, like object detection,
made from combinations of lower-level features. We increase the
number of filters at higher layers to improve the ability to encode
richer representations.
Activation Function. The AWF model only uses the ReLU activation
function. ReLU is popular in CNNs, but it maps all negative values
to zero. Our input formats include negative values that represent
incoming packets, so using ReLU in convolutional layers close the
input can substantially reduce the information available to deeper
layers in the model. In the DF model, the activation function in
the first basic block is ELU, which can learn a data representation
containing negative values to ensure that the model can learn all
meaningful representations from the input.
Fully-connected Layers. The AWF model directly connects the last
max pooling layer to the prediction layer, a densely connected layer
with an output size equal to number of classes. In more recent
CNNs, there are a set of fully connected (FC) layers that follow the
convolutional layers and precede the prediction layer. The FC layers
play an important role in the learning and classification processes
of the model. Essentially, the convolutional layers perform feature
extraction, but that means that it is important to carefully design the
classifier that uses the extracted features, which is the role of the FC
layer. In the DF model, we add two FC layers with the combination
of BN and dropout to prevent the overfitting that normally occurs
in FC layers.
Overall, our DF model was specifically designed to effectively
perform WF attacks by leveraging the state-of-the-art techniques
from computer vision research. We provide a thorough explanation
on how the DF model was developed and a visualization of the
DF model in Appendix A to allow other researchers to gain better
understanding and reproduce our work. Our experimental results
confirm that DF performs better than AWF model in defended and
non-defended and on both closed-world and more realistic open-
world scenarios. These results help to illustrate the impact of the
DL architecture design on the performance of the attacks.
5.4 Closed-world Evaluation on Non-defended
Dataset
We evaluate the performance of the DF attack in the closed-world
scenario on the non-defended dataset, which comprises website
traces from the closed-world dataset with no WF defenses in place.
Moreover, we compare DF model with the state-of-the-art WF
attacks: k-NN, CUMUL, k-FP, AWF, and SDAE. We re-evaluate
these attacks on our non-defended dataset and apply k-fold cross-
validation for training their classifiers and testing their performance,
as was done in the papers presenting these attacks [14, 27, 38].
Table 2: Closed World: Accuracy on the non-defended
dataset for state-of-the-art attacks.
Classifier
Accuracy
CUMUL k-FP
97.3%
95.5%
SDAE
92.3%
DF
98.3%
AWF
94.9%
k-NN
95.0%
Table 2 shows the accuracy results. Our DF model attains 98.3%
accuracy, which is better than the other attacks and higher than any
previously reported result for a WF attack in Tor. Our DF model
y
c
a
r
u
c
c
A
100
98
96
94
92
90
DF Training Accuracy
DF Testing Accuracy
DF Testing Error Rate
DF Training Error Rate
10
10
30
20
20
30
Number of epochs
40
40
10
8
6
4
2
0
e
t
a
R
r
o
r
r
E
Figure 4: Closed World: Impact of the number of training
epochs on DF accuracy and error rate
100
90
80
70
y
c
a
r
u
c
c
A
60
0
200
400
600
Training Size
DF
CUMUL
k-NN
k-FP
AWF
SDAE
800
Figure 5: Closed World: Impact of numbers of training traces
on classification accuracy
performs better than AWF. Our results for AWF (94.9%) are a bit
lower than the reported results by Rimmer et al. (96.5%), we believe
this is due to the larger dataset used by them. We observe that
CUMUL, k-FP, k-NN and SDAE benefit from the larger training data
set with 2-4% higher accuracies than previously reported results
that used smaller datasets (usually 90 training instances). SDAE
was not as accurate as the other attacks.
Additionally, we investigate how fast the model can learn to
distinguish patterns from the input data, also known as convergence
of the model. This depends on many factors such as the method
used for data pre-processing, the DL architecture and the hyperpa-
rameters used to create the model. This evaluation helps to validate
the quality of our hyperparameter tuning method. Moreover, the
attacker can use this to estimate the number of training epochs,
rounds of feeding training data into the classifier, required for the
Session 10A: TORCCS’18, October 15-19, 2018, Toronto, ON, Canada1935classifier to reach the expected level of accuracy. Normally, the
classifier gradually learns better with more training epochs.
Figure 4 shows that with only 10 training epochs, DF can reach
testing accuracy of about 97%, DF consistently improves with more
training epochs, until accuracy levels off after 30 epochs.