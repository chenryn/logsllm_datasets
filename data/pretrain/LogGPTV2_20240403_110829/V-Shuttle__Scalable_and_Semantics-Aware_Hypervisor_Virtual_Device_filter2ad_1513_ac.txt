In order to address this issue, we propose a fine-grained
semantics-aware fuzzing method. Fundamentally, our design aims
at providing type awareness for the fuzzing engine, so that it can
dynamically generate targeted test cases according to the requested
data type of the program. This design choice allows us to lever-
age the advantages of coverage-guided fuzzing, favoring the input
which exhibits a new coverage and guiding the fuzzer towards
learning to generate semantically valid inputs to each type of data.
Overall, with the help of type awareness, the fuzzing engine is ca-
pable of providing semantically correct node data when traversing
the nested structures.
1 // before hooking
2 pci_dma_read(dev, buffer_addr, &buf, size);
3
4 // after hooking
5 if (fuzzing_mode)
6
read_from_testcase(&buf, size, type_id);
Listing 2: Conversion to fuzzed inputs with type constraints.
To this end, V-Shuttle first decouples the nested structures
into independent nodes by using an improved DMA redirection
method. Next, it implements a seedpool-based fuzzing engine to
maintain multiple seed queues, one for each type of decoupled node.
Then with the type guidance, V-Shuttle performs semantics-aware
fuzzing to the hypervisor. This design method is based on the basic
knowledge: the semantics of each node is independent, and there is
no dependency between them. Thus, this decoupling method does
not destroy the semantics of the whole nested structure. Besides,
this method trades off the semantic granularity and deployment
cost well, since the number of data structures with different types
in the hypervisor implementation is limited (no more than dozens).
In the following, we describe each step in detail.
1) Static Analysis to Label DMA Objects. To gain awareness
of node types, we retrieve type information indicated by each DMA
Figure 5: Decouple the nested structures into independent seed queues
through DMA redirection with type constraints.
operation at the code level. Typically, the object transferred by
pci_dma_read is uncertain since one function call may serve for
different types of objects (when wrapped into an internal function),
which requires an accurate type indication for each DMA opera-
tion. Therefore, we define a DMA object as a host’s structure that
holds the copy of the guest’s data through DMA. Each DMA object
represents a unique type of node. Aiming to label all the DMA
objects, V-Shuttle performs static analysis on the hypervisor’s
source code. In particular, V-Shuttle utilizes a live-variable analy-
sis, which is a special type of data flow analysis. Considering the
host’s buffer field of DMA operations (e.g., pci_dma_read, and its
wrapped function) as the source, we do the backward data flow
analysis from the source to its declaration or definition (the DMA
object). After collecting all the DMA objects, we assign unique IDs
to each of them. These labeled objects help us identify the node
type of each DMA request at runtime and ensure that each type of
DMA object can be correctly grouped.
2) DMA Redirection with Type Constraints. Given the la-
beled objects, V-Shuttle now understands the specific type of
node required when performing DMA transfer in the fuzzing itera-
tion. Based on the previous DMA redirection, V-Shuttle introduces
additional type constraints when converting the DMA transferring
to reading from fuzzed input. Listing 2 summarizes the simplified
code of the DMA redirection with type constraints. With additional
type constraints, V-Shuttle ensures that each memory read will
be constrained to fetch data from the specific seed queue according
to the node type (rather than an ordered DMA sequence). In this
manner, V-Shuttle decouples the nested structures into individual
nodes, and clusters those into categories based on the node type,
as shown in Figure 5.
3) Seedpool-Based Fuzzer Design. Aiming to handle multi-
object inputs (more than a single file input), we extend the AFL to
support multiple seed queues in parallel. We call these multiple par-
allel queues as seedpool. This allows the fuzzer to perform mutations
on each seed queue individually for each type of program input.
With coverage feedback, the fuzzing engine can quickly pick up on
the device’s structure and patterns, learning how to generate inputs
tailored specifically to each type of object. Even if the program
attempts to take different types of data as the input dynamically
in the execution flow, it is feasible for the fuzzer to provide the
semantically valid inputs from the corresponding seed queues.
This seedpool-based method reuses existing coverage-guided
fuzzing algorithms and introduces parallelism. All basic seed queues
Device EmulatorsGuest MemoryFuzzed InputDATA1HypervisorDMA1DATA2DATAnDMA2DMAnDMASession 7B: Fuzzing CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2203are treated equally, independent of each other, and adopt the same
mutation strategy (deterministic stage, havoc stage, etc.). Besides,
all basic queues share a global coverage map, in which any inter-
esting seed that exhibits a new branch will be added to its belong-
ing seed queue. Based on this separate organization, each seed
queue will finally evolve its own pattern that favors the input with
the corresponding type, utilizing the self-learning ability of the
coverage-guided fuzzer.
last_td with
with
4) Semantics-aware Fuzzing Process. Combining runtime
type awareness and seedpool-based fuzzing engine, V-SHUTTLE
performs semantics-aware fuzzing to the hypervisor. The fuzzing
process runs in a typical client-server model, where V-Shuttle
(server) handles incoming DMA requests from the target hypervisor
(client). The main fuzzing loop is as presented in algorithm 1 in
Appendix, which has four main steps: (1) V-Shuttle establishes
all the basic seed queue and initializes the global coverage map, as
in lines 2-5 of algorithm 1. (2) V-Shuttle repeatedly blocks to wait
for the DMA requests from the target hypervisor, which indicates
the type of required data. (3) V-Shuttle selects seed from the cor-
responding seed queue and mutates it to generate a new candidate
seed. (4) V-Shuttle feeds the target program with the new candi-
date seed and tracks the coverage information. If the candidate seed
explores new coverage, it will be regarded as an interesting seed
and pushed into its belonging seed queue, as presented in lines 9-12.
This method renders each basic seed queue learning from scratch to
generate its own type of interesting seeds. After convergence of this
algorithm, we typically obtain semantics-valid input for each type
of DMA object and thus enhance the overall efficiency of fuzzing.
In the reproducing stage, V-Shuttle automatically recovers the
connections between the seeds from different seed pools by keep-
ing a reference from the currently accessed seed to the previously
accessed seed, so as to produce reliable and reproducible crashes.
Example: Semantics-Aware Fuzzing in USB-UHCI. Fig-
ure 9 we present in Appendix shows the semantics-aware
fuzzing in USB-UHCI in detail. As a first step, we list three
DMA objects (qh, td, and last_td) we found by live-variable
analysis. Specifically, since qh holds the user-supplied buffer
through pci_dma_read in uhci_process_frame, we replace
for
the pci_dma_read(&qh,sizeof(qh)) that
the
serves
object qh with pci_dma_read(&qh,sizeof(qh),1).
In ad-
dition, since td and last_td hold the user-supplied buffer
through pci_dma_read
(pci_dma_read
here serves for multiple objects in a wrapped function), we
replace the function call uhci_read_td(&td) that serves
for the object td with uhci_read_td(&td,2), replace the
function call uhci_read_td(&td) that serves for
the ob-
ject
replace
and
pci_dma_read(td,sizeof(*td))
pci_dma_read(td,
sizeof(*td),id). In this way, these three kinds of objects
represent nodes with different semantics in the nested structures.
Then guided by the type information, V-Shuttle performs
DMA redirection with ID constraints, and dynamically maintains
three seed queues that target qh, td and last_td. Each time the
hypervisor requests a kind of DMA object, the ID is sent to the
fuzzer through the UNIX pipe as guidance information, with
which V-Shuttle takes the corresponding seed from the fuzzed
uhci_read_td(&td,3),
in uhci_read_td
inputs. With the coverage feedback, each basic seed queue tends to
produce semantics-valid inputs for each of the three DMA objects.
3.5 Lightweight Fuzzing Loop
Figure 6: V-Shuttle’s fuzzing loop.
Previous work on hypervisor fuzzing usually used some kind
of agent running in the guest OS [13, 20, 31, 50, 58]. There are
some limitations to this method. (1) This degrades performance
due to the frequent use of VM-exit. Whenever the guest VM needs
to access the hardware, it triggers a trap that causes a VM-exit in
the host kernel. Then the VM-exit transfers the control back to the
hypervisor, which emulates the privileged operation on behalf of
the VM. This shows that every access request in the guest system
results in a “heavy-weight exit” to the hypervisor. (2) This increases
the complexity of implementation and communication instability,
as it requires establishing a communication channel between host
and guest for transmitting fuzzed instructions.
Environment Main Function Model. V-Shuttle utilizes a
lightweight design to drive the fuzzing loop. Distinct from previous
approaches, V-Shuttle integrates the fuzzing agent into the hyper-
visor instead of running it in guest OS (Section 3.2). The hypervisor
is an event-based system. The control flow is driven by events from
guest OS. Therefore, V-Shuttle constructs an environment main
function to serve as a fuzzing entry point (fuzzing harness [17, 35]).
The whole environment model is shown in Figure 6. V-Shuttle
hooks hypervisor’s API used to initialize MMIO/PIO regions. When
the device is initialized during the VM booting, V-Shuttle retrieves
MMIO/PIO operation(read/write) callbacks ①. We regard them as
fuzzing entry points, as MMIO and PIO are the main entry for driv-
ing the interaction with hardware (as described in Section 2.2), with
which V-SHUTTLE drives the fuzzing loop interacting between
the fuzzer and the device ②. During the fuzzing loop, V-Shuttle
explicitly invokes the I/O callbacks using fuzzer-generated data
③. Afterward, the device emulator processes the I/O requests and
performs transactions ④. Finally, the fuzzing process loops back to
the start, repeating the above steps ⑤. Hence, as both the fuzzer
and the fuzzing agent run in one host system, sharing input files
and coverage bitmap between them is straightforward. This design
choice makes V-Shuttle lightweight, driver-free, and easily im-
plemented. Because taking device operation callbacks as specific
fuzzing entry points can avoid VM-exit, which lowers the perfor-
mance cost. Meanwhile, when applying fuzzing to a new device,
V-Shuttle would automatically set up the fuzzing requirements
via the above methods without additional human resources.
4 IMPLEMENTATION
We implement live variables dataflow analysis (described in Sec-
tion 3.4 - (1)) based on CodeQL [6] static analysis platform. We use
American Fuzzy Lop (AFL) version 2.52b for fuzzing [5].
Device InstanceInitializationMMIO/PIO Callbacks③Invoke Device Callbacks explicitly④TransactionProcessed①Retrieve MMIO/PIO Operation Callbacks②Start Fuzzing                Fuzzing EntrySetupMain Fuzzing Loop⑤RepeatperiodicallySession 7B: Fuzzing CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2204Hypervisor Instrumentation. To apply coverage-guided
fuzzing, we selectively instrument device-related code in the hy-
pervisor to gain feedback information, using AFL’s edge coverage
scheme. When the hypervisor starts, the instrumented code in the
target hypervisor writes the coverage feedback to the bitmap, which
is exported as a shared memory area accessible by the fuzzer com-
ponent. Note that the instrumentation is limited to device-related
code instead of the whole hypervisor for performance concern [58].
Initial Corpus Collection. To improve the fuzzing efficiency
further, we collect initial seeds of valid test cases under standard
full-system emulation, logging all accesses to the target device via
DMA and MMIO/PIO. This step is optional: one could start from
any arbitrary seed or craft test cases on their own.
5 EVALUATION
We evaluate V-Shuttle extensively on QEMU and VirtualBox,
which are two popular hypervisor platforms among the world.
Both QEMU and VirtualBox are the targets in the virtualization
category of many PWN contests, such as Pwn2Own, Driven2Pwn
and TianfuCup. We perform experiments to answer the following
research questions (RQ):
RQ1: Can V-Shuttle be scalable when fuzzing hypervisor
virtual devices?
RQ2: What is the performance of dumb fuzzing, structure-
aware fuzzing, V-Shuttle and V-Shuttle semantics-aware
mode?
RQ3: What is the performance gain of V-Shuttle compared
to the state-of-the-art hypervisor fuzzing tools such as Nyx,
Hyper-Cube and VDF?
RQ4: How is the vulnerability hunting capability of V-
Shuttle?
Our experiments are run on a machine with 2.20 GHz, 48-core
Xeon, and 256 GB RAM running Ubuntu 18.04 LTS. We targeted
QEMU 5.1.0 and VirtualBox 6.1.14, and built them with AddressSan-
itizer [53] to expose memory corruption bugs. Each experiment is
run for 24 hours and repeated for 10 times. We report their average
statistical performance [38].
5.1 Scalability
We perform large-scale experiments to demonstrate the scalability
of V-Shuttle (RQ1). We applied V-Shuttle(with semantics-aware
mode enable) to a dozen QEMU virtual devices. The code coverage
and performance overhead statistics data in Table 2 shows that
V-Shuttle can be easily configured for various virtual devices
fuzzing setup and efficiently promote the fuzzing process.
5.1.1 Code Coverage. To examine the ability of V-Shuttle, we
perform experiments in QEMU to discover code coverage in 24h
fuzzing. We used gcov to measure branch coverage. We choose 16
popular QEMU devices for evaluation. They are chosen based on
the following features: popularity in the community, development
activeness, and diversity of categories. These devices are represen-
tative on the x86 platform (including audio, graphics, network, USB,
and storage devices), which cover standard virtualization scenes
such as cloud and virtual private server (VPS) hosting and desktop
virtualization. Each device was fuzzed within a single hypervisor
instance.
Table 2 presents some insightful statistics about the line, func-
tion, and branch coverages. For branch coverage, the smallest im-
provement in the percentage of branch coverage was seen in the
AHCI virtual device (9.7% increase), and the largest improvement
in branch coverage was seen in the CS4231a virtual device (82.8%
increase). Also, the last line shows the final average coverage after
applying V-Shuttle. On average, the initial seed test cases cov-
ered 40.98% of line coverage, 58.10% of functions coverage, and
25.03% of branch coverage. By fuzzing, V-Shuttle respectively
increased their coverage to 87.95%, 89.58%, and 77.18%. V-Shuttle
further covered 46.97%, 31.48%, and 52.15% of the code, because
the hypervisor-specific solutions in V-Shuttle carry the fuzzing
exploration towards the application execution stage.
The results show that our framework can be adapted to various
types of devices, including USB, network, audio, storage, etc., which
further confirms V-Shuttle’s scalability. We emphasize that the
whole process of implementing fuzzing to each device is automatic
- no human intervention is required at any point. We attribute
this feature to our DMA redirection solutions. By redirecting data
interaction interfaces to fuzzing input, fuzzing hypervisor becomes
the same as fuzzing application, which is naturally suitable for
coverage-guided fuzzer, such as AFL, libfuzzer, etc.
However, there are still some code coverages not covered in
Table 2, mainly due to two reasons: (1) some devices are not tested
at all. (2) some code snippets can only be covered with specific
emulated architectures (Arm/PPC/MIPS etc.) and startup configu-
rations.
In summary, V-Shuttle can significantly improve the code cov-
erage as well as scalability.
5.1.2 Overhead Analysis. The last column in Table 2 presents
the number of execution per second. As expected, V-Shuttle man-
ages to achieve a throughput of 6110.23 executions per second on
average, since we use a very lightweight design without fork() or
restarting of the hypervisor. Besides, as we integrate the fuzzing
agent into the hypervisor instead of running it in guest OS, the
fuzzer spends negligible time on data interaction. This design choice
makes V-Shuttle comparable to traditional application fuzzing.
We demonstrate that our framework offers a significant advantage
over other designs where the fuzzer runs in a kernel module. For
comparison, we’ve also evaluated the throughput of dumb fuzzing
as our baseline, which simply writes a bunch of random data into
basic interfaces (MMIO, DMA) without the knowledge about the
nested DMA structures. The results in Table 2 show our semantics-
aware DMA redirection fuzzing approach is comparable to dumb
fuzzing on the same machine and workload.
5.2 Effectiveness
To validate the effectiveness of V-Shuttle main framework and
the semantics-aware fuzzing mode, we evaluate V-Shuttle-M (dis-
abling the semantics-aware fuzzing mode) and V-Shuttle-S (en-
abling semantics-aware fuzzing mode) for comparison. We then
implement a dumb fuzzing as our baseline, which has no knowledge
of the DMA data and its deep nested characteristics (like VDF), and
randomly mutates 𝑘 bits of inputs to the basic interfaces (MMIO,
Session 7B: Fuzzing CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2205Table 2: The line, function and branch coverage of V-Shuttle as well as the performance results on the 16 QEMU devices (24 hours each). Initial coverage
shows the percentage covered during device initialization states (i.e., BIOS and the guest kernel initialization of the device). Total coverage shows the
percentage covered after 24 hours of fuzzing.
Device
CS4231a
Intel-HDA
ES1370
SoundBlaster
Audio
Graphics
ATI-VGA
E1000
NE2000
PCNET
RTL8139
UHCI
EHCI