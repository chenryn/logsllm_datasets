i], c(cid:48)) that is random from the receiver’s point of view.
i PRF(m[i, c(cid:48)
and send this circuit to the ideal functionality.
The cost of this protocol is σ instances of OT per oblivious encoding. Since the protocol uses
OTs with chosen secrets (not random secrets chosen by the functionality), it can be instantiated
in the standard model.1
5 A Warmup: Quadratic-Cost PSI
The main technical idea for achieving malicious security is to carefully apply the dual execution
paradigm of Mohassel & Franklin [MF06] to the PSZ paradigm for private set intersection. In this
section we give a protocol which contains the main ideas of our approach, but which has quadratic
complexity. In the next section we describe how to apply a hashing technique to reduce the cost.
5.1 Dual Execution Protocol
The main idea behind our approach is as follows (a formal description is given in Figure 3):
detail, the parties invoke Fencode once for each of Alice’s items. Alice learns(cid:74)xj(cid:75)B
is her jth item and(cid:74)·(cid:75)B
can obtain(cid:74)v(cid:75)B
2. The parties do the same thing with the roles reversed. Bob learns(cid:74)yi(cid:75)A
item and(cid:74)·(cid:75)A
1. The parties perform an encoding step similar to PSZ, where Alice acts as receiver. In more
j , where xj
j is the encoding used in the jth instance of Fencode. Note that Bob
is the encoding. As above, Alice can obtain any encoding of the form(cid:74)v(cid:75)A
j for any v and any j, by appropriately querying the functionality.
i , where yi is his ith
j .
i
At this point, let us deﬁne a common encoding:
(cid:74)v(cid:75)i,j
def= (cid:74)v(cid:75)A
i ⊕(cid:74)v(cid:75)B
j
The important property of this encoding is:
j then she can compute the common encoding(cid:74)v(cid:75)i,j for any i.
• If Alice knows(cid:74)v(cid:75)B
• If Alice does not know(cid:74)v(cid:75)B
hard for her to predict common encoding(cid:74)v(cid:75)i,j for any i.
j , then it is actually random from her point of view. It is therefore
A symmetric condition holds for Bob. Now the idea is for the parties to compute all of the common
encodings that they can deduce from these rules. Then the intersection of these encodings will
correspond to the intersection of their sets. In other words (continuing the protocol overview):
3. Alice computes a set of encodings E = {(cid:74)xj(cid:75)i,j | i, j ∈ [n]}, and sends it to Bob.
1Modern OT extension protocols can be optimized for OT of random secrets, but it is not known how to make
this special case less expensive while avoiding the programmable-random-oracle model.
7
4. Bob likewise computes a set of encodings and checks which of them appear in E. These
encodings correspond to the intersection. More formally, Bob outputs:
Z = {yi ∈ Y | ∃j ∈ [n] :(cid:74)yi(cid:75)i,j ∈ E}
We note that in this protocol, only Bob receives output. In fact, it turns out to be problematic
if Bob sends an analogous set of encodings to Alice. In Section 6.7 we discuss in more detail the
problems associated with both parties receiving output.
5.2 Security
The protocol achieves malicious security:
Theorem 1. The protocol in Figure 3 is a UC-secure protocol for PSI in the Fencode-hybrid model.
learns(cid:74)xj(cid:75)B
We defer giving a formal proof for this protocol in favor of a single proof of our ﬁnal protocol
in the next section. Instead, we sketch the high-level idea of the simulation.
When Alice is corrupt, the simulator plays the role of Fencode and therefore observes Alice’s
inputs to the functionality during Step 2. Let xj denote Alice’s jth input to Fencode, in which she
j . Let ˜X = {x1, . . . , xn}. We can make the following observations:
• Suppose Bob has an item y (cid:54)∈ ˜X. In the protocol, Alice will send a set of encodings E, and
Bob will search this set for encodings(cid:74)y(cid:75)i,j, for certain i, j values. But by the deﬁnition of
˜X, Alice does not know any encoding of the form(cid:74)y(cid:75)B
j , and so with high probability cannot
guess any encoding which will cause Bob to include y in the output. In other words, we can
argue that Alice’s eﬀective input is a subset of ˜X.
• Suppose for simplicity Bob’s input happens to be ˜X. This turns out to be the most interesting
case for the proof. Bob will randomly permute these items and obtain an encoding of each
π(j). Now Bob will be looking in the
one. Let π be the permutation such that Bob learns(cid:74)xj(cid:75)A
set E for common encodings of the form(cid:74)xj(cid:75)π(j),∗. Note that from the deﬁnition of ˜X, Alice
can only produce valid encodings of the form (cid:74)xj(cid:75)∗,j. It follows that Bob will include a
value xj in his output if and only if Alice includes encoding (cid:74)xj(cid:75)π(j),j ∈ E.
simulator chooses a random π and sets X∗ = {xj |(cid:74)xj(cid:75)π(j),j ∈ E}. It is this X∗ that the simulator
Since the distribution of π is random, the simulator can simulate the eﬀect. More precisely, the
ﬁnally sends to the ideal functionality. In the above, we were considering a special case where Bob’s
input happens to be ˜X. However, this simulation approach works in general.
The simulation for a malicious Bob is simpler, and it relies on the fact that common encodings
look random, for values not in the intersection.
The protocol is correct as long as there are no spurious collisions among common encodings.
That is, we do not have any xj ∈ X and yi ∈ Y \ X for which(cid:74)xj(cid:75)i,j =(cid:74)yi(cid:75)i,j (which would cause
Bob to erroneously place yi in the intersection). The probability of this happening for a ﬁxed xj, yi
is 2−(cid:96), if the encodings have length (cid:96). By a union bound, the total probability of such an event is
n22−(cid:96). We set (cid:96) = λ + 2 log n to ensure this error probability is at most 2−λ.
5.3 Encode-Commit Protocol
In addition to the approach described above, we present an alternative protocol based on Fencode and
1 , ...,(cid:74)xn(cid:75)B
commitments that oﬀers communication/computation trade-oﬀs. Fundamentally, the dual execu-
n}.
tion protocol above ﬁrst restricts Alice to her set by requiring her to encode it as {(cid:74)x1(cid:75)B
8
Parameters: Fencode is the Oblivious Encoding functionality with input domain {0, 1}σ output
bit length λ + 2 log n.
On Input (Send, sid, X) from Alice and (Receive, sid, Y ) from Bob, where X, Y ⊆ {0, 1}σ
and |X| = |Y | = n. Each party randomly permutes their set.
1. [A Encoding] For i ∈ [n], Bob sends (Encode, (sid, A, i), yi) to Fencode who sends
i ) to Bob and (Output, (sid, A, i)) to Alice.
sends
(Encode, (sid, A, i), xj)
to Fencode and receives
i ) in response.
2. [B Encoding] For i ∈ [n], Alice sends (Encode, (sid, B, i), xi) to Fencode who sends
∈ [n], Bob sends
j
(Encode, (sid, B, i), yj)
to Fencode and receives
i ) to Alice and (Output, (sid, B, i)) to Bob.
3. [Output] Alice sends the common encodings
i ) in response.
For
j ∈ [n], Alice
(Output, (sid, A, i),(cid:74)yi(cid:75)A
(Output, (sid, A, i),(cid:74)xj(cid:75)A
(Output, (sid, B, i),(cid:74)xi(cid:75)B
(Output, (sid, B, i),(cid:74)yj(cid:75)B
For
to Bob who outputs
E = {(cid:74)xj(cid:75)A
i ⊕(cid:74)xj(cid:75)B
j | i, j ∈ [n]}
i ⊕(cid:74)yi(cid:75)B
{yi | ∃j :(cid:74)yi(cid:75)A
j ∈ E}
Figure 3: Malicious-secure n2 PSI.
In some sense this encoding operation can be viewed as Alice committing to her inputs. The prop-
erty that we need from the B encoding are: 1) (cid:74)∗(cid:75)B must allow the simulator to extract the set
of candidate xj values; 2) provides a binding proof to the value xj. Continuing to view(cid:74)∗(cid:75)B as a
to xj) to these values by sending all(cid:74)xj(cid:75)B
commitment, the dual execution protocol instructs Alice to then decommit (prove she was bound
i so that the
j encodings to Bob, but masked under(cid:74)xj(cid:75)A
commitment can only be “decommitted” if Bob knows one of these encodings of xj.
Taking this idea to its conclusion, we can formulate a new protocol where Alice simply commits
to her inputs by sending Comm(x1; r1), ..., Comm(xn; rn) to Bob in lieu of Figure 3 Step 2, where
Comm is a standard (non-interactive) commitment scheme. The ﬁnal step of the protocol is for
her to send the decommitment rj masked under the encodings of xj
(cid:110)(cid:74)xj(cid:75)A
E =
i ⊕ rj | i, j ∈ [n]
(cid:111)
In the event that Bob knows(cid:74)xj(cid:75)A
i , i.e. his input contains yi = xj, he will be able to recover the
decommitment value rj and decommit Comm(xj; rj), thereby inferring that xj is in the intersection.
The security proof of this protocol follows the same structure as before. For the more interesting
case of a malicious Alice, we require an extractable commitment scheme. The simulator is able
to extract the set ˜X = {x1, ..., xn} from the commitments Comm(x1; r1), ..., Comm(xn; rn) and
π(j) ⊕ rj ∈ E} to the functionality. The correctness of this simulation
strategy follows from the sketch in the previous section by viewing Comm(xj; rj) as equivalent to
sends X∗ = {xj | (cid:74)xj(cid:75)A
the encoding(cid:74)∗(cid:75)B
j and rj as equivalent to(cid:74)xj(cid:75)B
j .
The communication and computation complexity for both of these protocols is O(n2). However,
we will later show that the concrete communication/computation overheads of these two approaches
9
result in interesting performance trade-oﬀs. Most notable is that the commitment based approach
requires less computation at the expense of additional communication, making it more eﬃcient in
the LAN setting.
6 Our Full Protocol
After constructing a quadratic-cost PSI protocol, the PSZ paradigm is for the parties to use a
hashing scheme to assign their items into bins, and then perform the quadratic-cost PSI on each
bin. We review this approach here, and discuss challenges speciﬁc to the malicious setting.
6.1 Hashing
Cuckoo hashing and its drawbacks. The most eﬃcient hashing scheme in PSZ is Cuckoo
hashing. In this approach, the parties agree on two (or more) random functions h1 and h2. Alice
uses Cuckoo hashing to map her items into bins. As a result, each item x is placed in either bin
B[h1(x)] or B[h2(x)] such that each bin has at most one item. Bob conceptually places each of his
items y into both bins B[h1(y)] or B[h2(y)]. Then the parties perform a PSI for the items in each
bin. Since Alice has only one item per bin, these PSIs are quite eﬃcient.
Unfortunately, this general hashing approach does not immediately work in the malicious se-
curity setting. Roughly speaking, the problem is that Bob may place an item y into bin B[h1(y)]
but not in B[h2(y)]. Suppose Alice also has item y, then y will appear in the output if and only if
Alice’s cuckoo hashing has chosen to place it in B[h1(y)] and not B[h2(y)]. Because of the nature
of Cuckoo hashing, whether an item is placed according to h1 or h2 event depends in a subtle way
on all other items in Alice’s set. As a result, the eﬀect of Bob’s misbehavior cannot be simulated
in the ideal world.
Simple hashing. While Cuckoo hashing is problematic for malicious security, we can still use
a simple hashing approach. The parties agree on a random function h : {0, 1}∗ → [m] and assign
item x to bin B[h(x)]. Then parties can perform a PSI for each bin. Note that under this hashing
scheme, the hashed location of each item does not depend on other items in the set. Each item has
only one “correct” location.
Note that the load (number of items assigned) of any bin leaks some information about a party’s
input set. Therefore, all bins must be padded to some maximum possible size. A standard balls-
and-bins argument shows that the maximum load among the m = O(n/ log n) bins is O(log n) with
very high probability.
Phasing.
In the standard-model variant of our protocol, the oblivious encoding step scales linearly
with the length of the items being encoded. Our random-oracle protocol also has a weak dependence
on the representation length of the items which is aﬀected by the size of the sets. Hence, it is
desirable to reduce the length of these items as much as possible.
Pinkas et al. [PSSZ15] described how to use a hashing technique of Arbitman et al. [ANS10]
called phasing (permutation-based hashing) to reduce the length of items in each bin. The idea is
as follows. Suppose we are considering PSI on strings of length σ bits. Let h be a random function
with output range {0, 1}d, where the number of bins is 2d. To assign an item x to a bin, we write
x = xL(cid:107)xR, with |xL| = d. We assign this item to bin h(xR) ⊕ xL, and store it in that bin with xR
as its representation. Arbitman et al. [ANS10] show that this method of assigning items to bins
results in maximum load O(log n) with high probability.
10
Note that the representations in each bin are σ − d bits long — shorter by d bits. Importantly,
shrinking these representations does not introduce any collisions. This is because the mapping
phase(xL(cid:107)xR) = (h(xR) ⊕ xL, xR) is a Feistel function and therefore invertible. So distinct items
will either be mapped to distinct bins, or, in the case that they are mapped to the same bin, they
must be assigned diﬀerent representations. Hence the PSI subprotocol in each bin can be performed
on the shorter representations.
The idea can be extended as follows, when the number m of bins is not a power of two (here h
is taken to be a function with range [m]):
(cid:16)
h((cid:98)x/m(cid:99)) + x mod m, (cid:98)x/m(cid:99)(cid:17)
phaseh,m(x) =
phase−1
h,m(b, z) = zm + [h(z) + b mod m]
We show that phasing is a secure way to reduce the length of items, in the presence of malicious
adversaries.
6.2 Aggregating Masks Across Bins
Suppose we apply the simple hashing technique to our quadratic PSI protocol. The resulting
protocol would work as follows.
1. First, the parties hash their n items into m = O(n/ log n) bins. With high probability each
bin has at most µ = O(log n) items. Bins are artiﬁcially padded with dummy items to a ﬁxed
size of µ items.
2. For each bin the parties perform the quadratic-cost PSI protocol from Section 5. Each party
acts as Fencode sender and receiver, and computes common encodings of the items. For each
bin, Alice sends all µ2 = O(log2 n) encodings to Bob, who computes the intersection.
The total cost of this protocol is therefore mµ2 = O(n log n), a signiﬁcant improvement over the
quadratic protocol.
We present an additional optimization which reduces the cost by a signiﬁcant constant factor.
Our primary observation is that in order to hide the number of items in each bin, the parties must
pad the bins out to the maximum size µ. However, this results in their bins containing mostly
dummy items (in our range of parameters, around 75% are dummy items).
When Alice sends her common encodings in the ﬁnal step of the protocol, she knows that the
encodings for dummy items cannot contribute to the ﬁnal result. If she had a way to avoid sending
these dummy encodings, it would reduce the number of encodings sent by roughly a factor of 4.
Hence, we suggest an optimization in which Alice aggregates her encodings across all the bins,
and send only the non-dummy encodings to Bob, as a uniﬁed collection. Similarly, Bob need not
check Alice’s set of encodings for one of his dummy encodings. So Bob computes common encodings
only for his actual input items.
To show the security of this change, we need only consider Bob’s view which has been slightly
altered. Suppose Alice chooses a random value d to be a “universal” dummy item in each bin.
Since this item is chosen randomly, it is negligibly likely that Bob would have used it as input to
any instance of Fencode where he was the receiver. Hence, the common encodings of dummy values
look random from Bob’s perspective. Intuitively, the only common encodings we removed from
the protocol are ones that looked random from Bob’s perspective (and hence, had no eﬀect on his
output, with overwhelming probability).
Note that it is not secure to eliminate dummy encodings within a single quadratic-PSI. This
would leak how many items Alice assigned to that bin. It is not secure to leak the number of items
11
Parameters: X is Alice’s input, Y is Bob’s input, where X, Y ⊆ {0, 1}σ. m is the number of bins and
µ is a bound on the number of items per bin. The protocol uses instances of Fencode with input length
σ − log n, and output length λ + 2 log(nµ), where λ is the security parameter.
1. [Parameters] Parties agree on a random hash function h : {0, 1}σ → [m] using a coin tossing
protocol.
2. [Hashing]
(a) For x ∈ X, Alice computes (b, x(cid:48)) = phaseh,m(x) and adds x(cid:48) to bin BX [b] at a random
(b) For y ∈ Y , Bob computes (b, y(cid:48)) = phaseh,m(y) and adds y(cid:48) to bin BY [b] at a random unused
unused position p ∈ [µ].
position p ∈ [µ].
Both parties ﬁll unused bin positions with the zero string.
3. [Encoding] For bin index b ∈ [m] and position p ∈ [µ]:
(Output, (sid, B, b, p)) from Fencode.
(a) Let x(cid:48) be the value in bin BX [b] at position p. Alice sends (Encode, (sid, B, b, p), x(cid:48)) to
b,p). Bob receives
(b) Let y(cid:48) be the value in bin BY [b] at position p. Bob sends (Encode, (sid, A, b, p), y(cid:48)) to
b,p). Alice receives
the Fencode functionality which responds with (Output, (sid, B, b, p),(cid:74)x(cid:48)(cid:75)B
the Fencode functionality which responds with (Output, (sid, A, b, p),(cid:74)y(cid:48)(cid:75)A
(Output, (sid, A, b, p)) from Fencode.
4. [Output]
(a) [Alice’s Common Mask] For each x ∈ X, in random order, let b, p be the bin index
and position that x(cid:48) was placed in during Step 2a to represent x. For j ∈ [µ], Alice sends