title:Ethane: taking control of the enterprise
author:Mart&apos;ın Casado and
Michael J. Freedman and
Justin Pettit and
Jianying Luo and
Nick McKeown and
Scott Shenker
Ethane: Taking Control of the Enterprise
Martìn Casado, Michael J. Freedman,
Justin Pettit, Jianying Luo,
and Nick McKeown
Stanford University
Scott Shenker
U.C. Berkeley and ICSI
ABSTRACT
This paper presents Ethane, a new network architecture for the
enterprise. Ethane allows managers to deﬁne a single network-
wide ﬁne-grain policy, and then enforces it directly. Ethane cou-
ples extremely simple ﬂow-based Ethernet switches with a central-
ized controller that manages the admittance and routing of ﬂows.
While radical, this design is backwards-compatible with existing
hosts and switches.
We have implemented Ethane in both hardware and software,
supporting both wired and wireless hosts. Our operational Ethane
network has supported over 300 hosts for the past four months in
in Stanford University’s network, and this deployment experience
has signiﬁcantly affected Ethane’s design.
Categories and Subject Descriptors
C.2.6 [Computer Communication Networks]: Internetworking;
C.2.1 [Computer Communication Networks]: Network Archi-
tecture and Design
General Terms
Design, Experimentation, Performance
Keywords
Network, Architecture, Security, Management
1.
INTRODUCTION
Enterprise networks are often large, run a wide variety of appli-
cations and protocols, and typically operate under strict reliability
and security constraints; thus, they represent a challenging envi-
ronment for network management. The stakes are high, as busi-
ness productivity can be severely hampered by network misconﬁg-
urations or break-ins. Yet the current solutions are weak, making
enterprise network management both expensive and error-prone.
Indeed, most networks today require substantial manual conﬁgura-
tion by trained operators [11, 22, 23, 25] to achieve even moderate
security [24]. A Yankee Group report found that 62% of network
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’07, August 27–31, 2007, Kyoto, Japan.
Copyright 2007 ACM 978-1-59593-713-1/07/0008 ...$5.00.
downtime in multi-vendor networks comes from human-error and
that 80% of IT budgets is spent on maintenance and operations [16].
There have been many attempts to make networks more manage-
able and more secure. One approach introduces proprietary middle-
boxes that can exert their control effectively only if placed at net-
work choke-points. If trafﬁc accidentally ﬂows (or is maliciously
diverted) around the middlebox, the network is no longer managed
nor secure [25]. Another approach is to add functionality to ex-
isting networks—to provide tools for diagnosis, to offer controls
for VLANs, access-control lists, and ﬁlters to isolate users, to in-
strument the routing and spanning tree algorithms to support better
connectivity management, and then to collect packet traces to al-
low auditing. This can be done by adding a new layer of protocols,
scripts, and applications [1, 10] that help automate conﬁguration
management in order to reduce the risk of errors. However, these
solutions hide the complexity, not reduce it. And they have to be
constantly maintained to support the rapidly changing and often
proprietary management interfaces exported by the managed ele-
ments.
Rather than building a new layer of complexity on top of the
network, we explore the question: How could we change the en-
terprise network architecture to make it more manageable? Our
answer is embodied in the architecture we describe here, called
Ethane. Ethane is built around three fundamental principles that
we feel are important to any network management solution:
The network should be governed by policies declared over high-
level names. Networks are most easily managed in terms of the en-
tities we seek to control—such as users, hosts, and access points—
rather than in terms of low-level and often dynamically-allocated
addresses. For example, it is convenient to declare which services
a user is allowed to use and to which machines they can connect.
Policy should determine the path that packets follow. There are
several reasons for policy to dictate the paths. First, policy might
require packets to pass through an intermediate middlebox; for ex-
ample, a guest user might be required to communicate via a proxy,
or the user of an unpatched operating system might be required to
communicate via an intrusion detection system. Second, trafﬁc can
receive more appropriate service if its path is controlled; direct-
ing real-time communications over lightly loaded paths, important
communications over redundant paths, and private communications
over paths inside a trusted boundary would all lead to better ser-
vice. Allowing the network manager to determine the paths via
policy—where the policy is in terms of high-level names—leads
to ﬁner-level control and greater visibility than is easily achievable
with current designs.
The network should enforce a strong binding between a packet
and its origin. Today, it is notoriously difﬁcult to reliably deter-
mine the origin of a packet: Addresses are dynamic and change
frequently, and they are easily spoofed. The loose binding between
users and their trafﬁc is a constant target for attacks in enterprise
networks. If the network is to be governed by a policy declared
over high-level names (e.g., users and hosts) then packets should
be identiﬁable, without doubt, as coming from a particular physical
entity. This requires a strong binding between a user, the machine
they are using, and the addresses in the packets they generate. This
binding must be kept consistent at all times, by tracking users and
machines as they move.
To achieve these aims, we followed the lead of the 4D project [14]
and adopted a centralized control architecture. Centralized solu-
tions are normally an anathema for networking researchers, but we
feel it is the proper approach for enterprise management. IP’s best-
effort service model is both simple and unchanging, well-suited for
distributed algorithms. Network management is quite the opposite;
its requirements are complex and require strong consistency, mak-
ing it quite hard to compute in a distributed manner.
There are many standard objections to centralized approaches,
such as resilience and scalability. However, as we discuss later in
the paper, our results suggest that standard replication techniques
can provide excellent resilience, and current CPU speeds make it
possible to manage all control functions on a sizable network (e.g.,
25,000 hosts) from a single commodity PC.
Ethane bears substantial resemblance to SANE, our recently-
proposed clean-slate approach to enterprise security [12]. SANE
was, as are many clean-slate designs, difﬁcult to deploy and largely
untested. While SANE contained many valuable insights, Ethane
extends this previous work in three main ways:
Security follows management. Enterprise security is, in many
ways, a subset of network management. Both require a network
policy, the ability to control connectivity, and the means to observe
network trafﬁc. Network management wants these features so as to
control and isolate resources, and then to diagnose and ﬁx errors,
whereas network security seeks to control who is allowed to talk to
whom, and then to catch bad behavior before it propagates. When
designing Ethane, we decided that a broad approach to network
management would also work well for network security.
Incremental deployability. SANE required a “fork-lift" replace-
ment of an enterprise’s entire networking infrastructure and changes
to all the end-hosts. While this might be suitable in some cases, it is
clearly a signiﬁcant impediment to widespread adoption. Ethane is
designed so that it can be incrementally deployed within an en-
terprise:
it does not require any host modiﬁcations, and Ethane
Switches can be incrementally deployed alongside existing Ether-
net switches.
Signiﬁcant deployment experience. Ethane has been implemented
in both software and hardware (special-purpose Gigabit Ethernet
switches) and deployed at Stanford’s Computer Science department
for over four months and managed over 300 hosts. This deployment
experience has given us insight into the operational issues such a
design must confront, and resulted in signiﬁcant changes and ex-
tensions to the original design.
2. OVERVIEW OF ETHANE DESIGN
Ethane controls the network by not allowing any communica-
tion between end-hosts without explicit permission. It imposes this
requirement through two main components. The ﬁrst is a central
Controller containing the global network policy that determines the
fate of all packets. When a packet arrives at the Controller—how
it does so is described below—the Controller decides whether the
ﬂow represented by that packet1 should be allowed. The Controller
knows the global network topology and performs route computa-
tion for permitted ﬂows.
It grants access by explicitly enabling
ﬂows within the network switches along the chosen route. The
Controller can be replicated for redundancy and performance.
The second component is a set of Ethane Switches.
In con-
trast to the omniscient Controller, these Switches are simple and
dumb. Consisting of a simple ﬂow table and a secure channel to
the Controller, Switches simply forward packets under the direc-
tion of the Controller. When a packet arrives that is not in the ﬂow
table, they forward that packet to the Controller (in a manner we
describe later), along with information about which port the packet
arrived on. When a packet arrives that is in the ﬂow table, it is for-
warded according to the Controller’s directive. Not every switch
in an Ethane network needs to be an Ethane Switch: Our design
allows Switches to be added gradually, and the network becomes
more manageable with each additional Switch.
2.1 Names, Bindings, and Policy Language
When the Controller checks a packet against the global policy,
it is evaluating the packet against a set of simple rules, such as
“Guests can communicate using HTTP, but only via a web proxy”
or “VoIP phones are not allowed to communicate with laptops.” If
we want the global policy to be speciﬁed in terms of such physical
entities, we need to reliably and securely associate a packet with the
user, group, or machine that sent it. If the mappings between ma-
chine names and IP addresses (DNS) or between IP addresses and
MAC addresses (ARP and DHCP) are handled elsewhere and are
unauthenticated, then we cannot possibly tell who sent the packet,
even if the user authenticates with the network. This is a notorious
and widespread weakness in current networks.
With (logical) centralization, it is simple to keep the namespace
consistent as components join, leave and move around the network.
Network state changes simply require updating the bindings at the
Controller. This is in contrast to today’s network where there are no
widely used protocols for keeping this information consistent. Fur-
ther, distributing the namespace among all switches would greatly
increase the trusted computing base and require high overheads to
maintain consistency on each bind event.
In Ethane, we also use a sequence of techniques to secure the
bindings between packet headers and the physical entities that sent
them. First, Ethane takes over all the binding of addresses. When
machines use DHCP to request an IP address, Ethane assigns it
knowing to which switch port the machine is connected, enabling
Ethane to attribute an arriving packet to a physical port.2 Second,
the packet must come from a machine that is registered on the net-
work, thus attributing it to a particular machine. Finally, users are
required to authenticate themselves with the network—for exam-
In this paper, we describe our experiences designing, implement-
ing, and deploying Ethane. We begin with a high-level overview of
the Ethane design in §2, followed by a detailed description in §3. In
§4, we describe a policy language Pol-Eth that we built to manage
our Ethane implementation. We then discuss our implementation
and deployment experience (§5), followed by performance analy-
sis (§6). Finally we present limitations (§7), discuss related work
(§8), and then conclude (§9).
1All policies considered in Ethane are based over ﬂows, where the
header ﬁelds used to deﬁne a ﬂow are based on the packet type (for
example, TCP/UDP ﬂows include the Ethernet, IP and transport
headers). Thus, only a single policy decision need be made for
each such “ﬂow”.
2As we discuss later, a primary advantage of knowing the ingress
port of a packet is that it allows the Controller to apply ﬁlters to the
ﬁrst-hop switch used by unwanted trafﬁc.
Figure 1: Example of communication on an Ethane network.
Route setup shown by dotted lines; the path taken by the ﬁrst
packet of a ﬂow shown by dashed lines.
ple, via HTTP redirects in a manner similar to those used by com-
mercial WiFi hotspots—binding users to hosts. Therefore, when-
ever a packet arrives at the Controller, it can securely associate the
packet to the particular user and host that sent it.
There are several powerful consequences of the Controller know-
ing both where users and machines are attached and all bindings
associated with them. First, the Controller can keep track of where
any entity is located: When it moves, the Controller ﬁnds out as
soon as packets start to arrive from a different Switch port. The
Controller can choose to allow the new ﬂow or it might choose to
deny the moved ﬂow (e.g., to restrict mobility for a VoIP phone
due to E911 regulations). Another powerful consequence is that
the Controller can journal all bindings and ﬂow-entries in a log.
Later, if needed, the Controller can reconstruct all network events;
e.g., which machines tried to communicate or which user commu-
nicated with a service. This can make it possible to diagnose a
network fault or to perform auditing or forensics, long after the
bindings have changed.
In principle, Ethane does not mandate the use of a particular pol-
icy language. For completeness, however, we have designed and
deployed Pol-Eth, in which policies are declared as a set of rules
consisting of predicates and, for matching ﬂows, the set of result-
ing actions (e.g., allow, deny, or route via a waypoint). As we will
see, Pol-Eth’s small set of easily understood rules can still express
powerful and ﬂexible policies for large, complex networks.
2.2 Ethane in Use
Putting all these pieces together, we now consider the ﬁve basic
activities that deﬁne how an Ethane network works, using Figure 1
to illustrate:
Registration. All Switches, users, and hosts are registered at the
Controller with the credentials necessary to authenticate them. The
credentials depend on the authentication mechanisms in use. For
example, hosts may be authenticated by their MAC addresses, users
via username and password, and switches through secure certiﬁ-
cates. All switches are also preconﬁgured with the credentials needed
to authenticate the Controller (e.g., the Controller’s public key).
Bootstrapping. Switches bootstrap connectivity by creating a span-
ning tree rooted at the Controller. As the spanning tree is being
created, each switch authenticates with and creates a secure chan-
nel to the Controller. Once a secure connection is established, the
switches send link-state information to the Controller, which ag-
gregates this information to reconstruct the network topology.
Authentication.
1. UserA joins the network with hostA. Because no ﬂow entries
exist in switch 1 for the new host, it will initially forward all
Figure 2: An example Ethane deployment.
of hostA’s packets to the Controller (marked with switch 1’s
ingress port).
2. HostA sends a DHCP request to the Controller. After check-
ing hostA’s MAC address,3 the Controller allocates an IP ad-
dress (IPA) for it, binding hostA to IPA, IPA to MACA, and
MACA to a physical port on switch 1.
3. UserA opens a web browser, whose trafﬁc is directed to the
Controller, and authenticates through a web-form. Once au-
thenticated, userA is bound to hostA.
Flow Setup.
1. UserA initiates a connection to userB (who we assume has
already authenticated in a manner similar to userA). Switch
1 forwards the packet to the Controller after determining that
the packet does not match any active entries in its ﬂow table.
2. On receipt of the packet, the Controller decides whether to
allow or deny the ﬂow, or require it to traverse a set of way-
points.
3. If the ﬂow is allowed, the Controller computes the ﬂow’s
route, including any policy-speciﬁed waypoints on the path.
The Controller adds a new entry to the ﬂow tables of all the
Switches along the path.
Forwarding.
1. If the Controller allowed the path, it sends the packet back
to switch 1 which forwards it based on the new ﬂow entry.
Subsequent packets from the ﬂow are forwarded directly by
the Switch, and are not sent to the Controller.
2. The ﬂow-entry is kept in the switch until it times out (due to
inactivity) or is revoked by the Controller.
3. ETHANE IN MORE DETAIL
3.1 An Ethane Network