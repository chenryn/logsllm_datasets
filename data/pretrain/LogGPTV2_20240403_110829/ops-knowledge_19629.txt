User: I am using Hadoop 2.8.0 in my Mac. I want to run all the mappers simultaneously. I tried by forcing to make more than one split of input file and using more than one input files, so that multiple mappers are created. They are created, but they run sequentially. I see in the output something like this:
starting task ****_m_0
...............
finising task ****_m_0
starting task ****_m_1
Why mappers run one after another? how can I configure so that they start at once?
Assistant: If you are running mapreduce in local mode (e.g., from eclipse), it will only run one mapper and one reducer at a time. If you are running it in distributed (or pseudo-distributed) mode (e.g., using the hadoop command from the terminal, it can run with more mappers. 
Make sure to set the max number of mappers to more than 1 in the configuration files.
If you have 4 files, your Mac has at least 4 cores, then you should see at least 4 map tasks running simultaneously.