### The Scenario Advantageous to the Attacker

The scenario that is advantageous to the attacker involves:
1. Providing the attacker with a clear view of the victim’s screen.
2. Having the victim provide verbal cues indicating their actions during the experiment (e.g., answering question 2 in a form).

The study concluded that the system could deauthenticate such attackers within a reasonable time, while maintaining a low false negative rate.

### Our Attack

ZEBRA has several attractive attributes. Instead of attempting to recognize the user, ZEBRA's bilateral approach compares two sequences characterizing user interaction. This method does not limit how a user interacts with the terminal nor requires storing any information about the user or their interaction style. This simplicity makes ZEBRA robust but also vulnerable.

In this section, we revisit the security analysis from [23], identify a design flaw, and explain how it can be exploited to attack ZEBRA.

#### Revisiting ZEBRA Security Analysis

As mentioned in Section II, the Segmenter ignores all measurement data from the bracelet during periods when the Interaction Extractor does not record any activity on the terminal involving the three types of interactions recognized by ZEBRA. However, the attacked terminal is under the control of the adversary, allowing them to choose which parts of the bracelet measurement data will be used by ZEBRA for re-authentication.

Mimicking all interactions is not the most effective strategy. A smart adversary can selectively mimic only a subset of the victim’s interactions, ensuring that the rest are ignored by the Authenticator. To validate security, a realistic adversary model must be used, one that allows attackers to be skilled and experienced in mimicking human-terminal interactions. Using inexperienced test participants to model the adversary is unreasonable. In our study, the role of the attacker was played by two knowledgeable and experienced members of our research group.

#### Attack Scenarios and Strategies

In our attack scenarios, we model a malicious adversary against ZEBRA as discussed in Section II. We assume the adversary (A) accesses the attacked terminal (AT) when the victim (V) steps away without logging out. We also assume V is using another computing device (the "victim device," VD) elsewhere, such as a nearby terminal. Figure 3 illustrates the attack setting.

**Strategy:**
- The goal of A is to remain logged in on AT for as long as possible while interacting with the terminal.
- To achieve this, A needs to consistently produce a sufficiently large fraction of interactions that match V’s interactions on VD.
- Since AT is under A's control, A can choose when the Interaction Extractor triggers the Authenticator to compare the predicted and actual interaction sequences.
- An opportunistic strategy involves selectively mimicking only a subset of V’s interactions to maximize the fraction of matching interactions. We conjecture that such an opportunistic adversary will be more successful than the naive adversary considered in [23].

**First, we consider a keyboard-only attack:**
- A mimics only the typing interactions while ignoring all others.
- Typing sequences are typically longer and less prone to delays in mimicking.
- The opportunistic strategy is for A to start typing only after V starts and stop as soon as V stops.
- A sophisticated keyboard-only attacker may estimate the expected length of V’s typing session and attempt to stop before V does.
- If A makes just a few key presses each time V begins typing, they can be confident that the actual interaction sequence will match the predicted interaction sequence.
- These keyboard-only attacks are powerful because a wide range of actions can be performed using only the keyboard in modern personal computer operating systems.

**Second, we consider an all-activity attack:**
- A mimics all types of interactions (typing, scrolling, and MKKM) but opportunistically chooses a subset.
- A’s selection criterion is the likelihood of correctly mimicking V.
- Strategy:
  - Once A successfully mimics a keyboard-to-mouse interaction, they can carry out any mouse-related interaction (scroll, drag, move) at will because the bracelet measurements for all mouse interactions are likely to be similar.
  - If A fails to quickly mimic a keyboard-to-mouse (or vice versa) interaction, they do nothing until the next opportunity for an MKKM interaction arises (foregoing all interactions until after the MKKM is completed).

**Observation Channels:**
- By default, similar to [23], we consider an adversary A who has a clear view of V’s interactions (Figure 3). This models two cases: where A has direct visual access to V and where A has access to a video aid, such as a surveillance camera aimed at VD.
- During our attacks that use visual information of the victim’s behavior, VD was placed next to the victim terminal AT.
- We also consider the case where A has no visual access but can still hear sounds resulting from V’s activities. This models two cases: where both V and A are in the same physical space separated by a visual barrier (e.g., adjacent cubicles) and where A has planted an audio aid (e.g., a small hidden bug or a microphone) close to VD.

**Scenarios:**
- **Naive all-activity attack:** A can see and hear V and attempts to mimic all interactions of V. This is the attack scenario proposed and studied in [23].
- **Opportunistic keyboard-only attack:** A can see and hear V and selectively mimics only a subset of V’s typing interactions.
- **Opportunistic all-activity attack:** A can see and hear V and selectively mimics a subset of all types of interactions of V following the guidelines mentioned above.
- **Audio-only opportunistic keyboard-only attack:** A can hear but not see V’s interactions. A listens for keyboard activity and attempts to mimic a subset of V’s typing interactions.

While other attack combinations are possible, we consider these four to be representative of different choices available to A. For example, we leave out an audio-only all-activity attack because it is unlikely to succeed. Although our experiments are “unaided” (i.e., no audio or video recording), the results generalize to aided scenarios if data transmission between the aid and the attacker does not introduce excessive delays.

### ZEBRA End-to-End System

Mare et al. [23] describe a framework for ZEBRA and implemented some individual pieces, but this was not a complete system. Therefore, we built an end-to-end system from scratch to evaluate our conjecture about opportunistic attacks. Our goal was to make this system as close to the one in [23] as possible. We now describe our system and how we evaluated its performance.

#### Design and Implementation

**Software and Hardware:**
- We followed the ZEBRA system architecture as described in Figure 2.
- Our system consists of two applications: the bracelet runs an Android Wear application, and the terminal runs a Java application.
- The Interaction Classifier is implemented in Matlab.
- Communicator modules in both applications orchestrate communication over Bluetooth to synchronize clocks and transfer bracelet measurements to the terminal.
- The rest of the terminal software consists of the “ZEBRA Engine” (shaded rectangle) with the functionality described in Section II.
- The bracelet and terminal synchronize their clocks during connection setup.
- For our experiments, we used a widely available smartwatch (4GB LG G Watch R with a 1.2 GHz CPU and 512MB RAM) with an accelerometer/gyroscope as the bracelet and standard PCs as terminals.

**Parameter Choices:**
- Mare et al. [23] do not fully describe the parameters used in their implementation of ZEBRA components.
- Wherever available, we used the exact parameters provided in [23] [22].
- For the rest, we chose reasonable values. A full list of parameters and rationales for choosing their values appears in Appendix A.

**Classifier:**
- We use the Random Forest [7] classifier.
- As [23] did not include all details on how their classifier was trained and tuned, we made parameter choices that gave the best results.
- Our forest consisted of 100 weak-learners. Each split in a tree considered sqrt(n) features, where n = 24 was the total number of features, and the trees were allowed to fully grow.
- Classes were weighted to account for any imbalances in the training dataset (described below in Section IV-B).
- We adopt the same set of features used in [23] and extract them for both accelerometer and gyroscope segments. A full list appears in Appendix ??.

**Differences:**
- Despite our efforts to keep our system similar to that in [23], there are some differences.
- We wanted to use commercially widely available general-purpose smartwatches as bracelets. They tend to be less well-equipped compared to the high-end Shimmer Research bracelet used in [23].
- Our smartwatch has a maximum sampling rate of around 200 Hz, whereas the Shimmer bracelet had a sampling frequency of 500 Hz. We discuss the implications of this difference in Section VII.
- [23] mentions a rate of 21 interactions in a 6s period (3.5 interactions per second). However, in our measurements, users filling standard web forms averaged around 1.5 interactions per second. Their typing interactions were slightly less than 1s long on average, and MKKM interactions typically spanned 1-1.5s.
- With our chosen parameters, we could produce a rate of 3.5 interactions per second only in sessions involving hectic activity—switching extremely rapidly between a few key presses and mouse scrolls. Such a high rate could not be sustained in realistic PC usage.

#### Data Collection

In our study, we recruited 20 participants to serve as users (victims) of the system. They were mostly students recruited by word of mouth (ages 20–35, 15 males, 5 females, all right-handed). Participation was voluntary, based on explicit consent. The study included both dexterous typists and less-experienced ones. Initially, we told the participants that the purpose of the study was to collect information on how they typically use a PC. At the end of the study, we explained the actual nature of the experiment. The members of our research groups played the role of the adversary A, compared to the untrained users in [23]. No feedback was given to A whether a given attack attempt was successful or not.

Experiments were conducted in a realistic office setting (with several other people working at other nearby desks). During a session, a participant did four 10-minute tasks filling a web form, in a similar setting as in [23]. From each task, two sets of user data were collected simultaneously: accelerometer and gyroscope measurements from the user’s bracelet and the actual interaction sequence extracted by the Interaction Extractor on the terminal. An attacker A assigned to a participant V conducted each of the four types of attack scenarios from III-B in turn. In the first three scenarios, A had direct visual access to V. In the fourth scenario, we placed a narrow shoulder-high partition between V and A so that A could hear but not see V. The 20 sessions resulted in a total of 80 samples, with each sample consisting of three traces: bracelet data of the user, actual interaction sequence of the user, and the actual interaction sequence of the attacker. All traces within a sample were synchronized. No other information (e.g., the content of what the participant typed in) was recorded. Participants were told what data was collected.

The data collection and the study followed IRB procedures at our institutions. The data we collected has very little personal information. However, the interaction sequences or bracelet data could potentially be used to link a participant in our study to similar data from the same participant elsewhere. For this reason, we cannot make our datasets public but will make them available to other researchers for research use.

#### Performance Evaluation

**Usability:**
- To evaluate usability, we follow the same approach as in [23] to compute the false negative rate (FNR) as the fraction of windows in which the Authenticator, comparing the actual and predicted interaction sequences from the same user, incorrectly outputs “different user.”
- We employ the leave-one-user-out cross-validation approach: for each session, we train a random forest classifier using the 76 samples of bracelet data from all the other 19 sessions. We then use the four samples from the current session to test the classifier. We thus train 20 different classifiers and report results aggregating classification of 80 samples in all.

**Results:**
- (a) Average FNR vs. window size (w) for different threshold (m) values. Fraction of windows that are incorrectly classified as mismatching.
- (b) Fraction of users remaining logged in after (n) authentication attempts.