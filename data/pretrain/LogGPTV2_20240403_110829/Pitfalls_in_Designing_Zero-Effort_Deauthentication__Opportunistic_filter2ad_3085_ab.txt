the scenario advantageous to the attacker by (a) providing
the attacker with a clear view of the victim’s screen and (b)
have the victim give verbal cues to indicate what the victim
was doing during the experiments (e.g., answering question
2 in the form). They concluded that their system was able to
deauthenticate such attackers in reasonable time, while keeping
false negative rates low.
III. OUR ATTACK
There are a number of attributes that make ZEBRA at-
tractive. In particular, rather than trying to recognize the user,
ZEBRA’s bilateral approach simply compares two sequences
that characterize user interaction. Consequently, its decisions
neither limit how a user interacts with the terminal nor require
storing any information about the user or his style of interac-
tion. Such simplicity makes ZEBRA robust but also vulnerable.
In this section, we revisit the security analysis in [23], point
out a design ﬂaw, and explain how it can be used to attack
ZEBRA.
A. Revisiting ZEBRA Security Analysis
Recall from Section II that Segmenter ignores all measure-
ment data from the bracelet during periods when Interaction
Extractor does not record any activity on the terminal involv-
ing the three types of interactions recognized by ZEBRA.
However, the attacked terminal is under the control of the
adversary and thus she can effectively choose which parts
of the bracelet measurement data will be used by ZEBRA to
re-authenticate the user. Mimicking all interactions is not the
best attack strategy. A smart adversary can selectively choose
only a subset of the victim’s interactions to mimic since it can
ensure that the rest of the victim’s interactions will be ignored
by Authenticator. Furthermore, to validate security, we need
to use a realistic adversary model which allows attackers to
be skilled and experienced in mimicking how people interact
with terminals. It is unreasonable to use inexperienced test
participants to model
the adversary. Thus, the role of the
attacker in this paper was played by two members of our
research group that were knowledgeable of the ZEBRA system
and experienced at mimicking attacks.
B. Attack Scenarios and Strategies
In our attack scenarios, we model a malicious adversary
against ZEBRA as discussed in Section II. We assume that
the adversary A accesses the attacked terminal AT when the
victim V steps away from it without logging out. We also
assume that V is using another computing device (the “victim
device”, VD) elsewhere (e.g., a nearby terminal). Figure 3
illustrates the attack setting.
Strategy: The goal of A is to remain logged in on AT for
as long as possible, while interacting with the terminal. To
this end, A needs to consistently produce a sufﬁciently large
fraction of interactions that will match V’s interactions on
VD. Since AT is under the control of A, it can choose when
AT ’s Interaction Extractor triggers Authenticator to compare
the predicted and actual interaction sequences. If A adopts an
opportunistic strategy, it can selectively choose only a subset
3
                       Sensor Data Terminal Legitimate User Bracelet  Input (Keyboard/Mouse) 1a Accept/Reject 3 2 Authenticator decides “Same User” or “Different User”? 1b Fig. 2: ZEBRA system architecture
of V’s interactions to mimic so as to maximize the fraction of
matching interactions. We conjecture that such an opportunistic
adversary will be more successful than the na¨ıve adversary that
was considered in [23].
First, we consider a keyboard-only attack where A mimics
only the typing interactions while ignoring all others. Typing
sequences are typically longer and less prone to delays in
mimicking. The opportunistic strategy is for A to start typing
only after V starts typing and attempt to stop as soon as V
stops. A sophisticated keyboard-only attacker may estimate
the expected length of V’s typing session and attempt to stop
before V does. If A makes just a few key presses each time V
begins typing, he can be conﬁdent that the actual interaction
sequence he produces will match the predicted interaction
sequence. These keyboard-only attacks are powerful because in
all modern personal computer operating systems a wide range
of actions can be performed using only the keyboard.
•
Second, we consider an all-activity attack, where A mimics
all types of interactions (typing, scrolling and MKKM) but
opportunistically chooses a subset of the set of interactions. As
before, the A’s selection criterion is the likelihood of correctly
mimicking V. In particular, A will use the following strategy:
Once A successfully mimics a keyboard to mouse
interaction, he is free to carry out any interaction
involving the mouse (scroll, drag, move) at will be-
cause the bracelet measurements for all interactions
involving the mouse are likely to be similar.
If A fails to quickly mimic a keyboard to mouse
(or vice versa) interaction, he does nothing until the
next opportunity for an MKKM interaction arises
(foregoing all interactions until after the MKKM is
completed).
•
ZEBRA concatenates continual typing events into up-to 1
second long interactions: as such the typing speed of A is
not particularly relevant. Instead, A may divert more of his
attention to observing V.
Observation Channels: By default, and similar to [23], we
consider an adversary A who has a clear view of V’s interac-
tions (Figure 3). This models two cases: where A has direct
visual access to V and where A has access to a video aid such
4
as a surveillance camera aimed at VD. During our attacks that
use visual information of the victim’s behavior, victim’s new
device VD was placed next to the victim terminal AT . We
also consider the case where A has no visual access to but
can still hear sounds resulting from V’s activities. Again, this
models two cases: where both V and A are in the same physical
space separated by a visual barrier (e.g., adjacent cubicles) and
where A has planted an audio aid (e.g., a small hidden bug
or a microphone) close to VD.
Scenarios: The combination of attack strategy and type of
observation channel leads to several different attack scenarios.
We consider four of the most signiﬁcant ones:
•
•
•
•
In na¨ıve all-activity attack, A is able to both see and
hear V. A attempts to mimic all interactions of V.
This is the attack scenario proposed and studied in
[23].
In opportunistic keyboard-only attack, A is able to
both see and hear V. A selectively mimics only a
subset of V’s typing interactions.
In opportunistic all-activity attack, A is able to both
see and hear V. A selectively mimics a subset of all
types of interactions of V following the guidelines
mentioned above.
In audio-only opportunistic keyboard-only attack, A
is able to hear, but not see, V’s interactions. A listens
for keyboard activity and attempts to mimic a subset
of V’s typing interactions.
While one can imagine other attack combinations, we
consider these four to be representative of different choices
available to A. For example, we leave out an audio-only all-
activity attack because it is unlikely to succeed. Although our
experiments are “unaided” (i.e., no audio or video recording),
the results generalize to aided scenarios, if data transmission
between the aid and the attacker does not introduce excessive
delays.
IV. ZEBRA END-TO-END SYSTEM
Mare et al [23] describe a framework for ZEBRA and
implemented some individual pieces. However, this was not
 Synchronize time & transfer sensor data  Input events Accelerometer & Gyroscope measurements Communicator Input Events Listener Interaction Extractor Segmenter Communicator Interaction Classifier Feature Extractor Segmented  data Features Input events Authenticator Predicted Interaction sequence ZEBRA Engine “Same user” Or “Different user” Interaction time interval Actual Interaction Sequence Terminal	
  Bracelet	
  User	
  Fig. 3: Basic attack setting
a complete system. Therefore, we needed to build an end-
to-end system from scratch to evaluate our conjecture about
opportunistic attacks. Our goal was to make this system as
close to the one in [23] as possible. We now describe our
system and how we evaluated its performance.
A. Design and Implementation
Software and Hardware: We followed the ZEBRA system
architecture as described in Figure 2. Our system consists of
two applications: the bracelet runs an Android Wear appli-
cation and the terminal runs a Java application. Interaction
Classiﬁer is implemented in Matlab. Communicator modules
in both applications orchestrate communication over Bluetooth
to synchronize clocks between them and to transfer bracelet
measurements to the terminal. The rest of the terminal software
consists of the “ZEBRA Engine” (shaded rectangle) with the
functionality described in Section II. The bracelet and terminal
synchronize their clocks during connection setup. For our
experiments, we used a widely available smartwatch (4GB LG
G Watch R with a 1.2 GHz CPU and 512MB RAM) with
accelerometer/gyroscope as the bracelet and standard PCs as
terminals.
Parameter Choices: Mare et al [23] do not fully describe
the parameters used in their implementation of ZEBRA com-
ponents. Wherever available, we used the exact parameters
provided in [23] [22]. For the rest, we strived to choose
reasonable values. A full list of parameters and rationales for
choosing their values appears in Appendix A.
Classiﬁer: We use the Random Forest [7] classiﬁer. Again,
as [23] did not include all details on how their classiﬁer was
trained and tuned, we made parameter choices that gave the
best results. Our forest consisted of 100 weak-learners. Each
split in a tree considered sqrt(n) features, where n = 24
was the total number of features, and the trees were allowed
to fully grow. In addition, classes were weighted to account
for any imbalances in the training dataset (described below
in Section IV-B). We adopt the same set of features used in
[23], and extract them for both accelerometer and gyroscope
segments. A full list appears in Appendix ??.
Differences: Despite our efforts to keep our system similar to
that in [23], there are some differences. First, we wanted to use
commercially widely available general-purpose smartwatches
as bracelets. They tend to be less well-equipped compared to
the high-end Shimmer Research bracelet used in [23]. Our
smartwatch has a maximum sampling rate of around 200 Hz,
whereas the Shimmer bracelet had a sampling frequency of
500 Hz. We discuss the implications of this difference in
Section VII.
5
In addition, [23] mentions a rate of 21 interactions in a 6s
period (3.5 interactions per second). However, in our measure-
ments, users ﬁlling standard web forms averaged around 1.5
interactions per second. Their typing interactions were slightly
less than 1s long on average and MKKM interactions typically
spanned 1-1.5s. With our chosen parameters we could produce
a rate of 3.5 interactions per second only in sessions involving
hectic activity – switching extremely rapidly between a few
key presses and mouse scrolls. Such a high rate could not be
sustained in realistic PC usage.
B. Data Collection
In our study, we recruited 20 participants to serve as users
(victims) of the system. They were mostly students recruited
by word of mouth (ages 20–35, 15 males; 5 females, all right-
handed). Participation was voluntary, based on explicit consent.
The study included both dexterous typists and less-experienced
ones. Initially, we told the participants that the purpose of the
study was to collect information on how they typically use a
PC. At the end of the study, we explained the actual nature of
the experiment. The members of our research groups played
the role of the adversary A, compared to the untrained users
in [23]. No feedback was given to A whether a given attack
attempt was successful or not.
Experiments were conducted in a realistic ofﬁce setting
(with several other people working at other nearby desks).
During a session, a participant did four 10-minute tasks ﬁlling
a web form, in a similar setting as in [23]. From each task, two
sets of user data were collected simultaneously: accelerometer
and gyroscope measurements from the user’s bracelet and the
actual interaction sequence extracted by Interaction Extractor
on the terminal. An attacker A assigned to a participant V
conducted each of the four types of attack scenarios from III-B
in turn. In the ﬁrst three scenarios, A had direct visual access
to V. In the fourth scenario, we placed a narrow shoulder-
high partition between V and A so that A can hear but not
see V. The 20 sessions thus resulted in a total of 80 samples,
with each sample consisting of three traces: bracelet data of
the user, actual interaction sequence of the user, and the actual
interaction sequence of the attacker. All traces within a sample
were synchronized. No other information (e.g., the content of
what the participant typed in) was recorded. Participants were
told what data was collected.
The data collection and the study followed IRB procedures
at our institutions. The data we collected has very little
personal
the interaction
sequences or bracelet data could potentially be used to link
a participant in our study to similar data from the same partic-
ipant elsewhere. For this reason, we cannot make our datasets
is conceivable that
information. It
       Sensor Data    Input (Keyboard/Mouse) by mimicking Victim       ’s activities  2 Bracelet Accept/Reject 4 Input (Keyboard/Mouse) 1a Authenticator decides  “Same user” or  “Different user”? 3 Benign Channel Adversary Channel        Attacker         with clear  view/sound of Victim Device    Attacked Terminal Victim Victim Device 1b public, but will make them available to other researchers for
research use.
C. Performance Evaluation
Usability: To evaluate usability, we follow the same ap-
proach as in [23] to compute the false negative rate (FNR) as
the fraction of windows in which Authenticator comparing the
actual and predicted interaction sequences from the same user
incorrectly outputs “different user.” We employ the leave-one-
user-out cross-validation approach: for each session, we train
a random forest classiﬁer using the 76 samples of bracelet
data from all the other 19 sessions. We then use the four
samples from the current session to test the classiﬁer. We
thus train 20 different classiﬁers, and report results aggregating
classiﬁcation of 80 samples in all.
(a) Average FNR vs. window size (w) for different threshold (m)
values. Fraction of windows that are incorrectly classiﬁed as mis-
matching.
(b) Fraction of users remaining logged in after (n) authentication