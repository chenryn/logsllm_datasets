Targets Studying attackers in-the-wild can identify variation
in targeting by threat actors. Tajalizadehkhoob et al. [114]
analysed around 150k Zeus malware conﬁguration ﬁles col-
lected by a managed service provider. They show that just
175 of 6 500 ﬁnancial institutions were targeted, of which
larger banks were disproportionately represented. Similar stud-
ies identify factors affecting victimisation rates for DDoS
ampliﬁcation attacks [90] and phishing emails [106]. Simoiu
et al. [106] ﬁnd that user adoption of 2-factor authentication or
a recovery mechanism is positively associated with phishing
targeting. The authors warn against a causal interpretation in
which criminals seek out victims with greater security, and
instead suggest that victims who are more likely to be targeted
are also more likely to employ security measures.
An even more ﬁne-grained measurement involves detecting
denial of service (DoS) attacks in the back-scatter of internet
trafﬁc. Moore et al. [87] used this approach to estimate the
frequency, severity, and duration of a subset of DoS attacks.
The method identiﬁes which exact IP addresses were targeted.
Researcher intervention Simulating the attacker as part
of an experiment provides complete control over the threat
level of each subject in a laboratory setting. For example, Cai
and Yap [20] study Android anti-virus (AV) app effectiveness
using 200 known malware strains. In the causal diagram,
this experimental design investigates how compromise C is
determined by the installed app’s preventative security Sp
when exposed to the same malware samples T .
Ecological validity is questionable in this research de-
sign because the authors only used “sufﬁciently old” mal-
ware samples that were “detected by at least 40 out of 57
AVs” [20]. This means the study over-samples detectable mal-
ware, whereas rational attackers deliberately use undetectable
malware. This can be addressed by collecting malware samples
via honeypots [15, 48, 49]. The question remains as to whether
failing to detect a malware sample translates into harm or even
meaningful compromise.
Summary A unifying approach to controlling for threat is
unlikely to be found. Although bigger targets tend to face a
greater threat, many DoS attacks on home machines constitute
“relatively large, severe attacks with rates in the thousands of
packets” [87, p. 133]. Research designs should consider the
speciﬁc form of cyber attack when deciding how to control
for varying threats.
C. Measuring exposure
Constructing a measurement model for exposure seems
intuitively simple because exposed assets are also exposed
to measurement. Selecting the unit of analysis and the right
number of variables are challenging.
Unit of analysis Stone et al. [112] tried to shame careless
hosting providers by creating a ranking of the amount of
persistent maliciousness. Hosting providers were associated
with an autonomous system (AS), which functions as the
technical unit of analysis. Tajalizadehkhoob et al. [115] argue
this is a bad approach because some providers share ASs and
others operate multiple ASs. The authors provide an alternative
way forward by building a costly mapping from IP addresses
to 45 358 hosting providers [117].
Variables The number of IP addresses associated with a
hosting provider has been used to control for exposure [112,
133], but is this enough? Tajalizadehkhoob et al. [117] show it
can explain 20% of the variance in phishing abuse associated
with each hosting provider. This rises to 84% when three
additional variables related to the size and business model of
the hosting providers are added to the model. The majority
(77%) of the remaining 16% of variance can be explained by
including variables related to pricing and the ICT index of the
hosting provider. This leads the authors to ask: if so much can
be explained by exposure alone, what are we studying when
we study abuse?
The explanatory power of exposure is further demonstrated
by Soska and Christin [109]. They trained a classiﬁer to predict
whether a website will become malicious C, which achieves
66%/17% true/false positive rates. The features are all based
on the website’s content and trafﬁc statistics, both of which
represent indicators of exposure Es. A powerful aspect of
their research design is that features can be gathered after
compromise has been observed thanks to “an archive of more
than 391 billion web-pages saved over time”
Summary The explanatory power of exposure can be easily
underestimated when omitting relevant variables or using the
wrong unit of analysis. Going from one to four indicators of
exposure in hosting providers led to a four fold increase in
explanatory power [117]. Many of these variables were only
available because the authors focused on hosting providers
rather than relying on ﬂawed proxies like measuring the num-
ber of IPs at the associated AS [115]. Beyond organisations,
Canali et al. [22] show indicators of exposure like the amount
or time of web-browsing impact compromise outcomes.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:54 UTC from IEEE Xplore.  Restrictions apply. 
218
SYSTEMATISATION OF CYBER RISK QUANTIFICATION BY INVESTIGATED CONSTRUCT OF THE CAUSAL MODEL.
TABLE III
1990
2000
2010
2020
MITIGATION STUDIES
HARM STUDIES
Survey of ﬁrms
Organisation incident
Abuse study
End-user
Threat index
Cybercrime ecosystem
End-user
AV effectiveness
Abuse study
End-user
Notiﬁcation
Compliance
Cybercrime ecosystem
IP backscatter
Organisation incident
Abuse study
Market reaction
Data breach
Legal cases
Case study
Market reaction
Data breach
Operational loss
Survey of ﬁrms
Insurance prices
Market reaction
Data breach
Operational loss
Case study
Manually compiled
Bitcoin ledger
Market reaction
Data breach
Data breach
Manually compiled
Market reaction
Notiﬁcation
Notiﬁcation
WEIS 2017
Biancotti [12]
JMIS 2015
Sen and Borle [105]
ISR 1990
Straub Jr [113]
JCyS 2016
Sarabi et al. [101]
ITDSCM 2015
Vasek et al. [122]
Edwards et al. [37]
arXiv 2019
Tajalizadehkhoob et al. [116] CCS 2017
NDSS 2014
Zhang et al. [133]
IMC 2019
DeKoven et al. [34]
CCS 2017
Bilge et al. [14]
SnP 2010
Geer [52]
Oakland 2011
Levchenko et al. [75]
USENIX 2012
McCoy et al. [85]
Oakland 2018
Huang et al. [63]
CCS 2007
Franklin et al. [47]
Lalonde L´evesque et al. [71] CCS 2013
NCA 2009
Gashi et al. [48]
ISSRE 2011
Bishop et al. [15]
SafeComp 2013
Gashi et al. [49]
CODASPY 2016
Cai and Yap [20]
Soska and Christin [109]
USENIX 2014
Tajalizadehkhoob et al. [117] TOIT 2018
ACSAC 2009
Stone-Gross et al. [112]
AsiaCCS 2014
Canali et al. [22]
USENIX 2016
Stock et al. [111]
WEIS 2017
Cetin et al. [26]
WEIS 2019
Zeng et al. [132]
CCS 2019
Rahaman et al. [94]
Noroozian et al. [90]
RAID 2016
Tajalizadehkhoob et al. [114] WEIS 2014
TOCS 2016
Moore et al. [87]
USENIX 2015
Liu et al. [81]
Nagle et al. [89]
WEIS 2017
JCoS 2003
Campbell et al. [21]
RIMR 2003
Hovav and D’Arcy [62]
JEC 2004
Cavusoglu et al. [24]
ICIS 2006
Acquisti et al. [1]
WESSI 2006
Ishiguro et al. [64]
JEC 2007
Kannan et al. [69]
JCoS 2011
Gordon et al. [53]
FRL 2019
Iyer et al. [65]
JFE 2020
Kamiya et al. [68]
JIPLS 2008
Curtin and Ayres [30]
IME 2017
Eling and Loperﬁdo [40]
JELS 2014
Romanosky et al. [99]
SafeComp 2017
Ceross and Simpson [25]
TDSC 2010
Schroeder and Gibson [104]
JMS 2019
Colivicchi and Vignaroli [29]
SSRN 2019
Tosun [119]
EPJ 2010
Maillart and Sornette [83]
GPRI 2015
Biener et al. [13]
EJOR 2019
Eling and Wirfs [41]
Heitzenrater and Simpson [58] JCyS 2015
WEIS 2019
Woods et al. [130]
JITS 2016
Park et al. [93]
Deane et al. [33]
IFM 2016
Malliouris and Simpson [84] WEIS 2019
JAPP 2018
Berkman et al. [11]
Xu et al. [131]
TIFS 2018
IMF 2018
Bouveret [18]
TOR 2014
Franke et al. [46]
Self 2019
Cyentia Institute [31]
FC 2014
Spagnuolo et al. [110]
Liao et al. [79]
APWG 2016
Paquet-Clouston et al. [92]
JCyS 2019
Gatzlaff and McCullough [50] RIMR 2010
Wang et al. [125]
Amir et al. [5]
Edwards et al. [36]
Wheatley et al. [128]
Carfora et al. [23]
Wheatley et al. [127]
Farkas et al. [43]
Romanosky [98]
Gay [51]
Li et al. [78]
Vasek et al. [123]
ISR 2013
RAS 2018
JCyS 2016
GPRI 2019
JOR 2019
EPJ 2016
Self 2020
JCyS 2016
JCyS 2017
WWW 2016
WISCS 2016
2020
Each study is classiﬁed according to our causal diagram (size due to space constraints) and then a category. We include the venue
and year of publication in the fourth column. The ﬁfth column describes the time period of the sample. Blue = Computer science,
Red = Big four security conference, Orange = Inter-disciplinary CS, Green = Finance and Management, Grey = Miscellaneous.
1990
2000
2010
(cid:72)(cid:35) denotes the type of threat conditioned on compromise T|C.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:31:54 UTC from IEEE Xplore.  Restrictions apply. 
219
D. Structural relationships
The previous subsections described different measurement
models for latent factors. This section identiﬁes research
designs investigating the relationship between these latent
factors. We point the readers back to previous descriptions
of studies using latent models of security to explore structural
relationships [113, 116] and turn to unidentiﬁed approaches,
which break down into: between-subject, within-subject, and
multiple indicator research designs.
Between-subject designs compare outcomes for subjects
with differing levels of security. Edwards et al. [37] use this
approach to study botnet infections across organisations with
different security levels. They ﬁt a linear model with variables
like available network protocols and TLS conﬁguration and
certiﬁcate weaknesses. Training a separate model for each
industry achieves the best balance between complexity and
goodness of ﬁt according to the chosen criteria. In some
industries TLS certiﬁcate errors and misconﬁguration were
associated with less compromise [37]. The only consistent
effect related to whether peer-to-peer ﬁle sharing was blocked.
At the level of web servers, Vasek et al. [122] use a case-
control design to explore factors inﬂuencing the likelihood of
a web server compromise. The authors discover evidence that
running up to date software Sp “may actually put webservers at
greater risk of being hacked” [122, p. 8]. This ‘more security,
more compromise’ relationship likely resulted from sampling
relatively many low-threat, low-security websites who only
have low compromise rates because they are not targeted.
Evidence in support of this is provided by restricting the
sample to servers that have already been compromised, which
is an indicator for high threat. After doing so, the authors
observe a smaller fraction of updated websites (22.6%) are
re-compromised than the fraction of sites that never update
(33.5%). This suggests more security is associated with lower
rates of compromise only in the high-risk population.
Within-subject designs track the same subject’s security
level over time using longitudinal data. Nagle et al. [89] ﬁt a
ﬁxed-effect regression model using 33 million security events
occurring at 480 enterprises collected by a security monitoring
company. The number of open ports, which serves as an
indicator of (the lack of) security management effort Sp, has a
statistically signiﬁcant effect on three of the four indicators of
compromise C. The authors suggest the failure to establish
an effect on the fourth indicator despite 33m observations
results from the sparsity of observed malware infections.
Such imbalances are common in samples collected from a
population of ﬁrms before a breach has occurred—subsequent
compromise and harm are (fortunately) rare exceptions.
Technical indicators A group of researchers used network
scans to predict cyber risk outcomes in a cluster of related pub-
lications.The ﬁrst study [133] identiﬁed a correlation between
indicators of mismanaged networks Sp and malicious activities
C emanating from the corresponding AS. The indicators of
mismanagement are all normalised for exposure Es. They
also control for social and economic factors using a method
designed to capture latent factors. The authors identify a
statistically signiﬁcant correlation between network misman-
agement and network abuse. A metric aggregating all the
individual symptoms had the strongest relationship [133, p. 8]
highlighting the value of combining multiple noisy indicators.
A later publication [81] reformulates cyber risk forecasting
network as a classiﬁcation problem on an IP block. Blocks