### Targets and Threat Variation

Studying attackers in the wild can reveal variations in targeting by threat actors. Tajalizadehkhoob et al. [114] analyzed approximately 150,000 Zeus malware configuration files collected by a managed service provider. Their findings indicate that only 175 out of 6,500 financial institutions were targeted, with larger banks being disproportionately represented. Similar studies have identified factors influencing victimization rates for DDoS amplification attacks [90] and phishing emails [106]. Simoiu et al. [106] found that users who adopt two-factor authentication or a recovery mechanism are more likely to be targeted by phishing attempts. However, the authors caution against interpreting this as criminals specifically seeking out more secure victims; instead, they suggest that individuals more likely to be targeted are also more likely to implement security measures.

### Fine-Grained Measurement of DoS Attacks

A more detailed measurement approach involves detecting denial-of-service (DoS) attacks through backscatter analysis of internet traffic. Moore et al. [87] used this method to estimate the frequency, severity, and duration of a subset of DoS attacks, identifying the exact IP addresses targeted. This fine-grained approach provides valuable insights into the nature and impact of these attacks.

### Researcher Intervention and Experimental Design

Simulating attackers in a controlled experimental setting allows researchers to have complete control over the threat level. For example, Cai and Yap [20] studied the effectiveness of Android antivirus (AV) apps using 200 known malware strains. In their causal diagram, the experimental design investigates how compromise (C) is influenced by the installed app's preventative security (Sp) when exposed to the same malware samples (T).

However, the ecological validity of such research designs is questionable because the authors used "sufficiently old" malware samples detected by at least 40 out of 57 AVs. This oversampling of detectable malware does not reflect the use of undetectable malware by rational attackers. A more realistic approach would involve collecting malware samples via honeypots [15, 48, 49]. The question remains whether failing to detect a malware sample translates into significant harm or meaningful compromise.

### Summary: Controlling for Threat

A unified approach to controlling for threat is unlikely to be found. Although larger targets generally face greater threats, many DoS attacks on home machines constitute "relatively large, severe attacks with rates in the thousands of packets" [87, p. 133]. Research designs should consider the specific form of cyber attack when deciding how to control for varying threats.

### Measuring Exposure

Constructing a measurement model for exposure seems intuitively simple because exposed assets are also exposed to measurement. However, selecting the appropriate unit of analysis and the right number of variables presents challenges.

#### Unit of Analysis

Stone et al. [112] attempted to shame careless hosting providers by ranking them based on the amount of persistent maliciousness. They associated hosting providers with autonomous systems (AS), which functioned as the technical unit of analysis. Tajalizadehkhoob et al. [115] argue that this approach is flawed because some providers share ASs, while others operate multiple ASs. They propose an alternative method by creating a costly mapping from IP addresses to 45,358 hosting providers [117].

#### Variables

The number of IP addresses associated with a hosting provider has been used to control for exposure [112, 133], but is this sufficient? Tajalizadehkhoob et al. [117] show that it can explain 20% of the variance in phishing abuse associated with each hosting provider. Adding three additional variables related to the size and business model of the hosting providers increases the explanatory power to 84%. Including variables related to pricing and the ICT index of the hosting provider further explains 77% of the remaining 16% of variance. This leads the authors to question what we are truly studying when we focus on abuse, given that so much can be explained by exposure alone.

Soska and Christin [109] further demonstrate the explanatory power of exposure by training a classifier to predict whether a website will become malicious (C). The classifier achieves 66%/17% true/false positive rates using features based on the website’s content and traffic statistics, both indicators of exposure (Es). A key aspect of their research design is the ability to gather features after observing compromise, thanks to an archive of over 391 billion web pages saved over time.

### Summary: Explanatory Power of Exposure

The explanatory power of exposure can be easily underestimated when relevant variables are omitted or the wrong unit of analysis is used. Increasing the number of exposure indicators from one to four for hosting providers led to a fourfold increase in explanatory power [117]. Many of these variables were only available because the authors focused on hosting providers rather than relying on flawed proxies like measuring the number of IPs at the associated AS [115]. Beyond organizations, Canali et al. [22] show that indicators of exposure, such as the amount or time of web browsing, impact compromise outcomes.

### Structural Relationships

The previous subsections described different measurement models for latent factors. This section identifies research designs investigating the relationship between these latent factors. We refer readers to previous descriptions of studies using latent models of security to explore structural relationships [113, 116] and turn to unidentifiable approaches, which break down into: between-subject, within-subject, and multiple indicator research designs.

#### Between-Subject Designs

Between-subject designs compare outcomes for subjects with differing levels of security. Edwards et al. [37] used this approach to study botnet infections across organizations with different security levels. They fit a linear model with variables like available network protocols and TLS configuration and certificate weaknesses. Training a separate model for each industry achieved the best balance between complexity and goodness of fit according to the chosen criteria. In some industries, TLS certificate errors and misconfiguration were associated with less compromise [37]. The only consistent effect was related to whether peer-to-peer file sharing was blocked.

At the level of web servers, Vasek et al. [122] used a case-control design to explore factors influencing the likelihood of a web server compromise. They discovered evidence that running up-to-date software (Sp) "may actually put web servers at greater risk of being hacked" [122, p. 8]. This 'more security, more compromise' relationship likely resulted from sampling relatively many low-threat, low-security websites, which only have low compromise rates because they are not targeted. Restricting the sample to servers that have already been compromised, an indicator of high threat, revealed that a smaller fraction of updated websites (22.6%) were re-compromised compared to the fraction of sites that never update (33.5%). This suggests that more security is associated with lower rates of compromise only in the high-risk population.

#### Within-Subject Designs

Within-subject designs track the same subject's security level over time using longitudinal data. Nagle et al. [89] fit a fixed-effect regression model using 33 million security events occurring at 480 enterprises collected by a security monitoring company. The number of open ports, an indicator of (the lack of) security management effort (Sp), had a statistically significant effect on three of the four indicators of compromise (C). The authors suggest that the failure to establish an effect on the fourth indicator, despite 33 million observations, results from the sparsity of observed malware infections. Such imbalances are common in samples collected from a population of firms before a breach has occurred—subsequent compromise and harm are (fortunately) rare exceptions.

#### Technical Indicators

A group of researchers used network scans to predict cyber risk outcomes in a cluster of related publications. The first study [133] identified a correlation between indicators of mismanaged networks (Sp) and malicious activities (C) emanating from the corresponding AS. The indicators of mismanagement were normalized for exposure (Es), and the authors controlled for social and economic factors using a method designed to capture latent factors. They identified a statistically significant correlation between network mismanagement and network abuse. A metric aggregating all individual symptoms had the strongest relationship [133, p. 8], highlighting the value of combining multiple noisy indicators.

A later publication [81] reformulated cyber risk forecasting as a classification problem on an IP block. Blocks