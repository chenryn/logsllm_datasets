0
5
0
y
c
n
e
u
q
e
r
F
0
0
0
0
4
1
0
0
0
0
0
1
0
0
0
0
6
0
0
0
0
2
0
y
c
n
e
u
q
e
r
F
0
0
0
0
5
3
0
0
0
0
5
2
0
0
0
0
5
1
0
0
0
0
5
0
y
c
n
e
u
q
e
r
F
1e−05
0.001 0.01
0.1
1
10
100
1000
1e−05
0.001 0.01
0.1
1
10
100
1000
1e−05
0.001 0.01
0.1
1
10
100
1000
Interval, sec
Interval, sec
Interval, sec
Figure 2: Distribution of interval between identical packets seen in three sample traces.
(in particular, load due to redundant trafﬁc), so we do not want to
use an overly conservative rule for identifying phantoms unless we
know it incurs little in the way of “false positives” (misidentifying
truly distinct packets as phantoms).
A more accurate rule. Given that identifying phantoms on the
basis of a separation ≤ 15 µsec misidentiﬁes some phantoms as
reﬂecting separate source transmissions, we now turn to assessing
whether a higher threshold might yield better results, or will too of-
ten conﬂate separate transmissions as phantoms. To do so, we rely
on the notion of sole-sourced packets—those which we can infer
with high conﬁdence were transmitted only a single time within a
given trace. We proceed as follows.
First, note that we conﬁne our analysis to Ethernet broadcast
packets, since those should be replicated to create expected phan-
toms, whereas for unicast packets or even for the general group of
Ethernet multicast4 packets that may or may not hold.
Next, we observe that any packet whose contents appears in a
given trace 6 or more times was not sole-sourced, since the repli-
cation process can create at most 4 phantoms for a given end-host
transmission.
If we knew that all 5 ports in a given trace were active, then we
could assume that any packet whose contents appear ≤ 5 times was
sole-sourced. However, applying this approach we ﬁnd nominally
sole-sourced packets separated by large amounts of time between
the phantom copies (in some cases hours). Surely no switch repli-
cation process introduces such delays. In fact, it is plausible that
no switch process introduces delays exceeding 100 msec. This is
conﬁrmed in Figure 2, which shows identical packets separated by
either signiﬁcantly less than 100 msec or signiﬁcantly more than
100 msec. The same holds for the distribution computed for the
other traces. Thus, we deem as sole-sourced broadcast packets for
which (i) we see 5 or fewer total copies, and (ii) the intervals be-
tween the copies all lie below 100 msec. This rule is not ironclad—
it’s possible that with a small enough replication size and rapid
transmissions by a source host that we will misclassify some non-
sole-sourced packets—but it should sufﬁce to ﬁnd all of the truly
sole-sourced packets, and we presume these will dominate.
Given this deﬁnition, we then examined the intervals seen be-
tween the copies of sole-sourced packets. Across all of the traces,
we found a total of 20.4M such intervals. (Note, this number is
much lower than the total number of packets in the traces because
our analysis is limited to broadcast packets.) In 60% of the traces,
the interval never exceeded 1 msec, and across all traces the 99th
4An Ethernet MAC address is deﬁned as multicast (a group ad-
dress) if the least signiﬁcast bit of the ﬁrst octet is 1; otherwise, the
packet is unicast [4]. The Ethernet broadcast address is a particular
multicast address with all bits set (ff:ff:ff:ff:ff:ff).
percentile never exceeded 2 msec (other than for a pathological
trace with only one nominally sole-sourced packet in it). 99.998%
of the intervals lie below 5 msec. All intervals lie below 58 msec.
Thus, a threshold of a few msec will work for correctly identify-
ing the phantoms associated with virtually all of the sole-sourced
broadcast packets. We can further estimate the corresponding false
positive rate associated with a given threshold by determining how
often we observe the same payload appearing > 5 times within a
given threshold across all broadcast trafﬁc (i.e., not just the sole-
sourced packets). We know that structurally such occurrences must
reﬂect multiply-sourced packets (or peculiar measurement prob-
lems). We ﬁnd that a threshold of 60 msec yields 450 such false
positives out of 7.8M unique packet payloads; with 5 msec it drops
to 150; and with 100 µsec it further drops to 46.
In conclusion, we ﬁnd that a value of 5 msec rather than 15 µsec
gives us signiﬁcantly more complete coverage of sole-sourced
packets, and with at most a quite modest degree of misidentiﬁca-
tion of multiply-sourced packets. Accordingly, we deﬁne phantoms
as identical copies of previous packets that we observed less than
5 msec in the past.
Analysis of the middle mode. In light of this new deﬁnition, we
revisit Figure 2. Now we no longer interpret the middle mode from
100 µsec to 1 msec as representing truly distinct (separately orig-
inated) packets, and it behooves us to investigate why we observe
a separate mode here rather than a single mode extending from a
few µsec up to 1 msec.
The evidence indicates that switches exhibit two different repli-
cation mechanisms. Indeed, we ﬁnd that this is the case. The mid-
dle mode is heavily dominated by a particular type of trafﬁc, the
Cisco Group Management Protocol (CGMP) [1]. These packets
represent control trafﬁc governing how switches forward IP mul-
ticast. We ﬁnd that CGMP phantoms come with sharp intervals
of time between them, exhibiting narrow spikes at 125 µsec and
multiples thereof. This suggests that the switch uses a timer-driven
mechanism to generate the replicas, and occasionally misses one or
two beats of the timer when doing so.5 We can rule out that these
packets are instead generated by their source as multiple copies,
since we consistently observe the switches replicating the packets
to the same degree that they replicate broadcast packets (i.e., in re-
ﬂection of the number of monitored ports that are currently active).
If the replication occurred at the source, then sometimes these val-
5We note that these packets are quite small, so it is presumably
coincidence that the 125 µsec spacing happens to match that of
maximum-sized Ethernet packets. We also note that intervals seen
at multiples of 125 µsec, such as 250 µsec or 375 µsec, occur much
more frequently than can be due to measurement loss leading to a
failure to record intervening packets that all came 125 µsec apart.
146 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
F
D
C
 0
-0.0002 -0.00015 -0.0001
-5e-05
 0
 5e-05
 0.0001  0.00015  0.0002
Clock Difference (sec)
Figure 3: Distribution of the difference between a packet’s
timestamp on the ﬁrst monitoring interface and the second
monitoring interface across a sample merged trace.
ues would differ, since the source would have no way of knowing
how many of the ports we were passively monitoring happened to
currently be active.
4. TIMING
For the consideration of timing ﬁdelity, we note that previ-
ous work has established that packet trace timestamps can exhibit
a wide range of errors—many of which require pairs of traces
recorded using different clocks to detect [7]. As sketched in § 2,
our traces were all recorded using a single clock, and thus we can-
not employ many clock-calibration methods. However, we do two
quick calibration tests to ensure that we can in fact use the com-
ponent trace of each pair to examine temporal aspects of the trafﬁc
with conﬁdence that the events recorded in the component traces
do in fact happen contemporaneously. After verifying that time
progressed in monotone-increasing timestamps in all of our traces,
we turned to the problem of comparing the timestamps recorded
in each trace in a pair for the same event. While our setup used
a single tracing host, it executed two separate tracing processes
(tcpdump), leaving the calibration question of how closely the
timestamps recorded by one match those recorded by the other. Our
methodology proceeds as follows.
We ﬁrst remove phantoms from each trace in our dataset using
the Δt < 5 msec rule developed in § 3. Next, we merge each trace
pair into a single trace—other than one pair of traces we removed,
as discussed below—and collect identical broadcast packets to-
gether based on the MD5 checksum (with an indication of the ori-
gin trace for each packet). We then identify sole-sourced packets—
which appear exactly once in each of two traces after removing
phantoms—and examine the difference in their timestamps.
In
principle there are additional opportunities to compare the time-
stamping processes using non-sole-sourced packets. However, con-
sidering only sole-sourced packets side-steps the tricky issue of
teasing apart pairs of packets that correspond to the same packet
transmission, and we note that using only sole-sourced packets pro-
vides ample timestamp samples to solidly compare the two traces.
In particular we ﬁnd that the number of samples per trace ranges
from 6,000–165,000 across the merged traces (i.e., per ≈23 hours
of time).
For these samples, we examine the absolute value of the differ-
ence in the pairs of timestamps from sole-sourced packets. We ﬁnd
the median of this value to be 39 µsec, with 99.8% coming less
than 152 µsec apart (maximum just over 5 msec). The largest me-
dian across any of the pairs of traces was 49 µsec. Finally, we note
that the direction of the differences is roughly balanced so neither
timestamping process runs consistently ahead of the other. Figure 3
shows the distribution of differences between packets observed on
the ﬁrst and second interfaces of our monitoring host for one of the
trace pairs. The plot shows that (i) the differences are small, (ii) the
differences go in both directions with each process ahead and be-
hind almost exactly half of time, and (iii) there is a no-man’s-land
between ±15 µsec that likely corresponds to the monitor’s min-
imum time for switching from servicing (and thus timestamping)
one interface over to the other. Note that this no-man’s-land also
points up an inherent shortcoming of the initial Δt < 15µsec rule
for detecting replicas: a single interrupt switching the timestamping
process from one interface to the other, arriving in the middle of a
replication burst, can lead to an interval for the burst that exceeds
30 µsec (the shortest time until the timestamping can return to the
original interface).
Examining the largest differences between the timestamping
processes led to the discovery that one set of “paired” traces in
fact did not constitute a pair, meaning that while the traces were
recorded concurrently, they tapped different switches.
(We con-
ﬁrmed this ﬁnding using the “layout” techniques discussed in § 6.)
We omit these traces from any analysis we conducted using merged
pairs of traces.
Based on sole-sourced packets we conclude that the timestamps
of concurrently recorded traces are very closely aligned (as ex-
pected, since the same workstation recorded both of them), and
thus we can use a fairly narrow window of time to analyze the
merged pair for further details (either in terms of calibration—as
we leverage the merged traces in § 5—or more generally in terms
of characterizing the network).
5. DETECTING MEASUREMENT LOSS
We now turn to gauging the degree to which our monitoring
setup incurred measurement losses, i.e., failed to record packets
that traversed the tapped links. Such losses can arise from a variety
of processes: a faulty tap that sometimes fails to physically copy
bits transmitted over the link; buffer exhaustion in the aggregation
switch as it multiplexes 10 streams of 100 Mbps each onto a 1 Gbps
SPAN port; buffer exhaustion in the monitoring workstation, either
in its NICs, its kernel, or the user-level tcpdump process; NIC
PCI bus contention, since one machine was capturing two gigabit
ethernet streams; or bit errors during transmission between these
stages (presumed very rare). We need as best as we can to dis-
tinguish these effects, all of which only affect copies of the actual
trafﬁc, from true loss of actual trafﬁc, since the latter represents an
interesting networking event, while the former is a mundane mea-
surement artifact.
We pursue four separate strategies for estimating measurement
loss, two based on broadcast trafﬁc (with one being generally con-
servative, the other less so), and two using unicast trafﬁc. First,
we can examine pairs of traces for the presence of “orphans”—
broadcast packets that should appear in both traces in a pair but
only show up in one. Second, as suggested previously we can as-
sess variations of the replication size occurring in a trace, inter-
preting short-lived reductions in the number of phantoms observed
that quickly return to the previous baseline level as likely reﬂect-
ing measurement loss rather than tapped hosts going inactive and
then becoming active again. This second approach is equivalent
to the ﬁrst where the reduction in replication size goes all the way
to zero—but that event is not discernible when inspecting a single
147trace. Third, we exploit the structure and reliable nature of TCP
trafﬁc to infer measurement loss, by looking for instances where a
receiver acknowledges data, but for which we do not see the data
itself previously appearing in the trace. This technique lends itself
to two variants, one based on the rate at which we observe such ac-
knowledgments and the other based on the volume of data we can
tell is missing.
We consider these four approaches in the following subsections.
(Note that we defer a comparison between them until Figure 4,
which presents per-trace estimates based on all four.) However,
before we tackle these assessment strategies we need to address a
peculiar measurement artifact. In the process of analyzing broad-
cast trafﬁc present in one trace but not in its companion, we dis-
covered that for many of the traces at either the beginning (“head”)
or the end (“tail”) a fall-off in replication size occurs, coupled with
a preponderance of orphans (packets missing from the companion
trace). Sometimes, the replication size systematically falls off (5,
4, 3, 2, 1) and then likewise rises again. Based on changes in pre-
dominant MAC and IP addresses at these points, we identiﬁed the
cause as reﬂecting the network operator physically moving the net-
work monitoring taps from one set of ports to another—which in
retrospect we would indeed expect to occur right at the beginning
or end of a trace collection period, as the operator prepares to set
up a new set of monitoring points.
Thus, we discovered that the traces are in fact polluted in the
sense that they do not in their raw form reﬂect a single set of 5 mon-
itored ports, but instead might each represent up to 10 such ports.
We term this the head/tail effect. We manually determined the ex-
tent of this distortion and found that across all of the traces, the
phenomenon did not manifest beyond the ﬁrst or last 12 minutes
of a trace.6 Consequently, we trimmed each trace to delete its ﬁrst
and last 15 minutes (to have a conservative margin), and in addition
aligned the trimming so that the two traces we would then merge
started and ended at the same time. The analysis we discuss in this
paper for pairs of traces uses these trimmed traces rather than the
original raw traces.
5.1 Detecting Orphans