a
d
n
u
o
r
g
e
r
o
f
m
o
r
f
n
r
e
t
t
a
p
/
n
i
p
k
c
o
l
a
t
a
d
ﬀ
i
n
S
ﬀ
i
n
S
s
p
p
a
e
t
a
m
i
t
i
g
e
l
g
n
i
k
c
i
m
m
i
s
p
p
a
e
k
a
F
s
p
p
a
s
e
g
e
l
i
v
i
r
p
e
t
a
m
i
t
i
g
e
l
d
e
t
a
l
a
c
s
e
n
i
a
G
f
o
I
U
e
r
e
f
r
e
t
n
I
s
n
o
i
t
a
c
ﬁ
i
t
o
n
s
n
o
i
t
a
c
i
l
p
p
a
s
t
u
c
t
r
o
h
s
d
e
g
r
o
F
d
e
g
r
o
F
l
l
a
t
s
n
I
g
n
i
k
c
a
j
p
a
t
d
e
s
i
v
e
R
n
o
i
s
r
e
V
d
i
o
r
d
n
A
l
e
v
e
l
I
P
A
d
e
t
s
e
T
d
n
a
W
O
D
N
I
W
T
R
E
L
A
M
E
T
S
Y
S
.
g
.
e
e
l
b
a
l
i
a
v
a
e
r
a
s
n
o
i
s
s
i
m
r
e
p
e
m
i
t
n
u
r
e
r
u
t
a
n
g
i
s
e
r
o
m
2
2
>
I
P
A
e
m
a
n
a
e
r
a
l
c
e
d
l
d
u
o
c
e
n
o
,
s
s
e
l
e
h
t
e
n
o
N
.
e
l
t
i
t
p
p
a
e
h
t
m
o
r
f
d
e
c
t
e
f
s
i
n
o
i
t
a
c
ﬁ
i
t
o
n
e
h
t
f
o
e
l
t
i
t
n
O
e
h
t
:
∗
3
2
>
I
P
A
n
O
:
.
y
t
i
l
i
b
a
c
i
l
p
p
a
∗
∗
d
n
a
s
k
c
a
t
t
A
)
b
(
.
S
G
N
I
T
T
E
S
E
T
I
R
W
6
.
2
2
4
.
3
3
6
.
9
2
7
.
0
)
%
(
e
r
a
h
s
t
e
k
r
a
M
.
r
e
s
u
e
h
t
k
c
i
r
t
o
t
s
e
h
s
a
d
r
o
s
e
c
a
p
s
y
n
a
m
h
t
i
w
338
E. Alepis and C. Patsakis
dialog windows. Following the same logic, an app’s activity can also be launched
from other apps using intents, a special Android mechanism to enable a kind of
“communication” between applications through asynchronous messages. Conse-
quently, there is a strong relationship between activities and intra- and inter-app
navigation, which makes them one of the fundamental building blocks of apps
on the Android platform.
At this point it is essential to clarify how Android UI elements interact with
each other inside or outside the scope of an app. In principle, a dialog window
cannot appear outside the scope of its calling app; i.e. appear on top of another
app’s activity, unless this app is granted the SYSTEM ALERT WINDOW permission.
While there is an exception to this rule inside Android, concerning the “Toast”
window, this type of windows have limited functionality and very short lifetime
(maximum 3.5 s). Moreover, the SYSTEM ALERT WINDOW permission is a signa-
ture level permission; far more strict than dangerous permissions, and allows
an application to create windows shown on top of all other apps by using the
TYPE SYSTEM ALERT option. According to Google Developer resources [7]: “Very
few apps should use this permission; these windows are intended for system-level
interaction with the user”. Apparently, while many applications may request
this permission, this permission is actually neither automatically granted nor
the user is notiﬁed about it during installation. Therefore, a permission manage-
ment screen is presented to the user to grant it [7] and to allow the application
to draw on top of the others. Table 2 provides an overview of the properties of
all UI elements that are able to draw over other apps have.
On the contrary, a newly launched activity is by default, and without requir-
ing any permission, able to appear on top of another app. This is the usual
and obvious way of interaction inside Android OS where apps appear on top
of others, usually as a result of users’ actions, creating a kind of an applica-
tion stack. Activities which are launching other activities or other apps’ activi-
ties and sometimes even return results, are a commonplace in Android and are
thus thoroughly supported through the Android Intent [5] mechanism. Notably,
up to recently, each application would have been actually stacked on top of the
others covering them entirely, as the size of each application would have been
equal to the screen’s size. This is not the case any more as several features,
recently introduced in Android’s UI, are providing more complex stacks such as
messaging apps’ “chatheads”; through SYSTEM ALERT WINDOW permission, and
Multi-Window [8].
2.1 Attacks to the UI
In principle, one of the main goals of malware is to perform unauthorised
actions on victims’ devices and for achieving this an adversary may use var-
ious approaches. Nonetheless, if the adversary cannot ﬁnd a vulnerability to
penetrate into the user’s device either remotely or by getting physical access to
it, one alternative way would be to trick the user into performing the malicious
action himself. To this end, the adversary may use social engineering methods
to convince the user to e.g. install a malicious application or change speciﬁc OS
Trapped by the UI: The Android Case
339
Table 2. Android UI elements over other apps.
UI window type
Required permission Manifest declaration Focusable Duration Launch
from service
Toast messages
Alert messages
System alerts
Keyguards*
Normal activity
Transparent activity
Small shaped activity
Notiﬁcation
Not required
SYSTEM ALERT WINDOW Not required
SYSTEM ALERT WINDOW Not required
Required
Required
Required
Required
Not required
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
3.5 s
No limit
No limit (cid:2)
No limit (cid:2)
No limit (cid:2)
No limit (cid:2)
No limit (cid:2)
No limit (cid:2)
settings. Obviously, the application must not raise an alert to the user indicating
its maliciousness, otherwise the user will not perform the task.
However, even if the user is tricked into installing a malicious app, this does
not guarantee that the adversary will accomplish his/her goals. For instance,
if the adversary has the goal of stealing a user’s password, then the embedded
security mechanisms of the operating system may prevent the adversary from
this theft. To overcome this obstacle, many malicious applications try to trick
users into providing the necessary input directly to them. An obvious method
to achieve this is by disguising themselves as legitimate apps so as to trick users
into providing the input to them. Another approach, which is very often used in
mobile devices due to their UI, is to provide a transparent layer on top of the
legitimate application and thus to steal the sensitive user input.
In literature, several attacks targeting Android relevant to our work are doc-
umented. Despite the fact that transparent elements in browsers were used as
the ﬁrst UI redressing attacks, we are not studying them hereafter since they tar-
get an entirely diﬀerent environment. Besides, these attacks cannot recover the
sensitive information nor can perform the actions that we target in our attacks.
To the best of our knowledge, the ﬁrst attempts to escape the browser envi-
ronment can be attributed to Richardson [32] and Johnson [22]. Nevertheless,
these attacks were quite limited as e.g. they used a simple toast. The actual
successful UI redressing attack can be attributed to Niemietz and Schwenk [30]
who ported them to Android. The authors managed to create an overlay which
is “touch transitive” in that the clicks are also transferred to the application
which is positioned below it. In that scenario for example, the user is tricked
into clicking at speciﬁc points on the screen while his clicks are also parsed to
the dialer application which sits below the app. In that way, the user performs
an unauthorised call to a premium number without realising it.
The attack of Chen et al. [18] starts from a side channel attack to the under-
lying GUI system. While in principle the attack can be launched to any GUI,
the authors focus on Android and more precisely try to infer the activity that
is displayed from the foreground application based on shared memory. First,
the authors monitor oﬄine the memory counters (virtual and physical) of an
application as they are recorded in procfs. That is, they monitor the memory
340
E. Alepis and C. Patsakis
consumption of each activity in an application by tracking the memory alloca-
tion of the corresponding /proc/[pid]/statm ﬁle. The hypothesis is that the
transition from one activity to another has a speciﬁc memory footprint that
can be used to create a unique signature in a target app. Based on this signa-
ture, the adversary can infer the foreground application and the corresponding
activity. By monitoring network traﬃc through /proc/net/tcp6 one can further
improve the results. Based on this input, the adversary may determine whether,
for instance, the victim is presented with the login screen of a sensitive app or
he/she is being asked to enter payment details. Therefore, he can timely bring
his malicious app in the foreground with a replicated UI and trick the user into
disclosing the sensitive information.
Bianchi et al. in [16] categorise all Android UI attacks under the general
umbrella of GUI confusion attacks. Despite the countermeasures that are dis-
cussed in this work, of special interest to our work is the reported leakage
of foreground application by profs. In this case, the leakage is from the ﬁle
/proc/[pid]/cgroups whose contents change from /apps/bg non interactive
to /apps when an app is sent to the foreground. Recently, Fernandes
et al.
[21] showed that one could exploit the use of a defense mechanism
such as the aforementioned one, by monitoring the binder IPC calls in
/sys/kernel/debug/binder. This allows an adversary to know when the scan
has ﬁnished and to timely present user with a fake activity to steal the sensi-
tive data. To overcome this drawback, Fernandes et al. provide a more advanced
mechanism which mitigates such attacks.
The attacks of Ying et al. [41] can be considered quite narrow and the assump-
tions that the authors make are rather strong. Firstly, the attack is mainly
focused on custom ROMs where the ecosystem is very diﬀerent compared to
Android AOSP, as there is a lot of customisation and radically diﬀerent imple-
mentations even for native libraries. Actually, the authors exploit one of these
features, more precisely the SYSTEM ALERT WINDOW permission to draw on top
of other windows. Notably, to grant this permission to an application the user
has to perform a set of actions post installation [7]. Using Tacyt1 to estimate
the exposure from this attack vector, we identiﬁed 235,059 versions in Google
Play and 28,533 version outside it which use this permission. The reason for
this choice is that Tacyt downloads all the apps from Google Play and all their
versions in daily basis, analyses them and provides an interface to mine part of
this information. Due to the implementation of Tacyt, the responses are in per
app version and not per app, nonetheless, they provide a very good snapshot
of available Android apps. Notably, the latter numbers contradict the reported
ones by Ying et al. [41]. For Android AOSP, their attack cannot be considered
valid as none of the big corporations which are explicitly granted this permis-
sion by Google would try to exploit it as such actions would most probably put
them out of business immediately. Alternatively, the user has to be tricked into
performing a set of unusual and very dangerous actions.
1 https://www.elevenpaths.com/technology/tacyt/index.html.
Trapped by the UI: The Android Case
341
Currently, there are several reported possible countermeasures to UI redress-
ing attacks [1,21,28,29,38]. Nonetheless, in terms of state of practice we consider
as baseline the latest version of Android AOSP, which at the time of writing is
7.1.1. The reasons for this choice is that while several defense mechanisms are
implemented for quite old Android versions e.g. Android 4.4 and they actu-
ally account for a low percentage of market share which has currently been left
unsupported. Additionally, Google has issued several security features in the
newer versions to tackle many of these attacks, and introduced new UI features,
some of which are exploited by our attacks. Notwithstanding the above, the
attacks that we demonstrate here can be launched to a plethora of Android
versions, illustrating that the defense mechanisms are rather low. For a more
thorough overview of this ﬁeld, the interested reader may refer to [37].
3 The Attacks
The following paragraphs present the backbone of our attacks. After introducing
our threat model, we provide the necessary technical details and research ﬁndings
that enable the realisation of our attacks. Based on these ﬁndings, we detail how
an adversary can take advantage of them to launch an attack.
3.1 Threat Model
Like most attacks on Android, we assume that the victim has been tricked into
installing a malicious app [19,20,36]. To minimize the risk of alerting the user
that the app might be malicious, we minimize the requirement for permissions,
by requesting access only to the Internet. The latter is a weak assumption, since
after the radical changes in Android 6, the new permission model considers this
access as a normal permission. Practically, the user is not notiﬁed about it, yet
the permission is automatically granted and cannot be revoked. Therefore, our
threat model assumes that the device has not been compromised via a root
exploit. In fact, as we are going to show, most of our attacks can be applied to
the latest version of Android. Therefore, our malicious apps are assumed to be
unprivileged and managed to trick Bouncer and be shared through Google Play.
To provide stealthiness to our app, instead of just using Internet to commu-
nicate the commands and results, we use Firebase. The idea behind this choice
is that Firebase provides a nice hide out for the execution of our attack since
the channel is considered secure and trustworthy, as it is powered by Google,
and the traﬃc is also considered legitimate as many applications use it to store
information. Additionally, it facilitates the development lifecycle as Android has
many native API calls to exchange information with Firebase. In this regard,
the use of Firebase can be considered similar to the use of Facebook, Twitter,
etc. by social botnets [23] to hide their communication with the C&C server.
342
E. Alepis and C. Patsakis
3.2 Drawing over Other Activities
Microphone and touchscreen inputs can be considered as the most sensitive infor-
mation on a smartphone, as they constitute the primary inputs to the device.
While for the former the main security mechanisms can be found in the trans-
port layer, for the latter the mechanisms are embedded in the operating system.
This is perhaps the reason why a signiﬁcant number of corresponding attacks
has already been reported. For instance, apart from the obvious keylogger appli-
cations, an attacker may try to recover information from leaks (potential or
malicious) of the software keyboard [17], processor’s cache [24], motion sensors
[14,39], distortions of the wireless signals from ﬁnger motions [42], hand motion
[26], audio [25], video [33] or both [34] to infer user’s input.
In our approach, we exploit Android’s UI and side channel information to
either steal or interfere with the user’s input. In what follows we discuss how
one can draw on top of other activities. Practically, this is split in two cases: one
where a transparent overlay activity covers another one, and one where one or
more non transparent activities partially cover other activities.
For the former case we use typical Android manifest theme declarations.
More speciﬁcally we have used the Theme.Translucent.NoTitleBar parame-
ter in the activities’ theme declaration to make an activity transparent and
extend it to full screen. In the cases where “on-screen” actions, such as clicks,
or key input through the supplementary presence of a keyboard needs to be
recorded, the transparent layout was supplied with corresponding KeyListener
and ClickListener objects. Notably, drawing over the Android UI by utiliz-
ing a transparent activity was seamless, as a “layer” since any visible view on
the transparent activity is seen as visible on the mobile screen (e.g. TextViews,
Buttons, etc.). The latter case was more demanding as activities whose size is
smaller than the screen are statistically quite “rare” in Android apps. Moreover,
apart from this constraint, we required to leave user interaction pass through
the outer space of the activity. To achieve these, we deﬁned Application Theme
styles that contained the following items as elements:
true
true
@android:color/transparent
true
Then, a crucial step was to override the activity’s onCreate() method to
deﬁne some additional parameters. Namely, a WindowManager.LayoutParams
object was created whose dimAmount was set to 0 and it was ﬂagged with the
attributes FLAG LAYOUT NO LIMITS and FLAG NOT TOUCH MODAL. To position the
sized ﬂoating activity on the screen, one can ﬁne tune several parameters of
the corresponding LayoutParam e.g. “Gravity” parameters, or actual position
through (X,Y) on-screen coordinates. Finally, to make an activity “wrap” around
its contents (e.g. ImageViews) its layout width and layout height parame-
ters have to be deﬁned to take the wrap content value, instead of the default
match parent default value. Notably, the aforementioned properties, can be used
Trapped by the UI: The Android Case
343
to create arbitrary stacks of activities on top of others, allowing an adversary to
create an interface as in Fig. 1a, where only part of the activity on the bottom
can be seen, nonetheless, the interaction (click) is passed to it. The fact that arbi-
trary number of sized activities can overlay other apps can also be used to create
a grid on top of the screen as illustrated in Fig. 1b. Both of these approaches, con-
cerning a number of ﬂoating, sized activities are used in our research for a wide
variety of attacks that range from permission escallation attacks, to revisiting
tapjacking, as it is illustrated in the next section.
(a) Stacked overlay activities.
(b) Grid from overlay activities.
Fig. 1. Exploiting ﬂoating Android activities.
3.3 Tricking Users to Open Apps
In API level 4 Google introduced notiﬁcations to Android. As the name suggests,
this mechanism notiﬁes users about application events. To create a notiﬁcation
there is no permission needed to be granted. From API level 11, one must denote
the text of the notiﬁcation; through setContentText which accepts a string vari-
able, the title of the notiﬁcation; through setContentTitle which also accepts a
string variable, and the notiﬁcation icons for the status bar and the notiﬁcation
view, using setSmallIcon and setLargeIcon respectively [9]. As of API level
23, both icons can be set dynamically using custom bitmaps. Prior to API level
23, only the setLargeIcon provided this feature, as setSmallIcon required
an integer which denoted the resource ID in the application’s package of the
drawable to use. Practically, this means that a developer can now fetch all the
content of a notiﬁcation; strings and icons, from the Internet, without having
any restriction from the declared app resources in the package. Notably, these
attacks emerged since API level 23. While one could long press on the icon of a
notiﬁcation to see its properties, which would actually show the user the correct
app, this cannot be considered a normal user interaction, as it beats the purpose
of the notiﬁcations and cannot be expected to be performed regularly.
Shortcuts are an easy way to launch applications beyond going through the
list of installed applications. To this end, they are created in the home screen
344
E. Alepis and C. Patsakis
of Android so that the user can quickly ﬁnd the apps she uses most often.
While the user can create shortcuts for her apps and arrange them in the
home screen, applications can also do it when deemed necessary, as long as
they have declared the normal permission INSTALL SHORTCUT in their manifest.
The underlying mechanism to create a shortcut is intents [4], so the developer
has to declare three variables: a string which denotes the caption of the shortcut
(EXTRA SHORTCUT NAME), a string which denotes the “action” of the intent to be
launched (setAction), and its icon as a bitmap (EXTRA SHORTCUT ICON). Again,
as in the previous case of notiﬁcations, all the parameters for the creation of app
shortcuts can be set dynamically, using Internet resources.
3.4 Sniﬃng PIN/Pattern
Due to the sensitivity of the data stored in modern smartphones, a wide set
of authentication and authorization methods have been introduced to prevent
unauthorised access. Perhaps the most common mechanism, regardless of the
underlying platform, is the lock screen, where users have to enter a PIN or
pattern to unlock the device. The approach is rather simple and provides base-
line security from physical intrusion. According to a recent study [35], most
users lock their phones by preferring patterns over text based methods; PIN and
passphrase.
the pattern is
While in some versions there might be some minor ﬁlename chang-
ers, by default,
stored as an unsalted SHA-1 hash in
/data/system/gesture.key ﬁle, while the PIN or passphrase are stored in
/data/system/password.key as a concatenation of the password’s SHA-1 and