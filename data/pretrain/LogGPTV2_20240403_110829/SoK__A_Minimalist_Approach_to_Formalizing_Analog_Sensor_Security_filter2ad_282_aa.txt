title:SoK: A Minimalist Approach to Formalizing Analog Sensor Security
author:Chen Yan and
Hocheol Shin and
Connor Bolton and
Wenyuan Xu and
Yongdae Kim and
Kevin Fu
SoK: A Minimalist Approach to Formalizing
Analog Sensor Security
Chen Yan∗§, Hocheol Shin†§, Connor Bolton‡§, Wenyuan Xu∗¶, Yongdae Kim†¶, and Kevin Fu‡¶
∗Zhejiang University, {yanchen, wyxu}@zju.edu.cn
†KAIST, {h.c.shin, yongdaek}@kaist.ac.kr
‡University of Michigan, {mcbolto, kevinfu}@umich.edu
Abstract—Over the last six years, several papers demonstrated
how intentional analog interference based on acoustics, RF, lasers,
and other physical modalities could induce faults, inﬂuence, or
even control the output of sensors. Damage to the availability and
integrity of sensor output carries signiﬁcant risks to safety-critical
systems that make automated decisions based on trusted sensor
measurement. Established signal processing models use transfer
functions to express reliability and dependability characteristics
of sensors, but existing models do not provide a deliberate way
to express and capture security properties meaningfully.
Our work begins to ﬁll this gap by systematizing knowledge of
analog attacks against sensor circuitry and defenses. Our primary
contribution is a simple sensor security model such that sensor
engineers can better express analog security properties of sensor
circuitry without needing to learn signiﬁcantly new notation. Our
model introduces transfer functions and a vector of adversarial
noise to represent adversarial capabilities at each stage of a
sensor’s signal conditioning chain. The primary goals of the
systematization are (1) to enable more meaningful quantiﬁcation
of risk for the design and evaluation of past and future sensors,
(2) to better predict new attack vectors, and (3) to establish
defensive design patterns that make sensors more resistant to
analog attacks.
I. INTRODUCTION
Cyber-physical systems such as airplanes [1], [2], au-
tonomous vehicles [3], [4], and medical devices depend on
the trustworthiness of measurement from trillions of embedded
sensors for critical decision making [5]. A key research
problem is how to build security into the analog circuitry of
sensors to protect against denial of service and damage to the
integrity of sensor outputs.
Today, manufacturers operate in a more reactive stance,
closing sensor security holes one by one after each is discov-
ered. We believe that a more effective approach is to mitigate
security risks by design rather than reaction. Our work sys-
tematizes past papers on analog sensor security by providing a
simple sensor security model based on transfer functions that
map to the components within a sensor’s signal conditioning
chain. The model offers a way for sensor engineers to more
deliberately and concisely write down security requirements
and limitations concerning analog security risks to sensors.
This process helps an engineer to more quickly identify the
security limitations of sensor design and to have a way to
debate the effectiveness of various defenses.
§Co-ﬁrst authors.
¶Corresponding authors.
Since our goal is to improve sensor design, we build our
work on a wide community of publications yet focus on inves-
tigating how adversaries may intentionally induce untrustwor-
thy sensor output (measurement) via analog attacks, i.e., those
that employ analog signals to manipulate sensor output. Notice
that attacks within this scope exploit a sensor’s implementation
rather than the overall system incorporating that sensor. Thus,
in this paper we do not consider the following attacks: (1)
attacking the digital transmission of sensor data, e.g., on a
vehicular CAN bus [6]–[9] and in sensor networks [10]–[14];
(2) utilizing sensors to ﬁngerprint a device [15]–[18], invade
privacy [19]–[26], or trigger malicious behaviors [27]–[30];
(3) modifying the measurand (the target of measurement), e.g.,
using a dummy ﬁnger, to fool sensors or the systems [31]–[40].
We adopt the term transduction attacks [41] to refer to
analog attacks in our scope, i.e., those where victim sensor
circuitry transduces an attacker’s malicious physical signals
to analog ones. Transduction attacks are diverse in adversarial
signal modality (e.g., light or acoustic waves), application, and
vulnerable hardware with examples including: acoustic waves
manipulating a drone’s gyroscope [42]–[44], lasers creating
false points in an autonomous vehicle’s lidar [45], [46], and
radio frequency waves injecting false audio into smart-device
microphones [47], [48]. Existing work categorizes a set of
attacks that partially includes transduction attacks [49], [50]
or uses transfer functions to describe the security properties
of analog-to-digital converters (ADCs) at high-frequency in-
puts [51], but engineers still lack a simple language to compare
how well sensors defend against transduction attacks.
We propose a model to simplify transduction attack analysis
based in (1) mathematical models of sensor physics and (2) ab-
stracted methods to exploit these mathematical sensor models.
Sensors may be modeled as a series of transfer functions, with
a separate function for each sensor component in the signal
processing chain. Each transduction attack exploits at least one
transfer function. We ﬁnd that one can abstract and categorize
these methods to exploit the physics of sensor circuits based
on two categories of basic steps. Each step describes a method
to exploit a transfer function and is an abstraction above the
physical component level. Thus, different transduction attacks
may share some basic steps that exploit the same vulnerability
in transfer functions regardless of sensor components or sensor
type. This mathematical abstraction simpliﬁes comparison of
attacks across different sensors and signal modalities, as many
attacks may be described as a chain of ﬁve or fewer steps.
Additionally, the model enables defense abstraction across
different types of sensors. Since a successful attack depends
on the full chain of steps, the key to defending an attack is to
mitigate at least one step in the attack chain. Within this model,
each step and the mitigation to the step are all mathematically
abstracted over sensor types and components.
Lastly, the cross-sensor analysis provided by the model
enables rudimentary prediction of transduction attacks and
defenses. A new attack is theoretically possible if one can
construct a new series of steps. More importantly, a sensor
designer may implement defenses for each known step at the
design time. As such, even if an attacker discovers a new step,
she could not easily construct a successful attack as existing
defenses against other known steps may mitigate the attack.
Contributions. Our primary contributions pertain to a simple
collection of formalisms to better express the analog security
of sensor circuitry:
• A simple sensor security model. Building upon established
notation and transfer functions from the signal processing
community, our model introduces a vector of intentional,
malicious noise to express how well a sensor design can
resist various transduction attacks. The model enables more
meaningful quantiﬁcation of risk for the design and evalua-
tion of past and future sensors.
• Formalisms to help predict new attack vectors. The small
number of formalisms help a sensor engineer to capture the
security properties of sensor circuitry. Our hope is that by
empowering the engineer with a few simple mathematical
tools and engineering steps, engineers will make fewer
mistakes against known analog vulnerabilities as well as
future unknown vulnerabilities.
• Defensive design patterns. By systematizing the knowledge
of attacks against sensors, our work helps to establish
defensive design patterns that make sensors more resistant
to analog attacks.
II. SENSOR BACKGROUND
Existing studies on sensor security focus on analyzing the
security of one or a few sensor types. Systematizing sensor
attacks and defenses is challenging due to the heterogeneity of
sensors. For example, there are more than 370 types of sensors
on record [52] that rely on dozens of conversion phenomena
for measurement [53]. In this section, we show that despite
great diversity, sensors share components and properties that
facilitate security exploits in general.
A. Sensors
A sensor is a device that outputs usable measurement in
response to a speciﬁc measurand [54]. We present the signal
conditioning chain of typical sensors in Fig. 1, where a sensor
is represented as an interconnection of essential electronic
components. Sensors transform a physical stimulus (input) to
an analog intermediate and ﬁnally to a digital representation
(output). We introduce the signal conditioning chain in the
following.
Fig. 1: A general signal conditioning chain of sensors. Signals ﬂow from left
to right through each component and transform from the physical stimulus
(input) to an analog intermediate and ﬁnally to a digital representation
(output). Depending on the speciﬁc design, variations to this schematic may
include multiple ampliﬁers or ﬁlters, no ﬁlters, ﬁlters before the transducer
(e.g., CMOS) or ampliﬁer, other circuits (e.g., comparators), etc.
Stimulus and Measurand. The measurand is a quantity
that a sensor intends to measure, and a stimulus is a physical
signal involved in measuring the measurand. For example, an
accelerometer’s measurand and stimulus are acceleration and
force, respectively. A thermocouple’s measurand and stimulus
are temperature and heat. Despite the wide variety of stimuli,
we have two measurement methods:
(i) Passive sensors passively accept physical stimuli and do
not emit external stimuli. For example, microphones are
passive sensors that capture sound from the environment.
The stimuli of passive sensors, e.g., light, sound, force,
and chemicals, are generated by other objects in the
environment or already exist.
(ii) Active sensors emit physical stimuli to an environment
and actively measure the response after the stimuli’s in-
teraction with the environment. For example, ultrasonic
sensors/lidars measure the distance to objects by emitting
ultrasound/lasers and receive the reﬂection. Active sensors
are often used to measure quantities of tangible objects,
such as obstacle distance, rotation speed, and liquid drop.
For simplicity, we do not show the emitter in Fig. 1.
Transducer. Commonly a sensor’s ﬁrst component, a trans-
ducer produces an analog electrical representation of the
measurand by measuring a physical stimulus. Transducer
heterogeneity, even for the same measurand or physical stim-
uli, is the primary source for sensor diversity. For example,
dynamic, condenser, and piezoelectric microphones all can
capture sound, but they rely on entirely different conversion
phenomena [55].
Analog Signal Processing Circuits. Typically, a sensor
must process a transducer’s analog signals to reduce noise
while amplifying useful
information. Standard components
include ampliﬁers to increase the signal amplitude, ﬁlters to
remove noise, envelop detectors, comparators, etc.
ADC. An analog-to-digital converter (ADC) digitizes ana-
log signals for digital processing, storage, etc.
Note that a sensor may not contain all components shown in
Fig. 1. For instance, some sensors do not have ﬁlters by design.
Nevertheless, Fig. 1 represents a simpliﬁed yet functionally
comprehensive structure of a modern sensor.
B. Common Properties for Sensor Exploits
Sensitive to Physical Signals. By design, sensors are
sensitive to the target physical stimulus, even if the stimulus
is unintended for measurement. This effect guarantees that at
least one type of physical signal will affect the sensor.
Similar Analog Signal Processing. Analog signal pro-
cessing circuits often remain similar despite transducer het-
erogeneity. For example, sensors commonly use ampliﬁers
and ﬁlters, even if designed to measure different phenomena.
Thus, exploits on similar signal processing circuits may re-
main similar even on different sensors, e.g., microphones and
thermocouples.
Same Signal Modalities. There are three signal modalities
for the signal conditioning chain: physical, analog, and digital,
as shown in Fig. 1. The shared signal modalities show that the
same signal properties in each modality may be exploited for
attacks across various sensors.
Chain of Blind Trust. Sensors are essentially proxies of
reality. Most sensor designs use a series of electric components
to approximate the measurand. Typically, each component
blindly assumes its input is valid. However, this blind trust
can allow malicious signals to exploit components in the signal
conditioning chain without detection.
III. ATTACK OVERVIEW AND SCOPE OF THE STUDY
This research lies on analog sensor security, which focuses
on the trustworthiness of sensor measurement under the threat
of analog attacks. Trustworthiness refers to whether the sensor
measurement reﬂects reality. Within this scope, we use the
term transduction attacks [41] to indicate sensor-related attacks
that fall into the scope.
A. Transduction Attack
A transduction attack exploits vulnerabilities in the physics
of a sensor to manipulate its output. In particular, an attacker
generates malicious physical signals that are transduced to ma-
licious analog signals in the sensor circuitry, either explicitly
through transducers or implicitly through other components in
the sensor. The types of malicious physical signals include but
are not limited to the following items.
• Electromagnetic radiation refers to the waves of an elec-
tromagnetic (EM) ﬁeld that propagate through space. It
includes radio frequency (RF) waves,
infrared, (visible)
light, ultraviolet, X-rays, and gamma rays.
• Sound is a vibration that propagates as a wave of pressure
through mediums, including gas, liquid, and solid. It includes
audible sound, ultrasound, and infrasound.
• A magnetic ﬁeld is created by magnetized materials and
by moving electric charges (currents) such as those used in
electromagnets.
• An electric ﬁeld is generated by particles that bear electric
charges in any form.
An attacker may generate malicious physical signals of any
modality for transduction attacks, regardless of whether the
signal is of the same type as the intended stimulus by design.
For example, attackers can use infrared (IR) to attack a lidar
(which measures obstacles with IR) or RF signals to attack a
microphone (which measures sound).
Out-of-scope: Sensor design vulnerabilities enable transduc-
tion attacks to produce untrustworthy sensor measurements.
For example, attacks can cause a lidar to detect non-existing
obstacles or a microphone to report non-existing sounds. Our
intention is to improve the security of sensor design. Thus,
we do not consider the attacks that intentionally modify the
measurand. For instance, attackers can use a hairdryer to heat
a thermocouple such that the temperature measurements are
higher than the ones of the distant environment. However,
the measurements, though manipulated, still reﬂects the tem-
perature near the sensor. Similarly, we do not consider fake
ﬁngers for ﬁngerprint sensors [56], IR decoy ﬂares for infrared
homing missiles [57], and melamine adulteration of milk
for measurement of nitrogen content [58], since all involve
measurand manipulation. Mitigating these attacks normally
requires alternative defense mechanisms of the systems rather
than sensor design, such as extra functionality (e.g., liveness
detection, object recognition, and protein measurement) or fus-
ing multiple sensors for the intended application. In short, we
focus on systematizing academic knowledge on transduction
attacks from the view of sensor designers.
B. Attacker Objectives
We consider two adversarial objectives.
Denial-of-service (DoS). The goal is to prevent a sensor
from acquiring usable measurements. For instance, a strong
acoustic signal can cause unreliable, seemingly random gy-
roscope output if the signal’s frequency is close to the gyro-
scope’s resonant frequency. Thus, such a signal may prevent
proper ﬂight for drones relying on gyroscope output [42].
Spooﬁng. The goal is to trick a sensor into providing seem-
ingly legitimate but erroneous measurements. For example, for
an RC car controlled by a phone’s gravitational orientation,
malicious acoustic signals can induce false acceleration mea-
surements and control the RC car’s movement while the phone
remains stationary [59].
C. Threat Model
In this paper, we consider adversaries with the following
assumptions.
Analog Attacks. An adversary focuses on affecting the
analog signals in a sensor and does not interfere with digital
measurement processing or transmission.
Sensor Assessment. We assume an adversary cannot tam-
per with victim sensors but can obtain similar sensors for
assessment. The adversary may reverse engineer sensor design
parameters, such as operational frequencies, bandwidth, signal
format, etc., and explore vulnerabilities.
Attack Range. Transmission power generally bounds ef-
fective attack range, but an adversary may extend the range
by emitting stronger physical signals at extra costs. Thus, we
focus on other aspects contributing to attack feasibility rather
than strictly range.
IV. TRANSDUCTION ATTACK SYSTEMATIZATION
Existing approaches to defending sensor security tend to
follow an endless cat and mouse game—security researchers
ﬁnd a physics-based exploit, then manufacturers deploy an
exploit-speciﬁc patch rather than create an overarching and
measurable security goal to address the root causes of that
speciﬁc exploit. The lack of a measurable, goal-oriented ap-
proach to analog sensor security makes it difﬁcult to apply
science to defensive design.
Thus, our model seeks a balance between the salient secu-
rity properties of sensors while requiring minimal additional
cognitive effort by established sensor experts. To achieve this,
our model consists of a simple adaptation to a well-established
language from the signal processing community.
A. Simple Sensor Security Model Overview
To avoid creating overly complicated notation and termi-
nology, our systematization of knowledge on sensor security
seeks to ﬁnd a minimal amount of new formalisms sufﬁciently
powerful for a descriptive model to characterize how secure
existing and future sensor systems are to transduction attacks.
An underlying goal is to ensure the model does not simply
describe past attacks and defenses, but is predictive of the
future and helps sensor engineers to better build measurable
security into sensor circuitry.
The key to identifying transduction attacks is how to ar-
ticulate the signal conditioning chain in sensors. Given that a
transfer function [60] is a well-established concept in signal
processing community to model system input and output
relationships [61]–[63], our model extends this approach by