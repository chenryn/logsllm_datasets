### References

1. **EUROCRYPT, Volume 3027 of Lecture Notes in Computer Science, Pages 571–589. Springer, 2004.**

2. **M. H. Au, P. P. Tsang, A. Kapadia, and W. Susilo.**
   - BLACR: TTP-Free Blacklistable Anonymous Credentials with Reputation. Technical Report TR695, Indiana University Bloomington, May 2011.

3. **M. Bellare and P. Rogaway.**
   - Random Oracles are Practical: A Paradigm for Designing Efficient Protocols. In ACM Conference on Computer and Communications Security, Pages 62–73, 1993.

4. **J. C. Benaloh and M. de Mare.**
   - One-Way Accumulators: A Decentralized Alternative to Digital Signatures (Extended Abstract). In EUROCRYPT, Pages 274–285, 1993.

5. **D. Boneh, X. Boyen, and H. Shacham.**
   - Short Group Signatures. In CRYPTO, Volume 3152 of Lecture Notes in Computer Science, Pages 41–55, 2004.

6. **J. Camenisch, R. Chaabouni, and A. Shelat.**
   - Efficient Protocols for Set Membership and Range Proofs. In ASIACRYPT, Volume 5350 of Lecture Notes in Computer Science, Pages 234–252. Springer, 2008.

7. **Z. Lin and N. Hopper.**
   - Jack: Scalable accumulator-based Nymble system. In WPES, Pages 53–62, 2010.

8. **P. Lofgren and N. Hopper.**
   - FAUST: Efficient, TTP-Free Abuse Prevention by Anonymous Whitelisting. In Proceedings of the Workshop on Privacy in the Electronic Society (WPES), October 2011.

9. **T. P. Pedersen.**
   - Non-Interactive and Information-Theoretic Secure Verifiable Secret Sharing. In CRYPTO’91, Volume 576 of LNCS, Pages 129–140, 1992.

10. **P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith.**
    - Blacklistable Anonymous Credentials: Blocking Misbehaving Users without TTPs. In ACM Conference on Computer and Communications Security, Pages 72–81. ACM, 2007.

11. **P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith.**
    - PEREA: Towards Practical TTP-Free Revocation in Anonymous Authentication. In ACM Conference on Computer and Communications Security, Pages 333–344, 2008.

12. **P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith.**
    - BLAC: Revoking Repeatedly Misbehaving Anonymous Users without Relying on TTPs. ACM Trans. Inf. Syst. Secur., 13(4):39, 2010.

13. **P. P. Tsang, A. Kapadia, C. Cornelius, and S. W. Smith.**
    - Nymble: Blocking Misbehaving Users in Anonymizing Networks. IEEE Trans. Dependable Sec. Comput., 8(2):256–269, 2011.

### Appendix
#### A. Security Analysis

We adopt the simulation-based security definition as in PEREA [4]. In the real world, there are several players who communicate via cryptographic protocols, while in the ideal world, the same players communicate via a trusted party \( T \) who is responsible for handling all inputs and outputs for the players. The adversary \( A \) controls the same players in both the real and ideal worlds. All inputs and the scheduling of the players' interactions are decided by another probabilistic polynomial-time (PPT) algorithm and the environment \( E \). \( A \) can communicate arbitrarily with \( E \).

Informally, PERM is secure if, for any PPT algorithms \( A \) and \( E \), there exists another algorithm \( S \) controlling the same players in the ideal world as \( A \) does in the real world such that \( E \) cannot tell if it is interacting with \( A \) or \( S \). \( S \) has black-box access to \( A \).

PERM supports a set of functionalities. An invocation of a functionality is an event. We assume all events are scheduled according to \( E \)'s wishes. We use a static model and assume the number of players and whether they are honest or not is fixed before the system starts. All communications with \( T \) are not anonymous, meaning that \( T \) knows the identity of the communicating parties. It is also assumed that communication between honest parties is not observed by \( A \) and when \( A \) receives a message, it does not learn its origin.

PERM supports the following functionalities:

1. **SP Setup.**
   - **Real World:** The SP generates a key pair \((PK, SK)\). \( PK \) is made available to all players in the system.
   - **Ideal World:** The trusted party \( T \) initializes a database, which stores the registration status and authentication history of all users. To capture the functional requirement of PERM, \( T \) keeps track of the score of every user with respect to each category and all authentications that the user has participated in.

2. **Registration.**
   - **Real World:** User \( i \) sends a request for registration to the SP. The user and the SP output individually the outcome of this transaction to \( E \). If user \( i \) has obtained a credential in a previous registration event, then an honest SP would reject the request. Likewise, an honest user would discard the second credential it obtains from the SP if it has successfully registered in a previous registration event.
   - **Ideal World:** User \( i \) sends a registration request to \( T \), who informs the SP that user \( i \) would like to register and whether user \( i \) has obtained a credential before. The SP returns its decision to \( T \), who forwards it back to the user. If the SP accepts the request and user \( i \) has not registered before, \( T \) stores the registration status of user \( i \) in its database. The user and the SP individually output the outcome of this transaction to \( E \).

3. **Authentication.**
   - **Real World:** User \( i \) conducts the authentication protocol with the SP imposing the access policy \( P \). The user and the SP output individually the outcome of this transaction as well as the transaction identifier \( t \) to \( E \).
   - **Ideal World:** User \( i \) sends a request to \( T \), who informs the SP that some anonymous user requests an authentication. The SP replies with the list \( L \), the current transaction identifier \( t \), and the policy \( P \). \( T \) forwards the reputation lists, the value \( t \), and \( P \) back to user \( i \) and whether \( i \) satisfies the authentication policy or not. User \( i \) then decides if he/she would continue. If yes, \( T \) informs the SP whether the anonymous user satisfies the authentication policy or not. The SP replies with accept or reject to \( T \), who forwards the reply to user \( i \). If the authentication is successful, \( T \) stores \( t \) as one of the user’s transaction identifiers. The user and the SP output individually the outcome of this transaction as well as the transaction identifier \( t \) to \( E \).

4. **Scoring a Transaction.**
   - **Real World:** \( E \) instructs the SP to give a score of \((s_1, \ldots, s_J)\) to transaction identifier \( t \). If \( t \) is not a valid authentication or has already been put on reputation list \( L \), an honest SP ignores this request.

5. **Updating a Score.**
   - **Real World:** \( E \) instructs the SP to update a score of \((s_1, \ldots, s_J)\) for transaction identifier \( t \). If \( t \) is not a valid transaction identifier on \( L \), then an honest SP would ignore this request.

6. **Score Update.**
   - **Real World:** \( E \) instructs user \( i \) to update his score on transaction identifier \( t \). If \( t \) is not a past identifier of the user, an honest user ignores the request.
   - **Ideal World:** User \( i \) sends a request to \( T \), who informs the SP that some anonymous user requests a score update on transaction identifier \( t \). The SP replies with accept or reject. If the SP replies accept, \( T \) updates the stored reputation of the user. The user and the SP output individually the outcome of this transaction as well as the transaction identifier \( t \) to \( E \).

The ideal-world PERM provides all the desired security properties and functionalities of PERM. Firstly, all transactions, in the view of the SP, are anonymous. \( T \) only informs the SP that some anonymous user would like to authenticate, thus ensuring anonymity. Secondly, \( T \) verifies whether the authenticating user satisfies the access policy, ensuring the system functions correctly. The real-world PERM is secure if its behavior is the same as the ideal-world PERM. Thus, assuming \( \text{negl}(\lambda) \) is a negligible function in security parameter \( \lambda \), we have the following definition of security for any construction of PERM.

**Definition 1. Security.**
Let \( \text{Real}_{E,A}(\lambda) \) (resp. \( \text{Ideal}_{E,S}(\lambda) \)) be the probability that \( E \) outputs 1 when run in the real world (resp. ideal world) with adversary \( A \) (resp. \( S \) having black-box access to \( A \)). PERM is secure if for all PPT algorithms \( E \) and \( A \), the following expression holds:
\[
|\text{Real}_{E,A}(\lambda) - \text{Ideal}_{E,S}(\lambda)| = \text{negl}(\lambda)
\]

To prove that PERM is secure, we must construct an ideal-world adversary \( S \) given any real-world adversary \( A \) in such a way that no PPT environment \( E \) can distinguish whether it is interacting with \( S \) or \( A \).

The proof is divided into two cases according to the subset of players controlled by \( A \):

1. **Case 1: The SP is honest.**
   - **SP Setup:**
     - **Representing an Honest SP to \( A \):** \( S \) generates the key pair \((PK, SK)\) and gives \( PK \) to \( A \).
   - **Registration:**
     - **Representing a dishonest user \( i \) to \( T \)/an honest SP to \( A \):** Using the zero-knowledge extractor, \( S \) extracts from \( A \) the value \( x \). \( x \) will be used to identify the dishonest user \( i \). \( S \) sends the request to \( T \) on behalf of user \( i \). If \( T \) replies accept, \( S \) issues the credential to \( A \) and also stores that credential.
   - **Authentication:**
     - **Representing a dishonest user \( i \) to \( T \)/an honest SP to \( A \):** Note that \( S \) does not receive \( P \) from \( E \) directly since \( P \) is sent to the honest SP in the ideal world. However, \( S \) learns about \( P \) from \( T \) on behalf of the dishonest user \( i \) in the ideal world. The difficulty here is that \( S \) does not know which credential \( A \) is using for the authentication. For instance, while \( E \) specifies that user \( i \) should perform the authentication, it is entirely possible for \( A \) to use the credential from another dishonest user, say \( \hat{i} \), to perform the authentication. To locate the actual user, \( S \) extracts and uses the value \( x \) during the authentication to locate the correct user.

The outputs of \( S \) and the honest users in the ideal world are always indistinguishable to \( A \) and the honest users in the real world unless the following happen. We also explain why such cases happen with negligible probability below:

1. **During a Registration event, \( S \) fails to extract from \( A \) the value \( x \).** This happens with negligible probability under the soundness property of the protocol \( S_{Iss} \) of the BBS+ signature scheme.
2. **During a successful Authentication event, \( S \) fails to extract from \( A \) the values \( x \).** This happens with negligible probability under the soundness property of the protocol \( S_{Sig} \) of the BBS+ signature scheme.
3. **There exists a successful Authentication event from \( A \) such that \( S \) on behalf of an honest SP outputs accept, but \( T \) indicates the authenticating user does not satisfy the policy.** This represents either that \( A \) has been able to fake one of the proofs in the authentication or \( A \) can forge a signature on a new queue that has never been signed. All these happen with negligible probability under the assumption that BBS+ signatures are existentially unforgeable and that the interval proof is sound.

Note that in the security proof, we require \( S \) to run the zero-knowledge extractor on \( A \) for each registration and authentication event. To keep \( S \) in polynomial time, we have to require that authentication and registration events are executed sequentially (security proofs of BLACR and PEREA also impose this restriction) or to employ the stronger universally composable proofs of knowledge.

2. **Case 2: The SP is dishonest.**
   - **SP Setup:**
     - **Representing Honest users to \( A \):** \( S \) receives \( PK \) from \( A \).
   - **Registration:**
     - **Representing a dishonest user to \( T \)/an honest user \( i \) to \( A \):** Upon receiving a registration request from \( T \) on behalf of user \( i \), \( S \) engages \( A \) in the registration protocol, using the zero-knowledge simulator to simulate the ZKPoK in \( S_{Iss} \). If \( S \) fails to obtain a valid credential from \( A \), then \( S \) replies reject to \( T \).
   - **Authentication:**
     - **Representing a dishonest SP to \( T \)/an honest user to \( A \):** Upon receiving an authentication request from \( T \) on behalf of an anonymous user, \( S \) engages \( A \) in the authentication protocol. If \( T \) replies with a bit indicating that the underlying user would proceed and satisfies the authentication policy, \( S \) uses the zero-knowledge simulator to simulate the ZKPoK proofs in the authentication protocol using a random value \( q \). If \( A \) rejects the authentication, \( S \) replies reject to \( T \).

The simulation provided to \( A \) is perfect due to the zero-knowledgeness of the ZKPoK protocols and the perfect hiding property of the commitment scheme. At the same time, the behavior of \( S \) in the ideal world is the same as that of \( A \) in the real world. Thus, the output of \( S \) to the environment \( E \) is indistinguishable from that of \( A \).

Based on this dual strategy in the construction of \( S \), our construction of PERM is secure according to Definition 1.