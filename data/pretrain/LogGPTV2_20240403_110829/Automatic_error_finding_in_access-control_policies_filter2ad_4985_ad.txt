20000, 80000
30000, 130000
40000, 200000
12, 19
20, 266
32, 162
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
1.
2.
3.
M/O
0.097s
0.050s
31s
0.016s
0.025s
M/O 0.103s
M/O 0.110s
M/O 0.624s
M/O
3.2s
414s
M/O
M/O
M/O
M/O
M/O
M/O
M/O
0.022s
0.021s
0.026s
0.064s
M/O 0.048s
M/O 0.122s
M/O 0.472s
M/O 1.819s
M/O
109s
M/O
M/O
M/O
M/O
M/O
M/O
0.102s
0.030s
0.044s
0.033s
M/O 0.056s
M/O 0.169s
M/O 0.972s
M/O 2.422s
109s
M/O
M/O
M/O
M/O
M/O
M/O
M/O
0.022s
0.025s
0.023s
0.026s
M/O 0.182s
Forward
reachability
T/O
0.625s
0.695s
0.806s
0.780s
1.471s
2.177s
7.658s
110s
210s
6m 16s
0.513s
0.519s
0.512s
0.534s
0.699s
2.414s
311s
T/O
T/O
T/O
1.452s
1.666s
1.364s
1.476s
2.258s
7.350s
511s
T/O
T/O
T/O
0.531s
0.559s
1.556s
Backward
reachability
Err
0.240s
0.281s
Err
Err
Err
Err
Err
Err
Err
Err
0.241s
0.252s
Err
Err
Err
Err
Err
Err
Err
Err
0.665s
0.881s
Err
Err
Err
Err
Err
Err
Err
Err
0.238s
0.247s
0.568s
2s
0.382s
0.431s
0.733s
0.379s
0.477s
0.531s
3.138s
53s
2m 14s
4m 32s
0.442s
0.501s
0.436s
1.303s
0.504s
0.597s
2.753s
40s
1m 39s
4m 12s
0.380s
0.431s
0.381s
0.984s
0.486s
0.487s
2.478s
41s
2m 57s
6m 21s
0.300s
0.400s
0.830s
m
s
ms
MC
BMC
- minutes
-
seconds
- milliseconds RBAC-PAT - Tool from Stoller et al. [13, 46]
- NuSMV symbolic model checking T/O - Time out after 60 mins
- NuSMV bounded model checking M/O - Memory out
Err
-
Segmentation fault
Table 2: Evaluation of model-checking, bounded model-checking, RBAC-PAT, and Mohawk on various benchmarks.
benchmarks, experimental methodology and provide a sum-
mary of results.
5.1 Case Study
We conducted a case study for banking that has been vet-
ted by a major ﬁnancial institution. The case study involves
several branches, and is realistic. We modeled several of
the job functions at the branches, and the associated state-
change rules. Our case-study has a number of similarities
to an earlier case-study [41]. Our ARBAC policy has 612
roles and 6142 can assign and can revoke rules. Separation
of privilege properties are of importance in banking [41];
commercial tools exist for checking this property for certain
state-only schemes [1, 2]. Hence, we focused on checking for
errors that encode such properties. The particular separa-
tion of privilege property on which our case study is based
expresses the constraint that in any branch, a user may be
assigned to at most three of a set of ﬁve roles that are sen-
sitive. The violation of this constraint can be checked by
appropriately encoding a safety question. Our benchmarks
(see Section 5.2) use similar safety questions.
We discussed this policy with the representatives of a lead-
ing bank, who agreed that enforcing separation of privilege
is crucial for their operations and that our example is realis-
tic [42]. Lack of such an enforcement can lead to toxic pairs
of roles being assigned to the same user.
Our experience with the case study provides two insights
about realistic policies. First, our case study aﬃrms that
the sources of complexity that we discuss in Section 4 oc-
cur in realistic policies. Second, realistic ARBAC policies
are not amenable to static slicing techniques such as those
proposed in prior work [21, 46]. Static slicing techniques are
eﬀective only in cases where the role in question is dependent
in particular ways only on a small set of roles, irrespective of
the size of the policy (see Section 3.8). Such a dependency
does not exist for the encoding of the separation of privilege
property on which Table 2 is based, and for other properties
we have investigated in our case-study.
We have tested our case study on all the error-ﬁnding tools
for our safety question (see Table 2). Mohawk identiﬁed
an error in 2 seconds, BMC identiﬁed the same error in 31
seconds, and the other tools ran out of resources.
5.2 Benchmarks Used
We used two set of policies in our evaluation. Both are
based on prior work [13, 21, 41, 46]. The ﬁrst set has not
been used previously; we built it based on our case study,
and the sources of complexity, given that they do indeed
occur in practice. Our second set of policies has been used
in the context of veriﬁcation of ARBAC policies in prior
work [13, 46]. These policies are simpler than the policies in
the ﬁrst set.
171Complex Policies (Set 1): We have created a test suite
based on the case study, and the sources of complexity that
we know occur in practice. As noted earlier, both from our
case study and analysis we have concluded that the the num-
ber of roles (or size of the policy) and type of state-change
rules are sources of complexity in ARBAC policies. Depend-
ing on the type of state-change rules, the safety analysis
problem for ARBAC is PSPACE-Complete, NP-Complete,
or solvable in polynomial time [21]. Accordingly, we have
created three sets of complex test suites with varying gra-
dations of roles:
• Test suite 1: Policies with positive conjunctive
can assign rules and non-empty can revoke rules.
Error-ﬁnding problem is solvable in polynomial time
for these policies.
• Test suite 2: Policies with mixed conjunctive
can assign rules and empty can revoke rules. Error-
ﬁnding problem is NP-Complete for these policies.
• Test suite 3: Policies with mixed conjunctive
can assign rules and non-empty can revoke rules. The
error-ﬁnding problem is PSPACE-Complete for these
policies.
For each complex policy, we identiﬁed a user-role pair at
random such that the role is reachable by an unauthorized
user. Our results are for verifying this question. Recall that
the basic safety question is determining whether a unautho-
rized user u can reach a role r. In our complex policies, a
majority of the roles in the policy are related to the target
role in the safety query. This is realistic, as it is similar to
the policy in our case study.
Simple Policies (Set 2): This set comprises three AR-
BAC policies that have been used in previous work for the
evaluation of RBAC-PAT [13, 39, 46]. The ﬁrst policy is for
a hypothetical hospital, and the second policy is for a hypo-
thetical university. The third policy from [13] is a test case
that has mixed preconditions. The ﬁrst two policies were
used in [46] for case studies. The third policy was used in
[13], and a complete state-space exploration is reported to
have taken 8.6 hours in RBAC-PAT. An important restric-
tion in these policies is that they have at most one positive
pre-condition per can assign rule. As we explain in Sec-
tion 5.4.2, answering the safety question for these policies
was fairly easy for all the tools.
5.3 Experimental Methodology
All the experiments were conducted on a Macbook Pro
laptop with an Intel Core 2 Duo 2.4 GHz processor and
4GB of RAM.
In all the experiments, the input to the error-ﬁnding
tools consisted of an ARBAC policy and a safety question.
We applied the static slicing techniques proposed in prior
work [21, 46] on all the policies prior to the experiments.
The policies were encoded using the input language of the
respective tools. MC and BMC use the SMV ﬁnite state ma-
chine language, while RBAC-PAT and Mohawk have their
own input language. We implemented a translation tool to
convert policies in Mohawk’s input language to both SMV
and RBAC-PAT input languages. We expected the tools to
conclude that the role is reachable and provide the sequence
of administrative actions that lead to the role assignment.
In our evaluation, we had two users for each policy, namely
the user in the safety question and the administrator. These
are the only users required for answering the safety question.
Moreover, static slicing techniques remove all users but the
one that is relevant to the safety question.
5.4 Results Explained
We explain the results of our experimental evaluation