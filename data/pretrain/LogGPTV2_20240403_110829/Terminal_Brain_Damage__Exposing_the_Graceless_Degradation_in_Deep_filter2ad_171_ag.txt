feating software mitigations against rowhammer: a surgical precision
hammer. In International Symposium on Research in Attacks, Intru-
sions, and Defenses, pages 47–66. Springer, 2018.
[59] Andrei Tatar, Cristiano Giuffrida, Herbert Bos, and Kaveh Razavi. De-
feating software mitigations against rowhammer: a surgical precision
hammer. In International Symposium on Research in Attacks, Intru-
sions, and Defenses, pages 47–66. Springer, 2018.
[60] Andrei Tatar, Radhesh Krishnan Konoth, Elias Athanasopoulos, Cris-
tiano Giuffrida, Herbert Bos, and Kaveh Razavi. Throwhammer:
Rowhammer attacks over the network and defenses. In 2018 USENIX
Annual Technical Conference (USENIX ATC 18), pages 213–226,
Boston, MA, 2018. USENIX Association.
[61] Florian Tramèr, Fan Zhang, Ari Juels, Michael K. Reiter, and Thomas
Ristenpart. Stealing machine learning models via prediction apis. In
25th USENIX Security Symposium (USENIX Security 16), pages 601–
618, Austin, TX, 2016. USENIX Association.
[62] Victor Van Der Veen, Yanick Fratantonio, Martina Lindorfer, Daniel
Gruss, Clémentine Maurice, Giovanni Vigna, Herbert Bos, Kaveh
Razavi, and Cristiano Giuffrida. Drammer: Deterministic rowham-
mer attacks on mobile platforms. In Proceedings of the 2016 ACM
SIGSAC conference on computer and communications security, pages
1675–1689. ACM, 2016.
[63] Bolun Wang, Yuanshun Yao, Bimal Viswanath, Haitao Zheng, and
Ben Y. Zhao. With great training comes great vulnerability: Practical
attacks against transfer learning. In 27th USENIX Security Sympo-
sium (USENIX Security 18), pages 1281–1297, Baltimore, MD, 2018.
USENIX Association.
[64] Naigang Wang, Jungwook Choi, Daniel Brand, Chia-Yu Chen, and
Kailash Gopalakrishnan. Training deep neural networks with 8-bit
ﬂoating point numbers.
In S. Bengio, H. Wallach, H. Larochelle,
K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in
Neural Information Processing Systems 31, pages 7675–7684. Curran
Associates, Inc., 2018.
[65] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad
Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao,
Klaus Macherey, et al. Google’s neural machine translation system:
Bridging the gap between human and machine translation. arXiv
preprint arXiv:1609.08144, 2016.
[66] Jidong Xiao, Zhang Xu, Hai Huang, and Haining Wang. Security
implications of memory deduplication in a virtualized environment. In
2013 43rd Annual IEEE/IFIP International Conference on Dependable
Systems and Networks (DSN), pages 1–12. IEEE, 2013.
[67] Yuan Xiao, Xiaokuan Zhang, Yinqian Zhang, and Radu Teodorescu.
One bit ﬂips, one cloud ﬂops: Cross-vm row hammer attacks and privi-
lege escalation. In 25th USENIX Security Symposium (USENIX Secu-
rity 16), pages 19–35, Austin, TX, 2016. USENIX Association.
[68] Bing Xu, Naiyan Wang, Tianqi Chen, and Mu Li. Empirical evaluation
of rectiﬁed activations in convolutional network, 2015.
[69] Yan Zhou, Murat Kantarcioglu, and Bowei Xi. Breaking transferability
of adversarial samples with randomness, 2018.
Appendix
A Network Architectures
We use 19 DNN models in our experiments: six architecture
and their variants. Table 7 describes two architectures and
their six variations for MNIST. For CIFAR10, we employ the
base architecture from [55] that has four convolutional layers
and a fully-connected layer, and we make three variations
of it. CIFAR10-AlexNet11 and CIFAR10-VGG1612 are from
the community. For ImageNet, we use the DNN architectures
available from the Internet13. In Sec 6.2, we employ two
networks (8-bit quantized14 and binarized versions of MNIST-
L5) from the community15 with adjustments.
B The Vulnerability Using Different Criterion
We examine the vulnerable parameter ratio (vulnerability)
using the different RAD criterion with 15 DNN models. Our
results are in Figure 12. Each ﬁgure describe the vulnera-
ble parameter ratio on a speciﬁc RAD criterion; for instance,
in MNIST-L5, the model has 40% of vulnerable parameters
that cause [RAD > 0.5], which estimates the upper bound of
the blind attacker. In MNIST, CIFAR10, and two ImageNet
models, the vulnerability decreases as the attacker aims to
inﬂict the severe damage; however, in ImageNet, ResNet50,
DenseNet161, and InceptionV3 have almost the same vulner-
ability (∼50%) with the high criterion [RAD > 0.8].
C Hyper-parameters for Training
In our experiments, we use these hyper-parameters:
• MNISTs. For MNIST models, we use: SGD, 40 epochs,
0.01 learning rate (lr), 64 batch, 0.1 momentum, and
adjust learning rate by 0.1, in every 10 epochs.
• CIFAR10s. For Base models we use: SGD, 50 epochs,
0.02 lr, 32 batch, 0.1 momentum, and adjust lr by 0.5,
in every 10 epochs. For AlexNet, we use: 300 epochs,
11https://github.com/bearpaw/pytorch-classification/blob/master/
models/cifar/alexnet.py
12https://github.com/kuangliu/pytorch-cifar/blob/master/models/vgg.
py
13https://github.com/pytorch/vision/tree/master/torchvision/models
14https://github.com/eladhoffer/quantized.pytorch
15https://github.com/jiecaoyu/XNOR-Net-PyTorch
USENIX Association
28th USENIX Security Symposium    513
Table 7: 8 Network Architectures for MNIST. We take the two baselines (Base and LeNet5) and make four and two variants
from them, respectively. Note that we highlight the variations from the baselines in red color.
Base
Base (Wide)
Base (Dropout)
Base (PReLU)
Layer Type
Conv (R)
Conv (R)
Layer Size Layer Type
Conv (R)
5x5x10 (2)
5x5x20 (2)
Conv (R)
Layer Size
5x5x20 (2)
5x5x40 (2)
-
100
-
10
Layer Type
Conv (R)
Conv (-)
Dropout (R)
FC (R)
Dropout (R)
FC (S)
Layer Size
5x5x10 (2)
5x5x20 (2)
0.5
50
0.5
10
Layer Type
Conv (P)
Conv (P)
-
-
FC (P)
FC (S)
Layer Size
5x5x10 (2)
5x5x20 (2)
-
50
-
10
FC (R)
FC (S)
Base (D-BNorm)
LeNet5 [33]
LeNet5 (Dropout)
LeNet5 (D-BNorm)
Layer Size Layer Type
5x5x10 (2)
Conv (R)
Layer Size
5x5x6 (2)
Layer Type
Conv (R)
Layer Size
5x5x6 (2)
Conv (-)
5x5x20 (2)
BatchNorm (R)
5x5x16 (2)
5x5x16 (2)
-
-
-
-
-
-
-
-
FC (R)
FC (S)
Layer Type
Conv (-)
BatchNorm (R)
Dropout (R)
FC (R)
Dropout (R)
FC (S)
-
50
-
10
10
-
20
-
-
-
0.5
-
-
50
0.5
10
-
-
-
-
-
-
-
MaxPool (-)
Conv (R)
MaxPool (-)
Conv (R)
MaxPool (-)
Conv (R)
FC (R)
FC (S)
-
2x2
-
2x2
-
-
2x2
84
-
10
-
-
-
MaxPool (-)
Conv (R)
MaxPool (-)
Conv (R)
Dropout (R)
MaxPool (-)
Conv (R)
FC (R)
Dropout (R)
FC (S)
-
2x2
-
2x2
-
0.5
2x2
84
0.5
10
Layer Type
Conv (-)
BatchNorm (R)
MaxPool (-)
Conv (-)
BatchNorm (R)
MaxPool (-)
Conv (R)
BatchNorm (R)
Dropout (R)
MaxPool (-)
Conv (R)
FC (R)
Dropout (R)
FC (S)
Layer Size
5x5x6 (2)
5x5x16 (2)
6
2x2
16
2x2
120
0.5
2x2
84
0.5
10
5x5x120 (2)
5x5x120 (2)
5x5x120 (2)
5x5x120 (1)
5x5x120 (1)
5x5x120 (1)
Figure 12: The vulnerability of 15 DNN models using different criterions. We plot the vulnerable parameter ratio based on
the different RADs that an attacker aims; 5 from MNIST (left), 5 from CIFAR10 (middle), and 5 from ImageNets (right).
0.01 lr, 64 batch, 0.1 momentum, and adjust lr by 0.95,
in every 10 epochs. For VGG16, we use: 300 epochs,
0.01 lr, 128 batch, 0.1 momentum, and adjust lr by 0.15,
in every 100 epochs.
• GTSRB. We ﬁne-tune VGG16 pre-trained on ImageNet,
using: SGD, 40 epochs, 0.01 lr, 32 batch, 0.1 momentum,
and adjust lr by 0.1 and 0.05, in 15 and 25 epochs. We
.
freeze the parameters of the ﬁrst 10 layers.
• Flower102. We ﬁne-tune ResNet50 pre-trained on Im-
ageNet, using: SGD, 40 epochs, 0.01 lr, 50 batch, 0.1
momentum, and adjust lr by 0.1, in 15 and 25 epochs.
We freeze the parameters of the ﬁrst 10 layers.
514    28th USENIX Security Symposium
USENIX Association