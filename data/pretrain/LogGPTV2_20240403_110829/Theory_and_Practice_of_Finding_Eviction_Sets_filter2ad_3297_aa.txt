title:Theory and Practice of Finding Eviction Sets
author:Pepe Vila and
Boris K&quot;opf and
Jos&apos;e F. Morales
(cid:19)(cid:17)(cid:18)(cid:26)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:1)(cid:52)(cid:90)(cid:78)(cid:81)(cid:80)(cid:84)(cid:74)(cid:86)(cid:78)(cid:1)(cid:80)(cid:79)(cid:1)(cid:52)(cid:70)(cid:68)(cid:86)(cid:83)(cid:74)(cid:85)(cid:90)(cid:1)(cid:66)(cid:79)(cid:69)(cid:1)(cid:49)(cid:83)(cid:74)(cid:87)(cid:66)(cid:68)(cid:90)
Theory and Practice of Finding Eviction Sets
Pepe Vila1,3, Boris K¬®opf2 and Jos¬¥e F. Morales1
1IMDEA Software Institute
2Microsoft Research
3Technical University of Madrid (UPM)
Abstract‚ÄîMany micro-architectural attacks rely on the ca-
pability of an attacker to efÔ¨Åciently Ô¨Ånd small eviction sets:
groups of virtual addresses that map to the same cache set.
This capability has become a decisive primitive for cache side-
channel, rowhammer, and speculative execution attacks. Despite
their importance, algorithms for Ô¨Ånding small eviction sets have
not been systematically studied in the literature.
In this paper, we perform such a systematic study. We begin
by formalizing the problem and analyzing the probability that
a set of random virtual addresses is an eviction set. We then
present novel algorithms, based on ideas from threshold group
testing, that reduce random eviction sets to their minimal core
in linear time, improving over the quadratic state-of-the-art.
We complement the theoretical analysis of our algorithms with
a rigorous empirical evaluation in which we identify and isolate
factors that affect their reliability in practice, such as adaptive
cache replacement strategies and TLB thrashing. Our results
indicate that our algorithms enable Ô¨Ånding small eviction sets
much faster than before, and under conditions where this was
previously deemed impractical.
I. INTRODUCTION
Attacks against the micro-architecture of modern CPUs have
rapidly evolved from an academic stunt to a powerful tool
in the hand of real-world adversaries. Prominent examples
of attacks include side-channel attacks against shared CPU
caches [1], fault injection attacks against DRAM [2], and
covert channel attacks that leak information from speculative
executions [3].
A key requirement for many of the documented attacks is
that the adversary be able to bring speciÔ¨Åc cache sets into
a controlled state. For example, Ô¨Çush+reload [1] attacks use
special instructions to invalidate targeted cache content (like
clflush on x86), for which they require privileged execution
and shared memory space. Another class of attacks, called
prime+probe, evicts cache content by replacing it with new
content and can be performed without privileges from user
space or from a sandbox.
The primitive used for replacing cache content is called
an eviction set. Technically, an eviction set is a collection of
(virtual) addresses that contains at least as many elements that
map to a speciÔ¨Åc cache set as the cache has ways. The intuition
is that, when accessed, an eviction set clears all previous
content from the cache set. Eviction sets enable an adversary
to (1) bring speciÔ¨Åc cache sets into a controlled state; and to
(2) probe whether this state has been modiÔ¨Åed by the victim,
by measuring latency of accesses to the eviction set.
(cid:165)(cid:1)(cid:19)(cid:17)(cid:18)(cid:26)(cid:13)(cid:1)(cid:49)(cid:70)(cid:81)(cid:70)(cid:1)(cid:55)(cid:74)(cid:77)(cid:66)(cid:15)(cid:1)(cid:54)(cid:79)(cid:69)(cid:70)(cid:83)(cid:1)(cid:77)(cid:74)(cid:68)(cid:70)(cid:79)(cid:84)(cid:70)(cid:1)(cid:85)(cid:80)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:15)
(cid:37)(cid:48)(cid:42)(cid:1)(cid:18)(cid:17)(cid:15)(cid:18)(cid:18)(cid:17)(cid:26)(cid:16)(cid:52)(cid:49)(cid:15)(cid:19)(cid:17)(cid:18)(cid:26)(cid:15)(cid:17)(cid:17)(cid:17)(cid:21)(cid:19)
(cid:20)(cid:26)
Accessing a large enough set of virtual addresses is suf-
Ô¨Åcient for evicting any content from the cache. However,
such large eviction sets increase the time required for evicting
and probing, and they introduce noise due to the unnecessary
memory accesses. For targeted and stealthy eviction of cache
content one hence seeks to identify eviction sets of minimal
size, which is fundamental, for example, for
‚Ä¢ Ô¨Åne-grained monitoring of memory usage by a concurrent
process in timing attacks against last-level caches [4], [5];
‚Ä¢ enforcing that memory accesses hit DRAM instead of
the cache with high enough frequency to Ô¨Çip bits in
rowhammer attacks [6];and
‚Ä¢ increasing the number of instructions that are specula-
tively executed by ensuring that branch guards are not
cached [3].
Computing minimal eviction sets is recognized as a chal-
lenging problem, equivalent to learning the mapping from vir-
tual addresses to cache sets [4]. The difÔ¨Åculty of the problem
is governed by the amount of control the adversary has over
the bits of physical addresses. For example, on bare metal,
the adversary completely controls the mapping to cache sets;
on huge pages, it controls the mapping to cache sets within
each cache slice, but not the mapping to slices; on regular 4KB
pages, it only partially controls the mapping to sets within each
slice; and on sandboxed or hardened environments it may not
have any control over the mapping at all [7], [5].
Several approaches in the literature discuss algorithms for
Ô¨Ånding minimal eviction sets, see Section VII for an overview.
These algorithms rely on a two-step approach in which one
Ô¨Årst collects a large enough set of addresses that is an eviction
set, and then successively reduces this set to its minimal core.
Unfortunately, these algorithms are usually only considered
as a means to another end, such as devising a novel attack.
As a consequence,
lack an in-depth analysis in
terms of complexity, real-time performance, correctness, and
scope, which hinders progress in research on attacks and on
principled countermeasures at the same time.
they still
Our approach: In this paper we perform the Ô¨Årst system-
atic study of Ô¨Ånding minimal eviction sets as an algorithmic
problem. In our study we proceed as follows:
‚Ä¢ We give the Ô¨Årst formalization and analysis of the pro-
blem of Ô¨Ånding eviction sets. We study different variants of
the problem, corresponding to different goals, for example,
‚Äúevicting a speciÔ¨Åc cache set‚Äù, and ‚Äúevicting an arbitrary cache
set‚Äù. For these goals, we express the probability that a set of
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:41:36 UTC from IEEE Xplore.  Restrictions apply. 
virtual addresses is an eviction set as a function of its size.
The function exhibits that a small set of virtual addresses is
unlikely to be an eviction set, but that the likelihood grows fast
with the set size. This analysis justiÔ¨Åes the two-step approach
taken in the literature for computing minimal eviction sets,
and it exhibits favorable set sizes to start the reduction.
‚Ä¢ We design novel algorithms for Ô¨Ånding minimal evic-
tion sets. The basis of our algorithms are tests from the
literature [4] that use the cache side-channel as an oracle
to determine whether a given set of virtual addresses is an
eviction set. The key observation underlying our algorithms
is that these tests can be seen as so-called threshold group
tests [8]. This observation allows us to leverage ideas from the
group testing literature for computing minimal eviction sets.
We show that the resulting algorithm reduces an eviction set of
size n to its minimal core using only O(n) memory accesses,
which improves over the current O(n2) state-of-the-art [9].
‚Ä¢ We perform a rigorous reliability analysis of our algo-
rithms on Intel‚Äôs Haswell and Skylake microarchitectures. In
our analysis, we identify ways to isolate the inÔ¨Çuence of TLBs
and cache replacement policies. This allows us to exhibit
conditions under which our algorithms are almost perfectly
reliable, as well as conditions under which their reliability
degrades.
‚Ä¢ We carry out a performance analysis of our algorithms
on Intel Skylake. Our analysis shows that the execution time
of our algorithms indeed grows only linearly in practice,
which leads to signiÔ¨Åcant speed-up compared to the exist-
ing quadratic algorithms. While previous approaches rely on
assumptions about
the number of controlled physical bits
(provided by huge and regular pages), our algorithms enable,
for Ô¨Årst time, computing eviction sets in scenarios without any
control of the mapping from virtual addresses to cache sets,
as in [7], [5].
Summary of contributions: Our contributions are both
theoretical and practical. On the theoretical side, we formalize
the problem of Ô¨Ånding minimal eviction sets and devise novel
algorithms that improve the state-of-the-art from quadratic to
linear. On the practical side, we perform a rigorous empirical
analysis that exhibits the conditions under which our algo-
rithms succeed or fail. Overall, our insights provide a basis
for principled countermeasures against, or paths for further
improving the robustness of, algorithms for Ô¨Ånding eviction
sets.
We also include a tool for evaluating, on different platforms,
all tests and algorithms presented in this paper:
https://github.com/cgvwzq/evsets
logically partitioned into a set of blocks. Each block is cached
as a whole in a cache line of the same size. When accessing
a block, the cache logic has to determine whether the block is
stored in the cache (a cache hit) or not (a cache miss). For this
purpose, caches are partitioned into equally sized cache sets.
The size or number of lines of cache sets is called associativity
a (or ways) of the cache.
Cache Replacement Policies: Since the cache is much
smaller than main memory, a replacement policy must decide
which memory block to evict upon a cache miss. Tradi-
tional replacement policies include least-recently used (LRU),
pseudo-LRU (PLRU), and Ô¨Årst-in Ô¨Årst-out (FIFO). In modern
microarchitectures, replacement policies are often more com-
plex and generally not documented. For example, recent Intel
CPUs rely on replacement policies [10], [11] that dynamically
adapt to the workload.
Cache Hierarchies: Modern CPU caches are organized
in multiple levels, with small and fast lower-level caches per
CPU core, and a larger but slower last-level cache (LLC) that
is shared among different cores. The relationship between the
content of different cache levels is governed by an inclusion
policy. Intel caches, for instance, are usually inclusive. This
means that the content of higher level caches (L1 and L2) is
always a subset of the LLC‚Äôs. In particular, blocks that are
evicted from the LLC are also invalidated in higher levels. In
this paper we focus on inclusive LLCs.
Mapping Memory Blocks to Cache Sets: The mapping of
main memory content to the cache sets of a LLC is determined
by the content‚Äôs physical address. For describing this mapping,
consider an architecture with n-bit physical addresses, cache
lines of 2(cid:2) bytes, and 2c cache sets. The least signiÔ¨Åcant (cid:2)
bits of a physical address y = (bn‚àí1, . . . , b0) form the line
offset that determines the position within a cache line. Bits
(bc+(cid:2)‚àí1, . . . , b(cid:2)) of y are the set index bits that determine the
cache set, and we denote them by set(y). The most signiÔ¨Åcant
n‚àí(cid:2)‚àíc bits form the tag of y. See Figure 1 for a visualization
of the role of address bits on a Intel Skylake machine.
Cache Slicing: Modern Intel CPUs partition the LLC into
different 2s many slices, typically one or two per CPU core.
The slice is determined by an undocumented s-bit hash of the
most signiÔ¨Åcant n ‚àí (cid:2) bits of the address. With slicing, the c
set index bits only determine the cache set within each slice.
The total cache size |M| = 2s+c+(cid:2)a is then determined as
the product of the number of slices, the number of cache sets
per slice, the size of each line, and the associativity.
II. A PRIMER ON CACHING AND VIRTUAL MEMORY
In this section we provide the necessary background and
notation used along the paper.
A. Caches
Caches are fast but small memories that bridge the latency
gap between the CPU and main memory. To proÔ¨Åt from spatial
locality and to reduce management overhead, main memory is
B. Virtual Memory
Virtual memory is an abstraction of the storage resources of
a process that provides a linear memory space isolated from
other processes and larger than the physically available re-
sources. Operating systems, with help from the CPU‚Äôs memory
management unit (MMU), take care of the translation of virtual
addresses to physical addresses.
(cid:21)(cid:17)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:41:36 UTC from IEEE Xplore.  Restrictions apply. 

	%&&
	

	

	


		

	

	
	

 !"	#
$"	#




	


	

%





Fig. 1: Mapping from physical addresses to cache sets for
Intel Skylake LLC, with 4 cores, 8 slices (s = 3), 1024
cache sets per slice (c = 10), lines of 64 bytes ((cid:2) = 6), and
associativity a = 12. The Ô¨Ågure also displays page offsets and
frame numbers for 4KB pages (p = 12) and 2MB huge pages
(p = 21). The set index bits that are not part of the page offset
determine the page color.
Virtual Address Translation: Physical memory is parti-
tioned in pages of size 2p. Common page sizes are 4KB (i.e.
p = 12), or 2MB for huge pages1 (i.e. p = 21).
We model
the translation from virtual
to physical ad-
dresses as a function pt that acts as the identity on the least
signiÔ¨Åcant p bits (named page offset) of a virtual address
x = (x48, . . . , x0). That is, the virtual and physical addresses
coincide on (xp‚àí1, . . . , x0). pt maps the most signiÔ¨Åcant
48‚àíp bits, named virtual page number (VPN), to the physical
frame number (PFN). We discuss how pt acts on these bits
in Section III-C. Figure 1 includes a visualization of the page
offsets and physical frame numbers for small and huge pages,
respectively.
	


%&
!



#
#
#
 
#
#
#
"
"
$"





!
!
!

 
#
#
#
#
#
#
 
"
"


 
#
#
#
