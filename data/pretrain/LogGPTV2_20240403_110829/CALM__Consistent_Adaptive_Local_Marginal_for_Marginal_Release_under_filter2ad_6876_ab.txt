adult
· · ·
elderly
v1
v2
v3
v4
· · ·
vn
v
⟨male, teenager⟩
⟨male, adult⟩
⟨male, elderly⟩
⟨female, teenager⟩
⟨female, adult⟩
⟨female, elderly⟩
F(v)
0.20
0.15
0.20
0.15
0.20
0.10
(a) Dataset.
(b) Full contingency table.
v
M{gender}(v)
⟨male,∗⟩
⟨female,∗⟩
0.55
0.45
(c) Marginal table for gender.
v
M{age}(v)
⟨∗,teenager⟩
⟨∗,adult ⟩
⟨∗,elderly⟩
0.35
0.35
0.30
(d) Marginal table for age.
Figure 1: Example of the dataset, the full contingency table,
and the marginal tables.
[ci ] if ai ∈ A, otherwise vi = ∗} to denote the set of all possible
values specified by A.
When given a set A of k attributes, the k-way marginal over A,
denoted by MA, gives the fraction of users having each value in VA.
We call the fraction for each value v ∈ VA a cell of the marginal
table. MA contains fewer cells than the full contingency table F.
Each cell in MA can be computed from summing over the values in
the cells in F that have the same values on the attributes in A.
Figure 1 gives an example where each user has two attributes
gender and age. In the centralized setting, the server has access to
the raw dataset Figure 1(a), from which, it can compute the full con-
tingency table (Figure 1(b)). The two marginal tables (Figure 1(c,d))
can be computed from the contingency table.
3.2 Problem Definition: Local Setting
In the local setting, the aggregator does not have access to the raw
dataset, such as the one shown in Figure 1(a). Instead, each user
possesses one row of the dataset and sends a randomly perturbed
value based on it. Our goal is to have the aggregator to use the
perturbed reports to compute with reasonable accuracy any k-way
marginal. Some methods (such as those proposed in [11]) require
a specification of the maximum k ahead of time. Our proposed
method can support queries of arbitrary k values.
To measure the utility empirically, we use sum of squared er-
ror (SSE), i.e., the square of the L2 distance between the true mar-
ginal MA and the reconstructed TA. When we query many k-way
marginals, we calculate the SSE for each marginal, and use the
average SSE as the indicator of a method’s accuracy.
The reconstructed TA can be viewed as a random variable since
random noises are added in the process to satisfy LDP. When a
method is able to produce an unbiased estimation, the expected
value of TA is the true marginal MA, and the expected value of SSE
is the variance of the random variable TA.
Figure 1 gives an example where each user has two attributes
gender and age. The goal is to construct all the marginal tables. Each
user’s private value corresponds to a row in Figure 1(a). No one has
Symbol
Description
n
v j
d
A
ai
ci
F
A
MA
m
ℓ
The total number of users
Value of user j
Number of attributes
The set of all attributes
Attribute i
Number of possible values for attribute ai
The full contingency table
Some set of attributes
The marginal table of attribute set A
Number of marginal tables output by our method
Size of each marginal table in our method
Table 1: List of Notations
the full view of the whole dataset. To construct the marginal tables
Figure 1(c,d), one can let each user report the two values (using an
FO as described earlier), aggregate the users’ reports to construct
the full contingency table (with some noise), and build the marginal
tables. This method is more formally described in the following.
See Table 1 for the list of notations.
3.3 Full Contingency Table Method (FC)
To estimate M, one straightforward approach is to estimate the
full contingency table F first, and then construct M from F. We
call this approach the Full Contingency (FC) table method. In this
method, each user reports her value v ∈ D using an FO protocol.
The aggregator estimates the frequency of each value in the full
domain. Once having the full contingency table, the aggregator can
compute any k-way marginal.
The main shortcoming of FC is that, since one has to query the
frequency of each value in the full domain of all attributes, the time
complexity and space complexity grows exponentially with the
number of attribute d and can be prohibitively expensive.
Furthermore, even when it is feasible to construct the full con-
tingency table, computing marginals from a noisy full contingency
table can have high variance. For example, suppose we have 32
binary attributes, the domain size is thus 232. When constructing a
4-way marginal, each value in the 4-way marginal is the result of
summing up 228 noisy entries in the full contingency table. Let Var0
be the variance of estimating each single cell in the full contingency
table, the variance of each cell in the reconstructed marginal is then
228 × Var0, and the expected SSE is 24 × 228 × Var0 = 232 × Var0.
In general, the variance of computing k-way marginals from the
noisy full contingency table is
VarFC = 2d · Var0
(4)
3.4 All Marginal Method (AM)
To mitigate the exponential dependency on d, one can construct
all the k-way marginals directly. There are two alternatives, one
is to divide the privacy budget ϵ into (cid:0)d
user reports (cid:0)d
is to divide the user population into (cid:0)d
k(cid:1) pieces, and have each
k(cid:1) times, once for each k-way marginal. The second
k(cid:1) disjoint groups, and have
users in each group report one k-way marginal. Under the LDP
setting, it is generally better to divide the population than dividing
the privacy budget, because reporting under low privacy budget is
very noisy [26, 37, 38].
Under LDP, estimating fraction frequencies is less accurate with
a smaller group than with a larger group, because the noises have
larger impact when the true counts are small. The variance is in-
versely proportional to the group size. Thus dividing the population
into (cid:0)d
k(cid:1) groups will add a (cid:0)d
results in the following variance.
k(cid:1) factor to the variance. This factor
VarAM = 2k · (cid:18)d
k(cid:19) · Var0
When k is relatively small (and hence (cid:0)d
(5)
better than FC; when k is large, AM could perform worse than FC.
Another limitation of this method is that one has to specify the
value k ahead of time. After the protocol is executed, there is no
way to answer any t-way marginal queries for t > k.
k(cid:1) is small), AM performs
3.5 Fourier Transformation Method (FT)
Fourier Transformation (FT) was used for publishing k-way
marginals in the centralized setting [5]. Kulkarni et al. [11] applied
the technique to the local setting. Effectively, it is an optimization
of the AM method. The motivation underlying FT is that, the calcu-
lation of a k-way marginal requires only a few coefficients in the
Fourier domain. Thus, users can submit noisy Fourier coefficients
that are needed to compute the desired k-way marginals, instead
of values in those marginals.
This method results in slightly lower variance than AM. How-
ever, in order to reconstruct all k-way marginals, a large number
of coefficients need to be estimated; thus this method would still
perform poorly when k is large. Furthermore, the method is de-
signed to deal with the binary attributes. Therefore, the non-binary
attributes must be pre-processed to binary attributes, resulting in
more dimensions. For example, an attribute with c values has to be
transformed into ⌈log2 c⌉ binary attributes.
The details of FT are presented in Appendix A.1. Here, we briefly
analyze its variance. Specifically, there are k
be estimated. Estimating TA(v) requires information for a selected
set of 2k coefficients, each multiplied by 2−k . Therefore, this method
has variance
s(cid:1) coefficients to
s =0 (cid:0)d
VarFT =
k
s =0 (cid:18)d
s(cid:19) · Var0
(6)
3.6 Expectation Maximization Method (EM)
This method allows each user to upload the value for each attribute
separately with split privacy budget. The aggregator then conducts
Expectation Maximization (EM) algorithm to reconstruct the mar-
ginal tables. This approach is first introduced by Fanti et al. [17] for
estimating joint distribution for two attributes, and then generalized
by Ren et al. [31] to handle multiple attributes.
Specifically, denote y j = ⟨y
⟩ as the report from user
j. The algorithm attempts to guess the private value distribution
TA, for any A, by maximizing the probability y j are reported from
user j.
j
2, . . . , y
j
1, y
j
d
The original EM algorithm runs slowly. Therefore, we use the
algorithm proposed in the appendix of [38] to help compute TA.
In most cases, if the initial values are set using the result returned
by this algorithm, the EM algorithm finishes quickly. Specifically,
this algorithm first estimates the value distribution for any single
attribute, and then uses that estimation to estimate distribution for
any pair of attributes, and so on. The method is proven to produce
unbiased estimation.
The detailed protocol of EM is given in Appendix A.2. Overall,
the EM method has the advantage of being able to compute t-way
marginals for any t. But since ϵ is split into each attribute, this
method has large variance.
4 CALM: CONSISTENT ADAPTIVE LOCAL
MARGINAL
In this section, we describe our proposed method CALM (Consis-
tent Adaptive Local Marginal) for publishing k-way marginal via
LDP. Our method is inspired by the PriView method for publish-
ing marginal under the centralized DP setting [29], so we describe
PriView first.
4.1 An Overview of PriView
The PriView method was designed for privately computing arbi-
trary k-way marginals for a dataset with d binary attributes in the
centralized setting. PriView privately publishes a synopsis of the
dataset. Using the synopsis, it can reconstruct any k-way marginal.
The synopsis takes the form of m size-ℓ marginals that are called
views. Below we give an overview of the PriView method, using an
example where there are d = 8 attributes {a1, a2, · · · , a8}, and we
aim to answer all 3-way marginals. PriView has the following four
steps. (See [29] for complete specification of PriView.)
Choose the Set of Views. The first step is to choose which
marginals to include in the private synopsis as views. That is, one
needs to choose m sets of attributes. PriView chooses these sets so
that each size-2 (or size-3) marginal is covered by some view. For
example, if aiming to cover all 2-way marginals, then one could
choose the following m = 6 sets of attributes to construct views:
{a1, a2, a3, a4}
{a4, a6, a7, a8}
{a1, a5, a6, a7}
{a2, a3, a6, a7}
{a2, a3, a5, a8}
{a1, a4, a5, a8}
Observe that any pair of two attributes are included in at least one
set.
Generate Noisy Views. In this step, for each of the m attribute
sets, PriView constructs a noisy marginal over the attributes in the
set, by adding Laplace noise Lap (cid:0) m
table. This is the only step that needs direct access to the dataset.
After this step, the dataset is no longer accessed.
ϵ (cid:1) to each cell in the marginal
Consistency Step. Given these noisy marginals/views, some 3-
way marginals can be directly computed. For example, to obtain
the 3-way marginal for {a1, a2, a3}, we can start from the view
for {a1, a2, a3, a4} and marginalizes out a4. However, many 3-way
marginal are not covered by any of the 6 views. For example, if
we want to compute the marginal for {a1, a3, a5}, we have to rely
on partial information provided by the 6 views. We can compute
the marginals for {a1, a3}, {a1, a5}, and {a3, a5}, and then combine
them to construct an estimation for {a1, a3, a5}.
Observe that {a1, a5} can be computed both by using the view for
{a1, a5, a6, a7} and by using the view for {a1, a4, a5, a8}. Since in-
dependent noises are added to the two marginals, the two different
ways to compute marginal for {a1, a5} most likely have different re-
sults. In addition, the noisy marginals may contain negative values.
PriView performs constrained inference on the noisy marginals
to ensure that the marginals in the synopsis are all non-negative
and mutually consistent. (For self-containment, we included the
description of the consistency step in Appendix A.3.)
Generating k-way Marginals. From the m consistent views, one
can reconstruct any k-way marginals. When given a set of k at-
tributes, if all k attributes are included in one view, then we can
compute the k-way marginal directly. When no view includes all
k attributes, PriView uses Maximum Entropy estimation to com-
pute the k-way marginal. For example, when given the marginals
for {a1, a3}, {a1, a5}, and {a3, a5}, Maximum Entropy estimation
finds among all possibles marginals for {a1, a3, a5} that are consis-
tent with the three known marginals, the one with the maximum
entropy. Note that while the marginal for {a1, a3, a5} have 7 un-
knowns (the 8 cells must sum up to 1), and each marginal over
{a1, a3}, {a1, a5}, and {a3, a5} gives 3 equations, these equations
are not independent. In this case, the three 2-way marginals to-
gether give 6 independent linear constraints on the 7 unknowns,
leaving one degree of freedom.
Discussions. Using the PriView method, one could answer k-way
marginals for arbitrary k values. For a k-way marginal computed
by PriView, there are two sources of errors. Noise Errors are due
to the Laplacian noises added to satisfy DP. Reconstruction Errors
are due to the fact that one has to estimate a k-way marginal from
partial information.
Two important algorithmic parameters affect the magnitude
of these two kinds of errors. They are the number m of
marginals/views in the synopsis, and the size ℓ (i.e., number of
attributes) of these views. With a larger ℓ, the views cover more
combinations of attributes, reducing Reconstruction Errors. How-
ever, one would be summing over more noisy entries to compute
any marginal, increasing the Noise Errors. Similarly, a larger m
means more marginals and better coverage of combinations of at-
tributes, which reduces Reconstruction Errors. However, a larger m
also means less privacy budget for each marginal and higher Noise
Errors. Consider the running example with 8 attributes, by using
14 (instead of 6) size-4 marginals, one can ensure that any set of 3
attributes is covered by at least one of the marginals, eliminating
Reconstruction Errors. However, this is done at the cost of adding
noises sampled from Lap (cid:16) 14