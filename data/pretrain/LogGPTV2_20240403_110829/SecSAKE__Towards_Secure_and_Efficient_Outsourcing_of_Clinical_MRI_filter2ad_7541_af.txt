252.
[12] Xinyu Lei, Xiaofeng Liao, Tingwen Huang, and Feno Heriniaina. 2014. Achieving
security, robust cheating resistance, and high-efficiency for outsourcing large
matrix multiplication computation to a malicious cloud. Information sciences 280
(2014), 205–217.
[13] Xinyu Lei, Xiaofeng Liao, Tingwen Huang, Huaqing Li, and Chunqiang Hu.
2013. Outsourcing large matrix inversion computation to a public cloud. IEEE
Transactions on cloud computing 1, 1 (2013), 1–1.
[14] Weixian Liao, Wei Du, Sergio Salinas, and Pan Li. 2016. Efficient Privacy-
Preserving Outsourcing of Large-Scale Convex Separable Programming for Smart
Cities. In High Performance Computing and Communications; IEEE 14th Interna-
tional Conference on Smart City; IEEE 2nd International Conference on Data Science
and Systems (HPCC/SmartCity/DSS), 2016 IEEE 18th International Conference on.
IEEE, 1349–1356.
[15] Michael Lustig. 2016. ESPIRiT: Reference Implementation of Compressed Sensing
(March 2016). Retrieved Jun 20, 2016 from
and Parallel Imaging in Matlab.
https://people.eecs.berkeley.edu/~mlustig/software
[16] Michael Lustig. 2017. MR Datasets for Compressed Sensing. (Dec. 2017). Retrieved
Dec, 2017 from http://mridata.org/undersampled
man & Hall/CRC.
[17] Michael Lustig, Kurt Keutzer, and Shreyas Vasanawala. 2013. Introduction to
parallelizing compressed sensing magnetic resonance imaging. The Berkeley
par lab: progress in the parallel computing landscape. Redmond, WA: Microsoft
Corporation (2013), 105–139.
[18] Michael Lustig and John M Pauly. 2010. SPIRiT: Iterative self-consistent parallel
imaging reconstruction from arbitrary k-space. Magnetic resonance in medicine
64, 2 (2010), 457–471.
[19] Rajeev Motwani and Prabhakar Raghavan. 2010. Randomized algorithms. Chap-
[20] Haixin Nie, Xiaofeng Chen, Jin Li, Josolph Liu, and Wenjing Lou. 2014. Efficient
and verifiable algorithm for secure outsourcing of large-scale linear programming.
In Advanced Information Networking and Applications (AINA), 2014 IEEE 28th
International Conference on. IEEE, 591–596.
[21] Klaas P Pruessmann, Markus Weiger, Markus B Scheidegger, Peter Boesiger, et al.
1999. SENSE: sensitivity encoding for fast MRI. Magnetic resonance in medicine
42, 5 (1999), 952–962.
[22] Zhan Qin, Jingbo Yan, Kui Ren, Chang Wen Chen, and Cong Wang. 2014. Towards
efficient privacy-preserving image feature extraction in cloud computing. In
Proceedings of the 22nd ACM international conference on Multimedia. ACM, 497–
506.
[23] Sergio Salinas, Changqing Luo, Xuhui Chen, and Pan Li. 2015. Efficient secure out-
sourcing of large-scale linear systems of equations. In Computer Communications
(INFOCOM), 2015 IEEE Conference on. IEEE, 1035–1043.
[24] Sergio Salinas, Changqing Luo, Xuhui Chen, Weixian Liao, and Pan Li. 2017.
Efficient secure outsourcing of large-scale sparse linear systems of equations.
IEEE Transactions on Big Data (2017).
[25] Sergio Salinas, Changqing Luo, Weixian Liao, and Pan Li. 2016. Efficient secure
outsourcing of large-scale quadratic programs. In Proceedings of the 11th ACM on
Asia Conference on Computer and Communications Security. ACM, 281–292.
[26] Peter J Shin, Peder EZ Larson, Michael A Ohliger, Michael Elad, John M Pauly,
Daniel B Vigneron, and Michael Lustig. 2014. Calibrationless parallel imag-
ing reconstruction based on structured low-rank matrix completion. Magnetic
resonance in medicine 72, 4 (2014), 959–970.
[27] Cong Wang, Kui Ren, and Jia Wang. 2011. Secure and practical outsourcing of
linear programming in cloud computing. In INFOCOM, 2011 Proceedings IEEE.
IEEE, 820–828.
[28] Cong Wang, Kui Ren, Jia Wang, and Qian Wang. 2013. Harnessing the cloud for
securely outsourcing large-scale systems of linear equations. IEEE Transactions
on Parallel and Distributed Systems 24, 6 (2013), 1172–1181.
[29] Cong Wang, Bingsheng Zhang, Kui Ren, and Janet M Roveda. 2013. Privacy-
assured outsourcing of image reconstruction service in cloud. IEEE Transactions
on Emerging Topics in Computing 1, 1 (2013), 166–177.
[30] Katherine L Wright, Jesse I Hamilton, Mark A Griswold, Vikas Gulani, and Nicole
Seiberlich. 2014. Non-Cartesian parallel imaging reconstruction. Journal of
Magnetic Resonance Imaging 40, 5 (2014), 1022–1040.
[31] Yihua Zhang and Marina Blanton. 2014. Efficient secure and verifiable outsourc-
ing of matrix multiplications. In International Conference on Information Security.
Springer, 158–178.
[32] Lifeng Zhou and Chunguang Li. 2016. Outsourcing eigen-decomposition and
singular value decomposition of large matrix to a public cloud. IEEE Access 4
(2016), 869–879.
Session 13: Privacy 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea548A APPENDIX
A.1 Proof of Theorem 4.1
Proof. We separately show the probability of getting a false
positive error and a false negative error in the cheating detection
phase.
1) Consider the case that U′Σ′V′ = ˜A′
n:
(V′
rj ) − ˜A′
U′Σ′
(U′Σ′V′ − ˜A′
nrj =
n )rj = 0
(34)
Hence, the probability of returning ’false’ for a correct ˜A′ is always
0.
Let Z = U′Σ′V′ − ˜A′
n and D = Zrj. Then there exist at least one
non-zero entry zvw in Z. Note that the vth element of D can be
represented by:
2) Consider the other case, i.e. U′Σ′V′ (cid:44) ˜A′
n:
dv = zv1r1 + zv2r2 + ... + zvw rw + ... + zvprp
(35)
Let m = dv − zvw rw , then the chance the corresponding entry is
zero can be described as:
P (dv = 0) = P (dv = 0|m = 0)P (m = 0) + P (dv = 0|m (cid:44) 0)P (m (cid:44) 0)
= P (rw = 0)P (m = 0) + P (rw = 1, zvw rw = −m)P (m (cid:44) 0)
≤ 1
2 P (m = 0) +
1
2 (1 − P (m = 0)) =
(36)
Hence, P (D = 0) ≤ 1
2. After repeating the above process by l times,
the probability that a false result passes the Algorithm 3 is less than
1
□
2l
A.2 Proof of Theorem 4.2
1
2
Proof. Similarly, we show the probability of getting a false
positive error and a false negative error in the cheating detection
phase, respectively.
.
1) Consider the case that ˆNˆx′
τ(cid:88)
k
ˆNψ − ζ = ˆN
τ(cid:88)
= Mk:
tk ˆx′
k − τ(cid:88)
k =1
tk ( ˆNˆx′
k =1
k − Mk)
=
k =1
tk Mk
(37)
Hence, the probability of returning ’false’ is always 0, if every
included M is correct.
2) Consider the other case, i.e. ˆNˆx′
k
(cid:44) Mk:
Without the loss of generality, we assume that the very first entry
of ˆNψ and ζ is different. Suppose zk = ˆNˆx′
[1][1] − Mk[1][1]. If it
still holds that ˆNψ = ζ , this equation can be represented by the
τ(cid:88)
followings:
τ(cid:88)
k
ˆNψ11 − ζ11 = 0 =
(38)
tk zk = t1z1 +
tk zk
k =2
k =1
Hence,
t1 = −z−1
1 (
τ(cid:88)
k =2
tk zk )
If every tk has been fixed except for t1, the chance that ˆNψ11 − ζ11
would be equivalent with a random selection over the field {0, 1}l′,
2l′ . Note that if there are less than τ − 1 of tk are fixed, the
i.e. 1
probability of ˆNψ11 − ζ11 holds will be less than 1
2l′ .
□
1
ij
0λiaijγj.
Proof. Note that the encryption represented by Equation (7)
A.3 Proof of Theorem 6.1
can be translated into ˜aij = η0η′
Suppose the probabilistic polynomial-time adversary A holds a
0
pair of arbitrary numbers with the same length n, denoted as a
ij
. Then A outputs these two numbers to the oracle, who later
and a
choses a random bit b from {0, 1} and computes η0η′
ijγj. A then
guesses the chosen bit as b′ by obtaining the result from oracle.
The experiment outputs 1 if b′ = b, or 0 otherwise.
Let the possibility that A can output 1 in the above experiment
to be 1
2 + p(n). If the encryption function is truly random, the
probability A outputs 1 is at most 1
2 + q (n)2 , where q(n) is the
number of oracle queries made by A. There exists a Distinguisher
D who has the access to the oracle. D makes guesses on whether
the encryption function is pseudorandom or truly random based
on the output of the previous experiment. Then D’s distinguishing
probability can be described as:
0λiab
| 1
2 +
q(n)
2 − (
1
2 + p(n))| =
q(n)
2 − p(n)
(40)
which is known as negligible. Hence, p(n) is negligible and the
advantage that A can make a correct guess is negligible over 1
2. □
1Z1)[Tˆr (Q∗
1Z2)]∗
Proof. We firstly show that the aggregated shares after the low-
rankness projection is δ times the reconstructed data matrix in
A.4 Correctness of Equation (26)
Section 4.2, i.e. ˆA0 = (1/δ )(cid:80)3
3(cid:88)
ˆAl0. Simply,
l =1
|| − Tˆr (P∗
1Z1)]Σ′
[V′′
|| + Tˆr (Q∗
1Z2)]∗
ˆr
[V′′
1Z2)]∗ + Tˆr (P∗
|| − Tˆr (Q∗
1Z1)]Σ′
ˆr
ˆr V′′∗
||Σ′′
|| = δ ˆA0
1
2[U′′
ˆAl0 =
l =1
1
|| + Tˆr (P∗
2[U′′
ˆr V′′∗
||Σ′
= U′′
+
|| = δU′′
l =1 ˆxl0. Thus,
0 = (1/δ )(cid:80)3
(41)
According to the definition of the H†, the projection onto the k-
space domain relates to the average values on the anti-diagonal
directions. Hence, H† is an linear operator and it also satisfies that
ˆx′
3(cid:88)
The linear operator Hw ensures (cid:80)3
1 =(cid:80)3
l =1
1 = δA1 and the asso-
ciative principle of matrix multiplication then guarantees that
′
˜A
□
x1 = Nˆx0 + D†y = (1/δ )N
l =1
l =1 Al
3(cid:88)
3(cid:88)
ˆxl0 +
Cl =
(42)
l =1
ˆxl1
′l1 .
l =1 ˜A
(39)
Hence, the Equation (26) allows the executor to get through the
SVD computation and proceed to the rest of the second loop.
Session 13: Privacy 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea549A.5 More details on Equation (31) and (33)
|Pr[D(R( ˆmi, j )) = 1] − Pr[D(R(ri, j )) = 1]|
(43)
)
(44)
= |Pr[R( ˆmi, j ) > cR(vj )]
+ Pr[R( ˆmi, j )  R(cvj − mi, j )]
+ Pr[R(zi, j ) < −R(cvj + mi, j )] − 1
2]|
≤ Ka/2cR(vj )
µ (κ) = 1 − (1 − Ka/2cR(vj ))(1 − Kb /2cI(vj ))
≤ 1 − (1 − 2n/2d +max{n,l }
≤ 21−d + 2−2d ≤ 22−d ≤ 2κ−max{n,l }−q+1
)(1 − 2l /2d +max{n,l }
Session 13: Privacy 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea550