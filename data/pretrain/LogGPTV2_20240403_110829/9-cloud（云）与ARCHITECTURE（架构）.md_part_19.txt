}
\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--
# logstash配置读取文件
https://www.elastic.co/guide/en/logstash/current/index.html 借助官网说明
\[root@logstash \~\]# rm -rf
/root/.sincedb_64c00e328863fd2a37ee9e00f33c59f2 #删默认读取位置文件
\[root@logstash \~\]# vim /etc/logstash/logstash.conf
input{
stdin{ codec =\> \"json\" }
file {
path =\> \[\"/tmp/a.log\"\]
sincedb_path =\> \"/var/logstash/since.db\"
#记录读取文件的位置,默认的要删掉,如上
start_position =\> \"beginning\" #//配置第一次读取文件从什么地方开始
type =\> \"testlog\" #打标签,类型名称
}
tcp {
mode =\> \"server\" #默认本身是server,写出来无歧义
host =\> \"0.0.0.0\"
port =\> 8888
type =\> \"tcplog\"
}
udp {
port =\> 8888
type =\> \"udplog\"
}
}
}
filter{
}
output{
stdout{ codec =\> \"rubydebug\" }
}
\[root@logstash \~\]# /opt/logstash/bin/logstash -f
/etc/logstash/logstash.conf
Settings: Default pipeline workers: 2
Pipeline main started
**另开终端可测试**
\[root@logstash \~\]# ss -ltun #另开终端可看到8888端口被监听
Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port
udp UNCONN 0 0 127.0.0.1:323 \*:\*
udp UNCONN 0 0 :::8888 :::\*
tcp LISTEN 0 128 \*:22 \*:\*
tcp LISTEN 0 50 :::8888 :::\*
\[root@logstash \~\]# echo A\_\[\$RANDOM\] \>\>/tmp/a.log
#发送随机数给/tmp/a.log
\[root@logstash \~\]# echo A\_\[\$RANDOM\] \>\>/tmp/a.log
\[root@logstash \~\]# echo 123 \>/dev/udp/192.168.1.25/8888
#发送udp消息给主机8888端口
\[root@logstash \~\]# echo 123 \>/dev/tcp/192.168.1.25/8888
#发送tcp消息给主机8888端口
\"message\" =\> \"A\_\[20125\]\",
\"@version\" =\> \"1\",
\"@timestamp\" =\> \"2019-03-26T07:39:25.296Z\",
\"path\" =\> \"/tmp/a.log\",
\"host\" =\> \"logstash\",
\"type\" =\> \"testlog\"
}
{
\"message\" =\> \"A\_\[9687\]\",
\"@version\" =\> \"1\",
\"@timestamp\" =\> \"2019-03-26T07:39:25.296Z\",
\"path\" =\> \"/tmp/a.log\",
\"host\" =\> \"logstash\",
\"type\" =\> \"testlog\"
}
{
\"message\" =\> \"123\\n\",
\"@version\" =\> \"1\",
\"@timestamp\" =\> \"2019-03-26T07:43:15.300Z\",
\"type\" =\> \"udplog\",
\"host\" =\> \"192.168.1.25\"
}
{
\"message\" =\> \"123\",
\"@version\" =\> \"1\",
\"@timestamp\" =\> \"2019-03-26T07:43:26.101Z\",
\"host\" =\> \"192.168.1.25\",
\"port\" =\> 40236,
\"type\" =\> \"tcplog\"
## 手动添加一个测试系统日志
\[root@web \~\]# vim /etc/rsyslog.conf
\...
local0.notice /var/log/test.log
\... #自己添加日志,等级为notice(第5级),日志路径为:/var/log/test.log
\[root@web \~\]# systemctl restart rsyslog
\[root@web \~\]# logger -p local0.notice -t nsd \"test\"
#发送"test"给test.log日志
\[root@web \~\]# cat /var/log/test.log #查看日志
Mar 26 15:55:58 web nsd: test #刚刚发送的日志内容
## 启用syslog模块(读取系统日志文件)
\[root@logstash \~\]# vim /etc/logstash/logstash.conf
input{
stdin{ codec =\> \"json\" }
file {
path =\> \[\"/tmp/a.log\"\]
sincedb_path =\> \"/var/logstash/since.db\"
start_position =\> \"beginning\"
type =\> \"testlog\"
}
tcp {
mode =\> \"server\"
host =\> \"0.0.0.0\"
port =\> 8888
type =\> \"tcplog\"
}
udp {
port =\> 8888
type =\> \"udplog\"
}
syslog {
type =\> \"syslog\" #添加
}
}
filter{
}
output{
stdout{ codec =\> \"rubydebug\" }
}
**web主机配置**
\[root@web \~\]# vim /etc/rsyslog.conf
local0.notice /var/log/test.log
local0.notice @@192.168.1.25:514
> #将日志内容发送给远程主机一个@表示udp 两个@表示tcp
\[root@web \~\]# systemctl restart rsyslog #重启rsyslog
\[root@web \~\]# logger -p local0.notice -t TESTLOG aabbccdd
#手动发送日志消息
**logstash主机查看到,发送的日志消息**
{
\"message\" =\> \"aabbccdd\\n\",
\"@version\" =\> \"1\",
\"@timestamp\" =\> \"2019-03-26T08:02:03.000Z\",
\"type\" =\> \"syslog\",
\"host\" =\> \"192.168.1.20\",
\"priority\" =\> 133,
\"timestamp\" =\> \"Mar 26 16:02:03\",
\"logsource\" =\> \"web\",
\"program\" =\> \"TESTLOG\",
\"severity\" =\> 5,
\"facility\" =\> 16,
\"facility_label\" =\> \"local0\",
\"severity_label\" =\> \"Notice\"
}
\[12\]?\[0-9\]?\[0-9\]\\.
## 取用apache的日志
input{
stdin{ codec =\> \"json\" }
file {
path =\> \[\"/tmp/a.log\"\]
sincedb_path =\> \"/dev/null\" #修改
start_position =\> \"beginning\"
type =\> \"testlog\"
}
tcp {
mode =\> \"server\"
host =\> \"0.0.0.0\"
port =\> 8888
type =\> \"tcplog\"
}
udp {
port =\> 8888
type =\> \"udplog\"
}
syslog {
type =\> \"syslog\"
}
}
filter{
grok {
match =\> { \"message\" =\> \"%{COMBINEDAPACHELOG}\" } #添加
}
}
output{
stdout{ codec =\> \"rubydebug\" }
}
\[root@logstash \~\]# vim /tmp/a.log
> #添加一条apache的access日志放到测试日志里,内容如下,清空之前的内容
192.168.1.254 - - \[15/Sep/2018:18:25:46 +0800\] \"GET / HTTP/1.1\" 403
4897 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:52.0) Gecko/20100101
Firefox/52.0\"
#apache日志在web主机的/var/log/httpd/access_log里面
\[root@logstash \~\]# /opt/logstash/bin/logstash -f
/etc/logstash/logstash.conf
Settings: Default pipeline workers: 2
Pipeline main started
{
\"message\" =\> \"192.168.1.254 - - \[26/Mar/2019:17:09:34 +0800\]
\\\"GET /favicon.ico HTTP/1.1\\\" 404 209 \\\"http://192.168.1.20/\\\"
\\\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like
Gecko) Chrome/60.0.3112.113 Safari/537.36\\\"\",
\"@version\" =\> \"1\",
\"@timestamp\" =\> \"2019-03-26T09:12:11.310Z\",
\"path\" =\> \"/tmp/a.log\",
\"host\" =\> \"logstash\",
\"type\" =\> \"testlog\",
\"clientip\" =\> \"192.168.1.254\",
\"ident\" =\> \"-\",
\"auth\" =\> \"-\",
\"timestamp\" =\> \"26/Mar/2019:17:09:34 +0800\",
\"verb\" =\> \"GET\",
\"request\" =\> \"/favicon.ico\",
\"httpversion\" =\> \"1.1\",
\"response\" =\> \"404\",
\"bytes\" =\> \"209\",
\"referrer\" =\> \"\\\"http://192.168.1.20/\\\"\",
\"agent\" =\> \"\\\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36
(KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36\\\"\"
}
# ELK整合实验(\*\*重点实施\*\*)
web访问,将access日志推送给logstash,,,logstash将数据接收,处理,输出给Elasticsearch数据库存储,最后由kibana在终端显示
现已将环境准备好了,具体如下:
192.168.1.10 为kibana
192.168.1.11-192.168.1.15为elasticsearch
192.168.1.20 为web
192.168.1.25 为logstash
每台主机配置了/etc/hosts 文件, 配置了yum源,,其中有个源是自己做的
\[root@logstash \~\]# yum repolist
已加载插件：fastestmirror
Loading mirror speeds from cached hostfile
源标识 源名称 状态
esl esl 4
local_repo CentOS-7 - Base 4,986
repolist: 4,990
## ES集群安装配置步骤
1.配置所有的IP地址
a)192.168.11-192.168.1.15
b)主机名分别是:esl esl2 esl3 esl4 esl5
c)将所有主机的/etc/hosts文件将所有主机名与IP对应好
2.制作yum源.在192.168.1.254真机的ftp目录//var/ftp/elk目录放有所有所需安装包,并做好了yum源
\[root@room9pc01 \~\]# ls /var/ftp/esl/
accounts.json.gz elasticsearch-head-master.zip kibana-4.5.2-1.x86_64.rpm
shakespeare.json.gz
alog.gz elasticsearch-kopf-master.zip logs.jsonl.gz
bigdesk-master.zip elk.tar logstash-2.3.4-1.noarch.rpm
elasticsearch-2.3.4.rpm filebeat-1.2.3-x86_64.rpm repodata
注:做yum源的命令为:\~\]# createrepo 安装包所以在目录 #在当前目录可用点.
代替
3\. 安装
a)yum -y install java-1.8.0-openjdk
b)yum -y install elasticsearch-2.3.4.rpm
4.vim /etc/elasticsearch/elasticsearch.yml
cluster.name: nsd1811
node.name: {{ansible_hostname}}
discovery.zen.ping.unicast.hosts: \[\"esl\", \"esl2\", \"esl3\"\]
## web:服务器的配置:
web地址:192.168.1.20
1.安装filebeat
\[root@web \~\]# yum -y install filebeat
\[root@web \~\]# vim /etc/filebeat/filebeat.yml
paths:
\- /var/log/httpd/access_log //日志的路径，短横线加空格代表yml格式
document_type: apachelog //文档类型
elasticsearch: //加上注释
hosts: \[\"localhost:9200\"\] //加上注释
logstash: //去掉注释
hosts: \[\"192.168.1.67:5044\"\] //去掉注释,logstash那台主机的ip
\[root@web \~\]# systemctl start filebeat
## logstash:服务器配置
logstash地址:192.168.1.25
\[root@logstash \~\]# vim /etc/logstash/logstash.conf
input{
stdin{ codec =\> \"json\" }
beats{
port =\> 5044
}
file {
path =\> \[\"/tmp/a.log\"\]
sincedb_path =\> \"/dev/null\"
start_position =\> \"beginning\"
type =\> \"testlog\"
}
tcp {
mode =\> \"server\"
host =\> \"0.0.0.0\"
port =\> 8888
type =\> \"tcplog\"
}
udp {
port =\> 8888
type =\> \"udplog\"
}
syslog {