# Evaluation of Causal Inference Techniques for AIOps

**Authors:**
- V. Arya¹, K. Shanmugam², P. Aggarwal¹, Q. Wang², P. Mohapatra¹, S. Nagar¹
- IBM Research AI (India¹, USA²)

## Abstract
Inferring causality from log data is crucial for IT operations teams, who continuously strive to identify the probable root causes of events in order to quickly resolve incident tickets and minimize downtime and service interruptions. Although prior work has applied specific causal inference techniques on proprietary log data, they fail to benchmark the performance of different techniques on a common system or dataset. In this work, we evaluate the performance of multiple state-of-the-art causal inference techniques using log data obtained from a publicly available benchmark microservices system. We model the log data both as a time series of error counts and as a temporal event sequence, and evaluate three families of Granger causal techniques: regression-based, independence testing-based, and event models. Our preliminary results indicate that event models yield causal graphs with high precision and recall compared to regression and independence testing-based Granger methods.

## CCS Concepts
- Computing Methodologies → Causal Reasoning and Diagnostics

## Keywords
Causal Inference, Granger Causality, AIOps, IT Operations, Log Data

## ACM Reference Format
V. Arya¹, K. Shanmugam², P. Aggarwal¹, Q. Wang², P. Mohapatra¹, S. Nagar¹. 2021. Evaluation of Causal Inference Techniques for AIOps. In 8th ACM IKDD CODS and 26th COMAD (CODS-COMAD 2021), January 2–4, 2021, Bangalore, India. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3430984.3431027

## 1. Introduction
AIOps (AI for IT Operations) solutions aim to automate the monitoring of large, complex enterprise application environments and their supporting infrastructure. By ingesting data from various sources such as applications, infrastructure, networks, clouds, and existing monitoring tools, these integrated solutions promise to provide a wide variety of functions to minimize service outages and assist site reliability engineering teams with rapid incident resolution [18]. These functions generally include anomaly detection, event correlation, prediction and prevention of emerging incidents, reduction in false alarms or alert/ticket storms, and root cause analysis. A key component needed to implement most of these functions is the ability to determine the causality of events from historical log data. 

While prior work has studied the problem of inferring causal relationships from log data in the context of ISP networks [13, 14], data centers [15], and search engine query logs [28], these works apply specific causal inference techniques on proprietary data and fail to compare the performance of different techniques on a common system or a publicly available log dataset. As a consequence, it becomes challenging to replicate results or understand the advantages and disadvantages of different causal inference techniques and recommend the right one in the context of a new IT environment. Moreover, prior work primarily models log data as a time series and applies variants of the PC algorithm [12] based on independence testing or variants of regression-based Granger causality tests [9] to infer causal relationships among events. This modeling choice limits the range of causal inference techniques that can be subsequently applied to log data.

In this work, we compare the performance of three families of Granger causal inference techniques and their variants on a benchmark TrainTicket microservice system that is publicly available [34–36]: (a) PC algorithm based on independence tests and its variants, (b) variants of regression-based techniques, and (c) graphical event models [3, 10]. While in the first two approaches, the log data is modeled as a time series, in the third approach, the log data is modeled as a temporal event sequence, and we leverage recently proposed graphical event models to infer causal relationships. We present preliminary performance results of different Granger causal inference techniques on a log dataset that spans half an hour and is obtained by injecting a fault in one of the microservices in the benchmark system, which includes a total of 41 microservices. With the help of ground truth data, we compute the precision, recall, and F1 scores of the inferred causal graphs among a subset of impacted microservices.

We view the main contributions of this work as follows:
- Using log data collected from a publicly available benchmark microservices system, we investigate the performance of different Granger causal inference algorithms and present preliminary evaluation results for different variants of each algorithm. In addition to modeling the log data as a time series, which is commonly used in prior work, we also model it as a temporal event sequence and present accuracy results for the recently proposed graphical event models.
- Our preliminary experimental results show that event models generally yield causal graphs with high precision and recall compared to other approaches. However, regression and independence testing-based Granger methods have parameters that may be fine-tuned to improve performance.

The rest of this paper is organized as follows. Section 2 briefly describes the benchmark microservices system and the modeling of log data. Section 3 provides an overview of the three families of Granger causal inference techniques. Section 4 presents the experimental results, and we conclude in Section 5 with directions for future work.

## 2. Log Data and Modeling
### Benchmark Microservice System
In this work, we use a publicly available benchmark TrainTicket microservices system and deploy it on a Kubernetes cluster to collect log data. This system has about 41 microservices that work together and allow users to reserve train tickets, make payments, enter stations, etc. Several microservices in the TrainTicket system interact with one another, resembling microservices systems commonly seen in large enterprises.

### Modeling Logs
To avoid introducing errors in labeling, we first evaluate the performance of different causal inference methods in the absence of any label noise. We model the log data in two ways:

#### Modeling Logs as a Time Series
We consider different time bin sizes (10ms, 100ms, 1sec) and count the number of error logs in each bin to obtain a time series of error counts corresponding to each impacted microservice (e.g., see Figure 1(b)).

#### Modeling Logs as an Event Sequence
We construct a tuple sequence \(\{(t_i, l_i)\}\) where \(t_i\) refers to the time at which the error log of microservice \(l_i\) occurs. We consider unique tuples only, i.e., if more than one error log of the same microservice is recorded at the same time, only one tuple is retained. However, if error logs of different microservices occur at the same time, all of them are retained.

Our goal is to infer the causal graph among the microservices that have been impacted by the fault to aid in root cause analysis. Figure 1(c) shows a sample graph that explains how errors in one microservice are caused by errors in another microservice. The next section briefly reviews the three families of causal inference techniques that we evaluate in our experiments.

## 3. Overview of Granger Causality for Time Series and Event Sequences
### Intuitive Idea of Granger Causality
The intuitive idea of Granger causality [9] is that if the time series A Granger causes time series B, the past of A has additional information about the future of B over and above the information contained in the past of time series B. This criterion could be used to verify if a "causal" relationship exists between time series A and B. Since the criterion is purely associational (as opposed to an interventional notion popular in other causal theories [11, 19]) but applied with the aid of the arrow of time, this notion is often called Granger causality to distinguish it from interventional notions.

### 3.1 Regression-Based Approaches
Regression-based approaches involve fitting a regression model to the time series data and using statistical tests to determine if the inclusion of past values of one time series improves the prediction of another. These methods are widely used due to their simplicity and interpretability.

### 3.2 Independence Testing-Based Approaches
Independence testing-based approaches, such as the PC algorithm [12], use conditional independence tests to construct a causal graph. These methods are non-parametric and can handle non-linear relationships, but they can be computationally intensive.

### 3.3 Graphical Event Models
Graphical event models [3, 10] represent the log data as a sequence of events and use probabilistic graphical models to infer the causal relationships. These models are particularly useful for capturing the temporal dependencies and can handle the sparsity of event sequences.

## 4. Experimental Results
### Experimental Setup
We inject a fault in one of the microservices in the benchmark system and collect log data spanning half an hour. We then apply the three families of Granger causal inference techniques to this dataset and evaluate their performance using precision, recall, and F1 scores.

### Preliminary Results
Our preliminary results indicate that event models yield causal graphs with high precision and recall compared to regression and independence testing-based Granger methods. However, regression and independence testing-based Granger methods have parameters that can be fine-tuned to improve performance.

## 5. Conclusion and Future Work
In this work, we evaluated the performance of multiple state-of-the-art causal inference techniques on a publicly available benchmark microservices system. Our preliminary results suggest that event models are effective in inferring causal relationships from log data. Future work will focus on further refining the parameters of the regression and independence testing-based methods and exploring the scalability of these techniques to larger and more complex systems.

## References
[References listed here]

---

This version of the text is more structured, coherent, and professional, making it easier to read and understand.