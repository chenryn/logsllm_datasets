title:Automating Mimicry Attacks Using Static Binary Analysis
author:Christopher Kruegel and
Engin Kirda and
Darren Mutz and
William K. Robertson and
Giovanni Vigna
Automating Mimicry Attacks Using Static Binary Analysis
Christopher Kruegel and Engin Kirda
Technical University Vienna
PI:EMAIL, PI:EMAIL
Darren Mutz, William Robertson, and Giovanni Vigna
Reliable Software Group, University of California, Santa Barbara
{dhm,wkr,vigna}@cs.ucsb.edu
Abstract
Intrusion detection systems that monitor sequences of sys-
tem calls have recently become more sophisticated in
deﬁning legitimate application behavior. In particular, ad-
ditional information, such as the value of the program
counter and the conﬁguration of the program’s call stack
at each system call, has been used to achieve better char-
acterization of program behavior. While there is com-
mon agreement that this additional information compli-
cates the task for the attacker, it is less clear to which ex-
tent an intruder is constrained.
In this paper, we present a novel technique to evade the ex-
tended detection features of state-of-the-art intrusion de-
tection systems and reduce the task of the intruder to a
traditional mimicry attack. Given a legitimate sequence of
system calls, our technique allows the attacker to execute
each system call in the correct execution context by ob-
taining and relinquishing the control of the application’s
execution ﬂow through manipulation of code pointers.
We have developed a static analysis tool for Intel x86 bi-
naries that uses symbolic execution to automatically iden-
tify instructions that can be used to redirect control ﬂow
and to compute the necessary modiﬁcations to the envi-
ronment of the process. We used our tool to successfully
exploit three vulnerable programs and evade detection by
existing state-of-the-art system call monitors. In addition,
we analyzed three real-world applications to verify the
general applicability of our techniques.
Keywords: Binary Analysis, Static Analysis, Symbolic
Execution, Intrusion Detection, Evasion.
1 Introduction
One of the ﬁrst host-based intrusion detection systems [5]
identiﬁes attacks by ﬁnding anomalies in the stream of
system calls issued by user programs. The technique is
based on the analysis of ﬁxed-length sequences of sys-
tem calls. The model of legitimate program behavior is
built by observing normal system call sequences in attack-
free application runs. During detection, an alert is raised
whenever a monitored program issues a sequence of sys-
tem calls that is not part of the model.
A problem with this detection approach arises in situa-
tions where an attack does not change the sequence of sys-
tem calls. In particular, the authors of [17] observed that
the intrusion detection system can be evaded by carefully
crafting an exploit that produces a legitimate sequence of
system calls while performing malicious actions. Such
attacks were named mimicry attacks.
To limit the vulnerability of the intrusion detection sys-
tem to mimicry attacks, a number of improvements have
been proposed [4, 9, 14]. These improvements are based
on additional information that is recorded with each sys-
tem call. One example [14] of additional information is
the origin of the system call (i.e., the address of the in-
struction that invokes the system call). In this case, the
intrusion detection system examines the value of the pro-
gram counter whenever a system call is performed and
compares it to a list of legitimate “call sites.” The idea
was extended in [4] by incorporating into the analysis in-
formation about the call stack conﬁguration at the time of
a system call invocation.
A call stack describes the current status and a partial his-
tory of program execution by analyzing the return ad-
dresses that are stored on the program’s run-time stack.
To extract the return addresses, it is necessary to unwind
the stack, frame by frame. Figure 1 shows a number of
frames on a program stack and the chain of frame (base)
pointer references that are used for stack unwinding.
Checking the program counter and the call stack at each
system call invocation serves two purposes for the de-
fender. First, the check makes sure that the system call
USENIX Association
14th USENIX Security Symposium
161
Frame
N-1
Frame 
N
Function Parameters
Return Address N-1 
Frame Pointer N-1
Local Variables
Function Parameters
Return Address N
Frame Pointer N
Local Variables
Current
Frame Pointer
Current
Stack Pointer
Figure 1: Call stack and chain of frame pointers.
was made by the application code. This thwarts all code
injection attacks in which the injected code directly in-
vokes a system call. Second, after a system call has ﬁn-
ished, control is guaranteed to return to the original appli-
cation code. This is because the return addresses on the
stack have been previously veriﬁed by the intrusion detec-
tion system to point to valid instructions in the application
code segment. This has an important implication. Even if
the attacker can hijack control and force the application
to perform a single system call that evades detection, con-
trol would return to the original program code after this
system call has ﬁnished.
The common agreement is that by including additional
information into the model, it is signiﬁcantly more difﬁ-
cult to mount mimicry attacks [3]. However, although ad-
ditional information undoubtedly complicates the task of
the intruder, the extent to which the attack becomes more
complicated is less clear. System-call-based intrusion de-
tection systems are not designed to prevent attacks (for
example, buffer overﬂows) from occurring. Instead, these
systems rely on the assumption that any activity by the
attacker appears as an anomaly that can be detected. Un-
fortunately, using these detection techniques, the attacker
is still granted full control of the running process. While
the ability to invoke system calls might be signiﬁcantly
limited, arbitrary code can be executed. This includes the
possibility to access and modify all writable memory seg-
ments.
The ability to modify program variables is in itself a sig-
niﬁcant threat. Consider, for example, an attacker that
alters variables that are subsequently used as open or
execv system call parameters. After the modiﬁcation,
the attacker lets the process continue. Eventually, a sys-
tem call is invoked that uses values controlled by the at-
tacker. Because the system call is made by legitimate ap-
plication code, the intrusion remains undetected.
In some cases, however, modifying program variables is
not sufﬁcient to compromise a process and the attacker is
required to perform system calls. Given the assumption
that an attacker has complete knowledge about the detec-
tion technique being used, it is relatively straightforward
to force the application to perform one undetected system
call. To do so, the attacker ﬁrst pushes the desired system
call parameters on the stack and then jumps directly to
the address in the application program where the system
call is done. Of course, it is also possible to jump to a li-
brary function (e.g., fopen or execlp) that eventually
performs the system call. Because it is possible for the
injected code to write to the stack segment, one can inject
arbitrary stack frames and spoof any desired function call
history. Thus, even if the intrusion detection system fol-
lows the chain of function return addresses (with the help
of the stored base pointers), detection can be evaded.
The problem from the point of view of the attacker is that
after the system call ﬁnishes, the checked stack is used to
determine the return address. Therefore, program execu-
tion can only continue at a legitimate program address and
execution cannot be diverted to the attacker code. As a
consequence, there is an implicit belief that the adversary
can at most invoke a single system call. This constitutes
a severe limitation for the intruder, since most attacks re-
quire multiple system calls to succeed (for example, a call
to setuid followed by a call to execve). This limi-
tation, however, could be overcome if the attacker were
able to somehow regain control after the ﬁrst system call
completed. In that case, another forged stack can be set
up to invoke the next system call. The alternation of in-
voking system calls and regaining control can be repeated
until the desired sequence of system calls (with parame-
ters chosen by the attacker) is executed.
For the purpose of this discussion, we assume that the at-
tacker has found a vulnerability in the victim program that
allows the injection of malicious code. In addition, we as-
sume that the attacker has identiﬁed a sequence of system
calls s1, s2, . . . , sn that can be invoked after a successful
exploit without triggering the intrusion detection system
(embedded within this sequence is the attack that the in-
truder actually wants to execute). Such a sequence could
be either extracted from the program model of the intru-
sion detection system or learned by observing legitimate
program executions. By repeatedly forcing the victim ap-
plication to make a single undetected system call (of a
legitimate sequence) and later regaining control, the pro-
tection mechanisms offered by additional intrusion detec-
tion features (such as checking return addresses or call
histories) are circumvented. Thus, the task of the intruder
162
14th USENIX Security Symposium
USENIX Association
is reduced to a traditional mimicry attack, where only the
order of system calls is of importance.
2 Related Work
In this paper, we present techniques to regain control ﬂow
by modifying the execution environment (i.e., modifying
the content of the data, heap, and/or stack areas) so that
the application code is forced to return to the injected at-
tack code at some point after a system call. To this end, we
have developed a static analysis tool that performs sym-
bolic execution of x86 binaries to automatically determine
instructions that can be exploited to regain control. Upon
detection of exploitable instructions, the code necessary
to appropriately set up the execution environment is gen-
erated. Using our tool, we successfully exploited sample
applications protected by the intrusion detection systems
presented in [4] and [14], and evaded their detection.
The paper makes the following primary contributions:
• We describe novel attack techniques against two
well-known intrusion detection systems [4, 14] that
evade the extended detection features and reduce the
task of the intruder to a traditional mimicry attack.
• We implemented a tool that allows the automated
application of our techniques by statically analyzing
the victim binary.
• We present experiments where our tool was used
to generate exploits against vulnerable sample pro-
grams. In addition, our system was run on real-world
applications to demonstrate the practical applicabil-
ity of our techniques.
Although our main contributions focus on the automated
evasion of two speciﬁc intrusion detection systems, an im-
portant point of our work is to demonstrate that, in gen-
eral, allowing attackers to execute arbitrary code can have
severe security implications.
The paper is structured as follows. In Section 2, we re-
view related work on systems that perform intrusion de-
tection using system calls. In Section 3, we outline our
techniques to regain control ﬂow. Section 4 provides an
in-depth description of our proposed static analysis and
symbolic execution techniques. In Section 5, we demon-
strate that our tool can be used to successfully exploit
sample programs without raising alarms. In addition, the
system is run on three real-world applications to under-
line the general applicability of our approach. Finally, in
Section 6, we brieﬂy conclude and outline future work.
System calls have been used extensively to characterize
the normal behavior of applications.
In [7], a classiﬁ-
cation is presented that divides system-call-based intru-
sion detection systems into three categories: “black-box”,
“gray-box”, and “white-box”. The classiﬁcation is based
on the source of information that is used to build the sys-
tem call proﬁles and to monitor the running processes.
Black-box approaches only analyze the system calls in-
voked by the monitored application without considering
any additional information. The system presented in [5],
which is based on the analysis of ﬁxed-length sequences
of system calls, falls into this category. Alternative data
models for this approach were presented in [18], while
the work in [19] lifted the restriction of ﬁxed-length se-
quences and proposed the use of variable-length patterns.
However, the basic means of detection have remained the
same.
Gray-box techniques extend the black-box approaches by
including additional run-time information about the pro-
cess’ execution state. This includes the origin of the sys-
tem call [14] and the call stack [4], as described in the
previous section. Another system that uses context in-
formation was introduced in [6]. Here, the call stack is
used to generate an execution graph that corresponds to
the maximal subset of the program control ﬂow graph that
one can construct given the observed runs of the program.
White-box techniques extract information directly from
the monitored program. Systems in this class perform
static analysis of the application’s source code or binary
image.
In [16], legal system call sequences are rep-
resented by a state machine that is extracted from the
control-ﬂow graph of the application. Although the sys-
tem is guaranteed to raise no false positives, it is vulner-
able to traditional mimicry attacks. Another problem of
this system is its run-time overhead, which turns out to
be prohibitively high for some programs, reaching sev-
eral minutes per transaction. This problem was addressed
in [8], using several optimizations (e.g., the insertion of
“null” system calls), and later in [9], where a Dyck model
is used. For this approach, additional system calls need to
be inserted, which is implemented via binary rewriting.
An approach similar to the one described in the previous
paragraph was introduced in [11]. In this work, system
call inlining and “notify” calls are introduced instead of
the “null” system calls. Also, source code is analyzed in-
stead of binaries. Another system that uses static analysis
to extract an automaton with call stack information was
presented in [3]. The work in this paper is based on the
gray-box technique introduced in [4]. In [20], waypoints
USENIX Association
14th USENIX Security Symposium
163
are inserted into function prologues and epilogues to re-
strict the types of system calls that they can invoke.
Black-box and gray-box techniques can only identify
anomalous program behavior on the basis of the previous
execution of attack-free runs. Therefore, it is possible that
incomplete training data or imprecise modeling lead to
false positives. White-box approaches, on the other hand,
extract their models directly from the application code.
Thus, assuming that the program does not modify itself,
anomalies are a deﬁnite indication of an attack. On the
downside, white-box techniques often require the analy-
sis of source code, which is impossible in cases where the
code is not available. Moreover, an exhaustive static anal-
ysis of binaries is often prohibitively complex [6].
This paper introduces attacks against two gray-box sys-
tems. Thus, related work on attacking system-call-based
detection approaches is relevant. As previously men-
tioned, mimicry attacks against traditional black-box de-
signs were introduced in [17]. A similar attack is dis-
cussed in [15], which is based on modifying the exploit
code so that system calls are issued in a legitimate order.
In [7], an attack was presented that targets gray-box intru-
sion detection systems that use program counter and call
stack information. This attack is similar to ours in that it is
proposed to set up of a fake environment to regain control
after the invocation of a system call. The differences with
respect to the attack techniques described in this paper are
twofold. First, the authors mention only one technique to
regain control of the application’s execution ﬂow. Second,
the process of regaining control is performed completely
manually. In fact, although the possibility to regain con-
trol ﬂow by having the program overwrite a return address
on the stack is discussed, no example is provided that uses
this technique. In contrast, this paper demonstrates that
attacks of this nature can be successfully automated using
static analysis of binary code.
3 Regaining Control Flow
In this section, we discuss possibilities to regain control
after the attacker has returned control to the application
(e.g., to perform a system call). To regain control, the
attacker has the option of preparing the execution envi-
ronment (i.e., modifying the content of the data, heap,
and stack areas) so that the application code is forced to
return to the attacker code at some point after the sys-
tem call. The task can be more formally described as
follows: Given a program p, an address s, and an ad-
dress t, ﬁnd a conﬁguration C such that, when p is exe-
cuted starting from address s, control ﬂow will eventually
reach the target address t. For our purposes, a conﬁgura-
tion C comprises all values that the attacker can modify.
This includes the contents of all processor registers and
all writable memory regions (in particular, the stack, the
heap, and the data segment). However, the attacker can-
not tamper with write-protected segments such as code
segments or read-only data.
Regaining control ﬂow usually requires that a code