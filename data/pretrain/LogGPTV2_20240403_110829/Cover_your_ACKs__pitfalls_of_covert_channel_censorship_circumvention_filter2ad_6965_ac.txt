and packet loss SkypeMorph implements its own retransmission
mechanisms adapted from TCP to ﬁt their trafﬁc shaping model.
The packetizer module in SkypeMorph has one thread for sending
packets and one for receiving packets, both of which handle packet
loss and retransmission. The sending thread ensures that packets
get ﬂagged as an ACK every 100 ms or so with the last sequence
number seen. The receiving thread keeps track of the last ACK
0246810012345Time (s)MOS365(a) Packet vs ACK Loss Rate
(b) ACK Loss Rate vs Bandwidth
(c) Packet Loss vs Bandwidth
Figure 4: While the censor is attempting to drop ACK packets in SkypeMorph, (a) shows percent of ACKs dropped with different caps on
packet loss rate (b) looks at how varying ACK loss rates effect overall bandwidth and (c) shows CDF of available bandwidth based on packet
loss rates.
Then the probability assigned to the actual packet is just the aver-
age of the probabilities computed over all paths belonging to that
packet.
4.3.2 Dropping ACKs
One avenue for distrupting the data transfer is for the censor to
drop as many ACK packets as possible, increasing the delay in re-
sponding to packet loss causing throughput to drop. First we ex-
plored the range of ACK loss rates that can be achieved for varying
packet loss rates. The packet dropping algorithm described was
implemented on the client side with overall packet loss capped at a
set rate. For each packet loss rate 100 downloads were performed
to get the distribution of ACK loss rates achieved. Figure 4a shows
these distributions for packet loss rates of 5, 10, 15 and 20%. Note
that out of all packet sent, a full 10% of them are marked as ACK
packets. This places a hard upper bound on packet loss rate of 5%,
where at most 50% of all ACK packets will be able to be dropped
with perfect accuracy, which did have a maximum ACK loss rate
of 47%. Interestingly, packet loss rates of 10% and 15% had a very
large span of possible ACK loss rates. These wide discrepancies
are caused by the fact that occasionally in the ACK packet tracking
algorithm you will see two distinct paths emerge. Dropping packets
in both paths would result in packet loss rates exceeding the cap,
forcing the algorithm to choose the probabilistically higher paths,
which it will ultimately stick with the remainder of the transfer un-
less they happen to merge later. When it happens to choose the
wrong path to follow, you see the very low ACK drop rates in Fig-
ure 4a. The distribution narrows considerably for packet loss rate
of 20%, due to the fact that it’s able to drop packets in both paths
and still stay under the packet loss cap, something which could not
be done with packet loss rates of 10 and 15%.
Dropping ACK packets from the client to server causes the server
to take longer in responding to packet loss and start resending lost
data. The end result from this is that it will decrease the through-
put and increase the time it takes the server to transmit data, which
is what the censor is ultimately interested in. To determine the
effects of various ACK loss rates, the client was conﬁgured to di-
rectly drop ACK packets at a capped rate. The experiment would
vary the ACK loss rate, performing 100 downloads for each chosen
rate, while the server had a static packet loss rate of 10%. This was
kept static because varying it had little effect on the overall band-
width. Since the server rewinds the entire buffer back to the ﬁrst
packet lost and then retransmits everything beyond that, it doesn’t
matter how many packets past that initial lost packet were dropped.
The experiments showed an initial drop from 34 KB/s to 27 KB/s
even with the smallest amounts of ACK packet droping, and then
the bandwidth held stable until ACK loss rates went past 50%. The
results for rates past this threshold are in Figure 4b, showing the
regression of the median bandwidth value along with the 95th con-
ﬁdence interval. While there is a slow decrease in observed band-
width, after 80% it accelerates downward reaching as low as 5-10
KB/s for ACK loss rates past 90%.
Given the large variation in both ACK loss rates and observed
bandwidth, we want to see what the end result is when looking
at packet loss rate from targeted packet dropping compared to the
observed bandwidth, as these are the two parameters a censor is
concerned about. Figure 4c shows a CDF of observed bandwidth
for packet loss rates ranging from 5 to 20%. Since packet loss rate
of 5% has an upper bound of a 50% ACK drop rate, it’s not sur-
prising that we don’t see the bandwidth drop much below 25 KB/s
as this was the constant rate seen for ACK loss rates ranging from
5 to 50%. For packet loss rates from 15-20%, considered to be a
rough upper bound on the censor packet dropping capability, we
see roughly about a quarter of transfers dropping below 15 KB/s
bandwidth. While these rates may not seem like a large reduction
compared to the initial 34 KB/s seen with SkypeMorph, the initial
paper [18] noted that the normal bridge operated at 200 KB/s, im-
plying that the combination means 90-95% reduction in available
bandwidth.
4.3.3 Replaying ACKs
While the packet dropping techniques served more as a throttling
mechanism than outright blocking, an active censor can also at-
tempt to replay packets over the cover-protocol, while having little
impact on legitimate trafﬁc. SkypeMorph uses sequence numbers
to keep track of what parts of the buffered data are being trans-
fered, so upon receiving any overlapping or duplicate data, it’s able
to detect this and either drop the packet or discard the data.
●●●●●0.050.10.150.20.20.40.60.81.0Packet Loss RateACK Loss Rate●●●●●●●●●●●●●●●●●●●●0.50.60.70.80.905101520253035ACK Loss RateBandwidth (KB/s)051020300.00.20.40.60.81.0Bandwidth (KB/s)CDF5%10%15%20%366(a) Time to transfer data with varying ACK replay inter-
vals
(b) ACK number sent by client with and without single
ACK injection
Figure 5: SkypeMorph ACK replay attacks with (a) showing the progression of the sent sequence number when replaying 4 ACK packets at
a time at different intervals and (b) shows the effects on the received ACK number when injecting a single ACK packet every 100ms.
Before the check for duplicate data happens, SkypeMorph ﬁrst
checks the packet ﬂag to determine whether the packet is an ACK
or not, and if so processes the ACK number before the data dupli-
cation check is performed. This is done because dummy packets
not transferring any real data can be ﬂagged as ACK, so the ACK
check needs to be done before the data processing. This opens up a
potential packet replay attack to the censor, where they have the ca-
pability of replay old ACK packets seen and have them legitimately
processed by the SkypeMorph client, even if the data is discarded.
The censor runs the same ACK tracking algorithm as discussed pre-
viously and waits until all paths merge into a single possible ACK,
increasing the probability of correctly selecting an ACK packet.
This ACK packet can be replayed to the server in bursts of 4 at a
time, so they will be received simultaneously causing the server to
reset its current sequence number and roll back the buffer.
For the experiment we conﬁgured the client to record the ﬁrst
packet that appeared alone in the possible ACK window, and re-
play it 4 times in a row at a ﬁxed interval, while the server was
conﬁgured with a static 10% packet loss rate. We ran an exper-
iment in default mode with no ACK replays, and then replaying
ACKs in intervals of 300 ms, 200 ms, and 100 ms. The results for
this experiment are shown in Figure 5a. Replaying ACKs at in-
tervals of 200 and 300 ms does signiﬁcantly increase the amount
of time it takes to transfer data, but it doesn’t completely kill the
transfer. This is because after the train of replays are sent, the next
valid ACK that the server receives will reset the current ACK value
and will roll forward the buffer to this position, as it assumes it has
received everything before the ACK counter. For the interval of
100 ms, we see a very dramatic reduction in how much data is able
to be sent, having it take around 40 seconds to send as much data
normally sent in the ﬁrst 5 seconds.
This result leads to a lower resource and more efﬁcient replay
attack. The server needs to receive 4 packets with the same ACK
number before it rolls back and starts retransmitting data. There-
fore, while inducing a small amount of packet loss from the server
to the client, a censor can simply inject a recorded ACK packets
once every 100 ms, continually causing the server to reset the cur-
rent ACK value and preventing the ACK counter from ever reach-
ing high enough to rewind the buffer. Figure 5b shows the ACK
number received by the server under default operation and while
performing the single ACK injection. We can see the received ACK
number jumping between the legitimate ACK value and the replay
ACK being injected. Once a packet is dropped from the server to
the client, the client keeps sending the server the same ACK num-
ber in an attempt to notify of data loss, but since the injected packet
keeps reseting the current ACK counter the server never resends the
data, stalling out the transfer and completely killing the connection.
4.4 CensorSpoofer
CensorSpoofer uses asynchronous communication in order to
hide the identify of the proxy, having data ﬂow only from the proxy
to the client. This means the client cannot notify the proxy of lost
packets or missing data like SkypeMorph was able to do. So in
order to reliably transmit data they suggest two methods of error
correction, one using an XOR encoder/decoder to send redundant
packets and the other to use forward error correction codes such as
Reed-Solomon. We explore these methods and how they hold up
to a censor attempting to disrupt communication between a Cen-
sorSpoofer client and server.
4.4.1 XOR Encoding
The XOR encoder/decoder has a redundant packet sent for ev-
ery n packets transmitted, so given packets (p1, p2,··· , pn), the
packet r = p1 ⊕ p2 ⊕ ··· ⊕ pn is constructed and sent after packet
pn. By including a simple packet counter at the beginning of each
packet, the client will be able to detect if a packet was lost, and as
long as n−1 of the remaining packets in the n packet window were
received, the client will be able to reconstruct the missing packet
simply by XORing the packets together. Assuming uniform packet
n+1 packet
loss, this type of system will be able to handle a rate of
loss. There are, however, problems with making this assumption.
The ﬁrst problem is that one of the common causes of packet
loss is due to buffers ﬁlling up and having to drop packets, which
in turn causes bursts of packets to be dropped [4]. This means that
there will be a very high chance that packet loss will cause more
than one packet to be dropped from the n packet window, meaning
that the lost data will not be able to be recovered. The more trouble-
some problem is that an active censor could prevent any client from
attempting to use CensorSpoofer by dropping a few consecutive
packets, ensuring that data being transfered over CensorSpoofer is
lost while barely effecting the usage of legitimate VoIP communi-
cation. As we can see in Figure 7, even using the smallest possible
value of n = 2 a censor can still cause a large amount of data loss,
ensuring all data transfers would fail when using XOR encoding.
1
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●01020300100000250000Time (s)Sequence Number●Default300 ms200 ms100 ms●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●01234050000100000150000Time (s)ACK Number●DefaultReplay367(a) Percent Data Loss
(b) Percent Transfered Failed
Figure 6: Effects of packet loss in CensorSpoofer while producing varying overhead values based on Reed-Solomon parameters, looking at
both (a) percent of data loss and (b) percent of failed transfers while using Reed-Solomon with different overhead.
to cause a portion of the data to be corrupted, thus disrupting the
entire transmission. In order to ﬁx this problem, we need to intro-
duce a bit interleaver which causes a single block to be dispersed
throughput multiple packets instead of being concentrated in a sin-
gle packet. Using a random bit interleaver, we experimented with
different Reed-Solomon parameters, ﬁxing n = 255 and varying k
while expressing the combination in terms of overhead of extra data
transfered, equivalent to n−k
k . For each set of parameters we per-
formed 100 downloads of a 320 KB ﬁle and recorded the average
percent of data loss during the downloads and the percent of failed
transfers. Figure 6 shows the packet loss thresholds for overhead
values ranging from 10 to 50%. With the combination of a random
bit interleaver and forward error correction, the server would still
need to encode with 50% overhead to to avoid losing data below
the 20% packet loss rate threshold.
5. PROXY MODEL IN P2P SYSTEMS
Many of these censorship circumvention systems attempt to ap-
ply a client-proxy system of anonymous communication to a dy-
namic peer-to-peer system outside their control. For example, Skype-
Morph and FreeWave both use Skype or other peer-to-peer VoIP
systems as their cover-protocol. This section explores some of the
difﬁculties that arises when forcing a proxy model into a peer-to-
peer system.
5.1 Tor Over Skype
The main problem SkypeMorph attempts to solve is the ability
of censors to enumerate Tor bridges and blacklist them. By us-
ing Skype as the protocol to mimic, it makes it hard for censors
to detect and enumerate these bridges, and outright blocking pop-
ular services like Skype is something many censors would like to
avoid. However, attempting to use the Skype network to tunnel
Tor connections through is problematic due to fundamental differ-
ent use cases for Tor verses VoIP. The Skype system is peer to peer
with sporadic short lived connections made between unique clients,
while the client-proxy model in Tor sees long lived connections be-
tween many clients and a single proxy. These differing use cases
open up potential avenues for a censor to ﬁngerprint SkypeMorph.
Figure 8 shows the ratio of daily bridge users from Syria, Iran,
and China compared to the total number of bridge relays in the Tor
network. Syria and Iran peaked at around 8-12 times as many users
as available bridges, and while China currently ﬂuctuates below
that, they at one point saw ratio as high as 120 users to bridges be-
Figure 7: Percent of data loss in CensorSpoofer compared to packet
loss rates when using XOR encoding with different n packet win-
dows for redundant data.
2
2, b(cid:48)
4.4.2 Reed-Solomon
The other method mentioned that could be used by CensorSpoofer
was a forward error correcting code such as Reed-Solomon, a pop-
ular code used in many error-prone mediums. Reed-Solomon codes
are parameterized by encoding messages of k symbols, where each
symbol is m-bits and the resulting encoded block is n = 2m − 1
symbols. Such a code can correct up to n − k errors if the location
of the erroneous symbols are known, otherwise it can only correct
up to n−k
errors. While this offers more reliable error correction in
the presence of packet loss, we can still run into some of the same
problems that we previously did. The naive way to perform the en-
coding is to split the data into blocks bi of size k symbols, encode
each block b(cid:48)
i = Reed-Solomon(bi, n, k) resulting in n symbols,
then transmit the encoded blocks b(cid:48)
3, . . . to the client. Since
reliable transmission means that all data encoded in the blocks must
be recovered, a censor that can cause enough packet loss to corrupt
a single block would cause the entire transmission to fail. For ex-
ample, a common Reed-Solomon code has m = 8 bit symbols
with (n, k) = (255, 223) message and block lengths. So in order
to send a 320 KB ﬁle, a server would need to transmit 1470 en-
coded blocks, only one of which needs to be corrupted in order to
stop the transmission.
1, b(cid:48)
From examining both these schemes, we can identify the real
problem is that for a server sending an averaged sized web ﬁle,
a censor only has to drop a small amount of continuous packets
●●●●●●●●●●●●●●0.00.10.20.30.40.5020406080Packet LossData Loss (%)●●●●●●●●●●●●●●0.00.10.20.30.40.50.60.00.40.8Packet LossPercent Transfered Failed●10%15%25%30%50%100%●●●●●●●●●●0.020.040.060.080.100.000.040.08XOR EncodingPacket LossData Loss●n=10n=5n=2368(a) English Packet Lengths
(b) Portuguese Packet Lengths
(c) Modem Packet Lengths
Figure 9: Skype packet lengths of English and Portuguese speech samples from the OPI corpus compared to modem audio sent over Skype.
nection to the actual FreeWave server and off to the end destination.
However, there are other issues for relying on an external system
for proxying connections. At the end of the day, software develop-
ers building a product that runs on top of an existing system have to
make assumptions about how that base system will behave. One of
the largest problems with directly utilizing an existing VoIP client
for censorship circumvention is that these assumptions, which se-
curity guarantees can depend on, do not always hold up over time.
Changes made without announcement can result in failures of the
system to uphold its security goals. An excellent example of this
is FreeWave’s assumptions about how and when Skype clients at-
tempt to use supernodes as a proxy for VoIP connections. Free-
Wave assumes that by placing a Skype node behind a NAT box it
will cause Skype to automatically use a supernode to bridge VoIP
connections. This was shown by prior research [13] to be the case.
However Skype is a constantly changing system and its behavior
evolves over time, in many cases without announcement.
While at the time FreeWave was designed Skype might have
been more willing to use supernodes, currently Skype clients at-
tempt, no matter the details of the network they reside in, to di-