area is greater than 6 pixels, the resulting captcha will significantly
affect user experience because it becomes difficult for humans to
recognize characters from the image [8].
2004005008001000020406080100 Fine-tuned solver success rate (%)Number of real captchas Google   Wikipedia   eBay   Microsoft   Baidu   Alipay   JD   Sina   Sohu   Weibo   Qihu3600.800.850.900.950.97020406080100Fine-tunedsolversuccessrate(%)Ratioofmis-classifiedsyntheticcaptchasMicrosoftWikipediaeBayBaiduJD(a) Overlapped characters(b) Rotated characters(c) Distorted characters(e) Waved charactersNo.
Sample
Overlapping
Rotation
Distortion Waving
1
2
3
4
5
6
7
8
9
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
All security features
Success
Rate
74.85%
65.05%
58.8%
64.95%
82.35%
62.45%
57.50%
52.50%
46.30%
Table 5: Impacts of multiple combined security features.
Rotation. In this experiment, we apply our solver to captchas
where the characters are rotated clockwise/anti-clockwise with an
angle of 15, 30, 45 and 60 degrees. Figure 16b illustrates some of the
rotated captchas generated by our synthesizer. Our solver correctly
recognizes all (100%) the captchas when characters are rotated at a
15- or 30-degree angle. It only fails to recognize 3 (99.85%) and 9
(99.55%) out of 2,000 captchas when characters are rotated at a 45-
and a 60-degree angles respectively. Our solver fails to recognize
some captchas because some of the characters of these captchas
are largely overlapping with each due to rotation. We note that the
rotation angle used by most of the current captcha schemes is under
30 degrees, because a greater rotation angle may have a negative
impact on user experience. The results indicate that rotation alone
does not enhance the security of text captchas under our attack.
Distortion.Character distortion can confuse bot programs as two
different characters could look similar when they are distorted. For
example, “O" and “0" are visually similar when they are distorted.
Figure 16c gives some of the synthetic, distorted captchas that are
used to test our solver. For this set of testing captchas, our solver
correctly labels 92.9% of the captchas. This experiment suggests
that distortion alone is not strong enough to defeat our attack.
Waving. Figure 16d shows some of the testing captchas with vari-
ous waving degrees. Our solver is able to successfully label 98.85%
of the captchas, outperforming the 93.6% success rate presented in
[36]. Our solver only fails on 23 captchas which contain characters
that are similar after waving, such as “O" and “0", and “l" and “1".
For some of those failed captchas, our annotators also did not reach
a consensus.
Combining security features. Table 5 shows how the combina-
tion of security features affect the accuracy of our solver. Combining
multiple security features does improve the robustness of a captcha
scheme. This can be seen from the drop in the solver’s success rate
when using two or more security features together. Specifically,
character overlapping and distortion are more effective compared
to rotation and waving, because overlapping and distortion can
result in significant alterations to the shape of a character. This
observation is also confirmed by the relatively lower success rate
presented in rows No. 1 to No. 4 (where overlapping or distortion
is used) compared with the 82.35% success rate at row No. 5 when
rotation and waving (but not overlapping nor distortion) are used.
Moreover, while using more security features results in a stronger
captcha scheme, it reduces the usability of captchas. For example,
our annotators struggle to recognize the captcha presented in row
No. 8 in the first attempt. If we now consider Row No. 9, an example
with all the security features considered in this work (including
background noise and occluding lines), all our annotators consider
this captcha to be user unfriendly and fail to correctly recognize
it in the first attempt. For all the cases presented in Table 5, our
solver success rate is above 46%, which is still greater than the 1%
threshold when a captcha scheme is considered to be ineffective.
Therefore, the results of this experiment suggest that balancing the
security strength and usability of a text captchas under our attack
is non-trivial.
6.8 Captcha Usability Study
Captcha is designed to be easy for humans to recognize while
hard for bots. However, balancing the security strength and user
experience is becoming increasingly difficult. In this experiment,
we perform user study to quantify the impact of security features
on user experience (i.e., captcha usability) and the success rate
of our solver. To do so, we have conducted an online survey by
recruiting 20 participants to fill in an anonymous questionnaire.
Our participants are at the age group of under 30s and are familiar
with text captchas. In the questionnaire, we present 100 synthetic
captchas with different security strengthes. We give each partic-
ipant one minute to label a captcha. We divide the captchas into
six categories based on the number of characters and the security
parameters used for generating the captacha. In the user study, we
ask each participant to rate the usability of five captchas from each
category on a 5-point Likert-scale, where 1 = very poor and 5 =
excellent usability.
Table 6 gives the criteria used to determine the captcha diffi-
culties and an example captcha image for each category. For each
captcha category, we also give the averaged success rates achieved
by our participants and our solver, as well as the averaged rating
given by the participants.
While using more security features increases the difficulty for
a computer program to solve a captcha challenge, doing so also
makes it harder for a user to recognize the content of the captcha.
For example, the averaged human success rate for the captchas
in category 6 of Table 6 is below 70%, meaning that nearly one-
third of the time a user will enter a wrong answer for captchas in
this category. Therefore, captchas in this category were given the
lowest usability score of 2.1 is not surprising. Also, as we expected,
humans in general are better than computers at solving captchas,
and the success rate of a computer solver drops as the difficulty of
the captcha increases.
No.
Example
Anti-segmentation
Anti-recognition
Humans Our approach
Security Features
Success Rate
1
2
3
4
5
6
English letters and arabic numerals
Rotation, varied font sizes
English letters
Rotation, varied font sizes
English letters, complex background
Rotation, distortion
English letters, overlapping characters,
complex background
Varied font sizes, rotation, distortion
English letters
Varied font sizes, ratation, distortion
English letters, overlapping characters
Varied font sizes, rotation, distortion, wav-
ing
95.25%
90.25%
91%
89.25%
79.75%
68.75%
100%
88%
96%
86%
77%
40%
Usability
4
2.75
2.8
2.7
2.8
2.1
Table 6: Example captchas used in our user study, the success rates of humans and our approach, and the usability rating.
If we now consider categories 3 and 4 in Table 6 where back-
ground confusion is used, we find that noisy backgrounds have a
negative impact on the user experience because our participants
gave an overaged usability score of less than 3 for captchas in these
categories. On the other hand, background confusion has little con-
tribution to the security strength of captchas under our attack. This
can be confirmed from the similar, or even better solving perfor-
mance given by our solver when compared to human participants
for captchas in the two categories. This finding suggests that com-
plex background confusion perhaps should be abandoned in future
text captcha schemes.
Overall, this user study shows that a deep-learning-based captcha
solver can achieve comparable performance for solving text captchas
when compared to humans, but balancing the security and usability
of a text captcha scheme is non-trivial.
7 DISCUSSIONS
In this section, we discuss the limitations of our approach and
the potential countermeasures for our attack.
7.1 Limitations
Naturally there is room for further work and possible improve-
ments. We discuss a few points here.
Captchas with variable numbers of characters. Our current
implementation targets text-based captchas with a fixed number
of characters, but it can be extended to captachs with a variable
numbers of characters. This can be achieved by first predicting
how many characters are in the captcha and then selecting a model
specifically trained for that number of characters. Our preliminary
results show that we can learn a CNN model to predict the number
of characters of an input captach image with a accuracy of 89% and
70% for Wikipedia and Google schemes respectively.
Multi-word captchas. Our approach can be easily extended to
multi-word captchas too. This can be done by either treating all
words as a sequence of characters, or first segmenting the words
and then recognizing individual words.
Extend to other captcha schemes. Our approach is generally ap-
plicable and can be naturally extended for video and image captchas
by adapting the network architecture to recognize objects from the
inputs; and favorably, the process of synthetic data generation,
model training and tuning still is unchanged. This flexibility allows
one to attack various types of captchas, not just text-based ones.
For example, to target NuCAPTCHA [2], a motion-based captcha
scheme, we need to replace our CNN solver with a model similar to
the Mask R-CNN [26]. The idea is to first segment the video frames
into images and then recognize characters from individual images.
After replacing the solver structure, we also need to extend our
GAN-based captcha synthesizer to generate a sequence of synthetic
images (as recognition is performed at the image level). For motion-
based captchas, the key is to maintain the temporal relationships
among images, for which a temporal CNN can be useful [37].
7.2 Countermeasures
Recent studies have shown that adversarial examples generated
by GANs can confuse machine learning classifiers [57]. By insert-
ing some imperceptible perturbation on captcha images, one can
mislead a machine learning model [47, 57] and at the same time
the small perturbation does not interfere with a successful recogni-
tion of the image contents by humans. However, the perturbation
to be put on the captcha image is tightly coupled to not only the
captcha image itself, but also the captcha solver and its parameters.
To generate effective adversarial examples requires having a way to
observe the solver behavior. Doing so is difficult in practice because
an adversary is unlikely to release the solver, while a small change
in the solver structure (e.g., by changing the number and types of
some neural network layers) is often sufficiently enough to invalid
the adversarial mechanism. This work shows that it is possible to
quickly learn a highly accurate captcha solver using a small set of
real captchas. This means the structure of the solver can be quickly
changed to invalid a adversarial mechanism used by a captcha
scheme. While our work does not necessarily pronounce a death
sentence to text-based captchas – as they are keeping evolving, we
hope the high success rate achieved by our deep-learning-based
attack can encourage the community to carefully think about the
implications of this widely used security mechanism.
Numerous alternative schemes have been proposed to replace
text-based captchas. These include video-based captachas such as
NuCAPTCHA [2] and game-based CAPTCHAs [43]. The former
was shown to be vulnerable [7, 62]. The later seemly offers some
promises but the recently breakthrough of deep reinforcement
learning in game playing may pose a threat to such schemes [42]. To
develop a robust countermeasure for deep-learning-based attacks,
one probably need to combine multiple mechanisms similar to the
multi-factor authentication protocol [33, 51]. Nonetheless, how
to balance the security strength and usability of a scheme is an
outstanding problem.
8 RELATED WORK
Text-based captchas are a dominant captcha scheme used by
many websites. There is an extensive body of prior work investi-
gates ways to improve the security of text-based captchas, building
upon attacks on existing schemes. However, text captchas are going
through an iterative development process, just like cryptography
and digital watermarking, where the previously successful attacks
have led to the development of more secure schemes. While there
are alternative captcha schemes available, text captchas are still
preferred by many users due to familiarity and a sense of security
and control [35].
Mori et al. were among the first attempts to break text captchas [25].
Their attack employs a set of analytical models and heuristics to
break Gimpy and EZ-Gimpy, two early simple text-based captcha
schemes. Yan et al. show a simple character segmentation method [63],
which counts the number of pixels of individual characters, can
break most of the captchas from Captchaservices.org. Later, they
show an improved segmentation method can be used to attack the