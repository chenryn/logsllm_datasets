### Analysis of False Positives in Test Cases

Our analysis now focuses on identifying the causes of false positives across all test cases. Table 7 provides a breakdown of the 68 false positives. Approximately 66% of these false positives are attributed to message reordering, which can occur both within and across flows, even when requests are made to the same server. For example, in test case T8, the output consists of 57 TCP connections, with 31 of them used to fetch image files from a single server. In the first set of tests, requests for `cornerpng_upperleft.png` and `cornerpng_upperright.png` were consistently issued as the 22nd and 23rd requests. However, in the second set of tests, the order was altered, leading to false positives. Additionally, our analysis revealed that the reordering of HTTP GET messages within a single persistent HTTP connection also generated false positives. In test case T5, a large number of HTTP GET messages were pipelined over a persistent connection, and the order of these requests varied across different tests, even when the tests were performed sequentially and addressed to the same server.

**Table 7: Breakdown of False Positives Flagged by NetDialign**

| Cause               | Count (Percentage) |
|---------------------|--------------------|
| Message Reordering  | 45 (66%)           |
| Cookies             | 21 (31%)           |
| Random Changes      | 2 (3%)             |
| **Total**           | **68 (100%)**      |

### Issues with Cookies

The second major issue is related to cookies. While NetDialign generally filters out irrelevant cookie values, a problematic case was identified in test case T4. This weather application uses cookies to store and periodically update the last updated weather information, such as the low and high temperatures for a specific location. Since T4 has two output sets generated from two different zip codes (for testing potential leaks), the cookie values for each weather-related field differ between the two sets. This led NetDialign to identify these differences as location leaks. This raises a broader question: how can we automatically distinguish between significant and insignificant exposures, such as a user ID associated with a user account? We consider this problem of inferring the semantics of exposed information as part of future work.

### Other Causes of False Positives

The remaining 3% of false positives (2 instances) were due to SSL encryption and dynamic content changes at the server, causing the client to fetch a different file. We will discuss an approach to handle encrypted SSL connections in the next section. However, addressing dynamic content changes at the server end is more challenging, and we believe such occurrences are not frequent, as indicated in Table 7.

### Limitations of Privacy Oracle

#### Encrypted Connections
Without access to the implementation details and source code of the target applications, it can be difficult to collect plaintext from an application that implements its own encryption scheme. Privacy Oracle requires a mechanism to inspect messages in plaintext because properly encrypted messages will always appear different, even if they convey the same information. For SSL, this can be achieved by explicitly proxying HTTP connections through a man-in-the-middle attacker or by instrumenting commonly used APIs like WININET and Mozilla NSS with tools like HTTP Analyzer [6].

#### Message Reordering
As discussed, message reordering within and across flows significantly increases the false positive rate of the NetDialign algorithm. To reduce this, one approach could be to conduct a large number of application tests and select pairs of network traces with the best pairwise message alignment. Another promising technique is to use metrics (e.g., entropy, compressed length) to measure the similarity among messages and adjust reordered messages before feeding them to NetDialign.

#### Traffic Randomization
Applications that understand Privacy Oracle's process can undermine its effectiveness. For example, by adding random tokens to packets, an application can increase the false positive rate arbitrarily to hide real information leaks. Similarly, by spreading sensitive information over long sequences of bytes, an application might communicate personal information without triggering NetDialign’s detection of low similarity, thus increasing the false negative rate.

### Related Work

Concerns about the threat software applications pose to consumer privacy have driven efforts to improve user awareness through governmental and academic studies, as well as the development of technological tools. One study [24] by the Canadian Internet Policy and Public Interest Clinic examined the behavior of products using digital rights management (DRM) technologies, including Apple’s iTunes Music Store and Intuit’s QuickTax. The study found that some products track usage, surfing habits, and IP addresses, violating Canada’s Personal Information Protection and Electronic Documents Act. Their analysis involved collecting network traces and registry modifications via Wireshark [28] and RegSnap [19], but unlike Privacy Oracle, their results were derived from manual inspection of the traces. Their focus was to inform users about specific DRM applications, rather than developing an automated way to detect leaks.

Commercial software tools for detecting leaks [27, 25] are widely used and successful in detecting and trapping leaks of personal information such as credit card and social security numbers and sensitive documents. These tools work by constructing signatures of private information (e.g., via automatically generated content "fingerprints" from documents and manually entered regular expressions that characterize the format of sensitive information). They then look for matches in network traces. Such tools detect leaks when the structure of the content being leaked is known a priori, but unlike Privacy Oracle, they cannot detect leaks with unknown structure. Complementary tools like Little Snitch [9] alert users to where their content is going, which is useful since connections to third parties such as advertisement and spyware servers often go unannounced.

Privacy Oracle automatically detects leaks by looking for differences in the network traces produced by several test runs of an application. The problem of aligning identical substrings to highlight differences has been studied since 1970, when scientists searched for similarities in the amino acid sequences of proteins [14]. Our work adapts Dialign [12], a more refined method for pairwise and multiple alignment of nucleic acid and protein sequences. A previous adaptation of sequence alignment algorithms to network traces [8] had similar goals. Kreibich and Crowcroft [8] presented a variant of Jacobson-Vo, which finds the longest common subsequence (LCS) of two input strings with the minimum number of fragmentations. Compared to their algorithm (or LCS-based algorithms in general), NetDialign is a segment-to-segment based alignment algorithm, focusing on finding common contiguous segments rather than maximizing the number of matches. We argue that a segment-to-segment based algorithm is better suited to our problem setting when the input data contain long dissimilar regions (e.g., 160 bytes randomly generated session ID).

The black-box analysis style used by Privacy Oracle is reminiscent of the fuzz testing approach [11] first applied to software testing. Instead of providing random data to the inputs of a program to see if it crashes, we apply random data to see if and how they disturb the program’s output. When a change in input generates a change in output, Privacy Oracle concludes that some transformation of the input has been leaked. Since inputs are chosen to be sensitive (e.g., a user’s name or birthday), a corresponding perturbation of the output signifies a privacy concern in the form of a leak of that information.

Another system exploring the black-box analysis technique for leak detection is TightLip [30]. When sensitive data are accessed by an application process, TightLip creates a sandboxed copy process of the target process, gives fuzzed data to the copy process, and runs the copy process in parallel with the target for output comparison. Yumerefendi et al. showed that the overhead of running TightLip is insignificant when implemented and tested in a Linux operating system [30].

Although the efficiency of TightLip in detecting real leaks is not shown in the paper, we believe that an instrumentation like TightLip can enable Privacy Oracle to run online for real-time leak detection by applications. Specifically, Privacy Oracle offers a methodology for generating fuzzed inputs for interactive applications and a technique for analyzing network data to isolate meaningful differences. When combined with a process-level testing harness, Privacy Oracle can essentially run the black-box differential testing in real-time (e.g., with two copy processes—one with the same input and one with fuzzed input, in parallel with the original process).

Black-box testing is a practical approach to understanding how inputs affect outputs and is useful for studying applications (e.g., Web application interfaces [7]). A more rigorous technique is to trace the information explicitly as it flows from inputs to outputs. For example, by tainting the inputs and carefully accounting for memory operations (e.g., [29]), a system can provide a step-by-step metamorphosis of input information into output information, allowing users a more detailed view of the transformation. McCamant and Ernst describe a technique by which analysis of the execution of a program can determine a theoretical upper bound on how much information its inputs reveal about its outputs [10]. Their tool instruments a program by dynamically rewriting its instruction stream using the Valgrind framework.

While taint analysis can be effective on platforms or applications that allow it, our overall goal is to investigate broader mechanisms for detecting information leaks that do not depend on instrumenting the underlying operating system or application. Furthermore, while we validated the Privacy Oracle methodology for applications running in an environment that could be instrumented for taint analysis (e.g., by running Windows XP on a virtual processor), we expect our methodology to extend to the growing ecosystem of portable and embedded devices where such instrumentation would be difficult. An extension of our approach to mobile devices may require integration with existing approaches for testing mobile devices, such as robotic hands.

Finally, important work aimed at automatically reverse engineering network protocols from network traces is complementary to Privacy Oracle. Projects such as RolePlayer [2, 4] and the Protocol Informatics Project [18] infer commonly seen protocol idioms such as packet typing and sequencing in monitored packets. Using such techniques in conjunction with Privacy Oracle might help us attribute semantics to detected substring leaks, thereby ruling out false positives and improving accuracy.

### Conclusion

We have presented Privacy Oracle, a system that uncovers applications' leaks of personal information in transmissions to remote servers. The black-box differential fuzz testing approach taken by Privacy Oracle discovers leaks even when the structure of the information being leaked was previously unknown, and does so without requiring deep or intrusive instrumentation of the computing system under study. This makes our approach broadly applicable to a myriad of device architectures and software systems. Key to Privacy Oracle’s success is the NetDialign flow alignment tool, which efficiently isolates differences among network messages. Our contribution is the adaptation and implementation of Dialign for comparing raw packet data.

We evaluated 26 popular applications and showed that Privacy Oracle discovers various kinds of leaks, many of which were previously undisclosed. We find that at least 5 applications send personal information (email, name, zip code, age, gender) in the clear. Among these, two applications frequently transmit such information whenever they poll for content updates from servers. We have also demonstrated Privacy Oracle’s capability to detect the exposure of opaque identifiers, accurately identifying unique, random-looking user IDs that applications internally generate and communicate with remote servers. We extended Privacy Oracle to inspect encrypted messages by intercepting calls to the Windows APIs via HTTP Analyzer [6]. With this extended capability, we discovered the disclosure of specific system configuration information (machine name) by a popular media application. For the 11 test cases we investigated, NetDialign generated no more than 15 false positives per test case (all of which could be easily eliminated by manual inspection), even when over 50% of the tests produced large output traces (over 29KB) for analysis.

In summary, what we presented is an initial step toward a completely automated system for finding personal information leaks from applications. Ongoing efforts aim to increase the coverage and improve the accuracy of Privacy Oracle.

### References

[1] AutoIT v3 — Automate and Script Windows Task.
http://www.autoitscript.com/autoit3/

[2] Weidong Cui, Vern Paxson, and Nicholas Weaver.
Protocol-independent adaptive replay of application dialog. In NDSS, 2006.

[3] Robert B. Evans and Alberto Savoia. Differential testing: a new approach to change detection. In ESEC-FSE posters, 2007.

[4] Leita Corrado gand Ken Mermoud and Marc Dacier. Scriptgen: an automated script generation tool for honeyd. In ACSAC, 2005.

[5] J. W. Hunt and M. D. McIlroy. An algorithm for differential file comparison. Technical report, Bell Telephone Laboratories, 1976.

[6] IEInspector HTTP Analyzer.
http://www.ieinspector.com/httpanalyzer/

[7] Marc Fisher II, Sebastian Elbaum, and Gregg Rothermel. Dynamic characterization of web application interfaces. FASE 2007, LNCS, 4422:260–275, 2007.

[8] Christian Kreibich and Jon Crowcroft. Efficient sequence alignment of network traffic. In IMC, 2006.

[9] Little Snitch. http://www.obdev.at/products/littlesnitch/

[10] Stephen McCamant and Michael D. Ernst. Quantitative information flow as network flow capacity. In PLDI, 2008.

[11] Barton P. Miller, Lars Fredriksen, and Bryan So. An empirical study of the reliability of UNIX utilities. CACM, 33(12):32–44, 1990.

[12] Burkhard Morgenstern, Andreas Dress, and Thomas Werner.
Multiple DNA and protein sequence alignment based on segment-to-segment comparison. PNAS, 93(22):12098–12103, October 1996.

[13] Burkhard Morgenstern, Kornelie Frech, Andreas Dress, and Thomas Werner. Dialign: finding local similarities by multiple sequence alignment. Bioinformatics, 14(3):290–294, 1998.

[14] S.B. Needleman and C.D. Wunsch. A general method applicable to the search for similarities in the amino acid sequence of two proteins. Journal of Molecular Biology, 1970.

[15] NMMI FAQ-O-Matic: What is my machine Windows name?
http://faq.nmmi.edu/fom-serve/cache/338.html

[16] Ruoming Pang, Vinod Yegneswaran, Paul Barford, Vern Paxson, and Larry Peterson. Characteristics of internet background radiation. In IMC, 2004.

[17] Vern Paxson. Bro: a system for detecting network intruders in real-time. Computer Networks, 31(23–24):2435–2463, 1999.

[18] The Protocol Informatics Project.
http://www4tphi.net/~awaiters/PI/PI.html

[19] RegSnap — Registry Tracer. http://www.lastbit.com/regsnap/

[20] T. Scott Saponas, Jonathan Lester, Carl Hartung, Sameer Agarwal, and Tadayoshi Kohno. Devices that tell on you: Privacy trends in consumer ubiquitous computing. In Usenix Security Symposium, 2007.

[21] Slashdot — Adobe Quietly Monitoring Software Use?
http://yro.slashdot.org/yro/07/12/29/2120202.shtml

[22] Slashdot — Sears Installs Spyware.
http://yro.slashdot.org/yro/08/01/03/1630203.shtml

[23] Stuart Cheshire and Marc Krochmal. Multicast DNS.
http://files.multicastdns.org/draft-cheshire-dnsext-multicastdns.txt, 2006.

[24] The Canadian Internet Policy and Public Interest Clinic. Digital Rights Management and Consumer Privacy.
http://www.cippic.ca, September 2007.

[25] VIP Privacy. http://www.vipdefense.com/

[26] VMware: Virtualization via Hypervisor, Virtual Machine & Server Consolidation.
http://www.vmware.com/

[27] WebSense Content Protection Suite. http://www.websense.com/

[28] Wireshark. http://www.wireshark.org

[29] Heng Yin, Dawn Song, Manuel Egele, Christopher Kruegel, and Engin Kirda. Panorama: capturing system-wide information flow for malware detection and analysis. In CCS, 2007.

[30] Aydan R. Yumerefendi, Benjamin Mickle, and Landon P. Cox. Tightlip: Keeping applications from spilling the beans. In NSDI, 2007.