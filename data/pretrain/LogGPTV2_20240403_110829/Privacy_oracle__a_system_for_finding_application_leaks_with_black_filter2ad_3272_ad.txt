We now focus our analysis on identifying the causes of the
false positives across all the test cases. Table 7 shows the break-
Figure 4: Evaluation of NetDialign over eleven test cases. The test cases
are sorted by the increasing order of output message size.
down of the 68 false positives. Almost 66% of the false posi-
tives were caused due to message reordering. Message reorder-
ing takes places both within and across ﬂows even when the re-
quests are made to the same server. For instance, an output
from T8 is composed of 57 TCP connections, 31 of which were
generated to fetch image ﬁles from a single server.
In the ﬁrst
set of tests, messages to retrieve cornerpng_uppperleft.png
and cornerpng_uppperright.png were consistently issued as the
22nd and 23rd request across all the test outputs. However in the
second set of tests the orders were changed, causing false posi-
tives. Our analysis also revealed false positives being generated
by the reordering of HTTP GET messages within a single persistent
HTTP connection. In the case of T5, a large number of HTTP GET
messages were pipelined over a persistent HTTP connection. The
order of these requests varied across the different tests even when
the tests were performed sequentially and requests were addressed
to the same server.
Message reordering
45 (66%)
Cookies
21 (31%)
Random changes
2 (3%)
Total
68 (100%)
Table 7: Break-down of false positives ﬂagged by NetDialign
The second issue is cookies. In most cases, NetDialign effec-
tively sifts out irrelevant cookie values. But, a troubling case was
found in T4. This weather application uses cookies to place last
updated weather information such as low and high temperature of
a particular location and periodically send them to servers for up-
dates. Since T4 has two output sets generated from two different
zip codes (for testing their leaks), the two output sets have different
cookie values for each weather related ﬁeld, leading NetDialign to
identify those as location leaks. This brings up a bigger question:
How do we automatically separate out this from dependent-and-
signiﬁcant exposure such as a user ID associated with a user ac-
count? We leave this problem of inferring the semantics of exposed
information as part of future work.
The above two sources account for 97% of false positives. The
remaining two instances of false positives were due to SSL encryp-
tion and dynamic content change at the server, causing the client
to fetch a different ﬁle. We present an approach to deal with en-
crypted SSL connections in the next section. However, there is no
easy way to address the dynamic content changes at the server end
and we believe that such occurrences are not frequent as indicated
in Table 7.
024681012141618T6 (2.4KB)T11 (3.6KB)T7 (3.8KB)T3 (22.6 KB)T8 (26.0 KB)T4 (29.6KB)T9 (38.4KB)T2 (41.0KB)T1 (43.5 KB)T10 (58.8 KB)T5 (92.1KB)CountTotal # of flagsFalse positives6.2 Limitations of Privacy Oracle
Encrypted connections. Without access to the implementation de-
tails and the source code of the target applications, it might be difﬁ-
cult to collect plaintext from an application that implements its own
encryption scheme. Privacy Oracle must be provided a mechanism
to inspect messages in plaintext, since properly encrypted messages
will always look different even if they are conveying exactly the
same information. In the case of SSL, this can be achieved by ex-
plicitly proxying HTTP connections through a man-in-the-middle
attacker or by instrumenting the commonly used WININET and
Mozilla NSS APIs with a tool like HTTP Analyzer [6].
Message reordering. As discussed in the previous section, mes-
sage reordering within and across ﬂows can signiﬁcantly increase
the false positive rate of the NetDialign algorithm. An approach to
reduce the false positive rate could be to conduct a large number of
application tests and pick pairs of network traces with the best pair-
wise message alignment. Another promising technique is to use
metrics (e.g., entropy, compressed length) by which we can mea-
sure the similarity among messages and adjust reordered messages
before feeding them to NetDialign.
Trafﬁc randomization. Applications that understand Privacy Or-
acle’s process can undermine its effectiveness. For example, by
adding random tokens to packets, an application may increase Pri-
vacy Oracle’s false positive rate arbitrarily to hide real information
leaks in the noise. Likewise, by spreading sensitive information
over arbitrarily long sequences of bytes, an application might be
able to communicate personal information without triggering Net-
Dialign’s detection of low similarity, and thus increase the false
negative rate.
7. RELATED WORK
Concern about the threat software applications pose to consumer
privacy has fueled efforts to improve user awareness both via gov-
ernmental and academic studies as well as through the development
of technological tools. In one study [24], the Canadian Internet Pol-
icy and Public Interest Clinic examined the behavior of a number
of products that use digital rights management (DRM) technologies
including Apple’s iTunes Music Store and Intuit’s QuickTax . The
study found some products track usage, surﬁng habits and IP ad-
dresses, which violates Canada’s Personal Information Protection
and Electronic Documents Act. Their analysis involved the collec-
tion of network traces and registry modiﬁcations via wireshark [28]
and RegSnap [19], respectively, but unlike Privacy Oracle, their re-
sults derive from manual inspection of the traces. Their focus was
only to inform users about a speciﬁc set of DRM applications, and
not to develop automated way to detect leaks.
Commercial software tools to automatically detect leaks [27, 25]
are in widespread use and are quite successful in detecting and trap-
ping leaks of personal information such as credit card and social
security numbers and sensitive documents. They work by ﬁrst con-
structing signatures of private information (e.g., via automatically
generated content “ﬁngerprints” from documents and manually en-
tered regular expressions that characterize the format of sensitive
information). They then look for matches in network traces. Such
tools detect leaks when the structure of the content being leaked is
known a priori, but unlike Privacy Oracle, they cannot detect leaks
with unknown structure. Complementary to tracking what informa-
tion is being leaked is the aim of tools like Little Snitch [9], which
alerts users to where their content is going. These tools are useful
as the establishment of connections to third parties such as adver-
tisement and spyware servers often goes unannounced otherwise.
Privacy Oracle automatically detects leaks by looking for dif-
ferences in the network traces produced by several test runs of
an application. The problem of aligning identical substrings to
highlight the differences between them has been under study since
1970, when scientists searched for similarities in the amino acid se-
quences of proteins [14]. Our work is an adaptation of Dialign [12],
a more reﬁned method for pairwise as well as multiple alignment
of nucleic acid and protein sequences. A previous adaptation of
sequence alignment algorithms to network traces [8] has similar
goals. Kreibich and Crowcroft [8] presented a variant of Jacobson-
Vo, which ﬁnds a longest common subsequence (LCS) of two input
strings with the minimum number of fragmentations. Compared
to their algorithm (or LCS-based algorithm as a whole), NetDi-
align is a segment-to-segment based alignment algorithm (its foun-
dation derived from Dialign), focusing on ﬁnding common con-
tiguous segments rather than trying to maximize the number of
matches. We argue that a segment-to-segment based algorithm is
better suited to our problem setting when the input data contain
long dissimilar regions (e.g., 160 bytes randomly generated session
ID).
The style of black box analysis that Privacy Oracle uses is rem-
iniscent of the fuzz testing approach [11] that was ﬁrst applied to
software testing. Instead of providing random data to the inputs of
a program to see if it crashes, we apply random data to see if and
how they disturb the program’s output. When a change in input
generates a change in output, Privacy Oracle concludes that some
transformation of the input has been leaked. Since within Privacy
Oracle, inputs are chosen to be sensitive in nature (e.g., a user’s
name or birthday), a corresponding perturbation of the output sig-
niﬁes a privacy concern in the form of a leak of that information.
Another system exploring the black-box analysis technique for leak
detection is TightLip [30]. When sensitive data are accessed by an
application process, TightLip creates a sandboxed copy process of
the target process, gives fuzzed data to the copy process and runs
the copy process in parallel with the target for output comparison.
Yumerefendi et al. showed that the overhead of running TightLip
is insigniﬁcant when implemented and tested in a Linux operating
system [30].
Although the efﬁciency of TightLip with respect to detecting real
leaks is not shown in the paper, we believe that an instrumentation
like TightLip can enable to run Privacy Oracle online for realtime
leak detection by applications. In particular, Privacy Oracle offers
a methodology for generating fuzzed inputs for interactive applica-
tions and a technique for analyzing network data to isolate mean-
ingful differences. When combined with a process-level testing
harness, Privacy Oracle can essentially run the black-box differen-
tial testing in real-time (e.g., with two copy processes—one with
the same input and one with fuzzed input, in parallel with the orig-
inal process).
Black box testing is a practical approach to understanding how
inputs affect outputs and thus useful for studying applications (e.g.,
Web application interface [7]). A more rigorous technique is to
trace the information explicitly as it ﬂows from inputs to outputs.
For example, by tainting the inputs and carefully accounting for
memory operations (e.g., [29]), a systems can provide a step-by-
step metamorphosis of input information into output information,
thus allowing users a more detailed view of the transformation. Mc-
Camant and Ernst describe a technique by which analysis of the
execution of a program can determine a theoretic upper bound on
how much information its inputs reveal about its outputs [10]. Their
tool instruments a program by dynamically rewriting its instruction
stream using the Valgrind framework.
While taint analysis can be effective on platforms or applica-
tions that allow it, our overall goal is to investigate broader mech-
anisms for detecting information leaks that are not dependent on
instrumenting the underlying operating system or application. Fur-
thermore, while we validated the Privacy Oracle methodology for
applications running in an environment that could be instrumented
for taint analysis (e.g., by running Windows XP on a virtual pro-
cessor), we expect our methodology to extend to the ever-growing
ecosystem of portable and embedded devices where such instru-
mentation would be difﬁcult, albeit an extension of our approach to
mobile devices may require integration of existing approaches for
testing mobile devices, e.g., robotic hands.
Finally, important work aimed at automatically reverse engineer-
ing network protocols from network traces is complementary to
Privacy Oracle. Projects such as RolePlayer [2, 4] and the Proto-
col Informatics Project [18] infer commonly seen protocol idioms
such as packet typing and sequencing in monitored packets. Us-
ing such techniques in conjunction with Privacy Oracle might help
us attribute semantics to detected substring leaks to rule out false
positives and improve accuracy.
8. CONCLUSION
We have presented Privacy Oracle, a system that uncovers appli-
cations’ leaks of personal information in transmissions to remote
servers. The black-box differential fuzz testing approach that Pri-
vacy Oracle takes, discovers leaks even when the structure of infor-
mation being leaked was previously unknown, and does so without
requiring a deep or intrusive instrumentation of the computing sys-
tem under study; thus our approach is broadly applicable to a myr-
iad of device architectures and software systems. Key to Privacy
Oracle’s success is the NetDialign ﬂow alignment tool that efﬁ-
ciently isolates differences amongst network messages. Our con-
tribution is the adaptation and the implementation of Dialign for
comparing raw packet data.
We evaluated 26 popular applications and showed that Privacy
Oracle discovers various kinds of leaks, many of which were pre-
viously undisclosed. We ﬁnd that at least 5 applications send
personal information (email, name, zip code, age, gender) in the
clear. Among these, two applications frequently transmit such in-
formation whenever the applications poll for content updates from
servers. We have also demonstrated Privacy Oracle’s capability to
detect the exposure of opaque identiﬁers: it accurately identiﬁed
the unique random-looking user IDs that applications internally
generated and communicated with remote servers. We have ex-
tended Privacy Oracle to inspect encrypted messages by intercept-
ing calls to the Windows APIs via HTTP Analyzer [6]. With this
extended capability, we discovered the disclosure of speciﬁc sys-
tem conﬁguration information (machine name) by a popular media
application. For the 11 test cases that we investigated in the paper,
NetDialign generated no more than 15 false positives per each test
case (all of which could be easily eliminted simply by manual in-
spection) even when over 50% of the tests produced large output
traces (over 29KB) for analysis. In summary, what we presented in
the paper is an initial step toward a completely automated system
for ﬁnding personal information leaks from applications. Stepping
forward, efforts are ongoing to increase the coverage and to im-
prove the accuracy of Privacy Oracle.
9. REFERENCES
[1] AutoIT v3 — Automate and Script Windows Task.
http://www.autoitscript.com/autoit3/.
[2] Weidong Cui, Vern Paxson, and Nicholas Weaver.
Protocol-independent adaptive replay of application dialog. In NDSS,
2006.
[3] Robert B. Evans and Alberto Savoia. Differential testing: a new
approach to change detection. In ESEC-FSE posters, 2007.
[4] Leita Corrado gand Ken Mermoud and Marc Dacier. Scriptgen: an
automated script generation tool for honeyd. In ACSAC, 2005.
[5] J. W. Hunt and M. D. McIlroy. An algorithm for differential ﬁle
comparison. Technical report, Bel Telephone Laboratories, 1976.
[6] IEInspector HTTP Analyzer.
http://www.ieinspector.com/httpanalyzer/.
[7] Marc Fisher II, Sebastian Elbaum, and Gregg Rothermel. Dynamic
characterization of web application interfaces. FASE 2007, LNCS,
4422:260–275, 2007.
[8] Christian Kreibich and Jon Crowcroft. Efﬁcient sequence alignment
of network trafﬁc. In IMC, 2006.
[9] Little Snitch. http://www.obdev.at/products/littlesnitch/.
[10] Stephen McCamant and Michael D. Ernst. Quantitative information
ﬂow as network ﬂow capacity. In PLDI, 2008.
[11] Barton P. Miller, Lars Fredriksen, and Bryan So. An empirical study
of the reliability of UNIX utilities. CACM, 33(12):32–44, 1990.
[12] Burkhard Morgenstern, Andreas Dress, and Thomas Werner.
Multiple DNA and protein sequence alignment based on
segment-to-segment comparison. PNAS, 93(22):12098–12103,
October 1996.
[13] Burkhard Morgenstern, Kornelie Frech, Andreas Dress, and Thomas
Werner. Dialign: ﬁnding local similarities by multiple sequence
alignment. Bioinformatics, 14(3):290–294, 1998.
[14] S.B. Needleman and C.D. Wunsch. A general method applicable to
the search for similarities in the amino acid sequence of two proteins.
Journal of Molecular Biology, 1970.
[15] NMMI FAQ-O-Matic: What is my machine Windows name?
http://faq.nmmi.edu/fom-serve/cache/338.html.
[16] Ruoming Pang, Vinod Yegneswaran, Paul Barford, Vern Paxson, and
Larry Peterson. Characteristics of internet background radiation. In
IMC, 2004.
[17] Vern Paxson. Bro: a system for detecting network intruders in
real-time. Computer Networks, 31(23–24):2435–2463, 1999.
[18] The Protocol Informatics Project.
http://www4tphi.net/~awaiters/PI/PI.html.
[19] RegSnap — Registry Tracer. http://www.lastbit.com/regsnap/.
[20] T. Scott Saponas, Jonathan Lester, Carl Hartung, Sameer Agarwal,
and Tadayoshi Kohno. Devices that tell on you: Privacy trends in
consumer ubiquitous computing. In Usenix Security Symposium,
2007.
[21] Slashdot — Adobe Quietly Monitoring Software Use?
http://yro.slashdot.org/yro/07/12/29/2120202.shtml.
[22] Slashdot — Sears Installs Spyware.
http://yro.slashdot.org/yro/08/01/03/1630203.shtml.
[23] Stuart Cheshire and Marc Krochmal. Multicast DNS.
http://files.multicastdns.org/
draft-cheshire-dnsext-multicastdns.txt, 2006.
[24] The Canadian Internet Policy and Public Interest Clinic. Digital
Rights Management and Consumer Privacy.
http://www.cippic.ca, September 2007.
[25] VIP Privacy. http://www.vipdefense.com/.
[26] Vmware: Virtualization via Hypervisor, Virtual Machine & Server
Consolidation. http://www.vmware.com/.
[27] WebSense Content Protection Suite. http://www.websense.com/.
[28] Wireshark. http://www.wireshark.org.
[29] Heng Yin, Dawn Song, Manuel Egele, Christopher Kruegel, and
Engin Kirda. Panorama: capturing system-wide information ﬂow for
malware detection and analysis. In CCS, 2007.
[30] Aydan R. Yumerefendi, Benjamin Mickle, and Landon P. Cox.
Tightlip: Keeping applications from spilling the beans. In NSDI,
2007.