the usability of our approach. The significant difference between
the E-speed and the D-speed also indicates the effectiveness of our
optimizations.
RQ.2. How can we decide the proper BOU N D for the greedy
compression?
In the evaluations in Table 2, we set the BOU N D value of the
sliding window in Algorithm 1 as 4. We get this setting by tuning
the value of BOU N D on the benchmarks compiled with GCC, as
presented in Table 3. The choice of BOU N D’s value is a spatial-
temporal trade-off. A larger BOU N D may lead to a higher com-
pression rate with a longer time. Due to the complexity of program
control flows, there is no universal optimal value. We use the fol-
lowing formula to help choose the preferable value of BOU N D
from Table 3,
Avдp∈benchmarks((1 − 1/Rp)/Tgr,p)(cid:17)
(cid:16)
max
(1)
For each program, (1-1/R) represents the ratio of compression in
another form of (#evfold − #evgr)/#evfold. Therefore, (1 − 1/R)/Tgr
measures the gain of compression in each time unit. For each
value of BOU N D, we calculate the average value of this gain for
the benchmarks in Table 3. The tuning procedure finally chooses
BOU N D = 22 used in our evaluations. Intuitively, Tgr increases ex-
ponentially along with the exponential increase of BOU N D. Mean-
while, the increase in the gain of compression is not exponential
thus small BOU N D is preferred. However, we may choose other val-
ues of BOU N D by using optimization functions other than Eq.(1),
considering the tolerance of network capacity and the computing
resources of the prover.
RQ.3. What’s the effectiveness of the security enforcement of
the verifier?
At the verifier, the performance is generally affected by the
design of the shadow stack and the scale of the security policy. The
key measurements are the size of the two policy mappings ⟨M, F⟩
because the map searches are the critical operations. We present the
size of the mappings, i.e., |F | and |M|, in Table 4. Because we use
the ordinary workloads on the SPEC2k6 benchmarks, which contain
no exploit to hijack the control flows, our verifier can consume all
the recovered control-flow events and report the secure execution
of the benchmarks.
The total verification time consists of two parts. The first part
is the time of the reverse procedure of the greedy compression, i.e.
Tgr−1 in Table 4. This procedure recovers the folded control-flow
events collected by the instrumented prover binaries, i.e., evfold.
The second part is the verification time taking all the control-flow
events in evfold as input and enforcing the security policy, i.e.,
Tvrf in Table 4. The security enforcement is performed on folded
control-flow events and requires no recovery of the original runtime
control-flow events evtotal. Therefore the control-flow events veri-
fication speed is figured out by #evfold/(Tgr−1 + Tvrf), where #evfold
is identical to the statistics in Table 2. The verification speed ranges
13K/s∼1.74M/s for GCC binaries and 26K/s∼1.70M/s for LLVM bi-
naries. The average verification speed is 1.03M/s. In general, our
attestation speed (28.2M/s) and verification speed (1.03M/s) is in-
comparable to the speeds of ScaRR [36] (250∼400K/s for attestation
and 1.4∼2.7M/s for verification), because we take different defini-
tions of control-flow event. Our control-flow events include un-
skippable direct calls, indirect branches, and returns, while ScaRR’s
control-flow events also take the direct jumps and system calls
318ReCFA: Resilient Control-Flow Attestation
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Table 3: Tuning the Value of BOU N D. Compression rate R = #evfold/#evgr
Program
R
1.002
400.perlbench
1.035
401.bzip2
403.gcc
1.018
1.377
429.mcf
433.milc
1.000
1.009
445.gobmk
456.hmmer
1.000
462.libquantum 1.000
1.002
464.h264ref
470.lbm
1.000
482.sphinx3
1.157
Avд((1- 1R / Tgr)
0.511
22
Tgr(s)
0.538
0.075
3.431
0.309
0.002
1.594
0.001
0.003
1.344
0.001
0.032
23
BOU N D
R
1.004
1.213
1.046
1.488
1.000
1.019
1.006
1.000
1.003
1.000
1.183
Tgr(s)
1.198
0.122
6.762
0.517
0.003
3.309
0.001
0.004
2.890
0.001
0.055
R
1.002
1.106
1.039
1.470
1.000
1.010
1.001
1.000
1.002
1.000
1.177
24
Tgr(s)
2.576
0.225
14.924
1.112
0.004
7.357
0.002
0.006
6.725
0.001
0.109
25
Tgr(s)
5.111
0.426
28.358
2.197
0.007
14.013
0.002
0.011
13.278
0.001
0.223
R
1.005
1.253
1.056
1.492
1.000
1.022
1.008
1.000
1.003
1.000
1.187
into account. More potential improvements on the efficiency of our
approach are discussed in Section 5.
RQ.4. Does our control-flow attestation effectively enforce CFI
to resist real-world exploits?
In this section, we evaluate our system to see if our context-
sensitive control-flow attestation can detect several real-world code
reuse exploits at the prover and if the vulnerable control-flow events
can be diagnosed by the remote verifier. We reproduce the exploits
presented in Table 5 at the prover. The CVE is also described in
[19] and the Control Jujutsu proof-of-concept (PoC) exploits [15]
are reported detectable by the control-flow policy of TypeArmor
[37]. Because our enforcement of the verifier uses the same security
policy as TypeArmor, these PoC attacks are expected to be detected
by our approach. After instrumenting the vulnerable binary, we
manually examined that the static binary instrumentation does
not affect the memory corruption attacks; otherwise, we adjust
the overflow data to ensure the attack take effect. The large size
of ffmpeg’s binary impedes the static instrumentation; thus, we
only instrument on a related part of the CFG. Then, we launch
the exploit to trigger the vulnerable control-flow edges at runtime
and let the binary fold the control-flow events and deliver them to
the verifier. Our verifier detects and reports the exact control-flow
events that violate the rules.
These exploits corrupt the forward edges therefore the verifier re-
ports violations that some runtime edge target is not in the expected
set of targets. For the PoC exploit on Nginx, we detected an invalid
control-flow edge from the call site in ngx_output_chain to the
function ngx_execute_proc. For the PoC exploit on Apache httpd,
we detected an invalid edge from the indirect call site inside the
function ap_run_dirwalk_stat to the function piped_log_spawn.
For the CVE-2016-10190 on ffmpeg, we found an invalid edge issued
from the indirect call site inside the function avio_read.
5 DISCUSSION
The prototype implementation of ReCFA does not support multi-
thread programs. To extend our approach to support multi-thread
0.506
0.496
0.492
programs, we may obtain the thread id at each instrumentation
point with Dyninst. We label each control-flow event with the
thread id. Then the control-flow event sequence for each thread can
be compressed and delivered concurrently as separate attestation
reports to the verifier. We also have to instrument at the thread
start point to tell the verifier when to copy the context of shadow
stack for monitoring a new thread. Then at the verifier, we can
create monitoring threads corresponding to the prover-side threads
to enforce the security policy.
Differently from the local CFI protections that usually merges
larger equivalent classes (ECs) of valid targets to improve the effi-
ciency [8], our verifier-side enforcement, especially the mapping F ,
leverages the original sets of valid targets derived by the state-of-
the-art approach, i.e. [37]. We believe the throughput of the network
communication give us more flexibility to address precision rather
than the efficiency at the verifier. However, we argue that larger
equivalent classes are still effective in further improving the ef-
ficiency of security enforcement. Another choice to improve the
efficiency of the map searching is to build a layer of fix-size cache
ahead of the map searching for the big mappings, e.g. 403.gcc and
400.perlbench of Table 4. Due to the locality of control flow, once
the set of valid targets of an indirect call site is missed in the cache
by a runtime forward edge, we check the hit in the mapping and
load the mapping relations of this call site into the cache.
Delivering control-flow events from the prover to the verifier
gives us the opportunity to achieve a real-time control-flow at-
testation compared with the traditional control-flow attestations
using the hash digests as path measurements. Though we have
not exploited this potential in our implementation, we may fur-
ther investigate the lagging of the verifier-side anomaly reports
concerning the overhead of instrumented binary, the cost of the
runtime control-flow event condensing, and the network latency
caused by data delivering.
We have not considered the non-control-data attack [9], which
is claimed to be mitigated by C-FLAT [4]. In their approach, the
valid values for branch-condition data are enumerated to derive
319ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Yumei Zhang, Xinzhi Liu, Cong Sun, Dongrui Zeng, Gang Tan, Xiao Kan, and Siqi Ma
Table 4: Effectiveness of Context-Sensitive Enforcement at Verifier. Verification speed = #evfold/(Tgr−1 + Tvrf)
Program
400.perlbench
401.bzip2
403.gcc
429.mcf
433.milc
445.gobmk
456.hmmer
458.sjeng
462.libquantum
464.h264ref
470.lbm
482.sphinx3
Avg. vrf. speed
|M|
4,289
134
21,879
5
372
3,191
789
273
234
750
19
1,078
|F|
15,299
460
53,159
83
1,591
9,969
4,074
1,247
554
3,347
74
2,758
Tgr−1(s)
0.556
0.066
3.455
0.294
0.002
1.646
0.001
N/A
0.003
1.414
0.002
0.029
GCC
LLVM
Tvrf(s)
18.025
0.974
56.417
5.498
0.015
43.629
0.005
N/A
0.021
39.829
0.000
0.651
|M|
4,308
129
21,740
5