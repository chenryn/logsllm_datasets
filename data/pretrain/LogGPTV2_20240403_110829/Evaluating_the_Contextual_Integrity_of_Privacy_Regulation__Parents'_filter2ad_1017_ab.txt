unrealistic information ﬂows is a core part of the CI survey
method [3] for reducing the total number of questions and
the corresponding cost of running the survey. This process
resulted in 1056 total information ﬂow descriptions for use
in CI survey questions (Section 3.2).
The degree to which these ﬂows are rated as acceptable or
unacceptable by survey respondents indicate agreement or
disagreement between COPPA and parents’ privacy norms.
This rest of this section describes how we selected values for
each information ﬂow parameter in detail.
Transmission Principles from COPPA. We used the Fed-
eral Trade Commission’s Six Step Compliance Plan for
COPPA [10] to identify transmission principles. Some of
these transmission principles match those in our previous
work [3], facilitating results comparison.
We converted steps 2–4 of the Compliance Plan into four
transmission principles regarding consent, notiﬁcation, and
privacy policy compliance (Table 1). COPPA dictates that
parents must receive direct notice and provide veriﬁable con-
sent before information about children is collected. Opera-
tors covered by COPPA must also post a privacy policy that
describes what information will be collected and how it will
be used. Our corresponding transmission principles allow us
to test whether these requirements actually increase the ac-
ceptability of data collection from and about children.
The ﬁfth step of the Compliance Plan concerns “parents’
ongoing rights with respect to personal information collected
from their kids” [10]. Operators must allow parents to review
collected information, revoke their consent, or delete col-
lected information. We translated this requirement into the
transmission principle “if its owner can at any time revoke
their consent, review or delete the information collected.”
The sixth step of the Compliance Plan concerns opera-
tors’ responsibility to implement “reasonable procedures to
protect the security of kids’ personal information” [10] and
to only release children’s information to third party service
providers who can do likewise. We translated this step into
ﬁve transmission principles involving conﬁdentiality, secu-
rity, storage and deletion practices (Table 1).
The Compliance Plan also lists a set of exclusions to
COPPA. We converted the exclusions that were most ap-
plicable to Internet-connected children’s devices into four
transmission principles (Table 1). We also added the trans-
mission principle “if it complies with the Children’s Online
Privacy Protection Rule” to test parents’ trust and awareness
of COPPA itself.
Importantly, we also included the null transmission prin-
ciple to create control information ﬂows with no COPPA-
based criteria. Comparing the acceptability of ﬂows with
the null transmission principle against equivalent ﬂows with
COPPA-based transmission principles allows us to deter-
mine whether the COPPA conditions are relevant to parents’
privacy norms.
Smart Toy Senders. The senders included in our survey
represent ﬁve categories of children’s IoT devices: a smart
speaker/baby monitor, a smart watch, a toy walkie-talkie,
a smart doll, and a toy robot. We chose these senders
by searching for children’s Internet-connected devices men-
tioned in recent press articles [13, 17, 20, 29, 31, 35], aca-
demic papers [5, 25], blogs [9, 19, 37], IoT-speciﬁc web-
sites [21, 23, 38], and merchants such as Toys “R” Us and
Amazon. All of the selected senders are devices that are rea-
sonably “directed towards children” [10, 11] in order to en-
sure that they are covered by COPPA. We excluded devices
such as smart thermometers or other smart home devices that
might collect information about children but are not directly
targeted at children.
It is important to note that the selected devices do not rep-
resent the full breadth of smart toy products. However, infor-
mation ﬂow descriptions involving speciﬁc devices or device
categories evoke more richly varied privacy norms from sur-
vey respondents than ﬂows describing a generic “smart toy.”
This is supported by existing interview data [58] noting that
IoT device owners often have very different privacy opinions
of speciﬁc entities than of their generic exemplars (e.g., the
“Seattle government” versus “government”).
reviewed academic
Information Attributes. We
re-
search [25], online privacy websites [38],
toy descrip-
tions [15], and privacy policies [18, 36] to compile a list of
information attributes collected by the toys in our sender list.
The ﬁnal selected attributes include heart rate, frequently
asked questions, the times the subject is home, frequently
traveled routes, the times the device is used, location, sleep-
ing habits, call history, audio of the subject, emergency con-
tacts, video of the subject, and birthday. These attributes
cover a variety of personally identiﬁable or otherwise sen-
sitive information with speciﬁc handling practices mandated
by COPPA.
First- and Third-party Recipients. We included device
manufacturers and third-party service providers as recipient
parameters. This allowed us to examine variations in privacy
between ﬁrst and third parties while limiting the total number
of information ﬂows and the corresponding cost of running
the survey.
Children as Information Subjects. The only subject pa-
rameter included in the survey is “its owner’s child.” This
wording emphasizes that the child is not the owner of the
device and acknowledges the parental role in ensuring chil-
dren’s privacy. It also accounts for devices that may not be
used directly or exclusively by the child (e.g., a baby mon-
itor). We indicated in the survey overview that respondents
should think about their own children’s information when in-
terpreting this subject.
126    28th USENIX Security Symposium
USENIX Association
Sender
a smart speaker/baby monitor
a smart watch
a toy walkie-talkie
a smart doll
a toy robot
Recipient
its manufacturer
a third-party service provider
Subject & Attribute
its owner’s child’s heart rate
its owner’s child’s frequently
asked questions
the times its owner’s child is home
its owner’s child’s frequently
traveled routes
the times it is used
its owner’s child’s location
its owner’s child’s sleeping habits
its owner’s child’s call history
audio of its owner’s child
its owner’s child’s emergency contacts
video of its owner’s child
its owner’s child’s birthday
Transmission Principle
COPPA Compliance Plan Steps 2-3
if its privacy policy permits it
if its owner is directly notiﬁed before the information was collected
COPPA Compliance Plan Step 4
if its owner has given veriﬁable consent
if its owner has given veriﬁable consent before the information was collected
COPPA Compliance Plan Step 5
if its owner can at any time revoke their consent, review or delete the information collected
COPPA Compliance Plan Step 6
if it implements reasonable procedures to protect the information collected
if the information is kept conﬁdential
if the information is kept secure
if the information is stored for as long as is reasonably necessary for the purpose
for which it was collected
if the information is deleted
COPPA Exclusions
if the information is used to protect a child’s safety
if the information is used to provide support for internal operations of the device
if the information is used to maintain or analyze the function of the device
if the information is used to serve contextual ads
Other
if it complies with the Children’s Online Privacy Protection Rule
null
Table 1: Contextual integrity parameter values selected for information ﬂow generation. The null transmission principle is an
important control included to generate information ﬂows with no explicit conditions. The transmission principles were derived
from the FTC’s Six Step Compliance Plan for COPPA [10].
3.2 Survey Design
We created and hosted the survey on the Qualtrics plat-
form [39]. The survey was split into six sections: con-
sent, demographic questions I, overview, contextual
in-
tegrity questions, awareness questions, and demographic
questions II. This section provides details about each sec-
tion. The survey did not mention COPPA, privacy, security,
nor any potential negative effects of smart toy information
ﬂows prior to the contextual integrity questions to prevent
priming and framing effects.
Consent. Respondents were initially presented with a con-
sent form approved by our university’s Institutional Review
Board. Respondents who did not consent to the form were
not allowed to proceed with the study.
Demographic Questions I. The ﬁrst set of demographic
questions asked respondents for the ages of their children
under 13. We chose this age limit because COPPA only ap-
plies to data collection from children under 13. We randomly
selected one of the ages for each respondent, n, which was
piped to the survey overview.
Overview. Respondents were then presented with a sur-
vey overview containing a brief description of Internet-
connected devices and instructions for the contextual in-
tegrity questions (Appendix A). This overview also ex-
plained how respondents should interpret
the recurring
phrase “its owner’s child,” and instructed them to keep their
n-year-old child in mind while taking the survey (where n
was selected for each respondent from their responses to the
demographics questions I).
Contextual Integrity Questions. The core of the survey
consisted of 32 blocks of questions querying the acceptabil-
ity of our generated information ﬂows (Section 3.1). Each
question block contained 33 information ﬂows with the same
sender, same attribute, varying recipients, and varying trans-
mission principles. For example, one block contained all in-
formation ﬂows with the sender “a smart doll” and the at-
USENIX Association
28th USENIX Security Symposium    127
tribute “the times it is used.” Each question block also in-
cluded one attention check question.
Each respondent was randomly assigned to a single ques-
tion block. Answering questions about ﬂows with the same
sender and attribute reduced cognitive fatigue and ensured
independence across recipients and transmission principles.
The information ﬂows in each block were divided into ma-
trices of individual Likert scale multiple choice questions.
The ﬁrst matrix in each block contained questions about in-
formation ﬂows to different recipients with the null trans-
mission principle (Figure 1). The remaining matrices each
contained questions about information ﬂows to a speciﬁc re-
cipient with varying transmission principles (Figure 2). The
order of the information ﬂows in each block was randomized
for each respondent.
Each individual multiple choice question in the matrices
asked respondents to rate the acceptability of a single infor-
mation ﬂow on a scale of ﬁve Likert items: Completely Ac-
ceptable (2), Somewhat Acceptable (1), Neutral (0), Some-
what Unacceptable (-1), Completely Unacceptable (-2). We
also included the option “Doesn’t Make Sense” to allow re-
spondents to indicate if they didn’t understand the informa-
tion ﬂow.
Awareness Questions. Respondents then answered ques-
tions about their general technological familiarity and In-
ternet use, ownership of Internet-connected devices, owner-
ship of children’s Internet-connected devices, and previous
knowledge of COPPA.
Demographic Questions II. Finally, respondents answered
standard demographic questions from the United States Cen-
sus. This allowed us to check the representativeness of our
sample (Appendix B, Section 5.2) and account for demo-
graphic variables in our analysis.
3.3 Survey Deployment
We tested the survey on UserBob [52] once during the sur-
vey design process and again immediately prior to deploy-
ment. UserBob is a usability testing service for obtaining
video screen capture of users interacting with a website while
recording audio feedback. Each survey test involved creating
a UserBob task with a link to the survey, brief instructions
for users,1 and settings to recruit 4 users to take the survey
for 7 minutes each. UserBob automatically recruited users
through Amazon Mechanical Turk at a cost of $1 per user per
minute. The resulting video and audio recordings of users
interacting with the survey informed changes to our survey
design. In particular, we reduced the number of questions
per block and increased the number of pages over which
the questions were presented. This reduced the amount of
1UserBob task instructions: “This is a survey that will be given to a
group of parents with children younger than 13. Take the survey, pretending
you have one or more children younger than 13. Record your thoughts on
the user interface and whether the questions do/don’t make sense.”
scrolling necessary to complete the survey and improved en-
gagement. This practice of using pre-deployment “cognitive
interviews” to test and debug survey design is common in
survey research [49]. UserBob responses were not included
the ﬁnal results.
We used Cint [8], an insights exchange platform, to deploy
our survey to a panel of 296 adult parents of children under
the age of 13 in the United States. We selected respondents
with children younger than 13 because COPPA applies to
“operators of websites or online services directed to children
under 13” [11]. Our surveyed population therefore consisted
entirely of individuals affected by COPPA. We chose not to
set a minimum age for respondents’ children, because there
is a lack of readily available information on the minimum
age of use of Internet-connected children’s devices. While
certain manufacturers list recommended minimum ages for
their connected toys and devices, this was not the case for the
majority of the devices we considered. Additionally, many
devices such as wearable trackers, water bottles, baby mon-
itors, are targeted towards very young children. Lastly, not
restricting the minimum age allowed us to relax the demo-
graphic requirements for survey deployment.
Respondents were paid $3 for valid responses where the
attention check question was answered correctly. Each re-
spondent was only allowed to answer the survey once. The
survey responses were collected over an 18 hour time frame.
We chose Cint to deploy our survey instead of Amazon Me-
chanical Turk, because Cint allowed us to directly target a
speciﬁc panel of respondents (as in Zyskowski et al. [60])
without requiring a preliminary screening questionnaire to
identify parents [44].
3.4 Response Analysis
We began with 296 responses. We removed the responses
from 8 respondents who did not consent to the survey (none
of their information was recorded) as well as those from 85
respondents who did not correctly answer the attention check
question. We removed 2 responses in which over 50% of
the information ﬂows were characterized as “Doesn’t make
sense.” We also removed 2 responses where not all informa-
tion ﬂow questions were answered. Finally, we removed 1
response where the respondent self-reported over 10 children
and 3 responses that were completed in less than 2 minutes.
This resulted in a ﬁnal set of 195 responses with an average
of 6 responses per information ﬂow (standard deviation 1.4).
The responses to all contextual integrity questions (Sec-
tion 3.2) were on a Likert scale with the following Lik-
ert items: “Completely acceptable” (2), “Somewhat accept-
able” (1), “Neutral” (0), “Somewhat unacceptable” (-1), and
“Completely unacceptable” (-2). We call this value the “ac-
ceptability score” of each information ﬂow for each respon-
dent.
In order to generalize privacy norms beyond individual re-
spondents and information ﬂows, we averaged the accept-
128    28th USENIX Security Symposium