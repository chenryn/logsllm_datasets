.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
A-9 ROP gadget to set up the phantom stack .
A-10 ROP gadget for write .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
. 67
. 71
. 72
. 72
. 73
. 74
. 75
. 75
. 76
. 77
. 78
10
Chapter 1
Introduction
Buffer overﬂows and other memory vulnerabilities have been exploited by attackers for
more than two decades [22]. At ﬁrst, these attacks worked by injecting new code (called
shellcode because it commonly spawned an attacker-controled shell on the victim’s ma-
chine) into memory and then overwriting control ﬂow data (a return address or function
pointer) to jump to the new code [29]. In response to these attacks, compilers and oper-
ating systems implemented defenses such as W(cid:8)X memory [33] [42] to prevent attackers
from running new code; shellcode detection, to monitor inputs for potential shellcodes [31];
and code signing, which ensures that all the code executed has been veriﬁed [11] [10].
As a response to defenses designed to prevent code injection attacks, the attacker com-
munity developed code reuse attacks [8] [27], which, instead of injecting new code, reuse
code that is already in the process memory. These attacks evade defenses that prevent code
injection by preventing attackers from executing new, malicious code because they use
code that is already present in malicious ways.
The evolution of the code reuse attack and defense space has resembled an arms race,
with new attacks circumventing defenses either by undermining their core assumptions
(e.g. jump-oriented programming [6] vs. returnless kernels [26]) or by exploiting imper-
fect implementation and deployment (e.g. surgical strikes on randomization [32] vs. ASLR
[39]). Defensive techniques have evolved in lockstep, attempting to more comprehensively
deny attackers key capabilities. For example, G-Free’s [28] gadget-elimination techniques
target classes of free branch instructions rather than focusing on ret statements. While
11
substantial research has been conducted in this space, it is difﬁcult to determine how these
defenses, based on different threat models, compose with one another to protect systems,
and howl various classes of attack fare against both individual and composed defenses.
Techniques targeting ROP attacks may eliminate gadgets while doing little against return-
into-libc (RiL) code reuse attacks, for example.
In general, speciﬁc defenses can only
target speciﬁc attacker capabilities. In addition to evaluating whether a particular defense
successfully eliminates the attacker capabilities it targets, it is also necessary to evaluate
whether eliminating those capabilities is sufﬁcient for preventing the attacker from achiev-
ing malicious behavior.
With this higher-level evaluation in mind, in this thesis we perform a systematic analysis
and categorization of attacks and defenses using a formal model of the software security
space. Speciﬁcally, we represent the attackers’ overall goals of deploying malware as a
satisﬁability instance, where vulnerabilites and other attacker capabilities are represented as
literals, speciﬁc attacks are compound formulas of those literals and defenses are additional
dependencies on the capabilities and attacks. We use the model to identify gaps in the
current set of defenses and evaluate the effectiveness of proposed defense techniques and
develop two attacks which bypass existing defenses. The ﬁrst of these attacks is pure ROP,
which illustrates that ROP attacks can be used to cause a broad range of malicious behavior.
The second attack is return-to-libn which broadens attacks that, previously, required access
to libc to more libraries.
Next, we investigate the claim that defenses that enforce control ﬂow integrity (CFI)
provide a complete defense against code reuse attacks [9]. These defenses work by lim-
iting the program control ﬂow to a statically determined graph consisting only of control
transfers that might happen during normal program execution. We use a graph to model
the set of possible behaviors of programs protected by CFI defenses. We then show that it
is possible to construct code reuse attacks that achieve malicious behavior using only con-
trol transfers allowed by the existing control ﬂow integrity enforcement systems [47] by
building several code reuse payloads for Lynx, a simple web browser, (a call to system, a
downloader, an uploader, and a root inserter) which work in the presence of CFI systems.
The main contributions of this thesis are the following:
12
(cid:15) We develop a systematic model to analyze the code reuse attack and defense space.
(cid:15) Based on the data from the model, we build attacks which bypass existing code reuse
defenses.
(cid:15) We investigate and model the control ﬂow graphs enforced by CFI defenses.
(cid:15) We build code reuse attacks that work within these control ﬂow graphs.
The rest of the thesis is structured as follows: Chapter 2 provides background and a
history of code reuse attacks; Chapter 3 describes the defenses that have been proposed
and implemented to protect against code reuse attacks; Chapter 4 describes our systematic
model, its applications and several results; Chapter 5 discusses control ﬂow enforcement
systems and describes a system for searching the space of control transfers allowed by those
systems; Chapter 6 describes actual attacks that work around control ﬂow enforcement
systems; Chapter 7 concludes.
13
14
Chapter 2
Code Reuse Attack Background
Buffer Overﬂows A buffer overﬂow vulnerability is a programming bug that allows an
attacker to construct an input to a program that writes past the end of the buffer allocated
for the input and overwrites other data stored on the stack. Since control ﬂow data such
as function pointers and return addresses are stored on the stack, the attacker can exploit
the buffer overﬂow overwrite these values and redirect the program control ﬂow. Similar
attacks apply to heap-allocated spaces and control data stored on the heap. These vul-
nerabilities were originally used by attackers [29] to inject malicious code onto the stack
and run it. Defenses were introduced to prevent attackers from injecting and running ma-
licious code by preventing data execution (enforcing the property that memory pages are
never both writable and executable or W(cid:8)X memory) [30] or monitoring inputs to look for
potential malicious payloads [31].
Code Reuse Attacks Code reuse attacks were created as a response to protection mech-
anisms that prevent code injection. As in code injection attacks, code reuse attacks begin
when an attacker overﬂows a buffer on the stack or heap and overwrites program control
data to redirect the program control ﬂow. However, unlike code injection attacks, which
redirect the control ﬂow to new code written into memory by the attacker, code reuse at-
tacks redirect the control ﬂow to sections of existing executable code from the program
space. Advanced techniques allow attackers to reuse (or chain together) multiple sections
[27] [34] of code to create complex payloads. Code-reuse attacks are categorized based
15
on the granularity of the sections of reused code (called gadgets). The most commonly
discussed types of code reuse attacks are return-into-libc attacks and return-oriented pro-
gramming (ROP) attacks.
Return-into-Libc
attacker with control of the stack can call a sequence of functions with arguments of their
In return-into-libc attacks [27], the gadgets are entire functions. An
choosing. Usually these functions are system functions from the system libraries (libc) such
as exec, but they can be any complete function from the program space. Because nearly
every program written in C links to libc, which implements a signiﬁcant amount of system
functionality including accessing the network, accessing the ﬁlesystem, and providing a
wrapper to the system call interface, attackers can implement many payloads using only
functions from libc that are portable across different vulnerable programs. In fact, it has
been shown to be possible to achieve Turing complete behavior with only function calls
from libc [40].
Return Oriented Programming In ROP attacks [34], a gadget is a series of machine
instructions terminating in a ret or a ret-like sequence, such as pop x followed by
jmp *x [9]. The ret instructions are used to transfer control from one gadget to the next
to allow attackers to construct complex attacks from the existing code (see Figure 2-1).
On processors that use variable length instructions, ROP gadgets can come from “un-
intended instructions” caused by transfering control into the middle of an instruction [34].
The x86 instruction set, in particular, is very dense. As a result, a random byte stream has a
high probability of containing a valid sequence of x86 instructions. Gadgets resulting from
unintended instructions still need to end in a ret to allow transfering control from one
gadget to the next. In x86, ret is represented by a single byte: C3. As a result, rets (and
by extension, gadgets) are common enough to allow attackers to use them to build useful
malware.
It has been shown to be possible to create complete malware payloads using only code
reuse attacks [34], even when a very limited amount of code is available for the attacker to
reuse [19]. However, real attacks often use limited ROP techniques to perform very speciﬁc
16
Figure 2-1: Program stack with a ROP payload, which executes xor %eax, %ebx; add
%ebx, %edx; xor %eax, %ebx; : : :
operations, such as disabling W(cid:8)X, to allow a more general subsequent attack. This may
be as simple as calling a single function [14] or leaking a single memory address [32].
After W(cid:8)X is disabled, an injected payload is executed.
Memory Disclosure and Breaking Randomization Systems Many defenses have been
proposed which randomize the layout of the process address space in order to prevent
attackers from predicting the locations of functions and gadgets [18] [23] [33] [39] [44]
[45]. However, techniques exist which allow attackers to learn enough information about
the address space to construct effective code reuse payloads. The randomization systems
that are currently deployed randomize the base addresses of executables and linked libraries
[30] [33]. The addresses of code within the program and linked libraries relative to the base
address are ﬁxed for all instances of the program or library. Shacham, et. al. [35] show
that it is relatively easy for an attacker to use brute force attacks to guess the address of one
function (they use the sleep function as an example) and then use that address to calculate
the base address for the library and, consequently, the addresses of the rest of the code