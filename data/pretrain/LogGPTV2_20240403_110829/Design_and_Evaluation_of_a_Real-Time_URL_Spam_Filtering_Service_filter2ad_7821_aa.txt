title:Design and Evaluation of a Real-Time URL Spam Filtering Service
author:Kurt Thomas and
Chris Grier and
Justin Ma and
Vern Paxson and
Dawn Song
2011 IEEE Symposium on Security and Privacy
Design and Evaluation of a Real-Time URL Spam Filtering Service
Kurt Thomas*, Chris Grier*†, Justin Ma*, Vern Paxson*†, Dawn Song*
{kthomas, grier, jtma, vern, dawnsong}@cs.berkeley.edu
† International Computer Science Institute
* University of California, Berkeley
Abstract
On the heels of the widespread adoption of web services
such as social networks and URL shorteners, scams, phishing,
and malware have become regular threats. Despite extensive
research, email-based spam ﬁltering techniques generally fall
short for protecting other web services. To better address this
need, we present Monarch, a real-time system that crawls
URLs as they are submitted to web services and determines
whether the URLs direct to spam. We evaluate the viability
of Monarch and the fundamental challenges that arise due to
the diversity of web service spam. We show that Monarch can
provide accurate, real-time protection, but that the underlying
characteristics of spam do not generalize across web services.
In particular, we ﬁnd that spam targeting email qualitatively
differs in signiﬁcant ways from spam campaigns targeting
Twitter. We explore the distinctions between email and Twitter
spam, including the abuse of public web hosting and redirec-
tor services. Finally, we demonstrate Monarch’s scalability,
showing our system could protect a service such as Twitter—
which needs to process 15 million URLs/day—for a bit under
$800/day.
1. Introduction
In recent years, the Internet has seen a massive proliferation
of web services, including social networks, video sharing sites,
blogs, and consumer review pages that draw in hundreds of
millions of viewers. On the heels of the widespread adoption
of these services, phishing, malware, and scams have become
a regular threat [1]–[3]. Bypassing protection mechanisms
put
in place by service operators, scammers are able to
distribute harmful content through the use of compromised
and fraudulent accounts [4], [5]. As spam evolves beyond
email and becomes a regular nuisance of web services, new
defenses must be devised to safeguard what is currently a
largely unprotected space.
While email spam has been extensively researched, many
of the solutions fail to apply to web services. In particular,
recent work has shown that domain and IP blacklists currently
in use by social network operators and by URL shortening ser-
vices [6]–[9] perform too slowly (high latency for listing) and
inaccurately for use in web services [5], [10], [11]. Alternative
solutions, such as account-based heuristics that are speciﬁcally
designed to identify automated and suspicious behavior in web
services [12]–[14], focus on identifying accounts generated by
spammers, and thus have limited utility in detecting misuse of
1081-6011/11 $26.00 © 2011 IEEE
DOI 10.1109/SP.2011.25
447
compromised accounts. They also can incur delays between
a fraudulent account’s creation and its subsequent detection
due to the need to build a history of (mis-)activity. Given
these limitations, we seek to design a system that operates
in real-time to limit the period users are exposed to spam
content; provides ﬁne-grained decisions that allow services to
ﬁlter individual messages posted by users; but functions in a
manner generalizable to many forms of web services.
To this end we design Monarch, a real-time system that
crawls URLs as they are submitted to web services and deter-
mines whether the URLs direct to spam content. For our study,
we deﬁne spam to include scams advertising pharmaceuticals,
adult content, and other solicitations, phishing that attempts to
capture account credentials, and pages attempting to distribute
malware. By restricting our analysis to URLs, Monarch can
provide spam protection regardless of the context in which a
URL appears, or the account from which it originates. This
gives rise to the notion of spam URL ﬁltering as a service.
Monarch frees other web services from the overhead of rein-
venting spam classiﬁers and the accompanying infrastructure
components.
The architecture of Monarch consists of three core elements:
a front-end that accepts URLs submitted by web services
seeking a classiﬁcation decision, a pool of browsers hosted on
cloud infrastructure that visits URLs to extract salient features,
and a distributed classiﬁcation engine designed to scale to
tens of millions of features that rapidly returns a decision for
whether a URL leads to spam content. Classiﬁcation builds
upon a large foundation of spam characteristics [15]–[24] and
includes features drawn from the lexical properties of URLs,
hosting infrastructure, and page content (HTML and links).
We also collect new features including HTTP header content,
page frames, dynamically loaded content, page behavior such
as JavaScript events, plugin usage, and a page’s redirection
behavior. Feature collection and URL classiﬁcation occur at
the time a URL is submitted to our service, with the overall
architecture of Monarch scaling to millions of URLs to satisfy
the throughput expected of large social networks and web mail
providers.
In this paper, we evaluate the viability of Monarch as
a real-time ﬁltering service and the fundamental challenges
that arise from the diversity of web service spam. We show
that Monarch can provide accurate, real-time protection, but
that the underlying characteristics of spam do not generalize
across web services. In particular, we leverage Monarch’s
feature collection infrastructure to study distinctions between
11 million URLs drawn from email and Twitter. We ﬁnd that
spam targeting email is qualitatively different from Twitter
spam, requiring classiﬁers to learn two distinct sets of rules
to ensure accuracy. A basic reason for this distinction is that
email spam occurs in short-lived campaigns that quickly churn
through spam domains, while spam on Twitter consists of long
lasting campaigns that often abuse public web hosting, generic
redirectors, and URL shortening services.
Our evaluation also includes an analysis of which URL
features serve as the strongest indicators of spam and their
persistence as spam evolves. We ﬁnd that classiﬁcation re-
quires access to every URL used to construct a landing page,
HTML content, and HTTP headers to ensure the best accuracy.
In contrast, relying solely on DNS entries or the IP address of
spam infrastructure achieves much less accuracy. Furthermore,
without regular retraining and access to new labeled spam
samples, accuracy quickly degrades due to the ephemeral
nature of spam campaigns and their hosting infrastructure.
We deploy a full-ﬂedged implementation of Monarch to
demonstrate its scalability, accuracy, and run-time performance
at classifying tweet and email spam URLs. Using a modest
collection of cloud machinery, we process 638,000 URLs per
day. Distributed classiﬁcation achieves an accuracy of 91%
(0.87% false positives) when trained on a data set of nearly
50 million distinct features drawn from 1.7 million spam
URLs and 9 million non-spam URLs, taking only one hour
to produce a model. While the current false positive rate is
not optimal, we discuss several techniques that can either
lower or ameliorate their impact in Section 6.1. During live
classiﬁcation, each URL takes on average 5.54 sec to process
from start to ﬁnish. This delay is unavoidable and arises from
network requests made by the browser, which is difﬁcult to
speed up; only 1% of overhead comes from instrumenting
the browser for feature collection. The cloud infrastructure
required to run Monarch at this capacity costs $1,587 for a
single month. We estimate that scaling to 15 million URLs per
day would cost $22,751 per month, and requires no changes
to Monarch’s architecture.
In summary, we frame our contributions as:
• We develop and evaluate a real-time, scalable system for
detecting spam content in web services.
• We expose fundamental differences between email and
Twitter spam, showing that spam targeting one web
service does not generalize to other web services.
• We present a novel feature collection and classiﬁcation
architecture that employs an instrumented browser and a
new distributed classiﬁer that scales to tens of millions
of features.
• We present an analysis of new spam properties illu-
minated by our system, including abused free hosting
services and redirects used to mask spam web content.
• We examine the salience of each feature used for detect-
ing spam and evaluate their performance over time.
2. Architecture
In this work we present the design and implementation of
Monarch, a system for ﬁltering spam URLs in real-time as
448
Fig. 1: Intended operation of Monarch. Web services provide URLs
posted to their sites for Monarch to classify. The decision for whether
each URL is spam is returned in real-time.
they are posted to web applications. Classiﬁcation operates
independently of the context where a URL appears (e.g., blog
comment, tweet, or email), giving rise to the possibility of
spam URL ﬁltering as a service. We intend the system to
act as a ﬁrst layer of defense against spam content targeting
web services, including social networks, URL shorteners, and
email.
We show the overall intended operation of Monarch in
Figure 1. Monarch runs as an independent service to which any
web service can provide URLs to scan and classify. During
the period it takes for Monarch’s classiﬁcation to complete,
these services can either delay the distribution of a URL,
distribute the URL and retroactively block visitors if the URL
is ﬂagged as spam (risking a small window of exposure), or
employ a heavier-weight veriﬁcation process to enforce even
stricter requirements on false positives than are guaranteed by
classiﬁcation.
2.1. Design Goals
To provide URL spam ﬁltering as a service, we adopt six
design goals targeting both efﬁciency and accuracy:
1) Real-time results. Social networks and email operate as
near-interactive, real-time services. Thus, signiﬁcant de-
lays in ﬁltering decisions degrade the protected service.
2) Readily scalable to required throughput. We aim to
provide viable classiﬁcation for services such as Twitter
that receive over 15 million URLs a day.
3) Accurate decisions. We want the capability to emphasize
low false positives in order to minimize mistaking non-
spam URLs as spam.
4) Fine-grained classiﬁcation. The system should be ca-
pable of distinguishing between spam hosted on public
services alongside non-spam content (i.e., classiﬁcation
of individual URLs rather than coarser-grained domain
names).
5) Tolerant to feature evolution. The arms-race nature of
spam leads to ongoing innovation on the part of spam-
mers’ efforts to evade detection. Thus, we require the
ability to easily retrain to adapt to new features.
6) Context-independent classiﬁcation. If possible, decisions
should not hinge on features speciﬁc to a particular
service, allowing use of the classiﬁer for different types
of web services.
Fig. 2: System ﬂow of Monarch. URLs appearing in web services are fed into Monarch’s cloud infrastructure. The system visits each URL
to collect features and stores them in a database for extraction during both training and live decision-making.
2.2. System Flow
Figure 2 shows Monarch’s overall internal system ﬂow.
URLs posted to web services are fed into a dispatch queue
for classiﬁcation. The system visits each URL to collect its
associated raw data, including page content, page behavior,
and hosting infrastructure. It then transforms these raw features
into meaningful boolean and real-valued features and provides
these results to the classiﬁer for both training and live decision-
making. During live classiﬁcation, Monarch’s ﬁnal decision is
returned to the party that submitted the URL; they can then
take appropriate action based on their application, such as
displaying a warning that users can click through, or deleting
the content that contained the URL entirely. We now give an
overview of each component in this workﬂow.
URL Aggregation. Our current architecture aggregates URLs
from two sources for training and testing purposes:
links
emailed to spam traps operated by a number of major email
providers and links appearing in Twitter’s streaming API. In
the case of Twitter, we also have contextual information about
the account and tweet associated with a URL. However, we
hold to our design goal of remaining agnostic to the source
of a URL and omit this information during classiﬁcation.
We examine how removing Twitter-speciﬁc features affects
accuracy in Section 6.
Feature Collection. During feature collection,
the system
visits a URL with an instrumented version of the Firefox
web browser to collect page content including HTML and
page links, monitor page behavior such as pop-up windows
and JavaScript activity, and discover hosting infrastructure.
We explore the motivation behind each of these features in
Section 3. To ensure responsiveness and adhere to our goal
of real-time, scalable execution, we design each process used
for feature collection to be self-contained and parallelizable.
In our current architecture, we implement feature collection
using cloud machinery, allowing us to spin up an arbitrary
number of collectors to handle the system’s current workload.
Feature Extraction. Before classiﬁcation, we transform the
raw data generated during feature collection into a sparse
feature vector understood by the classiﬁcation engine. Data
transformations include tokenizing URLs into binary features
and converting HTML content
into a bag of words. We
permanently store the raw data, which allows us to evaluate
new transformations against it over time.
Classiﬁcation. The ﬁnal phase of the system ﬂow produces a
classiﬁcation decision. Training of the classiﬁer occurs off-
line and independent of the main system pipeline, leaving
the live decision as a simple summation of classiﬁer weights.
During training, we generate a labeled data set by taking URLs
found during the feature collection phase that also appear in
spam traps or blacklists. We label these samples as spam, and
all other samples as non-spam. Finally, in order to handle
the millions of features that result and re-train daily to keep
pace with feature evolution, we develop a distributed logistic
regression, as discussed in Section 4.
3. Feature Collection and Extraction
Classiﬁcation hinges on having access to a robust set of
features derived from URLs to discern between spam and
non-spam. Previous work has shown that lexical properties
of URLs, page content, and hosting properties of domains are
all effective routes for classiﬁcation [15], [16], [22]–[24]. We
expand upon these ideas, adding our own sources of features
collected by one of three components: a web browser, a DNS
resolver, and IP address analysis. A comprehensive list of
features and the component that collects them can be found
in Table 1. A single monitor oversees multiple copies of each
component to aggregate results and restart failed processes.
In turn, the monitor and feature collection components are
bundled into a crawling instance and replicated in the cloud.
3.1. Web Browser
Within a crawling instance, a web browser provides the
primary means for collecting features for classiﬁcation. Due
to real-time requirements, a trade-off arises between expedited
load times and ﬁdelity to web standards. Given the adversarial
nature of spam, which can exploit poor HTML parsing or the
lack of JavaScript and plugins in a lightweight browser [25],
449
Source
Initial URL,
Final URL
Redirects
Frame URLs
Source URLs
HTML Content
Page Links
JavaScript Events
Pop-up Windows
Plugins
HTTP Headers
DNS
Geolocation
Routing Data
Collected By
Web browser
Features
Domain tokens, path tokens, query parameters, is obfuscated?, number of subdomains, length of
domain, length of path, length of URL (From here on out, we denote this list as URL features)
Web browser
URL features for each redirect, number of redirects, type of redirect
URL features for each embedded IFrame
Web browser
URL features for every outgoing network request; includes scripts, redirects, and embedded content Web browser
Tokens of main HTML, frame HTML, and script content
Web browser