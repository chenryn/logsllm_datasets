math functionalities that operate on non-uniform minimal
bitwidths. As a baseline, another option is to use existing
2PC protocols that work with a uniform bitwidth (for all
values) that is large enough to accommodate all intermediate
values,
to prior
works, this would force us to work over much larger rings
such as Z264. Since the complexity of secure protocols
grows proportionally with the bitwidth used, our use of
non-uniform bitwidth leads to much more communication
efﬁcient protocols than the na¨ıve approach of uniform
bitwidth. We consider 4 main building blocks to achieve
this: (a) Extension - to increase bitwidths, (b) Truncation
- to decrease bitwidths (and precision), (c) Multiplication
- to multiply an m and n bit integer into an (m + n)-bit
output
is later truncated
to have the right bitwidth required for further operations),
and (d) Digit decomposition - to extract relevant substrings
(that we call digits) of the input bitstring using which table
lookups are performed. Moreover, the ﬁxed-point cleartext
code of our benchmarks also uses non-uniform bitwidths in
linear layers such as matrix multiplications and convolutions,
to avoid overﬂows (this product
and we use our protocols for efﬁcient realizations of the same.
Secure Inference Library. We have implemented our pro-
tocols for math functions in a new library, called SIRNN3,
for DNN inference. We evaluate SIRNN on three state-of-the-
art models that use ﬁxed-point arithmetic with non-uniform
bitwidths [72]. Two of the models, one for the standard
Google-30 dataset and the other for sports training, use an
RNN architecture that provides accurate analysis of time series
data [74]. For the Google-30 dataset, the task is to recognize
commands like “Yes” and “No” from speech data, whereas
the sports training model provides performance feedback to a
sportsperson from sensor readings. To the best of our knowl-
edge, this is the ﬁrst empirical evaluation of secure inference of
RNNs on time series inputs like speech and sensor readings.
While it is possible to perform this inference using generic
2PC protocols, the overheads are intractable. To evaluate this
quantitatively, we implemented our benchmarks using the
state-of-the-art ABY [41] framework and this baseline is three
orders of magnitude worse in latency and communication.
Our third model uses an architecture that combines RNNs
and CNNs for the task of ﬁnding human heads in images [104].
This model uses the reciprocal square root function that is not
supported by any of the prior works on secure inference. Ad-
ditionally, it makes roughly 3 million calls to sigmoid and tanh
each. In contrast, prior works on secure inference evaluated on
models with less than 3000 calls to sigmoid/tanh [83], [102].
SIRNN can run the Heads model securely in under 7 minutes.
To summarize, we make three key contributions:
1) We provide cryptographically friendly new approxima-
tions to math functions exponential, sigmoid, tanh and re-
ciprocal square root that are provably precise (Section V).
for non-uniform
bitwidths (Section IV) that realize these math function-
alities efﬁciently (up to 423× lower communication than
prior work, Section VI-A).
2) We provide novel 2PC protocols
3) We implement these secure implementations in the library
SIRNN that provides the ﬁrst secure inference of RNNs
on speech and time series sensor data and a model
that combines RNNs and CNNs. SIRNN outperforms
state-of-the-art by three orders of magnitude in size of
benchmarks (given by number of calls to math functions),
latency and communication (Section VI-C). Furthermore,
because of the high numerical precision of our math
implementations, SIRNN has no loss in model accuracy.
The rest of the paper is organized as follows. We ﬁrst pro-
vide a motivating example and an overview of our technical re-
sults in Section II. After discussing the necessary background
in Section III, we provide our novel protocols in Section IV.
The math functionalities are discussed in Section V with
their formal veriﬁcation in Section V-D. Section VI provides
our evaluation on microbenchmarks, i.e., math functions in
isolation (Table I & Table II), DNNs used by prior work
that use math functions (Table III), and our RNN-based
3Implementation is available at https://github.com/mpc-msri/EzPC.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:57 UTC from IEEE Xplore.  Restrictions apply. 
1004
int16[2][2] W = ... ; int16[2] x = ...;
int16[2][2] U; int32[2] V; int32[2][2] T; int32[2] S;
U[0][0] = W[0][0]-x[0];
T[0][0] = U[0][0]*U[0][0], ...
V[0] = ((T[0][0] >> 12) + (T[0][1] >> 12), ...
S[0] = exp(-V[0], 32, 12, 32, 30), ...
return sign(S[0] - S[1])
U[0][1] = W[0][1]-x[1]; , ...
Fig. 1: Fixed-point code for SVM with RBF kernel
benchmarks (Table IV). Finally, we discuss other related work
in Section VII.
II. OVERVIEW
We now present an overview of our approximations for
math functions and the building block protocols required
to realize them. We begin with a motivating example of an
inference task that crucially uses math functions; this will
help us highlight concepts such as scale and bitwidth changes.
Motivating example. Support vector machines
(SVMs)
are one of the most widely used classical ML algorithms.
While prior work on secure inference has used SVMs with
polynomial kernels [76], [80], [87], [98] (that helps SVMs
perform classiﬁcation in exponentially large dimensions), the
more powerful and hence widely used Radial Basis Function
(RBF) kernels (that operate on inﬁnite dimensions) [55]
crucially relies on computing exponentiations, i.e., ex, x < 0.
No prior work on secure 2PC inference supports RBF.
Consider the simple task of predicting rain using a feature
vector x ∈ R2, where x[0] and x[1] are temperature and
humidity respectively, and the output is yes (y = −1) or no
(y = 1). An SVM with RBF model infers the result using
(cid:32) k(cid:88)
sign
cie−γ2||Wi−x||2
(cid:33)
i=1
where the vectors Wi ∈ R2 are part of the model and
ci ∈ {−1, 1}. Here, ||Wi − x||2 is the square of the L2 norm
or the Euclidean distance between Wi and x. Let k = 2,
γ = 1, c0 = 1 and c1 = −1.
Scales and bitwidths. Since 2PC is much more efﬁcient
over integers than ﬂoating-point [29], [73], automated ﬂoat-
to-ﬁxed converters [14], [24], [51], [72], [89], [94] can be
used to express this model as computation over integers
using ﬁxed-point
arithmetic,
r ∈ R is (approximately) represented using an (cid:96)-bit integer
(cid:98)r·2s(cid:99) mod 2(cid:96), where (cid:96) is the bitwidth and s ∈ Z is the scale.
Hence, ﬁxed-point integer a with scale s denotes a
In ﬁxed-point
arithmetic.
Consider the ﬁxed-point code for our example given in Fig-
ure 1 generated by a ﬂoat-to-ﬁxed converter. The code stores
the input x and the model parameters W as 16-bit integers
with scale 12 (scale 12 is a common setting used in several
prior works on secure inference [73], [92], [99]). To compute
the inference result, it ﬁrst computes Ui = Wi−x where U has
scale 12 using standard integer subtraction. Next, it computes
T = U (cid:12) U, where (cid:12) is pointwise multiplication. Since U has
2s ∈ R.
16-bit entries, to avoid integer overﬂows, the entries of T must
be 32-bits wide. Standard integer multiplication accumulates
the scale and hence entries in T have a scale of 24. Thus, the
code right shifts the entries of T by 12 to bring the scale back
to 12 and accumulate them in Vi = ||Wi − x||2. Next, it calls
exponentiation on negative inputs of bitwidth 32 and scale 12
and produces the result S with bitwidth 32 and scale 30. The
ﬁnal result is the sign of c0S[0] + c1S[1]. SIRNN incurs less
than 30KB of communication to run this code.
Observe that the ﬁxed-point code in Figure 1 frequently
changes bitwidths and scales with each operation. As we
describe in Figure 3 (Section V), our math functionality
for exponential would require multiplying two 32-bit values
to compute an intermediate 64-bit result. Now, if we had
to implement Figure 1 using existing 2PC protocols, we
would be forced to use uniform bitwidth of at least 64 for
all variables. In particular, the bitwidths of x, W, U, T, V, S
will all be 64 instead of 16 or 32. More generally,
the
requirement of a high bitwidth even in one operation,
coupled with the requirement of uniform bitwidths, raises
the bitwidths of all variables and operations throughout an
inference task, resulting in a communication blowup. In
contrast SIRNN provides novel protocols for these low-level
operations of switching bitwidth and scale and multiplying
values of
small bitwidth into large bitwidth. Ensuring
that bitwidths used in secure code mimic the bitwidths
used in low-bitwidth cleartext code,
is the key factor in
low communication complexity of our secure math functions.
Next we give an overview of our approximations for math
functions followed by building blocks for our protocols.
A. Our approximations for math functions
Our math functionalities are designed keeping cryptographic
costs in mind. We ﬁrst use lookup tables (LUT) to get a
good initial approximation of the math functions and then
run an iterative algorithm such as Goldschmidt’s iterations
to improve upon this approximation. Larger LUTs lead to
more precise results. However, the communication of secure
protocol for LUTs grows linearly with size of LUT. Hence, we
need to strike a balance to obtain implementations that are both
precise and communication efﬁcient. Thus, for exponentiation
for negative inputs, we break the input bitstring x into smaller
d-length substrings (via digit decomposition) that are used
to index multiple 2d-sized LUTs. The looked up values are
multiplied into high bit intermediate results which are then
truncated to match the speciﬁed output bitwidth and scale.
Sigmoid and tanh reduce to exponentiating negative values
and reciprocating values between 1 and 2. For the latter, Ito et
al. [63] provide a method for initial approximation of recip-
rocal using an LUT. After obtaining an initial approximation
with (cid:96) bit entries and (cid:96) − 2 bits of fractional part, we iterate
using standard Goldschmidt’s method. To make these itera-
tions communication efﬁcient, we run them using ﬁxed-point
arithmetic with non-uniform bit-widths. Our implementation
for reciprocal square root is similar but requires additional
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:28:57 UTC from IEEE Xplore.  Restrictions apply. 
1005
work to shift the initial input to be between 1 and 2 using the
most signiﬁcant non-zero bit (MSNZB).
B. 2PC protocols in SIRNN
The 2PC protocols in SIRNN are based on 4 building blocks:
(a) Extension; (b) Truncation; (c) Multiplication; and (d) Digit
decomposition. Our protocols mimic the low bitwidths used
by cleartext ﬁxed-point code, and work over power-of-2 rings,
i.e. Z2(cid:96). Let λ = 128 be the computational security parameter.
a) Extension: This is used to lift values from smaller
ring Z2m to larger ring Z2n (i.e. m < n). Although ex-
tension has been considered in honest majority three-party
computation [67], there are no specialized 2PC protocols for
it. A natural baseline, however, is provided by Yao’s garbled
circuits4 (GC) [115], which requires around λ(4m + 2n) bits
of communication to reconstruct and re-share. In contrast, our
protocol requires around λm bits of communication, that is
roughly 6× better than GC.
b) Truncation: This operation is used to reduce scale
and is often used after multiplication. We require 4 kinds of
truncation operations for (cid:96)-bit values by s bits: logical and
arithmetic right shifts (that preserve the bitwidth), truncate-
and-reduce (outputs the truncated value in Z2(cid:96)−s), and division
by 2s. State-of-the-art protocol for arithmetic right shift (ARS)
was given by [99] with communication roughly λ((cid:96) + s) that
can also be used for logical right shift and truncate-and-reduce.
We give a new protocol for logical/arithmetic right shift with
communication ≈ λ(cid:96), i.e., independent of λs. Moreover, most
of our math functionalities require only truncate-and-reduce
that decreases both scale and bitwidth. We show how to
achieve this in only ≈ λ(s+1) bits of communication. Finally,
our ﬁxed-point benchmarks also require a division by power-
of-2 operation that is different from ARS for negative x and
outputs (cid:100)x/2s(cid:101). Our protocol for this division requires roughly
4.5× less communication than GC.
c) Multiplication: We consider the functionality for mul-
tiplying an m-bit integer with an n-bit integer to produce an
(cid:96) = (m + n)-bit output. This choice of (cid:96) ensures that there
are no overﬂows. A similar functionality has been considered
in the 3-party setting [67] that extends both operands to (cid:96)
bits and then invokes existing multiplication protocols over
(cid:96) bits. This approach can be used in 2PC setting as well
using our optimized protocols for extension (that are 6× better
than GC). We provide an alternate protocol that requires 1.5×
less communication than the na¨ıve approach of extend-then-
multiply.
d) Digit Decomposition: This splits an (cid:96)-bit value into
c = (cid:96)/d digits of d-bits. It can be realized using GC with
communication λ(6(cid:96)− 2c− 2) bits. We propose an optimized
protocol that requires communication of ≈ λ(c − 1)(d + 2)
bits, that is, roughly 5× lower than GC. We build on digit
decomposition for an efﬁcient protocol for MSNZB required
to realize the functionality for reciprocal square root.
Fig. 2: The computed result exp(x) is in error of 3 ULPs
from the mathematically exact result ex. Dots denote the
representable numbers.
III. PRELIMINARIES
A. Math functions and ULP errors
The math functions have irrational outputs which are impos-
sible to represent exactly in ﬁnite number of bits. When using
a ﬁnite-bit representation, like ﬂoating-point or ﬁxed-point, the
most precise implementation is the one that generates correctly
rounded results, i.e., the output of the implementation is a
representable number that is closest to the ideal R result.
However, because of Table maker’s dilemma, such implemen-
tations are computationally very expensive [45]. Consequently,
standard math libraries like GNU’s or Intel’s libm don’t
return the correctly rounded results.
ULP error. The deviation between the ﬁnite-bit output and
the exact result can be quantiﬁed in three ways: absolute error,
relative error, and “units in last place” or ULPs. The former
two have serious issues and the “most natural way to measure
rounding error is in ulps” [48]; standard math libraries use
ULPs to report the precision of their implementations [4],
[111]. To see why this is the case, observe that if r is a
very small real number, then the absolute error between r
and r(cid:48) = 2r, i.e., |r − r(cid:48)| = |r|, is small as well. Hence,
a low absolute error can be achieved even when every bit
|,
of the output is incorrect. Relative error, given by | r−r(cid:48)
remedies this situation and r(cid:48) = 2r leads to high relative errors
irrespective of the magnitude of r. However, the relative error
is undeﬁned for r = 0. ULP errors have the nice property that
they are always well-deﬁned and don’t grow or shrink with
the magnitude of r. At a high level, the ULP error5 between
an exact real result r and the library output a is the number of