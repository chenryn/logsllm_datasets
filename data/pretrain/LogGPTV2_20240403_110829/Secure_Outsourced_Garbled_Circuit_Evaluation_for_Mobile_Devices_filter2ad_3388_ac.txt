function pair indexed at I.
2. Check consistency: Alice then checks that all the
hash seeds were generated by the same function by
checking if:
βb j, j,i = βb j, j,Evl1 (cid:23) RCLW (I,αb j, j,i (cid:28) (αb j, j,Evl1)−1)
for i = 2...e.
If any of these checks fails, Alice
aborts the protocol.
Phase 4: Circuit evaluation
1. Evaluating the circuit:For each evaluation circuit,
the cloud evaluates GCi(gai,gbi) for i ∈ Evl in the
pipelined manner described by Kreuter et al.
in
[25]. Each circuit produces two garbled output
strings, (g f ai,g f bi).
2. Checking the evaluation circuits: Once these output
have been computed, the cloud hashes each evalua-
tion circuit as H1(GCi) =HC (cid:30)i for i ∈ Evl and sends
these hash values to Alice. Alice checks that for ev-
ery i,HCi = HC(cid:30)i. If any of these checks do not pass,
Alice aborts the protocol.
USENIX Association  
22nd USENIX Security Symposium  295
Phase 5: Output check and delivery
1. Committing the outputs:The cloud then generates
random commitment keys kai,kbi and commits the
output values to their respective parties according to
the commitment scheme deﬁned by Kiraz [23], gen-
erating CA j,i = commit(ka j,i,g f a j,i) and CB j,i =
commit(kb j,i,g f b j,i) for j = 1...n and i = 1...e. The
cloud then sends all CA to Alice and CB to Bob.
2. Selection of majority output: Bob opens the com-
mitments CO j,i for j = 1...n and i = 1...e for both
Alice and the Cloud. These commitments contain
the mappings from the hash of each garbled output
wire H2(wb, j,i) to real output values b j,i for j = 1...n
and i = 1...e. The cloud selects a circuit index ma j
such that the output of that circuit matches the ma-
jority of outputs for both Alice and Bob. That is,
f ama j = f ai and f bma j = f bi for i in a set of indices
IND that is of size |IND| > e
2
3. Proof of output consistency: Using the OR-proofs
as described by Kiraz [23], the cloud proves to
Bob that CB contains valid garbled output bit val-
ues based on the de-committed output values from
the previous step. The cloud then performs the same
proof to Alice for her committed values CA. Note
that these proofs guarantee the output was generated
by one of the circuits, but the value ma j remains
hidden from both Alice and Bob.
4. Output release: The cloud then decommits g f ama j
to Alice and g f bma j to Bob. Given these garbled
outputs and the bit values corresponding to the hash
of each output wire, Alice recovers her output string
f a, and Bob recovers his output string f b.
5. Output decryption: Alice recovers her output
fA(a,b) = f a ⊕ ar, while Bob recovers fB(a,b) =
f b⊕ br.
5 Security Guarantees
In this section, we provide a summary of the security
mechanisms used in our protocol and an informal se-
curity discussion of our new outsourced oblivious trans-
fer primitive. Due to space limitations, we provide fur-
ther discussion and proofs of security in our technical
report [6].
Recall from Section 3 that there are generally four se-
curity concerns when evaluating garbled circuits in the
malicious setting. To solve the problem of malicious cir-
cuit generation, we apply the random seed check vari-
ety of cut-&-choose developed by Goyal et al. [11]. To
solve the problem of selective failure attacks, we em-
ploy the input encoding technique developed by Lin-
dell and Pinkas [29]. To prevent an adversary from us-
ing inconsistent inputs across evaluation circuits, we em-
ploy the witness-indistinguishable proofs from shelat and
Shen [41]. Finally, to ensure the majority output value
is selected and not tampered with, we use the XOR-
and-prove technique from Kiraz [23] as implemented by
Kreuter et al. [25].
In combination with the standard
semi-honest security guarantees of Yao garbled circuits,
these security extensions secure our scheme in the mali-
cious security model.
Outsourced Oblivious Transfer: Our outsourced obliv-
ious transfer is an extension of a technique developed by
Naor et al. [37] that allows the chooser to select entries
that are forwarded to a third party rather than returned
to the chooser. By combining their concept of a proxy
oblivious transfer with the semi-honest OT extension by
Ishai et al. [18], our outsourced oblivious transfer pro-
vides a secure OT in the malicious model. We achieve
this result for four reasons:
1. First, since Alice never sees the outputs of the OT
protocol, she cannot learn anything about the gar-
bled values held by the generator. This saves us
from having to implement Ishai’s extension to pre-
vent the chooser from behaving maliciously.
It is important to note that this particular application of
the OOT allows for this efﬁciency gain since the evalua-
tion of the garbled circuit will fail if Alice behaves ma-
liciously. By applying the maliciously secure extension
by Ishai et al. [18], this primitive could be applied gen-
erally as an oblivious transfer primitive that is secure in
the malicious model. Further discussion and analysis of
this general application is outside the scope of this work.
We provide the following security theorem here,
which gives security guarantees identical to the Salus
protocol by Kamara et al. [21]. However, we use dif-
ferent constructions and require a completely different
proof, which is available in our technical report [6].
Theorem 1. The outsourced two-party SFE protocol se-
curely computes a function f (a,b) in the following two
2. Since the cloud sees only random garbled values
and Alice’s input blinded by a one-time pad, the
cloud learns nothing about Alice’s true inputs.
3. Since Bob’s view of the protocol is almost identical
to his view in Ishai’s standard extension, the same
security guarantees hold (i.e., security against a ma-
licious sender).
4. Finally, if Alice does behave maliciously and uses
inconsistent inputs to the primitive OT phase, there
is a negligible probability that those values will hash
to the correct one-time pad keys for recovering ei-
ther commitment key, which will prevent the cloud
from de-committing the garbled input values.
296  22nd USENIX Security Symposium 
USENIX Association
8
(1)The cloud is malicious and
corruption scenarios:
non-cooperative with respect to the rest of the parties,
while all other parties are semi-honest, (2)All but one
party is malicious, while the cloud is semi-honest.
6 Performance Analysis
We now characterize how garbled circuits perform in the
constrained-mobile environment with and without out-
sourcing.1 Two of the most important constraints for
mobile devices are computation and bandwidth, and we
show that order of magnitude improvements for both fac-
tors are possible with outsourced evaluation. We begin
by describing our implementation framework and testbed
before discussing results in detail.
6.1 Framework and Testbed
Our framework is based on the system designed by
Kreuter et al. [25], hereafter referred to as KSS for
brevity. We implemented the outsourced protocol and
performed modiﬁcations to allow for the use of the
mobile device in the computation. Notably, KSS uses
MPI [33] for communication between the multiple nodes
of the multi-core machines relied on for circuit evalu-
ation. Our solution replaces MPI calls on the mobile
device with sockets that communicate directly with the
Generator and Proxy. To provide a consistent compari-
son, we revised the KSS codebase to allow for direct eval-
uation between the mobile device (the Evaluator) and the
cloud-based Generator.2
Our deployment platform consists of two Dell R610
servers, each containing dual 6-core Xeon processors
with 32 GB of RAM and 300 GB 10K RPM hard drives,
running the Linux 3.4 kernel and connected as a VLAN
on an internal 1 Gbps switch. These machines perform
the roles of the Generator and Proxy, respectively, as de-
scribed in Section 4.1. The mobile device acts as the
Evaluator. We use a Samsung Galaxy Nexus phone with
a 1.2 GHz dual-core ARM Cortex-A9 processor and 1
GB of RAM, running the Android 4.0 “Ice Cream Sand-
wich” operating system. We connect an Apple Airport
Express wireless access point to the switch attaching the
servers, The Galaxy Nexus communicates to the Airport
Express over an 802.11n 54Mbps WiFi connection in
an isolated environment to minimize co-channel interfer-
ence. All tests are run 10 times with error bars on ﬁgures
representing 95% conﬁdence intervals.
1We contacted the authors of the Salus protocol [21] in an attempt
to acquire their framework to compare the performance of their scheme
with ours, but they were unable to release their code.
2The full technical report [6] describes a comprehensive list of mod-
iﬁcations and practical improvements made to KSS, including ﬁxes that
were added back into the codebase of KSS by the authors. We thank
those authors for their assistance.
 1e+06
 100000
)
s
m
(
e
m
T
i
 10000
 1000
 100
Outsourced
Non-Outsourced
ED2
ED4
ED8
ED16
Program Size
ED32
ED64
ED128
Figure 3: Execution time for the Edit Distance program
of varying input sizes, with 2 circuits evaluated.
We measured both the total execution time of the pro-
grams and microbenchmarks for each program. All re-
sults are from the phone’s standpoint. We do not mea-
sure the time the programs take to compile as we used
the standard compiler from Kreuter et al. For our mi-
crobenchmarks, the circuit garbling and evaluation pair
is referred to as the ‘evaluation’.
6.2 Execution Time
Our tests evaluated the following problems:
Millionaires: This problem models the comparison of
two parties comparing their net worth to determine who
has more money without disclosing the actual values. We
perform the test on input values ranging in size from 4 to
8192 bits.
Edit (Levenshtein) Distance: This is a string compari-
son algorithm that compares the number of modiﬁcations
required to covert one string into another. We performed
the comparison based on the circuit generated by Jha et
al. [19] for strings sized between 4 and 128 bytes.
Set Intersection: This problem matches elements be-
tween the private sets of two parties without learning
anything beyond the intersecting elements. We base our
implementation on the SCS-WN protocol proposed by
Huang et al. [14], and evaluate for sets of size 2 to 128.
AES: We compute AES with a 128-bit key length, based
on a circuit evaluated by Kreuter et al. [25].
Figure 3 shows the result of the edit distance compu-
tation for input sizes of 2 to 128 with two circuits evalu-
ated. This comparison represents worst-case operation
due to the cost of setup for a small number of small
circuits—with input size 2, the circuit is only 122 gates in
size. For larger input sizes, however, outsourced compu-
tation becomes signiﬁcantly faster. Note that the graph
is logarithmic such that by the time strings of size 32
are evaluated, the outsourced execution is over 6 times
USENIX Association  
22nd USENIX Security Symposium  297
9
Evaluation
Checks
OT
 1e+06
 100000
)
s
m
(
e
m
T
i
 10000
 1000
 100
         NON
OUT        
         NON
         NON
OUT        
OUT        
ED2
ED4
ED8
         NON
OUT        
ED16
Progam
         NON
        NON
         NON
OUT        
OUT        
OUT        
ED32
ED64
ED128
 1e+06
 100000
)
s
m
(
e
m
T
i
 10000
 1000
 100
Outsourced
Non-Outsourced
2
4
8
16
32
Circuits Evaluated
64
128
256
Figure 4: Execution time for signiﬁcant stages of garbled
circuit computation for outsourced and non-outsourced
evaluation. The Edit Distance program is evaluated with
variable input sizes for the two-circuit case.
Figure 5: Execution time for the Edit Distance problem
of size 32, with between 2 and 256 circuits evaluated. In
the non-outsourced evaluation scheme, the mobile phone
runs out of memory evaluating 256 circuits.
faster than non-outsourced execution, while for strings of
size 128 (comprising over 3.4 million gates), outsourced
computation is over 16 times faster.
The reason for this becomes apparent when we exam-
ine Figure 4. There are three primary operations that
occur during the SFE transaction: the oblivious transfer
(OT) of participant inputs, the circuit commit (including
the circuit consistency check), and the circuit generation
and evaluation pair. As shown in the ﬁgure, the OT phase
takes 292 ms for input size 2, but takes 467 ms for input
size 128. By contrast, in the non-outsourced execution,
the OT phase takes 307 ms for input size 2, but increases
to 1860 ms for input size 128. The overwhelming fac-
tor, however, is the circuit evaluation phase. It increases
from 34 ms (input size 2) to 7320 ms (input size 128)
for the outsourced evaluation, a 215 factor increase. For
non-outsourced execution however, this phase increases
from 108 ms (input size 2) to 98800 ms (input size 128),
a factor of 914 increase.
6.3 Evaluating Multiple Circuits
The security parameter for the garbled circuit check is
2−0.32k [25], where k is the number of generated cir-
cuits. To ensure a sufﬁciently low probability (2−80) of
evaluating a corrupt circuit, 256 circuits must be eval-
uated. However, there are increasing execution costs
as increasing numbers of circuits are generated. Fig-
ure 5 shows the execution time of the Edit Distance
problem of size 32 with between 2 and 256 circuits be-
ing evaluated.
In the outsourced scheme, costs rise as
the number of circuits evaluated increases. Linear re-
gression analysis shows we can model execution time
T as a function of the number of evaluated circuits k
with the equation T = 243.2k + 334.6 ms, with a coef-
ﬁcient of determination R2 of 0.9971. However, note
that in the non-outsourced scheme, execution time in-
creases over 10 times as quickly compared to outsourced
evaluation. Regression analysis shows execution time
T = 5435.7k + 961 ms, with R2 = 0.9998. Because in
this latter case, the mobile device needs to perform all
computation locally as well as transmit all circuit data
to the remote parties, these costs increase rapidly. Fig-
ure 6 provides more detail about each phase of execution.
Note that the OT costs are similar between outsourced
and non-outsourced execution for this circuit size, but
that the costs of consistency checks and evaluation vastly
increase execution time for non-outsourced execution.
Note as well that in the non-outsourced scheme, there
are no reported values for 256 circuits, as the Galaxy
Nexus phone ran out of memory before the execution
completed. We observe that a single process on the
phone is capable of allocating 512 MB of RAM before
the phone would report an out of memory error, provid-
ing insight into how much intermediate state is required
for non-outsourced evaluation. Thus, to handle circuits
of any meaningful size with enough check circuits for
a strong security parameter, the only way to be able to
perform these operations is through outsourcing.
Table 1 presents the execution time of a representative
subset of circuits that we evaluated. It spans circuits from
small to large input size, and from 8 circuits evaluated to
the 256 circuits required for a 2−80 security parameter.
Note that in many cases it is impossible to evaluate the
non-outsourced computation because of the mobile de-
vice’s inability to store sufﬁcient amounts of state. Note
as well that particularly with complex circuits such as set