SIM-cards [20, 16, 14] or intrinsic hardware characteristics
such as code execution side-eﬀects [15, 24, 26] and Physically
Unclonable Functions [19]. Interestingly, most proposed im-
plementations employ hash functions and PRNGs that are
not cryptographically secure. Further, works that use cryp-
tographically secure algorithms do not consider whether these
algorithms maintain their security properties in the “keyless”
software attestation scenario where the underlying secrets,
such as the PRNG states, are known to the adversary. This
is the reason why existing analysis papers on remote attes-
tation, such as [4, 8], cannot be applied to software-based
attestation, as they assume trusted hardware or software
components. In this respect, our formal analysis provides a
fundamental ﬁrst step towards a deeper and more compre-
hensive understanding of software attestation.
An approach [13, 12] related to software attestation uses
Quines. The basic idea is that the device outputs the whole
content of its memory such that the veriﬁer can compare it
to the expected memory content. In contrast, software attes-
tation aims to use short outputs only for practical reasons.
In that sense, both approaches can be seen as special in-
stantiations of proof-of-knowledge schemes where the proof
either includes the knowledge itself (Quines) or responses de-
pending on the knowledge (software attestation). A further
diﬀerence is that, to reduce the impact of network jitter, soft-
ware attestation typically minimizes the interaction between
the prover and the veriﬁer. In contrast the Quine-schemes
in [13, 12] require signiﬁcant interaction between the veriﬁer
and the device.
Similar to software attestation protocols, proofs of work
schemes challenge the prover with computationally expen-
sive or memory-bound tasks [6, 7]. However, while the goal
of these schemes is to mitigate denial-of-service attacks and
Spam by imposing artiﬁcial load on the service requester,
the goal of software attestation schemes is using all of the
prover’s resources to prevent it from executing malicious
code within a certain time frame. Hence, proofs of work are
in general not suitable for software attestation since they
are usually less eﬃcient and not designed to achieve the op-
timality requirements of software attestation algorithms.
3. PRELIMINARIES
Notation. Let X, Y be two sets and x ∈ X and y ∈ Y be an
element of each set. We denote with f : X → Y a function
f that maps the set X to set Y . Further f : x (cid:55)→ y means
that function f maps an element x to an element y. Let A
and B be arbitrary algorithms. Then y ← A(x) means that
means that A has black-box access to B. We denote with A(cid:98)B
on input x, A assigns its output to y. The expression AB
an algorithm A that does not access an algorithm B. Let D
be a probability distribution over the set X, then the term
x D← X means the event of assigning an element of X to
variable x that has been chosen according to D. Further, we
deﬁne D(x) := Pr(cid:2)x|x D← X(cid:3) for each x ∈ X and denote
with U the uniform distribution.
System Model. Software attestation is a protocol between
a veriﬁer V and a (potentially malicious) prover P where the
latter belongs to a class of devices with clearly speciﬁed char-
acteristics. That is, whenever we speak about a prover P,
we refer to a device that belongs to this class. Typically
a prover P is a low-end embedded system that consists of
memory and a computing engine (CE). The memory is com-
posed of primary memory (PM), such as CPU registers and
cache, and secondary memory (SM), such as RAM and Flash
memory. We assume that the memory is divided into mem-
ory words and denote by Σ := {0, 1}ls the set of all possible
memory words (e.g., ls = 8 if words are bytes). Let s and p
be the number of memory words that can be stored in SM
and PM, respectively. An important notion is the state of a
prover:
Deﬁnition 1 (State). Let P be a prover, i.e., a device that
belongs to the speciﬁed class of devices. The state State(P) =
S of P are the memory words stored in the secondary mem-
ory (SM) of P.
Note that S includes the program code of P and hence spec-
iﬁes the algorithms executed by P.
The computing engine (CE) comprises an arithmetics and
logic unit that can perform computations on the data in
primary memory (PM) and alter the program ﬂow. For per-
formance reasons, PM is typically fast but also expensive.
Hence, the size of PM is usually much smaller than the size
of SM. To make use of SM, CE includes the Read instruction
to transfer data from SM to PM and the Write instruction
to write data from PM to SM. More precisely, Read(S, a, b)
takes as input a memory address a of SM and a memory ad-
dress b of PM and copies the data word x stored at address
a in SM to the data word at address b in PM. For conve-
nience, we write Read(S, a) instead of Read(S, a, b) whenever
the address b of PM is not relevant. Note that Read(S, a, b)
overwrites the content y of PM at address b. Hence, in
case y should not be lost, it must be ﬁrst copied to SM us-
ing Write or copied to another location in PM before Read
is performed. It is important to stress that, whenever CE
should perform some computation on some value x stored
in SM, it is mandatory that x is copied to PM before CE
can perform the computation. Further, since SM is typically
much slower than PM, Read and Write incur a certain time
overhead and delay computations on x. We denote the time
required by CE to perform some instruction or algorithm
Ins with Time(Ins). Note that we only consider provers as
described above while the veriﬁer V can be an arbitrary com-
puting platform that may interact with P.
Remark 1: Platform Architecture. Note that we focus
on embedded microcontrollers since these are commonly tar-
geted by software attestation. We explicitly exclude provers
that are high-end computing platforms with multiple CPUs
3and/or Direct Memory Access (DMA) since these are typ-
ically equipped with secure hardware (such as TPMs) and
hence could support common cryptographic solutions based
on secrets. Further, their memory architectures are usually
more complex than in our system model. In particular, such
platforms usually feature additional hardware to predict and
fetch memory blocks in advance, making the time-bounded
approach much more diﬃcult and its realization highly de-
pendent on the concrete system.
4. SECURE SOFTWARE ATTESTATION
Secure software attestation enables the veriﬁer V to gain
assurance that the state of a prover P is equal to a particular
If this is the case, we say that P is in state S,
state S.
i.e., formally State(P) = S. Consequently, a prover P is
called honest (with respect to some state S) if State(P) = S,
otherwise it is considered to be malicious.
Prover State. Observe that a prover (cid:101)P is already con-
Remark 2: Distance between Honest and Malicious
sidered to be malicious even if its state diﬀers by only one
state entry (memory word) from S. This is a necessary con-
sequence of the goal of having a deﬁnition of honest and
malicious provers that is as generic as possible.
The common approach of software attestation is to vali-
date the prover’s state by requesting N random samples of
the prover memory content. Hence, the Hamming distance
λ between the state S of an honest prover and the state (cid:101)S
of a malicious prover (cid:101)P directly aﬀects a malicious prover’s
success probability. As far as we know, we are the ﬁrst to
formally take into account the impact of λ on the security
of software attestation schemes (cf. λ in Theorem 1).
Ideal Approach. Ideally, V could disable the computing
engine (CE) of P and directly read and verify the state S
stored in the secondary memory (SM) of P. However, expos-
ing CE and SM of P to V in such a way requires hardware
extensions1 on P, which contradicts the goal of software at-
testation to work with no hardware modiﬁcations.
Practical Approach. As the ideal approach is not feasi-
ble in practice, the common approach in the literature is
that V and P engage in a challenge-response protocol Attest
where P must answer to a challenge of V with a response
that depends on S. In the following, whenever we refer to
a software attestation scheme we actually mean the corre-
sponding challenge-response protocol Attest. Observe that
Attest needs to include a description of the algorithm that
processes the veriﬁer’s challenge and computes the prover’s
response.
In general, software attestation aims to ﬁgure out whether
the original state S of a device has been replaced by the
adversary with a malicious state (cid:101)S (cid:54)= S. Observe that al-
though (cid:101)S is diﬀerent from S, we cannot exclude that (cid:101)S may
depend on S. This implies an important diﬀerence to com-
mon cryptographic scenarios: Software attestation cannot
rely on any secrets since the adversary has access to the
same information as the honest prover P. Therefore soft-
ware attestation follows a fundamentally diﬀerent approach
1Note that existing testing interfaces such as JTAG cannot
be used since they are typically disabled on consumer devices
to prevent damage to the device and unintended reverse-
engineering.
and leverages side-channel information, typically the time
δ the prover takes to compute the response. A basic re-
quirement of this approach is that S speciﬁes a practically
optimal implementation of the algorithm that processes the
challenge according to Attest. This means that it should
be hard to ﬁnd any other implementation of this algorithm
that can be executed by a prover P in signiﬁcantly less time
than δ. Otherwise, a malicious prover could use a faster
implementation and exploit the time diﬀerence to perform
additional computations, e.g., to lie about its state.
Furthermore, the communication time jitter between V
and P is typically much higher than the time needed by
the computing engine of P to perform a few instructions.
Hence, to ensure that V can measure also slight changes to
the prover’s code (that could be exploited by a malicious
prover to lie about its state), V needs to amplify the eﬀect
of such changes. The most promising approach to realize
this in practice is designing the attestation protocol as an
iterative algorithm with a large number of rounds.
Further, since showing the optimality of complex imple-
mentations is a hard problem and since P must compute
the response in a reasonable amount of time, it is paramount
that the individual rounds are simple and eﬃcient. As a re-
sult, cryptographically secure hash functions and complex
Pseudo-Random Number Generators (PRNGs) are not a vi-
able option. Hence, several previous works deployed light-
weight ad-hoc designs of compression functions and PRNGs,
however, without analyzing the underlying requirements on
these components and their interaction. In contrast, we iden-
tify concrete suﬃcient requirements.
Adversary Model and Security Deﬁnition.
receives as input a state S and a time-bound δ.
In the following, we provide the ﬁrst formal speciﬁcation
of the adversary model and the security of a software attesta-
tion scheme Attest based on a security experiment ExpAAttest
that involves an adversary A. The experiment is divided
into two phases and works as follows:
Preparation Phase: At the beginning, the adversary A
It
outputs a (possibly) malicious prover (cid:101)P by specifying
its state (cid:101)S, i.e., State((cid:101)P) = (cid:101)S.
Execution Phase: The prover (cid:101)P speciﬁed in the previous
phase receives a challenge c and returns a “guess”(cid:101)r for
The result of the experiment is accept if (cid:101)P responded within
time δ and(cid:101)r = r , and reject otherwise.
case State((cid:101)P) = S, that is (cid:101)P is in the state expected by V,
the prover (cid:101)P should always succeed, i.e., the result of the ex-
in case State((cid:101)P) (cid:54)= S, the probability that the result of the
Based on this experiment we deﬁne correctness and sound-
ness. Correctness is deﬁned analogously to the common
meaning of correctness of challenge-response protocols: In
the correct response r .
periment should always be accept. Soundness means that
experiment is accept should be below a certain threshold.
Deﬁnition 2 (Correctness and Soundness). Consider a soft-
ware attestation scheme Attest and a state S. For a given ad-
versary A we denote by EqualState the event that the output
of A during the experiment is a prover (cid:101)P with State((cid:101)P) = S.
4The software attestation scheme Attest is correct if for all
adversaries A it holds that
Pr
ExpAAttest(S) = accept|EqualState
= 1.
Attest is ε-secure if for all adversaries A it holds that
Pr
ExpAAttest(S) = accept|¬EqualState
(cid:104)
(cid:104)
(cid:105)
(cid:105) ≤ ε.
Remark 3: Power of A. The security of software atten-
tion signiﬁcantly diﬀers from common cryptographic models,
where the time eﬀort of the adversary is typically bounded
(often polynomially bounded in some security parameter).
More detailed, in the preparation phase, A can be any un-
restricted probabilistic algorithm. However, A has no in-
ﬂuence anymore once Attest is executed between (cid:101)P and V
in the execution phase. As (cid:101)P is a device with the same
characteristics as an honest prover, (cid:101)P has to comply to the
same restrictions as P. In other words, the adversary has un-
bounded resources for preparing the attack but only a tight
time-bound and limited resources for executing the attack.