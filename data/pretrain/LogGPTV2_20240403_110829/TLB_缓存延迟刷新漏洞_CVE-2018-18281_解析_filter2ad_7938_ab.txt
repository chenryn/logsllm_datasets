  * 2) C 循环读取 X 的内容
  * 3) A 调用 mremap 重新映射 X 到 Y, 这个调用会执行下面两个函数: 
    * 3.1) move_ptes , 该函数做如下操作: 
      * 3.1.1) 获取 X 页表和 Y 页表的锁
      * 3.1.2) 遍历 X 对应页表的 pte , 释放之, 并在 Y 页表重建这些 pte
      * 3.1.3) 释放 Y 页表的锁
      * 3.1.4) 释放 X 页表的锁
    * 3.2) flush_tlb_range : 刷新 X 对应的 TLB 缓存
  * 4) B 调用 ftruncate 将文件 a 的文件大小改为 0, 这个调用会执行下面操作: 
    * 4.1) 获取 Y 页表的锁
    * 4.2) 删除 Y 对应的页表
    * 4.3) 释放 Y 对应的 pages
    * 4.4) 刷新 Y 对应的 TLB 缓存
    说明: 
    实际上 X 和 Y 是两块内存区域, 也就是说可能比一个 pmd 所容纳的地址范围大, 
    不管是 mremap 还是 ftruncate, 底层实现会将 X 和 Y 按照 pmd 为单位循环执行上表的操作, 
    即上表所说的 X 页表实际指的是 X 内存区域里的某个 pmd, 这里是为了表达方便简化处理, 
    下面的描述也是一样.
这里存在的竞态条件是当 4.3 已经执行完毕 (3.1.3 释放 Y 锁 4.1 就可以执行), 地址 Y 的内存已经释放, 物理页面已经返回给
[伙伴系统](https://en.wikipedia.org/wiki/Buddy_memory_allocation) , 并再一次分配给新的虚拟内存,
而此时 3.2 还没有执行, 这种情况下, 虽然 X 的映射关系在页表里已经被清空, 但在 TLB 缓存里没有被清空, 线程 C 依然可以访问 X 的内存,
造成地址复用
    注意:
    除了可以用 ftruncate 函数来跟 mremap 竞争, 还有一个 linux 系统特有的
    系统函数 fallocate 也可以起到同样的效果, 原因很简单, 
    fallocate 和 ftruncate 的底层调用链是一样的
    sys_fallocate()->shmem_fallocate()->shmem_truncate_range()
    ->shmem_undo_range()->truncate_inode_page()->unmap_mapping_range
v4.9 之前的内核都是上述列表显示的代码逻辑
v4.9 之后的内核, move_ptes 的逻辑与上述有些许不同
    注意:
    在 versions > 4.9 的 linux 内核, Dirty 标记的页面会在 move_ptes 函数内部刷新 TLB , 
    而不是等到 3.2 由 flush_tlb_range 函数去刷新, 因此, race 发生之后, 
    线程 C 能通过 X 访问到的内存都是之前 non-Dirty 的页面, 即被写过的页面都无法复用. 
    这点改变会对 poc 和 exploit 造成什么影响? 留给大家思考.
## 简单版的 poc
根据上述分析, 一个简单的 poc 思路就出来了, 通过不断检测线程 C 从地址 X 读取的内容是不是初始内容就可以判断 race 是否被触发,
正常情况下, C 读取 X 只会有两种结果, 一种是 mremap 彻底完成, 即 3.2 执行完毕, 此时地址 X 为无效地址, C
的读操作引发进程奔溃退出, 第二种是 mremap 还未完成, C 读取的地址返回的是 X 的初始内容, 只有这两种情况才符合 mremap 函数的定义.
但是由于漏洞的存在, 实际运行会存在第三种情况, 即 C 读取 X 不会奔溃(3.2 还没执行, 地址映射还有效), 但内容变了( 4.3 执行完毕,
物理页面已经被其他地方复用)
[这份 poc](https://github.com/jiayy/android_vuln_poc-exp/tree/master/CVE-2018-18281) 可以清晰看出 race 是怎么发生的, 需要注意, 这份 poc
必须配合内核补丁才能稳定触发 race , 否则命中率非常低, 补丁通过在 move_page_tables 函数调用 flush_tlb_range
之前(即 3.2 之前)增加一个大循环来增大 race 条件的时间窗口以提高命中率
上述 poc 的运行结果是, 大部分情况下 poc 奔溃退出, 少数情况下读取 X 会返回一个被其他地方复用的页面
这离稳定提权还有很远的距离, 为了得到稳定利用, 至少有两个问题需要解决:
  * 如何提高 race 的命中率
  * 怎么实现提权
## 如何提高 race 的命中率
要提高本漏洞 race 的命中率, 就是要增大 move_ptes 函数和 flush_tlb_range 函数之间的时间间隔
    怎么才能增加这俩函数执行的时间间隔呢?
这里要引入linux内核的 [进程抢占](https://en.wikipedia.org/wiki/Linux_kernel#PREEMPTION)
概念, 如果目标内核是可抢占的 (CONFIG_PREEMPT=y) , 则如果能让进程在执行 flush_tlb_range 函数之前被抢占, 那么
race 的时间窗口就够大了, 用户空间的普通程序能不能影响某个进程的调度策略呢? 答案是肯定的.
有两个系统函数可以影响进程的调度
  * [sched_setaffinity](http://man7.org/linux/man-pages/man2/sched_setaffinity.2.html) 函数用来绑定进程到某个 cpu core
  * [sched_setscheduler](http://man7.org/linux/man-pages/man2/sched_setscheduler.2.html) 函数用来设置进程的调度策略和调度参数
使用这两个函数将 poc 修改为下面的方案,
新建 A,B,C,D 四个线程:
  * 1) A 映射一个文件 a 到地址 X, A 绑定到核 c1, A 调度策略设置为 SCHED_IDLE
  * 2) C 绑定到核 c1, C 阻塞在某个 pipe, pipe 返回则调用 ftruncate 将文件 a 的文件大小改为 0
  * 3) A 调用 mremap 重新映射 X 到 Y, 这将执行下面两个函数: 
    * 3.1) move_ptes
    * 3.2) flush_tlb_range
  * 4) D 绑定到核 c2, 监控进程的内存映射情况,如果发生变化则通过写 pipe 唤醒 C
  * 5) B 绑定到核 c3, 循环读取 X 的内容, 并判断是否还是初始值
    注意:
    mremap 执行 move_ptes 函数会引发内存状态变化, 这种变化可以通过
    用户态文件 /proc/pid/status 文件获取, 这就是线程 D 的作用
此时, 通过监控线程 D 唤醒 C, 由于A 和 C 绑定在同一个核心 c1, 且 A 的调度策略被设置  
为最低优先级 SCHED_IDLE, C 的唤醒将抢占 A 的执行, 如此一来, 3.2 的执行就可能被延迟.  
C 被唤醒后立即执行 ftruncate 释放 Y 的内存触发漏洞.
通过上述方案可以理论上让线程 A 在执行 3.1 后, 执行 3.2 前被挂起,  
从而扩大 3.1 和 3.2 的时间间隔
[这个 poc](https://github.com/jiayy/android_vuln_poc-exp/blob/master/CVE-2018-18281-Android/poc.old.c) 是根据上述思路写的
## 改进版的 poc
实测发现上述 poc 触发率还是低, 借鉴 Jann Horn 的思路, 继续如下修改 poc
改进版方案: 新建 A,B,C,D,E 五个线程:
  * 1) A 映射一个文件 a 到地址 X, A 绑定到核 c1, A 调度策略设置为 SCHED_IDLE
  * 2) C 绑定到核 c1, C 阻塞在某个 pipe, pipe 返回则立即将 A 重新绑定到核 c4, 并调用 ftruncate 将文件 a 的文件大小改为 0
  * 3) A 调用 mremap 重新映射 X 到 Y 
    * 3.1) move_ptes
    * 3.2) flush_tlb_range
  * 4) D 绑定到核 c2, 监控进程的内存映射情况,如果发生变化则通过写 pipe 唤醒 C
  * 5) B 绑定到核 c3, 循环读取 X 的内容, 并判断是否还是初始值
  * 6) E 绑定到核 c4, 执行一个死循环.
改进的地方有两点, 1 是增加一个 E 线程绑定到核 c4 并执行死循环, 2 是线程 C 被唤醒后立刻重绑定线程 A 到核 c4, 即让 A 和 E
在同一个核上
这个改变会提高 race 触发的命中率, 个人判断原因是由于当 C 的管道返回后手动执行重绑定操作会比执行其他操作更容易导致 A 立即被挂起
[改进版 poc 代码](https://github.com/jiayy/android_vuln_poc-exp/blob/master/CVE-2018-18281-Android/poc.c) 是根据上述思路写的
利用这个 poc, 我们可以将这个漏洞的 race 命中率提升到可以接受的程度.
## 物理页面管理
现在我们可以在比较短的时间内稳定触发漏洞, 得到一片已经被释放的物理页面的使用权,  
而且可读可写, 怎么利用这一点来提权?
这里需要了解物理内存的分配和释放细节,
物理内存管理属于[伙伴系统](https://en.wikipedia.org/wiki/Buddy_memory_allocation), 参考
[内存管理](https://github.com/pjhades/tolarian-academy/blob/master/linux-mm.md)
物理页面的管理是分层的:
  * node: NUMA 体系架构有 node 的概念, 不同 node 的物理内存是分开管理的
  * zone: 根据物理内存的区域分若干种 zone, 不同场景会优先向不同的 zone 分配 , 比如用户空间申请内存, 会优先从 ZONE_NORMAL 这个 zone 分配, 如果不够再从其他 zone 分配 
    * ZONE_DMA
    * ZONE_NORMAL
    * ZONE_HIGHMEM
    * 其他
  * migration-type: 内核根据可迁移性对页面进行分组管理, 用于 anti-fragmentation, 可以参考 [内核页面迁移与反碎片机制](https://www.jeanleo.com/2018/09/06/%E3%80%90linux%E5%86%85%E5%AD%98%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91%E9%A1%B5%E9%9D%A2%E8%BF%81%E7%A7%BB/)
    * MIGRATE_UNMOVABLE
    * MIGRATE_RECLAIMABLE
    * MIGRATE_MOVABLE
__alloc_pages_nodemask 函数是 zoned buddy allocator 的分配入口, 它有快慢两条路径:
  * get_page_from_freelist , 快路径 
    * 1) if order == 0, 从 per-cpu 的指定 zone 指定 migratetype 的 cache list 里获取 page 
      * pcp = &this_cpu_ptr(zone->pageset)->pcp
      * list = &pcp->lists[migratetype]
      * page = list_entry(list->next, struct page, lru);
    * 2) __rmqueue_smallest : 在指定迁移类型下自底向上进行各阶遍历查找所需的空闲页面 
      * area = &zone->free_area[current_order]
      * list = &area->free_list[migratetype]
      * page = list_entry(list->next, struct page, lru);
    * 3) __rmqueue_cma, [连续内存分配器](https://www.jeanleo.com/2018/09/07/%E3%80%90linux%E5%86%85%E5%AD%98%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E3%80%91%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8%EF%BC%88cma%EF%BC%89/) 用于DMA映射框架下提升连续大块内存的申请
    * 4) __rmqueue_fallback, 如果在指定迁移类型下分配失败，且类型不为MIGRATE_RESERVE时, 就在 fallbacks 数组里找到下一个 migratetype, 由此获得的阶号和迁移类型查找zone->free_area[]->free_list[]空闲页面管理链表
  * __alloc_pages_slowpath, 慢路径 
    * 略
从漏洞利用的角度, 我们希望将漏洞释放的物理页面尽可能快的被重新分配回来, 所以, 用来触发漏洞释放物理页面的场景和重新申请物理页面用来利用的场景,
这两种场景的 zone, migratetype 最好一致, 而且这两个场景的触发最好在同一个 cpu core 上.
比如, 触发漏洞时, 通过用户空间 mmap 一片地址, 然后访问这片地址触发物理内存分配, 这种分配大概率是从 ZONE_NORMAL 而来,
而且页面大概率是 MIGRATE_MOVABLE 的, 然后用 ftruncate 释放, 这些页面很可能会挂在当前 cpu 的 freelist 上.
所以, 漏洞利用的时候如果是在其他 cpu core 触发申请物理页面, 则可能申请不到目标页面, 或者, 触发申请物理页面的场景如果是某种 dma 设备,
那么也大概率命中不到目标页面.
## 怎么实现提权
根据上述物理内存管理的分析, 选择使用文件的 page cache 用于重新申请目标物理页面, 在此基础上, 想办法实现提权
linux 上硬盘文件的内容在内核用 page cache 来维护, 如果漏洞触发后释放的页面被用于某个文件的 page cache,
则我们拥有了读写该文件的能力, 如果这个文件恰好是用户态的重要动态库文件, 正常情况下普通进程无法改写这种文件, 但通过漏洞普通进程可以改写它,
这样就可以通过修改动态库文件的代码段来提权.
上述利用思路的关键有3点:
  * 选择目标动态库文件
  * 选择目标文件要改写的位置