αi.
(2)
As we increase the window size w, we can detect more
subtle changes in the underlying churn trend. If λ or αn,l
exceed a manually deﬁned threshold, an alert is raised.
Section 5.3 elaborates on how we can select a threshold
in practice.
4.3.2 Uptime matrix
For convenience, Sybil operators are likely to administer
their relays simultaneously, i.e., update, conﬁgure, and
reboot them all at the same time. This is reﬂected in their
relays’ uptime. An operating system upgrade that re-
quires a reboot of Sybil relays will induce a set of relays
to go ofﬂine and return online in a synchronized manner.
To isolate such events, we are visualizing the uptime pat-
terns of Tor relays by grouping together relays whose up-
time is highly correlated. The churn technique presented
above is similar but it only provides an aggregate, high-
level view on how Tor relays join and leave the network.
Since the technique is aggregate, it is poorly suited for
visualizing the uptime of speciﬁc relays; an abnormally
high churn value attracts our attention but does not tell
us what caused the anomaly. To ﬁll this gap, we comple-
ment the churn analysis with an uptime matrix that we
will now present.
This uptime matrix consists of the uptime patterns of
all Tor relays, which we represent as binary sequences.
Each hour, when a new consensus is published, we add
a new data point—“online” or “ofﬂine”—to each Tor re-
lay’s sequence. We visualize all sequences in a bitmap
whose rows represent consensuses and whose columns
1174  25th USENIX Security Symposium 
USENIX Association
51015TimeNew relays per hourJun 05Jun 15Jun 25Jul 05Jul 1551020TimeNew relays per hourSep 03Sep 08Sep 13Sep 18Sep 23Sep 280.020.040.060.080200400600Threshold for churn value αMax. undetected SybilsMaximumRealisticFigure 7: The uptime matrix for 3,000 Tor relays for
all of November 2012. Rows represent consensuses and
columns represent relays. Black pixels mean that a relay
was online, and white means ofﬂine. Red blocks denote
relays with identical uptime.
represent relays. Each pixel denotes the uptime status
of a particular relay at a particular hour. Black pixels
mean that the relay was online and white pixels mean
that the relay was ofﬂine. This type of visualization was
ﬁrst proposed by Ensaﬁ and subsequently implemented
by Fiﬁeld [12].
Of particular importance is how the uptime sequences
are sorted. If highly correlated sequences are not adja-
cent in the visualization, we might miss them. We sort
sequences using single-linkage clustering, a type of hier-
archical clustering algorithm that forms groups bottom-
up, based on the minimum distance between group mem-
bers. For our distance function, similar to Andersen et
al. [1, § II.B], we use Pearson’s correlation coefﬁcient
because it tells us if two uptime sequences change to-
gether. The sample correlation coefﬁcient r yields a
value in the interval [−1,1]. A coefﬁcient of −1 denotes
perfect anti-correlation (relay R1 is only online when re-
lay R2 is ofﬂine) and 1 denotes perfect correlation (relay
R1 is only online when relay R2 is online). We deﬁne our
distance function as d(r) = 1− r, so two perfectly cor-
related sequences have a distance of zero while two per-
fectly anti-correlated sequences have a distance of two.
Once all sequences are sorted, we color ﬁve or more ad-
jacent sequences in red if their uptime sequence is iden-
tical. Figure 7 shows an example of our visualization al-
gorithm, the uptime matrix for a subset of all Tor relays
in November 2012.
4.3.3 Fingerprint analysis
The information a Tor client needs to connect to an onion
service is stored in a DHT that consists of a subset of all
Tor relays, the onion service directories (HSDirs). As
of June 2016, 47% of all Tor relays serve as HSDirs. A
daily-changing set of six HSDirs hosts the contact infor-
mation of any given onion service. Tor clients contact
one of these six HSDirs to request information about the
onion service they intend to connect to. A HSDir be-
comes responsible for an onion service if the difference
between its relay ﬁngerprint and the service’s descriptor
ID is smaller than that of any other relay. The descrip-
tor ID is derived from the onion service’s public key, a
time stamp, and additional information. All HSDirs are
public, making it possible to determine at which posi-
tion in the DHT an onion service will end up at any point
in the future. Attackers can exploit the ability to pre-
dict the DHT position by repeatedly generating identity
keys until their ﬁngerprint is sufﬁciently close to the tar-
geted onion service’s index, thus becoming its HSDir [4,
§ V.A].
We detect relays that change their ﬁngerprint fre-
quently by maintaining a lookup table that maps a relay’s
IP address to a list of all ﬁngerprints we have seen it use.
We sort the lookup table by the relays that changed their
ﬁngerprints the most, and output the results. Note that
reboots or newly assigned IP addresses are not an issue
for this technique—as long as relays do not lose their
long-term keys that are stored on their hard drive, their
ﬁngerprint stays the same.
4.3.4 Nearest-neighbor ranking
We frequently found ourselves in a situation where ex-
itmap discovered a malicious exit relay and we were left
wondering if there were similar, potentially associated
relays. Looking for such relays involved tedious manual
work, which we soon started to automate. We needed
an algorithm for nearest-neighbor ranking that takes as
input a “seed” relay and creates as output a list of all re-
lays, ranked by their similarity to the seed relay. We de-
ﬁne similarity as shared conﬁguration parameters such as
port numbers, IP addresses, exit policies, or bandwidth
values. Our algorithm ranks relays by comparing these
conﬁguration parameters.
To quantify the similarity between two relays, we
use the Levenshtein distance [18], a distance metric that
takes as input two strings and determines the minimum
number of modiﬁcations—insert, delete, and modify—
that are necessary to turn string s2 into s1. Our algorithm
turns the router statuses and descriptors of two relays into
strings and determines their Levenshtein distance. As an
example, consider a simple representation consisting of
the concatenation of nickname, IP address, and port. To
turn string s2 into s1, six operations are necessary; four
modiﬁcations (green) and two deletions (red):
s1: Foo10.0.0.19001
s2: Bar10.0.0.2549001
Our algorithm determines the Levenshtein distance
between a “seed” relay and all other relays in a consen-
sus. It then ranks the calculated distances in ascending
order. For a consensus consisting of 6,525 relays, our al-
gorithm takes approximately 1.5 seconds to ﬁnish.5 Note
5We measured on an Intel Core i7-3520M CPU at 2.9 GHz, a
consumer-grade CPU.
USENIX Association  
25th USENIX Security Symposium  1175
7
that we designed our ranking algorithm to assist in man-
ual analysis. Unlike the other analysis techniques, it does
not require a threshold.
5 Evaluation and results
Equipped with sybilhunter, we applied our techniques to
nine years of archived Tor network data. We did not set
any thresholds, to capture every single churn value, ﬁn-
gerprint, and uptime sequence, resulting in an unﬁltered
dataset of several megabytes of CSV ﬁles and uptime
images. We then sorted this dataset in descending or-
der by severity, and began manually analyzing the most
signiﬁcant incidents, e.g., the largest churn values.
In
Section 5.1, we begin by characterizing Sybil groups we
discovered that way. Instead of providing an exhaustive
list of all potential Sybils, we focus on our most salient
ﬁndings—relay groups that were either clearly malicious
or distinguished themselves otherwise.6 Afterwards, we
explore the impact of sybilhunter’s thresholds in Sec-
tions 5.2 to 5.6.
Once we discovered a seemingly harmful Sybil group,
we reported it to The Tor Project. To defend against
Sybil attacks, directory authorities can either remove a
relay from the consensus, or take away its Valid ﬂag,
which means that the relay is still in the consensus, but
Tor clients will not consider it for their ﬁrst or last hop in
a circuit. The majority of directory authorities, i.e., ﬁve
out of nine, must agree on either strategy. This mecha-
nism is meant to distribute the power of removing relays
into the hands of a diverse set of people in different ju-
risdictions.
5.1 Sybil characterization
Table 2 shows the most interesting Sybil groups we iden-
tiﬁed. The columns show (i) what we believe to be the
purpose of the Sybils, (ii) when the Sybil group was at
its peak size, (iii) the ID we gave the Sybils, (iv) the
number of Sybil ﬁngerprints at its peak, (v) the analysis
techniques that could discover the Sybils, and (vi) a short
description. The analysis techniques are abbreviated as
“N” (Neighbor ranking), “F” (Fingerprint), “C” (Churn),
“U” (Uptime), and “E” (exitmap). We now discuss the
most insightful incidents in greater detail.
The “rewrite” Sybils These recurring Sybils hijacked
Bitcoin transactions by rewriting Bitcoin addresses in re-
layed HTML. All relays had the Exit ﬂag and replaced
onion domains found in a web server’s HTTP response
6Our datasets and visualizations are available online, and can be
inspected for an exhaustive set of potential Sybils. The URL is
https://nymity.ch/sybilhunting/.
with an impersonation domain, presumably hosted by
the attacker.
Interestingly, the impersonation domains
shared a preﬁx with the original. For example, the do-
main sigaintevyh2rzvw.onion was replaced with the im-
personation domain sigaintz7qjj3val.onion whose ﬁrst
seven digits are identical to the original. The attacker
could create shared preﬁxes by repeatedly generating key
pairs until the hash over the public key resembled the de-
sired preﬁx. Onion domains are generated by determin-
ing the SHA-1 hash over the public key, truncating it to
its 80 most signiﬁcant bits, and encoding it in Base32.
Each Base32 digit of the 16-digit-domain represents ﬁve
bits. Therefore, to get an n-digit preﬁx in the onion do-
main, 25n−1 operations are required on average. For the
seven-digit preﬁx above, this results in 25·7−1 = 234 op-
erations. The author of scallion [30], a tool for gener-
ating vanity onion domains, determined that an nVidia
Quadro K2000M, a mid-range laptop GPU, is able to
generate 90 million hashes per second. On this GPU,
a partial collision for a seven-digit preﬁx can be found
in 234 ·
90,000,000 (cid:29) 190 seconds, i.e., just over three min-
utes.
We inspected some of the phishing domains and found
that the attackers further replaced the original Bitcoin ad-
dresses with addresses that are presumably controlled by
the attackers, enabling them to hijack Bitcoin transac-
tions. As a result, we believe that the attack was ﬁnan-
cially motivated.
1
The “redirect” Sybils These relays all had the Exit
ﬂag and tampered with HTTP redirects of exit trafﬁc.
To protect their users’ login credentials, some Bitcoin
sites would redirect users from their HTTP site to the
encrypted HTTPS version. This Sybil group tampered
with the redirect and directed users to an impersonation
site, resembling the original Bitcoin site, probably to
steal credentials. We only observed this attack for Bit-
coin sites, but cannot rule out that other sites were not
attacked.
Interestingly, the Sybils’ descriptors and consensus
entries had less in common than other Sybil groups.
They used a small set of different ports, Tor versions,
bandwidth values, and their nicknames did not exhibit
an easily-recognizable pattern. In fact, the only reason
why we know that these Sybils belong together is be-
cause their attack was identical.
We discovered three Sybil groups that implemented
the redirect attack, each of them beginning to surface
when the previous one got blocked. The initial group
ﬁrst showed up in May 2014, with only two relays, but
slowly grew over time, until it was ﬁnally discovered in
January 2015. We believe that these Sybils were run by
the same attacker because their attack was identical.
It is possible that this Sybil group was run by the same
1176  25th USENIX Security Symposium 
USENIX Association
8
Purpose
MitM
Peak activity Group ID
Jan 2016
Nov 2015
Jun 2015
Apr 2015
Mar 2015
Feb 2015
Jan 2015
rewrite∗
rewrite∗
rewrite∗
rewrite∗
redirect†
redirect†
redirect†
Number
42
8
55
71
24
17
26
Fingerprint
Neighbor
Exitm ap