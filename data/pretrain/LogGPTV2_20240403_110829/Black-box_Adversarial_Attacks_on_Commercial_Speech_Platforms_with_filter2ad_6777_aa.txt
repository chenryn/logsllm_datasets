title:Black-box Adversarial Attacks on Commercial Speech Platforms with
Minimal Information
author:Baolin Zheng and
Peipei Jiang and
Qian Wang and
Qi Li and
Chao Shen and
Cong Wang and
Yunjie Ge and
Qingyang Teng and
Shenyi Zhang
1
2
0
2
v
o
N
0
3
]
R
C
.
s
c
[
2
v
4
1
7
9
0
.
0
1
1
2
:
v
i
X
r
a
Black-box Adversarial Attacks on Commercial Speech Platforms
with Minimal Information
Baolin Zheng1,∗, Peipei Jiang1,∗, Qian Wang1,†, Qi Li2, Chao Shen3, Cong Wang4, Yunjie Ge1,
Qingyang Teng1, and Shenyi Zhang1
1 School of Cyber Science and Engineering, Wuhan University
2 Institute of Network Sciences and Cyberspace, Tsinghua University; BNRist
3 School of Cyber Science and Engineering, Xi’an Jiaotong University
4 Department of Computer Science, City University of Hong Kong
{baolinzheng, ppjiang, qianwang}@whu.edu.cn, PI:EMAIL, PI:EMAIL,
PI:EMAIL, {yunjiege, qingyangteng, shenyizhang}@whu.edu.cn
ABSTRACT
Adversarial attacks against commercial black-box speech platforms,
including cloud speech APIs and voice control devices, have re-
ceived little attention until recent years. Constructing such attacks
is difficult mainly due to the unique characteristics of time-domain
speech signals and the much more complex architecture of acoustic
systems. The current “black-box” attacks all heavily rely on the
knowledge of prediction/confidence scores or other probability
information to craft effective adversarial examples (AEs), which
can be intuitively defended by service providers without return-
ing these messages. In this paper, we take one more step forward
and propose two novel adversarial attacks in more practical and
rigorous scenarios. For commercial cloud speech APIs, we propose
Occam, a decision-only black-box adversarial attack, where only
final decisions are available to the adversary. In Occam, we formu-
late the decision-only AE generation as a discontinuous large-scale
global optimization problem, and solve it by adaptively decom-
posing this complicated problem into a set of sub-problems and
cooperatively optimizing each one. Our Occam is a one-size-fits-all
approach, which achieves 100% success rates of attacks (SRoA) with
an average SNR of 14.23dB, on a wide range of popular speech and
speaker recognition APIs, including Google, Alibaba, Microsoft,
Tencent, iFlytek, and Jingdong, outperforming the state-of-the-art
black-box attacks. For commercial voice control devices, we pro-
pose NI-Occam, the first non-interactive physical adversarial attack,
where the adversary does not need to query the oracle and has no
access to its internal information and training data. We, for the first
time, combine adversarial attacks with model inversion attacks,
and thus generate the physically-effective audio AEs with high
transferability without any interaction with target devices. Our ex-
perimental results show that NI-Occam can successfully fool Apple
Siri, Microsoft Cortana, Google Assistant, iFlytek and Amazon Echo
with an average SRoA of 52% and SNR of 9.65dB, shedding light on
non-interactive physical attacks against voice control devices.
KEYWORDS
Speech recognition; speaker recognition; adversarial attacks; black-
box attacks
∗ The first two authors contributed equally to this work.
† Qian Wang is the corresponding author.
ACM Reference format:
Baolin Zheng1,∗, Peipei Jiang1,∗, Qian Wang1,†, Qi Li2, Chao Shen3, Cong
Wang4, Yunjie Ge1, Qingyang Teng1, and Shenyi Zhang1. 2021. Black-box
Adversarial Attacks on Commercial Speech Platforms with Minimal Infor-
mation. In Proceedings of Proceedings of the 2021 ACM SIGSAC Conference
on Computer and Communications Security, Virtual Event, Republic of Korea,
November 15–19, 2021 (CCS ’21), 23 pages.
https://doi.org/10.1145/3460120.3485383
1 INTRODUCTION
Nowadays, with the advance of speech and speaker recognition
technologies, they are reshaping the way we interact with ubiq-
uitous smart devices. More specifically, automatic speech recogni-
tion (ASR) technologies [41] allow machines to understand human
voices, while speaker recognition (SR) technologies [37, 71] enable
machines to identify a person from the characteristics of his/her
voices1. As a result, ASR and SR have become universal in our
daily lives, ranging from personal voice assistants (PVAs) [14, 46]
to biometric authentication [20, 79] on various smart devices. The
popularity of such speech services allows people to greatly enjoy
the convenience of integrating speech as a new input for smart
devices to perform daily and even complicated tasks. For exam-
ple, Amazon has released Alexa [1] and Auto SDK [4] that allow
users to make credit card payments and control vehicles with voice
interaction, respectively.
Despite their wide applications, the excessive use of voice com-
mands in safety-critical systems, like autonomous driving [38, 59]
and biometric identification, also poses potential safety hazards.
A line of recent researches [12, 23, 92] have extensively demon-
strated the vulnerability of acoustic systems to numerous types of
abnormal audios, such as noises and inaudible ultrasounds. These
attacks, however, can be easily detected and/or defended by differ-
entiating and analyzing the nature (i.e., legitimate or malicious) of
the received audio signals. Inspired by the resounding success of ad-
versarial attacks against image recognition systems [24, 40, 62, 78],
more recent researches have begun to investigate the feasibility of
adversarial examples in the audio domain [47], as shown in Table 1.
The very first attempts made by Carlini et al. [25] and Yuan et
al. [90] have shown that ASR systems are also inherently vulnerable
to audio AEs in the white-box scenarios, where the attackers can
1To facilitate differentiation, in the following discussions we abbreviate automatic
speech recognition and speaker recognition to ASR and SR, respectively.
make full use of a prior knowledge of the structure and parameters
inside the system. When it comes to black-box settings, however,
the success of adversarial attacks in the image domain is hard to
be ported to the audio domain, mainly owing to the multiple non-
trivial challenges presented by the unique characteristics of time-
domain speech signals and the much more complex architecture of
acoustic systems.
As evidenced by [80], Taori et al. combined genetic algorithms
[84] and gradient estimation [28], which have been proved effec-
tive in the image domain [13, 19], to carry out a black-box attack
against open-source DeepSpeech [42] but with only a success rate
of 35%. Besides, considering that the attacker requires query ac-
cess to the last layer (i.e., logits) of DNNs inside the DeepSpeech,
such attacks become unrealistic when applied to the closed-source
ASR systems. More recently, Chen et al. [32] showed that when
the confidence scores are publicly known, several commercial ASR
systems are vulnerable to adversarial inputs, but with only a very
limited number of target commands. Almost instantaneously, Du et
al. [35] and Chen et al. [26] presented the first black-box adversarial
attacks against SR systems that both heavily relied on prediction
scores. However, such kind of scores defined by the attackers or
provided by speech service APIs may be useless to legitimate users,
so service providers can easily hide these scores to defend against
the above black-box attacks. Besides, there also exist a significant
number of speech service APIs (e.g., Alibaba Short Speech Recogni-
tion API [11], iFlytek Speech-to-Text API [3]) which do not return
any intermediate information (e.g., confidence/prediction scores or
other probabilities), except for the final decision results, e.g., final
transcriptions in ASR systems and user-ids in SR systems.
From the practical perspective, the prior efforts are important but
not satisfactory enough with respect to the minimum information
as required by the adversary to launch a successful black-box attack.
We may ask: “is it possible to launch effective and practical audio
adversarial attacks against commercial black-box speech platforms
with the minimum information?” We are facing this opportunity
already, more facing a big challenge mainly due to the extreme lack
of information about the target model. Specifically, the acoustic
system, which involves non-linear feature extraction steps to cope
with the intricate frequency feature changes in the time dimen-
sion, is much more complicated than the image processing system.
Furthermore, a speech vector usually contains nearly one hundred
thousand variables, far exceeding the hundreds or thousands of
pixels in images, i.e., MNIST and CIFAR-10 are 28×28 and 32×32
respectively. As reported in [88], the explicit interdependencies
among the massive number of variables significantly hinder the
successful construction of audio AEs.
1.1 Our Works
Generally speaking, there are mainly two types of black-box speech
platforms. One is commercial Cloud Speech APIs that provide audio
services to users, and the other is commercial Voice Control Devices,
such as Apple Siri, which perform the speech-to-text task in the
physical world. In this paper, we present two attack schemes, Oc-
cam2, a decision-only attack on cloud speech APIs, and NI-Occam,
a non-interactive physical attack on voice control devices.
Occam. In our first design, we take one more step forward and
focus on real-world threat scenarios where the adversary has access
to an oracle (target model) which returns only its final decision.
We propose Occam, a decision-based black-box adversarial attack
against cloud speech APIs. We demonstrate that various commercial
speech API services, such as Google Cloud Speech-to-Text, Alibaba
Cloud Speech-to-Text, and Microsoft Azure Speech Service, are
inherently vulnerable to audio AEs generated by our Occam, even
if no internal information is exposed to the adversary.
Our key idea of Occam is to formulate the decision-based black-
box attack against smart acoustic systems as a discontinuous large-
scale global optimization problem, on the basis of the final discrete
decision (the attacker can only obtain) and a large number of opti-
mization variables incurred by the speech. Inspired by this obser-
vation, we develop a novel technique called CC-CMA-ES, which
applies a cooperative co-evolution (CC) framework to the pow-
erful covariance matrix adaptation evolution strategy (CMA-ES),
to solve the large and complex problem in the strictly black-box
setting. More specifically, CC-CMA-ES first decomposes the com-
plicated problem into a set of smaller and simpler sub-problems,
and then uses CMA-ES to cooperatively optimize each one by mod-
eling their local geometries. To improve the attack efficiency, we
further propose an adaptive counterpart, which allows the sub-
problem size and the decomposition strategy to self-adapt to the
environmentally changeable evolution process.
We conduct extensive experiments to evaluate our attack ca-
pabilities on both speech and speaker recognition tasks, and also
compare it with five decision-based black-box methods to demon-
strate the superiority of Occam. We first craft audio adversarial
examples against the local DeepSpeech model in the strictly black-
box setting, achieving perfect success rates in both targeted and
untargeted attacks. Then, we launch black-box adversarial attacks
on a wide range of commercial speech-to-text API services, includ-
ing Google, Microsoft, Alibaba, Tencent, and iFlytek, with success
rates of 100% and an average SNR of 14.37dB. Furthermore, we
verify the attack effectiveness against commercial SR systems in-
cluding Microsoft and Jingdong. It still achieves success rates of
100% and an average SNR of 14.07dB.
NI-Occam. In our second design, we further probe the possibility
of launching more rigorous and practical attacks on voice control
devices, where the adversary still has no access to internal informa-
tion and training data of the oracle, and does not even need to make
queries to probe it. We, for the first time, propose a non-interactive
physical attack, named NI-Occam, which successfully attacks many
commercial voice control devices without any interaction. We show
that NI-Occam works well in real-world attack scenarios, where
audio AEs are played over-the-air.
Our key idea of NI-Occam is to combine adversarial attacks with
model inversion attacks [29, 36, 94]. More specifically, we make
the attempt to recover the key parts of natural commands audio
that are critical for speech recognition on the original example via
2Occam comes from the famous Occam’s razor that plurality should not be posited
without necessity, indicating that our attacks against speech platforms can be per-
formed with minimal information.
Carlini et al. [25]
CommanderSong [90]
Taori et al. [80]
SGEA [82]
Devil’s Whisper [32]
SirenAttack [35]
FakeBob [26]
Ours
White-box
White-box
Black-box
Black-box
Black-box
Black-box
Black-box
Black-box
Digital
Digital
Digital
Digital
Digital
Physical
Digital
Digital
Digital
Physical
Task
ASR
ASR
ASR
ASR
ASR
ASR
SR
SR
ASR
SR
ASR
Knowledge
Gradient
Gradient
Prediction score
Prediction score
Confidence score
Gradient
Prediction score
Prediction score
Final decision
None♯
✗
✗
✗
✗
Commercial§ Queries
∼1000
∼100
∼300,000
∼300,000
∼1500
∼1000
∼7500
∼5000
∼30,000
∼10,000
✗
✗
✗
✓
✓
✓
0
SRoA†
100%
100%
<40%
100%
∼50%♭
<100%
100%
100%
100%
100%
∼50%
Table 1: An overview of the state-of-the-art adversarial audio attacks against ASR and SR systems.
Method
Threat Scenario Attack Type‡
Note that, (i) ‡: “Digital” means that audio AEs are injected into target systems, while “Physical” means that audio AEs are played over-the-air. (ii) §: “ ✓” means that the target
model is the commercial platforms, otherwise “ ✗”. (iii) †: SRoA denotes the success rate of attack. It calculates the proportion of adversarial examples that can successfully attack
target systems. (iv) ♯: Our physical attack focuses on the non-interactive setting where the adversary has no access to the oracle (the target model). (v) ♭: The SRoA of “∼50%”
is calculated from our reproduced experiments on 5 digital speech APIs. Since the confidence scores are not available from Alibaba, iFlytek, and Tencent, we have omitted the
score-related processing step in reproduced experiments of Devil’s Whisper on these three speech APIs. Targeting Google TTS and Microsoft ASR (which return confidence scores),
we did not omit the score-related steps from Devil’s Whisper. That is, we followed the original version of Devil’s Whisper when conducting the experiments on Google and Microsoft.
More details about our reproduced experiment can be found at Table 4.
the gradient information. Since these two audios are well blended
together in model inversion process, it is difficult to be separated by
human ears, which significantly hinders people from recognizing
the malicious audio. Finally, our proposed NI-Occam can success-
fully fool Apple Siri, Microsoft Cortana, Google Assistant, iFlytek,
and Amazon Echo with an average SRoA of 52%. Human perception
experiments further show that after being heard once, only 6.4%
auido AEs can be recognized as target commands by volunteers.
We emphasize that our attacks have the following highlights:
1) Practicality. They are able to attack commercial black-box plat-
forms in the real-world scenarios without any prior knowledge;
2) Generality. They are able to attack a wide range of commercial
cloud speech APIs and voice control devices; 3) Effectiveness. They
are able to automatically and easily generate audio AEs with high
success rates of attack.
Contribution. Our major contributions are summarized as follows.
• Generic black-box attacks with the minimum required information.
We present a novel decision-only audio adversarial attack, named
Occam, under the strictly black-box scenario where the attackers
can rely solely on the final decisions available in any application
cases, and this is quite different from the state-of-the-art black-
box adversarial attacks against commercial Cloud Speech APIs. In
this sense, our attack strategy is the first one that can fool both
commercial ASR and SR services, to our best knowledge.
• Effective attacks with a perfect success rate of attack. We thoroughly
evaluate our attack on a wide range of popular open-source and
commercial (A)SR systems, including Google, Alibaba, Microsoft,
Tencent, iFlytek, Jingdong, and DeepSpeech systems. Extensive
experiments demonstrate that our attack is highly effective with a
success rate of 100% and an average SNR of 14.23dB on commer-
cial speech services, outperforming the state-of-the-art black-box