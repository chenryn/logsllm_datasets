0.167
0.137
0.163
0.120
0.182
338
Sb
0.533
0
0
0
0.457
0.947
Sb
0.004
0.296
0.311
0
0.038
0.649
Sb
0.339
0.246
0.297
0.262
0.328
1
Sb
0.024
0.026
0.028
0.032
0.025
0.467
Sb
0.104
0.140
0.160
0.143
0.138
0.995
S
C
S
C
S
C
S
C
S
C
to previous reports; we mitigated this risk through the large
sample size and discuss it in more detail in Section V-G. The
distribution of crawler hits was skewed left, characterized by
a small number of early requests from the entity to which we
reported, followed by a large stream of trafﬁc from it as well
as other entities. Importantly, different cloaking techniques
showed no signiﬁcant effect on the time of the ﬁrst crawling
attempt;
the median response time ranged from 50 to 53
minutes, from the time of reporting, for all ﬁlter types.
During our full experiments, only sites which were crawled
were ultimately blacklisted. Generally, the crawling also had
to result in successful retrieval of the phishing content for
blacklisting to occur, though in 10 cases (all in the GSB
experiment with Filter D), a site would be blacklisted despite
a failed retrieval attempt; possible factors for this positive
phishing classiﬁcation are described in prior work [20].
B. Entity Scoring
For each entity tested, let U be the set of phishing URLs
reported to the entity, let B be the set of browsers monitored,
let T be the set of observed blacklisting times, let F be the
set of cloaking ﬁlters used, and let M S denote the worldwide
browser market share. Additionally, we deﬁne the value of the
function accessible(b, f) to be true if and only if a phishing
site with ﬁlter f is designed to be accessible in browser b.
U, per Formula
For each URL-browser combination in B
1, we deﬁne a normalized performance score SU RLb on the
range r0, 1s, where 0 represents no blacklisting and 1 repre-
sents immediate blacklisting relative to the time reported. The
score decays linearly over our 72-hour observation window
Ś
TABLE VII: Formulas for aggregate scores (per test).
ą
@ b, U RL P B
#
1 ´ TU RL blacklistedb
ą
0
@ b, f P B
Twindow
F, Sbf “
U, SU RLb
´ TU RL reported
ÿ
“
(1)
blacklisted in b
otherwise
SU RLb
n
Sbf
n
(2)
(3)
(4)
@ b P B, Sb “
S “ÿ
ÿ
U RL, FU RL“f
f, accessiblepb, fq
M Sb
M SB
¨ Sb
b
“
(e.g. a site blacklisted after 36 hours would have SU RLb
0.5). We take the average of all these URL-browser scores for
each browser-ﬁlter combination, as Sbf , per Formula 2.
We further aggregate the Sbf scores to meaningfully sum-
marize the protection of each browser by each entity: the
browser score Sb, as per Formula 3, is the average of all Sbf
for a given browser b, but limited to ﬁlters f accessible in
b. To gauge the blacklisting of each cloaking ﬁlter, we report
P Bf as the raw proportion of sites blacklisted in at least one
browser for each respective ﬁlter. Note that P Bf will always
be greater than or equal to any Sbf because the former is not
reduced by poor timeliness; we thus additionally report T Bf ,
the mean time to blacklisting for each ﬁlter f (in minutes).
To capture the overall real-world performance of each entity,
we average all Sb, weighted by the market share of each
browser, to produce S, as per Formula 4. The scores S allow
us to efﬁciently compare the performance between entities
and would be useful in modeling long-term trends in future
deployments of PhishFarm. We also include and the proportion
of all sites crawled, C, to illustrate the entity’s response effort.
We present the aforementioned aggregate scores in Table VI
for all entities in the full tests. Indeed, the large number
of 0 or near-0 scores was disappointing and representative
of multiple ecosystem weaknesses which we discuss in the
following sections. Scores for the preliminary tests are found
in Table VIII in Appendix II. Note that because Chrome,
Firefox, and Safari showed nearly identical scores across
all experiments, we simplify the table to report the highest
respective score under the GSB heading. We make a similar
simpliﬁcation for IE 11 on Windows 10 and 8.1.
We do not separately report
the performance of mo-
bile browsers because we observed the behavior of mobile
browsers to be directly related to their desktop counterparts.
During the preliminary tests, mobile Firefox and Opera mir-
rored the blacklisting— and thus also the scores— of their
desktop versions. Mobile Chrome and Mobile Safari showed
no blacklist warnings whatsoever for any of our phishing
sites and thus receive Sb scores of 0. During the full tests,
the behavior of mobile Chrome, Safari, and Opera remained
unchanged. Firefox stopped showing blacklist warnings, and
its scores thus dropped to 0 (the 0 scores of mobile browsers
represented a serious issue; this was corrected after we con-
tacted Google and Mozilla after the full tests, as discussed in
Section VI-A1). We did not test mobile versions of Microsoft
(cid:18)(cid:20)(cid:22)(cid:19)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:45 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 2: Blacklisting over time in each browser (full tests).
Fig. 3: Effect of cloaking on blacklisting over time (full tests).
browsers because mobile IE is no longer supported; Edge for
Android and iOS was released after we began testing.
C. Preliminary vs. Full Tests
We observed many core similarities when comparing the
performance same entity between the preliminary and full
tests. We also saw improvements related to the recommenda-
tions we shared during our disclosure meetings, in particular
with respect to the APWG’s treatment of Filters C and E.
Notably, during the full tests, crawler trafﬁc to sites with
cloaking increased by 44.7% relative to sites without cloaking,
while the overall trafﬁc volume also increased by 89.7%. We
discuss all entity-speciﬁc improvements in section V-F.
The comparison also revealed some surprises, however. The
main experimental difference between the two sets of tests,
apart from sample size, was our exclusive use of random URLs
in the full tests. On the other hand, the preliminary tests in-
cluded a sampling of deceptive URLs. In the preliminary tests,
we observed that Edge and IE were quick to display blacklist
warnings for sites with certain deceptive URLs. In fact, many
Type IV URLs (with domain names containing either the
PayPal brand or deceptive keywords) saw proactive zero-hour
warnings in these browsers without any prior crawler activity.
Figure 5b in Appendix II shows the effect of URL type on
blacklisting in the preliminary tests. During the full tests, no
phishing site was blacklisted unless it had previously been
visited by a crawler. In the absence of deceptive URLs, we
thus observed all the blacklists to be purely reactive; this, in
turn, led to lower Sb scores of Edge, IE, and sites with Filter
B, and a lower overall score S for SmartScreen.
D. Browser Performance
Figure 2 shows the percentage of our phishing sites black-
listed over the course of all the full experiments, grouped by
browser, but limited to sites intended to be accessible in each
respective desktop browser (i.e. Filter B was excluded for all
and Filters C and D were excluded for IE, Edge, and Opera).
Chrome, Safari, and Firefox consistently exhibited the high-
est overall blacklisting speed and coverage, but were still far
from covering all cloaked sites. Opera generally outperformed
the Microsoft browsers during the ﬁrst four hours, but was later
overtaken for the remainder of our experimental period. In the
absence of deceptive phishing URLs, Edge and IE simply lost
their edge in the full tests; Figure 5c in Appendix II shows
their superior performance in the preliminary tests.
1) Consistency Between Browsers: Chrome, Firefox, and
Safari are all protected by the GSB blacklist; our tests
conﬁrmed these browsers do consistently display blacklist
warnings for the same set of websites. However, during our full
tests, Chrome displayed warnings up to 30 minutes earlier than
Safari, and up to one hour earlier than Firefox; the warnings
became consistent after the ﬁve-hour mark. Upon further
investigation, we believe that this disparity was caused by
different caching implementations of the GSB Update API (v4)
in each browser (this API ensures privacy and quick lookups
but requires periodic refreshes of the entire blacklist [53]).
Latency is a notable shortcoming of blacklists [6] and it
appears that browser blacklist caching can still be improved
from a security perspective.
Edge and IE 11 (both protected by SmartScreen) proved
far less consistent. In the full tests, Edge displayed warnings
up to two hours earlier and covered more sites than IE until
the 24-hour mark. However, in the preliminary tests— which
involved deceptive URLs detectable by heuristics— IE would
often display preemptive warnings for sites which would not
be blocked in Edge for several hours, if at all. These deviations
were evident in the preliminary APWG, SmartScreen, and
PayPal tests as per Table VIII in Appendix II.
E. Filter Performance
Figure 3 shows the percentage of our phishing sites black-
listed over the course of all the full experiments, grouped by
cloaking ﬁlter type. Because this summary view masks some
of the distinctive per-entity behavior we observed in Table VI,
Figure 4 in Appendix I should be consulted as a supplement.
Note that because these ﬁgures consider all browser-ﬁlter
combinations, their Y-axes differ from Figure 2 and the Sbf
scores in Table VI. Nevertheless, they all convey the ﬁnding
that there exist considerable gaps in today’s blacklists.
The overall earliest blacklisting we observed occurred after
approximately 40 minutes, in Chrome. Signiﬁcant growth took
place between 1.5 and 6.5 hours and continued at a slower
rate thereafter for the full 72-hour period. Compared to sites
without cloaking, our cloaking techniques showed moderate
(cid:18)(cid:20)(cid:22)(cid:20)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:45 UTC from IEEE Xplore.  Restrictions apply. 
to high effectiveness throughout the life of each phishing site.
Filter B saw no blacklisting whatsoever across any desktop
or mobile browser we tested. Filters E and F proved most
effective in the early hours of deployment, while the geo-
speciﬁc Filters C and D saw the lowest amount of blacklisting
in the long term. Between 48 and 72 hours after deployment,
sites with Filter E overtook Filter A sites by a small margin;
upon further analysis, we found that this was due to a high
level of interest in such sites following reporting to the APWG.
All other types of sites with cloaking were on average less
likely to be blacklisted than sites without.
F. Entity Performance
Although no single entity was able to overcome all of
the cloaking techniques on its own, collectively the entities
would be successful in doing so, with the exception of Filter
B (this has since been corrected as per the discussion in
Section VI-A1).
1) Google Safe Browsing: Due to the high market share
of the browsers it protects, GSB is the most impactful anti-
phishing blacklist today. It commanded the highest score S
in both the preliminary and full tests. GSB’s key strength lies
in its speed and coverage: we observed that a crawler would
normally visit one of our sites just seconds after we reported it.
94.7% of all the sites we reported in the full tests were in fact
crawled, and 97% of sites without cloaking (Filter A) ended
up being blacklisted. Blacklisting of Filter D was comparable,
and Filter F improved over the preliminary tests.
However, GSB struggled with Filter E, which blocked
hostnames speciﬁc to Google crawlers. It also struggled with
Filter C, which denied non-US trafﬁc. The reason the re-
spective P Bf scores are low is that if the initial crawler
hit on the phishing site failed, GSB would abandon further
crawling attempts; the initial hit almost always originated from
a predictable non-US IP address. Another weakness appears
to be data sharing, as none of the sites we reported to GSB
ended up being blacklisted in Edge, IE, or Opera.
2) Microsoft SmartScreen: SmartScreen proved to be the
only native anti-phishing blacklist to leverage proactive URL
heuristics to blacklist phishing sites, which allowed Microsoft
browsers to achieve high scores during the preliminary tests.
These heuristics were mainly triggered by URLs with a
deceptive domain name. In the preliminary tests, Edge proved
to be exceptionally well-protected, achieving a top Sb score
of 0.87— the highest of any browser.
In the full tests, the performance of IE improved over the
preliminary tests and became more consistent with that of
Edge. Surprisingly, SmartScreen was more likely to blacklist
sites with cloaking than those without, possibly due to use
of classiﬁcation of cloaking (which would be commendable)
alongside low trust of our phishing reports (see Limitations).
Reporting to SmartScreen did not seem to signiﬁcantly
affect any non-Microsoft browsers; the entity thus shares a
similar shortcoming with GSB. SmartScreen was also among
the slowest entities to reactively respond to phishing reports,
and its overall coverage was poor, which is its key weaknesses.
3) APWG: The APWG was the second-highest scoring
entity in our full tests and showed consistent protection of
all browsers. Its score S increased substantially compared to
the preliminary tests due to improvements to bypass Filters C
and E, which allowed APWG reports to result in blacklisting
of such sites in GSB browsers— something not achieved when
we reported directly to GSB. The APWG also generated the
highest level of crawler trafﬁc of any entity we tested.
Unfortunately, the APWG failed to blacklist any sites with
Filter D or F in the full tests; its preliminary success proved
to have been related solely to the detection of deceptive URLs
by IE and Edge. Interestingly, we saw a large increase in the
blacklisting of sites with Filter E after the 24-hour mark; after
analyzing the trafﬁc logs we believe that this is due to data
sharing with PayPal (this trend is also reﬂected in Figure 4e).
4) PhishTank: PhishTank is a community-driven clearing-
house that allows human volunteers to identify phishing con-
tent [54]; it also leverages a network of crawlers and partners
to aid in this effort. It was the second-highest performer in
our preliminary tests thanks to its expeditious blacklisting in
GSB browsers. In the full tests, we were surprised to see that
only 46.7% of sites reported were crawled, and very few sites
were ultimately blacklisted. Despite this, PhishTank generated
the second-highest volume of total crawler trafﬁc. We do not
know the reasons for its shortcomings and PhishTank did not
reply to our disclosure; we suspect that the manual nature of
classiﬁcation by PhishTank may be a limiting factor.
5) PayPal: During the preliminary tests, PayPal’s own
abuse reporting service struggled to bypass Filters D and F, but
overcame the latter in the full experiments while maintaining
a moderate degree of blacklisting. Its protection of Opera also
improved between the two tests. Despite crawling all but two
of the sites we reported in the full tests, the average response
time and browser protection ended up being poor overall. We
cannot disclose the reasons for this but expect to see a future
improvement as a result of our ﬁndings.
6) Remaining Entities: Performance scores for entities
only included in the preliminary tests are found in Table VIII
within Appendix II. High-level descriptions of each follow.
All sites we reported to ESET ended up being crawled, but
only a fraction of those– all with Filter A– were actually black-
listed. Overall timeliness was poor, though the blacklisting did
span multiple browsers. Netcraft yielded the best protection
of Opera in the preliminary tests, but overall it struggled
with most of our cloaking techniques and did not deliver
timely blacklisting. In retrospect, given the unexpectedly poor
performance of PhishTank in the full tests, we would have
been interested in re-testing Netcraft. Reports to the US CERT
led to minimal crawler activity and blacklisting; disregarding
heuristics from the Microsoft browsers, only a single site was
blacklisted. Phishing reports we sent to McAfee effectively
bypassed Filter A and Filter E but only appeared to lead to
timely blacklisting in Microsoft Edge. Reports to WebSense
had no effect beyond crawler trafﬁc related to the URL
heuristics used by Microsoft; while we were hopeful the e-
mail reporting channel we used would prove fruitful, this is
(cid:18)(cid:20)(cid:22)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:45 UTC from IEEE Xplore.  Restrictions apply. 
understandable given that the company focuses on protection
of its enterprise customers.
G. Limitations
Our ﬁndings are based on a controlled (to the extent possible
without sending out real spam e-mails) empirical experiment
and observations from a large set of supporting metadata
and a high volume of anti-abuse crawler trafﬁc. Our study
focuses exclusively on native phishing blacklist protection that
is available by default in the browsers and platforms tested.
Systems with third-party security software may see enhanced
protection [6], though cloaking can also have an impact on
systems powering such software.
Within its scope, our analysis should still be considered
with certain limitations in mind. We suspect that real-world
blacklisting of phishing attacks may be more timely than
what our results otherwise suggest, as our efforts to isolate
cloaking as a variable in our experimental design (i.e. by
using randomized domain names, never rendering the actual
phishing content in browsers being monitored, and using .com
domains months after registration) also eliminated many of
the methods that the ecosystem can use to detect or classify
phishing (e.g. URL-, network-, or DNS-based analysis). How-
ever, this reduced detectability is offset, to an extent, by the
possibility of malicious actors to likewise evade such forms of
detection. We observed in the preliminary tests that only URLs
containing brand names were quicker to be blacklisted than
others; in the wild, there is also a shifting tendency to abuse
compromised infrastructure and distribute random phishing
URLs in lieu of more deceptive alternatives [8], [49]. In terms
of factors under our control, it was not ﬁnancially feasible to
achieve a one-to-one mapping between IP addresses and all of
our domains; this is a skewing factor which may have acted in
favor of blacklists in the full tests, such as with the 10 Filter
D sites which were blacklisted despite not being successfully
retrieved during the GSB experiment.
Finally, we only submitted a single and direct report for each
phishing site deployed. Although real-world phishing sites
might see a much higher volume of automated reports (e.g.
from sources such as spam ﬁlters), the volume of per-URL
phishing reports in the wild can in fact be reduced by attackers
(e.g. through the use of redirection links). More importantly,
direct reports such as ours (in particular to the blacklist
operators) might be subject to more suspicion because anti-
phishing entities must account for adversaries who willingly
submit false reports or seek to proﬁle crawling infrastructure.
Although the blacklist operators to which we disclosed did not
express concern with our reporting methodology, we learned
that crawling infrastructure used to respond to direct reports
is indeed designed to be unpredictable to mitigate adversarial
submissions. SmartScreen’s lower crawl rate may be explained
by this; GSB, on the other hand, consistently responded
quickly and seemed to give our direct reports a high level
of priority. It is therefore possible that either classiﬁcation of
reporting channel abuse works very accurately, or that report-
ing channels are more vulnerable to adversarial submissions
than what the entities otherwise believe; regardless, to improve
the future effectiveness of reporting, we propose an alternative
approach in Section VI-B2.
Ultimately, if each report represents a chance that a phishing
site will be blacklisted, we believe that our experimental
design still captures trends therein; moreover, our ﬁndings with
respect to cloaking effectiveness are consistent with internal
PayPal e-mail and web trafﬁc data pertaining to actual victims
of phishing. To address its current limitations, our framework
could be adapted to follow a different (possibly collaboratively
arranged) reporting methodology, consider a broader range of
cloaking techniques, or even be applied to proactively-detected
live phishing URLs for which cloaking can be proﬁled.
1) Statistical Tests: In the full tests, we were surprised to
ﬁnd the blacklisting performance of each entity with respect to
the different ﬁlters to have far more clear-cut gaps than in the
preliminary tests; 11 of the 30 the per-entity ﬁlter groups saw
no blacklisting whatsoever (per Table VI). Although ANOVA
as originally planned could still be meaningfully applied to
the subset of entities which had three or more ﬁlter groups
that satisﬁed homogeneity of variance [50] (i.e. had some
blacklisting activity), we chose not to perform such tests as