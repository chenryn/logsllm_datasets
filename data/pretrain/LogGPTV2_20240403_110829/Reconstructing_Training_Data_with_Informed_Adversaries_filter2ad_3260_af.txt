against deep neural networks,” in IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), 2020.
[19] A. Salem, Y. Zhang, M. Humbert, P. Berrang, M. Fritz,
and M. Backes, “ML-Leaks: Model and data independent
membership inference attacks and defenses on machine
learning models,” in Network and Distributed System
Security Symposium (NDSS), 2019.
[20] M. Nasr, R. Shokri, and A. Houmansadr, “Compre-
hensive privacy analysis of deep learning: Passive and
active white-box inference attacks against centralized and
federated learning,” in IEEE Symposium on Security and
Privacy (SP), 2019.
[21] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei,
and I. Sutskever, “Language models are unsupervised
multitask learners,” 2019.
[22] Z. Wang, M. Song, Z. Zhang, Y. Song, Q. Wang, and
H. Qi, “Beyond inferring class representatives: User-
level privacy leakage from federated learning,” in IEEE
Conference on Computer Communications (INFOCOM),
2019.
[23] J. Geiping, H. Bauermeister, H. Dr¨oge, and M. Moeller,
“Inverting gradients - how easy is it to break privacy in
federated learning?” in Conference on Neural Informa-
tion Processing Systems (NeurIPS), 2020.
[24] A. Wainakh, F. Ventola, T. M¨ußig, J. Keim, C. G.
Cordero, E. Zimmer, T. Grube, K. Kersting, and
M. M¨uhlh¨auser, “User label leakage from gradients in
federated learning,” arXiv:2105.09369, 2021.
Paverd, O. Ohrimenko,
[25] S. Z. B´eguelin, L. Wutschitz, S. Tople, V. R¨uhle,
and
A.
“Analyzing information leakage
M. Brockschmidt,
language models,” in ACM
of updates
Conference on Computer and Communications Security
B. K¨opf,
to natural
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:22:08 UTC from IEEE Xplore.  Restrictions apply. 
1151
(CCS), 2020.
[26] A. Salem, A. Bhattacharya, M. Backes, M. Fritz, and
Y. Zhang, “Updates-leak: Data set inference and recon-
struction attacks in online learning,” in USENIX Security
Symposium, 2020.
[27] P. McCullagh and J. A. Nelder, Generalized linear mod-
els. Routledge, 2019.
[28] R. W. Wedderburn, “On the existence and uniqueness of
the maximum likelihood estimates for certain generalized
linear models,” Biometrika, 1976.
[29] R. Zhang, P. Isola, A. A. Efros, E. Shechtman, and
O. Wang, “The unreasonable effectiveness of deep fea-
tures as a perceptual metric,” in IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), 2018.
[30] P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros, “Image-to-
image translation with conditional adversarial networks,”
in IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), 2017.
[31] X. Mao, Q. Li, H. Xie, R. Y. Lau, Z. Wang, and
S. Paul Smolley, “Least squares generative adversarial
networks,” in IEEE International Conference on Com-
puter Vision (ICCV), 2017.
[32] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner,
“Gradient-based learning applied to document recogni-
tion,” Proceedings of the IEEE, 1998.
[33] S. Zagoruyko and N. Komodakis, “Wide residual net-
works,” in British Machine Vision Conference (BMVC),
2016.
[34] S. Fort,
J. Ren, and B. Lakshminarayanan, “Ex-
ploring the limits of out-of-distribution detection,”
arXiv:2106.03004, 2021.
[35] H. Li, Z. Xu, G. Taylor, C. Studer, and T. Gold-
stein, “Visualizing the loss landscape of neural nets,” in
Conference on Neural Information Processing Systems
(NeurIPS), 2018.
[36] T. Hennigan, T. Cai, T. Norman, and I. Babuschkin,
“Haiku: Sonnet for JAX,” 2020. [Online]. Available:
http://github.com/deepmind/dm-haiku
[37] M. Jagielski, J. Ullman, and A. Oprea, “Auditing differ-
entially private machine learning: How private is private
sgd?” Advances in Neural Information Processing Sys-
tems, 2020.
[38] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and
M. Naor, “Our data, ourselves: Privacy via distributed
noise generation,” in International Conference on the
Theory and Applications of Cryptographic Techniques
(EUROCRYPT), 2006.
[39] I. Mironov, “R´enyi differential privacy,” in IEEE Com-
puter Security Foundations Symposium (CSF), 2017.
[40] M. Bun and T. Steinke, “Concentrated differential pri-
vacy: Simplifications, extensions, and lower bounds,” in
Theory of Cryptography Conference (TCC), 2016.
[41] A. Bhowmick, J. C. Duchi, J. Freudiger, G. Kapoor,
reconstruction
in private federated learning,”
“Protection against
and R. Rogers,
and its applications
arXiv:1812.00984, 2018.
[42] N. Papernot, S. Song, I. Mironov, A. Raghunathan,
K. Talwar, and ´U. Erlingsson, “Scalable private learning
with PATE,” in International Conference on Learning
Representations (ICLR), 2018.
[43] I. Mironov, K. Talwar, and L. Zhang, “R´enyi differ-
ential privacy of the sampled gaussian mechanism,”
arXiv:1908.10530, 2019.
[44] A. Blum, C. Dwork, F. McSherry, and K. Nissim, “Prac-
tical privacy: the SuLQ framework,” in ACM Symposium
on Principles of Database Systems (PODS), 2005.
[45] F. McSherry, “I suspect the ”Discovery” had a different
feel for the various involved people. I personally spent
a lot of time trying to remove explicit references to
adversaries and assumptions about
them.” Jan 2021.
[Online]. Available: https://twitter.com/frankmcsherry/
status/1354789417727234049
[46] D. Kifer and A. Machanavajjhala, “Pufferfish: A frame-
work for mathematical privacy definitions,” ACM Trans.
Database Syst., 2014.
[47] A. Ghosh and R. Kleinberg, “Inferential privacy guar-
antees for differentially private mechanisms,” in Inno-
vations in Theoretical Computer Science Conference
(ITCS), 2017.
[48] S. P. Kasiviswanathan and A. D. Smith, “On the ’seman-
tics’ of differential privacy: A bayesian formulation,” J.
Priv. Confidentiality, 2014.
[49] Y. Duan, “Privacy without noise,” in ACM Conference on
Information and Knowledge Management (CIKM), 2009.
[50] R. Bhaskar, A. Bhowmick, V. Goyal, S. Laxman, and
A. Thakurta, “Noiseless database privacy,” in Inter-
national Conference on the Theory and Application
of Cryptology and Information Security (ASIACRYPT),
2011.
[51] R. Bassily, A. Groce, J. Katz, and A. D. Smith, “Coupled-
worlds privacy: Exploiting adversarial uncertainty in sta-
tistical data privacy,” in IEEE Symposium on Foundations
of Computer Science (FOCS), 2013.
[52] D. Desfontaines, E. Mohammadi, E. Krahmer, and
D. Basin, “Differential privacy with partial knowledge,”
arXiv:1905.00650, 2019.
[53] R. Shokri, J. Freudiger, M. Jadliwala, and J. Hubaux,
“A distortion-based metric for location privacy,” in ACM
Workshop on Privacy in the Electronic Society (WPES),
2009.
[54] R. Shokri, G. Theodorakopoulos, J. L. Boudec, and
J. Hubaux, “Quantifying location privacy,” in IEEE Sym-
posium on Security and Privacy (SP), 2011.
[55] L. Wasserman and S. Zhou, “A statistical framework for
differential privacy,” Journal of the American Statistical
Association, 2010.
[56] P. Kairouz, S. Oh, and P. Viswanath, “The composition
theorem for differential privacy,” in International Con-
ference on Machine Learning (ICML), 2015.
[57] B. Balle, G. Barthe, M. Gaboardi, J. Hsu, and T. Sato,
“Hypothesis testing interpretations and renyi differential
privacy,” in International Conference on Artificial Intel-
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:22:08 UTC from IEEE Xplore.  Restrictions apply. 
1152
ligence and Statistics (AISTATS), 2020.
[58] I. Dinur and K. Nissim, “Revealing information while
preserving privacy,” in ACM Symposium on Principles
of Database Systems (PODS), 2003.
[59] C. Dwork, F. McSherry, and K. Talwar, “The price
of privacy and the limits of LP decoding,” in ACM
Symposium on Theory of Computing (STOC), 2007.
[60] C. Dwork, A. Smith, T. Steinke, and J. Ullman, “Ex-
posed! A survey of attacks on private data,” Annual
Review of Statistics and Its Application, 2017.
[61] A. Cohen and K. Nissim, “Linear program reconstruction
in practice,” J. Priv. Confidentiality, 2020.
[62] A. Cohen, S. Nikolov, Z. Schutzman, and J. Ullman,
“Reconstruction attacks in practice,” 2020. [Online].
Available: https://differentialprivacy.org/diffix-attack/
[63] G. Smith, “On the foundations of quantitative informa-
tion flow,” in International Conference on Foundations
of Software Science and Computational Structures (FOS-
SACS), 2009.
[64] M. S. Alvim, K. Chatzikokolakis, A. McIver, C. Morgan,
C. Palamidessi, and G. Smith, The Science of Quantita-
tive Information Flow. Springer, 2020.
[65] E. ElSalamouny, K. Chatzikokolakis, and C. Palamidessi,
“Generalized differential privacy: Regions of priors that
admit robust optimal mechanisms,” in Horizons of the
Mind. A Tribute to Prakash Panangaden - Essays Ded-
icated to Prakash Panangaden on the Occasion of His
60th Birthday, 2014.
[66] B. Balle, G. Cherubin,
“Recon-
structing training data with informed adversaries,”
arxiv:2201.04845, 2022.
and J. Hayes,
[67] M. Shaked and J. G. Shanthikumar, Stochastic orders.
Springer Science & Business Media, 2007.
[68] S. Dasgupta and A. Gupta, “An elementary proof of a
theorem of johnson and lindenstrauss,” Random Struct.
Algorithms, 2003.
[69] M. Johnson, “add gpu determinism note,” Nov 2020.
[Online]. Available: https://github.com/google/jax/pull/
4824
[70] “JAX activations,” https://jax.readthedocs.io/en/latest/jax.
nn.html, accessed: 2022-03-25.
APPENDIX
PROOFS
We provide proof sketches for the main theoretical results
of the paper. Full proofs can be found on the arXiv version of
the paper [66].
Proof sketch of Theorem 1. For a GLM model θ trained to
convergence, (1) takes the form
x(g−1(⟨x, θ⟩) − y) = − ¯X⊤(g−1( ¯Xθ) − ¯Y ) − λθ .
When the model contains an intercept parameter, this yields
d equations with d unknowns (x2, . . . , xd, y) because x1 = 1.
From the equation corresponding to this coordinate we obtain
g−1(⟨x, θ⟩)− y = ¯X⊤
1 B + λθ1, which we can plug in the rest
of equations to obtain the desired expression for x. Once we
have x we plug it back into the first equation to recover y.
Proof sketch of Theorem 2. Fix R : Θ → Z and D- ∈ Z n−1,
and let Z ∼ π, DZ = D- ∪ {Z} and θ ∼ M (DZ). We write
pM (θ|z) = P[M (Dz) = θ] for the output density of M on
input Dz. First we take an arbitrary z0 ∈ Z and show the
probability P[ℓ(Z, R(θ)) ≤ η] equals
pM (θ|z)
pM (θ|z0)
1[ℓ(z, R(θ)) ≤ η]
pM (dθ|z0) .
(cid:18)(cid:90)
(cid:19)
π(dz)
(cid:90)
Next we take α′ = α
H¨older’s inequality bound the inner integral above by:
α−1 and through a standard application of
Z
Θ
(cid:18)(cid:90)
(cid:19)α
(cid:18) pM (θ|z)
pM (θ|z0)
Z
κ1/α′ ·
(cid:19)1/α
π(dz)
.
Plugging this bound into the expression for P[ℓ(Z, R(θ)) ≤ η]
and re-arranging terms, we use Jensen’s inequality and the
RDP assumption on M to obtain:
(cid:19)α ≤
(cid:18)P[ℓ(Z, R(θ)) ≤ η]
(cid:18) pM (θ|z)
(cid:19)α
(cid:90)
(cid:19)α
(cid:18) pM (θ|z)
(cid:18)(cid:90)
(cid:90)
pM (θ|z0)
κπ(η)1/α′
≤
Θ
Z
≤ sup
≤ e(α−1)ϵ .
Θ
z
pM (θ|z0)
(cid:19)
pM (dθ|z0)
π(dz)
pM (dθ|z0)
Proof sketch of Theorem 5. Fix arbitrary D- ∈ Z n−1, z, z′ ∈
Z, z ̸= z′, and E ⊆ Θ, and let π = πp,z,z′. Define the
reconstruction mapping RE mapping θ to z is θ ∈ E and
to z′ otherwise. By the ReRo assumptions on M we have
PZ∼π,θ∼M (DZ )[RE(θ) = Z] ≤ γ. On the other hand, by
definition of π and RE, PZ∼π,θ∼M (DZ )[RE(θ) = Z] equals
P[M (Dz) ∈ E] − eϵP[M (Dz′) ∈ E] + eϵ
.
eϵ + 1
Upper bounding by γ and re-arranging completes the proof.
Proof of Proposition 6. Let π = U(Bd
1 (0)) and write Vol(A)
to denote the Eucliean volume of a set A ⊂ Rd. By definition
of the baseline error, for η ∈ (0, 1) we have
κπ,ℓ2 (η) = sup
z0
Vol(Bd
1 (0) ∩ Bd
Vol(Bd
1 (0))
η (z0))
= ηd = e−Ω(d) ,
where the calculation follows by the standard volume formula
for d-dimensional Euclidean balls. Plugging this expression in
Corollary 3 shows that any ϵ-DP mechanism with ϵ = o(d)
provides (η, γ)-ReRo with respect to π and ℓ with γ = e−Ω(d).
A similar claim follows from Corollary 4 applied to ρ-zCDP
mechanisms with ρ = o(d).
Proof sketch of Proposition 7. Let Z ∼ N (0, I)
and
Fη(z0) = P[∥Z + z0∥2 ≤ η2]. First we show that
argmaxz0 Fη(z0) = 0. The proof of this intuitive fact relies
on extending a 1-dimensional stochastic domination property
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:22:08 UTC from IEEE Xplore.  Restrictions apply. 
1153
of Gaussian random variables [67, Example 1.A.27] to d
dimensions using an orthogonal decomposition of Z along
the space spanned by z0 and its orthogonal complement.
Then we show that for ν = N (w, σ2I) this claim implies
κν,ℓ2(η) = Fη/σ(0). Next we use a tail lower bound for chi-
squared random variables [68, Lemma 2.2] to get
1− η2
κν,ℓ2(η) ≤ e
σ2 d
In particular, for σ ≥ 2η√
we get κν,ℓ2 (η) ≤ e−Ω(d). The
remaining of the proof follows the same argument as in
Proposition 6.
+log η2
σ2d
d
(cid:16)
d
2
(cid:17)
.
APPENDIX
ADDITIONAL EXPERIMENTAL RESULTS
We provide additional experiment results here. The inter-
ested reader can find a more expansive set of findings in [66],