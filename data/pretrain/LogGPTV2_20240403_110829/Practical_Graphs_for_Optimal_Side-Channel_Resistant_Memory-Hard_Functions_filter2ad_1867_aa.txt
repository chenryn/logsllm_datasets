title:Practical Graphs for Optimal Side-Channel Resistant Memory-Hard Functions
author:Jo&quot;el Alwen and
Jeremiah Blocki and
Benjamin Harsha
Practical Graphs for Optimal Side-Channel Resistant
Memory-Hard Functions
Joël Alwen∗
IST Austria
PI:EMAIL
Jeremiah Blocki
Purdue University
PI:EMAIL
Ben Harsha†
Purdue University
PI:EMAIL
ABSTRACT
A memory-hard function (MHF) fn with parameter n can be com-
puted in sequential time and space n. Simultaneously, a high amor-
tized parallel area-time complexity (aAT) is incurred per evaluation.
In practice, MHFs are used to limit the rate at which an adversary
(using a custom computational device) can evaluate a security sensi-
tive function that still occasionally needs to be evaluated by honest
users (using an off-the-shelf general purpose device). The most
prevalent examples of such sensitive functions are Key Derivation
Functions (KDFs) and password hashing algorithms where rate
limits help mitigate off-line dictionary attacks. As the honest users’
inputs to these functions are often (low-entropy) passwords special
attention is given to a class of side-channel resistant MHFs called
iMHFs.
Essentially all iMHFs can be viewed as some mode of operation
(making n calls to some round function) given by a directed acyclic
graph (DAG) with very low indegree. Recently, a combinatorial
property of a DAG has been identified (called “depth-robustness”)
which results in good provable security for an iMHF based on
that DAG. Depth-robust DAGs have also proven useful in other
cryptographic applications. Unfortunately, up till now, all known
very depth-robust DAGs are impractically complicated and little
is known about their exact (i.e. non-asymptotic) depth-robustness
both in theory and in practice.
In this work we build and analyze (both formally and empirically)
several exceedingly simple and efficient to navigate practical DAGs
for use in iMHFs and other applications. For each DAG we:
mal.
• Prove that their depth-robustness is asymptotically maxi-
• Prove bounds of at least 3 orders of magnitude better on
their exact depth-robustness compared to known bounds
for other practical iMHF.
• Implement and empirically evaluate their depth-robustness
and aAT against a variety of state-of-the art (and several
∗Supported by the European Research Council, ERC consolidator grant (682815 -
TOCNeT).
†Supported in part by a CERIAS/Intel Research Assistant award.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’17, October 30-November 3, 2017, Dallas, TX, USA
© 2017 Copyright held by the owner/author(s). Publication rights licensed to Associa-
tion for Computing Machinery.
ACM ISBN 978-1-4503-4946-8/17/10...$15.00
https://doi.org/10.1145/3133956.3134031
new) depth-reduction and low aAT attacks. We find that,
against all attacks, the new DAGs perform significantly
better in practice than Argon2i, the most widely deployed
iMHF in practice.
Along the way we also improve the best known empirical attacks on
the aAT of Argon2i by implementing and testing several heuristic
versions of a (hitherto purely theoretical) depth-reduction attack.
Finally, we demonstrate practicality of our constructions by modi-
fying the Argon2i code base to use one of the new high aAT DAGs.
Experimental benchmarks on a standard off-the-shelf CPU show
that the new modifications do not adversely affect the impressive
throughput of Argon2i (despite seemingly enjoying significantly
higher aAT).
CCS CONCEPTS
• Security and privacy → Hash functions and message au-
thentication codes;
KEYWORDS
hash functions; key stretching; depth-robust graphs; memory hard
functions
1 INTRODUCTION
A memory-hard function (MHF) is a family of functions equipped
with an honest algorithm N for evaluating them such that N re-
quires a limited amount of (sequential) computation and memory,
yet no parallel amortized algorithm can significantly reduce the
product of space and time required per evaluation of the MHF.
Intuitively, the goal of MHFs is to limit the advantage (in terms
of dollar per rate of evaluation) that an adversary equipped with
a (potentially highly parallel) custom computational device such
as an FPGA or an Application Specific Integrated Circuit (ASIC)
has over the average honest user who only has an (essentially se-
quential) general purpose CPU at their disposal. In practice, MHFs
are useful in applications where we would like to limit the rate
at which an adversary can evaluate a particular function while
simultaneously not preventing honest parties from evaluating the
function at a moderate rate. An important family of such functions
are found in password based cryptography. For example we may
wish to limit the rate at which an adversary can evaluate a KDF or
password hashing algorithm in order to increase the difficulty of
the adversary performing dictionary attacks.
Data (In)Dependence. MHFs can generally be divided into two
categories. A data-dependent MHF (dMHF) is characterized by the
property that the memory-access pattern of N depends on the input
to the MHF. Conversely, if the property does not hold then we use
Session E1:  Hardening CryptoCCS’17, October 30-November 3, 2017, Dallas, TX, USA1001the term data-independent MHF (iMHF). The latter are particularly
interesting in the context of password hashing as they naturally
resist a class of side-channel attacks (e.g. cache-timing attack [13])
which could potentially leak sensitive information about the inputs;
namely about the password being hashed. However this resistance
does come at a price; certain dMHFs such as scrypt have been
shown to enjoy strictly greater memory-hardness [9] then can
possibly be achieved by any iMHF [5]. Therefore, for practical MHF
applications where inputs are not sensitive (such as proof-of-work
protocols), it is generally preferred to make use of dMHFs such as
scrypt or Argon2d.
Recently an interesting hybrid MHF was proposed by the authors
of the Argon2 RFC [17] called Argon2id. The first part of the execu-
tion consists of an iMHF followed by a dMHF. Intuitively in order
to leverage any side-channel information gleaned about the dMHF
segment of a computation, the full iMHF part must first be com-
puted to test for each new input being matched against the leaked
information. Thus Argon2id represents a elegant middle ground
between time/memory resistance and side-channel resistance. Be-
cause of its use of the initial iMHF section, any improvements to
our understanding and construction of iMHFs would also directly
benefit an Argon2id like construction, e.g. by improving the cost of
leveraging leaked side-channel information about data-dependent
part of a computation.
Memory Hardness. Several distinct hardness notions based on
memory have been considered in the literature. An early exam-
ple is (sequential) space complexity (e.g., considered in [37]) which
lowerbounds the minimum amount of memory required to eval-
uate a given function on a (sequential) computational device. In
the context of cryptography memory-bound functions were first
considered in [3, 27]. There, the complexity of a function is taken to
be the minimum expected number of cache misses in a computation
of the function.
More recently, memory-hard functions (MHFs) were introduced
by Percival [38] in the form of the scrypt algorithm. Intuitively
MHFs define the complexity of a function to be the minimum prod-
uct of the space and time required to compute the function (amor-
tized across a large number of concurrent evaluation). 1 MHFs
have since found growing favor in the security and cryptographic
community. They have been proposed (and are being increasingly
used) for password hashing for use in storing credentials in a login
server and as key derivation functions in password based cryptogra-
phy. (For example in the recent Password Hashing Competition [2]
almost all of the entrants, including all finalists and the winner,
claimed some form of memory-hardness.) Memory Hard Puzzles
are also being increasingly used as the basis for Proof-of-Work
protocols underlying cryptocurrencies such as Litecoin [24], Doge-
coin [14], ZCash [47] and Ethereum [45].
iMHFs and Graphs. In a bit more detail, this class of iMHFs can be
characterized as iMHFs consisting of some static mode of operation
over (a fixed input-length) compression function. Both in theory
and in practice essentially all iMHFs are designed (or can be viewed)
as such. Whats more, the particular mode of operation can in turn
1For a brief discussion on the difference between memory-bound and memory-hard
see Appendix A.
be viewed as directed acyclic graph (DAG) which describes how the
inputs and outputs of various calls to an underlying compression
function are related to each other. First used in [28] this method of
describing a function in terms of a DAG and compression function
has witnessed various incarnations both explicit [7, 11, 29, 30, 32, 35]
and implicit [4, 16, 21, 23, 26, 39, 46] to name just a few.
Put simply, the iMHF fG given by DAG G and round function h
is computed by labeling the nodes of G. The input(s) to fG are the
labels of the source nodes of G.2 The labels of internal node v is
computed by applying a fixed round function h to the labels of the
parents of v.3 The output of fG is the label of the sink(s) of G.4 If
G has n nodes then for any given input x, by computing the labels
one at a time in topological order, algorithm N can evaluate the
graph function fG(x) in time n using space n times the label size. In
practice h is chosen to be some cryptographic hash function. Thus
the memory-hardness of the graph functions is usually analyzed
in the random oracle (RO) model where h is modeled as an ideal
compression function (i.e. fixed input length RO).
Besides clarity gained by such a modular design, the real power
of describing fG in terms of G can be seen in [11, 12] where a lower-
bound on the memory-hardness of fG (in the parallel random oracle
model) is given in terms of the “amortized area-time” pebbling com-
plexity (aAT) of G or aAT(G) for short. This is a complexity notion
for a DAG given by measuring cost of an optimal strategy for a
game played involving placing pebbles on the nodes of G according
to two very simple rules.5 Intuitively, while any DAG on n nodes
gives rise to an iMHF which takes the same amount of resources for
the honest party using algorithm N, the memory-hardness of fG
grows as does aAT(G). This motivates the search for simple DAGs
with maximal aAT over all graphs of equal size.
Depth-Robust Graphs. Recently it has been shown that for a DAG
G to have high aAT it is both necessary [7] and sufficient [5] for G
to be very depth-robust.
An (e, d)-depth-robust directed acyclic graph (DAG) has the prop-
erty that after removing any subset of up to e nodes (and adjacent
edges) there remains a directed path of length d. By very depth-
robust we essentially mean that the product of e and d should
be large. The problem of constructing DAGs with extreme depth-
robustness was first investigated by Erdös, Graham and Szemerédi
in[31]. There, a graph on n nodes with indegree O (log(n)) is con-
structed6 such that for certain positive constants c1 and c2 removing
any c1n nodes leaves a path of length c2n. More recently Mahmoody,
Moran and Vadhan [35] adapted the construction of [31] such that
for every ϵ > 0 and n ≥ nϵ large enough [35] constructs a graph
Gn on n nodes with indegree ˜Ω(log2) such that for any α ∈ (0, 1)
the graph is (αn,(α − ϵ)n)-depth-robust.7
2A node is called a source if it has no incoming edges.
3A parent of v is a node u such that G contains the edge (u, v).
4A sink is a node with no out going edge.
5In some other works aAT(G) is lowerbounded by the closely related notion of “cu-
mulative pebbling complexity” of the graph [7, 11].
6The indegree of a graph is the largest number of incoming edges for any node in the
graph.
7To be precise, except for [31], the remaining works on depth-robustness from the
70s and 80s actually considered a vairant with edge removal instead of node removal.
However, for constant indegree graphs, as used in this work, the two notions are
effectively the same.
Session E1:  Hardening CryptoCCS’17, October 30-November 3, 2017, Dallas, TX, USA1002Originally, depth-robust graphs found theoretical applications
in proving lowerbounds on circuit complexity and Turing ma-
chine time [36, 42–44] and, quite recently, to prove lowerbounds in
the domain of proof complexity [1]. However, more recently [35]
used depth-robust graph to construct several Proofs of Sequential
Work; protocols allowing a prover to convince a computationally-
bounded verifier that a certain amount of sequential work was
done (despite the prover being capable of arbitrary parallel com-
putation). Yet more recently, strong connections have emerged
between depth-robust graphs and study of secure memory-hard
functions (MHF). [5, 7] In particular, [7] showed that if G is (e, d)-
depth-robust then aAT(G) > ed. The more depth-robust G the more
memory hard fG becomes.
New Requirements and Constraints for Practice. In contrast to
more theoretical applications of depth-robust graphs, both those
in [35] and those in the study of memory-hard functions impose new
requirements on the constructions of depth-robust (and high aAT)
graphs. This is because both types of applications require honest
parties to label a fixed concrete depth-robust graph G (though
with different round functions and to different ends). Moreover
the security and efficiency of the resulting constructions is tightly
related to the indegree of G and to the maximal e and d for which G
is (e, d)-depth-robust (or to the aAT G). In particular, the analogue of
a security parameter in more conventional cryptographic schemes
is the number of nodes of G. Thus, applications ask for a sequence
of graphs of increasing size n such that their respective depth-
robustness (or aAT) properties grow in n. Together these properties
of the applications impose the following new desiderata for depth-
robust graphs:
Low In-Degree: For the MHF applications the round func-
tion h is modeled as a (random) oracle. In particular this
imposes the restriction that evaluating h requires having
all inputs in memory simultaneously. In practice though h
is implemented by a cryptographic hash function which
are iterative functions (e.g. using the Merkle-Damgård con-
struction). This means that when the input x to h is long
then there is really no need to store all of x at once. Given
the importance of memory consumption to the security
definition it is important to minimize this discrepancy be-
tween the RO model and real world computation. Thus,
as the length of the (longest) input to h is dictated by the
indegree of G, to build a memory-hard function we would
like that the indegree of G be as small as possible (usually
2).
For the case of Proofs-of-Sequential-Work, the efficiency
of each protocol in [35] degrades significantly in the in-
degree of G. Therefore, in this case too we would like to
minimize the indegree.
Extreme Depth-Robustness & aAT: The security of cryp-
tographic applications discussed above is tightly tied to the
depth-robustness and aAT of the underlying DAG. Thus,
a good start is to use a family of graphs with asymptot-
ically maximal values in n for these measures. However,
while asymptotics provide some evidence for soundness
of a construction, in any given practical instance, it is the
exact security for the concrete parameters being used that
ultimately matters.
Therefore, going beyond asymptotic optimality we pro-
pose two further desiderata. First, the hidden constants
in the asymptotics should be made explicit and upper
bounded as far as possible. Second, we would like em-
pirical evidence supporting the claim that the graph has
high depth-robustness and/or large aAT. This can take the
form of evaluating the success of state-of-the-art depth-
reduction algorithms and of efficient pebbling strategies
that aim to minimize the pebbling cost of the graph. (The
latter algorithms can, in particular, give rise to evaluation
strategies for evaluating the iMHF fG on a parallel devices
with low amortized space/time per instance. [5, 7])
Simple & Locally Navigable: In all cryptographic applica-