SWaT testbed for the purpose of data collection [12]. These
attacks cover a variety of attack points, and were designed
to comprehensively evaluate the robustness of SWaT under
different network attacks. Of the 36 attacks, we implemented
the 15 that could be supported by the ODEs of (and thus had
an effect on) the SWaT simulator. The attacks are all achieved
by (simulating) the manipulation of the communication taking
EFFECT OF INCREASING THE TIME INTERVAL ON ACCURACY OF SVN-RBF FUNCTION
TABLE III
#time interval
100
150
200
250
300
accuracy
90.98%
90.04%
90.12%
91.05%
90.05%
cross-validation accuracy
88.68%
90.01%
90.08%
90.99%
90.99%
EFFECT OF INCREASING THE NUMBER OF MUTANTS ON ACCURACY OF SVN-RBF FUNCTION
TABLE IV
#mutants
#effective mutants
300
400
500
600
700
23
31
62
76
91
accuracy
63.01%
83.01%
90.07%
91.04%
91.05%
cross-validation accuracy
81.91%
89.01%
89.08%
90.89%
90.99%
RESULTS: DETECTING NETWORK ATTACKS INVOLVING MOTORISED VALVES (MV), PUMPS (P), AND LEVEL INDICATOR TRANSMITTERS (LIT)
TABLE V
attack #
attack point
start state
MV101 is closed
P101 is on whereas P102 is off
Water level between L and H
Water level between L and H
MV504 is closed
MV304 is open
attack
Open MV101
Turn on P102
Increase by 1mm every second
Water level increased above HH
Open MV504
Close MV304
detected
yes
yes
eventually
yes
yes
yes
Water level between L and H
Decrease water level by 1mm each second
eventually
MV101
P102
LIT101
LIT301
MV504
MV304
LIT301
MV304
LIT401
LIT301
LIT101
P101
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
MV304 is open
Water level between L and H
Water level between L and H
Water level between L and H
P101 is on
Close MV304
Set LIT401 to less than L
Set LIT301 to above HH
Set LIT101 to above H
Turn P101 off
P101; P102
P101 is on; P102 is off
Turn P101 off; keep P102 off
P302
LIT101
P302 is on
Close P302
Water level between L and H
Set LIT101 to less than LL
accuracy
89.67%
90.01%
63.11%
99.86%
92.11%
88.01%
56.97%
90.16%
89.36%
99.07%
91.12%
92.06%
91.62%
90.91%
89.37%
yes
yes
yes
yes
yes
yes
yes
yes
place over the network, i.e. hijacking data packets and chang-
ing sensor readings before they reach the PLC, and actuator
signals before they reach the valves and pumps. The attacks
cover a variety of attack points in the SWaT simulator: these
are documented online [10], but intuitively represent motorised
valves (MV), pumps (P), and level
indicator transmitters
(LIT). The table indicates whether or not the invariant was
able to detect each attack, and the accuracy with which it
labels the feature vectors (here, this reﬂects the percentage of
feature vectors labelled as negative after the attack has been
launched). If the accuracy is high (above a threshold of 85%),
we deem the attack to have been detected. Note that for attacks
manipulating the sensor readings (LITs) read by PLCs, we
assume that the correct levels are logged by the historian.
As can be seen, all of the attacks were successfully detected.
For all the attacks except #3 and #7, this is with very high
accuracy (around 90% and above). This is likely because these
attacks all trigger an immediate state change in an actuator
(opening/closing a valve; switching on/off a pump), either
by directly manipulating a control signal to it, or indirectly,
by reporting an incorrect tank level and causing the PLC to
send an inappropriate signal instead (e.g. attack #4 causes the
PLC to switch on a pump to drain the tank, even though the
water level is not actually high). Attacks #3 and #7 are not
detected initially, hence the lower accuracy (approx. 60%),
because the sensor for the tank level is manipulated slowly,
by 1mm per second. As a result, it takes more time to reach
the threshold when the PLC opens a valve or switches on
a pump, at which point the attack has a physical effect. If
measuring from this moment onwards, Attack #3 would have
an accuracy of 99.83% and #7 an accuracy of 99.72%—hence
our judgements of detected eventually.
Overall, the results suggest that our invariant is successful at
detecting network attacks when they lead to unusual physical
behaviour, and thus might be useful in monitoring a sys-
tem in combination with complementary defence mechanisms
(e.g. for ensuring the integrity of the communication links).
Code modiﬁcation attacks. Table VI presents the results of
some code modiﬁcation attacks, and our invariant’s ability to
detect them. Unlike for network attacks, there is no benchmark
of code modiﬁcation attacks to use for SWaT. In lieu of
this, we randomly generated 40 effective mutants (distinct
from those in our learning phase), each consisting of a
single mutation to a PLC program controlling some stage of
the SWaT simulator. We generated data from these mutants
with respect to our 20 initial conﬁgurations, collected feature
vectors, and applied our invariant. The table reports how
many of the mutants were detected and with what accuracy
(we determine whether a feature vector should be positive
or negative analogously to how we labelled feature vectors
derived from mutant traces). After grouping the attacks with
respect to the PLC program they affect, we report both the
average accuracy for all attacks as well as for only those that
were detected.
Our invariant was able to detect 32 of the 40 mutants. Upon
manual investigation, we believe the reason it was unable
to detect the remaining mutants was because they generated
data traces that were too similar to the normal behaviour
of the system. Similar to our network attacks, when a code
modiﬁcation attack led to an unexpected change in the states of
valves and pumps, the attack was detected. The results suggest
that the invariant could be effective for physically attesting the
PLCs, i.e. by monitoring the physical state of the system for
any unexpected behaviours that could be caused by modiﬁed
control code. Of course, an intelligent attacker may manipulate
the code in a way that is not sufﬁciently captured by random
modiﬁcations: seeking a more realistic attestation benchmark
set is thus an important item of future work.
F. Threats to Validity
Finally, we remark on some threats to the validity of our
evaluation:
(1) Our dataset is limited to a single system: the SWaT
simulator;
initial conﬁgurations;
(2) Data traces were generated with respect to a ﬁxed set of
(3) We used randomly generated code modiﬁcation attacks,
rather than code modiﬁcations injected by an intelligent
attacker.
modiﬁcation attacks designed by attackers with knowledge of
the system.
V. RELATED WORK
Anomaly detection has been widely applied to CPS in
order to detect unusual behaviours (e.g. possible attacks)
from their data [25–33]. Many of these approaches, however,
require prior knowledge about the internals of the system—
our technique avoids this and attempts to construct a model
systematically and automatically.
The idea of detecting attacks by monitoring physical invari-
ants has been applied to a number of CPS [34, 35]. Typically,
however, the invariants are manually derived using the laws
of physics and domain-speciﬁc knowledge. Moreover, they are
derived for speciﬁc, expected physical relationships, and may
not capture other important patterns hiding in the sensor data.
Manual invariants have also been derived for stages of the
SWaT testbed itself [36, 37].
Apart
invariants,
from monitoring physical
the SWaT
testbed has also been used to evaluate other attack detection
mechanisms, such as a hierarchical intrusion detection system
for monitoring network trafﬁc [38], and anomaly detection
approaches based on unsupervised machine learning [5, 6].
The latter approaches were trained and evaluated using an
attack log [12] from the testbed itself. As our approach was
evaluated on the SWaT simulator, an immediate and direct
comparison with our results is not possible. However, we
believe that our supervised approach would lead to higher
sensitivity, and plan to do a proper comparison to conﬁrm
or refute this.
Mutations are applied by Brandl et al. [39], but to speciﬁ-
cations of hybrid systems (rather than to the PLC programs
themselves) in order to derive distinguishing model-based test
cases that can be seen as classiﬁers. A discrete view of
the system is used for generating test cases, with qualitative
reasoning applied to represent the continuous part.
It is possible to obtain strong guarantees about the behaviour
of a CPS by applying formal veriﬁcation, but only with
accurate enough models of the controllers and ODEs. With
these, the CPS can be modelled as a hybrid system and a
variety of established techniques can be applied (e.g. model
checking [40], SMT solving [41], non-standard analysis [42],
concolic testing [43], runtime model validation [44], or theo-
rem proving [45, 46]). With discretised models of the phys-
ical part, classical modelling and veriﬁcation techniques can
also be applied, e.g. as demonstrated for some properties of
SWaT [47, 48].
VI. CONCLUSION
Due to (1), it is possible that our results do no generalise to
other CPSs. Because of (2), it is possible that normal but rarely
occurring behaviours may have been missed in the training
phase, and thus may be classiﬁed incorrectly by our invariant.
These behaviours may also have been missed from the data
traces used in the validation phase (SMC). Because of (3), it
could be possible that our results do not apply to real code
We proposed a novel approach for automatically construct-
ing invariants of CPS, in which supervised ML is applied to
traces of data obtained from PLC programs that have been
systematically mutated. We implemented it for a simulator of
the SWaT raw water puriﬁcation plant, presenting a framework
that can generate large quantities of mutant PLC programs,
data traces, and feature vectors. We used SVM-RBF to learn
RESULTS: DETECTING CODE MODIFICATION ATTACKS
TABLE VI
attack stage
# effective mutants
# detected
accuracy (detected)
accuracy (all)
PLC 1
PLC 3