A VDS is operated by a user using voice commands. The voice
command is processed by the service and a response is returned
either verbally to the user (e.g., announcing the time) or by per-
forming a specific action (e.g., turning lights on/off). Devices that
use VDS are triggered by a user using a pre-specified phrase (e.g.,
Alexa, Hey Siri), and operate in a turn-taking mode. The device
actively listens to the user once triggered and the user listens to
the device when it responds. AEOLUS embeds the acoustic nonce
once the device is triggered and is actively listening to the user.
A typical VDS has four different sub-components, (i) an in-
put/output voice channel to listen to a user’s command and send ver-
bal responses, (ii) a text/speech processing engine to convert speech-
to-text and text-to-speech, (iii) a speaker verification/identification
module to only permit authorized users to execute privileged com-
mands, and (iv) a text/intent processing engine to execute com-
mands. AEOLUS aims to prevent speech re-use of an authentic VDS
user.
2.2 Example Use Cases
Voice-driven Payments. Voice-driven services are being increas-
ingly used for payments, especially in retail environments [14].
Amazon and Exxon recently announced voice-driven payments at
over 11,500 gas stations in the US [2]. A recent user study [11] indi-
cates that while most users are comfortable conducting low-value
purchases such as ordering a meal and shopping for groceries using
voice-driven payment services, the majority of them do not have
sufficient confidence in conducting high value purchases due to
security concerns.
Most voice-driven payment services authenticate users through
speaker verification. However, they often lack adequate protec-
tion mechanisms against speech re-use attacks where an attacker
records a user interaction and re-uses it to attack the service ei-
ther on-site or remotely. This is analogous to card skimming [48]
where an attacker re-uses a victim’s credit card information. AEOLUS
can be deployed to prevent speech re-use attacks in voice-driven
payments.
Workplace Automation. A variety of digital assistants are being
used for unsupervised or semi-supervised interactions in work-
place environments [1]. In addition to accurate speaker recognition
(identification and/or verification), it is important to have adequate
protection mechanisms against speech re-use to protect sensitive
resources in such environments [15]. AEOLUS can be incorporated
in workplace digital assistants for this purpose.
2.3 Related Work
Speech Replay Detection Existing research related to speech re-
play detection can be classified into two categories, software-based
and hardware-based methods. Software-based methods use ma-
chine learning to determine whether the input speech is produced
by a human or replayed using a recording device [26] [22] [38].
284RAID ’21, October 6–8, 2021, San Sebastian, Spain
Yangyong Zhang, Sunpreet S. Arora, Maliheh Shirvanian, Jianwei Huang, and Guofei Gu
Figure 3: Use of the proposed security overlay to prevent speech re-use in voice-driven services. At the time of user interaction, an acoustic
nonce is generated and embedded in over-the-air channel, and its presence is detected in the recorded speech to ensure speech freshness.
commands and confidential passphrases. For example, to prevent re-
use of a user’s voice password to access recent account transactions
when the user is interacting with a voice banking VDS [18].
The following assumptions are made while designing AEOLUS to
address the speech re-use attack scenario.
• Adversary Capability. We aim to address speech re-use
in the context of VDS protected with AEOLUS. An adversary
uses a commodity recording device to record prior user inter-
actions with a AEOLUS-enabled VDS, and re-use the recorded
interaction to attack a AEOLUS-enabled VDS. Hence, attack
scenarios where an adversary can record or access clean user
speech samples (i.e., recordings without embedded acoustic
nonce) from a different context to launch replay or speech
synthesis attacks are not considered. The key underlying
assumptions are that (i) users typically interact with VDS us-
ing specific commands (e.g., a user-defined passphrase [20])
and these commands can be protected with AEOLUS, and (ii)
it is difficult to record clean samples of these commands from
interactions with different VDS without AEOLUS protection
or in human conversations. Also, it is assumed that AEOLUS
can be used in conjunction with other defense mechanisms
for replay or speech synthesis attacks.
• Hardware Assumptions. We study the problem of speech
re-use prevention wherein speech is presented over-the-air.
It is assumed that the hardware device (loudspeaker and
microphone) used by a user to interact with VDS is trusted,
secure and functioning, and an adversary cannot disable
the speaker or the microphone. Furthermore, we assume
that the channel between hardware and other VDS mod-
ules is secure/protected. Similar hardware assumptions are
made by other software-based security mechanisms such as
CAPTCHA. The proposed framework does not address hard-
ware integrity which can be addressed using other security
mechanisms, e.g., hardware attestations.
• Protection Scope. An adversary who has access to the prox-
imity of an AEOLUS-enabled device may inject audible or in-
audible voice commands [21, 61] during users’ interaction
with the devices. This type of attack may happen before
or during the period when users speak voice commands.
AEOLUS does not provide protection again such malicious
voice command injection because the goal of AEOLUS is to
prevent speech re-use rather than providing the integrity of
the current speech.
3.2 Core Components
To prevent speech re-use in VDS, AEOLUS uses three core compo-
nents, nonce generation, nonce embedding and nonce detection.
Nonce Generation. The nonce generation module is invoked upon
initiation of a new user interaction session (see Figure 4 1○). Akin
to nonce-based authentication [24, 55], the module generates a
digital nonce (a random number of a length L) that is valid for
the current session. Nonce length L should be sufficiently large to
prevent use of duplicate nonces in different sessions. Given limited
bandwidth of over-the-air channel and estimated user base for
popular VDS (e.g., Alexa skill has 300,000 daily users [16]), the
minimum permitted value of L is set to 32 bits. 32-bit long nonce is
sufficient to protect short speech samples (e.g., a voice passphrase)
in a particular session. Nonce repetition is permitted to protect
longer speech samples during the session. The nonce δ for session
S is stored in a set Sset . Sset is subsequently used by the nonce
detection module to determine if the embedded nonce is current.
Nonce Embedding. Post nonce generation, an encoding algorithm,
Binary Frequency Shift Keying (BFSK) [45, 54], is used to encode
the generated digital nonce as an acoustic nonce. Each bit is in-
dependently encoded as a cosine wave ωi. Bit “0” is encoded as a
1kHz cosine wave, and bit “1” as a 5 kHz cosine wave. All cosine
waves in the set ω are concatenated to yield the acoustic nonce δ.
The acoustic nonce δ is embedded in over-the-air channel using
UserVDSMix(nonce, speech)Response Acoustic NonceDetectionSession Start Nonce BeginAcoustic NonceGenerationNonce EndAcoustic NonceEmbeddingSession End ⋮“confirm my payment.”Wake-upWord  Protected voice command⋮VDSProcessAlexa, 285Practical Speech Re-use Prevention in Voice-driven Services
RAID ’21, October 6–8, 2021, San Sebastian, Spain
we discuss the root causes of these challenges. Lastly, we present
an optimization scheme to tackle the challenges.
4.1 Challenges
Reliability. The first challenge is to reliably embed an acoustic
nonce in over-the-air channel, as well as to accurately detect nonce
from the recorded speech. Because over-the-air acoustic nonce
transmission is impacted by factors such as background noise and
distance between microphone and playback device, it is difficult to
achieve this in operational settings. It is also important to deter-
mine if any previously embedded acoustic nonce is present in the
recorded speech to ascertain speech re-use. The metric used to mea-
sure reliability is the bit error rate (BER) between the embedded and
detected nonce. Recall that BFSK is used for acoustic nonce embed-
ding and detection. Under the assumption that only additive white
Gaussian noise (AWGN) is present in over-the-air channel, BER can
be computed using the complimentary error function er f c() [40]
as follows:
2er f c((cid:112)
BER = 1
Eb/N0)
(1)
Note that BER computation in Eqn. 1 involves the normalized per bit
signal-to-noise ratio Eb/N0 [36] which depends on the frequency f
and amplitude α of the carrier wave. However, other types of noises
besides AWGN are typically present in over-the-air channel. Hence,
we conduct Room Impulse Response (RIR) simulation experiments
to study the impact of carrier wave amplitude and frequency on
BER.
Imperceptibility. The second challenge is to ensure that the em-
bedded acoustic nonce does not degrade VDS user experience. For
this, the acoustic nonce should be as imperceptible as possible to a
VDS user. The nonce embedding and generation modules presented
earlier do not adequately address this challenge because (i) they
do not optimize any objective metric for imperceptibility, and (ii)
they do not account for dynamic and noisy environments where
it is difficult to achieve both reliability and imperceptibility simul-
taneously. For measuring imperceptibility, Sound Pressure Level
(SPL) is computed using the following equation:
SPL = 2π 2 f 2α2ρc/v
(2)
Here, f represents the frequency and α is the amplitude of the
carrier wave. ρ represents the density of the transmission channel
(e.g., over-the-air channel), and c denotes the speed of acoustic
transmission. Given that the average SPL for human speech is
60dBm [12], f and α should ideally ensure that SPL is below this
threshold for imperceptibility. Like Equation 1, while this equation
provides a theoretical basis to understand SPL, we study how the
aforementioned parameters impact SPL using RIR simulation.
4.2 Key Parameters
There are two key parameters that impact reliability and impercep-
tibility: (i) acoustic nonce generation and embedding parameters
that include frequency and amplitude of the carrier wave used for
acoustic nonce generation and bitrate used for acoustic nonce en-
coding, and (ii) environmental parameters that include the distance
between the microphone and user, the room size, and background
Figure 4: AEOLUS-enabled VDS components with the associated data
flows. Shown in blue and grey are the components used to prevent
speech re-use.
VDS playback device ( Figure 4 2○). An important parameter for
nonce embedding is the time duration of the embedded acoustic
nonce relative to the time duration of user interaction. Using a
real-world dataset with 27,000 samples [35], we estimate that the
average user interaction is 3 sec. As an example, let the minimum
duration of embedded nonce be half of the average user interaction.
In this case, the acoustic nonce embedding would require a bitrate
of 14 bits/sec, and the maximum duration of each component cosine
wave wi can be 42 ms. Note that this estimate does not consider the
idle time in user interaction. Additionally, to prevent an adversary
from obtaining clean speech sample by removing the embedded
nonce, the nonce embedding module leverages Frequency-hopping
Spread Spectrum (FHSS) [29, 30]. FHSS is a well-known technique
that provides high robustness against standard embedded signal
removal attacks. For high robustness, the module uses FHSS with a
set of different frequencies and periodically selects the operating
frequency at random.
Nonce Detection. Once user interaction ends, the recorded audio
is processed using the nonce detection module (Figure 4 3○). The
module decodes the acoustic nonce using BFSK, and checks that
(i) the nonce is completely decoded, and (ii) the decoded nonce
is current. The recorded speech is subsequently processed using
standard VDS modules (Figure 4 4○). If nonce detection fails or if
the decoded nonce has a high Bit Error Rate (BER), a recourse action
(e.g. a retry or reject) can be taken. Furthermore, if speech is re-
used by an adversary and both the current nonce and the obsolete
nonce from re-used speech are detected, information about re-used
speech such as when and where it was recorded can be determined
from Sset . Another scenario can be signal interference between
the current and obsolete nonce resulting in inappropriate decoding
result. In such case, pertinent recourse action can be taken.
4 PRACTICAL REALIZATION
In this section, we first illustrate two key challenges while imple-
menting AEOLUS in practice: reliability and imperceptibility. Then,
NonceEmbeddingNonce GenerationPlayback DeviceMicrophone/TriggersBackend ProcessingNonce DetectionInitializationOptimization①②③④⑥AEOLUSVDS⑤Speech & SpeakerRecognition286RAID ’21, October 6–8, 2021, San Sebastian, Spain
Yangyong Zhang, Sunpreet S. Arora, Maliheh Shirvanian, Jianwei Huang, and Guofei Gu
(a) Frequency range = 4-5kHz, hopping = 2, bi-
trate = 30 bits/sec
(b) Frequency range = 4-5kHz, hopping = 2,
amplitude = 1
(c) Frequency range = 4-5kHz, hopping = 2, bi-
trate = 30 bits/sec, amplitude = 1
Figure 5: Variation of bit error rate (%) with: (a) amplitude of carrier wave, (b) bitrate used for encoding acoustic nonce, (c) background noise
levels when embedding the acoustic nonce. Eb/N0 is calculated in decibels. The distance between user (simulated using a loudspeaker) and
the microphone is set to 1 m.
noise among others. To understand the impact of the these param-
eters on reliability and imperceptibility, we implement AEOLUS as
a prototype and setup an RIR environment called MCRoomSim
in MATLAB [56]. RIR is a commonly used tool for estimating the
performance of signal processing applications in over-the-air chan-
nel [21, 27].
4.2.1 Nonce Generation and Embedding Parameters.
Amplitude. According to RIR simulation, a lower amplitude yields
lower Eb/N0 ratio and consequently, higher BER (see Figure 5a).
This is consistent with Equation 1. Furthermore, as shown in Fig-
ure 6, SPL is proportional to the amplitude of the carrier wave.
Frequency. BER and SPL are evaluated in the frequency range at
which typical speaker recognition systems operate (5 Hz - 8 kHz;
sampling rate = 500 Hz). The other parameters are fixed as follows:
Eb/N0 = 1, frequency hopping = 2, amplitude (normalized) = 1,
bitrate = 30 bits/sec, distance = 1 meter. It is observed that the
carrier wave frequency neither impacts BER nor SPL. The later is in
contrast to existing research [4, 52] which shows that the frequency
of an acoustic wave affects the loudness as perceived by humans in
a non-linear manner. Hence, the frequency to SPL mapping from
IoSR toolkit [6] is used as reference.
Bitrate. Figure 5b shows the impact of acoustic nonce bitrate on
BER. BER increases significantly as bitrate increases beyond 20
bits/sec. One of the causes is asynchronous signal overlapping in
the time domain when two bits are transmitted too close to each
other.
4.2.2 Environmental Parameters.
Frequency Shifting. Over-the-air acoustic nonce transmission in-
duces differences in the received frequencies and the transmitted
frequencies called frequency shifting. Frequency shifting can also
occur because of hardware limitations, e.g., a microphone with
a 1.8 kHz frequency limit being used to capture a 2 kHz wave.
Since the received frequency is used to decode the acoustic nonce,
frequency shifting needs to be accounted for by AEOLUS. We in-
vestigate frequency shifting in the simulation setting (operating
frequency range: 500 Hz-8 kHz, cardioid loudspeaker type, dipole
(a) Eb/N0 = 1, carrier frequency range = 4-5kHz,
hopping = 2, bitrate = 30 bits/sec, distance = 1 me-
ter
(b) Eb/N0 = 1, carrier frequency range = 4-5kHz,
hopping = 2, bitrate = 30 bits/sec, Amplitude (nor-
malized) = 1