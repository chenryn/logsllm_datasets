title:"If HTTPS Were Secure, I Wouldn't Need 2FA" - End User and Administrator
Mental Models of HTTPS
author:Katharina Krombholz and
Karoline Busse and
Katharina Pfeffer and
Matthew Smith and
Emanuel von Zezschwitz
(cid:19)(cid:17)(cid:18)(cid:26)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:1)(cid:52)(cid:90)(cid:78)(cid:81)(cid:80)(cid:84)(cid:74)(cid:86)(cid:78)(cid:1)(cid:80)(cid:79)(cid:1)(cid:52)(cid:70)(cid:68)(cid:86)(cid:83)(cid:74)(cid:85)(cid:90)(cid:1)(cid:66)(cid:79)(cid:69)(cid:1)(cid:49)(cid:83)(cid:74)(cid:87)(cid:66)(cid:68)(cid:90)
“If HTTPS Were Secure, I Wouldn’t Need 2FA”-
End User and Administrator Mental Models of
HTTPS
Katharina Krombholz
CISPA Helmholtz Center
for Information Security
Karoline Busse
Bonn University
Katharina Pfeffer
SBA Research
Matthew Smith
Bonn University
FhG FKIE
Emanuel von Zezschwitz
Bonn University
FhG FKIE
Abstract—HTTPS is one of the most important protocols used
to secure communication and is, fortunately, becoming more
pervasive. However, especially the long tail of websites is still not
sufﬁciently secured. HTTPS involves different types of users, e.g.,
end users who are forced to make security decisions when faced
with warnings or administrators who are required to deal with
cryptographic fundamentals and complex decisions concerning
compatibility.
In this work, we present the ﬁrst qualitative study of both
end user and administrator mental models of HTTPS. We inter-
viewed 18 end users and 12 administrators; our ﬁndings reveal
misconceptions about security beneﬁts and threat models from
both groups. We identify protocol components that interfere with
secure conﬁgurations and usage behavior and reveal differences
between administrator and end user mental models.
Our results suggest that end user mental models are more
conceptual while administrator models are more protocol-based.
We also found that end users often confuse encryption with
authentication, signiﬁcantly underestimate the security beneﬁts
of HTTPS. They also ignore and distrust security indicators
while administrators often do not understand the interplay of
functional protocol components. Based on the different mental
models, we discuss implications and provide actionable recom-
mendations for future designs of user interfaces and protocols.
I. INTRODUCTION
In the context of information technologies, protecting com-
munication content at large scale has become more important
than ever before. Almost
twenty years after Whitten and
Tygar’s usability evaluation of PGP [1], reliable encryption
still cannot be taken for granted even though adoption rates
are growing [2]. In today’s Internet ecosystem, HTTPS is
the fundamental cryptographic protocol to secure information
in transit and to ensure data integrity and privacy between
two communicating parties. However, HTTPS is still not the
default for all websites, especially when it comes to the long
tail of websites [2], [3]. At the time of writing, Internet-wide
scans from SSLPulse suggest that 36,3% of sites surveyed still
have inadequate security1. Recent studies, e.g., by Krombholz
et al. [4], show that this is, among other reasons, due to
the fact that the deployment of cryptographic protocols is a
difﬁcult task even for knowledgeable users. Similar to message
1https://www.ssllabs.com/ssl-pulse/, Accessed: 10/30/2018
encryption, HTTPS confronts different types of (mostly techni-
cally adept) users with cryptographic algorithms and protocols
which they do not fully understand – see, e.g., Krombholz
et al. [4], Green and Smith [5], Acer et al.[3], Fahl et al.
[6], Oltrogge et al. [7], and Reeder et al. [8]. In addition,
users who are exposed to poorly conﬁgured sites are forced
to make security-critical decisions and are often not aware of
the respective consequences.
We argue that we still do not understand why these carefully
designed protocols do not meet the needs of (knowledgeable)
users to securely operate cryptographic applications. There-
fore, this work employs an inductive approach to learn about
the root causes for user misconceptions by formalizing mental
models of end users and administrators. In particular, we focus
on how users think that HTTPS works and against which types
of attackers they think they are protected. By doing so, we
get a detailed understanding of which knowledge gaps have
to be ﬁlled in future protocol designs. We thereby contribute
a qualitative study with 18 end users and 12 experienced
administrators; our ﬁndings reveal interesting differences in
the mental models of these two distinct user groups.
We found that many non-expert participants signiﬁcantly
underestimate the level of protection that HTTPS offers,
whereas administrators generally have a good understanding of
what HTTPS can or cannot protect against. We also discovered
that most administrators have little conceptual knowledge of
how the protocol works but are very familiar with the different
steps of establishing a communication. Key elements are
often considered as blackboxes and poorly understood. We
further found that the distinction between authentication and
encryption is unclear to many users–even to some experts.
Based on our ﬁndings, we identiﬁed protocol components that
diverge from user mental models and discuss implications and
potential countermeasures.
The goal of this paper is to derive and compare mental
models in order to understand if and how they deviate from
the underlying functionality of HTTPS and their impact on
security. The main contributions of this paper are as follows:
We conducted an in-depth qualitative study with n = 30
participants to formalize user mental models and threat
models and to understand users’ perceptions, attitudes
and misconceptions of how HTTPS works. By focusing on
(cid:165)(cid:1)(cid:19)(cid:17)(cid:18)(cid:26)(cid:13)(cid:1)(cid:44)(cid:66)(cid:85)(cid:73)(cid:66)(cid:83)(cid:74)(cid:79)(cid:66)(cid:1)(cid:44)(cid:83)(cid:80)(cid:78)(cid:67)(cid:73)(cid:80)(cid:77)(cid:91)(cid:15)(cid:1)(cid:54)(cid:79)(cid:69)(cid:70)(cid:83)(cid:1)(cid:77)(cid:74)(cid:68)(cid:70)(cid:79)(cid:84)(cid:70)(cid:1)(cid:85)(cid:80)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:15)
(cid:37)(cid:48)(cid:42)(cid:1)(cid:18)(cid:17)(cid:15)(cid:18)(cid:18)(cid:17)(cid:26)(cid:16)(cid:52)(cid:49)(cid:15)(cid:19)(cid:17)(cid:18)(cid:26)(cid:15)(cid:17)(cid:17)(cid:17)(cid:23)(cid:17)
(cid:19)(cid:21)(cid:23)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:45:08 UTC from IEEE Xplore.  Restrictions apply. 
different scenarios and studying two distinct groups of users,
namely end users and system administrators, we were able
to reveal group-speciﬁc differences.
II. RELATED WORK
In
this
section, we
on
HTTPS/SSL/TLS from both the expert and non-expert
user’s perspective, message encryption, and mental model
studies.
related works
examine
A. HTTPS From the Expert Users’ Perspective
Krombholz et al. [4] identiﬁed major challenges in HTTPS
deployment from an administrator’s perspective and showed
that the procedure is too complex. They identiﬁed usability
issues and protocol components that are difﬁcult to understand
even for knowledgeable users who managed to deploy valid
conﬁgurations. The results from Krombholz et al. [4] also
suggest
that administrators rely heavily on online sources
and that the quality of these resources often leads to faulty
implementation. Acar et al. [9] showed that this is also the case
for API documentations, which inﬂuence code performance
and security. Their ﬁndings suggest simplifying interfaces,
providing more support for a broad range of tasks, and giving
code examples to promote effective security in applications.
These API documentations are among the primary sources that
construct mental models.
Fahl et al. [10] studied reasons for webmasters to miscon-
ﬁgure security-critical X.509 certiﬁcates which do not validate
on their website. They found that one third accidentally mis-
conﬁgured those certiﬁcates and two thirds explained why they
deliberately used non-validating certiﬁcates. Oltrogge et al. [7]
studied the applicability of pinning for non-browser software
and implemented a web-application to support the deployment
of pining-protected TLS implementations. Manousis et al.
[11] found that only 50% of the domains with Let’s Encrypt
certiﬁcates actually responded with a valid LE certiﬁcate on
the standard HTTPS port which indicates that even automation
does not obviate the need for administrators to deal with the
complexity of the protocol, resulting in serious misconﬁgura-
tions.
While these works [4], [10], [7] identiﬁed speciﬁc (protocol-
related) tasks that are not sufﬁciently understood by knowl-
edgeable users such as administrators and developers, they did
not show how they are actually understood. Based on their
ﬁndings, we measure user mental models to detect reasons for
inadequately secured conﬁgurations and security misbehavior.
B. HTTPS From the End Users’ Perspective
To ensure a safe usage of the HTTPS infrastructure, SSL
warnings and connection security indicators serve as primary
interaction components for end users. Related work in our
ﬁeld has signiﬁcantly contributed to improving these UI com-
ponents; Sunshine et al. [12] conducted the ﬁrst study on the
effectiveness on browser warnings. Harbach et al. [13] studied
how linguistic properties inﬂuence the perceived difﬁculty
of warning messages. Akhawe et al. [14] focused on the
(in)effectiveness of different security warnings in browsers,
which are strongly correlated to user experiences. Weber et
al. [15] used participatory design to improve security warnings.
Felt et al. [16] studied differences of SSL warnings between
Google Chrome and Mozilla Firefox along with click-through
rates. As a follow-up, Felt et al. [17] introduced new SSL
warnings, which helped 30% of the tested users to stay safe.
Those opinionated design-based warnings were released by
Google Chrome. To provide users with further visual feedback,
they proposed a new set of browser security indicators for
HTTPS security in Google Chrome [18] based on a user study
with 1,329 participants.
Even though adherence rates have improved, they could still
be much higher. Reeder et al. [8] explored reasons for low
adherence rates and misconceptions about browser warnings.
They identiﬁed contextual misunderstandings that inﬂuence
users in clicking through warnings and found that users are
inconsistent in their perceptions and security assessments.
Acer et al. [3] studied over 2,000 Google Chrome browsing
errors and classiﬁed their root causes. They showed that
the majority of errors were caused on the client-side or by
network issues and proposed mitigation for spurious certiﬁcate
warnings. Chothia et al. [19] presented a security analysis of
TLS used in UK banking apps that emphasized the importance
of security by revealing privacy and security ﬂaws.
Our work extends the state of the art by studying how
connection indicators, warnings, and other UI cues contribute
to the formation of valid mental models and perceptions of
how to operate the system in the most secure manner. While
related work has signiﬁcantly improved security indicators
and warnings and thus improved adherence rates, our results
suggest that these UX components do not necessarily establish
trust among end users.
C. Message Encryption
Already in 1999 Whitten and Tygar [1] had found that
user interfaces for security applications need different usability
standards to be effective. This led to a series of other studies,
especially as messaging encryption became popular.
Fahl et al. [20] conducted a screening study on the us-
ability of the message security of Facebook. Based on their
ﬁndings that automatic key management and key recovery
capabilities are important, they implemented a usable, service-
based encryption mechanism. The effect of integration and
transparency on users’ trust was examined by Atwater et
al. [21] and indicated that users have a stronger conﬁdence
in desktop applications and integrated encryption software
than others. Different Instant Messaging applications were
evaluated concerning their usability by Herzberg et al. [22],
Schroder et al. [23], and Vaziripour et al. [24], concluding that
the security mechanisms are impractical due to incorrect men-
tal models, a lack of understanding, and usability problems.
Secure email exchange is desired by many users. However,
as found by Ruoti et al. [25], the time component detains
regular usage since simultaneous users are unsure at which
point in time they use encrypted emails. Lerner et al. [26]
(cid:19)(cid:21)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:45:08 UTC from IEEE Xplore.  Restrictions apply. 
introduced a prototype for encrypting emails with Keybase
for automatic key management and showed that lawyers and
journalists were able to efﬁciently send encrypted e-mails with
few errors. However, the operational constraints differ, and
there is no one-size-ﬁts-all solution.
Abu-Salma et al. [27] studied users’ perceptions of secure
communication tools and reasons for not adopting them,
and revealed misconceptions of encryption concepts in users’
mental models.
D. Mental Models
Users’ mental models inﬂuence their behaviour and reac-
tions in certain situations. Wash et al. [28] proposed a way to
shape the mental models of non-experts to encourage security
behavior irrespective of the users’ technical understanding.
Bravo-Lillo et al. [29] studied how users perceive and respond
to security alerts. Renaud et al. [30] found that incomplete
threat models, misaligned incentives, and a general absence of
understanding of the email architecture lead to non-adoption
of end-to-end encryption for emails. Oates et al. [31] explored
mental models of privacy, and Wu et al. [32] explored end
user mental models of encryption. Abu Salma et al. [33]
quantiﬁed mental models and misconceptions of a hypothetical
encrypted communication tool and found a large percentage
of users underestimate the security beneﬁts of E2E encrypted
tools. Kang et al. [34] measured mental models about the
Internet and its privacy and security challenges. Based on their
ﬁndings, they proposed systems and policies which do not rely
on the knowledge of users. Gallagher et al. [35] conducted a
study with experts and non-experts on their mental models of
the Tor network and found severe gaps in their knowledge
which could lead to deanonymization. Zeng et al. [36] studied
user understanding of smart-home technologies and revealed
mismatches in users threat models compared to reality. Related
works on mental models revealed severe misconceptions with
respect to message encryption or speciﬁc tools. We replicate
and conﬁrm some conceptual misunderstandings on message
encryption and extend the state of the art by investigating
mental models of transport layer security from the end users’
and administrators’ perspective. In comparison to message
encryption, especially, the conﬁguration of the protocol from
an administrators’ perspective is complex and has a severe
impact on the security of the Internet ecosystem.
III. METHODOLOGY
In the following, we describe our research questions and
how we address them, i.e., the study design and procedure of
our semi-structured interviews, recruitment, participants, and
how we ﬁnally analyzed the resulting data. Our goal is to
understand why end users and administrators make mistakes
when using or conﬁguring HTTPS that result in security-
critical situations. Our approach is to construct theories by
means of identiﬁcation of patterns in the data [37] (inductive
approach), which is why we opted for a qualitative interview
study with a diverse sample of participants. In particular, we
sought to answer the following research questions:
• What are people’s expectations and perceptions of en-
cryption and visiting sites via HTTPS?
• How well do users understand the associated threat mod-
els?
• What are the differences between end users’ and admin-
istrators’ mental models of HTTPS?
A. Study Design and Procedure
Kearney et al. [38] showed that humans commonly possess
tacit knowledge about technology, i.e., superﬁcial knowledge,
of which they are not aware and which they cannot easily
articulate. Nevertheless, this tacit knowledge determines peo-
ple’s decisions and responses to new situations. Our study is
designed in a way that it supports participants in exploring
and reporting their tacit knowledge by externalizing it. Based
on related work on HTTPS usability, e.g., [4], [18], [2] and
recent mental model studies from usable security, e.g.,
[34],
[35], [36], [28], [30] we constructed an interview guideline for
semi-structured interviews including a three-part drawing task
and a short questionnaire with closed-ended questions cov-
ering demographics and questions on the participants’ online
communication behavior. The complete study material can be
found in the Appendix, including the screening questionnaire
in Section B and the interview guideline in Section C. Twenty-
seven interviews were conducted in person in three different
cities in Austria and Germany, namely Vienna, Bonn, and
Hannover. The participants were invited to a quiet room at
one of our labs or at a local hackerspace. In addition, three
interviews were conducted via Skype.
All participants were informed about the purpose of the
study and then signed a consent form. Then, depending on
whether a participant was classiﬁed as end user or adminis-
trator, they were presented a questionnaire. After completion
of the questionnaire, the main part of the study–namely the
interview with the drawing tasks–was conducted. In order to
elicit articulations and visualization of user mental models, the
participants were guided through three drawing tasks based
on different scenarios and asked to verbalize their thought
process as they drew, consistent with traditional think aloud
protocols [39]. The scenarios were (1) a general scenario of
sending an encrypted message to a communication partner, (2)
online shopping via HTTPS, and (3) online banking.
All but one interview were recorded after the participants
gave their written consent. In addition to the audio recordings,
the interviewers took notes.
Contrary to quantitative research, where the appropriate
sample size can be determined by power calculations, the
sample size in qualitative research is determined by the point
at which no new themes or ideas emerge from the data. This
metric is also referred to as saturation [40]. We conducted
interviews until we reached saturation. As the sample of end
users was more diverse in terms of demographics, education
and technical experience (assessed in the screening question-
naire), a larger sample was required to reach saturation in
comparison to the administrator sample. We validated our
(cid:19)(cid:21)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:45:08 UTC from IEEE Xplore.  Restrictions apply. 
study design with pilot interviews and a post-hoc validity
study.
B. Expectations on User Mental Models
While our scientiﬁc principles encourage us to evaluate
results from a neutral, non-involved standpoint, researchers
introduce their own individual biases and preconceptions. To
make these personal inﬂuences more transparent, we discussed
a series of expectations on mental models prior to analyzing
the data. We argue that mental models of both types of users
are constructed based on the protocols and UX with which
they interact. We therefore expected these components to be
essential parts of their mental models. Mental models are also
inﬂuenced by media articles, education, experience, and other
factors. As we cannot isolate these factors, we do not build