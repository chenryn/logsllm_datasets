deactivate_super at ffffffff8017f776
kill_block_ super at fffff808677
journal_destroy at fffffffa007a80f
www.TopSage.com
CPU: 2 COMMAND: "umount"
HACK#35 kernel panic 1 203
209
---
## Page 222
210
行为，适当地应用就好。
此外，这也是个灵活运用 WARN_ON(1)和 sysctl 参数的例子。根据情况和操作系统的
bug。编写复现测试程序，还能验证补丁（backport）和自行编写的补丁是否正确。
逐步确认源代码，然后按照 bug 发生的路径在操作系统上执行操作，最终复现了
这次偶然地找到了已改好的补丁，如果要自己修改，理解其中的原理是很重要的。
图5-8改正后的调用顺序
所以必须进行解锁，因此只能这样修改。
简单地考虑，只要不在途中解锁就没问题，但图 5-8的函数调用中包含进程调度，
I_WILL_FREE 标志，就不再释放。IWILL_FREE 标志表示已准备释放，这样两个进程
这个补丁在解锁之前设置了I_WILL_FREE 标志。要释放 inode 时，如果发现
2041第5章实践内核调试
总结
就不会释放同一个 inode 了。
Date: Sat Feb 10 01:44:59 2007 -0800
Author: Jan Blunck 
commit4a3b0a490d49ada8bbf3f426bela0ace4dcd0a55
Date: Thu Jun 23 00:09:01 2005 -0700
Author: Alexander Viro 
commit 991114c6fa6a21d1fa4d544abe78592352860c82
[PATCH] igrab() should check for I_CLEAR
[PATCH] fix for prune_icache()/forced final iput() races
generic_forget_inode()
-write_inode_now( )
www.TopSage.com
wait_on_inode()
→inode_wait()
>schedule()
---
## Page 223
的复现程序成功地复现了。出于说明的目的，错误处理等细节部分就省略了。
问题都能复现，我仍然尽力尝试各种复现步骤，并编写复现程序。这个 bug 用下面
如果问题能在手头的环境中复现，通向问题的解决之路就非常近了。尽管不是所有
编写复现程序
另外，即使在系统负载较低时，复现频率也很高。
select()时还指定了timeout 参数。
端应用程序，由多个子线程通过 select()系统调用接收客户端的请求。此外，运行
接下来问了问这个实时进程都执行了什么处理，原来它是个提供网络服务的服务器
不能保证不满足这些条件，bug一定不会发生，但这些的确是有效的信息。
问题在上述条件全部满足的情况下发生。也许还有其他报告者没注意到的条件，也
下发生了问题。
首先，尽可能收集、整理信息是很重要的。进一步详细地询问后，得知在以下情况
询问问题发生的详细状况
个基于内核版本 2.6.9 的发行版。
发送 core dump 信号，几十秒后操作系统似乎仍然没有响应。出问题的操作系统是
某天接到了一个报告，说操作系统停止响应了。报告说，给实时进程用 kill 命令
#36
#include 
#include 
$ cat segfault.c
#include 
用kill 命令发送 SIGSEGV、SIGABRT 等能引发 core dump 的信号。
多线程。
进程调度策略为SCHED_FIFO。
方法。
本 hack以实际发生的操作系统停止响应的问题为例，介绍内核的调试
内核停止响应（死循环篇）
www.TopSage.com
HACK#36内核停止响应（死循环篇）丨205
211
---
## Page 224
212
复现成功后，稍稍改变一下条件看看能否复现。我的常用做法是在同一环境中只把
用各种条件尝试复现程序
要改变 NUM_THREADS、SLEEP_NSEC，可以在编译时用 gCC 的-D选项传递参数。让这些
206|第5章 实践内核调试
内核改成新版本。此外还尝试了一些其他方法，这样就能更详尽地了解发生条件。
会停止响应几十秒，而这个程序会导致永久停止响应。
命令。我设置的参数 SLEEP_NSEC为 100 毫秒，NUM_THREADS 为 CPU 个数+1。报告说
变调度策略。将调度策略改成实时，需要 root 权限，因此执行命令时要加上 sudo
序，就成功地复现了 bug。chrt 命令是 RedHat 系列发行版中的一个命令，可以改
可能成为关键的参数可以被简单地改变，测试时就很方便了。用 chrt 命令执行该程
$ sudo chrt -f 99 ./segfault 
 $ gcc -DSLEEP_NSEC=1eeeee0 -DNUM_THREADS=3 -lpthread -0 segfault segfault.C
int main (void)
void thread (void* buf)
#include 
#include 
return 0;
pthread_t thr;
} while (1);
struct timespec tm = { 0, SLEEP_NSEC };
kill(0, SIGSEGV);
/*给自己发送 core dump 信号 */
sleep(2);
/*稍稍释放CPU，让子线程运行*/
for (i=0; ibt 3817
>3819
>3818
crash> ps | grep segfault
38173781
PIDPPIDCPU
旧版本内核上也能发生
新版本内核上不发生。
→不接受任何命令。
用户空间似乎没有工作
无法接收键盘操作。
→但是反应速度变慢。
停止响应后仍然能响应外部的ping。
与系统负载没有关系。
复现频率为100%，能立即发生。
故意访问NULL指针时并不会发生
线程数大于等于CPU数+1时发生。
仅在SCHED_FIFO时发生。
ps命令的运行结果中，最左列标有“”的就是当前任务。
3781
3781
1007dddb030
1007cec5030
1007debf7fo
TASK
www.TopSage.com
CPU:1 COMMAND:“segfault”"
IN
召
RU
ST
0.0
0.0
0.0
MEMVSZ
241085
24108
24108
RSS
528
528
COMM
segfault
segfault
segfault
213
---
## Page 226
214
图 5-9确认线程行为
储的处理部分。
接下来调查一下独占 CPU 的当前任务在做什么。下面省略了 watchdog 引发崩溃转
中释放了CPU。
就无法再获得。进程接收到致命的信号，于是创建 core dump 后就结束了，在这途
然后再查看task_struct及运行队列中残留的时间戳信息，可知一旦释放了CPU,
放了CPU。查看内核代码后证实其行为的确如此（图5-9)。
do_coredump()被调用表明父线程在执行 core dump，其中执行了 sched_yield(），释
208 1
#16 [100778blel] get_signal_to_deliver at fffff01433c9
PID: 3818 TASK: 1007cec5030
crash> bt -a
#5 [100780b3f50] ptregscall_common at ffffffff801105df
#4 [100780b3e50] do_signal at ffffff8010f6fb
#3 [100780b3e10] get_signal_to_ deliver at ffff801433a1
#2 [100780b3d20] d
#0 [100780b3c28] schedule at ffffffff8030d7b4
：
RAX: fffffffffffffdfc RBX: 0ooo0oo0000oooo RcX: ffffffffffffffff
RIP: 000000320170bab5 RSP: 000000040a001a0 RFLAGS: 00000202
ORIG_RAX: 00000003e CS: 0033 SS: 002b
R13: 0000007fbffbc0 R4: 00000000 R15: 00000000000
R10:
RBP:
RDX: 0000000000000000
RAX: 00000000000000O R
RIP: 0000003200e2e829 RSP: 0000007fbffffab8 RFLAGS: 00000206
[100778ble50] do_signal at ffffffff8010f6fb
第5章实践内核调试
0000007fbffffa01 R
00000o7fbffffafo
do_coredump at fffffff f80184e02
www.TopSage.com
R11: 0000000000000206 R12: 00000000004007d0
R8:
RSI:
RBX:0000000000000000 R
get_signal_to_deliver()
: 0000007fbffff8e0
I:000000000000000bRDI:0000000000000000
>do_coredump()
CPU: 0 COMMAND: "segfault"
>coredump_wait()
>yield()
R9: 0000002a9557b190
RcX:ffffffffffffffff
---
## Page 227
程间共享队列中已获得了信号信息。
TIF_SIGPENDING。相反，信号处理失败的原因是父线程已开始信号接收处理，从线
号信息放到线程间共享的队列中。nanosleep()中断的原因就是设置了这个
信号被发送到进程后，进程内的所有线程都会被设置 TIF_SIGPENDING 标志，并将信
导致像图5-11那样反复出现睡眠中断和信号处理失败。
束后，就执行 nanosleep_restart()，继续残留的睡眠。但是，这次无法处理该信号，
nanosleep()被信号中断后，就会停止睡眠，试图处理信号（图5-10)。信号处理结
代码。结果就发现，下面的信号导致了死循环。
从分析转储的过程中明白了各个线程正在运行的操作，因此可以高效率地添加调试
于是在内核源代码中加入 printk()，看看究竟是什么处理花费了较多的时间。我们
从 backtrace 来看，当前任务中似乎没有奇怪的地方。只看转储也看不出什么东西,
加入调试代码进行分析
转储，就可以了解问题发生时各个线程都在运行什么。
分系统调用中一旦发生信号，就会先处理信号，再继续剩下的处理。通过观察内核
PID:3818 线程在处理信号。PID:3819似乎正在执行 nanosleep()，nanosleep()等部
$
#
PID: 3819 TASK: 1007dddb030
ORIG_RAX: 0000000000000db CS: 0033 SS: 002b
3 [100778b3ef0] schedule_ timeout at fffff8030elad
R13:0
RIP: 000000320170bab5 RSP: 00000000414011a0 RFLAGS: 00000202
[100778b3f80] system_call at fffff8011026a
[100778b3f50] nanosleep_ restart at fffffff8030e335
ORIG_RAX:00000000000000db
R13: 000000320170d1c0 R14:
R10: 0000000040a00101 R11: 0000000000000202R
RBP: 0000000040a001d0
RDX:0000000000000002 R
DX:
AX:0
000000320170d1c0 R14: 0000000000000 R15: 000000320170d1c0
00000000414019f0 R
00000000414011d0
0000000000000002
000000000000obdb
R8:
RSI:
RBX:
R8:0000000040a00960
RSI: 00000000000000 RDI: 000000004008d0
: 0000000041401960
CS: 0033 SS: 002b
www.TopSage.com
0000000000000202
0000000000000000
ffffffff8011026a
0000000000000000
 CPU: 1 COMMAND: "segfault"
HACK#36内核停止响应（死循环篇）
RDI:00000000004008d6
aRcx:ffffffffffffffff
R15: 000000320170d1c0
R9: 0000000041401960
R12: 0000003201706080
R9: 0000000040a00960
1209
215
---
## Page 228
216
图5-12信号接收处理的调用流程
如图5-12。
检查当前的信号接收状况，因此几乎所有信号接收处理都会执行该函数。调用流程
TIF_SIGPENDING标志在 recalc_sigpending_tsk()内被清除。recalc_sigpending_tsk()
程去接收信号。
TIF_SIGPENDING 标志上。尽管应当处理的信号信息已被父线程取走，却仍通知子线
处在执行该操作之前，子线程就失控了。观察整个流程后发现，问题似乎出在
通常，应当给开始信号接收处理的父线程发送 SIGKILL，以终止所有子线程，但此
图5-11子线程死循环
图5-10nanosleep()被信号中断
210
第 5章实践内核调试
sys_nanosleep()
>schedule_timeout(}
/*注册100毫秒的定时器*/
do_signal()
> schedule()
get, signal_ to_deLiver()
/*在信号处理中检测到中断（检查任务的TIF_SIGPENDING标志），不
> dequeue_signal()
www.TopSage.com
nanosleep restart()中断
无法处理信号
中断nanosleep()
→ recalc sigpending()
dequeue_signal()
无法处理信号
> recalc_sigpending_ tsk()
---
## Page 229
标志，清除该标志所需的 group_stop_count 被设置为0的时机有问题。
coredump_wait()函数之后。调试到这里就能明白,停止响应的原因是 TIF_SIGPENDING
而且仔细观察可以发现，这个计数器的清除时机位于父线程释放CPU的
在 do_coredump()中被清除。
这次的复现程序没有改变信号掩码，因此由于 TIF_SIGPENDING 会被清除，所以
recalc_sigpending_tsk()函数如下所示。
（也就是说kill()系统调用过程中）从属于该进程的线程数。实际上，这个计数器
int do_coredump(long signr, int exit_code, struct pt_regs * regs)
[fs/exec.c]
fastcall void recalc_sigpending_tsk(struct task_struct *t)
[kemel/signal.c] 
current->signal->group_stop_count = 0;
 coredump_wait(mm);
 if (t->signal->group_stop_count > 0 |1 
else
*1
PENDING(&t->signal->shared_pending, &t->blocked)