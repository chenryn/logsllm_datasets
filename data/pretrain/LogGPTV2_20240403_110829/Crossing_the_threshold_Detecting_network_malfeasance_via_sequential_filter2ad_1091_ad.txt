### Clear Outcome for Hosts
We define a clear outcome as one where a host receives an NX response.

### A. Offline Analysis
To evaluate the accuracy of our classifier, we conducted empirical evaluations over several months to confirm its stability. We used the top 100 zones from a white-list based on historical NX traffic. Our evaluation method involved k-fold cross-validation, a technique that partitions the data into k subsets. One subset is used for testing, while the remaining k-1 subsets are used for training. This process is repeated k-1 times, ensuring each subset is used once for testing. The results are then averaged to provide a robust performance assessment.

#### Cross-Validation and Error Estimation
In our experiments, we estimated the error rates (e0 and e1) using k-fold cross-validation. We varied the training window sizes (6, 12, and 24 hours) and used different values of k (10, 5, and 3). Figure 7 shows the box-and-whisker plot of the error estimation for varying window sizes and k values. The root mean square error (RMSE) was computed over two repeated runs, and the results indicate that a 24-hour training window yields the best results with an average RMSE of 0.034.

#### Detection Time
Figure 8 illustrates the time (in seconds) taken to classify a client as a bot after the first unique NX response. Most bots were correctly classified within a few seconds, primarily because they perform multiple queries at once. However, some bots make singular queries at uniform intervals, which can take several hours to detect.

#### Rendezvous Point Analysis
To assess the effectiveness of our classifier, we manually located the "rendezvous point" for 20 prominent bots and compared the time between classification and the actual rendezvous. Figure 9 shows the results, indicating that in 83% of the cases, we detected bots either shortly before or during the liaison with the command-and-control server. In the remaining cases, the detection occurred after the rendezvous point.

### B. Visualizing AGD Traffic
In an enterprise setting, security analysts often need to manage pending hosts. We found that 95% of the pending hosts remained in that state for at least 2.5 hours, and some for almost the entire 24-hour period. To reduce the memory footprint, we implemented a Zipf Filter using the top 100 pending zones, which removed 30% of the pending hosts. Future work will explore strategies to prune pending hosts based on their age or unique NX response count.

### C. Comparison with Existing Work
We implemented the Edit-Distance algorithm by Yadav and Reddy [31], which extends the time binning approach to individual clients. Despite the additional domains collected from NX traffic, the false positive rate remained high (over 14%). Our approach, which only requires storing DNS zones for each observed event, outperformed Yadav and Reddy's method, which required both successful and NX domain names, adversely affecting its runtime and storage requirements.

### D. Grouping Infected Clients
After the detection process, we provide a technique for grouping infected clients based on their AGD traffic. This grouping is based on the observations that (1) multiple clients tend to be infected with the same type of bot and (2) infected hosts perform the same domain lookups due to a global seed. Figure 11 shows the hierarchical clustering of AGDs, with the size of the domain name indicating its prevalence in the cluster.

### Example AGDs
- kt2syggf436dtag458.com
- kt2syggf436dtagl82.com

### Conclusion
Our classifier demonstrates high accuracy and efficient detection times, making it a valuable tool for identifying and classifying bots in an enterprise network. The use of k-fold cross-validation and hierarchical clustering provides a robust and scalable solution for managing and visualizing AGD traffic.

---

This optimized text aims to provide a clear, coherent, and professional presentation of the original content.