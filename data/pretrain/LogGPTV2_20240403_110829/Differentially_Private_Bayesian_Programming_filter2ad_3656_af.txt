tl :: B list | lŸ Φ lŹu Ñ MSD,0tx :: r0, 1s |“u
Ñ MSD,ζtx :: r0, 1s |“u
The choice of which metric to use is ultimately left to the
user.
This example easily extends also to the Dirichlet example.
More details about the Dirichlet distribution are given in the
supplementary material section. Indeed, Lemma 6.1 can be
generalized to arbitrary Dirichlet distributions:
Lemma 6.3. Let k P Ně2, d1, d2 : rks list with d1Φd2.
Let a1, a2, . . . , ak P R`. Let Prpξq “ Dirichletpa1, a2, . . . , akq.
Then ∆HDpPrpξ | d1q, Prpξ | d2qq ď
1 ´ π
a
4 “ ρ.
Using this lemma we can assign to the following program:
1.let rec learnP db prior = match dbn with
2.| [] Ñ prior
3.| d::dbs Ñ mlet rec = (learnP dbs prior) in observe
4. (fun r sÑ mlet z = ran multinomial(r,s) in
5.
return (d=z)) rec
the type:
tl :: r3s list | lŸ Φ lŹu Ñ MHD,0tx :: r0, 1s2 |“u
Ñ MHD,ρtx :: r0, 1s2 |“u
1.let rec learnBias db prior = match dbn with
2.| [] Ñ prior
3.| d::dbs Ñ mlet rec = (learBias dbs prior) in observe
4.
(fun r Ñ mlet z = ran bernoulli(r) in return (d=z)) rec
Similarly to the previous example we can now add noise
to the output of the inference process using the sensitivity
with respect to the Hellinger distance and obtain a pρ, 0q-
diﬀerential privacy guarantee.
7. RELATED WORK
Differential privacy and Bayesian inference. Our sys-
tem targets programs from the combination of diﬀerential
privacy and Bayesian inference. Both of these topics are ac-
tive areas of research, and their intersection is an especially
popular research direction today. We brieﬂy summarize the
most well-known work, and refer interested readers to sur-
veys for a more detailed development (Dwork and Roth [17]
for diﬀerential privacy, Bishop [9] for Bayesian inference).
Blum et al. [10] and Dwork et al. [18] proposed diﬀerential
privacy, a worst-case notion of statistical privacy, in a pair
of groundbreaking papers, initiating intense research interest
in developing diﬀerentially private algorithms. The original
works propose the Laplace and Gaussian mechanisms that
we use, while the seminal paper of McSherry and Talwar [31]
introduces the exponential mechanism. Recently, researchers
have investigated how to guarantee diﬀerential privacy when
performing Bayesian inference, a foundational technique in
machine learning. Roughly speaking, works in the literature
have explored three diﬀerent approaches to guaranteeing
diﬀerential privacy when the samples are private data. First,
we may add noise directly to the samples, and then perform
inference as usual [39]. Second, we may perform inference on
the private data, then add noise to the parameters themselves
[41]. This approach requires bounding the sensitivity of the
output parameters when we change a single data sample,
relying on speciﬁc properties of the model and the prior
distribution. The ﬁnal approach involves no noise during
inference, but outputs samples from the posterior rather
than the entire posterior distribution [16, 41, 42]. This last
approach is highly speciﬁc to the model and prior, and our
system does not handle this method of achieving privacy,
yet.
Formal veriﬁcation for differential privacy. In parallel
with the development of private algorithms, researchers in
formal veriﬁcation have proposed a wide variety of tech-
niques for verifying diﬀerential privacy. For a comprehensive
discussion, interested readers can consult the recent survey
by Barthe et al. [8]. Many of these techniques rely on the
composition properties of privacy, though there are some ex-
ceptions [7]. For a brief survey, the ﬁrst systems were based
on runtime veriﬁcation of privacy [30]. The ﬁrst systems for
static veriﬁcation of privacy used linear type systems [22, 34].
There is also extensive work on relational program logics for
diﬀerential privacy [2–4], and techniques for verifying privacy
in standard Hoare logic using product programs [5]. None of
these techniques have been applied to verifying diﬀerential
privacy of Bayesian inference. Our system is most closely
related to HOARe2, a relational reﬁnement type system that
was recently proposed by Barthe et al. [6]. This system has
been used for verifying diﬀerential privacy of algorithms, and
more general relational properties like incentive compatibil-
ity from the ﬁeld of mechanism design. However, it cannot
model probabilistic inference.
Probabilistic programming. Research in probabilistic pro-
gramming has emerged early in the 60s and 70s, and is nowa-
days a very active research area. Relevant to our work is
in particular the research in probabilistic programming for
machine learning and statistics which has been very active
in recent years. Many probabilistic programming languages
have been designed for these applications, including Win-
BUGS [29], IBAL [33], Church [23], Infer.net [32], Tabu-
lar [25], Anglican [37], Dr. Bayes [38]. Our goal is not to
provide a new language but instead is to propose a frame-
work where one can reason about diﬀerential privacy for
such languages. For instance, we compiled programs written
[25] into PrivInfer so that diﬀerential privacy
in Tabular
could be veriﬁed. More information on this translation can
be found in the supplementary material section. Another
related work is the one by Adams and Jacobs [1] proposing
a type theory for Bayesian inference. While technically their
work is very diﬀerent from ours it shares the same goal of pro-
viding reasoning principles for Bayesian inference. Our work
considers a probabilistic PCF for discrete distributions. It
would be interesting to extend our techniques to higher-order
languages with continuous distributions and conditioning,
by building on the rigorous foundations developed in recent
work [11, 36].
8. CONCLUSION
We have presented PrivInfer, a type-based framework for
diﬀerentially private Bayesian inference. Our framework
allows to write data analysis as functional programs for
Bayesian inference and add to noise to them in diﬀerent ways
using diﬀerent metrics. Besides, our framework allows to
reason about general f -divergences for Bayesian inference.
Future directions include exploring the use of this approach
to guarantee robustness for Bayesian inference and other ma-
chine learning techniques [15], to ensure diﬀerential privacy
using conditions over the prior and the likelihood similar
to the ones studied by Zhang et al. [41], Zheng [42], and
investigating further uses of f -divergences for improving the
utility of diﬀerentially private Bayesian learning. On the
programming language side it would also be interesting to
extend our framework to continuous distributions following
the approach by Sato [35]. We believe that the intersection
of programming languages, machine learning, and diﬀerential
privacy will reserve us many exciting results.
References
[1] R. Adams and B. Jacobs. A type theory for probabilistic
and bayesian reasoning. CoRR, abs/1511.09230, 2015.
[2] G. Barthe and F. Olmedo. Beyond diﬀerential pri-
vacy: Composition theorems and relational logic for
f-divergences between probabilistic programs. In ICALP,
2013.
[3] G. Barthe, B. K¨opf, F. Olmedo, and S. Zanella-B´eguelin.
Probabilistic Relational Reasoning for Diﬀerential Pri-
vacy. In POPL, 2012.
[4] G. Barthe, G. Danezis, B. Gr´egoire, C. Kunz, and
S. Zanella B´eguelin. Veriﬁed computational diﬀeren-
tial privacy with applications to smart metering. In
CSF, 2013.
[5] G. Barthe, M. Gaboardi, E. J. Gallego Arias, J. Hsu,
C. Kunz, and P.-Y. Strub. Proving diﬀerential privacy
in Hoare logic. In CSF, 2014.
[6] G. Barthe, M. Gaboardi, E. J. G. Arias, J. Hsu, A. Roth,
and P. Strub. Higher-order approximate relational re-
ﬁnement types for mechanism design and diﬀerential
privacy. In POPL, 2015.
[24] A. D. Gordon, M. Aizatulin, J. Borgstr¨om, G. Claret,
T. Graepel, A. V. Nori, S. K. Rajamani, and C. V.
Russo. A model-learner pattern for bayesian reasoning.
In POPL, 2013.
[7] G. Barthe, M. Gaboardi, B. Gr´egoire, J. Hsu, and P.-
Y. Strub. Proving diﬀerential privacy via probabilistic
couplings. In LICS, 2016.
[25] A. D. Gordon, T. Graepel, N. Rolland, C. V. Russo,
J. Borgstr¨om, and J. Guiver. Tabular: a schema-driven
probabilistic programming language. In POPL, 2014.
[8] G. Barthe, M. Gaboardi, J. Hsu, and B. Pierce. Pro-
gramming language techniques for diﬀerential privacy.
ACM SIGLOG News, 2016.
[9] C. M. Bishop. Pattern Recognition and Machine Learn-
ing (Information Science and Statistics). 2006. ISBN
0387310738.
[10] A. Blum, C. Dwork, F. McSherry, and K. Nissim. Prac-
tical privacy: The SuLQ framework. In PODS, 2005.
[11] J. Borgstr¨om, U. D. Lago, A. D. Gordon, and M. Szym-
czak. A lambda-calculus foundation for universal proba-
bilistic programming. In ICFP, 2016.
[12] K. Chaudhuri, C. Monteleoni, and A. D. Sarwate. Dif-
ferentially private empirical risk minimization. 2011.
[13] I. Csisz´ar. Eine informationstheoretische Ungleichung
und ihre Anwendung auf den Beweis der Ergodizitat von
Markoﬀschen Ketten. Magyar. Tud. Akad. Mat. Kutat´o
Int. K¨ozl, 1963.
[14] I. Csisz´ar and P. Shields. Information theory and statis-
tics: A tutorial. Foundations and Trends in Communi-
cations and Information Theory, 2004.
[26] M. Hardt, K. Ligett, and F. McSherry. A simple and
practical algorithm for diﬀerentially private data release.
In NIPS, 2012.
[27] M. Hicks, G. M. Bierman, N. Guts, D. Leijen, and
N. Swamy. Polymonadic programming. In MSFP, 2014.
[28] S. Katsumata. Parametric eﬀect monads and semantics
of eﬀect systems. In POPL, 2014.
[29] D. J. Lunn, A. Thomas, N. Best, and D. Spiegelhalter.
WinBUGS - A bayesian modelling framework: Concepts,
structure, and extensibility. Statistics and Computing,
2000.
[30] F. McSherry. Privacy integrated queries: an extensi-
ble platform for privacy-preserving data analysis. In
International Conference on Management of Data, 2009.
[31] F. McSherry and K. Talwar. Mechanism design via
diﬀerential privacy. In FOCS, 2007.
[32] T. Minka,
D. Knowles.
http://research.microsoft.com/infernet. MSR.
Infer.NET 2.5,
J. Winn,
J. Guiver,
2012.
and
URL
[33] A. Pfeﬀer. IBAL: A Probabilistic Rational Programming
Language. In IJCAI, 2001.
[15] D. K. Dey and L. R. Birmiwal. Robust Bayesian analy-
sis using divergence measures. Statistics & Probability
Letters, 1994.
[34] J. Reed and B. C. Pierce. Distance Makes the Types
Grow Stronger: A Calculus for Diﬀerential Privacy. In
ICFP, 2010.
[16] C. Dimitrakakis, B. Nelson, A. Mitrokotsa, and B. I. P.
Rubinstein. Robust and Private Bayesian Inference. In
ALT, 2014.
[17] C. Dwork and A. Roth. The algorithmic foundations of
diﬀerential privacy. Foundations and Trends in Theo-
retical Computer Science, 2014.
[18] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Cali-
brating noise to sensitivity in private data analysis. In
TCC, 2006.
[19] C. Dwork, G. N. Rothblum, and S. P. Vadhan. Boosting
[35] T. Sato. Approximate Relational Hoare Logic for Con-
tinuous Random Samplings. CoRR, abs/1603.01445.
[36] S. Staton, H. Yang, C. Heunen, O. Kammar, and
F. Wood. Semantics for probabilistic programming:
higher-order functions, continuous distributions, and
soft constraints. In LICS, 2016.
[37] D. Tolpin, J. van de Meent, and F. Wood. Probabilistic
Programming in Anglican. In ECML PKDD, 2015.
[38] N. Toronto, J. McCarthy, and D. V. Horn. Running
Probabilistic Programs Backwards. In ESOP, 2015.
and diﬀerential privacy. In FOCS, 2010.
[39] O. Williams and F. McSherry. Probabilistic Inference
[20] H. Ebadi, D. Sands, and G. Schneider. Diﬀerential
privacy: Now it’s getting personal. POPL, 2015.
[21] F. Eigner and M. Maﬀei. Diﬀerential privacy by typing
in security protocols. In CSF, 2013.
[22] M. Gaboardi, A. Haeberlen, J. Hsu, A. Narayan, and
B. C. Pierce. Linear dependent types for diﬀerential
privacy. In POPL, 2013.
[23] N. D. Goodman, V. K. Mansinghka, D. M. Roy,
K. Bonawitz, and J. B. Tenenbaum. Church: a lan-
guage for generative models. In UAI, 2008.
and Diﬀerential Privacy. In NIPS, 2010.
[40] J. Zhang, G. Cormode, C. M. Procopiuc, D. Srivas-
tava, and X. Xiao. PrivBayes: Private data release via
bayesian networks. In SIGMOD, 2014.
[41] Z. Zhang, B. I. P. Rubinstein, and C. Dimitrakakis. On
the Diﬀerential Privacy of Bayesian Inference. In AAAI,
2016.
Zheng.
Bayesian
privacy
[42] S.
of
URL
http://nrs.harvard.edu/urn-3:HUL.InstRepos:14398533.
Bachelor’s thesis, Harvard College.
The
inference,
diﬀerential
2015.