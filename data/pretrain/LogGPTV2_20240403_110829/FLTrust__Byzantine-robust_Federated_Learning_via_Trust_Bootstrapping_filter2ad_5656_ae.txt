0.10
0.10
0.90
0.10
(b) CNN global model, MNIST-0.5
FedAvg
Trim-mean Median
FLTrust
No attack
LF attack
Krum attack
Trim attack
Scaling attack 0.02 / 1.00 0.09 / 0.01 0.06 / 0.02 0.06 / 0.01 0.05 / 0.00
Adaptive attack
0.05
0.05
0.05
0.06
0.04
0.06
0.10
0.28
0.06
0.06
0.14
0.23
0.06
0.06
0.15
0.43
0.06
0.13
0.10
0.22
0.90
Krum
0.10
0.10
0.91
0.10
(c) CNN global model, Fashion-MNIST
Trim-mean Median
FedAvg
FLTrust
No attack
LF attack
Krum attack
Trim attack
Scaling attack 0.90 / 1.00 0.16 / 0.03 0.17 / 0.85 0.16 / 0.05 0.11 / 0.02
Adaptive attack
0.11
0.11
0.12
0.14
0.10
0.14
0.13
0.90
0.14
0.26
0.18
0.24
0.14
0.21
0.23
0.27
0.14
0.90
0.18
0.34
0.24
Krum
0.16
0.15
0.90
0.16
Krum
0.54
0.56
0.90
0.51
(d) ResNet20 global model, CIFAR-10
Trim-mean Median
FedAvg
FLTrust
No attack
LF attack
Krum attack
Trim attack
Scaling attack 0.90 / 1.00 0.44 / 0.07 0.22 / 0.96 0.25 / 0.96 0.18 / 0.02
Adaptive attack
0.18
0.18
0.18
0.20
0.16
0.21
0.24
0.81
0.24
0.27
0.52
0.72
0.25
0.45
0.64
0.75
0.20
0.90
0.58
0.69
0.82
(e) LR global model, HAR
FedAvg
Trim-mean Median
FLTrust
No attack
LF attack
Krum attack
Trim attack
Scaling attack 0.04 / 0.81 0.10 / 0.03 0.04 / 0.36 0.05 / 0.13 0.05 / 0.01
Adaptive attack
0.04
0.04
0.04
0.05
0.03
0.17
0.03
0.32
0.04
0.05
0.05
0.36
0.05
0.05
0.05
0.13
0.05
0.04
0.19
0.05
0.06
Krum
0.12
0.10
0.22
0.10
(f) ResNet20 global model, CH-MNIST
Trim-mean Median
FedAvg
FLTrust
No attack
LF attack
Krum attack
Trim attack
Scaling attack 0.26 / 0.20 0.34 / 0.03 0.14 / 0.02 0.11 / 0.01 0.14 / 0.03
Adaptive attack
0.10
0.12
0.12
0.13
0.10
0.12
0.11
0.64
0.10
0.15
0.13
0.55
0.11
0.13
0.13
0.44
0.13
0.14
0.29
0.50
0.47
Krum
0.24
0.39
0.95
0.21
for FedAvg. Previous work [9] showed that FedAvg can be
arbitrarily manipulated by a single malicious client.
Moreover, for the Scaling attack, FLTrust substantially
reduces its attack success rates. Speciﬁcally, the attack success
rates for FLTrust are at most 0.03. On the contrary, the attack
success rates for FedAvg are always high on the six datasets,
and they are also high for the existing Byzantine-robust FL
methods on multiple datasets, indicating that existing FL meth-
ods are not robust against the Scaling attack. One interesting
observation is that the Scaling attack may decrease the testing
error rates in some cases. We suspect the reason may be that
the data augmentation in the Scaling attack positively impacts
the aggregation of the local model updates. Speciﬁcally, the
11
TABLE IV: The testing error rates of different variants of FLTrust under different attacks and the attack success rates of the
Scaling attacks on MNIST-0.5. The results for the Scaling attacks are in the form of “testing error rate / attack success rate”.
“–” means that the attacks are not applicable.
No attack
LF attack
Krum attack
Trim attack
Scaling attack
Adaptive attack
FLTrust-Server
FLTrust-withServer
FLTrust-NoReLU
FLTrust-NoNorm
FLTrust-ParNorm
FLTrust
0.21
0.07
0.28
0.05
0.06
0.05
–
0.08
0.90
0.06
0.06
0.05
–
0.09
0.90
0.06
0.06
0.05
–
0.10
0.90
0.08
0.06
0.06
–
0.08 / 0.01
0.94 / 0.08
0.94 / 0.08
0.06 / 0.01
0.05 / 0.00
–
0.94
0.90
0.06
0.06
0.06
Fig. 3: The training error rates vs. the number of iterations for
FLTrust under different attacks and FedAvg without attacks on
MNIST-0.5.
(a) Testing error rate
(b) Attack success rate
Fig. 4: Impact of the root dataset size on FLTrust under
different attacks for MNIST-0.5.
data augmentation in the Scaling attack improves the diversity
of the training data, and thus helps the learned global model
better generalize to the testing dataset.
Third, FLTrust achieves the efﬁciency goal. Speciﬁcally,
in each iteration, FLTrust does not incur extra overhead to
the clients; and compared to FedAvg, the extra computation
incurred to the server by FLTrust includes computing a server
model update, computing the trust scores, and normalizing the
local model updates, which are negligible for the powerful
server. Moreover, Figure 3 shows the training error rates versus
the global iteration number for FLTrust under different attacks
and FedAvg under no attack on MNIST-0.5. Our results show
that FLTrust converges as fast as FedAvg, which means that
FLTrust also does not incur extra communications cost for
the clients (each iteration of FL requires communications
between clients and server), compared to FedAvg under no
attacks. We note that Krum, Trim-mean, and Median do not
incur extra overhead to the clients. However, Krum incurs
signiﬁcant computational overhead to the server when there
are a large number of clients. This is because Krum requires
calculating pairwise distance between local model updates in
each iteration.
Comparing different variants of FLTrust: FLTrust has three
key features: a root dataset, using ReLU to clip the cosine
similarity scores, and normalizing each local model update.
Depending on how each feature is used, we consider the
following ﬁve variants of FLTrust:
•
FLTrust-Server. In this variant, the server only uses
the root dataset to train the global model. Therefore,
there is no communications between the clients and
the server during the training process. We use this
variant to show that the server cannot obtain a good
model using its root dataset alone. In other words,
even if some clients are malicious, communicating
with clients still improves the global model.
•
•
•
•
FLTrust-withServer. In this variant, the server com-
putes the weighted average of the clients’ local model
updates together with the server model update whose
trust score is 1.
FLTrust-NoReLU. In this variant, the server does not
use ReLU to clip the cosine similarity scores of the
local model updates when computing their trust scores.
FLTrust-NoNorm. In this variant, the server does not
normalize the local model updates to have the same
magnitude as the server model update.
FLTrust-ParNorm. In this variant, the server applies
partial normalization, i.e., only normalizes the local
model updates whose magnitudes are larger than that
of the server model update to have the same magnitude
as the server model update.
Table IV compares the variants with respect to their testing
error rates under different attacks and the attack success rates
of the Scaling attacks on MNIST-0.5. The attacks are not appli-
cable to FLTrust-Server as it does not require communications
from the clients. Our results show that FLTrust outperforms
the ﬁve variants. FLTrust outperforms FLTrust-Server and
FLTrust-withServer because the root dataset is small. The fact
that FLTrust outperforms FLTrust-NoReLU, FLTrust-NoNorm,
and FLTrust-ParNorm indicates the necessity of our ReLU
operation and normalization.
Impact of
the root dataset: Our root dataset can be
characterized by its size and how it is sampled (i.e., Case I vs.
Case II). Therefore, we study the impact of the root dataset
on FLTrust with respect to its size and how it is sampled.
Figure 4 shows the testing error rates of FLTrust under different
attacks and the attack success rates under the Scaling attack on
MNIST-0.5 when the size of the root dataset increases from
50 to 500, where the root dataset is sampled uniformly in
Case I. We observe that a root dataset with only 100 training
examples is sufﬁcient for FLTrust to defend against the attacks.
12
0500100015002000Iteration0.00.20.40.60.81.0Training error rateFedAvg w/o attacksLF attackKrum attackTrim attackScaling attackAdaptive attack50100200300500Size of the root dataset0.00.20.40.60.81.0Testing error rateFedAvg w/o attacksLF attackKrum attackTrim attackScaling attackAdaptive attack50100200300500Size of the root dataset0.00.20.40.60.81.0Attack success rateFedAvg w/o attacksScaling attack0.1
0.04
0.04
0.04
0.04
0.1
0.05
0.05
0.05
0.06
0.1
0.11
0.11
0.12
0.14
0.1
0.18
0.18
0.18
0.20
0.17
0.04
0.04
0.04
0.05
TABLE V: The testing error rates of FLTrust under different
attacks and the attack success rates of the Scaling attacks when
the root dataset is sampled with different bias probabilities in
Case II.
Bias probability
No attack