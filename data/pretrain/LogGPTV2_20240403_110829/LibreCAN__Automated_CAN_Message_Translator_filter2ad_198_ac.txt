filtered through three separate stages, each designed to indepen-
dently identify potential candidate CAN IDs. The order of these
filtering stages was set based upon extensive evaluation to achieve
Figure 7: Phase 2 Filtering Example
the highest accuracy. Stages 1, 2, and 3 operate under the assump-
tion that body-related events should trigger visible and immediate
changes in the messages broadcast on the CAN bus.
Stage 1: Filtering messages with constant payloads. We as-
sume that body-related events should trigger changes in message
payloads for at least one CAN ID, so we removed all CAN IDs whose
payloads did not change throughout the snippet. As an example,
in Fig. 7, messages with a CAN ID of 300 were filtered out at this
stage because all payloads sent in the event snippet were the same.
Stage 2: Filtering messages present in the reference state. We
removed candidate messages if their CAN IDs and payloads matched
a (CAN ID, payload) pair found in the reference state. If a candidate’s
payload from the event snippet was identical to the reference state,
when no body-related events occurred, it is highly unlikely this
message was sent due to a change in the state of the vehicle’s body.
This stage can be considered a diff between the reference state
and each event Re. In Fig. 7, messages with the (CAN ID, payload)
pairs (400, 056089000A00A000) and (600, 000000024CB016EA) were
filtered out because they were present in the reference state. Fur-
thermore, we found better results obtained by rejecting candidates
whose CAN IDs were not present in the reference state.
Stage 3: Filtering messages which were likely powertrain-
related. To reduce the quantity of remaining candidates, we re-
moved those CAN IDs that were identified as potential candidates
for powertrain-related events in Phase 1. This was possible since
there was little overlap between the events being identified in both
phases. To minimize the removal of candidates that were mistak-
enly classified as powertrain-related in Phase 1, we only removed
CAN IDs if their correlation scores from Phase 1 were higher than
Session 10A: Cyberphysical SecurityCCS ’19, November 11–15, 2019, London, United Kingdom2289Table 1: Confusion Matrix for Phases 1 and 2
Positive
Negative
Ground Truth
Results from
Phases 1 & 2
Positive
TP
Phase 1: Signals that are correctly identified
as part of the ground truth
Phase 2: Candidate CAN IDs that were
correctly identified as being related to an event
FP
Phase 1: Signals that are incorrectly identified
and are not part of the ground truth
Phase 2: Candidate CAN IDs that were incorrectly
identified as being related to an event
Negative
FN
Phase 1: Signals that are not identified,
but are part of ground truth
Phase 2: CAN IDs that were incorrectly
rejected during the filtering process
TN
Phase 1: Signals that are not identified,
but are also not part of ground truth
Phase 2: CAN IDs that were correctly
identified as not being related to an event
a threshold (Tp2,3). The correlation scores for each CAN ID in the
example in Fig. 7 can be observed in the section POWERTRAIN. In
such a situation, messages were filtered out at this stage if their
correlation scores were greater than 0.80.
Finally, those messages that were not filtered out are considered
the candidates for that particular event snippet. In Fig. 7, the (CAN
ID, payload) pairs that were not filtered out are labeled CANDIDATE
in the TRACE section. Eventually, we need to compare the results
obtained from our intelligent filtering algorithm against the ground
truth. As in Phase 1, a ground truth needs to be created from manual
inspection of the DBC files for each test vehicle — a confusion matrix
is defined for this classification task in Table 1.
4 EVALUATION
4.1 Data Collection
Four vehicles are used for our evaluation, all from the same OEM:
Vehicle A is a 2017 luxury mid-size sedan, Vehicle B is a 2018
compact crossover SUV, Vehicle C is a full-size crossover SUV while
Vehicle D is a full-size pickup truck. We have acquired DBC files
for all four vehicles and used them as the ground truths against
which to compare the results of LibreCAN. Vehicles A, C and D have
at least two HS-CAN buses, both of which are routed out to the
OBD-II connector, whereas Vehicle B has at least one HS-CAN and
one MS-CAN, with only the former being accessible via OBD-II.
We collected two types of data: Free driving data for an hour
with each vehicle (for Phase 1) as well as event data for reverse-
engineering body-related events (for Phase 2). For the former, data
was collected through the OBD-II port with two devices: an ELM327
dongle and an OpenXC dongle. A Y-cable was used to allow both
devices to connect to the port at the same time, allowing us to
gather raw CAN data via the OpenXC dongle, while simultaneously
gathering OBD-II data and smartphone data via the ELM327 dongle.
The recorded CAN dump consists of raw JSON data with CAN
message metadata such as the CAN ID and timestamp, along with
the payload data. We used the Torque Pro Android app to interface
with the ELM327 dongle via Bluetooth. This produced a CSV file
with around 22 signals d ∈ S, containing both OBD-II PIDs V as
well as mobile sensor data P (see Table 9). For Phase 2, we solely
used the OpenXC dongle to record raw CAN data.
4.2 Accuracy and Coverage
In the previous subsection, we introduced several parameters for
each phase x that are denoted as Tpx,y, where y is an incremental
number. Besides tuning these parameters to achieve the highest
accuracy, another design goal is to find a set of parameters for each
vehicle — henceforth called parameter configuration — that does not
significantly differ from the configuration of other vehicles. In a real-
world use-case of LibreCAN, DBC files are not available, and thus
the parameters cannot be tuned to achieve optimal performance. So,
we would like to show the existence of a universal configuration
that can achieve good performance on any vehicle without any
prior knowledge of its architecture or DBC structure.
Phase 0: Signal Bounds Accuracy and Reverse-Engineering
Coverage. To evaluate how well our implementation and enhance-
ments to the READ algorithm’s extracted signal boundaries, we
compared the boundaries produced by Phase 0 with the ground
truth boundaries extracted from the DBC files for both vehicles. To
find the optimal values of the four parameters defined in Section 3.1,
we performed a brute-force search through all possible combina-
tions as depicted in Table 3. For Phase 0, we defined optimal as
the total number of correctly extracted signals (CE). We sorted all
parameter configurations in a descending list by this metric. For
the maximum number of CE, we manually inspected these con-
figurations among all four vehicles for similarity and selected the
configurations with the smallest distance to each other. As shown
in the first four columns of Table 3, the numbers of each 4-tuple
configuration are very close to each other.
The results of the run with the optimal parameters for Phase 0 are
summarized in Table 2. It shows the number of correctly extracted
signals (CE) that we optimized our parameter configurations for,
the number of total extracted signals (TE) and the total number of
signals in the DBC files (TDBC). Note that Vehicle B has a lower
number of TDBC since we can only reverse-engineer one CAN bus
(the second one is not available through the OBD-II port). We define
two ratios: CE/TE and TE/TDBC. The latter can be defined as reverse-
engineering coverage. LibreCANcan always extract more than half
of the available signals, with varying success for the number of
correctly extracted signals. There are multiple reasons for these
less than desirable numbers.
Session 10A: Cyberphysical SecurityCCS ’19, November 11–15, 2019, London, United Kingdom2290Table 2: Phase 0 Evaluation Metrics
Veh.
Correctly
Extracted
(CE)
Veh A 308
Veh B
95
Veh C 208
Veh D 251
Total
Extracted
(TE)
846
453
698
828
Total
in DBC
(TDBC)
1640
829
1236
1327
CE /
TE
TE /
TDBC
36.4% 51.6%
21.0% 54.6%
29.8% 56.5%
30.3% 62.4%
First, not all signals can be triggered in the recordings. Although
we use both free driving and event data for signal extraction in
Phase 0, it is impossible to capture everything, e.g., deployed airbags
or emergency call signals. Since all our evaluation vehicles were
newer with several features and also not the highest trim level
for that particular model, the number of functionalities and thus
signals is relatively higher than an older vehicle. This explains the
TE/TDBC ratio. Second, it is not always possible to match the exact
signal boundaries to the ground truth DBC file. For instance, the
engine speed (RPM) range can go up to 8000 RPM in most vehicles.
Under normal driving conditions with an automatic transmission,
the vehicle will shift to the next gear in the range of 2000–3000
RPM. As a result, we will miss the most significant bits of that
particular signals. The same applies to another physical signals,
such as vehicle speed or engine coolant temperature. This will
intrinsically result in a low CE/TE ratio.
As a result, the aforementioned ratio in Table 2 should not be
used to draw conclusions about the performance of LibreCAN since
the signals inspected in Phases 1 and 2 yield high accuracy numbers.
Table 3: Optimal Parameters in LibreCAN
Tp0,0
[0,64]
Veh. A 0
Veh. B
2
Veh. C 0
Veh. D 2
Tp0,1
[0,64]
3
3
4
3
Tp0,2 Tp0,3
[0,64]
[0,1]
2
0.02
0.01
2
2
0.01
0.01
2
Tp1
[0,1]
0.05
0.07
0.05
0.06
Tp2,0
[0,.1]
0.03
0.03
0.03
0.02
Tp2,3
[.2,1]
0.70
0.70
0.55
0.60
Phase 1: Correlation Accuracy. We analyzed the accuracy of
Phase 1 both independently from Phase 0 (using correct signal
boundaries from the DBC files) in order to avoid possible error
propagation, as well as with the extracted signal boundaries from
Phase 0.
Using the terminology from the confusion matrix in Table 1, we
defined the following metrics to assess for Phase 1:
TP + TN
• Accuracy =
TP + TN + FP + FN
• Precision = TP
TP + FP
• Recall =
TP
TP + FN
In Phase 1, we introduced one parameter that can be tuned
to achieve the best performance. This parameter is the threshold
Tp1 to define the cut-off point, defined previously in Sec. 3.2. One
mechanism to define the optimal value for Tp1 is via the Receiver
Operating Characteristic (ROC) curve. Since we have an unbalanced
ground truth (e.g., the speed contains more CAN signals r than
altitude), a Precision-Recall (PR) curve is a better option. Fig. 8 shows
the PR curve for both vehicles. Each data point depicts a value of
Tp1 ∈ [0, 1].
Figure 8: Precision-Recall Curve for Phase 1
The closest data point to the upper right corner delivers the
optimal threshold Tp1 for the best performance. The PR curve de-
picted in Fig. 8 does not have an ideal shape for Vehicles A, B and
C because the recall value never exceeds 0.55. According to the
above definition of recall, this means that the True Positives (TP)
are always smaller than the number of False Negatives (FN), i.e.,
the ground truth contains CAN signals that can never be found by
our algorithm. Since the ground truth is a subjective interpretation
which we generated by manual inspection of the DBC files, we as-
sume that some CAN signals r are unrelated to the analyzed signal
d. This is a limitation of our work since we could not receive the
OEM’s help in interpreting the DBC files. Some examples where we
encountered this phenomenon are the z-component of accelerome-
ter, altitude and bearing (all from phone). The former two can be
explained by the fact that all our driving took place in a relatively
flat area without many hills. The latter could be caused by GPS
issues since bearing is collected from the phone’s GPS module.
The first part of Table 4 sums up the precision and recall values
using the optimal threshold Tp1 (see Table 3) obtained from the PR
curve analysis. entering The precision and recall values reflect the
evaluation of Phase 1 with correct bounds in the first line and with
the signal bounds from Phase 0 in the second. The latter values are
shown to be slightly lower for all vehicles, with the exception of
Vehicle C. High precision values mean that most of the identified
signals are part of the ground truth, whereas relatively low recall
values mean that we cannot match the majority of signals defined
in our subjective ground truth due to the high number of FNs, as
mentioned previously.
0.00.20.40.60.81.0Recall0.00.20.40.60.81.0PrecisionVehicle AVehicle BVehicle CVehicle DSession 10A: Cyberphysical SecurityCCS ’19, November 11–15, 2019, London, United Kingdom2291Table 4: Phases 1 and 2 Evaluation Metrics
Phase2
Prec.
88.0% 8.9%
90.1% 8.5%
Recall
58.2%
46.2%
Phase 1
Prec.
Vehicle A 82.6%/
77.2%
66.7%/
Vehicle B
61.1%