增加的可用性：0.09%
可用性目标：99.9%→99.99%
第3章拥抱风险
---
## Page 71
在Bigtable的例子中，我们可以构建两个集群：低延迟集群和高吞吐量集群。低延迟集
这样看来，对于这些用户而言，成功和失败是相反的。低延迟用户的成功是关注离线分
化吞吐量，Bigtable系统应该避免处于空闲状态。
低延迟的用户希望Bigtable的请求队列（几乎总是）为空，这样系统可以立刻处理每个
Bigtable请求队列的期望。
常昂贵的。为了更好地了解不同类型用户的不同需求，我们可以分析每个用户对自己
实际情况中，这些基础设施服务往往需要占用大量资源，超高可靠性的代价通常是非
能够同时满足两种情况的要求的一种方法就是将所有基础设施服务做得极为可靠。但在
靠性。这两个情况的风险容忍度相当不同。
作为离线分析的数据存储使用（例如，MapReduce）。这些团队往往更关注吞吐量而非可
它服务用户请求。这样的服务需要很低的延迟和较高的可靠性。其他团队则把Bigtable
Bigtable是一个大型结构化数据分布式存储系统，
可用性目标水平
基础设施组件有多个客户，而他们通常有很多不同的需求。
在一个高可用、全球统一的数据存储中（例如，
的需求又能够压缩成本的服务水平。例如，Google+将与保护用户隐私相关的数据放置
的成本的一部分转移给了用户。以这种方式暴露成本可以促使客户选择既能够满足他们
行正确的风险和成本权衡。通过明确划定的服务水平，基础设施提供者其实就是将服务
基础设施服务运维的关键战略就是明确划分服务水平，从而使客户在构建系统时能够进
的10%~50%。由于Bigtable是广泛部署的系统，这种成本上的降低非常显著。
量集群的配置余度较低，利用率较高。在实践中，高吞吐量集群只有低延迟集群成本
更严格的客户端隔离要求，Bigtable系统可以配备更多的余资源。另一方面，高吞吐
群是为那些需要延迟较低和可靠性较高的服务而设计的。为了确保队列长度最小和满足
务，在多个独立的服务水平上提供该服务。
一种在符合成本效益条件下满足这些竞争性约束的方式就是将基础设施分割成多个服
成本
析的用户的失败。
线分析的用户更感兴趣的是系统的吞吐量，因此用户希望请求队列永远不为空。为了优
出现的请求。（事实上，效率低下的排队过程往往是导致较高的长尾延迟的原因。）而离
故障类型
一个全球复制式的类似于SQL的系统，
，一些面向消费者的服务数据直接通过
服务的风险容忍度
2
SLI是指服务质量指标（indicator）
指标
的词语描述其中不同的涵义，以便更加清晰地进行讨论。
因为在常见的使用环境中，SLA经常被赋予了过多的意义，Google则更倾向于利用不同
前文介绍的莎士比亚搜索服务作为示例来展开讨论，具体详见第2章的“莎士比亚搜索服务”。
本章描述了SRE团队在指标建模、指标选择，以及指标分析上采用的基本框架。我们会采用
也为SRE团队判断系统是否正常工作提供帮助。
API，我们都需要制定一个针对用户的服务质量目标，并且努力去达到这个质量目标。
编辑：BetsyBeyer
作者：Chris Jones、John Wilkes、Niall Murphy、Cody Smith
服务质量目标
第4章
很多读者可能都对SLA这个概念非常熟悉，但SLI与SLO则可能需要一个详细定义。
服务质量术语
应对计划。事先选择好合适的指标有助于在故障发生时帮助SRE进行更好地决策，同时
别是指该服务最重要的一些基础指标、这些指标的预期值，以及当指标不符合预期时的
些服务质量指标（SLI）、服务质量目标（SLO），以及服务质量协议（SLA）。这三项分
在这个过程中，我们需要利用一些主观判断结合过去的经验以及对服务的理解来定义一
无法正确运维这个系统，更不要说可靠地运维了。那么，不管是对外服务，还是内部
如果不详细了解服务中各种行为的重要程度，并且不去度量这些行为的正确性的话，就
一该服务的某项服务质量的一个具体量化指标。
---
## Page 77
设置一个服务性能的预期，即使这可能跟运维人员或者设计者所想的完全不同。这种问
据的抱怨——
SLO的选择和公布可以帮助设立用户对服务质量的预期。该策略可以应对那些没有根
而且，可能不那么直观的是，这两个SLI—QPS和延迟—很可能是相关的：QPS升
得参与程度下降。详情参见“SpeedMatter”，文献[Bru09]中有详细介绍）。