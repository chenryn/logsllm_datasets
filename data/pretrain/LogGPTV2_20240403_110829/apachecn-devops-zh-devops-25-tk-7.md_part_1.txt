# 七、收集和查询日志
In critical moments, men sometimes see exactly what they wish to see.
- *史巴克*
到目前为止，我们主要关注的是指标。我们以不同的形式和不同的目的使用它们。在某些情况下，我们使用指标来扩展 Pods 和节点。在其他情况下，指标用于创建警报，当出现无法自动修复的问题时，这些警报会通知我们。我们还创建了一些仪表板。
然而，度量标准通常是不够的。在处理需要人工干预的问题时尤其如此。当仅有度量标准还不够时，我们通常需要查阅日志，希望它们能揭示问题的原因。
日志记录经常被误解，或者更准确地说，与度量混合在一起。对许多人来说，日志和指标之间的界限是模糊的。一些人正在从日志中提取指标。其他人将指标和日志视为相同的信息来源。这两种方法都是错误的。度量和日志是独立的实体，它们服务于不同的目的，并且它们之间有明显的区别。我们分别存储它们，并使用它们来解决不同类型的问题。我们会把它和其他一些讨论放在一起。我们将通过实际例子来探索细节，而不是基于理论。为此，我们需要一个集群。
# 创建集群
你知道规矩。我们将进入带有`vfarcic/k8s-specs`([https://github.com/vfarcic/k8s-specs](https://github.com/vfarcic/k8s-specs))存储库的目录，我们将获取最新版本的代码，以防我最近推送了一些东西，我们将创建一个新的集群，除非您手头已经有了一个。
All the commands from this chapter are available in the `07-logging.sh` ([https://gist.github.com/vfarcic/74774240545e638b6cf0e01460894f34](https://gist.github.com/vfarcic/74774240545e638b6cf0e01460894f34)) Gist.
```
 1  cd k8s-specs
 2
 3  git pull
```
这一次，对集群的要求发生了变化。我们需要比以前多得多的记忆。罪魁祸首是弹性搜索，它非常需要资源。
如果您使用桌面 Docker(T0)或 T2 minikube(T3)，您需要将群集专用内存增加到 10gb(T5)。如果这对于您的笔记本电脑来说太多了，您可以选择阅读*通过弹性搜索、Fluentd 和 Kibana* 探索集中日志记录，而不运行这些示例，或者您可能不得不切换到云提供商之一(AWS、GCP 或 Azure)。
在 **EKS** 和 **AKS** 的情况下，我们需要更大的节点。对于 EKS，我们将使用 **t2.large** ，对于 AKS **Standard_B2ms** 。两者均基于**2 CPU**和 **8 GB RAM** 。
**GKE** 要求同上。
在新的需求之上，应该注意的是我们在这一章中不需要普罗米修斯，所以我把它从 Gists 中移除了。
请随意使用下面的 Gists 之一来创建一个新的集群，或者验证您计划使用的集群是否满足要求。
*   `gke-monitor.sh` : **具有 3 个 n1-standard-1 工作节点的 GKE** 、 **nginx Ingress** 、 **tiller** 和存储在环境变量**LB _ IP**(https://gist . github . com/vfarcic/10e 14 bfbec 466347 D70 d 11 a 78 Fe 7 ee C4)中的集群 IP。
*   `eks-logging.sh` : **具有 3 个 T2 .大型工作节点的 EKS** 、 **nginx Ingress** 、 **tiller** 、 **Metrics Server** 、 **Cluster Autoscaler** ，以及存储在环境变量**LB _ IP**([https://gist . github . com/vfarcic/a 783351 fc9a 3637 a 291346 DD 4 BC 346 E7](https://gist.github.com/vfarcic/a783351fc9a3637a291346dd4bc346e7)
*   `aks-logging.sh` : **带有 3 个 Standard_B2ms 工作节点的 AKS** 、 **nginx Ingress** 和 **tiller** ，以及存储在环境变量 **LB_IP** 中的集群 IP。
*   `docker-logging.sh` : **Docker for Desktop** 带有 **2 个 CPU**和 **10 GB RAM** 、 **nginx Ingress** 、 **tiller** 、 **Metrics Server** ，以及存储在环境变量**LB _ IP**([https://gist . github . com/vfarcic/17 d4f 11ec 53 eed 74 e4b 5e 73 ebb4 a 59](https://gist.github.com/vfarcic/17d4f11ec53eed74e4b5e73debb4a590)
*   `minikube-logging.sh` : **带 **2 个 CPU**和 **10 GB RAM** 、**入口**、**存储提供程序**、**默认存储类**和**指标-服务器**插件已启用、**分蘖**和存储在环境变量 **LB_IP** 中的集群 IP([https://gist](https://gist.github.com/vfarcic/9f72c8451e1cca71758c70195c1c9f07)**
现在我们有了一个工作集群，我们将通过`kubectl`来探索如何使用日志。这将为接下来更全面的解决方案提供基础。
# 通过 kubectl 浏览日志
大多数人在 Kubernetes 中与日志的第一次接触是通过`kubectl`。不使用它几乎是不可避免的。
当我们在学习如何驯服 Kubernetes 兽时，当我们陷入困境时，我们一定会查看日志。在 Kubernetes 中，术语“日志”是为运行在集群中的我们和第三方应用产生的输出保留的。但是，这些不包括由不同的 Kubernetes 资源生成的事件。尽管许多人也称它们为日志，但 Kubernetes 将它们与日志分开，称它们为事件。我相信您已经知道如何从应用中检索日志，以及如何查看 Kubernetes 事件。尽管如此，我们也将在这里简单地探讨它们，因为这将增加我们稍后讨论的相关性。我保证保持简短，如果对 Kubernetes 中的日志记录和事件的简单概述对您来说过于基础，您可以跳过这一部分。
我们将安装已经熟悉的`go-demo-5`应用。它应该生成足够的日志供我们探索。由于它由一些资源组成，我们也必然会创建一些 Kubernetes 事件。
我们走吧。
```
 1  GD5_ADDR=go-demo-5.$LB_IP.nip.io
 2
 3  echo $GD5_ADDR
 4
 5  helm upgrade -i go-demo-5 \
 6      https://github.com/vfarcic/go-demo-5/releases/download/
    0.0.1/go-demo-5-0.0.1.tgz \
 7      --namespace go-demo-5 \
 8      --set ingress.host=$GD5_ADDR
 9
10  kubectl -n go-demo-5 \
11    rollout status deployment go-demo-5
12
13  curl "http://$GD5_ADDR/demo/hello"
```
我们推出了`go-demo-5`并发送了`curl`请求以确认它确实在工作。
The outputs and screenshots in this chapter are taken from minikube, except inside the sections dedicated to exclusively GKE, EKS, and AKS. There might be slight differences between what you see here and what you can observe on your screen.
要查看由 Kubernetes 生成并限于特定资源的“日志”，我们需要检索事件。
```
 1  kubectl -n go-demo-5 \
 2    describe sts go-demo-5-db
```
输出仅限于`Events`部分的消息，如下所示。
```
...
Events:
... Message
... -------
... create Claim go-demo-5-db-go-demo-5-db-0 Pod go-demo-5-db-0 in StatefulSet go-demo-5-db success
... create Pod go-demo-5-db-0 in StatefulSet go-demo-5-db successful
... create Claim go-demo-5-db-go-demo-5-db-1 Pod go-demo-5-db-1 in StatefulSet go-demo-5-db success
... create Pod go-demo-5-db-1 in StatefulSet go-demo-5-db successful
... create Claim go-demo-5-db-go-demo-5-db-2 Pod go-demo-5-db-2 in StatefulSet go-demo-5-db success
... create Pod go-demo-5-db-2 in StatefulSet go-demo-5-db successful
```
在某种程度上，你前面看到的事件是由`go-demo-5-db`状态集生成的 Kubernetes 日志。
虽然这些事件是有用的，但它们往往是不够的。很多时候，我们事先不知道问题在哪里。如果我们的一个 Pod 行为不当，原因可能在该 Pod 中，但也可能在创建它的复制集内，或者可能在创建复制集的部署中，或者可能节点从集群中分离，或者它可能是完全不同的东西。
For any but the smallest systems, going from one resource to another and from one node to another to find the cause of an issue is anything but practical, reliable, and fast.
简而言之，通过描述资源来看待事件不是办法，我们需要找到一个替代方案。
但是，在此之前，让我们看看应用的日志会发生什么。
我们部署了几个`go-demo-5`应用编程接口的副本和几个 MongoDB 的副本。如果我们怀疑其中一个日志有问题，我们如何查看它们的日志？我们可以像下面这样执行`kubectl logs`命令。
```
 1  kubectl -n go-demo-5 \
 2      logs go-demo-5-db-0 -c db
```
输出显示了`go-demo-5-db-0`舱中`db`容器的日志。
虽然前面的输出仅限于单个容器和单个 Pod，但我们可以使用标签从多个 Pod 中检索日志。
```
 1  kubectl -n go-demo-5 \
 2      logs -l app=go-demo-5
```
这一次，输出来自标签`app`设置为`go-demo-5`的所有 Pods。我们扩大了我们的成果，这往往是我们所需要的。如果我们知道有问题，比如说，`go-demo-5` Pods，我们需要弄清楚问题是出现在多个 Pods 中，还是仅限于单个 Pods。虽然之前的命令允许我们扩大搜索范围，但如果日志中有可疑的东西，我们就不知道它来自哪里。从多个 Pods 中检索日志并不能让我们更加了解哪些 Pods 行为不检点。
使用标签仍然是非常有限的。它们绝不是更复杂查询的替代品。我们可能需要根据时间戳、节点、关键字等过滤结果。虽然我们可以通过额外的`kubectl logs`参数以及`grep`、`sed`和其他 Linux 命令的创造性使用来完成这些事情，但是这种检索、过滤和输出日志的方法远非最佳。
More often than not, `kubectl logs` command does not provide us with enough options to perform anything but simplest retrieval of logs.
我们需要一些东西来提高我们的调试能力。我们需要一种强大的查询语言来过滤日志条目，我们需要关于这些日志来源的足够信息，我们需要快速查询，我们需要访问在集群的任何部分创建的日志。我们将尝试通过建立一个集中的日志解决方案来实现这一点以及其他一些事情。
# 选择集中式日志解决方案
我们需要做的第一件事是找到一个存放日志的地方。考虑到我们希望能够过滤日志条目，从一开始就应该放弃将它们存储在文件中。我们需要的是一个数据库。它比事务性更快，这一点很重要，因此我们很可能会考虑内存数据库解决方案。但是，在我们看选择之前，我们应该讨论我们的数据库的位置。我们应该在集群内部运行它，还是应该使用服务？在做出选择之前，我们将探讨两种选择，而不是立即做出决定。
有两种主要的日志记录即服务类型。如果我们使用云提供商之一运行集群，一个明显的选择可能是使用他们提供的日志解决方案。EKS 有 AWS CloudWatch，GKE 有 GCP Stackdriver，AKS 有 Azure 日志分析。如果您选择使用云供应商之一，这可能很有意义。如果一切都已经准备好了，还等着你，为什么还要费心去建立自己的寻找第三方服务的解决方案呢？我们很快就会探索它们。
由于我的任务是提供适用于(几乎)任何人的指令，我们还将探索托管供应商之外的日志即服务解决方案。但是，我们应该选择哪一个呢？市场上的解决方案太多了。例如，我们可以选择*Splunk*([https://www.splunk.com/](https://www.splunk.com/))或*DataDog*([https://www.datadoghq.com/](https://www.datadoghq.com/))。两者都是很好的选择，而且都不仅仅是日志解决方案。我们可以用它们来收集指标(就像普罗米修斯一样)。他们提供仪表盘(像 Grafana)，和一些其他的东西。稍后，我们将讨论是否应该在一个工具中组合日志和度量。目前，我们只关注日志记录，这是我们将跳过 Splunk、DataDog 和类似的综合工具的主要原因，这些工具提供的功能远远超过我们的需求。这并不意味着您应该放弃它们，而是本章试图保持对日志记录的关注。
可用的测井服务有很多，其中*Scalyr*([https://www.scalyr.com/pricing](https://www.scalyr.com/pricing))、[T5】logdna](https://logdna.com/)([https://logdna.com/](https://logdna.com/))、*相扑逻辑*([https://www.sumologic.com/](https://www.sumologic.com/))只是少数。我们不会一一列举，因为这需要的时间和空间比我认为有用的多得多。考虑到大部分服务在涉及到日志的时候非常相似，我就跳过详细的比较，直接跳到我最喜欢的日志服务*paper trail*([https://papertrailapp.com/](https://papertrailapp.com/))。请记住，我们将只把它作为一个例子。我会假设你会检查至少几个其他的，并根据你的需求做出自己的选择。
日志即服务可能并不适合所有人。有些人可能更喜欢自托管解决方案，而有些人甚至不被允许向集群外发送数据。在这些情况下，自托管日志解决方案可能是唯一的选择。
即使您不局限于自己的集群，也可能有其他原因将它保留在内部，延迟只是众多原因之一。我们还将探索一个自托管解决方案，所以让我们选择一个。会是哪一个？
鉴于我们需要一个地方来存储我们的日志，我们可能会考虑传统的数据库。然而，大多数都不符合我们的需要。像 MySQL 这样的事务数据库需要固定的模式，所以我们可以立即丢弃它们。NoSQL 更适合，所以我们可能会选择像 MongoDB 这样的东西。但是，这将是一个糟糕的选择，因为我们需要执行非常快速的自由文本搜索的能力。为此，我们可能需要一个内存数据库。MongoDB 不是其中之一。我们可以使用 Splunk Enterprise，但这本书专门介绍免费(大部分是开源)解决方案。到目前为止，我们唯一的例外是云提供商，我打算保持这种情况。
我们提到的几个要求(快速、自由文本、内存和免费解决方案)将我们的潜在候选人限制在少数几个。*Solr*([http://lucene.apache.org/solr/](http://lucene.apache.org/solr/))就是其中之一，但是它的使用量一直在下降，今天也很少使用了(理由很充分)。来自一小群人的解决方案是*弹性搜索*([https://www.elastic.co/products/elasticsearch](https://www.elastic.co/products/elasticsearch))。如果您更喜欢不同的内部解决方案，请考虑我们将要介绍的示例，这些示例是您应该能够应用于其他集中式日志记录解决方案的一组实践。
总之，我们将探索独立日志即服务产品(Papertrail)的示例，我们将探索云托管供应商(AWS CloudWatch、GCP Stackdriver 和 Azure Log Analytics)提供的解决方案，我们将尝试与几个朋友一起建立 ElasticSearch。这些应该为您提供足够的示例，让您选择最适合您的用例的解决方案类型。
但是，在我们探索存储日志的工具之前，我们需要弄清楚如何收集日志并将其运送到最终目的地。