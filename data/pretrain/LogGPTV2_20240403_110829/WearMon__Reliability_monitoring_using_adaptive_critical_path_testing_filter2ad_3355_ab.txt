in our results 
test vectors 
to be included 
for the number of vectors 
Note that the minimum number of test vectors 
needed 
of using just two input combinations 
selected 
test vectors 
that exercise 
the most critical 
a group of critical 
path at design time to less crit­
paths in the CUT 
used in 
and CUT's operating 
in the order from 
stored in 
by DTC based 
condi­
of test results 
DTC selects 
(slowest) 
that 
path in the CUT, multiple 
test 
for one path to get tested for a rising or a falling 
is two. Instead 
exercises 
vectors 
will be used in each test phase. Thus, test vectors 
each test phase are a small subset of the vectors 
TVR. This subset is dynamically 
on the history 
tion. Initially 
the most critical 
ical paths. As path criticality 
of the chip, cases might be observed 
initially 
slower paths are not. Hence, the order of the critical 
paths 
updated by the DTC by moving 
tested can be dynamically 
the failing 
to the top of the test list. To ac­
count for the unpredictability 
in device variations, 
test vectors 
randomly 
each test phase making sure that all the paths in the TVR are 
checked frequently 
allows more robust testing 
over time due to different 
and difference 
since critical 
usage patterns, 
enough. This multi-vector 
where paths that were 
on each signal path. 
input patterns 
additional 
in the devices 
are failing 
to be faster 
thought 
present 
selects 
DTC also 
from TVR during 
test approach 
while the expected 
changes during the lifetime 
While our approach 
ensures 
that dynamic variations 
of 
paths may change 
device variability, 
show that 
variations 
timing degradation, 
critical 
paths are accounted 
tion is that a non-critical 
TVR will not fail while all the critical 
through TVR are still operational. 
that due to the physical 
aging related 
which is not in the TVR failing 
paths that are being tested is extremely 
65nm devices 
to NBTI are very small and gradual 
lar, the probability 
voltage 
zero [16, 13]. Thus the probability 
ing is the same as the probability 
margin greater 
to the extent that it violates 
tinely make the assumption 
is highly unlikely 
believe 
trial standards. 
than the guardband 
our fundamental 
while selecting 
which results 
assumption 
of a sudden large variation 
in threshold 
in large path delay changes is nearly 
of an untested 
path fail­
of a path with timing 
suddenly 
deteriorating 
timing. Chip designers 
rou­
that such sudden deterioration 
the guardband. 
Hence we 
is acceptable 
by indus­
for, the fundamental  assump­
path that is not tested by vectors 
in 
paths that are tested 
nature of the phenomena 
It is important 
to note 
causing 
the probability 
before any of the circuit 
of a path 
on 
low. Studies 
voltage 
due 
in threshold 
over time. In particu­
Once the test complexity 
has been determined, 
then DTC 
978-1-4244-7501-8/10/$26.00 
©201O IEEE 
153 
DSN 2010: Zandian 
et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:14:37 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEEIIFIP 
International 
Conference 
on Dependable 
Systems 
& Networks 
(DSN) 
There are two different 
approaches 
DTC initially 
say 1 
cycles between two test phases and then DTC dy­
the next test phase. In the first 
a large test interval, 
to create much finer clock scaling 
in [23]. Alternatively, 
it is possible 
as described 
generator 
such as the one proposed 
minimal area and power overhead. 
an aging resilient 
delay 
in [1] can be used with 
capabilities 
to be inversely 
proportional 
While in our description 
we associated 
one DTC per 
alters 
the test interval 
the test interval. 
when to initiate 
selects 
selects 
for selecting 
approach 
million 
namically 
to the number of failures 
For instance, 
test phases then DTC decreases 
half of the current 
test interval. 
An alternate 
testing. 
approach to 
In this approach 
if two failures 
Current 
overhead. 
are idle waiting 
execution 
writeback, 
for testing 
the entire 
from the correct 
Execution, 
tunistic 
tion only when the CUT is idle thereby 
formance 
tiple such opportunities 
a branch misprediction 
structions 
the pipeline. 
of the pipeline 
the newly fetched 
instructions 
the backend. When a long latency 
L2 cache miss is encountered, 
processors 
stalling 
rarely reaches 
tion phases provides 
CUT within the system. We quantify 
idle times and their duration 
tectural 
are unable to hide the entire 
blocks in the experimental 
the pipeline. 
an excellent 
Finally, 
seen in the past few test phases. 
were noticed 
in the last eight 
the new test interval 
to be 
determine 
test interval 
DTC initiates 
resulting 
is oppor­
a test injec­
in zero per­
mul­
on 
is flushed and in­
a CUT. For example, 
pipeline 
microprocessors  provide 
CUTs share a single 
to have multiple 
CUT it is possible 
DTC which can make testing 
on each CUT's own reliability 
logic can reduce the area overhead 
Mon. In addition, 
from multiple 
an appropriate 
a system-wide 
local RHTs in a hierarchical 
global testing 
decision. 
decisions 
history. 
for each CUT based 
This sharing 
of DTC 
Wear­
of implementing 
DTC can combine  data 
manner to make 
3. Experimental 
Methodology 
into 
path are fetched 
and retirement 
stages 
since 
cycles to reach 
for new instructions 
take multiple 
operations 
such as a 
even aggressive 
out-of-order 
miss latency 
thereby 
computer 
system utilization 
WearMon is not an error correcting 
capabilities 
apply error detection 
which may in-turn 
mechanism. 
It pro­
be used to 
or correction 
mecha­
does not improve re­
design are 
by itself 
Hence, the aims of our experimental 
of 
area overhead 
and design complexity 
using close-to-industrial 
of the RMU and all the associated 
design imple­
components. 
First, 
vides monitoring 
more effectively 
nisms. As such, monitoring 
liability. 
as follows: 
RMU are measured 
mentation 
Second, we explored 
space. Third, performance 
sured. As described 
earlier, 
reduced 
software simulation 
tunity and the distance 
ing. In all our experiments 
rence of rare stochastic 
events, 
are deliberately 
the results 
produced 
overhead 
to zero if testing 
of monitoring 
the overhead 
test intervals 
overhead 
and test complexity 
state 
of monitoring 
is mea­
can be 
of testing 
We use 
of each oppor­
for test­
for the occur­
between two opportunities 
instead 
of waiting 
to measure the duration 
is done opportunistically. 
effects 
of timing degradation 
accelerated 
to measure the overheads 
show worst case 
by this assumption 
and 
compared 
to real implementation. 
100% and the idle time between two utiliza­
opportunity 
the distance 
to test any 
between 
for a select set of microarchi­
results 
section. 
DTC can automatically 
adapt to the reliability 
needs of 
to have failures 
test interval 
As the CUT 
testing. 
is reduced. 
operation, 
DTC can increase 
due to low power set­
Note that the time scale for 
the system. For a CUT which is unlikely 
during the early stages of its in-field 
is increased 
and test complexity 
ages or when the CUT is vulnerable 
tings, 
test interval 
timing degradation 
utes of intense 
will be in the order of seconds even in the worst case. We 
will explore 
of test intervals 
results 
occurs only after many seconds or min­
in the CUT. Hence testing 
and test complexities 
long. For instance, 
performance 
is extremely 
for different 
penalties 
activity 
section. 
selections 
in the experimental 
NBTI related 
interval 
2.5. Design Issues 
3.1. FPGA Emulation Setup 
We modeled the RMU design, 
including 
TVR, DTC 
Floating 
Point Multiplier 
and RHT using Verilog HDL. We then selected 
precision 
that will be monitored. 
IEEE 754 floating 
The RMU and the FPU 
CUT are then mapped onto a Virtex 5 XC5VLX 1 DOT FPGA 
chip using Xilinx ISE Design Suite 10.1. 
This FPU implements 
point standard. 
Unit (FPU) as the CUT 
a double­
the 64-bit 
RHT-Ll is implemented 
as 256 entry table using FPGA 
the CUT does not in 
in aging of the CUT. The 
is negligible 
to 
that testing 
We should emphasize 
lead to noticeable 
increase 
of time a CUT is tested 
itself 
percentage 
the normal usage time. We would also like to 
are design alternatives 
described. 
are existing 
within a chip. For instance, 
processors 
current 
to several 
For implementing 
variable 
for supporting 
for power and thermal 
infrastructures 
granularity 
frequency 
of scaling 
DVFS is supported 
management. 
on most 
While the 
compared 
note that there 
testing 
is  also 
frequency, 
the test vector being in­
sent to the RHT-L2, which is imple­
test result and FPU temperature 
SRAMs. During each test phase 
jected, 
are stored as a single entry in RHT-L1. When a test fails 
the test result 
mented on CompactFlash 
only by size of the CompactFlash. 
the oldest entry in the RHT-L1 will be overwritten,  hence, 
DTC can only observe 
decisions 
tation DTC reading 
at most the past 256 tests for making 
In our implemen­
the test interval. 
memory, and it's size is limited 
from RHT does not impact the 
When RHT-Ll  is full 
on selecting 
results 
of the RMU components 
test frequencies, 
multiple 
there 
clocks 
may be too coarse, 
978-1-4244-7501-8/10/$26.00 
©2010 IEEE 
154 
DSN 2010: Zandian 
et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:14:37 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEE/IFIP 
International 
Conference 
on Dependable 
Systems 
& Networks 
(DSN) 
6 
'*' 4 
QI ... !11 c::: 2 
applu 
......... 
-----apsi 
--
mgrid 
swim 
wupwise 
_ .  -
clock period of the CUT and it does not interfere 
normal operation 
reading 
RHT 
can be done simultaneously 
being written to 
of the CUT. Furthermore, 
while test injection 
RHT. 
with the 
results 
are 
_ 
. .  
between 
One important 
issue that  needs 
to be addressed 
is the 
on 
paths in the FPU 
synthesis. 
The critical 
would also be observed 
between FPGA and ASIC implementa­
of ASIC implementations 
CAD tools are used for synthesis 
!11 u.. 
which exists between FPU's implementation 
0 
difference 
FPGA as compared to ASIC (Application  Specific  Inte­
grated Circuit) 
would be different 
tions. These differences 
instances 
different 
route, or between different 
However, 
designs, 
Slices which exist on the Virtex 5 XC5VLX100T FPGA 
chip. These DSP slices 
on the FPGA chip rather than the traditional 
used in conventional 
DSP slices 
would make its layout and 
ilar to industrial 
SRAM LUTs 
FPGA implementations. 
the efficiency 
and 
more sim­
of the same unit when 
and place and 
technology 
similarity 
to ASIC 
of the FP multiplier 
timing characteristics 
to maximize 
the FPU is implemented 
use dedicated combinational 
ASIC implementation. 
implementation 
using fifteen DSP48E 
fabrication 
increases 
Using these 
nodes. 
logic 
............. 
18 
16 
2. Timing margin degradation 
Figure 
Clock Frequency (MHz) 
24 
20 
22 
of 6.66 nanoseconds. 
in the FPU will fail to meet timing. 
ing step more input operand pairs that exercise 
of critical 
input operand 
pairs. 
paths will fail, in addition 
the next set 
to the first set of failed 
At the next overclock­
In our design, 
FPU's nominal clock period is 60.24 
all the input operand pairs 
output. We then overclocked 
clock period to 40 nanosec­
the 
16.6 MHz, 18.75 MHz, 
decrement 
the correct 
we could achieve 
(16.6 MHz) where 
nanoseconds 
generate 
FPU from 60.24 nanosecond 
ond clock period in equal decrements 
These correspond 
to 4 frequencies: 
21.42 MHz, 25 MHz. The clock period reduction 
step was the smallest 
FPGA board. Percentage 
that failed as the test clock frequency 
shown for multiple 
is initially 
put vectors 
that activate 
gin. We selected 
as the test vectors 
beyond 25 MHz (simulating 
most all input vectors 
in Figure 2. When the CUT 
by a small amount the number of in­
overclocked 
that fail is relatively 
fail across all benchmarks. 
paths with the smallest 
of the FP multiply 
benchmarks 
the critical 
timing mar­
the top 1000 failing 
to fill the TVR. As CUT is overclocked 
a large timing degradation), 
input operand pairs 
al­
small. These are the vectors 
in each 
on the 
was increased 
are 
instructions 
3.2. T hree Scenarios for Monitoring 
We emulated 
three wearout scenarios 
for measuring 
the 
is relatively 
are: Early-stage 
monitoring. 
monitoring 
for instance, 
the condition 
monitoring 
monitoring, 
Early-stage 
overhead. 
Mid-stage 
The three scenarios 
monitoring, 
Late-stage 
monitoring: In early-stage 
operations, 
that the CUT will pass all the tests con­
we 
of a chip which has just started 
its 
the first year of chip's oper­
emulated 
in-field 
ation. Since the amount of timing degradation 
small, it is expected 
RMU tests the 
ducted by RMU. To emulate this condition, 
which is 16.6 MHz in 
CUT at only the nominal frequency, 
our experimental 
into the 
CUT do not produce any errors and hence DTC does not 
change either test interval 
two different 
tervals 
injection 
ity setting. 
or 20 test vectors 
two different test 
of 5 test vectors 
for each test phase. The early-stage 
or test complexity. 
where tests are conducted 
At each test 
complex­
of 100,000 cycles and 1,000,000 
setup. The test vectors 
phase we also explored 
a test complexity 
test intervals, 
We used either 
injected 
cycles. 
We explored 
at in­
mon-
Section 
2.2 described 
an approach 
for selecting 
test vec­
to generate 
to charac­
driven input vector genera­
a set of five SPEC CPU2000 floating 
Applu, Apsi, Mgrid, Swim, Wupwise, 
we did not have access to any existing 
test 
paths. For the FPU selected 
in our 
efforts 
by running 
designer's 
using benchmark 
a trace of floating 
them on 
tors to fill TVR by exploiting 
terize and test critical 
experiments 
vector data. Hence, we devised an approach 
test vectors 
tion. We selected 
point benchmarks, 
point multiplies 
and generated 
benchmarks 
Simplescalar 
with Wattch [10] and Hotspot [19]. The simulator 
ured to run as a 4-way issue Out-Of-Order 
Pentium-4 
tions in each benchmark 
ing point multiplication 
instructions 
recorded 
to 24.39 million 
put operand pair, the expected 
FPU temperature; 
ature is used to mimic processor 
stored on a CompactFlash 
for each trace ranges from 4.08 million 
memory accessible 
The first 300 million 
were recorded. 
we will shortly 
operations 
processor 
(Applu). 
layout. 