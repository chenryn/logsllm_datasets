Reports
Full
12.2 M
243
34.6 M
7.9 M
4.1 M
2.3 B
1.7 B
5.4 K
2.8 M
4.6 M
Subset
412.6 M
4.2 K
1.6 M
VirusTotal
TABLE I: Summary of datasets used.
India
Japan
France
Brazil
Canada
# Country
1 United States
2
3
4 Germany
5 United Kingdom
6
7
8 Australia
9
10 Netherlands
11
12
13
14
15
Italy
Spain
Poland
Belgium
Russia
Devices
20.7%
17.7%
15.3%
7.1%
5.3%
3.3%
2.6%
2.5%
2.3%
2.1%
1.9%
1.6%
1.3%
1.0%
0.9%
Vendor
Samsung
Xiaomi
Motorola
LYF
Huawei
Sony
LGE
Lenovo
Sharp
Asus
Fujitsu
HMD Global
OnePlus
Oppo
Google
Devices
40.5%
8.6%
7.0%
4.9%
4.6%
4.6%
4.3%
4.3%
2.6%
1.9%
1.8%
1.3%
1.1%
1.1%
1.0%
TABLE II: Top 15 coun-
tries by devices.
TABLE III: Top 15 device
vendors by devices.
apps installed on 12M Android devices, as well as parent-child
install relationships among them. We query VirusTotal (VT)
to obtain AV labels for unwanted app classiﬁcation and APK
metadata such as permissions and certiﬁcate info.
Reputation logs. These logs capture metadata about
the
presence of apps in 12M Android devices. The dataset does
not include the actual apps, but only their metadata. These
logs are collected from real devices in use by customers of
the security vendor. The customers opted-in to sharing their
data and the devices are anonymized to preserve the privacy
of the customers. The dataset covers four months that span
from June 1st, 2019 to September 30th, 2019.
The dataset contains devices in 243 country codes [3].
thus covering nearly all countries in the world, save a few
exceptions like North Korea. The top 15 countries by number
of devices are shown in Table II. These 15 countries cover
89% of the devices, but the distribution is long-tailed. The
dataset is skewed towards North America, Europe, and Japan
where the security vendor has a larger market share. Of the 20
largest countries by population we see that China, Indonesia,
Pakistan, Nigeria, and Bangladesh are underrepresented, but
we still have tens of thousands of devices in China and several
thousands in the rest.
The dataset includes devices from over 3K device vendors.
Table III shows the top 15 vendors by devices in the dataset.
Samsung is the dominant device vendor with over 40% of
the devices, followed by Xiaomi (8.6%) and Motorola (7.0%).
Again, the distribution is long-tailed with only 14 vendors
having more than 1% of the devices.
Each device in the dataset regularly queries a cloud-based
reputation system to obtain the reputation for the APKs
installed in the device. The query includes ﬁle metadata such
as APK hash, APK package name, the signer key (i.e., the
SHA256 of the public key in the APK’s certiﬁcate), and
optionally the name of the parent package that installed the
APK. The response includes a reputation score, which is one of
the inputs, but not the only one, used by the security vendor’s
AV engine to make a determination about an APK. Since the
reputation score is proprietary, we avoid using it to make our
approach replicable. We only use it to select samples with low
reputation to query to VirusTotal.
The AV client may query the same APK at different times.
To remove duplicated events, for each unique tuple of an
anonymized device identiﬁer, APK’s SHA256 hash, APK’s
package name, APK’s signer key, and APK’s parent package
name (potentially null), we obtain the earliest date when
the tuple was queried to the reputation system. The dataset
comprises of 2.3B such unique events with 34.6M APKs from
7.9M packages using 4.1M certiﬁcate chains.
The AV client queries Android’s Package Installer3 to obtain
the name of the parent package for each installed APK. If
the parent package is known, it is included in the query to
the reputation server. However, in some cases parent packages
might be unknown to the Package Installer. Some examples
are apps that come preinstalled on the device and sideloaded
apps installed via the Android Debug Bridge (ADB) and for
which the user did not provide an installer package name.
Of the 2.3B unique events in the dataset, 75% correspond
to installations (i.e., have a parent package different from
the child package), 24% correspond to updates (i.e., same
parent and child package), and 1% have no parent package
information. The 1.7B install events contain 5.4K parent
(installer) packages and 2.8M child packages.
The interplay between the AV engine and the reputation
log collection is as follows. The APK reputation is part of
the decision made by the AV client. APKs are queried to the
reputation server prior to making a determination. Thus, apps
ﬂagged by the AV client will appear in the reputation logs for
the device. Upon detection, if the app is classiﬁed as malware,
the AV client displays a large warning and asks for permission
to uninstall it. If classiﬁed as PUP, a notiﬁcation explains the
risks to the user and how to uninstall it.
VirusTotal. We query the hash of APKs in VirusTotal
(VT) [75], an online service that analyzes ﬁles and URLs
submitted by users using a large number of security tools.
VT offers a commercial API that given a ﬁle hash returns ﬁle
metadata and the list of detection labels assigned by a large
3Using the PackageInstaller.getInstallerPackageName method.
number of AV engines used to scan the ﬁle. Unfortunately,
given VT’s API restrictions, we could not query all 34.6M
APKs. We queried all parent APKs that performed at least one
installation (i.e., all installers), the 10 most prevalent APKs
for each signer, all the APKs with negative reputation, and
a subset of the APKs with positive reputation. This resulted
in VT reports for 4.6M APKs. We use the AV labels in the
VT reports as an input to our unwanted app identiﬁcation and
classiﬁcation. Since we only have VT reports for 13% of all
APKs, our unwanted app prevalence results is a lower bound.
We also use the VT reports to obtain APK metadata such as
certiﬁcate information, used to analyze APK ownership, and
permissions declared in the manifest, used to identify installers
that can perform silent
installations without user consent.
Having APK metadata for 13% of samples does not affect
our results because we only use the certiﬁcate information for
analysis of selected samples and permissions for installers. In
both cases, we have queried the necessary APKs.
Play market. We check if an app found in user devices is
available in Android’s ofﬁcial market by trying to download
its public webpage using the app’s package name. For apps
in the Play market, we obtain metadata such as its category.
We queried all 7.9M package names during February 2020. Of
those, 24% (1.9M) were present at that time in the Play market.
More may have been available in the past, but have since
been removed [76]. The rest may be distributed only through
alternative distribution vectors, or may come pre-installed.
IV. APPROACH
This section ﬁrst describes data challenges we had to
overcome and then explains how we identiﬁed platform keys
and categorized installers.
Obtaining parent information. The reputation logs contain
the package name of the parent APK, but not the parent APK’s
hash or public key. This is problematic because benign apps
could be impersonated by unwanted apps, misleading us into
assigning unwanted installs to benign installers. To avoid this,
for each install event, we scan all reputation queries from that
device during the 4 months, extracting those that queried an
APK whose package name corresponds to the parent in the
install event (i.e., the parent we look for appears as child). If
such reputation queries exist, we sort them by decreasing time
difference from the install event and assign the APK’s hash
and public key from the closest event as the parent .
We apply this procedure on the 1.7B install events in the
reputation logs (Full column in Table I), recovering parent
information for 24% (412.6M) of the install events. This 24%
subset of install events covers 78% (4.2 K) of the installer
packages and 57% of the child packages in the full install
events, as summarized in column Subset in Table I. Recovery
failures are likely due to each APK being assigned a time-
to-live (TTL) indicating when to re-query its reputation. For
APKs positively benign, the TTL may be large enough so
that the install event happens before our study period and the
device never re-queries (or leaves the dataset before). Thus, the
24% install events may be skewed towards unwanted installers,
which may bias VDR absolute numbers. We avoid this bias by
computing the relative VDR and by conﬁrming results do not
signiﬁcantly change when computed on all 1.7B install events.
We use the Full dataset of 34.6 M APKs installed on 12M
devices to analyze unwanted app encounters in Section V. We
use the Subset of 24% install events to analyze distribution
vectors in Section VI.
Identifying platform keys. To identify platform keys in the
reputation logs we ﬁrst obtain from the AOSP repository a
list of 65 package names that are part of the Android OS.
Then, we search for keys in the reputation logs that satisfy the
following properties: signs com.android.phone (a core Android
package) and signs at least ten AOSP packages. Third, for
each of those candidate keys we identify the top 10 packages
signed by the key. If at least half of those packages are present
in the list of 65 AOSP packages we keep the key, otherwise
we remove it. Finally, we examine the certiﬁcate information.
If the subject DN mentions a speciﬁc vendor, and we are
able to ﬁnd a webpage for the vendor, we keep the key.
Otherwise we remove it. For 10% of the examined keys we
could not identify a vendor due to a generic Subject DN. This
veriﬁcation is manual, so we restrict it to keys that appear in
more than 1K devices. However, thanks to this veriﬁcation, we
are conﬁdent that the resulting keys are platform keys. Using
this procedure, we identiﬁed 201 platform keys belonging to
80 device vendors or OS publishers. The highest number of
platform keys is 57 for Motorola that uses separate keys for
different devices. Those 201 platform keys appear in over 6M
(50%) devices. Thus, when we say a key is a platform key we
are conﬁdent about it, but we may miss that some keys (e.g.,
for less prevalent vendors) are indeed platform keys.
Installer categorization. To analyze how apps are distributed
to the devices, we manually classify the installers into 12 cate-
gories that correspond to distribution vectors: the ofﬁcial Play
market, alternative markets, browsers, commercial PPI, backup
and restore, IM, theme stores, ﬁle managers, ﬁle sharing apps.
bloatware, mobile device management (MDM), and package
installers. Bloatware [51] corresponds to apps signed by a
device vendor or a carrier with unclear functionality, i.e., they
do not belong to any of the other categories. Bloatware typi-
cally comes pre-installed, although it could be installed later as
well. MDM apps enable the administration of corporate mobile
devices, e.g., ensuring corporate apps are installed and the cor-
porate security policy is conﬁgured. Package installers are apps
that enable installing APKs. They include implementations
of Android’s Package Installer module (e.g., com.android.
packageinstaller, com.google.android.packageinstaller, com.
samsung.android.packageinstaller) as well
third-party APK
installers (e.g., com.apkinstaller.ApkInstaller, com.aefyr.sai).
We also add an Other category that comprises of apps that we
can classify but do not correspond to any of the 12 expected
distribution vectors such as games, video players, and news.
Unwanted Apps
2.2 M (18.3%)
3.0 M (8.6%)
Value
Malware
Devices
1.4 M (11.2%)
APKs
1.2 M (3.4%)
TABLE IV: Unwanted app prevalence at selected t=4.
PUP
1.3 M (11.1%)
1.8 M (5.1%)
A. Unwanted App Prevalence
We measure the prevalence of unwanted apps on user
devices, i.e., the fraction of user devices that had an unwanted
app encounter throughout the four months analysis period.
For this, we ﬁrst identify unwanted apps installed on user
devices. Then, we measure their prevalence across the 12M
user devices. A common practice to identify unwanted apps
is to collect their AV detection labels using VT and consider
any ﬁle ﬂagged (i.e., assigned a non-empty label) by at least
a threshold number of AV engines [84]. A higher threshold
reduces false positives due to a few AV engines making an
incorrect determination, but may increase false negatives. As
explained in Section III, we could not query all 34.6M APKs
due to VT API restrictions, but were able to collect VT reports
for 13% (4.6M) of all APKs. Figure 1 shows the number of
unwanted APKs in our dataset depending on the selected VT
≥ t threshold. The number of unwanted APKs decreases as
the threshold increases.
We use the set of unwanted APKs obtained at each threshold
value to compute the device prevalence, i.e., the fraction of
devices where those unwanted APKs were installed. Threshold
selection varies among different works [84]. Thus, we provide
the prevalence at all threshold values in Figure 2. The preva-
lence quickly decreases from t=1 to t=3, and then at around
one percentage point per step increase until t=19. Recent work
has shown that threshold values between two and 14 are good
for stability and for balancing precision and recall [84]. Thus,
the unwanted app prevalence in our dataset ranges between
24.3% (t=2) and 10.0% (t=14).
For the rest of the paper we need to set a threshold value, so
that the set of unwanted APKs is ﬁxed. We select t=4 as our
threshold. This value falls in the range recommended in [84]
and has been used in closely related works (e.g., [45], [47]).
Using this threshold, there are 3.0M unwanted APKs and the
prevalence is 18.3%, as summarized in Table IV. Clearly, this
estimate is very conservative as it considers benign all APKs
that were not queried to VT, or were not found in VT, or
were ﬂagged by less than four AV products. We believe this
is a lower bound for prevalence. Among the devices with at
least one unwanted app encounter at t=4, the median is 2.0
unwanted apps per device (avg=5.0, std=1497.0). Figure 3 in
the Appendix details the distribution.
Table IV also provides the split between malware and PUP
APKs, according to the AVClass malware labeling tool [63]
(see Section V-C). It shows that 60% of the unwanted APKs at
t=4 are considered PUP and 40% malware. However, malware
prevalence (11.2% of all 12M devices) is almost the same
as PUP prevalence (11.1%), indicating the presence of some
high prevalence malware. The devices typically encounter only
malware or PUP, but 490K devices encounter both types.
Fig. 1: Unwanted APKs per VT detection threshold.
Fig. 2: Unwanted app prevalence per VT detection threshold.
For installers available in the Play market we leverage their
app description since market categories are too coarse-grained.
However, only 12% of the installers were in the Play market
when we queried them in February 2020. For the rest, we need
to examine sources such as alternative markets, results from
Web searches, and forums. This process is quite challenging
for the long tail of less popular installers. Overall, out of the
4.2K installers, only 665 install at least one unwanted app. We
focus on those and are able to classify 622 (95%). Those 662
include the most prevalent installers so we classify 96.3% of
the 412.6M install events. The largest category is alternative
markets with over one hundred installers. The results of the
categorization are detailed in Section VI-A.
V. UNWANTED APP ENCOUNTERS
This section reports on unwanted app encounters that af-
fected the 12M devices in the full reputation logs. Section V-A
measures the prevalence of unwanted apps on the user devices.