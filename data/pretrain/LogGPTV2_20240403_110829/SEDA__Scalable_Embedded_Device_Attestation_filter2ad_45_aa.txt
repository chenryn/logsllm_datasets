# SEDA: Scalable Embedded Device Attestation

## Authors
N. Asokan<sup>1</sup>, Ferdinand Brasser<sup>2</sup>, Ahmad Ibrahim<sup>2</sup>, Ahmad-Reza Sadeghi<sup>2</sup>,  
Matthias Schunter<sup>3</sup>, Gene Tsudik<sup>4</sup>, and Christian Wachsmann<sup>2</sup>

<sup>1</sup>Aalto University and University of Helsinki, Espoo and Helsinki, Finland  
<sup>2</sup>Technische Universität Darmstadt, Germany  
<sup>3</sup>Intel Labs, Portland, OR, U.S.A.  
<sup>4</sup>University of California, Irvine, CA, U.S.A.  

Contact: {ferdinand.brasser, ahmad.ibrahim, ahmad.sadeghi, christian.wachsmann}@trust.cased.de,  
PI:EMAIL, PI:EMAIL, PI:EMAIL

## Abstract
Today, large numbers of interconnected smart devices provide critical safety and security services for energy grids, industrial control systems, gas and oil search robots, home/office automation, transportation, and critical infrastructure. These devices often operate in swarms—large, dynamic, and self-organizing networks. Ensuring the correct and safe operation of these device swarms, as well as protecting them against attacks, requires the verification of software integrity. However, current attestation schemes are designed for single devices and do not scale to swarms.

We present SEDA, the first attestation scheme for device swarms. We introduce a formal security model for swarm attestation and demonstrate the security of our approach within this model. We also provide two proof-of-concept implementations based on recent (remote) attestation architectures for embedded systems, including an Intel research platform. Our performance evaluation, based on these implementations and simulations of large swarms, shows that SEDA can efficiently attest swarms with both dynamic and static topologies, common in automotive, avionic, industrial control, and critical infrastructure settings.

## Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection

## Keywords
Remote attestation, device swarms, security

## 1. Introduction
Current and emerging industrial trends envision systems consisting of large numbers of heterogeneous embedded and mobile devices, forming the so-called Internet of Things (IoT). Analysts predict billions of connected devices that will enable many new services and experiences. Examples include:

1. Industrial control systems, where large numbers of connected, autonomously operating devices collaborate to monitor and control safety-critical processes (e.g., smart factories).
2. Connected IoT devices in smart environments (e.g., smart homes and buildings).
3. Self-organizing dynamic networks, where multiple devices form collectively intelligent systems (e.g., robots used for oil and gas exploration).

Inspired by nature, such systems are often referred to as device swarms. To ensure their correct operation, it is crucial to maintain their software integrity and protect them against attacks. For instance, large-scale industrial control systems or robot swarms are vulnerable to a wide range of attacks. Verifying the correct and safe operation of these systems requires an efficient mechanism to collectively verify the software integrity of all devices to detect software modifications. However, naive applications of remote attestation do not scale to these systems. In particular, device swarms with dynamic topologies, such as vehicular ad-hoc networks, robot swarms, and sensors in fluid environments, require novel and flexible solutions.

Many approaches to remote attestation have been proposed. Common to all of them is that the entity (device) to be attested, called the prover, sends a status report of its current software configuration to another party, called the verifier, to demonstrate that it is in a known and trustworthy state. All existing attestation techniques consider only a single prover and verifier. Since malicious software on the prover could forge this report, its authenticity is typically assured by secure hardware and/or trusted software. Attestation based on secure hardware is most suitable for advanced computing platforms, such as smartphones, tablets, laptops, personal computers, and servers. However, underlying security hardware is often too complex and/or expensive for low-end embedded systems. In contrast, software-based attestation requires neither secure hardware nor cryptographic secrets but relies on strong assumptions, such as the adversary being passive during the attestation protocol execution and the optimality of the attestation algorithm and its implementation. Such assumptions are hard to achieve in practice and restrict the applicability of software-based attestation to the one-hop setting. Hence, a secure and practical remote attestation scheme requires minimal security features in hardware, such as read-only memory (ROM) and memory isolation (e.g., memory protection unit).

Consequently, designing efficient and secure attestation for device swarms poses several challenges. In particular, in swarms with dynamic topology, attestation needs to be combined with key management, network discovery, and routing in a secure and efficient way. It is important to ensure that compromised devices cannot evade detection during attestation and that honest devices are not double-counted. Furthermore, computation and communication costs for the verifier and (possibly many) provers should be minimized. This requires a cumulative and efficient attestation scheme that cannot be instantiated by trivial combinations of existing attestation protocols. Moreover, a swarm attestation protocol should ideally distribute its burden—including computation, communication, and energy costs—over all devices in the swarm.

### Contributions:
- **First Swarm Attestation Scheme:** We design SEDA, Scalable Embedded Device Attestation, which, to the best of our knowledge, is the first attestation scheme for large-scale swarms. SEDA represents the first step in a new line of research on multi-device attestation. Although SEDA adheres to the common assumption—made in most (single-prover) attestation techniques—of ruling out physical attacks on devices, we discuss mitigation techniques for such attacks in Section 9.
- **Security Model & Analysis:** We present the first security model for swarm attestation and demonstrate the security of SEDA in this model.
- **Two Working Prototypes:** We describe two concrete instantiations of SEDA based on state-of-the-art security architectures for low-end embedded systems: SMART [16] and TrustLite [25], the latter based on an Intel research platform [44]. They demonstrate the feasibility of SEDA on swarms of low-end embedded devices with minimal hardware security features.
- **Performance Analysis:** We assess the performance of two SEDA instantiations and present simulation results for swarms with up to 1,000,000 devices, thus demonstrating SEDA’s scalability. Our results clearly indicate that SEDA performs significantly better than individually attesting each device separately.

### Outline:
- **Section 2:** Overview of swarm attestation and our notation.
- **Section 3:** Detailed description of the SEDA protocol.
- **Section 4:** Two implementations of SEDA.
- **Section 5:** Performance results.
- **Section 6:** Security analysis of SEDA.
- **Section 7:** Discussion of several extensions.
- **Section 8:** Revisiting the question of physical attacks.
- **Section 9:** Summary of related work.

## 2. Swarm Attestation

### 2.1 Problem Description and System Model
A swarm \( S \) is a set of \( s \) devices with possibly different hardware and software configurations, as shown in Figure 1. Devices are initialized and deployed by a swarm operator \( OP \) in a trusted manner. Table 1 summarizes our notation.

The goal of swarm attestation is to assure a verifier \( VRF \), which may be different from \( OP \), of the overall software integrity of \( S \) or the lack thereof. \( VRF \) may be a remote entity. An important property of swarms is that each device can communicate only with its direct neighbors. \( S \) might be dynamic in terms of both topology and membership. Device mobility might be voluntary (i.e., self-locomotion) or involuntary (i.e., guided by ambient factors). Hence, the current topology of \( S \) may be unknown to \( OP \) and \( VRF \).

The main idea is that \( S \) is trustworthy if all of its devices have been deployed by \( OP \) and are running a software configuration certified by \( OP \). SEDA focuses on swarm attestation and leaves policies to \( VRF \). It guarantees that \( VRF \) reliably learns the total number of participating and correctly operating devices. Note that devices not responding to protocol messages cannot be successfully attested and are considered compromised. When determining the swarm's current state, the distinction between compromised and unreachable devices can be ignored, as, in each case, the device is not functioning correctly.

### 2.2 Requirements Analysis

#### Objectives
A secure swarm attestation scheme must have the following properties:
1. **Property (1):** Support the ability to remotely verify the integrity of \( S \) as a whole.
2. **Property (2):** Be more efficient than individually attesting each device \( D_i \) in \( S \).
3. **Property (3):** Not require \( VRF \) to know the detailed configuration of \( S \) (e.g., the type and software version of devices and network topology).
4. **Property (4):** Support multiple parallel or overlapping attestation protocol instances.
5. **Property (5):** Be independent of the underlying integrity measurement mechanism used by devices in \( S \).

**Property (1)** is the core objective of swarm attestation. **Property (2)** is essential for scalability in large swarms. **Property (3)** simplifies attestation and is needed if system configuration must not be disclosed to \( VRF \). For example, in smart factories, maintenance may be outsourced, and maintenance staff may need to check the overall trustworthiness of the production system while the exact setup remains secret. **Property (4)** is relevant to applications where multiple verifiers need to independently verify system integrity without coordination. **Property (5)** is needed for extensibility, to support a wide range of single-device attestation mechanisms and to adapt to future attestation schemes, e.g., those that allow detection of code-reuse attacks.

#### Adversary Model
As common in the attestation literature, we consider software-only attacks. This means that, although the adversary, denoted as \( ADV \), can manipulate the software of (i.e., compromise) any device \( D \) in \( S \), it cannot physically tamper with any device. However, \( ADV \) can eavesdrop on and manipulate all messages between devices and between devices and \( VRF \). Furthermore, we rule out denial-of-service (DoS) attacks since \( ADV \) typically aims to remain stealthy and undetected while falsifying the attestation result for \( VRF \). This is also in line with our primary goal of detecting device compromise that occurs via remote malware infestations.

Nevertheless, we sketch out several approaches for mitigating physical attacks in Section 9 and address DoS attack mitigation techniques in Section 7.

#### Device Requirements
To satisfy properties (1), (2), and (3), a secure swarm attestation scheme should be able to remotely verify the integrity of each \( D \) and aggregate the results. These impose the following requirements on each device \( D \):
- **Integrity Measurement:** It must be infeasible for \( ADV \) to tamper with the mechanism that attests the integrity of \( D \)'s software.
- **Integrity Reporting:** It must be infeasible for \( ADV \) to forge the integrity measurement report sent from \( D \) to \( VRF \).
- **Secure Storage:** It must be infeasible for \( ADV \) to access any cryptographic secrets used by \( D \) as part of attestation.

In Section 5, we demonstrate the viability of SEDA implemented on top of two recent attestation architectures that satisfy the above requirements with minimal hardware support: SMART [16] and TrustLite [25].

#### Assumptions
Following recent literature on attestation of low-end embedded systems, we assume that each \( D \) in \( S \) satisfies minimal requirements for secure remote attestation, as discussed above. Furthermore, following swarm robotics literature, we assume that \( D \) can communicate with all its neighboring devices in \( S \), and that the network is connected, i.e., each \( D \) is reachable, at least while the attestation protocol executes. We consider all underlying cryptographic primitives and their implementations to be secure. We also assume that \( OP \) is trusted. Finally, we assume that the swarm topology remains static for the duration of a given attestation protocol instance. This does not preclude "herd mobility" (entire swarm moving as a whole) or micro-mobility (devices move while retaining overall topology). Topology can change between attestation protocol instances. In Section 8, we discuss how SEDA can be modified to allow mobility of devices even during attestation.

## 3. Preliminaries and Notation
Let \( |M| \) denote the number of elements in a finite set \( M \). If \( n \) is an integer (or a bit-string), \( |n| \) means the bit-length of \( n \). Let \( m \xleftarrow{\$} M \) denote the assignment of a uniformly sampled element of \( M \) to variable \( m \). Furthermore, let \( \{0, 1\}^\ell \) be the set of all bit-strings of length \( \ell \).

If \( E \) is some event (e.g., the result of a security experiment), then \( \Pr[E] \) denotes the probability that \( E \) occurs. Probability \( \epsilon(\ell) \) is called negligible if, for all polynomials \( f \), \( \epsilon(\ell) < \frac{1}{f(\ell)} \) for sufficiently large \( \ell \).