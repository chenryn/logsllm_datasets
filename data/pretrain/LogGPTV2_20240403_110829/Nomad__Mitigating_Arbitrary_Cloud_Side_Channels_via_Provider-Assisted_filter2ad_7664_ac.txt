and periodically re-balances the placement of client VMs across
its provisioned hardware. The period (i.e., duration of an epoch,
D) and conﬁguration parameters such as ∆ determine the security
implications of our system and should be adjusted based on the
state-of-the-art side-channel attacks.
Security implications of Nomad: Having presented the overview
of Nomad, we now explain the security semantics and implications
of the system.
The security implications depend on three parameters: 1) K ,
leakage rate; 2) ∆, number of epochs in a sliding window; and 3)
D, epoch duration. Note that D and ∆ are conﬁgured by providers
and K summarizes the capability of the side channels.
In essence, Nomad is resilient against any side channel where
K × ∆ × D ≤ P where P is the Min(time to refresh the secret,
Placement AlgorithmService APINon-movable VMsVM PlacementsArrivals & DeparturesSliding WindowMigration BudgetClient APIVM Assignments & WorkloadsConfig.Migration EngineSet of MovesDeployment ModelAlgorithm 1 Baseline Greedy Algorithm
1: function GREEDYALGORITHM(CurPlace, Budget, Typesof-
Moves)
2:
3:
4:
5:
6:
NumMig = 0, ChosenMove={}
MoveSet = InitializeMoves(TypesofMoves,CurPlace)
while NumMig ≤ Budget do
(cid:46) Return a set of (cid:104)move,cost(cid:105)
MoveBeneﬁts=
InfoLeakReduction(MoveSet, curPlace,clientConstraints)
(cid:46) Return a set of (cid:104)move,cost,beneﬁt(cid:105)
move = PickBestMove(MoveBeneﬁts)
ChosenMove.insert(move)
NumMig += move.cost()
CurPlace = UpdatePlacement(CurPlace,move)
MoveSet = UpdateMoves(MoveSet,move)
7:
8:
9:
10:
11:
12:
13:
14:
15: end function
end while
Return ChosenMove
need to solve and then highlight the scaling limitations of strawman
solutions. Then, we present the main ideas underlying the Nomad
approach that enable a scalable realization.
5.1 Problem Formulation
We begin by describing the abstract problem that the Placement Al-
gorithm needs to solve to provide the context for why this problem
is intractable in practice.
The Placement Algorithm needs to compute the VM placements
every epoch with the goal of minimizing the information leakage
between arbitrary pairs of cloud clients, while ensuring that the
overall cost of doing so (i.e., number of migrations) is low. Specif-
ically, we want to minimize the total information leakage func-
tion subject to some budget on the migration overhead measured
in terms of total number of migrations. We acknowledge that there
are other ways to capture the trade-off between migration overhead
vs. information leakage.
Meeting the security concern should not come at the cost of scal-
ability. Our problem target size (i.e., large public cloud deploy-
ment) is tens of thousands of servers with roughly 4-5 VM slots
per server.3 We envision the Nomad Placement Algorithm running
at the beginning of each epoch, with each epoch lasting several
minutes up to tens of minutes. A reasonable target to compute the
placement assignments for one epoch would be roughly under 1
min. The choice of 1 min for the computation time allows epoch
duration to be as small as few minutes (§4).
Since the cloud provider cannot predict the VM arrivals and de-
partures into the future, we consider a myopic formulation that de-
termines placement for the next epoch given the historical place-
ments over the previous few epochs. We can model this placement
problem subject to migration budget constraints as an integer lin-
ear program (ILP). For completeness, we present the full ILP in
Appendix A. Unfortunately, solving this ILP is intractable and it
takes more than a day to even solve a small problem instance with
just 40 machines (Table 1 in §8). Thus, while the ILP approach is
an exact optimal solution in terms of the leakage subject to ﬁxed
migration budget, it is far from viable in terms of the scalability
requirements. This motivates the need for heuristic approximations
as we describe next.
3While public numbers are hard to get, tens of thousands of servers
seems roughly in the ball park of public deployment instances.
5.2 Baseline Greedy
Given that we are solving a budgeted optimization problem, we re-
sort to a natural greedy algorithm. Algorithm 1 shows our baseline
greedy algorithm.
In the baseline greedy design, we enumerate a set of moves in-
volving VMs. For instance, we can consider all possible n-way
swaps between VMs or consider pair-wise swaps (i.e., Typesof-
Moves = {free-insert, pair-wise swap, . . . , n-way swaps})
Each move has both a cost incurred in terms of number of migra-
tions required to execute the move and the beneﬁt it yields in terms
of the reduction in information leakage. Then, in each iteration
of the greedy algorithm, we pick the best move (Line 8 in Algo-
rithm 1) within the migration budget that gives us the maximum
beneﬁt in terms of reduction in information leakage.
Note that each move conceptually changes the state of the system
and thus the beneﬁt of future moves may decrease or increase de-
pending on the moves we have already made; e.g., moving VM c,i
may mean that all previously considered swaps involving this in-
stance may no longer provide any value. Thus, we explicitly re-
compute the set of allowed moves and the beneﬁt that they yield
(Line 6 and 12 in Algorithm 1).
Unfortunately, even using this greedy algorithm instead of the
ILP solver does not provide the desired scalability; e.g., even run-
ning this on a small 50 node cluster does not meet our 1 min goal.
5.3 Scalable Greedy Algorithm
Next, we describe key ideas of our scalable greedy algorithm to im-
prove scalability. Using a careful run-time analysis, we identiﬁed
three key bottlenecks in this baseline greedy algorithm:
1. Calculating the beneﬁt of each move (Line 6): Recomputing
beneﬁt is computationally expensive as the InfoLeakage across
all VM pairs and client pairs have to be computed.
2. Large search space (Line 3): A large search space results from
having many machines and many types of moves (i.e., free-
inserting a VM into an empty slot, pair-wise swaps, etc.,).
3. Updating move after each state change (Line 12): Updating
move sets requires generating all possible moves which leads
to a large input size for the beneﬁt computation (Line 6).
Incremental beneﬁt computation: Recomputing the beneﬁt (Line
6 in Algorithm 1) is a large contributor to high run time of the
baseline greedy. Thus, we use an incremental beneﬁt computa-
tion which computes the delta in the current value of the objective
function by only updating information leakage for set of dependent
client pairs whose InfoLeakage are affected by the move. This elim-
inates the need to compute the entire co-residency pairs across all
VMs when 1) a potential move has been tried to evaluate the beneﬁt
of a move or 2) a move is made.
However, to enable the use of this approach, we need to make
approximations to non-(cid:104)R, C(cid:105) InfoLeakage models which consist
of Max operations. Finding the delta with Max operation requires
the algorithm to iterate over all other inputs to the Max . This is in
contrast to the Sum whose delta only depends on one input’s value
before and after an update. Therefore, we introduce the concept
of “Soft-Max” for (cid:104)NR, NC(cid:105), (cid:104)NR, C(cid:105), and (cid:104)R, NC(cid:105) models to
beneﬁt from the scalability gain by using an incremental beneﬁt
computation as shown below.
1. (cid:104)NR, NC(cid:105):
InfoLeak
(cid:104)NR,NC(cid:105)
c→c(cid:48)
(t, ∆) ≈ eα∗InfoLeak c,i→c(cid:48) ,i(cid:48) (t,∆), α > 0
(6)
2. (cid:104)NR, C(cid:105):
InfoLeak
3. (cid:104)R, NC(cid:105):
α∗(cid:80)
i(cid:48) InfoLeak c,i→c(cid:48) ,i(cid:48) (t,∆)
(t, ∆) ≈ e
(cid:104)NR,C(cid:105)
c→c(cid:48)
, α > 0
(7)
α∗(cid:80)
(cid:104)R,NC(cid:105)
c→c(cid:48)
(t, ∆) ≈ e
InfoLeak c,i→c(cid:48) ,i(cid:48) (t,∆)
i
InfoLeak
, α > 0
(8)
The intuition behind “Soft-Max” is that an exponential function is
a good approximation of the Max operation as the function gives
more weights to larger values. Suppose we consider a sliding win-
dow ∆ of size 5. Then, for the (cid:104)NR, NC(cid:105) model, the inputs to
InfoLeak c,i→c(cid:48),i(cid:48) (t, ∆) ranges from 0 to 5. Using Equation 6 (for
α = 0.8), the values [0, 1, 2, 3, 4, 5] would map to [0, 2.23, 4.95,
11.02, 24.53, 54.60]. Our scalable greedy algorithm then will nat-
urally see the most beneﬁt in reducing the larger co-residency val-
ues; reducing InfoLeak c,i→c(cid:48),i(cid:48) (t, ∆) from 5 to 4 gives a larger In-
foLeakage reduction than reducing InfoLeak c,i→c(cid:48),i(cid:48) (t, ∆) from 4
to 3.
Search space: We present two key ideas to tackle two causes
(many types of moves and many machines) for a large search space
(Line 3 in Algorithm 1).
1. Hierarchical placement: The high-level idea is to group ma-
chines into clusters (with each cluster consisting of approxi-
mately 1,500 machines) and each client assigned to a cluster.
This design choice builds on the following insight. A move can
only affect clients whose VMs reside in the affected machines.
Suppose a move involves moving a VM c,i from machine 1 to
machine 2. Then, the only InfoLeakage client pairs affected
are clients whose VMs reside in machine 1 and 2 (i.e., only the
co-residency between VM c,i and VMs in machine 1 and 2 are
affected by this move). Therefore, we consider it inefﬁcient to
try the moves across all machines when the number of affected
co-residency pair is bounded.
2. Pruning the move sets: We could potentially consider a move
from a free-insert up to n-way swaps where n is the number of
VMs. However, we limit the types of moves to a free-insert
and pair-wise swaps. Our evaluation on the effect of pruning
the move sets shows signiﬁcant gain in scalability with little-
to-no loss optimality (Figure 6 in §8).
2
Lazy evaluation: Third, we identiﬁed that the need to recom-
pute the move sets after each move affects scalability (Line 12 in
Algorithm 1). Consider a 1,500 machine per cluster with 4 VM
slots per machine with an expected occupancy rate of 50% (i.e.,
3,000 VMs). Entire move sets then would contain approximately
(cid:1) entries. Therefore, recomputing the entire
3, 000× 1, 500 +(cid:0)3000
move set is inefﬁcient when only a few are affected. To tackle this,
we use lazy evaluation [24]. First, we populate the entire move ta-
ble at the beginning of an epoch. Second, the algorithm traverses
the move set starting from the move that gives the most beneﬁt. If
the claimed beneﬁt from the time that beneﬁt was computed lies
within 95% of the current beneﬁt and a move is feasible, then that
move is made. If not, the move is re-inserted with an updated ben-
eﬁt. We show that lazy evaluation brings little-to-no loss in opti-
mality even for a cluster size of 50 (§8). Note that as a side effect
of providing a client-agnostic defense and considering global co-
residency across all client-pairs, Nomad can utilize the same algo-
rithm for (cid:104)R, NC(cid:105) and (cid:104)NR, C(cid:105).
Dealing with heterogeneous resource constraints: In a real cloud
setting, servers are not identical and the resource requirements of
each VM may also vary. In our design of the algorithm, we have
abstracted the server resource constraints as VM slots but this can
easily be extended to consider heterogeneous VM resource require-
ments and server constraints (i.e., vCPU, RAM, Disk, etc.) Re-
source constraints are handled in the Nomad Placement Algorithm
when the scheduler looks for free VM slots. For clarity, we evalu-
ated the algorithm using a homogeneous server conﬁguration (Fig-
ure 6 in §8).
6 Security Analysis
In this section, we describe how Nomad deals with strategic adver-
saries and the potential threats that could arise with the deployment
of Nomad.
Strategic adversary: By construction, Nomad defends against
legacy side-channel adversaries. Here, we focus on strategies of
advanced adversaries who are aware of the Nomad’s algorithms.
Speciﬁcally, we identify three possible attack vectors to obtain high
information leakage in spite of Nomad: (1) launch many VMs; (2)
exploit the non-migration constraints of the client-facing API; and
(3) induce a lot of churn. Here, we qualitatively analyze these sce-
narios and defer quantitative results to §8. For brevity, we only
discuss the (cid:104)R, C(cid:105) model since that has the highest possible leak-
age surface (i.e., it subsumes other models) and argue why Nomad
either renders these vectors ineffective or induces high costs for the
adversary.
• Launch many VMs: An adversarial client can launch a large
number of long-lasting VMs hoping to be co-resident with tar-
get clients. First, we observe that this comes at a high cost for
the adversary; e.g., public clouds such as Amazon EC2 which
charges based on CPU hours [1]. Moreover, Nomad’s goal of
minimizing InfoLeakage will naturally tend to localize VMs of
clients with many VMs (even without explicitly identifying the
adversary client).
• Exploit non-migration constraints of the Client API (§4): To
help legitimate applications with strong dependencies on bot-
tleneck VMs, Nomad’s Client API allows a client to specify
non-migration constraints. An adversary may try to exploit
this feature and request a large percentage of its workloads to
fall under non-migration constraints to avoid the eventual clus-
tering mentioned above. Note that this is a serious threat as
this is legitimate behavior allowed by the API and thus is non-
detectable. Second, an adversary incurs no additional cost in
specifying non-migration constraints. We observe, however,
that Nomad is resilient to this strategy. For “non-movable”
instances, Nomad runs the Placement Algorithm to determine
the initial placement of VM to cause minimal increase to the
overall InfoLeakage. The algorithm will then naturally localize
“non-movable” VMs of a speciﬁc client upon “non-movable”
instances’ arrivals.
• Frequent churn: An adversary can induce frequent churn with
VMs arrival/departure. This can exhaust the migration bud-
get of the Placement Algorithm and poses a higher threat than
statically launching the same number of VMs, as it does not
give Nomad Placement Algorithm enough epochs to localize
the adversary VMs. Suppose that such anomalous behavior is
detectable. Then, after the detection, the cloud provider can
dedicate a set of machines which are assigned to the particular
client creating frequent churn. Note that this will not impact le-
gitimate clients who may also exhibit high churn (even though
this is unlikely). However, designing algorithms for detecting
churn is outside the scope of this work and can be done via
well-known anomaly detection techniques [10].
Potential new threats: We acknowledge the potential new threats
that could arise with the deployment of Nomad.
• New side-channel threats: We acknowledge that deploying No-
mad may have indirect consequences that may strengthen some
side channels. For instance, with Nomad which incurs periodic