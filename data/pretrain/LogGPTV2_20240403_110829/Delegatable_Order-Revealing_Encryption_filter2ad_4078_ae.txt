to view the result — tables, plots, values and raw JSON,
which we used to build plots for this paper. Input size on
the website is limited for practical purposes and users are
encouraged to run arbitrary-size simulations using our bina-
ries or Docker images.
5.1
Implementation
We have implemented most of the primitives, data struc-
tures, and constructions ourselves. For some primitives and
all schemes we provided the ﬁrst open-sourced cross-platform
C# implementation. We note that neither primitives, nor
schemes are production-ready; however, we believe they can
be used in research projects and prototypes. We also em-
phasize that the B+ tree implementation we are using, al-
though our own with instrumentation in it, is not custom
in any way, but rather standard as deﬁned in the original
paper [3] with deletion algorithm by [33].
This software project (22K lines of code, third of which
are tests) is documented and tested (over 97% coverage). All
code including primitives, data structures, schemes, proto-
cols, simulation logic, benchmarks, build scripts and tests is
published on GitHub [6] under CC BY-NC 4.0 license. Ad-
ditionally, we have published parts of the project as stand-
alone .NET Core (nuGet) packages, and we host a web-
server where users can run simulations for small inputs (see
previous subsection).
5.1.1 Primitives
All schemes and protocols use the same primitives, most
of which we implemented ourselves. All primitives rely on
the default .NET Core AES implementation.
.NET Core
uses platform-speciﬁc implementation of AES, thus lever-
ages AES-NI CPU instruction. In our project all key sizes
are 128 bits, as is AES block size.
We implemented AES-based PRG, which uses AES in
CTR mode and caches unused entropy (as suggested in [30]).
For PRF, since we need only 128-bit inputs and outputs,
we used one application of AES [37, Proposition 3.27]. For
symmetric encryption we use AES with a random initializa-
tion vector in CBC mode [37, Section 3.6.2]. For hash we
use default .NET Core SHA2 implementation. For PRP, we
implemented unbalanced Feistel networks [59] for large in-
puts and Knuth shuﬄe [43] for small inputs. Please see the
README of project’s repository [6] for low-level details.
Schemes and protocols
5.1.2
We implemented schemes and protocols precisely as in the
original papers. When we found problems or improvements,
we described them in implementation challenges notes, but
did not alter the original designs in our code, unless ex-
plicitly stated. Each ORE scheme implements a C# inter-
face; thus our own implementation of B+ tree operates on
a generic ORE. For the no encryption baseline, we have
a stub implementation of the interface, which has identity
functions for encryption and decryption. It is important to
note that all schemes and protocols use exclusively our im-
plementations of primitives. Thus we rule out the possible
bias of one primitive implementation being faster than the
other.
(a) Schemes benchmark (time
(b) Primitives benchmark
in microseconds, log scale).
Lewi-Wu parameter is the
number of blocks.
(time in microseconds)
Figure 1: Benchmarks of the schemes and primitives
Simulations
5.1.3
We have four types of simulations.
Protocol simulation runs both protocol stages — construc-
tion and search — on supplied data for all protocols includ-
ing all schemes coupled with B+ tree. In this simulation we
measure the primitive usage, number of ORE scheme oper-
ations (when applies), communication volume and size, and
the number of I/O requests. We intentionally do not mea-
sure elapsed time, since it would be extremely inaccurate
in this setting — simulation and measurement routines take
substantial fraction of time.
Scheme simulation runs all ﬁve ORE schemes and tracks
only the primitive usage.
The scheme benchmark, however,
is designed to track
time. We use Benchmark.NET [54] to ensure that the re-
ported time is accurate. This tool handles issues like cold
/ warm start, elevating process’ priority, and performing
enough runs to draw statistically sound conclusions. This
benchmark reports elapsed time up to nanoseconds for all
four schemes (excluding CLOZ) and their variants.
Finally, primitive benchmark uses the same tool, but com-
pares the primitives. We use it to compare diﬀerent imple-
mentations of primitives (e.g. Feistel PRP vs pre-generated
permutation) and to approximate time consumption of the
schemes and protocols based on primitive usage.
5.2 Setup
For our simulations, we have used three datasets. Two
synthetic distributions, that are uniform (range is third of
data size) and normal (standard deviation is 0.1 of data
size). The real dataset is California public employees salaries
(“total pay and beneﬁts” column) [63]. Synthetic datasets
and subsets of the real dataset are generated pseudo-ran-
domly. Queries are generated uniformly at random with a
range as a percentage of data size.
5.3 Results
5.3.1 Primitive usage by schemes
In Table 4 we show the simulation-derived values of each
OPE and ORE scheme’s primitive usage. Each scheme is
given 1000 data points of each dataset. First, the scheme
encrypts each data point, then decrypts each ciphertext and
then performs ﬁve comparisons (all possible types) pairwise.
This micro-simulation is repeated 100 times. Resulting val-
ues for primitive usage are averaged for each scheme. State
and ciphertext sizes are calculated after each operation and
the values are averaged. Please note that the simulated val-
ues are consistent with the theoretical calculations.
5.3.2 Benchmarks of schemes and primitives
Using the Benchmark.NET tool [54], we have accurately
tracked the performance of the schemes and primitives run-
ning of diﬀerent parameters (see Figure 1). ORE schemes
benchmark setup is the same as in primitive usage simula-
tion 5.3.1. Primitives were given randomly generated byte
inputs and keys of diﬀerent sizes (e.g. PRP of 2 to 32 bits).
Benchmark.NET decides how many times to run the routine
to get statistically sound results. For example, large vari-
ance results in more runs. To improve the accuracy, each
run is compiled in release mode as a separate project and
runs in a separate process with the highest priority.
Please note the logarithmic scale of the schemes’ perfor-
mances. FH-OPE is fast since it does not perform CPU-
heavy operations and works in main memory. Lewi-Wu per-
formance degrades exponentially with the increase of block
size mainly due to exponential number of PRF executions
and the performance of PRP degrading exponentially. Note
also that Lewi-Wu comparison takes noticeable time due to
Hash primitive usage.
In the primitives benchmark, it is clear that most prim-
itives use AES under the hood. PRG and PRF take less
than AES because they do not include the initialization
vector generation needed for symmetric encryption. PRP
is implemented as a Knuth shuﬄe [43] and its complexity
is exponential in the input bit length. Input size of 2 bits
is shown on Figure 1. PRG does not discard the entropy
generated by AES cycle, so one AES cycle can supply four
32-bit integers. PRP generates the permutation table once
and does not regenerate it if the same key and number of
bits are supplied.
5.3.3 Protocols
In this experiment we have run each protocol with each
of the three datasets. Dataset sizes are 247000 (bounded
by California Employees dataset size) and the number of
queries is 1000. Queries are generated uniformly at random
with a ﬁxed range — 0.5% of data size. The cache size is
ﬁxed to 128 blocks, and the B+ tree branching factor as well
as block sizes for other protocols are set such that the page
size is 4 kilobytes. The values we are measuring are the
number of I/O operations, communication volume, and size
for both construction and query stages.
See Table 3 for the snapshot for particular distribution
(CA employees). Figure 2 shows all values we tracked for
BCLOCLWWLewi-Wu-16Lewi-Wu-8Lewi-Wu-4FH-OPE101102103104105EncryptionComparisonAESPRGPRFHashPRPHG Sampler0369121518212427(a) Construction stage number of I/O
(b) Construction stage communication
(c) Construction stage communication size
requests
volume (number of messages)
(bytes transferred)
(d) Queries stage number of I/O requests
(e) Queries stage communication volume
(f ) Queries stage communication size (bytes
(number of messages)
transferred, log scale)
Figure 2: Performance values for diﬀerent data distributions
all protocols and distributions. Values for ORE based pro-
tocols are averaged. Being “cold” in our simulations means
executing the ﬁrst query and being “warm” means the ﬁrst
query has been previously executed. This diﬀerence makes
sense only for POPE as its ﬁrst query incurs disproportion-
ately large overhead by design.
Note that all ORE based protocols behave the same except
when ciphertext size matters. Thus, since BCLO, CLWW
and FH-OPE have the same ciphertext size, they create B+
trees with the same page capacity and have the same num-
ber of I/Os for diﬀerent operations. Lewi-Wu and CLOZ
schemes have relatively large ciphertexts and thus induce
larger traﬃc (see Subﬁgure 2c) and smaller B+ tree branch-
ing factor resulting in greater number of I/O requests (see
Subﬁgure 2d). Kerschbaum protocol requires high number
of I/O requests during construction since it needs to insert
an element into the arbitrary place in an array and rotate
the data structure on a disk.
POPE suﬀers huge penalty on the ﬁrst query (see Sub-
ﬁgures 2d, 2e and 2f) since it reads and sends all blocks to
the client for sorting. POPE performance improves as more
queries are executed.
Logarithmic-BRC does not support interactive insertions
and thus its construction stage is not benchmarked. Oth-
erwise it is the most performant of all non-ORE protocols.
Note, however, that its performance depends on the result
size, not data size.
As expected, ORAM performs worse than the ORE-based
protocols, but its performance is in-line with the non-ORE
protocols.
It may seem that ORAM does especially bad
in construction communication (Subﬁgures 2e, 2f), but it is
only because POPE has a shortcut in construction. This
“debt” is being payed oﬀ during queries (Subﬁgure 2f).
Note that the values do not vary a lot among diﬀerent
data distributions except for I/O requests. I/O performance
depends on the result size for queries, and is therefore more
sensitive to data distribution.
Also note that using an ORE scheme with relatively small
ciphertext in B+ tree does not add any substantial I/O over-
head (see “No encryption”).
On Figure 4a it is clear that query performance does not
depend substantially on the query size, except for Loga-
rithmic-BRC, for which the relation is linear. Note that
Logarithmic-BRC with optimally conﬁgured pack extension
shows almost no growth. This is because for large ranges
BRC will return the higher nodes (keywords matching many
documents), which are optimally packed in I/O pages. As
query range doubles, higher nodes are involved increasing
the chance that requested keywords have their documents
packed.
Figure 3 shows Table 2 asymptotic values. The simulation
was run for uniform dataset of 247000 records (hundred per-
cent), 1000 queries, 0.5% query range and 128 blocks cache
size. Kerschbaum construction I/Os and cold POPE query
values grow linearly with inputs, while the other protocols
grow logarithmically, square-logarithmically, or do not grow.
Figure 4b shows how the performance of protocols ﬂuctu-
ates as queries are processed. Note that POPE and Loga-
rithmic-BRC ﬂuctuate the most (which is, in general, unde-
sirable), and POPE is the only protocol where cold versus
warm makes a diﬀerence.
482484486488490492494Uniform distributionNormal distributionCA public employees datasetNo encryptionBCLO, CLWW,FH-OPELewi-WuCLOZKerschbaumPOPE coldPOPE warmORAM04812162024283245607590105120135150Uniform distributionNormal distributionCA public employees datasetNo encryptionBCLO, CLWW,FH-OPELewi-WuCLOZKerschbaumPOPE coldPOPE warmORAM051015202530354045320360400440480520560600640680ORAM avg: 17482Uniform distributionNormal distributionCA public employees datasetNo encryptionBCLO, CLWW,FH-OPELewi-WuCLOZKerschbaumPOPE coldPOPE warmORAM0481216202428322505007501,0001,2501,5001,7502,0002,2502,500Uniform distributionNormal distributionCA public employees datasetNo encryptionBCLO, CLWW,FH-OPELewi-WuCLOZKerschbaumPOPE coldPOPE warmLogarithmicBRCORAM020406080100120140160180200490,500492,000493,500495,000496,500498,000499,500501,000502,500504,000Uniform distributionNormal distributionCA public employees datasetNo encryptionBCLO, CLWW,FH-OPELewi-WuCLOZKerschbaumPOPE coldPOPE warmLogarithmicBRCORAM0150300450600750900No encryptionBCLO, CLWW,FH-OPELewi-WuCLOZKerschbaumPOPE coldPOPE warmLogarithmicBRCORAM101102103104105106107Uniform distributionNormal distributionCA public employees dataset(a) Construction stage I/O requests
(b) Construction stage number of messages
(a) For diﬀerent query sizes
(c) Queries stage I/O requests
(d) Queries stage number of messages
(b) Over time (queries).
Figure 3: Protocol scalability
Figure 4: Number of I/O requests
6. REMARKS AND CONCLUSION
Having done theoretical and practical evaluations of the
protocols, we have found that primitive usage is a much bet-
ter performance measure than the plain time measurements.
When it comes to practical use, the observed time of a query
execution is a mix of a number of factors and I/O requests
can slow the system down dramatically.
ORE-based B+ tree protocol is provably I/O optimal and
can potentially be extended by using another data structure
with ORE. Its security/performance trade oﬀ is tunable by
choosing and parametrizing the underlying ORE scheme.
Each scheme we considered has its own unique advantages
and drawbacks. BCLO [8] is the least secure scheme in the
benchmark, but is stateless and produces numerical cipher-
texts, so it may be used in the databases without any modi-
ﬁcations. Frequency-hiding OPE [39] also has this property,
hides the frequency of the ciphertexts, but is stateful and re-
quires uniform input. Lewi-Wu [46] is easily customizable in
terms of tuning performance to security ratio, and it oﬀers
the security beneﬁts of left / right framework — particuarly
useful for B+ tree. CLWW [18] provides weaker security
guarantees but is the fastest scheme in the benchmark.
Kerschbaum protocol [41] oﬀers semantically secure ci-
phertexts, hiding the location of the smallest and largest of
them, and has a simple implementation. The protocol is
well-suited for bulk insertions and scales well.
POPE [58] oﬀers a “deferred” B+ tree implementation.
By deferring the sorting of its ciphertexts, POPE remains
more secure for the small number of queries. POPE has
the fastest insertion routine and does not reveal the order of
most of its ciphertexts. It will be more performant for the
systems where there are a lot more insertions than queries.
We would also recommend to “warm up” the structure to
avoid a substantial delay upon the ﬁrst query.
Logarithmic-BRC is a perfect choice for huge datasets
where query result size is limited. It is the only protocol with
substantial space overhead, but it oﬀers scalability and per-
fect (in a snapshot setting) security, and a carefully chosen
and conﬁgured SSE scheme ensures that I/O grows slowly
as a function of result size.
ORAM has shown the most interesting result. Its perfor-
mance is not only adequate, but also in-line with the other
even less secure protocols. With this empirical result, we
expect more interest in ORAM research, possibly discover-
ing tighter bounds, faster constructions and eﬃcient ways to
use the schemes. The performance of ORAM gives an upper
bound on the acceptable performance level of less secure (ac-