title:On Community-Oriented Internet Measurement
author:Mark Allman and
Lann Martin and
Michael Rabinovich and
Kenneth Atchinson
On Community-Oriented Internet Measurement
Mark Allman1, Lann Martin2, Michael Rabinovich2, and Kenneth Atchinson3
1 International Computer Science Institute
2 Case Western Reserve University
3 Baldwin-Wallace College
Abstract. In this paper we describe a new measurement framework that re-
searchers can use to abstract away some of the mundane logistic details that tend
to dog every measurement project. The measurement community has outlined
the need for better ways to gather assessments from a multitude of vantage points
and our system is designed to be an open community-oriented response to this
desire. While many previous efforts have approached this problem with heavy-
weight systems that ultimately ﬁzzle due to logistical issues (e.g., hosts breaking
and no money to replace them) we take the opposite approach and attempt to use
the lightest possible weight framework that allows researchers to get their work
done. In particular, we take the approach of designing a system without any sort of
central “core” component and therefore the system has no single point of failure.
In addition, our proposed system is community-oriented in that there is no central
control and we build just enough mechanism for the community to get their work
done and police the infrastructure. In addition, our proposed system works in an
open fashion such that results from the community’s infrastructure are immedi-
ately provided to the community through publicly available “live feeds”.
1 Introduction
The Internet has become a vastly complex and heterogeneous system that deﬁes simple
characterization or measurement. Researchers gain fundamental understanding from
detailed measurements spanning a wide variety of vantage points around the network. A
thriving sub-community of networking researchers has emerged that focuses on Internet
measurement and analysis. Arguably, this sub-community has greatly enhanced global
understanding of a wide variety of aspects of how networks work “in the wild” (e.g.,
operations of the routing system, better understanding of peer-to-peer transfers, how
various attacks operate, etc.). With this understanding come new and better techniques
for designing and deploying Internet technologies. Our goal is to both enhance this
sub-community’s ability to provide further understanding, as well as enhance the entire
community’s ability to assess the efﬁcacy of new ideas through live measurements.
The research community has clearly stated its need for more and better measurement
data. An NSF-sponsored workshop on “Community-Oriented Network Measurement
Infrastructure” brought together a set of measurement experts who noted a variety of
community needs [5]. Among the needs articulated were both the need to more easily
run large-scale Internet measurements and the need for datasets from a broad range of
networks. In this paper we provide an initial sketch of a system that addresses both of
these desires.
M. Claypool and S. Uhlig (Eds.): PAM 2008, LNCS 4979, pp. 112–121, 2008.
c(cid:2) Springer-Verlag Berlin Heidelberg 2008
On Community-Oriented Internet Measurement
113
Internet measurement studies often fall into one of two camps: (i) those that require
researchers to expend large amounts of time on a formidable amount of mundane lo-
gistical details in order to run their measurement tools and collect data from a variety
of locations and (ii) small-scale studies that only consider small pockets of the network
and therefore may not be indicative of large-scale behavior. Our goal is to provide a
community-based measurement framework to address some of the problems associated
with large-scale measurement. We intend to form a lightweight measurement platform
that maintains no dedicated infrastructure. Instead, it relies on using a distributed hash
table (DHT) (e.g., OpenDHT [9], an overlay substrate used by a variety of other ap-
plications) to handle all communication needs for a mesh of measurement hosts. We
will provide tools and libraries to aid in the communication tasks speciﬁcally required
to undertake Internet measurements (e.g., ﬁnd measurement points, form measurement
requests and collect results). Our over-arching goals are to ease the pain involved with
conducting large-scale measurement studies such that researchers can both (a) spend
more time focused on gaining insight about the network and how their new technolo-
gies work and less time on logistics and (b) have better access to large-scale infrastruc-
ture and data such that researcher will be incentivized to move away from small-scale
studies. The Internet has beneﬁted from community effort for a number of innovations.
Community members proved willing to contribute resources to projects of individual re-
search groups, such as seti@home, traceroute@home and DIMES. We expect that they
would be even more willing to take part in an effort that beneﬁts the entire community.
Abstracting the mundane details of measurement away from researchers should not
be taken as a small contribution. In fact, our experience is that much of the effort as-
sociated with large measurement studies is spent getting the mundane logistics right.
While we do not provide a framework to rid researchers of all the logistical headaches
of network measurement we provide a framework that takes care of a number of the
issues. With this in mind we sketch several aspects of our framework:
– The infrastructure can support a ﬂuid set of measurement points that are provided
and administered by the community. Unlike other efforts there is no central man-
agement required, making this system a truly community-oriented effort that is of
and for the network research community.
– Our envisioned system uses a general-purpose DHT for the “glue” that (loosely)
connects the system components. The lack of a central core is a feature in that no
central maintenance is required and no single point of failure exists.
– Researchers will be freed from many, but not all, of the logistic details of recruiting
measurement points to focus their attention on the important details of the mea-
surements themselves (techniques, data analysis, etc.).
– The system requires no centralized maintenance beyond keeping the DHT running.
We envision that the research community will keep a DHT such as OpenDHT run-
ning for a variety of purposes anyway and so using the DHT to coordinate mea-
surements is not an extra burden. If this is not the case and yet the community still
desired such a system for measurement purposes a DHT can be readily built from
existing and available DHT software.
– Long-running measurements that beneﬁt the entire community can be run with
community-wide resources. For instance, a setup similar to CAIDA’s skitter
114
M. Allman et al.
system [4] could be built and be supported by a distributed set of organizations—
none of which control, or can hinder (e.g., due to funding or manpower issues), the
overall data collection operation.
– Small and focused sets of measurements can be easily taken between a consenting
group of measurement points. That is, the group of measurement points used in
a particular experiment may be organized speciﬁcally for that experiment and not
assembled from generic measurement hosts donated to the community. This can
help with measurements that are too unknown or specialized to run on shared mea-
surement points (e.g., due to security concerns or because an experiment requires a
specialized kernel).
– Since the measurement results are reported through the DHT, anyone can pull down
the results of measurements as they are completed. This allows the entire commu-
nity to beneﬁt from measurements involving the community’s shared infrastructure
immediately, rather than waiting for the raw data to be posted to some measure-
ment repository and indexed in systems like DatCat [3] or PREDICT [1]. (Note, as
discussed in § 3 our system provides immediate but short-term storage of results.
Therefore, archiving and indexing measurement results in long-term repositories is
orthogonal to our framework.)
– The “barrier to entry” for doing large-scale Internet measurement studies is quite
high due to the need for a distributed set of measurement points and the time re-
quired to coordinate measurements and observations. This shuts many researchers
with small-to-modest resources out of the entire area of research (or, relegates them
to conducting limited studies, as noted above). Our proposed system will open the
ﬁeld of sound, large-scale Internet measurement to a much broader community of
researchers than are currently engaged in this ﬁeld.
– In addition, having a lightweight measurement infrastructure that can be easily used
can encourage researchers who are not engaged in “Internet measurement” per se
to both (i) test their ideas out on the real network and (ii) take broad measurements
to solidly ground their work in the actual operation of the network.
– While we are proposing an “open” infrastructure the security implications of ne-
farious use of the platform must be taken into account. We discuss mitigating such
concerns in § 3.2.
2 Related Work
Our work is related to two classes of previous efforts: (i) measurement taking infras-
tructures and (ii) data dissemination systems.
A number of measurement taking infrastructures have been developed, each with
their own wrinkle (e.g., NIMI [7], Surveyor [6]). Generally these systems have been
more heavyweight than the system we propose. These systems have features that we
do not include in our design, such as allowing for the updating of tools, coordinating
measurements, stronger and more ﬁne-grained notions of access control, etc. Our sys-
tem is in some sense on the opposite end of the spectrum—making up for a lack of
features by making the key tasks as easy as possible. In addition, we note that in many
cases these heavyweight all-encompassing measurement infrastructures have ultimately
On Community-Oriented Internet Measurement
115
required more upkeep than their designers and operators could handle (e.g., due to the
cost of replacing worn out portions of the infrastructure) and so have withered.1 Again,
we take the opposite approach and focus on designing a framework that can be used
without any sort of central authority and without relying on any particular organiza-
tion other than the community at-large to maintain infrastructure. Similarly, the current
DipZoom project [8] uses a peer-to-peer approach, but aims to leverage Internet users
at large as measurement providers and uses a central core that must be maintained. This
approach distributes the cost and effort to maintain the entire system.
Taking measurements is only one part of our system. Since we are using an open DHT
for all communication, the results of the measurements can be retrieved directly from
the DHT by the community at-large.2 These “live feeds” of data then beneﬁt the entire
community. A number of efforts provide access to archived measurement data (e.g., as
indexed in CAIDA’s Data Catalog [3]). While our system provides direct access to data
without such a catalog, the systems are actually orthogonal. We do not envision keeping
measurement results in the DHT indeﬁnitely. Rather, we envision that the data will age
out on the order of days after it was produced. Therefore, while the community can
latch on to live feeds, longer term archival and indexing systems will still be required.
3 System Architecture
As outlined above, the proposed measurement system is centered around an open dis-
tributed hash table such as OpenDHT [9]. Our only requirement for the DHT is that it
support a get()/put() interface. That is, put (k,value,t) places value into the DHT under
hash key k with a time-to-live of t. Note that multiple values can be placed in the DHT
for a given key. The DHT is queried using get (k) to retrieve all the values stored under
the hash key k.
Fundamentally, there are three types of actors and three operations for a measurement
system. The actors consist of (i) measurement requesters who desire some assessment
of the network, (ii) measurement points (MPs) that provide certain types of measure-
ments upon request and (iii) so-called “watchers” that do not request measurements,
but do track the “live feeds” by retrieving measurement results from measurements
scheduled by others. The operations that must be supported are: (a) identifying a re-
mote measurement point suitable to provide the desired measurement, (b) requesting a
measurement be conducted by a remote measurement point and (c) retrieving measure-
ment results when available. In the following subsections we discuss in detail how the
system works and several additional considerations.
3.1 Tables
Since we employ a DHT to loosely couple all the entities in our system, all communi-
cations happen through entries in various tables held in the DHT. The various actors in
1 Note that not all infrastructures have met this fate. For instance, the skitter infrastructure [4]
(and its descendant archipelago [2]) has been kept running for close to 10 years (through much
hard work).
2 Clearly, a researcher could encrypt measurement results before placing them in the DHT to
prevent community access, but this runs counter to the spirit of the system.
116
M. Allman et al.
the system are responsible for inserting new table entries, maintaining existing entries
and polling the DHT tables periodically to ﬁnd new entries. Our system does not call
for the explicit removal of items from the DHT, but rather assumes they will be aged out
(based on the time-to-live described above.3 We now discuss the three basic operations
provided by the platform.
Identifying Measurement Points. The ﬁrst key task for researchers wishing to make
use of our system is ﬁnding the names of the tables to deposit measurement requests
into and ﬁnding the names of the tables that can be monitored for results. Methods that
would accomplish this goal depend on the usage scenarios of our proposed framework.
If the experimenter is simply using the framework to interact with a set of well-known
nodes that have been constructed for a particular study then the task of ﬁnding MPs
is unnecessary. However, if a researcher wishes to make use of a set of community-
provided MPs (e.g., hosts setup to run wget on request) then some discovery process
needs to be put in place. Our system contains a master table AllMPs that includes infor-
mation about each measurement provider. At a minimum this master list will indicate
the measurement type including version (traceroute, wget, etc.), acceptable arguments,
the name of the DHT key monitored for measurement requests and the name of the
DHT key under which results will be deposited. In addition, ancillary information may
also be given (e.g., tool version, operating system and version, location of the measure-
ment host, etc.). The entries in the master table are populated and maintained by the
MPs as they come online. If an MP becomes inactive, its entry in the master table will
age out, so MP failures may only cause some number of measurements requests to go
unfulﬁlled—already possibility due to the best-effort nature of our system. Also note if
some host provides multiple measurement types (e.g., ping and pathload) then it will
have multiple entries in the master list. That is, each entry in the list is scoped to one
measurement type.
Requesting Measurements. Requesting a measurement involves simply inserting an
appropriate record into a table that a given measurement point regularly consults—as
determined, for instance, by consulting the master list of measurement providers dis-
cussed above. The time-to-live of measurement requests should be fairly short (minutes)
since MPs are assumed to be polling for new requests regularly. Each request will give
the time the measurement point should run the measurement4, the arguments to run the
tool with and the name of a DHT table to place the results into (in addition to the table
where all a given MP’s results are deposited).
Reporting Measurement Results. Similar to issuing a measurement request, reporting
measurement results involves putting the data into the DHT and then placing at least
one pointer to that result into appropriate tables. First, each measurement result is put
into the DHT under a unique hash key, U . For instance, a Universal Unique Identi-
ﬁer (UUID) could be used for U (as returned by uuidgen or similar). Using a unique
3 Note that OpenDHT has a built-in TTL limit to deal with overly long TTL requests. A TTL