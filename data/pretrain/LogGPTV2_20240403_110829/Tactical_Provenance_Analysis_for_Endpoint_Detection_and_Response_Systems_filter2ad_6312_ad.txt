severity score that was provided by the EDR vendor, normal-
ized to our ﬁfteen point scale. We converted the descriptive
values for each metric into a numeric scale of one to ﬁve,
and combined the two metrics together. We give the severity
score a higher weight
than the likelihood score since we
are defending against advanced adversaries that have many
resources at their disposal to effectively execute techniques
that might be considered unlikely due to their difﬁculty or
cost. The resulting threat score for each individual alert is:
T S(technique) = (2 ∗ SeverityScore) + LikelihoodScore (1)
For example, the MITRE technique called Registry Run
Keys / Startup Folder (T1060) [62] refers to the attack pattern
called Modiﬁcation of Registry Run Keys (CAPEC-270) [63]
which assigns a likelihood of attack of “medium” and a
severity of “medium”. Thus, we assign an alert that detects
technique T1060 a score of nine out of a possible ﬁfteen
(T S(T1060) = 2 ∗ 3 + 3 = 9).
Next, we explain different schemes that we used to combine
individual alert scores into an overall threat score.
A. Limitations of Path-Based Scoring Schemes
To aggregate scores, we ﬁrst tried an approach based on
grouping and scoring alerts using a single, non-branching
provenance path as was proposed by Hassan et al. in [38].
For each alert, we generated the backward tracing path and
then aggregated the scores that occurred on that path. We tried
different aggregation schemes such as adding the individual
alert scores or multiplying them, with and without technique
or tactic deduplication. Unfortunately, we realized during our
experiments that the path-based approach was not capturing
the entire context of the attacks in some situations. This led
us to explore another approach to grouping and scoring alerts.
B. Graph-Based Scoring Schemes
To capture the broader context of a candidate alert, we
generate the TPG for the candidate alert which is derived from
the subgraph rooted at the shallowest alert in the candidate’s
backward tracing provenance path as described in Section IV.
The key insight behind our proposed scheme is that we
would like to maximize the threat score for TPGs where the
alerts are consistent with an attacker proceeding through the
ordered phases of the tactical kill chain deﬁned by MITRE.
We formalize this intuition in a scoring algorithm as follows.
The sequence edges in the TPG form a temporally ordered
sequence of the graph’s constituent alerts. We ﬁnd the longest
(not necessarily consecutive) subsequence of these ordered
alerts that is consistent with the phase order of MITRE’s
tactical kill chain. We then multiply the scores of the individual
alerts in this subsequence to give an overall score to the TPG.
If there are multiple longest subsequences, we choose the one
that yields the highest overall score. More formally:
T S(TPG) = max
Ti∈T
T S(T i
j
)
(2)
(cid:2)
∈Ti
T i
j
In Equation 2, T is the set of all longest subsequences
in TPG consistent with both temporal and kill-chain phase
ordering. Note that an attacker cannot evade detection by
introducing out-of-order actions from earlier, already com-
pleted stages of the attack. RapSheet’s scoring approach will
simply ignore these actions as noise when ﬁnding the longest
subsequence of alerts from the TPG, which need not be
consecutive.
VI. GRAPH REDUCTION
System logs enable two key capabilities of EDR tools: 1)
threat alert triage based on alert correlation and 2) after-the-
fact attack investigation using attack campaign visualization.
Thus, EDR tools need to retain these logs long enough to
provide these capabilities. However, system logs can become
enormous quickly in large enterprises, making long-term reten-
tion practically prohibitive. As mentioned in Section II, most
EDR tools store logs in a limited FIFO buffer, destroying old
logs to make space for new logs. Unfortunately, this naive log
retention strategy can lose critical information from older logs.
So, it is important to use this limited memory efﬁciently.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:13 UTC from IEEE Xplore.  Restrictions apply. 
1179
t8
t3
33
P5
P5P5
t9
P4
PP4
4
O5
t4
O1
O
P1
P
PP1
t1
P2
P
PP
P2
2
t6
t6
t7
t2
2
t5
t55t
t
O3
O3
O4
O4
P3
PPP
PPP333PPP3333
O2
OOOO222
(a)
t7
t8
O4
O
P1
P
PP1
t1
P2
P
2P2
t6
P5
P
5P5
P4
P4
PP4
t9
O5
t4
O1
O
O3
O
(b)
Fig. 6: Graph reduction example. After every conﬁgurable time
interval, RapSheet runs graph reduction and store only skeleton graph
which preserves the linkability between current and future tactics.
We propose a novel technique to reduce the ﬁdelity of logs
while still providing the two key EDR capabilities. To provide
these key capabilities, we need to ensure that we can generate
the TPG from the pruned graph. Once we have the TPG, we
can derive correlations between alerts, assign threat scores to
correlated alerts and provide high-level visual summaries of
attacks to the cyber analyst.
For our graph reduction algorithm, we assume the properties
of the provenance graph and backward tracing graph described
in Section IV-C. We also assume all the alert events in the
provenance graph are incident to at least one process vertex.
Based on these properties, we propose the following two rules
to prune the provenance graph at any point in time while
preserving TPG-based alert correlation.
Rule#1: Remove object vertex O iff there are no alert
events in the backward tracing graph of O and there are
no alert event edges directly connected to O.
This rule ensures that O is not currently part of any IIP
graph derived from the current provenance graph. If it were,
then it either would be directly involved in an alert (i.e., there
would be an alert edge incident to O), or it would be on a path
from some IIP vertex to some alert edge, which entails that
the alert incident to that IIP vertex would be in O’s backward
tracing graph. Note that even if there is a live process vertex
in the ancestry of object O, and that process generates an
alert event E1 in the future, this new alert event will have a
timestamp later than the edges currently leading to O. Hence,
O would not be part of the IIP graph containing E1.
To explain our graph reduction algorithm we use an example
provenance graph shown in Figure 6(a). Vertices labeled with
a P represent processes while those with an O represent object
vertices. The red edges indicate alerts, green vertices show live
processes at the time of reduction, and edges are marked with
ordered timestamps t1 to t9. Gray vertices and edges show
candidates for removal according to Rule#1 and Rule#2.
The only candidate for object vertex reduction is O2 since
it satisﬁes all the conditions of Rule#1. The backward tracing
graph of O2 consists of vertices {P2, P1} and the edges with
timestamps {t5, t1}, which do not have any alert events. Thus,
we can safely remove O2 and the edge with timestamp t5
from the graph without losing any connectivity information
for current or future alerts. Note that the edge with timestamp
t7 will not be included in the backward tracing graph because
it happened after t5. After graph reduction, if some process
vertex reads or writes to the object O2, then vertex O2 will
reappear in the provenance graph. Next, we discuss how to
prune process vertices from the graph.
Rule#2: Remove process vertex P iff: i) there are no alert
events in the backward tracing graph of P , ii) there are no
alert event edges directly connected to P and iii) process
P is terminated.
The ﬁrst two conditions of Rule#2 have the same reasoning
as Rule#1. In addition, we have to ensure that process P
is terminated so that it does not generate new alerts which
will become part of an IIP graph. In the example shown in
Figure 6(a), process P3 is terminated, has no alert event in
its backward tracing graph, and does not have any incident
edges that are alert events. Thus, we can safely remove the
process vertex P3 from the graph along with the edges that
have timestamp {t2, t3}.
By applying these two reduction rules to a given prove-
nance graph, RapSheet generates a space-efﬁcient skeleton
graph which can still identify all the causal dependencies
between alerts and can generate exactly the same set of TPGs
(procedure described in Section IV-D) as from the classical
provenance graph. Figure 6(b) shows the skeleton graph for
our example graph. We describe an efﬁcient way to generate
the skeleton graph, which does not require performing a
backward trace for every vertex of a given provenance graph,
in Appendix B.
Properties. A skeleton graph generated by RapSheet will
not have any false positives, that is, TPGs generated from the
skeleton graph will not have alert correlations that were not
present in the original provenance graph. This is clear since
RapSheet does not add any new edges or vertices during the
reduction process. Furthermore, a skeleton graph generated
by RapSheet will not have any false negatives, meaning it
will capture all alert correlations that were present in the
original provenance graph. This follows from the properties of
provenance and our backward tracing graphs. The reduction
rules ensure that, at the time of reduction, the removed nodes
and edges are not part of any IIP graph. And since our
backward traces include only events that happened before a
given event, they would not be part of any future IIP graph.
Retention Policy. To provide log reduction and prevent stor-
age requirements from growing indeﬁnitely, enterprises can
run the graph reduction algorithm at a conﬁgurable retention
time interval. This conﬁguration value must be long enough
for alert rule matching to complete. The retention policy can
be easily reﬁned or replaced according to enterprise needs.
The conﬁgured retention interval controls how long we store
high-ﬁdelity log data (i.e., the unpruned graph). RapSheet’s
backward tracing and forward tracing works seamlessly over
the combined current high-ﬁdelity graph and the skeleton
graph that remains from prior pruning intervals.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:13 UTC from IEEE Xplore.  Restrictions apply. 
1180
VII. EVALUATION
In this section, we focus on evaluating the efﬁcacy of
RapSheet as a threat investigation system in an enterprise
setting. In particular, we investigated the following research
questions (RQs):
RQ1 How effective is RapSheet as an alert triage system?
RQ2 How fast can RapSheet generate TPGs and assign threat
scores to TPGs?
RQ3 How much log reduction is possible when using skeleton
graphs?
RQ4 How well does RapSheet perform against realistic attack
campaigns?
A. Implementation
We used Apache Tinkerpop [64] graph computing frame-
work for our provenance graph database. Tinkerpop is an
in-memory transactional graph database and provides robust
graph traversal capabilities. We implemented the three Rap-
Sheet components (tactical graph generation,
threat score
assignment, and graph reduction) in 6K lines of Java code.
We use a single thread for all our analyses. We generate our
provenance graphs in GraphViz (dot) format which can be eas-
ily visualized in any browser. Our implementation interfaces
with Symantec EDR. Symantec EDR is capable of collecting
system logs, matching events against attack behaviors, and
generating threat alerts.
B. Experiment Setup & Dataset
We collected system logs and threat alerts from 34 hosts
running within Symantec. The logs and alerts were generated
by Symantec EDR which was conﬁgured with 67 alert gener-
ating rules that encode techniques from the MITRE ATT&CK
knowledge-base. In our experiments, we turned off other EDR
rules that did not relate to MITRE ATT&CK. During all
experiments, RapSheet was run on a server with an 8-core
AMD EPYC 7571 processor and 64 GB memory running
Ubuntu 18.04.2 LTS.
Our data was collected over the period of one week from
hosts that were regularly used by members of a product devel-
opment team. Tasks performed on those hosts included web
browsing, software coding and compilation, quality assurance
testing, and other routine business tasks. Due to variations
in usage, some machines were used for only one day while
others logged events every day during data collection week.
In total, 35GB worth of (lightly compressed) logs with around
40M system events were collected. On average, each host
produced 400K events per machine per day. We describe
further characteristics of our dataset in Appendix A.
During the experimental period, we injected attack behav-
iors into three different hosts. The attack behaviors correspond
to three different attack campaigns, two based on real-world
APT threat groups (APT3 and APT29) and one custom-built
data theft attack. These simulated attacks were crafted by
an expert security red-team. The underlying EDR generated
58,096 alerts during the experiment period. We manually
examined the alerts from the machines which were targeted
Fig. 7: ROC curve for our experiments. We tried two different
schemes to rank TPGs. TPG-Seq means sequence-based scoring
while TPG-mult means strawman approach of score multiplication.
F
D
C
1
0.8
0.6
0.4
0.2
0
True Attack TPGs
False Alarm TPGs
Threshold
10
100
1000
10000
100000
Threat Score [log-scale]
Fig. 8: CDF of threat scores for false alarm and true attack TPGs.
by the simulated attacks to determine that 1,104 alerts were
related to simulated attacker activity. The remaining alerts
were not associated with any of the simulated attacks and we
consider them to be false positives.
C. Effectiveness
The ﬁrst research question of our evaluation is how effective
RapSheet is as an alert triage tool. In our experiment, we
used the EDR tool to monitor hosts for MITRE ATT&CK
behaviors and generate alerts. We then manually labeled these
alerts as true positives and false positives based on whether the
log events that generated the alert were related to simulated
attacker activity. This labeled set is used as the ground truth
in our evaluation. Then, we used RapSheet to automatically
correlate these alerts, generate TPGs, and assign threat scores
to TPGs.
Of the 1,104 true alerts and 56,992 false alarms generated
during our experiments, RapSheet correlated these alerts into
681 TPGs. Of these, 5 were comprised of true alerts and
676 contained only false alarms.4 We then calculated threat
scores for these TPGs and sorted them according to their
score. We tried two different scoring schemes. For the ﬁrst
scheme, we assigned scores to each TPG using a strawman
approach of multiplying the threat scores of all alerts present
in the TPG. However, since TPGs may contain duplicate alerts,
we normalize the score by combining alerts which have the
same MITRE technique, process, and object vertex. For the
second scheme, we used the scoring methodology described
in Section V.
Different true positive rates (TPRs) and false positive rates
(FPRs) for the scoring schemes above are shown in the ROC
graph in Figure 7. Our sequence-based scoring scheme was
4Three out of ﬁve truly malicious TPGs were related to the APT29
simulation, which the red team performed three times during the week with
slight variations. The other two attack campaigns resulted in one TPG each.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:41:13 UTC from IEEE Xplore.  Restrictions apply. 
1181
1
0.8
1
0.8
F
D
C
0.6
0.4
F
D
C
0.6
0.4
0.2
0
0
5
10
15
20
25
30
35
ResponseTime(sec)
0.2
0
0
5