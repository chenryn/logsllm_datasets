within the trace are randomly selected. All 100 probings detect hop
6 (i.e., link Y ) as the bottleneck. All other candidate choke points
are ﬁltered out because of a low conﬁdence value (i.e., conf <
0.1). Obviously, the detection results for the probing sets are also
100% accurate.
This experiment represents the easiest scenario for Pathneck, i.e.,
the bottleneck is determined by the link capacity, and the back-
ground trafﬁc is not heavy enough to affect the bottleneck loca-
tion. This is however an important scenario on the Internet. A large
fraction of the Internet paths fall into this category because only a
limited number of link capacities are widely used and the capacity
differences tend to be large.
3.2.2 Experiment 2 — Load-determined Bottleneck
Besides capacity, the other factor that affects the bottleneck po-
sition is the link load. In this experiment, we set the capacities of
both X and Y to 50Mbps. We use the 35Mbps exponential-load on
Y and the light-trace on other links, so the difference in trafﬁc load
on X and Y determines the bottleneck. Out of 100 probings, 23
had to be discarded due to ICMP packet loss. Using the remaining
77 cases, the probing sets always correctly identify Y as the bottle-
neck link. Of the individual probings, 69 probings correctly detect
Y as the top choke link, 2 probings pick link (cid:6)R7, R8(cid:7) (i.e., the link
after Y ) as the top choke link and Y is detected as the secondary
choke link. 6 probings miss the real bottleneck. In summary, the
accuracy for individual probings is 89.6%.
3.2.3 Comparing the Impact of Capacity and Load
To better understand the impact of link capacity and load in de-
termining the bottleneck, we conducted two sets of simpliﬁed ex-
periments using conﬁgurations similar to those used in experiments
1 and 2. Figure 5 shows the gap measurements as a function of the
hop count (x axis). In the left ﬁgure, we ﬁx the capacity of X to
50Mbps and change the capacity of Y from 21Mbps to 30Mbps
with a step size of 1Mbps; no background trafﬁc is added on any
link.
In the right ﬁgure, we set the capacities of both X and Y
to 50Mbps. We apply different CBR loads to Y (changing from
29Mbps to 20Mbps) while there is no load on the other links. For
each conﬁguration, we executed 10 probings. The two ﬁgures plot
the median gap value for each hop; for most points, the 30-70 per-
centile interval is under 200µs.
In both conﬁgurations,
the bottleneck available bandwidth
changes in exactly the same way, i.e., it increases from 21Mbps
to 30Mbps. However, the gap sequences are quite different. The
gap increases in the left ﬁgure are regular and match the capacity
changes, since the length of the packet train is strictly set by the
link capacity.
In the right ﬁgure, the gaps at the destination are
less regular and smaller. Speciﬁcally, they do not reﬂect the avail-
able bandwidth on the link (i.e., the packet train rate exceeds the
available bandwidth). The reason is that the back-to-back prob-
ing packets compete un-fairly with the background trafﬁc and they
can miss some of the background trafﬁc that should be captured.
This observation is consistent with the principle behind TOPP [26]
and IGI/PTR [18], which states that the probing rate should be set
properly to accurately measure the available bandwidth. This ex-
plains why Pathneck’s packet train rate at the destination provides
only an upper bound on the available bandwidth. Figure 5 shows
that the upper bound will be tighter for capacity-determined bottle-
necks than for load-determined bottlenecks. The fact that the gap
changes in the right ﬁgure are less regular than that in the left ﬁg-
ure also conﬁrms that capacity-determined bottlenecks are easier to
detect than load-determined bottlenecks.
3.2.4 Experiments 3 & 4 — Two Bottlenecks
In these two experiments, we set the capacities of both X and Y
to 20Mbps, so we have two low capacity links and the bottleneck
location will be determined by load. In experiment 3, we use the
heavy-trace for Y and the light-trace for other links. The probing
set results are always correct, i.e., Y is detected as the bottleneck.
When we look at the 86 valid individual probings, we ﬁnd that X
is the real bottleneck in 7 cases; in each case Pathneck successfully
identiﬁes X as the only choke link, and thus the bottleneck. In the
remaining 79 cases, Y is the real bottleneck. Pathneck correctly
identiﬁes Y in 65 probings.
In the other 14 probings, Pathneck
identiﬁes X as the only choke link, i.e., Pathneck missed the real
bottleneck link Y . The raw packet traces show that in these 14
incorrect cases, the bandwidth difference between X and Y is very
small. This is conﬁrmed by Figure 6, which shows the cumulative
distribution of the available bandwidth difference between X and
Y for the 14 wrong cases (the dashed curve), and for all 86 cases
(the solid curve). The result shows that if two links have similar
available bandwidth, Pathneck has a bias towards the ﬁrst link. This
is because the probing packet train has already been stretched by
the ﬁrst choke link X, so the second choke link Y can be hidden.
As a comparison, we apply the heavy-trace to both X and Y in
experiment 4. 67 out of the 77 valid probings correctly identify X
as the bottleneck; 2 probings correctly identify Y as the bottleneck;
and 8 probings miss the real bottleneck link Y and identify X as
the only bottleneck. Again, if multiple links have similar available
bandwidth, we observe the same bias towards the early link.
Table 3: The number of times of each hop being a candidate
choke point.
Router
conf ≥ 0.1
d rate ≥ 0.5
1
24
6
2
18
0
3
5
0
4
21
2
5
20
0
6
75
85
7
34
36
3.2.5 Experiment 5 — Reverse Path Queuing
To study the effect of reverse path queuing, we set the capacities
of X and Y to 50Mbps and 20Mbps, and apply exponential-load
in both directions on all links (except the two edge links). The
average load on each link is set to 30% of the link capacity. We
had 98 valid probings. The second row in Table 3 lists the number
of times that each hop is detected as a candidate choke point (i.e.,
with conf ≥ 0.1). We observe that each hop becomes a candidate
choke point in some probings, so reverse path trafﬁc does affect the
detection accuracy of RPTs.
However, the use of probing sets reduces the impact of reverse
path trafﬁc. We analyzed the 98 valid probings as 89 sets of 10 con-
secutive probings each. The last row of Table 3 shows how often
links are identiﬁed as choke points (d rate ≥ 0.5) by a probing
set. The real bottleneck, hop 6, is most frequently identiﬁed as the
actual bottleneck (last choke point), although in some cases, the
next hop (i.e., hop 7) is also a choke point and is thus selected as
the bottleneck. This is a result of reverse path trafﬁc. Normally, the
train length on hop 7 should be the same as on hop 6. However, if
reverse path trafﬁc reduces the gap between the hop 6 ICMP pack-
ets, or increases the gap between the hop 7 ICMP packets, it will
appear as if the train length has increased and hop 7 will be labeled
as a choke point. We hope to tune the detection algorithm to reduce
the impact of this factor as part of future work.
3.3 Validation of Bandwidth Bounds
A number of groups have shown that packet trains can be used
to estimate the available bandwidth of a network path [26, 18, 21].
However, the source has to carefully control the inter-packet gap,
and since Pathneck sends the probing packets back-to-back, it can-
not, in general, measure the available bandwidth of a path. Instead,
as described in Section 2.3, the packet train rate at the bottleneck
link can provide a rough upper bound for the available bandwidth.
In this section, we compare the upper bound on available band-
width on the bottleneck link reported by Pathneck with end-to-end
available bandwidth measurements obtained using IGI/PTR [18]
and Pathload [21].
Since both IGI/PTR and Pathload need two-end control, we used
10 RON nodes for our experiments, as listed in the “BW” column
in Table 4; this results in 90 network paths for our experiment.
On each RON path, we obtain 10 Pathneck probings, 5 IGI/PTR
measurements, and 1 Pathload measurement2. The estimation for
the upper bound in Pathneck was done as follows. If a bottleneck
can be detected from the 10 probings, we use the median packet
train transmission rate on that bottleneck. Otherwise, we use the
largest gap value in each probing to calculate the packet train rate
and use the median train rate of the 10 probings as the upper bound.
Figure 7 compares the average of the available bandwidth esti-
mates provided by IGI, PTR, and Pathload (x axis) with the up-
per bound for the available bandwidth provided by Pathneck (y
axis). The measurements are roughly clustered in three areas.
For low bandwidth paths (bottom left corner), Pathneck provides
2We force Pathload to stop after 10 ﬂeets of probing. If Pathload
has not converged, we use the average of the last 3 probings as the
available bandwidth estimate.
Table 4: Probing sources from PlanetLab (PL) and RON.
ID
1
2
3
Probing
Source
aros
ashburn
bkly-cs
AS
Number
6521
7911
25
Location
UT
DC
CA
Denmark
Germany
Canada
Canada
Canada
Canada
10781
NY
UT
GA
PA
CA
CA
NY
MD
OR
73
46
11
20130
239
6509
611
27
7018
7018
3549
5723
18473
11085
14
1835
17055
3356
71
9
12
88
17
91
3479
1249
3388
17055
NY
NJ
IN
NY
GA
MA
NM
UT
WA
MA
NJ
MA
CH
columbia
diku
emulab
frankfurt
grouse
gs274
bkly-intel
intel
jfk1
jhu
nbgisp
nortel
nyu
princeton
purdue
rpi
uga
umass
unm
utah
uw-cs
vineyard
rutgers
harvard
depaul
toronto
halifax
unb
umd
dartmouth
virginia
upenn
cornell
mazu1
kaist
cam-uk
ucsc
ku
snu-kr
bu
northwestern
cmu
mit-pl
stanford
wustl
msu
uky
ac-uk
umich
cornell
lulea
ana1
ccicom
ucsd
utah
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
29
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
CA
55
UT
56
CA
57
58
UT
BW: measurements for bandwidth estimation;
ST: measurements for stability analysis;
MH: measurements for multihoming analysis.
10755
225
55
26
3356
1781
786
5739
2496
9488
111
103
9
3
32
2552
237
10437
786
237
26
2831