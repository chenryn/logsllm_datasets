from, 
4.2.  The fail-bounded approach 
From  the previous rcsults, the  types of faults that were 
identified as being able to collapse the pendulum are 
Errors that affect the program code 
Errors that affect data not periodically recalculated 
(constants) 
Since  the  code  in  this  type  of  controllers  is  usually 
stored  in  ROM  and/or  is  protected  by  a  signature  and 
regularly  verified  by  diagnosis  code,  it  is  reasonable  to 
expect that this typc of errors do not go undetected  in real 
applications.  The  above  experiments  show  that  even  if 
corrupted  code  is  executed  during  one  iteration,  if  that 
corruption  is  dctected  within  a  few  control  cycles,  any 
erroneous output  produced  meanwhile  would  be harmless 
to  the  process.  Since the diagnosis code can easily  verify 
the check code of  the program  every few iterations, these 
errors are of no substantial consequence. 
Thus,  the  most  critical  part  to  be  protected  is  the 
permanent  data  used  by  the  program  - the  data  that  is 
not  recalculated 
in  all  iterations,  or  at  least  is  not 
recalculated  frequently.  While  the  constants  used  by  the 
application  can  also  be  stored  in  ROM,  they  may  be 
in 
copied  to  RAM  during  execution  e.g.  for  performance 
reasons.  Other  permanent  data  is  only  collected  or 
calculated  during  the  controller/process setup phase,  e.g. 
calibration  data.  Thus, 
the 
Fail-Bounded model, we have protected  all that data with 
checksums,  to  enable  the  detection  of  almost  all  of  the 
potentially  serious errors. 
just  as  prescribed 
But  we  cannot  assume  that  these  methods have  100% 
effectiveness, nor that there are no other sources of errors 
that  can  lead  to  the  collapse  of  the  pendulum.  We  need 
some kind  of end-to-end protection  [IS], which is exactly 
what  well-designed  assertions  can  provide.  Indeed,  to 
completely  implement  the  Fail-Bounded  model  we  still 
have to decide what assertions to use. They should enable 
us  to  let  the  non-critical  errors pass, but  should  filter  the 
serious  ones,  thus  providing  us  with  the  compromise 
between Fail-Arbitrary and Fail-Silent that we are looking 
for. 
The  usual  approach  to  define  assertions  is  to  look  at 
to  derive  a  simpler 
the  control  algorithm,  and 
expression  that  detects  gross  deviations from  the  correct 
result.  However,  as  in  many  other  control  systems,  the 
control equation is only a couple of high level instructions 
long, thus making  it difficult to define what is a “simpler” 
expression.  Besides,  although  the  equation  itself  resulted 
from an analytical analysis of the system, the exact values 
of  several  parameters  were experimentally  tuned,  making 
it  more  difficult  to  derive  and  tune  a  good  assertion.  A 
serious  additional  hurdle  is  the  fact  that  the  assertions 
should  not  react  to  an  isolated  wrong  output  (we  have 
seen  in  our experiments that there can be arbitrarily  large 
output  errors,  as  long  as  they  don’t  last  long)  but  to  a 
series of significantly  wrong  outputs. Considering time in 
this manner is not simple. 
try 
To solve this problem we can take a radically different 
approach: instead of looking at the stream of outputs from 
the  controller,  we  should  look  at  the  controlled  system. 
The  robust  assertions  underlying  the  concept  of  fail- 
-boundedness should be  applied  to the system as a whole 
(controller + process)  rather  than  solely to  the controller, 
and  the  best  indicator  of  the  quality  of  the  control  is  the 
behavior  of  the  controlled  system  itself. We just have to 
define  an  acceptable  interval  around  the  set-point,  such 
that  whenever  the  pendulum  leaves  such  an  interval  that 
is  flagged  as  an  error.  This  view  is  more  related  to  the 
concept  of  “quality  of  service”  rather  than  to  the  more 
traditional  “consistency  checks”.  In  fact,  the  consistency 
of  the  process  is  checked  rather  than  the  consistency  of 
the  outputs  produced,  and  time  is  inherently  taken  into 
account,  because  only  lasting  perturbations  will  result  in 
the system  leaving that  interval. This approach is general 
and  can  be  applied  to  almost  every  feedback  control 
system: every  application’s state-space  has an  “envelope” 
of  executiodstability  that  can  be  used  to  deduce  the 
quality/effectiveness  of  the  control  applied.  In  fact,  this 
32 1 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply. 
quality  of  service is  the  metrics used  in  every  optimizing 
control techniques.  Again,  we  are  using  knowledge from 
the  analysis  of  the  control  problem  to  improve depend- 
ability. 
For  the  experiments  described  next,  the  bounds  we 
have  set  in  the  input  assertions  were  chosen  based  on 
observations of  the  system behavior, and  not  derived  by 
any  rigorous  method,  which  should  be  the  subject  of 
another  study.  Namely,  if  the  rod  angle  or  the  cart 
position  of the inverted pendulum are greater than 60% of 
the  crash  angle  or  position  (defined  in  section  3.2),  the 
assertion signals an error. 
The results from  the  injection  of  a  new  series of  597 
faults  inducing. permanent  errors  solely  in  constant  data 
used by the algorithm are presented  in Table 5. 
Controller behavior 
Detected error 
Crash 
Correct output 
98.8% 
0% 
0% 
Undet. wrong output 
7 
Table  5.  Behaviour  of  the  Fail-Bounded 
controllers  to  faults  injected  in  constant 
data (70 and no. of cases) 
The  pendulum  did  not  fall  down  for  the  1.2%  wrong 
outputs  generated.  Of  the  590  detected  errors,  12  were 
detected  only  by  the  assertions; all  others  were  detected 
by  the  simple  checksums  used.  This  is  the  confirmation 
that  a careful protection of these  structures  can detect  the 
occurrence of  the  most  dangerous  errors  for  this  kind  of 
systems.  If  better  check  codes  were  used,  the  figure  of 
1.2%  of  undetected  wrong  outputs  could  certainly  be 
lowered.  It  is  relevant  to  note  also  that  there  were  no 
vanished  errors  nor  crashes  since  only  pure  data  errors 
were injected  in these experiments. There were three false 
alarms,  that  is,  3  times  an  error  was  detected,  but  the 
controller output  was equal to the output of the  reference 
controller. Probably  it  was  a  case  where  the  checksums 
themselves were corrupted, but not the data. 
It  must  be  stressed  that  the  Fail-Arbitrary  and  Fail- 
-Bounded figures were achieved with a simplex computer 
without  any structural  redundancy as opposed to  the  Fail- 
-Silent  version  where  two  machines  and  voting  were 
used.  This  means  that  it  is  possible  to  achieve,  for  this 
setup  and  fault  model,  an  higher  availability  using  only 
one  controller  than  using  two,  because  the  Fail-Silent 
model  leads  to  many  unnecessary  stops  of  the  system. 
The  Fail-Bounded  model  thus  retains  the  advantage  of 
low  redundancy  of  the  Fail-Arbitrary  model,  while  not 
exhibiting  the  disadvantage  of  losing  control  of  the 
system. 
5.  Conclusions and Future Work 
In  this  paper  we  presented  a  study  where  it  is  shown 
that the feedback used in most continuous control  systems 
to  compensate for external disturbances can also be  used 
to compensate errors in  the controller itself. We have not 
considered  permanent  faults,  which  could  lead  to  more 
frequent  loss of  control. However, we have observed that 
whenever  permanent  errors  are  generated  (the  faults 
change  the  program  code  or  permanent  data),  a  quick 
diagnosis  can  provide  a  disciplined  shut  down  or  even 
restart  the  system on  time  to  recover  control. Permanent 
to  detect  by  means  of  a 
faults  are  relatively  easy 
watchdog  timer,  in  case  of  a  crash,  or  by  periodic 
diagnostic routines that use up the application idle time. 
Another  interesting  conclusion  of  this  study is  that,  in 
feedback  systems  like  the  one  studied,  the  Fail-Silent 
model  is  clearly  inappropriate, because  it  flags  as failure 
situations where  the  system suffers no negative impact at 
all.  Essentially  the  Fail-Silent  model  lacks  the  notion  of 
time - a single erroneous output is not significant, only a 
sequence of erroneous outputs is - and  fails to  take into 
account the  fact  that  the  natural  inertia  of  the  controlled 
system  filters  out  short lived  disturbances. We show that 
the  Fail-Bounded  model,  with  assertions  based  on  the 
behavior of the controlled system, is a much better failure 
model  for these systems, compared to both Fail-Silent  and 
Fail-Arbitrary.  This conclusion cannot be  generalized for 
every class of applications. 
the 
the  Fail-Silent  model: 
It is fair to say that there is a characteristic of feedback 
control  systems that has not been  sufficiently  addressed in 
this  study,  that  may  impact  this  conclusion  about  the 
inadequacy  of 
level  of 
"memory"  of  the  control  algorithm.  Since  the  inverted 
pendulum  is a "fast" system, only the inputs of the present 
and  previous  iterations  are  needed  to  calculate  the  next 
output.  In  other  "slower"  systems  (for  instance,  the 
control  of  temperature in  industrial  boilers), that  use  e.g. 
PI  (Proportional  Integrative)  algorithms,  the  system 
integrates  the  previous  history  of  the  controlled  system, 
and  uses  that  integration  in  the  calculation  of  the  next 
output.  In 
the  consequences  of  a 
short-lived  perturbation  will  last  longer.  It  can  also  be 
argued 
that  since  the  system  is  also  slower  these 
perturbations will have no  consequences. Further  study is 
needed  to clarify this point. 
those  systems, 
Another  contribution of  this study  is a different way of 
defining  effective  assertions.  Instead  of  analyzing  the 
outputs  of  the  controller,  the  behavior  of  the  controlled 
system  should  be  taken  into  account.  While  it  is  not 
possible to fully  characterize the best  assertions for every 
application, we claim that truly effective assertions should 
not check the  outputs of  the controller per se, but  instead 
the  quality  of  service  delivered  by  the  controller.  This 
approach  encompasses  the  sensors,  controller,  actuators 
322 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply. 
and  the  application.  In  feedback  control  applications  it 
makes no sense to consider separately those components: 
they  should  be  viewed  as  a  whole,  since  the  feedback 
control equations consider the full control loop. 
In our opinion, another very interesting conclusion can 
be drawn from this study, regarding real-time scheduling. 
Many scheduling algorithms have been proposed with the 
aim  that  no  hard  deadline  should  be  missed,  lest  some 
catastrophe  may  happen.  The  observations  presented  in 
this  paper  show  that  for  the  type  of  systems  studied 
neither the deadlines are so hard nor  errors have dramatic 
consequences as long as they  are corrected in  subsequent 
iterations  of  the control  loop. These results  are not  valid 
only  in  rare  circumstances: on  the  contrary, the  inverted 
pendulum 
is  one  of  the  most  time  critical  control 
applications.  These  observations  confirm  a  concept  well 
known in industry, that of grace-time, i.e. the time that an 
application  can  run  without  control,  exhibiting  no 
significant  or  even  null  consequences.  A  more  thorough 
study  is  required  to  fully  characterize  the  number  of 
deadlines that can be lost versus the errors present  in  the 
control  loop,  and  different  scheduling algorithms should 
be  developed  to  take  that  into  account.  We  have  done 
some work in that direction in the past [ 16). 
There  is  a  final  area of  open  research  that  we  would 
like  to  mention.  It  is  not  clear  whether  these  or  similar 
conclusions also apply to discrete systems since they  are 
not  so  forgiving  of  short-lived  disturbances.  This  is 
another point of research currently underway 
6.  Acknowledgements 
We  acknowledge  the  fruitful  discussions  with  the 
members  of  the  Control  System group  of  CISUC  at  the 
University  of  Coimbra,  namely  Jorge  Henriques  and 
Alberto  Cardoso,  and  thank  Professor  Ant6nio  Dourado 
for  letting  us  use  the  inverted  pendulum  testbeb  used  in 
these experiments. 
References 
[ 13  A.  .Avizienis,  “Building  Dependable  Systems:  How  to 
Keep Up  with  Complexity” Special  Issue ofthe FTCS-25, 
Pasadena-CA, 1995, pp.4-14. 
[2]  J.  Carreira, H.  Madeira, J.  G.  Silva, “Xception: Software 
Fault  Injection  and  Monitoring  in  Processor  Functional 
Units”,  DCCA ‘95,  Urbana,  Champaign-USA,  1995, 
pp.135-149. 
[3]  Chillarege, R.,  and  N.  S.  Bowen,  “Understanding Large 
System Failures: A Fault Injection Experiment”, FTCS-IY, 
1989. 
141  J.  C.  Cunha,  M.  Z.  Rela,  J.  G.  Silva,  “Can  Software- 
-Implemented Fault-Injection  be  used  on  Real-Time Sys- 
tems?’,  EDCC-3,  Prague,  Czech  Republic,  September 
1999. 
[5]  M.  Hiller,  “Executable  Assertions  for  Detecting  Data 
Errors  in  Embedded  Control  Systems”, DSN’2000,  New 
York, June 2000, pp.24-33. 
[6]  J.  C.  Laprie,  “Dependability:  Basic  Concepts  and 
Terminology”, Springer- Verlag, 199 1. 
[7]  M.  Pease, R.  Shostak, L. Lamport, “Reaching Agreement 
in  the presence of  faults”, Journal  ofthe ACM, 25, 1980, 
pp. 228-234. 
[8]  D. Powell, P.  Verissimo, G. Bonn, F. Waeselynck, and  D. 
Seaton, “The Delta-4 Approach  to  Dependability in  Open 
Distributed Computing Systems”, FTCS-18, Tokyo, 1988. 
[9]  B.  Randell,  “System  Sructure  for  Software  Fault- 
-Tolerance”, IEEE  Trans.  on  Software  Engineering,  SE- 
1(2), 1975, pp. 220-232. 
[IO] M. Rela, H. Madeira, J.G. Silva, “Experimental Evaluation 
of  the Fail-Silent Behavior of  Programs with  Consistency 
Checks”, FTCS-26, Sendai, Japan, 1996. 
[I I] L.  Sha, “Dependable System Upgrade”, RTSS’98, Madrid, 
Spain, December 1998, pp.440-448. 
[12] J. G. Silva, P. Prata, M. Rela, H. Madeira, “Practical Issues 
in the Use of  ABFT and a New Failure Model”, FTCS-28, 
Munich, Germany, 1998, pp.26-35. 
[ 131 “PS600  Laboratory  Experiment  Inverted  Pendulum  - 
Manual” - Amira GmbH, Germany, 1996. 
[ 141 http://www.smxinfo.com 
[15] J.  H.  Saltzer,  D.  P.  Reed,  D.  D.  Clark  “End-To-End 
Arguments  in  System  Design”,  ACM  Transactions  in 
Computer  Systems,  Vol  2,  N.  4,  November  1984,  pp. 
277-288. 
1161 A.  P.  MagalhBes, J.  G.  Silva, “Stabilizing Pre-Run-Time 
Schedules with  the  Help  of  Grace Time”, Real-Time SJJS- 
tems,  17(l), July 1999, pp. 65-86. 
323 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply.