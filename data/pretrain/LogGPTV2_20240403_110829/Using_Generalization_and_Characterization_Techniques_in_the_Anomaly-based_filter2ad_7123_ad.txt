tuted or used to supplement the basic heuristic, such as
abstract execution [20], with associated tradeoffs in per-
formance.
7. Evaluation
The system was evaluated in terms of its false positive
rate, its ability to correctly group and classify anomalies,
and its ability to perform detection on web request logs
in real-time. All experiments were conducted on a Pen-
tium IV 1.8 GHz machine with 1 GB of RDRAM.
7.1. False Positive Rate
In order to evaluate the false positive rate of the
anomaly detector, data sets from two universities, TU
Vienna and UCSB, were analyzed by the system. To
this end, a client was written to replay the requests to
a honeypot web server while a misuse detection system
sniffed a link between the client and server. All requests
corresponding to reported attacks were stripped from the
data set. Also, since many of the attacks were intended
for Microsoft IIS while the data sets were produced by
the Apache web server, many attacks were stripped out
simply by removing requests for documents that did not
exist.
The detection system itself was conﬁgured with an
initially empty anomaly signature set, and default learn-
ing, detection, and similarity thresholds were used. The
learning phase was performed over the ﬁrst 1,000 ex-
amples of a speciﬁc web application attribute, at which
point the attached proﬁle was switched into detection
mode. During detection mode, any alerts reported by
the system were ﬂagged as false positives, due to the as-
sumption that the data set was attack-free. The results of
the experiment are shown in Table 1.
During analysis of the TU Vienna data set, the de-
tection system produced 14 alerts over 737,626 queries,
resulting in a quite low false positive rate. We believe
this attests to the ability of the anomaly detection mod-
els to accurately capture the “normal” behavior of at-
tribute values during the learning phase. The addition
of the anomaly generalization and aggregation compo-
nents, however, improved this even further by allow-
ing the system to collapse those 14 alerts into 2 groups.
When these groups were examined, we found that each
of the groups indeed comprised related alerts. For the
ﬁrst, an IMAP mailbox was repeatedly accessed through
the imp webmail application, which had not been ob-
served during the learning phase. In response, the token
ﬁnder generated an alert, and the resulting anomaly sig-
nature allowed the system to group the alerts together in
a logical manner.1 For the second group, developers of
a custom web application passed invalid values to an at-
tribute during test invocations of their program. In this
case, the attribute length model detected an anomaly,
and the resulting anomaly signature correctly grouped
subsequent variations on the input errors with the ﬁrst
instance.
The results of the generalization and aggregation
components during analysis of the UCSB data set were
even more dramatic. The detection system reported 513
alerts over 35,261 queries, resulting in a false positive
rate several orders of magnitude greater than the TU Vi-
enna data set. However, due to generalization and ag-
gregation, the 513 alerts were partitioned into 3 groups.
Manual inspection of the aggregated alerts demonstrated
that, as in the case of the TU Vienna data set, the groups
were again comprised of related alerts. The ﬁrst group
was composed of a series of anomalous queries to the
whois.pl user lookup script, which expects a name
attribute with a valid username as the value.
In this
case, the grouped alerts all possessed the name attribute
value teacher+assistant++advisor, possibly
as the result of a bad hyperlink reference to the script
from elsewhere on the department website. In this case,
the character distribution model detected an anomalous
number of “a” characters. The second group was iden-
tical in nature to the ﬁrst group, except that the name ar-
gument value was dean+of+computer+science.
For this group, the character distribution detected an
anomalous number of “e” characters. The ﬁnal group
was composed of several alerts on an optional argument
to the whois.pl script named showphone, which
takes either a yes or no value as an argument. In this
case, the alerts were attributed to an uppercase YES,
1Incidentally, this would be a reasonable case to put the associated
models back into the learning phase, in order to incorporate the char-
acteristics of the legitimate value into the attribute proﬁle.
Table 1. False positive results.
Data set
TU Vienna
UCSB
Queries
737,626
35,261
False positives
False Positive Rate Groups Grouped False Positive Rate
14
513
1.90 × 10−5
1.45 × 10−2
2
3
3.00 × 10−6
8.50 × 10−5
Table 2. Attack classiﬁcation results.
Attack
csSearch
htmlscript
imp
phorum
phpnuke
webwho
Detected? Variations Groups
Alerting Models
Yes
Yes
Yes
Yes
Yes
Yes
10
10
10
10
10
10
1
1
1
1
1
1
Length, Char. Distribution
Length, Structure
Length, Char. Distribution
Length, Char. Distribution, Token
Length, Structure
Length
Characterization
Cross-site scripting
Directory traversal
Cross-site scripting
Buffer overﬂow
SQL injection
None
which the token ﬁnder correctly detected as anomalous.
To evaluate the effectiveness of the attack inference
heuristics, a number of attacks comprising the different
attack classes that the system claims to detect, were in-
jected into the TU Vienna data set. This data set was
chosen because legitimate invocations of the vulnera-
ble applications were previously present in the access
log. Ten variations of each distinct attack were injected
throughout the data set, utilizing mutation techniques
from the Sploit framework [22]. The detection system
was conﬁgured with exactly the same parameters as in
the previous experiment. The results of the experiment
are shown in Table 2.
From the experimental results, we ﬁrst note that all
instances of each attack were determined to be anoma-
lous by the anomaly detector. This is to be expected,
as the main focus of this work is on the effectiveness
of grouping and characterizing related anomalous alerts,
and not on improving the ability of the system to detect
raw anomalies. In each case, all instances of a given at-
tack were classiﬁed into one group. In addition, each
of the groups was correctly characterized as belonging
to the proper attack class. The only attack that was not
characterized by the attack inference heuristics was the
webwho attack. This, however, is correct behavior from
the system, as the webwho attack exploited an input val-
idation error for which the system includes no charac-
terization heuristics.
It is important to note, however,
that the anomaly was still detected, and further varia-
tions were grouped correctly. Indeed, although a variety
of models provided the initial decision that the request
was anomalous, in each case the anomaly signature gen-
eration procedure was able to match subsequent varia-
tions of the same attack. We believe that this demon-
strates the power our anomaly generalization technique,
speciﬁcally with respect to its ability to group similar
anomalies.
7.2. Performance
The performance of the detection system was evalu-
ated in terms of both elapsed processing time and mem-
ory usage when run on both attack-free data sets from
TU Vienna and UCSB. Both metrics are important for
the real-world applicability of this system, since in the
ideal case it would be run in real-time on hardware avail-
able to most web site operators. The same parameters
used for the false positive evaluation were used for this
experiment. Ten runs were performed for each data set,
and the elapsed times were averaged. The results of the
time required for analysis by the system are displayed in
Table 3.
For both data sets, the detection system was able to
Table 3. Detection performance results (time).
Data set
TU Vienna
UCSB
Requests
737,626
35,261
Request Rate
0.107095 req/sec
0.001360 req/sec
Elapsed Analysis Time Analysis Rate
788.06 req/sec
550.95 req/sec
934 sec
64 sec
maintain a processing rate orders of magnitude above
the rate of client requests logged by the web server.
For instance, in the case of the TU Vienna data set,
the request analysis was performed approximately 7,000
times as quickly as actual requests were being logged.
From this, we conclude that for many sites, the detection
system is capable of performing its analysis in real-time.
In addition to CPU usage, an analysis of the memory
utilization of the system was performed. The results of
this evaluation showed that the system did not require
substantial memory resources once the proﬁles were es-
tablished. The details of the memory usage evaluation
are not provided for the sake of space.
8. Conclusions and Future Work
This paper presented an approach that addresses the
limitations of anomaly-based intrusion detection sys-
tems by using both generalization and characterization
techniques. Generalization is used to create a more
abstract description of an anomaly that enables one to
group similar attacks. Characterization is used to in-
fer the class of attack that is associated with a group of
anomalies. Using these two techniques, it is possible to
reduce the time required by an administrator to make de-
cisions about the nature of the anomalies (actual attacks
versus false positives) and their criticality. Furthermore,
the generalization and characterization presented can as-
sist application developers in pinpointing the location
and nature of previously unknown vulnerabilities.
One possible drawback of the architecture occurs if
an attack that has been successfully detected is grouped
with attacks that will be considered false positives. If the
group of attacks is dropped by the system administrator,
then the real attack is not identiﬁed as such and becomes
a false negative.
We developed a system that implements anomaly sig-
nature generation and attack class inference, and we
tested it on real-world data collected at two universities.
The results shows that the proposed techniques are able
to correctly generalize and characterize attacks, consid-
erably reducing the effort needed to analyze the output
of the intrusion detection system.
The promising results of our initial experiments sug-
gest that the generalization and characterization tech-
niques can be extended to other domains, such as the
arguments of system calls issued by critical applications.
Future research will explore these new domains and the
general applicability of our techniques.
We will also investigate whether the attack inference
technique can be improved, either by using more so-
phisticated heuristics or by relying on different decision
models. For example, we plan to explore whether attack
characterization can be expressed as a Bayesian network
where the model outputs are used as evidence nodes.
Finally, we also plan to investigate whether evalua-
tion of the system using alternative metrics increases the
precision of our characterization of the system’s effec-
tiveness in reducing the effective false positive rate.
Acknowledgments
This research was supported by the Army Research
Ofﬁce, under agreement DAAD19-01-1-0484, and by
the National Science Foundation, under grants CCR-
0238492 and CCR-0524853.
References
[1] M. Almgren, H. Debar, and M. Dacier. A Lightweight
Tool for Detecting Web Server Attacks. In Proceedings
of the ISOC Symposium on Network and Distributed Sys-
tems Security, San Diego, CA, February 2000.
[2] M. Almgren and U. Lindqvist. Application-Integrated
In Proceed-
Data Collection for Security Monitoring.
[15] L. Portnoy, E. Eskin, and S. Stolfo. Intrusion Detection
with Unlabeled Data Using Clustering. In Proceedings of
ACM CSS Workshop on Data Mining Applied to Security,
Philadelphia, PA, November 2001.
[16] M. Roesch. Snort - Lightweight Intrusion Detection for
Networks. In Proceedings of the USENIX LISA ’99 Con-
ference, Seattle, WA, November 1999.
[17] A. Stolcke and S. Omohundro.
Inducing Probabilistic
Grammars by Bayesian Model Merging. In Conference
on Grammatical Inference, 1994.
[18] K.M.C. Tan, K.S. Killourhy, and R.A. Maxion. Under-
mining an Anomaly-Based Intrusion Detection System
Using Common Exploits. In Proceedings of the 5th In-
ternational Symposium on Recent Advances in Intrusion
Detection, pages 54–73, Zurich, Switzerland, October
2002.
[19] E. Tombini, H. Debar, L. Me, and M. Ducasse. A Se-
rial Combination of Anomaly and Misuse IDSes Applied
to HTTP Trafﬁc.
In Proceedings of the Twentieth An-
nual Computer Security Applications Conference, Tuc-
son, Arizona, December 2004.
[20] Thomas Toth and Christopher Kruegel. Accurate Buffer
Overﬂow Detection via Abstract Payload Execution. In
5th Symposium on Recent Advances in Intrusion Detec-
tion (RAID), 2002.
[21] G. Vigna, W. Robertson, V. Kher, and R.A. Kemmerer.
A Stateful Intrusion Detection System for World-Wide
Web Servers.
In Proceedings of the Annual Computer
Security Applications Conference (ACSAC 2003), pages
34–43, Las Vegas, NV, December 2003.
[22] Giovanni Vigna, William Robertson,
and Davide
Balzarotti. Testing Network-based Intrusion Detection
Signatures Using Mutant Exploits. In 11th ACM Confer-
ence on Computer and Communications Security (CCS),
2004.
[23] D. Wagner and P. Soto. Mimicry Attacks on Host-Based
Intrusion Detection Systems. In Proceedings of the 9th
ACM Conference on Computer and Communications Se-
curity, pages 255–264, Washington DC, USA, November
2002.
ings of Recent Advances in Intrusion Detection (RAID),
LNCS, pages 22–36, Davis, CA, October 2001. Springer.
[3] C. Warrender and S. Forrest and B.A. Pearlmutter. De-
tecting Intrusions using System Calls: Alternative Data
Models. In IEEE Symposium on Security and Privacy,
pages 133–145, 1999.
[4] K. Coar and D. Robinson. The WWW Common Gateway
Interface, Version 1.1. Internet Draft, June 1999.
[5] Common Vulnerabilities and Exposures.
http://
www.cve.mitre.org/, 2005.
[6] D.E. Denning. An Intrusion Detection Model.
IEEE
Transactions on Software Engineering, 13(2):222–232,
February 1987.
[7] S. Forrest. A Sense of Self for UNIX Processes. In Pro-
ceedings of the IEEE Symposium on Security and Pri-
vacy, pages 120–128, Oakland, CA, May 1996.
[8] A.K. Ghosh, J. Wanken, and F. Charron. Detecting
Anomalous and Unknown Intrusions Against Programs.
In Proceedings of the Annual Computer Security Appli-
cation Conference (ACSAC’98), pages 259–267, Scotts-
dale, AZ, December 1998.
[9] C. Ko, M. Ruschitzka, and K. Levitt. Execution Moni-
toring of Security-Critical Programs in Distributed Sys-
tems: A Speciﬁcation-based Approach. In Proceedings
of the 1997 IEEE Symposium on Security and Privacy,
pages 175–187, Oakland, CA, May 1997.
[10] C. Kruegel, T. Toth, and E. Kirda. Service Speciﬁc
Anomaly Detection for Network Intrusion Detection. In
Symposium on Applied Computing (SAC). ACM Scien-
tiﬁc Press, March 2002.
[11] C. Kruegel and G. Vigna. Anomaly Detection of Web-
based Attacks.
In Proceedings of the 10th ACM Con-
ference on Computer and Communication Security (CCS
’03), pages 251–261, Washington, DC, October 2003.
ACM Press.
[12] W. Lee, S. Stolfo, and P. Chan. Learning Patterns from
Unix Process Execution Traces for Intrusion Detection.
In Proceedings of the AAAI Workshop: AI Approaches to
Fraud Detection and Risk Management, July 1997.
[13] M. Mahoney and P. Chan. Learning Nonstationary Mod-
els of Normal Network Trafﬁc for Detecting Novel At-
tacks.
In Proceedings of the 8th International Confer-
ence on Knowledge Discovery and Data Mining, pages
376–385, 2002.
[14] V. Paxson. Bro: A System for Detecting Network In-
truders in Real-Time. In Proceedings of the 7th USENIX
Security Symposium, San Antonio, TX, January 1998.