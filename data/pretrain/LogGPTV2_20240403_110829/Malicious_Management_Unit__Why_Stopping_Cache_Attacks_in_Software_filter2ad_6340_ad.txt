### Architectures and Translation Caches

Our analysis in this section extends the results presented in a short paper at a recent workshop [39]. We found that Intel's Page-Structure Caches, or split translation caches, are implemented in Intel Core and Xeon processors since at least the Nehalem microarchitecture. Specifically, on Intel Core and Xeon processors, we identified translation caches available for 32 Page Directory Entries (PDEs) and 4 Page Directory Pointer Table Entries (PDPTEs). In contrast, Intel Silvermont has only a single translation cache for 16 PDEs.

On AMD, the K10 architecture employs a 24-entry dedicated and unified page table cache, while the Bobcat architecture uses an 8 to 12 entry variant. Since the Bulldozer architecture, the L2 TLB has been repurposed to also host page table entries, allowing it to store up to 1024 PDEs on AMD Bulldozer and Piledriver, and up to 1536 PDEs on AMD Zen. Additionally, AMD Zen introduces another L2 TLB with 64 entries dedicated to 1G pages, allowing it to store up to 64 PDPTEs.

On ARM, low-power variants implement unified page table caches with 64 entries, while performance-oriented variants implement a translation cache with 16 PDEs on ARMv7-A and one with 6 PDPTEs on ARMv8-A. Overall, our results show that translation caches take very different and complex forms across contemporary microarchitectures. Therefore, our reverse engineering efforts are crucial and effective for devising practical MMU-based attacks and defenses.

### Reliability of Covert Channels

To evaluate the reliability of XLATE and compare it with state-of-the-art cache attacks, we implemented an LLC-based covert channel framework. In this framework, the sender and receiver assume the roles of the victim and the attacker, respectively. The receiver monitors specific cache lines using one of the cache attacks, while the sender accesses the cache line to transmit a one and does nothing to send a zero. To synchronize both the sender and the receiver, we dedicated 6 bits of the 19-bit word to sequence numbers. Additionally, we use 4-bit Berger codes to detect simple errors and prevent zero from being a legal value in our protocol, as it could be introduced by tasks being interrupted by the scheduler.

We used our framework to compare the raw bandwidth, the correct bandwidth, and the bit error rate between hardware threads on the same CPU core and between different CPU cores. Our results, presented in Figure 4, show that FLUSH + RELOAD achieved the highest bandwidth of around 40 KiB/s with the least noise. PRIME + PROBE performed slightly worse, with a bandwidth of about 8 KiB/s. FLUSH + FLUSH performed well on the cross-core setup with a bandwidth of about 4 KiB/s but much worse on the cross-thread setup with a bandwidth of only 500 bytes/s. This is due to the timing difference of flushing a cache line depending on the cache slice hosting it. Compared to other covert channels, XLATE + PROBE only reached a bandwidth of 900 bytes/s. While this is slower, the low error rate indicates that this is due to the higher latency of indirect MMU-mediated memory accesses rather than noisier conditions. This experiment demonstrates that XLATE provides a reliable channel and can be used to mount side-channel attacks in practical settings.

### Effectiveness of XLATE

To evaluate the effectiveness of XLATE, we mounted a side-channel attack against a real-world security-sensitive application. We focused our attack on OpenSSLâ€™s T-table implementation of AES, using OpenSSL 1.0.1e as a reference. This attack scenario has been extensively used to compare the performance of cache side-channel attacks in prior work (e.g., [8]).

The AES implementation in our version of OpenSSL uses T-tables to compute the cipher text based on the secret key \( k \) and plain text \( p \). During the first round of the algorithm, table accesses are made to entries \( T_j[p_i \oplus k_i] \) with \( i \equiv j \mod 4 \) and \( 0 \leq i < 16 \). As these T-tables typically map to 16 different cache lines, we can use a cache attack to determine which cache line has been accessed during this round. If \( p_i \) is known, this information allows an attacker to derive \( p_i \oplus k_i \), and thus, possible key-byte values for \( k_i \).

More specifically, by choosing \( p_i \) and using new random plain text bytes for \( p_j \), where \( i \neq j \), while triggering the attack, we can monitor the cache lines. Our results demonstrate that XLATE is effective in mounting side-channel attacks and can be used in practical settings.

### Reverse Engineering Results

Table 3 summarizes our reverse engineering results for the translation caches of 26 different microarchitectures, including various Intel, AMD, and ARM processors. These results highlight the diverse and complex nature of translation caches across contemporary microarchitectures, underscoring the importance of our reverse engineering efforts for both attacking and defending against MMU-based vulnerabilities.

---

This revised text is more structured, clear, and professional, making it easier to understand the technical details and the significance of the findings.