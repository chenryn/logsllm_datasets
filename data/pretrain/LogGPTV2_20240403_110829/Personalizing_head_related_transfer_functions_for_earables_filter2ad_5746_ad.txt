potential AoAs.
The key idea for disambiguating is to still utilize the time domain
shape of the channel. Since we cannot extract the left or right
channel, our key intuition is to compare the shape of the "relative"
channel. Suppose the left ear recording is 𝐿, and right ear 𝑅, in
the frequency domain. Then the relative channel is 𝐿
𝑅 . We can
also calculate the relative channel for all angle 𝜃 in the personal
HRTF template 𝐻𝑅𝑇 𝐹𝐿(𝜃)
𝐻𝑅𝑇 𝐹𝑅 (𝜃) . Ideally, for the correct 𝜃, these 2 relative
channels should match:
(10)
𝐿
𝑅
=
𝐻𝑅𝑇 𝐹𝐿(𝜃)
𝐻𝑅𝑇 𝐹𝑅(𝜃)
Since division are sensitive to errors when the denominator is small,
we change Equation (10) into a multiplication form:
𝐿 × 𝐻𝑅𝑇 𝐹𝑅(𝜃) = 𝑅 × 𝐻𝑅𝑇 𝐹𝐿(𝜃)
(11)
By plugging all the potential 𝐴𝑜𝐴𝑖’s (inferred from relative channel
peaks) into the above equation, and finding the one that gives the
closest LHS and RHS, we identify the true AoA.
.
Figure 14: Relative channel between left and right ear:
there are multiple channel taps due to poor signal auto-
correlation.
By now, we have covered the key system design ideas. We will then
show some system details.
4.6 Engineering and System Details
■ System frequency response compensation: Before perform-
ing HRTF measurements, the first step is to compensate for the
frequency response of the speaker and microphone pair. This is
important because any channel we estimated would intrinsically
embed this frequency response inside. We estimate frequency re-
sponse of the speaker and microphone pair by placing microphone
co-located with speaker and play a flat amplitude chirp signal.
■ Tackling room reflections: The traditional approaches to HRTF
measurement are conducted in echo-free acoustic chambers. Home
users obviously do not have access to such “anechoic” chambers.
However, we can eliminate room-level echoes as a pre-processing
step in UNIQ. The idea is simple: when users rotate the phone
around their heads, head diffraction and pinna multipath should
arrive earlier than room reflections. We eliminate the latter channel
taps to exclude room reflections.
■ Automatically correcting user gestures:
A user may not be able to rotate the phone around the head in the
very first attempts; practical problems can occur such as the arms
lowering, the phone spinning, etc. This can affect measurement
and downstream accuracy. UNIQ identifies such cases by detecting
that the estimated phone distance to head center 𝑟𝑖 in Equation
𝑖 in equation (2) is too
large. This triggers a message to the user to redo the measurement
exercise. With this, we are ready to move to system evaluation.
5 EVALUATION
Figure 15 shows our system setup. UNIQ is implemented on a Xiaomi
[11] smartphone and a Sound Professionals earphone (model: SP-
TFB-2) [1], which supports in-ear microphones. In-ear microphones
are becoming popular and can improve the HRTF quality since the
sounds will be recorded closer to the ear-drum. Since our phone
does not have a front-facing speaker, we connect the audio output
to a small external speaker. User wears the earphone and rotates
the smartphone (with pasted speaker) around her head.
(3) is too small, or the overall error𝑁
𝑖=1 𝛿2
.
Figure 15: System prototype. Left: experimental setup. Right:
zoom in to in-ear microphone
.
During the measurement process, we collect 100𝐻𝑧 IMU data from
the phone, and 96𝑘𝐻𝑧 sound recording from the in-ear microphone.
The speaker, microphone, and IMU are all synchronized. The data
processing pipeline runs on MATLAB. The ground-truth data for
smartphone (and head) locations are obtained from an overhead
camera installed on top of the user’s head.
145
0123Time10-3-101Amplitude Relative ChannelSIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
Zhijian Yang and Romit Roy Choudhury
Figure 16 shows the frequency response of our speaker microphone
pair. The response curve is unstable below 50𝐻𝑧 and stabilizes
reasonably over [100𝐻𝑧, 10𝑘𝐻𝑧]. This shows that our hardware is
not anything special; in fact, expensive phones and headphones
may exhibit better frequency response curves. Finally, given that
human ears are insensitive to sound below 100𝐻𝑧 [13], any standard
hardware platform should be adequate to run the UNIQ system.
Personalized HRTF Estimates
The HRTF is a vector that completely embeds the head/pinna’s
acoustic impulse response. An objective way to evaluate HRTF
estimate is to cross-correlate personalized HRTF vector with ground
truth. This will reveal how closely UNIQ matches the truth. Further,
plotting correlation between ground truth and global HRTF will
also reveal the improvement of personal over global HRTF.
.
Figure 16: Frequency response of our speaker-microphone
pair. Most hardware platforms exhibit such response curves,
if not better [31].
.
5.1 Results
Phone Localization Accuracy
Figure 17 plots the phone localization angular error in near-field.
The X-axis in Figure 17(a) plots the ground-truth polar angle of the
phone as viewed from the overhead camera. The Y-axis plots UNIQ’s
estimate of the polar angle as the user rotates her hand. Perfect
accuracy would mean that the plotted points would like on the 𝑋 =
𝑌 diagonal line. Evidently, UNIQ’s localization is consistently quite
accurate. Figure 17(b) plots the CDF; the median error is 4.8 degrees.
The error is mostly due to the difficulty of ensuring the phone’s
center is perfectly facing the user’s own head. Imperfection of the
acoustic diffraction model also partly contributes to the errors, but
less significantly. Only in rare cases, the phone’s localization error
climbs to 15 degrees because the volunteer’s movement has deviated
too much from the instructions. This adds to the downstream errors,
however, wee include these cases since they are a part of real-world
operating conditions.
.
Figure 17: Phone’s angular error for hand-rotation: (a) com-
parison with ground truth, (b) error CDF.
146
Figure 18: Cross-correlation between ground-truth versus
UNIQ, global, and another measurement of ground-truth
HRIR, for (a) left ear, (b) right ear.
Figure 18 shows the cross-correlations between estimated and gen-
eral HRIR against the ground-truth HRIR (error bars represent
standard division). We also show the cross-correlation between 2
separate measurements of ground-truth HRIR as a reference upper
bound. Figure 18(a) plots for the left ear, and Figure 18(b) for the
right; in both cases, the sound source was placed on the left of
the head. Evidently, UNIQ’s estimated HRIR achieves an average
correlation of 0.74 and 0.71 for the left and right ear, respectively.
In contrast, the general HRIR can attain average correlation of 0.41
for both ears. This is a key result, illustrating that:
1. Global HRIRs significantly differs from personalized ones.
2. UNIQ considerably closes this gap (by a factor of ∼ 1.75𝑋)
For the right ear, our estimated HRTF exhibits higher accuracy
when the angle is ≈0 or ≈180 degrees, but degrade around ≈90
degrees. This is because when the phone is at 90 degrees, the right
ear microphone is exactly at the opposite side of the speaker, sig-
nificantly suppressing the SNR of the received signal, resulting in
lower accuracy. Higher quality earphones would certainly benefit
in these cases.
Variation across Different Volunteers
Figure 19 shows the mean correlation for 5 volunteers (who wore
the earphones and performed the smartphone rotation in front of
102103104Frequency (Hz)-60-40-200Amplitude (dB) Frequency Response050100150Groundtruth Angle050100150Estimated Angle01020Angular Error (Degrees)00.20.40.60.81CDF050100150Angle (Deg)00.20.40.60.81Correlation UNIQ Global HRIR Gnd HRIR050100150Angle (Deg)00.20.40.60.81Correlation UNIQ Global HRIR Gnd HRIRPersonalizing Head Related Transfer Functions for Earables
SIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
their head). The two graphs – (a) and (b) – are again for the left and
right ear, respectively. The personalization gain is consistent across
all. Of course, UNIQ estimates the HRTF slightly less accurately
for volunteers 4 and 5 compared to volunteers 1, 2, and 3. This is
because when holding the phone, volunteers 4 and 5 moved the
phone a bit too close to the back of their heads, due to their arm
movement constraints, (even after automatic correction procedure
of UNIQ), leading to sub-optimal estimates in the diffraction model,
and downstream far-field estimations.
.
Figure 19: Average cross-correlation between estimated /
global HRIR and the groundtruth across different volun-
teers for (a) left ear, (b) right ear
While the above results are statistical, Figure 20 zooms into few
raw HRTFs in the time domain (called head related impulse response,
HRIR). Specifically, the figure shows the (a) best case, (b) average
case, and the (c) worst case estimation of UNIQ’s HRIR in compari-
son to the general HRIR. Evidently, across all 3 cases, our estimated
HRIRs always decode the channel taps at correct locations; the
general HRIR makes frequent mistakes. This is primarily due to
UNIQ’s ability to capture per-user head and pinna multipath, which
are obviously different from one human to another.
Application of HRTF to AoA
A more accurate HRTF implies that ambient sounds can now be
better analyzed spatially, such as a hearing aid identifying the
direction of an incoming sound. We put this to test by comparing
the AoA error when applying the personalized HRTF from UNIQ,
versus the global HRTF. We begin by playing a known source signal
(from different locations in the far field) and estimating AoA.
Figure 21 plots the CDF of angular AoA error. With UNIQ’s person-
alized HRTF producing a median error of 7.8◦, compared to global
HRTF’s median error of 45.3◦. More importantly, the maximum
error of personalized HRTF is 60◦ while the maximum for global
HRTF is > 150◦. This is because a global HRTF suffers considerably
.Figure 20: Sample example HRIRs for (a) best case, (corr =
0.96), (b) average case, (corr = 0.85), (c)worst case, (corr = 0.43).
Global HRIRs almost always inferior.
.
Figure 21: AoA estimation with personalized and global
HRTF using a known source signal. Global HRTF performs
poorly since measured signals deviate from HRTF estimate.
from “front-back ambiguity”, i.e., it does not reliably differentiate
between sounds arriving symmetric front and back angles, such as
45◦ north-east and 45◦ south-east. In fact, in 29% of our experiments,
using global HRTF caused a front-back confusion.
We repeat the above experiments with unknown source signals,
such as when Alice calls Bob (and Bob is wearing a hearing aids
or earphones). Alice’s voice signal is unknown to Bob’s device,
however, the ear-devices can still decode Alice’s direction better.
We tested with a variety of “unknown” signal categories, such as
white noise, music, and speech. Figure 22(a)-(c) shows the CDF
of AoA error for each of these categories. The personalized HRTF
offers consistent gains across all types of signals; the distribution
has a somewhat heavy tail because, with unknown signals, the front-
back ambiguity begins to affect UNIQ as well. The 80 percentile AoA
error with personalized HRTF is within 20◦ for music and white
noise. The improvement with speech is smaller because speech is
dominated by lower frequencies, thus less sensitive to HRTF errors.
Figure 22(d) zooms into the front-back cases, since these are crucial
for real applications (we do not want Bob to hear a virtual voice that
comes from a wrong direction). With UNIQ, the average front-back
accuracy is 82.8% — white noise is highest at 87.2% and speech
signals are lowest at 72.8%. This is because white noise spans over a
large frequency range, offering more information about the acoustic
channel; in contrast, speech signals are concentrated on base and
harmonic frequencies, revealing less information about the channel.
For global HRTF, the front-back accuracy is 59.8%.
147
12345Volunteer #00.20.40.60.81Correlation UNIQ Global HRIR12345Volunteer #00.20.40.60.81Correlation UNIQ Global HRIR050100150Amplitude050100150Samples050100150 UNIQ Groundtruth Global050100150200Far-field AoA Error, Known Source (Deg)00.51CDF UNIQ Global HRTFSIGCOMM ’21, August 23–27, 2021, Virtual Event, USA
Zhijian Yang and Romit Roy Choudhury
.
Figure 22: (a)-(c): AoA estimation error, (d): front-back identification accuracy for an unknown source signal.
6 RELATED WORK
■ Smart earphones and earable computing: With the develop-
ment of mobile computing technologies [19], smart earphones are
becoming popular these days. Past works have looked at enabling
spatial audio[18, 21, 26, 51] and acoustic augmented reality [15, 54],
step counting [44] and motion tracking [53], user authentication
[20] and health monitoring [42] on sensor embedded smart ear-
phones. This paper, however, adds another building block - personal
HRTF to smart earphones. We believe this is a step towards even
better functionality on future earables: e.g., more immersive spatial
audio, and smarter beamforming, etc.
■ HRTF personalization: HRTF personalization has gained in-
terest in recent years due to the development of VR and AR related
technology. Traditionally people use large speaker arrays inside
acoustic chambers to measure HRTF [17, 22], which is obviously not
scalable. Some newer work [27, 29, 33, 36, 45, 58] tried to approach
this problem without acoustic hardware from the pure signal pro-
cessing perspective. They used acoustic simulation to generate the
specific personalized HRTF for a given user from 3D scans of human
head. These methods are reported to be slow and computationally
heavy [28]. Moreover, obtaining an accurate 3D scan is also not easy
[57]. Few attempts utilize mobile devices for HRTF measurement.
[12] is the closest to our work. Their method, however, requires
an external speaker placed on the table, and need to user to tie the
smartphone onto the head, which is not portable. Moreover, their
setup can be polluted by environmental multipath. Our approach,
on the contrary, is novel, fast, and scalable. Users can get their
personalized HRTF by simply rotating the phone around the head,
in a couple of minutes.
■ Acoustic/wireless sensing and sound source AoA estima-
tion: Acoustic/wireless sensing and sound source AoA estimation
is a hot research topic in mobile, acoustic, and robotic community