if s_pos >= 0:
buf_skipped.remove(s_candidate_syscall)
return s_candidate_syscall
curr_syscall)
Listing 1. Flexible matching algorithm
(pseudo code).
The algorithm for performing ﬂexible system call
matching in replay mode is simple (refer to Listing 1).
We use two queues to keep track of short-lived differ-
ences in the executions. One queue, called buf extra,
records the system calls that have been invoked by the
program but that were not found in the log. The other
queue, called buf skipped, holds those system calls
that were in the log trace but were not invoked in the cur-
rent execution.
At each system call invocation, our algorithm com-
pares this system call (curr syscall) with the one at
the current head of the log. If the algorithm ﬁnds a match,
the algorithm returns this system call and advances one
step in the log (line 18).
If the ﬁrst entry in the log does not match the cur-
rent system call, the algorithm ﬁrst searches the queue of
system calls that were previously skipped. If a match is
found, it is removed from the queue and is returned to the
corresponding handler (lines 22–30).
If no match is found at the head of the log or in the
skip buffer, it may be the case that additional system calls
were executed in log mode that were not invoked in this
execution. Then, we try to ﬁnd a match in the log by
skipping over one or more of the calls at the head of log
(a sort of look-ahead operation). If this procedure yields
a match, then those system calls in the log that needed to
be skipped are added to buf skipped, and the match
is returned to our corresponding handler (lines 32–37).
If no match is found, i.e., the current system call was
not invoked in log mode, it is added to buf extra and
passed to the operating system.
Our algorithm uses two conﬁgurable parameters, L
and M. L is used to detect deviations in the behavior of
two executions. More precisely, if at any point during
the replay, the number of system calls that have been
skipped or added with respect to the log trace reaches
L, then the algorithm concludes that the current exe-
cution of the application is different than in log mode
(lines 4–6). To avoid the accumulation of short-lived, lo-
calized differences, we remove system calls inserted in
the buf skipped and buf extra queues after M ex-
ecutions of the matching algorithm (lines 8–11, we do
not show the implementation of the expire function
for sake of space).
4
Implementation
Our approach requires a logging infrastructure that
is capable of recording and replaying Windows system
calls inside and outside of virtual machines. Here, we
will describe our implementation of this infrastructure
and a number of interesting, technical challenges that it
required to tackle.
4.1 Log and Replay Infrastructure
Our log and replay infrastructure consists of two parts:
a user-space application and a kernel driver. The user-
space application is responsible to load and start the
driver and to control its operations by sending speciﬁc
I/O control codes. It is also responsible to start the pro-
cess that has to be analyzed, to communicate the process
ID of the sample to the driver, and to receive and store
the data generated during the logging phase.
The driver is the core part of our system. It is responsi-
ble to trap all the system calls and either log or replay all
the information exchanged between the Windows kernel
and the monitored application. This is achieved by hook-
ing the System Service Descriptor Table (SSDT). Each
entry in the SSDT contains the entry point of a Windows
system call, so when an application invokes such a call,
the SSDT is queried to ﬁnd the address of the function
that is responsible to serve it.
When the driver is loaded, every entry in the SSDT
that contains a system call address is overwritten with
an address that points to one of our handler functions.
However, since it is still necessary to be able to invoke
the original functionalities, the addresses of the original
system calls are stored in a backup table (and restored
when the kernel module is removed).
It would have been extremely impractical to manually
write each of the 283 function handlers that wrap all the
Windows XP system calls. In addition, the function pa-
rameters often contain complex data types such as point-
ers to structures (that sometimes recursively contain ref-
erences to other structures), making a manual approach
even more complicated.
To address these problems, we implemented a tool
that automatically generates the source code for the han-
dler functions. This generator tool receives as input the
system call declarations and the deﬁnition of all the sys-
tem call arguments (especially, data structures). We ex-
tracted this information from the Windows Research Ker-
nel. Then, for each system call, our tool creates the
source code of two handler functions, one to be used in
log mode and the other in replay mode.
In log mode, all our system call handlers have the
same purpose: To dump all the data that is exchanged
between the application and the kernel, working like a
proxy between the user-space program and the original
system call handlers. This is done by recursively log-
ging the content of all the parameters before and after
the original system call is invoked. Additionally, the re-
turn value of the system call is also logged. The kernel
driver contains a buffer that is used by the handler func-
tions to temporarily store all the parameter values of the
system calls. For performance reasons, the driver does
not write the contents of the buffer into a ﬁle. Instead,
the user-mode program contacts the driver at given inter-
vals, copies the content of the buffer into user space, and
ﬁnally stores it in a binary log ﬁle.
In replay mode, the driver has two main tasks: To pro-
vide the application with the same input data that was
stored during the execution in the reference environment,
and to analyze the application behavior looking for devi-
ations from the expected one.
As explained in Section 3, it is not possible to blindly
intercept all the system calls and replay their parameters.
Some functions have important side effects in the kernel
(e.g., when the program requires to allocate new mem-
ory) and, therefore, they must be forwarded to the orig-
inal handler to be processed. Other system calls (e.g.,
when the program reads the value of a key from the reg-
istry) can instead be safely replayed by substituting all
the out parameters and the return value with the corre-
sponding values extracted from the log ﬁle. We say that
the handler forwards a system call in the former case, and
replays it in the latter.
Finally, the last task of the driver during the replay
phase consists of monitoring the application behavior for
possible deviations, which is done by using the ﬂexible
matching algorithm described in Section 3.
In the rest of this section, we will describe a number
of practical aspects of our log and replay infrastructure.
4.2 Handle Consistency
In Windows, handles are opaque integers that are used
as an abstraction to provide a uniform interface to ker-
nel objects. Depending on the context in which they are
used, handles may refer to ﬁles, registry keys, processes,
timers, events, communication ports, etc. Since we re-
play some of the system calls and we let the operating
system execute others, in replaying mode, an application
will have two kind of handles: live handles that refer to
existing objects in the kernel, and replayed handles that
were retrieved from the log ﬁle and passed to the applica-
tion by one of our replaying function handler. For exam-
ple, if the application tries to open a ﬁle, we intercept the
OpenFile system call and we replay all the outgoing
parameters, including the FileHandle, i.e., the refer-
ence to be used by the program for any further operations
on the ﬁle. However, since the OpenFile system call is
intercepted by our driver and it is never received by the
kernel, the handle we return does not reﬂect any actual
object in kernel memory.
The problem arises because certain system call wrap-
pers (e.g., the wrapper for Close) can operate on both
kinds of handles. To operate correctly, these system calls
need to distinguish if they are passed a live handle (which
cannot be replayed) or a replayed handle (which cannot
be forwarded to the OS). Therefore, our system main-
tains a list of all replayed handles. Then, when a system
call wrapper receives a handle that is not in the list of
replayed handles, it simply forwards the call to the oper-
ating system.
4.3 Networking
Windows does not have special system calls dedi-
cated to networking operations. Instead, most of func-
tionalities are exported using an undocumented interface
through NtDeviceIOControlFile, a generic sys-
tem call that is used by user-space applications to com-
municate with device drivers.
NtDeviceIOControlFile has
two general-
purpose, opaque parameters, called InputBuffer
and OutputBuffer, which are used to exchange
information between the application and the driver. The
speciﬁc data and the format of these parameters depend
on the functionality required by the application. To
correctly implement our network handlers, we had to
reverse engineer the parameters used by the most com-
mon network operations and understand their formats
and semantics. For instance, when the RECV function is
invoked, it requires the ﬁrst word of the input buffer to
be a pointer to a data structure in the process memory
that contains (among other data) a pointer to a byte array
that will store the data received from the network socket.
In replay mode, the driver analyzes the parameters
of the NtDeviceIOControlFile.
If the function
speciﬁed by NtDeviceIOControlFile is one of the
functions that our tool supports, then the correspond-
ing handler is invoked with the values from the log
ﬁle (thus, replaying the network operation that was re-
quested). Otherwise, the system call is simply forwarded
to the operating system. This avoids disrupting services
using the NtDeviceIOControlFile interface that
we have not reverse engineered. We have currently im-
plemented support for TCP sockets. Support for UDP
system calls could be added in a similar way.
4.4 Deferred Results
An additional issue that arises with logging and re-
playing network trafﬁc is that networking system calls
often return before results are available (e.g., before the
data requested from the network is ready to be sent to
the user-space program). This phenomenon is referred to
as deferred results and occurs commonly also with ﬁle
system-related system calls.
More precisely, whenever a system call returns a
STATUS PENDING result, it means that the required
action was successfully initiated but the results are not
yet available to the application. Then,
the program
thread has to wait until the operation is completed by
invoking NtWaitForSingleObject (or the similar
NtWaitForMultipleObjects) on the event han-
dler that was speciﬁed when the operation was initially
requested.
To log deferred results, we follow a two-step strat-
egy. First, when a system call handler has some of its
output parameters deferred, it simply stores the memory
location of each deferred parameter to an internal De-
ferred Parameters List (DPL). The second step occurs in
the handler of the NtWaitForSingleObject system
call. The handler forwards the call to the OS. If the result
is STATUS SUCCESS, it means that the deferred data is
now available. Then, the values for the parameters that
were saved in the DPL can be retrieved, and they are in-
serted into the correct position in the log.
Replaying deferred results is simple. In fact, when a
handler needs to replay a system call with deferred re-
sults, it immediately copies all the data (including the
values of deferred parameters) into its output param-
eters and returns it to the application. However,
to
prevent changing the application behavior, it also re-
plays the STATUS PENDING return code. This cre-
ates the impression for the application that certain pa-
rameters are indeed deferred (even though they have
already been copied to the application). Therefore,
the application synchronizes its execution using the
NtWaitSingleObjection system call, following
the same execution path that was followed in the refer-
ence environment.
4.5 Thread Management
Managing multi-threaded applications poses addi-
tional challenges.
In particular, in log mode, we need
to ensure that all threads of the process under test are
properly identiﬁed so that we can distinguish system calls
made by different threads. To do this, our handler for the
NtCreateThread system call initializes a new log for
every new thread.
It then simply forwards the system
call to the OS, and records the thread ID assigned to this
new thread. We use the thread ID to uniquely associate a
thread to its log. Other call handlers then get the thread
ID of the currently executing thread and use it to store the
execution information in the correct log. Logs also store
the relative order in which threads invoked system calls.
handler
the
NtCreateThread system call
lets the OS handle
the call and associates the newly created threads (their
thread IDs) to the corresponding logs according to the
order of the NtCreateThread invocations. Other
system calls, similarly to what done in log mode, use
the thread ID to retrieve the correct log and replay
inputs. Absent race conditions between the threads,
this is sufﬁcient to correctly replay multiple threads.
While we did not ﬁnd malware samples that relied on
race conditions, it would be possible to handle these
cases, for example, by forcing that multiple threads are
scheduled in the same relative order, as outlined by the
authors of [35].
replay mode,
In
the
for
4.6 Memory Mapped Files
Memory mapping is a technique used in most mod-
ern operating system to map all or part of the content
of a ﬁle to a memory area in the process address space.
When a ﬁle has been mapped into memory, the program
can freely read and modify its content without invoking
any additional system call. This would prevent our sys-
tem to load and replay those operations. [29] proposes
an interrupt-based technique to intercept the access to a
memory-mapped area and dump its content whenever the
process modiﬁes this area. However, we found that in our
case, the most common uses of memory mapping can be
safely handled by simply forwarding the memory map to
the OS.
In Windows, memory mapping is commonly used by
the process loader to load dynamic libraries (DLLs) into
memory. Dynamic libraries should be considered an in-
put of the application and therefore should be, at least
in principle, logged and replayed by our system. How-
ever, it is much more efﬁcient to have the same copies of
the libraries in the reference and analysis environments
and let the application free to load them from disk. For
this reason, when our kernel module receives a request to
open or memory map a system library, it deactivates the
replay for the system call and it forwards the request to
the operating system.
A second very common use of memory mapping that
we observed in malicious samples is to create and later
execute an executable ﬁle. To address this problem, we
parse the log ﬁle that has been generated in the reference
environment. Every time we ﬁnd a ﬁle that is created by
the process and then memory-mapped, we remove from
the log the system calls responsible to open and create
the ﬁle. Then, during the replay phase, the matching al-
gorithm will be unable to ﬁnd a match for the system call
that was removed from the log ﬁle. Therefore, the system
call is added to queue of extra system calls, and it is for-
warded to the operating system. As a consequence, the
handle for the memory-mapped ﬁle is generated by the
operating system (i.e., it is a live handle), and other sys-
tem calls that operate on this handle will not be replayed
by our system. The practical effect is that the application
is going to create the ﬁle and operate on it also during the
replay mode.
4.7 Current Limitations
Implementing a system to correctly log and replay
system calls under Microsoft Windows is a very complex
task. In many cases, we had to rely on reverse engineer-
ing internal, undocumented Windows data structures and
behaviors.
The current prototype supports a large set of func-
tionalities and can be used to analyze real programs and
malware samples. However, as any prototype, it still has
some limitations that we can summarize in the following
areas:
• Multiple processes: The current prototype is not
able to log and replay the input if the program is
composed of multiple processes. In practice, if the
different processes do not communicate with each
other, we can still instruct our system to analyze one
process at a time.