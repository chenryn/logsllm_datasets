CEP 的实现包括 Esper【69】、IBM InfoSphere Streams【70】、Apama、TIBCO StreamBase 和 SQLstream。像 Samza 这样的分散式流处理元件，支援使用 SQL 在流上进行宣告式查询【71】。
#### 流分析
使用流处理的另一个领域是对流进行分析。CEP 与流分析之间的边界是模糊的，但一般来说，分析往往对找出特定事件序列并不关心，而更关注大量事件上的聚合与统计指标 —— 例如：
* 测量某种型别事件的速率（每个时间间隔内发生的频率）
* 滚动计算一段时间视窗内某个值的平均值
* 将当前的统计值与先前的时间区间的值对比（例如，检测趋势，当指标与上周同比异常偏高或偏低时报警）
这些统计值通常是在固定时间区间内进行计算的，例如，你可能想知道在过去 5 分钟内服务每秒查询次数的均值，以及此时间段内响应时间的第 99 百分位点。在几分钟内取平均，能抹平秒和秒之间的无关波动，且仍然能向你展示流量模式的时间图景。聚合的时间间隔称为 **视窗（window）**，我们将在 “[时间推理](#时间推理)” 中更详细地讨论视窗。
流分析系统有时会使用机率演算法，例如 Bloom filter（我们在 “[效能最佳化](ch3.md#效能最佳化)” 中遇到过）来管理成员资格，HyperLogLog【72】用于基数估计以及各种百分比估计算法（请参阅 “[实践中的百分位点](ch1.md#实践中的百分位点)”）。机率演算法产出近似的结果，但比起精确演算法的优点是记忆体使用要少得多。使用近似演算法有时让人们觉得流处理系统总是有损的和不精确的，但这是错误看法：流处理并没有任何内在的近似性，而机率演算法只是一种最佳化【73】。
许多开源分散式流处理框架的设计都是针对分析设计的：例如 Apache Storm、Spark Streaming、Flink、Concord、Samza 和 Kafka Streams 【74】。托管服务包括 Google Cloud Dataflow 和 Azure Stream Analytics。
#### 维护物化检视
我们在 “[资料库与流](#资料库与流)” 中看到，资料库的变更流可以用于维护衍生资料系统（如快取、搜寻索引和资料仓库），并使其与源资料库保持最新。我们可以将这些示例视作维护 **物化检视（materialized view）** 的一种具体场景（请参阅 “[聚合：资料立方体和物化检视](ch3.md#聚合：资料立方体和物化检视)”）：在某个资料集上衍生出一个替代检视以便高效查询，并在底层资料变更时更新检视【50】。
同样，在事件溯源中，应用程式的状态是透过应用事件日志来维护的；这里的应用程式状态也是一种物化检视。与流分析场景不同的是，仅考虑某个时间视窗内的事件通常是不够的：构建物化检视可能需要任意时间段内的 **所有** 事件，除了那些可能由日志压缩丢弃的过时事件（请参阅 “[日志压缩](#日志压缩)”）。实际上，你需要一个可以一直延伸到时间开端的视窗。
原则上讲，任何流处理元件都可以用于维护物化检视，尽管 “永远执行” 与一些面向分析的框架假设的 “主要在有限时间段视窗上执行” 背道而驰，Samza 和 Kafka Streams 支援这种用法，建立在 Kafka 对日志压缩的支援上【75】。
#### 在流上搜索
除了允许搜寻由多个事件构成模式的 CEP 外，有时也存在基于复杂标准（例如全文搜寻查询）来搜寻单个事件的需求。
例如，媒体监测服务可以订阅新闻文章 Feed 与来自媒体的播客，搜寻任何关于公司、产品或感兴趣的话题的新闻。这是透过预先构建一个搜寻查询来完成的，然后不断地将新闻项的流与该查询进行匹配。在一些网站上也有类似的功能：例如，当市场上出现符合其搜寻条件的新房产时，房地产网站的使用者可以要求网站通知他们。Elasticsearch 的这种过滤器功能，是实现这种流搜寻的一种选择【76】。
传统的搜寻引擎首先索引档案，然后在索引上跑查询。相比之下，搜寻一个数据流则反了过来：查询被储存下来，文件从查询中流过，就像在 CEP 中一样。最简单的情况就是，你可以为每个文件测试每个查询。但是如果你有大量查询，这可能会变慢。为了最佳化这个过程，可以像对文件一样，为查询建立索引。因而收窄可能匹配的查询集合【77】。
#### 讯息传递和RPC
在 “[讯息传递中的资料流](ch4.md#讯息传递中的资料流)” 中我们讨论过，讯息传递系统可以作为 RPC 的替代方案，即作为一种服务间通讯的机制，比如在 Actor 模型中所使用的那样。尽管这些系统也是基于讯息和事件，但我们通常不会将其视作流处理元件：
* Actor 框架主要是管理模组通讯的并发和分散式执行的一种机制，而流处理主要是一种资料管理技术。
* Actor 之间的交流往往是短暂的、一对一的；而事件日志则是持久的、多订阅者的。
* Actor 可以以任意方式进行通讯（包括回圈的请求 / 响应模式），但流处理通常配置在无环流水线中，其中每个流都是一个特定作业的输出，由良好定义的输入流中派生而来。
也就是说，RPC 类系统与流处理之间有一些交叉领域。例如，Apache Storm 有一个称为 **分散式 RPC** 的功能，它允许将使用者查询分散到一系列也处理事件流的节点上；然后这些查询与来自输入流的事件交织，而结果可以被汇总并发回给使用者【78】（另请参阅 “[多分割槽资料处理](ch12.md#多分割槽资料处理)”）。
也可以使用 Actor 框架来处理流。但是，很多这样的框架在崩溃时不能保证讯息的传递，除非你实现了额外的重试逻辑，否则这种处理不是容错的。
### 时间推理
流处理通常需要与时间打交道，尤其是用于分析目的时候，会频繁使用时间视窗，例如 “过去五分钟的平均值”。“过去五分钟” 的含义看上去似乎是清晰而无歧义的，但不幸的是，这个概念非常棘手。
在批处理中过程中，大量的历史事件被快速地处理。如果需要按时间来分析，批处理器需要检查每个事件中嵌入的时间戳。读取执行批处理机器的系统时钟没有任何意义，因为处理执行的时间与事件实际发生的时间无关。
批处理可以在几分钟内读取一年的历史事件；在大多数情况下，感兴趣的时间线是历史中的一年，而不是处理中的几分钟。而且使用事件中的时间戳，使得处理是 **确定性** 的：在相同的输入上再次执行相同的处理过程会得到相同的结果（请参阅 “[容错](ch10.md#容错)”）。
另一方面，许多流处理框架使用处理机器上的本地系统时钟（**处理时间**，即 processing time）来确定 **视窗（windowing）**【79】。这种方法的优点是简单，如果事件建立与事件处理之间的延迟可以忽略不计，那也是合理的。然而，如果存在任何显著的处理延迟 —— 即，事件处理显著地晚于事件实际发生的时间，这种处理方式就失效了。
#### 事件时间与处理时间
很多原因都可能导致处理延迟：排队，网路故障（请参阅 “[不可靠的网路](ch8.md#不可靠的网路)”），效能问题导致讯息代理 / 讯息处理器出现争用，流消费者重启，从故障中恢复时重新处理过去的事件（请参阅 “[重播旧讯息](#重播旧讯息)”），或者在修复程式码 BUG 之后。
而且，讯息延迟还可能导致无法预测讯息顺序。例如，假设使用者首先发出一个 Web 请求（由 Web 伺服器 A 处理），然后发出第二个请求（由伺服器 B 处理）。A 和 B 发出描述它们所处理请求的事件，但是 B 的事件在 A 的事件发生之前到达讯息代理。现在，流处理器将首先看到 B 事件，然后看到 A 事件，即使它们实际上是以相反的顺序发生的。
有一个类比也许能帮助理解，“星球大战” 电影：第四集于 1977 年发行，第五集于 1980 年，第六集于 1983 年，紧随其后的是 1999 年的第一集，2002 年的第二集，和 2005 年的第三集，以及 2015 年的第七集【80】[^ii]。如果你按照按照它们上映的顺序观看电影，你处理电影的顺序与它们叙事的顺序就是不一致的。（集数编号就像事件时间戳，而你观看电影的日期就是处理时间）作为人类，我们能够应对这种不连续性，但是流处理演算法需要专门编写，以适应这种时序与顺序的问题。