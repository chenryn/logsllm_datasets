2011/277, 2011, http://eprint.iacr.org/2011/277.
[39] S. Halevi and V. Shoup, “HElib – an implementation of homomorphic
encryption,” 2014, https://github.com/shaih/HElib.
[40] O. Goldreich, “Foundations of cryptography. basic applications,” 2004.
[41] N. P. Smart and F. Vercauteren, “Fully homomorphic SIMD operations,”
Designs, codes and cryptography, vol. 71, no. 1, pp. 57–81, 2014.
[42] M. T. Ahamed, A. Danielsson, S. Nemes, and H. Car´en, “MethPed: an R
package for the identiﬁcation of pediatric brain tumor subtypes,” BMC
bioinformatics, vol. 17, no. 1, p. 262, 2016.
[43] R. A. Philibert, N. Terry, C. Erwin, W. J. Philibert, S. R. Beach,
and G. H. Brody, “Methylation array data can simultaneously identify
individuals and convey protected health information: an unrecognized
ethical concern,” Clinical epigenetics, vol. 6, p. 28, 2014.
[44] E. E. Schadt, S. Woo, and K. Hao, “Bayesian method to predict
individual SNP genotypes from gene expression data,” Nature genetics,
vol. 44, pp. 603–608, 2012.
[45] E. A. Franzosa, K. Huang, J. F. Meadow, D. Gevers, K. P. Lemon,
B. J. Bohannan, and C. Huttenhower, “Identifying personal microbiomes
using metagenomic codes,” Proceedings of the National Academy of
Sciences, p. 201423854, 2015.
[46] M. Backes, P. Berrang, A. Hecksteden, M. Humbert, A. Keller, and
T. Meyer, “Privacy in epigenetics: Temporal linkability of MicroRNA
expression proﬁles,” in Proceedings of
the 25th USENIX Security
Symposium, 2016.
[47] M. Backes, P. Berrang, M. Humbert, and P. Manoharan, “Membership
privacy in MicroRNA-based studies,” in Proceedings of the 2016 ACM
SIGSAC Conference on Computer and Communications Security. ACM,
2016, pp. 319–330.
[48] D. A. Duverle, S. Kawasaki, Y. Yamada, J. Sakuma, and K. Tsuda,
“Privacy-preserving statistical analysis by exact logistic regression,” in
Security and Privacy Workshops (SPW), 2015 IEEE.
IEEE, 2015, pp.
7–16.
[49] E. Ayday, J. L. Raisaro, P. J. McLaren, J. Fellay, and J.-P. Hubaux,
“Privacy-preserving computation of disease risk by using genomic,
clinical, and environmental data,” in Presented as part of the 2013
USENIX Workshop on Health Information Technologies, 2013.
[50] M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, and T. Ristenpart,
“Privacy in pharmacogenetics: An end-to-end case study of personalized
warfarin dosing,” in Proceedings of the 23rd USENIX Security Sympo-
sium, 2014, pp. 17–32.
[51] R. Canetti, “Security and composition of multiparty cryptographic
protocols,” Journal of CRYPTOLOGY, vol. 13, no. 1, pp. 143–202, 2000.
[52] Y. Lindell and B. Pinkas, “Secure multiparty computation for privacy-
preserving data mining,” IACR Cryptology ePrint Archive, vol. 2008,
p. 197, 2008. [Online]. Available: http://eprint.iacr.org/2008/197
APPENDIX
Although we assume the same security model as in the work
by Bost et al. [23], we recap here the necessary concepts.
A. Secure two-party computation framework
Both, our protocol to change the ownership of an encryption
and the protocol to privately evaluate a random forest model
are two-party protocols. Let the two parties be denoted by
A and B. In order to show that all computations are done
privately, we assume the honest-but-curious (semi-honest)
model as described in [40].
973
Let f = (fA, fB) be a (probabilistic) polynomial function
and Π be a protocol computing f. Using A’s input a and B’s
input b, the two parties want to compute f (a, b) by applying
the protocol Π with the security parameter λ.
We denote the view of a party P ∈ {A, B} dur-
ing the execution of Π by the tuple VP (λ, a, b) =
t ) where r is P ’s random tape and
1 , . . . , mP
(1λ; a; rP ; mP
are the messages received by P . We deﬁne
mP
the outputs of parties A and B for the execution of Π as
OutΠ
B(λ, a, b). The global output is deﬁned
as the tuple OutΠ
A(λ, a, b) and OutΠ
(λ, a, b) = (OutΠ
A(λ, a, b), OutΠ
B(λ, a, b)).
1 , . . . , mP
t
To ensure the private, secure computation, we require that
whatever A can compute from its interactions with B can be
computed from its input and output, yielding the following
security deﬁnition.
Deﬁnition 1. A two-party protocol Π securely computes the
function f if there exist two probabilistic polynomial time
algorithms SA and SB (also called simulators) such that for
every possible input a, b of f,
{SA(1λ, a, fA(a, b)), f (a, b)} ≡c {VA(λ, a, b), OutΠ
and
{SB(1λ, b, fB(a, b)), f (a, b)} ≡c {VB(λ, a, b), OutΠ
(λ, a, b)}.
≡c means computational indistinguishability against proba-
bilistic polynomial time adversaries with negligible advantage
in the security parameter λ.
(λ, a, b)}
B. Cryptographic assumptions
In this section, we brieﬂy review the cryptographic assump-
N
N = {x ∈ Z∗
N ) | |N| = λ} and {(N, QNR
tions underlying the cryptosystems we use.
Assumption 1 (Quadratic Residuosity Assumption [36]).
Let N = p × q be the product of
two distinct odd
primes p and q. Let QR
N be the set of quadratic
|
residues modulo N and QNR
x is not a quadratic residue modulo N, but JN (x) = +1}
be the set of quadratic non residues, where JN (x) is the
Jacobi symbol.
{(N, QR
N ) | |N| = λ} are
computationally indistinguishable with respect to probabilistic
polynomial time algorithms.
Assumption 2 (Decisional Composite Residuosity Assump-
tion [37]). Let N = p× q with |N| = λ be the product of two
distinct odd primes p and q. We call z a Nth residue modulo
N 2 if there exists y ∈ Z
N 2 such that z = yN mod N 2.
Nth residues and non Nth residues are computationally
indistinguishable with respect to probabilistic polynomial time
algorithms.
Assumption 3 (RLWE [38]). Let f (x) = xd + 1 where d =
d(λ) is a power of 2. Let q = q(λ) ≥ 2 be an integer. Let
R = Z[x]/(f (x)) and let Rq = R/qR. Let χ = χ(λ) be a
distribution over R. The RLW Ed,q,χ problem is to distinguish
between two distributions: In the ﬁrst distribution, one samples
(ai, bi) uniformly from R2
q. In the second distribution, one ﬁrst
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:45 UTC from IEEE Xplore.  Restrictions apply. 
draws s ← Rq uniformly and then samples (ai, bi) ∈ R2
by sampling ai ← Rq uniformly, ei ← χ, and setting bi =
ai·s+ei. The RLW Ed,q,χ assumption is that the RLW Ed,q,χ
problem is infeasible.
q
C. Modular Sequential Composition
In order to ease the security proof of our construction, we
rely on sequential modular composition as deﬁned in [51]. The
idea is that two parties run a protocol Π and use calls to an
ideal functionality f while running Π. This can be imagined
as A and B privately computing f by sending their inputs
to a trusted third party T and receiving the results from it.
If we can now show that Π respects security and privacy in
the honest-but-curious model and if we have a protocol ρ that
securely and privately computes f in the same model, we can
replace f by executions of ρ in Π. The resulting protocol Πρ
is then still secure in the aforementioned model.
We call (f1, . . . , fm)-hybrid model the semi-honest model
augmented with an incorruptible trusted party T for evaluating
the functionalities. The parties A and B run a protocol Π that
contains calls to T for these functionalities. For each call,
the parties send their input to T and wait until they receive
the respective results. It is crucial that both parties must not
communicate until receiving the result, since we only consider
sequential composition here. T does not keep state between
different calls to the functionalities. Therefore the protocol
may contain multiple calls even for the same function, which
all are independent.
Let Π be a two-party protocol in the (f1, . . . , fm)-hybrid
model and ρ1, . . . , ρm be secure protocols in the semi-honest
{ρ1,...,ρm} as the
model computing f1, . . . , fm. We deﬁne Π
protocol where all ideal calls of Π have been replaced by
executions of the corresponding protocol: if party Pj needs to
compute fi with input xj, it halts, starts an execution of ρi
with the other party, gets the result βj from ρi and continues
as if βj was received from T .
Theorem 3 (Modular Sequential Composition Theorem [51],
[52]). Let f1, . . . , fm be two-party probabilistic polynomial
time functionalities and ρ1, . . . , ρm be protocols that compute
respectively f1, . . . , fm in the presence of semi-honest adver-
saries.
Let g be a two-party probabilistic polynomial time func-
tionality and Π a protocol that securely computes g in the
(f1, . . . , fm)-hybrid model
in the presence of semi-honest
adversaries.
Then Πρ1,...,ρm securely computes g in the presence of semi-
honest adversaries.
D. Changing Encryption Owner
Proof of Theorem 1. The function f this protocol computes
is:
f (([[x]]B, SKA, PKB), (PKA, SKB)) = (∅, [[x]]A)
For the sake of simplicity, we do not take into account the
(cid:4)
randomness used for the encryptions of r for A and c
=
x + r for B. The distribution of these coins for one party
974
is completely independent of the other elements taken into
account in the simulations, so we omit them in our security
proof.
A’s view is VA = (SKA, PKB, [[x]]B; r;∅). A does not
output anything. The simulator SA(SKA, PKB, [[x]]B) runs as
follows:
1) Picks uniformly at random ˜r ← MP .
2) Outputs (SKA, PKB, [[x]]B; ˜r;∅)
Since r and ˜r are sampled from the same distribution, inde-
pendently from any other parameter,
{(SKA, PKB, [[x]]B; ˜r;∅), f ([[x]]B, SKA, PKB, PKA, SKB)} =
{(SKA, PKB, [[x]]B; r;∅), f ([[x]]B, SKA, PKB, PKA, SKB)}.
Moreover, it holds that
{(SKA, PKB, [[x]]B; r;∅), f ([[x]]B, SKA, PKB, PKA, SKB)} =
{(SKA, PKB, [[x]]B; r;∅), (∅, [[x]]A)}
and we can conclude
{SA(SKA, PKB, [[x]]B), f ([[x]]B, SKA, PKB, PKA, SKB)} ≡c
{VA([[x]]B, SKA, PKB, PKA, SKB),
Out([[x]]B, SKA, PKB, PKA, SKB)}.
B’s view is VB = (PKA, SKB; [[x + r]]B, [[r]]A). B outputs
[[x]]A. We build a simulator SB(PKA, SKB) as follows:
1) Pick uniformly at random ˜r ← MP and ˜c ← MP .
2) Generate the encryptions [[˜r]]A and [[˜c]] using PKA.
3) Output (PKA, SKB; [[˜c]]B, [[˜r]]A)
By semantic security of the encryption scheme (in our concrete
case the Paillier cryptosystem), it holds that (proof see below)
{(PKA, SKB; [[˜c]]B, [[˜r]]A), f ([[x]]B, SKA, PKB, PKA, SKB)} ≡c
(4)
{(PKA, SKB; [[x + r]]B, [[r]]A), f ([[x]]B, SKA, PKB, PKA, SKB)}
(5)
and hence (using also the correctness of the scheme)
{SB(PKA, SKB), f ([[x]]B, SKA, PKB, PKA, SKB)} ≡c
{VB([[x]]B, SKA, PKB, PKA, SKB),
Out([[x]]B, SKA, PKB, PKA, SKB)}.
We will prove the computational
indistinguishability of
(4) and (5) in more detail by giving a reduction to the
semantic security. To this end, we assume that we have a
distinguisher D that can distinguish (4) and (5). Speciﬁcally,
, [[y]]SK(cid:2) , [[r]]SK), [[x]]SK} D outputs 1 if y, r and
given {(PK, SK(cid:4)
x are independent uniformly random values and 0 if r = y−r
(cid:4)
(cid:4) and x = y − r = r
(cid:4). Then, we construct a
for a random r
reduction R as follows:
) ←
1) On input PK, generate a new key pair (SK(cid:4)
2) Pick uniformly at random y, ˜r ← M.
3) Choose challenger messages m0 = y − ˜r, m1 = ˜r and
KeyGen(1λ).
, PK(cid:4)
give them to the semantic security challenger.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:45 UTC from IEEE Xplore.  Restrictions apply. 
4) Receive c from the challenger, compute [[˜r]]PK and query
, [[y]]SK(cid:2) , c), [[˜r]]PK}),
distinguisher D({(PK, SK(cid:4)
the
which returns b.
5) Return b to the challenger.
Since we simulate both cases ((4) and (5)) perfectly to the
distinguisher, its success probability in distinguishing (4) and
(5) transfers exactly to our reduction in the semantic security
game. Since Paillier encryption is shown to be semantically
secure under the Decisional Composite Residuosity Assump-
tion, the distinguisher must have at most negligible success
probability. And hence our scheme is secure.
E. Private Random Forest Evaluation
The correctness of our protocol follows from the correctness
of the private classiﬁcation tree protocol in [23]. Moreover, we
will provide a security proof for the protocol revealing only
the plurality-vote class. Since our second protocol instantiation
– revealing all trees’ outcomes – is essentially only a shorter
version of the main protocol, we do not provide a separate
security proof for this protocol.
Proof of Theorem 2. Let A be the server S and B be the client
C. We prove the security of our protocol (see Protocol 2) in
the hybrid model using the following 5 ideal functionalities,
which we let execute by a trusted third party:
B, PKP
B , PKQR
• the comparison protocol in step 3:
B) = ([x ≤
f1([[x]]B, [[y]]B, l, SKQR
B , SKP
y]B,∅)
• the protocol to change the encryption scheme in step 4:
) = ([[[b]]]B,∅)
• the protocol to change the encryption scheme in step 10:
f3([[[y1, . . . , yk]]]B, SKF HE
=
({[[y1]]B, . . . , [[yk]]C}k
i=1,∅)
• the protocol to change the ownership of the encryption
f2([b]B, SKQR
B , SKF HE
B , PKQR
B, PKP
B)
, PKF HE
, PKF HE
, SKP
B
B
B
B
A, PKP
in step 12:
f4([[x]]B, SKP
A, SKP
• the arg max protocol in step 13:
f5({[[ai]]A}k
(∅, arg maxi
i=1, l, SKP
{ai}k