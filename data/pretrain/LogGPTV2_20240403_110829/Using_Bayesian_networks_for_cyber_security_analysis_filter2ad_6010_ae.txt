# AIZ WEB Analysis and Experiment Results

## Table 6: Results of Experiment 1
| Identifier | WEB (%) | FS (%) | WS (%) | Trojan (%) | NFS Shell (%) | mountd (%) |
|------------|---------|--------|--------|------------|---------------|-------------|
| AI.        | 83.13   | -      | -      | -          | -             | -           |
| AIS        | 89.92   | 14.10  | -      | -          | -             | -           |
| Alfi       | 92.73   | 53.01  | 51.39  | 38.47      | -             | -           |
| AI7        | 97.23   | 68.93  | 60.00  | 100.00     | 57.53         | 68.93       |
| AIS (Revised)| 100.00  | -      | -      | -          | -             | -           |

### Observations
- The likelihood of the fileServer being compromised, as determined by the BN-based tool, is 74.8%.
- The likelihood of an NFS Shell attack being enforced is also confirmed by the experiment.

### Conclusion
- Experiment 6 shows that there are no false positives and only AE2 has insignificant latency, confirming the effectiveness of the BN-based tool in this scenario.

## 4.4 Sensitivity Analysis
To make the BN-based tool practical for real-time security analysis, it must be robust against reasonable (small) changes in its CPT tables. The CPT tables are generated based on human expertise and are only approximate to the truth in the real world. Therefore, the BN-based tool must be resilient to slight changes in its CPT tables.

### Desirable Sensitivity Analysis
- **Holistic Approach**: The most desirable sensitivity analysis should consider the combined effects of all parameters. However, developing such a method is extremely difficult.
- **Isolated Analysis**: In our work, we analyze the sensitivity of the BN-based tool in an isolated way, considering the effect of one parameter at a time while keeping others constant.

### Findings
- The BN-based tool is not significantly affected by small changes in its CPT tables. For example, to generate a +5% change in the answer at time All (83.13%), the minimum change required on the parameters is 5%. The same holds for a -5% change.

## 5 Related Work
Bayesian network techniques have been applied to intrusion detection systems [4, 17, 25]. Our application of BN is at a different level, integrating it into a holistic security analysis framework. Our BN model does not deal with low-level system events but incorporates the output of various intrusion detectors.

- **Frigault et al. [10, 11]**: Study how to use Bayesian networks and attack graphs to measure network security risk, focusing on the pre-deployment phase.
- **Dantu and Kolan [12, 13, 9, 14, 20, 21, 27]**: Use Bayesian networks for risk management, intrusion detection, and response. Our work extends their approach by modeling uncertainties in system conditions and run-time observations.
- **Tang [24]**: Applies Dempster-Shafer (DS) theory in fault-diagnosis for overlay networks. Our focus is on analyzing cyber attacks, which differ from faults due to the presence of malicious players.

## 6 Conclusions
Graphical models are important tools for analyzing security events in enterprise networks. By combining attack graphs and Bayesian networks, we can capture uncertain relationships and provide a more comprehensive security analysis. This work is the first effort to systematically combine these approaches for improved enterprise security.

## 7 Acknowledgements
This work was partially supported by the Army Research Office, U.S. NSF, and U.S. AFOSR. Specific grants and contracts include W911NF-07-C-0101, 0716665, FA9550-09-1-0138, and FA8750-08-C-0137.

---

**References**
[1] NVD CVSS National Vulnerability Database, April 2008.
[2] Magnus Almgren, Ulf Lindqvist, and Erland Jonsson. A database CVSS support.
[3] Paul Ammann, Duminda Wijesekera, and Saket Kaushik. Scalable, graph-based network vulnerability analysis.
[4] Pablo Garcia Bringas. Intensive use of Bayesian belief networks for the unified, flexible, and adaptable detection and prevention of misuses and anomalies in network intrusion systems.
[5] Hei Chan and Adnan Darwiche. When do numbers really matter? Journal of Artificial Intelligence Research, pages 265-287, 2002.
[6] Ram Dantu and Prakash Kolan. Risk management using behavior-based Bayesian networks.
[7] A.P. Dempster. Upper and lower probabilities induced by a multivalued mapping. Ann. Statistics, 28:325-339, 1967.
[8] Rinku Dewri, Nayot Poolsappasit, Indrajit Ray, and Darrell Whitley. Optimal security hardening using multi-objective optimization on attack tree models of networks.
[9] Bingrui Foo, Yu-Sung Wu, Yu-Chun Mao, Saurabh Bagchi, and David Ahmad. Managing complexity through visual hierarchical aggregation.
[10] Marcel Frigault and Lingyu Wang. Measuring network security using dynamic Bayesian networks.
[11] Marcel Frigault, Lingyu Wang, Anoop Singhal, and Sushil Jajodia. Measuring network security using dynamic Bayesian networks.
[12] Saurabh Bagchi, Gaspar Modelo-Howard, and Guy Lebanon. Determining the optimal placement of intrusion detectors for a distributed application through Bayesian network modeling.
[13] Kyle Ingols, Richard Lippmann, and Keith Piwowarski. Practical attack graph generation for network defense.
[14] Sushil Jajodia, Steven Noel, and Brian O'Berry. Topological analysis of network attack threats: Issues, approaches, and challenges.
[15] F.V. Jensen, S.L. Lauritzen, and K.G. Olesen. Bayesian updating in causal probabilistic networks by local computations. Computational Statistics Quarterly, 4:269-282, 1990.
[16] Gene H. Kim and Eugene H. Spafford. The design and implementation of Tripwire: A file system integrity checker.
[17] Christopher Kruegel, Darren Mutz, William Robertson, and Fredrik Valeur. Bayesian event classification for intrusion detection.
[18] Richard Lippmann, Kyle Ingols, Chris Scott, Keith Piwowarski, Kendra Kratkiewicz, Mike Artz, and Robert Cunningham. Validating defense in depth using attack graphs.
[19] Peter Mell, Karen Scarfone, and Sasha Romanosky. A complete guide to the Common Vulnerability Scoring System Version 2.0.
[20] Steven Noel and Sushil Jajodia. Managing attack graph multi-sensor models to improve automated attack detection.
[21] Xinming Ou, Wayne F. Boyer, and Miles A. McQueen. A scalable approach to attack graph generation.
[22] Judea Pearl. Probabilistic reasoning in intelligent systems: Networks of plausible inference. Morgan Kaufman, 1999.
[23] Mike Schiffman, Gerhard Eschelbeck, David Ahmad, Andrew Wright, and Sasha Romanosky. CVSS: A Common Vulnerability Scoring System. National Infrastructure Advisory Council (NIAC), 2004.
[24] Yongning Tang and Ehab Al-Shaer. Sharing end-user negative symptoms for improving overlay network dependability.
[25] Alfonso Valdes and Keith Skinner. Adaptive, model-based monitoring for cyber attack detection.
[26] Lingyu Wang, Steven Noel, and Sushil Jajodia. Minimum-cost network hardening using attack graphs.
[27] Leevar Williams, Richard Lippmann, and Kyle Ingols. GAMET: A graphical attack graph and reachability evaluation tool.