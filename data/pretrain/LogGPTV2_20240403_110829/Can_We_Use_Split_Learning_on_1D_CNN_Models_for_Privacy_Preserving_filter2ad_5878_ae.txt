time-series/sequential data would exhibit a possibility of high
privacy leakage from feature values. Initial mitigation attempts
via i) increasing the number of layers in a CNN model and ii)
using differential privacy explicitly indicate there is a trade-
off between the degree of privacy leakage reduction and joint
model accuracy deterioration—substantial when applying the
differential privacy. Perhaps, it would be more challenging to
preserve privacy via 1D CNN models compared with 2D CNN
models. This is because 1D CNN usually has much less hidden
layers where more 1D CNN layers usually tend to affect the
model accuracy adversely. As future work, privacy leakage
through the split layer should be thoroughly evaluated for (1D
and 2D) CNN models, and corresponding effective mitigation
techniques need to be developed.
ACKNOWLEDGMENT
The work has been supported by the Cyber Security Re-
search Centre Limited whose activities are partially funded
050001=30500=30500=60500Proportion=6050001=240500=240500=570500Proportion=61050001=530500=600500=1300500Proportion=136050001=1000500=1000500=2630500Proportion=278050001=1070500=1310800=4300800Proportion=4440500Improved by 113x01=3380500Improved by 119x=35801400Improved by 150x=89901400Improved by 158xProportion=9450.00.20.40.60.81.0Distribution of DTW0.00.20.40.60.81.0Two most correlated channelsTwo least correlated channelsNodiffpriv=10=7=5=3=1[22] George B Moody and Roger G Mark. The impact of the mit-bih
IEEE Engineering in Medicine and Biology
arrhythmia database.
Magazine, 20(3):45–50, 2001.
[23] Praneeth Vepakomma, Otkrist Gupta, Abhimanyu Dubey, and Ramesh
Raskar. Reducing leakage in distributed deep learning for sensitive
health data. arXiv preprint arXiv:1812.00564, 2019.
[24] Arthur Gretton, Kenji Fukumizu, and Bharath K Sriperumbudur. Discus-
sion of: Brownian distance covariance. The annals of applied statistics,
3(4):1285–1294, 2009.
[25] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya
Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential
In Proceedings of the 2016 ACM SIGSAC Conference on
privacy.
Computer and Communications Security, pages 308–318. ACM, 2016.
[26] Naoise Holohan, Stefano Braghin, P´ol Aonghusa, and Killian Lev-
acher. Diffprivlib: The ibm differential privacy library. arXiv preprint
arXiv:1907.02444, 2019.
[27] Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory.
Neural computation, 9(8):1735–1780, 1997.
[28] Tom´aˇs Mikolov, Martin Karaﬁ´at, Luk´aˇs Burget, Jan ˇCernock`y, and
Sanjeev Khudanpur. Recurrent neural network based language model. In
Eleventh annual conference of the international speech communication
association, 2010.
[29] Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly
Shmatikov.
Exploiting unintended feature leakage in collaborative
learning. In 2019 IEEE Symposium on Security and Privacy (SP), pages
691–706. IEEE, 2019.
[30] Yansong Gao, Chang Xu, Derui Wang, Shiping Chen, Damith C Ranas-
inghe, and Surya Nepal. Strip: A defence against trojan attacks on
deep neural networks. In 35th Annual Computer Security Applications
Conference (ACSAC), pages 113–125, 2019.
[31] Bolun Wang, Yuanshun Yao, Shawn Shan, Huiying Li, Bimal Viswanath,
Haitao Zheng, and Ben Y Zhao. Neural cleanse: Identifying and
Neural Cleanse:
mitigating backdoor attacks in neural networks.
Identifying and Mitigating Backdoor Attacks in Neural Networks, page 0,
2019.
[32] Yansong Gao, Yeonjae Kim, Bao Gia Doan, Zhi Zhang, Gongxuan
Zhang, Surya Nepal, Damith C Ranasinghe, and Hyoungshick Kim.
Design and evaluation of a multi-domain trojan detection method on
deep neural networks. arXiv preprint arXiv:1911.10312, 2019.
[33] Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and
Vitaly Shmatikov. How to backdoor federated learning. arXiv preprint
arXiv:1807.00459, 2018.
[34] Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and H Brendan
McMahan. Can you really backdoor federated learning? arXiv preprint
arXiv:1911.07963, 2019.
[35] David L Donoho and Jain M Johnstone.
Ideal spatial adaptation by
wavelet shrinkage. biometrika, 81(3):425–455, 1994.
APPENDIX
The MIT-BIH database contains 48 records retrieved from
47 different patients. About 110K ECG signals are distributed
in 48 records. Each record includes a 30-minute excerpt of
two-channel ECG signals. Also, each record has an annotation
pair that contains time positions and beat types of all ECG
signals in the paired record. Similar to [11], [12], we ﬁrst
eliminate four records (record 102, 104, 107, and 217) contain-
ing paced heartbeats. Among two channels of ECG data, we
extract only the upper channel from each record as it highlights
abnormal ECG patterns [12]. In most cases, the upper channel
signals come from modiﬁed limb II (ML II); however, in the
case of record 114, the ML II signal is located at its bottom
channel. Therefore, we exclude record 114 too. A total of 43
out of 48 records are selected for further preprocessing.
Each ECG record contains n number of cardiac cycles of
heartbeat collected using electrodes placed on the skin. Each
heartbeat has three main components: the P wave that reﬂects
the depolarization of the atria; the QRS complex that reﬂects
the depolarization of the ventricles; and the T wave that reﬂects
12
the repolarization of the ventricles. Together, they can tell if
the heart is normal or has a problem.
The next step is to extract every single beat from selected
43 records. We took an equal number of samples from the
left and right side of R-peaks which is done by iterating
through the time-series annotations. One hundred values were
taken from both sides; However, the segment was discarded
if another R-peak existed in the sampled interval. The current
beat after this step has 201 sampling values containing only
single R-peak. Each signal was then rescaled by the min-max
normalization shown in Equation (7), where x is original, and
x(cid:48) is normalized value in the signal. The normalized signal
was downsampled to 128 by adopting the Fourier method.
x(cid:48) =
x − min(x)
max(x) − min(x)
(7)
Denoising was the last step of reﬁning ECG signals. We chose
biorthogonal wavelet as decomposition and reconstruction
wavelet function. The level of signal decomposition was 3.
As shown in Equation (8), we applied a soft thresholding
technique to decomposed coefﬁcients w, based on calculated
universal threshold [35].
(|w| ≥ λ)
(|w| < λ)
(8)
(9)
w(cid:48) =
(cid:40)sgn(w)(|w| − λ)
λ = σ(cid:112)2 log N
0
Equation (9) shows the universal threshold value, where σ
is the median absolute deviation of the wave coefﬁcients at
the last level divided by 0.6745, and N is the length of the
denoising input signal, in this case, 128.
ECG heartbeat samples in the MIT-BIH database are clas-
siﬁed into 17 categories according to morphological patterns
in a signal, labeled by independent cardiologists. Following
[12], we select 5 types of heartbeat as classiﬁcation targets:
N (normal beat), L (left bundle branch block), R (right bundle
branch block), A (atrial premature contraction), V (ventricular
premature contraction). After excluding beat samples whose
labels are not included among 5 types, 96K beat samples
remain. We randomly pick 6,000 samples for N, L, R, and
V class, however, 2,490 samples for A class, as a number of
A-labeled beats in the dataset are not as sufﬁcient as other
categories. We divide this data pool equally into the train and
test set as shown in Table I.
We further detail the training ﬂow in Algorithm 1 and
Algorithm 2 in terms of 1D CNN, as shown in Fig. 6. This
training ﬂow can be directly applied to the 1D CNN ECG
classiﬁcation model we made in Section III-A2.
In initialization,
the client ﬁrst connects to the server
through the socket and gets some training parameters to
synchronize. The initialization in Algorithm 1 and 2 require
5 parameters to be synchronized between the client and the
server. The server sends φ, η, o and n to the client that the
client should adjust to, just after accepting the connection. φ
is a random weight initializer, η is learning rate, o is a type of
optimizer, and n is the batch size. These four hyperparameters
should be synchronized on both sides to let them trained in
13
requires it to continue the backpropagation. Therefore, the
model on the server part should be forced to calculate the
gradient to the input level. To update weights, computing the
gradient of weights in layer i can be given as follows [11]:
∂E
∂w(i)
kj
= Conv1D(a(i−1)
k
,
∂E
∂z(i)
j
)
(12)
which is the same way. When the client receives n, it sends
N to the server, which is the number of total batches to be
trained. n is implicitly used not only for the batch generation
but also for determining the shape of the matrix in forward
and backward propagation. N helps the server to know how
many times the forward backward propagation should be done.
If needed, the number of epochs should also be synchronized
between the client and the server. In Algorithm 1 and 2, they
give only a single epoch training process. Hence, the training
repetition process is omitted.
Forward propagation starts from the client-side. The client
ﬁrst generates the batch, (x, y), which has n data extracted
from the train set D. x represents the features of data, and y
shows their labels. Starting with x, the client does the forward
propagation until layer l. If layer i is 1D convolutional layer,
f (i) can be expressed as follows [11]:
k = f (i)(a(i−1)) = b(i)
z(i)
k +
Conv1D(a(i−1)
j
, w(i)
jk ) (10)
Ci−1(cid:88)
j=1
j
j
where z(i)
is the k-th channel of the output from the i-th
k
layer, and a(i−1)
is the j-th channel of activation from layer
i−1. Also, w(i)
jk is a convolution ﬁlter which connects between
a(i−1)
and z(i)
k . Ci−1 means the number of channels in the
output from the (i − 1)-th layer. Conv1D means the regular
1D convolution operation without zero padding. b(i)
k is the bias
value added after the convolution operation. Let us assume that
the server has at least one convolutional layer on its previous
side. Equation (10) tells that forward propagation on layer i
only depends on the activated output of (i−1)-th layer. In other
words, the server can continue forward propagation on layer
l + 1 by only receiving a(l) from the client. After receiving
a(l) and label y, the server is able to do forward propagation
to the L-th layer.
Before starting the backpropagation, the server calculates
loss between a(L) and y. Here, the loss function L produces E
by computing either mean squared error or cross-entropy loss
in the usual case. The backpropagation function f (i)
can be
T
written as follows if i-th layer is 1D convolutional layer [11].
Ci+1(cid:88)
j=1
∂E
∂a(i)
k
= f (i)
T (
∂E
∂z(i+1)
k
∂E
∂z(i+1)
k
) =
Conv1Dz(
, rev(w(i+1)
kj
))
∂E
(11)
rev means reversing 1D convolution ﬁlter array, and Conv1Dz
is full 1D convolution operation with (ﬁlter size−1) zero pads
on both side. Again, Equation (11) indicates that computing
∂z(i+1) . This means the client can
∂a(i) only depends on
∂E
continue backpropagation by receiving just
from the
server. When the client receives ∂E
∂a(l) , the client can generate
∂z(l) , which is g(l)(cid:48)(z(l)). Then the client
∂z(l) by multiplying ∂a(l)
∂E
is able to do backpropagation to the ﬁrst hidden layer with
(11). In backpropagation, there is no need for calculating
gradients of input because it is not trainable. For example,
the client does not have to calculate ∂E
∂a(0) , because the input
is literally a untrainable parameter which is directly given by
the user. However, from the server perspective, the server has
∂a(l) , because the client
to calculate the gradient of its input, ∂E
∂E
∂a(l)