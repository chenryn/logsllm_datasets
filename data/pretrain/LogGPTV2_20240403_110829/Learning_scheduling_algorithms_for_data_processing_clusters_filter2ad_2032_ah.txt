We found that capturing all first-order effects of the Spark envi-
ronment is crucial to achieving this accuracy (§6.2). For example,
without modeling the delay to move an executor between jobs, the
simulated runtime consistently underapproximates reality. Training
in such an environment would result in a policy that moves executors
more eagerly than is actually sensible (§7.4). Likewise, omitting the
effects of initial and subsequent “waves” of tasks, or the slowdown
overheads imposed with high degrees of paralllism, significantly in-
creases the variance in simulated runtime and makes it more difficult
for Decima to learn a good policy.
E Expressiveness of Decima’s state representation
Decima’s can only learn strong scheduling policies if its state repre-
sentation, embedding scheme, and neural network architecture can
express them (§7).
In Equation (1), combining two non-linear transforms f (·) and д(·)
enables Decima to express a wide variety of aggregation functions. For
example, if f ∼ log(·/n), д ∼ exp(n×·), and n →∞, the aggregation
computes the maximum of the child node embeddings. By contrast,
u∈ξ(v) f (eu)
a standard aggregation operation of the form ev =
Learning Scheduling Algorithms for Data Processing Clusters
SIGCOMM ’19, August 19-23, 2019, Beijing, China
the max operation and therefore accurately identifies the critical path
after about 150 iterations, while the standard embedding is incapable
of expressing the critical path and consequently never reaches a stable
high accuracy.
F Multi-resource scheduling heuristic comparison details
When evaluating Decima’s performance in a multi-resource set-
ting (§7.3), we compared with several heuristics.
First, we considered the optimally tuned weighted fair heuristic
from §7.2. This heuristic grants each job an executor share based on
the total work in the job. Then the heuristic chooses a stage the same
way as in the single resource setting. Among the available execu-
tor types, the heuristic first exhausts the best-fitting category before
choosing any others. The scheduler ensures that the aggregate allo-
cated resources (across different executor types) do not exceed the
job’s weighted fair share.
Second, we compared to the resource-packing algorithm from
Tetris [34]. To maximize resource utilization, we select the DAG node
that yields the largest dot product of the requested resource vector
and the available resource vector for each executor type. Then, we
greedily grant as much parallelism as the tasks in this node need.
The prior two heuristics lack each other’s key scheduling ingredi-
ents (fairness and packing), and neither understands the DAG struc-
ture. Finally, we compared to Graphene [36], whose hybrid heuristic
combines these factors. However, our multi-resource scheduling en-
vironment with discrete executor classes differs from the original
Graphene setting, which assumes continuous, infinitely divisible re-
sources. We adapted the Graphene algorithm for discrete executors,
but kept its essence: specifically, we estimate and group the “trouble-
some” nodes the same way [36, §4.1]. To ensure that troublesome
nodes are scheduled at the same time, we dynamically suppress the
priority on all troublesome nodes of a DAG until all of these nodes are
available in the frontier. We also include parallelism control by sharing
the executors according to the optimally tuned weighted fair partition
heuristic; and we pack resources by prioritizing the executor type that
best fits the resource request. Finally, we perform a grid search on
all the hyperparameters (e.g., the threshold for picking troublesome
nodes) to tune the heuristic for the best scheduling performance in
each of the experiments (§7.3).
G Further analysis of multi-resource scheduling
In §7.3, we found that Decima achieves 32% − 43% lower average
JCT than state-of-the-art heuristics when handling continuous job
arrivals in a multi-resource environment. Decima achieves this by
carefully fragmenting cluster memory: Figure 12b illustrated that
Decima selectively borrows large executors if they can help finishing
short jobs quickly and increase cluster throughput.
This effect is also evident when examining the timeseries of job du-
ration and executor usage over a single experiment. Figure 20 shows
that Decima maintains a smaller number of concurrent active jobs
during periods of high load both for a synthetic TPC-H workload and
for the Alibaba trace. During busy periods (e.g., around snapshot 50
in Figure 20a1), Decima clears the backlog of jobs in the queue more
quickly than the best competing heuristic, Graphene∗. During these
periods, Decima assigns more executors to each job than Graphene∗
(Figures 20a2 and 20b2), e.g., by sometimes borrowing large execu-
tors for jobs that need only smaller ones. As a consequence, Decima
(a) Single job running in isolation.
(b) Mixture of jobs on a shared cluster.
Figure 18: Testing the fidelity of our Spark simulator with Decima as a
scheduling agent. Blue bars in the upper part show the absolute real Spark job
duration (error bars: standard deviation across ten experiments); the orange
bars in the lower figures show the distribution of simulation error for a 95%
confidence interval. The mean discrepancy between simulated and actual job
duration is at most ±5% for isolated, single jobs, and the mean error for a mix
of all 22 queries running on the cluster is at most ±9%.
Figure 19: Trained using supervised learning, Decima’s two-level non-linear
transformation is able to express the max operation necessary for computing
the critical path (§5.1), and consequently achieves near-perfect accuracy on
unseen DAGs compared to the standard graph embedding scheme.
without a second non-linear transformation д(·) is insufficient to
express the max operation. Consequently, such an architecture cannot
learn the aggregation (max) required to find the critical path of a graph.
During development, we relied on a simple sanity check to test
the expressiveness of a graph embedding scheme. We used super-
vised learning to train the graph neural network to output the critical
path value of each node in a large number of random graphs, and
then checked how accurately the graph neural network identified
the node with the maximum critical path value. Figure 19 shows the
testing accuracy that Decima’s node embedding with two aggregation
levels achieves on unseen graphs, and compares it to the accuracy
achieved by a simple, single-level embedding with only one non-
linear transformation. Decima’s node embedding manages to learn
286
050100150200250300350Number of iterations40%60%80%100%Testing accuracySingle non-linear aggregationDecima's two-level aggregationSIGCOMM ’19, August 19-23, 2019, Beijing, China
H. Mao et al.
(a) TPC-H workload.
(b) Industrial trace replay.
Figure 20: Timeseries of different statistics in the extended Spark multi-
resource environment. We compare Decima and Graphene∗, the best
competing heuristic. During busy periods, Decima finishes jobs faster and
maintains a lower number of concurrent jobs by using more executors per job.
achieves lower JCT and higher cluster throughput when the cluster
load is high (Figures 20a3 and 20b3).
Figure 21a and 21b compare the executor assignment between
Decima and Graphene∗ in detail (Figure 12b is the first column of
this profile). On the x-axis, we bin jobs according to the total amount
of work they contain (in task-seconds). The y-axis of each graph is
the number of executors Decima uses normalized to the number of
executors used by Graphene∗ — i.e., a value above one indicates
that Decima used more executors. Overall, Decima tends to assign
more executors per job compared to Graphene∗. This helps Decima
complete jobs faster in order to then move on to others, instead of
making progress on many jobs concurrently, similar to the behavior
we discussed in §7.2. Moreover, Decima uses more large executors
on small jobs. This aggressive allocation of large executors — which
wastes some memory — leads to faster job completion during the
busy periods (Figure 20a3 and 20b3), at the expense of leaving some
memory unused. This trade-off between resource fragmentation and
prioritizing small jobs can be tedious to balance, but Decima automat-
ically learns a strong policy by interacting with the environment.
Decima may enjoy an advantage here partly because Graphene∗
is restricted to discrete executor classes. In a cluster setting with
arbitrary, continuous memory assignment to tasks, large executor
“slots” could be subdivided into multiple smaller executors, assuming
sufficient CPU capacity exists. This choice is difficult to express with
a finite action space like Decima’s, and it is an interesting direction for
future work to investigate whether RL with continuous action could
be applied to cluster scheduling.
H Optimality of Decima
In §7, we show Decima is able to rival or outperform existing schedul-
ing schemes in a wide range of complex cluster environments, includ-
ing a real Spark testbed, real-world cluster trace simulations and a
multi-resource packing environment. However, the optimality of Dec-
ima in those environments remains unknown due to the intractability
of computing exact optimal scheduling solutions [36, 57], or tight
(a) TPC-H workload.
(b) Industrial trace replay.
Figure 21: Profile of executor assignments on jobs with different sizes,
Decima normalized to Graphene∗’s assignment (>1: more executors in
Decima, <1: more in Graphene∗). Decima tends to assign more executors.
lower bounds.9 To nevertheless get an idea of how close Decima
comes to an optimal scheduler, we test Decima in simplified settings
where a brute-force search over different schedules is possible.
We consider the Spark scheduling framework simulated in §6.2
with an average JCT objective for a batch of jobs. To simplify the
environment, we turn off the “wave” effect, executor startup delays
and the artifact of task slowdowns at high degrees of parallelism. As a
result, the duration of a stage has a strict inverse relation to the number
of executors the stage runs on (i.e., it scales linearly with parallel
resources), and the scheduler is free to move executors across jobs
without any overhead. The dominating challenges in this environment
are to pack jobs tightly and to favor short jobs as much as possible.
To find a good schedule for a batch of n jobs, we exhaustively search
all n! possible job orderings, and select the ordering with the lowest
average JCT. To make the exhaustive search feasible, we consider
a batch of ten jobs. For each job ordering, we select the unfinished
job appearing earliest in the order at each scheduling event (§5.2),
and use the DAG’s critical path to choose the order in which to finish
stages within each job. By considering all possible job orderings,
the algorithm is guaranteed to consider, amongst other schedules,
a strict shortest-job-first (SJF) schedule that yields a small average
JCT. We believe this policy to be close to the optimal policy, as we
have empirically observed that job orderings dominate the average
JCT in TPC-H workloads (§7.4). However, the exhaustive search also
explores variations of the SJF schedule, e.g., orders that prioritize
9In our setting (i.e., Spark’s executor-based scheduling), we found lower bounds based
on total work or the critical path to be too loose to provide meaningful information.
287
(2)(3)(1)(3)(1)(2)(1)(2)(3)(4)(1)(2)(3)(4)Learning Scheduling Algorithms for Data Processing Clusters
SIGCOMM ’19, August 19-23, 2019, Beijing, China
Figure 22: Comparing Decima with near optimal heuristics in a simplified
scheduling environment.
Figure 23: Decima performs worse on unseen jobs without task duration
estimates, but still outperforms the best heuristic.
model trained for a specific load and cluster size to similar workloads
with different parameters. To test this, we train a Decima agent on
a scaled-down version of the industrial workload, using 15× fewer
concurrent jobs and 10× fewer executors than in the test setting.
Table 3 shows how the performance of this agent compares with
that of one trained on the real workload and cluster size. Decima is
robust to changing parameters: the agent trained with 15× fewer jobs
generalizes to the test workload with a 7% reduced average JCT, and
an agent trained on a 10× smaller cluster generalizes with a 3% reduc-
tion in average JCT. Generalization to a larger cluster is robust as the
policy correctly limits jobs’ parallelism even if vastly more resources
are available. By contrast, generalizing to a workload with many more
jobs is harder, as the smaller-scale training lacks experiences with
complex job combinations.
J Decima with incomplete information
In a real cluster, Decima will occasionally encounter unseen jobs
without reliable task duration estimates. Unlike heuristics that funda-
mentally rely on profiling information (e.g., weighted fair scheduling
based on total work), Decima can still work with the remaining infor-
mation and extract a reasonable scheduling policy.
Running the same setting as in §7.2, Figure 23 shows that training
without task durations yields a policy that still outperforms the best
heuristic, as Decima can still exploit the graph structure and other
information such as the correlation between number of tasks and the
efficient parallelism level.
Decima training scenario
Decima trained with test setting
Decima trained with 15× fewer jobs
Decima trained with test setting
Decima trained with 10× fewer executors
average JCT (seconds)
3,290±680
3,540±450
610±90
630±70
Table 3: Decima generalizes well to deployment scenarios in which the
workload or cluster differ from the training setting. The test setting has 150
jobs and 10k executors.
jobs which can exploit parallelism to complete more quickly than
less-parallelizable jobs that contain smaller total work.
Next, we train an unmodified Decima agent in this environment,
similar to the setup in §7.2. We compare this agent’s performance
with our exhaustive search baseline, a shortest-job-first critical-path
heuristic, and the tuned weighted fair scheduler (described in §7.2).
Figure 22 shows the results. We make three key observations. First,
unlike in the real Spark cluster (Figure 9), the SJF-CP scheme outper-
forms the tuned weighted fair scheduler. This meets our expectation
because SJF-CP strictly favors small jobs to minimize the average
JCT, which in the absence of the complexities of a real-world cluster is
a good policy. Second, the exhaustive search heuristic performs better
than SJF-CP. This is because SJF-CP strictly focuses on completing
the job with the smallest total work first, ignoring the DAG structure
and the potential parallelism it implies. The exhaustive search, by
contrast, finds job orderings that prioritize jobs which can execute
most quickly given the available executors on the cluster, their DAG
structure, and their total work. While the search algorithm is not aware
of these constraints, by trying out different job orderings, it finds the
schedule that both orders jobs correctly and exploits cluster resources
to complete the jobs as quickly as possible. Third, Decima matches the
average JCT of the exhaustive search or even outperforms it slightly
(by 9% on average). We found that Decima is better at dynamically
prioritizing jobs based on their current structure at runtime (e.g., how
much work remains on each dependency path), while the exhaustive
search heuristic strictly follows the order determined in an offline
static search and only controls when jobs start. This experiment shows
that Decima is able to automatically learn a scheduling algorithm that
performs as well as an offline-optimal job order.
I Generalizing Decima to different environments
Real-world cluster workloads vary over time, and the available cluster
machines can also change. Ideally, Decima would generalize from a
288