> _关于何为Proguard,可以参考 **GuardSquare官网其优化业务** 及 **Wikipedia相关条目**._  
>  Proguard:  
>  Wikipedia:
# 局部敏感哈希与Proguard混淆对抗
2017年6月, **Richard Baumann** 发表了标题为" **Anti-ProGuard: Towards Automated
Deobfuscation of Android Apps**
"([DOI:10.1145/3099012.3099020](https://dl.acm.org/doi/10.1145/3099012.3099020
"DOI:10.1145/3099012.3099020"))的论文,其旨在利用 **SimHash**
算法实现对Apk的自动化反混淆.关于何为SimHash,简要来讲可以理解为 **可用之计算两个文本片段相似度的算法**
,此处不再进行具体阐述,可以参考Google在2007年发表的论文" **Detecting Near-Duplicates for Web
Crawling**
"([DOI:10.1145/1242572.1242592](https://dl.acm.org/doi/abs/10.1145/1242572.1242592
"DOI:10.1145/1242572.1242592")).
论文第二部分中,其强调Proguard对Apk进行 **Obfuscating** 的过程是多个 **Transformation**
的集合,论文设欲混淆工程为 **P** ,而 **P** 可看作同时包含多个对象的对象集合,对象集合中包含的对象与未混淆之工程中的类,方法,成员一
一存在映射关系,作者统一称这些对象为 **S**.即 **P={S1,S2,S3...}**  
经过Proguard混淆后的工程设之为 **P'** ,而Proguard的混淆过程可看作一个能够传入任意量的 **Transformation** 函数
**T(x)** ,即
**P'={T(S1),T(S2),T(S3)...}**.可见论文强调整个混淆过程为对整个未混淆工程中各个元素进行转换的总和(事实上也确实如此),而该思想在接下来的分析中也会多次得到体现.
而论文中的第三部分正式进入到自动化反混淆的实现部分,但由于论文中阐述的实现思路略去了很多细节,故下文不以论文进行分析,而 **Richard
Baumann** 已经将自动化方案落地,在其Github账户[ohaz](https://github.com/ohaz/
"ohaz")下即可找到对应的POC项目( **论文中并未给出其实现的项目地址,而该项目的首次commit时间最早为2016年,即早于论文发布时间**
).接下来以该项目具体分析自动化反混淆的实现思路.  
作者在其项目README文件上简述了工具的基本使用,需要引起注意的是其工具的`--sb
-t`参数与`-d`参数,其前者用于指定一个未被混淆的Apk,并将未混淆Apk之包,类,方法名及其对应的方法实体逐一抽离提取,存入数据库,后者为反混淆的进行指定一个欲反混淆的Apk.
由于篇幅限制,下文仅对项目最核心的算法部分进行分析,并在分析前 **假设一个前提:数据库中已经填充了足够多的未混淆Apk**.  
项目中`antiproguard.py`申明了一个关键方法`compare`,该方法用于将传入的欲分析方法实体( **被混淆** )与数据库中储存的
**各个** 方法实体( **未混淆**
)分别进行相似度对比,并依据相似度对比结果判断是否生成一个`hint`,该生成的`hint`将作为辅助分析其他被混淆方法实体的依据.  
可见在`compare`方法内,程序分别 **对被混淆方法实体** 分别生成了三个不同的SimHash值,而经过后续验证,这三个SimHash的产生
**均与方法实体所对应的操作码串有高度关联** ,则此三个SimHash值的关系可以下图进行表达.  
由上图不难得知这三个SimHash值与 **被混淆方法实体** 的关联强度有关,并按照关联强度以由大到小的顺序排列.  
接着该三值分别与数据库中的 **未混淆方法实体** 对应产生的此三个SimHash值以论文中提到的如下方式分别进行一次计算:  
SimHash结合汉明距离,该计算方式得出的结果可抽象理解为两个方法实体的 **相似程度** ,接着程序判断计算出的 **相似程度** 是否大于
**90%** ,若超过该值,则判断该 **被混淆方法实体** 与正在与之进行对比的 **未混淆方法实体**
高度相似,此时即可为下一次`compare`的调用产生一个`hint`,根据该`hint`以加快识别其他方法实体相似程度的速度,此处不再对`hint`更进一步分析.  
而最终程序将对所有经过`compare`方法确定的与数据库中未混淆的方法实体产生对应关系的被混淆的方法实体进行批量重命名,将其方法名'还原'为数据库中对应的未混淆方法实体的对应方法名,简而言之,`compare`方法负责确定被混淆方法与数据库中的那个未混淆方法具有
**强相关** 的关系.  
如果已经理解了`compare`方法,不难看出`compare`方法与反混淆之精细程度有着直接关系,同时也不难得出该反混淆方案的本质.既已分析过关键方法,剩下的分析流程我仅以一图概之.  
虽方案可行,但仍有局限之处,且看该论文的第四部分.  
可见其选择的被测试对象均为 **F-Droid** 上开放源代码的项目,且这些项目 **至少使用了一个或多个开源的第三方库**
,这些开源第三方库将在正式测试前被导入至数据库中,以启用Proguard优化的情况下编译项目,以反混淆工具提供的方案处理之,虽然最终该反混淆方案正确还原的包超过了50%,但该方案依然在很大程度上无法胜任真正的逆向工程实战.
  * 其一,回顾上文对关键方法`compare`的分析,不难发现一个需求与方案实现上的冲突,即逆向工程的本质是分析与剥离被分析对象最有价值的核心代码,而根据`compare`的实现可知其对方法实体的分析基于数据库中数据量的多少,而能够输入数据库的数据也仅限于第三方的开源支持库( **你总不能输入一些能够还原未开源代码的数据吧,这形成了悖论** ).  
  * 其二,论文第一部分明确指出, **其所提出的基于相似性算法的混淆代码还原方案基于数据库中的已知代码** ,而如第一点所言,能输入数据库的代码主要来源于第三方的开源支持库,故该论文提出的所谓通用性方案仅能对 **本就开源但被混淆的部分** 进行还原.
基于以上两点假设一个理想情况,方案能够还原所有被混淆的第三方开源库代码,但需要明确的是,逆向工程的主要对象仍是针对软件的业务代码,而市面上投放的软件其业务代码量均十分庞大(
**想象一下如今用户能够从已知渠道下载的软件,其臃肿程度导致的代码量可见一斑** ),即使能还原所有第三方开源库代码,对逆向工程的帮助也是微乎其微.
* * *
# DataFlow分析与Proguard混淆对抗
不论是尝试'还原'被混淆为短字节的方法名还是以其他方式处理被Proguard混淆的Apk工程,不难发现这些工作的
**本质都是尝试辅助逆向工程人员'理解'被混淆方法实体,排除无意义短字节的干扰** ,以减少逆向工程中抽离出有价值代码的时间成本.  
基于该思想,我曾于21年4月份编写并开源过一个项目,该项目的主旨是通过分析被混淆的成员与成员,方法,类之间的关系,让逆向工程人员快速判断被混淆成员是否具有被分析价值,但由于当时该项目不与任何现有工具联动,且分析对象仅针对成员,职能单一,在逆向工程中发挥的作用不大,故在今年(22年)5月对部分代码重构,拓展了项目职能,目前可以与著名逆向工程工具[
**JADX**](https://github.com/skylot/jadx "JADX")进行联动,且分析对象由单一的成员拓展至方法,可
**通过分析欲分析方法中的参数在被标记为污点的情况下的向下传播方向,即DataFlow分析**.  