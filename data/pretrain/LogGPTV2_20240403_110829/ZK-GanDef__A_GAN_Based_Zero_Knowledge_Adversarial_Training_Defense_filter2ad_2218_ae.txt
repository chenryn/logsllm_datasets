### Summary of Findings

We summarize our findings from the results as follows:
1. **Superior Performance and Scalability**: ZK-GanDef outperforms existing zero-knowledge defenses (CLP and CLS) in terms of test accuracy on adversarial examples and scalability to large datasets. This supports our hypothesis that a more flexible and sophisticated approach to handling pre-softmax logits (as in ZK-GanDef) is more effective than forcing them to be smooth at a small scale (as in CLP and CLS).
2. **Comparable Test Accuracy**: The test accuracy of ZK-GanDef is on par with state-of-the-art full-knowledge adversarial training defenses. This indicates that using perturbation-invariant features in the classifier can significantly enhance test accuracy on adversarial examples.
3. **Adaptability to New Adversarial Examples**: Unlike full-knowledge defenses, ZK-GanDef is adaptable to new types of adversarial examples. For instance, FGSM-Adv shows significant adaptability issues on the MNIST and Fashion-MNIST datasets, which are not observed on CIFAR10 due to input dropout in the classifier structure [25]. PGD-Adv does not currently exhibit adaptability issues, but this may change with the generation of stronger adversarial examples in the future [25] [22]. In contrast, ZK-GanDef's training is independent of specific adversarial examples, making it more adaptable.

### Generalizability

To demonstrate the generalizability of ZK-GanDef, we evaluated it on additional sets of adversarial examples generated by Deepfool [16] and Carlini & Wagner (CW) [4]. These methods produce perturbation patterns significantly different from Gaussian noise, allowing us to assess ZK-GanDef's effectiveness against a broader range of adversarial attacks.

**Evaluation Results:**
- **Deepfool Adversarial Examples**: ZK-GanDef achieved over 85% accuracy across all three datasets, consistent with the test errors reported in [16]. Deepfool aims to find adversarial examples with smaller perturbations compared to projected gradient descent-based methods (FGSM, BIM, PGD), making them easier to defend.
- **Carlini & Wagner (CW) Adversarial Examples**: ZK-GanDef maintained a similar level of test accuracy across all three datasets. This indicates that ZK-GanDef is not limited to defending against specific types of perturbations and can generalize to a wide range of adversarial examples, including FGSM, BIM, PGD, Deepfool, and CW.

### Training Time

We evaluated the training time of ZK-GanDef in terms of seconds per training epoch. Since ZK-GanDef significantly outperforms existing zero-knowledge defenses (CLP and CLS) in test accuracy, we compared its training time with full-knowledge defenses (FGSM-Adv, PGD-Adv, and PGD-GanDef).

**Results:**
- **MNIST and Fashion-MNIST**: ZK-GanDef's training time (8.75s per epoch) is close to that of FGSM-Adv (7.83s), while PGD-Adv and PGD-GanDef have much longer training times (110.85s and 132.75s, respectively).
- **CIFAR10**: ZK-GanDef and FGSM-Adv have shorter training times (71.20s and 62.85s, respectively) compared to PGD-Adv (146.91s) and PGD-GanDef (257.72s). For example, on CIFAR10, the end-to-end training time for PGD-Adv is 14.3 hours, while ZK-GanDef only takes 6.9 hours.

In summary, ZK-GanDef provides test accuracy comparable to the best state-of-the-art full-knowledge defenses (PGD-Adv) while reducing training time by 92.11% and 51.53% on MNIST/Fashion-MNIST and CIFAR10, respectively.

### Convergence Issues

The evaluation results of CLP and CLS on the CIFAR10 dataset show that these zero-knowledge adversarial training defenses fail to correctly classify both original and adversarial examples. This is primarily due to the non-convergence of their training loss. The mathematical models of CLP and CLS aim to prevent overconfident predictions by adding l2 norm penalties on pre-softmax logits. However, they do not include original examples in their training dataset, leading to a lack of important features for discrimination. This simple and inflexible design logic results in convergence issues, especially on complex datasets like CIFAR10.

**Validation:**
- **CLS Loss Analysis**: We recorded the loss of CLS during the first 30 training epochs under four different hyper-parameter settings. The results show that CLS does not learn useful features and thus does not converge under most settings. Only when the penalty and perturbation are reduced, CLS converges, but it then fails to defend against adversarial examples. Similar results were observed for CLP, where the training loss diverges under most settings.

### Conclusion

In this paper, we introduced ZK-GanDef, a new zero-knowledge adversarial training defense that combines adversarial training and feature learning to better recognize and identify adversarial examples. Our evaluations show that ZK-GanDef enhances test accuracy on both original and adversarial examples by up to 49.17% compared to other zero-knowledge defenses. Additionally, ZK-GanDef has test accuracy close to full-knowledge defenses (with a degradation of less than 8.46%) while requiring significantly less training time (more than 51.53% reduction). Furthermore, ZK-GanDef can adapt to new types of adversarial examples because its training is agnostic to specific adversarial examples.

### Future Work

Future research will focus on designing defensive methods that provide robustness against various single-step and iterative adversarial examples while minimizing computational overhead during training.