plained above, XenFIT only runs in user-space in Dom0. Be-
sides, our solution does not require any code to run in the
protected DomU. The only changes to DomU is some break-
points put in its kernel memory. Therefore the intruder has
very little chance to detect the presence of XenFIT.
We will discuss few tactics in section 4 to make XenFIT more
invisible and harder to detect even if the attacker has root
access. All of this exercises are to improve the problem (6).
• Low maintaining overhead: Because XenFIT knows what
is happening in the system in real-time, clearly it does not
need the base-line database to compare with like other FIT
solutions. All it needs is a security policy kept in Dom0,
so it can verify if the gathered activities of the protected
DomU are against the policy. Therefore XenFIT does not
require to generate the database at initializing or to maintain
the database during the run-time like others. As a result, the
problem (3) is addressed.
• Easy to deploy: As XenFIT can gather the integrity related
information at run-time only by injecting breakpoints into
the protected VM, it does not need any code loaded or base-
line database in the virtual domain. In fact, everything we
need to deploy our IDS is to run XenFIT in Dom0, and let it
monitor the protected DomU. Subsequently, this beneﬁt ﬁxes
the problem (2)
Another merit of our approach is that because XenFIT peeks
data from DomU by using breakpoints at run-time, we do
not need to patch the DomU’s kernel. As a result, maintain-
ing XenFIT for different kernel versions becomes extremely
easy.
• Enriched information: Since XenFIT captures the hook events
at run-time, it can provide valuable information such as the
time when the event happens, who (user-id) generates the
event, and the related process-id/ process-name. These knowl-
edge give the administrator much better view on what hap-
pened in his VMs. Consequently XenFIT can improve the
problem (4).
• Resistant tampering: XenFIT is proposed to run in Dom0
only, and we have absolutely no code running in protected
VMs. Therefore the attacker cannot apply the strategy of
shutting down the integrity checking operation like he can
do with traditional FIT. Even if he takes over the whole sys-
tem and has access to his kernel, everything he can do is to
disable the breakpoints putting in his kernel, but cannot tam-
per with our IDS running in a separated and highly-secure
VM (speciﬁcally, in Dom0).
Furthermore, XenFIT keeps the security policies in Dom0,
so the attacker cannot compromise them, either.
Another advantage of our solution is that XenFIT in Dom0
does not expose to the network, so the attacker has no chance
to exploit it from outside like in traditional way4.
Clearly with the above beneﬁts, the problem (5) is partly ad-
dressed. Section 4 will discuss few more methods to harden
the kernel of protected VM, so even if the attacker has root
privilege, he cannot access and compromise the breakpoints
XenFIT put inside the kernel.
4Actually we recommend to run Dom0 without network access,
thus mitigate the security risks for the whole system.
196
XenFIT handled the debug event; and ﬁnally the control is given
back to the original DomU. These switchings can cause a lot of neg-
ative impact to to the overall performance of the protected DomU.
When we ﬁrst investigated the problem, we thought it was a good
idea to employ the same tactic of the current Xen kernel debugger
to monitor DomU, because the debugger also exploits INT3 to in-
spect DomU’s kernel at run-time ([1]). However, this approach has
a major problem that can affect the system performance: the debug-
ger in Dom0 detects the debugging event by periodically polling
DomU’s status 5 to see if it is paused, which is the evidence that the
breakpoint was hit. By default the checking interval is 10 million
nanoseconds, which means the breakpoint is not processed imme-
diately if it comes between the checking time. For debugging pur-
pose, this is not a major concern because performance is not a pri-
ority. But for our target, that is unfortunately unacceptable because
the whole process extremely slows down.
To ﬁx the problem, we decide not to use the mentioned polling
tactic of the Xen kernel debugger. Instead we exploit the fact that
whenever the breakpoint as well as when the processor is in step-
trace mode, the hypervisor sends an event to Dom0 to notiﬁes po-
tential debugger. While the standard debugger does not use this
feature, we employ the trick, and have XenFIT handled the debug-
ging event. To do that, XenFIT only needs to put the protected
DomU into the debugging mode6, and binds to the virtual interrupt
dedicated for debugging event to get notiﬁed from the hypervisor7 .
Thanks to this strategy, XenFIT is instantly aware when the DomU
hits the breakpoints, and does not need to poll the DomU for the
paused status. The experiements prove that the solution signiﬁ-
cantly improves the overall performance.
3.2.3 Breakpoints
To capture the information that can be used to detect intrusion,
it is very important to put the breakpoints at the right places in
DomU’s kernel. Because all the I/O from user-space to devices
must go through system-calls, it is natural that we should put our
breakpoints to I/O system-calls. Speciﬁcally we pay attention to
I/O system-calls that creates, removes or change attributes of ﬁle,directory
and device. See Table 1 for the full list of selected system-calls.
By intercepting 15 system-calls8, we can get all the interesting
events about system integrity: for example we are notiﬁed when
a ﬁle is created/written to/renamed/unlinked, a directory is cre-
ated/removed, etc.
Regarding the breakpoints, one of the major concerns is that how
can we know exactly where we must put the breakpoints into the
kernel? An intuitive answer for this question is to rely on the kernel
source code, and decide to put the breakpoints at related lines of
code. Clearly this is an convenient way, because we can inspect the
code and see where is the best place to intercept the system ﬂow. So
if we know the address in the memory of related lines of code, we
can put the breakpoints there. But then, we have another question:
how to determine the address of related lines of code?
Fortunately, this problem can be solved quite easily thanks to de-
bugging information coming with kernel binary. In fact, we can ex-
ploit a feature made for kernel debugger: If the kernel is compiled
with debug option, the kernel binary stores detail information in
DWARF format about the kernel-types, kernel variables and, most
importantly to our purpose, the kernel address of every source code
5This can be done thanks to the libxc function xc waitdomain()
6This can be done with a domain control hypercall, with the special
command XEN DOMCTL setdebugging
7The virtual interrupt is named VIRQ DEBUGGER
8Thus 15 breakpoints are put into the kernel memory of protected
VM
One more advantage of XenFIT is that it is quite ﬂexible: be-
cause of its design, we can start or stop monitoring any DomU at
any time we like, just by removing the breakpoints from its kernel.
Even better, all the modiﬁcation can be quietly done from Dom0,
and that can make XenFIT even more stealthy to the intruder inside
the protected DomU.
Another advantage of XenFIT is that we can centralize all the
security policies of protected DomUs in Dom0, thus managing and
updating them can be done very easily. This beneﬁt is mostly wel-
comed by the administrator, because otherwise the burden of keep-
ing control on scatter policies in various VMs is very big, especially
for system with hundred VMs running on it.
All the approaches above lead us to the design of XenFIT as
followings.
3.2 XenFIT Design
3.2.1 XenFIT Architecture
XenFIT comes in a shape of a daemon process named xenﬁtd
and runs in user-space of Dom0. It put breakpoints into the ker-
nel memory of the protected VM, and handles the interrupt events,
which happen when the breakpoints are hit. The overall and simpli-
ﬁed architecture of XenFIT is outlined in Fig.1. In our architecture,
Figure 1: XenFIT architecture
whenever a breakpoint is hit inside the DomU’s kernel, control is
changed to xenﬁtd staying inside Dom0, and the DomU itself is
paused. All of these jobs are done by the hypervisor automatically
and we do not need to modify any part of the hypervisor for this
“feature”. The xenﬁtd daemon then accesses the DomU’s kernel
and gather necessary information related to the breakpoint. Af-
ter that it resumes the DomU and let it continue running normally.
The whole process is repeated when the next breakpoint is hit in
DomU’s kernel.
Regarding the collected information, xenﬁtd veriﬁes them against
a security policy of corresponding DomU, and an alarm is ﬁred if
a violation is conﬁrmed. Besides, xenﬁtd also logs the collected
information to ﬁle-system of Dom0, so the administrator can take
a closer look when investigating the potential problems.
3.2.2 Performance Challenge
One of the challenges of XenFIT is the performance penalty
problem: every breakpoint in DomU leads to several hyper-switchs:
ﬁrst is a switch from DomU kernel to hypervisor when the break-
point is hit; second is a switch from hypervisor to Dom0 to have
197
2056 static long do_unlinkat(int dfd,
const char __user *pathname)
int error=0;
char * name;
name=getname(pathname);
if(IS_ERR(name))
return PTR_ERR(name);
error=do_path_lookup(dfd, name,
LOOKUP_PARENT, &nd);
dentry=lookup_hash(&nd);
error=PTR_ERR(dentry);
if (!IS_ERR(dentry)) {
error=vfs_unlink(nd.dentry->d_inode,
dentry);
exit2:
dput(dentry);
}
2057 {
2058
2059
...
2063
2064
2065
2066
2067
2068
...
2075
2076
2077
...
2084
2085
2086
2087
...
Figure 2: The unlink system-call source code of Linux kernel
2.6.16
with other system-calls that only work with ﬁle-descriptor
like write to ﬁgure out which ﬁle (in term of path-name) is
affected.
• Close system-call: A process can open and close many ﬁles
in its lifetime, and the old ﬁle-descriptor can be reused. By
watching the close system-call and correlate with open system-
call, we can know exactly which ﬁles are still open.
Besides, it is essential to have information about related user-id
and process-id which generated the event. To achieve these kind of
information, we can access other kernel object, such as task struct
structure of the current process. Thanks to the kernel types infor-
mation got from the DWARF data coming in the kernel binary, we
can access to all kernel objects, as well as extract out all the struc-
ture ﬁelds (More on this problem will be discussed in the Imple-
mentation section below).
3.2.5
Once we know which ﬁle is processed, to detect the intrusion we
must rely on the security policy. For each protected DomU, XenFIT
has a separate policy, and it must verify the collected events against
the pre-deﬁned policy and report the violations accordingly. At the
moment the available policies are:
Security Policy
• ReadOnly policy: All modiﬁcations except access times will
be reported for these ﬁles. The binary ﬁles in /usr/bin and
system conﬁguration ﬁles (for example ﬁles in /etc directory)
are good candidates to have this policy.
• IgnoreAll policy: No modiﬁcations will be reported. This
policy can be applied for /tmp, for example.
• IgnoreNone policy: All modiﬁcations such as owner and
access-mode will be reported. Critical ﬁles such as kernel
System-call Gathered information
open
close
mkdir
rmdir
link
unlink
rename
setattr
mknod
chmod
chown
setuid
write
setxattr
removexattr
A ﬁle is open
A ﬁle is close
A directory is created
A directory is removed
A link ﬁle is created
A ﬁle is removed
A ﬁle is renamed
File-permission is changed
A device ﬁle is created
Access mode of a ﬁle is changed
Owner of a ﬁle is changed
A ﬁle is set uid, thus run with higher privilege
A ﬁle is written to
Extra attributes are set on a ﬁle
Extra ﬁle attributes are removed
Table 1: List of system-calls adopted by XenFIT
line ([7]). As a result, we only need to compile DomU’s kernel with
debug option on, and analyze the kernel binary to get the kernel ad-
dresses of the source code lines we want to insert the breakpoints
to. Note that this option only generates a big debugged kernel bi-
nary ﬁle besides the normal kernel binary, and this debugged kernel
saves all the information valuable for debugging process. We can
still use the normal kernel binary, thus the above requirement does
not affect our system at all.
To make clear on where to insert breakpoints, let us look at one
example: the unlink system-call in the Fig. 2. In this function, the
unlink system-call successfully removes a ﬁle in line 2086. Be-
cause other error path does not remove the ﬁle, thus does not affect
the ﬁle-system integrity, we should focus on this line of code and
put the breakpoint there. When XenFIT is notiﬁed of this break-
point, it comes to get the value of the variable name, which stores
the removed ﬁle-name. Besides, we should also get the value of the
variable error, which tells us the result of the system-call. We can
get the address of these variables name and error from the DWARF