title:KHyperLogLog: Estimating Reidentifiability and Joinability of Large
Data at Scale
author:Pern Hui Chia and
Damien Desfontaines and
Irippuge Milinda Perera and
Daniel Simmons-Marengo and
Chao Li and
Wei-Yen Day and
Qiushi Wang and
Miguel Guevara
(cid:19)(cid:17)(cid:18)(cid:26)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:1)(cid:52)(cid:90)(cid:78)(cid:81)(cid:80)(cid:84)(cid:74)(cid:86)(cid:78)(cid:1)(cid:80)(cid:79)(cid:1)(cid:52)(cid:70)(cid:68)(cid:86)(cid:83)(cid:74)(cid:85)(cid:90)(cid:1)(cid:66)(cid:79)(cid:69)(cid:1)(cid:49)(cid:83)(cid:74)(cid:87)(cid:66)(cid:68)(cid:90)
KHyperLogLog: Estimating Reidentiﬁability and
∗
, Daniel Simmons-Marengo
,
Joinability of Large Data at Scale
∗
Pern Hui Chia
∗†
∗
, Irippuge Milinda Perera
∗
, Wei-Yen Day
∗
, Miguel Guevara
, Damien Desfontaines
∗
Chao Li
∗
∗
, Qiushi Wang
ETH Z¨urich
†
Google,
∗{pernhc, milinda, dasm, chaoli, wday, qiushi, mgt}@google.com,
†
PI:EMAIL
Abstract—Understanding the privacy relevant charac-
teristics of data sets, such as reidentiﬁability and joinabil-
ity, is crucial for data governance, yet can be difﬁcult for
large data sets. While computing the data characteristics
by brute force is straightforward, the scale of systems
and data collected by large organizations demands an
efﬁcient approach. We present KHyperLogLog (KHLL),
an algorithm based on approximate counting techniques
that can estimate the reidentiﬁability and joinability risks
of very large databases using linear runtime and minimal
memory. KHLL enables one to measure reidentiﬁability of
data quantitatively, rather than based on expert judgement
or manual reviews. Meanwhile, joinability analysis using
KHLL helps ensure the separation of pseudonymous
and identiﬁed data sets. We describe how organizations
can use KHLL to improve protection of user privacy.
The efﬁciency of KHLL allows one to schedule periodic
analyses that detect any deviations from the expected risks
over time as a regression test for privacy. We validate the
performance and accuracy of KHLL through experiments
using proprietary and publicly available data sets.
I. INTRODUCTION
Understanding and monitoring the privacy state of pro-
duction systems is a crucial element of privacy engineer-
ing. Data-ﬂow analysis enables one to know which data
processing workﬂows are reading which data and gener-
ating which outputs. Static and dynamic code analyses
help to understand what binaries do at a more granular
level e.g., whether they use pre-approved APIs, whether
they read or write sensitive data types, or whether they
use safe defaults. Potential violations of privacy policies
can be surfaced at code review time before an engineer
is allowed to run workﬂows in production systems.
While data ﬂow analysis and code analysis are power-
ful tools, characterizing the data to assess their sensitivity
(such as we propose in this paper) can often be useful
or necessary. While human reviewers often have good
intuitions and context about the sensitivity of data, there
are obvious limitations: humans may make mistakes, and
are limited in how much they can review. An automated
analysis system can be accurate and scalable. Where
humans would have to settle for evaluating a system or
data set once, automated systems can be re-run. This
provides regression testing for privacy characteristics
and enables data custodians to be conﬁdent about the
properties of their systems.
Automatic evaluation becomes challenging as data set
size increases and data becomes increasingly hetero-
geneous. While brute force approaches will work for
smaller data sets, their runtime and memory require-
ments become unworkable when run on petabytes of
data.
We identify two characteristics of data sets that are
often useful during privacy impact assessments: reiden-
tiﬁability and joinability, and develop a new, scalable,
automated approach to measuring them. While these
terms may have different connotations, we deﬁne and
use them consistently throughout the paper.
Reidentiﬁability is the potential that some supposedly
anonymous or pseudonymous data sets could be de-
anonymized to recover the identities of users. A good
practice is to keep reidentiﬁable data sets guarded with
strict access control and access audit trails. As companies
collect more information to build useful services it can
be difﬁcult to manually determine when a data set be-
comes reidentifying and requires more careful handling.
The ability to estimate the reidentiﬁability of data sets
automatically and efﬁciently reduces the work required
of data custodians to manually label the different data
sets.
Joinability measures whether data sets are linkable by
unexpected join keys. Sometimes it is necessary to retain
multiple data sets with different ID spaces. In those cases
data custodians should avoid linking the two data sets
to respect the choices of users who maintain separate
identities. As an example, consider a website that can be
used either signed-in or signed-out. A user may choose
(cid:165)(cid:1)(cid:19)(cid:17)(cid:18)(cid:26)(cid:13)(cid:1)(cid:49)(cid:70)(cid:83)(cid:79)(cid:1)(cid:41)(cid:86)(cid:74)(cid:1)(cid:36)(cid:73)(cid:74)(cid:66)(cid:15)(cid:1)(cid:54)(cid:79)(cid:69)(cid:70)(cid:83)(cid:1)(cid:77)(cid:74)(cid:68)(cid:70)(cid:79)(cid:84)(cid:70)(cid:1)(cid:85)(cid:80)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:15)
(cid:37)(cid:48)(cid:42)(cid:1)(cid:18)(cid:17)(cid:15)(cid:18)(cid:18)(cid:17)(cid:26)(cid:16)(cid:52)(cid:49)(cid:15)(cid:19)(cid:17)(cid:18)(cid:26)(cid:15)(cid:17)(cid:17)(cid:17)(cid:21)(cid:23)
(cid:20)(cid:22)(cid:17)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:06 UTC from IEEE Xplore.  Restrictions apply. 
to use the website signed-out to separate activities from
their signed-in identity. If the website operator maintains
data sets about activities of both signed-in and signed-out
users, it might accidentally include granular information
(e.g. web browser user agent) in both data sets that could
allow the signed-in and signed-out identities to be linked.
In that case, we would say that the identities in the two
data sets are joinable.
There are various existing metrics
for comput-
ing reidentiﬁability and joinability. For example, k-
anonymity [1] and l-diversity [2] are two popular mea-
sures for reidentiﬁability. Meanwhile, data similarity are
commonly measured using Jaccard index [3] or contain-
ment [4]. Two data sets are joinable if there exist a pair
of data ﬁelds, similar in content, that can serve as a join
key. Yet, managing reidentiﬁability and joinability risks
at scale is more challenging than it appears. The naive
approach requires memory proportional to the size of the
data set, which becomes extremely difﬁcult as data set
sizes climb into the petabytes. Our experiments reveal
how costly this naive approach is even for data sets in
the order of gigabytes (see Section VIII). Linear runtime
and sublinear memory are necessary for large-scale data
analysis.
Contributions. In this paper we present the KHyper-
LogLog (KHLL) algorithm and demonstrate how it can
be used to efﬁciently characterize both the reidentiﬁa-
bility and joinability of very large data sets. Adapted
from the ﬁeld of approximate counting, KHLL produces
quantitative measures for reidentiﬁability and joinability
using only a single pass over the data set and minimal
memory. Both reidentiﬁability and joinability of data
sets can be estimated using the compact data structures
(colloquially known as “sketches”) of KHLL rather than
raw data. In addition, the approach is format-agnostic,
allowing it to analyze any data set without modiﬁcation.
We have validated that KHLL is fast, parallelizable and
accurate on both proprietary and public data sets.
This paper starts by describing the design goals and
challenges in Section II, and how KHLL can be used
improve protection of user privacy in organizations with
large data sets in Section III. We provide some back-
ground on approximate counting in Section IV before
presenting our KHLL algorithm in Section V. Next, we
describe the use of KHLL for reidentiﬁability analysis
in Section VI and joinability analysis in Section VII.
We evaluate the performance and accuracy of KHLL
empirically in Section VIII and Section IX. We present
the related work in Section X before concluding in
Section XI.
II. QUANTIFYING REIDENTIFIABILITY AND
JOINABILITY AT SCALE
Our main goal is to design an efﬁcient approach for
quantifying the reidentiﬁability and joinability risks of
large data sets. Speciﬁcally, it should help mitigate the
risk of mistakes by engineers (e.g., adding additional
ﬁelds to data sets without realizing they are overly
unique or pose joinability risks) particularly as complex
production systems evolve. We assume that everyone
using KHLL wants to measure the privacy risks of
their data sets, and so we don’t defend against users
attempting to get KHLL to under-report the risks of their
data.
We introduce the metrics for reidentiﬁability and join-
ability that will be used in the rest of this paper. These
metrics are deﬁned on individual data ﬁelds and can be
directly extended to any combinations of ﬁelds.
A. Reidentiﬁability by Uniqueness Distribution
Let F = {fi} be the set of all values of a ﬁeld,
and ID = {idj} be the set of all user IDs. Let
{(fi, idj)} ∈ F × ID denote the pairs of F and ID
values as found in a given data set D. Speciﬁcally, let
ID[fi] = {idj : (fi, idj) ∈ D} be the set of user IDs
associated with a given ﬁeld value fi in D.
Deﬁnition 1. The uniqueness of a ﬁeld value fi with
respect to ID is given by the number of unique IDs
associated with fi i.e., |ID[fi]|.
Deﬁnition 2. The uniqueness distribution of F with
to ID is estimated by the histogram of the
respect
uniqueness of individual values in F in data set D.
Different from k-anonymity [1] which computes the
minimum number k of unique IDs associated with any
values in F , we propose to keep the entire distribution
of k so that it will be easy to compute the fraction of
values in F with high reidentiﬁability risks, and thus
the potential impact to the data when one would like to
protect the data with k-anonymity or its variants.
In practice, the uniqueness distribution can be skewed.
A few values in F might appear with high frequency
while other values may pose high reidentiﬁability risks
as they associate with only a small number of user IDs.
As an example, imagine a log that contains the User
Agent (UA) of users who visit a site. UA is an HTTP
header ﬁeld which describes the application type, oper-
ating system, software vendor and software version of
an HTTP request. To gauge the reidentiﬁability of UAs,
one can estimate the uniqueness distribution by counting
(cid:20)(cid:22)(cid:18)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:06 UTC from IEEE Xplore.  Restrictions apply. 
the number of unique IDs that individual UA strings
associate with. We expect a high percentage of raw UA
strings to be associated with only one or a few user IDs
and thus reidentifying [5].
B. Joinability by Containment
Let F1 and F2 represent the sets of values of two ﬁelds
in data sets D1 and D2 respectively. Let |F1| denote the
number of unique values in F1, i.e., the cardinality of
F1, and F1 ∩ F2 denote the set of values in both F1 and
F2 (the intersection). We measure the joinability of D1
and D2 through F1 and F2 using the containment metric.
Deﬁnition 3. The containment of F1 in F2 is the ratio
between the number of unique values of the intersection
of F1 and F2, and the number of unique values in F1
i.e., |F1 ∩ F2|/|F1|.
Note that containment is similar to the Jaccard Index
but it is asymmetric. Unlike the Jaccard Index which
computes the ratio between the number of unique values
in the intersection of F1 and F2, and the union of F1
and F2, containment uses the number of unique values
in either F1 or F2 as the denominator. This difference is
important when F1 and F2 differ in size. Imagine one
data set that contains a small subset of the users from a
larger data set. The Jaccard Index will always be small
and would not report joinability risk even when all values
of F1 are contained in F2.
C. Scalability Requirements
While both uniqueness distribution and containment
are easy to compute on small data sets, the computation
will need to scale to handle very large data sets. In
addition to hosting user content for digital services,
organizations collect data for providing physical services
(e.g., healthcare and location-based services), improving
user experience and service availability, and anti-spam
and fraud detection purposes. The scale of data can be
huge, both in terms of the number of data ﬁelds and
rows, and the number of databases.
It would be a Herculean task for human reviewers
to manually oversee all product iterations and changes
to data strategies. In a similar fashion, individual well-
intentioned groups of engineers also ﬁnd it hard to keep
up with the increasingly large number of policy and
regulatory requirements.
An ideal system for measuring reidentiﬁability and
joinability that is scalable will need to use efﬁcient and
parallelizable algorithms. Also, as increasingly heteroge-
nous data is collected and used it will need an approach
agnostic to data types and formats to handle data sets
generated by different engineering teams.
III. APPLYING KHLL TO PROTECT USER PRIVACY
Data custodians can use KHLL in a number of differ-
ent ways to improve user privacy.
Quantitative Measurement: KHLL can be used to
quantitatively measure the reidentiﬁability risk of a data
set. This can inform data custodians about the sensitivity
of data and its risks so they can plan a suitable and
appropriate data strategy (e.g., anonymization, access
controls, audit trails) at points in the life cycle of the data,
including data collection, usage, sharing and retention (or
deletion).
Exploring Data Strategies: The efﬁciency of KHLL
provides data custodians a powerful analysis tool for
exploring different data sanitization strategies. Many data
analysis tasks (e.g., experimentation to improve service
availability, anti-spam and fraud detection) can use a
projection (view) of a high-dimensional data set that is
protected with k-anonymity [1] (or related techniques
such as l-diversity [2] or anatomy [6]). KHLL can be run
on different possible combinations of ﬁelds in the data
set at once to estimate how much data will be lost as a
function of the technique. Together, the data custodian
and data analysts can decide how to trade off the utility
of the data projection and the reidentiﬁability risk (e.g.,
which ﬁelds to be included, suppressed, generalized or
made disjoint in separate data sets, and whether the data
needs stronger guarantees like differential privacy [7]).
Consider the Netﬂix prize data set, which contains
the movie ids and ratings given by different users at
different dates (year, month and day). Analyzing the
data set using KHLL, we obtain results that mirror those
of Narayanan and Shmatikov [8]. While no single ﬁeld
has high uniqueness (e.g., we observe that all movies
included in the data set are rated by at least 50 users),
the combination of movie ratings and dates are highly
unique. An efﬁcient analysis using the like of KHLL
might have helped the Netﬂix team to measure the
reidentiﬁability risks, explore alternatives for treating the
data, or to potentially conclude that the risk was too high
to share the data externally.
Regression Testing: In cases where data custodians
regularly produce k-anonymous (or the like) data sets,
KHLL can be further used as a regression test. KHLL
analysis can be run on the output as part of
the
anonymization pipeline to expose any implementation
bugs, or to alert on any unexpected changes to the
characteristics of the input data.
(cid:20)(cid:22)(cid:19)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:06 UTC from IEEE Xplore.  Restrictions apply. 
Joinability Assessment: KHLL can also enable efﬁ-
cient joinability assessment to protect user privacy. If an
organization collects data about users under multiple ID
spaces in different contexts (e.g. signed in vs signed out),