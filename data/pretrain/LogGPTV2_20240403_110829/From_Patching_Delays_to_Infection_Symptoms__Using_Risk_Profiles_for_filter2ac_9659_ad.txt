• “Raw features”: Trained with [Raw] features on 10
days of observational data post-disclosure.
3We did not use PCA for dimensionality reduction in order to retain
interpretability of the features used.
• “Day x”: A set of classiﬁers trained using only
[Community] and on x days of observational data
post-disclosure (for both symptoms and risk). Only
CVEs whose known detection dates are beyond day
x are used for testing these classiﬁers.
• “Back x”: A set of classiﬁers trained using only
[Community] and on 10 days of observational data
starting from x days before disclosure (for both
symptoms and risk).
• “Intrinsic features”: Trained using [Intrinsic] and
[CVSS] families of features.
• “Community+Intrinsic”: This is a classiﬁer trained
with [Intrinsic] and [Community] features on 10
days of observational data post-disclosure.
• “Direct+Raw+Intrinsic”: This is a classiﬁer trained
with [Intrinsic], [Direct], and [Raw] features on 10
days of observational data post-disclosure.
The main comparison is given in Figure 8a. We see a
remarkable improvement in detection performance when
we combine the community features with CVE intrin-
sic features. We see that even though both community
and direct features are extracted from the raw features,
they both perform much better than directly using raw
features.
In particular, the community detection based
method is shown to perform the best among these three.
The reason why extracted features perform better than
raw features is because with the latter a lot of the tempo-
ral information embedded in the time series data is under-
utilized (e.g., in decision tree type of classiﬁers, time se-
ries data are taken as multiple individual inputs), whereas
the features we extract (either in the form of community
comparison or in the form of row-by-row correlation) at-
tempt to preserve this temporal information.
Additionally, we see that combining community fea-
tures with intrinsic features achieves very good detection
912    27th USENIX Security Symposium
USENIX Association
performance, almost similar to the concatenation of all
features; this suggests that when combined with intrin-
sic features, community features can effectively replace
the use of raw and direct features. Finally, the overall at-
tainable performance is very promising: 96% AUC, and
90% and 10% true and false positive rates. The same set
of results are re-plotted in terms of precision and recall
in Figure 8b.
As mentioned earlier and observed here, the intrinsic
features by themselves are not particularly strong predic-
tors, and weaker than the community features when used
alone, as measured by AUC (69%). This is because the
intrinsic features are a priori characterizations of a vul-
nerability (thus the use of which amounts to prediction),
whereas community features are a posteriori signs of ex-
ploitation, allowing us to perform detection.
It is thus
not surprising that the latter is a more powerful metric. It
is however promising to see that the two sets of features
complement each other well by providing orthogonal at-
tributes for predicting/detecting exploitation, resulting in
much higher performance when combined.
It should be noted that this level of performance still
falls short of what could be attained in a typical intrusion
detection systems (IDS) or spam ﬁlters, and there are a
few reasons for this. Firstly, as mentioned earlier our la-
beling of vulnerabilities as exploited and non-exploited
may be noisy: some exploited vulnerabilities may have
remained unidentiﬁed and unreported. Secondly, in an
IDS type of detection system there are typically very spe-
ciﬁc signatures one looks for, whereas in our setting the
analysis is done over large populations where such sig-
natures become very weak or non-existent; e.g., we can
only observe if a host is sending out spam without any
visibility into how or why. Accordingly, a performance
gap is expected if comparing to IDS type of detection
systems. It is however worth noting that in our setting a
false positive is not nearly as costly as one in an IDS; ours
would merely suggest that an as-yet unexploited CVE
should be prioritized for patch development/deployment,
which arguably would have to be done at some point re-
gardless of our detection result.
If multiple CVEs are simultaneously exploited, our
detection can still work as long as the hosts have non-
identical patching behavior for these CVEs. This is be-
cause the risk behavior would be different even if the in-
fection groups are the same, as we showed in Figure 2c.
If the host population also exhibit the same patching be-
havior toward these CVEs, then the resulting ambiguity
will cause our algorithm to “detect” all of these CVEs,
only one/some of which are the culprit. This would be
another type of false positive; the consequence however
is again limited – all these CVEs will be suggested as
high priority even though one or some of them could
have waited.
Note that the accuracies presented here are obtained
in spite of multiple sources of noise that can appear in
our datasets or imperfections in our methodology. For
instance the one-to-multiple mapping from symptoms of
malicious behavior (indicated by RBLs) to vulnerabili-
ties, especially when multiple vulnerabilities appear in
the same time window, and hosts appearing in a black-
list for reasons other than exploitation of software vul-
nerabilities, can introduce noise in the measured symp-
toms (malicious activities). Furthermore, aggregation at
a coarse level can lead to only observing the averages
of behavior that could otherwise be utilized to detect ex-
ploitation. However, the ground-truth for testing the per-
formance of our technique is independent of the afore-
mentioned sources of noise, and the observed perfor-
mance shows that our method is, to a large extent, robust
to these imperfections.
We next examine the impact of the length of the ob-
servational period when using community detection, by
comparing the ROCs of classiﬁers trained using differ-
ent number of days, immediately following disclosure, as
well as starting from a few days before disclosure. This
is shown in Figure 8c. We see that as we increase the
observation period post-disclosure the predictive power
of the similarity comparison improves. This is to be
expected as longer periods are more likely to capture
symptoms of infection especially during the early days
as vulnerabilities are just starting to be exploited. Inter-
estingly, starting the observation even before disclosure
also seems to be picking up information, an indication
that some exploits do start earlier than ofﬁcial disclosure
as mentioned in the introduction. Among the examined
set the “Day 4” version is the worst-performing; this is
due to a very short window of observation, only 4 days
post-disclosure. This short window affects the effective-
ness of time series data analysis but also is more likely to
miss information that is just emerging post-disclosure.
7 Case Studies and Discussion
In this section we present a few examples of our sys-
tem’s output for (potentially) zero-day EIW vulnerabili-
ties, and discuss the robustness of our technique against
strategic attackers, and its practical utility for building
real-world monitoring of software vulnerabilities.
7.1 Case studies
Figure 8c suggests that by performing a retrospective
analysis on the disclosure date, our technique can also
detect zero-day exploits. We now discuss two such ex-
amples below, both of which were detected by the “Back
10” classiﬁer with an operating point (corresponding to
USENIX Association
27th USENIX Security Symposium    913
a threshold of 0.7) of 80.6% true positive and 20% false
positive rate.
CVE-2013-0640 This vulnerability affects Adobe Ac-
robat Reader and was disclosed on 02/13/2013 [1].
It
allows remote attackers to execute arbitrary code via a
crafted PDF document. Our system detected this vulner-
ability on the same day as disclosure using data from the
preceding 10 days. Interestingly, we also found proof of
zero-day exploits for this vulnerability [7].
CVE-2013-5330 This vulnerability affects several ver-
sions of Adobe Flash Player and was disclosed on
11/12/2013. It allows attackers to execute arbitrary code
or cause a denial of service (memory corruption) via un-
speciﬁed vectors. Again, our system detected that this
vulnerability on the disclosure day using data from the
preceding 10 days. While this vulnerability has been re-
ported as exploited in the wild, the earliest report was on
01/28/2014 [11]; our results suggest that this CVE might
have been exploited months before this date.
7.2 Robustness against strategic attacks
In security applications, strategic adversaries always
have incentive to manipulate instances they have con-
trol over to evade detection [44, 50, 49, 16]. During
such manipulations, the attacker usually needs to mimic
normal user behavior as well as preserving their original
malicious functionality without making arbitrarily large
changes. Since our detection method relies on models
trained using measurement data, it is potentially vulner-
able to attempts of data manipulation. An adversary of
the second type mentioned in Section 2.3 is such an ex-
ample: we assume it has the ability to alter the patching
information (as it is collected) from a signiﬁcant number
of hosts, so as to alter the aggregate signals and skew the
similarity analysis. Below we examine how robust our
detection system is against such evasion attempts.
We will simulate this data manipulation by altering the
risk signals for a group of ISPs. Speciﬁcally, we ran-
domly select a set of N ISPs from the total population I
and revise their risk signals as follows:
n(t) ←− ∑i∈N w j
w j
i (t)
(cid:107)N(cid:107) ± γ · w j
n(t), n ∈ N,
(3)
where the ﬁrst term is the average value among this con-
trolled group of ISPs, and γ is randomly drawn from the
set (0.1,0.2,0.3) for each n (similarly, ± is determined
by a random coin ﬂip) to serve as a small perturbation
around the average. The intention of this manipulation is
to make these N values very similar to each other, each
a small perturbed version of the common average; this
Figure 9: Robustness of performance against an
adversary controlling hosts within a percentage of all
ISPs (x-axis).
revision also preserves the original average so as to min-
imize the likelihood detection by a simple statistical test.
For each selection N we perform 20 random trials of
the detection algorithm, each over different random per-
turbations shown above. The average AUC is reported in
Figure 9 as we increase the size of N, from 10% to 45%
as a fraction of the overall ISP population I . As can
be seen, our method is fairly robust against this type of
evasion attacks with gracefully degrading performance.
It should be noted that for examining the robustness of
our method we have assumed a powerful (and not very
realistic) adversary; even at 10% this would have been
an extremely costly attack as it indicates the control of
hosts within hundreds of ISPs.
7.3 Practical use
We next discuss how the proposed methodology could
be used in practice, in real time, and by whom. Any soft-
ware or AV vendor, as well a security company would
perform such a task; they typically have access to data
similar in nature to WINE. The RBLs and NVD are pub-
licly available, so is IP intelligence data (usually at a
cost). Since we rely on CVE information to perform user
patching data aggregation (risk with respect to speciﬁc
vulnerabilities) and on intrinsic features of a vulnerabil-
ity, the detection process is triggered by a CVE disclo-
sure. Following the disclosure, malicious activity data
and user patching data can be processed on a daily ba-
sis. On each day following the disclosure we have two
signals of length: risk signal w(t) and symptom signal
r(t) for each ISP. Community detection, feature extrac-
tion, and detection then follow as we described earlier. In
addition, the community structure can be updated in an
online fashion, so the information can be obtained and
maintained in a computationally efﬁcient manner [27].
914    27th USENIX Security Symposium
USENIX Association
How our detection system can enhance security in
practice lies in the primary motivation of this study:
[38] has measured the portion of the vulnerability win-
dow (time from disclosure to patch installation) that is
incurred by user negligence for four of the products
included in this paper, the largest is roughly 60% for
Chrome and Flash Player; suggesting delays may exist
in patch development. The ability to detect active ex-
ploits early would allow a software vendor to better pri-
oritize patch development and more judiciously allocate
its resources. A secondary use of the system is to allow
a network (e.g., an ISP) to identify its most at-risk host
populations that have not patched a vulnerability with de-
tected exploits, and encourage prompt actions by these
hosts. This system is not meant to alter individual end-
user patching behavior, but would allow users through
silent updates to get patches sooner for vulnerabilities
most at risk of being exploited.
Furthermore, [30] suggests that in the timeline of evo-
lution of software patches, patch development happens
soon after vulnerability disclosure, yet there is a gap
prior to patch deployment, as, e.g., enterprises want to
test patches before they deploy them. In this landscape,
early detection can also be utilized by enterprises to pri-
oritize patch deployment of vulnerabilities that are being
actively exploited. Our community detection method can
be used to complement intrinsic attributes of a CVE, such
as the CVSS score, to detect critical vulnerabilities with
more precision. Additionally, the ability to detect ma-
chines with critical software vulnerabilities helps third-
parties better assess a ﬁrm’s cyber-risk, e.g., to design
cyber-insurance policies and incentivize ﬁrms to improve
their state of security [25, 26].
Note that our proposed technique relies on observ-
ing spam activity to detect compromised hosts, there-
fore our methodology fails to recognize exploits that do
not result in any spam activity. However, once a ma-
chine is compromised, it is up to the attacker how they
use the infected host, e.g., for ransomware, or to send
spam. Even though a vulnerability might be used mainly
for non-spam activities, one can detect exploitation as
long as a portion of infected devices are used for send-
ing spam. Nevertheless, infected hosts discovered by al-
ternative bot detection techniques (e.g., scanning activ-
ity extracted from network telescope data and/or honey-
pots [3]) can be appended to the proposed symptomatic
data, in order to build a more robust system.
Finally, while our technique is evaluated over mea-
surements that are 3-4 years old (due to unavailabil-
ity of the WINE dataset), the updating mechanism em-
ployed by the software examined herein have remained
largely the same. In particular, except for Adobe Acrobat
Reader, all of the software included in this study were
using silent updates to automatically deliver patches to
users, at the start of our observation windows (1/2013).
This supports our claim that the same dynamics apply to
more recent vulnerabilities, where even though patches
are developed and disseminated by vendors through au-
tomated mechanisms, users and enterprises often opt out
of keeping their software up to date, leading to eventual
exploitation, and then followed by observation of symp-
toms. WannaCry and NotPetya outbreaks (exploiting
CVE-2017-0144), and the Equifax data breach (caused
by CVE-2017-5638) are all recent examples of this phe-
nomena, where patches for the underlying vulnerabilities
had been disseminated by software vendors months be-
fore each incident, but had not yet been deployed on the
compromised machines [46, 47, 20].
8 Related Work
Bozorgi et al. [8] used linear support vector to predict
the development of proof-of-concept (POC) exploits by
leveraging exploit metadata. Our interest in this study is
solely on exploits in the wild and their early detection. In
[36] social media was used to predict ofﬁcial vulnerabil-