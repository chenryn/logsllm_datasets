of logging into her bank account. No attack was simulated
against the users during this task.
Requiring users to use their own accounts is certainly
a good start for creating a sense of risk, but the degree to
which the academic setting of the physical location of these
studies affected the users’ evaluation of their actual risk is
unclear. Even if the experimenters were not in the same
room as the users while they used the computer, the fact that
they were nearby may have inﬂuenced the users to appear
“helpful” and behave with less caution than they normally
would.
A few studies have simulated attacks against users in
the ﬁeld without obtaining prior consent. One study at the
United States Military Academy at West Point sent cadets
a simulated phishing email from a ﬁctitious Colonel “com-
manding” them to click on a link [19]. Studies by Jagatic
et al. [30] and Jakobsson et al. [31] also remotely simu-
lated phishing attacks against users. Although these studies
closely simulated real attacks, provided large data sets, and
achieved a high level of ecological validity, the absence of
prior consent raises ethical issues. After learning that they
were unknowing participants in one study, some users re-
sponded with anger and some threatened legal action [11].
Also, these studies collected only a limited amount of de-
mographic and behavioral data and did not conduct a exit
survey to probe users’ decisions.
Email for authentication. Other researchers have pro-
posed leveraging email for authentication [2, 6, 21, 23, 48].
In particular, the design of Simple Authentication for the
Web (SAW) by Horst and Seamons is similar to our email
registration ceremony [48]. The main difference is that we
propose using email only for relatively infrequent machine
registrations, i.e., credential initialization, while the SAW
authors propose using email authentication as a direct re-
placement for passwords.
In SAW, users receive a fresh
email link during each authentication attempt. Also, the
SAW authors do not consider social engineering attacks that
try to steal authentication links.
conditioning
and education. Previous
anti-
User
phishing research has attempted to take advantage of user
conditioning by using secure attention keys. Two anti-
phishing tools, PwdHash [43] and Web Wallet [59], employ
a secure attention key to create a trusted path between the
user and the browser. Although these tools require users
to activate the secure attention key before entering any
sensitive information, they may be vulnerable to attacks
which persuade users to omit the SAK (Section 4.1). A
user study of Web Wallet suggests that this attack strategy
can be effective [59].
Related to conditioning is training and education. Sev-
eral
researchers have proposed innovative educational
methods for teaching users about Internet security and so-
cial engineering attacks [35, 45, 56]. Their initial results
are promising, and related research suggests that users who
better understand Internet risks may be more likely to resist
attacks [15]. However, user education may have its limita-
tions. If education is not periodically reinforced, satisﬁcing
users may forget or omit defensive habits they have learned.
Also, a study consisting of interviews designed to reveal
users’ decision making strategies for suspicious emails sug-
gests that while users may be able to manage risks they are
familiar with, it can be difﬁcult for them to generalize this
knowledge to resist unfamiliar attacks [14]. These results
suggest that educational approaches may require continual
adaptation to address new attacks; otherwise users’ defen-
sive strategies may become outdated and ineffective.
12 Conclusion
Our study results suggest that 1) ceremonies can affect
user behavior, for better or worse, and 2) the resiliency of
a ceremony to social engineering is related to whether the
actions it conditions users to take are safe to perform in
the presence of an adversary. These results suggest that
conditioned-safe ceremonies may be a useful notion for
building ceremonies which resist social engineering attacks.
We proposed several design principles for conditioned-safe
ceremonies and described one ceremony, email registration,
designed according to these principles. Although email reg-
istration may be an imperfect approximation of what we
would ultimately like out of a conditioned-safe ceremony,
we believe it is nonetheless a useful example for explor-
ing and evaluating this notion further. Regardless, the fact
that 42% of email users in our study were vulnerable to our
simulated attacks exempliﬁes the formidable challenge in
designing ceremonies to resist social engineering attacks.
Acknowledgments
This work is
supported in part by the TRUST
Project (National Science Foundation award number CCF-
0424422) and the iCAST Project. The conclusions in this
paper are our own and do not necessarily reﬂect those of
the NSF, the US Government, or any other funding agency.
The authors also thank Rachna Dhamija, Allan Schiffman,
Marco Barreno, Adrian Mettler, Monica Chew, AJ Shankar,
Bill McCloskey, and the anonymous reviewers for their use-
ful comments.
References
[1] A. Adams and M. A. Sasse. Users are not the enemy. Com-
munications of the ACM, 42(12):40–46, 1999.
[2] B. Adida. BeamAuth: Two-Factor Web Authentication with
a Bookmark. In Proceedings of the Fourteenth ACM Confer-
ence on Computer and Communications Security (CCS 07),
pages 48–57, October 2007.
[3] C. M. Allwood. Error Detection Processes in Problem Solv-
ing. Cognitive Science, 8(4):413–437, 1984.
[4] Anti-Phishing Working Group.
http://www.
antiphishing.org/.
[5] Anti-Phishing Working Group.
Ebay - Update Your
Account MITM attack. http://www.antiphishing.
org/phishing_archive/05-03-05_Ebay/
05-03-05_Eba%y.html.
[6] D. Balfanz. Usable Access Control for the World Wide Web.
In Proceedings of the 19th Annual Computer Security Appli-
cations Conference, pages 406–416, December 2003.
[7] Bank of America SiteKey: Online Banking Security. http:
//www.bankofamerica/privacy/sitekey/.
[8] Browser market
share.
hitslink.com/report.aspx?qprid=0,
Sept. 11, 2008.
http://marketshare.
retrived
[9] R. Cialdini.
Inﬂuence: Science and Practice, 5th edition.
Allyn and Bacon, 2008.
[10] T. Close. Waterken YURL. http://www.waterken.
com/dev/YURL/httpsy/.
[11] C. Corley.
Students Go ‘Phishing’
for User
Info.
http://www.idsnews.com/news/story.aspx?
id=29400&comview=1.
[12] L. F. Cranor and S. Garﬁnkel, editors. Security and Us-
ability: Designing Secure Systems That People Can Use.
O’Reilly, 2005.
[13] R. Dhamija, J. D. Tygar, and M. Hearst. Why Phishing
Works. In Proceedings of the SIGCHI Conference on Hu-
man Factors in Computing Systems, pages 581–590, 2006.
[14] J. S. Downs, M. B. Holbrook, and L. F. Cranor. Decision
strategies and susceptibility to phishing. In Proceedings of
the Symposium on Usable Privacy and Security (SOUPS),
pages 79–90, July 2006.
[15] J. S. Downs, M. B. Holbrook, and L. F. Cranor. Behavior
In APWG 2nd Annual eCrime
response to phishing risks.
Researchers Summit, pages 37–44, October 2007.
[16] S. Egelman, L. F. Cranor, and J. Hong. You’ve Been
Warned: An Empirical Study of the Effectiveness of Web
Browser Phishing Warnings.
In Proceedings of the CHI
2008 Conference on Human Factors in Computing Systems,
2008.
[17] C. Ellison. Ceremony Design and Analysis. Cryptology
ePrint Archive, Report 2007/399, 2007.
[18] C. Ellison, C. Hall, R. Milbert, and B. Schneier. Protect-
ing Secret Keys with Personal Entropy. Future Generation
Computer Systems, 16(4):311–318, 2000.
[19] A. J. Ferguson. Fostering E-Mail Security Awareness: The
West Point Carronade. EDUCASE Quarterly, 28(1):54–57,
2005.
[20] J. Franklin, V. Paxson, A. Perrig, and S. Savage. An Inquiry
into the Nature and Causes of the Wealth of Internet Miscre-
ants. In 14th ACM Conference on Computer and Communi-
cations Security (CCS ’07), November 2007.
[21] S. Garﬁnkel. Email-based Identiﬁcation and Authentication:
An Alternative to PKI? IEEE Security & Privacy Magazine,
1(6):20–26, 2003.
[22] N. Good, R. Dhamija, J. Grossklags, D. Thaw, S. Aronowitz,
D. Mulligan, and J. Konstan. Stopping Spyware at the Gate:
A User Study of Notice, Privacy and Spyware.
In Pro-
ceedings of the Symposium on Usable Privacy and Security
(SOUPS), pages 43–52, July 2005.
[23] P. Gutmann.
Underappreciated Security Mechanisms.
http://www.cs.auckland.ac.nz/˜pgut001/
pubs/underappreciated.pdf.
[24] P. Gutmann.
Security Usability Fundamentals (Draft).
http://www.cs.auckland.ac.nz/˜pgut001/
pubs/usability.pdf, retrieved Sept. 7, 2008.
[25] C. Haney, W. Banks, and P. Zimbardo. Study of Prisoners
and Guards in a Simulated Prison. Naval Research Reviews,
9:1–17, 1973.
[26] A. Herzberg and A. Jbara. Security and Identiﬁcation In-
dicators for Browsers Against Spooﬁng and Phishing At-
tacks. ACM Transactions on Internet Technology (TOIT),
8(4), September 2008.
[27] ING Direct Privacy Center.
https://home.
ingdirect.com/privacy/privacy_security.
asp?s=newsecurityfe%ature.
[28] C. Jackson and A. Barth. ForceHTTPS: Protecting High-
Security Web Sites from Network Attacks.
In Proceed-
ings of the 17th International World Wide Web Conference
(WWW 2008), April 2008.
[29] C. Jackson, D. R. Simon, D. S. Tan, and A. Barth. An Eval-
uation of Extended Validation and Picture-in-Picture Phish-
ing Attacks. In Proceedings of Usable Security (USEC’07),
February 2007.
[30] T. Jagatic, N. Johnson, M. Jakobsson, and F. Menczer. So-
cial Phishing. Communications of the ACM, 50(10):94–100,
October 2007.
[31] M. Jakobsson and J. Ratkiewicz. Designing Ethical Phish-
ing Experiments: A Study of (ROT13) rOnl Auction Query
Features. In Proceedings of the 15th annual World Wide Web
Conference (WWW 2006), pages 513–522, May 2006.
[32] M. Just. Designing Authentication Systems with Challenge
Questions. In L. F. Cranor and S. Garﬁnkel, editors, Security
and Usability: Designing Secure Systems That People Can
Use, chapter 8, pages 143–155. O’Reilly, 2005.
[33] C. Karlof, J.D. Tygar, and D. Wagner. A User Study De-
sign for Comparing the Security of Registration Protocols.
In First USENIX Workshop on Usability, Psychology, and
Security (UPSEC 2008), April 2008.
[34] C. Karlof, U. Shankar, J.D. Tygar, and D. Wagner. Dynamic
Pharming Attacks and Locked Same-origin Policies for Web
Browsers. In Fourteenth ACM Conference on Computer and
Communications Security (CCS 2007), pages 58–72, Octo-
ber 2007.
[35] P. Kumaraguru, Y. Rhee, A. Acquisti, L. F. Cranor, J. Hong,
and E. Nunge. Protecting People from Phishing: The Design
and Evaluation of an Embedded Training Email System. In
CHI ’07: Proceedings of the SIGCHI conference on Human
factors in computing systems, pages 905–914, 2007.
[36] U. Maimon. Universal Man-in-the-Middle Phishing Kit –
http://www.rsa.com/
Why is This Even News?
blog/entry.asp?id=1160.
[37] S. Milgram. Obedience to Authority: An Experimental View.
Harper Collins, 1974.
[38] D. A. Norman. The Design of Everyday Things. Basic
Books, 1988.
[39] J. Rasmussen. What Can be Learned from Human Error
Reports? In K. D. Duncan, M. M. Gruenberg, and D. Wal-
lis, editors, Changes in Working Life, pages 97–113. Wiley,
1980.
[40] J. Rasmussen.
Skills, Rules, and Knowledge: Signals,
Signs, Symbols and Other Distinctions in Human Perfor-
mance Models. IEEE Transactions on Systems, Man, and
Cybernetics, 13(3):257–266, 1983.
[41] J. Reason. Human Error. Cambridge University Press, 1990.
[42] A. Reber. Penguin Dictionary of Psychology, 2nd Edition.
Penguin Books, 1995.
[43] B. Ross, C. Jackson, N. Miyake, D. Boneh, and J. C.
Mitchell. Stronger Password Authentication Using Browser
Extensions.
In Proceedings of the 14th USENIX Security
Symposium, pages 17–32, August 2005.
[44] S. Schechter, R. Dhamija, A. Ozment, and I. Fischer. Em-
peror’s New Security Indicators: An Evaluation of Website
Authentication and the Effect of Role Playing on Usability
Studies.
In Proceedings of the 2007 IEEE Symposium on
Security and Privacy, pages 51–65, May 2007.
[45] S. Sheng, B. Magnien, P. Kumaraguru, A. Acquisti, L. F.
Cranor, J. Hong, and E. Nunge. Anti-Phishing Phil: The De-
sign and Evaluation of a Game That Teaches People Not to
Fall for Phish. In Proceedings of the Symposium on Usable
Privacy and Security (SOUPS), pages 88–99, July 2007.
[46] C. Soghoian and M. Jakobsson. A Deceit-Augmented Man
in the Middle Attack Against Bank of America’s SiteKey
Service. http://paranoia.dubfire.net/2007/
04/deceit-augmented-man-in-middle-atta%
ck.html, April 2007.
[47] R. Thomas and J. M. (a.k.a. Team Cymru). The Under-
;login: The USENIX Maga-
ground Economy: Priceless.
zine, 31(6):7–16, December 2006.
[48] T. W. van der Horst and K. E. Seamons.
Simple Au-
thentication for the Web. In 3rd International Conference
on Security and Privacy in Communication Networks (Se-
cureComm), September 2007.
[49] Vanguard Security Center. https://www.vanguard.
com/.
[50] W. A. Wagenaar and J. Groeneweg. Accidents at Sea: Mul-
International
tiple Causes and Impossible Consequences.
Journal of Man-Machine Studies, 27(5/6), Nov/Dec 1987.
[51] Washington Post. Citibank Phish Spoofs 2-Factor Au-
http://blog.washingtonpost.
thentication.
com/securityfix/2006/07/citibank_phish_
spoof%s_2factor_1.html.
[52] Washington Post.
Not Your Average Phishing
http://blog.washingtonpost.com/
Scam.
securityfix/2007/01/not_your_average_
ama%zon_phishi.html.
[53] R. West. The Psychology of Security: Why Do Good
Users Make Bad Decisions? Communications of the ACM,
51(4):34–40, April 2008.
[54] T. Whalen and K. M. Inkpen. Gathering Evidence: Use of
Visual Security Cues in Web Browsers. In Proceedings of
Graphics Interface 2005, pages 137–144, May 2005.
[55] A. N. Whitehead. Introduction To Mathematics. Williams
and Northgate, 1911.
[56] A. Whitten and J.D. Tygar. Safe Staging for Computer Se-
In Workshop on Human-Computer Interaction and
curity.
Security Systems, April 2003.
[57] M. S. Wogalter, editor. Handbook of Warnings. Lawrence
Erlbaum Associates, 2006.
[58] M. Wu, R. C. Miller, and S. Garﬁnkel. Do Security Toolbars
Actually Prevent Phishing Attacks? In Proceedings of the
SIGCHI Conference on Human Factors in Computing Sys-
tems, pages 601–610, 2006.
[59] M. Wu, R. C. Miller, and G. Little. Web Wallet: Prevent-
ing Phishing Attacks by Revealing User Intentions. In Pro-
ceedings of the Symposium on Usable Privacy and Security
(SOUPS), pages 102–113, July 2006.
[60] K.-P. Yee. Guidelines and Strategies for Secure Interaction
Design. In L. F. Cranor and S. Garﬁnkel, editors, Security
and Usability: Designing Secure Systems That People Can
Use, chapter 13, pages 247–273. O’Reilly, 2005.
[61] J. Youll.
Fraud Vulnerabilities in SiteKey Security at
cr-labs.com/publications/
Bank of America.
SiteKey-20060718.pdf, July 2006.