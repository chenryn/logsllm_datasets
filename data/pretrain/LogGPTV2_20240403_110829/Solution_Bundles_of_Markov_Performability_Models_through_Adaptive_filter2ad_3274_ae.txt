1.36 · 104
1.84 · 102
8.87 · 10−6
74
determines a quick decrease of pivots’ magnitude, as depicted
in Figure 6.
pressed in hour−1) is:
For Case study 2, parameters’ assignment (rates are ex-
−5
nc = 3, λ = 10
, ne,1 = 5, ne,2 = 3,
θ1 := L ∈ [1, 3], θ2 := μ ∈ [0.5, 2.5].
Speedup and accuracy are reported in Table II for Reliabil-
ity at increasing of points number (speciﬁcally, n0 is kept
equals to 10, and both n1 and n2 span {10, 20, 100}), and
for Low charge with 106 points. As expected, the speedup
increases at the increase of points number. Indeed, k remains
low (about 30) but parameters’ ﬁbers require an increasing
number of approximation points. Notice that both the strict
deﬁnition of accuracy employed here and the adaptive choice
of pivots are responsible for obtaining a smaller accuracy with
32 and 34 approximation points than with 32.
|
t
o
v
i
p
|
100
−1
10
−2
−3
−4
−5
−6
10
10
10
10
10
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
h
Fig. 6. Case study 1c: Absolute value of the pivot when computing Reliability
as a function of the steps h = 1, . . . , k. In this run ACA stops at k = 15.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:18:14 UTC from IEEE Xplore.  Restrictions apply. 
389
Fig. 7. Case study 1a: Under repair for tmax = 2 years.
Fig. 8. Case study 2: Reliability for tmax = 2 years.
B. Comparison with GLM
(cid:5)
To enrich the comparison study, the GLM metamodel has
been selected as another alternative to the proposed ACA
approximation. Generalized Linear Model (GLM), here deﬁned
consistently with the rest of the paper as
ˆm = E[m|t, θ] = g
β−1+β0·t+β1·h1(θ1)+···+βp·hp(θp)
is the ancestor of many interpretable metamodels [10]. Hence,
choosing GLM not only allows to perform a quantitative
comparison, but also to discuss qualitative differences between
ACA and descendants of GLM. In particular:
−1
• in GLM a case-by-case choice of dependent variable
distribution (within the exponential family) and link
function g is needed because Equations (3) and (4) can
have different ranges and shapes, whereas ACA is general;
• the independent variable functions hi are also chosen case-
by-case, taking into account the discussion of Section II-C
and how it is expected that a given parameter inﬂuences
the ﬁnal measure;
• the parameters vector β in GLM has always p + 2 entries,
whereas in ACA the number of approximants k is chosen
dynamically. Thus, GLM is not expected to gain much in
accuracy at increasing of points number over a threshold
of the order of p.
Numerical evaluations have been carried out on Reliability
in Case study 1 for n0n1n2 = 8 · 103, choosing the Gamma
family with default link function and exploiting MATLAB
fitglm. Several arranges of points and functions of the
independent variables have been considered. The best relative
accuracy reached training the GLM metamodel is 1.40 · 10
−2,
obtained with 100 randomly distributed points (with 10 points
the accuracy is 2.21 · 10
−2). With the approach of Section IV,
k = 9 is sufﬁcient to obtain a relative accuracy of 3.19 · 10
−7.
The higher accuracy of the ACA approximation is payed by a
higher computation time: GLM is about 37 times faster than
ACA. However, it has to be considered that both require less
(cid:6)
than one second to perform the approximation (while the full
tensor evaluation requires about 9 seconds).
In fitglm it is also possible to introduce mixed terms in
the approximation, but loosing a little bit of interpretability.
Through trial and error, the best accuracy obtained has been
2.59 · 10
−4 with the option poly233, and almost the same
training time.
,
C. Results from sensitivity analysis
To exemplify the utility of the computed measure bundle,
global sensitivity analysis has been selected among the kind of
analyses that greatly beneﬁt from the presented contribution,
as discussed in Section II-B.
Speciﬁcally, the measure Under repair of Case study 1a and
the measure Reliability of Case study 2 have been considered.
Heatmaps of the approximated measures ˆm, for tmax equals to
2 years and at varying parameter values, are shown in Figures 7
and 8 to point out different parameters’ interplay. Figure 7
conﬁrms that c is more relevant than λ for Under repair, and
the increase/decrease pattern follows the axes directions. In
Figure 8, instead, bend curves of equal Reliability appear,
meaning that more complex design choices are possible.
VII. RELATED WORK
Narrowing the discussion to aspects directly related to the
contribution, i.e., ﬁnd ways to avoid the full measures tensor
evaluation, a ﬁrst observation is that the literature focuses
mainly on the time ﬁber. Integration- and simulation- based
approaches differ from the expansion- and approximation-
based ones for a relevant aspect. In fact, the former impose
a causal order among time points, so the computation of
the model solution cannot be parallelized in time. Instead,
uniformization and semi-symbolic [11], [30], [31] just work
with a single time point (trivial case of no time causal order),
and approximation as the one presented here can be done with
a high level of parallelism, even exploiting dedicated hardware.
Indeed, importing in the approach of Section IV a different
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:18:14 UTC from IEEE Xplore.  Restrictions apply. 
390
method to evaluate the tensor along time ﬁber, e.g. [7], does
not impact on the presented speedup.
The main issue, as brieﬂy illustrated in Section I, with
the previously mentioned strategies is that, even if they are
efﬁcient/effective in solving one system of ODEs, dealing with
large values of nsample can quickly become unfeasible. Among
the strategies to mitigate this issue that have been already
published, in the following only those that explicitly address
the parameters ﬁber are discussed.
In [16], [17] a metamodel (also known as surrogate model
or emulator in the literature) is presented. The performability
model is solved on a predeﬁned set of time and parameters
points, the dataset {(t(h), θ(h)), mθ(h)(t(h))}h is divided in
training/test/validation and ˆm(t, θ) is learned. The results
show that the required training set size is much smaller than
the number of points of the full tensor M, as also in this
paper. However, how to choose the samples (for instance
through random sampling, Latin hypercube sampling, and Sobol
sequence sampling) can be challenging. The training set is ﬁxed
at the beginning, whereas the approach presented in this paper
is adaptive. Comparing the impact of this difference on accuracy
is beyond the scope of this paper. No assumption is made on
measure smoothness, and actually the performability model
can be solved through simulation, thus the approach addresses
models more general than Markov. Instead of adopting a single
approximation/machine learning method, the authors present
a stack of methods to enhance accuracy with respect to each
method exercised in isolation: a group of methods work on
input data, their results are compared and fed to a second group
of methods, and so on. It follows that, even though some of
the methods can be interpretable, the stack ˆm is trained as a
black box, so interpretability is lost. Further work is required to
investigate how well-known or new explainability techniques
[10] can increase trust in this approach.
investigations.
Weakening the usual deﬁnitions of surrogate model and
solution bundle, the approach presented in [32], dealing with
Continuous Time Continuous Space Kolmogorov PDE, could
be relevant too.
VIII. CONCLUSIONS AND FUTURE WORK
In this paper a new low rank approximation ˆM of per-
formability measures, based on the ACA technique, has been
presented for Markov models. The main challenge, i.e., how
to address parameters’ ﬁbers to gain in efﬁciency with respect
to the full evaluation of the tensor M, has been addressed
tailoring well-known results to the measures of interest in
Sections IV-D and IV-E. The resulting approximation approach
is accurate (as shown in Section VI) and trustworthy because of
the decomposability property promoted by exploiting separable
approximants.
Future work is foreseen in several directions. As already
discussed, the presented approach belongs to the category of
interpretable solutions. Comparison with existing alternatives
in the explainable (black box) category (such as [16], [17])
would be an interesting investigation to carry on. This research
requires careful identiﬁcation of the baseline and perspectives
for the common comparison.
It is known that ACA performs really well only if the
measure under analysis is sufﬁciently smooth in time and
parameters. Thus, tweaking the presented approach to address
models that are more general than Markov, maintaining a good
performance, is doable as long as the resulting measures are
smooth. For instance, the presented approach is ready to address
instantaneous measures on non-homogeneous CTMC [1], but,
to obtain good speedups with respect to the full evaluation of
M, the developments of Section IV-E has to be improved.
Semi-Markov models, under not-so-restrictive conditions on
the involved Cumulative Distribution Functions, are clearly the
next kind of models to address. In addition, case study 2 is
actually formulated as a semi-Markov model, and then it would
be interesting to compare the reported performance, obtained
applying the presented approach on a Markovian approximation
of this case study, with that obtainable directly addressing the
semi-Markov model. Of course, the challenge here is how to
adapt solutions presented in Sections IV-D and IV-E to the
semi-Markov case.
Generalizations in other directions are foreseen as well. For
instance, considering a time- and parameters- dependent reward
r(t, θ) poses no issues to the approximation of instantaneous
measures, as long as it is a smooth function, but again ask for
additional work when addressing accumulated measures.
In the literature, it is also known that ACA starts to face
troubles when the number of parameters p becomes large.
Thus, to the best of the authors’ knowledge, the best choice to
address several parameters is to adopt one of the approaches
presented in [16], [17]. Nonetheless, generalizations of ACA
to address high dimensional tensors exist in the literature, and
then the next step is to apply and test those generalizations to
the presented approach.
Equations (1) and (2) are systems of PDEs (even though
they can be actually seen as fake systems of ODEs because
involve only partial derivative on time), thus natural com-
petitors of the proposed approach can be searched among
approximation/machine learning approaches addressing PDEs.
A strategy for computing the solution bundle has been recently
presented in [8], where the case studies have a small number
of dependent variables, but closed form solutions, if available,
are too complex to be exploitable in practice. A nonlinear, non
separable, approximation is chosen (approximants are Deep
Neural Networks), so this is a black box approach too. When
dealing with moderate and large values of N, the strategy of [8]
is no more applicable in the context of Markov models, because
automatic differentiation is too expensive (actually this issue
can be mitigated by exploiting ﬁnite difference) and relevant
properties of the solution bundle, such as for Equation (1)
being a state probability vector, are not addressed. Preliminary
investigations show that accuracy can be also problematic, since
performability models typically require high accuracy (e.g.,
when targeting critical systems), well beyond values reported
in [8] related to other contexts. Whether or not it is appropriate
to address performability models in this way requires further
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:18:14 UTC from IEEE Xplore.  Restrictions apply. 
391
[25] N. Halko, P. G. Martinsson, and J. A. Tropp, “Finding structure
with randomness: Probabilistic algorithms for constructing approximate
matrix decompositions,” SIAM Rev., vol. 53, no. 2, pp. 217–288, 2011.
[Online]. Available: https://doi.org/10.1137/090771806
[26] M. Bebendorf, “Approximation of boundary element matrices,” Numer.
[Online]. Available:
Math., vol. 86, no. 4, pp. 565–589, 2000.
https://doi.org/10.1007/PL00005410
[27] L. Grasedyck, D. Kressner, and C. Tobler, “A literature survey of low-rank
tensor approximation techniques,” GAMM-Mitt., vol. 36, no. 1, pp. 53–78,
2013. [Online]. Available: https://doi.org/10.1002/gamm.201310004
[28] J. B. Dugan and K. S. Trivedi, “Coverage modeling for dependability
analysis of fault-tolerant systems,” IEEE Trans. on Comp., vol. 38, no. 6,
pp. 775–787, 1989.
[29] MathWorks, MATLAB R2018a, The Mathworks, Inc., 2018.
[30] A. L. Reibman, R. Smith, and K. S. Trivedi, “Markov and Markov
reward model transient analysis: An overview of numerical approaches,”
European Journal of Operational Research, vol. 40, no. 2, pp. 257–267,
1989.
[31] A. Reibman and K. S. Trivedi, “Transient analysis of cumulative measures
of Markov model behavior,” Communications in Statistics. Stochastic
Models, vol. 5, no. 4, pp. 683–710, 1989.
[32] J. Berner, M. Dablander, and P. Grohs, “Numerically solving parametric
families of high-dimensional Kolmogorov partial differential equations
via deep learning,” ArXiv, vol. abs/2011.04602, 2020.
REFERENCES
[1] K. S. Trivedi and A. Bobbio, Reliability and Availability Engineering:
Modeling, Analysis, and Applications, 2017.
[2] B. R. Haverkort and K. S. Trivedi, “Speciﬁcation techniques for Markov
reward models,” Discrete Event Dyn. Syst., no. 3, pp. 219–247, 1993.
[3] W. H. Sanders and J. F. Meyer, “A uniﬁed approach for specifying
measures of performance, dependability and performability,” Dependable
Computing for Critical Applications, Vol. 4 of Dependable Computing
and Fault-Tolerant Systems, pp. 215–237, 1991.
[4] A. L. Reibman and K. S. Trivedi, “Transient analysis of cumulative
measures of Markov model behavior,” Communications in Statistics.
Stochastic Models, vol. 5, no. 4, pp. 683–710, 1989.
[5] A. L. Reibman, R. Smith, and K. S. Trivedi, “Markov and Markov
reward model transient analysis: An overview of numerical approaches,”
European Journal of Operational Research, vol. 40, pp. 257–267, 1989.
[6] M. Malhotra, J. K. Muppala, and K. S. Trivedi, “Stiffness-tolerant
methods for transient analysis of stiff Markov chains,” Microelectronics
Reliability, vol. 34, no. 11, pp. 1825–1841, 1994.
[7] A. V. Ramesh and K. Trivedi, “Semi-numerical transient analysis of
Markov models,” in Proceedings of the 33rd Annual on Southeast
Regional Conference, ser. ACM-SE 33, 1995, pp. 13–23.
[8] C. W. Flamant, P. Protopapas, and D. Sondak, “Solving differential equa-
tions using neural network solution bundles,” ArXiv, vol. abs/2006.14372,
2020.
[9] M. Bebendorf, “Adaptive cross approximation of multivariate functions,”
Const. Approx., vol. 34, no. 2, pp. 149–179, 2011.
[10] R. Marcinkeviˇcs and J. E. Vogt, “Interpretability and explainability: A
machine learning zoo mini-tour,” ArXiv, vol. 2012.01805, 2020.
[11] M. Malhotra, J. K. Muppala, and K. S. Trivedi, “Stiffness-tolerant
methods for transient analysis of stiff Markov chains,” Microelectronics
Reliability, vol. 34, no. 11, pp. 1825–1841, 1994.
[12] A. C. Hindmarsh, P. N. Brown, K. E. Grant, S. L. Lee, R. Serban,
D. E. Shumaker, and C. S. Woodward, “SUNDIALS: Suite of nonlinear
and differential/algebraic equation solvers,” ACM Transactions on
Mathematical Software (TOMS), vol. 31, no. 3, pp. 363–396, 2005.
[13] R. L. Iman and J. C. Helton, “An investigation of uncertainty and
sensitivity analysis techniques for computer models,” Risk Analysis,
vol. 8, no. 1, pp. 71–90, 1988.
´E. Walter and L. Pronzato, Identiﬁcation of parametric models: from
experimental data, ser. Communications and Control Engineering.
Heidelberg: Springer-Verlag, 1997.
[14]
[15] H. Pham, Reliability Modeling, Analysis and Optimization, ser. on Quality,
Reliability and Engineering Statistics, M. Xie, T. Bendell, and A. P. Basu,
Eds. Singapore: World Scientiﬁc, 2006, vol. 9.
[16] M. Rausch and W. H. Sanders, “Sensitivity analysis and uncertainty
quantiﬁcation of state-based discrete-event simulation models through a
stacked ensemble of metamodels,” in Quantitative Evaluation of Systems,
2020, pp. 276–293.
[17] ——, “Evaluating the effectiveness of metamodeling in emulating
quantitative models,” in Quantitative Evaluation of Systems, 2021, pp.
127–145.
[18] A. Townsend and L. N. Trefethen, “An extension of Chebfun to two
dimensions,” SIAM J. Sci. Comput., vol. 35, no. 6, pp. C495–C518,
2013. [Online]. Available: https://doi.org/10.1137/130908002
[19] R. A. Maire, A. L. Reibman, and K. S. Trivedi, “Transient analysis
of acyclic Markov chains,” Performance Evaluation, vol. 7, no. 3, pp.
175–194, 1987.
[20] L. N. Trefethen, Approximation theory and approximation practice.
Society for Industrial and Applied Mathematics (SIAM), Philadelphia,
PA, 2013.
[21] A. J. Carpenter, A. Ruttan, and R. S. Varga, “Extended numerical
computations on the 1/9 conjecture in rational approximation theory,” in
Rational approximation and interpolation. Springer, 1984, pp. 383–411.
[22] B. Hashemi and L. N. Trefethen, “Chebfun in three dimensions,”
SIAM J. Sci. Comput., vol. 39, no. 5, pp. C341–C363, 2017. [Online].
Available: https://doi.org/10.1137/16M1083803
[23] J. W. Demmel, Applied numerical linear algebra. Society for Industrial
and Applied Mathematics (SIAM), Philadelphia, PA, 1997. [Online].
Available: https://doi.org/10.1137/1.9781611971446
[24] T. F. Chan, “Rank revealing QR factorizations,” Linear Algebra
[Online]. Available: https:
Appl., vol. 88/89, pp. 67–82, 1987.
//doi.org/10.1016/0024-3795(87)90103-0
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:18:14 UTC from IEEE Xplore.  Restrictions apply. 
392