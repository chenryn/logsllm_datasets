solid triangle point is male, blue point is the property “race: black” and red point is data without the property.
(a) FaceScrub
(b) Yelp-author
Fig. 4: AUC vs. the fraction of the batch that has the property on FaceScrub and Yelp-author.
Top Words in Positive Class
pregnancy, delivery, women, birth, ultrasound
pediatrics, sick, parents, kid, newborn
Health Service
Obstetricians
Pediatricians
Cosmetic Surgeons augmentation, plastic, breast, facial, implants
Cardiologists
Dermatologists
Ophthalmologists
Orthopedists
Radiologists
Psychiatrists
Urologists
cardiologist, monitor, bed, heart, ER
acne, dermatologists, mole, cancer, spots
vision, LASIK, contacts, lenses, frames
knee, orthopedic, shoulder, injury, therapy
imaging, SimonMed, mammogram, CT, MRI
psychiatrist, mental, Zedek, depression, sessions
Edgepark, pump, supplies, urologist, kidney
TABLE IV: Words with the largest positive coefﬁcients in the
property classiﬁer for Yelp-health.
training data that are uncorrelated with class membership.
To understand why, we plot the t-SNE projection [59] of the
features from different layers of the joint model in Figure 3.
Observe that the feature vectors are grouped by property in
the lower layers pool1, pool2 and pool3, and by class label
in the higher layer. Intuitively, the model did not just learn
to separate inputs by class. The lower layers of the model
also learned to separate inputs by various properties that are
uncorrelated with the model’s designated task. Our inference
attack exploits this unintended extra functionality.
Yelp-health. On this dataset, we use review-score classiﬁca-
tion as the main task and the specialty of the doctor being
reviewed as the property inference task. Obviously, the latter
is more sensitive from the privacy perspective.
We use 3,000 most frequent words in the corpus as the
vocabulary and train for 3,000 iterations. Using BoWs from
the embedding-layer gradients,
the attack achieves almost
perfect AUC. Table IV shows the words that have the highest
predictive power in our logistic regression.
Fractional properties. We now attempt to infer that some of
the inputs in a batch have the property. For these experiments,
we use FaceScrub’s top 5 face IDs and Yelp-author (the latter
with the 3,000 most frequent words as the vocabulary). The
model is trained for 3,000 iterations. As before, 1/2 of the
target’s batches include inputs with the property, but here we
vary the fraction of inputs with the property within each such
batch among 0.1, 0.3, 0.5, 0.7, and 0.9.
Figure 4 reports the results. On FaceScrub for IDs 0, 1, and
3, AUC scores are above 0.8 even if only 50% of the batch
contain that face, i.e., the adversary can successfully infer that
photos of a particular person appear in a batch even though
(a) the model is trained for generic gender classiﬁcation, and
(b) half of the photos in the batch are of other people. If the
fraction is higher, AUC approaches 1.
On Yelp-author, AUC scores are above 0.95 for all identities
even when the fraction is 0.3, i.e., the attack successfully infers
the authors of reviews even though (a) the model is trained
for generic sentiment analysis, and (b) more than two thirds
of the reviews in the batch are from other authors.
C. Inferring when a property occurs
Continuous training, when new training data is added
to the process as it becomes available, presents interesting
opportunities for inference attacks. If the occurrences of a
property in the training data can be linked to events outside the
training process, privacy violation is exacerbated. For example,
(cid:23)(cid:26)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:37 UTC from IEEE Xplore.  Restrictions apply. 
(a) PIPA
(b) FaceScrub
Fig. 5: Inferring occurrence of a single-batch property.
suppose a model
leaks that a certain third person started
appearing in another participant’s training data immediately
after that participant uploaded his photos from a trip.
PIPA.
Images in the PIPA dataset have between 1 to 3
faces. We train the collaborative model to detect if there is
a young adult in the image; the adversary’s inference task is
to determine if people in the image are of the same gender.
The latter property is a stepping stone to inferring social
relationships and thus sensitive. We train the model for 2,500
iterations and let the batches with the “same gender” property
appear in iterations 500 to 1500.
Figure 5a shows, for each iteration, the probability output by
the adversary’s classiﬁer that the batch in that iteration has the
property. The appearance and disappearance of the property in
the training data are clearly visible in the plot.
FaceScrub. For the gender classiﬁcation model on FaceScrub,
the adversary’s objective is to infer whether and when a certain
person appears in the other participant’s photos. The joint
model is trained for 2,500 iterations. We arrange the target’s
training data so that
two speciﬁc identities appear during
certain iterations: ID 0 in iterations 0 to 500 and 1500 to 2000,
ID 1 in iterations 500 to 1000 and 2000 to 2500. The rest of the
batches are mixtures of other identities. The adversary trains
three property classiﬁers, for ID 0, ID 1, and also for ID 2
which does not appear in the target’s dataset.
Figure 5b reports the scores of all three classiﬁers. ID 0
and 1 receive the highest scores in the iterations where they
appear, whereas ID 2, which never appears in the training data,
receives very low scores in all iterations.
These experiments show that our attacks can successfully
infer dynamic properties of the training dataset as collaborative
learning progresses.
D. Inference against well-generalized models
To show that our attacks work with (1) relatively few ob-
served model updates and (2) against well-generalized models,
we experiment with the CSI corpus. Figure 6 reports the
accuracy of inferring the author’s gender. The attack reaches
0.98 AUC after only 2 epochs and improves as the training
progresses and the adversary collects more updates.
Figure 6 also shows that the model is not overﬁtted. Its
test accuracy on the main sentiment-analysis task is high and
improves with the number of the epochs.
Fig. 6: Attack performance with respect to the number of collabora-
tive learning epochs.
E. Active property inference
To show the additional power of the active attack from Sec-
tion IV-E, we use FaceScrub. The main task is gender classi-
ﬁcation, the adversary’s task is to infer the presence of ID 4
in the training data. We assume that this ID occurs in a single
batch, where it constitutes 50% of the photos. We evaluate the
attack with different choices of α, which controls the balance
between the main-task loss and the property-classiﬁcation loss
in the adversary’s objective function.
Figure 7a shows that AUC increases as we increase α.
Figure 7b and Figure 7c show the t-SNE projection of the ﬁnal
fully connected layer, with α = 0 and α = 0.7, respectively.
Observe that the data with the property (blue points) is grouped
tighter when α = 0.7 than in the model trained under a passive
attack (α = 0). This illustrates that as a result of the active
attack, the joint model learns a better separation for data with
and without the property.
VII. MULTI-PARTY EXPERIMENTS
In the multi-party setting, we only consider passive prop-
erty inference attacks. We vary the number of participants
between 4 and 30 to match the deployment scenarios and
applications proposed for collaborative learning, e.g., hospitals
or biomedical research institutions training on private medical
data [29, 30]. This is similar to prior work [25], which was
evaluated on MNIST with 2 participants and face recognition
on the AT&T dataset with 41 participants.
(cid:23)(cid:26)(cid:26)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:37 UTC from IEEE Xplore.  Restrictions apply. 
(a) ROC for different α
(b) t-SNE of the ﬁnal layer for α = 0
(c) t-SNE of the ﬁnal layer for α = 0.7.
Fig. 7: Active property inference attack on FaceScrub. For (b) and (c), hollow circle point is female, solid triangle point is male, blue point
is the property “ID 4” and red point is data without the property.
(a) LFW
(b) Yelp-author
Fig. 8: Multi-party learning with synchronized SGD: attack AUC score vs. the number of participants.
A. Synchronized SGD
As the number of honest participants in collaborative learn-
ing increases, the adversary’s task becomes harder because
the observed gradient updates are aggregated across multiple
participants. Furthermore, the inferred information may not
directly reveal the identity of the participant to whom the data
belongs (see Section IX-D).
In the following experiments, we split the training data
evenly across all participants, but so that only the target
and the adversary have the data with the property. The joint
model is trained with the same hyperparameters as in the two-
party case. Similar to Section VI-B, the adversary’s goal is
to identify which aggregated gradient updates are based on
batches bprop with the property.
LFW. We experiment with (1) gender classiﬁcation as the
main task and “race: black” as the inference task, and (2)
smile classiﬁcation as the main task and “eyewear: sunglasses”
as the inference task. Figure 8a shows that the attack still
achieves reasonably high performance, with AUC score around
0.8, when the number of participants is 12. Performance then
degrades for both tasks.
Yelp-author. The inference task is again author identiﬁcation.
In the multi-party case, the gradients of the embedding layer
leak the batch BoWs of all honest participants, not
just
the target. Figure 8b reports the results. For some authors,
AUC scores do not degrade signiﬁcantly even with many
participants. This is likely due to some unique combinations
of words used by these authors, which identify them even in
multi-party settings.
B. Model averaging
(see Algorithm 2),
(cid:2)
nk
n θk
In every round t of federated learning with model averaging
the adversary observes θt − θt−1 =
t −θk
t−1 =
t−1
are the aggregated gradients computed on the k-th participant’s
local dataset.
t−1), where θk
t −(cid:2)
nk
n θk
(cid:2)
t −θk
nk
n (θk
k
k
k
In our experiments, we split the training data evenly among
honest participants but ensure that in the target participant’s
subset, ˆp% of the inputs have the property, while none of the
other honest participants’ data have it. During each epoch of
local training, every honest participant splits his local training
data into 10 batches and performs one round of training.
We assume that the adversary has the same number of inputs
with the property as the target. As before, when the adversary
trains his binary classiﬁer, he needs to locally “emulate” the
collaborative training process, i.e., sample data from his local
dataset, compute aggregated updates, and learn to distinguish
between the aggregates based on the data without the property
and aggregates where one of the underlying updates was based
on the data with the property.
We perform 8 trials where a subset of the training data has
the property and 8 control trials where there are no training
inputs with the property.
Inferring presence of a face. We use FaceScrub and select
two face IDs (1 and 3) whose presence we want to infer.
(cid:24)(cid:17)(cid:17)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:37 UTC from IEEE Xplore.  Restrictions apply. 
(a) Face ID 1, K = 3
(b) Face ID 1, K = 5
(c) Face ID 3, K = 3
(d) Face ID 3, K = 5
Fig. 9: Multi-party learning with model averaging. Box plots show the distribution of the adversary’s scores in each trial: in the 8 trials on
the left, one participant’s data has the property; in the 8 trials on the right, none of the honest participants have the data with the property.
Fig. 10: Inferring that a participant whose local data has the property
of interest has joined the training. K = 2 for rounds 0 to 250, K = 3
for rounds 250 to 500.
Property / % parameters update
Top region (Antwerpen)
Gender
Veracity
10% 50% 100%
0.93
0.84
0.93
0.90
0.94
0.99
0.86
0.91
0.99
TABLE V: Inference attacks against the CSI Corpus for different
fractions of gradients shared during training.
In the “property” case, ˆp = 80%, i.e., 80% of one honest
participant’s training data consist of the photos that depict
the person in question. In the control case, ˆp = 0%, i.e., the
photos of this person do not occur in the training data. Figure 9
shows the scores assigned by the adversary’s classiﬁer to the
aggregated updates with 3 and 5 total participants. When the
face in question is present in the training dataset, the scores
are much higher than when it is absent.
Success of the attack depends on the property being in-
ferred, distribution of the data across participants, and other
factors. For example, the classiﬁers for Face IDs 2 and 4,
which were trained in the same fashion as the classiﬁers
for Face IDs 1 and 3, failed to infer the presence of the
corresponding faces in the training data.
Inferring when a face occurs. In this experiment, we aim to
infer when a participant whose local data has a certain property
joined collaborative training. We ﬁrst let the adversary and
the rest of the honest participants train the joint model for
250 rounds. The target participant then joins the training at
round t = 250 with the local data that consists of photos
depicting ID 1. Figure 10 reports the results of the experiment:
the adversary’s AUC scores are around 0 when face ID 1 is not
present and then increase almost to 1.0 right after the target
participant joins the training.
Fig. 11: Uniqueness of user proﬁles with respect to the number of
top locations.
VIII. DEFENSES
A. Sharing fewer gradients
As suggested in [52], participants in collaborative learning
could share only a fraction of their gradients during each
update. This reduces communication overhead and, potentially,
leakage, since the adversary observes fewer gradients.
To evaluate this defense, we measure the performance of
single-batch inference against a sentiment classiﬁer collabora-
tively trained on the CSI Corpus by two parties who exchange
only a fraction of their gradients. Table V shows the resulting
AUC scores: when inferring the region of the texts’ authors,
our attack still achieves 0.84 AUC when only 10% of the
updates are shared during each iteration, compared to 0.93