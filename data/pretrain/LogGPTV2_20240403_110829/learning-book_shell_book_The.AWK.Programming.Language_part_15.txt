Right!
+ + +
Notice that alternative answers (for example, sodium or natrium) are easily
handled with regular expressions in the data file.
quiz-present a quiz
usage: awk -f quiz topicfile question-subj answer-subj
BEGIN{
PS = *:"
if (ARGC 1= 4)
if（getline  NP ii a > NP 1: q = a)
break
while （getline 0)#1oad the quiz
error("valid subjects
are "s0)
ARGC2;ARGV[1]。*_"
qa[++nq]=s0
now read standard input
srand()
}op
（x‘[（L+bu(）puex）au]eb)ads
while（（input=getline)>0)
printf(“%s?",x[q])
if（s0²-"（”x[a）
print “Right1*
“)s")(
}else if （s0 ==*"）{
break
print x[a]
}else
break
printf(“wrong, try again:")
}while （input>0)
function error（s)(printf(°error:Xs\n”,s);exit }
---
## Page 129
SECTION 5.3
TEXT PROCESSING
119
We have to surround the regular expression for the right answer with ^ and $;
without this, any matching substring of the right answer would also be accepted
(so N would match Ne and Na as well as N).
Exercise 5-9. Modify quiz so that it does not present any question more than once. 
5.3 Text Processing
Because of its string manipulation capabilities, awk is useful for tasks that
arise in text processing and document preparation. As examples, this section
contains programs for counting words, formatting text, maintaining cross-
references, making KWIC indexes, and preparing indexes.
Word Counts
In Chapter 1, we presented a program to count the number of lines, words,
and characters in a file, where a word was defined as any contiguous sequence
of nonblank, nontab characters.A related problem is to count the number of
times each different word appears in a document. One way to solve this prob-
lem is to isolate the words, sort them to bring identical words together, and then
count occurrences of each word with a control-break program.
Another way, well suited to awk, is to isolate the words and aggregate the
count for each word in an associative array. To do this properly, we have to
decide what a word really is. In the following program, a word is a field with
“(word)” are all counted in the entry for word. The END action prints the
word frequencies, sorted in decreasing order.
wordfreq -print nunber of occurrences of each word
input:
text
（gsub（/[.,:;1?（）(）]/,**)
for (1 = 1;i 0）（
print substr(1ine,2)
removes leading blank
line = *"
Exercise 5-13. Modify fmt to align the right margin of the text it prints. 
Exercise 5-14. Enhance fnt to infer the proper format of a document by recognizing
probable titles, headings, lists, etc. Rather than formatting, it could generate formatting
commands for a formatter like troff or TEX. 
Maintaining Cross-References in Manuscripts
names or numbers for items like bibliographic citations, figures, tables, exam-
ples, and so on. Some text formatters help out with this task, but most expect
you to do it yourself. Our next example is a technique for numbering cross-
references. It's quite useful for documents like technical papers or books.
As the document is being written, the author creates and uses symbolic
names for the various items that will be cross-referenced. Because the namcs
are symbolic, items can be added, deleted, and rearranged without having to
bolic names are replaced by suitable numbers. Here is a sample document
---
## Page 131
SECT1ON 5.3
TEXT PROCESSING
121
containing symbolic names for two bibliographic citations and one figure:
.Fig_quotes_
Figure _quotes_ gives two brief quotations from fanous books.
Figure _quotes_:
.Bib _alice_
`without pictures or conversations?'" [_alice_]
.#Bib _huck
"..."if I?d a knowed what a trouble it was to make a book
I wouldn't a tackled it and ain't agoing to no more." [_huck_]
[_alice_] Carroll, L., Alice's Adventures in Wonderland,
[_huck_] Twain, K.,Adventures of Huckleberry Finn,
Macmi11an, 1865.
Webster & Co.,1885.
Each symbolic name is defined by a line of the form
.#Category_SymbolicName_
Such a definition can appcar anywhere in the document, and there can be as
many different categories as the author wants. Throughout the document an
item is referred to by its symbolic name. We have chosen symbolic names that
begin and end with an underscore, but any names can be used as long as they
different categories.) The names .#Fig and .#Bib begin with a period so
they will be ignored by the troff formatter in case the document is printed
without resolving the cross-references; with a different formatter, a different
convention may be required.
The conversion creates a new version of the document in which the defini-
tions are removed and each symbolic name is replaced by a number. In each
category the numbers start at one and go up sequentially in the order in which
the definitions for that category appear in the original document.
The conversion is done by passing the document through two programs.
This division of labor is another instance of a powerful general technique: the
first program creates a second program to do the rest of the job. In this case,
the first program, called xref, scans the document and creates the second pro-
gram, called xref .temp, that does the actual conversion. If the original ver-
references is created by typing:
sion of the manuscript is in the file document, the version with the numeric
awk -f xref document >xref.temp
awk -f xref.temp document
The output of the second program can be directed to a printer or text formatter.
---
## Page 132
122
PROCESSING WORDS
CHAPTER5
The result for our sample above:
Figure 1 gives tvo brief quotations from fanous books.
Figure 1:
"...and what is the use of a book,’thought Alice，
'without pictures or conversations?'"[1]
"...if I'd a knowed what a trouble it was to make a book
I wouldn't a tackled it and ain't agoing to no more." [2]
[1] Carroll, L., Alice's Adventures in Wonderland,
[2]Twain,M., Adventures of Huckleberry Finn,
Macmi11an,1865.
Webster & Co.,1885.
The xref program searches the document for lines beginning with “, #"; for
cach such definition it increments a counter in the array count for items of
that category and prints a gsub statement.
xref - create numeric values for symbolic names
#
input: text with definitions for symbolic nanes
output: awk program to replace symbolic nanes by numbers
/\.#/(printf（"(gsub（/%s/，\"%d\")}\n”，$2,++count[$1]）}
END
(printf(*1/*[.]#^n°)}
The output of xref on the file above is the sccond program, xref . temp:
{gsub（/_quotes_/,"1）}
（gsub（/alice_7,
{gsub（/_huck_7,"2"）}
/[]/!
The gsub's globally substitute numbers for the symbolic names; the last state-
ment deletes the definitions by not printing lines that begin with .#.
Exercise 5-15. What might happen if the trailing underscore were omitted from a sym-
bolic name? 
Exercise 5-16. Modify xref to detect multiple definitions of a symbolic name. 
Exercise 5-17. Modify xref to create editing commands for your favorite text or
stream editor (e.g., sed) instead of creating awk commands. What effect does this have
on performance?
ndu a o ssed aus e uo x oi gaxx  no pnoo mo gs 
What restrictions on placement of definitions does this imply?
Making a KwiC Index
A Keyword-In-Context or KwIC index is an index that shows cach word in
the context of the line it is found in; it provides essentially the same information
---
## Page 133
SECTION 5.3
TEXT PROCESSING
123
as a concordance, although in a different format. Consider the three sentences
All's well that ends well.
Nature abhors a vacuum.
Every san has a price.
Here is a KwIC index for these sentences:
Every man has
a price.
Nature abhors
Nature
a vacuum.
abhors a vacuum.
All's well that ends well.
Al1's well that
Every nan has a price.
ends well.
Every nan
has a price.
Every
man has a price.
Nature abhors a vacuum.
Every man has a
that ends vell.
price.
Nature abhors a
All's wel1
vell that ends well.
vacuum.
Al1's wel1 that ends
A11'8
vell.
The problem of constructing a KwiC index has an interesting history in the
field of software engineering. It was proposed as a design exercise by Parnas in
1972; he presented a solution based on a single program. The Unix command
ptx, which does the same job in much the same way, is about 50o lines of C.
The convenience of Unix pipelines suggests a three-step solution: a first pro-
front, a sort puts them in order, and another program unrotates. This forms the
basis of the version in Sofrware Tools, which required about 70 lines of Ratfor
(a structured Fortran dialect), excluding the sort.
This method is even easier with awk; it can be done by a pair of short awk
programs with a sort between them:
awk *
#kwic -generate kwic index
for（1=length（s0);1>0;--)compute 1ength only once
print $0
if（subatr（s0,i,1）)
prefix space suffix =e>suffix tab prefix
print substr（$0,i+1) "\t"substr($0,1,i-1)
sort -f1
awk'
(printf("x"wID "s%s\n”,substr($2,length($2)-WID+1),
}
substr($1,1,WID))
u sndno ue sud ose i su sndus q jo Adoo e suud wloud sy o
---
## Page 134
124
PROCESSING WORDS
CHAPTER 5
for every blank within each input line; the output consists of the part of the
input line after the blank, followed by a tab, followed by the part before the
blank.
All output lines are then piped into the Unix command sort -f which sorts
them,“folding” upper and lower-case letters together, so that, for example,
Jack and jack will appear adjacent.
From the output of the sort command, the second awk program recon-
structs the input lines, appropriately formatted. It prints a portion of the part
after the tab, followed by a blank, followed by a portion of the part in front of
the tab.
Exercise 5-19. Add a “stop list" to kwic: a set of words like “a" and “the" that are
not to be taken as keywords. 
the ends rather than truncating. 
Exercise 5-20. Fix kwic to show as much as possible of lines, by wrapping around at
Exercise 5-21. Write a program to make a concordance instead of a KwiC index: for
cach significant word, show all the sentences or phrases where the word appears. 
Making Indexes
One task that accompanies writing a major document like a book or a
manual is preparing an index. There are two parts to this job. The first is
deciding on the terms to be indexed; this is demanding intellectual work if done
well, and not very susceptible to mechanization. The other part really is
mechanical: producing,from a list of index terms and page numbers, a properly
alphabetized and formatted index, like the one at the back of this book.
In the remainder of this section, we are going to use awk and the sort com-
mand to build the core of an indexer (whose slightly bigger sibling was used to
create the index of this book). The basic idea is similar to what was used in the
KWIC index program: divide and conquer. The job is broken down into a
sequence of easy pieces, each based on a one-line sort or a short awk program.
Since the pieces are tiny and separate, they can be adapted or augmented with
others quite easily, to satisfy more complicated indexing requirements.
These programs contain a number of details that are specific to the troff
formatter, which we used to typeset this book. These details would change if
the programs were to be used with another formatter, such as TEX or Scribe,
but the basic structure will be the same.
We indexed the book by inserting formatting commands into the text. When
the text is run through troff, these commands cause index terms and page
numbers to be collected in a file. This produces a sequence of lines like the fol-
lowing, which is the raw material for the index-preparation programs (a single
tab separates the number from the index term):
---
## Page 135
SECTION 5.3
TEXT PROCESSING
125
[FS] variable
35
[Fs] variable
36
arithmetic operators
36
coercion rules
44
string comparison
44
44
nuneric comparison
arithmetic operators
44
coercion-to number
45
coercion-to string
45
control-flow statements
48
47
[FS]  variable
52
• + .
The intent is that an index term like
string comparison
44
should ultimately appear in the index in two forms:
string comparison 44
comparison, string 44
Index terms are normally split and rotated at each blank in the term. The tilde
- is used to prevent splitting:
coercion*to nunber
45
is not to be indexed under “to."
There are a couple of other frills. Since we use troff, some troff size-
and font-change commands are recognized and properly ignored during sorting.
Furthermore, because font changes occur frequently in the index, we use the
shorthand [. ] to indicate material that should appear in the index in the
constant-width font; for example
[if]-[else]statement
is to be printed as
if-else statement
The indexing process is a composition of six commands:
ix.sort1
sort input by index term, then by page number
ix.collapse
collapse number lists for identical terms
ix.rotate
generate rotations of index term
ix.genkey
generate a sort key to force proper ordering
ix.sort2
sort by sort key
ix.fornat
gencrate final output
These commands gradually massage the index-term, page-number pairs into the
final form of the index.
.For the remainder of this section we will consider these
commands in order.
The initial sort takes the index-term, page-number pairs as input and brings
identical terms together in page-number order:
---
## Page 136
126
PROCESSING WORDS
CHAPTER S
ix.sort1-sort by index term，then by page number
input/output: lines of the forn string tab number
sort by string, then by number; discard duplicates
sort -t'tab′+0-1+1n -2-u
The arguments to the sort command need explanation: -t'tab′ says tab is
the field separator; +0 -1 says the first sort key is field 1, which is to be sorted
alphabetically; + 1n =2 says the second sort key is field 2, which is to be sorted
numerically: and -u says to discard duplicates. (In Chapter 6, we describe a
ix.sort 1 on the input above is:
[FS] variable
35
[FS] variable
36
[if]-[else]statenent
[Fs]variable
52
47
arithmetic operators
arithmetic operators
44
9E
coercion rules
coercionto number
45
44
coercion-to string
45
control-flow statements
numeric comparison
48
44
string conparison
44
This output becomes the input to the next program, ix.collapse, which
the usual control-break program.
puts the page numbers for identical terms on a single line, using a variation of
ix.collapse - combine nunber lists for identical terms
input:
string tab num \n string tab nun...
output: string tab num nun ...
BEGIN  FS =OFS ="\t”}
$1I=prev (
if (NR > 1)
printf("\n")
prev = $1
printf("%s\t%s",s1,$2)
next
{printf（*%s"，s2）}
The output of ix.collapse is
---
## Page 137
SECTION 5.3
TEXT PROCESSING
127