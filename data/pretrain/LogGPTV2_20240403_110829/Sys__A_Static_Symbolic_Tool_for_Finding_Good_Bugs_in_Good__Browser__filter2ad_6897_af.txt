In this section, we explore two variables that users control
and that can effect checker results: Sys’s block bound and the
checked optimization level. We ran each of these experiments
on Firefox’s Prio library, since it contains at least three unini-
tialized memory bugs, and Sys found these bugs in its default
conﬁguration.
Optimization level We ran the uninitialized memory
checker on optimization levels O0-O3, Os, and Oz, because
LLVM IR for the same program looks different across levels.
USENIX Association
29th USENIX Security Symposium    211
Sys found no bugs at O0 or O1; one bug at Oz; and all three
bugs at O2 (the default level for most of the browser), O3, and
Os. Sys does not ﬁnd bugs at the lowest optimization levels
because its static analysis pass matches on patterns more com-
mon in production builds; future work is understanding if
Sys can ﬁnd additional bugs at different, higher optimization
levels in the browser, and determining whether building static
analysis speciﬁcally for lower optimization levels can yield
new bugs, as well.11
Block bound We ran Sys on Prio (O2) with block bounds
of 1, 2, 5, 10, 15, 20, and 30. It found three bugs at bounds
ﬁve and up; at bound two, it found one bug, and at bound one,
it found zero bugs. This, in combination with our analysis
of Sys’s false negatives, suggests that optimizing the sys-
tem to support longer block bounds is a good ﬁrst step in
increasing the number of bugs Sys is capable of ﬁnding. It’s
possible, though, that longer block bounds will cause more
false positives, since more blocks means more opportunities
for undeﬁned state to affect the analysis.
7 Limitations and future work
Sys skips code and so is not exhaustive: it doesn’t prove the
absence of bugs, and may miss bugs because of false positive
suppression, solver timeouts, loop bound and offset bound
conﬁguration, and the size of the checking window. Other
symbolic execution tools like KLEE, UC-KLEE, and angr
symbolically execute whole programs or whole functions, and
so miss fewer bugs but also cannot scale to check browsers
as written.12 Each tool hits a different point on the trade-off
curve: on the one end, KLEE is designed for exhaustive check-
ing of small programs, while Sys is meant to incompletely
check huge ones (§8). Moreover, angr (for example) could
implement our scaling strategies, or we could modify Sys to
symbolically execute whole functions or programs.
Though Sys has a lower false positive rate than other UC
implementations—angr’s version has “a false positive rate of
93%, in line with . . . UC-KLEE[’s]” [131]—it still produces
false reports. Many of its false positives come from unknown
caller invariants on the functions it checks. About half of these
are obviously false after quick examination; the other half are
hard to reason about. In the future, we plan to eliminate the
easy half by jumping back to callers and re-checking for bugs.
Sys, like all extensible checking systems (e.g., Pin [98],
angr [131], Semmle [126], etc.), requires users to write new
checkers if they want to ﬁnd new styles of bugs; users may
obviously re-use any existing checkers to ﬁnd new bugs in
different systems. For example, we re-used each checker on
each different system without modiﬁcation. Finally, Sys runs
on LLVM IR, which means that developers must be able to
compile their code to use it—which can be a problem in
11For example, it may be able to ﬁnd undeﬁned behavior bugs that the
compiler optimizes away at higher optimization levels.
12These symbolic tools can also miss bugs due to small sizes of input
objects or their environmental models.
practice, for example, when checking closed source systems,
or when integrating with a new build system [39, 41].
8 Related work
We designed Sys to check huge (browser) codebases that
are thoroughly, continuously, and automatically vetted. To
our knowledge, most other symbolic tools check codebases
that are orders-of-magnitude smaller than browsers, and most
research bug-ﬁnding systems in general look at codebases that
are less thoroughly checked by state-of-the-art tools. Since
many of the challenges we ran into arose precisely because of
trying to check very large, very good code, we see our work
as largely complimentary to the existing literature.
Flexible symbolic checking. Analysis tools have been us-
ing extensions to exploit domain- and program-speciﬁc knowl-
edge for many years [62, 90, 98, 135]. Symbolic tools have
incorporated these capabilities, but as far as we know, there
is no symbolic checking system designed solely for iterative
bug-ﬁnding. UC-KLEE’s main goals were to scale symex
while (1) checking C program correctness without user in-
tervention and (2) avoiding false negatives [114]. Though
UC-KLEE supports checker extensions, the extensions’ false
positive rates are high (80-100% for most checkers), and users
must specify invariants as C annotations (§3).
Woodpecker [59] veriﬁes user-speciﬁed rules over com-
plete C programs, so things like false-positive suppression are
irrelevant. Woodpecker is built on KLEE and provides four
built-in checkers, and it appears that users write checkers that
directly manipulate constraints; we discuss Woodpecker more
below. Saturn [143, 144] users write checkers by associating
ﬁnite state machines with program objects. Though Saturn
found many locking bugs in the Linux kernel, the tool is not
designed to check large C++ codebases (e.g., it relies on a
custom front-end compiler and IR that models C, and does
not let users encode heuristics or false positive suppressions).
The angr [131] framework, originally designed to compare
different binary analysis techniques, is used for everything
from exploit generation to binary patching. Though we share
similar high-level goals with angr, they focus on easy imple-
mentation of analyses, while we focus speciﬁcally on bug
checkers—one level of abstraction higher. angr’s low-level,
untyped interfaces make the tool ﬂexible (e.g., Sys’s scaling
approach could likely be implemented on top of angr to ﬁnd
bugs in binaries). In our experience these low-level interfaces
also make it hard to use for bug-ﬁnding (e.g., from debugging
checkers and heuristics to modifying the tool itself to adding
support for multi-threaded execution; §3). Sys, on the other
hand, is poorly suited to tasks like reverse engineering.
Combined static and symbolic execution. We are not the
ﬁrst to combine static analysis and symbolic execution. The
most relevant work is Woodpecker [59], which signiﬁcantly
speeds up symbolic execution by skipping paths that are not
relevant to a given checker. While skipping paths helps, Wood-
212    29th USENIX Security Symposium
USENIX Association
pecker still must ﬁnd a full path to a bug from main. This
problem matters less for them, since they check code that is
orders of magnitude smaller than browsers.
The Dowser system ﬁnds buffer overﬂow vulnerabilities
by combining fuzzing, program analysis, and symbolic ex-
ecution: it performs static analysis to identify complicated
program pieces, and then uses combined symbolic execution
and fuzzing to steer the program towards the target lines [81].
Deadline [145] ﬁnds double fetch bugs in OS kernels—Linux
and FreeBSD—by using static analysis to prune uninteresting
paths and focus the symbolic execution to paths that contain
multiple reads. Gadelha et al. [71] implement an extension
to the Clang Static Analyzer that reduces false positives by
encoding the path constraints leading to a bug as SMT con-
straints; if the constraints are unsatisﬁable, it suppresses the
bug report (e.g., they ﬁnd 7% of bugs to be unreachable).
Finally, Parvez et al. [109] use static analysis to identify po-
tentially buggy statements, and then use symbolic execution
to synthesize test cases that hit the statements.
Other systems combine static and symex for failure repro-
duction. Zamﬁr et al. take a bug report and use a combi-
nation of static analysis and symbolic execution to repro-
duce the bug. Chopper [140] users specify uninteresting
parts of a program, which the tool then excludes (with static
analysis) before performing symbolic execution. Many oth-
ers [34, 59, 66, 73, 78, 79, 93, 112, 118, 120, 130, 147, 153]
similarly combine static analysis and symbolic execution for
testing, veriﬁcation, and bug ﬁnding—from memory leaks to
use-after-frees to buffer overﬂows. All of these approaches
demonstrate the power of symbolic execution combined with
static analysis. However, none use underconstrained symbolic
execution, which is how Sys scales to large code.
Incomplete symbolic execution. Our incomplete symbolic
execution builds on prior work. UC-KLEE [115], the ﬁrst
system to support underconstrained symbolic execution [63],
deals with the problem of undeﬁned state by cross-checking
a patched and unpatched function: if the two versions differ
beyond the bug ﬁx, UC-KLEE reports an error. As a result,
all state is deﬁned explicitly by equivalence. Our work can
be seen as a response to UC-KLEE’s (and later, angr’s) open
challenge to reduce the false positive rate of underconstrained
symbolic execution of single versions of functions.
Chopper [140] deals with undeﬁned state by avoiding it: it
lazily executes any state that the path under analysis requires.
Bergan et al. [38], like our work, allows symbolic execution to
start at any program point; they, however, tackle the undeﬁned
state challenge by using context-speciﬁc data-ﬂow analysis to
soundly over-approximate the state. In contrast, our symbolic
execution strategy has similarities to call-chain-backward
symbolic execution [99] and iterative veriﬁcation [110].
Combined concrete and symbolic execution Symbolic
execution tools (e.g., [45, 132, 143, 144]) have been success-
ful at bug ﬁnding, test generation, and partial veriﬁcation. But,
since full symbolic execution struggles to scale [36, 47, 131],
much past work has focused on tackling this challenge. Most
often, modern tools combine symbolic execution with con-
crete execution; these concolic execution tools (e.g., [42, 46,
50, 61, 74–76, 127]) can run long paths in large programs by
executing some code concretely. But the set of code paths
and values are inexhaustible, and thus even these tools can
easily miss errors by not hitting a given path, or not executing
it with the right value. Similar problems arise for other bug
ﬁnding systems (e.g., [32, 33, 44, 49]).
Finally, for more information on the beneﬁts and draw-
backs of underconstrained symbolic execution compared to
traditional symbolic execution—in other words, information
on the impact of skipping code—Ramos [113] directly com-
pares KLEE and UC-KLEE along a number of axes (e.g.,
scalability, false positives, etc).
Fuzzing and symbolic execution. Fuzzing has identiﬁed
more bugs in browsers than any other approach [30], but
fuzzers have their own scaling challenges. In particular,
fuzzers like AFL [152] have a hard time checking deep code.
In response to this, various systems, including Driller [137],
QSYM [150], CAB-Fuzz [86] and several others (e.g., [97,
100, 108]), combined fuzzing with symbolic execution. T-
Fuzz [111], for example, scales fuzzing by skipping complex
constrains and uses symbolic execution to determine if the
bugs ﬂagged bugs are real; it, however, relies on full symbolic
execution which does not scale to checking browsers.
Extensible static checking. There are many extensible
static frameworks for bug checking [39, 48, 60, 121]. Hallem
et al. [80] present one such system, and the Clang Static Ana-
lyzer [87] allows users to write their own static checks using
an API. Semmle provides a query language for detecting
buggy patterns in source code; they, however, require devel-
opers to add inline source annotations [126]. Joern provides
a query language for ﬁnding bugs and “fuzzy” parsing to
avoid constructing full program graphs [85]. These efforts are
largely complimentary; indeed, an future direction is to com-
bine such source-level static analysis with low-level symbolic
execution.
Memory safety bug checkers We are not the ﬁrst to iden-
tify uninitialized memory, buffer overﬂow, and use-after-free
bugs; we chose these classes of bugs because they are ag-
gressively checked for and thus good test cases for new tools.
Many static tools identify the bug types we look for: Garmany
et al. build a static analysis framework for detecting unini-
tialized accesses in binaries, identifying seven bugs [72], and
tools like the Clang Static Analyzer [87], Coverity [19], and
Semmle [126] all detect uninitialized memory bugs in source
code. We compare to Clang and Semmle in Section 6; these
tools and others [31, 35, 65, 80, 89, 117, 138, 146] also detect
overﬂow and use-after-free bugs statically. Finally, Lee et al.
provide a thorough overview of undeﬁned behavior—and how
to view certain bug types as cases of undeﬁned behavior [92].
USENIX Association
29th USENIX Security Symposium    213
Dynamic tools and “sanitizers” [133] can also detect
the bug types Sys ﬁnds. MSan [136], UBSan [57], and
ASan [128] automatically instrument programs to detect unini-
tialized reads, undeﬁned behavior, and memory and use-after-
free errors, respectively; Ye et al. reduce the overhead of
MSan on the SPEC2000 benchmark [148]. Valgrind [106]
supports the MemCheck tool [129] that warns about memory
errors like out-of-bounds access and uninitialized memory.
Mitigating memory safety bugs There is a large body of
work on eliminating and mitigating the classes of bugs Sys
checks for. For example, DangSan [141], DangNull [91],
and FreeSentry [149] can mitigate use-after-frees; Baggy-
Bounds [28] and others (we refer the reader to [139]) can
mitigate buffer overﬂows; and systems like SafeInit [101]
can mitigate uninitialized memory bugs. In practice, browsers
rely on sandboxing to contain the damage caused by these
classes of bugs, and more recently, they have turned to veriﬁ-
cation [154] and memory safe languages like Rust [29, 77].
9 Conclusion
This paper presents Sys, an extensible framework for automat-
ically detecting bugs using a combination of static analysis
and symbolic execution: static analysis identiﬁes potential
errorsites cheaply, while symbolic execution reasons deeply
about whether the sites are actually in error. Developers can
use existing Sys checkers for uninitialized memory, overﬂow,
and use-after-free bugs, or they can write their own checkers
for custom properties. Sys identiﬁes 51 bugs (four CVEs and
three groups of bounties) in browsers and operating systems.
Acknowledgments
We thank the reviewers, and our shepherd Thorsten Holz for
his insightful comments and help navigating this process.
Many thanks to Ranjit Jhala for his always impeccable guid-
ance. Thanks to Craig Disselkoen for work on an early version
of the tool, and Diana Young, Mike Walﬁsh, David Ramos,
Riad S. Wahby, Andres Nötzli, and Henry Corrigan-Gibbs for
their assistance with both prose and ideas. Thanks to everyone
who responded to our bug reports for Firefox, Chrome, and
FreeBSD, especially Daniel Veditz and Nicholas Nethercote
at Mozilla, and Ed Maste, Gordon Tetlow, and Ali Mashti-
zadeh with FreeBSD. Thanks to Tom Ritter for helping us run
Semmle and Evan Johnson for helping us run angr. Thanks to
Mary Jane Swenson for everything. This work was supported
in part by a gift from Cisco, the NSF under Grant Number
CCF-1918573 and CPS-1931750, and the Global Research
Outreach program of Samsung Research.
References
[1] https://bugzilla.mozilla.org/show_bug.cgi?id=952406.
[2] https:
//bugs.chromium.org/p/chromium/issues/detail?id=930035.
[3] https://bugzilla.mozilla.org/show_bug.cgi?id=1521360.
[4] https://bugzilla.mozilla.org/show_bug.cgi?id=1544181.
[5] https://bugzilla.mozilla.org/show_bug.cgi?id=923799.
[6] https:
//bugs.chromium.org/p/chromium/issues/detail?id=940323.
[7] https:
//bugs.chromium.org/p/chromium/issues/detail?id=922882.
[8] https:
//bugs.chromium.org/p/chromium/issues/detail?id=943345.
[9] https://bugzilla.mozilla.org/show_bug.cgi?id=952406.
[10] https://bugzilla.mozilla.org/show_bug.cgi?id=1544153.
[11] https://bugzilla.mozilla.org/show_bug.cgi?id=1535880.
[12] https://bugzilla.mozilla.org/show_bug.cgi?id=1544178.
[13] https:
//bugs.chromium.org/p/chromium/issues/detail?id=942269.
[14] https://github.com/harfbuzz/harfbuzz/issues/2168.
[15] https://bugzilla.mozilla.org/show_bug.cgi?id=1473278.
[16] https:
//bugs.chromium.org/p/chromium/issues/detail?id=943374.
[17] https://bugzilla.mozilla.org/show_bug.cgi?id=1614250.
[18] https://bugzilla.mozilla.org/show_bug.cgi?id=1615130.
[19] Coverity scan. https://scan.coverity.com/.
[20] Coverity scan: Firefox.
https://scan.coverity.com/projects/firefox/.
[21] Google/ClusterFuzz. https://github.com/google/clusterfuzz.
[22] How SQLite is tested. https://www.sqlite.org/testing.html.
[23] KLEE workshop 2018.
https://srg.doc.ic.ac.uk/klee18/cfpresentations.html.
[24] Testing Mozilla code. https://developer.mozilla.org/en-
US/docs/Mozilla/Testing.
[25] Email correspondence with Ed Maste, Mar. 2019.