### Section: Controllable Variables and Their Impact on Checker Results

In this section, we examine two variables that users can control, which significantly influence the outcomes of the checker: Sys's block bound and the optimization level. We conducted these experiments using Firefox's Prio library, as it contains at least three uninitialized memory bugs, all of which Sys detected in its default configuration.

#### Optimization Level

We tested the uninitialized memory checker across various optimization levels (O0, O1, O2, O3, Os, and Oz) because the LLVM IR representation varies with different optimization settings. 

- **Results:**
  - At O0 and O1, Sys did not detect any bugs.
  - At Oz, Sys found one bug.
  - At O2, O3, and Os, Sys identified all three bugs. 
  - O2 is the default optimization level for most of the browser code.

**Explanation:**
Sys fails to detect bugs at the lowest optimization levels (O0 and O1) because its static analysis pass is designed to match patterns more common in production builds. Future work will explore whether Sys can identify additional bugs at higher optimization levels and if building static analysis specifically for lower optimization levels can uncover new bugs.

#### Block Bound

We ran Sys on Prio (at O2) with block bounds of 1, 2, 5, 10, 15, 20, and 30. 

- **Results:**
  - At block bounds of five and above, Sys found all three bugs.
  - At a block bound of two, Sys found one bug.
  - At a block bound of one, Sys found no bugs.

**Analysis:**
Combining these results with our analysis of Sys's false negatives, we conclude that optimizing the system to support longer block bounds could increase the number of bugs Sys can detect. However, longer block bounds may also introduce more false positives, as more blocks mean more opportunities for undefined state to affect the analysis.

### Limitations and Future Work

Sys does not perform exhaustive checks and thus cannot guarantee the absence of bugs. It may miss bugs due to:
- False positive suppression
- Solver timeouts
- Loop and offset bound configurations
- The size of the checking window

Other symbolic execution tools like KLEE, UC-KLEE, and angr execute entire programs or functions, missing fewer bugs but unable to scale to check large codebases such as browsers. Each tool strikes a different balance between thoroughness and scalability. For example, KLEE is designed for exhaustive checking of small programs, while Sys is intended for incomplete but scalable checking of large codebases.

**False Positives:**
Sys has a lower false positive rate compared to other underconstrained (UC) implementations. Many false positives arise from unknown caller invariants. About half of these are easily dismissed upon quick examination, while the other half are more challenging to resolve. Future work will focus on eliminating the easily identifiable false positives by re-checking with caller information.

**Extensibility:**
Like other extensible checking systems (e.g., Pin, angr, Semmle), Sys requires users to write new checkers for new types of bugs. Users can reuse existing checkers without modification. Sys operates on LLVM IR, necessitating that developers compile their code to use it, which can be problematic for closed-source systems or when integrating with new build systems.

### Related Work

Sys is designed to check large, well-vetted codebases like those in browsers. Most symbolic tools and research bug-finding systems target smaller codebases. Our work complements existing literature by addressing the unique challenges of very large, high-quality code.

#### Flexible Symbolic Checking

Tools like UC-KLEE, Woodpecker, Saturn, and angr have incorporated domain-specific knowledge and extensions. However, none of these tools are designed solely for iterative bug-finding. Sys aims to reduce false positives and scale to large C++ codebases, making it more suitable for continuous, automated vetting.

#### Combined Static and Symbolic Execution

Several systems, including Woodpecker, Dowser, Deadline, and Gadelha et al.'s Clang extension, combine static and symbolic execution to find specific types of bugs. These approaches demonstrate the power of combining static and symbolic techniques but do not use underconstrained symbolic execution, which is key to Sys's scalability.

#### Incomplete Symbolic Execution

Sys builds on prior work in incomplete symbolic execution, such as UC-KLEE and Chopper. These tools address undefined state through various methods, but Sys focuses on reducing false positives in underconstrained symbolic execution.

#### Combined Concrete and Symbolic Execution

Concolic execution tools (e.g., KLEE, S2E) combine concrete and symbolic execution to scale to large programs. However, even these tools can miss errors due to the inexhaustible set of code paths and values. Sys addresses this by focusing on specific, high-impact error sites.

#### Fuzzing and Symbolic Execution

Fuzzing has been highly effective in finding bugs in browsers, but it struggles with deep code. Tools like Driller, QSYM, and T-Fuzz combine fuzzing with symbolic execution to overcome these limitations. Sys complements these efforts by providing a scalable, underconstrained approach.

#### Extensible Static Checking

Many extensible static frameworks (e.g., Clang Static Analyzer, Semmle, Joern) allow users to write custom checks. Sys integrates with these tools to provide a comprehensive bug-finding solution.

#### Memory Safety Bug Checkers

Static and dynamic tools (e.g., MSan, UBSan, ASan, Valgrind) can detect the types of bugs Sys finds. Browsers also use sandboxing, verification, and memory-safe languages like Rust to mitigate these issues.

### Conclusion

This paper introduces Sys, an extensible framework for automatically detecting bugs using a combination of static analysis and symbolic execution. Sys identifies potential error sites efficiently and deeply analyzes them. Developers can use existing Sys checkers for uninitialized memory, overflow, and use-after-free bugs or write their own for custom properties. Sys has identified 51 bugs (including four CVEs and three groups of bounties) in browsers and operating systems.

### Acknowledgments

We thank the reviewers and our shepherd Thorsten Holz for their insightful comments. Special thanks to Ranjit Jhala for his guidance, Craig Disselkoen for early work on the tool, and Diana Young, Mike Walfish, David Ramos, Riad S. Wahby, Andres NÃ¶tzli, and Henry Corrigan-Gibbs for their assistance. We also thank the teams at Mozilla, Chrome, and FreeBSD for their responses to our bug reports. This work was supported by Cisco, the NSF, and Samsung Research.

### References

[1] https://bugzilla.mozilla.org/show_bug.cgi?id=952406.
[2] https://bugs.chromium.org/p/chromium/issues/detail?id=930035.
[3] https://bugzilla.mozilla.org/show_bug.cgi?id=1521360.
[4] https://bugzilla.mozilla.org/show_bug.cgi?id=1544181.
[5] https://bugzilla.mozilla.org/show_bug.cgi?id=923799.
[6] https://bugs.chromium.org/p/chromium/issues/detail?id=940323.
[7] https://bugs.chromium.org/p/chromium/issues/detail?id=922882.
[8] https://bugs.chromium.org/p/chromium/issues/detail?id=943345.
[9] https://bugzilla.mozilla.org/show_bug.cgi?id=952406.
[10] https://bugzilla.mozilla.org/show_bug.cgi?id=1544153.
[11] https://bugzilla.mozilla.org/show_bug.cgi?id=1535880.
[12] https://bugzilla.mozilla.org/show_bug.cgi?id=1544178.
[13] https://bugs.chromium.org/p/chromium/issues/detail?id=942269.
[14] https://github.com/harfbuzz/harfbuzz/issues/2168.
[15] https://bugzilla.mozilla.org/show_bug.cgi?id=1473278.
[16] https://bugs.chromium.org/p/chromium/issues/detail?id=943374.
[17] https://bugzilla.mozilla.org/show_bug.cgi?id=1614250.
[18] https://bugzilla.mozilla.org/show_bug.cgi?id=1615130.
[19] Coverity scan. https://scan.coverity.com/.
[20] Coverity scan: Firefox. https://scan.coverity.com/projects/firefox/.
[21] Google/ClusterFuzz. https://github.com/google/clusterfuzz.
[22] How SQLite is tested. https://www.sqlite.org/testing.html.
[23] KLEE workshop 2018. https://srg.doc.ic.ac.uk/klee18/cfpresentations.html.
[24] Testing Mozilla code. https://developer.mozilla.org/en-US/docs/Mozilla/Testing.
[25] Email correspondence with Ed Maste, Mar. 2019.