information is important for publishers, because it enables them to optimize their site
content according to the users’ interests, for advertisers, because it allows them to
target a selected population, and many other parties, which we will refer to as analysts.
State-of-the-Art. In order to obtain aggregated user information, today, websites com-
monly use third party web analytics services, called aggregators, which however track
individual users’ browsing behavior across the web, thereby violating their privacy.
Newer systems, e.g., a series of non-tracking web analytics systems [7, 20, 21] recently
proposed by Chen et al., provide users with DP guarantees but rely on strong non-
collusion assumptions. Should a collusion happen, not only the noise but also the
individual user’s data would be disclosed.
Protocol design in PrivaDA. The computation parties are operated by third-parties,
which are possibly paid by the aggregator.
In order to avoid multiple responses by
each user without relying on a public key infrastructure, which is unrealistic in this
setting, we add an initial step to the protocol. The publisher signs and gives each
visiting user a diﬀerent token, along with one or more queries and an associated expiry
20
Figure 2: Privacy-preserving Web Analytics: Protocol Flow
time (within which the result has to be computed). The user sends the tokens to
the computation parties, together with their answer shares, so that the computation
parties are able to detect duplicates and to discard them before the aggregation. The
users have just to submit their shares and can then go oﬄine. Finally, the support
for a variety of perturbation mechanisms enables the execution of diﬀerent kinds of
analytical queries. The protocol is depicted in Figure 2.
Anonymous Surveys. A further application scenario consists of anonymous surveys.
In this setting, it is often reasonable to tolerate a little result perturbation in favor of
strong privacy guarantees for the participating users.
State-of-the-Art. ANONIZE [38] is a recently proposed large-scale anonymous survey
system. The authors exemplify it on an anonymous course evaluation service, in which
students grade the courses they attend. However, ANONIZE does not address the
problem that the survey result itself might still leak a lot of information about the
individual user, which diﬀerential privacy aims at preventing.
Protocol design in PrivaDA. As compared to ANONIZE, the usage of PrivaDA yields
diﬀerential privacy guarantees, besides avoiding the need to design and implement a
complicated ad-hoc protocol. We exemplify the usage of PrivaDA for anonymous sur-
veys on the previously mentioned course evaluation service. Before submitting a grade
for a certain course, students have to authenticate to prove their enrollment in that
class. We envision a public key infrastructure maintained by the university or an anony-
mous credential system used by the professor to grant her students access credentials.
The computation parties will be implemented by mutually distrustful organizations,
yet all interested in the results of the evaluation, such as the student association, the
university administration, and so on.
Traﬃc Statistics for Anonymous Communication Networks (ACNs). Given
their anonymous nature, it is hard to collect egress traﬃc statistics from ACNs, such
as Tor, without violating the privacy of users. Such statistics are interesting to both
designers and researchers, which might for instance want to know how much of the
network traﬃc is made up by people trying to circumvent censorship.
State-of-the-Art. Elahi et al. recently proposed PrivEx [30], a system for collecting
diﬀerentially private statistics on ACNs traﬃc in predeﬁned slots of time (epochs).
Their work provides two ad-hoc protocols that rely on secret sharing and distributed
21
...P1PnC1CβAggregator...token1,[f(D1)]βtoken1,[f(D1)]1tokenn,[f(Dn)]1tokenn,[f(Dn)]β[≈f(D1,...Dn)]1[≈f(D1,...Dn)]β≈f(D1,...Dn)Publisherf, endf, token1f, endf, tokenndecryption respectively. Nevertheless, to tolerate even an HbC adversary PrivEx has
to compromise on the utility or the epoch duration.
Protocol design in PrivaDA. We can easily apply PrivaDA to the problem of collecting
anonymous traﬃc statistics: we simply let the ACN egress nodes, which relay traﬃc
between the ACN and the destination websites, count the accesses to the diﬀerent
destinations that they relayed. After a ﬁxed epoch, they then share their individual
counts among mutually distrustful computation parties (e.g., privacy organizations,
research centers, and service providers), which jointly compute the overall egress traﬃc
in a privacy-preserving manner with optimal utility.
8 Conclusion and Future Work
Although it is a long-held belief that SMPCs may be used to generically design diﬀer-
entially private data aggregation protocols, such an approach has not been undertaken
so far due to the ineﬃciency of generic constructions. In this work we demonstrated
the viability of such an approach, by designing an SMPC architecture that constitutes
not only a generic, but also a practical building block for designing a variety of privacy-
preserving data aggregation protocols. In particular, the computational eﬀort on the
client side is negligible, which makes PrivaDA suitable even for computationally lim-
ited devices, such as smartphones. In contrast to previous works, PrivaDA supports a
variety of perturbation mechanisms, oﬀers strong privacy guarantees as well as optimal
utility, and is resistant to answer pollution attacks. Furthermore, PrivaDA can support
a large number of clients without any signiﬁcant performance penalty.
For the security of certain arithmetic operations, the SMPC schemes we use assume
that the majority of the computation parties are not colluding. This assumption is
present in any secret sharing-based SMPC scheme5. There exist SMPCs based on other
techniques (homomorphic encryption, oblivious transfer, etc.) that do not assume an
honest majority (e.g., [40, 54]), but that are currently less eﬃcient. Nevertheless, since
PrivaDA is parameterized over the underlying arithmetic SMPCs, it can take immediate
advantage of the rapid progress in this research ﬁeld.
As a future work, we indeed intend to investigate the usage of alternative SMPC
schemes and to explore the integration of more sanitization mechanisms. To foster
further progress in this ﬁeld, we made the implementation of PrivaDA publicly avail-
able [2]: to the best of our knowledge, this is the ﬁrst publicly available SMPC imple-
mentation that supports a variety of arithmetic operations in the malicious setting.
References
[1] GMP: The GNU Multiple Precision Arithmetic Library. http://gmplib.org.
5However, stronger assumptions are common in the DP literature and deemed appropriate in many
realistic scenarios.
22
[2] Our Distributed Diﬀerential Privacy Library. https://sites.google.com/site/
arithmeticsmpc/.
[3] The Boost C++ Libraries. http://www.boost.org.
[4] The OpenSSL Project. http://www.openssl.org.
[5] M. Abramowitz and I. A. Stegun. Handbook of Mathematical Functions with For-
mulas, Graphs, and Mathematical Tables. Dover, 1964.
[6] G. ´Acs and C. Castelluccia.
I have a DREAM! (DiﬀeRentially privatE smArt
Metering). In IH’11, pages 118–132, 2011.
[7] I. E. Akkus, R. Chen, M. Hardt, P. Francis, and J. Gehrke. Non-tracking Web
Analytics. In CCS’12, pages 687–698, 2012.
[8] D. Alhadidi, N. Mohammed, B. C. M. Fung, and M. Debbabi. Secure Distributed
Framework for Achieving -Diﬀerential Privacy. In PETS’12, pages 120–139, 2012.
[9] M. Aliasgari, M. Blanton, Y. Zhang, and A. Steele. Secure Computation on Float-
ing Point Numbers. In NDSS’13, 2013.
[10] Y. Amir, C. Nita-Rotaru, J. R. Stanton, and G. Tsudik. Secure Spread: An
Integrated Architecture for Secure Group Communication. TDSC, 2(3):248–261,
2005.
[11] D. F. Aranha and C. P. L. Gouvˆea. RELIC is an Eﬃcient LIbrary for Cryptogra-
phy. http://code.google.com/p/relic-toolkit/.
[12] M. Backes, A. Kate, and A. Patra. Computational Veriﬁable Secret Sharing Re-
visited. In ASIACRYPT’11, pages 590–609, 2011.
[13] G. Barthe, G. Danezis, B. Gr´egoire, C. Kunz, and S. Zanella-B´eguelin. Veri-
ﬁed Computational Diﬀerential Privacy with Applications to Smart Metering. In
CSF’13, pages 287–301, 2013.
[14] A. Ben-David, N. Nisan, and B. Pinkas. FairplayMP: A System for Secure Multi-
party Computation. In CCS’08, pages 257–266, 2008.
[15] R. Bhaskar, A. Bhowmick, V. Goyal, S. Laxman, and A. Thakurta. Noiseless
Database Privacy. In ASIACRYPT’11, pages 215–232, 2011.
[16] F. Boudot. Eﬃcient Proofs that a Committed Number Lies in an Interval.
In
EUROCRYPT’00, pages 431–444, 2000.
[17] R. Canetti. Security and Composition of Multiparty Cryptographic Protocols.
Journal of Cryptology, 13(1):143–202, 2000.
[18] O. Catrina and A. Saxena. Secure Computation With Fixed-Point Numbers. In
FC’10, pages 35–50, 2010.
23
[19] T.-H. H. Chan, E. Shi, and D. Song. Privacy-Preserving Stream Aggregation with
Fault Tolerance. In FC’12, pages 200–214, 2012.
[20] R. Chen, I. E. Akkus, and P. Francis. SplitX: High-Performance Private Analytics.
In SIGCOMM’13, 2013. to appear.
[21] R. Chen, A. Reznichenko, P. Francis, and J. Gehrke. Towards Statistical Queries
over Distributed Private User Data. In NSDI’12, pages 13–13, 2012.
[22] B. Chor, S. Goldwasser, S. Micali, and B. Awerbuch. Veriﬁable Secret Sharing and
Achieving Simultaneity in the Presence of Faults. In Proc. 26th IEEE Symposium
on Foundations of Computer Science (FOCS), pages 383–395, 1985.
[23] R. Cramer, I. Damg˚ard, and Y. Ishai. Share Conversion, Pseudorandom Secret-
In TCC’05, pages 342–362,
Sharing and Applications to Secure Computation.
2005.
[24] G. Danezis, M. Kohlweiss, and A. Rial. Diﬀerentially Private Billing with Rebates.
In IH’11, pages 148–162, 2011.
[25] L. Devroye. Non-Uniform Random Variate Generation, 1986.
[26] C. Dwork. Diﬀerential Privacy. In ICALP’06, pages 1–12, 2006.
[27] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our Data,
Ourselves: Privacy Via Distributed Noise Generation. In EUROCRYPT’06, pages
486–503, 2006.
[28] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating Noise to Sensitivity
in Private Data Analysis. In TCC’06, pages 265–284, 2006.
[29] F. Eigner and M. Maﬀei. Diﬀerential Privacy by Typing in Security Protocols. In
CSF’13, 2013.
[30] T. Elahi, G. Danezis, and I. Goldberg. PrivEx: Private Collection of Traﬃc
Statistics for Anonymous Communication Networks. Technical Report CACR
2014-08, 2014.
[31] S. L. From and T. Jakobsen. Secure Multi-Party Computation on Integers. Mas-
ter’s thesis, University of Aarhus, Denmark, 2006.
[32] I. Gazeau, D. Miller, and C. Palamidessi. Preserving diﬀerential privacy under
ﬁnite-precision semantics. In QAPL’13, pages 1–18, 2013.
[33] J. Gehrke, E. Lui, and R. Pass. Towards Privacy for Social Networks: A Zero-
Knowledge Based Deﬁnition of Privacy. In TCC’11, pages 432–449, 2011.
[34] R. Gennaro, M. O. Rabin, and T. Rabin. Simpliﬁed VSS and Fact-Track Multi-
party Computations with Applications to Threshold Cryptography. In PODC’98,
pages 101–111, 1998.
24
[35] A. Ghosh, T. Roughgarden, and M. Sundararajan. Universally Utility-Maximizing
Privacy Mechanisms. In STOC’09, pages 351–360, 2009.
[36] S. Goryczka, L. Xiong, and V. Sunderam. Secure Multiparty Aggregation with
Diﬀerential Privacy: A Comparative Study. In EDBT/ICDT’13, pages 155–163,
2013.
[37] A. Haeberlen, B. C. Pierce, and A. Narayan. Diﬀerential Privacy under Fire. In
USENIX’11, 2011.
[38] S. Hohenberger, S. Myers, R. Pass, and abhi shelat. ANONIZE: A Large-Scale
Anonymous Survey System. In S&P’14, 2014.
[39] S. Inusah and T. J. Kozubowski. A Discrete Analogue of the Laplace Distribution.
JSPI, 136(3):1090–1102, 2006.
[40] Y. Ishai, M. Prabhakaran, and A. Sahai. Secure Arithmetic Computation with No
Honest Majority. In TCC’09, pages 294–314, 2009.
[41] M. Jawurek and F. Kerschbaum. Fault-Tolerant Privacy-Preserving Statistics. In
PETS’12, pages 221–238, 2012.
[42] S. P. Kasiviswanathan and A. Smith. A Note on Diﬀerential Privacy: Deﬁning
Resistance to Arbitrary Side Information. Report 2008/144, 2008.
[43] D. Kifer and A. Machanavajjhala. No Free Lunch in Data Privacy. In SIGMOD’11,
pages 193–204, 2011.
[44] F. McSherry and K. Talwar. Mechanism Design via Diﬀerential Privacy.
In
FOCS’07, pages 94–103, 2007.
[45] I. Mironov. On Signiﬁcance of the Least Signiﬁcant Bits for Diﬀerential Privacy.
In CCS’12, pages 650–661, 2012.
[46] I. Mironov, O. Pandey, O. Reingold, and S. P. Vadhan. Computational Diﬀerential
Privacy. In Crypto’09, pages 126–142, 2009.
[47] A. Molina-Markham, P. Shenoy, K. Fu, E. Cecchet, and D. Irwin. Private Memoirs
of a Smart Meter. In BuildSys’10, pages 61–66, 2010.
[48] T. P. Pedersen. Non-Interactive and Information-Theoretic Secure Veriﬁable Secret
Sharing. In Crypto’91, pages 129–140, 1991.
[49] V. Rastogi and S. Nath. Diﬀerentially Private Aggregation of Distributed Time-
Series with Transformation and Encryption. In SIGMOD’10, pages 735–746, 2010.
[50] M. K. Reiter. Secure Agreement Protocols: Reliable and Atomic Group Multicast
in Rampart. In CCS’94, pages 68–80, 1994.
25
[51] E. Shi, T.-H. H. Chan, E. G. Rieﬀel, R. Chow, and D. Song. Privacy-Preserving
Aggregation of Time-Series Data. In NDSS’11, 2011.
[52] R. Wang, Y. F. Li, X. Wang, H. Tang, and X. Zhou. Learning Your Identity and
Disease from Research Papers: Information Leaks in Genome Wide Association
Study. In CCS’09, pages 534–544, 2009.
[53] A. C.-C. Yao. Protocols for Secure Computations (Extended Abstract).
In
FOCS’82, pages 160–164, 1982.
[54] C.-H. Yu, S. S. Chow, K.-M. Chung, and F.-H. Liu. Eﬃcient Secure Two-Party
Exponentiation. In Topics in Cryptology, CT-RSA 2011, pages 17–32. 2011.
A Basic Arithmetic SMPC Protocols
Protocol
Type
Rand. Generation RandInt
Reconstruction
Addition
Multiplication
Division
Scalar
Multiplication
Comparison
Conversion
Rounding
Exponentiation
Logarithm
Rec
IntAdd
FPAdd
FLAdd
FLMul
FLDiv
IntScMul
FPScMul
FLScMul
FLLT
Int2FL
FP2FL
FL2Int
FL2FP
FLRound
FLExp2
FLLog2
Rounds
Interactive Operations
0
1
0
0
0
1
0
0
log (cid:96) + log log (cid:96) + 27
14(cid:96) + (log log (cid:96)) log (cid:96) + ((cid:96) + 9) log (cid:96) + 9k + 4 log k + 37
11
2 log (cid:96) + 7
0
0
10
6
log (cid:96) + 13
log (cid:96) + 13
3 log log (cid:96) + 53
3 log log (cid:96) + 53
log log (cid:96) + 30
12 log (cid:96) + log log (cid:96) + 27
13.5(cid:96) + 0.5(cid:96) log (cid:96) +
3 log (cid:96) + 0.5(cid:96) log log (cid:96) +