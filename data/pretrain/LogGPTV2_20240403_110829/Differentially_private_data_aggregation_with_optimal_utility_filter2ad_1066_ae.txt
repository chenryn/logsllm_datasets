### Information and Its Importance for Publishers, Advertisers, and Analysts

Information is crucial for publishers as it enables them to optimize their site content according to users' interests. For advertisers, it allows targeting a specific audience. Additionally, other stakeholders, referred to as analysts, also benefit from this information.

### State-of-the-Art in Web Analytics

Currently, websites commonly use third-party web analytics services, known as aggregators, to obtain aggregated user information. However, these services often track individual users' browsing behavior across the web, thereby compromising their privacy. Newer systems, such as the non-tracking web analytics systems proposed by Chen et al. [7, 20, 21], provide differential privacy (DP) guarantees but rely on strong non-collusion assumptions. If collusion occurs, not only the noise but also the individual user’s data could be disclosed.

### Protocol Design in PrivaDA

In PrivaDA, the computation parties are operated by third-parties, which may be compensated by the aggregator. To avoid multiple responses from each user without relying on a public key infrastructure (which is impractical in this setting), we introduce an initial step in the protocol. The publisher signs and issues a unique token to each visiting user, along with one or more queries and an associated expiry time. Users send these tokens to the computation parties, along with their answer shares, allowing the computation parties to detect and discard duplicates before aggregation. This process ensures that users only need to submit their shares and can then go offline. The support for various perturbation mechanisms enables the execution of different types of analytical queries. The protocol flow is illustrated in Figure 2.

### Anonymous Surveys

Another application scenario is anonymous surveys. In this context, it is often reasonable to tolerate a small amount of result perturbation to ensure strong privacy guarantees for participating users.

### State-of-the-Art in Anonymous Surveys

ANONIZE [38] is a recently proposed large-scale anonymous survey system, exemplified by an anonymous course evaluation service where students grade the courses they attend. However, ANONIZE does not address the issue that the survey results themselves might still leak information about individual users, which differential privacy aims to prevent.

### Protocol Design in PrivaDA for Anonymous Surveys

Compared to ANONIZE, PrivaDA provides differential privacy guarantees and avoids the need to design and implement a complex ad-hoc protocol. We illustrate the use of PrivaDA for anonymous surveys using the previously mentioned course evaluation service. Before submitting a grade for a specific course, students must authenticate to prove their enrollment in that class. We envision a public key infrastructure maintained by the university or an anonymous credential system used by the professor to grant access credentials to students. The computation parties will be implemented by mutually distrustful organizations, all interested in the results of the evaluation, such as the student association and the university administration.

### Traffic Statistics for Anonymous Communication Networks (ACNs)

Given the anonymous nature of ACNs like Tor, it is challenging to collect egress traffic statistics without violating user privacy. Such statistics are valuable to designers and researchers who, for example, want to know how much network traffic is generated by people trying to circumvent censorship.

### State-of-the-Art in ACN Traffic Statistics

Elahi et al. recently proposed PrivEx [30], a system for collecting differentially private statistics on ACN traffic in predefined time slots (epochs). Their work provides two ad-hoc protocols based on secret sharing and distributed decryption. However, to tolerate even a half-corrupted adversary (HbC), PrivEx has to compromise on utility or epoch duration.

### Protocol Design in PrivaDA for ACN Traffic Statistics

PrivaDA can be easily applied to the problem of collecting anonymous traffic statistics. We let the ACN egress nodes, which relay traffic between the ACN and destination websites, count the accesses to different destinations. After a fixed epoch, they share their individual counts among mutually distrustful computation parties (e.g., privacy organizations, research centers, and service providers), which jointly compute the overall egress traffic in a privacy-preserving manner with optimal utility.

### Conclusion and Future Work

Although it is widely believed that secure multi-party computation (SMPC) can be used to design differentially private data aggregation protocols, such an approach has not been pursued due to the inefficiency of generic constructions. In this work, we demonstrate the viability of this approach by designing an SMPC architecture that serves as a practical building block for various privacy-preserving data aggregation protocols. Specifically, PrivaDA requires negligible computational effort on the client side, making it suitable for computationally limited devices like smartphones. Unlike previous works, PrivaDA supports a variety of perturbation mechanisms, offers strong privacy guarantees and optimal utility, and is resistant to answer pollution attacks. Furthermore, PrivaDA can support a large number of clients without significant performance penalties.

For the security of certain arithmetic operations, the SMPC schemes we use assume that the majority of the computation parties are not colluding. This assumption is common in any secret sharing-based SMPC scheme. There are alternative SMPCs based on techniques like homomorphic encryption and oblivious transfer that do not require an honest majority, but they are currently less efficient. Since PrivaDA is parameterized over the underlying arithmetic SMPCs, it can take advantage of rapid progress in this field.

As future work, we plan to investigate the use of alternative SMPC schemes and explore the integration of more sanitization mechanisms. To foster further progress, we have made the implementation of PrivaDA publicly available [2]. To the best of our knowledge, this is the first publicly available SMPC implementation that supports a variety of arithmetic operations in the malicious setting.

### References

[1] GMP: The GNU Multiple Precision Arithmetic Library. http://gmplib.org.
[2] Our Distributed Differential Privacy Library. https://sites.google.com/site/arithmeticsmpc/.
[3] The Boost C++ Libraries. http://www.boost.org.
[4] The OpenSSL Project. http://www.openssl.org.
[5] M. Abramowitz and I. A. Stegun. Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables. Dover, 1964.
[6] G. Ács and C. Castelluccia. I have a DREAM! (Differentially Private Smart Metering). In IH’11, pages 118–132, 2011.
[7] I. E. Akkus, R. Chen, M. Hardt, P. Francis, and J. Gehrke. Non-tracking Web Analytics. In CCS’12, pages 687–698, 2012.
[8] D. Alhadidi, N. Mohammed, B. C. M. Fung, and M. Debbabi. Secure Distributed Framework for Achieving ε-Differential Privacy. In PETS’12, pages 120–139, 2012.
[9] M. Aliasgari, M. Blanton, Y. Zhang, and A. Steele. Secure Computation on Floating Point Numbers. In NDSS’13, 2013.
[10] Y. Amir, C. Nita-Rotaru, J. R. Stanton, and G. Tsudik. Secure Spread: An Integrated Architecture for Secure Group Communication. TDSC, 2(3):248–261, 2005.
[11] D. F. Aranha and C. P. L. Gouvêa. RELIC is an Efficient Library for Cryptography. http://code.google.com/p/relic-toolkit/.
[12] M. Backes, A. Kate, and A. Patra. Computational Verifiable Secret Sharing Revisited. In ASIACRYPT’11, pages 590–609, 2011.
[13] G. Barthe, G. Danezis, B. Grégoire, C. Kunz, and S. Zanella-Béguelin. Verified Computational Differential Privacy with Applications to Smart Metering. In CSF’13, pages 287–301, 2013.
[14] A. Ben-David, N. Nisan, and B. Pinkas. FairplayMP: A System for Secure Multi-Party Computation. In CCS’08, pages 257–266, 2008.
[15] R. Bhaskar, A. Bhowmick, V. Goyal, S. Laxman, and A. Thakurta. Noiseless Database Privacy. In ASIACRYPT’11, pages 215–232, 2011.
[16] F. Boudot. Efficient Proofs that a Committed Number Lies in an Interval. In EUROCRYPT’00, pages 431–444, 2000.
[17] R. Canetti. Security and Composition of Multiparty Cryptographic Protocols. Journal of Cryptology, 13(1):143–202, 2000.
[18] O. Catrina and A. Saxena. Secure Computation With Fixed-Point Numbers. In FC’10, pages 35–50, 2010.
[19] T.-H. H. Chan, E. Shi, and D. Song. Privacy-Preserving Stream Aggregation with Fault Tolerance. In FC’12, pages 200–214, 2012.
[20] R. Chen, I. E. Akkus, and P. Francis. SplitX: High-Performance Private Analytics. In SIGCOMM’13, 2013. to appear.
[21] R. Chen, A. Reznichenko, P. Francis, and J. Gehrke. Towards Statistical Queries over Distributed Private User Data. In NSDI’12, pages 13–13, 2012.
[22] B. Chor, S. Goldwasser, S. Micali, and B. Awerbuch. Verifiable Secret Sharing and Achieving Simultaneity in the Presence of Faults. In Proc. 26th IEEE Symposium on Foundations of Computer Science (FOCS), pages 383–395, 1985.
[23] R. Cramer, I. Damgård, and Y. Ishai. Share Conversion, Pseudorandom Secret-Sharing and Applications to Secure Computation. In TCC’05, pages 342–362, 2005.
[24] G. Danezis, M. Kohlweiss, and A. Rial. Differentially Private Billing with Rebates. In IH’11, pages 148–162, 2011.
[25] L. Devroye. Non-Uniform Random Variate Generation, 1986.
[26] C. Dwork. Differential Privacy. In ICALP’06, pages 1–12, 2006.
[27] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our Data, Ourselves: Privacy Via Distributed Noise Generation. In EUROCRYPT’06, pages 486–503, 2006.
[28] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating Noise to Sensitivity in Private Data Analysis. In TCC’06, pages 265–284, 2006.
[29] F. Eigner and M. Maffei. Differential Privacy by Typing in Security Protocols. In CSF’13, 2013.
[30] T. Elahi, G. Danezis, and I. Goldberg. PrivEx: Private Collection of Traffic Statistics for Anonymous Communication Networks. Technical Report CACR 2014-08, 2014.
[31] S. L. From and T. Jakobsen. Secure Multi-Party Computation on Integers. Master’s thesis, University of Aarhus, Denmark, 2006.
[32] I. Gazeau, D. Miller, and C. Palamidessi. Preserving differential privacy under finite-precision semantics. In QAPL’13, pages 1–18, 2013.
[33] J. Gehrke, E. Lui, and R. Pass. Towards Privacy for Social Networks: A Zero-Knowledge Based Definition of Privacy. In TCC’11, pages 432–449, 2011.
[34] R. Gennaro, M. O. Rabin, and T. Rabin. Simplified VSS and Fast-Track Multi-Party Computations with Applications to Threshold Cryptography. In PODC’98, pages 101–111, 1998.
[35] A. Ghosh, T. Roughgarden, and M. Sundararajan. Universally Utility-Maximizing Privacy Mechanisms. In STOC’09, pages 351–360, 2009.
[36] S. Goryczka, L. Xiong, and V. Sunderam. Secure Multiparty Aggregation with Differential Privacy: A Comparative Study. In EDBT/ICDT’13, pages 155–163, 2013.
[37] A. Haeberlen, B. C. Pierce, and A. Narayan. Differential Privacy under Fire. In USENIX’11, 2011.
[38] S. Hohenberger, S. Myers, R. Pass, and abhi shelat. ANONIZE: A Large-Scale Anonymous Survey System. In S&P’14, 2014.
[39] S. Inusah and T. J. Kozubowski. A Discrete Analogue of the Laplace Distribution. JSPI, 136(3):1090–1102, 2006.
[40] Y. Ishai, M. Prabhakaran, and A. Sahai. Secure Arithmetic Computation with No Honest Majority. In TCC’09, pages 294–314, 2009.
[41] M. Jawurek and F. Kerschbaum. Fault-Tolerant Privacy-Preserving Statistics. In PETS’12, pages 221–238, 2012.
[42] S. P. Kasiviswanathan and A. Smith. A Note on Differential Privacy: Defining Resistance to Arbitrary Side Information. Report 2008/144, 2008.
[43] D. Kifer and A. Machanavajjhala. No Free Lunch in Data Privacy. In SIGMOD’11, pages 193–204, 2011.
[44] F. McSherry and K. Talwar. Mechanism Design via Differential Privacy. In FOCS’07, pages 94–103, 2007.
[45] I. Mironov. On Significance of the Least Significant Bits for Differential Privacy. In CCS’12, pages 650–661, 2012.
[46] I. Mironov, O. Pandey, O. Reingold, and S. P. Vadhan. Computational Differential Privacy. In Crypto’09, pages 126–142, 2009.
[47] A. Molina-Markham, P. Shenoy, K. Fu, E. Cecchet, and D. Irwin. Private Memoirs of a Smart Meter. In BuildSys’10, pages 61–66, 2010.
[48] T. P. Pedersen. Non-Interactive and Information-Theoretic Secure Verifiable Secret Sharing. In Crypto’91, pages 129–140, 1991.
[49] V. Rastogi and S. Nath. Differentially Private Aggregation of Distributed Time-Series with Transformation and Encryption. In SIGMOD’10, pages 735–746, 2010.
[50] M. K. Reiter. Secure Agreement Protocols: Reliable and Atomic Group Multicast in Rampart. In CCS’94, pages 68–80, 1994.
[51] E. Shi, T.-H. H. Chan, E. G. Rieffel, R. Chow, and D. Song. Privacy-Preserving Aggregation of Time-Series Data. In NDSS’11, 2011.
[52] R. Wang, Y. F. Li, X. Wang, H. Tang, and X. Zhou. Learning Your Identity and Disease from Research Papers: Information Leaks in Genome Wide Association Study. In CCS’09, pages 534–544, 2009.
[53] A. C.-C. Yao. Protocols for Secure Computations (Extended Abstract). In FOCS’82, pages 160–164, 1982.
[54] C.-H. Yu, S. S. Chow, K.-M. Chung, and F.-H. Liu. Efficient Secure Two-Party Exponentiation. In Topics in Cryptology, CT-RSA 2011, pages 17–32. 2011.

### Basic Arithmetic SMPC Protocols

| **Protocol** | **Type** | **Rounds** | **Interactive Operations** |
|-------------|----------|------------|---------------------------|
| Rand. Generation | RandInt | 0 | - |
| Reconstruction | Rec | 1 | - |
| Addition | IntAdd | 0 | - |
| FPAdd | 0 | - |
| FLAdd | 0 | - |
| Multiplication | FLMul | 14ℓ + (log log ℓ) log ℓ + (ℓ + 9) log ℓ + 9k + 4 log k + 37 | 11 |
| Division | FLDiv | 2 log ℓ + 7 | - |
| Scalar Multiplication | IntScMul | 0 | - |
| FPScMul | 0 | - |
| FLScMul | 0 | - |
| Comparison | FLLT | 3 log log ℓ + 53 | - |
| Conversion | Int2FL | 0 | - |
| FP2FL | 0 | - |
| FL2Int | log ℓ + 13 | - |
| FL2FP | log ℓ + 13 | - |
| Rounding | FLRound | log log ℓ + 30 | - |
| Exponentiation | FLExp2 | 12 log ℓ + log log ℓ + 27 | - |
| Logarithm | FLLog2 | 13.5ℓ + 0.5ℓ log ℓ + 3 log ℓ + 0.5ℓ log log ℓ + 53 | - |