# Title: Power Supply Induced Common Cause Faults: Experimental Assessment of Potential Countermeasures

## Authors
Peter Tummeltshammer and Andreas Steininger  
Vienna University of Technology â€“ Embedded Computing Systems Group  
Treitlstrasse 3, A-1040 Vienna, Austria  
Phone: +43 1 58801 18261, Fax: +43 1 58801 18297  
Email: {petertu, steininger}@ecs.tuwien.ac.at

## Abstract
Fault-tolerant architectures based on physical replication of components are vulnerable to faults that cause the same effect in all replicas. Short outages in a power supply shared by all replicas are a prominent example of such common cause faults (CCFs). For systems where providing a replicated power supply would be prohibitively complex, identifying reliable countermeasures against these effects is vital to maintain the required dependability level. In this paper, we propose several such countermeasures, including parity protection, voltage monitoring, and time diversity among the replicas. We perform extensive fault injection experiments on three fault-tolerant dual-core processor designs: one FPGA-based and two commercial ASICs. These experiments provide evidence for the vulnerability of an unprotected dual-core solution, while time diversity and voltage monitoring, in combination with increased timing margins, prove particularly effective in eliminating common cause effects.

## 1. Introduction
Modern real-time architectures offer a wide variety of levels for fault tolerance using M-out-of-N systems like Triple Modular Redundancy (TMR) or a two-core master-checker architecture [4, 6]. While these architectures can achieve error rates of less than 10^-9 faults per hour in a multi-chip solution [6], their fabrication can be very cost-intensive, making them difficult to use in mass production, such as in the automotive industry. This has led to the development of fault-tolerant systems-on-chip, where the entire fault-tolerant system is manufactured on a single die.

This paper addresses the question of how power supply-induced faults affect a single-chip dual-core processor system implementing the master-checker architecture. We focus on finding the system's susceptibility to common cause faults (CCFs), which are the class of faults that affect both cores similarly and may render comparison-based error detection mechanisms ineffective. Furthermore, we present and evaluate the effectiveness of countermeasures against these CCFs using three different architectures.

The paper is organized as follows: Section 2 discusses related work, Section 3 provides an overview of the dual-core architecture and the fault model used, Section 4 presents the experimental setup, and Section 5 shows the results. The paper concludes with Section 6.

## 2. Related Work
The occurrence of CCFs in redundant systems has been extensively studied in literature [1, 3, 10] in the context of system models. CCF models facilitate the calculation of the system's overall failure rate if the probability of a common cause fault occurring is known a priori. The probability of a CCF can be determined through long-term analysis or, if not applicable, through worst-case estimations based on design properties [6].

The problem is that for new designs, long-term analyses are not feasible, and worst-case estimations may not consider novel countermeasures correctly. Therefore, this work focuses on evaluating the effect of several countermeasures, as the evaluation of the CCF rate itself is very architecture and technology-dependent.

Power supply disturbance (PSD) fault injection on a two-core master-checker architecture has been carried out in previous studies [7, 11, 12]. In [7], the authors generate noise on the power supply and test their recovery mechanisms. They also introduce time diversity between the cores, thereby reducing the number of non-recoverable faults to zero. However, they mainly focus on the recovery mechanism and have a very limited number of experiments.

In [12], the authors perform PSD fault injection on the master core in a master-checker architecture with two Pentium processors. The system crashed in 50% of the injections, while for the other 50%, faults were detected by their mechanisms. However, the computations were correct in 99.93% of all fault detection cases, leading to the conclusion that the cores themselves were not affected, but rather the error-detecting periphery. To overcome this effect, we confined our PSD fault injection to the core voltage, leaving the I/O voltage faultless.

In [2], PSD experiments were conducted on an SRAM-based FPGA. The experiments showed that in almost 60% of all PSD injections, the FPGA configuration was lost. This is why we chose a flash-based FPGA for our PSD experiments, which does not suffer from configuration loss on a voltage drop. Otherwise, we would have had to reconfigure the device for every experiment iteration, which is very time-consuming.

## 3. The Dual-Core Architecture

### 3.1 Principle
The architecture we investigate in this paper is a dual-core processor implementing a lockstep master-checker architecture, as shown in Figure 1. Its details were proposed in [8] and extended in [9]. In a lockstep architecture, the master and checker processors execute the same program code highly synchronized. The master processor drives all the outputs, and the checker processor is used to validate those outputs while both cores receive the same inputs. A compare unit checks the outputs every clock cycle, allowing for quick detection of mismatches. All external components are instantiated only once and must be protected against faults, e.g., using ECC or parity for the RAM and buses.

In case of a mismatch, the compare unit can trigger an external mechanism, which resets the cores or starts a recovery procedure, respectively. Such a recovery mechanism is presented in [13]. One can see that such a system, despite its quick fault detection, is susceptible to faults that affect both cores concurrently. This is why we chose PSD fault injection, as it offers highly concurrent fault injection and is a well-known method found in literature. Note that there are other potential CCF origins, such as electrical (clock tree, substrate), environmental (temperature, pressure), or design and fabrication faults, which are not covered in this paper.

### 3.2 Fault Model
The simplest mathematical model to describe the effect of CCFs in dual-channel systems is the beta factor model [3]. This model uses only one factor, the beta factor, which gives the probability that a fault affects both cores. For simplicity, we use time-free failure probabilities in our model; for timed failure rates, the failure probabilities \( P(X) \) have to be expanded as \( P(X) = 1 - e^{-\lambda_X t} \), with a failure rate of \( \lambda_X \) for component X.

In a two-component system, such as the dual-core architecture, we assume that the probability of a single component failing independently is \( P_i(A) \) for component A and \( P_i(B) \) for component B. Furthermore, \( P_d(AB) \) is the probability that both components fail dependently, i.e., a fault affects both components. Then, the probability of a system fault is:

\[ P_s = P_i(A) \cdot P_i(B) + P_d(AB). \]

Beta is the fraction of dependent faults over all faults:

\[ \beta = \frac{P_d(AB)}{P_i(A) + P_i(B) + P_d(AB)}. \]

Beta can be determined experimentally using field data, but it can also be estimated architecturally using worst-case estimations [6]. Beta highly influences the system reliability of multi-component systems, as their independent component failure probabilities cannot simply be multiplied to determine the overall system failure probability, as shown in the equation above.

However, for a fail-silent dual-core system, this approach is very pessimistic, as a fault affecting both cores does not necessarily violate the fail-silence property since the faults can affect the cores differently and can therefore be detected by a compare unit. Thus, the model has to be extended by the probability \( c \), that a fault is detected even though it affected both cores:

\[ \beta_{SYS} = \beta \cdot (1 - c). \]

Now, \( \beta_{SYS} \) is the probability that a fault affects both cores in a way that it cannot be detected by the compare unit or any other error detection mechanism. This is quite similar to the concept of common mode failures in redundant systems.