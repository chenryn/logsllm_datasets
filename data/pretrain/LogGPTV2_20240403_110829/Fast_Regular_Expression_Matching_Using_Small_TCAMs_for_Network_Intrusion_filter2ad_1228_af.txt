hours. This table consolidation time is roughly one
fourth of the ﬁrst table consolidation time because the
number of DFA states has been cut in half by the ﬁrst ta-
ble consolidation and table consolidation has a quadratic
running time in the number of DFA states. The BW times
are the time per DFA state required to minimize these
transition tables using the Bitweaving algorithm in [21];
these times are roughly constant as Bitweaving depends
on the size of the transition tables for each state and is not
dependent on the size of the DFA. For our largest DFA
Scale 34 with 305,339 states, the total Bitweaving opti-
mization time on TS, TS+TC2, and TS+TC4 is 10 hrs, 5
hrs, and 2.5 hrs. These times are not cumulative and fall
by a factor of 2 as each table consolidation step cuts the
number of DFA states by a factor of 2.
14
7.3 Results on 7-var-stride DFAs
We consider two implementations of variable striding
assuming we have a 2.36 megabit TCAM with TCAM
width 72 bits (32,768 entries). Using Table 1, the latency
of a lookup is 2.57 ns. Thus, the potential RE matching
throughput of by a 7-var-stride DFA with average stride
S is 8 × S/.00000000257 = 3.11 × S Gbps.
In our ﬁrst implementation, we only use self-loop un-
rolling of root states in the deferment forest. Speciﬁcally,
for each RE set, we ﬁrst construct the 1-stride DFA using
transition sharing. We then apply self-loop unrolling to
each root state of the deferment forest to create a 7-var-
stride transition table. In all cases, the increase in size
due to self-loop unrolling is tiny. The bigger issue was
that the TCAM width doubled from 36 bits to 72 bits.
We can decrease the TCAM space by using table con-
solidation; this was very effective for all RE sets except
the string matching RE sets Bro217 and C613. This was
only necessary for Snort31. All other self-loop unrolled
tables ﬁt within our available TCAM space.
Second, we apply full variable striding. Speciﬁcally,
we ﬁrst create 1-stride DFAs using transition sharing and
then apply variable striding with no table consolidation,
table consolidation with 2-decision tables, and table con-
solidation with 4-decision tables. We use the best result
that ﬁts within the 2.36 megabit TCAM space. For the
RE sets Bro217, C8, C613, Snort24 and Snort34, no ta-
ble consolidation is used. For C10 and Snort31, we use
table consolidation with 2-decision tables. For C7, we
use table consolidation with 4-decision tables.
We now run both implementations of our 7-var-stride
DFAs on traces of length 287484 to compute the aver-
age stride. For each RE set, we generate 4 traces using
Becchi et al.’s trace generator tool using default values
35%, 55%, 75%, and 95% for the parameter pM . These
generate increasingly malicious trafﬁc that is more likely
to move away from the start state towards distant accept
states of that DFA. We also generate a completely ran-
dom string to model completely uniform trafﬁc such as
binary trafﬁc patterns which we treat as pM = 0.
We group the 8 RE sets into 3 groups: group (a) repre-
sents the two string matching RE sets Bro217 and C613;
group (b) represents the three RE sets C7, C8, and C10
that contain all wildcard closures; group (c) represents
the three RE sets Snort24, Snort31, and Snort34 that con-
tain roughly 40% wildcard closures. Fig. 11 shows the
average stride length and throughput for the three groups
of RE sets according to the parameter pM (the random
string trace is pM = 0).
We make the following observations. (1) Self-loop un-
rolling is extremely effective on the uniform trace. For
the non string matching sets, it achieves an average stride
length of 5.97 and 5.84 and RE matching throughputs
Self-Loop Unrolling
Group (a)
Group (b)
Group (c)
 0
 0.2
 0.4
pM
 0.6
 0.8
 1
Variable Striding
Group (a)
Group (b)
Group (c)
)
s
p
b
G
(
t
u
p
h
g
u
o
r
h
T
)
s
p
b
G
(
t
u
p
h
g
u
o
r
h
T
 20
 15
 10
 5
 0
 20
 15
 10
 5
 0
t
h
g
n
e
l
e
d
i
r
t
S
e
g
a
r
e
v
A
t
h
g
n
e
l
e
d
i
r
t
S
e
g
a
r
e
v
A
 6
 4
 2
 0
 6
 4
 2
 0
 0
 0.2
 0.4
pM
 0.6
 0.8
 1
Figure 11: The throughput and average stride length of
RE sets.
of 18.58 and 18.15 Gbps for groups (b) and (c), re-
spectively. For the string matching sets in group (a), it
achieves an average stride length of 3.30 and a result-
ing throughput of 10.29 Gbps. Even though only the
root states are unrolled, self-loop unrolling works very
well because the non-root states that defer most transi-
tions to a root state will still beneﬁt from that root state’s
unrolled self-loops. In particular, it is likely that there
will be long stretches of the input stream that repeatedly
return to a root state and take full advantage of the un-
rolled self-loops. (2) The performance of self-loop un-
rolling does degrade steadily as pM increases for all RE
sets except those in group (b). This occurs because as
pM increases, we are more likely to move away from
any default root state. Thus, fewer transitions will be
able to leverage the unrolled self-loops at root states. (3)
For the uniform trace, full variable striding does little
to increase RE matching throughput. Of course, for the
non-string matching RE sets, there was little room for
improvement. (4) As pM increases, full variable strid-
ing does signiﬁcantly increase throughput, particularly
for groups (b) and (c). For example, for groups (b) and
(c), the minimum average stride length is 2.91 for all
values of pM which leads to a minimum throughput of
9.06Gbps. Also, for all groups of RE sets, the aver-
age stride length for full variable striding is much higher
than that for self-loop unrolling for large pM . For ex-
ample, when pM = 95%, full variable striding achieves
average stride lengths of 2.55, 2.97, and 3.07 for groups
(a), (b), and (c), respectively, whereas self-loop unrolling
achieves average stride lengths of only 1.04, 1.83, and
1.06 for groups (a), (b), and (c), respectively.
These results indicate the following. First, self-loop
unrolling is extremely effective at increasing throughput
for random trafﬁc traces. Second, other variable striding
techniques can mitigate many of the effects of malicious
trafﬁc that lead away from the start state.
8 Conclusions
We make four key contributions in this paper. (1) We
propose the ﬁrst TCAM-based RE matching solution.
We prove that this unexplored direction not only works
but also works well. (2) We propose two fundamental
techniques, transition sharing and table consolidation, to
minimize TCAM space. (3) We propose variable striding
to speed up RE matching while carefully controlling the
corresponding increase in memory. (4) We implemented
our techniques and conducted experiments on real-world
RE sets. We show that small TCAMs are capable of stor-
ing large DFAs. For example, in our experiments, we
were able to store a DFA with 25K states in a 0.5Mb
TCAM chip; most DFAs require at most 1 TCAM entry
per DFA state. With variable striding, we show that a
throughput of up to 18.6 Gbps is possible.
References
[1] B. Agrawal and T. Sherwood. Modeling TCAM
power for next generation network devices. In Proc.
IEEE Int. Symposium on Performance Analysis of
Systems and Software, 2006.
[2] A. V. Aho and M. J. Corasick. Efﬁcient string
matching: an aid to bibliographic search. Commu-
nications of the ACM, 1975.
[3] M. Alicherry, M. Muthuprasanna, and V. Kumar.
High speed pattern matching for network IDS/IPS.
In Proc. ICNP, 2006.
[4] M. Becchi and S. Cadambi. Memory-efﬁcient reg-
ular expression search using state merging. In Proc.
INFOCOM, 2007.
[5] M. Becchi and P. Crowley. A hybrid ﬁnite automa-
ton for practical deep packet inspection. In Proc.
CoNext, 2007.
[6] M. Becchi and P. Crowley. An improved algorithm
to accelerate regular expression evaluation. In Proc.
ANCS, 2007.
[7] M. Becchi and P. Crowley. Efﬁcient regular expres-
sion evaluation: Theory to practice. In Proc. ANCS,
2008.
[8] M. Becchi and P. Crowley. Extending ﬁnite au-
tomata to efﬁciently match perl-compatible regular
expressions. In Proc. CoNEXT, 2008.
15
[9] M. Becchi, M. Franklin, and P. Crowley. A work-
load for evaluating deep packet inspection architec-
tures. In Proc. IEEE IISWC, 2008.
[22] A. Mitra, W. Najjar, and L. Bhuyan. Compiling
PCRE to FPGA for accelerating SNORT IDS. In
Proc. ACM/IEEE ANCS, 2007.
[10] M. Becchi, C. Wiseman, and P. Crowley. Evalu-
ating regular expression matching engines on net-
work and general purpose processors.
In Proc.
ANCS, 2009.
[11] A. Bremler-Bar, D. Hay, and Y. Koral. Com-
pactDFA: generic state machine compression for
scalable pattern matching
In Proc. INFOCOM,
2010.
[23] J. Moscola, J. Lockwood, R. P. Loui, and M. Pa-
chos. Implementation of a content-scanning mod-
ule for an internet ﬁrewall. In FCCM, 2003.
[24] R. Sidhu and V. K. Prasanna. Fast regular expres-
sion matching using fpgas. In FCCM, 2001.
[25] R. Smith, C. Estan, and S. Jha. XFA: Faster sig-
nature matching with extended automata. In Proc.
Symposium on Security and Privacy, 2008.
[12] B. C. Brodie, D. E. Taylor, and R. K. Cytron. A
scalable architecture for high-throughput regular-
expression pattern matching. SIGARCH Computer
Architecture News, 2006.
[26] R. Smith, C. Estan, S. Jha, and S. Kong. Deﬂating
the big bang: fast and scalable deep packet inspec-
tion with extended ﬁnite automata. In Proc. SIG-
COMM, pages 207–218, 2008.
[13] C. R. Clark and D. E. Schimmel. Efﬁcient reconﬁg-
urable logic circuits for matching complex network
intrusion detection patterns.
In Proc. FPL, pages
956–959, 2003.
[14] C. R. Clark and D. E. Schimmel. Scalable pattern
matching for high speed networks. In FCCM 2004.
[15] J. E. Hopcroft. The Theory of Machines and Com-
putations, chapter An nlogn algorithm for minimiz-
ing the states in a ﬁnite automaton, pages 189–196.
Academic Press, 1971.
[16] S. Kong, R. Smith, and C. Estan. Efﬁcient signa-
ture matching with multiple alphabet compression
tables. In Proc. ACM SecureComm, Article 1, 2008.
[17] S. Kumar, B. Chandrasekaran, J. Turner, and
G. Varghese. Curing regular expressions matching
algorithms from insomnia, amnesia, and acalculia.
In Proc. ACM/IEEE ANCS, pages 155–164, 2007.
[18] S. Kumar, S. Dharmapurikar, F. Yu, P. Crowley, and
J. Turner. Algorithms to accelerate multiple regular
expressions matching for deep packet inspection. In
Proc. SIGCOMM, 2006.
[19] S. Kumar, J. Turner, and J. Williams. Advanced al-
gorithms for fast and scalable deep packet inspec-
tion. In Proc. ANCS, pages 81–92, 2006.
[20] C. R. Meiners, A. X. Liu, and E. Torng. TCAM
Razor: A systematic approach towards minimizing
packet classiﬁers in TCAMs. In Proc. ICNP, 2007.
[21] C. R. Meiners, A. X. Liu, and E. Torng. Bit weav-
ing: A non-preﬁx approach to compressing packet
classiﬁers in TCAMs. In Proc. ICNP, 2009.
[27] R. Sommer and V. Paxson. Enhancing bytelevel
network intrusion detection signatures with con-
text. In Proc. ACM CCS, pages 262–271, 2003.
[28] I. Sourdis and D. Pnevmatikatos. Pnevmatikatos:
Fast, large-scale string match for a 10gbps fpga-
based network intrusion detection system. In Proc.
FCCM, pages 880–889, 2003.
[29] I. Sourdis and D. Pnevmatikatos. Pre-decoded cams
for efﬁcient and high-speed nids pattern matching.
In Proc. FCCM, 2004.
[30] J.-S. Sung, S.-M. Kang, Y. Lee, T.-G. Kwon, and
B.-T. Kim. A multi-gigabit rate deep packet in-
spection algorithm using TCAM.
In Proc. IEEE
GLOBECOM, 2005.
[31] S. Suri, T. Sandholm, and P. Warkhede. Compress-
ing two-dimensional routing tables. Algorithmica,
2003.
[32] L. Tan and T. Sherwood. A high throughput string
matching architecture for intrusion detection and
prevention. In Proc. ISCA, 2005.
[33] N. Tuck, T. Sherwood, B. Calder, and G. Varghese.
Deterministic memory-efﬁcient string matching al-
gorithms for intrusion detection. In Proc. IEEE In-
focom, pages 333–340, 2004.
[34] F. Yu, Z. Chen, Y. Diao, T. V. Lakshman, and R. H.
Katz. Fast and memory-efﬁcient regular expres-
sion matching for deep packet inspection. In Proc.
ANCS, 2006.
[35] F. Yu, R. H. Katz, and T. V. Lakshman. Gigabit
rate packet pattern-matching using TCAM. In Proc.
ICNP, 2004.
16