### Table Consolidation and Bitweaving Optimization

The table consolidation time for the second consolidation is approximately one-fourth of the initial consolidation time. This reduction is due to the number of DFA states being halved by the first consolidation, and the consolidation process having a quadratic runtime in the number of DFA states. The Bitweaving (BW) times represent the time per DFA state required to minimize transition tables using the Bitweaving algorithm [21]. These times remain relatively constant because Bitweaving's performance depends on the size of the transition tables for each state, not the overall DFA size.

For our largest DFA, Scale 34, with 305,339 states, the total Bitweaving optimization times for TS, TS+TC2, and TS+TC4 are 10 hours, 5 hours, and 2.5 hours, respectively. These times are not cumulative and decrease by a factor of 2 as each table consolidation step reduces the number of DFA states by a factor of 2.

### Results on 7-Variable-Stride DFAs

We evaluated two implementations of variable striding, assuming a 2.36 megabit TCAM with a width of 72 bits (32,768 entries). According to Table 1, the latency for a lookup is 2.57 ns, resulting in a potential RE matching throughput of 3.11 Ã— S Gbps for a 7-variable-stride DFA with an average stride S.

#### First Implementation: Self-Loop Unrolling

In the first implementation, we applied self-loop unrolling only to root states in the deferment forest. For each RE set, we constructed a 1-stride DFA using transition sharing and then unrolled self-loops at each root state to create a 7-variable-stride transition table. The increase in size due to unrolling was minimal, but the TCAM width doubled from 36 bits to 72 bits. We reduced the TCAM space using table consolidation, which was effective for all RE sets except Bro217 and C613. Table consolidation was necessary only for Snort31; all other self-loop unrolled tables fit within the available TCAM space.

#### Second Implementation: Full Variable Striding

In the second implementation, we created 1-stride DFAs using transition sharing and then applied full variable striding with no table consolidation, table consolidation with 2-decision tables, and table consolidation with 4-decision tables. We used the best result that fit within the 2.36 megabit TCAM space. No table consolidation was needed for Bro217, C8, C613, Snort24, and Snort34. For C10 and Snort31, we used table consolidation with 2-decision tables, and for C7, we used table consolidation with 4-decision tables.

#### Performance Evaluation

We ran both implementations of our 7-variable-stride DFAs on traces of length 287,484 to compute the average stride. For each RE set, we generated four traces using Becchi et al.'s trace generator tool with default values of 35%, 55%, 75%, and 95% for the parameter pM, representing increasingly malicious traffic. We also generated a completely random string to model uniform traffic, treated as pM = 0.

We grouped the 8 RE sets into three categories:
- **Group (a)**: String matching RE sets (Bro217 and C613).
- **Group (b)**: RE sets with all wildcard closures (C7, C8, and C10).
- **Group (c)**: RE sets with approximately 40% wildcard closures (Snort24, Snort31, and Snort34).

Figure 11 shows the average stride length and throughput for the three groups of RE sets according to the parameter pM (the random string trace is pM = 0).

**Observations:**
1. **Self-Loop Unrolling**: 
   - Extremely effective on the uniform trace.
   - For non-string matching sets, it achieves an average stride length of 5.97 and 5.84, with RE matching throughputs of 18.58 and 18.15 Gbps for groups (b) and (c), respectively.
   - For the string matching sets in group (a), it achieves an average stride length of 3.30 and a throughput of 10.29 Gbps.
   - Even though only root states are unrolled, self-loop unrolling works well because non-root states that defer transitions to a root state benefit from the unrolled self-loops.
   - As pM increases, the performance of self-loop unrolling degrades, especially for groups (a) and (c), because fewer transitions leverage the unrolled self-loops at root states.

2. **Full Variable Striding**:
   - Little improvement in throughput for the uniform trace.
   - As pM increases, full variable striding significantly increases throughput, particularly for groups (b) and (c).
   - For example, when pM = 95%, full variable striding achieves average stride lengths of 2.55, 2.97, and 3.07 for groups (a), (b), and (c), respectively, compared to 1.04, 1.83, and 1.06 for self-loop unrolling.

### Conclusions

Our key contributions include:
1. Proposing the first TCAM-based RE matching solution, proving its effectiveness.
2. Introducing transition sharing and table consolidation to minimize TCAM space.
3. Proposing variable striding to speed up RE matching while controlling memory usage.
4. Implementing and testing these techniques on real-world RE sets, demonstrating that small TCAMs can store large DFAs. For instance, we stored a DFA with 25K states in a 0.5Mb TCAM chip, with most DFAs requiring at most 1 TCAM entry per DFA state. With variable striding, we achieved a throughput of up to 18.6 Gbps.

### References

[References listed as provided in the original text.]

This optimized version of the text is more structured and clear, making it easier to follow the technical details and results.