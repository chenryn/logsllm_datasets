基于误差函数的正则化：
$$
J(w,b) = \frac{1}{2m}\sum_{i=1}^m(f(x^{(i)}) - y^{(i)})^2
+\frac{\lambda}{2m}\sum_{j=1}^nw_j^2
$$
使得参数 w 越大，代价就越高，这样梯度下降算法就会选择较小的 w ，改善过拟合
如果选择的正则化参数$\lambda$过大，则会把所有的参数都最小化了，但若$\lambda$过小，那就只能得到一条斜率为0的直线
- 添加 L1 正则项之后，一些特征的权重会变小，一些绝对值较小的系数甚至直接变为 0（相当于抛弃了一些特征），来增强模型的泛化能力。这种回归也叫 Lasso 回归
- 添加 L2 正则项之后，模型在不抛弃任何一个特征的情况下，会缩小回归系数，也就是某些特征的权重，让模型相对稳定，通常模型的泛化能力也更好。这种回归也叫 Rigde 回归
#### 增加训练数据
- 数据增强：对已有训练数据进行合理变换，产生新数据
- 数据合成：如通过计算机生成的图像来当做模型的训练数据
### 蒙特卡洛算法和拉斯维加斯算法
- 两类算法的统称，利用随机的方法来简化整体的算法过程
蒙特卡罗算法原理：每次计算都尽量尝试找更好的结果路径，但不保证是最好的结果路径。用这样寻找结果的方法，无论何时都会有结果出来，而且给的时间越多、尝试越多，最终会越近似最优解
拉斯维加斯算法原理：就是每次计算都尝试找到最好的答案，但不保证这次计算就能找到最好的答案，尝试次数越多，越有机会找到最优解
### 随机搜索
生成一定范围内的随机题解，代入成本函数，也许可以得到一个可以接受的题解
### 爬山法
随机选取一个题解，在这个题解临近的解题空间内寻找成本更低的题解
这种方式问题是得到题解的可能只是局部最优而非全局最优
### 模拟退火算法
随机选取一个题解，然后也会跟爬山法一样尝试寻找成本更低的解
区别在于如果发现新的题解比老的题解花费的成本更高，这个题解可能也会被接收（随机），但随着迭代次数不断增加（温度下降），这种花费成本更高的题解被接受的概率会越来越小
### 遗传算法
随机选取一组题解，对这些题解的成本函数进行排序
选取成本函数最小的一部分顶端题解，称之为**精英选拔**，创建新种群，新种群的其他题解都是根据这些精英演变而来的
演变的方式有两种：
- 变异：对题解的某一个变量做一个微小的调整
- 配对：调两个题解按某种方式进行交叉结合
## 评估模型
数据集被划分为训练集跟测试集，一般是七三分
对于回归模型：通过比较不同模型测试集的预测误差的大小，越大代表对未知数据性能越差
预测误差的计算就是原理同线性回归的代价函数：
$$
J(w,b) = \frac{1}{2m}\sum_{i=1}^m(f(x^{(i)}) - y^{(i)})^2
$$
即数据集的预测值与目标值的差累加
更一般的，是把数据集被划分为训练集跟交叉验证集、测试集，一般是六二二分
通过比较不同模型对于验证集的预测误差，选择一个在验证集效果最好的模型，当最终决定使用哪个后模型，使用测试集来展示模型对未知数据的性能
总结一下，划分数据的方法有如下：
- Holdout 检验：将原始的样本集合随机划分为训练集和测试集两部分，评估的结果有一定随机性
- 交叉校验：为了消除 Holdout 检验的随机性，将全部样本划分成 k 个大小相等的样本子集，然后依次遍历这 k 个子集，每次把当前遍历到的子集作为验证集，其余所有的子集作为训练集，这样依次进行 k 次模型的训练和评估，再将所有 k 次评估指标的平均值作为最终的评估指标
- 自助法：对于总数为 n 的样本集合，先进行 n 次有放回地随机抽样，得到大小为 n 的训练集。在 n 次采样过程中，有的样本会被重复采样，有的样本没有被抽出过，再将这些没有被抽出的样本作为验证集进行模型验证
- 时间切割：将时间序列数据分为训练集和测试集，在某一个时间点之前的数据用作训练集，之后的数据用作验证集，防止模型在训练和评估过程中引入未来信息
- 离线 Replay：根据数据生成时间对测试样本进行排序，并根据模型的更新时间点，逐步更新模型并评估模型在更新前后的性能，以更准确地反映模型在生产环境中的表现
### 偏差与方差
偏差的含义是模型预测值的期望和真实结果之间的区别，如果偏差为 0，模型给出的估计的就是无偏估计，方差的含义则是模型预测值的方差，也就是预测值本身的波动程度，方差越小意味着模型越有效。
模型的设计追求低偏差，即准确度高，低方差，即比较简单的模型。高偏差意味着过拟合，高方差意味着欠拟合，理想情况下应该选择低偏差与低方差的模型，即在过拟合与欠拟合直接选择
偏差使用训练集计算得到，即对于训练集使用代价函数计算，代价越小，则偏差越高
方差使用验证集计算得到，即对于验证集使用代价函数计算，代价越小，则方差越低
模型验证的任务就是确定模型的复杂度以避免过拟合的发生，选择数据集基本的原则就是确保训练集、验证集和测试集三者两两互不相交，同时保证三个数据集中正例和负例的比例应该大致一致，避免在数据集之间出现不平衡，再在这些数据集上使用Holdout检验或者交叉校验
![](/assets/20231025155745.png)
正则化可以用来防止过拟合，如果选择的正则化参数$\lambda$过大，则会把所有的参数都最小化了，这会使得模型欠拟合，而$\lambda$越小，模型就越过拟合
![](/assets/2023102516181.png)
使用学习曲线可以决定是否能通过增加训练数据提升模型效果
![高偏差下添加更多数据](/assets/2023102517425.jpg)
![高方差下添加更多数据](/assets/2023102517435.jpg)
在过拟合的情况下，添加更多的数据能提升模型效果，但在欠拟合的情况下，模型压根就设计的不对，添加再多的数据也无益
- 获得更多的训练样本——解决高方差
- 尝试减少特征的数量——解决高方差
- 尝试获得更多的特征——解决高偏差
- 尝试增加多项式特征——解决高偏差
- 尝试减少正则化程度λ——解决高偏差
- 尝试增加正则化程度λ——解决高方差
较小的神经网络，参数比较少，容易欠拟合。而更大的神经网络，偏差相对会较低，即过拟合，使用正则化可以减少过拟合，但计算代价会越来越高，所以中大型神经网络一般要解决的是高方差的问题，针对不同隐藏层层数的神经网络训练神经网络， 然后选择验证集代价最小的神经网络
### 评估指标
- 正样本：即属于某一类的样本
- 负样本：即不属于某一类的样本
对比项 | 正类 | 负类
-|-|-
被检索	|True Positive|	False Positive
未检索|	False Negative|	True Negative
- 准确率(Accuracy)：指分类正确的样本占总样本个数的比例 $(TP + TN) / ALL$
- 查准率（Precision）：被正确检索的样本数 与 被检索到样本总数之比 $TP / (TP + FP)$
- 查全率（Recall）：被正确检索的样本数 与 应当被检索到的样本数之比 $TP / (TP + FN)$
宁愿漏掉，不可错杀：Precision 将是一个被侧重关心的指标。宁愿错杀，不可漏掉：Recall 将是一个被侧重关心的指标。当两个数字都很高时，表示模型有很好的效果
F-Score，用来综合考虑 Precision 与 Recall，$\beta$是用来调整 Precision 与 Recall 二者的权重，这个分数越高代表 Precision 与 Recall 更平衡：
$$
FS=\left(1+\beta^2\right)\cdot\frac{Precision\cdot Recall}{\beta^2\cdot(Precision+Recall)}
$$
对数损失：
$$
\begin{aligned}-\frac{1}{N}\sum_{i=1}^{N}\left(y_i\log P_1+(1-y_i)\log\left(1-P_i\right)\right)\end{aligned}
$$
（二分类对数损失函数）
yi​ 是输入实例 xi​ 的真实类别, pi​ 是预测输入实例 xi​ 是正样本的概率，N 是样本总数
（多分类对数损失函数）
$$
\text{Multi-LogLoss }=-\frac1n\sum_{i=1}^n\sum_{j=1}^my_{i,j}\log{(p_{i,j})}
$$
均方根误差：用来评估预测连续值的模型的效果
$$
\mathrm{RMSE}=\sqrt{\frac{\sum_{i=1}^n\left(y_i-\hat{y}_l\right)^2}n}
$$
yi​ 是第 i 个样本点的真实值，y^​l​ 是第 i 个样本点的预测值，n 是样本点的个数。那么均方根误差越小，就证明这个回归模型预测越精确
P-R曲线：横轴是召回率，纵轴是精确率，可以用来对比不同模型在固定召回率或精确率的情况，另外一个指标怎样
ROC曲线：横坐标是 False Positive Rate（FPR，假阳性率），纵坐标是 True Positive Rate （TPR，真阳性率）
AUC 是ROC曲线下的面积，AUC 的取值范围在 0 到 1 之间，越接近 1 表示分类器性能越好
平均精度均值：
## 调参
### 网格搜索
超参数是机器学习算法中需要手动设置的参数，不同的超参数组合可能会对模型的性能产生显著影响。网格搜索通过指定超参数的候选值，并遍历所有可能的组合，来找到最佳的超参数组合
### 随机搜索
随机搜索在超参数空间中随机选择一组候选值进行评估，而不是遍历所有可能的组合
## 迁移学习