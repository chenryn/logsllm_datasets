and the NXDOMAINs they queried. Each row represents one host and each column
represents one NXDOMAIN. If host i queried NXDOMAIN j in that day, we assign
weight wij = 1 in the matrix. Otherwise, we assign wij = 0. Then, each row is
normalized such that the sum of weights is one.
119
Figure A.1: Cumulative distribution of distinct number of NXDOMAINs queried by each
host in 12/18/2016.
3. Next, we do Singular Value Decomposition (SVD) over this matrix and keep the ﬁrst
N eigenvalues. For our dataset, we choose N = 35 according to the scree plot of
Eigenvalues. Figure 5.4 shows that the Eigenvalues line plateaus after N >= 35.
4. The resulting eigenvectors are used for XMeans clustering.
5. Once we have the clusters of NXDOMAINs, we extract a feature vector for each
cluster, which will be used for classiﬁcation. We have four feature families: length,
entropy, pairwise jaccard distance of character distribution, and pairwise dice dis-
tance of bigram distribution. This yields a 36-length feature vector for classiﬁcation
that relies on properties of the domain strings themselves. Please refer to Section
4.1.1 in the original Pleiades paper [25] for further details.
6. Finally, the classiﬁer uses the feature vectors of the clusters to detect existing, known
DGAs and identify never-before-seen DGAs.
To obtain DGA domains as a training dataset for the classiﬁer, we analyzed dynamic
malware execution trafﬁc and executed reverse-engineered DGA algorithms. Firstly, we
identiﬁed NXDOMAINs that were queried by malware md5s by analyzing malware pcaps
obtained from a security vendor. We used AVClass [132] to get the malware family labels
of those md5s. Using this method, we labeled pykspa, suppobox, and gimemo malware
120
0.50.60.70.80.91.0101001,00010,000Number of NXDomainsCDFTable A.1: DGA families contained within our ground truth dataset.
DGA Family
Chinad
Corebot
Gozi
Locky
Murofet
Necurs
NewGOZ
PadCrypt
Qadars
Qakbot
Ranbyus
Sisron
Symmi
Pykspa
Pykspa
Gimemo
Suppobox
# of Domains # of Feature Vectors
18
18
72
36
56
18
18
36
18
35
18
19
18
48
40
17
40
4,608
720
864
360
54,720
36,864
18,000
1,728
3,600
180,000
720
739
1,152
90,300
1,190
9,144
12,846
families, which were active in our dataset. We extract one feature family per cluster for
these. Secondly, we use reverse engineered DGA domains to compensate limited visibility
of DGAs active in the network dataset. Although only Pykspa, Suppobox, and Murofet do-
mains have matches in active clusters, we extract one feature vector for each version’s daily
domains of 14 DGA families from the reversed engineered DGA domain dataset. Table A.1
shows the distribution of the number of features vectors from the reverse engineered DGAs
(top) and those seen in clusters (bottom).
We trained the classiﬁer with 17 classes, including 16 malware families and one man-
ually labeled benign class. We labeled benign class from clusters containing mixture of
all kinds of benign domains, as well as clusters containing disposable domains (e.g., DNS
queries to Anti-Virus online reputation products [133]).
We performed model selection to choose among the following algorithms: Naive Bayes,
Linear SVM, Random Forest, Logistic Regression and Stochastic Gradient Descent Clas-
siﬁer. After the analysis of the performance of the different classiﬁers, we chose to use
121
Figure A.2: ROC curves for 16 malware DGA classes and one benign class.
Figure A.3: Micro and macro ROC curves.
122
0.50.60.70.80.91.00.000.250.500.751.00False Positive RateTrue Positive Rateclassbenignchinadcorebotgimemogozilockymurofetnecursnewgozpadcryptpykspaqadarsqakbotranbyussisronsuppoboxsymmi0.50.60.70.80.91.00.000.250.500.751.00False Positive RateTrue Positive Ratemicro−average ROC curvemacro−average ROC curveFigure A.4: Newly found DGAs.
Random Forest as our classiﬁer. Random Forests are similar to Alternative Decision Trees,
a boosted tree-based classiﬁer, which were used in the original Pleiades paper. We tested
our classiﬁer with ﬁve fold cross-validation and measured an average accuracy at 96.08%,
and a false positive rate of 0.9%. Figure A.2 shows the multi-class ROC curves of the clas-
siﬁer performance. Figure A.3 shows the micro and macro ROC curves of the multi-class
classiﬁer in our implementation of Pleiades.
A.4 Current DGA Landscape
We ran the DGA detection system over anonymized network trafﬁc from a Recursive DNS
server in a telecommunication provider, from December 18, 2016 to December 29, 2016.
Newly Discovered DGAs We found 12 new DGA malware families. Figure A.4 shows
5 of them. New DGA A is classiﬁed as similar to the DGA Chinad, with a total of 59,904
domains. The generated domains have a ﬁxed length of 18 characters and use ﬁve dif-
ferent tlds:
.com, .net, .cn, .biz, and .ru. Chinad has similar characteristics in domain
names, but its domain length is 16 characters, and it uses two additional tlds: .info and
.org. New DGA B is a dictionary-words DGA that is classiﬁed as similar to Gozi. Gozi
generates domains by combining words from word lists such as Requests for Comments
123
New DGA Cwww.mazubykuhat[.]kzwww.kesgunvux[.]kzwww.qatwafpyg[.]kzwww.hucadunvucy[.]kzwww.soruqlyahat[.]kzNew DGA Ans1d8qh2t51tndo5v3[.]netkcprqut8ub4zgsrfst[.]ru5qq6fzk452ijexoavi[.]netniv62bplro1yre1efs[.]cn2x5d2mg73yjnc3mitm[.]comNew DGA Bwww.alltraveltweets[.]comwww.kenfeverbusterrec[.]comwww.profnimorningmap[.]comwww.heavyninjaeternal[.]comwww.hubasicsbinjames[.]comNew DGA Dzmvctpqqibxymed0[.]comalgxwtzbnnwtbvo0e[.]comneuqfxffaoazda1e[.]comzwaikccluviktrh[.]comjwioadkvjlnfrl[.]comNew DGA E-v1wmdgu1a6.myrkraverk[.]net0nxnc9mu.plorp[.]comdk5ikx03.strangled[.]netmp9693zy.iiiii[.]infocgakona8.myfruit[.]org[.]ruNew DGA E-v2iyjiy.teakwondo[.]one[.]pl39mig.mafia-ag[.]infolzj2q.good[.]one[.]plw9u1k.no-ip[.]orgz23uq.ignorelist[.]comNew DGA E-v3r7g4en.professionalcopy[.]net0akah1.myvnc[.]comcjch25.nitrousexpress[.]infob8sl4c.bot[.]nuzw7wj8.aintno[.]info(RFC), the Ninety Five Theses of Martin Luther in its original Latin text, and GNU Gen-
eral Public License (GNU GPL). In 12 days, we observed 9815 domain names from this
DGA, with 10,435 infected hosts. New DGA C is classiﬁed as similar to Gimemo.
It
repeatedly uses bigrams and trigrams as units for composing domain name strings. We
found 6,738 domains for new DGA C. Most of the domains from DGA C follow a pat-
tern of consonant-vowel-consonant at the beginning, usually followed by another similar
pattern or a sequence of vowel-consonant-vowel, which makes the generated domains ap-
pear almost readable. Nevertheless, New DGA C generated domains did not follow the
character frequency distribution for any of the languages that use the English or similar
alphabets. The length of the generated domains is not ﬁxed but it appears to be around
10 characters with either a character added or removed. New DGA D uses .com tld, and
second-level labels varying between 12 and 18 characters. New DGA E-v1 iterates through
both algorithm-generated second level domains and child labels.
Evasion Attempts in the Wild The DGAs of qakbot and pykspa provide us with evi-
dence that the malware authors are attempting to avoid or obstruct detection. A special
mode of Qakbot is triggered when the malware detects that it is running inside a sandbox
environment. Speciﬁcally, the seed of the algorithm is appended to generate redundant do-
mains that won’t be used as actual C&C. Similary, Pykspa generates two sets of domains
based on two different seed sets, which appear identical to a human analyst as if there were
only one set of generated domains. Different than Qakbot, in normal operation Pykspa
queries both sets of domains, along a list of benign domains. This kind of behavior could
be a method to detect analysis efforts. If an analyst sets the environment to provide answers
to these “bogus” queries, it could indicate anomaly to the malware. Generating a large
number of “fake” domains could also increase the cost of sinkholing the botnets. It makes
the sinkholing operation more likely to fail to cover all of the actual C&C domains [134].
These efforts appear to be in their infancy in terms of complexity and effectiveness at this
124
point. If malware authors unleash their creativity in the future, we might come across more
elaborate evasion cases that require a lot more effort to identify and detect.
Furthermore, we identify instances of DGAs already evading the classiﬁcation part of
Pleiades by introducing a child label. Our classiﬁer has low conﬁdence for detecting new
DGAs B, C, and E-v1. Since there are no DGA domains with child labels in the training
dataset, the classiﬁer does not have the requisite knowledge to predict such DGAs. After
deploying the classiﬁer for 12 days, we retrained the classiﬁer with additional DGA fami-
lies observed from the network. After retraining, our classiﬁer has successfully identiﬁed
the following new variants with high conﬁdence: DGA E-v2 and DGA E-v3.
125
REFERENCES
[1]
ITNews. Inside eBays 90PB data warehouse. https://www.itnews.com.
au/news/inside-ebay8217s-90pb-data-warehouse-342615.
[2] The Economist. Data, data everywhere. http : / / www . economist . com /
node/15557443.
[3]
Interactive Advertising Bureau. Viewability Has Arrived: What You Need To Know
To See Through This Sea Change. http://www.iab.net/iablog/2014/
03/viewability- has- arrived- what- you- need- to- know- to-
see-through-this-sea-change.html. 2014.
[4] Google. Just in time for the holidays - viewability across the Google Display Net-
work. http : / / adwords . blogspot . co . uk / 2013 / 12 / just - in -
time-for-holidays-viewability.html. 2013.
[5] FBI New York Field Ofﬁce. Press Release: Defendant Charged In Massive In-
ternet Fraud Scheme Extradited From Estonia Appeared In Manhattan Federal
Court. https://archives.fbi.gov/archives/newyork/press-
releases / 2012 / defendant - charged - in - massive - internet -
fraud-scheme-extradited-from-estonia-appeared-in-manhattan-
federal-court. 2012.
[6] LawFuel Editors. Massive Internet Fraud Nets Extradicted Estonian Defendant at
Least $14 Million. http://www.lawfuel.com/massive- internet-
fraud - nets - extradicted - estonian - defendant - least - 14 -
million. 2014.
[7] Paul Pearce et al. “Characterizing Large-Scale Click Fraud in ZeroAccess”. In:
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communi-
cations Security. CCS ’14. Scottsdale, Arizona, USA: ACM, 2014, pp. 141–152.
ISBN: 978-1-4503-2957-6.
[8] Daniel Lowd and Christopher Meek. “Good Word Attacks on Statistical Spam Fil-
ters”. In: CEAS. 2005.
[9] Gregory L Wittel and Shyhtsun Felix Wu. “On Attacking Statistical Spam Filters”.
In: CEAS. 2004.
126
[10] Charles Smutz and Angelos Stavrou. “Malicious PDF Detection Using Metadata
and Structural Features”. In: Proceedings of the 28th Annual Computer Security
Applications Conference. ACM. 2012, pp. 239–248.
[11] Nedim Rndic and Pavel Laskov. “Practical Evasion of a Learning-Based Classiﬁer:
A Case Study”. In: Security and Privacy (SP), 2014 IEEE Symposium on. IEEE.
2014, pp. 197–211.
[12] Weilin Xu, Yanjun Qi, and David Evans. “Automatically Evading Classiﬁers”. In:
Proceedings of the 2016 Network and Distributed Systems Symposium. 2016.
[13] Suphannee Sivakorn, Iasonas Polakis, and Angelos D Keromytis. “I Am Robot:(deep)
Learning to Break Semantic Image Captchas”. In: Security and Privacy (EuroS&P),
2016 IEEE European Symposium on. IEEE. 2016, pp. 388–403.
[14] Amir Globerson and Sam Roweis. “Nightmare at Test Time: Robust Learning by
Feature Deletion”. In: Proceedings of the 23rd international conference on Ma-
chine learning. ACM. 2006, pp. 353–360.
[15] Nicolas Papernot et al. “The Limitations of Deep Learning in Adversarial Settings”.
In: Security and Privacy (EuroS&P), 2016 IEEE European Symposium on. IEEE.
2016, pp. 372–387.
[16] Nicholas Carlini and David Wagner. “Towards evaluating the robustness of neural
networks”. In: Security and Privacy (EuroS&P), 2017 IEEE European Symposium
on. IEEE. 2017.
[17] Prahlad Fogla and Wenke Lee. “Evading Network Anomaly Detection Systems:
Formal Reasoning and Practical Techniques”. In: Proceedings of the 13th ACM
conference on Computer and communications security. ACM. 2006, pp. 59–68.
[18] David Wagner and Paolo Soto. “Mimicry Attacks on Host-Based Intrusion De-
tection Systems”. In: Proceedings of the 9th ACM Conference on Computer and
Communications Security. ACM. 2002, pp. 255–264.
[19] Battista Biggio et al. “Is Data Clustering in Adversarial Settings Secure?” In: Pro-
ceedings of the 2013 ACM workshop on Artiﬁcial intelligence and security. ACM.
2013, pp. 87–98.
[20] Battista Biggio et al. “Poisoning Behavioral Malware Clustering”. In: Proceedings
of the 2014 Workshop on Artiﬁcial Intelligent and Security Workshop. ACM. 2014,
pp. 27–36.
[21] Wei Meng, Ruian Duan, and Wenke Lee. “DNS Changer Remediation Study”. In:
M3AAWG 27th General Meeting. 2013.
127
[22] TDSS/TDL4 Domain Names. http://www.cc.gatech.edu/˜ychen462/
files/misc/tdssdomains.pdf.
[23] ClickZ. Fake Display Ad Impressions Comprise 30% of All Online Trafﬁc [Study].
http://bit.ly/2e3HdCZ.
[24] Association of National Advertisers. The Bot Baseline: Fraud in Digital Advertis-
ing. http://bit.ly/1PKe769.
[25] Manos Antonakakis et al. “From Throw-Away Trafﬁc to Bots: Detecting the Rise
of DGA-Based Malware”. In: Presented as part of the 21st USENIX Security Sym-
posium (USENIX Security 12). 2012, pp. 491–506.
[26] Yacin Nadji et al. “Connected Colors: Unveiling the Structure of Criminal Net-
works”. In: International Workshop on Recent Advances in Intrusion Detection.
Springer Berlin Heidelberg. 2013, pp. 390–410.
[27] Ulrich Bayer et al. “Scalable, Behavior-Based Malware Clustering.” In: NDSS.
Vol. 9. 2009, pp. 8–11.
[28] Roberto Perdisci, Wenke Lee, and Nick Feamster. “Behavioral Clustering of HTTP-
Based Malware and Signature Generation Using Malicious Network Traces”. In:
NSDI. Vol. 10. 2010, p. 14.
[29] Terry Nelms et al. “Towards Measuring and Mitigating Social Engineering Soft-
ware Download Attacks”. In: 25th USENIX Security Symposium (USENIX Security
16). USENIX Association. 2016, pp. 773–789.
[30] Luca Invernizzi et al. “Nazca: Detecting Malware Distribution in Large-Scale Net-
works”. In: NDSS. Vol. 14. 2014, pp. 23–26.
[31] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. “Deepwalk: Online learning of
social representations”. In: Proceedings of the 20th ACM SIGKDD international
conference on Knowledge discovery and data mining. ACM. 2014, pp. 701–710.