stream should enjoy high priority re-injection so that the pkt 4
is re-injected right after Stream 1. In XLINK, we employ stream
priority-based re-injection (Fig. 4(b)) to take care of concurrent
QUIC streams. In this mode, when the sender sends out the last
packet in Stream 1, it immediately checks the unacked_q to look for
packets of the same stream priority. If any, it inserts those packets
before the unsent packets of lower priority streams, as shown in
Fig. 4(b), thus preventing stream blocking.
First-video-frame acceleration. XLINK further introduces video-
frame priority-based re-injection to accelerate first-video-frame
delivery, which is critical for short videos. Without it, the use of
multi-path in the presence of a large path delay difference may suffer
from a slow video start caused by the video frame blocking effect.
The reason is that a multi-path scheduler may put a first-video-
frame packet on an ill-conditioned path if the congestion window of
a well-conditioned path is full (e.g., pkt 3 in blue in Fig. 4(c)). In this
case, the stream-level granularity offered by stream priority-based
re-injection is not enough because the re-injected packet still has to
wait for other video frames in the same stream to be delivered (See.
422
ACK_MPpktQoEControl SignalQoE-drivenmulti-path scheduling & mgmt.LTEWi-FiLoadBalancerQoESignalCaptureEdgeServerspktPath1QUICXLINKClientPath2VideoPlayerHTTPMediaServerHTTPUDPPath1QUICXLINKServerPath2UDPStream1Stream2First video frameSIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Z. Zheng et al.
Fig. 4(b)). XLINK addresses this problem with video-frame priority-
based re-injection shown in Fig. 4(c). In this mode, XLINK provides
stream_send API to the application to express video QoE-awareness
at a finer granularity. Specifically, to accelerate the first video frame,
the application can set the stream data containing the first video
frame at the highest priority with position and size parameters that
indicate the video frame’s relative location. When enabled, XLINK
checks the unacknowledged packet from the first video frame (pkt
3) after sending out the last first-frame packet (pkt 4). If there is
any, the scheduler re-injects it (pkt 3) before any unsent packets
of the other video frames in the same stream. The re-injected copy
can go through the fast path this time, which may arrive earlier
than the original packet. Therefore, the video-frame priority-based
re-injection avoids the slow path’s excessive delay and significantly
improves the video start-up speeds.
5.2 QoE feedback and re-injection control
The problem with packet re-injection is that it, unfortunately, in-
troduces a lot of redundant packets. In our case, we found that
direct applying of re-injection increased the total amount
of traffic by 15%. The humongous cost overhead 9 would be un-
acceptable for large-scale deployment. Besides the cost problem,
redundancy could also impact the overall throughput. In order to
address this challenge, XLINK leverages the client’s QoE feedback
to control the cost overhead associated with packet re-injection
while ensuring user-perceived QoE.
Indeed, redundant packets are not always needed as the video
player caches video chunks. If the buffer occupancy level is high,
the play-time left until the next possible re-buffering is long, and
hence, the urgency of using re-injection is low. On the contrary, if
the buffer occupancy level is low, the time left until the next possible
re-buffering is short and, hence, the urgency of using re-injection
is high. Knowing that the client video player’s buffer occupancy
is a strong indicator of the user-perceived QoE, XLINK captures
buffer occupancy information and sends it back to the server to
control its re-injection usage. These signals are conveyed in the
QoE_Control_Signal field of the ACK_MP frame in Fig. 16. The
definition of QoE signals can be flexible. In our case, we capture
four types of signals from the client’s video player: (1) the number
of cached bytes (𝑐𝑎𝑐ℎ𝑒𝑑_𝑏𝑦𝑡𝑒𝑠), (2) the number cached of frames
(𝑐𝑎𝑐ℎ𝑒𝑑_𝑓 𝑟𝑎𝑚𝑒𝑠), (3) the bitrate (𝑏𝑝𝑠), and (4) the framerate (𝑓 𝑝𝑠).
5.2.1 Capturing QoE signals. The process of how XLINK cap-
tures QoE feedback signals is illustrated in Fig. 5. Here we focus on
the video pipeline, which consists of the Media Source, the Source
Pipe, the Decoder, the Decoder Pipe, and the Renderer. The Media-
CacheService responds to video play request from media player and
sends out HTTP range requests to server to obtain video chunks.
TNET is an Android network SDK used in Taobao client, which
delivers the QoE signals to XLINK. The incoming media data is first
processed by the Media Source where the audio and video frames
are split and cached in the Source Pipes, which subsequently send
the frames to their respective Decoders for the actual decoding.
The Source Pipe keeps track of the number of cached frames and
the number of cached bytes. The Decoder has the knowledge of
9The traffic cost is $0.085 per GB[42]
Figure 5: Illustration of how XLINK captures QoE feedback signals
from the media player.
the frame-rate and bit-rate. In order to obtain the QoE information,
the Source Pipe and Decoder keep sending the these updated met-
rics to TNET, periodically. When XLINK wants to send out a QoE
feedback, it queries the TNET. If the QoE information is updated in
TNET, TNET responds to XLINK’s query, then XLINK encapsulates
the QoE feedback information into the QoE Control Signal field in
ACK_MP frames as shown in Appx. C.
5.2.2 Double thresholding control. The algorithm that con-
trols the re-injection usage needs to satisfy three properties: respon-
siveness, cost-efficiency, and flexibility. (1) It must be responsive
enough when re-injection is urgently required. (2) It should accu-
rately prevent any unnecessary re-injections. (3) It needs to offer
flexibility to adjust the balance between performance and costs. We
introduce double thresholding control to meet the above needs. The
basic form of the algorithm is shown in Alg. 1. The inputs of this
algorithm are the four types of QoE signals as described above, and
the output of the algorithm is the decision of whether re-injection
should be enabled. At a high level, the algorithm can be divided
into three steps:
Step1: Computing play-time left. We first estimate the video
play-time left Δ𝑡 in the client’s buffer with the QoE feedback. One
could use quotient of the 𝑐𝑎𝑐ℎ𝑒𝑑_𝑓 𝑟𝑎𝑚𝑒𝑠 divided by 𝑓 𝑝𝑠 or the
quotient of 𝑐𝑎𝑐ℎ𝑒𝑑_𝑏𝑦𝑡𝑒𝑠 divided by bps to compute Δ𝑡. When the
video is not encoded with constant bitrate and the framerate is high,
we recommend computing Δ𝑡 using 𝑐𝑎𝑐ℎ𝑒𝑑_𝑓 𝑟𝑎𝑚𝑒𝑠 and 𝑓 𝑝𝑠 since
the 𝑏𝑝𝑠 could exhibit large variations. However, if the framerate
is very low, computing based on 𝑐𝑎𝑐ℎ𝑒𝑑_𝑏𝑦𝑡𝑒𝑠 and 𝑏𝑝𝑠 is desired.
Basically, one should look at both the bit-rate and the frame-rate.
This allows us to get a more conservative estimate 10.
Step 2: Double thresholding. The second step is double threshold-
ing, in which we compare the play-time left Δ𝑡 with two thresholds,
𝑇𝑡ℎ1 and 𝑇𝑡ℎ2, where we set 𝑇𝑡ℎ1  𝑇𝑡ℎ2, it means that the cached data on the
client is sufficient, and we can safely turn off re-injection to reduce
cost, so Alg. 1 returns false. The combination of two thresholds
offers flexibility as one can easily tune these thresholds to trade
performance with cost.
Step 3: Comparing with delivery time. When Δ𝑡 is in the range
of [𝑇𝑡ℎ1,𝑇𝑡ℎ2], the buffer occupancy has a medium level, so the
delivery time of in-flight packets plays a role in the decision. We
further compare Δ𝑡 with the estimated maximum delivery time of
in-flight packets 𝑑𝑒𝑙𝑖𝑣𝑒𝑟𝑇𝑖𝑚𝑒𝑚𝑎𝑥. If Δ𝑡 
𝑑𝑒𝑙𝑖𝑣𝑒𝑟𝑇𝑖𝑚𝑒𝑚𝑎𝑥, the in-flight packets will arrive in time, so the
re-injection should be turned off to save cost. 𝑑𝑒𝑙𝑖𝑣𝑒𝑟𝑇𝑖𝑚𝑒𝑚𝑎𝑥 is
calculated as the maximum 𝑅𝑇𝑇 plus its variation 𝛿 of all paths that
have unacknowledged packets, as shown below:
max
𝑑𝑒𝑙𝑖𝑣𝑒𝑟𝑇𝑖𝑚𝑒𝑚𝑎𝑥 =
𝑝∈P ∧ 𝑢𝑛𝑎𝑐𝑘𝑒𝑑_𝑞𝑝 ≠∅{𝑅𝑇𝑇𝑝 + 𝛿𝑝}
(1)
Example. To illustrate how Alg. 1 overcomes HoL blocking with
reduced cost in fast-changing wireless environments, we plot the
dynamics of the client’s buffer level and the amount of re-injected
packets vs, time in one example as shown in Fig. 6. We test vanilla-
MP (Fig. 6b), re-injection without QoE control (Fig. 6c) and re-
injection with QoE control (Fig. 6d) replayed with the same net-
work traces shown in Fig. 6a. We can see that vanilla-MP, whose
buffer level drops to zero several times as Path 1 deteriorates, suf-
fers from severe multi-path HoL blocking and results in frequent
video re-buffering in Fig. 6b. Re-injection is effective in overcoming
multi-path HoL blocking, so when path 1 deteriorates, Fig. 6c and
Fig. 6d can maintain sufficient cached bytes in their buffer. How-
ever, without QoE control, Fig. 6c uses re-injection recklessly as it
re-injects packets even when the buffer level is high, causing un-
necessary, redundant traffic. With the help of QoE control, Fig. 6d
only uses re-injection when the buffer level is low, so it avoids any
unnecessary usage of re-injection when the buffer level is high. As
a result, Fig. 6d is able to ensure the smoothness of the video play
with the least traffic overhead 11.
Performance and cost tradeoffs. The two thresholds 𝑇𝑡ℎ2 and
𝑇𝑡ℎ2 offer flexibility in the trade-off between performance and cost.
For example, a larger 𝑇𝑡ℎ1 provides better tail performance at the
cost of increasing the lower bound of traffic overhead 𝐶𝑚𝑖𝑛. While
𝑇𝑡ℎ2 allows us to control the upper bound of traffic overhead 𝐶𝑚𝑎𝑥
and we have, 𝐶𝑚𝑖𝑛 >= 𝛽 ∗ 𝑃𝑟𝑜𝑏(Δ𝑡  𝑇𝑡ℎ2 then
3
4 if Δ𝑡  maxDeliverTime then
maxDeliverTime ← deliverTime
10
11
12
13 if Δ𝑡  5G NSA > WiFi > LTE 13. We measured the first-frame
delivery time vs. different frame sizes when starting a multi-path
connection from different wireless interfaces in Fig. 7. The mea-
surement was conducted with our 5G SA test-bed and enterprise
Wi-Fi. The influence of primary path selection on first-video-frame
delivery time is significant. Simply starting with the right primary
path can offer a much faster video start-up.
Fastest-path Multi-path ACK. Finally, but importantly, XLINK
utilizes fastest-path Multi-path ACK. Different from MPTCP, whose
ACK is supposed returned on the same sub-flow (original path) [4].
XLINK allows ACK_MP returned from any of the paths, which
gives more flexibility. There are two basic strategies: ACK_MP on
the fastest path (min-RTT path), and ACK_MP on the original path.
In XLINK, we use the fastest path to transmit ACK_MP. We show
the effect of the two ACK path selection strategies with Cubic con-
gestion control in Fig. 8. We measured the request completion time
13The ranking is subject to change in different countries and states. One should
follow local statistics.
SIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Z. Zheng et al.