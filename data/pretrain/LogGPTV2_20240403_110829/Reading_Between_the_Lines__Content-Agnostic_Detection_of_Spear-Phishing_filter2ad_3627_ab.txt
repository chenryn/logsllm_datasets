method needs to be capable of learning a classiﬁcation model, even if only very
few training data is available, such as a couple of emails only.
In view of these requirements, we select the following two learning methods
for our detection approach: (a) a k-nearest-neighbors classiﬁer (kNN) that can
generate good classiﬁcation results with very few training data and (b) a multi-
class support vector machine (SVM) which is known for eﬀectively operating in
high-dimensional vector spaces (see [9]).
76
H. Gascon et al.
Fig. 2. Schematic overview of the detection: a classiﬁer is used to identify emails as
spoofed when a mismatch between the output of the classiﬁer and the origin sender
address occurs.
K-Nearest Neighbors Classiﬁer. The kNN algorithm is a simple yet eﬀective
learning method for classiﬁcation. It computes the distance between a test sample
and all existing samples in a training set and makes a decision through voting on
the labels of its k-nearest samples after applying a weight function (see Fig. 2).
Such instance-based learning algorithms do not construct an explicit learning
model and thus can be applied even if only a single email is available for a sender.
For our approach, we label each feature vector with the address of the originating
sender address. When a new email is received, we compute the distance between
this sample and the feature vectors of all existing emails as follows
d(ex, ey) =
| If (ex) − If (ey)| ,
(cid:3)(cid:3)(cid:3)(cid:3) ϕ(ex) − ϕ(ey)
(cid:3)(cid:3)(cid:3)(cid:3)
1 =
(cid:4)
f∈F
where d corresponds to the Manhattan or L1 distance. A mismatch between the
incoming sender address and the prediction of the classiﬁer is then ﬂagged by
our method as a spooﬁng attempt.
The advantage of making predictions with very few training data, however,
comes at a price. The distance between each new email and all existing emails
needs to be computed before making a decision, which is computationally expen-
sive on large mailboxes. Fortunately, this problem can be addressed in two ways:
First, one can implement the classiﬁer using special data structures for reducing
the number of distance computations, such as ball trees and cover trees [2]. Sec-
ond, if the number of training instances reaches a certain limit, one can simply
switch to another learning method, such as a support vector machine or, when
possible, sample the training data according to a distribution that maintains the
classiﬁer performance.
Multi-class Support Vector Machines. As second learning method, we employ
a linear multi-class SVM algorithm [11]. The algorithm computes a series of
maximum-margin hyperplanes that separate the emails from one sender from
the emails of all other senders (see Fig. 2b). That is, given N diﬀerent senders, N
Content-Agnostic Detection of Spear-Phishing Emails
77
hyperplanes are determined, each one of them represented by a vector w ∈ R
and a scalar b in the vector space.
|F|
If a new email arrives, we simply determine the position to the learned hyper-
planes and pick the sender with the best match, that is, the largest value of
h(e) = (cid:6)ϕ(e), w(cid:7) + b =
If (e) · wf + b.
(cid:4)
f∈F
Note that this function can be computed eﬃciently, if the feature vector ϕ(e) is
sparse, as only non-zero dimensions If (e) contribute to the output. As a result,
we can compute h(e) in linear time in the number of traits |e| extracted from
e and the overall run-time for analyzing an email is O(N|e|). In contrast to the
kNN algorithm, the run-time for the prediction of a linear SVM is independent
of the size of the training set and thus this learning method is suitable if more
emails are available from particular senders (see [11]).
4 Evaluation
We proceed to evaluate our detection method on a large dataset of real-world
emails. In particular, we are interested in studying the ability of our method
to characterize the sender of an email based on its structure and to identify
spoofed emails under diﬀerent levels of knowledge of the adversary. Before pre-
senting these experiments, we ﬁrst introduce our dataset (Sect. 4.1) and deﬁne
the corresponding attacker model (Sect. 4.2).
4.1 Evaluation Data
Total
Basic statistics
Table 1. Statistics of evaluation data.
Mailboxes
Emails
Senders
Features
For our evaluation, we have
gathered anonymized features
extracted from 92 mailboxes
from twelve diﬀerent domains,
including enterprise and com-
mercial email
services. To
evaluate the eﬃcacy of our
detection method, we require
at least one email for learning
and one for testing from each
sender. Consequently, we dis-
card all emails from senders that have sent only a single email. Our ﬁnal dataset
comprises a total of 760,603 emails from 17,381 senders, where each sender has
authored at least two emails. These emails are described by a total of 617,960
features extracted using the traits deﬁned in Sect. 2. Table 1 provides an overview
of the statistics of our evaluation data.
Emails per mailbox
Emails per sender
Senders per mailbox
Features per email
Emails per sender and mailbox
2 8,267 50,924
43 44,204
2
2,144
1
279
69
5
183
2
29 10,304
92
760,603
17,381
617,960
Detailed statistics
Min. Mean Max.
Figure 3 depicts in more detail how emails and senders are distributed within
our dataset. From Fig. 3a and b we can see that over 50% of the mailboxes in
78
H. Gascon et al.
Fig. 3. Overview of the evaluation data: (a) distribution of emails and (b) distribution
of senders in the 92 mailboxes; (c) training data available for learning with varying
emails per sender.
our dataset contain between 103 to 104 emails and between 102 to 103 diﬀerent
senders. This large corpus of emails provides a good basis for evaluating the
performance of our method. Depending on the applied learning model, however,
we require a minimum number of emails per sender and thus not all senders
might be available for training. Figure 3c shows the amount of training data
available to a learning method depending on the minimum number of emails per
sender. While for the kNN classiﬁer all senders can be used for evaluation, in
the case of the SVM classiﬁer, we need to restrict our experiments to 46% of the
data, as we require at least 5 emails for training.
To prepare our experiments, we extract feature vectors from all emails in
our evaluation data. This may seem as an intractable task at ﬁrst glance, as
the resulting vector space has over 600,000 dimensions. However, the majority
of these dimensions is zero and each email contains only between 5 to 183 fea-
tures (see Table 1). As a result, we can make use of eﬃcient data structures for
operating with these sparse feature vectors (see [31]).
As a sanity check whether our representation is suitable for learning a clas-
siﬁcation, we ﬁrst study how senders in a mailbox diﬀer from each other and
then analyze how emails from a speciﬁc sender change over time. To this end,
we ﬁrst calculate a simple statistic: For each sender, we compute the average
of its feature vectors and measure the distances between the resulting 17,381
mean vectors within each mailbox. We make use of the Manhattan distance (L1
distance) for comparing the mean vectors. The distance can be interpreted as
the average number of features diﬀering between the senders and thus provides
an estimate for the quality of extracted traits.
Figure 4 shows the distribution of the Manhattan distances between all
senders in each mailbox. It can be observed that most senders are separated
from each other by a distance larger than 40 on average. This demonstrates that
several of the extracted traits are highly speciﬁc and capture nuances of the
email structure suitable for discriminating the senders. Multiple sources may
introduce variability and noise into the email traits of a sender, such as software
updates, network conﬁgurations and changing devices. We thus study how emails
from an individual sender change over time. In particular, we want to answer
Content-Agnostic Detection of Spear-Phishing Emails
79
Fig. 4. Distance between senders
Fig. 5. Feature drift over time
the question how many features change in a new email when it is compared
with existing emails from the same sender. For this, we measure the Manhattan
distance between each email received at a certain point in time in a mailbox
and all emails previously received from the same sender. The average number of
diﬀering features is then presented as a percentage of the feature space dimen-
sionality. Figure 5 shows that a slight feature drift exits. It can be observed
how the variability grows rapidly at ﬁrst with the initial emails received from
a sender. However, when an increasing number of emails is received each class
becomes more compact and the average percentage of diﬀerent features in a new
email decreases. Note that although proﬁles become more stable during time,
they also tend to diﬀer considerably as shown in Fig. 4.
As the ﬁnal preparation step, we determine the presence of anti-spooﬁng
techniques in the 760,603 emails using corresponding email client and transport
features. Table 2 shows the percentage of emails in our dataset that contain
anti-spooﬁng techniques, where we additionally report statistics from the top
million web domains listed at the monitoring service BuiltWith [3]. Although the
adoption of SPF [24] has reached almost 40% by now, the overall implementation
of anti-spooﬁng techniques is still low in both data sources. In particular, recent
techniques, such as DKIM [7] and DMARC [25] are used in less than 5% of the
emails, thereby emphasizing the need for alternative protection measures.
4.2 Attacker Model
In the absence of anti-spooﬁng tech-
niques, a skilled adversary is able to
forge most of the data contained in
an email. However, we argue that,
by inferring a sender proﬁle based
on traits of the email structure, an
attacker is forced to mimic such pro-
ﬁle to eﬀectively masquerade as the
Table 2. Anti-spooﬁng techniques in our
evaluation data and as reported by the
monitoring service BuiltWith.
Anti-spooﬁng technique Our data Top 1M [3]
SPF
DKIM
DMARC
PGP, S/MIME
—
4.3%
—
0.88%
39.9%
0.1%
1.3%
—
80
H. Gascon et al.
sender. As a consequence, the success of such spooﬁng depends on how much
information of the email structure is available to the adversary and if the attacker
has access to the senders delivery infrastructure.
Therefore, we begin the evaluation of our approach by measuring in a con-
trolled experiment how an attacker may aﬀect the detection performance by
spooﬁng an increasing number of features from a sender’s proﬁle (i.e. all fea-
tures extracted from all emails received from a speciﬁc sender in a mailbox). To
this end, we ﬁrst split each sender’s data in a mailbox into training and testing
sets and then train both kNN and SVM classiﬁers. For testing, we select random
emails from other mailboxes and relabel them as known senders of the target
mailbox to imitate spooﬁng attempts. This means that our testing set is com-
prised of 50% of legitimate emails and 50% of spoofed emails with a random
percentage of correct traits of the target sender.
Note that to generate spoofed emails we do not rely on their textual content
for feature extraction. Moreover, we adapt the transport features added by the
recipient MTA to the recipient mailbox. As a result, the spoofed emails in our
testing set are not diﬀerent from real spear-phishing emails sent by an attacker,
as no textual content is considered.
We measure the detection performance of our classiﬁers using the true-
positive rate (TPR) and false-positive rate (FPR). In our setup, a true positive
implies that a spoofed email has been correctly identiﬁed, while a false positive
corresponds to a legitimate email wrongly being tagged as spoofed. Furthermore,
we use a Receiver Operating Characteristic (ROC) curve to present both evalua-
tion metrics and calculate the area under the ROC curve (AUC) as a numerical
aggregate of the classiﬁcation performance (see [12]). Although an adversary
with increasing capacity will aﬀect the ability of the classiﬁer to correctly iden-
tify deviations from a user proﬁle, the information available to an attacker is
constrained by threat scenarios that can occur in reality. In this work, we thus
assume that the knowledge of an attacker can range from knowing nothing about
the spoofed sender to having real examples of her emails.
Fig. 6. Threat scenarios for increasing attacker capabilities based on the acquired
knowledge about the spoofed sender: (a) the attacker has no information about the
sender, (b) the attacker has access to emails received from the sender’s domain and,
(c) the attacker has access to one or more emails from the real sender.
Content-Agnostic Detection of Spear-Phishing Emails
81
Accordingly, we model these attackers through a series of increasing adver-
sarial setups and proceed to evaluate the performance of our approach in each
scenario as depicted in Fig. 6:
(a) Blind Spooﬁng: In this scenario, the attacker (Mallory in Fig. 6) tries to
spoof a particular sender from which she does not have any information.
The only available strategy for the attacker is to simply replace the From and
Return-Path headers of the targeted email and try to guess the behavior,
composition and transport features.
(b) Known Domain: In this scenario, the attacker has received or has access to
one or more emails sent by a sender that belongs to the same email domain as
the spoofed sender. The attacker can thus expect that some of their transport
features are present in the emails received by the victim from the sender she
wants to spoof.
(c) Known Sender: In this scenario, shown in Fig. 6c, the attacker has received
or has access to one or more emails sent by the spoofed sender. As a result,
several traits used for constructing the proﬁle are available to the attackeri
and can be incorporated in her spoofed emails.
In the following, we describe how we learn a proﬁle of each sender within a
mailbox and assign the role of the victim to the owner of the mailbox. Then,
based on the attack strategies described in each scenario and using the emails
available in our dataset we build corresponding sets of spoofed emails for each
sender and combine them with legitimate emails to evaluate our method.
4.3 Spoofed Email Detection
In the following we evaluate the performance of our approach in the threat
scenarios deﬁned in the previous section. In order to learn a proﬁle for each
sender we begin again by splitting all available emails into training and testing
sets. For training, we consider all emails received up to a certain point in time. In
the case of the kNN classiﬁer one email from a sender in the training set suﬃces
to make a decision about an incoming email from this origin address, while for
the SVM classiﬁer we require a minimum of 5 emails from a sender to include
this class during training. In order to tune the parameters of each classiﬁer, we
partition the training data into 5 splits and use training/validation partitions,
such that the temporal order of emails is preserved—similar to a regular cross-
validation. This enables us to simulate training with past data and generating
predictions for data yet unseen. Note that although a mailbox or sender may not
present enough emails for training, we still use these samples to generate test
spoofed emails.
For the testing phase, we combine the test set of legitimate emails with a
set of emails crafted according to the attacker strategies described in Sect. 4.2.
In the case of a blind spooﬁng attack, we select a random set of emails sent to
recipients at diﬀerent domains than the victim and label them as the spoofed
sender. Likewise, we evaluate the known domain attack by selecting emails sent
82
H. Gascon et al.
Table 3. Detection performance of our approach in diﬀerent threat scenarios.
Threat
scenario
Blind spooﬁng