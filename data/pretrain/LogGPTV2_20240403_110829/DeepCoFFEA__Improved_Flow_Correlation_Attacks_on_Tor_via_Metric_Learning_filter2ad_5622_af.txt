### Performance and Transferability of DeepCoFFEA

- **Reduction in False Positives (FPs):** DeepCoFFEA significantly reduces the number of false positives (Figure 8a and 8b) through the use of amplification. This results in substantial performance improvements over DeepCorr and m-DeepCorr, with a notable 80% increase in True Positive Rate (TPR) (93% vs. 13%) at a False Positive Rate (FPR) of \(2 \times 10^{-4}\).

- **Transferability:** DeepCoFFEA demonstrates transferability across different circuits, sites, and time scales up to 14 months (Figure 7c). This suggests that annual retraining would be sufficient to maintain its performance. In contrast, DeepCorr showed a significant decline in performance with a 14-month gap between training and testing (Figure 9a).

- **Detection of Protected Flows:** DeepCoFFEA effectively detected many protected flows by obfs4, WTF-PAD, and FRONT defenses, achieving detection rates of 95%, 90%, and 84% respectively for an FPR of \(10^{-3}\) (Figure 7d). This is in stark contrast to DeepCorr, which degraded significantly against all defenses (Figure 9b). Additionally, DeepCoFFEA can conduct flow correlation analysis for both undefended and defended traces without the need for separate models (Figure 7e).

### Countermeasures

In this section, we discuss potential countermeasures to thwart DeepCoFFEA-style attacks. DeepCoFFEA learns the difference between correlated and uncorrelated flows rather than directly learning correlated features based on predefined labels. This allows it to better distinguish between obfuscated, correlated, and uncorrelated flows, even if the Tor flows are further perturbed. Figure 7d shows that FRONT was able to hinder DeepCoFFEA to some degree, with a 15% TPR drop at \(10^{-3}\) FPR. However, this reduction is insufficient, indicating the need for more effective defenses.

Given the performance gap between DeepCoFFEA and DeepCorr against all tested defenses, we speculate that the key property making DeepCoFFEA difficult to defend against is its use of amplification, which filters out incorrect correlations from a subset of windows. Random noise generally does not create enough false correlations across enough windows among mismatched flow pairs to confuse the attacker. Therefore, we explored additional settings in FRONT to more effectively undermine DeepCoFFEA:

- **Increased Padding Window:** We increased the padding window with \(W_{\text{max}} = 25\) to increase the chances of padding the entire 25-second flow.
- **Decreased Padding Window:** We decreased the padding window with \(W_{\text{max}} = 10\) to increase the chances of injecting dummy packets in earlier windows.
- **Increased Padding Data Budget:** We raised the padding data budget for both tests (\(N_s, N_c = 2, 500\)) compared to Figure 7d.

As shown in Figure 10, the number of true positives decreased when obfuscation was forced into the first several windows, indicating that window-level obfuscation could be more effective in weakening the amplification ability.

### New Defense Strategy: Decaf

We further explored a new defense strategy called Decaf to more effectively disrupt the window pattern. For each Tor flow \(t_i\), we randomly selected a peer flow from the DCF set. After dividing the peer flow into non-overlapping windows of \(\omega\) seconds, we randomly picked \(v\) windows among the total \(k\) windows (where \(v\) and \(k\) are tunable parameters). We then extracted the timestamps \(T_{\text{pad}}\) in the chosen \(v\) windows and injected dummy packets at these timestamps for each \(t_i\). This approach forces the defender to ruin the window pattern while making each Tor flow less distinct by adding timing information from peer flows. Figure 10 shows the result of applying this approach (Decaf-DCF) with \(\omega = 5\) seconds and \(k = 0.5\), achieving a bandwidth overhead of 49.6% and performing much more effectively than any setting of FRONT. This suggests that a defense specifically focused on perturbing a significant fraction of windows could overcome the amplification feature of DeepCoFFEA.

### Conclusion and Future Work

End-to-end correlation can break the unlinkability property of an anonymity system, enabling attackers to match users with the servers they connect to. In this work, we introduced DeepCoFFEA, which is more scalable and practically effective than state-of-the-art attacks. By adapting the triplet network architecture as a feature extractor, DeepCoFFEA enables full pairwise comparisons at a cost that is linear rather than quadratic with the number of flows. Further, by splitting flows into a small number of windows and extracting features for each window, DeepCoFFEA creates multiple semi-independent correlation tests that can be combined to amplify differences between matched and unmatched pairs, thereby lowering the false positive rate.

Our evaluation demonstrated that this new architecture and attack paradigm greatly improves state-of-the-art flow correlation attacks while reducing time complexity by two orders of magnitude. Future research should explore more realistic Tor traffic, investigate more sophisticated DNN architectures, and develop effective defenses against DNN-based traffic analysis attacks.

### Acknowledgments

We thank our anonymous reviewers for their helpful suggestions and comments. We also thank Milad Nasr for sharing the code of Compressive Traffic Analysis and the DeepCorr set, and Erik Lindeman for assistance with the data collection method. This work was funded by the National Science Foundation under Grants nos. 1816851, 1433736, and 1815757, and the Ewha Womans University Research Grant of 2022.

### References

[1] A. Mani, T. Wilson-Brown, R. Jansen, A. Johnson, and M. Sherr, “Understanding tor usage with privacy-preserving measurement,” in ACM Internet Measurement Conference (IMC), 2018, pp. 175–187.
[2] T. Wang and I. Goldberg, “Improved website fingerprinting on tor,” in ACM workshop on Workshop on privacy in the electronic society (WPES), 2013, pp. 201–212.
...
[51] S. Lawrence, C. L. Giles, A. C. Tsoi, and A. D. Back, “Face recognition: A convolutional neural-network approach,” IEEE Transactions on Neural Networks, vol. 8, no. 1, pp. 98–113, 1997.