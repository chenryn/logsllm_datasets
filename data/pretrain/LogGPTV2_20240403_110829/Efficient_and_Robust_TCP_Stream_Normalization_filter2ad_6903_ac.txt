number of the ACK. If such a segment exists, RoboNorm
rewrites the sequence number of the ACK and shifts it up-
wards to the starting sequence number of the expected (cid:2)t-
ting segment (i.e., the end of the partially overlapping seg-
ment), as shown in Figure 4(iii). We refer to this mechanism
as ACK promotion. As we can see from the (cid:2)gure, ACK pro-
motion enables RoboNorm to check the consistency of the
partially overlapping segment without stalling connections.
This situation might seem a bit precarious, as it requires
RoboNorm to generate an ACK for data that has not in fact
reached the receiver yet, playing fast-and-loose with TCP’s
end-to-end and fate-sharing semantics. However, given that
the connection may simply stall and keep retransmitting
the same segment (which will not be forwarded since each
time there still isn’t enough information to check for con-
sistency), this step is required. Although RoboNorm must
now (cid:147)take responsibility(cid:148) for the delivery of this segment
to the receiver, doing so does not require RoboNorm to
implement any portion of the TCP state machine or any
additional timers. As long as ACKs come in from the re-
ceiver, RoboNorm can promote them, and as long as ACKs
reach the TCP sender, the sender will transmit additional
segments (e.g., a segment starting at the (cid:2)rst unacknowl-
edged byte) to make a set of (cid:2)tting segments. Once the
(cid:2)tting segments have all arrived, RoboNorm will forward
all of the held data, since it can now verify consistency
with the corresponding original segment. This approach al-
ways guarantees forward progress, and requires no addi-
tional mechanisms in RoboNorm other than the ability to
rewrite ACKs to promote them. Under the assumption that
RoboNorm sees all packets of both directions of a connec-
tion, the packet processing algorithms ensure that a connec-
tion never stalls inde(cid:2)nitely due to a pending consistency
101
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:31 UTC from IEEE Xplore.  Restrictions apply. 
procedure HANDLEDATA(dataSgmt)
tuple   GETCONNECTIONTUPLE(dataSgmt)
hashList   FETCHHASHLIST(tuple)
if (hashList = NULL)
hashList   INITHASHLIST(tuple)
SegList   SPLIT(dataSgmt)
// Split at boundaries of previous segments
for each sgmt 2 SegList do
if (sgmt is new segment)
HANDLENEWSEGMENT(sgmt)
else if (sgmt completely overlaps some segHash)
HANDLEEXACTOVERLAP(sgmt; segHash)
// sgmt partially overlaps some segHash
HANDLEPARTIALOVERLAP(sgmt; segHash)
else
procedure HANDLENEWSEGMENT(sgmt)
hashList   hashList [ SEGMENTHASH(sgmt)
FORWARD(sgmt)
procedure HANDLEEXACTOVERLAP(sgmt; segHash)
if (SEGMENTHASH(sgmt) = segHash)
FORWARD(sgmt)
else Flag inconsistent retransmission
procedure HANDLEPARTIALOVERLAP(sgmt; segHash)
BufSegs   fsgmtg [ BUFFEREDSEGMENTS(segHash)
if (FITTINGSEGMENTS(BufSegs) = True)
concat   CONCATENATE(BufSegs)
HANDLEEXACTOVERLAP(concat; segHash)
Keep segments for which ACK promoted
Clear rest of the (cid:2)tting segments from buffer
procedure HANDLEACK(Ack)
if (Ack not a segment hash boundary)
DEMOTEACK()
TRIMHASHLIST(Ack)
if (Buffered segments starting at Ack)
Ack   Start of next (cid:2)tting segment
Mark buffered segments as ACK promoted
FORWARD(Ack)
// Promote
times we observe the following sequence: an original seg-
ment S = [s; e); a partial overlap [s; e0), where e0 < e;
an ACK for e0; followed at some later point in time by a
segment starting with e0. That is, the retransmitted segment
[s; e0) and its successor that started at e0 were (cid:147)split(cid:148) in the
trace by an ACK e0. The intuition here is that the ACK e0
was in fact necessary to elicit the segment starting at e0. In
such a case, holding the segment [s; e0) in a buffer without
forwarding it could have prevented the ACK e0 from arriv-
ing at all; ergo, if we don’t promote ACKs, in this case the
connection could stall.
Table 2 shows that about 20(cid:150)50% of (cid:2)tting segment pairs
are split by an ACK between them (row 4), and that about
0.01% of all connections have such (cid:2)tting segments (row
5), across all traces. These (cid:2)gures are low, but certainly not
negligible: for sites that see millions of connections per day
(as do all of the sites in our study), such a rate would result
in 100s to 1000s of broken connections each day without
the ACK promotion mechanism.
ACK not on segment hash boundary. While ACKs not
on an existing segment hash boundary might strike us as
highly peculiar (just what drove the receiver to select the
particular sequence number to acknowledge?), our traces
show that these do occur occasionally in real traf(cid:2)c (rows
6 and 7 of Table 2). In this case, RoboNorm (cid:2)rst demotes
the ACK to the segment hash boundary closest to and be-
low its sequence number, after which it handles it like a
normal ACK on a segment hash boundary. To see why
we must demote such ACKs, observe that if we forwarded
such an ACK to the TCP sender without demotion, its ar-
rival may trigger a partially overlapping segment starting
at the sequence number of the ACK. Moreover, the (cid:2)tting
segments of this triggered, partially overlapping segment
would belong to the sequence space that has already been
acknowledged by the forwarded ACK and hence will never
be retransmitted. Thus, demoting ACKs avoids accumulat-
ing partially overlapping segments whose consistency can
never be veri(cid:2)ed by RoboNorm.
The complete pseudocode of RoboNorm’s operations is
given in Figure 5.
Figure 5. RoboNorm’s algorithms.
4. Memory Savings With RoboNorm
check of retransmitted segments.
From our traces we can estimate how often such ACK
promotion is required in practice. Because the traces were
collected without a normalizer in the forwarding path, it is
impossible to tell for sure what would have happened had
there been a normalizer that did not forward partial over-
laps. Instead, we use a heuristic: we compute the number of
In this section, we compute the amount of memory a
typical RoboNorm deployment would consume. Under the
assumption that RoboNorm stores an 8-byte hash of con-
tents for each unacknowledged TCP segment,5 each entry
of the segment hash list(cid:151)composed of the hash itself, a se-
quence number range, and a 3-byte pointer to the next seg-
5We argue in x6.4 that an 8-byte hash provides acceptable security guar-
antees.
102
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:31 UTC from IEEE Xplore.  Restrictions apply. 
# Provisioning the connection table
1
Peak concurrent connections
2 Avg. concurrent connections
Provisioning the retransmission buffer
3 Avg. concurrent bytes per connection
4
Peak total concurrent bytes
Univ1
10,647
7,616
Univ2
33,932
23,686
Lab1
4,010
3,098
Lab2
1,927
1,556
Super
295
203
639
13,213
579
116,937
665
87,118
594
12,411
566
2,256
Table 3. Measurements used to provision RoboNorm.
ment hash in the list(cid:151)can all be made to (cid:2)t in 15 bytes (Ap-
pendix B). Each connection table entry, consisting of a con-
nection tuple and pointers into the hash store and retrans-
mission buffer, consumes around 48 bytes (Appendix C).
With these estimates, we (cid:2)nd that RoboNorm deployed on
a Gbps access link of a typical network needs to be provi-
sioned with as little as 2.5 MB of on-chip memory, while
a normalizer that buffers all unacknowledged data would
need 10 times as much (x4.1). Given the high cost of fast
on-chip memory, this memory gain is signi(cid:2)cant. More-
over, the actual memory that would have been consumed
(had RoboNorm been deployed at the sites we collected the
traces from) was found to be much smaller than the provi-
sioned amount in most cases, and up to two orders of magni-
tude smaller than the actual memory consumed by the full-
content normalizer (x4.2).
4.1. Savings in Provisioning
Hash Store. Each new segment hash in RoboNorm occu-
pies space in the hash store and remains there until cleared
by an ACK. Suppose segments arrive at a rate of (cid:21) per sec-
ond, and that the average time before clearing is (cid:14) seconds
across all connections. Then, by Little’s Law, on average
the system has to store (cid:21)(cid:14) segment hashes in it. In general,
(cid:14) is roughly equal to the average connection round-trip time
(RTT),6 and (cid:21) is roughly equal to C=s, where C is the rate
of traf(cid:2)c entering the system in bytes per second, and s is
the average packet size in bytes. Thus, the number of seg-
ment hashes in the system at any time is roughly (cid:14)C=s.
To estimate an upper bound on (cid:14), we compute the largest
segment clearing time observed during the lifetime of a con-
nection for every connection in our traces, and compute
the mean of this value across all connections in all traces.
We found this value to be around 150 ms. We also found
that the average non-empty segment is at least 1 KB across
all traces. So, picking (cid:14) = 200 ms and s = 1 KB gives
us a bound of 25,000 hashes when provisioning for these
6Actually, (cid:14) is less than the average connection RTT, since what matters
is the time that elapses between the monitor seeing a data packet and then
seeing the corresponding ACK. In the absence of loss, this will be less than
RTT; possibly a great deal, if the monitor is near the receiver.
C = 1 Gbit/s links. This translates to 375 KB of memory,
assuming 15 bytes per segment hash. On the other hand,
the full-content normalizer would require (cid:14)C = 25 MB of
memory to buffer all unacknowledged data.
Connection Table. We need to size the connection ta-
ble according to the maximum number of concurrent (es-
tablished) connections expected. Row 1 of Table 3 shows
that the maximum value we (cid:2)nd in our traces is about
34,000 connections. The next row of the table also gives
the average value, which runs about 1/3 lower. Assuming
each connection table slot consumes 48 bytes, and we use
a hash table with 80% bucket utilization, we can accom-
modate 34,000 concurrent connections in about 2 MB. It is
reasonable to assume that the full-content normalizer would
also need comparable amounts of memory to store per-
connection state.
Retransmission Buffer. Table 3 (rows 3 and 4) gives
two different sets of statistics regarding the amount of
buffer needed to hold partially overlapping retransmitted
segments (cf. the (cid:147)Hold(cid:148) elements in Figure 4). Row 3 lists
the average buffer space required for each connection that
includes at least one such held retransmission. Row 4 lists
the aggregate peak buffer space required for such held re-
transmissions across all connections. We see that a few
10 KBs suf(cid:2)ce across all of our datasets, a number small
enough that we ignore it for our subsequent comparisons.
In summary, we (cid:2)nd that RoboNorm requires about
2.5 MB of memory on our 1 Gbit/s links, while the full-
content normalizer requires about 27 MB, giving us a sig-
ni(cid:2)cant provisioning gain of a factor of 10 between the two
designs.
4.2. Savings in Observed Memory Consumption
The actual memory consumed by a normalizer in real de-
ployments will of course vary compared to the provisioned
amount. We now estimate the actual memory consumption
for each trace, as shown in Table 4. We consider both direc-
tions of every connection. Row 1 of the table gives the max-
imum number of concurrent hashes (that RoboNorm would
103
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:11:31 UTC from IEEE Xplore.  Restrictions apply. 
Peak concurrent hashes
Peak concurrent bytes when holding full data
Peak total memory by RoboNorm
Peak total memory by full-content norm.
# Memory consumed in practice
1
2
3
4
Factor of memory savings in practice
5
6
Savings in total memory
Savings in unacknowledged data
Univ2
9,000
Lab1
2,124
Lab2
1,469
Univ1
18,417
Super
2,118
16,417 KB 5,236 KB 2,709 KB 1,836 KB 3,029 KB
46 KB
16,928 KB 6,865 KB 2,901 KB 1,928 KB 3,043 KB
787 KB 1,764 KB
224 KB
115 KB
21.5
59.4
3.9
38.8
13
85.0
16.8
83.3
66.3
95.3
Table 4. Memory savings of RoboNorm compared to the full-content normalizer.
have had to store if deployed) and row 2 gives the maxi-
mum number of concurrent bytes buffered by the system
(had we deployed a normalizer that buffered all unacknowl-
edged bytes) across all traces. We can then approximate the
actual peak memory consumption of the trace as the mem-
ory required to store the peak number of concurrent con-
nections and the peak number of concurrent bytes or hashes
in the trace, as the case may be. Rows 3 and 4 of the table
show the total maximum memory consumed by RoboNorm
and the full-content normalizer respectively.
Row 5 of the table computes the ratio of the total mem-
ory consumed by the full-content normalizer to that con-
sumed by RoboNorm. We (cid:2)nd that the memory savings are
considerable in practice too, generally 1(cid:150)2 orders of mag-
nitude. Note that these values include the connection table,
which for our scheme heavily dominates total memory con-
sumption (but not for the full-content normalizer). If we ex-
clude the connection table, the savings are about two orders
of magnitude (row 6). Thus any technique that compresses
the per-connection hash table (e.g., connection compres-
sors [11]) will improve the relative gain of RoboNorm over
the full-content normalizer.
5. Implementation Options
Realizing a prototype of RoboNorm that can process
packets at line speed on Gbps (or faster) links requires an
implementation that uses memory frugally, and performs
only a small amount of per-packet processing (in terms of
computation and memory accesses). We now argue that the
design of RoboNorm lends itself to such an implementation.
RoboNorm deployed on our Gbps links requires around
2.5 MB of memory (x4), an amount that can readily (cid:2)t on-
chip. The common case packet-processing in RoboNorm in-
volves (a) looking up a hash table and (b) manipulating the
hash lists, either by adding new segment hashes at the end of
the list (when new data arrives) or clearing hashes from the
beginning of the list (on an ACK). Both these operations
can be performed ef(cid:2)ciently in hardware: much work has
been done on how to perform hardware hash table lookups
ef(cid:2)ciently [12], and we can make the common-case hash
list operations inexpensive by maintaining pointers to the
start and end of each hash list. Thus, per-packet process-
ing in RoboNorm would involve only a few accesses to
on-chip memory in the common case. Retransmitted seg-
ments, however, may require traversing the segment hash
list to compare hashes, or more complex operations involv-
ing partially overlapping segments. But because retransmis-
sions form around 0.5% of all packets (row 4 of Table 1),
we can handle such operations on a slow path or in software
without introducing perceptible delays in packet process-
ing.