Evading next-gen AV using A.I.
Hyrum Anderson
PI:EMAIL
@drhyrum
/in/hyrumanderson
https://github.com/endgameinc/gym-malware
Rules for static analysis
x1
rule malware {
strings:
$reg = “\\CurrentVersion\\Internet Settings”
condition:
filesize  3  } 
filesize
count(-registry-prefix)
Next-gen AV using machine learning
f("size,"#reg )
filesize
count(-registry-prefix)
Automated
Sophisticated 
relationships
Generalizes
Can We Break Machine Learning?
§
Static machine learning model trained on millions of samples
x1
Machine Learning 
Model
score=0.95 
(malicious, moderate confidence)
•
Simple structural changes that don’t change behavior
Machine(Learning(
Model
score=0.49 
(benign, just barely)
•
upx_unpack
•
‘.text’ -> ‘.foo’ (remains valid entry point)
•
create ‘.text’ and populate with ‘.text from calc.exe’
+
modified 
elements 
of PE file
Yes! For deep learning and images…
• Machine learning models have blind spots / hallucinate (modeling error)
• Depending on model and level of access, they can be straightforward to exploit 
• Adversarial examples can generalize across models / model types (Goodfellow 2015)
•
blind spots in MY model may also be blind spots in YOUR model
(scaled(for(visibility)
image(credit:(http://www.popsci.com/byzantine-science-deceiving-artificial-intelligence
What about for PE malware?
+
= image
Bus (99%), Ostrich (1%) 
BUT…
+
!=
modified 
bytes or
features
break PE format
destroy function
Malware (90%), Benign (10%)
Attacker requires full knowledge of *deep learning* model 
Generated sample may not be valid PE file
Related Work: PDF attack / report score
Genetic algorithm
Functional
Broken
Black Box AV
(produces score)
Oracle
Requires score from black box model
Oracle/sandbox [expensive]
EvadeML [for PDF malware] 
(Xu, Qi, Evans, 2016)
Summary of Previous Works
Gradient-based attacks: perturbation or GAN
• Attacker requires full knowledge of model structure and weights
• Generated sample may not be valid PE file
Genetic Algorithms
• Attacker requires score from black box model
• Requires oracle/sandbox [expensive] to ensure that functionality is preserved
Goal: Design a machine learning agent that
•
bypass black-box machine learning using
•
format- and function-preserving mutations 
•
hardest attack to pull off; difficult to learn
Reinforcement Learning!
Atari Breakout
Nolan Bushnell, Steve Wozniak, Steve Bristow
Inspired by Atari Pong
"A lot of features of the Apple II went in 
because I had designed Breakout for Atari” 
(The Woz)
Game
• Bouncing ball + rows of bricks
• Manipulate paddle (left, right)
• Reward for eliminating each brick
Atari Breakout: an AI
• Environment
• Bouncing ball + rows of bricks
• Manipulate paddle (left, right, nothing)
• Reward for eliminating each brick
• Agent
• Input: environment state (pixels)
• Output: action (left, right) via policy
• Feedback: delayed reward (score)
• Agent learns through 1000s of games: 
what action is most useful given a 
screenshot of the Atari gameplay? 
https://gym.openai.com/envs/Breakout-v0
Learning: rewards and credit assignment
+0
+0
+0
+0
+0
(breaks(
brick)
+1
+---------------+---------------+---------------+--------------+----------------+
Anti-malware evasion: an AI
• Environment
• A malware sample (Windows PE)
• Buffet of malware mutations 
• preserve format & functionality
• Reward from static malware classifier
• Agent
• Input: environment state (malware bytes)
• Output: action (stochastic)
• Feedback: reward (AV reports benign)
https://github.com/endgameinc/gym-malware
https://github.com/endgameinc/gym-malware
The Agent’s State Observation
Features
• Static Windows PE file features 
compressed to 2350 dimensions
• General file information (size)
• Header info
• Section characteristics
• Imported/exported functions
• Strings
• File byte and entropy histograms
• Feed a neural network to choose 
the best action for the given 
“state”
The Agent’s Manipulation Arsenal
Functionality-preserving mutations:
• Create
• New Entry Point (w/ trampoline)
• New Sections
• Add
• Random Imports
• Random bytes to PE overlay
• Bytes to end of section
• Modify
• Random sections to common name
• (break) signature
• Debug info
• UPX pack / unpack
• Header checksum
• Signature
The Machine Learning Model
Static PE malware classifier
• gradient boosted decision tree (for which 
one can’t directly do gradient-based attack)
• need not be known to the attacker
Machine learning malware model for demo purposes only.  Resemblance to Endgame or other vendor models is incidental.
Ready,"Fight!
Evasion Results
• Agent training: 15 hours for 100K trials (~10K games x 10 turns ea.)
• Using malware samples from VirusShare
Cross-evasion: detection(
rate(on(VirusTotal (average)
• from(35/62((original)(
• to(25/62((evade)
0% 
2% 
4% 
6% 
8% 10% 12% 14% 16% 18% 
random(mutations
black(box
Evasion-rate-on-200-holdout-samples
Summary
• Gym-malware: https://github.com/endgameinc/gym-malware
• No knowledge of target model needed
• Manipulates raw binaries: no malware source / disassembly needed
• Produces variants that preserve format and function of original
• Make it better!
• Machine learning models quite effective, even under attack
• All machine learning models have blind spots
Thank(you!
Hyrum Anderson
Technical Director of Data Science
PI:EMAIL
@drhyrum
/in/hyrumanderson
Co-contributors:
Anant Kharkar, University of Virginia
Bobby Filar, Endgame
Phil Roth, Endgame