particular, the AUCs for Huawei watch 2 and LG Urbane W150 are
94.5% and 88.9% under the two poses. The vertical position shows
slightly higher AUCs as it has the largest impact angles between
acoustic waves and smartwatches‚Äô screens. Given an FPR of 5%,
WearID can achieve high TPRs of 95.2% and 98.5% for Huawei
watch 2 held in both positions. The results indicate that WearID is
effective in defending against random attacks.
Against Impersonation and Replay/Synthesis Attack. Next,
we evaluate WearID under more sophisticated impersonation and
replay/synthesis attacks which reproduce a user‚Äôs voice character-
istics on the VA device. In this case, the wearable is attached to
the absent user and out of the adversary‚Äôs control, and it seldom
happens when the two separated devices (i.e., VA device and the
smartwatch) receive the exact same speech. However, the smart-
watch may still record the user‚Äôs speeches but with other content.
For evaluation, we alternatively set each participant as the legiti-
mate user. We use each legitimate user‚Äôs critical voice command
recorded by two smartwatches against other 19 audio recordings.
To simulate legitimate use of critical voice commands, we use the
legitimate user‚Äôs vibration data of each command against the corre-
sponding audio data. Figure 11 and Figure 12 show the ROC curves
(i.e., black curves) when authenticating the user under imperson-
ation/replay attacks. We find that WearID successfully reject the
adversaries by using both Huawei watch 2 and LG Urbane W150
under both horizontal and vertical poses. In particular, WearID
achieves 89.1% and 86.8% for Huawei Watch 2 and LG Urbane
W150 under horizontal position. The AUCs are 91.23% and 88.34%
under vertical pose. For a FPR of 10%, WearID can obtain the TPRs
of 91.2% and 93.3% when Huawei watch 2 is held in horizontal
and vertical directions. We find the performance of WearID under
impersonation/replay attacks are slightly lower than that under
random attacks. This is because the adversary has obtained the
user‚Äôs voice samples to improve the attack. While in the practi-
cal scenarios, a legitimate user‚Äôs wearable device does not usually
record the user‚Äôs speeches, which make the performance of WearID
approaching to that under the normal situation.
7.4 User Authentication under Co-location
Attack
Against Hidden Voice Command. To evaluated WearID under
hidden voice command attacks, we compare the vibration data and
the audio data for each of the 100 recorded hidden commands. In
addition, we alternatively set each of the 10 participants as the
legitimate user and compare the vibration and the audio data of
each critical voice command. Figure 14 depicts the CDFs of the
cross-domain similarities of the hidden commands recorded by
00.20.40.60.81False positive rate00.20.40.60.81True positive rateNormal SituationRandom AttackReplay Attack00.20.40.60.81False positive rate00.20.40.60.81True positive rateNormal SituationRandom AttackReplay Attack00.20.40.60.81False positive rate00.20.40.60.81True positive rateNormal SituationRandom AttackReplay Attack00.20.40.60.81False positive rate00.20.40.60.81True positive rateNormal SituationRandom AttackReplay AttackWearID
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
(a) Microphone
(b) Huawei watch 2
(c) LG Urban W150
Figure 13: The frequency responses of the VA system and the wearables (i.e., microphone, Huawei watch 2, LG Urban W150
from left to right) under ultrasound attacks.
(a) Huawei watch 2
(b) LG Urban W150
(a) Nexus6 vs. iPhone7
(b) Nexus6 vs. Laptop
Figure 14: CDF of the cross-domain 2D correlations to distin-
guish the hidden voice commands and the legitimate user‚Äôs
voice commands.
Figure 15: Normalized 2D cross-correlation between spectro-
gram of different recording devices .
the VA device and the legitimate user‚Äôs critical voice command
captured by the smartwatches‚Äô accelerometers. We observe that
the similarities between the two sensor readings are low for the
hidden voice commands, which can be differentiated well from the
legitimate user‚Äôs critical commands. In particular, the median of the
cross-domain similarities for the hidden voice commands is around
0 for Huawei watch 2 and 0.05 for LG Urban W150. In comparison,
the median similarities for the legitimate user‚Äôs voice commands
are around 0.5 for Huawei watch 2 and 0.4 for LG Urban W150. This
is because the accelerometers on the wearables have short response
distances (i.e., less than 25ùëêùëö) and unique frequency selectivity
patterns to sound. Thus, with our cross-domain user authentication
approach, the hidden voice attacks can be defended.
Against Ultrasound Attack. Under the ultrasound attack, an
adversary modulates the recorded user voice command to an in-
audible frequency and replays it using an ultrasound speaker. In
this scenario, both the VA‚Äôs microphone and the user‚Äôs smartwatch
are exposed to this inaudible sound. We evaluate WearID by com-
paring the accelerometer‚Äôs and the smartwatches‚Äô responses under
a nearly inaudible chirp signal. In particular, we use a function gen-
erator (i.e., Keysight Technologies 33509B [41]) to generate a chirp
of 15ùëòùêªùëß ‚àº 25ùëòùêªùëß and play the chirp using a tweeter speaker,
which is placed 30ùëêùëö away from the smartwatch. Figure 13 shows
the frequency responses of the microphone and the two accelerom-
eters. We can find that though the microphone show responses
from 15ùëòùêªùëß ‚àº 24ùëòùêªùëß, we do not observe any responses on the
two smartwatches. The experimental results show that the smart-
watch‚Äôs accelerometer could shield the VA system from ultrasound
attacks.
7.5 Scalability to Different VA Devices
To demonstrate the scalability of WearID to various VA devices
(e.g., phones, laptops), we compare the voice signals recorded by
Nexus 6 smartphone used to test WearID with the sound recorded
with two other devices, a iPhone 7 and a MSI GL62 laptop. Since
microphones in different VA devices share similar hardware compo-
nents (e.g., membrane, black-plate) and audio processing pipelines,
a voice command recorded by different VA devices should exhibit
high similarity. In the experiment, we place the smartphones and
the laptop 1m away from a subject and set the sampling rates to
8ùëòùêªùëß. Then we use the three devices to simultaneously record 5
trials of each of the three spoken voice commands: S1-‚ÄúWhat‚Äôs
on my calendar for tomorrow?‚Äù; S2-‚ÄúWhat is my password?‚Äù; S3-
‚ÄúDelete all my reminders‚Äù. To quantify the similarity between voice
commands, we derive a spectrogram of each recorded voice signal
and then calculate the normalized 2-D cross-correlation between
voice commands recorded with each pair of devices. As shown in
Figure 15 (a) and Figure 15 (b), high correlation scores between
the same recordings on the two pairs of different devices can be
observed. These results validate that WearID can be easily extended
to various VA devices with different audio recording capabilities.
8 DISCUSSION
Deployment Feasibility. WearID requires a minimum sampling
rate of 100Hz for the accelerometer to capture aerial speech vibra-
tions. This sampling rate is commonly available in the mainstream
wearable devices, such as Samsung Gear Series and Fitbit. A user
could pair/enroll a wearable device to an account of a VA system
(e.g., Google or Alexa account), allowing the user to use critical
152025Frequency (kHz)-0.500.5Amplitude152025Frequency (kHz)-0.500.5Amplitude152025Frequency (kHz)-0.500.5Amplitude-1-0.500.51Corrrelation score00.20.40.60.81CDFHidden voice commandHuman voice-1-0.500.51Corrrelation score00.20.40.60.81CDFHidden voice commandHuman voiceS1S1Nexus 6S2S3S2S3iPhone 7S1S1Nexus 6S2S3S2S3MSI GL62 laptopACSAC 2020, December 7‚Äì11, 2020, Austin, USA
Cong Shi, Yan Wang, Yingying Chen, Nitesh Saxena, and Chen Wang
commands on any VA devices linked to his account. For wearable
devices without WiFi/cellular modules (e.g., some activity trackers),
WearID will still work by using Bluetooth to bridge the wearable
devices to the VA‚Äôs clouds using the paired smartphones. A user
can use WearID in typical room environments without requiring
the wearable and the VA device (e.g., Google Home, Amazon Echo)
being close to each other. The user‚Äôs voice could easily reach the
wearable worn by the user and the VA device within an effective
range of approximately 7 meters. WearID is especially useful in the
scenarios where multiple users share the VA devices (e.g., business
office and home). With the cross-domain authentication, WearID
could detect unauthorized critical commands and alert the corre-
sponding user.
Energy Consumption and Delay. WearID offloads the com-
putationally expensive tasks (i.e., Cross-domain Voice Comparison)
to the cloud, avoiding the heavy computation/energy consumption
on the wearable device. Therefore, the most power-consuming task
on the wearable device is data acquisition, which uses the built-in
accelerometer to capture users‚Äô voice commands. We find that voice
commands usually last less than 10 seconds, and the corresponding
power consumption of recording the voice commands by using the
built-in accelerometer on a wearable device is lower than 0.21ùêΩ.
We also notice that since traditional VA systems still need to send
recorded voice data to the cloud for data processing, the wearable
device could send its data to the cloud at the same time. Thus, the
delay of WearID is close to the response time of traditional VA
systems (e.g., 1.93 seconds on average for Alexa [7]).
Replay Attack in Vibration Domain. Considering WearID
exploits vibration signals for cross-domain authentication, an ad-
versary may attack WearID via replaying well-designed audio that
generates vibration signals replicating the replayed audio. Partic-
ularly, to design such an audio signal, the adversary can study
time-frequency response of the same model of wearable device
used by the legitimate user. However, due to the unique manu-
facture imperfections, each wearable device exhibits distinctive
frequency-selective patterns, even for the same type of device, mak-
ing it difficult to replicate the vibration signals. Additionally, the
adversary needs to get very close to the wearable device (i.e., less
than 30cm) to generate the vibration signals, which will be noticed
by the user. We leave the study on exploring the frequency-selective
pattern to defend against replay attacks in the vibration domain to
our future work.
9 CONCLUSION
In this paper, we presented WearID, a wearable-assisted low-effort
user authentication system that assists existing Voice Assistant
(VA) systems with enhanced security, especially the critical voice
commands (e.g., big purchases, critical calls). WearID authenticates
the user via examining the cross-domain similarity between the
unique voice characteristics captured by the accelerometers of the
wearable device and the microphone of the VA system, respectively.
The cross-domain comparison enables WearID to achieve training-
free and privacy-preserving voice authentication. We developed
the spectrogram-based conversion and frequency/amplitude selec-
tion algorithms, which model the unique and complex relationships
between the voice commands across two domains under a huge sam-
pling rate gap. By utilizing the cross-domain similarity along with
the motion sensor‚Äôs short response distance to voice, WearID can
shield the VA system from various acoustic attacks (e.g., imperson-
ation, replay, hidden command, and ultrasound attacks). Extensive
experiments with two commodity smartwatches and 1000 voice
commands showed that WearID can authenticate users‚Äô voice com-
mands with 99.8% accuracy in the normal situation and detect 97.2%
fake voice commands under audible/inaudible attacks.
10 ACKNOWLEDGMENT
This work was partially supported by the National Science Founda-
tion Grants CCF-1909963, CCF-2000480, CCF-2028876, CNS1526524,
CNS1547350, CNS1714807, CNS1814590 and Army the Research
Office Grant W911NF-18-1-0221.
REFERENCES
[1] 2015. Wearable ID: Is it a fit for your campus? https://www.cr80news.com/news-
item/wearable-id-is-it-a-fit-for-your-campus/.
[2] 2016. Hidden Voice Commands Example. http://www.hiddenvoicecommands.
com/white-box.
[3] Amazon.
2020.
Your
ognize
https://www.amazon.com/gp/help/customer/display.html?nodeId=202199440.
Voice
[4] S Abhishek Anand and Nitesh Saxena. 2011. Speechless: Analyzing the Threat to
Alexa
and
Uses
Voice
Personalize
Profiles
Your
to
Rec-
Experience.
Speech Privacy from Smartphone Motion Sensors. (2011).
[5] S Abhishek Anand, Chen Wang, Jian Liu, Nitesh Saxena, and Yingying Chen. 2019.
Spearphone: A speech privacy exploit via accelerometer-sensed reverberations
from smartphone loudspeakers. arXiv preprint arXiv:1907.05972 (2019).
EURASIP Journal on Applied Signal Processing 2003 (2003), 668‚Äì675.
Showdown. https://www.tomsguide.com/us/siri-vs-alexa,review-3681.html.
[6] Les Atlas and Shihab A Shamma. 2003. Joint acoustic and modulation frequency.
[7] Anna Attkisson. 2016. Siri vs. Alexa: Why Amazon Won Our 300-Question
[8] Android Authority. 2020. Google Home and Assistant commands ‚Äì here‚Äôs the
ones you need to know. https://www.androidauthority.com/google-assistant-
commands-727911/.
1437‚Äì1462.
[9] JenniferE Bellemare. 2018. Consumers Need Answers to Amazon Echo Privacy
Concerns. https://www.identityforce.com/blog/amazon-echo-privacy-concerns.
[10] Logan Blue, Hadi Abdullah, Luis Vargas, and Patrick Traynor. 2018. 2MA: Veri-
fying Voice Commands via Two Microphone Authentication. In Proceedings of
the 2018 on Asia Conference on Computer and Communications Security. ACM,
89‚Äì100.
[11] Joseph P Campbell. 1997. Speaker recognition: A tutorial. Proc. IEEE 85, 9 (1997),
[12] Nicholas Carlini, Pratyush Mishra, Tavish Vaidya, Yuankai Zhang, Micah Sherr,
Clay Shields, David Wagner, and Wenchao Zhou. 2016. Hidden Voice Commands.
In USENIX Security Symposium. 513‚Äì530.
[13] Nicholas Carlini and David Wagner. 2018. Audio adversarial examples: Targeted
attacks on speech-to-text. In 2018 IEEE Security and Privacy Workshops (SPW).
IEEE, 1‚Äì7.
[14] Si Chen, Kui Ren, Sixu Piao, Cong Wang, Qian Wang, Jian Weng, Lu Su, and
Aziz Mohaisen. 2017. You can hear but you cannot steal: Defending against
voice impersonation attacks on smartphones. In Distributed Computing Systems
(ICDCS), 2017 IEEE 37th International Conference on. IEEE, 183‚Äì195.
[15] Geumhwan Cho, Jusop Choi, Hyoungshick Kim, Sangwon Hyun, and Jungwoo
Ryoo. 2018. Threat modeling and analysis of voice assistant applications. In
International Workshop on Information Security Applications. Springer, 197‚Äì209.
[16] Kirsten Crager, Anindya Maiti, Murtuza Jadliwala, and Jibo He. 2017. Informa-
tion leakage through mobile motion sensors: User awareness and concerns. In
Proceedings of the European Workshop on Usable Security (EuroUSEC).
[17] Phillip L De Leon, Michael Pucher, and Junichi Yamagishi. 2012. Evaluation of
the vulnerability of speaker verification to synthetic speech. IEEE Transactions
on Audio, Speech, and Language Processing 20 (2012), 2280 ‚Äì 2290.
[18] Pyramid Electronics. 2018. Pyramid Car Audio, 300 Watt Aluminum Bullet Horn
in Enclosure with Swivel Housing. http://www.pyramidcaraudio.com/sku/TW28/
300-Watt-Aluminum-Bullet-Horn-in-Enclosure-wSwivel-Housing.
[19] Adrienne Porter Felt, Elizabeth Ha, Serge Egelman, Ariel Haney, Erika Chin, and
David Wagner. 2012. Android permissions: User attention, comprehension, and
behavior. In Proceedings of the eighth symposium on usable privacy and security.
ACM, 3.
[20] Huan Feng, Kassem Fawaz, and Kang G Shin. 2017. Continuous authentication
for voice assistants. In Proceedings of the 23rd Annual International Conference on
Mobile Computing and Networking. ACM, 343‚Äì355.
WearID
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA