5
5
5
5
6
6
7
7
7
7
8
8
8
8
9
9
1
1
0
0
6
6
2
2
8
8
4
4
0
0
6
6
2
2
8
8
4
4
0
0
6
6
2
2
8
8
4
4
0
0
0
0
Fig. 3: Throughput vs. system size. We measure peak throughput as we increase the number of replicas in different payment system
implementations, one based on consensus (BFT-SMaRt), and two based on broadcast (Astro I and II). We do not employ sharding.
System size (number of replicas in the system)
System size (number of replicas in the system)
Throughput (pps)
 1000
 10000
)
s
m
 10000
(
y
c
n
e
t
a
L
 1000
 100
 1
BFT-SMaRt
Astro I
Astro II
 10
 100
Fig. 4: Latency/throughput. Performance evaluation of three pay-
ment systems each running at N = 100.
increase the system size in increments of 6, starting from the
smallest size of 4, until we reach 100.
As an overall observation, our two Astro prototypes out-
perform the consensus-based solution at every system size we
investigate. At small size, all systems exhibit their respective
highest throughput. The consensus-based implementation us-
ing BFT-SMaRt sustains over 10K pps, while Astro reaches
almost 13.5K pps and Astro II sustains 55K pps. The 4x
improvement of Astro II over Astro I is owed to the the linear
communication complexity of the former system (§IV-A).
As can be seen, however, this beneﬁt slowly tapers off with
increasing system size. At maximum system size (N = 100),
the consensus-based system saturates at 334 pps; Astro I
sustains 6x higher throughput, being able to apply 2K pps,
and Astro II can sustain 5K pps (a 16x improvement over
consensus and 2.5x over Astro I).
Latency-Throughput. We now explore the difference in
performance between the consensus-based baseline and Astro
I/II at the maximum system size we consider, N = 100.
As before, all systems are running in a single-shard setup.
The results depicted in Figure 4 show how latency evolves
with respect
the y-axis
(latency) starts at 100ms, and we convey order of magnitude
differences using logscale axes.
to throughput. For clarity sake,
The consensus-based implementation typically exhibits
sub-second latencies. We do not show the 95th percentile la-
tencies because they obstruct visibility, but these are between
1.3 and 1.5 seconds. Latencies in Astro I are more variable,
between 400 and 500ms prior to saturation, while the 95th
percentile latencies are on the order of one second. Recall that
clients connect to random replicas, which are geographically
spread. Astro II exhibits more stable performance and lower
latencies: prior to saturation, clients observe a conﬁrmation
latency of 200ms on average. The 95th percentile latency (at
low load) is under 240ms. The 99th percentile for all these
systems are within the same order of magnitude as the 95th.
We remark that the latencies for these three systems are
not necessarily at their worst when N = 100. We also
investigate the same execution at N = 10, for instance,
and observe only slightly better performance (e.g., latency
for Astro II is 150ms on average). The latencies do not
change considerably because there is a lot of parallelism
inherent in the underlying quorum-based protocols, both for
consensus and broadcast. This is intuitive: obtaining one
response from a particular distant replica takes as much time
as obtaining several responses (in parallel) from multiple
distant replicas. Primarily, it is throughput that suffers in
quorum-based systems, and latency secondarily [26], [72],
[75].
An important observation here is that our evaluation con-
cerns the critical part of a payment system, the ordering
layer. For the deterministic system model, we are only
aware of prior experiments of this layer which considered a
maximum system size of N = 10, concretely for Hyperledger
Fabric [70], which builds on BFT-SMaRt. To conclude this
part of our evaluation, for systems of moderate size—up to
100 replicas—broadcast-based systems are simpler and sig-
niﬁcantly outperform consensus-based solutions for decen-
tralized payments. Even if Astro relies on broadcast, it still
employs quorum-gathering to achieve consistent replication;
hence the throughput of Astro is inversely proportional to the
system size (akin to consensus-based solutions). To avoid this
throughput decay and scale to larger systems, we now discuss
experiments with sharding.
2) Sharding in Smallbank Application: For a real-world
application workload, we use the Smallbank transaction
family from the BLOCKBENCH framework [31]; this is a
version of the H-Store Smallbank benchmark [22] adapted
to the cryptocurrency setting. The application models bank
accounts, where the owners of these accounts are clients
that can issue several types of transactions. In particular,
accounts can be of either savings or checking type. Some
transactions model payments across two accounts of the same
owner, while other transactions deal with the transfer of
funds between different owners. For the sake of consistency,
hereinafter we refer to bank accounts and their owners as
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:24:09 UTC from IEEE Xplore.  Restrictions apply. 
33
#
2
2
3
3
4
4
s
d
r
a
h
s
f
o
#
tc
delay (ms)
0
20
0
20
0
20
Throughput (Kilo-pps)
per-shard\total
BFT-S†
1.0\2.0
0.3\0.5
1.0\3.1
0.3\0.8
1.0\4.1
0.3\1.1
Astro II
7.9\15.7
5.1\10.2
5.1\15.4
4.5\13.6
5.0\20.1
4.5\18.1
Latency (ms)
Average\95th %ile
BFT-S†
Astro II
600\808
204\279
479\705 2245\2673
213\375
600\808
368\656 2245\2673
213\259
600\808
354\620 2245\2673
†
TABLE I: Smallbank sharded benchmark. Performance results
for up to 4 shards (each N = 52 replicas).
BFT-SMaRt results are
upper-bound values based on a single-shard experiment.
xlogs and clients, respectively.
Experimental Setup. We associate each client with two
xlogs (for checking and savings). Thus same-client transac-
tions at the application level appear as full-ﬂedged payments
between two distinct xlogs in the underlying layer. We use
a multi-shard setup for Astro II, ensuring that both xlogs of
any client belong to the same shard. Whenever a transac-
tion involves different shards, the cross-shard coordination
consists of the CREDIT message described earlier (§V). For
BFT-SMaRt, we use an equivalent setup.
Each shard consists of N = 52 replicas uniformly spread
among the four EC2 regions of Europe. We execute using
2, 3 and 4 shards (total of 208 replicas); we limit ourselves
to 4 mainly due to ﬁnancial constraints, but also because it
is straightforward to estimate performance at larger scales.
Clients attach to a certain replica and simultaneously issue
transactions as prescribed by the Smallbank benchmark,
meaning that 12.5% of the overall number of transactions are
cross-shard. To produce more realistic network conditions,
we introduce artiﬁcial network delays: We use the trafﬁc
control (tc) subsystem of the Linux Kernel, and increase
inter-replica latencies by 20ms. Network latency between
replicas in Europe is around 20ms, so having this delay
essentially doubles latencies; additionally, this also eliminates
any advantage that may arise due to co-location of some
replicas in the same EC2 region.
Experimental Results. We provide the results in Table I. We
show both per-shard and overall (i.e., total) throughput for
a given latency envelope. Astro II sustains the highest per-
shard throughput when there are 2 shards. As the number of
shards increases (the # column), per-shard throughput slowly
decreases: This is because intra-shard payments are more
lightweight (lacking the cross-shard notiﬁcation mechanism)
and the number of intra-shard operations decreases with
growing number of shards [80]. We observe that the 20ms
network delay affects performance. The reason is TCP’s
congestion control: Astro II saturates the links and network
delays become the bottleneck.
As Table I shows, performance in Astro II scales well
with the number of shards. In absolute numbers, Astro II
sustains up to 20K pps using four shards, with average
latencies of around 200ms. The BFT-SMaRt baseline running
on four shards sustains a total throughput of just above 4K
pps; importantly, these result are only for comparison, and
Consensus-Leader
Consensus-Random
Broadcast-Random
Crash-stop failure
 400
 100
 300
 200
t
u
p
h
g
u
o
r
h
T
)
c
e
s
/
s
t
n
e
m
y
a
p
(
 0
 20
 25
 35
 30
 50
Execution history (seconds)
 40