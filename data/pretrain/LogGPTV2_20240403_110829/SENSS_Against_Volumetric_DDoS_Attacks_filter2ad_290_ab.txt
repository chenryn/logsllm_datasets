few ISPs on the attack’s path, collaborating with the victim, enable
that victim to filter much of the attack traffic.
Pushback [12] applies ISP-to-ISP collaboration. Such collabora-
tion is difficult in general, because an ISP handles a lot of traffic for
many customers. Moderate floods, which may not be noticeable at
the ISP level may overwhelm a customer on a small downlink. To
detect these floods the ISP would have to continuously monitor all
its customers’ traffic, which is costly. It would also have to make
guesses as to which traffic to filter, while a victim can make a better
decision (and implement it with SENSS) based on its knowledge of
its inbound traffic patterns.
CoDef [19] focuses on handling of cross-fire attacks, through col-
laborative rerouting and rate limiting. Collaboration occurs between
the affected network and the networks that host legitimate sources.
CoDef’s mitigation (rerouting) resembles SENSS’s route control
messages, but its diagnosis requires packet marking, while SENSS
does not require this. SENSS is thus more deployable than CoDef.
Further, CoDef’s collaboration model (victim-to-source) means that
CoDef requires a wider deployment than SENSS to achieve a given
effectiveness target.
SIBRA [4] introduces a new mechanism for legitimate sources
and destinations to reserve bandwidth on inter-AS links, and thus
isolate themselves from DDoS attacks. SIBRA is complementary
to SENSS and attempts to prevent DDoS, while SENSS attempts
to mitigate it. SIBRA also requires more extensive changes to ISPs
than SENSS and is thus less deployable.
SPIFFY [15] introduces implicit collaboration between the bottle-
neck and sources of traffic, by temporarily expanding the bottleneck
link and identifying sources, which do not expand their sending
rate, as attackers. SPIFFY only handles cross-fire attacks and is thus
complementary to SENSS.
2.3 SENSS vs First-ISP vs Clouds
We now briefly discuss how SENSS could complement current
operational solutions: first-ISP and clouds.
SENSS’s messaging mechanism offers a way for remote networks
to collaborate on demand, without prior trust. As such, SENSS mech-
anisms could be used to remotely trigger first-ISP or cloud-based
solutions. This could transform cloud defenses from pre-arranged
into on-demand solutions.
SENSS could further be used when first-ISP or cloud defenses
fail or are overwhelmed (e.g. Spamhaus attacks in 2013 [31] and
Dyn attacks in 2016 [35]). A cloud or an ISP can use SENSS to
achieve a collaborative response with other ISPs in the Internet, to
lighten its load. SENSS can also benefit from clouds and first-ISP
solutions, which could act as victim proxies, and enable adoption of
SENSS among non-technical victims.
3 SENSS
In this section, we discuss challenges of collaborative defense, pro-
vide a high-level overview of SENSS operation, and detail how
SENSS would be implemented at ISPs and at attack victims.
leavesroot=bottleneckACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Sivaramakrishnan, Jelena Mirkovic, Minlan Yu, and Ying Zhang
attacks, e.g., to learn about its normal traffic patterns. An ISP can
decide to provide SENSS services for free or for a fee, which could
be a flat-rate or per-message fee. Economically, a per-message fee
makes the most sense as the ISP incurs cost for running SENSS only
when it handles SENSS messages, and a victim is only interested in
paying for SENSS when they are under attack.
An ISP deploys SENSS by implementing SENSS APIs on a
server, and exposing them to the public. These APIs can be im-
plemented as a Web service, and thus deployed at the ISP’s Web
server. This leverages existing approaches for service robustness
(Web server replication), message security (HTTPS), and charging
for service (e-commerce). The ISP also implements automated mech-
anisms within its network, which act on SENSS client’s requests by
implementing traffic/route handling in border routers. This is shown
as grey lines in the Figure. These mechanisms can be implemented
as a collection of scripts, which communicate with switches/routers
using Netflow, Openflow, Flowspec or switch-specific management
language (e.g., for ACL setup). We assume that all client-server
communication occurs at the network level and not at the host or
user level. This limits the cost of communication and the state at
SENSS servers.
A victim under attack runs the SENSS client. The client first
uses a public SENSS directory to identify multiple SENSS servers
(step 1 in the Figure). One way to implement this directory is to
assign a common DNS name to each SENSS server. The victim
sends queries to SENSS servers about the victim’s inbound traffic or
the routes to the victim’s prefixes (step 2 in the Figure). For security
reasons, clients are only allowed to ask about and manipulate traffic
and routes for the prefixes their network owns. While some attack
diagnostics may be easier if we allowed clients to ask about anyone’s
traffic, this would create grave privacy concerns, and jeopardize
adoption of SENSS.
Each query is accompanied by a digital certificate, which proves
the that the client is authorized to issue query and control messages
about the IP prefixes contained in the query. We call this certificate
proof of prefix ownership and provide more information about it
in Section 3.5. The SENSS server validates the certificate and the
message, performs the required service, charges the victim for it, and
returns the response to the client (step 2 in the Figure). The server
may also decide not to perform a given action, e.g., because it would
be against some internal policy or because it would consume too
many resources. In this case the server does not charge the victim
and simply returns a reject message to the client.
The client analyzes responses obtained from SENSS servers,
identifies the best action and the best locations for mitigation (e.g.,
filtering, rerouting) and issues control messages to chosen SENSS
servers (step 3 in the Figure), which authenticate them, charge for
and perform the actions. The query and control steps can be repeated
multiple times, until the desired mitigation effect is achieved.
ISP Implementation
3.3
APIs. Table 1 summarizes SENSS APIs, used by the client to
request SENSS services. Each message has an action field, which
specifies if the traffic/route handling rules should be installed (start)
or removed (stop) at the SENSS ISP. The server enacts these handling
rules after each message, by installing them in the appropriate border
Figure 2: SENSS architecture.
3.1 Challenges
When designing a collaborative defense, we must address the labor-
division challenge (what will be done where), the deployment chal-
lenge (how to motivate deployment) and the security challenge.
Labor division: we must decide which functionalities are re-
quired for attack handling and where to implement them. SENSS
uses victim-to-ISP collaboration, which places all the intelligence at
the victim and requires only simple functionalities of ISPs. This en-
ables a victim to request help from any ISP for diagnosis and mitiga-
tion, but remain fully in control over the attack handling. The victim
can combine its internal knowledge of its business and customers,
with observations received from SENSS, to create customized de-
fenses. Because the victim can directly contact any SENSS ISP,
neighbor or remote, SENSS is very effective in sparse deployment
(see Section 4) and robust to misbehavior (see Section 3.5).
Deployment: collaborative defenses must offer significant ben-
efits to networks that deploy them. SENSS brings clear benefits to
the victims of attacks, but the challenge lies in making it appealing
to ISPs. We address this challenge in several ways. First, SENSS
handles several attack variants, thus an ISP can offer it to current
customers as added value, and many customers may find it useful.
Second, SENSS works with existing hardware and thus has low cost
to deploy. Third, SENSS offers significant benefits to early adopters,
thus ISPs can offer immediate protection to their customers against
DDoS, even in sparse deployment.
Security: collaboration should not introduce new vulnerabilities
even under direct attacks, or when some collaborators misbehave.
SENSS has multiple security layers to protect against misuse: (1) It
allows the victims to only observe/control traffic and routes for their
prefixes, whose ownership is proved via digital certificates. SENSS
ISPs validate these certificates before processing each request. (2)
All communication between the victim and the SENSS ISPs is
secured using TLS, and is thus protected against message sniffing,
forgery, modification or replay, (3) SENSS operation is driven by the
victim, with each SENSS ISP reporting its own observations of the
victim’s traffic and routes. Such design severely limits the impact of
a misbehaving ISP (see Section 3.5).
3.2 SENSS Architecture
Figure 2 illustrates SENSS operation. SENSS consists of client code,
which runs at an end network or an ISP, and server code running
at an ISP. Clients are illustrated as blue circles and servers as grey
circles in the Figure. We refer to the client-deploying network as
the victim, but it may decide to engage SENSS even in absence of
SENSS serverSENSS clientvictimattackerSENSS server2. Query and reply3. Control2. Query and reply3. ControlSENSS directory1. Lookup     SENSS    serversSENSS Against Volumetric DDoS Attacks
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Type
Traffic query
Route query
Traffic control
Route control
Abort
Message
traffic_query
route_query
filter/allow
demote
abort
Matching Fields
predicates, otime
prefix
predicates, tag, dur
prefix, seg, dur
prefix
Action
start/stop
none
start/stop
start/stop
none
Reply/Response
rule_id and a list of  matching the predicate during otime
rule_id and AS paths from the SENSS ISP to the prefix
rule_id and filter/allow all traffic matching the  for duration dur
rule_id and reduce pref. of routes to prefix if they contain seg in AS path, for duration dur
delete all rules for the prefix, and blacklist the public key
Table 1: SENSS APIs
Figure 3: Illustration of traffic query.
routers at the ISP. The server then replies with a unique identifier
(rule_id) to the client. All rules expire after the duration (otime or
dur parameter) specified in the message. When a rule expires at the
server, the server removes the rule from the routers where it was
installed. The client may choose to remove a handling rule prior to
its expiry, by setting the action field to stop and specifying rule’s
identifier. Additionally, the client can use a special abort message,
which removes all the rules for the given prefix. A SENSS server
may also decide not to handle the client’s message, and return a
reject reply to the client.
The basic building block of traffic messages (traffic_query and
traffic_control) are predicates, which match a flow based on header
fields. For example, the predicate “(src_ip=10.0.0.1 | src_ip=10.0.0.2)
& src_port=53” matches flows with source IP 10.0.0.1 or 10.0.0.2
and source port 53. Predicates support conjuction (&), disjunction
(|), negation (!) and wildcard (*) operators. Predicates can also spec-
ify traffic direction (SELF – generated by the ISP, IN and OUT), and
they can specify a tag, denoting a peering link to which the query
applies. A traffic_query asks for monitoring of traffic matching the
predicate for time otime. On receiving a traffic_query, a SENSS
server installs the appropriate traffic collection rules (Openflow or
Netfilter) to some or all border routers. After time otime the server
collects observations from the routers and removes the collection
rules. It then aggregates these observations into a single reply, and
sends it to the client. The reply contains rule_id, and a list of tuples.
Each tuple contains a tag, identifying the neighbor, traffic direction
dir and the amount of traffic observed in packets or bytes. The tag
is the ISP-specific, unique identifier per neighbor, and should be
anonymized in a manner, which is reversible only by the ISP. For
example, the ISP could encrypt the neighbor’s identity with a secret
key. If the client later requests filtering of traffic with a given tag, the
ISP decrypts the tag to identify the appropriate peering link and the
switch, where the filters should be installed. One traffic_query and
its reply are illustrated in Fig. 3. The client A asks for monitoring
traffic to its prefix, 1.2.3.0/24, for 10 seconds. The server B replies
with the list containing three records – one for each neighbor that
forwards traffic to B with destination IP in 1.2.3.0/24.
A traffic_control message requests a SENSS ISP to filter or allow
traffic matching the specific predicates and tags, for the duration dur.
If the client sends multiple messages for the same prefix, they will be
matched in the order in which they are received. The server translates
each rule into a filtering rule that its routers understand (e.g., ACL,
Flowspec, Openflow) and installs it at the routers matching the tag
field from the message. Rules are removed after time dur.
A route_query asks an ISP about the AS paths in its best routes to
the prefix. The server collects the best routes from all border routers,
and replies with the set of unique AS paths.
A route_control message asks an ISP to demote all its routes
for the select prefix that contain the AS-path segment seg, for the
duration dur. The server collects all the routes from each border
routers for the specified prefix. It then decides for each router if the
route should be demoted. This decision can take into account the
ISP’s internal route selection policy and the cost of demotion (e.g., if
a customer route is being demoted and the next best route is peer or
provider route there will be an associated cost). If the server decides
to demote the route, it issues appropriate messages to the router’s
BGP daemon. After time dur these messages are reversed.
Identifying deployment routers. After receiving and validating
(see Section 3.5) a SENSS message, the SENSS server identifies the
routers or switches, which should implement the required function-
ality. For traffic queries with IN direction, and for route queries and
route control, all ingress routers would be used. For traffic filters, the
server only needs to identify those ingress routers that were specified
in the tag field of the client’s message. If no tag is specified, the
egress router to the specific prefix can be used for filter installation.