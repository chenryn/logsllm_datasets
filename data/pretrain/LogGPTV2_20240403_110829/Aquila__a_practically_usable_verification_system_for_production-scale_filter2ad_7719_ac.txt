modified(pkt.ipv4.dst_ip);
// Dst. IP is modified
}
pipe_out = {...}
}
program {
assume(init);
call(ingress_pipeline);
assert(pipe_in);
#quit = (ig_md.drop == 0)
|| (ig_md.to_cpu == 0);
if (!#quit) {
call(egress_pipeline);
assert(pipe_out);
}}
// Add assumption
// Execute ingress program
// Check pipe_in assertion
// Skip the egress pipeline
// if dropped or sent to CPU
Figure 6: Example specification program
config {path = ./forward.p4;}
assumption {
init {
SIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
Figure 7: Verification process of Aquila. Gray components
are our contributions.
and assertions at designated places; next, the entire GCL is trans-
lated into verification conditions; finally, we invoke an SMT solver
(e.g., Z3 [9]) to check whether the specification holds. Note that
such a verification methodology is widely used in the verification
community‚Äîfor example, p4v [30] also adopts the similar principle;
thus, we make no claim it is novel by itself.
Nevertheless, we find that directly applying the existing ap-
proaches to verify our hyper-converged programs will result in
state explosion for the following reasons. First, the parser in our
production program is a big state machine, and previous approaches
would further expand it into thousands of states and branches. And
second, our production programs have hundreds of tables, each
containing hundreds of entries, and the match-action dependencies
across these tables would give rise to complex logical relations.
Given these situations, the formula size generated by existing ap-
proaches can easily outgrow a solver‚Äôs compute capability.
To address the above challenges, our solution intuition is to
circumvent the exponential growth of states associated with the
upscaling of dataplane programs to production level. Therefore,
we propose a new encoding approach (i.e., the gray components
in Figure 7) that can generate a ‚Äúcompacted‚Äù GCL representation
with a smaller number of variables and lower complexity, thus
ensuring the generated formula simple enough to solve. The en-
tire GCL composition and verification condition translation parts
straightforwardly follow Dijkstra‚Äôs classic way [10, 30], so we skip
the details. This section first describes our core sequential encoding
approach for P4 program (¬ß4.1), then shows data structures encod-
ing, e.g., packet and table (¬ß4.2), and new features encoding such as
inter-pipeline packet passing (¬ß4.3).
4.1 Sequential Encoding
We propose a sequential encoding approach to encode the main
body of a data plane component (including parser, MAU, and de-
parser) into a compact GCL representation, i.e., Component GCL
Encoding in Figure 7. In ¬ß4.1, we use parser as an example (shown
in Figure 8) to first illustrate the key reason for state explosion and
then present how our sequential encoding works. This approach
also applies to encoding match-action dependencies across tables
in MAUs.
The state explosion problem. The parser in P4 uses a state ma-
chine model. As shown in Figure 8(a), a parser parses a TCP/UDP
packet with either an IPv4 or IPv6 header, and it has five states. If
we naively encode this state machine into if-else GCL statements,
the result would involve seven states, i.e., a tree structure with
regular value checking via ‚Äò==‚Äô, LPI allows us to use logical connec-
tives to construct more complex conditional checking. Line 10-11
in Figure 6 show such an example that checks the destination IP
when the input packet has a TCP header. The ‚Äò@‚Äô symbol allows
us to get the value before the packet entering the switch.
LPI can also specify operation properties, such as whether some
value is changed successfully before a table is applied, and whether
an action in a table is hit by a specific packet. We use ‚Äòmatch‚Äô to
specify whether a specific action in a table is hit and ‚Äòmodified‚Äô
to check whether a specific header or metadata is modified, no
matter what the modified value is. Engineers can express different
specification for different actions of the same time. In Figure 6
example, line 12-13 indicate the input packet hits the fwd table, send
action and the destination IP is modified.
Program. LPI uses program to connect assumptions and assertions
to their corresponding data plane modules, forming the entire spec-
ification. For example, line 18 and 20 surround the ingress pipeline
encoding (line 19) with assumption ‚Äòinit‚Äô and assertion ‚Äòpipe_in‚Äô
before and after its execution, respectively. LPI also allows us to
specify customized connections between pipelines. For example,
line 21-22 define a ghost variable ùëûùë¢ùëñùë° and skips the egress pipeline
when ùëûùë¢ùëñùë° holds. Aquila also supports bounded recirculation by
defining a recirc with the maximum allowed recirculations.
During execution, Aquila first parses the specification program,
rejects it if it is either syntactically or semantically incorrect. Then,
it reads P4 program provided in the config section. Finally, Aquila
verifies whether the input program meets the specification.
4 VERIFICATION APPROACH
Aquila‚Äôs verification employs Dijkstra‚Äôs classic methodology to
check a program based on the predicate transformer semantics [10]:
given a specification, a P4 program, and table entries, we first en-
code individual P4 components into Guarded Command Language
(GCL); then, we follow the specification program to compose com-
ponent GCLs into a whole-switch GCL and insert assumptions
SpecificationReportVerification ConditionsVerificationSMTSolverP4 ProgramTable EntriesComponent GCLEncodingData Structure Encoding (¬ß4.2)Sequentially EncodingProgram (¬ß4.1)Other Feature Encoding (¬ß4.3)SMTFormula Whole-SwitchGCL GeneratorSIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
Tian et al.
By far, we sequentially encode a parser program. Given a state
machine in Figure 8(a), the sequential encoding algorithm results in
Figure 8(b). The chain of states represents the union of all possible
traces in the DAG, some states can be skipped based on the in-
put packet‚Äôs value. For example, if an IPv4 packet with TCP header
comes in, then $Tcp is true and $Udp is false, the UDP state is skipped
after the TCP state is visited. Compared with prior work, the sequen-
tial encoding algorithm achieves ùëÇ(ùëõ) complexity and significantly
speeds up the verification later. In the same IP option parser exam-
ple, the new encoding method reduces number of encoded states
from 1174 to 30.
Handling loops. The above algorithm has one assumption that
the state machine‚Äôs dependency graph is a DAG. However, loop
may exist when parsing complicated headers like TCP options.
Aquila introduces another approach to encode the entire loop into
one state and the rest of the graph is encoded via the sequential
encoding approach. In short, we first break the loop by removing
the transition to the root state (a state that has incoming edges from
outside the loop), then encode the states via sequential encoding,
and finally surround the encoded statement with a while loop in
the format of GCL. Similar to the sequential encoding algorithm,
the loop exits when the value monitored by the while loop is set to
false, and the followup state is applied based on other labels in the
loop. Due to limited space, see Appendix B.1 for details.
4.2 Data Structure Encoding
Besides sequential encoding, we also encode two important data
structures, table and packet, to further compress the resulting GCL.
Table encoding. In a P4 program, a table with multiple entries
can be treated as an ordered switch-statement where each entry
represents a case branch: a table entry‚Äôs match filed (i.e., condition)
and its corresponding action (i.e., branch body). In our production
program, tables may contain thousands of entries, encoding table
along with its entries naively with if-statements would easily result
in memory explosion. Thus, a memory-efficient table encoding is
important. More specifically, we encode the table via a two-step
approach: (1) use Action BitVector (ABV) to encode each entry in
the table to avoid branches and (2) use a tree like lookup algorithm
to encode the search operation among the ABVs.
Action BitVector (ABV). The ABV decouples the condition and
branch body by encoding the action index, action parameter into
a fixed-length bitvector. The entries of a table are encoded as a
list of match conditions and the corresponding ABVs. The table
apply operation is separated into (1) looking up the match condition
according to the matched field to get the first matched ABV, and
(2) applying the corresponding action based on the action and
parameter field of the ABV. This encoding decouples the match and
action operation, significantly reduces the memory footprint. More
details about the format and implementation of ABV can be found
in Appendix B.3.
ABV lookup. The naive solution of looking up the ABVs is to
use the ITE (If-Then-Else) statement and simulate the one-by-one
matching. to simulate the one-by-one matching. It generates deep
AND-OR nested expression, which is hard to verify. We instead
encode ABVs into a balanced lookup tree via the following formula:
Figure 8: Example for sequential encoding.
seven nodes. It is easy to learn such an encoding structure grows
exponentially as the number of states increases. The key problem is
that a tree-like GCL, unlike a state machine, has to explicitly embed
all possible execution paths, leading to inevitable state duplication.
In the worst case, a DAG with ùëÇ(ùëõ) nodes can be expanded into
a tree with ùëÇ(2ùëõ) nodes. In one of our production programs, for
example, the parser has only 30 states; however, due to the IP option
header, the expansion results in 1174 states and there are hundreds
of complex table dependencies and actions corresponding to each
of these states, potentially leading to out of memory.
Our algorithm. Our sequential encoding addresses this scalability
challenge. We observe that each state (e.g., rectangles in Figure 8(a))
can be visited at most once. Thus, we perform topological sorting
on the DAG, introduce ghost variables1 to indicate the activation
of states, and encode the graph as a straight-line program (e.g.,
Figure 8(b)). This encoding has only ùëÇ(ùëõ) complexity. The algorithm
works as follows:
‚Ä¢ (1) Given a state machine DAG, ùëÜ, we order all its states by
topological sorting [6] and put the result in a vector ùê∏.
‚Ä¢ (2) For each state ùëíùëñ ‚àà ùê∏, we look for all statements that will
result in state transitions (e.g., statements in select). We gather
its path condition and translate the transition into an assignment
to a ghost variable as below:
select (ùê∂) {... V: L} ‚áí $L := ùê∂ == ùëâ
For example in Figure 8(b), the state transition statement
select(eth.type){IPV4:Ipv4}, is replaced by an assignment ex-
pression $Ipv4:=eth.type==IPV4.
‚Ä¢ (3) Finally, except the ‚ÄòStart‚Äô state, we enclose each state in an
if-statement, using its label as the entry condition. In Figure 8(b)
example, an if($Ipv4==true) is added to guard the second state.
In the end, E contains the straight-line program that encodes the
original DAG ùëÜ.
1Ghost variables are assignable variables that appear in program encoding but do not
correspond to actual variables in the header or program, such as $Ipv4 in Figure 8(b)
Ipv4:  extract(ipv4);  select (ipv4.proto){    TCP: Tcp;    UDP: Udp;  }Ipv6:  extract(ipv6);  select (ipv6.next){    TCP: Tcp;    UDP: Udp;  }Udp:  extract(udp);Tcp:  extract(tcp);extract(eth);$Ipv4:=eth.type==IPV4;$Ipv6:=eth.type==IPV6;if ($Ipv4 == true):  extract(ipv4);  $Tcp:=ipv4.proto==TCP;  $Udp:=ipv4.proto==UDP;if ($Ipv6 == true):  extract(ipv6);  $Tcp:=ipv6.next==TCP;  $Udp:=ipv6.next==UDP;if ($Udp == true):  extract(udp);if ($Tcp == true):  extract(tcp);(b) Sequential encoding result(a) An example parser state machine(cid:16)ùëÄùëéùë°ùëê‚Ñéùëô, ùëô+ùëü
2
ùê¥ùêµùëâùëô,ùëü = ite
ùëÄùëéùë°ùëê‚Ñéùëô,ùëü = ùëÄùëéùë°ùëê‚Ñéùëô, ùëô+ùëü
2
(cid:17) ,
, ùê¥ùêµùëâùëô, ùëô+ùëü
2
‚à® ùëÄùëéùë°ùëê‚Ñé ùëô+ùëü
, ùê¥ùêµùëâ ùëô+ùëü
2 ,ùëü
2 ,ùëü ,
where ite is the If-Then-Else operator. This optimization reduces
the lookup complexity from ùëÇ(ùëõ) to ùëÇ(ùëôùëúùëî(ùëõ)).
Packet encoding. Previous approaches (e.g., p4pktgen [36] and
p4v [30]) model the input packet as a huge bitvector with a maxi-
mum length. Such an encoding method adds significant overhead
to the SMT solver. Because in the deparser, the header fields had to
be assigned back to the bitvector. Each assignment creates a new
copy of the bitvector in the final logic expression, quickly expand-
ing the memory cost. Aquila introduces a simple, key-value based
structure: encoding packet header operations as (key-value) assign-
ments, which gets rid of the huge vector copying issue. For exam-
ple, the packet operation extract(eth) is encoded as eth:=pkt.eth.
Key-value based encoding requires us to additionally maintain the
header order, which can be encoded as a sequence.
Packet encoding makes lookahead no longer trivial. Constraints
about the bits looked ahead in previous states should be considered.
We move this detail to Appendix B.2.
4.3 Encoding Other Features
Aquila can encode new features from P416 (e.g., inter-pipeline
packet passing and recirculation), and other data structures (e.g.,
hash). Please see Appendix B.4 for details.
5 AUTOMATIC BUG LOCALIZATION
Understanding the violated properties is not enough, since local-
izing bugs is tedious and time-consuming for our engineers. Prior
efforts were extensively proposed to localize bugs in C and Haskell
programs [7, 27, 40, 44, 53]; however, they do not fit in P4 programs
for the following reasons. First, existing work is unable to localize
bugs resulting from statement missing (e.g., Figure 4), which com-
monly existed in our development. Second, the general-purpose
language debugging tools cannot localize the bugs in P4-specific
semantics such as bugs in parser and lookahead.
The intuition of our solution is to first narrow down suspects
based on reported violations (¬ß5.1), and then pinpoint the buggy
code snippets by simulating a fix for each suspect (¬ß5.2). Our bug
localization approach not only localizes bugs for statement missing,
but also speeds up debugging process by leveraging table action as
granularity.
5.1 Finding Violated Assertion
When a violation is reported, the first step of bug localization is to
find all the violated assertions. Specifically, we first let the solver
only return the first violated assertion. Then, we remove it from
the specification and iterate ùëö times to find all violated assertions.
For each assertion assertùëñ, we add labels beforeùëñ and afterùëñ before
and after the assertions, respectively. So the specification is finally
encoded as: beforeùëñ ‚àß (¬¨assertùëñ ‚à® (assertùëñ ‚àß afterùëñ ‚àß (beforeùëñ+1 ¬∑ ¬∑ ¬∑))).
Such an expression guarantees that, if assertùëñ is violated, the ex-
pression can be simplified into beforeùëñ ‚àß true. Thus, the satisfiability
of the above expression is only determined by beforeùëñ. All the fol-
lowing variables (e.g., afterùëñ) are irrelevant to satisfiability and do
SIGCOMM ‚Äô21, August 23‚Äì27, 2021, Virtual Event, USA
control BugExample(md) {
action a1() { md.ttl = ipv4.ttl; }
action a2() { ipv4.ttl = md.ttl - 1; }
table t1() {
key = { ipv4.dst_ip : exact; } // table entry bug
actions = { a2; }
}
apply { a1(); t1.apply(); }
} // assert ipv4.ttl == @ipv4.ttl - 1
Figure 9: Localizing table entry bug.
not appear in the counterexample found by the solver, narrowing
down our search space later.
5.2 Bug Localization
We now localize the bug. Bug localization requires Aquila to point
out the potential locations that could potentially fix the viola-
tion [44, 53], such as replacing table entries and changing a state-
ment in the action granularity. A fix should correspond to a po-
tential bug location. Because one bug may have multiple fixes, our
goal is to report the minimal scope of program snippet that may
trigger the violation.
Preparation. Before localizing the bug, we first use SMT solver
to return a counterexample, which exhibits concrete values for all
the variables to trigger the violation. We assign these values to
the target program in order to ‚Äúfreeze‚Äù the input. Also, we record
the actions that the counterexample triggers. The preparation can
reduce the search space. Next, we run the following algorithms to
locate the bugs.
Table entry bug localization. A table entry bug means the table
does not behave as expected, such as incorrect table entry, and a
table entry missing. For example in Figure 9, table t1 has no entry,