### 7.1 Economic Considerations

In Section 3.2, our attack model assumes that an adversary can induce churn in the Sybil region by creating and deleting Sybil identities. This assumption is consistent with the threat models of social Sybil defenses, which typically assume that such operations are cost-free for the adversary [35, 8]. In practice, however, social networks employ various defense mechanisms to raise the bar for adversaries, including CAPTCHAs, email and phone verification, and IP blacklists [3, 24]. These measures impose an economic impact on the adversary, as they require resources to circumvent registration barriers.

In recent years, an underground market has emerged, specializing in bypassing these registration barriers, such as email, phone, and CAPTCHA confirmation [33, 23, 21]. Several websites and internet forums now offer services that allow adversaries to easily obtain large networks of Sybil accounts or followers. For example, Hotmail and Yahoo accounts are available on blackhatworld.com for $6 per thousand, while Twitter accounts from the same forum are priced at $40 per thousand. Consequently, we expect that combining these ad hoc mechanisms with social Sybil defenses will increase the cost of performing temporal attacks, much like CAPTCHAs increase the cost of spam [21]. However, these measures do not fundamentally mitigate our attacks, highlighting the need for improved defenses.

### 7.2 System-Specific Countermeasures

#### Batch Mode Enforcement for SybilLimit
To rate-limit the re-registration of new Sybils, a simple countermeasure is for honest nodes to process protocol messages (such as incoming random route requests) in batch mode, say every x time units. This means that if an attacker tries to introduce multiple Sybil identities using the registration slot (tail), it can only do so once every x time units. 

This countermeasure introduces a trade-off between usability and security. As the time period x increases, the system's security improves because the attacker must wait longer before replacing existing Sybil identities. Conversely, increasing x adversely impacts the system's usability, as new honest nodes have to wait longer to set up their random routes and get validated. Note that this defense only slows down the rate of attack; it does not fundamentally mitigate the observations that (a) over time, an adversary can insert different Sybil identities into the system (bounded), and (b) given enough time, an adversary can insert an unbounded number of Sybil identities at a single instant.

#### Bound the Variance for SybilLimit
The second countermeasure involves bounding the variance in the number of new random routes terminating at a node, corresponding to its \(O(\sqrt{m})\) entries. For instance, if, within a time period x, a particular public key entry registered at an honest node A is overwritten many times compared to other public keys registered at node A, this indicates an attack. The parameters for the bound on the variance can be learned using models of honest social network evolution in real-world datasets. Incoming random route messages that violate this condition are ignored.

This countermeasure constrains the effects of an adversary by rate-limiting new random route setups based on models of honest social network evolution. Similar to the previous countermeasure, this approach only slows down the adversary but does not fundamentally mitigate our observations.

#### Moving-Target Defense for SybilInfer and SybilRank
The concept of moving-target defense (MTD) aims to impose asymmetric uncertainty for the attacker by making systems dynamic and harder to predict. By adding randomness to the system, the attacker must use significant resources to study the system, identify vulnerabilities, and deploy attacks. For systems like SybilInfer and SybilRank, which rely on performing random walks from honest trust seeds, MTD can be leveraged by first selecting multiple random seeds and then regularly changing them after a certain time T. Thus, the attacker cannot estimate the location of the trust seeds once and use this information to perform effective attacks indefinitely.

#### Ephemeral Attacker Resource for Persea
The identified problem with Persea is that the resources corresponding to deleted edges cannot be revoked. Therefore, the attacker can change attack edges over time and obtain more system resources. To address this, introducing the concept of "ephemeral resources" ensures that obtained system resources eventually time out (unless renewed). This way, the attacker cannot increase its share of system resources by changing attack edges over time. For Persea, a possible solution is to enforce a timeout T for the ID space of an edge, rendering this ID space invalid once the edge is deleted.

#### Asymmetric Penalty for Ostra and SumUp
The design of Ostra penalizes each edge along the path evenly when the receiver marks the communication traffic as unwanted. To mitigate user targeting and edge targeting attacks, an asymmetric penalty approach can be adopted, where edges close to the sender are penalized more, and edges close to the receiver are penalized less. This makes it more costly for the attacker to target specific users or edges. For SumUp, a similar approach could be adopted by penalizing edges close to the vote collector (i.e., in the lower level) less and penalizing edges far from the vote collector more.

#### Generic Defense via Detecting Anomalous Churn
We now briefly discuss a possible approach to detect anomalous churn in the social graph, which could work on a variety of systems. The key insight is that temporal attacks often rely on the attacker inducing a high rate of churn in the Sybil region, which can be used as a detection point. We propose observing the graph evolution to distinguish the Sybil region from the honest region. For example, one can quantify changes in the neighborhood structure for each user in a time series of graphs using statistical distance metrics and use them as features for detection. Once the Sybil region is detected, Sybil identities and their attack edges can be blocked from the social network, and the process can be repeated.

### 8. Conclusion

In this paper, we explored the temporal dynamics of social Sybil defenses, focusing on churn in the Sybil region, churn in attack edges, and churn in the honest region. We proposed temporal attacks that exploit these system dynamics and investigated the vulnerabilities of various social Sybil defenses. We found that temporal attacks can have devastating consequences for system security, especially for distributed Sybil defenses like SybilLimit and Persea. We also discussed potential countermeasures to prevent these attacks, though carefully designing and evaluating robust countermeasures remains a task for future work. Our work underscores the importance of explicitly considering temporal dynamics in both system design and security evaluation.

### Acknowledgments

We would like to thank the anonymous reviewers at CCS 2015 for their helpful feedback and are especially grateful to Ting Yu for his guidance as our shepherd. This work was supported in part by NSF awards numbers CNS-1423139, CNS-1409415, CNS-1423163, and CNS-0954133.

### 9. References

[1] Known bad relays in Tor. https://trac.torproject.org/projects/tor/wiki/doc/badRelays.
[2] Trotsky IP addresses in Tor. https://trac.torproject.org/projects/tor/wiki/doc/badRelays/trotskyIps.
[3] Ahn, L. V., Blum, M., Hopper, N. J., and Langford, J. CAPTCHA: Using hard AI problems for security. In EUROCRYPT (2003).
[4] Al-Ameen, M. N., and Wright, M. Design and evaluation of Persea, a Sybil-resistant DHT. In ACM ASIACCS (2014), pp. 75–86.
[5] Barabási, A.-L., and Albert, R. Emergence of scaling in random networks. Science 286, 5439 (1999), 509–512.
[6] Bilge, L., Strufe, T., Balzarotti, D., and Kirda, E. All your contacts are belong to us: automated identity theft attacks on social networks. In WWW (2009).
[7] Cao, Q., Sirivianos, M., Yang, X., and Pregueiro, T. Aiding the detection of fake accounts in large-scale social online services. In NSDI (2012).
[8] Danezis, G., and Mittal, P. SybilInfer: Detecting Sybil nodes using social networks. In NDSS (2009).
[9] Douceur, J. The Sybil Attack. In IPTPS (2002).
[10] Ghosh, S., Viswanath, B., Kooti, F., Sharma, N. K., Korlam, G., Benevenuto, F., Ganguly, N., and Gummadi, K. P. Understanding and combating link farming in the Twitter social network. In WWW (2012).
[11] Gilbert, E., and Karahalios, K. Predicting tie strength with social media. In CHI (2009).
[12] Irani, D., Balduzzi, M., Balzarotti, D., Kirda, E., and Pu, C. Reverse social engineering attacks in online social networks. In DIMVA (2011).
[13] Kossinets, G., and Watts, D. J. Empirical analysis of an evolving social network. Science 311, 5757 (2006), 88–90.
[14] Krebs, B. Twitter bots drown out anti-Kremlin tweets, Dec. 2011. https://krebsonsecurity.com/2011/12/twitter-bots-drown-out-anti-kremlin-tweets/.
[15] Lesniewski-Laas, C., and Kaashoek, M. F. Whanaungatanga: A Sybil-proof distributed hash table. In NSDI (2010).
[16] Mislove, A., Post, A., Druschel, P., and Gummadi, K. P. Ostra: Leveraging trust to thwart unwanted communication. In NSDI (2008).
[17] Mislove, A., Viswanath, B., Gummadi, K. P., and Druschel, P. You are who you know: Inferring user profiles in online social networks. In Proceedings of the third ACM international conference on Web search and data mining (2010), ACM, pp. 251–260.
[18] Mittal, P., Caesar, M., and Borisov, N. X-Vine: Secure and pseudonymous routing using social networks. In NDSS (2012).
[19] Mohaisen, A., Hopper, N., and Kim, Y. Keep your friends close: Incorporating trust into social network-based Sybil defenses. In INFOCOM (2011).
[20] Mohaisen, A., Yun, A., and Kim, Y. Measuring the mixing time of social graphs. In IMC (2010).
[21] Motoyama, M., Levchenko, K., Kanich, C., McCoy, D., Voelker, G. M., and Savage, S. Re: CAPTCHAs—understanding CAPTCHA-solving services in an economic context. In USENIX Security Symposium (2010), vol. 10, p. 3.
[22] Thomas, K., Grier, C., and Paxson, V. Adapting social spam infrastructure for political censorship. In LEET (2012).
[23] Thomas, K., Grier, C., Song, D., and Paxson, V. Suspended accounts in retrospect: An analysis of Twitter spam. In ACM IMC (2011), ACM, pp. 243–258.
[24] Thomas, K., Iatskiv, D., Bursztein, E., Pietraszek, T., Grier, C., and McCoy, D. Dialing back abuse on phone-verified accounts. In ACM CCS (2014).
[25] Tong, H., Faloutsos, C., and Pan, J.-Y. Fast random walk with restart and its applications. In ICDM (2006).
[26] Tran, N., Li, J., Subramanian, L., and Chow, S. Optimal Sybil-resilient node admission control. In INFOCOM (2011).
[27] Tran, N., Min, B., Li, J., and Subramanian, L. Sybil-resilient online content voting. In NSDI (2009).
[28] Viswanath, B., Mislove, A., Cha, M., and Gummadi, K. P. On the evolution of user interaction in Facebook. In WOSN (2009).
[29] Viswanath, B., Post, A., Gummadi, K. P., and Mislove, A. An analysis of social network-based Sybil defenses. In SIGCOMM (2010).
[30] Wei, W., Xu, F., Tan, C., and Li, Q. SybilDefender: Defend against Sybil attacks in large social networks. In INFOCOM (2012).
[31] Wilson, C., Boe, B., Sala, A., Puttaswamy, K. P., and Zhao, B. Y. User interactions in social networks and their implications. In Eurosys (2009).
[32] Winter, P., Köwer, R., Mulazzani, M., Huber, M., Schrittwieser, S., Lindskog, S., and Weippl, E. Spoiled onions: Exposing malicious Tor exit relays. In PETS (2014).
[33] Yang, C., Harkreader, R., Zhang, J., Shin, S., and Gu, G. Analyzing spammers’ social networks for fun and profit: A case study of cyber-criminal ecosystem on Twitter. In WWW (2012), ACM, pp. 71–80.
[34] Yang, Z., Wilson, C., Wang, X., Gao, T., Zhao, B. Y., and Dai, Y. Uncovering social network Sybils in the wild. ACM Transactions on Knowledge Discovery from Data (TKDD) 8, 1 (2014), 2.
[35] Yu, H., Gibbons, P. B., Kaminsky, M., and Xiao, F. SybilLimit: A near-optimal social network defense against Sybil attacks. In IEEE S&P (2008).
[36] Yu, H., Kaminsky, M., Gibbons, P., and Flaxman, A. SybilGuard: Defending against Sybil attacks via social networks. In SIGCOMM (2006).