7.1 Economic Considerations
Our attack model in Section 3.2 assumes that an adver-
sary that can induce churn in the Sybil region via creation
and deletion of Sybil identities. This is consistent with the
threat model of social Sybil defenses, which typically assume
that such operations have no cost for an adversary [35, 8].
In practice, social networks employ a range of defense mech-
anisms that raise the bar for an adversary, including account
registration barriers such as CAPTCHAs, email and phone
conﬁrmation, and IP blacklists [3, 24]. Thus creation and
deletion of Sybil identities has an economic impact on the
adversary, in terms of the resources required to circumvent
registration barriers.
In recent years, however, there has been an emergence of
an underground market that specializes in bypassing regis-
tration barriers such as email, phone, and CAPTCHA con-
Number of messages020406080100Fraction of available edges00.20.40.60.81Number of messages0100200300400500Fraction of available edges00.20.40.60.81814ﬁrmation [33, 23, 21]. In fact, a number of websites and In-
ternet forums have emerged that allow adversaries to easily
obtain a large network of Sybil accounts (or followers)1,2,3.
For example, Hotmail and Yahoo accounts are available on
blackhatworld.com for $6 per thousand, while Twitter ac-
counts from the same forum are $40 per thousand. Thus,
we expect that the combination of such ad hoc mechanisms
with social Sybil defenses should increase the cost of per-
forming temporal attacks, much as CAPTCHAs increase the
cost of spam [21]. They do not fundamentally mitigate our
attacks, however, motivating the search for improved de-
fenses.
7.2 System-speciﬁc Countermeasures
Batch mode enforcement for SybilLimit: To rate limit
the re-registration of new Sybils, a simple countermeasure
is for honest nodes to process protocol messages (such as in-
coming random route requests) in a batch mode, say every
x time units. This means that if an attacker tries to in-
troduce multiple Sybil identities using the registration slot
(tail), then it can do so only once every x time units.
This countermeasure introduces a trade-oﬀ between us-
ability and security. Clearly, as the time period x is in-
creased, the security of the system improves as the attacker
has to wait longer before being able to replace its existing
Sybil identities. On the other hand, increasing the time pe-
riod x adversely impacts the usability of the system, since
new honest nodes have to wait longer before being able to
set up their random routes and get validated by the system.
Note that this defense only slows down the rate of attack.
It does not fundamentally mitigate our observations that (a)
over time, an adversary can insert diﬀerent Sybil identities
in the system (bounded), and (b) given enough time, an ad-
versary can insert an unbounded number of Sybil identities
at a single instant of time.
Bound the variance for SybilLimit: The second coun-
termeasure is for honest nodes to bound the variance in the
√
number of new random routes, terminating at itself, cor-
m) entries. For example, if in time
responding to its O(
period x, a particular public key entry registered at an hon-
est node A is overwritten a large number of times, as com-
pared to other public keys registered at node A, then this is
an indication of attack. The parameters for the bound on
the variance can be learned using models of honest social
network evolution in real world datasets. A new incoming
random route message that violates this condition is ignored.
Note that our second countermeasure constrains the ef-
fects of an adversary by rate limiting new random route
setups based on models of honest social network evolution.
Similar to before, this attack also only slows down an adver-
sary, but does not fundamentally mitigate our observations.
Moving-target defense for SybilInfer and SybilRank:
The idea of moving-target defense (MTD) is to impose asym-
metric uncertainty for the attacker by making systems dy-
namic and harder to predict. By adding randomness in the
system, the attacker has to use lots of resource to study the
system, identify its vulnerabilities, and deploy the attacks.
Speciﬁcally for systems like SybilInfer and SybilRank, which
rely on performing random walks from honest trust seeds,
1https://devumi.com/twitter-followers/
2https://www.fastfollowerz.com/
3http://twitterboost.co/
the idea of MTD can be leveraged by ﬁrst selecting multiple
random seeds, and then regularly changing them after some
time T . Thus, the attacker is not able to estimate the loca-
tion of the trust seeds once and use this location information
to perform eﬀective attacks forever.
Ephemeral attacker resource for Persea: The identi-
ﬁed problem with Persea is that the resources correspond-
ing to deleted edges can not be revoked. Thus, the attacker
is able to change attack edges over time and obtain more
system resources. To deal with this, a natural way is to
introduce the concept of “ephemeral resources”, such that
the obtained system resources eventually time out (unless
renewed). Thus, the attacker would not be able to increase
its share of system resouces by changing attack edges over
time. For Persea, a possible solution is to enforce a timeout
T for the ID space of an edge, so that this ID space will
eventually not be valid once the edge has been deleted.
Asymmetric penalty for Ostra and SumUp: The de-
sign of Ostra penalizes each edge along the path evenly once
the receiver marks the communication traﬃc as unwanted.
To mitigate the previously discussed user targeting and edge
targeting attacks, we may adopt an asymmetric penalty ap-
proach, by penalizing edges close to the sender more and
penalizing edges close to the receiver less. Thus, the at-
tacker would lose more attack edges to attack a target/set
of edges, comparing to the previous symmetric penalty ap-
proach. For SumUp, a similar approach could be adopted by
penalizing edges close to the vote collector (i.e., in the lower
level) less and penalizing edges far from the vote collector
more.
Generic Defense via Detecting Anomalous Churn:
We now brieﬂy discuss a possible approach to detect anoma-
lous churn in the social graph that could work on a variety of
systems. The key insight is that temporal attacks often rely
on the attacker inducing a high rate of churn in the Sybil
region, which can be used as a point of detection. Thus, we
propose to observe the graph evolution to distinguish the
Sybil region from the honest region. For example, one can
quantify change in the neighborhood structure for each user
in a time series of graphs, using statistical distance metrics,
and use them as a feature for detection. Once the Sybil re-
gion is detected, Sybil identities and their attack edges can
then be blocked from the social network (and the process is
repeated).
8. CONCLUSION
In this paper, we explored temporal dynamics of social
Sybil defenses: churn in the Sybil region, churn in attack
edges, and churn in the honest region. We proposed tempo-
ral attacks that exploit these system dynamics and investi-
gated the vulnerabilities of a variety of social Sybil defenses.
We ﬁnd that temporal attacks can have devastating conse-
quences for system security, specially for distributed Sybil
defenses such as SybilLimit and Persea. We also discussed
proposed possible countermeasures that could be used to
prevent these attacks, though carefully designing and evalu-
ating robust countermeasures remains for future work. Our
work motivates the importance of explicitly considering tem-
poral dynamics in both system design and system security
evaluation.
815Acknowledgments
We would like to thank the anonymous reviewers at CCS
2015 for helpful feedback, and we are especially grateful to
Ting Yu for his guidance as our shepherd. This work was
supported in part by NSF awards number CNS-1423139,
CNS-1409415, CNS-1423163 and CNS-0954133.
9. REFERENCES
[1] Known bad relays in Tor. https://trac.torproject.
org/projects/tor/wiki/doc/badRelays.
[2] Trotsky IP addresses in Tor.
https://trac.torproject.org/projects/tor/wiki/
doc/badRelays/trotskyIps.
[3] Ahn, L. V., Blum, M., Hopper, N. J., and
Langford, J. Captcha: Using hard ai problems for
security. In EUROCRYPT (2003).
[4] Al-Ameen, M. N., and Wright, M. Design and
evaluation of Persea, a Sybil-resistant DHT. In ACM
ASIACCS (2014), pp. 75–86.
[5] Barab´asi, A.-L., and Albert, R. Emergence of
scaling in random networks. science 286, 5439 (1999),
509–512.
[6] Bilge, L., Strufe, T., Balzarotti, D., and
Kirda, E. All your contacts are belong to us:
automated identity theft attacks on social networks.
In WWW (2009).
[7] Cao, Q., Sirivianos, M., Yang, X., and
Pregueiro, T. Aiding the detection of fake accounts
in large scale social online services. In NSDI (2012).
[8] Danezis, G., and Mittal, P. Sybilinfer: Detecting
Sybil nodes using social networks. In NDSS (2009).
[9] Douceur, J. The Sybil Attack. In IPTPS (2002).
[10] Ghosh, S., Viswanath, B., Kooti, F., Sharma,
N. K., Korlam, G., Benevenuto, F., Ganguly,
N., and Gummadi, K. P. Understanding and
combating link farming in the twitter social network.
In WWW (2012).
[11] Gilbert, E., and Karahalios, K. Predicting tie
strength with social media. In CHI (2009).
[12] Irani, D., Balduzzi, M., Balzarotti, D., Kirda,
E., and Pu, C. Reverse social engineering attacks in
online social networks. In DIMVA (2011).
[13] Kossinets, G., and Watts, D. J. Empirical analysis
of an evolving social network. Science 311, 5757
(2006), 88–90.
[14] Krebs, B. Twitter bots drown out anti-kremlin
tweets, Dec. 2011.
https://krebsonsecurity.com/2011/12/
twitter-bots-drown-out-anti-kremlin-tweets/.
[15] Lesniewski-Laas, C., and Kaashoek, M. F.
Whanaungatanga: A Sybil-proof distributed hash
table. In NSDI (2010).
[16] Mislove, A., Post, A., Druschel, P., and
Gummadi, K. P. Ostra: leveraging trust to thwart
unwanted communication. In NSDI (2008).
[17] Mislove, A., Viswanath, B., Gummadi, K. P., and
Druschel, P. You are who you know: inferring user
proﬁles in online social networks. In Proceedings of the
third ACM international conference on Web search
and data mining (2010), ACM, pp. 251–260.
[18] Mittal, P., Caesar, M., and Borisov, N. X-vine:
Secure and pseudonymous routing using social
networks. In NDSS (2012).
[19] Mohaisen, A., Hopper, N., and Kim, Y. Keep your
friends close: Incorporating trust into social
network-based Sybil defenses. In INFOCOM (2011).
[20] Mohaisen, A., Yun, A., and Kim, Y. Measuring the
mixing time of social graphs. In IMC (2010).
[21] Motoyama, M., Levchenko, K., Kanich, C.,
McCoy, D., Voelker, G. M., and Savage, S. Re:
Captchas-understanding captcha-solving services in an
economic context. In USENIX Security Symposium
(2010), vol. 10, p. 3.
[22] Thomas, K., Grier, C., and Paxson, V. Adapting
social spam infrastructure for political censorship. In
LEET (2012).
[23] Thomas, K., Grier, C., Song, D., and Paxson, V.
Suspended accounts in retrospect: an analysis of
twitter spam. In ACM IMC (2011), ACM,
pp. 243–258.
[24] Thomas, K., Iatskiv, D., Bursztein, E.,
Pietraszek, T., Grier, C., and McCoy, D.
Dialing back abuse on phone veriﬁed accounts. In
ACM CCS (2014).
[25] Tong, H., Faloutsos, C., and Pan, J.-Y. Fast
random walk with restart and its applications. In
ICDM (2006).
[26] Tran, N., Li, J., Subramanian, L., and Chow, S.
Optimal Sybil-resilient node admission control. In
INFOCOM (2011).
[27] Tran, N., Min, B., Li, J., and Subramanian, L.
Sybil-resilient online content voting. In NSDI (2009).
[28] Viswanath, B., Mislove, A., Cha, M., and
Gummadi, K. P. On the evolution of user interaction
in Facebook. In WOSN (2009).
[29] Viswanath, B., Post, A., Gummadi, K. P., and
Mislove, A. An analysis of social network-based
Sybil defenses. In SIGCOMM (2010).
[30] Wei, W., Xu, F., Tan, C., and Li, Q.
Sybildefender: Defend against Sybil attacks in large
social networks. In INFOCOM (2012).
[31] Wilson, C., Boe, B., Sala, A., Puttaswamy,
K. P., and Zhao, B. Y. User interactions in social
networks and their implications. In Eurosys (2009).
[32] Winter, P., K¨ower, R., Mulazzani, M., Huber,
M., Schrittwieser, S., Lindskog, S., and Weippl,
E. Spoiled onions: Exposing malicious Tor exit relays.
In PETS (2014).
[33] Yang, C., Harkreader, R., Zhang, J., Shin, S.,
and Gu, G. Analyzing spammers’ social networks for
fun and proﬁt: a case study of cyber criminal
ecosystem on twitter. In WWW (2012), ACM,
pp. 71–80.
[34] Yang, Z., Wilson, C., Wang, X., Gao, T., Zhao,
B. Y., and Dai, Y. Uncovering social network sybils
in the wild. ACM Transactions on Knowledge
Discovery from Data (TKDD) 8, 1 (2014), 2.
[35] Yu, H., Gibbons, P. B., Kaminsky, M., and Xiao,
F. Sybillimit: A near-optimal social network defense
against Sybil attacks. In IEEE S&P (2008).
[36] Yu, H., Kaminsky, M., Gibbons, P., and
Flaxman, A. SybilGuard: Defending against Sybil
attacks via social networks. In SIGCOMM (2006).
816