MaxTime
Local
Progressive
ASAP
MaxTime
Local
40
60
80
100
120
40
60
80
100
120
time bound u (s)
time bound u (s)
Fig. 5. Probabilities of system failure containing DPUs without (left) and
with (right) repair.
rates has been applied to make the (lack of) effect of the
strategies more clear.
To connect the error speciﬁcations with the components,
fault injections have been speciﬁed which affect the power
and control signals. In case of a fault (be it transient, hot or
permanent), either power is disabled, or the signal set to false,
indicating a failure.
The case study itself consists of approximately 800 lines
of SLIM code, featuring 20 nominal and error component
deﬁnitions and 37 component instances. Furthermore, 20 fault
injections were speciﬁed. The case study and tool are accessible
from [16].
d) Experimental Results: In order to evaluate the relia-
bility of the system, probabilistic reachability properties were
deﬁned, evaluating the probability of a system failure occurring.
The system is considered failed if control of the thrusters is
lost, which happens if neither triplex can send a command
to the thrusters because it has failed. This property has been
speciﬁed using the probabilistic existence pattern, which can
be translated into the CSL formula Pr((cid:10)[0,u]failure), where
failure is an atomic proposition indicating failure, in this case
both triplex commands being false and the system being in
ﬂight. Here, u controls the upper time-bound of the property.
Figure 5 shows the evaluation results for the two versions
for the case study with permanent (left graph) and recoverable
(right graph) faults for the DPUs (experiments were run with
parameters δ = 0.9 and  = 0.005). In the left graph, the
results are the same for all possible strategies. This is due
to the fact that the behavior of the model only contains
probabilistic or deterministic transitions, thus time scheduling
has no effect. In the right graph, the different strategies result in
different behavior, due to the non-deterministic delay required
for recovery. The ASAP strategy always schedules the repair too
early, whereas the MaxTime strategy never does so. The Local
and Progressive strategies are somewhere in between, randomly
selecting delays before restarting a DPU. The Progressive
strategy performs slightly better, as it makes it more likely
for the DPU error model to preempt a too early recovery
attempt.
VI. RELATED WORK
Statistical model checking is an active ﬁeld, and there is
a fair amount of past and current research. On the practical
side, various tools have been developed that make use of this
technique as well. Tools such as YMER [21], (P)Vesta [26],
[27], MRMC [24], and APMC [7] allow various Markov models
to be analyzed by statistical means. More recently, and more
closely related to our tool, the MODES [4] and UPPAAL-
SMC [3] tools have been developed, which support real-time
stochastic models, introducing support for underspeciﬁcation
of time. Aside from the input language, these tools differ from
ours mainly on the semantics of the input language, as well as
the possible scheduling approaches. A major difference between
UPPAAL-SMC and our tool is that UPPAAL-SMC supports
broadcast events only. For MODES, the main difference is that
only the ASAP strategy is supported. The PLASMA-lab [5]
and Prism [28] tools ﬁnd their way in the middle, supporting
non-deterministic, but not real-timed, models speciﬁed in the
Prism Reactive Modules language.
An important aspect of statistical model checking lies in the
scope of rare-events: occurrences of behavior that only occur
with a very low probability. Whereas model checking using the
full state space guarantees such events are detected, they are
inherently unlikely to be found by regular statistical analysis.
Various methods are introduced to support rare-event simulation
for discrete systems [29], [30], [31], [32], which introduce a
bias in the model to make such events more likely to occur,
adjusting the ﬁnal probability to take this into account.
One particular downside of using statistical model check-
ing for non-deterministic models such as ours is that it is
currently not possible to accurately determine the possible
lower and upper bounds of the properties’ probability. Various
approaches are suggested to address this, such as reinforcement
learning [33] or deﬁning history-dependent schedulers [34].
Finally, an important aspect of the efﬁciency of the simulator
is the number of paths that it requires to determine the ﬁnal
outcome. Various methods exist to ﬁnd such bounds. The
Chernoff-Hoeffding bound of our implementation is well known,
but other approaches exist, both for quantitative and qualitative
analysis. The work of [20] introduces various tests, and
classiﬁes them according to correctness, power and efﬁciency.
VII. CONCLUSION
This paper introduced our statistical model checker for
the COMPASS toolset, supporting an AADL dialect input
formalism (SLIM) with linear-hybrid and stochastic aspects.
The main aim is to support performability analysis (that is,
probabilistic dependability) for which no tools existed that
supported the SLIM semantics.
The Monte Carlo method was chosen as it provides a
tractable, yet powerful approach to support the combination of
real-time and stochastic semantics. By allowing the implemen-
tation of various strategies, we address the issue of different
possible interpretation of non-determinism which is inherently
required for the path generation.
The tool has been integrated into the existing COMPASS
toolset, allowing it to be used alongside the various other
analyses that it supports, and integrating it into both a GUI
and CLI based system.
A benchmark and an industrial case study of a launcher show
that the use of Monte Carlo simulation is a viable approach.
Although it shows that for smaller discrete model it can be
outperformed by the existing tool-chain, for larger models, or
timed models, simulation can be a better alternative.
8787
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:48:59 UTC from IEEE Xplore.  Restrictions apply. 
A. Future Work
One point of improvement is more complete support for path
generation strategies, giving the user more control to steer the
simulation, for instance regarding non-deterministic transitions.
This also includes controlling the scheduling order of transitions
and the memory policies [18] being used. Automating or
guiding the strategy selection would help improve usability, as
this requires a less intricate knowledge of the methods.
Another item of interest is support for the full spectrum of
CSL speciﬁcations [35], beyond the predeﬁned patterns of the
COMPASS toolset. This would include nested operators. The
work of [21] shows that this has a fairly high complexity, but
is manageable by using memoization techniques.
ACKNOWLEDGMENTS
The authors would like to thank Sebastian Junges and Jens
Katelaan for their help in designing and building the simulator.
This work was partially supported by ESA/ESTEC (contract
no. 4000107221 (HASDEL)) and the EU (project reference
318490 (SENSATION)).
REFERENCES
[1] P. H. Feiler and D. P. Gluch, Model-Based Engineering with AADL:
An Introduction to the SAE Architecture Analysis & Design Language,
1st ed. Addison-Wesley Professional, 2012.
[2] COMPASS Consortium, “COMPASS toolset web-site,” http://compass.
informatik.rwth-aachen.de, [Online; accessed 8-December-2014].
[3] P. Bulychev, A. David, K. G. Larsen, M. Mikuˇcionis, D. Bøgsted Poulsen,
A. Legay, and Z. Wang, “UPPAAL-SMC: Statistical Model Checking
for Priced Timed Automata,” in QAPL, ser. EPTCS, vol. 85. Open
Publishing Association, 2012, pp. 1–16.
J. Bogdoll, A. Hartmanns, and H. Hermanns, “Simulation and Statistical
Model Checking for Modestly Nondeterministic Models,” in MMB/DFT,
ser. LNCS, vol. 7201. Springer, 2012, pp. 249–252.
[4]
[5] B. Boyer, K. Corre, A. Legay, and S. Sedwards, “PLASMA-lab: A
Flexible, Distributable Statistical Model Checking Library,” in QEST,
ser. LNCS, vol. 8054. Springer, 2013, pp. 160–164.
[6] A. Legay, B. Delahaye, and S. Bensalem, “Statistical Model Checking:
Springer, 2010, pp.
An Overview,” in RV, ser. LNCS, vol. 6418.
122–135.
[7] T. H´erault, R. Lassaigne, F. Magniette, and S. Peyronnet, “Approximate
Probabilistic Model Checking,” in VMCAI, ser. LNCS. Springer, 2004,
vol. 2937, pp. 73–84.
[8] M. Bozzano, A. Cimatti, J.-P. Katoen, V. Y. Nguyen, T. Noll, and
M. Roveri, “Safety, dependability and performance analysis of extended
aadl models,” Comput. J., vol. 54, no. 5, pp. 754–775, 2011.
[9] M.-A. Esteve, J.-P. Katoen, V. Y. Nguyen, B. Postma, and Y. Yushtein,
“Formal Correctness, Safety, Dependability, and Performance Analysis of
a Satellite,” in ICSE, ser. ICSE ’12.
IEEE Press, 2012, pp. 1022–1031.
[10] M. Bozzano, A. Cimatti, J.-P. Katoen, P. Katsaros, K. Mokos, V. Y.
Nguyen, T. Noll, B. Postma, and M. Roveri, “Spacecraft early design
validation using formal methods,” RESS, vol. 132, no. 0, pp. 20–35,
2014.
[11] A. Cimatti, E. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore,
M. Roveri, R. Sebastiani, and A. Tacchella, “Nusmv 2: An opensource
tool for symbolic model checking,” in CAV, ser. LNCS, vol. 2404.
Springer, 2002, pp. 359–364.
[12] G. Audemard, A. Cimatti, A. Kornilowicz, and R. Sebastiani, “Bounded
model checking for timed systems,” in Formal Techniques for Networked
and Distributed Sytems–FORTE 2002, ser. LNCS, vol. 2529. Springer,
2002, pp. 243–259.
[13] H. Hermanns and J.-P. Katoen, “The how and why of interactive markov
chains,” in FMCO, ser. LNCS, F. S. de Boer, M. M. Bonsangue,
S. Hallerstede, and M. Leuschel, Eds.
Springer, 2010, vol. 6286,
pp. 311–337.
8888
[14] P. Bertoli, M. Bozzano, and A. Cimatti, “A Symbolic Model Checking
Framework for Safety Analysis, Diagnosis, and Synthesis,” in Model
Checking and Artiﬁcial Intelligence, ser. LNCS, vol. 4428. Springer,
2007, pp. 1–18.
[15] M. Bozzano, A. Cimatti, J.-P. Katoen, V. Y. Nguyen, T. Noll, and
M. Roveri, “The COMPASS approach: Correctness, modelling and
performability of aerospace systems,” in Computer Safety, Reliability,
and Security, ser. LNCS, vol. 5775. Springer, 2009, pp. 173–186.
[16] H. Bruintjes, “Tool and case study download,” http://compass.informatik.
rwth-aachen.de/slimsim dsn, [Online; accessed 8-December-2014].
[17] H. Bohnenkamp, P. R. D’Argenio, H. Hermanns, and J.-P. Katoen,
“MODEST: A Compositional Modeling Formalism for Hard and Softly
Timed Systems,” IEEE TSE, vol. 32, no. 10, pp. 812–830, 2006.
[18] D. Bohlender, H. Bruintjes, S. Junges, J. Katelaan, V. Y. Nguyen, and
T. Noll, “A Review of Statistical Model Checking Pitfalls on Real-Time
Stochastic Models,” in ISoLA, ser. LNCS, vol. 8803. Springer, 2014,
pp. 177–192.
[19] K. L. McMillan, “The SMV language,” Technical report, Cadence
Berkeley Labs, Tech. Rep., 1999.
[20] D. Reijsbergen, P.-T. de Boer, W. Scheinhardt, and B. Haverkort, “On
hypothesis testing for statistical model checking,” STTT, pp. 1–19, 2014.
[21] H. L. S. Younes, “Ymer: A Statistical Model Checker,” in CAV, ser.
LNCS, vol. 3576. Springer, 2005, pp. 429–433.
[22] P. Bulychev, A. David, K. G. Larsen, A. Legay, and M. Mikuˇcionis and
Danny Bøgsted Poulsen, “Checking and distributing statistical model
checking,” in NASA Formal Methods, ser. LNCS, vol. 7226. Springer,
2012, pp. 449–463.
[23] R. Wimmer, M. Herbstritt, H. Hermanns, K. Strampp, and B. Becker,
“Sigref–a symbolic bisimulation tool box,” in ATVA, ser. LNCS, vol.
4218. Springer, 2006, pp. 477–492.
J.-P. Katoen, I. S. Zapreev, E. M. Hahn, H. Hermanns, and D. N. Jansen,
“The Ins and Outs of The Probabilistic Model Checker MRMC,” in
QEST.
IEEE, 2009, pp. 167–176.
[24]
[25] Y. Yushtein, M. Bozzano, A. Cimatti, J.-P. Katoen, V. Y. Nguyen,
T. Noll, X. Olive, and M. Roveri, “System-software co-engineering:
Dependability and safety perspective,” in SMC-IT.
IEEE, 2011, pp.
18–25.
[26] K. Sen, M. Viswanathan, and G. A. Agha, “VESTA: A Statistical Model-
IEEE
checker and Analyzer for Probabilistic Systems,” in QEST.
Computer Society, 2005, pp. 251–252.
[27] M. AlTurki and J. Meseguer, “PVeStA: A Parallel Statistical Model
Checking and Quantitative Analysis Tool,” in CALCO, ser. LNCS, vol.
6859. Springer, 2011, pp. 386–392.
[28] M. Kwiatkowska, G. Norman, and D. Parker, “PRISM 4.0: Veriﬁcation
of Probabilistic Real-time Systems,” in CAV, ser. LNCS, vol. 6806.
Springer, 2011, pp. 585–591.
[29] G. Rubino and B. Tufﬁn, Rare Event Simulation Using Monte Carlo
Methods. Wiley Publishing, 2009.
[30] D. Reijsbergen, P.-T. de Boer, W. Scheinhardt, and B. Haverkort, “Rare
event simulation for highly dependable systems with fast repairs ,”
Performance Evaluation, vol. 69, no. 78, pp. 336 – 355, 2012.
[31] D. Reijsbergen, P.-T. de Boer, B. Haverkort, and W. Scheinhardt,
“Automated Rare Event Simulation for Stochastic Petri Nets,” in QEST,
ser. LNCS, vol. 8054. Springer, 2013, pp. 372–388.
[32] C. J´egourel and Axel Legay and Sean Sedwards, “An Effective Heuristic
for Adaptive Importance Splitting in Statistical Model Checking,” in
ISoLA, ser. LNCS, vol. 8803. Springer, 2014, pp. 143–159.
[33] D. Henriques, J. Martins, P. Zuliani, A. Platzer, and E. M. Clarke,
“Statistical Model Checking for Markov Decision Processes,” in QEST.
IEEE, 2012, pp. 84–93.
[34] P. D’Argenio, A. Legay, S. Sedwards, and L.-M. Traonouez,
“Smart Sampling for Lightweight Veriﬁcation of Markov Decision
Processes,” CoRR, vol. abs/1409.2116, 2014. [Online]. Available:
http://arxiv.org/abs/1409.2116
[35] C. Baier, B. Haverkort, H. Hermanns, and J.-P. Katoen, “Model Checking
Algorithms for Continuous-Time Markov Chains,” IEEE TSE, vol. 29,
no. 6, pp. 524–541, 2003.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:48:59 UTC from IEEE Xplore.  Restrictions apply.