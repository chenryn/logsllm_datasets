### None of these recordings are included in the publications of existing detectors.
#BHUSA @BlackHatEvents
**Information Classification: General**

### Selected Existing Detectors
- **Deep4SNet**: 
  - **Description**: Latest computer vision (CV)-based approach.
  - **Implementation**: We use the open-sourced implementation provided by the original authors.
- **RawNet2**: 
  - **Description**: End-to-end (E2E) based approach, used as a baseline in ASVspoof 2021.
  - **Implementation**: We use the open-sourced implementation from ASVspoof 2021.
- **Farid et al.**:
  - **Description**: First CV-based approach presented at a top conference.
  - **Implementation**: We use the open-sourced implementation from BlackHat USA 2019.
- **DeepSonar** (Not selected):
  - **Description**: First neural network feature (NNF)-based approach.
  - **Note**: No open-source implementation is available. We have attempted to contact the authors but have not received a response.

#BHUSA @BlackHatEvents
**Information Classification: General**

### Real-world False Positive Rate (FPR) of Existing Approaches
- **Objective**: To answer Research Question 1 (RQ1).
- **Environment**: Real-world, with unbalanced samples (human speeches significantly outnumber fake ones).
- **Importance**: FPR is crucial for real-world deployment.
- **Results**: Using baseline datasets, we evaluated the FPR of existing approaches. None of the FPRs were acceptable for real-world use.
- **Answer to RQ1**: No

| Approach   | Language | Baseline | FPR (%) |
|------------|----------|----------|---------|
| Farid et al.| English  | 3,656    | 67.70   |
| Farid et al.| Mandarin | 11,020   | 45.39   |
| Deep4SNet  | English  | 3,597    | 66.61   |
| Deep4SNet  | Mandarin | 22,081   | 90.95   |
| RawNet2    | English  | 5,099    | 94.43   |
| RawNet2    | Mandarin | 11,580   | 47.70   |

#BHUSA @BlackHatEvents
**Information Classification: General**

### Speaker-irrelevant Feature Evaluation
- **Objective**: To answer Research Question 2 (RQ2).
- **Experiment Components**:
  - **Slight Denoise**: Removes background noise without affecting human voice. Theoretically, detection results should remain unchanged.
  - **Silence Removal**: Crops silences before and after human speech. Theoretically, detection results should remain unchanged.

#### Slight Denoise
- **Observation**: All existing approaches are significantly affected by background noise. This suggests that noise in human recordings can help fake voices bypass detection.
- **Comparison with Baseline Results**:

| Approach   | Language | Baseline FPR (%) | DN-FPR (%) | Diff (%) |
|------------|----------|------------------|------------|----------|
| Farid et al.| English  | 67.70            | 75.09      | ↑ 10.92  |
| Farid et al.| Mandarin | 45.39            | 84.37      | ↑ 85.88  |
| Deep4SNet  | English  | 66.61            | 59.85      | ↓ 10.15  |
| Deep4SNet  | Mandarin | 90.95            | 99.37      | ↑ 9.26   |
| RawNet2    | English  | 94.43            | 97.22      | ↑ 2.95   |
| RawNet2    | Mandarin | 47.70            | 55.74      | ↑ 16.86  |

#### Silence Removal
- **Observation**: All existing approaches are significantly affected by meaningless silence. This suggests that the silence part of human recordings can help fake voices bypass detection.
- **Comparison with Baseline Results**:

| Approach   | Language | Baseline FPR (%) | DN-FPR (%) | Diff (%) |
|------------|----------|------------------|------------|----------|
| Farid et al.| Mandarin | 45.39            | 84.37      | ↑ 85.88  |
| Deep4SNet  | Mandarin | 90.95            | 99.37      | ↑ 9.26   |
| RawNet2    | Mandarin | 47.70            | 55.74      | ↑ 16.86  |

#### Conclusion
- **Finding**: Speaker-irrelevant features (background noise and silences) are considered by detection systems as part of the feature vector, which can be exploited to bypass AI-synthesized speech detection.
- **Answer to RQ2**: Yes

#BHUSA @BlackHatEvents
**Information Classification: General**

### Detection Bypass Evaluation
- **Objective**: To answer Research Question 3 (RQ3).
- **Experiment Setup**:
  - **Language**: English only (due to cost reasons).
  - **Baseline Dataset**: Removed falsely reported positive samples.
  - **Generated Recordings**: For each human recording, five new recordings were generated with specific phrases.
- **Phrases**:
  - "I’m not kidding you, this voice is fake."
  - "The weather is really nice today."
  - "I’ve sent you the number via WeChat."
  - "Can you please lend me some money?"
  - "You need to come to the office tomorrow."

- **Observation**: Fake recordings generated by SiF-DeepVC have much higher negative rates, indicating they can effectively deceive existing approaches.
- **Answer to RQ3**: Yes

| Approach   | SiF-DeepVC Recordings | Baseline Original Recordings | Diff (%) |
|------------|-----------------------|------------------------------|----------|
| Farid et al.| 2,823                 | 1,744                        | 32.37    | 32.30    | ↑ 1.00  |
| Deep4SNet  | 6,294                 | 1,803                        | 69.82    | 33.39    | ↑ 109.10|
| RawNet2    | 46                    | 301                          | 3.06     | 5.57     | ↓ 45.06 |
| Average    | 9,136                 | 3,848                        | 47.62    | 23.57    | ↑ 102.86|

#BHUSA @BlackHatEvents
**Information Classification: General**

### Speaker-irrelevant Features on Voice Cloning (VC)
- **Objective**: To answer Research Question 4 (RQ4).
- **Experiment Setup**:
  - **Participants**: 10 participants.
  - **Task**: Listen to selected recordings with headphones and manually verify if they are clear and understandable.
  - **Recordings**:
    - 100 recordings generated by SiF-DeepVC (Output Voice).
    - 100 recordings generated by Voice Cloner (Cloned Voice).
    - 100 recordings from the English baseline dataset (Human Voice).

- **Conclusion**: There is no statistical difference between the clarity and understandability of the voices.
- **Answer to RQ4**: Yes

| Type        | Understandable | Total | Ratio (%) |
|-------------|----------------|-------|-----------|
| Baseline    | 97             | 100   | 97.00     |
| Cloned Voice| 94             | 100   | 94.00     |
| Output Voice| 96             | 100   | 96.00     |

#BHUSA @BlackHatEvents
**Information Classification: General**

### Conclusion
- **Takeaways**:
  - **AI-synthesized Speeches**:
    - Generation methods.
    - Existing detection approaches and their limitations.
    - A novel attack framework to bypass existing detectors.
  - **Defending Against AI-synthesized Speeches**:
    - With SiF-DeepVC, cloned voices can be more "human" than real human voices.
    - Risk warning: Current solutions are far from being "usable."
  - **New Datasets**:
    - We have built and open-sourced several high-quality datasets.

#BHUSA @BlackHatEvents
**Information Classification: General**

### Demos
- **Reproducibility**: We understand the importance of reproducibility. All code and datasets are available.
- **Code Repositories**:
  - Deep4SNet: [GitHub](https://github.com/yohannarodriguez/Deep4SNet)
  - Farid et al.: [GitHub](https://github.com/cmrfrd/DetectingDeepFakes_BlackHat2019)
  - RawNet2: [GitHub](https://github.com/eurecom-asp/rawnet2-antispoofing)
  - RTVC: [GitHub](https://github.com/CorentinJ/Real-Time-Voice-Cloning)
- **Datasets**:
  - Available via Google Drive (zip file, ~7.8 GB).

### Description for Datasets
- **RQ1**:
  - `for-real-validation`: Original human recordings from FoR Validation dataset.
  - `zh-real-test`: Original human recordings from MagicData Test dataset.
- **RQ2**:
  - `for-real-validation-denoised`: Slightly denoised `for-real-validation`.
  - `zh-real-test-denoised`: Slightly denoised `zh-real-test`.
  - `zh-real-test-silenced`: Silence-removed `zh-real-test`.
- **RQ3**:
  - `for-bh-madefake-final-r4k`: Cloned fake voices by SiF-DeepVC for Farid et al.
  - `for-deep4s-madefake-final-r4k`: Cloned fake voices by SiF-DeepVC for Deep4SNet.
  - `for-rawnet-madefake-final-r4k`: Cloned fake voices by SiF-DeepVC for RawNet2.
- **RQ4**:
  - Any sample can be taken for evaluation.

#BHUSA @BlackHatEvents
**Information Classification: General**

### Sadly, We Cannot Really Detect the Fake Voices Now
- **Future Prospects**: Maybe we can do it in the future.

#BHUSA @BlackHatEvents
**Information Classification: General**

### Thanks