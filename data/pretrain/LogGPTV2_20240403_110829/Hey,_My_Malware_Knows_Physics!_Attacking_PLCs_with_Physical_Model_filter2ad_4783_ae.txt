magnitudes and angles, respectively.
10
Fig. 9: Injected Malicious PID Controller
The legitimate OPF’s objective is to minimize the cost
while ensuring the system operates safely. HARVEY imple-
ments a modiﬁed version of the algorithm, malicious optimal
power ﬂow (mOPF), to maximize the cost without the need
for compliance with safety constraints:
max
u
s.t.
c(x,u)
i − Pl
Pg
i − Ql
Qg
∀i, j ∈ N, ∀l ∈ G, ∀k ∈ C
i = ∑
i = ∑
k∈C
k
|Vi||Vk|(Gik cosθik + Bik sinθik)
|Vi||Vk|(Gik sinθik − Bik cosθik)
(5)
where the calculated control commands would maximize the
amount of possible damage to the power system. The calcu-
lated commands are used as set-points to be maintained by
the inner-loop PID controllers. Please note that the speciﬁc
objective function for different malicious goals can be simply
used instead in the formulation above.
Our power system test-bed implements IEEE nine-node
(bus) benchmark topology [15] including three synchronous
power generators and controlled by nine distributed PLCs.
Figure 10 shows the test-bed (top right), its cyber network
topology (top middle), power system topology (top left), Lab-
View control diagram (bottom right), supervisory control and
data acquisition device interconnections (bottom middle), and
monitoring and control operations (bottom left). The model
has three substations and corresponding loads (which con-
sume power). The power nodes are connected through power
transmission lines. To follow real world implementations, we
equipped each substation with protection functions such as
over-current, voltage and frequency, i.e., the substation will
open a transmission line if they carry current beyond its physi-
228922419325406319700100002000030000400005000060000PID (DINT)PID (REAL)Relay LogicAttack CodePID Attack CodeAvailableMemoryCode Size (Bytes)Instruction/CodeUnused MemoryReusable Memorypid_update PUSH     {R4-R6} (collapsed code) STRD.W   R3, R4, [R7,#0x30]  (collapsed code)            ;integration with windup guarding BEQ      loc_81D0 LDR    R3,=windup_guard   ;int_error>windup_guard        ;int_error=windup_guard (collapsed code) LDR       R3,=int_error    ;int_error >= windup_guard (collapsed code) B         loc_81F2 LDR     R3,=int_error  ;int_error-=windup_guard (collapsed code) B       loc_81F2 LDR     R3,=prev_error        ;differentiation (collapsed code) STRD.W  R3,R4,[R7#0x28] LDR     R3,=proportional_gain ;scaling (collapsed code) BL      _muldf3 (collapsed code) LDR     R3,=integral_gain LDRD.W  R0,R1,[R3] LDR     R3,=int_error (collapsed code) BL      _muldf3 (collapsed code) LDR     R3,=derivative_gain (collapsed code) BL      _muldf3 (collapsed code) LDR     R2,=control          ;summation of terms(control=p+i+d) (collapsed code) LDR     R2,=prev_error       ;prev_error=curr_error (collapsed code) POP     {R4-R7,PC} Fig. 10: The Evaluation Smart Grid Test-Bed
cal capacity or cause over-voltage or over-frequency situations.
To monitor the power system, the voltage and current sensors
(phasor measurement units PMUs) send their measurements to
PLC controllers that act as monitoring/control agents and are
responsible for all operational functions in the system.
On the cyber end, the testbed includes a human-machine
interface (HMI) server to provide the system status to the op-
erators through its connections to the PLC. The data exchange
between different ﬁeld devices is established by open platform
communications (OPC) Client I/O servers [38]. Kepware OPC
Server provides embedded drivers to connect to the PLC. The
testbed employs a ReLab device driver to connect to and obtain
measurements (IEEE C37.118) from PMU sensors. Brieﬂy,
using Kepware’s IEC 61850 MMS clients, the KEPServerEX
OPC Server drivers create an interface for any of the OPC
clients running in the network.
We evaluated HARVEY for two attack scenarios.
Steady-state system malicious attack: Repeated heavy load
circuit breaker open/close triggering without loss of power
system stability. In this scenario, the malicious PLC ﬁrmware
randomly (blindly) selects a circuit breaker to attack and
triggers the opening/closing of the breaker several times, i.e.,
a transmission line opened and closed repeatedly. The power
system was able to withstand this attack scenario without
losing the stability since the target circuit breaker load was
in the limits of power system generation reserve capacity. The
SEL-451 PMU is located on generator 1 bus, and the 421-PMU
is located at generator 2 bus. Figure 11 shows the power system
status during the attack that starts at 11.29.30 PM. The circuit
breaker was opened and closed three times sequentially within
ten seconds. The heavy loading in the system deteriorated the
system frequency (Figure 11a) and voltage (Figure 11b). The
AC phase angle difference between generator 1 and generator
2 exceeded permissible limits (Figure 11c). The power ﬂow
magnitudes (Figure 11d) also violated safety thresholds tem-
porarily. As shown, although the instant voltage and frequency
of the system exceeded permissible limits, the power system
was able to withstand this type of attack. During the attack,
HARVEY was able to run the power system model on the
PLC in parallel and generate fake legitimate-looking sensor
that
measurements to be viewed by the operators. Figure 12 shows
the results (before the noise was added for the presentation
clarity). As the attack on the physical plant would result in
noticeable side effects such as equipment operational noise,
HARVEY’s outputs show a minor system perturbation within
safety limits that is normally observed on daily dynamic power
system operations. From the operators’ viewpoint, the system
acts safely and no corrective action is needed.
Adversary–optimal control attack: optimal malicious attack
using real-world control algorithms. In this attack scenario,
HARVEY implements a real-world power system controller
algorithm, called optimal power ﬂow (OPF) [10],
is
widely used in power system control centers internationally.
OPF is implemented as a linear programming function: it
typically ﬁnds the optimal power system control strategy that
minimizes the overall cost while ensuring the system safety.
The system safety is usually deﬁned by a set of lower and
upper bound thresholds for various system parameters such
as power transmission line current capacities, and minimum/-
maximum allowed system frequency 59.5-61Hz (60Hz is the
nominal power grid frequency in USA). The control strategy
is essentially a set of control commands that the PLC sends
to the actuators, e.g., generation set-points to the generators
that mandate how much power each generator should generate.
HARVEY implements the same control algorithm on the PLC
after making three modiﬁcations to the algorithm (we call
it malicious OPF - mOPF): i) it removes the condition that
ensures the system is within safety margins; ii) it replaces
the cost minimization function with maximization so that the
adversarial impact becomes maximum; and iii) HARVEY adds
predeﬁned stealthy conditions to ensure its malicious control
actions do not get noticed/detected by the local operators on
site due to the noise the actions generate. Example conditions
are “no power generator disconnect from the rest of the power
grid” in large power plants, since such disconnects cause a
noticeable sound noise to the potential
local operators. In
practice, there are typically few or no operators present on
remote power system substations. This gives HARVEY more
freedom in terms of what malicious actions it can carry out.
In this attack scenario, HARVEY’s objective was to im-
11
  IEEE 9 Bus Power System Control Area12Gen 1739Gen 2Substation 3Gen 384Substation 165Substation 2PMUPMUPMUPMUPMUPMUPower System Control Area    Control PlaneSubstation 1 RouterSubstation 3 Router Communication LinkSubstation 2RouterIEDsDistributionLinesGenerationUnitSCADAPLCMain	
  Control	
  UnitIED 2Substation MeasurementIED 1Substation MeasurementIED 3Substation MeasurementPLCCentral ControllerOPC UAMiddlewareInformation ExchangeHIL SimulationSCADA PDCMaster SCADAControl CenterSystem OperatorGrid Control ApplicationsState EstimationLoad SheddingWide Area Monitoring and ControlEvent Analysis and Disturbance RecordingProtectionPower FlowEthernetFiber Optic(a) Frequency
(b) Voltage Magnitude
(c) AC Voltage Phase Angle
(d) Power
Fig. 11: Actual Power System Measurements
system. The fabricated fake sensor measurements (Figure 14)
are sent back to the operators’ HMI screens. Consequently,
from the operators’ viewpoint, the underlying power system
follows their expectation, while in reality, the system goes
through serious instability situations facing potential large-
scale failures. An experienced operator might get suspicious
of small disturbances visible in the graph. However, such
disturbances can also occur in normal operation. Similarly, an
automated tool monitoring the ICS must be tolerant to small
disturbances to reduce the number of false positive alarms.
VII. RELATED WORK
We discuss related work on ICS security in terms of
proposed defense mechanisms and possible attacks.
Defense mechanisms have been proposed on network and
host/device levels. SOCCA [53] generates network-level attack
graphs based on Markov decision processes considering the
impact of the adversarial actions on the physical power system.
CPMA [17] uses the ICS attack graphs to perform security-
oriented risk analysis, so-called contingency analysis, regard-
ing potential threats against the power grid. Both solutions
consider PLCs as the interface between cyber and physical
assets of the infrastructures, and identify them as potential
targets by the adversaries. SCPSE [54] and CPAC [21] present
a stateful detection mechanism to detect attacks against control
systems based on the received sensor measurements by the
operators. HARVEY evades such detectors completely through
replacing them with legitimate-looking fake measurements.
Unlike traditional IT cyber networks, ICS networks often
follow well-deﬁned behavioral patterns. Therefore, online ICS
intrusion detection solutions monitor the runtime operation
for anomalous behaviors as opposed to the signature-based
paradigm [13], [31], [51]. Formby et al. [26] employ the
behavioral proﬁles for device ﬁngerprinting and access control.
Security solutions in ICS has to be non-intrusive against safety-
critical operations with real-time constraints that run mostly
on resource-limited embedded devices/controllers [52]. Such
anomaly-based solution cannot identify HARVEY, since it uses
Fig. 12: Fake Measurements to Mislead the Operator
plement mOPF on the PLC to calculate adversary-optimal
control strategy for the power plant. Using the power system’s
safety constraints, HARVEY intercepts the legitimate control
action outputs and instead sends out its optimally-calculated
malicious control commands to the power actuators at speciﬁc
time points. HARVEY sets the nominal frequency reference to
62 Hz, and its malicious controller calculates and sends out
control commands accordingly.
Figure 13 shows the actual power system measurements.
HARVEY makes the power system frequency exceed its safety
margins through its malicious commands (Figure 13a). The
system’s voltage magnitude (Figure 13b), AC voltage phase
angle (Figure 13c), and electric power values (Figure 13d)
experience serious instability as well. However, in order to
mislead the operator, HARVEY implements a legitimate OPF
algorithm in the background to simulate the power system and
calculate individual system parameters assuming that the legit-
imate OPF control commands were carried out on the power
12
Frequency (Hz) Voltage Amplitude (V) Phase Angle (Degrees) Active Power (MW) Active Power (MW) Voltage (V) Frequency (Hz) Time(s) (a) Frequency
(b) Voltage Magnitude
(c) AC Voltage Phase Angle
(d) Power
Fig. 13: Actual Power System Measurements
as HARVEY would feed fake-legitimate-looking measurements
to the PLCs backplane, i.e., HARVEY resides between the
the I/O modules and the backplane. However, a Weaselboard
implementation can prevent arbitrary ﬁrmware updates over
the network. Therefore, an attacker would need to convince
the operator to run a ﬁrmware update with a compromised
ﬁrmware binary ﬁle or use a JTAG implantation to modify the
ﬁrmware.
There have been several security solutions focused on
the detection of ﬁrmware modiﬁcations that could prevent
an attack like HARVEY, e.g., control-ﬂow monitoring solu-
tions [40]. However, our contribution is not in the evasion of
ﬁrmware modiﬁcation attacks, but rather the evasion of intru-
sion detection solutions that sit outside of the PLC. Attacks
such as Ghost in the PLC [3] have shown that these ﬁrmware
modiﬁcation monitoring solutions can be circumvented.
Attacks on ICS and PLCs have grown signiﬁcantly since
their seminal example emergence, the Stuxnet worm [24] that
targeted the Iranian Natanz nuclear enrichment plant. Stuxnet
is categorized as a malicious control command injection attack.
Through four Windows zero-days, Stuxnet compromised HMI
and sent malicious control logic to the PLC. Stuxnet attacks
would be identiﬁed using TSV [34] as violating the plant’s
safety requirements and blocked from the PLC execution.
Similar to Stuxnet, PLC-Blaster worm [12] injects a malicious
control logic on the vulnerable PLCs (Siemens S7-1200v3)
after a network scan. For stealth, PLC-Blaster manipulates
the meta-data of its control logic which will cause the HMI
software (Siemens Step7) to crash when the operator tries to
retrieve information from an infected PLC. This would raise
the operator’s suspicion leading to potential detection. Ghost
in the PLC [3] provided a PLC rootkit that exploited I/O
pin control operations to provide a cyber framework for an
undetectable rootkit. However, the rootkit does not provide a
means of stealthiness with respect to the monitoring entity
overseeing the physical evolution of the system.
On the sensing side, false data injection attacks [33],
[35], [50] have been shown to be capable of misleading the
operators. The attackers in control of a subset of sensors would
send corrupted measurements to control centers to mislead
the state estimation and controller servers. False data injection
Fig. 14: Fake Measurements to Mislead the Operator
the same power model to fake sensor measurements and make
them look normal.
TSV [34] and [55] provide a bump-in-the-wire solution
between the HMI and PLC device to intercept and analyze the
control logic downloads on the PLC by the HMI server. TSV
implements formal methods to verify the safety of the code
regarding the physical plant safety requirements, and drops the
control logic if a counterexample is found. TSV is unable to
detect HARVEY as it targets control logic updates and does not
support ﬁrmware updates or network-level ﬁrmware exploits.
The Weaselboard [36] is a PLC backplane analysis that
captures backplane communications between modules with the
intention of preventing zero-day exploits on PLCs. The inter-
module trafﬁc is forwarded to an external analysis system that
detects changes to process control settings, sensor values, mod-
ule conﬁguration information, ﬁrmware updates, and process
control program (logic) updates. Because the board monitors
backplane communication, HARVEY would remain undetected
13
Frequency (Hz) Voltage Magnitude (V) Phase Angle (Degrees) Active Power (MW) Active Power (MW) Current (A) Frequency (Hz) Time(s) attacks do not consider the operator’s control commands to the
plant, and hence their fabricated system state may not satisfy
the operators’ expectation, and hence can be detected simply.
On the network side, Beresford [8] discovered vulnerabil-
ities in Siemens S7 series communication protocol for replay
attacks leading to a remote shell access. The attack was speciﬁc
to that PLC model number of Siemens only. The similar attacks
on ﬁrmware vulnerabilities (e.g., insecure checksum validation
during the update process [7], DDoS attacks against common
industry protocol CIP package handler functions [44]) are
orthogonal to HARVEY since HARVEY’s core contribution is
to inject and run a power system model as a rootkit (after
the ﬁrmware is compromised) to damage the physical plant
while evading the operator detection. The above-mentioned
PLC attacks did not leverage the domain-speciﬁc features to
i) maximize their destructive physical impact using adversary-
optimal control algorithms, and ii) simulate the physical plant
model
to fabricate legitimate-looking measurements to the
operators.
Klick et al. [32] show that internet-facing controllers can
be compromised, act as a SNMP scanner or SOCKS proxy,
and be misused by an adversary to attack devices that are
not directly connected to the internet. This technique can be
used to extend HARVEY’s compromised devices. Additionally,
there have been theoretical attack frameworks proposed against