network mechanism. Indeed, non-optimized Si-DF has the
best performance: with a TPR of 0.94 and a FPR of 0.005,
previous works would have presented its precision (which is
actually 1-precision) as π1 = 0.995. However, this implicitly
requires an unrealistic r = 1 value; in the more realistic (and
much more difﬁcult) r = 1000 scenario, its 1000-precision is
still low at π1000 = 0.143.
Amongst the attacks to be optimized, the best-performing
though 30–40% of
attacks are Wa-kNN and Pa-CUMUL,
TABLE III: Summary of the seven WF attacks, as well as their baseline 20-precision (π20) and 1000-precision (π1000) using
the non-monitored class strategy (i.e. no optimization).
Name
Bi-XCor [1]
Pa-SVM [20]
Ca-OSAD [3]
Wa-kNN [29]
Ha-kFP [7]
Pa-CUMUL [19]
Si-DF [25]
Classiﬁer
Scoring
SVM
SVM
kNN
SVM
NN
Random Forest
Classiﬁcation mechanism
Cross correlation on inter-packet timing and lengths
SVM on sequence features
Custom SVM kernel using Levenshtein distance
Custom-weighted kNN on sequence features
1000 decision trees on sequence features
SVM on cumulative packet sizes
Neural Network on raw data
π20
.068 ± .001
.510 ± .013
.57 ± .07
.615 ± .012
.53 ± .01
.701 ± .007
.860 ± .018
π1000
.0007 ± .0001
.022 ± .001
.03 ± .01
.032 ± .001
.024 ± .001
.047 ± .002
.143 ± .04
(a) 20-precision for each attack using the best PO.
(b) 1000-precision for each attack using the best PO.
Fig. 2: Overall best optimized 20-precision and 1000-precision results across the three types of POs. The best optimizer used
is written above the chart for each bar. Lighter areas indicate the original precision of each attack in previous work, and the
darker top area indicates the increased new precision achieved with the given PO. An arrow (if shown) jutting out of the bar
indicates that the precision was obtained with the conservative Wilson method.
their classiﬁcations were wrong in the easier π20 scenario
(when about 5% of the user’s page visits are sensitive to
the attacker). In the harder π1000 scenario, all attacks are
imprecise. The results show that the trivial strategy of adding a
non-sensitive class, used in previous work, is unable to achieve
high precision with realistically high r.
All 100,000 packet sequences were part of the testing set
for each attack except Ca-OSAD.3 To form the training set,
we used 10-fold cross validation, so that the training set would
have 100x180+72000 elements and the testing set would have
100x20+8000 elements, and we would repeat this ten times
with ten disparate testing sets. However, we found that this
was impossible for one attack, Ha-KFP, which ran out of
memory. For this attack only, we reduced the training set to
100x20+8000 elements during 10-fold cross validation, similar
in size to their original data set.
k-neighbors strategy. Any classiﬁcation strategy based on
the proximity of the testing element to training elements can
be enhanced with the k-neighbors strategy. When classifying
a testing element, the classiﬁer ﬁnds the k closest training
elements to the testing element. The classiﬁer will output a
positive class only if all k closest training elements belong
to that positive class. Otherwise, the classiﬁer will output the
negative class, rejecting classiﬁcation. This strategy was seen
in two previous attacks, Wa-kNN and Ha-kFP [7], [29]. Other
3We tested Ca-OSAD only on 100x100+10000 elements because of the
computational time involved to compute the custom SVM distance kernel,
which scales with the square of the number of instances. On the full data set,
it would’ve taken around 300,000 CPU hours.
Fig. 3: 1000-precision for Ha-kFP under the k-neighbors
strategy, varying k from 1 to 15.
attacks cannot use this strategy because they do not classify
based on proximity.
We test the effectiveness of this strategy and show π1000 in
Figure 3 for Ha-kFP (the better attack). We varied k from 1
to 15, the same range of values as both previous works. We see
that increasing k improves precision within this range, but not
sufﬁciently signiﬁcantly; its highest value π1000 = 0.04 is still
poor. This strategy also allows Ha-KFP to reach π20 = 0.69
at k = 15. Thus, we ﬁnd that the non-monitored class strategy
and the k-neighbors strategy are both insufﬁcient to achieve
high precision.
B. Conﬁdence-based PO
To classify an input element P , some classiﬁers compute
some matching function match between P and all trained
 0 0.2 0.4 0.6 0.8 1Bi-XCorPa-SVMCa-OSADWa-kNNHa-kFPPa-CUMULDistanceDistanceDistanceConfidenceConfidenceDistanceπ20 0 0.2 0.4 0.6 0.8 1Bi-XCorPa-SVMCa-OSADWa-kNNHa-kFPPa-CUMULEnsembleDistanceDistanceDistanceConfidenceConfidenceDistanceEnsembleπ1000 0 0.01 0.02 0.03 0.04 0.05 0 3 6 9 12 15π1000kclasses C, and classify P to the class that maximizes the value
of the function:
TABLE IV: Best 20-precision (π20) and 1000-precision
(π1000) with conﬁdence-based PO.
argmax
match(P, C)
C
As an example,
in the following we describe the match
function used by Support Vector Machines (SVMs). SVMs are
used by several WF attacks [3], [19], [20], [30]. We specify
the match function for other classiﬁers in the Appendix.
SVMs attempt to ﬁnd an optimal separator between two
classes in training. We denote fC,C(cid:48)(P ) ∈ {C, C(cid:48)} as the
classiﬁcation output of an SVM trained on two classes C and
C(cid:48) when classifying P . For multi-class classiﬁcation, SVMs
can use the “one-against-one” classiﬁcation system [4], as
follows. To decide whether or not P belongs to C, the system
computes a score S(P, C):
S(P, C) =(cid:12)(cid:12){C(cid:48) (cid:54)= C|fC,C(cid:48)(P ) = C}(cid:12)(cid:12)
In other words, S(P, C) is the number of classes C(cid:48) such
that the SVM prefers C over C(cid:48) for classifying P . In the end,
the element is classiﬁed to the class with the highest aggregate
score. Therefore, S ﬁts the deﬁnition of the matching function
for SVMs: S(P, C) = match(P, C).
The matching function of a classiﬁer can be interpreted
as its conﬁdence. If match(P, C) is low for all classes, the
classiﬁer is reluctant to classify P to any class. Normally, the
classiﬁer will nevertheless choose the highest-scoring class.
This causes false positives despite the classiﬁer’s uncertainty.
A conﬁdence-based PO would recognize such uncertainty, and
instead classify the element as negative.
Our conﬁdence-based PO works as follows. Suppose that
the classes are ordered from highest match to lowest, such
that C1 matches P the most (i.e. C1 is the assumed class)
, followed by C2, and so on, until CN +1. We ﬁrst scale
all match values linearly so that match(P, C1) = 1 and
(cid:80)K+1
match(P, CN +1) = 0. For parameters K and Mmatch,
we reject classiﬁcation (classify the element as negative) if
i=2 match(P, Ci) > K · Mmatch. In other words, we
classify an element as negative if the top K competing classes
to the assumed class have a mean match score of Mmatch or
above. We vary K and Mmatch and test their effects on r-
precision. The output of match is also useful in cases where
the attacker may want to rank his classiﬁcations, or explicitly
output the conﬁdence of classiﬁcation.
Which attacks apply?
All known attacks in the WF literature can be said to
compute a match(P, C) function for all C and choosing the
highest-scoring class to classify P . Therefore, the conﬁdence-
based PO applies to all of our classiﬁers.
Results
We present the results of conﬁdence-based PO with regards
to how it improves r-precision of our chosen WF attacks in
Table IV.
Optimized Ha-kFP becomes highly precise even under the
difﬁcult 1000-precision scenario. In the optimal case (K = 3,
Name
Bi-XCor [1]
Pa-SVM [20]
Ca-OSAD [3]
Wa-kNN [29]
Ha-kFP [7]
Pa-CUMUL [19]
π20
.16 ± .01
.60 ± .02
.77 ± .10
≥ .93
≥ .96
.79 ± .02
π1000
.0040 ± .0002
.031 ± .002
.06 ± .03
≥ .40
≥ .86
.076 ± .005
Mmatch = 0.08), we were able to achieve π1000 > 0.86 as
shown in the table, and the attack achieved no false positives
in all 80,000 non-monitored traces. In fact, if we were using
the Wald method, its mean precision would be much higher
(0.999), but we must use the more conservative Wilson method
as explained in Section II-B.
An attack may seem to achieve a low FPR but still be
insufﬁcient to obtain high precision under π1000; for instance,
optimized Wa-kNN achieved a false positive rate of 0.03%, but
due to its poor true positive rate and the conservative nature
of the Wilson method, it was still unable to beat optimized
Ha-kFP. This shows the importance of the r-precision metric.
Some of the above attacks became many times more pre-
cise under π1000. Bi-XCor became 6 times more precise;
Wa-kNN became at least 13 times more precise; Ha-kFP
became at
least 40 times more precise. The SVM-based
classiﬁers Pa-SVM and Pa-CUMUL gained a relatively small
improvement using conﬁdence-based metrics. This may be
because the SVM match function was not sufﬁciently infor-
mative about classiﬁer conﬁdence.
C. Distance-based PO
Several WF attacks use or induce a notion of distance
between packet sequences when performing classiﬁcation.4
We found that those distances, when used to augment the
normal classiﬁcation algorithm of WF attacks, could serve to
remove questionable positive classiﬁcations and thus improve
precision.
We derived distances between packet sequences based on
known attacks. For example, we deﬁned a distance based
on Pa-SVM by executing its feature extraction algorithm,
and then applying the radial basis function on the extracted
features. From each distance between packet sequences, we
derive a distance between packet sequences and classes. Note
that while classiﬁers always chose the class with the highest
match score, they did not choose the class with the shortest
distance. For details on how we derived distances from WF
attacks, we refer the reader to the Abstract. Then, we tested
two different distance-based POs:
1) Too-far PO: We trained the PO by computing expected
in-class distance (distance between packet sequences of
4In our work, we do not use the strict mathematical deﬁnition of a “metric”
when referring to distances. In particular, many of our distances do not
satisfy the triangle inequality in edge cases. Rather, the distance quantiﬁes
the difference between packet sequences from the classiﬁer’s perspective.
We avoid use of the word “metric” for this reason, opting to use the word
“distance”.
TABLE V: Best π20 and π1000 with the too-far PO and too-close PO on a 100x100+10000 data set.
Name
Bi-XCor [1]
Pa-SVM [20]
Ca-OSAD [3]
Wa-kNN [29]
Ha-kFP [7]
Pa-CUMUL [19]
π20
.42 ± .02
.91 ± .05
.88 ± .10
.93 ± .04
.98 ± .02
.95 ± .04
Too-close PO
.014 ± .004
π1000
≥ .18
≥ .08
≥ .21
≥ .59
≥ .33
Best distance
Wa-kNN
Bi-XCor
Wa-kNN
Bi-XCor
Wa-kNN
Bi-XCor
π20
.46 ± .02
.92 ± .04
.93 ± .09
.94 ± .05
.97 ± .03
.94 ± .05
Too-far PO
π1000
.016 ± 0.001
≥ .21
≥ .14
≥ .30
≥ .39
≥ .27
Best Distance
Wa-kNN
Bi-XCor
Bi-XCor
Bi-XCor
Wa-kNN
Bi-XCor
the same class, for each class). If the distance of a testing
packet sequence to the assumed class was more than
Mf ar times the expected in-class distance, we rejected
classiﬁcation.
2) Too-close PO: If there were at least Mclose classes that
were closer to the packet sequence than its assumed
class, we rejected classiﬁcation.
Which attacks apply?
We tested ﬁve distances, each one based on a different
attack; Ha-kFP did not produce a distance. All classiﬁers can
be optimized with both distance-based POs, even if it itself
does not produce a distance. This means that we have a total
of 60 optimized classiﬁers (two types of POs, ﬁve distances,
six classiﬁers).
Results
We present the results for the two distance-based POs in
Table V for the full data set.
In both cases, we can achieve signiﬁcant increases in both
20-precision and 1000-precision. In particular, Ha-kFP with
Wa-kNN distance reached π20 = .98 and .97 respectively. It
reaches π1000 ≥ .59 and ≥ .39 as well, representing a more
than 20-fold increase in precision compared to no POs.