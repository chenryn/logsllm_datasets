title:Automatic Evaluation of Intrusion Detection Systems
author:Fr&apos;ed&apos;eric Massicotte and
François Gagnon and
Yvan Labiche and
Lionel C. Briand and
Mathieu Couture
Automatic Evaluation of Intrusion Detection Systems 
Frédéric Massicotte 
Canada Communication Research Center 
François Gagnon, Yvan Labiche,  
Lionel Briand and Mathieu Couture 
3701 Carling 
Ottawa, Canada 
Abstract 
their  accuracy.  Only  a 
An  Intrusion  Detection  System  (IDS)  is  a  crucial 
element  of a network security posture. Although there are 
many  IDS  products  available,  it  is  rather  difficult  to  find 
information  about 
few 
organizations  evaluate  these  products.  Furthermore,  the 
data  used  to  test  and  evaluate  these  IDS  is  usually 
proprietary.  Thus,  the  research  community  cannot  easily 
evaluate  the  next  generation  of  IDS.  Toward  this  end, 
DARPA  provided  in  1998,  1999  and  2000  an  Intrusion 
Detection Evaluation Data Set. However, no new data set 
has been released by DARPA since 2000, in part because 
of  the  cumbersomeness  of  the  task.  In  this  paper,  we 
propose  a  strategy 
to  address  certain  aspects  of 
generating  a  publicly  available  documented  data  set  for 
testing and evaluating intrusion detection systems. We also 
present  a  tool  that  automatically  analyzes  and  evaluates 
IDS using our proposed data set. 
1  Introduction 
Since  the DARPA Intrusion Detection Evaluation Data 
Set  [1]  was  made  available  in  1998  and  then  updated  in 
1999 and 2000, no other significant publicly available data 
set  has  been  provided  to  benchmark  Intrusion  Detection 
Systems (IDS). 
Other  organizations  [2,  3]  also  provide  data  sets  of 
traffic traces with attacks and intrusions such as worms and 
denials  of  service.  However,  these  data  sets  are  mainly 
used for the statistical and traffic behavior analysis of large 
traffic  traces  (e.g.,  studying  the  infection  evolution  of 
worms).  These  data  sets  are  very  useful  to  the  security 
research  community,  but 
they  are  not  sufficiently 
documented  for  automated  IDS  testing  and  evaluation. 
Moreover,  these  data  sets  contain  traffic  from  only  4 
different  worms:  Nimda,  Slammer,  W32.Mydoom  and 
Witty; and from only a few denials of service. Thus, these 
data sets contain an insufficient variety of attack instances 
and behaviors to properly test and evaluate IDS. 
This  lack  of  properly  documented  data  sets  for  IDS 
testing and evaluation was mentioned in a NIST report [4], 
which  concludes  with  recommendations  for  IDS  testing 
Carleton University 
1125 Colonel By 
Ottawa, Canada 
research.  In  particular,  the  authors  insist  that  data  sets 
should  contain  realistic  data  and  be  shared  freely  among 
multiple organizations. They also state that there is a  need 
to provide the security community with a large set of attack 
traces.  Such  information  could  be  easily  added  to  and 
would  greatly  augment  existing  vulnerability  databases. 
The  resulting  vulnerability/attack  trace  databases  would 
aid  IDS  testing  researchers  and  would  provide  valuable 
data for IDS developers. 
Data sets used to test IDS can be described by two main 
characteristics:  the  type  of  intrusion  detection  technology 
used  (signature-based  or  anomaly-based)  and  the  location 
of  the  IDS  (host-based  or  network-based).  The  test  cases 
needed  to  evaluate  a  signature  network-based  IDS  are 
significantly  different  from  those  needed  by  an  anomaly 
host-based IDS. 
In this paper, we present both a traffic trace generation 
technique  and  an  IDS  evaluation  framework.  The  former, 
referred  to a Virtual Network Infrastructure (VNI), allows 
us to automatically generate properly documented data sets 
of  attack  scenarios.  The  latter,  referred  to  as  Intrusion 
Detection  System  Evaluation  Framework  (IDSEF),  allows 
us to automatically test and evaluate IDS using these traffic 
traces. 
The  data  set  generated  by  our  framework,  though 
extensible, is currently specific to signature-based, network 
intrusion detection systems. It currently contains only well-
known  attacks,  without  background  traffic.  The  main 
reason  for  these  two  restrictions  is  that  we  wanted  to  be 
convinced  of  the  feasibility  of  our  approach  to  devise  a 
thorough  experimental  evaluation  of  existing  IDS.  Also, 
the current goal of the data set is not to check whether IDS 
raise  alarms  on  normal  traffic  (which  will  be  the  focus  of 
future  work),  but  rather  to  test  and  evaluate  the  detection 
accuracy of IDS in the case of successful and failed attack 
attempts. 
This  paper  also  reports  on  an  initial  evaluation  of  our 
framework  on  two  well-known  IDS  namely  Snort  [5]  and 
Bro [6]. The experiment showed that properly documented 
data sets such as ours can be used to automatically test and 
evaluate  IDS.  Results  are  encouraging  as  we  are  able  to 
automatically  generate  a  large,  properly  documented  data 
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006set, which is publicly available to the research community, 
and  use  this  data  set  to  perform  an  initial  evaluation  of 
Snort  and  Bro.  This  evaluation  also  identified  many 
problems with Snort and Bro. 
This paper is organized as follows. Section 2 describes 
related  work  on  IDS  testing  and  evaluation.  Section  3 
describes  the  VNI  as  well  as  the  automatic  collection 
process  of  the  data  set  and  the  automatic  documentation 
process.  It  also  summarizes  the  current  contents  of  our 
Intrusion  Detection  Evaluation  data  sets.  Section  4 
describes  the  IDSEF  and  discusses  the  automatic  analysis 
of  the  results.  Section  5  presents  the  results  of  the 
evaluation  of  Snort  and  Bro  using  our  data  set.  The  last 
section concludes this article by outlining future work. 
2  Related Work 
The  relevant  literature  shows  that  many  different 
techniques are  used to test IDS. A classification of testing 
techniques  can  be  found  in  [7].  There  are  two  main 
techniques  for  testing  IDS  detection  accuracy:  the  IDS 
stimulator  approach  and  the  vulnerability  exploitation 
program approach. 
2.1  IDS Stimulators 
Descriptions of the most popular IDS stimulators can be 
found  in  [8,  9,  10,  11].  They  are  used  for  many  testing 
purposes: To generate false alarms by sending packets that 
resemble  well-known  intrusions  [9,  11]  (These  false 
attacks  are  launched  in  combination  with  real  attacks  to 
test  whether  IDS  are  still  able  to  detect  real  attacks  when 
flooded  by  false  alarms  [12]);  for  cross-testing  network-
based IDS signatures and for testing the IDS engine [8] (In 
particular, test cases are generated from the Snort signature 
database  and  launched  against  different  IDS);  and  to 
generate the appropriate traffic by using the IDS signature 
[8,  9,  11].  Thus,  these  tools  rely  on  publicly  available 
signature  databases 
cases. 
Unfortunately,  in  many  situations,  the  needed  signatures 
are undisclosed or not available from vendors. 
to  generate 
the 
test 
2.2  Vulnerability Exploitation Programs 
To  overcome  this  limitation  imposed  by  the  IDS 
vendors, vulnerability exploitation programs can be used to 
generate test cases. IDS evasion techniques such as packet 
fragmentation  can  also  be  applied  to  these  vulnerability 
exploitation  programs  to  further  test  the  accuracy  of  the 
IDS.  The  most  popular  IDS  evasion  techniques  used  by 
hackers  can  be  found  in  [13–19]:  [13]  provides  a 
classification of such IDS evasion techniques. 
The  use  of  vulnerability  exploitation  programs  for IDS 
testing  and  evaluation  usually  implies  building  a  test  bed 
where  the  attacks  are  launched  using  these  vulnerability 
exploitation programs. The attack traffic can be combined 
with  real  or  emulated  normal  traffic  as  background.  The 
traffic is either recorded for off-line IDS testing or the IDS 
are tested in real-time on the test bed network. 
A number of organizations and projects such as [1, 12-
13,  16,  20-24]  have  developed  such  test  beds  and 
techniques. However, we found three major problems with 
the data sets they used for IDS testing and evaluation: their 
availability,  the  documentation  of  their  traffic  traces  and 
their generation processes. 
With the exception of those provided by DARPA, most 
of the data sets used for evaluating and testing IDS are not 
publicly  available.  Since 
traces 
represent the only significant, publicly available data, they 
are  still  used  by  the  security  research  community,  even  if 
they  contain  no  recent  attacks  and  the  techniques  used  to 
create normal traffic has been criticized [25]. 
the  DARPA 
traffic 
Documentation  is  one  of  the  main  problems  with  the 
available  traffic  traces  from  [2,  3]  and  the  DARPA  data 
sets.  To  test  and  evaluate  IDS,  it  is  essential  to  use  a 
properly  documented  data  set.  For  each  attack  in  the  data 
set,  it  is  important  to  know  key  information  such  as  the 
targeted  system  configuration  (operating  system,  targeted 
service)  and 
(vulnerability 
exploitation  program  used,  its  configuration  and  targeted 
vulnerability).  As presented  in Section 4 such information 
allows the automation of IDS testing and evaluation. 
the  attack  specification 
In a number of cases, the generation of traffic traces and 
their  use  during  actual  IDS  testing  and  evaluation  is 
manual or semi-automated. Manual intervention takes time 
and  restricts  the  diversity  and  updatability  of  the  data  set. 
Manual  or  semi-automated  IDS  evaluation  limits  the 
number of test cases the testing techniques are able to use. 
For  instance,  according  to  the  authors  of  [13],  one  of  the 
most recent IDS evaluations by NSS (4th edition) [12] was 
done manually. In addition, some of the tests conducted in 
[24] were done by hand. In [16, 20], the authors used test 
beds  with  real  systems.  Incidentally,  resetting the targeted 
system  to  the  initial  conditions  in  place  before  the  attack 
affected  the  system  is  either  slow  [20]  (reloading  Ghost 
images of the unaffected system) or not automatic. In fact, 
the  number  of  vulnerability  exploitation  programs  used  in 
the data sets discussed in this section is often small and the 
variety of the targeted systems is limited (Section 3.4). 
2.3  Proposed Solution 
The  techniques  proposed  in  this  paper  attempt  to 
overcome these limitations. Our contribution is to propose 
a  virtual  network  infrastructure  (VNI)  that  is  able  to 
generate  a  data  set  that  can  be  shared  with  the  research 
community  and  that  can  be  rapidly  and  automatically 
updated,  documented  and  used  for  IDS  testing  and 
evaluation.  This  system  is  completely  automated  and  can 
generate  a  data set in a  matter of  hours. This  allows us  to 
generate  real  attacks  and  then  quickly  revert  our  test 
network  back  to  its  initial  state  before  each  attack  (see 
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006Section  3).  Our  VNI  is  therefore  able  to  rapidly  and 
efficiently  generate  a  large  data  set  with  hundreds  of 
vulnerability  exploitation  programs  launched  against  a 
large variety of target systems (Section 3.4). Our approach 
is  also  flexible  as  we  can  choose  whether  to  apply  or  not 
IDS  evasion  techniques.  It  can  be  used  to  generate  data 
sets  for  other  purposes:  An  older  version  of  the  VNI  was 
used  to  fingerprint  208  operating systems according to 12 
passive  fingerprint  identification  techniques  [26].  The 
current  version  is  used  to  provide  data  to  the  LEURRE 
[27] and SCRIPTGEN [28] projects of Eurecom. It is also 
updatable:  new  attack  scenarios,  IDS  evasion  techniques, 
and target systems can easily be added. 
3  Virtual Network Infrastructure Overview 
In this section, we first summarize the requirements for 
an  infrastructure  supporting  our  approach  and  discuss  our 
design  choices  (Section  3.1).  We  then  describe  our 
infrastructure  for  collecting  traffic  traces  and  discuss  our 
traffic trace documentation (Sections 3.2 and 3.3). Section 
3.4 then summarizes the current contents of our data set. 
3.1  Infrastructure Requirements 
To  create  a  large  scale  data  set,  a  controlled  network 
infrastructure  had  to  be  developed  to  allow:  (1)  recording 
of  all  network  traffic; (2)  control  of network traffic noise; 
(3)  control  of  attack  propagation;  (4)  usage  of  real  and 
heterogeneous  system  configurations;  and  (5)  fast  attack 
recovery to initial condition state. 
To meet most of these requirements emulators or virtual 
machines are often used. For instance, they are used by the 
security  community  to  construct  virtual  networks  as  they 
provide  traffic  propagation  control  and  reduce  computer 
resources (e.g., [29, 30]). 
it 
fulfilled 
it 
[26]  and 
We  developed  a  controlled  virtual  network  using 
VMware1  5.0  [31].  We  selected  VMware,  among  others 
(e.g.,  [32,  33]),  as  we  already  had  a  positive  experience 
with 
the  aforementioned 
requirements.  It  provides  a  virtual  broadcasting  network 
environment that allows the capture of all communications, 
in  our  case  generated  by  the  attack  within  a  single  traffic 
trace. These traffic traces can then be used to study attack 
behaviors  (req.  1).  This  virtual  network  also  allows  us  to 
control  the  network  traffic  to  create  clean  traces  that  only 
contain  network  traffic  relevant  to  the  attack  scenarios 
(req. 2). With VMware, the attack propagation is confined, 
thus preventing infection of the physical machines running 
the  virtual  network  (req.  3).  VMware  facilitates  the 
creation  of  template  virtual  machines  having  different 
software  configurations  (operating  system,  services,  etc). 
Thus,  it  allows  creation  of  a  database  of  virtual  machine 
templates  that  can  be  used  to  rapidly  deploy  custom 
network  configurations  within  a  single  physical  machine 
1 VMware is a trademark of VMware, inc. 
(req.  4). Also, VMware snapshot allows restoration of  the 
test  network  to  the  state  it  was  in  before  each  attack 
attempt.  All attack scenarios can then  be performed under 
the same initial conditions (req. 5). 
3.2  Collection Process 
The  virtual  network  we  use  to  collect  traffic  traces  is 
shown  in  Figure  1.  It  contains  attack  systems  (Attacker), 
target systems (Target) and network infrastructure services 
and  equipment  such  as  DNS  and  mail  servers.  The  attack 
systems  are  used  to  launch  attacks  against  the  target 
systems by using vulnerability exploitation programs either 
with  or  without  IDS  evasion  techniques.  The  attack 
systems  are  also  used  to  capture  the  packets  that  are 
generated by the execution of the vulnerability exploitation 
programs.  The  network 
infrastructure  services  and 
equipment  ensure  the  network  communications  needed 
while the attack is in progress. 
Each  step  of  our  collection  process  is  indicated  in 
Figure 1. A link between the involved entities, steps 2 to 5 
being repeated for each attack. 
1.  Script  Generation.  This  process  chooses  which 
vulnerability  exploitation  program  (VEP)  will  be  run 
against  a  given  target  system  and  how  it  should  be 
configured.  For  the  current  data  set,  we  decided  to  run 
every  VEP  against  every  target  system  offering  a  service 
on the same port as the VEP targeted service. To automate 
script  generation,  we  built  a  database  containing  the 
complete system configuration for each target template, as 
well as the ports targeted by the VEP we downloaded. 
2. Virtual Network Setup. A different virtual network is 
built  for  every  script.  Each  contains  the  target  virtual 
machine,  the  attacking  virtual  machine  and  some  other 
machines  offering  the  network  services  needed  for  the 
execution of the attack (e.g., DNS server). The coordinator 
opens  the  virtual  network  and  locks  the  resources  (virtual 
machines)  it  uses.  Many  virtual  networks  can  be  setup  in 