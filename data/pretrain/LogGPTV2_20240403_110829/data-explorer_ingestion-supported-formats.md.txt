---
title: Data Formats Supported by Azure Data Explorer for Ingestion
description: Learn about the various data and compression formats supported by Azure Data Explorer for ingestion.
ms.reviewer: tzgitlin
ms.topic: conceptual
ms.date: 09/13/2022
---

# Data Formats Supported by Azure Data Explorer for Ingestion

Data ingestion in Azure Data Explorer is the process of adding data to a table, making it available for querying. For all ingestion methods except `ingest-from-query`, the data must be in one of the supported formats. The following table lists and describes the formats that Azure Data Explorer supports for data ingestion.

> [!NOTE]
> Before ingesting data, ensure that your data is properly formatted and includes the expected fields. We recommend using a preferred validator to confirm the format's validity. Here are some useful validators:
>
> * CSV: http://csvlint.io/
> * JSON: https://jsonlint.com/
>
> For more information on potential ingestion failures, see [Ingestion Failures](kusto/management/ingestion-failures.md) and [Ingestion Error Codes in Azure Data Explorer](error-codes.md).

| Format         | Extension  | Description                                                                 |
|----------------|------------|-----------------------------------------------------------------------------|
| ApacheAvro     | `.avro`    | An [AVRO](https://avro.apache.org/docs/current/) format with support for [logical types](https://avro.apache.org/docs/current/spec.html#Logical+Types). Supported compression codecs: `null`, `deflate`, and `snappy`. Reader implementation is based on the official [Apache Avro library](https://github.com/apache/avro). For more information on ingesting Event Hub Capture Avro files, see [Ingesting Event Hub Capture Avro Files](ingest-data-event-hub-overview.md#schema-mapping-for-event-hub-capture-avro-files). |
| Avro           | `.avro`    | A legacy implementation for [AVRO](https://avro.apache.org/docs/current/) format based on the [.NET library](https://www.nuget.org/packages/Microsoft.Hadoop.Avro). Supported compression codecs: `null` and `deflate` (for `snappy`, use `ApacheAvro` data format). |
| CSV            | `.csv`     | A text file with comma-separated values (`,`). See [RFC 4180: _Common Format and MIME Type for Comma-Separated Values (CSV) Files_](https://www.ietf.org/rfc/rfc4180.txt). |
| JSON           | `.json`    | A text file with JSON objects delimited by `\n` or `\r\n`. See [JSON Lines (JSONL)](http://jsonlines.org/). |
| MultiJSON      | `.multijson` | A text file with a JSON array of property bags (each representing a record), or any number of property bags delimited by whitespace, `\n` or `\r\n`. Each property bag can span multiple lines. |
| ORC            | `.orc`     | An [ORC file](https://en.wikipedia.org/wiki/Apache_ORC). |
| Parquet        | `.parquet` | A [Parquet file](https://en.wikipedia.org/wiki/Apache_Parquet). |
| PSV            | `.psv`     | A text file with pipe-separated values (`|`). |
| RAW            | `.raw`     | A text file whose entire contents is a single string value. |
| SCsv           | `.scsv`    | A text file with semicolon-separated values (`;`). |
| SOHsv          | `.sohsv`   | A text file with SOH-separated values (SOH is ASCII codepoint 1; this format is used by Hive on HDInsight). |
| TSV            | `.tsv`     | A text file with tab-separated values (`\t`). |
| TSVE           | `.tsv`     | A text file with tab-separated values (`\t`). A backslash character (`\`) is used for escaping. |
| TXT            | `.txt`     | A text file with lines delimited by `\n`. Empty lines are skipped. |
| W3CLOGFILE     | `.log`     | [Web log file](https://www.w3.org/TR/WD-logfile.html) format standardized by the W3C. |

> [!NOTE]
> * Ingestion from data storage systems that provide ACID functionality on top of regular Parquet format files (e.g., Apache Iceberg, Apache Hudi, Delta Lake) is not supported.
> * Schema-less Avro is not supported.
> * For more information on ingesting data using `json` or `multijson` formats, refer to [this document](ingest-json-formats.md).

## Supported Data Compression Formats

Blobs and files can be compressed using the following compression algorithms:

| Compression | Extension |
|-------------|-----------|
| GZip        | `.gz`     |
| Zip         | `.zip`    |

Indicate compression by appending the extension to the name of the blob or file. For example:
* `MyData.csv.zip` indicates a blob or a file formatted as CSV, compressed with ZIP (archive or a single file).
* `MyData.json.gz` indicates a blob or a file formatted as JSON, compressed with GZip.

Blob or file names that do not include the format extensions but just the compression (e.g., `MyData.zip`) are also supported. In this case, the file format must be specified as an ingestion property because it cannot be inferred.

> [!NOTE]
> * Some compression formats keep track of the original file extension as part of the compressed stream. This extension is generally ignored for determining the file format. If the file format cannot be determined from the (compressed) blob or file name, it must be specified through the `format` ingestion property.
> * Do not confuse this with the internal (chunk level) compression codec used by `Parquet`, `AVRO`, and `ORC` formats. Internal compression names are usually added to a file name before the file format extension, for example: `file1.gz.parquet`, `file1.snappy.avro`, etc.
> * [Deflate64/Enhanced Deflate](https://en.wikipedia.org/wiki/Deflate#Deflate64/Enhanced_Deflate) Zip compression method is not supported. Note that Windows' built-in Zip compressor may choose to use this compression method for files over 2GB.

## Related Content

* Learn more about [data ingestion](ingest-data-overview.md).
* Learn more about [Azure Data Explorer data ingestion properties](ingestion-properties.md).

---