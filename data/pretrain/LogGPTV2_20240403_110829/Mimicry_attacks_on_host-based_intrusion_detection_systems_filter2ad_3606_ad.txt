with zero mismatches by the database generated earlier.
Note that we were able to transform the original attack se-
quence into a modi(cid:12)ed variant that would not trigger even
a single mismatch but that would have a similarly harmful
e(cid:11)ect.
In other words, there was no need to take advan-
tage of the fact that pH allows a few occasional mismatches
without setting o(cid:11) alarms: our attack would be successful
no matter what setting is chosen for the pH locality frame
count threshold. This makes our successful results all the
more meaningful.
In summary, our experiments indicate that sophisticated
attackers can evade the pH IDS. We were fairly surprised at
the success of the mimicry attack at converting the autowux
script into one that would avoid detection. On (cid:12)rst glance,
we were worried that we would not be able to do much with
this attack script, as its payload contains a fairly unusual-
looking system call sequence. Nonetheless, it seems that the
database of normal system call sequences is rich enough to
allow the attacker considerable power.
Shortcomings. We are aware of several signi(cid:12)cant limita-
tions in our experimental methodology. We have not com-
piled the stealthy sequence in Fig. 1 into a modi(cid:12)ed exploit
script or tried running such a modi(cid:12)ed script against a ma-
chine protected by pH. Moreover, we assumed that we could
modify the autowux exploit sequence so long as this does not
a(cid:11)ect the e(cid:11)ect of a successful attack; however, our exam-
ple would have been more convincing if the attack did not
require modi(cid:12)cations to the original exploit sequence.
Also, we tested only a single exploit script (autowux), a
single vulnerable application (wuftpd), a single operating
system (Redhat Linux), a single system con(cid:12)guration (the
default Redhat 5.0 installation), and a single intrusion de-
tection system (pH). This is enough to establish the pres-
ence of a risk, but it does not provide enough data to assess
the magnitude of the risk or to evaluate how di(cid:11)erences in
operating systems or con(cid:12)gurations might a(cid:11)ect the risk.
We have not tried to assess how practical the attack might
be. We did not study how much e(cid:11)ort or knowledge is re-
quired from an attacker to mount this sort of attack. We
did not empirically test how e(cid:11)ectively one can predict the
con(cid:12)guration and IDS normal database found on the target
host, and we did not measure whether database diversity is
a signi(cid:12)cant barrier to attack. We did not estimate what
percentage of vulnerabilities would both give the attacker
su(cid:14)cient control over the application to mount a mimicry
attack and permit injection of enough foreign code to ex-
ecute the entire stealthy sequence. Also, attacks often get
better over time, and so it may be too soon to draw any
de(cid:12)nite conclusions. Because of all these unknown factors,
more thorough study will be needed before we can con(cid:12)-
dently evaluate the level of risk associated with mimicry
attacks in practice.
7Because pH uses lookahead pairs, stide is more restrictive
than pH. However, the results of the test are still valid:
since our modi(cid:12)ed sequence is accepted by stide, we can
expect that it will be accepted by pH, too.
If anything,
using stide makes our experiment all the more meaningful,
as it indicates that stide-based IDS’s will also be vulnerable
to mimicry attacks.
2627. RELATED WORK
There has been some other recent research into the se-
curity of host-based anomaly detection systems against so-
phisticated, adaptive adversaries.
Wagner and Dean brie(cid:13)y sketched the idea of mimicry
attacks in earlier work [25, x6]. Gi(cid:14)n, Jha, and Miller elab-
orated on this by outlining a metric for susceptibility to eva-
sion attacks based on attack automata [6, x4.5]. Somayaji
suggested that it may be possible in principle, but di(cid:14)cult
in practice, to evade the pH IDS, giving a brief example to
justify this claim [22, x7.5]. None of these papers developed
these ideas in depth or examined the implications for the
(cid:12)eld, but they set the stage for future research.
More recently, and independently, Tan, Killourhy, and
Maxion provided a much more thorough treatment of the
issue [23]. Their research shows how attackers can render
host-based IDS’s blind to the presence of their attacks, and
they presented compelling experimental results to illustrate
the risk. In follow-up work, Tan, McHugh, and Killourhy
re(cid:12)ned the technique and gave further experimental con(cid:12)r-
mation of the risk from such attacks [24]. Their methods
are di(cid:11)erent from those given in this paper, but their results
are in agreement with ours.
8. DISCUSSION
Several lessons suggest themselves after these experiments.
First and foremost, where possible, intrusion detection sys-
tems should be designed to resist mimicry attacks and other
stealthy behavior from sophisticated attackers. Our attacks
also give some speci(cid:12)c guidance to IDS designers. It might
help for IDS’s to observe not only what system calls are at-
tempted but also which ones fail and what error codes are
returned. It might be a good idea to monitor and predict
not only which systems calls are executed but also what ar-
guments are passed; otherwise, the attacker might have too
much leeway. Moreover, the database of normal behavior
should be as minimal and precise as possible, to reduce the
degree of freedom a(cid:11)orded to an attacker.
Second, we recommend that all future published work
proposing new IDS designs include a detailed analysis of the
proposal’s security against evasion attacks. Even if this type
of vulnerability cannot be completely countered through
clever design, it seems worthwhile to evaluate carefully the
risks.
Finally, we encourage IDS designers to publicly release a
full implementation of their designs, to enable independent
security analysis. There were several proposed intrusion de-
tection techniques we would have liked to examine in detail
for this work, but we were unable to do so because we did
not have access to a reference implementation.
9. CONCLUSIONS
We have shown how attackers may be able to evade de-
tection in host-based anomaly intrusion detection systems,
and we have presented initial evidence that some IDS’s may
be vulnerable. It is not clear how serious a threat mimicry
attacks will be in practice. Nonetheless, the lesson is that
it is not enough to merely protect against today’s attacks:
one must also defend against tomorrow’s attacks, keeping in
mind that tomorrow’s attackers might adapt in response to
the protection measures we deploy today. We suggest that
more attention could be paid in the intrusion detection com-
munity to security against adaptive attackers, and we hope
that this will stimulate further research in this area.
10. ACKNOWLEDGEMENTS
We thank Umesh Shankar, Anil Somayaji, and the anony-
mous reviewers for many insightful comments on an earlier
draft of this paper. Also, we are indebted to Somayaji for
making the pH source code publicly available, without which
this research would not have been possible.
11. REFERENCES
[1] M. Chung, N. Puketza, R.A. Olsson, B. Mukherjee,
\Simulating Concurrent Intrusions for Testing
Intrusion Detection Systems: Parallelizing Intrusions,"
National Information Systems Security Conference,
pp.173{183, 1995.
[2] S. Forrest, S.A. Hofmeyr, A. Somayaji, T. A.
Longsta(cid:11), \A Sense of Self for Unix Processes," 1996
IEEE Symposium on Security & Privacy.
[3] S. Forrest, A.S. Perelson, L. Allen, R. Cherukuri,
\Self-Nonself Discrimination in a Computer," 1994
IEEE Symposium on Security & Privacy.
[4] A.K. Ghosh, A. Schwartzbard, M. Schatz, \Learning
Program Behavior Pro(cid:12)les for Intrusion Detection,"
1st USENIX Workshop on Intrusion Detection &
Networking Monitoring, 1999.
[5] A.K. Ghosh, A. Schwartzbard, M. Schatz, \Using
Program Behavior Pro(cid:12)les for Intrusion Detection,"
3rd SANS Workshop on Intrusion Detection &
Response, 1999.
[6] J.T. Gi(cid:14)n, S. Jha, B.P. Miller, \Detecting
Manipulated Remote Call Streams," 11th USENIX
Security Symposium, 2002.
[7] M. Handley, C. Kreibich, V. Paxson, \Network
Intrusion Detection: Evasion, Tra(cid:14)c Normalization,
and End-to-End Protocol Semantics," 10th USENIX
Security Symposium, 2001.
[8] S. Hofmeyr, S. Forrest, A. Somayaji, \Intrusion
Detection Using Sequences of System Calls," Journal
of Computer Security, vol. 6, pp. 151-180, 1998.
[9] G.J. Holzmann, Design and Validation of Computer
Protocols, Prentice-Hall, 1990.
[10] G.J. Holzmann, \The Model Checker Spin," IEEE
Trans. on Software Engineering, Special issue on
Formal Methods in Software Practice, May 1997.
[11] J.E. Hopcroft, J.D. Ullman, Introduction to Automata
Theory, Languages, and Computation,
Addison-Wesley, 1979.
[12] T. Lane, C.E. Brodley, \Sequence Matching and
Learning in Anomaly Detection for Computer
Security," AAAI Workshop: AI Approaches to Fraud
Detection and Risk Management, pp.49{49, 1997.
[13] T. Lane, C.E. Brodley, \Temporal Sequence Learning
and Data Reduction for Anomaly Detection," ACM
Trans. Information & System Security, vol. 2, no. 3,
pp.295{331, 1999.
[14] W. Lee, S.J. Stolfo, \Data Mining Approaches for
Intrusion Detection," 7th USENIX Security
Symposium, 1998.
[15] W. Lee, S.J. Stolfo, K. Mok, \A Data Mining
Framework for Building Intrusion Detection Models,"
263s
s
(cid:0)! Alarm of the old model, we introduce tran-
(s0; : : : ; s4)
(cid:0)! ((s1; : : : ; s4; s); m + 1) for each
sitions ((s0; : : : ; s4); m)
m = 0; 1; : : : ; 6, where we view the notation (q; 7) as short-
hand for the Alarm state. As usual, we introduce self-loops
from Alarm to itself on each system call, and the accepting
states are exactly the non-alarm states. Note that the size
of the automaton has increased by only a small constant
factor, hence this transformation should be practical.
def
As another example, Warrender, et al., propose a slightly
di(cid:11)erent extension, which is more forgiving of occasional
mismatches [26]. They suggest that the IDS should trigger
an alarm only if at least 6 of the last 20 length-6 subtraces
are mismatches. We can model this extension within our
(cid:12)nite-state framework by adding an extra dimension to the
statespace to account for the history of the last 20 subtraces.
= fS (cid:18) f1; 2; : : : ; 20g : jSj (cid:20) 6g denote the set of
Let W
all subsets of f1; 2; : : : ; 20g of cardinality at most 6. Then
the statespace of our re(cid:12)ned (cid:12)nite-state automaton becomes
Q0 def
= (Q (cid:2) W ) [ fAlarmg, and each non-alarm state is a pair
(q; fi1; : : : ; ikg) of a state q 2 Q = (cid:6)5 from the unadorned
model and a list i1; : : : ; ik of times in the recent past where
a mismatch was found. If S is a set of integers, let delay(S)
= fs + 1 : s 2 Sg \ f1; : : : ; 20g.
denote the set delay(S)
(cid:0)! q0 of the old model, we
For each non-alarm transition q
(cid:0)! (q0; delay(S)) for each S 2
introduce transitions (q; S)
(cid:0)! Alarm of
W . Also, for each alarm transition (s0; : : : ; s4)
(cid:0)!
the old model, we introduce transitions ((s0; : : : ; s4); m)
((s1; : : : ; s4; s); delay(S) [ f1g) for each S 2 W . Here we
view the notation (q; S) as short-hand for the Alarm state
when S =2 W , i.e., when jSj > 6. This transformation does
increase the size of the automaton by a noticeable amount:
def
s
s
s
s
namely, by a factor of   20
6
+ (cid:1) (cid:1) (cid:1) +   20
0
In short, we can see that many natural extensions and
variations on the basic IDS scheme can be incorporated
within our framework. We conclude that the idea of mod-
elling an IDS as a (cid:12)nite-state automaton seems broadly ap-
plicable.
= 60460.
IEEE Symposium on Security & Privacy, 1999.
[16] K.L. McMillan, Symbolic Model Checking, Kluwer
Academic Publishers, 1993.
[17] C. Michael, A. Ghosh, \Using Finite Automata to
Mine Execution Data for Intrusion Detection: A
Preliminary Report," RAID 2000, LNCS 1907,
pp.66{79, 2000.
[18] V. Paxson, \Bro: A System for Detecting Network
Intruders in Real-Time," Computer Networks,
31(23{24), pp.2435{2463, 14 Dec. 1999.
[19] T.H. Ptacek, T.N. Newsham, \Insertion, Evasion, and
Denial of Service: Eluding Network Intrusion
Detection," Secure Networks, Jan. 1998.
[20] F. Schneider, \Enforceable security policies," ACM
Transactions on Information & System Security, vol.
3, no. 1, pp.30{50, Feb. 2000.
[21] A. Somayaji, S. Forrest, \Automated Response Using
System-Call Delays," 9th Usenix Security Symposium,
pp.185{197, 2000.
[22] A.B. Somayaji, \Operating System Stability and
Security through Process Homeostasis," Ph.D.
dissertation, Univ. New Mexico, Jul. 2002.
[23] K.M.C. Tan, K.S. Killourhy, R.A. Maxion,
\Undermining an Anomaly-Based Intrusion Detection
System Using Common Exploits," to appear at RAID
2002, 16{18 Oct. 2002.
[24] K. Tan, J. McHugh, K. Killourhy, \Hiding Intrusions:
From the abnormal to the normal and beyond," to
appear at 5th Information Hiding Workshop, 7{9 Oct.
2002.
[25] D. Wagner, D. Dean, \Intrusion Detection via Static
Analysis," IEEE Symposium on Security & Privacy,
2001.
[26] C. Warrender, S. Forrest, B. Pearlmutter, \Detecting
intrusions using system calls: Alternative data
models," 1999 IEEE Symposium on Security &
Privacy.
[27] A. Wespi, M. Dacier, H. Debar, \Intrusion Detection
Using Variable-Length Audit Trail Patterns," RAID
2000, LNCS 1907, pp.110{129, 2000.
APPENDIX
A. EXTENSIONS: HOW TO MODEL MORE
SOPHISTICATED IDS’S
Forrest, et al., have proposed [2] counting the total num-
ber of mismatched length-6 subtraces and only triggering an
alarm if the total mismatch count exceeds some threshold,
say 7 mismatches. This gives the intruder an extra degree
of freedom, because now the exploit code is free to cause a
few mismatches, as long as they are not too numerous.
We can easily extend our (cid:12)nite-state model above to ac-
count for this degree of freedom, as follows. We add an
extra dimension to the statespace, counting the number of
mismatches so far. Thus, the statespace becomes Q0 def
=
(Q (cid:2) f0; 1; : : : ; 6g) [ fAlarmg, and each non-alarm state is
a pair (q; m) of a state q 2 Q = (cid:6)5 from the old model
and a count m 2 f0; : : : ; 6g of the number of mismatches
(cid:0)! q0 of
seen so far. For each non-alarm transition q
(cid:0)! (q0; m)
the old model, we introduce transitions (q; m)
for each m = 0; 1; : : : ; 6. Also, for each alarm transition
s
s
264
