time and location of charging, the card charger id, the
bus number and the bus stop. Our experiments prove that
they are not stored in a static or cyclic way on the card.
We may assume that if the date and time of charging and
the card charger id were represented in the card’s mem-
ory, they would have been encoded in the same way as
the other dates, times and ids. A search of these encoded
values in the binary dumps did not give a hit. There-
fore, we conjecture that these attributes are not stored on
the card, not even at a dynamically determined location.
Given that a validated ride allows for unrestricted travel
through the whole country for two hours, there is also no
need to store the bus number and bus stop on the card.
As a consequence of carving for internal attributes we
have not only located four pointers, but we have also re-
verse engineered part of the dynamics of updating e-go
cards. The transaction sectors are written to cyclically.
They contain data related to the history of the card. The
current state of each of the products on the card is stored
in the product sectors. Every product is assigned to one
sector, except the currently active product. This product
is updated alternatingly in two sectors. This redundancy
is probably built in to keep a consistent product state even
if a transaction does not ﬁnish successfully.
More safeguards against update errors are found in the
frequent checksums that we have been able to locate. A
protection against intentional modiﬁcation of the stored
data is the cryptographic seal in the shell sector.
Even though we found the majority of observed at-
tributes, there are still locations in the card’s memory
that we have not been able to assign a meaning to. Of
course, the current dump set provides no information on
the meaning of the constant (blue) bits in Figure 8. The
variant (red) bits either have to do with the internal orga-
nization of the card or with attributes that we did not or
could not observe.
With respect to convergence, we see that the dumps in
this case study behave slightly worse than the dumps in
the idealized set from Section 7.2. Finding an attribute
requires roughly 12 dumps (or 5 bundles).
Occasionally, we incorrectly entered an attribute
value. The algorithms that we developed are not robust
against such mistakes, since a single modiﬁcation in the
input can drastically change the output. In practice, how-
ever, such mistakes were quickly identiﬁed by regularly
performing experiments on a subset of the dump set, such
as all dumps belonging to a given card.
A very useful feature of our methodology is that in the
search for an attribute we do not presuppose a particular
encoding of that attribute. This allowed us to search for
the combination of license plate number and reader loca-
tion in order to ﬁnd the reader ID. Similarly, we found a
rides left counter counting down and one that counts up
while searching for one attribute.
9 Conclusion and future work
We have deﬁned the carving problem for attributed dump
sets as the problem of recovering the attribute mapping
and encoding of attributes in a dump. We have pro-
posed algorithms for recovering the attribute mapping
and proven their correctness. The ﬁrst algorithm com-
putes the commonalities to determine the positions in a
dump that cannot be contained in the mapping. The sec-
ond algorithm computes subset-minimal dissimilarities
to give a lower-bound on the bits that need to be con-
tained in the attribute mapping. By combining these two
algorithms, a set of possible mappings is derived.
In order to validate our approach we have imple-
mented a prototype, called mCarve, with commonality
and dissimilarity algorithms. A case study performed on
data from the electronic fare collection system in Luxem-
bourg showed that mCarve is valuable in analyzing real-
world systems. Using mCarve, we have located more
than a dozen attributes on the e-go card as well as their
encoding. We have also partly reverse engineered the dy-
namics of updating e-go cards.
There are several research directions that remain to be
explored. To be able to understand the attribute values,
the encoding has to be recovered as well.
In our case
study, we have recovered the encoding of attributes man-
ually, while automatic approaches should in some cases
be feasible. Heuristic approaches seem most viable, pos-
sibly approaches based on ﬁle carving techniques. Sec-
ondly, the robustness of our algorithms can be improved.
Currently, a small error in the data, due to, for instance, a
transmission error or a mistake in inputting the attribute
value will make the results unreliable. Although these
mistakes can be found by hand, an automatic way would
be preferable.
a cell phone. Our performance results show that we have
to optimize the implementation of our algorithms to an-
alyze cell phone dumps. Another use of mCarve will
be to analyze proprietary communication protocols. By
recording the data and applying our algorithms, we could
reconstruct their speciﬁcation.
References
[1] BILLARD, D., AND HAURI, R. Making sense of unstructured
memory dumps from cell phones, 2009.
[2] COHEN, M. I. Advanced carving techniques. Digital Investiga-
tion 4, 3-4 (2007), 119–128.
[3] CONTI, G., DEAN, E., SINDA, M., AND SANGSTER, B. Visual
reverse engineering of binary and data ﬁles. In VizSec ’08: Pro-
ceedings of the 5th international workshop on Visualization for
Computer Security (Berlin, Heidelberg, 2008), Springer-Verlag,
pp. 1–17.
[4] GARCIA, F. D., DE KONING GANS, G., MUIJRERS, R., VAN
ROSSUM, P., VERDULT, R., SCHREUR, R. W., AND JACOBS,
B. Dismantling MIFARE classic. In ESORICS (2008), pp. 97–
114.
[5] GARCIA, F. D., AND VAN ROSSUM, P. Modeling privacy for
off-line RFID systems. In CARDIS (2010), pp. 194–208.
[6] GARCIA, F. D., VAN ROSSUM, P., VERDULT, R., AND
SCHREUR, R. W. Wirelessly pickpocketing a MIFARE classic
card. In IEEE Security and Privacy (2009), pp. 3–15.
[7] GARFINKEL, S. Carving contiguous and fragmented ﬁles with
fast object validation. Digital Investigation 4s (2007), 2–12.
[8] HELFMAN, J. Dotplot patterns: A literal look at pattern lan-
guages. TAPOS 2, 1 (1996), 31–41.
[9] RUKHIN, A., SOTO, J., NECHVATAL, J., SMID, M., AND
BANKS, D. A statistical test suite for random and pseudoran-
dom number generators for statistical applications. NIST Special
Publication in Computer Security (2000), 800–22.
[10] SENCAR, H. T., AND MEMON, N. Identiﬁcation and recovery
of JPEG ﬁles with msising fragments. Digital Investigation 6
(2009), 88–98.
[11] SHAMIR, A., AND VAN SOMEREN, N. Playing “hide and seek”
Lecture Notes in Computer Science 1648
with stored keys.
(1999), 118–124.
[12] VAN DEURSEN, T., MAUW, S., AND RADOMIROVI ´C, S.
mCarve tool, 2011. Available at http://satoss.uni.lu/
mcarve.
A Proofs
Proof of Lemma 1. We show the ﬁrst property by con-
tradiction. Assume that there exists an attribute a such
that f (a) * comm(a, S). Then there exists an index
i ∈ f (a) such that i 6∈ common(a, S). It follows from
the deﬁnition of comm that there is a bundle that con-
tains bit strings s and s′ such that si 6= s′
i. However,
since f is an attribute mapping, index i ∈ f (a), and
vala(s) = vala(s′), we have that si = s′
i. Thus, f (a)
must be a subset of comm(a, S).
We would like to apply mCarve to other case stud-
ies. An interesting application would be the memory of
The second property follows from the fact that if we
extend an encoding, it remains an encoding. We know
that e(vals(a)) = s|f (a) is an encoding for attribute
mapping f . By deﬁnition of attribute mapping, the map
e′(vals(a)) = s|f ′(a) is an encoding as long as for all
j ∈ f ′(a) we have sj = s′
j if vala(s) = vala(s′) and
e′ is injective. The former follows from the assumption
that j ∈ comm(a, S). The latter follows from the fact
that extending the range of the encoding maintains the
injectivity of it. Hence, f ′(a) 7→ Ia is an attribute map-
ping.
Proof of Lemma 2. Let a ∈ A and let s, s′ ∈ S, such that
vala(s) 6= vala(s′). From the deﬁnition of an attribute
mapping and injectivity of encoding functions, we derive
that s|f (a) 6= s′|f (a). Therefore, we can ﬁnd i ∈ f (a),
such that si 6= s′
i, and thus f (a) satisﬁes the deﬁnition
of diss(a, S).
Proof of Lemma 3. We deﬁne Q = {p ∈ P | ∀p′ ∈
P : p′ ⊆ p =⇒ p′ = p} and prove that this is the
required set. From the deﬁnition of Q it follows directly
that Q is subset minimal.
The inclusion Q ⊆ P follows directly from Q ⊆ P .
For the converse, P ⊆ Q, we use the fact that strict
set inclusion on P(F ) is well-founded for ﬁnite F . Let
p ∈ P , then there exists p′ ∈ P , such that p′ ⊆ p. We
consider two cases: p′ ∈ Q and p′
6∈ Q. If p′ ∈ Q,
then from p′ ⊆ p it follows that p ∈ Q, as required.
In the second case, p′
6∈ Q, we use the deﬁnition of
Q to ﬁnd p′′ ∈ P such that p′′ ( p′. Again, we can
consider two cases: p′′ ∈ Q and p′′
6∈ Q. In the ﬁrst
case, p′′ ∈ Q we have p′′ ( p′ ⊆ p, so p ∈ Q, as
required.
In the second case we can repeat this con-
struction to ﬁnd p′′′ ( p′′ ( p′ ⊆ p. Given well-
foundedness, it will be impossible to create an inﬁnite
sequence in this way. Therefore, there is a point where
the loop will be broken by ﬁnding p(k) ∈ Q, such that
p(k) ( p(k−1) ( . . . ( p′ ⊆ p, which implies that
p ∈ Q.
Finally, we prove uniqueness. Assume that X and Y
are two subset-minimal sets with X 6= Y and X = P =
Y . Without loss of generality, we may assume that there
exists x ∈ X, such that x 6∈ Y . We derive a contradiction
and conclude X = Y as follows. If x ∈ X, then x ∈ Y .
From x 6∈ Y , we ﬁnd y ∈ Y , such that y ( x. From
y ∈ Y , it follows that y ∈ X, so there exists x′ ∈ X
with x′ ⊆ y. Thus, we have x′ ⊆ y ( x for x′, x ∈ X,
which contradicts the assumption of subset minimality of
X.
Proof of Lemma 4. By Lemma 3, let T be the unique
subset-minimal set for which T = diss(a, S). We show
that T ⊆ diss(a, S′).
Let I ∈ T .
S : (vala(s) 6= vala(s′) =⇒ ∃i ∈ I : si 6= s′
Then by deﬁnition, ∀s, s′ ∈
i). But
since S′ ⊆ S, the statement holds in particular for any
two dumps in S′. Thus I ∈ diss(a, S′).
inclusion
Proof of Lemma 5. The
⊆
ﬁlter(diss(a, S), comm(a, S))
ﬁlter(diss(a, R), comm(a, S)) follows from Lemma 4.
∈
ﬁlter(diss(a, R), comm(a, S)) be an index set
in
the ﬁltration of diss(a, R) with respect to the common
set of the attribute a of the dumps in S.
inclusion,
reverse
For
the
let
I
a
towards
Suppose
6∈
ﬁlter(diss(a, S), comm(a, S)).
Then there must
be dumps s1, s2 ∈ S such that s1|I = s2|I , but
vala(s1) 6= vala(s2).
contradiction that
I
Consider representatives r1, r2 ∈ R of s1 and s2
such that vala(r1) = vala(s1) 6= vala(s2) = vala(r2).
Since I ⊆ comm(a, S), it follows that r1|I = s1|I ,
r2|I = s2|I , but vala(r1) 6= vala(r2). This contradicts
I ∈ diss(a, R).
Proof of Theorem 2. By
ﬁces
smin(ﬁlter(diss(a, R), comm(a, S))).
it
smin(diss(a, R|comm(a,S)))
Lemma
prove
to
5,
The
inclusion
smin(diss(a, R|comm(a,S)))
ﬁlter(diss(a, R), comm(a, S))
diss(a, R|comm(a,S))
⊆
smin(diss(a, R|comm(a,S))) ⊆ comm(a, S).
holds,
diss(a, R)
suf-
=
⊆
since
and
The
inclusion
⊇
diss(a, R|comm(a,S))
smin(ﬁlter(diss(a, R), comm(a, S))) holds
fol-
lows. Let I ∈ smin(ﬁlter(diss(a, R), comm(a, S))).
Then I ∈ diss(a, R) and I ⊆ comm(a, S),
thus
I ∈ diss(a, R|comm(a,S)).
as
The Lemma now follows by uniqueness of subset
minimal sets (Lemma 3) and the facts that the dissim-
ilarity sets and ﬁlters of dissimilarity sets are superset
closed.
Proof of Lemma 7. T is interval-subset-minimal by def-
inition. It is obvious that T ⊆ diss(a, S) ∩ In. Since
diss(a, S) ∩ In is interval-superset closed, it follows that
T ∩In ⊆ diss(a, S)∩In. Furthermore, for all i ∈ [0, n),
if iv(a, S)(i) exists, then iv(a, S)(i) ∈ T ∩ In.
Suppose towards a contradiction that T ∩ In (
diss(a, S) ∩ In. Then there exists I ∈ diss(a, S) ∩ In
such that I 6∈ T ∩ In. Let I = [i0, i1] and con-
sider iv(a, S)(i0). By deﬁnition of iv(a, S), we have
iv(a, S)(i0) ⊆ I and we know that iv(a, S)(i0) ∈
T ∩ In. This contradicts I 6∈ T ∩ In.
Proof of Theorem 3. We ﬁrst prove correctness of the al-
gorithm and then compute its time complexity.
Correctness.
By
Lemma 7, to prove correctness of the algorithm, we need
to show that for any two dumps s, s′ ∈ R there exists an
Let k = maxj∈[1,|R|](kj)].
index ind ∈ [i, i + k] such that sind 6= s′
this by iterating over the sorted list of dumps.
ind. We show
Dump s(1) differs from all other dumps within the
[i, k1] because it differs from s(2) within
interval
is sorted. Assum-
this interval and the dump list
ing that for all j  s(j0) differ from s(j0) within the inter-
val [i, kj0 ] because s(j0) differs from s(j0+1) within this
interval and the dump list is sorted. Thus the algorithm
correctly computes iv(a, R)(i).
Complexity. The complexity of the algorithm is given
by the complexity to sort the dump set and the com-
plexity to compare adjacent dumps in the sorted list.
The bit-complexity for comparing the adjacent dumps
s(j), s(j+1) is kj . Thus, in the worst case, it is bounded
by n, the bit length of the dump. Thus iv(a, R)(i) can be
computed in time O((n − i)|R| + (n − i)|R| log |R|) =
O((n − i)|R| log |R|).
If iv(a, R)(i) is computed for all i ∈ [0, n), the sort-
ing complexity for i > 0 can be lowered by taking ad-
vantage of the sorted list of dumps with respect to >i−1.
We merely need to perform a merge-sort for <i on two
sets given by the restrictions si−1 = 0 and si−1 = 1 and
ordered with respect to <i−1. This can be performed in
time O((n − i)|R|). By summing up the time it takes to
compute iv(a, R)(i) for i ∈ [0, n) we obtain the theo-
rem.