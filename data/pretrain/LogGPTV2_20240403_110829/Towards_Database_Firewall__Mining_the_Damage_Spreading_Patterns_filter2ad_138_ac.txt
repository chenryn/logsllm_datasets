G
G
{1}
{3}
G
G
B
G
GBG
BBG
B
G
B
B
GBB
BBB
G
G
{4}
G          B
0.15
0.85
0.65
0.35
0.8   
0.1    
0.3
0.2
0.2
0.9
0.7
0.8
0.25
0.75
0.1   
0.9
Figure 3. An Example of Bayesian Network
with the Damage Spreading Probability Table
,  and . To construct
the DAG from these multi-hop patterns, we determine the select
group of predecessors of each node if they satisfy the following
condition: there is a rule as {parentsi} ⇒ {node} and the con-
ﬁdence of the rule is larger than or equal to a user speciﬁed pa-
rameter c, then an arc between parentsi and node is drawn ac-
cordingly. We identify the following rules from above patterns:
{1} ⇒ {2}(conf = 75%),{1} ⇒ {3}(conf = 50%), {1} ⇒
{4}(conf = 75%), {1} ⇒ {5}(conf = 50%), {2} ⇒
{3}(conf = 66%), {2} ⇒ {4}(conf = 66%), {3} ⇒
{4}(conf = 66%), {4} ⇒ {5}(conf = 75%).
The rules with conﬁdence less than c=50% are dis-
carded from all rules generated. Figure 3 shows an example
Bayesian network constructed from above rules. In addi-
tion, the conditional probability tables computed based on
previous attack histories is drawn as well in ﬁgure 3.
Bayesian network is adopted in our framework to predict
the integrity of data objects when some data object has been
observed as damaged. The idea of is, given evidence about
the state G or B of a one-hop pattern, where G and B denote
Good, and Bad for short, the state of data objects in other
one-hop pattern can be inferred by equation 4:
X
P (X) =
P (X, Y )
(4)
Y
where Y stands for all unknown variables excluding vari-
able X, and P (X, Y ) may be expanded using the prod-
uct rule shown as 3. Because Bayesian network deﬁnes
a joint probability it is clear that P (X, Y ) can be com-
puted from the DAG. For example, to ﬁnd the probabil-
ity that the 5 is damaged given that 1 is damaged, that is
P ({5} = B|{1} = B), it is necessary to marginalize over
the unknown parameters. This amounts to summing the
probabilities of all routes through the graph.
Example. Given the Bayesian network as shown in ﬁgure 3,
if we observe at time t that the data object oi = (A) ∈ {1}
is damaged when scanning the new attack history hnew, we can
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006compute the damage probability of the data object sets belonging
to pattern {5} by equation 4 as follows:
P (5 = B|1 = B) =
{P (5 = B|4 = x, 3 = z, 2 = y)
X
x,y,z
= 0.465
Suppose that data objects (C), (D) and (E) are in {5}, and
 ⇒  with probability 0.465. Then
we denote the integrity level of data objects (C), (D) and
(E) as 0.465, which means that there is a 0.465 certainty
that these data objects are damaged. If along the scanning
process of the new attack history, new evidences of dam-
aged data are found, the integrity level is adjusted accord-
ingly. Meanwhile, ﬁltering rules are enforced and certain
clean transactions are triggered to repair the dirty data ac-
cording to the estimated integrity of the data objects. Fi-
nally, the integrity of data objects contained in Y as in algo-
rithm 2 is known, and the corresponding Integrity Filtering
List ˆIi (see Deﬁnition 3 in section 5.3) is updated for gener-
ating new ﬁltering rules. This algorithm is incremental. As
new evidence obtained, some interim results from previous
calculations can be reused to estimate the integrity of data
objects instead of re-computing.
Algorithm 2: Integrity Estimation
/* X → evidence; Y → to be estimated */
p[i] =
v p(cnode = v|pa1 = v, pa2 = v, . . .);
/* v∈G,B */
Input: G, X, Y
Result: Integrity Level List ˆIi
begin
cnode = Y;
while cnode.pa (cid:4)= ∅ do
P
cnode = cnode.pa;
i++;
Q
Pr(Y|X=x) =
i p[i];
ˆIi = ∀ oi ∈ Y ← P r;
end
1
2
3
4
5
6
7
8
9
5.3 Database Firewall Security Policy
A speciﬁc and strongly worded security policy is vital
to the pursuit of internal data integrity. This policy should
govern everything from acceptance of accessing data ob-
jects to response scenarios in the event that a security in-
cident occurs, such as policy updating upon new attacking.
Ideally, a database ﬁrewall policy dictates how transaction
trafﬁc is handled and how ﬁltering ruleset is managed and
updated. To limit the potential damage spreading, ﬁrewall
policy needs to create a ruleset to restrict the entrance of
transactions that could compromise other data objects, but
let other transactions enter to achieve maximum throughput.
ˆI=
{(o1, ox, . . . , oy)i1 , (o2, oz, . . . , ov)i2 , . . .}, where
is an
Deﬁnition
List,
i
Filtering
Integrity
3
ˆI
a
For
suppose
example,
integrity level. Objects ox with the same integrity level i are
grouped together.
=
transaction T1(t)
r1[ox]r1[oy]w1[oy] needs to enter the database at
time
t. We know that the integrity of data object ox has been
estimated and considered as corrupted at this moment, our
policy checker will screen and be aware if the request can
be granted using the rulesets deﬁned as follows:
T
Rule 1 : ∀ transaction T, if ∃ data object ox ∈ RT , and RT
(cid:5)= ∅, and if WT (cid:5)= ∅, DENY;
T
Rule 2 : ∀ transaction T, if ∃ data object ox ∈ RT , and RT
ˆI
(cid:5)= ∅, and if WT = ∅, and if i(ox) < Q then DENY, otherwise
GRANT;
T
Rule 3 : ∀ transaction T, if ∃ data object ox ∈ RT , and RT
ˆI
(cid:5)= ∅, and if WT (cid:5)= ∅, and if i(ox) < Q then DENY, otherwise
GRANT;
T
Rule 4 : ∀ transaction T, if (cid:2) data object ox ∈ RT , and RT
= ∅, GRANT;
Where, i(ox) is the integrity level of the object ox and
Q is Quality of Information Assurance associated with
applications. RT and WT are the readset, writeset of the
transaction T, respectively. For example, give Q = 0.5
of an application, it means if the integrity of data objects
is 0.5 or higher, it is acceptable to the application. Note,
what we have presented here is a sample ruleset. We
should be aware that ﬁrewall rulesets tend to become more
complicated with age.
ˆI
6 Experimental Results
In this section, we present the experimental results.
To assess the performance of our database ﬁrewalling ap-
proach, we conduct two empirical studies based on both
synthetic and real datasets. The simulation model of our
experimental studies is described in section 6.1.
6.1 Experiment Settings
In our experiments, we use two synthetic history sets
generated based on the modiﬁed TPC-C benchmark. We
take the parameters shown in table 6 to populate the syn-
thetic attack histories. The speciﬁed settings for each pa-
rameters used to generate the history sets are included in ta-
ble 7. In addition, a real dataset of transaction histories from
a clinic OLTP application is employed to verify the mining
algorithm. The dataset (400MB) contains 119 tables with
1142 attributes belonging to 9 different applications. For
more detailed description of the dataset we refer the reader
to [16]. Moreover, to verify the database ﬁrewall proto-
type, we re-construct the clinic application based on the ap-
plication and query templates and generate real syn attack
histories. We also assume that there is only one attack at
a time. Additionally, similar attack is practically deﬁned
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006Parameters
Notes
N
T
C(P)
D
H
Number of data objects
Average numbers of
data objects per transaction
Number of customers(patients)
Number of transactions
Number of attack histories
Table 6. Parameters of the synthetic datasets
Name
Syn1
Syn2
Real
Real Syn
N
1000
1000
1000
1000
T
3
5
8
8
C
500
1000
1000
1000
D
100,000
100,000
100,000
100,000
H
10
20
10
20
Table 7. Parameter values of the datasets
in our experiments as the attacks with the same transaction
type, such as Order, Payment transaction type in the TPC-C
benchmark.
6.2 Mining Algorithms Testing
To verify the mining algorithms, we conducted exper-
iments to measure the quality of mined one-hop frequent
damage spreading patterns using two metrics, recall and
precision. They are deﬁned as follows. Given a set of true
damage spreading patterns A and a set of obtained frequent
damage spreading patterns B, the recall is
and the
precision is
|A∩B|
|A|
|A∩B|
|B|
.
In table 8, the ﬁrst column shows we use two different
kinds of dataset, one from the synthetic application and one
from the real application. The last column is the minimum
support s to mine the patterns. It can be seen that when the
minimum support is set to 15%, using the synthetic dataset,
0.93 of recall rate can be achieved. When we lower s to
10%, higher recall rate (98%) can be obtained. Although
the high recall rate is achieved, the false-negative patterns
have the potential to cause the damage leakage. However,
after further investigation of the missed patterns, we ﬁnd
that the chance these missed patterns cause damage leak-
age is small. First, although these missed patterns are true
damage spreading patterns, they do not often occur in the
damage histories and then are screened out because of the
minimum support. The reason they do not frequently in-
Data Type
Syn
Syn
Real
RealS yn
A
300
600
200
300
B
279
587
190
291
Recall
0.93
0.98
0.95
0.97
Precision
1
1
1
1
s (%)
15
10
10
10
Table 8. Measurement of the Mining Algo-
rithm of One-hop Patterns
Real System Integrity SIr
80%
70%
65%
Time
BN
50
70
90
(s)
DR
260
270
300
%
Accuracy
94%
92%
87%
Table 9. Speed of System Integrity Estimation
volve in damage spreading is that transaction scripts always
have conditional statements, such as if-else statement. Only
when certain condition is satisﬁed, the branch will be gone
through, and then the patterns occur. Second, these missed
patterns are often on the downstream of a multi-hop spread-
ing pattern (similar to the leaf node of a tree). Thus, even
if they are damaged and not included in ﬁnal answer, they
do not cause damage leakage. The experiments to measure
the multi-hop patterns achieve similar results that are not
presented due to limited space. As a conclusion, we believe
that the mining algorithm is satisfactory. However, since we
deploy a relative simple SQL-injection attack, pattern min-
ing algorithm achieve high recall rate. How the algorithm
performs when the attack is sophisticated needs a further
investigation. Furthermore, the algorithm is designed par-
ticularly for the TPC-C and clinic applications. A generic
condition under which the mining algorithm can be useful
remains unknown.
6.3 System Integrity Analysis
n
Estimated system integrity SIe is deﬁned as the ratio
of the summation of the damage probabilities of the data
objects nd to the number of total data objects N in the
database: SIe = 1 − P
i=1 P
N . For example, if the database
contains N = 100 in which total nd = 20 are bad data, the
real system integrity should be SIr = 1 − P20
i=1 ∗1
100 =80%
when the system is detected to be under an attack. To ver-
ify the estimation accuracy of our approach, we deﬁne the
accuracy as the ratio of the number of data objects that are
estimated (and are tested as they are later) to the number of
damaged data objects in the new attack history.
Figure 4 shows the process of discovering system in-
tegrity. Our probability based approach is compared with
the algorithm adopted from [1] that use the dependency re-
lation of transactions. Along with the process of scanning
the new attack history, at each time ti a data object oi or a
set of data objects (oi, .., oj) are found to be bad, the de-
pendency relation based approach will only know what it
has learned up to time ti. However, with the Bayesian net-
work constructed from previous attack histories, we are able
to compute the damage probability of all data objects previ-
ously occurred in attack histories. Therefore, our approach
should be faster than the dependency based approach in
ﬁnding the system integrity. Results in table 9 demonstrate
that our Bayesian network based approach is much faster
than the dependency relation based approach in terms of as-
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 20061
y
t
i
r
g
e
t
n
I
m
e
t