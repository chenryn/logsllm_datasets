cryptography with auxiliary input setting [6]. It is a weaker
assumption than requiring a high HILL pseudoentropy [16],
as in the DP model. We believe it captures physical leakages
particularly well in the sense that we do not put constraint
on the form of the leakage (e.g., in terms of length or entropy
left): it can be a simple computation time, a huge sequence
of power consumption measurements, a map of electromag-
netic radiations, or anything else. Moreover, it does not rule
out the possibility that the adversary would be able to rec-
ognize the correct key if given to him. We only require that
the leakage functions cannot be inverted eﬃciently.
Stronger versions of these notions of seed preservation
would allow the adversary to recognize whether a candidate
key k1 is the correct one. This can happen in diﬀerent con-
texts in practice: it might be the case that half of 2PRG(k1)
is available as public output of a next round, enabling the
adversary to perform some comparisons; it might also be
the case that the adversary is able to reinitialize the circuit
to a value of his choice, and to compare the leakages ob-
served in the targeted execution to the leakage occurring in
an execution triggered after reinitialization. The security of
the PRG construction, as claimed next in Theorem 1, could
be rephrased in terms of this strengthened notion of seed
preservation. Proofs would remain the same, but reductions
would become tighter by a factor corresponding to the num-
ber of random oracle queries made by the adversary.
3.3 Security analysis
We show that, as long as the pairs of leakage functions
that are evaluated on the same keys are uniformly seed-
preserving and can be evaluated eﬃciently, the stateful PRG
construction of Fig. 1b is physically unpredictable in our
model.
1),
1, Li
1), (Lo
Theorem 1. Let A2PRG be a PPT adversary playing the
PredA2PRG,L(n) experiment with a sequence of leakage func-
tions L = ((Li
1, Lo
. . . ). Then, we have Pr[PredA2PRG,L(n) =
1] = 1
2 + negl(n), provided that the family of pairs of leakage
functions (⊥, Li
2), . . . is uniformly seed-preserving
and that all leakage functions can be evaluated in probabilis-
tic polynomial time.
Here, negl(n) ≤ p(n)2
2n +q(n)(p(n)+1)(n), where p is an up-
per bound on the number of request queries made by A2PRG,
q is the number of random oracles queries made by A2PRG,
and  is the uniform bound coming from the uniform seed-
preserving property of the leakage functions.
A proof is given in Appendix A.
3.4 Practical security analysis
First note that, in order to turn the previous analysis into
concrete security bounds, it is essential to propose an in-
stance of 2PRG to implement. For convenience, and fol-
lowing the suggestion of Pietrzak in [29], an easy solution
for this purpose is to use a block cipher based construc-
tion. As an illustration, assume BCk(x) denotes the en-
cryption of a plaintext x under a key k, e.g. with the AES
145Rijndael. Then, a length-doubling PRG can be instantiated
as: 2PRG(k) = (BCk(0n), BCk(1||0n−1)). From such an in-
stance, the practical security analysis to be performed by
hardware designers is straightforward: they need to bound
the leakage of an adversary who can only encrypt two known
plaintexts, i.e. a 2-limited adversary as deﬁned by Vaudenay
in his decorrelation theory [36]. This gives a simple tradeoﬀ
between the eﬃciency and the security of a leakage-resilient
stream cipher. That is, by turning the 2PRG of our con-
struction into a 3PRG, 4PRG, . . . , the amount of keystream
generated per PRG iteration increases, at the cost of more
input plaintexts that can be monitored by the adversary. So,
depending on the quality and trust of the lower level, one
can easily adapt the performances of the construction.
It is interesting to mention that, depending on the block
cipher used in the PRG, these instantiations may introduce
a gap with the assumptions in the previous section. Just ob-
serve that we consider the leakage on the output of a 2PRG
Lo(ki, xi) and the one on its input Li(ki−1) as independent.
But if a block cipher with an invertible key scheduling algo-
rithm (e.g., the AES Rijndael) is used, the output leakage
may potentially leak on the key that was used to produce
this output. This observation is not expected to modify
the practical security of the resulting PRG, but suggests
that carefully instantiating block cipher based constructions
may be important to prevent side-channel attacks. It also
recalls that non-invertible key scheduling algorithms (as in
the FOX block cipher [18], for instance) are desirable in the
context of leaking devices. Alternatively, one may also con-
sider slightly more expensive instantiations, e.g. by replac-
ing 2PRG(k) := (cid:0)BCk(0n), BCk(1||0n−1)(cid:1) by the following
one: 2PRG(k) :=(cid:0)BCBCk(0)(0n), BCBCk(0)(1||0n−1)(cid:1).
4. SECURITY IN THE STANDARD MODEL
We now propose two constructions with essentially the
same structure and eﬃciency as the one in Section 3 but with
two diﬀerences: the security holds in the standard model,
and the leakage functions are now restricted to have a range
limited to λ  κ and for any public randomness p, F(·, p) is a
PRG. So a straightforward construction is to produce pseu-
dorandom streams by simply iterating this PRG. But this
construction would be insecure as, even with non-adaptive
leakages (with the same input as F), “future computation at-
tacks” are still possible. This motivates the use of two public
random values p0 and p1 in our construction, that we will
use in alternation (without refreshing) for the pseudorandom
stream generation. This is where the non-adaptive selection
of the leakage functions is crucial:
it guarantees that the
leakage functions are independent of p0 and p1, even if these
values are public. Since either p0 or p1 will be part of the
leakage function inputs, but not both at the same time, this
ensures that no leakage can provide a function of the full
system state, preventing “future computation attacks”.
As depicted in Figure 3, the initial state of the stream ci-
pher is (p0, p1, k0) for public randomness (p0, p1) R←− ({0, 1}n)2
R←− {0, 1}κ. The i-th round of our stream
and secret key k0
cipher is then computed as: (ki, xi) := F(ki−1, pρ(i−1)), where
ρ(i) := i mod 2. The security experiment is essentially
identical to PredA,L(n), except that the triple (p0, p1, k0) is
selected at step 1, that 2PRG is instantiated with the wPRF
and public inputs as described above, and that the leakage
corresponding to round i is computed as Li(ki−1, pρ(i−1)).
k0
F,L1
p0
Round 1
k1
x1
L1(k0, p0)
Round 2
F,L2
p1
L2(k1, p1)
x2
k2
p0
F,L3
Round 3
k3
x3
L3(k2, p0)
Round 4
F,L4
p1
L4(k3, p1)
x4
k4
Figure 3: A leakage-resilient stream cipher based on any
weak pseudorandom function F:{0, 1}κ × {0, 1}n → {0, 1}2κ.
This pseudorandom generator can be instantiated with
any length-expanding wPRF (m > κ), which in turn can be
realized from any secure block cipher BC: {0, 1}κ × {0, 1}n
→ {0, 1}κ. That is, if BC is an (, s, 2q)-secure wPRF, then
F(k, pl(cid:107)pr)
= BCk(pl) (cid:107) BCk(pr) is an (, s, q)-secure wPRF
(another instantiation technique that does not double the
def
146amount of public randomness, but requires BC to be a PRF,
can be found in [29]). Thus, compared with the construction
in Section 3, the only performance penalty we have to pay
is the storage of two public random values, that are used
alternatively as inputs to our wPRF. Note that the practi-
cal security analysis given in Section 3.4 applies similarly,
e.g. we can make a trade-oﬀ between security and perfor-
mance by choosing m = 2κ, m = 3κ, and so on. Finally,
it is worth mentioning that the requirement of independent
leakages that is found in [9, 29] can also be relaxed here, al-
though not as strongly as for the construction of Section 3.
Precisely, our following proofs rely on the fact that, e.g.
when computing F(ki, p0), nothing is leaked about p1. But
this is made easier than in [9, 29] for two reasons. First,
p0 and p1 are public. Hence, they can be manipulated on
leaky buses between the round computations, e.g. in order
to read them from a part of the chip that does not interfere
with the computations. Second, they can be saved once for
all, prior to the computations, e.g.
in a non-volatile mem-
ory. This can be used to reduce possible coupling eﬀects,
since non volatile memories do not need to be supplied with
energy. The implementation of a similar idea with the con-
structions of Dziembowski and Pietrzak would be less con-
venient, since p0 and p1 are replaced by secret keys that are
modiﬁed during the iterations of their stream ciphers. This
implies regularly writing in a non volatile memory, which is
a highly consuming (and potentially leaking) task.
4.2 Security analysis
Notations.
def
We denote by Λi = (xi, Li(ki−1, pρ(i−1))) the information
an adversary obtains during the i-th computation round,
= {p0, p1} ∪ {Λi|i≤j} be the view
and let viewj(p0, p1, k0)
of the adversary for all rounds up to j based on initial state
p0, p1, k0. We will simply write viewj when this initial state
is clear. We use upper-case letters X, Y to denote ran-
dom variables, and lower-case x, y to denote the values they
take. Let |X| denotes the length of X, let Un denote uni-
form distribution over {0, 1}n, and let X ∼ Y denote that
X and Y are identically distributed. We write δ(X; Y ) for
the statistical distance between two distributions X and Y ,
which is deﬁned as the maximum distinguishing advantage
between these distributions with respect to all adversaries.
We also use size(f ) to denote the circuit-size complexity of
the function f . Finally, we denote the computational ana-
logue of statistical distance by δs(X; Y ), which is deﬁned
as the maximum distinguishing advantage with respect to
If distribution X is over {0, 1}n,
all adversaries of size s.
= δs(X; Un), d(X|Y )
def
= δ(X; Un), ds(X)
we have: d(X)
= δ((X, Y ); (Un, Y )), ds(X|Y )
def
def
= δs((X, Y ); (Un, Y )). The
min-entropy of a random variable X, denoted by H∞(X), is
given by − log maxx Pr[X = x]. A random variable X has
HILL pseudoentropy k, denoted HHILL
(X), if there is a dis-
tribution Y with min-entropy k such that δs(X; Y ) ≤ .
def
,s
Security statement.
We express the leakage-resilience of the proposed stream
cipher in the theorem below. It states that, given the out-
puts of the stream cipher and the corresponding non-adaptive
leakages for any (cid:96) (polynomial in n) rounds, the ((cid:96) + 1)-th
round output X(cid:96)+1 is still pseudorandom with a leakage tol-
erance of log(− 1
6 ) bits per round. This means that for many
block ciphers (which are believed to be exponentially secure)
the leakage can be a constant portion of the key size κ (see
[9] for a discussion). We refer to the appendix for a detailed
proof, and outline it below.
Theorem 2
(Leakage-Resilient Security). Consi-
der the stream cipher introduced in Section 4.1. Let F :
{0, 1}κ × {0, 1}n → {0, 1}2κ be any (, s, n/)-secure wPRF,
and let L0, L1, ··· ,:{0, 1}κ × {0, 1}n → {0, 1}λ be any se-
quence of eﬃcient leakage functions. Then for uniform (P0,
P1, K0), for any (cid:96) ∈ N, sf,F
= size(F) + max{size(Li)|i ≤ (cid:96)}