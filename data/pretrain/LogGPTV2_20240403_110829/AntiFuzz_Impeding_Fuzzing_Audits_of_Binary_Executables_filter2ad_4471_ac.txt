ing different “interesting” coverage for nearly all inputs. The
rationale behind this is that according to the coverage-guide
assumption, any new coverage means that the fuzzer found
an input that causes new behavior. Therefore, if the program
always displays new coverage (due to our fake code), the
fuzzer cannot distinguish between legitimate new coverage
and invalid fake coverage. As every single input seems to
trigger new behavior, the fuzzer assumes that every input is
interesting. Therefore, it spends a signiﬁcant amount of time
on generating mutations based on invalid input.
To implement this technique, we calculate the hash of the
program input and based on this hash, we pick a small random
subset of fake functions to call. Each fake function recursively
calls the next fake function from a table of function pointers,
in such a way that we introduce a large number of new edges
in the protected program.
Since even a single bit ﬂip in the input causes the hash to
be completely different, nearly any input that the fuzzer gener-
ates displays new behavior. Fuzzers that are objective-driven
and thus assign weights to more interesting code construct
might ﬁnd it easy to distinguish between this simple fake
code and the actual application code. Since we cannot assume
that future fuzzers will treat new coverage information in
the same way as current fuzzers do, we introduce a second
technique that aims at providing plausible-looking, semi-hard
constraints. The second technique is designed to add fake
code that looks like it belongs to the legitimate input handling
1936    28th USENIX Security Symposium
USENIX Association
code of the original application. At the same time, this code
should include a signiﬁcant number of easy constraints as
well as some very hard constraints. These hard constraints
can draw the attention of different solving strategies, while
the easy constraints allow us to add noise to the true cover-
age information. We create this fake code by creating random
trees of nested conditions with conditions on the input ranging
from simple to complicated.
Evasion Overall, the attack on the code-coverage assump-
tion consists of a combination of these two techniques to fool
the fuzzer into believing that most inputs lead to new code
coverage and thus they are classiﬁed as “interesting”. This
ﬁlls up the attention mechanism of the fuzzer (e.g., AFL’s
bitmap or a queue) with random information which breaks
the assumption that the feedback mechanism is helpful in
determining which inputs will lead to interesting code.
4.2 Preventing Crash Detection
After applying our previous method, coverage-guided fuzzers
are “blinded” and have few advantages left in comparison to
blind fuzzers. To further reduce the ability of both coverage-
guided and blind fuzzers to ﬁnd bugs, we introduced two
additional techniques that attack assumption B identiﬁed ear-
lier.
There are multiple ways for a fuzzer to detect if a crash has
happened. The three most common ways are (i) observing the
exit status, (ii) catching the crashing signal by overwriting the
signal handler, and (iii) using the operating system (OS) level
debugging interfaces such as ptrace. To harden our protected
program against fuzzers, we try to block these approaches
by common anti-debugging measures as well as a custom
signal handler that exits the application gracefully. After we
install our custom signal handler, we intentionally trigger a
segfault (fake crash) that our own signal handler recognizes
and ignores. This way, if an outside entity is observing crashes
that we try to mask, it will always observe a crash for each and
every input. It is worth mentioning that by design, the fake
crash is triggered at every program execution independent
from the user input. Thus we do not introduce crashes based
on user inputs.
Evasion We try to catch all crashes before they are re-
ported to an outside entity. If the current application is under
observation or analysis (i.e., where catching crashes is not
allowed), the application is terminated. Typically, if it was
deemed necessary to apply ANTIFUZZ to any application,
there is likely no scenario where it would also be necessary
to continue operating under the given conditions.
In all of these cases, no crashes will be detected even if
they still occur, which breaks the assumption that a crashing
input is detectable as such.
4.3 Delaying Execution
We found that fuzzing tools need many executions per second
to operate efﬁciently. Our third countermeasure attacks this
assumption, without reducing the overall performance of the
protected program, as follows: we check whether the input
is a well-formed input; if and only if we detect a malformed
input, we enforce an artiﬁcial slowdown of the application.
For most applications, this would not induce any slowdowns
in real-world scenarios, where input ﬁles are typically well-
formed. But at the same time, it would signiﬁcantly reduce
the execution speed for fuzzers, where most of the inputs will
be incorrect. We believe that even if malformed input ﬁles
occasionally happen in real scenarios, a slowdown of e.g.,
250ms per invalid input is barely noticeable to the end user in
most cases. In contrast, even such a small delay has drastic
effects on fuzzing. Thus, only fuzzers are negatively affected
by this technique.
Delaying the execution can happen through different means,
the easiest way to cause a delay is using the sleep() function.
However, to harden this technique against automated code
analysis and patching tools, one can add a computationally-
heavy task (e.g., encryption, hash calculation, or even crypto-
currency mining) to the protected program such that the re-
sulting solution is necessary to continue the execution.
Evasion Most applications expect some kind of structure
for their input ﬁles and have the ability to tell if the input
adheres to this structure. Therefore, ANTIFUZZ does not need
to rely on any formal speciﬁcation; instead, our responses
are triggered by existing error paths within the program. For
the prototype implementation, we do not propose to detect
error paths automatically, but instead insert them manually
as a developer. If the input is malformed, we artiﬁcially slow
down the execution speed of the program. This breaks the
assumption that the application can be executed hundreds
or thousands of times per second, thus severely limiting the
chances of efﬁciently ﬁnding new code coverage.
4.4 Overloading Symbolic Execution Engines
To prevent program analysis techniques from extracting infor-
mation to solve constraints and cover more code, we introduce
two techniques. Both techniques are based on the idea that
simple tasks can be rewritten in a way that it is a lot harder to
reason about their behavior [51]. For example, we can replace
an addition operation using an additive homomorphic encryp-
tion scheme. In the following, we introduce two practical
techniques to achieve this goal.
First, we use hash comparisons. The idea is to replace all
comparisons of input data to constants (e.g., magic bytes)
with a comparison of their respective strong cryptographic
hash values. While still practically equivalent (unless small
collisions for current hashes are found), the resulting compu-
tation is signiﬁcantly more complex. The resulting symbolic
USENIX Association
28th USENIX Security Symposium    1937
expressions grow signiﬁcantly, and the solvers fail to ﬁnd a
satisfying assignment for these equations; they become use-
less for ﬁnding correct inputs. However this technique has
one weakness: If a seed ﬁle is provided that contains the cor-
rect value, a concolic execution engine might still be able to
continue solving other branches.
As a second technique, we can encrypt and then decrypted
the input with a block cipher. We later describe this technique
in detail in Section 5.4.
Evasion By sending the input data through a strong block
cipher and replacing direct comparisons of input data to magic
bytes by hash operations, symbolic, concolic, and taint-based
execution engines are signiﬁcantly slowed down and ham-
pered in their abilities to construct valid inputs. This breaks
the assumption that constraints in the application are solv-
able. Even though the encryption/decryption combination
is an identity transformation, it is very hard to prove auto-
matically that the resulting output byte only depends on the
corresponding input byte. Therefore, symbolic/concolic ex-
ecution engines either carry very large expressions for each
input byte, or they concretize every input byte, completely
voiding the advantage they provide. Finally, common taint
tracking engines will not be able to infer taint on the input, as
the encryption thoroughly mixes the input bits.
5 Implementation Details
In this section, we provide an overview of the proof-of-
concept implementation of our techniques in a tool called
ANTIFUZZ. As explained above, the use case for ANTIFUZZ
is a developer who has access to source code and wants to
protect his application from attackers who use automatic bug
ﬁnding tools to ﬁnd bugs cost-effectively. Hence, an impor-
tant objective was to keep the required modiﬁcations to the
project at a minimum, so that ANTIFUZZ is easy to apply. The
implementation consists of a Python script that automatically
generates a single C header ﬁle that needs to be included in
the target program. Furthermore, small changes need to be
performed to instrumt a given application. For our experi-
ments, we analyzed the time it took us to apply ANTIFUZZ
to LAVA-M (which consists of the four programs base64,
md5sum, uniq, and who). As we were already familiar with
the code base of these tools, we could more closely resemble
a developer who has a good understanding of the structure of
the code. It took us four to ten minutes to apply ANTIFUZZ to
each application. The number of lines that needed to be added
or changed depends on the number of constant comparisons
that need to be replaced by hash comparisons. base64 was
an outlier with 79 changed lines, 64 of which were necessary
due to a check against every possible character in the base64
alphabet. The three remaining applications required 6 (uniq),
7 (who), and 23 (md5sum) changed lines, respectively.
In the following, we describe technical details of how AN-
TIFUZZ is implemented.
5.1 Attacking Coverage-guidance
To prevent coverage-guided fuzzing, it is necessary to gen-
erate random constraints, edges, and constant comparisons,
as detailed in Section 4.1. The core idea here is to use every
byte of the input ﬁle in a way that could lead to a new basic
block, e.g., by making it depend on some constraints or by
comparing it to randomly generated constants. Depending
on the conﬁgurable number of constraints and the size of the
input ﬁle, every byte could be part of multiple constraints and
constant comparisons.
Implementation-wise, although it is possible to generate
code for ANTIFUZZ dynamically at runtime, this might cause
problems for fuzzers relying on static code instrumentation
(i.e., they might not be able to “see" code introduced by ANTI-
FUZZ). Thus, our template engine, implemented in 300 lines
of Python code, generates a C ﬁle containing all randomly
chosen constraints and constants, and further provides the
ability to set conﬁguration values (e.g., number of fake basic
blocks).
The random edge generation is implemented through a
shufﬂed array (where the input ﬁle seeds the randomness)
consisting of functions that call each other based on their
position in the array (up to a certain conﬁgurable depth).
ANTIFUZZ provides a function called antifuzz_init()
that needs to be called with the input ﬁlename, ideally before
the ﬁle is being processed by the application. This change
needs to be done manually by the developer when he wants
to protect his software against fuzzing: the developer needs to
add one line that calls this function. The function implements
all the techniques against coverage-guided fuzzers mentioned
earlier and sets up signal handlers to prevent crash detection,
as detailed in the next section.
5.2 Preventing Crash Detection
When antifuzz_init() is called, ANTIFUZZ has to conﬁrm
that no crashes can be observed. As detailed in Section 4.2, it
is necessary to overwrite the crash signal handlers, as well as
prevent it from being observed with ptrace.
In the former case, ANTIFUZZ ﬁrst checks whether over-
writing signals is possible: we register a custom signal handler
and deliberately crash the application. If the custom signal
handler was called, it ignores the crash and resumes execution.
If the application does not survive the crash, it means that
overwriting signals is not possible and, for our purposes, the
resulting crash is a desirable side-effect. If the application
survives the crash, evidently, signal overwriting is possible.
ANTIFUZZ then installs custom signal handlers for all com-
mon crash signals and overwrites these with either a timeout
or a graceful exit (depending on the conﬁguration). This will
1938    28th USENIX Security Symposium
USENIX Association
keep some fuzzers from covering any code because they do
not survive the artiﬁcial crash at the beginning of the appli-
cation. This behavior could also be replaced by an exit or by
calling additional functions that lead to fake code coverage to
keep up a facade of a working fuzzer.
In the case of ptrace, we use a well-known anti-debugging
technique [34] to detect if we are being observed by ptrace:
we check whether we can ptrace our own process. If we can
ptrace our own process, it means that no other process is
ptraceing it. However, if we are unable to ptrace our own
process, it implies that another process is ptraceing it and
therefore ANTIFUZZ terminates the application.
5.3 Delaying Execution
As detailed in Section 4.3, ANTIFUZZ needs to know when an
input is malformed to slow down the application and hamper
the performance of fuzzers. The main idea, implementation-
wise, is to allow the developer to inform ANTIFUZZ whenever
an input is malformed. Most applications already have some
kind of error handling for malformed input, which either dis-
cards the input or terminates the application. Within this error
handling function of the to-be-protected program, the devel-
oper needs to add a single call to antifuzz_onerror().
Upon invocation of antifuzz_onerror(), ANTIFUZZ de-
lays the execution for a conﬁgurable amount of time using
either of the mechanisms mentioned in Section 4.3.
5.4 Overloading Symbolic Execution Engines
There are two main parts to our countermeasures against sym-
bolic/concolic execution and taint analysis engines: replacing
constant comparisons with comparisons of their respective
cryptographic hashes, and putting the input through a crypto-
graphic block cipher before usage.
The ﬁrst part is implemented via the SHA-512 hash func-
tion. The developer needs to replace important (i.e., input-
based) comparisons with the hash functions provided by AN-
TIFUZZ. Due to the nature of cryptographic hashes, two hash
values can only be checked for equality, and not whether one
is larger or smaller than the other.
To encrypt and decrypt the input buffer, we use the AES-
256 encryption function in ECB mode. The key is gener-
ated from a hash of the input at runtime. We provide a func-
tion that provides the encryption-decryption routine. We can
use this function on any kind of input stream. We provide
antifuzz_fread() as a convenience to make it easier to in-
tegrate the common cases. Any call to fread() needs to be
replaced with its ANTIFUZZ-equivalent call.
Figure 2 illustrates the implementation of all described
techniques using ANTIFUZZ in a simple program. Figure 2.a
shows an unprotected application which is checking an input
value. If the input is valid, it might lead to a program crash
caused by a bug. Otherwise, the program will print some error
and exit. Figure 2.b illustrates the same program which is
now protected by ANTIFUZZ. Additional layers of fake edges
and constraints are speciﬁcally targeting coverage-guided
fuzzers. Further down the control-ﬂow graph of the protected
application, ANTIFUZZ added its input encryption/decryption
routine. Next in the Figure 2.b, ANTIFUZZ installs its custom
signal handler and then causes an intentional segmentation
fault (fake crash). However, since ANTIFUZZ installed a cus-
tom signal handler, it receives the signal and checks whether
it is the fake crash or not. If it is legitimate, it delays the ex-
ecution and then exits gracefully. This step basically is the
anti-crash detection implementation of ANTIFUZZ, which
works together with an execution delay mechanism. Finally,
in Figure 2.b, we harden the comparison against 1337 with a
comparison of hashed values.
6 Evaluation
Our evaluation aims to answer the following ﬁve research
questions (RQs):