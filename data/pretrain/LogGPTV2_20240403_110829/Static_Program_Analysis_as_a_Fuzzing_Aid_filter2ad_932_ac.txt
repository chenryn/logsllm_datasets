### Protocol Fragment Extraction and Test Coverage Enhancement

By employing backward slicing from well-known taint sinks, such as `memcmp`, we have successfully extracted protocol fragments, including the string literal "America Online Inc." used by nDPI to fingerprint instant messaging traffic. These fragments have significantly increased test coverage.

**Listing 1.2: Syntactic Query on nDPI and libxml2 Codebases**

The following query returns string literals passed as arguments to taint sinks like `strcmp`.

```cpp
// Obtain string literals passed to POSIX APIs "strcmp" and "memcmp", and
// libxml2 APIs "xmlBufferWriteChar" and "xmlOutputBufferWrite".
StatementMatcher StringMatcher =
    stringLiteral(
        hasAncestor(
            declRefExpr(
                to(namedDecl(
                    anyOf(
                        hasName("strcmp"),
                        hasName("memcmp"),
                        hasName("xmlBufferWriteChar"),
                        hasName("xmlOutputBufferWrite")
                    )
                ))
            )
        )
    ).bind("construct");
```

### Benchmarks: Time to Vulnerability Exposure

To facilitate independent reproduction, we briefly document our evaluation methodology.

**Fuzzer Test Suite**

We used the fuzzer test suite [15] to measure the time required to expose program vulnerabilities. This suite is ideal for this purpose because it provides a controlled environment for timing measurements and includes test cases for several high-profile vulnerabilities. The specific vulnerabilities in our evaluation are:
- CVE-2014-0160 (OpenSSL Heartbleed)
- CVE-2016-5180 (buffer overflow in the c-ares DNS library)
- CVE-2015-8317 (buffer overflow in libxml2)
- A security-critical bug in Google’s WoFF2 font parser [6]

**Test Methodology**

For each test case, we measured the time to expose the underlying vulnerability in two scenarios:
1. The baseline fuzzer alone.
2. The baseline fuzzer augmented with an Orthrus-generated dictionary.

Our approach is considered effective if the time to expose the vulnerability decreases compared to the baseline. Timing measurements were conducted using Unix’s `time` utility. To minimize the effect of random variations, we obtained at least 80 timing measurements for each test case in both scenarios. Each experiment was run exclusively on a single core, and the input dictionary generated by Orthrus was supplied to libFuzzer via the `-dict` command line argument. We adhered strictly to the seed corpus selection mandated by the fuzzer test suite documentation to eliminate the effect of different seed corpuses.

**Results**

Figure 2 presents our test results as box plots. The baseline (libFuzzer) is on the left, and the results for libFuzzer augmented with Orthrus (Orthrus) are on the right. The Orthrus-generated input dictionary reduced the time to expose a buffer overflow in the libxml2 library (CVE-2015-8317) by an order of magnitude (from a median value of nearly 3 hours to 5 minutes). For all other test cases, the median time to expose the vulnerability was lower with Orthrus compared to libFuzzer. Additionally, Orthrus decreased the range of timing variations in exposing the vulnerabilities.

To understand the varying impact of the supplied dictionary, we analyzed the root causes of the tested vulnerabilities. Our approach consistently reduced the time to exposure for vulnerabilities triggered by specific file or protocol messages. Thus, our approach is particularly effective when knowledge of the input format is crucial. In scenarios where our approach did not substantially reduce the time to vulnerability exposure, the performance penalty due to dictionary mutations was minimal. In summary, static program analysis can enhance the bug-finding efficiency of fuzzers for bugs triggered by highly structured inputs, without imposing a significant performance penalty.

### Case Study

To investigate the practical utility of Orthrus, we conducted a case study on two popular network applications: nDPI and tcpdump. These applications were chosen because they are deployed in security-critical environments and parse potentially attacker-controlled data. For each application, we performed multivariate testing using baseline fuzzers (afl and aflfast) with and without an Orthrus-generated dictionary.

We also fuzzed these applications using the Peach fuzzer [29], a state-of-the-art fuzzer for protocol security assessments. Since grammar specifications for the protocols parsed by tcpdump and nDPI were not publicly available, we enabled Peach fuzzer’s input analyzer mode to automatically infer the input data model. However, the community edition of Peach fuzzer that we had access to is not designed for long runs, and we could not achieve a run time longer than 24 hours. Therefore, we document the results of our Peach experiments for reference but do not include them in the comparative evaluation.

**Evaluation Methodology**

We evaluated Orthrus using two metrics: test coverage achieved and the number of program vulnerabilities exposed. Test coverage was measured as the percentage of program branches discovered during testing. To deduplicate fuzzer crashes, we used fuzzy stack hashes [26] and manual triaging. We used two elementary seeds (bare-bone IPv4 and IPv6 packets) to fuzz tcpdump and nDPI. Tests involving afl and aflfast were conducted in a multi-core setting.

**Fuzzing Duration**

Dictionary-based mutations get a fraction of the total fuzz time. To fully evaluate our approach, we ran the fuzzer configurations (except Peach) until each unique program input synthesized by the fuzzer was mutated with the supplied dictionary constructs at least once. Due to the relatively poor execution throughput (under 100 executions per second), we ran each fuzzer over a period of one week, ensuring the supplied dictionary was utilized at least once for each unique input.

**Utilities**

We used CERT’s exploitable [11] utility for crash deduplication and AddressSanitizer [2] as a debugging aid to expedite the bug reporting process.

**Evaluated Software**

We evaluated nDPI revision f51fef6 (November 2016) and tcpdump trunk (March 2017).

**Test Coverage**

Table 3 shows the test coverage achieved by different fuzzer combinations for tcpdump and nDPI, while Figure 3 visualizes code coverage over time. The coverage measurements for tcpdump and nDPI approach a saturation point asymptotically, with a higher initial growth rate for afl-Orthrus and aflfast-Orthrus compared to their respective baselines. This results in a consistent increase in overall test coverage achieved by Orthrus. For nDPI, Orthrus' input dictionary increases test coverage by 14.57% over the afl fuzzer. For tcpdump, this increase is 9.67%. Orthrus' enhancements in test coverage over aflfast for nDPI and tcpdump are 3.7% and 7.47%, respectively.

Although aflfast is a fork of afl, the supplied input dictionary has a lesser effect on the former. We examined the source code and found that afl performs dictionary-based mutations on all inputs in the fuzzer queue at least once, whereas aflfast only does so when the input's performance score exceeds a certain threshold, which is too aggressive, resulting in fewer inputs undergoing dictionary mutations.