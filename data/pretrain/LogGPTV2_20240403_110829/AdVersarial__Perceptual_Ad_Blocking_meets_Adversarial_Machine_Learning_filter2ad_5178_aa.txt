title:AdVersarial: Perceptual Ad Blocking meets Adversarial Machine Learning
author:Florian Tramèr and
Pascal Dupr&apos;e and
Gili Rusak and
Giancarlo Pellegrino and
Dan Boneh
AdVersarial: Perceptual Ad Blocking meets
Adversarial Machine Learning
Florian Tramèr
PI:EMAIL
Stanford University
Pascal Dupré
PI:EMAIL
CISPA Helmholtz Center for
Information Security
Gili Rusak
PI:EMAIL
Stanford University
Giancarlo Pellegrino
gpellegrino@cispa.saarland
Stanford University, CISPA Helmholtz
Center for Information Security
ABSTRACT
Perceptual ad-blocking is a novel approach that detects online ad-
vertisements based on their visual content. Compared to traditional
filter lists, the use of perceptual signals is believed to be less prone
to an arms race with web publishers and ad networks. We demon-
strate that this may not be the case. We describe attacks on multiple
perceptual ad-blocking techniques, and unveil a new arms race that
likely disfavors ad-blockers. Unexpectedly, perceptual ad-blocking
can also introduce new vulnerabilities that let an attacker bypass
web security boundaries and mount DDoS attacks.
We first analyze the design space of perceptual ad-blockers and
present a unified architecture that incorporates prior academic and
commercial work. We then explore a variety of attacks on the ad-
blocker’s detection pipeline, that enable publishers or ad networks
to evade or detect ad-blocking, and at times even abuse its high
privilege level to bypass web security boundaries.
On one hand, we show that perceptual ad-blocking must visually
classify rendered web content to escape an arms race centered on
obfuscation of page markup. On the other, we present a concrete
set of attacks on visual ad-blockers by constructing adversarial
examples in a real web page context. For seven ad-detectors, we
create perturbed ads, ad-disclosure logos, and native web content
that misleads perceptual ad-blocking with 100% success rates. In
one of our attacks, we demonstrate how a malicious user can up-
load adversarial content, such as a perturbed image in a Facebook
post, that fools the ad-blocker into removing another users’ non-ad
content.
Moving beyond the Web and visual domain, we also build adver-
sarial examples for AdblockRadio, an open source radio client that
uses machine learning to detects ads in raw audio streams.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’19, November 11–15, 2019, London, United Kingdom
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6747-9/19/11...$15.00
https://doi.org/10.1145/3319535.3354222
Dan Boneh
PI:EMAIL
Stanford University
CCS CONCEPTS
• Security and privacy → Web application security; • Com-
puting methodologies → Machine learning approaches.
KEYWORDS
Ad Blocking; Machine Learning; Adversarial Examples
ACM Reference Format:
Florian Tramèr, Pascal Dupré, Gili Rusak, Giancarlo Pellegrino, and Dan
Boneh. 2019. AdVersarial: Perceptual Ad Blocking meets Adversarial Ma-
chine Learning. In 2019 ACM SIGSAC Conference on Computer and Commu-
nications Security (CCS ’19), November 11–15, 2019, London, United Kingdom.
ACM, New York, NY, USA, 17 pages. https://doi.org/10.1145/3319535.3354222
1 INTRODUCTION
Online advertising is a contentious facet of the Web. Online ads
generate over $200 billion in value [90], but many Internet users
perceive them as intrusive or malicious [46, 51, 68, 93]. The grow-
ing use of ad-blockers such as Adblock Plus and uBlock [1, 7] has
sparked a fierce arms race with publishers and advertising net-
works. Current ad-blockers maintain large crowdsourced lists of
ad metadata—such as page markup and URLs. In turn, publishers
and ad networks (including Facebook [9, 88] and 30% of the Alexa
top-10K list [95]) continuously adapt and deploy small changes to
web page code in an effort to evade, or detect ad-blocking.
Towards visual ad-blocking. This arms race has prompted ad-
blockers to search for more robust signals within ads’ visual content,
as altering these would affect user experience. One such signal is
the presence of ad-disclosures such as a “Sponsored” caption or
the AdChoices logo [24]), which many ad-networks add for trans-
parency [24]. Storey et al. [81] proposed Ad-Highlighter [82], the
first perceptual ad-blocker that detects ad-disclosures by combin-
ing web-filtering rules and computer vision techniques. Motivated
by the alleged superior robustness of perceptual techniques [81],
popular ad-blockers now incorporate similar ideas. For example,
Adblock Plus supports image-matching filters [1], while uBlock
crawls Facebook posts in search for “Sponsored” captions [7].
However, as proposed perceptual ad-blockers still partially use
markup as a proxy for ads’ visual content, they appear insufficient
to end the ad-blocking arms race. For example, Facebook routinely
evades uBlock Origin using increasingly complex HTML obfuscation
for the “Sponsored” captions (see [88]). Ad-Highlighter’s computer
Session 9B: ML Security IIICCS ’19, November 11–15, 2019, London, United Kingdom2005vision pipeline is also vulnerable to markup tricks such as image
fragmentation or spriting (see Figure 10). Escaping the arms race
over markup obfuscation requires perceptual ad-blockers to move
towards operating on rendered web content. This is exemplified in
Adblock Plus’ Sentinel project [10], that uses deep learning to detect
ads directly in web page screenshots. On a similar note, Percival [84]
is a recently proposed ad-blocker that adds a deep learning ad-
classifier into the rendering pipeline of the Chromium and Brave
browsers. While these approaches might bring an end to the current
markup-level arms race, our paper shows that visual ad-blocking
merely replaces this arms race with a new one, involving powerful
attacks that directly target the ad-blockers’ visual classifier.
A security analysis of perceptual ad-blocking. In this paper, we
present the first comprehensive security analysis of perceptual
ad-blockers, and challenge the belief that perceptual signals will
end the ad-blocking arms race. To provide a principled analysis
of the design space of these nascent ad-blocking techniques, we
first propose a general architecture that incorporates and extends
existing approaches, e.g., Ad-Highlighter [81, 82], Sentinel [10, 61]
and Percival [84]. We view perceptual ad-blocking as a classification
pipeline, where segmented web data is fed into one of a variety of
possible ad (or ad-disclosure) detectors.
Given this unified view of the design space, we identify and ana-
lyze a variety of attacks that affect each step of the ad-classification
pipeline. Multiple adversaries—publishers, ad networks, advertisers
or content creators—can exploit these vulnerabilities to evade, de-
tect and abuse ad-blockers. Our attacks combine techniques from
Web security and from adversarial machine learning [65]. In particu-
lar, we leverage visual adversarial examples [83], slightly perturbed
images that fool state-of-the-art classifiers.
Web attacks on perceptual ad-blockers. First, we show that ad-
blocking approaches that combine traditional markup filters and
visual signals remain vulnerable to the same attacks as current
filter-lists. HTML obfuscation of ad-disclosures is already ob-
served today [88], and we demonstrate similar attacks against
Ad-Highlighter’s image-matching pipeline (e.g., by fragmenting im-
ages). Thus, unless ad-blockers move towards relying on rendered
web content (as in Sentinel [10]), perceptual signals will not end
the ongoing markup arms race with ad-networks and publishers.
In addition to visual signals, Storey et al. [81] suggest to detect
ad-disclosures using behavioral signals such as the presence of a link
to an ad-policy page. We demonstrate that such signals can lead to
serious vulnerabilities (e.g., CSRF, DDoS or click-fraud). Specifically,
we show how a Facebook user can trick Ad-Highlighter into making
arbitrary web requests in other ad-block users’ browsers.
Adversarial examples for ad-classifiers. Ad-blockers can counter
the above attacks by operating on rendered web content. The main
threat to visual ad-blockers are then adversarial examples, which
challenge the core assumption that ML can emulate humans’ visual
ad-detection. To our knowledge, our attacks are the first application
of adversarial examples to a real-world web-security problem. 1
1Gilmer et al. [31] argue that the threat model of adversarial examples—in particular
the fact that the adversary is restricted to imperceptible perturbations of a given
input—is often unrepresentative of real security threats. Perceptual ad-blocking is
a perfect example where this threat model is entirely appropriate. The ad-blocker’s
adversaries—who have white-box access to its classifier—want to evade it on specific
Figure 1: Ad-Blocker Privilege Hijacking. A malicious user,
Jerry, posts adversarial content to Facebook that fools a per-
ceptual ad-blocker similar to Sentinel [10] into marking
Tom’s benign content as an ad (red box) and blocking it in
every user’s browser.
We rigorously assess the threat of adversarial examples on seven
visual ad-classifiers: Two computer-vision algorithms (perceptual
hashing and OCR) used in Ad-Highlighter [81]; the ad-classification
neural networks used by Percival [84] and [40]; a canonical fea-
ture matching model based on the Scale-Invariant Feature Trans-
form (SIFT) [52]; and two object detector networks emulating Sen-
tinel [10]. For each model, we create imperceptibly perturbed ads,
ad-disclosure or native content, that either evade the model’s de-
tection or falsely trigger it (as a means of detecting ad-blocking).
Among our contributions is a new evasion attack [41, 73] on
SIFT [52] that is conceptually simpler than prior work [39].
Attacking perceptual ad-blockers such as Sentinel [10] presents
the most interesting challenges. For these, the classifier’s input is
a screenshot of a web page with contents controlled by different
entities (e.g, publishers and ad networks). Adversarial perturbations
must thus be encoded into HTML elements that the adversary
controls, be robust to content changes from other parties, and scale
to thousands of pages and ads. We tackle the adversary’s uncertainty
about other parties’ page contents by adapting techniques used for
creating physical adversarial examples [12, 75]. We also propose a
novel application of universal adversarial examples [56] to create a
single perturbation that can be applied at scale to all combinations
of websites and ads with near 100% success probability.
We further show that adversarial examples enable new attacks,
wherein malicious content from one user can hijack the ad-blocker’s
high privilege to incorrectly block another user’s content. An ex-
ample is shown in Figure 1. Here Jerry, the adversary, uploads a
perturbed image to Facebook. That image is placed next to Tom’s
post, and confuses the ad-blocker into classifying Tom’s benign
post as an ad, and incorrectly blocking it. Hence, a malicious post
by one user can cause another user’s post to get blocked.
Moving beyond the Web and visual domain, we build imper-
ceptible audio adversarial examples for AdblockRadio [2], a radio
ad-blocker that uses ML to detect ads in raw audio streams.
Outlook. While visual ad-classification of rendered web content
is both sufficient and necessary to bring an end to the arms race
around page markup obfuscation, we show that this merely replaces
inputs (e.g., an ad-network cannot “sample” new ads until it finds one that evades the
ad-blocker), with attacks that the user should be oblivious to.
Session 9B: ML Security IIICCS ’19, November 11–15, 2019, London, United Kingdom2006(a)
(b)
(c)
Figure 2: The AdChoices Logo. AdChoices is a standard for
disclosure of behavioral advertising [24]. Ads are marked by
the icon (a), with optional text (b). Despite creative guide-
lines [25], many variants of the logo are in use (c).
one arms race with a new one centered on adversarial examples.
Our attacks are not just a first step in this new arms race, where
ad-blockers can easily regain the upper hand. Instead, they describe
an inherent difficulty with the perceptual ad-blocking approach, as
ad-blockers operate in essentially the worst threat model for visual
classifiers. Their adversaries prepare (offline) digital attacks to evade
or falsely trigger a known white-box visual classifier running inside
the ad-blocker. In contrast, the ad-blocker must resist these attacks
while operating under strict real-time constraints.
Our study’s goal is not to downplay the merits of ad-blocking, nor
discredit the perceptual ad-blocking philosophy. Indeed, ML might
one day achieve human-level perception. Instead, we highlight
and raise awareness of the inherent vulnerabilities that arise from
instantiating perceptual ad-blockers with existing ML techniques.
Contributions. This paper makes the following contributions:
• We conduct a detailed security analysis of perceptual ad-
blocking;
• We present nine general classes of attacks against the various
components of the perceptual ad-blocking pipeline;
• We evaluate adversarial examples for eight ad classifiers (seven
visual, one audio). We make novel use of transformation-
robust [12] and universal adversarial examples [56] to create
scalable attacks robust to arbitrary changes in web content.
• We release all our data and classifiers, including a new neural
network that locates ads in web page screenshots, that may
prove useful in non-adversarial settings: https://github.com/
ftramer/ad-versarial
2 PRELIMINARIES AND BACKGROUND
2.1 The Online Advertising Ecosystem
Online advertising comprises four actors: users, publishers, ad net-
works, and advertisers. Users browse websites owned or curated
by a publisher. Publishers assigns parts of the site’s layout to ad-
vertisements. Control of these spaces is often outsourced to an ad
network that populates them with advertisers’ contents.
To protect users from deceptive ads, the Federal Trade Com-
mission and similar non-US agencies require ads to be clearly rec-
ognizable [26]. These provisions have also spawned industry self-
regulation, such as the AdChoices standard [24] (see Figure 2).
2.2 Perceptual Ad-Blocking
Perceptual ad-blocking aims at identifying ads from their content,
rather than from ad metadata such as URLs and markup. The insight
of Storey et al. [81] is that many ads are explicitly marked—e.g., via a
“Sponsored” link or the AdChoices logo—to comply with regulations
on deceptive advertising. They developed Ad-Highlighter [82], an
ad-blocker that detects ad-disclosures using different perceptual
techniques: (i) textual searches for “Sponsored” tags, (ii) fuzzy image
search and OCR to detect the AdChoices logo, and (iii) “behavioral”
detection of ad-disclosures by identifying links to ad-policy pages.
Ad-blockers that rely on perceptual signals are presumed to be less
prone to an arms race, as altering these signals would affect user
experience or violate ad-disclosure regulations [81].
Perceptual ad-blocking has drawn the attention of major ad-
blockers, that have integrated visual signals into their pipelines. For
example, uBlock blocks Facebook ads by detecting the “Sponsored”
caption. Adblock Plus has added support for image-matching rules,
which are easily extended to fuzzy image search [8].
The above perceptual ad-blocking approaches still rely on some
markup data as a proxy for ads’ visual content. This has prompted
an ongoing arms race between Facebook and uBlock (see [88])
where the former continuously obfuscates the HTML tags that ren-
der its “Sponsored” tag—a process that is invisible to the user. This
weakness is fundamental to perceptual approaches that rely on
signals with an indirect correspondence to ads’ rendered content.
This insight led Adblock Plus to announce the ambitious goal of
detecting ads directly from rendered web pages—with no reliance
on markup—by leveraging advances in image classification. Their
Sentinel [10] project uses an object-detection neural network to
locate ads in raw Facebook screenshots. The recently released Perci-
val project [84] targets a similar goal, by embedding a deep-learning
based ad-blocker directly into Chromium’s rendering engine.
2.2.1 Design and Goals. Ad-blockers are client-side programs run-