# AdVersarial: Perceptual Ad Blocking Meets Adversarial Machine Learning

**Authors:**
- Florian Tramèr, Stanford University
- Pascal Dupré, CISPA Helmholtz Center for Information Security
- Gili Rusak, Stanford University
- Giancarlo Pellegrino, Stanford University and CISPA Helmholtz Center for Information Security
- Dan Boneh, Stanford University

## Abstract
Perceptual ad-blocking is a novel approach that detects online advertisements based on their visual content. This method is believed to be less susceptible to the arms race with web publishers and ad networks compared to traditional filter lists. However, we demonstrate that this may not be the case. We present a series of attacks on multiple perceptual ad-blocking techniques, revealing a new arms race that likely disfavors ad-blockers. Additionally, perceptual ad-blocking can introduce new vulnerabilities, allowing attackers to bypass web security boundaries and launch DDoS attacks.

We first analyze the design space of perceptual ad-blockers and propose a unified architecture that incorporates prior academic and commercial work. We then explore various attacks on the ad-blocker’s detection pipeline, enabling publishers or ad networks to evade or detect ad-blocking, and even abuse the high privilege level to bypass web security boundaries.

On one hand, we show that perceptual ad-blocking must visually classify rendered web content to escape an arms race centered on obfuscation of page markup. On the other hand, we present concrete attacks on visual ad-blockers by constructing adversarial examples in a real web page context. For seven ad-detectors, we create perturbed ads, ad-disclosure logos, and native web content that mislead perceptual ad-blocking with 100% success rates. In one of our attacks, we demonstrate how a malicious user can upload adversarial content, such as a perturbed image in a Facebook post, that fools the ad-blocker into removing another user's non-ad content.

Beyond the web and visual domain, we also build adversarial examples for AdblockRadio, an open-source radio client that uses machine learning to detect ads in raw audio streams.

**CCS Concepts:**
- Security and privacy → Web application security
- Computing methodologies → Machine learning approaches

**Keywords:**
- Ad Blocking
- Machine Learning
- Adversarial Examples

**ACM Reference Format:**
Florian Tramèr, Pascal Dupré, Gili Rusak, Giancarlo Pellegrino, and Dan Boneh. 2019. AdVersarial: Perceptual Ad Blocking meets Adversarial Machine Learning. In 2019 ACM SIGSAC Conference on Computer and Communications Security (CCS '19), November 11–15, 2019, London, United Kingdom. ACM, New York, NY, USA, 17 pages. https://doi.org/10.1145/3319535.3354222

## 1. Introduction
Online advertising generates over $200 billion in value but is often perceived as intrusive or malicious by many Internet users. The growing use of ad-blockers such as Adblock Plus and uBlock has sparked an arms race with publishers and advertising networks. Current ad-blockers maintain large crowdsourced lists of ad metadata, while publishers and ad networks continuously adapt and deploy small changes to web page code to evade or detect ad-blocking.

### Towards Visual Ad-Blocking
This arms race has prompted ad-blockers to search for more robust signals within ads’ visual content, as altering these would affect user experience. One such signal is the presence of ad-disclosures like “Sponsored” captions or the AdChoices logo. Storey et al. [81] proposed Ad-Highlighter [82], the first perceptual ad-blocker that combines web-filtering rules and computer vision techniques. Motivated by the alleged superior robustness of perceptual techniques, popular ad-blockers now incorporate similar ideas. For example, Adblock Plus supports image-matching filters, while uBlock crawls Facebook posts in search of “Sponsored” captions.

However, as proposed perceptual ad-blockers still partially use markup as a proxy for ads’ visual content, they are insufficient to end the ad-blocking arms race. Facebook, for instance, routinely evades uBlock Origin using increasingly complex HTML obfuscation for the “Sponsored” captions. Ad-Highlighter’s computer vision pipeline is also vulnerable to markup tricks such as image fragmentation or spriting. Escaping the arms race over markup obfuscation requires perceptual ad-blockers to operate on rendered web content. This is exemplified in Adblock Plus’ Sentinel project, which uses deep learning to detect ads directly in web page screenshots. Similarly, Percival is a recently proposed ad-blocker that adds a deep learning ad-classifier into the rendering pipeline of Chromium and Brave browsers. While these approaches might bring an end to the current markup-level arms race, our paper shows that visual ad-blocking merely replaces this arms race with a new one, involving powerful attacks that directly target the ad-blockers’ visual classifier.

### A Security Analysis of Perceptual Ad-Blocking
In this paper, we present the first comprehensive security analysis of perceptual ad-blockers, challenging the belief that perceptual signals will end the ad-blocking arms race. To provide a principled analysis of the design space of these nascent ad-blocking techniques, we propose a general architecture that incorporates and extends existing approaches, such as Ad-Highlighter, Sentinel, and Percival. We view perceptual ad-blocking as a classification pipeline where segmented web data is fed into one of a variety of possible ad (or ad-disclosure) detectors.

Given this unified view, we identify and analyze a variety of attacks that affect each step of the ad-classification pipeline. Multiple adversaries—publishers, ad networks, advertisers, or content creators—can exploit these vulnerabilities to evade, detect, and abuse ad-blockers. Our attacks combine techniques from web security and adversarial machine learning, leveraging visual adversarial examples that slightly perturb images to fool state-of-the-art classifiers.

### Web Attacks on Perceptual Ad-Blockers
First, we show that ad-blocking approaches combining traditional markup filters and visual signals remain vulnerable to the same attacks as current filter-lists. HTML obfuscation of ad-disclosures is already observed today, and we demonstrate similar attacks against Ad-Highlighter’s image-matching pipeline. Thus, unless ad-blockers move towards relying on rendered web content, perceptual signals will not end the ongoing markup arms race with ad-networks and publishers.

In addition to visual signals, Storey et al. suggest detecting ad-disclosures using behavioral signals such as the presence of a link to an ad-policy page. We demonstrate that such signals can lead to serious vulnerabilities, including CSRF, DDoS, or click-fraud. Specifically, we show how a Facebook user can trick Ad-Highlighter into making arbitrary web requests in other ad-block users’ browsers.

### Adversarial Examples for Ad-Classifiers
Ad-blockers can counter the above attacks by operating on rendered web content. The main threat to visual ad-blockers are then adversarial examples, which challenge the core assumption that ML can emulate humans’ visual ad-detection. To our knowledge, our attacks are the first application of adversarial examples to a real-world web-security problem. We rigorously assess the threat of adversarial examples on seven visual ad-classifiers, including two computer-vision algorithms used in Ad-Highlighter, the ad-classification neural networks used by Percival, a canonical feature matching model based on SIFT, and two object detector networks emulating Sentinel. For each model, we create imperceptibly perturbed ads, ad-disclosure, or native content that either evades the model’s detection or falsely triggers it.

Among our contributions is a new evasion attack on SIFT that is conceptually simpler than prior work. Attacking perceptual ad-blockers such as Sentinel presents the most interesting challenges, as the classifier’s input is a screenshot of a web page with contents controlled by different entities. Adversarial perturbations must be encoded into HTML elements that the adversary controls, be robust to content changes from other parties, and scale to thousands of pages and ads. We tackle the adversary’s uncertainty about other parties’ page contents by adapting techniques used for creating physical adversarial examples and proposing a novel application of universal adversarial examples to create a single perturbation that can be applied at scale with near 100% success probability.

We further show that adversarial examples enable new attacks, wherein malicious content from one user can hijack the ad-blocker’s high privilege to incorrectly block another user’s content. An example is shown in Figure 1, where Jerry, the adversary, uploads a perturbed image to Facebook, causing Tom’s benign post to be incorrectly blocked.

### Beyond the Web and Visual Domain
Moving beyond the web and visual domain, we build imperceptible audio adversarial examples for AdblockRadio, a radio ad-blocker that uses ML to detect ads in raw audio streams.

### Outlook
While visual ad-classification of rendered web content is both sufficient and necessary to bring an end to the arms race around page markup obfuscation, we show that this merely replaces one arms race with a new one centered on adversarial examples. Our attacks are not just a first step in this new arms race, where ad-blockers can easily regain the upper hand. Instead, they describe an inherent difficulty with the perceptual ad-blocking approach, as ad-blockers operate in essentially the worst threat model for visual classifiers. Their adversaries prepare digital attacks to evade or falsely trigger a known white-box visual classifier running inside the ad-blocker, while the ad-blocker must resist these attacks under strict real-time constraints.

Our study’s goal is not to downplay the merits of ad-blocking nor discredit the perceptual ad-blocking philosophy. Instead, we highlight and raise awareness of the inherent vulnerabilities that arise from instantiating perceptual ad-blockers with existing ML techniques.

### Contributions
- We conduct a detailed security analysis of perceptual ad-blocking.
- We present nine general classes of attacks against the various components of the perceptual ad-blocking pipeline.
- We evaluate adversarial examples for eight ad classifiers (seven visual, one audio). We make novel use of transformation-robust and universal adversarial examples to create scalable attacks robust to arbitrary changes in web content.
- We release all our data and classifiers, including a new neural network that locates ads in web page screenshots, which may prove useful in non-adversarial settings: https://github.com/ftramer/ad-versarial

## 2. Preliminaries and Background

### 2.1 The Online Advertising Ecosystem
Online advertising involves four actors: users, publishers, ad networks, and advertisers. Users browse websites owned or curated by a publisher. Publishers assign parts of the site’s layout to advertisements, often outsourcing control of these spaces to an ad network that populates them with advertisers’ content.

To protect users from deceptive ads, regulatory agencies require ads to be clearly recognizable. These provisions have also spawned industry self-regulation, such as the AdChoices standard (see Figure 2).

### 2.2 Perceptual Ad-Blocking
Perceptual ad-blocking aims to identify ads from their content rather than from ad metadata such as URLs and markup. The insight of Storey et al. [81] is that many ads are explicitly marked—e.g., via a “Sponsored” link or the AdChoices logo—to comply with regulations on deceptive advertising. They developed Ad-Highlighter [82], an ad-blocker that detects ad-disclosures using different perceptual techniques: (i) textual searches for “Sponsored” tags, (ii) fuzzy image search and OCR to detect the AdChoices logo, and (iii) “behavioral” detection of ad-disclosures by identifying links to ad-policy pages.

Perceptual ad-blocking has drawn the attention of major ad-blockers, who have integrated visual signals into their pipelines. For example, uBlock blocks Facebook ads by detecting the “Sponsored” caption. Adblock Plus has added support for image-matching rules, which are easily extended to fuzzy image search [8].

The above perceptual ad-blocking approaches still rely on some markup data as a proxy for ads’ visual content. This has prompted an ongoing arms race between Facebook and uBlock, where the former continuously obfuscates the HTML tags that render its “Sponsored” tag—a process invisible to the user. This weakness is fundamental to perceptual approaches that rely on signals with an indirect correspondence to ads’ rendered content.

This insight led Adblock Plus to announce the ambitious goal of detecting ads directly from rendered web pages, with no reliance on markup, by leveraging advances in image classification. Their Sentinel [10] project uses an object-detection neural network to locate ads in raw Facebook screenshots. The recently released Percival project [84] targets a similar goal by embedding a deep-learning-based ad-blocker directly into Chromium’s rendering engine.

### 2.2.1 Design and Goals
Ad-blockers are client-side programs run by users to remove or alter ads on web pages. The primary goal of perceptual ad-blocking is to detect and block ads based on their visual content, thereby providing a more robust and user-friendly alternative to traditional filter lists.