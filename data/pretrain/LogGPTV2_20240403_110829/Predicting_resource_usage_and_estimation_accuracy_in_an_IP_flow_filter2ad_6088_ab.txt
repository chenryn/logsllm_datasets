5
4
3
2
1
0
unsampled 
 N = 25
N = 100
0
5
10
15
20
Figure 3: ESTIMATED 10 MINUTE BYTE RATES FOR NNTP TRAFFIC OVER 24 HOUR PERIOD: smart sampling (left) and uniform
sampling (right)
sampling with a uniform distribution over ﬂow sizes is problematic
for usage estimation, since the estimates are very sensitive to omis-
sion of a single large ﬂow. Smart sampling avoids this problem
by always selecting large ﬂows. This approach was proposed in
[6, 7]. The probability pz represents an optimal trade-off between
the variance v of usage estimation, and expected number n of ﬂows
sampled in the following sense. Although in principle any non-zero
size-dependent probability p(x) may be used for ﬂow sampling,
pz is distinguished by the property that it minimizes v + z2n, re-
gardless of the actual ﬂow lengths. It is worth noting that, even
in the composite sampling scheme considered in this paper, once
the packet sampling period N is speciﬁed, use of ﬂow sampling
probability pz is still optimal in the above sense.
More generally, one can consider the trade-off between packet
sampling and ﬂow sampling. From Section 2.5.2 it is clear that
some amount of packet sampling is required at the router. In ex-
periments it is found that when further sampling is required, smart
sampling yields smaller bandwidth for a given variance of usage
estimates [7]. This is because it can capitalize on the compression
inherent in the formation of ﬂow records, as compared with reports
on the constituent packets.
In order to form an unbiased estimate of the original usage, a
ﬂow that reports x bytes, is normalized through division by the
selection probability, i.e., its contribution to the usage estimate is
x/pz(x) = max{x, z} bytes. Thus ﬂows whose size exceeds the
threshold z are (always) reported unaltered. Flows whose size is
less than z, have their size reported at z, if they survive sampling.
2.5.5 Comparing Smart and Uniform Sampling
Smart sampling allows vastly improved estimation accuracy, as
compared with uniform sampling, for a given volume of collected
ﬂow records. As an illustrative application, we compare the efﬁ-
cacy of the two sampling methods in estimating usage in classes of
trafﬁc. Raw NetFlow records were collected from a router over a
24 hour period. The task is to estimate byte usage by network news
(nntp) trafﬁc, as identiﬁed by application port number. This trafﬁc
comprised roughly 0.55% of all observed trafﬁc. Smart sampling
and uniform sampling were applied to each of the raw NetFlow
records for a range of sampling parameters. Figure 3 shows the es-
timated byte usage for smart sampling (left) and uniform sampling
(right), expressed as an average byte rate over 10 minute intervals.
Table 1 shows the effective sampling periods (i.e. the reciprocal of
the average rate at which ﬂows are sampled), and the relative errors
between estimated and actual rates, maximized over the set of 10
minute intervals.
In Figure 3(left) the points for smart sampling with threshold z
up to 1MByte are virtually indistinguishable from the true values
(i.e. those with no sampling). With this threshold, about 1 in 127
ﬂows are sampled, and the relative error is about 0.02. With uni-
form sampling at a comparable ﬂow sampling rate, 1 in N = 100,
the relative error is 3.1, i.e. over 150 times larger. This is re-
ﬂected in Figure 3(right), in which the estimated byte rates can
differ greatly from the true rates. By contrast, when smart sam-
pling threshold z = 10MBytes, i.e., sampling a little less than 1 in
1,000 ﬂows on average, the systematic variation in byte rate can
still be clearly discerned. An example showing the accuracy of
smart sampling in estimating per address usage is described in [6].
2.5.6 Composition of Sampling and Renormalization
Although sampling in TAP occurs in a speciﬁc order (packet
sampling, followed by ﬂow dropping, followed by smart sampling)
the corresponding renormalizations may be applied in any order
without biasing usage estimates. In the TAP architecture, renor-
malization for packet sampling is applied ﬁrst, followed by smart
sampling, ﬁnishing with ﬂow dropping. The ﬂow dropping normal-
ization is applied last because the average drop rate is determined
only after ﬂow records have been aggregated.
Method
No sampling
Smart
Smart
Smart
Smart
Uniform
Uniform
Parameter
z = 100kBytes
z = 1MByte
z = 10MBytes
z = 100MBytes
N = 25
N = 100
Flows Sampled
328,198,000
13,468,500
2,574,900
326,222
33,117
13,127,900
3,281,980
Period
1
24
127
1006
9910
25
100
Rel. Error
0
0.0028
0.020
0.23
0.81
1.2
3.1
Table 1: COMPARISON OF SAMPLING METHODS: method;
parameters; ﬂow records sampled; proportion of ﬂow records
sampled; maximum relative error for 10 minute average rates.
We illustrate with the examples in Figure 2. The packet sampling
period is N = 3, the packet transmission probability is q = 0.75,
and the smart sampling threshold is z = 9. For simplicity we set
all packets to have the nominal size of 1 byte.
The ﬁrst sampled ﬂow record has b = 4 bytes, and survives
transmission. It enters smart sampling reporting N b = 12 bytes.
This exceeds the smart sampling threshold of z = 9, and hence
this ﬂow is smart sampled with probability 1, reporting 12 bytes.
Finally, the reported bytes are normalized through division by q,
yielding 16 bytes.
The second sampled ﬂow record has b = 2 bytes, and sur-
It enters smart sampling reporting N b = 6
vives transmission.
bytes. Since this is less than z, it is smart sampled with probability
N b/z = 2/3. In happens to be discarded.
The third sampled ﬂow record has b = 1 byte, and happens to be
lost in transmission.
The fourth sampled ﬂow has size b = 1 byte, and is trans-
mitted successfully. It enters smart sampling reporting N b = 3
bytes. Since this is less than z, it is smart sampled with probability
N b/z = 1/3. It happens to be selected, and exits smart sampling
reporting max{z, N b} = 9 bytes. Finally, the reported bytes are
normalized through division by q, yielding 12 bytes.
The total bytes reported is 28; the total number of bytes of the
original packet stream (top row) was 24.
3. MODELING SAMPLING PROCESSES
The aim of this section is to model the effect of sampling upon
usage measurements. In doing so we regard the set of packets and
ﬂows sizes of the trafﬁc as deterministic quantities, representing
the actual usage that is to be estimated. The only randomness that
enters is due to the sampling itself.
In applications we wish to
estimate the usage for each trafﬁc class of interest. The statistical
properties of the underlying trafﬁc, which may be very complex,
do not enter the estimates.
3.1 Model for Sampled NetFlow
Within the functional requirement of sampling packets at a given
rate, different implementations are possible. In Sampled NetFlow
as provided by Cisco [4] packets are selected periodically, i.e., ev-
ery N th packet is selected for some period N. Another possibility
is to sample packets independently with probability 1/N–e.g. as
performed by sFlow [14], then compile ﬂow records from the sam-
pled packets. To what extent do the implementation details have
ramiﬁcations for modeling the sampling process?
Periodic sampling introduces correlations into the sampling pro-
cess: when a packet is selected, none of the following N−1 packets
are selected. Although this does not bias against selection of any
one packet, it can bias against selection of multiple packets from
short ﬂows. We do not believe this effect would be important for
sampling from high speed links that carry many ﬂows concurrently.
In this case, successive packets of a given ﬂow would be inter-
spersed by many packets from other ﬂows, effectively randomizing
packet selection from the given ﬂow. While such randomization
may not be effective at lower speed routers carrying fewer ﬂows
(e.g. edge routers), packet sampling is not expected to be crucial
for ﬂow formation in this case. For these reasons, we will model
the sampling of packets from a given ﬂow as being independent.
3.2 Model for Dropping of Flow Reports
We assume that ﬂow records are transmitted independently with
some probability q. Thus, we can view record loss as equivalent
to independent sampling with probability q. Note that, in princi-
ple, more complex patterns of dependent loss amongst ﬂow records
could also be detected from the received sequence numbers, and an
appropriate model constructed. We do not pursue this here.
3.3 Model for Smart Sampling
We assume that, conditioned on the set of packet and ﬂows pre-
sented in the trafﬁc, the selections of ﬂows during smart sampling
are mutually independent. This property is sometimes called con-
ditional independence. Conditionally independent selection occurs
when an independent random variate ω in [0, 1] is generated for
each ﬂow, a ﬂow of size x being selected if ω ≤ pz(x). This man-
ner of sampling can be implemented using a pseduorandom genera-
tor (such as [17]) for the ω. Note that the potentially complex statis-
tical properties of the the trafﬁc process— such as heavy tailedness
of ﬂow lengths and correlations amongst ﬂows and packets—do
not play a role because we condition on the single “sample-path”
of trafﬁc that is actually present. (On the other hand, if one aver-
aged over a distribution of sample-paths that exhibited dependence
between ﬂow length, ﬂow selection would be dependent).
An alternative approach to random selection is to use the ﬂow
sizes themselves as a source of randomness; see [8]. This is com-
putationally simpler, but does incur some dependence between se-
lection of different ﬂows. However, similar arguments to those we
made above for periodic packet sampling lead us to expect that de-
pendence will be weak when considering ﬂows of a given key. This
was found to be the case in experiments.
3.4 Sparse Flows and Splitting
Packet sampling can increase the number of measured ﬂows.
Given a sampling period N and a ﬂow interpacket timeout T , we
say that a given original ﬂow of packets is sparse if the typical
time between sampled packets exceeds T . In this case, a single
original ﬂow may give rise to multiple ﬂow records, each sampled
packet giving rise to one measured ﬂow record. To see more pre-
cisely when this can happen, consider an original ﬂow comprising
n packets distributed over an interval of duration t. The typical
time between sampled packets is tN/n, thus sparseness requires
than tN/(nT ) > 1. It also requires that there is typically more
than one sampled packet, i.e., n/N > 1. Combining, we can say
that the threshold for sparseness is crossed when
t
T
>
n
N
> 1.
(1)
From these conditions, we see that sparseness is most likely to arise
for ﬂows containing many packets occurring with relatively low
frequency. In experiments, it is found that streaming and multime-
dia applications generate sparse ﬂows at what may be reasonable
settings for sampled ﬂow measurement: sampling period N = 100
and ﬂow interpacket timeout T = 30s. See [7] for further details.
In this paper our interest in sparseness lies in understanding its
impact, if any, on the variance of usage estimates, and the volume
of ﬂow records. Although splitting may increase or decrease the
estimation variance, a simple bound we obtain is unaffected, re-
gardless of splitting. In order to calculate the effect on the volume
of measured ﬂows, we shall need to adopt a particular model of the
distribution of packets in the ﬂow.
4. SAMPLING ERROR IN USAGE ESTIMATES
Reduction by sampling of the volume of sampled data comes at
the cost of inherent uncertainty over the estimates of network usage
derived therefrom. Smart sampling has been tailored to optimize
the trade off between sample volume and estimator accuracy, and to
mitigate against the high variability of estimation that would occur
if ﬂow records were uniformly sampled.
(cid:1)n
4.1 Bounds on the Sampling Error
We aim to estimate the total usage X =
Estimation takes the following form in each stage of sampling.
from the statistical properties of these indicators. The quantities n,
mi and bij are considered ﬁxed in any given estimation problem.
may itself be a random quantity arising from an earlier stage of
sampling. Let w be an indicator random variable, conditionally
i=1 xi from n ﬂows
of sizes x1, . . . , xn, for example, ﬂows in a given trafﬁc class of in-
terest. Each ﬂow i in comprises mi packets of sizes bi1, . . . , bimi ;
hence xi =
according to the sampling operations and normalizations described
in Section 2.5, as modeled in Section 3. We will use random indi-
(cid:1)mi
j=i bij. We construct an estimator (cid:2)X of the usage X
cators (variables taking the value 0 or 1) to write (cid:2)X as a random
sum over all packets and ﬂows. The variance of (cid:2)X derives entirely
An object (a packet or a ﬂow) of some size(cid:2)x > 0 is selected with
some probability p((cid:2)x) > 0 that may depend on (cid:2)x. The size (cid:2)x
independent of(cid:2)x, that takes the value 1 with probability p((cid:2)x). Then
we form an estimate(cid:2)y =(cid:2)x · w/p((cid:2)x), i.e., by multiplying with the
random quantity w/p((cid:2)x).
the contribution(cid:2)x to usage is scaled up by a factor 1/p((cid:2)x) relative
to the actual usage. But for a given value of(cid:2)x, w/p has expectation
1, and hence(cid:2)y is an unbiased estimator of(cid:2)x in the sense that the its
conditional expectation obeys E[(cid:2)y |(cid:2)x] =(cid:2)x.
We also need to treat the special case(cid:2)x = 0 which arises when
this case we want to have(cid:2)y = 0 too. However, it is useful to have
the deﬁnition(cid:2)y =(cid:2)x·w/p((cid:2)x) work transparently in the calculations.
x/p(x) at x = 0 by continuity. As a result(cid:2)y = 0 as required, since
A potential problem arises if p(0) = 0; this happens for smart
sampling but not for packet sampling. A general approach is to
assume that x/p(x) is continuous from the right at x = 0. (This
is true for smart sampling). Then when p(0) = 0 we can deﬁne
If the object is not selected, w = 0,
i.e., usage which is not sampled makes no contribution to usage
estimates. On the other hand, if the object is selected, w = 1, the
the object was not selected in some previous stage of sampling. In
either p(0) > 0 (in which case x/p(x) = 0 at x = 0), or p(0) = 0
(in which case w is 0 with probability 1 when x = 0).
In preparation for analyzing the statistical properties of the us-
age estimates, we use the scheme just described to write the usage
estimates in terms of the underlying packet and ﬂow sizes, and the
indicator random variables for sampling.
• Packet Sampling: The total estimated bytes from packets
from ﬂow i are N
j=1 uij bij where the uij are mutually
independent indicator random variables taking the value 1 if
packet j of ﬂow i is sampled. Thus uij = 1 with the proba-
bility that a packet is sampled, namely 1/N.
• Flow Record Loss: The application to loss of ﬂow records is
achieved through further multiplying by vi/q, where the vi
are mutually independent indicator random variables taking
the 1 if ﬂow record i would survive transmission, i.e., with
probability q. The resulting unbiased estimate of xi is
(cid:1)mi
mi(cid:3)
(cid:2)xi = N q
−1
viuij bij.
j=i
(2)
• Smart Sampling: the application to smart sampling is com-
plicated slightly by the fact, mentioned in Section 2.5.6,
that usage renormalization to compensate for the loss of ﬂow
records is performed only after smart sampling. The size re-
ported in the normalized sampled ﬂow record presented for
smart sampling is q(cid:2)xi. Given a smart sampling threshold z,
then assuming no splitting of ﬂows, the record survives smart
sampling with probability pz(q(cid:2)xi) = pz/q((cid:2)xi). If so, its re-
−1 max{z, q(cid:2)xi} =
−1,(cid:2)xi}; see Section 2.5.4. Thus, estimated usage
ported size, after normalization with q, is q
max{zq
arising from smart sampling of the measured ﬂow (if any)
produced by sampling the packets of original ﬂow i is
(cid:2)yi = wi max{zq
−1,(cid:2)xi},
(3)
where the wi are mutually independent indicator random vari-
ables taking the value 1 if ﬂow record i would be selected
during smart sampling, i.e., with probability pz/q((cid:2)xi).
The ﬁnal estimate (cid:2)X of total usage resulting from all packets is
(cid:2)yi = q
obtained by summing over all original ﬂows i:
(cid:2)X =
In order to determine the variance of (cid:2)X we apply a conditioning
wi max{z, N
viuij bij}
−1
j=1
(4)
(cid:3)
(cid:3)
mi(cid:3)
i
i
equality for variances for each stage of sampling. Let A and B be
random variables and deﬁne the conditional variance of A given B
by
Var(A|B) = E[(A − E[A | B])2|B];
(5)
see, e.g., Problem 8 of Chapter 1 in [20]. Then the conditional and
unconditional variance of A are related by
(6)
Var(A) = E[Var(A | B)] + Var(E[A | B])
Consider again the unbiased estimate(cid:2)y =(cid:2)x · w/p of(cid:2)x. Then one