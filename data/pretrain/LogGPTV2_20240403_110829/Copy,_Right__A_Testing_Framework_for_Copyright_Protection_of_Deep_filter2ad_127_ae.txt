### 优化后的文本

#### 数据展示
- **2.79±0.09**
- **0.00±0.00**
- **0.05±0.02**
- **0.25±0.31**
- **0.03±0.02**
- **0.45±0.32**
- **39.61±9.74**
- **34.84±6.07**
- **17.20**
- **–**
- **0.286**
- **19.77**
- **1.66**
- **LAD**
- **Copy?**
- **0.000±0.00 Yes (4/4)**
- **12.82±1.00 Yes (4/4)**
- **21.64±2.47 Yes (4/4)**
- **14.57±3.12 Yes (4/4)**
- **20.58±3.44 Yes (4/4)**
- **64.32±2.42 No (0/4)**
- **62.69±1.75 No (0/4)**
- **37.48**
- **–**

#### 图5说明
图5展示了不同嫌疑模型与受害模型在CIFAR-10（左三列）和SpeechCommands（右三列）数据集上的相似性。我们用橙色线表示正向嫌疑模型，蓝色线表示负向嫌疑模型。雷达图的每个维度对应一个由DEEPJUDGE度量给出的相似性得分。相似性得分通过首先将度量（如RobD）归一化到[0, 1]区间，然后计算1 - RobD得到。

#### 观察结果
- DEEPJUDGE在5个正向嫌疑模型中有4个表现出与NAD相当的性能。
- 正向和负向嫌疑模型之间的巨大差距表明所有度量都能正确识别正向嫌疑模型。
- 单一的DEEPJUDGE度量能够达到与EmbeddingWatermark相同的保护水平。

#### 备注2
与现有最先进的防御方法相比，DEEPJUDGE在黑盒设置下表现更好，在白盒设置下对模型微调和剪枝攻击的表现相当，且不会影响模型训练。

### 防御模型提取攻击
模型提取（也称为模型窃取）被认为是DNN版权的一个更具挑战性的威胁。在此部分，我们评估DEEPJUDGE对模型提取攻击的防御能力，这是先前工作尚未深入研究的领域。

#### 攻击策略
我们考虑了两种类型的辅助数据进行模型提取：辅助数据或合成数据（参见第III节）。我们考虑以下最先进的模型提取攻击：
- **JBA**（基于雅可比的增强 [33]）从测试数据集中采样一组种子，然后应用基于雅可比的数据增强来合成更多数据。
- **Knockoff**（Knockoff Nets [32]）使用与原始训练数据具有类似属性的辅助数据集。
- **ESA**（ES攻击 [45]）不需要额外的数据，但需要大量查询。ESA利用自适应梯度优化算法从随机噪声中合成数据。ESA适用于难以访问任务域数据的情况，例如个人健康数据。

#### 提取攻击的效果
使用提取的数据，攻击者可以重新训练一个新模型，假设已知受害模型的架构。如果新模型的性能与受害模型匹配，则认为提取成功。

#### 水印技术的失败
我们在第V-B节中的实验表明，水印技术对微调和剪枝攻击的有效性和鲁棒性。不幸的是，这里我们发现嵌入的水印可以通过模型提取攻击被移除。图12显示了DNNWatermarking和EmbeddingWatermark的结果。不同提取攻击生成的模型都与受害模型有很大差异，根据TSA（来自DNNWatermarking）或BER（来自EmbeddingWatermark）值判断。例如，受害模型的TSA值为100%，而三个提取副本的TSA值均低于1%。这基本上意味着原始水印在提取模型中被完全擦除，导致所有权声明失败。这是因为水印是与任务无关的内容，并不是模型提取的重点。

#### DEEPJUDGE的有效性
表VI总结了DEEPJUDGE的结果，它成功地识别了所有正向嫌疑模型，除了那些性能极差的被盗副本（通过JBA攻击生成），其准确率比受害模型低15%、44%和55%。我们注意到模型提取并不总是有效，性能较差的提取不太可能构成真正的威胁。此外，我们观察到当提取效果较好时，DEEPJUDGE的工作效果更好，从而对抗了模型提取攻击的最终完美匹配目标。

与模型微调或剪枝相比，提取模型的平均RobD和JSD值相对较大，这意味着提取模型的决策边界与受害模型的决策边界差异更大。原因是提取模型通常从随机点开始训练，而微调只是稍微移动了受害模型的原始边界。因此，模型提取更加隐蔽且更难验证所有权。尽管如此，RobD和JSD两个度量仍然可以揭示提取模型与受害模型的独特相似性（较小的值）：提取效果越好（提取模型的准确率越高），RobD和JSD值越低。这表明提取模型的行为更接近受害模型，突显了DEEPJUDGE在对抗模型提取攻击方面的独特优势。

#### 进一步分析
在图7中，我们进一步展示了在整个Knockoff、ESA和JBA攻击提取过程中RobD和JSD值的变化。我们发现随着提取过程的进展，RobD（橙色线）和JSD（红色线）值都在下降，除了JBA。这证实了我们的推测，即当由DEEPJUDGE测试时，更好的提取模型会暴露更多的相似性。相比之下，我们还研究了这些值在独立训练的负向嫌疑模型训练过程中的变化，发现负向嫌疑模型倾向于与受害模型差异更大，并产生更高的RobD和JSD值。

#### 备注3
虽然模型提取攻击比微调或剪枝攻击更具挑战性，但DEEPJUDGE仍能正确识别成功的提取。此外，提取效果越好，DEEPJUDGE越容易将其识别为被盗副本。

### 对抗攻击的鲁棒性
本节探讨基于对手对DEEPJUDGE知识的潜在对抗攻击：
1. 对手知道测试度量和测试用例。
2. 对手只知道测试度量。

#### 知道测试度量和测试用例
在这种威胁模型中，对手完全了解DEEPJUDGE，包括测试度量Λ和秘密测试用例T。我们还假设对手拥有一部分干净数据。DEEPJUDGE有两种测试设置：白盒测试和黑盒测试。这两种测试在测试度量和生成的测试用例上有所不同（参见图17示例）。黑盒测试用例带有标签，因此对手可以将T混入其干净子集中，以微调被盗模型，使其在保持良好分类性能的同时具有较大的测试距离（即黑盒测试度量RobD和JSD）。这将使DEEPJUDGE误认为被盗模型与受害模型显著不同。这种针对黑盒测试的自适应攻击记为Adapt-B。由于白盒测试用例未标记，对手可以使用受害模型预测的标签作为真实标签，并按照与Adapt-B类似的程序微调被盗模型。这种针对白盒测试的攻击记为Adapt-W。

表VII报告了DEEPJUDGE使用暴露的测试用例T的结果。结果显示：
1. DEEPJUDGE对Adapt-W具有鲁棒性，Adapt-W无法同时最大化输出距离和激活距离，也无法保持原始分类准确性。
2. 尽管DEEPJUDGE在测试用例带标签的情况下不鲁棒于Adapt-B，但它可以通过使用不同种子生成的新测试用例轻松恢复性能（参见图8中暴露和新测试用例的ROC曲线）。
3. 当结合黑盒和白盒测试时，DEEPJUDGE仍能正确识别Adapt-B的被盗副本（最终判断都是正确的）。

#### 知道仅测试度量
在这种威胁模型中，对手仍可以以不同方式适应。我们考虑两种自适应攻击：针对黑盒测试的盲目对抗训练和针对白盒测试的一般迁移学习攻击。

1. **盲目对抗训练**：由于我们的黑盒测试主要依赖于使用对抗性测试用例探测决策边界的差异，对手可能会利用对抗训练来提高被盗副本的鲁棒性。给定PGD参数和一部分干净数据（原始训练数据的20%），对手迭代训练被盗模型以平滑模型决策边界。这种自适应攻击记为Adv-Train。如表VII所示，它确实可以绕过我们的黑盒测试，但牺牲了约10%的性能（一种称为精度-鲁棒性权衡的现象 [39], [46]）。然而，有趣的是，如果我们用低置信度种子替换DEEPJUDGE中的高置信度种子，DEEPJUDGE又变得有效（如图9所示）。可能的原因是，与高置信度种子相比，这些低置信度种子是自然边界（困难）样本，靠近决策边界，因此可以生成更多的测试用例。

### 表VII
| 模型类型 | 黑盒测试 | JSD | RobD | ACC |
| --- | --- | --- | --- | --- |
| Adapt-B | 81.4±0.9% | 0.985±0.011 | - | - |
| Adapt-W | 71.9±1.8% | 0.519±0.048 | - | - |
| Adv-Train | 93.3±1.7% | - | - | - |
| VTL | 84.2±0.6% | 0.920±0.021 | - | - |
| Neg-1 | 84.9±0.5% | 0.926±0.030 | - | - |
| Neg-2 | - | - | - | - |

### 白盒测试
| 模型类型 | NAD | LOD | NOD | LAD | Copy? |
| --- | --- | --- | --- | --- | --- |
| Positive Suspect Models | 0.44±0.15 | 1.94±0.12 | 0.38±0.04 | 0.40±0.05 | Yes (4/6) |
| Negative Suspect Models | 1.89±0.33 | 1.12±0.06 | 1.79 | 5.41±0.67 | No (0/6) |

### 备注
- τλ: 0.816, 0.537, 6.14, 6.89

通过这些优化，文本变得更加清晰、连贯和专业。希望这些改进对你有帮助！