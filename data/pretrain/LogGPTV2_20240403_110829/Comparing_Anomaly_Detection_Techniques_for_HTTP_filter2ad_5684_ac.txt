 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 0.02
 0.04
 0.06
 0.08
 0.1
False positive fraction
aya.org
explorenm.com
i-pi.com
cs.unm.edu
Fig. 2. Receiver Operating Characteristic curves showing the accuracy of the Maha-
lanobis distance algorithm
Figure 3 contains the χ2 distance results. This algorithm performs poorly on
all data sets, with a true positive rate at or below 40%.
The Mahalanobis distance and χ2 distance algorithms generalize by allowing
similar, instead of identical, character distributions. Unfortunately, this approach
fails. The HTTP protocol is ﬂexible enough that an attack can be padded to give
a character distribution considered close enough to normal, especially with the
myriad ways of encoding data allowed by the standards. To make the problem
worse for these metrics, some attacks such as the Apache chunked transfer error
[4] and some variants of Nimda [10] use a character distribution that might pass
as normal without padding, and had the attacker needed to, she could have easily
made minor changes to the attack (such as putting the proper host name or IP
address in the Host: ﬁeld) as needed to ensure a valid character distribution.
The problem is that the set considered normal is so large that it includes many
of the attacks in the attack database, regardless of if the attack is legal HTTP
or not.
54
K.L. Ingham and H. Inoue
ROC Curves for Chi-squared distance
n
o
i
t
c
a
r
f
e
v
i
t
i
s
o
p
e
u
r
T
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 0.02
 0.04
 0.06
 0.08
 0.1
False positive fraction
aya.org
explorenm.com
i-pi.com
cs.unm.edu
Fig. 3. Receiver Operating Characteristic curves showing the accuracy of the χ2 dis-
tance algorithm
ROC Curves for DFA
n
o
i
t
c
a
r
f
e
v
i
t
i
s
o
p
e
u
r
T
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 0.02
 0.04
 0.06
 0.08
 0.1
False positive fraction
aya.org
explorenm.com
i-pi.com
Filtered
Fig. 4. Receiver Operating Characteristic curves showing the accuracy of the DFA
algorithm
Wang and Stolfo [38] tested the Mahalanobis distance using the MIT Lincoln
Labs data (Section 2.2). This data set contains only four HTTP attacks. In the
years since the MIT data were collected, attack characteristics have changed;
our more comprehensive attack data set illustrates the eﬀect of this diﬀerence
on this algorithm (Figure 2).
4.3 DFA
Figure 4 shows the DFA accuracy. The DFA can achieve better than 80% true
positive rate at a false positive rate of less than 0.1%, which is better than all
but the 6-grams. At slightly higher false positive rates, it achieves true positive
rates of over 90%.
Comparing Anomaly Detection Techniques for HTTP
55
The DFA induced using tokens is a directed graph representing the structure
of the HTTP request. Generalization occurs in the DFA generation described in
[21]. It also occurs when one or more “missed tokens” are allowed. These gener-
alizations are limited compared to that performed by the length and character
distribution algorithms. The better true positive rate relative to all of the other
algorithms shows that the model is even more accurate than that of the n-grams.
4.4 Markov Model
The Markov model result values are in [0, 10−13] with many values as small as
10−300. These small values make it appear that the algorithm identiﬁes every-
thing (both normal traﬃc and attacks) as abnormal. To better understand these
results, Figure 5 shows the data plot where the similarity value from the Markov
|loge(m)| ,
model m has been transformed into a new similarity value s by s =
and the plot scale has been changed so the data appears (making these plots
not directly comparable to the rest of the ROC plots in this paper). This trans-
formation means that the data cannot go through the point (0, 0), and all of
the data appears on the plot. The log transformed Markov model provides 94%
accuracy on cs.unm.edu data, but with an unacceptable false positive rate. The
results on the other web sites show an even better true positive rate, but the
false positive rate remains unacceptably high.
1
ROC Curves for the log-transformed Markov Model
n
o
i
t
c
a
r
f
e
v
i
t
i
s
o
p
e
u
r
T
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 0.2
 0.4
 0.6
 0.8
 1
False positive fraction
aya.org
explorenm.com
i-pi.com
cs.unm.edu
Fig. 5. Receiver Operating Characteristic curves showing the accuracy of the Markov
model algorithm. Note that the scale on this plot does not match the scale of the other
plots.
In a Markov model, normal requests might have a probability of 0 due to
minor diﬀerences from the instances in the training data. If the model was in-
duced from ﬁltered data, attacks would also result in a probability of 0, and
the model has a hard time distinguishing between these two cases. The Markov
model’s generalization is traditionally achieved by allowing probabilities within
a given range. The diversity of normal requests means any given normal request
56
K.L. Ingham and H. Inoue
is unlikely, and perpetual novelty of HTTP data leads to normal requests with
a probability of 0. The combination of these two factors means that the Markov
model is a poor model for HTTP requests. Our results applying a Markov model
to the tokens of the complete HTTP request using tokens mirror those of Kruegel
and Vigna applying it to CGI parameters [22]. They reported that the Markov
model suﬀered because HTTP requests are so diverse that the probability of
any given request is low. When working with complete requests, the problem is
even worse, because the increased number of tokens increases the normal level
of diversity, resulting in lower probabilities for any given HTTP request.
4.5 Linear Combination
The linear combination results are in Figure 6. The accuracy is best on the
cs.unm.edu data, but the true positive rate is only around 60%. On the other
web sites, it is less accurate. Kruegel and Vigna reported a true positive rate of
100% and false positive rates less than 0.000650. The disparity is explained by the
attacks attempted—in contrast to their attack database which was constructed
solely of attacks in CGI parameters, these attacks account for only 40% of the
attacks in our database.
Most of the discrimination the linear combination came from the order, pres-
ence or absence, and enumerated or random tests which did not generalize.
We found it was not hampered by the character distribution overgeneralization
because they limited their work to a small portion of all attacks (CGI parame-
ters) and this measure was but one of six.
ROC Curves for the Linear Combination
n
o
i
t
c
a
r
f
e
v
i
t
i
s
o
p
e
u
r
T
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 0.02
 0.04
 0.06
 0.08
 0.1
False positive fraction
aya.org
explorenm.com
i-pi.com
cs.unm.edu
Fig. 6. Receiver Operating Characteristic curves showing the accuracy of the linear
combination algorithm
The method of combining IDSs itself determines the generalization of the
combined algorithm. If all models must agree that a request is normal, the least
general usually determines a request is abnormal. Combining overgeneralizing
Comparing Anomaly Detection Techniques for HTTP
57
detectors such as length and character distribution will usually indicate a nor-
mal request (including for many attacks), and therefore contribute little to the
discrimination power of the combination; combining overgeneralizing detectors
results in a system that overgeneralizes.
4.6 n-Grams
Results for 6-grams5 are in Figure 7. The accuracy starts at around 85% true
positive rate with a low false positive rate, making this algorithm comparable to
the DFA for accuracy.
ROC Curves for 6-grams
n
o
i
t
c
a
r