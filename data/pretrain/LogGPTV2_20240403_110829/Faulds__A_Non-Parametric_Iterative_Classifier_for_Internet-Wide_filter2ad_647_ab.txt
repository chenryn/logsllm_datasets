eration of hard EM, i.e., outputting the fraction of classifications
that belong to each OS ωi as an estimate of its popularity αi .
3.3 Discussion
We now address the question of whether (3) is sufficient for achiev-
ing good classification on its own and how much of the accuracy
depends on knowing the exact distortion model θ. If the major-
ity of the benefit is already obtained from recovering α, the extra
computational cost and modeling effort involved in estimating θ
may be unnecessary. For discussion purposes, we use a set of toy
databases that allow simple demonstration of the intended effects.
Note that the same conclusions apply to larger datasets, but finding
the corresponding scenarios may be more time-consuming.
Session D5:  Network SecurityCCS’17, October 30-November 3, 2017, Dallas, TX, USA973)
c
e
s
(
2
O
T
R
10
8
6
4
2
0
0
)
c
e
s
(
2
O
T
R
10
8
6
4
2
0
0
Linux
Windows
Novell
6
2
4
RTO1 (sec)
(a) database D1
Linux
Windows
Novell
6
2
4
RTO1 (sec)
(b) case S13
Figure 2: Database and distorted observations.
Simulations below apply a forward latency to the SYN packet,
pass each SYN-ACK through a FIFO queue, which adds random
one-way delays along the return path, and drop packets using an
iid (independent and identically distributed) loss model with some
fixed probability. This is similar to the context in which prior meth-
ods [41], [42] have been tested. For the scenario we call S1, there
are four different cases for the distribution of foward/reverse de-
lays and packet-loss probability. These are shown in Table 2 and
discussed in more detail next.
The first row matches exactly the assumed parameters θ in Her-
shel+ [41]. The second row uses Pareto delays with mean 500 ms
and 50% loss, emulating highly noisy network conditions. The next
row uses a shifted reverse-exponential forward latency with CDF
e −λ(2−x )
, defined for −∞  γj (r ). Let Γ(i, j) be the set of all monotonic
loss vectors that start with |di | packets and finish with |d(cid:3)
j |. Then,
the Hershel+ network classifier uses p(d(cid:3)
j |ωi , θd ) equal to [41]

τ

fT (τ )
pi (γ )
γ ∈Γ(i, j)
|d(cid:3)
j |
r =1
fΔ(d (cid:3)
jr − τ − di,γ (r )),
(6)
where pi (γ ) is the probability to observe loss pattern γ under |di |
transmitted packets. For lack of a better assumption, Hershel+ uses
binomial pi (γ ), Erlang(2) fT (τ ), and exponential fΔ(δ ), all with
some fixed parameters. Since θd encapsulates the set of these dis-
tributions, our next goal is to recover them using EM iteration.
4.2 Intuition
We start with a heuristic explanation of the proposed update for-
mulas, which is followed by a more rigorous treatment. Recall that
f t
(τ ) is an estimate of P(Tj = τ ) during iteration t. Then, one
T
obvious approach is to set this value to the average probability
that each observation j has experienced a forward latency τ , con-
ditioned on the previous estimates of unknown parameters, i.e.,
To update distribution qk ((cid:2)), our approach involves computing
the probability that observations experienced loss of (cid:2) packets out
of k transmitted, normalized by the probability that the original
host sent k packets in the first place. To express this mathemati-
cally, define Yj to be the number of SYN-ACKs originated by the
host in observation j. Letting 1X be an indicator of event X , we get
m
m
j =1
j =1
qt +1
k
((cid:2)) =
P(Yj = k |θt
d
P(Yj = k |θt
d
, α t )1 |d(cid:3)
, α t )1 |d(cid:3)
j |=k−(cid:2)
j | ≤k
,
(8)
from which the estimated probability of pattern γ is given by
qt
|di |
pt
i (γ ) =
(|di | − |γ |)
(cid:4) |di |
(cid:5)
|γ |
.
(9)
Finally, updates to PMF f t
(δ ) involve computing the probability
that one-way delay of each received packet equals δ , normalized
by the total number of packets collected during the scan, i.e.,
Δ
m
j =1
 |d(cid:3)
j |
s =1
f t +1
Δ
(δ ) =
P(Δjs = δ |d(cid:3)
m
j , θt
d
|d(cid:3)
j |
j =1
, α t )
.
(10)
4.3 Analysis
To make the framework outlined above usable, our next task is to
express the probability of events that cannot be directly observed
(e.g., Yj = k, Δjr = δ ) using a recurrence that depends on only the
distributions contained in θt
). Let
d , i.e., (f t
, f t
Δ
, qt
k
jr − τ − di,γ (r )
T
δi jτ γ r = d (cid:3)
(11)
be the one-way delay Δjr conditioned on Tj = τ , loss pattern γ ,

signature ωi , and observation j. For brevity of notation, suppose
i jτ γ s refers to five nested summations, where i goes from 1 to
n, j rolls from 1 to m, τ moves over all bins of the PMF fT (τ ), γ
iterates over all monotonic loss vectors in Γ(i, j), and s travels from
1 to |d(cid:3)
j |. If some of the variables are absent from the subscript, the
corresponding sums are omitted from the result. With this in mind,
define
|d(cid:3)
j |
pt
i jτ γ := α t
i f t
T (τ )pt
i (γ )
f t
Δ
(δi jτ γ r ),
r =1
β t
i jτ γ := p(ωi , τ , γ |d(cid:3)
j , θt
d