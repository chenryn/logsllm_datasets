search engine
Events
copy, mouseover
copy, mouseover
copy, mouseover
copy, mouseover
copy, mouseover
copy, mouseover
copy, mouseover
Table 4: Websites that perform real behavior sniﬀ-
ing using tynt.com
we found that 7 actually perform covert keyboard and mouse
tracking that we were able to reliably replicate. These 7
websites are listed in Table 3. For each site, we give its
Alexa rank, its URL, a short description, and events being
tracked covertly. One may be surprised to see “clicking” as
being tracked covertly. After all, when a user clicks on a
link, there is a clear visual cue that information is being
sent over the network – the target of the link will know that
the user has clicked. However, when we list clicking as being
tracked covertly, we mean that there is an additional event-
handler that tracks the click, and sends information about
the click to another server. google is known for doing this:
when a user clicks on a link on the search page, the click is
recorded by google through an event handler, without any
visual cue that this is happening (we do not list google in
Table 3 because we only visit the front pages of websites,
and google’s tracking occurs on the search results page)
The most notable example in Table 3 is the microsoft.
com site, which covertly tracks clicking and mouse behavior
over many links on the front page and sends the information
to the web statistics site webtrends.com.
Cases of visible tracking Of the 10 sites that were sam-
pled, 3 were actually cases of visible tracking, despite our ﬁl-
tering heuristic. In one of these cases, the server responded
with very small images (less than 100 bytes) that were be-
ing redrawn in response to mouse-over events. In an other
case, the server responded with small JSON commands that
caused some of the web page to be redrawn. In all of these
cases, there was a clear visual cue that the information was
being sent to the server.
Cases of using tracking libraries Of the 115 sites on
which the ﬁltered ﬂows were reported, we found that 7 used
a behavior tracking software product developed by tynt.com
to track what is copied oﬀ the sites. These 7 websites are
listed in Table 4. The library monitors the copy event.
When a visitor copies the content of a web page to her
clipboard, the library inserts the URL of the page into the
copied content. Thus, the URL is contained within subse-
quent pastes from the clipboard, e.g., in emails containing
the pasted text, thereby driving more traﬃc to the URL. Us-
ing our framework, we discovered that on each client website,
the copied content is also transferred to tynt.com.
sites
Suspicious website While investigating several
that installed event handlers, we also found that the
huffingtonpost.com site exhibits suspicious behavior.
In
particular, every article on the site’s front page has an on-
mouse-over event handler. These handlers collect in a global
data structure information about what articles the mouse
passes over. Despite the fact the information is never sent
on the network, we still consider this case to be suspicious
because not only is the infrastructure present, but it in fact
collects the information locally.
6. RELATED WORK
Information ﬂow [7] and non-interference [11] have been
used to formalize ﬁne-grained isolation for nearly three
decades. Several static techniques guarantee that certain
kinds of inputs do no ﬂow into certain outputs. These in-
clude type systems [31, 23], model checking [28], Hoare-
logics [1], and dataﬂow analyses [18, 26]. Of these, the most
expressive policies are captured by the dependent type sys-
tem of [21], which allows the speciﬁcation and (mostly) static
enforcement of rich ﬂow and access control policies includ-
ing the dynamic creation of principals and declassiﬁcation of
high-security information. Unfortunately, fully static tech-
niques are not applicable in our setting, as parts of the code
only become available (for analysis) at run time, and as they
often rely on the presence of underlying program structure
(e.g., a static type system).
Several authors have investigated the use of dynamic taint
propagation and checking, using specialized hardware [27,
29], virtual machines [4], binary rewriting [22], and source-
level rewriting [5, 19]. In the late nineties, the JavaScript
engine in Netscape 3.0 implemented a Data Tainting mod-
ule [10], that tracked a single taint bit on diﬀerent pieces of
data. The module was abandoned in favor of signed scripts
(which today are rarely used in Web 2.0 applications), in
part because it led to too many alerts. Our results show that,
due to the prevalence of privacy-violating ﬂows in popular
Web 2.0 applications, the question of designing eﬃcient, ﬂex-
ible and usable ﬂow control mechanisms should be revisited.
Recently, Vogt et al. [30] modiﬁed the browser’s JavaScript
engine to track a taint bit that determines whether a piece of
data is sensitive and report an XSS attack if this data is sent
to a domain other than the page’s domain, and Dhawan and
Ganapathy [8] used similar techniques to analyze conﬁden-
tiality properties of JavaScript browser extensions for Fire-
fox. Our approach provides a diﬀerent point in the design
space. In particular, our policies are more expressive, in that
our framework can handle both integrity and conﬁdential-
ity policies, and more ﬁne-grained, in that our framework
can carry multiple taints from diﬀerent sources at the same
time, rather than just a single bit of taint. On the down-
side, our approach is implemented using a JavaScript rewrit-
ing strategy rather than modifying the JavaScript run-time,
which results in a larger performance overhead. Dynamic
rewriting approaches for client-side JavaScript information
ﬂow have also been investigated in a theoretical setting [5,
28119]. Our work distinguishes itself from these more theoret-
ical advances in terms of experimental evaluation: we have
focused on implementing a rewriting-based approach that
works on a large number of popular sites, and on evaluating
the prevalence of privacy-violating ﬂows on these websites.
One way to ensure safety on the client is to disallow un-
known scripts from executing [16]. However, this will likely
make it hard to use dynamic third-party content. Finally,
Yu et al. [32] present a formal semantics of the interac-
tion between JavaScript and browsers and builds on it a
proxy-based rewriting framework for dynamically enforcing
automata-based security policies [17]. These policies are
quite diﬀerent from information ﬂow in that they require
sparser instrumentation, and cannot enforce ﬁne-grained iso-
lation.
The possibility of history sniﬃng was ﬁrst raised in the
academic community a decade ago [9]. The original form of
history sniﬃng used timing diﬀerence between retrieving a
resource that is cached (because it has previously been re-
trieved) and one that is not. In general, many other forms
of history sniﬃng are possible based on CSS link decoration,
some of which (for example, setting the background property
of a visited link to url(...)) work even when JavaScript is
disabled. This, together with the genuine user-interface util-
ity that visited link decoration provides, is the reason that
history sniﬃng is so diﬃcult to address comprehensively in
browsers (cf. [13] for a proposed server-side solution, [12] for
a proposed client-side solution and [2] for the ﬁx recently
deployed by the Firefox browser.) The potential of history
sniﬃng has been recently proven to be enormous [14]. How-
ever, since to date there has been no public disclosure re-
garding the use of history sniﬃng, and no publicly available
tools for detecting it, we expect that, today, many malicious
sites will prefer the simple, robust approach of querying and
exﬁltrating link computed style. Accordingly, it is this data
ﬂow that we focus on; if there are sites that use other ap-
proaches, we will not have detected them. Our goal in this
paper is to draw attention to the use of clandestine history
sniﬃng at popular, high-traﬃc sites, which means that false
negatives are acceptable. In future work, we hope to extend
our tool to detect other forms of history sniﬃng as well.
7. CONCLUSIONS AND FUTURE WORK
In this paper, we proposed a rewriting-based informa-
tion ﬂow framework for JavaScript and evaluated the per-
formance of an instantiation of the framework. Our evalu-
ation showed that the performance of our rewriting-based
information ﬂow control is acceptable given our engineering
and optimization eﬀorts, but it still imposes a perceptible
running-time overhead. We also presented an extensive em-
pirical study of the prevalence of privacy-violation informa-
tion ﬂows: cookie stealing, location hijacking, history sniﬀ-
ing, and behavior tracking. Our JavaScript information ﬂow
framework found many interesting privacy-violating infor-
mation ﬂows including 46 cases of real history sniﬃng over
the Alexa global top 50,000 websites, despite some incom-
pleteness.
One direction for future work is a larger scale study on
privacy-violating information ﬂows. Such a study could per-
form a deeper crawl of the web, going beyond the front-
pages of web sites, and could look at more kinds of privacy-
violating information ﬂows. Moreover, we would also like to
investigate the prevalence of security attacks led by privacy-
violating information ﬂows like phishing and request forgery.
Another direction for future work is to extend our cur-
rent framework to become a bullet-proof client-side protec-
tion mechanism. The primary purpose of our tool so far
has been to observe existing ﬂows in the wild, a scenario for
which we don’t need to worry about malicious code trying
to circumvent our system. However, with additional work,
our framework could possibly lead to a protection mecha-
nism as well. For this purpose, we would have to soundly
cover all possibly forms of information ﬂow, including im-
plicit ﬂow, ﬂows induced by the DOM and browser built-in
APIs. In addition, we would also need better performance to
deliver a practical browsing experience. However, we believe
that with careful and extensive engineering eﬀorts, there is
a possibility that our framework could lead to a practical
protection mechanism.
8. ACKNOWLEDGMENTS
This material
is based upon work supported by the
National Science Foundation under Grant Nos. CCF-
0644306, CCF-0644361, CNS-0720802, CNS-0831532, and
CNS-0964702. Any opinions, ﬁndings, and conclusions or
recommendations expressed in this material are those of the
authors and do not necessarily reﬂect the views of the Na-
tional Science Foundation.
9. REFERENCES
[1] T. Amtoft and A. Banerjee. Information ﬂow analysis
in logical form. In R. Giacobazzi, editor, Proceedings
of SAS 2004, volume 3148 of LNCS, pages 100–15.
Springer-Verlag, Aug. 2004.
[2] L. D. Baron. Preventing attacks on a user’s history
through CSS :visited selectors, Apr. 2010. Online:
http://dbaron.org/mozilla/visited-privacy.
[3] Bugzilla@Mozilla. Bug 147777 – :visited support
allows queries into global history, May 2002. Online:
https:
//bugzilla.mozilla.org/show_bug.cgi?id=147777.
[4] J. Chow, B. Pfaﬀ, T. Garﬁnkel, K. Christopher, and
M. Rosenblum. Understanding data lifetime via whole
system simulation. In M. Blaze, editor, Proceedings of
USENIX Security 2004, pages 321–36. USENIX, Aug.
2004.
[5] A. Chudnov and D. A. Naumann. Information ﬂow
monitor inlining. In M. Backes and A. Myers, editors,
Proceedings of CSF 2010. IEEE Computer Society,
July 2010.
[6] A. Clover. Timing attacks on Web privacy. Online:
http://www.securiteam.com/securityreviews/
5GP020A6LG.html, Feb. 2002.
[7] D. E. Denning. A lattice model of secure information
ﬂow. Commun. ACM, 19(5):236–243, 1976.
[8] M. Dhawan and V. Ganapathy. Analyzing information
ﬂow in JavaScript-based browser extensions. In
C. Payne and M. Franz, editors, Proceedings of
ACSAC 2009, pages 382–91. IEEE Computer Society,
Dec. 2009.
[9] E. W. Felten and M. A. Schneider. Timing attacks on
Web privacy. In S. Jajodia, editor, Proceedings of CCS
2000, pages 25–32. ACM Press, Nov. 2000.
282[10] D. Flannagan. JavaScript: The Deﬁnitive Guide.
[22] J. Newsome and D. X. Song. Dynamic taint analysis
O’Reilly, ﬁfth edition, Aug. 2006.
[11] J. A. Goguen and J. Meseguer. Security policies and
security models. In Proceedings of IEEE Security and
Privacy (“Oakland”) 1982, pages 11–20. IEEE
Computer Society, Apr. 1982.
[12] C. Jackson, A. Bortz, D. Boneh, and J. C. Mitchell.
Protecting browser state from Web privacy attacks. In
C. Goble and M. Dahlin, editors, Proceedings of
WWW 2006, pages 737–44. ACM Press, May 2006.
[13] M. Jakobsson and S. Stamm. Invasive browser sniﬃng
and countermeasures. In C. Goble and M. Dahlin,
editors, Proceedings of WWW 2006, pages 523–32.
ACM Press, May 2006.
[14] A. Janc and L. Olejnik. Feasibility and real-world
implications of Web browser history detection. In
C. Jackson, editor, Proceedings of W2SP 2010. IEEE
Computer Society, May 2010.
[15] D. Jang, R. Jhala, S. Lerner, and H. Shacham.
Rewriting-based dynamic information ﬂow for
JavaScript. Technical report, University of California,
San Diego, Jan. 2010. Online:
http://pho.ucsd.edu/rjhala/dif.pdf.
[16] T. Jim, N. Swamy, and M. Hicks. Defeating script
injection attacks with browser-enforced embedded
policies. In P. Patel-Schneider and P. Shenoy, editors,
Proceedings of WWW 2007, pages 601–10. ACM
Press, May 2007.
[17] H. Kikuchi, D. Yu, A. Chander, H. Inamura, and
I. Serikov. JavaScript instrumentation in practice. In
G. Ramalingam, editor, Proceedings of APLAS 2008,
volume 5356 of LNCS, pages 326–41. Springer-Verlag,
Dec. 2008.
[18] M. S. Lam, M. Martin, V. B. Livshits, and J. Whaley.
Securing Web applications with static and dynamic
information ﬂow tracking. In R. Gl¨uck and
O. de Moor, editors, Proceedings of PEPM 2008,
pages 3–12. ACM Press, Jan. 2008.
[19] J. Magazinius, A. Russo, and A. Sabelfeld. On-the-ﬂy
inlining of dynamic security monitors. In
K. Rannenberg and V. Varadharajan, editors,
Proceedings of SEC 2010, Sept. 2010.
[20] L. A. Meyerovich and V. B. Livshits. Conscript:
Specifying and enforcing ﬁne-grained security policies
for javascript in the browser. In Proceedings of IEEE
Security and Privacy (“Oakland”) 2010, pages
481–496. IEEE Computer Society, 2010.
[21] A. C. Myers. Programming with explicit security
policies. In M. Sagiv, editor, Proceedings of ESOP
2005, volume 3444 of LNCS, pages 1–4.
Springer-Verlag, Apr. 2005.
for automatic detection, analysis, and signature
generation of exploits on commodity software. In
D. Boneh and D. Simon, editors, Proceedings of NDSS
2005. ISOC, Feb. 2005.
[23] F. Pottier and V. Simonet. Information ﬂow inference
for ML. In J. C. Mitchell, editor, Proceedings of POPL
2002, pages 319–330. ACM Press, Jan. 2002.
[24] N. Provos, D. McNamee, P. Mavrommatis, K. Wang,
and N. Modadugu. The ghost in the browser: Analysis
of Web-based malware. In N. Provos, editor,
Proceedings of HotBots 2007. USENIX, Apr. 2007.
[25] A. Russo, A. Sabelfeld, and A. Chudnov. Tracking
information ﬂow in dynamic tree structures. In
M. Backes and P. Ning, editors, Proceedings of
ESORICS 2009, volume 5789 of LNCS, pages 86–103.
Springer-Verlag, Sept. 2009.
[26] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner.
Detecting format string vulnerabilities with type
qualiﬁers. In D. Wallach, editor, Proceedings of
USENIX Security 2001, pages 201–17. USENIX, Aug.
2001.
[27] G. E. Suh, J. W. Lee, D. Zhang, and S. Devadas.
Secure program execution via dynamic information
ﬂow tracking. In K. McKinley, editor, Proceedings of
ASPLOS 2004, pages 85–96. ACM Press, Oct. 2004.
[28] T. Terauchi and A. Aiken. Secure information ﬂow as
a safety problem. In C. Hankin, editor, Proceedings of
SAS 2005, volume 3672 of LNCS, pages 352–67.
Springer-Verlag, Sept. 2005.
[29] N. Vachharajani, M. J. Bridges, J. Chang, R. Rangan,
G. Ottoni, J. A. Blome, G. A. Reis, M. Vachharajani,
and D. I. August. RIFLE: An architectural framework
for user-centric information-ﬂow security. In
A. Gonz´alez and J. P. Shen, editors, Proceedings of
MICRO 2004, pages 243–54. IEEE Computer Society,
Dec. 2004.
[30] P. Vogt, F. Nentwich, N. Jovanovic, E. Kirda,
C. Kr¨ugel, and G. Vigna. Cross site scripting
prevention with dynamic data tainting and static
analysis. In W. Arbaugh and C. Cowan, editors,
Proceedings of NDSS 2007. ISOC, Feb. 2007.
[31] D. Volpano and G. Smith. Verifying secrets and
relative secrecy. In T. Reps, editor, Proceedings of
POPL 2000, pages 268–76. ACM Press, Jan. 2000.
[32] D. Yu, A. Chander, N. Islam, and I. Serikov.
JavaScript instrumentation for browser security. In
M. Felleisen, editor, Proceedings of POPL 2007, pages
237–49. ACM Press, Jan. 2007.
283