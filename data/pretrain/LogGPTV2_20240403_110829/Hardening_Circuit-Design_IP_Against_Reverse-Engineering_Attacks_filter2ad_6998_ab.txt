protects a broad class of functions (or their circuit repre-
sentation) against reverse-engineering attacks. Along the
way, we observe that certain types of “simple” functions
(e.g., functions with small domain) cannot be protected
by any DH scheme.
In Section II we will discuss our contributions in more
detail; but, before that, let us mention some of the immediate
next steps that future work might take.
Next Steps. Our work initiates a provable-security exploration
of DH schemes, putting the goals of prior work on a solid
foundation, and showing that these goals are achievable. As
such, it completes an important ﬁrst step towards the ultimate
goal of providing IP authors with efﬁcient schemes that
provably protect broad classes of practically relevant circuit
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:33:25 UTC from IEEE Xplore.  Restrictions apply. 
1673
designs. But there is much to be done between here and there,
and the following list captures some of the research challenges
that our results suggest.
1) HIDING MORE REALISTIC CIRCUITS. We consider DH
schemes for stateless circuits, as these were the target of
most prior work. However, many real-world circuits are
stateful, and comprised of multiple stateless sub-circuits.
There are very few DH schemes [33]–[36] for stateful
circuits and all of them have been shown to be broken
by a recent attack [37]. Thus, extending our formalisms to
such circuits is an important next step.
One may treat each stateless sub-circuit as an independent
circuit, and try to use OneChaffhd to prevent FR-attacks
on each of these. For reasons that we give in Section II,
OneChaffhd focuses on hiding Boolean circuits, i.e., those
with a single output bit. As we will explain, extending
OneChaffhd to stateless circuits with multiple output bits
requires some care. Intuitively, one can take the transitive
fan-in cone3 (TFC) of any output bit and use OneChaffhd
to hide the Boolean (sub)circuit
is the indicated
TFC. But determining which TFC(s) to hide may not be
straightforward, as we will see.
that
in practice,
the foundry recover the full
2) MORE PRACTICAL SECURITY GOALS. Capturing the secu-
rity goals of prior work, our FR-security notion demands
input-output behavior
that
of the hidden function. But
this is likely
too strong. In particular, it discounts attacks that recover
a “good enough” approximation of the hidden function.
There are many potential ways to address this. For example,
one might modify our FR-security experiment to demand
input-output correctness on a subset of the function’s
domain; but how should this subset be determined, and
how large should it be? Perhaps better, one could add an
explicit Test algorithm the syntax of a DH scheme, and then
modify the FR-security experiment to declare an attack
successful only if it fools the Test algorithm into saying
that the foundry’s dishonestly produced chip (not circuit)
is functionally correct. This would allow the IP author (via
the DH scheme) to specify what counts as a “win” for the
adversarial foundry, rather than having the security notion
assert it.
3) EXPLORING THE EFFECTS OF A PRIORI KNOWLEDGE.
Earlier works implicitly assumed that the adversary has no
a priori information about the hidden function. Our FR-
notion addresses this shortcoming, by restricting the to-
be-hidden function to come from a speciﬁed set (which
is a parameter of the notion); intuitively, this set captures
the ability of the foundry to narrow the search space. In
our analysis of OneChaffhd, we assume that the adversary
knows the exact hamming weight of the hidden function,
and we will justify this choice. But a thorough exploration
of the effects of a priori knowledge, on OneChaffhd or
3The transitive fan-in cone of an output bit in a function is the smallest
subgraph in the DAG (circuit) representation that connects the primary inputs
to the output bit.
any other realization of a DH scheme, is likely to be
illuminating.
4) EMPIRICAL EVALUATIONS. We prove that our OneChaffhd
construction is FR-secure for a wide range of functions.
Still, a “head-to-head” empirical evaluation of published
attacks against OneChaffhd and existing schemes, for a
range of parameter settings and families of circuits, would
be interesting. Among other things, this would help to
establish the tightness of our security results, and aid
in guiding security-sensitive choices in practice. Another
dimension for such an empirical evaluation is to explore
the power, performance and area overhead of the opaque
circuits created by OneChaffhd vs. those produced existing
DH schemes. For reasons of scope and focus, we do not
explore this evaluation in the current work.
II. OVERVIEW OF CONTRIBUTIONS
We now provide a more detailed overview of our contribu-
tions, before engaging with the technical core of the paper.
Formal foundations for DH schemes: Syntax. Notably
absent from the area is a provable-security foundation for the
design and analysis of DH schemes. Very few papers in the
area offer anything along these lines. The works that do [5],
[8], [15], [38], [39] fall short of what is needed, e.g., by giving
syntactic descriptions that are imprecise or clearly mismatch
existing schemes.
Such a foundation begins with a precise deﬁnition of a DH
scheme as a syntactic object, i.e., what are the component
algorithms that must be realized in a concrete scheme.
So, we begin by providing a formal syntax (in Section IV)
for DH schemes, and our formalization captures all currently
known methods of design-stage circuit hiding. Speciﬁcally, a
DH scheme is a pair of algorithms (Hide, Restore) that abstract
the portions (a) and (c) of Fig. 1, respectively. Loosely, the
design-hiding algorithm Hide takes as input a circuit CF
(and some design parameters θ), and it returns an opaque
circuit CL, along with the associated hiding key KO. The
design-restoring algorithm Restore takes an opaque chip CL,
a hiding key KO and design parameters θ as inputs; it returns
either a restored chip CF or an error symbol ⊥,
i.e, an
indication that restoring has failed.
The opaque circuit is transformed into a chip by a separate
chip-fabrication algorithm Fab that takes a circuit CL and
design parameters as inputs and returns a chip CL. Notice
that we use the heavy typeface in CL to distinguish between
unrestricted access to circuits (e.g. CL) and oracle access
to chips. This is necessary as otherwise the foundry can
purchase a restored chip and use invasive attacks [40] to read
the hiding key from (tamperproof) memory. In this work,
we consider such attacks to be out of scope as protecting
against invasive attacks will likely require design of special
hardware like active shields [41] and are hence, orthogonal
to the development of DH schemes. We note that no prior
work considered the fabrication process, which turns circuits
into chips, as a ﬁrst-class syntactic primitive. The effect is
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:33:25 UTC from IEEE Xplore.  Restrictions apply. 
1674
that fabrication-speciﬁc security issues could not be cleanly
surfaced. We will see that making the fabrication process
explicit uncovers an important connection between the security
of DH schemes, and detecting stealthy hardware trojans (in
packaged chips). More on this in a moment.
Formal foundations: Security notions. Given a precise
description of what a DH scheme is, we next deﬁne formal
notions of what it means for a DH scheme (however it is
realized) to be secure. An intuitive deﬁnition of reverse-
engineering the opaque circuit is to recover from it, the hidden
IP F by any means. But literature has tended to focus on
attacks (and countermeasures) that attempt
to recover the
secret hiding key KO. Thus, we give two formal notions
of security (in Section V): function recovery (FR) and key
recovery (KR). In both notions, the adversary is provided
unrestricted access to the opaque circuit, and various oracles
that abstractly capture the powers of a foundry.
In the KR notion, the adversary’s goal is to return a key K
that is equivalent to KO, in the sense that when one restores
the functionality of an honestly fabricated chip using either K
or KO, we get restored chips with identical functionalities.
The FR notion captures a stronger attack model. In it, the ad-
versary’s goal is to ﬁnd any chip that is functionally equivalent
to F . As one expects, KR-insecurity implies FR-insecurity: if
you can recover a key K equivalent to KO, then you can win
the FR game by returning an honestly fabricated chip restored
with K. The converse is not necessarily true, i.e., reverse-
engineering the hidden functionality of the opaque circuit does
not necessarily require recovering something equivalent to the
hiding key.
We note that certain kinds of functions cannot be protected
by any DH scheme in the logic-locking setting, where the
foundry may purchase honest chips and thereby learn input-
output pairs of its choosing. For example, if the domain of the
chip is small, the functionality of the chip can be recovered
by querying the chip on its entire domain. In the case of
Boolean functions, those whose decision-tree representations
have small depth/size cannot be hidden [42], nor can those
whose Fourier spectra contain relatively few signiﬁcant com-
ponents [43]. So, while our security notions are agnostic to
structural characteristics of the function(s) one wishes to hide,
our security results will surface this concern.
We also note that our security notions allow for fully
malicious foundries that may fabricate arbitrary, “dishonest”
chips, and submit these to be restored with the secret hiding-
key KO. The chip may have been fabricated from the opaque
circuit, but (say) with an embedded hardware trojan that
outputs KO when triggered on a particular input. Unless
knowledge of the secret KO sufﬁces to allow the Restore
algorithm to detect such a trojan (and alert the IP author not to
proceed), the restored chip can be run by the foundry (acting
as user), leaking KO and allowing it to win the FR game.
Given the state of the art in trojan detection, we know of no
remotely practical DH scheme that can be FR-secure against
fully malicious foundries. Thus, we restrict our attention to
designing DH schemes that are secure against honest-but-
curious foundries, i.e., ones that will try to reverse-engineer
the functionality of the IP, but will only fabricate chips that
adhere to the IP author’s opaque circuit. This is in keeping
with all prior work on DH schemes.
A new family of DH schemes: OneChaff. We introduce a
family of DH schemes that we call OneChaff (see Section VI),
and analyze a particular scheme OneChaffhd in this family. In
OneChaffhd, the Hide algorithm takes inspiration from SFLL-
ﬂex [15] as it encodes a single n-input-bit Boolean function H
(one “chaff” function) and an uninitialized lookup table (cid:103)Tab
in the opaque circuit. While SFLL-ﬂex allows arbitrary H,
in our OneChaffhd scheme, the chaff H matches the hidden
function F , except on ∆ ∈ N uniformly chosen inputs.
These are the so-called distinguishing inputs (DIs) for the
pair (H, F ). The hiding key KO encodes the correct input-
output behaviors on the DIs. (Practical Hide algorithms will
have ∆ (cid:28) 2n.) On input of a key K, chip CL, and design
parameters θ, the Restore algorithm in OneChaffhd loads the
key K into the (write-once,
tamper-resistant) uninitialized
lookup table of the chip. Under honest operation, key K is
equal to KO.
Proving security of OneChaffhd for Boolean functions.
After giving our foundations for DH schemes and introduc-
ing the OneChaff family of schemes, the remainder of this
work is spent showing that OneChaffhd provably prevents full
recovery of Boolean functions in the presence of honest-but-
curious adversarial foundries. While most real-world circuits
do not compute functions returning a single bit, several
prominent logic-locking schemes [15], [27]–[29] only aim to
hide Boolean functions. Moreover, no provably secure scheme
exists for circuits implementing functions from this “base”
class. We note that for circuits with multiple output bits, one
can attempt to hide Boolean sub-functions that are determined
by the transitive fan-in cone (TFC) of individual output bits.
Our main security result (Theorem 3) gives an upper-
bound on the probability that a computationally bounded,
honest-but-curious foundry manages to win the FR game
against OneChaffhd. To the best of our knowledge, this is the
ﬁrst positive provable-security result on DH schemes.
Security holds for Boolean functions that are not “simple” in
the sense we mentioned earlier (no DH scheme can hide those)
under some assumptions about the a priori knowledge that
the adversary has about F . All prior schemes assume that the
adversary has no a priori knowledge of F . Such an assumption
is unrealistic and also makes the adversary weak as the initial
“guess” space of the adversary is the set of all Boolean
functions. In our FR analysis of OneChaffhd, we assume that
the adversary knows a priori the hamming weight h, i.e., the
number of inputs that cause F to output one. This narrows the
initial “guess space” to Boolean functions that have hamming
weight of h. Also, the hamming-weight parameter allows us
to capture the fact that the number of functions in the guess
space of the adversary increases exponentially in h. Hence,
functions with hamming weight close to 2n−1 will be more
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:33:25 UTC from IEEE Xplore.  Restrictions apply. 
1675
secure compared to functions with hamming weights close
to zero or 2n. This is also intuitive and in agreement to a
result from learning theory that states that a random Boolean
function (with sufﬁciently large domain) will not be simple, as
it will lack the highly concentrated Fourier spectral structure
that is typically needed for a function to be learnable. Note
that a random Boolean function will have expected hamming
weight close to 2n−1.
Our analysis essentially bounds the number of functions that
remain in the adversary’s guess space after some number of
true input-output observations (X1, F (X1)), . . . , (Xq, F (Xq))
are (adaptively) obtained. Intuitively, if a large number of
functions remain in the guess space, then the probability of
winning the FR-game will be small, and conversely if the
adversary is able to eliminate all but a few functions, the
adversary’s winning probability will be close to one.
From Theorem 3, and the analysis leading to it, we can glean
some useful observations. In particular, the IP author should
use OneChaffhd to protect Boolean functions (or Boolean sub-
functions) that have large domains, and hamming weights not
too close to 0 or 2n. Functions with small domains cannot
be hidden by any DH scheme, at least not without severely
restrictive assumptions on the adversary. When the hamming
weight tends towards 0 or 2n, the function tends towards a
constant function. Intuitively, as the (known) hamming weight
of the hidden function moves away from 2n−1 towards either
0 or 2n, the number of possible functions decreases. This
makes it more likely, although not necessarily “likely”, that
the hidden function can be guessed after seeing the opaque
circuit and some true (X, F (X)) pairs. Finally, the IP author
should choose to make ∆ as large as is feasible. Intuitively,
if ∆ is small, the number of functions that remain in the
adversary’s guess space after it gets access to the opaque
circuit (that encodes chaff H and a lookup table (cid:103)Tab) will
also be small compared to large ∆. Note that the new guess
space will contain only functions that have a hamming weight
of h (due to its a priori knowledge of the hamming weight of
F ) and that also differ from H on ∆ DIs (by construction).
III. PRELIMINARIES
Basic notation. When X, Y are strings, we establish the fol-
lowing notations. We write X (cid:107) Y to denote the concatenation
of X and Y ; X[i] for the i-th element of X; and |X| to denote
the length of X. We extend the last two notations to ordered
objects (e.g., a sequence, list, table).
When T is any ordered object, we write T [i] for the i-th
element, and |T| to denote the number of elements in T . In
pseudocode, our convention will be: all such T are initialized
to T [i] = ⊥ for all values of i, where ⊥ is a distinguished
symbol. Likewise, all sets will be initially empty. We use the
notation (cid:104)V (cid:105) to denote the encoding of object V as a bit
string. The method of encoding is left implicit, and it is silently
overloaded to accommodate whatever is the type of V .
When m is an integer, we use the standard notation [m] to
denote the set {1, 2, . . . , m}. We write v1, v2, . . . , vr ←$ V to
denote sampling (with replacement) r > 0 uniform elements
of V , where V is some non-empty set. An unembellished
← denotes deterministic assignment. This notation is also
used for randomized algorithms, i.e., x ←$ A(··· ) means that
algorithm A runs on its indicated inputs, and halts with an