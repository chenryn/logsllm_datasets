33
requests. All tests utilize the static test suite shipped with WebBench 5.0, with a
setting of 10 concurrent client threads. Each test was run for 1600 seconds with
statistics calculated at 100-second intervals. In these tests, both L and W run
the Apache web server 2.2.2.
Table 2. Conﬁgurations of computers in the performance overhead evaluation
Machine Name Operating System
CPU
L
W
P
C
Memory Remarks
Linux kernel 2.6.8 Pentium IV 2.0 GHz 512 MB Replica
Windows XP Pro SP2 Pentium IV 2.0 GHz 512 MB Replica
Proxy
Windows XP Pro SP2 Pentium IV 2.2 GHz 512 MB Client
Linux kernel 2.6.11 Pentium IV 3.0 GHz
1 GB
We are primarily interested in the request throughput and latency as observed
by C in ﬁve tests. In the ﬁrst test, each of L and W sends its response to the
client’s request to the proxy P, which performs output voting on (i.e., compares)
these responses before responding to the client. Speciﬁcally, in the ﬁrst test, no
system call traces are collected on L or W, and no behavioral distance is calcu-
lated; as such, this serves as a baseline for our tests. In the second test, L and W
additionally capture the system calls made by the web server processes/threads,
and send the system call information to another machine (not P) for logging
and, potentially, oﬄine behavioral-distance calculations. This test thus includes
the costs of collecting the system call information and sending it oﬀ the server
machines, but not the cost of calculating behavioral distances. In the third test,
the system call information is sent to proxy P (and not to other machines) for
online behavioral distance calculation. P computes the behavioral distance (in
addition to performing output voting, as in the other tests) before responding to
the client. In the fourth test, the results of each behavioral distance calculation
is cached at P so that it need not be performed again if the same system call
sequences are received from L and W in the future. In the last test, only W and
C are used to evaluate the performance of an individual server, in which neither
output voting nor behavioral distance is used. We monitor the throughput and
latency in each test. The results are shown in Figure 1.
Results from the ﬁrst test, in which P does output voting only, serve as a
reference. The second test shows the performance overhead of simply capturing
and transporting the system call information oﬀ of L and W. From the results,
we can see that this overhead is very small: roughly 1% in throughput and 0.03
millisecond in latency on average. Results of the third test show the overhead
of capturing system call information and performing HMM-based behavioral
distance calculation on the critical path of responding to the client. As shown,
this cost adds substantial overhead to the request processing time. However, the
fourth test shows that this cost can be substantially reduced by caching the
behavioral distance results. It takes some time for the cache to warm up, and by
the end of the test there is less than a 20% throughput loss and 0.59 milliseconds
of additional latency on average. Comparing the results of the fourth and the
ﬁfth tests, we also see that L and W are roughly 25% underutilized in the fourth
34
D. Gao, M.K. Reiter, and D. Song
500
400
300
200
100
)
c
e
s
/
t
s
e
u
q
e
r
(
t
u
p
h
g
u
o
r
h
T
0
0
8
6
4
2
)
c
e
s
m
(
y
c
n
e
t
a
L
500
1000
Test Time (sec)
1500
0
0
500
1000
Test Time (sec)
1500
P:        output voting
L&W: serve requests
P:        output voting
L&W: serve requests + send syscall sequences for logging
P:        output voting + behavioral distance calculation
L&W: serve requests +  send syscall sequences to P
P:        output voting + behavioral distance calculation + cache results
L&W: serve requests + send syscall sequences to P
P:        not involved in experiment
L:        not involved in experiment
W:       serve requests directly
Fig. 1. Performance Overhead of the HMM-based Behavioral Distance
experiment due to the bottleneck created at the proxy. Instantiating the proxy
with a faster machine would presumably improve this situation.
6 Conclusion
In this paper we presented a new algorithm for computing behavioral distance
between processes. Our approach addresses shortcomings in prior techniques;
in particular, it better accounts for system-call orderings while oﬀering com-
parable performance. Empirical tests suggest that our algorithm oﬀers strong
defense against mimicry attacks, while providing substantial improvement in
the false-alarm rate over previous proposals. We believe that this algorithm is
a signiﬁcant step toward the practical use of behavioral distance as an anomaly
detection technique, particularly for fault- and intrusion-tolerant architectures
that already redundantly execute requests on multiple diverse platforms.
References
1. M. Abd-El-Malek, G. R. Ganger, G. R. Goodson, M. K. Reiter, and J. J. Wylie.
Fault-scalable Byzantine fault-tolerant services. In Proceedings of the 20th ACM
Symposium on Operating Systems Principles, pages 59–74, October 2005.
2. L. Alvisi, D. Malkhi, E. Pierce, and M. K. Reiter. Fault detection for Byzan-
tine quorum systems. IEEE Transactions on Parallel Distributed Systems, 12(9),
September 2001.
Behavioral Distance Measurement Using Hidden Markov Models
35
3. L. E. Baum and T. Petrie. Statistical inference for probabilistic functions of ﬁnite
state Markov chains. Ann. Math. Statist., 37:1554–1563, 1966.
4. S. Bhatkar, A. Chaturvedi, and R. Sekar. Dataﬂow anomaly detection. In Pro-
ceedings of the 2006 IEEE Symposium on Security and Privacy, 2006.
5. R. W. Buskens and R. P. Bianchini, Jr. Distributed on-line diagnosis in the presence
of arbitrary faults. In Proceedings of the 23rd International Symposium on Fault-
Tolerant Computing, pages 470–479, June 1993.
6. C. Cachin and J. A. Poritz. Secure intrusion-tolerant replication on the Internet.
In Proceedings of the 2002 International Conference on Dependable Systems and
Networks, 2002.
7. M. Castro and B. Liskov. Practical Byzantine fault tolerance and proactive recov-
ery. ACM Transactions on Computer Systems, 20(4), November 2002.
8. M. Castro, R. Rodrigues, and B. Liskov. BASE: Using abstraction to improve fault
tolerance. ACM Transactions on Computer Systems, 21(3), August 2003.
9. L. Chen and A. Avizienis. N-version programming: A fault-tolerance approach to
reliability of software operation. In Proceedings of the 8th International Symposium
on Fault-Tolerant Computing, pages 3–9, 1978.
10. S. Cho and S. Han. Two sophisticated techniques to improve HMM-based intrusion
detection systems. In Proceedings of the 6th International Symposium on Recent
Advances in Intrusion Detection (RAID 2003), 2003.
11. B. Cox, D. Evans, A. Filipi, J. Rowanhill, W. Hu, J. Davidson, J. Knight,
A. Nguyen-Tuong, and J. Hiser. N-variant systems – A secretless framework for se-
curity through diversity. In Proceedings of the 15th USENIX Security Symposium,
August 2006.
12. R. I. A. Davis, B. C. Lovell, and T. Caelli. Improved estimation of Hidden Markov
Model parameters from multiple observation sequences. In Proceedings of the 16th
International Conference on Pattern Recognition (ICPR 2002), 2002.
13. H. H. Feng, J. T. Giﬃn, Y. Huang, S. Jha, W. Lee, and B. P. Miller. Formalizing
In Proceedings of the 2004
sensitivity in static analysis for intrusion detection.
IEEE Symposium on Security and Privacy, 2004.
14. H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong. Anomaly detection
In Proceedings of the 2003 IEEE Symposium on
using call stack information.
Security and Privacy, 2003.
15. S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaﬀ. A sense of self for Unix
processes. In Proceedings of the 1996 IEEE Symposium on Security and Privacy,
1996.
16. D. Gao, M. K. Reiter, and D. Song. Gray-box extraction of execution graph for
anomaly detection. In Proceedings of the 11th ACM Conference on Computer &
Communication Security, 2004.
17. D. Gao, M. K. Reiter, and D. Song. On gray-box program tracking for anomaly
detection. In Proceedings of the 13th USENIX Security Symposium, 2004.
18. D. Gao, M. K. Reiter, and D. Song. Behavioral distance for intrusion detection. In
Proceedings of the 8th International Symposium on Recent Advances in Intrusion
Detection (RAID 2005), 2005.
19. J. T. Giﬃn, S. Jha, and B. P. Miller. Detecting manipulated remote call streams.
In Proceedings of the 11th USENIX Security Symposium, 2002.
20. J. T. Giﬃn, S. Jha, and B. P. Miller. Eﬃcient context-sensitive intrusion detection.
In Proceedings of Symposium on Network and Distributed System Security, 2004.
21. C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the detection of anomalous
system call arguments. In Proceedings of the 8th European Symposium on Research
in Computer Security (ESORICS 2003), 2003.
36
D. Gao, M.K. Reiter, and D. Song
22. L. Lamport. The implementation of reliable distributed multiprocess systems.
Computer Networks, 2:95–114, 1978.
23. I. M. Meyer and R. Durbin. Comparative ab initio prediction of gene structures
using pair HMMs. Oxford University Press, 2002.
24. L. Pachter, M. Alexandersson, and S. Cawley. Applications of generalized pair
Hidden Markov Models to alignment and gene ﬁnding problems. Computational
Biology, 9(2), 2002.
25. L. R. Rabiner. A tutorial on Hidden Markov Models and selected applications in
speech recognition. In Proceedings of IEEE, February 1989.
26. M. K. Reiter. Secure agreement protocols: Reliable and atomic group multicast in
Rampart. In Proceedings of the 2nd ACM Conference on Computer and Commu-
nication Security, pages 68–80, November 1994.
27. F. B. Schneider.
Implementing fault-tolerant services using the state machine
approach: A tutorial. ACM Computing Surveys, 22(4):299–319, December 1990.
28. R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A fast automaton-based
method for detecting anomalous program behaviors. In Proceedings of the 2001
IEEE Symposium on Security and Privacy, 2001.
29. P. H. Sellers. On the theory and computation of evolutionary distances. SIAM J.
Appl. Math., 26:787–793, 1974.
30. K. Shin and P. Ramanathan. Diagnosis of processors with Byzantine faults in a
distributed computing system. In Proceedings of the 17th International Symposium
on Fault-Tolerant Computing, pages 55–60, 1987.
31. K. Tan, J. McHugh, and K. Killourhy. Hiding intrusions: From the abnormal
to the normal and beyond. In Proceedings of the 5th International Workshop on
Information Hiding, October 2002.
32. D. Wagner and D. Dean. Intrusion detection via static analysis. In Proceedings of
the 2001 IEEE Symposium on Security and Privacy, 2001.
33. D. Wagner and P. Soto. Mimicry attacks on host-based intrusion detection systems.
In Proceedings of the 9th ACM Conference on Computer and Communications
Security, 2002.
34. C. Warrender, S. Forrest, and B. Pearlmutter. Detecting intrusions using system
In Proceedings of the 1999 IEEE Symposium on
calls: alternative data models.
Security and Privacy, 1999.
35. A. Wespi, M. Dacier, and H. Debar. Intrusion detection using variable-length audit
trail patterns. In Proceedings of the 2000 Recent Advances in Intrusion Detection,
2000.
36. J. Yin, J. Martin, A. Venkataramani, L. Alvisi, and M. Dahlin. Separating agree-
ment from execution for Byzantine fault tolerant services. In Proceedings of the
19th ACM Symposium on Operating System Principles, October 2003.
A Updating the bi Parameters of λ
The idea of updating bi parameters of λ is the same as of updating ai (see
Section 4.3). Here, we need to calculate the expected number of times λ emits
observable symbol [x, y] at qi, when generating [S1, S2]. To compute this expec-
tation, we ﬁrst deﬁne a conditional probability, ζ([x, y], u, v, i), as follows:
Behavioral Distance Measurement Using Hidden Markov Models
37
⎛
⎛
⎜
⎜
⎜
⎜
⎝
⎜
⎜
⎜
⎜
⎝
(cid:6)
t≥0
Statet = qi ∧
1 = Seq(x) ∧
Outt
2 = Seq(y) ∧
Outt
1 = Pre(S1, u) ∧
≤t
Out
≤t
2 = Pre(S2, v)
Out
⎞
⎟
⎟
⎟
⎟
⎠
(cid:14)
(cid:14)
(cid:14)
(cid:14)
(cid:16)
(cid:15)
Out>0
Out>0
1 = S1 ∧
2 = S2
⎞
⎟
⎟
⎟
⎟
⎠
ζ([x, y], u, v, i) = Prλ
where
Seq(x) =
(cid:11)(cid:2)x(cid:3)
(cid:2)(cid:3)
if x (cid:6)= σ
if x = σ
and Outt
1 is the sequence of system calls from C1 in the ﬁrst component of the
emitted symbol in iteration t, with either one (if the component of the emitted
symbol is not σ) or zero (if the component of the emitted symbol is σ) system
call in the sequence. Outt
2 is deﬁned similarly.
ζ([x, y], u, v, i) represents the probability of λ being in state qi after emitting u
system calls for process 1 and v system calls for process 2, and the last observable
symbol emitted by state qi is [x, y], given that the system call sequences for
process 1 and process 2 are S1 and S2, respectively. Note that
γ(u, v, i) =