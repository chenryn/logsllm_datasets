title:CrypTFlow: Secure TensorFlow Inference
author:Nishant Kumar and
Mayank Rathee and
Nishanth Chandran and
Divya Gupta and
Aseem Rastogi and
Rahul Sharma
2020 IEEE Symposium on Security and Privacy
CRYPTFLOW: Secure TensorFlow Inference
Nishant Kumar∗
Microsoft Research
PI:EMAIL
Divya Gupta
Microsoft Research
PI:EMAIL
Mayank Rathee∗
Microsoft Research
PI:EMAIL
Aseem Rastogi
Microsoft Research
PI:EMAIL
Nishanth Chandran
Microsoft Research
PI:EMAIL
Rahul Sharma
Microsoft Research
PI:EMAIL
Abstract— We present CRYPTFLOW, a ﬁrst of its kind system
that converts TensorFlow inference code into Secure Multi-party
Computation (MPC) protocols at the push of a button. To do
this, we build three components. Our ﬁrst component, Athos, is
an end-to-end compiler from TensorFlow to a variety of semi-
honest MPC protocols. The second component, Porthos, is an
improved semi-honest 3-party protocol that provides signiﬁcant
speedups for TensorFlow like applications. Finally, to provide
malicious secure MPC protocols, our third component, Aramis,
is a novel technique that uses hardware with integrity guarantees
to convert any semi-honest MPC protocol into an MPC protocol
that provides malicious security. The malicious security of the
protocols output by Aramis relies on integrity of the hardware
and semi-honest security of MPC. Moreover, our system matches
the inference accuracy of plaintext TensorFlow.
We experimentally demonstrate the power of our system by
showing the secure inference of real-world neural networks such
as RESNET50 and DENSENET121 over the ImageNet dataset
with running times of about 30 seconds for semi-honest security
and under two minutes for malicious security. Prior work in the
area of secure inference has been limited to semi-honest security
of small networks over tiny datasets such as MNIST or CIFAR.
Even on MNIST/CIFAR, CRYPTFLOW outperforms prior work.
I. INTRODUCTION
Secure multiparty computation (or MPC) allows a set of mu-
tually distrusting parties to compute a publicly known function
on their secret inputs without revealing their inputs to each
other. This is done through the execution of a cryptographic
protocol which guarantees that the protocol participants learn
only the function output on their secret inputs and nothing else.
MPC has made rapid strides - from being a theoretical concept
three decades ago [82], [35], to now being on the threshold
of having real world impact. One of the most compelling
use cases for MPC is that of machine learning (ML) - e.g.
being able to execute inference over ML algorithms securely
when the model and the query are required to be hidden
from the participants in the protocol. There has been a ﬂurry
of recent works aimed at running inference securely with
MPC such as SecureML [62], MinioNN [55], ABY3 [60],
CHET [27], SecureNN [79], Gazelle [49], Delphi [58], and
so on. Unfortunately, these techniques are not easy-to-use by
ML developers and have only been demonstrated on small
deep neural networks (DNNs) on tiny datasets such as MNIST
∗ Equal contribution
or CIFAR. However, in order for MPC to be truly ubiquitous
for secure inference tasks, it must be both effortless to use and
capable of handling large ImageNet [31] scale DNNs.
In this work, we present CRYPTFLOW, a ﬁrst of its kind
system,
that converts TensorFlow [6] inference code into
MPC protocols at the push of a button. By converting code
in standard TensorFlow, a ubiquitous ML framework that
is used in production by various technology companies, to
MPC protocols, we signiﬁcantly lower the entry barrier for
ML practitioners and programmers to use cryptographic MPC
protocols in real world applications. We make the following
four contributions:
First, we provide a compiler, called Athos, from Ten-
sorFlow to a variety of secure computation protocols
(both 2 and 3 party) while preserving accuracy. In the
absence of Athos, all prior works require manually re-
implementing ML models in an MPC friendly low-level
language/library, and hence, their evaluations have been
limited to small benchmarks where this task is feasible.
Second, we provide a semi-honest secure 3-party compu-
tation protocol, Porthos, that outperforms all prior proto-
cols for secure inference and enables us to execute, for
the ﬁrst time, the inference of ImageNet scale networks
in about 30 seconds.
Third, assuming a minimally secure hardware which
guarantees the integrity of computations, we show a
novel technique, Aramis, that compiles any semi-honest
secure MPC protocol to a malicious secure MPC protocol.
Aramis only relies on these integrity checks and assumes
no conﬁdentiality guarantees for data residing within the
hardware. Aramis enables the ﬁrst implementations of
DNN inference secure against malicious adversaries.
Fourth, we demonstrate the ease-of-use, efﬁciency and
scalability of CRYPTFLOW by evaluating on
(a) RESNET50 [40], which won the ImageNet Large
Scale Visual Recognition Challenge in 2015 [31];
(b) DENSENET121 [43], a convolutional neural network
that won the best paper at CVPR 2017.
These networks have heavily inﬂuenced the ML com-
munity with thousands of citations each. To demonstrate
that CRYPTFLOW is immediately useful in healthcare, we
© 2020, Aseem Rastogi. Under license to IEEE.
DOI 10.1109/SP40000.2020.00092
336
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:36:59 UTC from IEEE Xplore.  Restrictions apply. 
also evaluate CRYPTFLOW on DNNs used for prediction
of lung diseases and diabetic retinopathy.
Our toolchain and all of our benchmarks are publicly
available1.We now describe our results in more detail.
A. Results
CRYPTFLOW outperforms prior work on ease-of-use, scal-
ability, and efﬁciency. It automatically compiles TensorFlow
code to MPC protocols with no loss in classiﬁcation accuracy.
This makes CRYPTFLOW the ﬁrst secure inference system
to produce a Top 1 accuracy of 76.45% and Top 5 accuracy
of 93.23% for predictions running securely on the ImageNet
dataset. Furthermore, in the 3-party (3PC) setting, this can
be done in about 30 seconds with semi-honest security and
about 2 minutes with malicious security. Prior work in the
area of secure inference has been limited to small networks
over tiny datasets such as MNIST or CIFAR. Moreover,
these implementations are limited to security against weaker
semi-honest adversaries, that are assumed not to modify the
code of the MPC protocol. In contrast, our largest network
RESNET-200 has 200 layers, 65 million parameters, over 1000
ImageNet classes, and the user can choose between semi-
honest and malicious security – the latter also protects against
adversaries who can deviate from the MPC protocol speciﬁ-
cation arbitrarily. We have evaluated CRYPTFLOW on secure
inference over DNNs that are at least an order of magnitude
larger than the state-of-the-art [58], [27], [72], [79], [62], [49],
[19], [55], [60], [15], [71], [12]. Even on MNIST/CIFAR,
CRYPTFLOW has lower communication complexity and is
more efﬁcient than prior and concurrent works [79], [60],
[72], [12]. Furthermore, CRYPTFLOW is the ﬁrst system to
implement2 malicious security for secure DNN inference. We
show that the overhead of Aramis over semi-honest protocols
is small and varies between 25% and 3X depending on the size
of the computation. Moreover, by very conservative estimates,
Aramis based secure DNN inference is faster than state-of-the-
art malicious secure MPC inference protocols [4] by at least
an order of magnitude (and also the maliciously secure MPC
protocols for general computation [80], [81], [50]). Hence, on
inference tasks, prior MPC protocols are either much slower
than Aramis or fail
to provide security against malicious
adversaries.
B. Components of CRYPTFLOW
We describe the three components of CRYPTFLOW next.
Athos (Section III). Athos is a compiler that compiles
TensorFlow inference code to secure computation protocols.
There are several challenges in doing so. For optimizations
(Section III-D),
the compiler needs the dimensions of all
the tensors occurring in the dynamic Python code. The
1https://github.com/mpc-msri/EzPC
2ABY3 [60] provided a theoretical protocol to convert their semi-honest
protocol
into a malicious secure protocol on much smaller benchmarks
than CRYPTFLOW, but did not provide an implementation or experimental
validation.
compiler is designed to be modular (Section III-C) and it
provides facilities for plugging in various MPC protocols.
To demonstrate this modularity, we have implemented the
following backends: ABY-based 2-party computation (2PC),
Porthos-based semi-honest secure 3-party computation (3PC),
and Aramis-based malicious secure 3-party computation.
The transformations implemented in Athos are sensitive
to the performance of MPC protocols. For performance
reasons all efﬁcient secure computation protocols perform
computation over ﬁxed-point arithmetic - i.e., arithmetic over
integers or arithmetic with ﬁxed precision. This is in contrast
to TensorFlow where computations are over ﬂoating-point
values. Athos automatically converts TensorFlow code over
ﬂoating-point values into code that computes the same
function over ﬁxed-point values. This compilation is done
while matching the inference accuracy of ﬂoating-point code.
Prior works ([62], [55], [49], [60], [79], [58]) in the area
of running ML securely have performed this task by hand
with signiﬁcant losses in accuracy over ﬂoating-point code.
Although these ﬁxed-point conversions are feasible to do
manually for one or two small benchmarks, this task quickly
becomes intractable for large benchmarks and needs to be
repeated for every new benchmark. Athos automates this
tedious and error prone task.
(Section IV). Porthos
Porthos
is an improved semi-
honest 3-party secure computation protocol (tolerating one
corruption) that builds upon SecureNN [79]. Porthos makes
two crucial modiﬁcations to SecureNN. First, SecureNN
reduces convolutions to matrix multiplications and invokes
the Beaver triples [13] based matrix multiplication protocol.
When performing a convolution with ﬁlter size f × f on
a matrix of size m × m,
the communication is roughly
2q2f 2 + 2f 2 + q2 elements
in the ring Z264, where
q = m − f + 1. Porthos computes these Beaver triples by
appropriately reshaping m × m and f × f matrices. This
reduces the communication to roughly 2m2 + 2f 2 + q2 ring
elements. Typically the ﬁlter size, f, is between 1 and 11 and
the communication of Porthos can be up to two orders of
magnitudes lower than SecureNN. Additionally, in SecureNN,
the protocols for non-linear layers (such as Rectiﬁed Linear
Units (ReLU) and MaxPool) require the third party to send
secret shares to the ﬁrst two parties. In Porthos, we cut this
communication to half by eliminating the communication
of one of these shares. This reduces the communication in
the overall ReLU and MaxPool protocols by 25%. Thus,
by reducing the communication in both linear convolution
layers and non-linear layers, the communication in Porthos is
several GBs lower than SecureNN (Table VIII).
Aramis (Section V). Obtaining maliciously secure MPC
protocols through cryptography can often be challenging
and expensive – typically some sort of “proof of honest
computation” must be provided by the parties for every step
of the protocol. We present a novel technique, called Aramis,
that compiles MPC protocols secure against semi-honest
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:36:59 UTC from IEEE Xplore.  Restrictions apply. 
337
adversaries into MPC protocols that are secure against
malicious adversaries, by leveraging secure hardware. We
only require the hardware to provide code attestation and a
secure signing functionality (that we use to sign and verify
the protocol messages). Aramis has two attractive features:
(a) it works in a strong adversarial threat model; and (b) it
serves as a general technique that can work on a variety of
semi-honest secure MPC protocols. In more detail:
(a) The threat model of Aramis is signiﬁcantly stronger than
the prior work on MPC using secure hardware [74], [69],
[38], [11], [23], [29], [51], [32], [77], [83], [44]. Specif-
ically, in our threat model, not only is the host operating
system outside the Trusted Computing Base, but it is
also allowed to observe the entire state of the hardware
(including user data). In contrast, for security of the
protocol, the prior works require that the hardware hides
the state from the host and even if data is decrypted and
computed upon inside the hardware, it cannot be viewed
by the host. In Section V, we describe the Aramis threat
model in more detail, formalize the secure hardware as
an ideal functionality, provide a formal description of
the malicious secure MPC protocols, and formally prove
their security. The ideal functionality can potentially be
realized using various hardware platforms that provide
code attestation and signing, e.g., STM32H7, MediaTek
MT3620, CEC1702, ARMTrustZone, Intel’s SGX, etc.
We provide a proof-of-concept implementation of Aramis
by using SGX as the underlying secure hardware.
(b) Aramis is general and can be applied to any semi-
honest secure MPC protocol. To demonstrate this, we
derive malicious secure MPC protocols from both semi-
honest GMW (2 party protocol) [35] and Porthos (3
party protocol). Porthos compiled with Aramis gives the
ﬁrst experimentally vetted maliciously secure protocol for
neural network inference with at most 3X overhead over
semi-honest security. While these were the semi-honest
protocols we applied Aramis to, one could potentially
obtain performant maliciously secure variants of several
other recent semi-honest secure inference protocols (e.g.
[49], [58], [7]), and MPC protocols for other applica-
tions [52], [47].
C. Organization of the paper
We provide an end-to-end walkthrough of our system to
illustrate the overall toolchain in Section II. In Section III,
we describe our compiler Athos. Section IV describes our
improved 3-party semi-honest secure protocol for neural net-
works. We describe Aramis that compiles any semi-honest
secure protocol into a malicious secure protocol, in Section V.
We present all our experimental results in Section VI, related
works in Section VII and conclude in Section VIII.
II. MOTIVATING EXAMPLE
In this section, we describe the end-to-end working of
CRYPTFLOW through an example of logistic regression. The
TensorFlow
Code 
(Fig. 2)
Metadata
generation
(Fig. 3)
Athos
HLIL
(Fig. 4a)
Float-to-
fixed
(Sec. III(B))
LLIL
(Fig. 4b)
Outputs
Runtime
Private inputs
MPC 
protocol
LLIL
compilation
ABY
[30]
Porthos
(Sec. IV)
Aramis
(Sec. V)
Fig. 1: CRYPTFLOW: End-to-end toolchain
# x is an MNIST image of shape (1,784).
# W and b are the model parameters.
print(tf.argmax(tf.matmul(x, W) + b, 1))
Fig. 2: Logistic Regression: TensorFlow snippet
high-level toolchain is shown in Figure 1. We describe how
code compilation happens from TensorFlow to MPC protocols.
The CRYPTFLOW toolchain takes as input code written in
vanilla TensorFlow. For example, consider the code snippet
for logistic regression over MNIST dataset in TensorFlow as
shown in Figure 2. Our compiler ﬁrst generates the Ten-
sorFlow graph dump (as shown in Figure 3a) as well as
metadata to help compute the dimensions of all the tensors
(Figure 3b). III-A provides more details on the frontend. Next,
the TensorFlow graph dump is compiled into a high-level
intermediate language HLIL. The code snippet for logistic
regression in HLIL is shown in Figure 4a. Next, Athos’ ﬂoat-