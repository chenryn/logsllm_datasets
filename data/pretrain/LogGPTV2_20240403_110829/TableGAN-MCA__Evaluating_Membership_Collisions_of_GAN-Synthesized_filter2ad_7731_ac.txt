additional data pre-processing. (1) We discretize imbalanced and
sparse numerical values in given columns to categorical values.
(2) We normalize numerical columns into (0, 1) or (−1, 1). (3) We
one-hot encode all categorical features (4) We split the dataset into
the training set (𝐷𝑡, 70% records) and test set (𝐷𝑠, 30% records) (see
row 1 and row 2 in Table 3). The training set is used for dataset
synthesis and the test set is used for examining the utility of the
synthetic data.
Discretization in pre-processing. Features in tabular dataset are
either categorical or numerical variables. Unlike pictures, some nu-
merical columns are non-Gaussian distribution, that is, it either has
long tails, sparse distribution or multiple modes. Generative models
cannot model them well without appropriate pre-processing. To
address this issue, we discretize the imbalanced and sparse numer-
ical values to categorical values. In the experiments, such simple
discretization in pre-processing exhibits decent performance in
generating complex features while keeping original statistics. Note
that discretization definitely makes some records of the original
dataset share the same values (similar to 𝑘-anonymity [45]). We
show the uniqueness of the records after pre-processing in Table 3
(row three and four), where a large proportion of sensitive data
points can still be uniquely identified before feeding into generative
models.
5.3 Metrics
5.3.1 Data Utility Metrics. For data utility evaluation, we consider
two measurements: machine learning efficacy (models trained on a
synthetic dataset and the original dataset provide similar predic-
tions) and distribution fitness (a synthetic dataset is statistically
similar to its original dataset in all attributes).
∫ +∞
For distribution fitness, we present 1-way marginals that are
approximated by the Empirical Cumulative Distribution Function
(ECDF) for each attribute. Having ECDFs of real and synthetic data,
we compute attribute-wise Wasserstein distance, i.e., 𝑙1(𝑥𝑖, 𝑥′
𝑖) =
𝑛
−∞ |𝑈𝑖 −𝑉𝑖|, where 𝑈𝑖 and 𝑉𝑖 are respective CDFs of real attribute
𝑥𝑖 and synthetic attribute 𝑥′
𝑖 [37]. We compare the expected value
𝑖=1{𝑙1(𝑥𝑖, 𝑥′
𝑖)}.
of ECDFs by E𝑖(𝑙1) = 1
𝑛
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2100Table 4: Model prediction accuracy (%) trained on real train-
ing 𝐷𝑡 (“Base”) and GAN-synthesized datasets 𝑆. E𝑖(𝑙1) de-
notes the average of all attribute-wise Wasserstein distance.
E𝑖(𝑙1)
0
t
l
u
d
A
Methods
DT MLPC
84.11
85.39
Base
77.53
79.24
TVAE
81.76
CTGAN
81.53
83.62
WGANWC 82.74
WGANGP
83.16
83.95
89.54
81.90
l Base
85.38
79.53
TVAE
80.91
CTGAN
76.35
WGANWC 77.54
80.76
86.10
80.14
WGANGP
70.58
69.89
Base
68.07
64.42
TVAE
58.14
60.21
CTGAN
66.5
WGANWC 65.34
WGANGP
64.12
66.91
o
o
h
c
s
w
a
L
s
a
p
m
o
C
Ada
86.28
78.72
82.3
84.16
84.24
87.23
85.17
81.02
80.56
86.02
71.65
64.33
59.5
65.06
65.20
LR
84.74
80.2
82.41
83.96
83.93
87.68
85.26
81.37
80.93
86.79
71.46
68.33
58.12
68.46
68.34
0.0207
0.0266
0.0075
0.0039
0
0.0120
0.0283
0.0073
0.0047
0
0.0159
0.0373
0.0095
0.0179
5.3.2 Attack Performance Metrics. To evaluate the privacy of the
released synthetic table, we consider membership collisions pri-
vacy, i.e., the TableGAN-MCA effect. We use precision and recall
to evaluate the attack performance (following Shokri et al. [43]),
since the synthetic dataset that is used to inference has a skewed
label distribution. Specifically, precision measures the probability
of an entry inferred as a member is indeed the member of the train-
ing dataset, denoted as Pr(𝑦 = 1| ˆ𝑦 = 1). Intuitively, it implies the
confidence of the attacker in guessing positive membership. Recall
measures the probability of a member is correctly inferred as a
member by the attacker, denoted as Pr( ˆ𝑦 = 1|𝑦 = 1). It reflects
the percentage of positives exposed in the attack. In evaluation,
we report precision and recall by Precision-Recall (PR) curve since
it is more informative than ROC-curve under the case of skewed
label distribution [10]. A higher Area under the PR-curve (AUPRC)
implies both higher precision and recall, and thus they are used to
compare the attack efficacy.
In addition to the attack precision and recall, we also consider
a recovery rate because it reflects what the proportion of training
data 𝐷𝑡 are being exposed to TableGAN-MCA. Let 𝑅A be recovered
training data sets of the attack algorithm A. The recovery rate 𝜌A
of A is defined as below:
𝜌A = |𝑅A|/|𝐷𝑡|.
(7)
Note that the recovery rate shares the same numerator as the recall
of the attack model 𝑓 (·) but the different denominator (|𝐷𝑡| vs |𝐼|).
5.4 Synthetic Data Utility
We evaluate machine learning efficacy of synthetic data generated
by four generative models, CTGAN [46], TVAE [46], WGAN-GP and
WGAN-WC vary four binary classifiers: DecisionTreeClassifier,
MLPClassifier, AdaBoostClassifier, and LogisticRegression
(Standard scikit-learn machine learning library, see middle columns
in Table 4). We also compare ECDFs using the average of all attribute-
wise Wasserstein distance E𝑖(𝑙1) (see the last column in Table 4).
All numerical features are min-max scaled to (0, 1) and categorical
(a) Adult
(b) Compas
(c) Lawschool
Figure 5: The Empirical Cumulative Distribution of each at-
tribute in the Adult, Compas and Lawschool datasets (Or-
ange line for real and blue line for synthetic).
features are one-hot encoded before feeding into the classifier. For
“base”, we trained on the sensitive dataset 𝐷𝑡 that is used for data
synthesis and test on the real test set 𝐷𝑠 (see Table 3). For synthetic
data, we trained on a synthetic dataset 𝑆 of the same size as the
sensitive dataset and test on the same real test set 𝐷𝑠. To imple-
ment CTGAN and TVAE, we directly feed our pre-processed data
into the module CTGANSynthesizer and TVAESynthesizer of the
SDGym [5] (published code for [46]).
According to Table 4, the synthetic dataset generated by WGAN-
GP, WGAN-WC, CTGAN and TVAE can greatly restore the predic-
tion ability of the model trained on original dataset. TVAE is least
ideal than the others in the Adult dataset. CTGAN is least ideal
than the others in the Compas dataset. We will use these learned
generative models to perform TableGAN-MCA experiments later.
For marginal fitness, we depict an additional ECDF comparison
between real and synthetic Adult, Lawschool and Compas datasets
generated by WGAN-GP in Fig. 5. In our experiments, we depict
ECDFs of continuous variables (i.e., age, isat) and more complex
categorical variables (i.e., hours per week, priors count) since they
are more difficult to fit. As can be seen in Fig. 5, the marginals of
the synthetic dataset are almost indistinguishable from the original
one, thus supporting any statistical queries.
5.5 Attack Performance
5.5.1 Performance Evaluation on TableGAN-MCA. In this section,
we evaluate TableGAN-MCA of Alg. 1 on the Adult, Lawschool
and Compas datasets. The training and inference data statistics of
TableGAN-MCA are presented in Table 5, where positive percentage
implies the membership collisions proportion. Both target models
and shadow models are WGAN-GP. The attack model is trained on
the shadow dataset(cid:101)𝑆 and tested on the synthetic dataset 𝑆.
TableGAN-MCA provides a promising attack against the
GAN-synthesized tables. We report the PR-curve of the attack
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2101Table 5: Training and inference statistics for the Adult, Com-
pas and Lawschool datasets in TableGAN-MCA.
Table 6: TableGAN-MCA’s recovery rate 𝜌A. (|𝑅A|: # of recov-
ered data points under attack algorithm A)
|(cid:101)𝑆| (Train)
|𝑆| (Inference)
Pr(cid:101)𝑆 [𝑦𝑖 = 1]
Pr𝑆 [𝑦𝑖 = 1]
Adult
31655
31655
15.99%
16.90%
Lawsch Compas
43011
43011
22.68%
23.89%
3694
3694
40.49%
34.00%
Datasets
Adult
Lawsch
Compas
𝜌A(%)
3.04
6.10
3.03
4.66
12.41
17.17
|𝑅A|
962
1931
1305
2003
458
634
|𝐷𝑡|
31655
31655
43011
43011
3694
3694
Precision Recall
0.16
0.36
0.13
0.18
0.37
0.43