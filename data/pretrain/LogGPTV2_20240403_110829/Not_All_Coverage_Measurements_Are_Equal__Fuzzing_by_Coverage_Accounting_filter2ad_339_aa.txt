title:Not All Coverage Measurements Are Equal: Fuzzing by Coverage Accounting
for Input Prioritization
author:Yanhao Wang and
Xiangkun Jia and
Yuwei Liu and
Kyle Zeng and
Tiffany Bao and
Dinghao Wu and
Purui Su
Not All Coverage Measurements Are Equal:
Fuzzing by Coverage Accounting for Input Prioritization
Yanhao Wang1,2 Xiangkun Jia3 Yuwei Liu1,4 Kyle Zeng5
Tiffany Bao5 Dinghao Wu3
Purui Su1,4,6
1TCA/SKLCS, Institute of Software, Chinese Academy of Sciences
2QiAnXin Technology Research Institute
3Pennsylvania State University
5Arizona State University
{wangyanhao, liuyuwei}@tca.iscas.ac.cn
4School of Cyber Security, University of Chinese Academy of Sciences
6Cyberspace Security Research Center, Peng Cheng Laboratory
PI:EMAIL
{tbao, zengyhkyle}@asu.edu
{xxj56, duw12}@psu.edu
Abstract—Coverage-based fuzzing has been actively studied
and widely adopted for ﬁnding vulnerabilities in real-world
software applications. With coverage information, such as state-
ment coverage and transition coverage, as the guidance of
input mutation, coverage-based fuzzing can generate inputs that
cover more code and thus ﬁnd more vulnerabilities without
prerequisite information such as input format. Current coverage-
based fuzzing tools treat covered code equally. All inputs that
contribute to new statements or transitions are kept for future
mutation no matter what the statements or transitions are
and how much they impact security. Although this design is
reasonable from the perspective of software testing that aims
at full code coverage, it is inefﬁcient for vulnerability discovery
since that 1) current techniques are still inadequate to reach
full coverage within a reasonable amount of time, and that 2)
we always want to discover vulnerabilities early so that it can
be ﬁxed promptly. Even worse, due to the non-discriminative
code coverage treatment, current fuzzing tools suffer from recent
anti-fuzzing techniques and become much less effective in ﬁnding
vulnerabilities from programs enabled with anti-fuzzing schemes.
To address the limitation caused by equal coverage, we
propose coverage accounting, a novel approach that evaluates
coverage by security impacts. Coverage accounting attributes
edges by three metrics based on three different levels: function,
loop and basic block. Based on the proposed metrics, we
design a new scheme to prioritize fuzzing inputs and develop
TortoiseFuzz, a greybox fuzzer for ﬁnding memory corruption
vulnerabilities. We evaluated TortoiseFuzz on 30 real-world
applications and compared it with 6 state-of-the-art greybox and
hybrid fuzzers: AFL, AFLFast, FairFuzz, MOPT, QSYM, and
Angora. Statistically, TortoiseFuzz found more vulnerabilities
than 5 out of 6 fuzzers (AFL, AFLFast, FairFuzz, MOPT, and
Angora), and it had a comparable result to QSYM yet only
consumed around 2% of QSYM’s memory usage on average. We
also compared coverage accounting metrics with two other met-
rics, AFL-Sensitive and LEOPARD, and TortoiseFuzz performed
signiﬁcantly better than both metrics in ﬁnding vulnerabilities.
Furthermore, we applied the coverage accounting metrics to
QSYM and noticed that coverage accounting helps increase
the number of discovered vulnerabilities by 28.6% on average.
TortoiseFuzz found 20 zero-day vulnerabilities with 15 conﬁrmed
with CVE identiﬁcations.
Network and Distributed Systems Security (NDSS) Symposium 2020
23-26 February 2020, San Diego, CA, USA
ISBN 1-891562-61-4
https://dx.doi.org/10.14722/ndss.2020.24422
www.ndss-symposium.org
I.
INTRODUCTION
Fuzzing has been extensively used to ﬁnd real-world
software vulnerabilities. Companies such as Google and Apple
have deployed fuzzing tools to discover vulnerabilities, and
researchers have proposed various fuzzing techniques [4, 6, 7,
12, 18, 29, 33, 43, 45, 47, 56, 60, 61]. Speciﬁcally, coverage-
guided fuzzing [4, 6, 12, 18, 33, 43, 45, 56, 61] has been
actively studied in recent years. In contrast to generational
fuzzing, which generates inputs based on given format speci-
ﬁcations [2, 3, 16], coverage-guided fuzzing does not require
knowledge such as input format or program speciﬁcations.
Instead, coverage-guided fuzzing mutates inputs randomly and
uses coverage to select and prioritize mutated inputs.
AFL [60] leverages edge coverage (a.k.a. branch coverage
or transition coverage), and libFuzzer [47] supports both edge
and block coverage. Speciﬁcally, AFL saves all inputs with
new edge coverage, and it prioritizes inputs by size and
latency while guaranteeing that the prioritized inputs cover
all edges. Based on AFL, recent work advances the edge
coverage metrics by adding ﬁner-grained information such
as call context [12], memory access addresses, and more
preceding basic blocks [53].
However, previous work treats edges equally, neglecting
that the likelihoods of edge destinations being vulnerable are
different. As a result, for all the inputs that lead to new
coverage, those that execute the newly explored code that is
less likely to be vulnerable are treated as important as the
others and are selected for mutation and fuzzing.
lead to error-handling code, but
Although such design is reasonable for program testing
which aims at full program coverage, it delays the discovery
of a vulnerability. VUzzer [43] mitigates the issue by de-
prioritizing inputs that
it
depends on taint analysis and thus is expensive. CollAFL [18]
proposes alternative input prioritization algorithms regarding
the execution path, but it cannot guarantee that prioritized
inputs cover all security-sensitive edges and it may cause
the fuzzer to be trapped in a small part of the code. AFL-
Sensitive [53] and Angora [12] add more metrics comple-
mentary to edges, but edges are still considered equally, so
the issue still exists for the inputs with the same value in the
complementary metrics. LEOPARD [15] considers function
coverage instead of edges and it weights functions differently,
but it requires static analysis to preprocess, which causes
extra performance overhead. Even worse, these approaches are
all vulnerable to anti-fuzzing techniques [23, 28] (See II-D).
Therefore, we need a new input prioritization method that
ﬁnds more vulnerabilities and is less affected by anti-fuzzing
techniques.
In this paper, we propose coverage accounting, a new
approach for input prioritization. Our insight is that, any work
that adds additional information to edge representation will
not be able to defeat anti-fuzzing since the fundamental issue
is that current edge-guided fuzzers treat coverage equally.
Moreover, memory corruption vulnerabilities are closely re-
lated to sensitive memory operations, and sensitive memory
operations can be represented at different granularity of func-
tion, loop, and basic block [27]. To ﬁnd memory corruption
vulnerabilities effectively, we should cover and focus on edges
associated with sensitive memory operations only. Based on
this observation, our approach assesses edges from function,
loop, and basic block levels, and it labels edges security-
sensitive based on the three metrics of different levels. We
prioritize inputs by new security-sensitive coverage, and cull
the prioritized inputs by the hit count of security-sensitive
edges and meanwhile guarantee the selected inputs cover all
visited security-sensitive edges.
Based on the proposed approach, we develop TortoiseFuzz,
a greybox coverage-guided fuzzer1. TortoiseFuzz does not rely
on taint analysis or symbolic execution; the only addition to
AFL is the coverage accounting scheme inserted in the step
of queue culling (See II).
TortoiseFuzz is simple yet powerful in ﬁnding vulnera-
bilities. We evaluated TortoiseFuzz on 30 popular real-world
applications and compared TortoiseFuzz with 6 state-of-the-
art greybox [7, 31, 36, 60] and hybrid fuzzers [12, 59]. We
calculated the number of discovered vulnerabilities, and con-
ducted Mann-Whitney U test to justify statistical signiﬁcance
between TortoiseFuzz and the compared fuzzers. TortoiseFuzz
performed better than 5 out of 6 fuzzers (AFL, AFLFast,
FairFuzz, MOPT, and Angora), and it had a comparable result
to QSYM yet only consumed, on average, around 2% of
the memory resourced used by QSYM. TortoiseFuzz found
20 zero-day vulnerabilities with 15 conﬁrmed with CVE
identiﬁcations.
We also compared coverage accounting metrics against
AFL-Sensitive and LEOPARD, and the experiment showed
that our coverage accounting metrics performed signiﬁcantly
better in ﬁnding vulnerabilities than both metrics. Further-
more, we applied the coverage accounting metrics to QSYM,
and we noticed that coverage accounting boosted the number
of discovered vulnerabilities by 28.6% on average.
To foster future research, we will release the prototype of
TortoiseFuzz open-sourced at https://github.com/TortoiseFuzz/
as well as the experiment data for reproducibility.
Contribution. In summary, this paper makes the following
contributions.
• We propose coverage accounting, a novel approach for
input prioritization with metrics that evaluates edges in
1The name comes from a story of Aesop’s Fables. A tortoise is ridiculed
by a rabbit at ﬁrst in a race, crawls slowly but steadily, and beats the rabbit
ﬁnally. As American Fuzzy Lop is a kind of rabbit, TortoiseFuzz wins.
Fig. 1: The framework of AFL.
terms of the relevance of memory corruption vulnerabil-
ities. Our approach is lightweighted without expensive
analyses, such as taint analysis and symbolic execution,
and is less affected by anti-fuzzing techniques.
• We design and develop TortoiseFuzz, a greybox fuzzer
based on coverage accounting. We will release Tortoise-
Fuzz with source code.
• We evaluated TortoiseFuzz on 30 real-world programs
and compared it with 4 greybox fuzzers and 2 hybrid
fuzzers. As a greybox fuzzer, TortoiseFuzz outperformed
all the 4 greybox fuzzers and 1 hybrid fuzzers. Tortoise-
Fuzz achieved a comparable result to the other hybrid
fuzzer, QSYM, yet only spent
2% of the memory
resource costed by QSYM. TortoiseFuzz also found 20
zero-day vulnerabilities, with 15 conﬁrmed with CVE
IDs.
II. BACKGROUND
In this section, we present the background of coverage-
guided fuzzing techniques. We ﬁrst introduce the high-level
design of coverage-guided fuzzing, and then explain the details
of input prioritization and input mutation in fuzzing.
A. Coverage-guided Fuzzing
Fuzzing is an automatic program testing technique for gen-
erating and testing inputs to ﬁnd software vulnerabilities [38].
It is ﬂexible and easy to apply to different programs, as it
does not require the understanding of programs, nor manual
generation of testing cases.
At a high level, coverage-guided fuzzing takes an initial
input (seed) and a target program as input, and produces inputs
triggering program error as outputs. It works in a loop, where
it repeats the process of selecting an input, running the target
program with the input, and generating new inputs based on
the current input and its running result. In this loop, coverage
is used as the fundamental metric to select inputs, which is
the reason why such techniques are called coverage-guided
fuzzing.
Figure 1 shows the architecture of AFL [60], a reputable
coverage-guided fuzzer based on which many other fuzzers
2
   Fork-ServerFuzz LoopApplicationProgramInstancesCasesBitmapTest Case SelectionInstrumentNext CaseCase MutationExecution & MonitorCrash Report    QueueIsFavor are developed. AFL ﬁrst reads all the initial seeds and moves
them to a testcase queue ( 1 ), and then gets a sample
from the queue ( 2 ). For each sample, AFL mutates it with
different strategies ( 3 ) and sends the mutated samples to a
forked server where the testing program will be executed with
every mutated sample ( 4 ). During the execution, the fuzzer
collects coverage information and saves the information in
a global data structure. AFL uses edge coverage, which is
represented by a concatenation of the unique IDs for source
and destination basic blocks, and the global data structure is a
bitmap ( 5 ). If the testing program crashes, the fuzzer marks
and reports it as a proof of concept of a vulnerability ( 6 ).
If the sample is interesting under the metrics, the fuzzer puts
it into the queue and labels it as “favored" if it satisﬁes the
condition of being favored ( 7 ).
B.
Input Prioritization
Input prioritization is to select inputs for future mutation
and fuzzing. Coverage-guided fuzzers leverage the coverage
information associated with the executions to select inputs.
Different fuzzers apply different criteria for testing coverage,
including block coverage, edge coverage, and path coverage.
Comparing to block coverage, edge coverage is more delicate
and sensitive as it takes into account the transition between
blocks. It is also more scalable than path coverage as it avoids
path explosion.
AFL and its descendants use edge coverage for input prior-
itization. In particular, AFL’s input prioritization is composed
of two parts: input ﬁltering (step 7 in Figure 1) and queue
culling (step 1 in Figure 1). Input ﬁltering is to ﬁlter out
inputs that are not “interesting”, which is represented by edge
coverage and hit counts. Queue culling is to rank the saved
inputs for future mutation and fuzzing. Queue culling does
not discard yet re-organizes inputs. The inputs with lower
ranks will have less chance to be selected for fuzzing. Input
ﬁltering happens along with each input execution. Queue
culling, on the other hand, happens after a certain number
of input executions which is controlled by mutation energy.
Input Filtering
1)
AFL keeps a new input if the input satisﬁes either of the
following conditions:
• The new input produces new edges between basic blocks.
• The hit count of an existing edge achieves a new scale.
Both conditions require the representation of edge. To bal-
ance between effectiveness and efﬁciency, AFL represents an
edge of two basic blocks by combining the IDs of the source
and destination basic blocks by shift and xor operations.
cur_location = ;
bitmap[cur_location ⊕ prev_location]++;
prev_location = cur_location » 1;
For each edge, AFL records whether it is visited, as well
as the times of visit for each previous execution. AFL deﬁnes
multiple ranges for the times of visit (i.e., bucketing). Once
the times of visit of the current input achieves a new range,
AFL will update the record and keep the input.
3
The data structure for such record is a hash map, and
thus is vulnerable for the hash collision. CollAFL [18] points
out a new scheme that mitigates the hash collision issue,
which is complementary to our proposed approach for input
prioritization.
2) Queue Culling
The goal of queue culling is to concise the inputs while
maintaining the same amount of edge coverage. Inputs that
remained from the input ﬁltering process may be repetitive in
terms of edge coverage. In this process, AFL selects a subset
of inputs that are more efﬁcient than other inputs while still
cover all edges that are already visited by all inputs.
Speciﬁcally, AFL prefers inputs with less size and less
execution latency. To this end, AFL will ﬁrst mark all edges
as not covered. In the next, AFL iteratively selects an edge
that is not covered, chooses the input that covers the edge and
meanwhile has the smallest size and execution latency (which
is represented as a score proportional to these two elements),
and marks all edges that the input visits as covered. AFL
repeats this process until all edges are marked as covered.
Note that in AFL’s implementation, ﬁnding the best input
for each edge occurs in input ﬁltering rather than in queue
culling. AFL uses a map top-rate with edges as keys and
inputs as values to maintain the best input for each edge. In
the process of input ﬁltering, if AFL decides to keep an input,
it will calculate the score proportional to size and execution
time, and update the top-rate. For each edge along with the
input’s execution path, if its associated input in top-rate is
not as good as the current input in terms of size and execution
time, AFL will replace the value of the edge with the current
input. This is just for ease of implementation: in this way,
AFL does not need a separate data structure to store the kept
inputs in the current energy cycle with their size and latency.
For the details of the algorithm, please refer to Algorithm 1
in Section IV.
3) Advanced Input Prioritization Approaches
Edge coverage, although well balances between code cov-
erage and path coverage, is insufﬁcient for input prioritization
because it does not consider the ﬁner-grained context. Under
such circumstances, previous work proposes to include more
information to coverage representation. Angora [12] proposes
to add a calling stack, and AFL-Sensitive [53] presents mul-
tiple additional information such as memory access address
(memory-access-aware branch coverage) and n-basic block
execution path (n-gram branch coverage).
This advancement improves typical edge coverage to be
ﬁner-grained, but it still suffers from the problem that inputs
may fall into a “cold” part of a program which is less likely
to have memory corruption vulnerabilities yet contributes to
new coverage. For example, error-handling codes typically
do not contain vulnerabilities, and thus fuzzer should avoid
to spend overdue efforts in fuzzing around error-handling
code. VUzzer [43] de-prioritizes the inputs that lead to error
handling codes or frequent paths. However, it requires extra
heavyweight work to identify error-handling codes, which
makes fuzzing less efﬁcient.
CollAFL [18] proposes new metrics that are directly
related to the entire execution path rather than single or
a couple of edges. Instead of queue culling,
takes the
total number of instructions with memory access as metrics
for input prioritization. However, CollAFL cannot guarantee
that the prioritized inputs cover all the visited edges. As a
consequence, it may fall into a code snippet that involves
intensive memory operations yet is not vulnerable, e.g., a loop
with a string assignment.
it
LEOPARD [15] keeps queue culling yet add an additional
step, prioritizing the selected inputs from queue culling by
a function-level coverage metrics, rather than choosing ran-
domly in AFL. The approach is able to cover all visited edge
in each fuzzing loop, but it requires to preprocess the targeting
programs for function complexity analysis and thus brings
performance overhead.
C.
Input Mutation and Energy Assignment
Generally, input mutation can also be viewed as input
prioritization: if we see the input space as all the combinations
of bytes, then input mutation prioritizes a subset of inputs
from the input space by mutation. Previous work design
comprehensive mutation strategies [12, 26, 31, 58] and optimal
mutation scheduling approaches [36]. These input mutation
approaches are all complementary to our proposed input
prioritization scheme.
energy
as
AFLFast
[7], AFLGo [6], FairFuzz [31] also prioritizes
inputs by deciding the number of children inputs mutated
from a father input. AFLFast [7] assigns more energy to
the seeds with low frequency based on the Markov chain
model of transition probability. While AFLGo [6] becomes
a directed fuzzer, which allocates more energy on targeted
vulnerable code. FairFuzz [31] marks branches that are hit
fewer times than a pre-deﬁned rarity-cutoff value as rare
branches, and optimizes the distribution of fuzzing energy to
produce inputs to hit a given rare branch.
assignment
Similarly,
approaches
such
D. Anti-Fuzzing Techniques
Current anti-fuzzing techniques [23, 28] defeat coverage-
guided fuzzers by two design deﬁciencies: 1) most coverage-
guided fuzzers do not differentiate the coverage of different
edges, and 2) hybrid fuzzers use heavyweight taint analysis or
symbolic execution. Anti-fuzzing techniques deceive fuzzers
by inserting fake paths, adding a delay in error-handling code,
and obfuscating codes to slow down dynamic analyses.
Current anti-fuzzing techniques make coverage-guided
fuzzers much less effective in vulnerability discovery, causing
85%+ performance decrease in exploring paths. Unfortunately,
many of the presented edge-coverage-based fuzzers [12, 15,
43, 53, 60] suffer from the current anti-fuzzing techniques.
VUzzer is affected due to the use of concolic execution.
LEOPARD, which considers function-level code complexity
as a metric for input prioritization,
is vulnerable to fake
paths insertion. As path insertion increases the complexity of
the function with inserted paths, LEOPARD will mistakenly
prioritize the inputs that visit these functions while does not
prioritize the inputs that skip the inserted paths in the function.
As a consequence, inputs that execute the inserted path will
be more likely to be prioritized.
4
AFL, Angora, and AFL-Sensitive are also affected by fake
paths because fake paths contribute to more code coverage.
More generally, any approach that adds more information to
edge representation yet still treat edge equally will be affected
by anti-fuzzing. Essentially, this is because that edge coverage
is treated equally despite the fact that edges have different
likelihoods in leading to vulnerabilities.
III. COVERAGE ACCOUNTING
Prior coverage-guided fuzzers [4, 6, 7, 12, 33, 45, 47, 56,
60, 61] are limited as they treat all blocks and edges equally.
As a result, these tools may waste time in exploring the codes
that are less likely to be vulnerable, and thus are inefﬁcient
in ﬁnding vulnerabilities. Even worse, prior work can be
undermined by current anti-fuzzing techniques [23, 28] which
exploit the design deﬁciency in current coverage measurement.
To mitigate this issue, we propose coverage accounting,
a new approach to measure edges for input prioritization.
Coverage accounting needs to meet two requirements. First,
coverage accounting should be lightweighted. One purpose
of coverage accounting is to shorten the time to ﬁnd a
vulnerability by prioritizing inputs that are more likely to
trigger vulnerabilities. If coverage accounting takes long, it
will not be able to shorten the time.
Second, coverage accounting should not rely on taint
analysis or symbolic execution. This is because that coverage
accounting needs to defend against anti-fuzzing. Since current
anti-fuzzing techniques are capable of defeating taint analysis
and symbolic execution, we should avoid using these two
analyses in coverage accounting.
Based on the intuition that memory corruption vulner-
abilities are directly related to memory access operations,
we design coverage accounting for memory errors as the
measurement of an edge in terms of future memory access
operations. Furthermore, inspired by HOTracer [27], which
treats memory access operations at different levels, we present
the latest and future memory access operations from three
granularity: function calls, loops, and basic blocks.
Our design is different from known memory access-related
measurements. CollAFL [18] counts the total number of
memory access operations throughout
the execution path,
which implies the history memory access operations. Wang
et al. [53] apply the address rather than the count of memory
access. Type-aware fuzzers such as Angora [12], TIFF [26],
and ProFuzzer [58] identify inputs that associated to speciﬁc
memory operations and mutate towards targeted programs or