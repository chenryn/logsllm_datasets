physical world? In the above example, do Alice and
Bob see the green box in the same physical location
or in different physical locations? Are Alice and Bob
themselves in the same physical location, and what hap-
pens when their co-location status changes?
• Private content
in a shared physical world (Sec-
tion 4.3): How should the sharing module handle or
help shape users’ expectations of private AR content,
such as Alice’s blue box, when they interact in a shared
physical world?
Outbound
sharing controls
What and
with whom Permission management
Where
Location coupling (§4.2)
How much
Ghosting (§4.3)
Inbound
sharing controls
Two-party sharing consent
Personal space (§4.4)
Clutter management
Table 1: Summary of the components of our design for controlling
the outbound and inbound sharing of AR content.
• Ownership of physical-world spaces (Section 4.4):
How can a sharing module help apps respect people’s
existing ownership of physical spaces? For example,
users may wish to control AR content that they or oth-
ers see in front of their homes or on their own bodies.
Effective solutions to these challenges must integrate with
the system design components that have more direct ana-
logues in current technologies. In particular, we incorporate
the following established control structures into our design:
• Permission management. We leverage classic access
control work [30] to track and enforce per-object and
per-user permissions. Although we aim to be compat-
ible with whichever access control model a particular
app chooses to layer atop our module — e.g., a model
akin to Google Docs for the Multi-Team Whiteboards
case study — we note that this alone is not enough to
support the 3D experience of AR, and that the above
key design challenges must also be addressed.
• Two-party sharing consent.
Some existing sharing
models require that both the sharer and the receiver of
digital content authorize a sharing event before its com-
pletion (e.g., Google Drive, Apple AirDrop). We use
this principle in our design, with one twist:
to help
developers avoid decision fatigue in apps with high-
volume content sharing, we allow the app to authorize
a sharing event without the user in the loop. For in-
stance, an app might automatically authorize content
under some contexts but not others [70], use a notiﬁ-
cation UI that minimally disrupts the user’s workﬂow,
or allow users to always trust content from a speciﬁc
other user. We advise developers to be conscious of ha-
bituation and interruption in their app designs.
• Clutter management. Our design supports temporarily
or permanently removing an object from the user’s ﬁeld
of view, as we discuss further in Section 4.2.
We summarize these aspects of sharing control, both new
and precedented, in Table 1. We categorize the design points
along two axes: (1) where in the above sharing ﬂow the con-
trol occurs (outbound on the sharer’s end, or inbound on
the receiver’s end), and (2) what type of control is enforced
(what object is shared and with whom, where a shared object
can be, or how much information from that object is shared).
4.2 Physical World Integration
The sharing ﬂow in Section 4.1 demonstrates the basic build-
ing blocks of a sharing module, with view and edit permis-
USENIX Association
28th USENIX Security Symposium    147
sions for users at the granularity of AR objects (e.g., a virtual
cat or virtual browser window). We now explore how these
notions become signiﬁcantly more complicated when shared
AR objects are integrated into the physical world.
Location-coupled and -decoupled sharing. Recall from
Section 2 that we aim to support both physically co-located
sharing (i.e., two users in the same physical place and seeing
the same AR objects in the same physical locations) and re-
mote sharing (i.e., two users physically separated but seeing
the same AR objects in their own physical spaces).
Accordingly, our design supports two notions for how
an AR object can be shared with respect to the physical
world: (1) Location-coupled objects, which all users see in
the same physical location, and (2) Location-decoupled ob-
jects, where all users see the same object but in different
physical locations. In the coupled case, if one user moves
the object, other users also see the object’s location update;
in the decoupled case, the two instantiations of the object can
be moved independently.
We intend for these notions not to be mutually exclusive
for an object but rather to apply between sets of users. For
example, an AR object (say, a virtual whiteboard) may be
shared (1) in a location-coupled way between Alice and Bob
co-located in New York, and (2) in a location-coupled way
between Guanyou and Huijia in Beijing, and simultaneously
(3) in a location-decoupled way between the two groups.
Handling people moving around the physical world. A
challenge for location coupling and decoupling of shared
objects arises when we consider that users’ co-location can
change as they move around the physical world.
For example, suppose that Alice and Bob share a location-
coupled AR object — say, a whiteboard — both seeing it in
the same physical location. Alice may also share it in a
location-decoupled way with collaborator Carol working in
another room — i.e., Carol will see an instantiation of the
whiteboard in her own physical space. Initially, this appears
to meet our goals: all users see the whiteboard in their own
physical space in the same location as other co-located users.
What happens, however, when Carol moves into the same
physical space as Alice and Bob? Since the whiteboard is
shared among all of them, they will likely assume that all
three of them can now see the same AR whiteboard object
on the same wall [35]. This is not the case, however: Alice
and Bob see one instantiation of the whiteboard, and Carol
sees a separate instantiation in a slightly different location.
To resolve this potential inconsistency, our design keeps
track of all copies of a shared object, allowing the app to
show all of these copies to all users. Thus, when Carol joins
Alice and Bob in the same room, all users see both versions
of the whiteboard. All users then share the same view of the
augmented physical world. Note that this location informa-
tion may have privacy implications, though none in scope for
this work; we discuss this point further in Section 7.
Moreover, since users’ co-location may change over time,
their desired location-(de)coupling of objects may change
over time too. For example, in the above scenario, Alice and
Bob may wish to merge their whiteboard object with Carol’s
instantiation, so that all three indeed see the same, single
whiteboard object in the same place. Conversely, users may
wish to collaborate on a location-coupled object while they
are physically co-located but to both take their work with
them when they physically separate. Thus, we also provide
mechanisms to merge two location-decoupled instances into
a location-coupled object and to separate a location-coupled
object into two location-decoupled instances.
Another way to think about shared AR objects, then, is
that there is one conceptual object and potentially multiple
views of it. Each user sees a view in the same location as
do all other users, and users in different physical spaces will
see different views. If a user is in the same space as multiple
views, that user will see all present views. The object’s views
may be manipulated separately in space; a single view may
be split into two, or two may be merged into one, but the
underlying object that all views represent remains the same.
Implications of location coupling for object deletion. A
shared object’s location coupling or decoupling has design
implications for other features as well. For example, our de-
sign lets users delete AR content that they have created; it
is not clear, however, that this decision should propagate to
other users with whom the object has been shared, and loca-
tion coupling or decoupling affects how deletion is handled.
We design the module to support three cases, which can
be chosen by the app developer as appropriate:
1. Case 1: Local Deletion: Affect user’s local view of ob-
ject only. This option allows Alice to delete her object
without affecting other users. If, in Multi-Team White-
boards, Alice and Bob share a whiteboard in a location-
coupled manner, Alice can delete her instance of the
object while Bob keeps working.
2. Case 2: Global Location-Coupled Deletion: Affect all
users’ views of location-coupled object. Here, a deleted
object is also deleted for all other users with whom that
object was shared in a location-coupled way. That is,
when Alice deletes her document, Bob also sees that
document disappear. However, if Alice has also shared
the document in a location-decoupled way with remote
collaborator Carol, this option allows Alice to delete her
and Bob’s location-coupled instantiation without affect-
ing Carol’s remote, location-decoupled instantiation.
3. Case 3: Global, Location-Independent Deletion: Affect
all users’ view of object, independent of location cou-
pling. In this case, all instantiations of the object for
all users are deleted. Continuing the previous example,
Alice, Bob, and Carol will all see the object deleted.
Which of these cases is most appropriate depends on the
semantics of an app and each use case within that app.
148    28th USENIX Security Symposium
USENIX Association
Location coupling and decoupling have other design and
implementation implications as well. For instance, hiding
content with which the user does not currently wish to inter-
act requires considering the same set of options as deletion.
4.3 Private Content in Shared Physical World
As raised in the Multi-Team Whiteboards case study in Sec-
tion 2 and in prior work [35], the fact that AR supports per-
user private content can have beneﬁts, but it can also fail to
provide a signal about the use of physical space (e.g., lead-
ing to one user inadvertently standing in front of another’s
virtual content, or causing social tension due to one user not
knowing what another user is doing).
Thus, in this section we propose a design that allows users
to socially signal to other AR users that they are busy in-
teracting with private content without sharing the details of
their activities. Further, we aim for this design to align with
users’ intuitions about a shared physical world.
Strawman designs. Consider two incomplete solutions:
Status quo. A solution with no further intervention would
cause private content to be completely invisible to other AR
users. A user interacting with private content thus appears to
others as if the user were staring off into and manipulating an
undeﬁned region of empty space, giving no cue to other users
about how far away the object is if they want to walk around
it as well as no sense for what the user might be doing.
Occlusion by virtual barrier. Meta’s developer guidelines
recommend that sensitive content be shared publicly but oc-
cluded by a virtual barrier such as a curtain [40]. Although
this does provide a shared-world physical intuition and social
cue, it is not a robust privacy-preserving mechanism. Con-
sider a user who places a virtual curtain around sensitive con-
tent so that the content is visible only from the user’s point
of view. A curious other user can surreptitiously look over
the user’s shoulder and observe the sensitive content, similar
to shoulder-surﬁng with current mobile devices [56, 64].
Our approach: “Ghosts”. We propose an alternate design
that achieves our goal while avoiding the above drawbacks.
The key idea is to allow users to share that they are inter-
acting with an AR object, without sharing the details of that
object. This idea is analogous to how a user interacting with
a smartphone implicitly signals to bystanders that they are
engaged in another activity located in the palm of their hand,
without the contents of that activity being directly revealed,
or to how users may share free/busy information about spe-
ciﬁc time blocks on their calendar to avoid double-booking
without sharing the details of their calendar events.
To support this interaction, we introduce a new partial-
visibility state for shared AR objects that we call ghosting.
Ghost objects show only their location in space, not the sen-
sitive content they contain, no matter at which angle they are
viewed. As such, unlike the above smartphone analogy, they
are not susceptible to shoulder-surﬁng. Furthermore, a user
with whom a ghost object is shared receives from the sharer
only the data needed to instantiate the ghost, rather than the
full object data; this further insulates the private content.
Ghost shape granularity. For non-planar objects, we en-
counter the following question: How does the sharing mod-
ule determine the appropriate level of granularity to expose
in the ghosted object, given that object shapes may contain
app-speciﬁc information content?
For instance, in Community Art, the ghost of a sculpture
that is private during its development should not mimic the
original sculpture’s shape too closely. However, a shape
with too coarse of a granularity — e.g., a large ﬁxed-size
cube regardless of the sculpture — no longer gives mean-
ingful physical-world information to nearby users: e.g., by
marking an unreasonably large physical space as occupied.
To balance this dilemma,we allow app developers to spec-
ify what the ghosted view of an object should look like.
This approach allows for non-planar objects to assume an
obscured shape appropriate for the app-speciﬁc information
they carry. For instance, in the Community Art case study,
a sculpture that is private during its development might be
displayed to others as an appropriately sized cylinder.
4.4 Respecting Ownership of Physical Spaces
Finally, we turn to the question of how the sharing control
module can help apps respect people’s existing ownership
of physical-world space. We refer to both personal space
(near one’s body) and static owned space (e.g., one’s home)
as owned physical space in this section.
Helping users protect their owned physical spaces requires
several components: (1) Determining who owns a region in
space, (2) Determining what the boundaries of that region
are, and (3) Enforcing some kind of policy on shared AR
objects in that region.
We defer to future work (1), how to determine who owns
a region in space. This in itself is complex; for instance,
Google has analyzed abuse of location ownership in its Maps
app [26], and prior work has considered physical world
ownership for restricting continuous sensing apps (including
AR) [54]. Accounting for different types of space ownership
is also nontrivial: in particular, we identify (a) ﬁxed-location
physical spaces (e.g., a house, a room, a storefront, or a pub-
lic park), (b) person-relative spaces (e.g., within 5 feet of a
user), and (c) object-relative spaces (e.g., within 35 feet of a
virtual art object). A complete solution to this issue should
also consider non-AR users, and we offer the following sug-
gestion as a starting point for future work: locally on the AR
user’s device, employ computer vision techniques to identify
the spatial positions of bystanders visible by the AR user,
estimate the rough pose for each bystander, and use that in-
formation to mark bystanders’ forms as protected regions of
space (e.g., using techniques from [2, 39]). However, we do
not pursue this topic further in this work, since it is a com-
plex area of investigation in its own right; instead, we assume
a prior deﬁnition of owned physical space, and we focus on
USENIX Association
28th USENIX Security Symposium    149
the challenges of enforcing that space.
For (2), we observe that deﬁning the boundaries of a pro-
tected region of physical space — e.g., around a person or
house — is not a simple binary determination. A user might
perceive an object two feet away to be too close, for in-
stance, but may consider an object nine inches away to be
even more so; this deﬁnition may also vary across different
users [22]. Building on this observation, our solution is to
model owned physical space as a continuum, where viola-
tions become more severe — and thus policies could become
stricter — as virtual content approaches the protected region.
The key question, then, is (3): what should an app do when
one user’s shared AR content overlaps another user’s per-
sonal physical space, or a physical region (e.g., a house) that
another user owns?
Policies for AR content violating owned spaces. To an-
swer this question, we propose that the sharing control mod-
ule can provide a variety of policies that an app’s developer
could choose to apply in such a case. These policies can be
enforced either such that the result of enforcement is only
visible to the user whose personal space is in question, or
such that all users with access to the shared object see the
result of enforcement. App developers may choose which
policies to enable based on the needs of the app.
A simple, binary policy might make objects invisible in-
side a ﬁxed radius: for instance, deﬁne a three-foot radius
around a person within which AR content should not be vis-
ible (at least to that user). Such a policy can be exploited
by surrounding the person with AR content just outside the
boundary; thus, there is a tension between a large radius to
minimize the effects of such an attack and a small radius to
enable legitimate functionality.
To help balance this tension, and to take advantage of the
continuum in the boundary described above, our design pro-
vides a transparency gradient policy, by which the module
makes shared objects more transparent the closer the objects