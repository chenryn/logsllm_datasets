title:Detecting and characterizing social spam campaigns
author:Hongyu Gao and
Jun Hu and
Christo Wilson and
Zhichun Li and
Yan Chen and
Ben Y. Zhao
Detecting and Characterizing Social Spam Campaigns
Hongyu Gao
Northwestern University
Evanston, IL, USA
Jun Hu
HUST
Wuhan, China
PI:EMAIL
PI:EMAIL
Zhichun Li
Yan Chen
Northwestern University
Northwestern University
Evanston, IL, USA
Evanston, IL, USA
PI:EMAIL
PI:EMAIL
Christo Wilson
U. C. Santa Barbara
Santa Barbara, CA USA
PI:EMAIL
Ben Y. Zhao
U. C. Santa Barbara
Santa Barbara, CA USA
PI:EMAIL
ABSTRACT
Online social networks (OSNs) are exceptionally useful collab-
oration and communication tools for millions of users and their
friends. Unfortunately, in the wrong hands, they are also extremely
effective tools for executing spam campaigns and spreading mal-
ware.
In this poster, we present an initial study to detect and quanti-
tatively analyze the coordinated spam campaigns on online social
networks in the wild. Our system detected about 200K malicious
wall posts with embedded URLs, traced back to roughly 57K ac-
counts. We ﬁnd that more than 70% of all malicious wall posts are
advertising phishing sites.
Categories and Subject Descriptors
J.4 [Computer Applications]: Social and behavioral sciences
General Terms
Human Factors, Measurement, Security
Keywords
Online social networks, Spam, Spam Campaigns
1.
INTRODUCTION
Online social networks (OSNs) are exceptionally useful collabo-
ration and communication tools for millions of Internet users. Un-
fortunately, recent evidence shows that these trusted communities
could become highly effective mechanisms for spreading malware
and phishing attacks. Popular OSNs have recently become the
target of phishing attacks launched from large botnets [2, 3], and
account credentials are already being sold online in underground
forums [5]. Using compromised or fake accounts, attackers can
turn the trusted OSN environment against its users by masquerad-
ing phishing attempts and spam messages as communication from
friends and family members.
In this project, we present the ﬁrst attempt to detect and analyze
the prevalence of malicious users and spread of malicious content
on an OSN. We carry out the study on Facebook, the most popular
OSN in the world with over 400 million users. We use the crawled
Facebook data between April and June of 2009. We choose 8 re-
gional networks of various sizes (from over 1.6 million users down
Copyright is held by the author/owner(s).
CCS’10, October 4–8, 2010, Chicago, Illinois, USA.
ACM 978-1-4503-0244-9/10/10.
to ∼14K users) as targets for data collection. For each crawled user
we recorded the proﬁle, friend list, and interaction records going
back to January 1, 2008. Interaction records include the complete
history of status updates and wall posts received by each crawled
user within the given time frame. Overall, our complete dataset in-
cludes information on over 3.5 million users with more than 187
million wall messages.
We employ the correlation between wall messages, either by the
textual content or the contained web address, to identify the spread
of potentially malicious content. Our results are conﬁrmed by a
number of validation mechanisms. Our subsequent analysis pro-
vides insights into the operation of malicious accounts, and has sig-
niﬁcant implications on the design of future mechanisms to detect
malicious behavior.
2. MALICIOUS CAMPAIGN DETECTION
AND VALIDATION
2.1 Design Overview
An overview of the system workﬂow is shown in Figure 1.
The design of our system is guided by intuition about techniques
used in spam campaigns. From the recent work [4] and our ob-
servation of large number of malicious posts that look similar, we
infer that spam wall posts are generated using templates, and posts
generated from the same template should contain only small differ-
ences. Consequently, we propose to group wall posts with “simi-
lar" textual content together. Second, we recognize that the attempt
to direct the viewers towards a single destination URL must come
from the same spam campaign. Thus we will group together all
wall posts that include the same destination URL, including those
that have been hidden through URL obfuscation (e.g. www dot
hack dot com).
We model all wall posts as nodes in a large graph, and build
edges when two posts are connected by either similar textual con-
tent or same destination URL. During runtime, the system com-
pares the destination URL before computing the approaximate tex-
tual similarity between descriptions, since the former is less ex-
pensive to compute. Each of the resulting connected subgraphs
could represent messages within the same spam campaign. Iden-
tifying connected subgraphs is solved by iteratively choosing arbi-
trary nodes and identifying its transitive closure as a cluster. We
summarize the implementation in Algorithm 1. We omit the detail
of breadth-ﬁrst search (BFS) due to the space limitation.
After identifying distinct subgraphs, we use threshold ﬁlters on:
a) the number of users sending wall posts in the subgraph and b) the
681LOL
Hi!
Visit evil.com
How r u?
1) Crawl
Wall Posts
How r u?
Hi!
LOL
...
...
Visit evil.com
...
2) Filter Posts
without URLs
5) Locate Distributed
Blog here
Visit evil.com
Pills @ pharma.cn
...
...
Funny: video.com/
...
3) Link based on
text and URL
Malicious Users
and Posts
and Bursty
Clusters
4) Cluster
Figure 1: The system design, starting with raw data collection and ending with accurate classiﬁcation of malicious posts and the
corresponding users.
Algorithm 1 PostSimilarityGraphClustering(G )
traversed ← ∅
clusters ← ∅
Foreach v ∈ V
If v ∈ traversed
continue
EndIf
one_cluster ← BF S(v)
traversed ← traversed ∪ one_cluster
clusters ← clusters ∪ {one_cluster}
EndForeach
return clusters
time interval between consecutive wall posts in the subgraphtime to
distinguish potentially malicious campaigns.
2.2 Detection Result
The clustering approach produces 1,402,028 clusters. As ex-
pected, there are a small number of very large clusters as well as a
large number of very small clusters.
The chosen threshold, which is 5 as the minimum number of
users that have made wall posts in the cluster and 5400 seconds
(1.5 hours) as the maximum median interval between the timestamp
of two consecutive wall posts, results in 297 clusters classiﬁed as
malicious. The total number of wall posts contained in these 297
clusters is 212,863.
2.3 Experimental Validation
We apply a stringent set of heuristic tests to each URL that is
contained in the detected malicious posts. Whether the URL is ma-
licious determines whether the wall posts containing it is malicious.
6 steps are adopted. Each step can conﬁrm the malice of a subset
of the detection result. For any detection result that cannot be ver-
iﬁed as maliciouis, we assume it to be benign, i.e. , false positive.
These steps and the corresponding validation results are shown in
Table 1.
Overall, we observe that our detection methodology results in a
very low number of false positives. One additional positive fea-
ture of our detection methodology is that it is fully automated and
signiﬁcantly less costly in terms of time than our validation pro-
cess. As it returns results of roughly equal quality, we believe that
our detection methodology represents a step forward for automated
detection of spamming activity on OSNs.
Reason for Classiﬁcation
Obfuscated URL
Blacklisted
Redirects to a blacklisted URL
Contains spam keywords
Groups with other malicious URLs
Manual conﬁrmation
Malicious, True Positives
Benign, False Positives
# of URLs
1003 (6.3%)
4485 (28.0%)
4473 (27.9%)
196 (1.2%)
5300 (32.5%)
27 (<0.1%)
# of Wall Posts
45655 (21.4%)
55957 (26.3%)
29365 (13.8%)
19018 (8.9%)
33407 (15.7%)
16380 (7.7%)
15484 (96.1%) 199782 (93.9%)
616 (3.9%)
13081 (6.1%)
Table 1: Validation results. Each row provides the number of
conﬁrmed malicious URLs and wall posts in a given validation
step. All URLs that remain unvalidated after all steps are as-
sumed to be benign.
3. CAMPAIGN ANALYSIS
We use “campaign" to refer to a set of malicious posts of a cer-
tain type, e.g., pharmaceutical sales. We use the description part
of the wall post to distinguish campaigns, without considering the
destination URL.
3.1 Campaign identiﬁcation
We iteratively classify the wall posts by identifying strings char-
acteristic to each campaign with the aid of human knowledge. Ma-
licious posts that cannot be apparently grouped into any campaigns
form an additional “other" group. We present all the identiﬁed cam-
paigns in addition with a summary of their description in Table 2.
We further associate the campaigns with the clusters produced
by the detection mechanism. For most campaigns, their contained
clusters form mutually exclusive groups, except for only two in-
stances. More speciﬁcally, the “crush" campaign shares one cluster
with the “love-calc" campaign and the “PS3" campaign, respec-
tively. These campaigns shares some common embedded URLs. It
suggests that there is likely a single authority controlling all these
three campaigns, who is using a set of very different templates to
generate wall posts.
3.2 Attack categorization
In this subsection, we study the purpose of the attacker to launch
the attack. We determine the goal of the attackers based on cam-
paigns. The attacker’s goal is apparent for some campaigns, e.g.
product selling. For the other campaigns, we rely on McAfee
SiteAdvisor’s [1] user review summary of URLs within the cam-
682Campaign
Crush
Iphone
Blog
PS3
Webcam
Luxury
Ringtone
Pharma
Narcotics
Love-calc
Macy-gift
Fake-video A cool video is provided
Pic-misuse Your photo is misused online
114
21
23
20
11
5
4
Summarized wall post description Cluster # Post #
51082
Someone likes you
31329
Invitation for free ringtones
Pharmaceutical products like viagra
17614
16668
Sell drugs
16354
Test the love compatibility
14092
Invitation for free macy’s giftcard
11464
10683
6317
3948
3556
2707
2620
2125
1440
1131
1127
981
502
4042
Invitation for a free Playstation 3
Video chatting via web camera
Get cheap luxury product
Invitation for a free iphone
Someone writes you in the blog
Visit a (fake) facebook proﬁle
1
4
2
1
1
4
1
2
2
4
1
5
64
Fake-fbid
Fake-news Visit to read news
Is-that-you
Ipod-touch
Denigration Someone is disparaging you
Some webpage is about you
Invitation for a free itouch
Online-job Work online and earn big money
Other
No apparent pattern
Table 2: Campaigns encountered in the study. The attackers
use the description to entice the receiver to visit the contained
malicious URL. Cluster # shows how many clusters in the de-
tection result are involved in each campaign. Post # represents
the number of malicious posts in each campaign.
s
t
s
o
P
l
l
a
W
f
o
#
150K
120K
90K
60K
30K
0K
i
P
h
s
h
n
g
i
l
M
a
w
a
r
e
N
a
r
c
o
t
i
c
s
P
h
a
r
m
a
L
u
x
u
r
y
O
t
h
e
r
Figure 2: The number of instances in each attack category. At-
tack instances with multiple malicious intent are counted mul-
tiple times.
paign. We identify ﬁve different attacker’s goals and present them
in Figure 2.
The total size of all the categories exceeds the total number of
malicious posts, since some malicious posts have multiple goals
and are counted under all suitable categories. Phishing is the most
common attack (∼70.3%). We encountered two different types of
phishing attacks in the study. In the ﬁrst case the attackers target at
conﬁdential information. In the second case, the attackers directly
targets at money. Malware propagation is the second most common
goal (∼35.1%). Product selling as a whole is still one of the main
goals for the attackers to spam the OSNs (∼17.6%).
3.3 Temporal behaviors
We study the temporal features of the identiﬁed campaigns and
illustrate the result in Figure ??. The horizontal direction represents
the timeline during the period of the data collection. The spam
campaigns are represented by different strips. A short, thin vertical
line within the strip corresponds to one malicious posts within the
campaign. A block in the strip reﬂects a burst in the campaign, as it
is composed of densely distributed vertical lines. The ﬁgure clearly
shows the bursty nature of all the campaigns. The malicious posts
within each campaign are densely distributed in a few relatively
short time periods, although the entire campaign may span a much
longer time period, like the “crush" campaign.
4. CONCLUSION
In this poster, we describe our work on detecting and characteriz-
ing spam campaigns performed using asynchronous wall messages
on the Facebook social networks. We use automated techniques to
group together wall posts that show strong similarities in advertised
URL destination or text description. We identify about 200K mali-
cious wall posts attributable to 57K malicious accounts. Over 70%
of these attacks are phishing attacks. More importantly, our work
demonstrates that automated detection techniques can be success-
fully used to detect online social spam.
5. REFERENCES
[1] Mcafee siteadvisor. http://www.siteadvisor.com/.
[2] Users of social networking websites face malware and
phishing attacks. Symantec.com Blog.
[3] Zeus botnet targets facebook.
http://blog.appriver.com/2009/10/zeus-botnet-targets-
facebook.html.
[4] KREIBICH, C., KANICH, C., LEVCHENKO, K., ENRIGHT,
B., VOELKER, G., PAXSON, V., AND SAVAGE, S.
Spamcraft: An inside look at spam campaign orchestration. In
Proc. of LEET (2009).
[5] Verisign: 1.5m facebook accounts for sale in web forum. PC
Magazine, April 2010.
683