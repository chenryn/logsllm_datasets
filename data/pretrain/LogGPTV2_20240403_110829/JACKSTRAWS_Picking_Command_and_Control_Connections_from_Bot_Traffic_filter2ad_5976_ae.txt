successful in detecting other C&C connections that were
produced by a same set of malware families, but also
in detecting ﬁve related families that were only present
in the test set.
In a sense, this shows that C&C tem-
plates have a similar detection capability as manually-
generated, network-based signatures.
We also wanted to understand the impact of template
generalization compared to previous work that used di-
rectly the mined subgraphs [13]. For this, we used the
graphs mined from the malicious training set as signa-
tures, without any generalization (this is the approach
followed in previous work). Using a sub-isomorphism
test for detection over the 4,262 malicious graphs in the
test set, we found that the detection rate was 66%, 15.6%
lower. This underlines that the novel template generation
process provides signiﬁcant beneﬁts.
Experiment 2: Unknown connections. For the next
experiment, we decided to apply our templates to the
graphs that correspond to unknown network trafﬁc. This
should demonstrate the ability of JACKSTRAWS to detect
novel C&C connections within protocols not covered by
any network-level signature.
When applying our templates to the 98,018 unknown
connections, we found 9,464 matches (9.7%). We manu-
ally examined these connections in more detail to deter-
mine whether the detection results are meaningful. The
analysis showed that our approach is promising; the vast
majority of connections that we analyzed had clear indi-
cations of C&C activity. With the help of the anti-virus
labels, we could identify 193 malware families which
were not covered by the network signatures. The most
prevalent new families were Hotbar (1984), Pakes (871),
Kazy (107), and LdPinch (67). Furthermore, we de-
tected several new variants of known bots that we did
not detect previously because their network ﬁngerprint
had changed and, thus, none of our signatures matched.
Nevertheless, JACKSTRAWS was able to identify these
connections due to matched templates. In addition, the
manual analysis showed a low number of false positives.
In fact, we only found 27 false positives out of the 9,464
matches, all of them being HTTP connections.
When comparing the number of our matches with the
total number of unknown connections, the results may
appear low at ﬁrst glance. However, not all connec-
tions in the unknown set are malicious. In fact, 10,524
connections (10.7%) do not result in any relevant host-
activity at all (the graphs only contain network-relayed
system calls such as send or connect). For an-
other 13,676 graphs (14.0%), the remote server did not
send any data. For more than 7,360 HTTP connec-
tions (7.5%), the server responded with status code 302,
meaning that the requested content had moved. In this
case, we probably cannot see any interesting behavior
to match. In a few hundred cases, we also observed that
the timeout of JACKSTRAWS interrupted the analysis too
early (e.g., the connection downloaded a large ﬁle). In
these cases, we usually miss some of the interesting be-
havior. Thus, almost 30 thousand unknown connections
can be immediately discarded as non-C&C trafﬁc.
Furthermore, the detection results of 9,464 new C&C
connections for JACKSTRAWS need to be compared with
the total number of 16,535 connections that the entire
signature set was able to detect.Our generalized tem-
plates were able to detect almost 60% more connec-
tions than hundreds of hand-crafted signatures. Note
that our C&C templates do not inspect network trafﬁc at
all. Thus, they can, by construction, detect C&C connec-
tions regardless of whether the malware uses encryption
or not, something not possible with network signatures.
4.4 Template Quality
The previous section has shown that our C&C templates
are successful in identifying host-based activity related
to both known and novel network connections. We also
manually examined several templates in more detail to
determine whether they capture activity that a human an-
alyst would consider malicious.
JACKSTRAWS was able to extract different kinds of
templates. A few template examples are shown in Ap-
pendix B. More precisely, out of the 417 templates,
more than a hundred templates represent different forms
of information leakage. The leaked information is origi-
nally collected from dedicated registry keys or from spe-
ciﬁc system calls (e.g., computer name, Windows ver-
sion and identiﬁer, Internet Explorer version, current
system time, volume ID of the hard disk, or processor
information). About ﬁfty templates represent executable
ﬁle downloads or updates of existing ﬁles. Additional
templates include process execution: downloaded data
that is injected into a process and then executed. Five
templates also represent complete download and exe-
cute commands. The remaining templates cover vari-
ous other malicious activities, including registry modi-
ﬁcations ensuring that the sample is started on certain
events (e.g., replacing the default executable ﬁle handler
for Windows Explorer) and for hiding malware activity
(e.g., clearing the MUICache).
We also found 20 “weak” templates (out of 417).
These templates contain a small number of nodes and
do not seem related to any obvious malicious activity.
However, these templates did not trigger any false pos-
itive in the benign test set. This indicates that they still
exhibit enough discriminative power with regards to our
malicious and benign graph sets.
5 Related Work
Given the importance and prevalence of malware, it is
not surprising that there exists a large body of work
on techniques to detect and analyze this class of soft-
ware. The different techniques can be broadly divided
into host-based and network-based approaches, and we
brieﬂy describe the related work in the following.
Host-based detection. Host-based detection techniques
include systems such as traditional anti-virus tools that
examine programs for the presence of known mal-
ware. Other techniques work by monitoring the execu-
tion of a process for behaviors (e.g., patterns of system
calls [12, 28, 32]) that indicate malicious activity. Host-
based approaches have the advantage that they can col-
lect a wealth of detailed information about a program
and its execution. Unfortunately, collecting a lot of in-
formation comes with a price; it incurs a signiﬁcant per-
formance penalty. Thus, detailed but costly monitoring
is typically reserved for malware analysis, while detec-
tion systems, which are deployed on end-user machines,
resort to fast but imprecise techniques [43]. As a result,
current anti-virus products show poor detection rates [4].
A suitable technique to model the host-based activ-
ity of a program is a behavior graph. This approach
has been successfully used in the past [5, 13, 26] and
we also apply this technique. Recently, Fredrikson et
al. introduced an approach to use graph mining on be-
havior graphs in order to distinguish between malicious
and benign programs [13]. Graph mining itself is a well-
known technique [46–48] that we use as a building block
of JACKSTRAWS. Compared to their work, we have an-
other high-level goal: we want to learn which network
connections are related to C&C trafﬁc in an automated
way. Thus we do not only focus on host-level activities,
but also take the network-level view into account and
correlate both. Furthermore, we also cluster the graphs
and perform a generalization step to extract templates
that describe the characteristics of C&C connections.
From a technical point of view, we perform a more ﬁne-
grained analysis by applying taint analysis instead of the
coarse-grained analysis performed by [13].
BOTSWAT [41] analyzes how bots process network
data by analyzing system calls and performing taint
analysis. The system matches the observed behavior
against a set of 18 manually generated behavior patterns.
In contrast, we use mining and machine learning tech-
niques to automatically generate C&C templates. From
a technical point of view, BOTSWAT uses library-call-
level taint analysis and, thus, might miss certain depen-
dencies. In contrast, the data ﬂow analysis support of
JACKSTRAWS enables a more ﬁne grained analysis of
information ﬂow dependency among system calls.
Network-based detection. To complement host-based
systems and to provide an additional layer for defense-
in-depth, researchers proposed network-based detection
techniques [15–18, 45, 49]. Network-based approaches
have the advantage that they can cover a large num-
ber of hosts without requiring these hosts to install any
software. This makes deployment easier and incurs no
performance penalty for end users. On the downside,
network-based techniques have a more limited view
(they can only examine network trafﬁc and encryption
makes detection challenging), and they do not work for
malicious code that does not produce any network trafﬁc
(which is rarely the case for modern malware).
Initially, network-based detectors focused on the ar-
tifacts produced by worms that spread autonomously
through the Internet. Researchers proposed techniques
to automatically generate payload-based signatures that
match the exploits that worms use to compromise remote
hosts [25,27,29,31,39]. With the advent of botnets, mal-
ware authors changed their modus operandi. In fact, bots
rarely propagate by scanning for and exploiting vulnera-
ble machines; instead, they are distributed through drive-
by download exploits [36], spam emails [22], or ﬁle
sharing networks [23]. However, bots do need to com-
municate with a command and control infrastructure.
The reason is that bots need to receive commands and
updates from their controller, and also upload stolen data
and status information. As a result, researchers shifted
their efforts to developing ways that can detect and dis-
rupt malicious trafﬁc between bots and their C&C infras-
tructure. In particular, researchers proposed approaches
to identify (and subsequently block) the IP addresses and
domains that host C&C infrastructures [42], techniques
to generate payload signatures that match C&C connec-
tions [15, 17, 45], and anomaly-based systems to corre-
late network ﬂows that exhibit a behavior characteristic
of C&C trafﬁc [16, 18, 49]. In a paper related to ours,
Perdisci et al. studied how network traces of malware
can be clustered to identify families of bots that perform
similar C&C communication [34]. The clustering results
can be used to generate signatures, but their approach
does not take into account that bots generate benign traf-
ﬁc or can even deliberately inject noise [1, 10, 11, 33].
Our work is orthogonal to this approach since we can
precisely identify connections related to C&C trafﬁc.
6 Limitations
We aim at analyzing malicious software, which is a hard
task in itself. An attacker can use different techniques to
interfere with the analysis environment which is of con-
cern for us. Our approach relies on actually observing
the network communication of the sample to build the
corresponding behavior graph. Thus, we need to con-
sider attacks against the dynamic analysis environment,
and, speciﬁcally, the taint analysis, since this component
allows us to analyze the interdependence of network and
host activities. Several techniques have been introduced
in the past to enhance the analysis capabilities, for ex-
ample, multi-path execution [30] or the analysis of VM-
aware samples [2]. These and similar methods can be
integrated in JACKSTRAWS so that the dynamic analysis
process produces more extensive analysis reports. Note,
however, that the evaluation results demonstrate that we
can successfully, and in a large scale, analyze complex,
real-world malware samples. This indicates that the pro-
totype version of JACKSTRAWS already provides a ro-
bust framework for performing our analysis
Of course, an attacker might develop techniques to
thwart our analysis, for example, by interleaving unnec-
essary system calls with the calls that represent the ac-
tual, malicious activity. The resulting, additional nodes
might hinder the mining process and prevent the extrac-
tion of a graph core. An attacker might also try to in-
troduce duplicate nodes to launch complexity attacks,
since most of the graph algorithms used in JACKSTRAWS
are known to be NP-complete [6]. However, interleaved
calls have to share some data dependencies with relevant
system calls, otherwise, they would be stripped from
the behavior graph. Moreover, they must be speciﬁcally
crafted to escape the collapsing mechanism. Another ap-
proach to disturb the analysis is to mutate the sequence
of system calls that implement a behavior, as discussed
in [21]. A possible solution to this kind of attacks is to
normalize the behavior graphs in input using rewriting
techniques. That is, semantically equivalent graph pat-
terns are rewritten into a canonical form before mining.
7 Conclusion
In this paper, we focused on the problem of identifying
actual C&C trafﬁc when analyzing binary samples. Dur-
ing a dynamic analysis run, bots do not only communi-
cate with their C&C infrastructure, but they often open
also a large number of benign network connections. We
introduced JACKSTRAWS, a tool that can identify C&C
trafﬁc in a sound way. This is achieved by correlating
network trafﬁc with the associated host behavior.
With the help of experiments, we demonstrated the
different templates we extracted and showed that we
can even infer information about unknown bot families
which we did not recognize before. On the one hand, we
showed that our approach can be applied to proprietary
protocols, which demonstrates that it is protocol agnos-
tic. On the other hand, we also applied JACKSTRAWS
to HTTP trafﬁc, which is challenging since we need to
reason about small differences between legitimate and
malicious usage of the Windows API. The results show
that we can still extract precise templates in this case.
8 Acknowledgments
This work was supported by the ONR under grant
N000140911042,
the National Science Foundation
(NSF) under grants CNS-0845559 and CNS-0905537,
and the Ministry of Economic Affairs and Energy of
the State of North Rhine-Westphalia (grant 315-43-02/2-
005-WFBO-009). We also thank the anonymous review-
ers for their comments that helped to improve the paper,
Xifeng Yan for his precious help on graph mining, and
Luca Foschini for his help on graph algorithms.
References
[1] S. Adair.
Pushdo DDoS’ing or Blending In?
http:
//www.shadowserver.org/wiki/pmwiki.php/
Calendar/20100129, January 2010.