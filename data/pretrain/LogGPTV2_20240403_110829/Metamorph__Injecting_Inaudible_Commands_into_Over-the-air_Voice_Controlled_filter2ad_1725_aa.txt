title:Metamorph: Injecting Inaudible Commands into Over-the-air Voice Controlled
Systems
author:Tao Chen and
Longfei Shangguan and
Zhenjiang Li and
Kyle Jamieson
Metamorph: Injecting Inaudible Commands into
Over-the-air Voice Controlled Systems
Tao Chen
City University of Hong Kong
Longfei Shangguan
Microsoft
Zhenjiang Li
City University of Hong Kong
PI:EMAIL
PI:EMAIL
PI:EMAIL
Kyle Jamieson
Princeton University
PI:EMAIL
Abstract—This paper presents Metamorph, a system that
generates imperceptible audio that can survive over-the-air trans-
mission to attack the neural network of a speech recognition
system. The key challenge stems from how to ensure the added
perturbation of the original audio in advance at the sender side
is immune to unknown signal distortions during the transmission
process. Our empirical study reveals that signal distortion is
mainly due to device and channel frequency selectivity but with
different characteristics. This brings a chance to capture and
further pre-code this impact to generate adversarial examples
that are robust to the over-the-air transmission. We leverage this
opportunity in Metamorph and obtain an initial perturbation
that captures the core distortion’s impact from only a small set
of prior measurements, and then take advantage of a domain
adaptation algorithm to reﬁne the perturbation to further im-
prove the attack distance and reliability. Moreover, we consider
also reducing human perceptibility of the added perturbation.
Evaluation achieves a high attack success rate (90%) over the
attack distance of up to 6 m. Within a moderate distance, e.g.,
3 m, Metamorph maintains this high success rate, yet can be
further adapted to largely improve the audio quality, conﬁrmed
by a human perceptibility study.
I.
INTRODUCTION
Driven by deep neural networks (DNN), speech recognition
(SR) techniques are advancing rapidly [46] and are widely used
as a convenient human-computer interface in many settings,
such as in cars [4], on mobile platforms [3], [48], in smart
homes or cyber-physical systems (e.g., Amazon Echo/Alexa
[1], Mycroft [7], etc.), and in online speech-to-text services
(e.g., SwiftScribe [10]). In general, SR converts an audio clip
input I to the corresponding textual transcript T being spoken,
denoted SR(I) = T .
In the context of the extensive research effort devoted to
SR, this paper studies a crucial problem related to SR from a
security perspective — given any audio clip I (with transcript
T ), by adding a carefully chosen small perturbation sound δ
(imperceptible to people), will the resulting audio I + δ be
recognized as some other targeted transcript T(cid:48) ((cid:54)= T ) by a
receiver’s SR after transmission of I +δ over the air? In other
words, can I + δ (an adversarial waveform that still sounds
like T to a human listener) played by a sender fool the SR
neural network at the receiver?
Network and Distributed Systems Security (NDSS) Symposium 2020
23-26 February 2020, San Diego, CA, USA
ISBN 1-891562-61-4
https://dx.doi.org/10.14722/ndss.2020.23055
www.ndss-symposium.org
1 Transcript T of audio clip I is “this is for
Figure 1:
you”.
2 By adding a small δ , the adversarial example
I + δ can be correctly recognized as “power off” without
transmission [17]. This target transcript T(cid:48) is selected by the
3 After over-the-air transmission, however, I + δ
attacker.
is no longer adversarial. Recognized transcript is similar to the
original T , instead of T(cid:48).
If so, consequences are serious, since this introduces a
crucial security risk that an attacker could hack or deploy a
speaker to play malicious adversarial examples, hiding voice
commands that are imperceptible to people, for launching a
targeted audio adversarial attack (i.e., a T(cid:48) chosen by the
selection of δ ). Such malicious voice commands might cause:
1) Unsafe driving. Malicious commands could be embedded
into the music played by a hacked in-car speaker to fool the
voice control interface and cause an unsafe driving potentially,
e.g., tamper the navigation path to disturb the driver’s driving,
suddenly change personalization settings (like volume up), etc.
2) Denial of service. The attacker could inject hidden com-
mands to turn on the airplane mode of a mobile device and
disables its wireless data, switch off the sensors in cyber-
physical systems, etc.
3) Spam and phishing attacks. The attacker may delete or
add appointments in the victim’s calendar, update the phone
blacklist or visit a phishing website on the victim device.
Recent studies [17], [46] have investigated the ﬁrst step
of this attack, i.e., generating an adversarial example I + δ to
directly fool a SR without actual over-the-air audio transmis-
sion. As Figure 1 depicts, the transcript T (“this is for you”)
of the input audio I can be recognized as T(cid:48) (“power off”)
after adding a small perturbation δ . However, these works
also ﬁnd that the proposed technique fail after over-the-air
transmission (e.g., the recognized transcript becomes “this is
fo youd” instead of “power off” in Figure 1). This is because
after the transmission, the effective audio signal received by
SR is H(I + δ ), where H(·) represents signal distortion from
the acoustic channel, e.g., attenuation, multi-path, etc., and also
distortion from the device hardware (speaker and microphone).
Due to H(·), the effective adversarial example may not lead to
T(cid:48) any more. There are also follow up works [56], [57] try to
compensate the channel effect by directly feeding the channel
state information collected at other places into the training
model. However, these proposals are far from becoming a real-
world threaten primarily due to the short attacking range (e.g.,
 20 kHz) by a common speaker could
be inaudible to human beings, it fails to initiate adversarial
attack since the speech recognition system analyzes the voice
input mainly on the audible frequency, e.g., < 8 kHz [27].
White-box setting. Similar as recent attacks [17], [46], we
also focus on the white-box setting, assuming the awareness of
the speech recognition system’s particulars. Similar to recent
works [17], [27], [56], we adopt DeepSpeech [8], [27] as a
concrete attack target. DeepSpeech is an end-to-end speech
recognition system that has been widely adopted by a bunch of
voice assistant products (e.g., Mycroft [7]) and online speech-
to-text services (e.g., SwiftScribe [10]), as a concrete target.
B. Primer on Audio Adversarial Attack
Before we elaborate the Metamorph design in §III, we ﬁrst
provide a brief primer on audio adversarial attack. First, to
convert one audio clip I to its transcript T , there are two major
steps in the speech recognition (SR) system:
• Step one: The audio input I is divided into short frames
(e.g., 20 ms) [17]. The neural network of SR then takes these
frames as input and extracts the Mel-Frequency Cepstral
Coefﬁcients (MFCC) feature for each frame, based on which
each frame will be recognized as one of the following
tokens [26]: 1) English letters: ‘a’ to ‘z’; and 2) two special
characters: ‘space’ and a predeﬁned token ‘ε’, which means
“empty” corresponding to the frames without meaningful
contents, e.g., voiceless consonants.
• Step two: The recognized raw token sequence can be then
reduced to the ﬁnal recognized transcript, according to two
Connectionist Temporal Classiﬁcation (CTC) rules [17],
[23]: a) merge all the consecutively duplicated tokens as one
Figure 2: An illustration of in-ﬁeld audio adversarial attack.
The voice command sent from the attacker experiences distor-
tion, attenuation, and multi-path propagation before arriving at
the victim’s microphone.
token; and b) then exclude all the ε tokens. For instance,
the raw token sequence “n n d ε ε s s ε s” will be reduced
to “n d s s”.
Formulation. With the SR principle aforementioned, the state-
of-the-art adversarial attack [17] can be formulated as:
minimize
such that
dBI(δ ),
SR(I) = T,
SR(I + δ ) = T(cid:48),
(1)
(2)
(3)
where T (cid:54)= T(cid:48), T(cid:48) is chosen by the attacker and dBI(δ ) is
the audio sound distortion measured in Decibels (dB), i.e.,
dBI(δ ) = dB(I + δ )− dB(I).
Solving δ . The formulation above can be further rephrased as
follows to solve the perturbation δ [17]:
argminδ dBI(δ ) + α · L(SR(I + δ ),T(cid:48)),
(4)
where L(·) and α are the loss function and the weighting factor,
respectively. Two points are worth noting: