calculates deviation distance of a test payload from the
normal proﬁle using a simpliﬁed Mahalanobis distance,
i=0(|xi − yi|)/(σi + α), where yi is the
mean, σi is the standard deviation, and α is a smooth-
ing factor. A payload is considered as anomalous if this
distance exceeds a predetermined threshold. PAYL is ef-
fective in detecting worm exploits with a reasonable false
positive rate as shown in [46, 47]. However, it could be
evaded by a polymorphic blending attack (PBA) [18]. As
discussed in [47, 18, 31], a generic n-gram version of
PAYL may help to improve accuracy and the hardness
of evasion. The n-grams extract n-byte sequence infor-
mation from the payload, which helps in constructing a
more precise model of the normal trafﬁc compared to the
single-byte (i.e., 1-gram) frequency-based model. In this
case the feature space in use is not 256, but 256n
dimen-
sional. It is impractical to store and compute in a 256n
dimension space for high-n-grams.
SLADE makes the n-gram scheme practical by using a
lossy structure while still maintaining approximately the
same accuracy as the original full n-gram version. We
use a ﬁxed vector counter (with size v) to store a lossy
n-gram distribution of the payload. When processing a
payload, we sequentially scan n-gram substring str, ap-
ply some universal hash function h(), and increment the
counter at the vector space indexed by h(str) mod v.
We then calculate the distribution of the hashed n-gram
indices within this (much) smaller vector space v. We
deﬁne F as the feature space of n-gram PAYL (with a to-
tal of 256n
distinct features), and F’ as the feature space
of SLADE (with v features).
This hash function provides a mapping from F to F’
that we utilize for space efﬁciency. We require only v
(e.g., v = 2, 000), whereas n-gram PAYL needs 256n
(e.g., even for a small n=3, 2563 = 224 ≈ 16M). The
computational complexity in examining each payload is
still linear (O(L), where L is the length of payload), and
the complexity in calculating distance is O(v) instead
of 256n
. Thus, the runtime performance of SLADE is
comparable to 1-gram PAYL. Also note that although
both use hashing techniques, SLADE is different from
Anagram [45], which uses a Bloom ﬁlter to store all n-
gram substrings from normal payloads. The hash func-
tion in SLADE is for feature compression and reduction,
however the hash functions in Anagram are to reduce
the false positives of string lookup in Bloom ﬁlter.
In
essence, Anagram is like a content matching scheme. It
builds a huge knowledge base of all known good n-gram
substrings using efﬁcient storage and query optimiza-
tions provided by bloom ﬁlters, and examines a payload
to determine whether the number of its n-gram substrings
not in the knowledge base exceeds a threshold.
itives and false negatives) may be introduced because
of the lossy representation? To answer this question,
we perform the following simple analysis.3 Let us ﬁrst
overview the reason why the original n-gram PAYL can
detect anomalies. We use γ to represent the number of
non-zero value features in F for a normal proﬁle used
by PAYL. Similarly, γ0
is the number of non-zero value
features in F’ for a normal proﬁle used by SLADE. For
a normal payload of length = L, there is a total of
l = (L − n + 1) n-gram substrings. Among these l sub-
strings, 1 − βn percent substrings converge to γ distinct
features in the normal proﬁle, i.e., these substrings share
similar distributions as the normal proﬁle. The remaining
(small portion) βn percent of substrings are considered
as noise substrings that do not belong to the γ features
in the normal proﬁle. For a malicious payload, if it can
be detected as an anomaly, it should have a much larger
portion of noise substrings βa (βa > βn).
We ﬁrst analyze the false positives when using the
lossy structure representation to see how likely SLADE
will detect a normal (considered normal by n-gram
PAYL) payload as anomalous. For a normal payload, the
hashed indices of a 1 − βn portion of substrings (that
converge to γ distinct features in F for the normal pro-
ﬁle of PAYL) should now converge in the new vector
space (into γ0
distinct features in F’ for the normal pro-
ﬁle of SLADE). Because of the universal hash function,
hashed indices of the βn portion of noise substrings are
most likely uniformly distributed into F’. As a result,
some of the original noise substrings may actually be
hashed to the γ0
distinct features in the normal proﬁle
of SLADE (i.e., they may not be noise in the new fea-
ture space now). Thus, the deviation distance (i.e., the
anomaly score) can only decrease in SLADE. Hence, we
conclude that SLADE may not have a higher false posi-
tive rate than n-gram PAYL.
Now let us analyze the false negative rate, i.e., the like-
lihood that SLADE will treat a malicious payload (as
would be detected by n-gram PAYL) as normal. False
negatives happen when the hash collisions in the lossy
structure mistakenly map a βa portion of noise substrings
into the γ0
features (i.e., the normal proﬁle) for SLADE.
By using the universal hash function, the probability for
0
a noise substring to fall into γ0
γ
out of v space is
v . Thus,
the probability for all the lβa noise substrings to collide
0
into the γ0
portion is about ( γ
v )lβa. For example, if we
assume v = 2, 000, γ0 = 200, lβa = 100, then this prob-
ability is about (200/2000)100 = 1e− 100 ≈ 0. In prac-
tice, the probability of such collisions for partial noise
substrings is negligible. Thus, we believe that SLADE
does not incur a signiﬁcant accuracy penalty compared to
3We consider our analysis not as an exact mathematical proof, but
an analytical description about the intuition behind SLADE.
full n-gram PAYL, while signiﬁcantly reducing its stor-
age and computation complexity.
We measured the performance of SLADE in compar-
ison to 1-gram PAYL by using the same data set as in
[31]. The training and test data sets used were from
the ﬁrst and following four days of HTTP requests from
the Georgia Tech campus network, respectively. The at-
tack data consists of 18 HTTP-based buffer overﬂow at-
tacks, including 11 regular (nonpolymorphic) exploits,
6 mimicry exploits generated by CLET, and 1 polymor-
phic blending attack used in [18] to evade 2-gram PAYL.
In our experiment, we set n = 4, v = 2, 048.4
Table 1 summarizes our experimental results. Here,
DFP is the desired false positive rate, i.e., the rejection
rate in the training set. RFP is the “real” false positive
rate in our test data set. The detection rate is measured
on the attack data set and is deﬁned as the number of at-
tack packets classiﬁed as anomalous divided by the total
number of packets in the attack instances. We conclude
from the results that SLADE performs better with respect
to both DFP and RFP than the original PAYL (1-gram)
system. Furthermore, we discovered that the minimum
RFP for which PAYL is able to detect all attacks, includ-
ing the polymorphic blending attack, is 4.02%. This is
usually considered intolerably high for network intrusion
detection. On the other hand, the minimum RFP required
for SLADE to detect all attacks is 0.3601%. As shown
in [31], 2-gram PAYL does not detect the polymorphic
blending attack even if we are willing to tolerate an RFP
as high as 11.25%. This is not surprising given that the
polymorphic blending attack we used was speciﬁcally
tailored to evade 2-gram PAYL. We also ﬁnd that SLADE
is comparable to (or even better than) a well-constructed
ensemble IDS that combines 11 one-class SVM classi-
ﬁers [31], and detects all the attacks, including the poly-
morphic blending attack, for an RFP at around 0.49%.
SLADE also has the added advantage of more efﬁcient
resource utilization, which results in shorter training and
execution times when compared to the ensemble IDS.
4.1.3 Signature Engine: Bot-Speciﬁc Heuristics
Our ﬁnal sensor contributor is the Snort signature engine.
This module plays a signiﬁcant role in detecting several
of the classes of dialog warnings from our bot infection
dialog model. Snort is our second sensor source for di-
rect exploit detection (class E2), and our primary source
for binary downloading (E3) and C&C communications
(E4). We organize the rules selected for BotHunter into
four separate rule ﬁles, covering 1046 E2 rules, 71 E3
rules, 246 E4 rules, and a small collection of 20 E5 rules,
for total of 1383 heuristics. The rules are primarily de-
4One can also choose a random v to better defeat evasion attacks
like PBA. Also one may use multiple different hash functions and vec-
tors for potential better accuracy and hardness of evasion.
USENIX Association
16th USENIX Security Symposium
173
PAYL
SLADE
DFP(%)
RFP(%)
Detected Attacks
Detection Rate(%)
RFP(%)
Detected Attacks
Detection Rate(%)
0.0
0.00022
1
0.8
0.0026
3
20.6
0.01
0.01451
4
17.5
0.0189
13
74.6
0.1
0.15275
17
69.1
0.2839
17
92.9
Table 1: Performance of 1-gram PAYL and SLADE
1.0
0.92694
17
72.2
1.9987
18
99.2
2.0
1.86263
17
72.2
3.3335
18
99.2
5.0
5.69681
18
73.8
6.3064
18
99.2
10.0
11.05049
18
78.6
11.0698
18
99.2
rived from the Bleeding-Edge [10] and SourceFire’s reg-
istered free rulesets.
All the rulesets were selected speciﬁcally for their rel-
evance to malware identiﬁcation. Our rule selections are
continually tested and reviewed across operational net-
works and our live honeynet environment. It is typical
for our rule-based heuristics to produce less than 300
dialog warnings per 10-day period monitoring an oper-
ational border switch space port of approximately 130
operational hosts (SRI Computer Science Laboratory).
Our E2 ruleset focuses on the full spectrum of external
to internal exploit injection attacks, and has been tested
and augmented with rules derived from experimentation
in our medium and high interactive honeynet environ-
ment, where we can observe and validate live malware
infection attempts. Our E3 rules focus on (malware)
executable download events from external sites to in-
ternal networks, covering as many indications of (ma-
licious) binary executable downloads and download ac-
knowledgment events as are in the publicly available
Snort rulesets. Our E4 rules cover internally-initiated
bot command and control dialog, and acknowledgment
exchanges, with a signiﬁcant emphasis on IRC and URL-
based bot coordination.5 Also covered are commonly
used Trojan backdoor communications, and popular bot
commands built by keyword searching across common
major bot families and their variants. A small set of E5
rules is also incorporated to detect well-known internal
to external backdoor sweeps, while SCADE provides the
more in-depth hunt for general outbound port scanning.
4.2 Dialog-Based IDS Correlation Engine
The BotHunter correlator tracks the sequences of IDS
dialog warnings that occur between each local host
and those external entities involved in these dialog ex-
changes. Dialog warnings are tracked over a temporal
window, where each contributes to an overall infection
sequence score that is maintained per local host. We in-
troduce a data structure called the network dialog corre-
lation matrix, which is managed, pruned, and evaluated
by our correlation engine at each dialog warning inser-
tion point. Our correlator employs a weighted thresh-
old scoring function that aggregates the weighted scores
5E4 rules are essentially protocol, behavior and payload content sig-
nature, instead of a hard-coded known C&C domain list.
of each dialog warning, declaring a local host infected
when a minimum combination of dialog transactions oc-
cur within our temporal pruning interval.
Figure 4 illustrates the structure of our network dialog
correlation matrix. Each dynamically-allocated row cor-
responds to a summary of the ongoing dialog warnings
that are raised between an individual local host and other
external entities. The BotHunter correlator manages the
ﬁve classes of dialog warnings presented in Section 3 (E1
through E5), and each event cell corresponds to one or
more (possibly aggregated) sensor alerts that map into
one of these ﬁve dialog warning classes. This correlation
matrix dynamically grows when new activity involving a
local host is detected, and shrinks when the observation
window reaches an interval expiration.
In managing the dialog transaction history we employ
an interval-based pruning algorithm to remove old di-
alog from the matrix.
In Figure 4, each dialog may
have one or two expiration intervals, corresponding to
a soft prune timer (the open-faced clocks) and a hard
prune timer (the ﬁlled clocks). The hard prune inter-
val represents a ﬁxed temporal interval over which di-
alog warnings are allowed to aggregate, and the end of
which results in the calculation of our threshold score.
The soft prune interval represents a smaller temporal
window that allows users to conﬁgure tighter pruning
interval requirements for high-production dialog warn-
ings (inbound scan warnings are expired more quickly
by the soft prune interval), while the others are allowed
to accumulate through the hard prune interval. If a dia-
log warning expires solely because of a soft prune timer,
the dialog is summarily discarded for lack of sufﬁcient
evidence (an example is row 1 in Figure 4 where only E1
has alarms). However, if a dialog expires because of a
hard prune timer, the dialog threshold score is evaluated,
leading either to a bot declaration or to the complete re-
moval of the dialog trace should the threshold score be
found insufﬁcient.
To declare that a local host is infected, BotHunter
must compute a sufﬁcient and minimum threshold of ev-
idence (as deﬁned in Section 3) within its pruning inter-
val. BotHunter employs two potential criteria required
for bot declaration: 1) an incoming infection warning
(E2) followed by outbound local host coordination or ex-
ploit propagation warnings (E3-E5), or 2) a minimum of
174
16th USENIX Security Symposium
USENIX Association
Int. Host
Timer 
E1