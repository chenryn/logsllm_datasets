the multiplier is a memory-mapped peripheral, it has to be
accessed by writing the two operands to speciﬁc locations
in memory. Concretely, the ﬁrst operand of a multiply or a
MAC operation has to be written to one of four addresses
(MPY, MPYS, MAC, or MACS) and this address determines the
actual operation to be issued. The second operand must be
written to another speciﬁc address (OP2), and once this has
happened, the selected operation is immediately executed
[24]. After a few clock cycles, the 32-bit result is available
at the addresses RESLO (lower 16 bits) and RESHI (upper 16
bits). In the case of a MAC operation, the product of the
two operands is added to the content of RESHI|RESLO and
the obtained cumulative sum is written back to RESHI and
RESLO [24]. The carry bit produced by the accumulation is
written to another address, namely SUMEXT. When several
multiplications with one and the same operand need to be
carried out, it is possible to “re-use” this operand, provided
that it is the ﬁrst operand. Namely, the ﬁrst operand can
be used in consecutive multiplications or consecutive MAC
operations without having to write it again to one of the
four addresses that select the type of operation.
Multiple-Precision Multiplication
Most ECC implementations for the MSP430 platform use
the so-called product-scanning technique (or an optimized
variant of it) to perform multi-precision multiplication, see
e.g. [5, 21, 22]. The product-scanning method computes the
product of two multiple-precision integers in a column-wise
fashion and performs MAC operations in its loops, i.e. two
w-bit words are multiplied and the 2w-bit product is added
to a cumulative sum. Hence, the product-scanning method
performs well on MSP430 processors. Our implementation
is also based on product scanning, but we incorporated a
number of low-level optimizations. For example, we use all
free registers to “cache” 16-bit words of the operands so as
to minimize the number of memory accesses. Moreover, we
adapt the order in which the partial products are processed
with the goal of increasing the number of subsequent MAC
operations that can use one and the same operand. In this
way, we can save a few clock cycles as the re-used operand
has to be written to MAC only once. Listing 1 shows a code
snippet that illustrates the computation of the ﬁrst two
partial products of a column. The MOV instructions in line
1 and 2 write two operand words (which are accessed via
the pointers APTR and BPTR) to MAC and OP2. As explained
above, the 32-bit result of a MAC operation is placed in
RESHI and RESLO, while the carry from the accumulation is
written to SUMEXT. In line 3 and 7, the carry bit is added
into a register named CARRY. More precisely, the carry from
the ﬁrst MAC operation of a column can be directly moved
to CARRY, while subsequent carries need to be added.
1:
2:
3:
4:
5:
6:
7:
8:
MOV @APTR + , & MAC
MOV @BPTR , & OP2
MOV & SUMEXT , CARRY
SUB #2 , BPTR
MOV @APTR + , & MAC
MOV @BPTR , & OP2
ADD & SUMEXT , CARRY
SUB #2 , BPTR
Listing 1: Product-scanning technique using MAC
operations
Multiple-Precision Squaring
Since squaring received rather modest attention in previous
work (and was completely ignored in e.g. [18]), it bears the
potential for noticeable speed-ups through optimization. In
essence, squaring is a special case of multiplication since all
partial products of the form ai · aj with i (cid:54)= j appear twice
in the result due to the fact that ai · aj = aj · ai. Dedicated
squaring techniques compute these partial products once
and then double them, which reduces the number of word-
level multiplication or MAC operations by nearly 50%. The
squaring routine we implemented involves two steps; in the
ﬁrst step, all partial products to be doubled are generated
and summed up. Then, in the second step, the intermediate
result obtained so far is doubled and the partial products
from the “‘main diagonal” (i.e. the partial products that are
themselves squares of the form ai · ai) are added to yield
the full result. The ﬁrst step can be optimized in the same
way as the multi-precision multiplication, which means we
should use free registers to “cache” operand words and we
should re-order the processing of partial products with the
goal of executing a number of consecutive MAC operations
with the same ﬁrst operand. For example, once a0 has been
written to address MAC, we can process the partial products
a0 · a2 and a0 · a3 by only writing a2 and a3 to OP2.
Figure 1: Zig-zag squaring of a 160-bit integer
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
CLR R15
MOV R15 , & RESLO
MOV R15 , & RESHI
// A [0]* A [1]
MOV @APTR , & MAC
MOV @APTR2 + , & OP2
MOV & RESLO , 2( R14 )
MOV & RESHI , & RESLO
MOV R15 , & RESHI
// A [0]* A [2]
MOV @APTR2 + , & OP2
MOV & RESLO , 4( R14 )
MOV & RESHI , & RESLO
MOV R15 , & RESHI
// A [0]* A [3]
MOV @APTR2 + , & OP2
Listing 2: Zig-zag squaring using MAC operations
Taking all these optimization strategies into account, we
found that the most eﬃcient way to perform the ﬁrst step
is to process the partial products in a “zig-zag” fashion as
illustrated by the thick yellow line in Figure 1. We call this
approach “zig-zag squaring” because it is somewhat related
to the zig-zag multiplication described in [27]. Each dot in
Figure 1 represents one partial product. The computation
starts at the right corner and proceeds to the left. Both the
ﬁrst column on the yellow line (i.e. the column yielding the
word z1 of z = a2) and the second column (z2) consist of a
single partial product each, namely a0 · a1 and a0 · a2, while
the third column (producing the word z3) contains the two
partial products a0 · a3 and a1 · a2. Listing 2 demonstrates
the computation of the ﬁrst three partial products on the
yellow line, whereby this code snippet shows that a0 needs
to be written to the address MAC only once and can then be
a 0· a 0z 0a 9· a 0a 9· a 9z 9z 18z 1z 2used as operand in three MAC operations. The ﬁrst three
partial products (i.e. a0 · a1, a0 · a2, and a0 · a3) allow some
special optimizations as their accumulation into RESLO and
RESHI can not cause an overﬂow, i.e. SUMEXT is 0 and does
not need to be added to register CARRY. This also simpliﬁes
the w-bit right-shift of the cumulative sum, which has to
be performed at the end of each column in order to ensure
a proper alignment of the partial products. The white dots
in Figure 1 indicate all partial products that do not require
a carry propagation. When the ﬁrst step of the squaring is
completed, the intermediate result has to be doubled and
the partial products located on the red line at the bottom
of Figure 1 (i.e. a0 · a0 to a9 · a9) must be added, which can
be done together with the doubling in one pass.
Modular Reduction
Since the operands of a multiplication or squaring may be
incompletely reduced, the resulting product or square has
a length of up to 2n = 2k + 2 bits, but nonetheless always
ﬁts into 2m words. Our implementation of the reduction is
fully optimized for pseudo-Mersenne primes p = 2k − c and
consists of two steps. Let z be a 2m-word product. In the
ﬁrst step, z is split into an upper part zH that comprises
the m most signiﬁcant words and a lower part zL with all
the other words. At the beginning of this section we deﬁned
the exponent k of our primes to be a multiple of 32 minus
1, which implies that k is a multiple of w minus 1. Thus, we
have 2p = 2(2k − c) = 2n − d where n = k + 1 = mw and
d = 2c. Given z = zH · 2mw + zL, the ﬁrst reduction step is
to compute z(cid:48) ≡ z mod p as follows
(cid:48)
= zH · d + zL
z
(10)
Taking our 159-bit prime p = 2159 − 91 as an example, we
have d = 2c = 182. Since the two operands to be multiplied
must be less than 2160 each, it can be shown that z(cid:48) has a
maximum length of 168 bits and ﬁts into 11 words. Using
2p instead of p in the ﬁrst reduction step allows us to avoid
shift operations, which would otherwise be necessary since
k is not a multiple of the word size. The second step of the
reduction operation is the same as in the modular addition
(i.e. line 5 to 10 in Algorithm 1), except that the variable
t has to be composed of z(cid:48)
m (shifted one bit to the left) and
the MSB of z(cid:48)
m−1. More formally, t = z(cid:48)/2k, which means
t has a length of 9 bits in our 159-bit example. The product
t · c has a length of 16 bits, and, consequently, the result we
get after the second reduction step is at most 160 bits as in
the modular addition.
3.3 Fermat-Based Inversion
Using projective coordinates for the point arithmetic has
the advantage that only a single inversion in Fp needs to be
executed, namely at the very end of a scalar multiplication
to convert the result from projective to aﬃne coordinates
[8]. There exist two principal approaches for performing an
inversion in Fp, namely the Extended Euclidean Algorithm
(EEA) and inversion via exponentiation based on Fermat’s
little theorem. The EAA is, in general, more eﬃcient than
Fermat’s technique, but has an irregular execution pattern
and an operand-dependent execution time, both of which is
problematic if one aims for resistance against side-channel
attacks. Therefore, we implemented the inversion by means
of an exponentiation of the form a = z−1 ≡ zp−2 mod p. In
order to minimize the number of modular multiplications
needed for this exponentiation, we use an addition-chain as
shown in Algorithm 2 for our 159-bit prime. The comments
in each line specify the computational cost of the operation
carried out in that line, i.e. the number of multiplications
(M) and squarings (S). Also given is the intermediate value
of the exponent based on all operations executed until that
line. In total, an inversion modulo our 159-bit prime costs
158 squarings and 11 multiplications.
Algorithm 2. Fermat-based inversion mod p = 2159 − 91
Input: Integer a satisfying 1 ≤ a ≤ p − 1.
Output: Inverse z = ap−2 mod p = a−1 mod p.
{ exp: 2, cost: 0M+1S}
1: a2 ← a2
{ exp: 3, cost: 1M+0S}
2: a3 ← a2 · a
{ exp: 15, cost: 2S+1M}
3: a15 ← (a3)22 · a3
{ exp: 28 − 1, cost: 4S+1M}
4: t1 ← (a15)24 · a15
{ exp: 216 − 1, cost: 8S+1M}
5: t2 ← (t1)28 · t1
{ exp: 232 − 1, cost: 16S+1M}
6: t3 ← (t2)216 · t2
{ exp: 264 − 1, cost: 32S+1M}
7: t4 ← (t3)232 · t3
{ exp: 2128 − 1, cost: 64S+1M}
8: t5 ← (t4)264 · t4
9: t6 ← ((t5)216 · t2)28 · t1 { exp: 2152 − 1, cost: 24S+2M}
10: z ← ((t6)22 · a)25 · a3
{ exp: 2159 − 93, cost: 7S+2M}
11: return z
A Fermat-based inversion modulo p = 2191 − 19 can be
performed in a similar fashion using an optimized addition
chain, whereby the overall computational cost amounts to
190 modular squarings and 12 modular multiplications.
4. EXPERIMENTAL RESULTS
Ephemeral ECDH key exchange requires each of the two
involved nodes to perform a ﬁxed-base and a variable-base
scalar multiplication. Since our implementation is based on
MoTE curves, we can execute the former with a ﬁxed-base
comb method (using the twisted Edwards model), whereas
the second scalar multiplication can take advantage of the
existence of a birationally-equivalent Montgomery model
and its high eﬃciency in variable-base scenarios. Similar to
Curve25519 [2], we exchange only the x-coordinates of the
ephemeral public keys. Thus, it is necessary to convert the
point obtained as result of the ﬁrst scalar multiplication to
a point on the equivalent Montgomery curve. This can be
done in combination with the projective-aﬃne conversion
so that only one inversion is necessary for both conversions
(see [16] for the conversion formulae).
Operation
159 bit
191 bit
Addition
Subtraction
Multiplication
Squaring
Inversion
108
124
1,828
1,505
133
156
2,555
1,983
268,547
419,823
Table 1: Execution time (in clock cycles) of ﬁeld
arithmetic operations.
We determined the execution time of various arithmetic
operations with help of the cycle-accurate simulator that is
part of IAR Embedded Workbench 6.10 using the F1611 as
target device. Table 1 summarizes the results of the ﬁeld
Implementation
Field Mul
Fixed SM
Variab SM
Full ECDH
Regular
Device
Implementations using curves over a 159 or 160-bit prime ﬁeld
Liu and Ning [13]
Marin et al [18]
Wenger and Werner [27]
Hinterw¨alder et al [9]
Szczechowiak et al [23]
Wenger [26]
Gouvˆea and L´opez [5]
This work (curve P159)
Implementations using curves over a 191 or 192-bit prime ﬁeld
Wenger and Werner [27]
Wenger [26]
This work (curve P191)