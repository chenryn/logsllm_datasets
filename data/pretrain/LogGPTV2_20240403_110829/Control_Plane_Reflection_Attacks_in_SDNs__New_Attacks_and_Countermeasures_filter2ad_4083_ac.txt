striking attack.
Statistics Query are much more expensive than Packet-Out while they two have
a similar expense for the downlink channel.
Furthermore, more conﬁdential information could be obtained with the joint
trials and analysis of data plane stream and double-peak phenomenon. If the
attacker obtains a series of successive double-peak phenomenon (as shown in
Fig. 6(b) with the input of data plane stream template1, where v is a big value,
and obtains a series of intermittent double-peak phenomenon (Fig. 6(c) with
template2, where v is also a big value, she/he could determine that packet num-
ber volume-based statistic calculation method is adopted. This is because packet
number volume-based statistic calculation approach is sensitive to stream with
a high pps. The other three cases are also listed in Table 1. From this table, we
can conclude the concrete statistic calculation approach the application adopts.
Furthermore, with the variations of v and p, the attacker could infer the critical
value of volume or rate. In addition, we can verify our inference with a lot of
172
M. Zhang et al.
(a) Timing probe RTTs for Flow Moni-
toring-based applications.
(b) Timing probe RTTs patterns 1.
(c) Timing probe RTTs patterns 2.
(d) Timing probe RTTs pattern 3.
Fig. 6. Timing-based patterns for Counter Manipulation Attack.
other ways, not only the proposed two data plane stream templates as shown
above. We are planning to develop more representative templates in our future
works. In particular, we test our four indirect event driven applications, and ﬁnd
them fall into the distribution in Table 2. This is consistent with the policies of
each application, which demonstrates the eﬀectiveness of our probing phase.
With the results and information (query period, packet number/byte-based,
volume/rate values) obtained from the probing phase, we move to the second
step and start to commit our Counter Manipulation Attack. We select one appli-
cation, PIAS, setting its priority as 3 levels, and initiate 10 new ﬂows per second.
We carefully set the sent bytes of each ﬂow in each period (2 s), which is bigger
than the critical value we probed. As a consequence, a number of Flow-Mod
messages are issued to the switch when statistic query/reply occurs. As shown
in Fig. 7, the number of Flow-Mod messages could increase as high as 60 at the
end of each period. This would incur pretty high loads to the software agent
of the switch at this moment. Even in some cases, when the attacker controls
thousands of ﬂows intentionally and manipulates all the ﬂow to reach the criti-
cal values simultaneously, thousands of Flow-Mod messages are directed to the
switch, which would cause catastrophic results such as the disruption of connec-
tions between the controller and the switches.
Table 1. Relationship between data plane stream and double-peak phenomenon.
Control Plane Reﬂection Attacks
173
Volume-based
Rate-based
Packet number Template1(v↑, p)→ patterns 1 Template1(v↑, p)→ patterns 3
Template2(v↑, p)→ patterns 2 Template2(v↑, p)→ patterns 1
Template1(v, p↑)→ patterns 1 Template1(v, p↑)→ patterns 3
Template2(v, p↑)→ patterns 2 Template2(v, p↑)→ patterns 1
Packet byte
Table 2. Distribution of the four indirect event driven applications.
Volume-based
Rate-based
Packet number Microburst
-
Packet byte
Heavy Hitter
PIAS
DDoS Detection
DDoS Detection
4.3 Attack Fundamentals and Analysis
In this subsection, we study more about low-level details of Control Plane Reﬂec-
tion Attacks.
Test Packet Rate and Test Packet Type. Fig. 8 shows the timing probe
RTTs as the rate of test packets varies where the controller is conﬁgured to
issue a Flow-Mod message for each test packet. Figure 9 shows the timing probe
RTTs as Statistics Query rate varies. Figure 10 shows the timing probe RTTs
as the rate of test packets varies where the controller processes each test packet
with a Packet-Out message. As we can conclude from these ﬁgures, diﬀerent
downlink messages have diverse expenses for the downlink channel, and all of
the three scenarios encounter a signiﬁcant nonlinear jump. In particular, when
the controller generates Flow-Mod message for each test packet, the RTTs can
reach 1000 times higher at approximately 50 pps. For Statistics Query messages,
the RTTs are about 100 times at 100 pps. And for Packet-Out messages, the
RTTs double 100 times at about 500 pps. Meanwhile, we measure the resource
usage of the hardware switch and the controller, and ﬁnd that the CPU usage of
the switch could reach above 90% at the point of the nonlinear jump, while the
memory usage of the switch, the CPU and memory usage of the control server
is relatively low (at most 30%). In addition, we have a conservation with the
Pica8 team via email, and obtain that the switch control actions (e.g. Flow-Mod,
Statistics Query) must contend for the limited bus bandwidth between a switch’s
CPU and ASIC, and insertion of a new ﬂow rule requires the rearrangement of
rules in TCAM, which lead to the results that the expense of Flow-Mod ≥
Statistics Query (cid:4) Packet-Out.
174
M. Zhang et al.
Fig. 7. Attack eﬀect
Fig. 8. Timing probe RTTs as Flow-
Mod rate varies.
Fig. 9. Timing probe RTTs as statis-
tic query rate varies.
Fig. 10. Timing probe RTTs
Packet-Out rate varies.
as
The Impact of Background Traﬃc. The background traﬃc has two impacts
for the Control Plane Reﬂection Attacks. First, it may aﬀect the accuracy of
probing phase. In fact, a moderate rate of background traﬃc would not weaken
the eﬀectiveness of the probing. Conversely, it ampliﬁes the probing eﬀect. The
reason behind this is that the eﬀect of background traﬃc is somewhat like the
role played by test packets, and it would put some baseline loads to the switch
protocol agent, which would make the probing more accurate. An excessively
high rate of background traﬃc would certainly lower the probing accuracy, since
there is already a high load for the protocol agent of the switch. As a consequence,
the loads incurred by Statistics Query would not cause the obvious and periodical
peaks for the RTTs of timing probing packets, instead, the patterns may become
random and irregular. However, in such cases, the switch is already suﬀering, thus
the aim of the attack has already been achieved. Second, the background traﬃc
may also aﬀect the trigger phase. Actually, this inﬂuence is positive, too. The
existence of the background traﬃc would inevitably bring about some downlink
Control Plane Reﬂection Attacks
175
messages to the control channel, which would boost the eﬀects of Control Plane
Reﬂection Attacks.
5 Defense Approach
5.1 Countermeasure Analysis
The control plane reﬂection attack is deeply rooted in SDN architecture since the
performance of existing commodity SDN-enabled hardware switches could not
suﬃce the need of the SDN applications. A straightforward method to mitigate
this attack is limiting the use of dynamic features for network applications, never-
theless, this comes at the expense of less ﬁne-grained control, visibility, and ﬂexi-
bility in traﬃc management, as evidently required in [4,14,31]. Another straight-
forward defense approach is limiting the downlink message transmission rate
directly in the controller, preventing the switches from being overwhelmed. How-
ever, the exact downlink message processing capabilities for diﬀerent switches
vary, even for a speciﬁc switch, the rate control in the controller cannot precisely
guarantee underload or overload for the remote switch6, making the uniﬁed con-
trol inaccurate and complicated. Adding some latency to random downlink mes-
sages seems feasible, which can make the patterns/policies of direct/indirect data
plane events diﬃcult to sniﬀ and obtain. Nevertheless, this technique increases
the total latency for the overall downlink messages, and would inevitably violate
the latency requirements of some latency-sensitive downlink messages, making
it high cost and infeasible.
To address the challenges above, we propose SWGuard to mitigate the reﬂec-
tion attack and fulﬁll the requirements of diﬀerent downlink messages. Our basic
idea is to discriminate good from evil, and prioritize downlink messages with dis-
crimination results. To this end, we propose a multi-queue scheduling strategy, to
achieve diﬀerent latency for diﬀerent downlink messages. The scheduling strategy
is based on the statistics of downlink messages in a novel granularity during the
past period, which takes both fairness and eﬃciency into consideration. When
the downlink channel is becoming congested, the malicious downlink messages
are inclined to be put into a low-priority scheduling queue and the requirements
of good messages are more likely to be satisﬁed.
5.2 SWGuard: A Priority-Based Scheduler on Switch
The architecture of SWGuard is shown in Fig. 11. SWGuard mainly redesigns
two components of SDN architecture. On the switch side, it changes the existing
software protocol agent to multi-queue based structure, and schedules diﬀerent
downlink messages with their types and priorities. On the controller side, it
adds a Behavior Monitor module as a basic service, which collects the downlink
message events and assigns diﬀerent priorities to diﬀerent messages dynamically.
6 There may be several hops between the switch and the controller, and the network
condition is unpredictable.
176
M. Zhang et al.
Fig. 11. SWGuard framework design.
Multi-queue Based Software Protocol Agent. In order to prioritize the
downlink messages, we redesign the software protocol agents of the existing
switches. A naive approach is to modify the existing single queue model directly
into priority-based multi-queue model, and enqueue all the downlink messages
into diﬀerent queues with their priorities and dequeue at diﬀerent scheduling
rates. However, the types of downlink messages vary, and diﬀerent message types
have diverse requirements, for example, if Handshake messages and Modify State
messages are put into the same queue, the latency requirement of the former may
be delayed by the latter so that the handshakes between the controller and the
switches could not be established timely.
To this end, we summarize the downlink messages into the following four
categories: (1) Modify State Messages (MSM), (2) Statistic Query Messages
(SQM), (3) Conﬁguration Messages (CM), and (4) Consistency Required Mes-
sages (CRM), and design a Classiﬁer to classify the downlink messages into
diﬀerent queues accordingly. The ﬁrst two types are related to the behaviors of
hosts and applications, so we design a multi-queue for each of them. The multi-
queue consists of three levels (quick, slow, block), and each level is designed for
the corresponding priority. The third type serves for basic services of the con-
troller (e.g., Handshake, LLDP), while the detail of the last type is illustrated
in Sect. 5.2, and both of them inherit from the original single queue. Classiﬁer
makes use of ofp header ﬁeld in OpenFlow Header to distinguish message type,
and a 2-bit packet metadata to obtain priority.
With the downlink messages in the queues, a Scheduler is designed to dequeue
the messages with a scheduling algorithm. In order not to overwhelm the capa-
bility of ASCI/Forwarding Engine, a Finish Signal should be sent back to the
Scheduler once a Modify State/Statistic Query message is processed. Then the
Scheduler knows whether to dequeue a next message of the same type from
queues. We design a time-based scheduling algorithm, setting diﬀerent strides
for diﬀerent queues. For the last two queues (Conﬁguration Messages, Consis-
tence Required Messages), the stride is set as 0, which means whenever there
is a message, it would be dequeued immediately. For the ﬁrst two multi-queues,
Control Plane Reﬂection Attacks
177
the stride for the queue of quick level is set as 0, for that of slow level is set as
a small time interval, while for that of block level is set as a relatively bigger
value. With the principles illustrated above, we design the scheduling algorithm
as Algorithm 1.
Algorithm 1. The Scheduling Algorithm for Protocol Agent.
foreach que ∈ queues do
// Initialization
set que.stride;
que.time = getcurrenttime();
// Enter the Scheduler thread
while true do
foreach que ∈ queues do
if que.stride ≤ getcurrenttime() − que.time then
if que.empty() == f alse then
que.time = getcurrenttime();
que.dequeue();
else
que.time = getcurrenttime();
Behavior Monitor. In order to distinguish diﬀerent downlink messages with
diﬀerent priorities, an appropriate Monitoring granularity is in urgent need. Pre-
vious approaches mainly conduct the monitoring with the granularity of source
host [3,34], and react to the anomalies on the statistics. However, in the control
plane reﬂection attacks, these approaches are no longer valid and eﬀective. For
example, if we only take the features of the data plane traﬃc into consideration,
and schedule with the statistics of source hosts [35], it would inevitably violate
the heterogeneous requirements of various applications.
To address this challenge, we propose the novel abstraction of Host-
Application Pair (HAP), and use it as the basic granularity for monitoring and
statistics. These two dimensions are easy to be obtained from the uplink mes-
sages and the conﬁgurations of the controller. Considering K applications exist
on the control plane, their requirements for downlink messages are represented
as vector a0 = (cid:5)a1, a2, . . . aK(cid:6), and N hosts/users in the data plane, correspond-
ing requirements vector h0 = (cid:5)h1, h2, . . . hN(cid:6). a0 and h0 are both set by the
network operators, depending on the property of the applications and the pay
T · h0.
of hosts/users. Thus the expected resource allocation matrix is R0 = a0
And the expected resource allocation ratio matrix is I0 =
. Dur-
ing the past period (T seconds), the statistics of HAP is represented as resource
R0
(cid:2)N
n=1 akhn
(cid:2)K
k=1
178
M. Zhang et al.
occupation matrix R =
⎛
r11 r12 . . . r1N
⎜⎜⎜⎝
r21 r22 . . . r2N
...