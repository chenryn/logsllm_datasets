### Hacking Desire: Reverse-Engineering What People Want

**Speaker: Ian Clarke, CEO of Uprizer Labs**

**Contact: PI:EMAIL**

#### Why?

- Everyone has needs and desires.
- If we can predict these, we can provide people with what they want.
- This will make them happy.
- Ultimately, this leads to profit.

#### Specific Problems We Can Solve

- **Music**: Platforms like last.fm, Indy, and Pandora
- **Movies**: Netflix
- **Advertising**: Behavioral advertising
- **Dating**: Matching algorithms

#### Existing Approaches

1. **Item-Based Collaborative Filtering (CF)**
   - **Example**: "People who liked X also liked these"
   - **Pros**:
     - Simple to implement
     - Easy for end-users to understand
   - **Cons**:
     - Naive: Relies on a single piece of information about the user
     - Limited diversity in recommendations

2. **User-Based Collaborative Filtering (CF)**
   - **Example**: "People like you liked these"
   - **Pros**:
     - Can develop a nuanced view of a user’s preferences
     - Easy for end-users to understand
   - **Cons**:
     - Requires a lot of data per user to accurately determine similarity
     - Can be hard to scale: Naive implementation is O(N^2)

#### Representing User Preferences

| Feature | User Preference |
|---------|-----------------|
| Action  | -10.0           |
| Violence| -5.0            |
| Sci-Fi  | 0               |
| Romance | 5.0             |

| Feature | Item Feature (Ian) |
|---------|--------------------|
| Action  | -11.25             |
| Violence| -3.75              |
| Sci-Fi  | 3.75               |
| Romance | 11.25              |

#### Computing User Preferences

- **User Preferences**: A, B, C, D
- **Item Features**: e, f, g, h
- **Rating Calculation**: Rating = Ae + Bf + Cg + Dh
- **Challenge**: How do we determine the values for A, B, C, D, e, f, g, and h?

#### Optimization through Gradient Descent

- **Objective**: Find the optimal solution by gradually moving towards it.
- **Analogy**: Similar to a ball rolling down a hill.
- **Caution**: Be careful of local minima.

#### Choosing Features

- **Question**: How do we decide what the important features of something are?
- **Answer**: We don't need to! The gradient descent algorithm figures it out for us.
- **Outcome**: The algorithm determines what features make sense for accurate predictions.
- **Note**: These features may correspond to qualities we have names for, or they may not.

#### Does It Work?

- **Netflix Prize**: De-facto standard for testing collaborative filters.
- **Data**:
  - 500,000 users
  - 20,000 movies
  - 100 million ratings

#### Root Mean Squared Error (RMSE)

- **Purpose**: Measures prediction accuracy.
- **Calculation**: Mean difference between predicted and actual user ratings.
- **Process**: Square the differences, take the root of their mean.
- **Effect**: Punishes very bad predictions more than simple mean would.
- **Validation**: Uses an unseen "probe set" to prevent memorization.

#### Our Algorithm's Performance

- **Score**: 0.905 on the Netflix probe set.
- **Comparison**: About 5% lower (better) than Netflix's own algorithm.
- **Benchmark**: Some algorithms achieve as low as 0.864.
- **Questions**:
  - How do they achieve this?
  - Can we beat them?
  - Do we want to?

#### Flaws in RMSE Metric

- **Context**: In most CF applications:
  - Predictions matter relative to each other.
  - Accuracy of high predictions is much more important than low predictions.
- **Limitation**: RMSE does not account for these facts.
- **Conclusion**: A better RMSE doesn’t necessarily translate into better real-world performance.