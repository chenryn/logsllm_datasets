描述
析，否则按millis解析
示例
305
---
## Page 330
点处于预备状态中。Coordinator 和 Zookeeper一样，如果全部失效后，将影响新 Segment 的
Druid需要通过Zookeeper管理Segment。
储系统中加载 Segment恢复数据支持查询。深度存储系统可以使用 HDFS、Amazon S3等。
SSD中。
理的方式，就是将最需要被查询的数据放在内存中，超出部分和不常用的数据放在磁盘或
持更多的数据、内存大小提升有限和 SSD技术的发展，Druid采用了内存映射加使用配置管
ThetaSketch为例，启动服务时需要在JVM参数中指定加载对应的扩展包。示例参数如下。
10.
306
部失败了，
3
2.
A.2
-Ddruid.extensions,directory=dist/druid/extensions
-Ddruid.extensions.loadList='["druid-datasketches"]'
millis
posix
iso
格式
Zookeeper会不会因为单点失效影响Druid？
Druid 依赖深度存储系统保存Segment文件。如果历史节点挂掉，Druid则可以从深度存
什么是Druid的深度存储？
Coordinator的运行采用Master/Slave模式，
Coordinator会不会存在单点失效问题？
首先，Zookeeper可以部署为多节点模式，且通常非常可靠。其次，即使Zookeeper全
早期的Druid的确被设计为内存数据库，所有数据都在内存中。后来，由于应用需要支
Druid是内存数据库吗？
当 Schema 中定义有使用扩展包特性时，需要在服务启动时指定加载扩展包。以使用
启动Tranquility-HTTP服务失败？
查询
从1970年1月1日（UTC）开始经过的毫秒数
从1970年1月1日（UTC）开始经过的秒数
描述
ISO8601标准
，Druid的查询部分也可正常对外服务，但是新写人的数据将无法进入系统，因为
即每次只有一个Master工作，多个 Slave节
Druid实时大数据分析原理与实践
1472702400000
2016-09-01T12:00:00+08:00
1472702400
示例
续表
---
## Page 331
查询和摄入的几个地方使用一致的本地时区。
0800"，且内部使用UTC时区作统一计算处理。如果想要使用本地时间，则需要在服务进程、
以写人各种JSON数据。
适合检索的场景。Druid需要预先定义数据的Schema，Elasticsearch则Schema free，因此可
将丢失。Elasticsearch保存原始数据并通过建立倒排索引的方式对文档索引查询，因此非常
节点。
分配和管理，
附录A常见问题（FAQ）
如何处理时区问题？
Druid通过数据预聚合的方式压缩数据并提升访问速度，但是原始数据经过Roll-up
Druid和Elasticsearch的比较？
查询是否会经过Coordinator？
Druid中的时间采用ISO8601格式，表示为日期+时间+时区，例如“2016-01-18T23:41:00+
Coordinator只会参与管理Segment而不参与查询过程，因此查询不会经过Coordinator
·查询时间区段设置。
·查询时区设置。
·Druid批量摄入任务时区设置。
·服务进程时区设置，
的表示方式为前闭后开（即时间范围是大于等于9月1日且小于9月2日）。
该区段表示查询从当地时间的9月1日起到9月2日时间范围内的数据，其中interval
"intervals":["2016-09-01T00:00:00+08:00/2016-09-02T00:00:00+08:00"]
"granularity": {"type”:“period","period”: "“P1D","timeZone":"Asia/Shanghai”}
"jobProperties":{
-Duser.timezone=UTC+0800..
"mapreduce.reduce.java.opts":"-Duser.timezone=UTC+0800....
"mapreduce.map.java.opts":"-Duser.timezone=UTC+0800.."
，但对已有的查询没有影响。
，服务启动时需要增加 JVMopts 参数。
后
307
---
## Page 332
响内存和磁盘的使用比例。如果这个参数的值大于总的内存容量，则很容易引起系统过于频
因此可以综合两方面的数据获得推荐内存配置。Segment数据可用内存大小的计算公式如下：
9.
则供group by查询操作时处理线程使用。Broker节点内存设置注意事项如下：
的内存，因此比较容易遇到内存使用上限的问题。
12.查询实时写人的数据时，数据来源？
繁换页，
10.
8
308
13.
11.
通常思路是从判断是否遇到GC瓶颈人手，聚合查询（比如HyperUnique）会用到更多
为何多次并行聚合查询性能会下降？
查询结果返回为空的原因？
maxSize用于设置一个节点的最大累计Segment大小（单位是字节）。修改这个参数将影
Historical节点配置的maxSize含义？
Historical节点利用堆外内存存储中间计算结果集，并通过内存映射的方式装载Segment。
如何设置Historical节点的内存？
MaxDirectMemorySize >= (processing.numThreads +1) x druid.processing.buffer.sizeBytes
Historical节点内存设置注意事项如下：
memory_for_segments=total_memory-heap-direct_memory-jvm_overhead
MaxDirectMemorySize >= (processing.numThreads + 1) x druid.processing.buffer.sizeBytes
·JVM参数-XX:MaxDirectMemorySize指定最大的堆外内存大小。
Broker节点主要利用JVM堆内内存合并历史节点和实时节点的查询结果，而堆外内存
·未完成切换（Handoff）的Segment数据由实时节点或中间管理者中的Peon提供查询。
·已完成切换（Hand off）的Segment数据将被加载至历史节点中供查询。
·查询的字段不存在。
·数据源不存在。
·JVM参数-XX:MaxDirectMemorySize指定最大的堆外内存大小。
如何设置Broker节点的内存？
查询的数据时间范围不匹配。
，导致查询过慢。
Druid实时大数据分析原理与实践
---
## Page 333
服务访问Druid集群，把权限检查放到代理模块中。
4.Druid如何设置DataSource级别的访问授权？
留时长（只有本地服务器上的Segment才能被查询）。配置参考如下：
管理页面（http://coordinator_ip:port）配置指定DataSource的 Segment 在本地服务器上的保
2.Druid的外部依赖有哪些？
则建议升级到Java8。
1.Druid支持的Java版本？
A.3
附录A常见问题（FAQ）
5.
3.
如何做到Druid服务升级不停止对外服务？
在Druid中如何配置Segment的保留时间？
当前没有比较直接的方式，但是可以通过间接的方式进行访问权限控制。比如设置代理
Druid 中已生成的 Segment会永久存储在 Deep Storage中，但是可以利用Coordinator 的
（4）查询节点
Druid的外部依赖很少，主要是下面三个。
Druid支持Java7，但是大部分应用都已升级到Java 8。如果运行的 JDK还在使用Java7，
（3）中间管理者节点
（2）统治节点
（1）历史节点
升级顺序如下：
·Period Load，只保留最近指定时长内的数据。
·ForeverLoad，永久保留。
·深度存储（HDFS）
Interval Load,
：协调管理（Zookeeper）
·元数据管理数据库（MySQL或PostgreSQL）
管理
只保留指定时间段的数据。
309
---
## Page 334
io.druid.cli.Main tools insert-segment-to-db --workingDir hdfs://host:port//druid/
-Ddruid.metadata.storage.connector.user=druid
-Ddruid.metadata.storage.connector.connectuRI=jdbc\:mysql\://localhost\:3306/druid
集群中。示例如下：
7.
日志和任务日志的循环功能。
6.
310
Cp$DRUID_CLASSPATH
-Ddruid.storage.type=hdfs
-Ddruid.extensions.loadList=[\"mysql-metadata-storage\",\"druid-hdfs-storage\"]
-Ddruid.metadata.storage.connector.password=diurd
-Ddruid.metadata.storage.type=mysql
java
如何将Druid数据转移到另一个Druid中？
由于Druid采用log4j2来记录日志，因此可以通过配置 RollingFile appender来实现服务
如何控制Druid日志大小？
storage/wikipedia--updateDescriptor true
·首先，停止MiddleManager服务状态，通过HTTPPOST请求http://middlemanager_ip:
·设置druid.indexer.task.restoreTasksOnRestart=true，服务重启后可以恢复任务状态。
因为涉及正在处理写入的任务，因此在中间管理者节点中有如下两种方式进行任务恢复。
（5）协调节点
求http://middlemanager_ip:port/druid/worker/v1/enable。
询。最后，重启升级后的 MidleManager服务并开启任务接收，通过HTTP POST请
务已完成，通过HTTPGET请求http://middlemanager_ip:port/druid/worker/v1/tasks查
port/druid/worker/v1/disable，该服务将不再接收新任务。然后，确认该服务的所有任
，它可以帮助将Segment插入到另一个Druid
Druid实时大数据分析原理与实践
---
## Page 335
合器ApproximateHistogram做统计估算。
3.
品A”的独立用户数，可以利用ThetaSketch 聚合器分别求出满足上述两周条件的独立用户
2.如何做留存分析？
1.如何做基数统计？
A.4应用
附录A常见问题（FAQ）
如何求百分位的数据？
比如，在分析性能指标中求处理延迟分别小于50%、90%、95%的数据时，可以利用聚
比如求满足留存条件“第一周来网站浏览过商品A后，第二周又来该网站浏览购买了商
·使用扩展库DataSketch，其基于ThetaSketch算法，支持交集、并集和差集运算，可配
·使用内置聚合器HyperUnique，其基于HyperLogLog算法，支持并集操作，统计结果
误差为2%左右。
置最大去重精度。
311
---
## Page 336
B.1扩展
常用参数表
附录
loadList
druid.extensions.
DruidClasspath
hadoopContainer-
druid.extensions.
enciesDir
hadoopDepend-
druid.extensions.
directory
druid.extensions.
配置项
如果没有设置，则会从“druid.extensions.directory”
配置要加载的扩展列表，它接收JSONArray格式。
配置该项
起Hadoop和Druid的依赖冲突，此时需要显式地
和扩展的路径自动生成的，但在有些情况下，会引
的classpath，默认这个路径是根据Druid的classpath
供了一种方式可以让用户显式地设置hadoop任务
HadoopIndexing启动hadoop任务时，这个配置项提
Maven中Hadoop的coordinate加载相关依赖
存放 Hadoop相关依赖的根目录，Druid 会根据
个目录加载所有扩展
存放Druid扩展相关文件的根目录，Druid会从这
任何扩展
目录下加载所有的扩展，如果配置为”，则不加载
描述
Druid 工作目录的相对
extensions，这是基于
null
null
录的相对路径
这是基于Druid工作目
hadoop-dependencies,
路径
默认值
---
## Page 337
B.2
附录B
druid.zk.paths.indexer.
SegmentsPath
druid.zk.paths.served-
druid.zk.paths.coordi-
QueuePath
druid.zk.paths.load-
SegmentsPath
druid.zk.paths.live-
announcementsPath
druid.zk.paths.
propertiesPath
druid.zk.paths.
druid.zk.service.acl
druid.zk.service.
sessionTimeoutMs
druid.zk.service.
druid.zk.service.host
druid.zk.paths.base
配置项
Classloader
searchCurrent-
druid.extensions.
natorPath
compress
配置项
base
Zookeeper
常用参数表
path中自动搜索扩展，其默认值为 true，如果设置
这是一个布尔型配置，它决定是否在Druid的class-
为false，
描述
索引服务的根目录
已废弃，
用于Coordinator
Segment
历史节点的 loadQueue，
存放Druid
Zookeeper属性路径
布尔型标志，是否在Zookeeper中设置ACL权
否采用压缩
布尔型标志，
Zookeeper的 Session超时时间，单位为毫秒
Zookeeper的host配置，这是必选项
druid在Zookeeper中的根路径
限
描述
告负责处理指定时段的数据
，则不会从classpath加载扩展
功能同liveSegmentsPath
1节点宣告负责的所有Segment
它决定写人Znode中的内容是
的选主操作
用于加载或者卸载
用于节点
${druid.zk.paths.base}
${druid.zk.paths.base)
false
${druid.zk.paths.base}
true
${druid.zk.paths.base}
/servedSegments
$[druid.zk.paths.base}
${druid.zk.paths.base}
/announcements
${druid.zk.paths.base}
30000
/indexer
/coordinator
/loadQueue
/segments
/properties
none
/druid
默认值
true
默认值
续表
313
---
## Page 338
B.4
B.3
314
druid.port
druid.host