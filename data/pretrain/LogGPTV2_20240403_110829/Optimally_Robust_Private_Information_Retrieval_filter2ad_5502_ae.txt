Note that the data is plotted on a log scale so that the
results can be easily compared, even though they span
ﬁve orders of magnitude.
Observe that the Guruswami-Sudan algorithm only
works when the number of Byzantine servers v = k − h
is less than k−(cid:98)√
kt(cid:99), and its running time blows up as v
nears that bound. Past that bound, with more Byzantine
servers, the only prior way for the client to decode the re-
sult was to use the brute-force decoding algorithm. Now,
we can see that our single-polynomial dynamic program-
ming algorithm and our multi-polynomial decoding al-
gorithm both outperform the brute-force algorithm, of-
ten substantially. For example, in Figure 2(c) we see
that for eight Byzantine servers with (k,t) = (20,10),
the Guruswami-Sudan algorithm is ineffective, and the
brute-force algorithm takes about 10 seconds. Mean-
while, our dynamic programming algorithm takes about
1.5 seconds, and our multi-polynomial decoding algo-
rithm takes about 6 milliseconds.
(cid:7) = 8 blocks.
this case, m =(cid:6)
ever, of forcing the client to fetch multiple blocks.
The multi-polynomial algorithm comes at a cost, how-
In
If the client were
going to fetch that many blocks anyway, there is no addi-
tional overhead to the scheme. Otherwise, the client may
have to request some blocks multiple times. In the worst
case, the client only wishes to fetch one block, and there
are v = k − t − 2 Byzantine servers. In this worst case,
h = t + 2, and the client must request its desired block
m = v = k− t − 2 times before it will be able to decode
it. Note that, even when multiple blocks are retrieved
from the servers, our multi-polynomial algorithm is run
only once, in order to distinguish the honest servers from
the misbehaving ones.
v
h−t−1
Figure 2: Timing measurements for the client-side decoding algorithms discussed in this paper for different param-
eters. We ran each algorithm 100 times for each choice of feasible parameters and plot the mean running times in
milliseconds. Note that times are plotted on a log scale.
The three vertical lines on each plot show the unique decoding radius for Reed-Solomon codes, on the left, the the-
oretical bound past which the Guruswami-Sudan algorithm used in Percy++ fails, in the middle, and the theoretical
bound past which efﬁcient decoding with any algorithm is impossible, on the right.
The main results of this paper are to give two client-side decoding algorithms that outperform Guruswami-Sudan in
its feasible region, and allow us to extend the range of efﬁcient client-side decoding to the region of interest between
the two vertical lines on the right. Note that the Guruswami-Sudan algorithm performs much slower in practice than
the Berlekamp-Welch algorithm used by our dynamic programming portfolio algorithm within the unique decoding
radius, and its running time blows up very quickly for parameters approaching its theoretical limit.
The running times of the brute force algorithm within the unique decoding radius have extremely high variance; we
do not plot error bars for those timings as they obscure the entire rest of the plot. We do plot error bars for all other
points, but they are generally too small to see.
 0.01 0.1 1 10 1001,00010,000100,000 0 2 4 6 8 10 12 14 16Time (ms)v (number of Byzantine servers)(a): (k,t) = (20,3) 0.01 0.1 1 10 1001,00010,000100,000 0 2 4 6 8 10 12Time (ms)v (number of Byzantine servers)(b): (k,t) = (20,7) 0.01 0.1 1 10 1001,00010,000100,000 0 1 2 3 4 5 6 7 8 9Time (ms)v (number of Byzantine servers)(c): (k,t) = (20,10) 0.01 0.1 1 10 1001,00010,000100,000 0 1 2 3 4 5Time (ms)v (number of Byzantine servers)(d): (k,t) = (20,14)brute force algorithmlatest version of Percy++ (using Guruswami-Sudan)our single-polynomial dynamic programming algorithm (sec. 5.2)our linear multi-polynomial decoding algorithm (sec. 5.3)unique decoding bound (v = (k-t-1)/2)theoretical limit for Guruswami-Sudan (v = k - √(kt))theoretical limit for polynomial-time decoding (v = k - t - 2)6 Conclusions
We have improved the client side of Goldberg’s 2007
Byzantine-robust information-theoretic private informa-
tion retrieval protocol to use state-of-the-art decoding al-
gorithms to improve the Byzantine robustness of the pro-
tocol to its theoretical limit. We did this using decoding
algorithms that are able to take advantage of decoding
information in multiple blocks of data simultaneously,
observing that in practical scenarios, clients will often be
interested in more than one block at a time.
We implemented our protocol and found that it is very
fast in practice: several thousand times faster than previ-
ous protocols, and usually less than 10 ms for the param-
eter choices in our experiments.
Combined with fast processing on the server side [29]
and scenarios in which the database servers are not in
collusion [28], we can see that information-theoretic pri-
vate information retrieval can be practical even in highly
adversarial settings.
Acknowledgements
We thank Dan Bernstein for pointing out the connections
between multi-polynomial error correction and some
kinds of PIR. We thank Mark Giesbrecht and Arne Stor-
johann for their pointers on implementing polynomial
lattice basis reduction. This material is based upon
work supported by NSERC, Mprime, the National Sci-
ence Foundation under Award No. DMS-1103803, and
the MURI program under AFOSR Grant No. FA9550-
08-1-0352. Finally, we thank the Shared Hierarchical
Academic Research Computing Network (SHARCNET)
and Compute/Calcul Canada for the computing cluster
on which we ran the experiments in Section 5.3 and the
appendix.
References
[1] C. Aguilar Melchor and P. Gaborit. A lattice-
based computationally-efﬁcient private information
In Western European Work-
retrieval protocol.
shop on Research in Cryptology (WEWoRC2007),
Bochum, Germany. Book of Abstracts, pages 50–
54, 2007.
[2] D. Asonov.
Private Information Retrieval: An
In ECDPvA Work-
overview and current trends.
shop, 2001.
rity in Communication Networks (SCN’02), pages
326–341, 2003.
[4] A. Beimel and Y. Stahl. Robust information-
theoretic private information retrieval. Journal of
Cryptology, 20:295–321, 2007.
[5] E. Berlekamp and L. Welch. Error correction of al-
gebraic block codes. US Patent Number 4,633,470,
1986.
[6] R. Carback, D. Chaum, J. Clark, J. Conway, A. Es-
sex, P. S. Herrnson, T. Mayberry, S. Popoveniuc,
R. L. Rivest, E. Shen, A. T. Sherman, and P. L.
Vora. Scantegrity II Municipal Election at Takoma
Park: The First E2E Binding Governmental Elec-
tion with Ballot Privacy. In 19th USENIX Security
Symposium, pages 291–306, 2010.
[7] D. L. Chaum. Untraceable electronic mail, re-
turn addresses, and digital pseudonyms. Commun.
ACM, 24(2):84–90, Feb. 1981.
[8] B. Chor and N. Gilboa. Computationally private
In 29th
information retrieval (extended abstract).
annual ACM Symposium on Theory of Computing
(STOC’97), pages 304–313, 1997.
[9] B. Chor, N. Gilboa, and M. Naor. Private informa-
tion retrieval by keywords. Technical Report TR
CS0917, Department of Computer Science, Tech-
nion, Israel, 1997.
[10] B. Chor, O. Goldreich, E. Kushilevitz, and M. Su-
dan. Private information retrieval. In 36th Annual
IEEE Symposium on Foundations of Computer Sci-
ence (FOCS’95), pages 41 –50, oct 1995.
[11] B. Chor, E. Kushilevitz, O. Goldreich, and M. Su-
dan. Private information retrieval. J. ACM, 45:965–
981, November 1998.
[12] H. Cohn and N. Heninger. Approximate common
divisors via lattices. Cryptology ePrint Archive,
Report 2011/437, 2011. http://eprint.iacr.
org/.
[13] C. Devet, I. Goldberg, and N. Heninger. Optimally
Robust Private Information Retrieval. Cryptology
ePrint Archive, Report 2012/083, 2012.
[14] R. Dingledine, N. Mathewson, and P. Syverson.
In 13th
Tor: the second-generation onion router.
USENIX Security Symposium, 2004.
[3] A. Beimel and Y. Stahl. Robust information-
theoretic private information retrieval. In Proceed-
ings of the 3rd International Conference on Secu-
[15] W. I. Gasarch. A survey on private information re-
trieval (column: Computational complexity). Bul-
letin of the EATCS, 82:72–107, 2004.
[16] Y. Gertner, S. Goldwasser, and T. Malkin. A
Random Server Model for Private Information Re-
trieval. In 2nd International Workshop on Random-
ization and Approximation Techniques in Computer
Science, pages 200–217, 1998.
[17] P. Giorgi, C.-P. Jeannerod, and G. Villard. On the
complexity of polynomial matrix computations. In
2003 International Symposium on Symbolic and Al-
gebraic Computation, pages 135–142, 2003.
[28] F. Olumoﬁn and I. Goldberg. Privacy-preserving
In 10th Inter-
queries over relational databases.
national Privacy Enhancing Technologies Sympo-
sium, pages 75–92, 2010.
[29] F. Olumoﬁn and I. Goldberg. Revisiting the Com-
putational Practicality of Private Information Re-
trieval. In 15th International Conference on Finan-
cial Cryptography and Data Security, pages 158–
172, 2011.
[18] I. Goldberg.
Percy++ project on sourceforge.
Accessed
http://percy.sourceforge.net.
February 2012.
[19] I. Goldberg.
Improving the robustness of private
information retrieval. In 2007 IEEE Symposium on
Security and Privacy, pages 131–148, 2007.
[20] C. Gomes and B. Selman. Algorithm Portfolios.
Artiﬁcial Intelligence, 126(1):43–62, 2001.
[21] V. Guruswami and A. Rudra. Explicit codes achiev-
ing list decoding capacity: Error-correction with
optimal redundancy. IEEE Transactions on Infor-
mation Theory, 54(1):135–150, 2008.
[22] V. Guruswami and M. Sudan. Improved decoding
of Reed-Solomon and algebraic-geometric codes.
39th Annual IEEE Symposium on Foundations of
Computer Science (FOCS’98), pages 28–39, 1998.
[23] E. Kushilevitz and R. Ostrovsky. Replication is not
needed: single database, computationally-private
In 38th Annual Symposium
information retrieval.
on Foundations of Computer Science (FOCS’97),
pages 364–373, 1997.
[24] H. W. Lenstra, A. K. Lenstra, and L. Lov´asz. Fac-
toring polynomials with rational coeﬁcients. Math-
ematische Annalen, 261(4):515–534, 1982.
[25] S. Micali, C. Peikert, M. Sudan, and D. A. Wilson.
Optimal Error Correction Against Computationally
In 2nd Theory of Cryptography
Bounded Noise.
Conference, pages 1–16, February 2005.
[26] P. Mittal, F. Olumoﬁn, C. Troncoso, N. Borisov,
and I. Goldberg.
PIR-Tor: Scalable Anony-
mous Communication Using Private Information
In 20th USENIX Security Symposium,
Retrieval.
pages 475–490, 2011.
[30] F. Olumoﬁn, P. Tysowski, I. Goldberg, and U. Hen-
gartner. Achieving efﬁcient query privacy for lo-
In 10th International Pri-
cation based services.
vacy Enhancing Technologies Symposium, pages
93–110, 2010.
[31] F. Parvaresh and A. Vardy. Correcting errors be-
yond the Guruswami-Sudan radius in polynomial
time. In 46th Annual IEEE Symposium on Founda-
tions of Computer Science (FOCS’05), pages 285–
294, 2005.
[32] I. S. Reed and G. Solomon. Polynomial Codes
Journal of the Soci-
over Certain Finite Fields.
ety for Industrial and Applied Mathematics (SIAM),
8(2):300–304, 1960.
[33] L. Sassaman, B. Cohen, and N. Mathewson. The
Pynchon Gate: a Secure Method of Pseudony-
mous Mail Retrieval. In Proceedings of the 2005
ACM Workshop on Privacy in the Electronic Soci-
ety (WPES ’05), pages 1–9, 2005.
[34] A. Shamir. How to share a secret. Commun. ACM,
22:612–613, November 1979.
[35] V. Shoup. NTL, a library for doing number theory.
http://www.shoup.net/ntl/, 2005. Accessed
February 2012.
[36] R. Sion and B. Carbunar. On the computational
practicality of private information retrieval. In Pro-
ceedings of the Network and Distributed Systems
Security Symposium, 2007.
[37] J. von zur Gathen. Hensel and Newton methods
in valuation rings. Math. Comp., 42(166):637–661,
1984.
[27] T. Mulders and A. Storjohann. On lattice reduc-
tion for polynomial matrices. Journal of Symbolic
Computation, 35(4):377 – 401, 2003.
[38] S. Yekhanin. Towards 3-query locally decodable
codes of subexponential length. J. ACM, 55(1):1–
16, 2008.
(cid:17)m(h−t−1)−v+1
(cid:16) 1|F|
Figure 3: In Section 5.3, we conjectured that the linear multi-polynomial algorithm we present will fail with probability
. We ran several hundred million trials in order to test this conjecture. In plots (a)-(d), we varied a
single parameter, keeping other parameters ﬁxed, and plotted the observed proportion of failures for our linear multi-
polynomial algorithm (black dots, with error bars at the 95% conﬁdence interval) along with the conjectured value
(dotted line). For plot (e) we varied m and used the maximum possible value of v for the given number of polynomials.
 1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.11625665537Proportion of FailuresSize of the Field(a) Varying the Field Size 1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1101112Proportion of Failuresv (Number of Byzantine Servers)(b) Varying the Number of Byzantine Servers 1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1234Proportion of Failuresm (Number of Polynomials)(c) Varying the Number of Polynomials (GF(28)) 1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1345Proportion of Failuresm (Number of Polynomials)(d) Varying the Number of Polynomials (GF(24))Conjectured Failure Rate 0 0.002 0.004 0.006 0.008 0.01 0 5 10 15 20 25 30 35 40Proportion of Failuresm (Number of Polynomials)(e) Varying the Number of Polynomials with Maximum Number of Byzantine ServersAppendix: Failure rate of Algorithm 1
(cid:16) 1|F|
(cid:17)m(h−t−1)−v+1
The linear multi-polynomial algorithm described in Sec-
tion 2.3.2 is probabilistic and may fail with some prob-
ability. We conjecture that the probability of failure is
but do not have a proof. We ran hun-
dreds of millions of tests, varying each of the parameters
in the expression, in order to validate this conjecture ex-
perimentally. Figure 3 contains plots of the results; for
details, see the extended version of this paper [13].
We observe that for large ﬁelds (|F| ≥ 256), our con-
jectured failure rate falls into the 95% conﬁdence interval
of our experimentally observed failure rate for all data
points except 2 of the 39 data points in Figure 3(e). This
is as expected from 95% conﬁdence intervals. However,
for a small ﬁeld (F = GF(24)) our conjecture appears to
consistently underestimate the actual failure rate. This
suggests the presence of an unknown second-order term
in the failure rate; we will be exploring this in future
work.