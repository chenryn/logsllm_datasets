### Data Visualization and Algorithm Performance

The data is plotted on a log scale to facilitate easy comparison, even though the results span five orders of magnitude.

### Guruswami-Sudan Algorithm Limitations

The Guruswami-Sudan algorithm is effective only when the number of Byzantine servers \( v = k - h \) is less than \( k - \left\lfloor \sqrt{kt} \right\rfloor \). As \( v \) approaches this bound, the running time of the algorithm increases significantly. Beyond this bound, with more Byzantine servers, the only prior method for the client to decode the result was to use the brute-force decoding algorithm.

### Comparison with New Algorithms

Our single-polynomial dynamic programming algorithm and our multi-polynomial decoding algorithm both outperform the brute-force algorithm, often by a substantial margin. For example, in Figure 2(c), for eight Byzantine servers with \( (k, t) = (20, 10) \), the Guruswami-Sudan algorithm is ineffective, and the brute-force algorithm takes about 10 seconds. In contrast, our dynamic programming algorithm takes approximately 1.5 seconds, and our multi-polynomial decoding algorithm takes about 6 milliseconds.

### Multi-Polynomial Decoding Cost

The multi-polynomial decoding algorithm comes at a cost, particularly if the client must fetch multiple blocks. If the client was already going to fetch that many blocks, there is no additional overhead. Otherwise, the client may need to request some blocks multiple times. In the worst case, where the client wishes to fetch only one block and there are \( v = k - t - 2 \) Byzantine servers, the client must request its desired block \( m = v = k - t - 2 \) times before it can be decoded. Even when multiple blocks are retrieved, our multi-polynomial algorithm is run only once to distinguish honest servers from misbehaving ones.

### Experimental Results

Figure 2 shows timing measurements for the client-side decoding algorithms discussed in this paper, for different parameters. Each algorithm was run 100 times for each set of feasible parameters, and the mean running times are plotted in milliseconds on a log scale. The three vertical lines in each plot represent:
- The unique decoding radius for Reed-Solomon codes (left),
- The theoretical bound past which the Guruswami-Sudan algorithm used in Percy++ fails (middle),
- The theoretical bound past which efficient decoding with any algorithm is impossible (right).

### Key Contributions

The main contributions of this paper are two client-side decoding algorithms that outperform Guruswami-Sudan within its feasible region and extend the range of efficient client-side decoding to the region of interest between the two rightmost vertical lines. Note that the Guruswami-Sudan algorithm performs much slower in practice than the Berlekamp-Welch algorithm used by our dynamic programming portfolio algorithm within the unique decoding radius, and its running time increases rapidly as parameters approach its theoretical limit.

### Variance in Brute Force Algorithm

The running times of the brute force algorithm within the unique decoding radius have extremely high variance. We do not plot error bars for these timings as they would obscure the rest of the plot. Error bars are plotted for all other points, but they are generally too small to see.

### Conclusions

We have improved the client side of Goldbergâ€™s 2007 Byzantine-robust information-theoretic private information retrieval protocol by using state-of-the-art decoding algorithms, achieving the theoretical limit of Byzantine robustness. Our implementation is very fast in practice, several thousand times faster than previous protocols, and usually less than 10 ms for the parameter choices in our experiments.

### Acknowledgements

We thank Dan Bernstein for pointing out the connections between multi-polynomial error correction and PIR, Mark Giesbrecht and Arne Storjohann for their pointers on implementing polynomial lattice basis reduction, and the Shared Hierarchical Academic Research Computing Network (SHARCNET) and Compute/Calcul Canada for the computing cluster. This work was supported by NSERC, Mprime, the National Science Foundation, and the MURI program.

### References

[References listed as provided in the original text.]

### Appendix: Failure Rate of Algorithm 1

The linear multi-polynomial algorithm described in Section 2.3.2 is probabilistic and may fail with some probability. We conjecture that the failure rate is \( \left( \frac{1}{|F|} \right)^{m(h-t-1)-v+1} \), but we do not have a proof. We ran hundreds of millions of tests to validate this conjecture experimentally. Figure 3 shows the results; for details, see the extended version of this paper [13].

For large fields (\(|F| \geq 256\)), our conjectured failure rate falls within the 95% confidence interval of the experimentally observed failure rate for all data points except two in Figure 3(e). For small fields (\(F = GF(2^4)\)), our conjecture appears to consistently underestimate the actual failure rate, suggesting the presence of an unknown second-order term in the failure rate, which we will explore in future work.