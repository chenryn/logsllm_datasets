uses a static disassembly to weight basic blocks according to
how “deep” they are within a function (e.g., how many condi-
tions have to be satisﬁed to reach this block). Higher scores
are assigned to harder-to-reach blocks. To further improve the
feedback mechanism, VUZZER excludes basic blocks that
belong to error paths by measuring the coverage produced
by random inputs. In the example shown in Figure 1(c), each
basic block has a weight. As can be seen, basic block H has a
much higher weight than basic block G because H is much less
likely to be reached by a random walk across the control-ﬂow
graph (with back-edges removed). Finally, all the weights of
all basic blocks in the path are added up to calculate a ﬁtness
value. VUZZER then uses an evolutionary algorithm to pro-
duce new mutations: inputs with a high ﬁtness value produce
more offspring. These newly created offspring are then used
as the next generation.
2.3 Hybrid Fuzzers
While using coverage-based fuzzing already leads to interest-
ing results on its own, there are code regions in a program
which are hard to reach. This typically happens if only a very
small percentage of the inputs satisfy some conditions. For
example, a speciﬁc four-byte magic value that is checked
by the program under the test makes it nearly impossible
for coverage-based fuzzers to pass the check and therefore
reach deeper code regions. To address this problem, various
research suggest using a combination of program analysis
techniques to assist the fuzzing process [44, 48, 54]. By using
symbolic execution or taint analysis, a fuzzer is able to reason
what inputs are necessary to cover new edges and basic blocks.
Instead of only relying on random mutations and selection
by information gathered through feedback mechanisms, these
tools try to calculate and extract the correct input necessary
for new code coverage. Examples of fuzzers which are using
symbolic or concolic execution to assist the coverage-based
fuzzer are DRILLER [48], QSYM [54], and T-FUZZ [44].
The archetypal hybrid fuzzer is DRILLER, which uses con-
colic execution to search for inputs that produce new coverage.
It tries to provide a comprehensive analysis of the program’s
behaviour. In contrast, QSYM [54] identiﬁed this behavior
as a weakness since the fuzzer can validate that the input
proposed by the symbolic or concolic execution generates
new coverage very cheaply. Therefore, an unsound symbolic
or concolic execution engine can produce a large number
of false positive proposals, without reducing the overall per-
formance of the fuzzer. Building upon this insight, QSYM
discards all but the last constraint in the concrete execution
trace as well as the symbolic values produced by basic blocks
that were executed frequently. Finally, it is worth mentioning
that in the case of T-FUZZ, symbolic execution is not used for
Figure 1: Using coverage information in AFL-like fuzzers versus Vuzzer in
the same path of a given Control-Flow Graph (b).
tion, it increments the corresponding value in the bitmap as
illustrated in Figure 1(a). The bitmap is typically limited to
64KiB, so it easily ﬁts inside an L2 cache [55]. Although
limiting the size of the bitmap allows very efﬁcient updates, it
also reduces its precision, since in some cases multiple edges
share the same index in the bitmap. It is possible to increase
the size of the bitmap, but at the cost of a signiﬁcant decline
in performance [22].
As mentioned earlier, ANGORA uses a very similar scheme
with a slight difference: before updating the bitmap entry, AN-
GORA XORs the edge index with a hash of the call stack. This
way, ANGORA can distinguish the same coverage in different
contexts, while AFL can not. For example, in Listing 1, AFL
cannot distinguish the coverage produced by lines 2 and 3
when called from line 10 from the coverage produced by the
same lines (lines 2 and 3) in the second call. Therefore, AFL
can use feedback to learn that the input should start with “fo”,
however, it cannot use the same information to learn that the
input should continue with “ba”. In contrast, ANGORA can
identify the context (here “fo” and “ba”) of the code and thus
distinguish between these two calls. It is worth to mention
that this drastically increases the number of entries in the
bitmap, and therefore ANGORA might need a bigger bitmap.
Listing 1: A sample code which illustrates the differences between AFL and
ANGORA on distinguishing coverage information
b o o l cmp ( char *a , char *b ) {
}
Vuzzer AFL does not discriminate among edges. There-
fore, an input that covers one previously unseen edge is just
as interesting as an input which covers hundreds of unseen
edges. This is the fundamental difference between VUZZER
i f
( a [0]== b [ 0 ] ) {
( a [1]== b [ 1 ] ) {
return t r u e ;
i f
}
( cmp ( i n p u t , " f o " ) ) {
( cmp ( i n p u t +2 , " ba " ) ) {
1
2
3
4
5
6
7
8
9
10
11
12
13
14
}
return f a l s e ;
}
. . . .
i f
i f
. . . .
}
1934    28th USENIX Security Symposium
USENIX Association
1124111.331001120100(a) Final Bitmap           (b) Control-Flow Graph        (c) Final Fitness: 11.33the fuzzing process itself. Instead, T-FUZZ patches hard con-
straints. Once T-FUZZ ﬁnds a crashing input for the patched
program, it uses symbolic execution to calculate an input that
actually crashes the unpatched target program.
3 Analysis of Fuzzing Assumptions
Based on the categories described in the previous section,
we now analyze and identify fundamental assumptions that
fuzzers use to ﬁnd bugs. The ﬁrst insight is that while many
aspects of fuzzing have changed since 1981, two basic as-
sumptions which were originally made still apply to most
modern fuzzers: these two basic original assumptions are
crash detection and high execution throughput. However, to
achieve better performance in modern fuzzers, additional as-
sumptions were made in the past years, as we discuss next.
To evade not only current but also future bug ﬁnding meth-
ods, we analyze under which core assumptions all (or at least
most) of the current tools operate. By systematically breaking
assumptions shared by most fuzzers, we can develop a more
universal defense against automated audits. Using this system-
atic approach, we avoid targeting speciﬁc implementations
and therefore will hamper all future fuzzing methods built
upon the same general assumptions. We divide the current
fuzzing assumptions into the following four groups:
(A) Coverage Yields Relevant Feedback Coverage-
guided fuzzers typically assume that novel code coverage
also strongly correlates with novel behavior. Therefore, ev-
ery time a modern coverage-guided fuzzer generates an input
which traverses through a new code region, it assumes that the
program behaves differently from previous inputs. Based on
the coverage, the fuzzer decides how much time to allocate for
generating further mutations of this input. For example, most
current fuzzers such as AFL, VUZZER, DRILLER, QSYM,
KAFL, ANGORA, T-FUZZ, and LIBFUZZER use this assump-
tion for coverage-guided fuzzing.
(B) Crashes Can Be Detected Triggering security-
relevant bugs will typically lead to a program crash. Thus,
most bug ﬁnding tools need the ability to tell a crashing input
apart from a non-crashing input in an efﬁcient and scalable
way. As a result, they require some techniques to detect if an
application has crashed. Nearly all random testing tools share
this assumption since 1981 [20]. In addition to the coverage-
guided fuzzers, this assumption is also shared by blind fuzzers
such as PEACH, RADAMSA, and ZZUF.
(C) Many Executions per Second To efﬁciently generate
input ﬁles with great coverage, the number of executions per
second needs to be as high as possible. In our experience,
depending on the application and fuzzer, a range from few
hundreds up to a few thousands of executions per second are
typical. Slow executions will drastically degrade the perfor-
mance. All fuzzers mentioned in the previous assumptions
also fall into this class. Only pure symbolic execution tools
such as KLEE do not fall into this category.
(D) Constraints Are Solvable with Symbolic Execution
Hybrid fuzzers or tools based on symbolic execution such
as DRILLER, KLEE, QSYM, and T-FUZZ need to be able
to represent the program’s behavior symbolically and solve
the resulting formulas. Therefore, any symbolic or concolic
execution-based tools only operate well when the semantics of
the program under test are simple enough. This means that the
internal representation of the state of the symbolic/concolic
execution engine has to be small enough to store and the
resulting constraints set has to be solvable by current solvers
to avoid problems related to state explosion.
Summary We compiled a list of 19 different bug ﬁnding
tools and systematically check which assumptions they rely
on. An overview of the analyzed tools and their corresponding
assumptions is shown in Table 1. It is worth mentioning that
various tools in this table are based on AFL and thus share
the same assumptions.
4
Impeding Fuzzing Audits
Based on the analysis results of the previous section, we now
introduce techniques to break the identiﬁed assumptions of
bug ﬁnding tools in a systematic and generic way. Moreover,
we sketch how these techniques can be implemented; actual
implementation details are provided in the next section.
Attacker Model Throughout this paper, we use the fol-
lowing attacker model. First, we assume that an attacker can
only access the ﬁnal protected binary executable and not the
original source code of the software. She wants to ﬁnd bugs
in an automated way in the protected binary executable, while
requiring only a minimum human intervention. Commonly
there is the notion that source-based fuzzers signiﬁcantly out-
perform binary-only fuzzers. Therefore, it is believed that
defenders already have a signiﬁcant cost advantage over at-
tackers. However, recent advances in fuzzing have shown
that this advantage is in decline. For example, recent binary-
only fuzzing techniques paired with hardware acceleration
technologies such as Intel PT have drastically reduced the
performance gap between binary and source fuzzing. For ex-
ample, Cisco Talos states that the overhead is only 5% to
15% [36] and similar numbers are reported for published Intel
PT-based fuzzers such as KAFL [47]. Additionally, smart
fuzzing techniques outperform source-based fuzzing even in
binary-only targets [8, 54].
Although many relevant software projects are open source,
a large part of all commercial software used in practice is
not available in source code format (e.g., Windows, iOS and
the vast majority of the embedded space). Nonetheless, some
large software projects such as certain PDF viewer and hy-
pervisors are not only well-tested by their developers, but
also by whitehat attackers. This additional attention is an
USENIX Association
28th USENIX Security Symposium    1935
Table 1: Bug ﬁnding tools and the assumptions they rely on.
(A) Coverage Feedback
(B) Detectable Crashes
(C) Application Speed
(D) Solvable Constraints
AFL
KAFL
AFLFAST
COLLAFL
AFLGO
WINAFL
STEELIX
REDQUEEN
HONGGFUZZ
VUZZER
DRILLER
KLEE
ZZUF
PEACH
QSYM
T-FUZZ
ANGORA
RADAMSA
LIBFUZZER





















important factor in their security model. Similarly, projects
that have a history of helpful interactions with independent
researchers should consider not to use ANTIFUZZ, to avoid
scaring researchers away. As an alternative, projects with such
a successful history of community integration can choose to
release unprotected binaries to a set of trusted security re-
searchers. On the other hand, the vast majority of software
gets far less to no attention. These less well-known pieces of
software are still used by many users and they might proﬁt sig-
niﬁcantly from raising the bar against fuzzing (e.g., industrial
controllers such as PLCs [6, 37] or other types of proprietary
software).
Furthermore, in this paper, we consider the case that the
attacker can use any state-of-the-art bug ﬁnding tool. How-
ever, we assume that she spends no time on manually reverse
engineering the binary or building custom tooling. We are
aware that in a more realistic scenario, the target application
might be attacked by a human analyst. However, we assume
that ANTIFUZZ is combined with other techniques that were
developed to incur signiﬁcant cost for human analyst during
reverse engineering [16, 17, 21, 24, 41, 43, 53]. Therefore, to
ensure that different concerns (defending against fuzzing and
defending against analysis by a human) are separated, we
explicitly exclude human analysts from our attacker model.
4.1 Attacking Coverage-guidance
As mentioned previously, the core assumption of coverage-
guided fuzzers is that new coverage indicates new behavior in
the program. To undermine this assumption, we modify the
program which we want to defend against fuzzing by adding
irrelevant code in such a way that its coverage information
drowns out the actual signal. More speciﬁcally, by adding
irrelevant code regions (which we call fake code), we deliber-
ately disturb the code coverage tracking mechanisms within
fuzzers. Thereby, we weaken the fuzzer’s ability to use the
feedback mechanism in any useful way and thus remove their
advantage over blind fuzzers.
To introduce noise into the coverage information, we use
two different techniques. The ﬁrst technique aims at produc-