~ 40%
';
o
0.. 30%
=;f 20%
10%
....~......(cid:173)
........
---~----
4
12
Number of Training Inputs
Figure 2. Variation of False positives rate with different num(cid:173)
ber of training inputs. The rate is <5% with 12 training sets,
motivating the use of 12 inputs for the rest of our experiments.
from external sources. For mcf, a script was used to gener(cid:173)
ate random inputs, while for art, different input options were
used to generate invariants. Since the inputs were predomi(cid:173)
nantly generated randomly, the inputs used for training were
significantly different from the reference inputs, which we
used for testing the false positives, coverage, latency, etc.
5. Experimental Results
In this section, we present our experimental results evaluat(cid:173)
ing the effectiveness of using likely program invariants to de(cid:173)
tect permanent hardware faults. All the injected FPU faults
were architecturally masked in all the applications, except
one floating point benchmark (art). So, we have excluded
the FPU unit results from the reported results, except as oth(cid:173)
erwise noted.
We subject the same application binary (instrumented
with invariant detection) to faults under both the SWAT and
the iSWAT systems. We use the same binary in both cases to
obtain a valid coverage comparison between the two cases
as the behavior of faults (Le., whether they are masked, or
detected, or become SDCs) depends on both static code lay(cid:173)
out and dynamic instruction sequence. In the SWAT sys(cid:173)
tem, since invariants are not monitored, the system ignores
the violation of any invariants and continues execution. The
iSWAT framework, on the other hand, invoked the diagnosis
module in the case of an invariant to determine false posi(cid:173)
tives. If a false positive is detected, it just continues execu(cid:173)
tion (in this case, the invariant will be disabled in the code),
otherwise a fault is detected. 2
5.1 False Positives
We first evaluate the effect of training with different training
sets on the number of false positives.
We define false positive rate to be the fraction of false
positive invariants as a percentage of total number of static
invariants. Figure 2 shows the variation of false positive rate
2 In a real system, iSWAT should check for false positives on every invariant
violation by invoking the rollback/recovery in diagnosis module. However,
since we have ref input available, we currently identify the false positive
invariants using an offline fault-free run and during faulty run, the diagnosis
module uses that information to detect false positives. In this way, we
effectively mimic a real system.
1-4244-2398-9/08/$20.00 ©2008 IEEE
75
DSN 2008: Sahoo et al.
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
for our five applications running on the ref input, as the
number of training inputs is increased from 2 to 12.
As expected, false positive rate decreases as the number
of inputs increases. By 12 inputs, the rate of false positives is
less than 5% for all applications and 0% for three. This false
positive rate is sufficiently low for our purpose, motivating
us to use 12 training inputs for all of our experiments. In
previous work using Siemens benchmarks [4, 22], hundreds
of inputs were used for training. We find much lower num(cid:173)
ber of training inputs suffice for pennanent fault detection
with our approach, as our techniques can tolerate more false
positives.
The maximum number of static invariants in all applica(cid:173)
tions was 231. Assuming each false positive detection has an
overhead of 1M instructions (conservatively computed con(cid:173)
sidering overheads due to checkpoint/replay and context mi(cid:173)
gration), the maximum overhead of false positive detection
on any input will be only 231M instructions, which is neg(cid:173)
ligible considering the application runtimes. In practice, the
overhead will even be lower due to low false positive rates.
Interestingly, Figure 2 shows that after just four inputs,
only less than 10% of the invariants are false positives for
four applications. These results show that likely invariants
generated from many inputs will have sufficiently few false
positives to be usable for pennanent fault detection.
5.2 Coverage
Here, we present the improvements in fault coverage achieved
by the iSWAT system (using 12 inputs for training in(cid:173)
variants) over the SWAT system, evaluated using micro(cid:173)
architecture-level fault injections.
Table 3 presents the improvements offered by iSWAT
over the baseline SWAT system to detect pennanent hard(cid:173)
ware faults. Each column shows the number of fault in(cid:173)
jections that result in different outcomes (both the absolute
number and as a percentage of total number of fault injec(cid:173)
tions) and the last column shows the unknown-fraction. The
first two columns represent faults that are masked by the
architecture (Arch-Mask), and the application (App-Mask).
The Unknown column represents the fraction of faults that
are not detected within 10M instructions in each of the sys(cid:173)
tems. The rest of the columns represent faults that are de(cid:173)
tected by each of the detection mechanisms in 10M in(cid:173)
structions, using the detection methods described previously
(Section 3). We don't show Abort-App in the table, as it does
not detect any fault.
Three points can be observed from this table. First, the in(cid:173)
variant detection is catching nearly 5.8% of total fault injec(cid:173)
tions. Second, the invariant detection is detecting some faults
that are not detected by the traditional symptoms which re(cid:173)
sulted in unknowns in SWAT, thus resulting in a 28.60/0 re(cid:173)
duction of unknown cases from 168 the in SWAT system to
120 in the iSWAT. Third, the iSWAT invariants detect some
faults (about 5% of total fault injections) that are caught
by the other symptoms in SWAT at a lower latency than
Microarchitecture structure
Instruction decoder
Integer ALU
Register bus
Physical integer register file
Reorder buffer (ROB)
Register alias table (RAT)
Address gen unit (AGEN)
Total
SWAT
0.7%
7.8%
4.97%
12.8%
0.9%
2.0%
2.4%
4.0%
iSWAT
0.6%
6.2%
2.6%
8.5%
0.9%
2.2%
1.3%
2.8%
Reduction
16.7%
20.5%
48.3%
33.7%
0.0%
-9.6%
46.1%
28.7%
Table 4. Reduction in Unknown category for each microar(cid:173)
chitectural structure.
Unknown
SWAT
iSWAT
168
120
Seg
fault
102
85
Other
signals
No
output
7
3
28
24
SDC
31
8
Table 5. Breakdown of Unknown category after the comple(cid:173)
tion runs. The "No output" category includes OS hangs, appli(cid:173)
cation hangs and OS crashes.
the other techniques, thus number of detections by other
symptoms in iSWAT are lower compared to SWAT. This re(cid:173)
sult leads to a small improvement in detection latency, as
we show in the subsection 5.4. The overall coverage of the
iSWAT system is 97.2%.
Detection using Invariants: In order to understand the ef(cid:173)
fectiveness of these invariants to detect faults in different
micro-architectural structures, we categorize the unknowns
in the two systems in Table 4. For each structure injected
with faults, the table shows the corresponding percentage of
non-masked faults that result in unknowns in the SWAT, and
iSWAT system, along with the percentage reduction in the
unknowns. The "Total" row shows the aggregate numbers.
These results show that invariants are most effective for
detecting faults in the integer ALU, register databus, integer
register, and AGEN units. These correspond to faults that
affect store values, without significantly perturbing the con(cid:173)
trol and data flow. Invariants are not effective for the decode,
ROB, and RAT units. Faults in these units perturb program
control flow, and do not directly affect values that the invari(cid:173)
ants monitor. Faults in these structures are also very likely
to cause the invariant checking to be done incorrectly. For(cid:173)
tunately, There are a very few remaining unknown cases in
these units. Faults in the RAT show an increased unknown
rate in the iSWAT system as some faults that are masked the
by the application in SWAT, are detected by the invariants in
iSWAT. These are real hardware faults which affect program
values, but are masked at the application level.
Invariants detect all the unknown cases for FPU Unit
faults. Thus the overall unknown-fraction decreases from
4.2% to 2.8%, if we include FPU unit. But, more floating
point applications are needed to draw any conclusions.
5.3 SDCs
A small fraction of faults still result in unknown outcomes
in the iSWAT system (2.8% of the non-masked faults) af(cid:173)
ter 10M instructions. After 10M instructions of detailed tim-
1-4244-2398-9/08/$20.00 ©2008 IEEE
76
DSN 2008: Sahoo et al.
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
Symptoms
App-mask
Arch-Mask
Fatal-Trap
SWAT(%)
iSWAT(%)
293(5.2%)
288(5.2%)
1090(20%)
1090(20%)
-App
1252(22%)
1187(21%)
Fatal-Trap
-as
1421(25%)
1357(24%)
Hang-App
Hang-OS
INV
High-OS
Unknown
47(0.8%)
29(0.5%)
16 (0.3%)
15(0.3%)
-
325(5.8%)
1305(23%)
1181(21%)
168(3.0%)
120(2.1%)
Unknown
-fraction
(4.0%)
(2.8%)
Table 3. Improvement in coverage of iSWAT over SWAT for permanent faults. The percentages are computed using total number
of fault injections as the baseline. Invariants are effective in catching faults that escape the traditional detection techniques in SWAT
and sometimes catching the same faults earlier, resulting in a reduced 2.80/0 unknown-fraction compared to 4% of the SWAT system.
ing simulation, we ran the unknown cases (for all structures
but the FPU) to completion in functional simulation mode
to evaluate how many of the unknown cases result in SDCs.
In this mode, faults are not injected during execution due
to lack of micro-architectural details in the functional sim(cid:173)
ulator. Also, in functional mode, invariants checks are not
enforced by the iSWAT system as we do not have the diag(cid:173)
nosis framework support to detect false positives caused by
invariants. Hence, our reported SDC numbers are conserva(cid:173)
tive estimates of realistic SDC numbers.
layout and dynamic instruction sequence, as they will deter(cid:173)
mine the instruction where fault is injected and how the fault
affects the architectural state.
Table 6. Results when invariant checking is done in simulator.
We refer to the number of cases which result in the same
output as App-Mask and rest of the cases as unknown. Ta(cid:173)
ble 5 shows the breakdown of the total number of unknown
cases according to the results after completion. The next two
columns show segmentation faults and application termina(cid:173)
tions due to other signals. Executions that produce no output
due to an application hang, an OS hang or OS Crash (indi(cid:173)
cated by timing out the execution after a long duration) fall
under the No output category. Finally, the cases that result in
undetected faults that corrupt application outputs are shown
under the SDC category.
Overall, the SDCs in the iSWAT system is significantly
lower than that in SWAT. The invariants reduce the SDCs by
740/0, from 31 to 8. We consider the reduction in the SDCs
as the most important contribution of the invariants. Though
a few SDCs remain, we believe that more sophisticated in(cid:173)
variants can make the SDC cases negligible. The number of
cases detected through other categories also decreases by 27
in iSWAT, which correspond to faults detected by invariants
before the application/OS crash through a signal or hang.
Analysis of SDCs: To do an in-depth analysis of why in(cid:173)
variants don't detect some of the SDC cases, we moved the
invariant checks to the simulator. In this way, we can observe
the monitored values and various other information, which is
not possible when the checks are in code.
To move the invariant checks into the simulator, we per(cid:173)
form an instrumentation pass to store the monitored invari(cid:173)
ant values to known memory locations. The simulator reads
the invariants ranges through a file. When it finds a store
to the known memory location, it can determine the corre(cid:173)
sponding invariant from its memory address and perform the
bounds checking. Table 6 shows the key results, when the
checks are done in the simulator. Overall, there is a 35% re(cid:173)
duction in unknown cases and 47% reduction in SDCs. We
observe a smaller reduction in SDCs compared to the Ta(cid:173)
ble 5. So, the SDC results seem to be sensitive to static code
We analyzed the remaining 17 SDC cases by running both
the correct runs and fault injection runs and comparing the
monitored values. We made some interesting observations:
• In three cases out of 17 (all in mcf), very few invariants
are checked after arch-state mismatch. In fact, in one of
these cases, the faulty run has much fewer checks com(cid:173)