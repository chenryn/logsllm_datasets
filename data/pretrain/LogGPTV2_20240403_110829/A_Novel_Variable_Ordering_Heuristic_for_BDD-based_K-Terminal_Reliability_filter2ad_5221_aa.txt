title:A Novel Variable Ordering Heuristic for BDD-based K-Terminal Reliability
author:Minh Lê and
Josef Weidendorfer and
Max Walter
2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
A Novel Variable Ordering Heuristic for
BDD-based k-terminal Reliability
Minh Lˆe
TU M¨unchen, LRR
M¨unchen, Germany
PI:EMAIL
Josef Weidendorfer
TU M¨unchen, LRR
M¨unchen, Germany
PI:EMAIL
Max Walter
Siemens AG
N¨urnberg, Germany
PI:EMAIL
Abstract—Modern exact methods solving the NP-hard k-
terminal reliability problem are based on Binary Decision Di-
agrams (BDDs). The system redundancy structure represented
by the input graph is converted into a BDD whose size highly
depends on the predetermined variable ordering. As ﬁnding the
optimal available ordering has exponential complexity, a heuristic
must be used. Currently, the breadth-ﬁrst-search is considered
to be state-of-the-art. Based on Hardy’s decomposition approach,
we derive a novel static heuristic which yields signiﬁcantly smaller
BDD sizes for a wide variety of network structures, especially
irregular ones. As a result, runtime and memory requirements
can be drastically reduced for BDD-based reliability methods.
Applying the decomposition method with the new heuristic to
three medium-sized irregular networks from the literature, an
average speedup of around 9,400 is gained and the memory
consumption drops to less than 0.1 percent.
Index Terms—BDD; decomposition; k-terminal reliability; de-
pendability analysis
Submission Category: Network Reliability Assessment
Binary Decision Diagram
A. Abbreviations
BDD
OBDD Ordered Binary Decision Diagram
dfs
bfs
Nw.
depth-ﬁrst-search
breadth-ﬁrst-search
Network
I. INTRODUCTION
For the last ﬁve decades, reliability and availability evalu-
ation of communication networks, power grids or in general,
fault-tolerant system structures has been an issue of interest.
Those systems can be modelled by a combinatorial graph
where the edges represent the network components which may
fail with a certain probability. The nodes in the combinatorial
graph represent network entities or participants that may also
fail. The k-terminal reliability is the probability that each
pair of nodes from a selected set of nodes K (terminal
nodes) can communicate through at least one path of working
edges. In general, the cardinality of K can range between
2 ≤ |K| ≤ |V |, where V is the set of nodes of an input
network. The two special cases where |K| = 2 and |K| = |V |
are called two-terminal and all-terminal respectively. Even
if failures are independent and all nodes are assumed to be
perfect, this problem was shown to be NP-hard [1].
(cid:2)
(cid:2)
Many different exact approaches were conceived to obtain a
solution. They can be classiﬁed into three categories:
a) Category 1: In the ﬁrst category, minimal cuts and
paths1 are enumerated and set-theoretically manipulated by
the sum of disjoint products (SDP) technique [2], [3] in order
to disjoint the path- and cut terms. However, this method
becomes impractical for larger networks since the number of
minimal cuts/paths grows exponentially with the size of the
network.
= K if u, v /∈ K or K
b) Category 2: Chang and Satyanarayana showed that it
is more efﬁcient to use factoring with reductions [4]. The k-
terminal reliability RK of network G can be expressed recur-
sively via the factoring theorem: RK(G) = pe · RK(cid:2) (G ∗ e) +
(1− pe)· RK(G − e), where pe is the reliability of edge e :=
(u, v), G∗e the subgraph for e working and G−e the subgraph
= K − u − v + u ∪ v
for e failed. K
if u ∈ K or v ∈ K. The complexity can be reduced by
applying reductions, e.g. series-parallel reductions or polygon-
to-chain reductions [5], which means that the network size is
reduced while its reliability is preserved. A remarkable result
was obtained by Satyanarayana and Wood [6]: they found a
way to determine the k-terminal reliability for series-parallel
graphs in linear time. Experimental results by Theologou and
Carlier showed the efﬁciency of factoring with reductions [7].
Still, the complexity for factoring with reductions increases
exponentially for larger and denser networks making the
computation already unfeasible for medium-sized networks
consisting of maximum thirty edges. Another drawback is that
a re-factoring must be conducted for the network graph once
the failure probabilities for a few edges has changed.
c) Category 3: To counteract
this disadvantage, ap-
proaches using Binary Decision Diagrams (BDDs) were con-
ceived [8], [9], [10], [11]. BDDs are considered to be the
state-of-the-art data structure to efﬁciently store large Boolean
terms. They were ﬁrst introduced by Akers [12] and fur-
thermore Bryant retrieved their full potential by making key
extensions such as variable ordering and sharing of isomorphic
subgraphs [13]. In the ﬁeld of reliability, BDDs were ﬁrst
used by Rauzy [14] and Coudert [15]. For the terminal-pair
reliability problem, Singh et al. showed how to extract Boolean
1A minimal path is a set of working edges connecting the terminal nodes.
It is minimal since there are no subsets having this property. Minimal paths
are Steiner trees if |K| > 2 and spanning trees if |K| = |V |.
978-1-4799-2233-8/14 $31.00 © 2014 IEEE
DOI 10.1109/DSN.2014.55
527
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:15 UTC from IEEE Xplore.  Restrictions apply. 
functions from the network structure and store them in a BDD
[16]. Kuo, Lu and Yeh employed Ordered BDDs (OBDDs)
and proposed an elegant way to avoid redundant computations
by recognizing isomorphic subgraphs [10]. As soon as the
OBDD is constructed, any performance measure can be easily
obtained by traversing the OBDD. No re-decomposition is
needed in case of probability changes. According to the results
in [10], [17], the Kuo-Lu-Yeh (KLY) algorithm is considerably
more efﬁcient in time and space compared to all algorithms
from category 1 and 2. With regard to undirected networks,
the decomposition method is another very efﬁcient BDD-based
method. It is based on the idea of Rosenthal [18] to classify
the different network states by means of a set of frontier nodes
F . The decomposition method’s complexity mainly depends
on the cardinality of the maximal frontier set Fmax [19]. In
fact, the reliability of networks with bounded |Fmax| can be
computed in time linear to the number of edges [11].
d) Variable ordering heuristics: In general, the complex-
ity of BDD-based reliability algorithms highly depends on the
size of the BDD to be computed. Again, the BDD size is
determined by the chosen variable ordering. Determining good
variable orderings which lead to small BDDs can signiﬁcantly
reduce the complexity of BDD-based reliability algorithms.
Unfortunately, the determination of an optimal ordering is
an NP-complete problem [20]. The best known algorithm for
an optimal variable ordering has complexity O(n23n) [20].
Hence, a set of heuristics were suggested for BDD variable
ordering. They can be grouped into static and dynamic class
of heuristics.
Static heuristics are applied prior to construction of a BDD and
are based on the type of application-speciﬁc input information.
Furthermore, the applicability of static heuristics depend not
only on the representation type but also on the additional
structural information that can be exploited. Unfortunately,
previous static heuristics in [21], [22] cannot be applied to the
network reliability problem since combinational logic circuits
with primary inputs and outputs or ﬁnite state machines are
assumed as initial representations. Thus, Zang et.al. [9] called
for new ordering strategies for the reliability graph analysis
and found dfs to be a good static heuristic. However, empirical
results by Kuo et al. [10] as well as Hardy et al. [11] showed
that the bfs variable ordering is better than dfs in most cases.
The application of dynamic heuristics requires an already built
BDD (see [23]). Kuo et al. [10] tested the post-minimization
sifting heuristic which is known to be one of the most effective
dynamic heuristic. They concluded that the variable swaps are
costly and do not give signiﬁcant beneﬁts.
This work contributes to the former heuristic class: a new static
heuristic will be derived from the decomposition algorithm. In
comparison to the state-of-the-art bfs heuristic, the new heuris-
tic performs signiﬁcantly better on many different network
structures, especially on irregular graphs where much lower
|Fmax| values are obtained. Hence, the new heuristic can lead
to drastic runtime and memory reduction. The new heuristic
can also be applied to other BDD-based reliability methods,
such as the KLY method,
to yield the same effect. Our
measurements further reveal that the decomposition method
in general does not outperform the KLY method with respect
to the bfs-heuristic. However, with regard to the new heuristic,
the decomposition method performs remarkably better than the
KLY method.
After giving some understandings about the combinatorial
model, basics about BDDs and a profound introduction to
the decomposition method in Section II, we will describe the
derivation of the novel heuristic in Section III. In Section IV,
our assertions are afﬁrmed by experimental results on a wide
variety of network structures of different sizes, including two
different sets of randomized networks. Finally, the work is
concluded and an outlook will be given in the last part of this
work.
II. BASICS
A. Formal description of the model

	







	
Fig. 1. Example network G
The redundancy structure of a system to be evaluated is
modelled by an undirected stochastic graph G := (V, E) with
no self-loops, where V stands for a set of vertices or nodes
and E ⊂ V × V a set of unordered pairs of nodes, called
edges with |V | = n, |E| = m. Each edge e ∈ E stands for
a distinct system component which is subjected to failure. In
other words, e can be in two states: either failed or working.
The probability of failure qe := 1−pe is given for each e ∈ E,
where pe is the probability for edge e working. All nodes are
assumed to be perfect. In G we specify a set of nodes K
which are called the terminal nodes: Figure 1 shows a network
with two terminals s and t. The system’s k-terminal reliability
RK is the probability that for any given node v ∈ K there
exists at least one working path from v to all other nodes in
K. A working path is a partial graph2 of G and consists of
only edges associated with working components. Such a path
represents an event (cid:2)x for the modelled system to be in working
state. The network in Figure 1 contains 16 working paths.
XG : (cid:2)x ∈ {0, 1}m → {0, 1} describes a binary random
variable mapping a binary state vector (cid:2)x (event vector) to
value 0/1 when the system is in failed/working state. The i-th
component xi of (cid:2)x can either be 0 or 1, whereas xi = 1 if
edge ei ∈ E
) the partial graph of G.
XG also stands for the set of all possible system events
(cid:2)
with cardinality 2m. Hence the k-terminal reliability is ex-
pressed in terms of RK(G) :=
(cid:2)x∈{0,1}m P(XG((cid:2)x) = 1).
(cid:3)
Since the failures are independent,
it holds P((cid:2)x) =
i=1 ((1 − xi) · qi + xi · pi).
Without loss of generality, the combinatorial undirected graph
2A partial graph of G := (V, E) is a graph G(cid:2) := (V, E(cid:2)) with E(cid:2) ⊆ E.
(cid:2), with G
m
(cid:2)
(cid:2)
:= (V, E
528
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:15 UTC from IEEE Xplore.  Restrictions apply. 
model has no parallel edges since those edges can be reduced
upfront to single edges by parallel reduction.
B. Binary Decision Diagrams
Any Boolean function can be represented by a Binary
Decision Diagram (BDD) which is a directed acyclic rooted
graph having a set of decision nodes N and two leafs labeled
with 0 (false) and 1 (true). Each decision node n ∈ N is
labeled by a Boolean variable b and has two outgoing edges
connected to two child nodes called high child and low child.
The low/high child is reached when b is assigned to 0/1.
Otherwise each BDD node is itself a Boolean function f which
can be decomposed in terms of a Boolean variable b (Shannon
decomposition of f with respect to b):
f = b · fb=1 + ¯b · fb=0,
where fb=1/fb=0 is the high/low child of b.
The size of a BDD representing a Boolean function equals
the number of decision nodes and highly depends on the
variable ordering. A BDD with respect to a certain ordering
is called OBDD. The representation of a Boolean function
in terms of a Reduced OBDD (ROBDD) is canonical [22].
This representation facilitates any Boolean operation such as
AND,OR,NOT=: ◦ on Boolean functions f and g in terms of
a Boolean variable b:
f ◦ g = b · (fb=1 ◦ gb=1) + ¯b · (fb=0 ◦ gb=0).
The complexity for these OBDD compositions is O(|Gf| ·
|Gg|), where Gf (Gg) is the ROBDD graph of f (g) having
|Gf| (|Gg|) decision nodes [22].
C. Decomposition method
The decomposition approach is along with the KLY ap-
proach the currently most efﬁcient approach for exact k-
terminal computation. However, in contrast to the KLY method
its applicability is restricted to undirected networks since
no directed path information is recorded. Its great strength
however is the unsurpassed effective reliability-calculation of
undirected regular networks. In what follows, we explain the
basics of the decomposition approach and thereafter apply it
to our example graph in Figure 1.
The decomposition method is based on factoring and consists
of three parts: ﬁrst, determine a suitable edge ordering. Then,
all edges are consecutively factored according to the stipulated
ordering. Concurrently, the result BDD is iteratively created
until all edges have been factored. Finally, the result BDD is
traversed to obtain the reliability value (see Prob function in
[10]).
1) Boundary set and partitions: Suppose, that the initial
ordering is e1 < e2 < . . . < ek < . . . < em. At
factoring-level k, we have Ek := {e1, e2, . . . , ek} and Ek :=
{ek+1, . . . , em}. The already factored edges are in the set
Ek and have a ﬁxed state (either working or failed). The
edges that still have to be factored are contained in Ek. For
a graph G = (V, E), let A = (Vk, Ek) and B = (Vk, Ek)
be two subgraphs of G with Ek, Ek ⊆ E and Ek ∪ Ek =
E, Ek ∩ Ek = ∅, Vk, Vk ⊆ V and Vk ∪ Vk = V . Furthermore,
Fk := Vk∩ Vk is called the k-th frontier set. The maximal size
of the frontier sets is deﬁned as |Fmax| :=
|Fi|.
i=1 Fi and Vk := (V \ Vk) ∪ Fk.
Thus, we have Vk :=
Subgraph A and its complement B are depicted in Figure
2. On the right side of Figure 2 |Fk| ≥ 2, whereas on the
left side Fk consist of only one vertex, called the articulation
vertex. In this case, the reliability of G can be computed
i=1,2,...,m−1
max
(cid:4)
k





Fig. 2. Left: Articulation vertex, Right: Frontier set Fk.
as R(G) = R(A) · R(B). Rosenthal deﬁned an equivalence
relation for Fk [18]: vertices from Fk are arranged into one
block, if there is a connecting path in A connecting them.
The equivalence classes are uniquely represented by partitions
consisting of at least one block. All vertices in a block can
be seen as being grouped into a single vertex. So Fk are the
vertices needed to encode the current network state in the k-
th level. The partitions describe the connections between the
frontier vertices and also record whether each vertex in Fk is
also connected to any of the terminals K.
At this point we start the computation of the terminal-pair
reliability of the example graph. First we conduct a bfs-
traversal from s to obtain a possible variable ordering: e0 <
e1 < e2 < e3 < e4. Then e0 is taken for factorization. The
ﬁrst frontier set F1 consists of the end nodes of e0. Factoring
[1] for e0 working
on edge e0, we obtain partition [01]
and failed respectively (see Figure 3).3 The blocks that contain
∗ and [0]
∗


	





	








	


