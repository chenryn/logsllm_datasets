compressed sequence in HDFS, to use in our experiments.
The ﬁles are composed of 10M, 20M, 30M, 40M, and 50M
key-value records where they allocate 48GB, 96GB, 144GB,
192GB, and 240GB space, respectively. The size of each data
record is approximately 11KB, and the records are generated by
using two types of data. The ﬁrst part is organized as relational
table. A medical dataset is simulated by using the personal
information of patients, such as name, address, age, doctor’s
name, diagnosis, etc. To this end, 1000 different male and
female ﬁrst and surnames, 32 different treatment groups, and
100 diagnosis types are used by uniform randomly selecting.
The other columns based on numbers (i.e. age, phone and ssn
numbers) are uniformly distributed within their domain ranges.
The second part of the records contains an unstructured text
data that represents the medical history of patients written by
doctors. For this part, we used 10 different real life medical
histories. The key part of each record is also labeled with a
set of security classiﬁcations. In addition, HDFS is set to use
replication factor 3 by achieving approximately 60% load rate.
C. ACFs
We have generated ﬁve ACFs, two predicate, two modiﬁca-
tion and a combination of the ﬁrst four, for experiments. The
ﬁrst one, key ACF, uses the security classiﬁcation labels in the
key of each pair to ﬁlter the unauthorized pairs. The second one,
relational ACF, ﬁlters the records based on the doctor name
column. The third one, sanitization ACF detailed in §VI-B,
uses a regular expression to sanitize phone numbers in the
relational part. The fourth one, redaction ACF, reads a set of
medicine names and transforms the medical history of patients
into list of medicines existing in the medical histories. The
ﬁfth ACF is the combination of ﬁrst four, where the application
order is key, relational, sanitization and redaction ACFs.
The ACFs are ﬁrst generated by means of given conﬁguration
and called from the aspects injected into Hadoop as a part of
the Vigiles system (namely Vigiles implementation). Then, the
same ACFs are implemented in Hadoop source code (namely
integrated implementation) so as to compare the performance
of these two approaches. To this end, all built-in RecordReader
classes of Hadoop are enhanced with ACFs, where four pointcut
methods of these classes are overridden. Note that the integrated
implementation cannot provide the same security guarantees as
Vigiles implementation does because the MapReduce jobs can
contain a custom RecordReader class, which would bypass the
ACFs in the integrated implementation.
By using AspectJ compiler version 1.7.3, the aspects are com-
piled independently of the Hadoop and jobs source code. Then,
the aspects are weaved into hadoop-core-1.1.2.jar, where the
RecordReader methods are called. While the generated ACFs
are running in the aspects, we observed some performance
issues especially for lazy copies. We believe this is due to
poor optimization of AspectJ compiler as analyzed in [25]. To
address this issue, we optimized the functions used in three
phases of ACFs by preventing unnecessary data copy.
D. Queries
We implemented three MapReduce jobs for our experiments.
The ﬁrst job is a selection query that selects the records by
patient name. The second job is ranking query that sorts the
records by the ascending ordered list of doctors having the
most patients. The third job is a statistic query that calculates
the average age of patients with heart disease.
E. Results
We ﬁrstly ran three MapReduce jobs on each data set
described in §VII-B so as to measure the performance without
ACFs (termed raw performance). Fig. 6(a) shows the perfor-
mance of the queries. The ranking and statistic queries run
faster than the selection query because their mappers emit less
data to reducers. During all experiments, the total running time
of the queries is used as our primary metric. Moreover, in a
typical scenario, the ACFs are expected to reduce the data
amount shown to the MapReduce jobs. To run the MapReduce
(a) Performance of Queries
(b) Key ACF overhead
(c) Relational ACF overhead
(d) Sanitization ACF overhead
(e) Redaction ACF overhead
(f) Combination ACF overhead
(g) Key ACF overhead for ranking
(h) Redaction ACF overhead for statistic
(i) Combination ACF overhead for statistic
Fig. 6. Comparison of three setup: No ACF, Integrated ACF and Vigiles ACF
jobs on the same amount of data with the raw performance
experiment, we setup the ACFs not to ﬁlter out the data while
performing all required operations. For example, the key ACF
checks the security labels but do not reduce the data amount.
The main purpose of experiments is to evaluate the per-
formance of (1) the generated ACFs, and (2) the injection
technique. To this end, we have measured the overhead of ACFs
and injection technique by comparing Vigiles implementation
with raw performance—no safety policy is enforced, and
integrated implementation—safety policies are integrated into
Hadoop. Thus, three queries are run on ﬁve datasets when (1)
no ACF is active, (2) the integrated ACFs are active, and (3)
Vigiles ACFs (weaved by AspectJ) are active.
Selection
Ranking
Statistic
Integ.
Vigiles
Integ.
Vigiles
0.38%
1.02%
-0.15%
0.23%
0.53%
1.14%
0.13%
0.63%
7.81%
22.01% 11.27% 21.11% 10.55%
16.68%
28.8%
27.61% 64.98% 63.72% 64.00% 62.15%
29.49% 28.32% 66.25% 64.96% 64.55% 63.98%
Vigiles
1.29%
1.00%
Integ.
0.54%
0.97%
Key
Rel.
San.
Red.
Com.
TABLE I
THE OVERHEADS OF VIGILES AND INTEGRATED IMPLEMENTATION ACFS
The overhead of ACFs: Fig. 6(b), 6(c), 6(d), 6(e) and
6(f) show the running time of selection query. The overhead
of predicate ACFs, key and relational, is almost negligible
(respectively 0.23% and 0.63% on average). On the other hand,
the modiﬁcation ACFs, sanitation and reduction, have 16.68%
and 28.8% overheads due to costly functions used in fetch
phases (i.e., regular expression search and whitelisting via a
hashmap). Tab. I shows the overhead of ACFs for each query
type. The overhead difference between different queries is due
to the difference of queries’ running times (see Fig. 6(a)).
Label ACF
Value ACF
Sanitization ACF
View Creation ACF
Combination ACF
Selection
0.33%
0.48%
7.58%
0.92%
0.90%
TABLE II
Ranking
0.48%
0.16%
8.80%
0.78%
0.79%
Statistic
0.90%
0.49%
8.71%
1.14%
0.7%
THE OVERHEADS OF ASPECTJ INJECTION
The overhead of ACF injection: The overhead of injection
technique is less than 1% in all ACFs expect the sanitization
ACF, where 8.36% overhead is observed on average. We believe
the regular expression based search algorithm underperforms
because of the relatively poor optimization of AspectJ compiler
(see. [25] for the detailed performance analysis of AspectJ).
Tab. II shows the overhead of injection technique for each
query type. Fig. 6(g), Fig. 6(h) and Fig. 6(i) show the running
time of ranking and statistic queries for the key, redaction and
combination ACFs. We observe the similar overheads of ACFs
 0 1000 2000 30001020304050Total Time (sec)Data Size (M records)SelectionRankingStatistic 0 1000 2000 30001020304050Total Time (sec)Data Size (M records)No ACFIntegrated ACFVigiles ACF 0 1000 2000 30001020304050Total Time (sec)Data Size (M records)No ACFIntegrated ACFVigiles ACF 0 1000 2000 30001020304050Total Time (sec)Data Size (M records)No ACFIntegrated ACFVigiles ACF 0 1000 2000 3000 40001020304050Total Time (sec)Data Size (M records)No ACFIntegrated ACFVigiles ACF 0 1000 2000 3000 40001020304050Total Time (sec)Data Size (M records)No ACFIntegrated ACFVigiles ACF 0 1000 20001020304050Total Time (sec)Data Size (M records)No ACFIntegrated ACFVigiles ACF 0 1000 2000 3000 40001020304050Total Time (sec)Data Size (M records)No ACFIntegrated ACFVigiles ACF 0 1000 2000 3000 40001020304050Total Time (sec)Data Size (M records)No ACFIntegrated ACFVigiles ACF(a) Key and Relational ACFs overhead
(b) Sanitation and Redaction ACFs overhead
(c) Combination ACF overhead
Fig. 7. The overhead of injection for multiple users
and injection technique with selection query.
The overhead for multiple users: To compare the perfor-
mance of ACFs and injection technique for multiple MapRe-
duce jobs, we performed another set of experiments. In these
experiments, the selection query is simultaneously run by
multiple users on the dataset containing 10M records when
Vigiles and integrated implementation of ACFs are assigned
to the MapReduce jobs. To run the jobs simultaneously, the
fair scheduler, developed by Zaharia et al. [26], is employed in
Hadoop. The fair scheduler is set to preemptive mode to evenly
assign resources to jobs. We begin with 1 user and exponentially
increase the number of users up to 8. The graphs in Fig. 7
show the performance of two approaches when the selection
query is run. The average performance differences are 0.14%,
0.56%, 0.02% and 0.05% for the key, relational and redaction
ACFs. The performance of integrated implementation is slightly
better than the performance of Vigiles implementation, where
the difference decreases when the number of users increases
due to higher running time of queries. On the other hand, the
performance difference of the sanitization ACF is 7.15%. As
discussed in previous experiments, the sanitization ACF suffers
from the poor compiler optimization of AspectJ.
VIII. CONCLUSION
To our knowledge, Vigiles is the ﬁrst system that provides
a critical security component for MapReduce, FGAC, without
modifying the source code of MapReduce system. It realizes
a modular policy enforcement by rewriting the front-end
API of MapReduce system with RMs. Our empirical results
indicate Vigiles exhibits just 1% overhead compared to the
implementation that modiﬁes Hadoop’s source code.
IX. ACKNOWLEDGEMENTS
This work was partially supported by Air Force Ofﬁce of
Scientiﬁc Research FA9550-12-1-0082, National Institutes of
Health Grants 1R0-1LM009989 and 1R01HG006844, National
Science Foundation (NSF) Grants Career-CNS-0845803, CNS-
0964350, CNS-1016343, CNS-1111529, CNS-1228198 and
Army Research Ofﬁce Grant W911NF-12-1-0558
REFERENCES
[1] J. Dean and S. Ghemawat, “Mapreduce: simpliﬁed data processing on
large clusters,” Commun. ACM, vol. 51, no. 1, pp. 107–113, Jan. 2008.
[2] K. Browder and M. A. Davidson, “The virtual private database in
oracle9ir2,” Oracle Technical White Paper, vol. 500, 2002.
[3] C. Mohan, “History repeats itself: sensible and nonsensql aspects of the
nosql hoopla,” in EDBT. ACM, 2013, pp. 11–16.
[4] F. B. Schneider, “Enforceable security policies,” TISSEC, vol. 3, no. 1,
pp. 30–50, 2000.
[5] K. W. Hamlen, G. Morrisett, and F. B. Schneider, “Computability classes
for enforcement mechanisms,” ACM Trans. Programming Languages
and Systems, vol. 28, no. 1, pp. 175–205, 2006.
[6] M. Stonebraker and E. Wong, “Access control in a relational data base
management system by query modiﬁcation,” in Proceedings of the 1974
Annual Conference - Volume 1, ser. ACM ’74, 1974, pp. 180–186.
[7] S. Rizvi, A. Mendelzon, S. Sudarshan, and P. Roy, “Extending query
rewriting techniques for ﬁne-grained access control,” in SIGMOD, 2004.
[8] K. LeFevre, R. Agrawal, V. Ercegovac, R. Ramakrishnan, Y. Xu, and
D. DeWitt, “Limiting disclosure in hippocratic databases,” in VLDB.
VLDB Endowment, 2004, pp. 108–119.
[9] R. Agrawal, P. Bird, T. Grandison, J. Kiernan, S. Logan, and W. Rjaibi,
“Extending relational database systems to automatically enforce privacy
policies,” in ICDE.
IEEE, 2005, pp. 1013–1022.
[10] S. Chaudhuri, T. Dutta, and S. Sudarshan, “Fine grained authorization
through predicated grants,” in ICDE.
IEEE, 2007, pp. 1174–1183.
[11] A. Rosenthal and E. Sciore, “Extending sqls grant operation to limit
privileges,” in Data and Application Security. Springer, 2002.
[12] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A. Wallach, M. Burrows,
T. Chandra, A. Fikes, and R. E. Gruber, “Bigtable: A distributed storage
system for structured data,” in TOCS, vol. 26, no. 2, p. 4, 2008.
[13] E. Pattuk, M. Kantarcioglu, V. Khadilkar, H. Ulusoy, and S. Mehrotra,
“Bigsecret: A secure data management framework for key-value stores,”
in IEEE CLOUD, 2013.
[14] W. Wei, J. Du, T. Yu, and X. Gu, “Securemr: A service integrity assurance
framework for mapreduce,” in ACSAC.
IEEE, 2009, pp. 73–82.
[15] I. Roy, S. T. V. Setty, A. Kilzer, V. Shmatikov, and E. Witchel, “Airavat:
Security and privacy for mapreduce,” in USENIX, 2010, pp. 20–20.
[16] F. Chen and G. Ros¸u, “Java-MOP: A Monitoring Oriented Programming
environment for Java,” in TACAS, 2005, pp. 546–550.
[17] D. S. Dantas and D. Walker, “Harmless advice,” in POPL, 2006.
[18] K. W. Hamlen and M. Jones, “Aspect-oriented in-lined reference
monitors,” in PLAS, 2008, pp. 11–20.
[19] M. Jones and K. W. Hamlen, “Enforcing IRM security policies: Two
case studies,” in ISI, 2009, pp. 214–216.
[20] K. W. Hamlen, M. M. Jones, and M. Sridhar, “Aspect-oriented runtime
monitor certiﬁcation,” in TACAS, 2012, pp. 126–140.
[21] I. Goldberg, D. Wagner, R. Thomas, and E. A. Brewer, “A secure
environment for untrusted helper applications: Conﬁning the wily hacker,”
in Proceedings of the 1996 USENIX Security Symposium, 1996.
[22] M. Sun, G. Tan, J. Siefers, B. Zeng, and G. Morrisett, “Bringing java’s
wild native world under control,” ACM Trans. Inf. Syst. Secur., 2013.
[23] L. Gong, M. Mueller, and H. Prafullch, “Going beyond the sandbox: An
overview of the new security architecture in the java development kit
1.2,” in USENIX, 1997, pp. 103–112.
[24] G. Kiczales, J. Lamping, A. Mendhekar, C. Maeda, C. Lopes, J. marc
Loingtier, and J. Irwin, “Aspect-oriented programming,” in ECOOP.
SpringerVerlag, 1997.
[25] E. Hilsdale and J. Hugunin, “Advice weaving in aspectj,” in Aspect-
oriented software development. ACM, 2004, pp. 26–35.
[26] M. Zaharia, D. Borthakur, J. S. Sarma, K. Elmeleegy, S. Shenker, and
I. Stoica, “Job scheduling for multi-user mapreduce clusters,” EECS
Department, UC Berkeley, Tech. Rep. USB/EECS-2009-55, 2009.
 0 1000 2000 3000 40001248Total Time (sec)User NumberAspectJ Key ACFIntegrated Key ACFAspectJ Rel. ACFIntegrated Rel. ACF 0 1000 2000 3000 4000 5000 60001248Total Time (sec)User NumberAspectJ San. ACFIntegrated San. ACFAspectJ Red. ACFIntegrated Red. ACF 0 1000 2000 3000 4000 5000 60001248Total Time (sec)User NumberAspectJ Com. ACFIntegrated Com. ACF