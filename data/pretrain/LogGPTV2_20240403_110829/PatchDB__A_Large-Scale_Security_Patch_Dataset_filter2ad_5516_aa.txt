title:PatchDB: A Large-Scale Security Patch Dataset
author:Xinda Wang and
Shu Wang and
Pengbin Feng and
Kun Sun and
Sushil Jajodia
0
3
0
0
0
.
1
2
0
2
.
7
8
9
8
4
N
S
D
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
1
2
0
2
©
0
0
.
1
3
$
/
1
2
/
7
-
2
7
5
3
-
4
5
6
6
-
1
-
8
7
9
|
)
N
S
D
(
s
k
r
o
w
t
e
N
d
n
a
s
m
e
t
s
y
S
e
l
b
a
d
n
e
p
e
D
n
o
e
c
n
e
r
e
f
n
o
C
l
a
n
o
i
t
a
n
r
e
t
n
I
P
I
F
I
/
E
E
E
I
l
a
u
n
n
A
t
s
1
5
1
2
0
2
2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)
PatchDB: A Large-Scale Security Patch Dataset
Xinda Wang†, Shu Wang†, Pengbin Feng∗, Kun Sun, Sushil Jajodia
Center for Secure Information Systems, George Mason University, Fairfax, VA, USA
{xwang44, swang47, pfeng4, ksun3, jajodia}@gmu.edu
Abstract—Security patches, embedding both vulnerable code
and the corresponding ﬁxes, are of great signiﬁcance to vulnera-
bility detection and software maintenance. However, the existing
patch datasets suffer from insufﬁcient samples and low varieties.
In this paper, we construct a large-scale patch dataset called
PatchDB that consists of three components, namely, NVD-based
dataset, wild-based dataset, and synthetic dataset. The NVD-
based dataset is extracted from the patch hyperlinks indexed
by the NVD. The wild-based dataset includes security patches
that we collect from the commits on GitHub. To improve the
efﬁciency of data collection and reduce the effort on manual
veriﬁcation, we develop a new nearest link search method to help
ﬁnd the most promising security patch candidates. Moreover,
we provide a synthetic dataset that uses a new oversampling
method to synthesize patches at the source code level by enriching
the control ﬂow variants of original patches. We conduct a
set of studies to investigate the effectiveness of the proposed
algorithms and evaluate the properties of the collected dataset.
The experimental results show that PatchDB can help improve
the performance of security patch identiﬁcation.
Index Terms—security patch, open source software, dataset
I. INTRODUCTION
A security patch is a set of changes on source code to ﬁx
the vulnerability. Both vulnerable code and the corresponding
ﬁxes are embedded in security patches. Compared to non-
security patches (e.g., performance bug ﬁxes and new fea-
tures), security-related patches usually take higher precedence
to be applied. Hence, security patch identiﬁcation plays a
signiﬁcant role in security research, especially in vulnerability
mitigation and software maintenance. The veriﬁed security
patches can be used to generate signatures for detecting more
vulnerabilities or patch presence [17], [36], [40].
A straightforward method to identify security patches is to
analyze the literal descriptions (e.g., bug reports and commit
messages) using text-mining techniques [15], [16], [26], [43].
However, such identiﬁcation methods are error-prone due to
the poor quality of the textual
information. For instance,
61% of security patches for the Linux kernel do not mention
security impacts in their description or subjects [35]. Instead,
other techniques go a further step by analyzing the source
code of security patches [29], [39], [42]. Nevertheless, this
process requires considerable human effort and expertise.
Although some automatic security patch identiﬁcation tools
have been proposed [31]–[33], they suffer from performance
and generalization issues.
There is an increasing demand for the deployment of a
robust classiﬁer (e.g., deep learning model). To achieve this
†The ﬁrst two authors contributed equally to this work.
∗Corresponding author: Pengbin Feng
978-1-6654-3572-7/21/$31.00 ©2021 IEEE
DOI 10.1109/DSN48987.2021.00030
149
goal, one of the biggest challenges is the lack of sufﬁcient
patch samples in the model learning and testing stages. Most
of the existing patch datasets [18], [20]–[22], [36] have several
limitations. First, the number of publicly available security
patches is not large enough to train the model. Second, those
security patches are collected from single or several speciﬁc
software repositories, leading to biases towards certain types
of software and vulnerabilities. Finally, they focus on speciﬁc
types of security patches (e.g., patches of sanity testing), which
limits the generalization capability of the learned models. As a
result, all these existing public datasets fail to involve complex
and variant patches for learning a general classiﬁer. Also, the
empirical study over those patch datasets may be biased.
In this paper, we construct a large-scale patch dataset called
PatchDB that contains a large number of security patches
and non-security patches in C/C++ languages. It consists
of three datasets, namely, NVD-based dataset, wild-based
dataset, and synthetic dataset. PatchDB not only contains the
veriﬁed security patches indexed by the National Vulnerability
Database (NVD) [5] but also includes a large number of
patches obtained from the wild. Moreover,
to enrich the
patch variants, PatchDB also provides an additional synthetic
patch dataset that is automatically generated from the existing
samples via a new patch oversampling technique. In contrast,
we call the patches in both the NVD-based dataset and the
wild-based dataset as natural patches.
We ﬁrst construct the NVD-based dataset based on the
NVD,
the largest known source for extracting security
patches [20]. In this dataset, around 4K security patches are
collected by crawling reference hyperlinks provided by the
NVD. Note that we focus on the patches in C/C++ projects that
have the largest number of vulnerabilities. The NVD-based
dataset contains many samples of typical severe vulnerabilities,
which are useful for security patch studies.
The patches in the wild-based dataset are collected from
the commits on GitHub. It is well known that around 6-10%
of commits are security patches that are not reported to the
NVD [20], [32]; however, it is time consuming and labor
intensive to manually check if each commit is security-related.
Based on the assumption that in the feature space, the closer a
commit sample is to a veriﬁed security patch, the more likely it
is a security one, we develop a nearest link search algorithm to
ﬁnd an equal number of candidates from the GitHub commits
that are closest to the security patches in the NVD-based
dataset. Then, each candidate is manually veriﬁed as either a
security patch or non-security patch by three security experts
who cross-check their decisions. After ﬁve rounds of this
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:12 UTC from IEEE Xplore.  Restrictions apply. 
data augmentation process, we ﬁnally collect 8K new security
patches and 23K cleaned non-security patches in the wild-
based dataset. Our experiments show that the proportion of
security patches in the candidates identiﬁed by the nearest link
search algorithm is around 30%, which is three times better
than the brute force search (i.e., 6-10%).
PatchDB also provides a synthetic patch dataset, which
is generated based on the above two natural datasets. It is
inspired by the fact that some vulnerability detection studies
use artiﬁcial vulnerabilities (e.g., SARD [8]) to train their
deep learning-based models due to the limited vulnerable code
gadgets [22], [23]. Similarly, patch synthesis could be a useful
approach to help improve the security patch identiﬁcation
or analysis. However, there is no synthetic patch dataset or
patch synthesis algorithm publicly available. Therefore, we
further develop an oversampling method to synthesize patches.
Different from traditional oversampling techniques [11] that
only synthesize instances in the feature space, our method
generates a set of synthetic patches by modifying the critical
statements at the source code level. Since around 70% security
patches involve modiﬁcations of conditional statements (i.e.,
if statements) [24], we focus on enriching the control ﬂow
variants of original patches. Speciﬁcally, we design eight
variants for if statements without affecting the original
program functionality. We develop a tool to automatically
synthesize patches based on these variants. The experimental
results show that synthesizing patches for a limited-size dataset
could improve the performance of automatic security patch
identiﬁcation.
is a large-scale security patch dataset
Overall, our PatchDB dataset has the following distinctive
features: 1) it
that
contains 12K natural security patches, where 4K are from the
NVD-based dataset and 8K are from the wild-based dataset;
2) it covers various types of security patches in terms of code
changes; 3) it provides a cleaned non-security patch dataset
of 23K instances; 4) it provides a synthetic dataset where
the patches are synthesized from the NVD-based dataset and
wild-based dataset; and 5) each natural patch is accessible
on GitHub for further context
information. As far as we
know, PatchDB is the largest dataset that contains NVD-based,
wild-based, and synthetic security patches. Also, we ﬁnd the
8K security patches in the wild-based dataset are silently
published, i.e., not listed in any CVE entries.
composition by classifying security patches into multiple cat-
egories in terms of code changes. The categorization results
of the NVD-based dataset exhibit a long tail distribution with
the high imbalance and our dataset augmentation approach
can alleviate the imbalance by introducing more instances
in the tail. Finally, we verify the usefulness of PatchDB by
showing that the performance of automatic patch analysis can
be improved by adopting the large-scale PatchDB.
In summary, we make the following contributions:
• We construct a large-scale patch dataset called PatchDB
that includes the NVD-based dataset, wild-based dataset,
and synthetic dataset. To the best of our knowledge, we
are the ﬁrst to collect and release a diverse set of patches
at this scale1.
• We develop a dataset augmentation scheme by ﬁnding
the most promising security patch candidates using a
new nearest link search algorithm, which can achieve
better performance than the state-of-the-art approaches
by reducing around 66% efforts on human veriﬁcation.
• We propose a new oversampling technique to synthesize
patches at the source code level. The experimental results
show that synthetic patches are effective for automatic
patch analysis tasks.
• We conduct an empirical study on PatchDB by catego-
rizing security patches based on their code changes. We
also assess the dataset quality and obtain some interesting
observations.
II. BACKGROUND
In this section, we give the deﬁnition of software patches
and illustrate the differences between security and non-security
patches. We also introduce the NVD, which is a reliable
repository for us to extract security patches.
A. Security and Non-Security Patches
A software patch is a set of changes between two versions
of source code to improve security, resolve functionality
issues, and add new features. Security patches address speciﬁc
security vulnerabilities, enhancing the security of the software.
Non-security patches include bug ﬁx patches and new feature
patches. The bug ﬁx patches make the software run more
smoothly and reduce the likelihood of a crash by correcting
the software bugs. The new feature patches add new or update
existing functionality to the software.
On the version control platform like GitHub [3], a commit
can be regarded as a patch. Listing 1 and 2 show an example
of security patch and non-security patch downloaded from
GitHub, respectively. Each patch is identiﬁed by a 20-byte
long hash string and the modiﬁed ﬁle will be recognized by
a line starting with diff --git. The consecutive removed and
added statements (i.e., lines start with - or +) in one patch are
called one hunk. Around the hunk, there are typically several
context lines. One patch may contain more than one hunk over
multiple functions and ﬁles. Listing 1 is a security patch for
1The dataset is available at https://github.com/SunLab-GMU/PatchDB.
Moreover, we conduct a set of experimental studies on
the composition and quality of PatchDB as well as the
effectiveness of our proposed algorithms. We ﬁrst show that
nearest link search can help dramatically reduce human ef-
forts on identifying security patches from the wild. Also, a
larger search range (i.e., more unlabeled GitHub commits)
can increase the identiﬁcation efﬁciency. Second, our dataset
augmentation method outperforms state-of-the-art machine
learning techniques by providing better tolerance to the dis-
tribution discrepancy between the NVD and the wild patches.
Third, our experimental results show that synthetic patches