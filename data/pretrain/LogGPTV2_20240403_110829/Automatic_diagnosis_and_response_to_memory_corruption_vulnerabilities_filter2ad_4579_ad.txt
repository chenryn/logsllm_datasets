licious input. In a Case-II(b) or Case-III crash, we need to
trace back to the corrupting instruction that writes the cor-
rupted data. For convenience, we call an instruction that
uses corrupted data as an address the victim instruction,
denoted as v. The takeover instruction in a Case-III crash
and the faulting instruction in a Case-II(b) crash are both
victim instructions.
4.3 Tracing the Corrupting Instructions
Once a victim instruction v is identi(cid:12)ed, we can obtain
T argetAddr(v), the address that instruction v is trying to
access. Note that the victim instruction cannot be a direct
addressing (e.g., mov 0x12345678, eax) or a constant based
indirect addressing instruction (e.g., mov eax, [0x4321]),
because the addresses involved in such instructions are hard
coded in the read-only code segment and cannot be modi(cid:12)ed
by the attack.
We discuss how to (cid:12)nd the address l where T argetAddr(v)
is stored in the programâ€™s address space using the address-
ing modes of the IA-32 architecture [15].
In the (cid:12)rst sit-
uation, the location where T argetAddr(v) is stored is pre-
dictable and can be determined. For example, when the vic-
tim instruction is ret, it is easy to see that T argetAddr(v)
is stored at the top of the stack. In the second situation,
the victim instruction may use two-level indirect address-
ing mode, and thus the address l where T argetAddr(v) is
stored can also be easily determined. For example, when the
victim instruction is jmp [ebx+esi] (i.e., jump to the ad-
dress retrieved from the memory location at x = ebx+esi),
we can easily infer that the address l must be x. How-
ever, in the third situation, the victim instruction may use
one-level indirect addressing, and the derivation of l is more
complicated. For example, the victim instruction could be
mov [ebx+esi], ebp (i.e., move the value at address x =
ebx+esi to register ebp), where T argetAddr(v) is computed
by adding the values in registers ebx and esi. We currently
rely on binary data dependency analysis to handle this case.
In our experiments, such cases can be easily handled. We
speculate that in many cases, binary analysis technique can
e(cid:11)ectively solve this problem. For example, consider the
following two instructions mov [ebx+esi], ebp; mov eax,
[ebp], where the latter instruction is the victim instruction.
Through binary data dependency analysis, we can easily de-
termine that the address l must be the value of ebx+esi.
However, the general situations where T argetAddr(v) may
be computed from the corrupted data require additional re-
search. In this paper, we show we can at least automatically
identify the unknown vulnerabilities in the (cid:12)rst two situa-
tions and many cases in the third one when we can identify
where T argetAddr(v) is stored, but leave the general solu-
tion to the third situation as future work.
The next issue is to (cid:12)nd out which instruction(s) writes
T argetAddr(v) to address l. The writing instruction is po-
tentially an initial corrupting instruction. We use hardware
watchpoint, which is available in most modern processors,
to (cid:12)nd out the corrupting instruction c. Speci(cid:12)cally, the
monitor sets the hardware watchpoint register to address l
and re-executes the program with the logged messages. The
hardware support in the processor guarantees that an excep-
tion is raised whenever data is written to address l. To ex-
ploit this hardware watchpoint feature, we provide an excep-
tion handler (in the monitor) to intercept such exceptions.
The exception handler inspects if the value being written is
T argetAddr(v). If yes, the exception handler records the
address of the writing instruction. This re-execution, as the
previous executions, will certainly crash. The last writing
instruction that causes the watchpoint exception before the
crash is the corrupting instruction we are looking for.
It is possible that after a data item is corrupted, it is
copied multiple times before (cid:12)nally being written to address
l. We iteratively (cid:12)nd all the instructions that perform the
value propagation and retrieve their respective stack traces.
These provide a history of the propagation of the corrupted
data. In practice, the number of times the corrupted data is
propagated should be very small, which is con(cid:12)rmed in our
evaluation using real world applications.
4.4 Discussions
It is certainly possible that a crash is due to accidental
rather than malicious memory fault. While the algorithm in
the previous section is discussed in the context of malicious
memory attacks, it could be applied to crashes due to both
types of memory faults. Regardless the nature of the fault,
it is triggered by some external messages. Our algorithm
does not need to distinguish between these two types, and
should be able to perform the same type of diagnosis and
locate the source of corruption. This, combined with the
response method to be discussed in Section 5, can potentially
prevent both types of crashes. It would be interesting future
research to evaluate the e(cid:11)ectiveness of our system for both
accidental and malicious memory faults.
Our current approach for tracing memory corruption vul-
nerabilities has a limitation. As discussed earlier, it cannot
guarantee to trace back to the initial corrupting instruction
if the data corrupted by this instruction is transformed in ar-
bitrary ways before being used as a faulty address. Despite
this limitation, our approach has successfully diagnosed the
memory corruption vulnerabilities under attacks in our ex-
perimental evaluation. This shows our approach is useful
in practice.
In our future work, we will investigate other
approaches that have the potential to provide a more gen-
eral solution. One possibility is to trace the attacks through
instructional-level dynamic data dependency analysis, which
can provide detailed information on how the corrupted data
is propagated before the faulting instruction is executed.
5. AUTOMATIC RESPONSE TO ATTACKS
One goal of vulnerability diagnosis is to stop future at-
tacks that exploit the same vulnerability. We use the result
from the vulnerability diagnosis to generate attack signa-
tures, and drop messages that match the attack signatures at
the message (cid:12)lter. In order to reduce false positives (without
increasing false negatives), we use automatically retrieved
program state in combination with the signatures.
The key to responding to (unknown) attacks is to distin-
guish between normal and malicious attack messages. This
falls into the general scope of anomaly detection, and has
been shown to be a very di(cid:14)cult (if not impossible) prob-
lem. The most widely used approach for attack detection is
the use of attack signatures: byte sequences extracted from
existing attacks against a vulnerability. Previously, attack
signatures are generated manually after attack messages are
collected in network sensors. There have been recent ad-
vances in automatic worm signature generation (e.g., Early-
Bird [34], Autograph [17], and Polygraph [26]). These meth-
ods usually rely on simple thresholds (e.g., number of failed
connections) or external ways to classify suspicious (cid:13)ows,
and use message contents from the classi(cid:12)ed (cid:13)ows to extract
worm signatures. These systems work best when there is an
outburst of worm tra(cid:14)c for accurate signature extraction.
However, they are not su(cid:14)cient for non-worm and stealthy
worm attacks. TaintCheck [27] uses an instruction emulator
to capture attack signatures at the cost of high performance
overhead (between 5-35 times). We observe that program
randomization causes an attacked program to crash, which
can be used as a de(cid:12)nitive sign of intrusion. In this section,
we will harness this observation and the results from the vul-
nerability diagnosis to identify and block attacks. This can
be achieved with low overhead due to the non-intrusiveness
of randomization to program execution.
5.1 Basic Message Signature
The basic response scheme is similar to the previous sig-
nature generation schemes in that we use critical byte se-
quences from the attack. Speci(cid:12)cally, we use the result from
the bug diagnosis algorithm from the previous section. Re-
call that the diagnosis method can identify the corrupting
instruction c that is tricked to overwrite critical program
data. As a result, we can obtain the (invalid) address y
that corrupting instruction c tries to write and the value
x that c is writing. The byte sequences x and/or y can
potentially serve as a message signature. We then search
through the logged messages to con(cid:12)rm the validity of these
values. Depending on the attack, both or one of them are
embedded in the malicious messages. With a single set of
attack messages, we can identify the critical byte sequences
in the messages and use them as the signature to block the
attacks. Whenever a message containing the byte sequences
x and/or y is received, the message (cid:12)lter drops it and also
resets the corresponding connection. Thus, this approach al-
lows the application to graciously handle attacks as dropped
connections without having its internal state corrupted.
Attack messages can be altered slightly while still being
successful. For example, in a stack smashing attack, as long
as the corrupted return address falls within the range of the
bu(cid:11)er, the attack can still be successful. Therefore, using
exact values of x and/or y as a signature can be evaded by
such attack variants. To detect such variants, we adopt the
method used in [27], that is, matching only the (cid:12)rst three
bytes in x and/or y in the message.
5.2 Correlating Message Signature with
Program Execution State
A message signature generated from the basic scheme con-
sists of short byte sequences. While previous work has shown
that such signatures can result in very low false positives
(typically under 1%), for servers with high volume of traf-
(cid:12)c, however, even such a low false positive rate may not be
acceptable. To more accurately detect attacks and further
reduce false alarm rate, we propose to correlate the message
that a program receives with its internal program execution
state.
We observe that a network server application can interact
with the external clients in many di(cid:11)erent program states in
order to perform the underlying service protocol. An attack
that aims to exploit a speci(cid:12)c security vulnerability has to
send its attack messages at a speci(cid:12)c server execution state
that exposes the vulnerability. If we can (cid:12)nd out to which
program execution state the attack message must be sent,
we only need to apply the message signature to network
messages received in that state. For all network messages
received in other program execution states, no message (cid:12)l-
tering is necessary. This not only can reduce false posi-
tive rate without decreasing the detection rate, but also can
speed up the message (cid:12)ltering process. For example, if a
bu(cid:11)er over(cid:13)ow vulnerability is exposed to a remote attack
in State X, we only need to inspect messages received in this
vulnerable state.
There is a large amount of state information that is avail-
able inside non-trivial server applications. Assuming that
we understand the semantics of the application, we could
use application speci(cid:12)c states such as the values of cer-
tain critical data variables dynamically retrieved from the
process address space as an indication of application state.
We could also modify the application to explicitly expose
such execution state to the external message (cid:12)ltering mech-
anisms. These application-dependent approaches can be the
most accurate indication of program state. However, such
approaches will require manual intervention and are not ap-
propriate to be used as automatic response to attacks.
Our goal is to automatically and transparently retrieve
program execution state that can be used in combination
with the generated message signatures. Toward this end,
we propose to use the applicationâ€™s call stack trace as an
indication of the server protocol state. An applicationâ€™s call
stack trace should be di(cid:11)erent at di(cid:11)erent state of the server
protocol execution. Thus, the call stack information can be
combined with the message signature to reduce false positive
rate (without decreasing the detection rate).
During the bug diagnosis phase, when a message that
matches the signature is received, we record its current call
stack trace. We abstract out most of the information except
the the chain of function return addresses and the current
program counter as: (pc; retn; : : : ; ret1), where pc is the pro-
gramâ€™s current program counter, and retn; : : : ; ret1 is the
chain of return addresses. Note that pc and the function
return addresses retn; : : : ; ret1 should be transformed into a
canonical form so that they are comparable in di(cid:11)erent ran-
domized versions of the program. During detection phase,
we raise an alarm and drop a connection only when both
of the following conditions are met: (1) when the signature
is matched in the message; and (2) the programâ€™s current
execution state matches the recorded state from the analy-
sis. Depending on the nature of the application protocols
and the size of the call stack, the order of message signa-
ture match and program call stack match can be changed
in order to speed up processing. For applications that re-
ceive a large amount of data, (cid:12)rst inspecting call stack is
better, since we do not need to inspect each and every byte
of the message. For smaller messages, performing message
signature matching (cid:12)rst should be better.
We illustrate the correlated message (cid:12)ltering scheme us-
ing the OpenSSH server as an example. Figure 4 shows
the message receiving states and their corresponding pro-
gram call stack traces for the OpenSSH server while run-
ning the SSH Protocol Version 1 using password authenti-
cation. Message sending states of the server is not shown
here since we are mainly concerned with how to inspect
messages received from a client. The execution states are
shown in ovals and named according to what type of infor-
mation the server is expecting from a remote client. For
example, the state session key is where the server is wait-
ing for the protocol session key from the client. The call
stack trace in di(cid:11)erent receiving states are also shown in
the (cid:12)gure. As we can see, each receiving state has a unique
call stack trace. OpenSSH server has a vulnerability that
can be exploited in the passwd receiving state. In this case,
the generated signature is the three-byte sequence extracted
from the message and the call stack trace (read, do authloop,
do authentication, main). An incoming message is dropped
only when both match conditions are satis(cid:12)ed. The method
incorporates semantics because it not only uses byte se-
quences but also the program execution state.
In Section
7, we show that the combined signature eliminates all false
positives in our experimental evaluation.
6.
IMPLEMENTATION
We have implemented a prototype system with the com-
ponents shown in Figure 2. The monitor, the diagnosis en-
gine and the signature generator are implemented as an inte-
grated user-space program. It uses the Linux ptrace system
facility for controlling application execution. Once our mon-
itor program launches the target application, it suspends it-
version
string
read
main
data
session
key
user
name
read
packet_read_expect
do_ssh1_kex
main
read
packet_read_expect
do_authentication
main
terminal
settings
passwd