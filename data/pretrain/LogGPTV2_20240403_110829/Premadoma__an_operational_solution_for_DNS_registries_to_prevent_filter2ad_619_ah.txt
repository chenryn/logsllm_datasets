We analyze the effects of this imbalance by applying class sub-
sampling, a common machine learning technique. This enables us to
configure a preferred ratio of benign and malicious class instances
in the training data. We name this parameter the distribution spread.
Incomplete ground truth.
Unfortunately, some malicious domains will never appear on a
blacklist. According to [22], 19% of domains registered as part of
malicious campaigns remain undetected.
This incompleteness of the ground truth makes it challenging to
train consistent models. To mitigate this issue, we improve the con-
sistency of the training set by removing registrations with potential
anomalous labelling from the training set. In case the fraction of a
registrant’s domains above a configurable threshold is flagged as
malicious, benign registrations from the same registrant are consid-
ered as potentially missed and therefore removed from the training
set.3 We name this threshold parameter the blacklist incompleteness
(bli).
For instance, a bli score of 100% means that no anomalies are
pruned, whereas a bli score of 80% prunes benign registrations from
a registrant which has more than 80% malicious registrations in the
past.
At the same time we take a non-optimistic approach for ground
truth incompleteness in terms of evaluation. Specifically, we do not
remove these blacklist anomalies while evaluating the predictions.
This strict measure negatively impacts prediction performance
2The features in Table 1 with a checkmark in the cla column are features used for
classification.
3For simplicity, the registrant’s phone number is used here as a proxy for the registrant.
Figure 2: Performance comparison of the different reputation-based prediction models in terms of precision and recall during
the validation phase.
metrics, but is a necessary vantage point for handling real-world
registrations. As a result, some of the false positives reported in this
paper might be read as true positives, which were unfortunately
not flagged by the consulted blacklists.
3.4 Parameter tuning
We look at the following parameters to determine the best reputation-
based model configuration in the validation phase.
The proposed system operates as follows, as illustrated in Fig-
ure 3. First, benign registrations are discarded, while similar black-
listed registrations are clustered together with the aim of represent-
ing “campaigns”. The goal is to obtain a small set of dense clusters
of associated malicious registrations. Next, for each new registra-
tion, the pair-wise distance between the new registration and the
blacklisted registrations is assessed. In case the new registration
belongs distance-wise to one of the malicious clusters, the new
registration is predicted as malicious.
Distribution spread
Blacklist incompleteness (bli)
Training window
0.001 - 100
55-100%
15, 30, 45 and 60 days
For each day in the validation phase (Figure 1), we execute a
training and prediction step to determine the overall performance
of a configuration. Figure 2 shows the performance of each setting
in terms of precision and recall. As depicted, the different configu-
rations achieve a trade-off between precision and recall.
As shown in Figure 2a, a large distribution spread preserves a
class imbalance with a majority of registrations being benign, and
as a result optimizes towards a high precision/low recall trade-off.
Lowering the distribution spread makes malicious registrations
more prominent in the training set, and steadily increases the recall
at the cost of precision.
The 15 day training window achieves a lower recall than train-
ing sets of a longer period, especially for predictors with a high
precision (Figure 2b). This illustrates that the classifier needs suffi-
cient samples to correctly identify and generalize patterns.
As expected, a low threshold for blacklist incompleteness
compensates for the ground truth incompleteness, and achieves a
better recall. This is particularly noticeable in Figure 2c for predic-
tors with a precision above 85%.