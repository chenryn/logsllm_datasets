Figure 9: Graph Generation Summary.
These facts serve as the basic requirements for the scalability of our
approach, since the runtime performance of graph matching and
query is largely dependent upon the number of nodes and graphs,
respectively.
5.3 Classiﬁcation Results
Signature Detection.
We use a multi-label classiﬁcation to identify the malware fam-
ily of the unrecognized malicious samples. Therefore, we expect to
only include those malware behavior graphs, that are well labeled
with family information, into the database. To this end, we rely on
the malware samples from the Android Malware Genome Project
and use them to construct the malware graph database. Conse-
quently, we built such a database of 862 unique behavior graphs,
with each graph labeled with a speciﬁc malware family.
We then selected 1050 malware samples from the Android Mal-
ware Genome Project and used them as a training set. Next, we
would like to collect testing samples from the rest of our collec-
tion. However, a majority of malware samples from McAfee are
not strongly labeled. Over 90% of the samples are coarsely labeled
as “Trojan” or “Downloader”, but in fact belong to a speciﬁc mal-
ware family (e.g., DroidDream). Moreover, even VirusTotal can-
not provide reliable malware family information for a given sam-
ple because the antivirus products used by VirusTotal seldom reach
a consensus. This fact tells us two things: 1) It is a non-trivial
task to collect evident samples as the ground truth in the context of
multi-label classiﬁcation; 2) multi-label malware detection or clas-
siﬁcation is, in general, a challenging real-world problem.
Despite the difﬁculty, we obtained 193 samples, each of which
is detected as the same malware by major AVs. We then used those
samples as testing data. The experiment result shows that our clas-
siﬁer can correctly label 93% of these malware instances.
Among the successfully labeled malware samples are two types
of Zitmo variants. One uses HTTP for communication, and the
other uses SMS. While the former one is present in our malware
database, the latter one was not. Nevertheless, our signature de-
tector is still able to capture this variant. This indicates that our
similarity metrics effectively tolerate variations in behavior graphs.
We further examined the 7% of the samples that were misla-
beled. It turns out that the mislabeled cases can be roughly put into
two categories. First, DroidDream samples are labeled as Droid-
KungFu. DroidDream and DroidKungFu share multiple malicious
behaviors such as gathering privacy-related information and hidden
network I/O. Consequently, there exists a signiﬁcant overlap be-
tween their WC-ADGs. Second, Zitmo, Zsone and YZHC instances
are labeled as one another. These three families are SMS Tro-
ADRDDroidDreamDroidKungFu000000.80.90000.90000.80.70.700000.7000.600.6000.9.........G1G2G4G3G7G8G861G862...G5G60	
  20	
  40	
  60	
  80	
  1	
  4001	
  8001	
  12001	
  Number	
  of	
  Graphs App	
  ID 0	
  10	
  20	
  30	
  40	
  1	
  501	
  1001	
  1501	
  Number	
  of	
  Graphs App	
  ID 0	
  200	
  400	
  600	
  1	
  30001	
  60001	
  90001	
  Number	
  of	
  Nodes Graph	
  ID 0	
  100	
  200	
  300	
  1	
  4001	
  8001	
  12001	
  16001	
  Number	
  of	
  Nodes Graph	
  ID Figure 10: Convergence of Unique Graphs in Benign Apps
jans. Though their behaviors are slightly different from each other,
they all exploit sendTextMessage() to deliver the user’s informa-
tion to an attacker-speciﬁed phone number. Despite the mislabeled
cases, we still manage to successfully label 93% of the malware
samples with a Naïve Bayes classiﬁer. Applying a more advanced
classiﬁcation algorithm will further improve the accuracy.
Anomaly Detection.
Since we wish to perform anomaly detection using our benign
graph database, the coverage of this database is essential. In the-
ory, the more benign apps that the database collects, the more be-
nign behaviors it covers. However, in practice, it is extremely difﬁ-
cult to retrieve benign apps exhaustively. Luckily, different benign
apps may share the same behaviors. Therefore, we can focus on
unique behaviors (rather than unique apps). Moreover, with more
and more apps being fed into the benign database, the database size
grows slower and slower. Figure 10 depicts our discovery. When
the number of apps increases from 3000 to 4000, there is a sharp
increase (2087) of unique graphs. However, when the number of
apps grows from 10000 to 11000, only 220 new, unique graphs are
generated, and the curve begins to ﬂatten.
We built a database of 10420 unique graphs from 11400 benign
apps. Then, we tested 2200 malware samples against the benign
classiﬁer. The false negative rate was 2%, which indicates that
42 malware instances were not detected. However, we noted that
most of the missed samples are exploits or Downloaders. In these
cases, their bytecode programs do not bear signiﬁcant API-level
behaviors, and therefore generated WC-ADGs do not necessarily
look abnormal when compared to benign ones. At this point, we
have only considered the presence of constant parameters in an API
call. We did not further differentiate API behaviors based upon
constant values. Therefore, we cannot distinguish the behaviors
of Runtime.exec() calls or network I/O APIs with varied string
inputs. Nevertheless, if we create a custom ﬁlter for these string
constants, we will then be able to identify these malware samples
and the false negative rate will drop to 0.
Next, we used the remaining 2100 benign apps as test samples to
evaluate the false positive rate of our anomaly detector. The result
shows that 5.15% of clean apps are mistakenly recognized as sus-
picious ones during anomaly detection. This means, if our anomaly
detector is applied to Google Play, among the approximately 1200
new apps per day [4], around 60 apps will be mislabeled as contain-
ing anomalies and be bounced back to the developers. We believe
that this is an acceptable ratio for vetting purpose. Moreover, since
we do not reject the suspicious apps immediately, but rather ask
the developers for justiﬁcations instead, we can further eliminate
these false positives during this interactive process. In addition, as
we add more benign samples into the dataset, the false positive rate
will further decrease.
Figure 11: Detection Ratio for Obfuscated Malware
Further, we would like to evaluate our anomaly detector with
malicious samples from new malware families. To this end, we
retrieve a new piece of malware called Android.HeHe, which was
ﬁrst found and reported in January 2014 [12]. Android.HeHe ex-
ercises a variety of malicious functionalities such as SMS inter-
ception, information stealing and command-and-control. This new
malware family does not appear in the samples from the Android
Malware Genome Project, which were collected from August 2010
to October 2011, and therefore cannot be labeled via signature de-
tection. DroidSIFT generates 49 WC-ADGs for this sample and,
once these graphs are presented to the anomaly detector, a warn-
ing is raised indicating the abnormal behaviors expressed by these
graphs.
Detection of Transformation Attacks.
We collected 23 DroidDream samples, which are all intention-
ally obfuscated using a transformation technique [28], and 2 be-
nign apps that are deliberately disguised as malware instances by
applying the same technique. We ran these samples through our
anomaly detection engine and then sent the detected abnormal ones
through the signature detector. The result shows that while 23 true
malware instances are ﬂagged as abnormal ones in anomaly de-
tection, the 2 clean ones also correctly pass the detection without
raising any warnings. We then compared our signature detection
results with antivirus products. To obtain detection results of an-
tivirus software, we sent these samples to VirusTotal and selected
10 anti-virus (AV) products (i.e., AegisLab, F-Prot, ESET-NOD32,
DrWeb, AntiVir, CAT-QuickHeal, Sophos, F-Secure, Avast, and
Ad-Aware) that bear the highest detection rates. Notice that we
consider the detection to be successful only if the AV can correctly
ﬂag a piece of malware as DroidDream or its variant. In fact, to our
observation, many AV products can provide partial detection re-
sults based upon the native exploit code included in the app pack-
age or common network I/O behaviors. As a result, they usually
recognize these DroidDream samples as “exploits” or “Download-
ers” while missing many other important malicious behaviors. Fig-
ure 11 presents the detection ratios of “DroidDream” across dif-
ferent detectors. While none of the antivirus products can achieve
a detection rate higher than 61%, DroidSIFT can successfully ﬂag
all the obfuscated samples as DroidDream instances. In addition,
we also notice that AV2 produces a relatively high detection ra-
tio (52.17%), but it also mistakenly ﬂags those two clean samples
as malicious apps. Since the disguising technique simply renames
the benign app package to the one commonly used by DroidDream
(and thus confuses this AV detector), such false positives again ex-
plain that external symptoms are not robust and reliable features for
malware detection.
5.4 Runtime Performance
Figure 12 illustrates the runtime performance of DroidSIFT. Specif-
ically, it demonstrates the cumulative time consumption of graph
0 2000 4000 6000 8000 10000 12000 3000 4000 5000 6000 7000 8000 9000 10000 11000 Number of Unique Graphs Number of Benign Apps 0 5 10 15 20 25 Number of Detections Detector ID True Positive False Positive Figure 12: Detection Runtime (s) for 3000
Benign and Malicious Apps
Figure 13: Similarity between Malicious
Graph Pairs.
Figure 14: Similarity between Benign and
Malicious Graphs.
and weighted graph matching.
Our weight generation automatically assign weights to the criti-
cal API labels, based on a training set of homogeneous graph pairs
and heterogeneous graph pairs. Consequently, killProcess(),
getMemoryInfo() and sendTextMessage() with a constant phone
number, for example, are assigned with fairly high weights.
generation, anomaly detection, and signature detection for 3000
apps.
The average detection runtime of 3000 apps is 175.8 seconds,
while the detection for a majority (86%) of apps is completed within
5 minutes. Further, most of the apps (96%) are processed within 10
minutes. The time cost of graph generation dominates the overall
runtime, taking up at least 50% of total runtime for 83.5% of the
apps. On the other hand, the signature and anomaly detectors are
usually (i.e., in 98% of the cases) able to ﬁnish running in 3 minutes
and 1 minute, respectively.
5.5 Effectiveness of Weight Generation and
Weighted Graph Matching
Finally, we evaluated the effectiveness of the generated weights
Then, given a graph pair sharing the same critical API labels,
other than the pairs used for training, we want to compare their
weighted graph similarity with the similarity score calculated by
the standard bipartite algorithm. To this end, we randomly picked
250 homogeneous pairs and 250 heterogeneous pairs.
The results of these comparisons, presented in Figure 13 and Fig-
ure 14, conform to our expectation. Figure 13 shows that for ev-
ery homogeneous pair, the similarity score generated by weighted
graph matching is almost always higher than the corresponding one
computed using standard bipartite algorithm. In addition, the bipar-
tite algorithm sometimes produces an extremely low similarity (i.e.,
near zero) between two malicious graphs of the same family, while
weighted graph matching manages to improve the similarity score
signiﬁcantly for these cases.
Similarly, Figure 14 reveals that between a heterogeneous pair,
the weighted similarity score is usually lower than the one from
bipartite computation. Again, the bipartite algorithm occasionally
considers a benign graph considerably similar to a malicious one,
provided that they share the same API nodes. Such results can
confuse a training system and the latter one thus fails to tell the
differences between malicious and benign behaviors. On the other
hand, weighted graph matching can effectively distinguish a ma-
licious graph from a benign one, even if they both have the same
critical API nodes.
We further attempted to implement the standard bipartite algo-
rithm and apply it to our detectors. We then compared the conse-
quent detection results with those of the detectors with weighted
graph matching enabled. The results show that weighted graph
matching signiﬁcantly outperforms the bipartite one. While the sig-
nature detector using the former one correctly labels 93% of mal-
ware samples, the detector with the latter one is able to only label
73% of them. On the other hand, anomaly detection with the bipar-
tite algorithm incurs a false negative rate of 10%, which is 5 times
greater than that introduced by the same detector using weighted
matching.
The result indicates that our algorithm is more sensitive to criti-
cal API-level semantics than the standard bipartite graph matching,
and thus can produce more reasonable similarity scores for the fea-
ture extraction.
6. DISCUSSION
In this section, we discuss the limitation and potential evasions
of our proposed technique.
6.1 Native Code & HTML5-based Apps
We perform static analysis on Dalvik bytecode to generate the
behavior graphs. In general, bytecode-level static program analysis
cannot handle native code or HTML5-based applications. This is
because neither the ARM binary running on the underlying Linux
nor the JavaScript code executed in WebView are visible from a
bytecode perspective. Therefore, an alternative mechanism is nec-
essary to defeat malware hidden from the Dalvik bytecode.
6.2 Evasion
Learning-based detection is subject to poisoning attacks. To con-
fuse a training system, an adversary can poison the benign dataset
by introducing clean apps bearing malicious features. For exam-
ple, she can inject harmless code intensively making sensitive API
calls that are rarely observed in clean apps. Once such samples are
accepted by the benign dataset, these APIs are therefore no longer
the distinctive features to detect related malware instances.
However, our detectors are slightly different from prior works.
First of all, the features are associated with behavior graphs, rather
than individual APIs. Therefore, it is much harder for an attacker
to engineer confusing samples at the behavioral-level. Second, our
anomaly detection serves as a sanitizer for new benign samples.
Any abnormal behavior will be detected, and the developer is re-
quested to provide justiﬁcations for the anomalies.