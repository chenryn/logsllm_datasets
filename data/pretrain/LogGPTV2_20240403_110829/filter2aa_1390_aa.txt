Attacking Information Visualization System Usability                                  
Overloading and Deceiving the Human 
Gregory Conti 
Mustaque Ahamad 
John Stasko 
College of Computing 
College of Computing 
College of Computing 
Georgia Institute of Technology 
Georgia Institute of Technology 
Georgia Institute of Technology 
ABSTRACT 
Information visualization is an effective way to easily 
comprehend large amounts of data.  For such systems to be truly 
effective, the information visualization designer must be aware of 
the ways in which their system may be manipulated and protect 
their users from attack. In addition, users should be aware of 
potential attacks in order to minimize or negate their effect.  
These attacks target the information visualization system as well 
as the perceptual, cognitive and motor capabilities of human end 
users.  To identify and help counter these attacks we present a 
framework for information visualization system security analysis, 
a taxonomy of visualization attacks and technology independent 
principles for countering malicious visualizations.  These themes 
are illustrated with case studies and working examples from the 
network security visualization domain, but are widely applicable 
to virtually any information visualization system. 
CR Categories: H.5.2 [Information Systems]:  Information 
Interfaces and Presentation - User Interfaces; C.2.3 [Computer-
Communication Networks]:  Network Operations:  Network 
monitoring; 
C.2.0 
[Computer-Communication 
Networks]:  
General - Security and Protection 
Keywords: malicious visualizations, usability attacks, denial of 
information, secure visualization, information visualization 
1 
INTRODUCTION 
Information visualization systems used for decision making must 
be designed with security in mind. Such systems are vulnerable to 
attack, either from malicious entities attempting to overwhelm, 
mislead or distract the human viewer or from non-malicious 
entities that accomplish the same result by accident.  Some might 
believe that today’s systems are not potential targets for attack.  
Clearly there are many domains where security is of minimal 
importance, but increasingly information visualization systems are 
being used to support critical decision making.  For example, 
intelligence analysis, law enforcement, network security and 
business decision-support systems exist in an adversarial 
environment where it is likely that malicious entities are actively 
attempting to manipulate human end users.  We believe that there 
is a clear threat today and there will be a growing problem into the 
foreseeable future.  For information visualization systems to 
maintain relevance security must be considered. Information 
visualization systems inherently have the human tightly coupled 
in the system loop.  In most cases, the human is the decision 
maker who will act upon (or not act upon) the information 
presented and, as a result, the human is a high-payoff and likely 
target.  Any point in the information visualization system may be 
attacked, from data collection to processing to final visualization, 
in order to impact human interpretation.  A “minor” compromise 
of a single bit may have significant impact on the human 
(consider a change in the foreground color of a scatter plot to the 
background color). Major compromises may have far greater 
impact.  Our primary goal is to identify these threats and 
vulnerabilities, as well as develop principles to counter or mitigate 
these attacks.  By identifying the threats and weaknesses of their 
system, designers can make appropriate decisions to mitigate 
these vulnerabilities.   
To see a sample attack in action, consider a visual intrusion 
detection system designed to supplement classical anomaly-based 
and signature-based intrusion detection systems.  Such systems 
are typically co-located with a firewall at the border between the 
internal institutional network and the public Internet.  This 
vantage point allows the system to observe and collect selected 
data from network traffic at entry and egress from the internal 
network.  Our example system collects header data from network 
traffic and visualizes it in real-time.  In particular, it captures the 
source and destination addresses of communicating network 
nodes, network protocols in use, source and destination ports 
(used for process to process communication across an Internet 
Protocol (IP) network, e.g. port 80 for a web server) as well as 
calculates a timestamp for each record.  An adversary may easily 
inject arbitrary data into the visualization system, intermingled 
with legitimate users’ traffic, due to weaknesses in current 
networking protocols.   In our example, the adversary knows the 
system operator on the night shift is red-green colorblind.  They 
also know that the default settings on the visualization system 
map the very common (99+% of traffic) Transmission Control 
Protocol (TCP) to green, the User Datagram Protocol (UDP) to 
blue and the Internet Control Management (ICMP) protocol to 
red.  In addition, the attacker knows that the target node has 
serious ICMP and UDP vulnerabilities.  The attacker waits until 
late in the operator’s shift and launches an ICMP based attack.  
The already tired operator does not notice the red packet amidst 
the much greater noise of green packets.  In this case, the attacker 
took advantage of the visualization system’s color mapping to 
target a specific user, but many other techniques could have been 
used.  We will describe and illustrate these attacks in later 
sections.   
To help combat usability attacks against visualization systems this 
work includes several novel contributions:  a framework for 
information visualization system security analysis, a taxonomy of 
malicious attacks as well as technology independent principles for 
designing information visualization systems that will resist attack.  
We illustrate and validate these contributions with results from the 
design, implementation and real-world use of a visual network 
intrusion detection system [1].   
Copyright is held by the author/owner. Permission to make digital or hard 
copies of all or part of this work for personal or classroom use is granted 
without fee.   Symposium On Usable Privacy and Security (SOUPS) 
2005, July 6-8, 2005, Pittsburgh, PA, USA. 
Information visualization systems are potentially vulnerable to a 
wide spectrum of attacks ranging from overt to subtle.  An 
obvious attack is to simply corrupt the data.  Akin to a denial of 
service (DoS) attack, an attack of this nature is likely to be 
immediately noticed by human users.  While significant, in this 
work we are concerned with the more subtle denial of information 
attack [2].  Denial of information (DoI) attacks target the human 
by exceeding their perceptual, cognitive and motor capabilities.  
They reduce the ability of a human to acquire desired information. 
Even if a traditional DoS attack against a machine is not possible, 
the human utilizing the machine to process information may still 
succumb to a DoI attack [3].  Typically much more subtle (and 
potentially much more dangerous), DoI attacks can actively alter 
the decision making of human visualization system users without 
their knowledge.  More specifically, for any visualization system, 
if an attacker can inject data into the dataset being visualized, or 
otherwise alter the dataflow, there exists the potential to exploit 
vulnerabilities in the human or the machine system.  This 
exploitation can be used to accomplish some or all of the 
following high-level goals (inspired by well-established military 
information operations doctrine [4]):   
• 
Mask a change in objects or actions that the system user 
has observed. 
• 
Block the system user's perception and/or identification 
of objects or actions being introduced into the 
visualization system.  
• 
Reinforce the system user's preconceived beliefs.  
• 
Distract the system user's attention from other activities.  
• 
Overload the visualization system or user’s data 
collection and analytical capabilities.  
• 
Create the illusion of strength where weakness exists.  
• 
Create the illusion of weakness where strength exists.  
• 
Accustom the system user to particular patterns of 
behavior that are exploitable at the time of the malicious 
entities choosing.  
• 
Confuse the system user’s expectations about an 
object’s attributes and actions.  In particular, to effect 
surprise in these areas. 
• 
Reduce the system user's ability gain situational 
awareness and effectively make decisions.  
To accomplish these goals, we make a key assumption:  malicious 
entities may insert data into the dataset being visualized as well as 
deny access to, corrupt or alter the timeliness of data generated 
and communicated by networked data sources. We believe these 
assumptions to be reasonable.  Many visualization systems gather 
information from potentially untrustworthy sources (such as 
unauthenticated Internet users or physically insecure sensors).  In 
addition, data integrity and data availability are likewise 
susceptible to manipulation both in storage and in transit. Current 
cryptographic techniques can, if properly implemented, protect 
the integrity of data, but cannot guarantee availability.  Consider 
that a small network device in the path of data flow can slow 
down or speed up transmission of sensor data despite 
cryptographic protection.  Even more simply, a sensor could be 
unplugged at tactically important times.  Given these assumptions, 
it is important to note that we will not concentrate on the more 
traditional, non-malicious problems associated with designing 
information visualization systems as we believe they are currently 
being addressed.  In most cases the problem of DoI attacks will 
remain even if these issues are addressed.  Nor will we address 
general system attacks designed to broadly compromise as this is 
well addressed by the systems security community. 
We argue that the ultimate goal of attacks against information 
visualization systems is to overload and deceive the human end 
users and force them to make incorrect conclusions and to take 
incorrect actions -- the exact antithesis of the goal of most 
information visualization system designers.  This manipulation 
can be accomplished in a variety of ways, but ultimately these 
attacks corrupt data or alter dataflow in some way. They may 
occur quickly or over a long period at a barely perceptible, low 
level. The manipulation may take place at data generation, in 
transit over a communication network, at rest on a data storage 
device or during processing by a visualization engine.  Attacks 
may be aggressive and essentially deny productive use of the 
system or may be subtle and covertly mislead.  Either way, the 
result of an attack is an inaccurate picture as interpreted by the 
human end user.  We have extensively reviewed these attacks and, 
for purposes of this paper, we will place emphasis on the more 
subtle attacks, but will also provide coverage of interesting more 
aggressive attacks.  Aggressive attacks are almost certain to be 
noticed, but subtle attacks are more insidious and may be 
overlooked for an extended period of time.  As a result, the 
negative impact of these attacks may be far greater. 
The threats to information visualization systems are legion. 
Attackers may range from trusted internal users to external 
competitors and be motivated by competitive advantage, curiosity, 
intelligence gathering, notoriety, intellectual challenge or 
financial gain.  To counter these attackers we argue that the only 
path to secure systems is via a thorough understanding of the 
possible threats and countermeasures.  An effective technique to 
help secure systems is to conduct a threat analysis.  Typically, this 
analysis includes the following elements:  identifying assets you 
wish to protect, brainstorming known threats to the system, 
ranking the threats by severity, choosing how to respond to threats 
and choosing techniques and technologies (if any) to mitigate the 
threats [5].  We will include these elements during the course of 
the paper.   
Section two of this paper discusses related work and places it in 
the field of current research.  Section three presents a general 
framework for information visualization systems security analysis 
and identifies critical assets.   Section four presents a detailed 
taxonomy of attacks. Section five provides countermeasures in the 
form of technology independent principles for information 
visualization designers to protect their systems and users from 
attack.  Section six presents our conclusions and directions for 
future work. 
2 
RELATED WORK 
The uniqueness of this work stems from the comprehensive 
analysis of the weaknesses of visualization systems, and their 
supporting 
data 
flow, 
including: 
data 
sources, 
data 
communications, data storage, processing, presentation and 
human interpretation. A novel taxonomy of attacks is presented as 
well as a technology independent set of design principles to assist 
in countering such attacks.  While each information visualization 
system and technique has inherent strengths and weaknesses (see 
[6] for an excellent survey) most authors do not examine the 
potential of a malicious entity acting upon the system.   
The field of information warfare and the related fields of 
psychological warfare, propaganda and battlefield deception do 
include the notion of external malicious entities.  In general, these 
fields seek to use deliberately false or misleading information to 
change people’s understanding through deception and confusion 
rather than persuasion and understanding [7].  In particular, the 
techniques of distraction, misinformation and disinformation are 
quite relevant, but do not specifically address information 
visualization.  We will consider these applications in our work. 
Information visualization, as an area, involves analysis of data 
sets in which the data is more abstract in nature, having no natural 
physical or geometrical representation [8].  Examples of data 
domains common to information visualization include statistics, 
financial data, text, and software.  Research into the manipulation 
of information visualization systems is relatively uncommon, 
however.  The VizLies special session of several IEEE 
Visualization conferences did address malicious visualization, but 
only in an informal manner, as entertainment at evening social 
functions.  Several researchers have more formally considered the 
notion of malicious visualizations. Tufte addressed such concepts 
as the “lie factor,” disappearing baselines, the difference between 
height and volume in pictograms, misleading or missing scales, 
missing data, design dominating the data and the effect of 3D 
graphics on correct interpretation [9,10,11].  All are valid, but 
anecdotal, instances of malicious visualizations. Tufte further 
explores the boredom, wasted-time and degraded quality and 
credibility of communication by incorrectly utilizing PowerPoint 
presentation software [12,13].  While there are some interesting 
characteristics relevant to malicious visualizations (e.g. degraded 
quality of information and wasted time), these essays deal with 
the limitations of PowerPoint presentations in a non-interactive 
speaker to audience scenario.  Books such as How to Lie with 
Charts [14] and How to Lie with Statistics [15] also explore 
techniques to design presentations and reports that mislead 
audiences or readers.  In a similar vein, researchers such as 
Globus [16] and Bailey [17] focus on how system creators can 
massage their results to mislead audiences. Rogowitz considered 
the application of perceptual rules to preventing “lying with 
visualization.”  He did not consider external malicious entities 
[18].  
 From our perspective, the primary limitation of these works is 
that they focus on techniques the creator of the visualization 
system, business presentation, advertisement or statistical report 
can use to manipulate their audience.  Our work assumes that this 
is not the case and that the creator of the information visualization 
system is non-malicious.  Our malicious entities attempt to attack 
the system itself, it’s data and the human attempting to utilize it.  
They are not the owners or creators of the system in question. 
3 
SYSTEM MODEL 
To best understand how attackers can accomplish the high-level 
goals presented in section one and to analyze how malicious 
visualizations manifest, we developed a generic producer-
consumer information visualization system using a holistic 
systems approach (Figure 1).  This architectural overview is 
useful for identifying assets by decomposing visualization 
systems and applications.  The results can then be used to identify 
and prioritize the implementation of countermeasures. 
The consumer is a combination of a human and machine.  The 
machine presents the information to the human using a 
visualization method that relies on one of the human’s senses 
(typically vision).  The human interacts with the interface using 
motor and speech commands and will draw conclusions based 
upon the information presented.  The producer is the source of the 
data that will be visualized.  In some cases, the producer will 
include a human who interacts with an information system to 