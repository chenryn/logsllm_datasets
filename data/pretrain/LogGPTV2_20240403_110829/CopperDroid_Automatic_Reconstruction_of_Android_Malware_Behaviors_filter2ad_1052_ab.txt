Location update
Battery status
Phone Reboot
Keyboard input
Text, from number
From number, duration
Geospatial coordinates
Amount of battery
Typed text
Table I: Main stimulations and parameters.
OutputStreamWriter out =
new OutputStreamWriter(
openFileOutput("samplefile.txt",
MODE_WORLD_READABLE));
out.write("Data write", 0, 10);
(a) File access behavior at Java level.
open("files/samplefile.txt", 0x20241, 0x180) = 0x1c
read(0x3f, 0x470bec04, 0xf) = 0xf
...
write(0x1c, "Data write", 0xa) = 0xa
(b) File access behavior at system call level.
FS_ACCESS::Creation of "sampefile.txt"
(link, ancillary info: 10 (bytes))
(c) Reconstructed ﬁle access behavior.
Figure 7: CopperDroid behavior reconstruction of a ﬁle access.
events CopperDroid handles is reported in Table I, which also
shows the parameters that can be customized for each event.
B. Value-based Data Flow Analysis
We extended CopperDroid with the ability to abstract a
stream of related low-level events to a more meaningful high-
level behaviors and to recreate resources (e.g., ﬁles, network
communications) associated with an application to enrich Cop-
perDroid’s behavioral reconstruction analyses (see Figure 7(c),
e.g., FS_ACCESS and NET_ACCESS).
To this end, CopperDroid performs a value-based data ﬂow
analysis by building a system call-related data dependency
graph and def-use chains. In particular, each observed sys-
tem call is initially considered as an unconnected node. A
forward slicing algorithm then inserts edges for every inferred
dependence between two calls. As the slicing proceeds, both
nodes and edges are annotated with the system call argument
constraints; these annotations are essential in the creation of
our def-use chains. Def-use chains, where each call is linked
by def-use dependencies, are formed when the output value by
one system call (the deﬁnition, e.g., open, dup, dup2) is the
input value to a following (non-necessarily adjacent) system
call (the use, e.g., write, writev). Therefore, by building a
data dependency graph over the set of observed system calls,
and performing forward slicing, we can recreate ﬁle system-
related events and the actual resources involved. Our analysis
retains deleted ﬁles (unlink) and multiple versions of the
resources with identical ﬁle names. Although we focus this
discussion on ﬁle system-related system calls, a similar process
holds and has been implemented for network-related calls.
9
VI. EVALUATION
Our experimental setup is as follows. We ran unmodiﬁed
Android images on top of the CopperDroid-enhanced emulator.
Each clean image was customized to include personal infor-
mation, such as contacts, SMS texts, call logs, and pictures
to mimic, as closely as possible, a real device. Each analyzed
malware sample was installed in the image and traced via Cop-
perDroid until a timeout was reached (10 minutes by default).
At the end of the analysis, a clean execution environment
is restored to prevent corruptions and side-effects caused by
installing multiple malware samples in the same system. To
limit noisy results, each sample was executed and analyzed
six times: three times without stimulation and three times with
stimulation; single execution results were then merged.
We evaluated CopperDroid on three datasets: two publicly
available [11], [49] and one provided by McAfee [30]. These
datasets are composed of 1,226, 395 and 1,365 samples,
respectively, counting more than 2,900 samples overall.
A. Effectiveness
To evaluate the effectiveness of CopperDroid’s stimulation
approach, we proceeded as follows. First, we analyzed all
the samples without external stimulation. Then, we performed
the stimulation-driven analysis of the same malware sets, as
outlined in Section V-A. A summary of the effects of the
stimulation on the three datasets is presented in Table II;
details of the analysis on the ﬁrst two datasets were presented
in our preliminary workshop work [36], while results on the
McAfee dataset are reported in Table VI (see Appendix A). As
Table II shows, the results of our analysis on the new McAfee
dataset are consistent with our previous and preliminary results
(see Table II and [36]): 836 out of 1365 (61%) McAfee
samples exhibited additional behaviors (see Section V for what
we consider to be a behavior) and, on average, the number
of additional behaviors was roughly 6.5, out of an average
number of exhibited behaviors of 22.8, observed during non-
stimulated executions6. Of course, it is important to understand
whether an observed behavior is new or if it refers to a similar,
previously-observed action (e.g., same network communication
with a different timestamp). Our current approach is simple:
We consider pseudorandom or ephemeral values observed
in speciﬁc behaviors (e.g., the above mentioned timestamp
parameter, or a pseudorandom ID characterized by high a byte
entropy) to refer to an already observed behavior and therefore
to not contribute to the percentage of additional behaviors
observed due to app stimulation. All the other behaviors are
considered to be new or additional and therefore contribute to
the aforementioned percentage. Future work includes building
on recent and promising hierarchical similarities [26] to better
discern among new or additional behaviors.
Table III reports the overall breakdown of the observed
behaviors (see Figure 5) on McAfee dataset. Each row identi-
ﬁes the class of behavior and how many samples over the total
exhibited at least one occurrence of such behavior, without and
with stimulation, respectively. As can be observed the two most
inﬂuenced behavioral class are Access Personal Information
and Make/Alter Call. The ﬁrst is triggered by a non-negligible
6Solutions to quantitatively improve code coverage may be built on top of
[1], [9]), but unfortunately they do not scale well.
symbolic execution (e.g.,
Malware
Dataset
Genome
Contagio
McAfee
Incr. Behav.
(Samples)
Avg.
Increment
Std.
Dev
752/1226 (60%)
289/395 (73%)
836/1365 (61%)
2.9/10.3 (28.1%)
5.2/23.6 (22.0%)
6.5/22.8 (28.5%)
2.4/11.8
3.3/19.8
9.5/30.1
Table II: Summary of stimulation results, per dataset.
Behavior Class
FS Access
Access Pers. Info.
Network Access
Exec. Ext. App.
Send SMS
Make/Alter Call
No Stimulation
889/1365 (65.13%)
558/1365 (40.88%)
457/1365 (33.48%)
171/1365 (12.52%)
38/1365 (2.78%)
1/1365 (0.07%)
Stimulation
912/1365 (66.81%)
903/1365 (66.15%)
461/1365 (33.77%)
171/1365 (12.52%)
42/1365 (3.08%)
55/1365 (4.03%)
Table III: Overall behavior breakdown of McAfee dataset.
number of samples that receive an incoming message sent by
CopperDroid stimulation technique (and exhibits an access to
the user’s personal information, otherwise hidden). The latter
is mostly due to a set of malware that, whenever a call is
received, hide its notiﬁcation to the user. Table V, instead
gives a more detailed overview of single behavioral subclasses
(deﬁned in Section V) and if—and how—they are inﬂuenced
by stimulation.
Lastly, we also ran a number of malware samples with
no, selective, and full stimulation. This experiment aimed at
qualitatively gathering which individual stimulus induced what
amount of incremental behavior, and whether combinations of
stimulation are more effective than individual triggers. Again,
these stimulations are tailored to each malware by analyzing
their Manifest to determine what triggers were possible due
to the permission scheme. We deliberately chose Android
malware samples that in our experiments had the highest,
average and lowest incremental behavior both percentage wise
and amount wise. If several families had the same maximum
amount of incremental behavior we choose the one with
the highest percentage incremental behavior and vice versa.
Lastly we determined the best representative sample from
each family based on the amount and diversity of behaviors.
The results of various stimulations on these malware samples
can be seen in Table IV. With the table we can begin to
see correlations between different stimuli and behaviors. As
Table IV shows, our selective stimulations was able to disclose
a number of additional previously-unseen (e.g., YZHC SMS
stimulation showed access of personal account information)
or already-observed (e.g., SHBreak showed 113 additional
generic execution) behaviors.
B. Performance
In this section we present an evaluation of CopperDroid
overhead through a number of different experiments conducted
on a GNU/Linux Debian 64-bit system equipped with an
Intel 3.30GHz core (i5) and 3GB of RAM. Benchmarking a
multi-layered system, such as Android, in conjunction with a
complex technique, such as CopperDroid (and in an emulated
environment), can be a rather complicated task. For exam-
ple, traditional benchmarking suites based on measuring I/O
10
Sample
Family
Behavior
Class
Behavior
Subclass
Behaviors
No Stim.
Incr. Behavior
Type Stim.
Incr. Behavior
SMS Stim.
Incr. Behavior
Loc. Stim.
Network Access
YZHC
Exec External App
zHash
Access Personal Info
FS Access
Network Access
Exec External App
Access Personal Info
FS Access
Network Access
SHBreak
Exec External App
FS Access
Network Access
Droid KungFu
Exec External App
FS Access
Network Access
Fladstep
Exec External App
FS Access
HTTP
DNS
Generic
Shell
Priv. Escalation
Install APK
Account
Write
HTTP
DNS
Generic
Shell
Priv. Escalation
Install APK
Account
Write
HTTP
Generic
Shell
Install APK
Write
HTTP
Generic
Shell
Install APK
Write
HTTP
Generic
Shell
Install APK
Write
4
1
3
1
2
4
-
414
2
-
1
1
4
4
2
163
3
2
1
4
195
13
1
1
4
3
15
3
1
4
171
-
-
+10 (+433%)
+3(+400%)
-
-
-
-
+2 (+100%)
-
+12 (+1300%)
+3 (+400%)
-
-
-
-
-
+113 (+5750%)
+22 (+2500%)
+4 (+100%)
+353 (+281%)
-
+2 (+300%)
-
-
+197 (+6667%)
-
+17 (+633%)
+5 (+500%)
-
+80 (+47%)
-
-
-
-
+2(+100%)
-
+1(⊥)
-
+5 (+350%)
+1 (⊥)
+3 (+400%)
-
-
-
-
+255 (+257%)
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
-
+1 (+200%)
-
-
+144 (+4800%)
N/A
N/A
N/A
N/A
N/A
Table IV: Incremental behavior induced by various stimuli, N/A means stimulus not possible based on Manifest.
operations are affected by caching mechanisms of emulated
environments. On the other hand, CPU-intensive benchmarks
are meaningless against the overhead of CopperDroid, as it
mainly operates on system calls.
To address such issues, we performed two different bench-
marking experiments. The ﬁrst is a macrobenchmark that tests
the overhead introduced by CopperDroid on common Android-
speciﬁc actions, such as accessing contacts and sending SMS
texts. Because such actions are performed via the Binder
protocol, these tests give a good evaluation of the overhead
caused by CopperDroid’s Binder analysis infrastructure. The
second set of experiments is a microbenchmark that measures
the computational time CopperDroid needs to analyze a subset
of interesting system calls.
To execute the ﬁrst set of benchmarks, we created a
ﬁctional Android application that performs generic tasks, such
as sending (SEND_SMS) and reading (SMS) texts, accessing
local account information (GET_ACC), and reading all contacts
(CONTACTS). We then ran the test application for 100 itera-
tions and collected the average time required to perform these
operations under three different settings: on an unmodiﬁed
Android emulator (i.e., without CopperDroid—baseline), on a
CopperDroid-enhanced emulator with CopperDroid conﬁgured
to monitor the test application (the common setting when
analyzing a piece of malware—CD (targeted)), and on a
CopperDroid-enhanced emulator with CopperDroid conﬁgured
to track system-wide events (CD (full)). Results are reported
in Figure 8 (A). As can be observed, the overhead introduced
by the targeted analysis is relatively low, respectively ≈ 26%,
≈ 32%, ≈ 24% and ≈ 20%. On the other hand, system-
wide analyses increase the overhead considerably (>2x). This
is due to the of the number of Android components that are
concurrently analyzed.
The second set of experiments measure the average time
CopperDroid requires to inspect a subset of interesting system
calls. This experiment collected more than 150,000 system
calls obtained by running apps and subjecting them to arbitrary
(and artiﬁcial) workloads. As tracking a system call requires
to intercept entry and exit execution points, we report such
measures separately in Figure 8 (B) (the average times are
0.092ms for entry and 0.091ms for exit).
VII. RELATED WORK
In this section we cite and compare similar works related
to CopperDroid. First off, DroidScope [43] is a framework
to create dynamic analysis tools for Android malware that
trades off simplicity and efﬁciency for transparency: as an
out-of-the-box approach, it instruments the Android emulator,
but it may incur high overhead (for instance, when taint-
tracking is enabled). DroidScope leverages a 2-level VMI [20]
to gather information about the system and exposes hooks and
a set of APIs, which enabled the development of plugins to
perform both ﬁne and coarse-grained analyses (e.g., system
call, single instruction tracing, and taint tracking). In contrast
with CopperDroid, DroidScope offers a set of instrumentation
points that analyses can build upon to intercept interesting
events and does not perform any behavioral analysis per-se.
For example, a tool leveraging DroidScope can intercept every
system call executed on an Android system, but would still
11
A
B
Figure 8: Binder Macrobenchmark (A) and System Call Microbenchmark (B).
Behavior Class
Network Access
FS Access
Access Personal Info.
Exec. External App.
Send SMS
Make/Alter Call
Subclass
Generic
HTTP
DNS
Write
SMS
Phone
Accounts
Location
Generic
Priv. Esc.
Shell
Inst. APK
—
—
No Stim.
483
309
416
889
32
510
51
143
132
103
73
8
38
1
Stim
489
318
416
912
266
559
672
147
132
103
73
8
42
55
Table V: Behavior breakdown on the Android malware samples
provided by McAfee.
need to do its own VMI to inspect the parameters of each call.
Following this principle, CopperDroid could have been built
on top of DroidScope, but at the time we implemented it, the
DroidScope framework was not publicly available. Moreover,
the main focus of our research is not to illustrate how to build a
framework or a clever VMI technique for Android systems, but
rather to point out how a proper system call-centric analysis—
which still includes a thorough IPC and RPC Binder-related
protocol analysis as well as automatic and seamlessly complex
Android object reconstructions—and stimulation technique can
comprehensively expose Android malware behaviors.
Enck et al. presents TaintDroid [14], a framework to enable
dynamic taint analysis for Android applications. TaintDroid’s
main goal is to track how sensitive information ﬂow between
the system and applications, or between applications, to au-
tomatically identify leaks. Because of the complexity of the
Android system, TaintDroid relies on different levels of instru-
mentation to perform its analyses. For example, to propagate
taint information through native methods and IPC, TaintDroid
patches JNI call bridges and the Binder IPC library. TaintDroid
is both extremely effective, as it allows it to propagate tainting
between many different levels, and efﬁcient, as it does that with
a very low overhead. Unfortunately, the price to pay is low
resiliency and transparency: modifying internal components of
Android inevitably exposes TaintDroid to a series of detection
12
and evasions techniques [10], [37], [38]. For instance, even
applications with standard privileges can detect TaintDroid’s
presence by calculating checksums over instrumented and
readable components. Moreover, TaintDroid cannot track the
taintedness of native code. Conversely, applications that can
escalate their privileges can go even further: identifying and
disabling TaintDroid’s hooks and analysis. Furthermore, the
decision to modify internal components exposes TaintDroid to
the issues deriving from constantly adapting the analysis code
to highly-mutable architecture as the Android OS.
AppsPlayground [35] performs a much granular stimula-
tion than CopperDroid, but its full capabilities require non-
negligible modiﬁcations to the Android framework (e.g., to
capture image identiﬁers in GUI elements). It also does not
analyze native code (with the exception of speciﬁc and known
low-level signatures, such as known root exploits), and inte-
grates a number of well-known techniques (e.g., TaintDroid),
inheriting their limitations, e.g. non-negligible modiﬁcation of
the Android runtime and limited taint-tracking when analyzing
malicious apps [10]. PuppetDroid [21] (as AppsPlaygrounds)
is an interesting approach to stimulate Android apps with
stimulation traces gathered from crowdsourcing. It is more
effective than CopperDroid with respect to stimulation, but
limited to the subset of apps for which there exists a similar
recorded stimulation trace. The downside, however, is that
the overhead of PuppetDroid is signiﬁcantly high whereas
CopperDroid does not require any modiﬁcation to the Android
OS (nor runtime).This avoids dealing with the ever-evolving
Android runtime system.
DroidBox is a dynamic, in-the-box, Android malware an-
alyzer [40] that leverages custom instrumentation of the An-
droid system and kernel to track a sample’s behavior through
TaintDroid’s taint-tracking of sensitive information [14]. Using
TaintDroid and instrumenting Android’s internal components
makes DroidBox prone to the problems of in-the-box analyses:
malware can detect, evade, or even disable them.
Andrubis [28] is an extension to the Anubis dynamic
malware analysis system to analyze Android malware [5],
[24]. According to its web site, it is mainly built on top of
both TaintDroid [14] and DroidBox [40] and it thus shares
their weaknesses (mainly due to operating “into-the-box”). In
addition, Andrubis does not perform any stimulation-based
analysis, limiting its effectiveness in discovering interesting
Android-speciﬁc behaviors.
DroidMOSS [46] relies on signatures to detect malware in
app markets. Similarly, DroidRanger [48] and JuxtApp [22]
identify known mobile malware repackaged into other apps.
Although successful, signature-based techniques does limit the
detection effectiveness to only known malware. In [15], Enck
et al. studied Android permissions found in a large dataset of
Google Play apps to understand their security characteristics.
Such an understanding is an interesting starting point for
designing techniques to enforce security policies [42] and
avoid the installation of apps requesting a dangerous combi-
nation [16] or an overprivileged set of permissions [18], [33].
Although promising, the peculiarity of Android apps (e.g., a
potential combination of Java and native code) can easily elude
policy enforcement or collude to perform malicious actions
while maintaining a seemingly legitimate appearance. This
clearly calls for continuous research in this direction.
Aurasium [42] is a technique (and tool) that enables ﬁne-
grained dynamic policy enforcement of Android apps. To
intercept relevant events, Aurasium instruments single apps,
rather than adopting system-level hooks. Working at the ap-
plication level, however, exposes Aurasium to easy detection
or evasion attacks by malicious Android applications. For
example, regular applications can rely on native code to detect
and disable hooks in the global offset table, even without
privilege escalation exploits. Aurasium’s authors state that their
approach can prevent such attacks by intercepting dlopen
invocations needed to load native libraries. It
is however
unclear how benign and malicious code can be distinguished,
as this policy cannot be lightheartedly delegated to Aurasium’s
end-users. Conversely, CopperDroid’s VMI-based system call-
centric analysis is resilient to such evasions.
Google Bouncer [29], as its name suggests, is a service
that “bounces” malicious applications off from the ofﬁcial
Google Play (market). Little is known about it, except that it
is a QEMU-based dynamic analysis framework. All the other
information come from reverse-engineering attempts [32] but
they are too scarce to properly compare it against our approach.
SmartDroid [45] leverages a hybrid analysis that statically
identiﬁes paths that lead to suspicious actions (e.g., accessing
sensitive data) and dynamically determines UI elements to
take the execution ﬂow down those identiﬁed paths. To this
end, the authors instrument both the Android emulator and
Android’s internal components to infer which UI elements
trigger suspicious behaviors. They also evaluated SmartDroid
on a testbed of seven different malware samples and found
it vulnerable to obfuscation and reﬂection, which make it
hard—if not impossible—to statically determine every possible
execution path. Conversely, CopperDroid’s dynamic analysis is
resilient to static obfuscation and reﬂection.
To overcome the limits of dynamic analysis (e.g., code or
path coverage), Anand et al. proposed a concolic-based solu-
tion [1] to automatically identify events an application reacts to
by generating input events for smartphone applications. While
no learning phase is required, such a solution has two main
drawbacks: it is based on instrumentation (i.e., easy to detect)
and is extremely time-consuming (i.e., up to hours to exercise
a single application). Although an interesting direction to ex-
plore further, that approach is ill-suited to perform large-scale
malware analysis. As described in Section V-A, CopperDroid
relies on a simple-yet-effective stimulation technique that is
able to improve basic dynamic analysis coverage and discover
additional behaviors with low overheads.
VetDroid is a dynamic analysis platform for reconstructing
sensitive behaviors in Android apps from a permissions use
perspective [44]. Zhang et al. points out that traditional system
call analysis is not appropriate for characterizing the behaviors
of Android apps as it misses high-level Android-speciﬁc se-
mantics and fails at reconstructing IPC and RPC interactions.
Contrary to this, we have shown that CopperDroid’s uniﬁed
system call-centric analysis is able to automatically and seam-
lessly reconstruct IPC and RPC interactions as well as complex
Android objects, generating insightful behavioral proﬁles.
Finally, one study recently used the insights of the Cop-
perDroid workshop paper to manually discover vulnerabilities
in the Android IPC [4].
VIII. CONCLUSION
We proposed CopperDroid, a VM-based dynamic system
call-centric analysis and stimulation technique to both uni-
formly, and automatically, reconstruct behaviors of Android
malware. In particular, we show how a careful dissection of
system calls coupled with the ability to automatically track and
deserialize IPC and RPC interactions, typically contextualized
through complex Android objects, is key to the reconstruction
of both OS- and Android-speciﬁc behaviors from a unique,
well-known, (system level) observation point. Not only is this
simplicity more transparent to changes in the Android runtime
system and its inner details, but it also makes the approach
agnostic to the underlying action invocation mechanisms (e.g.,
Java or native code). We evaluated the effectiveness and
performance of CopperDroid on more than 2,900 real world
Android malware, showing that a simple, external, stimulation
contributes to the discovery of additional behaviors.
We believe the novelty of CopperDroid’s analyses opens
the possibility to reconsider rich and uniﬁed system call-based
approaches as effective techniques to build upon to mitigate
Android malware threats.
AVAILABILITY
CopperDroid and information about our ongoing project-
related research are available at:
http://s2lab.isg.rhul.ac.uk/projects/mobsec/
where users can reach out to a publicly-available version of
CopperDroid and submit APK ﬁles to be analyzed. Analysis
results include behavioral proﬁles available in a number of
different formats (e.g., HTML and JSON, for easy parsing)
and additional ancillary information (e.g., network trafﬁc,
reconstructed ﬁles and executables, complete system call traces
with behavior reconstruction).
ACKNOWLEDGMENTS
This research has been partially supported by the UK
EPSRC grant EP/L022710/1 and by a generous donation from
Intel Security (McAfee Labs). We are equally thankful to the
anonymous reviewers’ comments and Timothy Leek (and An-
drew Davis), our shepherd, for their invaluable comments and
suggestions to improve the paper. We also thank Alessandro
13
[28] M. Lindorfer, M. Neugschwandtner, L. Weichselbaum, Y. Fratantonio,
V. van der Veen, and C. Platzer, “Andrubis - 1,000,000 Apps Later:
A View on Current Android Malware Behaviors,” in Proceedings of
the the 3rd International Workshop on Building Analysis Datasets and
Gathering Experience Returns for Security (BADGERS), 2014.
[29] H. Lockheimer, “Bouncer,” http://googlemobile.blogspot.it/2012/02/
android-and-security.html.
[30] McAfee, “Mcafee,” http://www.mcafee.com.
[31] A. Moser, C. Kruegel, and E. Kirda, “Exploring multiple execution
the IEEE Symposium on
paths for malware analysis,” in Proc. of
Security and Privacy, 2007.
J. Oberheide and C. Miller, “Dissecting the Android’s Bouncer,” Sum-
merCon, 2012, http://jon.oberheide.org/ﬁles/summercon12-bouncer.pdf.
[33] H. Peng, C. Gates, B. Sarma, N. Li, Y. Qi, R. Potharaju, C. Nita-Rotaru,
and I. Molloy, “Using probabilistic generative models for ranking risks
of android apps,” in ACM CCS, 2012.
[32]
[34] B. PETROVAN,
“Xposed
lollipop,
xposed-framework-lollipop-540928/.
xposed,”
and
art,
framework
creator weighs
on
http://www.androidauthority.com/
in
[35] V. Rastogi, Y. Chen, and W. Enck, “Appsplayground: Automatic secu-
rity analysis of smartphone applications,” in Proceedings of the Third
ACM Conference on Data and Application Security and Privacy, ser.
CODASPY ’13. New York, NY, USA: ACM, 2013.
[36] A. Reina, A. Fattori, and L. Cavallaro, “A system call-centric analysis
and stimulation technique to automatically reconstruct android malware
behaviors,” in Proceedings of the 6th European Workshop on System
Security (EUROSEC), Prague, Czech Republic, April 2013.
[37] G. Sarwar, O. Mehani, R. Boreli, and M. A. Kaafar, “On the effective-
ness of dynamic taint analysis for protecting against private information
leaks on Android-based devices,” in SECRYPT, Jul. 2013.
[38] A. Slowinska and H. Bos, “Pointless tainting?: evaluating the practical-
ity of pointer tainting,” in EuroSys, W. Schr¨oder-Preikschat, J. Wilkes,
and R. Isaacs, Eds. ACM, 2009, pp. 61–74.
[39] Statista, “Cumulative number of apps downloaded from the google play
android app store as of july 2013,” Jul 2013.
[40] The Honeynet
droidbox/.
Project,
“Droidbox,”
https://code.google.com/p/
[41] C. Willems, T. Holz, and F. Freiling, “Toward automated dynamic
malware analysis using cwsandbox,” IEEE S&P, 2007.
[42] R. Xu, H. Saıdi, and R. Anderson, “Aurasium: Practical policy enforce-
ment for android applications,” in Proc. of USENIX Security, 2012.
[43] L.-K. Yan and H. Yin, “DroidScope: Seamlessly Reconstructing OS
and Dalvik Semantic Views for Dynamic Android Malware Analysis,”
in Proc. of USENIX Security, 2012.
[44] Y. Zhang, M. Yang, B. Xu, Z. Yang, G. Gu, P. Ning, X. S. Wang, and
B. Zang, “Vetting undesirable behaviors in android apps with permission
use analysis,” in ACM CCS, 2013.
[45] C. Zheng, S. Zhu, S. Dai, G. Gu, X. Gong, X. Han, and W. Zou, “Smart-
Droid: an automatic system for revealing UI-based trigger conditions
in Android applications,” in Proc. of SPSM, 2012.
[46] W. Zhou, Y. Zhou, X. Jiang, and P. Ning, “Detecting repackaged
smartphone applications in third-party android marketplaces,” in Proc.
of CODASPY, 2012.
[47] Y. Zhou and X. Jiang, “Dissecting android malware: Characterization
the IEEE Symposium on Security and
and evolution,” in Proc. of
Privacy, 2012.
[48] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang, “Hey, you, get off of my
market: Detecting malicious apps in ofﬁcial and alternative android
markets,” in Proc. of NDSS, 2012.
[49] Y. Zhou and X. Jiang, “Android Malware Genome Project,” http://www.
malgenomeproject.org/.
Reina, Santanu Dash, Johannes Kinder, Igor Muttik, and Alex
Hinchliffe for their valuable suggestions and discussions on
the work.
REFERENCES
[1] S. Anand, M. Naik, H. Yang, and M. Harrold, “Automated concolic
testing of smartphone apps,” in Proc. of FSE, 2012.
[2] Android, “Android developer reference,” http://developer.android.com/
reference/packages.html.
[3] ——,
“Monkeyrunner,”
http://developer.android.com/tools/help/
monkeyrunner concepts.html.
[4] N. Artenstein and I. Revivo, “Man in the binder: He who controls ipc,
controls the droid,” 2014.
[5] U. Bayer, C. Kruegel, and E. Kirda, “Ttanalyze: A tool for analyzing
malware,” in Proc. of EICAR, 2006.
[6] F. Bellard, “QEMU, a fast and portable dynamic translator,” in Proc.
of USENIX ATC, 2005.
[7] D. Bornstein, “Dalvik VM internals,” in Google I/O, 2008.
[8] D. Brumley, C. Hartwig, Z. Liang, J. Newsome, D. Song, and H. Yin,
“Automatically identifying trigger-based behavior in malware,” Botnet
Detection, 2008.
[9] C. Cadar, D. Dunbar, and D. R. Engler, “Klee: Unassisted and automatic
generation of high-coverage tests for complex systems programs,” in
OSDI, 2008.
[10] L. Cavallaro, P. Saxena, and R. Sekar, “On the limits of information ﬂow
techniques for malware analysis and containment,” in DIMVA, 2008.
[11] Contagio Mobile, “Mila Parkour,” http://contagiominidump.blogspot.
com.
[12] D. Desai, “Malware Analysis Report: Trojan: AndroidOS/Zitmo,”
Semptember 2011, http://www.kindsight.net/sites/default/ﬁles/android
trojan zitmo ﬁnal pdf 17585.pdf.
[13] A. Developers, “Parcelable,” http://developer.android.com/reference/