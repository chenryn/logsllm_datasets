cate from the programs state space to one of two values:
safe or unsafe. In our setting, we consider only safety
policies enforceable by an execution monitor [34]. At
a high level, such policies are allowed to evaluate a
boolean predicate on the program state space at each
step of the execution, as well as keep track of any previ-
ous states executed so far. Common execution monitor
enforceable safety policies include dynamic taint analy-
sis, checking return address integrity, and dynamic type
enforcement.
We denote executing P on input x as P (x), and the
execution of instruction i as Pi(x). We denote checking
the safety policy at execution step i as φ(Pi(x)). The
vulnerability point [5] for a vulnerable program is the
ﬁrst instruction i such that φ(Pi(x)) = unsafe.
We use the term exploit to mean an input x for which
the safety policy returns unsafe. For example, if we use
a dynamic taint analysis policy, an exploit would be any
input that causes the analysis to raise a warning. One
reason we use this deﬁnition of an exploit is that it does
not presuppose a particular attack goal, e.g., informa-
tion disclosure vs. denial-of-service vs. hijack control
ﬂow. This makes sense in our context since the vulnera-
bility itself determines whether such speciﬁc attacks are
even possible (e.g., information disclosure exploits are
orthogonal to control hijack exploits). Note that there
are potentially many different exploits, with each indi-
vidual exploit called a polymorphic variant.
Safety policies are powerful enough (since they are
ﬁrst-order logic Boolean predicates over the entire pro-
gram state space, including all memory) to specify spe-
ciﬁc kinds of attack when desired. For example, it is
possible to specify a safety policy that is only violated
by control hijack attacks. For example, we can create a
safety policy which states the return address on the stack
should not be overwritten by user input. Such a safety
policy would only be violated by a typical control-hijack
buffer overﬂow.
A program control ﬂow graph (CFG) G = (V, E) is a
graph where each vertex ∈ V is a single instruction, and
there is an edge (i1, i2) ∈ E if there is a possible transfer
of control from instruction i1 to i2. An execution path
is a sequence of vertices through the control ﬂow graph
such that for each vertex there is an edge to the next
vertex in the CFG (note vertices may repeat in the path).
2.2 The Automatic Patch-Based Exploit Gen-
eration Problem
In the automatic patch-based exploit generation prob-
lem, we are given two versions of the same program P
and P ′ where P ′ ﬁxes an unknown vulnerability in P .
The goal is to generate an exploit for P for the vulnera-
bility ﬁxed in P ′. More formally, we are given a safety
policy φ, and the programs P and P ′. The purpose of
φ is to encode what constitutes an exploit. Our goal is
to generate an input x such that φ(P (x)) = unsafe, but
φ(P ′(x)) = safe.
2.3 Problem Scope and Approach
Vulnerabilities Addressed in this Paper. We focus on
input validation vulnerabilities where user input is not
sufﬁciently sanitized in P , but is sanitized via new
checks in P ′. Many common vulnerabilities are input
validation vulnerabilities which are ﬁxed by adding in-
put sanitization logic. For example, if P is vulnerable
to an integer overﬂow attack, then P ′ may insert a check
for this overﬂow, and ultimately we will be using that in-
serted check to help derive an exploit. Another example
is when P contains a typical buffer overﬂow where an
input string may be too large, which is addressed in P ′
by inserting a check for overly-long inputs. However,
a ﬁx in which P ′ increases the size of the destination
buffer to accommodate overly-long inputs currently falls
outside our problem setting. We plan on targeting other
types of vulnerabilities in future work.
Approach Overview. Our approach to APEG is based
on the observation that the new sanitization checks
added to P ′ often 1) identify the vulnerability point
where the vulnerability occurs, and 2) indicate the con-
ditions under which we can exploit P . Thus, an input
x that fails the added sanitization check at the vulnera-
bility point in P ′ is a candidate exploit for P . We call
x a candidate exploit because a new check may not cor-
respond to a real vulnerability. We verify a candidate
exploit by checking φ(P (x)), e.g., observing the execu-
tion of P (x) within an execution monitor. Our approach
therefore attempts to generate inputs which would fail
the new checks inserted at the vulnerability point.
We can use off-the-shelf tools to identify the vulner-
ability point and the added checks. In our implementa-
tion, we use EBDS [13], a tool that automatically com-
pares two executables and reports the differences. We
can also use off-the-shelf safety checkers for φ. For
example, dynamic taint analysis is a type of execution
monitor commonly used to detect a wide variety of ex-
ploits.
Thus, in this paper, we focus on the technical chal-
lenge of how to automatically generate candidate ex-
146
ploits which reach and fail the given new checks in the
patched version. To address this technical challenge, we
propose an approach which 1) generates the set of con-
straints on the input domain to reach and fail the new
check, and 2) ﬁnds a satisfying answer to the constraints,
which is a sample candidate exploit.
More formally, we compute the weakest precondi-
tion [11] on the input state space of the P ′ to execute
and fail the desired check. The weakest precondition is
a constraint formula F : I → {true, false} where I
is the input state space, and a satisfying answer is our
sample exploit. For example, the constraint formula
F (input)
.
= input%2 == 0 ∧ s = input + 2(mod232)
∧ ¬(s > input)
is satisﬁed by all inputs that execute the true branch of
P in Figure 2 and overﬂow. Finally, given the con-
straint formula, we query a solver to generate a satis-
fying answer to the formula (i.e., an input x such that
F (x) = true). If the solver returns a solution, the solu-
tion is a candidate exploit.
Thus, the steps to our approach are:
1. Identify the new sanitization checks added in P ′. The
remaining steps are performed for each new check in-
dividually (see Section 6 for a discussion on multiple
checks).
2. Generate a candidate exploit x which fails the new
check in P ′ by:
(a) Calculating the weakest precondition to fail the new
check in P ′. The result is the constraint formula F .
We present three approaches for generating the con-
straint formula target this problem in Section 3.2.1.
(b) Use a solver to ﬁnd x such that F (x) = true. x is
the candidate exploit.
3. Verify a candidate exploit is a real exploit by running
φ(P (x)).
4. If desired, we can generate polymorphic variants. Let
x be a known exploit. Let F ′(X) = F (X) ∧ (X <>
x). Then x′ such that F ′(x′) = true is a polymor-
phic variant exploit candidate. This process can be
repeated to enumerate polymorphic variants.
3 Automatic Patch-Based Exploit Genera-
tion
In this section, we describe our approach and steps for
automatic patch-based exploit generation.
3.1 Differencing Two Binaries Using an Off-
The-Shelf Tool
The ﬁrst step of our patch-based exploit generation is to
difference P and P ′ to ﬁnd new sanitization checks that
are added in P ′. Several tools exist for differencing bi-
naries which are reasonably accurate and can be used to
determine what new checks exist [12–14, 33]. We look
for new checks that introduce a new code path since that
indicates that P ′ is doing something different than P .
We use eEyE’s Binary Difﬁng Suite (EBDS) [13] in our
implementation since it is freely available.
Our approach does not assume the differencer only
outputs semantically meaningful differences (see Sec-
tion 7). In fact, the differencer (EBDS) we use is based
upon almost purely syntactic analysis of the disassem-
bled binary. As a result, the list of new checks based
on the syntactic analysis is a superset of the meaning-
ful checks. Our approach will (correctly) fail to produce
an exploit for semantically meaningless differences. For
example, if P has the check i > 10, and P ′ has the
check i − 1 > 9, the differencer may report the latter
is a new check. Semantically meaningless differences
such as these are weeded out by the veriﬁcation step.
For example, i = 12 is an example input which may
satisfy the above difference, but would fail veriﬁcation
since it behaves the same in the new and old version.
EBDS returns the list of differences; we ﬁlter them for
new checks. EBDS also indicates whether the true or
false branch of a new check corresponds to a new path.
We assume a new path corresponds to failing the check.
For example, in Figure 2 EBDS would report the false
branch of the new check on line 5 introduces a new path,
and we infer that s > input is the check that should fail.
Recall that the remaining steps in our process of
patch-based exploit generation are performed on each
identiﬁed new check. Of course our approach bene-
ﬁts from better differencing tools which output fewer
and more semantically meaningful checks, as fewer it-
erations are needed. In our evaluation, we measure the
number of new checks reported by the tool, but assume
the attacker can process each new check in parallel. This
is realistic since attackers often have many (perhaps hun-
dreds or thousands of) compromised hosts they can use
for checking each reported difference.
If there is a need to prioritize which new checks are
tried ﬁrst for APEG, we have found that one effective
scheme for prioritizing is to try new checks that appear
in procedures that have changed very little. The eEye
tool already provides a metric for how much a procedure
has changed between P and P ′.
3.2 Generating Constraint Formulas
In this section, we discuss techniques for automatically
generating the constraint formulas. First, we explore
the design space and provide intuition why we need
to consider several different approaches. We then pro-
vide background on generating formulas using dynamic
147
and static analysis (interested readers should consult the
cited papers for full details). We then show how to
adapt these ideas to the combined dynamic and static
approach.
3.2.1 Key Design Points
The most important design question for constructing the
constraint formula is to ﬁgure out what instructions to
include in the formula. We need to include all the in-
structions for an exploitable path for the solver to gen-
erate a candidate exploit. However, the number of ex-
ploitable paths is usually only a fraction of all paths to
the new check. Should the formula cover all such exe-
cution paths, some of them, or just one? We consider
three approaches to answering this question: a dynamic
approach which considers only a single path at a time,
a static approach which considers multiple paths in the
CFG without enumerating them, and a combined dy-
namic and static approach.
The Dynamic Approach: Generating a Constraint
Formula from a Sample Execution. In some cases, the
new check appears on a program path which is executed
by a known input, e.g., along a commonly executed path.
Such normal inputs can be found by examining logs of
normal inputs, fuzzing, or other techniques. Of course,
a normal input will likely satisfy the new check; other-
wise, it is already a candidate exploit.
For such a given input i where P ′(i) executes the new
check, we use techniques from dynamic analysis to gen-
erate the constraint formula representing the constraints
on input for any execution of that single path up to the
new check. Since the intuition behind our approach is
that exploits fail the new check, we add an additional
constraint that the input fails the new check.
The dynamic approach produces formulas that are
typically the smallest of the three approaches. Since
small formulas are generally the easiest to solve, the dy-
namic approach is usually the fastest for producing can-
didate exploits.
The ASPNet Filter vulnerability in our evaluation
(Section 4) is an example demonstrating real-world util-
ity of the dynamic approach. In ASPNet Filter, the vul-
nerability is in a webserver and the new check is added
along a common code path which is executed by most
URI requests. Thus, it is relatively easy to obtain at least
one benign input that reaches the point of the new check,
and hence it makes sense to start by analyzing that path
ﬁrst and see if we can generate an exploit using that path.
The Static Approach: Generating a Constraint For-
mula from a Control Flow Graph. Another approach
is to create a formula over a CFG [6]. In particular, in the
static case we are concerned with the CFG that includes
all paths from the instruction where input is read to the
new check. We perform program chopping on the pro-
gram CFG in order to create a CFG that only includes
paths to the new check. Computing a formula over the
CFG is more efﬁcient than computing a separate formula
for each path in the CFG separately [6].
The static approach will generate a candidate exploit
if any path in the CFG is exploitable. Since the static
formula potentially includes all instructions in the CFG
fragment, the formulas are typically larger and therefore
take longer to solve. The DSA SetItem vulnerability in
our evaluation is an example where a purely static ap-
proach works.
Creating Constraint Formulas Using Combined Dy-
namic and Static Approach. If the CFG fragment con-
tains a large number of instructions (because it covers a
large number of paths), the generated formula may be
too large for the solver. On the other hand, an exploit
may never take the same execution path as a known in-
put, thus a purely dynamic approach may not work ei-
ther.
We propose a third approach which mixes the dy-
namic and static approaches to generating constraints.
The intuition behind the combined approach is to com-
bine information about code paths we know how to ex-
ecute via known inputs, and additional code paths we
wish to explore using static analysis. For example, we
may know an input which does not reach the point of the
new check, but does get us half-way there. We can use
the dynamic analysis to the half-way point, then use the
static approach for all paths from the half-way point to
the new check.
The advantage of the combined approach is that it
provides a way of considering a subset of paths so that
the generated formula is (hopefully) small enough for
the solver to generate a candidate exploit. The IGMP
vulnerability in our evaluation is an example of this case
where neither the static nor dynamic approach worked
alone, but the combined approach generated a working
exploit.
3.2.2 Background: Generating a Constraint For-
mula from a Sample Execution
Here we provide a recap of the overall method for gen-
erating a constraint formula from an execution trace.
Due to space, interested readers should consult previous
work [4, 5, 7, 19, 30] for a more thorough treatment.
The dynamic approach for creating a formula takes
as input P ′, the new check, and a sample input i. We ex-
ecute P ′(i) and record each instruction executed up to
the sample check. We generate the constraint formula
over the instructions executed along this path. To be
efﬁcient, we only record instructions (including all of
their explicit and implicit operands) dependent upon in-
148
wp(x := e, Q) ⊢ let x = e in Q
ASSIGN
the new check fails.
wp(assert e, Q) ⊢ e ∧ Q
ASSERT
wp(s1, wp(s2, Q)) ⊢ Q1
wp(s1; s2, Q) ⊢ Q1
SEQ
wp(s1, Q) ⊢ Q1 wp(s2, Q) ⊢ Q2
wp(if e then s1 else s2, Q) ⊢ (e ⇒ Q1) ∧ (¬e ⇒ Q2)
CHOICE
Table 1. Rules for calculating the weakest
precondition.
puts since we only tackle vulnerabilities which can be
exploited via user input.
Modeling the Executed x86 Instructions. In order to
generate the constraint formula, we need to know the ef-
fects of each instruction executed. X86 is a complex in-
struction set. To accurately build the constraint formula,
we need to model the effects of an x86 instruction cor-
rectly, including all implicit side effects such as updates
to status registers. Thus, we raise the x86 instructions
to an assembly modeling language we designed called
Vine [2]. The ability to model the effects of each x86
instruction accurately is essential for automatically gen-
erating exploits.