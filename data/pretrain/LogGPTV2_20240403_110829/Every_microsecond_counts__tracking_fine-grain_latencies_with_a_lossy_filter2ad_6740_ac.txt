(5)
.
1
˜S
i=1
It is straightforward to show that
E[F ] =
1
R
(bx − ax)2
X
x
We can then estimate the standard deviation of the delays using (3).
The variance of F is upper-bounded by
Var[F ] =
1
R2
„
R − ˜S
˜S
rec’dX
x
4
x + 2
w
rec’dX
x(cid:2)=x(cid:2)
«
2
xw
2
x(cid:2)
w
.
For comparison, the basic estimator (4), which does not handle
packet loss, has variance
rec’dX
x(cid:2)=x(cid:2)
2
R2
2
xw
2
x(cid:2) .
w
By averaging several instances of the estimator as in [3], the vari-
ance can be reduced arbitrarily. In our experiments, however, we
use the estimator (5) directly with satisfactory results. It is worth
remembering that this standard deviation estimate comes “for free”
by mining the LDA data structure (designed for estimating average)
for more information.
The quantity S is is the effective sample size from which the av-
erage latency is calculated. In other words, if one were to sample
and store packet timestamps, the number of packets sampled would
need to be at least S to achieve the same statistical accuracy as the
LDA. Using a Hoeffding inequality [13], it can be shown that
Pr[|D − μ| ≥ μ] ≤ 2e
−2Sμ2/2σ2
(1)
where μ and σ are the actual mean and standard deviation of the de-
lays. When σ ≈ μ the estimate is very accurate given a reasonable
effective sample size. Let R and L be the number of received and
lost packets, respectively, so that R+L = N. For a single bank and
L ≥ m, setting the packet sampling probability p = αm/(L + 1),
where α is a parameter to be optimized, gives an expected effective
sample size of
E[S] ≥ α(1 − α) · m
L + 1
· R.
(2)
Note that if we were to store the sampled packets, the expected
sample size would be just pR with a tight concentration around this
value; however because we are not storing the packets but record-
ing them in the LDA, we pay a constant factor (1 − α) penalty in
the effective sample size and a higher variance. To maximize the
bound, we set α = 0.5, the value we use in our experiments.
3.4 Latency standard deviation
Note that we exploited the fact that the sum of the differences of
receive and send packet time stamps is the same as the difference
of their sum. While this reshufﬂing works for the sum, it does not
work for the sum of squares. Despite this obstacle, we now show
that the LDA can also be used to estimate the standard deviation
of the packet delays. This is crucial because an accurate measure
for standard deviation allows a network manager to compute tight
conﬁdence intervals on the delay, a highly desirable feature in a
trading or high-performance computing applications.
Again, let’s start by assuming no loss; we can correct for loss
later using the same hashing technique as we used for the average.
Consider the two timestamp sums we already keep at the sender
and receiver, TA and TB. If we take the difference, this is just the
sum of packet delays. If we now square this difference, we get
(bx − ax)2 +
(bx − ax)(bx(cid:2) − ax(cid:2) )
X
x
The ﬁrst sum (of delays squared) is exactly what we need for com-
puting the standard deviation, since
2 =
σ
(bx − ax)2 − μ
2
,
(3)
x
but we also get unwanted cross terms. Fortunately, the cross terms
can be eliminated using a technique introduced by Alon, Matias
and Szegedy [3]. The idea is to keep a slightly different timestamp
accumulator on the sender and receiver: instead of simply adding
the timestamp, we add or subtract with equal probability based on
a consistent hash. Using sx to denote the ±1 hash of the packet,
we now have:
X
x(cid:2)=x(cid:2)
X
2604. EVALUATION
Our evaluation has three major goals. First, we wish to empiri-
cally validate our analyses of an optimal LDA’s estimates, both in
terms of average delay and standard deviation. Second, we analyze
various tuning options to select a set of practical conﬁguration op-
tions. Finally, we use the resulting parameter settings to compare
the efﬁcacy of a practical LDA to the current cost-effective alter-
native: Poisson-modulated active probing.
(We do not compare
against special-purpose passive monitoring devices [35], as they
are prohibitively expensive to deploy at scale.)
We have implemented a special-purpose simulator in C++ to fa-
cilitate our evaluation1. The simulator generates packet traces with
various loss and delay distributions and implements several differ-
ent variants of the LDA data structure, as well as active probing and
the associated estimators needed to compare LDA with the active
probing approach.
In an effort to evaluate LDA in realistic scenarios, we use de-
lay and loss distributions drawn from the literature. In particular,
Papagiannaki et al. report that packet delays recorded at a back-
bone router are well modeled by a Weibull distribution [28], with a
cumulative distribution function
P (X ≤ x) = 1 − e
(−x/α)β
with α and β representing the scale and shape respectively. Unless
otherwise noted, all of our experiments consider a Weibull distri-
bution with their recommended shape parameter (0.6 ≤ β ≤ 0.8).
For comparison purposes, we also simulated Pareto distribution
generated according to the function P (X ≤ x) = 1 − (x/α)−β
with α and β representing the scale and shape parameters respec-
tively and β chosen between 3 to 5 so that the delay values do
not become too skewed and to ensure that the distributions have
bounded variance.
In order to ensure that sampled delay values do not cause packet
reordering, we assign timestamps to packets such that two succes-
sive packets always differ by more than the delay of the ﬁrst packet
drawn from the distribution. In other words, we ensure that there
is always only one packet in ﬂight at any given instant by enforc-
ing that a given packet begins transmission only after the previ-
ous packet has reached the receiver. This does not bias our results
in any way since LDA does not care about the actual timestamps
themselves; it’s only the differences that matter.
LDA performance is independent of loss distribution within an
interval, so most experiments use a uniform loss model for simplic-
ity. For our comparisons with active probes—whose performance
depends on the loss distribution—we use exponentially distributed
loss episodes (as suggested by Misra et al. in their study of TCP
behavior [26]), where each episode involves dropping a burst of
packets (following the model of Sommers et al. [33]).
4.1 Validation
The main goal of the set of experiments described in this subsec-
tion is to empirically validate our analytical bounds using a simple
single-bank LDA. In particular, we study the accuracy of LDA’s
estimates over different delay and loss distributions.
For these simulations, we conﬁgure the LDA to use n = 1
bank of m = 1, 024 counters. We simulate a 10-Gbps OC-192
link which, assuming an average packet size of 250 bytes, carries
roughly ﬁve million packets per second at capacity. (The choice
1The main advantage of standard packages like ns2 is the library
of prexisting protocol implementations like TCP, the vast majority
of which are not needed in our experiments. Thus, we feel the
remaining beneﬁts are outweighed by the simplicity and signiﬁcant
speed up of a custom solution.
i
e
z
s
e
p
m
a
S
l
1000000
10000
100
1
LDA
Expected
 0  0.02  0.04  0.06  0.08  0.1  0.12  0.14  0.16  0.18  0.2
Loss rate
Figure 4: The sample size obtained by a single-bank LDA as a
function of loss rate.
of 250-byte packets is arbitrary and results in round numbers; the
functionality of LDA is not impacted by packet size.) We simu-
late a measurement interval of one second (so N = 5, 000, 000
and an average delay of 0.2 μs). For different distributions, we en-
sure consistency by adjusting the scale parameters appropriately to
match the mean delay of 0.2 μs.
In order to isolate the effects of packet loss, for each experiment,
we ﬁrst generate a packet trace according to the desired delay dis-
tribution using a particular random seed, and then impose varying
levels of loss. Each graph presented in this section uses the same
random seed for the delay distribution.
We ﬁrst verify empirically that the actual sample size obtained
using our data structure matches expectation. For the purposes of
this experiment, we assume that we know a priori the loss rate l; we
compute the number of lost packets L = N · l and set the sampling
probability accordingly as p = αm/(L + 1), where α = 0.5.
Figure 4 shows the number of samples captured by the LDA as
we vary the loss rate from 0.5% to 20%, as well as the expected
value given by Equation 2. Two main observations can be made
from the ﬁgure: First, as expected, the sample size decreases as loss
rate increases. Second, our analytical bound is conservative; LDA
captures more samples in simulation than according to theory.
In Figure 5(a), we plot the average relative error (deﬁned as
|true − estimated|/|true|) of LDA as we vary the loss rate. We
obtain the ground truth by maintaining the full delay distribution.
Each point corresponds to the average of the relative error across a
set of ten independent runs—i.e., the packet trace is the same, but
the LDA selects a different random set of packets to sample during
each run. The LDA is optimally conﬁgured for each loss rate as
in the previous subsection. As expected, the relative error of the
estimate increases as the loss rate increases because the number of
available samples decreases with loss rate. While the curves all
follow the same general trend, the estimates for the Weibull dis-
tributions are less accurate compared to Pareto. For the particu-
lar shape parameters we simulated, the Weibull distribution suffers
from a larger variance than Pareto—variance is 0.123 at β = 0.6
for Weibull as compared to 0.013 at β = 3 for Pareto. LDA there-
fore requires more samples for Weibull to obtain the same accuracy
level as Pareto. Even in the worst case of 20% loss, however, the
estimates have less than 4% error on average. At low loss rates (<
0.1%), LDA estimates have less than 0.3% error. Results from sim-
ilar experiments with a variety of random seeds are qualitatively
similar; the relative error at loss rates of even 6% across different
traces is never more than 3% with an average of about 0.2%.
261r
o
r
r
e
e
v
i
t
l
a
e
R
)
c
e
s
u
(
y
a
e
D
l
 0.05
 0.04
 0.03
 0.02
 0.01
 0.35
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
Weibull (0.133,0.6)
Weibull (0.158,0.7)
Weibull (0.177,0.8)
Pareto (0.133,3.0)
Pareto (0.150,4.0)
Pareto (0.160,5.0)
 0  0.02  0.04  0.06  0.08  0.1  0.12  0.14  0.16  0.18  0.2
Loss rate
(a) Average relative error
98% confidence
 0  0.02  0.04  0.06  0.08  0.1  0.12  0.14  0.16  0.18  0.2
(b) Estimated average delay
Loss rate
Figure 5: Average relative error and 98% conﬁdence bounds of
the delay estimates computed by LDA as a function of loss rate.
Actual mean delay is 0.2 μs in all cases. In (b), each curve rep-
resents an LDA with different random seed on the same trace.
Low error in expectation is nice, but some applications require
guarantees of accuracy in every instance. To validate our error
bounds, we focus on the delay distribution with the least accurate
estimates from above, namely the (α = 0.133, β = 0.6) Weibull
distribution.
In Figure 5(b), rather than report relative error, we
graph the actual delay estimate computed by a representative ﬁve
of the ten constituent runs in Figure 5(a). In addition, we plot the
98%-conﬁdence bounds computed using Equation 1. The actual
conﬁdence bound depends on the number of samples obtained by
each LDA, and, therefore, varies across instances. Each error bar
shown in the ﬁgure corresponds to the most conservative bound
computed based on the run that collected the smallest number of
samples across the ten runs from Figure 5(a). While conﬁdence
decreases with higher loss rates, all of the individual estimates re-
ported in our simulation remain quite close to the actual value. Re-
sults of other distributions are even tighter.
For the same setup as above, we also measure the accuracy of the
LDA’s standard-deviation estimator (obtained from the variance es-
timator). We plot the average relative error incurred for different
distributions in Figure 6. Estimates suffer from about 20-50% rela-
tive error for Pareto to less than 10% error for Weibull distributions,
independent of loss rate. The magnitude of the relative error obvi-
ously depends on the actual standard deviation of the underlying
distribution, however. The true standard deviation of delay in the
r
o
r
r
e
e
v
i
t
l
a
e
R
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
Weibull (0.133,0.6)
Weibull (0.158,0.7)
Weibull (0.177,0.8)
Pareto (0.133,3.0)
Pareto (0.150,4.0)
Pareto (0.160,5.0)
 0  0.02  0.04  0.06  0.08  0.1  0.12  0.14  0.16  0.18  0.2
Loss rate
Figure 6: Average relative error of LDA’s standard-deviation
estimator as a function of loss rate.
Pareto- and Weibull-distributed traces is about 0.35 and 0.11 re-