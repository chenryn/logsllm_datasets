title:Efficient, Private and Robust Federated Learning
author:Meng Hao and
Hongwei Li and
Guowen Xu and
Hanxiao Chen and
Tianwei Zhang
Efficient, Private and Robust Federated Learning
Meng Hao
Guowen Xu
Hongwei Li∗
University of Electronic Science and
University of Electronic Science and
Nanyang Technological University
Technology of China
PI:EMAIL
Technology of China
PI:EMAIL
PI:EMAIL
Hanxiao Chen
University of Electronic Science and
Technology of China
PI:EMAIL
Tianwei Zhang
Nanyang Technological University
PI:EMAIL
ABSTRACT
Federated learning (FL) has demonstrated tremendous success in
various mission-critical large-scale scenarios. However, such promis-
ing distributed learning paradigm is still vulnerable to privacy in-
ference and byzantine attacks. The former aims to infer the privacy
of target participants involved in training, while the latter focuses
on destroying the integrity of the constructed model. To mitigate
the above two issues, a few works recently explored unified so-
lutions by utilizing generic secure computation techniques and
common byzantine-robust aggregation rules, but there are two ma-
jor limitations: 1) they suffer from impracticality due to efficiency
bottlenecks, and 2) they are still vulnerable to various types of
attacks because of model incomprehensiveness.
To approach the above problems, in this paper, we present Se-
cureFL, an efficient, private and byzantine-robust FL framework.
SecureFL follows the state-of-the-art byzantine-robust FL method
(FLTrust NDSS’21), which performs comprehensive byzantine de-
fense by normalizing the updates’ magnitude and measuring di-
rectional similarity, adapting it to the privacy-preserving context.
More importantly, we carefully customize a series of cryptographic
components. First, we design a crypto-friendly validity checking
protocol that functionally replaces the normalization operation in
FLTrust, and further devise tailored cryptographic protocols on top
of it. Benefiting from the above optimizations, the communication
and computation costs are reduced by half without sacrificing the
robustness and privacy protection. Second, we develop a novel
preprocessing technique for costly matrix multiplication. With this
technique, the directional similarity measurement can be evaluated
securely with negligible computation overhead and zero communi-
cation cost. Extensive evaluations conducted on three real-world
datasets and various neural network architectures demonstrate that
SecureFL outperforms prior art up to two orders of magnitude in
efficiency with state-of-the-art byzantine robustness.
∗corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8579-4/21/12...$15.00
https://doi.org/10.1145/3485832.3488014
KEYWORDS
Federated learning, Privacy protection, Byzantine robustness.
ACM Reference Format:
Meng Hao, Hongwei Li, Guowen Xu, Hanxiao Chen, and Tianwei Zhang.
2021. Efficient, Private and Robust Federated Learning. In Annual Computer
Security Applications Conference (ACSAC ’21), December 6–10, 2021, Virtual
Event, USA. ACM, New York, NY, USA, 16 pages. https://doi.org/10.1145/
3485832.3488014
1 INTRODUCTION
Federated learning (FL) [33], as a promising distributed learning par-
adigm, has shown its potential to facilitate real-world applications
like Gboard mobile keyboard [39] [47], electronic health records
mining [19] [31] and credit risk prediction [28]. Roughly speak-
ing, in FL multiple participants (e.g. mobile devices) collaboratively
train a global model via exchanging local updates (i.e., gradients)
under the orchestration of a service provider, while keeping the
training data decentralized. Despite such advantages, existing FL
approaches still suffer from privacy inference [52] [21] [20] and
byzantine attacks [4] [8] [5]. In the former, adversaries can infer
private information (e.g., sensitive training data) of target parties
from the local updates. Particularly in medical diagnosis applica-
tions, patients’ private information such as medical conditions may
be leaked from an unprotected FL system [37]. It fundamentally
violates current strict regulations, such as General Data Protection
Regulation (GDPR). The latter focuses on corrupting the global
model’s accuracy and convergence by submitting elaborate poison-
ing updates, which will cause serious security threats. For instance,
once the underlying FL models of autonomous driving suffer such
attacks, it will cause misclassification and hence severe traffic acci-
dents [4].
To mitigate the information leakage issue, a variety of secure
aggregation schemes based on cryptographic protocols [2] [50]
[7] [10] have been proposed and employed in improving the orig-
inal FL systems. For example, several works use homomorphic
encryption (HE) [2] [50] to encrypt the parties’ gradients. After
that, the service provider can aggregate such encrypted gradients
without decryption due to the homomorphic nature of HE. Besides,
secure multi-party computation (MPC) enables parties to jointly
perform arbitrary function evaluations over their inputs while keep-
ing those inputs private, which is also used in secure aggregation
in FL systems [7] [10] [46]. Consequently, the local gradients of
parties are obfuscated and only the aggregated update is revealed.
On the other hand, many works have made rapid strides towards
45ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Meng Hao, et al.
Table 1: Comparison with prior works on properties necessary for federated learning
realizing byzantine robustness in FL via developing statistically ro-
bust aggregation rules, such as Krum [9], Median [49], and Bulyan
[16]. The main idea is that the service provider removes suspicious
outliers by performing statistical analysis among parties’ local gra-
dients, before updating the global model with them (see Section 2
for more details). Notably, Cao et al. recently proposed the state-of-
the-art byzantine robust FL method, FLTrust [11], which performs
effective and comprehensive byzantine detection by introducing a
novel server update as the baseline and analyzing both the direction
and magnitude of local gradients. Specifically, they first designed
a normalization protocol to prevent the malicious parties’ manip-
ulation on magnitude, and then performed directional similarity
measurement to eliminate the effect of local gradients that are in
the opposite direction from the server update.
Although many works have been proposed to alleviate the prob-
lems of privacy leakage and byzantine attacks, most of them uni-
laterally separate the above two concerns and underestimate their
internal connections. Essentially, privacy violation and byzantine
attacks are intricately intertwined. Attackers may carefully exploit
byzantine vulnerabilities to infer other parties’ training datasets
and hence destroy even privacy-protected FL systems [25], while
privacy leakage provides adversaries with more favorable prior
knowledge to launch omniscient and adaptive byzantine attacks
[18] [8]. Therefore, it is necessary to design a FL system realizing
privacy protection and byzantine robustness simultaneously. To
this end, a natural approach is to integrate generic cryptographic
techniques such as MPC and HE [14] [17] with existing byzantine-
robust FL protocols [9] [11]. However, it adds a large overhead due
to the evaluation of heavy cryptographic operations, e.g. large-scale
matrix multiplication in the measurement of the parties’ gradient
quality, and complex non-linear function used to privately exclude
outlier gradients. Consequently, the challenging problem is how to
design customized cryptographic protocols for private FL systems
that can efficiently implement byzantine defense at the same time.
A few works [43] [24] [29] explored to develop unified solutions
(see Section 2 for more details), however, to "purely" facilitate the
design of efficient cryptographic protocols, they made inappro-
priate trade-offs, such as revealing intermediate values (e.g., the
quality of the parties’ updates) or exploiting simple but vulnerable
aggregation rules [9].
In this paper, we introduce SecureFL, an efficient, private and
byzantine-robust FL framework that approaches the above prob-
lems, as illustrated in Table 1. Our SecureFL follows the state-of-
the-art byzantine robust method, FLTrust [11], and adapts it to the
privacy-preserving context to achieve full privacy protection. We
mainly focus on reducing the overhead of evaluating byzantine
detection under ciphertext. Specifically, inspired by the respective
advantages of HE and MPC, we devise customized cryptographic
protocols for the two key steps of FLTrust. (1) For the magnitude
normalization, the key idea is to design a crypto-friendly
alternative that functionally replaces the costly normaliza-
tion operation. Specifically, we observe that this step involving d
(i.e., the size of the gradient) reciprocal square root and one high-
dimensional inner product is computationally expensive in secure
computation. To reduce this overhead, we leave the implementa-
tion of normalization to the party side in plaintext, and design a
crypto-friendly validity checking protocol for the service provider to
inspect whether parties deviate from the specification and explicitly
exclude updates with wrong form. Along with our customized MPC
protocols, our solution reduces the communication and computa-
tion costs roughly by half, without any privacy leakage and robust-
ness loss. (2) For the directional similarity measurement, our
main insight is that the service provider can pre-compute
some cryptographic protocols before the parties’ local gra-
dients are available. Specifically, we identify and repurpose an
important but under-utilized phase, called preamble phase, where
in prior works the service provider only stays idle and waits for
the parties to upload their local gradients. In our SecureFL, utiliz-