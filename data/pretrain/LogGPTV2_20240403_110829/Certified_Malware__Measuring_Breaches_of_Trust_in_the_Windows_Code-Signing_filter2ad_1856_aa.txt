title:Certified Malware: Measuring Breaches of Trust in the Windows Code-Signing
PKI
author:Doowon Kim and
Bum Jun Kwon and
Tudor Dumitras
Certified Malware: Measuring Breaches of Trust in the Windows
Code-Signing PKI
Doowon Kim
University of Maryland
College Park, MD
PI:EMAIL
Bum Jun Kwon
University of Maryland
College Park, MD
PI:EMAIL
Tudor Dumitras,
University of Maryland
College Park, MD
PI:EMAIL
ABSTRACT
Digitally signed malware can bypass system protection mechanisms
that install or launch only programs with valid signatures. It can
also evade anti-virus programs, which often forego scanning signed
binaries. Known from advanced threats such as Stuxnet and Flame,
this type of abuse has not been measured systematically in the
broader malware landscape. In particular, the methods, effective-
ness window, and security implications of code-signing PKI abuse
are not well understood. We propose a threat model that highlights
three types of weaknesses in the code-signing PKI. We overcome
challenges specific to code-signing measurements by introducing
techniques for prioritizing the collection of code-signing certificates
that are likely abusive. We also introduce an algorithm for distin-
guishing among different types of threats. These techniques allow
us to study threats that breach the trust encoded in the Windows
code-signing PKI. The threats include stealing the private keys asso-
ciated with benign certificates and using them to sign malware or by
impersonating legitimate companies that do not develop software
and, hence, do not own code-signing certificates. Finally, we discuss
the actionable implications of our findings and propose concrete
steps for improving the security of the code-signing ecosystem.
CCS CONCEPTS
• Security and privacy → Systems security; Operating sys-
tems security;
KEYWORDS
Code signing; Windows Authenticode; Malware; PKI; Compromised
certificates
1 INTRODUCTION
Each time we use our computers, we trust the programs executed,
either deliberately or in the background, not to perform unwanted
or harmful actions. Software that appears to come from reputable
publishers, but that performs such actions, breaches this trust.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’17, October 30-November 3, 2017, Dallas, TX, USA
© 2017 Copyright held by the owner/author(s). Publication rights licensed to Associa-
tion for Computing Machinery.
ACM ISBN 978-1-4503-4946-8/17/10...$15.00
https://doi.org/10.1145/3133956.3133958
To establish trust in third-party software, we currently rely on
the code-signing Public Key Infrastructure (PKI). This infrastruc-
ture includes Certification Authorities (CAs) that issue certificates
to software publishers, vouching for their identity. Publishers use
these certificates to sign the software they release, and users rely
on these signatures to decide which software packages to trust
(rather than maintaining a list of trusted packages). If adversaries
can compromise code signing certificates, this has severe impli-
cations for end-host security. Signed malware can bypass system
protection mechanisms that install or launch only programs with
valid signatures, and it can evade anti-virus programs, which often
neglect to scan signed binaries. More generally, the recent advances
in trustworthy computing [30] rely on a functioning mechanism
for bootstrapping trust in third-party programs.
In the past, compromised code-signing certificates have been
associated with advanced threats, likely developed by nation-state
adversaries. For example, the Stuxnet worm included device drivers
that were digitally signed with keys stolen from two Taiwanese
semiconductor companies, located in close proximity [10]. The
Flame malware masqueraded as a file from Windows Update by
conducting a previously unknown chosen-prefix collision attack
against the MD5 cryptographic hash [33]. In both cases, the valid
digital signatures allowed the malware to evade detection and to
bypass anti-virus and Windows protections.
Anecdotal information suggests that a broader range of mali-
cious programs may carry valid digital signatures, resulting from
compromised certificates [10, 11, 33]. However, this threat has not
been measured systematically. In particular, the methods, effective-
ness window, and security implications of code-signing PKI abuse
are not well understood, owing to the difficulty of distinguishing
between malicious and potentially-unwanted behavior. The prior
research on abuse in the code-signing ecosystem [18, 19, 21, 34]
has focused on potentially unwanted programs (PUPs), such as
adware, which are typically signed with certificates legitimately
issued to the PUP publishers. While the signed PUPs substantiate
the utility of valid signatures for abusive programs, the prior re-
sults do not distinguish between certificates issued to publishers of
dubious software by following a legitimate process and abuse of
the code-signing PKI.
In this paper, we conduct a systematic study of threats that breach
the trust encoded in the Windows code-signing PKI. We focus on
signed malware, which is more likely than PUPs to rely on abusive
code signing certificates as malware creators typically try to hide
their identities. Unlike the prior studies on other certificate ecosys-
tems, such as measurements of the Web’s PKI [3, 7, 14, 15, 24, 40],
we cannot rely on a comprehensive corpus of code signing certifi-
cates. These certificates cannot be collected at scale by scanning
the Internet; there is no official list of code signing certificates, or
even of the organizations that can issue such certificates.
To overcome these challenges, we analyze a large data set of
anti-virus reports, corresponding to 1,053,114 malicious files that
carry digital signatures. This data set is made available by Symantec
on the WINE platform [4]. By querying the VirusTotal service [35],
this analysis allows us to prioritize the collection of code signing
certificates that are likely abusive. We also utilize global corporate
directories to identify publishers of benign software and we develop
novel heuristics for distinguishing among different types of abuse.
We find that digitally signed malware was prevalent in the wild
before Stuxnet; the earliest sample in our data set was signed in
2003. 88.8% of the malware families using abusive certificates rely
on a single certificate, which suggests that, in most cases, these
certificates are controlled by the malware authors rather than by
third-party “signing” services. We also estimate that 80% of the
abusive certificates remain a threat for over 5.6 years after they are
first used to sign malware.
To characterize the real-world breaches of trust in the code sign-
ing PKI, we propose a threat model with three classes of weaknesses
that an adversary can exploit: inadequate client-side protections,
publisher-side key mismanagement, and CA-side verification failures.
We infer the prevalence and evolution of each weakness, and we
analyze how long users are exposed to these threats. Then, we con-
servatively select a subset of abusive code signing certificates for
in-depth investigation. Below, we highlight some of our findings
from this analysis:
• Inadequate client-side protections. We find that simply copy-
ing an Authenticode signature from a legitimate file to a
known malware sample may cause anti-virus products to
stop detecting it—even though the signature is invalid, as it
does not match the file digest. 34 anti-virus products are af-
fected, and this type of abuse accounts for 31.1% of malware
signatures in the wild. We notified the anti-virus companies
of the issue. Two companies confirmed that their products
fail to check signature properly; one of them plans to fix the
issue.
• Publisher-side key mismanagement. We identify 72 certifi-
cates that were likely compromised, and we were able to
confirm this with eight publishers; five of them were not
previously aware of the abuse. We analyze a malware family
that infects developer machines and copies malicious code
into files compiled and signed on those machines. We find
that, starting from 180 developer machines, variants of this
malware can reach 93,016 machines—an amplification factor
of 517×.
• CA-side verification failures. We identify 27 certificates issued
to malicious actors impersonating legitimate companies.
We utilize our findings to draw lessons about the trust that we
can place in unknown software packages. We also discuss concrete
proposals for improving the code signing ecosystem. We make the
information of the abusive certificates publicly available at https:
//signedmalware.org. The information includes publisher names,
issuer names, serial numbers, hash values of malware signed with
the certificates, etc.
2 PROBLEM STATEMENT
Code signing is a mechanism for authenticating the software pub-
lisher that released a given executable program. The publisher gen-
erates a pair of cryptographic keys (the public key and the private
key) computes a cryptographic hash of the executable code and
signs the hash with the private key. To prove that it owns the sign-
ing key, the publisher requests from Certificate Authority (CA) a
digital certificate. The certificate includes the name of the publisher,
its public key, and a few other fields; and it is signed with the CA’s
key. A CA may itself have a certificate signed by another CA, re-
sulting in a trust chain that must end in a root certificate that the
end-user trusts. Like any authentication token, certificates must be
revoked when they are compromised. Additionally, before signing
any field of the binary may be forged, including the compilation
timestamp. To prove that the certificate was valid at the time of
signing, the publisher may obtain an additional signature from a
Time Stamping Authority (TSA). The code signature, the certificate
and the timestamp are distributed with the binary. The user who
installs the software and runs the installed executables can then
authenticate the publisher and verify that the binary has not been
tampered with after signing.
The code signing mechanism allows users to set policies on what
executables to trust; for example all executables from a set of trusted
publishers, all executables for which the publisher can be identified
(i.e. they are signed with a valid certificate), or all executables signed
with a certificate that was valid at the time of signing. Additionally,
software updates may be validated and applied automatically if
they are signed with the same certificate as the original program.
Code signing relies on a Public Key Infrastructure (PKI), com-
posed of certificate authorities that can vouch for the identity of
software publishers. Users place their trust in an ecosystem of soft-
ware publishers, root CAs and root TSAs—a large trusted computing
base (TCB) that provides many opportunities for miscreants to com-
promise security. Like in the TLS certificate ecosystem, every CA
can sign certificates for any publisher, and there is no official list of
code signing certificates or even of the organizations that can issue
such certificates. Unlike for TLS, code signing is employed by many
different platforms and operating systems, each with its own root
certificate store: Windows and macOS executables and drivers, Fire-
fox XPIs, Android/iOS apps, Java Jars, Visual Basic for Applications,
Adobe Air apps, etc. This further expands the TCB for an end user.
The TLS PKI has been the subject of several measurement studies
[3, 7, 14, 15, 24, 40], which have illuminated vulnerabilities of the
PKI and how it is abused in the wild. These findings have stimu-
lated research on fixing these problems and have prompted several
efforts for preventing abuse, such as certificate transparency [22],
key pinning [20] and DANE [13]. In contrast, little is known about
the various code signing ecosystems, including the opportunities
for breaching the trust in various actors from these ecosystems, the
prevalence of real-world abuse of the PKI and the extent to which
code signing prevents security threats.
As a first step in this direction, our goal in this paper is to measure
breach-of-trust in the Windows code signing PKI. An adversary
can breach trust relationships explicitly, e.g. by stealing the private
keys associated with benign certificates and using them to sign
malware, or implicitly, e.g. by impersonating legitimate companies
that do not develop software and, hence, do not own code-signing
certificates. We aim to analyze the prevalence of this threat in the
real world and to illuminate the mechanisms for beaching the trust.
We also aim to understand the security implications of these types
of abuse and to examine the effectiveness of proposed PKI improve-
ments in defending against this threat. Our non-goals include fully
characterizing the code signing ecosystems, analyzing certificates
issued legitimately to real (but perhaps ill intentioned) publish-
ers, or developing new techniques for authenticating executable
programs.
2.1 Overview of code signing
On Windows, the prevalent code signing standard is Microsoft Au-
thenticode [26]. The standard is based on Public-Key Cryptography
Standard (PKCS) #7 [16] and is used to digitally sign Windows
portable executables (PE). These include installers (.msi), cabinet
(.cab) and catalog (.cat) files, Active X controls (.ctl, and .ocx), dy-
namically loaded libraries (.dll), and executables (.exe). PKCS #7-
formatted content is called signed data. A signed data blob includes
the signature, the hash value of a PE file, and the certificate chains.
The chains should end in a trusted root certificate, but the signed
data does not need to include the root certificate as long as the
root certificate is present in the users’ root stores. Authenticode
supports MD5, SHA-1, and SHA-256 hashes.
Protections that rely on code signing. On Windows, User Ac-
count Control (UAC) verifies the signature and includes the pub-
lisher’s name in the notification presented to the user when a pro-
gram requests elevated privileges. Microsoft SmartScreen checks ex-
ecutable files downloaded from the Web and assesses the publisher’s
reputation. A publisher may also obtain an Extended Validation
(EV) certificate, which must undergo stricter vetting procedures
outlined in the Guidelines for Extended Validation produced by
the CA/Browser Forum.1 Because of the higher degree of trust in
these certificates, they receive instant reputation in SmartScreen,
while standard code signing certificates must build up their repu-
tation to bypass the SmartScreen Filter. Google Safe Browsing is
another protection system similar to the SmartScreen. The whitepa-
per mentions that "Chrome trusts potentially dangerous file types
that match URLs in the whitelist, and it also trusts files signed by a
trusted authority." 2 Starting with Vista, drivers should be signed by
a trusted Certificate Authority (CA) to be installed on a Windows
machine3. From Windows 10 (version 1607), a stricter requirement
is set: EV certificates are necessary for any new kernel mode drivers
4.
Antivirus engines also utilize code signing information. To re-
duce false positives, some AV engines use whitelisting based on
code signing certificates. For example, Symantec mention in their
whitelisting page: "To prevent false positive detections we strongly
recommend that you digitally sign your software with a class 3
digital certificate." 5
1https://cabforum.org
2https://www.google.com/intl/en/chrome/browser/privacy/whitepaper.html
3https://www.digicert.com/code-signing/driver-signing-certificates.htm
4https://docs.microsoft.com/en-us/windows-hardware/drivers/install/
kernel-mode-code-signing-policy--windows-vista-and-later-
5https://submit.symantec.com/whitelist/
Revocation. Beside issuing new certificates, CAs must sometimes
revoke existing certificates, for a variety of reasons. One of the
most common cases is when a private key associated with the
certificate is compromised6. Certificates using weak cryptographic
keys [39] must be revoked as well. In rare cases, CAs must also
revoke erroneously issued certificates.7
CAs use two mechanisms for informing users of certificate revo-
cations: Certificate Revocation Lists (CRLs) and the Online Certifi-
cate Status Protocol (OCSP). A CRL includes multiple certificates
that have been revoked and is made available at a link specified in
the certificate. These lists are not comprehensive, and users must
periodically download multiple CRLs to receive all the information
about revoked certificates. With OCSP, users query a server main-
tained by the CA to receive the revocation status of a certificate on
demand. Both the CRLs and the OCSP responses are signed by the
CA to ensure their integrity.
2.2 Differences between code signing and TLS
Code signing and the TLS protocols used to secure HTTP communi-
cations utilize X.509 v3 certificates for authentication and integrity.
One type of certificate should not be used for another purpose (e.g.,
program code cannot be signed with a TLS certificate) because its
purpose is indicated in the “Key Usage" and “Extended Key Usage"
fields. The latter field must include “Code Signing” for code sign-
ing certificates and “Server Authentication” for TLS certificates.