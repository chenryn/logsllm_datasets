((x - y) / (xmx - y)) :: basis_loop x xmx ys
else basis_loop x xmx ys.
op basis (x xmx : t) (xm : t list) =
foldr (fun (x y : t) => x * y) F.one (basis_loop x xmx xm).
op interpolate_loop (x : t) (xm : t list) (pm : (t * t) list) =
with pm = [] => []
with pm = y :: ys =>
((basis x (fst y) xm) * (snd y)) :: interpolate_loop x xm ys.
op interpolate (x : t) (pm : (t * t) list) =
let xm = map fst pm in
let bs = interpolate_loop x xm pm in
foldr (fun (x y : t) => x + y) F.zero bs.
Fig. 29: Polynomial Lagrange interpolation
35
theory HBCSecretSharingSchemeSecurity.
clone import SecretSharingScheme.
module type Rand_t = {
proc gen() : rand_t
}.
module type Oracles_t = {
proc corrupt(pid : p_id_t) : unit
}.
...
module type Adv_t (O : Oracles_t) = {
proc choose() : secret_t * secret_t
proc guess(ss : shares_t) : bool
}.
module Game (R : Rand_t) (A : Adv_t) = {
module O = Oracles
module A = A(O)
proc main() : bool = {
...
b <\$ {0,1}; r <@ R.gen(); O.init();
(s0,s1) <@ A.choose();
ss <- share r (b ? s1 : s0);
ss <- get_corrupted O.corrupted ss;
b’ <@ A.guess(ss);
return (b = b’);
}
}.
end HBCSecretSharingSchemeSecurity.
Fig. 30: Honest-but-curious (HBC) security for secret sharing
In order to deﬁne integrity of shares, we used the security notion depicted in Figure 31. To win the security
game, an adversary needs to provide some forgery of shares that were not obtained via an honest execution of
the secret sharing scheme. We model the entire behaviour of the security experience in the adversary oracles
by giving him access to a share oracle - that provides the adversary honestly generated shares -, and with a
forge oracle - which the adversary can use in order to test if some shares are a valid forgery.
The reason why we are modeling the security goal inside an adversary oracle instead of the expected
way (the adversary only have access to a share oracle and it outputs shares that are going to be tested for
forge validity) is because it greatly simpliﬁes the composition proof with an honest-but-curious secret sharing
scheme.
The security of a commitment scheme is presented in Figure 32. It is a very similar security deﬁnition for
other integrity or authenticity schemes such as MAC schemes. An adversary can require commits and also
can check if some commitment is valid for some message. It will then try to forge a message/commitment
pair that veriﬁes but that was not obtained via an honest execution of the commitment scheme.
Finally, we deﬁne malicious security for secret sharing schemes as shown in Figure 33. In this security
experience, the adversary will try to break either the integrity of shares or the indistinguishability of them.
With that purpose, it is given access to a reconstruct oracle that provide it with secrets reconstructed using
the desired set of shares. A malicious (veriﬁable) secret sharing scheme can then be obtained by composing
an honest-but-curious secret sharing scheme with an unforgeable commitment scheme.
36
theory INTSecretSharingSchemeSecurity.
clone import SecretSharingScheme.
module type Rand_t = {
proc gen() : rand_t
}.
module type Oracles_t = {
proc share(s : secret_t) : shares_t option
proc forge(ss : shares_t) : unit
}.
module type Adv_t(O : Oracles_t) = {
proc main() : unit
}.
...
module Game (R : Rand_t) (A : Adv_t) = {
module O = Oracles
module A = A(O)
proc main() : bool = {
...
r <@ R.gen(); O.init(r);
A.main();
return (O.forgery);
}
}.
end INTSecretSharingSchemeSecurity.
Fig. 31: Integrity security for secret sharing
Appendix C MPC security deﬁnitions
The private (active) security deﬁnition for MPC protocols can be found in Figure 34. The security experience
works by phases:
– The initial phase (initial in Figure 34) is ﬁrst initialized with the protocol inputs and randomness, as
well as with an empty corrupted set.
– Before the execution of each phase, the adversary has the ability to either change the input with which a
party is going to execute the stage of the protocol or simply abandon it.
– The result of the phase execution are then used as input to the next phase of the protocol.
In the ideal scenario, the experience will run a simulator using some auxiliary input (which we depict
as leak t) and the input shares of corrupted parties. This simulator will need to be able to produce random
coins and communication traces that have the same probability distribution as the ones outputed by the
real protocol execution. For this particular case of private security, we want the simulator to also be able to
simuate the output share of corrupted parties.
Random security deﬁnition in Figure 35 is deﬁned in a very similar way to private security. In fact, the
only diﬀerences are the protocol input type - each party will only have a share as input - and the type of the
simulator - which will now need to produce random coins and conversation traces based on auxiliary input,
corrupted input shares and corrupted output shares.
Similarly to functionalities, proactive security can be seen as a special case of a re-randomization protocol
like refresh with the caveat that it undermines previous shares of recovered parties. At a high level, this means
that, after the execution of the protocol, the recovering party will have a good share even if it started with a
corrupt one. The deﬁnition of proactive security can be found in Figure 36.
37
theory CommitmentShemeSecurity.
clone import CommitmentScheme.
...
module type Rand_t = {
proc gen() : rand_t
}.
module type Oracles_t = {
proc mac(m : msg_t) : commit_t
proc verify(m : msg_t, t : commit_t) : bool
proc forge(m : msg_t, t : commit_t) : unit
}.
module type Adv_t(O : Oracles_t) = {
proc main() : unit
}.
...
module Game(R : Rand_t, A : Adv_t) = {
module O = Oracles
module A = A(O)
proc main(): bool = {
...
r <@ R.gen(); O.init(r);
A.main();
return (O.forgery);
}
}.
end CommitmentShemeSecurity.
Fig. 32: Unforgeability for commitment schemes
Appendix D MPC concrete protocols
This Appendix will focus on the presentation of several EasyCrypt implementations of MPC protocols, both
in the passive and malicious setting. Due to space constrains, we will focus on the functional behaviour of
protocols.
An honest-but-curious version of the addition protocol can be found in Figure 37. It is a very simple
protocol, since it is composed only by local operations. The only diﬀerence between the passive version and
the malicious one (Figure 38) is the computation of new homomorphic commitments to the new shares.
Figures 39 and 40 represent the passive and active versions of the refresh protocol, respectively. The two
main diﬀerences between the two rely on the use of homomorphic commitments to ensure share integrity:
ﬁrst, parties will produce sharings of zero using a veriﬁable secret sharing scheme and then, shares will be
checked for consistency during the addition step. Note that, besides being a simple modiﬁcation, it induces a
signiﬁcant performace penalty as it requires the computation of several ﬁeld and cyclic group exponentiations.
38
theory MALSecretSharingSchemeSecurity.
clone import SecretSharingScheme.
...
module type Rand_t = {
proc gen() : rand_t
}.
module type Oracles_t = {
proc corrupt(pid : p_id_t) : unit
proc reconstruct(ss : shares_t) : secret_t option
}.
module type Adv_t (O : Oracles_t) = {
proc choose() : secret_t * secret_t
proc guess(ss : shares_t) : bool
}.
module Game (R : Rand_t) (A : Adv_t) = {
module O = Oracles
module A = A(O)
proc main() : bool = {
...
b <\$ {0,1}; O.init(); r <@ R.gen();
(s0, s1) <@ A.choose();
ss <- share r (b ? s1 : s0);
ss <- get_corrupted O.corrupted ss;
b’ <@ A.guess(ss);
return (b = b’);
}
}.
end MALSecretSharingSchemeSecurity.
Fig. 33: Malicious security for secret sharing
An honest-but-curious version of the recover protocol can be obtained via Figure 41. This version is
simpler than the malicious one presented in Section 3.3 since it does not deal with share integrity veriﬁcation.
In fact, the only diﬃculty in implementing this protocol lies on the polynomial interpolation, since every
other operation is a combination of the share and addition protocols.
We end with the presentation of protocols to perform multiplication, both passive - Figure 42 -, and
malicious - Figure 43. Multiplication is done following directions pointed by Asharov and Lindell in [7]. Brieﬂy,
multiplication works by parties ﬁrst multiplying their shares and then subsharing them in order to perform
polynomial degree reduction. For the malicious protocol, parties need to cope with possible modiﬁcation of
subshares and thus there is the need to use an error correction algorithm upon receiving all sub-shares.
39
theory ProtocolPrivateSecurity.
...
module Game (R : Rand_t, Z : Environment_t, A : Adversary_t, S : Simulator_t) = {
module O = Oracles
module A = A(O)
b <\${0,1};
inps <@ Z.choose();
r <@ R.gen(inps);
C.init(inps);
if (valid_inputs inps /\ valid_rands r inps) {
if (b) {
A.run();
(cc,yy) <- P.prot r inps;
cc <- filter_corrupt_convs cc C.corrupt;
b’ <@ Z.guess(poutput2foutput yy, filter_corrupt_outputs yy C.corrupt, cc);
}
else {
A.run();
finp <- pinput2finput inps;
y <- F.f finp;
l <- F.φ finp;
(yy, cc) <@ S.simm(l, filter_corrupt_inputs inps C.corrupt, C.corrupt);
b’ <@ Z.guess(y, yy, cc);
}
}
else {
b <\$ {0,1}
}
return b’;
}.
end ProtocolPrivateSecurity.
Fig. 34: Private security
40
theory ProtocolRandomSecurity.
...
module Game (R : Rand_t, Z : Environment_t, A : Adversary_t, S : Simulator_t) = {
module O = Oracles
module A = A(O)
b <\${0,1};
inps <@ Z.choose();
r <@ R.gen(inps);
C.init(inps);
if (valid_inputs inps /\ valid_rands r inps) {
if (b) {
A.run();
(cc,yy) <- P.prot r inps;
b’ <@ Z.guess(filter_corrupt_outputs yy C.corrupt, filter_corrupt_convs cc C.corrupt);
}
else {
finp <- pinput2finput inps;
y <- F.f r finp;
l <- F.φ r finp;
cc <@ S.simm(l, filter_corrupt_inputs inps C.corrupt, filter_corrupt_foutput y C.corrupt, C.
corrupt);
b’ <@ Z.guess(filter_corrupt_outputs (foutput2poutput y) C.corrupt, cc);
}
}
else {
b <\$ {0,1}
}
return b’;
}.
end ProtocolRandomSecurity.
Fig. 35: Random security
41
theory ProtocolProactiveSecurity.
...