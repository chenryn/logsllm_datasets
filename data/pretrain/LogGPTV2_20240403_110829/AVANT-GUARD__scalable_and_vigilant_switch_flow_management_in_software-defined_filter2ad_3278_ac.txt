in the ﬂow table of the data plane. A set ﬂag bit implies that the
control plane wants to receive packet payloads that match this ﬂow
rule condition.
The running scenario for this function is described in Figure 8. In
this scenario, we assume that the control plane wants to investigate
packet payloads being delivered from a host at 10.0.0.1. First, the
control plane simply asks the data plane to deliver packet payloads
when the source IP address of packets is 10.0.0.1 (1). Second, the
data plane sets the condition ﬁeld for payload of a matched ﬂow
rule (i.e., ﬂow rule whose source IP address ﬁeld is 10.0.0.1) (2).
If the data plane receives a packet from a host whose IP address
is 10.0.0.1 (3), it forwards the packet (with payload) to the control
plane (4). In this case, we just need to add a 1-bit ﬂag to each ﬂow
rule entry in the data plane.
Conditional Flow Rule Activation: In addition to asynchronous
event notiﬁcations, we also employ triggers to introduce condi-
tional ﬂow rule activation. This is a powerful feature that enables
a security application to predeﬁne a course of action strategy for
handling ﬂows when the network encounters certain operating con-
ditions that can be expressed through switch statistics. For exam-
ple, when a DDoS targets a server, the control plane can ﬁnd this
based on the event delivered by the data plane. Then, the data plane
will enforce a ﬂow rule to stop the attack. However, this process
will delay the reaction to the attack because it requires a transaction
Control PlaneData PlaneFlow ruleCondition(2) Register a condition(1) Deﬁne a conditionmatch(3) Check a condition(4-1) Notify an eventPredeﬁned ﬂow rule(4-2) Activate a ﬂow ruleHost A417Figure 8: Scenario illustrating packet payload delivery to the
control plane
between the data plane and the control plane. If the control plane
already installed a ﬂow rule for stopping this attack, the data plane
need not notify the control plane to get a ﬂow rule; instead it simply
activates the installed rule.
To efﬁciently implement this function, we add new entries to
store ﬂow rules into the data plane. The format of these new en-
tries is the same as a normal ﬂow-rule entry in the data plane. The
only difference is that the rules stored in these entries can only be
activated by the condition ﬁeld for the ﬂow rule. The condition for
activating a ﬂow rule is the same as the condition ﬁeld for status,
which we explain below.
This idea is realized by adding two components to the data plane:
(i) memory to store ﬂow rules, and (ii) pointers to ﬁnd installed
ﬂow rules. The pointer is an 8-bit data structure attached to a con-
dition (i.e., the data plane manages up to 256 predeﬁned ﬂow rules).
Figure 9: Scenario illustrating trigger-based notiﬁcation to the
control-plane
To illustrate how a ﬂow rule is activated, we show an operational
scenario in Figure 10. The condition in this Figure is the same as
the condition presented in Figure 9. In this scenario, we assume
that the control plane wants to block a ﬂow if the ﬂow generates
more than 16 packets per second. In this case, the control plane can
deﬁne this condition as we do above (1-3), and request that the data
plane notify the control plane of this event (4). In addition, it will
install a predeﬁned ﬂow rule (5) to BLOCK this trafﬁc.
4. SYSTEM IMPLEMENTATION
We implemented AVANT-GUARD into the software-based Open-
Flow reference switch (we call this the software OF switch) [21].
This reference implementation covers OpenFlow speciﬁcation 1.0.0
[20], and it functions as the data plane. We modiﬁed the source
code of this implementation to support connection migration and
actuating triggers.
Speciﬁcally, we modiﬁed the packet_receive routine in the soft-
ware OF switch to respond to new connection attempts with SYN/ACKs.
The SYN cookie algorithm generates the SEQ number of this packet.
Figure 10: Scenario illustrating trigger-based activation of ﬂow
rules
If the packet-receiving routine subsequently receives a TCP ACK
(i.e., matching the previously generated SYN cookie), it requests
permission from the control plane to migrate the connection. Upon
receiving permission, the modiﬁed OF switch will initiate a TCP
connection to the real target host. To relay subsequent TCP pack-
ets through a migrated channel, we also add functions to care-
fully modify the corresponding ACK or SEQ numbers of each TCP
packet.
We added three new data structures into the software OF switch
to support actuating triggers. We modiﬁed the switch to check
whenever it updates the counter for each ﬂow (or other variables).
If a counter value satisﬁes a condition that is deﬁned by the con-
trol plane, the switch generates a signal back to the control plane.
To implement ﬂow rule activations, we created a data structure that
can hold predeﬁned ﬂow rules. The data structure’s format is the
same as the existing ﬂow-rule data structure (i.e., hash table and
linked list) in the software OF switch.
Although most of the implementation involves extensions to the
data plane (i.e., the software OF switch), minimal modiﬁcation is
also required to the control plane to support the aforementioned
new features. Hence, we extended the source code of the POX
controller [23] to support these capabilities. To support the novel
functionality of AVANT-GUARD, we have added ten new OpenFlow
commands as listed in Table 1. These commands are implemented
in both the software OF switch and the POX controller.
4.1 Hardware Implementation Strategies
Below, we consider how our proposed OpenFlow switch exten-
sions can be realized in a hardware-based implementation.
Traditional SDN Data Plane: First, we review the traditional
SDN data plane architecture, which is illustrated in Figure 11 (A).
This architecture is based on the NetFPGA implementation of the
OpenFlow switch by the OpenFlow inventors [18]. Our focus here
is the ASIC implementation used to conduct packet handling oper-
ations inside the switch. This implementation consists of six main
modules: (i) the input arbiter, which forwards a packet to following
logic; (ii) header parse, which parses a packet header; (iii) exact
match lookup, which ﬁnds a ﬂow rule (w/o wildcards) for a packet;
(iv) wildcard lookup, which ﬁnds a ﬂow rule (with wildcard) for a
packet; (v) the arbiter, which decides operations of a packet (for-
ward or drop); and (vi) the packet editor, which forwards or mod-
iﬁes a packet.
In addition, ﬂow rules are stored in a TCAM or
SRAM (outside of the ASIC), and a counter storing statistical val-
ues for each ﬂow rule is attached to the TCAM or SRAM.
We illustrate the operation of this hardware switch implementa-
tion using the following scenario. First, if the data plane receives
Control Plane10.0.0.1 -> *1(1)(2)10.0.0.120.0.0.1(3)(match with this rule)(4)Data Planecondition ﬁeldfor payloadControl Plane10.0.0.1 -> *: Forward10(1)(2)10.0.0.1(3)(match with this rule)(4)Data Planecondition ﬁeld for status1700:01010:0X1016 bit16 bit19 bit (3 + 16)10.0.0.1 -> *: Forward10(1)(2)(3)(match with this rule)(4)Data Planecondition ﬁeld for status1700:0110:1010:0X1016 bit16 bit22 bit (2+4+16)20.0.0.1 -> *: Blockﬂow rule: Block28 bit(5)(B)(A)10.0.0.1Control Plane418Command
OFPFC_MIGRATE
OFPFC_RELAY
OFPFC_REG_PAYLOAD
OFPFC_REG_STATUS
OFPFC_REG_RULE
OFPR_NEWFLOW
OFPR_MIGRATE_SUCCESS
OFPR_MIGRATE_FAIL
OFPR_PAYLOAD
OFPR_STATUS
Direction
C → D
C → D
C → D
C → D
C → D
D → C
D → C
D → C
D → C
D → C
Explanation
allow connection migration
allow data relay
register payload condition
register network status condition
register a new ﬂow rule
report a new ﬂow
report a migration result (SUCCESS)
report a migration result (FAIL)
deliver payload
report a detected event
Table 1: New OpenFlow commands implemented by AVANT-GUARD (C denotes control plane, and D denotes data plane)
a packet, the lookup component checks the TCAM or SRAM to
see if a ﬂow rule handling this packet exists. If so, it forwards the
packet to the arbiter. Otherwise, it asks the control plane through
an interface running on the CPU.
Implementation of Connection Migration: To implement con-
nection migration in hardware, we need to modify three compo-
nents in the data plane and add two new data structures into the data
plane. The new data-plane architecture with connection migration
is presented in Figure 11(B). The header parser is modiﬁed to ex-
tract TCP ﬂags, and the arbiter is modiﬁed to force the packet editor
to initiate connection migration or to reply with a TCP SYN/ACK
packet. We add a connection-handler module to the packet editor.
This module can initiate connection migration or answer a connec-
tion request by sending the SYN/ACK.
We also add two new data structures to support the relay stage
of connection migration. Because our data plane needs to manage
two TCP connections as a single connection, it should change the
ACK or SEQ number of each packet. We only need to track the
difference between the SEQ number of SYN packets (SYN from
a connection initiator to the data plane) and the inside connection
(SYN from the data plane to the destination of our migration). This
difference value will be stored in an ACK/SEQ delta structure, and
the number of this value is the same as the number of migrated
connections.
TCP connections also come with certain TCP options, such as
timestamp, and our data plane should handle this value as we do for
ACK or SEQ change. To support this, we have added an optional
structure into the data plane to track the TCP timestamps between
external and internal connections. However, this is optional, be-
cause the data plane could also simply discard such options during
TCP negotiation.
Implementation of Actuating Triggers: To implement our ac-
tuating trigger in hardware, we add two data structures for storage
into the data plane. This architecture is shown in Figure 11(B).
All condition ﬁelds for the actuating trigger are collectively labeled
as Condition in this Figure, and they are attached to counters in
the data plane. Also, predeﬁned ﬂow rules can be implemented by
adding the same components for ﬂow rules (TCAM and SRAM).
For implementations that are cost sensitive, we may share existing
TCAM or SRAM storage for these ﬂow rules (not denoted in the
Figure).
Off-ASIC Implementation of AVANT-GUARD: The architec-
ture described above involves adding new components to the ASIC
in the data plane which is both costly and complex. Here, we are
inspired by Mogul’s research [11], which suggests we may move
some components out of the ASIC, and could potentially lever-
age the switch CPU and DRAM to implement certain functionality.
In this case, we cannot avoid modifying existing components (i.e.,
Figure 12: Environment for network saturation attack scenario
modiﬁed header parser), but we can ofﬂoad some storage require-
ments from the ASIC by moving data structures into DRAM. This
architecture is presented in Figure 11(C). As shown in this ﬁgure,
we place all storage into DRAM. Logic that resides in the ASIC
could access DRAM content through the CPU (e.g., via a PCI in-
terface). This approach trades off some performance for simpliﬁed
development cost.
5. EVALUATION
In this section, we present how SDN security researchers and
practitioners can leverage the beneﬁt of AVANT-GUARD to develop
simpler and stronger network security applications.
5.1 AVANT-GUARD Use Cases
We ﬁrst describe an example use case for a security application
and then compare two scenarios: (i) implementing the security ap-
plication with existing OpenFlow technology and (ii) implement-
ing the same function with AVANT-GUARD. We select three com-
mon network threats for comparison: (i) network saturation attack,
(ii) network scanning attack, and (iii) network intrusion attack.
For each case, we employ the software OF reference switch imple-
mentation [21] for our data plane, and AVANT-GUARD has been
implemented into this reference implementation. We turn on or
off the functions of AVANT-GUARD to compare the functions of
each case. For the control plane, we use a modiﬁed POX controller
[23] for both switches. The host running this S/W OF switch (w
AVANT-GUARD or w/o AVANT-GUARD) was conﬁgured with an
Intel Core-i5 CPU and 8 GB of memory.
5.1.1 Network Saturation Attack
Example Scenario: The test environment for this experiment is
shown in Figure 12. It includes an OpenFlow switch (i.e., the data
plane) in which AVANT-GUARD has been implemented; a POX net-
work controller; a server that hosts a web service; a normal client
that contacts the server with HTTP requests; and an attacker who
performs a TCP SYN ﬂood attack.
In this scenario, we measure the response time (i.e., the time
it takes a normal client to fetch a page of data from the remote