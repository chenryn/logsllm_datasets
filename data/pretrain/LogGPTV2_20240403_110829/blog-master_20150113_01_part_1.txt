## ZFS case : top CPU 100%sy, when no free memory trigger it.  
### 作者                                                                                                                                                                                                 
digoal                                                                                                                                                                                                   
### 日期                                                                                                                                                                                                                  
2015-01-13                                                                                                                                                                                         
### 标签                                                                                                                                                                                               
PostgreSQL , Linux , ZFS                                                                                                                                                                                             
----                                                                                                                                                                                                         
## 背景                                
最近在一个系统频频遇到负载突然飙升到几百, 然后又下去的情况.  
根据负载升高的时间点对应的数据库日志分析, 对应的时间点, 有大量的类似如下的日志 :   
```  
"UPDATE waiting",2015-01-09 01:38:47 CST,979/7,2927976054,LOG,00000,"process 26366 still waiting for ExclusiveLock on extension of relation 686062002 of database 35078604 after 1117.676 ms",,,,,,"  
"INSERT waiting",2015-01-09 01:38:36 CST,541/8,2927976307,LOG,00000,"process 25936 still waiting for ExclusiveLock on extension of relation 686062002 of database 35078604 after 1219.762 ms",,,,,,"  
"INSERT waiting",2015-01-09 01:38:48 CST,1018/64892,2929458056,LOG,00000,"process 26439 still waiting for ExclusiveLock on extension of relation 686061993 of database 35078604 after 1000.105 ms",  
.........  
```  
对应几个对象的块扩展等待  
```  
select 686062002::regclass;  
          regclass             
-----------------------------  
 pg_toast.pg_toast_686061993  
(1 row)  
select relname from pg_class where reltoastrelid=686062002;  
               relname                 
-------------------------------------  
 tbl_xxx_20150109  
(1 row)  
Time: 4.643 ms  
```  
同时系统的dmesg还伴随 :   
```  
postgres: page allocation failure. order:1, mode:0x20  
Pid: 20427, comm: postgres Tainted: P           ---------------    2.6.32-504.el6.x86_64 #1  
Call Trace:  
   [] ? __alloc_pages_nodemask+0x74a/0x8d0  
 [] ? handle_IRQ_event+0x60/0x170  
 [] ? kmem_getpages+0x62/0x170  
 [] ? fallback_alloc+0x1ba/0x270  
 [] ? cache_grow+0x2cf/0x320  
 [] ? ____cache_alloc_node+0x99/0x160  
 [] ? kmem_cache_alloc+0x11b/0x190  
 [] ? sk_prot_alloc+0x48/0x1c0  
 [] ? sk_clone+0x22/0x2e0  
 [] ? inet_csk_clone+0x16/0xd0  
 [] ? tcp_create_openreq_child+0x23/0x470  
 [] ? tcp_v4_syn_recv_sock+0x4d/0x310  
 [] ? tcp_check_req+0x226/0x460  
 [] ? tcp_v4_do_rcv+0x35b/0x490  
 [] ? ipv4_confirm+0x87/0x1d0 [nf_conntrack_ipv4]  
 [] ? tcp_v4_rcv+0x522/0x900  
 [] ? ip_local_deliver_finish+0x0/0x2d0  
 [] ? ip_local_deliver_finish+0xdd/0x2d0  
 [] ? ip_local_deliver+0x98/0xa0  
 [] ? ip_rcv_finish+0x12d/0x440  
 [] ? ip_rcv+0x275/0x350  
 [] ? __netif_receive_skb+0x4ab/0x750  
 [] ? netif_receive_skb+0x58/0x60  
 [] ? napi_skb_finish+0x50/0x70  
 [] ? napi_gro_receive+0x39/0x50  
 [] ? igb_poll+0x981/0x1010 [igb]  
 [] ? tcp_delack_timer+0x0/0x270  
 [] ? tcp_send_ack+0xd9/0x120  
 [] ? net_rx_action+0x103/0x2f0  
 [] ? __do_softirq+0xc1/0x1e0  
 [] ? handle_IRQ_event+0x60/0x170  
 [] ? __do_softirq+0x11f/0x1e0  
 [] ? call_softirq+0x1c/0x30  
 [] ? do_softirq+0x65/0xa0  
 [] ? irq_exit+0x85/0x90  
 [] ? do_IRQ+0x75/0xf0  
 [] ? ret_from_intr+0x0/0x11  
   [] ? compaction_alloc+0x269/0x4b0  
 [] ? compaction_alloc+0x1c2/0x4b0  
 [] ? migrate_pages+0xaa/0x480  
 [] ? common_interrupt+0xe/0x13  
 [] ? compaction_alloc+0x0/0x4b0  
 [] ? compact_zone+0x61a/0xba0  
 [] ? compact_zone_order+0xac/0x100  
 [] ? try_to_compact_pages+0xe1/0x120  
 [] ? __alloc_pages_direct_compact+0xda/0x1b0  
 [] ? __alloc_pages_nodemask+0x415/0x8d0  
 [] ? alloc_pages_vma+0x9a/0x150  
 [] ? do_huge_pmd_anonymous_page+0x14d/0x3b0  
 [] ? handle_mm_fault+0x2f0/0x300  
 [] ? __do_page_fault+0x138/0x480  
 [] ? mutex_lock+0x1e/0x50  
 [] ? do_page_fault+0x3e/0xa0  
 [] ? page_fault+0x25/0x30  
```  
这是个日志表, 有4个索引, 其中一个变长字段存储的值较长(因此有用到TOAST存储), 例如  
```  
DxxxxxxxxxxxxzwLlyyDd7xGd7^7xxwLDxyD@5xHB7^if5^vv4&DJCEL7xxxCFyhsxxxd4x~j2%$BB%ChkzHlzzvxBwqn5^DDCFexzwC@zyLDz  
zC~zyDDzyCbAyyh3M~v5^DDCHvBBy%j0%iL4^fJB%K1xxxB%G1wz~h2M%B4%qn5&7xxwyPs!$xJ!Dd7xCb3^DFCGLnzyzlzyP7zyCJ7x)Lx^xxxxxxxy73$rLB&DND  
zL5zy~xxyCt4xPj4%DJCE~DzyP#zyLPzyypxxx3&~DB^P1zzC5zye5wzz10MCb3^Gp4^DLCEiNywi$yzvxBwL73&$F7%7xzwG5zyy5wyah4MbzB%C1DzL9zyf5yyG9z  
y!1zyLJxyCt4xPP5%nLB&xxxx  
&7xxwjHzzi#yyi$yzi$yzmHIPm^K@CbAzzh5MDBCGLxxxxwz~h5M$JB%DxDzGlzyH5zyL7zzylzyC9AyLxxx7xxwC5AyzNxxxxxx5%Pp0  
^~d0&6NzwK1wyzN1M%xxxx^P74^DJCGD7yyvBByiF4&Pt0%~d0&6hwwvDByiF4&et5xxxxxx17%$$1^DBCFGfwxzh2M!j1%qv5^DLCF!NzyH5zzvJBy%h4  
%aD4&%v4^61zwDnyyK5wyzN0Mxxxx5$71zwCd7xCv0&fj5&(h1%yNc%mf7%71zwxxx%a@4%rpd^a5d$71zwCt5x!l1$~^l^LDx&K1wzmh5MxxxxxxxxxxGr4&Dvd&$jl  
%LBx%K1wzPh5M$Ll^yn1&Ht6+fxxxxxxwC@5xqnxxx&~90^fj5+Oh5%71zwDJ7xH~j&yDh$G@5^7xxxx^Gp4@DLCEf1yw7b0~bn0^%^i&HDzyebz  
y6)zyLBzyfdyyvxBwH#5%GP5^nvd&$LB^DN5zqHA^%P1^nLlEDL5%$@n^i#4^$J7%nPn+bzF@Ct4xD~1&GB4^add%7xxw!7zybBxyC@5xqn5xxxxx!DLCEvBxxxd6&!vL@7xx  
w)dyECn5&)B1zxxxxxOz)D&HND&C9DOOl1yzpD&xxxxxx1^6hzwLrzyf3zxxx&L73+Gp4@DLCEiNywi$yzvxBw$h5%Hdf&(l9%zh0%nHB^D1zz~7zyvzB  
yHl6%jl4!!Fg^rLB%DhDzC5xxxxb7j&aH4^)txxxDzvxBw$v0%DJCEzNxxxxzyzr1y~Lzx(vA&(@zyrtCyy5DxxxHl5OHbDO$3DxxxyyN0MD~1%afd&71z  
wDd7xj17xxxxx$)7^7N2wq8*=  
```  
每天会新建一个表, 因此不停的在做数据块的扩展, 但是理论上扩展是比较快的, 不会导致以上情况的发生, 而且发生问题的时间点, 数据量, 并发量也正常.  
关于这个等待的情况, 可以参考之前写过一篇文章, 关于批量导入遇到的extend lock等待的性能问题.  
http://blog.163.com/digoal@126/blog/static/163877040201392641033482  
和本文 性能的 case 无关.  
看样子是ZFS的问题, 最后排查发现.   
free的内存在不停的减少, 当减少到0的时候, 负载就会马上飙升.   
环境 :   
```  
CentOS 6.x x64  
2.6.32-504.el6.x86_64  
```  
zfs 版本  
```  
zfs-0.6.3-1.1.el6.x86_64  
libzfs2-0.6.3-1.1.el6.x86_64  
zfs-dkms-0.6.3-1.1.el6.noarch  
```  
服务器内存 384G  
数据库shared buffer 20GB, maintenance_work_mem=2G, autovacuum_max_workers=6   
不算work_MEM的话, 数据库最多可能占用32G内存.   
还有300多G可以给系统和ZFS使用.  
zfs 参数如下  
```  
cd /sys/module/zfs/parameters  
# grep '' *|sort   
l2arc_feed_again:1  
l2arc_feed_min_ms:200  
l2arc_feed_secs:1  
l2arc_headroom:2  
l2arc_headroom_boost:200  
l2arc_nocompress:0  
l2arc_noprefetch:1  
l2arc_norw:0  
l2arc_write_boost:8388608  
l2arc_write_max:8388608  
metaslab_debug_load:0  
metaslab_debug_unload:0  
spa_asize_inflation:24  
spa_config_path:/etc/zfs/zpool.cache  
zfetch_array_rd_sz:1048576  
zfetch_block_cap:256  
zfetch_max_streams:8  
zfetch_min_sec_reap:2  
zfs_arc_grow_retry:5  
zfs_arc_max:10240000000  
zfs_arc_memory_throttle_disable:1  
zfs_arc_meta_limit:0  
zfs_arc_meta_prune:1048576  
zfs_arc_min:0  
zfs_arc_min_prefetch_lifespan:1000  
zfs_arc_p_aggressive_disable:1  
zfs_arc_p_dampener_disable:1  
zfs_arc_shrink_shift:5  
zfs_autoimport_disable:0  
zfs_dbuf_state_index:0  
zfs_deadman_enabled:1  
zfs_deadman_synctime_ms:1000000  
zfs_dedup_prefetch:1  
zfs_delay_min_dirty_percent:60  
zfs_delay_scale:500000  
zfs_dirty_data_max:10240000000  
zfs_dirty_data_max_max:101595342848  
zfs_dirty_data_max_max_percent:25  
zfs_dirty_data_max_percent:10  
zfs_dirty_data_sync:67108864  
zfs_disable_dup_eviction:0  
zfs_expire_snapshot:300  
zfs_flags:1  
zfs_free_min_time_ms:1000  
zfs_immediate_write_sz:32768  
zfs_mdcomp_disable:0  
zfs_nocacheflush:0  
zfs_nopwrite_enabled:1  
zfs_no_scrub_io:0  
zfs_no_scrub_prefetch:0  
zfs_pd_blks_max:100  
zfs_prefetch_disable:0  
zfs_read_chunk_size:1048576  
zfs_read_history:0  
zfs_read_history_hits:0  
zfs_recover:0  
zfs_resilver_delay:2  
zfs_resilver_min_time_ms:3000  
zfs_scan_idle:50  
zfs_scan_min_time_ms:1000  
zfs_scrub_delay:4  
zfs_send_corrupt_data:0  
zfs_sync_pass_deferred_free:2  
zfs_sync_pass_dont_compress:5  
zfs_sync_pass_rewrite:2  
zfs_top_maxinflight:32  
zfs_txg_history:0  
zfs_txg_timeout:5  
zfs_vdev_aggregation_limit:131072  
zfs_vdev_async_read_max_active:3  
zfs_vdev_async_read_min_active:1  
zfs_vdev_async_write_active_max_dirty_percent:60  
zfs_vdev_async_write_active_min_dirty_percent:30  
zfs_vdev_async_write_max_active:10  
zfs_vdev_async_write_min_active:1  
zfs_vdev_cache_bshift:16  
zfs_vdev_cache_max:16384  
zfs_vdev_cache_size:0  
zfs_vdev_max_active:1000  
zfs_vdev_mirror_switch_us:10000  
zfs_vdev_read_gap_limit:32768  
zfs_vdev_scheduler:noop  
zfs_vdev_scrub_max_active:2  
zfs_vdev_scrub_min_active:1  
zfs_vdev_sync_read_max_active:10  
zfs_vdev_sync_read_min_active:10  
zfs_vdev_sync_write_max_active:10  
zfs_vdev_sync_write_min_active:10  
zfs_vdev_write_gap_limit:4096  
zfs_zevent_cols:80  
zfs_zevent_console:0  
zfs_zevent_len_max:768  
zil_replay_disable:0  
zil_slog_limit:1048576  
zio_bulk_flags:0  
zio_delay_max:30000  
zio_injection_enabled:0  
zio_requeue_io_start_cut_in_line:1  
zvol_inhibit_dev:0  
zvol_major:230  
zvol_max_discard_blocks:16384  
zvol_threads:32  
```  
这些参数的介绍可参考 :   
```  
man /usr/share/man/man5/zfs-module-parameters.5.gz  
```  
zpool参数  
```  
# zpool get all zp1  
NAME  PROPERTY               VALUE                  SOURCE  
zp1   size                   40T                    -  
zp1   capacity               2%                     -  
zp1   altroot                -                      default  
zp1   health                 ONLINE                 -  
zp1   guid                   15254203672861282738   default  
zp1   version                -                      default  
zp1   bootfs                 -                      default  
zp1   delegation             on                     default  
zp1   autoreplace            off                    default  
zp1   cachefile              -                      default  
zp1   failmode               wait                   default  
zp1   listsnapshots          off                    default  
zp1   autoexpand             off                    default  
zp1   dedupditto             0                      default  
zp1   dedupratio             1.00x                  -  
zp1   free                   39.0T                  -  
zp1   allocated              995G                   -  
zp1   readonly               off                    -  