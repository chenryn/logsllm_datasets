title:Breaking and (Partially) Fixing Provably Secure Onion Routing
author:Christiane Kuhn and
Martin Beck and
Thorsten Strufe
2020 IEEE Symposium on Security and Privacy
Breaking and (Partially) Fixing Provably Secure
Onion Routing
∗(cid:104)ﬁrstname.lastname(cid:105)@kit.edu, KIT Karlsruhe
†(cid:104)ﬁrstname.lastname(cid:105)@tu-dresden.de, TU Dresden
Christiane Kuhn∗‡, Martin Beck†, Thorsten Strufe∗†
Abstract—After several years of research on onion routing,
Camenisch and Lysyanskaya, in an attempt at rigorous analysis,
deﬁned an ideal functionality in the universal composability
model, together with properties that protocols have to meet
to achieve provable security. A whole family of systems based
their security proofs on this work. However, analyzing HORNET
and Sphinx, two instances from this family, we show that this
proof strategy is broken. We discover a previously unknown
vulnerability that breaks anonymity completely, and explain a
known one. Both should not exist if privacy is proven correctly.
In this work, we analyze and ﬁx the proof strategy used for
this family of systems. After proving the efﬁcacy of the ideal
functionality, we show how the original properties are ﬂawed and
suggest improved, effective properties in their place. Finally, we
discover another common mistake in the proofs. We demonstrate
how to avoid it by showing our improved properties for one
protocol, thus partially ﬁxing the family of provably secure onion
routing protocols.
I. INTRODUCTION
Anonymous communication protocols are developed to
protect communication meta data from surveillance. With
millions of users1 Tor [16] is the most widely known protocol to
restrict the information an adversary learns. It relies on the idea
of Onion Routing (OR) [21]. This generic approach removes the
relationship between a message and its corresponding sender
by forwarding the message over multiple proxies that modify
it at each hop.
With increasing importance of OR,
the need to build
efﬁcient protocols for low delay communication with proven
security guarantees became apparent. To simplify building those
protocols, Sphinx [13] was proposed as a secure packet format
for onions. Building on this format HORNET [11], among
others, was proposed for high-speed OR at the network layer.
Using multiple cryptographic techniques the authors both of
Sphinx and HORNET present proofs along the lines of the
strategy proposed by Camenisch and Lysyanskaya in [8].
This proof strategy is based on deﬁning an ideal functionality
for OR2 in the universal composability (UC) model. The
functionality is an abstraction to show which information even
a perfect OR scheme leaks to an adversary. The authors in
addition design protocol properties. Proving that a real world
protocol complies with these properties, they claim, implies
‡ This work in parts was carried out while afﬁliated with TU Dresden.
1according to https://metrics.torproject.org/userstats-relay-country.html
2Understanding of OR varied in the ﬁeld. To be compliant with the
terms of [8], we understand OR in this work as a free-route Chaumian
MixNet [10] without requiring that messages are delayed. This conforms with
the understanding of [21] and [16] except that circuits are excluded.
the security and privacy of their ideal OR functionality. This
convenient proof scheme has been used to analyze the privacy
of a whole family of recent, efﬁcient packet formats (e.g. the
improved Minx [29] and Sphinx [13]) and OR protocols (e.g.
HORNET [11] and TARANET [12]).
Analyzing HORNET, we discovered a simple attack on its
data transmission phase that allows it to link senders to receivers
and large parts of the messages to their senders as well. Our
attack complies to HORNET’s adversary model and should
have been detected when proving its security. We found that
similar attacks are to some extent possible on related work [12],
[13], [29]. In addition, there is a padding ﬂaw in Sphinx [13],
luckily detected and corrected in the implementation3, that has
escaped the formal analysis. Undetected, this ﬂaw would have
jeopardized the privacy of the senders in systems using Sphinx.
the protocols prove privacy based on the ideal
functionality and properties of [8], attacks threatening the users’
privacy should not be possible in the ﬁnal protocol. We thus
set out to identify and correct the mistakes in the process. As it
turns out, there are multiple open questions and discrepancies
that have to be solved for the proof strategy.
As all
First, no one ever analyzed the privacy this ideal OR
functionality actually achieves, to start with. Many papers [1],
[3], [4], [6], [15], [17]–[19], [26]–[28], [30] citing it disagree
violently on this point. As our ﬁrst contribution towards solving
the matter, we analyze the ideal functionality. We show that
it indeed implies the privacy goals expected for OR, namely
sender anonymity and relationship anonymity, against a limited
yet useful adversary model.
Next, we look closer at the attack on Sphinx and realize the
ﬁrst mistake: The properties proposed to imply the privacy of
the ideal functionality are not sufﬁcient. Proving the original
properties thus does not provide any privacy guarantee. Having
a closer look at the properties, we discover that one of them
is inexact, a second missing important aspects, and the last
two lack to provide any additional privacy. To understand
what exactly is missing, we construct two obviously broken
protocols that still fulﬁll the properties. Based on our insights
from the broken protocols, we construct two new properties,
Tail-Indistinguishability and Layer-Unlinkability, and prove
that they, together with the correction of the inexact property,
indeed imply the privacy of the analyzed ideal functionality.
3https://github.com/UCL-InfoSec/sphinx/blob/
c05b7034eaffd8f98454e0619b0b1548a9fa0f42/SphinxClient.py#L67
© 2020, Christiane Kuhn. Under license to IEEE.
DOI 10.1109/SP40000.2020.00039
168
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:48 UTC from IEEE Xplore.  Restrictions apply. 
Thus, they allow to prove privacy with the convenient strategy
of showing that a protocol meets the improved properties.
By reconsidering our new attack on HORNET, we uncover an
independent second mistake: The properties of Camenisch and
Lysyanskaya have not been proven correctly for the protocols.
More precisely, the oracles used in the original deﬁnition of
the properties have been ignored or weakened.
Finally, we demonstrate how to perform an analysis for
our new properties, by proving that a variation of Sphinx [5],
which improves performance but neglects replies, has (with the
small additional correction to the padding ﬂaw known from the
Sphinx implementation) the privacy of the ideal functionality.
By solving the issues, it turns out that the model behind
the ideal functionality does neither support anonymous reply
packets, nor sessions – which are frequently adapted in above
papers. The privacy for these extensions cannot be proven
using the given ideal functionality. In this work, we favor a
rigorous treatment of the foundations, i.e. sending a message
to a receiver, over extensions like sessions and reply channels.
We conjecture that with the solid foundation given in this paper
the issues of sessions and replies can be solved in future work
by adapting the functionality and properties.
Our main contributions are: (a) a privacy analysis of the ideal
functionality of Camenisch and Lysyanskaya; (b) a rigorous
analysis of the original properties; (c) the design of improved
properties that provably achieve the ideal functionality; (d)
a new attack on HORNET, that similarly is possible on the
improved Minx (and in slight violation of their models, on
TARANET and Sphinx); (e) demonstrations of ﬂaws in the
privacy proofs of the above named formats and systems; (f) a
demonstration how to prove the corrected properties.
Outline: We ﬁrst introduce the background, then analyze
the ideal functionality, followed by the explanation of the
Sphinx ﬂaw and original properties. After this we show
weaknesses of the original properties, construct new properties
and prove them secure. Next, we explain the new HORNET
attack and the ﬂaw in the proofs. Finally, we prove a variation
of Sphinx private, discuss our ﬁndings and conclude the paper.
II. BACKGROUND
This section explains the adversary model, OR and selected
existing systems based on OR. We further introduce the formal
proof strategy [8] and the used privacy deﬁnitions [23].
For explaining OR, we consider the scenario of whistleblower
Alice who wants to leak sensitive information to media agent
Bob and uses open anonymization systems (like Tor) to hide
from a regime that deploys mass surveillance.
A. Adversary Model
Assuming a nation state adversary we have to expect a
global attacker with full control over the Internet infrastructure.
This entails the possibility to observe all links and to actively
drop, delay, modify, and insert packets on any link. Given
the open nature of anonymization systems, the adversary can
easily provide a large subset of nodes, which seemingly run the
anonymization system, but are really under her full control. She
hence knows all secret keys of those nodes, and she can modify,
drop, and insert packets at each of them. Even the receivers
are untrusted and considered potentially under control of the
adversary, and as the system is open, the adversary may also act
as one or a set of senders, seemingly using the anonymization
system parallel to Alice. We assume full collusion between all
adversarial parties, but follow the common assumption that the
attacker is limited to probabilistic polynomial time algorithms
(PPT). These assumptions are common for onion routing, and
they correspond to the model in [8].
B. Onion Routing (OR)
Considering the scenario, sending her message to Bob, the
journalist, Alice requires that both Bob and the regime shall
not learn that she was the individual sending the message.
Given the existence of a trusted proxy, she can encrypt her
message with the public key of the proxy and send it there, to
be decrypted and forwarded to Bob on her behalf. Her identity
then is hidden in the set of all users that communicate over this
proxy at the same time. The set of these users is commonly
called her anonymity set.
Given the open nature of the system, Alice cannot trust
any single proxy completely. She hence chooses a chain of
proxies, hoping that one of the proxies is honest and does not
collaborate with the adversary. To hide the mapping between the
packets that arrive at and depart from a proxy, she consecutively
encrypts the packet for each of the proxies on the chain, and
includes a header signaling where to forward the packet next.
Each proxy locally decrypts and forwards the packet. The last
proxy decrypts it to the original message and forwards it to
Bob.
As the packet is encrypted in several layers that consecutively
are removed, the scheme is commonly called onion encryption.
The proxies hence often are called onion routers, or relays.
Decrypting at the relays yields the intermediate header
and a shorter onion for the next relay. Corresponding length
reductions of the onions would leak information that the
adversary could use to link observed packets arriving and
departing at an honest relay. Onions hence are usually padded
to a ﬁxed length that is globally known, which restricts the
maximum length of the payload as well as the number of relays
on the path that can be addressed. We therefore assume the
maximum path length N in terms of hops between an honest
sender and a receiver.
Assumption 1: The OR protocol has a maximum path length
of N.
Protection in OR follows from hiding the link between
incoming and outgoing onions at a relay. Should the adversary
by chance control all proxies that are chosen for an onion, she
can trivially reversely link outgoing to incoming onions for
all relays, and hence identify Alice as the original sender of
a message delivered to Bob. As the path is chosen by Alice
who actively aims to remain anonymous towards Bob and the
regime, she will pick a path solely containing corrupted relays
only rarely, by mistake. We therefore, deem it suitable to add
the following assumption for our analysis:
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:48 UTC from IEEE Xplore.  Restrictions apply. 
169
Assumption 2: There is at least one honest relay on the
chosen path, if the sender is honest.
Further, as the adversary can actively insert packets, she
can replay the same onion at the honest relay and observe the
same behavior twice. OR protocols hence usually implement a
replay protection, by detecting and dropping replayed onions.
For an easier analysis, we limit our scope to replay protection
mechanisms that drop onions that have already been processed:
Assumption 3: The replay protection, if one is used, drops
bit-identical onions.
C. Network Model
Onion Routing can be used in two different modes: the
receiver participating in the anonymization protocol, or not.
The ﬁrst case considers an integrated system to be set up
for anonymous communication. The receiver will act as an
onion router and, while processing an onion, discover that
it is intended for herself. In the second case messages are
anonymized as a service and the receiver is unaware of the
anonymization happening. The last router, called exit node,
discovers that the message needs to be forwarded outside the
anonymization network to reach its receiver.
D. Existing Schemes and Systems
Danezis and Goldberg [13] deﬁne Sphinx, a packet format for
secure OR. Sphinx’s goals are to provide bitwise unlinkability
between onion layers before and after an honest node, resistance
against all active tagging attacks to learn the destination or
content of a message, and space efﬁciency. Hiding the number
of hops an onion already traveled, and the indistinguishability
of both forward onions as well as response onions on a reply
channel were considered to further strengthen privacy. Their
network model assumes anonymization services, and their
adversary model mainly matches the above description. Trafﬁc
analysis, ﬂooding or denial of service are however excluded.
Tagging attacks, i.e. an adversary modifying onions before
reinjecting them, on the other hand are explicitly allowed.
Sphinx’s onion layers consist of a header that contains all
path information except the receiver, and a payload that contains
the protected message and protected receiver address. Padding
and multiple cryptographic primitives are used for construction
and processing of onions, but the integrity of the payload at
each layer is not protected by Sphinx as this would conﬂict
with their support for replies. Tampering with the payload is
only recognized at the exit node. As security proof, Danezis
and Goldberg prove the properties of [8] for Sphinx.
Predecessors to Sphinx were Minx [14] and its ﬁxed
version [29]. Like Sphinx, neither of the two protects the
integrity of the payload at the relays. Beato et al. proposed
a variant of Sphinx [5] that neglects replies and replaces the
cryptographic primitives to increase performance and security,
and thereby protects the integrity of the payload at each relay.
Subsequent to the work on packet formats, Chen et al.
proposed the protocol HORNET [11] as a high-speed, highly
scalable anonymity system for the network layer. The authors
claim that HORNET protects the anonymity of Alice against
a slightly restricted adversary compared to our attacker: The
attacker does actively control a fraction of the relays (including
the receiver), but corruption of links is not explicitly mentioned.
Further, trafﬁc analysis attacks are excluded as in the case of
Sphinx. They assume an integrated anonymization network
including the receiver. HORNET distinguishes between a setup
phase and a transmission phase. It adapts Sphinx for the
setup phase to create an anonymous header that allows for
routing data in the subsequent transmission phase. Multiple
cryptographic primitives are used in the construction and
processing of packets in both phases. Similar to Sphinx,
HORNET’s data transmission phase does not protect the
integrity of the payload at each relay. Further, at every relay
the payload is decrypted with a block cipher in CBC mode.
Extending HORNET to protect against partially stronger
adversaries, TARANET [12] bases its setup on Sphinx as
well. Additionally, it proposes packet-splitting as a trafﬁc-
shaping technique to withstand some trafﬁc-analysis. Therefore,
however, shared trust between sender and receiver is presumed.
The privacy of HORNET’s and TARANET’s setup phase
is claimed to follow from Sphinx. The privacy of their
data transmission phase is proven following the same proof
technique from [8], similar as in the improved Minx [29] and
Sphinx.
E. Formally treating OR
Towards rigorous analysis of OR, Camenisch and Lysyan-
skaya [8] speciﬁed an ideal functionality in the UC framework
and deﬁned properties to ease the analysis of OR protocols4.
1) UC Framework [9]: An ideal functionality in the UC
framework is an abstraction of a real protocol that expresses the
security and privacy properties as required in the real protocol.
Proving that the real protocol realizes the ideal functionality
implies proving that attacks on the real protocol do not reveal
anything to the adversary she would not learn from attacks on
the ideal functionality.