at two distinct locations: one analysis environment is lo-
cated in the United States, while the other one is located
in Europe. In our experience, this setup enables us to re-
liably execute known spambots and observe their current
spamming behavior.
For this study, we analyzed the ﬁve different bot fam-
ilies that were the most active during the time of our
experiments: Rustock [5], Lethic, MegaD [4, 6], Cut-
wail [35], and Waledac. We ran our samples from July
2010 to February 2011. Some of the spambots we ran
sent out spam emails for a limited amount of time (typi-
cally, a couple of weeks), and then lost contact with their
controllers. We periodically substituted such bots with
newer samples. Other bots (e.g., Rustock) were active
for most of the analysis period.
5.2 Botnet Tags
After monitoring the spambots in a controlled environ-
ment, we attempt to assign botnet labels to spam emails
found in our spam trap. Therefore, we ﬁrst extract the
subject templates from the emails that were collected in
the analysis environment with the same technique de-
scribed in Section 2.1. Then, we compare the subject
templates with the emails we received in the spam trap
during that same day.
If we ﬁnd a match, we tag the
campaign set that contains the IP address of the bot that
sent the message with the corresponding botnet name.
Otherwise, we keep the campaign set unlabeled.
5.3 Botnet Clustering
As noted above, we ran ﬁve spambot families in our anal-
ysis environment. Of course, it is possible that one of the
monitored botnets is carrying out more campaigns than
those observed by analyzing the emails sent by the bots
we execute in our analysis environment. In addition, we
are limited by the fact that we cannot run all bot binaries
in the general case (e.g., due to newly emerging botnets
or in cases where we do not have access to a sample),
and, thus, we cannot collect information about such cam-
paigns. The overall effect of this limitation is that some
campaign sets may be left unlabeled.
The goal of the botnet clustering phase is to determine
whether an unlabeled campaign set belongs to one of the
botnets we monitored. If an unlabeled campaign set can-
not be associated with one of the existing labeled cam-
paign sets, then we try to see if it can be merged with
another unlabeled campaign set, which, together, might
represent a new botnet.
In both cases, there is a need to determine if two cam-
paign sets are “close” enough to each other in order to be
considered as part of the same botnet. In order to repre-
sent the distance between campaign sets, we developed
three metrics, namely an IP overlap metric, a destination
distance metric, and a bot distance metric.
IP overlap. The observation underlying the IP overlap
metric is that two campaign sets sharing a large number
of bots (i.e., common IP addresses) likely belong to the
same botnet.
It is important to note that infected ma-
chines can belong to multiple botnets, as one machine
may be infected with two distinct instances of malware.
Another factor one needs to take into account is network
address translation (NAT) gateways, which can poten-
tially hide large networks behind them. As a result, the
IP address of a NAT gateway might appear as part of
multiple botnets. However, a host is discarded from the
campaign set related to pi as soon as it contacts a des-
tination that is not in the target set (see Section 4 for a
discussion). Therefore, NAT gateways are likely to be
discarded from the candidate set early on: at some point,
machines behind the NAT will likely hit two destinations
that are unique to two different seed pools, and, thus,
will be discarded from all campaign sets. This might
not be true for small NATs, with just a few hosts behind
them. In this case, the IP address of the gateway would
be detected as a bot by BOTMAGNIFIER. In a real world
scenario, this would still be useful information for the
network administrator, who would know what malware
has likely infected one or more of her hosts.
Given these assumptions, we merge two campaign sets
with a large IP overlap. More precisely, ﬁrst the intersec-
tion of the two campaign sets is computed. Then, if such
intersection represents a sufﬁciently high portion of the
IP addresses in either of the campaign sets, the two cam-
paign sets are merged.
The fraction of IP addresses that need to match ei-
ther of the campaign sets to consider them to be part of
the same botnet varies with the size of the sets for those
campaigns. Intuitively, two small campaigns will have to
overlap by a larger percentage than two large campaigns
in order to be considered as part of the same botnet. This
is done to avoid merging small campaigns together just
based on a small number of IP addresses that might be
caused by multiple infections or by two different spam-
bots hiding behind a small NAT. Given a campaign c, the
fraction of IP addresses that has to overlap with another
campaign in order to be merged together is
Oc =
1
log10 (Nc) ,
(6)
where Nc is the number of hosts in the campaign set. We
selected this equation because the denominator increases
slowly with the number of bots carrying out a campaign.
Moreover, because of the use of the logarithm, this equa-
tion models an exponential decay, which decreases fast
for small values of Nc, and much more slowly for large
values of it. Applying this equation, a campaign carried
out by 100 hosts will require an overlap of 50% or more
to be merged with another one, while a campaign carried
out by 10,000 hosts will only require an overlap of 25%.
When comparing two campaigns c1 and c2, we require
the smaller one to have an overlap of at least Oc with the
largest one to consider them as being carried out by the
same botnet.
Destination distance. This technique is an extension
of our magniﬁcation step. We assume that bots carry-
ing out the same campaign will target the same desti-
nations. However, as mentioned previously, some bot-
nets send spam only to speciﬁc countries during a given
time frame. Leveraging this observation, it is possible to
ﬁnd out whether two campaign sets are likely carried out
by the same botnet by observing the country distribution
of the set of destinations they targeted. More precisely,
we build a destination country vector for each campaign
set. Each element of the destination country vector cor-
responds to the fraction of destinations that belong to a
speciﬁc country. We determined the country of each IP
address using the GEOIP tool [19]. Then, for each pair of
campaign sets, we calculate the cosine distance between
them.
We performed a precision versus recall analysis to de-
velop an optimal threshold for this clustering technique.
By precision, we mean how well this technique can dis-
criminate between campaigns belonging to different bot-
nets. By recall, we capture how well the technique can
cluster together campaigns carried out by the same bot-
net. We ran our analysis on 50 manually-labeled cam-
paigns picked from the ones sent by the spambots in our
analysis environment. Similarly to how we found the
optimal value of k in Section 4, we multiply precision
and recall together. We then searched for the threshold
value that maximizes this product. In our experiments,
we found that the cosine distance of the destination coun-
tries vectors is rarely lower than 0.8. This occurs regard-
less of the particular country distribution of a campaign,
because there will be a signiﬁcant amount of bots in large
countries (e.g., the United States or India). The precision
versus recall analysis showed that 0.95 is a good thresh-
old for this clustering technique.
Bot distance. This technique is similar to the destina-
tion distance, except that it utilizes the country distribu-
tion of the bot population of the campaign set instead of
the location of the targeted servers. For each campaign
set, we build a source country vector that contains the
fraction of bots for a given country.
The intuition behind this technique comes from the
fact that malware frequently propagates through mali-
cious web sites, or through legitimate web servers that
have been compromised [24, 34]. These sites will not
have a uniform distribution of users (e.g., a Spanish
web site will mostly have visitors from Spanish-speaking
countries) and, therefore, the distribution of compro-
mised users in the world for that site will not be uniform.
For this technique, we also performed a precision ver-
sus recall analysis, in the same way as for the destination
distance technique. Again, we experimentally found the
optimal threshold to be 0.95.
6 Evaluation
To demonstrate the validity of our approach, we ﬁrst ex-
amined the results generated by BOTMAGNIFIER when
magnifying the population of a large spamming botnet
for which we have ground truth knowledge (i.e., we
know which IP addresses belong to the botnet). Then,
we ran the system for a period of four months on a large
set of real-world data, and we successfully tracked the
evolution of large botnets.
6.1 Validation of the Approach
To validate our approach, we studied a botnet for which
we had direct data about the number and IP addresses of
the infected machines. More precisely, in August 2010,
we obtained access to thirteen C&C servers belonging
to the Cutwail botnet [35]. Note that we only used nine
of them for this evaluation, since two had already been
used to derive the optimal value of N in Section 4, and
two were not actively sending spam at the time of the
takedown. As discussed before, these C&C servers con-
tained detailed information about the infected machines
belonging to the botnet and the spam campaigns car-
ried out. The whole botnet was composed of 30 C&C
servers. By analyzing the data on the C&C servers we
had access to, we found that, during the last day of opera-
tion, 188,159 bots contacted these nine servers. Of these,
37,914 (≈ 20%) contacted multiple servers. On average,
each server controlled 20,897 bots at the time of the take-
down, with a standard deviation of 5,478. Based on these
statistics, the servers to which we had access managed
the operations of between 29% and 37% of the entire bot-
net. We believe the actual percentage of the botnet con-
trolled by these servers was close to 30%, since all the
servers except one were contacted by more than 19,000
bots during the last day of operation. Only a single server
was controlling less than 10,000 bots. Therefore, it is
safe to assume that the vast majority of the command
and control servers were controlling a similar amount of
bots (≈ 20,000 each).
We ran the validation experiment for the period be-
tween July 28 and August 16, 2010. For each of the 18
days, we ﬁrst selected a subset of the IP addresses refer-
enced by the nine C&C servers. As a second step, with
the help of the spam trap, we identiﬁed which campaigns
had been carried out by these IP address during that day.
Then, we generated seed and magniﬁed pools. Finally,
we compared the output magniﬁcation sets against the
ground truth (i.e., the other IP addresses referenced by
the C&C servers) to assess the quality of the results.
Overall, BOTMAGNIFIER identiﬁed 144,317 IP ad-
dresses as Cutwail candidates in the campaign set. Of
these, 33,550 (≈ 23%) were actually listed in the C&C
servers’ databases as bots. This percentage is close to
the fraction of the botnet we had access to (since we con-
sidered 9 out of 30 C&C servers), and, thus, this result
suggests that the magniﬁed population identiﬁed by our
system is consistent. To perform a more precise analy-
sis, we ran BOTMAGNIFIER and studied the magniﬁed
pools that were given as an output on a daily basis. The
average size of the magniﬁed pools was 4,098 per day.
In total, during the 18 days of the experiment, we grew
the bot population by 73,772 IP addresses. Of the IP ad-
dresses detected by our tool, 17,288 also appeared in the
spam trap during at least one other day of our experiment,
sending emails belonging to the same campaigns carried
out by the C&C servers. This conﬁrms that they were
actually Cutwail bots. In particular, 3,381 of them were
detected by BOTMAGNIFIER before they ever appeared
in the spam trap, which demonstrates that we can use our
system to detect bots before they even hit our spam trap.
For further validation, we checked our results against
the Spamhaus database, to see if the IP addresses we
identiﬁed as bots were listed as known spammers or not.
81% were listed in the blacklist.
We then tried to evaluate how many of the remaining
27,421 IP addresses were false positives. To do this, we
used two techniques. First, we tried to connect to the
host to check whether it was a legitimate server. Legit-
imate SMTP or DNS servers can show up in queries on
Spamhaus due to several reasons (e.g., in cases where
reputation services collect information about sender IP
addresses or if an email server is conﬁgured to query
the local DNS server). Therefore, we tried to determine
if an IP address that was not blacklisted at the time of
the experiment was a legitimate email or DNS server by
connecting to port 25 TCP and 53 UDP. If the server re-
sponded, we considered it to be a false positive. Unfor-
tunately, due to ﬁrewall rules, NAT gateways, or network
policies, some servers might not respond to our probes.
For this reason, as a second technique, we executed a
reverse DNS lookup on the IP addresses, looking for ev-
idence showing that the host was a legitimate server. In
particular, we looked for strings that are typical for mail
servers in the hostname. These strings are smtp, mail,
mx, post, and mta. We built this list by manually look-
ing at the reverse DNS lookups of the IP address that
were not blacklisted by Spamhaus. If the reverse lookup
matched one of these strings, we considered the IP ad-
dress as a legitimate server, i.e., a false positive. In total,
2,845 IP addresses resulted in legitimate servers (1,712
SMTP servers and 1,431 DNS servers), which is 3.8% of
the overall magniﬁed population.
We then tried to determine what coverage of the en-
tire Cutwail botnet our approach produced. Based on the
number of active IP addresses per day we saw on the
C&C servers, we estimated that the size of the botnet
at the time of the takedown was between 300,000 and
400,000 bots. This means that, during our experiment,
we were able to track between 35 and 48 percent of the
botnet. Given the limitations of our transaction log (see
Section 6.2.1), this is a good result, which could be im-
proved by getting access to multiple Spamhaus servers
or more complete data streams.
6.2 Tracking Bot Populations
To demonstrate the practical feasibility of our approach,
we used BOTMAGNIFIER to track bot populations in the
wild for a period of four months. In particular, we ran
the system for 114 days between September 28, 2010
and February 5, 2011. We had a downtime of about 15
days in November 2011, during which the emails of the
spam trap could not be delivered.
By using our magniﬁcation algorithm, our system
identiﬁed and tracked 2,031,110 bot IP addresses dur-
ing the evaluation period. Of these, 925,978 IP addresses
(≈ 45.6%) belonged to magniﬁcation sets (i.e., they were
generated by the magniﬁcation process), while 1,105,132
belonged to seed pools generated with the help of the
spam trap.
6.2.1 Data Streams Limitations
The limited view we have from the transaction log gen-
erated by only one DNSBL mirror limits the number of
bots we can track each day. BOTMAGNIFIER requires
an IP address to appear a minimum number of times in
the transaction log, in order to be considered as a po-
tential bot. From our DNSBL mirror, we observed that
a medium size campaign targets about 50,000 different
destination servers (i.e., |T (pi)| = 50,000). The value
of N for such a campaign, calculated using equation 5,
is 50. On an average day, our DNSBL mirror logs activ-
ity performed by approximately 4.7 million mail senders.
Of these, only about 530,000 (≈ 11%) appear at least 50
times. Thus, we have to discard a large number of po-
tential bots a priori, because of the limited number of
transactions our Spamhaus mirror observes. If we had
access to more transaction logs, our visibility would in-
crease, and, thus, the results would improve accordingly.
6.2.2 Overview of Tracking Results
For each day of analysis, BOTMAGNIFIER identiﬁed
the largest spam campaigns active during that day (Sec-
tion 2), learned the behavior of a subset of IP addresses
carrying out those campaigns (Section 3), and grew a
population of IP addresses behaving in the same way
(Section 4). This provided us with the ability to track
the population of the largest botnets, monitoring how ac-
tive they were, and determining which periods they were
silent.
A challenging aspect of tracking botnets with BOT-