      }
    }
    output {
       stdout {
          codec => "rubydebug"
       }
    }
此时尝试登陆，可以看到登陆失败和登陆成功的都被记录下来了
### 整合
最后将上面的配置整合一下，形成最终配置文件如下：
注：如果想收集之前的日志的话，可以在所有input块加上`start_position => "beginning"`即可
    input {
       file {
          path => "/var/log/nginx/access.log"
          type => "nginx"
          codec => "json"
       }
        file {
          path => "/var/log/httpd/access_log"
          type => "apache"
          codec => "json"
       }
        file {
          path => "/var/log/command.log"
          type => "history"
          codec => "json"
       }
        file {
          path => "/var/log/sshd.log"
          type => "ssh"
       }
    }
    filter {
      grok {
        match => [
          "message", "%{SYSLOGTIMESTAMP:syslog_date} %{SYSLOGHOST:syslog_host} %{DATA:syslog_program}(?:\[%{POSINT}\])?: %{WORD:login} password for %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}",
          "message", "%{SYSLOGTIMESTAMP:syslog_date} %{SYSLOGHOST:syslog_host} %{DATA:syslog_program}(?:\[%{POSINT}\])?: message repeated 2 times: \[ %{WORD:login} password for %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}",
          "message", "%{SYSLOGTIMESTAMP:syslog_date} %{SYSLOGHOST:syslog_host} %{DATA:syslog_program}(?:\[%{POSINT}\])?: %{WORD:login} password for invalid user %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}",
          "message", "%{SYSLOGTIMESTAMP:syslog_date} %{SYSLOGHOST:syslog_host} %{DATA:syslog_program}(?:\[%{POSINT}\])?: %{WORD:login} %{WORD:auth_method} for %{USERNAME:username} from %{IP:ip} %{GREEDYDATA}"
        ]
      }
    }
    output {
        if [type] == "nginx" { 
            elasticsearch {
                hosts => ["127.0.0.1:9200"]
                index => "nginx-%{+YYYY.MM.dd}"
            }       
        }   
        if [type] == "apache" {
            elasticsearch {
                hosts => ["127.0.0.1:9200"]
                index => "apache-%{+YYYY.MM.dd}"
            }
        }
        if [type] == "history" {
            elasticsearch {
                hosts => ["127.0.0.1:9200"]
                index => "history-%{+YYYY.MM.dd}"
            }
        }
        if [type] == "ssh" {
            elasticsearch {
                hosts => ["127.0.0.1:9200"]
                index => "ssh-%{+YYYY.MM.dd}"
            }
        }
    }
然后我们可以`logstash -t -f logstash.conf`来验证配置文件是否配置正确
    [2020-12-30T18:22:40,870][INFO ][logstash.runner          ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash
确认无误后启动`logstash`，然后我们到`es-head`上去查看索引是否创建成功，可以看到我们上面配置文件索引已经全部创建，接下来就去`Kibana`创建日志索引即可
这里拿`history`来举例，最终效果如下：
# 收集Windows日志
收集Windows日志我们可以使用`Winlogbeat`，`Winlogbeat`是属于`beats`家族成员之一，主要用于收集`Windows`上的日志。`Winlogbeat`使用`Windows
api`读取一个或多个事件日志，根据用户配置的条件筛选事件，然后将事件数据发送到配置的输出
`Winlogbeat`可以从系统上运行的任何事件日志中捕获事件数据。如：`Winlogbeat`可以捕获以下事件:
  * 应用程序事件（application）
  * 硬件事件
  * 安全事件（security）
  * 系统事件（system）
`Winlogbeat`下载：
简单的安装配置：
    .\install-service-winlogbeat.ps1
     .\winlogbeat.exe setup
## 配置
### Output
output可以指定一个输出点（只能定义一个输出点），下面列举一些常见的输出配置
Redis
    output.redis:
      hosts: ["localhost"]
      password: "my_password"
      key: "winlogbeat"
      db: 0
      timeout: 5
logstash
    output.logstash:
      hosts: ["127.0.0.1:5044"]
ES
    output.elasticsearch:
      hosts: ["https://myEShost:9200"]
kafka
    output.kafka:
      # initial brokers for reading cluster metadata
      hosts: ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
      # message topic selection + partitioning
      topic: '%{[fields.log_topic]}'
      partition.round_robin:
        reachable_only: false
      required_acks: 1
      compression: gzip
      max_message_bytes: 1000000
### Kibana
Kibana配置项：
  * `setup.kibana.host`：`Kibana`地址
  * `setup.kibana.protocol`：`http`或`https`，默认值为`http`，但是如果`setup.kibana.host`中指定的URL，则该值会被URL中的指定的协议覆盖掉
  * `setup.kibana.username`：kibana用户名
  * `setup.kibana.password`：kibana密码
  * `setup.kibana.ssl.enabled`：启用SSL，如果配置的协议为HTTPS，则该值默认为`true`并且`Winlogbeat`会使用默认的SSL设置。
例子：
    setup.kibana.host: "https://192.0.2.255:5601"
    setup.kibana.ssl.enabled: true
    setup.kibana.ssl.certificate_authorities: ["/etc/pki/root/ca.pem"]
    setup.kibana.ssl.certificate: "/etc/pki/client/cert.pem"
    setup.kibana.ssl.key: "/etc/pki/client/cert.key
### Winlogbeat配置文件项
  * `event_logs`：指定要监视哪些事件日志，列表中的每个条目都定义了要监视的事件日志以及与事件日志关联的任何信息
  * `event_logs.name`为`event_logs`必选项，指定要收集事件名，可以为日志名（可以使用`Get-WinEvent -ListLog *`获取Windows下所有的日志名），也可以为日志文件（需要注意的是路径必须为绝对路径，不能为相对路径）
    winlogbeat.event_logs:
      - name: Application
      #- name: 'C:\winlogbeat\xxx.evtx'
  * `event_logs.ignore_order`：如果指定了此选项，则Winlogbeat会过滤早于指定时间的事件，有效时间单位是"ns", "us" (or "µs"), "ms", "s", "m", "h"
    winlogbeat.event_logs:
      - name: Application
        ignore_older: 168h
  * `event_logs.event_id`：配置事件id的白名单和黑名单，事件id以逗号分隔，可以是单个id（如4624），可以是一个范围（4600-5000），如果排除某个事件id的话可以在id前面加个负号（如：-4625）
    winlogbeat.event_logs:
      - name: Security
        event_id: 4624, 4625, 4700-4800, -4735
  * `event_logs.index`：Winlogbeat的索引，如果es存在该日志的索引则会覆盖原来的索引。格式示例：`"%{[agent.name]}-myindex-%{+yyyy.MM.dd}"` -> `winlogbeat-myindex-2019.12.13`
  * `event_logs.level`：事件级别，多个值用逗号隔开
Level | Value  
---|---  
critical, crit | 1  
error, err | 2  
warning, warn | 3  
information, info | 0或4  
verbose | 5  
  * 其余配置项见官网
## 测试
修改配置文件`winlogbeat.yml`，`Kibana`和`elasticsearch`配成我们上面搭建好节点
    winlogbeat.event_logs:
        - name: Application
          provider:
              - Application Error
              - Application Hang
              - Windows Error Reporting
              - EMET
        - name: Security
          level: critical, error, warning
          event_id: 4624, 4625, 4634, 4672, 4720
        - name: System
          ignore_older: 168h
    setup.kibana:
        host: "http://100.2.170.124:5601"
    output.elasticsearch:
        hosts: ["100.2.170.124:9200"]
然后启动服务
    net start winlogbeat
服务启动之后，到`es-head`上可以看到已经创建了索引，说明已经配置成功。
然后我们可以通过`Kibana`对日志进行一系列分析了，如：筛选出登陆失败的用户名以及IP
**注：`Winlogbeat`提供的字段是相当丰富的，这里就不进行列举了，具体请查阅[官网手册](https://www.elastic.co/guide/en/beats/winlogbeat/current/exported-fields.html)**
    winlog.event_id: 4625
# Reference