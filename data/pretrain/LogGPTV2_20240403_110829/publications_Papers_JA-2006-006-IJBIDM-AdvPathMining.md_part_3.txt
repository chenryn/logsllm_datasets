select and apply specific approaches based on the nature of the problem. We went a
step forward with the idea that machine learning should dynamically create a hybrid
Web process and workflow path mining using the Multimethod approach 317
approach that is the most appropriate for a particular problem. The Multimethod
approach was introduced in Lenic and Kokol (2002). The goal was to achieve an
improvement of the quality of knowledge extraction that is not inherently limited to
sub-optimal solutions. The idea of combining different approaches had already been
proposed (Dietterich, 2000), but all attempts to combine different methods have use a
loose coupling approach. The most probable explanation for this fact is the ease of
implementation. While modularity represents an important aspect of the combination of
methods into hybrids, the main disadvantage of loose coupling is that methods work
almost independently of each other and, therefore, it is difficult to make them work as a
synergetic team.
As opposed to the conventional hybrid methods described in the previous subsection,
the idea of the Multimethod approach is to dynamically combine and apply different
methods with no predefined order to the same problem. The methods are applied not only
in sequence, but also at different crosscut points of the internal knowledge representation.
One solution can contain many knowledge representations that are hopefully the most
appropriate for presenting a solution for a specified problem.
The key idea of the Multimethod approach is to incrementally evolve and improve
knowledge by using different methods. The approach finds a way to enable dynamic
combination of methods to the somehow quasi-unified knowledge representation to
enable knowledge sharing between methods and not to set a limit to specific knowledge
representation.
As a result, we can get multiple solutions, like with evolutionary algorithms, where
each solution is obtained using the application of different methods with a different set
of parameters. Hence, the concept of population is introduced, which is composed of
individuals/solutions that have the common goal to improve their classification abilities
on a given environment/problem. The existence of an abstract view makes it possible to
enable the coexistence of different knowledge representations in the same population.
With this approach, the solution space and expressive power is dramatically increased.
This is also the main drawback of the approach, since the increased search space requires
more computing power to find an optimal solution.
To be able to reuse and improve knowledge using another method that produced
it, it is usually necessary to transform knowledge into a different form compatible
with the application method. The conversion between knowledge representations
(for example, between neural networks and decision trees) can be done using two
different approaches: (1) convert one knowledge representation into another using
different already known methods or (2) combine both knowledge representations into a
single one using a meta approach. In both cases, knowledge transmutation is executed
(Wolpert and Macready, 1997).
In the first case, the conversion between different knowledge representations must
be implemented, which is usually not perfect and some parts of the knowledge may be
lost. But it can provide a different view representing a good starting point in the solution
search space.
The second approach, which is based on combining knowledge, requires some
crosscut-points where knowledge representations can be merged. For example, in
decision trees such crosscut-points are internal nodes, where the condition in an
internal node can be replaced by another intelligent system (for example, support vector
machine – SVM). The same idea can be also applied to decision leafs (Figure 6).
318 J. Cardoso and M. Lenič
The transformation is usually time consuming and does not necessarily transform all
aspects of the source knowledge representation, because of different hypothesis spaces
and expressional capabilities of the target knowledge representation. To reduce the
transformation cost and information lost during the knowledge transformation some
common knowledge representation models have been standardised to support the
applicability of different methods to individuals. Of course, each method of
implementation can use its own internal knowledge representation that is not compatible
with other methods. As an example, we present the WEKA (Weka, 2004) system that
uses different knowledge representations but has no operations for transforming
knowledge to make it available to other method and the available methods are not
designed to incrementally improve extracted knowledge. In this case, the loose coupling
approach is used and additional knowledge transformations are needed to make it
available to other methods.
Figure 6 An example of a decision tree induced using the Multimethod approach. Each node
is induced with an appropriate method (genetic algorithm, ID3, Gini, Chi-square,
J-measure, SVM, neural network, etc.)
Using the idea of the Multimethod approach, we designed a framework that operates on a
population of extracted knowledge representations – individuals. Since methods are
usually composed of operations that can be reused in other methods we view methods
on the basis of operators. Therefore, we introduced the operation on an individual as a
function that transforms one or more individuals to a single individual. Operations can be
part of one or more methods, such as the pruning operator, the boosting operator, etc.
This approach provides the ability to simply add new operations to the framework
(Figure 7).
Figure 7 Multimethod framework
Web process and workflow path mining using the Multimethod approach 319
The representation with individual operations facilitates an effective and modular way
to represent the results as a single individual, but in general the results of the operations
can also be a population of individuals (for example, the mutation operation in
evolutionary algorithm is defined both on the individual and the population level).
Population operators can be generalised with higher order functions and thereby reused in
different methods.
The Multimethod approach uses methods with different learning techniques.
For example, heuristic approaches produce a good starting point in the solution space and
can also represent local optima. This approach can be combined with search space
strategies that are not limited to local optima and can improve the results from heuristic
approaches. Additionally, heuristics can be used on solution search space approaches to
converge to a different local optima that might represent a better solution than previous
ones. Another important benefit is that using multiple methods we can produce multiple
solutions with different perspectives to the initial problem.
Another benefit of combining two methods using a third classifier is the separation of
concepts. For example, in Figure 8 there are two concepts, c and c , that can be separated
1 2
using an existing set of methods. Let us suppose that there is no available method that is
able to acquire both concepts in a single knowledge representation. In such a case, we
need a separation of the problem using another concept, c . Please note that in the scope
3
of the domain problem, this additional concept has no special meaning to induce a
successful composite concept.
Figure 8 Concept separation using GA
The Multimethod approach uses populations and evolutionary based techniques to search
for solutions. The initial population of extracted knowledge is generated using different
methods with a different set of attributes. The starting points in our solution search space
are represented by individual methods. This implies that the results from a single method
will definitely be included, possibly improved and considered as potential solutions.
The Multimethod approach was tested and applied on different domains, mainly
medical (Lenic et al., 2003), where symbolic knowledge representation is required, which
can give some explanation about decision making.
320 J. Cardoso and M. Lenič
7 Experiments
In this section, we present the results of applying several data mining algorithms to carry
out process path mining. We describe the data set that has been used, the algorithms
applied to the data set, and finally we discuss the results obtained.
7.1 Data set description
The loan problem is the dataset that we used to illustrate how data mining methods can be
applied to process path prediction. To generate our dataset, we started with the process
presented in our introductory scenario (see Section 3), and using this as a process model
graph, logged a set of 1000 process instance executions.
As explained in section three, our process log system has been extended to store
information indicating the values of the input parameters passed to activities and the
output parameters received from activities. The information also includes the path that
has been followed during the execution of process instances. Each entry corresponds
to an instance execution. The log system also stores a list of event records consisting of
process names, instance identification, activity names, timestamps, variable names, etc
(see Table 1 for an overview of the information stored in the process log).
From each process instance in the log system, a process profile is created. Each
process profile provides the input for data mining algorithms. In our example, each
profile is characterised by a set of six attributes: income, loan_type, loan_amount,
loan_years, name and SSN. The profiles for the loan process contain two types of
attributes: numeric and nominal. The attributes income, loan_amount, loan_years
and SSN are numeric, whereas the attributes loan_type and name are nominal. As an
example of a nominal attribute, loan_type can take the finite set of values home-loan,
education-loan, and car-loan. Each profile is associated with a one of the six possible
classes indicating the path followed during the execution of a process when the attributes
of the profile have been assigned specific values (see Figure 1 to identify the six possible
paths that can be followed during the execution of a loan process instance).
For the loan process application, the process instance profile and process path class
schema is illustrated in Table 2. The data is formatted in a tabular format, with the
process path as decision class, in a way that can processed by supervised learning
algorithms.
7.2 Data mining algorithms
We have carried out process path mining to our data set using five distinct data mining
algorithms: the Multimethod, and WEKA implementation of J48, Naïve Bayes, SMO,
and MultiBoost. Since we have already explained the concepts behind the Multimethod
approach in Section 4, we will only briefly describe the J48, Naïve Bayes, and SMO
algorithms since they are fairly well-known to the data mining community.
J48. J48 algorithm is Weka’s (2004) implementation of the C4.5 (Quinlan, 1993)
decision three learner. The algorithm is commonly used to classify instances.
Unfortunately the problem of finding an ‘optimal’ solution tree is a multi-objective
problem and it is known to be NP complete. Therefore, C4.5 uses a heuristic approach to
generate suboptimal decision trees. The hypothesis is represented in a symbolic form and
Web process and workflow path mining using the Multimethod approach 321
can explain the reasons why some attributes and their values are involved in the decision
making procedure.
Naïve Bayes. Naïve Bayes (NB) classifier technique is based on the so-called
Bayesian theorem. It is a classification technique that is both predictive and descriptive.
It analyses the relationship between each independent variable and the dependent variable
to derive a conditional probability for each relationship. When a new case is analysed, a
prediction is made by combining the effects of the independent variables on the
dependent variables (i.e., the outcome that is predicted). Despite its simplicity, studies
comparing classification algorithms have found the Naïve Bayesian classifier to be
comparable in performance with classification trees and with neural network classifiers.
The hypothesis is represented based on all the learning instances, but does not give a
symbolic explanation of the decision making process.
SMO. SMO (Sequential Minimal Optimisation) (Platt, 1999) is a fast method to train
SVM (Support Vector Machines) (Cortes and Vapnik, 1995). Training an SVM requires
the solution of a very large quadratic programming (QP) optimisation problem. SMO
breaks this large QP problem into a series of smaller possible QP problems.
Support Vector Machines (SVM) are learning systems that use a hypothesis space of
linear functions in a high (possibly infinite) dimensional feature space, trained with a
learning algorithm from optimisation theory that implement a learning bias derived from
statistical learning theory. As SVM is supervised learning, a learning machine is required
to scan through a given training set of examples with associated labels. The hypothesis is
represented with a subset of important (support) learning instances with an importance
weight.
MultiBoost. MultiBoost (MB) (Todorovski and Dzeroski, 2000) is an improved meta
learning algorithm of AdaBoost (Freund and Schapire, 1999). It was constructed using
the black box principle by observing the performance of previously constructed
classifiers and adapting the weights of learning instances. It is widely used to improve the
classification accuracy of weak learners.
J48 was selected as a good representative of the symbolic method, Naïve Bayes
as a representative of a probabilistic method and the SMO algorithm as representative
of a method that has been successfully applied in the domain of text-mining. Multiboost
is expected to improve performance of single classifiers and can be used as direct
comparison to Multimethod approach since it introduces meta-level classification.
7.3 Experiments
Each experiment has involved data from 1000 process instance executions. To effectively
compare different learning methods that use heuristic and search space approaches,
the dataset was separated in a learning (2/3 of the instances) and a testing (1/3 of the
instances) set. For running instances not all the attributes are available once the instances
are started. For that reason, we have conducted experiments with a variable number
of attributes ranging from 0 attributes to 6 available attributes. We have conducted
64 experiments, i.e., all possible combination of attributes, analysing a total of 64,000
records containing data from process instance executions.
322 J. Cardoso and M. Lenič
The first set of experiments was conducted using multiboost (MB) in conjunction
with the selected classifiers. The Multimethod approach was not used in combination
with multiboost since it is a meta-level approach and it is not integrated with WEKA.
We should also mention that we have constrained the Multimethod approach not to use
the Naïve Bayes and SMO methods; only symbolic knowledge representation was used.
The comparison of methods was implemented using the accuracy of the testing set.
We obtained a very large number of results. For each one of the 64 experiments, we
obtained data for seven different types of experiments. For reasons of simplicity and as a
summary, we have compared each method to the best of all other methods and computed
the relative error of accuracy on the testing set by dividing the accuracy produced by the
target classifier with the accuracy of the best of all other classifiers. The comparisons of
the most promising methods are presented in Figure 9. The points above the line
represent the experiments for which the method under study was better than the best of
all other methods. To summarise all result we have grouped (summed) differences based
on the number of attributes used in the experiments. An overview of our results is given
in Table 3.
Table 3 Comparison of approaches using multiboost algorithm for single methods
No. of attributes No. of exp. Multi-method MB J48 MB NB MB SMO
1 6 16.12% –21.67 –23.00% –47.49%
2 15 35.21% –119.88 –49.27% –106.88%
3 20 69.46% –168.04 –90.57% –116.08%
4 15 61.34% –157.51 –75.21% –74.59%
5 6 19.78% –67.73 –28.67% –19.66%
6 1 3.65% –12.49 –3.52% –4.81%
Average 205.57% –547.32 –270.24% –369.50%
Best or equal 50 2 13 5
Best 45 0 11 2
We can observe that the Multimethod approach performed on average much better than
multiboosted WEKA classifiers. It produces a model with the best or equal accuracy in
50 out of 64 experiments and outperformed others in 45 experiments. The worst results
were produced by the multiboosted J48 algorithm which uses symbolic decision tree
knowledge representation. An interesting observation is that the Multimethod approach
uses decision trees as knowledge representation since this representation is preferred by
the approach because it has a symbolic nature.
It is safe to assume that the multiboosted approach overfitted and was not able to find
a generalised concept. That is probably because of the nature of the dataset that contains
attributes that introduce noise.
Next we removed the meta-level of the multiboost algorithm and repeated the
experiments only with single methods. As expected, a single model made more accurate
prognoses than ensembles of methods. The results are summarised in Table 4.
Web process and workflow path mining using the Multimethod approach 323
Table 4 Comparison of approaches without using the multiboost algorithm
No. of attributes No. of exp. Multimethod J48 NB SMO
1 6 15.38% –19.88% –23.00% –47.49%
2 15 15.38% –52.05% –35.85% –104.62%
3 20 6,07% –55.58% –38.93% –108.69%