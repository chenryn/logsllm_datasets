# Optimized Text

## 5.1 Prefix Length vs. ECS Scope for RIPE and PRES

- **(a) RIPE**
- **(b) Google (RIPE)**
- **(c) Edgecast (RIPE)**
- **(d) PRES**
- **(e) Google (PRES)**
- **(f) Edgecast (PRES)**

**Figure 2: Prefix length vs. ECS scope for RIPE and PRES (Google: March 2013, Edgecast: May 2013).**

The number of Autonomous Systems (ASes) with YouTube servers nearly tripled (271%) from 220 to 598. These ASes overlap with the already uncovered Google infrastructure, indicating the integration of YouTube into Google's global platform. Merging the IP address sets for Google and YouTube results in a total of 24,048 unique IP addresses. For a detailed analysis of Google's infrastructure expansion since November 2012, refer to [14]. Our study did not reveal significant growth in serving infrastructure for other ECS adopters.

## 5.2 Uncovering DNS Cacheability

Next, we examine the ECS-specific information included in DNS responses: the scope. In principle, if the ECS information corresponds to a publicly announced prefix, one might expect the returned scope to be equal to the prefix length. However, this is not always the case. Content providers often return either coarser or finer-grained scopes, such as aggregated or de-aggregated prefixes. This indicates that they perform end-user clustering for client-to-server assignment at a different granularity than the routing announcements.

We note that the scope can significantly affect the re-usability of DNS responses, i.e., their cacheability. While most responses have a non-zero Time To Live (TTL), a surprisingly large number have a /32 scope, which implies that the answer is valid only for the specific client IP that issued the DNS request. In this section, we explore DNS cacheability for two ECS adopters: Google and Edgecast. The others are less interesting because CacheFly always uses a /24 scope, and MySqueezebox is similar to Edgecast.

**Figure 2(a)** shows the RIPE prefix length distribution (circles) and the returned scopes from using the RIPE prefixes to query our ECS adopters. The distributions vary significantly. Google exhibits massive de-aggregation, while Edgecast, operating a smaller infrastructure, shows significant aggregation.

When executing back-to-back measurements for Google (e.g., 4 queries within a second), we find that typically both the answer and scopes are consistent within the duration of the TTL (300 seconds for Google). The answer and scope can change within seconds in some cases. A detailed study of the temporal changes in the returned scope is part of our future work. As seen in **Figure 2(a)**, for almost a quarter of the queries, the returned scope is 32, indicating that Google severely restricts the cacheability of ECS responses or may want to restrict reuse of the answers to single client IPs. For approximately 27% of the queries, the prefix length and scope are identical. For 41% of the queries, we see de-aggregation, while there is aggregation for 31%. The difference between the announced prefix and the returned scope may also be due to the BGP feed sent to the GGC by the ISP [13], which is not necessarily the same as what is publicly announced and collected by RIPE or Routeviews. We again note that the returned scopes for the RIPE and RV prefixes are almost identical.

Exploring the scopes returned by Edgecast may initially appear useless because they only return a single IP with a TTL of 180 seconds. However, Edgecast uses significant aggregation for all prefix lengths across all prefix sets. For example, when using the RIPE prefixes, the returned scope is identical for 10.5% but less specific for 87%.

When using the ISP prefix set, the overall picture is similar, even though the specific numbers vary. An initial study of the prefixes with scope 32 indicates that Google performs profiling, e.g., returning scope /32 for all CDN servers of a large CDN provider inside the ISP. In future work, we plan to explore if there exists a natural clustering for those responses with scope /32.

Given the limited size of the UNI prefix set, we issue queries from all IP addresses with prefix length 32. The returned scopes vary heavily from /32 to /15, even for neighboring IP addresses.

For the PRES prefixes, **Figure 2(d)** shows extreme de-aggregation. For more than 74% of the prefixes, the scope is more restrictive than the prefix length, and in 17% they are identical. Only a few returned scopes are /32s, which may indicate that Google treats popular resolvers differently than random IP addresses. Google may already be aware of the problem regarding caching DNS answers as discussed in Section 2.2. For Edgecast, we see significant aggregation.

To highlight the relationship between the prefix length in the query and the scope in the reply, **Figures 2(b) and 2(e)** show heatmaps of the corresponding two-dimensional histograms. For the RIPE dataset, we notice the two extreme points at scopes /24 and /32. For the PRES dataset, the heatmap highlights the de-aggregation. **Figures 2(c) and 2(f)** show the heatmaps for Edgecast. While for the RIPE dataset, we see the effect of the extreme prefix de-aggregation for Google very clearly, the picture for Edgecast is more complicated, as there is mainly aggregation. For the PRES dataset, the heatmap shows even more diversity, with both de-aggregation and aggregation, resulting in a blob in the middle of the heatmap.

## 5.3 User-Server Mapping Snapshots

So far, we have not yet taken advantage of the Web server IP addresses in the DNS replies. These allow us to capture snapshots of the user-to-server mapping employed by an ECS-enabled CDN or CP, which can shed light on CDN mapping strategies. In the following, we illustrate the measurement capabilities offered by ECS. We explore snapshots of Google's user-to-server mappings (based on the RIPE data set) and examine how stable this mapping is.

Google returns 5 to 16 different IP addresses in each reply. Almost all responses (>90%) include either 5 or 6 different IP addresses. We do not find any correlation between the ECS prefix length or the returned scope and the number of returned IP addresses. All IP addresses from a single response always belong to the same /24 subnet (the returned IPs are not necessarily in close geographic distance to each other [20]). We also notice that typically, the announced prefix length of subnets that host Google servers is /24. Thus, based on a single ECS lookup per prefix, we always find a unique mapping between the query prefix and the server subnet from the DNS reply.

Next, we assess the mapping consistency at the AS-level. First, we map all prefixes used in the ECS queries to their corresponding AS. Then, by looking at the returned A records, we find the corresponding server ASes for each client AS.

On March 26, 2013, the majority of client ASes, around 41K, were served exclusively by Google servers from a single AS. About 2K ASes were served by servers in 2 ASes, and less than 100 ASes were served by servers from more than 5 ASes. On August 8, 2013, the number of ASes served by a single AS dropped to around 38.5K, and around 5K were served by 2 ASes. ASes served by a large number of server ASes typically have a global footprint. We find that client prefixes of ASes that host GGC are also served by servers in other ASes. This is expected as GGC capacity may not always be sufficient to handle demand, and different prefixes within an AS, e.g., those that host the GCC servers, may be handled differently. As illustrated in **Figure 5.3**, a small number of ASes hosts servers that serve a large number of ASes. By far, the most popular AS is the official Google AS (AS15169), which served more than 41.5K ASes in March and around 40.5K in August 2013. In the top-10, we find the YouTube AS, as well as small and large transit providers that serve their customers. There is also a small number of ASes that exclusively serve their client subnets from GGC servers they host.

From our analysis, we derive some important observations. First, Google content is no longer exclusively served by servers in Google ASes, as reported in [12]. Second, GCCs have been enabled in a significant number of ASes over a five-month period. Third, within these five months, the number of ASes served by GGC servers in other ASes has significantly increased. This trend has significant implications for caching, as Google content can be available in the same or a neighboring AS. It also has implications for peering, as the presence of GGCs reduces inter-domain Google traffic, allowing smaller networks to reduce their transit costs by installing GGCs or peering with ASes that host GGCs.

To assess the stability of user-server mapping over time, we analyze the returned IP addresses when asking back-to-back queries over two days (May 3-4, 2013). We found that around 35% of the prefixes are always served by a single /24 block over the 48-hour period. Given Google's highly distributed infrastructure, one might have expected larger churn. 44% of the query prefixes are mapped to two /24 blocks, and a very small percentage to more than five /24 blocks. A possible explanation for this stable mapping is that Google uses local load balancers [24, 33]. We leave the study of temporal dynamics in user-to-server mapping over longer periods and during flash crowds or other events as future work. Our future research agenda also includes the study of temporal changes in user-to-server mapping not just for Google but also for other ECS adopters.

## 6. Conclusion

In this paper, we show that the adoption of the EDNS-Client-Subnet DNS extension (ECS) by major Internet companies offers unique but likely unintended measurement opportunities to uncover some of their operational practices. Using early ECS adopters like Google, Edgecast, and CacheFly as examples, our experimental study demonstrates how simple it is (using a single vantage point as simple as a commodity PC) to (i) uncover the footprint of these CDN/CP companies, (ii) observe them clustering clients, and (iii) take snapshots of the user-to-server mappings. Additionally, we point out potential implications that ECS can have on the cacheability of DNS responses by major DNS resolvers. We believe that the tools developed and the traces collected in this work, made available to the research community, shed light on the deployment and operation of CDNs given their central role in today's Internet. This work also highlights the need to increase awareness among current and future ECS adopters about the consequences of enabling ECS.

## Acknowledgments

We would like to thank our shepherd, Ethan Katz-Bassett, and the anonymous reviewers for their valuable feedback. This work was supported in part by the EU projects BigFoot (FP7-ICT-317858) and CHANGE (FP7-ICT-257422), EIT Knowledge and Innovation Communities program, and an IKY-DAAD award (54718944).

## References

[References remain unchanged]

---

This optimized text aims to improve clarity, coherence, and professionalism, making it easier to read and understand.