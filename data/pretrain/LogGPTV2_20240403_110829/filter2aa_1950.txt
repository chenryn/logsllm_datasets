Deanonymizing Tor
Nathan S. Evans
Christian Grothoﬀ
PI:EMAIL
PI:EMAIL
Colorado Research Institute for Security and Privacy
University of Denver
1
Motivation
• Tor is probably the most popular and widely used free software
P2P network used to achieve anonymity on the Internet:
– Tor has a strong, large user base
– The project is well supported
– Generally assumed to give users strong anonymity
The news today:
All the Tor nodes involved in a circuit can be discoverd, reducing Tor
users level of anonymity
2
Tor General Information
• Tor stands for “The onion router”
– Encrypts data multiple times and is decrypted as it travels
through the network a layer at a time: like peeling an onion
• Tor is a low latency P2P mix cascade
• Routes data through network along a “circuit”
• Data is encrypted as it passes through nodes (until the last hop)
3
Routing
• Data is forwarded through the network
• Each node knows only the previous hop and the next hop
• Only the originator knows all the hops
• Number of hops is hard coded (currently set to three)
Key security goal: No node in the path can discover the full path
4
Routing Example
Client
Server
Tor Node 1
Tor Node 2
Tor Node 3
Tor Node 4
Tor Node 5
Tor Node 6
Tor Node 7
Tor Node 8
Tor Node 9
Figure 1: Example showing how a normal path is chosen in the Tor network
5
Previous work
• Murdoch and Danezis wrote “Low Cost Traﬃc Analysis of Tor”
• Goal is to discover all the Tor routers involved in a given circuit
• Based on being able to tell the added load of one normal Tor
connection
• Send a certain sequence down a tunnel, monitor each Tor router
to see if it is involved
• Their attack worked well with the 2005 Tor network consisting of
approximately a dozen Tor routers
6
Problems With Previous Work
• Less feasible with 1000+ routers
• Must identify all the separate routers in the circuit
• Attempting to measure small eﬀects, large ﬂuctuations that occur
in actual current network give false positives
• We replicated their experiments, found method to be much less
eﬀective on today’s network
7
Our Basis for Deanonymization
• Three design issues enable users to be deanonymized
1. No artiﬁcial delays induced on connections
2. Path length is set at a small ﬁnite number
3. Paths of arbitrary length through the network can be constructed
• Target user is running Tor with privoxy with all the default settings
8
Regular Path Example
Client
Server
Tor Node 1
Tor Node 2
Tor Node 3
Figure 2: Example showing a typical Tor circuit
9
Circular Path Example 1/5
Client
Server
Tor Node 1
Tor Node 2
Tor Node 3
Figure 3: Example showing how long circular routes are created
10
Circular Path Example 2/5
Client
Server
Tor Node 1
Tor Node 2
Tor Node 3
Figure 4: Example showing how long circular routes are created
11
Circular Path Example 3/5
Client
Server
Tor Node 1
Tor Node 2
Tor Node 3
Figure 5: Example showing how long circular routes are created
12
Circular Path Example 4/5
Client
Server
Tor Node 1
Tor Node 2
Tor Node 3
Figure 6: Example showing how long circular routes are created
13
Circular Path Example 5/5
Client
Server
Tor Node 1
Tor Node 2
Tor Node 3
Figure 7: Example showing how long circular routes are created
14
Attack Example
Client
Tor Node 3 - Our Exit Node
Server
Tor Node 1 - Unknown Node
DoS Client
Tor Node 2 - Known
High BW Tor Node 1
High BW Tor Node 2
DoS Server
Figure 8: Example showing a partial view of the Tor network during the attack
15
Attack Implementation
• Modiﬁed exit node
• Modiﬁed DoS node
• Lightweight DoS web server running on GNU libmicrohttpd
• Client side JavaScript for latency measurements
• Instrumentation client to receive data
16
Attack Implementation
• Exit node injects JavaScript “ping” code into HTML response
• Client browses as usual, while JavaScript continues to “phone
home”
• Exit node measures variance in latency
• While continuing to measure, DoS attack strains possible ﬁrst
hop(s)
• If no signiﬁcant variance observed,
pick another node from
candidates and start over
• Once suﬃcient change is observed in measurements, initial node
has been found
17
Gathered Data Example (1/10)
 0
 20000
 40000
 60000
 80000
 100000
 120000
 0
 100
 200
 300
 400
 500
 600
Latency variance (in milliseconds)
Sample number
Latency measurements graph
Trial without stress
Trial with stress
Figure 9: Attack eﬀects on an unused Tor node. Red line is unstressed test, green
is stressed test. X axis is measurement number, Y is “latency”
18
Gathered Data Example (2/10)
 0
 5000
 10000
 15000
 20000
 25000
 30000
 35000
 40000
 0
 100
 200
 300
 400
 500
 600
Latency variance (in milliseconds)
Sample number
Latency measurements graph
Control Run
Attack Run
Figure 10: Attack eﬀects on a Tor node.
Red line is unstressed test, green is
stressed test
19
Gathered Data Example (3/10)
 0
 1000
 2000
 3000
 4000
 5000
 6000
 0
 100
 200
 300
 400
 500
 600
Latency variance (in milliseconds)
Sample number
Latency measurements graph
Control Run
Attack Run
Figure 11: Attack eﬀects on a Tor node.
Red line is unstressed test, green is
stressed test
20
Gathered Data Example (4/10)
 0
 500
 1000
 1500
 2000
 2500
 3000
 3500
 4000
 4500
 5000
 0
 100
 200
 300
 400
 500
 600
Latency variance (in milliseconds)
Sample number
Latency measurements graph
Control Run
Attack Run
Figure 12: Attack eﬀects on a Tor node.
Red line is unstressed test, green is
stressed test
21
Gathered Data Example (5/10)
 0
 10000
 20000
 30000
 40000
 50000
 60000
 70000
 80000
 90000
 0
 100
 200
 300
 400
 500
 600
Latency variance (in milliseconds)
Sample number
Latency measurements graph
Trial without stress
Trial with stress
Figure 13: Attack eﬀects on a Tor node.
Red line is unstressed test, green is
stressed test
22
Gathered Data Example (6/10)
Figure 14: Histogram plot of latency times, red is unstressed trial, green is stressed.
Each histogram is from the same trials as the previous set of graphs
23
Gathered Data Example (7/10)
Figure 15: Histogram plot of latency times (same trials as previous graphs)
24
Gathered Data Example (8/10)
Figure 16: Histogram plot of latency times (same trials as previous graphs)
25
Gathered Data Example (9/10)
Figure 17: Histogram plot of latency times (same trials as previous graphs)
26
Gathered Data Example (10/10)
Figure 18: Histogram plot of latency times (same trials as previous graphs)
27
What We Actually Achieve
• We do identify the entire path through the Tor network (same
result as Murdoch and Danezis)
• We do achieve this on the modern, current Tor network
• This means that if someone were performing this attack from an
exit node, Tor becomes as eﬀective as a one-hop proxy
28
Why Our Attack is Eﬀective
• Since we run the exit router, only a single node needs to be found
• Our multiplication of bandwidth technique allows low bandwidth
connections to DoS high bandwidth connections (solves common
DoS limitation)
29
Fixes
• Don’t use a ﬁxed path length (or at least make it longer)
• Don’t allow inﬁnite path lengths
• Induce delays into connections (probably not going to happen)
• Monitor exit nodes for strange behavior (been done somewhat)
• Disable JavaScript in clients
• Use end-to-end encryption
30
Attack Improvements/Variants
• Use meta refresh tags for measurements instead of JavaScript
• Parallelize testing (rule out multiple possible ﬁrst nodes at once)
• Improved latency measures for ﬁrst hop to further narrow possible
ﬁrst hops
31
Conclusion
• Current Tor implementation allows arbitrary length paths
• Current Tor implementation uses minimally short paths
• Arbitrary path lengths allow DoS
• DoS allows detection of signiﬁcant changes in latency
• Signiﬁcant changes in latency reveal paths used
32
Questions?
33