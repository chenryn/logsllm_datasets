### Figure 4: Distribution of the Number of Executed Instructions Between Fault Injection and Detection
This figure illustrates the distribution of the number of executed instructions between the injection and detection of a fault. The percentages are normalized to all the runs that are detected via output mismatch (M), program failure (S), or both combined (A).

### 4.3 Performance Results
Performance is evaluated using two redundant processes for fault detection (PLR2) and three processes to support recovery (PLR3). Figure 5 presents the PLR performance on benchmarks compiled with both -O0 and -O2 compiler flags. Performance is normalized to the native execution time.

- For -O0 programs, PLR2 incurs an average overhead of 8.1%, while PLR3 incurs an average overhead of 15.2%.
- For -O2 programs, PLR2 results in a 16.9% overhead, and PLR3 results in a 41.1% overhead.

The overhead in PLR is primarily due to multiple redundant processes competing for system resources. Programs that place higher demands on system resources result in higher PLR overhead. Optimized binaries (e.g., -O2) stress the system more than unoptimized binaries (e.g., -O0), leading to a higher overhead. As the number of redundant processes increases, there is a greater burden on the system memory controller, bus, and cache coherency implementation. Additionally, increased synchronization with semaphores and shared memory usage can further degrade performance. At certain points, the system resources become saturated, severely impacting performance. This is evident in benchmarks like 181.mcf and 171.swim when running PLR3 with -O2 binaries. Further details on PLR overhead and system resource saturation points are provided in the next subsection.

### 4.4 PLR Overhead Breakdown
The performance overhead of PLR consists of contention overhead and emulation overhead, as shown in Figure 5.

#### 4.4.1 Contention Overhead
Contention overhead arises from the simultaneous execution of redundant processes and the competition for shared resources such as memory and system bus. This overhead is measured by running the application multiple times independently and comparing the overhead to a single run. This simulates running the redundant processes without PLR's synchronization and emulation. The rest of the overhead is considered emulation overhead.

Figure 6 shows the effect of L3 cache miss rate on contention overhead. Both PLR2 and PLR3 exhibit significant contention overhead with increasing L3 cache miss rates. With fewer than 10 L3 cache misses per second, the overhead is around 10%. Beyond this point, the overhead increases dramatically, reaching over 50% at about 40 L3 cache misses per second. These results indicate that the total overhead for using PLR is highly influenced by the application's cache memory behavior. CPU-bound applications can be protected with low overhead, while memory-bound applications may suffer from high overheads.

#### 4.4.2 Emulation Overhead
Emulation overhead includes the overhead from synchronization, system call emulation, and mechanisms for fault detection. To examine each aspect of emulation overhead, two synthetic programs were designed and run with PLR.

- The first program calls the `times()` system call at a user-controlled rate. `times()` is one of the simpler system calls supported by PLR and is used to measure the synchronization overhead within the emulation unit.
- The second test program calls the `write()` system call ten times a second, writing a specified number of bytes per system call. Each `write()` system call forces the emulation unit to transfer and compare the write data in shared memory.

Figure 7 shows the effect of synchronization on PLR overhead. Synchronization overhead is minimal up to about 300-400 emulation unit calls per second, with less than 5% overhead for both PLR2 and PLR3. After this point, the emulation overhead increases rapidly. These results suggest that PLR might be best deployed for specific application domains with limited system call functionality.

Figure 8 illustrates the effect of write data bandwidth on emulation overhead. The experiment evaluates the amount of data that must be compared between redundant processes. The write data bandwidth has similar characteristics to system call synchronization, achieving low overhead until a cut-off point. For the experimental machines, the overhead is minimal when the write data rate stays below 1MB per second but increases substantially after that point for both PLR2 and PLR3.

### 5 Related Work
PLR is similar to a software version of hardware SMT and CMP extensions for transient fault tolerance [11, 23, 28]. However, PLR aims to provide the same functionality in software. Wang [35] proposes a compiler infrastructure for software redundant multi-threading, achieving 19% overhead with the addition of a special hardware communication queue. PLR attains similar overhead and relies only on the existence of multiple processors. Additionally, PLR does not require source code modifications.

Executable assertions [14, 15] and other software detectors [27] explore the placement of assertions within software. Other schemes explicitly check control flow during execution [31, 25]. The software-centric approach provides a different model for transient fault tolerance using a software equivalent of the commonly accepted SoR model.

### 6 Conclusion
This paper highlights the necessity for software transient fault tolerance in general-purpose microprocessors and proposes process-level redundancy (PLR) as a viable alternative in emerging multi-core processors. By providing redundancy at the process level, PLR leverages the OS to freely schedule processes across available hardware resources. Moreover, PLR can be deployed without modifying the application, operating system, or underlying hardware. A real PLR prototype supporting single-threaded applications is presented and evaluated for fault coverage and performance. Fault injection experiments demonstrate that PLR's software-centric fault detection model effectively detects faults while safely ignoring benign ones. Experimental results show that when running an optimized set of SPEC2000 benchmarks on a 4-way SMP machine, PLR provides fault detection with a 16.9% overhead. PLR performance surpasses existing software transient fault techniques and takes a step towards enabling software fault-tolerant solutions comparable to hardware techniques.

### 7 Acknowledgments
The authors would like to thank the anonymous reviewers, Robert Cohn, Manish Vachharajani, Rahul Saxena, and the DRACO Architecture Research Group for their insightful comments and helpful discussions. This work is funded by Intel Corporation.

### References
[1] J. Aidemark, J. Vinter, P. Folkesson, and J. Karlsson. Experimental evaluation of time-redundant execution for a brake-by-wire application. In Proc. of DSN, 2002.
...
[40] J. Ziegler and et al. IBM experiments in soft fails in computer electronics (1978 - 1994). IBM Journal of Research and Development, 40(1):3â€“18, January 1996.