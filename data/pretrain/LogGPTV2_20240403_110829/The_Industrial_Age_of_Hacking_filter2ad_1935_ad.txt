during the daily team discussions with subjects. A number
of factors challenge SD in a semi-autonomous, team-based
analysis environment. The process of investing signiﬁcant
resources into a single target can reveal novel ﬂaws or no
ﬂaws at all; a hacker will not know which without ﬁrst
consuming considerable time and effort.
Minimum skill threshold Apprentice hackers are
prone to falling in rabbit holes. Votipka described this
thusly: “Without prior experience guiding triage, our
practitioners relied on stumbling across vulnerabilities
incidentally; or on their curiosity, personal creativity,
and persistence with ample time to dig through the
complexity of a program. Such incidental discovery is
time consuming and haphazard, with little consistency
in results [40, §VI.A.1].”
SD made recruiting more difﬁcult because of the
extensive list of prerequisite knowledge required to get
started with some of our targets. Considering the two
depth-ﬁrst projects mentioned in this paper, we sought
experience in: (1) software reverse engineering and
assembly architectures (2) C software development
(3) understanding and modifying software build tool
chains (4) binary patching (5) source auditing (6) bug
ﬁnding (7) the use of static analysis tools (8) fuzzing We
also aimed to ﬁnd self-motivated problem solvers.
Unsurprisingly, SD overwhelmed the less-skilled sub-
jects. Subjects performing SD felt more surprised, more
frustrated, and more doubtful than during SB. Subjects
also claimed SD was a less effective use of their team’s
skills than SB. We posit that these sentiments resulted from
the quick exhaustion of novice work at the beginning of a
bug-ﬁnding session, leaving tasks requiring a more skilled
practitioner. Very early on, when looking at uhttpd and
dropbear, novice subjects found valuable information
from Internet research, but for the remainder of the week,
they contributed signiﬁcantly less to team progress.
Feedback Loop When our teams were assigned a
single target, they continued working on that problem
even when automation might be on the path to a solution.
At some point, the human will be doing work eventually
rendered unnecessary due to that automation. This is
inefﬁcient because, in general, human time is expensive
while computer time is inexpensive.
SD left subjects less time to interact with tools and less
time harnessing than SB. This means hackers are not able
to maximize the time spent producing new harnesses to
test new code. There is a natural break where—once a
harness is complete—it is inefﬁcient for the hacker to con-
tinue work until they know what automation will discover.
Knowledge sharing and tasking A team of humans
simultaneously investigating the same target incurs a high
synchronization overhead. Some ﬁndings are of general
interest and should be shared as soon as possible, but
other information might not be of broad interest. Com-
municating incurs overhead, but under-communicating
leads to duplicate work. How to balance this is not always
immediately clear. Feedback from subjects indicated
that SB left them feeling less a part of a team than SD. We
believe this stems from the fact that SB naturally leads
to more independent work and a reduction in real-time
communications in favor of asynchronous communica-
tion, such as notes and code submissions. This position
is bolstered by teaming research in a related discipline
that found the most productive teams in cyber defense
exercises have the fewest direct human interactions [4].
The discrete tasks in the fuzzing process seem con-
ducive to parallelization. In practice, these tasks turn out
to be a pipeline, with progress on one task being necessary
in order to advance to the next. With some targets, such as
ubus [29], emulating the target is a nontrivial prerequisite
to fuzzing. The narrow target selection of SD does little
to help with parallelizing the fuzzing pipeline.
Output Ultimately, Team A found zero bugs in uhttpd
and three bugs in dropbear; Team B, zero and four. With
SD, hackers tended to go down “rabbit holes,” investing
signiﬁcant time and effort into analyzing complex
components of a target. The more time spent delving into
a particular component, the more a sort of tunnel vision
would develop. This left other components of the target
ignored. Ultimately, deadlines led to overlooked bugs that
might have been easy to ﬁnd using automation techniques
and minimal human effort.
5.6 Breadth-ﬁrst strategy discussion
Minimum skill threshold and feedback Our appren-
tice hackers were both more proliﬁc and more effective
while employing SB. SB allows the human to completely
USENIX Association
29th USENIX Security Symposium    1139
Figure 5: Total number of materials (Git commits, GitLab comments, GitLab projects, issues, issue tags, and Rocket.Chat
messages) produced per team over time; the vertical dotted line represents the transition between strategies
hand off work to the machine and only continue work on
that target once the machine had a chance to discover a
solution. Such a model allows for a feedback loop from
the human to the machine and back, minimizing human
time spent, and iterating until reaching a desired outcome.
Knowledge sharing and tasking
SB allows team
members to work with conﬁdence on independent tasks,
make progress until they understand the key pieces
of information, and then communicate those pieces
of information in an asynchronous way. This reduces
overhead and redundancy while resulting in a continually
growing record of ﬁndings, each feeding into the next.
With respect to coaching, pairing a novice with an expert
frequently resulted in the expert spending more time
teaching then hacking. In a model where team members
can record and convey their problem solving, more expert
people can review those problems and suggest paths
forward based on their experience. SB’s large set of targets
means that hackers can create a collection of fuzzing
pipelines as part of a parallel strategy.
5.7 Subsequent and future work
We applied our breadth-ﬁrst strategy to other large-scale
projects after our experiment, and we record here some
additional lessons. We also suggest areas of future work.
Targeting We have further automated our targeting
stage to make leaders more efﬁcient. In one project, a
team was asked to analyze four interesting devices. We
wanted to apply SB, so we wrote a script to enumerate the
binaries on each device and establish issues on GitLab
for each. This eased deciding what to work on, and it
simpliﬁed the tracking of progress.
Future experiments might beneﬁt from prioritizing
targets. The targets in our experiment’s queue were
unsorted. Thus analysts tended to work through the
Open column in GitLab from top to bottom, suggesting
that sorting the queue would result in more time spent
analyzing the highest-priority software.
Information gathering Future work could investigate
using web scrapers to perform common research tasks.
For example, if the target was objdump, a script could
collect the results of searching for “objdump CVE”, or
“fuzzing objdump.” These tools could easily append this
information to each target’s GitLab issue.
Program understanding There is a great deal of
further research to be done in the area of program under-
standing and its impact on decision making. Automated
tools should identify indicators of potential bugs. These
indicators would justify additional time spent improving
harnesses and diving deeper into understanding a target
program. Without them, scaling becomes difﬁcult if
not impossible, as analysts tend to spend too much time
focusing on challenging targets, possibly overlooking
easier-to-ﬁnd bugs in other targets. This is not to say
that challenging targets should be ignored, but that team
leaders should make an evidence-based determination of
how much time to dedicate to a challenging target before
the manpower cost outweighs the beneﬁt of ﬁnding a bug.
Obvious examples of other information that tools could
add to targets’ GitLab issues include: the lack of basic
run-time protection mechanisms like stack canaries, PIE,
RELRO, and non-executable stacks; the presence of the
SUID bit; --help and --version outputs; and whether
the program listens on a port (i.e., netstat output) or
runs automatically (i.e., ps output). This information
1140    29th USENIX Security Symposium
USENIX Association
Tue,11/12Wed,11/13Thu,11/14Fri,11/15Mon,11/18Tue,11/19Wed,11/20Thu,11/21Fri,11/22Date0200400CumulativematerialcountBreadth-FirstDepth-Firstwould help leaders prioritize targets or hackers select
them, and there is clearly room for more ideas.
experiment—the number of known bugs in the targets
used.
Attack surface analysis During a pilot study that
preceded our experiment, running fuzz harnesses on our
dedicated cluster required transferring the harnesses to a
separate network where a team member managed fuzzing
jobs. This proved to be a signiﬁcant undertaking. The
quality of the documentation provided by our hackers var-
ied, and thus reproducing the harness occasionally failed.
Failures led to several hours of rework. As a remedy, we
adopted the use of Docker [3]. A Dockerﬁle able to build
the targeted program on a base Ubuntu image with AFL in-
stalled has since then accompanied each new harness. We
made the hackers responsible for performing test builds of
their Dockerﬁle. The switch to Dockerﬁles as a deliverable
drastically reduced the overhead incurred when trans-
ferring the harnesses to a different network for fuzzing.
We later expanded this architecture so that hackers could
produce docker images that used any arbitrary fuzzer.
Automated exploration Automation in this stage
consists of taking the completed harnesses and running
them on computing resources. An architecture such as
Clusterfuzz [32] matches our intent. During the depth-ﬁrst
strategy, we attempted to use our computing resources by
having a single fuzz job run on many nodes of our cluster.
When we transitioned into having many targets, we
needed a simpler structure that would allow us to quickly
run many jobs. We decided after our pilot study that a job
running on a single node and employing all cores on the
node would ﬁt our needs. Not only is this an easier archi-
tecture to implement and maintain, but Cioce et al. show
the diminishing returns of additional fuzz-cores make this
a more efﬁcient use of our computing resources [7].
Vulnerability recognition While our experiment was
focused on building teams around the process of harness-
ing target applications, we realize that more work needs to
be done to establish processes for managing the results of
the fuzzing campaign—vulnerability recognition at scale.
Some applications produced numerous crashes, with one
application producing thousands of crashes. Techniques
for dedicating sufﬁcient time to crash triage while also
continuing to harness new targets must be developed.
With limited manpower, this is a challenging problem for
which we are still working on a solution.
Other researchers who choose to extend our work
should attempt to assign criticality scores to the bugs
found. They might also wish to determine—before their
Other We found overheads in SB that were much
less impactful to SD. Small things such as enforcing
GitLab policies or shepherding targets on and off of our
computing resources became time-consuming with many
projects happening simultaneously. Fuzzing, archiving
and reviewing results was difﬁcult to balance with other
targets in the queue. Also, in our actual operational
environment, higher leadership would add to our target
queue, leaving us to ﬁgure out how assign priorities while
balancing ongoing work. As with many endeavors, these
practical matters are a ripe area for future work.
6 Conclusion
Frustrated with the pitfalls of SD, we sought a better ap-
proach, and we found one. Evidence indicates SB is more
effective at ﬁnding bugs, and we found some positive side
effects as well. SB more efﬁciently employs hackers of
varying skill levels. It also boosts the amount of documen-
tation and learning resources available to hackers and lead-
ers, cultivating technical growth. SB better applies auto-
mated bug-ﬁnding tools, and it more clearly deﬁnes work
roles and unit tasks. Our experiment to test SD and SB is re-
peatable and thus allows researchers to test other hypothe-
ses related to the hacking process in a similar environment.
Finally, we learned, coached, and hacked for fun and proﬁt.
Acknowledgments
We are grateful for the aid Leslie Bell provided while
we sought approval of our experimental approach using
human subjects. Temmie Shade helped review our
survey questions, and James Tittle coached us on the
counter-balanced design of our experiment. Andrew Ruef
also gave his time to discuss many of our early ideas.
Richard Bae and ForAllSecure provided us with Mayhem
installation, support, and notable computing resources.
The staff at Dreamport (https://dreamport.tech)
hosted our pilot and experiment, providing space, com-
puting resources, and support. We thank our participants
in both the actual study and the pilot. This paper would
not have been possible without their help.
Our work was performed in part during a segment of
the NSA’s Computer Network Operator Development
Program, and both the investigators and many of our
subjects came from three military services: the Army,
Navy, and Air Force. We are grateful for our services’
support towards advancing vulnerability discovery.
USENIX Association
29th USENIX Security Symposium    1141
A Self assessment
On a scale of 0–5, how comfortable do you feel . . .
• Programming?
– With the C programming language?
∗ Writing a program from start to ﬁnish?
∗ Reading and understanding a large program?
∗ Modifying a large program?
– With the Python programming language?
∗ Writing a program from start to ﬁnish?
∗ Automating data processing tasks?
∗ Implementing algorithms and data structures?
– Collaborating with a software development team?
• Using open-source software?
– Compiling large software packages written in C?
– Using make? cmake? GNU auto-tools? git?
– Making small modiﬁcations to software?
– Making large modiﬁcations to software?
• Using Linux?
– Using bash?
– Using Debian-based Linux?
∗ Conﬁguring a Debian-based Linux system?
∗ Using APT?
– Understanding system calls?
– Understanding exit signals such as SIGSEGV?
• Using Docker?
• Using dynamic analysis tools such as fuzzers?
– Using QUEMU?
– Using a AFL?
∗ Modifying a binary-only target to work with AFL?
∗ Modifying an open-source target to work?
B Schedule
– Using Libfuzzer? Honggfuzz?
– Using CISCO-TALOS/Mutiny?
– Using an unlisted dynamic-analysis tool?
– Understanding run-time instrumentation?
– Understanding compile-time instrumentation?
– Writing your own custom purpose fuzzer?
– Understanding differed forking?
– Understanding persistent fuzzing?
– Enumerating all possible program input methods?
• Recognizing a software security ﬂaw?
– Reading articles on new software vulnerabilities?
– Reproducing research on software vulnerabilities?
– Understanding DEP, ASLR, and stack canaries?
– Overcoming these protections?
– Exploiting control over the instruction pointer?
– Exploiting control over printf arguments?
– Exploiting a program that misuses strcpy, memcpy,
or sprintf with a stack destination?
– Attacking programs that misuse system?
– Understanding the implications of a SUID program?
– Exploiting with heap-metadata overwrites?
– Finding information on the Internet?
• Using the scientiﬁc method?
• With Assembly Languages?
– Reading Intel x86? Writing Intel x86?
– Using different calling convention such as stdcall,
fastcall, and cdecl?
• Reverse engineering?
– Using debuggers? Using disassemblers?
– Collaborating with a team, reversing a large target
binary?
November 7, 2019
Monday
Tuesday
Wednesday
Thursday
Friday
Introductions
AFL class
Skill assessment
Docker
standards
and
submission
8:00 am
9:00 am
10:00 am
11:00 am
12:00 noon
1:00 pm
2:00 pm
3:00 pm
4:00 pm
1142    29th USENIX Security Symposium
USENIX Association
November 12–15, 2019
Monday
Tuesday
Wednesday
Thursday
Friday
Introductions
Introductions
Introductions
Introductions
Sprint hours
• Apply targeting strategy
• Hourly survey
• Lunch
Sprint hours
• Apply targeting strategy
• Hourly survey
• Lunch
Sprint hours
• Apply targeting strategy
• Hourly survey
• Lunch
Sprint hours
• Apply targeting strategy
• Hourly survey
• Lunch
Team synchronization
Team synchronization
Team synchronization
Team synchronization
November 18–22, 2019
Monday
Tuesday
Wednesday
Thursday
Friday
Discussion
• Team interview
– Utility