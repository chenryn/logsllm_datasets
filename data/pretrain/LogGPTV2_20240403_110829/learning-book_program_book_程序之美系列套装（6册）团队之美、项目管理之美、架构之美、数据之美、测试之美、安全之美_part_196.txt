技巧#7对类进行instanceof的操作更快
对一个类进行instanceof的操作比用接口来操作它快得多。Java的单
继承模式意味着对于一个类，instanceof仅仅是一次减法和一次数组
查找；对于一个接口，那是一次数组搜索。
在这点并销也成问题的地方，我们可以进行进一步优化。请注意，
物理地址空间中的存储器分为三个不同的种类：
随机存取存储器（RAM）
物理的随机存取存储器从零地址向上映射。它被频繁地存取且等待
时间很短。
只读存储器（ROM）
只读存储器芯片可以存在于任何地址。它们很少读取且等待时间很
短。
I/O
I/O映射的存储器可以存在于任何地址。它被相当频繁地存取，但等
待时间通常比随机存取存储器更长。
1106
---
## Page 1108
为了对那些落入实际机器的RAM中的信息进行寻址，我们使用一阶
段查找。这确保对RAM存取的等待时间尽可能地低。为了存取其他
地址（ROM芯片和I/O映射存储器占据的地址），我们使用两阶段
查找，如图9-3所示。
210数组
210块
address>>>12
212bytes=4Kb
&Ox3ff
address
&Oxfff
数据字节
图9-3：两阶段查找的物理地址空间
现在，从RAM"get"一段内存有3个阶段：
return addressSpace.get (address) ;
return blocks [i>>>12].get (address&0xfff) ;
return memory[address]:
从更高地址"get"有4个阶段：
return addressSpace.get (address) ;
Oxf f f) :
return memory[address]:
1107
---
## Page 1109
这个两层优化节省了内存，同时避免在每次RAM存储器存取时形成
瓶颈。在一个存储器“get"中的每次调用和间接放置都执行一个函
数。确实应该使用的间接方式一不是为了交互，而是为了在性能和
复杂度之间达到最好的平衡。
JIPC在有可能用不到存储的任何地方还使用了延迟初始化。因此，
一个新的JPC实例拥有一个映射到不占据空间的Memory对象的物理
地址空间。当RAM的一个4KB区域第一次读或写时，这个对象将完
全初始化，如例9-1所示。
例9-1：延迟初始化
public byte getByte (int offset)
try(
return buffer[offset]:
)catch (NullPointerException e){
buffer=new byte[size]:
return buffer[offset]:
上
9.6保护模式的危险
保护模式的到来带来了一个完整的存储器管理系统，同时在物理地
址空间之上又增加了一个复杂的层。在保护模式中，内存分页可以
是激活的，这容许物理地址空间的4KB块进行重新排列。这种重新
排列由保存在存储器中的、可以由运行在这机器上的代码动态修改
的一系列表进行控制。图9-4演示了一个完整的分页转换所经过的路
线。
1108
---
## Page 1110
大体上，机器上的每次内存存取都需要这样一个完整的查找次序：
通过内存分页结构找到特定线性地址映射到的物理地址。由于这个
过程太复杂且开销很大，实际的机器会把这些查找的结果缓存在转
换后备缓冲（TLB）中。除了这些增加的间接层之外，内存分页还
有额外的保护特征。每个映射的分页都可以给定一个用户或管理员
和读或读/写的状态。没有足够的权限而试图存取分页的代码，或设
法存取不存在分页的代码会引起一个在某种意义上类似于一个软件
中断的处理器异常。
为了优化这样的结构，我们的首要战略应该是采用实际处理器的途
径，这非常清楚；换句话说，我们必须拥有某种形式的查找缓存。
为了设计它，我们做出了两个关键的选择：
线性地址
31
22
21
12
11
L
4KbPage
分页表
分页目录
(1024 Entries)
(1024 Entries)
物理地址
表项
目录项
分页目录基址
寄存器
图9-4：IA32架构的分页机制（仅仅4KB页）
分页的重新映射以4KB的粒度进行。不是巧合，而是为了方便，这
也是我们为物理地址空间选的粒度。
当一个保护模式进程存取内存时，它只看这些4KB块的重新映射图
（虽然其中的一些块引起处理器异常）。物理地址空间仅仅是最初
1109
---
## Page 1111
的Memory对象的一种可能的顺序（在那里，所有的对象都同时按地
址顺序排列），与其他的任何顺序相比，没有特别的意义。
根据这两个选择，我们明白缓存（例如，TLB）的最自然的形式是
复制物理地址空间结构。内存分页依照lookup分页表确定的新的顺
序进行映射。第一次请求一个给定表内的一个地址时，会完整遍历
这个表的结构以找到匹配的物理地址空间内存对象。然后，对这个
对象的一个引用会放入线性地址空间内的正确位置，从那时起它就
一直缓存着，直到我们选择清除它。
为了解决读/写和用户/管理员的问题，我们做了一个战术性的决
定，为了速度而牺牲一些内存开销。我们为每个组合（读-用户、
读-管理员、写-用户和写-管理员）制造一个线性地址空间。内存
"get"使用读标记，“set"使用写标记。因此，在用户模式和管理员模
式之间的转换只需要改变内存系统中的两个引用，如图9-5所示。
用户模式
管理员模式
写映射
写映射
读映射
读映射
图9-5：线性地址空间中的保护级别切换
注意：这非常适合Linux内核的分页方法。在Linux中，每个用户模
式进程都映射到它的线性地址空间的内核分页。在硬件中，这防止
了日常维护操作或系统调用在转移到内核代码时的上下文切换。我
们到内核空间的切换仅仅是数组引用的翻转，这也是一个低开销的
进程。
1110
---
## Page 1112
这还给我们留下页错误和保护系统侵犯的问题。我们处理这些情形
的态度在某些方面就是我们判断是否是异常的指示，既在低级别的
处理器方面也在Java语言中。这个态度可以总结如下：
Exception是异常，Error是错误。
详细地说：Exception应该代表极少或例外的情形，但不一定是毁灭
性的；Error应该代表毁灭性的或相当严重的不期望的情形。
就Java语言中异常处理实现的程度而言，许多程序员不愿意使用对
他们有利的异常处理机制，这有些奇怪。对软件来说，异常代表了
处理罕见但也可以纠正的情形的最有效和简捷的方式。抛出一个异
常会由于有效地优化常规路线而使执行并销有偏向，同时会增加处
理不可避免的异常情形的开销。这样说来，页错误和保护系统侵犯
是一个异常的但应该映射到一个Exception实例的正常事情，这是显
而易见的。
技巧#5：Exception用于异常的情况
Exception应该用于异常条件，不要用于错误。把异常用作为非正常
环境中的流控制会提示V/M优化正常的路径，给你带来更好的性
能。
在处理页错误和异常时，对异常的使用，我们有两个比较常用的惯
例：
·ProcessorException，是代表Intel处理器所有异常类型的一个类，继
承了RuntimeException。
页错误，轻度的保护系统侵犯，是异常的情形，但为了控制牺牲性
能，它们非常普通，我们使用静态的异常实例抛出它们。
关。
决定选择继承RuntimeException主要是考虑代码的美观。一般而言，
运行时异常用于不能捕获或不应该处理的异常。大部分材料推荐说
如果抛出这类异常，它们允许传播并引起抛异常的线程终止。我们
知道，在运行时异常和检查的异常之间的区别是类似于泛型、自动
封装或for-each循环的代码“糖果”。倒不是我们想要氓毁这些结构，
1111
---
## Page 1113
而是发现异常的分类对编译后的代码没有影响，我们可以安全地选
择最方便的类型而不会引起任何性能瓶颈。在我们的项目中，
ProcessorException是一个运行时异常以避免必须在很多方法中声明
throws ProcessorException。
异常），这在异常处理链的两端都产生好处。首先，我们自己节省
建调用线程的栈跟踪的开销（完全不像在现在的JVM中那么微不足
道）。其次，我们自己节省了判断thrown类型的并销，由于有了有
限的一组静态异常来判断thrown类型，我们只需进行一系列引用比
较。
9.7从事一项毫无成功希望的斗争
IA-32架构中没有什么比指令集更流行。经过这么多年，曾经在8080
时代基于累加器的简单架构已经成为一个非常巨大和复杂的指令
组。IA-32已经成为一个拥有无数固定扩展和许多寻址模式的类似于
RISC的芯片。
当作为Java开发人员看到这样的前景展望时，回复到打字和并始编
写类，这非常诱人，就好像编的结构越多，问题就越简单。如果我
们正在并发一个分拆器，那这种方式即使不完美，也会很好。在这
种创建非常多的对象的系统中，不可避免也会有许多的垃圾收集。
这导致双重的速度瓶颈。我们不仅承受大量的对象分配的并销，还
承受频繁的垃圾收集。在一个现代的按代区分的垃圾收集的环境中
（SumnJVM就是这样的），小的、短生命周期的对象都创建于初生