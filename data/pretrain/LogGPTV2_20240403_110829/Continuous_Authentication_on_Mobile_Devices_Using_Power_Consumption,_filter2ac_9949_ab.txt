Each of the components has device drivers, which report sensory statistics to
the kernel. The nature and frequency of this data depends on the individual
hardware component. Some components require registering event listeners with
the Android API, whereas other components require polling the system for data.
For the application context, the name of the application in focus was recorded
using the Activity Manager API while users interacted with the mobile device.
This is used to determine the context of the model.
For the power modality, in order to determine the power consumption result-
ing from the activities performed by the user, we used the built-in voltage and
current sensors available as part of the battery driver on smartphones. The power
drained from battery is proportional to load. While the batteries decay nonlin-
early (reﬂected directly in the voltage readings), the current readings oﬀset this
eﬀect in order to deliver the required power. Therefore, in order to model power
consumption, it is suﬃcient to capture voltage and current. The sensors report
the voltage and current to the operating system’s kernel in units micro-volts
(µV) and micro-Ampere (µA) respectively. While the voltage reading depends
on the battery charge and changes gradually between 4.35 V to 3.2 V, the current
reading directly depends on the amount drawn by the Android Operating Sys-
tem depending upon what activities are being performed. As a result, while we
poll the voltage every 5 s, the current reading is polled every 1 s and we take an
average of the recorded values every 5 s. Using these readings, we can calculate
the average power consumption every 5 s.
For the movement modality, readings were recorded using the SensorEvent
API, which is a part of the standard Android SDK. Depending upon which
hardware sensors are present on the Android device, the API has the capability
to report values from the following sensors: accelerometer, gyroscope, magnetic
ﬁeld, light, pressure, and proximity. For our analysis, we gathered movement
readings from both accelerometer and gyroscope sensors. The accelerometer sen-
sor measures acceleration in SI units (m/s2) along the device’s local [X, Y, Z]
axes and the gyroscope sensor measures rate of rotation in SI units (rad/s)
around the device’s local axes.
For the touch modality, the user-level touchscreen gestures of key-press, pinch
and zoom, swipe, and other gestures are all reported as multiple events to
an input driver. The touch event interface exists as a character device under
/dev/input and can be read by any program that has permissions to read it. For
security reasons, this input driver is a protected interface. Only vendor programs
are given this permission on any unmodiﬁed commercially available Android
device. The device driver reports the following information: [X, Y] coordinates,
number of ﬁngers touching the screen, pressure of each ﬁnger, and touch area of
each ﬁnger. We capture the events along with precise timing information directly
from these low-level event streams and reconstruct it back to user-level gestures.
Continuous Authentication on Mobile Devices Using Power Consumption
411
Fig. 2. Smartphone sensor data collection framework
Data Collection Tool. Figure 2 shows the smartphone sensor data collection
architecture. There are 4 services running in our data collection application:
PowerLogger, TouchLogger, GyroLogger, and ActivityLogger.
– Service 1 (PowerLogger): It collects the Voltage, Current and Battery Charge
from the battery driver (via sys ﬁlesystem).
– Service 2 (TouchLogger): This service reads the input events driver to collect
system-wide touchscreen events. The touch driver is protected by a system
user group “input”.
– Service 3 (GyroLogger): This uses the Android API to collect both gyroscope
and accelerometer sensor data using a SensorEventListener.
– Service 4 (ActivityLogger): This service uses an Android API to record the
user activity on the device. Speciﬁcally, we record the top running application,
incoming and outgoing calls, and screen-oﬀ and screen-on events.
All these services are active during both training and testing, and the overall
system power consumption is guided by user’s behavior plus a constant from
these services. Therefore, our measurement tool does not adversely impact the
power proﬁle we generate for a user. We took measures to make our services
robust, such that we keep this constant noise in the power consumption readings
small, regardless.
4 Experimental Design
When performing a study with volunteer participants, the results obtained
depend strongly on the quality of the data collected. It is vital to understand
any sources that can cause potential variance in the data for a speciﬁc user and
to retain data in a uniform format using uniform devices. While our proﬁle gen-
eration algorithms do not require such precautions, this step is needed in order
to compare the datasets and evaluate the performance fairly.
To achieve uniformity of measurements, we used the same device (Google
Nexus 5 Model:LG-D820) for all users who volunteered for this study. Further,
412
R. Murmuria et al.
all data collections were performed on Android version 4.4.4 (Build number
KTU84P). Studying the eﬀects of collecting data across diﬀerent smartphone
models or software versions was not attempted. We also did not use any tablet
devices.
In total, 73 users volunteered for this experiment. The experiments were
designed to collect data from each volunteer participant for two 45 min sessions.
We assumed that a user’s behavior varies while using diﬀerent applications on
the smartphone. All volunteer participants were allowed to use Chrome and Face-
book, which are standard applications available on Android phones. They were
not restricted in terms of what tasks they can perform using those applications.
The application currently in use was recorded and user proﬁles were generated
keeping separate data for each context.
We did not want environmental interference within our data and therefore,
the user was restricted to remain within a room. Each user was asked to use the
two pre-chosen applications for 20 min each with a break of 5 min for instructions.
This session was repeated on two diﬀerent days in order to capture the user’s
behavior eﬀectively. This would total up to 80 min of actual smartphone usage
data for each user. All tasks were performed while sitting down. Although no user
walked or performed any other physical activity, the smartphones were subject
to signiﬁcant movement due to typical usage of the device.
Our experimental setup does not emulate real-world use of the chosen appli-
cations. However, related research on mobile authentication techniques relies
solely on evaluating touch or movement patterns on custom designed applica-
tions or in much more restricted environments where users are asked to perform
speciﬁc actions repeatedly (swiping or moving in a direction). One of the contri-
butions of our work is the veriﬁcation of the idea that the application itself plays
a signiﬁcant role and alters the user behavioral patterns. Our results indicate
that previous results on active authentication are not applicable in real-world
scenarios.
As part of our experimental protocol, we instructed the volunteers to login to
Facebook ﬁrst. No touch or other sensory data was collected during this ﬁrst step.
All other activities the volunteers performed on the smartphones did not involve
entering a password of any nature. Each user was assigned a pseudonym with
the convention Sxx, where the xx is a digit between 1 and 100. The real names of
the users were not retained. We also did not record any user-generated content
outside of the sensory data. No web traﬃc or URLs were recorded. No attempt
was made to capture the content that a user saw on the screen. We recorded
data from all the sensors concerned into ﬁles for each modality. These ﬁles were
stored in the external storage directory of each smartphone. Upon completion of
a user’s session, we extracted that data out from the smartphone into our data
store where we analyzed the data.
All our volunteer participants were aged between lower 20s and upper 40s,
covering a variety of ethnicities and nationalities. Some of our participants
were not regular smartphone users. We did not attempt to discriminate who
volunteered, beyond requiring them to have an active Facebook account. Our
Continuous Authentication on Mobile Devices Using Power Consumption
413
research required behavioral data of human subjects and necessary approvals
were acquired from the Institutional Review Board (IRB).
5 Data Preparation
5.1 Feature Engineering
After collecting the raw data, we performed feature extraction on the data from
each modality. Currently, there are no universally accepted set of features that
represent individual events for each of the modalities. For the purposes of this
research, we selected our feature set based on our own experience with the data.
For the power modality, the activities performed by the user were repre-
sented in milliwatts (mW) using the voltage and current readings. These power
consumption readings were used in our algorithm as a time-series.
For the movement modality, the recorded events were divided into small win-
dows of time where we can measure properties related to the group of events.
Let the size of this window of time be w units, then we employed the use of a
sliding window technique that moved w/2 units in direction of increasing time
for each subsequent record in our prepared movement dataset. As a result, every
event in the raw data contributed to 2 windows in the movement dataset. We
made this choice because it is diﬃcult to determine the start and end of any
particular movement gesture, and using non-overlapping windows would result
in loss of precision. For the purposes of our analysis, the data associated within
each window frame can be referred to as one movement gesture. Each movement
gesture was encoded as a sequence of events; each event is a vector of sensory
signals as described in Sect. 3. Fourteen features were extracted from each move-
ment gesture. These features include mean and standard deviation along each
axes and resultant magnitude of all axes, for both accelerometer and gyroscope
readings.
For the touch modality, the recorded events were aggregated into touch ges-
tures. Each gesture is a sequence of touch events that begins with touch down
of the ﬁnger and ends with lifting the ﬁnger. Five features were extracted from
each touch gesture. These include: duration, end-to-end distance, end-to-end
direction, average pressure, and average touch area.
5.2 Data Cleaning and User Selection
Since each of the features we collected for touch and movement modalities had
diﬀerent units, we standardized the dataset using the mean and standard devi-
ation of each feature over the entire dataset of all users.
After extracting features, the data was divided according to application con-
text. The ActivityLogger in our data collection tool inserted place-markers in
the data whenever the user switched from one application to another. As part of
pre-processing the data, only those events were extracted, that were generated
while using the application for which the user proﬁles are being created. As a
414
R. Murmuria et al.
result, multiple datasets were created, one for every combination of the users,
applications, and modalities.
We then analyzed if a similar amount of data was collected for every user.
As we mentioned in Sect. 4, every user was given a ﬁxed amount of time to use
the device. Users who generated very small datasets did not perform enough
actions on the device for us to model. Further, users who generated too much
data expectantly did not follow a normal use-case and would not match them-
selves under diﬀerent circumstances. Therefore, any user who generated data
of abnormally large or small sizes was discarded. In order to compute this, we
ﬁrst merged the data collected for each of the 73 users over the two days of
experiments. The number of records was tabulated for each of the 6 datasets
(2 applications and 3 modalities) for every user, and the means and standard
deviations were computed. We then removed those users who had any dataset
with sizes more than or less than 2 standard deviations from the corresponding
mean. With this method, 59 users were selected who had comparable sizes of
data. In order to prepare the baseline, 60 % of each user’s dataset was used. The
algorithms we used to train a model using this data are described in Sect. 6. As
a result, users’ proﬁles were created. The remaining 40 % of datasets for each
user were used to test this model.
6 Analysis to Compute Authentication
We view the authentication task as one of determining whether the current
stream of measurements of a given kind follows the same distribution as those
obtained in a baseline session for a given user. As such, we employ algorithms
that are capable of detecting outliers with respect to the baseline distribution
and place a bound on how many outliers we can allow if we assume the test
data follows the same distribution of the baseline. Exceeding this bound is an
indication of the user being an impostor.
We separate the analysis techniques in two groups. The ﬁrst, utilized for
multivariate data (e.g., the data collected from touch and movement modalities),
is an adaptation of an outlier detection algorithm ﬁrst published by Barbara
et al. [16] and described in Sect. 6.1. The second, utilized for univariate time-
series data (e.g., power measurements) is based on a technique reported by Keogh
et al. [17] and is explained in Sect. 6.2.
6.1 Strangeness-Based Outlier Detection
Strangeness-based Outlier Detection (StrOUD) algorithm, utilizing a machine
learning technique called transduction, was devised by Barbara et al. [16] to
detect outliers in datasets. Transduction is a machine learning technique based
in the process of reasoning from speciﬁc (baseline) cases to speciﬁc (testing)
cases. This is in contrast to induction which reasons from speciﬁc cases to rules
that can be applied to test other cases. The method was invented by Vapnik
et al. [18], motivated by his view that induction requires solving a more general
Continuous Authentication on Mobile Devices Using Power Consumption
415
Fig. 3. Strangeness-based outlier detection
problem, while transduction requires solving a more speciﬁc problem, which is
easier, and, in many cases, more accurate.
Transduction is carried out by placing a point in a known sample distribution
of data and using hypothesis testing to determine whether it is a good ﬁt or not.
To that end, a measure of uniqueness, or strangeness is used for every point in
the distribution, including the one we are trying to ﬁt. Strangeness is deﬁned
by a function that measures the uniqueness of that point. Vapnik et al. utilized
transduction in the context of classiﬁcation, or supervised learning, to properly
place new points in their rightful class. The technique is called Transductive
Classiﬁcation Machines or TCM. The transduction methodology does not build
general models. The ‘models’ are captured in the distribution of uniqueness
values for each class.
Statistical hypothesis testing which aims to prove or disprove one of the