BEC-Guard
(Combined)
Impersonation Only
98.2%
11.7%
0.000019%
(1 in 5,260,000)
0.016%
(1 in 6,300)
Recall
96.9%
100%
Table 6: Precision, false positive rate, and recall of BEC-Guard
compared to the impersonation classiﬁer alone.
While this is indeed a potential evasion technique, these third
party services often have their own anti-fraud mechanisms
to stop impersonation. In addition, we believe an imperson-
ation attempt is less likely to succeed if it going through a
third-party service, since it would probably seem much less
natural than simply sending an email from the email account
of the employee. Regardless, we have never seen this evasion
technique being used by attackers.
7 Evaluation
In this section, we evaluate the efﬁcacy of BEC-Guard. We
ﬁrst analyze the end-to-end performance of BEC-Guard, using
a combination of the impersonation and content classiﬁers.
We then break down the performance of each set of classiﬁers,
and analyze the performance of different classiﬁer algorithms.
We also try to estimate the extent of unknown attacks that
are not caught by BEC-Guard, by comparing the number of
reported missed attacks by customers to the number of true
positives.
7.1 End-to-end Evaluation
For the end-to-end evaluation, we randomly sampled emails
that were processed by BEC-Guard in June 2018. We manu-
ally labeled the emails, and evaluated BEC-Guard’s classiﬁers
on the labeled data. We labeled the emails for the evalua-
tion dataset similar to the way we labeled the training data
for BEC-Guard’s classiﬁers (see §4.6). We ﬁrst ran a set of
queries that uncover all the BEC attacks that we could ﬁnd
under our labeling assumptions. We then manually labeled
the resulting emails, and found 4,221 BEC emails. The entire
process took about a week of work for one person. The emails
that were not labeled as BEC attacks were assumed to be
innocent (In §7.3 we discuss emails that might have been
missed by our labeling process).
To evaluate the classiﬁers, we randomly split the evaluation
dataset in half: we used half of the emails for training, and the
rest to test the classiﬁers. The dataset includes 200 million
emails from several hundred organizations.
To test the end-to-end efﬁcacy of BEC-Guard, we ran the
content classiﬁers only on the emails that were detected as
impersonation emails by the impersonation classiﬁer. Table 6
summarizes the efﬁcacy results. The recall of BEC-Guard is
high within the emails we labeled: 96.9% of the BEC emails
we labeled were successfully classiﬁed by the impersonation
classiﬁer as well as one of the content classiﬁers. The com-
bined false positive rate is only one in 5.3 million emails are
Algorithm
Logistic Regression
Linear SVM
Decision Tree
Random Forest
KNN
Text classiﬁer
Precision
97.1%
98.3%
96.0%
99.2%
98.9%
FP
6.1·10−5%
3.6·10−5%
8.5·10−5%
1.7·10−5%
2.3·10−5%
Recall
98.4%
98.7%
97.1%
96.4%
97.5%
Table 7: Text classiﬁer algorithm efﬁcacy using a dictionary of
10,000 words. There is very little difference between the efﬁcacy of
the algorithms for the text classiﬁer.
Algorithm
Logistic Regression
Linear SVM
Decision Tree
Random Forest
KNN
Link classiﬁer
Precision
33.3%
92.3%
94.9%
97.1%
92.5%
FP
85.7·10−5%
3.2·10−5%
2.3·10−5%
1.3·10−5%
3.3·10−5%
Recall
96.0%
90.8%
96.3%
96.0%
93.5%
Table 8: Link classiﬁer algorithm efﬁcacy. Random forest provides
superior results over the other algorithms.
falsely detected, which is above our design goal of 1 in a
million email. The precision is 98.2%.
The false positives of the combined classiﬁers were due
to unlikely incidents where the impersonation classiﬁer de-
tected the email (e.g., due to a personal email address) that
also contained anomalous content (e.g., an employee uses a
personal email to forward links with low popularity domains
to a colleague). Another common false positive occurs when
employees leave the organization, and request W-2 forms for
tax purposes or other personal information. We plan on ad-
dressing such false positives by incorporating features that
would indicate whether a sender is no longer an employee
of the organization (e.g., if they have stopped sending emails
from their corporate address). The false negatives are mostly
due to instances where the URL is not deemed suspicious,
because it belongs to a domain that got compromised that
had a relatively high domain popularity, or because the text
of the email is not classiﬁed as suspicious. The latter case is
typically because the attacker did not use phrases that were
similar to any of the BEC attacks that were used to train the
text classiﬁer. For example, one of the false negatives asked
the recipient for gift card information, which was not a request
that was used in any prior attacks.
We also ran the impersonation classiﬁer on the evaluation
dataset. Its precision is 11.7%, and its false positive rate is
0.016%. Organizations that are only concerned about recall
and have the ability to tolerate a relatively large number of
false alerts can run the impersonation classiﬁer on its own.
The vast majority of false positives of the impersonation clas-
siﬁer are due to employees using their personal or university
(alumni) email addresses.
1302    28th USENIX Security Symposium
USENIX Association
Org
TPs
FNs
Reason
A
B
C
D
E
Total
31
4
12
8
5
60
1
1
1
1
1
5
Generic Sender Name
Misclassiﬁed Content
External Impersonation
External Impersonation
Misclassiﬁed Content
Table 9: True positives (TPs) and reported false negatives (FNs)
among ﬁve organizations, where the administrator has reported at
least one false negative.
impersonation classiﬁer.
To analyze the effect of the dictionary size on the classiﬁ-
cation, Figure 5 plots the efﬁcacy of the text classiﬁer using
KNN with different dictionary sizes. The graph shows that
most of the marginal beneﬁt is achieved with a dictionary size
of 1,000. We observed no noticeable difference in efﬁcacy
when using a dictionary larger than 10,000.
7.3 Evaluating Missed Attacks
A general limitation of evaluating imbalanced datasets is that
it is difﬁcult to accurately estimate the true false negative
rate. In our evaluation dataset, we can only estimate the false
negative rate in relation to the data that we labeled. If we
missed an attack during labeling, and it was not detected by
the classiﬁers, we would not count it as a false negative.
To deal with “unknown” attacks, our production system
allows users to report attacks that it did not detect. We es-
timate the number of missed attacks among organizations
that have reported missed attacks. We selected ﬁve random
organizations that reported missed attacks, and analyzed their
detections in the month during which they reported missed
attacks. Table 9 provides the number of true and missed de-
tections among these ﬁve organizations, as well as the reason
for each false negative.
In organization A the attack was missed because the email
did not impersonate an employee name, but rather the sender
name had a generic title (e.g., “Accountant”). BEC-Guard
only detects the impersonation of an employee’s name. As we
explained in our labeling assumptions (see §4.6), BEC-Guard
is only designed to detect attacks that explicitly imperson-
ate an employee name. We speculate that this type of email
would be less successful, because the recipient might ﬁnd it
unusual to get an email from a sender name with a generic
title, which is not normally used in their company. Neverthe-
less, our commercial product utilizes other detectors that ﬁnd
“generic titles” as well (see §6). In organization B and E the
impersonation classiﬁer successfully detected an imperson-
ation, but the text classiﬁer did not deem the text of the email
as suspicious. In both instances, we have since retrained BEC-
Guard’s text classiﬁers using the reported emails. In the case
of organization C and D, the reported missed email was due
to the impersonation of an external colleague (e.g., a vendor
the company works with that got impersonated). In §6 we
Figure 4: ROC curve of text classiﬁer with different algorithms. All
four algorithms perform very similarly, and reach a precision cliff at
about 99% recall.
Figure 5: ROC curve of text classiﬁer using KNN with different
dictionary sizes. A dictionary size of 1,000 already provides most of
the beneﬁt.
7.2 Classiﬁer Algorithms
Table 7 compares the results of the text classiﬁer using dif-
ferent classiﬁer algorithms. As the results show, there is a
very small difference between the different classiﬁers. This
is primarily due to the fact that we use a dictionary with a
large number of features (10,000). Table 8 shows the results
for the link classiﬁer. In the case of the link classiﬁer, random
forest more clearly provides superior results than the other
classiﬁers, including KNN. The link classiﬁer is more sensi-
tive to the classiﬁcation algorithm, because it uses a smaller
number of features. Figure 4 presents the ROC curve for four
of the classiﬁer algorithms that have a probabilistic output.
The ROC curve shows the how each classiﬁer can be tweaked
to trade-off precision for recall. All four algorithms behave
almost identically: they provide a high level of precision, until
a recall level close to 99% where their precision drops. Note
that to generate the ROC curves we ran the text classiﬁer
only on the emails that were already classiﬁed as imperson-
ations. Therefore, its minimum precision in the ROC curve is
equal to about 11.7%, which is equal to the precision of the
USENIX Association
28th USENIX Security Symposium    1303
discuss how to extend BEC-Guard to detect such attacks.
8 Related Work
The growing threat of BEC is widely known and has been
described in many in industry and government reports [13,22,
23]. However, the existing academic work uses very small or
synthetic datasets, and suffers from high false positives. In ad-
dition, since existing related work is based on limited datasets,
it fails to address many of the real-world issues discussed in
our paper, such as dealing with the imbalanced dataset, the us-
age of personal email addresses by employees or “legitimate”
impersonations. We believe the reason for the small body of
related work is that BEC primarily affects corporate users
(not consumers), and it is generally difﬁcult for academic
researchers to obtain access to corporate email data.
EmailProﬁler [10] builds a behavioral model on incoming
emails in order to stop BEC. However, it is based on only 20
mailboxes, has no examples of real-world attacks and does
not report false positive rates. In addition, there is prior work
on systems that detect emails, which compromise employee
credentials with a phishing link [20,45]. There is some overlap
between BEC attacks and emails that compromise credentials:
in our dataset, 40% of BEC attacks try to phish employee
credentials with links. However, the remaining BEC attacks
do not contain a phishing link that compromises credentials,
and cannot be detected by these systems.
Gascon et al. [14] design a model to stop emails that
spoof the domain of the receiver. Similar to BEC-Guard, they
base their model on the historical communication patterns
of senders. However, in our dataset, spooﬁng emails repre-
sent only about 1% of BEC attacks. Therefore, their model
would not catch the other 99% of BEC attacks. The reason
domain spooﬁng represents a small percentage of our dataset,
is our dataset only contains emails that were already ﬁltered
by an existing spam ﬁlter (e.g., Ofﬁce 365’s default ﬁlter). Do-
main spooﬁng emails contain a mismatch between the sender
and reply-to domains, or between the sender domain and the
from email envelope. For this reason, traditional spam ﬁlters
already stop a large number of spooﬁng emails [33]. In addi-
tion, their model is based on a dataset of only 92 mailboxes.
DAS [20] uses unsupervised learning techniques to identify
that result in credential theft, which are a subset of BEC at-
tacks. However, it cannot detect attacks that contain only plain
text, and is based on a dataset from a single organization with
only 19 known attacks. It also suffers from a 0.2% precision,
and a much higher false positive rate than BEC-Guard. Simi-
larly, IdentityMailer [45] tries to prevent employee credential