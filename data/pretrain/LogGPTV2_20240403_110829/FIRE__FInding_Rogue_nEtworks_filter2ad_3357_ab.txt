Note that we observed C&C servers that were online
for more than 60 days, but limited the x-range of the
graph to illustrate the rapid decline in botnet C&C
servers that are taken down after only a few days,
mainly by reputable IRC and web hosting providers.
We have been monitoring 1,161 of drive-by-
download servers since August 2008. These servers
have a much higher average lifetime than the other
sources depicted in Figure 3. In fact, the number of
drive-by-download servers that have been online for
more than 60 days is 92, or more than 15%. Also,
there have been 17 (approximately 3% of all) drive-
by-download servers that have been online since the
start of our collection.
From July 2008, we recorded 12,149 IP addresses
hosting phishing websites. Similar to botnet C&C
servers, the majority of phishing websites were online
for only a few days. However, we also observed a few
phishing sites that were online for more than a year.
Figure 4 shows the uptime for the ﬁrst 60 days for
phishing hosts.
As mentioned previously, we use the longevity of
malicious services as a distinguishing feature of rogue
networks. This insight is supported by the previously-
shown data, which demonstrates that a small number
of ASNs is responsible for most persistent, malicious
activity. To discard IPs that have been active for a short
time only, we introduce a threshold δ. IP addresses that
are active less than this threshold are not considered
rogue and discarded from the subsequent malscore
computation. This removes most of the phishing pages
that are hosted on free web spaces or hacked machines,
and legitimate IRC/web servers that are temporarily
abused for botnet communications. As we will explain
later in more detail (in Section 5.2), we do not use
a threshold-based ﬁlter for drive-by-download servers.
The reason is that such servers are difﬁcult to set up,
and thus, are typically a direct indication for rogue
networks. This is also reﬂected in the uptime graph
for drive-by download servers (Figure 3), which is
different than the graphs for the other two data sources.
The output of the ﬁltering step (which removes
short-lived botnet C&C and phishing IPs) is a list of ac-
tive, rogue IPs that constitute the input to the malicious
score computation process, which is discussed in the
next section. In Section 5.2, we will come back to the
effects of selecting different values for the threshold δ
on malscores and ASN ranks.
4.2. Malscore Computation
Once per day, the data collection process produces
three lists Li of active, rogue IPs (each derived from a
different data source i). In the next step, the goal is to
combine this information to expose organizations that
act maliciously. For this, we consider an organization
to be equivalent with an autonomous system (AS).
An autonomous system is a group of a single entity
(RFC 1771). Thus, it is a natural choice to perform
analysis at the AS-level.
To identify those autonomous systems that are most
likely malicious, we ﬁrst map all IP addresses on the
three lists to their corresponding ASN. For this, we
query the whois database, selecting the most speciﬁc
entry for an IP address in case multiple autonomous
systems announce a particular IP. We are aware that
the whois data might not be completely accurate.
However, even in case of small errors, the database
is sufﬁciently complete and precise to recognize the
worst offenders.
A straightforward approach to identify those au-
tonomous systems that are most malicious is to com-
pute, for each AS, the sum of the IPs on the three lists
that belong to this AS. While simple, this technique is
not desirable because it ignores the size of a network.
Clearly, when an AS P controls many more live hosts
than AS Q, we can expect that the absolute number
of malicious hosts in P are higher than in Q, even
though the relative numbers might show the opposite.
To avoid this pitfall, we compute the maliciousness
score (malscore) MA for an AS P as follows:
MP = ρP ∗
3
X
i=1
ni(P )
(1)
In Equation 1, ni(P ) is the number of IP addresses
on list Li that belong to the autonomous system P .
Moreover, the malscore for each AS is adjusted by a
factor ρ, which is indirectly proportional to the number
of hosts in a network. That is, ρ decreases for larger
networks.
The purpose of ρ is to put into relation the number
of incidents with the number of active hosts in an
autonomous system. This requires, for each AS, the
knowledge of the number of live (active) hosts that
235
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:08:56 UTC from IEEE Xplore.  Restrictions apply. 
s
N
S
A
f
o
r
e
b
m
u
N
104
103
102
101
100
Average Uptime of Malicious Activity by ASN
Botnet IP Address Uptimes
s
P
I
f
o
r
e
b
m
u
N
140
120
100
80
60
40
20
0
10
20
30
40
50
60
Number of Days
10
20
30
40
50
60
Number of Days
Figure 1: Average IP uptime by ASN.
Figure 2: Botnet uptime between 0-60 days.
s
P
I
f
o
r
e
b
m
u
N
60
50
40
30
20
10
0
Drive-by-Download IP Address Uptimes
Phish IP Address Uptimes
5000
4000
s
P
I
f
o
r
e
b
m
u
N
3000
2000
1000
0
10
20
30
40
50
60
Number of Days
10
20
30
40
50
60
Number of Days
Figure 3: Drive-by uptime between 0-60 days.
Figure 4: Phishing uptime between 0-60 days.
are operating in the networks of this AS. Clearly, this
knowledge is difﬁcult to obtain precisely, and it also
can change over the course of several months. Previous
work attempted to address this question [20], resorting
to the idea of sending ping probes to a well-chosen
subset of the IP addresses of a network. While these
techniques can discriminate well between completely
inactive (dark) regions and used networks, it is still
quite difﬁcult to determine the exact number of active
hosts. Also, it is possible that networks are conﬁgured
so that they do not respond to ping requests at all,
thereby skewing the results. For these reasons, we
decided to estimate the size of a network based on the
size of the networks (i.e., the number of IP addresses)
that an AS announces as routeable to the global
Internet. To determine the size of the address space
that an AS announces to the Internet, we leverage data
provided by the Cooperative Association for Internet
Data Analysis (CAIDA). CAIDA is a collaborative
undertaking among organizations in the commercial,
government, and research sectors that promotes coop-
eration in the engineering and maintenance of a robust,
scalable, global Internet. In this role, CAIDA makes
available a variety of data repositories that provide
up-to-date measurements of the Internet infrastructure.
One of these data repositories [14] shows a ranking
of autonomous systems based on the size of their
customer cones (address spaces). This information is
compiled from RouteViews BGP tables.
We deﬁne sizep as the number of /20 preﬁxes that
an AS P announces. With this, we deﬁne ρ as shown in
Equation 2 below. As desired, ρ decreases when sizep
increases.
ρp = 2−sizep/c, where c = 4
(2)
Of course, we are aware of the fact that the an-
nounced address space is not a perfectly reliable in-
dicator for the number of active hosts. For example,
there are network telescopes or educational institutions
such as MIT that announce huge address ranges while
having few or no live hosts. However, such networks
are infrequent and, given the shortage of available
IPv4 address space, many networks densely populate
their available space. On the other hand, masquerading
(network address translation - NAT) might result in
multiple hosts sharing a singe IP address. Because
of the imprecision that is inherent in estimating the
number of active hosts, we limit the impact of size
on ρ by a parameter c. Empirically, we found that a
value of c = 4 yields good results. In Section 5.2,
we motivate this choice and discuss the inﬂuence of
different values of c on our results.
5. Evaluation
In this section, we analyze the quality of our results.
Moreover, we discuss in more detail the choice of im-
236
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:08:56 UTC from IEEE Xplore.  Restrictions apply. 
portant system parameters (such as the time threshold
δ and size parameter c).
which is believed to be run by the same criminals that
operated the Russian Business Network.
5.1. Analysis Results and Malicious Networks
Table 1 shows a snapshot of our system on June 1st,
2009, listing the ten entries with the largest malscores
and the originating country (using the ip2location.com
database). For this snapshot, we computed the mali-
ciousness scores for all 417 autonomous systems that
control at least one active, rogue IP.
Unfortunately, we do not have ground truth available
that would allows us to evaluate the results of our sys-
tem in a quantitative fashion. In fact, if such informa-
tion would be available, then there would be no need
for our system. Thus, we can only argue qualitatively
that our system produces meaningful and interesting
insights into the behavior of rogue networks.
Correctness of results. The top ten autonomous sys-
tems reported by FIRE on June 1st host a large number
of persistent, malicious servers. In an attempt to con-
ﬁrm that our results are correct and meaningful, we
leveraged a number of third party efforts that attempt
to track down certain types of malicious activity on
the Internet. More precisely, we ﬁrst obtained a top-25
list, complied by the ShadowServer Foundation [22],
that shows the most malicious networks with regards
to botnet activity. Then, we looked at Google’s Safe
Browsing initiative [15] and extracted the top 150
ASNs, based on the absolute numbers of malicious
drive-by servers that Google identiﬁed. In addition, we
used the top-10 entries provided by ZeusTracker [26],
a network that monitors and lists command and control
servers for the Zeus botnet. Finally, we searched a
number of blogs written by well-known security re-
searchers for references to malicious and rogue ISPs
and networks.
For each of our top ten entries, we then tried to
ﬁnd evidence in any of the third party lists that would
conﬁrm that a network is known to be rogue, or at least,
strongly linked to certain malicious activities. Table 1
shows that we were successful for all ten entries.
In our list, IPNAP-ES (GigeNET) has consistently
ranked among the top malicious networks, because it
hosts the largest numbers of IRC botnet C&C servers.
This is conﬁrmed by the ﬁndings of ShadowServer.
Some security forums have actually reported botnet
activity from IPNAP as early as 2006. The Petersburg
Internet Network (PIN), currently ranked second in
Table 1, is known to be hosting the Zeus malware kit
(also known as Zbot and WSNPoem).
It is also interesting to note that the “Novikov Alek-
sandr Leonidovich” AS has been linked to the recent
Beladen drive-by-download exploit campaign [12],
Completeness of results. In addition to checking our
own top entries and comparing them to information
from third parties, we also decided to analyze the
top entries that these third parties have listed. This
might allow us to ﬁnd malicious networks that our
analysis missed. In many cases, we found that ma-
licious networks in those lists were also identiﬁed
and prominently listed by FIRE (although, of course,
not always in the top ten). This is especially true for
Google’s Safe Browsing list.
For the remaining entries that did not overlap with
our results, we found that they mainly ﬁt into two
categories. In the ﬁrst category, we ﬁnd many large
networks that were given an unfair bias in these lists
due to the number of compromised hosts on their
network. This includes large ISPs such as Cogent.
We tagged these large networks with an X in each
table to show that they are likely false positives. The
second category consists of reputable networks that
provide web and IRC hosting services (e.g., EUnet
Finland hosts an IRC server for EFnet or FDCservers)
with very short-lived malicious servers. That is, these
networks just happen to be listed because they were
under attack on a certain day, but they drop out quickly
once the hosts or services are cleaned up. Thus, we
believe that our results clearly show the importance
of ﬁltering ASNs by size and IP address longevity
to accurately identify rogue networks while removing
false positives.
5.2. Sensitivity of Important Parameters
Longevity thresholds. To distinguish between rogue
and benign networks, FIRE uses thresholds δ based
on the longevity of a malicious server. If a malicious
host is online/active longer than this threshold, the IP is
considered malicious. If a host is taken ofﬂine before it
reaches the threshold, FIRE discards the corresponding
IP for the malscore computation. The choices of the
thresholds is thus important for the correctness of
the analysis. If a threshold is selected too low, many
compromised (but benign) hosts would be considered
part of malicious networks. If the threshold is chosen
too high, true malicious servers will be missed.
To quantify the inﬂuence of different thresholds on
the results produced by FIRE, we introduce a simple
distance metric between two rankings (i.e., lists of
malicious networks sorted by malscore). This metric
works by computing the edit distance between the two
rankings A and B; that is, the distance between A and
B is the number of insertions and deletions of ASNs
that are needed to “convert” the ranking A into B.
237
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:08:56 UTC from IEEE Xplore.  Restrictions apply. 
Rank
1
2
3
4
5
6
7
8
9
10
ASN
AS23522
AS44050
AS3595
AS41665
AS8206
AS48031
AS16265
AS27715
AS22576
AS16276
Name
GigeNET
Petersburg Internet Network
Global Net Access
National Hosting Provider
JUNIKNET
Novikov Aleksandr Leonidovich
LEASEWEB
LocaWeb Ltda
Layered Technologies
OVH OVH
Country
US
UK
US
ES
LV
UA
NL
BR
US
FR
Score
42.4
28.0
18.2
16.5
14.1
14.0
13.0
11.6
11.5
10.6
ShadowServer
Google
ZeusTracker
Blogs
1
-
-
-
-
-
24
-
-
25
-
-
23
104
30
-
14
130
64