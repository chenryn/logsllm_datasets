⊲ Clip each dimension of g(𝑖) so that −𝑐 ≤ g
(𝑖)
𝑗 ≤ 𝑐.
⊲ gradient normalization to (-1, 1)
⊲ initialization of the compressed sparse gradient vector
3: g
˜g(𝑖) ← 0
(𝑖)
𝑗 = min(max(g
4: ˆg(𝑖) ← g(𝑖)/(cid:13)(cid:13)g(𝑖)(cid:13)(cid:13)∞
 1,
˜𝑔(𝑖)
𝑗 =
8: end for
9: Return: ˜g(𝑖)
7:
5:
6: for each top-𝑘 index 𝑗 in h(𝑖) do
with probability 1+ ˆ𝑔(𝑖)
−1, with probability 1− ˆ𝑔(𝑖)
2
2
𝑗
𝑗
on the compressed teachers’ gradient vectors. Specifically, we want
to guarantee that the change of any teacher gradient vector will
not considerably shift the output distribution of the aggregation.
Algorithm 3 presents the aggregation algorithm.
After compression, each gradient vector is a sparse sign vector
with 𝑘 nonzero entries. Therefore, we propose a novel algorithm
that converts gradient aggregation into a voting problem. Specif-
ically, the gradient signs can be viewed as votes for the gradient
directions. Each teacher can vote for 𝑘 gradient dimensions. For
each dimension in the top-𝑘 selection, they vote either the positive
direction (i.e., ˜𝑔𝑗 = 1) or the negative direction (i.e., ˜𝑔𝑗 = −1).
We apply Gaussian mechanism [41] with post-processing thresh-
olding to aggregate the gradient votes. First, we take the sum of the
gradient vectors and inject Gaussian noise following distribution
N(0, 𝜎2). Then, we check whether the noisy vote for each gradi-
ent direction is greater than a threshold. This thresholding step
guarantees that we only select the gradient directions with high
agreement rate among the teacher models. To reach an agreement,
the following two conditions need to be satisfied. First, the gradi-
ent dimension is ranked as top-𝑘 for the majority of the teachers.
Second, these teachers also agree on the sign of the gradients along
these dimensions. With thresholding, we remove the influence of
outliers among the teachers. Intuitively, since the selected direc-
tions have higher votes, they are unlikely to be changed by the DP
noise injection mechanism to preserve utility.
In particular, the Top-𝑘 stochastic sign gradient quantization
and DP gradient aggregation approaches together form a novel DP
gradient compression and aggregation algorithm TopAgg (Algo-
rithm 3), which serves as a key building block in DataLens. These
joint operators are the first time to be adopted in a data generated
model, and we will provide the convergence analysis for these joint
operators in Section 4.3.
4.2 Differential Privacy Analysis for DataLens
In this section, we analyze the differential privacy bound for the pro-
posed DataLens framework, and we leverage the Rényi differential
privacy in our analysis. We also compare the data-dependent pri-
vacy bound and the data-independent privacy bound, and we show
Algorithm 3 - Differentially Private Gradient Compression
and Aggregation (TopAgg). This algorithm takes gradients of
teacher models and returns the compressed and aggregated differ-
entially private gradient vector.
1: Input: Teacher number 𝑁 , gradient vectors of teacher models G =
{g(1) , . . . , g(𝑁 ) }, gradient clipping constant 𝑐, top-𝑘, noise parameters
𝜎, voting threshold 𝛽
˜g(𝑖) ← TopkStoSignGrad(g(𝑖) , 𝑐, 𝑘)
2: ⊲ Phase I: Gradient Compression
3: for each teacher’s gradient g(𝑖) do
4:
5: end for
6: ⊲ Phase II: Differential Private Gradient Aggregation
7:
8: ⊲ Phase III: Gradient Thresholding (Post-Processing)
𝑗 of ˜g∗ do
9: for each dimension ˜𝑔∗
𝑗 ≥ 𝛽𝑁 ;
˜𝑔∗
𝑗 ≤ −𝛽𝑁 ;
˜𝑔∗
˜g∗ ←𝑁
 1,
if
if
otherwise.
𝑖=1 ˜g(𝑖) + N(0, 𝜎2)
−1,
0,
¯𝑔𝑗 =
10:
11: end for
12: Return: ¯g
the data-independent one is more suitable for analyzing DataLens.
Rényi Differential Privacy. We utilize Rényi Differential Privacy
(RDP) to perform the privacy analysis since it supports a tighter
composition of privacy budget and can be applied to both data-
independent and data-dependent settings. First, we review the defi-
nition of RDP and its connection to DP.
Definition 2 ((𝜆, 𝛼)-RDP [41]). A randomized mechanism M is
said to guarantee (𝜆, 𝛼)-RDP with 𝜆 > 1 if for any neighboring
datasets 𝐷 and 𝐷′,
𝐷𝜆(cid:0)M(𝐷) ∥M(cid:0)𝐷′(cid:1)(cid:1) =
1
𝜆 − 1 log E𝑥∼M(𝐷)
(cid:34)(cid:18) Pr[M(𝐷) = 𝑥]
Pr [M (𝐷′) = 𝑥]
(cid:19)𝜆−1(cid:35)
≤ 𝛼 .
For any given probability 𝛿 > 0, (𝜆, 𝛼)-RDP implies (𝜀𝛿, 𝛿)-
differential privacy with 𝜀𝛿 bounded by the following theorem. The
definition of neighboring dataset in this work follows the standard
definition used in PATE framework [43] and DP-SGD framework [2].
As noted in Abadi et al. [2], the neighboring datasets would differ
in a single entry, that is, one image instance is present or absent in
one dataset compared with the other taking image as an example.
Theorem 1 (From RDP to DP [41]). If a mechanism M guarantees
(𝜆, 𝛼)-RDP, then M guarantees (𝛼 + log 1/𝛿
𝜆−1 , 𝛿)-differential privacy
for any 𝛿 ∈ (0, 1).
In the remaining of this section, we first use RDP to analyze the
privacy bound of DataLens, and then derive the final DP bound
in Theorem 3. We will first analyze the data-independent and data-
dependent privacy bounds.
Data-Independent Privacy Bound. In our PATE based data gen-
erative framework, the teacher discriminators have access to the
sensitive training data and the student generator learns about the
sensitive data from the teachers through the gradient aggregation
algorithm. Therefore, if the gradient aggregation algorithm pre-
serves DP or RDP, the same privacy guarantee applies to the student
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2151𝑁
0, 𝜎2(cid:17)
𝑖=1
generator based on the post-processing theorems. Hence, we fo-
cus on deriving the privacy bound for the gradient aggregation
algorithm (TopAgg).
˜G = ( ˜g(1), . . . , ˜g(𝑁)) be the set of compressed teacher gra-
dient vectors, where ˜g(𝑖) is the compressed gradient of the 𝑖-th
teacher. We define sum aggregation function
Let
𝑓s𝑢𝑚( ˜G) =
˜g(𝑖) ,
and, by applying Gaussian mechanism, we have
˜G𝜎 𝑓s𝑢𝑚( ˜G) = 𝑓s𝑢𝑚( ˜G) + N(cid:16)
˜g + N(cid:16)
0, 𝜎2(cid:17) .

˜g∈ ˜G
=
For any real-valued function 𝑓 , the Gaussian mechanism provides
the following RDP guarantee:
Theorem 2 (RDP Guarantee for Gaussian Mechanism [41]).
If
𝑓 has ℓ2-sensitivity 𝑠, then the Gaussian mechanism G𝜎 𝑓 satisfies
(cid:0)𝜆, 𝑠2𝜆/(cid:0)2𝜎2(cid:1)(cid:1)-RDP.
Thus, to calculate the RDP guarantee for ˜G𝜎 𝑓s𝑢𝑚( ˜G), we first
need to calculate the ℓ2 sensitivity [16] of the aggregation algorithm.
Lemma 1. For any neighboring top-𝑘 gradient vector sets ˜G,
˜G′
differing by the gradient vector of one teacher, the ℓ2 sensitivity for
√
𝑘.
𝑓s𝑢𝑚 is 2
√
22𝑘 = 2
Proof. The ℓ2 sensitivity is the maximum change in ℓ2 norm
caused by the input change. For each of the top-𝑘 dimension, a
teacher could take one of the following two changes: (1) vote for
the opposite direction, which flips the gradient sign of one entry; (2)
vote for a different dimension, which reduces the vote of one entry
√
and increases the vote on another. The former changes ℓ2 norm by
2. In the worst case, the teacher flips all the
2, and the latter by
√
𝑘. □
top-𝑘 gradient signs, the change in ℓ2 norm equals
Theorem 3. The TopAgg algorithm (Algorithm 3) guarantees ( 2𝑘𝜆
𝜎2 +
log 1/𝛿
𝜆−1 , 𝛿)-differential privacy for all 𝜆 ≥ 1 and 𝛿 ∈ (0, 1).
Proof. The DPTopkAgg algorithm can be decomposed into ap-
plying gradient thresholding on the output of the sum aggregation
Gaussian mechanism G𝜎 𝑓s𝑢𝑚. G𝜎 𝑓s𝑢𝑚 guarantees (𝜆, 2𝑘𝜆/𝜎2)-RDP
(Lemma 1 & Theorem 2), and thus this theorem is the result of ap-
plying the post-processing theorem of RDP and Theorem 1.
□
Data-Dependent Privacy Bound. The parameters 𝜀 in Definition 1
and 𝛼 in Definition 2 are called the privacy budget of a randomized
mechanism. When 𝜀 and 𝛼 are dependent of the input dataset 𝐷,
the privacy bound is data-dependent. In the following section, we
compare the data-independent privacy bound in Theorem 3 with
a data-dependent privacy bound proposed by Papernot et al. [44].
We prove that, when the algorithm has high dimensional outputs,
the data-independent privacy bound (Theorem 3) is tighter and
achieves better utility.
First, we revisit the data-dependent RDP bound for randomized
algorithms [44]:
Theorem 4 (Data-Dependent RDP Bound [44]). Let M be a ran-
domized algorithm with (𝜇1, 𝛼1)−RDP and (𝜇2, 𝛼2)−RDP guarantees
and suppose that there exists a likely outcome ¯g∗ given a dataset 𝐷
and a bound ˜𝑞 ≤ 1 such that ˜𝑞 ≥ Pr [M(𝐷) ≠ ¯g∗]. Additionally,
suppose that 𝜆 ≤ 𝜇1 and ˜𝑞 ≤ 𝑒(𝜇2−1)𝛼2/(cid:16) 𝜇1
𝐷𝜆(cid:0)M(𝐷) ∥M(cid:0)𝐷′(cid:1)(cid:1) ≤
any neighboring dataset 𝐷′ of 𝐷, we have:
1
𝜆 − 1 log
(cid:17) 𝜇2. Then, for
𝜇1−1 ·
𝜇2
𝜇2−1
(cid:16)(1 − ˜𝑞) · 𝑨 ( ˜𝑞, 𝜇2, 𝛼2)𝜆−1
+ ˜𝑞 · 𝑩 ( ˜𝑞, 𝜇1, 𝛼1)𝜆−1(cid:17) ,
(cid:19)
(cid:18)
where
𝑨 ( ˜𝑞, 𝜇2, 𝛼2) ≜ (1− ˜𝑞)/
1 − ( ˜𝑞𝑒𝛼2) 𝜇2−1
𝜇2
,
𝑩 ( ˜𝑞, 𝜇1, 𝛼1) ≜ 𝑒𝛼1/ ˜𝑞
1
𝜇1−1 .
The parameters 𝜇1 and 𝜇2 are optimized to get a data-dependent
RDP guarantee for any order 𝜆.
The above data-dependent RDP bound is tighter than the data-
independent bound in Theorem 3 when ˜𝑞 ≪ 1. Since ˜𝑞 ≥ Pr [M(𝐷)
≠ ¯g∗], the data-dependent bound improves upon the data-independent
bound only when the algorithm’s output distribution peaks at a
likely outcome ¯g∗. Papernot et al. [44] demonstrated that the data-
dependent privacy bound improves the utility of the PATE frame-
work when teachers vote on one-dimensional predictions. However,
we observe that this bound does not always guarantee a better util-
ity for algorithms with high dimensional outputs. Specifically, with
the increase of the output dimensionality, there is a diminishing
benefit from using the data-dependent privacy bound in Theorem 4.
Below, we demonstrate the observation that the data-independent
privacy bound can achieve better utility with the aggregation and
thresholding steps in TopAgg. Let M( ˜G, 𝑁 , 𝛽) represent the compo-
sition of these two steps, where ˜G is the compressed gradient vector
set, 𝑁 is the number of teachers, and 𝛽 is the voting threshold.
Theorem 5. For any ¯g∗ ∈ {0, 1}𝑑 , we have
1 − Φ
Pr[M( ˜G, 𝑁 , 𝛽) ≠ ¯g∗] = 1 − 

(cid:18) 𝛽𝑁 − 𝑓𝑗
(cid:19) 
(cid:18)
(cid:18) 𝛽𝑁 − 𝑓𝑗
(cid:18) 𝛽𝑁 − 𝑓𝑗
(cid:19)(cid:19)
(cid:19)
{ 𝑗| ¯𝑔∗
𝑗 =1}
𝜎
Φ
{ 𝑗| ¯𝑔∗
𝑗 =−1}
𝜎
{ 𝑗| ¯𝑔∗
𝑗 =0}
erf
√
2𝜎
where Φ is the cumulative distribution function of the normal distri-
bution, erf is the error function, and 𝑓𝑗 is the 𝑗-th dimension of the
gradient vector sum𝑁
𝑖=1 ˜g(𝑖) without the noise injection.
Theorem 5 shows that the bound ˜𝑞 ≥ Pr[M( ˜G, 𝑁 , 𝛽) ≠ ¯g∗]
increases with the increasing output dimensionality of M. Since
the Gaussian mechanism adds independent Gaussian noise along
each dimension, this noise flattens out the probability distribution
around the likely outcome ¯g∗, and consequently reduces the peak
probability for Pr[M( ˜G, 𝑁 , 𝛽) = ¯g∗]. Therefore, when M has a
high dimensional output, it is very unlikely for the distribution
of the algorithm’s output to have a spike at any certain point (i.e.
˜𝑞 ≪ 1). Since the data-dependent privacy bound improves upon
the data-independent bound only when ˜𝑞 ≪ 1, it is unlikely to
benefit algorithms with high-dimensional output. Based on this
understanding, we use Theorem 3 (the data-independent privacy
bound) for the privacy analysis in DataLens. We also provide
empirical evaluation of the data-dependent and data-independent
privacy bounds in Figure 2 in Section 5.3.
4.3 Convergence Analysis of TopAgg
Why does top-𝑘 and sign compression help the DP data generation
process? In this section, we provide theoretical analysis on the