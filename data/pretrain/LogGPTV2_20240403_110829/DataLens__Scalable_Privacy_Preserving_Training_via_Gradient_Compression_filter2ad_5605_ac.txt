âŠ² Clip each dimension of g(ğ‘–) so that âˆ’ğ‘ â‰¤ g
(ğ‘–)
ğ‘— â‰¤ ğ‘.
âŠ² gradient normalization to (-1, 1)
âŠ² initialization of the compressed sparse gradient vector
3: g
Ëœg(ğ‘–) â† 0
(ğ‘–)
ğ‘— = min(max(g
4: Ë†g(ğ‘–) â† g(ğ‘–)/(cid:13)(cid:13)g(ğ‘–)(cid:13)(cid:13)âˆ
 1,
Ëœğ‘”(ğ‘–)
ğ‘— =
8: end for
9: Return: Ëœg(ğ‘–)
7:
5:
6: for each top-ğ‘˜ index ğ‘— in h(ğ‘–) do
with probability 1+ Ë†ğ‘”(ğ‘–)
âˆ’1, with probability 1âˆ’ Ë†ğ‘”(ğ‘–)
2
2
ğ‘—
ğ‘—
on the compressed teachersâ€™ gradient vectors. Specifically, we want
to guarantee that the change of any teacher gradient vector will
not considerably shift the output distribution of the aggregation.
Algorithm 3 presents the aggregation algorithm.
After compression, each gradient vector is a sparse sign vector
with ğ‘˜ nonzero entries. Therefore, we propose a novel algorithm
that converts gradient aggregation into a voting problem. Specif-
ically, the gradient signs can be viewed as votes for the gradient
directions. Each teacher can vote for ğ‘˜ gradient dimensions. For
each dimension in the top-ğ‘˜ selection, they vote either the positive
direction (i.e., Ëœğ‘”ğ‘— = 1) or the negative direction (i.e., Ëœğ‘”ğ‘— = âˆ’1).
We apply Gaussian mechanism [41] with post-processing thresh-
olding to aggregate the gradient votes. First, we take the sum of the
gradient vectors and inject Gaussian noise following distribution
N(0, ğœ2). Then, we check whether the noisy vote for each gradi-
ent direction is greater than a threshold. This thresholding step
guarantees that we only select the gradient directions with high
agreement rate among the teacher models. To reach an agreement,
the following two conditions need to be satisfied. First, the gradi-
ent dimension is ranked as top-ğ‘˜ for the majority of the teachers.
Second, these teachers also agree on the sign of the gradients along
these dimensions. With thresholding, we remove the influence of
outliers among the teachers. Intuitively, since the selected direc-
tions have higher votes, they are unlikely to be changed by the DP
noise injection mechanism to preserve utility.
In particular, the Top-ğ‘˜ stochastic sign gradient quantization
and DP gradient aggregation approaches together form a novel DP
gradient compression and aggregation algorithm TopAgg (Algo-
rithm 3), which serves as a key building block in DataLens. These
joint operators are the first time to be adopted in a data generated
model, and we will provide the convergence analysis for these joint
operators in Section 4.3.
4.2 Differential Privacy Analysis for DataLens
In this section, we analyze the differential privacy bound for the pro-
posed DataLens framework, and we leverage the RÃ©nyi differential
privacy in our analysis. We also compare the data-dependent pri-
vacy bound and the data-independent privacy bound, and we show
Algorithm 3 - Differentially Private Gradient Compression
and Aggregation (TopAgg). This algorithm takes gradients of
teacher models and returns the compressed and aggregated differ-
entially private gradient vector.
1: Input: Teacher number ğ‘ , gradient vectors of teacher models G =
{g(1) , . . . , g(ğ‘ ) }, gradient clipping constant ğ‘, top-ğ‘˜, noise parameters
ğœ, voting threshold ğ›½
Ëœg(ğ‘–) â† TopkStoSignGrad(g(ğ‘–) , ğ‘, ğ‘˜)
2: âŠ² Phase I: Gradient Compression
3: for each teacherâ€™s gradient g(ğ‘–) do
4:
5: end for
6: âŠ² Phase II: Differential Private Gradient Aggregation
7:
8: âŠ² Phase III: Gradient Thresholding (Post-Processing)
ğ‘— of Ëœgâˆ— do
9: for each dimension Ëœğ‘”âˆ—
ğ‘— â‰¥ ğ›½ğ‘ ;
Ëœğ‘”âˆ—
ğ‘— â‰¤ âˆ’ğ›½ğ‘ ;
Ëœğ‘”âˆ—
Ëœgâˆ— â†ğ‘
 1,
if
if
otherwise.
ğ‘–=1 Ëœg(ğ‘–) + N(0, ğœ2)
âˆ’1,
0,
Â¯ğ‘”ğ‘— =
10:
11: end for
12: Return: Â¯g
the data-independent one is more suitable for analyzing DataLens.
RÃ©nyi Differential Privacy. We utilize RÃ©nyi Differential Privacy
(RDP) to perform the privacy analysis since it supports a tighter
composition of privacy budget and can be applied to both data-
independent and data-dependent settings. First, we review the defi-
nition of RDP and its connection to DP.
Definition 2 ((ğœ†, ğ›¼)-RDP [41]). A randomized mechanism M is
said to guarantee (ğœ†, ğ›¼)-RDP with ğœ† > 1 if for any neighboring
datasets ğ· and ğ·â€²,
ğ·ğœ†(cid:0)M(ğ·) âˆ¥M(cid:0)ğ·â€²(cid:1)(cid:1) =
1
ğœ† âˆ’ 1 log Eğ‘¥âˆ¼M(ğ·)
(cid:34)(cid:18) Pr[M(ğ·) = ğ‘¥]
Pr [M (ğ·â€²) = ğ‘¥]
(cid:19)ğœ†âˆ’1(cid:35)
â‰¤ ğ›¼ .
For any given probability ğ›¿ > 0, (ğœ†, ğ›¼)-RDP implies (ğœ€ğ›¿, ğ›¿)-
differential privacy with ğœ€ğ›¿ bounded by the following theorem. The
definition of neighboring dataset in this work follows the standard
definition used in PATE framework [43] and DP-SGD framework [2].
As noted in Abadi et al. [2], the neighboring datasets would differ
in a single entry, that is, one image instance is present or absent in
one dataset compared with the other taking image as an example.
Theorem 1 (From RDP to DP [41]). If a mechanism M guarantees
(ğœ†, ğ›¼)-RDP, then M guarantees (ğ›¼ + log 1/ğ›¿
ğœ†âˆ’1 , ğ›¿)-differential privacy
for any ğ›¿ âˆˆ (0, 1).
In the remaining of this section, we first use RDP to analyze the
privacy bound of DataLens, and then derive the final DP bound
in Theorem 3. We will first analyze the data-independent and data-
dependent privacy bounds.
Data-Independent Privacy Bound. In our PATE based data gen-
erative framework, the teacher discriminators have access to the
sensitive training data and the student generator learns about the
sensitive data from the teachers through the gradient aggregation
algorithm. Therefore, if the gradient aggregation algorithm pre-
serves DP or RDP, the same privacy guarantee applies to the student
Session 7A: Privacy Attacks and Defenses for ML CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea2151ğ‘
0, ğœ2(cid:17)
ğ‘–=1
generator based on the post-processing theorems. Hence, we fo-
cus on deriving the privacy bound for the gradient aggregation
algorithm (TopAgg).
ËœG = ( Ëœg(1), . . . , Ëœg(ğ‘)) be the set of compressed teacher gra-
dient vectors, where Ëœg(ğ‘–) is the compressed gradient of the ğ‘–-th
teacher. We define sum aggregation function
Let
ğ‘“sğ‘¢ğ‘š( ËœG) =
Ëœg(ğ‘–) ,
and, by applying Gaussian mechanism, we have
ËœGğœ ğ‘“sğ‘¢ğ‘š( ËœG) = ğ‘“sğ‘¢ğ‘š( ËœG) + N(cid:16)
Ëœg + N(cid:16)
0, ğœ2(cid:17) .

Ëœgâˆˆ ËœG
=
For any real-valued function ğ‘“ , the Gaussian mechanism provides
the following RDP guarantee:
Theorem 2 (RDP Guarantee for Gaussian Mechanism [41]).
If
ğ‘“ has â„“2-sensitivity ğ‘ , then the Gaussian mechanism Gğœ ğ‘“ satisfies
(cid:0)ğœ†, ğ‘ 2ğœ†/(cid:0)2ğœ2(cid:1)(cid:1)-RDP.
Thus, to calculate the RDP guarantee for ËœGğœ ğ‘“sğ‘¢ğ‘š( ËœG), we first
need to calculate the â„“2 sensitivity [16] of the aggregation algorithm.
Lemma 1. For any neighboring top-ğ‘˜ gradient vector sets ËœG,
ËœGâ€²
differing by the gradient vector of one teacher, the â„“2 sensitivity for
âˆš
ğ‘˜.
ğ‘“sğ‘¢ğ‘š is 2
âˆš
22ğ‘˜ = 2
Proof. The â„“2 sensitivity is the maximum change in â„“2 norm
caused by the input change. For each of the top-ğ‘˜ dimension, a
teacher could take one of the following two changes: (1) vote for
the opposite direction, which flips the gradient sign of one entry; (2)
vote for a different dimension, which reduces the vote of one entry
âˆš
and increases the vote on another. The former changes â„“2 norm by
2. In the worst case, the teacher flips all the
2, and the latter by
âˆš
ğ‘˜. â–¡
top-ğ‘˜ gradient signs, the change in â„“2 norm equals
Theorem 3. The TopAgg algorithm (Algorithm 3) guarantees ( 2ğ‘˜ğœ†
ğœ2 +
log 1/ğ›¿
ğœ†âˆ’1 , ğ›¿)-differential privacy for all ğœ† â‰¥ 1 and ğ›¿ âˆˆ (0, 1).
Proof. The DPTopkAgg algorithm can be decomposed into ap-
plying gradient thresholding on the output of the sum aggregation
Gaussian mechanism Gğœ ğ‘“sğ‘¢ğ‘š. Gğœ ğ‘“sğ‘¢ğ‘š guarantees (ğœ†, 2ğ‘˜ğœ†/ğœ2)-RDP
(Lemma 1 & Theorem 2), and thus this theorem is the result of ap-
plying the post-processing theorem of RDP and Theorem 1.
â–¡
Data-Dependent Privacy Bound. The parameters ğœ€ in Definition 1
and ğ›¼ in Definition 2 are called the privacy budget of a randomized
mechanism. When ğœ€ and ğ›¼ are dependent of the input dataset ğ·,
the privacy bound is data-dependent. In the following section, we
compare the data-independent privacy bound in Theorem 3 with
a data-dependent privacy bound proposed by Papernot et al. [44].
We prove that, when the algorithm has high dimensional outputs,
the data-independent privacy bound (Theorem 3) is tighter and
achieves better utility.
First, we revisit the data-dependent RDP bound for randomized
algorithms [44]:
Theorem 4 (Data-Dependent RDP Bound [44]). Let M be a ran-
domized algorithm with (ğœ‡1, ğ›¼1)âˆ’RDP and (ğœ‡2, ğ›¼2)âˆ’RDP guarantees
and suppose that there exists a likely outcome Â¯gâˆ— given a dataset ğ·
and a bound Ëœğ‘ â‰¤ 1 such that Ëœğ‘ â‰¥ Pr [M(ğ·) â‰  Â¯gâˆ—]. Additionally,
suppose that ğœ† â‰¤ ğœ‡1 and Ëœğ‘ â‰¤ ğ‘’(ğœ‡2âˆ’1)ğ›¼2/(cid:16) ğœ‡1
ğ·ğœ†(cid:0)M(ğ·) âˆ¥M(cid:0)ğ·â€²(cid:1)(cid:1) â‰¤
any neighboring dataset ğ·â€² of ğ·, we have:
1
ğœ† âˆ’ 1 log
(cid:17) ğœ‡2. Then, for
ğœ‡1âˆ’1 Â·
ğœ‡2
ğœ‡2âˆ’1
(cid:16)(1 âˆ’ Ëœğ‘) Â· ğ‘¨ ( Ëœğ‘, ğœ‡2, ğ›¼2)ğœ†âˆ’1
+ Ëœğ‘ Â· ğ‘© ( Ëœğ‘, ğœ‡1, ğ›¼1)ğœ†âˆ’1(cid:17) ,
(cid:19)
(cid:18)
where
ğ‘¨ ( Ëœğ‘, ğœ‡2, ğ›¼2) â‰œ (1âˆ’ Ëœğ‘)/
1 âˆ’ ( Ëœğ‘ğ‘’ğ›¼2) ğœ‡2âˆ’1
ğœ‡2
,
ğ‘© ( Ëœğ‘, ğœ‡1, ğ›¼1) â‰œ ğ‘’ğ›¼1/ Ëœğ‘
1
ğœ‡1âˆ’1 .
The parameters ğœ‡1 and ğœ‡2 are optimized to get a data-dependent
RDP guarantee for any order ğœ†.
The above data-dependent RDP bound is tighter than the data-
independent bound in Theorem 3 when Ëœğ‘ â‰ª 1. Since Ëœğ‘ â‰¥ Pr [M(ğ·)
â‰  Â¯gâˆ—], the data-dependent bound improves upon the data-independent
bound only when the algorithmâ€™s output distribution peaks at a
likely outcome Â¯gâˆ—. Papernot et al. [44] demonstrated that the data-
dependent privacy bound improves the utility of the PATE frame-
work when teachers vote on one-dimensional predictions. However,
we observe that this bound does not always guarantee a better util-
ity for algorithms with high dimensional outputs. Specifically, with
the increase of the output dimensionality, there is a diminishing
benefit from using the data-dependent privacy bound in Theorem 4.
Below, we demonstrate the observation that the data-independent
privacy bound can achieve better utility with the aggregation and
thresholding steps in TopAgg. Let M( ËœG, ğ‘ , ğ›½) represent the compo-
sition of these two steps, where ËœG is the compressed gradient vector
set, ğ‘ is the number of teachers, and ğ›½ is the voting threshold.
Theorem 5. For any Â¯gâˆ— âˆˆ {0, 1}ğ‘‘ , we have
1 âˆ’ Î¦
Pr[M( ËœG, ğ‘ , ğ›½) â‰  Â¯gâˆ—] = 1 âˆ’ 

(cid:18) ğ›½ğ‘ âˆ’ ğ‘“ğ‘—
(cid:19) 
(cid:18)
(cid:18) ğ›½ğ‘ âˆ’ ğ‘“ğ‘—
(cid:18) ğ›½ğ‘ âˆ’ ğ‘“ğ‘—
(cid:19)(cid:19)
(cid:19)
{ ğ‘—| Â¯ğ‘”âˆ—
ğ‘— =1}
ğœ
Î¦
{ ğ‘—| Â¯ğ‘”âˆ—
ğ‘— =âˆ’1}
ğœ
{ ğ‘—| Â¯ğ‘”âˆ—
ğ‘— =0}
erf
âˆš
2ğœ
where Î¦ is the cumulative distribution function of the normal distri-
bution, erf is the error function, and ğ‘“ğ‘— is the ğ‘—-th dimension of the
gradient vector sumğ‘
ğ‘–=1 Ëœg(ğ‘–) without the noise injection.
Theorem 5 shows that the bound Ëœğ‘ â‰¥ Pr[M( ËœG, ğ‘ , ğ›½) â‰  Â¯gâˆ—]
increases with the increasing output dimensionality of M. Since
the Gaussian mechanism adds independent Gaussian noise along
each dimension, this noise flattens out the probability distribution
around the likely outcome Â¯gâˆ—, and consequently reduces the peak
probability for Pr[M( ËœG, ğ‘ , ğ›½) = Â¯gâˆ—]. Therefore, when M has a
high dimensional output, it is very unlikely for the distribution
of the algorithmâ€™s output to have a spike at any certain point (i.e.
Ëœğ‘ â‰ª 1). Since the data-dependent privacy bound improves upon
the data-independent bound only when Ëœğ‘ â‰ª 1, it is unlikely to
benefit algorithms with high-dimensional output. Based on this
understanding, we use Theorem 3 (the data-independent privacy
bound) for the privacy analysis in DataLens. We also provide
empirical evaluation of the data-dependent and data-independent
privacy bounds in Figure 2 in Section 5.3.
4.3 Convergence Analysis of TopAgg
Why does top-ğ‘˜ and sign compression help the DP data generation
process? In this section, we provide theoretical analysis on the