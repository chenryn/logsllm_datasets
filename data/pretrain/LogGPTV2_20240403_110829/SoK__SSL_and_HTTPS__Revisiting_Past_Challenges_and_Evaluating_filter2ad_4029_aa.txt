# Title: SoK: SSL and HTTPS: Revisiting Past Challenges and Evaluating Certificate Trust Model Enhancements

## Authors
Jeremy Clark and Paul C. van Oorschot  
School of Computer Science, Carleton University, Canada  
{clark, paulv}@scs.carleton.ca

## Abstract
Internet users today rely on HTTPS for secure communication with websites. Over the years, numerous attacks on HTTPS and its certificate trust model have been hypothesized, executed, and evolved. Meanwhile, the number of browser-trusted (and thus, de facto, user-trusted) certificate authorities (CAs) has increased, while the due diligence in baseline certificate issuance has declined. This paper surveys and categorizes prominent security issues with HTTPS, providing a systematic treatment of the history and ongoing challenges to offer context for future directions. We also provide a comparative evaluation of current proposals for enhancing the certificate infrastructure used in practice.

**Keywords:** SSL, certificates, browser trust model, usability

## I. Introduction
Enabling end users to easily communicate sensitive data online was a significant milestone in the development of today’s web and arguably a necessary condition for its explosive growth. The core SSL/TLS technology, little changed since its early days (1994–2000), remains the basis for securing many aspects of the Internet, including software downloads, data transfers, user passwords, and site authentication. While centered on the HTTPS protocol (HTTP over SSL/TLS), its security services—confidentiality, message integrity, and site authentication—fundamentally rely on the correct interplay of out-of-band infrastructures, procedures, and trust decisions.

As the web has evolved from serving static information pages to a platform for billions of dollars of commerce and critical infrastructures, confidence in the HTTPS certificate infrastructure has eroded. This erosion is due to several factors, such as the increasing issuance of server certificates through fully-automated (domain-validated) procedures, the proliferation of CAs, and the compromise of real-world CAs leading to increased concern among security experts about man-in-the-middle (MITM) attacks on HTTPS.

SSL/TLS has evolved in response to the discovery of cryptographic weaknesses and protocol design flaws. However, problems with the certificate model are more challenging, including design and implementation issues in the CA/Browser (CA/B) trust model, leading to fragility (compromise of a single CA can temporarily undermine system-wide security) and lack of trust agility. Other issues include poor support for certificate revocation, reduced CA diligence in certificate issuance, and user interface challenges related to reliably signaling security indicators and site authentication information to end-users.

In this paper, we provide a broad perspective on the TLS mechanism as employed with web browsers for securing HTTP traffic. We consider HTTPS, the underlying CA infrastructure, the CA/B trust model, and proposed enhancements. Our main contributions are:
1. Classifying and contextualizing disparate contributions on HTTPS security, spanning elements of cryptographic design and implementation, systems software, operations, and human factors.
2. Providing a comparative evaluation of existing proposals to enhance the security aspects of the CA/B model, deconstructing and evaluating their core ideas.
3. Summarizing open problems and future research directions based on a systematic review, classification, and analysis of security issues.

## II. Background
### Historical Objectives
SSL was developed to address Netscape’s needs for securing web traffic, specifically designed to work well with HTTP. The primary goals were confidentiality and server authentication, ensuring that sensitive data, like credit card details, are released only to the intended party, i.e., the correct web server. Client authentication was an optional third goal, but it is rarely used on the public internet.

Netscape intended SSL to be a core technology beyond use with HTTP alone, and since most high-runner internet protocols ran over TCP, SSL was designed to provide a general channel that can be adopted with minimal modification by almost any TCP-based protocol seeking some security. An important property was termed transparency: "the data that one end writes is exactly what the other end reads."

### Protocol Specification
HTTPS combines the network protocol HTTP with the cryptographic protocol TLS. TLS (versions 1.0, 1.1, 1.2) updates the older SSL protocol (version 3.0). TLS provides a secure tunnel to a server, which is most commonly authenticated by an X.509 certificate. The specification of the cryptographic primitives used by X.509 is largely delegated to PKCS standards. We do not focus on protocols (e.g., IMAP or SMTP) other than HTTP run over TLS, nor the use of TLS with transport layer protocols other than TCP (e.g., DTLS).

## III. Cryptographic Protocol Issues in HTTPS
In this section, we consider attacks on the TLS protocol that relate to HTTPS security. Section IV expands the focus to the broader CA/B infrastructure and human decisions involved. As TLS is well-documented, we assume familiarity with the basic protocol. Many attacks refine known techniques; examining both historical and recent attacks provides a fuller perspective.

### A. Weaknesses in Cryptographic Primitives
#### 1. Weak Encryption & Signature Key Lengths
Several encryption functions offered in the ciphersuites of early versions of TLS are no longer considered secure. Any symmetric key encryption scheme with 40, 56, or 64-bit keys is subject to brute-force attacks. TLS supported DES, RC2, and RC4 with some of these key lengths. Asymmetric encryption schemes like RSA are subject to factoring attacks when used with a 512-bit modulus. A 2007 analysis of TLS servers found that while only 4% of sites still offered RSA-512, 93% supported (single) DES. Note that supporting an insecure primitive does not imply it is ever used, as security parameters are negotiated (but see Downgrade Attacks below). NIST strongly recommends that primitives hold the equivalent of 112 bits (symmetric) security strength and will require this by 2014 (e.g., phasing out 1024-bit RSA/DSA and 193-bit ECDSA).

Key length is also an issue for certificates. Sufficient key lengths should be used by the CA to sign a certificate, and CAs should only sign certificates containing public keys that are of sufficient length.

#### 2. Weak Hash Functions
To issue a site certificate, CAs sign its hash. Collision resistance of the hash is paramount: an adversary that could construct two meaningful certificates with the same digest could transfer a CA signature from a benign site certificate to a malicious CA certificate. The MD5 hash function, published in 1992, has been eligible for providing certificate digests. However, the collision resistance of MD5 has deteriorated over time, from generic attacks to the first published collision, to the generation of "meaningful" collisions, and finally finding collisions that are structured enough to be both an acceptable benign site certificate and a malicious root certificate. Use of MD5 is discouraged (RFC 3279), and certificates digested with MD5 are in decline. MD5 remains recommended in other places in the TLS protocol where collision resistance of the hash function is not critical, i.e., HMAC and key derivation.

### B. Implementation Flaws and Related Attacks
#### 1. PRNG Seeding
Many values in the TLS protocol are generated randomly, including secret keys. This requires a strong pseudorandom number generator (PRNG), seeded with a high-entropy seed. The Netscape browser (prior to version 1.22) relied on a PRNG implementation with weak keys, allowing the TLS session key (master secret) to be predictable. A 2008 change to the Debian operating system reduced the randomness served to OpenSSL, which was used to generate TLS certificates with predictable private keys. Recently, 0.5% of TLS certificates were found to have recoverable RSA private keys due to shared prime factors, mostly originating from poor PRG seeding in embedded devices.

#### 2. Remote Timing Attacks
Remote timing attacks have been used against TLS servers that use an optimized variant of RSA decryption, the default in OpenSSL versions prior to 0.9.7b. The decryption algorithm makes branching decisions that are functionally dependent on the long-term certified secret key, resulting in measurable differences in execution time, leaking information about the key during TLS handshakes. Previous OpenSSL implementations of ECDSA enabled similar remote timing attacks.

### C. Oracle Attacks
The following attacks interactively and adaptively query the victim’s protocol implementation, treating it as an oracle.

#### 1. RSA Encoding
SSL 3.0 with the RSA ciphersuite uses "textbook" RSA (which enables ciphertext malleability) for transporting a PKCS#1 v1.5 encoded premaster secret to the server during the handshake. If upon decryption and decoding, the plaintext is not properly encoded, an error is returned to the client. An adversary could capture an encrypted premaster secret and, in separate handshakes with the same server, submit adaptively modified versions of it, learning if they are conformant. With just this information, the adversary can eventually (∼1M queries) recover the premaster secret. TLS 1.0 consequently recommends that encoding errors are handled indistinguishably from successful decryptions.

#### 2. CBC Initialization
In TLS 1.0 and earlier, all block ciphers are used in cipher block chaining (CBC) mode. Records are encrypted individually, but the initialization vector for each (except the first) is set equal to the last block of ciphertext sent (i.e., in a predictable way). CBC with predictable IVs is not secure against chosen plaintext attacks, and thus an adversary capable of injecting partial plaintext into a TLS connection and observing the transmitted ciphertext can determine semantic information about the rest of the plaintext. In one instantiation of this attack, BEAST, an adversary submits adaptively chosen cross-site requests for a domain with a secure cookie to learn the value of the cookie (and by adjusting the amount of the value included in a single block, due to partitioning, the value can be guessed byte-by-byte). This issue is resolved in TLS 1.1, not applicable to any stream cipher (e.g., RC4), and is purportedly mitigated by first sending the first byte as a separate record (‘1/n-1 record splitting’).

#### 3. Compression
The use of data compression is a negotiable option in TLS, although it is never broadly supported by browsers. TLS does not obfuscate the length of a compressed TLS record, thus an adversary capable of injecting partial plaintext into a TLS connection and observing the post-compression record length can determine semantic information about the rest of the plaintext. An instantiation of this attack, CRIME, used a similar setup to BEAST for recovering secret values from secure cookies. As a result, all major browsers have disabled TLS compression.

#### 4. CBC Padding
An extended version of this paper [32] discusses oracle attacks on CBC padding, which until very recently [16] applied only to non-HTTPS protocols run over TLS.

### D. Protocol-level Attacks
#### 1. Ciphersuite Downgrade Attack
The ciphersuite used by the client and server is negotiated during the TLS handshake. In SSL 2.0, a man-in-the-middle could influence the negotiation and downgrade the strength of the ciphersuite to the weakest acceptable by both parties. This is fixed in SSL 3.0 and all versions of TLS by having the client send, once the MAC keys have been established, an authenticated digest of the previous handshake messages and waiting for an authenticated confirmation from the server. Thus, downgrade prevention is contingent on the unavailability of weak MAC functions for negotiation.

#### 2. Version Downgrade Attack
The TLS version is also negotiated, and while version downgrade attacks are not possible against a strict implementation of the TLS specification, many client implementations respond to certain server errors by reconnecting with an older TLS version. These server errors can be spoofed by an attacker. To prevent an adversary from first downgrading to SSL 2.0 and then downgrading the ciphersuite, TLS prohibits downgrading to SSL 2.0. TLS implementations may still be vulnerable to downgrades from later versions to earlier versions (e.g., from TLS 1.1+ to TLS 1.0 to exploit CBC initialization vulnerabilities). One mitigation is to include the highest supported version number in the list of ciphersuites during negotiation, extending ciphersuite-downgrade protection to versions.

#### 3. Renegotiation Attack
Once a TLS connection has been established, either party can at any point request a new handshake, within the existing tunnel, to renegotiate the cipher suite, session key, or other relevant connection parameters. The renegotiation protocol was discovered to be flawed in 2009 and was subsequently updated. The erroneous version allowed an adversary to establish a connection to a server, send data, renegotiate, and pass the renegotiated connection onto a client that believes it is forming an initial connection. This effectively allowed the adversary to prepend chosen records to new HTTPS connections. An extension [50] to the standardized countermeasures [1] can provide a strong notion of renegotiation security.

#### 4. Cross-Protocol Attacks
An extended version of this paper [32] addresses cross-protocol attacks where parameters intended to be used in one setting (e.g., Diffie-Hellman) are replayed in a different setting (e.g., RSA).

## IV. Trust Model Issues in HTTPS
Section III narrowly considered attacks on the TLS protocol and the cryptographic algorithms it involves. This section assumes a perfectly functioning TLS protocol and considers attacks on the broader CA/B infrastructure. Our analysis covers the certification process itself, who is allowed to be a certificate authority (anchoring trust), how this authority can be delegated (transitivity of trust), how certificates are revoked (maintenance of trust), and how users interact with certificate information (indication and interpretation of trust). In what follows, we specifically note which issues remain unresolved.