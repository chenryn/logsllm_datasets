participants.
Second, apart from our search queries, our methodology is
passive. All secrets that we collect were already exposed when
we ﬁnd them, thus this research does not create vulnerabilities
where they did not already exist. We took a number of steps
to ensure that our collected secrets are unlikely to leak further.
These include running all experiments from a locked-down
virtual machine and ensuring that no secret data leaves our
collection database. Access to the database is only possible
through public-key-authenticated SSH.
Furthermore, we never attempt to use any of the discovered
secrets other than for the analytics in this paper, even for
innocuous purposes like to merely verify the secret could be
used successfully. This prevents the possibility that a secret
owner might be negatively impacted by our use of such a
secret, for example by causing a billing event or hitting a rate
limit cap. It also prevents us from obtaining any sensitive,
proprietary, or personal information from the secret owner.
Finally, it prevents the remote possibility that a service could
be negatively impacted by our testing.
Finally, as of the camera-ready we are currently working
to notify vulnerable repository owners of our ﬁndings.
V. SECRET LEAKAGE ANALYSIS
In this section, we use our collection of discovered secrets
to characterize how many projects on GitHub are at risk due to
secret exposure. Primarily, our focus is on identifying how many
exposed secrets are truly sensitive—we consider a “sensitive”
secret as one whose leakage is unintentional and discovery
presents security risk to the owner. First, we report high-level
statistics on the large numbers of exposed secrets that we
discovered via both data collection approaches (Section V-A).
Then, we show that most discovered secrets are likely sensitive
through a rigorous manual experiment (Section V-B). Next, we
compare single- and multiple-owner secrets to further conﬁrm
the aforementioned section (Section V-C). We also demonstrate
that ﬁnding one secret can be leveraged to discover other
secrets with high probability (Section V-D). We show many
secrets are very infrequently removed from GitHub and persist
indeﬁnitely (Section V-E). Finally, we focus speciﬁcally on
RSA keys to exemplify how an attacker could abuse exposed
keys (Section V-F).
A. Secret Collection
In this section, we provide high-level statistics on the set
of secrets we discovered. We detail the number of ﬁles at each
step in our collection methodology and culminate in the total
number of unique secrets that we discover. Here, we refer to
a “unique” secret as a secret that appears at least once in the
dataset; note that a unique secret can occur multiple times.
GitHub Search API The GitHub Search API collection
began on October 31, 2017 and ﬁnished on April 20, 2018.
During this period of nearly 6 months, we captured 4,394,476
candidate ﬁles representing 681,784 repos (Phase 1a of Figure
1), from which our distinct secret regular expression scan (Phase
2 of Figure 1) identiﬁed 307,461 ﬁles from 109,278 repos
containing at least one candidate string, giving a ﬁle hit rate
of approximately 7%.
Overall, we identiﬁed 403,258 total and 134,887 unique
candidate strings that matched our regular expressions. In
addition, our search collection collected a median of 4,258
and 1,793 unique candidate secrets per day, with a range from
2,516 to 7,159 total.
As discussed, some of the strings that match the regular
expression could be invalid secrets. We applied our ﬁltering
heuristics to determine the number of valid secrets from
candidate strings (Phase 3 of Figure 1). In total, we found
that 133,934 of the unique candidate strings were valid, giving
an overall accuracy of 99.29% for the distinct signature regular
expressions used in Phase 2.
GitHub BigQuery We performed our query on a single
GitHub weekly BigQuery snapshot on April 4, 2018. We
were able to scan the contents of 2,312,763,353 ﬁles in
3,374,973 repos (Phase 1b of Figure 1). We identiﬁed at
least one regular expression match in 100,179 of these ﬁles
representing 52,117 repos (Phase 2 of Figure 1), giving a ﬁle
hit rate of approximately 0.005% across all open-source GitHub
repositories in BigQuery. Within the ﬁles with matches, we
identiﬁed 172,295 total strings and 73,799 unique strings, of
which 73,079, or 98.93%, were valid (Phase 3 of Figure 1).
Dataset Overlap Some of our secrets may appear in both
datasets since a ﬁle we see via the Search API could be
contained within the BigQuery snapshot, or a secret may simply
be duplicated in different ﬁles. After joining both collections,
we determined that 7,044 secrets, or 3.49% of the total, were
seen in both datasets. This indicates that our approaches are
largely complementary.
Breakdown by Secret Table II breaks down the total
and unique numbers of secrets by distinct secret. The most
commonly leaked were Google API keys. RSA private key
leakage was also common, although leakage of other keys, such
as PGP and EC, was orders of magnitude lower. Many of our
6
TABLE II: The majority of secrets in the combined dataset
are used by a single-owner
Secret
Google API Key
RSA Private Key
Google OAuth ID
General Private Key
Twitter Access Token
EC Private Key
Facebook Access Token
PGP Private Key
MailGun API Key
MailChimp API Key
Stripe Standard API Key
Twilio API Key
Square Access Token
Square OAuth Secret
Amazon AWS Access Key ID
Amazon MWS Auth Token
Braintree Access Token
Picatic API Key
TOTAL
# Total
212,892
158,011
106,909
30,286
26,395
20,760
7,838
6,367
2,091
1,868
871
542
320
121
28
28
24
5
575,456
# Unique % Single-Owner
85,311
37,781
47,814
12,576
4,648
7,935
1,584
1,715
684
742
484
213
50
61
19
13
8
4
95.10%
90.42%
96.67%
88.99%
91.57%
94.83%
74.67%
97.35%
82.58%
94.25%
92.51%
91.87%
90.00%
96.67%
94.74%
100.00%
87.50%
100.00%
93.58%
201,642
API keys had relatively small incidents of leakage, likely due
to lower popularity of those platforms in the type of projects
on GitHub. Most importantly, we were able to identify multiple
secrets for every API we targeted.
B. Manual Review
Throughout this paper, we use statistical approaches and
heuristics to estimate the prevalence of secrets on GitHub. To
validate these results, we carried out a rigorous manual review
on a sample of the dataset. We collected a random sample
of 240 total candidate secrets, evenly split between Amazon
AWS and RSA keys. Two of three raters (all paper co-authors)
examined the ﬁle and repo containing the secret on GitHub’s
website. After considering the context of the secret, the raters
evaluated each secret as sensitive, non-sensitive, indeterminate,
or not a secret. Once every secret was coded, we evaluated the
interrater reliability of the two raters. We found a total of 88.8%
of the judgments were in agreement with a Cohen’s Kappa
of 0.753, lending conﬁdence in the result. All disagreements
were mediated by the third rater, who independently rated each
disagreeing case without knowledge of the prior codings, and
then were settled by group consensus. In the results that follow,
we exclude secrets that could not be determined sensitive or
non-sensitive (5 total) or that were not valid secrets (4 total)2.
We used these ﬁndings to estimate the overall sensitivity
of our entire data. We considered the sensitivity of AWS keys
representative of all API keys and the sensitivity of RSA
keys representative of all asymmetric keys. We then scaled
the percentages determined by the manual review experiment
against the base rate of each sub-type in our dataset. We
estimated that 89.10% of all discovered secrets are sensitive.
If we consider API and asymmetric key secrets separately, we
estimated that 93.74% of API secrets and 76.24% of asymmetric
keys are sensitive. This indicates that most of the discovered
secrets are sensitive and many users are at risk.
2We drew our random selection against non-ﬁltered “candidate” secrets,
so the number of invalid secrets in this sample is not representative of the
effectiveness of our overall analysis pipeline.
7
C. Single- and Multiple-Owner Secrets
The results in Table II show a level of duplication of secrets
within our collection as the number of unique secrets is less
than the number of total secrets. Since we previously deﬁned
a secret as a credential whose privacy must be maintained for
security, we evaluated this duplication to determine whether
it indicated our results were skewed towards non-sensitive
secrets. Intuitively, a secret should be kept private to the single
individual who “owns” it. While it would be a valid use case
to see duplication due to an individual using the same sensitive
secret in multiple ﬁles or repos, it would be unlikely to see
multiple users do so.
To verify this intuition, we further analyzed the results of
the Manual Review experiment from Section V-B. First, we
deﬁned a secret with one owner as a “single-owner secret,”
and a secret with multiple owners as a “multiple-owner secret.”
As we were unable to identify the committer of a secret, and
because our data sources did not easily provide contributor
information3, we considered the repo owner as the entity who
owned the secret. Of the 240 secrets examined, we had also
evenly split the secrets between single- and multiple-owner
secrets, allowing us to examine whether there was a difference
in sensitivity between single- and multiple-owner secrets for
AWS and RSA keys. At a high-level, 91.67% of single-owner
AWS keys were sensitive compared to 66.67% multiple-owner
AWS keys, and respectively 75% versus 38.33% for RSA keys.
For AWS keys, we found a statistically signiﬁcant difference
with a medium effect size (χ2 = 15.2, p  0.56),
and for RSA keys, we found a statistically signiﬁcant difference
with a large effect size (χ2 = 35.7, p  0.56). These
ﬁndings conﬁrmed our assertion that single-owner secrets are
more likely to be sensitive.
With our intuition conﬁrmed, we classiﬁed every secret in
our dataset as single- or multiple-owner to evaluate the impact
of duplication. Table II shows the results of this classiﬁcation
on the combined Search and BigQuery datasets. We show that
an overwhelming majority (93.58%) of unique secrets are found
in repos owned by a single owner, indicating that these are
more likely to be sensitive secrets4. Further, we computed the
Pearson correlation coefﬁcient between the relative rates of
single- and multiple-owner secrets between the Search and
BigQuery datasets. We found that the two datasets had a
correlation of r = 0.944 and a p-value of 1.4×10−9, indicating
that they have a similar level of exposure and distribution of
sensitive secrets, irrespective of their size and perspective.
Critically, because almost all detected secrets had their
privacy maintained, we show that the observed duplication
does not suggest our results were skewed by non-sensitive
secrets. In fact, deeper investigation showed one major source
of duplication was a single developer using their secrets
multiple times; in the Search dataset, we found that the average
single-owner secret was used in 1.52 different ﬁles, with the
most duplicated appearing in 5,502 ﬁles. A second source of
duplication was from a very small number of secrets used
3BigQuery does not provide this information. It is possible to obtain it
via the GitHub API, but not at a large scale due to rate limiting.
4Technical limitations prevented us from retrieving repo owner information
for about 7,500 secrets from BigQuery, which where excluded from this
analysis.
by many developers. This was particularly evident with RSA
private keys, where nearly 50% of all occurrences were caused
by the most common unique 0.1% keys, which were multiple-
owner secrets and likely test keys. Fortunately, since this
source duplication was restricted to a very small subset of
keys, duplication would have minimal impact on analysis done
on unique valid secrets. Consequently, we will only consider
the unique valid secrets in future sections of this paper.
D. Parallel Leakage
Some of our secrets require additional pieces of information
to be used, such as Google OAuth IDs which require the
OAuth Secret for privileged actions. We previously deﬁned
these secrets as “multi-factor” secrets in Section III-A and
identiﬁed them in Table I. While these parallel secrets may
seem to improve security by reducing the impact of leakage,
in this section we show that the missing information is often
leaked in parallel to the main secret, making this protection
mostly inconsequential. The difﬁculty in detecting the parallel
secrets is that they may not have a sufﬁciently distinct structure
to be included within our distinct signatures. However, they
can still be matched by a crafted regular expression and located
with high conﬁdence given prior knowledge of secret leakage.
We examined every ﬁle containing a distinct multi-factor secret
and then scanned for the parallel secrets5 in the 5 lines before
and after a secret. This context size was chosen based on prior
work that scanned Google Play applications [62].
Figure 2 shows the results of this experiment in terms of the
percent of ﬁles containing one of our secrets that has a parallel
secret. Every multi-factor secret in the Search dataset has at
least an 80% likelihood of leaking another parallel secret. For
example, even though Google OAuth IDs require another secret,
our ability to write regular expressions to identify them with
high ﬁdelity allows us to discover one of the other secrets in
nearly 90% of cases. BigQuery shows lower rates of parallel
leakage, perhaps due to the data source containing more mature
ﬁles, but still has a worrying amount of leakage. Thus, we
argue that the fact that these multi-factor secrets have varying
levels of compromisability and secrecy is not a large hurdle.
Additionally, this parallel leakage was not restricted to
single types of secrets; many ﬁles containing one secret also
contained another secret. We identiﬁed 729 ﬁles that leaked
secrets for two or more API platforms within the same ﬁle.
E. Secret Lifetime
Once a secret is exposed by a user, a user may attempt to
retroactively remove the secret via a subsequent commit. To
quantify the prevalence of this, we began monitoring all secrets
collected via the Search API after they were discovered starting
on April 4th, 2018. For the ﬁrst 24 hours from discovery, we
queried GitHub hourly to determine if the repo containing
the ﬁle, the ﬁle itself, and the detected secrets still existed on
the head of the default branch. After the initial 24 hours, we
performed the same check at a reduced daily frequency. The
results of the initial 24 hour short-term monitoring is shown
in Figure 3a, and the daily long-term monitoring is shown in
Figure 3b.
5The parallel targets we scanned for, and their regular expressions, can
be found in Table VI in the Appendix
Fig. 2: All of the multi-factor distinct secrets have a high rate
of leakage of other pieces of secret information
We observe several trends. First, the largest drop in secret
presence occurred in the ﬁrst hour after discovery, where about
6% of all detected secrets were removed. Second, secrets that
existed for more than a day tended to stay on GitHub long-
term—at the end of the ﬁrst day, over 12% of secrets were
gone, while only 19% were gone after 16 days. Third, the rate