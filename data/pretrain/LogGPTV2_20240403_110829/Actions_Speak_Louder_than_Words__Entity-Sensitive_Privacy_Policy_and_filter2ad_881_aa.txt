title:Actions Speak Louder than Words: Entity-Sensitive Privacy Policy and
Data Flow Analysis with PoliCheck
author:Benjamin Andow and
Samin Yaseer Mahmud and
Justin Whitaker and
William Enck and
Bradley Reaves and
Kapil Singh and
Serge Egelman
Actions Speak Louder than Words: Entity-Sensitive 
Privacy Policy and Data Flow Analysis with PoliCheck
Benjamin Andow, IBM T.J. Watson Research Center; Samin Yaseer Mahmud, 
Justin Whitaker, William Enck, and Bradley Reaves, North Carolina State 
University; Kapil Singh, IBM T.J. Watson Research Center; Serge Egelman, 
U.C. Berkeley / ICSI / AppCensus Inc.
https://www.usenix.org/conference/usenixsecurity20/presentation/andow
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.Actions Speak Louder than Words: Entity-Sensitive Privacy Policy and Data Flow
Analysis with POLICHECK
Benjamin Andow,(cid:63) Samin Yaseer Mahmud,† Justin Whitaker,†
William Enck,† Bradley Reaves,† Kapil Singh,(cid:63) Serge Egelman‡
(cid:63)IBM T.J. Watson Research Center
†North Carolina State University
‡U.C. Berkeley / ICSI / AppCensus Inc.
Abstract
Identifying privacy-sensitive data leaks by mobile applica-
tions has been a topic of great research interest for the past
decade. Technically, such data ﬂows are not “leaks” if they
are disclosed in a privacy policy. To address this limitation
in automated analysis, recent work has combined program
analysis of applications with analysis of privacy policies to de-
termine the ﬂow-to-policy consistency, and hence violations
thereof. However, this prior work has a fundamental weak-
ness: it does not differentiate the entity (e.g., ﬁrst-party vs.
third-party) receiving the privacy-sensitive data. In this paper,
we propose POLICHECK, which formalizes and implements
an entity-sensitive ﬂow-to-policy consistency model. We use
POLICHECK to study 13,796 applications and their privacy
policies and ﬁnd that up to 42.4% of applications either incor-
rectly disclose or omit disclosing their privacy-sensitive data
ﬂows. Our results also demonstrate the signiﬁcance of con-
sidering entities: without considering entity, prior approaches
would falsely classify up to 38.4% of applications as hav-
ing privacy-sensitive data ﬂows consistent with their privacy
policies. These false classiﬁcations include data ﬂows to third-
parties that are omitted (e.g., the policy states only the ﬁrst-
party collects the data type), incorrect (e.g., the policy states
the third-party does not collect the data type), and ambiguous
(e.g., the policy has conﬂicting statements about the data type
collection). By deﬁning a novel automated, entity-sensitive
ﬂow-to-policy consistency analysis, POLICHECK provides the
highest-precision method to date to determine if applications
properly disclose their privacy-sensitive behaviors.
1 Introduction
Privacy is a long-standing open research challenge for mobile
applications. Literature has proposed various program analy-
sis tools for Android [7, 11, 12, 14] and iOS [10] apps, often
citing private-information disclosure as motivations. Subse-
quent empirical studies [16, 18, 23–25, 27] have demonstrated
pervasive and continual disclosure of privacy-sensitive infor-
mation such as device identiﬁers and geographic location.
Broadly speaking, the concept of privacy is only vaguely
deﬁned and frequently debated. Privacy resides at the inter-
section of technical, cultural, and legal considerations. In the
case of mobile applications, data collection and sharing are
often considered (legally) acceptable if it is disclosed in the
privacy policy for the application. While there have been sev-
eral manual analyses of application privacy policies [9, 20], it
is hard to computationally reason about what privacy policies
say, and therefore how applications adhere to them.
A recent thread of research has begun studying privacy
policies and mobile applications [29, 32, 34, 38]. The goal of
these studies is to help app developers write accurate privacy
policies, help application stores identify privacy violations,
and help end users choose more-privacy-friendly applications.
Conceptually, these studies use a combination of static pro-
gram analysis and natural language processing to perform an
analysis of ﬂow-to-policy consistency. Simply, ﬂow-to-policy
consistency analysis determines whether an app’s behavior is
consistent with what is declared in the privacy policy.
While such prior studies have led to promising results, the
techniques have a fundamental weakness: they do not dif-
ferentiate the entity (e.g., ﬁrst-party vs. third-parties, such as
advertisers and analytics providers) receiving the data. In fact,
in Section 5.2, we show that entity-insensitive models may
wrongly classify 38.4% of applications as having privacy-
sensitive data ﬂows consistent with their privacy policies due
to reasoning over third-party data ﬂows using policy state-
ments discussing ﬁrst-party collection practices. For example,
consider the following sentence from a popular Android ap-
plication with over 10 million downloads:
When you launch any of our applications, we col-
lect information regarding your device type, oper-
ating system and version, carrier provider, IP ad-
dress, Media Access Control (MAC) address, In-
ternational Equipment Mobile ID (IMEI), whether
you are using a point package, the game version,
the device’s geo-location, language settings, and
unique device ID.
USENIX Association
29th USENIX Security Symposium    985
This statement indicates that the app (the ﬁrst-party) collects
different device identiﬁers; but there is no mention of third-
parties collecting this data. In actuality, dynamic analysis
found that the application sends the IMEI, Android ID, and
Ad ID to Tapjoy and the Android ID and Ad ID to Flurry (two
third-party advertisers). By not considering the entity receiv-
ing the privacy-sensitive data, prior work would incorrectly
classify these data ﬂows as being consistent with the policy.
In addition, the importance developers disclosing the third-
party entities with which they are sharing information is
grounded in regulations, such as GDPR [3] and CCPA [1]. In
particular, GDPR mandates that data controllers disclose the
recipients or categories of recipients with which they share
personal data. In the case of applications, the ﬁrst-party (de-
veloper) is considered the data controller while third-parties
can either be data controllers or data processors. The major-
ity of the entities involved in this study self-identify as data
controllers (e.g., Google, Facebook, TapJoy). Based on the
requirement that data controllers are required to disclose their
identity and contact information according to GDPR, it is
debatable whether the application is required to disclose all
third-parties by name if they also take the role as a data con-
troller. Further, the CCPA states that the privacy policy should
disclose the categories of third-parties with whom the busi-
ness shared personal information. Therefore, the application’s
privacy policy is also mandated to disclose the third-party
entities with which they share data based on the CCPA.
In this paper, we propose POLICHECK, which provides
an entity-sensitive ﬂow-to-policy consistency model to deter-
mine if an application’s privacy policy discloses relevant data
ﬂows. We formally specify a novel ﬂow-to-policy consistency
model that is sensitive to the semantic granularity of both the
data type and the entity receiving the data and sentiment of
the statement. We dissect ﬂow-to-policy consistency into 5
distinct types of disclosures (including non-disclosures) to
allow for targeted exploration of how apps are (not) disclos-
ing their privacy practices. We use POLICHECK to study the
ﬂow-to-policy consistency of 13,796 Android applications
observed to send privacy sensitive values to servers during
dynamic analysis (45,603 data ﬂows).
The ﬁndings from our large-scale empirical study found
several signiﬁcant ﬂow-to-policy inconsistencies in popular
real-world applications that impact tens-of-millions of users,
such as not disclosing data sharing with advertisers and analyt-
ics providers in privacy policies. In general, we found that ap-
plications almost never clearly disclose their privacy-sensitive
data ﬂows to third-parties. In fact, 40.4% of data ﬂows in-
volving third-party entities are broadly discussed using the
term “third-party,” leaving it up to guesswork to determine
where the data is ﬂowing. Furthermore, we found 5.2% of
applications state that they do not share or collect a speciﬁc
type of information within their privacy policy, but dynamic
analysis shows the opposite.
The results from our empirical study highlight the poor state
of privacy policies for Android applications, which demon-
strates the need for action from regulatory agencies and ap-
plication markets. For example, the FTC has set precedent
by charging mobile applications that were found to be omit-
ting or incorrectly disclosing their privacy practices [15, 30],
which corresponds to our omitted disclosures and incorrect
disclosures. Regulatory agencies could use POLICHECK for
automated analysis at-scale to identify applications violating
their privacy policies and take whichever actions they deem
appropriate. Further, application markets could also lever-
age POLICHECK to triage and remove applications that are
not correctly disclosing their privacy practices and to urge
developers to provide clearer disclosures.
This paper makes the following main contributions:
• We formally deﬁne an entity-sensitive ﬂow-to-policy con-
sistency model for mobile apps. This model includes two
types of consistencies and three types of inconsistencies.
By considering entities, the model avoids signiﬁcant mis-
classiﬁcations that result from prior approaches.
• We design and implement the POLICHECK tool for an-
alyzing the ﬂow-to-policy consistency of Android appli-
cations. POLICHECK builds on top of PolicyLint [4]
for privacy policy analysis and AppCensus [6] for dy-
namic analysis of Android applications. In doing so, we
bridge the gap between the low-level data types and DNS
domains used by program analysis tools and the often
higher-level concepts present in privacy policies.
• We study and characterize the ﬂow-to-policy consistency
of 13,796 Android applications. Our characterization
differentiates ﬁrst-party and third-party collection and
demonstrates the importance of an entity-sensitive con-
sistency model. We show that our entity-sensitive con-
sistency ﬁnds signiﬁcant ﬂow-to-policy inconsistencies
that involve sharing data to third-party entities, impact-
ing tens-of-millions of users.
The rest of this paper proceeds as follows. Section 2 uses ex-
amples to provide the high-level intuition behind POLICHECK.
Section 3 formally deﬁnes the different types of ﬂow-to-policy
consistencies and inconsistencies. Section 4 describes the de-
sign of POLICHECK. Section 5 presents our empirical study.
Section 6 discusses additional case studies. Section 7 dis-
cusses limitations and future work. Section 8 overviews re-
lated work. Section 9 concludes.
2 Flow-to-Policy Consistency
This section motivates POLICHECK’s functionality through
ﬁve examples that POLICHECK identiﬁed. We simultaneously
provide a high-level intuition of its functionality by walking
through how a human analyst might approach the task. In
doing so, we also exemplify the limitations of prior work.
986    29th USENIX Security Symposium
USENIX Association
Figure 1: POLICHECK determines the consistency of a mobile application’s data ﬂows to its privacy policy.
This section does not cover every corner case. Sections 3
and 4 describe POLICHECK in detail.
As shown in Figure 1, POLICHECK seeks to determine
if the privacy policies for mobile applications disclose their
privacy-sensitive data ﬂows to different network entities, as
required by various regulations [1, 3]. We deﬁne a data ﬂow
as a type of privacy-sensitive data (e.g., IMEI, location, email
address) and the entity receiving the data (e.g., Facebook,
TapJoy, AdMob). If an application’s privacy policy appro-
priately discusses the sharing or collection of the speciﬁc
data type to or by a speciﬁc entity for a given data ﬂow, we
refer to the data ﬂow as being consistent with the privacy
policy. To ensure sufﬁcient evidence of sharing or collection
by an entity, we scope data ﬂows to network transmission
identiﬁed during dynamic analysis. While dynamic analysis
may under-approximate data ﬂows if sufﬁcient code cover-
age is not achieved during testing, our goal was to optimize
for precision over recall. In contrast, static analysis may over-
approximate data ﬂows and lead to lower precision (e.g., some
ad libraries collect geographic location based on an applica-
tion developer’s server-side conﬁguration).
2.1 Clear Disclosures
A data ﬂow has a clear disclosure when there exists a state-
ment within the privacy policy that directly discusses the
exact type of data and entity of the data ﬂow, and there is
no other policy statement that contradicts it. For illustrative
purposes, consider the “Dr. Panda Town: Vacation” (com.d-
rpanda.town.holiday) game application with over 1 million
downloads on Google Play. This application is built on top
of the Unity third-party game engine. For analytics purposes,
it obtains the device’s advertising identiﬁer and sends it to
cdp.cloud.unity3d.com (i.e., Unity).
To determine if this data ﬂow is disclosed by the privacy
policy, the ﬁrst step is to resolve cdp.cloud.unity3d.com to
the entity “Unity” by matching the root domain (unity3d.com)
to a list of known analytics providers. For each policy state-
ment, we look for a direct positive sentiment match between
the ﬂow’s data type and entity and the policy statement’s data
type and entity. In this case, we identify the following state-
ment, “Unity collects the following information through our
Games: unique device ID and AD ID.” We then look for policy
statements that contradict the statement by extracting all nega-
tive sentiment statements that discuss the ﬂow’s data type and
entity at any semantic granularity (e.g., analytics providers
collecting device information). In this speciﬁc case, we do
not ﬁnd any policy statements that contradict the statement
above. Therefore, we label this case as a clear disclosure.
2.2 Vague Disclosures
A data ﬂow has a vague disclosure when the only statements
within a privacy policy that match a data ﬂow use broad
terms for the data type or entity. Similar to clear disclosures, a
statement is a vague disclosure only if a contradictory policy
statement does not exist. We differentiate vague disclosures
from clear disclosures, because there is a risk that the language
used to disclose the data ﬂow is so broad that it encapsulates
a wide-range of data ﬂows, making it difﬁcult to determine if
third-party sharing or collection occurs. Vague disclosures are
similar to Slavin et al. [29] and Wang et al.’s [32] deﬁnition
of weak violations, but entity-sensitive, sentiment-sensitive,
and contradiction-sensitive.
As an example, consider the popular “Elite Killer: SWAT”
(com.yx.sniper) game application on Google Play with over
10 million downloads and a 4.3 star rating. For monetiza-
tion purposes, this application uses the TapJoy advertising
provider to deliver advertisements within the application.
When requesting advertisements from TapJoy, the application
obtains the user’s Android advertising identiﬁer and transmits
it to ws.tapjoyads.com.
Similar to the previous example, we resolve ws.tapjoy-
ads.com to “TapJoy” through a substring match of the root
domain in our list of known advertisers. However, rather than
identifying only direct matches, we look for policy statements
with positive sentiment that match at any semantic granularity
for the ﬂow’s data type and entity. In this case, we identify
the following statement, “A device identiﬁer and in-game or
user session activity may be shared with the advertiser.” This
statement matches the data ﬂow, because TapJoy is an ad-
vertiser and the Android advertising identiﬁer is a type of
device identiﬁer. Next, we look for matching policy state-
ments with negative sentiment statements. Since we do not
USENIX Association
29th USENIX Security Symposium    987
AppPrivacy PolicyAppCensusPolicyLintData FlowsCollection StatementsPoliCheckClear DisclosureVague DisclosureConsistentOmitted DisclosureIncorrect DisclosureAmbiguous DisclosureInconsistentFlow-to-Policy ConsistencyApp Storeﬁnd any policy statements that contradict this statement, we
label this data ﬂow as a vague disclosure. Finally, we calculate
a vagueness score for the resolved policy statement to allow a
ranked ordering, which is based on a normalized ontological
distance between the ﬂow’s data type and entity and the policy
statements data type and entity.
2.3 Omitted Disclosure
A data ﬂow has an omitted disclosure when there are no policy
statements that discuss it. Omitted disclosures are similar to
Wang et al.’s [32] deﬁnition of strong violations. However, as
we demonstrate in the following example, prior deﬁnitions
do not consider both data type and entity, and therefore may
incorrectly classify an omitted disclosure as being ﬂow-to-
policy consistent.
Consider the application “Flash Emoji Keyboard &
Themes” (com.xime.latin.lite) on Google Play, which cur-
rently has over 50 million downloads and a 4.1 star rating.
This application uses the Avazu advertising provider to serve
advertisements within the application for monetization pur-
poses. When requesting advertisements from Avazu, this
application obtains the user’s Android identiﬁer, IMEI, and