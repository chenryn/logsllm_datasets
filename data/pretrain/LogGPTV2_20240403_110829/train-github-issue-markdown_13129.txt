## Environment info
  * `transformers` version:4.3.3
  * Platform:Pytorch
  * Python version:3.7.0
  * PyTorch version (GPU?):GPU
  * Tensorflow version (GPU?):
  * Using GPU in script?:
  * Using distributed or parallel set-up in script?:NO
### Who can help
## Information
Model I am using (Bert, XLNet ...):
The problem arises when using:
  * the official example scripts: (give details below)  
https://github.com/huggingface/transformers/blob/master/examples/language-
modeling/run_mlm.py
  * my own modified scripts: (give details below)
The tasks I am working on is:
  * an official GLUE/SQUaD task: (give the name)
  * my own task or dataset: (give details below)
## To reproduce
Steps to reproduce the behavior:
1.python run_mlm.py --model_name_or_path release_model/ --dataset_name
wikitext --dataset_config_name wikitext-2-raw-v1 --do_train --do_eval
--output_dir test-mlm --max_seq_length 128  
2.Got an error:
    [INFO|trainer.py:1408] 2021-03-15 11:10:32,884 >> Saving model checkpoint to test-mlm
    [INFO|configuration_utils.py:304] 2021-03-15 11:10:32,886 >> Configuration saved in test-mlm/config.json
    [INFO|modeling_utils.py:817] 2021-03-15 11:10:33,863 >> Model weights saved in test-mlm/pytorch_model.bin
    Traceback (most recent call last):
      File "run_mlm.py", line 475, in 
        main()
      File "run_mlm.py", line 450, in main
        trainer.log_metrics("train", metrics)
    AttributeError: 'Trainer' object has no attribute 'log_metrics'
## Expected behavior
The script finish without error.