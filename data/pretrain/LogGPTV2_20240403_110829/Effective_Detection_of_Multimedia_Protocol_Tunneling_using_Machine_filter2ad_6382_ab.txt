covert data. The adversary is also assumed to be unable
to control the software installed in the computers of end-
users. However, domestic ISPs are assumed to cooperate
with the adversary, enabling it to monitor, store and in-
spect all trafﬁc ﬂows crossing its borders.
For conducting our study, we were required to analyze a
number of network traces produced by the systems de-
scribed in Section 2.1. For our testbed, we used two 64-
bit Ubuntu 14.04.5 LTS virtual machines (VMs) provi-
sioned with a 2.40GHz Intel Core2 Duo CPU and 8GB
of RAM conﬁgured in a LAN setting. We used the
v4l2loopback camera emulator and the pulseaudio sound
server to feed video and audio to the carrier multimedia
applications. The prototypes of the considered systems
were obtained from their respective websites [3, 29, 33].
Due to the deprecation of Skype v4.3 and the incompati-
bility of v4l2loopback with the latest Skype v8.x desk-
top version, we have resorted to Skype for Web. For
gathering the trafﬁc samples generated by each system,
we captured the network packets produced by the carrier
USENIX Association
27th USENIX Security Symposium    171
multimedia streams for a duration of 60 seconds after a
given covert channel has been established. The method-
ology we followed for gathering trafﬁc samples has been
commonly used in the literature since it allows for the
analysis of the unobservability properties of covert chan-
nels while executing in steady-state. Next, we describe
the methodology we followed for generating our covert
and legitimate trafﬁc datasets.
Facet: For building our covert video dataset, we col-
lected 1000 YouTube videos from the YouTube-curated
Top Shared and Liked playlist. The legitimate Skype
video dataset consists of 1000 recorded live chat videos
available on YouTube. We adapted the Facet prototype to
sample three types of Facet transmissions, corresponding
to scaling the covert videos on top of legitimate videos by
a factor of 50%, 25% and 12.5% – the available proto-
type represents a proof-of-concept only capable of a (un-
morphed) 100% scaling. Then, we gathered 1000 traf-
ﬁc samples for each scaling factor by combining a pair
of legitimate and covert videos while following the au-
dio and video morphing techniques detailed in Facet’s
original description. To emulate legitimate Skype calls,
we streamed the media comprising our legitimate Skype
video dataset. The resolution of the camera emulator was
set to 320x240. For gathering trafﬁc samples, we used
each of the available VMs as a Skype peer.
CovertCast: For building our legitimate live-streaming
dataset, we crawled 200 live-streams included in the Live
YouTube-curated list. Then, we generated 200 Covert-
Cast live-streams by broadcasting several news websites
already included in the available CovertCast prototype.
The server component, responsible for scraping web-
sites, was executed in one of our VMs and streamed mod-
ulated video frames to YouTube. We used a Windows
laptop running Google Chrome as a CovertCast client.
Each video was streamed with a 1280x720 resolution.
DeltaShaper: We emulated 300 legitimate bi-directional
Skype calls by streaming a subset of our legitimate Skype
video dataset. We gathered DeltaShaper trafﬁc samples
by establishing a DeltaShaper connection between the
Skype endpoints installed in both VMs. We gathered
data for two DeltaShaper conﬁgurations, found to pro-
vide trafﬁc analysis resistance guarantees, and which re-
spected the tuple (payload frame area, cell size, num-
ber of bits, framerate). These were comprised by the
h320 × 240, 8 × 8, 6, 1i and h160 × 120, 4 × 4, 6, 1i tuples.
Each video was streamed in a 640x480 resolution.
3 Similarity-based Classiﬁcation
For the purpose of unobservability assessment, multiple
similarity functions have been used to feed similarity-
based classiﬁers. This section details the rationale be-
hind each of these functions and how they have been
used for the construction of similarity-based classiﬁers
and applied to different multimedia protocol tunneling
systems. Then, we conduct a comparative analysis of the
performance of each of these classiﬁers.
3.1 Currently Used Similarity Functions
Next, we introduce the three similarity-based classiﬁers
which have been previously used for evaluating the un-
observability of Facet, CovertCast, and DeltaShaper.
In similarity-based classiﬁcation [10], labeling is per-
formed by taking into account the pairwise-similarities
between the test sample and a set of labeled training sam-
ples (or a representative model based on these). In the
context of trafﬁc analysis, similarity scores are often ob-
tained from the comparison of the frequency distribution
of packet lengths or inter-arrival times of trafﬁc samples.
Pearson’s Chi-squared Test (χ 2) [40] tells us whether
the distributions of two categorical variables differ sig-
niﬁcantly from each other, by comparing the observed
and expected frequencies of each category. The χ 2 test is
used in a classiﬁer adapted for distinguishing Facet traf-
ﬁc [30, 51]. The classiﬁer starts by building two mod-
els for legitimate and Facet trafﬁc, respectively, using la-
beled samples. These models are based upon a selec-
tion of the bi-gram distribution of packet lengths, where
bi-grams expected to hurt classiﬁcation performance are
identiﬁed and discarded. Test samples are compared to
each of the models using the χ 2 test. A simpler version of
this classiﬁer labels a sample according to the minimum
distance obtained when compared against each model. A
more sophisticated version of the classiﬁer labels sam-
ples according to whether the ratio between the distance
to each model surpasses a threshold. An adversary can
adjust this threshold for balancing the expected true pos-
itive and false positive rates of the classiﬁer.
Kullback-Leibler Divergence (KL) [28] is a measure of
relative entropy between two target distributions which is
obtained by computing the information lost when trying
to approximate one distribution with the other. The KL
divergence is used for building a classiﬁer for Covert-
Cast trafﬁc. The classiﬁer aims at distinguishing a set of
YouTube videos carrying modulated data from a set of
regular YouTube videos through the comparison of the
quantized frequency distribution of packet lengths. For
each sample in a given set, the classiﬁer computes its KL
divergence from every other member in the same set and
every member in the other set. Then, the classiﬁer com-
putes a success metric, corresponding to the number of
times the KL divergence between a member of one set is
more similar to another member of the same set, divided
by the total KL divergences that were computed.
172    27th USENIX Security Symposium
USENIX Association
USENIX Association
27th USENIX Security Symposium    173
of unobservability. This can be inferred from the consis-
tently higher accuracy values provided by χ 2.
2. χ 2 produces large false positive rates when clas-
sifying Facet and DeltaShaper trafﬁc. Figure 1 de-
picts the ROC curve of the χ 2 and EMD classiﬁers
when detecting Facet and DeltaShaper trafﬁc. Figure 1a
shows that for correctly identifying 90% of all Facet
trafﬁc (TPR=90%), with s=50%, an adversary would
tag 45% of legitimate connections (45% FPR) as covert
trafﬁc, while employing the χ 2 classiﬁer. For iden-
tifying 90% of all DeltaShaper h320 × 240, 8 × 8, 6, 1i
trafﬁc, the adversary would face an FPR=51%. Thus,
even the deployment of the best performing similarity-
based classiﬁer results in a large number of misclassiﬁ-
cations for legitimate trafﬁc. Misclassiﬁcations are fur-
ther aggravated should an adversary resort to the EMD
Figure 1 conﬁrms that χ 2 performs only
classiﬁer.
fairly in distinguishing covert channels (e.g., AUC=0.83
for Facet s=50%, AUC=0.74 for DeltaShaper h320 ×
240, 8 × 8, 6, 1i). We do not show a ROC curve for KL as
the classiﬁer is not adjustable by an internal threshold.
3. CovertCast fails to provide unobservability. The
results in Table 1 show that the χ 2 classiﬁer can cor-
rectly identify all of CovertCast streams while incurring
only in a 2% false positive rate. Additionally, the num-
bers show that the remaining classiﬁers can correctly
identify >96.5% of CovertCast streams, albeit incurring
in a larger false positive rate (e.g., EMD: TPR=0.965,
FPR=0.305). We conjecture two explanations that may
justify the differences beween our results and those pub-
lished in the original CovertCast paper. Firstly, our re-
sults may stem from the use of a dataset which is one
order of magnitude larger than the one used for Covert-
Cast evaluation. This increased dataset may more ac-
curately represent the patterns generated by legitimate
YouTube streams’ trafﬁc and reveal CovertCast activ-
ity. Secondly, implementation changes in YouTube may
have impacted the unobservability properties provided
by hardcoded data modulation parameters, which may
in turn be no longer adequate to ensure unobservability.
4 Decision Tree-based Classiﬁcation
In this section, we depart from the use of similarity-based
classiﬁers for detecting the presence of covert trafﬁc. As
it is unpractical to explore all possible machine learning
algorithms, we focus our experiments in a subset of al-
gorithms based on decision trees. We have chosen these
algorithms due to their ability of handling data in a non-
linear fashion, their ability to perform feature selection,
and the ease of interpretation of the resulting models.
Our results show that this approach is highly effective
at detecting covert trafﬁc in the systems under study.
4.1 Selected Classiﬁers
We present a description of the decision-tree based algo-
rithms we have chosen for conducting our experiments:
Decision Trees [41] build a model in the form of a tree
structure, where each tree node is either a decision or
leaf node, representing a branch or a label, respectively.
Decision nodes split the current branch by an attribute.
A splitting attribute is commonly chosen according to its
expected information gain, i.e. the expected reduction in
entropy caused by choosing the attribute for a split. The
importance of each particular attribute can be assessed
by analyzing the tree structure, where nodes closer to the
root have a higher importance than those down the tree.
Despite its simple interpretation, decision trees can result
in complex models unable to generalize well or can build
unstable models due to the presence of large numbers
of correlated features. A popular way to mitigate such
disadvantages is to use decision tree ensembles.
Random Forests [6] are an ensemble learning method,
where a label is predicted by performing a majority vote
over the output of multiple decisions trees. To prevent
overﬁtting, Random Forests introduce variance in the
model through bootstrap aggregation, i.e. each tree is
trained using a random sample (with replacement) of the
training set. Additionally, Random Forests select ran-
dom attributes of the feature set when building each tree,
a technique named feature bagging. One method for as-
sessing the importance of an attribute is to average its
information gain across all trees in the ensemble.
eXtreme Gradient Boosting (XGBoost) [9] is another
technique for building a model based on an ensemble of
decision trees; it relies on a technique known as gradient
tree boosting. XGBoost starts by building a shallow de-
cision tree (i.e., a weak learner). In each step, XGBoost
creates a new tree which optimizes the predictions per-
formed by trees in earlier stages. XGBoost beneﬁts from
a regularized model formalization to control overﬁtting.
The importance of individual attributes can be computed
in a similar fashion to that of Random Forests. We ﬁnd
the use of XGBoost to be promising among a large pool
of classiﬁcation algorithms. In fact, XGBoost has played
a central role on multiple winning solutions for recent
data mining competitions, spawning multiple domains,
such as the KDD Cup 2016 [12, 44]
The next sections detail our experiments for evaluat-
ing the unobservability of Facet and DeltaShaper with
the decision tree-based classiﬁers enumerated above. In
our experiments we have used two distinct sets of fea-
tures: summary statistics and quantized packet lengths.
We omit a discussion over CovertCast, as we have found
that all of these techniques can identify its covert trafﬁc
with a negligible false positive rate.
174    27th USENIX Security Symposium
USENIX Association
USENIX Association
27th USENIX Security Symposium    175
176    27th USENIX Security Symposium
USENIX Association
USENIX Association
27th USENIX Security Symposium    177
3. Facet covert channels can be spotted by looking for
packets with a length comprehended between 115-195
bytes. Figure 4b not only shows that the most important
bin corresponds to that by the packets which length is
close to 150, but also that the top 10 features are domi-
nated by packets which lengths are in the range of 115 to
195 bytes. This result concurs with our previous obser-
vation, where the most important percentiles of packet
lengths focused packets with a mean length between 137
and 200 bytes. This observation is also true when de-
tecting Facet s={12.5%,25%} trafﬁc. This ﬁnding sug-
gests that the major factor leading to the distinguishing of
Facet trafﬁc concerns the packets carrying audio, which
are typically located in the range between 100 and 200
bytes [37]. Additionally, we can observe that some of the
least important features included in the top 20 for identi-
fying Facet s = 50% ﬂows include packets with a length
between 945-985 bytes. This result hints that larger ar-
eas dedicated to video payload translate into packet-level
modiﬁcations in a higher range of the feature space. Ad-
ditionally, XGBoost ranks only 175 out of 300 features
with a non-zero importance score, suggesting that only
approximately half of the quantized packet length bins
contribute for the discrimination of Facet trafﬁc.
4. DeltaShaper covert channels can be spotted by
looking for packets with a length between 85-100 and
1105-1205 bytes. Figure 4d shows that the two most
important features for identifying DeltaShaper h320 ×
240, 8 × 8, 6, 1i trafﬁc correspond to the packets which
size is close to 100 bytes (ﬂowing in both directions).
The top 20 features are dominated by packet length bins
in the range from 85-100 and 1105-1205 bytes, suggest-
ing that DeltaShaper data modulation markedly affects
two distinct regions of the feature space. The region in-
cluding larger packets roughly overlaps the mean length
of the packets included in the most important percentiles
of our analysis of summary statistics. Considering that
DeltaShaper’s covert data embedding procedure speciﬁ-
cally targets the video layer of Skype calls, this ﬁnding
suggests that such modulation largely affects larger pack-
ets of the connection. When classifying DeltaShaper
h320 × 240, 8 × 8, 6, 1i trafﬁc, XGBoost ranks 253 out
of 600 features with a non-zero importance score.
The most important features for detecting DeltaShaper
h160 × 120, 4 × 4, 6, 1i trafﬁc largely overlap the two fea-