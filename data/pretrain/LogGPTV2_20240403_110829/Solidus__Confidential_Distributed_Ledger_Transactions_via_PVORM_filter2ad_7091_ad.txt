tions involving Bs; if a different Circuit ORAM path is accessed,
Us is not involved, but if the same path is accessed, Us likely is.
In order to prevent this information leakage, Bs must post some
PVORM update to the ledger after sending the update to Br be-
fore initiating any other transaction. If the original transaction
settles that includes exactly such an update. Otherwise Bs can in-
voke “abortTxn” with a dummy update on the same tree path, thus
invalidating any information Br may have gained.
With these ideal functionalities defined, we can now present
the main Solidus protocol, ProtSol, in Figure 6. We note that the
environment Z is a standard UC framework entity that represents
all behavior external to the protocol execution. (Z feeds input to
and collects outputs from protocol parties and the adversary.)
To execute a transaction in ProtSol, a user executes “beginTxn”,
which sends a “requestTxn” request to the user’s bank. The bank
8
(cid:20)(cid:40)
Bi
ProtSol
User Ui :
On input (“beginTxn”, Uj, $v ) from environment Z:
Let Bi = bank(Ui ) and Bj = bank(Uj )
Generate random unique txid
Encrypt cr = Enc(ePKj, pkj ) and cv = Enc(ePKi, $v )
σ = hSign(ski, ePKj, (txid, cr , cv ))
send (“requestTxn”, txid, ePKj, cr , cv , σ ) to Bi
Bank Bi :
On receive (“initBank”, ePKj, sPKj, Cj ) from FInit:
assert B[Bj ] is not set
B[Bj ] ← (ePKj, sPKj, Cj )
On receive (“postTxn”, txid, txn) from FLedger:
Retrieve (Bs , C′
r ) from txn
if (Bi = Bs or Bi = Br ), then Pend ← ⊥
Update B[Bs ] ← (ePKs , sPKs , C′
s )
B[Br ] ← (ePKr , sPKr , C′
r )
s ) and (Br , C′
i, e, proof ) ← Update(eSKi, (Ui, 0), Ci )
On input (“abortPend”) from environment Z:
assert Pend (cid:44) ⊥
Retrieve Ui at Bi from Pend
Update (C′
Generate a ZK-proof pf ⋆ that e encrypts a 0-value change.
send (“abortTxn”, (txid, Bi, (C′
i, e, proof ), pf ⋆) to FLedger
On receive (“abortTxn”, abort) from FLedger:
Parse (txid, Bj, (C′
if Bj = Bi
assert Pend = (txid, _)
Pend ← ⊥
B[Bj ] ← (ePKj, sPKj, C′
j )
if Pend (cid:44) ⊥ and Bj is the other bank in Pend
Execute “abortPend” as described above
j, e, proof ), pf ⋆) ← abort
(cid:21)
(cid:41)k
i =1
Ui
(cid:41)n
(cid:40)
i =1,
On receive (“requestTxn”, txid, ePKs , cv , cr , σ ) from Us :
assert (Pend = ⊥) ∧ (txid is unique)
(cid:17)
∧ hVer(ePKi, (txid, cv , cr ), σ )
((α, β ), _) ← σ : Dec(eSKi, (α, β )) = pks
∧ (cid:16)
i, es, proof s ) ← Update(eSKi, (Us , −$v ), Ci )
Decrypt $v = Dec(eSKi, cv )
assert 0 ≤ $v ≤ Mi [Us ]
Update (C′
Let c′
v = Enc(ePKj, $v )
Generate txdatas containing:
• (txid, (cv , cr ), σ, c′
v )
• (C′
i, es, proof s )
• RangePf(ev , t )
• Proof that es updates Us by amount in cv
• Proof that cv and c′
v encrypt the same value
Pend ← txdatas
σs = Sign(sSKi, txdatas )
send (“approveSendTxn”, txid, txdatas , σs ) to Bj
On receive (“approveSendTxn”, txid, txdatas , σs ) from Bj :
assert (Pend = ⊥) ∧ (txid is unique)
∧ sVer(sPKj, txdatas , σs )
∧ all proofs in txdatas are valid
i, er , proof r ) ← Update(eSKi, (Ur , $v ), Ci )
Retrieve (txid, (cv , cr ), σ, c′
v ) from txdatas
Decrypt $v ← Dec(eSKi, c′
v )
assert txid is unique and $v ≥ 0
Decrypt pkr = Dec(eSKi, cr )
Update (C′
Generate txdatar containing:
• (txid, (cv , cr ), σ, c′
v )
• (C′
i, er , proof r )
• Proof that er updates account cr by value c′
Pend ← (txid, txdatar )
σr ← Sign(sSKi, txdatar )
Let txn = (Bj, Bi, txdatas , σs , txdatar , σr )
send (“approveRecvTxn”, txid, txn) to FLedger
v
Figure 6: FLedger-hybrid protocol for Solidus with banks {Bi} and users {Ui}. For simplicity we omit operations to open and close accounts.
exists a simulator S such that for all PPT distinguishers D,
(cid:103)
(cid:17)
= 1
(cid:17)
= 1
(cid:103)(cid:12)(cid:12)(cid:12) ≤ negl(λ).
verifies the request, updates its PVORM, signs the update, and
forwards it to the recipient’s bank. That bank similarly verifies,
updates, and signs before posting the completed transaction to
FLedger. For simplicity the sending bank performs all updates and
sends them to the receiving bank. In practice both banks can update
their respective PVORMs in parallel as implied by Figure 3.
The protocol also contains operations for two other purposes:
handling transaction aborts described above and updating other
banks’ states when they post updates to FLedger.
5.2 Security Definition
To demonstrate the security of ProtSol, we need a notion of how a
secure Solidus protocol operates. We define this as an ideal func-
tionality FSol presented in Figure 7. For an adversary A and en-
vironment Z, we let HybridA,Z (λ) denote the transcript of A
when interacting with ProtSol. We let IdealS,Z (λ) be the transcript
produced by a simulator S when run in the ideal world with FSol.
This allows us to define security as follows.
Definition 5.1. We say that Solidus securely emulates FSol if for
all real-world PPT adversaries A and all environments Z, there
(cid:12)(cid:12)(cid:12) Pr
(cid:102)
D(cid:16)
− Pr
(cid:102)
D(cid:16)
HybridA,Z (λ)
IdealS,Z (λ)
This definition leads to the following theorem, which we prove in
Appendix C.
Theorem 5.2. The Solidus protocol ProtSol satisfies Definition 5.1
assuming a DDH-hard group in the ROM.
In order to prove Theorem 5.2 in the Universal Composability
(UC) framework [19], we assume Solidus employs only universally
composable (UC) NIZKs. Prior work [6] demonstrates that GSPs
can be transformed into UC-NIZKs by using the Fiat-Shamir heuris-
tic and including a ciphertext of the witness under a public key
provided by a common initializer. As Solidus already employs this
trusted initialization and includes ciphertexts of most operations
anyway, the performance impact of ensuring UC-NIZKs is minimal.
6 OPTIMIZATIONS
In addition parallelizing operation, there are several optimizations
which make Solidus more practical. Some of these optimizations
are only appropriate for certain use cases, but they may result
9
(cid:20)(cid:40)
(cid:41)k
i =1,
(cid:40)
Ui
(cid:40)
(cid:41)n
i =1,
Bi
U$
i
(cid:21)
(cid:41)
ℓ
i =1
FSol
Init
Initialize T to empty
Initialize V [Ui ] ← 0 for i ∈ [1, n]
On receive (“requestTxn”, Ur , $v ) from Us :
assert $v ≥ 0
Generate unique txid
T [txid] ← (Us , Ur , $v, “req”)
send txid to Us
send (“req”, txid, Us , bank(Ur ), $v ) to bank(Us )
On receive (“approveSendTxn”, txid) from Bs :
Retrieve (Us , Ur , $v, f ) ← T [txid]
assert f = “req” and Bs = bank(Us )
T [txid] ← (Us , Ur , $v, “aprv”)
send (“aprv”, txid, Bs , Ur , $v ) to bank(Ur )
On receive (“approveRecvTxn”, txid) from Br :
Retrieve (Us , Ur , $v, f ) ← T [txid]
assert f = “aprv” and Br = bank(Ur )
Remove T [txid] mapping
Retrieve $bs ← V [Us ], $br ← V [Ur ]
assert $bs ≥ $v or Us = U$
for some i
i
V [Us ] ← $bs − $v
V [Ur ] ← $br + $v
i , bank(Us ) otherwise
Let Ps = Us if Us = U$
Let Pr = Ur if Ur = U$
j , bank(Ur ) otherwise
broadcast (“postTxn”, txid, Ps → Pr ) to all banks
On receive (“abortTxn”, txid) from B:
if txid has been seen before // Can “abort” nonexistent transactions
Retrieve (Us , Ur , _, _) ← T [txid]
assert B = bank(Us ) or B = bank(Ur )
Remove T [txid] mapping
broadcast (“abortTxn”, txid, B) to all banks
// Reveal identities of asset notaries and banks
Figure 7: Ideal functionality for the Solidus system with banks
{Bi}, users {Ui}, and asset notaries {U $
i }. For simplicity we assume
a fixed set of accounts for each bank.
in significant speedups when applicable. We include the simpler
optimizations in our evaluation in Section 7.
6.1 Precomputing Randomization Factors
A large computational expense in Solidus is re-randomizing cipher-
texts while updating a PVORM. Fortunately, El Gamal allows us to
re-randomize ciphertexts by combining them with fresh encryp-
tions of the group identity. That is, in a group G = ⟨д⟩ with key pair
(pk = дsk, sk) and a ciphertext c = (α, β ), we can re-randomize c
by picking a random r ← Z|G | and computing c′ = (α · pkr , β · дr ).
Computing (pkr , дr ) only requires knowledge of the group G, the
generator д, and a bank’s public key pk, none of which change. This
means we can precompute these unit ciphertexts and re-randomize
by multiplying in a precomputed value.
Since the system can continue indefinitely, it must continue
generating these randomization factors. Many financial systems
have predictable high and low load times (e.g., very light traffic at
night), so they can utilize otherwise-idle hardware for this purpose
during low-traffic times. If the precomputation generates more
10
randomization pairs than the application consumes over a modest
time frame (e.g. a day), we can drastically improve performance.
6.2 Reducing Verification Overhead
As we see in Section 7, proof verification is quite expensive. In
the basic protocol, the ledger consensus nodes must each verify
every transaction. As more banks join the system this increases
the load on the consensus nodes—which may be the banks. By
strengthening trust assumptions slightly, we can omit much of
this online verification and increase performance. We present two
strategies that rely on different assumptions.
Threshold Verification. In the financial industry, there is often a
group of entities (e.g., large banks and regulators) who are generally
trusted. If a threshold number of these entities verify a transac-
tion, this could give all other consensus nodes—often other banks—
confidence that the transaction is valid, allowing them to accept it
without further verification. Once the threshold is reached, each
other node need only verify the signatures of the trusted entities
that verified the transaction, which is far faster than performing
a full verification. If the group of trusted entities is significantly
larger than the threshold or those entities have much more capacity
than others, this strategy will improve system scaling.
In some cases banks can be treated
Full Offline Verification.
as covert adversaries. That is, they will attempt to learn extra in-
formation, but they will subvert the protocol only if attribution is
impossible. This situation could arise if each Solidus bank is con-
trolled by a large commercial bank. While a bank may wish to learn
as much information as possible, the cost of being caught misbe-
having is high enough to deter attributable protocol deviations.
Under these assumptions we can omit online verification entirely.
The verifiability of a ledger-based system remains in place, so if a
bank submits an invalid transaction or proof, post hoc identification
of the faulty transaction and offending bank is trivial. Thus, in this
covert adversary model, banks will only submit valid transactions
and proofs, meaning that the ledger can accept transactions without
first verifying the associated proofs first.
6.3 Transaction Pipelining
Solidus requires sequential processing of transactions at a single
bank because PVORM updates must be sequential to generate valid
proofs. Given transactions T1 followed by T2, in order for B to
process T2 it needs the PVORM state following T1. It does not,
however, need the associated proofs. Therefore, if B assumes T1
will settle—because faults are rare—it can start processing T2 early
while generating proofs for T1. While this technique will not reduce
transaction latency, it can drastically increase throughput. More-
over, determining the updated PVORM state requires primarily
re-randomizing ciphertexts, making this optimization particularly
effective when combined with precomputation (Section 6.1).
When failures do occur, it impacts performance but not correct-
ness. If T1 aborts for any reason, T2 will not yet have settled since T1
would have to settle first. This means B can immediately identify
the problem and reprocess T2—and any following transactions—
without T1. This reprocessing may lead to significant, but tempo-
rary, performance degradation, meaning this optimization is only
B = 3
B = 2
Ver
Update
0.7
0.6
0.5
0.4
0.3
)
c
e
s
(
e
m