time hadoop jar UnComSequenceFileWriteFile.jar UnComSequence
FileWriteFile
real 0m47.668s
//这是使用压缩的程序
time hadoop jar ComSequenceFileWriteFile.jar ComSequenceFile
WriteFile
real 0m7.539s
上面记录了程序具体运行的时间，以毫秒为单位。可以看出，使用压缩的程序其执行效率要远远高于不使用压缩的程序。我们推测这个时间的差距主要是受硬盘写入时间的影响，再加上传输10MB的数据所花的时间要远远少于传输159MB的数据的。这就能很好地解释为什么在MapReduce程序中采用压缩会提高效率了（因为一般而言，这是Map的输出文件）。
7.4.2 MapFile类
MapFile的使用与SequenceFile类似，建立MapFile文件的程序如下：
MapFileWriteFile. java
package cn.edn.ruc.cloudcomputing.book.chapter07；
import java.io.IOException；
import java.net.URI；
import org.apache.hadoop.conf.Configuration；
import org.apache.hadoop.fs.*；
import org.apache.hadoop.io.*；
public class MapFileWriteFile{
private static final String[]myValue={
"hello world"，
"bye world"，
"hello hadoop"，
"bye hadoop"
}；
public static void main（String[]args）throws IOException{
String uri="你想要生成SequenceFile的位置"；
Configuration conf=new Configuration（）；
FileSystem fs=FileSystem.get（URI.create（uri），conf）；
IntWritable key=new IntWritable（）；
Text value=new Text（）；
MapFile.Writer writer=null；
try{
writer=new MapFile.Writer（conf, fs, uri, key.get
Class（），value.getClass（））；
for（int i=0；i＜500；i++）{
key.set（i）；
value.set（myValue[i%myValue.length]）；
writer.append（key, value）；
}
}finally{
IOUtils.closeStream（writer）；
}
}
}
这个程序与建立SequenceFile文件的程序极其类似，这里就不详述了。与SequenceFile只生成一个文件不同，这个程序生成的是一个文件夹。如下所示：
-rw-r--r--**supergroup 16018*/user/root/MapFileOutput/data
-rw-r--r--**supergroup 227*/user/root/MapFileOutput/index
其中data是存储的数据，即MapFile文件（经过排序SequenceFile文件），index就是索引了，在这个程序中，其内容如下：
0 128
128 4200
256 8272
384 12344
可以看出，索引是按每128个键建立的，这个值可以通过修改io.map.index.interval的大小来修改。key值后面是偏移量，用于记录key的位置。
读取MapFile文件的程序也很简单，其内容如下所示：
package cn.edn.ruc.cloudcomputing.book.chapter07；
import java.io.IOException；
import java.net.URI；
import org.apache.hadoop.conf.Configuration；
import org.apache.hadoop.fs.FileSystem；
import org.apache.hadoop.io.IOUtils；
import org.apache.hadoop.io.IntWritable；
import org.apache.hadoop.io.MapFile；
import org.apache.hadoop.io.Writable；
import org.apache.hadoop.io.WritableComparable；
import org.apache.hadoop.util.ReflectionUtils；
public class MapFileReadFile{
public static void main（String[]args）throws IOException{
String uri="你想要读取的MapFile文件位置"；
Configuration conf=new Configuration（）；
FileSystem fs=FileSystem.get（URI.create（uri），conf）；
MapFile.Reader reader=null；
try{
reader=new MapFile.Reader（fs, uri, conf）；
WritableComparable key=（WritableComparable）
ReflectionUtils.newInstance（reader.getKeyClass（），conf）；
Writable value=（Writable）ReflectionUtils.
newInstance（reader.getValueClass（），conf）；
while（reader.next（key, value））{
System.out.printf（"%s\t%s\n"，key, value）；
}
reader.get（new IntWritable（7），value）；
System.out.printf（"%s\n"，value）；
}finally{
IOUtils.closeStream（reader）；
}
}
}
其特别之处是，MapFile可以查找单个键所对应的value值，见下面这段话：
执行这个操作时，MapFile.Reader（）需要先把index读入内存中，然后执行一个简单的二叉搜索找到数据，MapFile.Reader（）在查找时，会先在索引文件中找到小于我们想要找的key值的索引key值，然后再到data文件中向后查找。
大型MapFile文件的索引通常会占用很大的内存，这时我们可以通过重设索引、增加索引间隔的方法降低索引文件的大小，但是重设索引是一个很麻烦的事情。Hadoop提供了另一个非常有效的方法，就是读取索引文件时，可以每隔几个索引key再读取索引key值，这样就可以有效地降低读入内存的索引文件的大小。至于跳过key的个数是通过io.map.index.skip来设置的。
7.4.3 ArrayFile、SetFile和BloomMapFile
ArrayFile继承自MapFile，它保存的是从Integer到value的映射关系。这一点从它的代码实现上也可以看出：
public Writer（Configuration conf, FileSystem fs，
String file, Class＜?extends Writable＞valClass）
throws IOException{
super（conf, fs, file, LongWritable.class, valClass）；
}
public static class Reader extends MapFile.Reader{
private LongWritable key=new LongWritable（）；
public Reader（FileSystem fs, String file, Configuration conf）throws IOException{
super（fs, file, conf）；
}
}
从上面的代码中看出，在写出时，key的数据类型是LongWritable，而不是MapFile中的WritableComparator.get（keyClass），在读入的时候，可以直接定义成LongWriable。ArrayFile更加具体的定义缩小了其适用范围，但是也降低了使用的难度，提高了使用的准确性。
SetFile同样继承自MapFile，它同Java中的set类似，仅仅是一个Key的集合，而没有任何value。
public Writer（Configuration conf, FileSystem fs, String dirName，
Class＜?extends WritableComparable＞keyClass，
SequenceFile.CompressionType compress）
throws IOException{
this（conf, fs, dirName, WritableComparator.get（keyClass），compress）；
}
public void append（WritableComparable key）throws IOException{
append（key, NullWritable.get（））；
}
public Reader（FileSystem fs, String dirName, WritableComparator comparator，
Configuration conf）
throws IOException{
super（fs, dirName, comparator, conf）；
}
public boolean seek（WritableComparable key）
throws IOException{
return super.seek（key）；
}
public boolean next（WritableComparable key）
throws IOException{
return next（key, NullWritable.get（））；
}
从上面SetFile的实现代码（读、插入、写、查找、下一个key）也可以看出，它仅仅是一个key的集合，而非映射。需要注意的是向SetFile中插入key时，必须保证此key比set中的key都大，即SetFile实际上是一个key的有序集合。
BloomMapFile没有从MapFile继承，但是它的两个核心内部类Writer/Reader均继承自MapFile对应的两个内部类，其在实际使用中发挥的作用也和MapFile类似，只是增加了过滤的功能。它使用动态的Bloom Filter（请参见本书第5章）来检查key是否包含在预定的key集合内。BloomMapFile的数据结构有key/value的映射和一个Bloom Filter，在写出数据时先根据配置初始化Bloom Fliter，将key加入Bloom Filter中，然后写出key/value数据，最后在关闭输出流时写出Bloom Filter，具体可见代码：
public Writer（Configuration conf, FileSystem fs, String dirName，
WritableComparator comparator, Class valClass）throws IOException{
super（conf, fs, dirName, comparator, valClass）；
this.fs=fs；
this.dir=new Path（dirName）；
initBloomFilter（conf）；
}
private synchronized void initBloomFilter（Configuration conf）{
……
}
@Override
public synchronized void append（WritableComparable key, Writable val）
throws IOException{
……
bloomFilter.add（bloomKey）；//向BloomFilter插入数据