nl
The remaining issues are to derive Qhigh
nl (l), where 0 ≤ l ≤ nl, E[N high
nh, Qlow
derivation details are shown in [25].
1400
1200
1000
800
600
400
200
0
i
s
r
e
v
e
c
e
r
f
o
r
e
b
m
u
n
0
20
40
N=2048, z=6
proactivity factor=1.0
proactivity factor=1.1
proactivity factor=1.2
proactivity factor=1.5
60
120
block size k of a rekey message
100
80
140
160
180
Figure 16: Expected number of receivers satisfying C0
To see the beneﬁt of the sparseness rekey workload, Figure 16
shows the number of receivers satisfying C0 at the end of the ﬁrst
round. Since this number represents the reduction of the number of
receivers when we convert from Protocol I to Protocol II, it reﬂects
the savings of the sparseness rekey workload. We observe from this
ﬁgure that when message block size k is large, and when proactivity
factor ρ is small, the performance of a rekey multicast is equal to
the performance of a conventional reliable multicast with a much
smaller number of receivers.
3.3.3 Bandwidth overhead
We analyze in this section the bandwidth overhead of rekey trans-
port. Given nh high loss and nl low loss receivers, we let O(nh, nl)
denote the random variable of bandwidth overhead when receivers
run Protocol I. Let E[O(nh, nl)] denote the mean value of this
random variable. Given h high loss and l low loss receivers, we let
OII (h, l) denote the random variable of bandwidth overhead when
receivers run Protocol II. Let E[OII (h, l)] denote the mean of this
random variable. Given the conversion from Protocol I to Protocol
II, we have that:
E[O(nh, nl)] = Xh,l
nh (h) · Qlow
Qhigh
nl (l)E[OII (h, l)]
(2)
For given h and l, we can derive OII (h, l) by considering only
Protocol II, and the detailed derivation of E[OII (h, l)] is shown
in [25].
has better transport bandwidth efﬁciency, to reliably transport the
rekey message, the key server still needs to send a large amount of
repair packets. For a smaller rekey message, the overhead is even
higher. For example, for a rekey message with block size 20, the
key server needs to send about 14 (= (1.7− 1)· 20) repair packets.
3.3.4 Rekey transport latency
We measure the latency of rekey transport by the number of
rounds to deliver a rekey message to all receivers. It is intuitive
that rekey transport latency will also depend on the block size k of
a rekey message and proactivity factor ρ.
Figure 19 shows the simulation results for the number of rounds
to transport rekey messages with different message block size k at
different proactivity factor ρ. We make the following observations.
First, we observe that at a large proactivity factor ρ, the number of
rounds to transport a rekey message with a large block size k can
be smaller than that of a smaller rekey message. This is somehow
counter intuitive because we expect the number of rounds to trans-
port a large rekey message should always be larger than that of a
smaller rekey message. To explain this result, we notice that for a
rekey message with a large block size k, when proactivity factor ρ
is large, the probability that a receiver will receive at least k out of
the total (cid:10)kρ(cid:11) packets becomes higher; therefore, rekey transport
latency reduces. On the other hand, if proactivity factor ρ is small,
the number of rounds to transport a large rekey message is larger
than that of a smaller rekey message.
N=2048, z=6
proactivity factor=1.0
proactivity factor=1.1
proactivity factor=1.2
proactivity factor=1.5
0
20
40
60
120
block size k of a rekey message
100
80
140
160
180
s
d
n
u
o
r
f
o
r
e
b
m
u
n
5
4
3
2
1
0
0
20
40
N=2048, z=6
proactivity factor=1.0
proactivity factor=1.1
proactivity factor=1.2
proactivity factor=1.5
60
120
block size k of a rekey message
100
80
140
160
180
Figure 17: Overhead E[O(nh, nl)]
N=2048, z=6
proactivity factor=1.0
proactivity factor=1.1
proactivity factor=1.2
proactivity factor=1.5
Figure 19: Rekey transport latency by ns simulation
Let R(nh, nl) denote the random variable of the number of rounds
to rekey nh high loss and nl low loss receivers when receivers run
Protocol I. Let RII (h, l) denote the random variable of the num-
ber of rounds to transport k packets to h high loss and l low loss
receivers when receivers run Protocol II. Similar to Equation (2),
we have
d
a
e
h
r
e
v
o
i
t
h
d
w
d
n
a
b
d
a
e
h
r
e
v
o
h
t
d
w
d
n
a
b
i
2.1
2
1.9
1.8
1.7
1.6
1.5
1.4
1.3
2.1
2
1.9
1.8
1.7
1.6
1.5
1.4
1.3
0
20
40
60
120
block size k of a rekey message
100
80
140
160
180
Figure 18: Overhead by ns simulation
Figure 17 shows our analytical results of rekey transport band-
width overhead as functions of the block size k of a rekey message
and proactivity factor ρ. To validate our analysis, Figure 18 shows
simulation results using the ns simulator. Comparing both ﬁgures,
we observe that our analytical results match with simulation results
very well over a wide range of message block size and proactivity
factor. We observe from Figure 17 that even with the sparseness
property, the bandwidth overhead of reliable rekey transport is still
high. Even for a rekey message with a large block size k, which
E[R(nh, nl)] = Xh,l
Qhigh
nh (h)Qlow
nl (l)E[RII (h, l)]
(3)
Therefore, we again convert the analysis from Protocol I to Pro-
tocol II. However, an exact calculation of the number of rounds
to transport a rekey message requires complicated calculations in-
volving modeling of transition states. Therefore, we derive an up-
per bound on E[RII (h, l)]. The derivation of the upper bound is
shown in [25].
3.3.5 How to determine proactivity factor ρ?
In our previous investigations of bandwidth overhead and rekey
transport latency, we have considered the impacts of both the block
size k of a rekey message and proactivity factor ρ. Given a rekey
subtree and a key assignment algorithm, we know that block size
k is determined. The proactivity factor ρ, however, is a protocol
parameter of a rekey transport protocol. We next discuss how to
determine ρ.
To determine ρ, we observe that the key server can reduce rekey
transport latency and the number of receiver feedbacks by increas-
ing proactivity factor ρ. When ρ is large, the key server will send
more proactive repair packets in the ﬁrst round; therefore, more
receivers will receive their packets in the ﬁrst round, less receivers
will send feedback packets to the key server, and the key server will
send less repair packets in the following rounds. From Figure 20,
for example, we observe that for a rekey message with block size
20, when the key server increases ρ from 1 to 1.7, rekey transport
latency is reduced from 5 to about 1. Therefore, the key server can
reduce rekey transport latency by increasing ρ. However, we also
notice that the key server may set ρ to be too large and therefore
increase bandwidth overhead. From Figure 20, for example, we ob-
serve that if the key server sets ρ to be higher than 1.7, then band-
width overhead is dominated by proactivity factor and increases
linearly with ρ while rekey transport latency stays ﬂat.
d
a
e
h
r
e
v
o
h
t
i
d
w
d
n
a
b
5
4
3
2
1
0
0.8
N=2048, z=6, k=20
overhead
latency
5
4
3
2
1
s
d
n
u
o
r
f
o
r
e
b
m
u
n
1
1.2
1.4
1.6
1.8
2
2.2
2.4
0
2.6
proactivity factor
Figure 20: Overhead and latency as function of ρ
Given the above observations, we know that the key server should
choose ρ such that rekey transport latency is close to 1 while the
bandwidth overhead curve still stays ﬂat. For example, in Fig-
ure 20, a good choice of ρ will be 1.7.
In real implementation,
however, the key server does not know the loss properties of the re-
ceivers (for example, independent loss assumption tends to overes-
timate the amount of redundancy needed when losses are shared [13]),
and the block size of a rekey message may vary at different rounds.
Thus, the key server should dynamically adjust ρ at each round.
For example, in one type of strategy, the key server can adjust ρ us-
ing stochastic or AIMD (additive-increase-multiplicative-decrease)
control so that rekey transport latency is close to a reference value,
say 1 to 2 rounds. In another type of strategy, which we proposed
and investigated in [26], the key server adjusts ρ in a way such that
the number of receivers sending feedbacks is close to a small value,
say 5% of the receivers. For our following performance analysis,
we determine ρ by choosing the largest proactivity factor that still
gives the lowest bandwidth overhead.
4. TRADEOFFS OF BANDWIDTH OVER-
HEAD AND REKEY INTERVAL
In Section 2, given J join and L leave requests in a rekey in-
terval for a group with N users, we have investigated the mark-
ing algorithm to generate a rekey subtree. Given a rekey subtree,
in Section 3, we have investigated rekey transport, and evaluated
bandwidth overhead. Combining the results of Section 2 and Sec-
tion 3, given J, L, and N, we can derive bandwidth overhead.
Given group size N and user behaviors, we also know that J and
L will be a function of rekey interval T . Thus, rekey interval T
serves as a system design parameter that a group key management
system can use to control bandwidth overhead. Furthermore, given
user behaviors and system constraints, it is possible that a group
key management cannot ﬁnd a suitable T for a given group size N.
Under this scenario, the group key management system needs to