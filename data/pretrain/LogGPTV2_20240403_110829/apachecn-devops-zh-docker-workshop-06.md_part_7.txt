    b3f000eb4699   bridge           bridge
      local
    df5ebd75303e   docker_gwbridge  bridge
      local
    f52b4a5440ad   host             host
      local
    8hm1ouvt4z7t   ingress          overlay
      swarm
    9bed60b88784   none             null
      local
    q354wyn6yvh4   weavenet1        store/weaveworks/net-plugin:2.5.2
      swarm
    ```
5.  Execute the `docker network ls` command on the `Machine2` node to ensure that the `weavenet1` network is present on that machine as well:
    ```
    Machine2 ~$ docker network ls 
    ```
    `weavenet1`网络应列出:
    ```
    NETWORK ID    NAME              DRIVER
      SCOPE
    b3f000eb4699  bridge            bridge
      local
    df5ebd75303e  docker_gwbridge   bridge
      local
    f52b4a5440ad  host              host
      local
    8hm1ouvt4z7t  ingress           overlay
      swarm
    9bed60b88784  none              null
      local
    q354wyn6yvh4  weavenet1         store/weaveworks/net-plugin:2.5.2
      swarm
    ```
6.  On the `Machine1` node, create a service called `alpine-weavenet1` that uses the `weavenet1` network using the `docker service create` command:
    ```
    Machine1 ~$ docker service create -t --replicas 1 --network weavenet1 --name alpine-weavenet1 alpine:latest
    ```
    基于文本的进度条将显示服务的部署状态。它应该在没有任何问题的情况下完成:
    ```
    overall progress: 1 out of 1 tasks 
    1/1: running   [===========================================>]
    verify: Service converged 
    ```
7.  Use the `docker service create` command again to create another service in the `weavenet1` network called `alpine-weavenet2`:
    ```
    Machine1 ~$ docker service create -t --replicas 1 --network weavenet1 --name alpine-weavenet2 alpine:latest
    ```
    基于文本的进度条将再次显示，指示服务创建的状态:
    ```
    overall progress: 1 out of 1 tasks 
    1/1: running   [===========================================>]
    verify: Service converged 
    ```
8.  Run the `docker ps` command to validate that an Alpine container is successfully running on each node in the cluster:
    `Machine1` :
    ```
    Machine1 ~$ docker ps
    ```
    `Machine2` :
    ```
    Machine2 ~$ docker ps
    ```
    其中一个服务容器应该在两台机器上启动并运行:
    `Machine1` :
    ```
    CONTAINER ID    IMAGE           COMMAND      CREATED
      STATUS              PORTS               NAMES
    acc47f58d8b1    alpine:latest   "/bin/sh"    7 minutes ago
      Up 7 minutes                            alpine-weavenet1.1.zo5folr5yvu6v7cwqn23d2h97
    ```
    `Machine2`:
    ```
    CONTAINER ID    IMAGE           COMMAND     CREATED
      STATUS              PORTS        NAMES
    da2a45d8c895    alpine:latest   "/bin/sh"   4 minutes ago
      Up 4 minutes                     alpine-weavenet2.1.z8jpiup8yetj
    rqca62ub0yz9k
    ```
9.  Use the `docker exec` command to access an `sh` shell inside the `weavenet1.1` container instance. Make sure to run this command on the node in the swarm cluster that is running this container:
    ```
    Machine1 ~$ docker exec -it alpine-weavenet1.1.zo5folr5yvu6v7cwqn23d2h97 /bin/sh
    ```
    这将使您进入容器内部的根外壳:
    ```
    / #
    ```
10.  Use the `ifconfig` command to view the network interfaces present inside this container:
    ```
    / # ifconfig
    ```
    这将显示一个新命名的网络接口`ethwe0`。Weave Net 核心网络策略的一个核心部分是在容器内创建自定义命名的接口，以便于识别和故障排除。应该注意的是，该接口从我们提供的子网中分配了一个 IP 地址作为配置参数:
    ```
    ethwe0  Link encap:Ethernet  HWaddr AA:11:F2:2B:6D:BA  
            inet addr:10.1.1.3  Bcast:10.1.1.255  Mask:255.255.255.0
            UP BROADCAST RUNNING MULTICAST  MTU:1376  Metric:1
            RX packets:37 errors:0 dropped:0 overruns:0 frame:0
            TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
            collisions:0 txqueuelen:0 
            RX bytes:4067 (3.9 KiB)  TX bytes:0 (0.0 B)
    ```
11.  From inside this container, ping the `alpine-weavenet2` service by name, using the `ping` utility:
    ```
    ping alpine-weavenet2
    ```
    您应该会看到来自`alpine-weavenet2`服务的解析 IP 地址的响应:
    ```
    64 bytes from 10.1.1.4: seq=0 ttl=64 time=3.430 ms
    64 bytes from 10.1.1.4: seq=1 ttl=64 time=1.541 ms
    64 bytes from 10.1.1.4: seq=2 ttl=64 time=1.363 ms
    64 bytes from 10.1.1.4: seq=3 ttl=64 time=1.850 ms
    ```
    注意
    由于 Docker 和 Docker Swarm 的最新版本中 Docker libnetwork 栈的最新更新，按名称 ping 服务:`alpine-weavenet2`可能不起作用。要证明网络按预期工作，请尝试直接 ping 通容器的名称:`alpine-weavenet2.1.z8jpiup8yetjrqca62ub0yz9k`–请记住，此容器的名称在您的实验室环境中会有所不同。
12.  Try pinging Google DNS servers (`8.8.8.8`) on the open internet from these containers as well to ensure that these containers have internet access:
    ```
    ping 8.8.8.8
    ```
    您应该会看到响应返回，表明这些容器可以访问互联网:
    ```
    / # ping 8.8.8.8
    PING 8.8.8.8 (8.8.8.8): 56 data bytes
    64 bytes from 8.8.8.8: seq=0 ttl=51 time=13.224 ms
    64 bytes from 8.8.8.8: seq=1 ttl=51 time=11.840 ms
    type exit to quit the shell session in this container.
    ```
13.  Use the `docker service rm` command to remove both services from the `Machine1` node:
    ```
    Machine1 ~$ docker service rm alpine-weavenet1
    Machine1 ~$ docker service rm alpine-weavenet2
    ```
    这将删除两个服务，停止并删除容器实例。
14.  Delete the Weave Net network that was created by running the following command:
    ```
    Machine1 ~$ docker network rm weavenet1
    ```
    编织网络应该被删除。
在健壮的容器化网络概念系统中，Docker 有大量的网络驱动程序来覆盖您的工作负载所需的几乎任何环境。但是，对于默认 Docker 网络驱动程序之外的所有用例，Docker 支持几乎任何可能出现的网络条件的第三方定制驱动程序。第三方网络驱动程序允许 Docker 与各种平台甚至跨多个云提供商进行灵活的集成。在本练习中，我们查看了如何安装和配置 Weave Net 网络插件，以及如何在 Docker 集群中创建简单的服务来利用这个网络。
在下面的活动中，您将使用各种 Docker 网络驱动程序，应用本章中所学的知识来部署多容器基础架构解决方案。这些容器将使用相同主机上的不同 Docker 网络驱动程序进行通信，甚至在 Docker 群配置中跨多个主机进行通信。
## 活动 6.01:利用 Docker 网络驱动程序
在本章的前面，我们研究了各种类型的 Docker 网络驱动程序，以及它们如何以不同的方式发挥作用，以带来不同程度的网络功能，从而在您的容器环境中提供功能。在本练习中，您将在 Docker `bridge`网络中部署全景徒步应用的示例容器。然后，您将在`host`网络模式下部署一个辅助容器，作为监控服务器，并能够使用`curl`验证应用是否按预期运行。
执行以下步骤完成本活动:
1.  使用自定义子网和网关 IP 创建自定义 Docker `bridge`网络。
2.  在该`bridge`网络中部署名为`webserver1`的 NGINX 网络服务器，将容器上的转发端口`80`暴露给主机上的端口`8080`。
3.  在`host`联网模式下部署一个 Alpine Linux 容器，作为监控容器。
4.  使用 Alpine Linux 容器`curl`到 NGINX 网络服务器并得到响应。
**预期输出:**
完成活动后，当您直接连接到端口`80`上的转发端口`8080`和`webserver1`容器的 IP 地址时，您应该会得到以下输出:
![Figure 6.26: Accessing the NGINX web server from the IP address of the container instance ](img/B15021_06_26.jpg)
图 6.26:从容器实例的 IP 地址访问 NGINX 网络服务器
注意
此活动的解决方案可以通过[这个链接](16.html#_idTextAnchor331)找到。
在下一个活动中，我们将了解如何利用 Docker 网络为全景徒步旅行应用提供横向可扩展性。通过在多台主机上部署全景徒步，我们可以确保可靠性和持久性，并利用环境中多个节点的系统资源。
## 活动 6.02:覆盖网络在行动
在本章中，您已经看到了`overlay`网络在集群主机之间部署多个容器并在它们之间建立直接网络连接时是多么强大。在本练习中，您将重新访问双节点 Docker 群集，并从全景徒步应用创建服务，该应用将使用两个主机之间的 Docker DNS 进行连接。在这种情况下，不同的微服务将在不同的 Docker 群主机上运行，但仍然能够利用 Docker `overlay`网络直接相互通信。
要成功完成本活动，请执行以下步骤:
1.  使用自定义子网和网关的 Docker `overlay`网络
2.  一个名为`trekking-app`的应用 Docker 集群服务使用了一个 Alpine Linux 容器
3.  一个名为`database-app`的数据库 Docker 群服务使用 PostgreSQL 12 容器(提供默认凭证的额外信用)
4.  证明`trekking-app`服务可以使用`overlay`网络与`database-app`服务进行通信
**预期输出:**
`trekking-app`服务应该能够与`database-app`服务进行通信，这可以通过 ICMP 回复来验证，例如:
```
PING database-app (10.2.0.5): 56 data bytes
64 bytes from 10.2.0.5: seq=0 ttl=64 time=0.261 ms
64 bytes from 10.2.0.5: seq=1 ttl=64 time=0.352 ms
64 bytes from 10.2.0.5: seq=2 ttl=64 time=0.198 ms
```
注意
此活动的解决方案可以通过[这个链接](16.html#_idTextAnchor333)找到。
# 总结
在本章中，我们研究了与微服务和 Docker 容器相关的网络的许多方面。Docker 配备了许多驱动程序和配置选项，用户可以使用它们来调整他们的容器网络在几乎任何环境中的工作方式。通过部署正确的网络和正确的驱动程序，强大的服务网状网络可以快速旋转，以实现容器到容器的访问，而无需脱离任何物理 Docker 主机。甚至可以创建绑定到主机网络结构的容器，以利用底层网络基础设施。
可以说，Docker 中最强大的网络功能是跨 Docker 主机集群创建网络的能力。这使我们能够在主机之间快速创建和部署水平扩展应用，以实现高可用性和冗余。通过利用底层网络，`overlay`集群内的网络允许容器通过利用强大的 Docker DNS 系统直接联系运行在其他集群主机上的容器。
在下一章中，我们将探讨强大的容器化基础架构的下一个支柱:存储。通过了解容器存储如何用于有状态应用，可以构建极其强大的解决方案，不仅包括容器化的无状态应用，还包括容器化的数据库服务，这些服务可以像基础架构中的其他容器一样轻松地进行部署、扩展和优化。