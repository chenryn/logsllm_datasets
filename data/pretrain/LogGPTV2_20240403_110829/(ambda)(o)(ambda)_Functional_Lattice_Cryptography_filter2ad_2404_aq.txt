-- apply E-linear function to constant term c0
c0â€™ = evalLin fâ€™q c0
-- apply E-linear function to c1 via key-switching
c1s = coeffsPow c1 :: [Cyc t eâ€™ zqâ€™]
c1sâ€™ = zipWith switch hints (embed  c1s)
c1â€™ = sum c1sâ€™
return CT MSD 0 s $ P.const c0â€™ + c1â€™)
Here, tunnelHint is a function that outputs the hints ğ»ğ‘— with respect to the powerful basis
as deï¬ned in subsection 4.2.3. The rest of the algorithm matches exactly with the steps
114
outlined in that section: we ï¬rst lift and extend the linear function, compute ğ¿â€²(ğ‘0), and
apply key switching with the appropriate hint to the powerful basis coefï¬cients of ğ‘1. Finally,
we sum the results and produce the output ciphertext over ğ‘†ğ‘.
4.4 Evaluation
Recall that Î›âˆ˜ğœ† primarily aims to be a general, modular, and safe framework for lattice
cryptography, while also achieving acceptable performance. Î›âˆ˜ğœ† has proven to be extremely
ï¬‚exible and has been used (at least) for the following purposes:
â€¢ implementing advanced features of somewhat-homomorphic encryption (section 4.3);
â€¢ and creating a homomorphic compiler for homomorphic encryption (chapter 5);
â€¢ implementing the pseudorandom functions of [BPR12; BP14]; (chapter 6);
â€¢ generating RLWE/RLWR cryptanalytic challenges (chapter 7);
â€¢ exploring opportunities for parallelism of lattice cryptography using vector (SIMD)
instruction sets (the C++ tensor backend), multi-core CPUs (the Repa tensor backend),
and GPUs (currently in progress);
â€¢ masterâ€™s thesis on FHE [Muk16];
â€¢ and implementing identity-based encryption [Ret17].
While Î›âˆ˜ ğœ†â€™s modularity and static safety properties are demonstrated elsewhere in the
paper, here we evaluate two of its lower-level characteristics: code quality and runtime
performance.
For comparison, we also give a similar analysis for HElib [HS], which is Î›âˆ˜ğœ†â€™s closest
analogue in terms of scope and features. (Recall that HElib is a leading implementation
of homomorphic encryption.) We emphasize two main caveats regarding such a compar-
ison: ï¬rst, while Î›âˆ˜ ğœ† and HElib support many common operations and features, they
115
are not functionally equivalentâ€”e.g., Î›âˆ˜ğœ† supports ring-switching, error sampling, and
certain gadget operations that HElib lacks, while HElib supports ring automorphisms and
sophisticated plaintext â€œshufï¬‚ingâ€ operations that Î›âˆ˜ğœ† lacks. Second, Î›âˆ˜ğœ†â€™s host language
(Haskell) is somewhat higher-level than HElibâ€™s (C++), so any comparisons of code quality
or performance will necessarily be â€œapples to oranges.â€ Nevertheless, we believe that such a
comparison is still meaningful and informative, as it quantiï¬es the relative trade-offs of the
two approaches in terms of software engineering values like simplicity, maintainability, and
performance.
Summary. Our analysis shows that Î›âˆ˜ğœ† offers high code quality, with respect to both the
size and complexity. In particular, Î›âˆ˜ğœ†â€™s code base is about 7â€“8 times smaller than HElibâ€™s.
Also, Î›âˆ˜ ğœ† currently offers good performance, always within an order of magnitude of
HElibâ€™s, and we expect that it can substantially improve with focused optimization. Notably,
Î›âˆ˜ ğœ†â€™s C++ backend is already faster than HElib in Chinese Remainder Transforms for
non-power-of-two cyclotomic indices with small prime divisors, due to the use of better
algorithms associated with the â€œtensoredâ€ representations. For example, a CRT for index
ğ‘š = 2633 (of dimension ğ‘› = 576) takes about 99 ğœ‡s in Î›âˆ˜ğœ†, and 153 ğœ‡s in HElib on our
benchmark machine (and the performance gap grows when more primes are included).
4.4.1 Source Code Analysis
We analyzed the source code of all â€œcoreâ€ functions from Î›âˆ˜ğœ† and HElib, and calculated
a few metrics that are indicative of code quality and complexity: actual lines of code,
number of functions, and cyclotomatic complexity [McC76]. â€œCoreâ€ functions are any
that are called (directly or indirectly) by the librariesâ€™ intended public interfaces. These
include, e.g., algebraic, number-theoretic, and cryptographic operations, but not unit tests,
benchmarks, etc. Note that HElib relies on NTL [Sho06] for the bulk of its algebraic
operations (e.g., cyclotomic and ï¬nite-ï¬eld arithmetic), so to give a fair comparison we
116
include only the relevant portions of NTL with HElib, referring to their combination as
HElib+NTL. Similarly, Î›âˆ˜ğœ† includes a Tensor backend written in C++ (along with a pure
Haskell one), which we identify separately in our analysis.
Source Lines of Code
A very basic metric of code complexity is program size as measured by source lines of code
(SLOC). We measured SLOC for Î›âˆ˜ğœ† and HElib+NTL using Ohcount [Bla14] for Haskell
code and metriculator [KW11] for C/C++ code. Metriculator measures logical source lines
of code, which approximates the number of â€œexecutable statements.â€ By contrast, Ohcount
counts physical lines of code. Both metrics exclude comments and empty lines, so they do
not penalize for documentation or extra whitespace. While the two metrics are not identical,
they provide a rough comparison between Haskell and C/C++ code.
Table 4.1 shows the SLOC counts for Î›âˆ˜ğœ† and HElib+NTL. Overall, Î›âˆ˜ğœ† consists of
only about 5,000 lines of code, or 4,200 if we omit the C++ portion (whose functionality is
redundant with the Haskell code). By contrast, HElib+NTL consists of about 7â€“8 times as
much code.
Table 4.1: Source lines of code for Î›âˆ˜ğœ† and HElib+NTL.
Codebase
SLOC
Total
Î›âˆ˜ğœ†
HElib+NTL
Haskell
C++
4,257
HElib
734
NTL
4,991
14,709
20,073
34,782
Cyclomatic Complexity and Function Count
McCabeâ€™s cyclomatic complexity (CC) [McC76] counts the number of â€œlinearly independentâ€
execution paths through a piece of code (usually, a single function), using the control-
ï¬‚ow graph. The theory behind this metric is that smaller cyclomatic complexity typically
117
corresponds to simpler code that is easier to understand and test thoroughly. McCabe
suggests limiting the CC of functions to ten or less.
Results. Table 4.2 gives a summary of cyclomatic complexities in Î›âˆ˜ğœ† and HElib+NTL.
A more detailed breakdown is provided in Figure 4.3. In both codebases, more than 80 % of
the functions have a cyclomatic complexity of 1, corresponding to straight-line code having
no control-ï¬‚ow statements; these are omitted from Figure 4.3.
Table 4.2: Number of functions per argon grade: cyclomatic complexities of 1â€“5 earn an
â€˜A,â€™ 6â€“10 a â€˜B,â€™ and 11 or more a â€˜C.â€™
Codebase
A
B
C Total
Î›âˆ˜ğœ†
1,234
14
5
1,253
HElib+NTL 6,850
159
69
7,078
Only three Haskell functions and two C++ functions in Î›âˆ˜ğœ† received a grade of â€˜C.â€™ The
Haskell functions are: adding Cyc elements (CC=23); multiplying Cyc elements (CC=14);
and comparing binary representations of positive integers, for promotion to the type level
(CC=13). In each of these, the complexity is simply due to the many combinations of cases
for the representations of the inputs (see subsection 3.5.2). The two C++ functions are the
inner loops of the CRT and DFT transforms, with CC 16 and 18, respectively. This is due
to a case statement that chooses the appropriate unrolled code for a particular dimension,
which we do for performance reasons.
For comparison, HElib+NTL has many more functions than Î›âˆ˜ğœ† (see Table 4.2), and
those functions tend to be more complex, with 68 functions earning a grade of â€˜Câ€™ (i.e., CC
more than 10).
118
385
400
350
s
n
o
i
t
c
n
u
f
f
o
r
e
b
m
u
N
300
s
n
o
i
t
c
n
u
f
250
200
f
o
r
e
b
150
m
u
N
100
50
0
Î›âˆ˜ğœ†: Haskell
Î›âˆ˜ğœ†: C++
HElib
NTL
137
147
100
32
28
19
65
58
42
41
5
3
4
22
22
2
0
15
9
8
1
0
0
10
5
2
3
4
5
7
6
10
Cyclomatic Complexity
Cyclomatic Complexity
8
9
11
12
13 14+
Figure 4.3: Cyclomatic complexity (CC) of functions in Î›âˆ˜ğœ† and HElib+NTL. The case
CC=1 accounts for more than 80% of the functions in each codebase, and is suppressed.
4.4.2 Performance
Here we report on the runtime performance of Î›âˆ˜ğœ†. As a general-purpose library, we do not
expect it to be competitive with highly optimized (but inï¬‚exible) C implementations like
SWIFFT [Lyu+08] and BLISS [Duc+13], but we aim for performance in the same league as
higher-level libraries like HElib.
Here we give microbenchmark data for various common operations and parameter
sets, to show that performance is reasonable and to establish a baseline for future work.
All benchmarks were run by the standard Haskell benchmarking tool criterion [OSu14]
on a mid-2012 model Asus N56V laptop with 2.3GHz Core i7-3610QM CPU and 6 GB
1600MHz DDR3 RAM, using GHC 8.0.1. All moduli in our benchmarks are smaller than 32
bits, so that all mod-ğ‘ arithmetic can be performed naÃ¯vely in 64-bit registers.
We benchmarked the two Tensor backends currently included in Î›âˆ˜ğœ†: the â€œCTâ€ backend
is sequential and written in relatively unoptimized C++. The â€œRTâ€ backend uses the Repa
119
array library [Kel+10; Lip+12]. For operations that Î›âˆ˜ğœ† and HElib have in common, we
also include HElib benchmarks.
Most of our optimization efforts have been devoted to the CT backend, which partially
explains the poor performance of the Repa backend; we believe that similarly tuning RT
could speed up benchmarks considerably. However, RT performance is currently limited
by the architecture of our tensor DSL, which is blocking many compiler optimizations.
Speciï¬cally, the higher-rank types that make the DSL work for arbitrary cyclotomic indices
also make specialization, inlining, and fusion opportunities much more difï¬cult for the
compiler to discover. Addressing this issue to obtain a fast and general pure-Haskell
implementation is an important problem for future work.
Cyclotomic Ring Operations