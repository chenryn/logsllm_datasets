## 数据库的未来 - HTAP，软件、硬件、云生态的融合   
### 作者        
digoal        
### 日期        
2017-05-26         
### 标签        
PostgreSQL , GPU , FPGA , CPU , TPU , PL/language , 科研 , 嵌入式计算 , UDF , CUDA , 数据库嵌入式编程 , 流式计算 , 科学计算 , 软硬一体 , PostGIS , 点云 , 开发者生态 , python library , CRAN , R           
----        
## 背景       
数据库经过了几十年的发展，未来的路怎么走？从硬件、软件技术的发展，结合业务的需求出发我们可以从中看出一些端倪。       
## 一、数据类型多样化  
随着技术的普及，越来越多以前需要很高的成本才能获取的数据，现在触手可及。     
1\. 点云（点的位置坐标+RGB+其他属性），以前只有军用领域在使用，比如《普罗米修斯》这部电影，通过一些小的飞行器（点云传感器设备）飞入未知的通道后，传回获取的点云数据，从而构建通道的全系影像。         
![pic](20170526_01_pic_001.jpg)     
现在民用领域，也有很多点云的类似应用。例如：扫地机器人，无人车，消防（探测房屋结构），VR（通过点云数据构建全息影像）等等。          
![pic](20170526_01_pic_005.jpg)         
2\. 气象数据 （位置、日照、温度、雨量、风量等），气象数据往往是栅格类型的数据，一个栅格包含了一片区域的日照、温度、雨量、风量等数据，栅格可以切分和聚合。      
气象数据的有非常多的用途，例如：      
光伏电厂的选址，需要分析某区域某个时间段，日照数据统计。      
多个栅格的数据聚合，或者一个栅格数据的部分截取等。比如一个包含了浙江省的栅格数据，如果只需要杭州市区的数据，那么可以在读取时将杭州的区域切分出来。      
在时间维度上分析，在地理位置维度上分析，在其他属性维度分析，多个维度的分析。      
生成时序动态图等。      
历史栅格数据不断的积累，不停的上传新的数据使得历史数据越来越多。      
![pic](20170526_01_pic_002.jpg)         
3\. 地震数据（高频波，傅立叶变换），地震数据是一些包含了地理位置属性的XYZ三个方向的高频波形数据，收到数据后，需要对其进行快速的数据转换，预测和告警。      
同时还需要对历史的数据进行挖掘。      
![pic](20170526_01_pic_003.jpg)          
4\. 天文数据（寻天，星系，轨迹比对），从古至今，人类一直没有停止对外太空的探索，天文台就是一个最为直接的探索外太空的设备。      
有一个项目叫“寻天”，每天这些望远镜需要对天球坐标进行全方位的拍摄，拍摄的数据以栅格类型存入数据库，以备后续的分析。比如寻址超新星，寻找类太阳系等。其中寻找类太阳系就需要对单个栅格的多个历史数据进行比对，通过行星运行轨迹对光线造成的细微影响找出类太阳系的星体。      
涉及到大量的时间、空间维度的运算。      
![pic](20170526_01_pic_004.png)          
5\. 室内定位（孤立坐标系、相对坐标系），实际上现在室内定位也非常的成熟了，例如你站在某个商场中，商场有若干个WIFI热点，只要你的手机开启了WIFI，那么通过3个WIFI热点与你的手机之间的信号强弱，就可以定位到你的位置。除了通过WIFI进行定位，还有磁场、声波、视觉等定位方法。定位后，数据以坐标+误差范围的形式存入数据库，这个坐标是相对坐标。      
室内定位有什么商业用途呢？例如可以获取某个时间点的人群分布，哪个商场或者站台附近聚集了人群，进行营销效果的挖掘。      
又比如，在时间+空间维度上，统计分析人流量，平均的驻留时间等。      
![pic](20170526_01_pic_006.png)         
6\. 室外定位（定位方法：GPS、基站信号强弱等），人群踩踏事件预测，非法聚众预测，事件预测，某个位置的人群驻足时间（广告效应报告）等。      
![pic](20170526_01_pic_007.jpg)         
7\. 生物类型、化学类型、图像特征类型、IOT的发展衍生了更多的数据类型。    
![pic](20170526_01_pic_019.jpg)    
8\. 其他，民用，军用      
还有那些喜闻乐见的应用，o2o, 地图, 导航, 位置交友, 都带有很强的时间、空间、业务数据属性。      
面向这么多的军用转民用技术，民用的软件技术有没有准备好？数据库有没有准备好接招呢？      
## 二、查询维度多样化 - 时间、空间、业务等维度 - 存储与计算的挑战      
1\. 业务数据类型越来越丰富，例如大多数业务基本上都会包含空间数据。      
2\. 大多数的数据具备时序属性，例如金融数据、物联网传感数据、气象数据、天文数据、地震监测数据等。      
3\. 数据查询维度（筛选条件）越来越多，（时间、空间、业务维度等），例如      
在2017-01-01 ~ 2017-02-01这个月，某个点附近方圆30公里发生的事件。      
在某个时间段，所有区域发生的事件。      
在某个时间段，某个区域，某些用户发生的事件。      
4\. 数据的计算需求越来越复杂，参与计算的数据量越来越庞大，计算离数据太远导致传输效率浪费。      
越来越多计算下推的需求。      
5\. 业务对数据计算的时效性越来越高，越来越多的计算被前置（如流计算，数据清洗等）。      
6\. 业务对数据深度学习的需求越来越多，而计算与数据的距离使得效率低下。      
传统的存储与计算分离，使得整体的计算效率偏低。越来越多的计算前置、计算下推需求，来提升存储计算分离这种架构下的效率。      
## 三、数据库的认知  
由于数据库发展缓慢，并没有跟上业务对数据库的需求，大多数的处理逻辑、运算都通过应用程序来解决，甚至“没有什么问题是加一层不能解决的”使得数据离计算越来越远，路径的增加使得效率越来越低下。  
这也使得大多数的人对数据库的认知变成这样的：  
1、传统数据库  
就是支持SQL接口的数据存储。  
存储和计算分离，让大多数计算在应用层实现。  
2、因为数据库的处理能力弱，设计时产生妥协  
对业务分层，例如加入消息队列、流计算、K-V缓存 等等，减轻数据库负担。  
3、能耗比降低  
分层越多，应用离数据越远，路径越长、能耗比越低。  
4、传统数据库挑战  
数据类型、内置的函数、类型的操作符、支持更多类型的索引  
支持更大数据量的存储和计算  
可编程能力，数据库只有SQL接口是不够的，SQL的功能有限  
硬件的利用能力，有多少硬件资源，就能用多少硬件资源，绝不手软。  
软件生态的对接，开发者构筑了强大的软件生态，如何更好的对接？  
## 四、HTAP 的挑战  
综合前面的分析，业务对数据库的需求分为这几个层面：    
### 1、资源的有效利用  
当用户需要时（例如半夜跑报表），数据库可以利用一切可以利用的资源(CPU多核\GPU、磁盘吞吐、网络吞吐等)，快速的帮用户完成请求。  
![pic](20170526_01_pic_020.jpg)    
### 2、资源的控制和隔离  
如果满足了条件1，那么就会引发第二个问题，资源的隔离，例如A用户正在跑报表，它把所有资源都用掉了，而有一些需要实时响应的业务可能因此受到影响。  
类似Linux的CPU公平调度中的realtime 和 普通的进程，realtime进程在QoS时可以优先获得CPU时间片，不受大量资源使用的干扰。  
![pic](20170526_01_pic_021.jpg)    
### 3、能耗比  
这个很好理解，提高能耗比是高精尖的活。例如CPU向量计算指令的利用，光这一项就有可能提升10倍的数据分析效率。  
![pic](20170526_01_pic_022.jpg)    
### 4、天花板  
不管怎么优化，怎么扩容，单机一定是有天花板的。所以除了发挥单机能力，还需要具备水平扩展能力。  
![pic](20170526_01_pic_023.jpg)    
### 5、软件生态  
开发者辛辛苦苦积累的LIB库，例如python的科学计算library，R的CRAN等。  
数据库用的是SQL语言，没有办法与这些library对接。如何突破SQL的限制，对接开发者的生态，让开发者用起来更爽。  
![pic](20170526_01_pic_024.jpg)    
每个行业都有各自的特点，每个行业都有对行业理解深厚的ISV（地头蛇），每个行业都有各自的积累（开发框架、Lib库等）。      
例如      
在科学计算这个领域，有很多的python, R, go, julia语言相关的第三方库。这些行业第三方库是开发人员、科研人员对行业的理解与积累。（这些科学计算Lib库可能被广泛应用于气象预测、地震预测、金融等众多行业。）      
如果这些Lib库可以与数据紧密的结合，大大的拉近了计算与数据的距离，直接提升计算效率并且降低了成本，开发人员一定会很高兴。      
[](http://gohom.win/2015/08/10/python-good-lib/)      
![pic](20170526_01_pic_014.jpg)      
以往是这样算（数据从数据库拉取到应用程序，应用程序再对其进行计算）：      
![pic](20170526_01_pic_008.jpg)         
现在是这样算（使用科学计算相关的Lib库，就在数据库里面算）：      
![pic](20170526_01_pic_009.jpg)         
数据库与程序开发语言、以及对应的LIB库打通，是一件很美妙的事情。     
除了开发者生态，还有一个不容忽视的生态圈，云生态，也是未来数据库需要对接的生态。让数据库和云上数据可以无缝融合，是非常关键的。  
例如阿里云RDS PG与OSS对象存储，就实现了无缝融合，用户可以在数据库中直接读写OSS，将OSS作为无限容量的存储来使用，将历史数据存储到OSS，未来要分析时还可以直接进行读写。  
### 6、硬件生态  
以往大多数的软件都是围绕CPU在设计，但是现在已经迈入了计算密集型的时代，CPU正在逐渐的丧失市场核心的位置，GPU、FPGA、TPU等处理器正在逐渐的成为核心。  
这些处理器都有对应的SDK，也会有对应的编程语言。  
未来数据库如何与这类硬件更好的整合，利用它们的计算能力，是非常重要的。  
![pic](20170526_01_pic_025.jpg)    
![pic](20170526_01_pic_026.jpg)    
![pic](20170526_01_pic_027.jpg)    
![pic](20170526_01_pic_028.jpg)    
通常我们理解的计算单元就是CPU，然而随着技术的发展，越来越多专业的硬件，例如显卡计算单元GPU，例如可烧录，可编程的FPGA，还有随着AI火起来的面向机器学习的定制芯片TPU。      
[谷歌硬件工程师揭秘，TPU为何会比CPU、GPU快30倍？](https://www.leiphone.com/news/201704/55UjF0lafhIZVGJR.html)      
[老黄呕心之作，英伟达能凭借Tesla V100技压群雄吗？](https://www.leiphone.com/news/201705/ZTztMk9I6t8lVP2U.html?ulu-rcmd=0_5021df_art_0_a3ba8a6ccd22402199137fed4a3f604a)      
[深入理解 CPU 和异构计算芯片 GPU/FPGA/ASIC 1](https://www.qcloud.com/community/article/323436001490098149)      
[深入理解 CPU 和异构计算芯片 GPU/FPGA/ASIC 2](https://www.qcloud.com/community/article/35505001490098107)      
那么数据库能否跟上这波硬件发展的浪潮呢，或者说如何抓住硬件发展的红利呢？      
## 五、PostgreSQL HTAP之路  
### 1、资源的有效利用  
1、支持CPU多核并行  
2、支持流式计算  
3、精细锁粒度，提高并发处理能力  
### 2、资源的控制和隔离  
1、PG有一个参数可以控制全局并行度资源，控制并行查询的CPU的使用率，例如服务器有128核，分配给并行计算的限制到96。确保预留足够TP资源。  
2、PG可以在进程级进行资源控制(iops,cpu,mem,network,...)    
PostgreSQL是进程模型，这方面可以结合docker, cgroup等手段实现资源的控制。        
![pic](20170526_01_pic_013.jpg)      
### 3、能耗比  