5
6
input_extension(input, generalized)
recursive_replacement(input, generalized)
if input.is_generalized() then
7
string_replacement(content, strings)
Before we describe our mutations in detail, we ex-
plain two functions that all mutations have in common—
random_generalized and send_to_fuzzer. The function
random_generalized takes as input a set of all previously
generalized inputs, tokens and strings from the dictionary and
returns—based on random coin ﬂips—a random (slice of a )
generalized input, token or string. In case we pick an input
slice, we select a substring between two arbitrary (cid:3) in a gen-
eralized input. This is illustrated in Algorithm 3. The other
function, send_to_fuzzer, implies that the fuzzer executes
the target application with the mutated input. It expects con-
crete inputs. Thus, mutations working on generalized inputs
ﬁrst replace all remaining (cid:3) by an empty string.
Algorithm 3: Random selection of a generalized in-
put, slice, token or string.
Data: generalized is the set of all previously generalized inputs,
tokens and strings from the dictionary
Result: rand is a random generalized input, slice token or string
1 if random_coin() then
2
3
if random_coin() then
rand ← random_slice(generalized)
4
5
6 else
7
else
rand ← random_token_or_string(generalized)
rand ← random_generalized_input(generalized)
3.2.1
Input Extension
The input extension mutation is inspired by the observation
that—in highly structured input languages—often inputs are
chains of syntactically well-formed statements. Therefore,
we extend an generalized input by placing another randomly
chosen generalized input, slice, token or string before and
after the given one. This is described in Algorithm 4.
Algorithm 4: Overview of the input extension muta-
tion.
Data: input is the current generalized input, generalized is the
set of all previously generalized inputs, tokens and strings
from the dictionary
1 rand ← random_generalized(generalized_inputs)
2 send_to_fuzzer(concat(input.content(),
rand.content()))
3 send_to_fuzzer(concat(rand.content(),
input.content()))
Example 6. Assume that the current input is “pprint
’aaaa’” and its generalization is “pprint ’(cid:3)’”. Further-
more, assume that we randomly choose a previous generaliza-
tion “(cid:3)x=(cid:3)y+(cid:3)”. Then, we concretize their generalizations
to “pprint ’$$’” and “x=y+” by replacing remaining gaps
with an empty string. Afterwards, we concatenate them and
obtain “pprint ’$$’x=y+” and “x=y+pprint ’$$’”.
3.2.2 Recursive Replacement
The recursive replacement mutation recombines knowledge
about the structured input language—that was obtained earlier
in the fuzzing run—in a grammar-like manner. As illustrated
in Algorithm 5, given a generalized input, we extend its begin-
ning and end by (cid:3)—if not yet present—such that we always
can place other data before or behind the input. Afterwards,
we randomly select n ∈ {2,4,8,16,32,64} and perform the
following operations n times: First, we randomly select an-
other generalized input, input slice, token or string. Then, we
call replace_random_gap which replaces an arbitrary (cid:3) in
the ﬁrst generalized input by the chosen element. Further-
more, we enforce (cid:3) before and after the replacement such
that these (cid:3) can be subject to further replacements. Finally,
we concretize the mutated input and send it to the fuzzer. The
recursive replacement mutator has a (comparatively) high
likelihood of producing new structurally interesting inputs
compared to more small-scale mutations used by current
coverage-guided fuzzers.
Example 7. Assume that the current input is “pprint
’aaaa’”. We take its generalization “pprint ’(cid:3)’” and
extend it to “(cid:3)pprint ’(cid:3)’(cid:3)”. Furthermore, assume that
we already generalized the inputs “if(x>1)(cid:3)then (cid:3)end”
and “(cid:3)x=(cid:3)y+(cid:3)”.
In a ﬁrst mutation, we choose to re-
place the ﬁrst (cid:3) with the slice “if(x>1)(cid:3)”. We extend
the slice to “(cid:3)if(x>1)(cid:3)” and obtain “(cid:3)if(x>1)(cid:3)pprint
1992    28th USENIX Security Symposium
USENIX Association
String ReplacementInput101 1001101101001Recursive ReplacementInput ExtensionGeneralizedInputExecution EngineAlgorithm 5: Overview of the recursive replacement
mutation.
Data: input is the current generalized input, generalized is the
set of all previously generalized inputs, tokens and strings
from the dictionary
1 input ← pad_with_gaps(input)
2 for i ← 0 to random_power_of_two() do
3
4
rand ← random_generalized(generalized_inputs)
input ← replace_random_gap(input, rand)
5 send_to_fuzzer(input.content())
’(cid:3)’(cid:3)”.
Afterwards, we choose to replace the third
(cid:3) with “(cid:3)x=(cid:3)y+(cid:3)” and obtain “(cid:3)if(x>1)(cid:3)pprint
’(cid:3)x=(cid:3)y+(cid:3)’(cid:3)”. In a ﬁnal step, we replace the remaining (cid:3)
with an empty string and obtain “if(x>1)pprint ’x=y+’”.
3.2.3 String Replacement
Keywords are important elements of structured input lan-
guages; changing a single keyword in an input can lead to
completely different behavior. GRIMOIRE’s string replace-
ment mutation performs different forms of replacements, as
described in Algorithm 6. Given an input, it locates all sub-
strings in the input that match strings from the obtained dic-
tionary and chooses one randomly. GRIMOIRE ﬁrst selects a
random occurrence of the matching substring and replaces it
with a random string. In a second step, it replaces all occur-
rences of the substring with the same random string. Finally,
the mutation sends both mutated inputs to the fuzzer. As an
example, this mutation can be helpful to discover different
methods of the same object by replacing a valid method call
with different alternatives. Also, changing all occurrences of
a substring allows us to perform more syntactically correct
mutations, such as renaming of variables in the input.
Example 8. Assume the “if(x>1)pprint ’x=y+’” and that
the strings “if”, “while”, “key”, “pprint”, “eval”, “+”, “=”
and “–” are in the dictionary. Thus, the string replacement
mutation can generate inputs such as “while(x>1)pprint
’x=y+’”, “if(x>1)eval
’x+y+’” or “if(x>1)pprint
’x=y-’”. Furthermore, assume that the string “x” is also in
the dictionary. Then, the string replacement mutation can re-
place all occurrences of the variable “x” in “if(x>1)pprint
’x=y+’” and obtain “if(key>1)pprint ’key=y+’”.
4 Implementation
To evaluate the algorithms introduced in this paper, we built a
prototype implementation of our design. Our implementation,
called GRIMOIRE, is based on REDQUEEN’s [3] source code.
This allows us to implement our techniques within a state-
of-the-art fuzzing framework. REDQUEEN is applicable to
both open and closed source targets running in user or kernel
space, thus enabling us to target a wide variety of programs.
Algorithm 6: Overview of the string replacement mu-
tation.
Data: input is the input string, strings is the provided dictionary
obtained from the binary
1 sub ← find_random_substring(input, strings)
2 if sub then
3
4
5
6
7
rand ← random_string(strings)
data ← replace_random_instance(input, sub, rand)
send_to_fuzzer(data)
data ← replace_all_instances(input, sub, and)
send_to_fuzzer(data)
While REDQUEEN is entirely focused on solving magic bytes
and similar constructs which are local in nature (i. e., require
only few bytes to change), GRIMOIRE assumes that this kind
of constraints can be solved by the underlying fuzzer.
It
uses global mutations (that change large parts of the input)
based on the examples that the underlying fuzzer ﬁnds. Since
our technique is merely based on common techniques imple-
mented in coverage-guided fuzzers—for instance, access to
the execution bitmap—it would be a feasible engineering task
to adapt our approach to other current fuzzers, such as AFL.
More precisely, GRIMOIRE is implemented as a set of
patches to REDQUEEN. After ﬁnding new inputs, we apply
the generalization instead of the minimization algorithm that
was used by AFL and REDQUEEN. Additionally, we extended
the havoc stage by large-scale mutations as explained in Sec-
tion 3. To prevent GRIMOIRE from spending too much time
in the generalization phase, we set a user-conﬁgurable upper
bound; inputs whose length exceeds this bound are not be gen-
eralized. Per default, it is set to 16384 bytes. Overall, about
500 lines were written to implement the proposed algorithms.
To support reproducibility of our approach, we open
source the fuzzing logic, especially the implementation of
GRIMOIRE as well as its interaction with REDQUEEN at
https://github.com/RUB-SysSec/grimoire.
5 Evaluation
We evaluate our prototype implementation GRIMOIRE to an-
swer the following research questions.
RQ 1 How does GRIMOIRE compare to other state-of-the-
art bug ﬁnding tools?
RQ 2 Is our approach useful even when proper grammars
are available?
RQ 3 How does our approach improve the performance on
targets that require highly structured inputs?
RQ 4 How does our approach perform compared to other
grammar inference techniques for the purpose of
fuzzing?
RQ 5 How do our mutators impact fuzzing performance?
USENIX Association
28th USENIX Security Symposium    1993
RQ 6 Can GRIMOIRE identify new bugs in real-world ap-
plications?
To answer these questions, we perform three individual
experiments. First, we evaluate the coverage produced by
various fuzzers on a set of real-world target programs. In
the second experiment, we analyze how our techniques can
be combined with grammar-based fuzzers for mutual im-
provements. Finally, we use GRIMOIRE to uncover a set of
vulnerabilities in real-world target applications.
5.1 Measurement Setup
All experiments are performed on an Ubuntu Server 16.04.2
LTS with an Intel i7-6700 processor with 4 cores and 24 GiB
of RAM. Each tool is evaluated over 12 runs for 48 hours to
obtain statistically meaningful results. In addition to other
statistics, we also measure the effect size by calculating the
difference in the median of the number of basic blocks found
in each run. Additionally, we perform a Mann Whitney U
test (using scipy 1.0 [38]) and report the resulting p-values.
All experiments are performed with the tool being pinned to
a dedicated CPU in single-threaded mode. Tools other than
GRIMOIRE and REDQUEEN require source-code access; we
use the fast clang-based instrumentation in these cases. Addi-
tionally, to ensure a fair evaluation, we provide each fuzzer
with a dictionary containing the strings found inside of the
target binary. In all cases, except NAUTILUS (which crashed
on larger bitmaps), we increase the bitmap size from 216 to
219. This is necessary since we observe more collisions in the
global coverage map for large targets which causes the fuzzer
to discard new coverage. For example, in SQLite (1.9 MiB),
14% of the global coverage map entries collide [66]. Since
we deal with even larger binaries such as PHP which is nearly
19 MiB, the bitmap ﬁlls up quickly. Based on our empirical
evaluation, we observed that 219 is the smallest sufﬁcient size
that works for all of our target binaries.
Furthermore, we disable the so-called deterministic
stage [66]. This is motivated by the observation that these
deterministic mutations are not suited to ﬁnd new coverage
considering the nature of highly structured inputs. Finally—
if not stated otherwise—we use the same uninformed seed
that the authors of REDQUEEN used for their experiments:
"ABC. . . XYZabc. . . xyz012. . . 789!"$. . . ~+*".
As noted by Aschermann et al. [3], there are various def-
initions of a basic block. Fuzzers such as AFL change the
number of basic blocks in a program. Thus, to enable a fair
comparison in our experiments, we measure the coverage
produced by each fuzzer on the same uninstrumented binary.
Therefore, the numbers of basic blocks found and reported in
our paper might differ from other papers. However, they are
consistent within all of our experiments.
For our experiments, we select a diverse set of tar-
get programs. We use four scripting language inter-
preters (mruby-1.4.1 [41], php-7.3.0 [57], lua-5.3.5 [36]
and JavaScriptCore, commit “f1312” [1]) a compiler
(tcc-0.9.27 [6]), an assembler (nasm-2.14.02 [56]), a
database (sqlite-3.25 [31]), a parser (libxml-2.9.8 [59])
and an SMT solver (boolector-3.0.1 [44]). We select these
four scripting language interpreters so that we can directly
compare the results to NAUTILUS. Note that our choice of
targets is additionally governed by architectural limitations of
REDQUEEN which GRIMOIRE is based on. REDQUEEN uses
Virtual Machine Introspection (VMI) to transfer the target
binary—including all of its dependencies—into the Virtual
Machine (VM). The maximum transfer size using VMI in
REDQUEEN is set to 64 MiB. Programs such as Python [49],
GCC [18], Clang [40], V8 [24] and SpiderMonkey [43] ex-
ceed our VMI limitation; thus, we can not evaluate them.
We select an alternative set of target binaries that are large
enough but at the same time do not exceed our 64 MiB
transfer size limit. Hence, we choose JavaScriptCore over
V8 and SpiderMonkey, mruby over ruby and TCC over GCC
or Clang. Finally, we tried to evaluate GRIMOIRE with
ChakraCore [42]. However, ChakraCore fails to start in-
side of the REDQUEEN Virtual Machine for unknown rea-
sons. Still, GRIMOIRE performs well on large targets such as
JavaScriptCore and PHP.
5.2 State-of-the-Art Bug Finding Tools
To answer RQ 1, we perform 12 runs on eight targets using
GRIMOIRE and four state-of-the-art bug ﬁnding tools. We
choose AFL (version 2.52b) because it is a well-known fuzzer
and a good baseline for our evaluation. We select QSYM
(commit “6f00c3d”) and ANGORA (commit “6ff81c6”), two
state-of-the-art hybrid fuzzers which employ different pro-
gram analysis techniques, namely symbolic execution and
taint tracking. Finally, we choose REDQUEEN as a state-of-
the-art coverage-guided fuzzer, which is also the baseline of
GRIMOIRE. As a consequence, we are able to directly ob-
serve the improvements of our method. Note that we could
not compile libxml for ANGORA instrumentation. Therefore,
ANGORA is missing in the libxml plot.
The results of our coverage measurements are shown in Fig-
ure 4. As we can see, in all cases GRIMOIRE provides a signif-
icant advantage over the baseline (unmodiﬁed REDQUEEN).
Surprisingly, in most cases, neither ANGORA, REDQUEEN,
nor QSYM seem to have a signiﬁcant edge over plain AFL.
This can be explained by the fact that REDQUEEN and AN-
GORA mostly aim to overcome certain “magic byte” fuzzing
roadblocks. Similarly, QSYM is also effective to solve these
roadblocks. Since we provide a dictionary with strings from
the target binary to each fuzzer, these roadblocks become
much less common. Thus, the techniques introduced in AN-
GORA, REDQUEEN and QSYM are less relevant given the
seeds provided to the fuzzers. However, in the case of TCC, we
can observe that providing the strings dictionary does not help
AFL. Therefore, we believe that ANGORA and REDQUEEN
1994    28th USENIX Security Symposium
USENIX Association
Table 2: Conﬁrmatory data analysis of our experiments. We compare the
coverage produced by GRIMOIRE against the best alternative. The effect size
is the difference of the medians in basic blocks. In most experiments, the
effect size is relevant and the changes are highly signiﬁcant: it is typically
multiple orders of magnitude smaller than the usual bound of p < 5.0E-02
(bold).
Best
Alternative
ANGORA
REDQUEEN
REDQUEEN
Target
mruby
TCC
PHP
Boolector AFL
Lua
libxml
SQLite
NASM
ANGORA
AFL
ANGORA
ANGORA
Effect Size
(∆ = ¯A− ¯B)
3685
1952
11238
7671
-478
308
4846
272
Effect Size
in % of Best
p-value
19.3% 1.8E-05
22.6% 7.8E-05
31.6% 1.8E-05
43.9% 1.8E-05
-8.2% 4.5E-04
3.4% 1.8E-02
26.8% 1.8E-05
2.9% 9.7E-02
Lua accepts both source ﬁles (text) as well as byte code.
GRIMOIRE can only make effective mutations in the domain
of language features and not the bytecode. However, other
fuzzers can perform on both; this is why ANGORA outper-
forms GRIMOIRE on this target. It is worth mentioning that
GRIMOIRE outperforms REDQUEEN, the baseline on top of
which our approach is implemented.
To partially answer RQ 1, we showed that in terms of
code coverage, GRIMOIRE outperforms other state-of-the-art
bug ﬁnding tools (in most cases). Second, to answer RQ 3,
we demonstrated that GRIMOIRE signiﬁcantly improves the
performance on targets with highly structured inputs when
compared to our baseline (REDQUEEN).
5.3 Grammar-based Fuzzers
Generally, we expect grammar-based fuzzers to have an edge
over grammar inference fuzzers like GRIMOIRE since they
have access to a manually crafted grammar. To quantify this
advantage, we evaluate GRIMOIRE against current grammar-
based fuzzers. To this end, we choose NAUTILUS (commit
“dd3554a”), a state-of-the-art coverage-guided fuzzer, since
it can fuzz a wide variety of targets if provided with a hand-
written grammar. We evaluate on the targets used in NAU-
TILUS’ experiments, mruby, PHP and Lua, as their grammars
are available. Unfortunately, GRIMOIRE is not capable of
running ChakraCore, the fourth target NAUTILUS was eval-
uated on; thus, we replace it by JavaScriptCore and use
NAUTILUS’ JavaScript grammar. We observed that the origi-
nal version of NAUTILUS had some timeout problems during
fuzzing where the timeout detection did not work properly.
We ﬁxed this for our evaluation.
For each of the four targets, we perform an experiment
with the same setup as the ﬁrst experiment (again, 12 runs for
48 hours). The results are shown in Figure 5. As expected,
our completely automated method is defeated in most cases
by NAUTILUS since it uses manually ﬁne-tuned grammars.
Figure 4: The coverage (in basic blocks) produced by various tools over 12
runs for 48h on various targets. Displayed are the median and the 66.7%
intervals.
ﬁnd strings that are not part of the dictionary and thus outper-
form AFL.
A complete statistical description of the results is given in
the appendix (Table 7). We perform a conﬁrmatory statistical