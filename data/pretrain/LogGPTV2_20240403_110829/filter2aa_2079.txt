Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Adversarial 
Machine Learning 
And Several 
Countermeasures 
Trend Micro 
ch0upi 
miaoski 
7 Dec 2017 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
ch0upi 
•
Staff engineer in Trend Micro 
•
Machine Learning + Data Analysis 
•
Threat intelligence services 
•
NIPS 
•
KDDCup 2014 + KDDCup 2016: Top10 
•
GoTrend: 6th in UEC Cup 2015 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
miaoski 
•
Senior threat researcher in Trend Micro 
•
Threat intelligence 
•
Smart City 
•
SDR 
•
Arduino + RPi makers 
•
猫奴 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
4 
Outline 
•
Cheating machine learning? 
•
Attacking theories and practices 
•
Countermeasures 
•
Conclusion 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
CHEAT 
MACHINE LEARNING MODELS 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
We Were Good Guys ... 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Even NVIDIA... 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
ML-Based Anti-Virus? 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
ML-Based Anti-Virus? 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
CSOs Explained 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
But Still ... 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Rescan Makes It Worse 
Compiler 
Hello World 
(no debug) 
Hello World 
(debug) 
Nothing (no 
debug) 
Nothing 
(debug) 
Visual Studio 
2017 
Cylance, 
Jiangmin 
Cylance, Cyren, 
F-Prot, Sophos 
ML, 
SentinelOne 
Static ML 
Cylance, 
Jiangmin 
Cylance, Cyren, 
F-Prot, Sophos 
ML, 
SentinelOne 
Static ML 
MingW64 
Good 
Good 
Good 
Good 
Cygwin x86_64 Baidu, Cylance Baidu 
Baidu, Cylance Baidu 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
ML is Prosperous 
Taigman et al. (2014) DeepFace: Closing the Gap to Human-Level Performance in Face Verification 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
ML Drives 
https://www.tesla.com/sites/default/files/images/videos/tesla_autopilot_2_video.jpg 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine learning has its particular vulnerabilities. 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
NIPS 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
THEORIES AND 
PRACTICES 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Methodology 
•
Evasion 
•
Black box 
•
White box 
•
Model stealing 
•
Poisoning 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Methodology 
•
Evasion 
•
Black box 
•
Random 
•
Evolutionary algorithms (GA) 
•
White box 
•
Model stealing 
•
Poisoning 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Black Box 
•
No model 
•
Only predict interface & result 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Black Box: Random Noise Attack 
•
Add some white noise? 
? 
Not effective for most model 
random.normalvariate(0, 5) 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Black Box: Iterative Random Attack 
Add some 
noise 
Repeat 
hundreds times 
Select the best 
one 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Black Box – Random – STOP 
•
Inspired by Evtimov et al. (2017) 
•
We use iterative random attack instead 
•
Difficult: STOP sign  something else 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Black Box – Random – STOP 
•
Evtimov et al. (2017)  80 KM/h 
Hacked in iteration 5 
Predicted Labels: 39 ['Keep left'] 
(confidence = 73%) 
39 - Keep left 
14 - Stop 
13 - Yield 
  6 - End of speed limit (80km/h) 
41 - End of no passing 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Black Box – Random – Faces 
•
VGG Face and @mzaradzki 
N 
Square Size 
Success? 
10 
4x4 
Adam Driver 
10 
4x3 
Adam Driver 
10 
3x3 
Adam Driver 
10 
2x2 
Adam Driver (difficult) 
-- 
Cat face 
Failed 
10 
1x1 
Failed* 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Black Box – Random – Faces 
Adam Driver 
           Aamir Khan 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Black Box – Genetic Algorithm 
•
Effective random search 
•
Inspired by the process of natural selection 
•
Belongs to evolutionary algorithms (EA) 
•
Solving optimization and search problems 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Black Box – Genetic Algorithm 
•
Selection 
•
Crossover 
•
Mutation 
•
Evaluation 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Methodology 
•
Evasion 
•
Black box 
•
White box 
•
FGSM 
•
One-step target class 
•
Model stealing 
•
Poisoning 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
White Box 
•
With all model detail 
•
DNN architecture, weights 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Fast Gradient Sign Method 
•
simple and computationally efficient 
•
non-target attack 
•
Goodfellow et al. (2014) 
Xadv: Adversarial image 
X: Original image 
𝜖: perturbation level 
𝛻𝑋 𝐽(𝑋, 𝑦): gradient 
𝑋𝑎𝑑𝑡 = 𝑋 + 𝜖𝑠𝑖𝑔𝑛(𝛻𝑋𝐽 𝑋, 𝑦𝑡𝑟𝑡𝑑 ) 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Attack a Linear Model 
•
Introduction to FGSM 
Fei-Fei Li, Andrej Karpathy, Justin Johnson, Lecture 9-72, 2016 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
White Box Attack Methods 
•
Fast gradient sign method (non-target, one step) 
•
One-step target class methods (target, one step) 
•
Basic iterative method (non-target, multiple steps) 
•
Iterative least-likely class method (target , multiple 
steps) 
Kurakin et al., ADVERSARIAL MACHINE LEARNING AT SCALE. ICLR 2017 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
White Box – FGSM – Trash Can 
label: 412 (ashcan, trash can), certainty: 37.47% 
label: 899 (water jug), certainty: 10.85% 
label: 503 (cocktail shaker), certainty: 7.98% 
label: 412 (ashcan, trash can), certainty: 87.68%  
label: 463 (bucket, pail), certainty: 3.08% 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
White Box – One-Step Target 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Methodology 
•
Evasion 
•
Black box 
•
White box 
•
Model stealing 
•
Poisoning 
API 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Model Stealing 
Florian Tramer et. al., Stealing Machine Learning Models via Prediction APIs, Usenix Security Symposium 2016 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Model Stealing 
•
Model is data 
•
Model is asset 
•
Train a local DNN for Black box attack 
•
Data privacy 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Model Stealing: Adversarial Attack 
•
Transferability Property 
•
Train a local model for attack 
•
Effective data augmentation 
Ian Goodfellow, Practical Black-Box Attacks against Machine Learning, 2017 
Model A 
Model B 
Adversarial Samples 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Model Stealing: Data Privacy 
•
How to re-build your face if we have the model? 
Florian Tramer et. al., Stealing Machine Learning Models via Prediction APIs, Usenix Security Symposium 2016 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Methodology 
•
Evasion 
•
Black box 
•
White box 
•
Model stealing 
•
Poisoning 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Poison Attack 
•
Crowdsourcing 
•
Amazon Mechanical turk 
•
Mis-labeling 
•
Online training 
•
Microsoft chatbot: Tay 
•
User feedback 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Real World Adversarial 
•
Evading Against PDF ML 
•
Auto-pilot cars 
•
Access control w/ face recognition 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Evading Against PDF ML 
•
Genetic algorithm to generate adversarial sample 
•
Sandbox to ensure malicious behavior kept 
Weilin Xu, Yanjun Qi, and David Evans. Automatically Evading Classifiers A Case Study on 
PDF Malware Classifiers. Network and Distributed Systems Symposium 2016 
http://evademl.org/ 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Auto-pilot Cars 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Access Control w/ Face Recognition 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
COUNTERMEASURES 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Countermeasures 
•
Ensemble & Stacking 
•
Retrained model 
•
Denoiser 
•
Prevent Model Leakage 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Ensemble & Stacking 
•
Layer protection 
Xgboost 
SVM 
CNN 
RNN 
LR 
LDA 
Layer 1 
Layer 2 
Layer 3 
Input Data 
Prediction 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Retrained Models 
•
Distortion 
•
Retrain with noisy sample 
•
Randomization layer in DNN (NIPS 2nd) 
•
Generative Adversarial Networks (GAN) 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Denoiser 
•
Use denoise technologies from image processing 
•
Train a DNN denoiser to reduce the noise 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Prevent Model Leakage 
•
Avoid Model stealing 
•
Increase the challenge of black box attack 
•
Keep some info secret or add some noise 
•
Randomization and disinformation 
•
Adversarial sample detection 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
CONCLUSION 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Conclusion 
•
Know the limitations and weakness of your model 
•
Integrate adversarial machine learning into product 
development cycle 
•
Improve ML 
•
QA process 
•
Trend Micro is working on bypassing anti-virus with 
ML in order to make our product robust 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
References 
•
Evtimov et al. (2017) Robust Physical-World Attacks on Deep Learning Models 
•
https://iotsecurity.eecs.umich.edu/#roadsigns 
•
Nguyen et al. (2015) Deep Neural Networks are Easily Fooled: High Confidence 
Predictions for Unrecognizable Images. IEEE CVPR ‘15. 
•
Kurakin A., Goodfellow I.J., Bengio S. (2017) Adversarial Examples in the Physical 
World.  
•
https://github.com/tomaszkacmajor/CarND-Traffic-Sign-Classifier-P2 
•
https://aboveintelligent.com/face-recognition-with-keras-and-opencv-
2baf2a83b799 
•
https://github.com/davidsandberg/facenet 
•
http://www.vlfeat.org/matconvnet/pretrained/#face-recognition 
•
https://github.com/mzaradzki/neuralnets/tree/master/vgg_faces_keras 
Machine 
Learning 
Protect against 
tomorrow’s 
threats 
USE THE SOURCE, LUKE! 
https://github.com/miaoski/hitcon-2017-adversarial-ml