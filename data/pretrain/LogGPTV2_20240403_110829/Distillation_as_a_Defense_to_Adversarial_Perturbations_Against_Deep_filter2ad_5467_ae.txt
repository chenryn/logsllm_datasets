network output with respect to its input. A perturbation is then
constructed by ranking input features to be perturbed using
a saliency map based on the previously computed network
Jacobian and giving preference to features more likely to alter
the network output. Each feature perturbed is set to 1 for the
MNIST architecture and 2 for the CIFAR10 dataset. Note that
the attack [7] we implemented in this evaluation is based on
perturbing very few pixels by a large amount, while previous
attacks [8], [9] were based on perturbing all pixels by a small
amount. We discuss in Section VI the impact of our defense
‚àó
‚àó is classiÔ¨Åed in the target class F (X
with other crafting algorithms, but use the above algorithm
to conÔ¨Årm the analytical results presented in the preceding
sections. These two steps are repeated several times until the
).
resulting sample X
We stop the perturbation selection if the number of features
perturbed is larger than 112. This is justiÔ¨Åed because larger
perturbations would be detectable by humans [7] or poten-
tial anomaly detection systems. This method was previously
reported to achieve a 97% success rate when used to craft
90, 000 adversarial samples by altering samples from the
MNIST test set with an average distortion of 4.02% of the
input features [7]. We Ô¨Ånd that altering a maximum of 112
features also yields a high adversarial success rate of 92.78%
on the CIFAR10 test set. Note that throughout this evalua-
tion, we use the number of features altered while producing
adversarial samples to compare them with original samples.
B. Defensive Distillation and Adversarial Samples
Impact on Adversarial Crafting - For each of our two
DNN architectures corresponding to the MNIST and CIFAR10
datasets, we consider the original trained model FM N IST
or FCIF AR10, as well as the distilled model F d
M N IST or
F d
CIF AR10. We obtain the two distilled models by training
them with defensive distillation at a class knowledge transfer
temperature of T = 20 (the choice of this parameter is
investigated below). The resulting classiÔ¨Åcation accuracy for
the MNIST model F d
M N IST is 99.05% and the classiÔ¨Åcation
accuracy for the CIFAR10 model F d
CIF AR10 is 81.39%, which
are comparable to the non-distilled models.
In a second set of experiments, we measured success rate of
adversarial sample crafting on 100 samples randomly selected
from each dataset2. That
is, for each considered sample,
we use the crafting algorithm to craft 9 adversarial samples
corresponding to the 9 classes distinct from the sample‚Äô source
class. We thus craft a total of 900 samples for each model. For
the architectures trained on MNIST data, we Ô¨Ånd that using
defensive distillation reduces the success rate of adversarial
sample crafting from 95.89% for the original model to 1.34%
for the distilled model, thus resulting in a 98.6% decrease.
Similarly, for the models trained on CIFAR10 data, we Ô¨Ånd
that using distillation reduces the success rate of adversarial
sample crafting from 89.9% for the original model to 16.76%
for the distilled model, which represents a 81.36% decrease.
Distillation Temperature - The next experiments measure
how temperature impacts adversarial sample generation. Note
the softmax layer‚Äôs temperature is set to 1 at test time i.e.,
temperature only matters during training. The objective here
is to identify the ‚Äúoptimal‚Äù training temperature resulting in
resilience to adversarial samples for a DNN and dataset.
We repeat
the adversarial sample crafting experiment
on both architectures and vary the distillation tempera-
ture each time. The number of adversarial targets success-
fully reached for the following distillation temperatures T :
{1, 2, 5, 10, 20, 30, 50, 100} is measured. Figure 7 plots the
success rate of adversarial samples with respect to temperature
2Note that we extract samples from the test set for convenience, but any
sample accepted as a network input could be used as the original sample.
592592
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:13 UTC from IEEE Xplore.  Restrictions apply. 
'#$#"$&$$%
'#$#"$&$$%

'#$#"$$ %
'#$#"$$ %
%



$
$


&

"





#

$
#
'






	







$%%! "#%&#

Fig. 7: An exploration of the temperature parameter space: for 900 targets against the MNIST and CIFAR10 based models
and several distillation temperatures, we plot the percentage of targets achieved by crafting an adversarial sample while altering
at most 112 features. Baselines for models trained without distillation are in dashes. Note the horizontal logarithmic scale.
for both architectures and provides exact Ô¨Ågures. In other
words, the rate plotted is the number of adversarial sample
targets that were reached. Two interesting observations can be
made: (1) increasing the temperature will generally speaking
make adversarial sample crafting harder, and (2) there is an
elbow point after which the rate largely remains constant
(‚âà 0% for MNIST and ‚âà 5% for CIFAR10).
Observation (1) validates analytical results from Section III
showing distilled network resilience to adversarial samples:
the success rate of adversarial crafting is reduced from 95.89%
without distillation to 0.45% with distillation (T = 100) on
the MNIST based DNN, and from 87.89% without distillation
to 5.11% with distillation (T = 100) on the CIFAR10 DNN.
The temperature corresponding to the curve elbow is linked
to the role temperature plays within the softmax layer. Indeed,
temperature is used to divide logits given as inputs to the
softmax layer, in order to provide more discreet or smoother
distributions of probabilities for classes. Thus, one can make
the hypothesis that the curve‚Äôs elbow is reached when the tem-
perature is such that increasing it further would not make the
distribution smoother because probabilities are already close
to 1/N where N is the number of classes. We conÔ¨Årm this
hypothesis by computing the average maximum probability
output by the CIFAR10 DNN: it is equal to 0.72 for T = 1,
to 0.14 for T = 20, and to 0.11 for T = 40. Thus, the elbow
point at T = 40 correspond to probabilities near 1/N = 0.1.
ClassiÔ¨Åcation Accuracy - The next set of experiments
sought to measure the impact of the approach on accuracy. For
each knowledge transfer temperature T used in the previous
set of experiments, we compute the variation of classiÔ¨Åca-
tion accuracy between the models FM N IST , FCIF AR10 and
F d
M N IST , F d
CIF AR10, respectively trained without distillation
and with distillation at temperature T . For each model, the
accuracy is computed using all 10, 000 samples from the
corresponding test set (from MNIST for the Ô¨Årst and from
CIFAR10 for the second model). Recall
the baseline
rate, meaning the accuracy rate corresponding to training
that
!""# $ "


!""# $ "

"




"
!



"





"





$


#
















!"" "# 

	


Fig. 8: InÔ¨Çuence of distillation on accuracy: we plot the
accuracy variations of our two architectures for a training with
and without defensive distillation. These rates were evaluated
on the corresponding test set for various temperature values.
performed without distillation, which we computed previously
was 99.51% for model FM N IST and 80.95% for model
FCIF AR10. The variation rates for the set of distillation
temperatures are shown in Figure 8.
One can observe that variations in accuracy introduced by
distillation are moderate. For instance, the accuracy of the
MNIST based model is degraded by less than 1.28% for all
temperatures, with for instance an accuracy of 99.05% for
T = 20, which would have been state of the art until very
recently. Similarly, the accuracy of the CIFAR10 based model
is degraded by at most 1.37%. It also potentially improves
it, as some variations are positive, notably for the CIFAR10
model (the MNIST model is hard to improve because its
accuracy is already close to a 100%). Although providing
a quantitative understanding of this potential for accuracy
improvement is outside the scope of this paper, we believe
that it stems from the generalization capabilities favored by
593593
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:13 UTC from IEEE Xplore.  Restrictions apply. 
‚àí40 ‚àí 10
‚àí35
 	
 	
 	
10
‚àí35 ‚àí 10
‚àí30
	 
	 
	 
10
‚àí30 ‚àí 10
‚àí25
 	
 	
 	
10
‚àí25 ‚àí 10
‚àí20
	 
	 
	 
10
‚àí20 ‚àí 10
‚àí15
 	
  	
 	
10
‚àí15 ‚àí 10
‚àí10
	 
	  
	 
10
‚àí10 ‚àí 10
‚àí5
 	
  	
 	
10
‚àí5 ‚àí 10
‚àí3
	 
	 
	 
10
‚àí3 ‚àí 10
 
 
 
10
0
0 ‚àí 10
‚àí40
 
  
 















	
	
	















%
%
%
$
$




$
&