tween 10000 and 100000. Hence, RatBot uses another level of obfuscation (i.e.,
parameter-level obfuscation) to defeat such kind of statistical inferences.
6 Kad-Based RatBot Implementation
In this section, we discuss how to implement RatBot based on KAD, which ex-
tends from the Kademlia protocol proposed by Maymounkov and Mazieres [15].
Our implementation of RatBot is based on a popular KAD client, aMule2. UDP
2 The version we used in our study is aMule 2.1.3.
RatBot: Anti-enumeration Peer-to-Peer Botnets
145
)
x
(
f
n
o
i
t
c
n
u
f
y
t
i
s
n
e
d
y
t
i
l
i
b
a
b
o
r
P
 6
 5
 4
 3
 2
 1
 0
1000000 spoofing IPs
100000 spoofing IPs
10000 spoofing IPs
1000 spoofing IPs
 1e+08
 1e+07
 1e+06
 100000
 10000
 1000
 100
s
P
I
g
n
i
f
o
o
p
s
f
o
r
e
b
m
u
n
d
e
v
r
e
s
b
O
 0
 1
 2
 3
 4
 5
x
 10
 0
 200
 400
 600
Sample run ID
 800
 1000
Fig. 3. PDF of Pareto distribution
Fig. 4. Observed spooﬁng IPs
is used in aMule for searching and publishing data objects. If it is an explicit bot,
we keep the original implementation intact. Otherwise if it is an obscure bot, we
make the following modiﬁcations. First, when the bot receives a request mes-
sage, it drops the message immediately. A request message in KAD carries some
special operation types, such as KADEMLIA HELLO REQ, KADEMLIA SEARCH REQ,
KADEMLIA REQ, KADEMLIA PUBLISH REQ, etc.
Second, in the KAD protocol peers regularly send KADEMLIA HELLO REQ mes-
sages to each other to exchange liveness information. It is noted that the adver-
sary can use such messages to determine whether a peer is an obscure bot or
just a spoofed IP address. There are two solutions to this. One option is that
the obscure bot obfuscates these messages as well, using spooﬁng IP addresses.
The ﬂip side of this approach is that peers may inject those spoofed IP ad-
dresses into their routing tables, thus aﬀecting normal routing operations. The
other solution is that an obscure bot does not send out such messages at all.
Even though obscure bots and their spoofed IP addresses may still be inserted
into their neighbors’ routing tables when their neighbors receive search requests
from them, the lack of liveness messages makes them less likely to be chosen in
a search process because KAD prefers long-lived nodes when forwarding search
requests. Also, when a peer node ﬁnds that a neighbor has not been alive for a
certain period of time, it removes that neighbor from its routing table. Given
these considerations, we adopt the second approach in our implementation.
Third, as obscure bots do not send out KADEMLIA HELLO REQ messages
to their peers, their peers do not send back response messages with type
KADEMLIA HELLO RES. According to the standard KAD protocol, obscure bots’
routing tables would shrink faster because neighbors without liveness messages
are removed from the routing table after a certain period of time. To avoid
this, we increase the longevity of each neighbor without liveness messages in an
obscure bot’s routing table from the original two minutes to two hours.
Fourth, a KAD node initiates some random search operations when a bucket
does not have enough contacts in its routing table. For an obscure bot, it has
to use its authentic IP address for such random lookups. It is necessary to ob-
fuscate these searches also, because otherwise the adversary can infer whether
an observed IP address is authentic or not by how many unique keys it uses for
searching. In our implementation, we obfuscate these random searches as well.
146
G. Yan, S. Chen, and S. Eidenbenz
Finally, we let RatBot use the metadata tags in KAD, such as ﬁlenames, to
hide C&C information. Hence, no data transfer is needed for normal bot opera-
tions. Also, obscure bots never publish any information into the P2P network;
they only passively search commands given from the botmaster. The botmaster
uses only explicit bots to publish his C&C information.
7 Experimental Evaluation
We now evaluate the eﬀectiveness of RatBot in preventing the adversary from
obtaining an accurate estimate on the botnet size. Due to the destructive nature
of RatBot, we do this in a simulated environment to avoid legal and ethical is-
sues. Our KAD-based implementation of RatBot used the actual implementation
code of aMule. We further intercepted all system calls in it, such as time-related
and socket functions and replaced them with simulated function calls speciﬁc to
our local distributed simulation platform. According to the literature, behaviors
of both normal P2P users and bots exhibit strong time zone eﬀects [21,8]. To in-
corporate these details into our simulation, we model the geographic distribution
of normal KAD peers based on previous measurements on the KAD network [21]
and that of bots according to the Storm botnet IP distribution [6].
Our model of normal P2P user behaviors is based on the observations on the
online patterns of normal KAD users [22]. The starting time of a normal peer
being online is modeled with a Gaussian distribution with mean at 7:00pm and
standard deviation at 2 hours, and the duration of an online session is generated
with a three-parameter Weibull distribution. The online activity model of a bot
machine is simply deﬁned as follows: the starting time of it being online is drawn
from a Gaussian distribution with mean at 8:00am and the end time is drawn
from a Gaussian distribution with mean at 6:00pm; for both distributions, the
standard deviation is one hour. This model reﬂects people’s normal work hours.
The number of spooﬁng IP addresses corresponding to an obscure bot is gen-
erated from a Pareto distribution whose parameters are set as follows. Let us
number the 24 time zones from 1 to 24. The mean of the Pareto distribution is
drawn from a Gaussian distribution with mean and standard deviation set as 2z
and 4z, respectively, where z is the time zone number of the obscure bot. The
scale parameter of the Pareto distribution is 1.05 and its cutoﬀ parameter can
be calculated accordingly from its mean. In each experiment of this study, we
use 100 processors from a cluster machine to simulate the behaviors of RatBot.
7.1 Exclusive RatBot
In the ﬁrst set of experiments, we study the behavior dynamics of exclusive
RatBots. We let the botmaster send out a command every day. To improve the
reachability of the command to individual bots, the botmaster uses ﬁve bots to
publish it with 32 keys (as in the Storm botnet) periodically every 100 seconds.
Each individual bot, when online, periodically searches the command every 100
seconds with these 32 keys until it gets the command successfully. We simulate
RatBot: Anti-enumeration Peer-to-Peer Botnets
147
10,000 bots and vary the number of obscure bots among {1000 × i}i=0,1,2,3,4,5.
Among the 10,000 bots, 10% of them are P2P servers that always stay online.
We assume an adversarial model in which the adversary controls 10 servers
that can be used to monitor bot traﬃc. We simulate the botnet for two days:
the ﬁrst day is used as a ramp-up phase for each obscure bot to obtain some
empirical distributions, and the second day is used for testing. For each scenario,
we simulate it for 20 times with diﬀerent random number seeds.
We ﬁrst verify our implementation to ensure that behaviors of spooﬁng ses-
sions are close to those of authentic sessions. In Figure 5, we depict the frequency
histogram of the number of appearances of packets from spooﬁng and authentic
sessions observed by the monitors, respectively, in ﬁve runs when there are 1000
obscure bots. There is no obvious systematic diﬀerence between authentic and
spooﬁng sessions that can be exploited to diﬀerentiate them. From the simula-
tion results, we also note that regardless of the number of obscure bots in the
RatBot, almost every individual bot gets the command eventually. Hence, the
existence of obscure bots does not aﬀect the utility of the P2P botnet.
Figure 6 gives the median, smallest, and largest number of IP addresses ob-
served by the adversary in 20 sample runs eventually and after one day, respec-
tively, under diﬀerent number of obscure bots. In the eventual results, we show
the total number of spooﬁng IP addresses generated by obscure bots plus the
number of actual bots. We notice that after one day, the adversary observes
a large fraction of both actual and spooﬁng IP addresses. This is because we
assume the adversary is able to deploy monitors among the core servers of the
P2P botnet and the bots search the command frequently.
Unsurprisingly, if we increase the number of obscure bots, the number of ob-
served IP addresses by the adversary also increases. When there are 4000 or 5000
obscure bots, there are cases where the total number of IP addresses observed
by the adversary exceeds 100,000, suggesting that the obfuscation technique of
RatBot can lead to an overestimation more than 10 times of its actual size. On
the other hand, given the same number of obscure bots, the observed number of
IP addresses also varies signiﬁcantly among diﬀerent runs. In some scenarios, the
largest number of IP addresses observed is twice as much as the smallest number
of IP address observed in the 20 sample runs. It is also noted that the median
y
c
n
e
u
q
e
r
F
 4.5
 4
 3.5
 3
 2.5
 2
 1.5
 1
 0.5
 0
0-9
Run 1, authentic, no shift
Run 1, spoofing, no shift
Run 2, authentic, shift by 0.5 (Y-axis)
Run 2, spoofing, shift by 0.5 (Y-axis)
Run 3, authentic, shift by 1 (Y-axis)
Run 3, spoofing, shift by 1 (Y-axis)
Run 4, authentic, shift by 1.5 (Y-axis)
Run 4, spoofing, shift by 1.5 (Y-axis)
Run 5, authentic, shift by 2 (Y-axis)
Run 5, spoofing, shift by 2 (Y-axis)
)
y
l
l
o
b
a
u
t
n
e
v
e
(
d
e
v
r
e
s
b
o
s
t
f
o
r
e
b
m
u
n
l
a