那么，让我们来看看它是如何处理 I/O 的。Go 语言的一个关键特征是它包含自己的调度程序。在 Go 中，不是每个执行线程对应于一个单一的 OS 线程，其通过一种叫做 “ 协程   goroutine ” 的概念来工作。而 Go 的运行时可以将一个协程分配给一个 OS 线程，使其执行或暂停它，并且它不与一个 OS 线程相关联——这要基于那个协程正在做什么。来自 Go 的 HTTP 服务器的每个请求都在单独的协程中处理。
调度程序的工作原理如图所示：
![I/O Model Go](/data/attachment/album/201710/31/094320ass1uswfbnbp4qss.jpg)
在底层，这是通过 Go 运行时中的各个部分实现的，它通过对请求的写入/读取/连接等操作来实现 I/O 调用，将当前协程休眠，并当采取进一步动作时唤醒该协程。
从效果上看，Go 运行时做的一些事情与 Node 做的没有太大不同，除了回调机制是内置到 I/O 调用的实现中，并自动与调度程序交互。它也不会受到必须让所有处理程序代码在同一个线程中运行的限制，Go 将根据其调度程序中的逻辑自动将协程映射到其认为适当的 OS 线程。结果是这样的代码：
```
func ServeHTTP(w http.ResponseWriter, r *http.Request) {
    // the underlying network call here is non-blocking
    rows, err := db.Query("SELECT ...")
    for _, row := range rows {
        // do something with the rows,
// each request in its own goroutine
    }
    w.Write(...) // write the response, also non-blocking
}
```
如上所述，我们重构基本的代码结构为更简化的方式，并在底层仍然实现了非阻塞 I/O。
在大多数情况下，最终是“两全其美”的。非阻塞 I/O 用于所有重要的事情，但是你的代码看起来像是阻塞，因此更容易理解和维护。Go 调度程序和 OS 调度程序之间的交互处理其余部分。这不是完整的魔法，如果你建立一个大型系统，那么值得我们来看看有关它的工作原理的更多细节；但与此同时，你获得的“开箱即用”的环境可以很好地工作和扩展。
Go 可能有其缺点，但一般来说，它处理 I/O 的方式不在其中。
### 谎言，可恶的谎言和基准
对这些各种模式的上下文切换进行准确的定时是很困难的。我也可以认为这对你来说不太有用。相反，我会给出一些比较这些服务器环境的整个 HTTP 服务器性能的基本基准。请记住，影响整个端到端 HTTP 请求/响应路径的性能有很多因素，这里提供的数字只是我将一些样本放在一起进行基本比较的结果。
对于这些环境中的每一个，我写了适当的代码在一个 64k 文件中读取随机字节，在其上运行了一个 SHA-256 哈希 N 次（ N 在 URL 的查询字符串中指定，例如 .../test.php?n=100），并打印出结果十六进制散列。我选择这样做，是因为使用一些一致的 I/O 和受控的方式来运行相同的基准测试是一个增加 CPU 使用率的非常简单的方法。
有关使用的环境的更多细节，请参阅 [基准说明](https://peabody.io/post/server-env-benchmarks/) 。
首先，我们来看一些低并发的例子。运行 2000 次迭代，300 个并发请求，每个请求只有一个散列（N = 1），结果如下：
![Mean number of milliseconds to complete a request across all concurrent requests, N=1](/data/attachment/album/201710/31/094322yf579k1z343553l6.jpg)
*时间是在所有并发请求中完成请求的平均毫秒数。越低越好。*
仅从一张图很难得出结论，但是对我来说，似乎在大量的连接和计算量上，我们看到时间更多地与语言本身的一般执行有关，对于 I/O 更是如此。请注意，那些被视为“脚本语言”的语言（松散类型，动态解释）执行速度最慢。
但是，如果我们将 N 增加到 1000，仍然有 300 个并发请求，相同的任务，但是哈希迭代是 1000 倍（显着增加了 CPU 负载）：
![Mean number of milliseconds to complete a request across all concurrent requests, N=1000](/data/attachment/album/201710/31/094324zukvhu8ckp1pb5mp.jpg)
*时间是在所有并发请求中完成请求的平均毫秒数。越低越好。*
突然间， Node 性能显著下降，因为每个请求中的 CPU 密集型操作都相互阻塞。有趣的是，在这个测试中，PHP 的性能要好得多（相对于其他的），并且打败了 Java。（值得注意的是，在 PHP 中，SHA-256 实现是用 C 编写的，在那个循环中执行路径花费了更多的时间，因为现在我们正在进行 1000 个哈希迭代）。
现在让我们尝试 5000 个并发连接（N = 1） - 或者是我可以发起的最大连接。不幸的是，对于大多数这些环境，故障率并不显着。对于这个图表，我们来看每秒的请求总数。 *越高越好* :
![Total number of requests per second, N=1, 5000 req/sec](/data/attachment/album/201710/31/094326mwwewy6tisw4f1j2.jpg)
*每秒请求数。越高越好。*
这个图看起来有很大的不同。我猜测，但是看起来像在高连接量时，产生新进程所涉及的每连接开销以及与 PHP + Apache 相关联的附加内存似乎成为主要因素，并阻止了 PHP 的性能。显然，Go 是这里的赢家，其次是 Java，Node，最后是 PHP。
虽然与你的整体吞吐量相关的因素很多，并且在应用程序之间也有很大的差异，但是你对底层发生什么的事情以及所涉及的权衡了解更多，你将会得到更好的结果。
### 总结
以上所有这一切，很显然，随着语言的发展，处理大量 I/O 的大型应用程序的解决方案也随之发展。
为了公平起见，PHP 和 Java，尽管这篇文章中的描述，确实 [实现了](http://reactphp.org/) 在  [web 应用程序](https://netty.io/) 中 [可使用的](http://undertow.io/)  [非阻塞 I/O](http://amphp.org/) 。但是这些方法并不像上述方法那么常见，并且需要考虑使用这种方法来维护服务器的随之而来的操作开销。更不用说你的代码必须以与这些环境相适应的方式进行结构化；你的 “正常” PHP 或 Java Web 应用程序通常不会在这样的环境中进行重大修改。
作为比较，如果我们考虑影响性能和易用性的几个重要因素，我们得出以下结论：
| 语言 | 线程与进程 | 非阻塞 I/O | 使用便捷性 |
| --- | --- | --- | --- |
| PHP | 进程 | 否 |  |
| Java | 线程 | 可用 | 需要回调 |
| Node.js | 线程 | 是 | 需要回调 |
| Go | 线程 （协程） | 是 | 不需要回调 |
线程通常要比进程有更高的内存效率，因为它们共享相同的内存空间，而进程则没有。结合与非阻塞 I/O 相关的因素，我们可以看到，至少考虑到上述因素，当我们从列表往下看时，与 I/O 相关的一般设置得到改善。所以如果我不得不在上面的比赛中选择一个赢家，那肯定会是 Go。
即使如此，在实践中，选择构建应用程序的环境与你的团队对所述环境的熟悉程度以及你可以实现的总体生产力密切相关。因此，每个团队都深入并开始在 Node 或 Go 中开发 Web 应用程序和服务可能就没有意义。事实上，寻找开发人员或你内部团队的熟悉度通常被认为是不使用不同语言和/或环境的主要原因。也就是说，过去十五年来，时代已经发生了变化。
希望以上内容可以帮助你更清楚地了解底层发生的情况，并为你提供如何处理应用程序的现实可扩展性的一些想法。
---
via: 
作者：[BRAD PEABODY](https://www.toptal.com/resume/brad-peabody) 译者：[MonkeyDEcho](https://github.com/MonkeyDEcho) 校对：[wxy](https://github.com/wxy)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出