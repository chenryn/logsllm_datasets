var_14= dword ptr -14h
var_5= byte ptr -5
second_operand= dword ptr 8
first_operand= dword ptr 0Ch
push ebp
mov ebp, esp
push ebx
sub esp, 24h ; char *
mov eax, [ebp+first_operand]
mov [esp+28h+var_28], eax
call _atoi
mov ebx, eax
mov eax, [ebp+second_operand]
mov [esp+28h+var_28], eax
call _atoi
mov [esp+28h+var_1C], ebx
mov [esp+28h+var_20], eax
mov [esp+28h+var_24], offset aDAndD ; “%d and %d”
lea eax, [ebp+var_14]
mov [esp+28h+var_28], eax
call _sprintf
lea eax, [ebp+var_14]
mov [esp+28h+var_24], eax
mov [esp+28h+var_28], offset aTooManyArgumen ; “Too many
arguments...”
call _printf
mov [esp+28h+var_28], offset aProceedAnyway? ; “Proceed anyway?
[y/n]\r”
call _puts
call _getchar
mov [ebp+var_5], al
cmp [ebp+var_5], 79h
jz short loc_8048657
One goal might be to turn this assembly code listing back into its original code.
This is called decompilation. In general, for high-level languages such as C and C++,
the act of decompilation is infeasible at best. Consider that many different versions
of source code can correspond to the same assembly instructions. Also, aggressive
compiler optimizations can make decompilation difficult. The following is the
original C source code for the function disassembled above:
int error(char * a, char * b)
{
6760 Book.indb 58 12/22/17 10:50 AM
2.5 Bug Hunting Techniques 59
char small_buff[15];
char c;
sprintf(small_buff, “%d and %d”, atoi(a), atoi(b) );
printf(“Too many arguments were supplied. Only the first two (%s)
would get used.\r\n”, small_buff);
printf(“Proceed anyway? [y/n]\r\n”);
c = getchar();
if( c == ‘y’ || c == ‘Y’)
do_addition(a, b);
else
printf(“Ok, try again with better arguments.\r\n”);
}
However, it is not necessary to revert the application back to its original source
code in order to identify bugs. Good vulnerability analysts know that ‘sprintf’ is a
dangerous function (if the input is not trusted and used improperly), whether they
see it in a source code listing or in a disassembly of a binary. This sample code
does contain an error. In the source code, we see that ‘small_buff’ is only 15 bytes
long. We know that an integer (%d) when printing into a buffer can be as large as
10 bytes. The “and” portion of the buffer takes up 5 bytes. So, in total, 10 + 10 +
5 = 25 bytes can be written. Since that is larger than the space allocated, a buffer
overflow can occur here. While this is a contrived example, it does illustrate an
interesting point. If this function normally is used with only small integers passed to
it, the buffer will not typically overflow. It could be used by thousands of users all
the time without turning up the bug. It is only in extreme circumstances in which
this vulnerability will affect the execution of the program.
Understanding the size of ‘small_buff’ is a little more difficult from the disas-
sembly. ‘24h’ is subtracted from the stack, indicating the amount of space reserved
for local variables—only a portion of that space is the undersized buffer. Sometimes
an apparent bug seen in the source code will not exist in the binary depending on
how the compiler behaves. Therefore, a manual test of this potential flaw would
have to be conducted to prove or disprove this statically discovered bug.
Source code auditing is also used to analyze flaws. While this process might
appear easier or more logical than reverse engineering (since the actual program
source is available), such is not always the case. For example, a popular way to
employ Bindiff is to look at one version of a Microsoft application, then examine a
new version that has just been patched for security reasons. The difference between
the two should yield the original bug. Such a technique might identify bugs much
quicker than an entire review of a large code base.
Also, more than a few professional hackers have expressed that sometimes the
spotting of implementation flaws in assembly can actually be easier than in source
code. This is because complex lines of C or other high-level languages can be con-
voluted and hard to read. This could also be due to numerous macros, missing code
that is not linked in or expanded until compile time. Having said all that, there
certainly are advantages to having source code. Complex structure can quickly
be understood, comments are a huge advantage, and the auditor can simple grep
(search) for arbitrary combinations of code that could be problematic.
6760 Book.indb 59 12/22/17 10:50 AM
60 Software Vulnerability Analysis
2.5.2 Source Code Auditing
Source code auditing typically involves using automated tools, plus manual veri-
fication, to search source code for bugs. The source could be any type (a library,
headers, main program code) and in any language. The process will vary from
language to language.18
Again, to augment performing source code audits by hand, a variety of open
source and commercial tools exist to help highlight suspect code. The commercial
tools from companies like Coverity and Fortify tend to be very sophisticated and
capable of finding many different classes of vulnerabilities. The biggest drawback,
with regard to these static analysis tools, is the presence of false positives. While
these tools take care to minimize them, it is impossible to completely eliminate false
positives, and some code that is not problematic will be identified as a vulnerability.
As an open source example, Figure 2.8 illustrates the usage of the Rough Audit-
ing Tool for Security (RATS)19 to analyze the following program:
#include
void copy(char * ptr)
{
char buf[100];
strcpy(buf, ptr);
printf(“You entered: %s. Horray!\r\n”);
}
int main(int argc, char * argv[])
{
Figure 2.8 Running RATS against a trivial C source code file.
18 One recommended reading discussing code auditing in more detail is The Art of Software Security
Assessment: Identifying and Preventing Software Vulnerabilities, by Mark Dowd, John McDonald,
and Justin Schuh.
19 https://code.google.com/p/rough-auditing-tool-for-security/.
6760 Book.indb 60 12/22/17 10:50 AM
2.6 Fuzzing 61
if( argc != 2)
{
printf(“bad args\r\n”);
exit(-1);
}
copy(argv[1]);
}
In this simple case, the RATS tool effectively highlights the buffer overflow that
is present in the code. Note that it doesn’t actually prove the existence of a vulner-
ability, rather via the usage of heuristics states that one might exist because strcpy
was used. Therefore, even code using strcpy completely safely would be identified
(wrongly) as being potentially vulnerable. However, more sophisticated tools such
as those by Fortify and Coverity have a more sophisticated understanding of the
code and so can do a better job at identifying which strcpy’s are actually problem-
atic, among other things.
2.6 Fuzzing
The final remaining method of finding bugs is the actual topic of this book: Fuzz-
ing. One of the main strengths of fuzzing is that if an input crashes an application,
a problem definitely exists in the application (no false positives). It should be noted
that both source code audits and reverse engineering are (traditionally) a purely
static method for understanding the operation (and misoperation) of a given appli-
cation. However, actually executing the target for a few minutes can often yield
more understanding than hours of reverse engineering, at least from a high level.20
What if no understanding of an application was available and all we could do was
supply input? What if, for whatever reason, when we supply a malformed input, the
target crashes? This is the essence and origin of fuzzing. One of the first people to
employ fuzzing was Professor Barton Miller. He found that if random inputs were
given to core Unix command line utilities (like ls, grep, ps, passwd, etc.) many of
them would crash. This lack of robustness surprised him, and he went on to write
one of the first automated tools designed specifically to crash programs. His fuzzing
tool was dumb. However, in this context, the word dumb does not mean stupid. It
means that his fuzzing tool had no knowledge of what inputs these programs might
be expecting. That is, he merely sent random data as arguments to the functions.
Conversely, if his tool had been intelligent, it would have known that command a
always expects arguments b, in the forms c, d, or e. In later sections we’ll explain
when, where, and how nonintelligent/intelligence should be applied and balanced.
We’ll look at a number of topics, including how to build a fuzzer, how to reach the
lowest level of a protocol or application, types of fuzzers, where and when fuzzers
are most effective, what metrics to consider when fuzzing, and finally current and
future trends and research.
20 Paper on high-level reverse engineering is available here: www.net-security.org/article.php?id=1082.
6760 Book.indb 61 12/22/17 10:50 AM
62 Software Vulnerability Analysis
2.6.1 Basic Terms
Coverage is an important term that is used in testing, and the same applies for fuzz-
ing. From a vulnerability analysis perspective, coverage typically refers to simple
code coverage—that is, how many lines of the existing source code or compiled code
have been tested or executed during the test. Coverage could also measure path,
branch permutations, or a variety of other code coverage metrics.
A related term to coverage is attack surface: the amount of code actually exposed
to an attacker. Some code is internal and cannot be influenced by external data.
Examples of this include when a network server parses a configuration file or ini-
tially binds to a socket. This code should be tested, but cannot be externally fuzzed.
Since it cannot be influenced by external data, it is of little interest when finding
vulnerabilities. Thus, our interests lie in coverage of the attack surface. This is espe-
cially true for security researchers. Quality assurance professionals may be tasked
to test all of the code.
A trust boundary is any place that data or execution goes from one trust level
to another, where a trust level is a set of permissions to resources. For example,
data sent across a network to an application that parses that data is an example of
crossing a trust boundary. If the root user of a Unix system is the only one able to
start a given application (via command line arguments), priority would probably go
to fuzzing the network interface (assuming all or most untrusted users can access
the interface) instead of the command line arguments. This is true for two reasons:
A remotely exploitable bug is more interesting to attackers (since it can be done
remotely), but in terms of trust boundaries, an elevation of privilege (from none to
whatever the process runs as) can occur in the remote situation. Conversely, if the
user must already be root to gain root privileges (unless a tricky method is devised
to run the binary without root privileges), nothing has been gained, plus the attack
would only be local. The reading of the full-disclosure mailing list will often reveal
vulnerabilities in software if the application runs in an elevated privilege level. In
reality, many programs do not run at an elevated privilege level (think ls, rm, cat), so
a bug in these programs may not have security implications.21 Priority is important
to software companies and attackers alike because the problem of finding bugs is
difficult and time consuming. Neither is willing to waste much time (money) for
purely academic reasons; fuzzing is known for its ability to produce results.
Input source and input space are similar terms that refer to how data will be
generated (and ultimately delivered) to the application to be fuzzed (the target). The
input space is the entire set of all possible permutations that could be sent to the
target. This space is infinite, and that is why heuristics are used to limit this space
to be explored. Attack heuristics are known techniques for finding bugs in applica-
tions, normally based on the types of bugs discovered in the past.
2.6.2 hostile Data22
To find a vulnerability, you need to know what types of inputs will trigger the flaws.
And when you know why these inputs will cause an exception or a crash, you will
21 Unless those commands are executed by scripts running in higher privileges.
22 Each bug type (buffer overflow, format string, etc.) is further described in Section 2.7.
6760 Book.indb 62 12/22/17 10:50 AM
2.6 Fuzzing 63
be able to optimize the tests that you need to do. The examples below illustrate a
few simple heuristics against a typical (imaginary) simple string-based client-server
protocol.23
1. Buffer overflows are tested with long strings. For example:
[Client]-> “user jared\r\n”
“user Ok. Provide pass.\r\n”  “pass \r\n”
2. Integer overflows are tested with unexpected numerical values such as: zero,
small, large, negative: wrapping at numerical boundaries—2^4, 2^8, 2^16,
2^24: wrong number system—floats vs. integers. For example:
[Client]-> “user jared\r\n”
“user Ok. Provide pass.\r\n”  “pass jared\r\n”
“pass Ok. Logged in. Proceed with next command.\r\n”  “get [-100000.98] files: *\r\n”
Format string vulnerabilities are tested with strings such as:
[Client]-> “user ”
‘%n’s are useful because of the way the printf family of functions were
designed. A percent sign followed by a letter is referred to as a format
string.24 The ‘n’ is the only switch that triggers a write and is therefore use-
ful for triggering a crash while fuzzing. ‘x’ or ‘s’ may actually be a better
choice in some cases, as the ‘n’ usage may be disabled.25
3. Parse error: NULL after string instead of \r\n. Bad string parsing code might
be expecting a linefeed (\r or 0x0d) or newline (\n or 0x0a) in a given packet
and may incorrectly parse data if nothing or a NULL exists in its place. The
NULL (0x00) is special because string functions will terminate on it, when
perhaps the parsing code wouldn’t expect it to since no new-line is present.
[Client]-> “user jared0x00”
4. Parse error: Incorrect order and combined commands in one packet. Often,
network daemons expect each command to arrive in a separate packet. But
what if they don’t? And what if they’re out of order, and all strung together
with linefeeds in one packet? Bad things could happen to the parser.
[Client]-> “pass jared\r\nuser jared\r\n”
5. Parse error: Totally random binary data. If there is a particular character(s)
that the parser is looking for but might not handle well in an unexpected
scenario, this might uncover such an issue.
[Client]-> “\xff\xfe\x00\x01\x42\xb5...”
6. Parse error: Sending commands that don’t make sense—multiple login.
Design or logic flaws can also sometimes be uncovered via fuzzing.
[Client]-> “user jared\r\n”
“user Ok. Provide pass.\r\n”  “pass jared\r\n”
23 For more example inputs from web fuzzing, see www.owasp.org/index.php/OWASP_Testing_
Guide_Appendix_C:_Fuzz_Vectors.
24 See Section 2.7.1.1.
25 See http://blogs.msdn.com/michael_howard/archive/2006/09/28/775780.aspx.
6760 Book.indb 63 12/22/17 10:50 AM
64 Software Vulnerability Analysis
“pass Ok. Logged in. Proceed with next command.\r\n”  “user jared\r\n”
7. Parse error: Wrong number of statement helpers such as ‘../’, ‘{’, ‘(’, ‘[’, etc.
Many network protocols such as HTTP have multiple special chapters such
as ‘:’, “\\”, etc. Unexpected behavior or memory corruption issues can creep
in if parsers are not written very carefully.
[Client]-> “user jared\r\n”
“user Ok. Provide pass.\r\n”  “pass jared\r\n”
“pass Ok. Logged in. Proceed with next command.\r\n”  “get [1] files: {{../../../../etc/password\r\n”
8. Parse error: Timing issue with incomplete command termination. Suppose
we want to DoS the server. Clients can often overwhelm servers with a com-
mand that is known to cause processing to waiting on the server end. Or
perhaps this uses up all the validly allow connections (like a SYN flood26)
in a given window of time.
[Client]-> “user jared\r” (@ 10000 pkts/second with no read for server response)
2.6.3 Number of Tests
Again, it is obvious that the input space is infinite. This is why heuristics are used.
For example, if a buffer overflow occurs if a particular string is larger than 1,024
bytes, this can be found by sending a string of 1 byte, then 2, then 3, etc. Or it can
be found by sending a string of size 1, 2, 4, 8, etc. It is unlikely that an overflow
will exist that will not be found using this method, and yet it can greatly reduce
the number of test cases. Likewise, it would technically be possible to send totally
random data and get the same effect as using heuristics, but instead of the fuzzer
runtime being finite and reasonable ( centuries). Furthermore, with an increased number
of tests comes an increased load of logging.
The goal is to cover every unique test case, input space (without too much dupli-