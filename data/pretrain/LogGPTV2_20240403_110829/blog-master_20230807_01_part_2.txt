m = 32  
ef = 256  
$$);  
--- Or using IVFFlat algorithm.  
CREATE INDEX ON items USING vectors (embedding l2_ops)  
WITH (options = $$  
capacity = 2097152  
size_ram = 2147483648  
storage_vectors = "ram"  
[algorithm.ivf]  
storage = "ram"  
nlist = 1000  
nprobe = 10  
$$);  
```  
Now you can perform a KNN search with the following SQL simply.  
```sql  
SELECT *, emb  '[0, 0, 0]' AS score  
FROM items  
ORDER BY embedding  '[0, 0, 0]' LIMIT 10;  
```  
Please note, vector indexes are not loaded by default when PostgreSQL restarts. To load or unload the index, you can use `vectors_load` and `vectors_unload`.  
```sql  
--- get the index name  
\d items  
-- load the index  
SELECT vectors_load('items_embedding_idx'::regclass);  
```  
We planning to support more index types ([issue here](https://github.com/tensorchord/pgvecto.rs/issues/17)).  
Welcome to contribute if you are also interested!  
## Reference  
### `vector` type  
`vector` and `vector(n)` are all legal data types, where `n` denotes dimensions of a vector.  
The current implementation ignores dimensions of a vector, i.e., the behavior is the same as for vectors of unspecified dimensions.  
There is only one exception: indexes cannot be created on columns without specified dimensions.  
### Indexing  
We utilize TOML syntax to express the index's configuration. Here's what each key in the configuration signifies:  
| Key                    | Type    | Description                                                                                                           |  
| ---------------------- | ------- | --------------------------------------------------------------------------------------------------------------------- |  
| capacity               | integer | The index's capacity. The value should be greater than the number of rows in your table.                              |  
| size_ram               | integer | (Optional) The maximum amount of memory the persisent part of index can occupy.                                       |  
| size_disk              | integer | (Optional) The maximum amount of disk-backed memory-mapped file size the persisent part of index can occupy.          |  
| storage_vectors        | string  | `ram` ensures that the vectors always stays in memory while `disk` suggests otherwise.                                |  
| algorithm.ivf          | table   | If this table is set, the IVF algorithm will be used for the index.                                                   |  
| algorithm.ivf.storage  | string  | (Optional) `ram` ensures that the persisent part of algorithm always stays in memory while `disk` suggests otherwise. |  
| algorithm.ivf.nlist    | integer | (Optional) Number of cluster units.                                                                                   |  
| algorithm.ivf.nprobe   | integer | (Optional) Number of units to query.                                                                                  |  
| algorithm.hnsw         | table   | If this table is set, the HNSW algorithm will be used for the index.                                                  |  
| algorithm.hnsw.storage | string  | (Optional) `ram` ensures that the persisent part of algorithm always stays in memory while `disk` suggests otherwise. |  
| algorithm.hnsw.m       | integer | (Optional) Maximum degree of the node.                                                                                |  
| algorithm.hnsw.ef      | integer | (Optional) Search scope in building.                                                                                  |  
## Why not a specialty vector database?  
Imagine this, your existing data is stored in a Postgres database, and you want to use a vector database to do some vector similarity search. You have to move your data from Postgres to the vector database, and you have to maintain two databases at the same time. This is not a good idea.  
Why not just use Postgres to do the vector similarity search? This is the reason why we build pgvecto.rs. The user journey is like this:  
```sql  
-- Update the embedding column for the documents table  
UPDATE documents SET embedding = ai_embedding_vector(content) WHERE length(embedding) = 0;  
-- Create an index on the embedding column  
CREATE INDEX ON documents USING vectors (embedding l2_ops)  
WITH (options = $$  
capacity = 2097152  
size_ram = 4294967296  
storage_vectors = "ram"  
[algorithm.hnsw]  
storage = "ram"  
m = 32  
ef = 256  
$$);  
-- Query the similar embeddings  
SELECT * FROM documents ORDER BY embedding  ai_embedding_vector('hello world') LIMIT 5;  
```  
From [SingleStore DB Blog](https://www.singlestore.com/blog/why-your-vector-database-should-not-be-a-vector-database/):  
> Vectors and vector search are a data type and query processing approach, not a foundation for a new way of processing data. Using a specialty vector database (SVDB) will lead to the usual problems we see (and solve) again and again with our customers who use multiple specialty systems: redundant data, excessive data movement, lack of agreement on data values among distributed components, extra labor expense for specialized skills, extra licensing costs, limited query language power, programmability and extensibility, limited tool integration, and poor data integrity and availability compared with a true DBMS.  
## Setting up the development environment  
You could use [envd](https://github.com/tensorchord/envd) to set up the development environment with one command. It will create a docker container and install all the dependencies for you.  
```sh  
pip install envd  
envd up  
```  
## Contributing  
We need your help! Please check out the [issues](https://github.com/tensorchord/pgvecto.rs/issues).  
## Contributors ✨  
Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):  
      Alex Chi💻  
      Ce Gao💼 🖋 📖  
      Jinjing Zhou🎨 🤔 📆  
      Keming🐛 💻 📖 🤔 🚇  
      Usamoi💻 🤔  
      odysa📖 💻  
          Add your contributions  
This project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!  
## Acknowledgements  
Thanks to the following projects:  
- [pgrx](https://github.com/tcdi/pgrx) - Postgres extension framework in Rust  
- [pgvector](https://github.com/pgvector/pgvector) - Postgres extension for vector similarity search written in C  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
#### [PolarDB 云原生分布式开源数据库](https://github.com/ApsaraDB "57258f76c37864c6e6d23383d05714ea")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、内核开发公开课、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")