TaintART
App Launch Time
App Installation Time
348.2
1680.5
370.3
1886.3
Contacts Read/Write
7.0/9538.5
8.4/9655.2
6.1 Macrobenchmarks
Because TaintART is a general framework that can be
used by end-users to protect their privacy, we perform sev-
eral macrobenchmarks to measure the overhead for normal
usage. The evaluation results are shown in Table 5.
We ﬁrst evaluate the app’s load time. We create an app
based on Android 6.0.1 SDK with one activity (generated by
the app template of Android Studio 2.0 with Gradle 1.2.3).
We use an Android UI/application exerciser (i.e., the Monkey
tool [26]) to launch this app and record the time (t0). When
the attachBaseContext method is called, which means the
activity has been displayed on the screen, we record the time
(t1). Therefore, t1 − t0 represents the elapsed time from the
launch time into app context. The result indicates 22.1 ms
(6.0 %) overhead on app’s launch time. The overhead is
clearly acceptable because most of the logic for launching an
app is executed in the native code, and TaintART mainly
aﬀects runtime performance on the Java environment. For
the installation time, TaintART introduces about 205.8 ms
(12.2 %) overheads, which are mainly attributed to the in-
strumented ART compiler. We will present the evaluation
result of the compiler microbenchmark in the next subsec-
tion. Since we add taint sources on the content resolver, we
also evaluate the performance of reading and write contacts
in address book so as to demonstrate the impact. We ﬁrst
write 100 contacts with full information in batch through the
content resolver, then query these inserted contact names
for 100 times. The result shows that there are 20 % and
12 % overhead on read and write respectively. In summary,
TaintART introduces an acceptable level of overhead to
end-users or to analysts if they want to understand the in-
formation ﬂows.
6.2 Microbenchmarks
compiler and Java runtime. We also investigate the memory
usage and inter-process communication cost of TaintART.
Compiler Microbenchmarks Because TaintART in-
struments ART compiler and inserts taint logic at compi-
lation time, we evaluate the number of instructions and the
overall compilation time. For compiler microbenchmark, we
utilizes all 80 built-in apps in AOSP which can be found in
/out/target/common/obj/APPS/ as our evaluation dataset
including calculator, contacts, browser, download manager,
etc. We compile all apps using the original compiler and
TaintART compiler respectively and record the time of
compilation. Figure 8 illustrates the compilation time for
80 built-in apps. By adopting the TaintART compiler, the
average time increases from 336.076 milliseconds to 403.064
milliseconds and introduces about 19.9 % overhead. Because
Android uses ahead-of-time compilation strategy, an app is
only compiled once at the installation time. Therefore, the
overhead on compilation time is acceptable for analysis us-
age. In addition, we use oatdump to disassemble compiled
native code and categorize instructions into seven types.
Figure 9 depicts the total number of instructions for all 80
apps and the numbers in diﬀerent categories. The total num-
ber of instructions increases about 21 %. The increases are
mainly in data processing instructions (Type II) including
arithmetic instructions (ADD, SUB), logical instructions (ORR,
AND), movement instructions (MOV, MVN), etc. For memory
access instructions (Type I) which will cost more CPU cy-
cles, TaintART compiler only introduces about 0.8 % more
instructions. Because of this, the overhead of runtime per-
formance of TaintART is minimal, as we will show in the
Java microbenchmark later. This means that TaintART
can achieve better runtime performance than the VM-based
TaintDroid with the gains of AOT compilation strategy in
the new ART environment.
To understand the performance for some major compo-
nents in TaintART, we perform microbenchmarks on the
Java Microbenchmark Because Android apps are mainly
written in Java and TaintART tracks information ﬂows in
Figure 8: Comparison of compilation time.
Figure 10: CaﬀeineMark 3.0 Java microbenchmark.
Error bars indicate 95 % conﬁdence intervals.
Figure 9: Comparison of instruction numbers for
diﬀerent types.
Figure 11: CaﬀeineMark 3.0 memory microbench-
mark. Error bars indicate 95 % conﬁdence intervals.
apps, Java microbenchmark can accurately reﬂect the run-
time overhead introduced by TaintART. We utilize Caf-
feineMark 3.0 Java benchmark tools [39] to evaluate six
types of operations including sieve, loop, logic, string, ﬂoat
and method call. Note that the scores of CaﬀeineMark 3.0
are only useful for relative comparison. For comparison, we
evaluate and record scores in ﬁve diﬀerent runtime environ-
ments on the same Nexus 5 device: (1) ART with optimizing
compiler backend, (2) ART with quick compiler backend, (3)
interpreter only, (4) TaintART compiler, and (5) Dalvik in
Android 4.4. We run the tool ten times and record scores
for each sub-benchmark. Figure 10 illustrates scores for each
environment. Compared to the original ART compiler with
optimizing backend, TaintART compiler introduces about
14 % overhead overall and it is comparable with its prede-
cessor TaintDroid. Most importantly, we notice that ART
brings a huge improvement over the legacy Dalvik environ-
ment. Compared to the legacy Dalvik environment without
any instrumentation, TaintART can achieve about 99.8 %
more scores for overall runtime performance.
Memory Microbenchmark We also perform the memory
microbenchmark. We run the CaﬀeineMark 3 Java bench-
mark tool ten times and monitor the /proc/[pid]/status
ﬁle at runtime. Figure 11 shows the virtual memory resi-
dent set (VmRSS) size at runtime representing the portion
of memory occupied by the benchmark process in memory.
Because TaintART mainly relies on CPU registers for taint
tag storage, the overhead on memory usage is only about
0.4 %. For comparison, TaintDroid introduces 4.4 % mem-
ory overhead mainly because it doubles the size of internal
stack of Dalvik VM for storing taint tags, and we avoid this
by carefully using the register resources.
IPC Microbenchmark To carry out the IPC benchmark
of TaintART, we developed client and server applications
which communicate through binder. The client app will send
messages to server for setting and getting an object. The
object contains a string and an integer ﬁeld. We continu-
ously conduct pair of getting and setting requests for ten
thousand times and record their execution times. We also
average memory usages for client app and server app during
the communication phase. Table 6 depicts the benchmark
results. There are about 4.35 % overhead on IPC execution,
and less than 4 % memory overhead.
6.3 Compatibility Evaluation
We also evaluate the compatibility of TaintART using
Android Compatibility Test Suite (CTS) in 6.0_r5 version.
We execute the standard CTS plan which contains 131 test
package in total. We select several system, runtime and se-
curity test packages and illustrate some partial results (due
to page limit) in Table 7. Both TaintART and original
devices failed on the same 186 cases among 100317 cases.
These failed cases are relevant and mainly caused by envi-
ronmental setups such SD card or SIM card. There are three
02040608001,0002,0003,000336.067403.064IndexofBuilt-inAppsCompilationTime(milliseconds)OriginalTaintART00.20.40.60.811.21.4·107I:5,028,730,II:5,159,454,III:2379,IV:1,906,759,V:747,014,VI:61,898,VII:132,760I:4,988,969,II:2,747,897,III:2379,IV:1,909,696V:904,164,VI:61,693,VII:130,33813,038,99410,745,136TaintARTCompilerOriginalCompilerNumberofInstructions(ARM)I.MemoryaccessinstructionsII.DataprocessinginstructionsIII.MultiplyinstructionsIV.Branch/controlinstructionsV.BarrelshifterinstructionsVI.VFPinstructionsVII.OtherinstructionsSieveLoopLogicStringFloatMethodOverall025,00050,00075,000100,000125,000150,00049,826.5101,470.4124,526.225,328.238,948.339,657.853,926.749,084.156,800.2110,183.426,303.835,675.734,255.846,306.9BenchmarkItemofCaffeineMark3.0CaffeineMark3.0ScoreOptimizingCompilerBackendQuickCompilerBackendInterpreterOnlyTaintARTDalvikVM(4.4)051015202505,00010,00015,00020,00025,000ElapsedTimeofLaunchingCaffeineMark(seconds)MemoryUsageofCaffeineMark(kB)ART(OptimizingBackend)TaintARTTable 6: IPC Throughput Benchmark (10,000 pairs
of messages).
Macrobenchmark Name
Original TaintART Overhead
Execution Time
Memory (client)
2987 ms
3117 ms
51 572 kB
53 170 kB
Memory (server)
38 812 kB
39 689 kB
4.35 %
3.10 %
2.26 %
Table 7: Android Compatibility Test Suite (CTS)
results. The preﬁxes on test package names were
removed for simple representations.
Test Package
# of Tests
Tests Failed
Android TaintART
app
content
bionic
libcore
database
location
os
telephony
util
security
others
266
619
1274
23 371
264
99
409
67
206
103
100 317
Total (131 packages)
126 995
6
0
0
0
0
0
0
6
0
0
6
0
0
0
0
0
0
6
0
3
156
186
159
189
more failed cases introduced by TaintART in security test
package. The reason is that TaintART needs root privilege
to deploy on stock devices. In summary, TaintART cus-
tomizes the Android runtime and compiler, but maintains
similar compatibility level when compare with the original
Android environment.
7. DISCUSSION
Limitations Here, we discuss some limitations of Taint-
ART (and we like to state that other dynamic taint analysis
systems have the same limitations). Firstly, TaintART can-
not eﬀectively track implicit data ﬂows. This means that
attackers can ﬁnd ways [29, 45] to exchange data without
the track of TaintART. Because of the limitation of taint
analysis methodology, we cannot exhaustively monitor all
implicit leakage. Our goal is to track common explicit data
ﬂows for privacy leakage analysis and increase the bar for
malware writers. Secondly, malware can utilize some anti-
analysis techniques [40] to detect host devices. For example,
malware can infer the running system by inspecting the size
of compilation binary ﬁle. Thirdly, for malware analysis,
analysts need to manually trigger the behaviors. However,
researchers [54] have proposed various methodologies to gen-
erate input for dynamic analysis.
TaintART on Other Architectures Because most mo-
bile devices are based on the ARM architecture (99 % ac-
cording to [7]), our TaintART prototype is implemented on
an 32-bit ARM-based device. For the ARM64 (AArch64) ar-
chitecture, it provides 31 general-purpose registers. We can
utilize three of them (i.e., X25, X26, and X27) for taint tags
(tracking 24 registers for data storage in Android). In this
case, we can obtain eight bits for each tag to store more se-
mantics. In addition, AArch64 also has a set of instructions
(e.g., UBFX) for moving and copying bits among registers.
This will make propagation logic much easier and faster.
Moreover, due to availability of registers, performance over-
head will be comparable with (even better than) 32-bit ar-
chitecture. In addition, the latest Android version supports
other architectures including x86-64. To support other ar-
chitectures, we plan to port the ARM code generator of
TaintART compiler to other code generators so as to uti-
lize architecture-speciﬁc features. This is our future work.
8. RELATED WORK
With the rapid growth of mobile users, hackers and
researchers investigated many severe vulnerabilities and pro-
posed mitigation solutions [20, 28, 47, 66, 64, 18, 56, 13, 65,
44, 32, 48, 60, 6, 49, 4] in current mobile ecosystem. To un-
derstand the hidden malicious behaviors of malware such as
stealing private and sensitive information, researchers pro-
posed app analysis methodologies via dynamic and static
perspective. Based on these methodologies, some runtime
policy enforcement systems are proposed to prevent mali-
cious events or privacy leakage.
Dynamic Analysis System There are many systems
which dynamically monitor runtime information in diﬀer-
ent layers of the system. DroidScope [59], BareCloud [34]
and CopperDroid [51] introspect Dalvik VM to capture dy-
namic information for reconstructing malware behaviors.
VetDroid [61] analyzes permission usages to ﬁnd informa-
tion leaks and identiﬁes subtle vulnerabilities of apps. Poe-
plau et al. [41] systematically analyze malicious dynamic
code loading by a customized Dalvik VM. Similar to virtual
machine introspection technique, to reduce privacy leakage
across apps (unregulated aggregation), LinkDroid [21] an-
alyzes app links across diﬀerent apps dynamically. Note
that these systems are proposed for monitoring malicious
behaviors, they cannot track information-ﬂow which can ac-
curately detect privacy leakage. Minemu [8] is a general dy-
namic taint analysis system based on an optimized emulator
with JIT compilation. Similar with Minemu, TaintDroid [19]