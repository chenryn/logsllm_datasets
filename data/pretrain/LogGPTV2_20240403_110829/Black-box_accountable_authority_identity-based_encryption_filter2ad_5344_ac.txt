of size k for each j ∈ [m]. Compute the ciphertext C as
follows.
C = ({Jj}j∈[m], c = M · Y s,{(Ci = Ui,IDi
{(Ci,j = Ti,j
s) : j ∈ [m], i ∈ Jj})
s) : i ∈ [‘]},
The key generation for ID was set up so that if on each
component j ∈ [m] the user’s dummy attributes (Ij) inter-
sect the ciphertext’s dummy attributes (Jj) by more than
τ then the user can decrypt the message.
Decryption To decrypt the ciphertext
C = ({Jj}j∈[m], c,{Ci},{Ci,j})
using dID = ({di}i∈[‘],{(Ij,{di,j}i∈Ij )}j∈[m]), ﬁrst run a ci-
phertext sanity check on C, which we will deﬁne.
If the check fails, output ⊥. Otherwise, recover the mes-
sage M by selecting (for each j ∈ [m]) a set Sj ⊂ Ij ∩ Jj of
threshold size τ and performing the following computations:
c/ Y
e(Ci, di) Y
j∈[m]
i∈[‘]
= M · e(g, g)sy/ Y
i∈[‘]
(0)
(e(Ci,j, di,j))∆i,Sj
Y
i∈Sj
e(gsui,IDi , gri/ui,IDi )
(e(gsti,j , gqj (i)/ti,j ))∆i,Sj
(0)
Y
i∈Sj
Y
j∈[m]
= M · e(g, g)sy/e(g, g)sy0 Y
= M · e(g, g)sy/e(g, g)sy0 Y
j∈[m]
j∈[m]
e(g, g)sqj (0)
e(g, g)syj
= M
The decryption algorithm outputs ⊥ if there exists a j
such that |Ij ∩Jj| < τ . In Appendix A, we show an instan-
tiation of the parameters such that this case only happens
with negligible probability.
Ciphertext Sanity Check We speciﬁcally name this sub-
routine of the decryption algorithm for later reference in
the security analysis (Section 4.4). Our ciphertext sanity
check is similar to that in [17]. Given a ciphertext C =
({Jj}j∈[m], c,{Ci},{Ci,j}) for an identity ID, we deﬁne a
(deterministic) algorithm to check the well-formedness of
this ciphertext. Verify that
e(Ci, U1,ID1 ) ?= e(Ui,IDi , C1),
e(Ci,j, U1,ID1 ) ?= e(Ti,j, C1), j ∈ [m], i ∈ Jj
i ∈ [‘], and
If all of the above are veriﬁed, then the ciphertext sanity
check passes, otherwise it fails.
Trace This algorithm takes an identity ID, a well-formed
decryption key dID (i.e., passing the key sanity check) and
a decoder box D which is -useful (where  is polynomially
related to the security parameter). For convenience, we as-
sume that the message space is suﬃciently large so that the
probability of guessing a randomly chosen message is negli-
gible in the security parameter. We note that the algorithm
can be easily extended to the general case (and addition-
ally, it would require the input  to be “non-trivial”, i.e.,
noticeably higher than the probability with which a ran-
domly chosen message can be guessed correctly). Our trac-
ing algorithm will run in time polynomial in the number of
 . For each j ∈ [m] ﬁx an Xj ⊂ ([n] \ Ij)
repetitions m and 1
of size 1 + k− τ . Note that if C is a ciphertext with Jj ⊃ Xj
for any j, then this ciphertext cannot be decrypted by an
honest user. We will use this fact to attempt to catch the
PKG cheating because the PKG is oblivious to an honest
user’s key. The tracing algorithm will repeat the following
experiment η = ( 6m
 )2 times:
1. Iterate j? ∈ [m] and perform the following test:
(a) Choose a random Jj? ⊃ Xj? , and the remaining
{Jj}j6=j? at random.
(b) Encrypt a random message using {Jj} as the ci-
phertext dummy attributes.
(c) Test if the box correctly decrypts the message.
If it does, immediately implicate the PKG by re-
turning PKG and stop, otherwise continue.
If at the end of the experiment the PKG has not been impli-
cated, then the algorithm implicates the user by returning
User and stops. In the next section, we show that the above
simple tracing mechanism works except with negligible prob-
ability even though the ciphertexts on which we probe the
box are coming from a special distribution (rather than sim-
ply being random ciphertexts for the given identity).
In the full version [18], we show how to modify the above
scheme to achieve perfect completeness by running a “com-
plementary scheme” in parallel.
4.3 A Modiﬁcation For IND-ID-CPA Security
We describe a simple method to augment our construc-
tion to achieve IND-ID-CPA security. We can secret share
our message M by choosing a random M1 and setting M2 =
M − M1. We then encrypt M1 using our construction and
encrypt M2 using a IND-ID-CPA secure IBE scheme. Be-
cause both our construction and the Waters IBE scheme
rely on the decisional BDH assumption, we may achieve
IND-ID-CPA security in our scheme by including the pub-
lic parameters of the Waters IBE scheme into our own and
modifying the encryption and decryption schemes to secret
share the message as just described.
4.4 Security Proofs
We now prove the security of the scheme described above.
Recall that there is a global security parameter λ for which
we implicitly refer to whenever we mention “negligible” or
“polynomial”. We begin by addressing the IND-ID-CPA se-
curity of the scheme.
Theorem 1. The advantage of an adversary in the
IND-ID-CPA game is negligible for the above A-IBE scheme
under the decisional BDH assumption.
The above theorem follows trivially from the IND-ID-CPA
security of Waters construction [25]. Given an adversary
to break the IND-ID-CPA security of our construction, it
is straightforward to construct an adversary to break the
IND-ID-CPA security of Waters construction. We shall omit
the details from this paper.
Similar to [25], we remark that with small modiﬁcations,
it is possible to achieve IND-ID-CCA security by using tech-
niques of Canetti, Halevi and Katz [12]. We can also use
other methods [7, 8] to achieve greater eﬃciency. We can
also run diﬀerent IBE schemes such as the Gentry IBE scheme
[16] so long as we make the necessary additional security as-
sumptions.
Theorem 2. Assuming that the underlying k-out-of-n obliv-
ious transfer protocol is secure as per the ideal/real world
security deﬁnition 1 [10], the advantage of an adversary in
the DishonestPKG game is negligible for the above scheme.
Proof: Assume towards a contradiction that an adversary
A0 has some non-negligible probability ε of success. We
will eventually work to contradict a combinatorial lemma
(Lemma 5). We begin by replacing the oblivious transfer
protocol by an ideal OT functionality. By the security of the
simulation of the oblivious transfer protocol, the adversary
may lose at most a negligible advantage moving between the
two worlds. This can be stated as the following lemma:
Lemma 1
(Composition theorem (Canetti [10])).
For every adversary A0 which succeeds with probability ε in
the real world, there exists an A which succeeds in the ideal
OT world which succeeds with probability δ where |ε−δ| < ν1
and ν1 is negligible.
Let SUCC be the event that the adversary A succeeds in
this game. Let rA denote the randomness for this adversary,
and rC denote the randomness for the challenger. Recall
that the only randomness used by the challenger is during
the key generation protocol where it selects a set of dummy
attributes. We henceforth identify rC as also being a set of
1As discussed in Section 2, the existence of such k-out-of-n
oblivious transfer is implied by the decisional BDH assump-
tion.
dummy attributes {Ij}. Let E1 be the event that the execu-
tion of the adversary will not cause an abort in the key gen-
eration phase with probability at least δ/2. That is to say, E1
holds for the set of rA on which P r[Ch ﬁnishes KeyGen] ≥
δ/2 where the probability is taken over the randomness of
the challenger.
Lemma 2. The probability that event E1 occurs is at least
δ/2.
Proof: Observe that when E1 does not occur, A has at most
a δ/2 chance of success due to the fact that the challenger
will abort in the key generation phase with at least a 1− δ/2
probability. Thus we can lower bound the probability of E1
occurring by δ/2 using Markov’s inequality. (cid:4)
In other words, a δ/2 fraction of all possible dummy at-
tribute choices for ID will result in a well-formed decryption
key. We now focus on the executions on which E1 occur. The
expected success probability of the adversary must still be at
least δ because every execution where E1 does not occur will
fail with probability at least δ/2. Because the challenger
selects dummy attributes uniformly at random in the key
generation protocol, this implies at least a δ/2 fraction of all
dummy attribute sets will lead to the challenger receiving a
well-formed decryption key. We shall argue that even after
the decryption query phase, there are still too many possible
choices of dummy attributes for the adversary’s decoder box
to succeed against a non-negligible fraction of them.
Let E2 be the event that the challenger did not abort in the
key generation phase. Indeed, the success probability of the
adversary can only increase if we condition on E2 occurring:
anytime E2 does not occur, the adversary immediately loses.
If the challenger did not abort in the key generation phase,
then the ﬁnal check (Step 9) in the key generation protocol
guarantees that
where
Y = Y
i∈[‘]
e(Ui,IDi , di) Y
j∈[m]
Yj
Yj = Y
i∈S
e(di,j, Ti,j)∆i,S (0).
As a reminder, the key sanity check guarantees that the di,j
implicitly deﬁne a unique degree τ −1 polynomial qj for each
j. If in the decryption query phase a ciphertext
C = ({Jj}j∈[m], c,{Ci},{Ci,j})
i,IDi and Ci,j = T r
is asked to the challenger, the ciphertext sanity check in the
decryption algorithm guarantees that there is some unique
r such that Ci = U r
i,j. Regardless of which
di,j are used to decrypt (as noted above, they all deﬁne a
unique polynomial), one can see by algebraic manipulation
that the decryption will always return c/Y r provided that
|Ij ∩ Jj| ≥ τ for all j ∈ [m]. Note that for any ﬁxed cipher-
text, over a random choice of all the user’s dummy attributes
{Ij}, there is only a negligible probability that the user can-
not decrypt. This is inherent by the proper construction of
k,n,τ and m. We will call this negligible quantity ν2.
Let E3 be the event that all well-formed ciphertexts were
properly decrypted (i.e. the challenger did not fail on any
query to decrypt due to insuﬃcient intersection of dummy
attributes). We now analyze the probability of this event
occurring and how it aﬀects the view of the adversary. We
shall argue that the probability that E3 does not occur given
E1 ∧ E2 is negligible. We deﬁne this quantity to be ν3.
We stratify E3 as the conjunction of the events “Ch did not
fail on query i”. For some random tape rC of the challenger,
let {Ij} be the dummy attributes deﬁned by it, and let {J i
j }
be the dummy attributes in the ith ciphertext query, we
deﬁne GOODi to be the event that |Ij ∩ J i
j | ≥ τ for all
j ∈ [m]. Deﬁne Fi = GOOD1 ∧ . . .∧ GOODi. First, we prove
a lemma about the view of the adversary.
Lemma 3. Fix a random tape rA of the adversary such
that E1 occurs. Let rC , r0
C be any two arbitrary elements
from the set {rC : E2 ∧ Fi∗−1 holds}. Before query i∗ is
made, the view of the adversary in the execution where Ch
uses rC as its random tape is identical to the view in the
execution where Ch uses r0
C as its random tape.
Proof: After the key generation phase, the adversary learns
only whether or not the challenger aborted. Up to this point,
because we are in the ideal OT world, this is the only in-
formation the adversary learns. Event E2 occurring means
the challenger did not abort and received a well-formed key.
On every query i before the i∗th query, if the ciphertext is
malformed, the challenger will reject regardless of its own
dummy attributes, and if it is well-formed, then GOODi
guarantees that there are suﬃciently many attributes in the
intersection between the challenger’s dummy attributes and
the ones in the ciphertext, and so the challenger will reply
with c/Y r. (cid:4)
We now prove the statement that for any ﬁxed random
tape rA of the adversary such that E1 occurs, P r[¬E3|E2] ≤
2qν2
δ/2 where the probability is taken over the random tapes
of the challenger.
Lemma 4. Fix a random tape rA of the adversary such
δ/2 . We deﬁne the
that E1 occurs, then P rrC [¬E3|E2] ≤ 2qν2
negligible quantity on the right hand side to be ν3.
Proof: Let p2 be the probability that event E2 occurs. Be-
cause we ﬁxed an execution where E1 occurs, we have that
p2 ≥ δ/2. We shall prove inductively that P r[E2 ∧ Fi] ≥
p2 − iν2.
By Lemma 3, before the ﬁrst ciphertext query, the adver-
sary has no information about rC other than E2 occurred.
Hence, the ﬁrst ciphertext is independent of any rC for which
E2 holds. Recall that for any ciphertext, ν2 is the negligible
fraction of user keys that cannot decrypt it. The proba-
bility that a uniformly selected rC conditioned on E2 will
fail on the ﬁrst ciphertext query is P r[¬GOOD1|E2] ≤ ν2
.
Thus P r[GOOD1|E2] ≥ 1 − ν2
p2
and so there is at least a
(1 − ν2
) · p2 = p2 − ν2 fraction of the random tapes remain-
ing which satisfy E2 ∧ GOOD1.
p2
p2
On the ith query, the queried ciphertext once again cannot
In the
be decrypted by a ν2 fraction of all possible rC ’s.
worst case, this fraction is disjoint from the ones excised
by the ﬁrst i − 1 queries. By Lemma 3, the adversary has
no information about rC other than E2 ∧ Fi−1 occurred.
The ith query is independent of any rC for which E2 ∧ Fi−1
holds. By induction, this accounts for at least a p2−(i−1)ν2
fraction of all possible rC ’s. The probability that a uniformly
selected rC conditioned on E2 ∧ Fi−1 will fail to decrypt the
ith ciphertext query is P r[¬GOODi|E2 ∧Fi−1] ≤
.
p2−(i−1)ν2
ν2
Consequently, we calculate that P r[E2 ∧ Fi] is at least p2 −
iν2.
Eventually after q queries, we have P r[E2 ∧ E3] = P r[E2 ∧
≥ 1 − 2qν2
Fq] is at least p2 − qν2. So P r[E3|E2] ≥ 1 − qν2
from which the lemma follows. (cid:4)
p2
δ
Finally, the adversary must output a decoder box D. We
show that any decoder box can implicate the user in only
a negligible fraction of dummy attribute sets. We call this