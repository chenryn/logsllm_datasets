k = 0, . . . , N − 1.
Since the DFT is a weighted sum with ﬁxed coefﬁ-
cients e−i2π kn
the derivative for the backpropagation is
N ,
simply the corresponding coefﬁcient
∂X(t, k)
∂xw(t, n)
= e−i2π kn
N ,
k, n = 0, . . . , N − 1.
3) Magnitude: The output of the DFT is complex valued,
but as the phase is not relevant for speech recognition, we just
use the magnitude of the spectrum, which is deﬁned as
|X(t, k)|2 = Re(X(t, k))2 + Im(X(t, k))2,
with Re(X(t, k)) and Im(X(t, k)) as the real and imaginary
part of X(t, k). For the backpropagation, we need the deriva-
tive of the magnitude. In general, this is not well deﬁned and
allows two solutions,
We circumvent
this problem by considering the real and
imaginary parts separately and calculate the derivatives for
both cases
(cid:32) ∂|X(t,k)|2
∂ Re(X(t,k))
∂|X(t,k)|2
∂ Im(X(t,k))
(cid:18)2 · Re(X(t, k))
2 · Im(X(t, k))
(cid:19)
=
∇X(t, k) =
.
(2)
This is possible, as real and imaginary parts are stored sep-
arately during the calculation of the DNN, which is also
sketched in Figure 4, where pairs of nodes from layer 2
are connected with only one corresponding node in layer 3.
Layer 3 represents the calculation of the magnitude and
therefore halves the data size.
4) Logarithm: The last step is to form the logarithm of the
squared magnitude χ = log(|X(t, k)|2), which is the common
feature representation in speech recognition systems. It is easy
to ﬁnd its derivative as
∂χ
∂|X(t, k)|2 =
1
|X(t, k)|2 .
6
Fig. 4: For the creation of adversarial samples, we use an ASR
system where the preprocessing is integrated into the DNN.
Layers 1–4 represent the separate preprocessing steps. Note
that this is only a sketch of the used DNN and that the used
DNN contains far more neurons.
F. Hearing Thresholds
Psychoacoustic hearing thresholds allow us to limit audible
distortions from all signal manipulations. More speciﬁcally,
we use the hearing thresholds during the manipulation of the
input signal
in order to limit audible distortions. For this
purpose, we use the original audio signal to calculate the
hearing thresholds H as described in Section II-D. We limit
the differences D between the original signal spectrum S and
the modiﬁed signal spectrum M to the threshold of human
perception for all times t and frequencies k
D(t, f ) ≤ H(t, k),
∀t, k,
with D(t, k) = 20 · log10|S(t, k) − M (t, k)|
.
maxt,k(|S|)
The maximum value of the power spectrum |S| deﬁnes the
reference value for each utterance, which is necessary to
calculate the difference in dB. Examples for |S|, |M|, |D|,
and H in dB are plotted in Figure 5, where the power spectra
are plotted for one utterance.
able via
(3)
The resulting matrix Φ contains the difference in dB to the
calculated hearing thresholds.
Φ = H − D.
In the following step, we use the matrix Φ to derive scaling
factors. First, because the thresholds are tight, an additional
variable λ is added, to allow the algorithm to differ from the
hearing thresholds by small amounts
Φ∗ = Φ + λ.
(4)
In general, a negative value for Φ∗(t, k) indicates that we
crossed the threshold. As we want to avoid more noise for
these time-frequency-bins, we set all Φ∗(t, k)  0, as only these are in
excess of the hearing thresholds. This may happen when λ
is set to values larger than zero, or where changes in one
frequency bin also affect adjacent bins.
We sum all values Φ(t, k) > 0 for t = 0, . . . , T − 1
and k = 0, . . . , N − 1 and divide the sum by T · N for
normalization. This value is denoted by φ. It constitutes our
measure of the degree of perceptibility of noise.
C. Improving the Attack
As a baseline, we used a simpliﬁed version of the algo-
rithm, forgoing both the hearing thresholds and the forced
alignment stage. In the second scenario, we included the
proposed hearing thresholds. This minimizes the amount of
added noise but also decreases the chance of a valid adversarial
example. In the ﬁnal scenario, we added the forced alignment
step, which results in the full version of the suggested algo-
rithm, with a clearly improved WER.
For the experiments, a subset of 70 utterances for 10
different speakers from one of the WSJ test sets was used.
1) Backpropagation: First, the adversarial attack algorithm
the hearing thresholds or the forced
was applied without
8
50403020100  in dB050100WER in %with forced alignmentwithout forced alignment50403020100  in dB051015 in dBwith forced alignmentwithout forced alignmentTABLE I: WER in % for different values for λ in the range of
0 dB to 50 dB, comparing speech and music as audio inputs.
TABLE II: The perceptibility φ over all samples in the test
sets in dB.
Iter.
500
1000
500
1000
None
50 dB
40 dB
30 dB
20 dB
10 dB
0 dB
2.14
1.79