On `2012.12.18` the AWS region us-east-1 experienced an outage affecting
service of the DescribeInstances and DescribeTags APIs. This is turn brought
our two independent clusters operating in the region, as the Kubelet AWS
clustering mechanisms rely on the DescribeInstances API. Networking was
unaffected - master and nodes could still communicate without problem.
I propose that this AWS failure should not bring down a cluster.
The relevant Kubelet log message:
> Error updating node status, will retry: failed to get node address from
> cloud provider: no instances found for name: ip- _-_ - _-_.ec2.internal
There are several issues that relate to this functionality. I am filing this
issue to ensure that Kubernetes is not needlessly vulnerable to this type of
outage.
_Possibly Related_  
#17643 use private ip instead of local hostname for AWS  
#18525 We shouldn't use node names as addresses
Incident details from http://status.aws.amazon.com/
> 1:02 PM PST We are investigating elevated latencies and error rates for the
> DescribeInstances and DescribeTags APIs in the us-east-1 region. Customers
> may observe elevated error rates or missing tags for instances in the AWS
> Management Console.  
>  1:44 PM PST We have identified the root cause of elevated latencies and
> error rates for the DescribeInstances and DescribeTags APIs and are
> currently working to resolve. Customers may observe elevated error rates or
> missing tags for instances in the AWS Management Console.  
>  3:03 PM PST Between 12:30 PM and 2:44 PM PST, we experienced elevated
> latencies and error rates for the DescribeInstances and DescribeTags APIs.
> During this period, customers may have observed elevated error rates and
> missing tags for instances in the AWS Management Console. During this event,
> instances continued running normally. Tags requested during this period are
> now visible. This issue has been resolved and the service is operating
> normally.