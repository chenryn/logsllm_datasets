椅，轮毂，电子装置一样。
Q9：如果换云平台，比如从AWS到第三方，Eru需要多
大改造？
基本不需要，Eru 支持 host 模型，只不过就得在业务层去控制端
口冲突了，不过好在目前我们上云的业务还比较纯粹，不会出现混
排的需求。不过未来在这一块，我们有这样的计划：
 push 云支持自建子网（但不跟机器绑定），Azure 表示甲方（其
实我们才是乙方）您出钱我出命。
 Calico 这个方案和 MacVLAN 同时支持，这个就等我前领导
@洪强宁@宜信 那边的实现了。
高可用架构 40
Docker 实战
微博基于 Docker 容器的混合云
迁移实战
为什么要采用混合云的架构
在过去很长的时间内，大部分稍大些的互联网系统包括微博都是基
于私有体系的架构，可以在某种程度理解成私有云系统。混合云，
顾名思义就是指业务同时部署在私有云和公有云，并且支持在云之
间切换。实际上“为什么要采用混合云”这个问题，就等于“为什
么要上公有云”。我们的考虑点主要有四个方面
作者/ 陈飞
微博研发中心技术经理及高 业务场景
级技术专家。2008年毕业
随着微博活跃度的提升，以及push常规化等运营刺激，业务应对
于北京邮电大学，硕士学
位。毕业后就职华为北研。 短时极端峰值挑战，主要体现在两个方面：
2012年加入新浪微博，负
 时间短，业务需要应对分钟级或者小时级。
责微博Feed、用户关系和
微博容器化相关项目，致  高峰值，例如话题经常出现10到20倍流量增长。
力于Docker技术在生产环
境中的规模化应用。2015 成本优势
年3月，曾 在QClub北 京
对于短期峰值应对，常规部署，离线计算几个场景，我们根据往年
Docker专场分享《大规模
Docker集群助力微博迎接 经验进行成本对比发现公有云优势非常明显。
春晚峰值挑战》。
高可用架构 41
效率优势
公有云可以实现5分钟千级别节点的弹性调度能力，对比我们目前
的私有云5分钟百级别节点的调度能力，也具有明显优势。
业界趋势
“Amazon首次公布AWS业绩：2014年收入51.6亿美元，2015
年1季度AWS收入15.7亿美元，年增速超40%。”“阿里巴巴旗下
云计算业务阿里云营收6.49亿元，比去年同期增长128%，超越亚
马逊和微软的云计算业务增速，成为全球增速最快的云计算服务商。”
我们预计未来产品技术架构都会面临上云的问题，只是时间早晚问题。
安全性
基于数据安全的考虑，我们现阶段只会把计算和缓存节点上云，核
心数据还放在私有云；另外考虑到公有云的技术成熟度，需要支持
在多个云服务直接进行业务灵活迁移。
基于上述几点考虑，我们今年尝试了以私有云为主，公有云为辅的
混合云架构。核心业务的峰值压力，会在公有云上实现，业务部署
形态可参考下图：
高可用架构 42
下面介绍介绍技术实现。整体技术上采用的是Docker Machine +
Swarm + Consul的框架。系统分层如下图：
高可用架构 43
跨云的资源管理与调度
跨云的资源管理与调度（即上图中的pluto部分）的作用是隔离云
服务差异，对上游交付统一的Docker运行环境，支持快速弹性扩
缩容及跨云调度。功能上主要包括：
 系统初始化
 元数据管理
 镜像服务
 网络
 云服务选型
 命令行工具
 其他
系统界面如下图：
高可用架构 44
系统初始化
最初技术选型时认为Machine比较理想，仅需要SSH通道，不依
赖任何预装的Agent。我们也几乎与阿里云官方同时向Docker
Machine社区提交了Driver的PR，然后就掉进了大坑中不能自拔。
例举几个坑：
 无法扩展，Machine的golang函数几乎都是小写，即内部实现，
无法调用其API进行功能扩展。
 不 支持并发，并发创建只能通过启动多个Machine进程的方式，
数量多了无法承载。
 不支持自定义，Machine启动Docker Daemon是在代码中写
死的，要定义Daemon的参数就非常ugly。
目前我们采用的是Puppet的方案，采用去Master的结构。配置
在GitLab上管理，变更会通过CI推送到pluto系统，然后再推送
到各实例进行升级。在基础资源层面，我们目前正在进行大范围基
础环境从CentOS 6.5升级到CentOS 7的工作。做这个升级的主
要原因是由于上层基于调度系统依赖Docker新版本，而新版本在
CentOS 6.5上会引发cgroup的bug，导致Kernel Panic问题。
元数据的管理
调度算法需要根据每个实例的情况进行资源筛选，这部分信息目前
是通过Docker Daemon的Label实现的，这样做的好处是资源和
调度可以Docker Daemon解耦。例如我们会在Daemon上记录
高可用架构 45
这个实例的归属信息：
—label idc=$provider #记录云服务提供商
—label ip=$eth0 #记录ip信息
—label srv=$srv #记录所属业务
—label role=ci/test/production…
…
目前Docker Daemon最大的硬伤是任何元数据的改变都需要重启。
所以我们计划把元数据从Daemon迁移到我们的系统中，同时尝
试向社区反馈这个问题，比如动态修改Docker Daemon Label
的接口（PR被拒，官方虽然也看到了问题，但是比较纠结是否要
支持API方式），动态修改registry（PR被拒，安全因素），动态修
改Docker Container Expose Port（开发中）。
镜像服务
为了提升基础资源扩缩容的效率，我们正在构建虚机镜像服务。参
考Dockerfile的思路，通过描述文件定义定义虚机的配置，支持
继承关系，和简单的初始化指令。通过预先创建好的镜像进行扩缩
容，可以节省大约50%的初始化时间。
描述文件示意如下：
centos 7.0:
- dns: 8.8.8.8
- docker:
- version: 1.6
- net: host
高可用架构 46
meta:
- service: $SRV
puppet:
- git: git.intra.weibo.com/docker/puppet/tags/$VERSION
entrypoint:
- init.sh
不过虚机镜像也有一些坑，例如一些云服务会在启动后自行修改
一部分配置，例如router, dns, ntp, yum等配置。这就是上面
entrypoint的由来，部分配置工作需要在实例运行后进行。
网络
网络的互联互通对业务来说非常关键，通常来说有三种方案：公网，
VPC+VPN，VPC+专线。公网因为性能完全不可控，而且云服务
通常是按照出带宽收费，所以比较适合相互通信较少的业务场景。
VPC+VPN实际链路也是通过公网，区别是安全性更好，而且可以
按照私有云的IP段进行网络规划。专线性能最好，但是价钱也比较
好，且受运营商政策影响的风险较大。
网络上需要注意的是包转发能力，即每秒可以收发多少个数据包。
一些云服务实测只能达到10万的量级，而且与CPU核数、内存无
关。也就是说你花再多的钱，转发能力也上不去。猜测是云厂商出
于安全考虑在虚机层面做了硬性限制。我们在这上面也中过枪，比
如像Redis主从不同步的问题等等。建议对于QPS压力比较重的
实例进行拆分。
高可用架构 47
云服务选型
我们主要使用的是虚机和软负载两种云服务。因为微博对缓存服务
已经构建一套高可用架构，所以我们没有使用公有云的缓存服务，
而是在虚机中直接部署缓存容器。
虚机的选型我们重点关注CPU核数，内存，磁盘几个方面。CPU
调度能力，我们测试总结公有云是私有云的1.2倍，即假设业务在
私有云上需要6个核，在公有云上则需要8个。
内存写入速度和带宽都不是问题，我们测试发现甚至还好于私有云，
MEMCPY的带宽是私有云的1.2倍，MCBLOCK是1.7倍。所以
内存主要考虑的是价钱问题。
磁盘的性能也表现较好，顺序读写带宽公有云是私有云的1.4倍，
随机写是1.6倍。唯一要注意的是对于Redis这种业务，需要使用
I/O优化型的虚机。
以上数据仅供参考，毕竟各家情况不一样，我们使用的性能测试工
具：sysbench, mbw, fio，可自行测试。
CLI客户端（命令行工具）
为了伺候好工程师们，我们实现了简单的命令行客户端。主要功
能是支持创建Docker容器（公有云或私有云），支持类SSH登陆。
因为我们要求容器本身都不提供SSH（安全考虑），所以我们是用
Ruby通过模拟docker client的exec命令实现的，效果如下图：
高可用架构 48
其他方面
跨域的资源管理和调度还有很多技术环节需要处理，比如安全，基
础设施（DNS、YUM等），成本核算，权限认证，由于这部分通用
性不强，这里就不展开了。
高可用架构 49
容器的编排与服务发现
提到调度就离不开发现，Swarm是基于Consul来做节点发现
的。Consul采用raft协议来保证server之间的数据一致性，采用
gossip协议管理成员和传播消息，支持多数据中心。Consul集群
中的所有请求都会重定向到server，对于非leader的server会将
写请求转发给leader处理。
Consul对于读请求支持3种一致性模式：
 default：给leader一个time window，在这个时间内可能出现
两个leader（split-brain情况下），旧的leader仍然支持读的请
求，会出现不一致的情况。
 consistent：完全一致，在处理读请求之前必须经过大多数的
follower确认leader的合法性，因此会多一次round trip。
 stale：允许所有的server支持读请求，不管它是否是leader。
我们采用的是default模式。
除了Swarm是基于Consul来做发现，业务直接也是通过Consul