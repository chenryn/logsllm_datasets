title:Hypnoguard: Protecting Secrets across Sleep-wake Cycles
author:Lianying Zhao and
Mohammad Mannan
Hypnoguard: Protecting Secrets across Sleep-wake Cycles
Lianying Zhao and Mohammad Mannan
Concordia Institute for Information Systems Engineering
Concordia University, Montreal, Canada
{z_lianyi, mmannan}@ciise.concordia.ca
ABSTRACT
Attackers can get physical control of a computer in sleep
(S3/suspend-to-RAM), if it is lost, stolen, or the owner is
being coerced. High-value memory-resident secrets, includ-
ing disk encryption keys, and private signature/encryption
keys for PGP, may be extracted (e.g., via cold-boot or DMA
attacks), by physically accessing such a computer. Our goal
is to alleviate threats of extracting secrets from a computer
in sleep, without relying on an Internet-facing service.
We propose Hypnoguard to protect all memory-resident
OS/user data across S3 suspensions, by ﬁrst performing an
in-place full memory encryption before entering sleep, and
then restoring the plaintext content at wakeup-time through
an environment-bound, password-based authentication pro-
cess. The memory encryption key is eﬀectively “sealed” in a
Trusted Platform Module (TPM) chip with the measure-
ment of the execution environment supported by CPU’s
trusted execution mode (e.g., Intel TXT, AMD-V/SVM).
Password guessing within Hypnoguard may cause the mem-
ory content to be permanently inaccessible, while guessing
without Hypnoguard is equivalent to brute-forcing a high-
entropy key (due to TPM protection). We achieved full
memory encryption/decryption in less than a second on a
mainstream computer (Intel i7-4771 CPU with 8GB RAM,
taking advantage of multi-core processing and AES-NI), an
apparently acceptable delay for sleep-wake transitions. To
the best of our knowledge, Hypnoguard provides the ﬁrst
wakeup-time secure environment for authentication and key
unlocking, without requiring per-application changes.
1.
INTRODUCTION
Most computers, especially laptops,
remain in sleep
(S3/suspend-to-RAM), when not in active use (e.g., as in
a lid-close event); see e.g., [49]. A major concern for unat-
tended computers in sleep is the presence of user secrets in
system memory. An attacker with physical access to a com-
puter in sleep (e.g., when lost/stolen, or by coercion) can
launch side-channel memory attacks, e.g., DMA attacks [37,
53, 6, 57] by exploiting vulnerable device drivers; common
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’16, October 24-28, 2016, Vienna, Austria
c(cid:13) 2016 ACM. ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978372
mitigations include: bug ﬁxes, IOMMU (Intel VT-d/AMD
Vi), and disabling (FireWire) DMA when screen is locked
(e.g., Mac OS X 10.7.2 and later, Windows 8.1 [37]). A so-
phisticated attacker can also resort to cold-boot attacks by
exploiting DRAM memory remanence eﬀect [25, 22]. Sim-
pler techniques also exist for memory extraction (e.g., [16]);
some tools (e.g., [14]) may bypass OS lock screen and extract
in-memory full-disk encryption (FDE) keys.
Some proposals address memory-extraction attacks by
making the attacks diﬃcult to launch, or by reducing ap-
plicability of known attacks (e.g., [47, 45, 56, 23, 63, 24];
see Section 8). Limitations of these solutions include: be-
ing too application-speciﬁc (e.g., disk encryption), not being
scalable (i.e., can support only a few application-speciﬁc se-
crets), and other identiﬁed ﬂaws (cf. [5]). Most solutions also
do not consider re-authentication when the computer wakes
up from sleep.
If a regular re-authentication is mandated
(e.g., OS unlock), a user-chosen password may not provide
enough entropy against guessing attacks (oﬄine/online).
Protecting only cryptographic keys also appears to be fun-
damentally inadequate, as there exists more privacy/secu-
rity sensitive content in RAM than keys and passwords. Full
memory encryption can be used to keep all RAM content
encrypted, as used in proposals for encrypted execution (see
XOM [36], and a comprehensive survey [27]). However, most
such proposals require hardware architectural changes.
Microsoft BitLocker can be conﬁgured to provide cold
boot protection by relying on S4/suspend-to-disk instead of
S3. This introduces noticeable delays in the sleep-wake pro-
cess. More importantly, BitLocker is not designed to with-
stand coercion and can provide only limited defence against
password guessing attacks (discussed more in Section 8).
We propose Hypnoguard to protect all memory-resident
OS/user data across S3 suspensions, against memory ex-
traction attacks, and guessing/coercion of user passwords
during wakeup-time re-authentication. Memory extraction
is mitigated by performing an in-place full memory encryp-
tion before entering sleep, and then restoring the plaintext
content/secrets after the wakeup process. The memory en-
cryption key is encrypted by a Hypnoguard public key, the
private part of which is stored in a Trusted Platform Mod-
ule (TPM v1.2) chip, protected by both the user password
and the measurement of the execution environment sup-
ported by CPU’s trusted execution mode, e.g., Intel Trusted
Execution Technology (TXT [30]) and AMD Virtualization
(AMD-V/SVM [2]). The memory encryption key is thus
bound to the execution environment, and can be released
only by a proper re-authentication process.
Guessing via Hypnoguard may cause the memory content
to be permanently inaccessible due to the deletion of the
TPM-stored Hypnoguard private key, while guessing with-
out Hypnoguard, e.g., an attacker-chosen custom wakeup
procedure, is equivalent to brute-forcing a high-entropy key,
due to TPM protection. A user-deﬁned policy, e.g., three
failed attempts, or a special deletion password, determines
when the private key is deleted. As a result, either the pri-
vate key cannot be accessed due to an incorrect measurement
of an altered program, or the adversary takes a high risk to
guess within the unmodiﬁed environment.
By encrypting the entire memory space, except a few
system-reserved regions, where no OS/user data resides, we
avoid per-application changes. We leverage modern CPU’s
AES-NI extension and multi-core processing to quickly en-
crypt/decrypt commonly available memory sizes (up to
8GB, under a second), for avoiding degraded user experi-
ence during sleep-wake cycles. For larger memory systems
(e.g., 32/64GB), we also provide two variants, for encrypt-
ing memory pages of user selected applications, or speciﬁc
Hypnoguard-managed pages requested by applications.
Due to the peculiarity of the wakeup-time environment,
we face several challenges in implementing Hypnoguard. Un-
like boot-time (when peripherals are initialized by BIOS)
or run-time (when device drivers in the OS are active), at
wakeup-time, the system is left in an undetermined state,
e.g., empty PCI conﬁguration space and uninitialized I/O
controllers. We implement custom drivers and reuse dor-
mant (during S3) OS-saved device conﬁgurations to restore
the keyboard and VGA display to facilitate easy user in-
put/output (inadequately addressed in the past, cf. [46]).
Several boot-time solutions (e.g., [31, 64, 70]) also per-
form system integrity check, authenticate the user, and may
release FDE keys; however, they do not consider memory at-
tacks during sleep-wake cycles. For lost/stolen computers,
some remote tracking services may be used to trigger remote
deletion, assuming the computer can be reached online (with
doubtful eﬀectiveness, cf. [13, 62]).
Contributions:
1. We design and implement Hypnoguard, a new approach
that protects conﬁdentiality of all memory regions con-
taining OS/user data across sleep-wake cycles. We pro-
vide defense against memory attacks when the computer
is in the wrong hands, and severely restrict guessing of
weak authentication secrets (cf. [70]). Several propos-
als and tools exist to safeguard data-at-rest (e.g., disk
storage), data-in-transit (e.g., network traﬃc), and data-
in-use (e.g., live RAM content); with Hypnoguard, we ﬁll
the gap of securing data-in-sleep.
2. Our primary prototype implementation in Linux uses full
memory encryption to avoid per-application changes. The
core part of Hypnoguard is decoupled from the under-
lying OS and system BIOS, for better portability and
security. Leveraging modern CPU’s AES-NI extension
and multi-core processing, we achieve around 8.7GB/s
encryption/decryption speed for AES in the CTR mode
with an Intel i7-4771 processor, leading to under a second
additional delay in the sleep-wake process for 8GB RAM.
3. For larger memory systems (e.g., 32GB), where full mem-
ory encryption may add noticeable delay, we provide pro-
tection for application-selected memory pages via the
POSIX-compliant system call mmap() (requiring minor
changes in applications, but no kernel patches). Alter-
natively, Hypnoguard can also be customized to take a
list of applications and only encrypt memory pages per-
taining to them (no application changes).
4. We enable wakeup-time secure processing, previously un-
explored, which can be leveraged for other use-cases, e.g.,
OS/kernel integrity check.
2. TERMINOLOGIES, GOALS AND
THREAT MODEL
We explain the terminologies used for Hypnoguard, and
our goals, threat model and operational assumptions. We
use CPU’s trusted execution mode (e.g., Intel TXT, AMD-
V/SVM), and the trusted platform module (TPM) chip. We
provide brief description of some features as used in our
proposal and implementation; for details, see, e.g., Parno et
al. [48], Intel [30], and AMD [2].
2.1 Terminologies
Hypnoguard key pair (HGpub, HGpriv): A pair of public
and private keys generated during deployment. The pri-
vate key, HGpriv, is stored in a TPM NVRAM index, pro-
tected by both the measurement of the environment and the
Hypnoguard user password. HGpriv is retrieved through the
password evaluated by TPM with the genuine Hypnoguard
program running, and can be permanently deleted in ac-
cordance with a user-set policy. The public key, HGpub, is
stored unprotected in TPM NVRAM (for OS/ﬁle system
independence), and is loaded in RAM after each boot.
Memory encryption key (SK): A high entropy symmetric
key (e.g., 128-bit), randomly generated each time before en-
tering sleep, and used for full memory encryption. Before
the system enters sleep, SK is encrypted using HGpub and
the resulting ciphertext is stored in the small non-encrypted
region of memory.
Hypnoguard user password: A user-chosen password to un-
lock the protected key HGpriv at wakeup-time. It needs to
withstand only a few guesses, depending on the actual un-
locking policy. This password is unrelated to the OS unlock
password, which can be optionally suppressed.
TPM “sealing”: For protecting HGpriv in TPM, we use
the TPM_NV_DefineSpace command, which provides envi-
ronment binding (similar to TPM_Seal, but stores HGpriv
in an NVRAM index) and authdata (password) protec-
tion. We use the term “sealing” to refer to this mechanism
for simplicity.
2.2 Goals
We primarily consider attacks targeting extraction of se-
crets through physical access to a computer in S3 sleep
(unattended, stolen, or when the owner is under coercion).
We want to protect memory-resident secrets against side-
channel attacks (e.g., DMA/cold-boot attacks), but we do
not consider compromising a computer in S3 sleep for evil-
maid type attacks (unbeknownst to the user).
More speciﬁcally, our goals include: (G1) Any user or OS
data (secrets or otherwise), SK, and HGpriv must not remain
in plaintext anywhere in RAM before resuming the OS to
make memory attacks inapplicable. (G2) The protected con-
tent (in our implementation, the whole RAM) must not be
retrieved by brute-forcing SK or HGpriv, even if Hypnoguard
is not active, e.g., via oﬄine attacks. (G3) No guessing at-
tacks should be possible against the Hypnoguard user pass-
word, unless a genuine copy of Hypnoguard is loaded as the
only program in execution. (G4) The legitimate user should
be able to authenticate with routine eﬀort, e.g., memoriza-
tion of strong passwords is not required. (G5) Guessing the
user password when Hypnoguard is active should be severely
restricted by the penalty of having the secrets deleted.
An additional goal for coercion attacks during wakeup
(similar to the boot-time protection of [70]): (AG1) when
deletion is successful, there should be a cryptographic ev-
idence that convinces the adversary that the RAM secrets
are permanently inaccessible.
2.3 Threat model and assumptions
1. The adversary may be either an ordinary person with
skills to mount memory/guessing attacks, or an organi-
zation (non-state) with coercive powers, and considerable
but not unbounded computational resources. For exam-
ple, the adversary may successfully launch sophisticated
cold-boot attacks (e.g., [25, 22]), but cannot brute-force
a random 128-bit AES key, or defeat the TPM chip and
CPU’s trusted execution environment (for known imple-
mentation bugs and attacks, see e.g., [59, 68, 54]); see
also Item (f) in Section 7.
2. Before the adversary gains physical control, the computer
system (hardware and OS) has not been compromised.
After the adversary releases physical control, or a lost
computer is found, the system is assumed to be untrust-
worthy, i.e., no further use without complete reinitial-
ization. We thus only consider directly extracting se-