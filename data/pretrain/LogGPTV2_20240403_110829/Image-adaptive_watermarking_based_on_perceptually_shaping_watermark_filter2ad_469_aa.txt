title:Image-adaptive watermarking based on perceptually shaping watermark
blockwise
author:Xinshan Zhu and
Yong Gao and
Yan Zhu
Image-adaptive Watermarking Based on Perceptually
Shaping Watermark Blockwise
Xinshan Zhu
Institute of Computer Science
& Technology of Peking
University
No. 298 of Chengfu Road
Beijing, P. R. China
Yong Gao
Institute of Automation,
Chinese Academy of Sciences
No. 95 East of Zhongguan
Road
Beijing, P. R. China
Yan Zhu
Institute of Computer Science
& Technology of Peking
University
No. 298 of Chengfu Road
Beijing, P. R. China
PI:EMAIL
PI:EMAIL
PI:EMAIL
ABSTRACT
In a general additive watermarking model, a watermark sig-
nal is perceptually shaped and scaled with a global gain
factor before embedding. This paper presents a new image-
adaptive watermarking scheme based on perceptually shap-
ing watermark blockwise.
Instead of the global gain fac-
tor, a localized one is used for each block. And Watson’s
DCT-based visual model is adopted to measure the distor-
tion of each block introduced by watermark, rather than the
whole image. With the given distortion constraint, the max-
imum output value of linear correlation detector is derived
in one block, which demonstrates the reachable maximum
robustness in a sense. Meanwhile, an extended perceptu-
ally shaped watermarking (EX-PSW) is acquired through
making detection value approach that upper limit.
It is
proved mathematically that EX-PSW outputs higher detec-
tion value than perceptually shaped watermarking (PSW)
with the same distortion constraint. We also discuss the
adjustment strategies of parameters in EX-PSW, which are
helpful for improving the local image quality. Experimental
results show our scheme provides very good results both in
terms of image transparency and robustness.
Categories and Subject Descriptors
H.1 [Information Systems]: Models and Principles; K.6.5
[Management of Computing and Information Sys-
tems]: Security and Protection
General Terms
Algorithms, Theory
Keywords
Adaptive watermarking, human visual model, transparency,
robustness, blockwise watermarking
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS’06, March 21-24, 2006, Taipei, Taiwan.
Copyright 2006 ACM 1-59593-272-0/06/0003 ...$5.00.
INTRODUCTION
1.
Image watermarking [3], is ﬁnding more and more support
as a possible solution for the protection of intellectual prop-
erty rights. To this aim, the most important features a
watermarking technique should exhibit are unobtrusiveness
and robustness. However, the two basic requirements con-
ﬂict with each other.
Image-adaptive watermarking seeks
the tradeoﬀ between them utilizing human visual models
(HVM) to control and mask the distortion resulted from
watermark embedding.
HVM is constructed to describe the characteristics of hu-
man visual system (HVS), with consideration of frequency
sensitivity, luminance masking and contrast masking eﬀects,
etc. to human eyes [4]. Usually, an important parameter,
just noticeable diﬀerence (JND) is derived to estimate the
smallest discernible amount of change at each pixel or coef-
ﬁcient in transform domain. There have been existing many
ones founded in frequency domain [6, 16] and wavelet do-
main [8, 15]. Therefore, many image-adaptive watermark-
ing algorithms are proposed in those domains [1, 5, 7, 13,
17]. Perceptually shaped watermarking(PSW) [11] is a typ-
ical and basic scheme applying HVM for watermarking. A
watermark signal is shaped through weighting its each com-
ponent with JND. A global gain factor is used to adjust
adaptively the watermark strength under the given distor-
tion constraint. The idea is also applied in many other al-
gorithms [1, 5, 7, 13]. In fact, due to the global gain factor,
to adjust localized image quality is not ﬂexible. Generally,
to guarantee localized ﬂat image transparency, the factor
has to be set to a small value, which decreases the robust-
ness of watermark [18]. In [4], the optimal use of perceptual
models was presented. Two alternative optimal behaviors
for the embedder are speciﬁed as follows: 1) maximizing
the robustness of an embedded mark, while maintaining a
constant perceptual distance. 2) minimizing perceptual dis-
tance while maintaining a constant robustness. The opti-
mality also disregards the considerations of the local image
characteristics. In addition, JND is used to derive percep-
tually based quantizer and to determine perceptually based
bit allocation in some algorithms [2, 12]. In most proposed
algorithms, it is observed that a global gain factor is used,
which is not helpful to adjust local watermark energy.
In this paper, we propose a new image-adaptive watermark-

ing technology. This paper is organized as follows. Section
2 describes a general additive watermarking model. Based
on the model, blockwise watermarking model is proposed in
section 3. Unlike the block-based watermarking, it uses mul-
tiple local factor to control localized watermark strength. In
Section 4, we propose the extended PSW (EX-PSW) with
Watson’s model as distortion measurement. Section 5 math-
ematically compares the performance of EX-PSW and PSW.
Section 6 presents some adjustment strategies of parameters
in EX-PSW. A serial of tests are done to evaluate our al-
gorithm in Section 7. The paper is concluded in Section
8.
2. A GENERAL ADDITIVE WATERMARK-
ING MODEL
In this section, we brieﬂy describe an additive spread spec-
trum watermarking model [4] and introduce the notations
of the signals used in the text. Each signal is represented as
a matrix of size M × N .
Let Xo denote the cover data extracted from the host image.
The watermark signal, wm represents a speciﬁc message to
be embedded. Generally, each component of wm is gener-
ated independently by standard Normal distribution gener-
ator, which is initialized with a seed that depends on the
cryptographic key K. Therefore
wm(i, j) ∼ i.i.d N (0, 1)
(1)
In order to embed into the image the maximum, but still
unperceptible, the watermark signal wm need be ﬁrst per-
ceptually shaped as ws, i. e.,
ws = fs(wm)
(2)
where fs(·) denotes the shaping function. Then the covered
data, Xw is represented using the additive modulation as
Xw(i, j) = Xo(i, j) + αws(i, j)
(3)
where α is the global gain factor to control watermark strength.
The detection is performed by computing the linear corre-
lation between Xw and wm as
ρ =
1
M N i,j
Xw(i, j)wm(i, j)
(4)
and comparing it with a threshold to determine if the wa-
termark exists or not. The threshold depends on the chose
false positive probability [9].
3. BLOCKWISE WATERMARKING
In the previous watermarking model, the uniform gain fac-
tor is used during embedding. That is not ﬂexible to adjust
localized watermark strength. Hence, we consider that the
cover data should be divided into nonoverlapping blocks and
a localized gain factor is used for each block. We call such
a scheme as blockwise watermarking, which is described de-
tailedly as follows.
First, the cover data are divided into nonoverlapping blocks
of size L × L
where Bk, 0 ≤ k ≤ p, is a macroblock of size L × L.
If
p is not a whole number, extra pixels are truncated, i.e.,
M/L × N/L. The same operation is also performed on
the watermark signal. Let αk, 0 ≤ k ≤ p denote the gain
factor corresponding to block Bk. According to the idea
of blockwise watermarking, the resulting covered data are
obtained as
Xw(i, j) = Xo(i, j) +k
IBk (i, j)αkws(i, j)
(6)
where IBk (i, j) represents indicator function, that is
IBk (i, j) = 1,
0,
(i, j) ∈ Bk
else
Unlike traditional block-based watermarking [11], blockwise
watermarking can control localized watermark strength us-
ing αk.
Substituting Equation (6) into Equation (4), we obtain the
expression of detection value as
ρ =
1
M N k (i,j)∈Bk
(αkws(i, j)wm(i, j) + L2ρok)
(7)
where ρok represents the linear correlation between the cover
data and watermark signal in block Bk, that is
ρok =
1
L2 (i,j)∈Bk
Xo(i, j)wm(i, j)
(8)
According to our tests, the blockwise watermarking pos-
sesses several advantages over ones facing the media in global
sense: 1) the localized image characteristics are exploited
suﬃciently for embedding through adjusting localized gain
factors [10]; 2) localized watermark invisibility can be fur-
ther improved too; 3) loss of information in one block doesn’t
aﬀect to detect watermark in other blocks. But the left
problems are how to design the shaping function fs(.) and
adjustment strategy of αk.
4. PERCEPTUALLY SHAPING WATERMARK
BLOCKWISE
The design of the shaping function fs(·) depends on the
choice of distortion measurement. Here, Watson’s DCT-
based visual model [16] is adopted as an example to show
how to design fs(·).
In Watson’s model, the perceptual distance (PD) between
two images of size M × N is deﬁned as
Dq
p(I, I) =
1
M N
(i,j
q
|d(i, j)|
s(i, j)
1
q
)
(9)
where d(i, j) represents the diﬀerence in DCT coeﬃcient be-
tween two images and s(i, j) is just noticeable diﬀerence
(JND) at location (i, j). Watson recommends a value of
q = 4 for image. However, Voloshynovskiy [14] suggests
that with respect to watermarking better results are ob-
tained with q = 1. We follow this suggestion. Please refer
to [4, 14, 16] for more details of Watson’s model.
Xo = B1B2 . . .Bp
(5)
Assume Xo(i, j) denote the DCT coeﬃcient at location (i, j).

For block Bk, if the perceptual distance is set to T , i. e.
αk
L2 (i,j)∈Bk
|ws(i, j)|
s(i, j)
= T
(10)
we can derive the upper limit of detection value represented
by
ρk ≤ T max
(i,j)∈Bk |wm(i, j) · s(i, j)| + ρko
(11)
See the Appendix for a proof. Inequality (11) actually shows
the reachable maximum robustness in a sense. Obviously,
the shaping function fs(·) should be designed to make de-
tection value approach its upper limit. From the proof of
Inequality (11) , we also obtain a general form of ws ex-
tended from Equation (35) in the Appendix as
ws(i, j) = sgn(wm(i, j))s(i, j)r+l|wm(i, j)|l
(12)
Since perceptually shaped watermarking (PSW) is a special
example of such scheme deﬁned in Equation (11) with l = 1
and r = 0 [11], it is named as the extended perceptually
shaped watermarking (EX-PSW).
5. PERFORMANCE EVALUATION
In the section, we attempt to evaluate the performance of
the proposed EX-PSW mathematically. For this purpose, a
watermark is embedded into block Bk by EX-PSW and PSW
respectively. The resulting covered data are represented as
XEX−P SW (i, j) = Xo(i, j)+
αksgn(wm(i, j))|wm(i, j)|ls(i, j)l+r
(i, j) ∈ Bk
(13)
and
XP SW (i, j) = Xo(i, j) + βkwm(i, j)s(i, j)
(i, j) ∈ Bk (14)
So the outputs of the linear correlation detector in Bk are
calculated as
wm(i, j)l+1s(i, j)l+r + ρko
(15)
ρEX−P SWk =
and
αk
L2 (i,j)∈Bk
L2 (i,j)∈Bk
βk
ρP SWk =
w2
m(i, j)s(i, j) + ρko
(16)
We compare the detection value of EX-PSW and one of
PSW. To guarantee the fair comparison, a uniform percep-
tual distance is set for them. The distortion constraint can
be represented as
|wm(i, j)ls(i, j)l+r|
L2s(i, j)
αk (i,j)∈Bk
βk = αk (i,j)∈Bk
= βk (i,j)∈Bk
|wm(i, j)l|s(i, j)l+r/ (i,j)∈Bk
Equation (17) simpliﬁes to
|wm(i, j)s(i, j, k)|
L2s(i, j)
(17)
|wm(i, j)|
(18)
Suppose ∆ = ρEX−P SWk − ρP SWk and l = 1. Then com-
bining Equation (18), Equation (15) and Equation (16), we
obtain
(i,j)∈Bk |wm(i, j)| · ∆ = αk
|wm(u, v)|s(i, j)[sr(i, j) − sr(u, v)]
L2 (i,j)∈Bk (u,v)∈Bk
w2
m(i, j)·
(19)

Since {wm(i, j)} are i.i.d random variables, performing the
expectation operation on both sides of Equation (19) yields
E∆ =
1
L2 (i,j)∈Bk (u,v)∈Bk
s(i, j)[sr(i, j) − sr(u, v)]
(20)
While r > 0, it is easily derived that E∆ ≥ 0, that is
EρEX−P SWk ≥ EρP SWk
(21)
Inequality (21) shows that EX-PSW manifests better per-
formance than PSW under l = 1 and r > 0 situations.
6. ADJUSTMENT STRATEGIES OF PARAM-
ETERS
The section presents some eﬀective adjustment strategies of
parameters in EX-PSW to seek the best tradeoﬀ between
image transparency and robustness.
In most previous works on watermarking, distortion mea-
surement is performed in a whole image. However, the lo-
calized image quality is disregarded. Let P Dk denote the
perceptual distance between the host image and the water-
marked version in block Bk. We have the following Propo-
sition.
Proposition 6.1 (Property of perceptual distance):
min
k
P Dk ≤ P Dg ≤ max
k
P Dk
where P Dg represents the global perceptual distance be-
tween two images. Proposition 4.1 is easily proved. Accord-
ing to the proposition, although the distortion introduced
by watermarking is considered to be acceptable in a global
sense, watermark may be visible in some localized blocks.
Additionally, Voloshynovskiy [14] also presented some exper-
imental results to demonstrate such a conclusion. Therefore,
we suggest that measuring distortion should be in a block
of suitable size, but not in the whole image. As for the size
of block, Voloshynovskiy gave two referenced ones, 16 × 16
and 32 × 32 and their corresponding maximum acceptable
perceptual distance values in [14]. We consider 32 × 32 is a
little bigger and 16 × 16 is smaller, so the suitable choice of
block size should be 24 × 24.
Assume the acceptable localized perceptual distance is set
to T. To substitute Equation (12) into Equation (10) yields
αk = L2T /( (i,j)∈Bk
s(i, j)r+l−1|wm(i, j)|l)
(22)
Equation (22) presents the rule to adjust the localized gain
factor adaptively.
In previous section, we have proved that under l = 1 and
r > 0 situations, the performance of EX-PSW is better than
PSW. Although increasing r and l can enhance the detec-
tion value, watermark energy will be concentrated at some
isolated points, which will give rise to visible watermark.
Hence, their values are not able to set to be too large. Gen-
erally, we take l = 1 and 0 ≤ r ≤ 1.
7. EXPERIMENTAL RESULTS
The presented watermarking has been extensively tested on
various standard images and attempting diﬀerent kinds of
l
e
u
a
V
n
o
i
t
c
e
t
e
D
5
4.5
4
3.5
3
2.5
2
(a)
(b1)
(b2)
(b3)
PSW
EX−PSW r=0.1
EX−PSW r=0.4
EX−PSW r=0.7
EX−PSW r=1
2
4
6
8
10
12
14