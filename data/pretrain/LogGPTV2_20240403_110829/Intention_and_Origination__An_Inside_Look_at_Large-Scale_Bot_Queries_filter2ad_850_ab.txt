clusters for analysis. Speciﬁcally, we implement a paral-
lel version of the single-linkage hierarchical clustering al-
gorithm [24] that enables us to perform host clustering in
a fully distributed fashion. SBotScope then classiﬁes host
clusters based on their temporal and spatial behaviors. This
approach allows us to perform in-depth analysis of queries
submitted from botnets and data centers separately.
To summarize, Figure 1 shows the architecture overview
of the analysis performed by SBotScope. We describe the
details next.
3.3 Pattern Generation
We would like query patterns to capture only the invari-
ant portions of queries and remove irrelevant stufﬁng words.
In doing so, it is important to avoid extracting popular com-
binations of stopwords (e.g., “of”, “the”) as well as com-
mon, popular queries such as “facebook.com”.
To capture the above intuition, we deﬁne a query pattern
as a speciﬁc word-combination (or query) that occurs fre-
quently among bot queries. By “speciﬁc”, we require the
pattern to contain useful information, so that to avoid se-
lecting over-general patterns, such as those of stopwords.
f
o
n
o
i
t
c
a
r
f
e
v
i
t
l
a
u
m
u
c
e
h
T
s
n
o
i
t
i
a
n
b
m
o
c
d
r
o
w
1
0.8
0.6
0.4
0.2
0
0
1−Word Comb
2−Word Comb
3−Word Comb
4−Word Comb
5
10
Entropy
15
20
25
Figure 2. The distribution of entropy for fre-
quent word-combinations with certain length
By frequent, we require a pattern to be the common, in-
variant portion of a large number of queries. Finally, we
consider word-combinations instead of query sub-strings or
regular expressions to prevent attackers from manipulating
word orders or query formats to defeat our analysis.
3.3.1 Selecting Frequent Patterns
The “frequent” notion can be naturally quantiﬁed using
the pattern frequency. Without loss of generality, we con-
sider both frequent word combinations and frequent exact
queries. Since we ﬁnd that majority (95%) of the bot queries
contain at most four words, we consider all possible word
combinations up to length 4 for each query. Then for every
length (i.e., 1, 2, 3, and 4), we select the top 0.1% com-
binations that occurred across the most number of unique
queries. After this process, there are still some frequent ex-
act queries that are not covered by popular word combina-
tions. For such cases, we also select frequent exact queries
(i.e., top 0.1%) as potential patterns.
3.3.2 Selecting Speciﬁc Patterns
Once we identify frequent patterns, we proceed to select
speciﬁc ones using the following two metrics:
• Information gain G(wi) quantiﬁes the amount of in-
formation contained in a pattern wi:
G(wi) = E(Q) − E(Q|W = wi)
where E(Q) is the entropy for all bot queries, and
E(Q|W = wi) is the conditional entropy of bot
queries matching pattern wi. Since E(Q) is a con-
stant for the same set of queries Q, G(wi) can simply
be evaluated by E(Q|W = wi). The smaller the con-
ditional entropy, the larger the information gain is, and
hence the corresponding pattern is more speciﬁc. In
the exact query case, the pattern is the entire query it-
self, so the information gain is the maximum value of
E(Q).
• Historic
among
normal
popularity
queries
cnormal(wi):
it refers to the number of unique
IP addresses that submitted normal queries matching
pattern wi. The intuition is that a very speciﬁc bot
query is less likely to be a popular query among
a large number of normal users. A higher value
of cnormal(wi), means the pattern is not distin-
guishing; we ﬁnd that many of them are used for
obfuscating sessions or testing connectivity (e.g.,
“facebook.com”).
Figure 2 presents the conditional entropy E(Q|W = wi)
distribution for frequent patterns of different lengths (we ex-
clude exact query patterns). As shown in the ﬁgure, patterns
with more words tend to have smaller conditional entropy,
since they are naturally more speciﬁc (i.e., containing more
words). Based on these two metrics, SBotScope selects spe-
ciﬁc patterns if wi satisﬁes either of the following condi-
tions:
• E(Q|W = wi) falls in the bottom 90% of entropy for
all popular word combinations with the same length.
• cnormal(wi) is smaller than a certain threshold 1, 000.
We use these two conditions to eliminate over general
patterns or patterns that are popular among normal user
queries.
Note that given a set of patterns, a query may match mul-
tiple of them and contribute to all their frequencies. For
each query, to avoid generating multiple redundant patterns,
we select only the most speciﬁc pattern to represent it (i.e.,
we favor the pattern that has the smallest conditional en-
tropy). After the above pattern generation process, we can
dramatically reduce the data complexity by several orders
of magnitude, from 109 queries to 105 patterns.
3.4 Topic Analysis
The topic analysis step is where we further analyze
query patterns to identify semantically meaningful topics.
Patterns represent the prominent syntactic features of raw
queries, but different patterns may still correspond to the
same or similar intentions. For example, “auto” and “car”
are very different words, but they all correspond to similar
topics and our goal is to uncover the hidden semantic corre-
lations among them.
One potential approach to recognize semantically similar
patterns is to use dictionaries. However, as bot queries are
written in various languages, it is challenging to parse each
"powered"
Data
D1
D2
# of IP-Segments
14,856,347
14,350,435
"powered, smf"
"vbulletin,  powered"
Table 4. The number of “hosts” in two differ-
ent data sets.
"powered, smf,
"powered, smf,
version"
proﬁle"
"vbulletin, 
powered,
version"
"vbulletin, 
powered,
music"
"vbulletin, 
powered,
forum"
Figure 3. An example pattern tree
query and understand it semantically. In our work, we adopt
a simple yet effective process that includes two steps. The
ﬁrst step aggregates patterns hierarchically to construct a
set of pattern trees. The goal is to further reduce the pattern
complexity syntactically. The second step performs clus-
tering on the pattern trees to identify semantically coherent
topics.
3.4.1 Pattern Tree Generation
This step aggregates patterns based on shared common
words. We take a bottom-up approach and treat each in-
put pattern as an individual node. The tree construction
starts with merging the longest patterns with length K if
they share K − 1 common words. The merged pattern is
represented as a new parent node of the corresponding leaf
pattern nodes. This process repeats until all the top-level
tree nodes represent 1-word patterns and thus cannot be fur-
ther aggregated. Figure 3 shows an example pattern tree
constructed using this process. All the patterns on this tree
share the common word “powered”, and they may all be is-
sued to discover certain vulnerabilities. In particular, lower
level siblings are more strongly correlated, as they share
more common words than nodes in higher levels. In our
experience, this step can further reduce hundreds of thou-
sands of patterns to roughly two or three thousand pattern
trees.
3.4.2 Topic Clustering
This step groups pattern trees to identify their semantic cor-
relations. We use the probability of word co-occurrence to
model such correlations. For example, the word “auto” and
“car” may both co-occur with keywords such as “Toyota”
or “dealership”, which can link the two concepts together
into one group.
Speciﬁcally, we focus on only the top-level nodes. Given
two top-level pattern tree nodes with word w1 and w2, we
use a similarity score s(w1, w2) to measure their correla-
tion. We ﬁrst identify the two sets of queries Q1 and Q2
that contain word w1 and w2, respectively. We then com-
pute the similarity score in terms of the Jaccard distance
between Q1 and Q2:
s(w1, w2) =
|Q1 ∩ Q2|
|Q1 ∪ Q2|
With the similarity scores, we essentially obtain a graph
of pattern trees, with each tree becoming a super node in the
graph. The similarity scores serve as edge weights. Given
the graph is reasonably small (with a few thousands of
nodes), we perform spectral clustering [12], the best graph-
cut algorithm, to identify tightly connected subgraphs. Each
subgraph intuitively corresponds to a query topic.
The number of topics can be a pre-conﬁgured parameter
to control the granularity of topics (i.e., coarse-grained cat-
egorizations vs. detailed classiﬁcation). In our current sys-
tem, we pick the number of topics to be 50, which allows
security analysts or search engine operators to manually in-
spect the results.
3.5 Host Analysis
The host analysis step answers the question of “who sub-
mitted bot queries?”. We are interested in identifying and
separating data center hosts from botnet hosts, which we
ﬁnd are the two dominant cases. The infrastructures of
these two categories of hosts are drastically different, so
their query behaviors and contents may also differ radically.
Such a study could yield in-depth understanding to attacker
strategies and attack scales. In our analysis, we group hosts
with similar query behaviors via clustering.
3.5.1 Host Representation
With DHCP, a host’s IP address may dynamically change.
To mitigate this problem, we use an IP-segment to repre-
sent a host that has been active during a period. We ﬁnd
operating on the coarse-grained time period on the order of
days generates stable results. For example, if we observe an
IP address that submitted bot queries on day1, day2, day3,
and day5, then we use two IP-segments to represent the two
“hosts” that issued these queries: IP-segment1 ={IP: day1,
day2, day3} and IP-segment2 = {IP: day5}. We apply this
method to the two data sets to obtain hosts. The number
of hosts are similar across two data sets as presented in Ta-
ble 4. Furthermore, the number of such deﬁned “hosts” is
"powered"
"vbulletin, 
   powered"
host: H1
"powered"
20
1
"vbulletin, 
   powered"
19
1
1
1 1
...
1
host: H2
"powered"
20
"vbulletin, 
   powered"
20
"vbulletin, 
powered,
version"
"vbulletin, 
powered,
music"
"vbulletin, 
powered,
forum"
10 10
0
0
"vbulletin, 
powered,
version"
"vbulletin, 
powered,
music"
Figure 4. An example of generating feature
vectors
close to the number of unique IP addresses in Table 2, which
implies that the vast majority of the IP addresses are either
active on one day or active on consecutive days.
3.5.2 Feature Vector Generation
With the deﬁnition of “hosts”, we construct a feature vector
to represent each host. One straightforward solution is to
deﬁne the feature vectors in the original query space, where
each unique raw query is one dimension. Given that the
sheer volume of unique bot queries is huge, this option will
be prohibitively expensive in practice.
Instead, we leverage the derived pattern trees, which is
much more compact than raw queries. For each host H rep-
resented by an IP-segment, we match all of its bot queries
against the patterns on the trees starting from the root nodes,
using the following steps:
1. SBotScope ﬁrst produces a set of subtrees T (H) where
all the patterns on the subtrees match the queries from
host H.
2. For each node n on T (H), SBotScope additionally
records the number of queries from H matching n as
c(n).
3. SBotScope then prunes T (H). For an edge a → b on
T (H), if c(a) >> c(b) (we consider c(a) >> c(b) if
log10(c(a)) >= log10(c(b)) + 1), then a is a represen-
tative pattern for H while b is not. So we remove the
subtree rooted at b.
Finally, we pick the set of leaf nodes on the pruned sub-
trees to serve as features for describing H. The total num-
ber of dimensions in the feature vector space is the num-
ber of unique pattern nodes selected across all hosts. Fig-
ure 4 presents an example. In this example, H1 generates
20 queries and has matching count c(“powered”) = 20 and
c(“vbulletin, powered”) = 19. The remaining nodes match
only one query from H1. Therefore, we pick “vbulletin,
powered” as a feature to describe H1. For another host H2,
we pick “vbulletin, powered, version” and “vbulletin, pow-
ered, music” as two features to represent H2.
This step is critical as it signiﬁcantly reduces the feature
vector dimensions from billions of raw queries to only tens
of thousands of features (e.g., 27,507 for D1 and 37,843
for D2). More importantly, the feature vectors describe not
only the distinguishing local query contents of each host,
but also the global correlations among different query pat-
terns.
3.5.3 Host Clustering
With a feature vector to represent a host, we can group hosts
into clusters and classify their types based on the aggregated
behaviors of each group. This approach has two advantages
than directly analyzing individual hosts. First, it allows us
to identify correlated or coordinated query behaviors that
cannot be observed in isolation. Second, it is robust to in-
dividual host outliers as we rely on group behaviors rather
than host behaviors to perform classiﬁcation. Thus, we are
able to differentiate hosts even though some of their activi-
ties are atypical and are difﬁcult to classify otherwise.
To perform host clustering, we apply the single-linkage
hierarchical clustering algorithm [24] using the Jaccard dis-
tance of feature vectors:
dist(H1, H2) = 1 −
|F1 ∩ F2|
|F1 ∪ F2|
where F1 and F2 represent the set of features for H1
and H2 respectively. If the Jaccard distance of two hosts
is smaller than a pre-deﬁned threshold (e.g., 0.3), we ag-
gregate two hosts into one cluster. We choose the single-
linkage hierarchical clustering algorithm instead of the pop-
ular K-Means algorithm [10] because it does not need to
predetermine the number of clusters beforehand. In addi-
tion, it enables parallel implementation in a fully distributed
fashion on a computer cluster. In the current implementa-
tion, we keep a cluster if it includes at least 10 hosts.
3.5.4 Cluster Classiﬁcation
To answer the question of what types of hosts are from these
clusters, we classify the group behaviors. Two distinguish-
ing categories of hosts are botnets and data center hosts. A
botnet is a collection of compromised machines performing
malicious activities.