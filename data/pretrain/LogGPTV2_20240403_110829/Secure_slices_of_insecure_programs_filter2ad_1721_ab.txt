to output statements, the program is secure.
2.5 Program Slicing
Information ﬂow and program dependence analysis are
both closely related to program slicing [35]. A program slice
consists of those parts of a program that may aﬀect the
values computed at some program point of interest. Re-
searchers found program slices useful for program testing,
program understanding, program integration, reuse, pro-
gram maintenance and reverse engineering, among others
[36, 13, 33].
In a general sense, slicing is a program transformation
which preserves some aspects of the semantics of the original
program. Usually, the program transformation is sentence
deletion.
For eﬃciency and simplicity reasons, slices are usually
computed with the help of dependence graphs [33]. The set
of statements/expressions on which statement y —the slice
criterion— depends is called the backward slice of y [35]:
BS(y) = {x|x (cid:179) y}
Therefore, given a program P and a set S of secret vari-
ables, we can say:
(cid:161)∀o ∈ P, h ∈ S : h (cid:54)∈ BS(o)
(cid:162)
=⇒ P is non-interfering
That is, if the backward slices of output statements o in
program P are free of initialization nodes h of secret vari-
ables, then P is non-interfering.
3. SECURE SLICES
If one or more invalid ﬂows are detected in a program,
static IFC rejects it as insecure. Although correct, this ap-
proach does not diﬀerentiate between secure and insecure
executions of the program. For example, the following pro-
gram:
( l1  0 and h = 0 the program will output
only one value but if l1 > 0 and h (cid:54)= 0, the execution will
result in two outputted values. The fact that an output
statement is executed or not can leak secure information
of a running program, regardless the security level of the
published value; therefore some of such statements must
be necessarily deleted to avoid invalid ﬂows. The case of
statement 4 is diﬀerent: it is insecure because prints out a
high-labeled value. We can leave an output statement at
program position 4 and prevent the invalid ﬂow by replacing
the outputted value. These diﬀerences are due to the nature
of the information ﬂows arriving to the output statements.
We distinguish two kinds of information ﬂows: direct and
indirect. The assignment y := x, produces a direct ﬂow
from x to y. In if (x) then y:=1 else skip, an indirect
ﬂow from x to y is induced by the dependence of the ﬁnal
value of y on the evaluation of x.
Direct ﬂows are originated by data dependences: if x d→ y
then there is a direct ﬂow from x to y. Indirect ﬂows are
induced by control dependences: if x c→ y then there is an
gram:
( l2=0) then
l1 := h
1 l1 := 0 ;
2 i f
3
4 e l s e skip endif ;
5 output ((cid:163) ) ;
always prints out ’(cid:163)’, regardless if the assignment statement
3 was executed or not.
3.2 Example: Double-blind Peer-Review
In a double-blind peer-review process, submitting authors
are not informed of who reviews their papers and the identity
of the authors is not accessible for the reviewers. However,
the editor/chair knows who the authors and reviewers are.
Figure 4(a) shows a program that prints out information
related with submitted papers to a workshop. The available
information is: the workshop name (wshp variable), the sub-
mission date (papDate), the paper number (papN um), title
(papT tl), authors names (authors), referee names (ref eree)
and reviewers comments (ref Comments).
Variable state indicates if the paper is under reviewing
process (state 0), accepted (1), or rejected (-1). If the paper
is in accepted or rejected state, the referees comments are
printed out. This is controlled through pc variable.
The scenario of the example can be modeled with an in-
formation ﬂow policy deﬁned over a partial order of security
levels public (P ), authors & referees (AR), authors (A), ref-
erees (R), and editor (E); where P → AR, AR → A, AR → R,
A → E, and R → E. The policy labels wshp, papT tl,
papN um, and papDate as P ; state, pc, and ref Comments
as AR level; authors as A; and ref eree as R.
By transforming the program, we can automatically ex-
tract secure versions for diﬀerent users of the system: au-
thors, referees, and public (Figures 4(b), (c) and (d) respec-
tively). The program version for authors does not print out
the ref eree variable, the sole variable labeled with a secu-
rity level not equal nor lower than A. Referee’s version does
not print the authors variable. The version for general pub-
lic only prints wshp, papDate, papN um, and papT tl while
all other paper-related data is kept unpublished.
3.3 Correctness
Soundness of secure slices is consequence of the safe ap-
proximation of program dependences used to build the de-
pendence graph.
In our case, soundness means that the
obtained secure slices are correct, that is, they are free of
invalid ﬂows.
As we mentioned before, the computation of exact actual
dependences is undecidable thus they are safely approximate
by dependence analyses, and dependence graphs are conser-
vative models of actual dependences among program state-
ments; this means that dependence graphs may contain too
many edges but never too few.
Because invalid ﬂows are detected using safe dependence
information, it may occur that more than actual invalid ﬂows
are detected (false positives) but it will never happen that
an actual invalid ﬂow remains undetected. Consequently,
more than necessary output statements may be modiﬁed
(incompleteness) but it will never occur that an insecure
output remains unchanged (soundness).
In [2] we provide a proof of the soundness of secure slicing
in the context of a sequential fragment of the Java Virtual
Machine. The proof is based on the soundness of the type
system for non-interference enforcement described in [3].
3.4 Secure Slicing in Presence of Intentional
Declassiﬁcation of Information
Many realistic systems need to declassify some kind of
conﬁdential information as part of their regular behaviour —
password checking routines are the typical example of such
programs—. By deﬁnition, non-interference rejects these
programs thus it results too strong to be used in practice.
This has originated a lot of research —partially surveyed at
[28]— with the goal of provide a deﬁnition of secure program
in presence of intentional declassiﬁcation.