dropouts, we define the following event and will show in Lemma 4.7
that the event holds with overwhelming probability for the graph
generated in Part II.
Definition 4.5 (Enough shares are available). Let D ⊂ [n]. We
define the event E6 as
E6(D, G, t) = 1 iff ∀i ∈ [n] : |N•→(i) ∩ ([n] \ D)| ≥ t .
(In)consistent shares. Note that malicious clients may deliver
inconsistent shares to their neighbors, e.g., in a way that results in
different secrets being reconstructed if different sets of shares are
used for reconstruction. This means that we allow malicious parties
to tailor their inputs to which of their neighbors survive until the
end of the protocol. This is a consequence of the fact that we do
not model the fact that a client dropped out as private information.
One could limit that above ability with a simple modification in
the protocol: when sharing (encrypted) secret shares, the clients
also send hashes of their secrets (in the clear) to the server (note that
the secrets have high entropy, hence this does not leak information
to the server). At the end of the protocol, when reconstructing
either the self-mask seed bi or the pairwise masks keys sk
, the
server checks that the reconstructed secret matches the earlier
hashes, and otherwise aborts. This accomplishes that dishonest
clients cannot change their input based on which of their neighbors
dropout after they send their masked input. This, however, does not
prevent clients from changing their input based on which clients
dropout before that happens. In particular, a client i chosen as a
neighbor by a malicious client j could dropout immediately after
1
i
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA1261the protocol begins, and nothing prevents j from changing their
input in that event.
The above observation is also relevant to Bonawitz et al. [8], and
the protocol extension would also apply there.
4.3 Generating “Nice” Graphs
As explained above, we would like to show that Part II of Algo-
rithm 3 generates “nice” graphs, i.e., that the events E4, E5, and
E6 happen with overwhelming probability on graphs generated
according to Part II of Algorithm 3. Below, we define formally what
a nice graph generation algorithm is, and state in Lemma 4.7 that
Part II of Algorithm 3 satisfies the definition. A detailed proof of
Lemma 4.7 can be found in Appendix C of our full paper [5].
Definition 4.6. Let k, σ , η be integers and let α, δ ∈ [0, 1]. Let
C ⊆ [n]. Let D be a distribution over pairs (G, t). We say that D is
(σ , η, C, α)-nice if, for all sets D ⊂ [n] such that |D| ≤ δn, we have
that
(1) Pr[E4(C, G′, t′) ∧ E5(C, G′, t′, α) = 1 | (G′, t′) ← D] >
(2) Pr[E6(D, G′, t′) = 1 | (G′, t′) ← D] > 1 − 2−η−1
Analogously, we say that a graph generation algorithm is(σ , η, C, α)-
nice if it implements a (σ , η, C, α)-nice distribution.
1 − 2−σ
Lemma 4.7. Let γ ≥ 0 and δ ≥ 0 such that γ + 2δ < 1. Then
there exists a constant c making the following statement true for all
sufficiently large n. Let k be such that
c(1 + log n + η + σ) ≤ k < (n − 1)/4
(cid:114)
t = ⌈(3 + γ − 2δ)k/4⌉ and α = (1 − γ − 2δ)/12. Let C ⊂ [n], such
that |C| ≤ γn, be the set of corrupted clients. Then for sufficiently
large n, the distribution D over pairs (G, t) implemented by Part II of
Algorithm 3 is (σ , η, C, α)-nice.
4.4 Correctness and Security
In this section, we state our correctness and security theorems; we
formally prove them in Appendix C of our full paper [5].
Theorem 4.8 (Correctness). Let Π be the protocol of Algorithm 3
with the parameters of Lemma 4.7. Consider an execution of Π with
inputs X = ( (cid:174)xi)i∈[n], in which all parties follow the protocol. If
A′
4 ≥ (1 − δ)n, i.e. less than a fraction δ of the clients dropout, then
2 (cid:174)xi with probability
A′
1 − 2−η.
the server does not abort and obtains (cid:174)z =
Theorem 4.9 (Security). Let σ , η, λ be integer parameters. Let Π
be the protocol of Algorithm 3 with the parameters of Lemma 4.7,
p = k − (t − kγn
n − 1 +
k
2((σ + 1) log(2) + log n)) + 1,
and instantiated with a IND-CPA and INT-CTXT authenticated en-
cryption scheme, a EUF-CMA signature scheme, and a λ-secure key
agreement protocol. There exists a PPT simulator Sim such that, for
all C ⊂ [n] such that |C| ≤ γn, inputs X = ( (cid:174)xi)i∈[n]\C, and for all
malicious adversary A controlling the server and the set of corrupted
clients C behaving semi-honestly in Part I, the output of Sim is com-
putationally indistinguishable from the joint view of the server and
the corrupted clients RealC, i.e., RealC ≈σ,λ SimFX′,α (C), where the
simulator can query once the ideal functionality FX,α .
4.5 Performance Analysis
We report the communication and computation costs for the client
and server when k = O(log n). We recall that we assumed that basic
operations and representation of elements in X are O(1).
Client computation: O(log2
n + l log n). Each client computation
can be broken up as receiving ≤ 4k log n hashes (O(k log n) com-
plexity), ≤ 5k key agreements and k encryptions (O(k) complexity),
≤ 5k signatures signing and verifications (O(k) complexity), cre-
ating twice t-out-of-k Shamir secret shares (O(k
2) complexity),
generating values (cid:174)mi, j for all neighbors j (O(kl) complexity).
Client communication: O(log2
n + l). Each client performs ≤ 5k
key agreements (O(k) messages), send 2k encrypted shares (O(k)
messages), send a masked input (O(l) complexity), send ≤ 5k sig-
natures, and reveal up to 2k shares (O(k) messages).
Server computation: O(n(log2
n + l log n)). The server computa-
tion can be broken up as reconstructing t-out-of-k Shamir secrets
for each client (O(n · k
2) complexity), generating values (cid:174)mi, j for all
(dropped out) neighbors j of each client i (O(nkl) complexity).
n + l)). The server receives or
Server communication: O(n(log2
n + l) to each client.
sends O(log2
4.6 Guarantees with an honest server
We now discuss the setting where an adversary controls a subset
of γn actively corrupted clients, but the rest of the clients and the
server are honest. It is easy to see that the view of the adversary
in this case does not include any information whatsoever about
honest inputs, because clients only receive shares of a PRG seed
(for self masks) and shares of a public key (for pairwise masks). The
only message that contains the input is the masked input (cid:174)yi, which
is sent to the server. Note that malicious clients could lie about their
randomness (cid:174)ri and pairwise masks when sharing seeds for it, but
this boils down to sending an arbitrary (cid:174)yi maliciously, which is in
turn equivalent to lying about their input (cid:174)xi. Let us remark that we
do not prevent malicious clients to choose their input adaptively
depending on which of their neighbors dropped out (analogously
to [8]). As mentioned in Section 4.2 one could limit this flexibility
to choosing input based on which neighbors dropped out before the
masked input (cid:174)yi is sent with a cheap modification in the protocol.
To make the above security claim formal in the standard ideal
vs. real simulation paradigm, one needs to show that there is a sim-
ulator in the ideal world that can produce the view of the malicious
clients, along with the output of the honest server. Moreover, this
should be done for any setting D of honest dropped out clients (re-
call that the adversary controls if/when malicious clients dropout).
The simulator has one-time access to an ideal functionality return-
ing the sum of the values of the clients that did not dropout (the
prescribed output for the server), and can evaluate an attacker A
that controls γn malicious clients. The simulator just needs to run
A with an arbitrary fake input for honest clients, say all zeroes, and
dropping out honest clients according to D . This allows to extract
the sum zmal of the inputs of malicious clients provided by the
adversary. Note that zmal is all that is needed to query the ideal
functionality and obtain the server’s prescribed output (including
the true sum of the honest clients in this case).
Session 4D: Distributed Protocols CCS '20, November 9–13, 2020, Virtual Event, USA12625 NUMERICAL BOUNDS AND CONCRETE
EFFICIENCY RESULTS
In Theorems 3.6 and 4.9, we established that a number of neighbors
k = O(log n + η + σ) suffices to obtain secure and correct protocols
in the semi-honest and malicious variants. These theorems are
derived from tail bounds on the hypergeometric distribution. While
the same tail bounds could be used in practice to set the operating
parameters k, t (i.e. by direct evaluation of the expression for k in
Theorem 3.10), more efficient choices are found below by directly
evaluating the hypergeometric CDF.
5.1 Semi-honest Variant
The results in this Section follow from Lemma 3.7, and the fact
that the CDF of the hypergeometric distribution can be evaluated
directly. More concretely, note that Lemma 3.7 gives sufficient effi-
ciently checkable conditions that k, t can satisfy (given the rest of
the parameters) implying that our protocol is secure and correct
(Lemmas 3.6 and 3.5). This gives a numerical approach to obtain se-
cure parameters k, t given n, σ , η, γ , δ. The naive algorithm iterates
over all possible values of k, t in lexicographic order and stops as
soon as it finds one that satisfies both conditions in Lemma 3.7 (as-
suming our intent is to minimize computation and communication
for the required security σ). We implemented a more efficient and
stable variant of this approach, using binary search and checks in
the log domain, avoiding numerical under(over)flows. Our imple-
mentation consists of less than 100 lines of Python code leveraging
the Scipy scientific computing library [35].
Fig. 2 (a) shows secure values of k for several settings of param-
eters corresponding to all combinations of γ , δ taking values in
{1/3, 1/20}, σ = 40, and η = 30, as n grows from 103 to 108. Fig. 2
(b) shows how k scales with γ, everything else being the same. Note
that less than 150 neighbors are enough to provide security up to
n = 108 clients where at most 1 in 5 clients are corrupted by and
1 in 20 clients dropout (or vice versa). Moreover, k = 100 suffices
for n = 104, which immediately translates into a 100x concrete im-
provement in client computation and communication with respect
to the protocol by Bonawitz et al [8], with roughly the same server
computation cost. These gains increase linearly with n, as our pro-
tocol retains roughly the same client runtime and communication
costs for values of n for which the protocol by Bonawitz et al [8]
becomes highly impractical.
Benchmarking. In the semi-honest protocol, each client performs
(a) 2k key agreements, (b) secret sharing 2 secrets into k shares
(which takes O(k
2) time), and (c) generating and stretching k + 1
seeds using the PRG F (which we implement using AES) to the
length of the input vector l (which is O(kl)). Thus our runtime and
communication improvements with respect to the semi-honest ver-
sion of [8] are roughly a factor n/k = O(n/log n). We benchmarked
Shamir share generation and PRG expansion using AES to confirm
that the PRG expansion is the bottleneck (which is consistent with
the running times reported in [8]). We report running times for a
particular setting in Table 2 in the appendix. The setting was cho-
sen for ease of comparison with the running times reported to the
semi-honest version of the protocol of Bonawitz et al. (see Figure 8
in [8]). One can observe that our approach is roughly an order of
magnitude faster for n = 1000 (which is the the only value of n for
which Bonawitz et al. report runtimes). Crucially, our costs remain
almost the same as n increase, which the complete-graph construc-
tion of in [8] quickly becomes impractical. This is consistent with
the factor of n/k improvement mentioned above, as k = O(log n)
stays within (80, 120) as n grows within (103
, . . . , 105).
5.2 Malicious Variant
Our approach to compute numerical bounds for the malicious vari-
ant is analogous to the one from the semi-honest variant: Defini-
tion 4.6 states sufficient conditions that a triple (k, t, α) must satisfy
to get security and correctness. As in the semi-honest case these
checks involve only simple calculations and querying the CDF of
a hypergeometric random variable. Our implementation consists
of roughly 100 lines of Python code leveraging the Scipy scientific
computing library [35].
Fig. 2 (c) shows secure values of k and α for several settings cor-
responding to all combinations of γ , δ taking values in {1/5, 1/20},
σ = 40, and η = 30, as n grows from 103 to 108. For example, with
104 clients and γ = δ = 1/5, less than 600 neighbors per client are
enough for security, and every honest client is guaranteed that if
the (possibly malicious) server gets a sum z in the clear involving
their value, then z is the result of aggregating at least 0.39n = 3900
honest clients. The value of k in this plot is the minimum value
that guarantees security σ, thus minimizing client computation and
communication. Hence, the resulting α, which grows with k, is not
as large as it could be for each setting. This explains the counter-
intuitive fact that settings with smaller γ also have smaller α (as
they allow a smaller k). To clarify this point Fig. 2 (d) shows how α
scales with k: α converges towards (1 − γ − δ)n, which is the best
one can hope for (as in a round without dropouts a malicious server
can drop any set of (δ)n honest parties from the sum). Hence, by
increasing k, our analysis covers the full spectrum of possible α, and
allows one to fine tune parameters to trade-off between security
(captured by α, σ) and the main computational costs (captured by
k, t). Finally, to illustrate this kind of fine-tuning, Figure 3 shows
how α grows for small numbers of neighbors in some parameters.
, γ = δ = 1/20, 300
For example, the plot shows that, for n = 104
neighbors are enough so that every honest client is certain that
their value will be aggregated with at least 5000 other clients values!
6 SHUFFLING FROM SUMMATION
In this section we consider the following shuffling primitive be-
tween many clients with inputs and a server who should obtain
the shuffled clients’ inputs. Each client i has a message xi ∈ M
with |M| = m, and the goal is for the server to receive the mul-
tiset of messages with no information on which message came
from whom. This is equivalent to the messages being sent to a
trusted third party and shuffled (or sorted) before being handed
to the server. This primitive is the basis of the shuffle model of
differential privacy [3, 4, 11, 19] and could be used for anonymized
submissions [6].
We show a reduction from secure shuffling to secure summation.
Our reduction makes a single call to secure summation, and thus
the security and drop-out robustness properties of our protocol