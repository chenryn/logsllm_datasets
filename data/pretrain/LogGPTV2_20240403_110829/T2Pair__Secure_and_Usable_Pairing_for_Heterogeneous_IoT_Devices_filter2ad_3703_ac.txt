fuzzy commitment and the Reed-Solomon (RS) error correcting
code [38]. Given a set of possible words P each with 𝑚 bits, a set
of possible codewords Q each with 𝑛 bits, and 𝑛> 𝑚, RS codes are
initialized as P= F𝑚
The device 𝑑1 first randomly selects a “password” 𝑃∈ P using
codeword 𝜆∈ Q using the RS encoding function ( 2 ). This step adds
redundancy to the original words with 𝑛> 𝑚, based on polynomials
hiding it using the evidence 𝐸𝑑1. It performs an exclusive-OR (⊕)
between 𝑒(𝐸𝑑1) and 𝜆, and obtains the commitment 𝛿= 𝑒(𝐸𝑑1)⊕
𝜆 [20, 32], where 𝑒() is the encoding described in Section 4.1 ( 3 ).
𝑑2 then conducts decommitment. It uses the received 𝛿 and 𝑒(𝐸𝑑2)
to obtain a codeword 𝜆′= 𝑒(𝐸𝑑2)⊕ 𝛿 ( 4 ). Finally, 𝜆′ is decoded to
𝑃′ using the RS decoding function ( 5 ). Readers are referred to [20]
close enough, 𝑑2 is able to derive a value 𝑃′= 𝑃; otherwise, 𝑃′≠ 𝑃.
(because of false rejections) or an attacker (who has derived 𝑃′
using a guess of the evidence), is not sure whether 𝑃′= 𝑃.
over Galois fields [38], to support error correcting. After that, the
commitment process produces an encryption of the codeword 𝜆 by
The effects of this phase are as follows. (1) If 𝐸𝑑1 and 𝐸𝑑2 are
(2) However, at this moment, 𝑑2, no matter it is a benign device
for more detailed interpretation of fuzzy commitment.
The reason we call 𝑃, which is actually a random key value, a
“password” is to take offline brute-force attacks (BF-offline) into
consideration. If 𝑃 is directly used as the session key, an offline
attacker who has collected the traffic can try every possible evidence
and repeat 4 and 5 until he finds a key that can decrypt the traffic;
thus, the entropy of evidence (see Section 7.3) disqualifies 𝑃 to work
Session 1E: Cyberphysical Systems CCS '20, November 9–13, 2020, Virtual Event, USA314Figure 5: Six devices are used in our experiments, including
two keypads (a plastic keypad labeled as 1, and a rubber one
as 2; in either case, we only use one button for pairing); two
knobs (a large knob labeled as 3, and a small one as 4); two
touchscreens (a 5.2" Google Nexus 5X labeled as 5, and a 2.45"
Unihertz Atom labeled as 6).
as a secure shared key. We thus use PAKE, which securely generates
a high-entropy shared key from a low-entropy password [8].
PAKE. We use Diffie-Hellman Encrypted Key Exchange (DH-
EKE) [5], which has led to the PAKE family of methods in IEEE
P1363.2 [18], but many other PAKE methods should also work.
DH-EKE is a DH-based key exchange method that makes use of a
password to defeat MITM attacks, as both 𝐴 and 𝐵 are transmitted
in encrypted messages ( 6 and 8 ). Note the base 𝑔 and the modulus
𝑝 are public knowledge, h() is a cryptographic hash function, and
E() is a symmetric encryption function. If 𝑃′≠ 𝑃, 𝑑2 will receive a
after 11 and 12 , 𝑑1 and 𝑑2 establish a key 𝐾= 𝐾′.
value different from the challenge 𝐶1 it has picked ( 11 ); otherwise,
Parameter Consideration. The security of 𝜆 is primarily gov-
erned by the size (i. e., 2𝑘) of the set of codewords [20]. To provide
strong security, 𝑘 should be larger than 80, which is comparable to
RSA-1024. By applying RS, a word of length 𝑚 is uniquely mapped
to a codeword of length 𝑛. The maximum number of bits between
2 ⧹︀. Thus, if and
two codewords that can be corrected is 𝑇ℎ𝑟=⟨︀ 𝑛−𝑚
isfies Ham(𝑒(𝐸𝑑1), 𝑒(𝐸𝑑2))≤ 𝑇ℎ𝑟, the symmetric key 𝑃′= 𝑃 can
only if the Hamming distance between two pieces of evidence sat-
be established. The value selection for 𝑇ℎ𝑟 is studied in Section 7.1.
Resilience to Brute-Force Attacks. The forward secrecy of DH
ensures that even if 𝑃 is cracked offline (e.g., recording a video
of the user to assist offline analysis of 𝑃, or enumerating every
possible evidence to reveal 𝑃), it cannot be used to reconstruct the
session key. Thus, offline brute-force (BF-offline) attacks will fail.
BF-online will not work either. As PAKE attains zero-knowledge
password proof [18], an active (man-in-the-middle) attacker can
perform exactly one guess (unless he gets it right, he learns no
information), and a passive eavesdropper learns no information
about the password or the generated key.
5 PROTOTYPE IMPLEMENTATION
Helper. A user can either wear a wristband or hold a smartphone
to perform pairing. We implement the prototypes on two helpers:
(1) an LG W200 smartwatch, and (2) a Google Nexus 5X smartphone.
We develop an application for the smartwatch running Android
Wear 2.0, and an application for the smartphone running Android
7 to collect the motion data. Both the smartwatch and smartphone
are equipped with a Bosch BMI160 inertial measurement unit con-
taining a triple-axis accelerometer and a triple-axis gyroscope.
IoT device. A variety of IoT devices are used to build the prototypes,
as shown in Fig. 5. (1) Buttons made of two different materials are
used: a plastic keypad labeled as 1, and a rubber one labeled as
2. An Arduino board MKR1000 is adopted to interface with the
rubber keypad, and the communication is via the Wi-Fi module of
MKR1000. The plastic one has a Bluetooth module to communicate
with the helper. (2) Knobs with two different sizes are used: a large
knob labeled as 3, and a small one labeled as 4. The large knob is
a volume controller for desktop; we write an interface function to
read its data. For the small one, we use an Arduino board MKR1000
to build its interface. (3) Touchscreens with two different sizes are
used: Nexus 5X labeled as 5 has a screen size of 5.2", and Unihertz
Atom labeled as 6 has a screen size of 2.45". We implement an
application to collect the touch trajectory on the screen and record
the coordinates of each touch point in the 𝑥𝑦-plane of the screen.
6 DATA COLLECTION
We build two datasets: (1) Dataset I is used to measure the accuracy
of our system, and (2) Dataset II is used to evaluate the resistance
of our system to mimicry attacks.
We recruit 20 participants: 14 males and 6 females with ages
ranging from 18 to 36. We use three devices, including the large
knob, the plastic keypad, and the Nexus 5X smartphone, to collect
data (the other three devices are used to evaluate the stability of
the system, presented in Section 7.4).
6.1 Dataset I for Evaluating Accuracy
To build Dataset I, we ask each participant to wear a smartwatch
and perform the pairing operations on each of the three devices
for 30 times. In addition, to measure the impact of pauses, each
participant is asked to perform two types of pairing each time: one
without pauses, and another with random pauses (the user can
choose to add one or two pauses during the pairing operations).
Positive pairs. When a participant performs the pairing operations
on a device, we collect one positive data pair from the smartwatch
and device. Thus, for the pairing operations without pauses, our
dataset contains 1,800 (= 20× 30× 3) positive pairs, each with a
label 𝑠= 1; for the pairing operations with random pauses, we also
collect 1,800 (= 20× 30× 3) positive pairs, each with a label 𝑠= 1.
Negative pairs. Assuming two users, 𝜇1 and 𝜇2, perform the same
pairing operations on two devices, the evidence 𝐸𝑑1 from 𝜇1’s IoT
device and the evidence 𝐸ℎ2 from 𝜇2’s helper constitute a negative
pair; similarly, the evidence 𝐸ℎ1 from 𝜇1’s helper and the evidence
𝐸𝑑2 from 𝜇2’s device constitute another negative pair.
By randomly selecting two users performing the same pairing
operations, we generate 1,800 negative pairs (the same amount as
the positive pairs) for the pairing operations without pauses, and
1,800 negative pairs for the pairing operations with pauses, each
with a label 𝑠=−1.
6.2 Dataset II for Evaluating Resilience to
Mimicry Attacks
To build Dataset II, we have 10 participants act as victims and
the other 10 as attackers. We consider the three attack settings of
mimicry attacks as discussed in Threat Model in Section 2.
For MA-trained, we first ask each victim to perform pairing
on each type of device for five times, and record a video of each
pairing. Each attacker is trained by watching the corresponding
123456Session 1E: Cyberphysical Systems CCS '20, November 9–13, 2020, Virtual Event, USA315video as many times as needed to train herself. The attacker only
needs to learn one victim’s actions and launches attacks against
that victim. During the training, we provide the attackers with
immediate feedback on the differences between their evidence and
the victims’, so that they can adapt their operations to mimic better.
For each attack setting, each pair of attacker and victim performs
the pairing operations with/without pauses on each device for 15
times. Given 4 pieces of evidence: 𝐸𝑑𝑉 from𝒱’s device, 𝐸ℎ𝑉 from
𝒱’s helper, 𝐸𝑑𝐴 from𝒜’s device, and 𝐸ℎ𝐴 from𝒜’s helper, two kinds
(G1) The first pair consists of 𝐸ℎ𝑉 and 𝐸𝑑𝐴, implying that𝒜
attempts to have𝒱’s helper accept a pairing with𝒜’s device.
(G2) The second pair consists of 𝐸𝑑𝑉 and 𝐸ℎ𝐴, implying that𝒜
attempts to fool𝒱’s device into pairing with𝒜’s helper.
pairing operations without pauses, containing 450 (= 10× 15× 3)
For each attack setting, we collect 900 evidence pairs for the
of evidence pairs are constructed based on the attackers’ goal.
G1 pairs and 450 G2 pairs. We collect the same number of pairs for
the pairing operations with pauses.
7 EVALUATION
We conduct four in-lab studies to evaluate T2Pair in terms of pair-
ing accuracy, security, stability, and efficiency. The first study (Sec-
tion 7.1) examines its pairing accuracy. The second (Section 7.2)
evaluates the resilience of our system to mimicry attacks. The third
(Section 7.3) evaluates the randomness and entropy of evidence.
The fourth (Section 7.4) tests the stability of T2Pair under different
parameters and experimental settings. The time efficiency is evalu-
ated in Section 7.5. The user study that evaluates the usability of
our pairing operations is presented in Appendix A.
7.1 Pairing Accuracy
We use False Rejection Rate (FRR) and False Acceptance Rate (FAR) to
measure the pairing accuracy. 1) FRR is the rate that our system fails
to pair the legitimate user’s IoT device with the helper. A low FRR
is important for usability. 2) FAR is the rate that our system pairs
the legitimate user’s IoT device (resp. helper) with the attacker’s
helper (resp. IoT device). So a low FAR is critical for security.
Given a pairing operation, T2Pair accepts the pairing if a shared
key can be successfully derived from a pair of evidence that has
a Hamming distance smaller than the threshold (see Section 4.1).
The threshold (𝑇ℎ𝑟) indicates the allowed evidence difference for
T2Pair to accept a pairing. A false rejection occurs if T2Pair obtains
, 𝐸𝑑2)> 𝑇ℎ𝑟 for a legal pairing of 𝑑1 and 𝑑2, and a false
, 𝐸𝑑3)< 𝑇ℎ𝑟 for an illegal pairing of 𝑑1 and
Ham(𝐸𝑑1
acceptance if Ham(𝐸𝑑1
𝑑3. The evidence length is defined as the number of time intervals it
contains. For pairings with pauses, we set the evidence length to 7
for knobs, and 6 for both touchscreens and buttons (see Evidence
Length in Section 7.4). For pairings without pauses, we set the
evidence length to 8 for all devices.
We use Dataset I to evaluate the accuracy of T2Pair, and compare
the performance between the pairing operations with and without
pauses. Figure 6 and Figure 7 show the performance in terms of FAR
and FRR by varying the threshold of Hamming distance. We choose
the base value as 10ms (Base Value is studied in Section 7.4).
As expected, the larger the threshold, the lower the FRR (better
usability), but the higher the FAR (worse security). Figure 6 presents
the results for pairings without pauses. By choosing the threshold
that yields an FRR 0.10 (we consider an error below 0.10 is reason-
ably good for usability), we can achieve an FAR 0.02, 0.03, and 0.09
for buttons, knobs, and screens, respectively (see the vertical dashed
lines). An FRR of 0.10 means that on average 10 out of 100 pairing
attempts fail, and thus a user is expected to perform 100/90=1.1
pairing attempts for pairing one device.
Figure 7 shows the performance when random pauses are in-
troduced during pairing. We find that the FAR can be significantly
improved—the FAR grows very slowly as the threshold value in-
creases. The results indicate that random pauses can enhance the
discriminability of each pairing. If security is particularly impor-
tant for certain applications, we can set the FAR as 0.00 and T2Pair
achieves (FAR, FRR)=(0.00, 0.03) for buttons, (0.00, 0.09) for knobs,
and (0.00, 0.07) for screens (see the vertical dashed lines). Thus, se-
curity is much improved with usability keeping good. But if vanilla
fuzzy commitment (Section 4.1) is used, we can only achieve (FAR,
FRR) (0.00, 0.81) for buttons, (0.00, 0.48) for knobs, and (0.00, 0.73)
for screens, showing heavily degraded accuracies.
7.2 Resilience to Mimicry Attacks
This section evaluates the resilience of T2Pair (based on the thresh-
olds selected in Section 7.1) to mimicry attacks for two types of
pairing operations: one without pauses (Type-I) and the other with
pauses (Type-II). We use FAR to measure the success rate of attacks.
We evaluate the resilience using Dataset II (see Section 6.2).
Resilience to MA-obstructed. The attacker (𝒜) stands behind the
victim (𝒱) with a distance of 2–3 meters and does not have a clear
view of𝒱’s hand movements. As shown in Table 2, for the pairing
operations of Type-I, T2Pair can successfully identify 96.0%, 95.3%
and 90.7% of attacks on buttons, knobs, and screens, respectively.
The performance can be greatly improved if the random pauses
are considered—specifically, for the Type-II operations, T2Pair can
successfully defend against all the attacks on knobs, and 99.3% of
attacks on screens and buttons.
Resilience to MA-clear.𝒜 stands next to𝒱 and has a clear view of
𝒱’s hand movements. As shown in Table 2, for the Type-I operations,
the attackers’ success rate increases, especially for the screen-based
device. However, for the Type-II operations, the attackers’ success
rate is still very low. The results demonstrate that the random
pauses during each pairing can increase the difficulty for attackers
to mimic the victims’ hand movements. Thus, the pairing operations
with random pauses are more secure.
Resilience to MA-trained. How to train the attacker is described
in Section 6.2). Compared to the Type-II operations, FARs for the
Type-I operations increase sharply (up to 27.4%), which reveals a
noticeable weakness of pairing without pauses. The pauses make
the intervals more unpredictable and difficult to mimic. To eliminate
the weakness, our protocol performs self-checking at Phase 2 in
Table 1, which aborts pairing if there are no pauses.
7.3 Randomness and Entropy
Randomness. The randomness level of the time interval between
two consecutive events directly affects the entropy of evidence.
We notice that it ranges from large values when the user pauses to
small ones when she presses/twists/swipes quickly. It is challenging
Session 1E: Cyberphysical Systems CCS '20, November 9–13, 2020, Virtual Event, USA316(a) Button-based device pairing.
(b) Knob-based device pairing.
(c) Screen-based device pairing.
Figure 6: FARs and FRRs with different threshold values for pairing operations without random pauses.
(a) Button-based device pairing.
(b) Knob-based device pairing.
(c) Screen-based device pairing.
Figure 7: FARs and FRRs with different threshold values for pairing operations with random pauses.
Table 2: FARs under mimicry attacks. (Legend: 𝐴𝑖 stands for the 𝑖th attacker.)
Attacks
MA-obstructed
No clear view
Untrained attackers
MA-clear
Clear view
Untrained attackers
MA-trained
Clear view
Trained attackers
No
Yes
Pauses? Device
Button
Knob
Screen
Button
Knob
Screen
Button
Knob
Screen
Button
Knob
Screen
Button
Knob
Screen
Button