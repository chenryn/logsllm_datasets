Such cases can be rewritten by replacing them with a se-
mantically equivalent instruction or sequence of instructions.
Doing so systematically requires an understanding of x86 in-
struction coding. An x86 instruction contains: (i) an opcode
ﬁeld possibly with preﬁx, (ii) a MOD R/M ﬁeld that deter-
mines the addressing mode and includes a register operand,
(iii) an optional SIB ﬁeld that speciﬁes registers for indirect
memory addressing, and (iv) optional displacement and/or
immediate ﬁelds that specify constant offsets for memory
operations and other constant operands.
The strategy for rewriting an instruction depends on the
ﬁelds with which the WRPKRU or XRSTOR subsequence
overlaps. Table 1 shows the complete strategy.
An opcode ﬁeld is at most 3-bytes long. If the WRPKRU
(XRSTOR) starts at the ﬁrst byte, the instruction is WRP-
KRU (XRSTOR). In this case, we make the instruction safe
by inserting the corresponding check from Section 3.4 after
it. If the WRPKRU or XRSTOR starts after the ﬁrst byte of
the opcode, it must also overlap with a later ﬁeld. In this
case, we rewrite according to the rule for that ﬁeld below.
If the sequence overlaps with the MOD R/M ﬁeld, we
change the register in the MOD R/M ﬁeld. This requires
a free register. If one does not exist, we rewrite to push an
existing register to the stack, use it in the instruction, and pop
it back. (See lines 2 and 3 in Table 1.)
If the sequence overlaps with the displacement or the im-
mediate ﬁeld, we change the mode of the instruction to use
a register instead of a constant. The constant is computed
in the register before the instruction (lines 4 and 6).
If a
free register is unavailable, we push and pop one. Two
instruction-speciﬁc optimizations are possible. First, for
jump-like instructions, the jump target can be relocated in
the binary; this changes the displacement in the instruction,
obviating the need a free register (line 5). Second, associa-
tive operations like addition can be performed in two incre-
ments without an extra register (line 7). Rewriting the SIB
ﬁeld is never required because any WRPKRU or XRSTOR
must overlap with at least one non-SIB ﬁeld (the SIB ﬁeld is
1 byte long while these instructions are 3 bytes long).
Compilers and well-written assembly programs normally
do not mix data like constants, jump tables, etc. with the
instruction stream and instead place such data in a non-
executable data segment. If so, WRPKRU or XRSTOR se-
quences that occur in such data can be ignored.
Compiler support For binaries that can be recompiled
from source, rewriting can be added to the codegen phase of
the compiler, which converts the intermediate representation
(IR) to machine instructions. Whenever codegen outputs an
inadvertent WRPKRU or XRSTOR, the surrounding instruc-
tions in the IR can be replaced with equivalent instructions
as described above, and codegen can be run again.
Runtime binary rewriting For binaries that cannot be re-
compiled, binary rewriting can be integrated with the inter-
ception and inspection mechanism (Section 3.4). When the
inspection discovers an unsafe WRPKRU or XRSTOR on an
executable page during its scan, it overwrites the page with
USENIX Association
28th USENIX Security Symposium    1229
1-byte traps, makes it executable, and stores the original page
in reserve without enabling it for execution. Later, if there is
a jump into the executable page, a trap occurs and the trap
handler discovers an entry point into the page.
The rewriter then disassembles the reserved page from
that entry point on, rewriting any discovered WRPKRU or
XRSTOR occurrences, and copies the rewritten instruction
sequences back to the executable page. To prevent other
threads from executing partially overwritten instruction se-
quences, we actually rewrite a fresh copy of the executable
page with the new sequences, and then swap this rewritten
copy for the executable page. This technique is transparent
to the application, has an overhead proportional to the num-
ber of entry points in offending pages (it disassembles from
every entry point only once) and maintains the invariant that
only safe pages are executable.
A rewritten instruction sequence is typically longer than
the original sequence and therefore cannot be rewritten in-
place. In this case, binary rewriting tools place the rewrit-
ten sequence on a new page, replace the ﬁrst instruction in
the original sequence with a direct jump to the rewritten se-
quence, and insert a direct jump back to the instruction fol-
lowing the original sequence after the rewritten sequence.
Both pages are then enabled for execution.
Implementation and testing The rewrite strategy is ar-
guably complete. We have implemented the strategy as a
library, which can be used either with the inspection mecha-
nism as explained above or with a static binary rewrite tool,
as described here. To gain conﬁdence in our implementation,
we examined all binaries of ﬁve large Linux distributions (a
total of 204,370 binaries). Across all binaries, we found a
total of 1213 WRPKRU/XRSTOR occurrences in code seg-
ments. We then used a standard tool, Dyninst [15], to try
to disassemble and rewrite these occurrences. Dyninst was
able to disassemble 1023 occurrences and, as expected, our
rewriter rewrote all instances successfully. Next, we wanted
to run these 1023 rewritten instances. However, this was
infeasible since we did not know what inputs to the bina-
ries would cause control to reach the rewritten instances.
Hence, we constructed two hand-crafted binaries with WRP-
KRUs/XRSTORs similar to the 1023 occurrences, rewrote
those WRPKRUs/XRSTORs with Dyninst and checked that
those rewritten instances ran correctly. Based on these exper-
iments, we are conﬁdent that our implementation of WRP-
KRU/XRSTOR rewriting is robust.
5 Use Cases
ERIM goes beyond prior work by providing efﬁcient isola-
tion with very high component switch rates of the order of
105 or 106 times a second. We describe three such use cases
here, and report ERIM’s overhead on them in Section 6.
ities such as the Heartbleed bug [37] is well-studied [33,
34]. However, long-term keys are accessed relatively infre-
quently, typically only a few times per user session. Session
keys, on the other hand, are accessed far more frequently—
over 106 times a second per core in a high throughput web
server like NGINX. Isolating sessions keys is relevant be-
cause these keys protect the conﬁdentiality of individual
users. With its low-cost switching, ERIM can be used to
isolate session keys efﬁciently. To verify this, we partitioned
OpenSSL’s low-level crypto library (libcrypto) to isolate the
session keys and basic crypto routines, which run as T, from
the rest of the web server, which runs as U.
Native libraries in managed runtimes Managed runtimes
such as a Java or JavaScript VM often rely on third-party na-
tive libraries written in unsafe languages for performance.
ERIM can isolate the runtime from bugs and vulnerabilities
in a native library by mapping the managed runtime to T and
the native libraries to U. This use case leverages the “in-
tegrity only” version of ERIM (Section 3.7). We isolated
Node.js from a native SQLite plugin. Node.js is a state-of-
the-art managed runtime for JavaScript and SQLite is a state-
of-the-art database library written in C [1, 2]. The approach
generalizes to isolating several mutually distrusting libraries
from each other by leveraging ERIM’s multi-component ex-
tension from Section 3.7.
integrity (CPI)
CPI/CPS Code-pointer
[31] prevents
control-ﬂow hijacks by isolating sensitive objects—code
pointers and objects that can lead to code pointers—in a safe
region that cannot be written without bounds checks. CPS
is a lighter, less-secure variant of CPI that isolates only code
pointers. A key challenge is to isolate the safe region efﬁ-
ciently, as CPI can require switching rates on the order of
106 or more switches/s on standard benchmarks. We show
that ERIM can provide strong isolation for the safe region
at low cost. To do this, we override the CPI/CPS-enabled
compiler’s intrinsic function for writing the sensitive region
to use a call gate around an inlined sequence of T code that
performs a bounds check before the write. (MemSentry [30]
also proposes using MPK for isolating the safe region, but
does not actually implement it.)
6 Evaluation
We have implemented two versions of an ERIM prototype
for Linux.3 One version relies on a 77 line Linux Secu-
rity Module (LSM) that intercepts all mmap and mprotect
calls to prevent U from mapping pages in executable mode,
and prevents U from overriding the binary inspection han-
dler. We additionally added 26 LoC for kernel hooks to
Linux v4.9.110, which were needed by the LSM. We also
implemented ERIM on an unmodiﬁed Linux kernel using
the ptrace-based technique described in Section 3.4. In the
Isolating
Isolating cryptographic keys in web servers
long-term SSL keys to protect from web server vulnerabil-
3Available
online
at
vahldiek/erim.
https://gitlab.mpi-sws.org/
1230    28th USENIX Security Symposium
USENIX Association
following, we show results obtained with the modiﬁed ker-
nel. The performance of ERIM on the stock Linux kernel
is similar, except that the costs of mmap, mprotect, and
pkey_mprotect syscalls that enable execute permissions
are about 10x higher. Since the evaluated applications use
these operations infrequently, the impact on their overall per-
formance is negligible.
Our implementation also includes the ERIM runtime li-
brary, which provides a memory allocator over MT, call
gates, the ERIM initialization code, and binary inspection.
These comprise 569 LoC. Separately, we have implemented
the rewriting logic to eliminate inadvertent WRPKRU oc-
currences (about 2250 LoC). While we have not yet inte-
grated the logic into either a compiler or our inspection han-
dler, the binaries used in our performance evaluation exper-
iments do not have any unsafe WRPKRU occurrences and
do not load any libraries at runtime. However, the binaries
did have two legitimate occurrences of XRSTOR (in the dy-
namic linker library ld.so), which we made safe as de-
scribed in Section 3.4. Two other inadvertent XRSTOR oc-
curred in data-only pages of executable segments in libm,
which is used by the SPEC benchmarks. We made these safe
by re-mapping the pages read-only. Hence, the results we
report are on completely safe binaries.
We evaluate the ERIM prototype on microbenchmarks and
on the three applications mentioned in Section 5. Unless
otherwise mentioned, we perform our experiments on Dell
PowerEdge R640 machines with 16-core MPK-enabled In-
tel Xeon Gold 6142 2.6GHz CPUs (with the latest ﬁrmware;
Turbo Boost and SpeedStep were disabled), 384GB mem-
ory, 10Gbps Ethernet links, running Debian 8, Linux kernel
v4.9.60. For the OpenSSL/webserver experiments in Sec-
tions 6.2 and 6.5, we use NGINX v1.12.1, OpenSSL v1.1.1
and the ECDHE-RSA-AES128-GCM-SHA256 cipher. For
the managed language runtime experiment (Section 6.3), we
use Node.js v9.11.1 and SQLite v3.22.0. For the CPI exper-
iment (Section 6.4), we use the Levee prototype v0.2 avail-
able from http://dslab.epfl.ch/proj/cpi/ and
Clang v3.3.1 including its CPI compile pass, runtime library
extensions and link-time optimization.
6.1 Microbenchmarks
Switch cost We performed a microbenchmark to measure
the overhead of invoking a function with and without a
switch to a trusted component. The function adds a con-
stant to an integer argument and returns the result. Table 2
shows the cost of invoking the function, in cycles, as an in-
lined function (I), as a directly called function (DC), and as
a function called via a function pointer (FP). For reference,
the table also includes the cost of a simple syscall (getpid),
the cost of a switch on lwCs, a recent isolation mechanism
based on kernel page table protections [33], and the cost of a
VMFUNC (Intel VT-x)-based extended page table switch.
In our microbenchmark, calls with an ERIM switch are be-
Call type
Cost (cycles)
Inlined call (no switch)
Direct call (no switch)
Indirect call (no switch)
Inlined call + switch
Direct call + switch
Indirect call + switch
getpid system call
Call + VMFUNC EPT switch
lwC switch [33] (Skylake CPU)
5
8
19
60
69
99
152
332
6050
Table 2: Cycle counts for basic call and return
tween 55 and 80 cycles more expensive than their no-switch
counterparts. The most expensive indirect call costs less than
the simplest system call (getpid). ERIM switches are up to
3-5x faster than VMFUNC switches and up to 100x faster
than lwC switches.
Because the CPU must not reorder loads and stores with
respect to a WRPKRU instruction, the overhead of an ERIM
switch depends on the CPU pipeline state at the time the
WRPKRUs are executed. In experiments described later in
this section, we observed average overheads ranging from 11
to 260 cycles per switch. At a clock rate of 2.6GHz, this cor-
responds to overheads between 0.04% and 1.0% for 100,000
switches per second, which is signiﬁcantly lower than the
overhead of any kernel- or hypervisor-based isolation.
Binary inspection To determine the cost of ERIM’s bi-
nary inspection, we measured the cost of scanning the bina-
ries of all 18 applications in the CINT/FLOAT SPEC 2006
CPU benchmark. These range in size from 9 to 3918 4KB
pages, contain between 35 and 63765 intentional WRPKRU
instructions when compiled with CPI (see Section 6.4), no
unintended WRPKRU and no XRSTOR instructions. The
overhead is largely independent of the number of WRPKRU
instructions and ranges between 3.5 and 6.2 microseconds
per page. Even for the largest binary, the scan takes only
17.7ms, a tiny fraction of a typical process’ runtime.
6.2 Protecting session keys in NGINX
Next, we use ERIM to isolate SSL session keys in a high
performance web server, NGINX. We conﬁgured NGINX to
use only the ECDHE-RSA-AES128-GCM-SHA256 cipher
and AES encryption for sessions. We modiﬁed OpenSSL’s
libcrypto to isolate all session keys and the functions for AES
key allocation and encryption/decryption into ERIM’s T, and
use ERIM call gates to invoke these functions.
To measure ERIM’s overhead on the peak throughput, we
conﬁgure a single NGINX worker pinned to a CPU core,
and connect to it remotely over HTTPS with keep-alive from
4 concurrent ApacheBench (ab) [3] instances each simulat-
ing 75 concurrent clients. The clients all request the same
ﬁle, whose size we vary from 0 to 128KB across experi-
USENIX Association
28th USENIX Security Symposium    1231
File
size
(KB)
0
1
2
4
8
1 worker
3 workers
5 workers
10 workers
Native
(req/s)
95,761
87,022
82,137
76,562
67,855
ERIM
rel. (%)
95.8
95.2
95.4
95.3
96.0
Native
(req/s)
276,736
250,565
235,820
217,602
142,680
ERIM
rel. (%)
96.1
94.5
95.1
94.9