0.98
0.98
0.97
0.97
0.98
0.98
1
0.97
1
1
0.99
0.97
0.97
0.94
0.97
0
0
0
0
0
Table 2: The results for Generalized and Scenario-
speciﬁc models. Each column shows average (Avg)
and standard deviation (S.D.) for F-Measure, Re-
call and Precision for tapping duration of one sec-
ond. Precision captures the security of the system
while recall captures the usability of the system. F-
measure accounts for both precision and recall.
F-Measure
Avg (S.D.)
Recall
Precision
Avg (S.D.) Avg (S.D.)
Generalized
Chest-Angular
Waist-Flat
Chest-Vertical
Waist-Angular
0.93 (0.05)
0.89 (0.06)
0.91 (0.06)
0.92 (0.07)
0.91 (0.06)
0.97 (0.03)
0.92 (0.06)
0.95 (0.05)
0.94 (0.05)
0.95 (0.04)
0.91 (0.08)
0.87 (0.07)
0.88 (0.07)
0.89 (0.09)
0.88 (0.08)
120 in the general model). However, both models seem to
perform about equally well in detecting the tap biometrics.
6.3 Summary of Results
The results obtained from both the classiﬁcation models
show that the tap gesture can be detected in a robust manner
and thus will serve as an eﬀective method for authenticating
the users of NFC devices. This is reﬂected in high precision,
recall and F-measure for both models. The general model
can be used in applications where the user can train the
model with tapping gestures in diﬀerent scenarios (reader
positions). The scenario-speciﬁc model can be used in prac-
tice when the phone can acquire the knowledge about the
reader position. This knowledge can be acquired either by
asking the user about the reader position, although this will
require some user involvement in the authentication process,
or the terminal can send its position to the phone.
6.4 Power Analysis
Since our app records sensor values, we set forth to analyze
if our system is lightweight. To measure the battery power
consumption, we used P owerT utor [50]. P owerT utor is
an app readily available on on Google PlayStore2 which es-
timates the power/energy consumed by diﬀerent apps in-
stalled on the phone. The app provides the power/energy
consumed by apps based on various parameters such as screen
brightness, CPU usage, Wi-Fi polling and so on. We com-
2https://play.google.com/store/apps/details?id=edu.
umich.PowerTutor
pared the energy consumed by our app with N F Ctools3,
one of the most popular apps for NFC in Google PlayStore.
We logged the energy consumption for both apps accounting
for CPU usage only.
We ran P owerT utor app to monitor the power consump-
tion of all the apps on the phone. Then, we performed 20
taps with our app against the NFC reader, and then we
performed 20 taps with N F Ctools against an NFC tag. We
observed that our app consumes 0.2 J of energy per tap com-
pared to 0.13 J of energy per tap by N F Ctools. This shows
that our system is lightweight as it only uses an additional
0.07 J of energy for the sensor recordings.
7. ACTIVE ADVERSARIAL ATTACKS
From the analysis presented in Section 6, we can see that
our approach is robust and can authenticate users with a
high accuracy. That is, the approach can be eﬀectively used
to diﬀerentiate one user from the other. However, it is possi-
ble that the attacker may deliberately attempt to mimic the
tapping gesture exhibited by a victim user. In this section,
we assess our tap biometrics system against such an active
adversary.
If the attacker tries to authenticate himself as the victim
user, he has to move his hand in such a way that his hand
motion as sensed by diﬀerent sensors correlates signiﬁcantly
with the tapping gesture exhibited by the legitimate user.
Even when the attacker observes how the user taps, it may
still be diﬃcult for the attacker to reproduce the tapping
gesture as our gesture is sensed by multiple sensors and all
of the sensor values should match with the user’s template.
Mimicking multiple sensor events simultaneously would be
harder for the attacker and so our approach should provide
better resistance to active attacks compared to systems that
use single or fewer sensors. While robotic attacks have been
reported against other authentication systems (such as the
one developed in [38], such attacks will not apply to our
system since authentication is to be performed by a real
human user in the presence of retail personnel and using a
robot to make a purchase at the terminal would clearly raise
a suspicion.
We proceeded to evaluate the robustness of our system
against human-based observation and active adversarial at-
tacks. For our evaluation, we designed an active attack that
aimed at maximizing the attacker capabilities in defeating
3https://play.google.com/store/apps/details?id=com.
wakdev.wdnfc
272
our system. If our system could defeat this attacker, it could
also defeat other weaker attackers. To this end, we asked one
of our users to serve the role of the victim while a researcher
served the role of an expert attacker. The victim and the
attacker had similar body structures, i.e., their height and
weight were similar, which would have facilitated the at-
tacker to better mimic the victim’s tapping gesture. We
asked the victim user to perform his tapping for 30 times
in each of the four reader orientation scenarios while the at-
tacker recorded a clear video of him tapping. After the total
120 taps were collected from the victim, we built the classi-
ﬁer for this user following the procedure described in Section
6. The attacker then closely watched the previously recorded
video and practiced to re-create the victim’s tapping gesture
against a dummy reader several times while receiving a feed-
back from his friend (a colluding attacker). This simulated
the attacker’s training phase performed at home (i.e., not
at the retail store in the presence of the authentication ter-
minal/reader). Finally, during the actual attack phase, the
attacker performed 20 taps and each of these taps was tested
against the victim’s classiﬁer built earlier.
The success rate of this active attacker against our authen-
tication systems is shown in Table 3. From these results, we
can claim that even when an attacker practices and mimics
the hand motion of the victim, he cannot succeed. Also, we
can claim that we have a strong attacker as the attacker is
fully trained watching the victim’s tap video recording and
getting feedback from a colluding attacker. Moreover, the
victim we chose matched the body structure of the attacker
which may further facilitate the attack. Since our system
can defeat such strong attacker, it can, therefore, defeat at-
tacks in other scenarios where the victim’s structure is dif-
ferent from the attacker’s and/or where the attacker cannot
fully observe the victim and train.
8. DISCUSSION
8.1 Defeating Unauthorized NFC Reading
In our approach, the NFC transaction will not be pro-
cessed until the user is authenticated. Hence, our approach
can serve as a defense mechanism to unauthorized reading
of NFC information as well as relay attacks [34, 35] where an
unauthorized reader in close physical proximity of the phone
tries to leech the NFC information and perform fraudulent
transaction.
8.2 Dealing with Authentication Errors
Our system is robust and has very low error rates as shown
in the Section 6. However, our machine learning approach
learns from the data that user has provided during the train-
ing phase. If the user trains the classiﬁer with tap gestures
from one hand and later taps using the other hand, the sys-
tem may fail to authenticate the legitimate user. Such cases
can be avoided by either training the classiﬁer with both
hands or user switching back to correct hand while tapping.
Further study would be needed to analyze the handedness
of the users and their tapping behavior.
In situations where an authentication error (false nega-
tive) occurs,
i.e., when the legitimate user is denied the
transaction, we may need a fallback approach. In the tra-
ditional payment approach, for example, when the access is
denied once due to an error, the user has to swipe the card
again. We can follow the same model by requesting the user
to tap the phone again to the NFC transaction terminal. If
this process fails again, the device may not belong to the user
and the transaction can be blocked. As a fallback strategy,
the user may be authenticated using PINs or ﬁngerprints.
8.3 Power Efﬁciency
One of the design goals of our system is to be light-weight
as high power consumption may reduce the usability of the
system. Since the authentication procedure in our approach
lasts for no more than few seconds, our approach is quite
power eﬃcient and light-weight as shown in Section 6.4. The
sensors are activated as soon as the NFC transaction app is
turned on and are deactivated as soon as the corresponding
NFC message is received. Only those sensor data which falls
within the considered time window (up to 3 seconds in our
case) will be used by the classiﬁer to make the authentication
decision. The detection approach itself is very lightweight
and requires negligible amount of power.
8.4 User Transparency
Our approach is triggered as soon as the app, which needs
to process the NFC transaction, is turned on. The sensor
data is recorded from the start of that app to the point when
either the user has been authenticated or denied. This entire
process of authentication is transparent to the legitimate
user. This property satisﬁes one of our design goals of being
transparent and having a consistent usage model to existing
NFC usage.
9. RELATED WORK
There exists prior work that aims at improving security
based on sensors and sensor data. In this section, we review
some of this prior work relevant to our paper that utilizes
on-board sensors to improve the security of authentication
and authorization.
Shrestha et al. [41] proposed authorizing an app utilizing
hand movement of the user for calling, snapping, and NFC
tapping. In their work, the system tries to identify a cor-
responding gesture as calling, snapping or tapping when an
app requests for a permission to access these sensitive re-
sources. They use machine learning classiﬁers utilizing dif-
ferent sensors to identify if the hand motion matches with
the corresponding gesture. In contrast to this work, we use
hand motion as a biometric measure to authenticate the
users while they use the motion to distinguish the call, snap
or tap gesture with other gestures. Their work aims at pre-
venting against malware which is trying to access the sensi-
tive services without user awareness, but it cannot protect
in case of theft or device misuse by other users, which is
what our work is geared towards.
The work by Conti et al.
[10] is well-aligned with ours.
They authenticate users by analyzing the hand movements
while making/answering phone calls. They investigated if
such motion can be used as biometric authentication mea-
sure. They have used Dynamic Time Warping (DTW) algo-
rithm to analyze and detect the gesture of making/answering
phone calls in contrast to our approach where we use ma-
chine learning classiﬁers to identify if the tapping gesture
is performed by the owner. They have only considered ac-
celerometer and orientation sensors while our approach con-
siders ten diﬀerent sensors including not only motion and
position sensors but also environment sensor (ambient pres-
sure) for better accuracy. Although our approach may be
273
used to authenticate the users while making/answering the
phone calls as well, we focus on tap gesture biometrics, es-
pecially when user wants to make transaction with an NFC-
enabled device.
Hong et al. [19] propose Waving Authentication (WA), a
biometric authentication based on waving hand along with
the phone. WA utilizes accelerometer sensor to extract 8
features, train SVM classiﬁers to build a model and authen-
ticate users with this model. However, this approach is not
transparent to the user, unlike our method.
Gascon et al. [17] have analyzed typing motion behaviour
of the user to continuously authenticate a user on smart-
phones.
It records the touch input along with the times-
tamps when the keys are pressed or released. They use
diﬀerent sensors such as accelerometer, gyroscope, and ori-
entation sensors and extract 2376 dimensional vector repre-
senting the typing motion behaviour of the user. They use
linear Support Vector Machine (SVM) classiﬁer to identify
if the typing motion belongs to user or not. Other work
[11, 16, 36, 40] share the similar philosophy to authenticate
users based on the touch gesture. They either use only the
touch sensor or use the touch sensor in conjunction with
diﬀerent inertial sensors.
Some of the other work that focus on behavioral biometric
measure to authenticate users, include, but not limited to
the voice pattern recognition [27, 49], the walking pattern
[12, 26], and the tapping pattern [5, 28, 46]. To authenti-
cate with the voice pattern or the tapping pattern on touch
screen requires users to perform extra action while authen-
ticating themselves. Although these are biometric measures
to authenticate users, these are not transparent when a user
is trying to make an NFC transaction with the phone and,
hence, adds extra burden to users.
10. CONCLUSION AND FUTURE WORK
In this paper, we presented an approach to authenticate a
user transparently before making an NFC transaction. The
approach captures the user’s hand movement and identiﬁes
the user based on the sensor data recorded by the device.
The gesture is very unique to the user and is diﬃcult for
the attacker to mimic. We presented the design and im-
plementation of the proposed authentication approach. Our
results suggest that our approach could be very eﬀective in
authenticating users and preventing misuse of NFC services
in case of theft or loss of NFC phone, without necessitating
any additional user burden.
Our future eﬀort will be focused on exploring new fea-
tures from the available sensors as well as utilizing new sen-
sors as they are introduced by the phone manufacturers and
the operating systems. We also plan to further evaluate
our approach with diﬀerent smartphone models and a wider
range of users. Moreover, to further improve the authentica-
tion accuracy, we plan to use a smartwatch (when available)
along with the smartphone for detecting the tapping ges-
ture from the user. Using multiple devices may provide a
broader range of features (e.g., wrist movements and hand
movements) which may increase the accuracy of the system
and further reduce the chances for the attacker to mimic the
gesture.
Acknowledgments
We would like to thank ACSAC 2016 anonymous reviewers
for their useful feedback. We would also like to thank all
of our participants at UAB and Aalto university for partic-
ipating in our biometrics study. This work has been funded
by NSF CNS-1526524 grant.
References
[1] A. Adams and M. A. Sasse. Users are not the enemy.
Commun. ACM, 42(12), 1999.
[2] Android. Android ˆa ˘A¸S android pay. Available online
at https://www.android.com/pay/.
[3] Apple. Apple pay - apple. Available online at
http://www.apple.com/apple-pay/.
[4] ARM. ARM Security Technology Building a Secure
System using TrustZone Technology. Technical report,
April 2009.
[5] S. Azenkot, K. Rector, R. Ladner, and J. Wobbrock.
Passchords: secure multi-touch authentication for blind
people. In Proceedings of the 14th international ACM
SIGACCESS conference on Computers and accessibil-
ity, pages 159–166. ACM, 2012.