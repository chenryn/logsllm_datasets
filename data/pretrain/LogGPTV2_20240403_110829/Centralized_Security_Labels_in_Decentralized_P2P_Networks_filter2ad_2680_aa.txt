title:Centralized Security Labels in Decentralized P2P Networks
author:Nathalie Tsybulnik and
Kevin W. Hamlen and
Bhavani M. Thuraisingham
23rd Annual Computer Security Applications Conference
23rd Annual Computer Security Applications Conference
Centralized Security Labels in Decentralized P2P Networks
Nathalie Tsybulnik, Kevin W. Hamlen and Bhavani Thuraisingham
Department of Computer Science
University of Texas at Dallas
Richardson TX 75080, USA
PI:EMAIL, {hamlen, bhavani.thuraisingham}@utdallas.edu
Abstract
This paper describes the design of a peer-to-peer net-
work that supports integrity and conﬁdentiality labeling of
shared data. A notion of data ownership privacy is also
enforced, whereby peers can share data without revealing
which data they own. Security labels are global but the
implementation does not require a centralized label server.
The network employs a reputation-based trust management
system to assess and update data labels, and to store and
retrieve labels safely in the presence of malicious peers.
The security labeling scheme preserves the efﬁciency of net-
work operations; lookup cost including label retrieval is
O(log N), where N is the number of agents in the network.
1. Introduction
Ever since Napster [1] was introduced, peer-to-peer
(P2P) systems have become a ubiquitous technology for
data dissemination. Napster focused exclusively on music
exchange, but later more general-purpose systems followed,
including Gnutella [2], KaZaA [3], LimeWire [4], and many
others. Such P2P systems have enjoyed great success in
numerous application domains because they offer load bal-
ancing of computational resources, redundant storage, data
permanence, and low-cost deployment.
However, existing P2P systems offer relatively few se-
curity guarantees to users. Data shared over these networks
has low conﬁdentiality because it might potentially be di-
vulged to any peer, and it has low integrity because peers
can lie about the content of the data they serve. For ex-
ample, malicious peers can easily propagate (low-integrity)
malicious code over today’s P2P networks by publishing it
under a misleading name. Recent studies [5, 6] have con-
cluded that at as much as 68% of all executable content in
KaZaA and 15% of all ﬁles exchanged over LimeWire con-
tain malware.
These P2P network implementations also offer only
weak privacy guarantees. Malicious peers can with low
overhead generate a list of all data served by any given peer,
and can generate a list of all peers that serve any partic-
ular item of data. These drawbacks make traditional P2P
network implementations unsuitable for venues where pri-
vacy, data conﬁdentiality, and data integrity are important
to users.
In order to address these deﬁciencies, we have developed
Penny, a P2P network in which data objects are augmented
with reputations in the form of conﬁdentiality and integrity
labels. These reputations provide peers a basis for decid-
ing whether or not to serve or download data. For example,
data with a low integrity label is more likely to contain a
virus or corrupted content, so peers might avoid download-
ing it. Dually, peers might refuse to serve data with a high
conﬁdentiality label to peers that they do not trust. To help
peers evaluate the trustworthiness of other peers, Penny in-
cludes a reputation-based trust management system based
on EigenTrust [7]. Penny also allows peers to withhold ob-
ject ownership information from other peers in the network,
allowing them to publish data anonymously.
Object and peer reputations are centralized in Penny such
that each reputation is a function of the individual opin-
ions of all peers. However, these centralized reputations
are stored in a decentralized fashion such that the computa-
tional expense of tracking and communicating global repu-
tations is spread roughly evenly across all peers in the net-
work. In particular, for each object or peer, Penny assigns
k peers to track its global reputation, where k is a constant
chosen at network initialization. For a malicious collective
to subvert the reputation, at least k/2 of these peers must
be members of the collective. Since Penny peers cannot
choose which reputations they are assigned to track, this
makes it difﬁcult for a malicious collective to subvert a rep-
utation unless the collective is large relative to the size of
the network.
We are currently implementing Penny client software in
Java, and our early prototyping has signiﬁcantly inﬂuenced
1063-9527/07 $25.00 © 2007 IEEE
1063-9527/07 $25.00 © 2007 IEEE
DOI 10.1109/ACSAC.2007.13
DOI 10.1109/ACSAC.2007.13
315
315
the network design presented in this paper. Penny clients
function like typical P2P clients except that the list of ob-
jects displayed to the user in response to a query is aug-
mented with a global integrity and conﬁdentiality label for
each object, and the list of servers that offer each object is
augmented with a global trust value for each server. Users
can choose which object to download (if any) based on its
integrity label, and can choose which server to download it
from based on the server’s trust value. They can also choose
whether to serve an object to a particular requester based
on the object’s conﬁdentiality label and the requester’s trust
value. Peers can provide feedback after each transaction,
which inﬂuences the labels and trust values reported for fu-
ture queries submitted to the network.
In the analysis of our system, we consider four classes of
attacks:
• A malicious peer or collective might spread corrupt or
incorrect data. For example, the malicious peer or col-
lective might spread malicious code or circulate false
facts.
• A malicious peer or collective might attach incorrect
security labels to data.
In particular, low-integrity
data might be assigned a high-integrity label, or
high-conﬁdentiality data might be assigned a low-
conﬁdentiality label.
• A malicious peer or collective might attempt to learn
which peers own certain data, perhaps as a prelude to
staging additional attacks against those peers.
• A malicious peer or collective might attempt to gener-
ate a list of all data served by a particular peer, violat-
ing that peer’s privacy.
We do not consider attacks upon the network overlay it-
self, such as message misrouting, message tampering, or
denial of service attacks. These attacks are beyond the
scope of this paper, but could be addressed with various
techniques, such as digital signatures, delivery receipts, and
non-deterministic routing. In addition, security labels in our
system are treated as advice to peers rather than enforced se-
curity policies. That is, we do not enforce the requirement
that high-trust peers never obtain low-integrity data, or that
low-trust peers never obtain high-conﬁdentiality data. En-
forcing such policies using our labeling scheme is the sub-
ject of future work.
The organization of this paper is as follows. Related
work is discussed in §2. An overview of Penny’s design
is provided in §3. In §4, the Penny algorithm is deﬁned in
detail, and we discuss security properties enforced by the
design in §5. The paper is summarized with directions for
future work in §6.
2. Related Work
P2PRep [8] implements integrity labels and reputation-
based trust management for the Gnutella [2] P2P network.
Integrity labels and trust values are acquired in P2PRep by
polling a large number of peers using broadcast messages.
Poll responses are then aggregated by the requesting peer
to estimate the desired integrity label or trust value (along
with trust values for all peers whose opinions were acquired
by polling). This strategy has the advantage of being imple-
mentable atop the existing Gnutella network protocol, but
it has the disadvantage that labels and trust values are not
global and are not guaranteed to converge. That is, the in-
tegrity label or trust value obtained will depend on which
agents were polled, which in turn depends upon the poller’s
placement within the P2P network. Two peers at different
locations in the network might therefore consistently derive
different reputations for the same resource. Broadcast mes-
sages can also be expensive, requiring O(bd) messages to
be sent, where b is the branching factor of the network and
d is a time to live parameter dictating the maximum depth
of the tree of peers being polled.
Penny’s algorithm for efﬁciently circulating data is based
on the Chord algorithm [9]. Chord assigns an identiﬁer to
each peer, and arranges peers in a ring structure sorted by
identiﬁer. Each peer maintains a ﬁnger table of size m,
where 2m is the size of the identiﬁer space. This enables
peers to locate and contact the peer with a given identiﬁer in
O(log N) message hops, where N is the number of agents
in the network. Each shared data object also has a single
key-holder peer, who is charged with directing requesters
of that object to peers that own it. To request an object, a
peer can locate its key-holder in O(log N) message hops,
whereupon the key-holder responds with a list of servers
from which the object can be downloaded.
Alternatives to Chord include CAN [10], Pastry [11], and
Tapestry [12]. These systems offer distributed, scalable, and
efﬁcient search systems for P2P networks; however, they
do not include data security or privacy enforcement mecha-
nisms. Our work extends Chord by providing a framework
for maintaining centralized security labels for data shared
over a Chord network.
Trust management systems are a useful tool for identify-
ing warning signs for potential malicious behavior. Such
systems typically assign trust levels to principals as var-
ious actions appear in the system.
In this way they pre-
dict future behavior based on the past experiences of other
users. There are three major types of trust management
systems. Reputation-based systems use knowledge of a
peer’s reputation (gathered through personal or indirect ex-
perience) to determine the trustworthiness of another peer.
Some examples of reputation-based trust management sys-
tems are EigenTrust [7], DMRep [13], P2PRep/XRep [8],
316316
Sporas and Histos [14], PeerTrust [15], NICE [16], and
DCRC/CORC [17]. In contrast, policy-based trust manage-
ment systems, such as PolicyMaker [18], derive a trust level
for each peer based on supplied credentials. Finally, trust
management systems based on social networks determine
trust by analyzing a complex social network. Of this type,
Marsh [19] was one of the ﬁrst to formally express trust
from a sociological and psychological perspective. Some
other examples of social network systems are Regret [20]
and NodeRanking [21].
Penny incorporates a reputation-based trust management
system based on EigenTrust [7]. EigenTrust is a secure, dis-
tributed trust management system that maintains a global-
ized trust value for each peer. These globalized trust values
are obtained by an iterative computation that approximates
the left eigenvector v of the matrix T of all local trust values
in the network. That is, if we deﬁne element Tij to be the
degree to which peer ai trusts peer aj, then the left eigen-
vector v of matrix T measures each peer a’s global trust
based on how much each peer trusts a, how much each peer
trusts the peers who trust a, etc.
To keep the algorithm scalable and robust, eigenvector v
is computed in a distributed and redundant fashion, where
k different peers are responsible for computing each ele-
ment of v. Whenever peers ai and aj are involved in a
transaction, they report feedback to the peers responsible
for computing eigenvector elements vi and vj. These peers
are referred to as score-managers for agents ai and aj be-
cause elements vi and vj are the global trust values of peers
ai and aj, respectively. Score-managers for a given peer
are determined via a family of k hash functions applied to
the peer’s identiﬁer. Thus, acquiring a peer’s trust value re-
quires O(k log N) messages in an EigenTrust system built
atop Chord. Penny improves upon this performance. In §3.2
we show that using the Penny protocol trust values can be
retrieved using only O(log N + k) messages.
Penny peers desiring conﬁdentiality must send some
messages anonymously to other peers. Anonymizing tun-
nels are a powerful
technology for accomplishing this
within peer-to-peer networks. Penny therefore supports
the Tarzan system [22, 23], which implements anonymiz-
ing tunnels for Chord networks. In Tarzan, a peer desiring
anonymity routes its messages through a tunnel of randomly
chosen peers. Multilayer encryption and randomly gener-
ated cover trafﬁc are used to prevent any peer in the tunnel
from learning whether its successor is the message origina-
tor or just another hop in the tunnel. Tarzan tunnels are bidi-
rectional, allowing recipients of anonymous messages to re-
ply without knowing the identity of the message originator.
The approach has proved to be both ﬂexible and scalable,
requiring little overhead above that incurred by Chord’s ex-
isting message-routing protocol.
3. System Overview
In this section, we provide a high-level overview of the
structure of a Penny network, beginning with deﬁnitions of
important concepts. Details of the algorithm are presented
in §4.
3.1. Deﬁnitions
Agents. We refer to the peers in a P2P network as agents.
Each agent a is assigned an identiﬁer id a by applying a
one-way, deterministic hash function to its IP address and
port number. We assume that identiﬁers are unique and that
agents cannot inﬂuence which identiﬁer they are assigned.
An agent’s identiﬁer determines its position in the network’s
ring structure. When agents are arranged in a ring, each
agent has a predecessor pred(a) and a successor succ(a).
We refer to the interval [id a, id succ(a) − 1] as the identiﬁer
range of agent a.
Objects and keys. An object o is an atomic item of data
(e.g., a ﬁle) shared over a P2P network. Each object also
has a unique identiﬁer id o (e.g., a ﬁle name). Objects can
be owned by multiple agents. A single key is associated
with each object and each agent. The keys for object o and
agent a are deﬁned by key o := h(id o) and key a := h(id a)
respectively, where h is a one-way, deterministic hash func-
tion over the domain of identiﬁers.
Local conﬁdentiality and integrity labels. Each object
o is labeled with a measure of its integrity and conﬁdential-
ity levels. We denote the integrity and conﬁdentiality labels
assigned to object o by agent a as ia(o) and ca(o), respec-
tively. Integrity labels measure data quality; conﬁdentiality
labels measure who should be permitted to own the data.
In Penny, conﬁdentiality and integrity labels are modeled as
real numbers from 0 to 1 inclusive, with 0 denoting lowest
conﬁdentiality and integrity and 1 denoting highest conﬁ-
dentiality and integrity.
Local trust values. Trust measures the belief that one
agent has that another agent will behave as expected or
promised. Each ordered pair of agents (a1, a2) has a lo-
cal trust value denoted ta1(a2) that measures the degree to
which agent a1 trusts agent a2. Like conﬁdentiality and
integrity labels, trust values range from 0 to 1 inclusive.
EigenTrust [7] is an example of a trust management system
that employs trust values normalized to this range.
Key-holders and score-managers. Each agent a1 in the
Penny network is assigned a (not necessarily unique) key
range, denoted kr(a1). Agent a1 is charged with tracking
317317
the integrity and conﬁdentiality labels assigned to all ob-
jects o that satisfy key o ∈ kr(a1). In addition, agent a1
tracks the trust values assigned to all agents a2 satisfying
key a2 ∈ kr(a1). Whenever key o ∈ kr(a1) holds, we refer
to agent a1 as a key-holder for object o, and we refer to ob-
ject o as a daughter object of agent a1. Likewise, whenever
key a2 ∈ kr(a1) holds we refer to a1 as a score-manager
for agent a2, and we refer to agent a2 as a daughter agent
of agent a1. Every peer in a Penny network acts as both a
key-holder for some objects and a score-manager for some
peers.
Global labels and trust values. Key-holders with a com-
mon key-range use the local integrity and conﬁdentiality
labels reported to them by other agents in the network to
collectively compute global integrity and conﬁdentiality la-
bels, denoted io and co respectively, for objects o whose
keys fall within that range. Similarly, score-managers with
a common key-range collectively compute global trust val-
ues, denoted ta, for agents a whose keys fall within that
range. Speciﬁcally, io, co, and ta are deﬁned by
io := median{iakh (o)| key o ∈ kr(akh)}
co := median{cakh (o)| key o ∈ kr(akh)}
ta := median{tasm (o)| key a ∈ kr(asm)}
(1)
(2)
(3)
Thus, any agent in the network can compute a global la-
bel for any object o or global trust value for any agent a
by contacting all key-holders akh for object o, or all score-
managers asm for agent a.
3.2. Network Design
A Penny ring is like a Chord ring, with Penny’s iden-
tiﬁer ranges being equal to Chord’s key-ranges. However,
a Penny agent’s key-range strictly subsumes its identiﬁer
range, and agent key-ranges are not unique. Key-ranges
are assigned in a Penny ring so that for every agent a,
there are between k and 2k agents in the ring whose key-
ranges are equal to kr(a) (unless the entire network in-
cludes less than k total agents), where k is a ﬁxed constant
deﬁned at network initialization. Bounding the number of