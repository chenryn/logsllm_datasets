Type 
Signature Method 
- Bytes 
-DLLsused 
- DLL function calls 
- DLLs with 
counted function calls 
Naive Bayes 
I  - Strines 
~ Multi-Naive Bayes 
- Bytes 
!:  1 
1102 
True 
True 
i$ 
1000 
3176 
3191 
960 
940 
Positives (TP) 
Negatives (TN) 
Positives (FP)  Negatives (FN) 
Rate 
False 
False 
Detection  False Positive 
0 
19 
16 
11 
41 
61 
2163 
16 
11 
18 
89 
74 
Rate 
I  33.75% 
I 
57.89% 
71.05% 
0% 
9.22% 
7.77% 
83.62% 
89.36% 
52.63% 
5.34% 
97.43% 
3.80% 
97.76% 
6.01 % 
96.88% 
Table 3:  These are the results of classifying new malicious programs organized by  algorithm and feature.  Multi-Naive 
Bayes using Bytes had the highest Detection Rate, and Signature Method with strings had  the lowest False Positive Rate. 
Highest overall accuracy was the Naive Bayes algorithm with strings.  Note that the detection rate for the signature-based 
methods are lower than the data mining methods. 
7.4  Multi-Naive Bayes 
The Multi-Naive Bayes algorithm using bytes as features 
had the highest detection rate out of any method we tested, 
97.76%.  The false positive rate at 6.01% was higher than 
the Naive Bayes methods (3.80%) and the signature meth- 
ods (< 1%). 
The ROC curves in Figure 8 show a slower growth than 
the Naive Bayes with strings method until the false positive 
rate climbed above 4%.  Then the two algorithms converged 
for false positive rates greater than 6% with a detection rate 
greater than 95%. 
7.5  Same Model, Different Applications 
The ROC curves in  Figures  7  and  8 also let  security ex- 
peas understand how to tailor this framework to their spe- 
cific  needs.  For example, in  a  secure computing setting, 
it  may  be  more  important  to  have  a  high  detection  rate 
of 98.7970, in  which case the false positive rate would in- 
crease to 8.87%. Or if the framework were to be integrated 
into a mail server, it may be more important to have a low 
false positive rate below 1 Yo (0.39% FP rate in our case) and 
a detection rate of 65.62% for new malicious programs. 
8  ‘Defeating Detection Models 
Although these methods can detect new malicious executa- 
bles, a malicious executable author could bypass detection 
if the detection model were to be compromised. 
First, to defeat  the signature-based method  requires re- 
moving  all  malicious  signatures  from  the  binary.  Since 
these are typically a subset of a malicious executable’s total 
data, changing the signature of a binary would be possible 
although difficult. 
Defeating  the  models  generated  by  RIPPER  would  re- 
quire generating functions that would change the resource 
usage. These functions do not have to be called by  the bi- 
nary  but  would  change the  resource signature  of  an  exe- 
cutable. 
To defeat  our implementation  of  the Naive Bayes clas- 
sifier  it  would  be  necessary  to  change a  significant num- 
ber of features in  the example.  One way  this can be done 
is through encryption, but encryption will add overhead to 
small malicious executables. 
We corrected  the problem  of authors evading a strings- 
based rule set by initially classifying each example as ma- 
licious.  If  no strings that were contained in the binary had 
ever been  used  for training  then  the final class was mali- 
cious.  If there were  strings contained  in the program that 
the  algorithm had  seen before  then  the probabilities  were 
computed normally according to the Naive Bayes rule from 
Section 4.3.  This took care of  the instance where a binary 
had encrypted strings, or had changed all of its strings. 
The Multi-Naive Bayes method  improved  on  these re- 
sults because changing every line of byte code in the Naive 
Bayes  detection model  would  be  an  even  more  difficult 
proposition  than  changing all  the  strings.  Changing this 
many of the lines in a program would change the binary’s 
behavior significantly. Removing all lines of code that ap- 
pear in  our model would be difficult and time consuming, 
and even  then  if  none of  the byte sequences in  the exam- 
ple had been  used for training then the example would  be 
initially classified as malicious. 
The Multi-Naive Bayes is a more secure model of detec- 
tion  than  any  of  the  other methods discussed  in  this  pa- 
per  because  we  evaluate a  binary’s  entire  instruction  set 
whereas signature methods looks for segments of byte se- 
quences.  It  is much easier for malicious program  authors 
to modify the lines of code that a signature represents than 
to change all the  lines contained  in  the program  to evade 
a Naive Bayes or Multi-Naive Bayes model.  The byte se- 
quence model is the most secure model we devised in our 
test. 
47 
A further security concern is what  happens when mali- 
cious software writers obtain copies of the malicious bina- 
ries that we could not detect, and use  these false negatives 
to generate new malicious software. Presumably this would 
allow them to circumvent our detection models, but in fact 
having  a  larger set of similar false negatives would make 
our model more accurate. In other words, if malicious bi- 
nary  authors clone the  undetectable binaries,  they  are in 
effect making it  easier for  this  framework to detect  their 
programs. The more data that the method analyzes, and the 
more false positives and false negatives that  it learns from, 
the  more  accurate the  method  becomes  at  distinguishing 
between benign and malicious programs. 
copies of itself out over the network, eventually most users 
of  the LAN will  clog the  network  by  sending each other 
copies of the same malicious executable. This is very simi- 
lar to the old Internet Worm  attack. Stopping the malicious 
executables from  replicating on a network level  would  be 
very advantageous. 
Since  both  the  Naive  Bayes  and  Multi-Naive  Bayes 
methods are probabilistic we can also tell if a binary is bor- 
derline. A borderline binary is a program that has similar 
probabilities for both classes (i.e., could be a malicious ex- 
ecutable or a benign program). If it is a borderline case we 
have an  option in  the network filter to send a copy of the 
malicious executable to a central repository such as CERT. 
There, it can be examined by human experts. 
9  Conclusions 
The first contribution that we presented in this paper was a 
method for detecting previously undetectable malicious ex- 
ecutables.  We showed this by  comparing our results with 
traditional signature-based methods and with other learning 
algorithms.  The Multi-Naive Bayes method  had the high- 
est  accuracy and detection rate  of any algorithm over un- 
known programs, 97.76%, over double the detection rates 
of signature-based methods. Its rule set was also more dif- 
ficult to defeat than other methods because all lines of ma- 
chine  instructions would have to be changed to avoid de- 
tection. 
The  first  problem  with  traditional  anti-malicious  exe- 
cutable detection methods is that  in order to detect a new 
malicious executable, the program  needs  to be examined 
and a signature extracted from it and included in the anti- 
malicious executable software database. The difficulty with 
this method is that during the time required for a malicious 
program to be identified, analyzed and signatures to be dis- 
tributed, systems are at risk from that program. Our meth- 
ods may  provide a  defense during that  time.  With  a  low 
false positive rate, the inconvenience to the end user would 
be minimal while providing ample defense during the time 
before an update of models is available. 
Virus Scanners are updated about every month. 240-300 
new  malicious executables are created  in  that  time  (8-10 
a day [27]).  Our method would catch roughly 216-270  of 
those  new  malicious executables  without the  need  for  an 
update whereas traditional methods would catch only  87- 
109.  Our method more than  doubles the detection  rate of 
signature based methods for new malicious binaries. 
The methods discussed  in  this  paper  are being  imple- 
mented as a  network mail  filter.  We  are  implementing a 
network-level email filter that uses our algorithms to catch 
malicious  executables before  users  receive  them  through 
their mail.  We can either wrap the potential malicious ex- 
ecutable or we can block it.  This has the potential  to stop 
some malicious executables in the network and prevent De- 
nial of Service (DOS) attacks by malicious executables. If a 
malicious binary accesses a user’s address book and mails 
9.1  Future Work 
Future work involves extending our learning algorithms to 
better  utilize  byte-sequences.  Currently,  the Multi-Naive 
Bayes  method  learns  over  sequences  of  a  fixed  length, 
but  we theorize that rules with higher accuracy and detec- 
tion rates could be learned over variable length sequences. 
There are some algorithms such as Sparse Markov Trans- 
ducers [7] that can determine how long a sequence of bytes 
should be for optimal classification. 
We are planning to implement the system on a network 
of computers to evaluate its performance in terms of  time 
and accuracy in  real  world environments. We also would 
like to make the learning algorithms more efficient in time 
and space. Currently, the Naive Bayes methods have to be 
run on a computer with one gigabyte of RAM. 
Finally,  we  are planning on  testing this  method over a 
larger set of malicious and benign executables. Only when 
testing over a significantly larger set of malicious executa- 
bles can we  fully  evaluate the method.  In  that  light,  our 
current results  are preliminary.  In  addition  with  a  larger 
data set, we plan to evaluate this method on different types 
of malicious executables such as macros and Visual Basic 
scripts. 
References 
William  Arnold  and Gerald Tesauro.  Automatically 
Generated  Win32  Heuristic Virus  Detection.  Pro- 
ceedings  of  the  2000  International  Virus  Bulletin 
Conference, 2000. 
Fred  Cohen.  A  Short  Course on  Computer  Viruses. 
ASP Press, 1990. 
William Cohen.  Learning Trees and Rules with Set- 
Valued Features.  American Association for ArtiJicial 
Intelligence ( A M I ) ,  1996. 
R.  Crawford,  P.  Kerchen,  K.  Levitt,  R.  Olsson, 
M. Archer. and M. Casillas.  Automated Assistance 
[ 181  Peter  Miller.  Hexdump.  Online publication,  2000. 
http://www.pcug.org.au/ millerp/hexdump.html. 
[ 191  MIT Lincoln Labs.  1999 DARPA intrusion detection 
evaluation. 
[20] Tom  Mitchell.  Machine  Learning.  McGraw  Hill, 
1997. 
[21]  Kamal Nigam, Andrew McCallum, Sebastian Thrun, 
and  Tom  Mitchell.  Learning  to  Classify  Text  from 
Labeled and Unlabled Documents. M I - 9 8 ,  1998. 
[22]  Wildlist  Organization.  Virus  descriptions of  viruses 
in the wild.  Online publication, 2000.  http://www.f- 
secure.com/virus-infolwild. html. 
[23]  REUTERS.  Microsoft Hack  Shows Companies Are 
Vulnerable. New York Times, October 29, 2000. 
[24] Eugene H. Spafford. The Internet worm program: an 
analysis.  Tech. Report CSD-TR-823,  1988. Depart- 
ment of Computer Science, Purdue University. 
[25]  Gerald  Tesauro, Jeffrey  0. Kephart,  and  Gregory B. 
Sorkin. Neural Networks for Computer Virus Recog- 
nition.  IEEE Expert, 11(4):5-6.  IEEE Computer So- 
ciety, August,  1996. 
[26]  Steve R. White.  Open  Problems  in  Computer Virus 
Research.  Virus Bulletin  Conference, 1998. 
[27]  Steve R. White, Morton Swimmer, Edward J. Pring, 
William  C.  Arnold,  David  M.  Chess,  and  John  E 
Anatomy  of  a  Commercial-Grade  Im- 
Morar. 
IBM  Research  White  Paper,  1999. 
mune  System. 
http://www.av.ibm.com/ScientificPapers/White/ 
Anatomy/anatomy. html. 
for  Detecting  Malicious  Code.  Proceedings  of  the 
6th lnternatiorial  Computer Virus and Security  Con- 
ference, 1993. 
[5]  Cygnus.  GNU Binutils Cygwin.  Online publication, 
1 999. http://sourceware.cygnus.com/cygwin. 
[6]  D.Michie, D.J.Spiegelhalter, and  C.C.TaylorD.  Ma- 
chine  learning  of rules and  trees. In Machine Learn- 
ing, Neural  and Statistical  Class$cation.  Ellis Hor- 
wood, 1994. 
[7]  Eleazar  Eskin,  William  Noble  Grundy,  and  Yoram 
Singer.  Protein  Family  Classification  using  Sparse 
Markov Transducers. Proceedings of the Eighth Inter- 
national Conference on Intelligent Systems for Molec- 
ular Biology, 2000. 
[8]  Dmitry Gryaznov. Scanners of the Year 2000: Heuris- 
tics.  Proceedings of the 5th International  Virus Bul- 
letin, 1999. 
[9]  Jeffrey  0. Kephart  and  William  C.  Arnold.  Auto- 
matic  Extraction  of Computer Virus Signatures.  4th 
Virus Bulletin  International  Conference,  pages  178- 
184, 1994. 
[IO]  P.  Kerchen,  R.  Lo,  J.  Crossley,  G.  Elkinbard,  and 
R.  Olsson.  Static  Analysis  Virus  Detection  Tools 
for  UNIX  Systems.  Proceedings  of  the  /3th  Na- 
tional  Computer  Security  Cotlference,  pages  350- 
365,1990. 
[ l l ]  Zou  KH,  Hall  WJ,  and  Shapiro D.  Smooth  non- 
parametric  ROC  curves  for  continuous  diagnostic 
tests.  Statistics  in Medicine, 1997. 
[ 121  R Kohavi.  A study  of cross-validation and bootstrap 
for accuracy estimation and  model  selection.  IJCAI, 
1995. 
[ 131  W. Lee, S. J. Stolfo, and P. K. Chan. Learning patterns 
from  UNIX  processes  execution  traces for  intrusion 
detection. AAAI Workshop on AI Approaches to Fraud 
Detection and Risk Management, pages 50-56.  AAAI 
Press,  1997. 
[ 141  Wenke Lee, Sal Stolfo, and Kui Mok. A Data Mining 
Framework  for Building Intrusion Detection Models. 
IEEE Sj*rnposium on Security and Privacy, 1999. 
[ 151  R.W. Lo, K.N. Levitt, and R.A. Olsson. MCF: a Mali- 
cious Code Filter.  Computers & Securify, 14(6):541- 
566., 1995. 
[ 161  MacAfee.  Homepage - MacAfee.com.  Online publi- 
cation, 2000.  http://www.mcafee.com. 
[ 171  Microsoft.  Portable Executable Format.  Online pub- 
lication, 1999. http://support.microsoft.com 
/support/kb/articles/Q 12 1 /4/60.asp. 
49