to make such a large-scale search possible.
Given a known point on the route and a target area, we developed
a crawler using Google API to download the routes from the point
to the residential addresses in the target area [10]. Each route here
comes with a set of driving directions (e.g. html_instructions) in
text and an estimated driving time. Such text directions are roughly
a subset of the audio directions used by Google Navigator for the
same route, with some standard road name abbreviations (“Rd”,
“Dr”, etc.).
For each route with text directions, our approach replaces their
abbreviations with the full names [13], calls the Google text-to-
speech (TTS) engine to synthesize the audio for each sentence, and
then measures the length of each audio element. This produces a
sequence of speech lengths, which we call a TTS sequence. Compar-
ing a TTS sequence with its corresponding speech-length sequence
from a real drive (the real sequence), the former is typically a subset
of the latter. An example is illustrated in Table 4. Based on this
observation, we come up with a method to search a large number of
TTS sequences, as follows.
We ﬁrst extract all the subsequences on a real sequence under
the constraint that two neighboring elements on a subsequence
must be within a distance of 3 on the original sequence: that is, on
the real sequence, there must be no more than 2 elements sitting
in between these two elements. These subsequences are used to
search TTS sequences for those with substrings that match them.
The example in Table 4 shows a TTS sequence that matches a
subsequence on the real sequence. As a result of the search, we get
a list of TTS sequences ranked in a descending order according to
each sequence’s overlap ratio with the real sequence calculated with
the longest subsequence (under the above constraint) shared between
them. We then pick up top TTS sequences, run our simulator on
their source and destination addresses to generate their full speech-
length sequences, and compare them with the real sequence to ﬁnd
its route.
Figure 4: Audio length sequence dis-
tinguishability
Figure 5: False positive rate vs num-
ber of audio elements
In our research, we randomly chose 1000 test routes in Blooming-
ton with the similar driving time and number of elements as those of
the routes for 10 real drives to get their speechlength sequences us-
ing our simulator. These sequences were compared with the length
sequences recorded from the real routes, as illustrated in Figure 4.
Here we use a variant of Jaccard index, called overlap ratio, to
measure the similarity of two length sequences in a normalized way:
given sequences s and s(cid:48) and their longest common subsequence
¯s, their overlap ratio is deﬁned as R(s, s(cid:48)) =
|s|+|s(cid:48)|−|¯s| . Figure 4
shows the distribution of the ratios between the sequences in real and
test sets (which are associated with different routes) together with
the distribution of the ratios between the speech-length sequences
of real drives and the simulated drives on the same routes. As we
can see here, for two different routes, their speech-length sequences
are very different (mean: 0.1827, standard deviation: 0.0817), while
two identical routes always have highly similar length sequences
(mean: 0.6146, standard deviation: 0.0876). Based on these two
distributions, we set a threshold of 0.5 for determining when two
sequences “match”: that is, they are considered to be related to the
same route.
|¯s|
Figure 4 shows that speech-length sequences can effectively ﬁn-
gerprint their driving routes. A caveat here is that such a sequence
should not be too short. Figure 5 illustrates what happens when
comparing short sequences extracted from real driving routes with
those of the same lengths randomly sampled from the 1000 test
sequences. We can see here that false positives (i.e., matches be-
tween the sequences from different routes) begin to show up when
sequence lengths go below 9.
5.2 Attack Methodology
Given a speech-length sequence, we want to identify its route on
the map. To this end, we developed a suite of techniques for the
following attacks: (1) ﬁngerprinting a few “Points of interest” (PoI)
the user might go, such as hospitals, airport and others, to ﬁnd out
whether the user indeed goes there and when she goes; (2) collecting
a large number of possible routes the user might use (based on some
background information) and searching these routes for the target
speech-length sequence.
Location ﬁngerprinting. To ﬁngerprint a PoI, we ﬁrst ﬁnd a set of
start addresses surrounding it from Google Maps and then run our
driving-simulation app from these addresses to the target. This gives
us a set of speech-length sequences for the driving routes to the PoI,
which we treat as a signature for the location. To ensure that such a
signature is unlikely to have false positives, the start addresses are
selected in a way that their routes to the PoI have at least 10 speech
elements (Figure 5).
For each speech length sequence received from our zero permis-
sion app, our approach extracts a substring at the end of the sequence
according to the lengths of a target PoI’s signature sequences. On
such a substring are the last steps of the route our app observes,
00.20.40.60.8100.050.10.150.20.25overlap ratioprobability  truefalse24681000.10.20.30.40.5signature length vs false positive ratenumber of audio elementsfalse positive rate  false positive rate1024Table 4: Comparison between a Navigation Sequence and a Text Direction/TTS Sequence
Google Navigator
Turn left onto south xxx street, then turn right onto west xxx road
Turn right onto west xxx road
Continue onto west xxx Road for a mile
In one thousand feet, turn right onto xxxxx ** north
Turn right onto xxxxx ** north
Real Length
4.21
2.05
2.53
4.07
2.74
Google Direction API
N/A
Turn right onto west xxx Road
N/A
N/A
Turn right onto xxxxx ** north
Synthesis Audio Length
N/A
2.15
N/A
N/A
2.72
Table 5: Route Identiﬁcation Result. The third column is the highest overlap
ratio of a wrong route within the top 10 TTS sequences. FP indicates false
positive. All FP routes (actually similar routes) are marked out in Figure 6.
Route
No.
1
2
3
4
5
6
7
8
9
10
result(ratio)
Top ratio of a wrong route
Notes(error)
found (0.813)
found (1.0)
found (0.615)
missed
missed
found (0.846)
found (0.714)
found (0.5)
found (0.588)
found (0.6)
0.579 (FP)
0.846 (FP)
0.462
0.412
0.32
0.667 (FP)
0.415
0.345
0.261
0.292
similar route (0.2mi)
similar route (0.5mi)
similar route (0.3mi)
5.3 Attack Evaluation
Location determination. We ﬁngerprinted two PoIs in Blooming-
ton, i.e Bloomington Hospital and Indianapolis International Airport
(IND) using our driving simulator. For the hospital, 19 routes with
at least 10 audio elements on their speech-length sequences were
selected from Google Maps, which cover all the paths to the place.
The airport has only 4 paths to get in and get out, each having at
least 10 audio elements. We ﬁrst evaluated the false positives of
these signatures with 200 routes with similar lengths, and did not
observe any false match. Then we compared the signatures with 4
real driving sequences collected by our zero-permission app from
the trips to these PoIs (2 for each PoI), they all matched the right
routes in the signatures.
Driving-route identiﬁcation. We further tried to locate 10 speech-
length sequences our zero-permission app collected from real drives
from a highway exit to 10 random locations in Bloomington. To
this end, we randomly selected 1000 residential addresses from
each of the 5 ZIP code areas in the town using the local family
website [10] and called the Google Direction API to get the routes
from the highway exit (which was supposed to be known) to these
5000 addresses, together with the Google driving routes for the 10
real sequences. Then, the TTS sequences of those 5010 routes were
compared with the 10 real-drive speech length sequences collected
by our malicious app. For each real sequence, 10 TTS sequences
with the highest overlap ratios as described in Section 5.2 were
picked out for a validation that involves simulating drives on these
TTS sequences’ routes, measuring their speech-length sequences
and comparing them with the length sequences of the real drives.
In the end, we identiﬁed 11 routes using the 0.5 threshold for the
overlap ratio (see Table 5). Among them, 8 are true positives, the
real routes we drove.
Also, the 3 false positives are actually the routes that come very
close to the routes of 3 real-drive sequences (see Figure 6), with two
within 0.3 miles of the real targets and one within 0.5 miles. Note
that in all these cases, the real routes were also found and ranked
higher than those false positives. This actually indicates that our
approach works very well: even when the real-drive routes were
not among the routes we randomly sampled on the map (from the
highway exit to 5000 random addresses), the approach could still
identify those very close to the real routes, thereby locating the
smartphone user to the neighborhood of the places she went.
Figure 6: Three FP Routes and Their Corresponding TP Routes. Each
FP/TP pair has most of their routes overlapped.
6. MITIGATION AND DISCUSSION
Given the various public resources on Android, the information
leaks we found are very likely to be just a tip of the iceberg. Finding
an effective solution to this problem is especially challenging with
rich background information of users or apps gratuitously available
on the web. To mitigate such threats, we ﬁrst take a closer look at
the attacks discovered in our research. The ARP data has not been
extensively utilized by apps and can therefore be kept away from
unauthorized parties by changing the related ﬁle’s access privilege
to system. A simple solution to control the audio channel can be
to restrict the access to its related APIs, such as isMusicActive,
only to system processes whenever sensitive apps (e.g. navigation
related) are running in the foreground. The most challenging facet
of such a mitigation venture is to address the availability mecha-
nism of the data usage statistics, which have already been used by
hundreds of apps to help Android users keep track of their mobile
data consumption. Merely removing them from the list of public
resources is not an option. In this section, we report our approach on
mitigating the threat deriving from the statistics availability, while
maintaining their utility.
6.1 Mitigation Strategies
To suppress information leaks from the statistics available through
tcp_rcv and tcp_snd, we can release less accurate information.
Here we analyze a few strategies designed for this purpose.
Round up and round down. One strategy is to reduce the accuracy
of the available information by rounding up or down the actual
number of bytes sent or received by an app to a multiple of a given
integer before disclosing that value to the querying process. This
approach is reminiscent of a predominant defense strategy against
trafﬁc analysis, namely packet padding [20, 36]. The difference
between that and our approach is that we can not only round up but
also round down to a target number and also work on accumulated
payload lengths rather than the size of an individual packet. This
enables us to control the information leaks at a low cost, in terms of
impact on data utility.
Speciﬁcally, let d be the content of a data usage counter (tcp_rcv
or tcp_snd) and α an integer given to our enforcement frame-
work implemented on Android (Section 6.2). When the counter is
queried by an app, our approach ﬁrst ﬁnds a number k such that
1025kα ≤ d ≤ (k +1)α and reports kα to the app when d−kα < 0.5α
and (k + 1)α otherwise.
Aggregation. A limitation of the simple rounding strategy results
from the fact that it still gives away the payload size of each packet,
even though the information is perturbed. As a result, it cannot hide
packets with exceedingly large payloads. To address this issue, we
can accumulate the data usage information of multiple queries, for
example, conditions on WebMD the user looks at, and only release
the cumulative result when a time interval expires. This can be
done, for example, by updating an app’s data usage to the querying
app once every week, which prevents the adversary from observing
individual packets.
6.2 Enforcement Framework
To enforce the aforementioned policies, we designed and imple-
mented a preliminary framework, which is elaborated below.
Permission Design. A naive idea would be adding yet another
permission to Android’s already complex permission system and
have any data monitoring app requesting this permission in An-
droidManifest.xml. However, prior research shows that the users
do not pay too much attention to the permission list when installing
apps, and the developers tend to declare more permissions than
needed [25]. On the other hand, the trafﬁc usage data generated by
some applications (e.g banking applications) is exceptionally sensi-
tive, at a degree that the app developer might not want to divulge
them even to the legitimate data monitoring apps. To address this
problem, our solution is to let an app specify special “permissions”
to Android, which deﬁnes how its network usage statistics should
be released. Such permissions, which are essentially a security pol-
icy, was built into the Android permission system in our research.
Using the usage counters as an example, our framework supports
four policies: NO_ACCESS, ROUNDING, AGGREGATION and
NO_PROTECTION. These policies determine whether to release an
app’s usage data to a querying app, how to release this information
and when to do that. They are enforced at a UsageService, a
policy enforcement mechanism we added to Android, by holding
back the answer, adding noise to it (as described in Section 6.1) or
periodically updating the information.
Enforcement mechanism. Under our framework, public resources
on the Linux layer, such as the data usage counters, are set to
be accessible only by system or root users. Speciﬁcally, for the
/proc/uid_stat/ resources, we modiﬁed the create_stat
ﬁle in drivers/mis/uid_stat.c of the Android Linux ker-
nel and changed the mode of entry to disable direct access to
the proc entries by any app. With direct access turned off, the app
will have to call the APIs exposed in TrafficStats.java and
NetworkStats.java such as getUidTxBytes() to gain ac-
cess to that information. In our research, we modiﬁed these APIs
so that whenever they are invoked by a query app that requests a
target app’s statistics, they pass the parameters such as the target’s
uid through IPC to the UsageService, which checks how the
target app (uid) wants to release its data before responding to the
query app with the data (which can be perturbed according to the
target’s policy). In our implementation, we deliberately kept the
API interface unchanged so existing data monitor apps can still run.
Defense Evaluation. To understand the effectiveness our technique,
we ﬁrst evaluated the round up and round down scheme using the
WebMD app. Figure 7 illustrates the results: with α increasing from
16 to 1024, the corresponding number of conditions that can be
uniquely identiﬁed drops from 201 to 1. In other words, except a
peculiar condition DEMENTIA IN HEAD INJURY whose total reply
Figure 7: Effectiveness of round up and round down
payload has 13513 bytes with its condition overview of 11106 bytes
(a huge deviation from the average case), all other conditions can