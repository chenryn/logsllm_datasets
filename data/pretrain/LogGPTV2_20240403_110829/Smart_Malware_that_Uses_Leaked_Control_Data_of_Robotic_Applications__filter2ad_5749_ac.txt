can be injected on-the-ﬂy. The faults were designed through
a careful study of Raven-II’s operation and its rendering algo-
rithm. In this paper, we present three fault models that cause
the haptic feedback rendering engine to fail to prevent the
operator from penetrating the surface of the object under oper-
ation. The three fault models are representative in mimicking
realistic cases of (i) loss of information during transmission
of data, (ii) data corruption, (iii) a glitch in sensors, and/or
(iv) a bug in the software algorithm. None of the faults are
speciﬁc to the environment (i.e., the faults are not affected
by custom settings of the robot in a certain environment).
Hence, understanding of the application (without needing to
understand certain custom conﬁgurations) is sufﬁcient for
designing effective faults.
Fault 1: Loss of granularity in the depth map. As dis-
cussed in Section 3, the haptic feedback rendering algorithm
relies heavily on image sensor data. Our ﬁrst fault model
demonstrates a case in which the quality of the image from
the sensor is degraded. More speciﬁcally, we consider a case
in which the granularity of the depth map has become sparse
due to (i) hardware problems in the image sensor or (ii) loss
of data during transmission of the depth data. In this fault
model, we randomly choose a certain percentage of the pixels,
for which we neutralize the depth information (i.e., set it to
zero, which can be interpreted as setting the distance to that of
the ground surface). By carefully choosing the rate at which
pixels are dropped, we can disguise an attack as natural noise,
despite its critical impact.
Fault 2: Shifted depth map. The second fault model consid-
ers a case in which an entity with malicious intent manipulates
a ROS message to obfuscate the visual data provided to the
operator. Just as we dropped the depth information from the
image sensor in Fault 1, we can overwrite the depth map mes-
sage with shifted values, causing the rendering algorithm to
provide incorrect haptic feedback that the operator will rely
on. In our experiment, we shifted the depth map of the object
under operation by 50 pixels to the right. As the ROS message
that contained the BGR information remained untouched, the
3D rendered image of the object was incomplete. Similarly,
an attacker can shift the data in the BGR message and deliver
the malicious visual image to the Raven operator.
Fault 3: Corrupted reference frame. As part of rendering
haptic feedback, the application needs to derive the distance
from the object (under operation) to the robot arms, as the
location of the object can change on every run or during the
operation of the robot. An attacker can corrupt the coordi-
nates of the reference frame and make the rendered feedback
342          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Association(a)
(b)
(c)
Figure 4: Overview of the system setup for the experiment.
Figure 3: Experimental setup with (a) BGR image of the
operating table; (b) RVIZ representation of the operating table
in 3D; and (c) RVIZ representation of the operating room,
including Raven-II.
become invalid. In this fault model we modify the reference
frame during the transmission of the coordinates from the
image sensor node to the computational node. Note that the
ArUco detection-based reference frame is applicable in exper-
imental settings such as ours. In commercial surgical robots,
the known position of trocars (i.e., pen-shaped instruments
used to create an opening into the body [7, 29]) are used as
the reference frame, and the fault model would need to be
modiﬁed accordingly.
5 Experiment design
Experimental setup. In order to mimic the settings of a surgi-
cal operation, we set up a mock-up of a heart (the object under
operation in Figure 3a) on an operating table. We placed an
ArUco marker to calibrate the conﬁguration of the object (i.e.,
the mock-up of the heart). Once the image sensor passed the
information to the Raven-II simulator, the operating table and
the target object were rendered in 3D, as shown in Figure
3b. Note that the 3D axes were added to the image upon the
algorithm’s detection of the marker. Using the predetermined
transformation from the marker to the robot, RVIZ can place
the virtual representation of the robot over the operating ta-
ble (Figure 3c). For the demonstration of the smart malware,
the mock-up heart was replaced with a simpler shape, i.e., a
cuboid (see Figures 5 and 10–12). However, the performance
measurements were not affected by the simpliﬁcation of the
shape of the object.
Systems setup. To demonstrate the smart malware, as de-
picted in Figure 4, we set up three Linux (Ubuntu 16.04)
machines running ROS (i.e., Kinetic, one of the most recent
versions of ROS). While the nodes for Raven-II and the ren-
dering algorithm can be distributed across any combination of
machines, we simpliﬁed the conﬁguration by distributing the
application across two machines (tchaikovsky and pachelbel,
shown in Figure 4). The third machine (cloud7) is owned
Figure 5: Evaluation of the distance from the robot arm to the
object.
by the attacker. The two machines, both running Raven-II,
reside in the same (virtual) network (marked with the dotted
box in Figure 4), whereas cloud7 resides in the same network
only when executing the attack strategy (see Section 4.2).
The rendering algorithm is designed to run with the (physi-
cal) Raven-II robot. However, we limited the experiment to
a simulated environment to protect the physical robot from
potential damage. Although the experiment was limited to a
simulated environment, the faults and their impact still apply
to the physical robot.
Data. With the MITM established (as described in Section
4), we were able to eavesdrop on all messages transmit-
ted between the ROS nodes. Such messages included ones
communicating the robot’s joints’ state (i.e., the angle of
each joint), which determined the robot’s end-effector po-
sition. We took advantage of the ROS-provided API (i.e.,
TransformListener() [37]) to derive the position of each
joint. Using the API, we (in the shoes of an attacker) could col-
lect data on the x, y, and z coordinates of the robot end-effector
in three-dimensional space. We considered three scenarios to
mimic surgical operations of different levels of complexity: (i)
a surgeon focuses on a single region of the target object; (ii) a
surgeon operates on two regions of the target object; and (iii)
a surgeon operates on three regions of the target object. Note
that the movements of the robot arms (manipulated by the
surgeon) follow a trajectory speciﬁc to a given surgical proce-
dure. Because of our lack of real data on such trajectories, we
imitated rather complex routes to challenge our algorithm.
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 343down the genuine publisher (i.e., omni_client) and the mali-
cious topic (i.e., faulty data) is passed to the ROS application
( 8 ). Because of the faulty data, the operation of Raven is
corrupted, which puts the patient at risk ( 9 ).
6 Results
In this section, we present our results from inferring the time
to trigger the attack payload and injecting realistic faults.
6.1 Determining attack triggers
In this section, we evaluate our accuracy in determining the
robot’s end-effector position with respect to the target object.
In Figure 7, we present the results of the clustering algorithm
(based on DBSCAN) for the three scenarios: (i) a surgeon
operates on a single region of the target object; (ii) a surgeon
operates on two regions of the target object; and (iii) a surgeon
operates on three regions of the target object. Note that in
Figures 7a–7c, an “x” indicates that the point is considered
noise, and a circle indicates that the point belongs to a cluster.
(Different colors are used to differentiate clusters.) Also, in
Figure 5, we compare the clustering results with those from a
pedal-detection-based approach (pedal) [2].
Case 1: Single region of operation. Figure 7a depicts the
trajectory of the robot arm for the case in which a surgeon is
operating at a single region of the object. The algorithm effec-
tively identiﬁes the data points that correspond to the region
of operation and successfully ﬁlters out the data points related
to the transition of the robot arm from the starting point of the
robot arm to the region of operation. In Figure 8a, we present
a cumulative distribution of the distance from the clustered
points (robot’s joint positions) to the target object. While all
points of the DBSCAN-derived clusters had a distance of less
than 1 cm from the target object, the pedal-detection-based
algorithm included points related to transition of the robot,
which resulted in reduction of the probability of a successful
attack. Also, as depicted in Figure 9, the algorithm effectively
clusters the instances in which the robot is closer to the object
(“clustered1” in Figure 9), as opposed to the points that were
labeled as transitions to the object (“transition1” in Figure
9). For our algorithm, the distance (from the robot arm to the
object) varied from 0.0 mm to 7.5 mm, and our clustering
algorithm was able to ﬁlter out the points that corresponded
to transitions from the starting point of the robot arm to oper-
ational regions (cluster I in Figure 7a). The pedal-detection-
based approach includes the starting point of the robot arm as
a potential trigger for an attack. (Note that the starting point
is 121 mm from the object.). As shown in Figure 8a, 99.9%
of the DBSCAN-predicted triggers were within 7.1 mm of
the object. However, for the pedal detection-based approach,
only 80.3% of the predicted points were within 7.1 mm.
Case 2: Two regions of operation. As shown in Figure 7b,
the algorithm successfully captured the two regions despite
Figure 6: Overview of the steps taken by the malware.
Evaluation metrics. The goal of an attacker is to trigger the
execution of the attack payload at the most opportune time
so as to maximize the damage, e.g., hurt a patient or damage
the robot. In order to achieve that objective, the attacker must
precisely determine when the robot is operating near (if not
in contact with) the target object. The clustering algorithm
(in Section 4) indirectly derives the decision by monitoring
the trace density of the robot arm in 3D space. To evaluate
the effectiveness of the decision, we measured the distance
from the robot arm to the object (see Figure 5). That would
not be not possible for a real attacker, as the location of the
object would remain unknown. We evaluate the predictions by
using a threshold (i.e., 10 mm) that deﬁnes “close to object.”
Applying the deﬁnition, we derive the number of predicted
instances that would lead to a successful attack. (We consider
an attack to be “successful” if the execution is triggered when
the distance from the robot arm to the object is less than the
threshold).
Automated malware execution. In Figure 6, we show how
an attack using our smart malware would proceed. The at-
tacker starts by getting access to the control network of the
robot ( 1 ). This step could be accomplished by scanning
for the target ROS application connected to the public net-
work [13], or stealing the credentials of a legitimate user in
the control network (via social engineering or phishing at-
tacks). With access to the control network, the attacker scans
the network for the 11311 port to ﬁnd the ROS master ( 2 ).
In 3 , the attacker checks the version of ROSand disables
all patches that remediate the vulnerabilities of ROS 1. Next,
the attacker can deploy the smart self-learning malware. First,
the malware subscribes ( 4 ) to topics of interest (e.g., tf, a
ROS-generic topic for the x, y, z coordinates of the robot
end-point). By running the DBSCAN algorithm, the malware
can label each point (i.e., member of a cluster or noise) ( 5 ).
When the robot arm position is classiﬁed as a cluster, the
malware triggers the payload execution ( 6 ), which registers
the malicious publisher with the name of a genuine publisher.
Because of the name conﬂict, in 7 , the ROS master shuts
344          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Association(a) Single region of operation.
(b) Two regions of operation.
(a) Single region of operation.
(c) Three regions of operation.
Figure 8: Cumulative distribution of the distance from the
robot arm to the object.
the complexity added to the operation. While we have added
an intermediate transition between the regions of operation,
the algorithm successfully ﬁltered out such transitions, and
distinguished the two regions. As depicted in Figure 9 and
Figure 8b, the clustering algorithm was able to ﬁnd a subset
that contained the majority of the points that were closest to
the object (i.e., 0.26 mm ≤ distance ≤ 20.44 mm).
Case 3: Three regions of operation. In Figure 7c, we
present the case in which the surgery takes place in three adja-
cent regions. The algorithm successfully detected all three re-
gions. Also, all points clustered by our algorithm turned out to
be within 19.8 mm of the object (i.e., all points in the clusters
had a distance ≤ 19.82 mm). For the pedal-detection-based
algorithm, 19.2% of the points triggered unsuccessful attacks
while with our DBSCAN-based approach, 3.23% would have
been unsuccessful.
Discussion. Triggering when the instrument is in close prox-
imity to the target object is essential to increasing the like-
lihood of success. As demonstrated in the experiments, our
DBSCAN-based approach effectively predicts points that are
close to the target object. As discussed in [53], the success
of the DBSCAN algorithm is sensitive to the choice of the
two parameters (i.e., ε and n). In this paper, we have taken
a trial-and-error approach, which would not be feasible for
an attacker with limited information. (I.e., the attacker cannot
conﬁrm whether the resulting cluster truly represents the re-
gion of interest.) Instead, the attacker can tune the learning
algorithm (i.e., ﬁnd the optimal parameters, ε and n) ofﬂine
and install the malware with the parameters embedded.
(b) Two regions of operation.
(c) Three regions of operation.
Figure 7: Results of tracing of the robot’s arm movements in
three hypothetical surgical procedures.
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 345Figure 9: Distribution of the distances from the predicted
clusters (predicted either by DBSCAN or by pedal detection)
to the object. The labels “clustered” and “transition” indicate
coordinates that were predicted as “surgical operation” and
“transition of the robot”, while “pedal” is for the coordinates
ﬁltered by the approach in [2].
6.2 Impact of attacks on the Raven-II haptic
feedback rendering algorithm
This section presents the impacts of executing the three attack
payloads: (i) loss of granularity in the depth map, (ii) shifted
depth map, and (iii) corrupted reference point.
In Figure 10, we present the result of dropping 90% of the
pixels from the depth map. (Note that to maximize the visi-
bility of the fault’s impact, we have chosen an extreme case
and neutralized an unrealistically large portion of pixels.) As
a result, the robot arm tip penetrated the surface of the object
(Figure 10b), whereas the algorithm should have blocked it
from doing so (as seen in Figure 10a). In reality, incorrect