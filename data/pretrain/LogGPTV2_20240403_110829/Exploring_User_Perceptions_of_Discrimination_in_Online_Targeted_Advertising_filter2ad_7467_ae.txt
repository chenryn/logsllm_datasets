the ethical use of targeted advertising [1, 18, 25]. Of these
recommendations, only the EFF policy document men-
tions discrimination as a potential, unethical consequence.
Our results, as well as prior research that has brought
to light instances of discrimination (e.g., [13, 37]), high-
light the importance of discrimination as an ad-targeting
consideration. We ﬁnd that 43% of respondents rated
our discriminatory advertising scenarios a signiﬁcant or
moderate problem. More speciﬁcally, in the more prob-
USENIX Association
26th USENIX Security Symposium    947
Factor
T-Asian
T-Black
Behavior
Advertiser
Human
Age of respondent
HS+
BS+
R/E-Asian
R/E-Black
R/E-Hispanic or Latino
SSI
OR
0.91
1.05
1.15
0.94
0.91
1.00
0.96
0.68
1.90
1.57
1.30
1.03
CI
[0.65, 1.27]
[0.75, 1.47]
[0.87, 1.51]
[0.71, 1.24]
[0.69, 1.20]
[0.99, 1.01]
[0.64, 1.44]
[0.46, 1.00]
[0.97, 3.74]
[0.97, 2.53]
[0.76, 2.24]
[0.76, 1.40]
p-value
0.574
0.789
0.321
0.656
0.509
0.566
0.845
0.051
0.063
0.067
0.340
0.839
Table 18: Regression results for ethical behavior by the
end user (n=891), where OR > 1 is associated with
stronger disagreement that the end user behaved ethically.
See Table 10 caption for more detailed explanation.
lematic demographic scenario, 53% did so; even in the
less problematic behavioral scenario, when discrimina-
tion happened as a result of targeting based on users’
web browsing history, 34.2% did so. Thus, we propose
that guidelines, especially those issued by government
agencies, should include explicit language about discrimi-
nation to address this topic of common concern.
Our ﬁndings suggest that while respondents distinguish
behavioral from demographic targeting, they are not espe-
cially concerned with whether an algorithm was involved
in the outcome. This suggests that responses that focus
on the algorithmic nature of the ad ecosystem may not be
helpful for addressing public concerns.
Finally, our ﬁndings represent a broad cross-section
of users’ opinions, but they do not represent a normative
guideline for what should be appropriate. Many kinds of
discrimination that may seem acceptable to the general
public today may in fact be illegal, immoral, or unjust.
Activists and advocates who are concerned about online
discrimination can use our work as a starting point to
better understand where more education, persuasion, and
lobbying for new regulations may be most needed for
furthering their agenda.
7.3 Future Work
Overall, our work addresses only a small portion of the
critical topic of online algorithmic discrimination. Our
results highlight an important distinction between users’
perceptions of scenarios involving explicitly racial vs.
implicitly racial, online-behavior-based discrimination.
However, we explored only web-history-based targeting,
and thus, future work may seek to explore whether users
react similarly to other types of behaviors, or whether
certain online behaviors are more sensitive.
Similarly, future work is needed to explore reactions to
discrimination based on factors other than race. Our ﬁrst
pilot results suggested that users did not feel as strongly
about topics such as pre-existing health conditions, at
least in our advertising scenario, this should be explored
in further detail in a wider range of scenarios.
Relatedly, we only explored user perceptions of scenar-
ios involving advertising discrimination, and only in the
context of a potentially desirable ad (for a job). It would
be interesting to explore whether reactions remain the
same when the ad in question is potentially undesirable,
for example related to bail bonds or drug-abuse treatment.
Related work [17, 35] has also shown evidence of dis-
crimination in the search results shown to diﬀerent users;
questions about discrimination in pricing, insurance, and
other services also remain open. Thus, future work could
focus on exploring and comparing user reactions to dis-
criminatory results in a variety of settings.
Finally, the concrete regression models, with particu-
lar coeﬃcient values, as described in Section 5.3, were
not tested for predictive power against independent test
data. Such validation may make interesting future work
for those interested in accurately predicting people’s re-
sponses to cases of discrimination.
8 Acknowledgments
We thank Sean Kross for statistical guidance, the respon-
dents in our surveys, and the anonymous reviewers of our
submission. We gratefully acknowledge funding support
from the National Science Foundation (Grant 1514509),
and from a UMIACS contract under the partnership be-
tween the University of Maryland and DoD. The opinions
in this paper are those of the authors and do not neces-
sarily reﬂect the opinions of any funding sponsor or the
United States Government.
References
[1] Online
behavioral
and
concerns
ing
primer.
onlineprivacylegprimersept09.pdf, 2009.
and
tracking
solutions:
target-
Legislative
https://www.eff.org/files/
[2] U.S. digital ad spending to surpass TV this
year: Digital will represent 37% of U.S. total
media ad spending.
https:
//www.emarketer.com/Article/US-Digital-Ad-
Spending-Surpass-TV-this-Year/1014469.
eMarketer (2016).
[3] Agarwal, L., Shrivastava, N., Jaiswal, S., and Pan-
jwani, S. Do not embarrass. In SOUPS (2013).
948    26th USENIX Security Symposium
USENIX Association
[4] Akaike, H. A new look at the statistical model iden-
tiﬁcation. IEEE Transactions on Automatic Control
19, 6 (1974), 716–723.
[16] Evans, D. S. The online advertising industry: Eco-
nomics, evolution, and privacy. The Journal of Eco-
nomic Perspectives 23, 3 (2009).
[5] Balebako, R., Leon, P., Shay, R., Ur, B., Wang,
Y., and Cranor, L. Measuring the eﬀectiveness of
privacy tools for limiting behavioral advertising. In
Web 2.0 Security and Privacy Workshop (2012).
[6] Barford, P., Canadi, I., Krushevskaja, D., Ma, Q.,
and Muthukrishnan, S. Adscape: Harvesting and
analyzing online display ads. In WWW (2014).
[7] Bendera, R., and Lange, S. Adjusting for multiple
testing–When and how? The Journal of Clinical
Epidemiology 54, 4 (Apr. 2001), 343–349.
[8] Bergemann, D., and Bonatti, A. Targeting in ad-
vertising markets: implications for oﬄine versus
online media. The RAND Journal of Economics 42,
3 (2011).
[9] Carpenter, J. Google’s algorithm shows prestigious
job ads to men, but not to women. Here’s why that
should worry you. . The Washington Post (2015).
https://www.washingtonpost.com/news/the-
intersect/wp/2015/07/06/googles-algorithm-
shows-prestigious-job-ads-to-men-but-not-
to-women-heres-why-that-should-worry-you/.
[10] Carrascosa, J. M., Mikians, J., Cuevas, R., Er-
ramilli, V., and Laoutaris, N. I always feel like
somebody’s watching me. Measuring online be-
havioural advertising. In CoNEXT (2015).
[11] Coen, R., Paul, E., Vanegas, P., Lange, A., and
Hans, G. A user-centered perspective on algorith-
mic personalization. Master’s thesis, University of
California, Berkeley, 2016.
[12] Datta, A., Tschantz, M., and Datta, A. Dis-
crimination and opacity in online behavioral ad-
vertising.
http://possibility.cylab.cmu.edu/
adfisher/. Accessed June 2017.
[13] Datta, A., Tschantz, M. C., and Datta, A. Auto-
mated experiments on ad privacy settings. PoPETS
(2015).
[14] Debatin, B., Lovejoy, J. P., Horn, A.-K., and Hughes,
B. N. Facebook and online privacy: Attitudes, be-
haviors, and unintended consequences. Journal of
Computer-Mediated Communication 15, 1 (2009).
[15] Efron, B., and Tibshirani, R. Bootstrap methods
for standard errors, conﬁdence intervals, and other
measures of statistical accuracy. Statistical science
(1986), 54–75.
[17] FairSearch.
Can
search
violate U.S.
a monopolist
discrimination
antitrust
http://www.fairsearch.org/wp-
by
laws?
content/uploads/2011/07/Can-Search-
Discrimination-by-a-Monopolist-Violate-
U.S.-Antitrust-Laws1.pdf, 2011.
[18] FTC. Self-regulatory principles, for online behav-
https://www.ftc.gov/sites/
ioral advertising.
default/files/documents/reports/federal-
trade-commission-staff-report-self-
regulatory-principles-online-behavioral-
advertising/p085400behavadreport.pdf, 2009.
[19] Goldfarb, A., and Tucker, C. E. Online advertising,
behavioral targeting, and privacy. Communications
of the ACM 54, 5 (2011).
[20] Goodman, S. N. Multiple comparisons, explained.
American Journal of Epidemiology 147, 9 (May
1998), 807–812.
[21] Guha, S., Cheng, B., and Francis, P. Challenges
in measuring online advertising systems. In IMC
(2010).
[22] Guynn, J. Google Photos labeled black people ‘go-
rillas’. USA Today (2015).
[23] Hosmer, D. W., and Lemeshow, S. Applied logistic
regression. 2000.
[24] Huff, C., and Tingley, D. “Who are these peo-
ple?” Evaluating the demographic characteristics
and political preferences of MTurk survey respon-
dents. Research and Politics (2015).
[25] Institute for Advertising Ethics.
Principles
and practices for advertising ethics.
https:
//www.aaf.org/_PDF/AAF%20Website%20Content/
513_Ethics/IAE_Principles_Practices.pdf,
2011.
[26] Ipeirotis, P. G. Demographics of Mechanical Turk.
SSRN (2010).
[27] Johnson, L. U.S. digital advertising will make
$83 billion this year, says EMarketer. Adweek
(2017).
http://www.adweek.com/digital/u-s-
digital-advertising-will-make-83-billion-
this-year-says-emarketer.
[28] Lecuyer, M., Ducoffe, G., Lan, F., Papancea, A.,
Petsios, T., Spahn, R., Chaintreau, A., and Geam-
basu, R. XRay: Enhancing the Web’s Transparency
USENIX Association
26th USENIX Security Symposium    949
with Diﬀerential Correlation. In USENIX Security
(2014).
[29] Lecuyer, M., Spahn, R., Spiliopolous, Y., Chain-
treau, A., Geambasu, R., and Hsu, D. Sunlight:
Fine-grained targeting detection at scale with statis-
tical conﬁdence. In CCS (2015).
[30] Leon, P., Ur, B., Wang, Y., Sleeper, M., Balebako,
R., Shay, R., Bauer, L., Christodorescu, M., and
Cranor, L. What matters to users? Factors that
aﬀect users’ willingness to share information with
online advertisers. In SOUPS (2013).
[31] Levinson, N. The wiener (root mean square) error
criterion in ﬁlter design and prediction. Studies in
Applied Mathematics 25, 1-4 (1946).
[32] Liu, B., Sheth, A., Weinsberg, U., Chandrashekar,
J., and Govindan, R. AdReveal: Improving trans-
parency into online targeted advertising. In HotNets
(2013).
[33] Malheiros, M., Jennett, C., Patel, S., Brostoff, S.,
and Sasse, M. A. Too close for comfort: A study
of the eﬀectiveness and acceptability of rich-media
personalized advertising. In CHI (2012).
[34] McDonald, A. M., and Cranor, L. F. Americans’
attitudes about internet behavioral advertising prac-
tices. In WPES (2010).
[35] Mikians, J., Gyarmati, L., Erramilli, V., and
Laoutaris, N. Detecting price and search discrimi-
nation on the internet. In SOUPS (2012).
[36] Silverman, D.
IAB internet advertising revenue
report. Interactive Advertising Bureau. New York
(2010).
[37] Sweeney, L. Discrimination in online ad delivery.
Queue 11, 3 (2013).
[38] Tschantz, M., Egelman, S., Choi, J., Weaver, N.,
and Friedland, G. The accuracy of the demographic
inferences shown on Google’s Ad Settings. Tech.
Rep. TR-16-003, International Computer Science
Institute, 2016.
[39] Turow, J., King, J., Hoofnagle, C. J., Bleakley,
A., and Hennessy, M. Americans reject tailored
advertising and three activities that enable it.
In
SSRN (2009), vol. 1478214.
[40] Ur, B., Leon, P. G., Cranor, L. F., Shay, R., and
Wang, Y. Smart, useful, scary, creepy. In SOUPS
(2012).
[41] U.S. Census Bureau.
nity survey 5-year estimates.
census.gov/programs-surveys/acs/news/data-
releases/2015/release.html, 2015.
American commu-
http://www.
[42] U.S. Equal Employment Opportunity Commis-
Prohibited employment policiespractices.
sion.
https://www1.eeoc.gov//laws/practices/
index.cfm?renderforprint=1.
2017.
Accessed June
[43] Vagias, W. M.
Likert-type scale response
http://www.peru.edu/oira/wp-
anchors.
content/uploads/sites/65/2016/09/Likert-
Scale-Examples.pdf, 2006.
[44] Valentino-Davies, J., Singer-Vine, J., and Soltani,
A. Websites Vary Prices, Deals Based on Users’
Information. The Wall Street Journal (2012).
[45] Warshaw, J., Taft, N., and Woodruff, A. Intuitions,
Analytics, and Killing Ants - Inference Literacy of
High School-educated Adults in the US. In SOUPS
(2016).
[46] Willis, G. B. A Tool for Improving Questionnaire
Design. Sage Publications, 2005.
[47] Wills, C. E., and Tatar, C. Understanding what
they do with what they know. In WPES (2012).
A Survey Questions
Q1-4: How much responsibility does entity have for the
fact that their ads are seen much more frequently by peo-
ple who are target race than individuals of other races?
• Not at all responsible
• Somewhat responsible
• Mostly responsible
• Completely responsible
• Don’t know
This question would be asked four times in a random
order, each time with a new entity. Either Systemy (the
advertiser), Bezo Media (the ad network), the individual
visiting the website, or the the local news website.
Q5: Do you think it’s a problem that Systemy job ads
are seen much more frequently by people who are target
race than individuals of other races?
• Not at all a problem
• Minor problem
• Moderate problem
• Serious Problem
• Don’t know
950    26th USENIX Security Symposium
USENIX Association
Q6-9: Please tell us how much you agree or disagree
with the following statements: entity behaved ethically in
this situation
• Male
• Female
• Other
• Strongly Agree
• Agree
• Neutral
• Disagree
• Strongly Disagree
This question would be again be asked four times in
a random order, each time with a new entity. Either Sys-
temy (the advertiser), Bezo Media (the ad network), the
individual visiting the website, or the the local news web-
site.
Q10: Do you think the scenario we described could
happen in real life?
• Deﬁnitely could happen
• Probably could happen
• Neutral
• Probably could not happen
• Deﬁnitely could not happen
Q11:Please specify your age. [drop-down menu of ages
18-100 or over]
Q12: Please specify the gender with which you most
closely identify.
Q13: Please specify the highest degree or level of
school you have completed.
• Some high school credit, no diploma or equivalent
• High school graduate, diploma or the equivalent (for
example: GED)
• Some college credit, no degree
• Trade/technical/vocational training
• Associate degree
• Bachelor’s degree
• Master’s degree
• Professional degree
• Doctorate degree
Q14: Please specify your ethnicity.
• Hispanic or Latino
• Black or African American
• White
• American Indian or Alaska Native
• Asian
• Other
USENIX Association
26th USENIX Security Symposium    951