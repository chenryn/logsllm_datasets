title:Peek-a-Boo, I Still See You: Why Efficient Traffic Analysis Countermeasures
Fail
author:Kevin P. Dyer and
Scott E. Coull and
Thomas Ristenpart and
Thomas Shrimpton
2012 IEEE Symposium on Security and Privacy
Peek-a-Boo, I Still See You:
Why Efﬁcient Trafﬁc Analysis Countermeasures Fail
Kevin P. Dyer∗, Scott E. Coull†, Thomas Ristenpart‡, and Thomas Shrimpton∗
∗Department of Computer Science, Portland State University, Portland, USA. Email: {kdyer, teshrim}@cs.pdx.edu
† RedJack, LLC., Silver Spring, MD, USA Email: PI:EMAIL
‡Department of Computer Sciences, University of Wisconsin-Madison, USA. Email: PI:EMAIL
Abstract—
We consider the setting of HTTP trafﬁc over encrypted
tunnels, as used to conceal the identity of websites visited
by a user. It is well known that trafﬁc analysis (TA) attacks
can accurately identify the website a user visits despite the
use of encryption, and previous work has looked at speciﬁc
attack/countermeasure pairings. We provide the ﬁrst com-
prehensive analysis of general-purpose TA countermeasures.
We show that nine known countermeasures are vulnerable to
simple attacks that exploit coarse features of trafﬁc (e.g., to-
tal time and bandwidth). The considered countermeasures
include ones like those standardized by TLS, SSH, and
IPsec, and even more complex ones like the trafﬁc morphing
scheme of Wright et al. As just one of our results, we show
that despite the use of trafﬁc morphing, one can use only
total upstream and downstream bandwidth to identify —
with 98% accuracy— which of two websites was visited. One
implication of what we ﬁnd is that, in the context of website
identiﬁcation, it is unlikely that bandwidth-efﬁcient, general-
purpose TA countermeasures can ever provide the type of
security targeted in prior work.
Keywords-trafﬁc analysis countermeasures; privacy; ma-
chine learning; padding; encrypted trafﬁc
I. INTRODUCTION
Internet users increasingly rely on encrypted tunnels to
keep their web browsing activities safe from eavesdrop-
pers. A typical scenario involves a user establishing an
encrypted tunnel to a proxy that then relays all subsequent
HTTP trafﬁc (in both directions) through the tunnel. An-
other is when one browses the web on a wireless network
that uses WPA to encrypt all trafﬁc. In both cases, the
use of encryption should hide the contents of the trafﬁc
and, intuitively, the identity of the destination website(s).
Yet modern encryption does not obfuscate the length of
underlying plaintexts, nor the number of plaintexts that
are encrypted. This information may seem harmless, but
in fact it enables trafﬁc analysis (TA) attacks. Among other
things, TA attacks can reveal the identity of the websites
viewed by the user [1, 9, 10, 15, 19].
One commonly suggested TA countermeasure is to hide
the plaintext length by adding padding prior to encryption.
Padding countermeasures are standardized in TLS, explic-
itly to “frustrate attacks on a protocol that are based on
analysis of the lengths of exchanged messages” [5]. Simi-
lar allowances for padding appear in SSH and IPSec. More
advanced countermeasures, such as trafﬁc morphing [19],
manipulate whole streams of packets in order to precisely
mimic the distribution of another website’s packet lengths.
The seemingly widespread intuition behind these coun-
termeasures is that they patch up the most dangerous side
channel (packet lengths) and so provide good protection
against TA attacks, including website identiﬁcation. Exist-
ing literature might appear to support this intuition. For
example, Liberatore and Levine [10] show that padding
packets to the network MTU (e.g., 1500 bytes) reduces
the accuracy of one of their attacks from 98% to 7%.
Our results strongly challenge this intuition. We perform
the ﬁrst comprehensive analysis of low-level countermea-
sures (e.g., per-packet padding) for the kind of website
identiﬁcation attacks considered by prior work (c.f., [8, 10,
14, 22]): a closed-world setting for privacy sets, in which
the a priori set of possible websites a user might visit is
known to the attacker, coupled with the ability for the
attacker to train and test on trafﬁc traces that are free
of real-world artifacts (e.g., caching effects, interleaved
ﬂows, and user-speciﬁc content). We consider nine distinct
countermeasures, apply them to two large, independent
datasets of website downloads, and pit the resulting ob-
fuscated trafﬁc against a total of seven different attacks.
The results are summarized in Figure 1. What we uncover
is surprisingly bleak:
the countermeasures are effective. We show
None of
that two classiﬁers —a new na¨ıve Bayes classiﬁer called
VNG++ and a support vector machine classiﬁer due to
Panchenko et al. [14]— achieve better than 80% accuracy
in identifying which of k = 128 websites was visited
in a closed-world experiment. (Random guessing achieves
0.7% accuracy.) When k = 2 these classiﬁers achieve over
98% accuracy. This holds for all nine countermeasures
considered,
including ones inspired by the SSH, TLS
and IPSec RFCs, and state-of-the-art ones such as trafﬁc
morphing [21].
Hiding packet lengths is not sufﬁcient. We initiate a study
of classiﬁers that do not directly use ﬁne-grained features
such as individual packet lengths. The VNG++ classiﬁer
just mentioned uses only “coarse” information, including
overall time, total bandwidth, and size of bursts. In fact,
we provide a na¨ıve Bayes classiﬁer that uses only the total
bandwidth for training and testing, yet still achieves greater
© 2012, Kevin P. Dyer. Under license to IEEE.
DOI 10.1109/SP.2012.28
332
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:30 UTC from IEEE Xplore.  Restrictions apply. 
Attack
Classiﬁer
Liberatore and Levine [10] (LL)
na¨ıve Bayes (NB)
Herrmann et al. [8] (H)
Panchenko et al. [14] (P)
multinomial na¨ıve Bayes (MNB)
support vector machine (SVM)
Time (TIME)
Bandwidth (BW)
Variable n-gram (VNG)
VNG++
na¨ıve Bayes
na¨ıve Bayes
na¨ıve Bayes
na¨ıve Bayes
Features Considered
Packet lengths
Packet lengths
Packet lengths, Order, Total bytes
Total trace time
Upstream/Downstream total bytes
Bytes in trafﬁc bursts
Total trace time,
Upstream/Downstream total bytes,
Bytes in trafﬁc bursts
k = 2
85%
71%
99%
82%
98%
99%
99%
k = 128
k = 775
25%
3%
82%
9%
41%
69%
80%
8%
0%
63%
3%
18%
54%
61%
Figure 1. Summary of attacks evaluated in our work. The k = 2, k = 128 and k = 775 columns indicate the classiﬁer accuracy for a privacy set
of size k when using the most effective countermeasure for the Herrmann dataset (see Section II).
than 98% accuracy at k = 2 and 41% accuracy at k =
128. This implies that any effective countermeasure must
produce outputs that consume indistinguishable amounts
of bandwidth.
Coarse information is unlikely to be hidden efﬁciently.
Our coarse-feature attacks, in particular the bandwidth-
only attack, strongly suggest that resource-efﬁcient coun-
termeasures will not (on their own) effectively hide website
identity within a small privacy set. So, we investigate
an inefﬁcient strawman countermeasure, Buffered Fixed-
Length Obfuscation (BuFLO, pronounced “buffalo”), that
combines and makes concrete several previous sugges-
tions: it sends packets of a ﬁxed size at ﬁxed intervals,
using dummy packets to both ﬁll
in and (potentially)
extend the transmission. We subject it to the same analysis
as the other countermeasures. This analysis shows that
should BuFLO fail to obfuscate total time duration and
total bandwidth, then attacks still achieve 27% accuracy
at k = 128. With a bandwidth overhead of over 400%, we
can, in theory, ﬁnally reduce k = 128 accuracy to 5%.
Relevance to other settings. While the adversarial model
that we consider is consistent with previous work, we
admit that there are several factors (e.g., caching, open-
world identiﬁcation) that are not captured. Indeed, these
may reduce the effectiveness of the attacks, and improve
countermeasure efﬁcacy, in practice. There may also be
some other settings, such as Voice over IP (VoIP) traf-
ﬁc [18–21], where the nature of the application-layer
protocol enables some countermeasures to work very well.
That said, the model considered in this paper (and its
predecessors) is one that a general-purpose countermeasure
ought to cover.
Finally, our analysis does not cover application-
layer countermeasures
such as Camouﬂage [8] and
HTTPOS [12], which both make intimate use of spurious
HTTP requests to help obfuscate trafﬁc patterns. We
suspect, however, that the lessons learned here might help
direct future analysis of application-layer countermeasures,
as well.
II. EXPERIMENTAL METHODOLOGY
Like previous works [8, 10, 14, 22], our experiments
simulate a closed-world setting in which an adversary has
access to the timing, lengths, and directionality of packets
sent over an encrypted HTTP tunnel (e.g., to or from a
proxy server). We assume secure encryption algorithms are
used and no information can be learned from the encrypted
contents itself.
We base our simulation on two datasets that have been
widely used by previous works on web page identiﬁcation.
The Liberatore and Levine dataset [10] contains times-
tamped traces from 2,000 web pages. The Herrmann et
al. [8] dataset contains timestamped traces from 775 web
pages. A trace is deﬁned as a record of the lengths and
timings of ciphertexts generated by accessing a web page
using an OpenSSH single-hop SOCKS proxy. Please refer
to the previous works [8, 10] for further details about data
collection methodology.
Each of our experiments is performed with respect to
a particular classiﬁer, a particular countermeasure, and a
speciﬁed set of n web pages. An experiment consists of
a number of trials; we will say in a moment how the
particular number of trials is determined. At the start of
each experimental trial, we uniformly select a subset of
k ≤ n web pages to deﬁne the privacy set for that trial.1
Next we establish k sets of 20 traces, one for each web
page, as follows. For every web page in the data set, there
are m > 20 chronologically sorted sample traces. We
select a random trace index i ∈ {0, 1, . . . , m − 19}, and
take traces i, i + 1, . . . , i + 19 for each of the k web
pages. The ﬁrst t = 16 of the traces from each of the k
sets are used as the training data for the classiﬁer, and
the remaining T = 4 traces form the testing data set.2
The countermeasure is applied to both the training and
testing data, and the classiﬁer is trained and then tested to
determine its accuracy. Classiﬁer accuracy is calculated as
1We do not believe the uniform distribution represents typical user
web-browsing behavior. In practice, we expect that biased sampling from
the privacy set would further aid an attacker.
2We considered values of t ∈ {4, 8, 12, 16} and observed effects con-
sistent with those reported by Liberatore and Levine [10]: as t increases
there was a consistent, modest increase in classiﬁcation accuracy.
333
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:30 UTC from IEEE Xplore.  Restrictions apply. 
(c/T k), where c is the number of correctly classiﬁed test
traces and k is our privacy set size.
In each experiment, we perform 2(15−log2(k))
so that
there are a total of T · 215
tri-
als,
test data
points per experiment. We consider values of k ∈
{2, 4, 8, 16, 32, 64, 128, 256, 512, 775} in order to capture
countermeasure performance across a number of scenarios.
Intuitively, smaller values of k present easier classiﬁcation
(attack) settings, and larger values of k present more
difﬁcult classiﬁer settings.
We note that the engineering effort required to produce
our results was substantial. To aid future research efforts,
the Python framework used for our experiments is publicly
available3.
III. TRAFFIC CLASSIFIERS
A sequence of works detail a variety of TA attacks, in
the form of classiﬁers that attempt to identify the web
page visited over an encrypted channel. These classiﬁers
use supervised machine learning algorithms, meaning they
are able to train on traces that are labeled with the
destination website. Each algorithm has a training and
a testing phase. During training, the algorithm is given
a set {(X1, (cid:2)1), (X2, (cid:2)2), . . . , (Xn, (cid:2)n)}, where each Xi
is an vector of features and (cid:2)i is a label. During testing
the classiﬁcation algorithm is given a vector Y and must
return a label. In our case, a vector Xi contains information
about the lengths, timings, and direction of packets in the
encrypted connection containing a web page (cid:2)i, and the
format of a vector Xi is dependent upon the classiﬁer.
In the remainder of this section, we present a high-level
overview of the operation of the three published classiﬁers
that we use in our evaluation, and we refer interested
readers to more detailed descriptions elsewhere [8, 10, 13,
14].
A. Liberatore and Levine Classiﬁer
Pr(Y )
Liberatore and Levine [10] (LL) proposed the use of a
na¨ıve Bayes classiﬁer (NB) to identify web pages using
the direction and length of the packets. The na¨ıve Bayes
classiﬁer determines the conditional probability Pr ((cid:2)i|Y )
for a given vector of features Y using Bayes’ rule:
Pr ((cid:2)i|Y ) = Pr(Y |(cid:2)i) Pr((cid:2)i)
. The probability is computed
for all labels (cid:2)i with i = {1, 2, . . . , k} and k representing
the size of the privacy set (or number of labels being
considered), and the label with the highest probability is
selected as the classiﬁer’s guess. The probability Pr (Y |(cid:2)i)
is estimated using kernel density estimation over the ex-
ample feature vector provided during training, and Pr((cid:2)i)
is assumed to be 1/k. The feature vectors used by the LL
classiﬁer are derived from the count of the lengths of the
packets sent in each direction of the encrypted connection.
Speciﬁcally, the feature vector contains 2 · 1449 = 2898
integers that represent the number of packets seen in the
3http://www.kpdyer.com/
given vector with each of the potential direction and packet
length combinations (i.e., {↑,↓} × {52, . . . , 1500}). For
example, if we observe a packet of length 1500 in the ↓
direction (e.g., server to client) we would increment the
counter for (↓,1500).
B. Herrmann et al. Classiﬁer
Herrmann, Wendolsky and Fedarrath [8] (H) take a
similar approach to Liberatore and Levine, however they
make use of a multinomial na¨ıve Bayes (MNB) classiﬁer.
Like the na¨ıve Bayes classiﬁer with density estimation,
the multinomial na¨ıve Bayes classiﬁer attempts to estimate
the probability Pr ((cid:2)i|Y ) for each of the i = {1, 2, . . . , k}
potential labels and the given feature vector Y . The key
difference is that the multinomial classiﬁer does not apply