download or install activity.
We use four different techniques to identify candidates.
These four techniques focus on cases of repackaged malware,
distributed malware hosting, ad hoc malicious domains, and the
use of malware droppers. Our techniques are designed to be
fast so that they can work on large-scale datasets. Of course, we
cannot expect a single technique to handle all ways in which
malware is distributed. However, our experiments demonstrate
that the combination of our techniques provide good coverage.
Moreover, if needed, it is easily possible to add additional
techniques.
We now present the techniques used in the ﬁltering step
in detail. Keep Figure 1 for reference on how to interpret the
various symbols on the graphs that accompany them.
A. Detection of File Mutations
Our ﬁrst detection mechanism captures attempts by mal-
ware authors to bypass antivirus signatures. To avoid signature-
based detection at the end host, malware authors frequently
3
B. Detection of Distributed Hosting and Domain Fluxing
Cyber-criminals, like regular content providers, must en-
sure that their sites (and malware programs) are always avail-
able. Any downtime results in fewer compromised users, and
thus, a loss of revenue. For this reason, many cyber-criminals
replicate their infrastructure on multiple servers, much like
Content Delivery Networks (CDNs). Unlike CDNs, cyber-
criminals need to take one step further as they face defenders
that are actively trying to shut them down. Thus, malicious
distribution networks have different properties than benign
CDNs.
Our technique works in two steps. First, we attempt to
ﬁnd CDNs. We then use a classiﬁer to distinguish between
legitimate and malicious CDNs. As we show later, we found
that a decision tree classiﬁer performs well for our purpose.
For the ﬁrst step, we cluster domains so that two domains
end up in the same cluster if they host at least one identical
ﬁle (based on the ﬁle hash). That is, when we see web requests
to URIs that link to a ﬁle with hash h on domains d1 and d2,
respectively, both are put into the same cluster. We connect
two clusters when we ﬁnd a single ﬁle that has been hosted
by at least one element (domain) in each cluster. All clusters
that contain two or more elements are considered to be CDNs.
For the second step, we distinguish between malicious
and benign clusters (CDNs). This distinction is made using
a classiﬁer that we trained on a small data set of manually
labeled malicious and benign clusters. The classiﬁer leverages
six features, as described below:
Domain co-location: To reduce operating costs, some
cyber-criminals opt to host different domain names on the same
server (IP address), all serving the same malware (possibly,
under different names). Benign software is less likely to be
distributed in such manner, because a single host defeats the
idea of redundancy and load balancing. This feature is equal
to the number of hosts, divided by the number of domains.
Number of unique top-level domain names: To defeat
domain blacklisting, malware typically uses a variety of top-
level domains (TLDs). Legitimate CDNs might use several
domains, but they are all sub-domains under a single TLD.
For example, Facebook and Netﬂix use a single top-level
domain to distribute their ﬁles. Exceptions exist in a form of
legitimate software mirrors dispersed over different domains
that commonly serve open software.
Number of matching URI paths and Number of match-
ing ﬁle names: Legitimate CDNs are typically very well
organized, and every server replicates the exact directory
structure of the other ones. This is mainly for efﬁciency, which
is the central focus of a CDN. Malicious distributed hosting
instead focuses on avoiding blacklisting. Because of this, ﬁle
names and paths are often different. For these features, we
compute the number of URI paths (and ﬁlenames) that appear
in more than one domain in the cluster, divided by the number
of domains.
Number of URIs per domain: Malware distributors
usually have a small number of URLs serving executables
(often, a single one) from each of their domain. In contrast,
legitimate CDNs have vast directory structures. We leverage
Fig. 1. Legend to interpret graphs throughout the paper.
change their ﬁles. Typically, this is achieved by packing the
basic malware program, using a different (encryption) key for
each iteration. The technique of preparing and serving a new
variant of a malware program (or family) is called server-side
polymorphism. Alternatively, malware authors can prepare a
set of malicious executables, and serve a different one for each
request.
Our technique to detect ﬁle mutations (i.e., server-side
polymorphism) works by looking for download records that
are (i) associated with a single URI and (ii) download more
than n different ﬁles (determined by the hashes of the ﬁles). We
discuss the choice of a suitable threshold for n later. The nice
property of this technique is that increased efforts by cyber-
criminal to avoid being detected by antivirus signatures make
it easier for our technique to detect such activity.
Examples of malicious domains that
trigger this tech-
nique include cacaoweb.org, which hosts URIs that serve an
executable that changes every few hours (and that
is still
active at the time of writing). Other examples are the three
domains www.9530.ca, www.wgcqsf.com, and 585872.com.
All three domains host the same URL path /dlq.rar, which
contains malware that attacks Internet Explorer. This example
is particularly interesting because it shows that the malware
distributors are trying not only to evade antivirus signatures
by repackaging their malware (therefore exposing to detection
by our technique), but also to achieve robustness to blacklisting
and take-downs by using multiple domains, a behavior that is
handled by our subsequent techniques.
We expect that only a small minority of benign web sites
exhibit a similar behaviour, where a URI keeps pointing to
different executable ﬁles within a short time period. One reason
for this is that quickly rotating ﬁles negatively affects browser
and proxy caching, which in turn increases the page loading
time and the server load. Another reason is that such behavior
might cause unexpected timing effects, where the code that a
client receives depends on the precise time of access. We found
only one family of programs that seem to use such behavior,
namely, antivirus software itself. Since there are only a few
domains associated with well-known AV software, we simply
whitelist those domains.
4
redirection services forward requests to the dedicated host as
part of a successful drive-by download exploit. By hiding the
dedicated malware server behind multiple layers of redirection,
it is more difﬁcult to detect and, ultimately, to take down. Since
their sole purpose is delivering malware, dedicated hosts only
host a small number of executable payloads (often times, only
a single one) and at most a very small number of HTML
and JavaScript ﬁles to support malware delivery. This is very
different from a normal web server that hosts many different
HTML pages, CSS ﬁles, and JavaScript programs.
With this technique, we check for those dedicated malware
servers. To this end, we look for domains and IP addresses (in
case the server is accessed directly via its IP address) that are
involved in the download of a single executable ﬁle and host
at most one other URI that can be an HTML page. From the
set of candidates that this technique detects, we remove all
instances that serve an executable that we have seen hosted on
another domain (based on the ﬁle hash). The reason is that this
technique speciﬁcally checks for single, dedicated hosts that
are involved in a particular campaign. The previous technique
already handles cases where malware authors distribute their
samples over multiple hosts (domains).
As an example, we found dedicated servers (sub-domains)
hosted under the 3322.org domain. These servers were
used by the Nitol botnet and have since been taken
down after a legal action pursued by Microsoft [5]. More-
over, many executables
tech-
nique had names that
to execute
them (e.g., emule_ultra_accelerator_free.exe,
FreeTorrentViewer.exe). These names are unique with
respect to the rest of downloads that we observed.
that were found by this
try to lure the user
D. Detection of Exploit/Download Hosts
When a vulnerable client visits an exploit website and
the browser is successfully exploited, the shellcode silently
downloads the second-step malware binary. In some cases, the
host that serves the exploit is the same server that also delivers
the malware program. Reusing the same server for both exploit
and malware is a rational decision as the attacker knows that
the server is up and unblocked. After all, it just delivered the
infection.
Looking at the network trafﬁc of such an incident, we
observe two subsequent requests: one from the browser and
one from the shellcode. If the malware writer is not careful
and does not use the exploited browser’s code to download
the malware binary, the format of the second request will
differ from a typical browser request from that user. With
this technique, we leverage such discrepancies to identify
suspicious requests. In particular, we look for destinations that
are contacted more than once by the same IP address, but have
different User-Agent HTTP header ﬁeld values. Moreover,
we check whether the User-Agents of the subsequent
requests appear in requests that download the ﬁles. That is,
we compute a score for each User-Agent, as the number
of executables downloaded with that User-Agent, divided
by the total number of downloads made with that agent (we
count this during the Filtering Step). If this score is over a
certain threshold (discussed in Section VI-D4), we consider
the domain that is being contacted as a candidate for Nazca’s
Fig. 2. Candidates selected by the Distributed Hosting technique.
this difference as an indication of maliciousness. We note that
malware distributors, with some effort, could mimic this aspect
of a legitimate CDN. However, we found this to be quite
uncommon. For this feature, we count all the URIs across all
domains in the cluster, and we divide this by the number of
domains.
Served ﬁle types: File type diversity is also indicative:
while most domains serve different ﬁle types, malware CDNs
mostly serve executables. For this feature we divide the number
of executables that we have seen hosted on the cluster, divided
by the total number of ﬁles.
As an example of a malicious CDN, consider
three
URIs http://searchyoung.org/dfrg/dfrg, http://clickyawn.org/
dfrg/dfrg, and http://clickawoke.org/dfrg/dfrg. We see that the
same executable is offered on three different domains. The
ﬁle is a fake optimization software called “HDD repair.”
Here, all three domains offer the download under the same
path dfrg/dfrg. This is not always the case, as shown in
Figure 2. The malicious infrastructure in this ﬁgure is very
interesting, as it showcases how distributed malware hosting
tries to evade blacklisting by using multiple domains, servers,
payloads, ﬁle names, and URL paths. We explain the details
of this graph and the meaning of the different symbols in the
next section. For this discussion, it can be seen how pairs of
different URIs are linked together because they are linked to
identical ﬁles.
Cyber-criminals often decide to quickly run through many
domains, trying to stay ahead of domain blacklists. This is an
evasion technique called domain ﬂuxing. This evasive behavior
is also captured by our technique as such activity looks similar
to a CDN where only a single domain is used at any point in
time.
C. Detection of Dedicated Malware Hosts
One technique that cyber criminals use to make their in-
frastructure more robust is to set up dedicated backend servers
that deliver malware programs as part of a single domain.
Typically, these servers only host the malicious binary. Trafﬁc
5
last step. The assumption is that malicious download requests
often use the same (hard-coded) User-Agent values. Hence,
when the download request involves a User-Agent value
that is indicative of download requests in general, the corre-
sponding requests are considered suspicious. Otherwise, they
are discarded as likely benign.
There are legitimate cases that could trigger this technique
but result in false positives: a user could access the same site
with multiple browsers (for example, apps in iOS devices have
different User-Agent strings), or multiple users behind a
NAT or a fast-rotating DHCP might access a speciﬁc site, and
trigger our detection. We mitigate these issues by restricting
the maximum time delta   between a browser and a suspi-
cious User-Agent visiting a domain. In our experiments,
all malicious connections were issued within one minute of
the infection. Another mitigation that we did not employ is
ﬁltering out popular domains that are constantly hit by multiple
browsers.
An example of a domain identiﬁed via this technique is
pacedownloader.com. This site is a ﬁle-sharing site that hosts
bait software with hidden, malicious functionality, alongside
clean software. A user in our dataset downloaded GZIP2
decompressor from the culprit domain. Unfortunately,
this
software contained malicious code. Speciﬁcally, after being
launched, the Trojan (malware) component issued an HTTP
request to the same domains to download additional, unwanted
software (Funtool, a browser toolbar). This second request
had the User-Agent ﬁeld set to NSISDL/1.2. This is
a framework by NullSoft, designed to ease the creation of
installers. This framework is very popular among malware
writers because it allows downloading additional software at
runtime. Interestingly, this framework is abused so frequently
that it is blocked by Kaspersky’s AV software, and is detected
by Snort rules published by EmergingThreats.
V. DETECTION
The end result of Nazca’s candidate selection step is
a collection of URIs that have exhibited some suspicious
behavior, and thus, have been selected by one (or more) of our
candidate selection techniques. These techniques are designed
to efﬁciently ﬁlter the majority of benign trafﬁc; however, they
occasionally misclassify benign trafﬁc as suspicious, as they
miss contextual information to make a more accurate decision.
To remove false positives and focus the attention of the se-
curity administrator on large malware campaigns, we leverage
the scale of our dataset: in particular, the fact that it often
contains multiple clients’ interactions with various portions
of a malware distribution infrastructure (which might span
multiple hosts and domains). If enough of these interactions
are captured, they expose to Nazca the overall structure of
these malware distributions services and their interconnections.
We call this a “malicious neighborhood”; that is, a collection
of domains, hosts, executable ﬁles, and URLs that, bundled
together, deﬁne and compose one (or multiple) malicious
distribution services.
them into a botnet’s zombies. To receive commands from the
botnet’s C&C server, these clients connect to a variety of
IP addresses, and download their instructions. Note that the
overall structure of the malicious infrastructure is not visible
when we operate on a single connection or single host level.
Why are malware distribution infrastructure intercon-
nected? We see three fundamental reasons: cost effectiveness,
availability, and business deals among cyber-criminals.
As any web developer, cyber-criminals face the need of
maximizing their availability while limiting their expenses.
Their resources are therefore limited: servers and domain
registrations come with a price tag and need to be used
efﬁciently, so that proﬁts are maximized. Hence,
they co-
locate multiple malicious domains on the same server (e.g.,
Figure 2), and multiple malware specimens on the same
domain. Moreover, to achieve availability against blacklisting,
miscreants deploy multiple copies of their C&C servers and
initial attack domains, and discard them as they get blacklisted.
Finally, the economic ecosystem supporting malware is
complex, and cyber-criminals tend to specialize in offering a
particular service [6]. For example, some focus on compromis-
ing hosts and selling their bots. Others purchase access to bots
and use them as platform to send spam. Yet others develop
exploits that are sold to those that want to infect machines.
From the point of view of the malicious neighborhood graph,
we expect
to see clients that contact domains related to
attackers that infect machines. Afterwards, we see infected
machines connect to a different set of domains; those that are
related to the C&C infrastructure of the malware that has been
installed.
In this detection step, we build malicious neighborhood
graphs for each candidates produced by the candidate selection
step. If a candidate is actually malicious, it is likely (as we
have experimentally validated) that there are other malicious
candidates in the same graph, belonging to the same malicious
neighborhood. From this graph, we then compute for each
candidate a conﬁdence score on its likelihood to be malicious.
This score is based on how many other candidates appear in
the same graph and how close they are to the input candidate
in the graph.
A. Malicious Neighborhood Graph Generation
We deﬁne the malicious neighborhood as the collection of
malicious activities related to a suspicious candidate, which is
used as the starting point of the graph.
Neighborhood graphs are undirected and contain heteroge-
neous nodes that represent the following entities: IP addresses,
domain names, FQDNs, URLs, URL paths, ﬁle names, and
downloaded ﬁles (identiﬁed by their hash value). A simple
graph that we invite the reader to keep as a reference is
shown in Figure 1. It represents a zipped executable ﬁle being
downloaded from http://www.example.com/files-
/malware.zip.
An example of a complete malicious neighborhood is given
in Figure 3. Here, we have several clients that download
several malicious executables from a variety of sources, hosted
on several servers. The malware they are downloading turns
We build these graphs incrementally. At initialization, the
graph comprises only the seeding suspicious candidate;
it
can be a URL or a FQDN, depending on the technique that
generated it. We then execute a series of iterations to grow