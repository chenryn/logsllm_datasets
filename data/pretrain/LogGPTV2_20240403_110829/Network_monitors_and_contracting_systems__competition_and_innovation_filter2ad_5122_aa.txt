title:Network monitors and contracting systems: competition and innovation
author:Paul Laskowski and
John Chuang
Network Monitors and Contracting Systems:  
Competition and Innovation 
Paul Laskowski       John Chuang  
UC Berkeley 
{paul,chuang}@sims.berkeley.edu
ABSTRACT 
Today’s  Internet 
industry  suffers  from  several  well-known 
pathologies,  but  none  is  as  destructive  in  the  long  term  as  its 
resistance to evolution.  Rather than introducing new services, ISPs 
are  presently  moving  towards  greater  commoditization.    It  is 
apparent that the network’s primitive system of contracts does not 
align incentives properly.  In this study, we identify the network’s 
lack  of  accountability  as  a  fundamental  obstacle  to  correcting  this 
problem:    Employing  an  economic  model,  we  argue  that  optimal 
routes  and  innovation  are  impossible  unless  new  monitoring 
capability  is  introduced  and  incorporated  with  the  contracting 
system.    Furthermore,  we  derive  the  minimum  requirements  a 
monitoring  system  must  meet  to  support  first-best  routing  and 
innovation  characteristics.    Our  work  does  not  constitute  a  new 
protocol; rather, we provide practical and specific guidance for the 
design of monitoring systems, as well as a theoretical framework to 
explore the factors that influence innovation. 
Categories and Subject Descriptors 
C.2.4 [Computer-Communication Networks]: Distributed 
Systems; J.4 [Social And Behavioral Sciences]: Economics 
General Terms 
Economics, Theory, Measurement, Design, Legal Aspects. 
Keywords 
Innovation, Commoditization, Monitoring, Contracts, Incentives. 
1.  INTRODUCTION 
Many studies before us have noted the Internet’s resistance to new 
services  and  evolution.    In  recent  decades,  numerous  ideas  have 
been  developed  in  universities,  implemented  in  code,  and  even 
written  into  the  routers  and  end  systems  of  the  network,  only  to 
languish as network operators fail to turn them on on a large scale.  
The  list  includes  Multicast,  IPv6,  IntServ,  and  DiffServ.    Lacking 
the incentives just to activate services, there seems to be little hope 
of ISPs devoting adequate resources to developing new ideas.  In the 
long  term,  this  pathology  stands  out  as  a  critical  obstacle  to  the 
network’s  continued  success  (Ratnasamy,  Shenker,  and  McCanne 
provide extensive discussion in [11]). 
Permission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. To copy otherwise, or 
republish, to post on servers or to redistribute to lists, requires prior specific 
permission and/or a fee. 
SIGCOMM’06, September 11–15, 2006, Pisa, Italy. 
Copyright 2006 ACM 1-59593-308-5/06/0009...$5.00. 
On  a  smaller  time  scale,  ISPs  shun  new  services  in  favor  of  cost 
cutting  measures.    Thus,  the  network  has  characteristics  of  a 
commodity  market.    Although  in  theory,  ISPs  have  a  plethora  of 
routing policies at their disposal, the prevailing strategy is to route in 
the cheapest way possible [2].  On one hand, this leads directly to 
suboptimal routing.  More importantly, commoditization in the short 
term  is  surely  related  to  the  lack  of  innovation  in  the  long  term.  
When the routing decisions of others ignore quality characteristics, 
ISPs are motivated only to lower costs.  There is simply no reward 
for introducing new services or investing in quality improvements. 
In  response  to  these  pathologies  and  others,  researchers  have  put 
forth  various  proposals  for  improving  the  situation.    These  can  be 
divided according to three high-level strategies:  The first attempts 
to improve the status quo by empowering end-users.  Clark, et al., 
suggest  that  giving  end-users  control  over  routing  would  lead  to 
greater service diversity, recognizing that some payment mechanism 
must  also  be  provided  [5].    Ratnasamy,  Shenker,  and  McCanne 
postulate  a  link  between  network  evolution  and  user-directed 
routing [11].  They propose a system of Anycast to give end-users 
the  ability  to  tunnel  their  packets  to  an  ISP  that  introduces  a 
desirable protocol.  The extra traffic to the ISP, the authors suggest, 
will motivate the initial investment.  
The second strategy suggests a revision of the contracting system.  
This is exemplified by MacKie-Mason and Varian, who propose a 
“smart market” to control access to network resources [10].  Prices 
are set to the market-clearing level based on bids that users associate 
to  their  traffic.    In  another  direction,  Afergan  and  Wroclawski 
suggest  that  prices  should  be  explicitly  encoded  in  the  routing 
protocols [2].  They argue that such a move would improve stability 
and align incentives. 
third  high-level 
strategy  calls 
for  greater  network 
The 
accountability.    In  this  vein,  Argyraki,  et  al.,  propose  a  system  of 
packet obituaries to provide feedback as to which ISPs drop packets 
[3].  They argue that such feedback would help reveal which ISPs 
were  adequately  meeting  their  contractual  obligations.    Unlike  the 
first  two  strategies,  we  are  not  aware  of  any  previous  studies  that 
have 
the  pathologies  of 
commoditization or lack of innovation. 
accountability  with 
connected 
It is clear that these three strategies are closely linked to each other 
(for  example,  [2],  [5],  and  [9]  each  argue  that  giving  end-users 
routing  control  within 
is 
problematic).  Until today, however, the relationship between them 
has  been  poorly  understood.    There  is  currently  little  theoretical 
foundation  to  compare  the  relative  merits  of  each  proposal,  and  a 
particular  lack  of  evidence  linking  accountability  with  innovation 
and service differentiation.  This paper will address both issues. 
the  current  contracting  system 
We  will  begin  by  introducing  an  economic  network  model  that 
relates accountability, contracts, competition, and innovation.  Our 
model  is  highly  stylized  and  may  be  considered  preliminary:  it  is 
based  on  a  single  source  sending  data  to  a  single  destination.  
Nevertheless,  the  structure  is  rich  enough  to  expose  previously 
unseen  features  of  network  behavior.    We  will  use  our  model  for 
two main purposes: 
First, we will use our model to argue that the lack of accountability 
in  today’s  network  is  a  fundamental  obstacle  to  overcoming  the 
pathologies  of  commoditization  and  lack  of  innovation.    In  other 
words,  unless  new  monitoring  capabilities  are  introduced,  and 
integrated with the system of contracts, the network cannot achieve 
optimal routing and innovation characteristics.  This result provides 
motivation for the remainder of the paper, in which we explore how 
accountability can be leveraged to overcome these pathologies and 
create a sustainable industry.  We will approach this problem from a 
clean-slate perspective, deriving the level of accountability needed 
to sustain an ideal competitive structure. 
When we say that today’s Internet has poor accountability, we mean 
that it reveals little information about the behavior – or misbehavior 
– of ISPs.  This well-known trait is largely rooted in the network’s 
history.    In  describing  the  design  philosophy  behind  the  Internet 
protocols,  Clark  lists  accountability  as  the  least  important  among 
seven  “second  level  goals.”  [4]    Accordingly,  accountability 
received little attention during the network’s formative years.  Clark 
relates this to the network’s military context, and finds that had the 
network been designed for commercial development, accountability 
would have been a top priority.   
led 
to 
transparency  may  have 
Argyraki, et al., conjecture that applying the principles of layering 
and 
lack  of 
accountability [3].  According to these principles, end hosts should 
be  informed  of  network  problems  only  to  the  extent  that  they  are 
required to adapt.  They notice when packet drops occur so that they 
can perform congestion control and retransmit packets.  Details of 
where and why drops occur are deliberately concealed. 
the  network’s 
The  network’s  lack  of  accountability  is  highly  relevant  to  a 
discussion  of  innovation  because  it  constrains  the  system  of 
contracts. 
  This  is  because  contracts  depend  upon  external 
institutions to function – the “judge” in the language of incomplete 
contract theory, or simply the legal system.  Ultimately, if a judge 
cannot  verify  that  some  condition  holds,  she  cannot  enforce  a 
contract  based  on  that  condition.    Of  course,  the  vast  majority  of 
contracts never end up in court.  Especially when a judge’s ruling is 
easily predicted, the parties will typically comply with the contract 
terms on their own volition.  This would not be possible, however, 
without the judge acting as a last resort. 
An  institution  to  support  contracts  is  typically  complex,  but  we 
abstract  it  as  follows:  We  imagine  that  a  contract  is  an  algorithm 
that outputs a payment transfer among a set of ISPs (the parties) at 
every  time.    This  payment  is  a  function  of  the  past  and  present 
behaviors  of  the  participants,  but  only  those  that  are  verifiable.  
Hence, we imagine that a contract only accepts “proofs” as inputs. 
We will call any process that generates these proofs a contractible 
monitor.    Such  a  monitor includes metering or sensing devices on 
the physical network, but it is a more general concept.  Constructing 
a proof of a particular behavior may require readings from various 
devices  distributed  among  many  ISPs.    The  contractible  monitor 
includes  whatever  distributed  algorithmic  mechanism  is  used  to 
motivate ISPs to share this private information. 
Figure 1 demonstrates how our model of contracts fits together.  We 
make  the  assumption  that  all  payments  are  mediated  by  contracts.  
This  means  that  without  contractible  monitors  that  attest  to,  say, 
latency, payments cannot be conditioned on latency. 
Network 
Behavior 
Proof 
Monitor 
Contract 
Payments 
Figure 1: Relationship between monitors and contracts 
With this model, we may conclude that the level of accountability in 
today’s  Internet  only  permits  best  effort  contracts.    Nodes  cannot 
condition payments on either quality or path characteristics. 
Is  there  anything  wrong  with  best-effort  contracts?    The  reader 
might wonder why the Internet needs contracts at all.  After all, in 
non-network  industries,  traditional  firms  invest  in  research  and 
differentiate  their  products,  all  in  the  hopes  of  keeping  their 
customers  and  securing  new  ones.    One  might  believe  that  such 
market forces apply to ISPs as well.  We may adopt this as our null 
hypothesis: 
Null hypothesis: Market forces are sufficient to maintain service 
diversity and innovation on a network, at least to the same extent 
as they do in traditional markets. 
There is a popular intuitive argument that supports this hypothesis, 
and it may be summarized as follows: 
Intuitive argument supporting null hypothesis: 
1.  Access providers try to increase their quality to get more 
consumers. 
2.  Access providers are themselves customers for second hop 
ISPs, and the second hops will therefore try to provide high-
quality service in order to secure traffic from access 
providers.  Access providers try to select high quality transit 
because that increases their quality. 
3.  The  process  continues  through  the  network,  giving  every 
ISP a competitive reason to increase quality. 
We are careful to model our network in continuous time, in order to 
capture the essence of this argument.  We can, for example, specify 
equilibria in which nodes switch to a new next hop in the event of a 
quality drop. 
Moreover, our model allows us to explore any theoretically possible 
punishments  against  cheaters,  including  those  that  are  costly  for 
end-users  to  administer.    By  contrast,  customers  in  the  real  world 
rarely  respond  collectively,  and  often  simply  seek  the  best  deal 
currently  offered.    These  constraints  limit  their  ability  to  punish 
cheaters. 
Even with these liberal assumptions, however, we find that we must 
reject  our  null  hypothesis.    Our  model  will  demonstrate  that 
identifying  a  cheating  ISP  is  difficult  under  low  accountability, 
limiting the threat of market driven punishment.  We will define an 
index of commoditization and show that it increases without bound 
as  data  paths  grow  long.    Furthermore,  we  will  demonstrate  a 
framework  in  which  an  ISP’s  maximum  research  investment 
decreases hyperbolically with its distance from the end-user. 
To  summarize,  we  argue  that  the  Internet’s  lack  of  accountability 
must  be  addressed  before  the  pathologies  of  commoditization  and 
lack of innovation can be resolved.  This leads us to our next topic: 
How can we leverage accountability to overcome these pathologies?   
We approach this question from a clean-slate perspective.  Instead 
of focusing on incremental improvements, we try to imagine how an 
ideal industry would behave, then derive the level of accountability 
needed to meet that objective.  According to this approach, we first 
craft  a  new  equilibrium  concept  appropriate 
for  network 
competition.  Our concept includes the following requirements: 
First,  we  require  that  punishing  ISPs  that  cheat  is  done  without 
rerouting the path.  Rerouting is likely to prompt end-users to switch 
providers, punishing access providers who administer punishments 
correctly.    Next,  we  require  that  the  equilibrium  cannot  be 
threatened  by  a  coalition  of  ISPs  that  exchanges  illicit  side 
payments.  Finally, we require that the punishment mechanism that 
enforces contracts does not punish innocent nodes that are not in the 
coalition. 
The last requirement is somewhat unconventional from an economic 
perspective,  but  we  maintain  that  it  is  crucial  for  any  reasonable 
solution.  Although ISPs provide complementary services when they 
form  a  data  path  together,  they  are  likely  to  be  horizontal 
competitors  as  well.    If  innocent  nodes  may  be  punished,  an  ISP 
may  decide  to  deliberately  cheat  and  draw  punishment  onto  itself 
and its neighbors.  By cheating, the ISP may save resources, thereby 
ensuring  that  the  punishment  is  more  damaging  to  the  other  ISPs, 
which  probably  compete  with  the  cheater  directly  for  some 
customers.    In  the  extreme  case,  the  cheater  may  force  the  other 
ISPs out of business, thereby gaining a monopoly on some routes. 
Applying this equilibrium concept, we derive the monitors needed 
to  maintain  innovation  and  optimize  routes.    The  solution  is 
surprisingly simple: contractible monitors must report the quality of 
the rest of the path, from each ISP to the destination.  It turns out 
that  this  is  the  correct  minimum  accountability  requirement,  as 
opposed  to  either  end-to-end  monitors  or  hop-by-hop  monitors,  as 
one might initially suspect. 
Rest of path monitors can be implemented in various ways.  They 
may  be  purely  local  algorithms  that  listen  for  packet  echoes.  
Alternately, they can be distributed in nature.  We describe a way to 
construct a rest of path monitor out of monitors for individual ISP 
quality  and  for  the  data  path.    This  requires  a  mechanism  to 
motivate ISPs to share their monitor outputs with each other.  The 
rest of path monitor then includes the component monitors and the 
distributed  algorithmic  mechanism  that  ensures  that  information  is 
shared as required.  This example shows that other types of monitors 
may be useful as building blocks, but must be combined to form rest 
of path monitors in order to achieve ideal innovation characteristics. 
Our  study  has  several  practical  implications  for  future  protocol 
design.    We  show  that  new  monitors  must  be  implemented  and 
integrated  with  the  contracting  system  before  the  pathologies  of 
commoditization  and 
innovation  can  be  overcome.  
Moreover, we derive exactly what monitors are needed to optimize 
routes  and  support  innovation.    In  addition,  our  results  provide 
useful input for clean-slate architectural design, and we use several 
novel  techniques  that  we  expect  will  be  applicable  to  a  variety  of 
future research. 
lack  of 
The rest of this paper is organized as follows: In section 2, we lay 
out  our  basic  network  model.    In  section  3,  we  present  a  low-
accountability  network,  modeled  after  today’s  Internet.    We 
demonstrate  how  poor  monitoring  causes  commoditization  and  a 
lack of innovation.  In section 4, we present verifiable monitors, and 
show  that  proofs,  even  without  contracts,  can  improve  the  status 
quo.    In  section  5,  we  turn  our  attention  to  contractible  monitors.  
We show that rest of path monitors can support competition games 
with optimal routing and innovation.  We further show that rest of 
path monitors are required to support such competition games.  We 
continue by discussing how such monitors may be constructed using 
other  monitors  as  building  blocks.    In  section  6,  we  conclude  and 
present several directions for future research. 
2.  BASIC NETWORK MODEL 
A source, S, wants to send data to destination, D.  S and D are nodes 
on a directed, acyclic graph, with a finite set of intermediate nodes, 
V
,  representing  ISPs.    All  paths  lead  to  D,  and  every 
node not connected to D has at least two choices for next hop. 
{
,...2,1=
}N
 S 
D 
We will represent quality by a finite dimensional vector space, Q, 
called  the  quality  space.    Each  dimension  represents  a  distinct 
network  characteristic  that  end-users  care  about.    For  example, 
latency, loss probability, jitter, and IP version can each be assigned 
to a dimension.   
Qqi ˛ .  
To each node, i, we associate a vector in the quality space, 
This corresponds to the quality a user would experience if i were the 
 be the vector of all node 
only ISP on the data path.  Let 
qualities. 
NQ˛q
,...,
)nv
Of course, when data passes through multiple nodes, their qualities 
combine in some way to yield a path quality.  We represent this by 
an associative binary operation, *:
(
vv
, 2
1
operation reflects the characteristics of each dimension of quality.  
For example, * can act as an addition in the case of latency, 
multiplication in the case of loss probability, or a minimum-
argument function in the case of security. 
QQ ﬁ·
Q
*