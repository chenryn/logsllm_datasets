CRT显示器的输出画面会变得一片混乱，光怪陆离。
在PC产业如日东升的20世纪80年代，显卡是PC系统必备的关键部
件，而且价格不菲。于是以开发显卡为主业的多家公司相继出现，著名
的有1985年成立的ATI（Array Technology Inc.），1987年成立的Trident
Microsystems（中文名泰鼎）。两家公司都以研发显卡上的核心芯片组
而闻名。ATI公司的Wonder系列（ATI 18800）和Trident TVGA8800都
是VGA时代很有影响的显卡核心芯片。
 老雷评点 
在VGA时代，泰鼎是显卡领域的著名公司，老雷大学时所
购486电脑，搭配的便是TVGA显卡。但在后来的竞争中，泰鼎
逐步落后，于2012年解散。
8.1.2 硬件加速
1991年，S3公司（S3 Graphics, Ltd）推出了名为S3 86C911的图形
芯片，其最大的亮点是2D图形加速功能，可以通过芯片内的硬件单元
提高2D图形的绘制效果和速度。
举个简单的例子来解释2D图形加速的意义。假设我们要在屏幕上
显示一条斜线。因为屏幕上的每个像素点使用的是整数坐标，是离散
的，所以就需要通过一些近似算法来把连续的斜线映射成屏幕上离散的
一个个点。这个过程如果完全由软件来做，那么不仅占用CPU较久而且
效果可能不好。除了画斜线外，画圆和画其他图形或者对图形进行缩放
时也有类似的问题。S3的两位创立者（Dado Banatao和Ronald Yara）正
是看准了这个机遇，于1989年成立公司，用两年时间研发出了86C911，
结果一鸣惊人。产品名字中的911源自以速度著称的保时捷汽车。可以
说，S3公司就是为图形加速而生的。
1994年，3dfx Interactive公司成立，两年后，推出了名为巫毒
（Voodoo）的产品，其杀手锏是3D加速。第一代巫毒产品（Voodoo1）
不仅自身价格昂贵（约300美元），而且因为缺少普通的显示功能，还
需要用户同时配备一张普通显卡来一起工作，但这并没影响这款产品的
热销。3dfx Interactive公司依靠这款产品一夜成名，迅速成为显卡市场
的领导者。3D加速的主要应用便是3D游戏，巫毒系列显卡为3D游戏提
供了强大的动力，让PC游戏进入3D时代。3D游戏的发展反过来又进一
步推动3D加速技术的发展。二者相互推动，使3D加速和3D游戏成为20
世纪90年代的两大热门技术。
有了2D和3D加速技术后，显卡的用途更加广泛了，除了游戏之
外，还有工程建模。巨大的市场潜力吸引更多的公司加入这个领域。
1993年，Nvidia公司成立。1995年，芯片巨头英特尔推出i740显卡，正
式加入显卡领域的竞争。
1999年8月31日，Nvidia公司发布GeForce 256芯片[2]，将光照引擎
（lighting engine）、变换引擎（transform engine）和256位的四通道渲
染引擎（256-bit quadpipe rendering engine）集成到一块芯片中，并赋予
这块高度集成的芯片一个新的称呼，叫GPU（Graphics Processing
Unit）。从此，GPU之名逐渐流行，显卡成为旧的名字。
8.1.3 可编程和通用化
进入新千年后，显卡领域的竞争愈演愈烈。2000年年末，3dfx
Interactive公司陷入危机，申请破产失败，只好选择被Nvidia公司收购。
泰鼎和S3公司也因为跟不上创新的步伐而脱离第一阵线。英特尔依靠集
成在芯片组（北桥）中的集成显卡占据着低端市场。Nvidia和ATI公司
处在领先位置，争夺老大。
2001年，Nvidia公司发布第三代GPU产品——GeForce 3。值得说明
的是，上文提到的GeForce 256是第一代GPU，也是第一代GeForce，名
字中的256代表的是渲染引擎的位宽，不是产品的序号。
GeForce 3最大的亮点是可编程，最先支持微软DirectX 8引入的着色
器（shader）语言。
在GeForce 3之前，设计GPU的基本思路是把上层应用常用的复杂计
算过程用晶体管来实现，比如计算量比较大的各种2D和3D操作，这样
设计出的一个个功能模块称为固定功能（fixed function）单元，有时也
称为加速器，多个加速器连接起来便成为流水线（pipeline）。设计固
定功能单元的优点是速度快，缺点是死板和不灵活。而可编程的优点是
灵活度高，通用性好。当然，可编程方法也有缺点。首先，可编程方法
的速度通常慢于固定功能单元。其次，可编程引擎的效果更加依赖上层
软件，如果上层代码写得不好，或者与引擎的流水线结构配合得不好，
那么可编程方法的效果就可能很差。
那么到底是该多花资源做固定功能单元，还是集中资源做通用性更
好的可编程引擎呢？这是GPU设计团队中经常争论的一个问题。不同人
有不同的看法，同一个人在不同的时间也可能看法不同。通俗一点说，
固定功能单元直接满足需要，直截了当，见效快，立竿见影；而可编程
方法需要把各种应用中的通用逻辑抽象提炼出来，然后设计出具有通用
性的一条条指令，接着再编写软件实现各种应用。相对来说，后一种方
法的挑战更多，风险更大。
2003年，约翰·尼可尔斯（John Richard Nickolls）加入Nvidia公司的
GPU设计团队。约翰曾在Sun公司（Sun Microsystems）担任架构和软件
部门的副总裁，很熟悉并行计算，非常看好GPU在并行计算领域的前
景。
2006年11月8日，Nvidia公司发布Geforce 8800显卡，卡上的GPU名
叫G80，使用的是特斯拉微架构[3]。
G80最大的特色是使用通用处理器来替代固定功能的硬件单元，通
过多处理器并行来提高处理速度。G80引入了全新的流式多处理器
（Streaming Multiprocesor，SM）结构，使流处理器阵列成为GPU的核
心。G80中包含了128个流处理器（Streaming Processor，SP），每8个一
组，组成一个流式多处理器。G80把GPU的可编程能力和通用计算能力
提升到一个前所未有的高度，以通用计算来实现图形功能，革命性地把
图形和计算两大功能统一在一起。这种以通用处理器来替代以前的多个
分立着色器的做法，称为“统一化的流水线和着色器”（Unified Pipeline
and Shader），有时也称为“统一化的着色器架构”（Unified Shader
Architecture），又或者简称为统一化设计（Unified Design）[4]。
图8-2（a）是G80芯片的晶片照片（dieshot），图8-2（b）是主要
模块的描述。图中的SM即代表流式多处理器。G80一共有16个SM，分4
组均匀分布在芯片的4个黄金位置。从图中也可以粗略估计出通用单元
占据了芯片的大约一半面积。
（a）晶片照片            （b）布局描述
图8-2 G80的晶片照片和布局描述
G80的成功是空前的。G80显卡的各项性能明显超越竞争对手（ATI
Radeon X1950）以及自家的前一代产品。更重要的是，G80开创了新的
GPU设计方法，证明了使用通用处理器来加速图形计算不但是可行的，
而且是大有优势的。
2007年，Nvidia公司的CUDA计算模型发布，让开发者可以使用C
语言的扩展来开发各种应用，这进一步释放了G80架构的潜能，让GPU
逐步应用到通用计算领域，这为人工智能技术的大爆发奠定了计算方面
的基础。概而言之，G80不仅满足了图形加速方面的需求，还为GPU开
创出了通用计算的新道路。用著名科技媒体ExtremeTech的话来说，G80
重新定义了什么是GPU，以及它们能做什么。G80的成功在GPU历史上
具有里程碑的意义。2016年11月8日，G80发布10周年的时候，
ExtremeTech采访了G80研发团队的部分成员，记者询问道：“设计G80
时是否已经考虑到了通用计算用途？是有意为之，还是误打误撞，一石
二鸟，意外多了一项收获？”Nvidia GPU架构部门的副总裁约翰·丹斯金
（John Danskin）回答说，我们竭尽所能设计可编程能力优秀的图形引
擎，而后我们也确保它能很好地完成计算。他特别提到约翰· 尼可尔斯
（John Nickolls，图8-3），说他的愿景就是让GPU解决高性能计算的问
题。约翰·尼可尔斯长期耕耘在并行计算领域，曾合伙创建著名的小型
机公司MasPar Computer，也在Sun Microsystems公司工作过，于2003年
加入Nvidia公司。加入Nvidia后，他大力主张使用通用计算思想革新
GPU设计，是G80背后的一个伟大灵魂。可惜，约翰·尼可尔斯先生于
2011年因患癌症去世。
图8-3 G80的关键设计者约翰·尼可尔斯（1950—2011）
为了纪念约翰·尼可尔斯，Nvidia公司以及约翰·尼可尔斯的同事和
朋友们在约翰·尼可尔斯毕业的伊利诺伊大学设立了尼可尔斯奖学金
[5]。
8.1.4 三轮演进
前面简要回顾了GPU的演进过程，从最早的显示功能，到2D/3D加
速，再到通用可编程。经过这 3 个阶段的演进，一个单一功能的扩展卡
发展为支持多种类型应用并具有无限扩展能力的通用计算平台，其发展
前景难以估量。真可谓，三轮演进，终成正果。
  老雷评点 
打开20世纪90年代初的PC机箱，里面一般都插着几块卡，
比如声卡、显卡、超卡（超级I/O卡的简称）、电影卡等，如今
很多卡都灭亡了，只有显卡顽强地存活下来，而且生命力强劲，
不断发展。
值得说明的是，在这个演进过程中，前一阶段的成果并没有丢弃，
而是叠加在一起。比如，今天的GPU大多仍保留着最早的显示功能。总
体而言，今天的GPU包含四大功能：显示、2D/3D加速、视频编解码
（一般称为媒体）和通用计算（称为GPGPU）。图8-4中把这四大功能
模块画在了一起。
图8-4 现代GPU的四大功能模块
在开发GPU的团队中，通常也按上述四大功能来划分组织架构并分
配各种资源。
综上所述，经历三轮演进，传统的显卡演化成了今日的GPU。在这
场跨世纪的演进中，GPU积累了显示、2D/3D加速、媒体和通用计算四
大功能于一身。
8.2 设备身份
因为AI、区块链等潮流的推动，GPU产品常常供不应求。尽管在市
场中地位显赫，但是在计算机架构中GPU的身份没有改变过，始终属于
设备身份，比协处理器还低。今天的计算机架构是以CPU为核心的，
GPU一直属于设备。即使对于集成在CPU芯片中的GPU来说，虽然物理
上与CPU在一起，但是其身份仍是设备身份，以英特尔GPU为例，它在
PCI总线上的位置总是0 : 2.0（0号总线上的2号设备）。深刻理解这个基
本特征，对于学习GPU很重要，因为很多机制都是由这个基本身份问题
所决定的。本节简略探讨其中几个方面的机制。
8.2.1 “喂模式”
迄今为止，GPU还不能直接从磁盘等外部存储器加载程序。只能等
待CPU把要执行的程序和数据复制过来喂给它。本书把这种模式简称
为“喂模式”。
“喂模式”意味着GPU不独立，需要依靠CPU来喂它。不然，它就会
闲在那里，处于饥饿状态。或者说，GPU内虽然有强大的并行执行能
力，但如果没有CPU“喂”代码和数据过来，那么再强大的硬件也会空
置。
8.2.2 内存复制
“喂模式”决定了GPU端的代码和数据大多都是从CPU那边复制过来
的。对于独立显卡而言，这一点较好理解。对于集成显卡，其实很多时
候也需要复制。虽然集成的GPU常常使用一部分系统主内存作为显存，
但是这部分内存与CPU端的普通内存还是有很多区别的，这导致很多时
候还需要进行内存复制。
8.2.3 超时检测和复位
为了更好地管理GPU，CPU在给GPU“喂”任务后，通常会启动一个
计时器，目的是监视GPU的工作速度。如果GPU没有在定时器指定的时
间内完成任务，那么CPU端的管理软件就会重启GPU。这个机制在
Windows操作系统中有个专门的名字，称为超时检测和复位（Timeout
Detection and Reset，TDR）。Linux系统中也有类似的机制，似乎没有
专门的名字，本书将其泛称为TDR。从TDR机制来看，GPU像是工人，
CPU像是工头，工人如果跑错了路并堵在某个地方，工头会让它复位，
从头再来。
8.2.4 与CPU之并立
GPU不独立的根本原因是GPU上还没有自己的操作系统。从发展趋
势来看，GPU端将有自己的操作系统，与CPU端的操作系统并立或者将
其取代。只有到了那时候，GPU的设备身份才会彻底改变。
8.3 软件接口
因为GPU的设备身份，需要CPU把程序和数据喂给它。为了规范和
指导这个交互过程，CPU和GPU之间定义了多种接口，有些是行业内的
标准接口，有些是GPU厂商私有保密的。
8.3.1 设备寄存器
因为GPU从PC系统的显卡设备演变而来，所以通过设备寄存器与
其通信是最基本的方式。在几十年的演进中，设备寄存器的类型又分为
几种。在经典的PC系统中，通过固定的I/O端口来访问显卡。比如，下
面这几个I/O地址区间是给显卡使用的。
3B0～3BB：单色显示/EGA/VGA 视频和旧的打印适配器
3C0～3CF：视频子系统（Video Subsystem）
3D0～3DF：为视频保留的
打开Windows系统的设备管理器，单击“查看”菜单下的“按类型列出
资源”，仍可以看到上述I/O区域是给显卡用的。
0x000003B0～0x000003BB  Intel(R) HD Graphics 620  
0x000003C0～0x000003DF  Intel(R) HD Graphics 620  
在系统开机启动的时候，还依赖上面这些端口来对显卡完成基本的
初始化，让其可以工作。
I/O端口速度较慢，不适合传递大量数据。因此，PC系统中，一直
保留着一段物理内存空间给显卡用，其范围如下。
0xA0000～0xBFFFF  Intel(R) HD Graphics 620  
这样映射在物理内存空间的输入输出就是所谓的MMIO。直到今
天，MMIO仍是CPU和GPU之间沟通的主要方式。MMIO空间通常分为
几部分，其中一部分作为寄存器使用。第11章将以英特尔显卡为例对此
做更多介绍。