have a regex for a single direction, in which case we use “.∗”
for the other direction.) YAF contains at least two regexes
for each target protocol, and we indicate that using a 1 or 2
in the format name. The result is 12 diﬀerent formats.
Misclassiﬁcation evaluation. The misclassiﬁcation rates
for all 12 formats against the 6 classiﬁers appears in Figure 3.
Here (and throughout this section) the rate is calculated as
the number of TCP connections labeled as the target pro-
tocol by the classiﬁer, divided by the total number of TCP
connections generated when using that FTE format. Thus a
rate of 1.0 means complete misclassiﬁcation success, and 0.0
is complete failure. Throughout our evaluations, a connec-
tion that failed to be misclassiﬁed as the target protocol by
Format
appid-http
l7-http
yaf-http1
yaf-http2
appid-ssh
l7-ssh
yaf-ssh1
yaf-ssh2
appid-smb
l7-smb
yaf-smb1
yaf-smb2
Misclassiﬁcation Rate
appid
1.0
0.0
0.0
0.0
1.0
0.16
1.0
1.0
1.0
0.0
0.0
0.0
l7-ﬁlter YAF
1.0
0.16
1.0
1.0
1.0
0.16
1.0
1.0
1.0
0.38
1.0
1.0
0.0
1.0
0.0
0.0
0.32
1.0
0.31
0.21
1.0
1.0
0.04
0.04
bro
0.0
0.0
0.0
0.57
1.0
0.13
1.0
1.0
0.08
0.0
0.0
0.0
nProbe DPI-X
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
Figure 3: Misclassiﬁcation rates for the twelve DPI-
Extracted FTE formats against the six classiﬁers in
our evaluation testbed.
a DPI system was always marked as an unknown protocol,
regardless of the DPI system.
What Figure 3 reveals is that DPI-extracted regexes al-
ways succeed against the DPI system from which they were
extracted, and can even force misclassiﬁcation by diﬀerent
DPI systems. As an example of the latter, we need only look
at DPI-X, which is by far the easiest system to force misclas-
siﬁcation against despite having no information about its
operation. We conﬁrmed the proper operation of the device
by running a variety of control traﬃc, such as Facebook,
Gmail, and SSH, through the device, and found that our
results were indeed correct. While we still do not know the
exact DPI strategy used, our best guess is that DPI-X per-
forms minimalistic analyses, favoring performance and opti-
mistic labeling of protocols. These regexes were not eﬀective
against nProbe, and had varied success against bro. This can
be attributed to the latter DPI systems requiring slightly
more stringent protocol conformance.
Intersection formats. We also consider formats whose
regex R is the explicit intersection of multiple DPI regexes.
FTE based on such an intersection format will produce ci-
phertexts matching all of the individual regexes used to
form R. Using the intersection of the four DPI-extracted
formats for each target protocol resulted in formats with
perfect 1.0 misclassiﬁcation rates for appid, l7-ﬁlter, YAF, and
DPI-X. The rates against bro and nProbe are comparable to
those for the individual regexes.
4.2 Manually-Generated Regular Expressions
As our next strategy for producing regexes, we will code
them manually. Our FTE record layer makes this easy since
most developers are already familiar with regexes due to
their use in other programming contexts. Moreover, it turns
out to be very simple to build fast, simple regexes that
achieve perfect misclassiﬁcation for all classiﬁer/target pro-
tocol combinations in our evaluation set.
Coding regexes for FTE. We started by inspecting the
open-source DPI systems, in particular for cases from the
last section where the extracted regexes failed, in order to
educate regex design. For HTTP regular expressions, we
observed the following requirements.
l7-ﬁlter requires that
responses have an HTTP version of 0.9, 1.0, or 1.1; an
HTTP status code in the range of 100-599; and Connection,
Content-Type, Content-Length, or Date ﬁelds.
appid re-
quires that responses have a string of length greater than
zero following the status code, and that the status line is ter-
minated with \r\n. YAF requires that we have a valid HTTP
method verb for requests (i.e. GET, POST, etc.). nProbe re-
quires that we terminate HTTP messages with \r\n\r\n.
Finally, bro require that we have no payload for HTTP re-
quests, or a payload and a valid Content-Length ﬁeld — we
accommodate this requirement by not allowing a payload for
requests and specifying an FTE format parameter of m = 0.
(Section 3.1)
For SSH all classiﬁers require that the ﬁrst downstream,
and in some cases upstream, messages start with SSH-. Next,
l7-ﬁlter demands that the ﬁrst two messages in a stream start
with SSH-1.x or SSH-1.y. nProbe requires the ﬁrst messages
in an SSH stream to be less than or equal to 99 bytes long,
and we achieve this by setting our FTE format parameter
to k = 99 for both directions of traﬃc, which constricts
message lengths.
All classiﬁers in our evaluation require that SMB messages
have a valid SMB ﬁngerprint, which is the byte \xFF, fol-
lowed by SMB encoded in ASCII. In addition, nProbe requires
that message have a valid length that matches the length of
the message payload, that the length ﬁeld is located as the
ﬁrst 32-bit word in the message, and that SMB is encoded
as ASCII in the second 32-bit word. Here we encounter a
check that is not easily encoded as a regular language (or
avoided as above for nProbe’s checking of HTTP Content-
Length ﬁelds), at least if one wants to support all 232 possi-
ble lengths. However, we can simply use a speciﬁc value for
the length ﬁeld and provide an equivalently sized payload.
For the regexes in our experiments, we set the FTE format
parameter m to zero, meaning that we do not append any
raw AE ciphertext bytes.
Misclassiﬁcation evaluation. We speciﬁed regexes that
met the above requirements for each of the target proto-
cols. It took less than 30 minutes for one of the authors to
specify each regex and debug it by testing it against known
DPI engines. The resulting regexes achieved perfect mis-
classiﬁcation for all classiﬁer/target protocol combinations,
as shown in Figure 4. Every TCP connection was tagged as
the target protocol of our choosing.
4.3 Automatically-Generated
Regular Expressions
When we know the DPI systems and their classiﬁcation
methods, the DPI-extracted and manually-generated regexes
provide guaranteed evasion and optimal capacity. Unfortu-
nately, there are many cases where it is not possible to know
this information, like when the DPI classiﬁcation strategy
abruptly changes or when proprietary systems are used. In
these situations, we can use a simple but eﬀective process
to automatically generate regexes from network traﬃc sam-
ples using widely-available protocol parsers. This allows us
to implicitly learn FTE formats from data that is assumed
(or known) to pass DPI scrutiny without raising alerts. Al-
though other, more complex, methods of format discovery
are available [7, 8, 41, 50], we focus on well-known network
message formats to avoid unnecessary complexity while still
providing robust regex generation capabilities. The regex
generation process proceeds as follows.
1. Collect packet trace data for target protocol message.
2. Apply a parser to label message ﬁelds.
Format
Misclassiﬁcation Rate
manual-http
manual-ssh
manual-smb
auto-http
auto-ssh
auto-smb
appid
1.0
1.0
1.0
1.0
1.0
1.0
l7-ﬁlter YAF
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
bro
1.0
1.0
1.0
1.0
1.0
1.0
nProbe DPI-X
1.0
1.0
1.0
1.0
0.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
Figure 4: Misclassiﬁcation rates for the manually-
generated and automatically-generated FTE for-
mats against all six classiﬁers.
3. Create a set containing observed values for each ﬁeld,
called a dictionary.
4. Create a template for each message type by replacing the
values with placeholders for the associated dictionaries.
5. Convert each dictionary into a regex by concatenating
the values with an “or” operator between them.
6. For each template, replace the placeholders with the as-
sociated dictionary regexes.
7. Choose one or more of the resultant template regexes as
the language(s) used by the FTE system.
There are a number of ways this method can be tuned to
adjust the quality and capacity of the resultant language(s).
First, we can control the properties of the messages that
are collected in the packet trace data, such as their mes-
sage types or payload lengths. Data containing a single,
consistent message type will produce more coherent regexes
at the cost of smaller dictionaries, while a mix of message
types will produce much larger dictionaries with more ca-
pacity but with potentially inconsistent, low-quality regexes.
We can also control the regexes through the granularity of
the parsers used to break the data into ﬁelds. Fine-grained
parsing produces a greater number of dictionaries within
each template and, consequently, an increase in the number
of possible combinations among their values. Conversely,
coarse parsers will create templates that are more likely to
produce valid outputs, but with less overall capacity.
Regex generation. The packet trace data used to eval-
uate the security of the generated regexes was produced by
agents that randomly logged into and crawled HTTP, SMB,
and SSH servers. For HTTP, we used the wget utility to
download the front page of a random selection of web sites
on the Alexa Top 1000. SMB and SSH data was generated
by scripts that logged into local Linux and Windows servers,
randomly crawled the directory structure, accessed ﬁles, and
logged out several times over the course of a one-hour period.
We partitioned the captured data into groups based on their
message types and payload lengths. From these partitions,
we extracted client headers for HTTP POST requests, SMB
transaction requests, and SSH handshake banner messages.
The server messages that we use include HTTP 200 OK
responses, SMB transaction responses, and SSH handshake
banner messages. Each of these message types was parsed
using their respective Wireshark dissectors, and the highest-
capacity template regular expression was chosen for the FTE
format. Any remaining payload bytes not included in the
parsed message header were automatically replaced with a
regular expression that produced the appropriate number of
random bytes.
Misclassiﬁcation evaluation. Figure 4 presents the re-
FTE
format
avg.
DFA unrank
states
(ms)
intersection-http-downstream
intersection-smb-downstream
intersection-ssh-downstream
manual-http-downstream
manual-smb-downstream
manual-ssh-downstream