benchmarks, including IO-intensive and CPU-intensive appli-
cations. We measured the performance of the applications on
Hadoop, and also in isolation to remove the overhead-masking
effects of disk I/O, network transfers, and spawning of Hadoop
tasks. Before discussing our results, we brieﬂy describe each
application.
Application
LLOC
Size input
UserUsage
IoVolumes
Options
WordCount
Pi
Revenue
KeySearch
224
241
6098
103
88
96
125
41 GB
94 GB
1.4 MB
10 GB
8.8 MB
70 GB
1.4 MB
TABLE I: Applications used to evaluate VC3.
Size E−
(vc3)
18 KB
16 KB
42 KB
18 KB
15 KB
16 KB
12 KB
map tasks
665
1530
96
162
16
256
96
UserUsage and IoVolumes: Real applications that process
resource usage information from a large compute/storage
platform consisting of tens of thousands of servers. UserUsage
counts the total process execution time per user. IoVolumes
is a join. It ﬁlters out failed tasks and computes storage I/O
statistics for the successful tasks.
Options: Simulates the price of European call options using
Monte Carlo methods [42]. The large size of the application
in terms of LLOC (see Table I) stems from the inclusion of a
set of optimized mathematical functions.
WordCount: Counts the occurrences of words in the input.2
Pi: Benchmark that statistically estimates the value of Pi.3
Revenue: Reads a synthetic log ﬁle of users visiting websites
and accumulates the total ad revenue per IP (from [49]).
KeySearch: Conducts a known plaintext attack on a 16-byte
message encrypted with RC4 [63].
All experiments ran under Microsoft Windows Server 2012
R2 64-Bit on workstations with a 2.9 GHz Intel Core i5-4570
(Haswell) processor, 8 GB of RAM, and a 250 GB Samsung
840 Evo SSD. We used a cluster of 8 workstations connected
with a Netgear GS108 1Gbps switch. All code was compiled
with the Microsoft C++ compiler version 18.00.30501 for x64,
optimizing for speed. We compiled our 7 applications in four
conﬁgurations:
baseline runs the applications on plaintext data and with-
out following the job execution protocol. Also, no performance
penalty for enclave transitions (TLB ﬂush, delay cycles, and
swapping of the stack) is applied and unnecessary copying of
data across (non-existent) enclave boundaries is avoided.
vc3 runs the same application on VC3 with encrypted
mapper and reducer inputs and outputs. Sizes of the E− DLL
range from 12 KB for KeySearch to 42 KB for Options (see
Table I); the generic E+ DLL has a size of 210 KB. The
enclave memory size was set to be 512 MB and the cost of
an enclave transition (including interrupts) to one TLB ﬂush
and 1,000 delay cycles. This version provides the base security
guarantees of VC3.
vc3-w uses the same conﬁguration as vc3, but applications
were compiled to further guarantee region-write-integrity.
2http://wiki.apache.org/hadoop/WordCount
3http://hadoop.sourcearchive.com/documentation/0.20.2plus-pdfsg1-1/
PiEstimator 8java-source.html
5050
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:24 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 5: Execution time of running MapReduce jobs in a Hadoop cluster
over typical input data-sets. Running times are normalized to the perfor-
mance of running the same job in normal mode and with unencrypted data
(baseline). Note: vc3-w and vc3-wr correspond to vc3 with extra
region-write-integrity checks and region-read-write-integrity checks respec-
tively.
Fig. 6: Execution time of running the map phase of MapReduce jobs in
isolation over typical input data-sets. Running times are normalized to the
performance of running the same computation in the baseline conﬁgura-
tion.
vc3-wr uses the same conﬁguration as vc3, but applica-
tions were compiled to further guarantee region-read-write-
integrity.
A. Performance on Hadoop
We measured the execution times of baseline and vc3 in
an unmodiﬁed Hadoop environment. We used the Hortonworks
distribution of Hadoop 2 (HDP 2.1) for Windows with 8
worker nodes (one per workstation). We used the default con-
ﬁguration options for resource management, and conﬁgured
our jobs to use 8 reduce tasks; except for Pi, Options, and
KeySearch that conceptually use 1. We ran each job and each
conﬁguration at least 10 times and measured the execution
time. To facilitate comparisons, we normalized the running
times with the average running time for each job using the
baseline conﬁguration. Figure 5 plots the average ratios
for each job and conﬁguration, and the values of two standard
deviations below and above each average.
Figure 5 shows that vc3’s performance is similar
to
baseline; the differences in performance are well below
the experimental variability for all jobs. vc3’s overhead is
negligible with its base security guarantees. When introducing
the write and read-write integrity checks, the performance
overhead increases on average by 4.5% and 8% respectively.
The increased overhead is a small price for the extra security
guarantees. We believe these results show that VC3 can be
used in practice to provide general-purpose secure cloud
computation with good performance.
B. Performance in Isolation
When running applications, Hadoop performs many activities,
such as spawning mappers and reducers, waiting for disk I/O,
network transfers, and others, that may mask the overheads of
VC3. To better understand the performance impact of VC3 on
the execution times of individual map and reduce tasks, we ran
5151
the mappers and reducers in isolation, i.e., on a single machine
without Hadoop. We repeated each experiment 10 times, and,
as in Section X-A, we normalize using the average of the
baseline run. Figure 6 plots the average ratios for the map
tasks, as well as the values of two standard deviations below
and above the average. (The results for reduce tasks are similar
— we omit them for brevity.)
On average, vc3’s overhead was 4.3% compared to
baseline, vc3-w’s was 15.3%, and vc3-wr’s was 24.5%.
The overheads were negligible for the three compute intensive
jobs (Key Search, Options, and Pi); these jobs spend little
time in copying and encryption/decryption operations, and
most of the time they compute using plain-text data off of the
processor’s caches; in addition, for these jobs the compiler was
effective at eliding checks on safe memory accesses, and hence
the overheads of vc3-w and vc3-wr are also negligible.
The IoVolumes and UserUsage jobs were slower than
baseline in all conﬁgurations. The IoVolumes(UserUsage)
job was 23.1%(6.1%), 41.4%(23.6%) and 63.4%(55.3%)
slower in the vc3, vc3-w, and vc3-wr conﬁgurations
respectively. The overheads are higher in these cases, because
these applications are IO-intensive. Since they perform little
computation, the relative cost of encryption is higher. Revenue
and WordCount are also IO-intensive, but these applications
implement a combine operation which increases the compu-
tation performed at the mapper, hence reducing the relative
cost of encryption. The combine operation performs a group-
by of the key-value pairs generated by the map function, and
calls a combine function that performs a partial reduction
at
the mapper. This is a common optimization to reduce
network trafﬁc (IoVolumes does not implement combining,
which contributes to its larger overhead). We thus observe little
performance difference between baseline and vc3 for Rev-
enue and WordCount. The write(read-write) integrity checks
increased their running times by 18%(26%) and 22%(27%)
respectively. The performance differences between vc3 and
vc3-w/vc3-wr are due to the region self-integrity checks
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:24 UTC from IEEE Xplore.  Restrictions apply. 
and they vary according to the ability of the compiler to check
if memory accesses are safe at compile-time.
We now turn our attention to the performance difference
between baseline and vc3. This difference is due to:
(i) copying data to and from the enclave, (ii) encryption
and decryption operations, and (iii) enclave transitions (either
due to normal operations or due to system interrupts). We
measure the copy operations and the total encryption and
decryption times and use that to explain the difference in the
execution times of vc3 versus baseline. We ﬁnd that the
crypto(copying) operations contributed 13.3(4.8) percentage
points for IoVolumes; the crypto operations dominated the
overhead for UserUsage. Despite the use of hardware accelera-
tion to speed up encryption and decryption (with the AES-NI
instructions, see section IX), there is a performance penalty
for using encrypted data; this is unavoidable in our setting.
We believe that in all cases the overheads are reasonable for
the provided security guarantees. Moreover, when run as part
of Hadoop jobs, these overheads have small (if any) impact
on the total run time (Figure 5).
C. Effectiveness of region self-integrity
We also conducted fault-injection experiments to verify the
effectiveness of the region self-integrity invariants. We wrote
a tool that injects three types of faults in the source code
of applications: writes to a random address outside of the
enclave, reads from a random address outside the enclave, and
pointer dereferences that corrupt a return address inside the
enclave. For each type of fault, we conducted 10 experiments
per application. In all cases the region self-integrity checks
caught the invalid access and stopped the application.
XI. RELATED WORK
Applications of SGX were ﬁrst discussed in [27]. Haven [9] is
a recently proposed SGX-based system for executing Windows
applications in the cloud. Haven loads a given application
together with a library OS variant of Windows 8 into an
enclave. Haven makes a different trade-off between security
and compatibility: it can run unmodiﬁed Windows binaries, but
its TCB is larger than VC3’s by several orders of magnitude.
Unlike VC3, Haven neither guarantees integrity for distributed
computations, nor does it provide our region self-integrity
properties. Brenner et al. presented an approach to run Apache
ZooKeeper in enclaves [14].
Several systems protect conﬁdentiality of data in the cloud.
Fully homomorphic encryption and multiparty computation
[21], [22] can achieve data conﬁdentiality, but they are not ef-
ﬁcient enough for general-purpose computation. CryptDB [50]
and MrCrypt [61] use partial homomorphic encryption to
run some computations on encrypted data; they neither pro-
tect conﬁdentiality of code, nor guarantee data integrity or
completeness of results. On the other hand,
they do not
require trusted hardware. TrustedDB [7], Cipherbase [6], and
Monomi [64] use different forms of trusted hardware to
process database queries over encrypted data, but they do not
protect the conﬁdentiality and integrity of all code and data.
5252
Monomi splits the computation between a trusted client and an
untrusted server, and it uses partial homomorphic encryption
at
the server. Mylar [51] is a platform for building Web
applications that supports searches over encrypted data.
Several systems combine hardware-based isolation [37],
[46], [59] with trusted system software [17], [28], [36], [38],
[54], [58], [69], which is typically a trusted hypervisor. The
Flicker [39] approach uses TXT [31] and avoids using a trusted
hypervisor by time-partitioning the host machine between
trusted and untrusted operation. Virtual Ghost [18] avoids
using a trusted hypervisor and specialized hardware-based
isolation mechanisms by instrumenting the kernel.
Some systems allow the user to verify the result of a
computation without protecting the conﬁdentiality of the data
or the code [48]. Pantry [13] can be used to verify the integrity
of MapReduce jobs which are implemented in a subset of C.
Pantry incurs a high overhead. Hawblitzel et al. presented the
concept of formally veriﬁed Ironclad Apps [26] running on
partially trusted hardware. They report runtime overheads of
up to two orders of magnitude.
Several security-enhanced MapReduce systems have been
proposed. Airavat [52] defends against possibly malicious
map function implementations using differential privacy. Se-
cureMR [67] is an integrity enhancement for MapReduce that
relies on redundant computations. Ko et al. published a hybrid
security model for MapReduce where sensitive data is handled
in a private cloud while non-sensitive processing is outsourced
to a public cloud provider [33]. PRISM [12] is a privacy-
preserving word search scheme for MapReduce that utilizes
private information retrieval methods.
XII. CONCLUSIONS
We presented VC3, a novel approach for the veriﬁable and con-
ﬁdential execution of MapReduce jobs in untrusted cloud en-
vironments. Our approach provides strong security guarantees,
while relying on a small TCB rooted in hardware. We show
that our approach is practical with an implementation that
works transparently with Hadoop on Windows, and achieves
good performance. We believe that VC3 shows that we can
achieve practical general-purpose secure cloud computation.
REFERENCES
[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-Flow
In ACM
Integrity: Principles, Implementations, and Applications.
Conference on Computer and Communications Security (CCS), 2005.
[2] P. Akritidis, C. Cadar, C. Raiciu, M. Costa, and M. Castro. Preventing
memory error exploits with WIT. In IEEE Symposium on Security and
Privacy, 2008.
[3] I. Anati, S. Gueron, S. Johnson, and V. Scarlata. Innovative technology
for CPU based attestation and sealing. In Workshop on Hardware and
Architectural Support for Security and Privacy (HASP), 2013.
[4] Apache Software Foundation. Hadoop. http://wiki.apache.org/hadoop/,
Accessed: 11/05/2014.
[5] Apache Software Foundation. HadoopStreaming. http://hadoop.apache.
org/docs/r1.2.1/streaming.html, Accessed: 11/05/2014.
[6] A. Arasu, S. Blanas, K. Eguro, R. Kaushik, D. Kossmann, R. Rama-
In
murthy, and R. Venkatesan. Orthogonal security with Cipherbase.
Conference on Innovative Data Systems Research (CIDR), 2013.
[7] S. Bajaj and R. Sion. TrustedDB: A trusted hardware-based database
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:08:24 UTC from IEEE Xplore.  Restrictions apply. 
with privacy and data conﬁdentiality. In IEEE Transactions on Knowl-
edge and Data Engineering, volume 26, 2014.
[8] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho, R. Neuge-
bauer, I. Pratt, and A. Warﬁeld. Xen and the art of virtualization. In
ACM Symposium on Operating Systems Principles (SOSP), 2003.
[9] A. Baumann, M. Peinado, and G. Hunt. Shielding applications from