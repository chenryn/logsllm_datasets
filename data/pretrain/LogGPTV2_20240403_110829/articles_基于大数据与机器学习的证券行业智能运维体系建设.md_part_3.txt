3) 组建合适团队来实施 AIOps。团队应该具备几个特征：
 了解金融运维领域的场景特点，明白运维的标准，逻辑，原则
 有丰富行业运维经验及专家团队
 对现有 AI 技术充分了解和掌握，学术界的算法论文支持
 深入理解软件产品的设计理念
 对运维领域的技术熟悉（比如数据库/中间价/监控/容器技术、CI/CD、
问题诊断等）
2.2.2 AIOps 系统部署分析
经过评估和分析项目组建议，可以参考以下路径图来建设：
光大证券已经建立了较完善的运维监控系统，收集了比较全面的运维指标数
据(阶段一)，企业级的大数据平台建设完善（阶段二）。因此从阶段三至阶段十
是大部分用户需要考虑的下一步实施路径图，通过从最底层基本数据/平台开始
考虑，逐步构建智能化运维平台及金融类业务场景，实现数据中心全覆盖，最终
建立自有人工智能算法模型，完成智能洞察、智能定位、智能分析的运维系统建
设。
2.3 专家团队支持
2.3.1 清华 NetMan 实验室
本项目在算法支持上，与清华大学NetMan 实验室合作共研，共同推进智能
运维方案的落地实施，团队拥有 20 名 AI 运维方向博士、硕士组成的研究团队，
在国际顶级会议上发表论文100 余篇，是国内最顶尖、国际一流的AI运维团队。
团队领军人物裴丹教授，清华大学计算机系长聘副教授，国家青年千人计划专家，
前 AT&T 研究院主任研究员，美国 UCLA 计算机最佳博士论文。学术界资深的专
家团队的大力支持，保障智能运维体系建设的落地能够得到专业的理论指导，结
合光大证券的运维专家的经验知识，为智能运维体系在光大证券的落地打下了坚
实的基础。
2.3.2 日志易团队
本项目与日志易公司进行合作，负责数据的采集、分析、供数工作。作为国
内日志分析领域领导者，日志易已为近百家金融客户提供日志产品和日志分析服
务，拥有核心技术，已获得 8 项软件著作权，并申请了 17 项日志搜索分析方面
的技术发明专利。将采集的数据通过处理为智能算法需要的标准格式数据，保障
智能运维数据采集的实时性、准确性、完整性、可用性，为智能运维的落地夯实
了基础。
第 章运维数据的采集
3
3.1 运维数据种类
数据中心运维数据按照在AIOps的使用目的划分主要可以分为4大类，分别
为：静态数据、动态数据、模型数据以及脱敏数据。
3.1.1 静态数据
静态数据主要包含CMDB数据、变更管理数据、流程管理数据、SLA管理以及
平台的配置信息数据等内容。此类数据的特点是：
 在一定时间范围内是固定的；
 在AIOps平台中为动态数据分析提供基础配置信息；
 在平台启动时，部分静态数据需要加载到内存数据库中，作为平台启动
的前提；
静态数据一般保存在结构化数据库中或者大数据平台的 Hive 平台，一般执
行点到点的数据查询，数据的增删改动作较少。
3.1.2 动态数据
动态数据主要包含各类监控指标数据、各类日志数据以及第三方扩展数据。
此类数据的特点是：
 固定的轮巡时间获取的数据；
 作为基础数据，在进行数据分析时，需要通过数据清洗才能成为样本数
据；
 动态数据会按照使用场景保存到不同的大数据组件，数据分析数据主要
保存在Hive数据库，而日志检索功能数据主要保存到 Elasticsearch 中；
 需要根据不同的分析场景明确数据的保管周期以及销毁方式；
 保存过程中，还要区分冷热数据的应用场景，提高业务查询效率；
不存在修改和删除动作，只有查询处理。
3.1.3 模型数据
模型数据主要是按照不同的算法要求，完成数据清洗后的样本数据或者标签
数据。另外在模型数据中，还包括了另一类特殊数据，即知识图谱数据。由于金
融业是最早展开系统运维的一个行业分支，因此，在金融行业中，大量运维经验
被积累下来，但是一直没有形成知识体系，并且被利用在故障排查分析之中。因
此，在AIOps的平台之上，我们会建立知识图谱数据体系，帮助模型进行数据计
算。模型数据所具有的特点为：
 数据样本会经常更新；
 标签会随着数据样本的更新而产生变化；
 知识图谱在不断的更新中；
 新的数据样本对于模型准确度具有时效影响。
3.1.4 脱敏数据
数据脱敏主要是针对数据在页面显示过程中，对于敏感数据进行数据处理之
后进行显示。由于金融行业大量用户数据属于敏感私密数据，因此数据脱敏必须
被纳入AIOps的考虑范围。另外，由于某些数据还会进行加密操作，那么对于加
密的数据是不适合作为我们分析数据的，这个也需要在工作前期就进行清晰识别。
3.2 运维数据的采集
采集端采用HekaAgent，一款基于Go语音编写的日志采集工具，支持Windows、
Linux、AIX 等多种操作系统，可以通过界面配置直接采集文件、性能指标、收
集Syslog，日志收集完成后进入到数据接收模块Collector，并实时写入Kafka
消息队列中，通过流处理引擎 Logriver 做 ETL 处理后写入 Elasticsearch 引擎
Yottasearch 中。用户可以通过前端应用模块 Yottaweb 调用搜索处理模块
Splserver直接对入库的日志进行快速检索和分析。
关系图如下：
日志采集过程中，HekaAgent 对每条采集数据根据不同的数据源添加系统源
信息，以 appname、tag、ip、source 等方式进行标注，方便后续的日志查询和
分拣。
3.2.1 数据采集架构
数据采集管理系统主要作用是实现对数据采集情况的运行，各个采集数据的
程序的状况，数据的记录数量，采集源，目标源配置信息，进程状态的控制等进
行管理和配置。同时也可以通过本系统中手工录入或通过接口批量导入数据。若
今后需要建立新的数据来源，可以根据需要在数据采集管理系统中进行添加。
数据采集系统的框架如下图所示：
中间件日志，应用日志可以通过 Heka 实时采集，Heka 支持多级转发，同时
Heka支持自动负载均衡，自动能将日志分发到多个Collector。系统日志可以通
过Syslog转发到Collector。Collector可以定时主动采集数据库表数据以及第
三方应用数据。Collector接收到数据后，验证数据完整性，转发到分布式Kafka
消息队列中缓存。
3.2.2 数据采集模式
生产环境智能运维系统的数据采集主要有4种方式：
1) 对业务系统文本日志数据采用通过HekaAgent的方式获得数据，并根据需
要对数据进行汇总、分析、展示等。数据采集一般分为实时增量获取、按
非工作时间段获取（避免对业务运行时间造成网络带宽占用）。
2) 对于无法自动获取的源数据，将数据制作成符合格式要求的文件（如
EXCEL、CSV等），通过 ftp或其他服务存放在指定的文件系统中，采集系
统通过HekaAgent服务进行采集。另外对于数据库表数据，直接可以通过
Collector主动定时或者增量采集表数据。这部分数据主要为我司的资产
设备信息、机房机柜位置分布信息、交易统计数据、系统的性能数据等。
3) 其他应用开发商所开发的web应用服务数据提供接口的话，可以通过平台
API接口进行数据的对接。
4) 对于既无法通过数据采集接口自动获取、又无法实现文件导入的数据，通
过系统web界面录入数据。
数据采集客户端支持在各种不同类型操作系统上的运行。从功能性的角度，
支持如下特性：
 支持自动识别多行规则
 支持自动识别字符编码
 支持自动识别及自定义时间戳解析规则
 支持行首模式匹配
 支持子目录递归
 支持正则方式的目录和文件名过滤
 支持黑、白名单设置
 支持元信息上送，包括主机名、目录名、文件名、标签等
 支持对压缩文件的直接读取
 支持对资源占用控制，如CPU、内存、网络流量等
 支持压缩传输和加密
3.3 数据处理
数据处理分为从数据缓存-》数据处理-》数据存储三阶段，数据收集层直接
接收采集客户端上送的数据，实时写入到 Kafka Topic，流处理引擎 Logriver
从Kafka直接消费数据进行格式化处理存入到搜索引擎Yottasearch中，同时提
供 SparkStreaming 流处理和 Spark 离线处理等多种处理方式，按照不同数据需
求者的要求提供数据。
架构图如下：
3.3.1 数据缓存
Kafka 用于消息的持久化和缓存。该系统使用磁盘文件做持久化，顺序进行
读写，以 append 方式写入文件。为减少内存 copy，集群使用 sendfile 发送数
据，通过合并 message 提升性能。集群本身不储存每个消息的状态，而使用
（consumer/topic/partition）保存每个客户端状态，大大减小了维护每个消息
状态的麻烦。在消息推拉的选择上，集群使用拉的方式，避免推的方式下存在的
各个客户端的处理能力、流量等不同产生不确定性。以多机形式形成集群，建议
3台或3台以上奇数台服务器组建，并且支持分区副本。
模块架构如下：
3.3.3 数据处理
平台使用流式处理引擎Logriver，构建的高性能、分布式日志处理架构
可以每秒钟解析10万条日志，每天可以处理TB级的日志量，而且处理延时
非常短，可以搜索、分析几秒钟之前产生的日志。
流式计算集群具有如下特性：