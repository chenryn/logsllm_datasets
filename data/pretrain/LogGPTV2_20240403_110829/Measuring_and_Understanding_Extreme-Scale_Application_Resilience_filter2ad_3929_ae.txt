### 优化后的文本

#### 数据概览
下表展示了XE和XK节点上应用程序的运行数据，包括总运行次数、成功百分比和失败百分比。

| 运行次数 | 成功率 (%) | 失败率 (%) | 总运行次数 | 成功率 (%) | 失败率 (%) |
|----------|-------------|-------------|------------|-------------|-------------|
| 892,146  | 97.4%       | 2.2%        | 35,277,529 | 70.5%       | 29.5%       |
| 760,954  | 69.8%       | 30.1%       | 28,040,129 | 72.8%       | 27.2%       |
| 14,946   | 88.5%       | 7.2%        | 13,905,226 | 89.2%       | 10.8%       |
| 1,674    | 75.1%       | 25.5%       | 7,002,353  | 80.7%       | 19.3%       |
| 77,959   | 99.4%       | 0.5%        | 6,225,259  | 88.9%       | 11.1%       |
| 21,342   | 76.0%       | 15.8%       | 1,527,814  | 74.3%       | 25.7%       |
| 9.5%     | 90.2%       | 10,445,842  | 32.5%      | 67.5%       |
| 11,730   | 60.0%       | 34.8%       | 1,288,745  | 85.7%       | 14.3%       |
| 286,673  | 59.1%       | 40.9%       |            |             |             |
| 9,962    | 59.8%       | 36.3%       |            |             |             |
| 1,535,754|             |             |            |             |             |

#### 应用程序实例
- **rmg**: 一种基于MPI/OpenMP的实时多网格算法实现，用于模拟电子结构以预测和解释材料性质（高HSN负载）。
- **vmd**: 一种分子可视化程序，用于显示、动画和分析生物分子系统。
- **spectrum**: 一种基于MPI/OpenMP的petascale代码，用于模拟波传播（高HSN负载）。

#### MNBF比较
XE应用的MNBF通常大于XK应用。表V显示，所有分析的应用程序中，Blue Waters应用在XE节点上的MNBF大于在XK节点上的MNBF。影响MNBF的主要因素有三个：(i) 应用特性（持续时间和节点小时数），(ii) 应用级检查点/重启机制的有效性，(iii) 基础平台的可靠性（即XE和XK节点、互连和文件系统）。

##### A. 节点小时数和持续时间
图8(a)和(b)分别显示了因系统错误而失败的XE和XK应用程序的节点小时数（即节点数×应用持续时间）的直方图和累积密度函数。平均而言，XE和XK应用程序在系统错误暴露时分别在732和46个节点小时内失败。XE应用程序更可能在不到一个节点小时内失败（18% vs. 1.8%）。这些失败通常是由于系统故障或部分恢复期间启动的应用程序导致的，保护机制（如热交换和检查点/重启）在这种情况下无效。

##### B. 检查点/重启代码
使用检查点/重启技术的应用程序（表V中粗体字体）显示出显著更大的MNBF。我们对这些应用的代码进行了深入分析，发现它们在错误检测和检查点存储方面存在显著差异。例如，使用Charm++框架开发的应用程序比使用MPI/OpenMP的应用程序具有25%更大的MNBF。具体来说，namd和rhmd等应用在相同类型的节点上显示出相似的MNBF值。

##### C. 系统级测量比较
为了提供平台故障和应用故障之间的比较，我们分析了供应商在测量期间收集的故障报告数据。结果如表VI所示。通过比较表V和表VI中的MNBF值，我们观察到：
- 使用检查点/重启的应用程序的MNBF接近或超过单个节点的MNBF。
- 不使用检查点/重启技术的应用程序（如rmg、pmemd、vmd）的MNBF明显小于XE和XK节点的MNBF。

#### 规模与弹性关系
本节探讨应用规模（即节点数量和持续时间）与弹性的关系。我们估计了MTBI和由系统错误引起的应用程序失败概率作为节点数量和节点小时数的函数。通过将LogDiver生成的数据集分组为固定大小的桶来执行此分析，并针对每个桶计算相关指标。例如，对于在1到96个节点（即1个机柜）上执行的应用程序，MTBI计算为该桶中所有应用程序使用的总小时数与该桶中因系统错误导致的应用程序失败次数的比率。

图9显示了未使用检查点/重启技术时XE和XK应用程序的MTBI。全规模XE和XK应用程序（XE为22640个节点，XK为4224个节点）的MTBI值分别为8.7小时和9.2小时。与表VI中XE和XK节点的系统MTBI相比，全规模XE应用程序的MTBI与底层计算平台的MTBI相当（均为8.6小时）。

这些结果还表明，当运行在全规模时，检查点/重启机制受到严重压力。这不仅意味着由于频繁故障所需的检查点/重启开销而导致计算进展缓慢，还意味着故障处理协议可能需要处理多个错误。例如，在Charm++应用程序中，两个共享同一检查点文件的节点同时失败的情况下，即使是最先进的弹性机制也可能无法避免应用程序的失败。

关于GPU节点，我们的测量显示XK应用程序的MTBI约为GPU平台MTBI的三分之一（25.1小时；见表VI）。原因如下：
- 表VI中XE和XK节点的MTBI值指的是由系统级错误检测功能检测到的硬件问题导致的中断。然而，GPU的错误检测能力有限（奇偶校验和ECC），与AMD处理器和主内存的ECC/Chipkill技术相比不足。因此，硬件错误传播到应用层的概率不可忽略，导致未检测到的瞬态错误率较高，从而高估了MTBI测量和XK节点的弹性。
- GPU/混合应用程序在错误恢复过程中更难以处理。许多GPU相关的模块在重启或替换时会影响其他软件部分。此外，XK节点上不同软件栈之间缺乏通信（例如，GPU驱动程序与OpenMP或Charm++），使得弹性机制（如Charm++的心跳或MPI的连接扇出）难以检测与GPU栈相关的错误。例如，一个节点可能在心跳消息中回复，但其GPU栈中的错误可能导致应用程序崩溃。