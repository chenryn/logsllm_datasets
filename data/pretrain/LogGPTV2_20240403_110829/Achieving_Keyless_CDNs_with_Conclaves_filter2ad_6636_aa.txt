title:Achieving Keyless CDNs with Conclaves
author:Stephen Herwig and
Christina Garman and
Dave Levin
Achieving Keyless CDNs with Conclaves
Stephen Herwig, University of Maryland; Christina Garman, Purdue University; 
Dave Levin, University of Maryland
https://www.usenix.org/conference/usenixsecurity20/presentation/herwig
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.Achieving Keyless CDNs with Conclaves
Stephen Herwig
University of Maryland
Christina Garman
Purdue University
Dave Levin
University of Maryland
Abstract
Content Delivery Networks (CDNs) serve a large and in-
creasing portion of today’s web content. Beyond caching,
CDNs provide their customers with a variety of services, in-
cluding protection against DDoS and targeted attacks. As the
web shifts from HTTP to HTTPS, CDNs continue to provide
such services by also assuming control of their customers’
private keys, thereby breaking a fundamental security princi-
ple: private keys must only be known by their owner.
We present the design and implementation of Phoenix, the
ﬁrst truly “keyless CDN”. Phoenix uses secure enclaves (in
particular Intel SGX) to host web content, store sensitive key
material, apply web application ﬁrewalls, and more on oth-
erwise untrusted machines. To support scalability and multi-
tenancy, Phoenix is built around a new architectural primitive
which we call conclaves: containers of enclaves. Conclaves
make it straightforward to deploy multi-process, scalable,
legacy applications. We also develop a ﬁlesystem to extend
the enclave’s security guarantees to untrusted storage. In its
strongest conﬁguration, Phoenix reduces the knowledge of
the edge server to that of a traditional on-path HTTPS adver-
sary. We evaluate the performance of Phoenix with a series
of micro- and macro-benchmarks.
1 Introduction
Content delivery networks (CDNs), like Akamai [1] and
Cloudﬂare [2], play a critical role in making today’s web
fast, resilient, and secure. CDNs deploy servers around the
world, on which they host their customers’ websites. Be-
cause the web’s performance is largely determined by la-
tency [3], many websites rely on the fact that CDNs have
proximal servers to nearly all users on the web to ensure low-
distance and therefore low-latency connections.
While CDNs have grown more popular, so too has the
movement towards an HTTPS-everywhere web. The major-
ity of all websites are offered via HTTPS, and with the ad-
vent of free HTTPS certiﬁcate issuance [4], this number has
grown increasingly quickly [5].
Unfortunately, HTTPS and CDNs are,
in some sense,
pathologically incompatible. To accept TLS connections,
CDN servers store their customers’ secret keys—in many
cases, the CDN actually generates the keys on behalf of their
customers [6, 7]. As a result, CDNs are imbued with a huge
amount of trust: they could impersonate, eavesdrop on, or
tamper with all of their customers, including virtually all of
the world’s major banks, online shops, and many government
sites.
The messy relationship between HTTPS and CDNs is
made all the more challenging by the fact that CDNs today
do far more than merely host the bulk of the web’s content.
They also use web application ﬁrewalls (WAFs) to analyze
clients’ requests for evidence of targeted attacks like SQL
injection or cross-site scripting, and ﬁlter them before up-
loading to their customers [8]. CDN customers beneﬁt from
this service because it scrubs attack trafﬁc far from their own
networks. And yet, running a WAF on a CDN requires the
CDN to have access to the website’s unencrypted trafﬁc.
There have been recent advances to address aspects of this
problem, most notably Cloudﬂare’s Keyless SSL [9], which
is a protocol that allows CDN customers to maintain sole
ownership of their private keys. However, even with Key-
less SSL, the CDN learns all session keys, yielding little ad-
ditional assurance against eavesdropping or impersonation.
The ideal solution would allow for all requisite processing
and functionality to be performed on encrypted data, so that
the CDN operator is neither responsible for holding the keys
nor able to see any of the data through it. However, even
the state of the art in this area [10–16] is much too inefﬁ-
cient to be utilized at the scale and performance that would
be expected of a CDN.
In this paper, we introduce the design and implementa-
tion of Phoenix, the ﬁrst truly “Keyless CDN”. Phoenix uses
trusted execution environments (TEEs, in particular Intel
SGX enclaves) to perform all of the quintessential tasks of to-
day’s CDNs—hosting web servers, applying web application
ﬁrewalls, performing certiﬁcate management, and more—all
on otherwise untrusted machines.
Critical to the performance of any CDN is the ability to
support multiple concurrent web servers and multiple ten-
ants (customers). Unfortunately, no existing software in-
frastructures built off of SGX have been able to support
multi-process, multi-tenant applications. We introduce a new
general-purpose architectural primitive we call conclaves:
containers of enclaves. Conclaves facilitate the deployment,
conﬁguration, and dynamic scaling-up and -down of sophis-
ticated legacy (unmodiﬁed) applications.
Contributions We make the following contributions:
• We present the ﬁrst truly “keyless CDN,” which we call
Phoenix. Phoenix performs all of the quintessential tasks
USENIX Association
29th USENIX Security Symposium    735
ARTIFACTEVALUATEDPASSEDof today’s CDNs, without requiring CDNs to gain access
to sensitive key material, and without having to change
legacy web applications.
• To realize our design, we introduce a new architectural
primitive called conclaves, which creates a microkernel
out of secure enclaves. Conclaves offer the abstraction
of a “container of enclaves,” thereby making it straight-
forward to deploy multi-process, scalable, legacy applica-
tions within a dynamic number of enclaves.
• We present a detailed design and implementation of
Phoenix, and evaluate it on Intel SGX hardware. Our re-
sults indicate that conclaves scale to support multi-tenant
deployments with modest overhead (∼2–3× for many con-
ﬁgurations).
Roadmap We describe the essential features of today’s
CDNs and distill a set of goals and threat models in §2. We
review related work in §3. We present the design of con-
claves and of Phoenix in §4, and their implementation in §5.
We present our evaluation in §6 and conclude in §7.
2 Problem and Goals
We distill down the fundamental features of today’s CDNs,
discuss the inherent security challenges, and formulate the
goals and threat models that guide the rest of this paper.
2.1 Content Delivery Networks
CDNs are third-party services that host their customers’ web-
sites (and other data). Virtually all of the most popular
websites (and a very long tail of unpopular websites) use
one or more CDNs to help reliably host their content [6].
Historically, CDNs have been thought of as a massive web
cache [17], but today’s CDNs play a critical role in achieving
the performance and security that the web relies on [8].
We identify four key roles that fundamentally deﬁne to-
day’s CDNs, and their enabling technologies:
Low latency to clients:
The primary driving feature of
CDNs is their ability to offer low page-load times for clients
visiting their customers’ websites.
How they achieve this: CDNs achieve low latencies via a
massive, global network of multi-tenant edge servers. Edge
servers act primarily as reverse proxy web servers for the
CDN’s customers: to handle client requests, edge servers re-
trieve content from the customers’ origin servers, and cache
it so they can deliver it locally. CDNs direct client requests
to the edge servers in a way that balances load across the
servers, and that minimizes client latency—often by locating
the “closest” server to the client. There are many sophisti-
cated means of routing clients to nearby servers, involving IP
geolocation, IP anycast, and DNS load balancing—but these
speciﬁc mechanisms are outside the scope of this paper.
Edge-network services like CDNs therefore derive much
of their utility from the fact that they have servers close
to most clients. To this end, CDNs deploy their own data
centers, and deploy servers within other organizations’ net-
works, such as college campuses, ISPs, or companies. In-
deed, today’s CDNs have so many points of presence (PoPs)
that they often are within the same network as the clients vis-
iting their sites. To support such proximity without an inor-
dinate number of machines, CDNs rely on the ability to host
multiple tenants (customers) on their web servers at a time.
Manage customers’ keys:
As the web moves towards
HTTPS-everywhere [5], customers increasingly rely on
CDNs to store their HTTPS certiﬁcates and the correspond-
ing secret keys, so that they can accept TLS connections
while maintaining low latency to clients.
How they achieve this: CDNs manage their customers’ keys
in a variety of ways: sometimes by having their customers
upload their secret keys, but typically by simply generat-
ing keys and obtaining certiﬁcates on their customers’ be-
half [6, 7]. Many CDNs combine multiple customers onto
single “cruiseliner certiﬁcates” under the same key pair—
these customers are not allowed to access their own private
keys, as that would allow them to impersonate any other cus-
tomer’s website on the same cruiseliner certiﬁcate [6]. A re-
cent protocol, Keyless SSL [9], has been proposed to address
this; we describe this in more detail in §3.
Absorb DDoS trafﬁc: CDNs protect their customers by
ﬁltering DDoS trafﬁc, keeping it from reaching their cus-
tomers’ networks.
How they achieve this: CDNs leverage economies of scale
to obtain an incredible amount of bandwidth and computing
resources. Their customers’ networks block most inbound
trafﬁc, except from the CDN. Thus, attackers must overcome
these huge resources in order to impact a customer’s website.
Filter targeted attacks: An often overlooked but critical
feature [8] of today’s CDNs is the ability to ﬁlter out (non-
DDoS) attack trafﬁc, such as SQL injection and cross-site
scripting attacks.
How they achieve this: Unlike with DDoS trafﬁc, the primary
challenge behind protecting against targeted attacks is detect-
ing them. CDNs achieve this by running web-application
ﬁrewalls (WAFs), such as ModSecurity [18]. WAFs ana-
lyze the plaintext HTTP messages, and compare the mes-
sages against a set of rules (often expressed as regular expres-
sions [19]) that indicate an attack. Edge servers only permit
benign data to pass through to the customer’s origin server.
2.2 Security Implications of CDNs
Simultaneously fulﬁlling these four roles—low latency, key
management, absorbing large attacks, and blocking small
attacks—inherently requires processing client requests on
736    29th USENIX Security Symposium
USENIX Association
edge servers. In the presence of HTTPS, however, this pro-
cessing requires edge servers to have at least each TLS con-
nection’s session key, if not also each customer’s private key.
It is therefore little surprise that CDNs have amassed the
vast majority of private keys on the web [6, 7]. This has
signiﬁcant implications on the trust model of the PKI and the
web writ large: today’s CDNs could arbitrarily impersonate
any of their customers—and recall that virtually all of the
most popular websites use one or more CDNs [6].
Even if one were to assume a trustworthy CDN, the need to
store sensitive key materials on edge servers introduces sig-
niﬁcant challenges. CDNs have historically relied on a com-
bination of their own physical deployments and deployment
within third-party networks, such as college campuses. To
protect their customers’ keys, some CDNs refuse to deploy
HTTPS content anywhere but at the data centers they have
full physical control over [8]. However, as the web moves
towards HTTPS-everywhere, this means that such CDNs can
no longer make as much use out of third-party networks. In
short, without additional protections for private and session
keys on edge servers, the move towards HTTPS-everywhere
represents an existential threat to edge-network services.
2.3 Our Goals
At a high level, our goal is to maintain all of the core proper-
ties of a CDN—low latency, key management, and resilience
to DDoS and targeted attacks—without having to expose cus-
tomers’ keys or a client’s sensitive information, and without
requiring massive code changes from their customers. We
distill our overarching goal down to ﬁve speciﬁcs:
1. Protect private keys: Support HTTPS, but without ex-
posing the private keys corresponding to the certiﬁcate’s
public key to any edge server.
2. Protect session keys: Once a connection is established,
do not expose the ephemeral session keys (nor the sensi-
tive material for session resumption) to any edge server.
Support edge-
server-side WAFs, but without leaking plaintext mes-
sages to the server.
3. Secure web-application ﬁrewalls:
4. Support multi-tenancy: Be able to host multiple cus-
tomers on a single machine (or even the same web
server process), but with strong isolation between them.
5. Support legacy customer applications: Support all of
the same web architectures of today, with minimal mod-
iﬁcations to or impact on customer code.
These goals are a departure from today’s CDNs, which
store all of their customers’ keys (at least the session keys),
and operate on the plaintext of the client’s data. Achieving
these goals stands to improve websites’ security, users’ pri-
vacy, and also the ﬂexibility in how edge-network services
can be deployed.
2.4 Threat Models
An edge server is by deﬁnition a man-in-the-middle between
the client and the origin server. Given such a privileged po-
sition, there is a wide range of potential threats. We deﬁne
two threat models, the main distinction being who owns and
operates the physical edge server, i.e., the level of control
the CDN assumes over its hardware deployment.
In both
models we assume access to a trusted execution environment
with the following features:
isolation, trusted code execu-
tion, the ability to make calls into/out of the trusted envi-
ronment, attestation, and cryptographic “sealing” of the data.
This ensures strict isolation between customers’ data, as well
as strong protection for their keys, even in the event of node
compromise, so long as the TEE remains secure. We will de-
ﬁne these terms and expand upon the necessary TEE features
in Section 3.2.