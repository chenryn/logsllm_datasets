title:Understanding Data Lifetime via Whole System Simulation (Awarded Best
Paper!)
author:Jim Chow and
Ben Pfaff and
Tal Garfinkel and
Kevin Christopher and
Mendel Rosenblum
USENIX Association
Proceedings of the
13th USENIX Security Symposium
San Diego, CA, USA
August 9–13, 2004
© 2004 by The USENIX Association
Phone: 1 510 528 8649
All Rights Reserved
FAX: 1 510 548 5738
Rights to individual papers remain with the author or the author's employer.
Email: PI:EMAIL
For more information about the USENIX Association:
WWW: http://www.usenix.org
 Permission is granted for noncommercial reproduction of the work for educational or research purposes.
This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein.
Understanding Data Lifetime via Whole System Simulation
Jim Chow, Ben Pfaff, Tal Garﬁnkel, Kevin Christopher, Mendel Rosenblum
{jchow,blp,talg,kchristo,mendel}@cs.stanford.edu
Stanford University Department of Computer Science
Abstract
Strictly limiting the lifetime (i.e. propagation and duration
of exposure) of sensitive data (e.g. passwords) is an impor-
tant and well accepted practice in secure software develop-
ment. Unfortunately, there are no current methods available
for easily analyzing data lifetime, and very little information
available on the quality of today’s software with respect to data
lifetime.
We describe a system we have developed for analyzing sen-
sitive data lifetime through whole system simulation called
TaintBochs. TaintBochs tracks sensitive data by “tainting” it
at the hardware level. Tainting information is then propagated
across operating system, language, and application bound-
aries, permitting analysis of sensitive data handling at a whole
system level.
We have used TaintBochs to analyze sensitive data handling
in several large, real world applications. Among these were
Mozilla, Apache, and Perl, which are used to process millions
of passwords, credit card numbers, etc. on a daily basis. Our
investigation reveals that these applications and the compo-
nents they rely upon take virtually no measures to limit the life-
time of sensitive data they handle, leaving passwords and other
sensitive data scattered throughout user and kernel memory.
We show how a few simple and practical changes can greatly
reduce sensitive data lifetime in these applications.
1 Introduction
Examining sensitive data lifetime can lend valuable
insight into the security of software systems. When
studying data lifetime we are concerned with two pri-
mary issues: how long a software component (e.g. oper-
ating system, library, application) keeps data it is pro-
cessing alive (i.e. in an accessible form in memory
or persistent storage) and where components propagate
data (e.g. buffers, log ﬁles, other components).
As data lifetime increases so does the likelihood of
exposure to an attacker. Exposure can occur by way
of an attacker gaining access to system memory or to
persistent storage (e.g. swap space) to which data has
leaked. Careless data handling also increases the risk
of data exposure via interaction with features such as
logging, command histories, session management, crash
dumps or crash reporting [6], interactive error reporting,
etc.
Unfortunately, even simple questions about data life-
time can be surprisingly difﬁcult to answer in real sys-
tems. The same data is often handled by many different
components, including device drivers, operating system,
system libraries, programming language runtimes, ap-
plications, etc., in the course of a single transaction. This
limits the applicability of traditional static and dynamic
program analysis techniques, as they are typically lim-
ited in scope to a single program, often require program
source code, and generally cannot deal with more than
one implementation language.
To overcome these limitations we have developed
a tool based on whole-system simulation called Taint-
Bochs, which allows us to track the propagation of sen-
sitive data at hardware level, enabling us to examine
all places that sensitive data can reside. We examine
systems with TaintBochs by running the entire software
stack, including operating system, application code, etc.
inside a simulated environment. Every byte of system
memory, device state, and relevant processor state is
tagged with a taint-status ﬂag. Data is “tainted” if it is
considered sensitive.
TaintBochs propagates taint ﬂags whenever their cor-
responding values in hardware are involved in an opera-
tion. Thus, tainted data is tracked throughout the system
as it ﬂows through kernel device drivers, user-level GUI
widgets, application buffers, etc. Tainting is introduced
when sensitive data enters the system, such as when a
password is read from the keyboard device, an applica-
tion reads a particular data set, etc.
We applied TaintBochs to analyzing the lifetime
of password information in a variety of large, real-
world applications, including Mozilla, Apache, Perl, and
Emacs on the Linux platform. Our analysis revealed that
these applications, the kernel, and the libraries that they
relied upon generally took no steps to reduce data life-
time. Buffers containing sensitive data were deallocated
without being cleared of their contents, leaving sensi-
tive data to sit on the heap indeﬁnitely. Sensitive data
was left in cleartext in memory for indeterminate periods
without good reason, and unnecessary replication caused
excessive copies of password material to be scattered all
over the heap. In the case of Emacs our analysis also
uncovered an interaction between the keyboard history
mechanism and shell mode which caused passwords to
be placed into the keyboard history in the clear.
On a positive note our analysis revealed that sim-
ple modiﬁcations could yield signiﬁcant improvements.
For example, adding a small amount of additional code
to clear buffers in the string class destructor in Mozilla
greatly reduced the amount of sensitive input form data
(e.g. CGI password data) in the heap without a notice-
able impact on either code complexity or performance.
Our exposition proceeds as follows. In section 2 we
present the motivation for our work, discussing why data
lifetime is important to security, why minimizing data
lifetime is challenging, and how whole system simula-
tion can help. Section 3 describes the design of Taint-
Bochs, its policy for propagating taint information and
the rationale behind it, its support for introducing and
logging taints, and our analysis framework. Section 4
describes our experiments on Mozilla, Apache, Perl, and
Emacs, analyzes the results, and describes a few sim-
ple changes we made to greatly reduced the quantity of
long-lived tainted data in programs we examined. Sec-
tion 5 covers related work. Section 6 describes our
thoughts about future work in this area. Finally, sec-
tion 7 concludes.
2 Motivation
This section examines why data lifetime is important,
how this issue has been overlooked in many of today’s
systems, why it is so difﬁcult to ensure minimal data
lifetime, and how TaintBochs can help ameliorate these
problems.
Threat Model or Why Worry about Data Lifetime?
The longer sensitive data resides in memory, the greater
the risk of exposure. A long running process can easily
accumulate a great deal of sensitive data in its heap sim-
ply by failing to take appropriate steps to clear that mem-
ory before free()ing it. A skillful attacker observing
such a weakness could easily recover this information
from a compromised system simply by combing an ap-
plication’s heap. More importantly, the longer data re-
mains in memory the greater its chances of being leaked
to disk by swapping, hibernation, a virtual machine be-
ing suspended, a core dump, etc.
Basic measures for limiting the lifetime of sensitive
data including password and key material and keeping
it off persistent storage have become a standard part of
secure software engineering texts [29] and related liter-
ature [13, 28]. Extensive work has been done to gauge
the difﬁculty of purging data from magnetic media once
it has been leaked there [11], and even issues of per-
sistence in solid state storage have been examined [12].
Concern about sensitive data being leaked to disk has
fueled work on encrypted swap [21] and encrypted ﬁle
systems [4] which can greatly reduce the impact of sen-
sitive data leaks to disk. Unfortunately, these measures
have seen fairly limited deployment.
Identifying long-lived data is not so obviously useful
as, say, detecting remotely exploitable buffer overﬂows.
It is a more subtle issue of ensuring that principles of
conservative design have been followed to minimize the
impact of a compromise and decrease the risk of harmful
feature interactions. The principles that underly our mo-
tivation are: ﬁrst, minimize available privilege (i.e. sen-
sitive data access) throughout the lifetime of a program;
second, defense in depth, e.g. avoid relying solely on
measures such as encrypted swap to keep sensitive data
off disk.
While awareness of data lifetime issues runs high
among the designers and implementers of cryptographic
software, awareness is low outside of this community.
This should be a signiﬁcant point for concern. As our
work with Mozilla in particular demonstrates, even pro-
grams that should know better are entirely careless with
sensitive data. Perhaps one explanation for this phe-
nomenon is that if data is not explicitly identiﬁed as, for
example, a cryptographic key, it receives no special han-
dling. Given that most software has been designed this
way, and that this software is being used for a wide range
of sensitive applications, it is important to have an easy
means of identifying which data is sensitive, and in need
of special handling.
Minimizing Data Lifetime is Hard The many factors
which affect data lifetime make building secure systems
a daunting task. Even systems which strive to handle
data carefully are often foiled by a variety of factors
including programmer error and weaknesses in compo-
nents they rely upon. This difﬁculty underscores the
need for tools to aid examining systems for errors.
Common measures taken to protect sensitive data in-
clude zeroing out memory containing key material as
soon as that data is no longer needed (e.g. through the
C memset() function) and storing sensitive material
on pages which have been pinned in memory (e.g. via
the UNIX mmap() or mlock() system calls), to keep
them off of persistent storage. These measures can and
have failed in a variety of ways, from poor interactions
between system components with differing assumptions
about data lifetime to simple programmer error.
A very recent example is provided by Howard [14]
who noted that memset() alone is ineffective for clear-
ing out memory with any level of optimization turned on
in Borland, Microsoft, and GNU compilers. The prob-
lem is that buffers which are being memset() to clear
their contents are effectively “dead” already, i.e. they
will never be read again, thus the compiler marks this
code as redundant and removes it. When this problem
was revealed it was found that a great deal of software,
including a variety of cryptographic libraries written by
experienced programmers, had failed to take adequate
measures to address this. Now that this problem has
been identiﬁed, multiple ad-hoc ways to work around
this problem have been developed; however, none of
them is entirely straightforward or foolproof.
Sometimes explicitly clearing memory is not even
possible. If a program unexpectedly halts without clear-
ing out sensitive data, operating systems make no guar-
antees about when memory will be cleared, other than it
will happen before the memory is allocated again. Thus,
sensitive data can live in memory for a great deal of
time before it is purged. Similarly, socket buffers, IPC
buffers, and keyboard input buffers, are all outside of
programmer control.
Memory locking can fail for a wide range of rea-
sons. Some are as simple as memory locking functions
that provide misleading functionality. For example, a
pair of poorly documented memory locking functions in
some versions of Windows, named VirtualLock()
and VirtualUnlock(), are simply advisory, but this
has been a point of notable confusion [13].
OS hibernation features do not respect memory lock-
ing guarantees. If programs have anticipated the need,
they can usually request notiﬁcation before the system
hibernates; however, most programs do not.
Virtual machine monitors such as VMware Worksta-
tion and ESX [30] have limited knowledge of the mem-
ory management policies of their guest OSes. Many
VMM features, including virtual memory (i.e. paging),
suspending to disk, migration, etc., can write any and all
state of a guest operating system to persistent storage in
a manner completely transparent to the guest OS and its
applications. This undermines any efforts by the guest
to keep memory off of storage such as locking pages in
memory or encrypting the swap ﬁle.
In addition to these system level complications, un-
expected interactions between features within or across
applications can expose sensitive data. Features such
as logging, command histories, session management,
crash dumps/crash reporting, interactive error reporting,
etc. can easily expose sensitive data to compromise.
Systems are made of many components that applica-
tion designers did not develop and whose internals they
have little a priori knowledge of. Further, poor handling
of sensitive data is pervasive. While a few specialized
security applications and libraries are quite conservative
about their data handling, most applications, language
runtimes, libraries and operating system are not. As we
discuss later in Section 4, even the most common com-
ponents such as Mozilla, Apache, Perl, and Emacs and
even the Linux kernel are relatively proﬂigate with their
handling of sensitive data. This makes building systems
which are conservative about sensitive data handling ex-
tremely difﬁcult.
Whole System Simulation can Help TaintBoch’s ap-
proach of tracking sensitive data of interest via whole
system simulation is an attractive platform for tackling
this problem. It is practical, relatively simple to imple-
ment (given a simulator), and possesses several unique
properties that make it particularly well suited to exam-
ining data lifetime.
TaintBochs’s whole system view allows interactions
between components to be analyzed, and the location of
sensitive data to be easily identiﬁed. Short of this ap-
proach, this is a surprisingly difﬁcult problem to solve.
Simply greping for a sensitive string to see if it is
present in system memory will yield limited useful infor-
mation. In the course of traversing different programs,
data will be transformed through a variety of encodings
and application speciﬁc data formats that make naive
identiﬁcation largely impossible. For example, in sec-
tion 4 we ﬁnd that a password passing from keyboard to
screen is alternately represented as keyboard scan codes,
plain ASCII, and X11 scan codes. It is buffered as a set
of single-character strings, and elements in a variety of
circular queues.
Because TaintBochs tracks data at an architectural
level, it does not require source code for the components
that an analysis traverses (although this does aid inter-
pretation). Because analysis is done at an architectural
level, it makes no assumptions about the correctness of
implementations of higher level semantics. Thus, high
level bugs or misfeatures (such as a compiler optimizing
away memset()) are not overlooked.
Comparison of a whole system simulation approach
with other techniques is discussed further in the related
work, section 5.
3 TaintBochs Design and Implementation
TaintBochs is our tool for measuring data lifetime.
At its heart is a hardware simulator that runs the entire
software stack being analyzed. This software stack is re-
ferred to as the guest system. TaintBochs is based on the
open-source IA-32 simulator Bochs v2.0.2 [5]. Bochs
itself is a full featured hardware emulator that can emu-
late a variety of different CPUs (386, 486, or Pentium)
and I/O devices (IDE disks, Ethernet card, video card,
sound card, etc.) and can run unmodiﬁed x86 operating
systems including Linux and Windows.
Bochs is a simulator, meaning that guest code never
runs directly on the underlying processor—it is merely
interpreted, turning guest hardware instructions into ap-
propriate actions in the simulation software. This per-
mits incredible control, allowing us to augment the ar-
chitecture with taint propagation, extend the instruction
set, etc.
We have augmented Bochs with three capabilities to
produce TaintBochs. First, we provide the ability to
track the propagation of sensitive data through the sys-
tem at a hardware level, i.e. tainting. Second, we have
added logging capabilities that allow system state such
as memory and registers at any given time during a sys-
tem’s execution history to be examined. Finally, we de-
veloped an analysis framework that allows information
about OS internals, debug information for the software
that is running, etc. to be utilized in an integrated fashion
to allow easy interpretation of tainting information. This
allows us to trace tainted data to an exact program vari-
able in an application (or the kernel) in the guest, and
code propagating tainting to an exact source ﬁle and line
number.