# 四、调试通过指标和警报发现的问题
When you eliminate the impossible, whatever remains, however improbable, must be the truth.
- *史巴克*
到目前为止，我们探索了如何收集指标，以及如何创建警报，以便在出现问题时通知我们。我们还学习了如何查询指标，并在试图找到问题原因时挖掘我们可能需要的信息。我们将对此进行扩展，并尝试调试一个模拟问题。
仅仅说一个应用不能正常工作是不够的。我们应该更加精确。我们的目标是不仅能够查明哪个应用出现故障，而且能够查明哪个部分是罪魁祸首。我们应该能够责备特定的函数、方法、请求路径等等。我们在检测应用的哪个部分导致问题时越精确，我们就越快找到问题的原因。因此，通过新版本(修补程序)、扩展或我们可以使用的任何其他方式来修复问题应该会更容易、更快。
我们走吧。在我们模拟一个需要解决的问题之前，我们需要一个集群(除非您已经有一个集群)。
# 创建集群
`vfarcic/k8s-specs`([)https://github.com/vfarcic/k8s-specs](https://github.com/vfarcic/k8s-specs))存储库将继续作为我们的 Kubernetes 定义的来源，我们将在示例中使用它。我们将通过获取最新版本来确保它是最新的。
All the commands from this chapter are available in the `04-instrument.sh` ([https://gist.github.com/vfarcic/851b37be06bb7652e55529fcb28d2c16](https://gist.github.com/vfarcic/851b37be06bb7652e55529fcb28d2c16)) Gist. Just as in the previous chapter, it contains not only the commands but also Prometheus' expressions. They are all commented (with `#`). If you're planning to copy and paste the expressions from the Gist, please exclude the comments. Each expression has `# Prometheus expression` comment on top to help you identify it.
```
 1  cd k8s-specs
 2
 3  git pull
```
考虑到我们已经学会了如何安装一个完全运行的普罗米修斯和它的图表中的其他工具，并且我们将继续使用它们，我把它移到了 Gists。以下是我们在上一章中使用的副本，增加了环境变量`PROM_ADDR`和`AM_ADDR`，以及安装**普罗米修斯图表**的步骤。请创建一个满足(或超过)以下指南中指定要求的集群，除非您已经有一个满足这些要求的集群。
*   `gke-instrument.sh` : **具有 3 个 n1-standard-1 工作节点的 GKE** 、 **nginx Ingress** 、 **tiller** 、 **Prometheus** 图表以及环境变量 **LB_IP** 、 **PROM_ADDR** 和**AM _ ADDR**([https://gist.github.com/675f4b3ee2c55ee718cf132e71e04c6e](https://gist.github.com/675f4b3ee2c55ee718cf132e71e04c6e))。
*   `eks-instrument.sh` : **具有 3 个 T2 .小型工作节点的 EKS** 、 **nginx Ingress** 、 **tiller** 、 **Metrics Server** 、 **Prometheus** 图表以及环境变量 **LB_IP** 、 **PROM_ADDR** 和**AM _ ADDR**([https://gist.github.com/70a14c8f15c7ffa533ea7feb75341545](https://gist.github.com/70a14c8f15c7ffa533ea7feb75341545))。
*   `aks-instrument.sh` : **带有 3 个 Standard_B2s 工作节点的 AKS** 、 **nginx Ingress** 和 **tiller** 、 **Prometheus** 图表，以及环境变量 **LB_IP** 、 **PROM_ADDR** 和**AM _ ADDR**([https://gist.github.com/65a0d5834c9e20ebf1b99225fba0d339](https://gist.github.com/65a0d5834c9e20ebf1b99225fba0d339))。
*   `docker-instrument.sh` : **Docker for Desktop** 带有 **2 个 CPU**、 **3 GB RAM** 、 **nginx Ingress** 、 **tiller** 、**度量服务器**、 **Prometheus** 图表以及环境变量 **LB_IP** 、 **PROM_ADDR** 和**AM _ ADDR**([https://gist.github.com/1dddcae847e97219ab75f936d93451c2](https://gist.github.com/1dddcae847e97219ab75f936d93451c2)
*   `minikube-instrument.sh` : **minikube** 带 **2 个 CPU**、 **3 GB RAM** 、**入口、存储提供程序**、**默认存储类**和**指标服务器**插件已启用、**分蘖**、**普罗米修斯**图表和环境变量 **LB_IP** 、 **PROM_ADDR 【T20**
现在我们准备好面对第一个可能需要调试的模拟问题。
# 面对灾难
让我们探索一个灾难场景。坦率地说，这不会是一场真正的灾难，但它需要我们找到解决问题的方法。
我们将从安装已经熟悉的`go-demo-5`应用开始。
```
 1  GD5_ADDR=go-demo-5.$LB_IP.nip.io
 2
 3  helm install \
 4      https://github.com/vfarcic/go-demo-5/releases/download/
    0.0.1/go-demo-5-0.0.1.tgz \
 5      --name go-demo-5 \
 6      --namespace go-demo-5 \
 7      --set ingress.host=$GD5_ADDR
 8
 9  kubectl -n go-demo-5 \
10      rollout status \
11      deployment go-demo-5
```
我们用地址声明`GD5_ADDR`，通过该地址我们将能够访问应用。当我们安装`go-demo-5`图表时，我们使用它作为`ingress.host`变量。为了安全起见，我们一直等到应用推出，从部署的角度来看，剩下的就是通过发送一个 HTTP 请求来确认它正在运行。
```
 1  curl http://$GD5_ADDR/demo/hello
```
输出是开发者最喜欢的消息`hello, world!`。
接下来，我们将通过发送 20 个持续时间长达 10 秒的慢速请求来模拟一个问题。这将是我们对一个可能需要解决的问题的模拟。
```
 1  for i in {1..20}; do
 2      DELAY=$[ $RANDOM % 10000 ]
 3      curl "http://$GD5_ADDR/demo/hello?delay=$DELAY"
 4  done
```
由于我们已经有了普罗米修斯的警报，我们应该会在 Slack 上收到通知，指出应用太慢。然而，许多读者可能使用相同的渠道进行这些练习，可能不清楚信息是否来自我们。相反，我们将打开普罗米修斯的警报屏幕来确认有问题。在“真实”设置中，您不会检查普罗米修斯警报，而是等待 Slack 上的通知，或者您选择的任何其他通知工具。
```
 1  open "http://$PROM_ADDR/alerts"
```
过了一会儿(别忘了刷新屏幕)，应该会触发`AppTooSlow`警报，让我们知道我们的一个应用速度很慢，我们应该做点什么来补救这个问题。
不折不扣的承诺，每一章都会有不同 Kubernetes 风格的输出和截图，这次轮到 minikube 了。
![](img/fb08d36b-cba3-4acb-8385-f3836d1a1f1d.png)
Figure 4-1: One of Prometheus' alerts in the firing state
我们将假设我们不是有意生成缓慢的请求，因此我们将尝试找出问题所在。哪个应用太慢了？我们可以向团队传递哪些有用的信息，以便他们能够尽快解决问题？
第一个逻辑调试步骤是执行与警报使用的表达式相同的表达式。请展开`AppTooSlow`提醒，点击表达式的链接。您将被重定向到已经预先填充了表达式的图形屏幕。点击执行按钮，切换到*图形*选项卡。
从图中我们可以看到，慢速请求的数量激增。触发警报是因为不到 95%的响应在 0.25 秒的时间段内。从我的图表(下面的截图)来看，0%的响应在 0.25 秒的时间段内，换句话说，所有的响应都比这慢。过了一会儿，这种情况有所改善，快速请求的比例上升到了 6%。
总之，我们有一种情况，太多的请求得到的响应很慢，我们应该解决这个问题。主要问题是如何找出这种缓慢的原因？
![](img/8052c5cf-a627-4785-a91b-28e759a53a1c.png)
Figure 4-2: The graph with the percentage of requests with fast responses
执行不同的表达式怎么样。例如，我们可以输出该`ingress`(应用)的请求持续时间比率。
请键入下面的表达式，然后按“执行”按钮。
```
 1  sum(rate(
 2      nginx_ingress_controller_request_duration_seconds_sum{
 3          ingress="go-demo-5"
 4      }[5m]
 5  )) /
 6  sum(rate(
 7      nginx_ingress_controller_request_duration_seconds_count{
 8          ingress="go-demo-5"
 9      }[5m]
10  ))
```
该图向我们显示了请求持续时间的历史，但它并没有让我们更接近于揭示问题的原因，或者更准确地说，是应用中缓慢的部分。我们可以尝试使用其他指标，但它们或多或少都是通用的，可能不会让我们有所收获。我们需要更详细的特定于应用的指标。我们需要来自`go-demo-5`应用内部的数据。
# 使用工具提供更详细的指标
我们不应该只说`go-demo-5`应用慢。这将不会为我们快速检查代码以寻找这种缓慢的确切原因提供足够的信息。我们应该能够做得更好，并推断出应用的哪个部分有问题。我们能找出一条反应缓慢的特定路径吗？是所有方法都一样慢，还是问题仅限于一个？我们知道哪个函数产生慢度吗？在这种情况下，我们应该能够回答许多类似的问题。但是我们不能，以目前的标准。它们太通用了，通常只能告诉我们某个特定的 Kubernetes 资源行为不端。我们收集的指标过于宽泛，无法回答特定于应用的问题。
到目前为止，我们探索的指标是出口商和工具的结合。出口商负责获取现有的指标，并将其转换为对普罗米修斯友好的格式。一个例子是节点导出器([https://github.com/prometheus/node_exporter](https://github.com/prometheus/node_exporter))，它采用“标准”的 Linux 度量标准，并将它们转换成普罗米修斯的时间序列格式。另一个例子是 Kube-state-metrics([https://github.com/kubernetes/kube-state-metrics](https://github.com/kubernetes/kube-state-metrics))，它监听 Kube API 服务器并生成带有资源状态的度量。
Instrumented metrics are baked into applications. They are an integral part of the code of our apps, and they are usually exposed through the `/metrics` endpoint.
向应用添加指标的最简单方法是通过普罗米修斯客户端库。在撰写本文时，正式提供了 Go([https://github.com/prometheus/client_golang](https://github.com/prometheus/client_golang))、Java 和 Scala([https://github.com/prometheus/client_java](https://github.com/prometheus/client_java))、Python([https://github.com/prometheus/client_python](https://github.com/prometheus/client_python))和 Ruby([https://github.com/prometheus/client_ruby](https://github.com/prometheus/client_ruby))库。
除此之外，社区还支持 Bash([https://github.com/aecolley/client_bash](https://github.com/aecolley/client_bash))、c++([https://github.com/jupp0r/prometheus-cpp](https://github.com/jupp0r/prometheus-cpp))、Common Lisp([https://github.com/deadtrickster/prometheus.cl](https://github.com/deadtrickster/prometheus.cl))、酏剂([https://github.com/deadtrickster/prometheus.ex](https://github.com/deadtrickster/prometheus.ex))、二郎([https://github.com/deadtrickster/prometheus.erl](https://github.com/deadtrickster/prometheus.erl))、哈斯克尔([https://github.com/fimad/prometheus-haskell](https://github.com/fimad/prometheus-haskell))、Lua for Nginx([https://github.com/knyar/nginx-lua-prometheus](https://github.com/knyar/nginx-lua-prometheus))、Lua for Tarantool([https://github.com/tarantool/prometheus](https://github.com/tarantool/prometheus))。NET/c#([https://github.com/andrasm/prometheus-net](https://github.com/andrasm/prometheus-net))、node . js([https://github.com/siimon/prom-client](https://github.com/siimon/prom-client))、Perl([https://metacpan.org/pod/Net::Prometheus](https://metacpan.org/pod/Net::Prometheus))、PHP([https://github.com/Jimdo/prometheus_client_php](https://github.com/Jimdo/prometheus_client_php))和 Rust([https://github.com/pingcap/rust-prometheus](https://github.com/pingcap/rust-prometheus))。即使您使用不同的语言进行编码，也可以通过以基于文本的展示格式([https://Prometheus . io/docs/instrumenting/exposure _ formats/](https://prometheus.io/docs/instrumenting/exposition_formats/))输出结果，轻松提供对 Prometheus 友好的指标。
收集度量的开销应该可以忽略不计，而且由于普罗米修斯定期提取它们，输出它们也应该有很小的占用空间。即使您选择不使用普罗米修斯，或者切换到其他东西，格式也正在成为标准，您的下一个度量收集器工具可能会期待相同的数据。
总而言之，没有借口不将度量标准烘焙到您的应用中，正如您将很快看到的，它们提供了我们无法从外部获得的宝贵信息。
让我们看一下`go-demo-5`中的一个仪表化度量的例子。
```
 1  open "https://github.com/vfarcic/go-demo-5/blob/master/main.go"
```
The application is written in Go. Don't worry if that's not your language of choice. We'll just take a quick look at a few examples as a way to understand the logic behind instrumentation, not the exact implementation.
第一个有趣的部分如下。
```