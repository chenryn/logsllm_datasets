GPU memory aperture for exchanging data between CPU
and GPU, and the other in non-aperture space for holding
GPU data. As a consequence, the separated memory blocks
cannot be protected by the setting of the single pair of “base-
and-bound” registers in the GPU commands; e.g., viz., Intel
GPU. As illustrated in Figure 2(b), malicious VM2 uses the
simple attack of Figure 2(a) but this time it can access victim
VM1’s GPU memory despite base-and-bound protection,
because one of VM1’s GPU memory blocks falls between
two of VM2’s non-contiguous memory blocks. It should be
noted that the simple attack succeeds for other GPUs, not
just Intel’s; e.g. some instructions in AMD GPUs can per-
form register-indirect memory accesses, without specifying
added address-space protection [7].
2.3 Challenges of Commodity Platforms
Implementing a trusted display service on untrusted com-
modity OS and hardware platforms that support SecApp
isolation faces three basic challenges.
Incompatibility with commodity platforms. The goal of
maintaining object-code compatibility with untrusted OSes
that directly access GPU objects in an unrestricted manner
poses a dilemma. If one re-designs and re-implements GPU
functions on commodity OSes to block memory accesses that
breach address space separation, one introduces object-code
High	
  address	
  Base	
  Bound	
  VM2	
  VM1	
  Low	
  address	
  VM2	
  VM1	
  Low	
  address	
  VM2	
  VM1	
  Base	
  Bound	
  High	
  address	
  991incompatibility. If one does not, one forgoes trusted display.
To retain compatibility, access to GPU objects by untrusted
commodity OS/Apps code must be emulated by the trusted-
system, which increases the trusted code base and makes
high-assurance design impractical.
Inadequate GPU hardware protection. The inadequacy of
the hardware for memory protection has already been noted
in the literature for Intel GPUs [46]. The address-space sep-
aration attack by malicious GPU instructions of Section 2.2
illustrates another instance of this problem and suggests that
simplistic software solutions will not work. For example, ver-
ifying address oﬀsets of GPU instructions before execution
does not work because operand addressing cannot always be
unambiguously determined due to indirect branches [23] and
register-indirect memory accesses [23, 7].
Unveriﬁable code base. Even if, hypothetically, all the
OS/Apps functions that access GPU objects could be iso-
lated and made tamper-proof, their code base would be nei-
ther small (i.e., tens of thousands of SLoC) nor simple,
and hence the formal veriﬁcation of their security prop-
erties would be impractical. A large number of diverse
GPU instructions and commands spread throughout diﬀer-
ent drivers and application code provide access to a large
number of GPU objects; e.g., a GPU can have 625 con-
ﬁguration registers and 335 GPU commands, as shown in
Section 5. Furthermore, since the underlying trusted base
(e.g., micro-kernel or micro-hypervisor) must protect diﬀer-
ent SecApps on a commodity platform, the functions that
access GPU objects directly must be implemented within
the trusted base. Hence, these functions’ code would have
to preserve all existing assurance of the underlying trusted
base; i.e., their security properties and proofs must compose
with those of the trusted base. These challenges have not
been met to date.
3. SECURITY MODEL
In this section, we deﬁne the threats posed by an adver-
sary to trusted display and present security properties that
counter these threats. Furthermore, we present an infor-
mal GPU security model that satisﬁes those properties in
commodity systems.
3.1 Threats
An adversary can leak a SecApp’s security-sensitive out-
put via screen scraping attacks whereby the content of dis-
play output in a GPU’s memory is read by a malicious
program of a compromised commodity OS/App or SecApp.
The adversary can also modify the SecApp’s output content,
conﬁguration (e.g., geometry, pixel format, frame buﬀer’s
base address) via screen painting attacks whereby a ma-
licious program modiﬁes GPU memory and conﬁguration
registers. For example, to launch both attacks the adver-
sary can breach the separation of GPU’s address spaces.
These breaches can be implemented by unauthorized ac-
cess to GPU objects, either directly by CPU programs (e.g.,
drivers, applications), or indirectly by GPU commands and
instructions that cause the GPU to access other GPU ob-
jects in an unauthorized manner. Furthermore, the adver-
sary can manipulate the display engine’s data paths and
overlay a new frame buﬀer over a SecApp’s display thereby
breaking the integrity of SecApps’ display output without
touching its contents.
In this paper, we do not consider hardware, ﬁrmware, side-
channels, device peer-to-peer communication and shoulder-
surﬁng attacks [20]. We ignore I/O channel isolation attacks,
which have already been addressed in the literature [56, 55].
We also omit denial of service (DoS) attacks, such as manip-
ulation of GPU conﬁgurations to disable screen output; e.g.,
disable-then-resume GPU, color shifts. For a well designed
SecApp, it would be diﬃcult for an adversary to launch a
DoS attack that would remain unnoticed by an observant
user.
3.2 Security Properties
A security model for trusted display on commodity sys-
tems must satisfy three abstract properties (deﬁned below)
that are intended to counter an adversary’s threats. To ex-
press these properties, we partition the GPU objects into
two groups: security sensitive and insensitive objects. In-
tuitively, the security-sensitive GPU objects are those that
can be programmed by untrusted software (e.g., malicious
drivers, applications) to break the conﬁdentiality or authen-
ticity of trusted display output, and those which can be
tainted by access to other sensitive GPU objects. For ex-
ample, sensitive GPU objects include directly accessible ob-
jects, such as frame buﬀers, page tables, conﬁguration reg-
isters, and objects that can aﬀect the security of other ob-
jects, such as GPU commands, and instructions, which can
modify GPU page table structures. Furthermore, because
GPU objects are mapped into GPU address spaces, the cor-
responding virtual and physical GPU memory regions are
regarded as sensitive.
In contrast, the security-insensitive
GPU objects cannot aﬀect the conﬁdentiality and authen-
ticity of trusted display even if they are manipulated by
malicious software.
The three security properties that must be satisﬁed by
trusted display designs and implementations are expressed
in terms of the separation of sensitive-insensitive objects and
their accesses, complete mediation of accesses to sensitive
objects, and minimization of the trusted code base that im-
plements the separation and mediation properties.
P1. Complete separation of GPU objects and their
accesses.
The trusted display model must partition all
GPU objects into security-sensitive and security-insensitive
objects and must deﬁne all access modes (e.g., content read,
write, conﬁguration modiﬁcation) for the security sensitive
objects and their memory representations.
P2. Complete mediation of GPU sensitive-object
access. The trusted display model must include a GPU
separation kernel that must satisfy the following three prop-
erties. The kernel must:
(1) mediate all accesses to the security-sensitive objects ac-
cording to a deﬁned GPU access mediation policy;
(2) provide a GPU access-mediation policy that deﬁnes the
access invariants for security-sensitive objects; and
(3) be protected from tampering by untrusted OS/Apps and
SecApps5;
P3. Trusted code base minimization. The GPU sep-
aration kernel must: (1) have a small code base to facilitate
formal veriﬁcation, and (2) preserve the existing assurance
5The isolation of the GPU separation kernel can be easily
achieved using the services of existing micro-kernel or micro-
hypervisor security architectures [27, 56]
992Table 1: GPU object and access separation.
GPU Objects Untrusted OS/Apps
SecApps
Data
Conﬁguration
Registers
Page Tables
Commands
Instructions
Mediated sensitive
access and direct
insensitive access
Conﬁned by address
space separation
Submitted via GPU
separation kernel
No access
would signiﬁcantly enlarge and add complexity to the GSK
code base and hence diminish its security assurance. This
would also add signiﬁcant overhead to the OS’s graphics
performance.
To resolve the above access-mediation problem, we use an
eﬃcient address-space separation mechanism. Instead of ver-
ifying individual instruction access, this mechanism conﬁnes
the memory access of GPU instructions; i.e., it limits mem-
ory accesses only to those allowed by local GPU page tables.
As a consequence, GPU address-space separation attacks no
longer succeed since GPU instructions can no longer refer-
ence GPU memory via the shared GGTT. As the result, the
mediation mechanism does not require any GPU instruction
modiﬁcation.
The mediation mechanism must also protect command
buﬀers from modiﬁcation by malicious GPU instructions
and prevent TOCTTOU attacks. For example, some com-
mand buﬀers must be mapped into the local address space
of untrusted OS/Apps in GPU memory. However, mali-
cious GPU instructions can modify the GPU commands af-
ter command veriﬁcation and invalidate the veriﬁcation re-
sults for GPU commands at run time. Nevertheless, GPU
address-space separation hardware can still protect the in-
tegrity of GPU command buﬀers via write protection. The
conﬁdentiality of command-buﬀer content does not need ex-
tra protection6 and hence the accesses to GPU instructions
that read command buﬀers need not be mediated.
3.4.2 Access Mediation Policy
GPU access mediation policy comprises a set of “access
invariants” that are enforced by the GPU separation kernel.
These invariants are designed to ensure the security of the
SecApps’ display output and must hold at all intermediate
points during trusted-display operation. They yield both
secure-state invariants and transition constraints in a state-
transition model of security policy [18].
Access invariants. As argued in Section 3.1, an adver-
sary’s attacks may either breach the conﬁdentiality and au-
thenticity of trusted display content (i.e., content security),
or destroy the integrity of its conﬁgurations (i.e., conﬁgura-
tion integrity). For example, the adversary can modify the
conﬁgurations of both SecApps’ display and sensitive GPU
memory content. Hence, our access mediation policy is de-
ﬁned in terms of invariants for GPU object accesses that
must be maintained for both content security and conﬁgu-
ration integrity.
• GPU data. Content security requires the following in-
variants: (1) no untrusted read of the trusted display’s
6Our adversary model omits side channels and inference
analyses that may deduce sensitive output from command
content.
Figure 3: GPU Separation Kernel Architecture.
of the underlying Trusted Computing Base (TCB) necessary
for its protection.
3.3 Separation of GPU Objects and Accesses
All security properties of trusted display ultimately rely
on the complete separation of GPU objects and their ac-
cesses by GPU design and implementation; e.g., GPU sep-
aration kernel (GSK) discussed below. This requires the
analysis of all interfaces between the software components
(untrusted commodity OS/Apps, and SecApps) and GPU
objects. The results of this analysis, which are abstracted in
Figure 3 and Table 1, enable the design of the access media-
tion mechanism, policy, and access emulation. For example,
this analysis shows that SecApps may provide only display
content and geometry conﬁgurations to the GPU without
sending any commands or instructions, and hence do not
need direct access to GPU objects. Hence, all their direct
accesses to GPU objects are blocked by the GPU separation
kernel.
3.4 GPU Separation Kernel
3.4.1 Access Mediation Mechanism
The mediation mechanism of the GSK distinguishes be-
tween two types access outcomes, namely direct access to
security-insensitive GPU objects, and veriﬁed (mediated)
access to security-sensitive GPU objects. Every CPU ac-
cess to sensitive objects must be mediated even though GPU
hardware lacks mechanisms for intercepting all GPU com-
mands and instructions individually at run time. Since most
GPU commands and instruction references cannot be medi-
ated at run time, they must be veriﬁed before submitting
them to the GPU. Although previous work [46] illustrates
how to verify GPU commands, it does not address the ver-
iﬁcation of GPU instructions, which is more challenging, as
argued in Section 2.3.
GPU instructions are limited to three types of opera-
tions: arithmetic/logic operations, control ﬂow operations,
and memory access operations [23, 7, 50, 39]. Arithmetic/logic
operations run on GPU cores only and do not aﬀect GPU
memory or other GPU objects. However, an adversary may
exploit control ﬂow and/or memory access operations to
break the conﬁdentiality and authenticity of trusted dis-
play contents. Mediating each of these operations individu-
ally without hardware support would be prohibitive since it
          GPU Legend: Sensitive Access Insensitive Access Unprivileged Interface Sensitive Objects Insensitive Objects App 1  Commodity OS (unmodified) Apps Apps   SecApp 1 SecApp 2 Access Mediation Access Emulation Hardware Software GPU Separation Kernel 993frame buﬀer; and (2) no untrusted write to sensitive
GPU data.
• GPU page tables. The following invariants must hold
for GPU address space separation: (1) no untrusted
OS/Apps can map sensitive GPU memory to be writable
in any GPU local page tables; (2) no untrusted OS/Apps
can map the trusted display’s frame buﬀer to be read-
able in any GPU local page tables; (3) untrusted OS/
Apps must have a single mapping to sensitive GPU
memory in GPU global address space; and (4) GPU
instructions uploaded by untrusted OS/Apps cannot
reference the GPU’s global address space.
• GPU conﬁguration registers. Conﬁguration integrity
requires the following invariants: (1) no untrusted re-
conﬁguration of SecApps’ display; and (2) no untrusted
re-conﬁguration of sensitive GPU memory. Content
security requires the following invariant: no untrusted
read of the trusted display’s frame buﬀer, and no un-
trusted write to sensitive GPU memory.
In addition, the invariant that untrusted access to con-
ﬁguration cannot violate the access invariants of GPU
page tables must also be enforced.
• GPU commands. Content security requires the follow-
ing invariants: (1) no GPU command can read trusted
display’s frame buﬀers; and (2) no GPU command can
write sensitive GPU memory.