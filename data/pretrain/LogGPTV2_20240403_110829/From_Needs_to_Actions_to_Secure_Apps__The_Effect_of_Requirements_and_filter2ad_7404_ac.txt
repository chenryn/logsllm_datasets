4.2. Application Statistical Analysis  
As in the previous phase, we used graphical tools to explore 
the data, and linear analysis to explore relationships between 
the data. 
To investigate RQ2, we defined further scores to represent 
the outcome ‚Äúfewer security defects‚Äù in each app analyzed.  
Figure 3 shows the processing involved. We anticipated that 
the issue counts would have a Poisson distribution; to permit 
linear  analysis  we  used  a  log  transformation5.  As  with  the 
scores for developer behavior, we wanted scores that increase 
with increasing app security and privacy, and we therefore 
negated the log value. 
We used the same method as previously (Section 3.6) to look 
for relationships between these scores and the scores from 
Figure 2 covering the ‚Äúneed for security, involvement of spe-
cialist roles, and use of assurance techniques in a develop-
ment team‚Äù in RQ2.  
4.3. Ethical Considerations 
Our institutions‚Äô Institutional Review Boards approved this 
study, including the use of publicly available contact details 
for the survey invitations. Additionally, we modeled our re-
search plan and survey procedure to adhere to the strict data 
and privacy protection laws in the UK and Germany and the 
General Data Protection Regulation in the E.U. We provided 
all  participants  with  a  form  that  informed  them  about  the 
study purpose, the data we collected and stored, and an email 
address and phone number to contact the principal investiga-
tors in case they had questions or concerns. 
4.4. Survey Limitations 
As with most studies of this type, our work has limitations. 
The response rate for our online developer survey was very 
low, as might be expected from sending unsolicited emails to 
5 Specifically, log(ùë•&+	k), where k is chosen to minimize skewness [3]; in 
practice we trialed different values of k, finding no difference to the results, so 
used the conventional research practice of k=1. 
prospective participants. However, our recruitment approach 
was incorporated by relevant previous work [1,2,54]. The low 
response  rate  may  introduce  some  self-selection  bias,  but 
since the invitations made no mention of security, we have no 
reason  to  believe  a  priori  that  those  who  responded  differ 
meaningfully in terms of security or privacy behavior from 
those who did not. 
All the survey data‚Äîexcept download count and last app up-
date  date‚Äîis  self-reported.  Though  we  addressed  this  by 
keeping questions as fact-oriented as possible, this is an im-
portant limitation. 
In terms of the population, the survey reached app owners 
rather than all app developers; so, data about the respondents‚Äô 
own experience is not representative of all Android develop-
ers, nor of software developers in general. 
4.5. App Analysis Limitations 
The static analyses we chose each consider specific catego-
ries of vulnerabilities. This may disregard other categories of 
issues which may also be security critical. Indeed, many vul-
nerabilities‚Äîespecially privacy ones‚Äîwill tend to be in the 
intended app functionality rather than in the detailed imple-
mentation, and we have no way to estimate these. However, 
we used detectors for a range of implementation issues which 
may be found through other methods, and which developers 
who  consider  security  or  privacy  important  would  be  ex-
pected to address.  
Static program analysis tools often report false positives, and 
the tools we used are no exception. Our approach for this sur-
vey, however, was to assume that the reported issue counts 
will correlate with the numbers of true vulnerabilities, and 
therefore that such counts can be used as a proxy for aspects 
of app security in statistical analysis. 
We were able only to analyze ‚Äòfree‚Äô and ‚Äòfreemium‚Äô apps, not 
ones  where  Google  Play  Store  charges  for  download;  this 
may introduce a bias. In cases where respondents have more 
than one app, the app we downloaded may not be one requir-
ing the security practices and priorities described in the sur-
vey. 
We considered improving the app analysis by ranking vulner-
abilities  based  on  severity.  However,  the  analysis  did  not 
identify  vulnerabilities;  it  reported  counts  of  ‚Äòissues‚Äô  de-
tected, where an ‚Äòissue‚Äô is a potential vulnerability. To deter-
mine whether an issue represents a vulnerability would re-
quire detailed analysis of the source code; this source code 
was not available to the researchers, and decompilation was 
infeasible due to the widespread use of obfuscation tools. 
USENIX Association
29th USENIX Security Symposium    295
population median of 8 years; Mann Whitney ùëù=10234). 
will be seen, the respondents are generally more experienced 
than the corresponding general population (median 12 years; 
One concern was whether our app selection criterion (over 
100 downloads and one update) was too lenient, since little-
used apps may well have poor security. To test this, we used 
the Mann Whitney test comparing developers of apps with 
less than 1000 downloads against the rest6. We did this for all 
of the scores (Sections 3.6 and 4.2) and for all the numerically 
analyzable survey questions to see if the distribution was dif-
ferent  for  low-download  apps.  In  the  survey  results  and 
scores we found small p-values (<0.003) only for questions 
whose  answers  we  expected  to  correlate  with  download 
counts: ‚ÄòHow many apps have you developed‚Äô, ‚ÄòHow many 
Android apps have your developed‚Äô and ‚ÄòIs developing apps 
your  primary  job‚Äô,  and  we  concluded  that  the  populations 
were essentially the same. Doing the same Mann Whitney 
test on the scores in Phase 2, we found low p-values only for 
the Cryptographic API Misuse and Privacy Leak scores (p ~ 
0.016 for each). Though suggestive, these values are not sta-
tistically significant given the number of tests done on that 
same data. We concluded that there was no justification for 
changing our app selection criteria. 
Finally,  to  check  the  accuracy  of  respondents‚Äô  replies,  we 
compared the respondent-stated app update interval with ob-
jective evidence. App update histories are not generally avail-
able from Google Play, but we did collect the last update date 
for each app we considered. We correlated the time since that 
last update with the participant-stated update interval using 
log scales: Pearson R=0.38, P=1e-9 (n=242). The tiny P value 
corroborates the assumption that the stated update frequen-
cies  reflect  reality;  the  moderate  R  value  reflects  that  re-
spondents were asked the about updates to ‚Äòtheir most fre-
quently updated app‚Äô and not the app we considered, plus the 
randomness of where each app was in the release cycle. 
5.2. Findings on Self-Reported Developer Behavior 
The next sections describe the survey results for individual 
survey questions, without considering associations between 
answers7.  
Importance of Security and Privacy: Figure 6 shows respond-
ents‚Äô ratings of the importance of security and privacy in their 
apps.  For  comparison,  we  also  asked  and  show  the  im-
portance  of  other  functional  and  non-functional  require-
ments. We were surprised how many developers considered 
security and privacy important, with ratings comparable with 
multi-platform support and higher than for many features. 
7 The number of answers varies to each question or set of questions, giving 
different values for ‚Äòn‚Äô in each chart. 
Figure 4: Comparing Invitees (light blue)  
with Respondents (dark blue) 
We also considered distinguishing issues in the source code 
from issues in libraries, or using vulnerability ratings for li-
braries. However, although there have been several worth-
while tools developed to analyze the libraries used by An-
droid apps, including LibScout [6] and LibDetect [22], with 
the current state of the art they are not sophisticated enough 
to detect library versions reliably, nor are they integrated with 
other binary analysis tools to allow differentiation of issues 
in libraries from issues in the main code.  
5. Results 
This section describes our results, both from the survey and 
from the app analysis.  
5.1. Sample Validity 
Comparing the box plots for invitees with those for partici-
pants  in  Figure  4,  we  see  that  the  average  user  rating  and 
number of downloads for apps produced by the 345 develop-
ers who completed surveys are very similar to those for the 
55,000 invited. 
One survey question asked the respondent‚Äôs years of experi-
ence in software development. Figure 5 compares the results 
with answers to a similar question addressed to the 21,000 
Android  developers  out  of  the  89,000  developers  who  an-
swered the 2019 Stack Overflow developer survey [43]. As 
Figure 5: Development Experience 
6 We specified this analysis after data gathering; accordingly, significance in 
any of the correlations should be considered suspect. However, a lack of sig-
nificance in a wide range of correlation calculations is a valid finding. 
296    29th USENIX Security Symposium
USENIX Association
Figure 6: Importance of Different Requirements 
Team Structure: Only 42% of respondents were working in 
teams, the remainder being solo developers. Only 17% of re-
spondents  received  support  from  professional  security  ex-
perts. So, for RQ3 we calculate the ninety-five percent confi-
dence interval [48] for the proportion working with security 
experts in the Android app developer population as a whole 
as: 
Lower bound = 14%, Upper bound = 22% 
Figure 7: How Knowledgeable about Security 
Of these few professional security experts discussed by re-
spondents, 33% were part of the development team and the 
remainder external. Their most common function was Pene-
tration  Testing  (44%),  but  they  also  provided  Design  Re-
views (39%), Audits (33%) and Training (27%).  
Some teams (18%) had a ‚Äòsecurity champion‚Äô, a non-expert 
providing security input to the rest of the team. Only 7% had 
both professional experts and champions. 
Developer Security Knowledge: Figure 7 shows how survey par-
ticipants rated their security expertise. Interestingly, very few 
considered themselves to have no knowledge; this is as we 
would expect given the level of development experience of 
participants (Section 5.1). 
Use of Assurance Techniques: Figure 8 shows the reported use 
of assurance techniques. Unsurprisingly, Threat Assessment 
for every build is rare (possibly those respondents consider 
the list of threats every day), as is Penetration Testing (auto-
mated penetration testing, perhaps; one participant explicitly 
mentioned doing this). But otherwise the proportions using 
each are fairly consistent across all the techniques. 
Combinations  of  Assurance  Techniques:  We  investigated  the 
extent to which teams used combinations of assurance tech-
niques. Figure 9 summarizes how many and how often the 
techniques are used. It shows the proportion of respondents 
using each number of the techniques (at least), separated out 
to show how often they used them. As will be seen, less than 
half had used even one technique; about a quarter used one 
or more regularly; and very few used as many as four regu-
larly. 
Figure 8: Use of Assurance Techniques 
USENIX Association
29th USENIX Security Symposium    297
50%
40%
30%
20%
10%
0%
1
2
3
Every Build
Every Release
4
5
Occasionally
Figure 9: Proportion Using N Assurance Techniques 
So for RQ4, the 95% confidence intervals for the proportion 
regularly using one or more of the given assurance techniques 
in the wider Android developer population [48] are: 
Lower bound = 22%, Upper bound = 30% 
We analyzed which combinations of techniques were popular 
amongst the 14% (57) of respondents who only used two or 
three regularly. The most popular were: 
Auto. Static Analysis 
Auto. Static Analysis 
Code Review 
Threat Modelling 
Config. Review 
Code Review 
Config. Review 
Penetration Test 
37% 
32% 
21% 
18% 
Figure 10: Security Update Frequency (Cumulative) 
Security Updates: Figure 10 shows the frequency of security 
updates, calculated as the product of the reported update fre-
quency, and the reported proportion of security updates.  The 
95% confidence interval for the proportion with less than one 
update a year is 59% - 70%. 
5.3. Recent Changes in Team or Development Security 
Given how fast moving the field of software security has be-
come, it is also important to know what might have caused 
changes  in  the  developers‚Äô  perceptions  or  actions  around 
Figure 11: Top 5 Reasons for Security Changes 
security. Two questions in the survey addressed this: one list-
ing possible reasons for security and privacy improvements 
and  asking  which  had  affected  app  security;  and  for  those 
who mentioned an impact from the recent European GDPR 
legislation [19], a further question asking what changes they 
had made as a result. Since the GDPR legislation affects any 
apps sold in Europe, it impacts developers worldwide. 
Figure 11 shows the answers. Interestingly, the developers‚Äô 
perception is that, even more than GDPR, the main security 
driver  has  been  the  developers  themselves.  Encouragingly 
very few (3%) reported security improvements as a conse-
quence  of  actual  security  issues  affecting  themselves,  sug-
gesting that this is still rare; a few more (7%) reported ‚Äòhorror 
stories‚Äô‚Äîsomething bad happening to a competitor. 
Of the 45% of participants (n=133) who reported changes as 
a result of GDPR, Figure 12 summarizes the changes they 
made  as  a  result.  We  observe  that  the  majority  of  these 
changes were cosmetic, at least as far as the app itself was 
concerned: changing privacy policies or adding pop-up dia-
logs. Only 33 made substantive changes to improve user se-
curity or privacy (giving 95% confidence limits of 8% to 15% 
for the wider Android developer population [48]).  
5.4. Linear Analysis of Developer Survey Scores 
Table 1 shows the results of the analysis described in Section 
3.6. It correlates each of the two dependent scores represent-
ing ‚Äúsecurity-enhancing activities and interactions in the de-
velopment team‚Äù against four independent ‚Äúneed and mech-
anisms  for  security  and  privacy‚Äù  scores.  Non-italic  figures 
highlighted in yellow indicate a statistically significant result 
(p<0.01) 
Figure 12: Changes Due to GDPR 
298    29th USENIX Security Symposium
USENIX Association
Dependent: 
Assurance Technique Use 
Security Update Frequency 
Independent: 
Expertise Support 
Table 1: Pearson R Results (R, P) for Developer Survey Security Scores 
Developer  
Knowledge 
0.27, 8.6e-07 
0.03, 0.61 
0.56, 3.9e-25 
0.16, 0.0085 
0.37, 1.5e-11 
0.25, 2e-05 
Requirements 
Assurance  
Technique Use 
0.41, 5.7e-13 
Figure 13: Cross-plots of the Scores with Significant Correlations 
Figure 13 shows x-y plots of these significant results. Dots 
and vertical bars show the mean and its 95% confidence in-
terval for the y-readings corresponding to each x-value. The 
plots also show a simple linear regression line and its confi-
dence limits. The graphs validate the preconditions for the 
use of Pearson R [35]: particularly homoscedascity and lack 
of outliers.  
5.5. Post-Hoc Justification for Score Calculation and Analysis 
We observe that the first two plots also justify our choice of 
the  calculation  for  the  Requirements  Score  and  Expertise 
Support Score since the use of assurance techniques shows a 
strong linear relationship to both scores. 
For each of the six pairs of values highlighted in Table 1, we 
compared Decision Tree models with the corresponding lin-
ear models. (F-Test, with a cut-off alpha 0.01). We found no 
significant differences between the six pairs of models, which 
justifies using the simpler Pearson R (linear) model. See Ap-
pendix D for details. 
5.6. Findings on Application Security Indications  
In  the  Phase  2  analysis,  of  the  tools  used,  CogniCrypt  re-
ported no issues for 32% of apps; FlowDroid for 35% and the 
Bad  SSL/MalloDroid  combination  for  70%.  Only  20%  of 
apps analyzed showed no issues from any of the tools. 
5.7. Linear Analysis of App Analysis Scores 
Table 2 shows the results of the analysis described in Section 
4.2. It correlates each of three dependent scores representing 