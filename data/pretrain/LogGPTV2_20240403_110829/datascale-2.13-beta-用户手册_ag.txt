使用 ./bin/datascale 执行任何命令时，读取的配置文件 ./config/datascale.toml 中
的每个参数也都可以被相关的环境变量所覆盖。例如，使用指定的端口启动 DataScale manager
服务：
$ export DATASCALE_SERVICE_MODE="manager"
$ export DATASCALE_SERVICE_ADDRESS="localhost:8080"$ ./bin/datascale start
信息
更多关于环境变量使用方法的介绍，参见 环境变量。
版本：2.13.0-beta
Restful API
	信息 
关于 DataScale 服务的 Restful API 完整列表，参见 。
管理 Restful API 
DataScale 服务提供了丰富的 Restful API 用于管理数据采集任务相关的配置，包括：
• 配置用于管理 dataflow 的 worker group
• 配置 dataflow 及其内部 source、pipeline 和 sink 组件• 安装、删除自定义采集器
DataScale 命令行工具和 Web UI 上提供的各项管理功能都基于对这些 Restful API 的调用，这些 Restful API 同时也作为 DataScale worker 和 manager 之间同步配置数据的接口。指标 标 API 
指标 API 对外提供 DataScale 服务的指标数据，可用于对服务的监控。
Heartbeat API 
DataScale worker 和 manager 之间的 heartbeat 机制也是通过 Restful API 调用来完成。
版本：2.13.0-beta
进阶指南
更多 DataScale 的使用、部署指南。
📄限制系统资 统资源
当 DataScale 执行 dataflow 时，dataflow 的数量和繁重程度决定了 DataScale 服务消耗的系统资源的多少。
🗃 DataScale 集群
| 2 个项目 |
|---|
| 🗃自定义 义采集器 |
2 个项目
	版本：2.13.0-beta 
限制系统资 统资源2 个项目
	版本：2.13.0-beta 
限制系统资 统资源
当 DataScale 执行 dataflow 时，dataflow 的数量和繁重程度决定了 DataScale 服务消耗的系统 资源的多少。当你将 DataScale 服务和其他服务部署在同一台主机时，你可能会希望不要因为 DataScale 服务占用了过多的系统资源，而影响到其他服务的运行。这时，你可以设置 DataScale 服务可以使用的系统资源（CPU 和内存）的上限，确保其他服务可以得到必要的系统资源。
使用 Docker / Kubernetes
如果是在 Docker 或者 Kubernetes 的环境中运行 DataScale 服务，你可以使用它们的机制对容器
做资源限制。
具体方法可以参考 Docker 或者 Kubernetes 的资源管理相关文档。
使用 Systemd（只适用于 Linux 平台）使用 Systemd（只适用于 Linux 平台）
如果你是使用 Systemd 管理 DataScale 服务，Systemd 也提供了一套资源管理机制。
在安装 DataScale 服务之前，你可以修改 DataScale 安装包下的 Systemd 服务配置模版文件 init/systemd/datascale.service.template，打开资源限制的功能，并分配合适数量的 CPU 和内存资源。
假设你希望为 DataScale 服务设置的资源上限是最多用满一个 CPU core 以及最多使用 1GB 内 存，配置文件中的相关参数应该设置为：
[Service]
...
CPUAccounting=yes
对于已经安装或者正在运行中的 DataScale 服务，你可以修改 Systemd 服务配置文件 /usr/ lib/systemd/system/datascale.service中的上述参数以调整资源限制的设置，并重新 加载服务使新设置生效：$ sudo systemctl daemon-reload
如需了解更多细节，可以参考 Systemd 文档 。
使用 cgroup（只适用于 Linux 平台）
如果上述方式都不适用于你的使用场景，DataScale 服务还提供了内置的基于 cgroup 的资源限制机
制。在配置文件 config/datascale.toml 中， resources.cpu_quota 和 resources.memory_limit参数分别设置 CPU 和内存的使用上限。
假设你希望为 DataScale 服务设置的资源上限是最多用满一个 CPU core 以及最多使用 1GB 内 存，配置文件中的相关参数应该设置为：
[resources] 
# The CPU limit expressed as a percentage and is relative to a single core.# For examples: 
# 0 is "no limit"; 50 is 50% of a core; 200% is two cores.
cpu_quota = 100 
# Memory limit (in MB).
# For examples: 
# 0 is "no limit"; 1024 is 1GB 
memory_limit  = 1024
信息
• 目前，使用 cgroup 的方式限制系统资源需要使用 root 账号运行 DataScale 服务
• 修改配置文件中的上述参数后，需要重启 DataScale 服务使新参数生效
如需了解更多 cgroup 的技术细节，可以参考文档 .
版本：2.13.0-beta
DataScale 集群
关于使用 DataScale 集群功能的介绍。
📄部署 DataScale 集群📄部署 DataScale 集群
本文档将指导用户快速搭建一个简单的 DataScale 集群，包括一个 DataScale manager 和两个 DataScale worker。
📄管理 DataScale Worker 的群组
DataScale worker 的群组管理有两种方式：
版本：2.13.0-beta
部署 DataScale 集群
本文档将指导用户快速搭建一个简单的 DataScale 集群，包括一个 DataScale manager 和两个 DataScale worker。两个 DataScale worker 分别属于不同的 group，因此 DataScale manager 需要管理两个 worker 上的不同的 dataflow 配置。
信息
• 关于 DataScale 集群的工作机制，参见 DataScale 集群。• 关于 DataScale 集群的工作机制，参见 DataScale 集群。
• 本文档假设 DataScale 的 manager 和 worker 分别部署在不同的主机，因此不需要考虑 在同一台主机部署多个 DataScale 服务导致的端口地址冲突。关于修改 DataScale 服务 的监听地址，参见 Service 配置。
部署前的准备
• 完成文档 安装前的准备 中的准备步骤。
• 在炎凰数据平台中准备好数据集 my_datascale_cluster 。
手动 动部署 DataScale 集群
部署 manager
• 选择一台主机安装 DataScale，并参照文档 配置 DataScale 服务 完成配置：
◦ 服务在 manager 模式下运行
假设运行 manager 的主机名为 master1，则 manager 启动后的默认 Web UI 地址为http://master1:7880，默认 Restful API 地址为http://master1:7881。
• 参照文档 配置 Group，创建名称为 another_group 的 group。
部署 workers
另外选择两台主机安装 DataScale，并参照文档 配置 DataScale 服务 完成配置：
• 服务在 worker 模式下运行
• worker 所属的 manager 地址和 group
假设运行 worker 的两台主机名分别为 worker1 和 worker2，则他们的配置文件 config/ datascale.toml中的service配置分别为：
• worker1 分配到 group default
[service] 
mode = "worker" 
[service.worker]mode = "worker" 
[service.worker] 
	manager_address = "http://master1:7881" 	groups = "default"
• worker2 分配到 group another_group
[service] 
mode = "worker" 
[service.worker] 
	manager_address = "http://master1:7881" 	groups = "another_group"
创建 dataflow
参照文档 配置 Dataflow，分别在 manager 上的 group default 和 another_group 中创建 dataflow。这些新创建的 dataflow 将会立刻自动同步到对应的 worker。
• 在 default group 中创建 dataflow default_dataflow ，配置如下：{ 
	"name": "default_dataflow", 
	"sources": [ 
	{ 
	"name": "my_source", 
	"type": "exec", 
	"conf": { 
	"command": "echo \"Dataflow is default_dataflow and host is $HOSTNAME\"", 
	"mode": "scheduled", 
	"scheduled": { 
	"exec_interval_secs": 10 
	} 
	} 
	} 
	], 
	"pipelines": [], 
	"sinks": [ 
	{ 
	"name": "my_sink", 
	"inputs": [ "my_source" ], 
	"type": "yh", 
	"conf": { 
	"event_set": "my_datascale_cluster""event_set": "my_datascale_cluster" 
	} 
	} 
	]
• 在 another_group group 中创建 dataflow another_dataflow ，配置如下：
{ 
	"name": "another_dataflow", 
	"sources": [ 
	{ 
	"name": "my_source", 
	"type": "exec", 
	"conf": { 
	"command": "echo \"Dataflow is another_dataflow and host is $HOSTNAME\"", 
	"mode": "scheduled", 
	"scheduled": { 
	"exec_interval_secs": 10 
	} 
	} 
	} 
	], 
	"pipelines": [],} 
	} 
	} 
	], 
	"pipelines": [], 
	"sinks": [ 
	{ 
	"name": "my_sink", 
	"inputs": [ "my_source" ], 
	"type": "yh", 
	"conf": { 
	"event_set": "my_datascale_cluster" 
	} 
	} 
	] 
}
在 DataScale Web UI 中查 查看部署状态
在 DataScale Monitoring 仪 仪表板中查 查看部署状态
仪表板中可以看到一个 manager，两个 worker，以及 group、dataflow 及其组件的数量等：
在炎凰数据平台中查询 查询 workers 采集到的 events 
从查询数据集 my_datascale_cluster 得到的 events 可以看到两个 worker 分别执行了不同group 中的 dataflow：
使用 Ansible 部署 DataScale 集群
信息
目前，DataScale Ansible 工具包仅支持在具有 Systemd 服务管理器的 Linux 操作系统上部
署 DataScale 集群。
部署前的准备
• 在控制主机上安装 。
• 设置从控制主机到即将安装 DataScale manager 和 worker 的三台主机的 SSH 连接。
• 下载 DataScale Ansible 工具包。
	信息 
工具包可通过以下两种方式获得：
◦ U盘直接拷贝
◦ 在线下载(链接由炎凰数据团队提供)
初始化安装包和配置文件
• 将 DataScale Ansible 工具包拷贝到控制主机，并解压工具包
$ tar zxvf datascale-ansible-X.Y.Z.tar.gz 
$ cd datascale-ansible/$ cd datascale-ansible/ 
$ ls 
README.md       config          hosts           playbook vars.yaml
• 将 DataScale 安装包拷贝至 ./playbook/files/ 目录下
• 从安装包中提取出初始配置，存放至 ./config/ 目录
	信息 
如果你不需要集中管理 DataScale 部署的配置文件，你可以：
◦ 只提取 config/datascale.toml 配置文件至 ./config/ 目录
◦ 后续的 DataScale 服务配置、group 和 dataflow 的创建等步骤，都可以在 	DataScale 服务部署之后再通过 DataScale manager 的 Web UI 完成配置。$ tar zxvf playbook/files/datascale-X.Y.Z-x86_64-linux.tar.gz-C config/ --transform 's,^datascale/config,,' datascale/ config/ 
$ ls config/ 