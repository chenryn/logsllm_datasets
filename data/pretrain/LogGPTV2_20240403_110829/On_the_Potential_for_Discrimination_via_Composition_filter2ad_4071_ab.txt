### Methodology for Generating Compositions

Our method employs a greedy approach to combine the most skewed individual targeting attributes. Specifically, we approximate the 1,000 most skewed pairwise targeting compositions by combining the 46 most skewed individual attributes using a logical AND, resulting in 1,035 pairs, from which we randomly sample. To avoid very niche targetings, our method only considers individual targetings and pairs with a total reach of at least 10,000.

### Limitations

Our methodology has several limitations. First, our results are dependent on and subject to the quality of the ad platforms' sensitive attribute data. Second, the size statistics provided by these ad platforms may be affected by the presence of fake accounts or users with multiple accounts. Third, while we measure the skew in audiences arising from targeting, the operation of the ad platform's ad delivery system might introduce additional skews [4].

### Experiments

#### 4.1 Facebook’s Restricted Interface

We first investigate whether targeting compositions could exacerbate the potential for discrimination on Facebook’s restricted interface for ads in protected categories. For each set of targetings, we use box plots to visualize the distribution of representation ratios for males and users aged 18-24, as shown in Figure 1 (and for other age ranges in Figure 4 of Appendix A). Throughout the paper, we only show results for targetings with a total reach of 10,000 or more.

**Individual Targeting:**
For gender, we focus on the Individual column in the first box plot of Figure 1. The 393 targeting attributes offered by Facebook on its restricted interface show some evidence of gender skew. The 90th and 10th percentile representation ratios for males are 1.84 and 0.5, respectively, indicating that males are nearly twice as likely to be picked as females, and vice versa. For age, focusing again on the Individual column, we observe similar results across all age ranges studied. The 10th and 90th percentile representation ratios for the 18–24 age range are 0.39 and 1.39, respectively.

Despite the presence of some skewed attributes, the interface is still highly sanitized, excluding many highly skewed individual targeting attributes observed in Facebook’s normal interface, including hundreds of thousands of free-form attributes (e.g., "Interested in Marie Claire," which has a 0.08 representation ratio towards males).

**Compositional Targeting:**
Next, we study whether compositions of individual targetings (via a logical AND) on the sanitized interface could exacerbate the potential for discriminatory advertising. We select 1,000 random pairs of targeting attributes ("Random 2-way") and also use the approach in § 3 to discover the top 1,000 pairs of targeting attributes most skewed towards ("Top 2-way") and against ("Bottom 2-way") the given sensitive population.

Comparing the resulting skew of these compositions to the skew exhibited by individual targeting options in Figure 1, we observe that random pairs of attributes often lead to more skewed distributions, such as with the 18–24 age range, where combinations tend to make the resulting audience even more skewed away from the 18–24 group.

Focusing on the most skewed combinations, the sets of "Top 2-way" and "Bottom 2-way" targetings show additional skew, with 10th percentiles reaching as low as 0.1 and 90th percentiles as high as 8.98. For example, targeting users interested in Electrical Engineering and Cars yielded a representation ratio of 12.43 towards males, compared to smaller representation ratios (3.71 and 2.18, respectively) for each individual attribute.

We repeat the experiment with three targetings composed instead of two, creating "Top 3-way" and "Bottom 3-way" targetings for gender in Figure 1. The 90th percentile representation ratio for the "Top 3-way" targetings is 19.77, and the 10th percentile representation ratio for the "Bottom 3-way" targetings is 0.11, indicating a further increase in the degree of skew.

**Summary:**
Our findings show that compositions of targeting options can be abused to target skewed sets of users, exhibiting a greater degree of skew towards (or away from) particular ages and genders compared to individual targeting options. This is true even in the context of a highly sanitized advertising interface, indicating that significant additional work is needed to ensure these systems cannot be used for discriminatory advertising.

#### 4.2 Individual Targeting

We examine the skews arising from targeting various default targeting attributes on each platform individually. Focusing on the Individual column in the three sections of Figure 2 (and of Figure 4 of Appendix A), we make two observations:

1. **Varying Distributions of Skew:** Attributes from different platforms show varying distributions of skew. For example, LinkedIn’s targeting attributes are generally more skewed towards males, with a 90th percentile representation ratio of 2.09, while Facebook’s targeting attributes are more skewed towards females, with a 90th percentile representation ratio of 1.45. Google’s and LinkedIn’s targeting attributes are generally more skewed away from the youngest users (ages 18–24) and skewed towards the oldest users (ages 55+).
2. **Skewed Targeting Attributes:** In all cases, we see that there exist a number of skewed targeting attributes that may violate the four-fifths rule, especially concerning in the context of LinkedIn, which focuses on employment.

#### 4.3 Compositional Targeting

**Potential for Discrimination:**
We perform the experiments from § 4.1 on different ad platforms, plotting the distribution of representation ratios for random pairs of attributes and for the 1,000 most skewed pairs in Figure 2 (and in Figure 4 of Appendix A). Across ad platforms, we find that randomly chosen pairs of targeting attributes show modest additional skew, exacerbating the skew against smaller ages (18–24) on LinkedIn. The most skewed pairs of targeting attributes clearly indicate the exacerbated potential for discrimination from composition, with over 90 percent falling outside the thresholds of the four-fifths rule.

**Recall of Targeting Compositions:**
We study if an advertiser could selectively reach a large number of users (i.e., achieve a high recall) of a particular sensitive population using the previously highly skewed targeting pairs. For each set of targetings, we take skewed targetings that fall outside the thresholds of the four-fifths rule and plot the distribution of corresponding recalls of the given sensitive population. While we show results for gender and various age ranges in Figure 5 of Appendix A, we focus on results for females here.

We find that while skewed pairwise targeting compositions have substantial recalls, these typically correspond to small fractions of the overall target sensitive population on the platform. For example, the 90th percentile recall for the "Top 2-way" skewed compositions is 5M (4.17%), 30M (25%), 1.7M (0.14%), and 560K (0.79%) for Facebook’s restricted interface, Facebook’s full interface, Google, and LinkedIn, respectively. However, since most advertisers on these platforms only spend up to a few hundred dollars per ad on average, with tens of thousands of impressions [13], these recalls may still be appealing.

**Increasing Recall:**
We then study whether an advertiser could increase their recall even further by targeting ads across multiple skewed compositions. We measure the pairwise overlaps between the sets of females reached by the top 100 female-skewed targeting compositions and find a median pairwise overlap of approximately 22%, 15%, and 0% for Facebook’s restricted interface, Facebook’s full interface, and LinkedIn, respectively. This low overlap indicates the potential to increase recall further.

We confirm this by estimating the total recall of males across the union of the top 10 male-skewed compositions. While the top female-skewed composition on Facebook’s restricted interface, Facebook’s full interface, and LinkedIn had a recall of 1.1M (0.9%), 270K (0.2%), and 28K (0.0%), respectively, the total recall across the top 10 female-skewed compositions was significantly higher, i.e., 6.1M (5.1%), 4M (3.3%), and 1.1M (1.6%), respectively.

**Removing Skewed Individual Targetings:**
Finally, we study whether removing the most skewed individual targeting attributes is sufficient to mitigate against skew in targeting compositions. For each sensitive population, we successively remove the most skewed individual targeting attributes in steps of two percentiles and use the greedy method to obtain the "Top 2-way" and "Bottom 2-way" sets of most skewed compositions. We plot the resulting variation in representation ratio for gender (males) in Figure 3 and obtain similar results for different age ranges in Figure 6 of Appendix A.

We observe that the removal of the most skewed individual targetings leads, unsurprisingly, to a drop in the skew of the resulting compositions. However, the compositions of the remaining targeting attributes still yield highly skewed rules. For example, even with the removal of the top 10th percentile of male-skewed individual attributes for Facebook’s restricted interface, the 90th percentile of resulting "Top 2-way" representation ratios was 3.02, and the highest resulting representation ratio was 5.23.

### Concluding Discussion

In this paper, we performed the first study showing that the potential for discriminatory targeting, previously reported in the context of Facebook, exists across multiple ad platforms. Moreover, ad platforms allow advertisers to compose individual ad targeting options, which can exacerbate the potential for intentional or unintentional discriminatory targeting, even for a highly sanitized ad interface such as Facebook’s restricted interface.

**Mitigations:**
While prior work [37] showed that disabling the use of obviously stereotypically skewed targeting attributes was insufficient, this paper further shows that even an approach based on removing all highly skewed individual targeting attributes is also likely insufficient. Thus, our work reinforces the need to base mitigations against discriminatory advertising on the outcome of the targeting, rather than on the targeting itself. For example, ad platforms could potentially use anomaly detection based on the outcome of ad targeting to detect advertisers who consistently target skewed audiences. Any flagged advertisers could then be subject to further review about whether their use of targeting options is justifiable.

**Ethics:**
While conducting this work, we carefully considered the ethical issues and took care to ensure our work was consistent with best practices. We did not collect any individual user data; rather, we only collected high-level, obfuscated audience size statistics provided by the ad platforms to all advertisers. Additionally, our experiments did not impact users directly, as we did not run ads. We also minimized the load placed on the ad platforms by limiting both the count and rate of API queries we made.

### Acknowledgements

We thank the anonymous reviewers and our shepherd, Marco Mellia, for their valuable comments. This research was supported in part by NSF grant CNS-1916020. Additionally, Giridhari Venkatadri acknowledges support from a Facebook Fellowship.

### References

[1] 12 CFR § 202.4 (b) – Discouragement. https://www.law.cornell.edu/cfr/text/12/202.4.
[2] 24 CFR § 100.75 – Discriminatory advertisements, statements and notices. https://www.law.cornell.edu/cfr/text/24/100.75.
[3] 29 USC § 623 – Prohibition of age discrimination. https://www.law.cornell.edu/uscode/text/29/623.
[4] M. Ali, P. Sapiezynski, M. Bogen, A. Korolova, A. Mislove, and A. Rieke. Discrimination through Optimization: How Facebook’s Ad Delivery can Lead to Biased Outcomes. CSCW, 2019.
[5] M. Ali, P. Sapiezynski, A. Korolova, A. Mislove, and A. Rieke. Ad Delivery Algorithms: The Hidden Arbiters of Political Messaging. arXiv preprint arXiv:1912.04255, 2019.
[6] About Audiences for Special Ad Categories. https://www.facebook.com/business/help/2220749868045706.
[7] About Customer Match. https://support.google.com/adwords/answer/6379332?hl=en.
[8] D. Biddle. Adverse Impact and Test Validation: A Practitioner’s Guide to Valid and Defensible Employment Testing. Gower, 2005.
[9] S. Barocas and A. D. Selbst. Big data’s disparate impact. Cal. Law Rev., 104, 2016.
[10] A. Datta, A. Datta, J. Makagon, D. K. Mulligan, and M. C. Tschantz. Discrimination in Online Employment Testing. FAT*, 2018.
[11] A. Datta, M. C. Tschantz, and A. Datta. Automated Experiments on Ad Privacy Settings: A Tale of Opacity, Choice, and Discrimination. PETS, 2015.
[12] E. Dreyfuss. Facebook Changes Its Ad Tech to Stop Discrimination. WIRED. https://www.wired.com/story/facebook-advertising-discrimination-settlement/.
[13] L. Edelson, S. Sakhuja, R. Dey, and D. McCoy. An Analysis of United States Online Political Advertising Transparency. https://arxiv.org/abs/1902.04385.
[14] Exhibit a – Programmatic Relief. https://nationalfairhousing.org/wp-content/uploads/2019/03/FINAL-Exhibit-A-3-18.pdf.
[15] Facebook Engages in Housing Discrimination with Its Ad Practices, U.S. Says. https://www.nytimes.com/2019/03/28/us/politics/facebook-housing-discrimination.html.
[16] Facebook Lets Advertisers Exclude Users by Race. https://www.propublica.org/article/facebook-lets-advertisers-exclude-users-by-race/.
[17] Facebook: About Facebook Pixel. https://www.facebook.com/business/help/742478679120153.
[18] Facebook: About Lookalike Audiences. https://www.facebook.com/business/help/164749007013531.
[19] Facebook: Best Practices for Detailed Targeting. https://www.facebook.com/business/help/192687867014264.
[20] Facebook: Brand Safety Controls. https://www.facebook.com/business/help/905095143159925.
[21] Facebook: Use Detailed Targeting. https://web.archive.org/web/20200429194031/https://www.facebook.com/business/help/440167386536513.
[22] Get Started with LinkedIn Website Retargeting. http://web.archive.org/web/20200601191411/https://www.linkedin.com/help/lms/answer/73934.
[23] Google: About audience targeting. https://support.google.com/google-ads/answer/2497941?hl=en.
[24] Google: About contextual targeting. https://support.google.com/google-ads/answer/2404186?hl=en.
[25] Google: About managed placements. https://support.google.com/google-ads/answer/2470108?hl=en.
[26] Google: About remarketing setup. https://support.google.com/google-ads/answer/2454000?hl=en.
[27] Google: About similar audiences on the Display Network. https://support.google.com/google-ads/answer/2676774?hl=en.
[28] Google: About topic targeting. https://support.google.com/google-ads/answer/2497832?hl=en.
[29] Google: Frequency capping: Definition. https://support.google.com/google-ads/answer/2454000?hl=en.
[30] Google: How to use combined audiences. https://support.google.com/google-ads/answer/117579?hl=en.