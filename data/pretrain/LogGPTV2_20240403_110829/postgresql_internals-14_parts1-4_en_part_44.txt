Hash Cond: (f.aircraft_code = s.aircraft_code)
−> Seq Scan on flights f (cost=0.00..4772.67 rows=214867 widt...
(actual rows=214867 loops=1)
−> Hash (cost=21.39..21.39 rows=1339 width=15)
(actual rows=1339 loops=1)
Buckets: 2048 Batches: 1 Memory Usage: 79kB
−> Seq Scan on seats s (cost=0.00..21.39 rows=1339 width=15)
(actual rows=1339 loops=1)
(10 rows)
1 backend/optimizer/plan/createplan.c,create_hashjoin_planfunction
2 backend/optimizer/path/costsize.c,initial_cost_hashjoinandfinal_cost_hashjoinfunctions
420
22.1 HashJoins
Thestartupcostofthejoinreflectsprimarilythecostofhashtablecreationand
includesthefollowingcomponents:
• thetotalcostoffetchingtheinnerset,whichisrequiredtobuildthehashtable
• thecostofcalculatingthehashfunctionofallthecolumnsincludedintothe
joinkey,foreachrowoftheinnerset(estimatedatcpu_operator_cost perop- 0.0025
eration)
• the cost of insertion of all the inner rows into the hash table (estimated at
cpu_tuple_costperinsertedrow) 0.01
• thestartupcostoffetchingtheoutersetofrows,whichisrequiredtostartthe
joinoperation
Thetotalcostcomprisesthestartupcostandthecostofthejoinitself,namely:
• thecostofcomputingthehashfunctionofallthecolumnsincludedintothe
joinkey,foreachrowoftheouterset(cpu_operator_cost)
• thecostofjoinconditionrechecks,whicharerequiredtoaddresspossiblehash
collisions(estimatedatcpu_operator_costpereachcheckedoperator)
• theprocessingcostforeachresultingrow(cpu_tuple_cost)
The number of required rechecks is the hardest to estimate. It is calculated by
multiplyingthenumberofrowsoftheoutersetbysomefractionoftheinnerset
(storedinthehashtable). Toestimatethisfraction,theplannerhastotakeinto
accountthatdatadistributionmaybenon-uniform. Iwillspareyouthedetailsof
thesecomputations;1inthisparticularcase,thisfractionisestimatedat..
Thus,thecostofourqueryisestimatedasfollows:
=> WITH cost(startup) AS (
SELECT round((
21.39 +
current_setting('cpu_operator_cost')::real * 1339 +
current_setting('cpu_tuple_cost')::real * 1339 +
0.00
)::numeric, 2)
)
1 backend/utils/adt/selfuncs.c,estimate_hash_bucket_statsfunction
421
Chapter22 Hashing
SELECT startup,
startup + round((
4772.67 +
current_setting('cpu_operator_cost')::real * 214867 +
current_setting('cpu_operator_cost')::real * 214867 * 1339 *
0.150112 +
current_setting('cpu_tuple_cost')::real * 16518865
)::numeric, 2) AS total
FROM cost;
startup | total
−−−−−−−−−+−−−−−−−−−−−
38.13 | 278507.26
(1 row)
Andhereisthedependencygraph:
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Hash Join
(cost=38.13..278507.28 rows=16518865 width=78)
Hash Cond: (f.aircraft_code = s.aircraft_code)
−> Seq Scan on flights f
(cost=0.00..4772.67 rows=214867 width=63)
−> Hash
(cost=21.39..21.39 rows=1339 width=15)
−> Seq Scan on seats s
(cost=0.00..21.39 rows=1339 width=15)
(9 rows)
Two-Pass Hash Joins
Iftheplanner’sestimationsshowthatthehashtablewillnotfittheallocatedmem-
ory,theinnersetofrowsissplitintobatchestobeprocessedseparately.Thenum-
berofbatches(justlikethenumberofbuckets)isalwaysapoweroftwo;thebatch
touseisdeterminedbythecorrespondingnumberofbitsofthehashkey.1
Anytwomatchingrowsbelongtooneandthesamebatch: rowsplacedintodiffer-
entbatchescannothavethesamehashcode.
1 backend/executor/nodeHash.c,ExecHashGetBucketAndBatchfunction
422
22.1 HashJoins
Allbatchesholdanequalnumberofhashkeys.Ifthedataisdistributeduniformly,
batch sizes will also be roughly the same. The planner can control memory con-
sumptionbychoosinganappropriatenumberofbatches.1
Atthefirststage,theexecutorscanstheinnersetofrowstobuildthehashtable.
Ifthescannedrowbelongstothefirstbatch,itisaddedtothehashtableandkept
in.Otherwise,itiswrittenintoatemporaryfile(thereisaseparatefileforeach
batch).2
The total volume of temporary files that a session can store on disk is limited by the
temp_file_limit parameter (temporarytables are not included into this limit). As soon as −1
thesessionreachesthisvalue,thequeryisaborted.
inner
set
outer
set
Atthesecondstage,theoutersetisscanned.Iftherowbelongstothefirstbatch,
itismatchedagainstthehashtable,whichcontainsthefirstbatchofrowsofthe
innerset(therecanbenomatchesinotherbatchesanyway).
Iftherowbelongstoadifferentbatch,itisstoredinatemporaryfile,whichisagain
createdseparatelyforeachbatch. Thus,N batchescanuse2(N−1)files(orfewer
ifsomeofthebatchesturnouttobeempty).
Oncethesecondstageiscomplete,thememoryallocatedforthehashtableisfreed.
Atthispoint,wealreadyhavetheresultofthejoinforoneofthebatches.
1 backend/executor/nodeHash.c,ExecChooseHashTableSizefunction
2 backend/executor/nodeHash.c,ExecHashTableInsertfunction
423
Chapter22 Hashing
inner
set
outer
set
Both stages are repeated for each of the batches saved on disk: the rows of the
innersetaretransferredfromthetemporaryfiletothehashtable;thentherows
oftheoutersetrelatedtothesamebatcharereadfromanothertemporaryfileand
matchedagainstthishashtable.Onceprocessed,temporaryfilesgetdeleted.
outer
set
Unlikeasimilaroutputforaone-passjoin,theoutputofthecommandfor
atwo-passjoincontainsmorethanonebatch.Ifrunwiththeoption,this
commandalsodisplaysstatisticsondiskaccess:
=> EXPLAIN (analyze, buffers, costs off, timing off, summary off)
SELECT *
FROM bookings b
JOIN tickets t ON b.book_ref = t.book_ref;
424
22.1 HashJoins
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Hash Join (actual rows=2949857 loops=1)
Hash Cond: (t.book_ref = b.book_ref)
Buffers: shared hit=7225 read=55637, temp read=55126
written=55126
−> Seq Scan on tickets t (actual rows=2949857 loops=1)
Buffers: shared read=49415
−> Hash (actual rows=2111110 loops=1)
Buckets: 65536 Batches: 64 Memory Usage: 2277kB
Buffers: shared hit=7225 read=6222, temp written=10858
−> Seq Scan on bookings b (actual rows=2111110 loops=1)
Buffers: shared hit=7225 read=6222
(11 rows)
I have already shown this query above with an increased work_mem setting. The
defaultvalueofistoosmallforthewholehashtabletofit;inthisexam-
ple,the dataissplitinto  batches,and thehashtableuses  =  buckets.
Asthehashtableisbeingbuilt(theHashnode),thedataiswrittenintotemporary
files(tempwritten);atthejoinstage(theHashJoinnode),temporaryfilesareboth
readandwritten(tempread,written).
Tocollectmorestatisticsontemporaryfiles,youcansetthelog_temp_filesparam- −1
etertozero. Thentheserverlogwilllistallthetemporaryfilesandtheirsizes(as
theyappearedatthetimeofdeletion).
DynamicAdjustments
Theplannedcourseofeventsmaybedisruptedbytwoissues: inaccuratestatistics
andnon-uniformdatadistribution.
If the distribution of values in the join key columns is non-uniform, different
batcheswillhavedifferentsizes.
Ifsomebatch(exceptfortheveryfirstone)turnsouttobetoolarge,allitsrows
will have to be written to disk and then read from disk. It is the outer set that
causes most of the trouble, as it is typically bigger. So if there are regular, non-
multivariatestatisticsonsoftheouterset(thatis,theoutersetisrepresented p.
425
Chapter22 Hashing
byatable,andthejoinisperformedbyasinglecolumn),rowswithhashcodescor-
respondingtosareconsideredtobeapartofthefirstbatch.1 Thistechnique
(calledskewoptimization)canreducethe/overheadofatwo-passjointosome
extent.
Becauseofthesetwofactors,thesizeofsome(orall)batchesmayexceedtheesti-
mation.Thenthecorrespondinghashtablewillnotfittheallocatedmemorychunk
andwillsurpassthedefinedlimits.
Soifthehashtablebeingbuiltturnsouttoobig,thenumberofbatchesisincreased
(doubled)onthefly. Eachbatchisvirtuallysplitintotwonewones: abouthalfof
therows(assumingthatthedistributionisuniform)isleftinthehashtable,while
theotherhalfissavedintoanewtemporaryfile.2
Such a split can happen even if a one-pass join has been originally planned. In
fact,one-andtwo-passjoinsuseoneandthesamealgorithmimplementedbythe
samecode;Isinglethemoutheresolelyforsmoothernarration.
The number of batches cannot be reduced. If it turns out that the planner has
overestimatedthedatasize,batcheswillnotbemergedtogether.
Inthecaseofnon-uniformdistribution,increasingthenumberofbatchesmaynot
help.Forexample,ifthekeycolumncontainsoneandthesamevalueinallitsrows,
theywillbeplacedintothesamebatchsincethehashfunctionwillbereturning
the same value over and over again. Unfortunately,the hash table will continue
growinginthiscase,regardlessoftheimposedrestrictions.
Intheory,thisissuecouldbeaddressedbyamulti-passjoin,whichwouldperformpartial
scansofthebatch,butitisnotsupported.
Todemonstrateadynamicincreaseinthenumberofbatches,wefirsthavetoper-
p. formsomemanipulations:
=> CREATE TABLE bookings_copy (LIKE bookings INCLUDING INDEXES)
WITH (autovacuum_enabled = off);
=> INSERT INTO bookings_copy SELECT * FROM bookings;
INSERT 0 2111110
1 backend/executor/nodeHash.c,ExecHashBuildSkewHashfunction
2 backend/executor/nodeHash.c,ExecHashIncreaseNumBatchesfunction
426
22.1 HashJoins
=> DELETE FROM bookings_copy WHERE random()  ANALYZE bookings_copy;
=> INSERT INTO bookings_copy SELECT * FROM bookings
ON CONFLICT DO NOTHING;
INSERT 0 1899264
=> SELECT reltuples FROM pg_class WHERE relname = 'bookings_copy';
reltuples
−−−−−−−−−−−
211846
(1 row)
As a result, we get a new table called bookings_copy. It is an exact copy of the
bookings table, but the planner underestimates the number of rows in it by ten
times.Asimilarsituationmayoccurifthehashtableisgeneratedforasetofrows
producedbyanotherjoinoperation,sothereisnoreliablestatisticsavailable.
Thismiscalculationmakestheplannerthinkthatbucketsareenough,butwhile
thejoinisbeingperformed,thisnumbergrowsto:
=> EXPLAIN (analyze, costs off, timing off, summary off)
SELECT *
FROM bookings_copy b
JOIN tickets t ON b.book_ref = t.book_ref;
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Hash Join (actual rows=2949857 loops=1)
Hash Cond: (t.book_ref = b.book_ref)
−> Seq Scan on tickets t (actual rows=2949857 loops=1)
−> Hash (actual rows=2111110 loops=1)
Buckets: 65536 (originally 65536) Batches: 32 (originally 8)
Memory Usage: 4040kB
−> Seq Scan on bookings_copy b (actual rows=2111110 loops=1)
(7 rows)
Costestimation. Ihavealreadyusedthisexampletodemonstratecostestimation
foraone-passjoin,butnowIamgoingtoreducethesizeofavailablememoryto
theminimum,sotheplannerwillhavetousetwobatches.Itincreasesthecostof
thejoin:
427
Chapter22 Hashing
=> SET work_mem = '64kB';
=> EXPLAIN (analyze, timing off, summary off)
SELECT * FROM flights f
JOIN seats s ON s.aircraft_code = f.aircraft_code;
QUERY PLAN
−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−
Hash Join (cost=45.13..283139.28 rows=16518865 width=78)
(actual rows=16518865 loops=1)
Hash Cond: (f.aircraft_code = s.aircraft_code)
−> Seq Scan on flights f (cost=0.00..4772.67 rows=214867 widt...
(actual rows=214867 loops=1)
−> Hash (cost=21.39..21.39 rows=1339 width=15)
(actual rows=1339 loops=1)
Buckets: 2048 Batches: 2 Memory Usage: 55kB
−> Seq Scan on seats s (cost=0.00..21.39 rows=1339 width=15)
(actual rows=1339 loops=1)
(10 rows)
=> RESET work_mem;
The cost of the second pass is incurred by spilling rows into temporary files and
readingthemfromthesefiles.
The startup cost of a two-pass join is based on that of a one-pass join, which is
increasedbytheestimatedcostofwritingasmanypagesasrequiredtostoreall
thenecessaryfieldsofalltherowsoftheinnerset.1 Althoughthefirstbatchisnot
writtentodiskwhenthehashtableisbeingbuilt,theestimationdoesnottakeit
intoaccountandhencedoesnotdependonthenumberofbatches.
Initsturn,thetotalcostcomprisesthetotalcostofaone-passjoinandtheesti-
matedcostsofreadingtherowsoftheinnersetpreviouslystoredondisk,aswell
asreadingandwritingtherowsoftheouterset.
Bothwritingandreadingareestimatedatseq_page_costperpage,as/operations
areassumedtobesequential.
Inthisparticularcase,thenumberofpagesrequiredfortheinnersetisestimatedat
,whilethedataoftheoutersetisexpectedtofitpages.Havingaddedthese
estimationstotheone-passjoincostcalculatedabove,wegetthesamefiguresas
showninthequeryplan:
1 backend/optimizer/path/costsize.c,page_sizefunction
428
22.1 HashJoins
=> SELECT 38.13 + -- startup cost of a one-pass join
current_setting('seq_page_cost')::real * 7
AS startup,
278507.28 + -- total cost of a one-pass join
current_setting('seq_page_cost')::real * 2 * (7 + 2309)
AS total;
startup | total
−−−−−−−−−+−−−−−−−−−−−
45.13 | 283139.28
(1 row)
Thus,ifthereisnotenoughmemory,thejoinisperformedintwopassesandbe-
comeslessefficient.Therefore,itisimportanttoobservethefollowingpoints:
• Thequerymustbecomposedinawaythatexcludesredundantfieldsfromthe
hashtable.
• The planner must choose the smaller of the two sets of rows when building
thehashtable.
Using Hash Joins in Parallel Plans v..
Thehashjoinalgorithmdescribedabovecanalsobeusedinparallelplans. First,
severalparallelprocessesbuildtheirown(absolutelyidentical)hashtablesforthe
inner set, independently of each other; then they start processing the outer set
concurrently. Theperformancegainhereisduetoeachprocessscanningonlyits
ownshareofouterrows.
Thefollowingplanusesaregularone-passhashjoin:
=> SET work_mem = '128MB';
=> SET enable_parallel_hash = off;
=> EXPLAIN (analyze, costs off, timing off, summary off)
SELECT count(*)
FROM bookings b
JOIN tickets t ON t.book_ref = b.book_ref;
429
Chapter22 Hashing