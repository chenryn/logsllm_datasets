title:PhotoProof: Cryptographic Image Authentication for Any Set of Permissible
Transformations
author:Assa Naveh and
Eran Tromer
2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy
PhotoProof: Cryptographic Image Authentication
for Any Set of Permissible Transformations
Assa Naveh∗ and Eran Tromer†
Blavatnik School of Computer Science, Tel Aviv University
Email: ∗PI:EMAIL, †PI:EMAIL
Tel Aviv, Israel
Abstract—Since the invention of the camera, photos have been
used to document reality and to supply proof of events. Yet today
it is easy to fabricate realistic images depicting events that never
happened. Thus, dozens of papers strive to develop methods
for authenticating images. While some commercial cameras
already attach digital signatures to photographs, the images
often undergo subsequent transformations (cropping, rotation,
compression, and so forth), which do not detract from their
authenticity, but do change the image data and thus invalidate the
signature. Existing methods address this by signing derived image
properties that are invariant to some set of transformations.
However, these are limited in the supported transformations, and
often offer weak security guarantees.
We present PhotoProof, a novel approach to image authen-
tication based on cryptographic proofs. It can be conﬁgured,
according to application requirements, to allow any permissible
set of (efﬁciently computable) transformations. Starting with a
signed image, our scheme attaches, to each legitimately derived
image, a succinct proof of computational integrity attesting that
the transformation was permissible. Anyone can verify these
proofs, and generate updated proofs when applying further
permissible transformations. Moreover,
the proofs are zero-
knowledge so that, for example, an authenticated cropped image
reveals nothing about the cropped-out regions.
PhotoProof is based on Proof-Carrying Data (PCD), a cryp-
tographic primitive for secure execution of distributed compu-
tations. We describe the new construction, prove its security,
and demonstrate a working prototype supporting a variety of
permissible transformations.
I. INTRODUCTION
A. Background
Photography is one of the most prevalent media in the
modern age, and digital cameras are nowadays ubiquitous
and integrated into mobile phones and portable computers.
Photos are usually considered reliable and convincing, and are
relied upon in personal, commercial and legal contexts, and in
forming public opinion.
Digital
image editing tools are also very common, and
with the ability to improve image quality and add artistic
ﬂavor, they also help creating fake photos of scenes that are
essentially altered, or wholly ﬁctional, yet appear realistic.
Many such forgery examples are well known, in propaganda
[19], [41], photojournalism [26], [54], pranks, extortion at-
tempts, attempts at personal embarrassment, and falsiﬁed legal
evidence. Tools are needed to detect fake images and help the
photographic medium maintain its credibility.
Image Authentication (IA) is, loosely speaking, the ability
to prove that an image faithfully represents some original
photograph that was captured in a given class of physical
image acquisition devices (e.g., a camera model). Distinguish-
ing a genuine image from a fake just by inspection can be
very hard.1 Forensic experts can seek anomalies in content,
such as shadow/illumination direction [29], in ﬁle metadata,
e.g. thumbnails embedded in the image ﬁle header [30], or
in digital artifacts (see [16] for a survey), but
in general
this can be time-consuming and unreliable.2 An alternative
approach, pursued in this paper, is to associate additional data
(a signature or proof) with the ﬁnal image, in order to detect
forgery reliably and robustly.
B. Prior work
A popular approach to image authentication is to use
an authentication mechanism to append proofs to authentic
images. These proofs can readily be veriﬁed by any viewer.
One example is for the camera to digitally sign the image
when it is captured, as suggested by Friedman [21]. A secret
signing key can be securely embedded inside the camera’s
Image Signal Processor (ISP). Using the corresponding public
key, viewers can verify the signature and thus be convinced
that the image is authentic.
The limitation of this solution is that digital signatures
are, by design, sensitive to even the smallest change in the
signed data. When the signature is calculated on the image
(or, as is often done for efﬁciency, a collision-resistant hash
thereof), changing even a single bit of the image will result
in a mismatching signature. This restriction is incompatible
with many applications where it is legitimate and desirable
to alter images, as long as they are kept “authentic” (in
some application-speciﬁc sense). For example, operations such
as rotation, rescaling, lossy compression, brightness/contrast
adjustments and cropping may be considered permissible,
as the resulting image still faithfully represents a captured
physical scene.3
1For example, Schetinger et al. [44] found that nonprofessional human
inspectors identiﬁed forgeries in digital images with only about 58% accuracy.
2A recent Broad Agency Announcement (BAA) soliciting research propos-
als in the area of visual media forensics by the American agency DARPA [14]
points out the imbalance between thousands of available image manipulation
programs and very few forgery detection tools in the market, and the relatively
low work capacity of human analysts.
3For example, New York Times guidelines on integrity permit rectangular
cropping [53].
2375-1207/16 $31.00 © 2016 IEEE
© 2016, Assa Naveh. Under license to IEEE.
DOI 10.1109/SP.2016.23
DOI 10.1109/SP.2016.23
255
255
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:41 UTC from IEEE Xplore.  Restrictions apply. 
Developing an image authentication mechanism that sup-
ports some set of permissible transformations is an ongoing
research area. Generally speaking, the existing solutions can
be categorized into two main approaches.
Semi-fragile watermarking.
The ﬁrst category is semi-
fragile watermarking (e.g., [32], [52], [27]). A watermark is
a signal or pattern embedded into an image in a perceptually
and statistically invisible fashion. Embedding the watermark
ensures that performing one of the allowed transformations
on the image will not destroy the watermark, but (ideally)
any other digital manipulation will. Sun et al. [52] suggested
embedding a semi-fragile watermark in coefﬁcients of SVD
decomposition of image blocks in a way resilient to JPEG
compression. In [32], two JPEG compression invariants are
used to embed an authentication string in the image DCT co-
efﬁcients, making the watermark robust to JPEG compression.
Robust hashing. The second category of image authentica-
tion mechanisms is robust hashing or feature extraction (e.g.,
[46], [20], [55], [33], [48], [17], [59], [34], [60]). Here, a
specially designed hash function for images is deﬁned, such
that different images yield different results, but images that
are essentially the same (i.e., modiﬁed by some permissible
transformation) give identical (or close) hash digests. When an
image is captured, its digest is signed using a private signing
key and attached to the image. A veriﬁer that receives a copy
of the image computes its digest, veriﬁes the signature on
the attached digest using a veriﬁcation key, and compares the
two digests. If these two digests are close enough, by some
distance measure, they are accepted by the veriﬁer.
Venkatesan et al. [55] construct an image hash function
robust to JPEG compression and limited geometric modiﬁ-
cations. Their authentication method relies on a secret key
and is thus restricted to the private veriﬁcation setting. Lin
and Chang [33] use differences between corresponding DCT
coefﬁcients from different blocks to create authentication data
which is invariant to JPEG compression. Lin et al. [34] present
a robust hash based on running a pseudorandom feature
vector of the image through a Slepian-Wolf coding (where the
pseudorandom seed is known by the veriﬁer). They show this
technique to be resilient to JPEG compression, afﬁne warping,
and contrast and brightness adjustments.
All existing authentication methods have at least one of the
following drawbacks:
Fixed set of permissible transformations. Different appli-
cations may consider different transformations as permissible,
but most existing techniques are speciﬁc to a ﬁxed set of
supported transformations (e.g., [46], [20], [33], [48], [40],
[34]). Usually the set is also relatively small and includes
transformations of the same “nature”, e.g., only certain geo-
metric transformations or only image compression, which are
preserved by an invariant of their watermarking or underlying
hash. One exception is the method in [17], which allows some
degree of freedom in the choice of allowed transformations,
though at the expense of accuracy.
Non-negligible error probability. Most existing image au-
thentication techniques with permissible transformations have
non-negligible probabilities for false alarms or false accep-
tance. This is mainly due to the statistical nature of veriﬁ-
cation, usually in the form of comparison of some quantiﬁed
property to an (empirically chosen) threshold (as in [46], [33],
[17], [59], [34]).
Vulnerability to adversaries. Many of the methods are
insecure against an adaptive attacker who is familiar with the
authentication method. Such an attacker may devise an image
that will fool the veriﬁer with very high probability. In [46] for
example, the authors propose robust hash image authentication
that works by splitting an image into blocks (of different
sizes) and taking their intensity histograms. An attacker who
is aware of this method can generate an image that (a) gives
the same vector of authentication data (i.e., block histograms)
and (b) is not a result of a JPEG compression. To overcome
this weakness, some have suggested incorporating pseudo-
random elements into the authentication process. However,
in the public veriﬁcation setup, it is often the case that the
random seed (i.e., the key) must be known. The attacker might
then compose a manipulated image that fools the veriﬁer with
high probability. The method proposed in [34], for example,
is vulnerable in this way, and other methods are similarly
vulnerable.
Lack of succinctness on the veriﬁer side.
In most au-
thentication methods, the veriﬁcation time and the size of
the authentication data grow with the image size or with the
number of transformations that were applied on it. While
for robust hash methods this results in larger image data,
in watermarking based authentication, longer embedded data
results in a larger decrease in image quality.
CertiPics. A different approach to image authentication is
taken by Walsh [57], who implemented CertiPics, an image
authentication software over the Nexus operating system [45],
[49] using a secure co-processor (TPM). First, a policy is
deﬁned, stating the allowed transformations and editing rules.
Users use specially written and authorized applications on a
Nexus machine for editing. CertiPics keeps a certiﬁed and
unforgeable log of the transformations performed. This log is
then used when viewing the edited image on a Nexus machine,
to verify that the image is authentic according to the policy.
CertiPics, too, lacks succinctness on the veriﬁer side: the
size of the log and the effort to verify it grow with the length
of the history. It also does not provide zero-knowledge: the
log leaks the editing history of the image, even when this is
undesirable and not required by the policy.
Trusting cameras. Most approaches to image authentication,
including ours, rely on a signing camera as root of trust.
Critique and justiﬁcation of this assumption is not the main
focus of our contribution, but since it affects the overall
security of the system, we discuss it in Appendix A.
256256
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:41 UTC from IEEE Xplore.  Restrictions apply. 
COMPARISON BETWEEN EXISTING AUTHENTICATION METHODS AND PhotoProof
Table I
technique
type
claimed transformations
JPEG
rotate
crop
scale
brightness,
contrast
ﬂip
trans-
pose
ﬂexible
speciﬁcation
digital
signature
[32]
[33]
[52]
[17]
[34]
[55]
[60]
[20]
PhotoProof
SW
RH
SW
RH
RH
RH
RH
RH
CP
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
((cid:2))
(cid:2)
< 2◦
< 5◦
(cid:2)
(cid:2)
(cid:2)
(cid:2)
((cid:2))
< 10% < 10%
< 2%
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
×
×
×
×
restricted
×
×
×
×
any efﬁcient
transformation
negl.
error
probability
(cid:2)
×
×
×
×
×
×
×
×
(cid:2)
size
overhead
O(1)
O (n)
O (n)
O (n)
unspeciﬁed
O (n)
O (n)
O (1)
O (1)
O (1)
Type can be Robust Hash (RH), Semi-fragile Watermarking (SW), or Cryptographic Proofs (CP). Flexible speciﬁcation denotes whether the set of permissible
transformations is conﬁgurable. Error probability denotes whether the probability of false alarms and misdetections is negligible. Size overhead is the length of the
authentication data as a function of image size. ((cid:2)) refers to capabilities supported in our scheme but not yet implemented in our current prototype.
C. Our contribution
We present PhotoProof, a novel approach to image authen-
tication that is based on cryptographic proofs of computational
integrity. Our construction yields a public-proving and public-
verifying authentication system which is secure and reliable.
We also describe our implementation of a working proof-of-
concept prototype, including a collection of permissible image
transformations.
Our construction realizes IA scheme, a new cryptographic
primitive deﬁned in this work, which does not possess any