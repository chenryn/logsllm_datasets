d
e
r
r
e
w
o
P
)
%
(
n
o
i
t
c
u
d
e
r
r
e
w
o
P
 100
 80
 60
 40
 20
 0
 100
 80
 60
 40
 20
 0
S1
S2
S3
S4
S5
S6
S7
S8
S9
S10
Classifiers
(b) Synthetic classiﬁers
Figure 7: Compare power reductions of naive-divide and
SmartPC on real and synthetic classiﬁers with block sizes 128.
scale. For brevity, we use classiﬁers R1, R9, S4 and S10 as repre-
sentatives, while other classiﬁers show similar trends.
In the default scheme, the number of active blocks decrease lin-
early with block size because the number of active blocks equals to
⌈N/B⌉, resulting in a straight line for each classiﬁer in Figure 8.
While in SmartPC, there is a non-linear relationship between the
number of active blocks and block size. Initially, the number of
active blocks decreases quickly with block size, till it reaches some
point when the decreasing speed reduces. We can see this point oc-
curs at block size 64 for R1 (as shown in 8(a)), 128 for R9 (8(b)),
256 for S4 (8(c)) and 512 for S10 (8(d)). Accordingly, the max-
imum power reductions are achieved at these points as shown in
Figure 5.
Moreover, we discover that the number of active blocks for R1
reaches a constant value of 3 when the block size exceeds 128. 3
blocks is the minimum number of blocks that have to be searched
in our scheme 5, which include a block storing the pre-classiﬁer, a
general block and a speciﬁc block. Similarly, we also observe this
5This is generally true, while it is possible that the number of gen-
default
SmartPC
 1000
 100
 10
 1
 10
 100
 1000
 10000
Block size
(a) R1
default
SmartPC
 1000
 100
 10
s
k
c
o
l
b
f
o
r
e
b
m
u
N
s
k
c
o
l
b
f
o
r
e
b
m
u
N
s
k
c
o
l
b
f
o
r
e
b
m
u
N
s
k
c
o
l
b
f
o
r
e
b
m
u
N
default
SmartPC
 1000
 100
 10
 1
 10
 100
 1000
 10000
Block size
(b) R9
default
SmartPC
 10000
 1000
 100
 10
 1
 10
 100
 1000
 10000
 1
 10
 100
 1000
 10000
Block size
(c) S4
Block size
(d) S10
Figure 8: Number of blocks activated with default scheme and
SmartPC (both axes are in log scale)
behavior with other classiﬁers. For example, the number of active
blocks for S10 also reaches 3 when the block size is greater than
512.
5.5.2 The effect of preﬁx distribution and preﬁx length
Using ClassBench [21] tool, we generate classiﬁers with dif-
ferent preﬁx distributions by adjusting the smoothness parameter
which may take a value from 0 to 64. A value 0 maintains the dis-
tributions speciﬁed in a parameter ﬁle to the rule generator, while a
value of 64 models a uniform distribution. We observe that with the
increase of smoothness from 0 to 64, both the number of general
rules and the size of the pre-classiﬁer decrease, resulting in larger
power reductions. We set smoothness to 2 when generating the ten
synthetic classiﬁers to evaluate the performance of SmartPC in a
relatively rigorous environment.
We also generate classiﬁers with more or less speciﬁc address
preﬁxes by varying address scope, a parameter in range of -1.0 to
1.0 which adjusts the average scope of the address preﬁxes. With
less speciﬁc address preﬁxes (shorter preﬁx lengths), the number of
rules marked as general increases, while the size of the associated
pre-classiﬁer decreases. Though the number of general rules and
the size of pre-classiﬁer ﬂuctuate with the parameter, there is no
obvious change in the percentage of power reductions in SmartPC.
5.5.3 Power reductions on small classiﬁers and IPV6
classiﬁers
Though the focus of our work is on large classiﬁers, small clas-
siﬁers can also beneﬁt from SmartPC. From above analysis, our
scheme could provide power reductions on a classiﬁer which occu-
pies more than three TCAM blocks, since generally three blocks is
the minimum number of blocks that are activated in our scheme.
Although we do not have access to IPV6 classiﬁers, the algo-
rithms presented in Section 4 apply to IPV6 classiﬁers without any
modiﬁcations. We expect similar performance on IPV6 classiﬁers.
6. RELATED WORK
There are two main threads of research on packet classiﬁcation:
RAM-based algorithmic approaches and TCAM-based approaches.
A lot of intelligent algorithmic solutions are proposed and many
eral rules is zero for some classiﬁers, therefore bring down this
number to 2.
of them are based on decision trees, e.g., HiCuts [8], HyperCuts
[19], HyperSplit [18], Modular packet classiﬁcation [25], Common
Branches [4], and EfﬁCuts [23]. The core issue of algorithmic ap-
proaches centers on the tradeoff between memory usage and speed.
Wire speed packet classiﬁcation motivated the development of
hardware-based solutions. Ternary Content Addressable Memories
(TCAMs) has become the de facto industrial standard for packet
classiﬁcation in high performance routers. However, TCAMs suf-
fer from several primary deﬁciencies: high power consumption,
high cost per bit relative to other memory technologies, and stor-
age inefﬁciency. Accordingly, prior work in optimizing TCAM-
based systems fall into four broad categories: power efﬁciency [26,
20], circuit modiﬁcation [20, 11], classiﬁer compression [5, 15] and
range reencoding [17]. In this paper, we focus on power-efﬁcient
TCAM solutions, while reencoding or compression or reducing the
number of entries is an orthogonal problem, and our solution can
be combined with these types of work.
CoolCAMs [26] divides a TCAM device into multiple partitions.
An IP lookup becomes a two stage process where only one parti-
tion is selected in the ﬁrst stage and the partition is queried in the
second stage. However, CoolCAMs is limited to the problem of IP
forwarding where the destination address of an incoming packet is
matched against the longest matching preﬁx in a routing table.
To apply TCAMs to the more difﬁcult packet classiﬁcation prob-
lem where incoming packets are matched against multi-dimensional
rules in TCAMs, extended TCAMs [20] extends the partitioned
TCAM concept in [26]. A ﬁlter set is partitioned into multiple
blocks, each of which is associated with an appropriate index ﬁl-
ter. Upon a query, all matching index ﬁlters are ﬁrst identiﬁed and
then the blocks associated with those matching index ﬁlters are
queried. However, packets follow up on multiple matches in the
index TCAM, which makes this approach infeasible in two ways.
First, if legacy chips are used, the bitmap with the blocks can not
be transferred to activate on each search. Second, it requires a new
type of ternary match hardware that returns all matches because
commodity TCAMs give only the ﬁrst result.
Except [26] and [20], there is signiﬁcant recent work in the space
of power efﬁciency that we are aware of, but they are within com-
panies and are of proprietary nature. We are under NDA with one
company and can not refer to them.
Classiﬁer compression optimizations convert a given classiﬁer
into another semantically equivalent classiﬁer that requires fewer
TCAM entries. While these techniques would also reduce power
consumptions, SmartPC is complementary to compression tech-
niques, and if combined, power consumptions could be further re-
duced. In [5], by expanding, trimming, adding and merging rules,
the authors identify semantically equivalent classiﬁers that lead to
fewer TCAM entries. The redundancy removal algorithm in [12]
can reduce TCAM usage by eliminating all the redundant rules
in a packet classiﬁer. To address the preﬁx expansion problem
of TCAMs, TCAM Razor [15] proposed a greedy algorithm that
ﬁnds locally minimal solutions along each dimension and com-
bines these solutions into a smaller equivalent packet classiﬁer. In
Bit Weaving [16], the authors proposed the ﬁrst algorithm that can
compress a given classiﬁer into a non-preﬁx ternary classiﬁer.
Range reencoding schemes cope with range expansion by devel-
oping a new representation for important packets and intervals. Pre-
vious range reencoding schemes fall into two categories: database
independent encoding schemes [1, 11], where each rule is encoded
according to standard encoding scheme, and database dependent
encoding schemes [2, 17, 13], where the encoding of each rule de-
pends on the intervals present within the classiﬁer. While range
reencoding schemes mitigate the effects of preﬁx expansion, they
require either extra hardware or more per packet processing time.
In [9], the authors explored the structure and properties of four
ACLs, and provided a guideline for designing classiﬁcation algo-
rithm which states that a multi-dimensional classiﬁcation problem
should be split into two stages. Though we also employ a two-stage
process, there are major differences. The focus of [9] is on prop-
erties of ACLs and the authors did not design any speciﬁc packet
classiﬁcation algorithm. Furthermore, we employ a pre-classiﬁer
to pre-classify on source and destination addresses, and then a full
classiﬁer on all the ﬁve ﬁelds. While in [9], the ﬁrst stage is classiﬁ-
cation on source-destination pairs and the second is on other ﬁelds.
The results from the two stages are merged to get the ﬁnal result.
7. CONCLUSION
In this paper, we performed a large scale analysis of important
properties of more than 200 real classiﬁers. Based on our analy-
sis, we propose SmartPC, a smart pre-classiﬁer for power-efﬁcient
packet classiﬁcation using TCAMs. In SmartPC, the rules in a clas-
siﬁer are shufﬂed into TCAM blocks such that each pre-classiﬁer
entry is associated with a TCAM block. To classify a packet in
SmartPC, the two-dimensional pre-classiﬁer is ﬁrst consulted which
directs the search to at most one speciﬁc TCAM block that contains
rules intercepting with the packet. Then the speciﬁc block plus a
few general blocks are searched in parallel and two matches are
generated. Finally the action from the higher priority match is re-
turned as the ﬁnal result. SmartPC uses commodity TCAMs, and
the algorithms for building pre-classiﬁers are easy to implement.
We evaluated SmartPC with real and synthetic classiﬁers. SmartPC
achieves more than 80% power reductions on most classiﬁers with
less than 4% storage overhead. With block size 128, SmartPC
achieves a median power reduction of 91% and an average power
reduction of 88% on these classiﬁers. To demonstrate the effective-
ness of pre-classiﬁers, we compared SmartPC with naive-divide, a
naive approach that recursively divides the multi-dimensional space
into smaller regions. SmartPC outperforms naive-divide for every
classiﬁer, with 20% more power reductions on average. SmartPC
is a practical and promising solution to address the high power con-
sumption of TCAMs and can ﬁnd its applications in data centers.
8. ACKNOWLEDGEMENTS
All authors are supported in part by the following grants of the
US NSF: CNS-1040648, CNS-0916955, CNS-0855201, CNS-0747177,
CNS-1064944, and CNS-1059306.
9. REFERENCES
[1] A. Bremler-barr and D. Hendler. Space-efﬁcient
TCAM-based classiﬁcation using gray coding. In IEEE
INFOCOM, 2007.
[2] H. Che, Z. Wang, K. Zheng, and B. Liu. DRES: Dynamic
range encoding scheme for tcam coprocessors. IEEE
Transactions on Computers, 57:902–915, 2008.
[3] Cisco. Cisco catalyst 4500 series supervisor engine 6-e
centerﬂex technology.
http://www.cisco.com/en/US/prod/collateral/switches
ps5718/ps4324/prod_white_paper0900aecd806dc821.html.
[4] E. Cohen and C. Lund. Packet classiﬁcation in large ISPs:
Design and evaluation of decision tree classiﬁers. In ACM
SIGMETRICS, 2005.
[5] Q. Dong, S. Banerjee, J. Wang, D. Agrawal, and A. Shukla.
Packet classiﬁers in ternary CAMs can be smaller. In ACM
SIGMETRICS, 2006.
[6] H. Edelsbrunner, L. J. Guibas, and J. Stolﬁ. Optimal point
location in a monotone subdivision. SIAM J. Comput.,
15:317–340, May 1986.
[7] P. Gupta and N. Mckeown. Packet classiﬁcation on multiple
ﬁelds. In ACM SIGCOMM, 1999.
[8] P. Gupta and N. Mckeown. Packet classiﬁcation using
hierarchical intelligent cuttings. In Hot Interconnects VII,
1999.
[9] M. E. Kounavis, A. Kumar, H. Vin, R. Yavatkar, and A. T.
Campbell. Directions in packet classiﬁcation for network
processors. In HPCA-9, 2003.
[10] T. V. Lakshman and D. Stiliadis. High-speed policy-based
packet forwarding using efﬁcient multi-dimensional range
matching. In ACM SIGCOMM, 1998.
[11] K. Lakshminarayanan, A. Rangarajan, and S. Venkatachary.
Algorithms for advanced packet classiﬁcation with ternary
CAMs. In ACM SIGCOMM, 2005.
[12] A. X. Liu, C. R. Meiners, and Y. Zhou. All-match based
complete redundancy removal for packet classiﬁers in
TCAMs. In IEEE INFOCOM, 2008.
[13] H. Liu. Efﬁcient mapping of range classiﬁer into
Ternary-CAM. In HOT Interconnects, 2002.
[14] Y. Ma, S. Banerjee, S. Lu, and C. Estan. Leveraging
parallelism for multi-dimensional packet classiﬁcation on
software routers. In ACM SIGMETRICS, 2010.
[15] C. Meiners, A. Liu, and E. Torng. TCAM Razor: A
systematic approach towards minimizing packet classiﬁers in
TCAMs. In ICNP, 2007.
[16] C. R. Meiners, A. X. Liu, and E. Torng. Bit weaving: A
non-preﬁx approach to compressing packet classiﬁers in
TCAMs. In ICNP, 2009.
[17] C. R. Meiners, A. X. Liu, and E. Torng. Topological
transformation approaches to optimizing TCAM-based
packet classiﬁcation systems. In ACM SIGMETRICS, 2009.
[18] Y. Qi, L. Xu, B. Yang, Y. Xue, and J. Li. Packet classiﬁcation
algorithms: From theory to practice. In IEEE INFOCOM,
2009.
[19] S. Singh, F. Baboescu, G. Varghese, and J. Wang. Packet
classiﬁcation using multidimensional cutting. In ACM
SIGCOMM, 2003.
[20] E. Spitznagel, D. Taylor, and J. Turner. Packet classiﬁcation
using extended TCAMs. In ICNP, 2003.
[21] D. Taylor and J. Turner. ClassBench: A packet classiﬁcation
benchmark.
http://www.arl.wustl.edu/∼ det3/ClassBench/index.htm.
[22] TopCoder. Line sweep algorithms.
http://community.topcoder.com/tc?module=Static&d1=
tutorials&d2=lineSweep.
[23] B. Vamanan, G. Voskuilen, and T. N. Vijaykumar. EfﬁCuts:
optimizing packet classiﬁcation for memory and throughput.
In ACM SIGCOMM, 2010.
[24] G. Varghese. Network Algorithmics: An Interdisciplinary
Approach to Designing Fast Networked Devices. Morgan
Kaufmann, 2005.
[25] T. Y. Woo. A modular approach to packet classiﬁcation:
algorithms and results. In IEEE INFOCOM, 2000.
[26] F. Zane, G. Narlikar, and A. Basu. CoolCAMs:
Power-efﬁcient TCAMs for forwarding engines. In IEEE
INFOCOM, 2003.