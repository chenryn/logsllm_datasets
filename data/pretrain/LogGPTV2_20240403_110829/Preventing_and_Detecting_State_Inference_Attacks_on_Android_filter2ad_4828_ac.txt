surrounding context and leak a meaningful value when the target
application is going to be used by the victim.
Automatically identifying which APIs can potentially be used
by an attacker hides many challenges. In fact, applying a too
conservative approach may result in having a large number of false
positives to analyze manually. The opposite problem is the case in
which one adopts an overly restrictive approach, as there is the risk
of eliminating a valid API and thus incurring in false negatives.
Our analysis, divided into two stages, represents a tradeoff. As
part of the first stage, we start by considering all the collected API’s
return values. We consider the keys of these return values and we dis-
card all keys whose value is constant across all the API invocations. It
is safe to discard these keys because the attacker would not have any
chance to infer any state-change just by observing a constant value.
Then, we identify those keys whose value is particularly noisy,
i.e., the value has almost always a different value (e.g., out of 100
invocations, there are only a couple of repetitions). These values
are likely not providing a strong signal for the attacker, but we
opted to err on the safe side and we proceed to further inspection
before discarding them. In particular, we empirically found that the
6
vast majority of these noisy values belong to one of the following
categories: timestamps, incremental values (relative timestamps and
auto-incremented sequential numbers), and pointers (i.e., memory
addresses). We developed a simple, entirely conservative heuristics
to identify whether a noisy value belongs to one of these categories,
in which case, given their non-security-relevant semantics, we can
safely discard them. We consider a key to be of a certain category
if these conditions apply: Timestamp if, when all the values are
converted in a “datetime” object, the dates are always compatible
with when we run the experiments; Incremental values if, when
we calculate the difference between each consecutive value, these
differences are always a small positive number; Pointers if all the
values, when interpreted as memory addresses, would point to
memory locations within valid, mapped memory pages.
We stress that, if we cannot recognize the semantics of a
noisy key, we do not discard it and we consider it as a potentially
interesting.
At the end of this stage we obtain a set of candidate APIs for which
at least one key has not been discarded; that is, these APIs have a
chance to be useful for an attacker. We note that the APIs detected
as part of this stage could already be interesting for an attacker,
in the sense that these APIs are potentially returning a (changing)
value that may be correlated with the outside environment. We then
proceed to identify those APIs that can be used to determine state
transitions of other apps.
The second stage is conceptually straightforward: we focus on
identifying APIs that return the same value before the app has started,
and that suddenly start returning a different value just after the user
(in our case, the Stimulator module) has started the victim
app. The resulting APIs are the final output of the analysis pipeline.
F. Comparison with SCAnDroid
As we mentioned throughout the paper, we are not the first
ones to propose an analysis framework to pinpoint Android APIs
vulnerable to state inference attacks. This section offers a direct
comparison with a recent work with a similar goal, SCAnDroid [27],
and we show how it overlooked several of the challenges discussed
in Section V. Most of these shortcomings are not just implementation
issues, but they are about important aspects that were not considered.
The first group of shortcomings relate to how SCAnDroid
determines the set of potential APIs to test. First, they only consider
client-side APIs — the ones implemented in the Manager, by relying
on the AOSP documentation. Our analysis, instead, considers a
wider attack surface — the full list of methods exposed by client-
and server-side components. We determined the list of APIs to test
by relying on the source code of the AOSP project. Second, to limit
the number of APIs to analyze, SCAnDroid performs a filtering
step by only considering APIs whose name starts with a prefix such
as get, query, has or is, assuming that only similarly named methods
could constitute vulnerabilities. Our filtering process instead is
based on the internal functioning of the Android system.
Our evaluation shows that these strategies allow SCAnDroid to
potentially reach only ∼44% of the available attack surface (see Sec-
tion VII-E for the detailed comparison on the final results). Last, we
note how SCAnDroid cannot be easily extended to identify and sup-
port the test of server-side APIs, the ones reachable only via AIDL.
These APIs are not accessible neither via reflection, nor are described
in the official documentation available to the developers. These two
Description
Android 8.1.0 Android 9
Available Services
Proprietary Services
SELinux Denials
Runtime Permission error
Unreachable Services
Native Services
Attacker-Reachable Services
160
2
35
2
9
12
100
180
16
44
1
14
10
95
TABLE I: Extraction of attacker-reachable services.
techniques are the ones used by SCAnDroid to enumerate the attack
surface. Thus, it is conceptually and technically not possible for
SCAnDroid to cover and analyze this important portion of APIs.
One other conceptual limitation relates to the limited ability
to invoke APIs with proper arguments (e.g., pass a valid process
id when needed) and, more importantly, how it inspects the
return values. In fact, SCAnDroid recursively invokes all methods
implemented by the returned object through Reflection, leading to
two conceptual problems. First, the order these methods are invoked
with may permanently modify the return value and some data may be
lost. For example, invoking a setter method before the getter method
of a specific field overwrites the field’s value, potentially losing infor-
mation. Second, and more importantly, there is no guarantee that all
information stored in an object are accessible via its public or private
methods. Our approach, instead, relies on a custom serialization that
can recursively dump every field that is directly or indirectly stored
within a given object, thus solving the problems of the previous
approach. Our analysis found that these conceptual limitations are
the direct cause of false negatives for SCAnDroid. In fact, our
approach identified vulnerable APIs that were either not analyzed
or for which the analysis wrongly marked them as “not vulnerable.”
VII. EVALUATION
A. Experimental setup
We evaluate our framework’s efficacy on two versions of the
Android OS: Android 8.1, running on a Nexus 5X with the latest
available security patch (with security patch, December 2018),
Android 9, running on a Xiaomi MI A2 (August 2019). Finally, we
also tested our system on the latest version available at the time of
writing, Android 10. However, we noticed that our system was not
able to identify any new vulnerability on this latest version, despite
the fact that the attack surface had been correctly identified and
several APIs had been tested. Moreover, we have also manually
verified and confirmed that all bugs we identified affecting Android
8.1 and 9 have been correctly fixed on Android 10. Thus, since
no additional vulnerabilities were found on Android 10, in the rest
of the section we will focus the discussion and the analysis of the
results obtained on Android 8.1 and 9 versions.
B. Attack Surface Enumeration
Attacker-reachable services. Our system extracted a total of 160
services for Android 8.1. After having applied the filtering steps
7
# Methods
Total
After static analysis
Client-side
v. 9
4,092
1,324
v. 8.1.0
3,536
1,080
Server-side
v. 9
2,887
1,472
v. 8.1.0
2,683
1,384
TABLE II: The table summarizes the filtering process applied on
the APIs extracted from the AOSP source code, as described in
Section VI-B.
# APIs
Total
Accessible by an attacker
By removing constant APIs
By removing noisy APIs
Unique Methods
Potentially vulnerable
Fixed Args
v. 9
2,796
1,931
1,127
35
v. 8.1.0
2,464
1,616
813
48
Mutated Args
v. 9
2,796
1,929
1,141
52
v. 8.1.0
2,464
1,614
816
51
66
24
We then applied the same identification and filtering process to
Android 9. For what concerns this version, from the 95 initial ser-
vices, we extracted a total of 157 classes: 76 acting as Client (∼48%)
and the remaining 81 as Servers (∼ 52%). From these classes, we
then extracted a total of 6,979 invocable methods. The first static
filtering allowed our system to extract, from the 6,979 methods,
2,796 candidates (1,324 methods declared in the Client, while 1,472
defined in the Server). Instead, by removing the methods raising a
security violation at runtime when invoked, our system pinpointed
1,931 methods effectively reachable by a potential malicious appli-
cation. Thus, the combination of these pruning strategies allowed us
to lower the number of methods to test from 6,979 to 2,796.
Table II and Table III summarize the results obtained during
these pruning stages.
C. Method Testing
We analyzed each method for an average of 70 seconds (60
seconds plus time used for booting with both the configurations of
the Stimulator). The overall execution time to run all the experiments
is of 63 hours for Android 8.1, while it took 68 hours for Android 9.
TABLE III: The table summarizes the filtering process based on
the two stages described in Section VI-E.
D. Analysis Results
described in Section VI-B, it identified how a non-system app can
interact and reach 100 of them (∼62%).
For what concerns Android 9 instead, we identified 180 services,
but only 95 reachable (∼52%) from an unprivileged app.
As it is possible to see, for both versions of Android, the majority
of the services not reachable by a third-party application is due to
security violation. By monitoring these denials, in fact, our system
identified how more than the 23% of the services for Android
8.1, and 25% for Android 9.0, were not reachable by a third-party
application due to missing permissions or SELinux violations. This
first filtering procedure applied to services has allowed our system to
extract only those services that can actually be used by an attacker.
Table I shows how many services were not reachable and for
what reason.
API enumeration. Starting from the extracted services, we then
proceed by identifying and extract first the Manager and the
server-side services implementation, and then the candidate APIs.
On Android 8.1, the 100 services define a total of 157 classes.
These classes are divided in 71 Client classes (∼45%) and 86 Server
(∼ 55%). From these 157 classes, we identified a total of 6,219
invocable methods. These are all the methods that can be potentially
used by an attacker to mount state inference attacks. We then
proceed by applying the filtering rules, as described in Section VI-B.
This process allowed us to obtain, from the initial bucket of 6,219
methods, 2,464 candidates to test on Android 8.1. Out of these 2,464
methods, 1,080 are exposed through the Client while the remaining
1,384 are available from the Server. We then dynamically tested all
these methods looking for security violations. These methods have
to be discarded since a third-party application cannot invoke them.
This stage identified how only 1,616 of them is effectively reachable
by a third-party application. Thus, the combination of both static
and dynamic analysis reduced the candidates from 6,219 to 1,616.
8
We then proceed to analyze the data collected during the tests.
We start by discarding APIs not leaking any sensitive information
due to their values remaining constant, as well as very noisy APIs,
as described in Section VI-E. This process drastically reduces the
number of APIs to analyze in the second stage. For Android 8.1, we
reduced the number of APIs from 1,616 to 51 — discarding∼96.6%:
for Android 9, we started from 1,931 APIs and we ended up with 52
candidates — discarding ∼97.5% of APIs. In total, we obtained 66
unique APIs whose return value change appears to be conditioned
by the surrounding context. Out of the 66 APIs, the second stage of
the algorithm identified 24 potentially leaking APIs that can be used
to determine whether a target app went to “foreground.” Table III
summarizes all the intermediate results of these filtering stages.
Out of these 24 APIs, 18 are indeed vulnerable: 4 APIs
require no permission at all, 2 require a permission marked
as Normal, while the remaining APIs are protected with the
PACKAGE_USAGE_STATS permission, which allows an app to
collect the usage statistics of other apps, including the application
in foreground. This information, as discussed in Section II-B, is of
essence when mounting phishing attacks. Table IV, reports more
detailed information about these APIs.
We now discuss the 6 false positives. Interestingly, two APIs
actually leak some information about the surrounding system:
getInputMethodWindowVisibleHeight, which returns
the size of the keyboard on the screen, and getPendingApp-
Transition, which tells the attacker that an application “is going
to be moved on foreground.” The attacker can reliably infer that
an app is about to change its state, but she cannot determine which
app. However, since this scenario could lead to a more generic
phishing attack, we conservatively consider these as false positives.
For example, with the getPendingAppTransition API
the attacker can evince that the user is about to interact with an
app: Thus, she can simply display a pop-up a message informing
the user that an update is available (without the need of specifying
the name of the app). Since the timing is perfect, the user might
be lured into clicking it. The same attack can be mounted with the
getInputMethodWindowVisibleHeight API.
In fact,
Classname
IActivityManager
IActivityManager
ActivityManager
IUsageStatsManager
INetworkStatsService
INetworkStatsService
StorageStatsManager
StorageManager
IActivityManager
NetworkStatsManager
NetworkStatsManager
IActivityManager
IActivityManager
NetworkStatsManager
UsageStatsManager
UsageStatsManager
UsageStatsManager
IStorageStatsManager
IStorageStatsManager