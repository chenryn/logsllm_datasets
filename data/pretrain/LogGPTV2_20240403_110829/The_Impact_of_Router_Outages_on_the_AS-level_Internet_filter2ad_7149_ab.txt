### Multi-Homed Networks and BGP Churn

In multi-homed networks with at least two routers, we observe significant BGP churn for customers connected to either a single or multiple providers. The presence of an available alternate path is implied by the stabilization of BGP activity at a remote looking glass after an outage, as BGP converges to an alternate path. We classify the resultant per-prefix global BGP activity due to a router outage into four categories:
1. **None**: No BGP activity.
2. **Churn**: Frequent BGP updates.
3. **Partial Withdrawal**: A fraction of peers withdraw.
4. **Complete Withdrawal**: All peers withdraw, leaving no available path (see §4.3).

### Related Work

Significant prior research has examined network resilience and Internet outages. Our work extends this body of knowledge in several key ways:
1. **Breadth and Scope**: We provide 2.5 years of Internet-wide measurements.
2. **Router Outage Impact**: We take a first step toward understanding the impact of router outages.
3. **Single Points of Failure**: We empirically identify routers that represent single points of failure for their connected customers.

This section provides a concise taxonomy of prior work and its relation to our research.

#### Empirical Studies on Outages and Reachability

Empirical studies on outages, reachability, and failures have used both passive and active measurement techniques at the control and data planes. These methods have been applied within a single AS, across vantage points, and across the entire Internet.

- **Passive Analysis**: Techniques such as clustering and temporal grouping of BGP routing messages can reveal insights into events of interest [50] and their origins [20, 45]. Purely passive techniques are most effective with a complete view of all routing activity within a single AS [22], making it challenging to localize and infer causes of outages outside a single domain [9].
- **Synthesis of Data Sources**: Dainotti et al. [15] combined network telescopes and control-plane activity, showing that backscatter observed at their network telescope can correlate with BGP activity and known macro-level outages [6].

#### Active Probing and Crowdsourcing

- **Trinocular [39]** and **Pingin’ in the Rain [43]** use continual data-plane probes from dedicated measurement nodes to discover reachability issues.
- **Choffnes et al. [13]** enlisted BitTorrent nodes to crowdsource measurements, revealing real-world availability experienced by end nodes and demonstrating correlations with natural disasters, severe weather, and political events. However, these methods require significant volumes of probing traffic and cannot directly implicate a particular router as the root cause.

#### Fusion of Data and Control Plane Analysis

- **Feamster et al. [19]** and **Wang et al. [48]** utilized continual active measurements between a mesh of dedicated measurement nodes, correlating BGP activity with reachability problems. Our work takes an Internet-wide view of outages without requiring a full-mesh of measurement nodes.

#### Network Reachability Blackholes

A large body of research has investigated, localized, and proposed methods to mitigate network reachability blackholes—instances of end-to-end path failures that are avoidable because a policy-compliant route exists but is not used by the forwarding path [14, 17, 26, 27, 29]. Many of these works used tomography algorithms to locate faults. Our work focuses on router outages rather than silent reachability faults.

- **Iannaccone et al. [24]** provided a detailed analysis of router failures within the Sprint backbone.
- **[46]** examined availability in a regional network via logfile analysis.

Our focus is on Internet-wide identification of router outages and their impact.

#### Extensions to Previous Work

In this study, we extend our method in [7] to perform direct and unambiguous measurement of IPv6 router restarts, rather than relying on error-prone inferences. While [7] characterized the prevalence of observed router reboots via coarse-grained probing every six hours, we implement an adaptive probing algorithm based on each router’s behavior to enable efficient fine-grained sampling. This study is significantly broader in scope and duration. We also close the causal loop by tying observed reboots to the resulting impact (or lack thereof) on BGP, thereby providing a new way to concretely differentiate critical (i.e., single point of failure) routers from more resilient configurations.

### Methodology

Our methodology addresses three distinct aspects of router outage characterization:

1. **Identifying Router Restarts (§4.1)**: We use macroscopic traceroute data to identify IPv6 router interfaces, a novel adaptive-rate active probing technique to identify router restarts, and IPv6 alias resolution techniques to reduce interfaces to routers.
2. **Associating Networks with Routers (§4.2)**: We use traceroute data to find interfaces along the forward path to each network prefix and label routers with their relative distance from the customer edge border router. We use a similar procedure to map routers to the IPv4 prefixes for which they are responsible.
3. **Associating Router Restarts with BGP Activity (§4.3)**: We correlate global BGP data, including RIBs and BGP messages, from the Routeviews looking glass as part of a large-scale data-fusion effort. We juxtapose these three sources of data to correlate inferred outages with their impact on the global routing system.

**Figure 1** depicts the components of our methodology for fusing large uptime IPID time series with Routeviews BGP updates and traceroute data to identify single points of failure.

### Inferring Router Outages

Our router outage inference consists of two components: active router probing and identifying reboots from the responses.

#### Probing

Beverly et al. [7] performed a five-month uptime study of 66,471 IPv6 interfaces, sending six probes every six hours regardless of previous responses. In this work, we use CAIDA IPv6 traceroute topology data [10] to identify a much larger set of IPv6 router interfaces as probe targets, necessitating a more adaptive probing approach. Over the 2.5-year duration of our study, we found that the way interfaces respond can change, e.g., from predictable to random or vice versa. We implemented an optimized prober that regularly samples interfaces that respond with monotonically increasing IPID sequences and periodically samples interfaces that do not.

**Algorithm 1** describes how we infer a router reboot from an IPID time series. If the router appears to assign IPID values from a counter, a discontinuity in the time series implies a counter reset. An IPID less than the previous IPID from the interface indicates a potential reboot, though non-monotonicity can also be due to random or cyclic counters.

**Figure 2** shows the size of our probe list and the number of interfaces that sent incrementing IPID values over time. **Table 1** summarizes our measurement parameters.

### Associating Networks with Routers

The second fundamental problem is determining which networks are routed by which routers. We use CAIDA traceroutes to build a router graph that associates each interface in the graph with destination prefixes the interface is in the path towards. For example, if interface I is observed in the traceroute to destination D, we find the longest matching prefix P to which D belongs and note that I is involved in providing reachability to P.

In December 2016, the Ark project used a set of 55 IPv6 vantage points distributed around the world, each of which probed two addresses in each routed prefix. We also labeled each interface with the distance, in IP hops, from the AS originating the prefix. **Figure 6** illustrates our distance computation.

By directly probing routers rather than edge systems or networks, our adaptive prober achieves significant efficiency. For example, on December 30th, 2016, we sent approximately 17.4M packets toward 1,086,055 unique router interfaces, equating to ∼200pps (∼2Mbps). This is two orders of magnitude lower than existing approaches to outage inference, such as Trinocular [39].

**Figure 3** shows the CDF of minimum and maximum outage window lengths measured, and **Figure 5** shows the number of inferred outages per day.