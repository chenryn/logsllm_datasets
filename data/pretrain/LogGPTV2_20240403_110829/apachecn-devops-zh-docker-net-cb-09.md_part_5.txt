```
如果我们从本地子网之外向这些 IP 发起流量，我们可以通过检查上游网关上的 ARP 表来验证每个 IP 报告相同的 MAC 地址:
```
switch#show ip arp vlan 10
Protocol  Address          Age (min)  Hardware Addr   Type   Interface
Internet  172.16.10.6             0   000c.292d.dd79  ARPA   Vlan30
Internet  172.16.10.5             0   000c.292d.dd79  ARPA   Vlan30
Internet  172.16.10.2           111   000c.292d.dd79  ARPA   Vlan30
Internet  172.16.10.3           110   000c.2959.caca  ARPA   Vlan30
Internet  172.16.10.1             -   0021.d7c5.f245  ARPA   Vlan30
```
虽然我们不会在这里展示一个例子，但是 L2 模式下的 IPVLAN 接口也是有名称空间意识的，就像我们在上一组关于 MacVLAN 接口类型的食谱中看到的一样。唯一的区别是接口的媒体访问控制地址，正如我们在前面的代码中看到的。同样的限制适用于父接口不能与子接口对话，反之亦然。
现在我们知道了 L2 模式下的 IPVLAN 是如何工作的，下面我们来讨论一下 L3 模式下的 IPVLAN。到目前为止，L3 模式与我们看到的有很大不同。顾名思义，L3 模式这种接口类型在所有连接的子接口之间路由流量。这在名称空间配置中最容易理解。例如，让我们看看这个快速的实验拓扑:
![How to do it…](img/5453_09_08.jpg)
在上图中，您可以看到我在我们的两台实验室主机上创建了四个独特的名称空间。我还创建了四个唯一的 IPVLAN 接口，将它们映射到不同的名称空间中，并给它们每个都一个唯一的 IP 地址。由于这些是 IPVLAN 接口，您会注意到所有 IPVLAN 接口都共享父接口的媒体访问控制地址。为了构建此拓扑，我在每台主机上使用了以下配置:
```
user@net1:~$ sudo ip link del dev ipvlan1
user@net1:~$ sudo ip link del dev ipvlan2
user@net1:~$ sudo ip netns add namespace1
user@net1:~$ sudo ip netns add namespace2
user@net1:~$ sudo ip link add ipvlan1 link eth0 type ipvlan mode l3
user@net1:~$ sudo ip link add ipvlan2 link eth0 type ipvlan mode l3
user@net1:~$ sudo ip link set ipvlan1 netns namespace1
user@net1:~$ sudo ip link set ipvlan2 netns namespace2
user@net1:~$ sudo ip netns exec namespace1 ip address \
add 10.10.20.10/24 dev ipvlan1
user@net1:~$ sudo ip netns exec namespace1 ip link set dev ipvlan1 up
user@net1:~$ sudo ip netns exec namespace2 sudo ip address \
add 10.10.30.10/24 dev ipvlan2
user@net1:~$ sudo ip netns exec namespace2 ip link set dev ipvlan2 up
user@net2:~$ sudo ip netns add namespace3
user@net2:~$ sudo ip netns add namespace4
user@net2:~$ sudo ip link add ipvlan3 link eth0 type ipvlan mode l3
user@net2:~$ sudo ip link add ipvlan4 link eth0 type ipvlan mode l3
user@net2:~$ sudo ip link set ipvlan3 netns namespace3
user@net2:~$ sudo ip link set ipvlan4 netns namespace4
user@net2:~$ sudo ip netns exec namespace3 ip address \
add 10.10.40.10/24 dev ipvlan3
user@net2:~$ sudo ip netns exec namespace3 ip link set dev ipvlan3 up
user@net2:~$ sudo ip netns exec namespace4 sudo ip address \
add 10.10.40.11/24 dev ipvlan4
user@net2:~$ sudo ip netns exec namespace4 ip link set dev ipvlan4 up
```
一旦配置完成，您会注意到唯一可以相互通信的接口是主机`net2` ( `10.10.40.10`和`10.10.40.11`)上的接口。让我们从逻辑上来看一下这个拓扑，以了解为什么:
![How to do it…](img/5453_09_09.jpg)
从逻辑上看，它开始看起来像一个路由网络。您会注意到所有分配的 IP 地址都是唯一的，没有任何重叠。正如我前面提到的，IPVLAN L3 模式就像路由器一样。从概念角度来看，您可以将父接口视为该路由器。如果我们从第 3 层的角度来看，只有名称空间 3 和 4 中的接口可以说话是有意义的，因为它们在同一个广播域中。其他名称空间需要通过网关进行路由，才能相互对话。让我们检查所有名称空间的路由表，看看情况如何:
```
user@net1:~$ sudo ip netns exec namespace1 ip route
10.10.20.0/24 dev ipvlan1  proto kernel  scope link  src 10.10.20.10
user@net1:~$ sudo ip netns exec namespace2 ip route
10.10.30.0/24 dev ipvlan2  proto kernel  scope link  src 10.10.30.10
user@net2:~$ sudo ip netns exec namespace3 ip route
10.10.40.0/24 dev ipvlan3  proto kernel  scope link  src 10.10.40.10
user@net2:~$ sudo ip netns exec namespace4 ip route
10.10.40.0/24 dev ipvlan4  proto kernel  scope link  src 10.10.40.11
```
不出所料，每个名称空间只知道本地网络。因此，为了让这些接口进行通信，它们至少需要有一个默认路由。这就是事情变得有点有趣的地方。IPVLAN 接口不允许广播或多播流量。这意味着，如果我们将接口的网关定义为上游交换机，它将永远无法到达它，因为它将无法为它进行 ARP。然而，由于父节点就像一种路由器，我们可以让名称空间使用 IPVLAN 接口本身作为网关。我们可以通过以这种方式添加默认路由来做到这一点:
```
user@net1:~$ sudo ip netns exec namespace1 ip route add \
default dev ipvlan1
user@net1:~$ sudo ip netns exec namespace2 ip route add \
default dev ipvlan2
user@net2:~$ sudo ip netns exec namespace3 ip route add \
default dev ipvlan3
user@net2:~$ sudo ip netns exec namespace4 ip route add \
default dev ipvlan4
```
添加完这些路由后，您还需要在每台 Linux 主机上添加路由，以告诉它们从哪里到达这些远程子网。由于本例中的两台主机是第 2 层相邻的，因此最好在主机本身上进行。虽然您也可以依赖默认的路由，并在不理想的上游网络设备上配置这些路由。您实际上是在网关上路由进出同一个 L3 接口，这不是很好的网络设计实践。如果主机不是相邻的第 2 层，则需要在多层交换机上添加路由:
```
user@net1:~$ sudo ip route add 10.10.40.0/24 via 172.16.10.3
user@net2:~$ sudo ip route add 10.10.20.0/24 via 172.16.10.2
user@net2:~$ sudo ip route add 10.10.30.0/24 via 172.16.10.2
```
安装所有路由后，您应该能够从任何其他名称空间访问所有名称空间:
```
user@net1:~$ sudo ip netns exec namespace1 ping 10.10.30.10 -c 2
PING 10.10.30.10 (10.10.30.10) 56(84) bytes of data.
64 bytes from 10.10.30.10: icmp_seq=1 ttl=64 time=0.047 ms
64 bytes from 10.10.30.10: icmp_seq=2 ttl=64 time=0.033 ms
--- 10.10.30.10 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 999ms
rtt min/avg/max/mdev = 0.033/0.040/0.047/0.007 ms
user@net1:~$ sudo ip netns exec namespace1 ping 10.10.40.10 -c 2
PING 10.10.40.10 (10.10.40.10) 56(84) bytes of data.
64 bytes from 10.10.40.10: icmp_seq=1 ttl=64 time=0.258 ms
64 bytes from 10.10.40.10: icmp_seq=2 ttl=64 time=0.366 ms
--- 10.10.40.10 ping statistics ---
2 packets transmitted, 2 received, +3 duplicates, 0% packet loss, time 1001ms
rtt min/avg/max/mdev = 0.258/0.307/0.366/0.042 ms
user@net1:~$ sudo ip netns exec namespace1 ping 10.10.40.11 -c 2
PING 10.10.40.11 (10.10.40.11) 56(84) bytes of data.
64 bytes from 10.10.40.11: icmp_seq=1 ttl=64 time=0.246 ms
64 bytes from 10.10.40.11: icmp_seq=2 ttl=64 time=0.366 ms
--- 10.10.40.11 ping statistics ---
2 packets transmitted, 2 received, +3 duplicates, 0% packet loss, time 1001ms
rtt min/avg/max/mdev = 0.246/0.293/0.366/0.046 ms
user@net1:~$ s
```
正如你所看到的，IPVLAN L3 模式与我们到目前为止所看到的是不同的动物。与 MacVLAN 或 IPVLAN L2 不同，您需要告诉网络如何到达这些新接口。
# 使用 Docker IPVLAN 网络驱动程序
正如我们在前面的食谱中看到的，IPVLAN 提供了一些有趣的操作模式，这些模式可能与大规模容器部署相关。截至目前，Docker 在其实验软件通道中支持 IPVLAN。在这个食谱中，我们将回顾如何使用 Docker IPVLAN 驱动程序来使用 IPVLAN 连接的容器。
## 做好准备
在这个食谱中，我们将使用两个运行 Docker 的 Linux 主机。我们的实验室拓扑如下所示:
![Getting ready](img/5453_09_10.jpg)
假设每台主机都在运行 Docker 的实验通道，以便访问实验性 IPVLAN 网络驱动程序。关于实验软件通道的使用和消耗，请参见配方 1。主机应该只有一个 IP 接口，Docker 应该处于默认配置。在某些情况下，我们所做的更改可能要求您具有对系统的根级访问权限。
## 怎么做…
一旦您的主机运行了实验代码，通过查看`docker info`的输出来验证您的版本是否正确:
```
user@docker1:~$ docker info
……
Server Version: 1.12.2
……
Experimental: true
user@docker1:~$
```
在撰写本文的时刻，您需要在 Docker 的实验版本上，IPVLAN 驱动程序才会出现。
Docker IPVLAN 网络驱动程序提供第 2 层和第 3 层操作模式。由于 IPVLAN L2 模式与我们前面介绍的 MacVLAN 配置非常相似，因此我们将在本食谱中重点介绍 L3 模式的实现。我们需要做的第一件事是定义网络。在此之前，在使用 IPVLAN 网络驱动程序时，有几件事要记住:
*   虽然它允许您在定义网络时指定网关，但该设置会被忽略。回想一下之前的方法，您需要使用 IPVLAN 接口本身作为网关，而不是上游网络设备。Docker 会为您配置这个。
*   作为驱动程序的一个选项，您需要指定您希望用作所有附加了 IPVLAN 接口的容器的父接口的接口。如果不指定父接口作为选项，Docker 将创建一个虚拟网络接口，并将其用作父接口。这将阻止从该网络到外部网络的任何通信。
*   使用 IPVLAN 驱动程序创建网络时，`--internal`标志可用。指定后，父接口被定义为虚拟接口，防止流量离开主机。
*   如果您没有指定子网，Docker IPAM 将为您选择一个。不建议这样做，因为这些子网是可路由的。不同 Docker 主机上的 IPAM 可能会选择相同的子网。始终指定您希望定义的子网。
*   IPVLAN 用户定义的网络和父接口之间存在一对一的关系。也就是说，您只能在给定的父接口上定义一个 IPVLAN 类型的网络。
您会注意到，前面的许多要点与适用于 Docker MacVLAN 驱动程序的要点相似。一个显著的区别在于，我们不希望使用与父接口相同的网络。在我们的示例中，我们将使用主机`docker1`上的子网`10.10.20.0/24`和主机`docker3`上的子网`10.10.30.0/24`。现在让我们定义每台主机上的网络:
```
user@docker1:~$ docker network  create -d ipvlan -o parent=eth0 \
--subnet=10.10.20.0/24 -o ipvlan_mode=l3 ipvlan_net
16a6ed2b8d2bdffad04be17e53e498cc48b71ca0bdaed03a565542ba1214bc37
user@docker3:~$ docker network  create -d ipvlan -o parent=eth0 \
--subnet=10.10.30.0/24 -o ipvlan_mode=l3 ipvlan_net
6ad00282883a83d1f715b0f725ae9115cbd11034ec59347524bebb4b673ac8a2
```
创建后，我们可以在使用 IPVLAN 网络的每台主机上启动一个容器:
```
user@docker1:~$ docker run -d --name=web1 --net=ipvlan_net \