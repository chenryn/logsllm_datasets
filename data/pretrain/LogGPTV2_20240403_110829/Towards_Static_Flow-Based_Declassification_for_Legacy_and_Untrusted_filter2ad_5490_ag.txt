resulting value, for instance, to ensure that enough values
are being averaged. We believe that a full treatment of the
problem of how many times a loop runs can be achieved via a
cooperation between static analysis and runtime enforcement
mechanisms, with the former specifying the constraint and the
latter enforcing it. Secondly, this paper does not address the
problem of matching program graphs against policy graphs up
to algebraic equivalence of the denoted expressions [42]. This
would enable veriﬁcation of programs that compute expres-
sions that differ from those identiﬁed by the declassiﬁcation
policy, but that are equivalent to them under algebraic laws,
such as associativity, commutativity, and idempotence. One
possible approach to this would be to transform program
and policy graphs into a normal form and then apply the
matching we propose here. Of course, in general, this can
lead to a combinatorial explosion, and some conservative
approximation may be necessary to retain tractability.
Our ﬂow-analysis is termination-insensitive [43]. We can
make the analysis termination-sensitive either by disallowing
while loops under high conditionals or introducing a ﬂow
between the conditional
in which the loop is declared to
all the output channels in the program. However, both these
approaches are too restrictive. Disallowing the while loops
under high conditionals would also make the program depen-
dent on the policy, which we want to avoid. Achieving the
right balance between handling termination behavior correctly
versus ensuring that the analysis is practical is tough and it is
out of the scope of the current paper. In this paper, therefore,
we do not deal with termination and timing channels.
The policies used by our framework specify the expressions
over inputs that can be declassiﬁed, so they address the
what dimension of declassiﬁcation. It is straightforward to
extend our analysis to address the who dimension, as the
system operator can control which policy graphs are used
in analyzing the program based on who wrote the program
and the policies, and who is going to observe the outputs
from the output channels. On the other hand, utilizing the
where dimension extensively would be contrary to our goal of
making the policy program-independent. In the case of legacy
code, the programs are typically written without information-
ﬂow policies explicitly deﬁned. For untrusted code, we have
sought an approach that provides assurance without requiring
to trust the programmer. Nevertheless, for cases in which the
where dimension is required, it is straightforward to specify
program points at which a particular policy may be applied
by associating this condition with the policy itself; no code-
annotations are required. The when dimension may entail that
some part of the program be veriﬁed with one policy, and other
106
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:11:48 UTC from IEEE Xplore.  Restrictions apply. 
parts be veriﬁed with another, based on a condition that might
occur during the execution of the program. Specifying such
policies require intimate knowledge of the program and might
be possible for trusted code which is being newly written. For
legacy and untrusted code, it is unrealistic to specify such a
dimension.
One premise of our work is that declassiﬁcations are not
invertible. This assumption is realistic since we consider well-
formed policies. If a declassiﬁcation policy allows a f (α),
in the scenario where a f −1 function exists, then the policy
is actually allowing α to be disclosed. Even if we had
some mechanism that checks if a given function had not
been inverted throughout the code, nothing would prevent the
inverse function from being applied outside of the program.
Therefore, we assume that well-formed policies do not allow
invertible expressions to be declassiﬁed.
Sections V and VI assume that all output channels in the
program are observable. We also assume that all the input
channels are controlled by the target system. To weaken these
requirements, we can associate security levels to inputs and
outputs, and specify allowed ﬂows by using standard lattice
models. The labels on policy graph nodes would be extended
accordingly, and the analysis algorithm would be required to
respect these labels. This would result in very little change to
our approach or in the PCR theorem and its proof.
If the input channels used in the program are interactive,
the values of the inputs can change outside the program
control. As a result, accessing one input channel may inﬂuence
the value of another input channel. Such interactions are
not considered in our current threat model. However, they
can be treated by including additional assumptions about the
interactions between the channels. For example, if a collection
of input channels is under an attacker’s control,
they are
somewhat equivalent to each other, thus requiring that all such
channels share the same collection of control dependencies.
Thus, if any of them is read in a non-declassiﬁable context,
no value read from any of these channels may be declassiﬁed.
A similar reasoning applies if reads themselves are observable
events. We plan to address these issues in future work.
Our approach can also be extended to support a broader
range of language constructs. Since we rely on φ-functions
from SSA translation to recognize control-ﬂow branches,
commands like case, continue, break and others can
be included in our mechanism in a straightforward manner,
provided there is a valid translation of them to SSA form.
For constructs such as procedures, methods, classes and in-
heritance, our approach can be adapted to work in a modular
way [44]. Individual blocks of code, such as user deﬁned
functions, can be analyzed by generating separate graphs,
and calls to these blocks would use “procedure call edges”
to reference “argument nodes”. Global variables (and class
parameters), however, would need special treatment. As with
most language-based information ﬂow techniques, extending
our approach to allow concurrency and constructs that enable
control ﬂow to jump to unpredictable points of the code (e.g.,
computed goto, exceptions) pose bigger challenges.
ACKNOWLEDGEMENT
Part of this research was supported by the STW Sentinels
Project “S-Mobile”, the NSF under awards CNS 08-31212,
CNS-0716210 and CNS-0716750 and the Texas Higher Educa-
tion Coordinating Board NHARP Award 010115-0037-2007.
We would like to thank all the reviewers for their helpful
comments and suggestions.
REFERENCES
[1] A. Sabelfeld and A. C. Myers, “Language-based information-ﬂow se-
curity,” IEEE Journal on Selected Areas in Communications, vol. 21,
2003.
[2] J. A. Goguen and J. Meseguer, “Security policies and security models,”
in SP ’82: Proceedings of the 3rd IEEE Symposium on Security and
Privacy, 1982, pp. 11–20.
[3] A. C. Myers, “JFlow: practical mostly-static information ﬂow control,”
in POPL ’99: Proceedings of the 26th ACM SIGPLAN-SIGACT Sympo-
sium on Principles of Programming Languages. New York, NY, USA:
ACM, 1999, pp. 228–241.
[4] F. Pottier and V. Simonet, “Information ﬂow inference for ML,” ACM
Transactions on Programming Languages and Systems, vol. 25, no. 1,
pp. 117–158, 2003.
[5] D. M. Volpano, C. E. Irvine, and G. Smith, “A Sound Type System
for Secure Flow Analysis,” Journal of Computer Security, vol. 4, pp.
167–188, 1996.
[6] T. Amtoft and A. Banerjee, “Information Flow Analysis in Logical
Form,” in SAS ’04: 11th International Static Analysis Symposium, 2004,
pp. 100–115.
[7] T. Amtoft, S. Bandhakavi, and A. Banerjee, “A logic for information
ﬂow in object-oriented programs,” in POPL ’06: Proceedings of the 33rd
ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages, 2006, pp. 91–102.
[8] J.-P. Banˆatre, C. Bryce, and D. L. M´etayer, “Compile-Time Detection of
Information Flow in Sequential Programs,” in ESORICS ’94: Proceed-
ings of the 3rd European Symposium on Research in Computer Security.
London, UK: Springer-Verlag, 1994, pp. 55–73.
[9] D. E. Denning, “A Lattice Model of Secure Information Flow,” Com-
munications of the ACM, vol. 19, no. 5, pp. 236–243, 1976.
[10] A. Sabelfeld and D. Sands, “Dimensions and Principles of Declassi-
ﬁcation,” in CSFW ’05: Proceedings of the 18th IEEE Workshop on
Computer Security Foundations, 2005, pp. 255–269.
[11] S. Zdancewic, “Challenges in Information-ﬂow Security,” in PLID
’04: Proceedings of the First International Workshop on Programming
Language Interference and Dependence, Verona, Italy, August 2004.
[12] A. Banerjee, D. A. Naumann, and S. Rosenberg, “Expressive Declassiﬁ-
cation Policies and Modular Static Enforcement,” in SP ’08: Proceedings
of the 29th IEEE Symposium on Security and Privacy, 2008, pp. 339–
353.
[13] B. Hicks, D. King, P. McDaniel, and M. Hicks, “Trusted declassiﬁcation:
high-level policy for a security-typed language,” in PLAS ’06: Proceed-
ings of the 2006 Workshop on Programming Languages and Analysis
for Security. New York, NY, USA: ACM, 2006, pp. 65–74.
[14] R. Cytron, J. Ferrante, B. K. Rosen, M. N. Wegman, and F. K. Zadeck,
“Efﬁciently computing static single assignment form and the control
dependence graph,” ACM Transactions on Programming Languages and
Systems, vol. 13, no. 4, pp. 451–490, 1991.
[15] G. Bilardi and K. Pingali, “Algorithms for computing the static single
assignment form,” Journal of the ACM, vol. 50, no. 3, pp. 375–425,
2003.
[16] M. M. Brandis and H. M¨ossenb¨ock, “Single-pass generation of static
single-assignment form for structured languages,” ACM Transactions on
Programming Languages and Systems, vol. 16, no. 6, pp. 1684–1698,
1994.
[17] R. Milner, Communication and concurrency. Upper Saddle River, NJ,
USA: Prentice-Hall, Inc., 1989.
[18] B. P. S. Rocha, S. Bandhakavi, J. den Hartog, W. H. Winsborough, and
S. Etalle, “Towards Static Flow-based Declassiﬁcation for Legacy and
Untrusted Programs,” Tech. Rep., to appear.
107
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:11:48 UTC from IEEE Xplore.  Restrictions apply. 
[19] A. Askarov and A. Sabelfeld, “Gradual Release: Unifying Declassiﬁca-
tion, Encryption and Key Release Policies,” in SP ’07: Proceedings of
the 28th IEEE Symposium on Security and Privacy. Washington, DC,
USA: IEEE Computer Society, 2007, pp. 207–221.
[20] A. Banerjee and D. A. Naumann, “Secure Information Flow and Pointer
Conﬁnement in a Java-like Language,” in CSFW ’02: Proceedings of the
15th IEEE Workshop on Computer Security Foundations. Washington,
DC, USA: IEEE Computer Society, 2002, p. 253.
[21] J.-F. Bergeretti and B. A. Carr´e, “Information-ﬂow and data-ﬂow analy-
sis of while-programs,” ACM Transactions on Programming Languages
and Systems, vol. 7, no. 1, pp. 37–61, 1985.
[22] D. Clark, C. Hankin, and S. Hunt, “Information ﬂow for algol-like
languages,” Computer Languages, vol. 28, no. 1, pp. 3–28, 2002.
[23] C. Hammer, J. Krinke, and G. Snelting, “Information ﬂow control for
Java based on path conditions in dependence graphs,” in ISSSE ’06:
Proceedings of the IEEE International Symposium on Secure Software
Engineering.
IEEE, 2006.
[24] C. Hammer and G. Snelting, “Flow-sensitive, context-sensitive, and
object-sensitive information ﬂow control based on program dependence
graphs,” International Journal of Information Security, vol. 8, no. 6, pp.
399–422, December 2009, supersedes ISSSE and ISoLA 2006.
[25] N. Swamy and M. Hicks, “Veriﬁed enforcement of stateful information
release policies,” in PLAS ’08: Proceedings of the 3rd ACM SIGPLAN
Workshop on Programming Languages and Analysis for Security. New
York, NY, USA: ACM, 2008, pp. 21–32.
[26] P. Li and S. Zdancewic, “Downgrading policies and relaxed noninter-
ference,” SIGPLAN Notices, vol. 40, no. 1, pp. 158–170, 2005.
[27] S. Chong and A. C. Myers, “Security policies for downgrading,” in
CCS ’04: Proceedings of the 11th ACM Conference on Computer and
Communications Security, New York, NY, USA, 2004, pp. 198–209.
[28] S. Tse and S. Zdancewic, “A Design for a Security-Typed Language
with Certiﬁcate-Based Declassiﬁcation,” in ESOP ’05: 14th European
Symposium on Programming, 2005, pp. 279–294.
[29] S. Chong and A. C. Myers, “End-to-End Enforcement of Erasure and
Declassiﬁcation,” in CSF ’08: Proceedings of the 21st IEEE Computer
Security Foundations Symposium, 2008, pp. 98–111.
[30] A. Sabelfeld and A. C. Myers, “A Model for Delimited Information
Release,” in ISSS ’03: International Symposium on Software Security,
2003, pp. 174–191.
[31] N. Swamy, M. Hicks, S. Tse, and S. Zdancewic, “Managing policy
updates in security-typed languages,” in CSFW ’06: Proceedings of the
19th IEEE Workshop on Computer Security Foundations, 2006, pp. 202–
216.
[32] S. Bandhakavi, W. H. Winsborough, and M. Winslett, “A Trust Man-
agement Approach for Flexible Policy Management in Security-Typed
Languages,” in CSF ’08: Proceedings of
the 21st IEEE Computer
Security Foundations Symposium, 2008, pp. 33–47.
[33] B. Hicks, D. King, and P. McDaniel, “Declassiﬁcation with Crypto-
graphic Functions in a Security-Typed Language,” Network and Security
Center, Department of Computer Science, Pennsylvania State University,
Tech. Rep. NAS-TR-0004-2005, January 2005, (updated May 2005).
[34] A. Askarov and A. Sabelfeld, “Localized delimited release: combining
the what and where dimensions of information release,” in PLAS ’07:
Proceedings of the 2nd Workshop on Programming Languages and
Analysis for Security. New York, NY, USA: ACM, 2007, pp. 53–60.
[35] S. Chong, A. C. Myers, K. Vikram, and L. Zheng, Jif Reference Manual,
June 2006. [Online]. Available: http://www.truststc.org/pubs/548.html
[36] A. Askarov and A. Sabelfeld, “Security-Typed Languages for Imple-
mentation of Cryptographic Protocols: A Case Study,” in ESORICS ’05:
Proceedings of the 10th European Symposium on Research in Computer
Security, 2005, pp. 197–221.
[37] ——, “Tight enforcement of information-release policies for dynamic
languages,” in CSF ’09: Proceedings of the 22nd IEEE Computer Secu-
rity Foundations Symposium. Washington, DC, USA: IEEE Computer
Society, 2009, pp. 43–59.
[38] P. Giambiagi and M. Dam, “On the secure implementation of security
protocols,” Science of Computer Programming, vol. 50, no. 1-3, pp.
73–99, 2004.
[39] V. B. Livshits and M. S. Lam, “Finding security vulnerabilities in Java
applications with static analysis,” in SSYM ’05: Proceedings of the 14th
Conference on USENIX Security Symposium.
Berkeley, CA, USA:
USENIX Association, 2005, pp. 18–18.
[40] O. Tripp, M. Pistoia, S. J. Fink, M. Sridharan, and O. Weisman, “TAJ:
effective taint analysis of web applications,” in PLDI ’09: Proceedings of
the 2009 ACM SIGPLAN Conference on Programming Language Design
and Implementation, New York, NY, USA, 2009, pp. 87–97.
[41] R. Giacobazzi and I. Mastroeni, “Abstract non-interference: parameter-
izing non-interference by abstract interpretation,” in POPL ’04: Pro-
ceedings of the 31st ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages. New York, NY, USA: ACM, 2004, pp.
186–197.
[42] J. Hendrix and H. Ohsaki, “Combining equational tree automata over
ac and aci theories,” in RTA ’08: Proceedings of the 19th International
Conference on Rewriting Techniques and Applications. Springer-Verlag,
2008, pp. 142–156.
[43] A. Askarov, S. Hunt, A. Sabelfeld, and D. Sands, “Termination-
insensitive noninterference leaks more than just a bit,” in ESORICS ’08:
Proceedings of the 13th European Symposium on Research in Computer
Security. Springer, 2008, pp. 333 – 348.
[44] T. Reps, S. Horwitz, and M. Sagiv, “Precise Interprocedural Dataﬂow
Analysis via Graph Reachability,” in POPL ’95: Proceedings of the 22nd
ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages. New York, NY, USA: ACM, 1995, pp. 49–61.
108
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:11:48 UTC from IEEE Xplore.  Restrictions apply.