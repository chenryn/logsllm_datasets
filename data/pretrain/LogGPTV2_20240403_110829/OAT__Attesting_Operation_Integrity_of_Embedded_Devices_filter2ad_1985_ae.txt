1946
33
100
1
10
418
1
2
100
1
10
23
Blob
Size (B)
69
44
913
10
205
248
Veriﬁcation
Time (s)
5.6
0.61
1.74
0.13
1.35
1.89
20
6
7
8
4
9
operations.
It is worth noting that the execution delay caused by our
attestation may vary signiﬁcantly as the following two factors
change: the length/duration of the attested operation and the
frequency of critical variable def-use events. For shorter oper-
ations, the attestation overhead tends to be higher percentage-
wise. For instance, the operation in RC (the shortest among
the tested programs) takes 2.55 seconds to ﬁnish without
attestation and 2.66 seconds with attestation, resulting in the
highest relative overhead (4.5%) among all tested programs.
However, this does not mean the absolute delay, in this case,
is longer than others or unacceptable.
The more frequent the def-use events of critical variables
are, the higher the attestation delay becomes. For example,
the operations in HA and LC are similar in lengths. But the
attestation overhead on HA (1.3%) is lower than the overhead
on LC (4.4%) partly because HA has fewer def-use events of
critical variables.
In the “Instrumentation Statistics” column, we show, for
each operation execution, the numbers of the instrumented
events encountered during the attestation (including condi-
tional branches, def-use checks, returns, and indirect call-
s/jumps) as well as the number of critical variables selected.
These statistics provide some insights into the overhead re-
ported earlier. The instrumented events occur about thousands
of times during an operation, which translates roughly to an
average per-operation delay of 0.15 seconds.
Measurement Engine Memory Footprint and Runtime
Overhead: The measurement engine inside TEE consumes
memory mainly for three purposes: the BLAKE-2s HASH
calculation, the critical data deﬁne and use check, and the
forward control-ﬂow trace recording, including taken or not-
taken bits and indirect jump/call destination. The BlAKE-
2 HASH function only requires less than 2KB for storing
the block buffer, 32 Bytes for the IV, 160 Bytes for the
sigma array, and some temporary buffers. The critical data
check requires a static HASH table of 4KB with 512 slots,
and a dynamic pool for critical variables (the size of this
pool is proportional to the number of critical variables; in
our evaluation, the pool size is less than 2KB). The forward
control-ﬂow trace in our evaluation is no more than 2KB. The
whole memory footprint of the measurement engine is less
than 10KB for the real embedded applications used in our
evaluation.
The runtime overhead of the measurement engine comes
TABLE IV: Number of Instrumentation Sites: Value-based (R1) and
Address-based (R2)
SP
56
140
40% 9.5% 6.8% 44.4% 31.2% 26%
R1
R2
R1 / R2
RM
57
842
HA
37
388
Avg.
-
-
RC
20
45
LC
41
131
from three sources (i.e., the three major tasks of the measure-
ment engine): calculating the hash upon function return events,
recording critical data deﬁne events, and verifying critical data
use event. In our evaluation, on average, processing one return
event and calculating the new hash takes 0.19 µs; recording a
critical data deﬁne event takes 11.04 µs; verifying a critical
data use event takes 2.03 µs. Obviously, hash calculation is
relatively fast whereas critical data event processing requires
a longer time mainly because it involves hash table lookup or
memory allocation for a new entry.
Value-based Check vs. Addressed-based Check: To show
the performance difference between value-based checking
(CVI) and address-based checking (e.g., DFI), we measured
the number of instrumented instructions needed in both cases
for all of the test programs. As shown in Table IV, on average,
CVI’s instrumentation is 74% less than the instrumentation
required by address-based checking (i.e., a 74% reduction).
Speciﬁcally, CVI’s instrumentation is as little as 6.8% of what
DFI requires when the program is relatively large (e.g., RM).
The number only increases to 44.4% when we annotated most
of the variables as critical in RC.
Space-efﬁciency of Hybrid Attestation: Our control-ﬂow
attestation uses the hybrid scheme consisting both forward
traces and backward hashes to achieve not only complete
veriﬁability but also space-efﬁciency. To quantify the space-
efﬁciency, we compared the sizes of the control-ﬂow traces
produced by OAT (R1 in Table V) and the traces produced
by pure trace-based CFI (R2 in Table V). On average, OAT’s
traces take only 2.24% of space as needed by control-ﬂow
traces (i.e., a 97% reduction). This result shows that our hybrid
scheme is much better suited for embedded devices than solely
trace-based CFI in terms of space efﬁciency.
On the other hand, compared with existing hash-based
attestation schemes, OAT’s attestation blobs are not of ﬁxed-
length and grow as attested operations execute, which may
lead to overly large attestation blobs. However, in practice,
OAT attestation blobs are reasonably small in size. Based
11
TABLE V: Control-ﬂow Trace Size (Bytes): With Return Hash (R1)
and Without Return Hash (R2)
R1
R2
R1 / R2
SP
69
HA
44
3772
RM
913
13713
42941
0.2% 1.1% 6.7% 1.7% 1.5% 2.24%
RC
10
585
LC
205
13725
Avg.
-
-
on our experiments, the average blob size is 0.25kb. The
individual blob size for each program is shown in the “Blob
Size” column in Table III. We attribute this optimal result to
two design choices: (i) the hybrid measurement scheme that
uses ﬁxed length hashes for verifying returns (more frequent)
and traces for verifying indirect forward control transfers (less
frequent); (ii) the operation-scoped control-ﬂow attestation,
which generates per-operation measurements and is enabled
only when an operation is being performed.
Veriﬁcation Time: We also measured OAT veriﬁer’s execution
time when it checks the attestation blob generated for each
program. The result
is shown in the “Veriﬁcation Time”
column in Table III, averaging 1.89 seconds per operation.
It shows that veriﬁcation is not only deterministic but fast. On
average, the veriﬁcation is one order of magnitude faster than
the original execution (Table III). This result echoes that the
veriﬁcation is not a re-run of the program. It is a static abstract
execution guided by the measurement stream.
C. Attack Detection via OEI Attestation
Due to the lack of publicly available exploits for bare-
metal devices, we injected vulnerabilities to the previously
discussed test programs, launch basic control-ﬂow hijacks and
data corruption, and examine if the measurements generated
by OAT capture these attacks.
Speciﬁcally, we injected to the programs the vulnerabilities
similar to those shown in Listing 1. We then exploited the
vulnerabilities to (i) overwrite a function pointer; (ii) corrupt
a critical variable; (iii) trigger an unintended operation. By
verifying the measurements generated by OAT, we found that,
in each test case, (i) the illegal control-ﬂow transfer caused by
the subverted function pointer is recorded in the measurement
stream; (ii) the CVI ﬂag is set due to the failed CVI check; (iii)
the unintended operation is detected because the reconstructed
code path does not match the requested operation.
Although these tests are simple and created by ourselves,
they do demonstrate the basic functioning of our prototype and
conﬁrm OEI attestation as a viable way for remote veriﬁers
to detect
those attacks that are currently undetectable on
embedded devices. Moreover, they showcase that IoT backend
can now use OAT to remotely attest the operations performed
by IoT devices and establish veriﬁable trust on these devices.
D. Security Analysis
Our threat model (§III-D) anticipates that attackers may ﬁnd
and exploit unknown vulnerabilities in the embedded programs
running in the Normal World. However, we assume code in-
jection or modiﬁcation cannot happen, which the existing code
12
integrity schemes for embedded devices already prevent [16],
[37].
To evade OAT, a normal-world attacker would need to
1(cid:13) disable the instrumentation or the trampolines, 2(cid:13) abuse
the interfaces that the measurement engine exposed to the
trampolines, or CA-TA interfaces, 3(cid:13) manipulate the control
ﬂow in a way to generate a HASH collision, thus bypassing
the veriﬁcation, or 4(cid:13) modify the attestation blob including
replay an old recorded blob.
1(cid:13) is ruled out by the code integrity assumption. Plus,
attempts to divert the control-ﬂows of instrumented code or
trampolines are always recorded in the control-ﬂow trace
and detected later by the veriﬁer. Our design prevents 2(cid:13) as
follows. OAT compiler disallows world-switching instructions
(smc) used outside of the trampoline library. This restriction
ensures that only the trampoline functions can directly invoke
the CA-TA interfaces and the rest of the code in the Normal
World cannot. To further prevent code-reuse attacks (e.g.,
jumping to the interface invocation point in the library from
outside), OAT loads the library in a designated memory region.
The compiler masks the target of every indirect control transfer
in the embedded program so that the trampoline library cannot
be reached via indirect calls or jumps or returns (i.e., only
hard-coded direct calls from each instrumentation site can
reach trampolines). This masking-based technique is highly
efﬁcient and is commonly used for software fault isolation.
As a result, 2(cid:13) is prevented.
As for 3(cid:13), we assume that the attacker may exploit program
vulnerabilities and manipulate the control ﬂow of the program
in arbitrary ways. We prove that (see Appendix B) our control-
ﬂow veriﬁcation mechanism cannot be bypassed by such
a powerful attacker. Our proof shows that bypassing our
veriﬁcation is at least as hard as ﬁnding a hash collision,
which is practically infeasible considering that BLAKE-2s is
as collision-resistent as SHA3 [7].
Our veriﬁcation scheme prevents 4(cid:13) because the integrity
of the attestation blob is guarded by a signature generated
from TEE with a hardware-provisioned private key. A veriﬁer
can easily check the signature and veriﬁes the integrity of the
attestation blob. Replay attack is also prevented by checking
whether the cryptographic nonce inside the attestation blob
matches what originally was generated by the veriﬁer.
There is no higher privileged code (e.g., a standalone OS)
that needs to be protected or trusted because OAT targets bare-
metal embedded devices. For the same reason, it is realistic to
require the ﬁrmware to be entirely built using OAT compiler.
IX. RELATED WORK
Remote Attestation: Early works on remote attestation, such
as [60][44], were focused on static code integrity, checking if
code running on remote devices has been modiﬁed. A series
of works [4], [50], [21], [38] studied the Root of Trust for
remote attestation, relying on either software-based TCB or
hardware-based TPM or PUF. Armknecht et al. [5] built a
security framework for software attestation.
Other works went beyond static property attestation. Hal-
dar et al. [61] proposed the veriﬁcation of some high-level
semantic properties for Java programs via an instrumented
Java virtual machine. ReDAS [36] veriﬁed the dynamic system
properties. Compared with our work, these previous systems
were not designed to verify control-ﬂow or dynamic data
integrity. Further, their designs do not consider bare-metal em-
bedded devices or IoT devices. Some recent remote attestation
systems addressed other challenges. A tool called DARPA [35]
is resilient to physical attacks. SEDA [6] proposed a swarm
attestation scheme scalable to a large group of devices. In
contrast, we propose a new remote attestation scheme to solve
a different and open problem: IoT backend’s inability to verify
if IoT devices faithfully perform operations without being
manipulated by advanced attacks (i.e., control-ﬂow hijacks
or data-only attacks). Our attestation centers around OEI, a
new security property we formulated for bare-metal embedded
devices. OEI is operation-oriented and entails both control-
ﬂow and critical data integrity.
A recent work called C-FLAT [2] is closely related to our
work. It enabled control-ﬂow attestation for embedded devices.
However, it suffers from unveriﬁable hashes, especially when
attested programs have nested loops and branches. This is
because verifying a control-ﬂow hash produced by C-FLAT