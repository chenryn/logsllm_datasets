# CVE-2017-16995复现与分析
## 前言
CVE-2017-16995是一个内核提权漏洞，最近PWN2OWN爆出了一个ebpf模块相关的提权漏洞，因此打算系统地学习一下ebpf这个内核模块，并复现和分析与之相关的内核漏洞，之前先知已经有`rebeyond`前辈发了一篇分析[深入分析Ubuntu本地提权漏洞—【CVE-2017-16995】](https://xz.aliyun.com/t/2212)，本篇文章将补充一部分ebpf的基础知识为之后的其他漏洞复现做准备。
## 漏洞概述
漏洞存在于内核版本小于`4.13.9`的系统中，漏洞成因为`kernel/bpf/verifier.c`文件中的`check_alu_op`函数的检查问题，这个漏洞可以允许一个普通用户向系统发起拒绝服务攻击(内存破坏)或者提升到特权用户。
## 漏洞复现
本次复现使用的是`4.4.110`版本的内核，下载地址为[Download](https://mirrors.edge.kernel.org/pub/linux/kernel/v4.x/linux-4.4.110.tar.gz)。
下载源码之后编译内核得到二进制的内核文件，结合之前漏洞复现的文件系统启动qemu，使用[exploit-db](https://www.exploit-db.com/exploits/45010)上的exp编译`gcc ./poc.c -static -pthread -o
poc`，打包进文件系统再重新启动qemu，运行编译后的文件即可提权成功。
## 前置知识
### eBPF模块
ebpf是bpf模块的功能增强版本，我们先来了解一下bpf模块。BPF的全称为`Berkeley Packet
Filter`，顾名思义，这是一个用来做包过滤的架构。它也是tcpdump和wireshark实现的基础。BPF的两大核心功能是过滤和复制，以tcpdump为例，BPF一方面接受tcpdump经过libpcap转码后的滤包条件，根据这些规则过滤报文；另一方面也将符合条件的报文复制到用户空间，最终由libpcap发送给tcpdump。
BPF设计的架构如下，基本原理是网卡驱动在收到数据报文之后多出一条路径转发给内核的BPF模块，供其和用户态的程序交互使用。
我们这里使用tcpdump的-d参数查看我们过滤数据报文的实际规则，可以看到BPF有一套自己的指令集来过滤数据包。
    ╭─wz@wz-virtual-machine ~/Desktop/CTF/wangdingbei2020/zhuque/supersafe_vm ‹hexo*› 
    ╰─$ sudo tcpdump -d -i ens33 tcp port 23                                                                                         1 ↵
    (000) ldh      [12]
    (001) jeq      #0x86dd          jt 2    jf 8
    #判断是否是ipv6，false则jmp到L8
    (002) ldb      [20]
    (003) jeq      #0x6             jt 4    jf 19
    (004) ldh      [54]
    (005) jeq      #0x17            jt 18   jf 6
    (006) ldh      [56]
    (007) jeq      #0x17            jt 18   jf 19
    (008) jeq      #0x800           jt 9    jf 19
    #判断是否是ipv4
    (009) ldb      [23]
    (010) jeq      #0x6             jt 11   jf 19
    #判断是否是tcp
    (011) ldh      [20]
    (012) jset     #0x1fff          jt 19   jf 13
    #检测是否是ip分片报文
    (013) ldxb     4*([14]&0xf)
    (014) ldh      [x + 14]
    #tcp报文中的src port位置
    (015) jeq      #0x17            jt 18   jf 16
    (016) ldh      [x + 16]
    #tcp报文中的dest port位置
    (017) jeq      #0x17            jt 18   jf 19
    (018) ret      #262144
    #符合要求
    (019) ret      #0
    #不符合要求
BPF采用的报文过滤设计全称是`CFG((Computation Flow Graph))`，过滤器基于if-else的控制流图，具体的实现不再展开。
在[内核filter文档](https://www.kernel.org/doc/Documentation/networking/filter.txt)有关于BPF开发的sample，每条指令的格式类似，都是一个32字节大小的结构体类型，code表明指令类型，k用来做一些跳转的value或其他用处。
    struct sock_filter {    /* Filter block */
        __u16   code;   /* Actual filter code */
        __u8    jt; /* Jump true */
        __u8    jf; /* Jump false */
        __u32   k;      /* Generic multiuse field */
    };
BPF的交互过程也是类似的，可以总结为以下几个步骤：
  1. 使用`sock = socket(PF_PACKET, SOCK_RAW, htons(ETH_P_ALL))`创建一个raw socket
  2. 将Socket绑定指定网卡
  3. 使用`setsockopt(s, SOL_SOCKET, SO_ATTACH_FILTER, &bpf, sizeof(bpf)))`里的`SO_ATTACH_FILTER`参数将bpf结构体传入内核
  4. 用`bytes = recv(s, buf, sizeof(buf), 0);`recv函数来获取过滤的数据报文
之后BPF引入了`JIT`编译代码优化性能，引入了`seccomp`功能添加沙箱，在kernel 3.15版本后引入了eBPF。
### eBPF sample
eBPF(extended BPF)引进之后之前的BPF被称为cBPF(classical
BPF)，相比于cBPF，eBPF做了很多大刀阔斧的改变，比如拿C写的BPF代码，基于map的全新交互方式，新的指令集，Verifier的引进等。
我们首先来看下eBPF的sample来了解基本的交互方式。
第一个示例只有一个.c文件，BPF代码需要自己构造，可以类比成C里嵌了汇编。
    //./linux-4.4.110/samples/bpf/sock_example.c
    /* eBPF example program:
     * - creates arraymap in kernel with key 4 bytes and value 8 bytes
     *
     * - loads eBPF program:
     *   r0 = skb->data[ETH_HLEN + offsetof(struct iphdr, protocol)];
     *   *(u32*)(fp - 4) = r0;
     *   // assuming packet is IPv4, lookup ip->proto in a map
     *   value = bpf_map_lookup_elem(map_fd, fp - 4);
     *   if (value)
     *        (*(u64*)value) += 1;
     *
     * - attaches this program to eth0 raw socket
     *
     * - every second user space reads map[tcp], map[udp], map[icmp] to see
     *   how many packets of given protocol were seen on eth0
     */
    #include 
    #include 
    #include 
    #include 
    #include 
    #include 
    #include 
    #include 
    #include 
    #include 
    #include 
    #include 
    #include "libbpf.h"
    static int test_sock(void)
    {
        int sock = -1, map_fd, prog_fd, i, key;
        long long value = 0, tcp_cnt, udp_cnt, icmp_cnt;
        //[1]使用bpf_create_map函数新建一个map，其中map类型为BPF_MAP_TYPE_ARRAY，模拟一个数组
        map_fd = bpf_create_map(BPF_MAP_TYPE_ARRAY, sizeof(key), sizeof(value),
                    256);
        if (map_fd proto */),
            BPF_STX_MEM(BPF_W, BPF_REG_10, BPF_REG_0, -4), /* *(u32 *)(fp - 4) = r0 */
            BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
            BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4), /* r2 = fp - 4 */
            BPF_LD_MAP_FD(BPF_REG_1, map_fd),
            BPF_RAW_INSN(BPF_JMP | BPF_CALL, 0, 0, 0, BPF_FUNC_map_lookup_elem),
            BPF_JMP_IMM(BPF_JEQ, BPF_REG_0, 0, 2),
            BPF_MOV64_IMM(BPF_REG_1, 1), /* r1 = 1 */
            BPF_RAW_INSN(BPF_STX | BPF_XADD | BPF_DW, BPF_REG_0, BPF_REG_1, 0, 0), /* xadd r0 += r1 */
            BPF_MOV64_IMM(BPF_REG_0, 0), /* r0 = 0 */
            BPF_EXIT_INSN(),
        };
        //[3]使用bpf_prog_load函数加载eBPF代码到内核
        prog_fd = bpf_prog_load(BPF_PROG_TYPE_SOCKET_FILTER, prog, sizeof(prog),"GPL", 0);
        if (prog_fd 
    #include 
    #include 
    #include 
    #include "bpf_helpers.h"
    struct bpf_map_def SEC("maps") my_map = {
        .type = BPF_MAP_TYPE_ARRAY,
        .key_size = sizeof(u32),
        .value_size = sizeof(long),
        .max_entries = 256,
    };
    SEC("socket1")
    int bpf_prog1(struct __sk_buff *skb)
    {
        int index = load_byte(skb, ETH_HLEN + offsetof(struct iphdr, protocol));
        long *value;
        if (skb->pkt_type != PACKET_OUTGOING)
            return 0;
        value = bpf_map_lookup_elem(&my_map, &index);
        if (value)
            __sync_fetch_and_add(value, skb->len);
        return 0;
    }
    char _license[] SEC("license") = "GPL";
之后使用`sockex1_user.c`加载eBPF代码到内核进而执行代码，过滤数据包得到vaule并输出。
    #include 
    #include 
    #include 
    #include "libbpf.h"
    #include "bpf_load.h"
    #include 
    #include 
    int main(int ac, char **argv)
    {
        char filename[256];
        FILE *f;
        int i, sock;
        snprintf(filename, sizeof(filename), "%s_kern.o", argv[0]);
        if (load_bpf_file(filename)) {
            printf("%s", bpf_log_buf);
            return 1;
        }
        sock = open_raw_sock("lo");
        assert(setsockopt(sock, SOL_SOCKET, SO_ATTACH_BPF, prog_fd,
                  sizeof(prog_fd[0])) == 0);
        f = popen("ping -c5 localhost", "r");
        (void) f;
        for (i = 0; i < 5; i++) {
            long long tcp_cnt, udp_cnt, icmp_cnt;
            int key;
            key = IPPROTO_TCP;
            assert(bpf_lookup_elem(map_fd[0], &key, &tcp_cnt) == 0);
            key = IPPROTO_UDP;
            assert(bpf_lookup_elem(map_fd[0], &key, &udp_cnt) == 0);
            key = IPPROTO_ICMP;
            assert(bpf_lookup_elem(map_fd[0], &key, &icmp_cnt) == 0);
            printf("TCP %lld UDP %lld ICMP %lld bytes\n",
                   tcp_cnt, udp_cnt, icmp_cnt);
            sleep(1);
        }
        return 0;
    }
以上就是两种eBPF开发的基本方式，可以看到C语言编写eBPF代码更加简洁，这也是eBPF相比于cBPF的一个优势。
### eBPF代码执行过程
首先我们调用`bpf_create_map`来新建一个attr变量，这个变量为联合类型，其成员变量随系统调用的类型不同而变化，之后对变量成员进行初始化赋值，包括map类型，key大小，value大小，以及最打容量。
之后调用`sys_bpf`进而使用系统调用`syscall(__NR_bpf, BPF_MAP_CREATE, attr,
size);`创建一个map数据结构，最终返回map的文件描述符。这个文件是用户态和内核态共享的，因此后续内核态和用户态都可以对这块共享内存进行读写(可以参见下面的bpf_cmd)。
    //lib/bpf.c
    int bpf_create_map(enum bpf_map_type map_type, 