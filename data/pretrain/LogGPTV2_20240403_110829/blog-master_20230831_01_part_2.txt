# 连接PolarDB | PostgreSQL版集群数据库  
conn = psycopg2.connect(database="",  
                        host="",  
                        user="",  
                        password="",  
                        port="")  
conn.autocommit = True  
def answer(prompt_doc, prompt):  
    improved_prompt = f"""  
    按下面提供的文档和步骤来回答接下来的问题：  
    (1) 首先，分析文档中的内容，看是否与问题相关  
    (2) 其次，只能用文档中的内容进行回复,越详细越好，并且以markdown格式输出  
    (3) 最后，如果问题与PolarDB PostgreSQL版不相关，请回复"我对PolarDB PostgreSQL版以外的知识不是很了解"  
    文档:  
    \"\"\"  
    {prompt_doc}  
    \"\"\"  
    问题: {prompt}  
    """  
    response = openai.Completion.create(  
        model=GPT_COMPLETIONS_MODEL,  
        prompt=improved_prompt,  
        temperature=0.2,  
        max_tokens=MAX_TOKENS  
    )  
    print(f"{response['choices'][0]['text']}\n")  
similarity_threshold = 0.78  
max_matched_doc_counts = 8  
# 通过pgvector过滤出相似度大于一定阈值的文档块  
similarity_search_sql = f'''  
SELECT doc_chunk, token_size, 1 - (embedding  '{prompt_embedding}') AS similarity   
FROM polardb_pg_help_docs WHERE 1 - (embedding  '{prompt_embedding}') > {similarity_threshold} ORDER BY id LIMIT {max_matched_doc_counts};  
'''  
cur = conn.cursor(cursor_factory=DictCursor)  
cur.execute(similarity_search_sql)  
matched_docs = cur.fetchall()  
total_tokens = 0  
prompt_doc = ''  
print('Answer: \n')  
for matched_doc in matched_docs:  
    if total_tokens + matched_doc['token_size']  您可以对拆分方法以及问题prompt进行优化，以获得更加准确、完善的回答，本文仅为示例。  
总结  
如果未接入向量数据库，OpenAI对于问题“列举2023年PolarDB PostgreSQL 14版本新增功能点”的回答往往与阿里云不相关(因为大模型未训练相关知识点, 所以需要prompt来提升精准度).   
在接入存储在PolarDB | PostgreSQL版数据库中的专属知识库后，对于问题“列举2023年PolarDB PostgreSQL 14版本新增功能点”，我们将会得到只属于阿里云PolarDB PostgreSQL版数据库的相关回答。  
根据上述实践内容，可以看出PolarDB | PostgreSQL版完全具备构建基于LLM的垂直领域知识库的能力。  
#### PolarDB|PG新方法2 设计和实验   
ChatGPT 这类通用机器人在专业领域的回答可能不是那么精准, 原因有可能是通用机器人在专业领域的语料库学习有限, 或者是没有经过专业领域的正反馈训练.      
为了提升通用机器人在专业领域的回答精准度, 可以输入更多专业领域相似内容作为prompt来提升通用ai机器人在专业领域的精准度.     
- 参考openai文档. https://help.openai.com/en/articles/4936848-how-do-i-create-a-good-prompt    
PolarDB | PostgreSQL 开源数据库在与openai结合的过程中起到的核心作用是什么?    
将PolarDB|PG 作为OpenAI(大模型)的外脑, 当需要回忆知识时, 基于PolarDB|PG数据库向量插件的向量类型、向量索引、向量相似搜索操作符, 加速相似内容的搜索. 通过“问题 和 prompt:可能的正确答案(来自外脑的回忆)”作为参考输入, 修正OpenAI(大模型)在专业领域的回答精准度.       
1、准备:      
- PolarDB | PostgreSQL 开源数据库       
- plpython3u 函数插件  以及 python openai 包    
- 向量插件 (pgvector, hnsw, embedding等插件都可以)      
- openai 账号       
- 参考文档库素材      
2、建设专业领域的“参考文档库”, 问题+答案的格式. 这一步可能是人肉工作, 比如从文档提炼成“问题+答案”的格式. 例如:     
- 问题: 如何使用PolarDB的eqp功能实现多机并行计算?     
- 答案: 以htap模式构建PolarDB集群, 配置xxx相关并行参数, explain sql 观察执行计划, 执行sql; (实际情况你可以写得更详细一些.)    
3、创建向量插件    
4、创建openai的辅助参考表, 包括“问题文本、问题向量、答案文本”几个字段.  你可以理解为“正确答案”(或者prompt).     
5、将"参考文档库"导入数据库, 并调用openai得到辅助参考表“问题文本字段对应的vector值, 1536维度的向量”写入到辅助参考表.      
6、创建辅助参考表vector字段的向量索引.     
7、在用户向openai问非常专业的问题时,     
- 将“用户输入的问题1”抛给openai得到“向量值1”,     
    - 这一步的tiktoken过程介绍:     
    - [《PostgreSQL 或PolarDB 使用插件pg_tiktoken - 使用 OpenAI tiktoken库文本向量化(tokenization) - 使用分词算法BPE - NLP 自然语言处理》](../202307/20230706_05.md)     
- 使用“向量值1”搜索辅助参考表, 找到最相似的“向量2”(这一步就是向量检索, 可以用到向量索引), 取出与之相对应的“问题和答案”, (这一步可以设置阈值, 如果没有特别相似的就不要了.)      
- 将“用户输入的问题1 + 最相似问题和答案(如果有)”输入, 向openai提问, 从而修正直接向openai问“用户输入的问题1”的结果. 提升openai专业领域回答的准确度.      
Demo 演示  
1、通过云起实验启动数据库, 这个实验室是永久免费的.     
- https://developer.aliyun.com/adc/scenario/exp/f55dbfac77c0467a9d3cd95ff6697a31    
参考:    
- https://github.com/digoal/blog/blob/master/202307/20230710_03.md    
创建并启动容器    
```    
docker run -d -it --cap-add=SYS_PTRACE --cap-add SYS_ADMIN --privileged=true --name pg registry.cn-hangzhou.aliyuncs.com/digoal/opensource_database:pg14_with_exts      
```    
进入容器    
```    
docker exec -ti pg bash      
```    
连接数据库    
```    
psql      
```    
这个容器支持如下相似搜索插件, 接下来的例子使用pgvector插件, 如果向量文本特别多, 建议使用hnsw或pg_embedding插件.    
- similarity, 近似算法, 类型+索引      
- imgsmlr, 图像搜索, 类型+索引    
- pgvector, 向量搜索, 类型+索引(ivfflat)    
- hnsw, 向量搜索, 类型+索引(hnsw)    
- embedding, 向量搜索, 类型+索引(hnsw)    
2、创建插件以及 python openai 包    
```    
# apt install -y python3-pip    
# pip3 install openai    
root@689ed216de12:/tmp# psql    
psql (14.8 (Debian 14.8-1.pgdg110+1))    
Type "help" for help.    
postgres=# create extension plpython3u ;    
CREATE EXTENSION    
postgres=# create extension vector ;    
CREATE EXTENSION    
```    
3、准备"参考文档库", 你可以理解为“正确答案”.     
4、创建openai的辅助参考表, 包括“问题文本、问题向量、答案文本”几个字段.      
```    
create table tbl_faq (    
  id serial8 primary key,    
  f text,  -- 问题    
  q text,  -- 标准答案    
  v vector(1536)  -- 文本格式: faq (textcat('title: '||f, ' --- '||q)) 文本向量    
);    
```    
5、将"参考文档库"导入数据库, 并调用openai得到辅助参考表“问题文本字段对应的vector值, 1536维度的向量”写入到辅助参考表.      
直接update全表的话容易造成表膨胀, 建议从外面的文件导入的过程中调用openai实时计算vector值并导入.      
配置环境变量(启动数据库时的环境变量OPENAI_API_KEY. 用于存储openai key, 当然你也可以使用其他方式获取key, 改写下列function即可.)    
```    
create or replace function get_v (faq text) returns vector as $$    
  import openai    
  import os    
  text = faq    
  openai.api_key = os.getenv("OPENAI_API_KEY")    
  response = openai.Embedding.create(    
      model = "text-embedding-ada-002",    
      input = text.replace("\n", " ")    
    )    
  embedding = response['data'][0]['embedding']    
  return embedding    
$$ language plpython3u;    
```    
```    
insert into tbl_faq(f,q,v) select f,q,get_v(textcat('title: '||f, ' --- '||q)) from 外部表;    
```    
6、创建辅助参考表vector字段的向量索引.     
```    
create index on tbl_faq using ivfflat (v vector_cosine_ops);    
analyze tbl_faq;    
```    