conference on computer vision and pattern recognition. 815â€“823.
[57] Yagiz Sutcu, Qiming Li, and Nasir Memon. 2007. Protecting biometric templates
with sketch: Theory and practice. IEEE Transactions on Information Forensics and
Security 2, 3 (2007), 503â€“512.
[58] Yaniv Taigman, Ming Yang, Marcâ€™Aurelio Ranzato, and Lior Wolf. 2014. DeepFace:
Closing the gap to human-level performance in face verification. In Proceedings
of the IEEE conference on computer vision and pattern recognition. 1701â€“1708.
[59] Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank
Piessens, Mark Silberstein, Thomas F Wenisch, Yuval Yarom, and Raoul Strackx.
2018. Foreshadow: Extracting the keys to the intel {SGX} kingdom with tran-
sient out-of-order execution. In 27th {USENIX} Security Symposium ({USENIX}
Security 18). 991â€“1008.
[60] Zhicheng Wang, Hongwei Zhang, Juan Peng, and Li Yang. 2018. Fingerprint
identification based on neural network for large fingerprint database. In Third
International Workshop on Pattern Recognition, Vol. 10828. International Society
for Optics and Photonics, 1082804.
[61] Stephen B Wicker and Vijay K Bhargava. 1999. Reed-Solomon codes and their
applications. John Wiley & Sons.
[62] Andrew Chi-Chih Yao. 1986. How to generate and exchange secrets. In Annual
Symposium on Foundations of Computer Science. IEEE.
[63] Long Zhang, Zhenan Sun, Tieniu Tan, and Shungeng Hu. 2009. Robust biomet-
ric key extraction based on iris cryptosystem. In International Conference on
Biometrics. Springer, 1060â€“1069.
[64] Ye Zhang and Farinaz Koushanfar. 2016. Robust privacy-preserving fingerprint
authentication. In 2016 IEEE International Symposium on Hardware Oriented
Security and Trust (HOST). IEEE, 1â€“6.
A SECURE SKETCHES FOR SET DIFFERENCE
FROM [29]
For our multisketch construction, we use the secure sketch con-
struction for set-distance from [29]. We give a new (slightly less
efficient) construction for set-distance using authenticated encryp-
tion scheme (see Section 3). Here we give the original set-distance
construction given in [29] for reference purpose.
Let w and Ëœw be two sets of size n. We also assume that there is a
one-to-one mapping between the set elements and Z2k , where 2k
is the size of the universe from where the set elements are chosen.
Set-distance is defined as d(w, Ëœw) = wâˆ† Ëœw = |w âˆª Ëœw âˆ’ w âˆ© Ëœw|. The
sketching function SSâˆ†
t takes as input a set w and outputs a bit-
string s (a.k.a, the sketch of w). The recovery function Recâˆ†
t on
input s and a new set Ëœw, outputs w if at least t out of n points match
between w and Ëœw; that is to say | Ëœwâˆ†w| â‰¤ 2(n âˆ’ t). The algorithms
for sketch and recover are shown in Figure 13.
According to the security analysis in [29], the conditional min-
entropy of the message distributions (uniform messages over Zn
2k )
t (w = {x1, . . . , xn }):
SSâˆ†
s â† () ; tâ€² â† 2(n âˆ’ t)
for j = 1, 2, . . . , tâ€² do
xi
sj â† 
(cid:18)
(cid:19)
iâˆˆS
SâŠ†Zn
|S|=j
return s
t (s, wâ€² = {xâ€²
Recâˆ†
tâ€² â† 2(n âˆ’ t)
fh(z) â† zn +tâ€²
S â† {(cid:0)xâ€²
i)(cid:1)
i, fh(xâ€²
n }):
1, . . . , xâ€²
i =1 si ztâ€²âˆ’i
| i âˆˆ Zn }
Find a (n âˆ’ tâ€² âˆ’ 1)-degree polynomial fl
that agrees with at least t points in S
using [n, n âˆ’ tâ€², tâ€² + 1] Reed-Solomon
decoding [33, 61].
return the roots of fh âˆ’ fl .
Figure 13: Algorithms for sketch (SS) and recover (Rec) for secure sketch
for set-distances. (From [29].)
given the sketch values is nk âˆ’ 2(n âˆ’ t)k = (2t âˆ’ n)k. In our con-
struction, we used t = 7, n = 10, and therefore, the conditional
min-entropy will be at least 4k bits.
B DIAGRAMMATIC VIEW OF MULTISKETCH
OPERATIONS
A user registers with a user id u and a vector of biometric templates
w = w1 . . . wn. Multisketch uses two databases â„ and â„±, where
â„ contains user id u and the corresponding helper data v, and â„±
contains the random permutation of the templates registered so
far. Highlighted are the entries corresponding to a user u4 with
templates w4 = w41 . . . w4n.
u, w
register
MS
u, v
User
u, Ëœw
login
â„
u1 v1
u2 v2
u3 v3
u4 v4
â„±
w
w21 w12 w43
w41 w32 w33
w11 w42 w23
w31 w22 w13
w3n
. . . w2n
w1n
w4n
u
GetUser
v
MRec
Ëœw
FindMatches
wâ€²
Recover
w or âŠ¥
Figure 14: Diagram of multisketch as a part of an authentication service.
C WVU DATA
One of the fingerprint dataset we used for evaluating the accuracy
of TenSketch is a subset of the dataset collected through ManTech
Innovations Fingerprint Study Phase I [25]. The fingerprints were
collected at West Virginia University and released at GMU. We call
this dataset WVU dataset. The database contains fingerprints of 500
people acquired using 7 optical sensors like CrossMatch Guardian,
I3 digID mini, CrossMatch Seek II as well as ink-based Tenprint
cards. Among the participants, most of the participant were in the
age group 20-33, accounting for 60.6% percent of people. Among
the ethnicity, Caucasians accounted for 57.2%.
Also, there were nearly equal number of male (51%) and female
(48%) participants. The users provided the two sets of fingerprints in
the sequence of rolled individual fingers on the right and left hands,
left slap, right slap, and thumb slap for the live sensor. In order to
Attribute
Gender
Class
Position
NCIC class
Scan Type
FS
# cls Base Acc. ML Acc. Classifier
MLP
88.8%
RF
60.3%
28.2% MLP, RF
57.4%
MLP
93.6% MLP, RF
58.9%
MLP
88.8%
31.9%
10.0%
56.9%
92.3%
50.0%
2
6
10
18
2
2
Figure 15: Performance of machine learning classifiers (MLP: multilayer
perceptron; RF: random forest, and LR: Logistic Regression) in predicting
different attributes of fingerprints. The base accuracy (probability of the
most probable class) and the accuracy of the best performing classifier
averaged across 5-fold cross-validation is presented in the third and fourth
column. The last column notes the best performing classifier. In case the
performance of multiple classifiers are similar, we note all of them. Attribute
FS denotes whether the fingerprint is from the file (template) or the one
used for searching.
carry out the experiments of this paper, for every subject we used
the fingerprint images of the ten fingers acquired using the I3 digID
Mini sensor. Every subject provided two sets of fingerprints each
of: rolled fingers on right and left hands, left slap, right slap, and
thumb slap. This data has been used in multiple prior work [48, 50].
D INFERENCE FROM FINGERPRINT
TEMPLATES.
We explore what information can be learned from the fingerprints
in xyt format (list of minutiae points). The template might reveal
some non-trivial information about the finger, such as which finger
it is, what is the NCIC class type, or the gender of the user, etc. This
information might lead to improved guessing strategy. For example,
an attacker can split the database of the fingerprint templates based
on the type of the finger.
We tried random forest [46] and multi-layer perceptron [12] to
determine each of the attributes: gender, class, finger position, NCIC
class type, scan type, and first or second scan (FS). We report the
result of our classifier in Figure 15. Notably, finger position and the
class of the fingerprint can be retrieved with significant accuracy
from the fingerprints (in xyt format).
E TRAINING ADVERSARIAL CLASSIFIERS
USING SIAMESE ARCHITECTURE
To construct adversarial classifiers, we tried both deep neural net-
work (DNN) and Siamese networks. In standard DNNs, the order
of input features does not carry any information. Therefore, both
fingerprint templates are concatenated and passed directly to a
DNN model. However, in Siamese networks [56, 58], we can en-
force the knowledge that the model is receiving two separate sets
of features and the goal is to infer some information (identifying if
they are from the same person, in our case) about these two sets.
Siamese architectures are first shown in [56, 58] to be useful for
face recognition and verification.
In Siamese networks, two input feature sets are passed to two sis-
ter networks with identical parameters (weights). (See Figure 8 for
a high-level diagram of the setup.) The job of two sister networks is
to transform the input features into an encoded vector of ne values,
v0 and v1. The two vectors are merged using a specific function, e.g.,
i =2Î½
xi
i
Each solution of {xi}â€™s in the above equation is a valid classifier
combination, where xi denotes the number of times the classifier ğ’i
is used in the sequence. In the previous example, ğ’4 is used twice,
therefore x4 = 2 and all other xi = 0. If we assume the classifiersâ€™
performances are independent, the effective FPR of the stitched
, where Î½i is the FPR of classifier ğ’i.
classifier would be Î t
Therefore, for any combination of classifiers, the total number of
t-tuples that need to be checked through MRec is N tâˆ’b Â· Î t
=
ğ’ª(N tâˆ’b). A stitched classifier with a long combination of classifiers
â€” high value of xi â€” might have lower FPR, for example, x2 = 6.
However, a long combination of classifiers will also degrade the true
positive rate of the stitched classifier; the attacker might not find
the correct tuple at the end due to one of the classifiers misclassified
it. We therefore adjust the classifiers to have a true positive rate
(TPR) of 0.9 or more.
We empirically compute the FPR of the stitched classifiers for
all possible combinations. There are only 11 possible solutions to
the above equation for b = 1 and t = 7. We found x7 = 1 has the
least FPR, 0.1, and x2 = 6 has the second lowest FPR. In Section 7
we give different attacks using ğ’7 and ğ’2 and show their efficacy.
Overall, we show that no the attacker gets any better than 3.3-bits
of advantage via different combinations of classifiers.
i =2Î½
xi
i
absolute value, and passed to a fully connected layer (with single
output neuron) that outputs the probability. Two distance functions,
i.e., absolute value |v0 âˆ’ v1| and the square of differences (v0 âˆ’ v1)2
have been used in our experiments. Absolute distance function
provided superior performance with ne = 64. We have explored
multiple Siamese architectures with various hyperparameters.
The best performing Siamese based classifier underperforms
single DNN models. The accuracy with and without the quality
values is 66% and 62% respectively.
F GENERALIZED â€œSTITCHINGâ€ ATTACK
USING CLASSIFIERS
The trained classifiers {ğ’i} can be used to determine if a message
tuple of size i belongs to a single user. An attacker can use a com-
bination of ğ’iâ€™s to find a t-tuple of fingerprints belonging to the
same user. For example, the attacker, given b = 1 fingerprint w1,
can use ğ’4 to find all 4-tuples S1 likely belonging to the same user
and containing w1. For each tuple w1...4 âˆˆ S1, the attacker then
uses ğ’4 again to find remaining three fingerprints, by finding all
4-tuples which include, say, w4. Let call the second set, S2. Finally,
the attacker can apply MRec on the tuples in S2, to find a valid
7-tuple. The cost of this attack is C = N 3 Â·cc +|S1| Â· N 3 Â·cc +|S2| Â·cs.
Let the false positive rate (FPR) of ğ’4 be Î½4, then |S1| = N 3 Â· Î½4, and
4 Â· cs = ğ’ª(N 6).
|S2| = |S1| Â· N 3 Â· Î½4 = N 6 Â· Î½2
More generally, an attacker can use a sequence of ğ’iâ€™s to stitch a
t-tuple. We can find all possible such classifier combinations using
the following equation.
4. Therefore, C â‰ˆ N 6 Â· Î½2
t
i =2
(i âˆ’ 1) Â· xi = (t âˆ’ b) , where xi âˆˆ {0, 1, . . . , t}.