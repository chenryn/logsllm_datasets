1
(cid:2)
(cid:3)
1
n
-
1
-
1
n
(cid:14)
=
i
1
(cid:7)
(cid:5)
(cid:6)
'
-
p
p
+
+
i
i
1
1
--
p
p
c
+
i
i
i
1
(cid:4)
(cid:2)
(cid:3)
=
1
n
n
[
g
](cid:14)
-
1
-
1
=
1
i
i
, 
(3) 
where  gi  is  node  i’s  temptation  to  cheat  by  routing  to  the  lowest 
n
i <(cid:213)
g
i
=1
T
,  where 
price  next  hop.    Lemma  1  tells  us  that 
(
--=
rte
1
)0
T
minimized by setting each gi equal to 
we have 
, which shows that 
.    It  requires  a  bit  of  calculus  to  show  that  IC  is 
, 
.  However, as 
nT /1
¥ﬁCI
/1 ﬁnT
¥ﬁn
.  (cid:2) 
1
According to the claim, as the data path grows long, it increasingly 
resembles a lowest-price path.  Since lowest-price routing does not 
support innovation, we may speculate that innovation degrades with 
the length of the data path.  Though we suspect stronger claims are 
possible, we can demonstrate one such result by including an extra 
assumption: 
Claim 2.  Under the available bargain path assumption, if node  i , a 
distance n from S, can invest to alter its quality, and the source will 
sP  for a route including node i’s new quality, 
spend no more than 
then the payment to node i, p, decreases hyperbolically with n, 
p
£
p
l
+
/1
T
(
n
(
n
-
)
-
1
)
1
, 
P
s
(4) 
T
where 
  is  the  bound  on  the  product  of  temptations 
from  the  previous  claim.    Thus,  i  will  spend  no  more  than 
1
r
improvement,  which 
this  quality 
  on 
P
s
+
p
l
(cid:13)
(cid:11)
(cid:11)
(cid:12)
1
(
--=
rte
(
n
-
)
-
1
)
1
T
(
n
/1
)0
(cid:10)
(cid:8)
(cid:8)
(cid:9)
approaches the bargain path’s payment, 
pl
r
, as 
¥ﬁn
. 
The proof is given in the appendix.  As a node gets farther from the 
source,  its  maximum  payment  approaches  the  bargain  price,  pl.  
Hence, the reward for innovation is bounded by the same amount.  
Large  innovations,  meaning  substantially  more  expensive  than 
pl /
, will not be pursued deep into the network. 
r
Claim 2 can alternately be viewed as a lower bound on how much it 
costs to elicit innovation in a network.  If the source S wants node i 
to innovate, it needs to get a motivating payment, p, to i during the 
routing stage.  However, it must also pay the nodes on the way to i a 
premium  in  order  to  motivate  them  to  route  properly.    The  claim 
shows  that  this  premium  increases  with  the  distance  to  i,  until  it 
dwarfs the original payment, p. 
Our claims stand in sharp contrast to our null hypothesis from the 
introduction.  Comparing the intuitive argument that supported our 
hypothesis with these claims, we can see that we implicitly used an 
oversimplified model of market pressure (as either present or not).  
As  is  now  clear,  market  pressure  relies  on  the  decisions  of 
customers, but these are limited by the lack of information.  Hence, 
competitive forces degrade as the network deepens. 
4.  VERIFIABLE MONITORS 
In this section, we begin to introduce more accountability into the 
network.    Recall  that  in  the  previous  section,  we  assumed  that 
players  couldn’t  convince  each  other  of  their  private  information.  
What  would  happen  if  they  could?    If  a  monitor’s  informational 
signal can be credibly conveyed to others, we will call it a verifiable 
monitor.  The monitor’s output in this case can be thought of as a 
statement accompanied by a proof, a string that can be processed by 
any player to determine that the statement is true. 
A verifiable monitor is a distributed algorithmic mechanism that 
runs on the network graph, and outputs, to specific nodes, proofs 
about current or past network behavior. 
Along  these  lines,  we  can  imagine  verifiable  counterparts  to  E2E 
and  ROP.    We  will  label  these  E2Ev  and  ROPv.    With  these 
monitors, each node observes the quality of the rest of the path and 
can  also  convince  other  players  of  these  observations  by  giving 
them a proof. 
By adding verifiability to our monitors, identifying a single cheater 
is  straightforward.    The  cheater  is  the  node  that  cannot  produce 
proof  that  the  rest  of  path  quality  decreased.    This  means  that  the 
negative  results  of  the  previous  section  no  longer  hold.    For 
example, the following lemma stands in contrast to Lemma 1.  
Lemma 2.  With monitors E2Ev, ROPv, and PRc, and provided that 
the node before each potential cheater has an alternate next hop that 
isn’t more expensive, it is possible to enforce any data path in SPE 
so long as the maximum temptation is less than what can be deterred 
in finite time, 
(cid:13)
(cid:11)
(cid:12)
y
p
(cid:10)
(cid:8)
(cid:9)
max
£
1
-
rte
0
r
(cid:1)
t
0
(5) 
Proof.    This  lemma  follows  because  nodes  can  share  proofs  to 
identify  who  the  cheater  is.    Only  that  node  must  be  punished  in 
equilibrium,  and  the  preceding  node  does  not  lose  any  payoff  in 
administering the punishment.  (cid:2) 
With this lemma in mind, it is easy to construct counterexamples to 
Claim 1 and Claim 2 in this new environment. 
Unfortunately, there are at least four reasons not to be satisfied with 
this improved monitoring system.  The first, and weakest reason is 
that  the  maximum  temptation  remains  finite,  causing  some 
distortion  in  routes  or  payments.    Each  node  along  a  route  must 
extract some positive profit unless the next hop is also the cheapest.  
Of course, if t0 is small, this effect is minimal. 
The second, and more serious reason is that we have always given 
our  source  the  ability  to  commit  to  any  punishment.    Real  world 
users are less likely to act collectively, and may simply search for 
the  best  service  currently  offered.    Since  punishment  phases  are 
generally  characterized  by  a  drop  in  quality,  real  world  end-users 
may take this opportunity to shop for a new access provider.  This 
will make nodes less motivated to administer punishments. 
The  third  reason  is  that  Lemma  2  does  not  apply  to  cheating  by 
coalitions.    A  coalition  node  may  pretend  to  punish  its  successor, 
but  instead  enjoy  a  secret  payment  from  the  cheating  node.  
Alternately,  a  node  may  bribe  its  successor  to  cheat,  if  the 
punishment  phase  is  profitable,  and  so  forth.    The  required 
discounted  time  for  punishment  may  increase  exponentially  in  the 
number of coalition members, just as in the previous section! 
The final reason not to accept this monitoring system is that when a 
cheater is punished, the path will often be routed around not just the 
offender,  but  around  other  nodes  as  well.    Effectively,  innocent 
nodes will be punished along with the guilty.  In our abstract model, 
this  doesn’t  cause  trouble  since  the  punishment  falls  off  the 
equilibrium path.  The effects are not so benign in the real world.   
When  ISPs  lie  in  sequence  along  a  data  path,  they  contribute 
complementary services, and their relationship is vertical.  From the 
perspective  of  other  source-destination  pairs,  however,  these  same 
firms  are  likely  to  be  horizontal  competitors.    Because  of  this,  a 
node  might  deliberately  cheat,  in  order  to  trigger  punishment  for 
itself and its neighbors.  By cheating, the node will save money to 
some extent, so the cheater is likely to emerge from the punishment 
phase better off than the innocent nodes.  This may give the cheater 
a  strategic  advantage  against  its  competitors.    In  the  extreme,  the 
cheater may use such a strategy to drive neighbors out of business, 
and thereby gain a monopoly on some routes. 
5.  CONTRACTIBLE MONITORS 
At the end of the last section, we identified several drawbacks that 
persist  in  an  environment  with  E2Ev,  ROPv,  and  PRc.    In  this 
section, we will show how all of these drawbacks can be overcome.  
To do this, we will require our third and final category of monitor:  
A contractible monitor is simply a verifiable monitor that generates 
proofs  that  can  serve  as  input  to  a  contract.    Thus,  contractible  is 
jointly a property of the monitor and the institutions that must verify 
its proofs.  Contractibility requires that a court, 
1.  Can verify the monitor’s proofs. 
2.  Can understand what the proofs and contracts represent to 
the extent required to police illegal activity. 
3.  Can enforce payments among contracting parties. 
Understanding the agreements between companies has traditionally 
been a matter of reading contracts on paper.  This may prove to be a 
harder task in a future network setting.  Contracts may plausibly be 
negotiated by machine, be numerous, even per-flow, and be further 
complicated by the many dimensions of quality. 
When  a  monitor  (together  with  institutional  infrastructure)  meets 
these  criteria,  we  will  label  it  with  a  subscript  c,  for  contractible.  
The  reader  may  recall  that  this  is  how  we  labeled  the  packets 
received  monitor,  PRc,  which  allows  ISPs  to  form  contracts  with 
per-packet  payments.    Similarly,  E2Ec  and  ROPc  are  contractible 
versions of the monitors we are now familiar with.   
At  the  end  of  the  previous  section,  we  argued  for  some  desirable 
properties  that  we’d  like  our  solution  to  have.    Briefly,  we  would 
like to enforce optimal data paths with an equilibrium concept that 
doesn’t  rely  on  re-routing  for  punishment,  is  coalition  proof,  and 
doesn’t punish innocent nodes when a coalition cheats.  We will call 
such  an  equilibrium  a  fixed-route  coalition-proof  protect-the-
innocent equilibrium. 
As  the  next  claim  shows,  ROPc  allows  us  to  create  a  system  of 
linear (price, quality) contracts under just such an equilibrium. 
Claim 3.  With ROPc, for any feasible and consistent assignment of 
rest  of  path  qualities  to  nodes,  and  any  corresponding  payment 
schedule  that  yields  non-negative  payoffs,  these  qualities  can  be 
maintained  with  bilateral  contracts  in  a  fixed-route  coalition-proof 
protect-the-innocent equilibrium. 
Proof:    Fix  any  data  path  consistent  with  the  given  rest  of  path 
qualities.    Select  some  monetary  punishment,  P,  large  enough  to 
prevent any cheating for time t0 (the discounted total payment from 
the  source  will  work).    Let  each  node  on  the  path  enter  into  a 
contract with its parent, which fixes an arbitrary payment schedule 
so long as the rest of path quality is as prescribed.  When the parent 
node, which has ROPc, submits a proof that the rest of path quality 
is  less  than  expected,  the  contract  awards  her  an  instantaneous 
transfer,  P,  from  the  downstream  node.    Such  proofs  can  be 
submitted every  0t
 for the previous interval. 
Suppose  now  that  a  coalition,  C,  decides  to  cheat.    The  source 
measures  a  decrease  in  quality,  and  according  to  her  contract,  is 
awarded P from the first hop.  This means that there is a net outflow 
of P from the ISPs as a whole.  Suppose that node i is not in C.  In 
order for the parent node to claim P from i, it must submit proof that 
the quality of the path starting at i is not as prescribed.  This means 
that there is a cheater after i.  Hence, i would also have detected a 
change in quality, so i can claim P from the next node on the path.  
Thus, innocent nodes are not punished.  The sequence of payments 
must end by the destination, so the net outflow of P must come from 
the  nodes  in  C.    This  establishes  all  necessary  conditions  of  the 
equilibrium.  (cid:2) 
Essentially,  ROPc  allows  for  an  implementation  of  (price,  quality) 
contracts.  Building upon this result, we can construct competition 
games  in  which  nodes  offer  various  qualities  to  each  other  at 
specified  prices,  and  can  credibly  commit 
these 
performance  targets,  even  allowing  for  coalitions  and  a  desire  to 