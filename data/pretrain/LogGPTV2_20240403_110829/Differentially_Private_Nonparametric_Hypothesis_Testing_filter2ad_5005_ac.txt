whelm the value.
Because of space constraints, we don’t give pseudocode for this
hypothesis test, but it follows exactly that of the previous test. The
privatized statistic is computed byKWabsstat, which adds Laplace
noise in the same way as for(cid:103)KWstat, but scaled to the lower sensi-
tivity. The full hypothesis test,KWabsp, computes the p value in
the same way as was done for(cid:103)KWp.7
Theorem 3.5. AlgorithmKWabsstat andKWabsp are ϵ-differentially
Proof. The proof is identical to the proofs for Algorithms(cid:103)KWstat
and(cid:103)KWp (Theorems 3.2 and 3.3).
private.
□
Unequal group sizes. The traditional h statistic (and therefore
the noisy private analogue) has a reference distribution that is
independent of the allocation of observations between groups. This
is unfortunately not true for our new habs statistic. Fortunately,
it seems that the worst-case distribution (i.e., the one resulting in
the highest critical value) occurs when all groups are of equal size.
(We present both theoretical and experimental evidence for this in
the full version.) As a result, it is safe to always equal-sized groups
when simulating a reference distribution, though for very unequal
group sizes, there will be a significant loss in power compared to a
hypothetical where group sizes were known. (If approximate group
sizes are known publicly or released through other queries, those
could be used instead when simulating the reference distribution.)
7Unlike before, a χ 2 approximation cannot be used.
3.4 Experimental Results
on synthetic data (See the full version for an application to real-
world data.) We generate many databases of data distributed with
Power analysis. We now assess the power of ourKWabsp test
specified parameters and then runKWabsp on each. The power
KWabsp returns a significant result (i.e. a p-value less than the
of the test for a given set of parameters is the proportion of times
significance level α, generally set at 0.05). We use three groups
of normally-distributed data, separated by steps of one standard
deviation (so the highest and lowest groups differ by two standard
deviations). In our captions we denote the mean of group i with µi.
Figure 1: Power ofKWabsp at various values of ϵ and total
sample size n. (Effect size: maxi(µi) − mini({µi) = 2σ; д = 3;
α = .05; equal group sizes; normally distributed sample data)
As shown in Figure 1, our private absolute value test variant
requires significantly less data points than the original private test
to reach the same power. Thus, from here on, we only evaluate the
power of the absolute value variant. Figure 1 also shows that, at
an ϵ of 1, our private absolute value test only requires a database
around a factor of 3 larger than the public test needs.
Uniformity of p-values. If a test is correctly designed, the prob-
ability of type 1 error (i.e., rejecting the null hypothesis when it
is correct) should be less than or equal to α for any chosen value
of α. Comparing the fit of a large number of simulated p-values
generated from null distributions to the uniform distribution on
the unit interval allows one to evaluate the uniformity of p-values
for a given hypothesis test. A common tool to carry this proce-
dure out, the quantile-quantile (or Q-Q) plot, plots the quantiles of
the uniform, theoretical distribution against the quantiles of the
p-values. The theoretical and emperical quantiles will be nearly
equal at all quantiles when the p-values follow the theoretical dis-
tribution, resulting in a linear trend on the Q-Q plot. A convex Q-Q
plot indicates an increase in the type II error rate (i.e. the test not
rejecting the null hypothesis when it is indeed not true, causing
a decrease in power) which is acceptable but undesirable, while a
concave Q-Q plot indicates an exceedingly high type I error rate
(i.e. the test rejecting the null hypothesis when it is true, causing
undue increases in power) which is not acceptable. Figure 2 demon-
strates the p-value uniformity ofKWabsp. See the full version for a
discussion of uniformity of p-values with unequal group sizes.
and number of groups. We also vary the frequency of tied values in
the data, since the random ordering of tied values adds additional
noise for our statistic. Finally, we run the comparison on real data
comparing income and age. The results of these experiments are
shown in the full version. We find that the results discussed above
are consistent across these variations.
4 TWO GROUPS
We now consider the case of data with only two groups (e.g., re-
stricting our comparison to the methylation levels of the bipolar
subjects versus the healthy controls.) In the public nonparametric
setting, one could simply use Kruskal-Wallis with д = 2, but one
can also use the Mann-Whitney U -test (also called the Wilcoxon
rank-sum test), proposed in 1945 by Frank Wilcoxon [35] and for-
malized in 1947 by Henry Mann and Donald Whitney [18]. In this
section we construct a private version of the Mann-Whitney test
and compare it to simply usingKWabsp with д = 2.
The standard parametric test in the public setting is the two-
sample t-test. We know of three prior works that can, in some
sense, be seen as providing an analogue of the two-sample t-test
for the standard private setting. The only one for which this is
an explicit goal is that of D’Orazio et al. [7]. This test releases
private estimates of the difference in means and of the within-group
variance and produces a confidence interval rather than a p-value.
(The difference in means is done with simple Laplace noise, while
the variance estimate uses a subsample-and-aggregate algorithm.)
Most importantly, they assume that the size of the two groups is
public knowledge, where we treat the categorical value of a data
point (ex., schizophrenic or not) to be private data.
There are two other works we know of that provide a private
analogue of the two-sample t-test as a result of a slightly different
goal. The first is Ding et al. [6], who give a test under the more
restrictive local differential privacy definition. This test is of course
also private under the standard differential privacy definition. The
other work is that of Swanberg et al. [28], who give a private ana-
logue of the ANOVA test, as discussed previously. In the public
setting, ANOVA with д = 2 is equivalent to the two-sample t-test.
Based on (somewhat incomparable) experiments in their respec-
tive papers, it appears that the Swanberg et al. test is much higher
power, which is unsurprising given that it was developed for the
centralized database model of privacy. We therefore compare our
work to this.
To our knowledge, there is no prior work specifically on a private
version of the Mann-Whitney test. As before, we find that our
rank-based nonparametric tests outperform the private parametric
equivalent even when the data is normally distributed. We also find
that, unlike in the public setting, the more generic Kruskal-Wallace
analogue (used with д = 2) outperforms the more purpose-built
test.
4.1 The Mann-Whitney test
The function used to calculate the Mann-Whitney U statistic is
formalized in Algorithm MWstat. As before, x is a database of size
th data point in group i. A statistic
n, with rij being the rank of the j
is first calculated for each group by summing the rankings in that
group and subtracting a term depending on the group size. We
Figure 2: A quantile-quantile plot ofKWabsp comparing the
distribution of simulated p-values to the uniform distribu-
tion at varying n, all with equal group sizes. (д = 3; ϵ = 1)
Comparison to previous work. The only prior work on hypothesis
testing for independence of two variables, one continuous and one
categorical, is that on ANOVA. The best private ANOVA analogue
is that of Swanberg et al. [28]. In Figure 3 we compareKWabsp
to their test and we find its power to be much greater. To get 80%
power with this effect size, our test requires only 23% as much data
as the private ANOVA test. (The effect size used is the same as
in [28].) We stress that this means our test is significantly higher-
power, in addition to being usable for non-normal data. The test of
Swanberg et al. also requires that the analyst issuing the query can
accurately bound the range of the data—a bound that is too tight
or too loose will reduce the power of the test. Our test works for
data with unknown range.
Figure 3: Power ofKWabsp, Swanberg et. al.’s test [28], and
the public tests at various n. (Effect size: max(µn) − min(µn) =
2σ; ϵ = 1; д = 3; α = .05; equal group sizes; continuous sample
data)
Robustness of results. Though it is unusual, it is possible that the
relative power of different hypothesis tests could change when dif-
ferent effect sizes are considered. Therefore we repeat the analysis
shown in Figure 1 with a variety of different effect sizes, group sizes,
then take the minimum of the two statistics to get U . Compared
to the other statistics we are considering, the directionality of U
is reversed — low values are inconsistent with the null hypothesis
and cause rejection, rather than high values.
Algorithm MWstat : Mann-Whitney Test Statistic
Input: x
for i ∈ {1, 2} do
j rij
Ri ←−
Ui ←− Ri − ni(ni +1)
2
U ←− min{U1, U2}
Output: U
4.2 A Differentially Private Algorithm
The global sensitivity of MWstat is n, but the local sensitivity is
lower. We prove the following in the full version:
Theorem 4.1 (Sensitivity of MWstat). The local sensitivity is
given by LSMWstat(x) = max{n1, n2}, where n1 and n2 are the sizes
of the two groups in x.
We can now define our private test statistic, (cid:103)MWstat. This al-
Input: x, ϵm, ϵU , δ
m ←− min{n1, n2}
gorithm first uses a portion of its privacy budget (ϵm) to estimate
the size of the smallest group. This value is then reduced to m∗,
such that with probability 1 − δ we have n − m∗ > LSMWstat(x).
This means that we can then release U using noise proportional to
n−m∗ (using the remaining privacy budget, ϵU . See the full version
for proof that (cid:103)MWstat is (ϵm + ϵU , δ)-differentially private.
Algorithm (cid:103)MWstat : Private Mann-Whitney Test Statistic
(cid:17)
(cid:16) 1
(cid:101)m ←− m + Lap
m∗ ←− max(⌈(cid:101)m − c⌉ , 0)
(cid:101)U ←− MWstat(x) + Lap
Output:(cid:101)m,(cid:101)U
As before, (cid:103)MWstat is not meaningful on its own; we want an
sponding p-value. This is shown below in algorithm (cid:103)MWp. It works
similarly to the analogous algorithms(cid:103)KWp andKWabsp. The key
group size estimate(cid:101)m.8
difference is that the reference distribution now depends on the
applicable reference distribution with which to calculate a corre-
c ←− − ln(2δ)
ϵm
(cid:16) n−m∗
(cid:17)
ϵm
ϵU
8The algorithm given simulates full databases to compute the reference distribution.
This is not particularly slow, but in the full version we show that one can also sample
from a normal distribution with certain parameters to get an acceptable reference
distribution more quickly.
for k := 1 to z do
Input: x, ϵm,ϵU ,δ, z
x∗ ←− a database with n independent uniform values
Algorithm (cid:103)MWp : Complete Mann-Whitney Test
((cid:101)m, (cid:101)U) ←− (cid:103)MWstat(x, ϵm, ϵU, δ)
(cid:101)m ←− ⌈max(0,(cid:101)m)⌉
from [0,1] divided into 2 groups of size(cid:101)m and n −(cid:101)m
Uk ←− (cid:103)MWstat(x∗, ϵm, ϵU, δ)
p ←− fraction of Uk less than(cid:101)U
Output:(cid:101)U , p
A note on design. In the case ofKWabsp we found that the highest
possible critical value came from a reference distribution with equal-
size groups. For this test that is not the case, so we cannot use equal-
size groups when generating the reference distribution without
unacceptable type 1 error. As a result, we need an estimate of group
size. If we didn’t need this estimate for the reference distribution, it
is possible that (cid:103)MWstat would be more accurate by simply using the
global sensitivity bound on MWstat. (It would be a slightly higher
sensitivity, but no privacy budget would need to be expended on
estimating m.) This is a good example of a point made in Section
1: simply acheiving an accurate of estimate of a test statistic is not
enough. The ultimate goal of a hypothesis test is a p-value, which
also requires an accurate reference distribution and high power in
order to minimize decision error.
perimentally verify that type 1 error never exceeds α. See the full
version for evidence that our estimate appears to be sufficiently
accurate and for additional discussion.
Type 1 error. The reference distribution in the (cid:103)MWp algorithm
depends on m, which is only estimated by(cid:101)m, so we need to ex-
Theorem 4.2. Algorithm (cid:103)MWp is (ϵm + ϵU , δ)-differentially pri-
Proof. Since the computation of((cid:101)m,(cid:101)U) is(ϵm +ϵU , δ)-differentially
vate.
private (see full version for the proof of this fact) and all of the steps
following this computation do not require access to the database
and are, thus, post processing, by Theorem 2.4, it follows that the
complete algorithm is also (ϵm + ϵU , δ)-differentially private. □
4.3 Experimental Results
thetic data.9 We run (cid:103)MWp on many simulated databases and report
Power analysis. We first assessed the power of our test on syn-
statistic (cid:103)MWstat. We found that the optimal proportion of ϵ to allot
the percentage of the time that a significant result was obtained.
For our first effect size, we have the two groups consist of normally
distributed data with means one standard deviation apart. In all
experiments we set δ = 10−6.
Our first step was to determine the optimal proportion of the
total privacy budget, ϵtot , to allot to estimating m and the test
to estimating m is roughly .65, experimentally confirmed at several
choices of ϵtot , effect size, total sample size n, group size ratios
n1/n, and underlying distribution. (See the full version for more
9For application of our test to real-world data, see the full version
details.) We then fix the proportion of ϵtot allotted to ϵm as .65 and
vary ϵtot and total sample size n to measure the power of our test.
Figure 4: Power of (cid:103)MWp at various values of ϵtot and total
sample size n. (Effect size: µ1 − µ2 = 1σ; proportion of ϵtot to
ϵm = .65; α = .05; m:(n − m) = 1)
Figure 5: A quantile-quantile plot of (cid:103)MWp varying n. (ϵtot =
1; proportion of ϵtot to ϵm = .65; m:(n − m)= 1; normally dis-
tributed sample data)
As shown in Figure 4, the power loss due to privacy is not unrea-
sonably large. At an ϵtot of 1, the test only requires a database that
is approximately a factor of 3 larger than that needed for the public
test to reach a power of 1. As one might expect, the database size
needed to detect a given effect has a roughly inverse relationship
with ϵtot . In the full version we perform a similar power analysis,
varying effect size rather than sample size.
Uniformity of p-values. Algorithm(cid:103)MWp uses the privatized group
sample sizes m∗,(n − m∗) in place of the true group sizes n1, n2 in
order to simulate the reference distribution. Naturally, then, one
may wonder how conservative our critical values are as a result of
ensuring that the type 1 error rate does not exceed α. As shown in
Figure 5, the type I error rate of our test does not exceed α when
group sample sizes are equal. As total sample size n increases, the
p-value quantiles asymptotically approach that of the theoretical
distribution. In the full version, we also examine uniformity of p-
values of (cid:103)MWp with unequal group sizes and a variation of (cid:103)MWp
that assumes equal group sizes.
Comparison to previous work. The best existing test applicable in
the same use case is that of Swanberg et al. [28]. Their differentially
private ANOVA test can be used in the 2-group case to compare
to our Mann-Whitney test. The results of this comparison, using
the same paramater settings chosen for optimal power in their test,
can be seen in Figure 6, where our test offers a substantial power
increase.
Kruskal-Wallis can be used to compare the distributions of samples
from two groups. As shown in Figure 7, we find that in the private
Comparing (cid:103)MWp andKWabsp. Both the Mann-Whitney and the
setting,KWabsp is more statistically powerful than (cid:103)MWp. This
(cid:103)MWp requires knowledge of the group sizes, using up a fraction of
is perhaps surprising, since one might expect the test developed
specifically for the two-group case to perform better. But this is
an example of how some tests privatize more easily than others.
Figure 6: Power of (cid:103)MWp and Swanberg et. al.’s test at various
n. (ϵtot = 1; Effect size: µ1 − µ2 = 1σ; proportion of ϵtot to
ϵm = .65; α = .05; m:(n − m) = 1), normally distributed sample
data
group size.
the privacy budget, while theKWabsp statistic is not dependent on
method guaranteed an equal number in each group) then (cid:103)MWp can
increases the accuracy of (cid:103)MWstat both by reducing the sensitivity
U . We find that in this case (cid:103)MWp is superior toKWabsp. See the
We did find one exception to this finding. If the analyst knows a