title:BCD: Decomposing Binary Code Into Components Using Graph-Based Clustering
author:Vishal Karande and
Swarup Chandra and
Zhiqiang Lin and
Juan Caballero and
Latifur Khan and
Kevin W. Hamlen
Vishal Karande, Swarup Chandra, Zhiqiang Lin, Juan Caballero, Latifur Khan, and Kevin W. Hamlen.  
"BCD: Decomposing Binary Code Into Components Using Graph-based Clustring."  In Proceedings of the 
13th Asia Conference on Computer and Communications Security (AsiaCCS), pp. 393-398, June 2018.
BCD: Decomposing Binary Code Into Components Using
Graph-Based Clustering
Vishal Karande
The University of Texas at Dallas
PI:EMAIL
Swarup Chandra
The University of Texas at Dallas
PI:EMAIL
Zhiqiang Lin
The Ohio State University
PI:EMAIL
Juan Caballero
IMDEA Software Institute
PI:EMAIL
Latifur Khan
The University of Texas at Dallas
PI:EMAIL
Kevin Hamlen
The University of Texas at Dallas
PI:EMAIL
ABSTRACT
Complex software is built by composing components implement-
ing largely independent blocks of functionality. However, once the
sources are compiled into an executable, that modularity is lost.
This is unfortunate for code recipients, for whom knowing the com-
ponents has many potential benefits, such as improved program
understanding for reverse-engineering, identifying shared code
across different programs, binary code reuse, and authorship attri-
bution. This paper proposes a novel approach for decomposing such
source-free program executables into components. Given an exe-
cutable, our approach first statically builds a decomposition graph,
where nodes are functions and edges capture three types of rela-
tionships: code locality, data references, and function calls. It then
applies a graph-theoretic approach to partition the functions into
disjoint components. A prototype implementation, BCD, demon-
strates the approach’s efficacy: Evaluation of BCD with 25 C++
binary programs to recover the methods belonging to each class
achieves high precision and recall scores for these tested programs.
CCS CONCEPTS
• Information systems → Clustering; • Software and its engi-
neering → Automated static analysis;
KEYWORDS
Binary code decomposition, Components, Graph-Based Clustering
ACM Reference Format:
Vishal Karande, Swarup Chandra, Zhiqiang Lin, Juan Caballero, Latifur
Khan, and Kevin Hamlen. 2018. BCD: Decomposing Binary Code Into Com-
ponents Using Graph-Based Clustering. In ASIA CCS ’18: 2018 ACM Asia
Conference on Computer and Communications Security, June 4–8, 2018, In-
cheon, Republic of Korea. ACM, New York, NY, USA, 6 pages. https://doi.org/
10.1145/3196494.3196504
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5576-6/18/06...$15.00
https://doi.org/10.1145/3196494.3196504
Figure 1: Illustration of binary code hierarchy.
1 INTRODUCTION
Complex software is built by composing smaller components that
implement largely independent blocks of functionality. For example,
Figure 1 illustrates a hierarchy of an executable file that contains
m functions, denoted Fx with x ∈ [1, m]. These functions can
be associated with k modules or components, denoted Cx with
x ∈ [1, k]. Such components are integral to widely-used program-
ming paradigms like modular programming and object-oriented pro-
gramming. For instance, each class in a C++ program can be con-
sidered a separate component. Even in programming languages
like C that lack classes, modules, and packages, programmers often
place each component in its own source file and provide inter-
faces through header files. Such modular software design is key to
keeping code complexity at bay, controlling code development and
maintenance costs, and facilitating code reuse.
Once the source files are compiled into object files and those
object files are statically linked into an executable, this structural
modularity is hidden. This is unfortunate because most commercial
off-the-shelf (COTS) software are released as executables without
debugging information. Binary code analysis performed over a
third-party executable (without access to its source code) could
greatly benefit from modularity information. Security applications
that could benefit include program understanding and decompil-
ing [4, 11], finding related functions like the decryption routine
for a given encryption routine [6], identifying shared code across
different programs [16, 23, 29, 32, 33], reusing binary code [5, 18],
authorship attribution [1, 20, 26], and binary-level enforcement of
object flow integrity policies [31]. In all these applications, analysis
of an unknown binary at only the function level is time consuming
or inadequate, especially when the number of functions is large.
However, it may be intuitively easier or more effective to analyze
functions that are grouped at the component level.
For instance, many binary code reuse applications entail reusing
a set of functions belonging to a program component as a unit,
Binary CodeC1C2CkF3F4F5F1F2Fm-1FmCode-LevelComponent-LevelFunction-Level393rather than reusing the functions individually [5, 17, 18]. Intuitively,
component reuse is more useful since a set of functions (e.g., a li-
brary) can handle more complex logical tasks than individual func-
tions. As another example, consider the application of authorship
attribution using machine learning approaches [1, 26]. Discovery
of discriminatory stylistic patterns of code authors is potentially
enhanced by knowledge of each program’s components, since pat-
terns within each isolated function might be too fine-grained and
dispersed, whereas patterns spanning component-related function
families may provide a richer feature set.
This paper presents a novel static approach to decompose an
executable into components. Our approach is independent of the
compiler used to generate the executable and applies to both object-
oriented and procedural programs. The main idea in our approach is
to examine three key properties (code locality, data references and
function calls) that preserve useful information regarding the origi-
nal program components throughout the compilation process. We
represent these properties in the form of a decomposition graph, and
use a graph-theoretic clustering algorithm to identify the compo-
nents. We have implemented our approach as a tool called BCD. Our
empirical evaluation of BCD on 25 C++ programs, whose ground
truth we manually extracted using source code and debugging
symbols, shows high component detection accuracy.
2 BINARY CODE DECOMPOSITION
While much structural information is lost during compilation, an
executable still maintains useful information that can aid in identi-
fying program components created by the programmers or intro-
duced by a programming paradigm. In this section, we first describe
how BCD builds a graph for each of the three key decomposition
properties of code locality, data references, and function calls (Sec-
tion 2.1). We then detail how BCD builds the decomposition graph
from the three property graphs (Section 2.2). Finally, we describe
the clustering algorithm to partition the decomposition graph into
components (Section 2.3).
2.1 Decomposition Properties
The first step in our approach is to build a directed graph for each
of the three key decomposition properties of code locality, data ref-
erences, and function calls. In each graph, nodes correspond to the
functions in the executable. Different tools can be used to identify
functions in an executable such as IDA [8], BYTEWEIGHT [3], and
Dyninst [14]. BCD currently uses IDA to identify the functions in
an executable, but can easily be adapted to use other tools.
Code locality to sequence graph (SG). When developing a pro-
gram, structurally related functions are often placed close to each
other in the source code by programmers or the programming para-
digm. For example, the programming paradigm may place functions
that operate on the same data next to each other such as the meth-
ods of a class. Source code locality transfers directly to the binary
code because the compiler generates an object file for each source
file and then the static linker concatenates the code (.text) sections
of each object file to produce the code section of the final executable.
Thus, functions that were next to each other in the source code
(e.g., from the same source file or in the same class) end up being
next to each other in the final executable. Code locality captures
2
the intutition that functions that are close to each other more likely
belong to the same component. To generate the sequence graph,
the functions identified by IDA are sorted in increasing order of
their starting address. Then, directed edges are added between con-
secutive functions, directed from the function at lower address to
the one at higher address.
Data references to data-reference graph (DRG). Functions op-
erating on the same data are more likely to be structurally related,
as they are related to the data semantics. This is especially true
in object-oriented programming, where encapsulation makes data
members be accessed by methods in the class. BCD constructs a
data-reference graph by adding edges between functions that ac-
cess the same variable. In an executable, global variables, static
variables, and constant string literals are allocated statically with
lifetime spanning across the entire program execution. In this work,
a data reference is the offset of a statically allocated variable in
the .data, .bss, or .rodata sections of an executable. For local
variables and non-static class members, storage is dynamic. We
focus on static data, global variables, and string literals because
local variables in the stack do not reveal data references across
functions. Moreover, data references to heap-allocated variables
are difficult to analyze statically. To build the data-reference graph,
BCD first creates a mapping between a function f and the set of
statically allocated variables it references D. We denote this map-
ping as Φ : f → D, where D = ⟨D1, . . . , Dm⟩. Here, Dj is the
offset of the jth static variable accessed by function f . An edge
between two functions f i and f j is added when they reference at
least one variable in common. To maintain the directed semantics
of all graphs, an edge in each direction is added between the two
functions. A larger set of common data references between two
functions implies a stronger likelihood that both functions are part
of the same component. Thus, an edge weight is assigned propor-
tional to the number of common data references between the two
functions. The weight is the same in both directions.
Function calls to call graph (CG). The final decomposition prop-
erty that BCD leverages is that of function calling relationships.
Intuitively, when function f i calls function f j, it is likely that those
two functions are structurally related. If a set of functions call each
other more than they call functions not in the set, then it is more
likely that the set of functions belongs to the same component. BCD
builds a call graph by adding a directed edge from function f i to
function f j if f i calls f j. The larger the number of calls between
two functions the stronger their structural relationship. This no-
tion is captured by assigning an edge weight corresponding to the
number of calls between two functions.
Challenges. In each of the above graphs, it is challenging to iden-
tify component boundaries—i.e., a set of edges that when removed
results in a disconnected set of subgraphs, each representing a com-
ponent. Particularly, boundaries between consecutive components
(e.g., C++ classes) are unknown. This affects component boundary
identification in a sequence graph. Similarly, component boundary
identification in a data reference graph is affected by generic func-
tions such as memcpy or printf that may operate on the same data,
despite being largely unrelated to the set of related functions within
Session 9: Software SecurityASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea394a component. Finally, it is not always true that a function calls an-
other related function. For example, the main function may act as a
dispatcher to other functions and is not contextually related to its
callees. Thus, no single graph can be used to detect components. To
address these challenges, the next step combines the three graphs
into a decomposition graph.
2.2 Decomposition Graph Construction
While a graph built using a decomposition property contains infor-
mation about structural relationships between functions, it may not
contain sufficient information to identify components (i.e., disjoint
subgraphs that represent groups of structurally related functions).
To address this issue, our approach constructs a weighted and di-
rected decomposition graph H = (V ′, E′,W ), combining SG, CG,
and DRG. Here, V ′ is the set of functions in the executable and E′
is the union of all edges from the three decomposition properties.
Graph edges are weighted according to the associated decompo-
sition property. We denote an edge between function pair f i and
f j by (f i , f j). For all (f i , f j) ∈ E′, BCD computes an edge weight
wij as a linear combination of the corresponding edge weights in
SG, CG and DRG. We assign a value of 1 to each edge weight in SG
for indicating the relationship between consecutive functions.
Edge weight computation. The edge weights for each graph can
be represented as an adjacency matrix M, in which each matrix
x corresponds to an edge (f i , f j) ∈ Ex . Subscript x ∈
element M
{s, d, c} denotes SG, DRG, or CG, respectively. For nodes in SG, Ms
consists of an adjacency matrix whose elements are each 1 or 0:
ij
(cid:40)1
ij
s =
M
if (f i , f j) ∈ Es
0 otherwise
However, in the case of DRG and CG, the corresponding matrix
elements have a value equal to the count of common data references
or function calls, respectively:
(cid:40)
(cid:40)
yd
0
yc
0
M
ij
d
=
ij
c =
M
if (f i , f j) ∈ Ed , , where 0  0
otherwise
max(p,q)
ij
d
0
ρ
=
ij
d
= 0 since L(Di , Dj) = max(p, q).
where Di = Φ(f i) has length p, Dj = Φ(f j) has length q, and L
denotes the Levenshtein distance. When the length of either Di or
Dj is 0, we assign ρ
Given the three matrices (Ms, Md, and Mc) and the dissimilarity
matrix ρd, the combined edge weights are obtained using a linear
combination of elements in matrices as follows. We first compute a
penalty matrix N that computes the inverse distance between the
ordered set of functions. Each element of N is given by
(cid:40) 1
|i−j |
1
N ij =
if i (cid:44) j
otherwise
This penalty encourages the formation of components consisting
of functions that are sequentially connected. Finally, the final edge
weight matrix of the decomposition graph is given by
W = N ◦ (αMs + βMc + γ(ρd ◦ Md))
where α, β and γ are scalar hyperparameters, and operator ◦ de-
notes element-wise multiplication or Hadamard product. We empir-
ically determine the value of each hyperparameter through cross-
validation (see Section 3.1).
2.3 Partitioning
Our inductive assumption is that components are formed from dis-
joint sets of functions that primarily interact with other functions
within the component, while interacting less with functions in other
components. Since the number of components (or communities)
in a given executable is unknown, we use Newman’s generalized
community detection algorithm [22], which does not require prior
knowledge of the number of existing components (or communities).