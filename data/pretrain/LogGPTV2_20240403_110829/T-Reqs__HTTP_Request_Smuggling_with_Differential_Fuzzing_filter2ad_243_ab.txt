(3) The exitpoint receives the same request, correctly parses
Transfer-Encoding: ;chunked thanks to its lenient parser ig-
noring errors, and processes the body in chunks. Consequently,
the exitpoint treats lines 6-7 as the terminating empty chunk, and
ignores lines 8-9.
(4) The unprocessed data shown on lines 8-9 remain in the re-
quest buffer of the exitpoint. When eventually another request
arrives through the same connection (Listing 4), it is appended to
this unprocessed data, making up a brand new request (Listing 5).
This new request is only seen and processed by the exitpoint; the
attacker has successfully smuggled it through the entrypoint.
In this example, assuming that the entrypoint is a web cache
and the exitpoint a web application server, the attacker uses HRS
to launch a cache poisoning-based denial-of-service attack. Specifi-
cally, the web cache expects a JavaScript file in response (see List-
ing 4), but instead receives an image from the application (see List-
ing 5) and erroneously caches that, likely breaking the application
until the cache expires. This is but one example, and researchers
have shown that HRS can be utilized for general classes of attacks
such as cache poisoning, cache deception, session hijacking, circum-
vention of security controls, and response queue poisoning, as well
as abusing application specific design flaws [6, 15, 19, 23, 24, 35].
2.3 Differential Fuzzing
Fuzzing is a well-established software testing approach with many
applications in systems security [14, 38]. Of particular interest for
our purposes is differential fuzzing, based on the idea of differen-
tial testing [27], where the focus is to identify differing behavior
between applications when given the same input. To name recent
examples, this method was used to detect side-channel attacks [32],
to expose vulnerabilities in parsers and applications [33], and to
find RFC violations in TLS libraries [37].
To apply this technique to the HTTP protocol, we construct our
fuzzer using a custom context-free grammar (CFG). Context-free
grammars are sets of rules that allow for a formal definition of a
structure, e.g., an HTTP request, and values that correspond to
that structure. From this grammar, we are able to generate valid
inputs to our system, and make our fuzzing mutations based off of
them. An example CFG that produces an HTTP request is shown in
Listing 6. Grammar-based fuzzers have also been previously used
for software bug hunting (e.g., [1]).
A CFG has four components: a start symbol, non-terminal sym-
bols, terminal symbols, and production rules. The start symbol is
where the expansion of a CFG starts from. In Listing 6, the start
symbol is denoted by . Symbols surrounded by <> are non-
terminals, meaning they are expanded before the input is fully
generated. For example,  is expanded to a sequence of
other non-terminal symbols, whereas,  can be expanded
into multiple terminal strings. Finally, production rules define how
symbols are expanded. Each line in Listing 6 is a production rule.
When this CFG is fully expanded, one of the possible results is the
request shown in Listing 1.
2.4 Other Related Work
An emerging line of research is the application of HRS to higher
HTTP protocol versions; in particular, Emil Lerner and James Kettle
independently presented attacks on HTTP/2 [18, 22]. These utilize
the same techniques as before, but exploit flaws in the protocol
downgrade mechanisms when an entrypoint converts HTTP/2 to
HTTP/1.1 before forwarding requests to the exitpoint. Our work
does not explore this area.
Beyond the presentations, proof-of-concept exploits, and white
papers we discussed so far, there is no academic literature on HRS as
Session 6B: Web Vulnerabilities CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1807processing behavior of each individual server, and combine the
results to identify servers that process the same request differently.
At this stage, we experiment with each server in isolation to
analyze their individual behavior. Each server runs in a reverse-
proxy mode, where they receive requests and forward them on
to our feedback server. The feedback server gleans information
about the processing behavior of the tested server by analyzing
the forwarded request. This information is stored in a database for
later analysis. We specifically look for mismatches between parsed
message body lengths, and label those as discrepancies.
To explore (Q3), while we verify our findings in Stage 3 of the
experiment, we analyze the conditions affecting exploitability. We
document the novel and successful exploit mechanisms we identify,
and also the failures that hinder attacks in practice.
(Q4) What technology stacks are at risk? HRS is a system
interaction problem involving two HTTP processors, which may
not be flawed when operating in isolation; but stacked together they
Figure 1 depicts this whole process, where the top row is internal
to T-Reqs, and the bottom row is the rest of the experiment infras-
tructure. Note that, in order to avoid adding a confounding layer of
parsing in our own tools, we use low-level network programming.
Stage 2. We then reduce our set of discrepancies found in Stage
1 based on rules and heuristics detailed in Section 5. Essentially,
we associate mutation sets with the server pairs they cause a dis-
crepancy for, minimize them down to a representative group, and
finally, manually classify these groups based on their mutation pat-
terns. We stress that this manual classification is not mandatory;
we merely include this step to simplify the presentation for our
readers by attaching intuitive labels to similar discrepancy types.
Stage 3. Finally, we verify the exploitability of the results from
Stage 2. To achieve this, we layer and deploy suspected vulnerable
HTTP server pairs behind each other. We use a testing method
inspired by prior work to check whether a given mutated request
can really be used for HRS. We present the details of this method
in Section 5.3.
(Q2) What parts of a request can induce processing dis-
crepancies? Previous work has explored the parsing discrepan-
cies involving Content-Length and Transfer-Encoding headers.
Whether the remaining request components can be abused to simi-
lar effect remains an open question.
We address (Q2) by considerably expanding that scope. Not only
do we allow T-Reqs to mutate additional headers, but we also inves-
tigate whether abusing the request line and the message body can
also induce discrepancies, opening up novel attack vectors. We run
three separate experiments, one for each HTTP request component
listed above, each following the same stages we designed for ad-
dressing (Q1). In each experiment, we only allow T-Reqs to mutate
the part under focus, while keeping the other two request com-
ponents unmutated. This makes it feasible to pinpoint and reason
about the exploitable discrepancies in isolation.
(Q3) What escalates a processing discrepancy to HRS? The
presence of a discrepancy is a red flag, but not all discrepancies
necessarily lead to HRS. In particular, while exploits involving
Content-Length and Transfer-Encoding headers are intuitive
(i.e., they directly affect the body parsing behavior, which is a pre-
requisite for HRS), why the discrepancies in other request compo-
nents may lead to an attack is not obvious.
Figure 1: Inputs are generated from a grammar, mutated, and sent
to the tested server. The feedback server collects feedback from the
requests forwarded by the tested server and stores it for analysis.
of this writing. However, while this paper is the first work exploring
HRS within a scientific framework, there exists studies that propose
other ways to abuse HTTP processing discrepancies.
Omer Gil presented a novel cache poisoning attack called Web
Cache Deception (WCD), which exploits an object cacheability dis-
agreement between a web server and a cache, resulting in data
leaks in public caches [12, 13]. Mirheidari et al. generalized WCD
as a path confusion problem caused by a discrepancy in the in-
terpretation of a requested URL [28], and conducted a large-scale
measurement to identify vulnerable sites in the wild [29].
Nguyen et al. presented a different take on cache poisoning,
crafting HTTP requests that are considered valid by a web cache
while triggering an error at the origin server [31]. As a result,
the error response is erroneously cached, resulting in a denial-of-
service attack. Similarly, Chen et al. exploited HTTP servers that
respond differently to ambiguities in the Host header values, which
once again leads to cache poisoning [4].
3 RESEARCH QUESTIONS & METHOD
Previous work on HRS presents valuable concepts behind the at-
tack, but does not explore the issue in depth or breadth, instead
demonstrating impact through specific case studies. Our work is
motivated by this knowledge gap. Below, we detail our guiding
research questions, and explain our methods to answer them.
(Q1) Can we systematically test for HRS at scale?
(Q2) What parts of a request can induce processing discrepancies?
(Q3) What escalates a processing discrepancy to HRS?
(Q4) What technology stacks are at risk?
(Q1) Can we systematically test for HRS at scale? Previous
work relies on a combination of manual testing and basic tools
designed to target specific controlled environments (e.g., [7, 36]) for
attack discovery. In contrast, we aim to design a fully-automated,
generalizable, and extendable methodology that can explore HRS
at scale and discover previously unknown venues for exploitation.
To address (Q1), we design a multi-stage experiment powered by
a novel CFG-based differential fuzzer, T-Reqs. This is an automated
process, eliminating the manual labor and narrow scope hindering
previous work. This methodology and infrastructure to explore
HRS systematically equips us to answer the remaining research
questions. Below, we briefly describe the 3 stages of our experiment.
Stage 1. We first point T-Reqs to a set of popular HTTP servers
for testing, and send identical requests to each. We record the
InputsMutated Inputsgenerating requestsmutating requestsFeedback DatabaseInput Grammarsending requestsstoring requestsHTTP ServerFeedback Serverforwarding parsed requestsSession 6B: Web Vulnerabilities CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1808lead to a vulnerability. Previous work on HRS has made no attempt
to measure what server combinations are prone to smuggling.
While we cannot feasibly test all technology combinations in
existence, we make the first systematic attempt to answer (Q4)
by designing an experiment that measures and documents the
hazardous interactions between 10 HTTP processors.
Specifically, we pick popular web server, proxy, and CDN tech-
nologies in use today that make up a large portion of the Internet:
Apache, NGINX, Tomcat, Apache Traffic Server (ATS), HAProxy,
Squid, Varnish, Akamai, Cloudflare, and CloudFront. For specific
versions, please see Appendix A. To test CDN vendors, we subscribe
to their free or trial tier services. We configure each technology to
run as a reverse-proxy fronting our feedback server (except Tomcat,
which has no reverse-proxy mode, so we run a Java servlet on it that
echoes back the received requests). We use default configurations,
save for turning off buffering in NGINX to speed up testing, and
disabling caching for clean experiment runs.
4 T-REQS SYSTEM DESIGN
We now detail the design of T-Reqs, our grammar-based differential
HTTP fuzzer. T-Reqs is capable of generating HTTP requests as
inputs from a grammar, manipulating them with string and tree
mutations, and sending them to multiple HTTP servers in parallel
for testing.
4.1 Input Generation
To ensure that we test all relevant components of an HTTP request,
and their applicable values, T-Reqs uses a context-free grammar
(CFG) to generate inputs. Each generated input is a valid HTTP
request constructed by following one of the paths provided by the
CFG, chosen randomly to ensure uniform testing. We record each
random seed as the input ID to aid in reproducibility.
When building our input from the included grammar, we adopt
a tree structure. The start symbol becomes the root, and each non-
terminal is a non-terminated node in the tree. The leaves of the
tree, once fully expanded, are made up of the terminal symbols (i.e.,
string literals), and when combined form our HTTP request. We
present the specific CFGs used for our experiments in Section 5.
4.2 Mutating Inputs
In order to exercise the parsers of, and consequently trigger process-
ing discrepancies between, different HTTP servers, T-Reqs makes
mutations on the valid requests generated in the previous step.
Symbols, each corresponding to an HTTP element, can be marked
in one of two ways: string mutable or tree mutable. If a symbol
is not marked, it is assumed to be immutable. While string mu-
tations (e.g., character insertion, deletion) make small changes to
parts of an input, tree mutations lead to structural changes (e.g., re-
peated method specification, missing protocol version). This allows
T-Reqs to test both trivial and major changes to an input. Mutation
operations are formally defined in Appendix B.
In each iteration, T-Reqs randomly applies up to 2 mutations on
each input. This upper bound makes the impact analysis of specific
mutations feasible, as well as helping us avoid changing requests
to the degree that they are unrecognizable by the servers.
1 PORT //search HTTP/1.1
2 Host: example.com
3 Content-Length: 13
4
5 query=bananas
1 HTTP /search /search HTTP/1.1
2 Host: example.com
3 Content-Length: 13
4
5 query=bananas
Listing 7: String mutations.
Listing 8: Tree mutations.
4.3 String Mutations
If a symbol is string mutable, then a random character can be
deleted, replaced, or inserted at a random position inside that sym-
bol. To add or replace characters, an external character pool can be
defined. T-Reqs uses the ASCII character set (codes 0-127) as the
character pool suitable for HTTP requests.
Listing 7 shows an example. The last character in the protocol
version (1) is deleted, a letter in the method name (S) is replaced
with R, and a forward slash is inserted at the start of the URI.
4.4 Tree mutations
If a symbol is tree mutable, then a random symbol can be deleted,
replaced, or inserted at a random position. To add or replace sym-
bols, an external pool of elements can be defined. T-Reqs uses the
list of all symbols marked mutable as the external symbol pool.
For example, the request line is represented by 
and has several sub-elements including , , ,
and . In Listing 8, it is assumed that 
is tree mutable, and the following tree mutations are applied: 1)
 is replaced by , 2) an extra  is inserted after
the current URI, and 3) the existing  is deleted.
5 EXPERIMENT DETAILS AND RESULTS
In this section, we provide details and discuss results from the
experiments listed in Section 3. We first run three separate experi-
ments on each part of the HTTP request utilizing T-Reqs to expose
discrepancies in message body parsing behavior. Next, we reduce,
minimize, and categorize the sets of mutations that cause these dis-
crepancies to understand what leads servers to disagree on message
boundaries. We then verify the HRS potential of these categories,
and explore reasons why they succeed or fail.
5.1 Stage 1 - Finding Discrepancies
For this stage, we run three separate experiments on each part of the
HTTP request: the request line, request headers, and request body.
Table 2 shows the duration of each experiment, and the number
of requests generated and tested. We found that mutations in the
request line experiment caused more errors (e.g., 400 Bad Request),
even when bounding the total number of mutations to two. We see
more mutations an hour in the request line experiment because
these errors are significantly faster for HTTP servers to handle
than valid requests.
To make T-Reqs more efficient, we supply different grammars
and mutable symbols for each experiment as detailed below.
5.1.1 Request Line Experiment Details. Listing 9 shows the gram-
mar for the request line experiment. We test the standard HTTP
methods as defined by their RFCs [9, 11]. Note that we do not
Session 6B: Web Vulnerabilities CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1809Table 2: General information about experiments.
Name
Request line
Request headers
Request body
Duration
70 hours
94 hours
72 hours
# Inputs
8,857K
3,096K
2,051K
Table 3: Mutability of request line symbols.