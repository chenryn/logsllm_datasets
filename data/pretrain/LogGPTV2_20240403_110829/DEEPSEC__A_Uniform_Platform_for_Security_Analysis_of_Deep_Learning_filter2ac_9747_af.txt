ILLC
T-MI-FGSM
JSMA
BLB
CW2
EAD
κ = 0
κ = 20
EN
L1
Average of UAs
Totally Average
# of
AEs
897
898
837
1000
1000
1000
853
1000
1000
942.8
134
315
1000
1000
997
1000
1000
1000
1000
1000
844.6
891.1
Original Model
ACAC
MR
0.743
0.873
0.846
1.000
1.000
1.000
0.723
0.516
0.750
0.828
0.768
0.876
1.000
1.000
0.508
0.500
0.393
1.000
0.433
0.377
0.685
0.753
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
100.0%
Model 1
Model 2
Model 3
MR
88.2%
86.3%
89.1%
96.2%
98.2%
97.0%
87.0%
13.1%
22.7%
74.7%
3.7%
18.1%
25.3%
42.7%
7.7%
1.8%
1.8%
6.2%
1.9%
1.9%
9.7%
41.5%
ACAC
0.922
0.878
0.863
0.940
0.933
0.934
0.868
0.769
0.788
0.876
0.871
0.826
0.875
0.893
0.833
0.778
0.751
0.821
0.768
0.781
0.811
0.847
MR
88.4%
91.0%
88.8%
96.0%
99.4%
97.9%
88.5%
10.7%
20.9%
74.3%
14.2%
24.1%
27.0%
43.0%
9.0%
1.6%
1.5%
7.8%
2.1%
2.1%
10.6%
42.8%
ACAC
0.841
0.804
0.830
0.949
0.952
0.926
0.744
0.788
0.805
0.848
0.770
0.828
0.863
0.916
0.769
0.783
0.815
0.860
0.764
0.749
0.809
0.829
MR
92.4%
93.3%
90.0%
93.5%
98.8%
97.0%
90.4%
11.5%
19.2%
74.9%
17.9%
35.2%
23.0%
34.0%
7.6%
1.5%
1.4%
5.6%
1.6%
1.4%
9.5%
42.9%
ACAC
0.674
0.731
0.699
0.893
0.914
0.841
0.682
0.705
0.721
0.762
0.632
0.774
0.823
0.870
0.755
0.737
0.759
0.722
0.741
0.781
0.760
0.761
Average
MR of 3
Models
89.7%
90.2%
89.3%
95.2%
98.8%
97.3%
88.6%
11.8%
20.9%
74.6%
11.9%
25.8%
25.1%
39.9%
8.1%
1.6%
1.6%
6.5%
1.9%
1.8%
10.0%
42.4%
Average
ACAC of
3 Models
0.812
0.804
0.797
0.927
0.933
0.900
0.764
0.754
0.771
0.829
0.758
0.809
0.854
0.893
0.786
0.766
0.775
0.801
0.758
0.770
0.794
0.812
its resistance against attacks [31], [54], while others hold
the negative opinion [55]. To ﬁgure out the effectiveness of
different ensemble defenses against attacks, in this case study,
we evaluate the classiﬁcation performance (i.e., accuracy and
conﬁdence) of three different ensemble methods.
1) Experiment Setup: We use the same benchmark datasets
and corresponding original models as used in Section IV-A.
In addition, we use three ensemble methods as follows.
Completely-random Ensemble: randomly select 3 de-
fenses from all 9 complete defenses.3
Interclass-random Ensemble: randomly select 1 defense
separately from 3 categories of complete defenses and thus a
total of 3 defenses are selected.
Best-defense Ensemble: select the best three defenses that
outperform others in defending against various adversarial
attacks. As analyzed in Section IV-C1, PAT, TE and NAT are
the best three defenses for MINST. For CIFAR-10, NAT, EIT
and EAT are the best on average.
The experimental methodology proceeds as follows. First,
we prepare successful AEs that are generated by each attack
in Section IV-A. For each ensemble method, we get 3 selected
defense-enhanced models from Section IV-B. Finally, for each
testing AE, we predict it by letting each defense-enhanced
model votes for a label, i.e., yen = arg max
i=1 Pi(x)k.
Additionally, to avoid accidental phenomena in random-based
ensemble methods, we independently repeat
two
ensemble methods 3 times and calculate the average.
the ﬁrst
(cid:2)3
k
2) Results: Table IX shows the results of CIFAR-10, and
similar results on MNIST are reported in Appendix XI.
Generally, different ensemble methods show different defen-
sive performance. Among the three ensembles, the completely-
random ensemble performs the worst while the best-defense
ensemble performs the best w.r.t accuracy and conﬁdence. The
reason is that the performance of ensemble mainly depends
3We exclude RC in our ensemble methods as it does not provide conﬁdence
information for the testing examples.
PERFORMANCE OF DIFFERENT ENSEMBLE METHODS ON CIFAR-10
TABLE IX
t
e
s
a
t
a
D
UA/
TA
UAs
0
1
-
R
A
F
I
C
TAs
Attack
Objec-
tive
L∞
 = 0.1
FGSM
L2
Average of UAs
Attacks
BIM
PGD
R+FGSM
UAP
DF
OM
# of
AEs
 = 0.1 897
 = 0.2 898
837
1000
1000
U-MI-FGSM 1000
853
1000
1000
943
134
315
1000
T-MI-FGSM 1000
997
1000
κ = 0 1000
κ = 20 1000
EN 1000
1000
L1
Average of TAs
845
Average
891
R+LLC
ILLC
JSMA
BLB
CW2
EAD
LLC
L0
L2
L∞
 = 0.1
Ensemble Methods
random
Completely-
Orig-
Interclass-
random Best-defense
inal
model
Acc. Conf. Acc. Conf. Acc. Conf.
0% 35% 0.56 57% 0.63 73% 0.80
0% 26% 0.56 28% 0.63 42% 0.72
0% 40% 0.57 80% 0.67 87% 0.87
0% 29% 0.58 78% 0.68 88% 0.88
0% 24% 0.62 73% 0.66 85% 0.86
0% 24% 0.58 62% 0.64 78% 0.83
0% 41% 0.56 76% 0.66 83% 0.85
0% 93% 0.85 91% 0.83 91% 0.91
0% 88% 0.79 90% 0.84 92% 0.90
0% 44% 0.63 71% 0.70 80% 0.85
0% 30% 0.54 66% 0.63 78% 0.83
0% 39% 0.55 86% 0.68 91% 0.89
0% 63% 0.61 87% 0.76 91% 0.90
0% 34% 0.58 71% 0.66 84% 0.85
0% 6% 0.70 77% 0.75 76% 0.85
0% 93% 0.85 92% 0.85 91% 0.91
0% 93% 0.85 92% 0.86 92% 0.91
0% 87% 0.77 91% 0.85 91% 0.91
0% 93% 0.84 92% 0.85 92% 0.91
0% 93% 0.8
92% 0.85 91% 0.91
0% 69% 0.71 84% 0.77 88% 0.89
0% 57% 0.67 78% 0.74 84% 0.87
on the individual defense, and thus the best-defense ensemble
outperforms others.
We observe that ensemble of different defenses does not per-
form better than each individual defense on average. Accord-
ing to the results, the completely-random ensemble averagely