been performed, release all locks and commit T .  
Only phase I11 is executed serially for all incoming trans- 
actions.  The execution  of  write  operations (phase  IV)  is 
only  serial  in  the case of conflicts.  Non-conflicting  opera- 
tions  can be executed  concurrently and different  sites may 
even commit transactions  in different orders as long as they 
do not  conflict.  This  is  important since processing  mes- 
sages serially  as assumed  for most  applications deployed 
over group communication (including, e.g., [ 2 ] )  would  re- 
sult  in  significantly  lower  throughput rates.  Our protocol 
uses  the sequence number of  the  transaction  message mT 
as the global identifier gid(T) of T .  This has important ad- 
vantages.  First, gid(T) can be  determined independently 
at each site. Second, it represents  the serialization  order of 
transactions. Last, by using the gid  for tagging objects, we 
have the guarantee that all sites have the same version num- 
ber for an  object at a given logical time point.  Notice  that 
version  numbers are necessary  to detect whether read  op- 
erations have  read  stale data.  The protocol  is  serializable 
since read/write conflicts are handled  by  aborting the read- 
ing transaction, write/write conflicts are ordered in the same 
way at all sites according to the total order of the multicasts, 
and writehead conflicts are handled by traditional  2-phase- 
locking (the read waits until the write releases the lock). 
2.3. Failures 
In [ 151, we have shown that the replica control protocols 
described in the previous section can easily  be extended to 
cope with  site and communication failures by  (i)  sending 
messages using uniform reliable multicast as defined in Sec- 
tion 2. I  and by  (ii) restricting transaction  processing  to the 
sites of the primary  view.  If a site leaves the primary  view 
and installs  a non-primary  view, it simply stops processing 
transactions and ignores all incoming messages.  Members 
of  a consecutive primary  view  simply continue as before. 
They  do not  need  to  perform  any  further coordination to 
handle the failure.  We  have shown that  (i) and (ii)  guaran- 
tee transaction atomicity. That is, whenever a site commits a 
transaction T ,  T will be committed at all sites that are mem- 
ber of a primary view for a sufficiently long time. Moreover, 
no other site aborts T  (a site might fail before  committing 
T ,  but then, T was still active or had not started executing at 
119 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:01:57 UTC from IEEE Xplore.  Restrictions apply. 
the time of the failure).  The corresponding behavior holds 
in the case a site aborts a transaction T .  
With weaker forms of message delivery (e.g., reliable de- 
livery), transaction  atomicity can  be  violated:  a  failed site 
5’ might have committed a transaction T shortly before the 
failure even though  m~ was  not  delivered  at the sites that 
continue  in  a primary  view  [ 1.51.  Upon recovery  of  S ,  T 
must be reconciled (see, e.g., [ 131). 
3. Reconfiguration in Replicated Databases 
Before  transaction  processing  can  begin,  the  system 
“bootstraps” as follows. An  initial set of sites that defines a 
majority and that has a copy of the database start by joining 
the  group.  Transaction  processing  begins  as  soon as they 
have installed a view that includes all of them, defining the 
first  primary  view.  At  this point other  sites may  start  and 
join the group. These “new” sites may or may not have the 
initial copy of the database. A site that crashes and recovers 
will perform some clean-up on its copy of the database (see 
below) and then will join the group again. 
In  the  following,  we  shall  describe  the  actions  neces- 
sary to enable joining sites to resume transaction processing 
when  they  installs a primary  view.  S, depicts a site that is 
recovering after a failure (S, had crashed or a network par- 
tition had occurred), s, depicts a new site, Sj depicts either 
type  of joining site.  Furthermore,  S, denotes a  peer  site 
transferring the current database state to Sj.  Several tasks 
and issues for online reconfiguration can be identified: 
Single Site Recovery As in centralized systems, S, first 
needs to bring  its own database  into a consistent state. 
This requires the redoing of updates of committed trans- 
actions that were not yet reflected in the database when 
the failure occurred and the undoing of updates of trans- 
actions  that  were  aborted or  still  active  at  the  time  of 
the  failure.  For  this, each  site usually  maintains  a log 
during  normal  processing  such that for each write  op- 
eration on object X  the before- and after-images of X 
are appended to the log.  Since single site recovery  is a 
standard database technology  performed before S,  re- 
joins the group, we refer to [9] for details. 
Data Transfer A peer site S, of the primary view must 
provide Sj  with  the current state of  the database.  The 
simplest  solution is  to  send an  entire copy  (this is the 
only  solution in  the case of a new site).  Alternatively, 
S, only sends the data that was updated after S,  failed. 
Determination of a Synchronization Point: Care has 
to be taken in the case transaction processing is not sus- 
pended during the data transfer. We must guarantee that 
for each transaction in the system, either the updates of 
the  transaction  are  already  reflected  in  the  data trans- 
fered to Sj or Sj is able to process the transaction after 
the  transfer has  successfully  terminated.  Determining 
the synchronization point depends strongly on the data 
transfer technique that is employed. 
In the following, we shall assume that a primary view al- 
ways exists. In the case the primary view disappears (i.e., a 
total failure), transaction processing may resume only after 
execution of a creation protocol for determining the set of 
all transactions committed in  the system  and for  applying 
the  changes of  such  transactions at  all  participating  sites. 
In  the context of the replica control protocols presented in 
section  2.2, the  creation  protocol,  in  general,  requires  the 
involvement of all sites. This is ultimately due to the asyn- 
chrony  between  the  database  system  and  the  group com- 
munication system:  a site actually commits a transaction T 
some time after the delivery of the transaction message m ~ ;  
during  this  time  the  site  could  install  a  new  view  and/or 
fail.  For example, suppose there  are three  sites SI, S2, S3 
all members of  the primary  view  V .  SI sends the transac- 
tion message mT  that is delivered in V at all sites. It might 
happen that SI commits T and then fails, whereas both S2 
and 5’3  first install a new primary view W excluding 5’1, and 
then fail before committing T .  In that case, only the log of 
S1 will contain the commit record of T .  Therefore it is nei- 
ther enough that  the creation  protocol  involves a majority 
of sites nor that it involves all sites of the last primary view 
W .  Instead,  the  logs of  all  sites  in  the system have to be 
considered.  We omit the details of the creation protocol  (it 
merely requires comparing the highest transaction identifier 
g i d s  of transactions applied by each site S). Note that if Sa 
and S3 had  not failed they would  have committed T  guar- 
anteeing that the members of the primary  view commit all 
transactions that are committed by any site in the system. 
4. A Suite of Reconfiguration Algorithms 
Efficiency of a given reconfiguration strategy depends on 
a number of parameters:  the size of the database, the trans- 
action throughput, the read/write ratio within the workload, 
the  system  utilization  and  so  on.  As  a  consequence,  one 
should be able to adapt the strategy to the specific scenario, 
in particular, with respect to the data transfer task. In the fol- 
lowing we will discuss stepwise redefined transfer strategies 
aiming to solve three issues.  First, the data transfer should 
interfere as little as possible  with ongoing transaction pro- 
cessing.  Second, it  should  require  as little  CPU and  net- 
work overhead’as possible.  And third, the solutions should 
be easy to implement with existing database technology. 
4.1  Data Transfer within the Group Communica- 
tion System 
Some group communication systems are able to perform 
data transfer during the view change (e.g. [ 10, 3 ,  221). The 
essential  aspects  of this feature are as follows.  Let V and 
120 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:01:57 UTC from IEEE Xplore.  Restrictions apply. 
W be two consecutive primary views and let W be the first 
view including the joining site Sj. The application  defines 
the state that has to be transferred to Sj (by providing mar- 
shalling/unmarshalling  routines that will be invoked by the 
system when needed). During the view change protocol, the 
group communication system fetches the state from the ap- 
plication layer of some member of V, then incorporates this 
state at the  application  of  Sj  and  finally  delivers  the  view 
change event  v c h g ( W ) .  During the  view change protocol 
the activity  of the application  is suspended and the system 
does not deliver application-originated  messages.  As a re- 
sult, all sites that install W do so with the same state. 
Such an  approach has  important  disadvantages.  First, 
the group communication system can  only  send the entire 
database,  because  the  system  does  not  know  which  data 
has actually  been changed since Sj’s failure.  This may  be 
unacceptable if  Sj  is  recovering from a  short down-time. 
Second, the database would have  to remain  unchanged for 
the entire data transfer.  Considering the  enormous size of 
current databases, this can clearly  violate the common 24- 
hour/7-day availability requirement. Last, group communi- 
cation  systems usually  assume that they  have control  over 
the  common  group  state.  The database, however,  is  con- 
trolled  by  the  database system, and  if  the  group commu- 
nication  wants  to  access the  data, it  has  to  do so through 
the traditional  interface,  i.e., it has  to  submit transactions. 
While this  might  be  feasible,  it  will  be  highly  inefficient. 
Similar remarks apply  to  approaches in  which  the  system 
relays to Sj  all messages delivered during Sj ’s down-time, 
rather  than  the application-defined  state (e.g., [2]). In  this 
case Sj might have to apply thousands  of transactions  and 
not be able to catch up with the rest of the system. 
4.2. Data Transfer within the Database System 
As  a  result  of  the  previous  considerations, we  believe 
that  the data transfer  should be performed  by  the database 
system  using  the  appropriate  database  techniques.  The 
group communication system should  only provide the  ap- 
propriate semantics to coordinate the data transfer. 
We  shall consider the following framework for all alter- 
natives  depicted in  the  following  sections:  Let  W  be  the 
primary view installed when Sj joins the group. During the 
view change no database related state is transferred.  Upon 
the  delivery  of  v c h g ( W ) ,  sites  that  were  members of  the 
previous  primary  view  V  elect  one of  them  to act as peer 
site S, for S,.  Election  can be performed  without message 
exchange, based  on the compositions of V and  W .  Trans- 
action  processing  continues unhindered  at  all  sites  in  W ,  
except for S,  and Sj. S, transfers the data to Sj and Sj in- 
stalls it. The data transfer need not occur through the group 
communication platform  but could, e.g., be  performed  via 
TCP between  S, and  Sj. For all but the last of  the follow- 
ing data transfer strategies, the synchronization point in re- 
gard to concurrent transaction processing will be as follows: 
S,  transfers  a  database  state  including the  updates  of  all 
transactions  which  were delivered before the  view change 
vchg(W). However, the data does not include the updates 
of  transactions  delivered after  vchg(W).  Instead, Sj  en- 
queues all  transaction  messages  delivered  after  vchg(W) 
and processes them once the data transfer is completed. Af- 
ter that, Sj can start executing its own transactions. We first 
assume that no further view changes occur during reconfig- 
uration. We relax this requirement in Section 5. 
4.3. Transferring the Entire Database 
A simple option for data transfer is to transfer the entire 
database.  This is mandatory for new sites  but also attrac- 
tive for recovering sites if the database is small or if most of 
the data has been  updated  since S, failed.  In order to syn- 
chronize with concurrent transactions, S, transfers the data 
within the boundaries of a “data transfer transaction” DT: 
I.  Lock Phase: Upon delivery of vchg(w), create transaction 
D T   and  request in an atomic step  read locks for all ob- 
jects in the database. Order these read locks directly after 
all write locks associated with transaction messages deliv- 
ered before vchg(w). Successive transactions requesting 
a write lock for an object locked by D T  must wait until DT 
releases the lock. 
11.  Data  Transfer Phase:  Whenever  a  lock on  object X 
is 
granted, read X  and transfer it to S,  (which incorporates 
X  into its database and sends an acknowledgment back). 
As soon as the acknowledgment is received, release the 
lock and normal processing can continue on X .  Of course, 
both S,  and S,  can pack multiple objects and acknowledg- 
ments, respectively, in a single message. 
Notice, that read operations can continue unhindered on 
S,.  Write operations are only  delayed on  objects  that  are 
not  yet  transferred.  Also  note  that  in  order to  reduce the 
number of locks,  DT  can request course granularity  locks 
(e.g.,  on  relations)  instead  of fine granularity  locks  on  in- 
dividual  objects.  The normal  transactions  can still request 
locks on  a per  object basis.  The most  important  aspect  in 
here is that DT’s read locks must cover the entire database. 
4.4. Checking Version Numbers 
While transferring  the  entire database is  simple to  im- 
plement, it  will  often  be  highly  inefficient,  e.g.,  when  S, 
has  been  down  for a very  short time  or when  big  parts  of 
the database are seldomly updated. In such cases it may be 
more efficient to determine which  part of the  database ac- 
tually  needs to be transferred, Le, which  objects have been 
changed since Sr’s failure, and to transfer only this part. 
To do so,  S,  must  know  up  to  when  S,  has executed 
transactions.  For this, S ,  informs S,  about its cover trans- 
121 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:01:57 UTC from IEEE Xplore.  Restrictions apply. 
action.  The cover  transaction  for  a site  S  is  the  transac- 
tion  with  the  highest global  identifier gidmaxs  such  that 
S  has successfully  terminated  all transactions  with  gid  5 
gidmaxs. S, can easily determine gidmaxsv by scanning 
its single site recovery log (details are omitted for space rea- 
sons).  Now  recall  that:  (i) all  sites  have  the  same global 
identifiers for  transactions  (namely the  sequence numbers 
of  the  corresponding transaction  messages),  and  (ii)  con- 
flicting transactions  are  serialized  according  to  their  gids 
at all sites.  Accordingly,  if  S,  sends the objects that were 
updated by committed transactions with gid  > gidmaxs-, 
then S,  will receive all changed data. 
Since the  replica  control  protocol  of  Section  2.2  tags 
each object with the transaction that was the last one to up- 