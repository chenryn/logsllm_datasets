Service Delay and Network Stretch This set of experi-
ments examine the quality of the tree produced by the vari-
ous algorithms in terms of end-to-end service delay and net-
work stretch. The average service delay measures the aver-
age of all nodes’ end-to-end service delays along the over-
lay paths. The average stretch is the average of all nodes’
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:30:01 UTC from IEEE Xplore.  Restrictions apply. 
Figure 4: Avg. number of disruptions per
node.
Figure 5: CDF of avg. number of disrup-
tions.
Figure 6: Accumulative number of disrup-
tions of a typical member over time.
stretches, which is deﬁned as the ratio of one nodes’ ser-
vice delay to the delay along the direct unicast path in the
underlying network [4] [1].
Fig. 7 shows that the ROST algorithm achieves the best
result in terms of both metrics among the three distributed
algorithms (the other two are the minimum-depth algorithm
and the longest-ﬁrst algorithm). This reﬂects how band-
width ordering in ROST beneﬁts the tree depth.
Compared with the relaxed BO tree, the ROST algorithm
has a small increase in the two deﬁned metrics of 10-15%.
This is because the ROST algorithm optimizes the layout
in a more conﬁned space (only along the child-parent paths
regardless of the bandwidth order between siblings), and
hence yields a more sub-optimal bandwidth layout. How-
ever it should be pointed out that the best performance of
the relaxed BO algorithm relies on a centralized controller
owning the global topological information, which makes it
impractical for large-scale networked systems.
Fig. 8 shows the average stretch of nodes under vari-
ous network sizes, which agree with the observations from
Fig. 7. Fig. 9 shows the service delay of a typical member
with the same property as assumed in the experiments with
Fig. 6. It can be seen that under the ROST and relaxed TO
algorithms, the examined member’s delay becomes smaller
as time progresses, implying a higher and higher position in
the multicast tree. In contrast, the delay ﬂuctuates with no
convergence with the other three algorithms which do not
consider time ordering.
Comparison of Protocol Cost Both bandwidth ordering
and time ordering require reconnections between nodes to
optimize the structure of the tree, thus introducing a pro-
tocol overhead. This overhead is measured in the average
number of reconnections brought by the optimizing mech-
anism on a single node during its lifetime. Fig. 10 com-
pares the protocol overheads of the ﬁve algorithms. Note
that the minimum-depth algorithm and the longest-ﬁrst al-
gorithm do not impose any protocol overheads at all.
The results show that the ROST algorithm performs best
among the three algorithms that do incur protocol over-
heads. Besides which, the the ROST algorithm requires
far less than one reconnection for a single node during its
lifetime. This indicates that ROST is very efﬁcient in gen-
eral. Recall that the average node lifetime is 1809 seconds
and the default switching interval is 360 seconds. These
translate to 5 switches per node, which is clearly larger than
the measured overhead. The reason behind this is that a
switching interval does not necessarily correspond to an ac-
tual switching operation; rather, it only provides a possible
opportunity for switching. In an overlay that has evolved
for a long time, many high-bandwidth or long-lived nodes
have already occupied the high positions in the tree, so most
nodes have been left fewer chances to climb up the tree.
Effects of Switching Interval Fig. 11 shows the impact
of various switching intervals on the performance of an
8000-node system. As expected, a smaller interval provides
more adjusting opportunities for the overlay and thus the
streaming reliability is higher. Because of the implicit band-
width ordering, a small interval also leads to a small average
service delay and network stretch. These beneﬁts, however,
come at the expense of an increase of protocol overhead,
as shown in the bottom-right sub-ﬁgure in Fig. 11. Also
note that the protocol overhead is fairly small (0.15 recon-
nections per node) even when the interval takes the smallest
value (i.e., 480 seconds).
Effects of Recovery Group Size This section examines
the effect of different recovery group sizes on the user-
perceived quality of service and the requirement on the user
buffer through packet-level simulation. The data is propa-
gated from the tree root at a constant rate of 10 packets per
second after the network enters a steady state. By default,
each node has a playback buffer size of 5 seconds, or 50
packets, hence every lost packet must be repaired within 5
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:30:01 UTC from IEEE Xplore.  Restrictions apply. 
2000(cid:13)5000(cid:13)8000(cid:13)11000(cid:13)14000(cid:13)0(cid:13)1(cid:13)2(cid:13)3(cid:13)4(cid:13)5(cid:13)6(cid:13)Avg. disruptions per node(cid:13)Avg. Number of nodes in a steady state(cid:13) Minimum-depth(cid:13) Relaxed bandwidth-ordered(cid:13) Longest-first(cid:13) Relaxed time-ordered(cid:13) ROST(cid:13)1(cid:13)2(cid:13)4(cid:13)8(cid:13)16(cid:13)32(cid:13)64(cid:13)128(cid:13)30(cid:13)40(cid:13)50(cid:13)60(cid:13)70(cid:13)80(cid:13)90(cid:13)100(cid:13)Cumulative percentage  of  nodes(cid:13)Number of disruptions(cid:13) Minimum-depth(cid:13) Relaxed bandwidth-ordered(cid:13) Longest-first(cid:13) Relaxed time-ordered(cid:13) ROST(cid:13)-33(cid:13)0(cid:13)33(cid:13)67(cid:13)100(cid:13)133(cid:13)167(cid:13)200(cid:13)233(cid:13)267(cid:13)300(cid:13)0(cid:13)10(cid:13)20(cid:13)30(cid:13)40(cid:13)50(cid:13)60(cid:13)70(cid:13)Number of disruptions(cid:13)Time (minutes)(cid:13) Minimum-depth(cid:13) Relaxed bandwidth-ordered(cid:13) Longest-first(cid:13) Relaxed time-ordered(cid:13) ROST(cid:13)Figure 7: Avg. network delay vs. network
size.
Figure 8: Avg. stretch vs. network size.
Figure 9: Service delay of a typical member
over time.
Figure 10: Comparison of protocol overheads.
Figure 11: Effect of switching interval.
seconds. It is assumed that a member needs 5 seconds to de-
tect a failure of its parent, and another 10 seconds to rejoin
the tree; thus a failure recovery takes 15 seconds in total.
We only consider packet losses incurred by node failures.
A node’s residual bandwidth is uniformly distributed in 0-9
packets/second, and it only uses the residual bandwidth to
help others in error recovery.
A metric called starving time ratio, deﬁned as the ratio of
the total streaming disruption time to the whole view time
since the playback begins, is used to evaluate the quality of
service perceived by a user under the workload assumed in
Section 5. Fig. 12 presents the average starving time ratios
of all multicast members for varying recovery group sizes.
The tree is constructed using the minimum-depth algorithm.
The result shows that, compared with the group size of 1, a
small increase to a group size of 3 can reduce the average
starving time by an order of magnitude (< 0.2% for all net-
work sizes).
Fig. 13 depicts the relationship between the user’s buffer
size and starving time ratio. Clearly, a larger buffer size
can better accommodate streaming dynamics. However, a
large buffer size also means a long startup delay, and hence
worse quality of service in terms of interactivity. Again
we can see that a small increase in the recovery group size
can dramatically reduce the required buffer size. For exam-
ple, for the one-recovery-node case, the buffer size must
be ≥ 27 seconds to make the average starving time ra-
tio ≤ 0.55%, whereas for the two-recovery-node case, the
buffer size needs only to be 5 seconds to meet the same re-
quirement.
Evaluation of ROST+CER In this section, we compare
ROST+CER against a general overlay multicast scheme, in
which the tree is constructed using the minimum-depth al-
gorithm, and the packet losses are recovered from a sin-
gle source. We vary the recovery group size from 1 to 3,
and examine the average starving time ratio under the two
schemes. Fig. 14 gives the results with a 95% conﬁdence
interval.
It can be observed that for each group size, the
use of ROST+CER signiﬁcantly reduces the average starv-
ing time ratio. On average, the ratio is reduced by 8-9 times.
One can also see that, even with a recovery group size of 1,
the ROST+CER scheme performs better than a Minimum-
depth+Single source scheme with two recovery group mem-
bers, which again reﬂects the effectiveness of ROST.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:30:01 UTC from IEEE Xplore.  Restrictions apply. 
2000(cid:13)5000(cid:13)8000(cid:13)11000(cid:13)14000(cid:13)0(cid:13)100(cid:13)200(cid:13)300(cid:13)400(cid:13)500(cid:13)600(cid:13)Avg. service delay (ms)(cid:13)Avg. Number of nodes in a steady state(cid:13) Minimum-depth(cid:13) Relaxed bandwidth-ordered(cid:13) Longest-first(cid:13) Relaxed time-ordered(cid:13) ROST(cid:13)2000(cid:13)5000(cid:13)8000(cid:13)11000(cid:13)14000(cid:13)0(cid:13)2(cid:13)4(cid:13)6(cid:13)8(cid:13)10(cid:13)12(cid:13)Avg. network stretch(cid:13)Avg. Number of nodes in a steady state(cid:13) Minimum-depth(cid:13) Relaxed bandwidth-ordered(cid:13) Longest-first(cid:13) Relaxed time-ordered(cid:13) ROST(cid:13)-33(cid:13)0(cid:13)33(cid:13)67(cid:13)100(cid:13)133(cid:13)167(cid:13)200(cid:13)233(cid:13)267(cid:13)300(cid:13)64(cid:13)128(cid:13)256(cid:13)512(cid:13)1024(cid:13)Service delay (ms)(cid:13)Time (minutes)(cid:13) Minimum-depth  (cid:13) Relaxed bandwidth-ordered(cid:13) Longest-first       (cid:13) Relaxed time-ordered(cid:13) ROST(cid:13)2000(cid:13)5000(cid:13)8000(cid:13)11000(cid:13)14000(cid:13)0(cid:13)1(cid:13)2(cid:13)3(cid:13)4(cid:13)5(cid:13)6(cid:13)7(cid:13)Avg. number of reconns. per node(cid:13)Avg. Number of nodes in a steady state(cid:13) Minimum-depth(cid:13) Relaxed bandwidth-ordered(cid:13) Longest-first(cid:13) Relaxed time-ordered(cid:13) ROST(cid:13)480(cid:13)960(cid:13)1200(cid:13)1800(cid:13)0.60(cid:13)0.65(cid:13)0.70(cid:13)0.75(cid:13)0.80(cid:13)Avg. #distruptions per node(cid:13)Switch interval (seconds)(cid:13)480(cid:13)960(cid:13)1200(cid:13)1800(cid:13)0.08(cid:13)0.10(cid:13)0.12(cid:13)0.14(cid:13)0.16(cid:13)Avg. #reconn.s per node(cid:13)Switch interval (seconds)(cid:13)480(cid:13)960(cid:13)1200(cid:13)1800(cid:13)160(cid:13)165(cid:13)170(cid:13)175(cid:13)180(cid:13)185(cid:13)190(cid:13)195(cid:13)Avg. service delay(cid:13)Switch interval (seconds)(cid:13)480(cid:13)960(cid:13)1200(cid:13)1800(cid:13)3.0(cid:13)3.2(cid:13)3.4(cid:13)3.6(cid:13)3.8(cid:13)Avg. network stretch(cid:13)Switch interval (seconds)(cid:13)Figure 12: Avg. starving time ratio vs. group
size.
Figure 13: Avg.
buffer size.
starving time ratio vs.
Figure 14: Evaluation of ROST+CER.
7 Conclusions
This paper addresses the fault resilience of overlay multi-
cast using two techniques: (1) A proactive algorithm called
ROST that minimizes the failure correlation among mul-
ticast tree nodes by gradually switching the tree toward
a structure partially ordered in bandwidth and partially
ordered in time; (2) A reactive component that recovers
from streaming disruptions incurred by upstream member
failures using a CER protocol. The experimental results
demonstrate the superiority of the proposed schemes.
8 Acknowledgments
We are grateful to the anonymous reviewers for their ex-
cellent feedback. This research was sponsored in part by
grants from the NASA AMES Research Center (adminis-
trated by USARDSG, contract no. N68171-01-C-9012), the
EPSRC (contract no. GR/R47424/01) and the EPSRC e-
Science Core Programme (contract no. GR/S03058/01).
References
[1] S. Banerjee, B. Bhattacharjee, C. Kommareddy. Scalable
Application Layer Multicast. ACM SIGCOMM 2002.
[2] S. Banerjee, S. Lee, B. Bhattacharjee, and A. Srinivasan. Re-
silient multicast using overlays. ACM SIGMETRICS 2003.
[3] S. Birrer, D. Lu, F. E. Bustamante, Y. Qiao and P. Dinda.
FatNemo: Building a Resilient Multi-Source Multicast Fat-
Tree. In Proc. of the Ninth International Workshop on Web
Content Caching and Distribution (WCW), October 2004.
[4] Y. Chu, S. Rao, and H. Zhang. A Case for End System Mul-
ticast. Proc. of ACM SIGMETRICS, June 2000.
[5] M. Guo, M. Ammar. Scalable live video streaming to coop-
erative clients using time shifting and video patching. Proc.
of INFOCOM 2004.
[6] M. Guo, M. H. Ammar and E. W. Zegura. Cooperative Patch-
ing: A client based P2P architecture for supporting contin-
uous live video streaming. Proc. of the 13th International
Conference on Computer Communications and Networks
(ICCCN), 2004. J. Jannotti,
[7] D. Helder and S. Jamin. End-host Multicast Communication
Using Switch-tree Protocols. In Proc. of Internation Confer-
ence on Global and Peer-to-Peer Computing on Large Scale
Distributed Systems, 2002.
[8] V. N. Padmanabhan, Helen J. Wang, Philip A. Chou. Re-
silient Peer-to-Peer Streaming. Proc. 11th IEEE Interna-
tional Conference on Network Protocols (ICNP), 2003.
[9] V. N. Padmanabhan, H. J. Wang, P. A. Chou, and K. Sri-
panidkulchai. Distributing Streaming Media Content Using
Cooperative Networking. ACM NOSSDAV, May 2002.
[10] S. Saroiu, P. Gummadi and S. Gribble. A Measurement
Study of Peer-to-Peer File Sharing Systems. Proc. of Multi-
media Computing and Networking (MMCN), 2002.
[11] S. Sen and J. Wang. Analyzing peer-to-peer trafﬁc across
large networks. IEEE/ACM Trans. on Networking. Vol. 12,
No. 2, April 2004.
[12] K. Sripanidkulchai, A. Ganjam, B. Maggs and H. Zhang.
The feasibility of supporting large-scale live streaming appli-
cations with dynamic application end-points. Proc. of ACM
SIGCOMM, 2004, Portland, Oregon, USA.
[13] K. Sripanidkulchai, B. Maggs and H. Zhang. An analysis of
live streaming workloads on the Internet. Proc. of the 4th
ACM SIGCOMM IMC, Oct., 2004. Italy.
[14] D. A. Tran, K. A. Hua, and T. T. Do. A peer-to-peer archi-
tecture for media streaming. IEEE JSAC. Jan. 2004.
[15] E. Veloso, V. Almeida, W. Meira, A. Bestavros, and S. Jin.
A Hierarchical Characterization of A Live Streaming Media
Workload. IEEE/ACM Trans. on Networking, 12(5), 2004.
[16] K. Wong, W. Wong, G. Chan, Q. Zhang, W. Zhu, and Y.-Q.
Zhang. Lateral Error Recovery for Application-Level Multi-
cast. Proc. of IEEE INFOCOM 2004.
[17] X. R. Xu, A. C. Myers, H. Zhang and R. Yavatkar. Resilient
Multicast Support for Continuous-Media Applications. Proc.
NOSSDAV, 1997.
[18] M. Yang and Z. Fei. A Proactive Approach to Reconstructing
Overlay Multicast Trees. Proc. IEEE INFOCOM 2004.
[19] E. W. Zegura, K. Calvert and S. Bhattacharjee. How to
Model an Internetwork. Proc. of IEEE INFOCOM ’96, San
Francisco, CA.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:30:01 UTC from IEEE Xplore.  Restrictions apply. 
2000(cid:13)4000(cid:13)6000(cid:13)8000(cid:13)10000(cid:13)12000(cid:13)14000(cid:13)0.0(cid:13)0.5(cid:13)1.0(cid:13)1.5(cid:13)2.0(cid:13)2.5(cid:13)3.0(cid:13)Average starving time ratio (%)(cid:13)Avg. number of peers in a steady state(cid:13) Recovery group size = 1(cid:13) Recovery group size = 2(cid:13) Recovery group size = 3(cid:13) Recovery group size = 4(cid:13)5(cid:13)10(cid:13)15(cid:13)20(cid:13)25(cid:13)30(cid:13)0.0(cid:13)0.2(cid:13)0.4(cid:13)0.6(cid:13)0.8(cid:13)1.0(cid:13)1.2(cid:13)1.4(cid:13)1.6(cid:13)1.8(cid:13)2.0(cid:13)2.2(cid:13)2.4(cid:13) Average starving time ratio (%)(cid:13)Buffer size (seconds)(cid:13) Recovery group size = 1(cid:13) Recovery group size = 2(cid:13) Recovery group size = 3(cid:13)1(cid:13)2(cid:13)3(cid:13)0.0(cid:13)0.5(cid:13)1.0(cid:13)1.5(cid:13)2.0(cid:13)2.5(cid:13)3.0(cid:13)3.5(cid:13)4.0(cid:13)4.5(cid:13)5.0(cid:13)Average starving time ratio (%)(cid:13)Recovery group size(cid:13) Minimum-depth + Single Source(cid:13) ROST+CER(cid:13)