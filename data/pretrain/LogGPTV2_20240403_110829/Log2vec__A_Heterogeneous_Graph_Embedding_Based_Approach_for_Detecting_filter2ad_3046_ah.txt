for t ∈ set4 do
8:
9:
10:
11:
12:
13:
14:
15:
16: end for
17: return output
end while
set1 = set1\set2
output = output .append(set2)
set3 = set3 GetN eiдhbors(t,[loд1, loд2, sim], δ1)
set2 = set2 set4
end for
set4 = set3\set2
F DETECTION PERIOD OF CERT DATASET
Table 5 shows detection period of log2vec and training and test
period of HMM, DeepLog for six suspicious users in CERT dataset.
The period of log2vec is also the one of metapath2vec, node2vec,
log2vec-Euclidean, log2vec-cosine and log2vec++.
G PARAMETERS OF BASELINE METHODS
• TIRESIAS. In our scenarios, we treat user’s operations as
security events, its original input. In CERT dataset, we di-
vide user’s operations into three sequences according to
operation type, e.g. file, web and email operations, because
these log entries possess enough information for model’s
learning. The input information is host id, timestamp, op-
eration type and specific event information (e.g. filename,
url). We train and test the sequences involving malicious
log entries for each suspicious user. The training set is all
log entries before the first malicious ones. The test set is the
period during which the attack occurs. The training method
is gradient descent. We tune the number of unrolling w to
5, 10 and 20, to get the best performance. In LANL dataset,
TIRESIAS trains and tests its logon operations. The dataset is
logs recording suspicious users’ behavior in January. Specifi-
cally, the training and validation periods are the first twelve
days in January, the proportion is 8:2. The test dataset is
from 13th January to 31st January. The input information
is timestamp, event id, source user, destination user, source
computer, destination computer, authentication type, logon
type and authentication orientation. We set the number of
unrolling w to 20. For these two datasets, we respectively set
the training batch size to 128 and 512, the number of memory
array k to 4, and the number of hidden LSTM Memory Array
units to 128. The output is a probability distribution over
the n candidate events. If the next real value is in the first д
predicted events (sorted by probability), TIRESIAS views this
operation as normal. The predicted label is then compared
with the real one. We adjust д to compute AUCs and their
mean AUC.
Table 5: Detection period of log2vec, DeepLog and HMM for
six suspicious users in CERT dataset and the corresponding
numbers of log entries, malicious log entries and days
Log2vec
DeepLog/HMM
User Id
ACM2278
CMP2946
HIS1706
PLJ1771
CDE1846
MBG3183
Detection Period
(#log:#malicious)
2010.7-8 (7782:22)
2011.2-3(8584:242)
2010.7-8(6856:8)
2010.7-8(4161:18)
2011.2.21-4.25
(4879:134)
Test Period
(#day)
2010.7-8 (44)
2011.2-3 (43)
2010.7-8 (43)
2010.7-8 (31)
2011.2.21-
4.25(45)
2010.9-10(4995:4)
2010.9-10 (42)
Training
Period(#day)
2010.6 (22)
2011.1 (21)
2010.6 (22)
2010.6 (22)
2011.1.21-
2.20(21)
2010.8 (22)
• DeepLog. We utilize DeepLog’s log key anomaly detection
model. In CERT dataset, we analyze user’s behavior. There-
fore, we set operation type as log key, e.g. logon, device
connect and upload. For each suspicious user, the input is
recent log keys, and the output is a probability distribution
over the n log keys. The training and test set are shown
in Table 5 in Appendix F. The training method is gradient
descent. The window size h is 10, the number of layers L is 2
and the number of memory units in one LSTM block α is 64.
If the real value is in the first д predicted log key candidates,
DeepLog treats this operation as normal. The predicted label
is compared with the real one. We adjust д to compute AUC.
• Hidden markov model. We transform daily log entries into a
sequence. The two feature sets are both used: the simple set (7
features), markov-s and the comprehensive one (16 features),
markov-c. The training period and test one are shown in
Table 5 in Appendix F. We set ϵ = 0.01 and λ = 0.05. This
method outputs probability of daily log sequence. We set a
threshold. If the sequence probability is below the threshold,
we classify it as anomalous. For each malicious sequence,
we view all logs involved in it as malicious. Through tuning
this threshold, we compute users’ mean AUC.
Session 8C: Blockchain VICCS ’19, November 11–15, 2019, London, United Kingdom1793every two nodes. Due to traversing more neighbor nodes in
our task, we set p = 4 and q = 0.5. The number of neighbor
nodes (neiдh) in log2vec is designed for edge type of inter
group (e.g. edge5, edge10). When a walker encounters the
edge of inter group in log2vec, he also has a edge of intra
group (e.g. edge1, edge3) to choose. Therefore we set the
number of neighbor nodes in this model as the number in
log2vec +1. We set r = 90 and l = 60.
• Log2vec-Euclidean. It shares the same graph construction
and graph embedding as log2vec’s. It uses k-means with
Euclidean distance to detect anomalies. For each user, it
utilizes K-means++ initialization [1] and performs k-means
3 times from 70-150 clusters. We determine the optimal k
according to the maximum average silhouette score [43].
Log2vec-Euclidean produces clusters. We set a threshold. If
the number of log entries involved in a cluster is smaller
than the threshold, we will view this cluster as malicious.
For each malicious cluster, we treat all logs involved in it as
malicious. Through tuning this threshold, we compute six
users’ mean AUC in CERT dataset.
• Log2vec-cosine. It uses k-means with cosine distance. For
each user, it performs k-means 10 times from 70-150 clusters.
The remaining procedure is the same as log2vec-Euclidean.
• Log2vec++. Log2vec++’s neiдh++ and δ1++ are flexibly set
as shown in Table 6, while log2vec’s neiдh is 1 and δ1 is set
according to Section 5.3.
• Ensemble method. We utilize network flow logs of the first
day in LANL dataset. We set both pc and pcs to 0.2. pb/pm
is 2. Other parameters are set to the same ones in the work
of Atul Bohara et al. [4]. This method produces anomalous
hosts. We tune the threshold θavд to compute AUC in the
host-level granularity, as the work does [4].
H PARAMETERS SETTING
Table 6 depicts log2vec++’s and log2vec’s AUCs and three parame-
ters for each user in CERT dataset.
Table 6: Log2vec++’s and log2vec’s AUCs and three parame-
ters of them for each user in CERT dataset. Log2vec++ uti-
lizes neiдh++ and δ1++. Log2vec employs δ1 and neiдh is 1.
They share ps according to policies in Appendix C.
User Id
ACM2278
CMP2946
HIS1706
PLJ1771
CDE1846
MBG3183
log2vec++
1
0.83
0.97
0.83
0.92
1
log2vec
0.99
0.77
0.87
0.63
0.92
0.99
neiдh++
1
9
1
2
1
4
δ1++
0.67
0.61
0.63
0.57
0.66
0.62
δ1
0.7
0.65
0.66
0.69
0.66
0.64
ps
1:1:6:1
1:1:1:6
1:1:1:1
1:1:6:1
1:1:1:1
1:1:1:6
I FALSE ALARMS OF BENIGN USERS
In LANL dataset, 90 benign users are examined by log2vec. In
Figure 8, the mean and median of FPRs are 0.08 and 0.03 respectively.
The maximum of FPR is 0.45 and most of FPRs are less than 0.13.
In CERT dataset, log2vec tests 12 benign users. The mean and
median of FPRs are both 0.1. The maximum of FPR is 0.13.
Figure 8: Distribution of false positive rates on 90 benign
users in LANL dataset.
• Deep learning model. We use Deep Neural Network (DNN)
and Long Short-Term Memory (LSTM) Recurrent Neural
Network. For DNN and LSTM, we separately fix the number
of hidden layers to 3 and 3, the hidden layer dimension to 20
and 3, the batch size to 256 and 21. The training method is
Adam algorithm. We use the first 418 days as training dataset
and day 419∼516 as testing dataset, as the work does [57].
The method outputs anomaly score for each daily sequence.
We set a threshold. If the anomaly score is above the thresh-
old, we classify it as anomalous. For each malicious sequence,
we view all log entries involved in it as malicious. We tune
this threshold to compute AUC.
• STREAMSPOT. This method detects malicious information
flows [31]. It defines an information flow (graph) as a unit of
functionality (e.g.checking email). In CERT dataset, one log
entry is nearly corresponding to a graph in STREAMSPOT.
To compare this method, we define user’s operations of
the same type during an interval (one hour) as a graph.
STREAMSPOT scores each information flow graph. We set
a threshold. If the score is greater than the threshold, the
corresponding graph is classified as malicious, and all log
entries involved in it are viewed as malicious. We tune this
threshold to compute six users’ mean AUC.
• Metapath2vec. We use the same constructing graph and
detection algorithm as log2vec’s because metapath2vec is
a method of graph embedding. Metapath2vec demands the
specific metapath. We mainly define four general metapaths,
{edge1, edge4}, {edge2, edge5}, {edge3, edge6} and {edge9,
edge10}. For instance, only if the next edge belongs to edge1
or edge4, it can be considered to traverse in the round of
{edge1, edge4}. The proportion of them is 1:1:1:1 because of
no comparison of user’s and his colleagues’ behavior changes
in this model. We set r = 23, l = 60 to make them close to the
parameters in log2vec.
• Node2vec. This graph embedding also uses the same graph
construction and detection algorithm as log2vec’s. This model
just processes homogeneous graph so we view the eight edge
types as the same one and sum all their weights between
0%10%20%30%0.00.20.40.60.81.0FPRRatioSession 8C: Blockchain VICCS ’19, November 11–15, 2019, London, United Kingdom1794