title:Towards Plausible Graph Anonymization
author:Yang Zhang and
Mathias Humbert and
Bartlomiej Surma and
Praveen Manoharan and
Jilles Vreeken and
Michael Backes
Towards Plausible Graph Anonymization
Yang Zhang∗, Mathias Humbert†, Bartlomiej Surma∗,
Praveen Manoharan∗, Jilles Vreeken∗, Michael Backes∗
∗CISPA Helmholtz Center for Information Security,
{zhang, bartlomiej.surma, praveen.manoharan, vreeken, backes}@cispa.saarland
†Cyber-Defence Campus, armasuisse Science and Technology, PI:EMAIL
Abstract—Social graphs derived from online social interac-
tions contain a wealth of information that is nowadays exten-
sively used by both industry and academia. However, as social
graphs contain sensitive information, they need to be properly
anonymized before release. Most of the existing graph anonymiza-
tion mechanisms rely on the perturbation of the original graph’s
edge set. In this paper, we identify a fundamental weakness of
these mechanisms: They neglect the strong structural proximity
between friends in social graphs, thus add implausible fake edges
for anonymization.
To exploit this weakness, we ﬁrst propose a metric to quantify
an edge’s plausibility by relying on graph embedding. Extensive
experiments on three real-life social network datasets demonstrate
that our plausibility metric can very effectively differentiate fake
edges from original edges with AUC (area under the ROC curve)
values above 0.95 in most of the cases. We then rely on a Gaussian
mixture model to automatically derive the threshold on the edge
plausibility values to determine whether an edge is fake, which
enables us to recover to a large extent the original graph from
the anonymized graph. We further demonstrate that our graph
recovery attack jeopardizes the privacy guarantees provided by
the considered graph anonymization mechanisms.
To mitigate this vulnerability, we propose a method to
generate fake yet plausible edges given the graph structure and
incorporate it into the existing anonymization mechanisms. Our
evaluation demonstrates that the enhanced mechanisms decrease
the chances of graph recovery, reduce the success of graph de-
anonymization (up to 30%), and provide even better utility than
the existing anonymization mechanisms.
I.
INTRODUCTION
The rapid development of online social networks (OSNs)
has resulted in an unprecedented scale of social graph data
available. Access to such data is invaluable for both the indus-
trial and academic domains. For instance, Amazon or Netﬂix
have leveraged graph data to improve their recommendation
services. Moreover, researchers have been using graph data
to gain a deeper understanding of many fundamental societal
questions, such as people’s communication patterns [34], [50],
geographical movement [10], [51], and information propaga-
tion [23], [39]. These examples demonstrate that the sharing
of large-scale graph data can bring signiﬁcant beneﬁts to the
society.
Network and Distributed Systems Security (NDSS) Symposium 2020
23-26 February 2020, San Diego, CA, USA
ISBN 1-891562-61-4
https://dx.doi.org/10.14722/ndss.2020.23032
www.ndss-symposium.org
On the downside, graph data also inherently contains very
sensitive information about individuals [7], such as their social
relations [4], and it can be used to infer private attributes [22].
In order to mitigate privacy risks, it is crucial to properly
anonymize the graph data before releasing it to third parties.
The naive approach of replacing real identiﬁers by random
numbers has been proven ineffective by Backstrom et al.
about a decade ago already [5]. From then on, the research
community has been working on developing more robust graph
anonymization mechanisms [26], [40], [31], [49], [20]. The
majority of the proposed mechanisms focus on perturbing
the original edge set of the graph (instead of perturbing the
node set) by adding fake edges between users, such that the
perturbed graph satisﬁes well-established privacy guarantees,
such as k-anonymity [44] and differential privacy [11].
A. Contributions
In this paper, we identify a fundamental weakness of
the most prominent graph anonymization mechanisms: When
creating fake edges, they do not take into account key char-
acteristics of the underlying graph structure, in particular, the
higher structural proximity between friends [25], which results
in fake edges not being plausible enough compared to the
original ones. To exploit this weakness, we ﬁrst assess the
plausibility of each edge by relying on graph embedding [35],
[14]. We show that this approach can very effectively detect
fake edges (see Figure 1a for an example of the edge plau-
sibility distribution of fake and original edges on a real-life
social network dataset), and thus can eventually help recover
the original graph to a large extent. We then demonstrate
that our graph recovery attack jeopardizes the anonymization
mechanisms’ privacy guarantees. Finally, we develop enhanced
versions of the existing graph anonymization mechanisms that:
(i) create plausible edges (Figure 1b), (ii) reduce the risk of
graph recovery and graph de-anonymization, (iii) preserve the
initial privacy criteria provided by the mechanisms, and (iv)
provide even better graph utility (with respect to how well the
anonymized graph preserves the structural properties of the
original graph).
To illustrate the wide applicability of our approach, we
concentrate on two of the best established graph anonymization
mechanisms, namely k-DA [26] and SalaDP [40], which
provide k-anonymity and differential privacy guarantees, re-
spectively. The reason we choose k-DA and SalaDP is that
they are the best graph anonymization schemes with respect to
utility and resistance to de-anonymization (in addition to being
the most cited). This conclusion is drawn from the evaluation
performed by Ji et al. [18].
(a) k-DA (k = 100)
(b) Enhanced k-DA (k = 100)
Fig. 1: Plausibility distributions of fake and original edges in the NO dataset anonymized by (a) the original k-DA and (b) by
our enhanced k-DA mechanisms. The edge plausibility is deﬁned in Section III. The NO dataset is collected by Viswanath et
al. [47], and k-DA [26] is one of the anonymization mechanisms we concentrate on in this paper.
In the following, we provide an overview of our contribu-
tions in this paper.
Edge Plausibility: We measure the plausibility of an edge as
the structural proximity between the two users it connects.
In the ﬁeld of link prediction [25], structural proximity is
normally measured by human-designed metrics, which only
capture partial information of the proximity. Instead, we rely
on graph embedding [35], [14] to map users in the anonymized
graph into a continuous vector space, where each user’s vector
comprehensively reﬂects her structural properties in the graph.
Then, we deﬁne each edge’s plausibility as the similarity
between the vectors of the two users this edge connects, and
postulate that lower similarity implies lower edge plausibility.
Graph Recovery: We show the effectiveness of our approach
in differentiating fake edges from original ones without deter-
mining a priori a speciﬁc decision threshold on the plausibility
metric. For this case, we adopt the AUC (area under the ROC
curve) value as the evaluation metric. Extensive experiments
performed on three real-life social network datasets show
that our plausibility metric achieves excellent performance
(corresponding to AUC values greater than 0.95) in most of the
cases. Then, observing that the fake and real edges’ empirical
plausibility follow different Gaussian distributions, we rely
on a Gaussian mixture model and maximum a posteriori
probability estimate to automatically determine the threshold
on the edge plausibility values to detect fake edges. Our
experimental results show that this approach achieves strong
performance with F1 scores above 0.8 in multiple cases. After
deleting the fake edges, we are able to recover, to a large
extent, the original graph from the anonymized one.
Privacy Damage: The two anonymization mechanisms we
consider follow different threat models and privacy deﬁni-
tions. To precisely quantify the privacy impact of our graph
recovery, we propose privacy loss measures tailored to each
mechanism we target. As the ﬁrst anonymization mechanism
assumes the adversary uses the users’ degrees to conduct her
attack, we evaluate the corresponding privacy impact as the
difference between users’ degrees in the original, anonymized,
and recovered graphs. For the differential privacy mechanism,
we measure the magnitude and entropy of noise added to
the statistical measurements of the graph. Our experimental
results show that the privacy provided by both mechanisms
signiﬁcantly decreases, which demonstrates the vulnerabilities
of existing graph anonymization techniques.
Enhancing Graph Anonymization:
In order to improve the
privacy situation, we propose a method that generates plausible
edges while preserving the original privacy guarantees of each
mechanism. We rely on statistical sampling to select potential
fake edges that follow a similar plausibility distribution as
the edges in the original graph. Our experimental results
show that our enhanced anonymization mechanisms are less
prone to graph recovery (AUC dropping by up to 35%)
and preserve higher graph utility compared to the existing
anonymization mechanisms. More importantly, we show that
our enhanced mechanisms reduce the state-of-the-art graph de-
anonymization [32] attack’s performance signiﬁcantly (up to
30% decrease in the number of de-anonymized users).
In summary, we make the following contributions in this
paper:
• We perform a graph recovery attack on anonymized
social graphs based on graph embedding that captures
the structural proximity between users and thus unveils
fake edges (i.e., relations) between them.
• We show through extensive experimental evaluation
that our graph recovery attack jeopardizes the pri-
vacy guarantees provided in two prominent graph
anonymization mechanisms.
• We propose enhanced versions of
these graph
anonymization mechanisms that improve both their
privacy and utility provisions.
2
−0.20.00.20.40.60.81.0Edgeplausibility01234567Numberofedges×104OriginaledgesFakeedges−0.20.00.20.40.60.81.0Edgeplausibility01234567Numberofedges×104OriginaledgesFakeedgesTABLE I: Notations.
Description
Social graph
A social network user
An edge connecting users u and u(cid:48)
Anonymization mechanism
Anonymized social graph
Friends of user u
Embedding vector of user u
Plausibility of edge {u, u(cid:48)} in GA
Recovered social graph
dK-2 series of G
Anonymized graph by enhanced mechanism
Notation
G = (U , E)
u ∈ U
{u, u(cid:48)} ∈ E
A
GA
κ(u)
f (u)
sA(u, u(cid:48))
GR
D(G)
GF
B. Organization
The rest of the paper is organized as follows. We introduce
the notations, anonymization mechanisms, and threat model
used throughout the paper in Section II. Section III presents
our edge plausibility deﬁnition and Section IV evaluates its
effectiveness. The privacy impact of our graph recovery is
studied in Section V. In Section VI, we introduce our enhanced
graph anonymization mechanisms. Section VII discusses the
related work in the ﬁeld and Section VIII concludes the paper.
II. PRELIMINARIES
In this section, we ﬁrst introduce the notations, second,
describe the two anonymization mechanisms we study, and
third, present the threat model.
A. Notations
}|u, u(cid:48)
∈ U ∧ u (cid:54)= u(cid:48)
We model a social graph as an undirected graph G =
(U,E), where set U contains the users (nodes) and set E ⊆
{{u, u(cid:48)
} represents all the edges of the
graph. We deﬁne by A the anonymization mechanism which
transforms G to an anonymized graph GA = (U,EA) following
the privacy criteria of A. By this deﬁnition, we only consider
graph anonymization mechanisms that do not add new nodes
but only modify edges. This is in line with most of the previous
works [26], [52], [40], [31], [49]. We further use κ(u) to
represent u’s friends in G, i.e., κ(u) = {u(cid:48)
} ∈ E}. Ac-
cordingly, κA(u) represents u’s friends in GA. For presentation
purposes, we summarize the notations introduced here and in
the following sections in Table I.
|{u, u(cid:48)
B. Graph Anonymization Mechanisms
We brieﬂy review the two graph anonymization mecha-
nisms we study. For more details, we refer the readers to
the original papers. Note that, to fully understand these two
mechanisms, we have also inspected the source code of Sec-
Graph [18], a state-of-the-art software system for evaluating
graph anonymization which includes an implementation of
both k-DA and SalaDP.
k-DA [26]:
k-DA follows the notion of k-anonymity in
database privacy. The mechanism assumes that the adversary
has prior knowledge of its target users’ degrees in a social
graph, i.e., numbers of friends, and uses this knowledge to
identify the targets from the graph. To mitigate this privacy
risk, k-DA modiﬁes the original social graph, such that in the
3
resulting anonymized graph, each user shares the same degree
with at least k − 1 other users.
k-DA takes two steps to achieve its goal. First, it utilizes
dynamic programming to construct a k-anonymous degree
sequence. Second, the mechanism adds edges1 to the original
graph in order to realize the k-anonymous degree sequence.
By calculating the differences between the original degree
sequence and the k-anonymous degree sequence, k-DA main-
tains a list that stores the number of edges needed for each
user, namely the user’s residual degree. When adding an edge
for a certain user, k-DA picks the new adjacent user with the
highest residual degree.
SalaDP [40]: SalaDP is one of the ﬁrst and most widely
known mechanisms applying differential privacy for graph
anonymization. The statistical metric SalaDP concentrates on
is the dK-2 series of a graph G which counts, for each pair
(i, j) of node degrees i and j, the number of edges in G that
connect nodes of these degrees. A formal deﬁnition of dK-2
series will be provided in Section V.
SalaDP also takes a two-step approach to anonymize a
graph. First, the mechanism adds Laplace noise to each el-
ement in the original dK-2 series, and obtains a differentially
private dK-2 series. Then, it generates the anonymized graph
following the new dK-2 series. By checking SecGraph’s
source code, we ﬁnd that SalaDP generates the anonymized
graph by (mainly) adding fake edges to the original graph in
a random manner.2
From the above descriptions, we can see that neither of the
anonymization mechanisms consider friends’ strong structural
proximity when adding fake edges. The main hypothesis we
investigate is that we can effectively differentiate the fake
edges added by such mechanisms from the original edges,
using a suitable measure for edge plausibility. We focus on fake
added edges (and not on deleted edges) since most of the graph
anonymization mechanisms mainly add edges to the original
social graph for preserving better graph utility. It is worth
noting that our approach (Section III) can also help recover
deleted edges on anonymized graphs. However, the underlying
search space is then O(|U|2), which is computationally very
expensive on large graphs. In the future, we plan to tackle
this problem by designing heuristics to efﬁciently recover the
deleted edges.
C. Threat Model
The adversary’s goal is to detect fake edges in GA, partially
recover the original graph, and eventually carry out privacy
attacks on the recovered graph. To perform graph recovery, we
assume that the adversary only has access to the anonymized
graph GA and is aware of the underlying anonymization
algorithm. This means that the adversary does not need any
information about the original graph G, such as G’s graph
structure or any statistical background knowledge related to
this graph. Figure 2 depicts a schematic overview of the attack.
1In its relaxed version, k-DA also deletes a small fraction of edges, but its