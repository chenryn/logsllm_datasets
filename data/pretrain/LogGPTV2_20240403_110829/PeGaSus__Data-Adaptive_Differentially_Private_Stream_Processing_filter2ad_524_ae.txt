Theorem 5.3. Algorithm 4 satisfies ϵ-differential privacy.
Proof. For any two neighboring source streaming datasets, they
derive neighboring multiple streams that only differ by 1 at one
timestamp on one single stream. Calling function Prune at every
timestamp with ϵpr privacy budget ensures ϵpr -differential privacy
based on Theorem 5.2. For the pruned aggregated streams, we set
the count to be 0, which will not leak any information. For the
non-pruned aggregated streams, we apply an algorithm similar to
Algorithm 1 to compute noisy counts at each timestamp. Based
on the analysis of Theorem 3.1 and sequential composition of dif-
ferential privacy on the aggregation set with h levels, releasing
noisy counts at every timestamp will satisfy ϵp + ϵд-differential
privacy. Thus, Algorithm 4 satisfies ϵ = ϵpr + ϵp + ϵд-differential
privacy.
□
6 EVALUATION
In this section, we evaluate the proposed algorithms on real data
streams for a variety of workloads. We design the following experi-
ments:
if aдд ∈ Pruned then
for each aдд ∈ AGG at level i do
Pruned ← ∅, ϵAGG ← ∅
for level i = 1 to h do
Algorithm 4 Hierarchical-Stream PeGaSus with Pruning (PHS-
PGS)
Input: AGG with h levels, streams C (aдд) for each aдд ∈ AGG,
privacy budget ϵ = ϵpr + ϵp + ϵд, threshold β
Output: Streams ˆC (aдд) for each aдд ∈ AGG
1: function Prune(AGG, ct (aдд) for each aдд ∈ AGG, ϵ, β)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
end for
15:
Return Pruned, ϵAGG
16:
17: end function
18: for each timestamp t do
19:
Add every child of aдд to Pruned
Add ϵaдд = 0 to ϵAGG
Add every child of aдд to Pruned
Add ϵaдд = h − i + 1 to ϵAGG
Add ϵaдд = 1 to ϵAGG
else if (ct (aдд) + Lap(2/ϵ )) < (β +Lap(2/ϵ )) then
Pruned, ϵAGG ← Prune(AGG, ct (aдд) for each aдд ∈
for each aдд ∈ AGG do
AGG, ϵpr , β)
else
end if
end for
if aдд ∈ Pruned then ˆct (aдд) ← 0
else
˜ct (aдд) ← Perturber(ct (aдд),
ϵaдд (ϵp +ϵд )
Pt ← Grouper(Ct (aдд), Pt−1,
ϵд
h )
ˆct (aдд) ← Smoother( ˜Ct (aдд), Pt )
h
− ϵд
h )
20:
21:
22:
23:
24:
25:
26:
27:
28:
29: end for
end if
Output ˆct (aдд)
end for
1. We evaluate answering unit counting queries on data streams
2. We evaluate answering sliding window queries on data streams
with a single target state.
with a single target state.
3. We evaluate event monitoring (detecting jumping and drop-
ping points as well as low signal points) on data streams
with a single target state.
4. We evaluate answering unit counting queries on a collection
of hierarchical aggregations using data streams with multiple
target states.
Dataset : Our source data comes from real traces, taken over a six
month period, from approximately 4000 WiFi access points (AP)
distributed across the campus of a large educational institution. We
set the time interval to be 5 minutes and derive tuples from the
source data. If a user u makes at least one connection to AP s within
time interval t, then a tuple (u, s, t ) will be added to the stream.
Then, for any single AP s, a stream C (s) = c1 (s), c2 (s), . . . will be
generated, where ct (s) reports the number of users who success-
fully connected to AP s within time interval t. For the evaluation of
Table 1: An overview of the streams derived from real WiFi
access points connection traces. Length refers to the number
of counts, each representing the number of successful con-
nections in a 5 minute interval. Total count is the sum of all
counts in the stream.
Stream Name
Low_5
Med_5
High_5
Multi_5
# of target states
1
1
1
128
Length Total count
57901
57901
57901
20000
2846
101843
2141963
646254
data streams with a single target state, we pick three representative
APs with different loads (called "Low_5", "Med_5" and "High_5").
For the evaluation of data streams with multiple target states, we
randomly pick 128 APs (called "Multi_5"), and generate a hierar-
chical aggregation of these states as a binary tree of height 8. An
overview of the corresponding derived streams is shown in Table 1.
6.1 Unit counting query on a single target state
Answering a unit counting query on data streams with a single
target state is equivalent to releasing a private version of the entire
stream. Figure 2 shows visually the real and the privately generated
streams for the first 8000 timesteps of stream "High_5" under ϵ = 0.1
and 0.01. We compare our PeGaSus algorithm with the Laplace
Mechanism (LM). In PeGaSus, we set ϵp = 0.8 × ϵ and ϵд = 0.2 × ϵ.
We set θ = 5
in our Grouper. We use the MedianSmoother method
ϵд
as the Smoother. In each figure of a noisy stream, we truncate the
negative counts to zero. Clearly, PeGaSus produces private streams
that are more accurate when visualized.
t
We also quantitively evaluate the error of answering the unit
counting query by using a couple of measures related to L1 error. For
any input data stream Ct = {c1, c2, . . . , ct} and the output private
(cid:80)t
stream ˆCt = {ˆc1, ˆc2, . . . , ˆct}, the scaled total L1 error is defined to
(cid:80)t
i =1 |ci−ˆci |
(cid:80)t
be
. We also use average L1 error, which is defined as
i =1 ci
i =1 |ci−ˆci |
.
Figure 3 reports the evaluation results on the data streams with
the single target state from Table 1. In each figure, LM means Laplace
Mechanism, and PGS is PeGaSus with the MedianSmoother as Smoother.
In addition, as a simple comparison method, we use BS_t to mean a
method where we do backward smoothing of results from Laplace
Mechanism. Given a backward smoothing time k, for any t ≥ k,
ˆck is updated as
is the output from Laplace
Mechanism. Each bar in the figures reports the scaled total L1 error
in terms of the unit counting query at all timesteps. The value is
the average of 20 random trials. PeGaSus consistently performs the
best on all the data streams and under both ϵ settings.
, where ˆcLM
(cid:80)t
Next, we compare the impact of the three different smoothing
strategies – JSSmoother, MedianSmoother, and AverageSmoother –
in terms of answering the unit counting query. The results are
shown in Figure 4. Each bar reports the log10 value of the average
L1 error under 20 trials in terms of each smoothing strategy. We can
see that all JSSmoother, MedianSmoother and AverageSmoother are
ˆc LM
i
i =t−k
k +1
i
good smoothing strategies, but MedianSmoother is consistently bet-
ter than AverageSmoother and JSSmoother for all data streams and
ϵ settings.
6.2 Sliding window query on a single target
state
Next we evaluate the sliding window query with window size w.
Figure 5 presents the results. Each point shows the average L1 error
for answering the sliding window query with size w = 2x at all
timesteps and the value is the average of 20 trials. In each sub-figure,
LM represents using Laplace Mechanism to answer the unit counting
query first, then computing the sliding window query based on
the noisy unit counting query answers. SW_w is the state-of-the-
art data independent algorithm for computing the sliding window
query in terms of a fixed window size w [4]. SW_w generates binary
trees on every consecutive window of w counts and perturbs each
node query of each binary tree. Then, any sliding window query
with size w can be derived as the sum of the prefix and suffix of any
two neighboring binary trees. PGS_MS is a variant of PeGaSus with
MedianSmoother as Smoother; PGS_WWS is a variant of PeGaSus
with Window Sum Smoother (Algorithm 3) as Smoother.
As shown in the figure, LM introduces excessive error. PGS_WWS
performs slightly but consistently better than PGS_MS, demonstrat-
ing the benefit of using a different Smoother for this workload.
PGS_WWS computes more accurate sliding window queries when
w is not greater than 256 compared with the state of the art al-
gorithm SW_w. When the window size becomes larger, SW_w
becomes better because SW_w is designed specifically for the slid-
ing window query with window size w while our PeGaSus may
introduce a large bias into a large sliding window query. We empha-
size that PeGaSus can simultaneously support all sliding window
queries instead of having to split the privacy budget and design
algorithms for each sliding window workload with a fixed window
size.
6.3 Event monitoring on a single target state
In this experiment we consider event monitoring queries on the
"High_5" data stream. Figure 6 displays the ROC curves for detect-
ing jumping and dropping points on streams with a single target
state. In each sub-figure, LM represents using Laplace Mechanism to
generate a noisy stream and doing event monitoring on the noisy
stream. PGS is our PeGaSus with MedianSmoother. We use a fixed
window size w and threshold δ to compute the ground truth in
terms of the real stream. We vary the threshold from 0 to 1000 to do
the private event monitoring and compute the corresponding "True
Positive Rate" and "False Positive Rate". As shown in the figures, for
all different w and δ settings, when ϵ is large (= 0.1), both LM and
PeGaSus perform very well and LM is slightly better than PeGaSus.
However, when ϵ becomes smaller (=0.01), PeGaSus performs much
better than LM.
Figure 7 shows the ROC curves for detecting low signal points.
Since determining the low signal points requires computing the
sliding window queries, we compare SW_w from [2] with our
proposed PeGaSus with Algorithm 3 as Smoother. We use fixed
window size w and threshold δ to compute the ground truth in terms
of the real stream. We vary the threshold from -4000 to 4000 to do
(a) ϵ = 0.1, real
(b) ϵ = 0.1, LM
(c) ϵ = 0.1, PeGaSus
(d) ϵ = 0.01, real
(e) ϵ = 0.01, LM
(f) ϵ = 0.01, PeGaSus
Figure 2: Visualizations of the "High_5" stream for 8000 timesteps. The real stream is shown on the left followed by two
privately generated versions: the Laplace Mechanism (LM) and PeGaSus. Above ϵ = 0.1, while below ϵ = 0.01.
(a) Low_5
(b) Med_5
(c) High_5
Figure 3: Error for the unit counting query on streams with a single target state. The y-axis reports loд10 of the scaled total L1
error.
the private event monitoring and compute the corresponding "True
Positive Rate" and "False Positive Rate". As shown in the figures,
for all different ϵ, w and δ settings, PeGaSus always outperforms
SW_w.
(a) ϵ = 0.1