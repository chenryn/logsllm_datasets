1 + log k
2k
1/3
2κ/3
4kκ/3
4kκ/3
1
1
1
1
1
Comm.
k + k log k
2k
k + log k
2k
2κ/3
4κ/3
5kκ/3
8kκ/3
Rounds
1 + log k
1 + log k
1 + log k
2
1
1
1
1
Table 1: Conversion costs between arithmetic, binary and
Yao representations. Communication (Comm.) is measured
in average bits per party. x ∈ Z2k is an arithmetic value,
b ∈ {0, 1} is a binary value, κ is the computational security
parameter.
functions computed during machine learning training and predic-
tion are also of this form [40, 43]. While our new ABY framework
enables efficient three-party evaluation of such functions, we design
a more customized solution based on an optimized construction
for the following two building blocks: a(cid:74)b(cid:75)B = (cid:74)ab(cid:75)A (a known
by one party) and(cid:74)a(cid:75)A(cid:74)b(cid:75)B = (cid:74)ab(cid:75)A (a is shared) where b is a
bit and a ∈ Z2k . We observe that this mixed computation can be
instantiated using a generalized three-party oblivious transfer pro-
tocol where a bit bi is the receiver’s input and an integer a is the
sender’s input. We design new protocols for this task with both
semi-honest and malicious security that run in 1 and 2 rounds re-
spectively and require between 2k to 4k bits. This should be of
more general interest as piecewise polynomial functions appear in
many applications and are a common technique for approximating
non-linear functions.
2 RELATED WORK
Earlier work on privacy preserving machine learning considered de-
cision trees [39], k-means clustering [15, 35], SVM classification [56,
58], linear regression [25, 26, 49] and logistic regression [52]. These
papers propose solutions based on secure multiparty computation,
but appear to incur high efficiency overheads, as they do not take
advantage of recent advances in MPC and lack implementation.
Linear Regression. Privacy-preserving linear regression in the
two-server model was first considered by Nikolaenko et. al. [45]
who present a linear regression protocol on horizontally partitioned
data using a combination of linearly homomorphic encryption
(LHE) and garbled circuits. Gascon et. al. [29] and Giacomelli et.
al. [30] extend the results to vertically partitioned data and show
improved performance. However, they reduce the problem to solv-
ing a linear system using either Yao’s garbled circuit protocol or
an LHE scheme, which introduces a high overhead and cannot
be generalized to non-linear models. In contrast, we use the sto-
chastic gradient descent (SGD) method for training which yields
faster protocols and enables training non-linear models such as
neural networks. Recent work of Mohassel and Zhang [43] also
uses the SGD for training, using a mix of arithmetic, binary, and
Yao sharing 2PC (via the ABY framework). They also introduce
a novel method for approximate fixed-point multiplication that
avoids boolean operations for truncating decimal numbers and
yields the state-of-the-art performance for training linear regres-
sion models. The above are limited to the two-server model and
do not extend to the three-server model considered in this paper.
Session 1B: PrivacyCCS’18, October 15-19, 2018, Toronto, ON, Canada37Gilad-Bachrach et. al. [32] propose a framework which supports
privacy preserving linear regression. However, the framework does
not scale well due to extensive use of garbled circuits.
Logistic Regression. Privacy preserving logistic regression is con-
sidered by Wu et. al. [57]. They propose to approximate the logistic
function using polynomials and train the model using LHE. How-
ever, the complexity is exponential in the degree of the approxima-
tion polynomial, and as shown in [43] the accuracy of the model is
degraded compared to using the logistic function. Aono et. al. [8]
consider a different security model where an untrusted server col-
lects and combines the encrypted data from multiple clients, and
transfers it to a trusted client to train the model on the plaintext.
However, in this setting, the plaintext of the aggregated data is
leaked to the client who trains the model.
Neural Networks. Privacy preserving machine learning with neu-
ral networks is more challenging. Shokri and Shmatikov [50] pro-
pose a solution where instead of sharing the data, the two servers
share the changes on a portion of the coefficients during the training.
Although the system is very efficient (no cryptographic operation
is needed at all), the leakage of these coefficient changes is not
well-understood and no formal security guarantees are obtained.
Privacy-preserving prediction using neural networks models
has also been considered in several recent works. In this setting,
it is assumed that the neural network is trained on plaintext data
and the model is known to one party who evaluates it on private
data of another. One recent line of work uses fully homomorphic
or somewhat homomorphic encryption to evaluate the model on
encrypted data [14, 18, 31, 34]. Another line of work takes advan-
tage of a combination of LHE and garbled circuits to solve this
problem [20, 40, 48]. Riazi et al. [46] and Liu et al. [40] each pro-
poses efficiency improvements to the ABY framework and use
it for privacy-preserving neural network inference. Chandran et
al. [20] propose a framework for automatically compiling programs
into ABY components and show how to use it to evaluate neural
network models. These constructions are all based on two-party
protocols and do not benefit from major speed-ups due to new
3PC techniques [9, 28, 42]. They also only provide security against
a semi-honest adversary. In Section 6 we give an explicit perfor-
mance comparison to these frameworks and demonstrate that ours
is significantly more efficient.
Very few recent work consider privacy preserving training of
Neural Networks. Mohassel and Zhang [43] customize the ABY
framework for this purpose and propose a new approximate fixed-
point multiplication protocol that avoids binary circuits, and use it
to train neural network models. Their fixed-point multiplication
technique is limited to 2PC.
3 PRELIMINARIES
Let i ± 1 to refer to the next (+) or previous (-) party with wrap
around, i.e. party 3 + 1 is party 1, party 1-1 is party 3.
3.1 Three-party Secure Computation
Secret Sharing Based. Throughout our presentation the de-
3.1.1
fault representation of encrypted data uses the replicated secret
sharing technique of Araki, et al. [9]. A secret value x ∈ Z2k is
shared by sampling three random values x1, x2, x3 ∈ Z2k such
that x = x1 + x2 + x3. These shares are distributed as the pairs
{(x1, x2),(x2, x3),(x3, x1)}, where party i holds the ith pair. Such a
sharing will be denoted as(cid:74)x(cid:75)A. Sometimes, for brevity, we refer
to shares of(cid:74)x(cid:75)A as the tuple (x1, x2, x3), though we still mean the
replicated secret sharing where each party holds a pair of shares.
First, observe that any two out of the three parties have sufficient
information to reconstruct the actual value x. This immediately
implies that such a secret sharing scheme can tolerate up to a single
corruption. All of the protocols presented will achieve the same
threshold. We briefly review these building blocks here. To reveal
a secret shared value to all parties, party i sends xi to party i + 1,
and each party reconstructs x locally by adding the three shares.
To reveal the secret shared value only to a party i, party i − 1 sends
xi−1 to party i who reconstructs the secret locally.
Arithmetic operations can now be applied to these shares. To
are with respect to the group Z2k . To multiply two shared values
First observe that, xy = (x1 + x2 + x3)(y1 +y2 +y3). Collectively the
that z1 := x1y1 +x1y2 +x2y1 +α1, z2 := x2y2 +x2y3 +x3y2 +α2, z3 :=
x3y3 + x3y1 + x1y3 + α3. For now ignore the terms α1, α2, α3 and
add two values(cid:74)x(cid:75) +(cid:74)y(cid:75) all parties locally compute(cid:74)x(cid:75) +(cid:74)y(cid:75) =
(cid:74)x + y(cid:75) := (x1 + y1, x2 + y2, x3 + y3). Addition or subtraction of a
public constant with a shared value(cid:74)x(cid:75) ± c =(cid:74)x ± c(cid:75) can also be
done by defining the three shares of(cid:74)x ± c(cid:75) as (x1 ± c, x2, x3). To
multiply a shared value(cid:74)x(cid:75) with a public constant c we can define
the shares of(cid:74)cx(cid:75) as (cx1, cx2, cx3). Note that all of these operations
(cid:74)x(cid:75) and(cid:74)y(cid:75) together, the parties must interactively compute(cid:74)xy(cid:75).
parties can compute all such cross terms. We define(cid:74)z(cid:75) =(cid:74)xy(cid:75) such
observe that party i can locally compute zi given its shares of(cid:74)x(cid:75)
and(cid:74)y(cid:75). However, we require that all parties hold two out of the
three shares. To ensure this, the protocol specifies that party i sends
zi to party i − 1. We call this sending operation re-sharing. The
additional terms α1, α2, α3 are used to randomize the shares of z.
We therefore require that they be random elements of Z2k subject
to α1 +α2 +α3 = 0. Each party knows exactly one of the three values.
Such a triple is referred to as a zero sharing and can be computed
without any interaction after a one time setup[9].
The shares of(cid:74)x(cid:75) are then defined as (x1, x2, x3) := (α1 + x, α2, α3).
If, for example, party 1 wishes to construct a sharing of its private
input x, the parties first generate another zero sharing α1, α2, α3.
The sharing of x is completed by having party i send the share xi
to party i − 1. In the case of a malicious adversary, additional care
must be taken to ensure these operations are performed correctly.
For more details on these we refer to [28].
arithmetic sharing using the notation(cid:74)x(cid:75)A. The latter case will
3.1.2 Arithmetic vs. Binary sharing. Later we will make use of two
different versions of the above protocols. The first will correspond
to the case of k = 64 or some suitably large value which supports
traditional arithmetic operations such as +,-,*. We refer to this as
be for k = 1 where the binary operations ⊕,∧ correspond to +,*.
The advantage of a binary representation is that it can be more
flexible and efficient when computing functions that can not easily
be framed in terms of modular addition and multiplication. We refer
to this as binary sharing and use the notation(cid:74)x(cid:75)B.
3.1.3 Yao sharing.
Session 1B: PrivacyCCS’18, October 15-19, 2018, Toronto, ON, Canada38Two-party sharing. In the two-party setting, Yao’s garbled circuit
protocol allows a garbler to encode a boolean function into a garbled
circuit that is evaluated by a second party, called the evaluator.
More concretely, the garbling scheme first assigns two random keys
0
1
w to each wire w in the circuit corresponding to values 0 and 1
k
w, k
for that wire. Each gate in the circuit is then garbled by encrypting
each output wire key using different combinations (according to
the truth table for that gate) of input wire keys as encryption keys.
The evaluator obtains the keys corresponding to input wires to
the circuit which enables him to decrypt exactly one ciphertext in
each gabled gate and learn the corresponding output wire key. The
evaluator can decode the final output give a translation table that
maps the circuit’s final output wire keys to their real values.
Various optimizations to this basic garbling idea have been in-
troduced over the years, the most notable of which are the point-
and-permute [11], Free-XOR [36] and the half-gate [59] techniques.
These optimizations require some modifications to how the keys
are generated. In particular, the free-XOR techniques requires that
w ⊕ ∆ for every wire w where ∆ is a global random (secret)
1
0
w = k
k
string. To use the point-and-permute technique, we need to let the
least significant bit of ∆ to be 1, i.e. ∆[0] = 1. The least significant
bit of each key (pw⊕i = ki
w[0]) is then referred to as the permutation
bit. As discussed in the two-party ABY framework [24], two-party
Yao’s sharing of an input bit x for wire w, can be seen as one party
holding k
0
w and ∆, while the other party holds kx
w.
Three-party sharing. Mohassel et al. [42], extend Yao’s garbled
circuit protocol to the three-party setting with one corruption,
and obtain security against a malicious adversary with the cost
comparable to that of the semi-honest two-party Yao’s protocol.
The high-level idea is as follows. Party 1 plays the role of evaluator
and parties 2,3 play the role of garblers. The two garblers exchange
a random seed that is used to generate all the randomness and keys
required by the garbled circuit. They separately generate the garbled
circuit and send their copy to the evaluator. Since at least one
garbler is honest, one of the garbled circuits is computed honestly.
The evaluator can enforce honest garbling behavior by checking
equality of the garbled circuits.
The Yao sharing in the three-party setting, denoted by(cid:74)x(cid:75)Y,
can be seen as the evaluator holding kx
w and the two garblers
holding (k
w, ∆). In the semi-honest case, a garbler shares its in-
0
w ⊕ x∆ to the evaluator. In the malicious
0
put bit x by sending k
case, both garblers send commitments to both keys (permuted), i.e.
w), Comm(k¬b
Comm(kb
w ) to the evaluator and the garbler who is
sharing its input sends the opening for one of the commitments.
The evaluator checks that the two pairs of commitments are equal
(the same randomness is used to generate and permute them) and
that the opening succeeds. The evaluator could share its input by
performing an oblivious transfer with one of the garblers to obtain
one of the two keys. Mohassel et al. remove the need for OT by
augmenting the circuit such that each input wire corresponding
to evaluator is split into two inputs bits that XOR share the origi-
nal input. The circuit first XORs these two bits (for free) and then
computes the expected function. The evaluator shares its input bit
x by generating two random bits x2 and x3 where x = x2 ⊕ x3
and sending xi to party i. The party i then shares xi as it would
share its own input, except that there is no need to permute the
commitments since party 1 knows the xis.
4 SECURITY MODEL
We use the same security model and architecture as SecureML [43]
except that we extend it to the three party case with an honest
majority and consider both semi-honest and malicious adversaries.
In particular, data owners (clients) secret share their data among
three servers who perform 3PC to train and evaluate models on
the joint data. We observe that security in this model reduces to
standard security definitions for 3PC between the three servers.
Hence, we follow the same security definitions and refer to [9] and
[28] for a formal description of these adversarial settings. Since all
our building blocks are reduced to the composition of existing 3PC
building blocks, their security is implied via standard composition
theorems [17].
5 OUR FRAMEWORK
In this section, we construct efficient three-party protocols that
form the building blocks of our protocols for training linear and
logistic regression, and neural network models. We also provide a
general framework for performing mixed computation on shared
data, i.e. an equivalent of the ABY framework [24] for the three-
party setting.
5.1 Fixed-point Arithmetic
A fixed point value is defined as a k bit integer using twos-complement
representation where the bottom d bits denote the decimal, i.e. for
positive values bit i denotes the (i − d)th power of 2. Addition
and subtraction can be performed using the corresponding inte-
ger operation since the results are expected to remain below 2k.
Multiplication can also be performed in the same manner but the
number of decimal bits doubles and hence must be divided by 2d
to maintain the d decimal bit invariant.
5.1.1 Why technique of [43] fails. We start by reviewing the two-