can potentially fall victim to TOCTOU attacks due to control
ﬂow violation which occurs at a strategic point before or
during the attestation code execution.
There are 3 requirements for a TOCTOU attack to be
performed against a trusted computing system:
1) The attacker must know when the measurement is
possible after the measurement has ﬁnished.
These requirements are a useful conceptual framework for
examining trusted computing systems, because if any one
of these conditions is broken, the TOCTOU attack will not
succeed with 100% probability. We differentiate guaranteed
success TOCTOU attacks vs. probabilistic TOCTOU attacks
because real world guaranteed attacks more devastatingly
undercut
the trustworthiness of trusted computing. And
when the attacker can be forced into a probabilistic TOC-
TOU attack, defenders are forcing a race condition back
on the attacker. Because whatever capability the attacker
temporarily removes degrades his control, and the possibility
of detection increases. For instance an attacker who was
capturing keystrokes may miss important characters; an
attacker who was hiding ﬁles may have them detected by 3rd
party on-access scanning; or an attacker who was denying
execution to security programs by terminating them before
they launch could have an execution slip through.
A. Countering requirement 1
Virtualized security systems [8] [26] [19] or those us-
ing System Management Mode (SMM) [17] [1] typically
counter requirement 1 only by their assumptions. They
assume the attacker cannot reside at
the same privilege
level as the defender (that is the hypervisor layer). They
utilize the opportunity for the VM to be frozen in place and
measured at intervals unknown to the attacker. On the other
hand, when measurement takes place on demand in response
to actions performed inside the virtualized environment, it
may be possible for the attacker to remove modiﬁcations
before the event is triggered. Tools like Copilot [15], which
perform measurement from outside of the CPU and have
direct memory access can also measure memory in a way
where the attacker cannot know when the measurement is
about to take place.
For self-checking systems where the attacker is assumed
to be at the same privilege as the defender, we do not believe
it is possible to fully counter requirement 1 with just the
techniques proposed to date. This is because it is seemingly
always possible for an attacker to know when and what type
of measurement is about to begin. This can be achieved by
placing an inline hook into the self-check code at a location
251
on the path immediately prior to the self-check reading
any of its own memory. The problem is one of obvious
and deterministic control ﬂow paths to the self-check code.
Even if the code’s capability could be expanded to guarantee
runtime control ﬂow integrity, as we have started to do, it
can no more guarantee control ﬂow integrity before it runs
than it can guarantee code integrity before it runs.
An example of future work to counter this requirement
would be to augment control ﬂow with a system like
TEAS [5]. By injecting agents on the ﬂy, an attacker cannot
automatically analyze the code fast enough to recognize that
they are providing new control ﬂow to the existing self-
check mechanism. These agents could perform the prolog
of a self-check, and incorporate an initial measurement of
the existing self-check agent before jumping into a random
block of the existing self-check function and allowing it to
run to completion. In this way the agent which is pushed
to a system just in time would be able to detect the code
integrity modiﬁcations that the existing self-check function
cannot detect itself.
B. Countering requirement 2
Some approaches have implicitly attempted to counter
requirement 2 by measuring or proposing to measure all of
memory [21] [4] [7]. It was also suggested [7] to page out
and overwrite all memory that is not used for the veriﬁcation
function. On the face of it, this would seem to counter
requirement 2. However that assumes that every single page
of memory that is subsequently checked when it is read back
in can be validated. In practice we do not believe it will
be possible to apply whitelisting to dynamically allocated
memory pages, which can contain attacker code, and we do
not think it is likely that a blacklist would exist for malware
sophisticated enough to be targeting self-check functions.
For attestation of desktop systems this would not require
abandoning the kernel, but may require augmenting a ker-
nel agent with another smaller root of trust. Systems like
PioneerNG are implemented in SMM. While conceptually
SMRAM is meant to be used as a small, isolated memory
region, it is only isolated from the outside. An attacker inside
can access all system memory. That would mean even self-
checking code in these locations would still be vulnerable to
an inline hook placed at their start, followed by the attacker
removing himself to a safe location in physical memory. A
single un-measured function pointer used by 3rd party code
would then allow the attacker back into SMM.
Therefore approaches which attempt to measure all of
memory to prevent TOCTOU attacks would seem to only
work when all memory under measurement can be isolated
and controlled. Systems like Flicker [11] which use Intel
Trusted Execution Technology, or SecVisor [19] which uses
hardware support for virtualization plus an I/O Memory
Management Unit, may be required to counter the attacker
having an unmeasured location to hide in.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:23 UTC from IEEE Xplore.  Restrictions apply. 
C. Countering requirement 3
Because kernel-mode self-checksumming systems have
difﬁculty with countering the previous two requirements
without signiﬁcant assumption changes, we have made some
improvements for countering requirement 3. We focused on
removing as many generic, deterministic, TOCTOU rein-
stallation avenues as possible. The ability for an attacker
to corrupt return addresses and have our code return to
attacker code undetected was one area we mitigated. Because
of our use of imported functions, an attacker could gain
control soon after the self-check is done by placing an inline
hook or an IAT hook into code we call. Our extension
of the minichecksum mechanism to cover arbitrary ranges
helped mitigate this. And the existing technique of placing
checksum data onto the stack so that interrupts destroy it
is another mechanism that tries to maintain control ﬂow
integrity in addition to the existing code integrity. Although
software-based attestation constructions are built primarily
for code integrity [14], if they do not make these inclusions
of control ﬂow integrity, they remain vulnerable to TOCTOU
attacks.
However there still remain other mechanisms for the
attacker to perform a TOCTOU and regain control soon after
our code releases control of the processor. For instance we
have implemented a TOCTOU attack which uses a Windows
DPC to schedule attacker code to run. The attacker places
himself as ﬁrst to be removed from the DPC queue, which
begins emptying very soon after control is released by our
kernel module. When the attacker code runs, it reinstalls
the hook that allows him to gain control when attestation
is about to begin. This is a simple and effective way for
the attacker to never have his modiﬁcations detected by
the attestation mechanism. It is of course a losing game to
engage in an arms race and have the attestation mechanism
measure the DPC queue and every other way the attacker
can reinstall himself.
Future work can combat this by making it difﬁcult for
the attacker to know the true end time of the self-check
function. Such an approach could be achieved by having
multiple CPUs invoking the same self-check function in
parallel. Existing approaches such as PioneerNG & MT-
SRoT [28] try to have multiple CPUs ﬁnish their checksum
as close to the same time as possible. Instead checksum
completion could be displaced in time so that when one self-
check completes, others are still running on other CPUs. If
an attacker has set himself to reinstall as soon as possible
after the self-check is done on one CPU, the other CPUs
may end up reading his reinstallation of his modiﬁcations.
It would then also be desirable to randomize the order in
which CPUs are invoked, so that the attacker cannot know
which CPU will ﬁnish last, and simply schedule himself
to only reinstall after that CPU’s self-check ﬁnishes. While
we believe there will always be the possibility for attacks
to use TOCTOU attacks with course granularity reinstall
(e.g. a conceptual “sleep(10)”), if the defender can force
the attacker to temporarily relinquish control, it is a higher
measure of success than is achieved today. The defender has
then opened a window of time in which the attacker is more
vulnerable to detection and removal.
VI. CONCLUSION
In this paper we have shown the results of independent
implementations of both software and hardware timing-
based attestation systems. We have shown that an attestation
system for a commodity OS can compensate for ASLR
effects, does not need to know how to talk directly to NIC
hardware, and has attacker overhead which is detectable
over 10 network links. We have also shown that contrary
to expectations, TPMs of the same model and manufacturer
return a different number of ticks for computing the same
function. This means that unlike software timing-based
attestation, no single “expected” baseline can be set for
different hosts; each host must be baselined independently.
We have also clariﬁed that the majority of generic attacks
against timing-based attestation systems to date are in fact
TOCTOU attacks. We described the conditions necessary for
an attacker to achieve a TOCTOU attack, as well as areas
of future work to create generic countermeasures against
TOCTOU attacks.
We currently consider timing-based remote attestation to
be in its infancy, and it looks much like the early days
of cryptography, where heuristics abounded. Even though
cryptography has been formalized to the point of having
provably secure systems, these are not actually the systems
being used on a day to day basis. Instead, algorithms like
Rijndael were accepted for the AES standard based on
its resistance to established attack techniques, as well as
tradeoffs such as performance. In the same way we believe
that timing-based attestation mechanisms can be made more
robust through increased research and implementation in this
area. To this end we will be making our current reference
implementation openly available4, in the hope that others
will help further improve the state of the art for remote
timing-based attestation.
REFERENCES
[1] A. M. Azab, P. Ning, Z. Wang, X. Jiang, X. Zhang, and
N. C. Skalsky. Hypersentry: enabling stealthy in-context
measurement of hypervisor integrity. In Proceedings of the
ACM conference on Computer and Communications Security,
CCS, pages 38–49, 2010.
[2] S. Bratus, N. D’Cunha, E. Sparks, and S. W. Smith. TOC-
In Proceedings of the
TOU, traps, and trusted computing.
International Conference on Trusted Computing and Trust in
Information Technologies, Trust, pages 14–32, 2008.
4http://code.google.com/p/timing-attestation
252
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:23 UTC from IEEE Xplore.  Restrictions apply. 
[3] C. Castelluccia, A. Francillon, D. Perito, and C. Soriente.
On the difﬁculty of software-based attestation of embedded
devices. In Proceedings of the ACM conference on Computer
and Communications Security, CCS, pages 400–409, 2009.
[17] A. Seshadri. A Software Primitive for Externally-veriﬁable
Untampered Execution and its Applications to Securing Com-
puting Systems. PhD thesis, Carnegie Mellon University,
2009.
[18] A. Seshadri, M. Luk, A. Perrig, L. van Doorn, and P. Khosla.
SCUBA: Secure code update by attestation in sensor net-
In Proceedings of the ACM workshop on Wireless
works.
security, WiSe, pages 85–94, 2006.
[19] A. Seshadri, M. Luk, N. Qu, and A. Perrig. Secvisor: a
tiny hypervisor to provide lifetime kernel code integrity for
commodity oses. In Proceedings of ACM SIGOPS symposium
on Operating systems principles, SOSP, pages 335–350, 2007.
[20] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and
P. Khosla. Pioneer: verifying code integrity and enforcing
untampered code execution on legacy systems. In Proceed-
ings of the ACM symposium on Operating systems principles,
SOSP, pages 1–16, 2005.
[21] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla. SWATT:
Software-based attestation for embedded devices. In Proceed-
ings of the IEEE Symposium on Security and Privacy, May
2004.
[22] A. Shah, A. Perrig, and B. Sinopoli. Mechanisms to provide
In Proceedings of
integrity in SCADA and PCS devices.
the International Workshop on Cyber-Physical Systems -
Challenges and Applications (CPS-CA), June 2008.
[23] M. Shaneck, K. Mahadevan, V. Kher, and Y. Kim. Remote
In ESAS,
software-based attestation for wireless sensors.
pages 27–41, 2005.
[24] U. Shankar, M. Chew, and J. D. Tygar. Side effects are not
In Proceedings of the
sufﬁcient to authenticate software.
conference on USENIX Security Symposium, SSYM, pages
7–7, 2004.
[25] L. Ventura. Iperf on windows. 2010, http://linhost.info/2010/
02/iperf-on-windows/. Accessed: 10/21/2011.
[26] Zhi Wang, Xuxian Jiang, Weidong Cui, and Peng Ning.
Countering kernel rootkits with lightweight hook protection.
In Proceedings of the 16th ACM conference on Computer
and communications security, CCS ’09, pages 545–554, New
York, NY, USA, 2009. ACM.
[27] G. Wurster, P. C. van Oorschot, and A. Somayaji. A generic
attack on checksumming-based software tamper resistance. In
Proceedings of the IEEE Symposium on Security and Privacy,
pages 127–138, 2005.
[28] Q. Yan, J. Han, Y. Li, R. H. Deng, and T. Li. A software-based
root-of-trust primitive on multicore platforms. In Proceedings
of the ACM Symposium on Information, Computer and Com-
munications Security, ASIACCS, pages 334–343, 2011.
[4] Y. Choi, J. Kang, and D. Nyang. Proactive code veriﬁcation
In Proceedings of the
protocol in wireless sensor network.
International Conference on Computational Science and its
Applications - Volume Part II, ICCSA, pages 1085–1096,
2007.
[5] J. A. Garay and L. Huelsbergen. Software integrity protection
using timed executable agents. In Proceedings of the ACM
Symposium on Information, Computer and Communications
Security, ASIACCS, pages 189–200, 2006.
[6] Geeks3D.
Aogenmark 1.3.0: Simple multi-core cpu
2011, http://www.geeks3d.com/20110513/
Ac-
benchmark.
aogenmark-1-3-0-simple-multi-core-cpu-benchmark.
cessed: 10/21/2011.
[7] M. Jakobsson and K.-A. Johansson. Practical and secure
software-based attestation. In Workshop on Lightweight Secu-
rity Privacy: Devices, Protocols and Applications (LightSec),
pages 1 –9, March 2011.
[8] X. Jiang, X. Wang, and D. Xu. Stealthy malware detection
through VMM-based ”out-of-the-box” semantic view recon-
struction. In Proceedings of the ACM conference on Computer
and Communications Security, CCS, pages 128–138, 2007.
[9] Y. Li, J. M. McCune, and A. Perrig. SBAP: Software-Based
In Proceedings of the 3rd In-
Attestation for Peripherals.
ternational Conference on Trust and Trustworthy Computing
(Trust), June 2010.
[10] Y. Li, J. M. McCune, and A. Perrig. VIPER: Verifying the
In Proceedings of the
integrity of peripherals’ ﬁrmware.
ACM Conference on Computer and Communications Security
(CCS), October 2011.
[11] J. M. McCune, B. Parno, A. Perrig, Michael K. Reiter, and
Flicker: An execution infrastructure for
In Proceedings of the ACM European
Hiroshi Isozaki.
tcb minimization.
Conference in Computer Systems (EuroSys), April 2008.
[12] Microsoft.
(ndis 5.1)
Ndis drivers
(windows driver
kit). September 7th 2011, http://msdn.microsoft.com/en-us/
Library/ff556938(v=VS.85).aspx. Accessed: 11/01/2011.
[13] W. D. Norcott and D. Capps. Iozone ﬁlesystem benchmark.
20106, http://www.iozone.org/. Accessed: 10/21/2011.
[14] A. Perrig and L. van Doorn.
Refutation of on
software-based attestation of embed-
2010, http://sparrow.ece.cmu.edu/group/pub/
the difﬁculty of
ded devices.
perrig-vandoorn-refutation.pdf. Accessed: 11/01/2011.
[15] N. L. Petroni, Jr., T. Fraser, J. Molina, and W. A. Arbaugh.
Copilot - a coprocessor-based kernel runtime integrity mon-
In Proceedings of the 13th conference on USENIX
itor.
Security Symposium - Volume 13, SSYM, pages 13–13, 2004.
[16] D. Schellekens, B. Wyseur, and B. Preneel. Remote attestation
on legacy operating systems with trusted platform modules.
Electron. Notes Theor. Comput. Sci., 197:59–72, February
2008.
253
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:48:23 UTC from IEEE Xplore.  Restrictions apply.