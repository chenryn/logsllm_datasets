### Log-Based Design

**USENIX Association**
26th USENIX Security Symposium, Page 817

#### Figures and Descriptions

- **Figure 6:** The virtual page has been made inaccessible: accesses to objects A, B, or C would cause a fault.
- **Figure 7:** With one object per page, we can selectively disable object B.
- **Figure 8:** Each object has its own shadow virtual page, which all map to the same physical frame.

#### Memory Management and Virtual Pages

Recall that objects (and physical memory) are accessed via virtual addresses, which are translated by the MMU into physical addresses. By removing the mapping or changing the page permissions, we can make a virtual page inaccessible; the underlying physical memory can then be mapped to a different virtual address (changed lock) for reuse. A drawback is that making a virtual page inaccessible renders all objects on that page—often a non-trivial number, since pages are 4KB or larger—inaccessible (Figure 6). Placing one object per page (Figure 7) is wasteful of memory resources: it uses more memory and strains the cache and the TLB.

It is not strictly necessary to use page permissions to enforce page inaccessibility after deallocation. In principle, we could maintain a hashtable of live pointers and instrument all pointer dereferences to check if the pointer is still live, trading off instrumentation for system calls. This would still have less overhead than an explicit lock-and-key scheme, as we would not need to instrument pointer arithmetic.

#### Example Systems

- **Electric Fence [9]:** Implements this scheme by placing one object per physical frame. Its high physical memory usage makes it impractical for anything other than debugging.
- **Dhurjati and Adve [23]:** Overcame the shortcoming through virtual aliasing. Normally, `malloc` might place multiple objects on one virtual page, referred to as the canonical virtual page. For each object on the canonical virtual page, they create a shadow virtual page that is aliased onto the same underlying physical page frame. This allows each object to be disabled independently (by changing the permissions for the corresponding shadow page), while using physical memory/cache more efficiently than Electric Fence (Figure 8). However, this still requires many syscalls and increases TLB pressure. Furthermore, creating shadows introduces compatibility issues with `fork` (Section 5.1).

The physical memory overhead—one page table entry, one kernel virtual memory area struct, plus some user-space allocator metadata, per object—is proportional to the number of live objects. We expect this to be more efficient than other classes of lock-and-key schemes, which have overhead proportional to the number of pointers (albeit with a smaller constant factor). Some engineering is required to avoid stateholding of `munmap`'ed page table entries (Section 8).

### Summary of Lock and Key Schemes

Table 1 compares the plausible lock-and-key schemes. Implicit lock-and-key schemes that change the lock (i.e., one object per virtual page) are advantageous by having no overhead for any pointer arithmetic and no direct cost (barring TLB and memory pressure) for pointer dereferences. Furthermore, the core technique does not require application source code: for programs using the standard allocator, we need only change the glibc `malloc` and `free` functions. However, Dhurjati and Adve’s full scheme requires application source code to apply their static analysis optimization, which allows them to reuse virtual addresses when a pool is destroyed.

### Baseline Oscar Design

We will develop the shadow virtual pages idea in a direction that does not require source-code analysis, with less stateholding of kernel metadata for freed objects, and with better compatibility with `fork`. We focus on glibc and Linux.

While we have argued that page-permissions-based protections should require less instrumentation than newer schemes, there has been no good data on the overhead of shadows (without reliance on static analysis), let alone quantitative comparisons with recent schemes. In the first part of this paper, we quantify and predict the overhead when using only shadows. These measurements informed our approach for reducing the overhead, which are described in the second part of this paper.

To help us improve the performance of shadow-page-based schemes, we first measure their costs and break down the source of overhead. Shadow-page schemes consist of four elements: modifying the memory allocation method to allow aliased virtual pages, inline metadata to record the association between shadow and canonical pages, syscalls to create and disable shadow pages, and TLB pressure. We measure how much each contributes to the overhead, so we can separate out the cost of each.

It is natural to hypothesize that syscall overhead should be proportional to the number of `malloc`/`free` operations, as page-permissions-based schemes add one or two syscalls per `malloc` and `free`. However, the other costs (TLB pressure, etc.) are less predictable, so measurements are needed.

Our baseline design [23] uses inline metadata to let us map from an object’s shadow address to its canonical address. When the program invokes `malloc(numBytes)`, we allocate instead with `internal_malloc(numBytes + sizeof(void*))` to allocate an object within a physical page frame and then immediately perform a syscall to create a shadow page for the object. The object’s canonical address is stored as inline metadata within the additional `sizeof(void*)` bytes. This use of inline metadata is transparent to the application, unlike with plus-size pointers. Conceivably, the canonical addresses could instead be placed in a disjoint metadata store (similar to CETS), improving compactness of allocated objects and possibly cache utilization, but we have not explored this direction.

### Measurement Methodology

We quantified the overhead by building and measuring incrementally more complex schemes that bridge the design gap from glibc’s `malloc` to one with shadow virtual pages, one overhead factor at a time.

- **First Scheme:** Changes the memory allocation method. As background, `malloc` normally obtains large blocks of memory with the `sbrk` syscall (via the macro `MORECORE`), and subdivides it into individual objects. If `sbrk` fails, `malloc` obtains large blocks using `mmap(MAP_PRIVATE)`. (This fallback use of `mmap` should not be confused with `malloc`’s special case of placing very large objects on their own pages.) We cannot create shadows aliased to memory that was allocated with either `sbrk` or `mmap(MAP_PRIVATE)`; the Linux kernel does not support this. Thus, our first change was `MAP SHARED` arenas: we modified `malloc` to always obtain memory via `mmap(MAP_SHARED)` (which can be used for shadows) instead of `sbrk`. This change unfortunately affects the semantics of the program if it `fork()`s: the parent and child will share the physical page frames underlying the objects, hence writes to the object by either process will be visible to the other. We address this issue in Section 5.1.
- **Padding Further:** `MAP SHARED` with changes `malloc` to enlarge each allocation by `sizeof(void*)` bytes for the canonical address. We do not read or write from the padding space, as the goal is simply to measure the reduced locality of reference.
- **Create/Disable Shadows:** Creates and disables shadow pages in the `malloc` and `free` functions using `mremap` and `mprotect(PROT_NONE)` respectively, but does not access memory via the shadow addresses; the canonical address is still returned to the caller. To enable the `free` function to disable the shadow page, we stored the shadow address inside the inline metadata field (recall that in the complete scheme, this stores the canonical).
- **Use Shadows:** Returns shadow addresses to the user. The canonical address is stored inside the inline metadata field. This version is a basic reimplementation of a shadow-page scheme.

All timings were run on Ubuntu 14.04 (64-bit), using an Intel Xeon X5680 with 12GB of RAM. We disabled hyper-threading and TurboBoost for more consistent timings. Our “vanilla” `malloc`/`free` was from glibc 2.21. We compiled the non-Fortran SPEC CPU2006 benchmarks using gcc/g++ v4.8.4 with `-O3`. We configured libstdc++ with `--enable-libstdcxx-allocator=malloc`, and configured the kernel at run-time to allow more virtual memory mappings.

We counted `malloc` and `free` operations using `mtrace`. We placed `mtrace` at the start of `main`, which misses a small number of allocations (e.g., static initializers and constructors for global C++ objects), but these are insignificant.

### Results

The overhead measurements of the four incrementally more complete schemes are shown in Figure 9 for 15 of the 19 SPEC CPU2006 C/C++ benchmarks. The remaining four benchmarks (perlbench, dealII, omnetpp, xalancbmk) exhaust the physical memory on the machine when creating/disabling shadows, due to the accumulation of vm area structs corresponding to `mprotect`'ed pages of "freed" objects. We therefore defer discussion of them until the following section, which introduces our improvements to the baseline design.

Even for the complete but unoptimized scheme (Use shadows), most benchmarks have low overhead. `gcc` and `sphinx` have high overhead due to creating/destroying shadows, as well as using shadows. `astar` and `povray` have a noticeable cost mainly due to using shadows, a cost which is not present when merely creating/disabling shadows; we infer that the difference is due to TLB pressure. Notably, `mcf`’s overhead is entirely due to `MAP SHARED` arenas, as is most of `milc`’s. Inline padding is a negligible cost for all benchmarks.

In Figure 10, we plot the run-time of creating/disabling shadows against the number of shadow-page-related syscalls. We calculated the y-values by measuring the runtime of Create/disable shadows (we used the high watermark optimization from Section 4 to ensure all benchmarks complete) minus `MAP SHARED` with padding: this discounts runtime that is not associated with syscalls for shadows. The high correlation matches our mental model that each syscall has an approximately fixed cost, though it is clear from `omnetpp` and `perlbench` that it is not perfectly fixed. Also, we can see that `perlbench`, `dealII`, `omnetpp`, and `xalancbmk` each create over 100 million objects, which is why they could not run to completion using the unoptimized implementation.

### Lowering Overhead of Shadows

The previous section shows that the overhead is due to `MAP SHARED`, creating/destroying shadows, and using shadows. The cost of using shadows—via TLB pressure—can be reduced with hardware improvements, such as larger TLBs (see Section 6.2). In this section, we propose, implement, and measure three optimizations for reducing the first two costs.

- **High Water Mark:** The naive approach creates shadows using `mremap` without a specified address and disables shadows using `mprotect(PROT_NONE)`. Since disabled shadows still occupy virtual address space, new shadows will not reuse the addresses of old shadows, thus preventing use-after-free of old shadows. However, the Linux kernel maintains internal data structures for these shadows, called vm area structs, consuming 192 bytes of kernel memory per shadow. The accumulation of vm area structs for old shadows prevented a few benchmarks (and likely many real-world applications) from running to completion. We introduce a simple solution. Contrary to conventional approaches, we use a high water mark to manage the creation and destruction of shadows more efficiently.
- **mremap Optimization:** Up to now, we have used `mremap` to create shadows. `mremap` can actually be used to both destroy an old mapping and create a new virtual address mapping (at a specified address) in a single system call. We use this ability to both destroy the old shadow mapping and create a new one (i.e., refresh a shadow) with one system call, thereby collapsing 2 system calls to 1 system call. This optimization depends on the high water mark optimization: if we called `mremap` with `old_size = new_size` without specifying a new_address, `mremap` would conclude that there is no need to change the mappings at all, and would return the old shadow virtual address.
- **Using MAP_PRIVATE When Possible:** As mentioned earlier, `MAP SHARED` is required for creating shadows, but sometimes has non-trivial costs. However, for large objects that `malloc` places on their own physical page frames, Oscar does not need more than one shadow per page frame. For these large allocations, Oscar uses `MAP_PRIVATE` mappings.

Implementing `realloc` correctly requires care. Our ordinary `realloc` wrapper is, in pseudo-code:
```c
munmap(old_shadow);
new_canonical = internal_realloc(old_canonical);
new_shadow = create_shadow(new_canonical);
```

This ensures that the old shadow is properly unmapped and a new shadow is created for the reallocated memory.