    /examples/jsp/error/comain.php?stuff='\x0puname -n 1,1&rem
    /main.php?logout="&rm;q92555225&rem,
    /main.php?stuff='&lt\x09>
    /examples/jsp/jsp2/jspx/cart_showererearm/esessions/soct/aselettor/cons/showers.php?dit=/etc/passwd\x00
    /scripts/sesscripts/dispoller.php?module=../etc/passwd\x00
    /main.php?logout="'del;q57391279&rem;
    /javascript/charsidi/phpmodit.cgi?lase=/etc/passwd\x00
    /ma
好像有那么点意思，但是用作实际payloads怕是不太行，用作fuzzing的话可能还行。当黑样本相对少的情况下，可以用来生成黑样本。
### N-gram
n-gram的基本思想是将文本的内容按照字节进行大小为N的滑动窗口操作，形成长度是N的字节片段序列。相较于直接对文本进行统计词频的词袋方法和TF-IDF方法，笔者觉得n-gram带有了一点语法语意的意思，所以一般都是词袋模型与TF-IDF和n-gram结合在一起使用。
### Bag of Words
词袋是一种统计某个词在一份文档中出现次数的算法，统计的词频数可以作为向量。
### TF-IDF
TF-IDF（term frequency-Inverse document frequency），词频-逆文档频率，加入逆文档频率一定程度上弥补了单纯词频方法的不足。  
Sklearn中有实现bag of words和tfidf方法的类：CountVectorizer和TfidfVectorizer，这两个类支持n-gram和char-level。  
比如七雨师傅文章《基于机器学习的web异常检测》基于单分类的模型就是综合利用char-level+n-gram+词频来特征向量化，再用one-class
svm建立单类去判断恶意url，还有一篇比较老的文章《Fwaf-Machine-Learning-driven-Web-Application-Firewall》也是用了类似的char-level+n-gram+tfidf方法来向量化，再用逻辑回归去检测恶意url。
    vectorizer = TfidfVectorizer(min_df = 0.0, analyzer="char", sublinear_tf=True, ngram_range=(1,3)) #converting data to vectors
    X = vectorizer.fit_transform(queries)
总的来说这char-level/word-level+n-gram+tfidf一把梭下来，可以解决很多问题了，包括较长文本和短文本，而安全中的很多关键信息都可以看成是长文本和短文本，比如域名请求，恶意代码，恶意文件。
## 神经网络语言模型
之前一直觉得神经网络不太友好，认为统计+自然语言处理中的统计语言模型+传统机器学习算法就可以很好地解决问题了，后来发现统计并不是万能的，神经网络能发挥的作用也很大，地方也很多，神经网络语言模型可以用来得到特征向量化中的词嵌入向量和做分类中的文本分类，神经网络算法也可以用来做分类等。神经网络训练语言模型中一个关键的点是word
embedding（词嵌入，词的分布式表示），基于神经网络语言模型的word embedding（为什么不是基于word
embedding的神经网络语言模型，这是因为word embedding是神经网络训练语言模型的副产品），相较于统计语言模型，相较于n-gram僵硬地体现语义，word
embedding更好地表达了语义，因为词的分布式表示这类方法都基于分布假设：词的语义由上下文决定，方法核心是上下文的表示以及上下文与目标词之间的关系的建模。举个例子，`这个可爱的
泰迪 舔了我的脸`和`这个可爱的 京巴
舔了我的脸`,用统计语言模型向量化，是两个不同的向量，是两个不同的句子，而神经网络语言模型根据上下文就会认为'泰迪'和'京巴'是同义词，从而判断这两个句子相似，产出的词嵌入向量也会相似。  
word embedding是一种概念，几个比较有名的word embedding方法包括：word2vec (Google), GloVe,
FastText (Facebook)，这些都是word embedding的实现手段。
### word2vec
webber师傅的文章《使用深度学习检测XSS》中使用了word2vec对已分词的文本进行向量化操作，又结合了LSTM、RNN、CNN三种算法检测XSS，对比SVM具有相对更好的泛化能力，说明神经网络算法较传统算法效果更佳，这可能是因为神经网络处理自然语言时可以识别词位置和词与词之间的关系（词的位置可以理解，词与词之间的关系不大懂，word2vec在向量化的时候不是已经解决了词与词之间关系的问题了吗，神经网络相较于SVM作为分类算法，应该只有词位置识别方面的提升吧）。
    model=Word2Vec(data_set,size=embedding_size,window=skip_window,negative=num_sampled,iter=num_iter)
    embeddings=model.wv
    embeddings['0']
    array([ 0.06356055, -0.19921948,  0.3356784 ,  0.15330128,  0.31883803,
           -0.6977568 ,  0.13472763, -0.39462927, -0.02651692,  0.97309947,
            1.0602285 , -0.07370728, -0.7246065 ,  0.06775752,  1.109377  ,
           -0.34577966,  0.42254186, -0.13481887, -0.24872543,  0.9183436 ,
           -1.4428607 , -0.10109176,  0.7711238 ,  0.67028177,  0.5955905 ,
           -0.18963751,  0.4201649 , -0.5992032 , -0.7136238 , -0.73436624,
           -0.3201587 ,  0.03583186, -0.68885845,  0.6004483 ,  0.4784428 ,
           -0.5739937 , -0.5768896 ,  0.6175184 , -0.3029108 ,  0.01734808,
            0.04042359,  0.76293707,  0.52277046,  0.4090956 ,  0.47357482,
           -0.5972618 ,  0.6259779 , -0.4994182 , -0.7634801 ,  1.6244601 ,
           -0.44355297,  0.7109609 ,  0.9468291 ,  0.2866395 ,  0.25637504,
           -0.53924143, -1.0911181 ,  0.4528728 , -0.43621692, -0.17867813,
           -1.0109166 , -0.44911763, -0.27320656,  0.23866493,  0.15664867,
            0.6409447 , -0.23423721, -0.1837575 ,  0.12108286,  0.11966047,
           -0.1325919 , -0.17609857,  1.1720567 , -0.50236636, -0.6033684 ,
           -0.71848387, -0.03429153, -1.2958349 , -0.93953687, -0.1944222 ,
           -0.32847854, -0.30283213,  0.7113749 , -0.7551358 ,  0.57266515,
            0.137828  ,  0.26785246,  0.51493126,  0.31305224,  0.40927702,
            0.11831629, -0.64689773,  0.15885882, -1.0438223 ,  0.19861834,
           -0.71079874,  0.02020928, -1.2383761 , -0.5699059 ,  0.6994687 ,
            0.4998379 ,  0.23062779,  0.68073547,  0.5560602 , -0.30087334,
            0.65758115,  0.06739169,  0.5384448 ,  0.29031464,  0.44346014,
           -0.53719974, -1.0638485 , -0.84434575, -0.0850719 ,  0.63114655,
            0.13165227, -1.0634255 ,  0.19242877, -0.02073849, -0.07671507,
           -0.21831703, -0.45622998, -0.163901  , -0.21681851, -0.23947589,
           -0.64384156, -0.41555977,  0.39319035], dtype=float32)
### fastText
fastText和word2vec都可以无监督学习词向量，fastText功能更强，不仅加入了字符级n-gram作为特征，还可以直接有监督学习进行文本分类，正如iami师傅的文章《使用fasttext进行DGA检测》
    ./fasttext supervised -input ./demo/data.train  -output dga.model
    ./fasttext test dga.model.bin test.valid 1
### TextCNN
TextCNN是利用卷积神经网络对文本进行分类的算法，适合做一些长文本分类，又想到了第三届阿里云安全算法第一名队伍就是利用了TextCNN算法对API长序列进行建模。单独的TextCNN在安全方面的应用感觉还比较局限。
# 总结
本文主要介绍了各种算法的功能以及在安全方面的应用，缺少对算法的原理和结构的介绍，也缺少对各种算法之间的横向对比，比如在特征工程阶段，使用神经网络语言模型提取的词嵌入向量特征和统计语言模型提取的统计特征的对比（猜测神经语言模型效果会更好）；在分类算法阶段，使用神经网络算法和使用传统算法的对比（猜测神经网络算法效果会更好）。笔者认为NLP是一种联系安全的媒介，仅从算法角度考虑，把NLP处理的越好，安全上也会处理的更好。从安全人员的角度来看，算法是一种工具和手段，当个"调包侠”和“调参怪”已经够用，重点还得从安全本身出发，深入理解攻击行为模式和数据。
# Ref
  * [sklearn.feature_extraction.text.TfidfVectorizer](https://scikit-learn.org/stable/modules/classes.html)
  * [Text Preprocessing](https://keras.io/zh/preprocessing/text/)
  * [自然语言处理中N-Gram模型介绍](https://zhuanlan.zhihu.com/p/32829048)
  * [正经机器学习之文本分类方法及词向量概述](https://zhuanlan.zhihu.com/p/34114022)
  * [[NLP] 秒懂词向量Word2vec的本质](https://zhuanlan.zhihu.com/p/26306795)
  * [fastText原理及实践](https://zhuanlan.zhihu.com/p/32965521)
  * [Text Summarization](https://iami.xyz/Text-Summarization-GF/)
  * [Text Classification With Keras And CNN](https://iami.xyz/Text-Classification-With-Keras-And-CNN/)
  * [word2vec和word embedding有什么区别?](https://www.zhihu.com/question/53354714)
  * [基于机器学习的web异常检测](https://www.freebuf.com/articles/web/126543.html)
  * [fuzzing随机性与char-rnn样本生成](https://iami.xyz/Talking-About-Char-RNN-And-fuzzing/)
  * [深度学习PHP webshell查杀引擎demo](https://www.cdxy.me/?p=788)
  * [Detecting Malicious Requests with Keras & Tensorflow](https://medium.com/slalom-engineering/detecting-malicious-requests-with-keras-tensorflow-5d5db06b4f28)
  * [LSTM识别恶意HTTP请求](https://www.cdxy.me/?p=775)
  * [使用深度学习检测XSS](http://www.webber.tech/posts/使用深度学习检测XSS/)
  * [使用深度学习检测XSS(续)](http://www.webber.tech/posts/使用深度学习检测XSS\(续)/)
  * [使用fasttext进行DGA检测](https://iami.xyz/DGA-Detect/)
  * [Web安全检测中机器学习的经验之谈](https://iami.xyz/ML-IN-Webshell-Detection-Advantages-And-Disadvantages/)
  * [Fwaf-Machine-Learning-driven-Web-Application-Firewall](https://github.com/faizann24/Fwaf-Machine-Learning-driven-Web-Application-Firewall)