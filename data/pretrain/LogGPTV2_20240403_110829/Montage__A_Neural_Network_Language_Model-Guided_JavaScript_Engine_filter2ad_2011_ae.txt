a random fragment selection, and (2) Markov model-driven
fragment selection.
The former approach is the baseline for Montage where
fragments are randomly appended instead of querying a
model. The latter approach uses a Markov model that makes
a prediction based on the occurrence history of the preceding
two fragments. Speciﬁcally, we tailored the code from [25] to
implement the Markov chain.
Additionally, we compared our approach against a
character/token-level RNN language model-guided selection.
It leverages an NNLM to learn the intrinsic patterns from
training instances, which is in common with ours. Recently
proposed approaches [11,16,32], which resort to an NNLM to
generate highly structured inputs, adopted an approach more
or less similar to this one.
Note that there is no publicly available character/token-
level RNN model to generate JS tests. Thus, we referenced the
work of Cummins et al. [11] to implement this approach and
trained the model from scratch. To generate test cases from
the trained model, we referenced the work of Liu et al. [32]
because their approach is based on the seed mutation like our
approach.
The random, Markov, and ch-RNN columns of Table 1 sum-
marize the number of crashes found by each approach. We
conducted ﬁve fuzzing campaigns, each of which lasted 72
hours; all the underlying experimental settings are identical
to those in §7.4. Note that we conducted resolving reference
errors and fed the same dataset as Montage when evaluating
the aforementioned three models. Montage outperformed the
random selection and character/token-level RNN methods in
the terms of ﬁnding crashes and security bugs; thus, yield-
ing p-values under 0.05, which suggests the superiority of
Montage with statistical signiﬁcance.
When comparing the metrics from release and debug build
between Montage and the Markov chain approach, Montage
performed better. Montage found more unique bugs in total as
well. However, the Mann Whitney U test deems the difference
insigniﬁcant. Nevertheless, we emphasize that Montage is ca-
pable of composing sophisticated subtrees that the Markov
chain easily fails to generate. For instance, Montage gener-
ated a JS test triggering CVE-2017-8729 by appending 54
fragments, which the Markov chain failed to ﬁnd. We provide
more details of this case in §7.7.1.
2624    29th USENIX Security Symposium
USENIX Association
0510150204060Time (Hours)# of Known CVEsMedianMaxMinFigure 11: Empirical CDF of the number of appended frag-
ments against JS tests causing crashes in ChakraCore.
To evaluate the effectiveness of the LSTM model, we fur-
ther analyzed the number of fragments Montage appended to
generate JS tests that caused ChakraCore 1.4.1 to crash in the
experiment from §7.4.
Figure 11 shows the cumulative distribution function (CDF)
of the number of inserted fragments against 169,072 and 5,454
JS tests causing crashes and known CVEs, respectively. For
90% of JS tests that caused the JS engine to crash, Mon-
tage only assembled fewer than 15 fragments; however, it
appended up to 52 fragments to generate 90% of JS tests
that found the known CVEs. This demonstrates that Montage
should append more fragments suggested by the model to
ﬁnd security bugs rather than non-security bugs. It also de-
notes that the random selection approach suffers from ﬁnding
security bugs. Note that Table 1 also accords with this result.
From the aforementioned studies, we conclude that the
LSTM model trained on fragments is necessary for ﬁnding
bugs in the JS engines.
Resolving reference errors. We evaluated the importance of
the reference error resolution step (recall §5.3.2) in ﬁnding
JS engine bugs. Speciﬁcally, we ran Montage with the same
settings as other approaches while letting it skip the reference
error resolution step but still leverage the same LSTM model.
The last column of Table 1 demonstrates that Montage ﬁnds
fewer bugs if the resolving step is not applied, denoting that
the error resolving step improves the bug-ﬁnding capability of
Montage. However, Montage still found more bugs than the
other state-of-the-art fuzzers and the random approach even
without the resolving step. Considering the random approach
also takes advantages of the error resolution step, the LSTM
model signiﬁcantly contributes to ﬁnding JS engine bugs.
Pass rate. One of the key objectives of Montage is to generate
a valid JS test so that it can trigger deep bugs in JS engines.
Thus, we further measured how the use of language models
affects the pass rate of generated codes. A pass rate indicates
whether generated test cases are indeed executed after passing
both syntax and semantic checking.
Figure 12 illustrates the pass rate of 100,000 JS tests gen-
erated by the four different approaches: Montage with and
without resolving reference errors, the random selection, and
the Markov model. We excluded the character/token-level
RNN approach because only 0.58% of the generated tests
Figure 12: The pass rate measured against four different ap-
proaches: Montage (ktop = 64) with and without resolving
reference errors, random selection, and Markov model. Mon-
tage without resolving reference errors is denoted by †.
were executed without errors. Such a low pass rate could be
one possible reason why this approach failed to ﬁnd many
bugs, as shown in Table 1. As Liu et al. [32] also stated in
their paper, we believe this result is attributed to the lack of
training instances and the unique characteristics inherent in
the regression test suite.
Note from the ﬁgure that resolving reference errors in-
creases the pass rate by 12.2%. As a result, this helped Mon-
tage to ﬁnd more bugs, as shown in Table 1. On the other
hand, the pass rates of the random selection and Markov
model-guided approach were 5.2% and 11% greater than that
of Montage, respectively. We manually inspected the JS tests
generated by the random selection and the Markov model-
guided approaches. We concluded that these differences stem
from appending a small number of fragments. For instance,
if a model always replaces one fragment, such as a string lit-
eral, from the seed ﬁle, all generated JS tests will be executed
without errors.
7.6 Field Tests
We evaluated the capability of Montage in ﬁnding real-world
bugs. We have run Montage for 1.5 months on the latest
production versions of the four major engines: ChakraCore,
JavaScriptCore, SpiderMonkey, and V8. For this evaluation,
we collected datasets from the repository of each JS engine
at the version of February 3, 2019. We additionally collected
165 PoCs that triggered known CVEs as our dataset. Then,
we trained the LSTM model for each JS engine.
Montage has found 37 unique bugs from the four major JS
engines so far. Among the found bugs, 34 bugs were from
ChakraCore. The remaining two and one bugs were from
JavaScriptCore and V8, respectively. We manually triaged
each bug and reported all the found bugs to the vendors. In
total, 26 of the reported bugs have been patched so far.
Especially, we reported three of the found bugs as security-
related because they caused memory corruptions of the tar-
get JS engines. The three security bugs were discovered in
ChakraCore 1.11.7, ChakraCore 1.12.0 (beta), and JavaScript-
Core 2.23.3, respectively. Note that all of them got CVE IDs:
CVE-2019-0860, CVE-2019-0923, and CVE-2019-8594. Par-
ticularly, we were rewarded for the bugs found in ChakraCore
USENIX Association
29th USENIX Security Symposium    2625
02550751000255075100# of Appended FragmentsCumulative Percent (%)CrashesCVEsMontage †MontageRandomMarkov020406080Pass Rate (%)with a bounty of 5,000 USD.
Our results demonstrate that Montage is capable of ﬁnding
37 real-world JS engine bugs, including three security bugs.
We further describe one of the real-world security bugs that
Montage found in §7.7.3.
7.7 Case Study
To show how Montage leverages the existing structure of the
regression test, we introduce three bugs that Montage found.
We show two bugs that Montage found in ChakraCore 1.4.1
from the experiment in §7.4. We then describe one of the real-
world security bugs found in the latest version of ChakraCore,
which is already patched. Note that we minimized all test
cases for ease of explanation.
1
2
3
4
5
6
7
8
9
10
11
7.7.1 CVE-2017-8729
( function () {
for ( var v0 in [{
v1 = class {} ,
v2 = 2010
}. v2 = 20 ]) {
for ([] in {
value : function () {} ,
writable : false
}){}
}
})();
1
2
3
4
5
6
7
8
9
10
11
Figure 13: A test code that triggers CVE-2017-8729 on
ChakraCore 1.4.1.
Figure 13 shows the minimized version of a gener-
ated test that triggers CVE-2017-8729 on ChakraCore
1.4.1. From its seed ﬁle, Montage removed the body of
FunctionExpression and composed a new subtree corre-
sponding to Lines 2-10. Particularly, Montage appended 54
fragments to generate the new test.
ChakraCore is supposed to reject the generated test be-
fore its execution because it has a syntax error in the
ObjectPattern corresponding to Lines 2-5. However, as-
suming the ObjectPattern to be an ObjectExpression,
ChakraCore successfully parses the test and incorrectly infers
the type of the property v2 to be a setter. Thus, the engine
crashes with a segmentation fault when it calls the setter in
Line 5. Interestingly, the latest version of ChakraCore still
executes this syntax-broken JS test without errors but does
not crash.
The original regression test checked the functionalities re-
garding a complicated ObjectPattern. Similarly, the gener-
ated test triggered a type confusion vulnerability while parsing
the new ObjectPattern. Therefore, we believe that this case
captures the design goal of Montage, which leverages an exist-
ing regression test and puts it in a different execution context
to ﬁnd a potential bug.
7.7.2 CVE-2017-8656
var v1 = {
’a ’: function () {}
}
var v2 = ’a ’;
( function () {
try {
} catch ([ v0 = ( v1 [ v2 ]. __proto__ ( 1, ’b ’ ))]) {
var v0 = 4;
}
v0 ++;
})();
Figure 14: A test code that triggers CVE-2017-8656 on
ChakraCore 1.4.1.
Figure 14 shows a test case generated by Montage
that triggers CVE-2017-8656 on ChakraCore 1.4.1. Its
seed ﬁle had a different AssignmentExpression as the
parameter of a CatchClause in Line 7. From the seed
AST, Montage removed a subtree corresponding to the
AssignmentExpression in Line 7 and mutated it by append-
ing eight fragments that the LSTM model suggested.
In the generated code, the variable v0 is ﬁrst declared as
the parameter of the CatchClause (Line 7) and then rede-
clared in its body (Line 8). At this point, the ChakraCore
bytecode generator becomes confused with the scope of these
two variables and incorrectly selects which one to initialize.
Consequently, the variable v0 in Line 8 remains uninitialized.
As the JS engine accesses the uninitialized symbol in Line 10,
it crashes with a segmentation fault.
We note that the seed JS test aimed to check possible scope
confusions, and the generated code also elicits a new vulnera-
bility while testing a functionality similar to the one its seed
JS test checks. Hence, this test case ﬁts the design objective
of Montage.
7.7.3 CVE-2019-0860
Figure 15 describes a JS test triggering CVE-2019-0860 on
ChakraCore 1.12.0 (beta), which we reported to the vendor.
Its seed ﬁle had a CallExpression instead of the statements
in Lines 3-4. From the seed JS test, Montage removed a
subtree corresponding to the BlockStatement of the func-
tion f0 and appended 19 fragments to compose a new block
of statements (Lines 2-4). Notably, Montage revived the
AssignmentExpression statement in Line 2, which is a re-
quired precondition to execute the two subsequent statements
and trigger the security bug.
The seed regression test was designed to test whether JS
engines correctly handle referencing the arguments property
2626    29th USENIX Security Symposium
USENIX Association
1
2
3
4
5
6
7
8
9
10
11
function f0 ( f, p = {}) {
f. __proto__ = p;
f. arguments = 44 ;
f. arguments === 44 ;
}
let v1 = new Proxy({} , {});
for ( let v0 = 0; v0 < 1000 ; ++ v0 ) {
f0 ( function () { ’ use strict ’;} , v1 );
f0 ( class C {} , v1 );
}
Figure 15: A test code that triggers CVE-2019-0860 on
ChakraCore 1.12.0 (beta).
of a function in the strict mode. For usual cases, JS engines do
not allow such referencing; however, to place the execution
context in an exceptional case, the seed JS test enables the
access by adding a Proxy object to the prototype chain of the
function f (Line 2). As a result, this new test is able to access
and modify the property value without raising a type error
(Line 3).
While performing the JIT optimization process initiated
by the for loop in Lines 8-11, ChakraCore misses a postpro-
cessing step of the property in Line 3, thus enabling to write
an arbitrary value on the memory. Consequently, the engine
crashes with a segmentation fault as this property is accessed
in Line 4.
Note that the generated test case triggers a new vulnera-
bility while vetting the same functionality that its seed tests.
Moreover, the GlobOpt.cpp ﬁle, which is the most frequently
patched ﬁle to ﬁx CVEs assigned to ChakraCore, was patched
to ﬁx this vulnerability. Therefore, this JS test demonstrates
that Montage successfully discovers bugs that it aims to ﬁnd.
8 Related Work
Fuzzing. There have been a vast volume of research on
generation-based fuzzing. Highly-structured ﬁle fuzzing [15,
42], protocol fuzzing [46, 47], kernel fuzzing [19, 28, 55], and
interpreter fuzzing [2, 6, 12, 38, 41, 56] are representative re-
search examples.
IMF infers the model of sequential kernel API calls to fuzz
macOS kernels [19]. Dewey et al. [12] generated code with
speciﬁed combinations of syntactic features and semantic
behaviors by constraint logic programming.
Godefroid et al. [16] trained a language model from a large
number of PDF ﬁles and let the model learn the relations
between objects constituting the PDF ﬁles. Their approach
of using a language model in generating tests is similar to
ours per se, but their approach is not directly applicable to
generating JS tests, which demands modeling complicated
control and data dependencies.
Cummins et al. [11] also proposed a similar approach. They
trained an LSTM language model from a large corpus of
OpenCL code. Unlike Montage, they trained the model at a
character/token-level, which does not consider the composi-