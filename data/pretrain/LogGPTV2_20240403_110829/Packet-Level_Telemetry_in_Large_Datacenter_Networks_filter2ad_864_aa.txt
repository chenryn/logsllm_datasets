title:Packet-Level Telemetry in Large Datacenter Networks
author:Yibo Zhu and
Nanxi Kang and
Jiaxin Cao and
Albert G. Greenberg and
Guohan Lu and
Ratul Mahajan and
David A. Maltz and
Lihua Yuan and
Ming Zhang and
Ben Y. Zhao and
Haitao Zheng
Packet-Level Telemetry in Large Datacenter Networks
Yibo Zhu1,2 Nanxi Kang1,3
Jiaxin Cao1 Albert Greenberg1 Guohan Lu1 Ratul Mahajan1
Dave Maltz1
Lihua Yuan1 Ming Zhang1 Ben Y. Zhao2 Haitao Zheng2
1Microsoft
2U. C. Santa Barbara
3Princeton University
ABSTRACT
Debugging faults in complex networks often requires cap-
turing and analyzing trafﬁc at the packet level. In this task,
datacenter networks (DCNs) present unique challenges with
their scale, trafﬁc volume, and diversity of faults. To trou-
bleshoot faults in a timely manner, DCN administrators must
a) identify affected packets inside large volume of trafﬁc; b)
track them across multiple network components; c) analyze
trafﬁc traces for fault patterns; and d) test or conﬁrm poten-
tial causes. To our knowledge, no tool today can achieve
both the speciﬁcity and scale required for this task.
We present Everﬂow, a packet-level network telemetry
system for large DCNs. Everﬂow traces speciﬁc packets
by implementing a powerful packet ﬁlter on top of “match
and mirror” functionality of commodity switches. It shufﬂes
captured packets to multiple analysis servers using load bal-
ancers built on switch ASICs, and it sends “guided probes”
to test or conﬁrm potential faults. We present experiments
that demonstrate Everﬂow’s scalability, and share experi-
ences of troubleshooting network faults gathered from run-
ning it for over 6 months in Microsoft’s DCNs.
CCS Concepts
•Networks → Network management;
Keywords
Datacenter network; failure detection; probe
1.
INTRODUCTION
From online commerce to smartphone apps, datacenter
networks (DCNs) are essential to large online services. DCNs
typically operate at high utilization levels, and even small
performance degradations or fault-induced downtime can lead
to millions of lost revenue. These high stakes argue for a
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is per-
mitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
SIGCOMM ’15, August 17–21, 2015, London, United Kingdom
c(cid:13) 2015 ACM. ISBN 978-1-4503-3542-3/15/08. . . $15.00
DOI: http://dx.doi.org/10.1145/2785956.2787483
proactive model of DCN management, where infrastructure
observes, analyzes, and corrects faults in near-real time.
Understanding and debugging faults in DCNs is challeng-
ing because faults come in all shapes and sizes. For example:
1. Some packets may experience abnormally high delay
between servers A and B, but it may not be clear which
of the many links is responsible.
2. Packets destined for a speciﬁc set of servers may be
dropped, even when the packet-drop counters at switches
exhibit no abnormality.
3. TCP connections to a VIP (Virtual IP) may encounter
intermittent timeouts, and traceroute probes to debug
the issue may be blocked by the load balancers.
4. Load may not be balanced among a group of ECMP
(Equal Cost Multi Path) links; the network administra-
tors do not know if this issue is due to ﬂow size differ-
ences or a deeper problem (e.g., a poor hash function).
The diagnosis of such DCN faults requires examining net-
work behavior at the granularity of packets. Problems such
as faulty interfaces or switch software bugs can produce seem-
ingly random failures that impact speciﬁc groups of packets
based on any combination of characteristics, such as route
taken in the network, packet headers, or timing. As a result
of their subtle effects, these failures are often difﬁcult to de-
bug through analyses that rely on ﬂow-level information [7],
aggregate counters [5, 36], or sampled trafﬁc [29]. We re-
fer to tracing, collection and analysis of packet-level trafﬁc
behavior as packet-level network telemetry.
Building a responsive packet-level telemetry system for
large DCNs is challenging for at least three reasons. First,
today’s DCNs carry unprecedented levels of network trafﬁc.
A large DCN usually has over 100,000 servers, each with a
10 to 40 Gbps network connection. At high utilization lev-
els, aggregate trafﬁc can easily exceed 100 Tbps. Analyzing
even tiny subsets of this data is intractable for today’s com-
modity switches, and moving traces to commodity servers
for analysis would congest or even disrupt the network.
Second, DCN faults often occur over multiple hops or
switches, and effective diagnosis requires intelligently trac-
ing small subsets of packets over the network, as well as
the ability to search the packet traces based on sophisticated
query patterns, e.g., protocol headers, sources and destina-
tions, or even devices along the path. This task is not only
akin to searching in the proverbial haystack for needles, but
for speciﬁc needles of arbitrary size, shape and color. Ex-
479isting systems that rely on packet-level analysis [14, 31] in-
discriminately trace packets; they cannot scale to the size of
large DCNs or search for packets based on complex patterns.
Finally, passive tracing alone, which captures an instan-
taneous snapshot of the network, has limited effectiveness.
The traces observed in the snapshot may not be enough to
identify whether the problem is transient or persistent, and
they may not provide enough information to localize the
problem. For example, when we see a packet trace stops
before reaching its ﬁnal destination, we may not be able to
tell if this is due to a random drop or a blackhole.
We present Everﬂow, a network telemetry system that pro-
vides scalable and ﬂexible access to packet-level informa-
tion in large DCNs. To consistently trace individual packets
across the network, Everﬂow uses “match and mirror." Com-
modity switches can apply actions on packets that match on
ﬂexible patterns over packet headers or payloads; we use this
functionality with mirroring packets to our analysis servers
as the action. By installing a small number of well-chosen
match-and-mirror rules means we can reap the beneﬁts of
packet-level tracing while cutting down the overhead by sev-
eral orders of magnitude. To quickly search for patterns in
large volumes of packet traces, we build a scalable trace
collection and analytics pipeline. We leverage switch-based
load balancing [12] to distribute tracing and processing across
multiple servers while preserving ﬂow-level locality for ef-
ﬁcient analysis. Finally, Everﬂow supports guided probes—
packets that are specially crafted and injected into the net-
work to follow preset paths. Guided probes help validate the
performance and behavior of individual devices or links.
Everﬂow has been deployed since August 2014 in part
of Microsoft’s DCN infrastructure, including a cluster of 37
switches and a larger cluster of 440 switches. Both clusters
carry a wide range of application trafﬁc. We have also de-
ployed Everﬂow selectively on-demand to other production
clusters to help debug tricky network faults. We capture our
deployment experiences by describing several representative
debugging cases in §7, including latency problems, packet
drops, routing loops, ECMP load imbalance, and protocol-
speciﬁc issues around RDMA (Remote Direct Memory Ac-
cess).
In each case, we describe the observed symptoms,
steps taken, and how a solution was found using Everﬂow.
We also perform detailed microbenchmarks to quantify
the performance of Everﬂow along key aspects, including
packet analysis rate, bandwidth and storage overhead, and
overall system scalability. Our evaluations consistently show
that all components of Everﬂow impose low overheads, and
scale well to large DCNs with 100 Tbps of trafﬁc.
In developing Everﬂow, we sought to address a real need
for scalable, packet-level telemetry which can debug faults
that are hard to tackle via conventional techniques. We prior-
itized usability and simplicity over functionality or features,
e.g., Everﬂow works on commodity switches and requires
no specialized hardware. Our experiences with Everﬂow
demonstrate that it scales well to large DCNs, and provides
signiﬁcant beneﬁts to network administrators.
2. PACKET-LEVEL NETWORK TELEMETRY
Operational DCNs comprise a wide range of hardware
and software components, including multiple types of switches,
load balancers, and servers dedicated for processing and stor-
age. Faults can and do arise from any single or combination
of components, which makes debugging quite challenging
in practice. In this section, we describe a number of sam-
ple faults that commonly occur in large DCNs, to illustrate
why conventional tools are insufﬁcient and why packet-level
network telemetry is useful.
drops not reported by the culprit
Silent packet drops:
switch (e.g., discard counters are zero). This situation may
occur due to software bugs or faulty hardware on the switch.
Although such drops can be detected on end hosts (e.g., by
monitoring TCP retransmissions), it is quite tricky to local-
ize the culprit switch using conventional tools because of the
large number of switches in DCNs. With consistent tracing
of speciﬁc packets across switches, we can immediately lo-
cate the last hop switch where the victim packets appear as
well as their expected next hop switch(es). We then send
guided probes to each next hop switch to conﬁrm the culprit.
the type of routing blackhole that does
Silent blackhole:
not show up in forwarding tables. Therefore it cannot be
detected by tools that examine forwarding table entries [22,
23]. Silent blackhole can happen due to corrupted entries in
TCAM tables. Packet-level network tracing will allow us to
detect and localize a silent blackhole similar to how we deal
with silent packet drops.
high latency for a ﬂow. It
Inﬂated end-to-end latency:
is yet another problem that is easy to detect by end hosts,
but can be difﬁcult to debug using conventional tools. With
packet-level network traces across switches, this problem
becomes trivial, since we can obtain hop-by-hop latencies
between the two end points.
routing problems
Loops from buggy middlebox routing:
caused by middleboxes instead of switches (or routers). This
may happen when a middlebox incorrectly modiﬁes a packet
and its forwarding behavior (see §7.3). Such a problem can-
not be found by examining the switch routing or forwarding
tables because the tables are all correct. Given the network
trace of a packet, we can easily identify such a problem as
the trace will violate basic invariants such as loop-freedom.
the problem of (5-tuple) ﬂows being
Load imbalance:
forwarded unevenly by a group of ECMP links. The naive
detection method of comparing load counters at ECMP links
can have false positives, since link load differences may ac-
tually be caused by differences in ﬂow size (to be expected).
Even when load imbalance is conﬁrmed, the counters are too
coarse-grained to answer key questions for debugging, such
as “is the imbalance caused by ﬂows that match speciﬁc pat-
terns?” A packet-level network telemetry system allows us
to count the number of speciﬁc 5-tuple pattern ﬂows mapped
to each link and thus offers a more reliable and direct method
of detection and debugging.
bugs in the implementation of network
Protocol bugs:
protocols such as BGP, PFC (Priority-based Flow Control)
480and RDMA (Remote Direct Memory Access). When a pro-
tocol misbehaves, performance and reliability of the network
suffers. Troubleshooting protocol bugs is tricky, because
many protocols are implemented by third-party (switch and
NIC) vendors and cannot be easily instrumented. Tracing
the packets of these protocols offers a reliable yet indepen-
dent way to identify protocol misbehaviors. Here network
telemetry is particularly suitable because host-based tracing
may be too expensive (e.g., for RDMA) or unavailable (e.g.,
for PFC and BGP).
3. OVERVIEW OF EVERFLOW
This section outlines the challenges in designing a scal-
able packet-level network telemetry system and introduces
the key ideas in Everﬂow to address these challenges.
3.1 Design challenges
Tracing and analysis scalability. The ﬁrst challenge fac-
ing packet-level network telemetry for large DCNs is scal-
ability of trace collection. As mentioned earlier, the traf-
ﬁc in a large DCN (with 100,000+ servers) can easily go
beyond 100 Tbps. Tracing packets at this scale will con-
sume a tremendous amount of network and server resources.
Consider a typical scenario where the average packet size is
1,000 bytes, each mirrored packet is truncated to 64 bytes
(the minimum Ethernet frame size), and the network diam-
eter is 5 hops (in a typical 3-tier Clos topology). If we sim-
ply trace every packet at every hop, as proposed in Packet
History [14], the tracing trafﬁc will be 64B
× 5(hops) ×
1000B
100(T bps) = 32(T bps).1 Such a high rate of tracing traf-
ﬁc may cause congestion and packet drops, especially when
network utilization is already high.
A similar same scalability challenge applies to trace anal-
ysis. Because commodity switches have limited storage and
CPU power, traced packets must be sent to servers for analy-
sis. Even assuming a server can process tracing trafﬁc at line
rate (10 Gbps), we will still need 32(T bps)
10(Gbps) = 3, 200 servers
for analysis which is prohibitively expensive.
Done naively, the situation can be worse. For most types
of analysis (see §4.1 for details) require the per-hop trace of
the same packets to be sent to the same analysis server. This
stickiness can be achieved by having switches send traced
packets to a set of reshufﬂers which then reshufﬂe the pack-
ets according to the hash of the packet header. Adding these
reshufﬂing servers will double the total number of servers.