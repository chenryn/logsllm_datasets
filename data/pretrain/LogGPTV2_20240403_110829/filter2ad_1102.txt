title:POSTER: TouchTrack: How Unique are your Touch Gestures?
author:Rahat Masood and
Benjamin Zi Hao Zhao and
Hassan Jameel Asghar and
Mohamed Ali Kâafar
POSTER: TouchTrack: How Unique are your Touch Gestures?
University of New South Wales (UNSW), CSIRO Data61
Rahat Masood
Sydney, Australia
PI:EMAIL
Hassan Jameel Asghar
CSIRO Data61
Sydney, Australia
PI:EMAIL
ABSTRACT
This paper studies a privacy threat induced by the collection and
monitoring of a user’s touch gestures on touchscreen devices. The
threat is a new form of persistent tracking which we refer to as
łtouch-based trackingž. It goes beyond tracking of virtual identities
and has the potential for cross-device tracking as well as identi-
fying multiple users using the same device. To demonstrate the
likelihood of touch-based tracking, we propose an information the-
oretic method that quantiies the amount of information revealed
by individual features of gestures, samples of gestures as well as
samples of gesture combinations, when modelled as feature vectors.
We have also developed a purpose-built app, named łTouchTrackž
that collects data from users and informs them on how unique they
are when interacting with their touch devices. Our results from 89
diferent users indicate that writing samples and left swipes can
reveal 73.7% and 68.6% of user information, respectively. Combin-
ing diferent combinations of gestures results in higher uniqueness,
with the combination of keystrokes, swipes and writing revealing
up to 98.5% of information about users. We correctly re-identify
returning users with a success rate of more than 90%.
KEYWORDS
Touch-based Tracking, Mobile Privacy, Behavioural Biometrics,
Touch Gestures
1 INTRODUCTION
In this paper, we postulate that the very distinguishability of touch-
based gestures constitutes a major privacy threat as it enables a new
form of tracking of individuals. We call this notion łtouch-based
tracking,ž which is the ability to continuously and surreptitiously
observe, track and distinguish users via their touch gestures while
they are interacting with touchscreen devices.
As opposed to łregularž tracking mechanisms (e.g., based on
cookies, browser ingerprints) which track virtual identities [1ś3],
touch-based tracking is subtle and riskier as it allows the track-
ing and identiication of the actual (physical) person operating the
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proit or commercial advantage and that copies bear this notice and the full citation
on the irst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’17, October 30-November 3, 2017, Dallas, TX, USA
© 2017 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-4946-8/17/10.
https://doi.org/10.1145/3133956.3138850
Benjamin Zi Hao Zhao
CSIRO Data61
Sydney, Australia
PI:EMAIL
Mohamed Ali Kaafar
CSIRO Data61
Sydney, Australia
PI:EMAIL
device. Touch-based tracking also leads to cross-device tracking
where same user can potentially be traced on multiple mobile de-
vices. Additionally, we also envision the risk of distinguishing and
tracking multiple users accessing the same device. Not all use cases
of touch-based tracking are negative. It can also be beneicial to
users and service providers alike. For instance, the identiication
of multiple users using the same device may help in providing
content more suitable for each of them. Nevertheless, touch-based
tracking performed in any of the above cases can provide a more
complete view of a user’s behavior and can be used for a range
of purposes including targeted ads, proiling, and spamming. Our
main contributions are as follows:
Contributions: We investigate the potential of using touch-
based gestures for tracking, which we call touch-based tracking.
We develop an analytical framework that measures the amount
of identifying information (in bits) contained in these gestures,
represented as feature vectors, at diferent levels of granularity. At
the inest level, our framework quantiies the information carried by
individual features, e.g., pressure on screen. At the second level, we
quantify the information carried by a gesture sample, e.g., a single
swipe. At the third level, our framework calculates the amount of
information carried by multiple samples of the same gesture, e.g.,
a collection of swipes. Lastly, we measure the information carried
by a collection of samples from multiple gestures, e.g., swipes and
taps. We apply our framework on four widely used touch screen
gestures: i) swipes, ii) taps, iii) keystrokes, and iv) handwriting.
We develop and deploy a łgame-likež Android app called łTouch-
Trackž which consists of three well known open source games and
one purpose-built handwriting module. We test our framework on
a total of 40,600 gesture samples collected from 89 participants and
identiied features that contain high amount of identifying informa-
tion using the maximum-relevancy minimum-redundancy (mRMR)
algorithm [4]. With the same dataset, we measured the amount of
information contained in samples from the same gesture and from
multiple gestures. We found that 50 features in a single handwrit-
ing sample contribute 68.71% of information about users, which
increases to 73.7% with multiple samples. We further identiied that
diferent gestures combined together reveal more information about
users. For instance swipes, handwriting, and keystrokes carry 98.5%
of information. Among users who performed all the four gestures,
our framework showed 98.89% of information about users.
We also validated our framework in terms of correctly identifying
a returning user. We found that with multiple samples, swipes and
handwriting show a TPR of 90.0% and 91.0%, respectively. For a
PosterCCS’17, October 30-November 3, 2017, Dallas, TX, USA2555PosterCCS’17, October 30-November 3, 2017, Dallas, TX, USA2556PosterCCS’17, October 30-November 3, 2017, Dallas, TX, USA2557