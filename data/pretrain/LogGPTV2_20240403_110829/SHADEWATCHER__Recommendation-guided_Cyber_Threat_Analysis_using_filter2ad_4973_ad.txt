Parallel Provenance Graph Construction: Our initial pro-
totype shows that the provenance graph (PG) construction
is considerably time-consuming, which degrades the overall
system performance. To put this into perspective, we present
that our prototype spends approximately six hours on just PG
construction for the DARPA TRACE dataset, while it only
takes several seconds to predict cyber threats.
To address this issue, we implement a parallel pipeline, as
shown in Figure 4, to allow concurrent audit record processing.
The allocator ﬁrst loads local audit records in a streaming
fashion and inserts them into a record queue batch by batch.
Once the builder identiﬁes a new batch in the record queue, it
3SHADEWATCHER is avaialbe at https://github.com/jun-zeng/ShadeWatcher
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:13:26 UTC from IEEE Xplore.  Restrictions apply. 
496
RecordQueueGraph QueueallocatorgeneratorBuilderThread 2Thread nThread 1TABLE I: Statistics of attack scenarios in the TRACE and Simulated datasets. All attack scenarios are abstracted as 10 of
153,859 behaviors in Table II for cyber threat analysis. The PG, BG, and KG share the same number of nodes. The detection
results show the number of true positives (#TP), true negatives (#TN), false positives (#FP), and false negatives (#FN).
Dataset
Attack Scenario
#Node
TRACE
Dataset
Simulated
Dataset
Extension Backdoor
Firefox Backdoor
Pine Backdoor
Phishing Executable
Conﬁguration Leakage
Content Destruction
Cheating Student
Illegal Storage
Passwd Gzip Scp
Passwd Reuse
67,352
996
252
23
27
84
31
270
25
11
PG
1,297
263
67,396
23
99
358
51
75
14
1,284
#Edge
BG
995
251
67,351
22
26
83
30
269
24
10
For each dataset, we randomly select 80%, 10%, and 10% of
system entity interactions to constitute the training, validation,
and testing sets. To avoid data snooping and biased parameter
risks [68], we split interactions disjointly into these three sets
and tune SHADEWATCHER’s hyper-parameters based solely
on the validation set. With our full knowledge of attack
workﬂow, we manually label the ground truth of interactions
through their relations to attacks. Detailed descriptions of
attack scenarios are summarized in Appendix E.
TRACE Dataset. Our ﬁrst dataset is a public APT attack
dataset collected by the TRACE team in the DARPA TC
program [69]. This dataset was generated during the third
red-team vs. blue-team adversarial engagement in April 2018.
The engagement simulates an enterprise environment for two
weeks in an isolated network with multiple security-critical
services such as an SSH server, email server, and SMB server.
The red team carries out ﬁve APT campaigns to exﬁltrate
proprietary information. Four of them are visible in system
audit records [17],
including Extension Backdoor, Firefox
Backdoor, Pine Backdoor, and Phishing Executable. To mix
benign and malicious audit records, the red team also performs
extensive common routines in parallel to attacks, such as web
browsing, reading emails, and administrative tasks.
Simulated Dataset. For our second dataset, we simulate
six cyber-attacks from previous work, including Conﬁgura-
tion Leakage [31], Content Destruction [36], Cheating Stu-
dent [70], Illegal Storage [36], Passwd Gzip Scp [6], and
Passwd Reuse [31]. Following public attack documentation,
we implement these attacks in a controlled testbed environ-
ment to collect the associated audit records. To incorporate
the impacts of benign activities, we emulate diverse system
behaviors (e.g., software installation using apt) in the best
efforts during in-progress attacks.
Dataset
TABLE II: Dataset statistics in provenance graphs.
#Interaction
7,923,332
2,857,717
#Behavior
148,335
5,524
#Node
6,109,307
367,406
12,661,091
3,022,193
#Edge
TRACE Dataset
Simulated Dataset
B. Effectiveness
#Interaction
Benign Malicious
Detection Results
67,341
67,338
134,747
KG
2,292
514
45
125
441
81
99
24
1,553
263
243
10
6
22
77
23
259
15
7
732
8
16
4
6
7
10
9
3
#TP
729
7
13
4
6
6
10
8
3
#TN
260
231
10
5
22
76
23
255
15
6
#FP
3
12
0
1
0
1
0
4
0
1
#FN
3
1
3
3
0
0
1
0
1
0
detection effectiveness using precision, recall, F1-score, and
accuracy metrics. Speciﬁcally, precision measures correctly
detected threats against predicted threats; recall measures
correctly detected threats against ground-truth threats; and F1-
score calculates the harmonic mean of the precision and recall.
Evaluation on Attack Scenarios. We abstract
ten cyber-
attacks from the TRACE and Simulated datasets as individual
behaviors with sets of benign and malicious system entity
interactions. Their statistics and detection results are summa-
rized in Table I and Table III. As observed, SHADEWATCHER
exhibits satisfactory detection performance on both experimen-
tal datasets. Speciﬁcally, it only misses 12 of 68,136 mali-
cious interactions. Upon closer investigation, we ﬁnd that the
majority of false-negative interactions come from web server
communications. For example, two of three false negatives in
Extension Backdoor (i.e., motivating example) are interactions
between gtcache and {146.153.68.151:80, 162.66.239.75:80}.
SHADEWATCHER misclassiﬁes these malicious interactions
because gtcache represents an executable downloaded by
browsers, and it frequently occurs for such executable to con-
nect to a web server in the training set. To gain further insight,
we study how SHADEWATCHER provides recommendations
for Extension Backdoor in § VIII-F. From Table I, we also
observe that SHADEWATCHER generates relatively more false
positives for Firefox Backdoor compared with other attack
scenarios. This case shows the importance of usage contexts
for distinguishing different system entities and predicting their
preferences. For the reason of space, we provide an in-depth
analysis of Firefox Backdoor in Appendix F. Furthermore,
as discussed in § III-B, audit records may not be reliable
after an attacker performs privilege escalation. Therefore, we
also evaluate the effectiveness of SHADEWATCHER’s detection
based only on audit data collected before privilege escalation
in Appendix G.
TABLE III: Detection results of attack scenarios.
Dataset
Precision Recall
99.98% 99.99%
86.05% 94.87%
F1-Score Accuracy
0.9998
0.9024
0.9996
0.9819
TRACE Dataset
Simulated Dataset
SHADEWATCHER predicts a probability that a system entity
would not prefer its interactive entity, where the probability
exceeding a pre-deﬁned threshold indicates a malicious in-
teraction (i.e., cyber threat). We evaluate SHADEWATCHER’s
Evaluation on Normal Workloads. To evaluate false alarms
in normal workloads, we apply SHADEWATCHER to detect
cyber threats based on benign system entity interactions in the
testing sets. The results are summarized in Table IV. We see
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:13:26 UTC from IEEE Xplore.  Restrictions apply. 
497
Fig. 5: Training loss and AUC value vs. the number of epochs.
that SHADEWATCHER achieves reasonably low false-positive
rates (0.332% and 0.137%) in both datasets. This is because
SHADEWATCHER interprets system entity interactions based
on their semantics rather than historical frequencies. As such,
rare or even unobserved interactions are not necessarily identi-
ﬁed as anomalies. For example, although gtcache has not been
witnessed to interact with /proc/27/stat, SHADEWATCHER still
recommends a low probability (-1.39) for the interaction to
be adversarial, because /proc/27/stat shares similar semantics
with other /proc/pid/stat previously accessed by gtcache.
Notice that although SHADEWATCHER achieves reasonable
false-positive rates, the total number of false alarms can still be
high for manual veriﬁcation due to the overwhelming volume
of audit records. We leave as future work to further assist
analysts in attack investigation, e.g., by threat alert triage.
TABLE IV: Detection results of normal workloads.
Dataset
TRACE Dataset
Simulated Dataset
#Interaction
(Benign)
724,236
285,732
#TN
721,831
285,340
Detection Results
#FP
2,405
392
FPR
0.332%
0.137%
Evaluation on Classiﬁcation. Since our cyber threat detection
is essentially a classiﬁcation task, we further use Area Under
the Curve (AUC) to analyze SHADEWATCHER’s capability
in distinguishing between benign and malicious system entity
interactions. The higher the AUC value is, the better SHADE-
WATCHER is at interaction classiﬁcation. More speciﬁcally, we
study how AUC varies on the testing set while training our
recommendation model. Figure 5 shows the training loss and
AUC on the TRACE dataset for 30 training epochs. As can
be observed, AUC increases to a high value after 14 epochs
and remains stable above 0.988, while the training loss drops
to a low value after 25 epochs and remains around 0.340.
Accordingly, we conclude that SHADEWATCHER is promising
at classifying system entity interactions.
C. Comparison Analysis
To answer how our proposed ﬁrst-order and high-order mod-
eling facilitates cyber threat detection, we have developed sev-
eral baseline approaches in place of SHADEWATCHER’s com-
ponents to conduct an ablation study on the TRACE dataset.
In particular, we compare TransR with different embedding
Fig. 6: ROC curves for ablation study.
algorithms, namely one-hot encoding [71], TransE [52] and
TransH [53]. We also compare how SHADEWATCHER per-
forms with and without high-order information from GNN.
Figure 6 plots the receiver operating characteristics (ROC)
curves of threat detection results, demonstrating that SHADE-
WATCHER (TransR+GNN) outperforms all other approaches.
This is expected as one-hot encoding completely ignores the
contextual information of system entities. In addition, both
TransE and TransH assume system entity embeddings to be
the same under different relations contexts. However, entities
typically have multiple aspects, and different relations should
focus on different aspects. Following this principle, TransR
learns a separate representation for every relation on which an
entity is conditioned, so it does not conﬂate different aspects
of the same entity. To understand the internals of TransR, we
visualize TransR’s embedding spaces in Appendix H. While
TransR outperforms both TransE and TransH in our case, it
tends to incur a higher runtime overhead for projecting system