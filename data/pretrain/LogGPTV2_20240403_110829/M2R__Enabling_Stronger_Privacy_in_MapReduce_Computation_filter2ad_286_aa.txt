title:M2R: Enabling Stronger Privacy in MapReduce Computation
author:Tien Tuan Anh Dinh and
Prateek Saxena and
Ee-Chien Chang and
Beng Chin Ooi and
Chunwang Zhang
M2R: Enabling Stronger Privacy in MapReduce 
Computation
Tien Tuan Anh Dinh, Prateek Saxena, Ee-Chien Chang, Beng Chin Ooi,  
and Chunwang Zhang, National University of Singapore
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/dinh
This paper is included in the Proceedings of the 
24th USENIX Security Symposium
August 12–14, 2015 • Washington, D.C.
ISBN  978-1-939133-11-3
Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXM2R: Enabling Stronger Privacy in MapReduce Computation
Tien Tuan Anh Dinh, Prateek Saxena, Ee-Chien Chang, Beng Chin Ooi, Chunwang Zhang
School of Computing, National University of Singapore
PI:EMAIL, PI:EMAIL, PI:EMAIL
PI:EMAIL, PI:EMAIL
Abstract
New big-data analysis platforms can enable distributed
computation on encrypted data by utilizing trusted com-
puting primitives available in commodity server hard-
ware. We study techniques for ensuring privacy-
preserving computation in the popular MapReduce
framework.
In this paper, we ﬁrst show that protect-
ing only individual units of distributed computation (e.g.
map and reduce units), as proposed in recent works,
leaves several important channels of information leak-
age exposed to the adversary. Next, we analyze a variety
of design choices in achieving a stronger notion of pri-
vate execution that is the analogue of using a distributed
oblivious-RAM (ORAM) across the platform. We de-
velop a simple solution which avoids using the expen-
sive ORAM construction, and incurs only an additive
logarithmic factor of overhead to the latency. We im-
plement our solution in a system called M2R, which en-
hances an existing Hadoop implementation, and evaluate
it on seven standard MapReduce benchmarks. We show
that it is easy to port most existing applications to M2R
by changing fewer than 43 lines of code. M2R adds fewer
than 500 lines of code to the TCB, which is less than
0.16% of the Hadoop codebase. M2R offers a factor of
1.3× to 44.6× lower overhead than extensions of previ-
ous solutions with equivalent privacy. M2R adds a total of
17% to 130% overhead over the insecure baseline solu-
tion that ignores the leakage channels M2R addresses.
1
Introduction
The threat of data theft in public and private clouds from
insiders (e.g. curious administrators) is a serious con-
cern. Encrypting data on the cloud storage is one stan-
dard technique which allows users to protect their sen-
sitive data from such insider threats. However, once
the data is encrypted, enabling computation on it poses
a signiﬁcant challenge. To enable privacy-preserving
computation, a range of security primitives have sur-
faced recently, including trusted computing support for
hardware-isolated computation [2, 5, 38, 40] as well as
purely cryptographic techniques [20,21,47]. These prim-
itives show promising ways for running computation se-
curely on a single device running an untrusted software
stack. For instance, trusted computing primitives can iso-
late units of computation on an untrusted cloud server. In
this approach, the hardware provides a conﬁdential and
integrity-protected execution environment to which en-
cryption keys can be made available for decrypting the
data before computing on it. Previous works have suc-
cessfully demonstrated how to securely execute a unit of
user-deﬁned computation on an untrusted cloud node, us-
ing support from hardware primitives available in com-
modity CPUs [8, 14, 38, 39, 49] .
In this paper, we study the problem of enabling
privacy-preserving distributed computation on an un-
trusted cloud. A sensitive distributed computation task
comprises many units of computation which are sched-
uled to run on a multi-node cluster (or cloud). The input
and output data between units of computation are sent
over channels controlled by the cloud provisioning sys-
tem, which may be compromised. We assume that each
computation node in the cluster is equipped with a CPU
that supports trusted computing primitives (for example,
TPMs or Intel SGX). Our goal is to enable a privacy-
preserving execution of a distributed computation task.
Consequently, we focus on designing privacy in the pop-
ular MapReduce framework [17]. However, our tech-
niques can be applied to other distributed dataﬂow frame-
works such as Spark [62], Dryad [26], and epiC [27].
Problem. A MapReduce computation consists of two
types of units of computation, namely map and re-
duce, each of which takes key-value tuples as input.
The MapReduce provisioning platform, for example
Hadoop [1], is responsible for scheduling the map/reduce
operations for the execution in a cluster and for provid-
ing a data channel between them [31]. We aim to achieve
a strong level of security in the distributed execution of a
MapReduce task (or job) — that is, the adversary learns
nothing beyond the execution time and the number of
input and output of each computation unit. If we view
each unit of computation as one atomic operation of a
larger distributed program, the execution can be thought
of as running a set of operations on data values passed
USENIX Association  
24th USENIX Security Symposium  447
1
via a data channel (or a global “RAM”) under the ad-
versary’s control. That is, our deﬁnition of privacy is
analogous to the strong level of privacy offered by the
well-known oblivious RAM protocol in the monolithic
processor case [22].
We assume that the MapReduce provisioning platform
is compromised, say running malware on all nodes in
the cluster. Our starting point in developing a defense
is a baseline system which runs each unit of computation
(map/reduce instance) in a hardware-isolated process, as
proposed in recent systems [49, 59]. Inputs and outputs
of each computation unit are encrypted, thus the adver-
sary observes only encrypted data. While this baseline
offers a good starting point, merely encrypting data in-
transit between units of computation is not sufﬁcient (see
Section 3). For instance, the adversary can observe the
pattern of data reads/writes between units. As another
example, the adversary can learn the synchronization be-
tween map and reduce units due to the scheduling struc-
ture of the provisioning platform. Further, the adversary
has the ability to duplicate computation, or tamper with
the routing of encrypted data to observe variations in the
execution of the program.
Challenges. There are several challenges in building
a practical system that achieves our model of privacy.
First, to execute map or reduce operations on a single
computation node, one could run all computation units
— including the entire MapReduce platform — in an ex-
ecution environment that is protected by use of existing
trusted computing primitives. However, such a solution
would entail little trust given the large TCB, besides be-
ing unwieldy to implement. For instance, a standard im-
plementation of the Hadoop stack is over 190K lines of
code. The scope of exploit from vulnerabilities in such a
TCB is large. Therefore, the ﬁrst challenge is to enable
practical privacy by minimizing the increase in platform
TCB and without requiring any algorithmic changes to
the original application.
The second challenge is in balancing the needs of pri-
vacy and performance. Addressing the leakage channels
discussed above using generic methods easily yields a
solution with poor practical efﬁciency. For instance, hid-
ing data read/write patterns between speciﬁc map and
reduce operations could be achieved by a generic obliv-
ious RAM (ORAM) solution [22, 55]. However, such
a solution would introduce a slowdown proportional to
polylog in the size of the intermediate data exchange,
which could degrade performance by over 100× when
gigabytes of data are processed.
Our Approach. We make two observations that en-
able us to achieve our model of privacy in a MapRe-
duce implementation. First, on a single node, most of the
MapReduce codebase can stay outside of the TCB (i.e.
code performing I/O and scheduling related tasks). Thus,
we design four new components that integrate readily to
the existing MapReduce infrastructure. These compo-
nents which amount to fewer than 500 lines of code are
the only pieces of trusted logic that need to be in the
TCB, and are run in a protected environment on each
computation node. Second, MapReduce computation
(and computation in distributed dataﬂow frameworks in
general) has a speciﬁc structure of data exchange and ex-
ecution between map and reduce operations; that is, the
map writes the data completely before it is consumed by
the reduce. Exploiting this structure, we design a com-
ponent called secure shufﬂer which achieves the desired
security but is much less expensive than a generic ORAM
solution, adding only a O(logN) additive term to the la-
tency, where N is the size of the data.
Results. We have implemented a system called M2R
based on Hadoop [1]. We ported 7 applications from a
popular big-data benchmarks [25] and evaluated them on
a cluster. The results conﬁrm three ﬁndings. First, port-
ing MapReduce jobs to M2R requires small development
effort: changing less than 45 lines of code. Second, our
solution offers a factor of 1.3× to 44.6× (median 11.2×)
reduction in overhead compared to the existing solu-
tions with equivalent privacy, and a total of 17%− 130%
of overhead over the baseline solution which protects
against none of the attacks we focus on in this paper. Our
overhead is moderately high, but M2R has high compati-
bility and is usable with high-sensitivity big data analysis
tasks (e.g. in medical, social or ﬁnancial data analytics).
Third, the design is scalable and adds a TCB of less than
0.16% of the original Hadoop codebase.
Contributions. In summary, our work makes three key
contributions:
• Privacy-preserving distributed computation. We
deﬁne a new pragmatic level of privacy which can
be achieved in the MapReduce framework requiring
no algorithmic restructuring of applications.
• Attacks. We show that merely encrypting data in en-
claved execution (with hardware primitives) is inse-
cure, leading to signiﬁcant privacy loss.
• Practical Design. We design a simple, non-
intrusive architectural change to MapReduce. We
in a real Hadoop implementation
implement
and benchmark its performance cost for privacy-
sensitive applications.
it
2 The Problem
Our goal is to enable privacy-preserving computation for
distributed dataﬂow frameworks. Our current design and
448  24th USENIX Security Symposium 
USENIX Association
2
USENIX Association  
24th USENIX Security Symposium  449
mapmappershufflermapmapshufflermapreducereducereduce...............reducermapperreducerreducershuffle phaseFigure1:TheMapReducecomputationmodel.implementationarespeciﬁctoMapReduceframework,thecomputationstructureofwhichisneverthelesssimi-lartootherdistributeddataﬂowengines[26,27,62],dif-feringmainlyinsupportedoperations.BackgroundonMapReduce.TheMapReducelan-guageenforcesastrictstructure:thecomputationtaskissplitintomapandreduceoperations.Eachinstanceofamaporreduce,calledacomputationunit(orunit),takesalistofkey-valuetuples1.AMapReducetaskcon-sistsofsequentialphasesofmapandreduceoperations.Oncethemapstepisﬁnished,theintermediatetuplesaregroupedbytheirkey-components.Thisprocessofgroupingisknownasshufﬂing.Alltuplesbelongingtoonegroupareprocessedbyareduceinstancewhichex-pectstoreceivetuplessortedbytheirkey-component.Outputsofthereducestepcanbeusedasinputsforthemapstepinthenextphase,creatingachainedMapRe-ducetask.Figure1showsthedataﬂowfromthemaptothereduceoperationsviatheshufﬂingstep.Intheactualimplementation,theprovisioningofallmapunitsononeclusternodeislocallyhandledbyamapperprocess,andsimilarly,byareducerprocessforreduceunits.2.1ThreatModelTheadversaryisamaliciousinsiderinthecloud,aimingtosubverttheconﬁdentialityoftheclient’scomputationrunningontheMapReduceplatform.Weassumethattheadversaryhascompleteaccesstothenetworkandstorageback-endoftheinfrastructureandcantamperwiththepersistentstorageornetworktrafﬁc.Foreachcompu-tationnodeinthecluster,weassumethattheadversarycancorrupttheentiresoftwarestack,saybyinstallingmalware.Weconsideranadversarythatperpetratesbothpas-siveandactiveattacks.Apassiveorhonest-but-curiousattackerpassivelyobservesthecomputationsession,be-1Toavoidconfusionofthetuplekeywithcryptographickey,werefertotheﬁrstcomponentinthetupleaskey-component.havinghonestlyinrelayingdatabetweencomputationunits,butaimstoinfersensitiveinformationfromtheobserveddata.Thisisapragmaticmodelwhichincludesadversariesthatobservedatabackedupperiodicallyondiskforarchival,orhaveaccesstoperformancemoni-toringinterfaces.Anactiveormaliciousattacker(e.g.aninstalledmalware)candeviatearbitrarilyfromtheex-pectedbehaviorandtamperwithanydataunderitscon-trol.Ourworkconsidersbothsuchattacks.ThereareatleasttwodirectattacksthatanadversarycanmountonaMapReducecomputationsession.First,theadversarycanobservedatapassingbetweencompu-tationunits.Ifthedataisleftunencrypted,thisleadstoadirectbreachinconﬁdentiality.Second,theadversarycansubvertthecomputationofeachmap/reduceinstancebytamperingwithitsexecution.Toaddressthesebasicthreats,westartwithabaselinesystemdescribedbelow.BaselineSystem.Weconsiderthebaselinesysteminwhicheachcomputationunitishardware-isolatedandexecutedprivately.Weassumethatthebaselinesys-temguaranteesthattheprogramcanonlybeinvokedonitsentireinputdataset,orelseitabortsinitsﬁrstmapphase.Datablocksenteringandexitingacomputationunitareencryptedwithauthenticatedencryption,andallside-channelsfromeachcomputationunitareassumedtobemasked[51].Intermediatedataisdecryptedonlyinahardware-attestedcomputationunit,whichhaslimitedmemorytosecurelyprocessuptoTinputstuples.Sys-temsachievingthisbaselinehavebeenpreviouslypro-posed,basedondifferingunderlyinghardwaremecha-nisms.VC3isarecentsystembuiltonIntelSGX[49].Notethatinthisbaselinesystem,theMapReducepro-visioningplatformisresponsibleforinvokingvarioustrustedunitsofcomputationinhardware-isolatedpro-cesses,passingencrypteddatabetweenthem.InSec-tion3,weexplainwhythisbaselinesystemleakssig-niﬁcantinformation,andsubsequentlydeﬁneastrongerprivacyobjective.2.2ProblemDeﬁnitionIdeally,thedistributedexecutionoftheMapReducepro-gramshouldleaknothingtotheadversary,excepttheto-talsizeoftheinput,totalsizeoftheoutputandtherun-ningtime.Theaforementionedbaselinesystemfailstoachievetheidealprivacy.Itleakstwotypesofinforma-tion:(a)theinputandoutputsize,andprocessingtimeofindividualcomputationunit,and(b)dataﬂowamongthecomputationunits.Westressthattheleakageof(b)issigniﬁcantinmanyapplicationssinceitrevealsrelationshipsamongthein-put.Forinstance,inthewell-knownexampleofcomput-ingPagerankscoresforanencryptedgraph[44],ﬂowsfromacomputationunittoanothercorrespondtoedges3in the input graph. Hence, leaking the dataﬂow essen-
tially reveals the whole graph edge-structure!
Techniques for hiding or reducing the leakage in (a)
by padding the input/output size and introducing timing
delays are known [35, 41]. Such measures can often re-
quire algorithmic redesign of the application [9] or use of
specialized programming languages or hardware [33,34],
and can lead to large overheads for applications where
the worst case running time is signiﬁcantly larger than
the average case. We leave incorporating these orthogo-
nal defenses out-of-scope.
Instead, in this work, we advocate focusing on elimi-
nating leakage on (b), while providing a formulation that
clearly captures the information that might be revealed.
We formulate the admissible leakage as Ψ which cap-
tures the information (a) mentioned above, namely the
input/output size and running time of each trusted com-
putation unit invoked in the system. We formalize this
intuition by deﬁning the execution as a protocol between
trusted components and the adversary, and deﬁne our pri-
vacy goal as achieving privacy modulo-Ψ.
Execution Protocol. Consider an honest execution of a
program on input I = (cid:31)x1,x2, . . . ,x n(cid:30). For a given map-
reduce phase, let there be n map computation units. Let
us label the map computation units such that the unit with
label i takes xi as input. Recall that the tuples generated
by the map computation units are to be shufﬂed, and
divided into groups according to the key-components.
Let K to be the set of unique key-components and let
π : [n+1,n+m] → K be a randomly chosen permutation,
where m = |K|. Next, m reduce computation units are to
be invoked. We label them starting from n + 1, such that
the computation unit i takes tuples with key-component
π(i) as input.
Let Ii,Oi,Ti be the respective input size (measured by