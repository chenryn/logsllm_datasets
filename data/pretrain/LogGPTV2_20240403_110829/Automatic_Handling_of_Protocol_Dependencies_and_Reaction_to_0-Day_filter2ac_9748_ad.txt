ing the server answers, we can indeed note that content dependency handling has
correctly generated the correct links to handle those dependencies.
Experimental evaluation. We deployed a ScriptGen based host in our testing
virtual network, and we ran the attack script against the honeypot.
The emulator handled perfectly all the content and session dependencies,
traversing the whole path of the state machine.
Automatic Handling of Protocol Dependencies
201
Fig. 7. Test scenario
The output of the attack script is indistinguishable from the one of a successful
attack against a real host (table 1), proving the quality of the emulation.
It is important to notice that this is a complete validation of the region analysis
approach. It started from a rich training set, without any kind of additional
information, and successfully handled a conversation with same structure, but
with partially diﬀerent content (diﬀerent process IDs, diﬀerent timestamps).
5.2 Reaction to Unknown Activities
In this section we want to experiment with ScriptGen’s capability to react to new
activities and to automatically reﬁne existing state machines retrieving training
information through proxying. We know from the previous experimental results
that, given a suﬃcient number of training samples, ScriptGen is able to carry
on a complete conversation with a client. Here we want to inspect the ability of
the emulator to produce its own training set to reﬁne the state machine, and its
ability to reliably identify new activities.
The experiments have been run in a very simple test scenario, shown in Figure
7. The attack is run against a ScriptGen honeypot, that is allowed to rely on a Win-
dows 2000 virtual machine using the proxying algorithm described in Section 4.3.
Learning. The ﬁrst aspect that we want to inspect is ScriptGen’s ability to
reliably reﬁne the state machine. Given a certain activity, initially unknown,
ScriptGen should take advantage of proxying to build its own training set and
reﬁne the state machine. After the reﬁnement, ScriptGen must be able to cor-
rectly handle the activity, without contacting the proxy any more.
For reﬁnement to be reliable, the training set must be diverse enough to allow
a correct inference of its semantics. If the training set is not diverse enough,
coincidental matches of mutable values may lead to wrong deductions on their
nature. If this happens, following instances of the same activity may not match
the generated transitions. This may generate erroneous alerts for new activities
(false positives). Therefore the reﬁnement condition, that triggers the reﬁnement
202
C. Leita, M. Dacier, and F. Massicotte
Table 2. Experimental results
N # false alerts # critical requests
3
5
10
20
50
3
3
0
2
0
3
3
0
1
0
of the state machine when the samples are considered to be diverse enough,
becomes critical.
In this ﬁrst scenario, the ScriptGen honeypot has been deployed with an
empty state machine for port 139. We used diﬀerent reﬁnement conditions, and
then ran 100 times the same activity (the same exploit used to study the em-
ulation quality). Since the diﬀerent runs of the activities are spaced in time by
approximately 10 seconds, we considered as a good measure of diversity (also
from a temporal point of view) diﬀerent thresholds on the number of available
training samples. When the number of samples retrieved through proxying is
equal to N, ScriptGen reﬁnes the state machine and then continues emulation.
Running the experiment in the same conditions using diﬀerent values of N and
then inspecting the resulting state machines will give a measure of the sensitivity
of ScriptGen to the lack of diversity of the samples.
Table 2 shows the relevant characteristics of the generated state machines. If
the training sample is not diverse enough, ScriptGen will generate false alerts.
That is, after the ﬁrst reﬁnement of the state machine the emulator will not be
able to correctly match successive requests, interpreting them as a new activity.
The number of false alerts is therefore connected to the quality of the training
samples. We expect a decreasing number of false alerts when increasing the value
of N. After each alert ScriptGen will again use proxying to collect a training
sample, and reﬁne the existing state machine with one or more functional paths.
It is also important to understand whether or not these unmatched requests
are observed at a critical point of the state machine: there might be a particularly
complex request for which region analysis is not able to generate a reliable transi-
tion. For this reason we count the number of nodes that triggered an unmatching
transition, which therefore corresponds to the number of critical requests in the
protocol state machine.
Figure 8 gives a visual explanation of the two concepts previously explained.
While the ﬁrst case can be considered as a symptom of a general lack of variabil-
ity, the second case is probably due to a more speciﬁc problem in a given request.
Referring to Table 2, we can map the ﬁrst case to low values of N (N=3,N=5)
while we can ﬁnd an example of the second case for N=20.
A ﬁrst striking result is the fact that in all cases, ScriptGen has been able to gen-
erate a complete state machine at the ﬁrst time the reﬁnement condition has been
triggered. But since some of the protocol variability is linked to time-dependent
ﬁelds (timestamps, and as we will see process IDs), the produced reﬁnements in-
corporate false deductions that lead to unmatched requests after some time.
Automatic Handling of Protocol Dependencies
203
Fig. 8. Diﬀerent reﬁnement cases
When N is equal to 20 we can experience a rather strange artifact. For the
second request in the conversation, 2 false alerts are generated. Inspecting the
transitions, we can notice that the artifact is due to the last byte of the process
ID: it is considered as a ﬁxed region. Since this value is stored following the
little-endian convention in the NetBIOS protocol, it actually corresponds to the
high part of the process identiﬁer of the attacking client. Since process identiﬁers
are often assigned sequentially, and since the attacking host was not reverted to
initial conditions during the experiment, this is not surprising. It is a clear case
in which the lack of variability of the samples leads ScriptGen to make wrong
assumptions. Only with N equal to 50 we have enough variability to correctly
classify the byte as part of a mutating region. In the case N equal to 10, the
problem was not raised only by a fortunate sequence of 100 process IDs having
all the same high part.
It is important to understand that some of the lack of diversity that we en-
countered in this experiment is due to speciﬁc artifacts of the chosen scenario.
We are running every attack instance from the same host in an iterative way.
This means that the process ID in the SMB header, usually appearing as a ran-
dom ﬁeld, here has incremental values. In a real attack scenario in which the
honeypot is contacted by many diﬀerent hosts, the diversity of this ﬁeld would
be greatly increased and so probably the number of samples required to generate
reliable reﬁnements would decrease. However, ScriptGen has been able to cor-
rectly generate a reliable reﬁnement of an initially empty state machine using a
training set of 50 conversations automatically generated through proxying. This
validates the ability of ScriptGen to learn new activities.
Triggering new activities. After having shown how ScriptGen is able to pro-
duce reﬁnements to the state machine, we need to investigate its capability to
reliably detect new activities. The previous section investigated the ability to
generate reliable reﬁnements, and therefore ScriptGen’s ability of not generat-
ing false positives. Here we want to investigate ScriptGen’s ability to reliably
detect new activities, and therefore false negatives. To do so, we deployed a new
ScriptGen honeypot, in the same conﬁguration as shown in Figure 7, but already
instructed with the state machine generated in the previous example for a value
of N equal to 50. Then we run against this honeypot a new activity on the same
port, namely the Microsoft PnP MS05-039 Overﬂow [17]. We followed the same
pattern used in the previous experiment: 100 runs spaced in time choosing a
204
C. Leita, M. Dacier, and F. Massicotte
triggering threshold equal to 50. The attack followed the ﬁrst path for the ﬁrst
5 requests, and only at that point triggered an unmatched request. Using just
50 samples of interaction, ScriptGen has been able to correctly reﬁne the state
machine adding a single path to the existing one. The reﬁned state machine
correctly handled all the 50 successive runs of the attack.
This is an extremely important result. First of all, it shows how ScriptGen-
based honeypots are able to reliably identify new activities. Also, since the two
activities are identiﬁable only after the exchange of 5 couples of request/answer,
it validates the importance and the power of the ScriptGen approach with respect
to the current state of the art in honeypot technology.
6 Conclusion
In this paper, we have shown the feasibility of using a completely protocol-
unaware approach to build scripts to emulate the behavior of servers under
attack. As opposed to the approach considered by the authors of the RolePlayer
system, we have deliberately refused to take advantage of any heuristic to rec-
ognize important ﬁelds in the arguments received from the clients or sent by
the servers. Instead, by using several instances of the same attack, we can auto-
matically retrieve the ﬁelds which have some importance from a semantic point
of view and are important to let the conversation between the client and server
continue. More speciﬁcally, we have shown that two distinct types of dependency
are important to take into account. We have named them, respectively, intra-
protocol and inter-protocol dependencies. We have proposed new algorithms to
handle them eﬃciently. We have also shown that this newly created mechanism
can be further enhanced to create new scripts online as new attacks are appear-
ing by, temporarily, proxying the requests and responses between the attackers
and a real server. Experimental results obtained with our approach are very
good and demonstrate the potential inherent in the large-scale deployment of
honeynets such as our Leurre.com project [3,4,5,6,7,8]. The ScriptGen approach
would in fact allow us to collect an even richer data set than the one we have
accumulated so far.
References
1. Spitzner, L.: Honeypots: Tracking Hackers. Addison-Welsey, Boston (2002)
2. Provos, N.: A virtual honeypot framework. In: Proceedings of the 12th USENIX
Security Symposium. (2004) 1–14
3. Dacier, M., Pouget, F., Debar, H.: Attack processes found on the internet. In:
NATO Symposium IST-041/RSY-013, Toulouse, France (2004)
4. Dacier, M., Pouget, F., Debar, H.: Honeypots, a practical mean to validate ma-
licious fault assumptions. In: Proceedings of the 10th Paciﬁc Ream Dependable
Computing Conference (PRDC04), Tahiti (2004)
5. Dacier, M., Pouget, F., Debar, H.: Honeypot-based forensics. In: Proceedings of
AusCERT Asia Paciﬁc Information Technology Security Conference 2004, Bris-
bane, Australia (2004)
Automatic Handling of Protocol Dependencies
205
6. Dacier, M., Pouget, F., Debar, H.: Towards a better understanding of internet
threats to enhance survivability. In: Proceedings of the International Infrastructure
Survivability Workshop 2004 (IISW’04), Lisbonne, Portugal (2004)
7. Dacier, M., Pouget, F., Debar, H.: Leurre.com: On the advantages of deploying
a large scale distributed honeypot platform. In: Proceedings of the E-Crime and
Computer Conference 2005 (ECCE’05), Monaco (2005)
8. Dacier, M., Pouget, F., Debar, H.: Honeynets: foundations for the development of
early warning information systems. In Kowalik, J., Gorski, J., Sachenko, A., eds.:
Proceedings of the Cyberspace Security and Defense: Research Issues. (2005)
9. CERT: Cert advisory ca-2003-20 w32/blaster worm (2003)
10. Leita, C., Mermoud, K., Dacier, M.: Scriptgen: an automated script generation tool
for honeyd. In: Proceedings of the 21st Annual Computer Security Applications
Conference. (2005)
11. Needleman, S., Wunsch, C.: A general method applicable to the search for similar-
ities in the amino acid sequence of two proteins. J Mol Biol. 48(3):443-53 (1970)
12. Cui, W., Vern, P., Weaver, N., Katz, R.H.: Protocol-independent adaptive replay of
application dialog. In: The 13th Annual Network and Distributed System Security
Symposium (NDSS). (2006)
13. Freiling, F.C., Holz, T., Wicherski, G.: Botnet tracking: Exploring a root-cause
methodology to prevent distributed denial-of-service attacks. In: Lecture Notes in
Computer Science, Springer-Verlag GmbH (2005) 319–335
14. The Honeynet Project: Know your enemy: Tracking botnets. Know Your Enemy
Whitepapers (2005)
15. Massicotte, F., Couture, M., De Montigny-Leboeuf, A.: Using a vmware network
infrastructure to collect traﬃc traces for intrusion detection evaluation. In: Pro-
ceedings of the 21st Annual Computer Security Applications Conference. (2005)
16. OSVDB: Microsoft windows lsass remote overﬂow, http://www.osvdb.org/5248
(2006)
17. OSVDB: Microsoft pnp ms05-039 overﬂow, http://www.osvdb.org/18605 (2005)