＜/property＞
前面提到，读者可以通过设置conf/Hadoop-env.sh为Hadoop的守护进程设置环境变量。一般来说，大家至少需要在这里设置在主机上安装的JDK的位置（JAVA_HOME），以使Hadoop找到JDK。大家也可以在这里通过HADOOP_*_OPTS对不同的守护进程分别进行设置，如表2-1所示。
例如，如果想设置NameNode使用parallelGC，那么可以这样写：
export HADOOP_NameNode_OPTS="-XX：+UseParallelGC${HADOOP_NAMENODE_OPTS}"
在这里也可以进行其他设置，比如设置Java的运行环境（HADOOP_OPTS），设置日志文件的存放位置（HADOOP_LOG_DIR），或者SSH的配置（HADOOP_SSH_OPTS），等等。
关于conf/core-site.xml、conf/hdfs-site.xml、conf/mapred-site.xml的配置如表2-2～表2-4所示。
一般而言，除了规定端口、IP地址、文件的存储位置外，其他配置都不是必须修改的，可以根据读者的需要决定采用默认配置还是自己修改。还有一点需要注意的是，以上配置都被默认为最终参数（final parameters），这些参数都不可以在程序中再次修改。
接下来可以看一下conf/mapred-queues.xml的配置列表，如表2-5所示。
相信大家不难猜出表2-5的conf/mapred-queues.xml文件是用来做什么的，这个文件就是用来设置MapReduce系统的队列顺序的。queues是JobTracker中的一个抽象概念，可以在一定程度上管理Job，因此它为管理员提供了一种管理Job的方式。这种控制是常见且有效的，例如通过这种管理可以把不同的用户划分为不同的组，或分别赋予他们不同的级别，并且会优先执行高级别用户提交的Job。
按照这个思想，很容易想到三种原则：
同一类用户提交的Job统一提交到同一个queue中；
运行时间较长的Job可以提交到同一个queue中；
把很快就能运行完成的Job划分到一个queue中，并且限制queue中Job的数量上限。
queue的有效性很依赖在JobTracker中通过mapreduce.jobtracker.taskscheduler设置的调度规则（scheduler）。一些调度算法可能只需要一个queue，不过有些调度算法可能很复杂，需要设置很多queue。
对queue大部分设置的更改都不需要重新启动MapReduce系统就可以生效，不过也有一些更改需要重启系统才能有效，具体如表2-5所示。
conf/mapred-queues. xml的文件配置与其他文件略有不同，配置格式如下：
＜queues aclsEnabled="$aclsEnabled"＞
＜queue＞
＜name＞$queue-name＜/name＞
＜state＞$state＜/state＞
＜queue＞
＜name＞$child-queue1＜/name＞
＜properties＞
＜property key="$key"value="$value"/＞
……
＜/properties＞
＜queue＞
＜name＞$grand-child-queue1＜/name＞
……
＜/queue＞
＜/queue＞
＜queue＞
＜name＞$child-queue2＜/name＞
……
＜/queue＞
……
……
……
＜queue＞
＜name＞$leaf-queue＜/name＞
＜acl-submit-job＞$acls＜/acl-submit-job＞
＜acl-administer-jobs＞$acls＜/acl-administer-jobs＞
＜properties＞
＜property key="$key"value="$value"/＞
……
＜/properties＞
＜/queue＞
＜/queue＞
＜/queues＞
以上这些就是Hadoop配置的主要内容，其他关于Hadoop配置方面的信息，诸如内存配置等，如果有兴趣可以参阅官方的配置文档。
2.一个具体的配置
为了方便阐述，这里只搭建一个有三台主机的小集群。
相信大家还没有忘记Hadoop对主机的三种定位方式，分别为Master和Slave, JobTracker和TaskTracker, NameNode和DataNode。在分配IP地址时我们顺便规定一下角色。
下面为这三台机器分配IP地址及相应的角色：
10.37.128.2—master, namonode, jobtracker—master（主机名）
10.37.128.3—slave, dataNode, tasktracker—slave1（主机名）
10.37.128.4—slave, dataNode, tasktracker—slave2（主机名）
首先在三台主机上创建相同的用户（这是Hadoop的基本要求）：
1）在三台主机上均安装JDK 1.6，并设置环境变量。
2）在三台主机上分别设置/etc/hosts及/etc/hostname。
hosts这个文件用于定义主机名与IP地址之间的对应关系。
/etc/hosts：
127.0.0.1 localhost
10.37.128.2 master
10.37.128.3 slave1
10.37.128.4 slave2
hostname这个文件用于定义Ubuntu的主机名。
/etc/hostname：
“你的主机名”（如master, slave1等）
3）在这三台主机上安装OpenSSH，并配置SSH可以免密码登录。
安装方式不再赘述，建立～/.ssh文件夹，如果已存在，则无须创建。生成密钥并配置SSH免密码登录本机，输入命令：
ssh-keygen-t dsa-P''-f～/.ssh/id_dsa
cat～/.ssh/id_dsa.pub＞＞～/.ssh/authorized_keys
将文件复制到两台Slave主机相同的文件夹内，输入命令：
scp authorized_keys slave1：～/.ssh/
scp authorized_keys slave2：～/.ssh/
查看是否可以从Master主机免密码登录Slave，输入命令：
ssh slave1
ssh slave2
4）配置三台主机的Hadoop文件，内容如下。
conf/Hadoop-env. sh：
export JAVA_HOME=/usr/lib/jvm/jdk
conf/core-site. xml：
＜?xml version="1.0"?＞
＜?xml-stylesheet type="text/xsl"href="configuration.xsl"?＞
＜！--Put site-specific property overrides in this file.--＞
＜configuration＞
＜property＞
＜name＞fs.default.name＜/name＞
＜value＞hdfs：//master：9000＜/value＞
＜/property＞
＜property＞
＜name＞hadoop.tmp.dir＜/name＞
＜value＞/tmp＜/value＞
＜/property＞
＜/configuration＞
conf/hdfs-site. xml：
＜?xml version="1.0"?＞
＜?xml-stylesheet type="text/xsl"href="configuration.xsl"?＞
＜！--Put site-specific property overrides in this file.--＞
＜configuration＞
＜property＞
＜name＞dfs.replication＜/name＞
＜value＞2＜/value＞
＜/property＞
＜/configuration＞
conf/mapred-site. xml：
＜?xml version="1.0"?＞
＜?xml-stylesheet type="text/xsl"href="configuration.xsl"?＞
＜！--Put site-specific property overrides in this file.--＞
＜configuration＞
＜property＞
＜name＞mapred.job.tracker＜/name＞
＜value＞master：9001＜/value＞
＜/property＞
＜/configuration＞
conf/masters：
master
conf/slaves：
slave1
slave2
5）启动Hadoop。
bin/Hadoop NameNode-format
bin/start-all.sh
你可以通过以下命令或者通过http：//master：50070及http：//master：50030查看集群状态。
Hadoop dfsadmin-report
2.5 日志分析及几个小技巧
如果大家在安装的时候遇到问题，或者按步骤安装完成却不能运行Hadoop，那么建议仔细查看日志信息。Hadoop记录了详尽的日志信息，日志文件保存在logs文件夹内。
无论是启动还是以后会经常用到的MapReduce中的每一个Job，或是HDFS等相关信息，Hadoop均存有日志文件以供分析。
例如：NameNode和DataNode的namespaceID不一致，这个错误是很多人在安装时都会遇到的。日志信息为：
java.io.IOException：Incompatible namespaceIDs in/root/tmp/dfs/data：namenode
namespaceID=1307672299；datanode namespaceID=389959598
若HDFS一直没有启动，读者可以查询日志，并通过日志进行分析，日志提示信息显示了NameNode和DataNode的namespaceID不一致。
这个问题一般是由于两次或两次以上格式化NameNode造成的，有两种方法可以解决，第一种方法是删除DataNode的所有资料，第二种方法就是修改每个DataNode的namespaceID（位于/dfs/data/current/VERSION文件中）或修改NameNode的namespaceID（位于/dfs/name/current/VERSION文件中）。使其一致。
下面这两种方法在实际应用也可能会用到。
1）重启坏掉的DataNode或JobTracker。当Hadoop集群的某单个节点出现问题时，一般不必重启整个系统，只须重启这个节点，它会自动连入整个集群。
在坏死的节点上输入如下命令即可：
bin/Hadoop-daemon.sh start datanode
bin/Hadoop-daemon.sh start jobtracker
2）动态加入DataNode或TaskTracker。下面这条命令允许用户动态地将某个节点加入到集群中。
bin/Hadoop-daemon.sh--config./conf start datanode
bin/Hadoop-daemon.sh--config./conf start tasktracker
2.6 本章小结
本章主要讲解了Hadoop的安装和配置过程。Hadoop的安装过程并不复杂，基本配置也简单明了，其中有几个关键点：