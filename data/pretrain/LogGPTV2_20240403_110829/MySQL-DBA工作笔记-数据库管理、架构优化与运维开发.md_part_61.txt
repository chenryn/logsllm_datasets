候直接替换就行。
是准备了好几份这个配置文件，到时
前配置下 rules.xml 和 schema.xml，我
sharding分片，不同的线程数。需要
切分成12个sharding分片,那就是120
的表，如果是做分片，3个服务器节点
个小时来收到相对完整的数据情况。
据分布，然后细化到每个场景测试-
个
都大体跑了下，得到了一个基本的娄
表。测试的场景我是分为不同的
脚本如下,我配置了10个 sbtest[N]
function change_sharding
run Itee sysbench_
thread_no=$ 2
function sysbench_test
delete from sbtest10;
delete
delete
delete
delete
delete
delete
delete
mysql -umycat_user -pmycat_user -P8066 -h127 .0.0.1 /dev/null
mv /usr/local/mycat/conf/schema.xml /usr/local/mycat/conf/schema.xml.tmp
sysbench
date
shard_no=$ 1
sysbench
线程数
32
线程数
test
test
test
test
test
test
test
test
中间件CPU使用率
3
3
3
の
9
6
6
6
6
128
98
9
3
人
128
8
9
9
9
9
128
692
L
80%
20%
30%
9
分片节点数
表10-2
分片规则
表10-1
取
取
取模
3
模
模
分布式压测结果
20763
17956
(TPS)
14480
conf/schema.xml >/dev/null
第10章基于业务的数据库架构设计”379
10319.81
10479.45
InnoDB
单实例压测结果
6448
(TPS)
6288
5593
>/dev/null
---
## Page 402
380丨MySQLDBA工作笔记：数据库管理、架构优化与运维开发
以根据资源配置和实际的压力进行取舍，如图10-8所示。
而以线程数为基准，不同分片情况下的 TPS 指标也不是严格意义上的线性增长，可
6个分片为例，对于不同的线程数，TPS的指标如下图10-7所示。
线程数
128
8
9
128
3
心
3
7000
分片节点数
图10-8
图10-7
2
6
9
3
2
6
6
3
12
6
9
2
心
19980.49
19892.61
20289.89
23015.55
18232.87
19795.11
18231.94
18407.79
17689.42
18253.82
17713.65
16861.06
16316.64
14077.49
13768.96
15197.31
11122.29
10670.2
InnoDB
2100
续表
---
## Page 403
 dn50-dn65， database 是 histrecord01-histrecord16。
一张表就能拆分成2000多张表，一年有差不多5800张相关的表。
利”就是我们要修改的表目前没有写入，做变更不用考虑在线业务的写入影响。
如果有些业务暂时还没有迁移过来，有一整天的时间来缓冲调整修复。所以目前的需求“福
默认值，之后的就不需要了；这个从业务的角度来说，是因为应用层升级而需要这个属性，
天的表做了细粒度的拆分，每个日表会有 16 个分片做 hashl 路由。
rec20180302这种。所以按照这种增长的趋势，可以根据时间维度不断扩展，同时又对每
也不多，但是看看这个表 hisrecord 的分片逻辑就会发现，远远比我们想的要更丰富。
点，所以共有16个sharding 分片，正是应了那句话：百库十表。虽然目前看起来节点数
好像复杂度也不高。
10.1.5Mycat 中的 DDL
但是我看到开发同学提供的信息时就有点犹豫了，因为端口是 8066，也就意味着使
涉及的 DDL表有2个，即2个DDL 语句，所以算下来就是5664 张表了。所以你看
开发同学的需求是对某一天之后的日表添加字段，变更第一天的数据需要对该字段添加
这个表是按照日期来存储数据的，即数据的存储单位是日。表名类似于rec20180301、
我们先来简单看下 Mycat 里面的 schema.xml 配置。里面配置了 16个分片，即
mysql> select datediff('2018-11-01','2018-05-08');
有一天开发同学提了一个需求，是希望对某一个时间范围的表做DDL 操作，看起来
如果在这个基础上考虑当天的表结构变更，那就更复杂了。
1 row in set (0.00 sec)
mysql> select 177*16;
按照16个分片来算，这个数量就相当大了，有2832张表。
1 row in set (0.00 sec)
datediff('2018-11-01',
我简单算了下，按照目前的修改幅度，影响的日表有177个。
28321
177*16
'2018-05-08')
177
database="hisrecord02"
第10章基于业务的数据库架构设计”381
---
## Page 404
382丨MySQL DBA工作笔记：数据库管理、架构优化与运维开发
10.1.6
时候中间件层面的支持就很有限了，我们在一定程度上可能需要其他的解决方案。
角度来说，由于不断地拆分，历史数据的归档保留和数据的聚合需求还是有的，可能在这个
密集插入型的业务，如果是节点间的交互分布式，那这个方案就不大适合了。同时从业务的
重新配置一下，然后在Mycat 端 reload一些配置。
了不到半个小时，很多时间都是在不断的确认中，因为这个变更的影响范围确实有点大。
在每个节点上单独去执行相应的变更DDL。
件，按照日期循环100天，就写入100次。
文件。这个脚本的意义在于不断的处理表结构信息，打上时间戳，写入另外一个脚本文
的一些思路。
当然这个问题的前提是我们已经创建好了日表，如果没有日表的话，我们还是需要
把这个任务扩展一下，就会发现，中间件层面的数据处理更侧重于TP业务，而且是
根据得到的脚本略作改动，就可以分发到不同的 sharding 节点侧了。整个过程持续
我们输入两个时间，即起始时间和终止时间。app_sql/create_sql.sql 是表结构的定义
很快就完成了上述的基本操作。当然 Mycat 端是不支持 DDL 语句的，所以我们需要
function main(){
（1）定义循环主函数
enddate=^date -d "20181101"
startdate='date -d "20180508" +%Y%m%d′
MySQL分布式架构的扩缩容是一个很有意思的话题。严格的说，我们所说的这种架
（2）执行主函数 main
要做这个工作，手工完成的可能性太低，所以准备了下面的脚本，借鉴了之前同事
> /home/mysql/app_sql/alter_his_record.sql 
sed -i "s/20180508/$(startdate)/g" /home/mysql/app_sql/alter
echo ${startdate}
'rec2018030
dataNode="dn$50-65"
dataNode
p+
his
record.sql
---
## Page 405
到这个时候从库顶上来做了主库。
4个物理分片，可以扩容为8个物理分片，大体的架构和分布如下图10-10所示，可以看
分片，也就意味着一张表被分为了16份。
构方案是一种伪分布式架构，这里要表达的重点是扩缩容的思路上。
对于扩容来说，优先考虑主库写入为主，所以我们的扩容以2N的规模来扩容，比如
如果一套环境的主从完整且分为多个逻辑分片，大体是下图10-9这样的架构。
从扩容的角度来说，这也就是我们预期要做的事情，4个变8个，8个变16个。一
这个架构采用了4个物理分片，每个物理分片上有4个逻辑分片，总共有16个逻辑
图10-10
图10-9
Proxy
第10章基于业务的数据库架构设计”383
---
## Page 406
384|MySQLDBA工作笔记：数据库管理、架构优化与运维开发
状态，如图10-13。这个过程除了配置的变更，还需要保证切换过程的数据一致性。
状态，如图10-12。
inactive，只负责数据同步。
个相对详细的数据复制关系图，如图10-11。
套环境按照设定的分片规模可以扩容两次。
扩容后，原本的 db1、db2 为 active 状态，而 db3、db4 在原来的 Slave 节点上是 active