the file system:
Click here to view code image
2: kd> !locks -v 0xffffde07a33d6a28
Resource @ 0xffffde07a33d6a28    Shared 1 owning threads
    Contention Count = 28
     Threads: ffffde07a9374080-01
     THREAD ffffde07a9374080  Cid 0544.1494  Teb: 
000000ed8de12000
     Win32Thread: 0000000000000000 WAIT: (Executive) 
KernelMode Non-Alertable
         ffff8287943a87b8  NotificationEvent
     IRP List:
         ffffde07a936da20: (0006,0478) Flags: 00020043  Mdl: 
ffffde07a8a75950
         ffffde07a894fa20: (0006,0478) Flags: 00000884  Mdl: 
00000000
     Not impersonating
     DeviceMap                 ffff8786fce35840
     Owning Process            ffffde07a7f990c0       Image:         
svchost.exe
     Attached Process          N/A            Image:         
N/A
     Wait Start TickCount      3649           Ticks: 0
     Context Switch Count      31             
IdealProcessor: 1
     UserTime                  00:00:00.015
     KernelTime                00:00:00.000
     Win32 Start Address 0x00007ff926812390
     Stack Init ffff8287943aa650 Current ffff8287943a8030
     Base ffff8287943ab000 Limit ffff8287943a4000 Call 
0000000000000000
     Priority 7 BasePriority 6 PriorityDecrement 0 
IoPriority 0 PagePriority 1
     Child-SP          RetAddr           Call Site
     ffff8287`943a8070 fffff801`104a423a 
nt!KiSwapContext+0x76
     ffff8287`943a81b0 fffff801`104a5d53 
nt!KiSwapThread+0x5ba
     ffff8287`943a8270 fffff801`104a6579 
nt!KiCommitThreadWait+0x153
     ffff8287`943a8310 fffff801`1263e962 
nt!KeWaitForSingleObject+0x239
     ffff8287`943a8400 fffff801`1263d682 
Ntfs!NtfsNonCachedIo+0xa52
     ffff8287`943a86b0 fffff801`1263b756 
Ntfs!NtfsCommonRead+0x1d52
     ffff8287`943a8850 fffff801`1049a725 
Ntfs!NtfsFsdRead+0x396
     ffff8287`943a8920 fffff801`11826591 
nt!IofCallDriver+0x55
Pushlocks
Pushlocks are another optimized synchronization mechanism built on event
objects; like fast and guarded mutexes, they wait for an event only when
there’s contention on the lock. They offer advantages over them, however, in
that they can also be acquired in shared or exclusive mode, just like an
executive resource. Unlike the latter, however, they provide an additional
advantage due to their size: a resource object is 104 bytes, but a pushlock is
pointer sized. Because of this, pushlocks do not require allocation nor
initialization and are guaranteed to work in low-memory conditions. Many
components inside of the kernel moved away from executive resources to
pushlocks, and modern third-party drivers all use pushlocks as well.
There are four types of pushlocks: normal, cache-aware, auto-expand, and
address-based. Normal pushlocks require only the size of a pointer in storage
(4 bytes on 32-bit systems, and 8 bytes on 64-bit systems). When a thread
acquires a normal pushlock, the pushlock code marks the pushlock as owned
if it is not currently owned. If the pushlock is owned exclusively or the thread
wants to acquire the thread exclusively and the pushlock is owned on a
shared basis, the thread allocates a wait block on the thread’s stack, initializes
an event object in the wait block, and adds the wait block to the wait list
associated with the pushlock. When a thread releases a pushlock, the thread
wakes a waiter, if any are present, by signaling the event in the waiter’s wait
block.
Because a pushlock is only pointer-sized, it actually contains a variety of
bits to describe its state. The meaning of those bits changes as the pushlock
changes from being contended to noncontended. In its initial state, the
pushlock contains the following structure:
■    One lock bit, set to 1 if the lock is acquired
■    One waiting bit, set to 1 if the lock is contended and someone is
waiting on it
■    One waking bit, set to 1 if the lock is being granted to a thread and the
waiter’s list needs to be optimized
■    One multiple shared bit, set to 1 if the pushlock is shared and
currently acquired by more than one thread
■    28 (on 32-bit Windows) or 60 (on 64-bit Windows) share count bits,
containing the number of threads that have acquired the pushlock
As discussed previously, when a thread acquires a pushlock exclusively
while the pushlock is already acquired by either multiple readers or a writer,
the kernel allocates a pushlock wait block. The structure of the pushlock
value itself changes. The share count bits now become the pointer to the wait
block. Because this wait block is allocated on the stack, and the header files
contain a special alignment directive to force it to be 16-byte aligned, the
bottom 4 bits of any pushlock wait-block structure will be all zeros.
Therefore, those bits are ignored for the purposes of pointer dereferencing;
instead, the 4 bits shown earlier are combined with the pointer value.
Because this alignment removes the share count bits, the share count is now
stored in the wait block instead.
A cache-aware pushlock adds layers to the normal (basic) pushlock by
allocating a pushlock for each processor in the system and associating it with
the cache-aware pushlock. When a thread wants to acquire a cache-aware
pushlock for shared access, it simply acquires the pushlock allocated for its
current processor in shared mode; to acquire a cache-aware pushlock
exclusively, the thread acquires the pushlock for each processor in exclusive
mode.
As you can imagine, however, with Windows now supporting systems of
up to 2560 processors, the number of potential cache-padded slots in the
cache-aware pushlock would require immense fixed allocations, even on
systems with few processors. Support for dynamic hot-add of processors
makes the problem even harder because it would technically require the
preallocation of all 2560 slots ahead of time, creating multi-KB lock
structures. To solve this, modern versions of Windows also implement the
auto-expand push lock. As the name suggests, this type of cache-aware
pushlock can dynamically grow the number of cache slots as needed, both
based on contention and processor count, while guaranteeing forward
progress, leveraging the executive’s slot allocator, which pre-reserves paged
or nonpaged pool (depending on flags that were passed in when allocating
the auto-expand pushlock).
Unfortunately for third-party developers, cache-aware (and their newer
cousins, auto-expand) pushlocks are not officially documented for use,
although certain data structures, such as FCB Headers in Windows 10 21H1
and later, do opaquely use them (more information about the FCB structure is
available in Chapter 11.) Internal parts of the kernel in which auto-expand
pushlocks are used include the memory manager, where they are used to
protect Address Windowing Extension (AWE) data structures.
Finally, another kind of nondocumented, but exported, push-lock is the
address-based pushlock, which rounds out the implementation with a
mechanism similar to the address-based wait we’ll shortly see in user mode.
Other than being a different “kind” of pushlock, the address-based pushlock
refers more to the interface behind its usage. On one end, a caller uses
ExBlockOnAddressPushLock, passing in a pushlock, the virtual address of
some variable of interest, the size of the variable (up to 8 bytes), and a
comparison address containing the expected, or desired, value of the variable.
If the variable does not currently have the expected value, a wait is initialized
with ExTimedWaitForUnblockPushLock. This behaves similarly to
contended pushlock acquisition, with the difference that a timeout value can
be specified. On the other end, a caller uses
ExUnblockOnAddressPushLockEx after making a change to an address that
is being monitored to signal a waiter that the value has changed. This
technique is especially useful when dealing with changes to data protected by
a lock or interlocked operation, so that racing readers can wait for the
writer’s notification that their change is complete, outside of a lock. Other
than a much smaller memory footprint, one of the large advantages that
pushlocks have over executive resources is that in the noncontended case
they do not require lengthy accounting and integer operations to perform
acquisition or release. By being as small as a pointer, the kernel can use
atomic CPU instructions to perform these tasks. (For example, on x86 and
x64 processors, lock cmpxchg is used, which atomically compares and
exchanges the old lock with a new lock.) If the atomic compare and exchange
fails, the lock contains values the caller did not expect (callers usually expect
the lock to be unused or acquired as shared), and a call is then made to the
more complex contended version.
To improve performance even further, the kernel exposes the pushlock
functionality as inline functions, meaning that no function calls are ever
generated during noncontended acquisition—the assembly code is directly
inserted in each function. This increases code size slightly, but it avoids the
slowness of a function call. Finally, pushlocks use several algorithmic tricks
to avoid lock convoys (a situation that can occur when multiple threads of the
same priority are all waiting on a lock and little actual work gets done), and
they are also self-optimizing: the list of threads waiting on a pushlock will be
periodically rearranged to provide fairer behavior when the pushlock is
released.
One more performance optimization that is applicable to pushlock
acquisition (including for address-based pushlocks) is the opportunistic
spinlock-like behavior during contention, before performing the dispatcher
object wait on the pushlock wait block’s event. If the system has at least one
other unparked processor (see Chapter 4 of Part 1 for more information on
core parking), the kernel enters a tight spin-based loop for
ExpSpinCycleCount cycles just like a spinlock would, but without raising the
IRQL, issuing a yield instruction (such as a pause on x86/x64) for each
iteration. If during any of the iterations, the pushlock now appears to be
released, an interlocked operation to acquire the pushlock is performed.
If the spin cycle times out, or the interlocked operation failed (due to a
race), or if the system does not have at least one additional unparked
processor, then KeWaitForSingleObject is used on the event object in the
pushlock wait block. ExpSpinCycleCount is set to 10240 cycles on any
machine with more than one logical processor and is not configurable. For
systems with an AMD processor that implements the MWAITT (MWAIT
Timer) specification, the monitorx and mwaitx instructions are used instead
of a spin loop. This hardware-based feature enables waiting, at the CPU
level, for the value at an address to change without having to enter a loop, but
they allow providing a timeout value so that the wait is not indefinite (which
the kernel supplies based on ExpSpinCycleCount).
On a final note, with the introduction of the AutoBoost feature (explained
in Chapter 4 of Part 1), pushlocks also leverage its capabilities by default,
unless callers use the newer ExXxxPushLockXxxEx, functions, which allow
passing in the EX_PUSH_LOCK_FLAG_DISABLE_AUTOBOOST flag that
disables the functionality (which is not officially documented). By default,
the non-Ex functions now call the newer Ex functions, but without supplying
the flag.
Address-based waits
Based on the lessons learned with keyed events, the key synchronization
primitive that the Windows kernel now exposes to user mode is the alert-by-
ID system call (and its counterpart to wait-on-alert-by-ID). With these two
simple system calls, which require no memory allocations or handles, any
number of process-local synchronizations can be built, which will include the
addressed-based waiting mechanism we’re about to see, on top of which
other primitives, such as critical sections and SRW locks, are based upon.
Address-based waiting is based on three documented Win32 API calls:
WaitOnAddress, WakeByAddressSingle, and WakeByAddressAll. These
functions in KernelBase.dll are nothing more than forwarders into Ntdll.dll,
where the real implementations are present under similar names beginning
with Rtl, standing for Run Time Library. The Wait API takes in an address
pointing to a value of interest, the size of the value (up to 8 bytes), and the
address of the undesired value, plus a timeout. The Wake APIs take in the
address only.
First, RtlWaitOnAddress builds a local address wait block tracking the
thread ID and address and inserts it into a per-process hash table located in
the Process Environment Block (PEB). This mirrors the work done by
ExBlockOnAddressPushLock as we saw earlier, except that a hash table
wasn’t needed because the caller had to store a push lock pointer somewhere.
Next, just like the kernel API, RtlWaitOnAddress checks whether the target
address already has a value different than the undesirable one and, if so,
removes the address wait block, returning FALSE. Otherwise, it will call an
internal function to block.
If there is more than one unparked processor available, the blocking
function will first attempt to avoid entering the kernel by spinning in user
mode on the value of the address wait block bit indicating availability, based
on the value of RtlpWaitOnAddressSpinCount, which is hardcoded to 1024 as
long as the system has more than one processor. If the wait block still
indicates contention, a system call is now made to the kernel using
NtWaitForAlertByThreadId, passing in the address as the hint parameter, as
well as the timeout.
If the function returns due to a timeout, a flag is set in the address wait
block to indicate this, and the block is removed, with the function returning
STATUS_TIMEOUT. However, there is a subtle race condition where the
caller may have called the Wake function just a few cycles after the wait has
timed out. Because the wait block flag is modified with a compare-exchange
instruction, the code can detect this and actually calls
NtWaitForAlertByThreadId a second time, this time without a timeout. This
is guaranteed to return because the code knows that a wake is in progress.
Note that in nontimeout cases, there’s no need to remove the wait block,
because the waker has already done so.
On the writer’s side, both RtlWakeOnAddressSingle and
RtlWakeOnAddressAll leverage the same helper function, which hashes the
input address and looks it up in the PEB’s hash table introduced earlier in this
section. Carefully synchronizing with compare-exchange instructions, it
removes the address wait block from the hash table, and, if committed to
wake up any waiters, it iterates over all matching wait blocks for the same
address, calling NtAlertThreadByThreadId for each of them, in the All usage
of the API, or only the first one, in the Single version of the API.
With this implementation, we essentially now have a user-mode
implementation of keyed events that does not rely on any kernel object or
handle, not even a single global one, completely removing any failures in
low-resource conditions. The only thing the kernel is responsible for is
putting the thread in a wait state or waking up the thread from that wait state.
The next few sections cover various primitives that leverage this
functionality to provide synchronization during contention.
Critical sections
Critical sections are one of the main synchronization primitives that
Windows provides to user-mode application developers on top of the kernel-
based synchronization primitives. Critical sections and the other user-mode
primitives you’ll see later have one major advantage over their kernel
counterparts, which is saving a round trip to kernel mode in cases in which
the lock is noncontended (which is typically 99 percent of the time or more).
Contended cases still require calling the kernel, however, because it is the
only piece of the system that can perform the complex waking and
dispatching logic required to make these objects work.
Critical sections can remain in user mode by using a local bit to provide
the main exclusive locking logic, much like a pushlock. If the bit is 0, the
critical section can be acquired, and the owner sets the bit to 1. This
operation doesn’t require calling the kernel but uses the interlocked CPU
operations discussed earlier. Releasing the critical section behaves similarly,
with bit state changing from 1 to 0 with an interlocked operation. On the
other hand, as you can probably guess, when the bit is already 1 and another
caller attempts to acquire the critical section, the kernel must be called to put
the thread in a wait state.
Akin to pushlocks and address-based waits, critical sections implement a
further optimization to avoid entering the kernel: spinning, much like a
spinlock (albeit at IRQL 0—Passive Level) on the lock bit, hoping it clears
up quickly enough to avoid the blocking wait. By default, this is set to 2000
cycles, but it can be configured differently by using the
InitializeCriticalSectionEx or InitializeCriticalSectionAndSpinCount API at
creation time, or later, by calling SetCriticalSectionSpinCount.
 Note
As we discussed, because WaitForAddressSingle already implements a
busy spin wait as an optimization, with a default 1024 cycles, technically
there are 3024 cycles spent spinning by default—first on the critical
sections’ lock bit and then on the wait address block’s lock bit, before
actually entering the kernel.
When they do need to enter the true contention path, critical sections will,
the first time they’re called, attempt to initialize their LockSemaphore field.
On modern versions of Windows, this is only done if
RtlpForceCSToUseEvents is set, which is the case if the
KACF_ALLOCDEBUGINFOFORCRITSECTIONS (0x400000) flag is set
through the Application Compatibility Database on the current process. If the
flag is set, however, the underlying dispatcher event object will be created
(even if the field refers to semaphore, the object is an event). Then, assuming
that the event was created, a call to WaitForSingleObject is performed to
block on the critical section (typically with a per-process configurable
timeout value, to aid in the debugging of deadlocks, after which the wait is
reattempted).
In cases where the application compatibility shim was not requested, or in
extreme low-memory conditions where the shim was requested but the event
could not be created, critical sections no longer use the event (nor any of the
keyed event functionality described earlier). Instead, they directly leverage
the address-based wait mechanism described earlier (also with the same
deadlock detection timeout mechanism from the previous paragraph). The
address of the local bit is supplied to the call to WaitOnAddress, and as soon
as the critical section is released by LeaveCriticalSection, it either calls
SetEvent on the event object or WakeAddressSingle on the local bit.
 Note
Even though we’ve been referring to APIs by their Win32 name, in
reality, critical sections are implemented by Ntdll.dll, and KernelBase.dll
merely forwards the functions to identical functions starting with Rtl
instead, as they are part of the Run Time Library. Therefore,
RtlLeaveCriticalSection calls NtSetEvent. RtlWakeAddressSingle, and so
on.
Finally, because critical sections are not kernel objects, they have certain
limitations. The primary one is that you cannot obtain a kernel handle to a
critical section; as such, no security, naming, or other Object Manager
functionality can be applied to a critical section. Two processes cannot use
the same critical section to coordinate their operations, nor can duplication or
inheritance be used.
User-mode resources
User-mode resources also provide more fine-grained locking mechanisms
than kernel primitives. A resource can be acquired for shared mode or for
exclusive mode, allowing it to function as a multiple-reader (shared), single-
writer (exclusive) lock for data structures such as databases. When a resource
is acquired in shared mode and other threads attempt to acquire the same
resource, no trip to the kernel is required because none of the threads will be
waiting. Only when a thread attempts to acquire the resource for exclusive
access, or the resource is already locked by an exclusive owner, is this
required.
To make use of the same dispatching and synchronization mechanism you
saw in the kernel, resources make use of existing kernel primitives. A
resource data structure (RTL_RESOURCE) contains handles to two kernel
semaphore objects. When the resource is acquired exclusively by more than
one thread, the resource releases the exclusive semaphore with a single
release count because it permits only one owner. When the resource is
acquired in shared mode by more than one thread, the resource releases the
shared semaphore with as many release counts as the number of shared
owners. This level of detail is typically hidden from the programmer, and
these internal objects should never be used directly.
Resources were originally implemented to support the SAM (or Security
Account Manager, which is discussed in Chapter 7 of Part 1) and not exposed
through the Windows API for standard applications. Slim Reader-Writer
Locks (SRW Locks), described shortly, were later implemented to expose a
similar but highly optimized locking primitive through a documented API,
although some system components still use the resource mechanism.
Condition variables
Condition variables provide a Windows native implementation for
synchronizing a set of threads that are waiting on a specific result to a
conditional test. Although this operation was possible with other user-mode
synchronization methods, there was no atomic mechanism to check the result
of the conditional test and to begin waiting on a change in the result. This
required that additional synchronization be used around such pieces of code.
A user-mode thread initializes a condition variable by calling
InitializeConditionVariable to set up the initial state. When it wants to
initiate a wait on the variable, it can call SleepConditionVariableCS, which
uses a critical section (that the thread must have initialized) to wait for
changes to the variable, or, even better, SleepConditionVariableSRW, which
instead uses a Slim Reader/Writer (SRW) lock, which we describe next,
giving the caller the advantage to do a shared (reader) of exclusive (writer)
acquisition.
Meanwhile, the setting thread must use WakeConditionVariable (or
WakeAllConditionVariable) after it has modified the variable. This call
releases the critical section or SRW lock of either one or all waiting threads,
depending on which function was used. If this sounds like address-based
waiting, it’s because it is—with the additional guarantee of the atomic
compare-and-wait operation. Additionally, condition variables were
implemented before address-based waiting (and thus, before alert-by-ID) and
had to rely on keyed events instead, which were only a close approximation
of the desired behavior.