i=1 nid(cid:11)nie.
n Pr
2n Pr
n Pr
Proof. For the proof of 2.2, observe that G(U jVa) =
. We conclude that
i=1
2 . The other cases are similarly
j=1 j 1
= 1
ni
2n Pr
i=1 n2
n Pr
i + 1
(ni+1)ni
ni
i=1
n Pni
Pr
G(U jVa) = 1
straightforward.
2
While there are clear connections between the entropy
measures in the uniform case, there is no general relationship
between them for arbitrary probability distributions. Mas-
sey [22] shows that one can give lower bounds for G(X) in
terms of H(X), but that there are no general upper bounds
for G(X) in terms of H(X). Pliam [30] shows that there can
be no general inequality between marginal guesswork and
Shannon entropy.
Worst Case Entropy Measures.
All entropy measures presented so far are average case
measures. We use the example of guessing entropy to illu-
strate this and to show how they can be adapted to accom-
modate stronger, worst case guarantees.
The conditional guessing entropy G(U jVa) weights each
value G(U jVa = B) by the probability that a randomly cho-
sen key from K is contained in B 2 Pa. As G(U jVa = B)
measures the di(cid:14)culty of guessing a key if its enclosing block
B is known, G(U jVa) quanti(cid:12)es whether keys are, on the
average, hard to guess after an attack with strategy a.
Our model also accommodates entropy measures for a
worst case analysis, in the sense that they quantify the gues-
sing e(cid:11)ort for the keys in K that are easiest to guess. To cap-
ture this, we de(cid:12)ne the minimal guessing entropy ^G(U jVa) of
U given Va as ^G(U jVa) = minfG(U jVa = B) j B 2 Pag. The
value ^G(U jVa) is a lower bound on the expected guessing
e(cid:11)ort for the weakest keys in K.
The following example illustrates the di(cid:11)erence between
worst case and average case entropy measures.
Example 5. Consider a set of uniformly distributed keys
K = f1; : : : ; 10g and the partitions P = ff1g; f2; : : : ; 10gg
and Q = ff1g; : : : ; f10gg. We have ^G(U jVP ) = 1, which re-
(cid:13)ects that there exists a key that is trivial to guess with
knowledge of its enclosing block in P . The conditional gues-
sing entropy yields G(U jVP ) = 4:6 which re(cid:13)ects that, on
the average, 4.6 guesses are still necessary for key recove-
ry. Note that ^G(U jVP ) = ^G(U jVQ) and that G(U jVQ) =
1 < G(U jVP ). That is, only the average case measure can
distinguish between the partitions P and Q.
Ultimately, it will depend on the application whether worst
case or average case measures are appropriate. For the re-
mainder of this paper, we will focus solely on average case
measures, as they are better suited for distinguishing bet-
ween partitions. All of our technical results, however, carry
over to the worst case versions with only minor modi(cid:12)cati-
ons.
Given entropy measures for evaluating attack strategies,
we can now de(cid:12)ne attack optimality and give bounds for
what an attacker can, in principle, achieve by performing a
side-channel attack.
3.2 Measuring the Resistance to Optimal
Attacks
There is a trade-o(cid:11) between the number of attack steps ta-
ken and the attacker’s uncertainty about the key. More side-
channel measurements imply less uncertainty, which entails
fewer guesses. In the following, we give a formal account of
this for the entropy measures introduced. We then de(cid:12)ne a
function (cid:8)E that is parameterized by an entropy measure
E 2 fH; G; W(cid:11)g and whose value is the expected remaining
uncertainty about the key after n steps of an optimal attack
strategy. As we will show, (cid:8)E can be used for assessing an
implementation’s vulnerability to side-channel attacks.
When assessing the vulnerability of an implementation
to active side-channel attacks, we make the worst case as-
sumption that the attacker proceeds optimally. A strategy
is optimal if an attacker who follows it can expect to have
less uncertainty about the key than with any other strategy
of the same length.
De(cid:12)nition 4. Let a = (T; r; L) be an attack strategy of
length l against a set of partitions P of K. We call a optimal
with respect to E 2 fH; G; W(cid:11)g i(cid:11) E(U jVa) (cid:20) E(U jVb) holds
for all attack strategies b against P of length l.
Next, we de(cid:12)ne the expected remaining uncertainty as a
function of the number of attack steps taken by an optimal
attacker. In this way, we relate two important aspects of a
system’s vulnerability. Namely, how much information can
an attacker obtain and how many queries he needs for this.
De(cid:12)nition 5. Let P be a set of partitions of K and let
E 2 fH; G; W(cid:11)g. We de(cid:12)ne the resistance (cid:8)E to an attack
against P by
(cid:8)E (n) = E(U jVa) ;
where a is an optimal attack of length n with respect to E.
We now formally justify the intuition that more attack steps
lead to less uncertainty about the key. In particular, we prove
that (cid:8)E decreases monotonously. As notation, we say that
an attack strategy a = (T; r; L) is the pre(cid:12)x of an attack
strategy b = (T 0; r0; L0) if T is a subtree of T 0, r = r0, and
if L and L0 coincide on T . We denote this by a (cid:20) b.
Proposition 3. Let E 2 fH; G; W(cid:11)g be an entropy mea-
sure and let a and b be attack strategies.
1. a (cid:20) b implies E(U jVa) (cid:21) E(U jVb).
2. For all n 2 N, we have (cid:8)E (n) (cid:21) (cid:8)E (n + 1).
i=1 i pU (xB
Proof. We prove 3.1 for the case of the guessing entro-
py G. Consider a partition P of K. It is easy to see that
G(U jVP ) = PB2P PjBj
i ), where the elements xB
of block B are indexed in order of their decreasing probabili-
ties. Observe that the probabilities in the sum do not depend
on P , but that the indices of the elements decrease as P is
re(cid:12)ned. As a (cid:20) b implies Pa w Pb, 3.1 follows. Assertion 3.2
is a simple consequence of 3.1.
4. AUTOMATED VULNERABILITY
ANALYSIS
In the following, we (cid:12)rst show that (cid:8)E is computable for
E 2 fH; G; W(cid:11)g and we give algorithms and complexity
bounds. The bounds are exponential and render direct com-
putation infeasible. We then present a greedy heuristic for
approximating (cid:8)E to address this problem.
Throughout this section, let P be a set of partitions of
K and let r (cid:21) 2 be the maximum number of blocks of a
partition in P, i.e., r = maxfjP j j P 2 Pg. We assume
that partitions are represented using standard disjoint-set
data structures with operations Union and Find (see, e.g.,
[13]). Furthermore, we assume that O and K are ordered
sets for which two elements can be compared in O(1). It is
not di(cid:14)cult to see that, given a function f : K (cid:2) M ! O,
one can build disjoint-set data structures for Pf in time
O(jM j jKj log jKj), under the assumption that f can be com-
puted in time O(1).
4.1 Computing (cid:8)E
We begin by establishing an upper bound on the number
of attack strategies of a given length; we will use this later
when we compute (cid:8)E by enumerating strategies.
Lemma 1. The number of attack strategies of length n
rn
against P is bounded from above by jM j
r(cid:0)1 . Furthermore,
every attack strategy of length n can be encoded by an rn-
tuple over f1; : : : ; jM jg.
(cid:0)1
Proof. A straightforward inductive argument shows that
the partition induced by an attack strategy of length n has
at most rn blocks. We prove the claimed bound by inducti-
on on n. For n = 0, the bound is clearly valid. Assume now
rn
that there are at most jM j
r(cid:0)1 attack strategies of length
n. Each such attack strategy can be extended to an attack
strategy of length n+1 by assigning one of the jM j partitions
to every block of the induced partition. There are at most
rn blocks, so there are at most jM jrn
possible extensions.
(cid:0)1
(cid:0)1
rn
r(cid:0)1
(cid:1) jM jrn
In total, there are at most jM j
attack strategies of length n + 1, which concludes our in-
ductive proof. Now observe that the choices of partitions
at level j can be encoded by a rj-tuple (ij;1; : : : ; ij;rj ) over
f1; : : : ; jM jg. As Pn(cid:0)1
r(cid:0)1 (cid:20) rn, the entire strategy
can be encoded by a rn-tuple.
j=0 rj = rn(cid:0)1
= jM j
rn+1
r(cid:0)1
(cid:0)1
Computing (cid:8)E (n) requires identifying an optimal attack
of length n. We may compute (cid:8)E (n) directly by brute for-
ce: enumerate all attack strategies and compute E for each
induced partition. This algorithm yields an upper bound for
the complexity of computing (cid:8)E .
Theorem 1. The value (cid:8)E (n) can be computed in time
O(n jM jrn
jKj log jKj)
under the assumption that E can be computed in time O(jKj).
Proof. Let (i0; : : : ; in(cid:0)1;1; : : : ; in(cid:0)1;rn(cid:0)1 ), with 1 (cid:20) ij (cid:20)
jM j, represent an attack strategy a of length n, where the
choices of partitions at each level are encoded as in the proof
of Lemma 1 and where the individual levels are separated
by \;". Iterate over all k 2 K. For each k, call Find(k) on
the representation of partition i0 to obtain the index j of k’s
enclosing block in Pi0 . Use Find(k) to obtain k’s block in
Pi1;j . Repeat this procedure until k’s block in the partition
at depth n is determined. Save these n block indices in a list
and store it in an array I at index k. Performing this proce-
dure for all k 2 K has time complexity O(n jKj log jKj). Two
keys are in the same block of the partition induced by a if and
only if their corresponding index lists coincide. To obtain
the equivalence classes, sort K according to the lexicogra-
phic order given by the lists in I in O(n jKj log jKj), which
dominates the running time for evaluating E on the resulting
partition. Performing this procedure for all attack strategies
yields an overall running time of O(n jM jrn
4.2 Approximating (cid:8)E
jKj log jKj).
Brute-force computation of (cid:8)E requires time doubly expo-
nential in the number of attack steps and is hence infeasible
even for small parameter sizes. To address this problem, we
present a more e(cid:14)cient greedy heuristic and describe pro-
perties that help us approximate (cid:8)E .
A Greedy Heuristic.
Consider an attacker who has performed a number of at-
tack steps against a set of partitions P and has narrowed
down the set of possible keys to a subset A (cid:18) K. A gree-
dy choice for the subsequent query is a partition P 2 P
that minimizes the remaining entropy of A \ P . To forma-
lize this, consider the random variable UA = idA that mo-
dels the random choice of a key according to the conditio-
nal probability distribution p((cid:1)jA), and the random variable
VP \A : A ! P \ A that models the choice of the enclosing
block in P \ A.
De(cid:12)nition 6. An attack strategy a = (T; r; L) against P,
with T = (V; E), is greedy with respect to E 2 fH; G; W(cid:11)g i(cid:11)
for every v 2 V and all P; Q 2 P, fL(w) j w 2 succ(v)g =
L(v) \ P implies E(UAjVP \A) (cid:20) E(UAjVQ\A).
We next de(cid:12)ne an approximation ^(cid:8)E of (cid:8)E based on the
partition induced by a greedy strategy. Note that greedy
strategies are not unique and that the induced partitions
of two greedy strategies of the same length need not even
have the same entropy. Hence to de(cid:12)ne an approximation
^(cid:8)E we assume a (cid:12)xed greedy strategy a of su(cid:14)cient length
l whose underlying tree is full. For all n (cid:20) l, we denote
the full pre(cid:12)x of a with length n by a(n). We de(cid:12)ne ^(cid:8)a
E
as ^(cid:8)a
E (n) = E(U jVa(n)), for all n (cid:20) l. We only use a as an
artifact to consistently resolve the nondeterminism of greedy
strategies of di(cid:11)erent lengths. From now on, we assume that
a greedy strategy a of su(cid:14)cient length is (cid:12)xed and write ^(cid:8)E
instead of ^(cid:8)a
E .
Theorem 2. The value ^(cid:8)E (n) can be computed in time
O(n r jM j jKj2) ;
under the assumption that E can be computed in time O(jKj).
Proof. For computing intersections of partitions, we as-
sume a list representation of the blocks of every partition, in
which every list is ordered with respect to the order on K.
This can be extracted from the given disjoint-set data struc-
tures in time O(jM j jKj2). For a (cid:12)xed subset of K that is
represented as an ordered list, a greedy re(cid:12)nement can then