required to make the ﬁrst authentication decision in a ses-
sion. FAR is the fraction of strokes of imposters that are
recognized as strokes of the legitimate user by the classiﬁer.
FRR is the fraction of strokes of legitimate users that are
rejected by the classiﬁer. FRR quantiﬁes the empirical prob-
ability that the legitimate user must resort to conventional
authentication mechanisms. Put in a temporal context, if Ts
is the average time between two strokes, then the expected
time after which the legitimate user must type in a password
due to misclassiﬁcation is FRR−1Ts.
The two error rates FRR and FAR can be traded oﬀ
against each other via changing the decision threshold of
the classiﬁer. For instance, at the cost of missing out some
imposters one can reduce FRR by decreasing the threshold.
In order to account for this usability-security trade-oﬀ, we
report the equal error rate (EER) in all experiments. This
is the error rate at the threshold where FAR equals FRR.
For a classiﬁer and an attack dataset (e.g., random attacks
using strokes collected in sa, targeted attacks using strokes
collected in sb), we compute an EER using the dataset that
consists of the classiﬁer’s test positive examples (legitimate
strokes) and the attack dataset.
Intuitively, EER in our
context measures the degree of separability between touch
strokes of legitimate users and attack strokes.
6.3 Results for classiﬁers
Table 4 and Table 5 show the mean EERs of our sub-
jects for each classiﬁer and each attack dataset for horizontal
strokes and vertical strokes, respectively.
Diﬀ-setting attacks vs.
same-setting attacks: We
call an attack as a same-setting attack if the attack strokes
are collected in the same setting with the one in which the
classiﬁer uses. Otherwise, we call an attack diﬀ-setting at-
tack. For instance, random attacks using strokes collected
in the setting sa to the classiﬁer C-Baseline-a or C-ATCA-a
are same-setting attacks, while random attacks using strokes
collected in the setting sa to the classiﬁer C-Baseline-b or
C-ATCA-b are diﬀ-setting attacks. Moreover, we denote by
RA-xy (or TA-xy) the random attacks (or targeted attacks)
that use strokes collected in the setting sy to the classiﬁer
that uses the setting sx, where x, y ∈ {a, b, c, d, e}.
As we expect, same-setting targeted attacks achieve higher
EERs than diﬀ-setting targeted attacks for both C-Baseline
classiﬁers and our C-ATCA classiﬁers. This is because users’
touch behaviors are sensitive. For instance, for horizontal
strokes, EERs of diﬀ-setting targeted attacks are 13%-34%
smaller than those of same-setting targeted attacks for our
C-ATCA classiﬁers depending on which setting is used to
collect the targeted attacks data.
Moreover, when the diﬀerence between the screen setting
used to collect the targeted attacks data and the screen set-
ting of the classiﬁer increases, the EER of the corresponding
diﬀ-setting attacks decreases. For instance, for horizontal
strokes, the EER of the diﬀ-setting targeted attack TA-ea
is 12% smaller than that of the diﬀ-setting targeted attack
TA-ba for our C-ATCA classiﬁers. Our observations imply
that users’ touch behaviors are more sensitive when the dif-
ferences between screen settings are larger.
C-Baseline vs. C-ATCA: Our classiﬁers perform signiﬁ-
cantly better than C-Baseline classiﬁers at defending against
diﬀ-setting attacks. Speciﬁcally, EERs of diﬀ-setting ran-
Table 5: Mean EERs over all subjects for each classiﬁer and attack dataset for vertical strokes. Numbers in parentheses are
standard deviations.
(a) Vertical strokes, random attacks
sa
sb
sc
sd
se
C-Baseline-a
C-Baseline-b
C-Baseline-c
C-Baseline-d
C-Baseline-e
C-ATCA-a
C-ATCA-b
C-ATCA-c
C-ATCA-d
C-ATCA-e
0.09(0.0873)
0.08(0.0641)
0.11(0.0992)
0.12(0.1019)
0.15(0.1100)
0.07(0.0802)
0.08(0.0698)
0.08(0.0748)
0.07(0.0688)
0.07(0.0702)
0.10(0.0913)
0.08(0.0652)
0.12(0.1019)
0.12(0.0969)
0.14(0.1046)
0.05(0.0727)
0.11(0.0742)
0.08(0.0785)
0.08(0.0763)
0.06(0.0644)
0.11(0.0986)
0.09(0.0697)
0.12(0.1032)
0.12(0.0980)
0.14(0.1065)
0.05(0.0697)
0.09(0.0742)
0.12(0.0914)
0.08(0.0759)
0.07(0.0672)
0.11(0.1024)
0.10(0.0760)
0.12(0.1091)
0.11(0.0936)
0.14(0.1060)
0.05(0.0692)
0.08(0.0766)
0.09(0.0799)
0.11(0.0843)
0.08(0.0728)
0.12(0.1089)
0.10(0.0867)
0.13(0.1161)
0.12(0.1022)
0.15(0.1158)
0.07(0.0960)
0.09(0.0819)
0.11(0.0899)
0.10(0.0846)
0.12(0.0935)
(b) Vertical strokes, targeted attacks
sa
sb
sc
sd
se
C-Baseline-a
C-Baseline-b
C-Baseline-c
C-Baseline-d
C-Baseline-e
C-ATCA-a
C-ATCA-b
C-ATCA-c
C-ATCA-d
C-ATCA-e
0.50(0.0000)
0.48(0.0747)
0.44(0.1189)
0.42(0.1345)
0.44(0.1018)
0.50(0.0000)
0.36(0.1200)
0.33(0.1093)
0.28(0.0949)
0.25(0.1091)
0.44(0.0930)
0.50(0.0000)
0.44(0.0825)
0.43(0.0978)
0.44(0.1122)
0.26(0.0956)
0.50(0.0000)
0.32(0.1048)
0.31(0.0842)
0.28(0.0988)
0.42(0.1322)
0.45(0.1198)
0.50(0.0000)
0.46(0.1154)
0.45(0.0820)
0.26(0.1264)
0.30(0.0940)
0.50(0.0000)
0.30(0.0986)
0.30(0.0811)
0.41(0.1587)
0.42(0.1209)
0.46(0.1199)
0.50(0.0000)
0.47(0.1025)
0.24(0.1304)
0.31(0.1167)
0.31(0.1091)
0.50(0.0000)
0.29(0.0914)
0.35(0.1651)
0.38(0.1289)
0.41(0.1614)
0.44(0.0811)
0.50(0.0000)
0.23(0.1405)
0.31(0.1324)
0.32(0.1282)
0.31(0.0803)
0.50(0.0000)
Table 6: Possible attacks to the 7 authentication systems.
S-Baseline-a
S-Baseline-b
S-Baseline-c
S-Baseline-d
S-Baseline-e
Random attacks
max{RA-ay} for y ∈ {a, b, c, d, e}
max{RA-by} for y ∈ {a, b, c, d, e}
max{RA-cy} for y ∈ {a, b, c, d, e}
max{RA-dy} for y ∈ {a, b, c, d, e}
max{RA-ey} for y ∈ {a, b, c, d, e}
Targeted attacks
TA-aa
TA-bb
TA-cc
TA-dd
TA-ee
S-Baseline-improved RA-xy, where x, y ∈ {a, b, c, d, e} TA-xy, where x, y ∈ {a, b, c, d, e}
RA-xy, where x, y ∈ {a, b, c, d, e} TA-xy, where x, y ∈ {a, b, c, d, e}
S-ATCA
dom attacks to our classiﬁers are 1% to 8% smaller than
those of the C-Baseline classiﬁers. For instance, with hori-
zontal strokes, the EER of the diﬀ-setting random attacks
RA-ea is 9% for the C-Baseline-e classiﬁer. However, the
EER of RA-ea is 3% for our classiﬁer C-ATCA-e, which
is 6% smaller than the C-Baseline-e classiﬁer. Moreover,
EERs of diﬀ-setting targeted attacks to our classiﬁers are
6% to 22% smaller than those of the C-Baseline classiﬁers.
For instance, with horizontal strokes, the EER of the diﬀ-
setting targeted attacks TA-ea is 39% for the C-Baseline-e
classiﬁer. However, the EER of TA-ea is 21% for our classi-
ﬁer C-ATCA-e, which is 18% smaller than the C-Baseline-e
classiﬁer. This is because a user’s touch behaviors in the ﬁve
screen settings are both stable and sensitive, which results
in high EERs for the C-Baseline classiﬁers and explains the
low EERs for our classiﬁers, respectively.
For same-setting random attacks, the EERs of our clas-
siﬁers are slightly larger than those of the C-Baseline clas-
siﬁers in some cases. This is because our classiﬁers in a
setting s use more negative examples other than the strokes
of other users collected in s, which somehow makes their
decision boundaries move towards the strokes of other users
collected in s, and thus same-setting random attacks achieve
slightly higher EERs. As we expect, same-setting targeted
attacks achieve high EERs for all classiﬁers. Speciﬁcally,
EERs of our classiﬁers and the C-Baseline classiﬁers are all
close to 50% for same-setting targeted attacks. This means
that, for each stroke, the classiﬁer makes a random decision,
i.e., it accepts or rejects it with the same probability of 0.5.
6.4 Results for authentication systems
We ﬁrst introduce possible attacks to the considered au-
thentication systems and then show comparison results.
Attacks: Suppose the attacker already knows the set of
settings {sa, sb, sc, sd, se} that could be used by the authen-
tication systems. Moreover, for a targeted user, we assume
the attacker obtains touch strokes of the targeted user or
other users in all the ﬁve settings. This means that the
Table 7: Mean EERs over all subjects for each authentica-
tion system and attack for horizontal strokes and vertical
strokes. Numbers in parentheses are standard deviations.
We ﬁnd that our authentication system achieves signiﬁcantly
smaller EERs than previous work for both random attacks
and targeted attacks.
(a) Horizontal strokes
S-Baseline-a
S-Baseline-b
S-Baseline-c
S-Baseline-d
S-Baseline-e
S-Baseline-improved
S-ATCA
Random attacks Targeted attacks
0.08(0.0577)
0.06(0.0516)
0.09(0.0616)
0.11(0.0817)
0.11(0.0969)
0.07(0.0412)
0.04(0.0488)
0.50(0.0000)
0.50(0.0000)
0.50(0.0000)
0.50(0.0000)
0.50(0.0000)
0.44(0.0512)
0.32(0.0783)
(b) Vertical strokes
S-Baseline-a
S-Baseline-b
S-Baseline-c
S-Baseline-d
S-Baseline-e
S-Baseline-improved
S-ATCA
Random attacks Targeted attacks
0.12(0.1067)
0.11(0.0819)
0.14(0.1111)
0.14(0.1051)
0.17(0.1187)
0.12(0.0777)
0.08(0.0542)
0.50(0.0000)
0.50(0.0000)
0.50(0.0000)