作者：oxen@EnsecTeam  
公众号：[EnsecTeam](https://mp.weixin.qq.com/s/P9LJe2ZFbgdB2FkD2km5WA "EnsecTeam")
我们专注漏洞检测方向：danenmao、arnoxia、皇天霸、lSHANG、KeyKernel、BugQueen、zyl、隐形人真忙、oxen（不分先后）
提示：文章主要介绍漏洞扫描服务的衡量指标及如何解决的一些实践经验思考，大概阅读完所需时间15分钟左右
上一篇：[《分布式Web漏洞扫描服务建设实践系列——扫描架构演进及要点问题解决实践》](https://paper.seebug.org/634/
"《分布式Web漏洞扫描服务建设实践系列——扫描架构演进及要点问题解决实践》")
#### 一 引 言
一款扫描产品上线后，我们经常会反思到底做得怎么样呢？那么如何去衡量一款扫描器的优劣呢？我们确定了几个指标：准确率、扫描及时度及自主发现率，通俗来讲就是如何更快、更全、更准、更智能的去扫描，或者说如何能达到一种完美的平衡，下面从这四个维度去阐述一下我们的实践及思考。
#### 二 衡量指标及解决思路
##### （一）更快（扫描及时度）
更快：更及时发现漏洞，甚至追求在攻击者之前发现安全漏洞，但有一些残酷现实摆在面前：
  * 线上业务存在数千万的url需要扫描（截止目前数据中心已经收集超过7千万url，并且已经根据url进行了去重去脏处理）；
  * 存在众多安全漏洞扫描poc（光通用漏洞poc单个url发包量粗略估计10000+以上，还不包括第三方已知漏洞poc）；
  * 需要根据业务线承压能力进行限速（小的产品线能够承载的qps小于50/s）：这意味着即使不考虑poc本身扫描时间，光考虑限速单个url扫描就需要3.3分钟，再加上poc本身运行时间、集群调度时间，单个url总扫描时间肯定大于3.3分钟。
我们期望一轮线上所有业务例行扫描能够在3小时以内解决战斗，甚至期望能够做到1小时以内；集群形态时考虑的就是增加机器资源，通过足够的机器资源来提升扫描性能，即使不考虑资源成本，但因为有限速的限制，累加资源最终也会遇到瓶颈，况且真没这么多机器（偷笑）；这条路看来是走不通的，还是得从源头进行解决：
1.降低扫描量
数据中心中存在6千万url（已经经过了前面介绍的基于hash的url处理过程），但是有多少url是应该扫描或值得扫描？如果无区别的进行同等扫描估计一个月都没法完成一轮扫描，这里需要方法将数据中心中应该扫描的url抽取出来，减少扫描的url量。我们的思路是：
（1）抽取待扫描URL：通过url页面内容变化来判断当前url是否值得或需要扫描，这个过程中需要排除动态内容对内容相似性对比的干扰（默认认为内容存在变化才需要二次扫描）；同时存在后端逻辑变化未反映到页面内容的情形，这种该如何进行识别？完全识别应该是做不到的，只能借助其他手段辅助进行判断；比如可以通过数据分析统计出同一域名下不同url的访问顺序，通过顺序的变化来辅助判断，甚至可以统计不同url的访问量，通过访问量的变化来进行判断等，可以综合这些因素进行考虑筛选；
（2）分阶段进行：第一阶段优先扫描当天库中新增URL（url第一次扫描），第二阶段每半周扫描一次库中有变动的URL，第三阶段每月扫描一次库中全量URL，主要用于弥补后端逻辑有变化但是未引起页面内容变化，导致第二阶段扫描无法覆盖的case。
（3）分类进行：如果url实在太多，这里只能进行取舍，可以按照业务重要性及业务风险情况等维度进行url分类，优先去扫描既重要又风险大的业务。
2.降低poc发包量
针对常见通用安全漏洞，全部重新调研目前的主流扫描方案，然后结合自身经验进行充分思路碰撞形成新扫描方式，同时将poc发包量作为重要考量因素始终贯穿其中，达到换一种扫描思路来降低poc发包量；这里以反射型xss为例，传统扫描方案：收集尽可能全的payloads（至少70+），通过遍历每一个payload发包去验证是否存在漏洞，这里首先不考虑因payloads收集不全而造成漏报的问题，实际上这种情况发生的概率其实不低，就单单从发包量来考虑，单个参数就需要发包70+，一个url按照10处来估算（一个url需要扫描的位置有：headers、path、参数等），单个url至少发包700+，这从速度来考虑简直是灾难。
而新的扫描方案单个参数只需要发包7次不到（包括6次探测包+1次验证包），通过发送探测包（包括`“<>’”/*=”`、`“’”`、`“””`等）来确定xss输出的漏洞点及漏洞发生的具体场景，然后针对其发生场景针对性的构造一个payload进行验证是否存在漏洞即可，相对于传统扫描方案，性能提升了将近10倍。
3.限速
业务的承压能力越强，限速QPS可以放得更宽，相应扫描速度就会越快，尴尬是我们拥有数万域名量，主要里面还有一些小产品线，过高的QPS甚至可以将小产品线扫挂，在没有方法知晓产品线承压能力情况下，只能按照最低限速50QPS进行统一限速扫描；
但实际情况是不同业务线抗压能力相差甚远，统一按照50QPS进行限速将严重影响扫描速度，这里急需根据不同业务线进行逐个的限速设置，不过这里缺乏参照标准，只能借助于业务线的访问量进行大概估计。其实最理想的状态是，能否根据当前业务的响应状态来动态调整发包量？通过发包来确定业务线当前响应的快慢，只要业务线没有响应延迟的情况发生，便可动态调整发包量，从而做到根据业务线实际情况进行限速适配；不幸的是，由于网络延时的变化造成动态调整效果不甚理想，还有一段路需要走，或者是否存在其他更好的方式？
##### （二）更全（自主发现率）
更全：主要关注漏报率，反过来说就是主动发现率；造成漏报概括起来就两点：第一扫描能力不覆盖，第二能力覆盖，但是由于缺乏输入源或者平台产生异常；为了做到更全，我们就需要考虑：
  * 覆盖能覆盖的一切Web漏洞类型；
  * 收集最全的url作为扫描输入源；
  * 建立完善的监控追踪体系，实时监控，第一时间恢复。
理想很美好，可问题是：
（1）漏洞类型，特别是弱点规则成百上千需要收集和整理，这是一个浩大的工程，并且为了扫描的准确性，需要一一搭建本地环境进行验证确认；
（2）存在一些漏洞类型依靠之前传统的扫描思路很难解决，或者说不适合以扫描来解决，并且还是一些非常高危的漏洞类型，比如越权、无回显漏洞等；
（3）扫描之前一直以IDC全流量作为扫描的输入源，可问题是全流量并没有全机房覆盖，同时由于带宽及跨机房传输问题，全流量一直存在30%-40%丢失的问题，更重要的是全流量缺乏post请求类型及https流量，可post流量是检测某些漏洞类型的基础，比如存储型xss，而https是未来发展的趋势。
为了解决这些难题，我们的思路是：
1.规则收集