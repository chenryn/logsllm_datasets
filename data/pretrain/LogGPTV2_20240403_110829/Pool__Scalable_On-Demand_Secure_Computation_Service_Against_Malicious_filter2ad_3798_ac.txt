(5) A search could also terminate from Step 6, which indicates n is
too small to ever achieve ε statistical security at all.
(6) Initiating r0 to 0.01 is arbitrary as r0 can be initiated to any
decimal between 0 and 1. But in practice, setting r0 (cid:66) 0.01
alleviates us from resetting r0 and restart the search (Step 3) for
every n we have ever tried (assuming ε = 2−40).
Optimal strategy? In fact, the pool-based cut-and-choose game
could be framed as a general cost-aware zero-sum game (the utility
is each party’s winning odds). Our analysis above is by no means
the optimal strategy as it unnecessarily restricts the honest party to
a particular set of strategies, i.e., using a constant rc and constant B.
We only claim that the solution described above is optimal under
the premise of using constant rc and B. It is entirely possible to
guarantee an ϵ-bounded failure rate with even less costly strategies.
We leave it as an interesting open question to seek the most cost-
effective strategy to this pool-based cut-and-choose game.
Using additional pools. Because any Boolean circuit can be com-
puted using AND and XOR gates and secure XOR can be realized
without garbling, it suffices to just have a single pool of garbled
AND gates to realize any function. However, we discovered that
sometimes it may be beneficial to have pools of other types of
garbled gadgets when those gadgets, treated as a whole, can be
realized more efficiently than composed from individual AND gates.
In these circumstances, the servers can maintain multiple pools,
each with a different type of garbled gadgets. The security analysis
remains the same for additional pools. We will soon see an example
of exploiting a second pool for realizing MUX 30% more efficiently.
Costs. These include the time for initializing the pool, the storage
for storing the pool, and the time for replenishing the pool. The
time to initialize the pool is essentially the pool size n multiplied by
Rд/(1 − rc) where Rд is the speed of garbled-gate generation and
rc is determined by n and ε in a way described earlier. See Table 3
for concrete numbers about pool initialization. We stress that the
pool only need to be generated once in the lifetime of running the
servers. Likewise, the non-amortizable time required to replenish
the pool is merely B × Rд/(1 − rc) per gate in the target Boolean
circuit.
The storage costs of the pool can depend on n but also the role of
a server, since the garbler remembers wires whereas the evaluator
only need to store the (shorter) i-hashes of wires. Table 4 provides
exact numbers. We also note that the evaluator can even hash every
garbled gate it receives and organize all the hashes with a Merkle
tree. Thus, at a logarithmic cost of operating the Merkle tree, only
a single root hash needs to be stored on the evaluator side.
Round-trips. Our approach requires linear rounds but we will
discuss how a simple buffering trick can avoid most of the round-
trip overhead in Section 6.
5 MORE EFFICIENT SECURE MULTIPLEXERS
MUX is a frequently used component circuit in many computations
such as private set intersection and ORAM. An ℓ-bit MUX takes two
ℓ-bit inputs (say, x0 and x1), a 1-bit choice signal c, and outputs an
ℓ-bit output xc. Conventional approach implements an ℓ-bit MUX
by repeatedly calling a 1-bit MUX ℓ times:
ℓ-MUX(x[ℓ], y[ℓ], c) {
for i from 1 to ℓ
ret[i] ← 1-MUX(x[i], y[i], c);
return ret;
}
Since every 1-MUX can be realized using a single AND as
1-MUX(x, y, c) {
return c∧(x⊕y)⊕y;
}
an ℓ-bit MUX only needs ℓ AND gates.
However, recall that with LEGO protocols, the dominating cost
is actually due to the expensive wires (i.e., the input and output
wires of garbled AND gates) instead of the garbled-tables. Existing
implementation of ℓ-bit MUX requires ℓ AND gates thus involving 3ℓ
wires. Below, we show an optimization that enables more efficient
multiplexers by reducing roughly 1/3 of the wires.
Our approach. We note that the ℓ AND gates in an ℓ-bit MUX share
a common input bit, i.e., the selection bit of the MUX. To exploit this
observation, our key idea is to base our optimized ℓ-bit MUX on a
single special (ℓ + 1)-input ℓ-output circuit gadget, which we call
MUXCORE, and a few XOR gates. Our MUXCORE can be realized as
below:
MUXCORE(a[ℓ], c) {
for i from 1 to ℓ
ret[i] ← a[i]∧c;
return ret;
}
Then, let ⊕ be an ℓ-way parallel XOR (⊕), so ℓ-MUX can be simply
realized as
ℓ-MUX(x[ℓ], y[ℓ], c) {
return MUXCORE(x⊕y, c) ⊕ y;
}
The new implementation will still use ℓ AND gates which are all
wrapped in the MUXCORE gadget, however, since MUXCORE has only
2ℓ + 1 wires, the total number of expensive wires in a ℓ-bit MUX can
thus be reduced from 3ℓ + 1 to 2ℓ + 1 if we treat MUXCORE as a basic
gadget for cut-and-choose.
Checking MUXCORE. To check a garbled MUXCORE gadget, the cir-
cuit evaluator simply uses ℓ + 1 randomly sampled input bits to
obtain the corresponding ℓ + 1 input wire-labels, evaluates the
ℓ AND gates and verifies that the outcomes are consistent with
the commitments/i-hashes (just like the way garbled ANDs are
checked in the underlying LEGO protocol). Note that because every
garbled AND gate inside the MUXCORE gadget is checked with uni-
formly picked inputs, so any faulty AND gates in MUXCORE are still
detected with the same probability rd offered by the underlying
LEGO protocols.
class Party {
public :
/* Encode an input bit of garbler . */
virtual wire ** garblerIn ( bool * b , int len ) =0;
virtual wire ** garblerIn ( int len ) =0;
/* Encode an input bit of evaluator . */
virtual wire ** evaluatorIn ( bool * b , int len ) =0;
virtual wire ** evaluatorIn ( int len ) =0;
/* Reveal an output bit to garbler . */
virtual bool garblerOut ( wire * w) =0;
/* Reveal an output bit to evaluator . */
virtual bool evaluatorOut ( wire * w) =0;
/* Basic binary gates */
virtual wire * and ( wire * l , wire * r) =0;
virtual wire * xor ( wire * l , wire * r) =0;
/* APIs for RAM accesses using ORAM */
wire ** initRAM ( int nBlk , int sz );
wire ** accessRAM ( wire ** mem , wire ** rORw ,
wire ** index , wire ** data );
/* Run the computation specified by the
function `f ' using `ws '. */
wire ** exec (( wire **) f( wire **) , wire ** ws );
/* Run the computation specified in the
circuit file `f ' using
`ws '. */
wire ** exec ( File * f , wire ** ws );
}
class Garbler : public Party {
public :
wire ** garblerIn ( bool * b , int len ) { ... }
wire ** garblerIn ( int len ) { ... }
wire ** evaluatorIn ( bool * b , int len ) { ... }
wire ** evaluatorIn ( int len ) { ... }
bool garblerOut ( wire * wire ) { ... }
bool evaluatorOut ( wire * wire ) { ... }
wire * and ( wire * l , wire * r) { ... }
wire * xor ( wire * l , wire * r) { ... }
}
}
class Evaluator : public Party {
public :
wire ** garblerIn ( bool * b , int len ) { ... }
wire ** garblerIn ( int len ) { ... }
wire ** evaluatorIn ( bool * b , int len ) { ... }
wire ** evaluatorIn ( int len ) { ... }
bool garblerOut ( wire * wire ) { ... }
bool evaluatorOut ( wire * wire ) { ... }
wire * and ( wire * l , wire * r) { ... }
wire * xor ( wire * l , wire * r) { ... }
Figure 3: A succinct set of APIs offered by Pool
6 DESIGN AND IMPLEMENTATION
Design. We have designed and developed Pool, with the goal
of making it easier for non-crypto-expert developers to create and
run future secure computation services against active adversaries.
Thanks to the combination of the pool technique and the LEGO-
based cut-and-choose, we are able to encapsulate the sophisticated
cryptography into a list of application programming interfaces
(API) described in Figure 3.
The APIs include eight basic functions, four of which handle
function inputs (garblerIn, evaluatorIn) and two of which han-
dle outputs (garblerOut, evaluatorOut) while the rest two (and,
xor) handle AND and XOR gates, respectively. Note that there are
two overloaded version of garblerIn, supposed to be invoked si-
multaneously by the garbler and the evaluator, respectively. So are
the overloaded functions evaluatorIn. Since the behaviors of these
eight functions depend on their calling party’s role (either garbler
or evaluator), we define them as virtual functions in the base class
Party but provide concrete implementations in the sub-classes
Garbler and Evaluator. We stress that since the data structures
to represent wires are different on each side, the implementations
of wire also differ between the Garbler and the Evaluator.
Pool provides two different ways to specify and execute com-
putations, which are overloaded under the same function name
exec. The first reads the circuit description from a circuit file (with
the SHDL format used by Fairplay [21] and many other existing
works [25, 29, 35]) and runs the circuit over the wire encodings
supplied as the second argument to exec. Our second way allows
to specify computations as normal C functions (passed to exec as
a function pointer f). We assume the function f only calls AND
and XOR, which will be bound to the implementations of and and
xor functions Pool provides. To facilitate specifying functions in
this manner, Pool offers a library of circuits such as multiplex-
ers and basic arithmetic circuits like many other programming
tools [10, 33, 34] do.
Finally, Pool’s (initRAM and accessRAM) allow application de-
velopers to exploit the efficiency benefits of RAM-based secure
computation through Circuit-ORAM [30].
Example. Figure 4 shows the use of Pool in developing custom
applications. The example is for developing a secure MUX to select
one of two 8-bit numbers. Note that a developer only needs to
write six lines of code to implement mux and mux8 based on ANDs
and XORs. The rest two main functions are template procedures
to run/test custom-built applications (mux8 in our case). Of course,
common circuits like mux and mux8 are already part of Pool’s library
so developers can use them directly without reinventing the wheel.
Implementation Issues. Implemented naïvely, our protocols will
require one round-trip per bucket for the evaluator to disclose his
random choice of B garbled gates in the pool to place in a bucket,
incurring a significant network round-trip overhead. To alleviate
this issue, our simple strategy is to let the garbler maintain an
additional buffer (of 128K garbled-gates) per pool so that we only
need one round-trip per 128K/B buckets. Thus, empty spots in the
pool will always be refilled with garbled-gates from the buffer;
and whenever the buffer is depleted, the garbler will garble and
commit 128K gates altogether, after which the evaluator refresh
the randomness used to select garbled-gates from the pool till next
round of buffer regeneration. This design choice also helps to exploit
the fact that hardware-assisted AES runs faster in batches.
7 EVALUATION
Evaluation Setup. All performance numbers are measured with
single-threaded programs. We leased Amazon EC2 machines (in-
stance type: c4.2xlarge, Ubuntu Linux 16.04) to conduct all the
experiments. We evaluated our implementation in both LAN (2.5
Gbps bandwidth, < 1 ms latency) and WAN (200 Mbps bandwidth,
20 ms latency) settings. We have implemented Pool-Jimu which
// Common application code
wire * mux ( wire * x , wire * y , wire * c) {
return xor ( and (c , xor (x ,y)) , y)
}
wire ** mux8 ( wire ** ws ) {
wire * x = *ws , y = * ws +8 , c= * ws +16;
wire ** ret = new wire *[8];
for ( int i =0; i <8; i ++) {
ret [i] = mux (x+i , y+i , c);
}
return ret ;
}
// Alice 's main function
void main () {
Garbler alice = new Garbler () ;
bool inputA [9] = int2bits (0 x01AA );
wire ** wsA = alice . garblerIn ( inputA , 8) ;
wire ** wsB = alice . evalautorIn (8) ;
wire ** ws = new wire *[17];
for ( int i =0; i <8; i ++) {
* ws [i
]=* wsA [i ];
* ws [i +8]=* wsB [i ];
}
* ws [16] = ** alice . garblerIn ( inputA +8 , 1) ;
wire ** os = alice . exec ( mux8 , ws );
bool * ret = new bool [8];
for ( int i =0; i <8; i ++)
evaluatorOut ( os [i ]) ;
delete os ;
}
// Bob 's main function
void main () {
Evaluator bob = new Evaluator () ;
bool inputB [8] = int2bits (0 xBB );
wire ** wsA = bob . garblerIn (8) ;
wire ** wsB = bob . evalautorIn ( inputB , 8) ;
wire ** ws = new wire *[17];
for ( int i =0; i <8; i ++) {
* ws [i
]=* wsA [i ];
* ws [i +8]=* wsB [i ];
}
* ws [16] = ** bob . garblerIn (1) ;
wire ** os = bob . exec ( mux8 , ws );
bool * ret = new bool [8];
for ( int i =0; i <8; i ++)
ret [i] = evaluatorOut ( os [i ]) ;
printf ("%d" , bits2int ( ret ));
delete os ;
}
Figure 4: Example Application using Pool
uses JIMU [38] as the underlying secure computation scheme, thus
rd = 1/2. We set ε = 2−40. Reference performance data are mea-
sured by running implementations provided by their respective
authors in a test environment identical to that of Pool-Jimu.
7.1 The Pool
System Efficiency. As was discussed in Section 4, the pool size
has a decisive impact on the throughput of our system. Figure 5
depicts how the system performance changes as a result of varying
the pool size. Recall that B/(1 − rc) (the Y-axis in Figure 5a) is the
expected number of garbled AND gates needed to execute a logical-
gate. We also note because the X-axis is on a logarithmic scale, as n
increases, B/(1−rc) actually drops faster than it appears. Therefore,
most of the cost savings can be reaped with relatively smaller n,
e.g., B/(1 − rc) ≈ 4 when n = 8M.
Figure 5b shows the relation between the pool size and the actual
time cost per logical-ANDs of Pool-Jimu. Note that the observed
data points in Figure 5b form a curve of similar shape as that of
theoretical estimations in Figure 5a. A graphical ratio of 2 on the
units of the y-axis between the two figures indicates a garbled-gate
processing speed of roughly 500K garbled-gates/second, which
coincides well with the micro-benchmark of the underlying JIMU
protocol.
Compared to running LEGO protocols without a pool, the ben-
efit of our approach is remarkable. For example, setting n = 220
allows us to execute 100K logical-ANDs/second for circuits of any
sizes, whereas the same speed can only be achieved on running
circuits of more than 100K ANDs using JIMU [38] without a pool.
Note that the actual speed measurements also indicate that most
efficiency advantage of batched cut-and-choose can be harvested
with relatively small pools.
10
8
6
4
2
20
16
12
8
4
)
c
r
−
1
(
/
B
)
D
N
A
/
s
µ
(
d
e
e
p
S
12
16
24
28
20
log n
(a) Theoretical Analysis
12
16
24
28
20
log n
(b) Practical Observation
Figure 5: Relating System Efficiency to Pool Size
Check Rate and Bucket Size. As was described in Section 4, we
calculated the best (B, rc) values for each fixed pool size to mini-
mize B/(1 − rc). Figure 6 shows, under that premise, how B and
rc changes as n increases. Note that rc takes continuous values
relatively close to 0, whereas B takes discrete integral values. As n
grows, B will never increase but the check rate rc will periodically
jump up (synchronized with the changes in B) and then gradually
decrease as n increases while B holds the same.
B
7
6