mapreduce,” in Proc. of ICPADS, 2011.
[30] D. Hendrycks and K. Gimpel, “A baseline for detecting misclassiﬁed
and out-of-distribution examples in neural networks,” in Proc. of ICLR,
2017.
[31] S. T. Jan, Q. Hao, T. Hu, J. Pu, S. Oswal, G. Wang, and B. Viswanath,
“Throwing darts in the dark? detecting bots with limited data using
neural data augmentation,” in Proc. of IEEE S&P, 2020.
[32] A. Javaid, Q. Niyaz, W. Sun, and M. Alam, “A deep learning approach
for network intrusion detection system,” in Proc. of BIONETICS, 2016.
J. Jia, B. Wang, and N. Z. Gong, “Random walk based fake account
detection in online social networks,” in Proc. of DSN, 2017.
[33]
[34] H. Jiang, B. Kim, M. Guan, and M. Gupta, “To trust or not to trust a
classiﬁer,” in Proc. of NeurIPS, 2018.
[35] L. Jiang, Z. Zhou, T. Leung, L.-J. Li, and L. Fei-Fei, “Mentornet:
Learning data-driven curriculum for very deep neural networks on
corrupted labels,” in Proc. of ICML, 2018.
[36] R. Jordaney, K. Sharad, S. K. Dash, Z. Wang, D. Papini, I. Nouretdinov,
in malware
and L. Cavallaro, “Transcend: Detecting concept drift
classiﬁcation models,” in Proc. of USENIX Security, 2017.
[37] KDDCup, “Network intrusion data,” 1999, https://www.kdd.org/
kdd-cup/view/kdd-cup-1999/Data.
[38] A. Khraisat, I. Gondal, P. Vamplew, and J. Kamruzzaman, “Survey
of intrusion detection systems: techniques, datasets and challenges,”
Cybersecurity, 2019.
[39] D. S. Kim, H.-N. Nguyen, and J. S. Park, “Genetic algorithm to improve
svm based network intrusion detection system,” in Proc. of AINA, 2005.
J. Kinable and O. Kostakis, “Malware classiﬁcation based on call graph
clustering,” Journal in computer virology, 2011.
[40]
[41] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980, 2014.
[42] A. Kraskov, H. St¨ogbauer, and P. Grassberger, “Estimating mutual
information,” Physical review E, 2004.
[43] M. Kruczkowski and E. N. Szynkiewicz, “Support vector machine for
malware analysis and classiﬁcation,” in Proc. of WIIAT, 2014.
[44] S. Kudugunta and E. Ferrara, “Deep neural networks for bot detection,”
Information Sciences, 2018.
[45] P. Laskov and N. ˇSrndi´c, “Static detection of malicious javascript-
bearing pdf documents,” in Proc. of ACSAC, 2011.
[46] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” nature, 2015.
[47] W. Lee, S. J. Stolfo, and K. W. Mok, “A data mining framework for
building intrusion detection models,” in Proc. of IEEE S&P, 1999.
[48] H. Li, X.-H. Guan, X. Zan, and C.-Z. HAN, “Network intrusion
detection based on support vector machine,” Journal of Computer
Research and Development, 2003.
[49] Z. Li, Y. Li, and L. Xu, “Anomaly intrusion detection method based
on k-means clustering algorithm with particle swarm optimization,” in
Proc. of ICM, 2011.
[50] N. Milosevic, A. Dehghantanha, and K.-K. R. Choo, “Machine learning
aided android malware classiﬁcation,” Computers & Electrical Engi-
neering, 2017.
[51] Y. Mirsky, T. Doitshman, Y. Elovici, and A. Shabtai, “Kitsune: an
ensemble of autoencoders for online network intrusion detection,” in
Proc. of NDSS, 2018.
[52] K. P. Murphy, Machine learning: a probabilistic perspective. MIT
press, 2012.
[53] C. K. Ng, F. Jiang, L. Y. Zhang, and W. Zhou, “Static malware
clustering using enhanced deep embedding method,” Concurrency and
Computation: Practice and Experience, 2019.
[54] X. Niu, L. Wang, and X. Yang, “A comparison study of credit
card fraud detection: Supervised versus unsupervised,” arXiv preprint
arXiv:1904.10604, 2019.
[55] A. Paszke, S. Gross, S. Chintala, and G. Chanan, “Pytorch: Tensors
and dynamic neural networks in python with strong gpu acceleration,”
PyTorch, 2017.
[56] F. Pendlebury, F. Pierazzi, R. Jordaney, J. Kinder, and L. Cavallaro,
“TESSERACT: Eliminating experimental bias in malware classiﬁcation
across space and time,” in Proc. of USENIX Security, 2019.
[58]
[57] C. Phua, V. Lee, K. Smith, and R. Gayler, “A comprehensive sur-
vey of data mining-based fraud detection research,” arXiv preprint
arXiv:1009.6119, 2010.
J. Quionero-Candela, M. Sugiyama, A. Schwaighofer, and N. D.
Lawrence, Dataset shift in machine learning. The MIT Press, 2009.
[59] A. Rasmus, M. Berglund, M. Honkala, H. Valpola, and T. Raiko, “Semi-
supervised learning with ladder networks,” in Proc. of NeurIPS, 2015.
J. Rivero, B. Ribeiro, N. Chen, and F. S. Leite, “A grassmannian
approach to zero-shot learning for network intrusion detection,” in Proc.
of ICONIP, 2017.
[60]
[61] P. J. Rousseeuw, “Silhouettes: a graphical aid to the interpretation and
validation of cluster analysis,” Journal of computational and applied
mathematics, 1987.
[62] A. S. Sabau, “Survey of clustering based ﬁnancial fraud detection
research,” Informatica Economica, 2012.
[63] T. Shon, Y. Kim, C. Lee, and J. Moon, “A machine learning framework
for network anomaly detection using svm and ga,” in Proc. of IEEE
SMC information assurance workshop, 2005.
[64] C. Smutz and A. Stavrou, “Malicious pdf detection using metadata and
structural features,” in Proc. of ACSAC, 2012.
[65] R. Sommer and V. Paxson, “Outside the closed world: On using machine
learning for network intrusion detection,” in Proc. of IEEE S&P, 2010.
J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel, “The German
Trafﬁc Sign Recognition Benchmark: A multi-class classiﬁcation com-
petition,” in Proc. of IJCNN, 2011.
[66]
[67] A. Strehl and J. Ghosh, “Cluster ensembles—a knowledge reuse frame-
work for combining multiple partitions,” Journal of machine learning
research (JMLR), 2002.
[68] G. Stringhini, P. Mourlanne, G. Jacob, M. Egele, C. Kruegel, and
G. Vigna, “Evilcohort: Detecting communities of malicious accounts
on online services,” in Proc. of USENIX Security, 2015.
J. L. Su´arez, S. Garc´ıa, and F. Herrera, “A tutorial on distance metric
learning: Mathematical foundations, algorithms and software,” arXiv
preprint arXiv:1812.05944, 2018.
[69]
[70] M. Tavallaee, E. Bagheri, W. Lu, and A. A. Ghorbani, “A detailed
analysis of the kdd cup 99 data set,” in Proc. of CISDA, 2009.
[71] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and V. Paxson, “Trafﬁcking
fraudulent accounts: The role of the underground market in twitter spam
and abuse,” in Proc. of USENIX Security, 2013.
[72] O. Varol, E. Ferrara, C. A. Davis, F. Menczer, and A. Flammini, “Online
human-bot interactions: Detection, estimation, and characterization,” in
Proc. of Weblogs and Social Media Workshop of AAAI, 2017.
[73] P.
Vibert,
industry,”
the-rapid-evolution-of-the-ransomware-industry/.
“The
2019,
rapid
ransomware
https://www.cybersecurity-review.com/articles/
evolution
the
of
[74] N. X. Vinh, J. Epps, and J. Bailey, “Information theoretic measures
for clusterings comparison: Variants, properties, normalization and
correction for chance,” Journal of Machine Learning Research, 2010.
[75] G. Wang, T. Wang, H. Zheng, and B. Y. Zhao, “Man vs. machine:
Practical adversarial detection of malicious crowdsourcing workers,” in
Proc. of USENIX Security, 2014.
[76] D.-J. Wu, C.-H. Mao, T.-E. Wei, H.-M. Lee, and K.-P. Wu, “Droidmat:
Android malware detection through manifest and api calls tracing,” in
Proc. of Asia Joint Conference on Information Security, 2012.
[77] X. Wu, T. Ma, J. Cao, Y. Tian, and A. Alabdulkarim, “A comparative
study of clustering ensemble algorithms,” Computers & Electrical
Engineering, 2018.
15
TABLE V.
MEAN AMIS AND STANDARD DEVIATION OF FARE AND
Label Condition
GENERALIZED ZERO-SHOT LEARNING METHODS (GZSL).
ng = (cid:98)n/2(cid:99), 1% labels
Intrusion
Malware
0.74 ± 0
0.63 ± 0.06
0.00 ± 0
nc = (cid:98)n/2(cid:99), 1% labels
Intrusion
Malware
0.75 ± 0
0.64 ± 0.09
0.01 ± 0.01
0.89 ± 0.05
0.40 ± 0.35
0.00 ± 0
0.90 ± 0.05
0.63 ± 0.39
0.00 ± 0
Dataset
FARE
OSDN
DEM
(a) Malware categorization.
(b) Intrusion detection.
Fig. 4. FARE vs. baselines in missing classes.
TABLE VI.
DEMONSTRATION OF CONTINGENCY TABLE. COLUMN 2-4
REPRESENTS THE COUNTS OF OVERLAPPING SAMPLES BETWEEN EACH
PREDICTED CLUSTER AND TRUE CLASS. COLUMN 5 AND ROW 4 SUMS UP
THE SAMPLES IN PREDICTED CLUSTERS AND TRUE CLASSS.
Predictions
Cluster 1
Cluster 2
Sums
Labels
Class 1
Class 2
Class 3
960
20
980
18
0
18
2
0
2
Sums
980
20
1000
(a) Malware categorization.
(b) Intrusion detection.
Fig. 5. FARE vs. baselines in coarse-grained labels.
[78]
J. Xie, R. Girshick, and A. Farhadi, “Unsupervised deep embedding for
clustering analysis,” in Proc. of ICML, 2016.
[79] E. P. Xing, M. I. Jordan, S. J. Russell, and A. Y. Ng, “Distance metric
learning with application to clustering with side-information,” in Proc.
of NeurIPS, 2003.
[80] L. Zhang, T. Xiang, and S. Gong, “Learning a deep embedding model
for zero-shot learning,” in Proc. of CVPR, 2017.
[81] M. Zhang, Y. Duan, H. Yin, and Z. Zhao, “Semantics-aware an-
droid malware classiﬁcation using weighted contextual api dependency
graphs,” in Proc. of CCS, 2014.
[82] Z. Zhu and T. Dumitras¸, “Featuresmith: Automatically engineering
features for malware detection by mining the security literature,” in
Proc. of CCS, 2016.
[83] A. Zimek, E. Schubert, and H.-P. Kriegel, “A survey on unsupervised
outlier detection in high-dimensional numerical data,” Statistical Anal-
ysis and Data Mining: The ASA Data Science Journal, 2012.
[84] B. Zong, Q. Song, M. R. Min, W. Cheng, C. Lumezanu, D. Cho, and
H. Chen, “Deep autoencoding gaussian mixture model for unsupervised
anomaly detection,” in Proc. of ICLR, 2018.
APPENDIX-A. IMPLEMENTATION AND HYPER-PARAMETER.
We implemented FARE with the PyTorch [55] package.
We implemented K-means and DBSCAN with the APIs in
the scikit-learn package[11]. We adopted the hyper-
parameters suggested by scikit-learn package for K-
means and DBSCAN. The network architecture of DEC is the
same as other DNNs, which are speciﬁcied as the following.
(1) Network Structure: we used an MLP with the architecture
of “input dimension-500-500-2000-32” with Tanh activation
for each layer. We also adopted a weight decay with the
strength of 0.01 as the regularization. (2) Minibatch size:
we created two trunks of minibatch samplers sampling from
unlabeled and labeled data. Supervised DNN only uses the
labeled sampler. MixMatch and Ladder utilize both samplers
to ensure each batch contains both unlabeled and labeled data.
The batch size of labeled and unlabeled sampler is 64 and 128
respectively. (3) Training epochs: the maximum training epoch
is 1000. We used an early-stopping mechanism: we stop when
either the loss on the validation set increases in two consecutive
epochs, or the loss decrease on the training set is below 0.01
in two consecutive epochs. These DNNs were trained with the
Adam optimizer, with the learning rate of 0.001.
16
Regarding the hyper-parameters of FARE, ﬁrst, we ran
DEC, k-means, and DBSCAN 50 times with the hyper-
parameters introduced above. Together with the “given labels”,
we constructed in total M = 151 neighborhood models. Then
we set the distance radius α = 32, and the regularization coef-
ﬁcients λ = 0.01. For the weight of the “given labels” p1, we
applied the selection mechanism introduced in Section §III-D
and set it as 10 in the malware dataset and {1, 7, 10} in the
network intrusion dataset (1 is used in ng/nc = 7, 7 is used
for ng/nc = 4 and ng = 1, and the rest are 10). Finally,
for the input transformation network, we used the same set of
hyper-parameters as that of the semi-supervised baselines.
APPENDIX-B. BASELINES PERFORMANCE.
FARE vs. Semi-supervised Baselines. Figure 4 and 5 shows
the comparison between FARE and the baselines’ original im-
plementations. The AMIs of the baselines decrease drastically
as nc and ng increases. The worst AMI is even lower than 0.1.
The results indicate that, without further adaptation, none of
the baselines can handle missing classes/coarse-grained labeled
data. As thus, we amended all baselines in our evaluation.
FARE vs. Generalized Zero-shot Learning. We compared
FARE with two representative GZSL methods OSDN [4] and
DEM [80], under the low-quality label setups. For the missing
class setting, we ﬁxed nc = (cid:98)n/2(cid:99) for each dataset and
kept 1% labeled training sample in each known class. We
ran FARE, OSDN, and DEM on the constructed training set
and compared their testing AMIs. For the coarse-grained label
setting, we ﬁxed ng = (cid:98)n/2(cid:99) for each dataset and followed the
same procedure. In both experiments, we ran each method 10
times. Note that DEM requires side information (i.e., shared
semantic properties) about the connection between the training
and testing sets. Since our datasets do not provide such side
information, we set to provide random information to DEM.
As shown in Table V, FARE signiﬁcantly outperforms OSDN
and DEM in both setups. This is because GZSL requires rich
training samples from the known classes. However, in our
setting, we only have 1% of labels in known classes. We can
also observe that without meaningful side information, DEM
completely fails in our task. This result shows that GZSL
methods are not suitable for our setup. As such, we do not
consider them as the baselines in our experiments.
024nc0.20.30.40.50.60.70.80.9AMIFAREMixMatchLadderDNN0147nc0.20.40.60.81.0AMIFAREMixMatchLadderDNN024ng0.20.30.40.50.60.70.8AMIFAREMixMatchLadderDNN0147ng0.20.40.60.81.0AMIFAREMixMatchLadderDNNTABLE VII.
ACCURACY COMPARISON ON SELECTED MISSING
CLASSES AND COARSE-GRAINED LABEL SETTINGS.
Dataset
Label Setting
FARE
MixMatch+
Ladder+
DNN+
MALWARE
nc = 2
0.92 ± 0.03
0.92 ± 0.03
0.86 ± 0.05
0.88 ± 0.06
ng = 2
0.88 ± 0.02
0.89 ± 0.01
0.87 ± 0.01
0.88 ± 0.02
Network Intrusion
nc = 4
1 ± 0
0.97 ± 0.01
0.97 ± 0.02
0.98 ± 0
ng = 4
0.99 ± 0