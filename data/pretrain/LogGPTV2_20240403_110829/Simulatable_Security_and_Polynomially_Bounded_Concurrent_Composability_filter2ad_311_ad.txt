imately the following: Consider as real adversary only a
dummy adversary, i.e., an adversary that simply follows all
instructions received from the honest user.6 To prove ˆM p
1 as
secure as ˆM p
2 assuming ˆM1 is as secure as ˆM2, let a simu-
lator S for that dummy adversary attacking the single proto-
col be given. Note that since we assume universal security,
S does not depend on the honest user.
Namely, for each honest user H∗
It might be reasonable to expect that a “parallelised ver-
sion” Sp of the simulator S (so that Sp internally keeps p
simulations of S, one for each protocol instance) is a good
simulator for the dummy adversary that attacks the com-
posed protocol Mp
1. To support this intuition, we reduce
honest users of the composed protocol to honest users of
the single protocol. (Note that since we can restrict to the
dummy adversary as real adversary, this is all we need for
showing our claim.)
of the composed proto-
col ˆM p
1 , we construct a new honest user Hp of a single copy
ˆM1 as follows (cf. also Figure 3): Hp simulates H∗
. For
each copy of the protocol that H∗
expects, Hp does one of
the following: (i) the real protocol and real (dummy) adver-
sary are simulated (we will call this a “real copy”), (ii) the
ideal protocol and simulator S are simulated (we call this an
“ideal copy”), or (iii) communication from H∗
is rerouted
to the outside of Hp, where either one copy of the real or of
the ideal protocol resides (we speak of an “external copy”).
The number of “real” and “ideal copies” is chosen randomly
(and there will be exactly one “external copy”). Hp choos-
ing to simulate l “real copies” and running with the real
6Maybe somewhat surprisingly, this dummy adversary is the “worst
possible adversary” in the sense that it sufﬁces to give a simulator for the
real dummy adversary to show security, cf. [15].
protocol is equivalent to Hp choosing to simulate l + 1 “real
copies” and running with the ideal protocol and simulator.
This again is indistinguishable (by assumption of the secu-
rity of a single protocol copy) from Hp choosing to simulate
l + 1 copies and running with the real protocol. So we get a
chain of polynomial length of indistinguishable views7 from
Hp choosing to simulate 0 “real copies” to Hp choosing to
simulate p “real copies”, so these two settings are again in-
distinguishable (by the simulated H∗
). These two scenar-
ios again correspond to H∗
running with only ideal copies
of the protocol (and copies of the ’dummy adversary) and
H∗
running with only real copies (and copies of S for each
protocol-copy), so H∗
can indeed not distinguish between
real and ideal model.
But when we consider standard security, the following
problem occurs: We have relied on the fact that the simu-
lator S is a “good” simulator for Hp. But for standard se-
curity, such a “good” S would depend on Hp, which in turn
depends on S. It is not clear that this mutual dependency
should have a ﬁxpoint (and in fact, it does not have such
a ﬁxpoint in the counterexample presented in Section 3 for
the computational case).
While it is unknown whether such a ﬁxpoint exists in the
case of statistical standard security, a variation of the above
construction yields a proof. We ﬁrst state the theorem:
Theorem 4.2 (Polynomially Bounded Concurrent Compo-
sition Theorem). Let ˆM1 and ˆM2 be protocols s.t. ˆM1 is as
secure as ˆM2 (with respect to standard statistical security
as in Def. 4.1). Let further p be a polynomial.
1 is as secure as ˆM p
i denotes
the polynomially bounded concurrent composability as in
Def. 2.1).
Then ˆM p
2 (where ˆM p
This also holds when the honest user has access to an
auxiliary input.
Note that the limitation to a polynomial number is not
a limitation of our proof, indeed, it can easily be seen that
the concurrent composition of a superpolynomial number
of protocol instances can be insecure, even if the single in-
stance is secure. This condition is usually not explicitly
stated in the computational case: Since with polynomial-
time machines only a polynomial number of protocol in-
stances can be created, the condition is automatically ful-
ﬁlled.
We will now give a proof sketch for Theorem 4.2. The
full proof will be presented in the full version of this paper.
for the composed protocol ˆM p
Proof sketch. Like in the approach sketched above, given
an honest user H∗
1 , we con-
struct honest users Hi for the single protocol ˆM1. These
choose a random number l and then simulate l − 1 “ideal
copies” with session IDs 1, . . . , l − 1, have one “external
7With a common negligible bound on the statistical distance.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
H∗
l ∈ {1, . . . , i}
Hi
sid = 1
...
sid = l − 1
sid = l
sid = l + 1
...
sid = p(k)
ˆM2
...
ˆM2
ˆM1
...
ˆM1
S1
...
Sl−1
D
...
D
ˆM1
D
Figure 3. Construction of the honest user Hi (the dashed box). The variable l is drawn from the set
{1, . . . , i}. Messages from and to H∗ are rerouted according to their session ID sid as depicted. (The
fact that the adversaries/simulators are only connected to Mi is only for graphical reasons, in reality,
they are of course connected to H∗ as well.) The machines shown outside Hi are only exemplary, Hi
might of course be connected to other machines, e.g. M2 and Si.
copy” with session ID l and simulate p(k) − l − 1 “real
copies” with session IDs l + 1, . . . , p(k) (cf. also Figure 3).
There are however some noteworthy differences to the
• Instead of having a single honest user Hp which
chooses a random l ∈ {1, . . . , p(k)}, Hi chooses
l ∈ {1, . . . , i − 1}.
construction of Hp in the approach above:
• The number l is chosen randomly with a ﬁxed distri-
bution s.t. any number l has a probability to be chosen
whose inverse is polynomial in l. Then, if l ≥ i, the
honest user Hi aborts. Therefore, effectively a number
l ∈ {1, . . . , i} is chosen, but in a way that any Hi with
i > l chooses l with the same probability. This gives us
a kind of “compatibility” between the different honest
users which will prove necessary to construct a com-
mon simulator for all these Hi.
• Most importantly, the “ideal copies” do not all contain
the same simulator, since in the case of standard se-
curity there is no universal simulator to be used here.
Instead, in the “ideal copy” with session ID sid has a
simulator Ssid , where Ssid is deﬁned in dependence of
Hsid (see below). This of course seems to be a cyclic
deﬁnition. However, closer inspection reveals that Hi
only invokes “ideal copies” with session IDs sid  i, the view of the simulated H∗
in Hi and H∞ is the
same (independent of further machines involved). S∞ is a
simulator for H∞ that achieves that the statistical distance
between H∞’s real and ideal view is bounded by some neg-
ligible function, say ε. By ignoring runs with l > i, the
distance of the views cannot increase. Therefore also the
views of Hi have a distance of at most ε when running with
S∞. Since Si was a near-optimal simulator, the statistical
distance when running with Si is bounded by ε+2k. There-
fore we have a uniform bound for the distance of views for
all pairs of honest user Hi and simulator Si.
Now, if we modify Hi to always choose l = i (and call
the result ˜Hi), the statistical distance of views of this honest
user (with simulator Si) increases by a factor of at most the
inverse probability that l = i is chosen. Since this probabil-
ity was polynomial in l (and independent of i), the statistical
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:50:34 UTC from IEEE Xplore.  Restrictions apply. 
distance of the views of these modiﬁed ˜Hi is bounded by a
function εi(k) negligible in i and k.
Finally, ﬁx a security parameter k. By construction,
˜Hi+1 simulates i “ideal” and p(k) − i − 1 “real copies”. So
when running with ˆM1 and D as the “external copy”, this is
equivalent to having ˜Hi run with ˆM2 and Si. This again has
only a statistical distance of εi(k) (in the view of H∗
) from
the ˜Hi running with ˆM1 and D. So by repeatedly applying
that equation, we see that between ˜H0 and ˜Hp(k)+1 there is a
i=0 εi(k) =: ν(k), which is negligi-
distance of at most
ble in k. But ˜H0 just simulates H∗
together with p(k) “real
copies”, which corresponds exactly to H∗
running with the
composed real protocol ˆM p
1 (and the dummy adversary).
Similarly, ˜Hp(k)+1 simulates H∗
with p(k) “ideal copies”,
corresponding to H∗
running with the composed ideal pro-
tocol ˆM p
2 and a simulator S resulting from combining all the
individual simulators Si. So the statistical distance between
the views of H∗
Since k was chosen arbitrarily, this holds for any k, i.e.,
the views of H∗
in real and ideal composed protocol have a
distance of at most ν which is negligible. Since the proof
was done for arbitrary H∗
1 is as secure as
ˆM p
2 .
, it follows that ˆM p
(cid:2)p(k)
bounded by ν(k).
4.2 The Perfect Case
The above proof can easily be modiﬁed to show con-
current composition in the case of perfect security (i.e., the
views of the honest user must be identical and not only sta-
tistically close). However, there is a simpler argument using
the results of [29]. They show that in the perfect case, stan-
dard and universal security coincide. Since for universal
security, secure polynomially bounded concurrent compos-
ability is possible [15, 10], we immediately get
Theorem 4.3 (Polynomially Bounded Concurrent Compo-
sition Theorem, perfect case). The Polynomially Bounded
Concurrent Composition Theorem 4.2 also holds in the case
of perfect standard security.
5 Conclusions
Composability properties of notions of simulatable secu-
rity are of great importance when designing and analysing
protocols modularly. Here, already some results are known,
but the practically very signiﬁcant question of polynomially
bounded concurrent composability has not been answered
in the case of standard simulatability. In this work, we have
answered this open question for all ﬂavours of standard sim-
ulatability. This clariﬁes all previously unknown relations
among the different ﬂavours of simulatability and composi-
tional properties as depicted in Figure 1.
More speciﬁcally, we have shown that computa-
tional standard simulatability does not imply polynomially
bounded concurrent composability. This does not only set-
tle an open problem from [10]. It also has practical impli-
cations: many cryptographic protocol constructions in the
spirit of [41, 26] make use of a polynomial number of sub-
protocols. Our results show that due to the lack of poly-
nomially bounded concurrent composability, computational
standard security is not well suited to analyse such construc-
tions modularly. Hence, computational universal or black-
box security should be preferred over computational stan-
dard security wherever possible, especially since all practi-
cal protocol constructions known to the authors are already
proven secure with respect to these stronger notions.
On the other hand, we showed that in the statistical case,
polynomially bounded concurrent composability is indeed
guaranteed by standard simulatability. However, we still
recommend the use of universal or black-box simulatability
even in the statistical case, since the simulator constructed
in our proof needs much more computational power than
the simulator for the uncomposed protocol. In contrast to
this, universal and black-box simulatability guarantee the
existence of a simulator whose complexity is polynomial in
the complexity of the real adversary.
Acknowledgements We are indebted to Michael Backes
for many helpful comments and improvements. We also
thank Ran Canetti and Jörn Müller-Quade for valuable dis-
cussions. This work was partially funded by the EC project
PROSECCO under IST-2001-39227. Most of this work
was done while the ﬁrst author was with the Institut für Al-
gorithmen und Kognitive Systeme, Arbeitsgruppe System-
sicherheit, Prof. Dr. Th. Beth, Universität Karlsruhe.
References
the Otway-Rees protocol.
[1] Michael Backes. A cryptographically sound Dolev-
Yao proof of
In
Pierangela Samarati, Peter Y.A. Ryan, Dieter Goll-
mann, and Reﬁk Molva, editors, Computer Se-
curity, Proceedings of ESORICS 2004, number
3193 in Lecture Notes in Computer Science, pages
89–108. Springer-Verlag, 2004.
Online avail-
able at http://www.infsec.cs.uni-sb.de/