### 6.1 Developer-Assisted Vulnerability Analysis

#### Developer-Supplied Input
While automated syntactic analysis can generate a large number of inputs, not all of them are relevant to attackers. For example, in the PNG case, many inputs do not correspond to valid images, and it is not particularly useful to analyze errors in the PNG file format. In practice, only software developers can identify the specific set of inputs that they wish to make indistinguishable. This process is known as semantic-level analysis. Developers can select a set of inputs \( I \) that they want to be indistinguishable from the execution traces and use ANABLEPS to analyze \( E(p, I) \).

The steps for this analysis are similar to those described in ยง4, with the exception that the Input Generation step and the "determining input spaces for \( G_i \)" part of the Vulnerability Identification step can be skipped, as the set of inputs of interest is now provided by the developers. The output of the analysis will be \( |G_i \leftrightarrow I_i| \), which can be differentiated by order or time information in the execution traces.

#### Locating Vulnerabilities
Given a set of secretive inputs \( I \), if \( |E(p, I)| > 1 \), we aim to find the set of nodes in \( G \) that can be used to learn the inputs. This involves locating vulnerabilities (i.e., vulnerable nodes) in the graph and the program. Using the method discussed in ยง4, we can differentiate between order-based and time-based vulnerable nodes. The ability to easily locate vulnerabilities is one of the benefits of using ED-CFG to represent execution traces.

With the syntactic input set \( I_{\text{syntactic}} \), the statistics of the vulnerable nodes are shown in Table 4. The cache-level statistics are listed in columns 3 to 5, and the page-level statistics are reported in columns 6 to 8. The total number of nodes in \( G_i^p \) is shown in columns 3 and 6; the number of order-based vulnerable nodes is listed in columns 4 and 7; and the number of time-based vulnerable nodes is listed in columns 5 and 8, respectively. In Table 4, the time-based vulnerable nodes are mutually exclusive with the order-based vulnerable nodes. According to the results presented in Table 4, ANABLEPS significantly reduces the number of nodes to be examined for side-channel vulnerabilities. On average, the number of order-based vulnerable nodes is only 18% of all nodes in \( G_c \) and 37% of all nodes in \( G_p \); the number of time-based vulnerable nodes is only 6% of all nodes in \( G_c \) and 13% of all nodes in \( G_p \). The fraction of vulnerable nodes can be further reduced with a developer-supplied input set that is of interest.

### 6.2 Case Studies of the Exploitability Analysis

In this section, we briefly summarize three interesting cases to demonstrate how ANABLEPS can help enclave developers identify side-channel vulnerabilities that can be exploited to extract sensitive information.

#### 6.2.1 Deep Learning Algorithms
According to Table 2, there are 214 different inputs for algorithm \( dA \) that have unique \( G_c \), i.e., \( G_i^c \leftrightarrow I_i \). Therefore, potential vulnerabilities in \( dA \) may lead to exploitable information leakage. To start analyzing the vulnerabilities in \( dA \), we first manually selected inputs that might be of interest to attackers: a set of \( |I| \) training data that differ only in values. We then fed these inputs to ANABLEPS. The output indicated that all selected inputs have unique cache-level execution traces, i.e., \( |E(p, I)| = |I| \).

After locating the vulnerable nodes and some manual effort to examine the identified vulnerable nodes, we found that the primary leakage comes from the function `dA_get_corrupted_input()`, which has a for loop that enumerates every element of array \( x \) and calls the function `binomial()` if the element is not 0. The code snippet is shown in Figure 2.

The execution of `dA_get_corrupted_input()` and `binomial()` may be exploited to leak training data information. Whether or not the function `binomial()` is called by `dA_get_corrupted_input()` reveals the value of array \( x \). The function call sequence can be learned through cache-level side channels. The two functions are located in the same page but different cachelines. After compilation, the for loop in `dA_get_corrupted_input()` is compiled into two cachelines, denoted \( m1 \) and \( m2 \), and the function `binomial()` is compiled into two consecutive cachelines. We denote the first cacheline as \( m3 \). Therefore, if the \( i \)-th element of array \( x \) is 0, the order of executed cachelines is [\( m1 \), \( m2 \)]; otherwise, the execution order becomes [\( m1 \), \( m2 \), \( m3 \), \( m2 \)]. This order-based side-channel vulnerability on the cache level can completely leak the training data of the deep learning algorithm.

#### 6.2.2 Freetype Font Engine
According to Table 2, there are 206 inputs that have unique \( G_i^p \). To validate the page-level vulnerability, we generated some printable characters as input and fed them to ANABLEPS. The result indicates that every input corresponds to a unique \( G_i^p \).

ANABLEPS has helped us identify the vulnerable nodes. In fact, there are multiple vulnerable nodes. To illustrate these vulnerabilities, we explain the leakage through the function `psh_glyph_interpolate_strong_points()` at the page level. The code snippet is shown in Figure 3. `psh_glyph_interpolate_strong_points()` includes a loop to interpolate every strong point into the glyph. Adversaries can recover the strong points' positions according to the page sequence. Specifically, the function `psh_point_is_edge_min()` is placed in page \( m1 \). Functions `FT_MulFix()` and `FT_MulDiv()` are placed in another page, denoted \( m2 \). The page of the function `psh_glyph_interpolate_strong_points()` is denoted \( m3 \). The access order of these pages leaks information about the interpolated point: When a point is not marked as a strong point, the order of page access is [\( m3 \)]; when the strong point is located at the edge, the order of page access is [\( m3 \), \( m1 \), \( m3 \), \( m1 \), \( m3 \)]; otherwise, the sequence would be [\( m3 \), \( m1 \), \( m3 \), \( m2 \), \( m3 \), \( m1 \), \( m3 \)]. Given the sequence of this function, the attacker can learn whether each point is a strong point or not.

Although the example does not completely leak the content of the data, it illustrates how leakage can be identified.