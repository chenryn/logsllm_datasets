Security and Privacy. ACM, 2016, pp. 85–96.
[20] X. Gu, H. Zhang, D. Zhang, and S. Kim, “Deep API learning,” in
Proceedings of the 24th ACM SIGSOFT International Symposium on
Foundations of Software Engineering. ACM, 2016, pp. 631–642.
[21] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed, N. Jaitly,
A. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath, and B. Kingsbury,
“Deep neural networks for acoustic modeling in speech recognition:
The shared views of four research groups,” IEEE Signal Processing
Magazine, vol. 29, no. 6, pp. 82–97, 2012.
[22] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural
Computation, vol. 9, no. 8, pp. 1735–1780, 1997.
[23] S. Horwitz, T. Reps, and D. Binkley, “Interprocedural slicing using
dependence graphs,” ACM Transactions on Programming Languages
and Systems (TOPLAS), vol. 12, no. 1, pp. 26–60, 1990.
[24] B. James, B. Olivier, B. Fr´ed´eric, L. Pascal, and P. Razvan, “Theano: A
CPU and GPU math expression compiler,” in Proceedings of the Python
for Scientiﬁc Computing Conference (SciPy), 2010.
J. Jang, A. Agrawal, and D. Brumley, “ReDeBug: Finding unpatched
code clones in entire OS distributions,” in Proceedings of the 33th IEEE
Symposium on Security and Privacy.
IEEE, 2012, pp. 48–62.
[25]
[26] L. Jiang, G. Misherghi, Z. Su, and S. Glondu, “Deckard: Scalable and
accurate tree-based detection of code clones,” in Proceedings of the 29th
International Conference on Software Engineering.
IEEE Computer
Society, 2007, pp. 96–105.
[27] R. Jozefowicz, W. Zaremba, and I. Sutskever, “An empirical exploration
of recurrent network architectures,” in Proceedings of the 32nd Inter-
national Conference on Machine Learning, 2015, pp. 2342–2350.
[28] S. Kim, S. Woo, H. Lee, and H. Oh, “VUDDY: A scalable approach
for vulnerable code clone discovery,” in Proceedings of the 38th IEEE
Symposium on Security and Privacy, 2017.
[29] D. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980, 2014.
14
[30] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classiﬁcation
with deep convolutional neural networks,” in Advances in Neural
Information Processing Systems, 2012, pp. 1097–1105.
J. Li and M. D. Ernst, “CBCD: Cloned buggy code detector,” in Pro-
ceedings of the 34th International Conference on Software Engineering.
IEEE, 2012, pp. 310–320.
[31]
[32] Z. Li, D. Zou, S. Xu, H. Jin, H. Qi, and J. Hu, “VulPecker: An
automated vulnerability detection system based on code similarity
analysis,” in Proceedings of the 32nd Annual Conference on Computer
Security Applications. ACM, 2016, pp. 201–213.
[33] S. Montemagni and V. Pirelli, “Augmenting WordNet-like lexical re-
sources with distributional evidence. an application-oriented perspec-
tive,” in Proceedings of the COLING/ACL Workshop on Use of WordNet
in Natural Language Processing Systems, 1998, pp. 87–93.
[34] P. Morrison, K. Herzig, B. Murphy, and L. Williams, “Challenges with
applying vulnerability prediction models,” in Proceedings of the 2015
Symposium and Bootcamp on the Science of Security. ACM, 2015,
pp. 1–9.
[35] S. Moshtari and A. Sami, “Evaluating and comparing complexity,
coupling and a new proposed set of coupling metrics in cross-project
vulnerability prediction,” in Proceedings of
the 31st Annual ACM
Symposium on Applied Computing. ACM, 2016, pp. 1415–1421.
[36] L. Mou, G. Li, Y. Liu, H. Peng, Z. Jin, Y. Xu, and L. Zhang,
“Building program vector representations for deep learning,” arXiv
preprint arXiv:1409.3358, 2014.
[37] S. Neuhaus and T. Zimmermann, “The beauty and the beast: Vulner-
abilities in Red Hat’s packages.” in Proceedings of the 2009 USENIX
Annual Technical Conference. USENIX, 2009, pp. 527–538.
[38] S. Neuhaus, T. Zimmermann, C. Holler, and A. Zeller, “Predicting
vulnerable software components,” in Proceedings of the 14th ACM
conference on Computer and communications security. ACM, 2007,
pp. 529–540.
[39] M. Pendleton, R. Garcia-Lebron, J. Cho, and S. Xu, “A survey on
systems security metrics,” ACM Comput. Surv., vol. 49, no. 4, pp. 62:1–
62:35, 2017.
J. Pennington, R. Socher, and C. D. Manning, “Glove: Global vectors
for word representation.” in Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing, vol. 14, 2014, pp.
1532–1543.
[40]
[41] N. H. Pham, T. T. Nguyen, H. A. Nguyen, and T. N. Nguyen, “Detection
of recurring software vulnerabilities,” in Proceedings of the IEEE/ACM
International Conference on Automated Software Engineering. ACM,
2010, pp. 447–456.
[42] D. Rattan, R. Bhatia, and M. Singh, “Software clone detection: A
systematic review,” Information and Software Technology, vol. 55, no. 7,
pp. 1165–1199, 2013.
[43] D. Rumelhart, J. McClelland, and G. Hinton, “Distributed representa-
tions,” Parallel Distributed Processing: Explorations in the Microstruc-
ture of Cognition, vol. 1, pp. 77–109, 1986.
[44] H. Sajnani, V. Saini, J. Svajlenko, C. K. Roy, and C. V. Lopes, “Sourcer-
erCC: Scaling code clone detection to big-code,” in Proceedings of the
38th International Conference on Software Engineering. ACM, 2016,
pp. 1157–1168.
J. Saxe and K. Berlin, “eXpose: A character-level convolutional neural
network with embeddings for detecting malicious URLs, ﬁle paths and
registry keys,” arXiv preprint arXiv:1702.08568, 2017.
[45]
[46] R. Scandariato, J. Walden, A. Hovsepyan, and W. Joosen, “Predicting
vulnerable software components via text mining,” IEEE Transactions
on Software Engineering, vol. 40, no. 10, pp. 993–1006, 2014.
[47] M. Schuster and K. K. Paliwal, “Bidirectional recurrent neural net-
works,” IEEE Transactions on Signal Processing, vol. 45, no. 11, pp.
2673–2681, 1997.
[48] E. C. R. Shin, D. Song, and R. Moazzezi, “Recognizing functions in
binaries with neural networks.” in Proceedings of the 24th USENIX
Security Symposium. USENIX Associatioin, 2015, pp. 611–626.
[49] Y. Shin, A. Meneely, L. Williams, and J. A. Osborne, “Evaluating
complexity, code churn, and developer activity metrics as indicators of
software vulnerabilities,” IEEE Transactions on Software Engineering,
vol. 37, no. 6, pp. 772–787, 2011.
t (cid:12) tanh(cl
t),
layer l at the time t is:
hl
t = ol
t of the layer l at the time t is:
t + bl
t + W l
o)
and the state of LSTM cell cl
where the output gate ol
xoxl
ol
t = σ(W l
cocl
t−1 + W l
hohl
t of the layer l at the time t is:
c).
t−1 + bl
t + W l
hchl
xcxl
cl
t = f l
t (cid:12) cl
t−1 + il
t (cid:12) tanh(W l
The forget gate f l
t and the input gate il
t of the layer l at
the time t are calculated as follows:
f l
t = σ(W l
il
t = σ(W l
xf xl
xixl
t + W l
t + W l
hf hl
hihl
t−1 + W l
t−1 + W l
cf cl
cicl
t−1 + bl
f ),
t−1 + bl
i),
xi, W l
xo, W l
xf , W l
t is the input to layer l − 1 (l > 1) or the input of
where xl
xc are the weight
the network (l = 1), W l
t with the input gate, the forget gate, the
matrices connecting xl
ho, W l
output gate, and the LSTM cell input, W l
hc
are the weight matrices connecting hl
t−1 with the input gate,
the forget gate, the output gate, and the LSTM cell input, and
c are the bias items of the input gate, the forget
i, bl
bl
gate, the output gate, and the LSTM cell input.
hf , W l
hi, W l
f , bl
o, bl
B. Library/API function calls selected by Checkmarx
Table VII summarizes the C/C++ library/API function calls
related to the two types of vulnerabilities, buffer error (CWE-
119) and resource management error (CWE-399), where “*”
represents the wildcard. These library/API function calls are
generated by the commercial product Checkmarx [2].
Table VII.
LIBRARY/API FUNCTION CALLS RELATED TO TWO TYPES
OF VULNERABILITIES
CWE ID
CWE-119
recv,
istream.get,
istream.getline,
streambuf.snextc,
PostThreadMessage,
SendMessageCallback,
stdin, getdlgtext, getpass,
C/C++ library/API function calls related to vulnerabilities
cin, getenv, getenv s, wgetenv, wgetenv s, catgets, gets, getchar,
scanf,
getc, getch, getche, kbhit,
fscanf, vscanf, vfscanf,
istream.peek,
istream.putback, streambuf.sbumpc, streambuf.sgetc,
istream.read*,
streambuf.sputbackc,
streambuf.sgetn,
SendNotifyMessage,
SendMessage,
PostMessage,
recvfrom,
Receive,
ReceiveFrom, ReceiveFromEx, Socket.Receive*, memcpy, wmemcpy,
memccpy, memmove, wmemmove, memset, wmemset, memcmp,
strncpy*,
lstrcpyn,
wmemcmp, memchr, wmemchr,
strncat*,
tcsncpy*, mbsnbcpy*, wcsncpy*, wcsncpy, strncat,
tcscpy,
lstrcpy, wcscpy,
mbsncat*, wcsncat*, bcopy,
mbscpy, CopyMemory,
strchr,
strcmp,
strcoll, strcspn, strerror, strlen, strpbrk, strrchr, strspn, strstr, strtok,
strxfrm, readlink, fgets, sscanf, swscanf, sscanf s, swscanf s, printf,
vprintf, swprintf, vsprintf, asprintf, vasprintf, fprintf, sprint, snprintf,
snprintf*,
snwprintf*, vsnprintf, CString.Format, CString.FormatV,
CString.FormatMessage,
CStringT.FormatV,
CStringT.FormatMessage, CStringT.FormatMessageV, syslog, malloc,
Winmain, GetRawInput*, GetComboBoxInfo, GetWindowText,
GetKeyNameText, Dde*, GetFileMUI*, GetLocaleInfo*, GetString*,
GetCursor*, GetScroll*, GetDlgItem*, GetMenuItem*
free, delete, new, malloc, realloc, calloc,
vsprintf, vasprintf, sprintf, snprintf,
alloca, strdup, asprintf,
snwprintf, vsnprintf
CStringT.Format,
snprintf,
strncpy,
lstrlen,
lstrcat,
strcpy,
strcat,
[51]
IEEE, 1999, pp. 432–441.
[50] S. Sinha, M. J. Harrold, and G. Rothermel, “System-dependence-
graph-based slicing of programs with arbitrary interprocedural control
ﬂow,” in Proceedings of the 1999 International Conference on Software
Engineering.
J. Su, Z. Tan, D. Xiong, and Y. Liu, “Lattice-based recurrent neural
network encoders for neural machine translation,” in Proceedings of the
31st AAAI Conference on Artiﬁcial Intelligence, 2017, pp. 3302–3308.
J. Viega, J. T. Bloch, Y. Kohno, and G. McGraw, “ITS4: A static
vulnerability scanner for C and C++ code,” in Proceedings of the 16th
Annual Computer Security Applications Conference.
IEEE, 2000, pp.
257–267.
[52]
[53] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan, “Show and tell: A
neural image caption generator,” in Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, 2015, pp. 3156–3164.
[54] S. Wang, T. Liu, and L. Tan, “Automatically learning semantic fea-
tures for defect prediction,” in Proceedings of the 38th International
Conference on Software Engineering. ACM, 2016, pp. 297–308.
[55] M. Weiser, “Program slicing,” IEEE Transactioins on Software Engi-
neering, vol. 10, no. 4, 1984.
[56] M. White, M. Tufano, C. Vendome, and D. Poshyvanyk, “Deep learning
code fragments for code clone detection,” in Proceedings of the 31st
IEEE/ACM International Conference on Automated Software Engineer-
ing. ACM, 2016, pp. 87–98.
[57] M. White, C. Vendome, M. Linares-V´asquez, and D. Poshyvanyk,
“Toward deep learning software repositories,” in Proceedings of the
12th Working Conference on Mining Software Repositories.
IEEE,
2015, pp. 334–345.
[58] L. Wolf, Y. Hanani, K. Bar, and N. Dershowitz, “Joint word2vec
networks for bilingual semantic representations,” International Journal
of Computational Linguistics and Applications, vol. 5, no. 1, pp. 27–44,
2014.
[59] F. Yamaguchi, F. Lindner, and K. Rieck, “Vulnerability extrapolation:
Assisted discovery of vulnerabilities using machine learning,” in Pro-
ceedings of the 5th USENIX Conference on Offensive Technologies.
USENIX Association, 2011, pp. 13–13.
[60] F. Yamaguchi, M. Lottmann, and K. Rieck, “Generalized vulnerability
extrapolation using abstract syntax trees,” in Proceedings of the 28th
Annual Computer Security Applications Conference. ACM, 2012, pp.
359–368.
[61] F. Yamaguchi, A. Maier, H. Gascon, and K. Rieck, “Automatic inference
of search patterns for taint-style vulnerabilities,” in Proceedings of the
2015 IEEE Symposium on Security and Privacy.
IEEE, 2015, pp.
797–812.
[62] F. Yamaguchi, C. Wressnegger, H. Gascon, and K. Rieck, “Chucky:
Exposing missing checks in source code for vulnerability discovery,”
in Proceedings of the 2013 ACM SIGSAC Conference on Computer &
Communications Security. ACM, 2013, pp. 499–510.
[63] X. Yang, D. Lo, X. Xia, Y. Zhang, and J. Sun, “Deep learning for just-in-
time defect prediction,” in Proceedings of the 2015 IEEE International
Conference on Software Quality, Reliability and Security.
IEEE, 2015,
pp. 17–26.
APPENDIX
A. LSTM cells
The BLSTM layers in the BLSTM neural network contain
a complex structure called LSTM cells, which are brieﬂy
reviewed below and referred to [22] for greater details.
CWE-399
Let (cid:12) denote the element-wise multiplication, tanh denote
exp(x)+exp(−x) , and σ denote
the hyperbolic tangent function exp(x)−exp(−x)
the sigmoid function
1
1+exp(−x).
Each LSTM cell, denoted by c, uses an input gate i (i.e.,
the input data), a forget gate f (i.e., the state ﬂow of the cell),
and an output gate o (i.e., the output of module) to control
the data ﬂow through the neural network. The output hl
t of the
15