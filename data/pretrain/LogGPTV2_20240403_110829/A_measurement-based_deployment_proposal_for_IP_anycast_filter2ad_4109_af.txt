across the servers in the internal deployment. The set of
bars corresponding to “0 AS-hop” in ﬁgure 13(a) shows this
distribution. As can be seen, in the default set-up, most
of the clients (≈90%) are routed to the server at Cornell,
Cambridge or Pittsburgh. This result is consistent with the
uneven load distribution of clients across the anycasted J
root-servers [6] and K root-servers [12]. Hence, IP Anycast,
by itself, does not balance client load across the anycast
servers.
It is interesting to note that the distribution of clients is
skewed even amongst the servers that have ATT as their up-
stream since a lot more clients are routed to Pittsburgh than
to Seattle and Berkeley. On the other hand, the proximity
measurements in section 5 showed that anycast packets com-
ing into the ATT network are routed to the closest of these
three anycast servers. This would imply that most of the
clients in our list that are routed to ATT are closer to the
server at Pittsburgh than to the other two servers. In eﬀect,
this brings out the implicit trade-oﬀ between proximity and
load-balance. An anycast deployment which oﬀers optimal
latency-based selection of the anycast server is unlikely to
achieve an even distribution of clients across the servers in
the deployment.
Given the uneven load distribution, we would like to in-
vestigate if anycast operators can use routing advertisement
manipulations at individual server sites to control the num-
ber of clients routed to them.
In the rest of this section
we evaluate the eﬀectiveness of AS-PATH prepending as
a means of controlling the client load on anycast servers.
AS-PATH prepending at a server involves increasing the
length of the AS-PATH in the BGP advertisement that the
server propagates and hence, should wean some of the clients
away from it. For example, when “1 AS-hop” prepending
is used at the Cornell site, the AS-PATH seen by the Cor-
nell server’s peer is [33207 33207].8 Similarly, “2 AS-hop”
prepending implies that the Cornell server advertises the
internal deployment anycast preﬁx with the AS-PATH as
[33207 33207 33207].
Figure 13(a) shows the distribution of client load across
the anycast servers when path prepending is used at the
Cornell server. As can be seen, prepending 1 AS-hop causes
the fraction of clients being routed to the Cornell server to
reduce from 34% to 23%. However, the reduction in load ta-
pers oﬀ beyond this with ≈18% of the clients being routed to
the Cornell server irrespective of the amount of prepending
used. This can be explained in terms of typical ISP policies
and the BGP decision process: the ISP policy (expressed as
weights and local preferences) has higher priority than the
AS-PATH length in the BGP decision process. Thus, ASs
that choose to use the Cornell server as dictated by their
routing policies are oblivious to the amount of prepending
being done and the impact of path prepending soon runs
into diminishing returns. Figure 13(b) shows the variation
of client load with path prepending at the Cambridge server.
These results follow a pattern similar to what is described
above with the client load on the Cambridge server reducing
and then tapering oﬀ.
Figure 13(c) shows the distribution of client load with
path prepending at Pittsburgh, Seattle and Berkeley. These
are the three anycast sites with the same upstream provider
(ATT). The ﬁgure shows that prepending the AS-PATH of
the advertisement at the Pittsburgh server causes the num-
ber of clients routed to Pittsburgh to drop to zero. Since
the servers at Seattle and Berkeley also have ATT as the up-
stream provider, using AS-PATH prepending at Pittsburgh
causes routers in ATT’s network to prefer both the Berke-
ley and the Seattle servers to the Pittsburgh server. Hence,
8As mentioned earlier, 33207 is the origin AS used for the
internal deployment.
all anycast traﬃc reaching ATT’s network is split between
the Seattle and Berkeley servers only. Results for 1-AS hop
prepending at Seattle and Berkeley are analogous.
These results imply that if some servers in an anycast
deployment have the same upstream provider, all of them
need to prepend the AS-PATH in their advertisements in
order to divert clients away from them. In the internal de-
ployment, diverting clients away from the three servers with
ATT as their upstream ISP (Pittsburgh, Seattle and Berke-
ley) would require all of them to use path prepending. The
ﬁnal set of bars in ﬁgure 13(c) shows the load distribution
across our deployment in such a scenario.
Hence, while AS-PATH prepending can be used to manip-
ulate load across servers with diﬀerent providers, it is not
eﬀective for manipulating load within the set of servers with
the same provider. Alternatively, in an IP Anycast service
deployed according to the model presented in section 5, AS-
PATH prepending can only be used for balancing load across
between groups of servers that have the same upstream ISP.
For example, consider a deployment with a few servers hav-
ing ATT as their upstream provider and the rest having
WCG as their upstream provider. The servers with ATT as
their upstream need to use AS-PATH prepending together
to divert clients towards the servers with WCG as their up-
stream. For balancing the client load across servers with the
same upstream provider, the servers need some sort of traﬃc
engineering arrangement with their common provider. For
instance, many ISPs allow their customers to manipulate in-
coming traﬃc through the use of speciﬁc BGP community
attributes in their routing advertisements [10,50]. Anycast
servers with the same provider can thus use such mecha-
nisms to coarsely control the number of clients routed to
them. We are currently in the process of talks with ISPs
who would allow us to host anycast servers and experiment
with such mechanisms.
Finally, note that these mechanisms provide operators
with a coarse-grained control over the distribution of clients
across server sites (or groups of sites). For instance, this
could be used by anycast operators in the face of a DoS
attack on the deployment to redistribute traﬃc away from
server sites under strain. Beyond this, anycast operators can
use load balancing devices at server sites for a ﬁne grained
control over the distribution of clients being served by the
site across the hosts that are part of the site. As a matter of
fact, current commercial IP Anycast deployments use such
mechanisms for balancing the number of clients served by
individual cluster hosts at each site.
9. DISCUSSION
Section 2 described previous IP Anycast measurement
studies. Here we discuss other research eﬀorts relevant to
IP Anycast and relate our study to this broader context.
In addition to its implementation at the network layer,
anycast can also be implemented at the application layer.
Application-layer anycast provides a one-to-any service that
maps a high-level name, such as a DNS name, into one of
multiple servers, returning the selected server’s IP address to
the client. Such an approach oﬀers a number of advantages
over IP Anycast:
it is easier to deploy, oﬀers ﬁne-grained
control over the load on the servers and can provide very
fast failover to clients. And indeed, these advantages have
led to the widespread adoption of application layer anycast
as a service discovery primitive. For example, commercial
CDNs [38] use DNS-based redirection (in combination with
URL-rewriting) to direct clients to an appropriate server.
Related proposals in the academic community include, but
are not restricted to, [13,15,35–37].
In spite of these advantages, application-layer anycast is
not a panacea. The fact that IP Anycast operates at the
network layer implies that it is the only form of anycast
that can be used by low-level protocols; e.g., the use of any-
cast in IPv4-to-IPv6 transition [19]. As importantly, oper-
ating at the network layer gives IP Anycast a “ground level”
resilience not easily achieved by application-layer anycast –
e.g., using DNS-based redirection to achieve resilience across
a group of web servers requires ﬁrst that the DNS servers
themselves be available. It is this that makes IP Anycast
particularly well suited for replicating critical infrastructures
such as the DNS. For applications that do use IP Anycast,
our deployment proposal can be used to build an anycast
service that oﬀers good proximity, fast failover, and control
over the distribution of client load.
While IP Anycast functionality is available even today, it
scales poorly in the number of anycast groups. Recognizing
its many advantages, GIA [20] and PIAS [4] seek to make
IP Anycast more broadly usable and propose solutions to
improve the scalability of IP Anycast. Our study focusses
on the basic eﬀectiveness of IP Anycast, not its scalability,
and our results are relevant to the performance one might
expect of an IP Anycast service whether implemented as
a proxy-based service (PIAS) or a more scalable IP-layer
implementation (GIA).
Past studies have analyzed the use of AS-PATH prepend-
ing as a traﬃc engineering tool for multi-homed stub sites
[24,29] and have proposed automated mechanisms for this [9].
However, we are not aware of any studies analyzing the use
of AS-PATH prepending as a mechanism for controlling the
distribution of client load across anycasted servers. Simi-
larly, we conjecture other traﬃc engineering techniques can
also be used as a load distribution mechanism by anycast
operators. For example, some of the F root-servers use the
BGP no-export attribute as part of their anycast adver-
tisements. This restricts the scope of the advertisement em-
anating from the server and hence reduces the number of
clients served by it.
10. CONCLUSION
This paper presented the results of a detailed measure-
ment study of IP Anycast. Our study diﬀers from previous
eﬀorts on two fronts. First, we evaluate IP Anycast de-
ployments from a large number (>20,000) number of client
vantage points. Second, we deploy our own IP Anycast ser-
vice to perform controlled experiments that, for example,
allow us to study the failure-mode behavior of IP Anycast.
Our ﬁndings include:
1. IP Anycast, by itself, does not route clients to servers
that are close in terms of latency.
2. IP Anycast is aﬀected by delayed routing convergence
and may be slow in re-routing clients in the face of
server failures.
3. IP Anycast oﬀers good aﬃnity to all clients with the ex-
ception of a a small fraction that explicitly load balance
traﬃc across multiple upstream providers. i.e., we ﬁnd
IP Anycast does not interact poorly with inter-domain
routing and hence should not signiﬁcantly impact state-
ful services.
4. IP Anycast services experience a skewed distribution of
client load across the anycast servers.
Based on these measurements, we hypothesize that an IP
Anycast deployment with a single upstream provider and
with servers spread across this provider would oﬀer good
latency-based proximity. Our evaluation shows that this
holds in our internal anycast deployment. Further, we gen-
eralize this model and argue that for good proximity in an IP
Anycast deployment with multiple upstream providers, each
major upstream provider should be geographically spread
and well covered by anycast servers. Our evaluation fur-
ther suggests that such a deployment model provides fast
failover to clients. However, an evaluation of this approach
over larger deployments and fully characterizing the prox-
imity within such a model is a topic of future work. We
also evaluate the eﬀectiveness of AS-PATH prepending to
manipulate the distribution of client load across servers and
ﬁnd that it can be used for controlling the number of clients
routed to groups of anycast servers with the same upstream
provider. Overall, we ﬁnd that an IP Anycast service can be
deployed to oﬀer good proximity and fast failover to clients
while allowing for coarse-grained control over the distribu-
tion of client load across the deployment.
Our study is limited in several aspects. First, the size of
the internal deployment raises concerns regarding the gener-
ality of our results and beneﬁts of our proposed deployment
model for larger deployments. Second, our internal deploy-
ment setup does not allow us to evaluate the eﬀectiveness
of certain other traﬃc engineering techniques for controlling
client load. Finally, the use of external DNS nameservers as
clients in our study restricted the amount and rate of prob-
ing that could be done. For the same reason, our conjectures
regarding load balancing at clients had to be veriﬁed using
heuristics and survey data. Nonetheless, we hope the mea-
surement techniques presented here can serve in the large-
scale evaluation of experimental anycast deployments along
the lines presented in the paper. We are currently pursuing
the addition of anycast sites to our deployment which would
allow us to address some of the above limitations.
Note
The data sets used in this paper are available at
http://pias.gforge.cis.cornell.edu/measure.php.
Acknowledgements
We would like to thank Dan Eckstrom at CIT and James
Gurganus and the rest of the IT team at Intel-Research for
their eﬀorts towards the internal anycast deployment. We
are also grateful to Phil Buonadonna and Timothy Roscoe
for their help with the deployment. This material is based
upon work supported by the National Science Foundation
under Grant No. 0338750, by the AFOSR under Award No.
F49620-02-1-0233, FA8750-05-2-0128, PA8750-05-C-0268 and
by a grant from Cisco systems.
11. REFERENCES
[1] Abley, J. Hierarchical Anycast for Global Service
Distribution. ISC Technical Note ISC-TN-2003-1
www.isc.org/tn/isc-tn-2003-1.html.
[2] Abley, J. A Software Approach to Distributing
Requests for DNS Service Using GNU Zebra, ISC
BIND 9, and FreeBSD. In Proc. of USENIX Annual
Technical Conference (2004).
[3] Ballani, H., Ermolinskiy, A., Ratnasamy, S.,
and Francis, P. An Experiment in Deploying Next
Generation Network Protocols. Tech. rep., Cornell
University Technical Report, 2006.
[4] Ballani, H., and Francis, P. Towards a global IP
Anycast service. In Proc. of ACM SIGCOMM
(August 2005).
[5] Ballani, H., and Francis, P. Understanding IP
Anycast. Tech. rep., Cornell University Technical
Report, 2006. http://pias.gforge.cis.cornell.
edu/unpub/any-measure.pdf.
[6] Barber, P., Larson, M., Kosters, M., and
Toscano, P. Life and Times of J-Root. NANOG 32
meeting, October 2004.
http://www.nanog.org/mtg-0410/kosters.html.
[7] Basturk, E., Haas, R., Engel, R., Kandlur, D.,
Peris, V., and Saha, D. Using IP Anycast For Load
Distribution And Server Location. In Proc. of IEEE
Globecom Global Internet Mini Conference (1998).
[8] Boothe, P., and Bush, R. Anycast Measurements
Used to Highlight Routing Instabilities. NANOG 34
meeting, May 2005.
http://www.nanog.org/mtg-0505/boothe.html.
[9] Chang, R., and Lo, M. Inbound traﬃc engineering
for multi-homed AS’s using AS path prepending.
IEEE Network (2005), 18–25.
[10] Chen, E., and Bates, T. An Application of the
BGP Community Attribute in Multi-home Routing,
August 1996.
[11] Chun, B., Culler, D., Roscoe, T., Bavier, A.,
Peterson, L., Wawrzoniak, M., and Bowman, M.
PlanetLab: An Overlay Testbed for Broad-Coverage
Services. ACM SIGCOMM Computer Communication
Review 33, 3 (July 2003).
[12] Colitti, L. Eﬀect of anycast on K-root. DNS-OARC
Workshop, July 2005. http://www.ripe.net/info/
ncc/presentations/anycast-kroot.pdf.
[13] Fei, Z., Bhattacharjee, S., Zegura, E. W., and
Ammar, M. H. A Novel Server Selection Technique
for Improving the Response Time of a Replicated
Service. In Proc. of INFOCOM (1998).
[14] Feldmann, A., Maennel, O., Mao, Z. M.,
Berger, A., and Maggs, B. Locating internet
routing instabilities. In Proc. of ACM SIGCOMM
(2004).
[15] Freedman, M. J., Lakshminarayanan, K., and
Mazires, D. OASIS: Anycast for Any Service. In
Proc. of 3rd USENIX/ACM Symposium on Networked
Systems Design and Implementation (2006).
[16] Greene, B., and McPherson, D. ISP Security:
Deploying and Using Sinkholes. NANOG meeting,
June 2003. www.nanog.org/mtg-0306/sink.html.
[17] Gummadi, K. P., Saroiu, S., and Gribble, S. D.
King: Estimating Latency between Arbitrary Internet
End Hosts. In Proc. of the SIGCOMM Internet
Measurement Workshop (2002).
[18] Hardy, T. RFC 3258 - Distributing Authoritative
Name Servers via Shared Unicast Addresses, April
2002.
[19] Huitema, C. RFC 3068 - An Anycast Preﬁx for 6to4
Relay Routers, June 2001.
[20] Katabi, D., and Wroclawski, J. A framework for
scalable global IP-anycast (GIA). In Proc. of ACM
SIGCOMM (2000).
[21] Kim, D., Meyer, D., Kilmer, H., and Farinacci,
D. RFC 3446 - Anycast Rendevous Point (RP)
mechanism using Protocol Independent Multicast
(PIM) and Multicast Source Discovery Protocol
(MSDP), January 2003.
[22] Krishnamurthy, B., Wills, C., and Zhang, Y. On
the use and performance of content distribution
networks. In Proc. of ACM SIGCOMM Workshop on
Internet Measurement (2001).
[23] Labovitz, C., Ahuja, A., Bose, A., and Jahanian,
F. Delayed Internet routing convergence. IEEE/ACM
Trans. Netw. (2001).
[24] Lo, S. S. M., and Chang, R. K. C. Active
Measurement of the AS Path Prepending Method. In
Proc. of ICNP (Poster) (2005).
[25] Mao, Z. M., Bush, R., Griffin, T. G., and
Roughan, M. BGP beacons. In Proc. of the 3rd ACM
SIGCOMM conference on Internet measurement
(2003).
[26] Matsunaga, S., Ata, S., Kitamura, H., and
Murata, M. Applications of IPv6 Anycasting.
draft-ata-ipv6-anycast-app-00, February 2005.
[27] Miller, K. Deploying IP Anycast. NANOG 29
meeting, 2003.
http://www.net.cmu.edu/pres/anycast/.
[28] Partridge, C., Mendez, T., and Milliken, W.
RFC 1546 - Host Anycasting Service, November 1993.
[29] Quoitin, B., Pelsser, C., Bonaventure, O., and
Uhlig, S. A performance evaluation of BGP-based
traﬃc engineering. Intl. Journal of Network
Management 15, 3 (2005).
[30] Ratnasamy, S., Shenker, S., and McCanne, S.
Towards an Evolvable Internet Architecture. In
Proceedings of SIGCOMM 2005 (Aug. 2005).
[31] Sarat, S., Pappas, V., and Terzis, A. On the use
of Anycast in DNS. Tech. rep., HiNRG, Johns
Hopkins University Technical Report, 2004.
[32] Sarat, S., Pappas, V., and Terzis, A. On the use
of Anycast in DNS (Poster). In Proc. of ACM
SIGMETRICS (2005).
[33] Shaikh, A., Tewari, R., and Agrawal, M. On the
Eﬀectiveness of DNS-based Server Selection. In Proc.
of IEEE INFOCOM 2001 (2001).
[34] Spring, N., Mahajan, R., and Anderson, T.
Quantifying the Causes of Path Inﬂation. In Proc. of
ACM SIGCOMM (2003).
[35] Stoica, I., Adkins, D., Zhuang, S., Shenker, S.,
and Surana, S. Internet Indirection Infrastructure.
In Proc. of ACM SIGCOMM (2002).
[36] Wong, B., and Sirer, E. G. ClosestNode.com: An
Open-Access, Scalable, Shared Geocast Service 3A for
Distributed Systems. SIGOPS Operating Systems
Review 40, 1 (Jan 2006).
[37] Zegura, E. W., Ammar, M. H., Fei, Z., and
Bhattacharjee, S. Application-layer anycasting: a
server selection architecture and use in a replicated
Web service. IEEE/ACM Trans. Netw. 8, 4 (2000),
455–466.
[38] Akamai, May 2006. http://www.akamai.com/.
[39] AS112 Project Home Page, May 2006. www.as112.net.
[40] CacheFly, May 2006. http://www.cachefly.com.
[41] CIDR Report, May 2006.
http://www.cidr-report.org/.
[42] Global Server Load Balancing, May 2006.
http://www.tenereillo.com/GSLBPageOfShame.htm.
[43] History of DNS Root Anycast controversy, May 2006.
http://www.av8.net/IETF-watch/DNSRootAnycast/
History.html.
[44] Internal Anycast Service deployment, May 2006. http:
//pias.gforge.cis.cornell.edu/deployment.php.
[45] ISC F Root-Server, May 2006.
http://www.isc.org/index.pl?/ops/f-root/.
[46] National Lambda Rail, April 2006. www.nlr.net.
[47] Report on DNS Ampliﬁcation attacks, May 2006.
http://www.circleid.com/posts/
report on dns amplification attacks/.
[48] Root-Server Technical Operations, May 2006.
http://www.root-servers.org/.
[49] Route Views Project Page, May 2006.
www.route-views.org.
[50] SprintLink’s BGP Policy, May 2006.
http://www.sprintlink.net/policy/bgp.html.