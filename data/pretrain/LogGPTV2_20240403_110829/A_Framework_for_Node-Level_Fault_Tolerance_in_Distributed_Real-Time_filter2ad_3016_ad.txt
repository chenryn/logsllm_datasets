### NLFT Nodes

**State 0** represents the fault-free state, where all four wheel nodes are functioning correctly or experiencing transient faults that are masked by the Transient Error Masking (TEM) mechanism. A transition from **State 0** to **State F** occurs if a wheel node is affected by a permanent fault or if a transient fault cannot be masked by TEM.

\[
\begin{array}{c}
4\lambda_{t} \text{CDPT} \\
0 \\
4(\lambda_{P} + \lambda_{T}(1 - \text{CDPT})) \\
F
\end{array}
\]

**Figure 10.** State transition diagram for the wheel node subsystem with full functionality mode and NLFT nodes.

### State Transition Diagram with Degraded Functionality

**Figure 11** shows the state transition diagram for the wheel node subsystem when considering NLFT nodes and degraded functionality. The model consists of five states:

- **State 0:** All four computer nodes are working correctly.
- **State 1:** One of the computer nodes is affected by a permanent fault and is permanently down. The other nodes continue to provide their service.
- **State 2:** One of the computer nodes is affected by a transient fault and is temporarily down. The other nodes continue to provide their service.
- **State 3:** One of the computer nodes is affected by a transient fault and produces an omission failure. The other nodes continue to provide their service.
- **State F:** Failure. Two computer nodes are shut down, either due to a failure of two nodes or an undetected error in one node.

\[
\begin{array}{c}
4\lambda_{P} \text{CD} \\
3\lambda_{T} \text{CDPT} \\
1 \\
3(\lambda_{P} + \lambda_{T}(1 - \text{CDPT})) \\
4\lambda_{T} \text{CDPT} \\
0 \\
4\lambda_{T} \text{CDPOM} \\
4\lambda_{T} \text{CDPFS} \\
\mu_{\text{OM}} \\
\mu_{R} \\
4(1 - \text{CD})(\lambda_{P} + \lambda_{T}) \\
3\lambda_{T} \text{CDPT} \\
2 \\
3\lambda_{T} \text{CDPT} \\
3 \\
3(\lambda_{P} + \lambda_{T}(1 - \text{CDPT})) \\
F \\
3(\lambda_{P} + \lambda_{T}(1 - \text{CDPT}))
\end{array}
\]

**Figure 11.** State transition diagram for the wheel node subsystem with degraded functionality mode and NLFT nodes.

### Parameter Assignment

Before deriving results from the models presented, parameter values must be assigned. Fault rates and repair rates can be challenging to obtain as they depend on various factors such as underlying hardware, software implementation, and operating environment. However, for the purpose of comparing different approaches rather than deriving actual reliability measures, the following values may be acceptable:

- **Permanent fault rate (λP):** 1.82·10^-5^ faults per hour, derived from [15] using the MIL-HDBK-217 standard for a computer node in a distributed brake-by-wire system for heavy-duty trucks. The computer node includes a 32-bit processor, memory, communication interface, power IC, bus driver, and bus connections.
- **Transient fault rate (λT):** Assumed to be ten times higher than the permanent fault rate, i.e., λT = 1.82·10^-4^ faults per hour. Recent studies indicate that the proportion of transient faults will increase in future microcontrollers and memories [5].
- **Proportion of CPU time used by the real-time kernel (PFS):** 5% [10].
- **Fault tolerance (PT):** 90% of faults are tolerated, and 5% of transient faults result in omission failures (POM = 0.05) [7].
- **Error detection coverage (CD):** 99% (CD = 0.99), varied in Section 3.4.1.
- **Repair rate (µR):** 1.2·10^3^ repairs per hour, including time for restarting the node, checking for permanent faults, and reintegrating the node [16].
- **Omission failure repair rate (µOM):** 2.25·10^3^ repairs per hour, assuming a maximum repair time of 1.6 seconds.

### Results

The results of the reliability analysis for the complete Brake-By-Wire (BBW) system over one year are shown in **Figure 12**. As expected, the reliability for the degraded functionality mode is higher than for the full functionality mode. For degraded functionality with NLFT nodes, the reliability increases by 55% (from 0.45 to 0.70) after one year compared to fail-silent (FS) nodes. The mean time to failure (MTTF) also increases by almost 60% (1.2 years to 1.9 years) when using NLFT nodes.

**Figure 12.** Reliability of the BBW system.

**Figure 13** shows the reliability of the various subsystems with respect to both full and degraded functionality. The wheel node subsystem is identified as the main reliability bottleneck.

**Figure 13.** Reliability of the subsystems.

#### Effect of Varying Error Detection Coverage and Transient Fault Rate

The highest reliability for the BBW system is achieved when considering degraded functionality. In this subsection, we show the reliability for this mode after five hours for different values of error detection coverage and fault rate. The results, given in **Figure 14**, show the reliability of the system for increasing transient fault rates.

The results indicate that the error detection coverage has a significant influence on reliability. The fault rate has a negligible impact as long as it is much smaller than the repair rate. However, the reliability improvements from using NLFT increase for higher fault rates.

**Figure 14.** Reliability after five hours for varying error detection coverage and transient fault rate.

### Conclusions and Future Work

This paper proposes the use of node-level transient fault tolerance (NLFT) to improve the dependability of distributed systems. Specifically, we present a light-weight NLFT approach that aims to mask the majority of transient faults locally within the node. For permanent and transient faults that cannot be masked, the node must exhibit omission or fail-silent failures, simplifying error handling at the system level.

We suggest several error handling mechanisms based on previous studies, where a real-time kernel and parts of the proposed mechanisms have been implemented and evaluated using fault injection [7, 8]. Reliability calculations for a brake-by-wire application demonstrate that the reliability may increase by 55% after one year, and the MTTF increases almost 60% when using light-weight NLFT nodes compared to fail-silent nodes.

Future work includes the implementation and evaluation of the full set of error handling mechanisms to verify the viability of the approach and estimate total coverage and overhead. Additional work will investigate how to ensure replica determinism in replicated nodes and maintain consistency in case of omission failures. This may involve studying protocols like FlexRay [9], which facilitate fast recovery of state data with low communication overhead while guaranteeing the delivery of critical data.

### Acknowledgements

This work was partially supported by ARTES, the Swedish Foundation for Strategic Research (SSF), and the Saab Endowed Professorship in Robust Real-time Systems. We would like to thank Jonny Vinter at Chalmers University and Dr. Örjan Askerdal at Volvo Car Corporation for their valuable suggestions.

### References

[1] H. Kopetz and G. Bauer, "The Time-Triggered Architecture", Proceedings of the IEEE, vol. 91, 2003, pp. 112-26.

[2] D. Powell, J. Arlat, L. Beus-Dukic, A. Bondavalli, P. Coppola, A. Fantechi, E. Jenn, C. Rabejac, and A. Wellings, "GUARDS: A Generic Upgradable Architecture for Real-time Dependable Systems", IEEE Transactions on Parallel and Distributed Systems, vol. 10, 1999, pp. 580-599.

[3] D. Powell, "Distributed Fault Tolerance: Lessons from Delta-4", IEEE Micro, vol. 14, 1994, pp. 36-47.

[4] H. Kopetz, Real-Time Systems: Design Principles for Distributed Embedded Applications, Boston: Kluwer Academic, 1997.

[5] R. C. Baumann, "Soft Errors in Commercial Integrated Circuits", International Journal of High Speed Electronics and Systems, Vol. 14, No. 2, 2004, pp. 299-309.

[6] A. Burns and A. Wellings, Real-Time Systems and Programming Languages: Ada 95, Real-Time Java and Real-Time Posix, third ed. Harlow: Addison-Wesley, 2001.

[7] J. Aidemark, J. Vinter, P. Folkesson, and J. Karlsson, "Experimental Evaluation of Time-redundant Execution for a Brake-by-wire Application", Proc. of International Conference on Dependable Systems and Networks, Washington, DC, USA, 2002, pp. 210-216.

[8] J. Karlsson, J. Aidemark, P. Folkesson, and J. Vinter, "Experimental Dependability Evaluation of the Artk68-FT Real-time Kernel", International Conference on Real-Time and Embedded Computing Systems and Applications, Göteborg, Sweden, 2004.

[9] FlexRay Communications System Specifications Version 2.0, www.flexray.com, June 2004.

[10] J. J. Labrosse, MicroC/OS-II: The Real-Time Kernel, second edition, Lawrence: R&D, 1999.

[11] G. Heiner and T. Thurner, "Time-Triggered Architecture for Safety-related Distributed Real-time Systems in Transportation Systems", Proceedings of the 28th International Symposium on Fault Tolerant Computing, Munich, Germany, 1998, pp. 402-407.

[12] S. Poledna, Fault-tolerant Real-time Systems: The Problem Of Replica Determinism, Boston, Mass, Kluwer Academic Publishers, 1996.

[13] R. A. Sahner and K. S. Trivedi, "Reliability Modeling using SHARPE", IEEE Transactions on Reliability, vol. R-36, 1987, pp. 186-93.

[14] D. Chen, S. Dharmaraja, D. Chen, L. Li, K.S. Trivedi, R.R. Some, A.P. Nikora, "Reliability and Availability Analysis of the JPL Remote Exploration Experimentation System", Proc. of International Conference on Dependable Systems and Networks, Washington, DC, USA, 2002, pp. 337-342.

[15] V. Claesson, Efficient and Reliable Communication in Distributed Embedded Systems, Ph.d thesis, Chalmers University of Technology, Göteborg, Sweden, 2002.

[16] H. Sivencrona, On the Design and Validation of Fault Containment Regions in Distributed Communication Systems, Ph.d thesis, Chalmers University of Technology, Göteborg, Sweden, 2004.