### Performance Evaluation of the Access Control Phase

For each cluster member (as detailed in Section II-B), we evaluated the performance of the access control phase by testing whether normal and anomalous profiles could gain access to the network. We used a testing set containing 225 normal profiles from week-2 and a set of anomalous profiles generated by modifying one or multiple features by one, two, and three standard deviations away from the centroid of each individual cluster in the cluster distribution with \( k = 40 \). These profiles were assumed to be new users attempting to access the network. Each profile was paired with its closest cluster in the cluster distribution, which then conducted a vote among its members to decide on the access (see Section II-C).

The performance of the access control phase in terms of True Rejection (TR) is shown in Table I. Our experiments demonstrated that 95% or more of anomalous profiles can be detected successfully with a False Rejection (FR) rate of 10%. The reason 5% of the anomalous profiles went undetected lies in the method used to generate them. Anomalous profiles were generated one or more standard deviations away from the centroid of each individual cluster. This did not necessarily create profiles at distances larger than the access control threshold \( t_i \) for all cluster members. In fact, 5% of the anomalous profiles were at distances smaller than \( t_i \) for at least 50% of the cluster members. As a result, these anomalous profiles were accepted into the network. The TR increased to 100% for anomalous profiles that were three standard deviations away from individual clusters. These results demonstrate that the access control phase is capable of detecting a large fraction of anomalous profiles while still allowing normal profiles to gain access to the network. Moreover, these experiments show that an access control mechanism based on behavior profiles can be successfully implemented in a real network.

### Incremental-Learning Algorithm

So far, we have presented a validation of the mechanism without considering temporal evolution. Next, we evaluate the ability of the mechanism to dynamically adjust to new behaviors (concept drift) as well as its response to attacks.

#### 1. Concept Drift and Collusion Attacks

To evaluate the performance of the incremental-learning algorithm described in Section III, we started with the cluster distribution with \( k = 40 \) and non-weighted voting selected during the clustering phase. We calculated the global centroid \( C \) as the average of the centroids \( c_i \) of all clusters in the cluster distribution (see Figure 3). We then created profiles that were one, two, and three standard deviations away from the global centroid \( C \). The basic idea was to create outlier profiles located at the edges of the cluster distribution to determine the boundary between concept drift and collusion attacks (decision boundary). A total of 378 profiles were created by modifying one or multiple features by one, two, and three standard deviations from the average values stored in the global centroid. One by one, each newly generated profile was assigned to a member of the cluster distribution as if it were its newly computed profile. Each individual assignment triggered the incremental-learning algorithm, allowing us to quantify the percentage of candidate clusters that would be accepted as concept drift.

Table II summarizes our results. As can be seen, 85% of candidate clusters formed with profiles located one standard deviation away from the global centroid \( C \) were deemed collusion attacks, leaving only 15% of the candidate clusters as concept drift. On the other hand, 92% and 96% of candidate clusters were detected as collusion attacks for profiles two and three standard deviations away, respectively. The significance of this result is that the creation of new clusters of behavior is largely limited to a distance of one standard deviation or less from the global centroid of the cluster distribution. Hence, the damage that an attacker can inflict on the mechanism is limited. Although this may be seen as a limitation to the incorporation of new clusters of behavior, it protects the mechanism from attacks while still leaving some room for growth.

On certain occasions, there might be a need to force a new cluster of behavior that is very distant from the global centroid into the cluster distribution. For example, when a group of users starts using a new application that generates behavior profiles substantially different from previous ones, it is very likely that such profiles will raise attack alerts in the incremental-learning algorithm. If this is the case, the clustering and bootstrap phases will have to be re-executed to include these new profiles as initial network members so that the access control policies are modified accordingly.

#### 2. Threshold Attacks

One or multiple attackers within a cluster of behavior may try to modify the thresholds and alter the dimensions of their own cluster. We only considered attacks where fewer than 50% of the cluster members are compromised. Otherwise, the attackers hold control over the voting process. We concentrated on studying the effects of two types of attacks: diversified attacks, where attackers modified their own profiles to disperse their cluster in multiple directions, and unified attacks, where attackers agreed on a unique modified profile to stretch their cluster in a single direction (see Figure 4).

We started with the cluster distribution with \( k = 30 \) selected during the clustering phase. From the distribution, we picked two clusters: cluster1 and cluster2, which featured the highest and lowest spread, respectively, measured in terms of the distance between the behavior profiles of their members. The reasoning behind this selection was to study any possible correlation between the effects of the attacks and the spread across the members of a cluster. For each cluster, we produced a range of attacks by varying the number of attackers from 1% to 50% of the total size of the cluster. For the diversified attack, each attacker generated a different attack profile by iteratively increasing each of its normal profile features by 10%. In the case of the unified attack, all attackers started with the same initial normal profile and iteratively increased each of the profile features by 10%. A factor of 10% was chosen arbitrarily to demonstrate the effect of attacks. A different percentage selection would result in shorter or longer time scales for the attacks, but the end effects would be similar.

To evaluate the performance of the mechanism when faced with such attacks, we defined a dispersion factor \( d \) that represents the ratio between the initial average threshold of the cluster and the final average threshold of the cluster once the attack had been detected. The average threshold corresponded to the mean value of the thresholds for all the members of a cluster and, as such, constituted a reasonable measurement of the effects of an attack on the bootstrap phase.

Figure 6 shows the dispersion factors for different percentages of attackers. First, it is important to note that all unified and diversified attacks were eventually detected by the mechanism. Additionally, we see that the dispersion factor increased as a function of the percentage of attackers. Nonetheless, the dispersion factor seemed to be limited to a factor of three in all cases. The results also showed that the cluster with the largest spread (cluster1) displayed larger dispersion factors than the one with the smallest spread (cluster2). Moreover, diversified attacks appeared to be more effective than unified attacks in terms of dispersion factors. Overall, these experiments demonstrate that the mechanism is effective against threshold attacks involving 50% or fewer attackers within a cluster.

### Related Work

Clustering methods for anomaly detection have been used to model a normal class from a set of normal samples. Samples are then compared against the normal class and deemed either normal or anomalous. Portnoy [7] was perhaps the first to use a hierarchical clustering algorithm to obtain a normal model and successfully detect different types of intrusions from the KDD CUP 1999 dataset. Later work by Leon et al. [10] proposed a fully unsupervised clustering method for anomaly detection, where each cluster was characterized by a fuzzy membership function, allowing a certain sample to be a member of different clusters with different degrees of membership.

Our approach is novel in the sense that we apply clustering to behavior profiles computed from single samples rather than clustering the samples directly. Cooperative Anomaly Detection Sensors have been explored in systems like COSSACK [11] and CATS [12], where a distributed environment shares alerts to strengthen each individual local security capability. We implement the concept of cooperation by allowing each network member to participate in the access control decision rather than just sharing alerts.

A number of Network Access Control (NAC) technologies are currently available in the market. Cisco Network Module for Integrated Services Routers offers an agentless solution for authenticating, authorizing, and remediating devices connected wired or wirelessly to the network. The Cisco Profiler executes an in-depth control of the endpoint devices of the network by passively monitoring their traffic. The Network Access Protection (NAP) platform from Windows provides a client and server-side platform to implement policy validation, network access limitation, and ongoing compliance. Compared to all other previous NAC technologies, our mechanism uses automatically computed access control policies based on behavior profiles instead of fixed policies as a security feature for the pre-connect phase.

### Conclusions and Future Work

We have presented a network access control mechanism that enhances BB-NAC by improving its access control capabilities and incorporating the automatic update of behavior-based access control policies. Behavior profiles are clustered automatically into clusters that define the access control policies. Newcomers are admitted into the network only if their profiles are deemed normal by their closest cluster of behavior. We validate the mechanism using real user profiles computed from Cisco NetFlow logs from a router at our host institution. In particular, we achieve true rejection rates of 95% for anomalous profiles with 10% false rejection rates. We have also introduced an incremental-learning algorithm that allows for an automatic update of the behavior-based access control policies while making the mechanism robust against attacks. Experiments show that the mechanism is effective in detecting collusion attacks while leaving room for temporal evolution of clusters of behavior (concept drift). Moreover, the mechanism is robust to threshold attacks involving fewer than 50% of attackers.

The results presented here constitute the first full implementation of an automatic network access control mechanism based on behavior profiles. A more complete treatment exploring content- and non-content-based behavior profiles for multiple ports, as well as an evaluation of the practical limits of this approach, needs to be examined. By combining content- and non-content-based behavior profiles, we hope to achieve a more robust access control. Ultimately, behavior-based access control may also support role-based access control [13] by providing an automated means of assisting in the manual specification of the data and services a role may legitimately access.