for each cluster member (Section II-B). At this point, we
proceeded to measure the performance of the access control
phase by testing whether or not normal and anomalous proﬁles
could gain access into the network. For this purpose, we used
the testing set containing 225 normal proﬁles from week-2
and the set of anomalous proﬁles generated by modyﬁng one
or multiple features by one, two and three standard deviations
away from the centroid of each individual cluster in the cluster
distribution with k=40. These proﬁles were assumed to be
new users trying to gain access into the network. Therefore,
each proﬁle was paired with its closest cluster in the cluster
distribution which then conducted a vote among its members
to decide on the access of the proﬁle (see Section II-C).
The performance of the access control phase in terms
of TR is shown in Table I. Our experiments demonstrated
that 95% or more of anomalous proﬁles can be detected
successfully with a FR rate of 10%. The reason a 5% of
the anomalous proﬁles went undetected lies in the method
used to generate them. Anomalous proﬁles were generated
one or more standard deviations away from the centroid of
each individual cluster. This did not necessarily create proﬁles
at distances larger than the access control threshold ti for
all cluster members. In fact, 5% of the anomalous proﬁles
were at distances smaller than ti for at least 50% of the
cluster members. As a result, these anomalous proﬁles were
accepted into the network. The TR increased up to 100% for
anomalous proﬁles that were three standard deviations away
from individual clusters. These results demonstrate that the
access control phase is able to detect a large fraction of
anomalous proﬁles while still allowing normal proﬁles to gain
access into the network. Moreover, these experiments show
that an access control mechanism based on behavior proﬁles
can be successfully implemented in a real network.
C. Incremental-Learning Algorithm
Thus far we have presented a validation of the mechanism
without considering temporal evolution. Next, we evaluate
9
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:14:28 UTC from IEEE Xplore.  Restrictions apply. 
)
%
(
t
e
a
R
n
o
j
i
t
c
e
e
R
e
u
r
T
100
80
60
40
20
0
0
10
Daily Profiles
)
%
(
t
e
a
R
n
o
j
i
t
c
e
e
R
e
s
a
F
l
non−weighted voting
weighted voting
20
30
40
50
60
Number of Clusters
Daily Profiles
non−weighted voting
weighted voting
50
40
30
20
10
0
0
10
20
30
40
50
60
Number of Clusters
(a) Best TR as a function of k using K-means++ method.
(b) Best FR as a function of k using K-means++ method.
Fig. 5. Cross-validation Tests.
the ability of the mechanism to dynamically adjust to new
behaviors (concept drift) as well as its response to attacks.
1) Concept Drift and Collusion Attacks: In order to eval-
uate the performance of the incremental-learning algorithm
described in Section III, we started with the cluster distri-
bution with k=40 and non-weighted voting selected during
the clustering phase. We calculated the global centroid C
as the average of the centroids ci of all clusters in the
cluster distribution (see Figure 3). We then proceeded to create
proﬁles that were one, two and three standard deviations away
from the global centroid C. The basic idea was to create
outlier proﬁles located at the edges of the cluster distribution
in order to determine the boundary between concept drift
and collusion attacks (decision boundary). A total of 378
proﬁles were created by modifying one or multiple features
by one, two and three standard deviations from the average
values stored in the global centroid. One by one, each of the
newly generated proﬁles was assigned to a member of the
cluster distribution as if it were its newly computed proﬁle.
Each individual assignment triggered the incremental-learning
algorithm which allowed us to quantify the percentage of
candidate clusters that would be accepted as concept drift.
Table II summarizes our results. As can be seen, 85% of
candidate clusters formed with proﬁles located one standard
deviation away from the global centroid C were deemed
collusion attacks. Leaving only 15% of the candidate clusters
as concept drift. On the other hand, 92% and 96% of candidate
clusters were detected as collusion attacks for proﬁles two and
three standard deviations away respectively. The relevance of
this result is that the creation of new clusters of behavior is
largely limited to a distance one standard deviation or less
from the global centroid of the cluster distribution. Hence,
the damage that an attacker can infringe on the mechanism
is limited as well. Although this may be seen as a limitation
to the incorporation of new clusters of behavior, it protects
the mechanism from attacks while still leaving some room for
growth.
On certain occasions there might be a need to force a
new cluster of behavior that is very distant from the global
centroid into the cluster distribution. For example, when a
σ From Global Centroid
Candidate Clusters Rejected
1 σ
2 σ
3 σ
85%
92%
96%
TABLE II
PERCENTAGE OF candidate clusters DEEMED AS collusion attacks.
PROFILES WERE GENERATED AT ONE, TWO, AND THREE σ AWAY FROM
THE GLOBAL CENTROID. Candidate clusters CLOSER TO THE decision
boundary ARE MORE LIKELY TO BE DEEMED concept drift.
group of users start using a new application that generates
behavior proﬁles substantially different from previous ones,
it is very likely that such proﬁles will raise attack alerts in
the incremental-learning algorithm. If this is the case, the
clustering and bootstrap phases will have to be re-executed
to include these new proﬁles as initial network members so
that the access control policies are modiﬁed accordingly.
2) Threshold Attacks: One or multiple attackers within a
cluster of behavior may try to modify the thresholds and
alter the dimensions of their own cluster. We only considered
attacks where fewer than 50% of the cluster members are com-
promised. Otherwise, the attackers hold control over the voting
process. We concentrated on studying the effects of two types
of attacks: diversiﬁed attacks where attackers modiﬁed their
own proﬁles to disperse their cluster in multiple directions, and
uniﬁed attacks where attackers agreed on a unique modiﬁed
proﬁle to stretch their cluster on a single direction (see Figure
4).
We started with the cluster distribution with k=30 selected
during the clustering phase. From the distribution, we picked
two clusters: cluster1 and cluster2, which featured respectively
the highest and the lowest spread measured in terms of the
distance between the behavior proﬁles of their members. The
reasoning behind this selection was to study any possible
correlation between the effects of the attacks and the spread
across the members of a cluster. For each cluster, we produced
a range of attacks by varying the number of attackers from 1%
to 50% of the total size of the cluster. For the diversiﬁed attack,
each attacker generated a different attack proﬁle by iteratively
increasing each of its normal proﬁle features by 10%. In the
10
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:14:28 UTC from IEEE Xplore.  Restrictions apply. 
3
r
o
2.5
i
t
c
a
F
n
o
s
r
e
p
s
D
i
2
1.5
1
0
cluster1,diversified
cluster2,diversified
cluster1,unified
cluster2,unified
10
20
30
Percentage of Attackers
40
50
Fig. 6. Dispersion factor as a function of the percentage of attackers in a
cluster.
case of the uniﬁed attack, all attackers started with the same
initial normal proﬁle and iteratively increased each of the
proﬁle features by 10%. A factor of 10% was chosen arbitrarily
to demonstrate the effect of attacks. A different percentage
selection would result on shorter or longer time scales for the
attacks. However, the end effects would be similar.
In order to evaluate the performance of the mechanism when
faced with such attacks, we deﬁned a dispersion factor d that
represents the ratio between the initial average threshold of the
cluster, and the ﬁnal average threshold of the cluster once the
attack had been detected. The average threshold corresponded
to the mean value of the thresholds for all the members of a
cluster and as such it constituted a reasonable measurement of
the effects of an attack on the bootstrap phase.
Figure 6 shows the dispersion factors for different percent-
ages of attackers. First, it is important to note that all uniﬁed
and diversiﬁed attacks were eventually detected by the mech-
anism. In addition, we see that the dispersion factor increased
as a function of the percentage of attackers. Nonetheless, the
dispersion factor seemed to be limited to a factor of three in all
cases. The results also showed that the cluster with the largest
spread (cluster1), displayed larger dispersion factors than the
one with the smallest spread (cluster2). Moreover, diversiﬁed
attacks appeared to be more effective than uniﬁed attacks
in terms of dispersion factors. Overall,
these experiments
demonstrate that the mechanism is effective against threshold
attacks involving 50% or less of attackers within a cluster.
VI. RELATED WORK
Clustering methods for anomaly detection have been used to
model a normal class from a set of normal samples. Samples
are then compared against the normal class and deemed either
normal or anomalous. Portnoy [7] was perhaps the ﬁrst to
use a hierarchical clustering algorithm to obtain a normal
model and successfully detected different types of intrusions
from the KDD CUP 1999 dataset. Later work by Leon et
al. [10] proposed a fully unsupervised clustering method for
anomaly detection where each cluster was characterized by
a fuzzy membership function so that a certain sample would
be a member of different clusters with different degrees of
membership.
11
Our approach is novel in the sense that we apply clustering
to behavior proﬁles computed from single samples rather than
clustering the samples directly. Cooperative Anomaly Detec-
tion Sensors have been explored in systems like COSSACK
[11] and CATS [12] where a distributed environment shares
alerts to strengthen each individual local security capabilities.
We implement the concept of cooperation by allowing each
network member to participate in the access control decision
rather than just sharing alerts.
A number of NAC technologies are currently available in
the market. Cisco Network Module for Integrated Services
Routers offers an agentless solution authenticating, authorizing
and remediating devices connected wired or wirelessly to the
network. The Cisco Proﬁler executes an in-depth control of
the endpoint devices of the network by passively monitoring
their trafﬁc. The Network Access Protection (NAP) platform
from Windows, provides a client and server-side platform to
implement policy validation, network access limitation and
ongoing compliance. Compared to all other previous NAC
technologies, our mechanism uses automatically computed
access control policies based on behavior proﬁles instead of
ﬁxed policies as a security feature for the pre-connect phase.
VII. CONCLUSIONS AND FUTURE WORK
We have presented a network access control mechanism
that enhances BB-NAC by improving its access control ca-
pabilities as well as incorporating the automatic update of
behavior-based access control policies. Behavior proﬁles are
clustered automatically into clusters that deﬁne the access
control policies. Newcomers are admitted into the network
only if their proﬁles are deemed normal by their closest cluster
of behavior. We validate the mechanism using real user proﬁles
computed from Cisco Netﬂow logs from a router at our host
institution. In particular, we achieve true rejection rates of 95%
for anomalous proﬁles with 10% false rejection rates. We have
also introduced an incremental-learning algorithm that allows
for an automatic update of the behavior-based access control
policies while making the mechanism robust against attacks.
Experiments show that the mechanism is effective in detecting
collusion attacks while leaving room for temporal evolution of
clusters of behavior (concept drift). Moreover, the mechanism
is robust to threshold attacks involving fewer than 50% of
attackers.
The results presented here constitute the ﬁrst full imple-
mentation of an automatic network access control mechanism
based on behavior proﬁles. A more complete treatment ex-
ploring content- and non-content-based behavior proﬁles for
multiple ports as well an evaluation of the practical limits
of this approach need to be examined. By combining content-
and non-content-based behavior proﬁles, we hope to achieve a
more robust access control. Ultimately, behavior-based access
control may also support role-based access control [13] by
providing an automated means of assisting in the manual
speciﬁcation of the data and services a role may legitimately
access.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:14:28 UTC from IEEE Xplore.  Restrictions apply. 
REFERENCES
[1] V. Frias-Martinez, S. Stolfo, and A. Keromytis, “Behavior-based network
access control: A proof-of-concept,” in Information Security Conference
(ISC), 2008.
[2] ——, “Behavior proﬁle clustering for false alert reduction in anomaly
detection sensors,” in Annual Computer Security Applications Confer-
ence (ACSAC), 2008.
[3] ——, “Barter: Behavior proﬁle exchange for behavior-based admission
and access control in manets,” in Fifth International Conference on
Information Systems Security, 2009.
[4] D. Arthur and S. Vassilvitskii, “k-means++: the advantages of careful
seeding,” in SODA ’07: Proceedings of the eighteenth annual ACM-
SIAM symposium on Discrete algorithms.
Philadelphia, PA, USA:
Society for Industrial and Applied Mathematics, 2007, pp. 1027–1035.
[5] J. Hartigan and M. Wong, “A k-means clustering algorithm,” Applied
Statistics, vol. 28, 1979.
[6] H. Bock, “Automatic classiﬁcation,” 1974.
[7] L. Portnoy, E. Eskin, and S. Stolfo, “Intrusion detection with unlabeled
data using clustering,” in In Proceedings of ACM CSS Workshop on Data
Mining Applied to Security (DMSA), 2001.
[8] E. Spinosa, A. Ponce de Leon, and J. Gama, “Olindda: A cluster-based
approach for detecting novelty and concept drift in data streams,” in In
Proceedings of the ACM Symposium on Applied Computing, 2007.
[9] C. Systems, “Inside cisco ios software architecture,” 2000.
[10] E. Leon, O. Nasraoui, and J. Gomez, “Anomaly detection based on
unsupervised niche clustering with application to network intrusion,” in
In Proceedings of the congress of evolutionary Computation.
Press,
2004, pp. 502–508.
[11] C. Papadopoulos, R. Lindell, J. Mehringer, A. Hussain, and R. Govindan,
“Cossack: Coordinated suppression of simultaneous attacks,” in Pro-
ceedings of DARPA Information Survivability Conference and Exposition
(DISCEX III), 2003.
[12] F. Dressler, G. Munz, and G. Carle, “Attack detection using cooperating
autonomous detections systems (cats),” 2004.
[13] D. Ferraiolo and R. Kuhn, “Role-based access control,” in In 15th NIST-
NCSC National Computer Security Conference, 1992, pp. 554–563.
12
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:14:28 UTC from IEEE Xplore.  Restrictions apply.