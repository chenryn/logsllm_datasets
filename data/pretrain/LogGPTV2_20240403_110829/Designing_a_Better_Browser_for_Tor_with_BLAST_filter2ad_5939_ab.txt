have random advertisements or user tracking resources that
are loaded long after all other resources have been completed.
For example, a script may track user behavior and send it to the
server via a resource request every ten seconds. If we counted
those resource requests, the page load time would not be as
meaningful.
Second, we use resource load time, the time difference
between the browser requesting a resource and receiving that
resource. This metric helps us determine why pages are taking
a long time to load and how it can be resolved, as we break
down each resource loading into ﬁve events:
(1) Resource request created.
(2) Resource dispatched onto an available connection.
(3) First byte sent from the client (request).
(4) First byte received from the server (response).
(5) Final byte received from the server (response).
For a resource r, the time gap between events (1) and (5)
would be the resource load time. We refer to the gap between
events (1) and (2) as the queue wait time, (2) and (3) as the
TLS wait time2, (3) and (4) as the server wait time, and (4)
and (5) as the transfer time. Ideally, we would want server
wait time to be one round-trip time, and other types of load
times to approach zero.
We also categorize page load time using the resource tree.
We sum up the categorized resource load time of all resources
between the ﬁnal resource (counting 95% of resources) and
the root resource, following the path of parenthood in the
resource tree. If the ﬁnal byte of a resource was received after
its child resource was created, then its contribution to page
transfer time is accordingly cut. Any time gap between the ﬁnal
byte received and the child’s resource request being created
is classiﬁed as non-categorized time. Non-categorized time is
usually a minuscule time gap due to the browser parsing the
previous resource, although it can also be due to timed scripts.
III. HTTP/1.1 PIPELINING
In this section, we analyze HTTP/1.1 with pipelining.
We investigate the usefulness of pipelining for Tor Browser
and whether or not observed or suspected issues hamper its
usefulness. We start with a description of how pipelining
works in Section III-A, follow up with some potential issues
in Section III-B, describe our data collection methodology in
Section III-C, and analyze pipelining performance to determine
the impact of these potential issues in Section III-D.
A. Pipelining in Tor Browser
Normally, resources can only be dispatched on newly
established or idle connections that have ﬁnished receiving
resources. HTTP Pipelining (or simply pipelining) allows re-
sources to be dispatched on active connections without waiting
for a response for previous resources. The server should
respond to each resource request in order. Each pipeline has
a maximum depth, the maximum number of resource requests
that can be sent simultaneously on a connection. The browser’s
resource loading capacity for a server is therefore equal to
the number of concurrent connections allowed (six) times the
depth of each pipeline.
Pipelining has a difﬁcult history with HTTP. Pipelining was
brieﬂy implemented and deployed in both Firefox and Chrome
for HTTP/1.1, though it was quickly disabled in both due to a
lack of noticeable load time improvement. This was not before
pipelining became standard in HTTP/1.1, and as a result all
HTTP servers should support pipelining (no extra negotiation
is required to initiate pipelining). However, many servers still
respond incorrectly to pipelining.
2 This gap is the TLS wait time because resources do not wait for TLS
completion before being dispatched onto a connection, but they cannot be
written as network bytes before TLS negotiation is complete.
3
Partly as a response to website ﬁngerprinting attacks, Tor
developers enabled randomized pipelining on Tor Browser
after it had been disabled on major browsers. This implementa-
tion also contains several other features, including randomized
pipeline depth and randomized resource loading order. How-
ever, after a few years, Tor developers also disabled pipelining,
as it had “become a maintenance burden” due to its large
amount of difﬁcult-to-understand code. Pipelining code was
entirely removed from newer versions of both Firefox and Tor
Browser in favor of using HTTP/2.
Despite its problems, pipelining does reduce load times on
Tor Browser. Across our data set, the largest server for each
web page has a mean of 34.4 resources. Without pipelining,
only 6 resources can be loaded in one round trip, round
trips being the prohibitive bottleneck of browsing times on
an anonymity network. Pipelining is important for expanding
the limited resource loading capacity of HTTP/1.1.
B. Issues with Pipelining
We discuss some issues with pipelining as a protocol in
the following.
Head-of-line blocking. Head-of-line blocking refers to the
restriction that
the web server can only respond to each
requested resource following the order in which the client
requested them. Later resources can suffer delays waiting for
the pipelined connection to load earlier resources, with larger
resources causing greater delays.
Pipelining errors. Despite the standardization of pipelining
support in HTTP/1.1, many servers still respond to pipelining
incorrectly, leading to connection errors in the browser. These
connections are discarded and the resource requests must
be re-sent
in another connection, causing delays. This is
especially detrimental if a large number of resource requests
were pending on that connection. The browser will then cease
to use pipelining on that server for the given page load, losing
the beneﬁts of pipelining.
Choosing pipeline depth. While a larger pipeline depth
increases the total resource loading capacity of the browser, it
also exacerbates both head-of-line blocking and the potential
delay caused by loading errors. On the other hand, a larger
pipeline depth is helpful for loading servers with many small
resources in parallel. Another way to increase resource loading
capacity is to use more connections in parallel, but this causes
issues with some routers and increases memory consumption
for servers.
C. Data collection and methodology
To answer our questions about pipelining performance, we
collect data on two versions of Tor Browser: Tor Browser 8.5
(TB-8.5), the latest version of Tor Browser at data collection,
uses HTTP/2; Tor Browser 6.5 (TB-6.5), an earlier version,
instead uses pipelining. To eliminate extraneous factors in
our comparison between these protocols, we reintroduced
pipelining code to TB-8.5, where it had been removed. The
results in this section (to follow) are chieﬂy based on TB-8.5
with pipelining. Later, in Section IV, we compare TB-8.5 with
TB-6.5.
We collected all data using a single computer connected
to Tor. Tor consists of multiple nodes around the world and
we disabled guard selection so that new entry nodes would be
selected for every Tor circuit, allowing for greater coverage of
the global Tor network. Tor connections serve as the bandwidth
bottleneck so we did not attempt to limit our own bandwidth,
and it is responsible for almost all of the round trip times. In
experiments where we compared the performance of different
browser designs, we visited the same page with each browser
on the same circuit, and then we dropped the Tor circuit before
moving on to the next browser design. Using the same circuit
for the same instance allows us to compare page loads directly
(as different circuits may access different versions of the page
due to localization of the exit node), and using different circuits
between different pages lets us capture a wider range of the
Tor network.
We visited three sets of pages for each experiment: (1) Top
10 pages, 50 times each; (2) Top 200 pages, 5 times each; and
(3) Top 1000 pages, 1 time each. We visit the home pages
of Alexa’s top 1000 pages as they were the most popular,
to best represent likely user experience of the network. In
total, we have 2500 page instances, although some instances
did not load properly and were discarded (e.g. pages from
Chinese servers were often inaccessible to Tor). These pages
were visited from June 2019 to August 2019. We deﬁne a
properly loaded page as a page where at least 2 resources
were fully loaded. In comparative experiments, if an instance
of the page was not loaded properly for any of the browser
versions we were comparing, we also excluded that instance
from the experiment for the other browser versions.
D. Data Analysis
We analyze the features and implementation of pipelining
on Tor Browser. We begin with an analysis of the overall per-
formance in loading times, and proceed by analyzing whether
or not each of the above issues hampers the usefulness of
pipelining.
1) Overall performance: Over our pipelining data set,
pages had a mean of 104 resources and the mean page size
was 2.1 MB, so the mean resource size was 20 kB, but the
median resource size was only 3 kB: the majority of resources
were very small. The resource tree had a mean height of 15.4.
The top 10 sites were much smaller other sites, with a mean of
only 55 resources compared to 116 for the top 200 and 118 for
the next top 1000, and a mean page size of 1.3 MB compared
to 2.3 MB and 2.2 MB respectively. The mean page load time
over our whole pipelining data set was 16.4 s. This was 13.7 s
for the top 10 sites, and 19.6 s for both the top 200 sites and
the top 1000 sites.
2) Categorization of load time: For every page in our data
set, we break down its load time into the four categories
described in Section II-C, and show them in Figure 2. Roughly
5.8 s (36%) of page load time was due to resources waiting in
queue for connections; the same amount was incurred again
waiting for servers to respond to resource requests (as Tor has
a high latency). Only around 0.91 s (5.6%) of page load time
was due to transfer time.
The same ﬁgure shows that resources took 2.85 s to load
on average, but only 0.079 s (2.7%) of resource load time was
4
(a)
(b)
Fig. 2: Categorization of mean page load time and resource
load time on the pipeline data set. Note the different scales
of the y-axes.
Fig. 3: Cumulative distribution function for queue wait times
per resource, with a cutoff of 20 seconds.
due to transfer time. A much greater portion of resource load
time, 1.56 s (55%), was spent waiting in queue. This is not
sufﬁciently explained by resources waiting for connections to
be established as it far exceeds one round-trip time. We show
the distribution of queue wait times in Figure 3. Around a third
of resources did not have to wait in queue as an established
connection was already available, but more than half of them
had to wait for more than half a second. and 30% had to wait
for more than a second. These long queue wait times could
indicate a lack of resource loading capacity or pipelining errors
causing connection closure.
3) Analysis of potential issues: We analyze the possible
issues raised in Section III-B.
Head-of-line blocking. Head-of-line blocking can delay
pipelined resource loading because a resource cannot begin
transferring until the previously pipelined resource has ﬁn-
ished. We measure the block time of a resource by summing
up the transfer times of all resources pipelined before it, only
counting resources that were dispatched onto the same pipeline
within 0.01 s of each other. We set this restriction to ensure
that we are considering resources that were indeed blocked by
previously pipelined resources. Among these resources (33%
of all resources), the mean block time was 0.25 s. Only 1%
of resources suffered a head-of-line blocking time over 0.5 s,
and if we removed those, the mean block time drops to 0.05 s,
insigniﬁcant compared to the mean resource load time.
Therefore, a tiny portion (around 0.2%) of resources suf-
fered the majority of all head-of-line blocking. These large
block times suggest
that head-of-line blocking was rarely
severe and had little impact on load times in the vast majority
of pages. Note that block times are not necessarily caused by
pipelining: they may be due to connection stalling issues, Tor
circuit issues, server unresponsiveness, etc.
Pipelining errors. Pipelining support is required in HTTP/1.1
web servers. Surprisingly, we found that a signiﬁcant portion of
HTTP/1.1 pipelines encountered errors and were closed prema-
turely. Out of the 118,746 resources we found that attempted
to use pipelining, 25,679 (22%) of them were dispatched on
connections that were closed before loading them completely,
forcing them to dispatch on a new connection. On the other
hand, only 68 out of the 73,710 non-pipelined resources were
sent on prematurely closed connections.
We found that most servers seemed to support pipelining
correctly: 58% of the servers in our database that pipelined at
least 2 resources did not prematurely close connections. It is
not clear exactly why the other servers do not support pipelin-
ing: we observed that
they simply aborted the connection
without explanation some time after pipelined requests were
sent. The large error rate of pipelining hampers its usefulness.
Choosing pipeline depth. As poor resource loading capacity
increases queue wait time, and queue wait time is a signiﬁcant
portion of load time, it would seem that increasing resource
loading capacity should help ameliorate long load times. In
TB-8.5 with pipelining, we used 6 simultaneous connections
per server and a pipeline depth of 6 (referred to as 6-6), and
we change both these parameters to produce three more set-
ups with higher resource loading capacity: 6 connections and
20 pipeline depth (6-20), 20 connections and 6 pipeline depth
(20-6), and 20 connections and 20 pipeline depth (20-20). In
comparative experiments, we found that, disappointingly, none
of these parameter changes produced any notable difference in
load time. The mean load time was 16.4 s for 6-6 and 20-6,
16.3 s for 6-20, and 16.5 s for 20-20.3
These results show that further increasing resource loading
capacity on pipelining does not reduce page load time even for
pages with many resources. In other words, pipelining already
gives enough resource loading capacity.
Summary. Head-of-line blocking had little effect on page load
times. We also found that adding to the resource loading ca-
pacity of pipelining by increasing the number of simultaneous
connections and pipeline depth do not affect page load times;
this suggests that pipelining had sufﬁcient resource loading
capacity. However, pipelines often close prematurely for a
large portion of servers.
3 As a sanity check, we conﬁrmed that our parameters do affect the page
load time by testing an intentionally poor setup of 1 connection and 100