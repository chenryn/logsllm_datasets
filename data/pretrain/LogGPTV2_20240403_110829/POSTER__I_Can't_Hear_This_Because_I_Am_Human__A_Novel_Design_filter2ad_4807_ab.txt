Google on Google Chorme. The extracted acoustic features are
converted to audio files via inverse MFCC technique. In our exper-
iments, we used the extracted acoustic features and the inserted
acoustic features to audio file tools [4]. There are 10 MFCC param-
eters and we can modify parameters, when we extract the acoustic
features and insert the features into the audio file. Through this
process, the original audio can be changed from human understand-
able sounds to the machine-only sounds. In addition, it is possible
to generate human-only audio by properly modifying MFCC pa-
rameters in a reverse manner. Carlini et al. [2] generated mangled
sounds using inverse MFCC techniques. With the mangled sound,
the audio sample cannot be recognized by the human but it can be
recognized by the machine.
We also used the inverse MFCC tool [4], and controlled 4 pa-
rameters: wintime, hoptime, numcep and nbands [8]. In particular,
we generated sound samples with two different parameter settings.
The first setting makes the extraction parameter values equal to
the insertion parameter values. For example, when we extracted
acoustic features from input audio, we decided the extraction value
as 20. After the extraction, we also decided to use 20 as the insertion
parameter which is the same to the extraction value. The second
setting is to modify the extraction parameters, while fixing the
insertion parameters as default values. The mangled audio samples
generated by two settings are examined by Deep Speech. The re-
sulting audio samples are manually classified into machine-only,
human-only, or human-and-machine by two of us.
2. Mosaic: Mosaic art is a method of expressing patterns and
pictures by bonding various materials such as stone, glass, etc. We
focused on this concept to make an obfuscated audio sound. Similar
to the mosaic method in art, the process of creating an audio mosaic
is to link segments of sound.
However, unlike the previous study which extracts features from
audio and bonds them by arbitrary criteria, we synthesized seg-
ments of voice in syllable units by hand to generate human-only
audio. We created these by making syllable sound units and then
linking them together. For example, using text-to-speech software
such as Balabolka, we can create “thue” and “ree” with a different
sound. Thereafter, we bond them to generate “three” with audio
editor software (e.g., GoldWave, Adobe Audition, etc.). When creat-
ing mosaic audio, it is necessary to make a good synthesis so that
humans can understand it. Because of the different sound quality
among each syllable, machines would struggle to understand this
mosaic voice, while humans can trivially understand. If we establish
numerical metrics for generating syllables such as Mel-frequency
cepstral coefficients (MFCCs) and mosaic synthesis, we believe that
it will be possible to automate this process in the future.
3. Neural networks: Because neural networks are more fre-
quently used to attack CAPTCHAs, it is possible to exploit weak-
nesses in neural network systems to strengthen audio CAPTCHA
Poster SessionASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea834systems. In recent work, Carlini and Wagner targeted Mozilla’s
Deep Speech implementation with audio-based adversarial attacks [3].
In their method, they were able to optimize their targeted examples
through both MFC pre-processing as well as many rounds of Long
Short-Term Memories (LSTMs) in the Deep Speech architecture us-
ing a Connectionist Temporal Classification loss function [5]. They
achieved 99.9% similar audio waveforms, and they were able to fool
Deep Speech’s pre-trained models with 100% accuracy. Currently,
this method does not transfer to different neural network types,
but we demonstrated a proof-of-concept to detect neural networks
attempting to automatically solve an audio CAPTCHA. In our test,
we used the pre-trained models for Deep Speech that Mozilla re-
leased in combination with Carlini’s method hosted on GitHub6 to
generate adversarial audio. To demonstrate the feasibility of our
approach, we used a clean audio waveform that any human could
easily understand, for example, “one two three four five.” Then, we
applied Carlini’s method to generate an adversarial example against
Deep Speech. Targeted adversarial audio created in this manner
will never confuse a human, but Deep Speech will always return
the obviously incorrect targeted response like “nine eight seven
six five.” Any humans would notice very little differences between
the original and adversarial audio, while an attacker using Deep
Speech’s pre-trained binaries would be easily fooled.
3 EVALUATION AND RESULTS
To show the feasibility and effectiveness of our new audio CAPTCHA
system, we generated 18 human-only sounds, 4 machine-only sounds,
and 20 human-and-machine sounds. Each sound represents a num-
ber between 0 and 99. We produced 50 CAPTCHA sounds in a ran-
dom combination of 1 human-only sound, 1 machine-only sound,
and 3 human-and-machine audible sounds. For usability, silence
was inserted between five numbers in each CAPTCHA challenge.
3.1 User study
In lab experiments, we recruited 10 participants from a univer-
sity. Each participant listened to 5 randomly assigned CAPTCHA
challenges and wrote the answers that they recognized. Before the
experiment, each participant was instructed to control the volume
of headset for listening clearly to CAPTCHA sounds. We notified
the participants that they will hear some numbers, and asked them
to only write down the answers they can clearly recognize. Similar
to current audio CAPTCHAs, participants were allowed to play the
testing sounds multiple times.
Deep Speech was used for evaluating the attack performance. A
CHAPTCHA sound was generated with 5 spoken numbers with
silence between each number. To improve the performance of ma-
chine recognition, Deep Speech results were finally mapped to a
phonetically similar number, similar to the process of unCaptcha [1].
For example, the result “boor” is mapped to “four” and “ix” is
mapped to “six”.
3.2 Results
Human performance: Because one machine-only sound is in-
cluded in a CAPTCHA challenge, all participants except one cor-
rectly answered 4 numbers in all given CAPTCHA challenges. Only
6https://github.com/carlini/audio_adversarial_examples
one participant failed to pass the CAPTCHA test two times. In one
of the failed cases, the participant misheard “53” as “23”. In the other
case, the participant failed to recognize the whole audio sample.
Machine performance: When testing Deep Speech, the system
returned a guess of 5 numbers each time, including the machine-
only audio. In all CAPTCHA test cases, Deep Speech successfully
made a correct result of the machine-only sound. Although we
attempted to handcraft the human-only sound to be understood
only by a human user, Deep Speech recognized 5 cases correctly out
of the 50 CAPTCHA challenges. The machine correctly answered
on average 2.14 numbers for each CAPTCHA test. Excluding the
machine-only sounds, the machine correctly answered only 1.14
numbers of each CAPTCHA test. This is because the sounds are
stretched when we combine the sounds to generate a CAPTCHA
challenge. When we tested each number respectively, Deep Speech
could also correctly answered 4 numbers as similar to the user.
Summary: No participant could answer the machine-only sounds,
while Deep Speech could correctly answer all of them. But a ma-
chine cannot distinguish only machine-understandable sounds to
the other. From our results, we believe that fooling modern speech
recognition systems into outputting a targeted correct answer is
easier than fooling them to an incorrect answer. Using this charac-
teristic, we can distinguish between a machine and a human.
4 CONCLUSION AND FUTURE WORK
We present the novel audio CAPTHCHA system to defend against
the latest machine learning-based attacks. Our preliminary results
show promising results for developing a new type of CAPTCHA
based on the machine’s superiority over humans.
For future work, we plan to generate more sound samples, and
perform evaluations with different deep learning-based speech-to-
text systems to measure the effectiveness of our approach.
ACKNOWLEDGMENTS
This research was supported in part by the MIST (2015-0-00914) and the
ITRC program (IITP-2017-2015-0-00403).
REFERENCES
[1] Kevin Bock, Daven Patel, George Hughey, and Dave Levin. 2017. unCaptcha:
a low-resource defeat of recaptcha’s audio challenge. In USENIX Workshop on
Offensive Technologies (WOOT).
[2] Nicholas Carlini, Pratyush Mishra, Tavish Vaidya, Yuankai Zhang, Micah Sherr,
Clay Shields, David Wagner, and Wenchao Zhou. 2016. Hidden Voice Commands..
In USENIX Security Symposium.
on Speech-to-Text. ArXiv e-prints (Jan. 2018). arXiv:cs.LG/1801.01944
https://labrosa.ee.columbia.edu/matlab/rastamat/. (2015).
[4] D. P. W. Ellis. 2015. PLP and RASTA (and MFCC, and inversion) in Matlab.
[3] N. Carlini and D. Wagner. 2018. Audio Adversarial Examples: Targeted Attacks
[5] Alex Graves, Santiago Fernández, Faustino Gomez, and Jürgen Schmidhuber.
2006. Connectionist temporal classification: labelling unsegmented sequence
data with recurrent neural networks. In Proceedings of the 23rd international
conference on Machine learning. ACM.
[6] Mozilla. 2018. Deep Speech. https://github.com/mozilla/DeepSpeech. (2018).
[7] Jennifer Tam, Jiri Simsa, Sean Hyde, and Luis V Ahn. 2009. Breaking audio
captchas. In Advances in Neural Information Processing Systems. 1625–1632.
[8] Tavish Vaidya, Yuankai Zhang, Micah Sherr, and Clay Shields. 2015. Cocaine
noodles: exploiting the gap between human and machine speech recognition. In
USENIX Workshop on Offensive Technologies (WOOT).
computers apart automatically. Commun. ACM 47, 2 (2004), 56–60.
[9] Luis Von Ahn, Manuel Blum, and John Langford. 2004. Telling humans and
Poster SessionASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea835