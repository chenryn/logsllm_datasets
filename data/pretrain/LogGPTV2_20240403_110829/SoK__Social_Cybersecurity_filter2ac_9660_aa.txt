title:SoK: Social Cybersecurity
author:Yuxi Wu and
W. Keith Edwards and
Sauvik Das
7
5
7
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
2022 IEEE Symposium on Security and Privacy (SP)
SoK: Social Cybersecurity
Yuxi Wu, W. Keith Edwards, Sauvik Das
Georgia Institute of Technology
PI:EMAIL, PI:EMAIL, PI:EMAIL
Abstract—We analyze prior work in social cybersecurity and
present a structuring of this literature based on its pertinence
to four S&P-relevant social behaviors: (1) negotiating access
to shared resources, (2) shared and social authentication, (3)
managing self-presentation, and (4) inﬂuencing others’ S&P
behaviors. We further break down these domains into four
scales of social distance—intimate, personal, social, and public—
showing that desired access control policies, authentication meth-
ods, and privacy and sharing preferences vary across these
social scales. We evaluate the current landscape of work through
the lens of Ackerman’s social-technical gap in social computing
systems, ﬁnding that while social behaviors clearly impact S&P
preferences and needs, existing S&P systems are designed with
little understanding of these behaviors. This mismatch forces
users to choose between implementing their ideal S&P policies or
reducing social friction. To address this mismatch, we outline a
research agenda for social cybersecurity work that better aligns
S&P goals with social needs, preferences and behaviors.
I. INTRODUCTION
Many end-user cybersecurity and privacy (S&P) behaviors
are inherently social: we share information with other people
in our social networks [1], we ask questions of friends and
family about best S&P practices when confused [2], [3], and
we coordinate with and help others to be safe online [4].
Indeed, work in usable S&P has alluded to the existence
of social inﬂuences in S&P behaviors as early as the late
1990s [5]. Yet, most tools aimed at helping end-users improve
their security and privacy have been designed primarily with
individual behaviors in mind. As examples, there has been
a vast amount of work focused on improving the usability of
individual authentication systems [6] and access control policy
interfaces [7] [8], or increasing individual users’ comprehen-
sion of S&P warnings [9].
Due to the increasing interconnectedness of people on the
Internet, there has been a growing interest in studying end-
user S&P beyond the individual actor [10]. These emergent
perspectives—variously called social cybersecurity [11] [12],
socio-technical cybersecurity [13] [14], community oversight
[15] [16], or networked privacy [17]—share a common high-
level goal: to understand S&P behaviors and threats in an
ecosystem of interconnectedness and inﬂuence. Social ap-
proaches to S&P vary in the scales of populations they
consider and how they orient the experience of the individuals
within these populations: from high-level considerations of
how inﬂuence, (mis)information, and other threats propagate
through large social networks, to deeply personalized investi-
gations of the S&P considerations of families, couples, and
households. Across these scales, we see not only different
technical approaches to S&P, but also different deﬁnitions and
theoretical underpinnings across disparate research literature.
In this paper, we synthesize insights from the broad litera-
ture on social cybersecurity, highlighting gaps and proposing
areas for future exploration. We identify four key behavior
domains in the social cybersecurity literature: negotiating
access to shared resources, shared and social authentication,
managing self-presentation, and inﬂuencing others’ S&P be-
haviors. Within these domains, we categorize speciﬁc behav-
iors into four distinct scales of social organization described in
anthropology literature [18]: intimate (e.g., romantic partners),
personal (e.g., families, households, and close friends), social
(e.g., acquaintances, social media friends, coworkers) and the
public (e.g., strangers, advertisers, other institutions).
Much of the literature we explore in this paper covers
empirical studies that have shown how human social dynamics
push against and complicate the use of technical tools intended
to support S&P practices. These studies illustrate the ways
in which users must adapt their social practices to ﬁt the
affordances of these tools, or, alternately, how users are
driven to reappropriate existing technology, using it in new or
“unsanctioned” ways, in order to better support their desired
social behaviors—sometimes reducing S&P against the threats
those technologies are designed to thwart. This distinction
between the needs of social groups, and the support provided
to them by the technology, has been termed by Ackerman the
social-technical gap: the tension between what is achievable
with existing technology, and what is socially-required by the
users of that technology [19].
Many of the challenges of social cybersecurity arise due
to this gap: S&P burdens are foisted upon users who must
improvise their way through social situations—like sharing
digital resources, authenticating social group membership,
controlling self-representation online, and helping others with
S&P problems—with tools that have been designed with
irrespective of social behavior. But the literature also includes
attempts at creating new technical tools designed with the
social practices of their users in mind, and intended to support
or leverage the existing social practices of social groups.
Accordingly, we also suggest a few directions for future social
cybersecurity work.
II. METHODOLOGY AND SCOPING
The fundamental contribution of our work is a taxonimiza-
tion and synthesis of existing work on social cybersecurity.
Our methodology spanned three phases: gathering relevant
© 2022, Yuxi Wu. Under license to IEEE.
DOI 10.1109/SP46214.2022.00050
11863
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:32 UTC from IEEE Xplore.  Restrictions apply. 
prior work, identifying common themes among these papers,
and grouping themes into taxonomically signiﬁcant domains.
We began our search for existing social cybersecurity work
using two index terms on the ACM Digital Library: “human
and societal aspects of security and privacy” and “social as-
pects of security and privacy”. These index terms are typically
self-selected by authors to represent their work; we felt that if
authors believed that there was a signiﬁcant social S&P com-
ponent in their work, they would have self-identiﬁed it as such.
We supplemented these index terms with known keywords
from existing literature, such as “social cybersecurity”, “col-
laboration”, “community”, “privacy”, and “security”. Quickly
realizing that the literature covered disparate social scales and
contexts, we expanded searches on those contexts with new
keywords as they arose (examples include “couples”, “intimate
partner violence”, “family”, “households”, “teenagers”, “social
networks”, and “workplace”. )
We initially scoped collection to prior work from the last
ﬁve years of CCS, CHI, CSCW, IEEE S&P, NDSS, PETS,
SOUPS, TheWebConf, and USENIX Security. Older work and
papers from other venues, e.g., NSPW and UbiComp, that was
highly cited within this list was also included. These searches
resulted in about 1000 articles, many of which fell under the
umbrella of usable security and privacy. We pared this down
to approximately 100 by including only works that included
some element of social coordination or cooperation with end-
user S&P behaviors, asking questions like, “does this work
advance our knowledge of how social groups jointly navigate
S&P decisions, behaviors, threats or tools?”, and “does this
information advance our knowledge of how S&P threats, tools,
or advice affects groups differently than individuals?”.1 Recent
work by Carley et al. [21], termed “social cyber-security”, was
also excluded since we were focused on work that centers end-
users, rather than states, as actors.
From each of the papers gathered, we identiﬁed the core
research question(s), methodology, analysis, and results; re-
search context;
targeted stakeholders; and authors’ recom-
mendations for future work. This data was extracted into
a spreadsheet: one column per characteristic for each paper
row, similar to prior SoKs (e.g., [22]). We then applied a
reﬂexive approach to thematic analysis [23]. One researcher
performed the initial coding, updating the codebook as new
codes and categories emerged. We included the codebook in
the appendix. While we did not formally perform axial coding,
two additional researchers participated in iterative discussions
to organize codes and generate four taxonomically-signiﬁcant
domains, described in more detail in the next section. These
domains are the basis for how we structured and systematized
the extant work on social cybersecurity.
III. SYSTEMATIZATION
In our coding process, we found that prior work in social
cybersecurity tended to focus on speciﬁc user S&P behaviors
1For example, work on sharing passwords with others qualiﬁes as social
cybersecurity, since it involves an element of negotiation and trust in others
to protect secrets, but work on general password usage [20] does not).
that were either enabled or complicated by social interaction.
We identiﬁed four broad behavior domains commonly inves-
tigated across the literature:
• Negotiating access to shared resources includes sharing
media accounts, devices, work ﬁles, physical access to
workspaces, carpools, cars, and homes. These use cases
require trust between sharers, which in turn requires
negotiation of mutual S&P practices. Along with a dearth
of more socially-nuanced access control systems, this
section also includes many password-sharing behaviors,
which can function as coarse-grained access control for
small groups (more on this in Section IV).
• Shared and social authentication includes user reliance
on others to help them authenticate, as well as systems
that facilitate group authentication.