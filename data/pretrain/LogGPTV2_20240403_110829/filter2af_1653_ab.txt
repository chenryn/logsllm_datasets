### 孪生网络模型
基于Bi-LSTM构造的孪生网络的核心方法是计算待检测的目标代码和漏洞模板之间相似度，根据相似度是否超过阈值判定是否存在漏洞。因此，本文的神经网络模型输入为两个数字向量，输出为一个0到1之间的相似度值。如下图所示为神经网络的结构图，它有两个Bi-LSTM层，一个Merge layer（融合层），一个Dense
layer（全连接层）和一个Softmax层，最终使用一个Model进行封装，使得左右两个网络能够共享权值。Bi-LSTM层包含了LSTM神经元，将它们进行前后双向链接，能够前后双向的传播误差，提高算法准确度；融合层会将Bi-LSTM层的两个输出融合成一个张量；全链接层用于减少张量的维度；Softmax层将低维张量作为输入，然后输出一个0到1之间数值，代表了最初两个向量的相似度。相似度越高值接近1，相似度越低值越接近于0。为了适应模型的输入结构，要将训练或测试数据构造成一个元组(X1,X2)。第一维是漏洞模板，第二维是训练或测试数据，分别输入到两个分支网络中。模型使用Adam优化算法以及二元交叉熵（binary_crossentropy）损失函数，其损失值不为负，Adam对其的优化是一个由较高的正值逐渐向0靠近的过程。
## 2.4 系统流程
模型的过程主要分为两个阶段，训练阶段和检测阶段。两个阶段的处理过程是一致的，不过训练阶段的输出是模型，检测阶段的输出是漏洞检测结果。如下图所示（图中代码数据以PHP语言为例）是整个模型结构。
某一类型的漏洞可能存在多个子类型，它表示漏洞多种的利用方式。因此在本文的模型中，每一个漏洞都会存在多个漏洞模板。每个模板代表了某一个漏洞子类型，不同子类型之间的定义差别是非常微小的，因此模板之间的差别也是递进变化的，当一个目标代码与某一个模板相似度较高时，那必然与一定数量的模板都有较高的相似度，而正常代码与漏洞模板在特征的各个维度上是差别很大的。所以，一个目标代码是否存在漏洞要综合计算与所有漏洞模板的相似度均值，有以下公式：  
其中S表示相似度均值，N表示特定类型的漏洞模板数量，BLNN表示Bi-LSTM神经网络，T_i表示某一个具体的模板，P表示待检测的目标代码（本文以PHP为例）。BLNN是的输出是0（不相似）到1（相似）之间的一个值，当整体的相似度均值S超过了设定的阈值就判定存在漏洞，这里的初始阈值本文设定为0.5，用户可以根据使用情况在系统配置中进行修改。
在本文的实验中，漏洞模板本质是确定存在漏洞的字节码切片，每种类型的漏洞会有多个模板。判定是否存在某个类型的漏洞时要和该类型的模板都计算一次相似度，因此这个模型相对于单网络模型是非常耗时的。
# 三、算法实验
实验以P（准确率））、R（召回率）、F1值、假阴率（FNR）和假阳率（FPR）几个指标作为评估依据。实验数据来自美国国家漏洞库的  
[Sard](https://samate.nist.gov/SRD/index.php "Sard")
项目，该项目有大量的漏洞样例，并且每个都标记了CWE编号，也就是漏洞类型。经过统计，一共收集了18989个样本，其中SQL注入漏洞样本912个，XSS漏洞样本4352个，剩下的13725个为不存在漏洞的样本。
根据前面提到的数据处理过程，将采集到的数据转换成数字向量。前面说到我们没有太好的方法从源代码中提取数据流信息，而Sard
的数据某种程度上可以解决这个问题，上面的漏洞case 都是处理过的，每个实例文件基本都是单一的数据流程序，直接使用基本就可以满足我们的预期。一个XSS
漏洞而Sard 数据实例如下所示：
本文根据漏洞类型不同将数据集分成SQL-SET、XSS-SET和MUL-SET三个，MUL-SET是SQL和XSS漏洞数据的混合数据集，以此来检验模型对不同漏洞的区分能力。在SQL-SET数据集中有1032509个token，每一个token代表向量中的一个词，去重之后有182个；在XSS-SET数据中有510252个token，去重之后有168个；MUL-SET是前两者的和。这里的每一个token都是源代码中的一个关键词、变量名或者函数名，当以空格分割后会产生大量的token，但是转换成字节码后许多自定义名称或者程序关键词都被自动编码了，这使得字节码层面的token种类大幅减少。下表展示了三个数据集中字节码切片的统计情况，可以看到每一种类型漏洞数据的无漏洞样本要多于有漏洞的样本，这是数据采集中的正负样本不均衡的现象，会给模型训练带来一定负面影响。本实验会从三个数据集随机抽取10%的数据作为测试集，剩余的作为训练集用于模型训练。
数据集 | 字节码切片 | 漏洞字节码切片 | 无漏洞字节码切片  
---|---|---|---  
SQL-SET | 8904 | 912 | 7992  
XSS-SET | 10085 | 4352 | 5733  
MUL-SET | 18989 | 5264 | 13725  
如下图所示是训过中参数调优的过程，图中重点描述了几个核心参数随着F1值变化而变化的过程，根据参数与F1值的变化关系，综合选定参数值。  
然后使用剩余10%的数据进行测试，下表是测试集的检测结果。
孪生网络模型：
数据集 | P(%) | R(%) | F1(%) | FPR(%) | FNR(%)  
---|---|---|---|---|---  
SQL-SET | 78.04 | 100.0 | 88.04 | 3.13 | 0.00  
XSS-SET | 99.02 | 92.22 | 95.50 | 0.70 | 7.78  
MUL-SET | 85.76 | 97.99 | 91.44 | 6.26 | 2.01  
单网络模型的数据丢失了，没有找到备份，总体上是低于孪生网络模型的。不过若真正在生产环境下使用，孪生网络可行性比较低，主要是因为其检测速度太慢。
# 附 - 模型构造代码
    def gen_model(embedding_matrix, nb_words):
        num_lstm1 = 64
        num_lstm2 = 32
        num_dense = 64
        rate_drop_lstm = 0.1
        rate_drop_dense = 0.1
        """Build the lstm model"""
        embedding_layer = Embedding(nb_words,
                                    EMBEDDING_DIM,
                                    weights=[embedding_matrix],
                                    input_length=MAX_SEQUENCE_LENGTH,
                                    trainable=True)
        # Double bi-directional layer
        lstm_1_layer1 = Bidirectional(LSTM(num_lstm1, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm,return_sequences=True))
        lstm_1_layer2 = Bidirectional(LSTM(num_lstm2, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))
        lstm_2_layer1 = Bidirectional(LSTM(num_lstm1, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm,return_sequences=True))
        lstm_2_layer2 = Bidirectional(LSTM(num_lstm2, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm))
        # The first input data
        input_1 = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')
        embedded_sequences_1 = embedding_layer(input_1)
        sequence_1_input = Masking(mask_value=0, input_shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM))(embedded_sequences_1)
        first_y1 = lstm_1_layer1(sequence_1_input)
        y1 = lstm_1_layer2(first_y1)
        # The second input data
        input_2 = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')
        embedded_sequences_2 = embedding_layer(input_2)
        sequence_2_input = Masking(mask_value=0, input_shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM))(embedded_sequences_2)
        first_y2 = lstm_2_layer1(sequence_2_input)
        y2 = lstm_2_layer2(first_y2)
        # Concatenate layer
        merged = Concatenate(axis = -1)([y1, y2])
        merged = Dropout(rate_drop_dense)(merged)
        merged = BatchNormalization()(merged)
        # Dense layer
        merged = Dense(num_dense, activation='relu')(merged)
        merged = Dropout(rate_drop_dense)(merged)
        merged = BatchNormalization()(merged)
        # Output layer
        preds = Dense(1, activation='sigmoid')(merged)
        original_model = Model(inputs=[input_1, input_2], outputs=preds)
        parallel_model = multi_gpu_model(original_model, GPU)
        parallel_model.compile(loss='binary_crossentropy',
                      optimizer='adam',
                      metrics=[F1])
        return original_model, parallel_model