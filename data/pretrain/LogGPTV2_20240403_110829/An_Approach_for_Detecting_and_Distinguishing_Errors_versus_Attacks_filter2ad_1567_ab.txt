states s4 and s5, respectively.
The procedure presented above uses a set of model states
S = {s1, . . . , sM } to synthetically describe the possible
physical conditions traversed by the environment and by the
error/attack data. The goal of the Model State Identiﬁcation
module is to provide an updated estimate of this set. To cap-
ture natural variations in the model states, the Model State
Identiﬁcation module uses an on-line statistical clustering al-
gorithm. Starting from an initial set of model states So (e.g.,
selected randomly or based on historical data), the module
uses the incoming observation set Oi to update the value of
these states. The goal is to obtain a small set of states that
best represents the (potentially time-varying) distribution of
the incoming data. For each state sk, the module ﬁrst com-
putes the set of observations that are mapped to sk
Pk = {pj ∈ Oi|lj = k}
and then, if Pk is not empty, state sk is updated as follows
(cid:2)
sk = (1 − α)sk +
α
|Pk|
pj
pj ∈Pk
(5)
(6)
where α is a learning factor ranging in the open interval (0, 1).
In the example of Fig. 4, P1 = {p1, p2, p3, p4}, P4 = {p5},
and P5 = {p6}.
From the discussion above, it emerges that the Model State
Identiﬁcation module should not split correct data into a num-
ber of small-size clusters. This can be achieved by merging
two states that are too close to each other (relative to a pre-
deﬁned threshold) into a single state. Similarly, the module
should expand the current set of states when appropriate. This
can be achieved by checking if an observation pj is too far
(relative to a predetermined threshold) from its corresponding
2 and by creating a new state sM +1 = pj accordingly.
state slj
2lj is the state corresponding to pj, as calculated by using Equation 3.
3.2. Environment Modeling through HMMs
The proposed methodology analyzes the structural proper-
ties of two HMMs (see § 2 for an overview of HMMs) es-
timated from the collected data to classify the nature of the
error or attack that affects the system. In a general HMM,
hidden states and observation symbols may be of a differ-
In the methodology discussed in § 3, however,
ent nature.
both hidden states and observation symbols reﬂect the possi-
ble physical states {s1, . . . , sM } of the sensed environment,
which are estimated by the Model States Identiﬁcation mod-
ule in Fig. 1. Also, the proposed methodology considers two
types of HMMs: (1) an HMM MCO that relates sequence
ci (representing the hidden/correct dynamics of the environ-
ment) with sequence oi (representing the observable dynam-
ics of the environment); and (2) an HMM MCEk that relates
sequence ci with an error/attack track ek
i (representing the
dynamics of an erroneous/malicious sensor). Note that hid-
den/correct states of the environment ci are not directly ob-
servable. In the proposed methodology, they are estimated by
a Correct State Identiﬁcation module and are, thus, available
when building the two types of HMMs.
In this context, we can use a simple on-line procedure to
estimate an HMM.3 The proposed procedure operates at the
end of each observation time window and uses the estimate
of the current hidden state of the model (ci) and the current
observation symbol (either oi or ek
i , depending on the consid-
ered HMM). Let j be the current state, i be the state at the
previous time step, and l be the current observation symbol.
Then, at each time t we execute the following steps:
• If j (cid:8)= i, update the state transition distribution: ∀k =
1..M : aik = (1 − β)aik + βδkj.
• Update the observation symbol distribution: ∀k =
1..M : bik = (1 − γ)bik + γδkl.
In the above equations, β and γ are learning factors ranging in
the open interval (0,1), and δij is Kronecker’s delta.4 At ini-
tialization time, matrices A and B can be set equal to identity
3Advanced on-line HMM estimation techniques can be found in [10].
4δij is 1 if i is equal to j, and 0 otherwise.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:25 UTC from IEEE Xplore.  Restrictions apply. 
matrices. It is easy to show that if A and B are probability
distributions, then they remain so when updated with the two
formulas above.
3.3. Error and Attack Models
Sensor nodes can report corrupt data due to environmen-
tal disturbances, accidental errors in the sensor hardware or
software, or malicious attacks, such as an adversary captur-
ing and reprogramming a number of sensor nodes. In order
to initiate a proper recovery action we need to differentiate
between random errors and malicious tampering with the sys-
tem. Strictly speaking, distinguishing errors from attacks is
not always possible, since an adversary can launch an attack
that behaves like an error. In this work, we make an attempt
to answer the following question: “Given a detected network
malfunctioning, can we determine the type of the underlying
condition, accidental or malicious, that most likely caused this
misbehavior?” The proposed approach exploits the notion and
the properties of the HMMs introduced in § 3.2. Before pre-
senting the theoretical and technical details of our error/attack
classiﬁcation methodology, we introduce a formal description
of errors and attacks in sensor networks.
Model for Accidental Errors in Sensor Networks. Sen-
sor devices interact directly with the environment and, hence,
are subjected to a variety of physical, chemical, and biological
forces; this can degrade them fairly quickly. Field studies [1]
indicate that errors originating in degraded sensor devices are
a major cause of unreliability in a wireless sensor network.
Interestingly, these sensor failures are likely to manifest days
before the sensor electronics may fail. Based on these results,
we assume the following sensor fault model:
• Stuck-at-Value Error, a faulty sensor i constantly reports
a ﬁxed reading;
• Calibration Error, a faulty sensor i’s readings are af-
fected by a multiplicative error;
• Additive Error, a faulty sensor i’s readings are affected
by an additive error;
• Random Noise Error, a faulty sensor i’s readings are af-
fected by a zero-mean noise with high variance.
It is possible that the network is affected by an error whose
nature is different from the models above. In that case, we
say that the network is affected by an Unknown Error.
Model for Malicious Attacks in Sensor Networks. An
adversary may be interested in disrupting the communication
infrastructure of the network (e.g., by jamming wireless trans-
mission) or in disrupting/controlling the environmental sens-
ing mechanism of the network (e.g., by tampering with exist-
ing sensors to inject malicious data in the network). In this
work, we focus on the latter type of attack because it is not
easily detectable (e.g., by monitoring the arrival rate of sen-
sor data) and because it directly affects the semantics of the
sensor network. Based on these observations, we assume the
following sensor attack model:
• Dynamic Creation, an adversary is introducing a spuri-
ous behavior in the sensed environment, e.g., while cor-
rect sensors report constant temperature readings, the ad-
versary injects high temperature values so that the over-
all temperature measured by the network moves from the
valid readings and increases substantially;
• Dynamic Deletion, an adversary is removing a valid be-
havior in the sensed environment, e.g., when correct sen-
sors start to report an increase in the environment tem-
perature, the adversary injects low temperature values
so that the overall temperature measured by the network
does not change;
• Dynamic Change, an adversary is modifying the at-
tributes of an environment physical state, e.g., the ad-
versary selectively injects low temperature values so that
each time correct sensors report a 50 value in the envi-
ronment temperature the overall temperature measured
by the network equals 10;
• Mixed, an adversary is mounting a combination of the
attacks described above.
Distinguishing a simple attack (i.e., a Creation, a Deletion,
or a Change attack) from a more complex one (i.e., a Mixed
attack) can reveal valuable insights about the adversary. For
instance, to pass undetected, an adversary may be interested
in deleting environment changes that would otherwise be gen-
erated by a malicious activity that the adversary is inducing
in the environment. Precise knowledge of those changes can
help reveal the nature of the mounted attack.
The aim of our study is to classify attacks that change the
observable behavior of a system; hence, our attack models
focus on such attacks. A benign attack where the attacker
behaves according to correct sensors’ behavior is not a type
of attack we classify using our methodology, for it does not
alter the system behavior in any manner. Similarly, differ-
ent attacks at the network layer, like packet dropping, denial
of service, etc., are not addressed by our approach. Differ-
ent techniques have been developed to tackle network-level
attacks, and the discussion of those techniques is beyond the
scope of our paper.
3.4. Error versus Attack Classiﬁcation
The proposed error/attack classiﬁcation methodology is
portrayed in Fig. 5. To diagnose and classify system Mal-
functioning, we construct two mathematical models that cap-
ture the system’s dynamic behavior, namely an HMM MCO
relating correct environment states to observable environment
states, and an HMM MCE relating correct environment states
to error/attack states. Occurrence of errors and attacks in the
sensor network alter the dynamics of the sensed environment.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:25 UTC from IEEE Xplore.  Restrictions apply. 
Figure 5. Error/Attack classiﬁcation methodology.
These anomalies are reﬂected in anomalies in the two HMMs,
and hence, can be detected by inspecting these models.
To distinguish faults from attacks, we want to exploit the
following intuition: Attacks are generated by an intelligent
entity that knows the underlying dynamics of the environment
and attempts to selectively change the view of the environ-
ment that is sensed by the network. We express this intu-
ition by assuming, as a ﬁrst-order approximation, that “attacks
change the temporal behavior of the environment as sensed
by the network, while errors do not.” (Only Dynamic Change
attacks are not covered by this assumption and require ad-
ditional distinction.) From our perspective, making this as-
sumption corresponds to saying that if we build a Markov
Model MC from the sequence of the correct environment
states ci and a Markov Model MO from the sequence of the
observable environment states oi, then in case of errors the
two models have the same number of states and the same set
of transitions, while they may have different attributes (e.g.,
temperature, humidity) associated with a given state. In the
proposed approach, we do not build and compare such two
Markov Models, but more conveniently, we check whether
the rows and the columns of the observation symbol proba-
bility distribution BCO of the HMM MCO are orthogonal:
∀i, j :
kj = δij. The ﬁrst
equation expresses the condition that if two hidden states are
different, then they generate two different observation sym-
bols. The second equation expresses the condition that if two
observation symbols are different, then they are generated by
two different hidden states. Recall that in our methodology we
deﬁne hidden states of MCO as correct environment states,
and observation symbols of MCO as observable environment
states (see § 3.2). Further classiﬁcation into attack types and
error types requires a more in-depth look at the HMM MCO
for attacks and at the HMM MCE for errors.
(cid:3)
k bco
jk = δij and ∀i, j :
ikbco
kibco
(cid:3)
k bco
Attack Type Determination. To determine the type of a
detected attack, we look at the HMM MCO. Through this
model, we can study the effect of the attack on the observable
state of the environment as a function of the correct states of
the environment. In the absence of errors and attacks, each
correct state of the environment (hidden state of MCO) cor-
responds to a single observable state of the environment (ob-
servation symbol in MCO). The presence of an attack results
in a change of this one-to-one correspondence.
(cid:3)
A Dynamic Creation attack is characterized by a correct
environment state being associated with multiple observable
environment states (say, states i and j). Formally, this corre-
sponds to saying that there are two columns i and j of BCO
that are not orthogonal:∃i, j :
kj (cid:8)= 0. A Dynamic
Deletion attack is characterized by multiple correct environ-
ment states (say, states i and j) being associated with the same
observable environment state. Formally, this corresponds to
saying that there are two rows i and j of BCO that are not
orthogonal: ∃i, j :
jk (cid:8)= 0. If the conditions above
hold at the same time, then we classify a detected attack as a
Mixed attack.
ikbco
kibco
(cid:3)
k bco
k bco
A Dynamic Change attack is characterized by a correct en-
vironment state being associated with a single observable en-
vironment state, and vice versa. The attack does not affect
the orthogonality of rows and columns of BCO, and thus, the
classiﬁcation of this attack is shown on the left-hand side of
Fig. 5. To classify a Dynamic Change attack, we need to look
at the values of the attributes of corresponding correct and ob-
servable states of MCO. In the presence of such an attack, a
correct state sc = (cid:2)xc
n(cid:3) associated with an observable
state so = (cid:2)xo
1, ..., xo
i (cid:8)= xo
i ,
which reﬂects the attackers intention of modifying the physi-
cal attributes of the sensed environment without changing its
temporal behavior.
1, ..., xc
n(cid:3) in MCO is such that ∀i : xc
Error Type Determination. To determine the type of a
detected error, we look at the HMM MCE. Through this
model, we can study the behavior of the error as a func-
tion of the correct state of the environment. Recall that in
our methodology we deﬁne hidden states of MCE as correct
environment states, and observation symbols of MCE as er-
ror/attack states (see § 3.2).
A Stuck-at-Value error is characterized by a faulty sensor
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:25 UTC from IEEE Xplore.  Restrictions apply. 
always reporting the same value, independently of the cor-
rect state of the environment. Thus, all correct environment
states are associated with the same error state. Formally, this
corresponds to saying that the observation symbol probability
distribution BCE of MCE is such that it has one column (k)
that has all ones and other columns of all zeros:
(cid:4)
∃k : ∀i : bce
ij =
1 if
0 if
j = k
j (cid:8)= k
.
(7)
A Calibration error is characterized by a faulty sensor report-
ing an erroneous value that changes accordingly with the cor-
rect state of the environment. Thus, there is a one-to-one map-
ping between correct states and error states. This also holds
true for an Additive error. Formally, this corresponds to say-
ing that the rows and the columns of the observation symbol
probability distribution BCE are orthogonal:
(cid:2)
∀i, j :
(cid:2)
bce
ikbce
jk =
bce
kibce
kj = δij.
(8)
k
k
To further classify between additive and calibration errors,
we need to compute the ratio and the difference between the
attributes of corresponding correct and error/attack states in
MCE. A Calibration error leads to a constant ratio, while
an Additive error leads to a constant difference. Formally,
given a correct state sc = (cid:2)xc
n(cid:3) associated with an er-
1, ..., xc
ror/attack state se = (cid:2)xe
n(cid:3) in MCE, there is a constant
1, ..., xe
K = (cid:2)k1, ..., kn(cid:3) such that ∀i :
= ki for a Calibration
error or ∀i : xc
i = ki for an Additive error. If neither
of the conditions holds, then we check for the presence of a
Dynamic Change attack (described above).
i − xe
xc
i
xe
i
Under the environment estimation problem considered in
this paper (pj = Θ(t) + Nj, see § 3.1), it is difﬁcult to cor-
rectly classify a Random Noise error, as there is no ﬁxed pat-
tern observed in the observation symbol probability distribu-
tion, and the MO and MC estimated are identical. Thus, a
random error can be misclassiﬁed as being in an error-free
system state.
4 Experimental Results and Discussion
The next sections present results from an experimental
study where the proposed methodology is applied to real data
traces collected over one month of observation from 10 motes
(sensor nodes) deployed on the Great Duck Island (GDI) [7].
The GDI testbed consists of around 32 motes, out of which 9
are burrow motes. Our experiments only use the data gathered
by the outside motes. All motes are capable of measuring en-
vironment attributes, such as temperature, humidity, and pres-
sure, and all sample the environment at 5 minute intervals.
Due to the presence of missing and malformed sensor pack-
ets, when applying our methodology the constructed models
may present spurious states. In this initial evaluation, we do
not eliminate such states.
i
]
s
u
s
e
c
[
l
e
r
u
t
a
r
e
p
m
e
T
50
45
40
35
30
25
20
15
10
5
0
9
9.2
9.6
9.4
Time [day]
9.8
10
]
%
[
y
t
i