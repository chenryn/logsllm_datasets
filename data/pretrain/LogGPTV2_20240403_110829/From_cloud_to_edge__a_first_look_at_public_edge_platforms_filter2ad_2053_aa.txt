title:From cloud to edge: a first look at public edge platforms
author:Mengwei Xu and
Zhe Fu and
Xiao Ma and
Li Zhang and
Yanan Li and
Feng Qian and
Shangguang Wang and
Ke Li and
Jingyu Yang and
Xuanzhe Liu
From Cloud to Edge: A First Look at Public Edge Platforms
Mengwei Xu1, Zhe Fu2, Xiao Ma1, Li Zhang1, Yanan Li1, Feng Qian3, Shangguang Wang1, Ke Li4,
Beijing University of Posts and Telecommunications1
Tsinghua University2, University of Minnesota - Twin Cities3
Jingyu Yang4, Xuanzhe Liu5
Unaffiliated4, Peking University5
ABSTRACT
Public edge platforms have drawn increasing attention from both
academia and industry. In this study, we perform a first-of-its-kind
measurement study on a leading public edge platform that has
been densely deployed in China. Based on this measurement, we
quantitatively answer two critical yet unexplored questions. First,
from end users’ perspective, what is the performance of commodity
edge platforms compared to cloud, in terms of the end-to-end net-
work delay, throughput, and the application QoE. Second, from the
edge service provider’s perspective, how are the edge workloads
different from cloud, in terms of their VM subscription, monetary
cost, and resource usage. Our study quantitatively reveals the status
quo of today’s public edge platforms, and provides crucial insights
towards developing and operating future edge services.
CCS CONCEPTS
• Networks → Network measurement; • Computer systems
organization → Grid computing.
KEYWORDS
Measurement Study, Edge Computing, Workloads Analysis
ACM Reference Format:
Mengwei Xu1, Zhe Fu2, Xiao Ma1, Li Zhang1, Yanan Li1, Feng Qian3, Shang-
guang Wang1, Ke Li4, Jingyu Yang4, Xuanzhe Liu5. 2021. From Cloud to
Edge: A First Look at Public Edge Platforms. In ACM Internet Measurement
Conference (IMC ’21), November 2–4, 2021, Virtual Event, USA. ACM, New
York, NY, USA, 17 pages. https://doi.org/10.1145/3487552.3487815
1 INTRODUCTION
By bringing computation and storage closer to end users, edge
computing is expected to benefit a wide range of applications such
as auto-driving, AR/VR, IoTs, and smart cities. Edge computing
can be instantiated by various paradigms such as cloudlet [82]
and MEC [51]. This work targets at public edge platforms (or edge
clouds), which deploy massive yet lightweight datacenters (DCs)
decentralized at different geographical locations and provide hard-
ware resources to third-party customers. Such platforms are increas-
ingly popular, because they inherit the key spirits from commercial
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
IMC ’21, November 2–4, 2021, Virtual Event, USA
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-9129-0/21/11. . . $15.00
https://doi.org/10.1145/3487552.3487815
Plat-
form
AWS
EC2
Google
Cloud
Azure
Edge Zones
AWS Wav-
elength +
Local Zones
Regions /
Coverage
24
6
24
8
Global
U.S.
Global
U.S.
Density
(106mi 2)
0.13
1.58
0.13
2.10
5
U.S.
1.32
14
U.S.
3.70
Plat-
form
MS
Azure
Alibaba
Cloud
Huawei
Cloud
NEP (our
study)
Regions /
Coverage
33
8
23
12
Global
U.S.
Global
China
Density
(106mi 2)
0.17
2.11
0.12
3.23
5
China
1.35
>500
China
>135
Table 1: A comparison of NEP’s deployment with other pop-
ular cloud/edge services. Dated to May. 26, 2021.
cloud computing that has proved its tremendous success in the
past decade. For example, major cloud providers are building their
public edge platforms such as Azure Edge Zone [13] and AWS Local
Zones [11].
Edge platforms offer several major advantages compared to clas-
sic cloud computing, such as much lower network latency, improved
application performance, and potentially reduced operational costs.
Although these benefits are qualitatively known, their quantitative
characteristics in operational environments are far from being com-
prehensively studied. In this paper, we conduct to our knowledge
the first measurement study of a commercial public edge platform in
the wild, from both the end users’ and the edge providers’ perspec-
tives. For the former, we investigate key metrics that are perceivable
by edge customers (who deploy their apps on edges), such as end-
to-end latency, throughput, and application QoE; for the latter, we
take a closer look at the edge workload dynamics. Such a “dual”
approach helps reveal a complete landscape of the edge ecosystem.
Challenges We face several challenges in this study.
First, edge servers are more geographically distributed compared
to traditional cloud servers (Table 1), thus requiring more effort
on conducting measurements at a large number of vantage points.
To this end, we perform a country-wide crowd-sourced study in-
volving 158 participants, who run our custom testing tool on their
mobile devices. We obtained meaningful results from 41 cities in
China over diverse access networks (WiFi/LTE/5G). We also de-
velop two user applications that can benefit from edge computing:
cloud gaming and live video streaming, and deploy them over com-
mercial edge/cloud services. Our own implementations allow us to
instrument the apps and obtain detailed QoE information.
Second, obtaining an insider’s view of operational edge service
providers is difficult. In this study, we collaborate with a commer-
cial, multi-tenant edge service provider, referred to as NEP (Next-
generation Edge Platform1). As a leading edge service provider in
China, NEP has operated for more than 3 years, serving a wide
spectrum of applications used by millions of users. The deployment
scale of NEP is significantly larger than the aforementioned edge
1NEP is commercially known as Alibaba ENS [15].
37
IMC ’21, November 2–4, 2021, Virtual Event, USA
Mengwei Xu et al.
platforms or popular cloud platforms as summarized in Table 1.
We collected detailed usage traces of all Infrastructure-as-a-Service
(IaaS) VMs in NEP’s DCs for three months, and use them to profile
the edge workloads.
Third, ideally we would like to quantitatively compare edge to
cloud in terms of their performance and server workload. Through
active measurements, we compare NEP’s performance with Alibaba
Cloud ECS (AliCloud) [10], a leading cloud provider in China. The
server workload comparison is much more challenging as few cloud
providers release their workload traces. To this end, we compare
our NEP dataset with the Azure cloud dataset [38] collected in 2019
– the only touchable, full cloud workload that we are aware of 2.
We admit that this comparison is not perfectly apples-to-apples as
the Azure data is mainly for the U.S. market and the data collection
period is different. Yet, this is the best we can achieve due to a
lack of publicly available workload traces. We therefore draw our
conclusions in a conservative and cautious manner – only when
we are confident that the disparities we show between the NEP and
Azure datasets are very likely attributed to the inherent differences
between cloud and edge.
Findings We summarize our key findings below.
(1) Network latency (§3.1) is the key metric that edges are ex-
pected to improve. Our crowd-sourced results show that NEP offers
a lower network delay: the median RTTs between users and the
nearest edge DC are 10.5ms/34.2ms/11.7ms for WiFi/LTE/5G net-
works, which are 1.89×/1.42×/1.35× lower than the nearest cloud
DC of AliCloud, respectively. The reduced network jitter is even
more significant (∼5×). However, NEP still cannot (or barely) meet
the requirements of delay-critical applications like cloud VR/AR
(5ms–20ms) [8] and auto-driving (10ms) [7]. This is because the
nearest server of NEP is still 5–12 (median: 8) hops away from
end users, instead of 1–2 hops as commonly envisioned for edge
computing [51, 82]. The network performance of NEP can therefore
be further improved by a denser deployment of DCs and by sinking
DCs into the ISP’s core networks or even cellular base stations.
(2) Network throughput (§3.2) We find that by bringing servers
closer to users, NEP improves network throughput only when the
last-mile bandwidth capacity is high enough, e.g., >200Mbps like
5G downlink. Otherwise, e.g., for WiFi and LTE, the end-to-end
network throughput is bottlenecked by the wireless hop instead of
the Internet; therefore edges exhibit no improvements over remote
clouds. Considering the rare use cases where such high throughput
is demanded by today’s application and its incurred high opera-
tional cost, we believe that throughput is not a primary advantage
of NEP-like edges at this moment. However, this situation may
change in the near future, when 5G shifts the bottleneck from the
last mile to the wired Internet.
(3) Application QoE (§3.3) Through controlled experiments, we
observe that placing the gaming backend on nearby NEP sites can
noticeably improve the response delay compared to remote clouds
(91ms vs. 145ms). To further enhance the QoE, optimizations shall
focus on server-side gaming execution, e.g., through higher CPU
parallelism or hardware acceleration. For live streaming, NEP only
brings modest improvement (up to 24% of streaming latency) and
2§2.2 summarizes the publicly available workload traces and clarifies the reason why
Azure dataset is the only appropriate one for comparison.
the streaming delay remains high (400ms without a jitter buffer).
The reasons are twofold: (i) NEP’s edge resources can effectively
reduce the propagation delay, but not necessarily the transmission
delay; (ii) more importantly, the bottleneck is oftentimes the content
processing/computation rather than the network. Future efforts
should thus focus on improving the hardware capacities (e.g., the
camera’s image signal processor) and the system-software stacks.
(4) Characteristics of NEP’s edge VMs (§4.1) We find that
NEP’s VMs and their incurred workloads are noticeably different
from those of Azure. NEP’s VMs are often equipped with more
resources, including both CPU (median: 8 vs. 1) and memory (me-
dian: 32GBs vs. 4GBs). However, NEP’s resource utilization is much
lower than Azure (6× lower for mean CPU usage), indicating that its
customers may over-provision the hardware resources. We identify
two possible reasons for that: (i) NEP apps are mostly delay-critical
and their usage patterns exhibit high temporal variations, forcing
its customers to reserve more resources to ensure a consistently
good QoE; (ii) it remains difficult for edge customers to forecast the
fluctuating resource demands at different locations. Our findings
suggest that existing resource allocation challenges are amplified
when apps are migrated from clouds [39, 67] to edges.
(5) Resource usage (§4.2) is a critical piece of information that
an edge service provider needs to closely keep track of, and (6)
load balancing (§4.3) facilitates edge services’ SLA by adapting
resource allocation to applications’ needs. We find that for NEP,
its resource usage is highly unbalanced across servers (up to 14×
from the same site), across sites (up to 731× in the same province),
and across the VMs hosting the same app (up to 3×). These ob-
servations indicate possible imperfections of NEP’s VM placement
and selection strategies. We also identify important factors to con-
sider when designing load balancers for NEP-like edge platforms,
including the fluctuating usage patterns, the geo-sensitive resource
demand, and the decoupled VM placement and end-user request
scheduling strategies. Fortunately, our further experiments of (7)
resource prediction (§4.4) show that NEP workloads have stronger
seasonality and are easier to predict as compared to Azure. It of-
fers a good opportunity for more fine-grained, intelligent resource
management.
(8) Monetary cost (§4.5) is a critical dimension of commercial
edge services but is rarely studied by prior literature. We find that
the apps deployed on NEP are mostly bandwidth-hungry, which
often constitutes most of their billing cost. Since data is gener-
ated by nearby users, deploying applications over NEP is indeed
much cheaper compared to AliCloud (recall that both are Chinese
providers) – about 45% of cost reduction on average, and up to
98% for network cost reduction, making it one of the strongest
incentives to move from cloud to NEP. However, we also discover
that two types of apps may not get financial benefits if deployed on
NEP: (i) apps with high hardware demand but low network demand,
as NEP charges slightly higher on hardware resources; (ii) apps
with high temporal network usage variance, as NEP adopts a very
coarse-grained billing model.
Contributions This work presents a first-of-its-kind measurement
study of a major public edge platform in China from both the end
users’ and the edge operators’ perspectives. Our contributions con-
sist of detailed characterizations of the performance, workload, and
billing of the edge platform. Based on our findings, we summarize
38
From Cloud to Edge: A First Look at Public Edge Platforms
IMC ’21, November 2–4, 2021, Virtual Event, USA
(cid:13)(cid:28)(cid:20)(cid:21)(cid:31)(cid:1) (cid:21)(cid:17)(cid:9)(cid:16)(cid:16) (cid:3)(cid:2)(cid:21) (cid:9)(cid:22) (cid:11)(cid:15)(cid:13)(cid:13)(cid:12)(cid:20)(cid:12)(cid:18)(cid:22) (cid:16)(cid:19)(cid:10)(cid:9)(cid:22)(cid:15)(cid:19)(cid:18)(cid:21)
(cid:11)(cid:18)(cid:18)(cid:15) (cid:17)(cid:12)(cid:31)
(cid:10)(cid:20)(cid:22)(cid:21) (cid:9)(cid:29)(cid:29)(cid:31)
(cid:4)(cid:11)(cid:15)(cid:16)(cid:15)(cid:19)(cid:13)(cid:1)(cid:2)