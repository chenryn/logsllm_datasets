title:Crossing the threshold: Detecting network malfeasance via sequential
hypothesis testing
author:Srinivas Krishnan and
Teryl Taylor and
Fabian Monrose and
John McHugh
Crossing the Threshold: 
Detecting Network Malfeasance 
Testing 
Hypothesis 
via Sequential 
Srinivas 
Krishnan, 
Teryl Taylor, Fabian 
Monrose 
John McHugh 
Department 
of Computer Science, 
RedJack 
University 
of North Carolina 
at Chapel Hill 
PI:EMAIL 
{krishnan, 
fabian, 
tptaylor}@cs.unc.edu 
Abstract-The domain name system plays a vital role  in 
the dependability 
and security of modern network.  Unfortu­
nately, it has also been widely misused for nefarious activities. 
Recently, attackers have turned their attention to the  use of 
generated domain names (AGDs) in an effort to 
algorithmically 
circumvent network defenses. 
However, because such domain 
names are increasingly 
this transition 
classify 
highlight the challenges  they 
approaches and demonstrate their limitations. 
these shortcomings 
hypothesis testing that classifies 
AGDs based solely on  the format of  a domain name. To 
by proposing an online form of  sequential 
being  used in benign applications, 
non-existent (NX) responses they  elicit. 
clients based solely on the 
on 
face, we examine contemporary 
Our evaluations 
for techniques that 
has significant 
implications 
We address 
data show that  we outperform existing approaches, 
majority of cases, we  detect  mal ware 
before 
real-world 
and  for  the  vast 
they are able to successfully 
and control centers. 
rendezvous with their command 
would reach out to 250 pseudo-randomly 
[25]. 
To 
The 
millions 
worldwide. 
of computers 
wonn that propa­
in 2008, 
domain per day from eight Top Level Domains 
computer 
Since its discovery 
difficult 
such as conficker and kraken and web­
such as RunForestRun 
are botnets 
based mal ware and trojans 
Conficker is a sophisticated 
gates while fonning a botnet. 
it has remained surprisingly 
to counter because 
of its combined use of advance mal ware techniques. 
date, it has infected 
early variants 
generated 
(TLDs) in an attempt to update itself 
In an unprecedented 
instructions. 
community 
cybersecurity 
computers 
from reaching 
was reverse 
engineered, 
its domain generation 
the cooperation 
The so-called 
and otherwise 
erators, 
thereby 
Unfortunately, 
defensive 
of domains contacted 
to 500 (of 50,000 possibilities) 
Conficker Working Group sought to register 
block domains before the Conf icker op­
organized 
the domains. 
the defenders 
250 
across 116 different 
TLDs. 
act of coordination, 
to block the infected 
with new code or 
the 
the Conficker operators 
pre-registration 
practices 
were able to leverage 
of the appropriate 
computers-from 
them from updating 
to pre-register 
Once the malware 
by increasing 
by the infected 
preventing 
registries 
responded 
to the 
algorithm 
the botnet. 
domains with 
the number 
and authorities. 
Even more problematic 
for defenders, 
algorithmically 
content 
or to perform latency 
networks 
distribution 
for short­
identifiers 
services 
generated 
community 
like Spamhaus and 
domain names (AGD) are now also used for legit­
use algorithmically 
information. 
to provide 
within their networks, 
[6]. Additionally, 
regularly 
generated 
For instance, 
imate purposes. 
(CDNs) use such techniques 
lived objects 
experiments 
Senderbase 
names to query DNS blacklist 
the security 
has largely 
of these legitimate 
so, overlooked 
sance based solely on infonnation 
name. Given that most methods to detect malicious 
mically generated 
compare distributions 
from benign and malicious 
erated domain names used in benign applications 
can have 
a large impact on the accuracy 
of these techniques. 
uses of such domain names, and in doing 
to detect malfea­
gleaned from a domain 
of domain name features 
their effect on the ability 
domain names leverage 
dismissed 
domains, 
techniques 
that 
domain 
extracted 
algorithmically 
algorith­
gen­
Unfortunately, 
the prevalence 
I. INTRODUCTION 
of enterprise  networks 
of yet another compromise 
on computer networks 
would not 
event, and so operators 
choice but to deploy a myriad of network 
are 
and traffic engineering 
solutions, 
to 
of the networks 
they 
However, as networks grow bigger and faster, 
Most administrators 
by the discovery 
difficult. 
increasing 
name servers 
Indeed, attacks 
and stable service 
be surprised 
on their networks. 
are now an all too familiar 
left with little 
monitoring 
devices, 
ensure dependable 
operate. 
staying ahead of this constant  deluge 
becoming 
on enterprise 
that interact 
Name System (DNS). These name servers 
translating 
As a result, 
impact on a network's 
attacks 
(e.g., 
subtle and leverage 
facilitate 
on the latter 
prise name servers 
domain-name 
human readable 
any misuse of this service 
operational 
highlighting 
whereby infected 
algorithms 
an enterprise's 
attempt to exploit 
cache poisoning 
their nefarious 
activities. 
generation 
problem, 
attacks 
domain names to IP addresses. 
can have a significant 
health. 
While some of the 
flaws in the resolution 
[17, 22]), others are more 
to 
process 
DNS infrastructure 
of attack traffic is 
A case in point are the attacks 
with the Domain 
are a critical 
cog, 
In this paper, we focus 
a growing abuse of enter­
clients 
to bypass defenses. 
use automated 
As the name suggests, 
domain-name 
generation 
algo­
rithms are designed 
within the DNS namespace 
collisions. 
to generate 
Examples of mal ware that exhibit 
such behavior 
timeliness 
of detection, 
and scalability 
names that refer 
while minimizing 
to resources 
potential 
We explore 
techniques 
clients 
network and focus on their operational 
impact 
for identifying 
infected 
on 
an enterprise 
in tenns of accuracy, 
978-1-4799-0181-4/13/$31.00 
©2013 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:50:42 UTC from IEEE Xplore.  Restrictions apply. 
domains as "domain flux­
an algorithmica
generated 
by an automated 
lly generated 
of minimizing 
collisions 
domains tend to be relatively 
long pseudo-random 
Consequently, 
algorithmically 
the efficacy of existing 
that rely solely on the structure 
in mal ware 
techniques 
mechanisms 
on traces collected 
(e.g., 
First, 
proposed 
we explore 
techniques 
More specifically, 
detection 
these techniques 
to large networks. 
botnet detection 
of the domain name as a distinguishing 
feature 
identification. 
we implement 
suggested 
in recently 
[31, 32]) and evaluate 
at a large campus network. 
the rise of benign applications 
(e.g., 
in Web browsers 
in CDNs) has on these detection 
that the application 
lead to high false positive 
enhanced 
strategies. 
after extended 
the practical 
with a combination 
Moreover, 
and for location-based 
of these approaches. 
periods-which 
observation 
of smoothing 
successful 
utility 
of state-of-the-art 
detection 
services 
techniques. 
rates, even when classifiers 
are 
and whitelisting 
classification 
directly 
only occurs 
impacts 
prevalent 
We show 
techniques 
for performance 
testing 
of generating 
refer to the process 
ing." In this paper, we consider 
domain as a domain that  is 
process with the key objective 
within the DNS namespace. 
generated 
strings 
domain generator, 
strings 
are used to test whether the configured 
non-existent 
form prefetching 
its location 
bar. 
(NX) responses. 
for example, 
creates 
(each of length ten) upon startup, 
three alpha-character 
and these strings 
DNS server hijacks 
If so, Chrome does not per­
[13] of search terms that are entered 
into 
We also examine the impact that 
derived from some global seed. Google Chrome's 
is based on sequential 
to detect and model domains involved 
A recent method for identifying 
malicious 
traffic is to 
and reputation-based 
[1, 2, 4, 9]). Most of these 
about the domain 
reputation 
systems 
domains (with short lifetimes) 
attackers 
have turned to 
to 
As this cat and mouse game 
generated 
As DNS-based 
information 
of historical 
these blacklists. 
more timely blacklist 
take advantage 
name being requested. 
have been more widely deployed, 
algorithmically 
circumvent 
has continued, 
systems have emerged (e.g., 
proposals 
TTL-based 
cious activity. 
based features 
Antonakakis 
of the fact that for high availability, 
botnets 
several 
can therefore 
the underlying 
domains to an IP address 
that are time-based, 
use features 
Additionally, 
of DNS data are also used. For instance, 
both 
zone-, and evidence­
network-, 
et al. [2] and Yadav et al. [32] take advantage 
use the web of domains and IPs to uncover 
used by the botnet. 
network infrastructure 
answer-based, 
or 
in mali­
tend to map 
(or vice-versa).  Defenders 
In particular, 
internal 
that elicit 
noticeable 
the fact that  a 
client machines 
of NX responses 
(NX) responses. 
to evade blacklisting 
of a bot's 
a wider 
side-effect 
to have 
is its tendency 
across DNS zones (compared 
we propose an approach 
tend to generate 
DNS 
Our technique 
(popularized 
by lung et al. [15]) to 
In 
as benign or infected. 
the 
between benign and malicious 
DNS 
to 
approach 
these shortcomings, 
the fact that botnets 
non-existent 
To address 
that exploits 
queries 
we leverage 
attempts 
dispersion 
to benign hosts). 
hypothesis 
testing 
classify 
doing so, we address some key challenges, 
need to differentiate 
queries 
scale to high traffic loads. We show that our 
both of these challenges. 
Furthermore, 
characteristics 
of our approach 
NX traffic (and using novel filtering 
techniques), 
the overall 
to larger networks. 
DNS traffic during analysis. 
load on  a security 
cognitive 
on the hosts flagged as suspicious), 
analysis 
approach 
to cluster 
the output of our detector. 
By contrast, 
Lastly, 
analyst 
and the ability 
meets 
one of the unique 
high accuracy 
on  a fraction 
4%) which allows us to scale 
approaches 
use all 
in an effort to reduce the 
we can achieve 
DNS traffic (e.g., 
from the same client, 
is that by focusing 
(performing 
originating 
including 
we provide 
existing 
solely on 
a forensic 
an 
of 
and domain collapsing 
The rest of the paper is organized 
as follows. 
First, 
in 
of algorithmically 
generated 
work. §III 
related 
and summarizes 
of existing 
evaluation 
the background 
infrastructure 
§II, we explore 
domain names and discuss pertinent 
covers our data collection 
the data used in our evaluation. 
detailed 
name features 
our technique 
archived 
security 
clients 
insights on 
network in §VII, and conclude 
data in §VI. To reduce the cognitive 
analysts, 
flagged by our technique. 
and their shortcomings. 
in §V, followed 
by a detailed 
of our technique 
the deployment 
we also provide 
techniques 
a technique 
in §vm. 
evaluation 
on 
load on  a 
In §IV we provide a 
using domain 
We then introduce 
for visualizing 
We provide operational 
on our campus 
II. BACKGROUND AND RELATED WORK 
Unfortunately, 
the term algorithmically 
do­
Antonakakis 
main has been used in differing 
describe 
literature. 
pseudo-random 
domain 
AGD as an "automatically 
name" created 
by a botnet using a domain generation 
algo­
rithm (DGA), whereas other authors [4, 5, 24, 32] simply 
et al. [3], for example, 
generated 
contexts 
an 
generated 
in the existing 
or thousands 
Other auxiliary 
More recent work [3, 14, 
of random domain names 
information 
use the fact that domains are registered 
can also be used. Hao et al. 
their command and control 
[11], for example, 
"just in time" before an attack. 
27, 31, 32] focuses on the fact that bots tend to generate 
lookups to hundreds 
when locating 
Reddy [31] rely on the burstiness 
as  the entropy of domain name character 
classify 
five-step 
on client-level 
network-level 
et al. [14] cluster 
failed DNS queries 
subclusters  with 
specific, 
By contrast, 
approach 
structural 
information 
of NX responses 
to 
distributions 
et al. [3] use a 
that clusters 
information, 
and attempt 
malicious, 
bot clients. 
clustering 
to identify 
patterns. 
to better classify 
NX domains based 
Antonakakis 
presumably 
AGDs. liang 
and then incorporates 
server. 
Yadav and 
as well 
Unlike the aforementioned 
works, we do not rely on 
techniques 
or clustering 
bots. 
on the NX traffic patterns 
domain structure 
Rather, we focus entirely 
individual 
and can accurately 
unique domain names than prior work. Furthermore, 
thereby enabling 
utilize 
realtime 
analysis 
of all DNS traffic observed. 
NX traffic exclusively, 
by using only a fraction 
our approach 
bots upon seeing far fewer 
hosts. As a result, 
identify 
to identify 
of 
we 
is lightweight, 
The application 
of sequential 
hypothesis 
tests [28] in 
context is by no means new. lung et al. [15], 
proposed 
a threshold 
random walk (TRW) 