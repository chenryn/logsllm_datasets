title:Mimicry attacks on host-based intrusion detection systems
author:David A. Wagner and
Paolo Soto
Mimicry Attacks on Host-Based Intrusion Detection
Systems(cid:3)
David Wagner
University of California, Berkeley
PI:EMAIL
Paolo Soto
University of California, Berkeley
PI:EMAIL
ABSTRACT
We examine several host-based anomaly detection systems
and study their security against evasion attacks. First, we
introduce the notion of a mimicry attack, which allows a so-
phisticated attacker to cloak their intrusion to avoid detec-
tion by the IDS. Then, we develop a theoretical framework
for evaluating the security of an IDS against mimicry at-
tacks. We show how to break the security of one published
IDS with these methods, and we experimentally con(cid:12)rm the
power of mimicry attacks by giving a worked example of an
attack on a concrete IDS implementation. We conclude with
a call for further research on intrusion detection from both
attacker’s and defender’s viewpoints.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection
Keywords
Host-based intrusion detection, anomaly detection, evasion
attacks
General Terms
Security
1.
INTRODUCTION
The goal of an intrusion detection system (IDS) is like
that of a watchful burglar alarm: if an attacker manages to
penetrate somehow our security perimeter, the IDS should
set o(cid:11) alarms so that a system administrator may take ap-
propriate action. Of course, attackers will not necessarily
cooperate with us in this. Just as cat burglars use stealth
to escape without being noticed, so too we can expect that
computer hackers may take steps to hide their presence and
try to evade detection. Hence if an IDS is to be useful, it
(cid:3)This research was supported in part by NSF CAREER
CCR-0093337.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’02, November 18–22, 2002, Washington, DC, USA.
Copyright 2002 ACM 1-58113-612-9/02/0011 ...$5.00.
would be a good idea to make it di(cid:14)cult for attackers to
cause harm without being detected. In this paper, we study
the ability of IDS’s to reliably detect stealthy attackers who
are trying to avoid notice.
The fundamental challenge is that attackers adapt in re-
sponse to the defensive measures we deploy. It is not enough
to design a system that can withstand those attacks that are
common at the time the system is deployed. Rather, secu-
rity is like a game of chess: one must anticipate all moves the
attacker might make and ensure that the system will remain
secure against all the attacker’s possible responses. Conse-
quently, an IDS that is susceptible to evasion attacks (where
the attacker can cloak their attack to evade detection) is of
uncertain utility over the long term: we can expect that if
such an IDS sees widespread deployment, then attackers will
change their behavior to routinely evade it. Since in practice
many attacks arise from automated scripts, script writers
may someday incorporate techniques designed to evade the
popular IDS’s in their scripts. In this sense, the very suc-
cess of an approach for intrusion detection may lead to its
own downfall, if the approach is not secure against evasion
attacks.
Broadly speaking, there are two kinds of intrusion de-
tection systems: network intrusion detection systems, and
host-based intrusion detection systems. Several researchers
have previously identi(cid:12)ed a number of evasion attacks on
network intrusion detection systems [19, 18, 7, 1]. Moti-
vated by those results, in this paper we turn our attention
to host-based intrusion detection.
Though there has been a good deal of research on the se-
curity of network IDS’s against evasion attacks, the security
of host-based intrusion detection systems against evasion at-
tacks seems not to have received much attention in the se-
curity literature. One can (cid:12)nd many papers proposing new
techniques for intrusion detection, and authors often try to
measure their detection power by testing whether they can
detect currently-popular attacks. However, the notion of se-
curity against adaptive adversarial attacks is much harder
to measure, and apart from some recent work [23, 24], this
subject does not seem to have received a great deal of cov-
erage in the literature. To remedy this shortcoming, in this
paper we undertake a systematic study of the issue.
Host-based intrusion detection systems can be further di-
vided into two categories:
signature-based schemes (i.e.,
misuse detection) and anomaly detection. Signature-based
schemes are typically trivial to bypass simply by varying
the attack slightly, much in the same way that polymor-
phic viruses evade virus checkers. We show in Section 4.2
255how to automatically create many equivalent variants of a
given attack, and this could be used by an attacker to avoid
matching the IDS’s signature of an attack. This is an un-
avoidable weakness of misuse detection. Evasion attacks on
signature-based schemes are child’s play, and so we do not
consider them further in this paper.
Anomaly detection systems are more interesting from the
point of view of evasion attacks, and in this paper we focus
speci(cid:12)cally on anomaly detection systems. We show in Sec-
tion 3 several general evasion methods, including the notion
of a mimicry attack and the idea of introducing \semantic
no-ops" in the middle of the attack to throw the IDS o(cid:11).
Next, in Section 4, we introduce a principled framework for
(cid:12)nding mimicry attacks, building on ideas from language
and automata theory. We argue in Section 4.2 that nearly
every system call can be used as a \no-op," giving the at-
tacker great freedom in constructing an attack that will not
trigger any intrusion alarms. Sections 5 and 6 describe our
empirical experience in using mimicry attacks to escape de-
tection: we convert an o(cid:11)-the-shelf exploit script into one
that works without being detected by the pH IDS. Finally,
in Sections 8 and 9 we conclude with a few parting thoughts
on countermeasures and implications.
For expository purposes, this paper is written from the
point of view of an attacker. Nonetheless, our goal is not
to empower computer criminals, but rather to explore the
limits of current intrusion detection technology and to en-
able development of more robust intrusion detection sys-
tems. The cryptographic community has bene(cid:12)tted tremen-
dously from a combination of research on both attacks and
defenses|for instance, it is now accepted wisdom that one
must (cid:12)rst become expert in codebreaking if one wants to
be successful at codemaking, and many cryptosystems are
validated according to their ability to stand up to concerted
adversarial analysis|yet the intrusion detection community
has not to date had the bene(cid:12)t of this style of adversarial
scholarship. We hope that our work will help to jump-start
such a dialogue in the intrusion detection research literature.
2. A TYPICAL HOST-BASED IDS
There have been many proposals for how to do host-based
anomaly detection, but a paradigmatic (and seminal) exam-
ple is the general approach of Forrest, et al.
[3, 2, 8, 26,
21]. We will brie(cid:13)y review their scheme. They monitor the
behavior of applications on the host by observing the inter-
action of those applications with the underlying operating
system. In practice, security-relevant interactions typically
take the form of system calls, and so their scheme works
by examining the trace of system calls performed by each
application.
Their scheme is motivated by using the human immune
system as a biological analogy. If the system call traces of
normal applications are self-similar, then we can attempt to
build an IDS that learns the normal behavior of applications
and recognizes possible attacks by looking for abnormalities.
In the learning phase of this sort of scheme, the IDS gath-
ers system call traces from times when the system is not
under attack, extracts all subtraces containing six consecu-
tive system calls, and creates a database of these observed
subtraces1. A subtrace is deemed anomalous if it does not
1In practice, pH uses lookahead pairs to reduce the size of
the database. This only increases the set of system call
appear in this database. Then, in the monitoring phase,
the abnormality of a new system call trace is measured by
counting how many anomalous subtraces it contains.
The authors’ experience is that attacks often appear as
radically abnormal traces. For instance,
imagine a mail
client that is under attack by a script that exploits a bu(cid:11)er
overrun, adds a backdoor to the password (cid:12)le, and spawns a
new shell listening on port 80. In this case, the system call
trace will probably contain a segment looking something like
this:
open(), write(), close(), socket(), bind(), listen(),
accept(), read(), fork().
Since it seems unlikely that the mail client would normally
open a (cid:12)le, bind to a network socket, and fork a child in im-
mediate succession, the above sequence would likely contain
several anomalous subtraces, and thus this attack would be
easily detected.
We selected Somayaji and Forrest’s pH intrusion detec-
tion system [21] for detailed analysis, mainly because it was
the only system where full source code could be obtained
for analysis. Many other proposals for host-based anomaly
detection may be found in the literature [3, 2, 8, 26, 21, 5,
14, 15, 4, 26, 12, 13, 17, 27]. However, pH is fairly typical,
in the sense that many host-based IDS’s rely on recognizing
attacks based on the traces they produce, be it traces of sys-
tem calls, BSM audit events, or Unix commands. We will
use pH as a motivating example throughout the paper, but
we expect that our techniques will apply more generally to
host-based intrusion detection systems based on detecting
anomalies in sequences of events. For instance, it should be
possible to use our approach to analyze systems based on
system call sequences [3, 2, 8, 26, 5, 27], data mining [14,
15], neural networks [4], (cid:12)nite automata [17], hidden Markov
models [26], and pattern matching in behavioral sequences
[12, 13].
3. BUILDING BLOCKS FOR EVASION
Background. First, let us start with a few assumptions to
simplify the analysis to follow. It seems natural to assume
that the attacker knows how the IDS works. This seems
unavoidable: If the IDS becomes popular and is deployed at
many sites, it will be extremely di(cid:14)cult to prevent the source
code to the IDS from leaking. As usual, security through
obscurity is rarely a very reliable defense, and it seems nat-
ural to assume that the IDS algorithm will be available for
inspection and study by attackers.
Similarly, if the IDS relies on a database of normal behav-
ior, typically it will be straightforward for the attacker to
predict some approximation to this database. The behav-
ior of most system software depends primarily on the op-
erating system version and con(cid:12)guration details, and when
these variables are held constant, the normal databases pro-
duced on di(cid:11)erent machines should be quite similar. Hence,
an attacker could readily obtain a useful approximation to
the database on the target host by examining the normal
databases found on several other hosts of the same type, re-
taining only program behaviors common to all those other
databases, and using the result as our prediction of the nor-
mal database on the target host. Since in our attacks the
traces allowed by pH.
256attacker needs only an under-approximation to the normal
database in use, this should su(cid:14)ce. Hence, it seems rea-
sonable to assume that the database of normal behaviors is
mostly (or entirely) known.
Moreover, we also assume that the attacker can silently
take control of the application without being detected. This
assumption is not always satis(cid:12)ed, but for many common
attack vectors, the actual penetration leaves no trace in the
system call trace. For instance, exploiting a bu(cid:11)er over-
run vulnerability involves only a change in the control (cid:13)ow
of the program, but does not itself cause any system calls
to be invoked, and thus no syscall-based IDS can detect
the bu(cid:11)er overrun itself. In general, attacks can be divided
into a penetration phase (when the attacker takes control of
the application and injects remote code) and a exploitation
phase (when the attacker exploits his control of the appli-
cation to bring harm to the rest of the system by executing
the recently-injected foreign code), and most anomaly de-
tection systems are based on detecting the harmful e(cid:11)ects
of the exploitation, not on detecting the penetration itself.
Consequently, it seems reasonable to believe that many ap-
plications may contain vulnerabilities that allow attackers
to secretly gain control of the application.
With that background, the remainder of this section de-
scribes six simple ideas for avoiding detection, in order of
increasing sophistication and power. We presume that the
attacker has a malicious sequence of actions that will cause
harm and that he wants to have executed; his goal is to
execute this sequence without being detected.
Slip under the radar. Our (cid:12)rst evasion technique is based
on trying to avoid causing any change whatsoever in the ob-
servable behavior of the application. A simple observation
is that system call-based IDS’s can only detect attacks by
their signature in the system call trace of the application.
If it is possible to cause harm to the system without issu-
ing any system calls, then the IDS has no hope of detecting
such an attack. For instance, on some old versions of So-
laris it was possible to become root simply by triggering the
divide-by-zero trap handler, and this does not involve any
system calls. However, such OS vulnerabilities appear to
be exceptionally rare. As a more general instance of this
attack class, an attacker can usually cause the application
to compute incorrect results. For instance, a compromised
web browser might invisibly elide all headlines mentioning
the Democratic party whenever the user visits any news site,
or a compromised mailer might silently change the word \is"
to \isn’t" in every third email from the company’s CEO.
There seems to be little that an IDS can do about this
class of attacks. Fortunately, the harm that an attacker can
do to the rest of the system without executing any system
calls appears to be limited.
Be patient. A second technique for evading detection is
simply to be patient: wait passively for a time when the
malicious sequence will be accepted by the IDS as normal
behavior, and then pause the application and insert the ma-
licious sequence. Of course, the attacker can readily recog-
nize when the sequence will be allowed simply by simulating
the behavior of the IDS. Simulating the IDS should be easy,
since by our discussion above there are no secrets in the IDS
algorithm.
Moreover, it is straightforward for the attacker to retain
control while allowing the application to execute its usual se-
quence of system calls. For instance, the attacker who takes
control of an application could embed a Trojan horse by re-
placing all the library functions in the application’s address
space by modi(cid:12)ed code. The replacement implementation
might behave just like the pre-existing library code, except
that before returning to its caller each function could check
whether the time is right to begin executing the malicious
sequence. After this modi(cid:12)cation is completed, the attacker
could return the (cid:13)ow of program control to the application,
con(cid:12)dent in the knowledge that he will retain the power to
regain control at any time. There are many ways to accom-
plish this sort of parasitic infection, and there seems to be
no defense against such an invasion.
There is one substantial constraint on the attacker, though.
This attack assumes that there will come a time when the
malicious sequence will be accepted;
if not, the attacker
gains nothing. Thus, the power of this attack is limited
by the precision of the database of normal behavior.
Another limitation on the attacker is that, after the mali-