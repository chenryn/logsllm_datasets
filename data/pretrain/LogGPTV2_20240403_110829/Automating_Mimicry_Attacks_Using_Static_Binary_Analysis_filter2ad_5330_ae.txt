25:  int main(int argc, char **argv)
...
26:      if (check_pw(uid, passwd)) {
27:          fgets(cmd, sizeof(cmd), f);
28:          if (enable_logging)  
29:              do_log(uid);
30:          setuid(0);
31:          if (execl(cmd, cmd, 0) cmd_id
p->uid
Stack
struct cmd_entry 
pointed to by p
Figure 12: Successful return address overwrite via p.
The discussion above underlines that even if a pointer as-
signment is found, it is not always clear whether this as-
signment can be used to overwrite a return address. For
this example, our symbolic execution engine discovered a
possibility to overwrite the return address of do log().
This is achieved by preparing a conﬁguration in which
the cmds variable points directly to the return address of
do log(). After the content of cmds is assigned to p,
p→uid is compared to the uid parameter on line 13.
Because of the structure of the cmd entry record, this
comparison always evaluates to true. To see why this
is the case, refer to Figure 12. The ﬁgure shows that
when p points to the function’s return address, p→uid
points to the location that is directly “above” this ad-
dress in memory. Because of the x86 procedure calling
convention, this happens to be the ﬁrst argument of the
In other words, p→uid and the
do log() function.
parameter uid refer to the same memory location, there-
fore, the comparison has to evaluate to true. As before,
for a successful overwrite, it is necessary to set the value
of cmd id to t and enable auditing by assigning 1 to
enable logging.
Without the automatic process of symbolic execution,
such an opportunity to overwrite the return address is
probably very difﬁcult to spot. Also, note that no knowl-
edge about the x86 procedure calling convention is en-
coded in the symbolic execution engine. The possibility
to overwrite the return address, as previously discussed,
is found directly by (symbolically) executing the machine
instructions of the binary. If the compiler had arranged
the ﬁelds of the cmd entry structure differently, or if a
different calling convention was in use, this exploit would
not have been found.
For the second experiment, we used our symbolic execu-
tion tool on three well-known applications: apache2,
the netkit ftpd server, and imapd from the Univer-
sity of Washington. The purpose of this experiment was
to analyze the chances of an attacker to recover control
ﬂow in real-world programs. To this end, we randomly se-
lected one hundred addresses for each program that were
evenly distributed over the code sections of the analyzed
binaries. From each address, we started the symbolic ex-
ecution processes. The aim was to determine whether it is
possible to ﬁnd a conﬁguration and a sequence of instruc-
tions such that control ﬂow can be diverted to an arbitrary
address. In the case of a real attack, malicious code could
be placed at this address. Note that all applications were
dynamically linked (which is the default on modern Unix
machines).
Program
Instr.
Success
apache2
ftpd
imapd
51,862
9,127
133,427
83
93
88
Failed
Return Exhaust
5
0
1
12
7
11
Table 1: Symbolic execution results for real-world appli-
cations.
Table 1 summarizes the results for this experiment. For
each program, the number of code instructions (column
“Instr.”) are given. In addition, the table lists the number
of test cases for which our program successfully found a
conﬁguration (column “Success”) and the number of test
cases for which such a conﬁguration could not be found
(column “Failed”).
In all successful test cases, only a few memory locations
had to be modiﬁed to obtain a valid conﬁguration. In fact,
in most cases, only a single memory location (a function
address in the PLT) was changed. The code that is neces-
sary to perform these modiﬁcations is in the order of 100
174
14th USENIX Security Symposium
USENIX Association
bytes and can be easily injected remotely by an attacker
in most cases.
A closer examination of the failed test cases revealed that
a signiﬁcant fraction of these cases occurred when the
symbolic execution thread reached the end of the func-
tion where the start address is located (column “Return”).
In fact, in several cases, symbolic execution terminated
immediately because the randomly chosen start address
happened to be a ret instruction. Although the symbolic
execution engine simulates the run-time stack, and thus
can perform function calls and corresponding return op-
erations, a return without a previous function call cannot
be handled without additional information. The reason is
that whenever a symbolic execution thread makes a func-
tion call, the return address is pushed on the stack and
can be used later by the corresponding return operation.
However, if symbolic execution begins in the middle of a
function, when this initial function completes, the return
address is unknown and the thread terminates.
When an intruder is launching an actual attack, she usu-
ally possesses additional information that can be made
available to the analysis process. In particular, possible
function return addresses can be extracted from the pro-
gram’s call graph or by examining (debugging) a running
instance of the victim process. If this information is pro-
vided, the symbolic evaluation process can continue at the
given addresses. Therefore, the remaining test cases (col-
umn “Exhaust”) are of more interest. These test instances
failed because the symbolic execution process could not
identify a possibility to recover control ﬂow. We set a
limit of 1,000 execution steps for each thread. After that,
a thread is considered to have exhausted the search space
and it is stopped. The reason for this limit is twofold.
First, we want to force the analysis to terminate. Second,
when the step limit is reached, many memory locations
and registers already contain unknown values.
Our results indicate that only a small amount of test cases
failed because the analysis engine was not able to identify
appropriate conﬁgurations. This supports the claim that
our proposed evasion techniques can be successfully used
against real-world applications.
Program
apache2
ftpd
imapd
24
7
46
Steps
Avg. Max. Min.
0
0
0
131
62
650
Time
(in seconds)
12.4
0.3
1.2
Table 2: Execution steps and time to ﬁnd conﬁgurations.
Table 2 provides more details on the number of steps re-
quired to successfully ﬁnd a conﬁguration. In this table,
the average, maximum, and minimum number of steps
are given for the successful threads. The results show
that, in most cases, a conﬁguration is found quickly, al-
though there are a few outliers (for example, 650 steps for
one imapd test case). Note that all programs contained
at least one case for which the analysis was immediately
successful.
In these cases, the random start instruction
was usually an indirect jump or indirect call that could be
easily redirected.
The table also lists the time in seconds that the symbolic
execution engine needed to completely check all hundred
start addresses (successful and failed cases combined)
for each program. The run time for each individual test
case varies signiﬁcantly, depending on the amount of con-
straints that are generated and the branching factor of the
program. When a program contains many branches, the
symbolic execution process has to follow many different
threads of execution, which can generate an exponential
path explosion in the worst case. In general, however, the
run time is not a primary concern for this tool and the re-
sults demonstrate that the system operates efﬁciently on
real-world input programs.
6 Conclusions
In this paper, we have presented novel techniques to evade
two well-known intrusion detection systems [4, 14] that
monitor system calls. Our techniques are based on the
idea that application control ﬂow can be redirected to ma-
licious code after the intruder has passed control to the
application to make a system call. Control is regained
by modifying the process environment (data, heap, and
stack segment) so that the program eventually follows an
invalid code pointer (a function return address or an indi-
rect control transfer operation). To this end, we have de-
veloped a static analysis tool for x86 binaries, which uses
symbolic execution. This tool automatically identiﬁes in-
structions that can be used to redirect control ﬂow. In ad-
dition, the necessary modiﬁcation to the environment are
computed and appropriate code is generated. Using our
system, we were able to successfully exploit three sam-
ple programs, evading state-of-the-art system call moni-
tors. In addition, we applied our tool to three real-world
programs to demonstrate the general applicability of our
techniques.
The static analysis mechanisms that we developed for this
paper could be used for a broader range of binary anal-
ysis problems in the future. One possible application is
the identiﬁcation of conﬁgurations for which the current
function’s return address is overwritten. This might allow
USENIX Association
14th USENIX Security Symposium
175
us to build a tool that can identify buffer overﬂow vulnera-
bilities in executable code. Another application domain is
the search for viruses. Since malicious code is usually not
available as source code, binary analysis is a promising
approach to deal with this problem. In addition, we hope
that our work has brought to attention the intrinsic prob-
lem of defense mechanisms that allow attackers a large
amount of freedom in their actions.
Acknowledgments
This research was supported by the National Sci-
ence Foundation under grants CCR-0209065 and CCR-
0238492.
References
[1] R. Bagnara, E. Ricci, E. Zaffanella, and P. M. Hill.
Possibly not closed convex polyhedra and the Parma
Polyhedra Library. In 9th International Symposium
on Static Analysis, 2002.
[2] P. Cousot and R. Cousot. Abstract Interpretation:
A Uniﬁed Lattice Model for Static Analysis of Pro-
grams by Construction or Approximation of Fix-
points. In 4th ACM Symposium on Principles of Pro-
gramming Languages (POPL), 1977.
[3] H. Feng, J. Gifﬁn, Y. Huang, S. Jha, W. Lee, and
B. Miller. Formalizing sensitivity in static analysis
for intrusion detection. In IEEE Symposium on Se-
curity and Privacy, 2004.
[4] H. Feng, O. Kolesnikov, P. Fogla, W. Lee, and
W. Gong. Anomaly detection using call stack in-
formation. In IEEE Symposium on Security and Pri-
vacy, 2003.
[5] S. Forrest. A Sense of Self for UNIX Processes. In
IEEE Symposium on Security and Privacy, 1996.
[6] D. Gao, M. Reiter, and D. Song. Gray-Box Extrac-
tion of Execution Graphs for Anomaly Detection. In
11th ACM Conference on Computer and Communi-
cation Security (CCS), 2004.
[7] D. Gao, M. Reiter, and D. Song. On Gray-Box
Program Tracking for Anomaly Detection. In 13th
Usenix Security Symposium, 2004.
[8] J. Gifﬁn, S. Jha, and B. Miller. Detecting Manipu-
lated Remote Call Streams. In 11th Usenix Security
Symposium, 2002.
[9] J. Gifﬁn, S. Jha, and B.P. Miller. Efﬁcient context-
sensitive intrusion detection. In 11th Network and
Distributed System Security Symposium (NDSS),
2004.
[10] J. King. Symbolic Execution and Program Testing.
Communications of the ACM, 19(7), 1976.
[11] L. Lam and T. Chiueh. Automatic Extraction of Ac-
curate Application-Speciﬁc Sandboxing Policy. In
Symposium on Recent Advances in Intrusion Detec-
tion (RAID), 2004.
[12] T. Lengauer and R. Tarjan. A Fast Algorithm for
Finding Dominators in a Flowgraph. ACM Trans-
actions on Programming Languages and Systems,
1(1), 1979.
[13] F. Nielson, H. Nielson, and C. Hankin. Principles of
Program Analysis. Springer Verlag, 1999.
[14] R. Sekar, M. Bendre, D. Dhurjati, and P. Bolli-
neni. A fast automaton-based method for detecting
anomalous program behaviors. In IEEE Symposium
on Security and Privacy, 2001.
[15] K. Tan, K. Killourhy, and R. Maxion. Undermining
an Anomaly-Based Intrusion Detection System Us-
ing Common Exploits. In 5th Symposium on Recent
Advances in Intrusion Detection (RAID), 2002.
[16] D. Wagner and D. Dean.
Intrusion Detection via
Static Analysis. In IEEE Symposium on Security and
Privacy, 2001.
[17] D. Wagner and P. Soto. Mimicry Attacks on Host-
Based Intrusion Detection Systems.
In 9th ACM
Conference on Computer and Communications Se-
curity (CCS), 2002.
[18] C. Warrender, S. Forrest, and B.A. Pearlmutter. De-
tecting intrusions using system calls: Alternative
data models. In IEEE Symposium on Security and
Privacy, 1999.
[19] A. Wespi, M. Dacier, and H. Debar. Intrusion De-
tection Using Variable-Length Audit Trail Patterns.
In Recent Advances in Intrusion Detrection (RAID),
2000.
[20] H. Xu, W. Du, and S. Chapin. Context Sensitive
Anomaly Monitoring of Process Control Flow to
Detect Mimicry Attacks and Impossible Paths.
In
Symposium on Recent Advances in Intrusion Detec-
tion (RAID), 2004.
176
14th USENIX Security Symposium
USENIX Association