able keyboards or mice that enable programmable en-
crypted communication. However, myriad wireless key-
boards do implement encrypted communication with their
host adapter (e.g., encrypted Bluetooth packets are de-
crypted in the Bluetooth adapter’s ﬁrmware, and not in
software). Thus, the problem is not technical, but rather
a reﬂection of the market’s condition. Indeed, Microsoft’s
NGSCB was originally architected to depend on USB key-
boards capable of encryption [8,23]. In our system, we have
developed a USB Interposer using a low-power system-on-
a-chip. Our USB Interposer supports a USB keyboard and
mouse and manages encryption for use with Bumpy.
We have implemented Bumpy using an HP dc5750 with
an AMD Athlon64 X2 at 2.2 GHz and a Broadcom v1.2
TPM as the user’s computer, with a USB-powered Bea-
gleBoard [4] containing a 600 MHz ARM CPU running
embedded Linux serving as the USB Interposer. We use
a Nokia E51 smartphone running Symbian OS v9.2 as the
Trusted Monitor. Our USB Interposer supports encryption
of all keyboard events, and mouse click events. Mouse
movement events (i.e., X and Y delta information) are not
encrypted, since only mouse clicks trigger blur events in
the web browser GUI.
8.1 Bumpy Components
Only a formal user study can ascertain the level of risk
associated with this kind of attack, which we plan to pursue
in future work.
Our implementation includes the PreP and two PoPrs
that run with Flicker’s protections on the user’s computer,
the USB Interposer (BeagleBoard), the Trusted Monitor
running on a smartphone, and an untrusted web browser
extension and Perl script. We begin by describing the com-
ponents that are in Bumpy’s TCB, and then treat the addi-
tional untrusted components that are required for availabil-
ity (which we are forced to surrender since we consider the
OS as untrusted).
PreP and PoPrs. We implemented the PreP as a Piece
of Application Logic that runs with the protection of the
Flicker system [18] and (1) receives encrypted keystroke
events from the encrypting input device (i.e.,
the USB
Interposer), (2) invokes one of our PoPrs to process the
encrypted keystrokes for the webserver, either by re-
encrypting them or performing the PwdHash [25] opera-
tion on passwords, and (3) sends encrypted messages to the
Trusted Monitor that provide the favicon and domain of the
active web page and PoPr. In our implementation, the PreP
and both PoPrs are all part of the same PAL that runs using
Flicker. An input parameter controls which PoPr is active.
USB Interposer. Our USB Interposer is built using a
BeagleBoard featuring an OMAP3530 processor imple-
menting the ARM Cortex-A8 instruction set [4], and a Pro-
liﬁc PL-25A1 USB-to-USB bridge [24]. We currently run
embedded Debian Linux to beneﬁt from the Linux kernel’s
mature support for both USB host and client operation.
While this adds considerable code-size to our TCB, the in-
terposer executes in relative isolation with a very speciﬁc
purpose. We implement a small Linux application that re-
ceives all keyboard and mouse events (using the kernel’s
evdev interface), and encrypts all keyboard and mouse
click events, letting mouse movement information pass in
the clear. We describe the cryptographic protocol details in
Section 8.2.
(a) Protection enabled visiting
SunTrust bank.
(b) Protection disabled.
Figure 4. Screenshots of the Trusted Monitor.
Trusted Monitor. We implemented a Symbian C++ ap-
plication that runs on the Nokia E51 smartphone and serves
as the Trusted Monitor. The Trusted Monitor updates its
display in response to authenticated messages from the
PreP, as described in Section 6. Figure 4 shows screen shots
of the Trusted Monitor in action. When a session is active
between the Trusted Monitor and PreP, the Trusted Moni-
tor displays the domain name and favicon of the active web
page’s PoPr. It also displays a green keyboard (Figure 4(a))
as a uniﬁed indicator that protections are enabled. When
input protections are disabled, it displays a warning mes-
sage that input is unprotected and that @@ should be used
for sensitive input (Figure 4(b)). The Trusted Monitor uses
distinctive beeps whenever input protections transition be-
tween enabled and disabled.
Note that after the initial conﬁguration of the Trusted
Monitor and PreP (Section 8.2), no further conﬁguration is
necessary during subsequent input sessions. The long-term
symmetric keys encrypted under the master key that is kept
in PCR-protected TPM NV-RAM will only be accessible to
the correct PreP. Thus, only the PreP will be able to send
authentic messages to the Trusted Monitor.
Untrusted Components. We developed an untrusted
Firefox Browser Extension that communicates a web page’s
SSL certiﬁcate and embedded PoPr, and all focus events to
the PreP. An untrusted Perl script facilitates communication
between all components, manages the invocation of Flicker
sessions, injects decrypted keystrokes into the OS using the
Linux kernel’s Uinput driver, and provides TPM Quotes in
response to attestation requests. Note that the Flicker archi-
tecture provides the property that the code requesting the
attestation from the TPM chip need not be trusted [18]. To
convey encrypted data from the PreP to the USB Interposer,
Trusted Monitor, or browser extension, the PreP must exit
and release the ciphertext to the Perl script.
8.2 Secure Communication with the PreP
Both the USB Interposer and the Trusted Monitor re-
quire the ability to exchange secret,
integrity-protected
messages with the PreP. We implement the Flicker external
communication protocol for both, with a trust-on-ﬁrst-use
model for accepting the respective public keys created in
the PreP. Neither the USB Interposer nor the Trusted Mon-
itor is pre-conﬁgured with knowledge of the identity of the
TPM in the user’s computer or the identity of the PreP in-
stalled on the user’s computer.
We program a dedicated button on the USB Interposer
to bootstrap association with a PreP, whereas the Trusted
Monitor exposes a menu option to the user to connect to her
computer to perform the initial conﬁguration. The USB In-
terposer communicates with the user’s computer via USB,
and we use the AT&T 3G cellular network or WiFi to con-
nect the Trusted Monitor to the user’s computer using a
standard TCP/IP connection. An untrusted Perl script run-
ning on the user’s computer handles reception of these mes-
sages and invokes Flicker sessions with the PreP so that the
messages can be processed.
Both the USB Interposer and Trusted Monitor send a re-
quest to initiate an association with the PreP, passing in
the command to bootstrap Flicker’s external communica-
tion protocol [19], as well as a nonce for the subsequent
attestation. The PreP then uses TPM-provided random-
ness to generate a 1024-bit RSA keypair.
In accordance
with Flicker’s external communication protocol, the PreP
extends PCR 17 with the measurement of its newly gener-
ated public key. The public key is then output from the PreP
to be sent to the Trusted Monitor, and PCR 17 is capped
(extended with a random value) to indicate the end of the
Flicker session. At this point, PCR 17 on the user’s com-
puter contains an immutable record of the PreP executed
and public key generated during execution.
8.2.1 PreP Authentication
Our use of a trust-on-ﬁrst-use model to accept the PreP’s
public key dictates that no further veriﬁcation of the ex-
changed keys is necessary. However, rigorous security
goals may require the USB Interposer or Trusted Moni-
tor to verify that the user’s computer is running an ap-
proved PreP. In our current prototype, the USB Interposer
and Trusted Monitor request a TPM attestation from the
user’s computer to ascertain the machine’s public Attesta-
tion Identity Key (AIK) that it uses to sign attestations (TPM
Quotes [34]), and the measurement (SHA-1 hash) of the
PreP that will process input events. On subsequent connec-
tions, any change in the AIK or PreP measurement is an
error. This way, it is readily extensible to allow application
vendors to distribute signed lists of expected measurements,
to leverage a PKI, or to a community-driven system simi-
lar in spirit to that of Wendlandt et al. (Perspectives [35]),
and thus enable the USB Interposer and Trusted Monitor to
validate the identity of the PreP themselves.
The USB Interposer and Trusted Monitor include a
nonce with their initial connection requests, and expect
a response that includes a TPM Quote over the nonce
and PCR 17. The measurements extended into PCR 175
are expected to be the measurement of the PreP it-
self, the command to bootstrap external communication
(ExtCommCmd), and the measurement of the public RSA
key produced by the PreP:
PCR17 ← SHA1(SHA1(SHA1(0160||SHA1(PreP))
||SHA1(ExtCommCmd))||SHA1(PubKey)).
The USB Interposer and Trusted Monitor perform the
same hash operations themselves using the measurement of
5This example is speciﬁc to an AMD system. The measurements ex-
tended by Intel systems are similar.
the PreP, value of ExtCommCmd, and hash of the received
public key. They then verify that the resulting hash matches
the value of PCR 17 included in the TPM Quote.
8.2.2 Symmetric Key Generation for Communication
with the PreP
We bootstrap secret and integrity-protected communica-
tion between the PreP and the USB Interposer or Trusted
Monitor using the PreP’s relevant public key to establish
a shared master key KM1 . Separate symmetric encryption
and MAC keys are derived for each direction of commu-
nication. We use AES with 128-bit keys in cipher-block
chaining mode (AES-CBC) and HMAC-SHA-1 to protect
the secrecy and integrity of all subsequent communication
between the Trusted Monitor and the PreP. These keys form
a part of the long-term state maintained by both endpoints.
Kaes1 ← HMAC-SHA1(KM1 ,‘aes128.1’)128
Khmac1 ← HMAC-SHA1(KM1 ,‘hmac-sha1.1’)
Kaes2 ← HMAC-SHA1(KM1 ,‘aes128.2’)128
Khmac2 ← HMAC-SHA1(KM1 ,‘hmac-sha1.2’)
8.2.3 Long-Term State Protection
The PreP must protect its state from the untrusted legacy
OS while Flicker is not active. To facilitate this, the PreP
generates a 20-byte master key KM2 using TPM-provided
randomness. This master key is kept in PCR-protected
non-volatile RAM (NV-RAM) on the TPM chip itself. We
choose TPM NV-RAM instead of TPM Sealed Storage be-
cause of a signiﬁcant performance advantage. The PCR 17
value required for access to the master key is that which is
populated by the execution of the PreP using Flicker:
PCR17 ← SHA1(0160||SHA1(PreP)).
Flicker ensures that no code other than the precise PreP
that created the master key will be able to access it [19]. Our
PreP uses AES-CBC and HMAC-SHA-1 to protect the se-
crecy and integrity of the PreP’s state while the (untrusted)
legacy OS runs and stores the ciphertext. The necessary
keys are derived as follows:
Kaes ← HMAC-SHA1(KM2 ,‘aes128’)128,
Khmac ← HMAC-SHA1(KM2 ,‘hmac-sha1’).
This is sufﬁcient to detect malicious changes to the saved
state and to protect the state’s secrecy. However, a counter
is still needed to protect the freshness of the state and pre-
vent roll-back or replay attacks. The TPM does include a
monotonic counter facility [34], but it is only required to
support updating once every ﬁve seconds. This is insufﬁ-
cient to keep up with user input. Instead, we leverage the se-
quence numbers used to order encrypted input events com-
ing from the USB Interposer. The PreP is constructed such
that a sequence number error causes the PreP to fall back
to a challenge-response protocol with the USB Interposer,
where the PreP ensures that it is receiving fresh events from
the USB Interposer and reinitializes its sequence numbers.
Any sensitive input events that have been enqueued when a
sequence number error takes place are discarded. Note that
this should only happen when the system is under attack.
The USB Interposer and Trusted Monitor run on devices
with ample non-volatile storage available.
8.3 The Life of a Keystroke
Here, we detail the path taken by keystrokes for a sin-
gle sensitive web form ﬁeld. It may be useful to refer back
to Figures 2 and 3. At this point, symmetric cryptographic
keys are established for bidirectional, secret, authenticated
PreP-USB Interposer and PreP-Trusted Monitor communi-
cation. We now detail the process that handles keystroke
events as the user provides input to a web page.
The user begins by directing focus to the relevant ﬁeld,
e.g., via a click of the mouse. On a well-behaved system,
our browser extension initiates a Flicker session with the
PreP, providing the name of the ﬁeld, and the webserver’s
SSL certiﬁcate, PoPr (which includes the encryption key
certiﬁcate Cert ws enc), nonce, and favicon as arguments.
The PreP veriﬁes the SSL certiﬁcate using its CA list and
veriﬁes that the PoPr, nonce, and favicon are signed by the
same SSL certiﬁcate. The user then types @@ to indicate
that the following input should be regarded as sensitive.
The user’s keystrokes travel from the keyboard to the USB
Interposer, where they are encrypted for the PreP, and trans-
mitted to the Perl script on the user’s computer (Steps 1–3
in Figure 2). The script then initiates other Flicker sessions
with the PreP, this time providing the encrypted keystrokes
as input (Step 4 in Figure 2). The PreP decrypts these
keystrokes and recognizes @@ (Figure 3) as the sequence
to indicate the start of sensitive input. The PreP outputs
the @ characters in plaintext and prepares a message for the
Trusted Monitor to indicate the domain name and favicon
of the current website and PoPr. The Trusted Monitor re-
ceives this message, beeps, and updates its display with the
domain name and favicon.
Subsequent keystrokes are added to a buffer maintained
as part of the PreP’s long-term state. Dummy keystrokes
(asterisks) are output for delivery to the legacy operating
system (Step 5 in Figure 2) using the Uinput facility of the
Linux kernel (which is also used when cleartext mouse and
keyboard input events need to be injected). This enables
the browser to maintain the same operational semantics and
avoid unnecessary user confusion (e.g., by fewer asterisks
appearing than characters that she has typed).
In the common case (after the long-term cryptographic
keys are established), TPM-related overhead for one
keystroke is limited to the TPM extend operations to initi-
ate the Flicker session, and a 20-byte read from NV-RAM to
obtain the master key protecting the sealed state. All other
cryptographic operations are symmetric and performed by
the main CPU. Section 9 offers a performance analysis.
When the user ﬁnishes entering sensitive input into a
particular ﬁeld, she switches the focus to another ﬁeld. The
PreP catches the relevant input event (a Blur in Figure 3) on
the input stream, and prepares the sensitive input for hand-
off to the PoPr (Step 6 in Figure 2). We have implemented
two PoPrs: encryption directly to the webserver, and Pwd-
Hash [25]. The PreP will then receive a focus event from the
browser, indicating that focus has moved to another ﬁeld.
Note that form submission is a non-sensitive input event, so
no special handling is required.
Encryption for Webserver. A widely useful PoPr en-
crypts the sensitive input for the remote webserver exactly
as entered by the user (Steps 6–8 in Figure 2). This is ac-
complished using a public encryption key that is certiﬁed
by the webserver’s private SSL key. We use RSA encryp-
tion with PKCS#1v15 padding [15] to encrypt symmetric
AES-CBC and HMAC-SHA-1 keys, which are used to en-
crypt and MAC the actual input with its corresponding ﬁeld
tags. The public encryption key is embedded in the PoPr.
Post-Processing as PwdHash. Another useful PoPr per-
forms a site-speciﬁc transformation of data before submis-
sion to the webserver. We have implemented the Pwd-
Hash [25] algorithm in our PoPr. When this PoPr is active,
the remote webserver need not be aware that Bumpy is in
use, since the hashed password is output to the web browser
as if it were the user’s typed input. The PoPr manages the