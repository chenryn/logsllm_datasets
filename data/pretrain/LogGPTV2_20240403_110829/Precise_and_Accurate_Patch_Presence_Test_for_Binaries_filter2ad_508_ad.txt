the
operations and operands in the AST, with some
necessary
is
commutative, the order of the operands will not matter).
We also simplify the AST with a Z3 solver [11] before
comparison.
recursively match
relaxations
formulas
operator
process
simply
(e.g.,
the
if
5
Implementation
We implement the prototype of FIBER with 5,097 LOC
in Python on top of Angr [29], as it has a robust
symbolic
semantic
execution engine
to generate
formulas. To suit our needs, we also changed the
internals of Angr (including 1348 LOC addition and 89
LOC deletion). Below are some implementation details.
Architectural dependencies. As mentioned, FIBER
in principle supports any architecture as we can compile
the source code into binaries for any architecture.
Further, since we use Angr which lifts the binaries into
an intermediate language VEX (which abstracts away
instruction set architecture differences), most of our
system works ﬂawlessly without the need of tailoring
for architectural speciﬁcs. This not only allows FIBER
to be (for the most part) architectural independent, but
also facilitates the implementation. For instance, when
searching for root instructions, the data ﬂow analysis is
some small
performed on top of VEX. However,
needed
engineering
for
multi-architectural
to deal with
different calling conventions. At current stage FIBER
supports aarch64.
are
support,
such as
efforts
still
Root instruction annotation. To generate semantic
formulas for root instruction operands, it is necessary to
analyze all the binary code from the function entrance to
the root instruction. We choose symbolic execution as
our analyze method since it can cover all possible
execution paths and obtain the value expression of any
register and memory location at an arbitrary point along
the path.
Symbolic execution is well known for
the path
explosion problem, which makes it expensive and not as
practical. We employ multiple optimizations to address
the performance issue as detailed below.
(1) Path pruning.
Before starting the symbolic
execution we will ﬁrst perform a depth ﬁrst search
(DFS) in the function CFG to ﬁnd all paths from the
function entrance to the root instructions. We will then
put only the basic blocks contained in these paths in the
execution whitelist, all other basic blocks will be
dropped by the symbolic execution engine. Besides, we
also limit the loop unrolling times to 2 to further reduce
the number of paths.
(2) Under-constrained symbolic execution.
As
proposed previously [28], under-constrained symbolic
execution can process an individual function without
worrying about its calling contexts, effectively conﬁning
the path space within the single function. Although the
input to the function (e.g., parameters) is un-constrained
at the beginning, it will not affect the extraction of the
semantic formulas since they do not need such initial
constraints. Un-constrained inputs may also lead the
execution engine to include infeasible paths in real
world execution, however, our goal
for semantic
formulas is to make them comparable between reference
and target binaries, as long as we use the same
procedure for both sides, the extracted formulas can still
896    27th USENIX Security Symposium
USENIX Association
in
the
generate
formulas
that make
(3) Symbolic
be compared for the purpose of patch presence test. In
the end, we use intra-function symbolic execution, i.e.,
without following the callees (their return values will be
made un-constrained as well), which in practice can
already
root
instructions unique and stable.
execution
veritesting mode.
Veritesting [7] is a technique that
integrates static
symbolic execution into dynamic symbolic execution to
improve its efﬁciency. Dynamic symbolic execution is
path-based, a same basic block belonging to multiple
paths will be executed for multiple times, greatly
increasing the overhead especially when there is a large
number of paths. Static symbolic execution executes
each basic block only once, but its formulas will be
more complicated since it needs to carry different
constraints of all paths that can reach current node.
However, FIBER does not need to actually solve the
formulas,
it only needs to compare these
formulas extracted from reference and target binaries,
thus, the formula complexity matters less for us. Note
that this means an operand may sometimes have more
than one formulas: consider when the true and false
branch of a if statement merges. When we regard a
binary signature as matched in the target, we require
that the computed formulas in the target contain all of
the formulas in the signature (could be a superset). If at
least one formula is missing, we consider
the
corresponding source code in the target to have missed
certain important code that contributes to the signature.
instead,
6 Evaluation
In this section, we systematically evaluate FIBER for its
effectiveness and efﬁciency.
Dataset. We choose Android kernels as our evaluation
dataset. This is because Android is not only popular but
also fragmented with many development branches
maintained by different vendors such as Samsung and
Huawei [25]. Although Google has open-sourced its
Android kernels and maintained a frequently-undated
security bulletin [1], other Android vendors may not
port the security patches to their own kernels timely.
Besides, even though required by open source license,
many vendors choose not to open source their kernels or
make it extremely inconvenient (with substantial delays
and only periodic releases). This makes Android kernels
an ideal
two kinds of dataset
speciﬁcally:
target. We collect
(1) Reference kernel
source code and security
patches. We choose the open-source “angler” Android
kernel (v3.10) used by Google’s Nexus 6P as our
reference. We then crawl the Android security bulletin
from June 2016 to May 2017 and collect all published
vulnerabilities related security patches6 for which we
can locate the affected function(s) in the reference
kernel image (e.g., it may use a different driver than the
one gets patched, or the affected function itself may be
inlined). We also exclude one special patch that changes
only a variable type in its declaration, requiring type
inference at the binary level to handle, which we don’t
support currently as mentioned in §4.2.2.
In total we
collected 107 security patches that are applicable to our
reference kernel.
(2) Target Android kernel images and source code.
Besides the reference kernel, we also collect 8 Android
kernel images from 3 different mainstream vendors with
different timestamps and versions as listed in table 2.
Note that vendors publish way more binary images
(sometimes once every month) than the source code
packages. We only evaluate the binary images for which
we can ﬁnd the corresponding source code, which
serves only as ground truth of the patch presence test.
All our evaluations are performed on a server with In-
tel Xeon E5-2640 v2 CPU and 64 GB memory.
6.1 Experiment Procedure
To test patch presence in the target binary, we follow the
steps below:
Reference binary preparation. As shown in Fig 2,
we ﬁrst need to compile the reference source code to
binary, based on which we will generate the binary
signatures. The availability of source code enables us to
freely choose compilers, their options, and the target
architecture.
Naturally, we should choose the
compilation conﬁguration that is closest to the one used
for target binary, which can maximize the accuracy. To
probe the compilation conﬁguration used for the target
binary, we ﬁrst compile multiple reference binaries with
all combinations of common compilers (we use gcc and
clang) and optimization levels (we use levels O1 - O3
and Os7), then use BinDiff [2] to test the similarity of
each reference binary and the target binary, the most
similar reference binary will ﬁnally be used for binary
signature generation. Following this procedure (which
is yet to be automated), we observed in our evaluation
that kernel 6 and 7 as shown in table 2 use gcc with O2
optimization level, while all other 6 kernels use gcc with
Os optimization level, which is conﬁrmed by our
inspection
compilation
conﬁgurations (e.g., Makeﬁle).
source
code
Ofﬂine signature generation and validation. For
each security patch, we retain at most three binary
the
of
6Some security patches are not made publicly available on the
Android Security Bulletin.
7Optimize for size.
USENIX Association
27th USENIX Security Symposium    897
Device No. Patch Build Date Kernel
Accuracy
Online Matching Time (s)
Samsung
S7
LG
G5
Huawei
P9
0
1
2
3
4
5
6
7
Cnt* (mm/dd/yy) Version TP
42
102
43
102
85
102
102
92
32
103
95
103
10
31
30
25
06/24/16
09/09/16
01/03/17
05/18/17
05/27/16
10/26/17
02/22/16
05/22/17
3.18.20
3.18.20
3.18.31
3.18.31
3.18.20
3.18.31
3.10.90
4.1.18
TN FP
0
56
0
55
0
11
4
0
0
65
0
0
0
20
2
0
FN
4(3.92%)
4(3.92%)
6(5.88%)
6(5.88%)
6(5.88%)
8(7.77%)
1(3.23%)
3(10.00%)
Total
1690.43
1888.06
2421.44
1770.66
2122.37
1384.47
390.35
515.64
Avg
16.57
18.51
23.74
17.36
20.61
13.44
12.59
17.19
∼70%
8.47
8.24
5.49
5.33
8.90
4.76
8.47
7.4
Max.
306.47
438.76
1047.10
386.94
648.93
229.46
89.35
279.49
* Some patches we collected are not applicable for certain test subject kernels.
Table 2: Binary Patch Presence Test: Accuracy and Online Matching Performance
signatures, after testing their uniqueness by matching
them against both patched and un-patched reference
kernel images. If nothing is unique, we will add more
contexts to existing non-unique signatures.
Online matching. Given a speciﬁc security patch, we
will try to match all its binary signatures in the target
kernels. Note that all Android kernel
images are
compiled with symbol tables. We therefore can easily
locate the affected functions. As long as one signature
can be matched with a match count no less than that in
reference patched kernel, we will say the patch exists in
the target. As a performance optimization, we will ﬁrst
match the “fastest-to-match” signature.
6.2 Accuracy
We list the patch presence test results for target Android
kernel images in table 2.
It is worth noting that our
patch collection is oriented to “angler” kernel, which
will run on the Qualcomm hardware platform, while
kernel 6 and 7 intend to run on a different platform (i.e.,
Kirin), thus many device driver related patches do not
apply for kernel 6 and 7 (we cannot even locate the
same affected functions).
Overall, our accuracy is excellent. There are no false
positives (FP) across the board and very few false
negatives (FN). In patch presence test, we assume that
all patches are not applied by default. It has to be proven
otherwise.
In practice, FP may lead developers to
wrongly believe that a patch has been applied while in
reality not (a serious security risk). In contrast, FN only
costs some extra time for analysts to realize that the
code is actually patched (or perhaps unaffected due to
other reasons) while we say it is not. Thus, we believe
FN is more tolerable than FP. Since we have no FP, we
manually inspect each FN case to analyze the root
causes:
(1) Function inline. Function inline behaviors may
vary across different compilers and binaries. A same
function may be inlined in some binaries but not others,
or inlined in different ways. Some of our signatures
(e.g., the signature for CVE-2016-8463) model inline
function calls based on the reference kernel image, if the
target kernel has a different
inline behavior, our
signatures will fail to match. To address this problem,
we need to generate binary signatures based on a
collection of different kernel images to anticipate such
behaviors.
(2) Function prototype change.
Although rare,
sometimes the function prototype will change across
different kernel images. Speciﬁcally, the number and
order of the function parameters may vary. As discussed
in §4.3.1, we will differentiate the parameter order, thus,
if a same parameter has different orders in reference and
target kernels, the match will fail. We have one such
case (CVE-2014-9893) in the evaluation. To solve this
problem, we can extend our current implementation
with techniques such as parameter proﬁling (see §4.3.1).
(3) Code customization. As discussed in §4.2, extra
contexts are necessary if original patch change site is
not unique. However, the contexts may be different
across various kernel images due to code customization,
although the patch change site remains the same. If this
happens, our signature (with contexts extracted from the
reference kernel) will not match, although the target
kernel image has been patched. We encountered such a
case in Samsung kernels for CVE-2015-8942. Such
customizations are generally hard to anticipate and it
will likely still cause a FN even if the source code of the
target is given. This is why we prefer not to add
contexts.
If we can use more ﬁne-grained binary
analysis such as parameter and local variable proﬁling,
we may be able to avoid using contexts.
(4) Patch adaptation. A patch may need to be adapted
for kernels maintained by different vendors since the
vulnerable functions are not always exactly the same
across different kernel branches. Adaptation can also
happen when a patch is back-ported to an older kernel
version. In our evaluation, we ﬁnd that this happens in
some target