title:GreenFlag: Protecting 3D-Racetrack Memory from Shift Errors
author:Georgios Mappouras and
Alireza Vahid and
A. Robert Calderbank and
Daniel J. Sorin
2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)
GreenFlag: Protecting 3D-Racetrack Memory 
from Shift Errors 
Georgios Mappouras 
Electrical & Computer 
Engineering 
Duke University 
Durham, USA 
PI:EMAIL 
Alireza Vahid 
Electrical Engineering 
University of Colorado Denver 
Denver, USA 
PI:EMAIL 
Abstract—Racetrack  memory 
is  an  exciting  emerging 
memory  technology  with  the  potential  to  offer  far  greater 
capacity  and  performance  than  other  non-volatile  memories. 
Racetrack memory has an unusual error model, though, which 
precludes the use of the typical error coding techniques used by 
architects.  In  this  paper,  we  introduce  GreenFlag,  a  coding 
scheme  that  combines  a  new  construction  for  Varshamov-
Tenegolts  codes  with  specially  crafted  delimiter  bits  that  are 
placed  between  each  codeword.  GreenFlag  is  the  first  coding 
scheme  that  is  compatible  with  3D  racetrack,  which  has  the 
benefit  of  very  high  density  but  the  limitation  of  a  single 
read/write  port  per  track.  Based  on  our  implementation  of 
encoding/decoding hardware, we analyze the trade-offs between 
latency, code length, and code rate; we then use this analysis to 
evaluate the viability of racetrack at each level of the memory 
hierarchy. 
Keywords—Racetrack  Memory;  Coding;  Fault  Tolerance; 
Shift Errors 
I.  INTRODUCTION 
Many new non-volatile memory technologies are vying to 
replace conventional memory technologies—such as SRAM, 
DRAM, and Flash—and racetrack memory [1, 2, 3] has the 
potential to provide the best storage density and performance 
of any of these contenders. In Table I, we compare racetrack 
memory to two of the other emerging non-volatile memories 
as well as to SRAM. Competing technologies, such as phase 
change memory (PCM) and magneto-resistive random-access 
memory (MRAM), are at a disadvantage in terms of density 
and performance [4, 5, 6, 7, 8, 9, 10]. SRAM is somewhat 
faster than racetrack memory, but it is volatile and two orders 
of  magnitude  less  dense.  These  quantitative  advantages—
combined  with  racetrack’s  compatibility  with  standard 
fabrication processes and promising results in research labs [2, 
5,  8,  10,  11]—motivate  us  to  explore  the  potential  for 
racetrack memory to be used in computer architectures. 
As  we  explain  in  more  detail  in  Section  II,  racetrack’s 
unique design provides both the advantages mentioned above 
but also a new reliability challenge. Racetrack memory stores 
bits on a large number of  nanowire tracks that can each be 
accessed one bit at a time with a fixed port; the bits are shifted 
along the fixed track such that the desired bit position is over 
the  port.  This  design  enables  excellent  storage  density  and 
short access latencies, but it is unfortunately susceptible to an 
978-1-7281-0057-9/19/$31.00 ©2019 IEEE
DOI 10.1109/DSN.2019.00016
1
Robert Calderbank 
Electrical & Computer 
Engineering 
Duke University 
Durham, USA 
PI:EMAIL 
Daniel J. Sorin 
Electrical & Computer 
Engineering 
Duke University 
Durham, USA 
PI:EMAIL 
Density ((cid:1832)(cid:2870)) 
Volatile 
Read (ns) 
Write (ns) 
TABLE I. COMPARING MEMORY TECHNOLOGIES 
PCM  MRAM  SRAM  Racetrack 
No 
4-16 
10-50 
50-500 
No 
20-60 
10-35 
10-90 
No 
1-2 
3-10 
10-20 
Yes 
140 
1-10 
1-10 
error model that is unfamiliar to architects: shift errors. Shift 
errors  include  both  deletions  and  insertions  [12,  13].  A 
deletion occurs when the track is shifted more than expected 
and thus one (or more) bits are skipped, i.e., the memory is 
over-shifted. An insertion occurs when the track is shifted less 
than expected and the bit under the port does not change, and 
we read the same bit twice (or even more), i.e., the memory is 
under-shifted. 
The goal for architects is to tolerate shift errors without 
sacrificing  too  much  of  the  latency  and  density  benefits 
provided  by  racetrack  memory.  Error  coding—for  any 
memory technology—exhibits a fundamental tension between 
code length (i.e., how many bits are in each codeword), code 
rate (i.e., the ratio of the data bits to the sum of the data bits 
and  the  extra  bits  required  for  the  code),  and  latency. 
Achieving our goal for racetrack memory is complicated by 
both  its  unusual  error  model  (shift  errors)  and  its  bit-serial 
access nature, because the only ways to improve latency are 
to  read  from  multiple  tracks  in  parallel  or  use  shorter 
codewords.  
Consider a grid of racetrack memory, in which each track 
is a horizontal row (even if the track itself is 3D, as discussed 
later), and each column is the collection of bits at the same bit 
position in each track. Assume we want to be able to read (or 
write) C bits at a time. For the best latency, we would prefer 
to read one bit from each of C tracks—achieving a parallelism 
of C—and thus achieve single-cycle accesses. In theory, we 
could  do 
i.e.,  encoding 
information on a per-column basis. Unfortunately, as we show 
in Section III, known vertical coding schemes do not suffice. 
Vertical coding may be possible, but such a solution does not 
exist today.  
this  by  coding  “vertically”, 
If we cannot code vertically, we must code “horizontally” 
by encoding information in a group of C bits on a given track. 
Each  track  would  be  encoded  independently.  We  show  in 
Section III that commonly used codes like Hamming cannot 
handle  shift  errors,  so  we  have  developed  a  new  coding 
technique,  called  GreenFlag 1 ,  that  composes  Varshamov-
Tenegolts (VT) codes [14] with specially crafted delimiter bits 
that detect and correct shift errors. The architectural trade-off 
is that longer GreenFlag codes achieve a better rate but incur 
a  longer  read  latency.  (The  analysis  for  bandwidth  is  more 
subtle but bandwidth is far less sensitive than latency to the 
choice of code.) Assume that codeword length is C bits and 
we wish to access B bits (B>C). The best parallelism we can 
achieve is to read C bits on each of B/C tracks, thus achieving 
a  parallelism  of  B/C.  As  C  increases,  the  trade-off  is  that 
parallelism  decreases  (and  thus  latency  increases)  and  rate 
increases. The exact results for latency and bandwidth depend 
on the hardware, so we have implemented and evaluated the 
circuitry for encoding datawords and decoding codewords.  
There  is  one  clever  but  limited  exception  to  the  above 
analysis, which is HiFi [12]. HiFi is a horizontal “code” that 
can detect and correct errors at the granularity of a single bit. 
In the terms of horizontal coding above, it has the ideal C=1 
and parallelism of B. However, HiFi requires multiple ports 
on each track, and that is only possible  with 2-dimensional 
(2D) tracks. Because 3D tracks can offer vastly greater density 
than 2D tracks [5, 11, 15, 16], we do not consider HiFi or any 
other possible scheme that is constrained to 2D tracks.  
The  architectural  viability  of  racetrack  depends  on  the 
possible  trade-offs  between  code  length,  rate,  latency,  and 
bandwidth, so we analyzed these trade-offs for racetrack with 
GreenFlag at each level of the memory hierarchy. Our goal is 
to  determine  the  viability  of  Racetrack  with  effective  error 
tolerance,  not  to promote  Racetrack  as  necessarily  the  best 
option, and our analysis is thus more of a limit study than a 
cycle-accurate comparison against other schemes. For a given 
level  of  the  memory  hierarchy,  the  viability  of  racetrack 
memory is determined by B/C. Specifically, assume a given 
level of cache requires an access latency to B bits that is no 
longer than a specified amount of time (e.g., 20ns for an L3 
cache).  That 
the  required  access 
parallelism  B/C  and,  because  B  is  fixed,  determines  the 
codeword length C. In turn, C determines the rate of the code, 
and  we  explore  this  relationship  between  C  and  rate  for 
GreenFlag codes. If the rate  is too low, racetrack might be 
considered  unattractive  compared 
to  existing  memory 
technologies. For example, we show that the best rate we can 
achieve for a LLC cache with a 50ns access latency is 0.125. 
It is unlikely that racetrack at this rate is preferable to simply 
using SRAM. 
latency  determines 
We make the following contributions in this paper: 
(cid:120)  We present the GreenFlag coding scheme that combines a 
novel  construction  of  VT  codes  with  specially  crafted 
delimiter bits to efficiently detect and correct shift errors. 
(cid:120)  We  implement  and  evaluate  the  GreenFlag  hardware 
circuitry  required  to  encode  datawords  and  decode 
codewords. 
(cid:120)  We present the first analysis of the viability of racetrack 
memory—based  on  the  trade-off  between  code  length, 
code rate, latency, and bandwidth—at each level of the 
memory hierarchy. 
II.  RACETRACK MEMORY 
This  section  introduces  the  physical  model  of  racetrack 
memory and describes its error model.  
A.  Racetrack Background 
respectively—the 
Racetrack  memory  stores  data  in  tape-like  tracks.  Each 
track stores data bits in magnetic domains and neighboring 
domains are separated by a domain wall. All read/write ports 
and the physical substrate are fixed in position, and as spin-
coherent electric current is passed through a track, its domains 
shift by the magnetic read/write port positioned near the track. 
Although these tracks can be manufactured in two or three 
dimensions—sometimes referred to as horizontal and vertical 
racetrack  memory, 
three-dimensional 
structure  is  preferred  as  it  can  offer  dramatically  greater 
density [5, 11, 16]. With 3D racetrack, the tracks are in a U-
shaped geometry in three dimensions, and the read/write ports 
are  fixed  in  position  at  the  bottom  of  this  structure  as 
illustrated in Fig. 1. The 3D structure of racetrack memory 
limits the feasible number of read/write ports per track to one.  
Because  of  the  huge  density  benefits  of  3D  racetrack 
memory, we consider only 3D tracks and, thus, only coding 
schemes that can be implemented with one read/write port per 
track. However, for simplicity,  when we  illustrate tracks to 
facilitate the description of our code in the following sections, 
we use a 2D schematic representation.  
B.  Error Model 
Our  error  model  includes  single  shift  and  double  shift 
errors2. We do not consider triple or higher shift errors as prior 
work  [12]  has  shown  them  to  have  negligible  probability. 
Similar to prior work [12], we do not include bit-flip errors, as 
we  have  discovered  no  data  on  this  phenomenon  in  the 
literature. We do not claim that bit-flip errors are impossible 
in racetrack memory; if future evidence of them appears, we 
would need to extend our work here to address them. 
To  explain  shift  errors,  we  use  an  example  in  which  a 
number of bits is stored on a track as in  Fig. 2(a). To read 
A single track
from a Racetrack memory
Domain
Wall
Magnetic
Domain (MD)
Fig. 1. 3D (vertical) racetrack 
Substrate
g
n
i
t
f
i
h
S
s
D
M
Read/Write Port
1In car racing, a green flag indicates good track conditions. 
2A single shift error occurs when a single shift operation deletes or 
inserts a single bit. A double shift error occurs when a single shift 
operation deletes or inserts two bits. 
2
Simplified representation of a single track
the data we want to read
Shifting 
direction
  (cid:1854)(cid:2868)
  (cid:1854)(cid:2868)
  (cid:1854)(cid:2869)
  (cid:1854)(cid:2870)
  (cid:1854)(cid:2869)
  (cid:1854)(cid:2869)
  (cid:1854)(cid:2870)
  (cid:1854)(cid:2871)
  (cid:1854)(cid:2870)
  (cid:1854)(cid:2870)
  (cid:1854)(cid:2871)
  (cid:1854)(cid:2872)
  (cid:1854)(cid:2871)
  (cid:1854)(cid:2871)
  (cid:1854)(cid:2872)
  (cid:1854)(cid:2873)
  (cid:1854)(cid:2872)
  (cid:1854)(cid:2872)
  (cid:1854)(cid:2873)
  (cid:1854)(cid:2874)
(a)
  (cid:1854)(cid:2873)
  (cid:1854)(cid:2873)
  (cid:1854)(cid:2874)
  (cid:1854)(cid:2875)
(c)
  (cid:1854)(cid:2874)
  (cid:1854)(cid:2874)
  (cid:1854)(cid:2875)
  (cid:1854)(cid:2876)
(b)
  (cid:1854)(cid:2875)  (cid:1854)(cid:2876)
  (cid:1854)(cid:2875)  (cid:1854)(cid:2876)
  (cid:1854)(cid:2876)  (cid:1854)(cid:2877)
  (cid:1854)(cid:2877)  (cid:1854)(cid:2869)(cid:2868)
shifting data by one position
data position in the absence of shift errors
data position after a single deletion
(d)
Fig. 2. Error-free shifting and shift errors 