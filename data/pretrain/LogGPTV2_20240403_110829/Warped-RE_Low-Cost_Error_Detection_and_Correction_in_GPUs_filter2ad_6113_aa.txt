title:Warped-RE: Low-Cost Error Detection and Correction in GPUs
author:Mohammad Abdel-Majeed and
Waleed Dweik and
Hyeran Jeon and
Murali Annavaram
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Warped-RE: Low-Cost Error Detection and
Correction in GPUs
Mohammad Abdel-Majeed∗, Waleed Dweik∗, Hyeran Jeon, Murali Annavaram
Ming Hsieh Department of Electrical Engineering
{abdelmaj, dweik, hyeranje, annavara}@usc.edu
University of Southern California
Abstract—Graphics processing units (GPUs) are now the dom-
inant computing fabric within many supercomputers. As such
many mission critical applications run on GPUs, which demand
stringent reliability and computational correctness guarantees
from GPUs. Prior approaches to GPU reliability have tackled
solely either error detection, or error correction assuming error
detection is already present. In this paper we present Warped
Redundant Execution (Warped-RE), a uniﬁed framework that
is capable of detecting and then correcting transient and non-
transient errors in the GPU execution lanes. Our work exploits
two critical properties of applications running on GPUs. First, we
observe that neighboring execution lanes in GPUs may operate
on the same values. Thus when neighboring lanes execute the
same instruction using the same values then these lanes provide
inherent DMR (dual modular redundancy) or even inherent
TMR (triple modular redundancy) opportunities. The second
property we exploit is that due to insufﬁcient parallelism or due
to branch divergence, applications do not fully utilize all the
available execution lanes. In this case it is possible to force DMR
or TMR on unused execution lanes, when inherent redundancy
is insufﬁcient. During error-free execution, Warped-RE uses a
combination of inherent and forced DMR to guarantee that every
thread computation within every warp instruction will be veriﬁed.
When an error is detected in a warp instruction, the instruction
is re-executed in TMR mode in order to correct the error and
identify execution lanes with potential non-transient errors. Our
evaluations show 8.4% and 29% average performance overhead
during the DMR and TMR operation modes, respectively. Com-
pared to traditional DMR and TMR, Warped-RE reduces the
power overhead by 42% and 40%, respectively.
Keywords—GPUs; error detection; error correction; value sim-
ilarity;
I.
INTRODUCTION
GPUs are used to execute a wide range of parallel applica-
tions where thousands of threads can be executed concurrently.
In order to support such a large number of active threads,
hundreds or even thousands of execution units are integrated
inside the GPU chip. As technology scales, the susceptibility
to errors due to process variation [1] and short channel
effects [2][3] will increase. Previous research work presented
hardware and software approaches to detect computational
errors in GPU execution lanes [4] [5]. The Warped-Shield
framework proposed in [6] focused on tolerating non-transient
errors in the execution lanes to guarantee forward progress
with minimal performance overhead. However, Warped-Shield
assumes that the faulty execution units are identiﬁed a priori
before error tolerance can be activated to avoid faulty execution
∗
Abdel-Majeed and Dweik made equal contributions
units. In this paper we present the Warped Redundant Exe-
cution (Warped-RE) uniﬁed framework to detect and correct
computational errors in GPU execution lanes. In particular,
the proposed Warped-RE framework is capable of correcting
a single error and detecting up to two errors in every cluster
of three execution lanes.
The most straightforward approach to achieve error de-
tection and correction is triple modular redundancy (TMR).
TMR executes the same instruction three times on disjoint
execution units. The outputs of the three units are fed to a
voter circuit capable of choosing the majority among them
which essentially corrects a single error. In addition, TMR
also provides error isolation capability that identiﬁes a faulty
unit whenever a discrepancy is detected between the three
redundant executions. Considerable area/performance/power
overheads are expended to execute every instruction three
times before even the occurrence of the ﬁrst error. To address
this drawback, we propose to use dual modular redundancy
(DMR) during error-free execution to detect an error, and when
an error is detected then we activate TMR execution to provide
error correction capability.
Even with such an improvement, continually operating in
DMR mode during error free execution results in considerable
overheads. To signiﬁcantly reduce the overhead, Warped-RE
exploits two critical observations about the GPU applications
behavior. The ﬁrst observation is that neighboring execution
lanes in a GPU tend to operate on the same input operands
values. The execution lanes are called SIMT (single instruction
multiple thread) lanes in GPUs. Dozens of SIMT lanes are
clustered together into a streaming multiprocessors (SMs)
within a GPU. The software execution model of GPUs groups
several
the threads in
the warp execute the same instruction but on different input
operands. Since all SIMT lanes associated with the warp
execute the same instruction, whenever the input operands of
the lanes are the same the outputs will be the same, unless
one of the lanes encounters an error. Thus when the lanes
exhibit inherent redundancy they implicitly provide DMR or
even TMR for minimal additional cost.
tens of threads into warps and all
The second observation exploited in this work is the under-
utilization in the SIMT lanes due to insufﬁcient parallelism and
branch divergence. This observation was originally presented
in [4] [7]. Jeon and Annavaram [4] exploit the idle SIMT lanes
to redundantly execute some of the threads within the warp
and achieve intra-warp DMR execution, which can only detect
errors without correcting them. We propose to exploit the same
property to forcibly create new DMR and TMR opportunities
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
DOI 10.1109/DSN.2015.55
DOI 10.1109/DSN.2015.55
331
331
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:52:38 UTC from IEEE Xplore.  Restrictions apply. 
in order to both detect and correct errors.
The fault model in this work assumes that one execution
lane within a cluster of three adjacent SIMT lanes can be
faulty at any given time. Hence, Warped-RE will be able to
correct one error and detect up to two errors per each cluster
of three SIMT lanes. Based on this assumption, our results
show that leveraging the inherent redundancy across threads
within the same warp guarantees low cost DMR execution for
38% of the warps and low cost TMR execution for 36% of
the warps. Exploiting the idle SIMT lanes to force redundancy
allows extra 10% of warps to be redundantly executed during
DMR and TMR modes. Thus, nearly 48% of all the warps
can be opportunistically checked with DMR to detect an error.
Once an error is detected 46% of the warps can be corrected
with TMR. But to provide 100% error detection and correction
we deploy the dynamic warp deformation approach proposed
in [6]. Dynamic warp deformation employs temporal redun-
dancy where a single warp is split into multiple sub-warps to
create more idle lanes opportunities, which are then exploited
for redundant execution, albeit with some performance impact.
The rest of the paper is organized as follows. Section II
describes how to achieve low cost opportunistic redundant ex-
ecution in GPUs. Section III discusses the details of the DMR
mode and how the inherent redundancy and idle SIMT lanes
are used to achieve error detection at low cost. Sections IV
and V discuss the TMR mode operation for error correction
and the warp replay procedure needed to re-execute the faulty
warp instruction. The architectural support for the Warped-
RE framework is presented in section VI. We evaluated the
Warped-RE framework in section VII. The related work and
the conclusions are presented in sections VIII and IX.
II. OPPORTUNISTIC REDUNDANT EXECUTION
Warped-RE framework relies on redundant execution to
achieve error detection and correction in SIMT lanes. To
provide full detection coverage during DMR mode every thread
computation must be replicated on a single disjoint SIMT lane.
Similarly, to provide full correction coverage during TMR
mode every thread computation must be replicated on two
disjoint SIMT lanes. However, redundant execution can cause
high power/performance overheads when implemented naively
in the GPU platform. Instead, in this paper we leverage two
opportunities to reduce the overheads of redundant execution:
ﬁrst, inherent redundancy between threads within the same
warp and second, the underutilization in the SIMT lanes. The
combination of the two opportunities is termed as opportunistic
redundant execution.
The baseline GPU architecture used for the implementation
of Warped-RE framework is an Nvidia Fermi-like architec-
ture [8]. In the Fermi architecture, every SM contains 32 SIMT
lanes divided into two streaming processor (SP) units. Each SP
unit has 16 SIMT lanes and can execute 32 threaded warps
using double clocking; one half of the warp is completed in
the ﬁrst half of the SM cycle and the second half of the warp
is completed in the second half of the SM cycle.
A. Inherent Redundancy
As dictated by the SIMT execution model, all active threads
within a warp execute the same instruction in a given clock.
Hence, when the source operands of two or more active threads
are identical, the outputs of the threads are expected to match
when the SIMT lanes that executed the threads are error-
free. In other words, the threads are considered inherently
redundant when their source operands are identical. There are
multiple reasons why GPU applications exhibit value similarity
among the source operands of the threads within the same
warp. First, some warps operate on constant variables which
have the same values across multiple threads. Second, all the
threads within a warp may compute the same vector base
address which is then accessed using a thread-speciﬁc offset
from the base address. Thus, base address computations of a
vector access exhibit strong similarity. Third, image and video
processing applications that use GPUs exhibit great amount
of value localities in neighboring pixel data. Accordingly, our
detection and correction framework leverages the available
inherent redundancy by comparing the results of inherently
redundant threads within the same warp. The quantiﬁcation for
such opportunities and the details on how they are exploited
in the DMR and TMR modes will be discussed in sections III
and IV, respectively.
B. Underutilization of SIMT Lanes
Although every warp can support up to 32 active threads
executing in a lockstep fashion, some warps have less than
32 concurrent active threads which causes some SIMT lanes
to be idle. This idleness is due to the branch divergence
phenomenon and insufﬁcient parallelism. The intra-warp DMR
mechanism in prior work [4] identiﬁed the underutilization in
the SIMT lanes and exploited it to dual redundantly execute
the active threads within the warp to achieve error detection.
If one were to solely rely on intra-warp DMR to provide
100% error detection coverage, intra-warp DMR requires the
number of idle lanes to be equal or greater than the number
of active threads. In order to identify the active threads, GPUs
rely on the active mask. The active mask is a 32-bit vector
mask that determines which threads within a warp are actually
active during branch divergence or insufﬁcient parallelism. For
instance, if only two threads are active within a warp then the
active mask associated with that warp has two bits set to one,
while the remaining 30 bits are set to zero.
Similar to previous studies [4] [7], we measured the amount
of underutilization in the SIMT lanes by reporting the percent-
age of warps which have 1, 2, 3, ...31, and 32 active threads for
several benchmarks from Rodinia, GPGPU-Sim, and Parboil
suites and plotted the results in Figure 1. The ﬁgure shows that
some benchmarks suffer from insufﬁcient parallelism and end
up having less than 32 active threads for all the warps, as is
the case with the gaussian and NN benchmarks in the ﬁgure.
Alternatively, other benchmarks suffer from branch divergence
and end up having less than 32 simultaneous active threads for
some warps, as is the case with the hotspot, heartwall, and WP
benchmarks. On the other hand, some benchmarks fully utilize
the SIMT lanes by having 32 active threads across the majority
of the issued warps as is the case with the CP and cutcp
benchmarks. From the ﬁgure we infer that three benchmarks,
gaussian, NN, and nw, exhibit more than 50% lane idleness
which provides us the ability to achieve 100% DMR execution
with minimal penalty. However, not all benchmarks exhibit
sufﬁcient lane idleness to provide 100% DMR coverage. As
such in this work we combine inherent redundancy with lane
332332
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:52:38 UTC from IEEE Xplore.  Restrictions apply. 
100% 
e
g
a
t
n
e
c
r
e
p
p
r
a
W
80% 
60% 
40% 
20% 
0% 
backprop 
bfs 
btree  CP 
32 
30 
28 
26 
24 
22 
20 
18 
16 
14 
12 
10 
8 
6 
4 
2 
31 
29 
27 
25 
23 
21 
19 
17 
15 
13 
11 
9 
7 
5 
3 
1 
mri-q 
M U M 
NN 
nw 
pathfinder 
sgem m 
sad 
srad  WP 
lud 
LIB 
lbm 
Benchmarks 
gaussian 
cutcp 
hotspot 
heartwall 
kmeans 
lavaM D 
Fig. 1: Underutilization of SIMT lanes
idleness to signiﬁcantly increase the opportunities for error
detection and correction. By exploiting the idle SIMT lanes on
top of inherent redundancy, non-inherently redundant threads
can be redundantly executed such that more warps can be
DMR-ed and TMR-ed at low cost.
C. Dynamic Warp Deformation
Ideally one should rely on opportunistic redundant ex-
ecution to provide very low cost error correction and de-
tection capabilities. However, there may be warps that do
not exhibit value similarity across SIMT lanes and do not
have sufﬁcient lane idleness to force redundancy. In order
to provide error detection and correction for such warps,
Warped-RE framework deploys the dynamic warp deformation
approach proposed in [6]. Dynamic warp deformation splits a
warp into multiple sub-warps with fewer active threads which
artiﬁcially creates more idle lanes and allows threads which
are not covered by opportunistic redundant execution to be
DMR-ed or TMR-ed. Dynamic warp deformation may cause
performance degradation as more cycles are needed until all
sub-warps complete their execution. Thus, in this work we
try to minimize the warp deformation by ﬁrst relying on
opportunistic redundancy before deploying warp deformation.
III. ERROR DETECTION: OPPORTUNISTIC DMR MODE
A. Opportunistic DMR Granularity
In order to detect the inherent redundancy between threads
within a warp, the source operands of the threads must be com-
pared. One extreme implementation is to compare the source
operands across all the 32 threads within the warp. We refer to
this implementation as warp-level inherent redundancy. Warp-
level inherent redundancy requires comparing each SIMT lane
input with the inputs of all other SIMT lanes, which has a
signiﬁcant hardware complexity. A simpler implementation is
to divide the warp into clusters of size two and only compare
the source operands of the threads within the same cluster
together. The latter implementation is termed as cluster-level
inherent redundancy.
In the warp-level inherent redundancy, a warp is considered
inherently DMR-ed if for every active thread in the warp
there is at least one more active thread with matching source
operands regardless of the physical location of the SIMT lanes
to which the matching threads are assigned to. In the cluster-
level inherent redundancy, a warp is considered inherently
DMR-ed when the active threads assigned to every cluster
have matching source operands. Note that any warp that is
inherently DMR-ed in the cluster-level implementation will
also be inherently DMR-ed in the warp-level implementation,
but not vice versa.
L5
L4
L3
L2
L1
L0
L5
L4
L3
L2
L1
L0
(a)
(b)
0
0
1
1
1
1
0
1
1
0
1
1
L5
L4
L3
L2
L1
L0
L5
L4
L3
L2
L1
L0
(c)
(d)
Fig. 2: DMR inherent redundancy and idle SIMT lanes
To better understand the two implementations, we provide
four examples in Figure 2. In these examples, for simplicity
of illustration it is assumed that every warp consists of six
threads assigned to six SIMT lanes. Note that there are 16
SIMT lanes per SP unit in our actual implementation. When
multiple threads are inherently redundant, their corresponding
SIMT lanes are highlighted with the same hatch pattern in
the ﬁgure. In Figure 2a, threads assigned to L5, L2, L1, and
L0 are inherently redundant and threads assigned to L4 and
L3 are also inherently redundant. According to warp-level
inherent redundancy deﬁnition, this warp is inherently DMR-
ed. When the warp is divided into clusters of size two, the warp
does not qualify as inherently DMR-ed because the threads
assigned to the two leftmost clusters do not have matching
source operands. On the other hand, the warp in Figure 2b
is considered inherently DMR-ed at the warp-level and the
cluster-level implementations.
There are scenarios where inherent redundancy, even at
the warp-level, is insufﬁcient to provide 100% error detection.
For example, the warp shown in Figure 2c is not considered
inherently DMR-ed because the threads assigned to L3 and L0
have distinct source operands. Notice that the ﬁgure shows the
active mask bits on top of the SIMT lanes and that L5 and L4
are idle because their active mask bits are set to ”0”. When
inherent redundancy is not sufﬁcient, these idle lanes can be
exploited to replicate the non-inherently redundant threads to
create a forced redundancy. Similar to inherent redundancy,
the idle lanes can be exploited at the warp-level by allowing
an active thread within a warp to be replicated on any idle
lane within the same warp. As a result, the warp in Figure 2c
can be DMR-ed using a combination of inherent and forced
redundancy at the warp-level. This assertion is true because
L2 and L1 are inherently redundant, and idle SIMT lanes are
exploited at the warp-level by replicating the threads assigned
to L3 and L0 on L5 and L4, respectively.