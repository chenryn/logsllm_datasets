if cur w % g (cid:54)= 0 then
1 // g - GCD returned by gcdBinwidth()
2 // cur_w - Current Bin Width
3 proc adjustBinW idth(g, cur w)
4 if cur w < g then
5
6 else
7
8
9
10
11
12
13
14
15
16 end
17 return cur w
cur w ← cur w − (cur w % g)
cur w ← cur w + (g − (cur w % g))
// make cur_w a multiple of g
if (cur w % g) < (g − (cur w % g)) then
end
end
else
Procedure AdjustBinwidth
bin widths is achieved for a given query—e.g., the number
of connections seen by guard relays—this deﬁnition tends to
hold over time. That is, the guided binning algorithm is most
useful when issuing a new type of query or when the results
of a query indicate unexpected results.
We refer to each run of the guided binning algorithm as
an iteration.
The ﬁrst iteration takes two parameters as input: b, the
number of bins; and e, the total estimate of the statistics
(e.g., total bandwidth, total number of client connections, etc.)
being collected. Equal width bins are assigned for this ﬁrst
iteration—the lower bound of ﬁrst bin is set to 0, a bin-width
10
of (cid:98)e/b(cid:99) is used for the ﬁrst b − 1 bins and the upper bound
of last bin is set to e.
If more iterations are needed, the next iteration uses the
bin width distribution and the noised result of the previous
iteration to obtain a more optimal bin width distribution. The
guided binning algorithm ﬁrst computes the mean value, k
of the noised distribution. Then, in the lexical ordering of
bins, starting from bin 1, it splits all bins that have a value
ri greater than k into (cid:98)ri/k(cid:99) bins. The algorithm also merges
all consecutive bins that have a value less than k until their
combined value does not exceed k.
When a bin is split or when bins are merged, the algorithm
executes the GCDBinwidth procedure. The GCDBinwidth pro-
cedure chooses an optimal GCD value g (of the bin widths up
to that point) such that the total number of auxiliary bins (see
§V-B) is less than 15000. Then the guided binning algorithm
executes the AdjustBinwidth procedure that makes the current
new bin width a multiple of the optimal GCD g.
The algorithm can be terminated during any iteration in
which the analyst obtains a “satisfactory” histogram of the
noised results.
IX.
IMPLEMENTATION AND EVALUATION
We constructed an implementation of HisTor in Python
to verify our protocols’ correctness, assess the utility of the
noised aggregates, and measure the system’s overheads. We
implement GM encryption using the Python libnum library6
with a modulus size of 1024 bits. Our PRF is based on AES in
CFB mode, supported by the PyCrypto cryptographic library.
Mixes perform shufﬂe operations by applying the Fisher-
Yates algorithm, using the AES-based PRF as its source of
randomness.
As a system-wide parameter, we set  = 1 for all exper-
iments unless otherwise indicated. We note that this offers
more privacy than the experimental setting ( = 5) used by
Chen et al. [6]. For histogram queries, we semi-automate the
process of selecting appropriate bin widths using the human-
guided bin splitting algorithm described in §VIII.
Experiments were carried out on a 16-core AMD Opteron
machine with 32GB of RAM running Linux kernel 3.10.0.
Our implementation of HisTor is currently single-threaded.
Although HisTor’s computational costs are insigniﬁcant (see
§IX-D), certain operations are embarrassingly parallel—in
particular, encrypting and decrypting the elements of the e
v
vectors—and could likely further beneﬁt from parallelization.
We instantiated three HisTor mix instances, one HisTor
analyst instance, and all DCs on our 16-core server. In a real
deployment, these instances would all be distributed. Google
Protocol Buffers [29] were used for serializing messages,
which were communicated over TLS connections between
HisTor components. We use Python’s default TLS socket
wrapper for securing communication. All communication took
place over the local loopback mechanism (localhost).
Our experiments do not run actual Tor relay or client code.
As explained in more detail next, we derive our unnoised
6https://github.com/hellman/libnum
statistics from existing published data sets7. This data is used
as input to our DC instances, which then run HisTor protocols
to enable the analyst to obtain (noised) aggregate results.
A. Queries and Data Sets
We evaluate HisTor by considering three histogram
queries: the number of client connections as observed by Tor
guards, the amount of bandwidth used by Tor guards, and the
amount of exit bandwidth used by Tor exit relays. As our
ground truth, we use data from both the Tor Compass and
the Tor Metrics Portal.
Number of client connections.
For the number of client
connections, each Tor guard acts as a DC. In total, we
instantiate 1839 DCs—the total number of guards reported by
the Tor Compass with a non-zero selection probability.
We derive our “ground truth” by considering the total
number of direct users (T ) connecting to Tor as reported by
the Tor Metrics Portal over the period of July 26th through
July 30th, 2016. We assign pi · T client connections to each
guard relay i, where pi is the guard selection probability for
guard i as reported by the Tor Compass.
Bandwidth used by guards/exits.
Similarly, as our ground
truth for the bandwidth observed by guards (resp. exits), we
consider the total guard (resp. exit) bandwidth (B) reported by
the Tor Metrics Portal over the same ﬁve-day time period. Each
guard (resp. exit) acts as a DC, and is assigned a bandwidth
cost of (pi · B), where pi is the selection probability of the
guard (resp. exit). We instantiate 1839 DCs when measuring
guard bandwidth, and 924 DCs in the case of exit bandwidth.
The latter is the number of exits reported by the Tor Compass
that have a non-zero selection probability.
We do not argue that the above procedures yield perfect
ground truth. We apply them to derive a gross approximation
of the distributions of client connections and bandwidths which
can then be used to test the efﬁcacy of HisTor under near-real-
world conditions. When deployed, HisTor allows for much
more accurate and ﬁne-grained statistics reporting than offered
by the Tor Metrics Portal.
B. Accuracy
Figure 5 shows the returned histograms for the three
queries when applied to the Tor datasets. The Figure plots
the results of the histogram query after three iterations of the
guided binning algorithm (see §VIII). Other iterations exhib-
ited similar accuracy (as measured by the difference between
the noised and unnoised distributions), but had arguably less
useful bin deﬁnitions.
HisTor reports the “Noised” values shown in Figure 5. As
is clear from the Figure, these noised values closely resemble
7Note on ethical considerations: We evaluate HisTor using only already
published data from the Tor Compass and Tor Metrics Portal. This data,
by its nature,
is derived from the activities of human subjects. Because
the data has already been published and contains no personally-identiﬁable
information (PII), IRB approval was not required by our institution(s). Much
more importantly, the data itself is carefully collected by the Tor Project in
a manner that protects the privacy and anonymity of Tor’s users. The Tor
Compass and Tor Metrics Portal publish only aggregate information (e.g., at
the granularity of a country) that is unlikely to expose information about any
particular user. This paper advocates for even stronger privacy protections.
11
Fig. 5. The aggregate histogram results returned by HisTor when the analyst issues a query for the number of client connections as observed by guards (left),
the amount of bandwidth used by guards (center), and the amount of bandwidth used by exit relays (right). Also shown is the unnoised distribution (“Actual”).
TABLE I.
DISTANCES BETWEEN THE “ACTUAL” AND “NOISE”
DISTRIBUTIONS SHOWN IN FIGURE 5.
Distance function
No. Client Conn
R2
Bhattacharyya
0.98466
0.01820
GuardBW ExitBW
0.96970
0.98290
0.01179
0.02542
Fig. 7. HisTor’s communication cost per epoch (y-axis) as a function of the
number of bins (b; shown on the x-axis). Both axes are plotted in log scale.
encrypted matrices between the mixes and the analyst. To be
practical, a statistics gathering system should impose a low
communication overhead for the DCs, since relays are already
a bandwidth-limited resource in Tor [8]. We envision that
mixes and the analyst are dedicated resources for HisTor, and
our goal is to not incur unreasonable bandwidth requirements
for these components.
We explore HisTor’s bandwidth costs by varying the
number of bins b in a query. The values of the bins for the type
of query (class vs. histogram) do not affect the communication
cost, as the DCs only transmit e
ν) for both query
types. In our bandwidth measurements, we ﬁx the number of
DC relays at 1839.
v (and not e
Figure 7 shows the average communication costs for a DC,
mix, and analyst. For up to 80 bins, the communication cost
for each DC is fairly modest and is approximately 150 KB per
hour (or about 42 Bps). Generally, we anticipate the number
of bins to be around 20, although this can vary depending
upon the analyst’s query. As a potential point of interest, the
histograms shown in Figure 5 were derived using the guided
binning process, and resulted in 20, 21, and 20 bins (from left
to right).
Even when the number of bins is quite large (1280), a
DC’s communication cost is only 2.4 MB over the course of
the hourlong epoch—or 0.67 KBps.
The communication costs are greater for the mixes and
the analyst. With 40 bins, each mix consumes 47.8 MB of
bandwidth per hour, while the analyst uses 3.1 MB. In our
Fig. 6. The distance between the actual and noised distributions, as measured
by the Bhattacharyya distance (left y-axis) and R2 (right y-axis).
those of the unnoised (“Actual”) ground truth data. Looking at
just the “Noised” values, an analyst can clearly obtain useful
information about the distributions of client connections, guard
bandwidths, and exit bandwidths.
As a more quantiﬁable indicator of the closeness between
the noised and unnoised distributions, we consider both the co-
efﬁcient of determination (also called the R2 distance) and the
Bhattacharyya Distance [3]. The latter measures the divergence
between two probability distributions and ranges from 0 (iden-
tical distributions) to ∞. An R2 value of 1 indicates perfect
prediction. When no correlation exists, R2 = 0. Table I reports
the distances between the actual and noised distributions. Our
results highlight that even with a conservative setting of  = 1,
HisTor produces highly accurate aggregates.
The tradeoff between accuracy and security is governed by
the choice of . We explore this space by varying  between 0.2
and 2.0 for the connection count query. As shown in Figure 6,
we ﬁnd that varying  has little effect on accuracy. The overall
variation in R2 (resp. Bhattacharyya) distance between  = 0.2
and  = 2.0 was only 0.315 (resp. 0.098).
C. Bandwidth Overhead
HisTor incurs communication overhead by transmitting
encrypted counters between the DCs and the mixes, and
12
0 - 251252 - 502503 - 753754 - 10041005 - 12551256 - 15061507 - 17571758 - 20082009 - 22592260 - 25102511 - 27612762 - 30123013 - 32633264 - 35143515 - 37653766 - 40164017 - 42674268 - 45184519 - 47694770 - 1817993No. of Client Connections050100150200250300350400450500No. of GuardsActualNoised0.00%2.72%5.44%8.16%10.88%13.59%16.31%19.03%21.75%24.47%27.19%Percentage of Guards0 - 12 - 34 - 45 - 67 - 89 - 910 - 1112 - 1314 - 1415 - 1617 - 1718 - 1920 - 2122 - 2223 - 2425 - 2627 - 2728 - 2930 - 3132 - 559560 - 11812GuardBandwidth (MB)050100150200250300350400450500550600No. of GuardsActualNoised0.00%2.72%5.44%8.16%10.88%13.59%16.31%19.03%21.75%24.47%27.19%29.91%32.63%Percentage of Guards0 - 119120 - 239240 - 359360 - 479480 - 599600 - 719720 - 839840 - 959960 - 10791080 - 11991200 - 13191320 - 14391440 - 15591560 - 16791680 - 17991800 - 19191920 - 20392040 - 40784079 - 1835118352 - 734057ExitBandwidth (KB)050100150200250300350400450No. of ExitsActualNoised0.00%5.41%10.82%16.23%21.65%27.06%32.47%37.88%43.29%48.70%Percentage of Exits0.20.40.60.81.01.21.41.61.82.00.0000.0230.0460.0690.0920.115Bhattacharyya DistanceBD0.650.720.790.860.931.00R2R2102040801603206401280No. of Bins101102103104105106107Communication Cost (KB)MixAnalystClientFig. 8. Microbenchmark results for the DSes (left), mixes (center), and analyst (right). Boxes denote the lower and upper quartile values, with a line at the
median. The “whiskers” show the range of the data within 1.5xIQR from the lower and upper quartiles. Outliers are indicated with triangles.
largest binning scenario with 1280 bins, each mix consumes
1.5 GB of bandwidth each hour, or 424.7 KBps; the analyst
requires 27.7 KBps.
In summary, we ﬁnd that for modest number of bins (20-
40), HisTor incurs very little bandwidth overhead, and can
thus support multiple concurrent queries.
D. Computation Overheads
To understand the computation costs of HisTor, we per-
form a series of microbenchmarks. In our measurements, we
consider the connection counting histogram query with twenty
bins and 1839 DCs.
ν to e
i (such that R = Ri⊕ R(cid:48)
The left side of Figure 8 shows the distribution of the
processing overheads for the DCs. The operations involved
in maintaining the oblivious counters are initialization, incre-
menting, and mapping (from e
v). The total costs of these
operations is, in the worst case, less than two seconds per hour
(on a single core). Additionally, the DCs generate the random
vectors Ri and R(cid:48)
i), incurring a worst
case processing overhead of approximately 7.2 ms per hour.
The performance overheads for a mix are shown in the
center of Figure 8. To explore the range in overheads, we
repeat our query 100 times and plot the range of processing
costs incurred by the mix over all runs. Here, the operations
consist of GM decryption, the generation of noise records,
and shufﬂing the matrices. Each hour, in the worst case, a mix
spends approximately one minute of computation for a single
query. Using a single core, a mix could thus support at worst
60 simultaneous queries per hour.
The analyst’s processing times are shown in the right side
of Figure 8. As with the mix, we show the results over 100
iterations of the query. The most burdensome operation is
veriﬁcation of the three matrices. This consumes less than three
seconds of processing, in the worst case, per hour.
Overall, the processing costs of operating HisTor is neg-
ligible for the relays (DCs) and analyst, and manageable for
the mixes.
X. RELATED WORK
Loesing et al. [22] motivate the need for performing
statistical analysis of the Tor network. The authors promote
privacy-preserving statistics gathering as a means to identify
13
trends in the network, to detect performance bottlenecks, to
discover attacks against the network, and to better understand
how Tor is being blocked and censored in various regions of
the Internet [22].
We are not the ﬁrst to propose using differential privacy to
collect sensitive statistics on Tor. Elahi et al. [15] introduce two
variants—one based on secret sharing and another that uses
distributed decryption—to privately collect trafﬁc statistics for
Tor. PrivEx provides strong, measurable privacy protection
even against compromised participants. However, PrivEx does
not provide integrity guarantees, and as we demonstrate in
§III, even a single malicious DC can cause inaccurate results.