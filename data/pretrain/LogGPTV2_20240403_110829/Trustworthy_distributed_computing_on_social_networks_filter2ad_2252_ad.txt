### 6.5.2 Evaluation of Scheduling Policies

The performance difference when using different outlier handling policies can vary significantly, ranging from as low as 2% (when \( p = 0.1 \) in the physics co-authorship graph; see Fig. 6l) to as high as 70% (when \( p = 0.5 \) and outlier handling is applied in the wiki-vote graph; see Fig. 6o). These patterns are more clearly illustrated in Fig. 6, which shows the impact of various parameter and policy combinations.

One intuitive explanation for this behavior lies in the fairness aspects provided by the different policies. The shortest-first policy prioritizes shorter tasks, leading to a higher number of completed tasks over time, thus contributing more to the cumulative distribution function (CDF). Conversely, the longest-first policy focuses on longer tasks, resulting in fewer completed tasks but ensuring that the most resource-intensive tasks are handled first. The round-robin policy strikes a balance by alternating between shorter and longer tasks, yielding a mixed set of completed tasks.

### 6.5.3 Evaluation of Trust-Based Scheduling

Next, we evaluate the trust-based scheduling described in Section 4.3 and its impact on SocialCloud's performance. We use the settings outlined in Section 4.3.2 to assess the two scheduling policies detailed in Section 4.3.1. For the similarity-based scheduling, we assume a fixed number of nodes under the control of the adversary.

To simulate the adversary model, each node is assigned a variable degree. The degree distribution of the original graph is quantized into 10 brackets, and the degree of an adversary node is randomly selected from these brackets. The portion of malicious nodes is proportional to the number of honest nodes in each bracket. Assuming a budget of interactions, this budget is uniformly distributed across all edges controlled by the adversary. This scenario represents an optimal condition for the adversary and a worst-case scenario for our system.

For the similarity-based model, we limit the similarity score by connecting each malicious node to a random node in the graph, using one of its edges that contribute to its degree. The number of interactions the adversary can generate is set to ten times the maximum number of interactions associated with an honest user in the graph. This setting is pessimistic and assumes a powerful adversary, as meaningful interactions are difficult to forge.

We use the Facebook interaction social graph [40] for evaluation, which consists of 35,665 nodes and 86,525 weighted edges. The weights on the edges correspond to interactions, but for similarity calculations, these weights are omitted. The adversary can introduce 1,000 malicious nodes (approximately 2.8% of the total nodes) into the graph. The budget of interactions for the attacker is 20,000. The average node degree for the adversary is 3.2, slightly higher than the average degree of an honest node. The average weight on an edge controlled by the adversary is 6.25, about a quarter of the average weight on an edge between two honest nodes. Similarity is computed using the Jaccard index [26].

The proportion of outsourced computations depends on the perceived trust based on interaction and similarity. We assume the adversary does not return any computation results, and the outsourcer uses outlier handling policies to manage the failure. The same technique is used to recover from malicious activities when no trust models are employed. We compare the outcomes of the trust-based policies to a scenario where the adversary and honest neighbors are treated equally, using the metric described in Section 6.1.

Fig. 7 illustrates the results of this experiment. In both cases where trust-based scheduling is used, SocialCloud outperforms the plain scenario without trust. For example, while only 75% of compute tasks are completed at a normalized time of 1.5 without a trust model, approximately 92% and 95% of tasks are completed with the similarity- and interaction-based models, respectively. This improvement is due to the effective handling of outliers.

### 6.5.4 Performance with Outlier Handling

Outliers, as defined in Section 4.4, can significantly degrade system performance. However, handling outliers in SocialCloud is straightforward if accurate timing is used. Accurate timing is crucial for understanding the time-to-finish and determining whether rescheduling a task is necessary.

The impact of the outlier handling policy is shown in Fig. 6, which also demonstrates the effects of different scheduling policies. The simple handling policy we proposed improves system performance in all cases, with the improvement varying depending on parameters such as \( p \) and the scheduling policy. The improvement can range from 2% to over 60%. For example, in Physics 2 with the round-robin scheduling policy and \( p = 0.5 \), the potential for improvement is high (see Fig. 6).

### 6.5.5 Variable Task Size

In previous experiments, we considered computational tasks of fixed size (1,000 virtual time units). Here, we address the impact of variable task sizes, uniformly distributed in the interval [500, 1500] time units. The results, shown in Fig. 8, indicate that performance with variable task sizes is generally worse, as expected, since some tasks take longer to complete. However, the relative performance advantages of different scheduling policies remain consistent with those observed in the fixed-size task scenarios.

### 6.5.6 Structure and Performance

The performance of SocialCloud is closely tied to the underlying structure of the social graph. Sparse graphs, such as co-authorship graphs, which are slow-mixing, show performance advantages in SocialCloud. These graphs possess a high trust value, making them particularly useful for SocialCloud. Online social networks, which are more prone to infiltration, do not offer the same level of trust, highlighting the importance of trust-possessing graphs for achieving performance guarantees.

### 6.6 Additional Features and Limitations

Our simulator of SocialCloud omits some details of real-world distributed systems, such as failure handling. However, the simulator includes functionality for handling failures, similar to the outlier handling method (see Section 4.4). Additionally, the simulator abstracts hardware infrastructure and does not account for additional resource consumption, such as memory and I/O. Future work will include adding these functionalities to the simulator to study their impact on SocialCloud's behavior and benefits.

### 7. Related Work

There has been extensive research on using social networks for communication and security systems, including file sharing, anonymous communication, Sybil defenses, routing, referral and filtering, content distribution, and live streaming. Concurrently, Chard et al. [13] suggested using social networks for resource sharing, including a distributed computing service. Recent works have explored the motivations and trust foundations for social cloud systems [52], [53], [54]. Our work shares commonalities with grid and volunteer computing systems, where trust and resource management are key considerations.

### 8. Summary and Future Work

In this paper, we introduced SocialCloud, a distributed computing service that leverages social networks to recruit computing workers and establish trust. We demonstrated the potential of SocialCloud using real-world social graphs, showing that most nodes benefit from outsourcing computations. We evaluated various system features, such as outlier handling, scheduling decisions, and scheduler design, and showed their advantages. To our knowledge, this is the first work to base a computing paradigm on volunteers recruited from social networks and incorporate trust from these networks. Key findings include the relationship between social graphs and the behavior of the computing service, and the impact of trust models on performance. Future work will explore the heterogeneity of resources and the usability of SocialCloud in more detail.