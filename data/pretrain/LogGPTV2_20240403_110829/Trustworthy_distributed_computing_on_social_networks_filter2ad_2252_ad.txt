p and the outlier handling policy. The difference in the
performance when using different policies can be as low as
2 percent (when p ¼ 0:1 in physics co-authorship; shown in
Fig. 6l) and as high as 70 percent (when using p ¼ 0:5 and outlier
handling as in wiki-vote (Fig. 6o)). The patterns are clearer in
Fig. 6 by observing combinations of parameters and policies.
One possible intuitive explanation of this behavior is
understood by the fairness aspects the various policies
provide. While the shortest-first policy finishes shorter
tasks first, thus it is more likely to yield a set of accumulated
tasks that count toward the CDF as the time progresses, the
longest-first policy does the contrary by having less numbers
of finished tasks when dedicating resources for those that
take the longest. On the other hand, the round-robin policy
establishes a middle point, by mixing longer and shorter
tasks in its processing, and yielding a mix of them in the
ones finished.
6.5.3 Evaluation of Trust-Based Scheduling
Now we turn our attention to the trust-based scheduling
described in Section 4.3, and how they affect the performance
of SocialCloud. We use the settings described in Section 4.3.2
for evaluating the two scheduling policies described in
Section 4.3.1. In particular, for the similarity-based sched-
uling, we assume a fixed number of nodes under the control
of the adversary.
To simulate the adversary model described in Section 4.3.2,
we assume each node has a variable degree: we quantize
the degree distribution of the original graph into a set of
brackets (fixed to 10) and randomly select the degree of a
Fig. 5. Performance of SocialCloud on the different social graphs. These
plots demonstrate the inherent differences in these social graphs.
Both figures use p ¼ 0:3 and the round robin scheduling algorithm.
(a) Handled outliers. (b) Unhandled outliers.
MOHAISEN ET AL.: TRUSTWORTHY DISTRIBUTED COMPUTING ON SOCIAL NETWORKS
341
Fig. 6. Normalized time it takes to perform outsourced computations in SocialCloud for different scheduling policies. Naming convention: U stands for
unhandled outlier and B stands for handled outliers (Balanced). RRS, SFS, and LFS stand for round-robin, shortest first, and longest first scheduling.
(a) Physics 1 ðp ¼ 0:1Þ. (b) Physics 2 ðp ¼ 0:1Þ. (c) DBLP ðp ¼ 0:1Þ. (d) Epinion ðp ¼ 0:1Þ. (e) Wiki-vote ðp ¼ 0:1Þ. (f) Physics 1 ðp ¼ 0:3Þ. (g) Physics 2
ðp ¼ 0:3Þ. (h) DBLP ðp ¼ 0:3Þ. (i) Epinion ðp ¼ 0:3Þ. (j) Wiki-vote ðp ¼ 0:3Þ. (k) Physics 1 ðp ¼ 0:5Þ. (l) Physics 2 ðp ¼ 0:5Þ. (m) DBLP ðp ¼ 0:5Þ.
(n) Epinion ðp ¼ 0:5Þ. (o) Wiki-vote ðp ¼ 0:5Þ.
portion of the adversary nodes to fall within that bracket.
This portion of malicious nodes is proportional to the
number of honest nodes falling in that bracket. Assuming a
budget of interactions, we then uniformly distribute that
budget on all edges controlled by the adversary. We note
that this scenario is optimal for the adversary and worst
for our system. For the similarity-based model, and to limit
the similarity score, we connect each of those nodes to a
random node in the graph, using one of its edges that
contribute to its degree.
We assign the number of interactions the adversary is
capable of generating as ten times the maximum number of
interactions associated with an honest user in the graph.
We note that meaningful interactions are hard to forge, and
such simulated settings are pessimistic and correspond to a
powerful adversary.
For the evaluation of
these policies, we use the
interaction social graph of Facebook from [40]. The final
graph consists of 35,665 nodes, with 86,525 weighted
edges. The weights on the edges correspond to the inter-
actions. When using the graph for similarity, weights are
omitted. The adversary is capable of plugging 1000 malicious
nodes (roughly 2.8 percent of the total nodes) in the graph
in both of the similarity and interaction-based models. The
budget of interactions associated with the attacker is 20,000.
The average node degree for the adversary is calculated and
found to be 3.2, slightly more than the average degree of an
honest node. The average weight on an edge controlled by
the adversary is found to be 6.25, roughly a quarter of the
average weight on an edge between two honest nodes. The
similarity is computed as the Jaccard index [26], which is
also described in Section 4.3.1.
The proportion of outsourced computations depends on
the perceived trust by a node towards other nodes based on
weights attributed to interaction and similarity. We assume
that the adversary does not return any computation results
to the outsourcer, and the outsourcer uses the outlier
handling policies to perform the computations upon
not hearing back, thus treating the outcomes as a failure
of performing computations. The same technique is used
to recover from failure due to malicious activities when not
using trust models. We compare the outcomes of the trust-
based policies to the unweighted graph scenario where the
adversary and honest neighbors are treated equally. We
use the same metric described in Section 6.1.
Fig. 7 shows the outcomes of this experiment. We notice
that in both cases where the trust-based scheduling is used,
SocialCloud operates well by outperforming the plain
scenario where no trust is used. For example, we notice that
while only 75 percent of the compute tasks are finished for a
normalized time of 1.5 when not deploying any trust model,
about 92 percent and 95 percent of tasks are finished with the
342
IEEE TRANSACTIONS ON SERVICES COMPUTING, VOL. 7, NO. 3,
JULY-SEPTEMBER 2014
almost 65 percent improvement is due to outlier handling
when x ¼ 1.
6.5.5 Variable Task Size
In all of the above experiments, we considered computational
tasks of fixed size; 1000 of virtual time units in each of them.
Whether the same pattern would be observed in tasks with
variable size is unclear. Here we experimentally address this
concern by using variable duty size that is uniformly
distributed in the interval of [500, 1500] time units. The results
are shown in Fig. 8. Comparing these results to the middle
row of Fig. 6 (for the fixed size tasks), we make two
observations. 1) While the average task size in both scenarios
is same, we observe that the performance with variable task
size is worse. This performance is anticipated as our measure
of performance is the time to finish that would be definitely
increased as some tasks with longer time to finish are added.
2) The same patterns advantaging a given scheduling policy
on another are maintained as in earlier with fixed task length.
6.5.6 Structure and Performance
We note that the performance of SocialCloud is quite related
to the underlying structure of the social graph. We see that
like co-authorship graphsVwhich are
sparse graphs,
in [26] to be slow mixing graphsVhave
pointed out
performance advantage in SocialCloud. These graphs, in
particular, are shown to possess a nice trust value that can
be further utilized for SocialCloud. Furthermore, this trust
value is unlikely to be found in online social networks
which are prone to infiltration, making the case for trust-
possessing graphs even stronger, as they achieve perfor-
mance guarantees as well. This, indeed, is an interesting
finding by itself, since it shows contradicting outcomes to
what is known in the literature on the usefulness of these
graphsVsee Section 3 for more details and the work in [26]
for prior literature that agrees with our findings.
6.6 Additional Features and Limitations
Our simulator of SocialCloud omits a few details concerning
the way a distributed system behaves in reality.
In
particular, our measurements do not report on or exper-
iment with failure. However, our simulator is equipped
with functionality for handling failure in the same way
used for handling outliers (c.f. Section 4.4). Furthermore,
our simulator considers a simplistic scenario of study by
abstracting the hardware infrastructure, and does not
consider additional resources consumed, such as memory
and I/O resources. In the future, we will consider equipping
our simulator with such functionalities and see how this
affects the behavior and benefits of SocialCloud.
Fig. 7. Trust affects the performance of SocialCloud. Both of
the
similarity- and interaction-based models outperforms the plain model,
where no trust is used (parameters: round-robin scheduling at workers,
p ¼ 0:2, and variable task length of mean equal 1000 units.)
similarity- and interaction-based models, respectively. The
intuition behind this boost in the performance is simple:
whereas the plain setting (where no trust is applied) treats
neighboring nodes equally, and tasks of equal size are likely
to be outsourced to a malicious neighborVthus worsening
the overall time for finishing tasks, the trust-based models
described above punishes nodes with less trust. Given that
both interaction and similarity are not easy to manipulate,
according to the settings described earlier, the weight of the
tasks outsourced to the adversary are generally small, and
once the outsourcer realizes they are not completed it will
take shorter to finish them using the outlier handling policy.
6.5.4 Performance with Outliers Handling
Outliers, as defined in Section 4.4, drag the performance of
the entire system down. However, as pointed out earlier,
handling outliers is quite simple in SocialCloud if accurate
timing is used in the system. Providing such timing is
important in understanding the time-to-finish portion and
establish whether rescheduling a task is needed or not.
Here we consider the impact of the outlier handling policy
explained in Section 4.4. The impact of using the outlier
handling policy can be also seen on Fig. 6, which is used for
demonstrating the impact of using different scheduling
policies as well. In this figure, we see that the simple
handling policy we proposed improves the performance
of the system greatly in all cases. The improvement
differs depending on other parameters, such as p, and
the scheduling policy. As with the scheduling policy, the
improvement can be as low as 2 percent and as high as
more than 60 percent. When p is large, the potential
for example, p ¼ 5 in
for improvement
Physics 2 with the round robin scheduling policy where
is highVsee,
Fig. 8. Normalized time to perform outsourced computations in SocialCloud, for variable task size. (a) Physics 1 ðp ¼ 0:3Þ. (b) DBLP ðp ¼ 0:3Þ.
(c) Epinion ðp ¼ 0:3Þ. (d) Wiki-vote ðp ¼ 0:3Þ.
MOHAISEN ET AL.: TRUSTWORTHY DISTRIBUTED COMPUTING ON SOCIAL NETWORKS
343
For simplicity, we do not consider the heterogeneity of
resources, such as bandwidth and resources,
in nodes
acting as workers in the system. Furthermore, we did not
consider how this affects the usability of our system and
what decision choices this particular aspect of distributed
computing systems would have on the utility of our
paradigm. While this would be mainly a future work to
consider (c.f. Section 8), we expect that nodes would select
workers among their social neighbors that have resources
and link capacities exceeding a threshold, thus meeting an
expected performance outcome.
7 RELATED WORK
There have been many papers on using social networks for
building communication and security systems. Below we
highlight a few examples of these efforts and works.
Systems built on top of social networks include file
sharing [32], [7], [41], [26], anonymous communication [42],
[33], Sybil defenses [11], [23], [43], [44], [10], [26], routing
[24], [25], [45], referral and filtering [46], content distribu-
tion [47], [48], and live streaming systems [49], among many
others [50]. Most of these systems use social networks’ trust
and connectivity for their operation.
Concurrent to our work, and following their work in
[51], Chard et al. [13] suggested the use of social networks
to build a resource sharing system. Whereas their main
realization was still a social storage system as in [51], they
also suggested that the same vision can be used to build a
distributed computing service as we advocate in this work.
Recent realizations of this vision have been reported in [52]
and [53]. In [52], Thaufeeg et al. devised an architecture
where ‘‘individuals or institutions contribute the capacity
of their computing resources by means of virtual machines
leased through the social network’’. In [53] Koshy et al.
further explored the motivations of users to enable social
cloud systems for scientific computing. Caton et al. explored
foundations of trust in social cloud computing environ-
ments [54]. Engineering incentives for social cloud have
been studied in [55] and additional scientific applications
based on a social network governed computing nodes are
explored in [56].
With a similar flavor of distributed computing services
design, there has been prior works in literature on using
volunteers’ resources for computations exploiting locality
of data [16], [15], examination of programing paradigms,
like MapReduce [57] on such paradigm [28]. Finally, our
work shares several commonalities with grid and volunteer
computing systems [27], [28], [16], [15], [29], [58], of
which many aspects are explored in the literature. Trust
of grid computing and volunteer-based systems is explored
in [35], [36]. Applications built on top of these systems,
that would fit to our use model, are reported in [15], [31],
among others.
8 SUMMARY AND FUTURE WORK
In this section we summarize our work and conclude
with directions that we would like to investigate as a
future work.
8.1 Summary
In this paper we have introduced the design of SocialCloud,
a distributed computing service that recruits computing
workers from friends in social networks and use such social
networks that characterize trust relationships to bootstrap
trust
in the proposed computing service. We further
advocated the case of such computing paradigm for the
several advantages it provides. To demonstrate the poten-
tial of our proposed design, we used several real-world
social graphs to bootstrap the proposed service and
demonstrated that majority of nodes in most cases would
benefit computationally from outsourcing their computa-
tions to such service. We considered several basic distrib-
uted system characteristics and features, such as outlier
handling, scheduling decisions, and scheduler design, and
show advantages in each of these features and options
when used in our system. To the best of our knowledge,
this is the first and only work in literature that bases such
design of computing paradigm on volunteers recruited
from social networks and tries to bring the trust factor from
these networks and use it in such systems. This character-
istic distances our work from the prior work in literature
that uses volunteers’ resources for computations [16], [15].
Most important outcome of this study, along with the
proposed design, is two findings: the relationship exposed
between the social graphs and the behavior of the built
computing service on top of them, and the way trust
models impact the performance of SocialCloud. In particu-
lar, we have shown that social graphs that possess strong
trust characteristics as evidenced by face-to-face inter-
action [26], which are known in the literature for their poor
characteristics prohibiting their use in applications
(such as Sybil defenses [11], [23]), have a self-load-balancing
characteristics when the number of outsourcers are relatively
small (say 10 to 20 percent of the overall population on nodes