title:Understanding OSN-based facial disclosure against face authentication
systems
author:Yan Li and
Ke Xu and
Qiang Yan and
Yingjiu Li and
Robert H. Deng
Understanding OSN-Based Facial Disclosure Against Face
Authentication Systems
Yan Li, Ke Xu, Qiang Yan, Yingjiu Li, Robert H. Deng
School of Information Systems, Singapore Management University
{yan.li.2009, kexu.2013, qiang.yan.2008, yjli, robertdeng}@smu.edu.sg
ABSTRACT
Face authentication is one of promising biometrics-based user au-
thentication mechanisms that have been widely available in this era
of mobile computing. With built-in camera capability on smart
phones, tablets, and laptops, face authentication provides an attrac-
tive alternative of legacy passwords for its memory-less authentica-
tion process. Although it has inherent vulnerability against spoof-
ing attacks, it is generally considered sufﬁciently secure as an au-
thentication factor for common access protection. However, this
belief becomes questionable since image sharing has been popular
in online social networks (OSNs). A huge number of personal im-
ages are shared every day and accessible to potential adversaries.
This OSN-based facial disclosure (OSNFD) creates a signiﬁcant
threat against face authentication.
In this paper, we make the ﬁrst attempt to quantitatively measure
the threat of OSNFD. We examine real-world face-authentication
systems designed for both smartphones, tablets, and laptops. Inter-
estingly, our results ﬁnd that the percentage of vulnerable images
that can used for spooﬁng attacks is moderate, but the percentage
of vulnerable users that are subject to spooﬁng attacks is high. The
difference between systems designed for smartphones/tablets and
laptops is also signiﬁcant. In our user study, the average percentage
of vulnerable users is 64% for laptop-based systems, and 93% for
smartphone/tablet-based systems. This evidence suggests that face
authentication may not be suitable to use as an authentication fac-
tor, as its conﬁdentiality has been signiﬁcantly compromised due
to OSNFD. In order to understand more detailed characteristics of
OSNFD, we further develop a risk estimation tool based on logis-
tic regression to extract key attributes affecting the success rate of
spooﬁng attacks. The OSN users can use this tool to calculate risk
scores for their shared images so as to increase their awareness of
OSNFD.
Categories and Subject Descriptors
K.6.5 [Management of Computing and Information Systems]:
Security and Protection—Authentication; I.4.9 [Image Processing
and Computer Vision]: Applications
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ASIA CCS’14, June 4–6, 2014, Kyoto, Japan.
Copyright 2014 ACM 978-1-4503-2800-5/14/06 ...$15.00.
http://dx.doi.org/10.1145/2590296.2590315.
Keywords
Face authentication; online social networks; OSN-based facial dis-
closure
1.
INTRODUCTION
Online social networks (OSNs) have been an essential part of
modern social life. As the platforms for experience sharing and
social interaction, numerous personal data including personal im-
ages are being published in OSNs such as Facebook, Google+, and
Instagram at every moment. According to a recent report by Face-
book, 350 million personal images are published by users on Face-
book every day [40].
It is very likely that these images contain
facial images where the users’ faces can be clearly seen. The large
base number indicates that these shared personal images could be-
come an abundant resource for potential attackers to exploit, which
introduces the threat of OSN-based facial disclosure (OSNFD).
OSNFD may have a signiﬁcant impact on the current face
authentication systems, which is one of promising biometrics-
based user authentication mechanisms. Face authentication have
been widely available on all kinds of consumer-level computing
devices such as smartphones, tablets, and laptops with built-in
camera capability. Popular face authentication systems include
Face Unlock [10], Facelock Pro [8], and Visidon [38] on smart-
phones/tablets, Veriface [24], Luxand Blink [25], and FastAc-
cess [39] on laptops. These systems provide attractive alternatives
of legacy passwords, as face authentication requires zero memory
efforts from users and usually has higher entropy than legacy pass-
word as users tend to choose easy-to-guess passwords [28]. Previ-
ously, the major obstacle for an adversary to compromise face au-
thentication is that physical proximity is required to capture a vic-
tim’s facial images. However, this is no longer necessary since the
appearance of OSNFD. OSNFD provides abundant exploitable re-
sources affecting the applicability of face authentication as it com-
promises its conﬁdentiality, which is one of fundamental require-
ments for authentication [14, 18]. The facial images used for face
authentication are no longer secrets and can be disclosed in large
scale due to OSNFD.
In this paper, we make the ﬁrst attempt to provide a quantitative
measurement on the threat of OSNFD against face authentication.
We investigate real-world face-authentication systems designed for
both smartphones, tablets, and laptops. These systems recognize
users by analyzing facial images captured by built-in cameras. Our
study collects users’ facial images published in OSNs and uses
them to simulate the spooﬁng attacks against these systems. Since
all target systems including Google’s Face Unlock [10, 8, 38, 24,
25, 39] are closed-source and do not provide any programmable
testing interfaces, enormous efforts are made for image collection
and testing. We also build a dataset containing important image at-
413tributes that are common in real-life photos but rarely used in prior
controlled study on face authentication [6, 13].
Our study reveals interesting results indicating that face authen-
tication may not be suitable to use as an authentication factor. Al-
though the percentage of vulnerable images that can be used for
spooﬁng attacks is moderate, the percentage of vulnerable users
that are subject to spooﬁng attacks is high. On average, the per-
centage of vulnerable users is 64% for laptop-based systems, and
93% for smartphone/tablet-based systems. Our results also show
the difference between systems designed for smartphones/tablets
and laptops, as smartphones/tablets have to be accessible in more
varied environments. Further investigation shows the quality of im-
ages is a more important factor affecting the success rate of spoof-
ing attacks compared to quantity. A user who uploads a few clear
facial images is more vulnerable than another user who uploads
much more facial images of lower quality due to makeup, illumina-
tion, or other negative effects. All these ﬁndings show that OSNFD
has signiﬁcantly compromised the conﬁdentiality of face authenti-
cation.
In order to understand more detailed characteristics of OSNFD,
we further develop a risk estimation tool based on our dataset. Lo-
gistic regression is used to extract key attributes affecting the suc-
cess rate of spooﬁng attacks.
It achieves a precision of 81%, a
recall of 83%, and an F1 score of 82% on average. It can help users
evaluate the risk of uploading an image by calculating a risk score
based on the extracted attributes, which makes them aware of the
threat of OSNFD.
The contributions of this paper are summarized as follows:
• We investigate the threat of OSN-based face disclosure (OS-
NFD) against face authentication. Our results suggest that
face authentication may not be suitable to use as an authen-
tication factor, as its conﬁdentiality has been signiﬁcantly
compromised by OSNFD.
• We make the ﬁrst attempt to quantitatively measure the threat
of OSNFD by testing real-world face authentication systems
designed for smartphones, tablets, and laptops. We also build
a dataset containing important image attributes that signif-
icantly affect the success rate of spooﬁng attacks. These
attributes are common in real-life photos but rarely used in
prior controlled study on face authentication [6, 13].
• We use logistic regression to extract key attributes that af-
fect the success rate of spooﬁng attacks. These attributes are
further used to develop a risk estimation tool to help users
measure the risk score of uploading images to OSNs.
2. PRELIMINARIES
2.1 Face Authentication
Face authentication is a biometrics-based user authentication
mechanism, which veriﬁes a user’s identity by using information
extracted from the user’s facial features. As illustrated in Figure 1,
a typical face authentication system uses a camera to capture the
user’s facial image/video as input, and then veriﬁes it with enrolled
biometric information for the claimed identity. The objective of a
face authentication system is to recognize a user as long as the in-
put is collected from the legitimate user, while rejecting the inputs
from all other users.
Two key modules are involved in this veriﬁcation process. The
ﬁrst module is the face detection module, which identiﬁes the face
region and removes irrelevant information of an image. The pro-
cessed image is then passed to the next module named face match-
Figure 1: Work ﬂow of a typical face authentication system
ing. This module computes a similarity score for the input image
based on an enrolled face template containing key features which
can be used to distinguish a user from other users and imposters.
Different algorithms may be used for these two modules, but all
face authentication systems generally have these two modules and
follow this work ﬂow. In the end, a face authentication system out-
puts the ﬁnal decision (i.e. accepting or rejecting a claim) accord-
ing to whether or not the similarity score is higher than a match-
ing threshold. This threshold is carefully chosen so as to achieve
a proper balance between false rejection rate and false acceptance
rate.
2.2 OSN-based Facial Disclosure and Threat
Model
The OSN-based facial disclosure (OSNFD) addresses the issue
when users’ face biometrics are involuntarily disclosed by sharing
personal images in OSNs. These disclosed face biometrics would
raise security risks against face authentication systems.
It is a well-known limitation of face authentication that it is sub-
ject to spooﬁng attacks based on captured face biometrics, where
an adversary attempts to circumvent user authentication by replay-
ing a victim’s facial images/videos collected at an early time. As
shown in Figure 1, a face authentication system is not expected to
tell whether an input image is from a live user or from a captured
image/video, as they are all valid inputs from a legitimate user col-
lected at different times. Nevertheless, the impact of these attacks
was believed to be limited due to the requirement that an adversary
had to be physically close to a victim in order to collect the required
information. Therefore, it is generally considered sufﬁciently se-
cure as an authentication factor for common access protection [5],
as we observe that many face authentication systems [10, 8, 38,
24, 25, 39] such as Google’s Face Unlock and Lenovo’s Veriface,
are widely available on all kinds of consumer-level computing de-
vices. Considering its zero-memory requirement, it does provide
an attractive alternative for legacy passwords.
However, this belief may be questionable since OSNFD becomes
a common phenomenon. OSNFD supplies an adversary with abun-
dant facial images to exploit and makes large-scale identity theft
possible for those who use face authentication. Our work inves-
tigates the OSNFD threat and quantitatively measures its impacts.
We consider OSNFD-based attacks where an adversary attempts to
forge a valid input from image resources disclosed from OSNFD so
as to pass face authentication. Our study focuses on image-based
attacks unless explicitly mentioned.
The OSNFD threat may be mitigated with liveness detection
technologies, which rely on extra information sources or heuristic
algorithms to distinguish a live user from a captured image/video.
All the existing sophisticated liveness detection technologies asso-
ciate with considerable costs, which will be explained later in Sec-
tion 5.2. This may explain that only weak liveness detection tech-
CameraFace DetectionFace MatchingStored Face TemplateFace image/videoFace RegionFace templateDecisionFace AuthenticationAccept/Reject414nologies are currently deployed on the face authentication systems
designed for consumer-level computing devices [29, 19]. For ex-
ample, eye blinking detection is a common heuristic used by many
face authentication systems [10, 38, 29] including Google’s Face
Unlock; however, it can be easily bypassed using two facial im-
ages as demonstrated in [31]. Similar tricks can also apply to other
weak liveness detection mechanisms such as head rotation detec-
tion [29, 31]. Even worse is that the existing liveness detection
mechanisms are disabled by default in most popular face authenti-
cation systems [10, 8, 38, 24, 25, 39], as they may have negative
impacts on accessibility.
3. DATA COLLECTION AND EMPIRICAL
ANALYSIS
In order to quantitatively measure the impacts of OSNFD, we
conduct a user study to collect real personal images that have been
shared in OSNs. The collected images are used to test against real-
world face-authentication systems chosen from the most popular
face authentication products in terms of user base [37, 11]. This
section describes the detailed process of data collection and the re-
sults of our empirical analysis. We use the following classiﬁcations
in our discussion.
First, we classify the security settings of a face authentication
system into low and high. Most of face authentication products [10,
8, 38, 24, 25, 39] provide very limited choices on security set-
tings that generally affect the recognition threshold used in the face
matching module. For example, Google’s Face Unlock [10] does
not provide any option for users to adjust its security strength. Most
of our tested products [8, 38, 24, 25, 39] only have two options
for users, labeled as “high accessibility” (i.e.
low security) and
“high security”. Only Lenovo’s Veriface [24] provides a scroll-
bar for users to adjust its security strength from the lowest to the
highest. Therefore, we use “low” to indicate that a target system
enforces the weakest security protection, and use “high” to indicate
the strongest security protection achievable to the system.
Second, we classify face authentication systems into mobile and
traditional. A system is labeled as mobile if it is used for smart-
phones or tablets, while a traditional system is used for laptops or
desktops. A mobile system is usually more tolerant to varied en-
vironments, as it should be accessible no matter where a user uses
the device. Laptops is considered as traditional as it is not expected
to be used from anywhere at any time like what users expect smart-
phones and tablets.
Third, we classify users into different groups according to the
pattern of their sharing behaviors. As observed in our study, it is
quite common that a user tends to upload edited images where fa-
cial landmarks are signiﬁcant changed to create better visual ap-
peal. Therefore, it is also an important factor that needs to be con-
sidered.
These classiﬁcations represent three major factors that affect the
effectiveness of OSNFD-based attacks, which are security settings,
target platforms, and user behaviors, respectively. We use them as
controlled parameters to evaluate the severity of OSNFD, and more
sophisticated statistical analysis will be given in the next section to
identify the key attributes that can be used to mitigate the OSNFD
threat.
3.1 Data Collection
There are 74 participants involved in our study including 36
males and 38 females with age range between 19 and 35. Most
of these participants are students in our university. Each participant
is paid with 10 dollars as compensation. The study is conducted in
a quiet room. The study consists of three parts. In the ﬁrst part,
we ask each participant to select and download 20 facial images
published within the last 12 months in popular OSNs such as Face-
book, Google+, Instagram, etc. A facial image is deﬁned as an
image where a participant’s face can be seen. But the participant’s
face may be affected by many negative effects such as blur, occlu-
sion (e.g. covered by a sunglasses), head rotation (e.g. non-frontal
head pose). All these effects will be examined in our study.
In the second part, we capture the participant’s facial images with
35 controlled head poses and 5 facial expressions using a Canon
EOS 60D (18.0-megapixel DSLR CMOS camera). The resulting
images are 5184 × 3456 in size with inner pupil distance of the
subjects typically exceeding 400 pixels. 35 controlled head poses
are speciﬁed by both horizontal and vertical rotation. Rotation an-
gles are represented as (rotH, rotV ) where rotH corresponds to
the angle of horizontal rotation while rotV corresponds to the an-
gle of vertical rotation. The value range of rotH contains 0◦, 10◦
to left/right, 20◦ to left/right, 30◦ to left/right while the value range
of rotV contains 0◦, 10◦ to up/down, 20◦ to up/down. We choose
these boundary values according to the common restriction of ex-
isting face authentication systems [1], where a participant should
not pass user authentication if rotH exceeds 30◦ or rotV exceeds
20◦ degrees. On the other hand, 5 facial expressions include neu-
tral expression, smile without showing teeth, smile showing teeth,
closed eyes, and open mouth. Continuous lighting system is used
to eliminate the shadow on the participants’ faces.
We use a helmet equipped wit a gyroscope to control head rota-
tion of the participants. The use of gyroscope has advantages over
the other approaches, which includes attaining theoretical accuracy
of less than 1 degree, ignoring the head position, measuring only
orientation, not affected by metallic interference [27]. For each
head pose, we ﬁrstly ask the participants to face to the DSLR cam-
era and help them adjust their heads to frontal position in the way
similar to [13]. Then the participants rotate their heads to the re-
quired angles with help of the gyroscope. The gyroscope generates
real-time rotation angles and broadcasts them via WiFi. This rota-
tion information will be received and displayed on an iPad screen,
and shown to the participants. Thirdly, we ask the participants to
hold their head poses and one of our researchers then removes the
helmet gently and quickly in order to avoid movement of the heads
during helmet removal. After that, the images of each head pose
are captured immediately.
In the ﬁnal part, the participant will be asked to ﬁll in a question-
naire for collecting the participant’s attitudes towards usage of face
authentication systems and sharing behaviors in OSNs.