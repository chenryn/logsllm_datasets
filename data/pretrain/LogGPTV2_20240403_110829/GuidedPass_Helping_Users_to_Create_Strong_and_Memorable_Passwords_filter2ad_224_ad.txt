initial and the ﬁnal password input by user). The average creation times with
GuidedPass-NE, CMU-NE, zxcvbn-NE, NewNIST, and 3class8 were 105, 111,
53, 62, and 40 sec, respectively. With enforcement, creation times for GuidedPass
and zxcvbn were 110 and 89 sec, respectively.
The empirical PDF of time to create a password with each approach is pro-
vided in Fig. 4. The average time to create a password was up to two times higher
for suggestion-based approaches (GuidedPass-NE, GuidedPass, and CMU-NE)
than for those that oﬀer no user guidance (NewNIST, zxcvbn-NE, and zxcvbn).
This is expected, as users take time to read textual feedback, and suggestions,
and decide how to apply those to their password. GuidedPass-NE, GuidedPass
and CMU-NE all had comparable password creation times of just under 2 min
(105–111 s). Approaches that do not enforce a given target strength had the
lowest password creation time (3class8OP had 40 s, zxcvbn-NE had 53 s, and
New NIST had 62 s), while the zxcvbn approach, which enforced a given tar-
get strength but did not oﬀer guidance to users took 60% longer (89 s instead
of 53 s).
266
S. S. Woo and J. Mirkovic
0.018
0.016
0.014
0.012
0.01
0.008
0.006
0.004
0.002
0
0
GPass
NewNIST
z
GPass-NE
z-NE
cmu-NE
3class8
100
200
300
400
500
600
700
time (sec)
Fig. 4. Empirical PDF of time to create passwords with each approach.
Table 10. Overall suggestions statistics.
Total “Addition” suggestions 80.6%
2.77
Add chars
27.46
Add digits
Add symbols
17.63
24.94
Add uncommon words
Add words
7.81
Total “Structure Change” suggestions 19.4%
Flip Case
2.02
1.01
Insert chars
2.52
Insert digits
2.52
Insert symbols
Insert uncommon words
0.76
1.26
Insert words
0.25
Break sequence
8.82
Delete
Replace word
0.25
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
-5
start
end
0
5
10
15
20
25
30
Fig. 5. ECDF of strength improvement between the initial and the ﬁnal password in
GuidedPass approach.
GuidedPass: Helping Users to Create Strong and Memorable Passwords
267
7.6 Suggestions Adopted by Users
In GuidedPass approach, we present all the applicable suggestions to users. This
way, users have more ﬂexibility in adopting suggestions that they feel they will
be able to recall. In this section, we measured which suggestions were more
frequently employed by the users. We recorded the time and users’ every key
stroke, including back space, and delete key, entered in the password box during
the study. Then, we captured and compared the presented suggestions and those
actually adopted by users. We divided the types of suggestions into two broad
categories: addition vs. structural change. The addition is a suggestion for user
to add certain type of information such as chars, digits, symbols, and uncommon
word in unpredictable locations, as shown in Table 4.
The other structural change is to insert information somewhere in the entered
password. Also, this category includes deleting, replacing, and breaking exist-
ing structure into diﬀerent segments. On average, a user adopted 4.12 sugges-
tions. Most adopted suggestions were of the “addition” type (80.6%), followed
by “structural changes” (19%). Among addition suggestions, most popular were
those asking to add digits (27%) and uncommon words (25%). Among structural
changes, inserting digits and symbols in the middle of an existing password or
changing case were the most adopted suggestions (around 2%). Also, we detected
a lot of delete key actions (8.82% of users), which indicates that users attempted
to delete some part of their original passwords, and create new segments, based
on our suggestions (Table 10).
Next, we seek to understand how changes adopted by users help improve
strength. Thus, we measured the diﬀerence in strength, using guess number,
from the initial to the ﬁnal password for each given user. The initial and ﬁnal
strength distribution is shown in Fig. 5, where the X-axis is the log of guess
number, and the Y-axis is the probability. The overall strength improvement is
about 107–1010 guesses from users’ initial input to ﬁnal passwords as shown in
Fig. 5. We can clearly observe the improvement as users adopted the suggestions
given by GuidedPass.
7.7 Users Sentiment
After each participant completed their
authentication task, they were asked
to rate their agreement with the fol-
lowing statement, on a Likert-scale,
from 1 (strongly disagree)
to 10
(strongly agree) with 5 being neutral
– “the password creation was easy to
use.”
We present the boxplots of users’
responses in Fig. 6. In all cases, the
higher value on the Y-axis indicates a
more favorable response, the red line
10
9
8
7
6
5
4
3
2
1
GPass
NewNIST
z
GPass-NE
z-NE
cmu-NE
3class8
Fig. 6. Boxplots of user preference (easy to
use) on Likert scale (1-strongly disagree, 5-
neutral, 10- strongly agree)
268
S. S. Woo and J. Mirkovic
is the median and edges of the box represent the 25th and 75th percentiles.
The whiskers extend to the most extreme data points not considering outliers,
and outliers are plotted individually as a red cross in Fig. 6. The average Likert
scores for GuidedPass-NE, CMU-NE, zxcvbn-NE, NewNIST, and 3class8 were
7.34, 7.52, 7.59, 7.35, and 6.32, respectively. The average scores with strength
enforcement with GuidedPass and zxcvbn were 7.29 and 6.30. Approach zxcvbn-
NE was the easiest to use with the highest user rating. However, with meter
enforcement, zxcvbn had the worst rating with 6.30, since users were frustrated,
trying to exceed the target password strength without clear guidance on how to
do this. The pairwise corrected p-value was p = 2.04 × 10−6 (cid:3) 0.05 between
zxcvbn and zxcvbn-NE. Similarly to zxcvbn, 3class8 policy was rated 6.30. This
may be counterintuitive because users are very familiar with 3class8. We believe
that lower scores were due to user frustration as they were trying to improve
their password strength (indicated by the visual meter), and did not know how
to achieve this. GuidedPass-NE and GuidedPass had the average of 7.29 and
7.34 ratings. However, there was no statistical diﬀerence between these ratings,
with p = 0.21. The CMU-NE rating was slightly higher, but the pairwise cor-
rected p = 0.81 between CMU-NE and GuidedPass-NE shows that there was no
signiﬁcant statistical diﬀerence in rating between GuidedPass-NE and CMU-NE.
Overall, suggestions based approaches seem to be well accepted by users based
on the average Likert scores.
8 Discussion and Conclusions
Suggestions: Existing password meters, suggestions, or policy fail to adequately
help users create strong yet memorable passwords. Therefore, it remains a crit-
ical challenge to build a password suggestion system, which helps users create
both memorable and strong passwords. GuidedPass oﬀers semantically mean-
ingful and intuitive suggestions to users to create highly memorable passwords
by extending their existing initial inputs as shown in Table 5. Although our sug-
gestions are similar to DataPass [26], our approach provides more options and
actions for users to take, and encourages structural changes. We believe this is
an eﬀective way to guide users, and our results support this.
Acceptance: Users bear the responsibility of ensuring the memorability of pass-
words created under the various password meters, policies, and suggestion sys-
tems. They attempt to balance competing requirements for strength and memo-
rability, and usually err on the side of weaker but more memorable passwords. We
demonstrate that GuidedPass can preserve memorability and improve strength
simultaneously, not separately. Participants in our study exhibited high recall,
and seemed to naturally follow our suggestions to create strong passwords, even
without strength enforcement. Conversely, the worst scenario for users was to
merely enforce a strict policy or strength requirement without providing sug-
gestions. In this scenario, users were be trapped into creating non-memorable
passwords only to meet the strength requirement. Overall users found that Guid-
edPass was usable. Therefore, GuidedPass shows a promising research direction.
GuidedPass: Helping Users to Create Strong and Memorable Passwords
269
Application: Although suggestion based approaches (GuidedPass and CMU)
provide higher memorability and strength, they take twice longer than non-
suggestion based approaches (meters and policies). We believe that a longer
creation time pays oﬀ if users can create memorable and strong passwords. Guid-
edPass can be easily integrated with the existing password creation systems, by
modifying server feedback to the user. No other part of user authentication would
need to change. Thus GuidedPass is highly deployable.
Acknowledgement. We thank our shepherd Tudor Dumitras and anonymous review-
ers for their helpful feedback on drafts of this paper. This research was supported by
the MSIT (Ministry of Science and ICT), Korea, under the ICT Consilience Creative
program (IITP-2017- R0346-16-1007) supervised by the IITP(Institute for Information
& communications Technology Promotion), and by NRF of Korea by the MSIT(NRF-
2017R1C1B5076474).
References
1. Frequently occurring surnames from the census 2000. http://www.census.gov/
topics/population/genealogy/data/2000 surnames.html. Accessed 14 Oct 2015
2. Ansaldo, A.I., Marcotte, K., Scherer, L., Raboyeau, G.: Language therapy and
implications of psycholinguistic and neuroimaging
bilingual aphasia: clinical
research. J. Neurolinguistics 21(6), 539–557 (2008)
3. Blum, M., Vempala, S.S.: Publishable humanly usable secure password creation
schemas. In: Third AAAI Conference on Human Computation and Crowdsourcing
(2015)
4. Bonneau, J., Schechter, S.E.: Towards reliable storage of 56-bit secrets in human
memory. In: USENIX Security Symposium, pp. 607–623 (2014)
5. Burnett, M.: Today i am releasing ten million passwords (2015). https://xato.net/
today-i-am-releasing-ten-million-passwords-b6278bbe7495
6. de Carnavalet, X.D.C., Mannan, M.: From very weak to very strong: analyzing
password-strength meters. In: NDSS, vol. 14, pp. 23–26 (2014)
7. Crawford, S.D., Couper, M.P., Lamias, M.J.: Web surveys: perceptions of burden.
Soc. Sci. Comput. Rev. 19(2), 146–162 (2001)
8. Dell’Amico, M., Filippone, M.: Monte Carlo strength evaluation: fast and reli-
able password checking. In: Proceedings of the 22nd ACM SIGSAC Conference on
Computer and Communications Security, pp. 158–169. ACM (2015)
9. Egelman, S., Sotirakopoulos, A., Muslukhov, I., Beznosov, K., Herley, C.: Does my
password go up to eleven?: the impact of password meters on password selection. In:
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,
pp. 2379–2388. ACM (2013)
10. Florˆencio, D., Herley, C.: Where do security policies come from? In: Proceedings
of the Sixth Symposium on Usable Privacy and Security, p. 10. ACM (2010)
11. Florˆencio, D., Herley, C., Van Oorschot, P.C.: Pushing on string: the ‘don’t care’
region of password strength. Commun. ACM 59(11), 66–74 (2016)
12. Grassi, P.A., et al.: DRAFT NIST special publication 800-63B digital identity
guidelines (2017)
13. NEA Guidelines: NIST special publication 800-63B version 1.0. 2 (2006)
14. Habib, H., et al.: Password creation in the presence of blacklists (2017)
270
S. S. Woo and J. Mirkovic
15. Hanesamgar, A., Woo, K.C., Mirkovic, J.: Leveraging semantic transformation
to investigate password habits and their causes. In: Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems (2018)
16. Inglesant, P.G., Sasse, M.A.: The true cost of unusable password policies: password
use in the wild. In: Proceedings of the SIGCHI Conference on Human Factors in
Computing Systems, pp. 383–392. ACM (2010)
17. Ji, S., Yang, S., Wang, T., Liu, C., Lee, W.H., Beyah, R.: PARS: a uniform and
open-source password analysis and research system. In: Proceedings of the 31st
Annual Computer Security Applications Conference, pp. 321–330. ACM (2015)
18. Kelley, P.G., et al.: Guess again (and again and again): measuring password
strength by simulating password-cracking algorithms. In: 2012 IEEE Symposium
on Security and Privacy (SP), pp. 523–537. IEEE (2012)
19. Komanduri, S., Shay, R., Cranor, L.F., Herley, C., Schechter, S.E.: Telepathwords:
preventing weak passwords by reading users’ minds. In: USENIX Security, pp.
591–606 (2014)
20. Komanduri, S., et al.: Of passwords and people: measuring the eﬀect of password-
composition policies. In: Proceedings of the SIGCHI Conference on Human Factors
in Computing Systems, pp. 2595–2604. ACM (2011)
21. Shay, R., et al.: Can long passwords be secure and usable? In: Proceedings of
the 32nd Annual ACM Conference on Human Factors in Computing Systems, pp.
2927–2936. ACM (2014)
22. Shay, R., et al.: Designing password policies for strength and usability. ACM Trans.
Inf. Syst. Secur. (TISSEC) 18(4), 13 (2016)
23. Shay, R., et al.: Encountering stronger password requirements: user attitudes and
behaviors. In: Proceedings of the Sixth Symposium on Usable Privacy and Security,
p. 2. ACM (2010)
24. Summers, W.C., Bosworth, E.: Password policy: the good, the bad, and the ugly.
In: Proceedings of the winter International Symposium on Information and Com-
munication Technologies, pp. 1–6. Trinity College Dublin (2004)
25. UCREL CLAWS7 Tagset (2016). http://ucrel.lancs.ac.uk/claws7tags.html
26. Ur, B., et al.: Design and evaluation of a data-driven password meter. In: CHI
2017: 35th Annual ACM Conference on Human Factors in Computing Systems,
May 2017
27. Ur, B., et al.: How does your password measure up? The eﬀect of strength meters
on password creation. In: USENIX Security Symposium, pp. 65–80 (2012)
28. Veras, R., Collins, C., Thorpe, J.: On the semantic patterns of passwords and their
security impact. In: Network and Distributed System Security Symposium (NDSS
2014) (2014)
29. Wheeler, D.L.: zxcvbn: low-budget password strength estimation. In: Proceedings
of the USENIX Security (2016)
30. Woo, S., Kaiser, E., Artstein, R., Mirkovic, J.: Life-experience passwords (LEPs).
In: Proceedings of the 32nd Annual Conference on Computer Security Applications,
pp. 113–126. ACM (2016)