simplicity, we consider a scenario where every device is em-
bedded with the same secret key, generated by the generator.
This is easily generalized to a system with certiﬁcate chains
and possibility for revocation, as discussed in Section V-G.
The following properties must hold for G
, P
IA
, V
IA.9
IA
Completeness. An IA scheme IA is complete if it is always
possible to successfully prove the authenticity of an authentic
image. That is, for every N and for every N-image I with a
permissible provenance e = (O, (u1, ..., un) , Γ):
⎡
⎢⎣V
Pr
IA (vk
, I, π) = 1
IA
(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)
(pkIA,vkIA,skIA)←GIA(1N ,1λ)
σ←SS(skIA,O)
(I,π)←prove(e,σ)
⎤
⎥⎦ = 1
where we deﬁne prove (e, σ) to yield (In+1, πn+1), computed
using the recurrence relation:
I1 ← O, π1 ← σ, and (Ii+1, πi+1) ← P
, Ii, πi, ui, γi) .
IA (pk
IA
Unforgeability. The unforgeability of the signature scheme
S still holds, even when considering adversaries that receive
pk
IA as an auxiliary input.
IA and vk
Proof-of-knowledge.
If the veriﬁer accepts a proof π for
an image I generated by some adversary, then the image is
authentic, and moreover, the adversary “knows” a permis-
sible provenance of I and a signature according to which
I is authentic. Formally, an IA scheme IA has the proof-
of-knowledge property if, for every polynomial-time stateful
adversary A, there is a polynomial-time knowledge extractor
E that can output a provenance and a signature, such that for
every N and a large enough λ, and every polynomial-length
series of N-images (I1, .., Ir) for some r ∈ poly (λ), it holds
9These are adapted from the general deﬁnitions of PCD in Appendix D of
[7]. See also Section III.
259259
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:41 UTC from IEEE Xplore.  Restrictions apply. 
that:
⎡
Pr
(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)
VIA(vkIA,I,π)=1
DT (vkIA,I,e,σ)=0
⎢⎢⎢⎣
(pkIA,vkIA,skIA)←GIA(1N ,1λ)
σi←SS(skIA,Ii),1≤i≤r
(I,π)←A(pkIA,vkIA,(Ii,σi)i)
(e,σ)←E(pkIA,vkIA,(Ii,σi)i)
⎤
⎥⎥⎥⎦ ≤ negl (λ)
S
IA
IA
IA.
IA (vk
(1)
Above, DT (vk
, I, e, σ) is the procedure that returns 1 iff I is
authentic with respect to T , p
S according to e and σ, where p
is the public key of the signature scheme, which is contained
in vk
Succinctness and efﬁciency.
IA proofs are short and easy to
, I, π) runs in time Oλ (|I|) and an honestly
verify, i.e., V
generated proof is of length Oλ (1) (where Oλ hides a ﬁxed
polynomial in λ). The prover and generator run in polynomial
time in their inputs and in the (worst-case) running times of
the transformations in T on images of size at most N.10
Statistical zero-knowledge. The IA proofs reveal nothing
beyond the authenticity of the image. Formally, proofs are sta-
tistical zero-knowledge: there exists a polynomial-time stateful
simulator S such that for every stateful distinguisher D that
creates and observes proofs of legitimate images of its choice,
the distinguisher D cannot tell whether it is interacting with a
real prover or with the simulator S which does not even know
the original image. Formally, the following two probabilities
are negligibly close (in λ):
⎡
⎡
⎢⎢⎢⎣
⎢⎢⎢⎢⎢⎢⎣
t∈T
VIA(vkIA,Iin,πin)=1
D(π)=1
t∈T
VIA(vkIA,Iin,πin)=1
D(π)=1
(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)
(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)(cid:7)
1N←D(1λ)
(pkIA,vkIA,skIA)←GIA(1N ,1λ)
(Iin,πin,t,γ)←D(pkIA,vkIA,skIA)
(I,π)←PIA(pkIA,Iin,πin,t,γ)
1N←D(1λ)
(pkIA,vkIA,skIA)←S(1N ,1λ)
(Iin,πin,t,γ)←D(pkIA,vkIA,skIA)
I←t(Iin,γ)
π←S(I)
Pr
Pr
⎤
⎤
⎥⎥⎥⎦ (2)
⎥⎥⎥⎥⎥⎥⎦
(3)
Remark 2. As mentioned, the signing algorithm should be exe-
cuted by a trusted party, e.g., a secure camera (see Section A).
sk
IA should be available only to the generator algorithm and
the signing algorithm. In practice, this also means that the
key should be kept in a protected storage, thus unavailable to
outside untrusted users.
Remark 3. Zero-knoweldge (ZK) is a very useful property
for an IA scheme to have (e.g., to ensure that private or
embarrassing details that were cropped out of an image remain
secret), but one may ask what is the cost of making it a
requirement. In our particular case, our construction yields
zero-knowledge “for free”, since the succinctness of the proofs
relies on SNARK constructions, and today’s most efﬁcient
10In our construction, the dependence is quasilinear in the size of the
arithmetic circuit that computes the compliance predicate, which contains the
sub-circuits performing the transformations in T .
260260
SNARK constructions [43], [22], [4] provide ZK with neg-
ligible overhead over their non-ZK variant..
Remark 4. Our deﬁnition of proof-of-knowledge is non-
standard. We discuss this in Section IV-C.
Remark 5. The prover algorithm is comprised of two parts: (i)
creating the output image by applying the input transformation
on the input image with the input parameters, and (ii) gener-
ating a new proof for the new output image. It is possible to
separate these two steps, by deﬁning an editor algorithm and
a prover algorithm, e.g., to enable a user to edit an image with
one utility and then generate a proof with another. While this
may be desirable for some applications, it is easy to see that
the two methods are equivalent from a cryptographic point of
view. We chose to stick with the ﬁrst one for two reasons.
First, the interfaces are simpler and more elegant. Second, the
translation of parameters from the “image processing” form
to the “arithmetic circuit input” form is handled internally
without requiring the user’s involvement.
Remark 6. PhotoProof leaves the speciﬁcation of permissible
transformations at the hands of the system administrator. It
is up to the system administrator to make sure that
the
transformations chosen cannot be abused, for example, by
being repeatedly applied to accumulate to overall undesirable
changes. Note that in this case, PhotoProof can also restrict
the number of transformations that can be performed to prevent
such an abuse, see Section V-G.
III. PROOF-CARRYING DATA
Proof-Carrying Data [11] is a cryptographic primitive for
enforcing properties of distributed computation executed by
untrusted parties, using proofs attached to every message. As
our construction of the IA scheme is based on PCD, we
provide a brief and informal description of the concept and
terminology. (See [12] for a detailed overview and [9], [7]
for the latest deﬁnitions. Here we follow the deﬁnitions in
Appendix D of [7]).
Consider the scenario of a distributed computation between
multiple untrusting parties, where every party can receive
inputs from previous parties, add its own local data, perform
a computation and output its result to the following parties
(see Figure 1). We can think of this computation as a directed
acyclic graph, where nodes represent computation and edges
represent messages between parties. Edges are labeled with
the content of the message, and vertices are labeled with the
content of their node’s additional local data (if any). This graph
is called the transcript of the computation.
The property to be enforced is encoded as a compliance
predicate, denoted Π, which inspects a single node (i.e., its
incoming input edges, outgoing output edges, and its local
data) and accepts or rejects them. A transcript is said to be Π-
compliant if Π accepts all nodes in the transcript. A message
value m is said to be Π-compliant if it is the ﬁnal edge in
some Π-compliant transcript.
Given a compliance predicate Π, PCD transforms the origi-
nal computation into an augmented computation that enforces
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:41 UTC from IEEE Xplore.  Restrictions apply. 
compliance, in the following sense. Each party attaches, to
each of its output messages, a proof to the claim that the
message is Π-compliant. Thus, in particular, the ﬁnal output of
the computation can be veriﬁed to result from a Π-compliant
computation by merely inspecting the ﬁnal proof associated
with that output. The running time of the prover and veriﬁer,
and the size of the proofs, are all essentially independent of
the transcript’s size.
PCD
PCD
PCD
, V
, P
(cid:2)
Π, 1λ
PCD and veriﬁcation key vk
More concretely, a (preprocessing) PCD system is a triplet
(cid:3)
PCD).11 The generator algorithm
of algorithm (G
G
, given a compliance predicate Π and a security
parameter λ, probabilistically outputs a pair of public keys:
proving key pk
PCD. The generated
keys can be used by all parties to prove and verify messages
for an unlimited number of times. For input messages (cid:6)zin
with matching proofs (cid:6)πin, local data l and an output message
zout, the prover algorithm P
, (cid:6)zin, (cid:6)πin, l, zout) outputs
a new proof πout attesting that zout is Π-compliant (if this
is indeed the case). Given a message z and its proof π, the
, z, π) decides whether the proof
veriﬁer algorithm V
is valid. See Appendix D of [7] for the full deﬁnitions.
PCD (vk
PCD (pk
PCD
PCD
PCD runs in Oλ (|z|) (and,
A PCD system has the following properties. Completeness:
for any result of a Π-compliant transcript, the prover can
generate a message that convinces the veriﬁer. Succinctness:
proof size is Oλ (1) and V
in
particular, is independent of the size of Π or the transcript).
Proof-of-knowledge, which is a strengthening of soundness: an
adversary that successfully convinces the veriﬁer of the claim
that some message z is Π-compliant “knows” of a Π-compliant
transcript which outputs z. The adversary can get additional
polynomial-length auxiliary input, which is chosen before the
PCD keys are generated. (Statistical) zero-knowledge: a proof
for a message does not contain information about the transcript
which produced it.
On the theoretical side, PCD was shown to be constructable
by recursive composition of SNARK proofs [9] (which are,
essentially the single-message case of PCD). SNARK con-
structions are known, and some are implemented, on the basis
of knowledge-of-exponent assumptions [25], [35], [10], [43],
[6], [4], [22] and extractable collision resistant hashes [8],
[39], [10]. Recently, Ben-Sasson et al. [7] presented the ﬁrst
implementation of preprocessing PCD, which was also made
public via the libsnark library [47]; see below for further
details.
Expressing compliance predicates. As discussed, PCD
proves “compliance” as expressed by a predicate Π that applies
to every node of the transcript. We did not specify, however,
what language is used to express Π.
One possibility is to represent it as a computer program
using some programming language. There are implementations
of SNARKs (the 1-hop private case of PCD) for correct
11We follow the deﬁnition of [7], which is a somewhat stricter version
than the one in [11], in the sense that we assume that for any compliance
predicate Π, the generator GPCD can generate the appropriate keys efﬁciently
(the original deﬁnition only requires that a GΠ
PCD exists, i.e., GPCD may be
non-uniform). In a non-preprocessing PCD system, there are no keys or G.
execution of C programs [43], [7], [56], [4], [6]. However,
compiling C programs into an underlying “native” level of
SNARKs, such as Quadratic Arithmetic Programs (QAP) [22])
comes at a large overhead.
For this reason we chose to encode our compliance predicate
using a low-level language called the Rank 1 Constraint Sys-
tem (R1CS), an NP-complete language similar to arithmetic
circuit satisﬁability but allowing general bilinear gates at unit
cost (see Appendix E.1 in [5] for more details). This allows a
tight reduction to QAP, and preserves its expressive power.
Deﬁnition 7. A Rank 1 Constraint System S of size n ∈
N over ﬁnite prime order ﬁeld Fp (Fp-R1CS) is deﬁned by
vectors (cid:6)ai,(cid:6)bi, (cid:6)ci ∈ F
, i ∈ {1, . . . n}. For a vector (cid:6)α ∈
p , we say that (cid:6)α satisﬁes S if (cid:6)(cid:6)ai, (1, (cid:6)α)(cid:7)
=
(cid:6)(cid:6)ci, (1, (cid:6)α)(cid:7) for all i ∈ {1, . . . n}, where (cid:6)·,·(cid:7) denotes the inner
product of vectors.
p, k ≤ m.
such that (cid:6)x can be extended to a vector that satisﬁes S, i.e.,
there is a (cid:6)w ∈ F
The language of S is the set of all vectors (cid:6)x ∈ F
s.t. ((cid:6)x, (cid:6)w) satisﬁes S.
(cid:11)
(cid:6)bi, (1, (cid:6)α)
m−k
p
m+1
p
(cid:12)
m
F
k
As discussed in Section V, our PhotoProof implementation
use libsnark [47], an open-source C++ library which imple-
ments the preprocessing SNARK scheme of [22] and PCD of
Ben Sasson et al. [7]. This PCD implementation receives its
compliance predicates as an Fp-R1CS, and all of its messages,
local data and proofs are vectors over Fp. The libsnark
library also includes implementation of gadget classes, used
to construct instances of R1CS recursively. A gadget has two
main functionalities: generate a constraint system and generate
an assignment. For example, a gadget for a relation R (x, y)
can (i) generate a constraint system (that includes x and y
as variables) which can be satisﬁed iff R (x, y) = 1 and (ii)
given assignments to x, y compute a witness assignment that
satisﬁes this constraint system.
Remark 8. It is usually more intuitive to think of Π as an
arithmetic circuit, in which all the wires carry values from Fp
and gates are ﬁeld operations. There is a linear-time reduction
from any arithmetic circuit to a R1CS. Brieﬂy, the reduction
is performed by adding a variable for each wire of the circuit,
and adding a rank-1 constraint on those variables for each gate.
The resulting system size is linear in the number of gates of the
original circuit. The full details can be found in Appendix E.1
of [5].
IV. IMAGE AUTHENTICATION USING PCD
A. Construction
For any set of image transformations T , we construct
an IA for T , from a preprocessing PCD system and an
existentially unforgeable digital signature scheme [24]. We call