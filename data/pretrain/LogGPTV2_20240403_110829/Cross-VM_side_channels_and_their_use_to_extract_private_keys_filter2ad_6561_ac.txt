probe instance, but there remains the challenge of accu-
rately labeling them as M , S or R. To do so, we need to
establish communication from the victim VM to the at-
tacker VM to inform the latter of the operation being per-
formed (multiplication, squaring, or modular reduction) at
any point in time. However, this communication should take
as little time as possible, since if the communication takes
too long, measurements collected from the prime-probe tri-
als during training would diﬀer from those in testing.
We employ cross-VM shared memory for this communi-
cation. Brieﬂy, Xen permits diﬀerent domains to establish
memory pages shared between them (see [16, Ch. 4]). We
utilize this shared memory by modifying the victim VM to
write to the shared memory the type of operation (M , S, or
R) immediately before performing it, and the attacker VM
reads this value immediately after completing each Probe
of the entire cache.
Another challenge arises, however, which is how to mod-
ify the victim VM’s library that performs the exponentiation
while keeping other parts of the library unchanged. Adding
the shared-memory writes prior to compilation would change
the layout of the binary and so would ruin our Probe results
for the purpose of training. Instead, we prepare the instruc-
tions for shared-memory writing in a dynamic shared library
called libsync. Then we instrument the binary of the expo-
nentiation library to hook the Square, Mult, and ModReduce
functions and redirect each to libsync, which simply up-
dates the shared memory and jumps back to the Square,
Mult or ModReduce function, as appropriate. Because the
libsync and victim’s library are compiled independently,
the address space layout of the latter remains untouched.
Even so, the memory-writing instructions slightly pollute
the instruction cache, and so we exclude the cache sets used
by these instructions (three sets out of 64).
5.2 Noise Reduction
There are two key sources of noise that we need to address
at this phase of the key extraction process. The ﬁrst is the
classiﬁcation errors of the SVM. Noise arising from events
such as random ﬂuctuations in probe timings causes the ma-
jority of SVM classiﬁcation errors. Incomplete prime-probe
overlap with exponentiation operations occasionally creates
ambiguous cache observations, for which no classiﬁcation is
strictly correct. The second is the presence of prime-probe
results and, in turn, SVM outputs that simply encode no in-
formation of interest to the attacker for other reasons, e.g.,
because the victim VCPU had migrated to a diﬀerent PCPU
from the attacker or because it was performing an operation
not of interest to the attacker. Consequently, we develop
a sequence of mechanisms to reﬁne SVM outputs to reduce
these sources of noise.
Hidden Markov Model. We start by employing a hid-
den Markov model (HMM) to eliminate many of the errors
in SVM output sequences. (We assume reader familiarity
with HMM basics. For an overview, see, e.g., [12].) Our
HMM models the victim’s exponentiation as a Markov pro-
cess involving transitions among hidden “square,”“multiply,”
and “reduce” states, respectively representing Square, Mult,
and ModReduce operations. As exponentiation is executed
by the victim, labels output by the attacker’s SVM give a
probabilistic indication of the victim’s hidden state.
As the SVM outputs multiple labels per Square, Mult, or
ModReduce operation, we represent an operation as a chain
of hidden states in the HMM. As is the case with any error-
correcting code, the redundancy of SVM output labels helps
rectify errors. Intuitively, given multiple labels per operation
(e.g., induction of correct sequence SSSSS by a Square op-
eration), the HMM can correct occasional mislabelings (e.g.,
the outlying M in SSSM S). The HMM also corrects errors
based on structural information, e.g., the fact that a square
or multiply is always followed by a modular reduction.
While the HMM takes as input a sequence of SVM la-
bels, each such label, S, M , or R, is ﬁrst mapped into an
expanded label set that reﬂects its corresponding level of
SVM conﬁdence. Given a “high” SVM conﬁdence, in the
310experiments described in Sec. 6, we did so for chains of the
form R1 . . . R4 R5+ of length 24 or more. Chains of length
less than this were discarded.
Consequently, post-processing yields reﬁned HMM out-
puts over the label set {S, M, ∗}.
Filtering out non-cryptographic HMM outputs. Suc-
cessful key reconstruction requires that we reliably identify
and retain observed sequences of cryptographic operations,
i.e., those involving private key material, while discarding
non-cryptographic sequences. Extraneous code paths arise
when the victim migrates to a core away from the attacker
or executes software independent of the cryptographic key.
The SVM in our attack does not include a label for ex-
traneous code paths. (Non-cryptographic code constitutes
too broad a class for eﬀective SVM training.) Long non-
cryptographic code paths, however, are readily distinguish-
able from cryptographic code paths based on the following
observation. A random private key—or key subsequence—
includes an equal number of 0 and 1 bits in expectation.
As a 1 induces a square-and-multiply, while a 0 induces a
squaring only, the expected ratio of corresponding S to M la-
bels output by the SVM, and thus the HMM, is 2:1. Thus,
a reasonably long key subsequence will evidence approxi-
mately this 2:1 ratio with high probability. In contrast, a
non-cryptographic code path tends to yield many Unknown
states and therefore outputs sequences that are generally dis-
carded, or in rare cases yields short sequences with highly
skewed S-to-M ratio.
The following elementary threshold classiﬁer for crypto-
graphic versus non-cryptographic post-processed HMM out-
put sequences proves highly accurate. Within a given HMM
output sequence, we identify all subsequences of S and M la-
bels of length at least α, for parameter α. (In other words,
we disregard short subsequences, which tend to be spurious
and erroneously skew S-to-M ratios.) We count the total
number a of S labels and b of M labels across all of these
subsequences, and let a/(b + 1) represent the total S-to-M
ratio. (Here “+1” ensures a ﬁnite ratio.) If this S-to-M ratio
falls within a predeﬁned range [ρ1, ρ2], for parameters ρ1 and
ρ2, with 0 < ρ1 < 2 < ρ2, the output sequence is classiﬁed
as a cryptographic observation. Otherwise, it is classiﬁed as
non-cryptographic.
We found that we could improve our detection and ﬁl-
tering of inaccurate cryptographic sequences by additionally
applying a second, simple classiﬁer. This classiﬁer counts the
number of M M label pairs in an HMM output sequence. As
square-and-multiply exponentiation never involves two se-
quential multiply operations—there is always an interleaved
squaring—such M M pairs indicate a probable erroneous se-
quence. Thus, if the number of M M pairs exceeds a param-
eter β, we classify the output sequence as inaccurate and
discard it.
We applied these two classiﬁers (S-to-M ratio and M M -
pair) to all HMM output sequences, and discarded those
classiﬁed as non-cryptographic. The result is a set of post-
processed, ﬁltered HMM outputs, of which an overwhelm-
ing majority represented observed cryptographic operations,
and whose constituent labels were largely correct.
5.3 Code-path reassembly
Recall that a major technical challenge in our setting is
the fact that the victim VM’s VCPUs ﬂoat across physical
cores. This movement frequently interrupts attacker VM
Figure 3: Diagram of the HMM used in our exper-
iments with 4096-bit base x and modulus N . Emis-
sion labels are depicted in the lower half, hidden
states in the upper half. Solid arrows indicate tran-
sitions, dotted arrows denote emissions. Emission
probabilities below 0.01 are omitted.
range [0.8, 1.0], a label remains unchanged. For “medium”
conﬁdence, lying within [0.6, 0.8), a label is transformed into
a diﬀerent label indicating this medium conﬁdence; i.e., S,
M , and R are mapped respectively to new labels s, m, and
r. Finally, given a “low” conﬁdence, in [0, 0.6), any of S, M ,
or R is mapped to a generic, “low conﬁdence” label L.
In brief, then, the SVM output label set {S, M, R} is ex-
panded, through coarse integration of SVM conﬁdence mea-
sures, into a set of seven labels {S, M, R, s, m, r, L}. This ex-
panded set constitutes the emission labels of the HMM. We
found that hand-tuning the transition and emission prob-
abilities in the HMM resulted in better performance, i.e.,
fewer errors in HMM decoding, than training via the Baum-
Welch algorithm [10]. The full HMM, with hidden states,
emission labels, and transition and emission probabilities, is
depicted in Fig. 3.
Given this HMM and a sequence of expanded-label SVM
emissions, we run a standard Viterbi algorithm [45] to de-
termine the maximum likelihood sequence of corresponding
hidden states. The result is a sequence of labels from the
hidden-state set {S1, . . ., S5, M1, . . . , M5, R1, . . . , R5,
Unknown}. We refer to this as the HMM output sequence.
Post-processing HMM Outputs. We post-process HMM
output sequences to remove state labels that are redundant
or agnostic to key-bit values. The states in an HMM oper-
ator chain (e.g., S1 . . . S4 S5+, where “S5+” denotes one or
more occurrences of S5) collectively indicate only a single
operation (e.g., one instance of Square). Thus, our post-
processing step replaces every chain of the form S1 . . . S4 S5+
with a single S and every chain of the form M1 . . . M4 M5+
with a single M . Unknown states carry no information about
key bit values and so are discarded.
We found it necessary to post-process R1 . . . R4 R5+ chains
in a somewhat more reﬁned manner. Recall that ModReduce
operations are key-agnostic, and so we discarded such chains,
provided that they were short. The HMM output sequence,
however, would sometimes include long chains of the form
R1 . . . R4 R5+, which would typically signal a cryptographic
observation that passed unobserved. Any such chain of suf-
ﬁcient length was thus replaced in post-processing with a ∗,
indicating a hypothesized omitted Mult or Square.
In our
311prime-probe attempts, and truncates corresponding HMM
output sequences.
It is thus helpful to refer to the post-
processed, ﬁltered HMM outputs as fragments.
Fragments are short, more-or-less randomly positioned
subsequences of hypothesized labels for the target key oper-
ations. Despite the error-correcting steps detailed above,
fragments also still contain a small number of erroneous
S and M labels as well as ∗ labels. The error-correcting
steps detailed in Sec. 5.2 operate within fragments. In the ﬁ-
nal, sequence-reconstruction process described here, we cor-
rect errors by comparing labels across fragments, and also
“stitch” fragments together to achieve almost complete code-
path recovery. This will reveal most of the key sequence;
simple brute forcing of the remaining bits reveals the rest.
Accurate sequence alignment and assembly of fragments
into a full key-spanning label sequence is similar to the well-
known sequence-reconstruction problem in bioinformatics.
There are many existing tools for DNA sequencing and sim-
ilar tasks, e.g., [7, 17]. However, various diﬀerences between
that setting and ours, in error rates, fragment lengths, etc.,
have rendered these tools less helpful than we initially hoped,
at least so far. We therefore developed our own techniques,
and leave improving them to future work.
In this ﬁnal, sequence-reconstruction step of key recov-
ery, we partition fragments into batches. The number of
batches ζ and number of fragments θ per batch, and thus
the total number ζθ of fragments that must be harvested
by the attacker VM, are parameters adjusted according to
the key-recovery environment. It is convenient, for the ﬁnal
stage of processing (“Combining spanning sequences,” see
below) to choose ζ to be a power of three.
Our ﬁnal processing step here involves three stages: inter-
fragment error correction, fragment stitching to generate se-
quences that span most of the code-path, and then a method
for combining spanning sequences to provide an inferred
code-path. The ﬁrst two stages operate on individual batches
of fragments, as follows:
Cross-fragment error-correction. In this stage, we cor-
rect errors by comparing labels across triples of fragments.
First, each distinct pair of fragments is aligned using a
variant of the well-known dynamic programming (DP) algo-
rithm for sequence alignment [31]. We customize the algo-
rithm for our setting in the following ways. First, we permit
a ∗ label to match either a S or an M . Second, because two
fragments may reﬂect diﬀerent, potentially non-intersecting
portions of the key, terminal gaps (i.e., inserted before or
after a fragment) are not penalized. Third, a contiguous se-
quence of nonterminal gaps is penalized quadratically as a
function of its length, and a contiguous sequence of matches
is rewarded quadratically as a function of its length.
We then construct a graph G = (V, E) in which each
fragment is represented by a node in V . An edge is included
between two fragments if, after alignment, the number of
label matches exceeds an empirically chosen threshold γ.
Of interest in this graph are triangles, i.e., cliques of size
three. A triangle (v1, v2, v3) corresponds to three mutually
overlapping fragments / nodes, v1, v2, and v3, and is useful
for two purposes.
First, a triangle permits cross-validation of pairwise align-
ments, many of which are spurious. Speciﬁcally, let k12 be
the ﬁrst position of v1 to which a (non-gap) label of v2
aligned; note that k12 could be negative if the ﬁrst label
of v2 aligned with an initial terminal gap of v1, and simi-
larly for k13 and k23. If |(k13 − k12) − k23| ≤ τ , where τ is
an algorithmic parameter (5 in our experiments), then the
alignments are considered mutually consistent. (Intuitively,
k13 − k12 is a measure of alignment between v2 and v3 with
respect to v1, while k23 measures direct alignment between
v2 and v3. Given perfect alignment, the two are equal.)
Then, the triangle is tagged with the “length” of the region
of intersection among v1, v2 and v3
The second function of triangles is error-correction. Each
triangle (v1, v2, v3) of G is processed in the following way, in
descending order. Each position in the region of intersection
of v1, v2 and v3 has three corresponding labels (or gaps), one
for each fragment. If two are the same non-gap label, then
that label is mapped onto all three fragments in that posi-
tion. In other words, the three fragments are corrected over
their region of intersection according to majority decoding
over labels.
Cross-fragment error-correction changes neither the length
nor number of fragments in the batch. It merely reduces the
global error rate of fragment labels. We observe that if the
mean error rate of fragments, in the sense of edit distance
from ground truth, is in the vicinity of 2% at this stage,
then the remaining processing results in successful key re-
covery. We aim at this mean error rate in parameterizing
batch sizes (θ) for a given attack environment.
Fragment stitching. In this next processing stage, a batch
of fragments is assembled into what we call a spanning se-
quence, a long sequence of hypothesized cryptographic op-
erations. In most cases, the maximum-length spanning se-
quence for a batch covers the full target key.
The DP algorithm is again applied in this stage to every
pair of fragments in a batch, but now customized diﬀer-
ently. First, terminal gaps are still not penalized, though a
contiguous sequence of matches or (nonterminal) gaps accu-
mulates rewards or penalties, respectively, only linearly as
a function of its length. This is done since the fragments
are presumably far more correct now, and so rewarding se-
quences of matches superlinearly might overwhelm any gap
penalties. Second, the penalty for each nonterminal gap is
set to be very high relative to the reward for a match, so as
to prevent gaps unless absolutely necessary.
Following these alignments, a directed graph G′ = (V ′, E′)
is constructed in which each node in V ′ (as in V above) rep-
resents a fragment. An edge (v1, v2) is inserted into E′ for
every pair of fragments v1 and v2 with an alignment in which
the ﬁrst label in v2 is aligned with some label in v1 after the
ﬁrst. (Intuitively, v2 overlaps with and sits to the “right” of
v1.) Assuming, as observed consistently in our experiments,
that there are no alignment errors in this process, the re-
sulting graph G′ will be a directed acyclic graph (DAG).2
A path of fragments / nodes v1, v2, . . . , vm ∈ V ′ in this
graph is stitched together as follows. We start with a source
node v1 and append to it the non-overlapping sequence of
labels in v2, i.e., all of the labels of v2 aligned with the
ending terminal gaps of v1, if any. (Intuitively, any labels
in v2 positioned to the “right” of v1 are appended to v1.)
We build up a label sequence in this way across the entire
path. The resulting sequence of labels constitutes a spanning
sequence. We employ a basic greedy algorithm to identify
2A cycle in this graph indicates the need to adjust parame-
ters in previous stages and retry.
312the path in G′ that induces the maximum-length spanning
sequence.
Combining spanning sequences. The previous stages,
applied per batch, produce ζ spanning sequences. The ζ
spanning sequences emerging from the fragment stitching
stage are of nearly, but not exactly, equal length, and con-
tain some errors. For the ﬁnal key-recovery stage, we im-