yara-3.2.0
lzturbo-1.2
Mar 19 2015
rarlinux-4.0.0
rarlinux-4.0.0
‚úî
‚úî
‚úî
‚úî
‚úî
‚úî
‚úî
‚úî
‚úó
‚úó
‚úó
‚úó
Benchmark Selection: Our benchmark selection (Table 6) fol-
lows the current standard in the fuzzing literature, consisting of
eight binaries from popular open-source applications varying by
input file format (e.g., images, audio, video) and characteristics.
Furthermore, as CGT‚Äôs most popular usage to date [18, 23, 30] is in
accelerating binary-only fuzzing, we also incorporate a set of four
closed-source binary benchmarks distributed as free software. All
6As UnTracer is partially reliant on AFL‚Äôs source-level instrumentation and is hence
impossible to use on binary-only targets in its original form, we implement a fully
binary-only version suitable across all 12 of our evaluation benchmarks.
benchmarks are selected from versions with well-known bugs to
ensure a self-evident comparison in our bug-finding evaluation.
For each tracing approach we omit benchmarks that are unsup-
ported or fail: sam2p and sfconvert for QEMU (due to repeated
deadlock); lzturbo, pngout, rar, and unrar for Dyninst (due to its
inability to support closed-source, stripped binaries [38]); jasper,
nasm, sam2p, lzturbo, pngout, rar, and unrar for RetroWrite (due
to crashes on startup and/or being position-dependent/stripped);
and lzturbo, pngout, rar, and unrar for AFL-Clang (due to it only
supporting open-source targets).
Infrastructure: We carry out all evaluations on the Microsoft
Azure cloud infrastructure. Each fuzzing trial is issued its own
isolated Ubuntu 16.04 x86-64 virtual machine. Following Klees et
al.‚Äôs [32] standard we run 16√ó24-hour trials per benchmark for each
of the coverage-tracing approaches listed in Table 5, amounting
to over 2.4 years‚Äô of total compute time across our entire evalua-
tion. All benchmarks are instrumented on an Ubuntu 16.04 x86-64
desktop with a 6-core 3.50GHz Intel Core i7-7800x CPU and 64GB
memory. We repurpose the same system for all data post-processing.
5.2 Q1: Coverage Evaluation
To understand the trade-offs of adapting CGT to finer-grained cov-
erage metrics, we first evaluate HeXcite‚Äôs code and loop coverage
against the block-coverage-only Coverage-guided Tracer UnTracer;
as well as conventional always-on coverage-tracing approaches
QEMU, Dyninst, RetroWrite, and AFL-Clang. We detail our experi-
mental setup and results below.
5.2.1 Code Coverage. We compare the code coverage of all trac-
ing approaches in Table 5. We utilize AFL++‚Äôs Link Time Optimiza-
tion (LTO) instrumentation [18] to build collision-free edge-tracking
versions of each binary; the same technique is applied to our four
closed-source benchmarks (Table 6) with the help of the industry-
standard binary-to-LLVM lifting tool McSema [14]. We measure
each trial‚Äôs code coverage by replaying its test cases on the LTO
binary using AFL‚Äôs afl-showmap [59] utility and compute the av-
erage across all 16 trials. Table 7 reports the average across all
benchmark‚Äìtracer pairs as well as Mann-Whitney U significance
scores at the ùëù = 0.05 significance level; and Figure 7 shows the
relative edge coverage over 24-hours for several benchmarks.
Versus UnTracer: As Table 7 shows, HeXcite surpasses Un-
Tracer in total coverage across all benchmarks by 1‚Äì18% for a mean
improvement of 6.2%, with statistically higher coverage on 10 of 12
benchmarks. The impact of coverage granularity on CGT is signifi-
cant; besides seeing the worst coverage on unrtf (Figure 7c) and
sfconvert, block-only coverage UnTracer is bested by AFL-Clang
on all 8 open-source benchmarks, demonstrating that sheer speed
is not enough to overcome a sacrifice in code coverage‚Äîwhereas
HeXcite‚Äôs coverage-preserving CGT averages the highest overall
code coverage in our entire evaluation.
Versus binary-only always-on tracing: We see that HeXcite
achieves a mean 23.1%, 18.1%, and 6.3% higher code coverage over
binary-only always-on tracers QSYM, Dyninst, and RetroWrite
(respectively), with statistically significant improvements on all
but one binary per comparison (yara for QEMU, and sfconvert
for Dyninst and RetroWrite). For sfconvert in particular, we find
that all tracers‚Äô runs are dominated by timeout-inducing inputs,
Session 2A: Fuzzing and Bug Finding CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea358(a) nasm
(b) tcpdump
(c) unrtf
(d) pngout
(e) unrar
Figure 7: HeXcite‚Äôs mean code coverage over time relative to all supported tracing approaches per benchmark. We log-scale the trial duration (24 hours) to more
clearly show the end-of-fuzzing coverage divergence.
Binary
vs. Coverage-guided Tracing
HeXcite / UnTracer
jasper
mjs
nasm
sam2p
sfconvert
tcpdump
unrtf
yara
lzturbo
pngout
rar
unrar
Mean Increase
Rel. Cov
1.04
1.05
1.06
1.03
1.04
1.11
1.18
1.03
1.01
1.08
1.02
1.10
+6.2%
MWU
0.403
0.002
<0.001
0.003
<0.001
<0.001
0.002
0.057
<0.001
0.001
0.004
0.005
HeXcite / QEMU
Rel. Cov
MWU
<0.001
<0.001
<0.001
1.71
1.07
1.15
‚úó
‚úó
1.41
1.02
1.08
1.06
1.33
1.02
1.47
+23.1%
‚úó
‚úó
<0.001
0.168
0.028
<0.001
<0.001
0.026
<0.001
1.77
1.09
1.17
1.12
1.00
1.16
1.03
1.12
‚úó
‚úó
‚úó
‚úó
MWU
vs. Binary- and Source-level Always-on Tracing
HeXcite / RetroWrite
HeXcite / Dyninst
Rel. Cov
MWU
Rel. Cov
<0.001
<0.001
<0.001
<0.001
0.057
<0.001
0.041
0.034
0.492
<0.001
0.002
0.034
0.001
‚úó
‚úó
‚úó
‚úó
+18.1%
+6.3%
‚úó
1.04
‚úó
‚úó
1.00
1.13
1.06
1.09
‚úó
‚úó
‚úó
‚úó
‚úó
‚úó
‚úó
‚úó
‚úó
‚úó
‚úó
HeXcite / Clang
Rel. Cov
MWU
0.209
0.231
<0.001
0.292
0.031
0.002
0.440
0.061
1.01
1.01
1.03
1.02
0.99
1.08
1.00
0.95
‚úó
‚úó
‚úó
‚úó
+1.1%
‚úó
‚úó
‚úó
‚úó
Table 7: HeXcite‚Äôs mean code coverage relative to UnTracer, QEMU, Dyninst, Retrowrite, and AFL-Clang. ‚úó = the competing tracer is incompatible with the
respective benchmark and hence omitted. Statistically significant improvements for HeXcite (i.e., Mann-Whitney U test ùëù < 0.05) are bolded.
causing each to see roughly equal execution speeds, and hence, code
coverage. While we expect that timeout-laden binaries are less likely
to see benefit from CGT in general, overall, HeXcite‚Äôs balance of
fine-grained coverage and speed easily rank it the highest-coverage
binary-only tracer.
Versus source-level always-on tracing: Across all eight open-
source benchmarks HeXcite averages 1.1% higher coverage than
AFL‚Äôs source-level tracing, AFL-Clang. Despite having statistically
worse coverage on sfconvert (due to its heavy timeouts), HeX-
cite‚Äôs coverage is statistically better or identical to AFL-Clang‚Äôs on
7/8 benchmarks, confirming that coverage-preserving CGT brings
coverage tracing at least as effective as source-level tracing‚Äîto
binary-only fuzzing use cases.
Binary
jasper
mjs
nasm
sam2p
sfconvert
tcpdump
unrtf
yara
Mean Increase
HeXcite
/ UnTracer
Rel. LoopCov
HeXcite
/ Clang
Rel. LoopCov
1.56
3.61
2.54
1.05
1.89
1.21
3.54
2.98
+130%
1.14
1.06
1.85
1.19
2.56
1.39
0.73
0.95
+36%
Table 8: HeXcite‚Äôs mean loop coverage (i.e., average maximum consecutive
iterations capped at 128) relative to block-only CGT UnTracer and the source-
level conventional tracer AFL-Clang.
5.2.2 Loop Coverage. To determine if coverage-preserving CGT
is more effective at covering code loops, we develop a custom
LLVM instrumentation pass to report the maximum consecutive
iterations per loop per trial. Despite our success in lifting our closed-
source benchmarks to add edge-tracking instrumentation (¬ß 5.2.1),
(a) jasper
(b) mjsbin
(c) unrtf
(d) yara
Figure 8: HeXcite‚Äôs mean loop coverage relative to UnTracer. Each box rep-
resents a mutually-covered loop, with values indicating the mean maximum
consecutive iterations (capped at 128 total iterations to match AFL) over all
16 trials. Green and pink shading indicate a higher relative loop coverage for
HeXcite and UnTracer (respectively), while grey indicates no change.
none of our binary-to-LLVM lifters (McSema, rev.ng, RetDec, reopt,
llvm-mctoll, or Ghidra-to-LLVM) succeeded in recovering the loop
metadata necessary for our LLVM loop transformation to work; thus
our loop analysis is restricted to our eight open-source benchmarks.
We compare HeXcite to UnTracer and AFL-Clang as they sup-
port all eight open-source benchmarks (and hence omit QEMU,
Dyninst and RetroWrite which only support a few). We compute
each loop‚Äôs mean from the maximum consecutive iterations for all
trials per benchmark‚Äìtracer pair, capping iterations at 128 as AFL
0100101Hours of Fuzzing (log-scale)0.8000.8250.8500.8750.9000.9250.9500.9751.000Rel. Edge CoverageClangQEMUDyninstUnTracerHeXcite0100101Hours of Fuzzing (log-scale)0.30.40.50.60.70.80.91.0Rel. Edge CoverageClangRetroWriteQEMUDyninstUnTracerHeXcite0100101Hours of Fuzzing (log-scale)0.600.650.700.750.800.850.900.951.00Rel. Edge CoverageClangRetroWriteQEMUDyninstUnTracerHeXcite0100101Hours of Fuzzing (log-scale)0.50.60.70.80.91.0Rel. Edge CoverageQEMUUnTracerHeXcite0100101Hours of Fuzzing (log-scale)0.20.40.60.81.0Rel. Edge CoverageQEMUUnTracerHeXcite01234567891011012345678910111.01.01.01.01.01.04.731.02.091.121.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.01.00.690.691.041.041.02.091.01.01.412.131.01.01.01.01.051.01.01.02.261.02.851.01.01.381.01.020.142.13.711.01.00.312.370.64.170.812.314.171.641.649.02.472.660.730.511.01.01.830.771.01.01.01.01.01.01.01.01.00.61.01.01.01.02.131.01.01.02.041.511.091.01.231.652.418.860.81.081.01.01.00.654.061.08.331.021.01.01.01.467.01.496.676.41.311.04.641.0Relative Max Consecutive Iterations Per Loop01234567012345671.00.331.01.01.01.04.061.06.771.091.01.116.121.08.93.181.071.03.5810.753.01.381.681.052.284.384.2510.561.18.110.561.3310.646.981.493.762.771.071.071.52.271.61.01.013.042.01.02.881.02.2510.625.02.17.461.350.535.593.76Relative Max Consecutive Iterations Per Loop0123450123454.54.57.861.763.04.54.318.51.243.265.71.00.981.148.751.641.21.951.535.331.51.02.182.181.01.01.331.712.652.196.896.9Relative Max Consecutive Iterations Per Loop0123456780123456781.01.01.01.01.11.01.01.00.841.00.841.01.01.01.01.011.035.01.00.021.01.01.011.337.031.08.172.01.51.05.134.071.131.797.91.01.01.01.511.01.01.04.521.01.013.140.041.01.01.521.04.731.01.01.231.01.01.01.01.01.01.20.61.01.01.01.078.01.251.03.621.16Relative Max Consecutive Iterations Per LoopSession 2A: Fuzzing and Bug Finding CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea359Figure 9: HeXcite‚Äôs mean throughput relative to conventional coverage tracers. We normalize throughput to the worst-performing tracer per benchmark, and